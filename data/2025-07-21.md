<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 82]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.LG](#cs.LG) [Total: 52]
- [quant-ph](#quant-ph) [Total: 36]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.RO](#cs.RO) [Total: 21]
- [eess.SP](#eess.SP) [Total: 12]
- [eess.SY](#eess.SY) [Total: 16]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 13]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.SI](#cs.SI) [Total: 9]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 9]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.NE](#cs.NE) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 本篇论文全面 survey 了无人机（UVA）航拍场景下的开放词汇目标检测（OVOD），将OVOD原理与UVA视觉特性相结合，对现有方法进行分类，并探讨了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UVA）技术的发展，其应用范围不断扩大，但传统UVA航拍目标检测方法主要局限于预定义类别，限制了其适用性。开放词汇目标检测（OVOD）通过借鉴跨模态文本-图像对齐（如CLIP），能够识别以前未见过的物体，提高了UVA在航拍场景理解中的智能性和自主性。

Method: 本篇论文首先将开放词汇目标检测（OVOD）的核心原理与无人机（UVA）视觉的独特特性相结合，然后构建了一个系统性的分类法，对现有UVA航拍图像的OVOD方法进行了分类，并对相关数据集进行了全面的概述。

Result: 对现有OVOD方法进行了系统的分类和全面的概述，并深入分析了无人机航拍场景下OVOD的关键挑战和开放性问题，为该领域的研究提供了有价值的参考和未来发展方向。

Conclusion: 本篇论文提出了一个开放词汇目标检测（OVOD）在无人机（UVA）航拍场景下的系统性分类，并对现有方法进行了全面的概述，同时分析了该领域的关键挑战、开放性问题以及未来的研究方向和应用前景。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [2] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: QuantEIT是一种超轻量级的量子辅助EIT图像重建框架，参数量少，无需训练数据，重建精度高，鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法在EIT图像重建中虽然有前景，但通常需要复杂的网络结构和大量参数，限制了效率和可扩展性。

Method: 提出了一种名为QuantEIT的超轻量级量子辅助推理框架，结合了并行两比特量子电路（QA-Net）生成富有表现力的潜在表征，并通过单个线性层进行电导率重建。

Result: 实验结果表明，QuantEIT在模拟和真实世界的2D/3D EIT肺部成像数据上，相比传统方法，参数量减少99.8%，同时实现了相当或更优的重建精度，并提高了对噪声的鲁棒性。

Conclusion: QuantEIT相较于传统方法，在参数量仅为后者的0.2%的情况下，实现了相当或更优的重建精度，并且对噪声的鲁棒性更强，是EIT图像重建的有效解决方案。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [3] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: EDNIG是一个新的深度学习框架，用于低光图像增强。它使用光照引导和多尺度特征来提高图像质量，并在与最先进方法相比具有竞争力的同时，模型复杂度较低。


<details>
  <summary>Details</summary>
Motivation: 为了在低光照条件下提高图像的增强效果，本研究引入了一种新的深度学习框架，通过光照引导来帮助网络关注欠曝光区域，并利用多尺度上下文特征来处理各种光照条件。

Method: EDNIG是一个基于U-Net的深度学习框架，它整合了从亮通道先验（BCP）导出的光照图作为引导输入，并结合了空间金字塔池化（SPP）模块来提取多尺度上下文特征。模型在生成对抗网络（GAN）框架内进行优化，并使用包括对抗性损失、像素均方误差（MSE）和感知损失在内的复合损失函数。

Result: 实验结果表明，EDNIG在定量指标和视觉质量方面优于现有方法，并且模型复杂度较低。

Conclusion: EDNIG在定量指标和视觉质量方面取得了与最先进方法相媲美的使用，同时保持了较低的模型复杂度，证明了其适用于实际应用。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [4] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: Current Visual Language Models (VLMs) fail at non-local visual reasoning tasks that require understanding relationships between different parts of an image, despite their success in complex visual tasks. Even leading models struggle with basic tests that humans find easy, highlighting a gap in core visual reasoning abilities.


<details>
  <summary>Details</summary>
Motivation: Recent work suggests VLMs struggle with simple perceptual tests despite excelling at complex visual tasks. This evaluation aims to test VLMs' capacity for non-local visual reasoning, which requires chaining evidence from multiple, potentially distant, image regions.

Method: A structured evaluation suite was created to test non-local visual reasoning in VLMs, isolating three forms: comparative perception, saccadic search, and smooth visual search. The evaluation assesses if VLMs can perform visual algorithms similar to humans.

Result: Flagship VLM models (e.g., Gemini 2.5 Pro, Claude Vision 3.7, GPT-o4-mini) performed poorly on the designed tests, barely exceeding random accuracy on some variants, even those considered trivial for humans. This indicates a lack of core visual reasoning capabilities.

Conclusion: Despite improvements in visual acuity, current VLMs lack fundamental visual reasoning skills, failing tests designed to assess non-local reasoning capabilities.

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [5] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 通过基于场景图的CoT提示和GRPO微调，提升了VLMs的空间推理能力和泛化能力，解决了SFT易过拟合和泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究视觉语言模型（VLMs）在空间推理方面的能力，并寻找提高其性能和泛化能力的方法。研究者希望通过链式思考（CoT）提示和强化学习（RL）来增强VLMs处理空间关系的能力，特别是解决模型在面对不同表述方式时性能下降的问题。

Method: 本研究首先评估了不同提示策略对VLMs空间推理能力的影响，特别是CoT提示和基于场景图的CoT提示。随后，研究人员使用SAT数据集上的Group Relative Policy Optimization（GRPO）对模型进行了微调，并使用CVBench评估了其性能，将其与监督微调（SFT）进行了比较。

Result: 研究结果表明，基于场景图的CoT提示能够显著提高VLMs的空间推理准确性。与SFT相比，GRPO在Pass@1评估中实现了更高的准确率，并在分布外（OOD）条件下表现出更强的鲁棒性。SFT容易过拟合表面语言模式，导致在测试时遇到措辞变化（例如，“更近”变为“更远”）时性能下降。相反，GRPO能够更可靠地泛化，并在这些变化下保持稳定的性能。

Conclusion: 本研究通过引入结构化多阶段提示（如基于场景图的CoT）和使用GRPO进行微调，显著提高了视觉语言模型（VLMs）的空间推理能力和泛化能力。研究发现，简单的CoT提示可能损害模型性能，而基于场景图的CoT和GRPO则能有效提升准确性和鲁棒性，尤其是在处理分布外（OOD）条件和词语变化时。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [6] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 利用2D基础模型进行无需训练的开放词汇3D目标检测，并在伪nuScenes数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D目标检测数据集类别有限且标注成本高，限制了其在开放世界场景下的扩展性。而2D视觉语言模型具有丰富的语义理解能力，支持开放词汇检测。

Method: 利用2D视觉语言模型生成文本条件建议，并通过SAM进行分割，再利用相机几何和LiDAR或单目伪深度进行3D投影。引入基于DBSCAN聚类和旋转卡尺的几何膨胀策略进行3D边界框推断，无需训练。构建了伪nuScenes数据集来模拟真实世界的恶劣条件。

Result: 该方法在多种设置下（包括基于LiDAR和纯RGB-D输入）实现了具有竞争力的定位性能，且无需训练且支持开放词汇。

Conclusion: 2D基础模型在3D感知领域具有巨大潜力，能够实现无需训练的开放词汇3D目标检测。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [7] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: A new network ingests 12 data types (image, video, audio, etc.), uses specialized tokenizers and a shared transformer with cross-attention for a unified embedding. It's trained with a novel strategy (iterative modality switching) and an adapted algorithm balancing joint and pairwise training. Proven effective on 25 datasets, achieving SOTA results.


<details>
  <summary>Details</summary>
Motivation: To develop a network capable of ingesting and processing data from approximately 12 different modalities for multimodal and multitask scenarios.

Method: A novel multimodal multitask network using modality specialized tokenizers, a shared transformer architecture, and cross-attention mechanisms to create a unified embedding space. It incorporates modality-specific task heads for different tasks and employs a pretraining strategy with iterative modality switching and a training algorithm that balances fully joint training with pairwise training.

Result: State-of-the-art performances demonstrated across 25 datasets from 12 modalities, validating the effectiveness of the proposed architecture, pretraining strategy, and multitask training.

Conclusion: The proposed novel multimodal multitask network, associated training algorithm, pretraining strategy with iterative modality switching, and adapted multitask training achieve state-of-the-art performance across 25 datasets from 12 modalities.

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [8] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 该研究提出了一种集成了光学动作捕捉和基于Transformer的模型的端到端深度学习框架，用于增强医疗康复。该框架能够处理数据噪声和缺失，实时检测异常运动，并在重建和异常检测方面表现优越，为远程康复提供了有效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决由遮挡和环境因素引起的数据噪声和数据缺失问题，并实时检测异常运动以确保患者安全。

Method: 提出了一种端到端的深度学习框架，该框架集成了基于Transformer的光学动作捕捉模型，以增强医疗康复。

Result: 在心脏病和骨科康复数据集上的评估表明，该框架在数据重建和异常检测方面表现优越。

Conclusion: 该框架为远程医疗康复提供了可扩展、低成本的解决方案，减少了现场监督的需求。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [9] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 本研究提出了一个结合 ViT 和 GNN 的新框架，用于乳腺癌检测，准确率达到 84.2%，并提供可解释的热图。


<details>
  <summary>Details</summary>
Motivation: 早期发现乳腺癌对于提高生存率至关重要，乳腺癌是全球女性的主要死亡原因之一。

Method: 本研究引入了一个创新的框架，该框架集成了 Vision Transformers (ViT) 和图神经网络 (GNN)，以利用 ViT 捕捉全局图像特征的能力和 GNN 建模结构化关系的能力，从而提高乳腺癌的检测能力。

Result: 该框架在 CBIS-DDSM 数据集上实现了 84.2% 的准确率，优于传统方法。此外，可解释的注意力热图为模型的决策过程提供了见解。

Conclusion: 所提出的框架通过结合 Vision Transformers (ViT) 和图神经网络 (GNN)，在乳腺癌检测方面取得了 84.2% 的准确率，优于传统方法。可解释的注意力热图为模型决策过程提供了见解，有助于放射科医生在临床环境中的应用。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [10] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter是一个新颖的物体检测框架，通过FAFCE组件和PHFFNet模块来增强分层特征表示，以提高检测鲁棒性，在保持高精度的同时降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的物体检测架构（如YOLO和DETR）在保持不同尺度特征的一致性方面存在困难，同时难以平衡检测精度和计算效率。为了解决这些挑战，Butter框架被提出，旨在增强分层特征表示以提高检测鲁棒性。

Method: Butter框架引入了两种创新：1. 频率自适应特征一致性增强（FAFCE）组件，通过利用自适应频率滤波来优化多尺度特征一致性，增强结构和边界精度。2. 渐进式分层特征融合网络（PHFFNet）模块，逐步集成多层次特征，以缩小语义差距并加强分层特征学习。

Result: 通过在BDD100K、KITTI和Cityscapes上的大量实验，Butter展示了其卓越的特征表示能力，在提高检测精度的同时降低了模型复杂度。

Conclusion: Butter通过关注分层特征的精炼和集成，为自动驾驶中的物体检测提供了一种先进的方法，在准确性、可部署性和实时计算效率之间取得了平衡。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [11] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [12] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR:  a


<details>
  <summary>Details</summary>
Motivation: 为了解决二维材料在纳米电子学应用中，传统AFM技术（如C-AFM）数据采集速度慢的问题，并满足大规模生产对高效电学表征的需求。

Method: 本研究提出了一种名为SparseC-AFM的深度学习模型，通过对稀疏的导电原子力显微镜（C-AFM）扫描数据进行处理，能够快速准确地重建二维材料的电导率图。

Result: SparseC-AFM能够从稀疏扫描数据中重建出与全分辨率数据具有相似电学性质的电导率图，数据采集时间减少超过11倍，并能有效提取MoS2的薄膜覆盖率、缺陷密度、晶态岛边界、边缘和裂纹等关键材料参数。

Conclusion: 该研究展示了SparseC-AFM在二维材料（如MoS2）的电学性质表征方面的潜力，通过深度学习模型能够从稀疏的C-AFM扫描中快速准确地重建电导率图，从而在保证精度的前提下，将数据采集时间缩短11倍以上，为二维材料的工业化生产和表征提供了新的解决方案。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [13] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 工业缺陷检测正从传统方法转向更先进的开放集计算机视觉技术，以提高精度和适应性，本调查对此进行了概述。


<details>
  <summary>Details</summary>
Motivation: 随着对精度、自动化和可扩展性期望的提高，传统检查方法在满足现实世界需求方面越来越显得力不从心。本调查旨在提供对工业缺陷检测的全面理解，以应对这一挑战。

Method: 对 2D 和 3D 模式中的闭集和开集缺陷检测策略进行了深入分析，重点关注其近年来的演变和新兴趋势。

Result: 本调查全面概述了工业缺陷检测的最新进展，特别是开放集方法在减少对广泛缺陷注释的依赖和识别新异常方面的作用。

Conclusion: 这项调查提供了对 2D 和 3D 模式中工业缺陷检测策略的深入分析，重点介绍了从闭集到开集方法的演变以及新兴趋势。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [14] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 研究发现，将卫星光学影像与温度、风速等其他地理数据融合，能提升卫星机器学习模型的性能，尤其是在数据不足或新地理区域的表现上。硬编码的融合方式效果优于学习方式。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解在监督学习场景中，除了光学影像之外，利用其他输入模式的价值，本研究旨在探索将多种地理数据层与光学影像融合对卫星机器学习模型性能的影响。

Method: 本研究通过为涵盖分类、回归和分割任务的基准数据集添加额外的地理数据层（如环境传感器数据），来生成增强版的卫星机器学习基准任务。随后，利用这些增强的数据集来评估和比较不同输入模式的性能。

Result: 研究结果显示，融合额外的地理输入（如环境传感器数据）与光学影像可以显著提高SatML模型的性能，尤其是在标记数据有限和地理样本外的情况下。硬编码的融合策略相比学习型融合策略表现更优。

Conclusion: 实验结果表明，结合多种地理输入数据与光学影像进行融合，能够显著提升卫星机器学习模型（SatML）的性能。这种提升在标记数据有限和地理样本外（out-of-sample）的情况下尤为明显，这表明多模态输入对于提高SatML模型的数据效率和泛化能力具有重要价值。此外，研究还发现，硬编码的融合策略优于学习型融合策略，这为未来的研究提供了新的思路。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [15] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 一种新的极简概念擦除方法，通过优化生成输出的分布距离来解决安全和版权问题，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在生成高质量图像方面表现出色，但其对大规模无标签数据的依赖引发了安全和版权问题。虽然已有擦除无关概念的方法，但它们往往需要过度的修改，损害了模型的整体效用。

Method: 提出了一种基于生成输出分布距离的新颖极简概念擦除目标，并推导出一个可行的损失函数，利用反向传播进行端到端优化。为了提高擦除的鲁棒性，引入了神经元掩码作为模型微调的替代方案。

Result: 在最先进的流匹配模型上进行的实证评估表明，该方法能够稳健地擦除概念，同时不损害整体模型性能。

Conclusion: 该研究提出了一种新颖的极简概念擦除目标，仅基于最终生成输出的分布距离，并通过可行的损失函数利用反向传播进行端到端优化。该方法通过神经元掩码而非模型微调来提高擦除的鲁棒性，在最先进的流匹配模型上进行了实证评估，结果表明该方法在不损害整体模型性能的情况下能有效擦除概念，为更安全、更负责任的生成模型铺平了道路。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [16] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 本文提出了一种利用低成本二值占用数据进行3D语义占用预测的新方法，通过预训练和自动标注两种方式，有效提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 为了降低3D语义占用预测中数据采集的成本，本文旨在探索利用大规模二值占用数据的潜力，并提出了两种利用方式：预训练和学习型自动标注。

Method: 本文提出了一种新颖的基于二值占用预测的框架，该框架将预测过程分解为二值和语义占用模块，能够有效利用二值占用数据。

Result: 实验结果表明，所提出的框架在3D语义占用预测任务中，无论是在预训练还是自动标注方面，都取得了比现有方法更好的性能。

Conclusion: 所提出的框架在预训练和自动标注任务上均优于现有方法，有效地提升了3D语义占用预测的性能。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [17] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: InSyn是一个基于Transformer的模型，通过明确捕捉交互模式和采用SSOS训练策略，提高了行人轨迹预测的准确性，尤其是在拥挤环境中。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖相对位置来模拟行人交互，但忽略了诸如成对行走或冲突行为等特定的交互模式，限制了在拥挤场景下的预测精度。为了解决这个问题，需要能够明确捕捉多样化交互模式并提高预测准确性的模型。

Method: 提出了一种名为InSyn（Interaction-Synchronization Network）的新型Transformer-based模型，该模型能够显式捕捉多样化的交互模式（如同步行走或冲突行为），并有效模拟方向敏感的社交行为。此外，提出了一种名为Seq-Start of Seq（SSOS）的训练策略，以缓解数值时间序列预测中常见的初始步长发散问题。

Result: InSyn模型在ETH和UCY数据集上的实验结果表明，其性能显著优于近期基线方法，特别是在高密度场景下。SSOS策略成功地提高了序列预测性能，将初始步长预测误差减小了约6.58%。

Conclusion: InSyn模型在ETH和UCY数据集上显著优于现有方法，尤其是在高密度场景下。SSOS策略有效提高了序列预测性能，将初始步长预测误差降低了约6.58%。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [18] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: MADI框架通过MAgD（掩码增强高斯扩散）和Pause Tokens（推理时容量扩展）改进了扩散模型的视觉编辑和组合控制能力。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成方面取得了巨大成功，但在视觉编辑和组合控制方面仍具挑战性。受自监督学习和上下文生成模型进展的启发，提出了一系列简单而强大的设计选择，以增强扩散模型在结构化、可控生成和编辑方面的能力。

Method: 提出了一种名为掩码增强扩散推理时缩放（MADI）的框架，包含两个核心创新：1. 掩码增强高斯扩散（MAgD），一种包含双重腐化过程的新颖训练策略，结合了标准去噪评分匹配和掩码重建。2. 基于Pause Tokens的推理时容量扩展机制。

Result: MADI框架显著提升了扩散模型的编辑性、组合性和可控性。MAgD鼓励模型学习具有区分性和组合性的视觉表征，实现局部和结构感知的编辑。Pause Tokens在推理时增加了计算容量。在训练中采用富有表现力和密集的提示词进一步提升了性能，特别是对于MAgD。

Conclusion: MADI框架通过MAgD训练策略和Pause Tokens推理时容量扩展机制，显著提升了扩散模型的编辑性、组合性和可控性，为通用、上下文生成扩散架构的集成铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [19] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [20] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种新的框架，可以直接从CT/MRI图像生成光滑、CFD兼容的主动脉表面和网格，无需大量标注数据和手动干预。


<details>
  <summary>Details</summary>
Motivation: 现有主动脉构建方法依赖于大型标注数据集和大量手动干预，并且生成的网格难以产生几何一致、结构良好且适合下游CFD分析的表面。为了解决这些挑战，需要一种新的方法。

Method: AortaDiff首先使用体积引导的条件扩散模型（CDM）迭代生成以体积医学图像为条件的中心线。然后，每个中心线点自动用作提示，提取相应的血管轮廓，确保精确的边界划分。最后，将提取的轮廓拟合成光滑的3D表面，生成连续的、CFD兼容的网格表示。

Result: AortaDiff在有限的训练数据下表现有效，成功构建了正常和病变（如动脉瘤或狭窄）的主动脉网格，实现了高质量的可视化，并生成了CFD兼容的主动脉网格，具有高几何保真度。

Conclusion: AortaDiff是一个基于扩散的框架，可以直接从CT/MRI图像生成光滑的主动脉表面，并能生成CFD兼容的网格。该方法在有限的训练数据下表现有效，能够成功构建正常和病变（如动脉瘤或狭窄）的主动脉网格，为心血管研究提供了高质量的可视化和实用的解决方案。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [21] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: COREVQA是一个新的基准测试，用于评估视觉语言模型在拥挤场景下的视觉蕴含推理能力，结果显示现有模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在视觉蕴含推理方面存在不足，未能有效评估模型在处理拥挤场景时的推理能力。

Method: 提出COREVQA（Crowd Observations and Reasoning Entailment）基准测试，包含5608个图像和合成的真/假陈述对。图像来源于CrowdHuman数据集，旨在引发在挑战性拥挤图像上的视觉蕴含推理。

Result: 即使是表现最佳的视觉语言模型，在COREVQA基准测试上的准确率也低于80%，其他模型的准确率在39.98%-69.95%之间。这表明视觉语言模型在处理拥挤场景下的图像-问题对时存在显著的推理能力差距。

Conclusion: 现有的视觉问答基准测试未能充分评估模型在视觉蕴含推理方面的能力，尤其是在处理拥挤场景时。COREVQA基准测试揭示了顶尖模型在该任务上的准确率低于80%，其他模型表现更差，凸显了视觉语言模型在理解和推理图像中的复杂关系方面存在局限性。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [22] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: 提出了一种名为IConMark的AI图像语义水印方法，该方法将可解释的概念嵌入图像，使其能抵抗攻击且可供人类阅读。该方法在水印检测的AUROC得分上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速兴起，区分AI生成的图像和真实图像对于防范错误信息和确保数字真实性至关重要。传统的水印技术在对抗性攻击面前显得脆弱，削弱了其在攻击者存在时的有效性。因此，需要一种新的水印方法来应对这些挑战。

Method: 提出了一种名为IConMark的新颖的、在生成过程中即可抵抗攻击的语义水印方法，该方法将可解释的概念嵌入AI生成的图像中，使其具有可解释性，并能抵抗对抗性操作。该方法不依赖于向AI生成的图像添加噪声或扰动，而是融入有意义的语义属性，使其对人类具有可解释性，因此能够抵抗对抗性操作。此外，还提出了IConMark+SS和IConMark+TM两种混合方法，分别将IConMark与StegaStamp和TrustMark相结合，以增强其抵抗多种图像操纵的能力。

Result: IConMark被证明能够抵抗各种图像增强，并且可供人类阅读，能够进行手动验证。与现有的基线方法相比，IConMark及其变体（IConMark+SS和IConMark+TM）在水印检测的平均接收器操作特征曲线下面积（AUROC）得分方面分别提高了10.8%、14.5%和15.9%。

Conclusion: IConMark是一种新颖的、在生成过程中即可抵抗攻击的语义水印方法，它将可解释的概念嵌入AI生成的图像中，使其具有可解释性，并能抵抗对抗性操作。该方法不仅能抵抗各种图像增强，而且可供人类阅读，能够进行手动验证。IConMark及其变体（IConMark+SS和IConMark+TM）在水印检测的AUROC得分方面优于现有的基线方法。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [23] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: 人工智能系统通过集成多种深度学习模型，在肩部X光片中检测骨折，准确率达95.5%，可用于辅助临床诊断。


<details>
  <summary>Details</summary>
Motivation: 肩部骨折常常被漏诊，尤其是在急诊和高工作量的临床环境中，多达10%的骨折可能被放射科医生遗漏。人工智能驱动的工具可以辅助早期检测并减少诊断延迟。本研究旨在通过专门的肩部X光片人工智能系统来解决这一问题。

Method: 开发了一个多模型深度学习系统，使用了10,000张标注的肩部X光片。模型架构包括Faster R-CNN（ResNet50-FPN, ResNeXt）、EfficientDet和RF-DETR。为提高检测精度，应用了边界框和分类级别的集成技术，如Soft-NMS、WBF和NMW融合。

Result: NMW集成模型达到了95.5%的准确率和0.9610的F1分数，在所有关键指标上均优于单个模型。该模型在召回率和定位精度方面表现出色，证实了其在肩部X光片临床骨折检测中的有效性。

Conclusion: 基于集成的人工智能可以可靠地在X光片中检测肩部骨折，具有高度的临床相关性。该模型准确且已准备好部署，非常适合集成到实时诊断工作流程中。目前该模型仅限于二元骨折检测，用于快速筛查和分诊支持，而非详细的骨科分类。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [24] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 透過結合舊衛星影像和AI，成功在伊拉克發現了新的、已消失的考古遺址。


<details>
  <summary>Details</summary>
Motivation: 為了在過去五十年來經歷了巨大變遷，甚至許多考古遺址已被完全摧毀的環境中，提高AI模型對考古遺址自動識別的能力。

Method: 透過使用1960年代的CORONA衛星灰階影像來升級現有的深度學習模型，並在伊拉克阿布格萊布地區重新訓練了一個基於Bing的卷積神經網絡模型。

Result: 該模型在研究區域的檢測精度顯著提高，影像分割的IoU值超過85%，考古遺址檢測的總體準確率達到90%。此外，還新識別出四個先前未被發現的考古遺址。

Conclusion: 使用1960年代的CORONA衛星影像和人工智能技術，可以有效識別已消失的考古遺址，這對於研究受人類活動影響而消失的考古景觀具有重要意義。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [25] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane通过自监督深度估计和双通路架构，无需额外传感器或数据即可实现准确的单目3D车道线检测，并能在无相机标定场景下工作。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有单目3D车道线检测方法依赖昂贵的深度传感器、难以大规模收集的真实深度数据以及假设相机参数可用性等问题，本文提出了Depth3DLane。

Method: 提出了一种名为Depth3DLane的新型双通路框架，该框架集成了自监督单目深度估计。它利用自监督深度网络获取场景的点云表示，其中鸟瞰图通路提取显式的空间信息，而前视图通路提取丰富的语义信息。然后，Depth3DLane使用3D车道线锚点从两个通路采样特征，并推断出精确的3D车道线几何。此外，该框架还能预测每帧的相机参数，并通过一个理论驱动的拟合过程来增强每段的稳定性。

Result: 实验证明，Depth3DLane在OpenLane基准数据集上取得了有竞争力的性能。与以往的方法不同，所学参数的使用使得Depth3DLane能够应用于相机标定不可行的场景。

Conclusion: Depth3DLane通过集成自监督单目深度估计来解决单目3D车道线检测的局限性，无需昂贵的传感器或额外的真实深度数据。该框架的双通路设计能够同时提取空间和语义信息，并通过3D车道线锚点融合两者以推断精确的3D车道线几何。此外，该方法能够预测每帧的相机参数，并通过每段的拟合过程提高稳定性，使其能够应用于相机标定不可行的场景，并在OpenLane基准数据集上取得了有竞争力的性能。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [26] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: CaSTFormer 是一种新的因果时空 Transformer，用于提高驾驶意图预测的准确性和透明度，解决了现有方法在模拟人类驾驶行为方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的驾驶意图预测方法在准确模拟人类驾驶行为复杂的时空相互依赖性和不可预测的可变性方面仍然不足。

Method: CaSTFormer 提出了一种新的反向移位融合（RSF）机制来实现内部和外部特征流的精确时间对齐，一种因果模式提取（CPE）模块来系统地消除虚假相关性以揭示真实的因果依赖关系，以及一种创新的特征合成网络（FSN）来将这些纯化的表示自适应地合成为连贯的时空推理。

Result: CaSTFormer 在 Brain4Cars 公共数据集上进行了评估，取得了最先进的性能。

Conclusion: CaSTFormer 有效地捕捉了复杂的因果时空依赖关系，提高了驾驶意图预测的准确性和透明度。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [27] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [28] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 提出了一种新的摄影测量不确定性量化框架，特别解决了MVS阶段的挑战，使用自校准方法和MVS过程中的可靠点来回归不确定性，并在各种数据集上证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于多视角立体（MVS）阶段的不确定性估计具有非可微分和多模态的性质，该领域仍然存在未解决且非标准化的挑战。本研究旨在通过一个不确定性量化框架来解决这一问题。

Method: 提出了一种新颖的自校准方法，利用每个视图中可靠的n视点（n>=6）回归不确定性，并利用MVS过程中的匹配成本等相关线索。

Result: 与现有方法相比，该方法使用从MVS过程中直接提取的、自包含的、可靠的3D点，具有自监督的优点，并自然地遵循摄影测量过程的误差传播路径，从而为各种场景提供鲁棒且可验证的不确定性量化。

Conclusion: 该框架通过关联每点的误差协方差矩阵来量化包括多视角立体（MVS）在内的整个摄影测量过程的不确定性，并在各种公开的航空和无人机影像数据集上进行了评估。结果表明，该方法在不确定性估计过高的情况下，实现了高边界率，优于现有方法。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [29] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 利用3D卷积自编码器和时序编码对卫星图像进行无监督学习，实现甜菜胁迫检测。


<details>
  <summary>Details</summary>
Motivation: 利用卫星图像时间序列（SITS）数据对农业任务（特别是甜菜胁迫检测）的有效性，提出一种全无监督的方法。

Method: 提出一个3D卷积自编码器模型来提取特征，并结合特定采集日期的时序编码来捕捉甜菜的生长动态，然后将学习到的表示用于聚类任务以区分胁迫和健康田地。

Result: 开发了一个可以直接应用于不同年份数据的甜菜胁迫检测系统，为实际应用提供了便捷的工具。

Conclusion: 该研究提出了一种全无监督的方法，利用3D卷积自编码器和特定采集日期的时序编码，从Sentinel-2图像序列中提取特征，用于甜菜田的胁迫检测。该方法能够将学习到的表示用于下游聚类任务，以区分胁迫和健康田地，并且可以直接应用于不同年份的数据。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [30] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: A new method for calculating the second-order TGV of normal vectors on meshes is introduced, using a special finite element space, and tested in mesh denoising.


<details>
  <summary>Details</summary>
Motivation: To propose a novel formulation for the second-order total generalized variation (TGV) of the normal vector on an oriented, triangular mesh embedded in $"R^3$.

Method: A tailor-made tangential Raviart-Thomas type finite element space is constructed to extend the formulation to the manifold setting, considering the normal vector as a manifold-valued function on the unit sphere.

Result: The new regularizer is compared to existing methods in mesh denoising experiments.

Conclusion: The proposed formulation is compared to existing methods in mesh denoising experiments.

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [31] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [32] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 本研究提出了一种LoRA增强的合成重放方法，通过适配Stable Diffusion模型来生成更匹配的重放样本，解决了现有方法在处理包含细微差别和细粒度语义的真实数据时遇到的问题，并在MTIL基准测试中取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的合成重放方法在处理包含领域特定细微差别和细粒度语义的真实下游应用时，会生成与真实数据不匹配的样本，从而误导微调并损害先前知识的保留。

Method: 提出了一种LoRA增强的合成重放框架，通过注入任务特定的低秩适配器来改进冻结的Stable Diffusion模型，并结合两阶段的置信度采样方法来选择真实数据和生成的合成数据，以提升重放保真度。

Result: 在多域增量学习（MTIL）基准测试中的广泛实验表明，该方法优于先前的合成重放技术，并在塑性、稳定性和零样本能力之间取得了最佳平衡。

Conclusion: LoRA增强的生成器适配能够有效提升视觉语言模型在持续学习中的表现，实现了塑性、稳定性和零样本能力之间的最佳平衡。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [33] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 提出了一种名为NoiseSDF2NoiseSDF的新颖方法，用于从噪声点云中学习干净的3D神经SDF，该方法通过最小化噪声SDF表示之间的均方误差损失来实现去噪和表面精炼。


<details>
  <summary>Details</summary>
Motivation: 从点云中重建精确的隐式表面表示，尤其是在使用低质量扫描设备捕获的数据时，仍然是一项具有挑战性的任务。这些点云通常包含大量噪声，导致表面重建不准确。受2D图像噪声2噪声范例的启发，我们旨在将此概念扩展到3D神经场。

Method: 提出了一种名为NoiseSDF2NoiseSDF的新颖方法，该方法通过最小化噪声SDF表示之间的均方误差损失，直接从噪声点云中学习干净的神经SDF，从而实现隐式去噪和表面估计的精炼。

Result: NoiseSDF2NoiseSDF能够通过噪声监督直接从噪声点云中学习干净的神经SDF。

Conclusion: 该框架在ShapeNet、ABC、Famous和Real数据集的基准测试中得到了验证，实验结果表明，该框架显著提高了从嘈杂输入进行表面重建的质量。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [34] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 \thoughs 的新颖扩散模型框架，用于从非配对数据中学习图像去模糊。该框架通过利用空间变化的纹理先验，并引入纹理先验编码器（TPE）和纹理传递 Transformer 层（TTformer）来有效处理复杂和不可预测的模糊模式。实验证明，\thoughs 在无监督去模糊方面表现出色，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 由于获取大量真实的模糊-清晰图像对既困难又昂贵，因此从非配对数据中学习盲图像去模糊是一种更实用、更有前途的解决方案。不幸的是，主导方法严重依赖对抗性学习来弥合从模糊域到清晰域的差距，而忽略了真实世界模糊模式的复杂和不可预测的性质。

Method: 提出了一种新颖的基于扩散模型（DM）的框架（	houghs），通过学习来自非配对数据的空间变化纹理先验来进行图像去模糊。具体来说，	houghs 执行 DM 来生成有助于恢复模糊图像纹理的先验知识。为了实现这一点，我们提出了一个纹理先验编码器（TPE），它引入了一个内存机制来表示图像纹理并为 DM 训练提供监督。为了充分利用生成的纹理先验，我们提出了纹理传递 Transformer 层（TTformer），其中新颖的滤波器调制多头自注意力（FM-MSA）通过自适应滤波有效地去除空间变化的模糊。此外，我们实现了一种基于小波的对抗性损失来保留高频纹理细节。

Result: 通过在广泛使用的基准测试上进行的大量评估，表明 	houghs 提供了有前途的无监督去模糊解决方案，并在广泛使用的基准测试中超越了最先进的方法。

Conclusion: 该模型在广泛使用的基准测试中表现优于最先进的方法，并为无监督去模糊提供了有前途的解决方案。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [35] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 所提出的基于扩散模型的方法通过随机采样器和知识蒸馏，在保持超分辨率质量的同时，将运行时间缩短了98.4%。


<details>
  <summary>Details</summary>
Motivation: 为了通过扩散模型重建清晰、高保真的超分辨率图像，因为先前具有确定性训练的突发超分辨率方法会产生模糊的超分辨率图像，这在感官上是劣化的。

Method: 我们通过随机采样器和高阶常微分方程以及使用知识蒸馏的一步扩散来提高扩散模型的效率。

Result: 我们的方法可以将运行时间减少到基线的1.6％，同时保持基于图像失真和感知质量测量的SR质量。

Conclusion: 与保持超分辨率（SR）质量相比，我们的方法可以将运行时间减少到基线的1.6％。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [36] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: CoTasks框架通过将视频问题分解为帧定位、实体跟踪、时空关系提取等基础任务，并提供CoT风格的监督，有效增强了视频大语言模型的细粒度视频理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型（VideoLLMs）在基于细粒度物体理解的链式思考（CoT）推理能力方面存在不足，因为它们通常只在缺乏结构化注解的高层次视频-文本对上进行训练。

Method: 提出CoTasks框架，将复杂视频问题分解为帧定位、实体跟踪、空间和时间关系提取四个基础任务，并将中间推理步骤嵌入输入，以实现显式的、以物体为中心的时空推理。

Result: 在NeXT-QA基准测试中，CoTasks显著提升了模型性能：LLaVA-video-7B的平均GPT-4评估分数提高了+3.3分，Qwen2.5-VL-3B的平均分数提高了+17.4分，其中因果推理子任务提升了+14.6分，时间推理子任务提升了+10.9分，描述性子任务提升了+48.1分。

Conclusion: CoTasks通过提供结构化的、基于实体和时空关系的CoT风格监督，显著提高了视频大语言模型在复杂视频推理任务上的表现，尤其在因果、时间、描述性子任务上效果显著。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [37] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: 提出FoELS方法，整合光流和纹理信息，用于从移动摄像机视角分离运动和静态物体，解决了传统光流法在复杂场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 从移动摄像机视角分离运动和静态物体对于机器人技术中的3D重建、自主导航和场景理解至关重要。现有方法主要依赖于光流，但在涉及相机运动的复杂结构场景中难以检测运动物体。

Method: FoELS方法整合了光流和纹理信息，计算光流的扩张焦点（FoE），并从FoE计算的离群值中导出初始运动可能性。然后，该可能性与基于分割的先验信息融合，以估计最终的运动概率。

Result: FoELS方法在DAVIS 2016数据集和真实交通视频上进行了评估，结果证明了其有效性和最先进的性能。

Conclusion: FoELS方法有效地解决了复杂结构场景、旋转相机运动和平行运动等挑战，并在DAVIS 2016数据集和真实交通视频的综合评估中展示了其有效性和最先进的性能。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [38] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon是一种创新的3D虚拟人生成方法，通过其独特的高效点采样策略（ERO和EIO），大幅提升了训练和推理速度，同时保持了高质量的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于 NeRF 的方法在生成动漫化人体虚拟人方面取得了进展，但单纯使用 NeRF 细节不足。混合方法（结合 NeRF 和基于 SMPL 的网格）虽然能生成照片级逼真的虚拟人，但其基于 SMPL 蒙皮权重的变形方案导致推理速度极慢，因为计算成本高昂且大部分采样点位于空白空间，对生成质量影响甚微。

Method: EPSilon是一种混合表示的3D虚拟人生成方法，其创新之处在于采用了两种高效的点采样策略：空射线遗漏（ERO）和空区间遗漏（EIO）。ERO通过剔除穿过空白空间的射线来减少采样；EIO则在射线上缩小采样区间，剔除不被衣物或网格占据的区域。这些策略使得模型能够在减少约96%采样点的同时，实现约20倍的推理加速和4倍的训练收敛加速。

Result: EPSilon在保持与现有方法相当的生成质量的同时，仅使用了3.9%的采样点，实现了约20倍的推理加速和4倍的训练收敛加速，并在训练和推理方面均有显著提升。

Conclusion: EPSilon通过采用高效的点采样策略，在保持生成质量的同时，显著减少了计算量并加快了训练和推理速度，是3D虚拟人生成领域的有前景的方法。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [39] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 本研究提出了EvReID数据集和TriPro-ReID框架，以解决事件相机行人重识别中的数据稀缺问题，并提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的行人重识别算法主要关注可见光与事件流的融合以及隐私保护，但这些方法通常在小规模或模拟数据集上进行训练和评估，难以评估其实际识别性能和泛化能力。为了解决数据稀缺的问题，本研究旨在构建一个大规模的RGB-事件行人重识别数据集，并提出一个有效的行人重识别框架。

Method: 本研究提出了一个名为TriPro-ReID的框架，该框架采用对比学习，并利用了行人属性作为中级语义特征，以探索RGB帧和事件流中的视觉特征。此外，研究人员还构建了一个大规模RGB-事件行人重识别数据集EvReID，该数据集包含118,988张图像对，涵盖1200名行人，并在不同季节、场景和光照条件下收集。

Result: 研究成功构建了一个大规模RGB-事件行人重识别数据集EvReID，并提出了TriPro-ReID框架。在EvReID和MARS数据集上的实验结果表明，TriPro-ReID框架能够有效地利用RGB帧和事件流中的视觉特征以及行人属性，显著提升了行人重识别的性能。研究还评估了15种先进的行人重识别算法，为未来的研究奠定了数据和基准测试的基础。

Conclusion: 本研究提出了一个名为TriPro-ReID的RGB-事件行人重识别框架，并构建了一个大规模RGB-事件行人重识别数据集EvReID，以解决现有数据集规模小和模拟数据的问题。TriPro-ReID框架利用了RGB帧和事件流中的视觉特征，并结合了行人属性作为中级语义特征，以增强特征学习。在EvReID和MARS数据集上的广泛实验验证了该框架的有效性。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [40] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: PW-FNet 提出了一种高效的图像恢复方法，结合了金字塔小波多尺度/多频带分解和傅里叶变换替代自注意力机制，在多种恢复任务中实现了高质量和高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Transformer 的图像恢复方法虽然取得了显著进展，但其日益增长的系统复杂性对实时处理提出了重大挑战。现有方法大多尝试简化自注意力机制，但主要关注网络架构，忽略了图像恢复本身的固有特性。因此，探索金字塔小波-傅里叶迭代流程以展示小波-傅里叶处理在图像恢复中的潜力。

Method: 提出了一种名为金字塔小波-傅里叶网络（PW-FNet）的新型高效恢复基线。PW-FNet 具有两个关键的设计原则：1）在块间层面，集成了基于金字塔小波的多输入多输出结构，以实现多尺度和多频带分解；2）在块内层面，将傅里叶变换作为自注意力机制的有效替代方案，在有效降低计算复杂度的同时保留了全局建模能力。

Result: PW-FNet 不仅在恢复质量上超越了最先进的方法，而且在效率方面也表现出色，参数量、计算成本和推理时间均显著减少。

Conclusion: PW-FNet 在图像恢复任务中取得了优于最先进方法的恢复质量，同时在效率方面也表现出色，参数量、计算成本和推理时间均显著减少。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [41] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: MaskHOI是一个基于MAE的预训练框架，通过区域特定的掩码策略和SDF多模态学习，提升了单目RGB输入下3D手部-物体交互姿势估计的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单目RGB输入在3D手部-物体交互（HOI）任务中存在几何歧义和相互遮挡的挑战，导致精确估计手和物体关节姿势非常困难。现有方法在处理手部精细结构和真实遮挡场景时存在不足。

Method: MaskHOI框架的核心思想是利用MAE的掩码-重建策略来学习几何感知和遮挡鲁棒的表示。具体创新点包括：1. 区域特定掩码率分配：为手部区域分配比刚性物体更低的掩码率，以适应手部结构更复杂的特点。2. 骨架驱动的手部掩码：优先掩码关键手部区域（如指尖或手指）以模拟真实交互中的遮挡。3. 掩码符号距离场（SDF）驱动的多模态学习：通过自掩码3D SDF预测，使编码器能够感知超越2D图像的全局几何结构。

Result: 实验结果表明，MaskHOI显著优于现有的最先进方法，能够更好地处理3D手部-物体交互中的姿势估计问题。

Conclusion: MaskHOI通过掩码自动编码器（MAE）驱动的预训练框架，有效解决了单目RGB输入在3D手部-物体交互（HOI）任务中估计精确关节姿势的挑战，特别是在处理几何歧义和遮挡问题方面。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [42] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个用于异构传感器V2X协同感知的框架，通过分层融合和自适应策略提高了性能和鲁棒性，并在TUMTraf-V2X数据集和CVPR 2025 DriveX挑战赛中取得了领先成果。


<details>
  <summary>Details</summary>
Motivation: 现实世界的V2X协同感知系统常常面临异构传感器配置带来的挑战，这给特征融合和感知可靠性带来了困难。

Method: 提出了一种名为HeCoFuse的统一框架，用于跨异构传感器设置（包括摄像头和激光雷达）的协同感知。该框架采用分层融合机制，通过通道和空间注意力自适应地加权特征，解决了跨模态特征不对齐和表示不平衡的问题。此外，还包含一个自适应空间分辨率调整模块来平衡计算成本和融合效果，以及一个协同学习策略来动态调整融合类型。

Result: 在TUMTraf-V2X数据集上，HeCoFuse在全传感器配置（LC+LC）下达到了43.22%的3D mAP，优于CoopDet3D基线1.17%。在L+LC场景下，3D mAP达到了43.38%，并且在九种不同的异构传感器配置下，3D mAP保持在21.74%到43.38%之间。

Conclusion: HeCoFuse在TUMTraf-V2X数据集上取得了先进的性能，并在CVPR 2025 DriveX挑战赛中获得第一名，证明了其在不同传感器部署下的鲁棒性。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [43] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量新方法，通过运动一致性和超分辨率约束提高了亚像素级运动测量的精度和鲁棒性，且无需手动调整参数。


<details>
  <summary>Details</summary>
Motivation: 针对现有视觉测量方法在亚像素级运动测量中精度不足或需要大量手动参数调整的问题，提出一种无需大量手动调参即可达到高精度和鲁棒性的运动测量方法。

Method: 提出了一种新颖的高斯核（Gaussian kernel）为基础的运动测量方法，通过追踪高斯核的位置来提取不同帧之间的运动。引入了运动一致性（motion consistency）和超分辨率约束（super-resolution constraint）来提高方法的精度和鲁棒性。

Result: 所提出的方法能够一致地达到高精度，并且无需针对不同的测试样本进行定制化的参数设置。

Conclusion: 该文提出的高斯核运动测量方法在数值和实验验证中均表现出高精度和高鲁棒性，且无需针对不同测试样本进行定制化参数设置。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [44] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: This paper presents two new, more flexible metrics (extensions of GOSPA and T-GOSPA) to evaluate multi-object tracking algorithms, allowing different penalties for missed and false targets and asymmetric localization costs. Tested using simulations on Bayesian MOT algorithms.


<details>
  <summary>Details</summary>
Motivation: To address the need for more flexible performance assessment of multi-object tracking (MOT) algorithms, particularly in applications where different types of errors (missed vs. false objects) or localization inaccuracies have varying significance.

Method: Introduced two quasi-metrics for MOT performance assessment: an extension of the GOSPA metric for object sets and an extension of the T-GOSPA metric for trajectory sets. These quasi-metrics incorporate costs for localization error, false objects, and missed objects, with the T-GOSPA quasi-metric also including a track switching cost. Key features include flexible penalization of missed and false objects with different costs and non-symmetric localization costs.

Result: The proposed quasi-metrics provide a more flexible approach to MOT evaluation. Simulations using the T-GOSPA quasi-metric demonstrated its utility in assessing the performance of Bayesian MOT algorithms.

Conclusion: The paper proposes two new quasi-metrics for evaluating multi-object tracking (MOT) algorithms, extending the GOSPA and T-GOSPA metrics. These quasi-metrics offer greater flexibility by allowing different costs for missed and false objects, and non-symmetric localization costs, which can be beneficial in specific applications. The T-GOSPA quasi-metric was used to assess the performance of several Bayesian MOT algorithms through simulations.

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [45] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 该研究提出了一种名为PoemTale Diffusion的新方法，通过改进的提示精炼和自注意力机制，可以更准确地将诗歌转化为图像，并发布了一个包含1111首诗歌的数据集P4I，以促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 目前的文本到图像扩散模型在处理诗歌等富有创意的语言形式时面临挑战，因为诗歌通常具有多层次、抽象和双重含义，这会导致信息在转换过程中丢失。

Method: 本研究引入了一种新颖的训练无关方法，将多阶段提示精炼循环集成到语言模型中，以提高诗歌文本的可解释性。此外，还通过修改自注意力机制来生成多个一致的图像，并结合这些图像来传达诗歌的含义。

Result: 实验结果表明，该方法能够有效地捕捉诗歌的含义，生成具有增强信息的内容。定性和定量评估均证实了该方法的有效性，并为诗歌到图像生成领域提供了新的视角。

Conclusion: 该研究提出了一种新颖的训练无关方法，通过多阶段提示精炼循环和修改的自注意力机制来提高诗歌文本到图像转换的准确性，并引入了P4I数据集来支持该领域的研究。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [46] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 博物馆的AR新流程：使用GLPN和Depth-Anything从单个图像生成3D艺术品模型，提高准确性和视觉效果。


<details>
  <summary>Details</summary>
Motivation: 本研究的目的是为博物馆环境开发一种增强现实流水线，以识别艺术品并从单个图像生成准确的3D模型，从而应对艺术品不规则轮廓和多变纹理带来的挑战。

Method: 本研究提出了一种创新的增强现实流程，通过集成GLPN和Depth-Anything两个预训练的深度估计模型来识别艺术品并从单个图像生成准确的3D模型。该方法优化了深度图的生成，将其转换为高质量的点云和网格，以实现沉浸式AR体验。

Result: 实验结果表明，在重建精度和视觉真实感方面取得了显著的改进，证明了该系统在增强博物馆访客参与度的有效性。

Conclusion: 该系统为博物馆提供了增强游客参与度的强大工具，通过提供具有高重建精度和视觉真实感的交互式数字内容。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [47] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: StyleGAN通过修剪权重可降低计算需求，并能精细控制生成人脸特征，但存在被滥用于制造虚假身份的伦理风险。


<details>
  <summary>Details</summary>
Motivation: 深入理解StyleGAN生成器的工作原理，以及探索其模型压缩和潜在向量操纵的可能性，同时关注相关的伦理问题。

Method: 通过修剪StyleGAN生成器中的权重来分析其对输出的影响，并研究潜在向量对生成人脸特征的控制作用。

Result: 发现StyleGAN模型可以被修剪以减少计算需求，并且潜在向量的调整可以精确控制生成人脸的特定特征，但也揭示了该技术可能被滥用于制造虚假身份的风险。

Conclusion: StyleGAN通过修剪权重可以减少计算需求，并且可以通过调整潜在向量来精细控制生成图像的特征，但也引发了关于潜在滥用的伦理担忧。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [48] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: Diffusion-FSCIL uses a frozen diffusion model to overcome data limitations and catastrophic forgetting in few-shot class-incremental learning, achieving better results than prior methods.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenges of Few-shot class-incremental learning (FSCIL), which suffers from limited data and catastrophic forgetting. The proposed approach leverages the capabilities of large generative models, specifically text-to-image diffusion models, for their generation ability, multi-scale representation, and representational flexibility via text encoders, to improve FSCIL performance.

Method: Diffusion-FSCIL utilizes a frozen text-to-image diffusion model as its backbone, extracting multiple complementary diffusion features as latent replay, augmented by feature distillation to prevent generative biases. The framework prioritizes efficiency through a frozen backbone, minimal trainable components, and batch processing for feature extraction.

Result: The proposed Diffusion-FSCIL framework demonstrates superior performance compared to existing state-of-the-art methods in FSCIL.

Conclusion: Diffusion-FSCIL surpasses state-of-the-art methods on CUB-200, miniImageNet, and CIFAR-100 benchmarks, effectively preserving performance on previous classes while adapting to new ones.

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [49] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [50] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的高光谱图像重建方法，通过学习和注入光谱先验，解决了细节恢复不佳的问题，并取得了更好的重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的高光谱图像（HSI）重建方法在准确捕获HSI高频细节方面存在不足。

Method: 提出了一种基于扩散模型学习光谱扩散先验（SDP）的方法，并设计了光谱先验注入模块（SPIM）来动态指导模型恢复HSI细节。

Result: 提出的方法在MST和BISRNet数据集上，相比现有网络性能提升了约0.5dB，有效提高了HSI重建性能。

Conclusion: 该方法通过引入隐式学习的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），显著提高了高光谱图像（HSI）重建的性能，在MST和BISRNet两个数据集上，性能提升了约0.5dB。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [51] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 通过结合排列熵、HOG和LBP特征，并使用SVM进行分类，在不使用深度学习的情况下，实现了具有竞争力的图像分类性能，提供了一种轻量级且可解释的方法。


<details>
  <summary>Details</summary>
Motivation: 在优先考虑可解释性和计算效率而非参数量庞大的深度学习模型的场景下，重新审视基于经典机器学习的图像分类方法，探索新的特征工程技术。

Method: 提出了一种新颖的基于排列熵（PE）的图像分类方法，将PE扩展到二维图像，并提出了一种多尺度、多方向的熵特征提取方法，结合了方向梯度直方图（HOG）和局部二值模式（LBP）来增强特征的区分能力。最终形成一个包含780个维度的手工特征集，并使用SVM分类器进行训练和优化。

Result: 该方法在Fashion-MNIST、KMNIST、EMMNIST和CIFAR-10等多个基准数据集上进行了评估，取得了具有竞争力的分类性能，证明了所提出的熵特征融合方法在图像分类任务上的有效性和潜力。

Conclusion: 熵特征（包括排列熵、HOG和LBP）与SVM分类器相结合，在不依赖深度架构的情况下，为图像分类提供了一种紧凑、可解释且有效的替代方案，证明了熵描述子在图像分类中的潜力，并为可解释的机器学习提供了轻量级且可泛化的解决方案。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [52] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: The ClearVQA benchmark is introduced to help visual language models (VLMs) better handle ambiguous questions by enabling them to ask clarifying questions instead of just trying to answer them, which is a common issue due to users' varied expression habits.


<details>
  <summary>Details</summary>
Motivation: Users often pose ambiguous questions to VLMs due to varying expression habits. Overcoming the challenges in interactive clarification, such as the absence of benchmarks and VLMs' preference for answering over asking, is crucial for improving VLM performance.

Method: The paper introduces the ClearVQA benchmark to address the challenges in interactive clarification, targeting three common categories of ambiguity in VQA context and encompassing various VQA scenarios. This benchmark aims to assess VLMs' capacity for resolving ambiguities through interaction.

Result: The ClearVQA benchmark is introduced to assess VLMs' capacity for resolving ambiguities through interaction.

Conclusion: Existing research primarily addresses ambiguity by rephrasing questions, neglecting the interactive nature of user interactions with VLMs where ambiguities can be clarified through user feedback.

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [53] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 提出一种新的SSL和UDA方法，通过可微分聚类模块和利用监督数据计算质心，在低监督场景下效果显著。


<details>
  <summary>Details</summary>
Motivation: 利用聚类假设（同一簇中的数据点应属于同一类别）来增强SSL和UDA模型的性能，尤其是在标记数据有限的情况下。

Method: 通过显式引入可微分聚类模块，并扩展其以利用监督数据计算质心，实现端到端的训练策略。

Result: 在SSL和UDA的广泛实验中证明了该方法的有效性，尤其是在低监督情况下，其作为独立模型和作为现有方法的正则化器都显示出优势。

Conclusion: 该方法通过显式引入可微分聚类模块，并利用监督数据计算质心，在SSL和UDA任务上展示了有效性，尤其在低监督场景下表现突出，可作为独立模型或现有方法的正则化器。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [54] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: LoFNO是一种新型3D深度学习模型，通过结合几何先验和超分辨率技术，能够提高MRI血流数据的时空分辨率和信噪比，从而更准确地预测动脉瘤的血流动力学，辅助临床诊断。


<details>
  <summary>Details</summary>
Motivation: 为了解决磁共振成像（MRI）在测量动脉瘤血流动力学时存在的时空分辨率低和信噪比低的问题，本研究旨在提出一种能够直接从临床成像数据中预测壁面剪切应力（WSS）并提高时空分辨率的方法。

Method: 提出了一种名为局部傅立叶神经算子（LoFNO）的新型3D架构，该架构利用拉普拉斯特征向量作为几何先验以提高对不规则、未见几何形状的结构感知能力，并采用增强型深度超分辨率网络（EDSR）层进行鲁棒的上采样。

Result: LoFNO在速度和壁面剪切应力（WSS）的预测方面，相较于传统的插值方法和其它深度学习方法，取得了更优越的性能。

Conclusion: LoFNO通过结合几何先验和神经算子框架，能够对血流数据进行去噪和时空超分辨率处理，在预测速度和壁面剪切应力（WSS）方面优于插值和其他深度学习方法，从而实现更精确的脑血管诊断。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [55] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 通过自动化流程和Gemini模型，解决了图像编辑训练数据挖掘的难题，发布了NHR-Edit数据集和Bagel-NHR-Edit模型，提升了训练数据的规模和质量。


<details>
  <summary>Details</summary>
Motivation: 监督训练图像编辑模型需要大量的（原始图像、指令、编辑图像）三元组数据，但挖掘像素级精确、风格一致、符合物理规律且视觉吸引力的编辑样本非常困难，现有自动化评估指标不足以支持大规模高质量数据的生产。

Method: 开发了一个自动化的、模块化的流程，利用任务微调的Gemini验证器来评估指令遵循度和美学，无需分割或定位模型。通过反演和组合引导来扩大挖掘数据集。

Result: 成功挖掘了跨领域、跨分辨率、跨指令复杂度和风格的高保真三元组，并将数据集扩大了约2.2倍。发布的NHR-Edit数据集在最大规模的跨数据集评估中优于所有公开替代品。发布的Bagel-NHR-Edit模型在实验中实现了最先进的指标。

Conclusion: 该研究提出了一种自动化流程，用于大规模挖掘高质量的图像编辑训练数据（三元组：原始图像、指令、编辑后的图像），解决了手动标注成本高、难以保证编辑质量的问题。该流程利用Gemini模型进行打分，无需分割或定位模型，并通过反演和组合引导将数据量扩大了约2.2倍。研究发布了NHR-Edit数据集（358k高质量三元组）和Bagel-NHR-Edit模型，后者在实验中达到了最先进的性能。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [56] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore是一种新颖的盲人脸恢复方法，通过动态调整扩散采样过程来解决现有方法的局限性，实现了更好的保真度和质量平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用固定的扩散采样时间步和全局引导尺度，假设降级是统一的。这种限制和潜在不完美的降级核估计常常导致扩散不足或过度扩散，从而在保真度和质量之间产生不平衡。

Method: DynFaceRestore通过学习将任何盲退化的输入映射到高斯模糊图像。它利用这些模糊图像及其各自的高斯核，动态选择每个模糊图像的起始时间步，并在扩散采样过程中应用闭式引导以保持保真度。此外，它还引入了一个动态引导缩放调整器，以跨局部区域调节引导强度，从而在增强复杂区域细节生成的同时，保持轮廓的结构保真度。

Result: DynFaceRestore有效平衡了保真度和质量之间的权衡，在定量和定性评估中均取得了最先进的性能。

Conclusion: DynFaceRestore在盲人脸恢复方面取得了最先进的性能，在定量和定性评估中都得到了证明，并展示了鲁棒性和有效性。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [57] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: CF-SSC通过预测未来帧来解决单目SSC中的遮挡问题，并在关键基准上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单目SSC方法在处理真实交通场景中的遮挡或相机视野外的大部分场景时存在不足。

Method: 提出了一种名为CF-SSC的新型时间SSC框架，该框架利用伪未来帧预测来扩展模型的有效感知范围，并通过结合姿态和深度来建立准确的3D对应关系，以实现过去、现在和预测的未来帧在3D空间中的几何一致性融合。该模型采用了3D感知架构，并通过显式建模时空关系来提高场景补全的鲁棒性。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试上取得了最先进的性能，证明了该方法的有效性，并突出了其在改善遮挡推理和3D场景补全准确性方面的能力。

Conclusion: CF-SSC通过融合过去、现在和预测的未来帧，在3D空间中实现了几何一致的场景补全，解决了现有单目SSC方法在处理遮挡和视野外场景方面的不足。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [58] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA：一种高效、鲁棒的物联网多模态感知框架，通过Mamba和GRAM解决复杂性、对齐和缺失模态问题。


<details>
  <summary>Details</summary>
Motivation: 现有物联网多模态感知系统面临模型复杂度高、单向模态对齐忽视跨模态关系以及传感器数据缺失时鲁棒性差等问题，阻碍了其在资源受限环境下的高效部署和鲁棒运行。

Method: 本研究提出GRAM-MAMBA框架，采用线性复杂度的Mamba模型处理传感器时间序列，结合优化的GRAM矩阵策略进行多模态间的成对校准，并引入受LoRA启发的自适应低秩层补偿策略来处理训练后的传感器数据缺失问题。

Result: 在SPAWC2021室内定位数据集上，GRAM-MAMBA的预训练模型优于基线模型；在处理缺失模态时，通过训练不到0.2%的参数，性能提升了24.5%。在USC-HAD数据集上，该模型达到了93.55%的F1分数和93.81%的总体准确率（OA），优于现有方法；更新策略在训练不到0.3%的参数情况下，F1分数提高了23%。

Conclusion: GRAM-MAMBA框架在资源受限环境中实现了高效且鲁棒的多模态感知，通过线性复杂度的Mamba模型、优化的GRAM矩阵策略和自适应低秩层补偿策略解决了现有系统的挑战。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [59] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2 是一个统一的多模态遥感基础模型，使用单一的 Transformer 主干和针对遥感数据的新型自监督学习方法，解决了现有方法的冗余和效率问题，并在多项任务和数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数遥感基础模型（MM-RSFM）在处理不同数据模态时需要训练独立的骨干网络，这导致了参数冗余和利用效率低下。此外，现有的预训练方法通常直接套用自然图像的自监督学习技术，未能充分考虑遥感图像的独特性质，例如单一遥感图像内部复杂的语义分布。

Method: 该研究提出了 SkySense V2，一个统一的多模态遥感基础模型（MM-RSFM），采用单一的 transformer 主干来处理多种数据模态。该模型通过一种新颖的自监督学习（SSL）策略进行预训练，该策略专门针对遥感（RS）数据的特性进行了优化，解决了单一 RS 图像中复杂的语义分布问题。此外，SkySense V2 集成了创新的自适应图像块合并模块和可学习的模态提示令牌，以应对不同分辨率和有限特征多样性带来的挑战。同时，引入混合专家（MoE）模块进一步提升了模型的性能。

Result: SkySense V2 在涉及 16 个数据集和 7 个任务的广泛评估中，展示了出色的泛化能力，其平均性能比 SkySense 提高了 1.8 个百分点。

Conclusion: SkySense V2，一个统一的多模态遥感基础模型，通过单一的 transformer 主干和新颖的自监督学习策略，有效地处理了多模态遥感数据，并取得了优于 SkySense 的性能，在 16 个数据集的 7 项任务上平均提高了 1.8 个点。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [60] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: A new framework for video question answering uses multiple Video-LMMs coordinated by a structured chain of thought and integrated by an LLM, outperforming existing methods in generalization and robustness without retraining.


<details>
  <summary>Details</summary>
Motivation: Existing Video-Large Multimodal Models (Video-LMMs) often exhibit limited contextual understanding, weak temporal modeling, and poor generalization to ambiguous or compositional queries.

Method: We introduce a prompting-and-response integration mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs) via structured chains of thought. An external Large Language Model (LLM) serves as an evaluator and integrator, selecting and fusing the most reliable responses.

Result: Extensive experiments demonstrate that our method significantly outperforms existing baselines across all evaluation metrics, showcasing superior generalization and robustness.

Conclusion: Our proposed framework significantly outperforms existing baselines across all evaluation metrics, demonstrating superior generalization and robustness in open-ended video question answering. It offers a lightweight and extensible strategy for advancing multimodal reasoning without requiring model retraining.

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [61] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 本研究提出一種結合Quanvolution預處理與Attention U-Net模型的方法，用於城市建築分割。該方法在保持精度的同時，減少了模型參數，提高了計算效率。


<details>
  <summary>Details</summary>
Motivation: 城市區域的建築分割在城市規劃、災害響應和人口測繪等領域至關重要，然而，由於衛星影像尺寸大、解析度高，在密集的城市區域準確分割建築物存在挑戰。

Method: 本研究利用Quanvolutional預處理技術增強Attention U-Net模型在建築分割中的能力，並在突尼斯城市環境中，使用Sentinel-1合成孔徑雷達（SAR）影像進行實驗。

Result: 所提出的方法與標準Attention U-Net模型相比，達到了相當的測試準確度，同時顯著減少了網路參數，提高了計算效率。

Conclusion: 提出方法在保持模型精度的同時，顯著減少了網路參數，提高了計算效率。量子啟發的深度學習框架在城市環境的大規模建築分割方面具有潛力。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [62] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 该研究提出 PositionIC 框架，通过新的合成管线和位置调制层，解决了现有图像定制技术在精细空间控制方面的不足，实现了多主体、高保真度的图像定制。


<details>
  <summary>Details</summary>
Motivation: 现有的图像定制技术在保真度方面取得了显著进展，但在实体级别的精细空间控制方面仍有不足，这主要是由于缺乏将身份与精确位置线索绑定的可扩展数据集。

Method: 本文提出 PositionIC 框架，通过构建包含双向生成范式的可扩展合成管线来消除主体漂移并保持语义一致性，并设计轻量级的位置调制层来解耦主体间的空间嵌入，实现独立、精确的放置。

Result: 实验证明，PositionIC 在图像定制任务中能够实现精确的空间控制，同时保持高度的一致性。

Conclusion: PositionIC 框架通过解耦空间嵌入，实现了精确的空间控制和高一致性，为开放世界、多实体场景下的可控、高保真图像定制提供了新的可能性。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [63] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 研究了视觉语言模型（VLM）如何处理内部知识与外部信息之间的冲突，发现少数注意力头在其中起关键作用，并提出了一种通过修改这些头来控制模型行为并精确定位视觉线索的方法。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型（VLM）在利用多样化知识来源时，内部参数知识与外部信息之间存在的冲突问题，这类冲突会导致模型产生幻觉和不可靠的响应，而目前对于这类冲突的解决机制尚不明确。

Method: 通过引入包含故意与内部常识知识相矛盾的多模态反事实查询的数据集，并利用logit检查来定位控制冲突的少数几个注意力头，从而分析视觉语言模型（VLM）解决跨模态冲突的机制。

Result: 发现了少数几个注意力头能够控制冲突，并且通过修改这些注意力头，可以引导模型倾向于依赖内部知识或视觉输入。此外，研究表明这些注意力头的注意力机制能够精确地定位到导致视觉覆盖的图像区域，其精确度优于基于梯度的归因方法。

Conclusion: 通过修改控制冲突的关键连接，可以引导模型依赖其内部知识或视觉输入，并且这种方法在精确定位驱动视觉覆盖的图像区域方面优于基于梯度的归因方法。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [64] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: A new system fuses real-time video with nautical charts using a novel neural network to accurately match buoys, improving maritime navigation safety.


<details>
  <summary>Details</summary>
Motivation: To enhance marine vision by fusing real-time visual data with chart information for more accurate navigation.

Method: A transformer-based end-to-end neural network is introduced to predict bounding boxes and confidence scores for buoy queries, enabling direct matching of image-domain detections with world-space chart markers. This approach fuses real-time visual data with chart information by accurately matching detected navigational aids with their chart representations.

Result: Experimental results on real-world maritime scenes demonstrate significant improvements in object localization and association accuracy compared to baseline approaches like ray-casting and a YOLOv7-based network with distance estimation.

Conclusion: The proposed transformer-based end-to-end neural network significantly improves object localization and association accuracy in dynamic and challenging maritime environments by fusing real-time visual data with chart information.

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [65] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS 是一种创新的 COLMAP-free 3DGS 技术，通过相机姿态的共同正则化来处理具有复杂相机轨迹的场景。


<details>
  <summary>Details</summary>
Motivation: COLMAP-free 3D GS 在处理具有复杂相机轨迹（相邻相机视图之间具有急剧的旋转和平移）的场景时，通常难以获得良好的相机姿态估计，并导致联合优化中的局部最小值。

Method: PCR-GS 通过两种方式实现正则化：1. 特征重投影正则化：提取跨相邻相机视图的视图鲁棒 DINO 特征，并对齐它们的语义信息以进行相机姿态正则化。 2. 基于小波的频率正则化：利用高频细节的差异来进一步优化相机姿态中的旋转矩阵。

Result: PCR-GS 实现了优越的 3D 场景建模和相机姿态估计。

Conclusion: PCR-GS 在相机轨迹大幅变化的情况下实现了优越的无相机姿态 3DGS 场景建模。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [66] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 通过融合DepthAnything的深度先验来增强LiDAR点特征，并采用新的特征提取和融合框架，显著提高了3D目标检测的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶场景中LiDAR点特征表达能力有限，尤其是反射率属性区分能力较弱的问题，并更好地利用单目RGB图像的深度先验信息。

Method: 本文提出了一种融合深度先验的方法，通过点对特征提取模块和双路径RoI特征提取框架（包含基于体素的分支和基于点的分支），并使用双向门控RoI特征融合模块来整合互补的RoI特征。

Result: 在KITTI数据集上的大量实验表明，该方法能够持续提升检测精度。

Conclusion: 该方法通过融合DepthAnything预测的深度先验来丰富点特征，并提出了一种点对特征提取模块和双路径RoI特征提取框架，以有效融合全局和局部线索，从而提升了基于LiDAR的3D目标检测性能。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [67] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一个新颖的神经渲染方法，可以在任意视角和时间渲染新颖视图，即使只有很少的输入视图。它通过结合多视图立体、神经辐射场和解耦策略，实现了跨不同数据集的泛化能力，并能在不进行每场景优化的情况下，生成平稳过渡不同时间的逼真视图。


<details>
  <summary>Details</summary>
Motivation: 为了在元宇宙等数字领域中实现更具沉浸感的体验，需要能够对昼夜自然过渡的3D环境进行建模。现有的NeRF技术在合成新颖视图方面表现出色，但其在时间3D场景建模方面的潜力探索有限，且缺乏专门的数据集。

Method: TimeNeRF结合了多视图立体、神经辐射场和跨数据集的解耦策略，以构建隐式内容辐射场，并允许在任何任意时间构建神经辐射场，最终通过体积渲染来合成该时间的新颖视图。

Result: 实验证明，TimeNeRF可以在少样本设置中渲染新颖视图，而无需进行每场景优化，并且在创建跨越不同时间的逼真新颖视图方面表现出色，能够熟练地捕捉从黎明到黄昏的复杂自然场景变化。

Conclusion: TimeNeRF能够在新颖的视图设置中进行渲染，而无需进行每场景优化，并且在跨越不同时间（从黎明到黄昏）的平稳过渡方面表现出色。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [68] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一个创新的视频扩散框架，用于解耦视频中的静态外观和动态运动，通过其独特的编码器-解码器架构和正则化技术，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决无监督视频表示学习中静态外观和动态运动解耦的根本挑战，克服现有VAE和GAN方法中的信息泄漏和模糊重建问题。

Method: DiViD是一个端到端的视频扩散框架，通过序列编码器提取全局静态标记和每帧动态标记，并结合条件DDPM解码器，该解码器具有共享噪声调度、时变KL散度瓶颈和交叉注意力机制，以及正交正则化器，以实现显式的静态-动态因子化。

Result: DiViD在真实世界基准测试中，在基于交换的准确率和交叉泄漏指标上，优于最先进的顺序解耦方法，实现了最高的基于交换的联合准确率，提高了动态传输，同时保持了静态保真度，并减少了平均交叉泄漏。

Conclusion: DiViD在公开基准测试中表现优于最先进的顺序解耦方法，实现了最高的基于交换的联合准确率，在保持静态保真度的同时提高了动态传输，并减少了平均交叉泄漏。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [69] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 在短时间范围内，视觉模型的感知能力与其通用预测性能之间存在很强的相关性。通过在固定表示空间中预测未来特征，并使用分布度量进行评估，可以实现这一点。


<details>
  <summary>Details</summary>
Motivation: 预测接下来会发生什么对于在不同抽象级别上在世界中进行规划或行动的通用系统的关键技能。

Method: 提出了一种新颖的通用预测框架，该框架可以在任何固定的视觉骨干网上运行：我们训练潜在扩散模型来预测固定表示空间中的未来特征，然后通过轻量级的、特定任务的读出进行解码。为了在不同任务之间实现一致的评估，我们引入了直接在下游任务空间中比较分布特性的分布度量，并将此框架应用于九个模型和四个任务。

Result: 在短时间范围内，视觉模型的感知能力与其通用预测性能之间存在很强的相关性。这一趋势在多种预训练模型（包括生成式训练的模型）以及从原始像素到深度、点轨迹和对象运动的多个抽象级别上都成立。

Conclusion: 本文的发现强调了连接表征学习和生成模型对于时间相关的视频理解的价值。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [70] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 本研究提出了一个用于评估视觉隐私保护方法的框架和HR-VISPR数据集，该框架可以根据人类感知区分隐私级别，并权衡隐私、效用和实用性。


<details>
  <summary>Details</summary>
Motivation: 人工智能监控的最新进展加剧了人们对敏感个人数据收集和处理的担忧，因此需要客观的技术来评估隐私保护。现有研究日益关注“设计隐私”解决方案，这使得开发一个全面的评估框架变得至关重要。

Method: 提出一个包含隐私、效用和实用性三个维度的综合框架，并引入了一个名为HR-VISPR的、以人类为中心的数据集，其中包含生物识别、软生物识别和非生物识别标签，用于训练可解释的隐私指标。评估了11种隐私保护方法，涵盖了传统技术和先进的深度学习方法。

Result: 该框架能够区分与人类视觉感知一致的隐私级别，并突显了隐私、效用和实用性之间的权衡。评估结果表明，该框架为比较和选择隐私保护方法提供了一个结构化的方法。

Conclusion: 该研究提出了一个评估视觉隐私保护方法的综合框架，并在HR-VISPR数据集上进行了评估，该数据集包含生物识别、软生物识别和非生物识别标签，用于训练可解释的隐私指标。该框架能够区分与人类视觉感知一致的隐私级别，并强调隐私、效用和实用性之间的权衡。这项研究及其数据集为评估隐私保护技术提供了一个有价值的工具和结构化的评估框架。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [71] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 本研究提出 CSD-VAR，一种用于视觉自回归建模的内容-样式分解方法，可实现更好的内容保留和风格保真度。


<details>
  <summary>Details</summary>
Motivation: 在从单个图像中分离内容和样式（即内容-样式分解，CSD）的研究背景下，本研究旨在将视觉自回归建模（VAR）作为 CSD 的生成框架，利用其尺度生成过程来改进分离。

Method: CSD-VAR 是一种新颖的方法，它引入了三种关键创新：(1) 一种关注尺度的交替优化策略，将内容和样式表示与其各自的尺度对齐以增强分离；(2) 一种基于 SVD 的校正方法，以减轻内容泄露到样式表示中；(3) 增强内容身份保留的增强键值（K-V）内存。

Result: 实验表明，CSD-VAR 在内容保留和风格保真度方面优于先前的方法。

Conclusion: CSD-VAR 在内容保留和风格保真度方面优于先前的方法。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [72] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene is a new framework for creating 3D scenes from text, improving automation, consistency, and editing capabilities compared to previous methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for generating 3D scenes from natural language struggle with automation, 3D consistency, and fine-grained control.

Method: DreamScene is an end-to-end framework that uses a GPT-4 agent for scene planning, a graph-based placement algorithm for layout, Formation Pattern Sampling (FPS) for object geometry generation, and a progressive camera sampling strategy for global consistency. It also supports fine-grained editing.

Result: High-quality and editable 3D scene generation from text or dialogue, with improvements in quality, consistency, and flexibility.

Conclusion: DreamScene surpassed prior methods in quality, consistency, and flexibility, offering a practical solution for open-domain 3D content creation.

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [73] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种结合图像分类和分割的两步深度学习方法，用于隧道裂缝的检测，提高了准确性和效率，并通过可视化解释增强了模型的可理解性。


<details>
  <summary>Details</summary>
Motivation: 为了提高隧道裂缝分类和分割的准确性和效率。

Method: 提出了一种两步深度学习方法，第一步使用DenseNet-169开发自动隧道图像分类模型，第二步基于DeepLabV3+的裂缝分割模型，并通过分数加权可视化解释技术评估其内部逻辑。

Result: 该方法结合了隧道图像分类和分割，通过在第二步中分割第一步中选择的包含裂缝的图像，提高了检测的准确性和效率。实验验证了两步法的优越性能，其中裂缝分类模型的准确率为92.23%，每秒帧数为39.80；裂缝分割模型的交并比（IoU）和F1分数分别为57.01%和67.44%。

Conclusion: 该方法为隧道裂缝的快速准确量化评估提供了基础。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [74] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 利用改进的YOLOv5和多光谱成像技术，可以更有效地检测植物叶片营养缺乏。


<details>
  <summary>Details</summary>
Motivation: 精确检测植物叶片营养缺乏对于精准农业至关重要，有助于早期进行施肥、病虫害和胁迫管理。

Method: 提出了一种深度学习框架，利用多光谱成像和改进的YOLOv5模型（包含基于Transformer的注意力头）进行叶片异常分割。该模型能处理九通道多光谱输入，并利用自注意力机制捕捉精细、空间分布的症状。

Result: 实验结果表明，所提出的模型显著优于基线YOLOv5，平均Dice分数和IoU（交并比）提高了约12%，尤其在检测类症（如黄化）和色素积累等具有挑战性的症状方面效果显著。

Conclusion: 本研究提出的结合多光谱成像和基于Transformer注意力的YOLOv5模型，在检测作物叶片营养缺乏方面表现出色，为精准农业提供了有前景的解决方案。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [75] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Moodifier的先进方法，通过结合大型情感数据集（MoodArchive）和新颖的视觉-语言模型（MoodifyCLIP），实现了精准的情感驱动图像编辑，能够根据用户指定的情感（如快乐、悲伤）来修改图像内容（如人物表情、物品风格），同时保持图像的原始结构和身份特征。该方法在多个应用领域（如角色设计、时尚和家居装饰）均表现出色，并优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 情感驱动的图像编辑在创意产业中具有巨大潜力，但由于情感的抽象性和多变性，精确操控仍然困难。本研究旨在解决这一挑战。

Method: 本研究提出了一种整合方法，包括三个组成部分：1. MoodArchive：一个包含800万+图像及其情感标注的数据集，由LLaVA生成并经人类评估员部分验证。2. MoodifyCLIP：一个在MoodArchive上微调的视觉-语言模型，用于将情感转化为视觉属性。3. Moodifier：一个利用MoodifyCLIP和多模态大语言模型（MLLMs）的无训练编辑模型，实现情感转换并保持内容完整性。

Result: Moodifier系统在字符表情、时尚设计、珠宝和家居装饰等领域实现了跨域的情感图像编辑，能够保持身份和结构。实验评估表明，Moodifier在情感准确性和内容保留方面均优于现有方法，提供的编辑具有情境适应性。

Conclusion: 本研究通过整合MoodArchive数据集、MoodifyCLIP模型和Moodifier编辑模型，提出了一种创新的情感驱动图像编辑方法，实现了从抽象情感到具体视觉属性的精准转化，同时保持了内容完整性。该方法在字符表情、时尚设计、珠宝和家居装饰等多个领域表现出色，能够快速可视化情感变化，并优于现有方法，为现实世界的情感内容创作开辟了新途径。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [76] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: MTR是一种用于Vision Mamba的高效标记缩减框架，可减少计算量并保持性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决Vision Mamba在应用中的效率问题，并克服现有ViT标记缩减技术不适用于Mamba模型的问题。

Method: 本文提出了一种Mamba结构感知的重要性评分方法，并基于此开发了MTR框架，这是一个训练无关的Mamba标记缩减方法。

Result: MTR可作为即插即用组件应用于各种Mamba模型，在Vim-B主干上减少约40%的计算量，同时在ImageNet上的性能仅下降1.6%，且无需重新训练。

Conclusion: MTR是一种即插即用的训练无关模型Mamba的结构感知标记缩减框架，可有效减少计算量，同时将对性能的影响降至最低。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [77] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 本研究表明，冻结的、在大型皮肤病学数据集上预训练的基础模型（FM）非常适合用于皮肤病学疾病分类的持续学习（CIL）。通过保持FM冻结并训练一个简单的MLP，可以实现卓越的性能，并且不会遗忘先前学习的知识。即使在没有额外训练的情况下，利用FM的嵌入表示也可以获得有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 旨在探索大型基础模型（FM）在皮肤病学疾病分类的持续学习（CIL）中的潜力，以克服传统CIL方法在处理新类别时遗忘旧类别知识的问题。

Method: 本研究提出了一种简单有效的方法：保持基础模型（FM）的骨干网络冻结，并为每个任务增量训练一个轻量级多层感知机（MLP）。此外，还探索了在零训练场景下，使用基于原型的最近邻分类器，从冻结FM的嵌入中提取原型。

Result: 所提出的方法在不遗忘先前知识的情况下，在CIL任务上取得了最先进的性能，优于其他方法。基于原型的变体在零训练场景下也显示出有竞争力的结果。

Conclusion: 本研究系统地评估了在大型皮肤病变数据集上预训练的冻结基础模型（FM）在皮肤病学疾病分类中的持续学习（CIL）能力。研究提出了一种简单有效的方法，即保持骨干网络冻结，并为每个任务增量训练一个轻量级多层感知机（MLP），在不遗忘知识的情况下达到了最先进的性能，优于基于正则化、重放和架构的方法。此外，研究还探讨了使用基于原型的最近邻分类器，在零训练场景下利用冻结FM的嵌入表示，并取得了有竞争力的结果。研究结果强调了冻结FM在皮肤病学持续学习中的潜力，并支持其在实际医疗应用中的广泛采用。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [78] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark 是一种新的视觉语言模型水印框架，通过视觉对齐和跨模态协调来保护知识产权，同时保持语义保真度。它使用多尺度对齐指标和熵敏感机制进行水印注入，无需模型重新训练。实验表明，VLA-Mark 在提高文本质量和抵抗攻击方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本水印方法会通过有偏见的标记选择和静态策略破坏视觉-文本对齐，使得语义关键概念容易受到损害。视觉语言模型需要一种既能保护知识产权又不损害多模态连贯性的水印解决方案。

Method: 提出了一种名为 VLA-Mark 的视觉语言模型水印框架，该框架集成了多尺度视觉-文本对齐指标（包括局部块亲和力、全局语义连贯性和上下文注意力模式），并结合熵敏感机制来指导水印注入，无需重新训练模型。

Result: 实验结果显示，VLA-Mark 的困惑度（PPL）比传统方法低 7.4%，BLEU 分数高 26.6%，检测准确率（AUC）接近完美（98.8%）。该框架在面对释义和同义词替换等攻击时，表现出 96.1% 的攻击韧性，同时保持了文本-视觉一致性。

Conclusion: VLA-Mark 框架在保护知识产权的同时，通过跨模态协调保持了语义保真度，并在文本-视觉一致性方面设立了新的标准。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [79] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 研究评估了四种匿名化技术（模糊化、遮蔽、加密、头像替换）对四种异常检测算法（MGFN、UR-DMU、BN-WVAD、PEL4VAD）在UCF-Crime数据集上的影响，发现异常检测在匿名化数据下仍然可行，但性能受算法和匿名化方式影响，并指出了隐私保护与检测效用之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 深度学习在安防视频异常检测方面取得进展，但引发了对敏感人类数据收集的隐私担忧。

Method: 评估了四种异常检测方法（MGFN、UR-DMU、BN-WVAD和PEL4VAD）在经过模糊化、遮蔽、加密和头像替换四种匿名化技术处理后的UCF-Crime数据集上的表现。

Result: 实验结果表明，异常检测在匿名化数据下仍然可行，并且性能与算法设计和学习策略相关。某些匿名化模式（如加密和遮蔽）反而可能提高某些模型的AUC性能。研究强调了算法对匿名化的敏感性以及隐私保护与检测效用之间的权衡。此外，研究还对比了传统匿名化技术与新兴的隐私设计方案。

Conclusion: 该研究对四种人类匿名化技术（模糊化、遮蔽、加密和头像替换）在安防视频异常检测中的表现进行了全面分析，发现在匿名化数据下异常检测仍然可行，但其性能取决于算法设计和学习策略。某些匿名化方法（如加密和遮蔽）甚至可能提高某些模型的AUC性能。研究强调了在保护隐私和维持检测效用之间的权衡，并对比了传统匿名化技术与新兴的隐私设计方案，指出了在隐私保护鲁棒性和效用灵活性之间存在的权衡。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [80] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [81] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG 是一个无需训练的框架，可通过结合增量重叠图模型和外极几何来跨视图关联对象检测，以实现鲁棒的 3D 重建，即使在具有挑战性的条件下也是如此。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图多对象关联方法（通常依赖于外观特征或外极一致性等几何约束）在对象视觉上无法区分或观测值被噪声破坏时可能会失败。提出了 C-DOG 框架来解决这些限制。

Method: C-DOG框架结合了增量重叠图模型和外极几何来跨视图关联检测。它使用基于外极一致性的边缘权重表示每个 2D 观测值作为图节点。增量邻域重叠聚类步骤识别强一致性组，同时容忍噪声和部分连接。此外，还通过纳入基于四分位距 (IQR) 的过滤和 3D 反向投影误差标准来消除不一致的观测值。

Result: C-DOG 在合成基准上的广泛实验表明，与基于几何的基线相比，C-DOG 表现更好，并且在具有挑战性的条件下（例如高对象密度、无视觉特征和有限的相机重叠）保持鲁棒性。

Conclusion: C-DOG 在具有挑战性的条件下（例如高对象密度、无视觉特征和有限的相机重叠）表现优于基于几何的基线，并且具有鲁棒性，因此非常适合真实世界场景中的可扩展 3D 重建。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [82] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是一个完全开源的视觉基础模型，性能超越了现有专有模型，并引入了改进的聚类和位置解纠缠方法，以提高性能和可复现性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有专有模型（如DINOv2、CLIP、SigLIPv2）在性能上的局限性以及SSL聚类方法在处理语义模糊性方面的不足，提出Franca模型。

Method: Franca采用了一个受Web-SSL启发的透明训练流程，并使用了公开可用的数据集（ImageNet-21K和ReLAION-2B的一个子集）。为了解决SSL聚类方法的局限性，Franca引入了一种参数高效的多头聚类投影器，该投影器基于嵌套的Matryoshka表示，可以逐步优化特征到更精细的聚类，同时不增加模型大小。此外，Franca还提出了一种新颖的位置解纠缠策略，通过显式去除稠密表示中的位置偏差来改进语义内容的编码。

Result: Franca模型在性能上匹配甚至超越了最先进的专有模型，并在多个下游基准测试中取得了持续的提升，证明了更清晰特征空间效用。

Conclusion: Franca的贡献建立了一个新的透明、高性能视觉模型标准，并为整个AI社区开辟了更具可复现性和通用性的基础模型之路。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [83] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: This study proposes Adaptive Linguistic Prompting (ALP), a method using multimodal LLMs like GPT-4o and Gemini 1.5 Pro to detect phishing webpages by analyzing text, visuals, and URLs. ALP achieved an F1-score of 0.93, outperforming traditional methods and providing a foundation for more robust and adaptive phishing detection systems.


<details>
  <summary>Details</summary>
Motivation: Phishing attacks represent a significant cybersecurity threat, necessitating adaptive detection techniques.

Method: The study explores few-shot Adaptive Linguistic Prompting (ALP) in detecting phishing webpages through the multimodal capabilities of state-of-the-art large language models (LLMs) such as GPT-4o and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides LLMs to analyze textual deception by breaking down linguistic patterns, detecting urgency cues, and identifying manipulative diction commonly found in phishing content. By integrating textual, visual, and URL-based analysis, a unified model capable of identifying sophisticated phishing attempts is proposed.

Result: Experiments demonstrate that ALP significantly enhances phishing detection accuracy by guiding LLMs through structured reasoning and contextual analysis, achieving an F1-score of 0.93, surpassing traditional approaches.

Conclusion: ALP-integrated multimodal LLMs have the potential to advance phishing detection frameworks, achieving an F1-score of 0.93, surpassing traditional approaches. These results establish a foundation for more robust, interpretable, and adaptive linguistic-based phishing detection systems using LLMs.

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [84] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen框架利用LLM通过多阶段的角色扮演来生成情感丰富的文本，以解决情感数据集稀缺的问题，并在多样性、人类相似性和实际应用中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决情感识别领域中高质量、多样化情感数据集稀缺的挑战，以及情感表达的内在主观性和大规模、可泛化的数据收集的困难。

Method: PersonaGen框架通过结合人口统计学属性、社会文化背景和详细的情境背景来构建分层的虚拟角色，并利用这些角色引导情感表达的生成。

Result: PersonaGen显著优于基线方法，能够生成多样化、连贯且具有区分性的情感表达，为扩充或替代真实世界的情感数据集提供了一种强大的替代方案。

Conclusion: PersonaGen框架通过多阶段的、基于角色的条件设置，利用大型语言模型生成情感丰富的文本，为情感识别领域的数据集稀缺问题提供了新的解决方案。实验结果表明，PersonaGen生成的合成数据在多样性、人类相似性和现实性方面表现优于基线方法，并能有效提升下游情感分类任务的性能，显示出其作为增强或替代真实情感数据集的潜力。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [85] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT 是一种新的微调方法，通过将图结构注入 LLM 来提高其在处理结构化数据（如 AMR）时的性能，特别是在文本生成任务中。


<details>
  <summary>Details</summary>
Motivation: LLM 越来越多地应用于涉及结构化输入的任务，例如图形。AMR（将丰富的语义编码为有向图）为评估 LLM 从此类结构生成文本的能力提供了一个严格的测试平台。然而，现有方法通常会任意地线性化 AMR，忽略关键的结构线索，或者依赖于与标准 LLM 不兼容的架构。

Method: SAFT 是一种结构感知微调方法，无需架构更改即可将图拓扑注入预训练的 LLM。它从变换后的 AMR 的磁拉普拉斯算子计算方向敏感的位置编码，并将其投影到 LLM 的嵌入空间中。

Result: SAFT 在 AMR 3.0 上达到了新的最先进水平，比基线提高了 3.5 BLEU 分数。改进的幅度与图的复杂性成正比，这凸显了结构感知表示在增强 LLM 性能方面的价值。

Conclusion: SAFT 提供了一种通用且有效的方法，用于在结构化数据和语言模型之间架起桥梁。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [86] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 本研究提出了一种新的基于图的fake news检测方法，利用NLP将新闻转换为图，并使用MDL-based GBAD算法来识别异常模式。


<details>
  <summary>Details</summary>
Motivation: fake news在数字世界中迅速传播，已成为一个严峻的问题。本研究旨在解决这一挑战。

Method: 本研究提出了一种基于上下文图的方法来检测fake news。首先，利用自然语言处理（NLP）技术将新闻文章转换为上下文图结构。然后，应用基于最小描述长度（MDL）的图基异常检测（GBAD）算法进行图挖掘，以识别出与正常模式相悖的异常模式。

Result: 通过将新闻文章转换为上下文图并应用MDL-based GBAD算法，本研究提出了一种有效的fake news检测方法。

Conclusion: 本研究提出了一种基于上下文图的fake news检测方法，通过将新闻文章转换为图结构并应用基于MDL的GBAD算法，有效识别出与正常模式相悖的异常模式，从而检测fake news。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [87] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: PARAM-1 是一个 2.9B 参数的语言模型，旨在解决现有 LLM 的英语中心化问题，并解决印度语言多样性问题。它在以印度为中心的任务中表现出色，可作为通用模型和印度相关应用的基准。


<details>
  <summary>Details</summary>
Motivation: 由于现有的 LLM 以英语为中心，未能充分代表印度等语言多样化的地区，因此需要 PARAM-1 来解决这种排他性设计，并解决印度语言的多样性。

Method: PARAM-1 是一个 2.9B 参数的、仅解码器、仅文本的语言模型，使用包括印地语和英语的双语数据集从头开始训练，并通过 SentencePiece 分词器针对印度语语系进行了优化。

Result: PARAM-1 在以印度为中心的基准测试中表现出色，包括 IndicQA、代码混合推理和社会语言学稳健性任务，证明了其作为通用模型和印度相关应用的强大基准的有效性。

Conclusion: PARAM-1 是一个 2.9B 参数的、仅解码器、仅文本的语言模型，在一系列以印度为中心的任务中表现出色，可作为通用模型和印度相关应用的强大基准。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [88] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 通过在意见单元上操作重构主题建模管道，以提高从客户评论中提取见解的表现，并分析其对业务指标的影响。


<details>
  <summary>Details</summary>
Motivation: 提高从客户评论中提取见解的表现。

Method: 将主题建模管道重构为在意见单元上操作，意见单元是包含相关文本摘录和相关情感分数的独特声明。

Result: 提高了后续主题建模的表现，产生了连贯且可解释的主题，同时还捕获了与每个主题相关的情感。

Conclusion: 通过将主题建模管道重构为在意见单元上操作（包含相关文本摘录和相关情感分数），改进了从客户评论中提取见解的表现。将主题和情感与星级等业务指标相关联，可以深入了解特定的客户问题如何影响业务成果。评估了其在创建连贯主题方面的有效性，并评估了整合主题和情感模式以进行准确星级预测的方法。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [89] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel是一个新框架，仅使用单语语料库，通过风格检测器和扩散式风格应用器来提高神经机器翻译中的风格保真度。


<details>
  <summary>Details</summary>
Motivation: 尽管神经机器翻译取得了革命性进展，但在保留风格细微差别方面仍然面临挑战，而现有方法通常需要平行语料库来进行风格保留。

Method: Babel框架包含一个基于上下文嵌入的风格检测器，用于识别源文本和目标文本之间的风格差异，以及一个基于扩散的风格应用器，用于在保持语义完整性的同时纠正风格不一致。该框架作为后处理模块集成到现有的神经机器翻译系统中。

Result: Babel框架在法律、文学、科学写作、医学和教育内容等五个不同领域的广泛实验表明，该框架的识别风格不一致的准确率为88.21%，风格保留能力提高了150%，同时保持了0.92的高语义相似性得分。人类评估也证实了Babel润色的翻译能够更好地保留源文本风格，同时保持流畅性和充分性。

Conclusion: Babel框架通过仅使用单语语料库，在神经机器翻译中增强了风格保真度，并在各种领域实现了显著的风格保留和高语义相似性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [90] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 通过修改稀疏自编码器（SAE）特征，可以有效地控制大型多语言语言模型的生成语言，即使在没有明确语言提示或微调的情况下也能实现高成功率和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在零样本设置下，确定性地控制大型多语言语言模型（LLMs）目标生成语言这一根本性挑战。

Method: 利用预训练的稀疏自编码器（SAE）特征，通过修改单个SAE特征来控制大型多语言语言模型（LLMs）在推理过程中生成的语言。

Result: 通过修改单个SAE特征，可以实现高达90%的语言控制成功率，同时保持语义保真度。研究发现，语言引导在Transformer的中后期层最有效，并且会被与语言敏感SAE特征相关的特定注意力头所放大。

Conclusion: 研究结果表明，稀疏特征引导是一种轻量级且可解释的控制多语言生成的方法。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [91] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: ALIGNed-LLM 是一种将知识图谱注入语言模型的方法，通过对齐实体和文本嵌入来提高事实准确性并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）如 GPT-4、Gemini 和 Claude 在各种自然语言处理（NLP）任务中表现出色，但其易于产生幻觉是主要挑战之一。将知识图谱（KGs）集成到语言模型中，通过提供结构化、可靠、领域特定的外部信息，被认为是解决这一挑战的有前途的解决方案。

Method: ALIGNed-LLM 方法通过使用预训练的知识图谱嵌入（KGE）模型（如 TransE）的嵌入和一个可训练的投影层来对齐实体和文本嵌入，从而将 KGs 注入语言模型的潜在空间。

Result: 在三个常用的问答基准数据集上，ALIGNed-LLM 均显示出显著的改进。此外，该方法在一个来自欧洲大型中央银行的真实金融用例中也得到了验证，显著提高了 LLM 回答的准确性和精确度。

Conclusion: ALIGNed-LLM 通过将知识图谱（KGs）注入语言模型的潜在空间，有效提高了语言模型的 factual accuracy，并减少了幻觉。该方法在三个问答基准数据集和金融用例中均显示出显著的改进。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [92] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为PSA的新型越狱方法，通过利用大型语言模型对学术论文的信任倾向，成功攻击了多个模型，并发现了模型在安全漏洞方面存在的有趣偏差。


<details>
  <summary>Details</summary>
Motivation: 验证大型语言模型（LLM）在信任权威信息来源（如学术论文）方面可能存在的新的潜在漏洞。

Method: 提出了一种名为“Paper Summary Attack”（PSA）的新颖越狱方法，该方法通过系统地合成攻击或防御焦点的大型语言模型安全论文内容，并策略性地将有害查询作为对抗性负载填充到预定义的子部分中，从而构建对抗性提示模板。

Result: PSA在基础LLM和先进推理模型（如Deepseek-R1）中均发现了显著漏洞。PSA在Claude3.5-Sonnet上的攻击成功率（ASR）为97%，在Deepseek-R1上为98%。研究还揭示了模型在面对攻击性或防御性论文时，在不同模型及同一模型不同版本之间存在截然相反的漏洞偏差。

Conclusion: 该研究揭示了大型语言模型（LLM）在面对来自学术论文等权威来源的信息时，可能存在新的潜在漏洞。作者提出了一种名为“Paper Summary Attack”（PSA）的新颖越狱方法，该方法通过系统地合成攻击或防御焦点的大型语言模型安全论文内容，并策略性地将有害查询作为对抗性负载填充到预定义的子部分中，从而构建对抗性提示模板。实验证明，PSA不仅暴露了基础大型语言模型（LLM）的漏洞，还成功攻击了像Deepseek-R1这样的先进推理模型，在经过良好对齐的模型（如Claude3.5-Sonnet）上实现了97%的攻击成功率，在Deepseek-R1上甚至达到了98%。此外，研究还发现模型在暴露于攻击性或防御性论文时，在不同基础模型之间以及同一模型的不同版本之间存在截然相反的漏洞偏差，这为未来的对抗性方法和安全对齐研究提供了线索。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [93] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: LLM的价值评估方法存在鲁棒性和表达能力不足的问题，且其价值与现实行为关联性弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究在评估LLM的价值取向方面存在挑战：1. 缺乏对价值探测方法的系统性比较；2. 不清楚探测到的价值在多大程度上反映了模型在现实世界行为中的偏好。

Method: 本研究评估了三种广泛使用的探测策略在价值表示上的鲁棒性和表达能力，通过改变提示和选项来检测其在输入扰动下的方差。此外，研究引入了两个任务，以检测价值是否对人口统计学背景有反应，以及它们在多大程度上与模型在价值相关场景中的行为一致。

Result: 所有探测方法在输入扰动下都表现出较大的方差；人口统计学背景对自由文本生成影响甚微；模型的价值与其在基于价值的行动中的偏好只有微弱的相关性。

Conclusion: LLM的价值评估需要更仔细的检查和对其局限性的认识。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [94] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 句法结构可以用函数空间中的函数表示，并可通过神经计算实现。


<details>
  <summary>Details</summary>
Motivation: 提供一个数学框架，用于表示句法对象并探索其神经计算实现的理论可能性。

Method: 使用数学论证，将词汇项表示为函数（例如小波），在函数空间中构建任意句法对象的忠实表示。该空间具有基于第二Renyi熵的交换非结合半环结构，该结构与岩浆结构兼容。该函数集是自由代数，其运算对模型进行转换。

Result: 成功地在函数空间中构建了句法对象的忠实表示，该表示与岩浆结构兼容，并且Merge操作可以通过Hopf代数马尔可夫链上的余积来实现。

Conclusion: 该研究为句法核心计算结构提供了神经计算实现的理论可能性，并展示了如何使用正弦波上的交叉频率相位同步来实现Merge操作。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [95] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 提出了一种名为Filter & Reconnect的计算框架和图简化技术，用于分析对话。与先前的方法相比，该技术将语义指标S提高了2.06倍，并增强了对话建模的清晰度。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的交互系统的兴起，分析会话动态变得越来越重要。

Method: 提出了一种名为Filter & Reconnect的新型图简化技术，用于构建捕获松散组织对话（准模式对话）的对话图，以最小化噪声并保持语义连贯性和结构完整性。

Result: 使用大语言模型结合所提出的图简化技术，与先前的方法相比，语义指标S提高了2.06倍，同时保证了树状结构和0-δ双曲性，确保了对话建模的最佳清晰度。

Conclusion: 该研究提出了一种用于构建对话图的计算框架，结合Filter & Reconnect方法简化图结构，提高了对话分析的语义准确性和结构清晰度，并可应用于监控聊天机器人等自动化系统。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [96] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 本研究证明，结合语音停顿和语义分析的方法比单独分析语义更能准确地预测精神分裂症患者的思维形式障碍（FTD）严重程度，为开发更有效的自动化评估工具提供了依据。


<details>
  <summary>Details</summary>
Motivation: 传统FTD临床评估方法耗时且难以扩展。自动语音分析，特别是利用ASR提取的停顿特征，有望提供更客观、可扩展的评估手段，但其在FTD评估中的效用尚需验证。

Method: 本研究利用自动语音识别（ASR）技术提取言语中的停顿特征，并结合语义连贯性指标，使用支持向量回归（SVR）模型来预测临床FTD评分。研究在三个不同数据集（自然日记、图片描述、梦境叙述）上评估了这些特征的预测能力。

Result: 研究结果表明，单独的停顿特征能够有效预测FTD严重程度。将停顿特征与语义连贯性指标相结合，显著提高了预测性能（在TOPSY数据集中，联合模型相关系数最高可达0.649，AUC为83.71%），优于仅使用语义特征的模型（最佳相关系数0.584，AUC为79.23%）。不同数据集的停顿模式有所差异，但时间与语义特征的结合优势在所有数据集中均得到体现。

Conclusion: 结合时间（停顿）和语义的语音分析方法在评估精神分裂症谱系障碍中的思维形式障碍（FTD）方面优于单独使用语义特征，能够更有效地预测FTD的严重程度，并为自动化语音分析在精神病学中的应用提供了新方向。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [97] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: Balalaika是一个包含2000多小时高质量俄语语音及标注的新数据集，能提升语音合成和增强效果。


<details>
  <summary>Details</summary>
Motivation: 解决了俄语语音合成中的元音弱化、辅音清化、可变重音、同形异义词歧义和不自然语调等挑战。

Method: 介绍了Balalaika数据集的构建流程、标注方法和比较评估结果。

Result: 在语音合成和增强任务中，使用Balalaika数据集训练的模型显著优于使用现有数据集训练的模型。

Conclusion: Balalaika数据集显著提升了俄语语音合成和增强的效果，超越了现有数据集。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [98] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 研究通过分析语言特征发现，人写文本比机器生成文本（尤其是新模型）具有更多的句法和语义多样性，而机器文本趋于同质化。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在生成自然语言方面取得显著进展，其生成文本越来越难以与人写文本区分。本研究旨在超越简单的二元分类，通过分析语言特征来表征和区分人写文本和机器生成文本。

Method: 通过计算不同语言层面（形态、句法、语义）的语言特征，如依存长度和情感性，来表征人写文本和机器生成文本。研究使用了跨越8个领域和11个不同LLM的文本数据集，并考虑了采样策略、重复控制和模型发布日期等因素。此外，还应用了风格嵌入来测试文本的多样性。

Result: 人写文本倾向于展现更简单的句法结构和更多样化的语义内容。人写和机器生成的文本在不同领域都表现出风格多样性，但人类文本在所选特征上的变化性更大。更新的模型输出的文本变化性相似，表明机器生成文本存在趋同现象。

Conclusion: 该研究通过分析语言特征，发现人写文本在句法结构和语义内容上更为多样化，而机器生成文本，特别是较新模型生成的文本，表现出趋同性。研究还发现，人类文本在语言特征上的变化性更大。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [99] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-X是一个7B参数的开源多语言翻译模型系列，性能媲美GPT-4o和Gemini-2.5，并且优于其他开源模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在处理多语言翻译中的复杂语言模式和生硬翻译的挑战。

Method: Seed-X是一个包含指令和推理模型的开源LLM系列，其基础模型在包含28种语言的单语和双语内容的混合数据上进行预训练。指令模型通过思维链（CoT）推理进行微调，并通过强化学习（RL）进行增强。

Result: Seed-X系列模型在7B参数规模下，在28种语言的翻译能力上取得了突破性进展，性能媲美顶尖闭源模型，并优于其他开源模型。

Conclusion: Seed-X在28种语言的翻译性能上与Gemini-2.5和GPT-4o等领先的闭源模型相当，并且在自动评估和人类评估中均显著优于更大的开源模型。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [100] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: CU-ICU 是一种通过稀疏微调定制 ICU 数据的 T5 模型，可提高预测准确性和可解释性，同时所需的计算资源最少。


<details>
  <summary>Details</summary>
Motivation: 在 ICU 等专业领域集成大型语言模型存在域适应和标记数据有限等独特挑战。

Method: CU-ICU 采用稀疏微调方法，结合了少样本提示和选择性参数更新，能够以最少的监督进行高效适应。

Result: CU-ICU 在脓毒症早期检测、死亡率预测和临床笔记生成等关键 ICU 任务上，提高了预测准确性和可解释性，在脓毒症检测准确性方面提高了 15%，在生成临床相关解释方面提高了 20%，同时更新的模型参数不到 1%。

Conclusion: CU-ICU 是一种可扩展、低开销的解决方案，可在真实的 ICU 环境中提供准确且可解释的临床决策支持。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [101] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: KiC框架通过改进的响应选择和可靠性评估机制，在保持高准确率的同时显著降低了LLM API的使用成本。


<details>
  <summary>Details</summary>
Motivation: 现有级联方法在选择可靠的代表性响应和评估自由格式输出的整体可靠性方面存在不足，因为它们依赖于精确的文本匹配。LLMs虽然性能优越，但通常只能通过API访问，推理成本高昂。

Method: 提出了一种名为关键词启发级联（KiC）的新框架，该框架通过识别弱模型输出中最具代表性的答案，并评估其他响应与该答案的语义一致性，根据一致性程度决定是否接受弱模型的输出或升级到更强的模型。

Result: KiC实现了GPT-4 97.53%的准确率，同时平均API成本降低了28.81%，并在特定基准测试中表现优于GPT-4。

Conclusion: KiC框架通过识别弱模型输出中最具代表性的答案，并评估其他响应与该答案的语义一致性，根据一致性程度决定接受弱模型的输出或升级到更强的模型，在三个自由格式文本生成基准测试中，KiC实现了GPT-4 97.53%的准确率，同时平均API成本降低了28.81%，并在特定基准测试中表现优于GPT-4。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [102] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe 是一个用于多轮对话的 LLM 推理加速框架，通过在线稀疏化和渐进式键值压缩来提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了应对长对话中 LLM 面临的计算和内存挑战，并解决现有加速方法（如上下文压缩或键值缓存优化）依赖于固定或基于位置的启发式方法，未能适应动态对话模式的缺点。

Method: LoopServe 提出了一种自适应的双阶段推理加速框架。第一阶段，通过动态选择注意力矩阵中最重要的部分进行在线稀疏化。第二阶段，通过自适应地维护一个基于最近生成输出标记的相关且高效的缓存来进行渐进式键值压缩。

Result: LoopServe 显著加速了 LLM 推理，并在广泛的长上下文对话任务中表现出优于现有基线的效果。

Conclusion: LoopServe 在各种长上下文对话任务中一致地实现了优于现有基线的效果，并显著加速了 LLM 推理。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [103] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: LLM在GRS中的推荐结果与传统方法相似，但解释不够透明，存在模糊和不一致性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM作为GRS中的联合决策者和解释生成器的有效性，以及与传统聚合策略的对比，特别关注解释的透明度和可解释性。

Method: 通过对比LLM生成的推荐和解释与基于社会选择的聚合策略（如加性效用论ADD）来评估LLM在GRS中的表现。

Result: LLM推荐结果与ADD聚合相似；LLM解释常提及平均评分，但会引入额外标准；群组结构不影响推荐；额外标准的引入与评分数量相关，可能表明传统聚合方法在大规模数据集上的低效。

Conclusion: LLM驱动的群体推荐系统（GRS）在推荐结果上与基于效用论的聚合策略相似，但在解释方面，LLM倾向于提及平均评分，并且会引入额外标准（如用户/物品相似度、多样性、流行度），这可能导致解释的模糊性和不一致性，影响透明度和可解释性。群组结构（统一或发散）不影响推荐结果。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [104] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 本研究使用机器学习分析了 18,937 个法国法院的儿童抚养权案件，发现专家模型（基于个别法官的判决）比泛化模型（基于聚合数据）具有更高的预测准确性（F1 分数达 92.85% vs 82.63%），证明了法官的个体决策风格对案件结果有显著影响，支持了法律现实主义。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在检验个别法官的决策模式是否显著影响案件结果，挑战了法官是中立变量并统一适用法律的假设，以回应法律现实主义与法律形式主义的争论。

Method: 本研究采用混合方法，结合使用大型语言模型（LLMs）进行结构化特征提取和机器学习模型（RF、XGB和SVC）进行结果预测。研究分析了 10,306 个案件中提取的 18,937 个居住安排裁决，并比较了在个别法官过往裁决上训练的专家模型与在聚合数据上训练的、不区分法官的泛化模型。

Result: 专家模型持续提供比泛化模型更高的预测准确性，表现最佳的模型达到了 92.85% 的 F1 分数，而泛化模型（使用了 20 到 100 倍的样本量）的 F1 分数为 82.63%。专家模型捕捉到了稳定且不可迁移到其他法官的个体模式。

Conclusion: 本研究通过实证数据支持了法律现实主义，表明个别法官的身份在法律结果中起着可衡量的作用。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [105] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: LLMs存在性别与性取向偏见，使用LoRA微调可显著降低偏见，提升模型公平性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）常常会复现其训练语料库中存在的性别与性取向偏见，导致其输出边缘化LGBTQIA+用户。因此，减少这些偏见至关重要。

Method: 本研究评估了两种参数高效微调（PEFT）技术——低秩适应（LoRA）和软提示调优——作为减少大型语言模型（LLMs）性别与性取向偏见的轻量级替代方案。研究使用WinoQueer基准测试量化了三款开源LLMs的偏见，并通过在QueerNews语料库上应用LoRA进行微调，以评估其减少偏见的效果。

Result: 在WinoQueer基准测试中，研究观察到基线偏见得分高达98（满分100），而中性得分为50。通过在QueerNews语料库上使用LoRA（<0.1%额外参数）进行微调，偏见得分最高可降低50分，中性比例从近0%提升至最高36%。软提示调优（10个虚拟标记）仅带来边际改善。

Conclusion: LoRA参数高效微调技术在减少大型语言模型性别与性取向偏见方面表现出巨大潜力，可在极少计算资源消耗下实现显著的公平性提升。研究提倡广泛采用社区驱动的PEFT技术，构建更大规模的LGBTQIA+社群原创语料库，并开发超越WinoQueer的综合性评估方法，同时辅以持续的审计以确保模型的包容性。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [106] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 提示的细微变化会严重影响语言模型的输出，本研究发现视觉语言模型（VLM）在处理多模态输入时，其区分良性和有害内容的能力会下降。研究人员发现，通过特定的提示技巧（如加入视觉信息、对抗性示例或积极的起始短语）可以轻易地“越狱”VLM，使其生成不当内容，即使是少量示例也能达到效果。此外，他们还提出了一种改进模型结构的方法来增强这种攻击。最后，研究指出，看似无害的表情包也可能成为诱导 VLM 生成有害内容的有效途径。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究提示的敏感性在多大程度上会被用来生成不当内容，特别是关注提示设计中的离散组成部分如何影响视觉语言模型（VLM）生成不当内容的能力。

Method: 本研究探究了提示设计中的离散组成部分（视觉信息、对抗性示例、积极起始短语）如何影响视觉语言模型（VLM）生成不当内容。研究人员分析了这三个因素对成功越狱的影响，并提出了一种利用 VLM 内部层之间 skip-connection 连接的框架，以提高越狱成功率。

Result: 研究发现，VLM 在多模式环境中区分良性和有害输入的能力显著下降。提示设计的三个关键因素（详细的视觉信息、对抗性示例、积极的起始短语）都能独立触发越狱，并且少量（三个）的上下文示例即可导致模型生成不当输出。所提出的框架通过添加 skip-connection 连接，显著提高了越狱成功率，即使使用良性图像也是如此。表情包与有毒图像在诱导有害内容方面同样有效。

Conclusion: 虽然视觉语言模型（VLM）在单一模式下（仅文本或仅图像）可以可靠地区分良性和有害输入，但在多模式环境中，这种能力会显著下降。提示的离散组成部分（详细的视觉信息、对抗性示例、积极的起始短语）中的任何一个都能够成功地触发越狱，并且很少的上下文示例（少至三个）就足以使模型生成不当输出。此外，通过在 VLM 的两个内部层之间添加 skip-connection 连接，可以显著提高越狱成功率，即使在存在良性图像的情况下也是如此。有趣的是，通常被认为幽默或无害的表情包与有毒图像在诱导有害内容方面同样有效，这凸显了 VLM 细微且复杂的漏洞。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [107] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出GSDMM和GSDMM+算法，用于更有效地对稀疏、高维的短文本数据进行聚类，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 短文本聚类在社交媒体时代日益重要，但现有方法在处理短文本数据的稀疏性、大规模和高维度特性时面临挑战，并且表示学习的计算强度导致运行时间增加。需要更有效和高效的方法来解决这些问题。

Method: 提出了一种用于狄利克雷多项式混合模型（GSDMM）的折叠吉布斯采样算法，以解决短文本数据的稀疏性、大规模和高维度特征。在此基础上，提出了一种改进方法GSDMM+，通过减少初始化噪声和基于熵自适应调整词权重来优化性能，并通过策略性聚类合并进一步优化聚类粒度。

Result: 实验结果表明，GSDMM和GSDMM+在效率和有效性方面优于经典和最先进的方法，表明该模型能够有效处理短文本聚类任务。

Conclusion: GSDMM+通过减少初始化噪声和基于熵的自适应词权重调整，实现了更细粒度的聚类，更好地揭示了更多与主题相关的显式信息。此外，采用策略性聚类合并来优化聚类粒度，使预测分布与真实类别分布更匹配。实验结果证明了该方法在效率和有效性方面优于传统方法和现有最先进方法。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [108] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 提出两种方法（仅基于文本和基于知识图谱）来从科学论文中提取问答对，以帮助学者快速理解论文内容。基于知识图谱的方法效果更好。


<details>
  <summary>Details</summary>
Motivation: 为了帮助学者们快速识别和理解科学文章的核心概念和贡献，提出以问答（QA）对的形式提取这些关键信息。

Method: 提出两种方法：1. 仅依赖文章内容，通过选取显著段落、使用大型语言模型（LLM）生成问题、对问题进行排序以及生成答案。 2. 利用知识图谱（KG）生成问答对，包括构建知识图谱（通过微调实体关系提取模型）、提取显著三元组（基于三元组的TF-IDF类度量来评估三元组的重要性）以及生成问答对。

Result: 通过专家评估，基于知识图谱的方法在捕捉文章核心思想方面表现更优。

Conclusion: 研究表明，基于知识图谱的方法能够有效地捕捉文章的核心思想，并且在科学文献上微调实体关系提取模型对于提取高质量三元组至关重要。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [109] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 本研究发现，在中国心理咨询中，负面词汇的使用与抑郁和焦虑程度相关，但第一人称代词的使用与心理健康无关。这可能与文化差异有关。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索语言表达与中国心理咨询互动中的抑郁和焦虑心理状态之间的关系，重点分析第一人称单数代词和负面情绪词的使用情况，以理解文化和对话动态如何影响心理健康沟通中的语言使用。

Method: 本研究利用了来自735次在线咨询会话的语料库，并采用通用线性混合效应模型，结合语言查询和文字计数（LIWC）软件量化语言模式，以探究语言表达与抑郁、焦虑心理状态之间的关系，特别关注第一人称单数代词和负面情绪词的使用。

Result: 研究结果显示，负面情绪词的使用频率与客户的抑郁和焦虑严重程度之间存在显著的正相关。然而，与主要来自英语语言环境的先前研究结果相反，第一人称单数代词的使用频率与客户的心理状况没有显著差异。

Conclusion: 本研究揭示了在中国心理咨询互动中，负面情绪词的使用频率与抑郁和焦虑的严重程度呈显著正相关，而第一人称单数代词的使用频率与客户的心理状况没有显著差异。这些结果强调了文化和对话背景对心理健康沟通中语言使用的细微影响，并为华语人群的治疗实践提供了相关的心理语言学标记。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [110] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 这篇论文提出了一个分析侦探小说的框架，并用它来评估了LLM生成的小说，发现LLM小说虽然会制造意外，但往往破坏了“公平博弈”的原则，导致故事质量不高。


<details>
  <summary>Details</summary>
Motivation: 为了给读者提供更佳的阅读体验，需要平衡读者的期待与故事的意外性，尤其在侦探小说中，“公平博弈”是作者与读者之间的默契

Method: 提出一个概率框架来定义和量化“公平博弈”和“惊喜度”等品质

Result: LLM生成的侦探小说虽然有不可预测性，但在“惊喜度”和“公平博弈”之间未能取得平衡，影响了整体质量

Conclusion: LLM生成的侦探小说的质量普遍不高，因为它们在“公平博弈”和“惊喜度”之间难以取得平衡

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [111] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: InTraVisTo 是一个内部 Transformer 可视化工具，用于检查 LLM 的计算过程，帮助理解其内部模式和推理。


<details>
  <summary>Details</summary>
Motivation: LLM 在生产中的应用仍然具有挑战性，因为它们不可预测的行为以及期望行为与实际模型输出之间的差异。需要一个工具来帮助理解 LLM 的内部工作原理。

Method: InTraVisTo 通过解码模型各层的 token 嵌入以及使用桑基图可视化模型各组件之间跨层的信息流，提供 Transformer 模型内部状态和信息流的可视化。

Result: InTraVisTo 提供了一个可视化工具，用于检查和追踪 Transformer LLM 中生成每个 token 的计算过程。

Conclusion: InTraVisTo 旨在帮助研究人员和从业者更好地理解 Transformer 模型内的计算，从而揭示 LLM 使用的内部模式和推理过程。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [112] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 网络安全NER标签不统一，本研究试图通过标签统一来改善，但发现统一后的模型泛化能力差，提出的改进模型也未带来显著提升。


<details>
  <summary>Details</summary>
Motivation: 网络安全命名实体识别（NER）领域缺乏标准化标签，这使得组合数据集变得困难。本研究旨在通过跨越四个网络安全数据集的标签统一来提高数据资源可用性。

Method: 我们执行了粗粒度标签统一，并使用BiLSTM模型进行了成对交叉数据集评估。为了解决统一的局限性，我们提出了包括多头模型和基于图的迁移模型在内的替代架构。

Result: 定性分析预测结果揭示了错误、局限性和数据集差异。

Conclusion: 跨数据集评估显示，在统一数据集上训练的模型泛化能力差。多头模型（带权重共享）仅比统一训练有边际改进，而我们基于BERT-base-NER构建的图迁移模型与BERT-base-NER相比没有显著的性能提升。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [113] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 本研究旨在通过生成合成数据、连接单语音频和利用带语言令牌的真实数据来改进加泰罗尼亚语-西班牙语代码转换的自动语音识别（ASR）。实验证明，结合适量的合成数据和优势语言令牌能带来最佳的转录效果。


<details>
  <summary>Details</summary>
Motivation: 代码转换（CS）是双语或多语使用者在交流中交替使用两种或多种语言的现象。然而，由于训练数据稀少和语言相似性，代码转换对自动语音识别（ASR）构成了重大挑战。现有的 ASR 模型通常依赖于单语或混合语料库，这些语料库无法准确反映真实的 CS 模式。这种情况在社会中尤其普遍，在这些社会中，CS 在非正式和正式场合都很常见。加泰罗尼亚语-西班牙语 CS 是一个关键的例子，因为它广泛应用于媒体和议会演讲中。因此，有必要改进 ASR 系统以有效处理 CS。

Method: 本研究通过探索三种策略来改进加泰罗尼亚语-西班牙语代码转换的自动语音识别（ASR）：(1) 生成合成代码转换数据，(2) 连接单语音频，以及 (3) 利用带语言令牌的真实代码转换数据。研究人员从加泰罗尼亚语语音语料库中提取代码转换数据，并对 OpenAI 的 Whisper 模型进行微调，使其在 Hugging Face 上可用。

Result: 研究结果表明，将适量的合成 CS 数据与优势语言令牌相结合，可以实现最佳的转录性能。

Conclusion: 结合适量的合成代码转换数据和优势语言令牌可实现最佳的转录性能。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [114] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 使用大型语言模型 (LLM) 从情境判断测试 (SJT) 回应中提取与结构相关的特征，以实现个人和专业技能的可扩展评估。


<details>
  <summary>Details</summary>
Motivation: 随着对个人和专业技能日益增长的需求，以及衡量、评估和发展这些技能的可扩展系统的需求。

Method: 使用大型语言模型（LLM）从 SJT 回应中提取与结构相关的特征。

Result: 探索了一种使用大型语言模型（LLM）从 SJT 回应中提取与结构相关的特征的新颖方法，并使用 Casper SJT 证明了该方法的有效性。

Conclusion: 本研究为个人和专业技能的自动化评分的未来发展奠定了基础。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [115] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本研究通过整合和扩展现有数据集，并采用更优的训练方法，提升了政治文本分类模型在不同类型文本上的表现。


<details>
  <summary>Details</summary>
Motivation: 自动识别文本的政治倾向和政治性具有重要意义，但现有方法在处理分布外文本时表现不佳，限制了其应用范围。

Method: 本研究整合了12个用于政治倾向分类的数据集，并扩展了18个现有数据集以创建政治性分类的新数据集。通过留一法和留一法排除法的综合基准测试，评估了现有模型的性能，并训练了具有增强泛化能力的新模型。

Result: 本研究通过构建多样化的数据集和采用改进的模型训练方法，显著提高了政治倾向和政治性文本分类在分布外文本上的性能。

Conclusion: 现有的政治倾向和政治性文本分类方法构建了孤立的解决方案，在分布外文本上表现不佳。本研究通过整合现有数据集和训练新模型来解决这个问题，以提高泛化能力。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [116] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: AI的说服力主要来自预训练和提示，而非个性化或规模，但增强说服力的同时会牺牲事实准确性。


<details>
  <summary>Details</summary>
Motivation: 评估对话式AI对人类信念的潜在巨大影响，以及AI的说服力来源和对事实准确性的影响。

Method: 通过三项大规模实验（N=76,977），部署了19个LLM（包括一些专门为说服而预训练的模型），评估它们在707个政治问题上的说服力，并检查了466,769个由此产生的LLM声明的事实准确性。

Result: 预训练和提示方法比个性化或模型规模更能增强AI的说服力。这些方法通过利用LLM的信息处理能力来增强说服力，但会牺牲事实准确性。

Conclusion: 与普遍担忧相反，当前和近期AI的说服力可能更多地来源于预训练和提示方法（分别提高了51%和27%），而非个性化或扩大模型规模。这些方法通过利用LLM快速访问和战略性部署信息的能力来增强说服力，并且在提高AI说服力的同时，系统性地降低了事实准确性。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [117] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [118] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 微调LLM会放大先序偏见，但通过策略性地重新排序选项（基于语义相似性）可以利用这种偏见来提高MCQA任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM中的先序偏见，特别是这种偏见在微调过程中如何被放大，并探索利用这种偏见来改进MCQA性能的方法。

Method: 通过重新排序选项（不依赖正确答案）来利用先序偏见，以提升LLM在多项选择题问答（MCQA）任务中的表现。

Result: 实验证明，通过基于语义相似性重新排序选项的方法，显著提高了LLM在MCQA任务上的性能。

Conclusion: LLM在MCQA任务中存在显著的先序偏见，而通过根据语义相似性重新排序选项可以有效缓解并提升模型性能。该研究揭示了偏见的双重性，为设计偏见感知模型提供了思路。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [119] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 该研究提出了一种通过知识图谱生成任务来训练语言模型以获得领域专业知识的方法。他们使用医学知识图谱创建了一个名为 QwQ-Med-3 的模型，该模型在医学推理任务上表现出色，并能将其专业知识转移到其他任务上。研究认为，未来的通用人工智能将由多个具有特定领域专长的智能代理组成。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型在跨领域泛化方面表现良好，但在获取深层领域专业知识所需的抽象能力方面存在不足。作者认为，这种不足源于其在通用语料库上的自顶向下训练方法。为了克服这一限制，需要一种自底向上的方法，通过学习组合简单的领域概念来形成更复杂的概念，从而获得专业知识。

Method: 提出了一种直接从知识图谱（KG）的原始概念合成任务的生成流程，使模型能够学习和组合这些概念进行推理。然后，在生成的 KG 基础课程上对语言模型进行微调，以实现领域特定的超智能。具体来说，在医学领域，他们使用医学 KG 策划了 24,000 个推理任务和相应的思考过程，并使用 QwQ-32B 模型进行了微调，得到了 QwQ-Med-3。此外，他们还引入了一个名为 ICD-Bench 的评估套件，用于量化模型在 15 个医学领域内的推理能力。

Result: QwQ-Med-3 在 ICD-Bench 评估套件的 15 个医学领域中，其表现显著优于最先进的推理模型。进一步的分析表明，QwQ-Med-3 利用其学到的原始概念，在 ICD-Bench 的高难度任务上扩大了性能差距。此外，在医学问答基准测试上的评估结果显示，QwQ-Med-3 能够将其获得的专业知识转移到基础模型上，从而提升了基础模型的性能。

Conclusion: 该研究提出了一种从知识图谱（KG）的领域原始概念生成任务的方法，以培养语言模型的领域专业知识。通过在医学领域验证该方法，他们微调了一个名为 QwQ-Med-3 的语言模型，该模型在 ICD-BM 评估集上表现出色，并在医学问答基准测试中展示了其专业知识的转移能力。研究人员设想，未来的通用人工智能（AGI）将源于高效的、特定领域的超级智能代理的可组合交互。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [120] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 该研究提出了一种新的阿拉伯语语音处理方法，并训练了支持现代标准阿拉伯语（MSA）和古典阿拉伯语（CA）的新模型，达到了SOTA性能，并已开源。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯语是使用最广泛的语言之一，但由于其复杂性，阿拉伯语自动语音识别（ASR）系统发展面临挑战，且公开的阿拉伯语ASR模型有限。现有研究主要关注现代标准阿拉伯语（MSA），对语言内部的变体关注较少。

Method: 提出了一个阿拉伯语语音和文本处理的通用方法，并使用FastConformer架构训练了两个模型：一个MSA模型和一个同时支持MSA和CA的统一模型。

Result: MSA模型在相关数据集上达到了新的最先进（SOTA）性能。统一模型在CA上实现了带音标的SOTA准确率，同时在MSA上也保持了强劲性能。

Conclusion: 该研究介绍了用于阿拉伯语语音和文本处理的通用方法，并基于FastConformer架构训练了两种新型模型：一种专门用于现代标准阿拉伯语（MSA），另一种是首个同时支持MSA和古典阿拉伯语（CA）的统一公共模型。MSA模型在相关数据集上达到了新的最先进（SOTA）性能，而统一模型在CA上实现了带音标的SOTA准确率，同时在MSA上也保持了强劲性能。为促进研究可复现性，研究开源了模型及其训练方法。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [121] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM是一个利用大型语言模型进行轨迹预测的框架，通过分层时间标记化技术，在提高准确率和效率的同时，缩短了序列长度。


<details>
  <summary>Details</summary>
Motivation: 在人类轨迹预测和推理领域，利用大型语言模型（LLMs）作为时空预测器和轨迹推理器，以提高预测准确性和计算效率。

Method: RHYTHM框架利用大型语言模型（LLMs）作为时空预测器和轨迹推理器。该框架将轨迹划分为每日片段，并使用分层注意力将其编码为离散标记，从而同时捕捉每日和每周的依赖关系，并显著缩短序列长度。通过一个冻结的大型语言模型，将预先计算的提示嵌入添加到标记表示中，以增强模型在不增加大量计算开销的情况下捕捉相互依赖关系的能力。

Result: 与现有最先进方法相比，准确率提高了2.4%，周末准确率提高了5.0%，训练时间减少了24.6%。

Conclusion: RHYTHM框架在真实世界数据集上的评估显示，与现有最先进方法相比，准确率提高了2.4%，周末准确率提高了5.0%，训练时间减少了24.6%，在计算效率方面取得了显著成效。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [122] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出CPC-CMS框架，通过结合专家知识和多种评估指标（准确率、精确率、召回率、F1分数、特异度、MCC、Kappa、效率）的权重，为文档级情感分析选择最佳分类模型。实验发现ALBERT在不考虑时间时表现最好，但考虑时间因素则无最优模型。该框架可推广至其他分类应用。


<details>
  <summary>Details</summary>
Motivation: 为文档级情感分析提供一种模型选择框架。

Method: 提出了一种认知成对比较分类模型选择（CPC-CMS）框架，使用专家知识判断来计算包括准确率、精确率、召回率、F1分数、特异度、Matthews相关系数（MCC）、Cohen's Kappa（Kappa）和效率在内的评估标准的权重。将朴素贝叶斯、线性支持向量分类（LSVC）、随机森林、逻辑回归、极端梯度提升（XGBoost）、长短期记忆（LSTM）和ALBERT作为分类基线模型。通过构建包含分类评估分数和标准权重的加权决策矩阵来选择最佳分类模型。

Result: 使用三个公开的社交媒体数据集进行实验。结果表明，不考虑时间因素时，ALBERT在三个数据集中表现最佳；若考虑时间消耗，则没有单一模型能在所有情况下都优于其他模型。

Conclusion: CPC-CMS框架可应用于其他领域中的分类问题。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [123] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 该研究评估了用于生物医学任务的闭源和开源LLM，发现没有万能模型，并强调了开源模型的优势。


<details>
  <summary>Details</summary>
Motivation: 为了评估具有成本效益的大型语言模型（LLM）在生物医学领域的适用性，并为特定应用选择最佳模型。

Method: 对一系列闭源和开源LLM在生物医学文本分类、生成、问答和多模态图像处理等任务上进行了全面的评估。

Result: 没有单一的LLM能在所有任务上持续表现最佳，闭源LLM在特定任务上表现强劲，但开源LLM也能达到相当或更好的性能，并具有更快的推理速度和更好的隐私性。

Conclusion: 不同的LLM在不同的任务上表现出优势，开源LLM在某些方面（如推理速度和隐私）优于闭源LLM，为在生物医学领域选择合适的模型提供了有价值的见解。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [124] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 提出CRSA框架，一种基于信息论的RSA扩展，通过优化增益函数来改进多轮对话中的AI协作，并在实验中显示出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RSA框架在扩展到涉及多轮、协作场景时面临挑战，因此需要一种新的方法来让AI系统在协作角色中进行思考，实现共同目标和信念的推理，而不仅仅是生成流畅的语言。

Method: 提出了一种名为CRSA（Collaborative Rational Speech Act）的信息论（IT）扩展框架，通过优化来自率失真理论的增益函数来模拟多轮对话，该增益函数是原始RSA模型中最大化的增益模型的扩展，并考虑了对话双方拥有私有信息且话语基于对话的场景。

Result: CRSA在参照游戏和基于模板的医患对话中，相比现有基线，表现出更一致、更具可解释性和协作性的行为。

Conclusion: CRSA在参照游戏和基于模板的医患对话中表现出比现有基线更一致、更具可解释性和协作性的行为，为构建更具实用性和社会意识的语言代理铺平了道路。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [125] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: DENSE系统利用LLM和临床信息检索，通过整合零散的EHR笔记，生成连贯的患者进展记录，解决了数据中进展记录缺失的问题。


<details>
  <summary>Details</summary>
Motivation: EHR数据中进展记录代表性不足，存在纵向叙述的空白，影响了对患者病程的理解，因此需要一个系统来恢复跨越零散记录的叙事连贯性。

Method: DENSE系统通过精细的笔记分类和时间对齐机制，整合跨就诊的异构笔记，并利用临床信息检索策略和LLM来生成进展记录。

Result: 生成的进展记录在时间忠实度方面表现出色，时间对齐率达到1.089，优于原始记录的连续性。

Conclusion: DENSE系统通过生成连贯且时间准确的进展记录，弥补了EHR数据中进展记录的不足，并展示了在时间对齐方面的优越性，有望改进下游临床任务。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [126] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA赛道旨在评估语言模型改编生物医学文献为普通语言的能力。任务包括重写摘要和替换难词。顶尖模型在准确性和完整性方面表现接近人类，但在简洁性方面有差距。自动评估指标与手动评判的相关性不高。模型在替换难词方面表现尚可，但在简洁性方面仍需改进。该赛道凸显了LLM的潜力和局限性，并指出了改进自动评估工具的必要性。


<details>
  <summary>Details</summary>
Motivation: 语言模型的最新进展在将面向专业人士的生物医学文献改编为普通语言方面显示出了潜力，使其能够被患者和护理者所理解。然而，它们的不可预测性，加上该领域潜在的巨大风险，意味着必须进行严格的评估。我们举办此赛道的目标是激励研究并为最有前途的系统提供高质量的评估。

Method: 在2023年和2024年的文本检索会议上举办了生物医学摘要的普通语言改编（PLABA）赛道。任务包括对摘要进行完整的、句子级别的重写（任务1）以及识别和替换困难术语（任务2）。对于任务1的自动评估，我们开发了一组四重专业编写的参考资料。对任务1和任务2的提交都由生物医学专家进行了广泛的手动评估。

Result: 共有来自十二个国家的十二支队伍参加了该赛道，模型涵盖了从多层感知机到大型预训练变换器。在对任务1的手动评判中，表现最好的模型在事实准确性和完整性方面可与人类媲美，但在简洁性和简短性方面则不能。基于参考的自动评估指标通常与手动评判的相关性不高。在任务2中，系统在识别困难术语和对其进行分类以进行替换方面存在困难。然而，在生成替换词方面，基于大型语言模型的系统在手动评判的准确性、完整性和简洁性方面表现良好，但在简短性方面则不然。

Conclusion: PLABA赛道展示了使用大型语言模型将生物医学文献改编给公众的潜力，同时也凸显了它们的不足以及改进自动基准测试工具的必要性。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [127] [Resource-Splitting Games with Tullock-Based Lossy Contests](https://arxiv.org/abs/2507.13853)
*Marko Maljkovic,Gustav Nilsson,Nikolas Geroliminis*

Main category: cs.GT

TL;DR: 提出了一种新的博弈模型，用于分析供需平衡和资源投资回报，并提供了计算纳什均衡的方法，已在智能交通领域得到验证。


<details>
  <summary>Details</summary>
Motivation: 为解决现实世界中盈利能力依赖于供需平衡且更高资源投资带来更高回报的场景，引入了多阶段资源分配博弈模型。

Method: 提出了一种新颖的多阶段资源分配博弈模型，并探索了集中式和纳什均衡策略。开发了一种迭代的、半去中心化的方法来计算纳什均衡，并提出了一种半解析方法来计算 Blotto 游戏设置中的唯一纳什均衡。

Result: 证明了所提出的框架可以推广到包括衰退视界和 Blotto 游戏在内的多种现有模型。

Conclusion: 该模型为智能交通等实际应用提供了有力的分析工具，并为未来研究开辟了道路。

Abstract: This paper introduces a novel class of multi-stage resource allocation games
that model real-world scenarios in which profitability depends on the balance
between supply and demand, and where higher resource investment leads to
greater returns. Our proposed framework, which incorporates the notion of
profit loss due to insufficient player participation, gives rise to a
Tullock-like functional form of the stage payoff structure when weighted fair
proportional resource allocation is applied. We explore both centralized and
Nash equilibrium strategies, establish sufficient conditions for their
existence and uniqueness, and provide an iterative, semi-decentralized method
to compute the Nash equilibrium in games with arbitrarily many players.
Additionally, we demonstrate that the framework generalizes instances of
several existing models, including Receding Horizon and Blotto games, and
present a semi-analytical method for computing the unique Nash equilibrium
within the Blotto setup. Our findings are validated through a numerical case
study in smart mobility, highlighting the practical relevance and applicability
of the proposed model.

</details>


### [128] [Online MMS Allocation for Chores](https://arxiv.org/abs/2507.14039)
*Jiaxin Song,Biaoshuai Tao,Wenqian Wang,Yuhao Zhang*

Main category: cs.GT

TL;DR: 在線上分配雜務給多個代理的難題中，我們證明了無法實現接近完美的公平分配，但提出了一種在雜務種類或代理偏好有限的情況下可以實現相當公平分配的演算法。


<details>
  <summary>Details</summary>
Motivation: 這項研究的動機是解決在線上環境中將不可分割的雜務分配給 n 個代理的問題，其中物品按順序到達，必須在到達時不可撤銷地分配，同時目標是產生 α-MMS 分配。現有研究在限制性假設下僅獲得了非平凡的演算法，或者假設了代理的總效用知識。

Method: 研究表明，對於任何固定的 n 和 ε，沒有演算法可以保證 (n - ε)-MMS 分配，這與僅有的 n-MMS 上界相匹配。

Result: 證明了對於任何固定的 n 和 ε，沒有演算法能夠保證 (n - ε)-MMS 分配，這精確地匹配了平凡的上限。此外，還提出了一種線上演算法，保證了 min{n, O(k), O(log D)}-MMS 分配，在 k 是常數的情況下可以達到 O(1)-MMS 分配，並且在個性化雙值情況下可以達到 (2 + sqrt(3)) ≈ 3.7-MMS 分配。

Conclusion: 儘管存在強大的不可能結果，但研究也取得了一些積極的成果。提供了一種通用的線上演算法，保證了 min{n, O(k), O(log D)}-MMS 分配，其中 k 是所有代理之間不同效用的最大數量，D 是任何代理的最大與最小效用之間的比率。此外，對於每個代理最多只有兩種不同效用的個性化雙值情況，該演算法保證了 (2 + sqrt(3)) ≈ 3.7-MMS 分配。

Abstract: We study the problem of fair division of indivisible chores among $n$ agents
in an online setting, where items arrive sequentially and must be allocated
irrevocably upon arrival. The goal is to produce an $\alpha$-MMS allocation at
the end. Several recent works have investigated this model, but have only
succeeded in obtaining non-trivial algorithms under restrictive assumptions,
such as the two-agent bi-valued special case (Wang and Wei, 2025), or by
assuming knowledge of the total disutility of each agent (Zhou, Bai, and Wu,
2023). For the general case, the trivial $n$-MMS guarantee remains the best
known, while the strongest lower bound is still only $2$.
  We close this gap on the negative side by proving that for any fixed $n$ and
$\varepsilon$, no algorithm can guarantee an $(n - \varepsilon)$-MMS
allocation. Notably, this lower bound holds precisely for every $n$, without
hiding constants in big-$O$ notation, thereby exactly matching the trivial
upper bound.
  Despite this strong impossibility result, we also present positive results.
We provide an online algorithm that applies in the general case, guaranteeing a
$\min\{n, O(k), O(\log D)\}$-MMS allocation, where $k$ is the maximum number of
distinct disutilities across all agents and $D$ is the maximum ratio between
the largest and smallest disutilities for any agent. This bound is reasonable
across a broad range of scenarios and, for example, implies that we can achieve
an $O(1)$-MMS allocation whenever $k$ is constant. Moreover, to optimize the
constant in the important personalized bi-valued case, we show that if each
agent has at most two distinct disutilities, our algorithm guarantees a $(2 +
\sqrt{3}) \approx 3.7$-MMS allocation.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [129] [StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation](https://arxiv.org/abs/2507.13377)
*Zhenglin Pan,Haoran Xie*

Main category: cs.GR

TL;DR: StructInbet is an inbetweening system that uses structural guidance and temporal attention for smooth, consistent character transitions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the ambiguity in pixel trajectories in the inbetweening problem and ensure consistency in character appearance during transitions.

Method: StructInbet uses explicit structural guidance to reduce ambiguity in pixel trajectories and a temporal attention mechanism to ensure character appearance consistency by incorporating information from preceding and succeeding keyframes.

Result: The system generates controllable transitions over explicit structural guidance, ensuring character appearance consistency.

Conclusion: The paper proposes StructInbet, an inbetweening system that uses explicit structural guidance and a temporal attention mechanism for controllable transitions and consistent character appearance.

Abstract: In this paper, we propose StructInbet, an inbetweening system designed to
generate controllable transitions over explicit structural guidance.
StructInbet introduces two key contributions. First, we propose explicit
structural guidance to the inbetweening problem to reduce the ambiguity
inherent in pixel trajectories. Second, we adopt a temporal attention mechanism
that incorporates visual identity from both the preceding and succeeding
keyframes, ensuring consistency in character appearance.

</details>


### [130] [DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis](https://arxiv.org/abs/2507.13388)
*Zhen-Qi Chen,Yuan-Fu Yang*

Main category: cs.GR

TL;DR: 通过创新的双潜在集成框架和自适应融合模块（AGF或DSF），改进了稳定扩散模型在处理复杂场景时的特征聚合能力，从而提升了图像合成的全局一致性和局部细节保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的稳定扩散模型在特征聚合方面存在不足，尤其是在纹理丰富和复杂的场景中，会导致语义对齐不完全和细粒度细节丢失。为了解决这些限制，需要一种能够增强特征交互的方法。

Method: 提出了一种双潜在集成框架，其中包含特征连接策略和一个自适应融合模块，该模块可以实例化为（i）自适应全局融合（AGF）以进行分层特征协调，或（ii）动态空间融合（DSF）以进行空间感知精炼。

Result: 所提出的方法能够实现更有效的跨潜在通信，在保留全局一致性的同时，还能保持局部纹理细节的保真度，从而改善了高保真图像合成的质量。

Conclusion: 该研究提出了一个新颖的双潜在集成框架，通过增强基础潜在表示和精炼潜在表示之间的特征交互，以解决现有稳定扩散模型在特征聚合方面的不足，从而实现更有效的跨潜在通信，并同时保留全局一致性和局部纹理保真度。

Abstract: With the rapid advancement of diffusion-based generative models, Stable
Diffusion (SD) has emerged as a state-of-the-art framework for high-fidelity
im-age synthesis. However, existing SD models suffer from suboptimal feature
aggregation, leading to in-complete semantic alignment and loss of fine-grained
details, especially in highly textured and complex scenes. To address these
limitations, we propose a novel dual-latent integration framework that
en-hances feature interactions between the base latent and refined latent
representations. Our approach em-ploys a feature concatenation strategy
followed by an adaptive fusion module, which can be instantiated as either (i)
an Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or
(ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design
enables more effective cross-latent com-munication, preserving both global
coherence and local texture fidelity. Our GitHub page:
https://anonymous.4open.science/r/MVA2025-22 .

</details>


### [131] [Lab-Scale Gantry Crane Digital Twin Exemplar](https://arxiv.org/abs/2507.13419)
*Joost Mertens,Joachim Denil*

Main category: cs.GR

TL;DR: 提供了一个易于访问和使用的实验室规模龙门起重机及其数字孪生系统示例，包含物理和数字组件，并提供多种服务，旨在推动数字孪生领域的研究和教育。


<details>
  <summary>Details</summary>
Motivation: 为了促进开放和可重复的科学研究，解决数字孪生领域公开示例稀缺的问题。

Method: 本研究提出了一个包含物理和数字部分的实验室规模龙门起重机数字孪生系统。物理部分包括实际的起重机和控制器；数字部分则包含CAD模型、运动学模型，并提供优化控制、历史数据记录、数据可视化和持续验证等服务。

Result: 成功构建了一个实验室规模的龙门起重机及其数字孪生系统的公开示例，该系统功能得到验证，并且易于访问和使用，可用于未来的研究和教育。

Conclusion: 该研究提供了一个实验室规模的龙门起重机及其数字孪生系统的公开示例，旨在促进开放和可重复的科学研究。该系统包括物理实体（起重机及其控制器）和数字孪生（CAD模型、运动学模型），并提供优化控制、数据记录、可视化和验证等服务。该系统已在以往的出版物中得到验证，并且是公开可用的，仅依赖于免费软件，希望可以为数字孪生领域未来的研究或教育提供参考。

Abstract: The research topic of digital twins has attracted a large amount of interest
over the past decade. However, publicly available exemplars remain scarce. In
the interest of open and reproducible science, in this exemplar paper we
present a lab-scale gantry crane and its digital twin. The exemplar comprises
both the physical and digital side of the twin system. The physical side
consists of the physical crane and its controller. The digital side covers the
CAD models and kinematic model of the crane, and provides services for optimal
control, historical data logging, data visualization and continuous validation.
We used this setup as use case in several previous publications where its
functionality was validated. It is publicly available and only relies on other
freely available and commonly used software, this way we hope it can be used
for future research or education on the topic of digital twins.

</details>


### [132] [TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting](https://arxiv.org/abs/2507.13586)
*Kaiyuan Tang,Kuangshi Ai,Jun Han,Chaoli Wang*

Main category: cs.GR

TL;DR: TexGS-VolVis是一种新颖的体积可视化框架，它使用具有纹理和阴影属性的2D高斯基元，实现了高质量的风格化和灵活的场景编辑。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有体积可视化方法依赖复杂预定义规则和仅限于单一风格迁移的限制，我们主张使用可微分高斯基元和预训练大模型来表示体积可视化场景，以实现任意风格迁移和实时渲染。然而，传统的3D高斯基元将几何和外观紧密耦合，导致风格化结果不理想。

Method: 提出了一种名为TexGS-VolVis的新框架，该框架使用2D高斯基元，并为每个高斯扩展了额外的纹理和阴影属性，以实现更高质量、几何一致的风格化，并增强推理过程中的光照控制。此外，还开发了针对TexGS-VolVis的图像和文本驱动的非真实感场景编辑以及2D-lift-3D分割，以实现具有细粒度控制的部分编辑。

Result: TexGS-VolVis实现了更高质量、几何一致的风格化，并增强了光照控制。通过图像和文本驱动的编辑，实现了灵活且可控的场景编辑，并能够进行部分编辑和细粒度控制。

Conclusion: TexGS-VolVis在效率、视觉质量和编辑灵活性方面优于现有方法。

Abstract: Advancements in volume visualization (VolVis) focus on extracting insights
from 3D volumetric data by generating visually compelling renderings that
reveal complex internal structures. Existing VolVis approaches have explored
non-photorealistic rendering techniques to enhance the clarity, expressiveness,
and informativeness of visual communication. While effective, these methods
often rely on complex predefined rules and are limited to transferring a single
style, restricting their flexibility. To overcome these limitations, we
advocate the representation of VolVis scenes using differentiable Gaussian
primitives combined with pretrained large models to enable arbitrary style
transfer and real-time rendering. However, conventional 3D Gaussian primitives
tightly couple geometry and appearance, leading to suboptimal stylization
results. To address this, we introduce TexGS-VolVis, a textured Gaussian
splatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,
extending each Gaussian with additional texture and shading attributes,
resulting in higher-quality, geometry-consistent stylization and enhanced
lighting control during inference. Despite these improvements, achieving
flexible and controllable scene editing remains challenging. To further enhance
stylization, we develop image- and text-driven non-photorealistic scene editing
tailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing
with fine-grained control. We evaluate TexGS-VolVis both qualitatively and
quantitatively across various volume rendering scenes, demonstrating its
superiority over existing methods in terms of efficiency, visual quality, and
editing flexibility.

</details>


### [133] [Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading](https://arxiv.org/abs/2507.13917)
*Efstratios Geronikolakis,Manos Kamarianakis,Antonis Protopsaltis,George Papagiannakis*

Main category: cs.GR

TL;DR: Neural-GASh 是一种基于神经辐射场和共形几何代数的新型实时渲染管线，它无需预计算即可为动态和变形的 3D 网格提供高质量、高速度的着色，适用于移动和 VR 等多种平台。


<details>
  <summary>Details</summary>
Motivation: 传统的 PRT 方法需要昂贵的离线预计算，限制了其在动态场景中的应用。本研究旨在提出一种无需预计算即可对动画和变形的 3D 网格进行精确着色的方法，以适应动态、交互式环境的需求，并能在包括移动和 VR 在内的多种平台上实现快速高效的光传输模拟。

Method: 该研究提出了一种名为 Neural-GASh 的新颖实时渲染管线，该管线利用神经辐射场（NeRF）架构，并将共形几何代数（CGA）编码的顶点信息作为输入，以实现基于图像的渲染（IBR）。与传统的 PRT 方法不同，Neural-GASh 无需昂贵的离线预计算，可以直接处理基于 CGA 的顶点位置和法线表示，从而实现动态场景的实时着色。该方法已集成到 Unity 引擎中，并使用 CGA 优化了球谐函数的场景光旋转。

Result: Neural-GASh 能够对动画和变形的 3D 网格进行精确着色，并实现了快速的光传输模拟。与传统的 PRT 方法相比，该方法在渲染速度上具有竞争力，即使处理复杂的几何体也能保持高质量的渲染效果。该方法还展示了在处理 3D 高斯泼溅（3D Gaussian splats）等不同场景下的灵活性和鲁棒性。

Conclusion: Neural-GASh 实现了无需预计算的实时渲染，能够处理动态场景和变形网格，并且在渲染质量和速度上具有竞争力，适用于包括移动和 VR 在内的多种平台。

Abstract: This paper presents Neural-GASh, a novel real-time shading pipeline for 3D
meshes, that leverages a neural radiance field architecture to perform
image-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded
vertex information as input. Unlike traditional Precomputed Radiance Transfer
(PRT) methods, that require expensive offline precomputations, our learned
model directly consumes CGA-based representations of vertex positions and
normals, enabling dynamic scene shading without precomputation. Integrated
seamlessly into the Unity engine, Neural-GASh facilitates accurate shading of
animated and deformed 3D meshes - capabilities essential for dynamic,
interactive environments. The shading of the scene is implemented within Unity,
where rotation of scene lights in terms of Spherical Harmonics is also
performed optimally using CGA. This neural field approach is designed to
deliver fast and efficient light transport simulation across diverse platforms,
including mobile and VR, while preserving high rendering quality. Additionally,
we evaluate our method on scenes generated via 3D Gaussian splats, further
demonstrating the flexibility and robustness of Neural-GASh in diverse
scenarios. Performance is evaluated in comparison to conventional PRT,
demonstrating competitive rendering speeds even with complex geometries.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [134] [Leveraging Multi-Instance GPUs through moldable task scheduling](https://arxiv.org/abs/2507.13601)
*Jorge Villarrubia,Luis Costero,Francisco D. Igual,Katzalin Olcoz*

Main category: cs.DC

TL;DR: NVIDIA MIG技术可以通过可塑性任务调度和动态重配置来优化GPU资源利用率。研究提出的FAR算法通过三阶段方法有效解决了多任务执行的makespan最小化问题，并在实际应用中取得了显著的性能提升，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于发掘NVIDIA MIG（Multi-Instance GPU）技术的潜力，该技术允许将物理GPU划分为多个逻辑实例，并能动态重配置。研究者希望通过可塑性任务调度和动态重配置来最大化MIG的利用率，解决多任务执行下的makespan最小化问题，并探索MIG技术在GPU资源调度领域的研究前景。

Method: 该研究提出了一种名为FAR的三阶段算法来解决在NVIDIA MIG环境下多任务执行的makespan最小化问题。FAR算法首先利用经典的task moldability方法，然后结合Longest Processing Time First和List Scheduling，并引入了针对MIG约束的repartitioning tree启发式方法，最后通过task moves和swaps进行局部搜索。该算法能够处理任务可塑性，并考虑了GPU的动态重构。

Result: FAR算法在NVIDIA A30模型上实现了7/4的近似因子（不考虑重构成本），在NVIDIA A100/H100模型上实现了2的近似因子。实际实验表明，在考虑重构成本的情况下，对于基准测试集，其makespan与最优值的比率不超过1.22倍；对于受真实内核启发的合成输入，该比率不超过1.10倍。FAR算法在批处理和批次连接方面均取得了优于现有技术和不考虑GPU重构的方案的实验结果。

Conclusion: 该研究证明了NVIDIA MIG技术的潜力，并通过提出的FAR算法在GPU资源调度方面取得了显著的改进。FAR算法通过三阶段方法，考虑了任务的可塑性和GPU的动态重构，为多任务执行的makespan最小化问题提供了有效的解决方案，并在实际应用中表现出优于现有技术的性能。

Abstract: NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into
multiple logical instances with fully-isolated resources, which can be
dynamically reconfigured. This work highlights the untapped potential of MIG
through moldable task scheduling with dynamic reconfigurations. Specifically,
we propose a makespan minimization problem for multi-task execution under MIG
constraints. Our profiling shows that assuming monotonicity in task work with
respect to resources is not viable, as is usual in multicore scheduling.
Relying on a state-of-the-art proposal that does not require such an
assumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1
of FAR builds on a classical task moldability method, phase 2 combines Longest
Processing Time First and List Scheduling with a novel repartitioning tree
heuristic tailored to MIG constraints, and phase 3 employs local search via
task moves and swaps. FAR schedules tasks in batches offline, concatenating
their schedules on the fly in an improved way that favors resource reuse.
Excluding reconfiguration costs, the List Scheduling proof shows an
approximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to
the particular constraints of an NVIDIA A100/H100 to obtain an approximation
factor of 2. Including the reconfiguration cost, our real-world experiments
reveal a makespan with respect to the optimum no worse than 1.22x for a
well-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real
kernels. We obtain good experimental results for each batch of tasks, but also
in the concatenation of batches, with large improvements over the
state-of-the-art and proposals without GPU reconfiguration. Beyond the
algorithm, the paper demonstrates the research potential of the MIG technology
and suggests useful metrics, workload characterizations and evaluation
techniques for future work in this field.

</details>


### [135] [Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication](https://arxiv.org/abs/2507.13522)
*Ankit Bhardwaj,Weiyang Wang,Jeremy Carin,Adam Belay,Manya Ghobadi*

Main category: cs.DC

TL;DR: Checkmate enables efficient per-iteration checkpointing in DNN training by using gradients and a shadow cluster, eliminating training slowdown and reducing failure-related work.


<details>
  <summary>Details</summary>
Motivation: Traditional checkpointing methods create a tradeoff between checkpoint frequency and failure cost. This paper aims to eliminate this tradeoff by enabling per-iteration checkpointing without any training slowdown.

Method: Checkmate utilizes a new multicast abstraction to deliver gradients to a separate CPU-based shadow cluster, which applies these gradients to a model copy to create checkpoints, thereby avoiding the traditional checkpointing pause.

Result: Checkmate achieves per-iteration checkpointing with throughput comparable to a no-checkpoint baseline. It offers 5 to 34.5x more frequent checkpointing than existing systems, reducing repeated work by 80% to 97.1%. Additionally, it provides 1.3x to 6.5x higher throughput at the same checkpointing frequency.

Conclusion: Checkmate achieves per-iteration checkpointing without training slowdown, outperforming state-of-the-art systems in checkpointing frequency and throughput, leading to significant reductions in repeated work per failure.

Abstract: This paper presents Checkmate, a system that enables per-iteration
checkpointing in DNN training without any training slowdown. The traditional
approach to checkpointing requires a pause in training to copy model states to
a separate location, allowing the state to be restored in the event of failure.
This approach fundamentally has a tradeoff between the frequency of checkpoints
and the cost of a failure. We avoid this tradeoff; our key insight is that in
data-parallel training, all information necessary to create a checkpoint
already exists in the network as gradients. Our core contribution is a new
multicast abstraction that simultaneously delivers gradients to a separate
CPU-based shadow cluster. The shadow maintains a checkpoint by applying those
gradients to a copy of the model. Our evaluation shows that Checkmate performs
per-iteration checkpointing with training throughput comparable to an ideal
no-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent
checkpointing compared to state-of-the-art checkpointing systems, resulting in
80% to 97.1% reduction in repeated work per failure. At the same checkpointing
frequency, Checkmate delivers 1.3x to 6.5x throughput compared to other
systems.

</details>


### [136] [Edge Intelligence with Spiking Neural Networks](https://arxiv.org/abs/2507.14069)
*Shuiguang Deng,Di Yu,Changze Lv,Xin Du,Linshan Jiang,Xiaofan Zhao,Wentao Tong,Xiaoqing Zheng,Weijia Fang,Peng Zhao,Gang Pan,Schahram Dustdar,Albert Y. Zomaya*

Main category: cs.DC

TL;DR: 本综述全面概述了基于脉冲神经网络（SNNs）的边缘智能（EdgeSNNs），探讨了其在资源受限设备上的应用潜力、面临的挑战以及未来的研究方向，并提出了一种新的基准测试策略。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在资源受限设备上的应用存在延迟、带宽消耗和隐私问题。脑启发计算（尤其是脉冲神经网络SNNs）通过模拟生物神经元动力学来实现低功耗、事件驱动的计算，为解决这些问题提供了有前景的替代方案。

Method: 本篇论文对基于SNN的边缘智能（EdgeSNNs）进行了全面的概述，考察了它们在解决边缘场景中的设备上学习、推理和安全性方面的潜力。论文系统地分类了EdgeSNNs的基础，包括神经元模型、学习算法和支持的硬件平台。深入讨论了三种代表性的EdgeSNN实际考量：使用轻量级SNN模型进行设备上推理、在非平稳数据条件下进行资源感知训练和更新，以及安全和隐私保护问题。此外，本文还强调了在传统硬件上评估EdgeSNNs的局限性，并引入了双轨基准测试策略以支持公平比较和硬件感知优化。

Result: 论文提供了EdgeSNNs的系统分类，深入讨论了设备上推理、资源感知训练和更新以及安全隐私保护等实际问题，并提出了一种双轨基准测试策略以支持公平比较和硬件感知优化。

Conclusion: 本篇论文旨在弥合受脑启发学习与实际边缘部署之间的差距，并为神经形态计算和边缘智能交叉领域的研究人员和从业者提供重要的参考。

Abstract: The convergence of artificial intelligence and edge computing has spurred
growing interest in enabling intelligent services directly on
resource-constrained devices. While traditional deep learning models require
significant computational resources and centralized data management, the
resulting latency, bandwidth consumption, and privacy concerns have exposed
critical limitations in cloud-centric paradigms. Brain-inspired computing,
particularly Spiking Neural Networks (SNNs), offers a promising alternative by
emulating biological neuronal dynamics to achieve low-power, event-driven
computation. This survey provides a comprehensive overview of Edge Intelligence
based on SNNs (EdgeSNNs), examining their potential to address the challenges
of on-device learning, inference, and security in edge scenarios. We present a
systematic taxonomy of EdgeSNN foundations, encompassing neuron models,
learning algorithms, and supporting hardware platforms. Three representative
practical considerations of EdgeSNN are discussed in depth: on-device inference
using lightweight SNN models, resource-aware training and updating under
non-stationary data conditions, and secure and privacy-preserving issues.
Furthermore, we highlight the limitations of evaluating EdgeSNNs on
conventional hardware and introduce a dual-track benchmarking strategy to
support fair comparisons and hardware-aware optimization. Through this study,
we aim to bridge the gap between brain-inspired learning and practical edge
deployment, offering insights into current advancements, open challenges, and
future research directions. To the best of our knowledge, this is the first
dedicated and comprehensive survey on EdgeSNNs, providing an essential
reference for researchers and practitioners working at the intersection of
neuromorphic computing and edge intelligence.

</details>


### [137] [DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training](https://arxiv.org/abs/2507.13833)
*Zhixin Wang,Tianyi Zhou,Liming Liu,Ao Li,Jiarui Hu,Dian Yang,Jinlong Hou,Siyuan Feng,Yuan Cheng,Yuan Qi*

Main category: cs.DC

TL;DR: DistFlow is a distributed RL framework that improves LLM reasoning and safety by enabling scalable reinforcement learning, outperforming SOTA frameworks in throughput and scalability.


<details>
  <summary>Details</summary>
Motivation: The key to unlocking advanced reasoning capabilities and ensuring safe, goal-aligned behavior in powerful LLMs is scaling reinforcement learning. Minor load imbalances in mainstream hybrid-controller architectures constrain the scalability of the system.

Method: DistFlow, a novel, fully distributed RL framework that adopts a multi-controller paradigm dispatching data transfer and execution tasks to all workers, eliminating the centralized node and allowing each worker to operate independently. It decouples resource configuration from execution logic, allowing unique execution flows per worker.

Result: DistFlow achieves near-linear scalability up to thousands of GPUs and dramatic efficiency gains, with up to a 7x end-to-end throughput improvement over SOTA frameworks.

Conclusion: DistFlow achieved excellent linear scalability and up to a 7x end-to-end throughput improvement over SOTA frameworks.

Abstract: Reinforcement learning (RL) has become the pivotal post-training technique
for large language model. Effectively scaling reinforcement learning is now the
key to unlocking advanced reasoning capabilities and ensuring safe,
goal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually
employ a hybrid-controller architecture where a single-controller dispatches
the overall execution logic and manages overall data transfer and the
multi-controller executes distributed computation. For large-scale
reinforcement learning, minor load imbalances can introduce significant
bottlenecks, ultimately constraining the scalability of the system. To address
this limitation, we introduce DistFlow, a novel, fully distributed RL framework
designed to break scaling barrier. We adopt a multi-controller paradigm that
dispatches data transfer and execution tasks to all workers, which eliminates
the centralized node. This allows each worker to operate independently, leading
to near-linear scalability up to thousands of GPUs and dramatic efficiency
gains. Furthermore, our architecture decouples resource configuration from
execution logic, allowing each worker to have a unique execution flow, offering
significant flexibility for rapid and cost-effective algorithmic
experimentation. Extensive experiments show that DistFlow achieves excellent
linear scalability and up to a 7x end-to-end throughput improvement over
state-of-the-art (SOTA) frameworks.

</details>


### [138] [Shipwright: Proving liveness of distributed systems with Byzantine participants](https://arxiv.org/abs/2507.14080)
*Derek Leung,Nickolai Zeldovich,Frans Kaashoek*

Main category: cs.DC

TL;DR: Shipwright verifies liveness in PBFT despite malicious participants, enabling modular design and cryptographic reasoning. It was used to verify a PBFT prototype, proving its liveness in experiments.


<details>
  <summary>Details</summary>
Motivation: Ensuring liveness in decentralized systems like PBFT is critical due to the absence of a single administrator to restart the system in case of bugs, and it is challenging because individual participants can be malicious while the system must still progress. Prior work has not been able to verify liveness for executable PBFT implementations.

Method: Shipwright is a verification framework that introduces three techniques: enabling formal reasoning about decentralized settings with malicious participants, allowing modular decomposition of systems and proofs into sub-protocols and sub-proofs, and supporting sound reasoning about cryptographic signatures embedded in messages.

Result: Shipwright was used to implement and verify a prototype of PBFT's single log entry agreement, demonstrating its operation and liveness experimentally in both common and failure scenarios.

Conclusion: Shipwright successfully implemented and verified an initial prototype of agreement on a single log entry in PBFT, translating it to an executable implementation in Go, and experimentally demonstrating its operation and liveness in common and failure scenarios.

Abstract: Ensuring liveness in a decentralized system, such as PBFT, is critical,
because there may not be any single administrator that can restart the system
if it encounters a liveness bug. At the same time, liveness is challenging to
achieve because any single participant could be malicious, and yet the overall
system must make forward progress. While verification is a promising approach
for ensuring the absence of bugs, no prior work has been able to verify
liveness for an executable implementation of PBFT.
  Shipwright is a verification framework for proving correctness and liveness
of distributed systems where some participants might be malicious. Shipwright
introduces three techniques that enable formal reasoning about decentralized
settings with malicious participants, allow developers to decompose their
system and proof in a modular fashion into sub-protocols and sub-proofs, and
support sound reasoning about cryptographic signatures that may be embedded in
messages. We used Shipwright to implement and verify an initial prototype of
agreement on a single log entry in PBFT (with a few limitations) and translate
it to an executable implementation in Go. We experimentally demonstrate its
operation and liveness both in the common case and in several failure
scenarios.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [139] [Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication](https://arxiv.org/abs/2507.13470)
*Michael Elkin,Chhaya Trehan*

Main category: cs.DS

TL;DR: 本文改进了 S × V 可达性问题的算法性能，尤其是在具有小递归分离器和界限树宽的图上。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决 S × V 可达性问题，并改进现有算法在并行计算和分布式计算中的性能。

Method: 本文提出了一种新的分布式算法，利用 Kogan 和 Parter 的快捷构造，实现了比现有算法更优的运行时间。该算法适用于具有小递归分离器的图，并推广到具有界限树宽的图。

Result: 本文提出了一种新的分布式算法，在特定参数范围内优于现有算法。对于具有界限树宽的图，也提供了优于现有算法的中心化算法。

Conclusion: 本文提出了一种新的分布式算法，用于解决 S × V 可达性问题。该算法在具有小递归分离器的图上实现了比现有算法更低的并行时间复杂度，并将其推广到具有界限树宽的图。此外，还扩展到近似距离计算。

Abstract: Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \subseteq V$
of $|S| = n^{\sigma}$ (for some $0 \le \sigma \le 1$) designated sources, the
$S \times V$ reachability problem is to compute the sets $\mathcal V_s$ of
vertices reachable from $s$, for every $s \in S$. Naive centralized algorithms
run BFS/DFS from each source in $O(m \cdot n^{\sigma})$ time or compute $G$'s
transitive closure in $\hat O(n^{\omega})$ time, where $\omega \le
2.371552\ldots$ is the matrix multiplication exponent. Thus, the best known
bound is $\hat O(n^{\min \{ 2 + \sigma, \omega\}})$. Leveraging shortcut
constructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a
centralized algorithm with running time $\hat O(n^{1 + \frac{2}{3}
\omega(\sigma)})$, where $\omega(\sigma)$ is the rectangular matrix
multiplication exponent. Using current estimates on $\omega(\sigma)$, our
exponent improves upon $\min \{2 + \sigma, \omega \}$ for $\tilde \sigma \leq
\sigma \leq 0.53$, where $1/3 < \tilde \sigma < 0.3336$ is a universal
constant.
  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel
algorithms for $S \times V$ reachability on graphs admitting balanced recursive
separators of size $n^{\rho}$ for $\rho < 1$, requiring polylogarithmic time
and work $n^{\max \{\omega \rho, 2\rho + \sigma \} + o(1)}$. We significantly
improve, extend, and generalize Cohen's result. First, our parallel algorithm
for graphs with small recursive separators has lower work complexity than
Cohen's in boraod paramater ranges. Second, we generalize our algorithm to
graphs of treewidth at most $n^{\rho}$ ($\rho < 1$) and provide a centralized
algorithm that outperforms existing bounds for $S \times V$ reachability on
such graphs. We also do this for some other graph familes with small
separators. Finally, we extend these results to $(1 + \epsilon)$-approximate
distance computation.

</details>


### [140] [Strassen $2\times2$ Matrix Multiplication from a 3-dimensional Volume Form](https://arxiv.org/abs/2507.13510)
*Benoit Jacob*

Main category: cs.DS

TL;DR: Strassen's $2\times2$ matrix multiplication algorithm comes from the volume form of a specific quotient space of matrices.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand the origins of the Strassen $2\times2$ matrix multiplication algorithm through the lens of linear algebra and geometric concepts.

Method: The method involves analyzing the volume form on the 3-dimensional quotient space of $2\times2$ matrices.

Result: The result is the derivation of the Strassen $2\times2$ matrix multiplication algorithm from the specified mathematical structure.

Conclusion: The Strassen $2\times2$ matrix multiplication algorithm is derived from the volume form on the 3-dimensional quotient space of $2\times2$ matrices by multiples of the identity.

Abstract: The Strassen $2\times2$ matrix multiplication algorithm arises from the
volume form on the 3-dimensional quotient space of the $2\times 2$ matrices by
the multiples of identity.

</details>


### [141] [Combinatorics of Palindromes](https://arxiv.org/abs/2507.13671)
*Michael Itzhaki*

Main category: cs.DS

TL;DR: Manacher 数组的结构和重建复杂度被研究。证明了根串联重复树的数量超过了 Manacher 数组的数量。引入了一个图论框架，并将 Manacher 数组与图相关联。分析了一种重建算法，证明其具有最小字母表大小和对数数量的符号，并可适应任意字母表。这些结果解决了该领域的一个公开问题。


<details>
  <summary>Details</summary>
Motivation: 研究 Manacher 数组的结构和重建复杂度。

Method: 1. 组合下界证明：证明具有 n+1 个基因的根串联重复树的数量超过了长度为 n 的不同 Manacher 数组的数量。
2. 图论框架：将图与每个 Manacher 数组相关联，其中每个顶点着色都会产生一个与数组一致的字符串。
3. 重建算法分析：分析 I et al. (SPIRE 2010) 的重建算法，证明其实现了全局最小字母表大小，使用了不超过 log_2(n-1) + 2 个不同的符号，并可适应在可能的情况下在任意字母表上进行重建。

Result: 1. 组合下界：具有 n+1 个基因的根串联重复树的数量大于长度为 n 的 Manacher 数组的数量。
2. 图论框架：为 Manacher 数组创建了一个关联图，其顶点着色可产生一致的字符串。
3. 重建算法：I et al. (SPIRE 2010) 的算法实现了最小字母表大小，使用了对数数量的符号，并且可以适应任意字母表。

Conclusion: Manacher 数组的组合理解和结构约束下的字符串重建新方向。

Abstract: We investigate the structure and reconstruction complexity of Manacher
arrays. First, we establish a combinatorial lower bound, proving that the
number of rooted tandem repeat trees with $n+1$ genes exceeds the number of
distinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic
framework that associates a graph to each Manacher array, where every proper
vertex coloring yields a string consistent with the array. Finally, we analyze
a reconstruction algorithm by I et al. (SPIRE 2010), showing that it
simultaneously achieves a globally minimal alphabet size, uses at most
$\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce
reconstructions over arbitrary alphabets when possible. Our results also
resolve an open problem posed by the original authors. Together, these findings
advance the combinatorial understanding of Manacher arrays and open new
directions for string reconstruction under structural constraints.

</details>


### [142] [Tight Bounds for Answering Adaptively Chosen Concentrated Queries](https://arxiv.org/abs/2507.13700)
*Emma Rapoport,Edith Cohen,Uri Stemmer*

Main category: cs.DS

TL;DR: 在自适应数据分析中，即使有浓缩查询的限制，查询数量也比独立样本情况少得多。本研究证明了这种差距是固有的，并提供了一个匹配该上限的简化算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据集中样本相关时，即使在非适应性设置下，如果没有结构性约束也会变得难以处理的问题。

Method: 提出了匹配该（查询数量限制）奠基性结果的简化算法。

Result: 证明了在浓缩查询框架的当前表述下，查询数量的限制是固有的。

Conclusion: 该研究证明了在浓缩查询框架的当前表述下，在一些自然条件下，查询数量的限制是固有的，并提出了一种匹配该限制的简化算法。

Abstract: Most work on adaptive data analysis assumes that samples in the dataset are
independent. When correlations are allowed, even the non-adaptive setting can
become intractable, unless some structural constraints are imposed. To address
this, Bassily and Freund [2016] introduced the elegant framework of
concentrated queries, which requires the analyst to restrict itself to queries
that are concentrated around their expected value. While this assumption makes
the problem trivial in the non-adaptive setting, in the adaptive setting it
remains quite challenging. In fact, all known algorithms in this framework
support significantly fewer queries than in the independent case: At most
$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the
independent setting.
  In this work, we prove that this utility gap is inherent under the current
formulation of the concentrated queries framework, assuming some natural
conditions on the algorithm. Additionally, we present a simplified version of
the best-known algorithms that match our impossibility result.

</details>


### [143] [Improved girth approximation in weighted undirected graphs](https://arxiv.org/abs/2507.13869)
*Avi Kadria,Liam Roditty,Aaron Sidford,Virginia Vassilevska Williams,Uri Zwick*

Main category: cs.DS

TL;DR: 提出了一种新的图算法，可以在O(kn^(1+1/k)log n + m(k+log n))的期望时间内找到长度不超过4k/3 * g的环，改进了加权和未加权图的现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了在加权图中找到比现有算法更短的环，特别是当 k=1 时，改进 Roditty 和 Tov 的结果。

Method: 提出了一种新的图算法，能够找到长度不超过 4k/3 * g 的环。

Result: 该算法在 O(kn^(1+1/k)log n + m(k+log n)) 的期望时间内，找到长度不超过 4k/3 * g 的环，优于之前加权图和未加权图（特别是在 k=1 时）的最优算法。

Conclusion: 该算法对于任意输入、整数k ≥ 1，能在 O(kn^(1+1/k)log n + m(k+log n)) 的期望时间内找到长度不超过 4k/3 * g 的环，在加权图方面优于现有技术。

Abstract: Let $G = (V,E,\ell)$ be a $n$-node $m$-edge weighted undirected graph, where
$\ell: E \rightarrow (0,\infty)$ is a real \emph{length} function defined on
its edges, and let $g$ denote the girth of $G$, i.e., the length of its
shortest cycle. We present an algorithm that, for any input, integer $k \geq
1$, in $O(kn^{1+1/k}\log{n} + m(k+\log{n}))$ expected time finds a cycle of
length at most $\frac{4k}{3}g$. This algorithm nearly matches a
$O(n^{1+1/k}\log{n})$-time algorithm of \cite{KadriaRSWZ22} which applied to
unweighted graphs of girth $3$. For weighted graphs, this result also improves
upon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\log n+m)\log
(nM))$ time, where $\ell: E \rightarrow [1, M]$ is an integral length function,
finds a cycle of length at most $2kg$~\cite{KadriaRSWZ22}. For $k=1$ this
result improves upon the result of Roditty and Tov~\cite{RodittyT13}.

</details>


### [144] [Quantum Pattern Matching with Wildcards](https://arxiv.org/abs/2507.13885)
*Masoud Seddighin,Saeed Seddighin*

Main category: cs.DS

TL;DR: 该研究提出了一种新的量子算法，能够以亚线性时间复杂度解决带有通配符的模式匹配问题，前提是通配符的数量也是亚线性的。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决带有通配符的模式匹配问题，并探究其是否能像经典模式匹配问题一样，在亚线性时间复杂度内解决。特别是，研究者受到了 Ramesh 和 Vinay 在 2000 年提出的经典模式匹配量子算法的启发。

Method: 本文提出的量子算法，其运行时间复杂度为 O(sqrt(n) * sqrt(k))，其中 n 是输入字符串的长度，k 是通配符的数量。该算法适用于 k >= sqrt(n) 的情况。

Result: 本文提出了一个量子算法，在通配符数量 k 被限制在 k >= sqrt(n) 的情况下，能够以 O(sqrt(n) * sqrt(k)) 的时间复杂度解决带有通配符的模式匹配问题。当通配符数量 k 为亚线性时，该算法的运行时间也为亚线性。

Conclusion: 本文提出了一个量子算法，用于解决带有通配符的模式匹配问题，其运行时间为 O(sqrt(n) * sqrt(k))，其中 k 是通配符的数量，当 k >= sqrt(n) 时。这使得在通配符数量为亚线性时，算法的运行时间为亚线性。

Abstract: Pattern matching is one of the fundamental problems in Computer Science. Both
the classic version of the problem as well as the more sophisticated version
where wildcards can also appear in the input can be solved in almost linear
time $\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform,
respectively. In 2000, Ramesh and Vinay~\cite{ramesh2003string} give a quantum
algorithm that solves classic pattern matching in sublinear time and asked
whether the wildcard problem can also be solved in sublinear time? In this
work, we give a quantum algorithm for pattern matching with wildcards that runs
in time $\tilde O(\sqrt{n}\sqrt{k})$ when the number of wildcards is bounded by
$k$ for $k \geq \sqrt{n}$. This leads to an algorithm that runs in sublinear
time as long as the number of wildcards is sublinear.

</details>


### [145] [Optimal antimatroid sorting](https://arxiv.org/abs/2507.13994)
*Benjamin Aram Berendsohn*

Main category: cs.DS

TL;DR: 本研究将拓扑堆排序推广到基于抗拟合 सम 的排序问题，并为多种受限排序问题提供了最优算法。


<details>
  <summary>Details</summary>
Motivation: 研究受限排序问题，特别是当可能的全序集合 T 以压缩形式给出时，并寻找最优算法。

Method: 提出了一种拓扑堆排序的简单推广方法，并将其应用于多种受限排序问题。

Result: 为受限排序问题（包括由单调优先公式、弦图的完美消除序或连通根图的可能顶点搜索序限制的全序）提供了最优算法。 T 对应于给定的抗拟合 सम。 此外，该方法还适用于由单调优先公式、弦图的完美消除序或连通根图的可能顶点搜索序限制的全序。  与现有算法相比，该方法具有更广泛的适用性，并能在特定情况下实现最优运行时间。

Conclusion: 本研究将拓扑堆排序的简单推广应用于更广泛的受限排序问题，其中 T 对应于给定的抗拟合 सम，从而为一系列受限排序问题提供了最优算法。

Abstract: The classical comparison-based sorting problem asks us to find the underlying
total order of a given set of elements, where we can only access the elements
via comparisons. In this paper, we study a restricted version, where, as a
hint, a set $T$ of possible total orders is given, usually in some compressed
form.
  Recently, an algorithm called topological heapsort with optimal running time
was found for the case where $T$ is the set of topological orderings of a given
directed acyclic graph, or, equivalently, $T$ is the set of linear extensions
of a given partial order [Haeupler et al. 2024]. We show that a simple
generalization of topological heapsort is applicable to a much broader class of
restricted sorting problems, where $T$ corresponds to a given antimatroid.
  As a consequence, we obtain optimal algorithms for the following restricted
sorting problems, where the allowed total orders are restricted by: a given set
of monotone precedence formulas; the perfect elimination orders of a given
chordal graph; or the possible vertex search orders of a given connected rooted
graph.

</details>


### [146] [Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and Hardness](https://arxiv.org/abs/2507.14060)
*Sanjeev Khanna,Ashwin Padaki,Erik Waingarten*

Main category: cs.DS

TL;DR: 本文研究了构建稀疏可导航图的近似算法和计算下界，将其与集合覆盖问题联系起来，提出了多种近似算法，并证明了某些算法的近似比和时间复杂度已接近最优。


<details>
  <summary>Details</summary>
Motivation: 最近在图基础的最近邻搜索（nearest neighbor search）领域取得了进展，而稀疏可导航图是这些进展的核心基础。因此，研究稀疏可导航图的构建方法，包括其近似算法和计算障碍，具有重要的理论和实践意义。研究目标是找到尽可能稀疏（优化最大出度和总边数）且满足可导航性条件的图。

Method: 本文采用了近似算法和计算复杂性理论的方法。具体来说，研究了稀疏可导航图的构建问题，并将其与集合覆盖问题联系起来，利用集合覆盖的已知近似算法和理论来指导稀疏可导航图算法的设计。同时，利用矩阵乘法等技术来加速算法。最后，通过分析查询过程来建立下界。

Result: 1. DiskANN 的预处理版本在稀疏性上存在 $\widetilde{\Omega}(n)$ 的近似比。2. 稀疏可导航图问题与集合覆盖问题等价，存在 $O(n^3)$ 时间的 $(\ln n + 1)$-近似算法，且 $o(\ln n)$-近似是 NP-hard 的。3. 提出了 $\widetilde{O}(n \cdot \mathrm{OPT})$ 时间的 $O(\ln n)$-近似算法和 $\widetilde{O}(n^{\omega})$ 时间的双标准算法。4. 存在查询复杂度下界 $\Omega(n^2)$，表明对于 $\mathrm{OPT} = \widetilde{O}(n)$ 的情况，$\widetilde{O}(n \cdot \mathrm{OPT})$ 时间算法接近最优。

Conclusion: 本文研究了构建稀疏 α-可导航图（sparse α-navigable graphs）的近似算法和计算障碍。文章的主要贡献包括：1. 证明了 DiskANN 的预处理版本在稀疏性方面存在显著的近似比（可能达到最优解的 $\widetilde{\Omega}(n)$ 倍）。2. 建立了稀疏可导航图问题与经典集合覆盖问题之间的近似保持等价性，提出了一个 $O(n^3)$ 时间的 $(\ln n + 1)$-近似算法，并证明了获得 $o(\ln n)$-近似是 NP-hard 的。3. 基于此等价性，开发了更快的 $O(\ln n)$-近似算法，其中一个算法能在 $\widetilde{O}(n \cdot \mathrm{OPT})$ 时间内完成，当最优解稀疏时效率很高。另一个算法利用了快速矩阵乘法，是一个双标准算法，能在 $\widetilde{O}(n^{\omega})$ 时间内计算出 $O(\ln n)$-近似的 $2\alpha$-可导航图。4. 提出了一个查询复杂度下界，表明任何 $o(n)$-近似算法都需要检查 $\Omega(n^2)$ 的距离，这表明在 $\mathrm{OPT} = \widetilde{O}(n)$ 的情况下，$\widetilde{O}(n \cdot \mathrm{OPT})$ 时间的算法已接近最优。

Abstract: We initiate the study of approximation algorithms and computational barriers
for constructing sparse $\alpha$-navigable graphs [IX23, DGM+24], a core
primitive underlying recent advances in graph-based nearest neighbor search.
Given an $n$-point dataset $P$ with an associated metric $\mathsf{d}$ and a
parameter $\alpha \geq 1$, the goal is to efficiently build the sparsest graph
$G=(P, E)$ that is $\alpha$-navigable: for every distinct $s, t \in P$, there
exists an edge $(s, u) \in E$ with $\mathsf{d}(u, t) < \mathsf{d}(s,
t)/\alpha$. We consider two natural sparsity objectives: minimizing the maximum
out-degree and minimizing the total size.
  We first show a strong negative result: the slow-preprocessing version of
DiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose
sparsity is $\widetilde{\Omega}(n)$ times larger than optimal, even on
Euclidean instances. We then show a tight approximation-preserving equivalence
between the Sparsest Navigable Graph problem and the classic Set Cover problem,
obtaining an $O(n^3)$-time $(\ln n + 1)$-approximation algorithm, as well as
establishing NP-hardness of achieving an $o(\ln n)$-approximation. Building on
this equivalence, we develop faster $O(\ln n)$-approximation algorithms. The
first runs in $\widetilde{O}(n \cdot \mathrm{OPT})$ time and is thus much
faster when the optimal solution is sparse. The second, based on fast matrix
multiplication, is a bicriteria algorithm that computes an $O(\ln
n)$-approximation to the sparsest $2\alpha$-navigable graph, running in
$\widetilde{O}(n^{\omega})$ time.
  Finally, we complement our upper bounds with a query complexity lower bound,
showing that any $o(n)$-approximation requires examining $\Omega(n^2)$
distances. This result shows that in the regime where $\mathrm{OPT} =
\widetilde{O}(n)$, our $\widetilde{O}(n \cdot \mathrm{OPT})$-time algorithm is
essentially best possible.

</details>


### [147] [An Efficient Massively Parallel Constant-Factor Approximation Algorithm for the $k$-Means Problem](https://arxiv.org/abs/2507.14089)
*Vincent Cohen-Addad,Fabian Kuhn,Zahra Parsaeian*

Main category: cs.DS

TL;DR: 本文提出了一种新的MPC算法，用于解决k-means问题，该算法能在更少的轮次（o(log n)）内实现常数因子近似，同时保持可控的内存使用量。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决k-means问题，并提出一种比现有方法更高效的MPC算法，以实现更少的计算轮数。

Method: 本文提出了一种高效的大规模并行近似算法来解决k-means问题。该算法利用MPC模型，在O(log log n * log log log n)轮内计算出任意k-means实例的常数因子近似值。算法在每台机器上使用O(n^σ)比特的内存，其中σ>0是一个常数，可以任意小。全局内存使用量为O(n^(1+ε))比特，其中ε>0是一个任意小的常数，因此内存使用量仅略超线性。

Result: 本文提出了一种MPC算法，能够在O(log log n * log log log n)轮内计算k-means问题的常数因子近似值，并且内存使用量仅略超线性。

Conclusion: 该算法是第一个在MPC模型中实现o(log n)轮的k-means问题常数因子近似算法。

Abstract: In this paper, we present an efficient massively parallel approximation
algorithm for the $k$-means problem. Specifically, we provide an MPC algorithm
that computes a constant-factor approximation to an arbitrary $k$-means
instance in $O(\log\log n \cdot \log\log\log n)$ rounds. The algorithm uses
$O(n^\sigma)$ bits of memory per machine, where $\sigma > 0$ is a constant that
can be made arbitrarily small. The global memory usage is
$O(n^{1+\varepsilon})$ bits for an arbitrarily small constant $\varepsilon >
0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang,
Krauthgamer, and Vesel\'{y} showed that a constant-factor bicriteria
approximation can be computed in $O(1)$ rounds in the MPC model. However, our
algorithm is the first constant-factor approximation for the general $k$-means
problem that runs in $o(\log n)$ rounds in the MPC model.
  Our approach builds upon the foundational framework of Jain and Vazirani. The
core component of our algorithm is a constant-factor approximation for the
related facility location problem. While such an approximation was already
achieved in constant time in the work of Czumaj et al.\ mentioned above, our
version additionally satisfies the so-called Lagrangian Multiplier Preserving
(LMP) property. This property enables the transformation of a facility location
approximation into a comparably good $k$-means approximation.

</details>


### [148] [Weighted Matching in a Poly-Streaming Model](https://arxiv.org/abs/2507.14114)
*Ahammed Ullah,S. M. Ferdous,Alex Pothen*

Main category: cs.DS

TL;DR: 该研究提出了一种用于大规模图匹配的poly-streaming模型和算法，该算法在并行处理和内存效率方面表现出色，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在流式计算模型中，处理大规模数据集通常需要多次遍历，这会影响效率。该研究旨在扩展流式计算模型，以支持多处理器并行处理多个数据流，从而提高处理大规模图匹配问题的效率。

Method: 文章介绍了一种称为“poly-streaming”的计算模型，这是流式计算模型的泛化，其中k个处理器处理k个数据流，包含N个项。该算法允许使用O(f(k)·M1)的空间，其中M1可以是o(N)或顺序流算法的空间界限。处理器可以根据需要进行通信。算法通过评估其通过的次数、每项处理时间、总运行时间、空间使用量、通信成本和解的质量来评估。文章设计了一种单通道算法，用于近似最大加权匹配（MWM）问题。该算法使用k条边流和参数ε>0，可以计算出(2+ε)近似MWM。

Result: 该算法在有向图上实现了近似最大加权匹配，并对通信成本和整体性能进行了分析。在共享内存并行设置中，对于任何恒定的ε>0，该算法的运行时间为Õ(Lmax+n)，其中n是顶点的数量，Lmax是最大流的长度。它支持Õ(k⋅n)的空间和O(1)的每边处理时间。此外，该算法可推广到分层架构，保持了所有其他性能保证。在具有数万亿条边的图上对该算法的评估表明，随着k的增加，运行时间显著缩短，内存使用量大幅减少，并且得到的匹配权重远超理论保证。

Conclusion: 该算法在有向图上实现了近似最大加权匹配，并对通信成本和整体性能进行了分析。在共享内存并行设置中，对于任何恒定的ε>0，该算法的运行时间为Õ(Lmax+n)，其中n是顶点的数量，Lmax是最大流的长度。它支持Õ(k⋅n)的空间和O(1)的每边处理时间。此外，该算法可推广到分层架构，保持了所有其他性能保证。在具有数万亿条边的图上对该算法的评估表明，随着k的增加，运行时间显著缩短，内存使用量大幅减少，并且得到的匹配权重远超理论保证。

Abstract: We introduce the poly-streaming model, a generalization of streaming models
of computation in which $k$ processors process $k$ data streams containing a
total of $N$ items. The algorithm is allowed $O\left(f(k)\cdot M_1\right)$
space, where $M_1$ is either $o\left(N\right)$ or the space bound for a
sequential streaming algorithm. Processors may communicate as needed.
Algorithms are assessed by the number of passes, per-item processing time,
total runtime, space usage, communication cost, and solution quality.
  We design a single-pass algorithm in this model for approximating the maximum
weight matching (MWM) problem. Given $k$ edge streams and a parameter
$\varepsilon > 0$, the algorithm computes a
$\left(2+\epsilon\right)$-approximate MWM. We analyze its performance in a
shared-memory parallel setting: for any constant $\varepsilon > 0$, it runs in
time $\widetilde{O}\left(L_{\max}+n\right)$, where $n$ is the number of
vertices and $L_{\max}$ is the maximum stream length. It supports
$O\left(1\right)$ per-edge processing time using $\widetilde{O}\left(k\cdot
n\right)$ space. We further generalize the design to hierarchical
architectures, in which $k$ processors are partitioned into $r$ groups, each
with its own shared local memory. The total intergroup communication is
$\widetilde{O}\left(r \cdot n\right)$ bits, while all other performance
guarantees are preserved.
  We evaluate the algorithm on a shared-memory system using graphs with
trillions of edges. It achieves substantial speedups as $k$ increases and
produces matchings with weights significantly exceeding the theoretical
guarantee. On our largest test graph, it reduces runtime by nearly two orders
of magnitude and memory usage by five orders of magnitude compared to an
offline algorithm.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 本文将Transformer大语言模型视为量子系统，从物理角度进行建模。


<details>
  <summary>Details</summary>
Motivation: 填补在理论理解上，特别是从物理角度理解Transformer模型及其工作原理的空白。

Method: 将Transformer大语言模型构建为Fock空间上的物理模型，并将其视为开放量子系统。

Result: 文章从物理角度提供了Transformer大语言模型的底层模型。

Conclusion: 文章从物理角度构建了基于Transformer大语言模型的量子力学模型，并将其视为开放量子系统。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


### [150] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 本研究提出了一种“多元化对齐”方法，并创建了DIVE数据集，以解决当前文本到图像模型未能充分考虑人类多样化经验的问题。研究证明了人口统计学信息对于理解和解决模型中的偏见至关重要，并为构建更公平、更对齐的T2I系统提供了指导。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到图像（T2I）模型未能充分考虑人类经验的多样性，导致系统失准。因此，需要一种能够理解并可控于多样化、甚至相互冲突的人类价值观的“多元化对齐”方法。

Method: 提出了一种名为“多元化对齐”的方法，并构建了DIVE（Diverse Intersectional Visual Evaluation）数据集，这是一个包含1000个提示和大量人口统计学背景的人类评估者反馈的多模态数据集，用于评估T2I模型在不同安全观念下的表现。

Result: 研究结果证实了人口统计学在T2I模型对齐中的重要性，发现不同人口统计学群体对危害的感知存在显著且依赖于上下文的差异，这与传统的评估方法不同。此外，研究还讨论了在高效数据收集、语言模型判断能力以及模型可控性以适应不同观点方面的潜在影响。

Conclusion: 本研究为构建更公平、更对齐的文本到图像（T2I）系统提供了基础工具，并通过DIVE数据集、对人口统计学作为多样化观点的代理的实证检验以及对齐T2I模型的讨论，为实现T2I模型中的多元化对齐做出了贡献。

Abstract: Current text-to-image (T2I) models often fail to account for diverse human
experiences, leading to misaligned systems. We advocate for pluralistic
alignment, where an AI understands and is steerable towards diverse, and often
conflicting, human values. Our work provides three core contributions to
achieve this in T2I models. First, we introduce a novel dataset for Diverse
Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for
pluralistic alignment. It enable deep alignment to diverse safety perspectives
through a large pool of demographically intersectional human raters who
provided extensive feedback across 1000 prompts, with high replication,
capturing nuanced safety perceptions. Second, we empirically confirm
demographics as a crucial proxy for diverse viewpoints in this domain,
revealing significant, context-dependent differences in harm perception that
diverge from conventional evaluations. Finally, we discuss implications for
building aligned T2I models, including efficient data collection strategies,
LLM judgment capabilities, and model steerability towards diverse perspectives.
This research offers foundational tools for more equitable and aligned T2I
systems. Content Warning: The paper includes sensitive content that may be
harmful.

</details>


### [151] [Improving KAN with CDF normalization to quantiles](https://arxiv.org/abs/2507.13393)
*Jakub Strawa,Jarek Duda*

Main category: cs.LG

TL;DR: CDF 归一化在 KANs 中优于传统归一化，能提升预测精度和解释性。


<details>
  <summary>Details</summary>
Motivation: 机器学习中普遍使用数据归一化，但传统的归一化方法（如减去均值除以标准差或缩放到固定范围）在处理金融领域的 copula 理论中的归一化方法时可能存在不足。金融领域使用 CDF 变换将数据近似到 [0,1] 区间内的均匀分布，这种方法在机器学习中似乎未被充分认识，但可能带来优势。

Method: 本文提出并演示了使用累积分布函数（CDF）进行归一化，以替代传统的均值-方差归一化或最小-最大归一化。作者通过在 Kolmogorov-Arnold Networks (KANs) 上的实验，将传统的 Legendre-KAN 模型与使用 CDF 归一化的模型进行了比较。

Result: 通过将 Legendre-KAN 模型中的归一化方法从传统方法切换为 CDF 归一化，可以显著提高预测精度。此外，CDF 归一化在 HCR 解释中，其权重可以被理解为混合矩，能够模拟局部联合分布，并允许概率分布的传播和改变传播方向。

Conclusion: CDF 归一化是一种在机器学习中，特别是在 KANs 中，很有前景的替代归一化方法，可以提高预测精度并提供更强的解释性。

Abstract: Data normalization is crucial in machine learning, usually performed by
subtracting the mean and dividing by standard deviation, or by rescaling to a
fixed range. In copula theory, popular in finance, there is used normalization
to approximately quantiles by transforming x to CDF(x) with estimated CDF
(cumulative distribution function) to nearly uniform distribution in [0,1],
allowing for simpler representations which are less likely to overfit. It seems
nearly unknown in machine learning, therefore, we would like to present some
its advantages on example of recently popular Kolmogorov-Arnold Networks
(KANs), improving predictions from Legendre-KAN by just switching rescaling to
CDF normalization. Additionally, in HCR interpretation, weights of such neurons
are mixed moments providing local joint distribution models, allow to propagate
also probability distributions, and change propagation direction.

</details>


### [152] [Selective Embedding for Deep Learning](https://arxiv.org/abs/2507.13399)
*Mert Sehri,Zehui Hua,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: 选择性嵌入是一种新颖的数据加载策略，通过模仿人类信息处理来提高深度学习模型的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习模型在非平稳条件和不同领域下的性能下降问题，以及传统数据加载策略的局限性。

Method: 提出了一种名为选择性嵌入的新颖数据加载策略，通过在单个输入通道中交替来自多个源的短数据片段来模仿人类信息处理。

Result: 在六个时域数据集上进行了验证，证明了该方法在各种深度学习架构中始终如一地实现了高分类准确率，同时显著减少了训练时间。

Conclusion: 该方法为复杂系统提供了可扩展且资源高效的解决方案，适用于医疗保健、重型机械、海运、铁路和农业等领域。

Abstract: Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.

</details>


### [153] [LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](https://arxiv.org/abs/2507.13413)
*Aleksey Lapin,Igor Hromov,Stanislav Chumakov,Mile Mitrovic,Dmitry Simakov,Nikolay O. Nikitin,Andrey V. Savchenko*

Main category: cs.LG

TL;DR: LightAutoDS-Tab是一个多AutoML代理系统，通过结合LLM代码生成和多种AutoML工具，提高了表格数据任务的处理效率和鲁棒性，并在Kaggle竞赛中取得了优于现有开源方案的成果。


<details>
  <summary>Details</summary>
Motivation: 解决现有AutoML在处理复杂任务时，效率受限于特定底层工具依赖性的问题。

Method: LightAutoDS-Tab是一个多AutoML代理系统，利用基于LLM的代码生成和多个AutoML工具来处理表格数据任务。

Result: LightAutoDS-Tab在Kaggle的多个数据科学任务上，相比最先进的开源解决方案，在灵活性、鲁棒性和整体性能上均有提升。

Conclusion: LightAutoDS-Tab通过结合基于LLM的代码生成和多个AutoML工具，在处理表格数据任务时提高了灵活性和鲁棒性，在Kaggle的多个数据科学任务上表现优于最先进的开源解决方案。

Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs,
yet its efficiency remains limited by dependence on specific underlying tools.
In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for
tasks with tabular data, which combines an LLM-based code generation with
several AutoML tools. Our approach improves the flexibility and robustness of
pipeline design, outperforming state-of-the-art open-source solutions on
several data science tasks from Kaggle. The code of LightAutoDS-Tab is
available in the open repository https://github.com/sb-ai-lab/LADS

</details>


### [154] [An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC](https://arxiv.org/abs/2507.13736)
*Matthias Jobst,Tim Langer,Chen Liu,Mehmet Alici,Hector A. Gonzalez,Christian Mayr*

Main category: cs.LG

TL;DR: 提出了一种新的 DNN 调度框架，可以将 PyTorch 模型部署到 SpiNNaker2 芯片上，实现边缘推理。


<details>
  <summary>Details</summary>
Motivation: 为了实现将大型复杂 DNN（达 Transformer 规模）在 SpiNNaker2 这一神经形态平台上进行边缘执行。

Method: 提出了一种多层 DNN 调度框架，作为 OctopuScheduler 的扩展，并结合了量化和降低（lowering）等前端步骤。

Result: 成功实现了从 PyTorch 模型到 SpiNNaker2 芯片的端到端流程，使得复杂的 DNN 能够在边缘设备上运行。

Conclusion: 该框架实现了将 PyTorch 模型部署到 SpiNNaker2 芯片上进行边缘推理，支持达 Transformer 规模的大型复杂 DNN。

Abstract: This work presents a multi-layer DNN scheduling framework as an extension of
OctopuScheduler, providing an end-to-end flow from PyTorch models to inference
on a single SpiNNaker2 chip. Together with a front-end comprised of
quantization and lowering steps, the proposed framework enables the edge-based
execution of large and complex DNNs up to transformer scale using the
neuromorphic platform SpiNNaker2.

</details>


### [155] [Gauge Flow Models](https://arxiv.org/abs/2507.13414)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: Gauge Flow Models是一种新的生成流模型，通过在流ODE中引入Gauge场，在实验中取得了比传统流模型更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升生成流模型的性能，本文引入了一种新颖的Gauge Flow Models。

Method: 本文提出了一种新颖的生成流模型类别——Gauge Flow Models，其特点是在流常微分方程（ODE）中引入了一个可学习的Gauge场。

Result: 在基于高斯混合模型的流匹配实验中，Gauge Flow Models的性能显著优于同等或更大规模的传统流模型。

Conclusion: Gauge Flow Models在生成任务中展现出优于传统流模型的性能，并且有潜力在更广泛的生成任务中实现性能提升。

Abstract: This paper introduces Gauge Flow Models, a novel class of Generative Flow
Models. These models incorporate a learnable Gauge Field within the Flow
Ordinary Differential Equation (ODE). A comprehensive mathematical framework
for these models, detailing their construction and properties, is provided.
Experiments using Flow Matching on Gaussian Mixture Models demonstrate that
Gauge Flow Models yields significantly better performance than traditional Flow
Models of comparable or even larger size. Additionally, unpublished research
indicates a potential for enhanced performance across a broader range of
generative tasks.

</details>


### [156] [Scalable Submodular Policy Optimization via Pruned Submodularity Graph](https://arxiv.org/abs/2507.13834)
*Aditi Anand,Suman Banerjee,Dildar Ali*

Main category: cs.LG

TL;DR: 强化学习问题，其中奖励函数是次模的。提出了一种基于修剪的次模图方法，该方法提供了可证明的近似解决方案，并在基准环境中进行了测试，结果优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在奖励函数为次模函数（具有递减收益）的强化学习（RL）问题变体中，旨在找到最大化奖励函数的优化策略。

Method: 提出了一种基于修剪的次模图方法

Result: 实验结果表明，所提出的方法比基线方法能获得更多的奖励。

Conclusion: 该研究提出了一种基于修剪的次模图方法，该方法可在可行计算时间内提供可证明的近似解决方案，并保证了性能。

Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the
environment via a set of possible actions, and a reward is generated from some
unknown distribution. The task here is to find an optimal set of actions such
that the reward after a certain time step gets maximized. In a traditional
setup, the reward function in an RL Problem is considered additive. However, in
reality, there exist many problems, including path planning, coverage control,
etc., the reward function follows the diminishing return, which can be modeled
as a submodular function. In this paper, we study a variant of the RL Problem
where the reward function is submodular, and our objective is to find an
optimal policy such that this reward function gets maximized. We have proposed
a pruned submodularity graph-based approach that provides a provably
approximate solution in a feasible computation time. The proposed approach has
been analyzed to understand its time and space requirements as well as a
performance guarantee. We have experimented with a benchmark agent-environment
setup, which has been used for similar previous studies, and the results are
reported. From the results, we observe that the policy obtained by our proposed
approach leads to more reward than the baseline methods.

</details>


### [157] [FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning](https://arxiv.org/abs/2507.13624)
*Daniel Commey,Kamel Abbad,Garth V. Crosby,Lyes Khoukhi*

Main category: cs.LG

TL;DR: FedSkipTwin通过服务器端的LSTM数字孪生预测客户端更新的幅度和不确定性，从而仅在需要时才请求通信，以减少通信开销，同时提高模型精度。


<details>
  <summary>Details</summary>
Motivation: 通信开销是联邦学习（FL）中的主要瓶颈，尤其是在涉及移动和物联网设备的带宽受限应用中。

Method: FedSkipTwin通过在服务器端使用简单的LSTM实现轻量级数字孪生，观察客户端的梯度范数历史序列，预测其下次更新的幅度和不确定性。服务器利用这些预测，仅在其中一个值超过预定阈值时才请求通信，否则指示客户端跳过该轮次。

Result: FedSkipTwin在UCI-HAR和MNIST数据集上，在10个客户端和非IID数据分布下进行了实验。结果表明，在20轮通信中，FedSkipTwin将总通信量减少了12-15.5%，同时将最终模型精度提高了多达0.5个百分点。

Conclusion: FedSkipTwin是一种实用的、有效的策略，适用于带宽受限的边缘环境中的资源感知联邦学习。

Abstract: Communication overhead remains a primary bottleneck in federated learning
(FL), particularly for applications involving mobile and IoT devices with
constrained bandwidth. This work introduces FedSkipTwin, a novel
client-skipping algorithm driven by lightweight, server-side digital twins.
Each twin, implemented as a simple LSTM, observes a client's historical
sequence of gradient norms to forecast both the magnitude and the epistemic
uncertainty of its next update. The server leverages these predictions,
requesting communication only when either value exceeds a predefined threshold;
otherwise, it instructs the client to skip the round, thereby saving bandwidth.
Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients
under a non-IID data distribution. The results demonstrate that FedSkipTwin
reduces total communication by 12-15.5% across 20 rounds while simultaneously
improving final model accuracy by up to 0.5 percentage points compared to the
standard FedAvg algorithm. These findings establish that prediction-guided
skipping is a practical and effective strategy for resource-aware FL in
bandwidth-constrained edge environments.

</details>


### [158] [Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling](https://arxiv.org/abs/2507.13416)
*Jiaxiang Yi,Bernardo P. Ferreira,Miguel A. Bessa*

Main category: cs.LG

TL;DR: 数据驱动学习已推广到处理具有认知不确定性和随机不确定性的历史依赖多保真度数据，可用于各种科学和工程领域。


<details>
  <summary>Details</summary>
Motivation: 将数据驱动学习推广到考虑历史依赖的多保真度数据，同时量化认知不确定性并将其与数据噪声（随机不确定性）分离。

Method: 该方法将数据驱动学习推广到考虑历史依赖的多保真度数据，同时量化认知不确定性并将其与数据噪声（随机不确定性）分离。这种推广是分层的，并能适应不同的学习场景：从训练最简单的单保真度确定性神经网络到提出的多保真度方差估计贝叶斯循环神经网络。

Result: 该方法在包含有噪声和无噪声的多保真度数据的不同数据驱动本构建模场景中得到了验证，显示了其多功能性和通用性。

Conclusion: 该方法能够准确预测响应并量化模型误差，同时发现噪声分布（如果存在），为未来在不同科学和工程领域的实际应用打开了机会，尤其是在涉及不确定性设计和分析的最具挑战性的情况下。

Abstract: Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.

</details>


### [159] [Soft-ECM: An extension of Evidential C-Means for complex data](https://arxiv.org/abs/2507.13417)
*Armel Soubeiga,Thomas Guyet,Violaine Antoine*

Main category: cs.LG

TL;DR: 一种名为Soft-ECM的新算法被提出，用于聚类复杂数据，如混合数据和时间序列数据，解决了现有算法在非欧几里得空间中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于证据函数的聚类算法难以处理数值和类别混合数据或时间序列等复杂数据，因为它们依赖于欧几里得空间的性质，特别是质心的构造。本研究旨在解决这一局限性。

Method: 提出了一种名为Soft-ECM的新算法，该算法将ECM问题重新定义，以处理复杂的、非欧几里得空间中的数据，仅需半度量即可实现质心的精确对齐。

Result: Soft-ECM算法在数值数据上的表现与传统的模糊聚类方法相当，并能有效处理混合数据。

Conclusion: Soft-ECM算法能够处理数值型、混合型以及时间序列数据，并且在处理时间序列数据时，结合模糊聚类和DTW等半度量具有优势。

Abstract: Clustering based on belief functions has been gaining increasing attention in
the machine learning community due to its ability to effectively represent
uncertainty and/or imprecision. However, none of the existing algorithms can be
applied to complex data, such as mixed data (numerical and categorical) or
non-tabular data like time series. Indeed, these types of data are, in general,
not represented in a Euclidean space and the aforementioned algorithms make use
of the properties of such spaces, in particular for the construction of
barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem
for clustering complex data. We propose a new algorithm, Soft-ECM, which
consistently positions the centroids of imprecise clusters requiring only a
semi-metric. Our experiments show that Soft-ECM present results comparable to
conventional fuzzy clustering approaches on numerical data, and we demonstrate
its ability to handle mixed data and its benefits when combining fuzzy
clustering with semi-metrics such as DTW for time series data.

</details>


### [160] [Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity](https://arxiv.org/abs/2507.13423)
*Edward Henderson,Dewi Gould,Richard Everson,George De Ath,Nick Pepper*

Main category: cs.LG

TL;DR: 使用基于 GNN 的可解释框架，可以对航空交通管制员的任务需求进行实时评估，并将其归因于特定飞机。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前空域日益拥挤的背景下，对近地空域航空交通管制员（ATCO）任务需求的实时评估所面临的挑战，因为现有的复杂性指标往往无法捕捉除简单飞机数量之外的细微操作驱动因素。

Method: 本研究引入了一个基于图神经网络（GNN）的可解释框架，利用注意力机制对即将发布的指令数量进行预测。通过系统地移除飞机并测量其对模型预测的影响，我们推导出了一个可解释的、每个飞机的任务需求分数。

Result: 我们的框架显著优于受航空交通管制员启发的启发式方法，并且比已建立的基准更能可靠地估计场景复杂性。

Conclusion: 该框架能够将任务需求归因于特定飞机，为分析和理解通信员培训和空域重新设计中复杂性的驱动因素提供了一种新方法。

Abstract: Real-time assessment of near-term Air Traffic Controller (ATCO) task demand
is a critical challenge in an increasingly crowded airspace, as existing
complexity metrics often fail to capture nuanced operational drivers beyond
simple aircraft counts. This work introduces an interpretable Graph Neural
Network (GNN) framework to address this gap. Our attention-based model predicts
the number of upcoming clearances, the instructions issued to aircraft by
ATCOs, from interactions within static traffic scenarios. Crucially, we derive
an interpretable, per-aircraft task demand score by systematically ablating
aircraft and measuring the impact on the model's predictions. Our framework
significantly outperforms an ATCO-inspired heuristic and is a more reliable
estimator of scenario complexity than established baselines. The resulting tool
can attribute task demand to specific aircraft, offering a new way to analyse
and understand the drivers of complexity for applications in controller
training and airspace redesign.

</details>


### [161] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出了一种跨模态自监督预训练方法，使用IMU-视频数据来提高人类活动识别（HAR）的泛化能力，特别是在面对不同环境或人群的数据时。该方法在零样本和少样本评估中表现优于现有方法，并为处理动态数据模式提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 大多数基于IMU数据的机器学习方法在HAR任务中依赖于特定应用的标签，缺乏泛化能力，无法在不同环境或人群的数据中进行应用。为了解决这个问题，需要一种能够提高泛化能力的方法。

Method: 提出了一种新的跨模态自监督预训练方法，利用大规模未标记的IMU-视频数据学习表示，并证明了在不同环境或人群的IMU数据集（包括帕金森病患者数据集）上进行HAR任务的泛化能力得到了改善。

Result: 所提出的跨模态预训练方法在零样本和少样本评估中优于最先进的IMU-视频预训练方法和仅IMU预训练方法，并且在包括帕金森病患者在内的OOD IMU数据集上，HAR任务的泛化能力得到了改善。

Conclusion: 提出的跨模态预训练方法在零样本和少样本评估中优于最先进的IMU-视频预训练方法和仅IMU预训练方法，并证明了在动态数据模式（如IMU信号）中，跨模态预训练可用于学习可泛化的数据表示。

Abstract: Human Activity Recognition (HAR) based on wearable inertial sensors plays a
critical role in remote health monitoring. In patients with movement disorders,
the ability to detect abnormal patient movements in their home environments can
enable continuous optimization of treatments and help alert caretakers as
needed. Machine learning approaches have been proposed for HAR tasks using
Inertial Measurement Unit (IMU) data; however, most rely on
application-specific labels and lack generalizability to data collected in
different environments or populations. To address this limitation, we propose a
new cross-modal self-supervised pretraining approach to learn representations
from large-sale unlabeled IMU-video data and demonstrate improved
generalizability in HAR tasks on out of distribution (OOD) IMU datasets,
including a dataset collected from patients with Parkinson's disease.
Specifically, our results indicate that the proposed cross-modal pretraining
approach outperforms the current state-of-the-art IMU-video pretraining
approach and IMU-only pretraining under zero-shot and few-shot evaluations.
Broadly, our study provides evidence that in highly dynamic data modalities,
such as IMU signals, cross-modal pretraining may be a useful tool to learn
generalizable data representations. Our software is available at
https://github.com/scheshmi/IMU-Video-OOD-HAR.

</details>


### [162] [Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](https://arxiv.org/abs/2507.13491)
*Thomas Banker,Ali Mesbah*

Main category: cs.LG

TL;DR: 本文提出模型学习智能体是一种有前景的强化学习方法，可解决无模型方法中的样本效率低、不安全和可解释性差的问题。模型学习智能体利用系统模型进行学习，并可以通过无模型方法进行改进，以实现高效、安全和可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 当前无模型强化学习（RL）方法虽然在自主系统中取得显著进展，但其对神经网络的依赖加剧了样本效率低、学习不安全和可解释性有限等问题。本文旨在探索模型学习智能体作为一种有前景的替代方案。

Method: 本文探讨了模型学习智能体作为一种替代方案，用于策略近似，利用了系统动力学、成本和约束的适应性模型。主要学习方法包括贝叶斯优化、策略搜索强化学习和离线策略。

Result: 模型学习智能体利用系统动力学、成本和约束的模型，能够纳入先验知识，从而有助于解释智能体的决策。同时，模型不匹配导致的不足可以通过无模型强化学习来弥补。文章还讨论了模型学习智能体的优点和挑战，并详细介绍了贝叶斯优化、策略搜索强化学习和离线策略等主要学习方法。

Conclusion: 模型学习智能体与无模型强化学习的结合为高效学习安全和可解释的决策智能体提供了新的方向，尽管两者都面临各自的挑战，但它们可以互补。

Abstract: Training sophisticated agents for optimal decision-making under uncertainty
has been key to the rapid development of modern autonomous systems across
fields. Notably, model-free reinforcement learning (RL) has enabled
decision-making agents to improve their performance directly through system
interactions, with minimal prior knowledge about the system. Yet, model-free RL
has generally relied on agents equipped with deep neural network function
approximators, appealing to the networks' expressivity to capture the agent's
policy and value function for complex systems. However, neural networks amplify
the issues of sample inefficiency, unsafe learning, and limited
interpretability in model-free RL. To this end, this work introduces
model-based agents as a compelling alternative for control policy
approximation, leveraging adaptable models of system dynamics, cost, and
constraints for safe policy learning. These models can encode prior system
knowledge to inform, constrain, and aid in explaining the agent's decisions,
while deficiencies due to model mismatch can be remedied with model-free RL. We
outline the benefits and challenges of learning model-based agents --
exemplified by model predictive control -- and detail the primary learning
approaches: Bayesian optimization, policy search RL, and offline strategies,
along with their respective strengths. While model-free RL has long been
established, its interplay with model-based agents remains largely unexplored,
motivating our perspective on their combined potentials for sample-efficient
learning of safe and interpretable decision-making agents.

</details>


### [163] [On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach](https://arxiv.org/abs/2507.13805)
*Tim Rensmeyer,Denis Kramer,Oliver Niggemann*

Main category: cs.LG

TL;DR: 在微调过程中，利用贝叶斯神经网络和动态学习工作流来评估和处理基础模型的不确定性，从而实现对稀有事件的有效检测和采样。


<details>
  <summary>Details</summary>
Motivation: 为了应对第一性原理计算的计算复杂性以及生成足够大和多样化的训练数据集的挑战，特别是在模拟稀有事件或具有大构型空间的系统时，利用预训练的材料或分子数据库基础模型进行微调是一种有前景的方法。

Method: 本文引入了一种基于贝叶斯神经网络方法和后续的动态学习工作流的微调方法。

Result: 该方法能够自动微调模型，保持预定准确性，并有效检测和采样稀有事件。

Conclusion: 通过引入基于贝叶斯神经网络方法和后续的动态学习工作流，可以克服在微调基础模型时评估模型不确定性的挑战，该工作流可自动微调模型，同时保持预定的准确性，并能以相对于其发生率增加的速率检测稀有事件（如过渡态）并对其进行采样。

Abstract: Due to the computational complexity of evaluating interatomic forces from
first principles, the creation of interatomic machine learning force fields has
become a highly active field of research. However, the generation of training
datasets of sufficient size and sample diversity itself comes with a
computational burden that can make this approach impractical for modeling rare
events or systems with a large configuration space. Fine-tuning foundation
models that have been pre-trained on large-scale material or molecular
databases offers a promising opportunity to reduce the amount of training data
necessary to reach a desired level of accuracy. However, even if this approach
requires less training data overall, creating a suitable training dataset can
still be a very challenging problem, especially for systems with rare events
and for end-users who don't have an extensive background in machine learning.
In on-the-fly learning, the creation of a training dataset can be largely
automated by using model uncertainty during the simulation to decide if the
model is accurate enough or if a structure should be recalculated with
classical methods and used to update the model. A key challenge for applying
this form of active learning to the fine-tuning of foundation models is how to
assess the uncertainty of those models during the fine-tuning process, even
though most foundation models lack any form of uncertainty quantification. In
this paper, we overcome this challenge by introducing a fine-tuning approach
based on Bayesian neural network methods and a subsequent on-the-fly workflow
that automatically fine-tunes the model while maintaining a pre-specified
accuracy and can detect rare events such as transition states and sample them
at an increased rate relative to their occurrence.

</details>


### [164] [Fake or Real: The Impostor Hunt in Texts for Space Operations](https://arxiv.org/abs/2507.13508)
*Agata Kaczmarek,Dawid Płudowski,Piotr Wilczyński,Przemysław Biecek,Krzysztof Kotowski,Ramez Shendy,Jakub Nalepa,Artur Janicki,Evridiki Ntagiou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The "Fake or Real" competition hosted on Kaggle
(\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})
is the second part of a series of follow-up competitions and hackathons related
to the "Assurance for Space Domain AI Applications" project funded by the
European Space Agency
(\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).
The competition idea is based on two real-life AI security threats identified
within the project -- data poisoning and overreliance in Large Language Models.
The task is to distinguish between the proper output from LLM and the output
generated under malicious modification of the LLM. As this problem was not
extensively researched, participants are required to develop new techniques to
address this issue or adjust already existing ones to this problem's statement.

</details>


### [165] [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
*Yongyi Yang,Hidenori Tanaka,Wei Hu*

Main category: cs.LG

TL;DR: ICL 能够通过内化提示的数据生成过程 (DGP) 来学习新行为，其机制在于“双重收敛”框架，该框架在上下文和层之间收敛隐藏表示，从而产生对平滑表示的偏见，并具有抵抗高频噪声的内在鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探究 LLM 通过 ICL 从输入序列中学习新行为（无需参数更新）的机制，以及 LLM 如何内化提示的数据生成过程 (DGP) 的结构到隐藏表示中。

Method: 提出了一种名为“双重收敛”的统一框架，其中隐藏表示在上下文和层之间进行收敛。

Result: 双重收敛过程导致对平滑（低频）表示的隐式偏见，并通过分析证明和经验验证。该理论解释了几个悬而未决的经验观察结果，例如为何学习到的表示会展现出全局结构化但局部失真的几何形状，以及为何它们的总能量会在不消失的情况下衰减。

Conclusion: ICL 的内在鲁棒性可以抵抗高频噪声，并通过经验得到证实。这些结果为 ICL 的潜在机制提供了新的见解，并为其研究奠定了理论基础，有望扩展到更一般的数据分布和设置。

Abstract: In-context learning (ICL) enables large language models (LLMs) to acquire new
behaviors from the input sequence alone without any parameter updates. Recent
studies have shown that ICL can surpass the original meaning learned in
pretraining stage through internalizing the structure the data-generating
process (DGP) of the prompt into the hidden representations. However, the
mechanisms by which LLMs achieve this ability is left open. In this paper, we
present the first rigorous explanation of such phenomena by introducing a
unified framework of double convergence, where hidden representations converge
both over context and across layers. This double convergence process leads to
an implicit bias towards smooth (low-frequency) representations, which we prove
analytically and verify empirically. Our theory explains several open empirical
observations, including why learned representations exhibit globally structured
but locally distorted geometry, and why their total energy decays without
vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness
towards high-frequency noise, which we empirically confirm. These results
provide new insights into the underlying mechanisms of ICL, and a theoretical
foundation to study it that hopefully extends to more general data
distributions and settings.

</details>


### [166] [Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography](https://arxiv.org/abs/2507.13542)
*Beka Begiashvili,Carlos J. Fernandez-Candel,Matías Pérez Paredes*

Main category: cs.LG

TL;DR: A new AI-derived parameter called the Acoustic Index, developed using EDMD and a hybrid neural network, shows high accuracy (AUC 0.89) in detecting cardiac dysfunction from echocardiograms, outperforming traditional methods and offering a scalable, interpretable, and vendor-independent tool for early detection and monitoring.


<details>
  <summary>Details</summary>
Motivation: Traditional echocardiographic parameters like ejection fraction (EF) and global longitudinal strain (GLS) have limitations in early detecting cardiac dysfunction due to factors like normal EF values despite pathology and GLS's susceptibility to load conditions and vendor variability. There is a need for reproducible, interpretable, and operator-independent parameters for subtle cardiac functional alterations.

Method: The study utilized Extended Dynamic Mode Decomposition (EDMD) based on Koopman operator theory combined with a hybrid neural network that incorporates clinical metadata. Spatiotemporal dynamics were extracted from echocardiographic sequences to identify coherent motion patterns, which were then weighted via attention mechanisms and fused with clinical data using manifold learning to generate a continuous risk score.

Result: In a prospective cohort of 736 patients, the Acoustic Index achieved an AUC of 0.89 on an independent test set. Cross-validation confirmed robustness, with sensitivity and specificity exceeding 0.8 on independent data. The parameter demonstrated stable trade-offs between sensitivity and specificity.

Conclusion: The Acoustic Index, a novel AI-derived parameter, shows promise as a scalable, vendor-independent tool for early detection, triage, and longitudinal monitoring of cardiac dysfunction. Future research will focus on external validation, longitudinal studies, and disease-specific adaptations.

Abstract: Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.

</details>


### [167] [Time Series Forecastability Measures](https://arxiv.org/abs/2507.13556)
*Rui Wang,Steven Klee,Alexis Roos*

Main category: cs.LG

TL;DR: 通过谱可预测性得分和最大李雅普诺夫指数量化时间序列的可预测性，以指导预测模型开发和资源规划。


<details>
  <summary>Details</summary>
Motivation: 为了在模型开发之前量化时间序列的固有可预测性，以便从业者能够更好地规划资源和设定预期。

Method: 提出并评估了谱可预测性得分和最大李雅普诺夫指数这两种量化时间序列可预测性的指标。

Result: 研究结果表明，谱可预测性得分和最大李雅普诺夫指数能够有效反映时间序列的固有可预测性，并与实际预测性能呈强相关性。

Conclusion: 该研究提出了两种量化时间序列可预测性的指标：谱可预测性得分和最大李雅普诺夫指数。这些指标在模型开发之前评估数据的固有可预测性特征，而不是依赖传统的模型评估指标。研究结果表明，这两种指标能够准确反映时间序列的固有可预测性，并与各种模型的实际预测性能高度相关。通过在模型训练前了解时间序列的固有可预测性，从业者可以更有效地规划其在可预测性较高产品和供应链层面的工作，并为可预测性有限的产品设定适当的预期或寻求替代策略。

Abstract: This paper proposes using two metrics to quantify the forecastability of time
series prior to model development: the spectral predictability score and the
largest Lyapunov exponent. Unlike traditional model evaluation metrics, these
measures assess the inherent forecastability characteristics of the data before
any forecast attempts. The spectral predictability score evaluates the strength
and regularity of frequency components in the time series, whereas the Lyapunov
exponents quantify the chaos and stability of the system generating the data.
We evaluated the effectiveness of these metrics on both synthetic and
real-world time series from the M5 forecast competition dataset. Our results
demonstrate that these two metrics can correctly reflect the inherent
forecastability of a time series and have a strong correlation with the actual
forecast performance of various models. By understanding the inherent
forecastability of time series before model training, practitioners can focus
their planning efforts on products and supply chain levels that are more
forecastable, while setting appropriate expectations or seeking alternative
strategies for products with limited forecastability.

</details>


### [168] [Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)
*Mrinal Mathur,Mike Doan,Barak Pearlmutter,Sergey Plis*

Main category: cs.LG

TL;DR: SELF-Transformer 是一种新的 Transformer 架构，通过迭代更新注意力权重来提高其表达能力，在不增加参数的情况下提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在不依赖于标记级自回归的情况下提高编码器 Transformer 的表达能力，我们引入了 SELF-Transformer。

Method: SELF-Transformer 是一种编码器层，它迭代地将其自身的注意力权重精炼到固定点。

Result: SELF-Transformer 在不增加参数数量的情况下，在类似编码器的基准测试中，准确率提高了高达 20%。

Conclusion: Transformer 的一种新架构 SELF-Transformer，它通过迭代更新注意力权重来提高表达能力，在不增加参数数量的情况下，在类似编码器的基准测试中提高了高达 20% 的准确率。

Abstract: Transformers evaluated in a single, fixed-depth pass are provably limited in
expressive power to the constant-depth circuit class TC0. Running a Transformer
autoregressively removes that ceiling -- first in next-token prediction and,
more recently, in chain-of-thought reasoning. Both regimes rely on feedback
loops that decode internal states into tokens only to re-encode them in
subsequent steps. While this "thinking aloud" mirrors human reasoning,
biological brains iterate without externalising intermediate states as
language. To boost the expressive power of encoder Transformers without
resorting to token-level autoregression, we introduce the SELF-Transformer: an
encoder layer that iteratively refines its own attention weights to a fixed
point. Instead of producing -- in one pass -- the alignment matrix that remixes
the input sequence, the SELF-Transformer iteratively updates that matrix
internally, scaling test-time computation with input difficulty. This
adaptivity yields up to 20\% accuracy gains on encoder-style benchmarks without
increasing parameter count, demonstrating that input-adaptive alignment at test
time offers substantial benefits for only a modest extra compute budget.
Self-Transformers thus recover much of the expressive power of iterative
reasoning while preserving the simplicity of pure encoder architectures.

</details>


### [169] [Apple Intelligence Foundation Language Models: Tech Report 2025](https://arxiv.org/abs/2507.13575)
*Hanzhi Zhou,Erik Hornberger,Pengsheng Guo,Xiyou Zhou,Saiwen Wang,Xin Wang,Yifei He,Xuankai Chang,Rene Rauch,Louis D'hauwe,John Peebles,Alec Doane,Kohen Chia,Jenna Thibodeau,Zi-Yi Dou,Yuanyang Zhang,Ruoming Pang,Reed Li,Zhifeng Chen,Jeremy Warner,Zhaoyang Xu,Sophy Lee,David Mizrahi,Ramsey Tantawi,Chris Chaney,Kelsey Peterson,Jun Qin,Alex Dombrowski,Mira Chiang,Aiswarya Raghavan,Gerard Casamayor,Qibin Chen,Aonan Zhang,Nathalie Tran,Jianyu Wang,Hang Su,Thomas Voice,Alessandro Pappalardo,Brycen Wershing,Prasanth Yadla,Rui Li,Priyal Chhatrapati,Ismael Fernandez,Yusuf Goren,Xin Zheng,Forrest Huang,Tao Lei,Eray Yildiz,Alper Kokmen,Gokul Santhanam,Areeba Kamal,Kaan Elgin,Dian Ang Yap,Jeremy Liu,Peter Gray,Howard Xing,Kieran Liu,Matteo Ronchi,Moritz Schwarzer-Becker,Yun Zhu,Mandana Saebi,Jeremy Snow,David Griffiths,Guillaume Tartavel,Erin Feldman,Simon Lehnerer,Fernando Bermúdez-Medina,Hans Han,Joe Zhou,Xiaoyi Ren,Sujeeth Reddy,Zirui Wang,Tom Gunter,Albert Antony,Yuanzhi Li,John Dennison,Tony Sun,Yena Han,Yi Qin,Sam Davarnia,Jeffrey Bigham,Wayne Shan,Hannah Gillis Coleman,Guillaume Klein,Peng Liu,Muyang Yu,Jack Cackler,Yuan Gao,Crystal Xiao,Binazir Karimzadeh,Zhengdong Zhang,Felix Bai,Albin Madappally Jose,Feng Nan,Nazir Kamaldin,Dong Yin,Hans Hao,Yanchao Sun,Yi Hua,Charles Maalouf,Alex Guillen Garcia,Guoli Yin,Lezhi Li,Mohana Prasad Sathya Moorthy,Hongbin Gao,Jay Tang,Joanna Arreaza-Taylor,Faye Lao,Carina Peng,Josh Shaffer,Dan Masi,Sushma Rao,Tommi Vehvilainen,Senyu Tong,Dongcai Shen,Yang Zhao,Chris Bartels,Peter Fu,Qingqing Cao,Christopher Neubauer,Ethan Li,Mingfei Gao,Rebecca Callahan,Richard Wei,Patrick Dong,Alex Braunstein,Sachin Ravi,Adolfo Lopez Mendez,Kaiwei Huang,Kun Duan,Haoshuo Huang,Rui Qian,Stefano Ligas,Jordan Huffaker,Dongxu Li,Bailin Wang,Nanzhu Wang,Anuva Agarwal,Tait Madsen,Josh Newnham,Abhishek Sharma,Zhile Ren,Deepak Gopinath,Erik Daxberger,Saptarshi Guha,Oron Levy,Jing Lu,Nan Dun,Marc Kirchner,Yinfei Yang,Manjot Bilkhu,Dave Nelson,Anthony Spalvieri-Kruse,Juan Lao Tebar,Yang Xu,Phani Mutyala,Gabriel Jacoby-Cooper,Yingbo Wang,Karla Vega,Vishaal Mahtani,Darren Botten,Eric Wang,Hanli Li,Matthias Paulik,Haoran Yan,Navid Shiee,Yihao Qian,Bugu Wu,Qi Zhu,Ob Adaranijo,Bhuwan Dhingra,Zhe Gan,Nicholas Seidl,Grace Duanmu,Rong Situ,Yiping Ma,Yin Xia,David Riazati,Vasileios Saveris,Anh Nguyen,Michael,Lee,Patrick Sonnenberg,Chinguun Erdenebileg,Yanghao Li,Vivian Ma,James Chou,Isha Garg,Mark Lee,Keen You,Yuhong Li,Ransen Niu,Nandhitha Raghuram,Pulkit Agrawal,Henry Mason,Sumeet Singh,Keyu He,Hong-You Chen,Lucas Guibert,Shiyu Li,Varsha Paidi,Narendran Raghavan,Mingze Xu,Yuli Yang,Sergiu Sima,Irina Belousova,Sprite Chu,Afshin Dehghan,Philipp Dufter,David Haldimann,Zhen Yang,Margit Bowler,Chang Liu,Ying-Chang Cheng,Vivek Rathod,Syd Evans,Wilson Tsao,Dustin Withers,Haitian Sun,Biyao Wang,Peter Grasch,Walker Cheng,Yihao Feng,Vivek Kumar,Frank Chu,Victoria MönchJuan Haladjian,Doug Kang,Jiarui Lu,Ciro Sannino,Max Lam,Floris Weers,Bowen Pan,Kenneth Jung,Dhaval Doshi,Fangping Shi,Olli Saarikivi,Alp Aygar,Josh Elman,Cheng Leong,Eshan Verma,Matthew Lei,Jeff Nichols,Jiulong Shan,Donald Zhang,Lawrence Zhou,Stephen Murphy,Xianzhi Du,Chang Lan,Ankur Jain,Elmira Amirloo,Marcin Eichner,Naomy Sabo,Anupama Mann Anupama,David Qiu,Zhao Meng,Michael FitzMaurice,Peng Zhang,Simon Yeung,Chen Chen,Marco Zuliani,Andrew Hansen,Yang Lu,Brent Ramerth,Ziyi Zhong,Parsa Mazaheri,Matthew Hopkins,Mengyu Li,Simon Wang,David Chen,Farzin Rasteh,Chong Wang,Josh Gardner,Asaf Liberman,Haoxuan You,Andrew Walkingshaw,Xingyu Zhou,Jinhao Lei,Yan Meng,Quentin Keunebroek,Sam Wiseman,Anders Boesen Lindbo Larsen,Yi Zhang,Zaid Ahmed,Haiming Gang,Aaron Franklin,Kelvin Zou,Guillaume Seguin,Jonathan Janke,Rachel Burger,Co Giang,Cheng Shen,Jen Liu,Sanskruti Shah,Xiang Kong,Yiran Fei,TJ Collins,Chen Zhang,Zhiyun Lu,Michael Booker,Qin Ba,Yasutaka Tanaka,Andres Romero Mier Y Teran,Federico Scozzafava,Regan Poston,Jane Li,Eduardo Jimenez,Bas Straathof,Karanjeet Singh,Lindsay Hislop,Rajat Arora,Deepa Seshadri,Boyue Li,Colorado Reed,Zhen Li,TJ Lu,Yi Wang,Kaelen Haag,Nicholas Lusskin,Raunak Sinha,Rahul Nair,Eldon Schoop,Mary Beth Kery,Mehrdad Farajtbar,Brenda Yang,George Horrell,Shiwen Zhao,Dhruti Shah,Cha Chen,Bowen Zhang,Chang Gao,Devi Krishna,Jennifer Mallalieu,Javier Movellan,Di Feng,Emily Zhang,Sam Xu,Junting Pan,Dominik Moritz,Suma Jayaram,Kevin Smith,Dongseong Hwang,Daniel Parilla,Jiaming Hu,You-Cyuan Jhang,Emad Soroush,Fred Hohman,Nan Du,Emma Wang,Sam Dodge,Pragnya Sridhar,Joris Pelemans,Wei Fang,Nina Wenzel,Joseph Yitan Cheng,Hadas Kotek,Chung-Cheng Chiu,Meng Cao,Haijing Fu,Ruixuan Hou,Ke Ye,Diane Zhu,Nikhil Bhendawade,Joseph Astrauskas,Jian Liu,Sai Aitharaju,Wentao Wu,Artsiom Peshko,Hyunjik Kim,Nilesh Shahdadpuri,Andy De Wang,Qi Shan,Piotr Maj,Raul Rea Menacho,Justin Lazarow,Eric Liang Yang,Arsalan Farooq,Donghan Yu,David Güera,Minsik Cho,Kavya Nerella,Yongqiang Wang,Tao Jia,John Park,Jeff Lai,Haotian Zhang,Futang Peng,Daniele Molinari,Aparna Rajamani,Tyler Johnson,Lauren Gardiner,Chao Jia,Violet Yao,Wojciech Kryscinski,Xiujun Li,Shang-Chen Wu*

Main category: cs.LG

TL;DR: 苹果公司发布了两个新的语言模型（一个设备端模型和一个服务器模型），用于苹果智能功能。这些模型在多语言和多模态任务上表现出色，并支持新的开发框架，同时注重负责任的AI和用户隐私。


<details>
  <summary>Details</summary>
Motivation: 为了给苹果设备和服务的苹果智能功能提供支持，研究介绍了两个新的多语言、多模态基础语言模型。

Method: 研究中引入了两个苹果智能基础语言模型：1. 一个30亿参数的设备端模型，通过KV缓存共享和2位量化感知训练等架构创新进行了优化。2. 一个可扩展的服务器模型，基于新颖的并行轨道混合专家（PT-MoE）Transformer构建，结合了轨道并行、混合专家稀疏计算和全局-局部交错注意力。模型在多语言和多模态数据集上进行训练，并通过监督微调和强化学习进行优化。此外，还提出了一个以Swift为中心的Foundation Models框架，用于集成这些能力，并强调了负责任的AI方法和隐私保护。

Result: 所介绍的模型支持更多语言，能够理解图像并执行工具调用。在公共基准测试和人类评估中，服务器模型和设备端模型均能达到或超过同等规模的开放基线模型。此外，新提出的Swift-centric Foundation Models框架简化了开发者的集成过程。

Conclusion: 该研究介绍了两个用于苹果设备和服务的苹果智能基础语言模型：一个30亿参数的设备端模型和一个可扩展的服务器模型。两个模型都在多语言和多模态数据集上进行了训练，并在公共基准和人类评估中与同等规模的开放基线模型相匹配或超越。

Abstract: We introduce two multilingual, multimodal foundation language models that
power Apple Intelligence features across Apple devices and services: i a
3B-parameter on-device model optimized for Apple silicon through architectural
innovations such as KV-cache sharing and 2-bit quantization-aware training; and
ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts
PT-MoE transformer that combines track parallelism, mixture-of-experts sparse
computation, and interleaved global-local attention to deliver high quality
with competitive cost on Apple's Private Cloud Compute platform. Both models
are trained on large-scale multilingual and multimodal datasets sourced via
responsible web crawling, licensed corpora, and high-quality synthetic data,
then further refined with supervised fine-tuning and reinforcement learning on
a new asynchronous platform. The resulting models support several additional
languages while understanding images and executing tool calls. In public
benchmarks and human evaluations, both the server model and the on-device model
match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation,
constrained tool calling, and LoRA adapter fine-tuning, allowing developers to
integrate these capabilities with a few lines of code. The latest advancements
in Apple Intelligence models are grounded in our Responsible AI approach with
safeguards like content filtering and locale-specific evaluation, as well as
our commitment to protecting our users' privacy with innovations like Private
Cloud Compute.

</details>


### [170] [Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries](https://arxiv.org/abs/2507.13579)
*Hyunji Nam,Yanming Wan,Mickel Liu,Jianxun Lian,Natasha Jaques*

Main category: cs.LG

TL;DR: 提出PLUS框架，通过学习用户偏好摘要来个性化LLM响应，优于现有方法，并支持GPT-4的零样本个性化。


<details>
  <summary>Details</summary>
Motivation: 随着LLM AI助手在日常使用中的普及，使其响应符合不同用户的偏好和目标变得日益重要。现有的RLHF方法虽然能提升LLM的通用性和流畅性，但未能考虑用户间的差异性，因为它仅用单一的奖励模型来模拟整个用户群体。

Method: 提出了一种名为PLUS（Preference Learning Using Summarization）的新框架，该框架通过学习用户偏好、特征和过往对话的文本摘要来个性化LLM的响应。用户摘要用于条件化奖励模型，使其能够针对每个用户进行个性化预测。用户摘要模型通过强化学习进行训练，并同时更新奖励模型，形成一个在线的协同适应循环。

Result: PLUS框架生成的摘要能够捕捉用户偏好的有意义的方面，优于现有的个性化RLHF技术或上下文学习方法。在不同的多元用户数据集中，该方法在新用户和多样化的对话主题上表现出鲁棒性。此外，用户摘要可以迁移用于对GPT-4等更强大的专有模型进行零样本个性化。

Conclusion: PLUS框架生成的文本摘要简洁、便携且易于用户理解和修改，从而提高了LLM对齐的透明度和用户控制力。

Abstract: As everyday use cases of large language model (LLM) AI assistants have
expanded, it is becoming increasingly important to personalize responses to
align to different users' preferences and goals. While reinforcement learning
from human feedback (RLHF) is effective at improving LLMs to be generally more
helpful and fluent, it does not account for variability across users, as it
models the entire user population with a single reward model. We present a
novel framework, Preference Learning Using Summarization (PLUS), that learns
text-based summaries of each user's preferences, characteristics, and past
conversations. These summaries condition the reward model, enabling it to make
personalized predictions about the types of responses valued by each user. We
train the user-summarization model with reinforcement learning, and update the
reward model simultaneously, creating an online co-adaptation loop. We show
that in contrast with prior personalized RLHF techniques or with in-context
learning of user information, summaries produced by PLUS capture meaningful
aspects of a user's preferences. Across different pluralistic user datasets, we
show that our method is robust to new users and diverse conversation topics.
Additionally, we demonstrate that the textual summaries generated about users
can be transferred for zero-shot personalization of stronger, proprietary
models like GPT-4. The resulting user summaries are not only concise and
portable, they are easy for users to interpret and modify, allowing for more
transparency and user control in LLM alignment.

</details>


### [171] [Off-Policy Evaluation and Learning for Matching Markets](https://arxiv.org/abs/2507.13608)
*Yudai Hayashi,Shuhei Goda,Yuta Saito*

Main category: cs.LG

TL;DR: 提出 DiPS 和 DPR 估计器，改进了匹配市场的离线策略评估和学习，解决了方差和奖励稀疏性问题，并在合成数据和真实世界场景中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 匹配服务（如求职和约会应用）中基于用户相互偏好的匹配是推荐系统的基本方面。虽然 A/B 测试是评估新策略的黄金标准，但成本高昂且不适合频繁更新。因此，离线策略评估（OPE）至关重要，但现有 OPE 方法在匹配市场中由于用户交互的规模和双向性而面临方差问题和奖励稀疏性问题，导致其不可靠。

Method: 提出名为 DiPS 和 DPR 的新型 OPE 估计器，结合了直接法（DM）、逆倾向得分（IPS）和双重稳健（DR）估计器的要素，并融入了中间标签（如初始参与信号）以更好地控制偏差-方差。

Result: 在理论上，推导了所提出估计器的偏差和方差，并证明了其相对于传统方法的优势。在实践中，通过在合成数据和真实求职匹配平台上的 A/B 测试日志进行实验，证明了所提出的方法在 OPE 和离线策略学习方面优于现有方法。

Conclusion: 所提出的 DiPS 和 DPR 估计器通过结合中间标签（如初始参与信号）来解决匹配市场中方差和奖励稀疏性问题，实现了更好的偏差-方差控制。这些估计器可以无缝扩展到离线策略学习方法，以改进匹配策略。

Abstract: Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

</details>


### [172] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
*Binxiong Li,Yuefei Wang,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao,Xi Yu*

Main category: cs.LG

TL;DR: Tri-GFN框架通过结合GCN、AE和图Transformer，利用三元学习和特征融合策略，解决了图聚类中的关键挑战，并在多个数据集上显著提升了聚类准确性，尤其在Reuters数据集上的优异表现使其可应用于新闻分类等领域。


<details>
  <summary>Details</summary>
Motivation: 现有的图卷积网络（GCN）在处理大规模和复杂图数据集时存在过平滑和过压缩问题，导致聚类质量下降。图Transformer虽然缓解了部分问题，但在处理异构图数据时性能仍然受限。

Method: 提出了一种新颖的深度聚类框架Tri-GFN，该框架整合了图卷积网络（GCN）、自编码器（AE）和图Transformer。通过“三元学习”机制促进各模块间的互学习，并采用特征融合增强策略来融合节点属性和拓扑结构信息，以获得更具区分性的聚类表示。

Result: Tri-GFN框架在ACM、Reuters和USPS数据集上取得了优于SOTA方法的聚类效果，准确率分别提升了约0.87%、14.14%和7.58%。

Conclusion: Tri-GFN框架通过整合GCN、AE和图Transformer，并利用其独特的“三元学习”机制和特征融合增强策略，有效解决了大规模和复杂图数据分析中的过平滑、过压缩以及异构图数据处理性能受限等问题。该框架在ACM、Reuters和USPS数据集上取得了优于现有SOTA方法的聚类效果，准确率分别提升了约0.87%、14.14%和7.58%。

Abstract: In recent years, models based on Graph Convolutional Networks (GCN) have made
significant strides in the field of graph data analysis. However, challenges
such as over-smoothing and over-compression remain when handling large-scale
and complex graph datasets, leading to a decline in clustering quality.
Although the Graph Transformer architecture has mitigated some of these issues,
its performance is still limited when processing heterogeneous graph data. To
address these challenges, this study proposes a novel deep clustering framework
that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the
Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the
differentiation and consistency of global and local information through a
unique tri-learning mechanism and feature fusion enhancement strategy. The
framework integrates GCN, AE, and Graph Transformer modules. These components
are meticulously fused by a triple-channel enhancement module, which maximizes
the use of both node attributes and topological structures, ensuring robust
clustering representation. The tri-learning mechanism allows mutual learning
among these modules, while the feature fusion strategy enables the model to
capture complex relationships, yielding highly discriminative representations
for graph clustering. It surpasses many state-of-the-art methods, achieving an
accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the
Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding
performance on the Reuters dataset, Tri-GFN can be applied to automatic news
classification, topic retrieval, and related fields.

</details>


### [173] [A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design](https://arxiv.org/abs/2507.13646)
*Nimisha Ghosh,Daniele Santoni,Debaleena Nawn,Eleonora Ottaviani,Giovanni Felici*

Main category: cs.LG

TL;DR: Transformer models are revolutionizing protein analysis and design, impacting areas from gene ontology to protein binding. This review covers recent advances, strengths, weaknesses, and future directions.


<details>
  <summary>Details</summary>
Motivation: To discuss recent advances in Transformer-based models for protein sequence analysis and design, providing a comprehensive insight into the field for researchers.

Method: This paper reviews and analyzes recent advances in Transformer-based models for protein sequence analysis and design, discussing a significant number of works in the field.

Result: The paper analyzes recent works on Transformer-based models for protein sequence analysis and design, covering various applications and discussing their strengths and weaknesses.

Conclusion: The review highlights the impact of Transformer-based models in protein sequence analysis and design, covering applications like gene ontology, functional and structural identification, de novo protein generation, and protein binding. It analyzes the strengths and weaknesses of existing research and suggests future directions.

Abstract: The impact of Transformer-based language models has been unprecedented in
Natural Language Processing (NLP). The success of such models has also led to
their adoption in other fields including bioinformatics. Taking this into
account, this paper discusses recent advances in Transformer-based models for
protein sequence analysis and design. In this review, we have discussed and
analysed a significant number of works pertaining to such applications. These
applications encompass gene ontology, functional and structural protein
identification, generation of de novo proteins and binding of proteins. We
attempt to shed light on the strength and weaknesses of the discussed works to
provide a comprehensive insight to readers. Finally, we highlight shortcomings
in existing research and explore potential avenues for future developments. We
believe that this review will help researchers working in this field to have an
overall idea of the state of the art in this field, and to orient their future
studies.

</details>


### [174] [Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction](https://arxiv.org/abs/2507.13685)
*Yue Yang,Zihan Su,Ying Zhang,Chang Chuan Goh,Yuxiang Lin,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 本研究提出GRU-KAN和LSTM-KAN模型，通过结合KAN与GRU/LSTM，提高了贷款违约预测的提前性和准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法在提前预测贷款违约方面存在准确性不足和依赖特定时间范围内训练测试的缺陷，限制了其在实际中的应用。本研究旨在提高贷款违约模型提前三个月以上的预测能力，以便金融机构能够及时采取预防措施。

Method: 本研究引入了GRU-KAN和LSTM-KAN两种新的网络架构，将Kolmogorov-Arnold网络（KAN）与门循环单元（GRU）和长短期记忆（LSTM）网络相结合。

Result: GRU-KAN和LSTM-KAN模型在不同特征窗口长度、样本量和提前预测区间下，与LSTM、GRU、LSTM-Attention和LSTM-Transformer等基线模型进行了评估。结果表明，所提出的模型在提前预测方面表现优异。

Conclusion: 本研究提出的GRU-KAN和LSTM-KAN模型在预测准确性、精确率、召回率、F1分数和AUC方面显著优于现有基线模型，能够提前三个月达到92%以上的预测准确率，提前八个月达到88%以上的预测准确率。

Abstract: This study addresses a critical challenge in time series anomaly detection:
enhancing the predictive capability of loan default models more than three
months in advance to enable early identification of default events, helping
financial institutions implement preventive measures before risk events
materialize. Existing methods have significant drawbacks, such as their lack of
accuracy in early predictions and their dependence on training and testing
within the same year and specific time frames. These issues limit their
practical use, particularly with out-of-time data. To address these, the study
introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge
Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long
Short-Term Memory (LSTM) networks. The proposed models were evaluated against
the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms
of accuracy, precision, recall, F1 and AUC in different lengths of feature
window, sample sizes, and early prediction intervals. The results demonstrate
that the proposed model achieves a prediction accuracy of over 92% three months
in advance and over 88% eight months in advance, significantly outperforming
existing baselines.

</details>


### [175] [Byzantine-resilient federated online learning for Gaussian process regression](https://arxiv.org/abs/2507.14021)
*Xu Zhang,Zhenyuan Yuan,Minghui Zhu*

Main category: cs.LG

TL;DR: 提出了一种拜占庭容错联邦GPR算法，通过云端聚合和智能体融合优化预测，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究拜占庭容错的联邦在线学习，特别是针对高斯过程回归（GPR），以应对部分智能体可能出现的任意或对抗性行为，旨在提高联邦学习的鲁棒性和性能。

Method: 提出了一种拜占庭容错联邦高斯过程回归（GPR）算法。该算法允许云和一组智能体协同学习一个潜在函数，并在部分智能体出现拜占庭故障（即任意或对抗性行为）的情况下提高学习性能。具体来说，基于智能体的本地GPR发送可能被篡ч的本地预测到云端，云端聚合的GPR通过拜占庭容错专家乘积聚合规则计算全局模型，然后云端将当前全局模型广播给所有智能体。基于智能体的融合GPR通过融合接收到的全局模型和智能体本身的本地GPR来优化本地预测。

Result: 量化了基于智能体的融合GPR相对于基于智能体的本地GPR在学习准确性上的提升。

Conclusion: 实验表明，所提出的算法在玩具示例和两个中等规模的真实世界数据集上都表现良好，证明了其有效性。

Abstract: In this paper, we study Byzantine-resilient federated online learning for
Gaussian process regression (GPR). We develop a Byzantine-resilient federated
GPR algorithm that allows a cloud and a group of agents to collaboratively
learn a latent function and improve the learning performances where some agents
exhibit Byzantine failures, i.e., arbitrary and potentially adversarial
behavior. Each agent-based local GPR sends potentially compromised local
predictions to the cloud, and the cloud-based aggregated GPR computes a global
model by a Byzantine-resilient product of experts aggregation rule. Then the
cloud broadcasts the current global model to all the agents. Agent-based fused
GPR refines local predictions by fusing the received global model with that of
the agent-based local GPR. Moreover, we quantify the learning accuracy
improvements of the agent-based fused GPR over the agent-based local GPR.
Experiments on a toy example and two medium-scale real-world datasets are
conducted to demonstrate the performances of the proposed algorithm.

</details>


### [176] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
*Martin Krutský,Gustav Šír,Vyacheslav Kungurtsev,Georgios Korpas*

Main category: cs.LG

TL;DR: PI-GNN 在处理高密度图时性能下降，原因在于模型输出与二值解之间存在差异。我们提出了一种结合模糊逻辑和二值化神经网络的解决方案，该方案可提高 PI-GNN 在密集图上的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然 PI-GNN 框架在各种组合优化问题中取得了有前景的结果，但其性能会随着组合问题图密度的增加而系统性地下降。我们发现了 PI-GNN 训练动力学中与更密集问题的退化解相关的明显相变。

Method: 提出了一种基于模糊逻辑和二值化神经网络的原则性替代方法来解决 PI-GNN 中存在的现实值模型输出与二值值问题解之间的差异。

Result: 实验证明，所提出的方法组合显著提高了 PI-GNN 在日益密集的设置中的性能。

Conclusion: 所提出的方法组合显著提高了 PI-GNN 在日益密集的设置中的性能。

Abstract: Physics-inspired graph neural networks (PI-GNNs) have been utilized as an
efficient unsupervised framework for relaxing combinatorial optimization
problems encoded through a specific graph structure and loss, reflecting
dependencies between the problem's variables. While the framework has yielded
promising results in various combinatorial problems, we show that the
performance of PI-GNNs systematically plummets with an increasing density of
the combinatorial problem graphs. Our analysis reveals an interesting phase
transition in the PI-GNNs' training dynamics, associated with degenerate
solutions for the denser problems, highlighting a discrepancy between the
relaxed, real-valued model outputs and the binary-valued problem solutions. To
address the discrepancy, we propose principled alternatives to the naive
strategy used in PI-GNNs by building on insights from fuzzy logic and binarized
neural networks. Our experiments demonstrate that the portfolio of proposed
methods significantly improves the performance of PI-GNNs in increasingly dense
settings.

</details>


### [177] [Bayesian Optimization for Molecules Should Be Pareto-Aware](https://arxiv.org/abs/2507.13704)
*Anabel Yong,Austin Tripp,Layla Hosseini-Gerami,Brooks Paige*

Main category: cs.LG

TL;DR: EHVI在分子优化中优于标量化EI。


<details>
  <summary>Details</summary>
Motivation: 探讨MOBO在分子设计中的经验优势，并与标量化方法进行比较。

Method: 通过在三个分子优化任务中，使用相同的GP代理和分子表示，将EHVI（一种基于Pareto的MOBO策略）与固定权重标量化EI进行基准测试。

Result: EHVI在帕累托前沿覆盖率、收敛速度和化学多样性方面持续优于标量化EI，即使是强确定性标量化方法在低数据量情况下表现也可能不佳。

Conclusion: EHVI在MOBO中表现优于标量化EI，尤其在数据稀疏和需要权衡的场景下，为从头分子优化提供了实际优势。

Abstract: Multi-objective Bayesian optimization (MOBO) provides a principled framework
for navigating trade-offs in molecular design. However, its empirical
advantages over scalarized alternatives remain underexplored. We benchmark a
simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --
against a simple fixed-weight scalarized baseline using Expected Improvement
(EI), under a tightly controlled setup with identical Gaussian Process
surrogates and molecular representations. Across three molecular optimization
tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front
coverage, convergence speed, and chemical diversity. While scalarization
encompasses flexible variants -- including random or adaptive schemes -- our
results show that even strong deterministic instantiations can underperform in
low-data regimes. These findings offer concrete evidence for the practical
advantages of Pareto-aware acquisition in de novo molecular optimization,
especially when evaluation budgets are limited and trade-offs are nontrivial.

</details>


### [178] [Learning Deformable Body Interactions With Adaptive Spatial Tokenization](https://arxiv.org/abs/2507.13707)
*Hao Wang,Yu Liu,Daniel Biggs,Haoru Wang,Jiandong Yu,Ping Huang*

Main category: cs.LG

TL;DR: AST方法使用网格和注意力机制来高效模拟可变形物体，解决了现有方法的计算瓶颈，并在大规模模拟中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决基于学习的方法在模拟可变形物体交互时遇到的可扩展性问题，特别是为应对需要动态创建成对全局边而导致的计算密集型和不切实际的瓶颈。

Method: 通过将模拟空间划分为网格单元，并将非结构化网格映射到结构化网格上，利用图神经网络（GNNs）和自注意力机制来预测潜在空间中的下一个状态。

Result: 该方法在模拟可变形物体交互方面显著优于现有最先进方法，并在处理超过10万个节点的网格的大规模模拟中表现出有效性。

Conclusion: 所提出的自适应空间标记化（AST）方法在模拟可变形物体交互方面显著优于现有方法，并且能够处理大规模模拟，超越了现有方法的计算限制。此外，还贡献了一个新的大规模数据集以支持该领域未来的研究。

Abstract: Simulating interactions between deformable bodies is vital in fields like
material science, mechanical design, and robotics. While learning-based methods
with Graph Neural Networks (GNNs) are effective at solving complex physical
systems, they encounter scalability issues when modeling deformable body
interactions. To model interactions between objects, pairwise global edges have
to be created dynamically, which is computationally intensive and impractical
for large-scale meshes. To overcome these challenges, drawing on insights from
geometric representations, we propose an Adaptive Spatial Tokenization (AST)
method for efficient representation of physical states. By dividing the
simulation space into a grid of cells and mapping unstructured meshes onto this
structured grid, our approach naturally groups adjacent mesh nodes. We then
apply a cross-attention module to map the sparse cells into a compact,
fixed-length embedding, serving as tokens for the entire physical state.
Self-attention modules are employed to predict the next state over these tokens
in latent space. This framework leverages the efficiency of tokenization and
the expressive power of attention mechanisms to achieve accurate and scalable
simulation results. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches in modeling deformable
body interactions. Notably, it remains effective on large-scale simulations
with meshes exceeding 100,000 nodes, where existing methods are hindered by
computational limitations. Additionally, we contribute a novel large-scale
dataset encompassing a wide range of deformable body interactions to support
future research in this area.

</details>


### [179] [Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods](https://arxiv.org/abs/2507.13716)
*Danilo Avola,Andrea Bernardini,Giancarlo Crocetti,Andrea Ladogana,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本研究对用于帕金森病诊断的机器学习和深度学习模型进行了基准测试，发现CNN-LSTM模型表现最佳，但XGBoost等传统模型也表现出色，为未来的研究提供了参考框架。


<details>
  <summary>Details</summary>
Motivation: 帕金森病（PD）的早期诊断对其有效的临床干预至关重要。脑电图（EEG）作为一种无创且经济的检测PD相关神经变化的方法，其在开发可靠的自动化诊断模型方面仍面临挑战。本研究旨在为开发有效的学习系统奠定基础，并确定哪种方法能产生最佳结果。

Method: 本研究对传统机器学习和深度学习模型进行了系统的基准测试，使用公开的oddball任务数据集对帕金森病进行分类。实施了统一的七步预处理流程，并应用了持续的受试者交叉验证和评估标准，以确保模型的可比性。

Result: 基线深度学习架构，特别是CNN-LSTM模型，与其它深度学习架构相比，在捕捉长期时间依赖性方面表现出最佳性能。然而，包括XGBoost在内的几种传统分类器也提供了强大的预测准确性和校准的决策边界。

Conclusion: 与其它深度学习架构相比，基于CNN-LSTM的模型在捕捉长期时间依赖性方面表现出最佳性能，而XGBoost等传统分类器也提供了强大的预测准确性和校准的决策边界。

Abstract: Parkinson's Disease PD is a progressive neurodegenerative disorder that
affects motor and cognitive functions with early diagnosis being critical for
effective clinical intervention Electroencephalography EEG offers a noninvasive
and costeffective means of detecting PDrelated neural alterations yet the
development of reliable automated diagnostic models remains a challenge In this
study we conduct a systematic benchmark of traditional machine learning ML and
deep learning DL models for classifying PD using a publicly available oddball
task dataset Our aim is to lay the groundwork for developing an effective
learning system and to determine which approach produces the best results We
implement a unified sevenstep preprocessing pipeline and apply consistent
subjectwise crossvalidation and evaluation criteria to ensure comparability
across models Our results demonstrate that while baseline deep learning
architectures particularly CNNLSTM models achieve the best performance compared
to other deep learning architectures underlining the importance of capturing
longrange temporal dependencies several traditional classifiers such as XGBoost
also offer strong predictive accuracy and calibrated decision boundaries By
rigorously comparing these baselines our work provides a solid reference
framework for future studies aiming to develop and evaluate more complex or
specialized architectures Establishing a reliable set of baseline results is
essential to contextualize improvements introduced by novel methods ensuring
scientific rigor and reproducibility in the evolving field of EEGbased
neurodiagnostics

</details>


### [180] [Bi-GRU Based Deception Detection using EEG Signals](https://arxiv.org/abs/2507.13718)
*Danilo Avola,Muhammad Yasir Bilal,Emad Emam,Cristina Lakasz,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本研究提出了一种使用Bi-GRU神经网络分析脑电图信号的深度学习方法，以检测欺骗行为，准确率达到97%。


<details>
  <summary>Details</summary>
Motivation: 欺骗检测在安全、心理学和法医学等领域是一个重大挑战。

Method: 提出了一种使用双向门控循环单元（Bi-GRU）神经网络对脑电图（EEG）样本进行二元分类的深度学习方法。

Result: 所提出的模型在Bag-of-Lies数据集上达到了97%的测试准确率，并在两个类别中都取得了高精确率、召回率和F1分数。

Conclusion: 使用双向时间建模进行基于脑电图的欺骗检测是有效的，并且有潜力用于实时应用。

Abstract: Deception detection is a significant challenge in fields such as security,
psychology, and forensics. This study presents a deep learning approach for
classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)
signals from the Bag-of-Lies dataset, a multimodal corpus designed for
naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit
(Bi-GRU) neural network was trained to perform binary classification of EEG
samples. The model achieved a test accuracy of 97\%, along with high precision,
recall, and F1-scores across both classes. These results demonstrate the
effectiveness of using bidirectional temporal modeling for EEG-based deception
detection and suggest potential for real-time applications and future
exploration of advanced neural architectures.

</details>


### [181] [Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion](https://arxiv.org/abs/2507.13721)
*Zizhao Zhang,Tianxiang Zhao,Yu Sun,Liping Sun,Jichuan Kang*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的混合特征融合框架和改进的布谷鸟搜索算法，用于构建自主货船故障模式的图结构数据集，提高了文献检索效率和故障预测准确性。


<details>
  <summary>Details</summary>
Motivation: 为了应对自主货船（ACS）中由组件故障引起的级联反应以及应急决策中的不确定性所带来的挑战。

Method: 提出了一种新颖的混合特征融合框架，用于构建故障模式的图结构数据集。通过改进的布谷鸟搜索算法（HN-CSA）提高了文献检索效率（相比NSGA-II和CSA分别提高了7.1%和3.4%）。构建了分层特征融合框架，使用Word2Vec对子系统/组件特征进行编码，使用BERT-KPCA处理故障模式/原因，并使用Sentence-BERT量化故障影响与应急决策之间的语义关联。该数据集涵盖12个系统，1,262个故障模式和6,150个传播路径。

Result: GATE-GNN模型的分类准确率达到0.735，与现有基准相当。轮廓系数为0.641，表明特征具有高度可区分性。在标签预测结果中，岸基气象服务系统达到了0.93的F1分数，显示出高预测准确性。

Conclusion: 该研究为自主货船（ACS）的故障分析提供了坚实的基础，并为故障诊断、风险评估和智能决策系统提供了可靠的支持。

Abstract: To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.

</details>


### [182] [Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics](https://arxiv.org/abs/2507.13727)
*René Heinrich,Lukas Rauch,Bernhard Sick,Christoph Scholz*

Main category: cs.LG

TL;DR: 对抗性训练能提升音频分类模型在分布偏移和对抗性攻击下的表现。


<details>
  <summary>Details</summary>
Motivation: 探索对抗性训练对音频分类模型在面对数据分布偏移时的泛化能力的影响，以及其对提高模型鲁棒性的作用。

Method: 研究了两种对抗性训练策略（基于输出空间和嵌入空间的攻击）在ConvNeXt和AudioProtoPNet两种模型架构上的应用，并评估了其在具有显著分布偏移的鸟类声音分类基准上的表现。

Result: 对抗性训练（尤其是基于输出空间的攻击）使模型的干净测试数据性能平均提高了10.5%，同时增强了模型的对抗鲁棒性。对于AudioProtoPNet，还评估了其学习到的原型在面对嵌入空间攻击时的稳定性。

Conclusion: 对抗性训练，特别是基于输出空间的攻击，可以提高音频分类模型在面对分布偏移和对抗性攻击时的泛化能力和鲁棒性。

Abstract: Adversarial training is a promising strategy for enhancing model robustness
against adversarial attacks. However, its impact on generalization under
substantial data distribution shifts in audio classification remains largely
unexplored. To address this gap, this work investigates how different
adversarial training strategies improve generalization performance and
adversarial robustness in audio classification. The study focuses on two model
architectures: a conventional convolutional neural network (ConvNeXt) and an
inherently interpretable prototype-based model (AudioProtoPNet). The approach
is evaluated using a challenging bird sound classification benchmark. This
benchmark is characterized by pronounced distribution shifts between training
and test data due to varying environmental conditions and recording methods, a
common real-world challenge. The investigation explores two adversarial
training strategies: one based on output-space attacks that maximize the
classification loss function, and another based on embedding-space attacks
designed to maximize embedding dissimilarity. These attack types are also used
for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses
the stability of its learned prototypes under targeted embedding-space attacks.
Results show that adversarial training, particularly using output-space
attacks, improves clean test data performance by an average of 10.5% relative
and simultaneously strengthens the adversarial robustness of the models. These
findings, although derived from the bird sound domain, suggest that adversarial
training holds potential to enhance robustness against both strong distribution
shifts and adversarial attacks in challenging audio classification settings.

</details>


### [183] [SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification](https://arxiv.org/abs/2507.13741)
*Shangyou Wang,Zezhong Ding,Xike Xie*

Main category: cs.LG

TL;DR: SamGoG是一种基于采样的图图（GoG）学习框架，可以解决图分类中的类别不平衡和图大小不平衡问题，同时提高训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的图数据常常存在类别不平衡和图大小不平衡这两种关键形式的不平衡，这会影响学习过程并降低模型性能。现有方法通常只解决其中一种不平衡问题，或者需要高昂的计算成本。

Method: SamGoG通过一种高效的基于重要性的采样机制构建多个图图（GoG），并进行顺序训练。该采样机制结合了可学习的成对相似性和自适应的GoG节点度，以增强边同质性，从而提高下游模型的质量。

Result: SamGoG在基准数据集上的大量实验表明，该方法实现了最先进的性能，准确率最高提高了15.66%，同时训练速度加快了6.7倍。

Conclusion: SamGoG通过一种高效的基于采样的图图（GoG）学习框架，能够有效缓解类别不平衡和图大小不平衡问题，并能与各种下游GNN无缝集成，从而在图分类任务中实现高效适应。

Abstract: Graph Neural Networks (GNNs) have shown remarkable success in graph
classification tasks by capturing both structural and feature-based
representations. However, real-world graphs often exhibit two critical forms of
imbalance: class imbalance and graph size imbalance. These imbalances can bias
the learning process and degrade model performance. Existing methods typically
address only one type of imbalance or incur high computational costs. In this
work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning
framework that effectively mitigates both class and graph size imbalance.
SamGoG constructs multiple GoGs through an efficient importance-based sampling
mechanism and trains on them sequentially. This sampling mechanism incorporates
the learnable pairwise similarity and adaptive GoG node degree to enhance edge
homophily, thus improving downstream model quality. SamGoG can seamlessly
integrate with various downstream GNNs, enabling their efficient adaptation for
graph classification tasks. Extensive experiments on benchmark datasets
demonstrate that SamGoG achieves state-of-the-art performance with up to a
15.66% accuracy improvement with 6.7$\times$ training acceleration.

</details>


### [184] [Search-Optimized Quantization in Biomedical Ontology Alignment](https://arxiv.org/abs/2507.13742)
*Oussama Bouaggad,Natalia Grabar*

Main category: cs.LG

TL;DR: 本文提出了一种创新的模型优化方法，通过集成先进的Transformer模型、Microsoft Olive和Intel优化工具，在保持性能的同时，显著提高了推理速度并降低了内存消耗，为资源受限环境下的AI模型部署提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 在人工智能领域，随着模型规模和计算需求的不断增长，在资源受限的环境（如边缘设备）中部署这些模型面临着能耗、内存使用和延迟等严峻挑战。因此，需要有效的模型优化技术来应对这些挑战。

Method: 本文首先提出了一种基于监督式Transformer模型的本体对齐方法，该方法通过计算生物医学通俗词汇与UMLS元数据库之间的余弦语义相似度来实现。然后，研究者利用Microsoft Olive在ONNX Runtime后端上搜索不同的执行提供商（EPs）以实现目标优化，并结合Intel Neural Compressor和IPEX进行动态量化。

Result: 通过优化过程，在DEFT 2020评估活动的两个任务上取得了新的最先进成果，平均推理速度提高了20倍，内存使用量减少了约70%，同时保持了性能指标不变。

Conclusion: 本文提出了一种系统化的本体对齐方法，利用监督式、基于Transformer的模型，通过生物医学通俗词汇与统一医学语言系统（UMLS）元数据库之间的基于余弦的语义相似性来实现。通过使用Microsoft Olive和Intel Neural Compressor及IPEX（Intel Extension for PyTorch）进行动态量化，实现了20倍的平均推理加速和约70%的内存使用量减少，同时保持了性能指标不变，并在DEFT 2020评估活动的两个任务上取得了新的最先进成果。

Abstract: In the fast-moving world of AI, as organizations and researchers develop more
advanced models, they face challenges due to their sheer size and computational
demands. Deploying such models on edge devices or in resource-constrained
environments adds further challenges related to energy consumption, memory
usage and latency. To address these challenges, emerging trends are shaping the
future of efficient model optimization techniques. From this premise, by
employing supervised state-of-the-art transformer-based models, this research
introduces a systematic method for ontology alignment, grounded in cosine-based
semantic similarity between a biomedical layman vocabulary and the Unified
Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to
search for target optimizations among different Execution Providers (EPs) using
the ONNX Runtime backend, followed by an assembled process of dynamic
quantization employing Intel Neural Compressor and IPEX (Intel Extension for
PyTorch). Through our optimization process, we conduct extensive assessments on
the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new
state-of-the-art in both. We retain performance metrics intact, while attaining
an average inference speed-up of 20x and reducing memory usage by approximately
70%.

</details>


### [185] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
*Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Mingyue Zheng,Qian Shi*

Main category: cs.LG

TL;DR: 提出PIF模型用于分子生成，克服了BFNs的局限性，并在药物设计中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了克服贝叶斯流网络（BFNs）在设计灵活的分布变换路径方面的局限性，并探索更简单、更高效的基于参数空间模型。

Method: 提出了一种新颖的参数插值流（PIF）模型，并给出了详细的理论基础、训练和推理过程，然后开发了用于结构药物设计的MolPIF。

Result: MolPIF在结构药物设计任务中表现出优于基线模型的性能，并在多种评估指标上取得了更好的结果。

Conclusion: 该研究提出了参数插值流（PIF）模型，并在分子生成领域取得了优于基线模型的性能，证明了基于参数空间生成模型的有效性，并为模型设计提供了新思路。

Abstract: Advances in deep learning for molecular generation show promise in
accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown
impressive performance across diverse chemical tasks, with their success often
ascribed to the paradigm of modeling in a low-variance parameter space.
However, the Bayesian inference-based strategy imposes limitations on designing
more flexible distribution transformation pathways, making it challenging to
adapt to diverse data distributions and varied task requirements. Furthermore,
the potential for simpler, more efficient parameter-space-based models is
unexplored. To address this, we propose a novel Parameter Interpolation Flow
model (named PIF) with detailed theoretical foundation, training, and inference
procedures. We then develop MolPIF for structure-based drug design,
demonstrating its superior performance across diverse metrics compared to
baselines. This work validates the effectiveness of parameter-space-based
generative modeling paradigm for molecules and offers new perspectives for
model design.

</details>


### [186] [Dual-Center Graph Clustering with Neighbor Distribution](https://arxiv.org/abs/2507.13765)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Li Jin,Liqiang Nie*

Main category: cs.LG

TL;DR: DCGC是一种新的图聚类方法，通过利用邻域分布信息和双中心优化来克服现有方法的局限性，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的图聚类方法在处理无监督学习的挑战时，虽然目标导向的聚类技术取得了显著成果，但基于伪标签的对比学习方法所使用的伪标签作为监督信号并不可靠。此外，现有方法仅利用特征来构建单一目标分布进行单中心优化，这导致了不完整且不可靠的指导。

Method: 提出了一种基于邻域分布性质的双中心图聚类（DCGC）方法，该方法包括邻域分布表示学习和双中心优化两个关键部分。在表示学习中，利用邻域分布作为监督信号来挖掘困难负样本，以增强表示学习的有效性。在优化过程中，引入了邻域分布中心和特征中心，共同构建双目标分布进行双中心优化。

Result: 大量实验和分析表明，所提出的DCGC方法具有优越的性能和有效性。

Conclusion: 所提出的双中心图聚类（DCGC）方法在邻域分布性质的基础上，通过结合邻域分布和特征中心进行双中心优化，并利用邻域分布作为监督信号挖掘困难负样本，从而提高了表示学习的效果。

Abstract: Graph clustering is crucial for unraveling intricate data structures, yet it
presents significant challenges due to its unsupervised nature. Recently,
goal-directed clustering techniques have yielded impressive results, with
contrastive learning methods leveraging pseudo-label garnering considerable
attention. Nonetheless, pseudo-label as a supervision signal is unreliable and
existing goal-directed approaches utilize only features to construct a
single-target distribution for single-center optimization, which lead to
incomplete and less dependable guidance. In our work, we propose a novel
Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution
properties, which includes representation learning with neighbor distribution
and dual-center optimization. Specifically, we utilize neighbor distribution as
a supervision signal to mine hard negative samples in contrastive learning,
which is reliable and enhances the effectiveness of representation learning.
Furthermore, neighbor distribution center is introduced alongside feature
center to jointly construct a dual-target distribution for dual-center
optimization. Extensive experiments and analysis demonstrate superior
performance and effectiveness of our proposed method.

</details>


### [187] [Self-supervised learning on gene expression data](https://arxiv.org/abs/2507.13912)
*Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar*

Main category: cs.LG

TL;DR: 研究了三种自监督学习方法在散装基因表达数据表型预测中的应用，发现它们优于传统监督方法，并减少了对标注数据的需求。


<details>
  <summary>Details</summary>
Motivation: 为克服传统监督学习方法在基因表达数据中需要大量标注数据的限制，探索自监督学习在表型预测中的应用。

Method: 本研究调查了三种基于不同方法、最先进的自监督学习方法在散装基因表达数据上的应用，以评估它们利用数据固有结构和生成用于下游预测任务的定性表征的能力。

Result: 所选的自监督学习方法能够有效捕捉复杂信息并提高表型预测准确性，表现优于传统监督模型。

Conclusion: 自监督学习方法在基因表达数据分析中表现出优于传统监督学习模型的潜力，能够有效捕捉复杂信息并提高表型预测准确性，同时显著减少对标注数据的依赖。

Abstract: Predicting phenotypes from gene expression data is a crucial task in
biomedical research, enabling insights into disease mechanisms, drug responses,
and personalized medicine. Traditional machine learning and deep learning rely
on supervised learning, which requires large quantities of labeled data that
are costly and time-consuming to obtain in the case of gene expression data.
Self-supervised learning has recently emerged as a promising approach to
overcome these limitations by extracting information directly from the
structure of unlabeled data. In this study, we investigate the application of
state-of-the-art self-supervised learning methods to bulk gene expression data
for phenotype prediction. We selected three self-supervised methods, based on
different approaches, to assess their ability to exploit the inherent structure
of the data and to generate qualitative representations which can be used for
downstream predictive tasks. By using several publicly available gene
expression datasets, we demonstrate how the selected methods can effectively
capture complex information and improve phenotype prediction accuracy. The
results obtained show that self-supervised learning methods can outperform
traditional supervised models besides offering significant advantage by
reducing the dependency on annotated data. We provide a comprehensive analysis
of the performance of each method by highlighting their strengths and
limitations. We also provide recommendations for using these methods depending
on the case under study. Finally, we outline future research directions to
enhance the application of self-supervised learning in the field of gene
expression data analysis. This study is the first work that deals with bulk
RNA-Seq data and self-supervised learning.

</details>


### [188] [Reframing attention as a reinforcement learning problem for causal discovery](https://arxiv.org/abs/2507.13920)
*Turan Orujlu,Christian Gumbsch,Martin V. Butz,Charley M Wu*

Main category: cs.LG

TL;DR: 本研究提出了因果过程框架和模型，用于在强化学习中推断动态因果关系，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在弥合因果框架与深度强化学习之间的差距，并解决现有神经因果模型忽略动态因果相互作用的问题。

Method: 本研究将因果推断重新表述为强化学习任务，通过强化学习智能体来构建因果图假设，并借鉴 Transformer 的注意力机制来建立单元之间的联系。

Result: 在强化学习环境中，本研究提出的方法在因果表示学习和智能体性能方面优于当前替代方法，并能恢复动态因果过程图。

Conclusion: 本研究提出了因果过程框架和因果过程模型，用于表示动态因果结构假设，并在强化学习设置中实现了 Transformer 的注意力机制，以从视觉观察中推断可解释的因果过程。研究结果表明，该方法在因果表示学习和智能体性能方面优于现有方法，并能恢复动态因果过程图。

Abstract: Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.

</details>


### [189] [MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space](https://arxiv.org/abs/2507.13950)
*Jingbo Liang,Bruna Jacobson*

Main category: cs.LG

TL;DR: MoDyGAN利用MD模拟和GANs，将蛋白质结构表示为2D矩阵，有效探索蛋白质构象空间，生成新的构象，并使潜在空间插值与SMD结果一致。


<details>
  <summary>Details</summary>
Motivation: 为了解决计算生物学中由于基于物理的动态模拟的高计算成本而广泛探索蛋白质构象景观的挑战。

Method: 提出了一种名为MoDyGAN的新型框架，该框架结合了分子动力学（MD）模拟和生成对抗网络（GANs）。MoDyGAN包含一个生成器，将高斯分布映射到MD衍生的蛋白质轨迹，以及一个包含集成学习和双判别器的精炼模块，用于提高生成构象的可信度。其核心是一种创新的表示技术，将3D蛋白质结构可逆地转换为2D矩阵，从而能够应用基于图像的GANs架构。

Result: 使用三种刚性蛋白质证明了MoDyGAN可以生成新的合理构象。使用十聚丙氨酸作为案例研究，表明潜在空间的插值与গতির分子动力学（SMD）模拟获得的轨迹密切一致。

Conclusion: 该研究提出的MoDyGAN框架通过将蛋白质结构表示为类图像数据，并结合MD模拟和GANs，能够有效地探索蛋白质构象空间，生成新的合理构象，并使潜在空间的插值与SMD模拟结果保持一致。

Abstract: Extensively exploring protein conformational landscapes remains a major
challenge in computational biology due to the high computational cost involved
in dynamic physics-based simulations. In this work, we propose a novel
pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and
generative adversarial networks (GANs) to explore protein conformational
spaces. MoDyGAN contains a generator that maps Gaussian distributions into
MD-derived protein trajectories, and a refinement module that combines ensemble
learning with a dual-discriminator to further improve the plausibility of
generated conformations. Central to our approach is an innovative
representation technique that reversibly transforms 3D protein structures into
2D matrices, enabling the use of advanced image-based GAN architectures. We use
three rigid proteins to demonstrate that MoDyGAN can generate plausible new
conformations. We also use deca-alanine as a case study to show that
interpolations within the latent space closely align with trajectories obtained
from steered molecular dynamics (SMD) simulations. Our results suggest that
representing proteins as image-like data unlocks new possibilities for applying
advanced deep learning techniques to biomolecular simulation, leading to an
efficient sampling of conformational states. Additionally, the proposed
framework holds strong potential for extension to other complex 3D structures.

</details>


### [190] [Robust Anomaly Detection with Graph Neural Networks using Controllability](https://arxiv.org/abs/2507.13954)
*Yifan Wei,Anwar Said,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 通过整合节点平均可控性，改进了图神经网络在稀疏、不平衡数据集上的异常检测能力。


<details>
  <summary>Details</summary>
Motivation: 异常检测在复杂域中面临挑战，需要大量标记数据，且异常样本与良性样本的比例不平衡。图模型虽有潜力，但异常数据稀缺，需要创新策略。本研究提出假设，通过平均可控性量化节点影响，可显著提升异常检测性能。

Method: 提出两种新方法将平均可控性整合到基于图的学习框架中：1. 使用平均可控性作为边权重；2. 将其编码为单热边属性向量。

Result: 在真实和合成网络上进行的严格评估显示，所提出的方法在识别异常方面表现出优于六种最先进基线方法的性能，证明了可控性度量在提升图机器学习模型性能中的关键作用。

Conclusion: 该研究表明，将平均可控性作为附加指标整合到图机器学习模型中，可以有效应对稀疏和不平衡数据集中的异常检测挑战，并显著提高检测性能。

Abstract: Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.

</details>


### [191] [Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs](https://arxiv.org/abs/2507.13959)
*Eli Verwimp,Gustav Ryberg Smidt,Hendrik Hameeuw,Katrien De Graef*

Main category: cs.LG

TL;DR: 本文研究了机器学习在楔形文字符号分类中的应用，分析了数据变异性对模型性能的影响，并使用ResNet50模型取得了87.1%的top-1准确率。


<details>
  <summary>Details</summary>
Motivation: 由于楔形文字符号存在显著的变异性，这使得在一个数据集上训练的ML模型在另一个数据集上可能表现不佳，因此本文研究了这些差异对模型性能的影响。

Method: 本文描述了用于楔形文字符号分类的机器学习（ML）技术的训练和评估，并对ResNet50模型进行了分析。

Result: ResNet50模型在至少有20个实例的符号上，取得了87.1%的top-1准确率和96.5%的top-5准确率。

Conclusion: 该研究旨在为未来的楔形文字符号分类任务奠定坚实的基础，并期望影响未来的数据采集标准。

Abstract: The work in this paper describes the training and evaluation of machine
learning (ML) techniques for the classification of cuneiform signs. There is a
lot of variability in cuneiform signs, depending on where they come from, for
what and by whom they were written, but also how they were digitized. This
variability makes it unlikely that an ML model trained on one dataset will
perform successfully on another dataset. This contribution studies how such
differences impact that performance. Based on our results and insights, we aim
to influence future data acquisition standards and provide a solid foundation
for future cuneiform sign classification tasks. The ML model has been trained
and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary
texts inscribed on clay tablets originating from three Mesopotamian cities
(Nippur, D\=ur-Abie\v{s}uh and Sippar). The presented and analysed model is
ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for
signs with at least 20 instances. As these automatic classification results are
the first on Old Babylonian texts, there are currently no comparable results.

</details>


### [192] [Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks](https://arxiv.org/abs/2507.13992)
*Jagruti Patel,Thomas A. W. Bolton,Mikkel Schöttner,Anjali Tarun,Sebastien Tourbier,Yasser Alemàn-Gòmez,Jonas Richiardi,Patric Hagmann*

Main category: cs.LG

TL;DR: 为解决神经影像学中小样本量和多中心研究中的数据异质性问题，提出了一种无需元数据或旅行受试者的图卷积自编码器协调框架，并在模拟数据中验证了其在保留拓扑结构和个体特征方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 神经影像学（特别是结构连接组学）研究中的小样本量限制了可靠生物标志物的发展，而大规模研究则面临扫描仪异质性导致的采集偏差问题。现有的协调方法依赖于详细的元数据或旅行受试者，或忽略了SC的图拓扑结构。

Method: 提出了一种无需元数据或旅行受试者即可跨不同采集站点协调SC的站点条件深度协调框架，并测试了三种深度架构（全连接自编码器、卷积自编码器和图卷积自编码器）与基于线性回归的基线的性能。

Result: 图自编码器在保留拓扑结构和个体特征方面优于非图模型，尽管线性回归基线在数值上表现最佳，但缺乏实际应用性。结果表明，模型架构在SC协调中起着关键作用，基于图的方法更适合结构感知和领域可泛化的SC协调。

Conclusion: 图卷积自编码器在结构连接组学（SC）协调中表现出优越的拓扑结构和个体层面特征保留能力，使其成为大规模多中心研究中结构感知的、领域可泛化的SC协调的有力方法。

Abstract: Small sample sizes in neuroimaging in general, and in structural connectome
(SC) studies in particular limit the development of reliable biomarkers for
neurological and psychiatric disorders - such as Alzheimer's disease and
schizophrenia - by reducing statistical power, reliability, and
generalizability. Large-scale multi-site studies have exist, but they have
acquisition-related biases due to scanner heterogeneity, compromising imaging
consistency and downstream analyses. While existing SC harmonization methods -
such as linear regression (LR), ComBat, and deep learning techniques - mitigate
these biases, they often rely on detailed metadata, traveling subjects (TS), or
overlook the graph-topology of SCs. To address these limitations, we propose a
site-conditioned deep harmonization framework that harmonizes SCs across
diverse acquisition sites without requiring metadata or TS that we test in a
simulated scenario based on the Human Connectome Dataset. Within this
framework, we benchmark three deep architectures - a fully connected
autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a
top-performing LR baseline. While non-graph models excel in edge-weight
prediction and edge existence detection, the graph AE demonstrates superior
preservation of topological structure and subject-level individuality, as
reflected by graph metrics and fingerprinting accuracy, respectively. Although
the LR baseline achieves the highest numerical performance by explicitly
modeling acquisition parameters, it lacks applicability to real-world
multi-site use cases as detailed acquisition metadata is often unavailable. Our
results highlight the critical role of model architecture in SC harmonization
performance and demonstrate that graph-based approaches are particularly
well-suited for structure-aware, domain-generalizable SC harmonization in
large-scale multi-site SC studies.

</details>


### [193] [ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies](https://arxiv.org/abs/2507.13998)
*Itay Katav,Aryeh Kontorovich*

Main category: cs.LG

TL;DR: 提出ParallelTime架构，通过动态加权机制ParallelTime Weighter优化了Transformer和Mamba结合在时间序列预测中的表现，实现了更优的长期和短期依赖关系处理，并在准确性、效率和鲁棒性上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有将Transformer和Mamba结合用于时间序列预测的方法，在处理短期和长期依赖关系时赋予了相同的权重，但研究发现这种平均加权并非最优。作者认为，根据输入和模型知识动态调整长期和短期依赖关系的权重，能更好地进行时间序列预测。

Method: 提出了一种名为ParallelTime Weighter的动态加权机制，该机制能够为每个token计算长期和短期依赖关系的相互依赖权重。在此基础上，构建了ParallelTime架构，将该机制整合其中，并结合了Transformer（用于捕捉短期依赖）和Mamba（用于捕捉长期依赖）的优点。

Result: ParallelTime架构在多个基准测试中表现出色，实现了最先进的性能。与现有方法相比，它具有更低的计算量（FLOPs）、更少的参数量、更好的可扩展性（适用于更长的预测范围）以及更强的鲁棒性。

Conclusion: 该研究提出了ParallelTime架构，通过引入动态加权机制ParallelTime Weighter，优化了结合Transformer和Mamba处理多元时间序列预测的性能。该机制为每个时间序列token动态计算长期和短期依赖关系的权重，而非简单平均。实验结果表明，ParallelTime架构在准确性、计算量、参数量、预测范围和鲁棒性方面均优于现有方法，为未来基于Attention-Mamba模型在时间序列预测领域的发展提供了新的方向。

Abstract: Modern multivariate time series forecasting primarily relies on two
architectures: the Transformer with attention mechanism and Mamba. In natural
language processing, an approach has been used that combines local window
attention for capturing short-term dependencies and Mamba for capturing
long-term dependencies, with their outputs averaged to assign equal weight to
both. We find that for time-series forecasting tasks, assigning equal weight to
long-term and short-term dependencies is not optimal. To mitigate this, we
propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates
interdependent weights for long-term and short-term dependencies for each token
based on the input and the model's knowledge. Furthermore, we introduce the
ParallelTime architecture, which incorporates the ParallelTime Weighter
mechanism to deliver state-of-the-art performance across diverse benchmarks.
Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer
parameters, scales effectively to longer prediction horizons, and significantly
outperforms existing methods. These advances highlight a promising path for
future developments of parallel Attention-Mamba in time series forecasting. The
implementation is readily available at:
\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub

</details>


### [194] [On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes](https://arxiv.org/abs/2507.14005)
*Mathieu Godbout,Audrey Durand*

Main category: cs.LG

TL;DR: 动态规划方法在寻找最优策略时可能因“风险分配一致性约束”失效而失败，优化单一策略存在局限性。


<details>
  <summary>Details</summary>
Motivation: 近期研究发现，基于对偶重构的动态规划（DP）方法在寻找马尔可夫决策过程（MDP）的静态条件风险价值（CVaR）最优策略时可能会失败，但其根本原因尚不明确。本研究旨在深入探究并阐明这一失败现象的根源，并进一步分析相关评估和优化过程的局限性。

Method: 本研究通过将给定策略的静态CVaR评估重构为两个独立的最小化问题来分析问题。研究引入了“风险分配一致性约束”的概念，并证明当这些约束的交集为空时，会导致评估错误。通过量化评估误差为CVaR评估差距，并证明在对偶CVaR DP优化中观察到的问题源于策略具有非零CVaR评估差距，从而解释了优化失败的原因。此外，研究利用提出的风险分配视角，证明了通过对偶CVaR分解寻找单一、统一最优策略的搜索存在根本性局限。

Result: 研究表明，CVaR评估的准确性依赖于一组“风险分配一致性约束”的满足，当这些约束的交集为空时，会导致评估误差，即CVaR评估差距。研究还发现，在对偶CVaR DP优化中出现的评估问题，是因为返回的策略具有非零的CVaR评估差距。最重要的是，研究证明了通过对偶CVaR分解寻找单一、统一最优策略存在根本性局限，并举例说明了在某些MDP中不存在能在所有初始风险水平下都最优的单一策略。

Conclusion: 该研究揭示了基于对偶重构的马尔可夫决策过程（MDP）动态规划（DP）方法在静态条件风险价值（CVaR）最优策略搜索中的失败根源在于风险分配一致性约束的交集为空，这会导致CVaR评估中的偏差。研究还证明，通过对偶CVaR分解寻找单一、统一最优策略的方法存在根本性局限，并提供了一个具体案例，说明在某些MDP中不存在能在所有初始风险水平下都最优的单一策略。

Abstract: Recent work has shown that dynamic programming (DP) methods for finding
static CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when
based on the dual formulation, yet the root cause for the failure has remained
unclear. We expand on these findings by shifting focus from policy optimization
to the seemingly simpler task of policy evaluation. We show that evaluating the
static CVaR of a given policy can be framed as two distinct minimization
problems. For their solutions to match, a set of ``risk-assignment consistency
constraints'' must be satisfied, and we demonstrate that the intersection of
the constraints being empty is the source of previously observed evaluation
errors. Quantifying the evaluation error as the CVaR evaluation gap, we then
demonstrate that the issues observed when optimizing over the dual-based CVaR
DP are explained by the returned policy having a non-zero CVaR evaluation gap.
We then leverage our proposed risk-assignment perspective to prove that the
search for a single, uniformly optimal policy via on the dual CVaR
decomposition is fundamentally limited, identifying an MDP where no single
policy can be optimal across all initial risk levels.

</details>


### [195] [DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis](https://arxiv.org/abs/2507.14038)
*Aileen Luo,Tao Zhou,Ming Du,Martin V. Holt,Andrej Singer,Mathew J. Cherukara*

Main category: cs.LG

TL;DR: DONUT是一种新的物理感知神经网络，可以通过纳米束X射线衍射数据实时提取晶格应变和取向，且无需预训练或标记数据。


<details>
  <summary>Details</summary>
Motivation: 为了解决扫描X射线纳米衍射显微镜在实时分析中存在的伪影和计算需求问题，以及光束发散与样品局部结构卷积的挑战。

Method: DONUT是一种结合了物理知识的神经网络，通过可微分几何衍射模型直接作用于其架构，以快速、自动地分析纳米束衍射数据。

Result: 实验证明，DONUT的效率比传统拟合方法高出200多倍，能够准确地提取数据中的所有特征。

Conclusion: DONUT克服了X射线科学中有监督机器学习的根本限制，无需标记数据集或预训练即可实时预测晶格应变和取向。

Abstract: Coherent X-ray scattering techniques are critical for investigating the
fundamental structural properties of materials at the nanoscale. While
advancements have made these experiments more accessible, real-time analysis
remains a significant bottleneck, often hindered by artifacts and computational
demands. In scanning X-ray nanodiffraction microscopy, which is widely used to
spatially resolve structural heterogeneities, this challenge is compounded by
the convolution of the divergent beam with the sample's local structure. To
address this, we introduce DONUT (Diffraction with Optics for Nanobeam by
Unsupervised Training), a physics-aware neural network designed for the rapid
and automated analysis of nanobeam diffraction data. By incorporating a
differentiable geometric diffraction model directly into its architecture,
DONUT learns to predict crystal lattice strain and orientation in real-time.
Crucially, this is achieved without reliance on labeled datasets or
pre-training, overcoming a fundamental limitation for supervised machine
learning in X-ray science. We demonstrate experimentally that DONUT accurately
extracts all features within the data over 200 times more efficiently than
conventional fitting methods.

</details>


### [196] [Noradrenergic-inspired gain modulation attenuates the stability gap in joint training](https://arxiv.org/abs/2507.14056)
*Alejandro Rodriguez-Garcia,Anindya Ghosh,Srikanth Ramaswamy*

Main category: cs.LG

TL;DR: 提出一种不确定性调制增益动态机制，模仿生物大脑多时间尺度运作，有效减小持续学习中的稳定性差距。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法在学习新任务时，在已掌握任务上的性能会短暂下降（稳定性差距），即使在理想的联合损失下也存在，这表明其在缓解遗忘方面缺乏鲁棒性。这种现象与持续学习的目标相悖，因此需要深入研究以解决此问题。

Method: 提出了一种名为“不确定性调制增益动态”的自适应机制，该机制近似于双时间尺度优化器，能够动态地平衡知识整合和对先前巩固信息的干扰。通过在MNIST和CIFAR数据集的域增量和类增量变体上进行评估，证明了该机制能有效减小稳定性差距。

Result: 实验结果表明，不确定性调制增益动态机制有效地减小了稳定性差距，并在MNIST和CIFAR数据集的域增量和类增量任务上表现出改进的性能。同时，分析揭示了增益调制如何模拟神经去甲肾上腺素在皮层回路中的功能，为减少稳定性差距提供了机制层面的理解。

Conclusion: 该研究提出的不确定性调制增益动态机制，通过模仿生物大脑的多时间尺度运作和神经调质信号的作用，有效减轻了持续学习中的稳定性差距，为提升持续学习性能提供了新的见解。

Abstract: Recent studies in continual learning have identified a transient drop in
performance on mastered tasks when assimilating new ones, known as the
stability gap. Such dynamics contradict the objectives of continual learning,
revealing a lack of robustness in mitigating forgetting, and notably,
persisting even under an ideal joint-loss regime. Examining this gap within
this idealized joint training context is critical to isolate it from other
sources of forgetting. We argue that it reflects an imbalance between rapid
adaptation and robust retention at task boundaries, underscoring the need to
investigate mechanisms that reconcile plasticity and stability within continual
learning frameworks. Biological brains navigate a similar dilemma by operating
concurrently on multiple timescales, leveraging neuromodulatory signals to
modulate synaptic plasticity. However, artificial networks lack native
multitimescale dynamics, and although optimizers like momentum-SGD and Adam
introduce implicit timescale regularization, they still exhibit stability gaps.
Inspired by locus coeruleus mediated noradrenergic bursts, which transiently
enhance neuronal gain under uncertainty to facilitate sensory assimilation, we
propose uncertainty-modulated gain dynamics - an adaptive mechanism that
approximates a two-timescale optimizer and dynamically balances integration of
knowledge with minimal interference on previously consolidated information. We
evaluate our mechanism on domain-incremental and class-incremental variants of
the MNIST and CIFAR benchmarks under joint training, demonstrating that
uncertainty-modulated gain dynamics effectively attenuate the stability gap.
Finally, our analysis elucidates how gain modulation replicates noradrenergic
functions in cortical circuits, offering mechanistic insights into reducing
stability gaps and enhance performance in continual learning tasks.

</details>


### [197] [Preference-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.14066)
*Ni Mu,Yao Luan,Qing-Shan Jia*

Main category: cs.LG

TL;DR: 提出Pb-MORL框架，利用偏好替代奖励函数，通过优化与偏好一致的奖励模型来学习帕累托最优策略，并在实验中表现优于oracle方法。


<details>
  <summary>Details</summary>
Motivation: 传统的MORL方法依赖预定义的奖励函数，设计困难且可能导致目标冲突的过度简化。偏好作为一种更灵活、更直观的决策指导，可以消除复杂的奖励设计需求。

Method: 提出了一种偏好引导的多目标强化学习（Pb-MORL）框架，该框架将偏好形式化地整合到MORL框架中，通过构建与给定偏好一致的多目标奖励模型来指导策略优化，并理论证明了优化该奖励模型等同于训练帕累托最优策略。

Result: 理论证明了偏好可以导出整个帕累托前沿的策略；实验证明，所提出的Pb-MORL方法在多个任务中表现优于oracle方法。

Conclusion: 所提出的方法在基准多目标任务、多能源管理任务以及多线公路上的自动驾驶任务中表现具有竞争力，甚至优于使用真实奖励函数きのoracle方法，显示出其在复杂实际系统中的应用潜力。

Abstract: Multi-objective reinforcement learning (MORL) is a structured approach for
optimizing tasks with multiple objectives. However, it often relies on
pre-defined reward functions, which can be hard to design for balancing
conflicting goals and may lead to oversimplification. Preferences can serve as
more flexible and intuitive decision-making guidance, eliminating the need for
complicated reward design. This paper introduces preference-based MORL
(Pb-MORL), which formalizes the integration of preferences into the MORL
framework. We theoretically prove that preferences can derive policies across
the entire Pareto frontier. To guide policy optimization using preferences, our
method constructs a multi-objective reward model that aligns with the given
preferences. We further provide theoretical proof to show that optimizing this
reward model is equivalent to training the Pareto optimal policy. Extensive
experiments in benchmark multi-objective tasks, a multi-energy management task,
and an autonomous driving task on a multi-line highway show that our method
performs competitively, surpassing the oracle method, which uses the ground
truth reward function. This highlights its potential for practical applications
in complex real-world systems.

</details>


### [198] [DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration](https://arxiv.org/abs/2507.14088)
*Xiyun Li,Yining Ding,Yuhua Jiang,Yunlong Zhao,Runpeng Xie,Shuang Xu,Yuanhua Ni,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: A new DPMT framework improves human-AI collaboration by better modeling human mental characteristics using a multi-scale ToM module, especially in situations lacking direct communication.


<details>
  <summary>Details</summary>
Motivation: Real-time human-AI collaboration is crucial yet challenging, especially when AI agents must adapt to diverse and unseen human behaviors in dynamic scenarios. Existing LLM agents often fail to accurately model complex human mental characteristics such as domain intentions, especially in the absence of direct communication.

Method: The paper proposes a novel dual process multi-scale theory of mind (DPMT) framework, which incorporates a multi-scale theory of mind (ToM) module to facilitate robust human partner modeling through mental characteristic reasoning.

Result: Experimental results demonstrate that DPMT significantly enhances human-AI collaboration.

Conclusion: DPMT significantly enhances human-AI collaboration, and ablation studies further validate the contributions of our multi-scale ToM in the slow system.

Abstract: Real-time human-artificial intelligence (AI) collaboration is crucial yet
challenging, especially when AI agents must adapt to diverse and unseen human
behaviors in dynamic scenarios. Existing large language model (LLM) agents
often fail to accurately model the complex human mental characteristics such as
domain intentions, especially in the absence of direct communication. To
address this limitation, we propose a novel dual process multi-scale theory of
mind (DPMT) framework, drawing inspiration from cognitive science dual process
theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)
module to facilitate robust human partner modeling through mental
characteristic reasoning. Experimental results demonstrate that DPMT
significantly enhances human-AI collaboration, and ablation studies further
validate the contributions of our multi-scale ToM in the slow system.

</details>


### [199] [Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective](https://arxiv.org/abs/2507.14121)
*Pankaj Yadav,Vivek Vijay*

Main category: cs.LG

TL;DR: KANs在原始不平衡数据上表现出色，但计算成本高且不兼容标准不平衡处理方法。MLPs结合不平衡技术在效率和性能上更具优势。


<details>
  <summary>Details</summary>
Motivation: 评估KANs在类别不平衡分类任务中的表现，并研究其与常规不平衡处理策略的兼容性，以了解其在实际应用中的潜力和局限性。

Method: 对KANs在10个基准数据集上进行了类别不平衡分类的实证评估，并与MLPs进行了对比，同时测试了常规不平衡策略（如重采样和Focal Loss）对KANs和MLPs的影响。

Result: KANs在原始不平衡数据上优于MLPs，无需重采样。然而，重采样和Focal Loss等策略会严重降低KANs的性能。结合不平衡技术的MLPs在性能上可与KANs媲美，但资源消耗更低。KANs存在计算成本高但性能增益不成比例的问题。

Conclusion: KANs在原始类别不平衡数据上表现优于MLPs，但在实践应用中存在计算成本高、与常规不平衡策略不兼容等问题。MLPs结合不平衡技术在资源消耗和性能上与KANs相当。

Abstract: Kolmogorov Arnold Networks (KANs) are recent architectural advancement in
neural computation that offer a mathematically grounded alternative to standard
neural networks. This study presents an empirical evaluation of KANs in context
of class imbalanced classification, using ten benchmark datasets. We observe
that KANs can inherently perform well on raw imbalanced data more effectively
than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,
conventional imbalance strategies fundamentally conflict with KANs mathematical
structure as resampling and focal loss implementations significantly degrade
KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from
prohibitive computational costs without proportional performance gains.
Statistical validation confirms that MLPs with imbalance techniques achieve
equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.
These findings reveal that KANs represent a specialized solution for raw
imbalanced data where resources permit. But their severe performance-resource
tradeoffs and incompatibility with standard resampling techniques currently
limits practical deployment. We identify critical research priorities as
developing KAN specific architectural modifications for imbalance learning,
optimizing computational efficiency, and theoretical reconciling their conflict
with data augmentation. This work establishes foundational insights for next
generation KAN architectures in imbalanced classification scenarios.

</details>


### [200] [Toward Temporal Causal Representation Learning with Tensor Decomposition](https://arxiv.org/abs/2507.14126)
*Jianhong Chen,Meng Zhao,Mostafa Reisi Gahrooei,Xubo Yue*

Main category: cs.LG

TL;DR: CaRTeD是一个整合了时间因果表述学习和不规则张量分解的框架，用于分析高维、不规则张量数据，并在理论和实验上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 真实世界应用中的数据通常是高维的，具有不同的输入长度，并以不规则张量的形式存在，因此需要不规则张量分解来提取有意义的聚类。

Method: 提出了一种新颖的因果表述，用于一组潜在聚类，并提出了CaRTeD，一个整合了时间因果表述学习和不规则张量分解的联合学习框架。该框架为下游任务提供了蓝图，并提供了一种更灵活的正则化设计来增强张量分解。

Result: 理论上，证明了该算法收敛到一个稳定点，填补了现有不规则张量分解方法在收敛性理论保证方面的空白。实验结果表明，所提出的方法在MIMIC-III数据集上表现优于现有技术。

Conclusion: 所提出的CaRTeD框架在合成和真实世界数据集上均优于现有技术，并在表型分析和网络恢复方面增强了因果表示的可解释性。

Abstract: Temporal causal representation learning is a powerful tool for uncovering
complex patterns in observational studies, which are often represented as
low-dimensional time series. However, in many real-world applications, data are
high-dimensional with varying input lengths and naturally take the form of
irregular tensors. To analyze such data, irregular tensor decomposition is
critical for extracting meaningful clusters that capture essential information.
In this paper, we focus on modeling causal representation learning based on the
transformed information. First, we present a novel causal formulation for a set
of latent clusters. We then propose CaRTeD, a joint learning framework that
integrates temporal causal representation learning with irregular tensor
decomposition. Notably, our framework provides a blueprint for downstream tasks
using the learned tensor factors, such as modeling latent structures and
extracting causal information, and offers a more flexible regularization design
to enhance tensor decomposition. Theoretically, we show that our algorithm
converges to a stationary point. More importantly, our results fill the gap in
theoretical guarantees for the convergence of state-of-the-art irregular tensor
decomposition. Experimental results on synthetic and real-world electronic
health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both
phenotyping and network recovery perspectives, demonstrate that our proposed
method outperforms state-of-the-art techniques and enhances the explainability
of causal representations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [201] [Cryogenic Performance Evaluation of Commercial SP4T Microelectromechanical Switch for Quantum Computing Applications](https://arxiv.org/abs/2507.13574)
*Yong-Bok Lee,Connor Devitt,Xu Zhu,Nicholas Yost,Yabei Gu,Sunil A. Bhave*

Main category: quant-ph

TL;DR: 本研究评估了商用MEMS开关在超导量子计算机低温复用器中的应用潜力，发现在低温下其性能得到提升且运行可靠，可用于实现大规模量子计算。


<details>
  <summary>Details</summary>
Motivation: 为了解决超导量子计算机扩展到数百万个量子比特以实现实际应用所面临的互连瓶颈挑战，本研究旨在研究商用MEMS开关作为大规模量子计算系统中低温复用器的可行性。

Method: 通过有限元模拟和实验测量在低温（< 10 K）下评估MEMS开关的直流和射频特性。

Result: MEMS开关在低温下表现出改进的导通电阻、更低的驱动电压和卓越的射频性能，并且具有超过1亿次的可靠运行。此外，还演示了在低温下稳定的单刀四掷（SP4T）开关和逻辑门（包括NAND和NOR门）。

Conclusion: MEMS开关在低温下表现出改进的导通电阻、更低的驱动电压和卓越的射频性能，并且具有超过1亿次的可靠运行，展示了其在实现大规模量子计算系统中的潜力。

Abstract: Superconducting quantum computers have emerged as a leading platform for
next-generation computing, offering exceptional scalability and unprecedented
computational speeds. However, scaling these systems to millions of qubits for
practical applications poses substantial challenges, particularly due to
interconnect bottlenecks. To address this challenge, extensive research has
focused on developing cryogenic multiplexers that enable minimal wiring between
room-temperature electronics and quantum processors. This paper investigates
the viability of commercial microelectromechanical system (MEMS) switches for
cryogenic multiplexers in large-scale quantum computing systems. DC and RF
characteristics of the MEMS switches are evaluated at cryogenic temperatures (<
10 K) through finite element simulations and experimental measurements. Our
results demonstrate that MEMS switches exhibit improved on-resistance, lower
operating voltage, and superior RF performance at cryogenic temperatures, with
reliable operation over 100 million cycles. Furthermore, stable single-pole
four-throw (SP4T) switching and logical operations, including NAND and NOR
gates, are demonstrated at cryogenic temperatures, validating their potential
for quantum computing. These results underscore the promise of MEMS switches in
realizing large-scale quantum computing systems.

</details>


### [202] [Two-photon coupling via Josephson element II: Interaction renormalizations and cross-Kerr coupling](https://arxiv.org/abs/2507.13427)
*Eugene V. Stolyarov,V. L. Andriichuk,Andrii M. Sokolov*

Main category: quant-ph

TL;DR: Investigates SQUID-mediated interactions in phase qubits, analyzing various coupling types and their renormalizations using an anharmonic oscillator model, with implications for qubit design.


<details>
  <summary>Details</summary>
Motivation: The research aims to study the interactions mediated by a symmetric superconducting quantum interference device (SQUID), their renormalizations, and the applicability of the anharmonic oscillator model for a coupled phase qubit.

Method: The paper considers a coupled resonator and an rf SQUID, analyzing interactions including linear, two-photon, optomechanical, and cross-Kerr couplings. It calculates renormalizations near the two-photon resonance, especially with higher Josephson energy in the coupler, and interprets these via virtual processes.

Result: The coupling SQUID can switch between single- or two-photon interaction in situ, and interactions of optomechanical type and a cross-Kerr coupling arise. Renormalizations due to nonresonant interactions are calculated and found to be more prominent with higher Josephson energy of the coupler.

Conclusion: The study interprets renormalizations by depicting virtual processes and determines the minimal metastable states required for renormalization formulas to hold.

Abstract: We study the interactions mediated by symmetric superconducting quantum
interference device (SQUID), their renormalizations, and applicability of the
anharmonic oscillator model for a coupled phase qubit. The coupling SQUID can
switch between single- or two-photon interaction in situ. We consider a coupled
resonator and an rf SQUID. The latter dwells in the vicinity of its metastable
well holding a number of anharmonic energy states and acts as an artificial
atom known as the phase qubit. Apart from the linear and two-photon couplings,
interactions of optomechanical type and a cross-Kerr coupling arise. Near the
two-photon resonance, we calculate the renormalizations due to nonresonant
interactions, which are more prominent with the higher Josephson energy of the
coupler. We interpret the renormalizations by depicting some of the virtual
processes involved. That also allows us to determine the minimal amount of
metastable states in the phase qubit for the renormalization formulas to hold.

</details>


### [203] [Quantum Wave Atom Transforms](https://arxiv.org/abs/2507.10739)
*Marianna Podzorova,Yi-Kai Liu*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper constructs the first quantum algorithm for wavelet packet
transforms with a tree structure, sometimes called wave atom transforms.
Classically, wave atoms are used to construct sparse representations of
differential operators, which enable fast numerical algorithms for partial
differential equations. Compared to previous work, our quantum algorithm can
implement a larger class of wavelet and wave atom transforms, by using an
efficient representation for a larger class of possible tree structures. Our
quantum implementation has $O(\mathrm{poly}(n))$ gate complexity for the
transform of dimension $2^n$, while classical implementations have $O(n 2^n)$
floating point operations. The result can be used to improve existing quantum
algorithms for solving hyperbolic partial differential equations.

</details>


### [204] [Free Fermion Dynamics with Measurements: Topological Classification and Adaptive Preparation of Topological States](https://arxiv.org/abs/2507.13437)
*Asadullah Bhuiyan,Haining Pan,Chao-Ming Jian*

Main category: quant-ph

TL;DR: 本研究提出了一个分类费米子动力学系统的框架，利用对称性和拓扑性，通过mEO和sTM两种方案。发现了动力学体边界对应，即时空体拓扑决定时间边界稳态拓扑。设计了高斯自适应电路来实现这些拓扑相，有限范围电路可制备稳态集合。模拟显示2+1d电路可实现陈绝缘体，并研究了相变和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于开发一个统一的框架来分类具有测量的费米子动力学系统，并利用对称性和拓扑性来理解这些系统的行为。具体来说，研究人员希望建立一个能够连接不同尺度（从单粒子到许多体）和不同物理现象（如安德森定位和拓扑相）的分类方案。通过引入动力学体边界对应，他们旨在揭示动力学系统内部（时空体）的拓扑结构如何决定其边界（稳态集合）的拓扑性质。最终目标是设计可行的物理实现方案（如高斯自适应电路）来制备和控制这些拓扑动力学相，并研究其性质和鲁棒性。

Method: 本研究开发了一个分类费米子动力学系统的通用框架，该框架基于对称性和拓扑性。它提出了两种互补的分类方案，均基于Altland-Zirnbauer十重方法：1. 许多体演化算子（mEO）对称类，用于分类许多体层面的费米子动力学，并可推广至相互作用动力学；2. 单粒子转移矩阵（sTM）对称类，用于分类单粒子层面的自由费米子动力学，并与安德森定位物理相关。在自由费米子极限下，这两种框架具有一一对应的关系，并产生等价的面积定律纠缠动力学相的拓扑分类。基于此，研究人员提出了一个新颖的动力学体边界对应，即动力学系统的时空体区域的拓扑结构决定了其时间边界上的面积定律纠缠稳态集合的拓扑结构。为了实现拓扑动力学相，研究人员设计了高斯自适应电路，以在任何空间维度上制备和稳定自由费米子拓扑态作为稳态。研究表明，具有指数局域操作的电路可以稳定单一拓扑稳态，而具有有限范围操作的电路可以达到一个拓扑稳态集合。作为具体实例，研究人员构建并模拟了2+1维自适应电路，实现了mEO A类拓扑动力学，并证明了有限范围版本在$\mathcal{O}(1)$电路深度内收敛于陈绝缘体集合。此外，还对拓扑相变、动力学畴壁模式以及对相干噪声的鲁棒性进行了数值研究。

Result: 研究人员成功开发了一个基于对称性和拓扑性的费米子动力学系统分类框架，并提出了两种互补的分类方案（mEO和sTM）。他们证明了在自由费米子极限下，这两种方案等价，并揭示了一种新的动力学体边界对应，即动力学系统的时空体拓扑决定了其时间边界上的稳态集合拓扑。基于此，他们设计了高斯自适应电路，能够制备和稳定自由费米子拓扑态作为稳态，并证明了有限范围操作的电路可在有限深度内实现陈绝缘体稳态集合。此外，研究还对拓扑相变、动力学畴壁模式以及协议对噪声的鲁棒性进行了数值分析。

Conclusion: 该研究提出了一个分类费米子动力学系统的通用框架，利用对称性和拓扑性。该框架通过两种互补的分类方案实现：一是基于许多体演化算子（mEO）的对称性分类，用于许多体层面上的费米子动力学，并可推广至相互作用动力学；二是基于单粒子转移矩阵（sTM）的对称性分类，用于单粒子层面的自由费米子动力学，并与安德森定位物理相关。在自由费米子极限下，这两种方案一一对应，并产生等价的面积定律纠缠动力学相的拓扑分类。这引出了一种新颖的动力学体边界对应：动力学系统的时空体区域的拓扑结构决定了其时间边界上的面积定律纠缠稳态集合的拓扑结构。基于此对应关系，研究人员通过高斯自适应电路通用实现了拓扑动力学相，这些电路旨在制备和稳定自由费米子拓扑态作为其在任何空间维度上的稳态。研究表明，具有指数局域操作的电路可以稳定单一拓扑稳态，而具有有限范围操作的电路可以达到一个拓扑稳态集合。作为证明，研究人员明确构建并模拟了2+1维自适应电路，实现了mEO A类拓扑动力学。他们发现有限范围版本在$\mathcal{O}(1)$电路深度内收敛于陈绝缘体集合。研究人员还对该对称类别下不同拓扑动力学相之间的拓扑相变和动力学畴壁模式进行了数值研究，并分析了自适应电路协议对相干噪声的鲁棒性。

Abstract: We develop a general framework for classifying fermionic dynamical systems
with measurements using symmetry and topology. We discuss two complementary
classification schemes based on the Altland-Zirnbauer tenfold way: (1) the
many-body evolution operator (mEO) symmetry class, which classifies fermionic
dynamics at the many-body level and generalizes to interacting dynamics, and
(2) the single-particle transfer matrix (sTM) symmetry class, which classifies
free-fermion dynamics at the single-particle level and connects to Anderson
localization physics. In the free-fermion limit, these two frameworks are in
one-to-one correspondence and yield equivalent topological classifications of
area-law entangled dynamical phases. This leads to a novel dynamical
bulk-boundary correspondence: the topology of the dynamical system's spacetime
\textit{bulk} determines the topology of the area-law entangled steady-state
ensemble living on its temporal \textit{boundary}. Building on this
correspondence, we provide a general realization of topological dynamical
phases using Gaussian adaptive circuits. They are designed to prepare and
stabilize free-fermion topological states as their steady states in
\textit{any} spatial dimension. While circuits with exponentially local
operations can stabilize a single topological steady state, those with
finite-range operations can reach a topological steady-state ensemble. As a
demonstration, we explicitly construct and simulate 2+1d adaptive circuits that
realize mEO-class-A topological dynamics. We show that the finite-range
versions converge to an ensemble of Chern insulators in $\mathcal{O}(1)$
circuit depth. We numerically study the topological phase transitions and
dynamical domain-wall modes between different topological dynamical phases in
this symmetry class. We also analyze the robustness of our adaptive circuit
protocol to coherent noise.

</details>


### [205] [Bipartite and tripartite entanglement in pure dephasing relativistic spin-boson model](https://arxiv.org/abs/2507.13438)
*Kensuke Gallock-Yoshimura,Erickson Tjoa*

Main category: quant-ph

TL;DR: 本研究利用相对论自旋-玻色模型，发现双发射器纠缠易于生成，而三体纠缠生成困难，提示需要新的研究方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探讨在相对论量子场论框架下，发射器之间纠缠生成的机制和限制，特别是理解多体纠缠的生成难度。

Method: 本研究使用一种可精确求解的相对论自旋-玻色模型，该模型等价于Unruh-DeWitt探测器模型的时无关形式，来非微扰地研究两体和三体发射器之间的纠缠生成。。

Result: 研究表明，(i) 高度纠缠态需要深层光锥相互作用；(ii) 场的质量可以改善纠缠生成；(iii) 与双体情况不同，三体纠缠的产生在非微扰情况下非常困难。此外，还提供了N体模型在Fock空间中具有良好定义基态的正则条件。

Conclusion: 本研究表明，在非微扰情况下，两体和三体发射器之间的纠缠生成在不同的条件下表现出显著差异。双发射器系统可以通过深层光锥相互作用实现高度纠缠态，并且场的质量可以普遍地改善纠缠生成。然而，对于三体发射器系统，即使在足够长的时间内，要产生真正的多方纠缠也非常困难，这表明需要新的探测技术或UDW模型的变体来研究相对论量子场的多方纠缠。

Abstract: We study non-perturbatively the entanglement generation between two and three
emitters in an exactly solvable relativistic variant of the spin-boson model,
equivalent to the time-independent formulation of the Unruh-DeWitt detector
model. We show that (i) (highly) entangled states of the two emitters require
interactions very deep into the light cone, (ii) the mass of the field can
generically improve the entanglement generation, (iii) unlike the bipartite
case where it is possible to generate close to maximally entangled states via
the spin-boson interactions, the generation of genuine tripartite entanglement
is non-perturbatively hard even at sufficiently long times. Result (iii), in
particular, suggests that probing the multipartite entanglement of a
relativistic quantum field non-perturbatively requires either different
probe-based techniques or variants of the UDW model. Along the way we provide
the regularity conditions for the $N$-emitter model to have well-defined ground
states in the Fock space.

</details>


### [206] [Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification](https://arxiv.org/abs/2507.14116)
*Daniëlle Schuman,Mark V. Seebode,Tobias Rohe,Maximilian Balthasar Mansky,Michael Schroedl-Baumann,Jonas Stein,Claudia Linnhoff-Popien,Florian Krellner*

Main category: quant-ph

TL;DR: 提出了一种改进的并行量子退火方法，用于监督学习场景下的QBM训练，实现了近70%的加速，并取得了与CNN相当的性能，为QBM在NISQ时代的实际应用提供了可能。


<details>
  <summary>Details</summary>
Motivation: 当前的量子退火方法训练QBM成本高昂，需要大量量子处理单元（QPU）时间，限制了其在NISQ时代的广泛应用。

Method: 提出了一种改进的并行量子退火技术，并将其应用于监督学习场景下的量子玻尔兹曼机（QBM）训练。

Result: 所提出的方法在MedMNIST数据集上取得了与相似大小的卷积神经网络（CNN）相当的性能，并且训练轮次显著减少。与常规退火方法相比，并行退火技术实现了近70%的加速。

Conclusion: 通过提出一种改进的并行量子退火技术，并在监督设置下训练量子玻尔兹曼机（QBM），我们实现了近70%的加速，并取得了与CNN相当的结果，同时所需训练轮次更少，从而为QBM在NISQ时代的实际应用铺平了道路。

Abstract: Exploiting the fact that samples drawn from a quantum annealer inherently
follow a Boltzmann-like distribution, annealing-based Quantum Boltzmann
Machines (QBMs) have gained increasing popularity in the quantum research
community. While they harbor great promises for quantum speed-up, their usage
currently stays a costly endeavor, as large amounts of QPU time are required to
train them. This limits their applicability in the NISQ era. Following the idea
of No\`e et al. (2024), who tried to alleviate this cost by incorporating
parallel quantum annealing into their unsupervised training of QBMs, this paper
presents an improved version of parallel quantum annealing that we employ to
train QBMs in a supervised setting. Saving qubits to encode the inputs, the
latter setting allows us to test our approach on medical images from the
MedMNIST data set (Yang et al., 2023), thereby moving closer to real-world
applicability of the technology. Our experiments show that QBMs using our
approach already achieve reasonable results, comparable to those of
similarly-sized Convolutional Neural Networks (CNNs), with markedly smaller
numbers of epochs than these classical models. Our parallel annealing technique
leads to a speed-up of almost 70 % compared to regular annealing-based BM
executions.

</details>


### [207] [Emergent cavity-QED dynamics along the edge of a photonic lattice](https://arxiv.org/abs/2507.13444)
*Enrico Di Benedetto,Xuejian Sun,Marcel A. Pinto,Luca Leonforte,Chih-Ying Chang,Vincent Jouanny,Léo Peyruchat,Pasquale Scarlino,Francesco Ciccarello*

Main category: quant-ph

TL;DR: This paper studies qubits on the edge of a 2D photonic lattice with unique flat band edge modes. It models light-matter interactions using a cavity QED approach, revealing a special mode that localizes unconventionally around the qubit. The study predicts phenomena like vacuum Rabi oscillations and efficient state transfer, and suggests a superconducting circuit experiment.


<details>
  <summary>Details</summary>
Motivation: To investigate qubits coupled to the boundary of a two-dimensional photonic lattice that supports dispersionless edge modes, exploring their properties and potential applications in light-matter interactions.

Method: Investigating qubits coupled to the boundary of a two-dimensional photonic lattice with dispersionless edge modes, using a honeycomb lattice as a case study. Light-matter interactions are captured by a dissipative cavity QED model where the emitter couples to a fictitious cavity mode emerging from edge modes. This mode exhibits unconventional power-law localization around the qubit, tunable by lattice anisotropy.

Result: A fictitious cavity mode emerging from edge modes is identified, which exhibits unconventional power-law localization around the qubit and is tunable by lattice anisotropy. Vacuum Rabi oscillations and efficient state transfer between distant emitters are predicted.

Conclusion: The paper predicts vacuum Rabi oscillations and efficient state transfer between distant emitters, with a proposal for experimental demonstration using superconducting circuits.

Abstract: We investigate qubits coupled to the boundary of a two dimensional photonic
lattice that supports dispersionless edge modes, unlike conventional edge modes
that sustain propagating photons. As a case study, we consider a honeycomb
lattice (photonic graphene) of coupled resonators with a zigzag edge, where the
edge modes form a flat band defined only over a restricted region of momentum
space. We show that light matter interactions are effectively captured by a
dissipative cavity QED model, wherein the emitter coherently couples to a
fictitious cavity mode emerging as a superposition of edge modes. This mode has
support on only one sublattice and, most notably, displays an unconventional
power law localization around the qubit, yet remaining normalizable in the
thermodynamic limit, with a spatial range that can be tuned by introducing
lattice anisotropy We predict occurrence of vacuum Rabi oscillations and
efficient state transfer between distant emitters. An experimental
demonstration using superconducting circuits is proposed.

</details>


### [208] [Scalable suppression of heating errors in large trapped-ion quantum processors](https://arxiv.org/abs/2507.13457)
*Zixuan Huo,Yangchao Shen,Xiao Yuan,Xiao-Ming Zhang*

Main category: quant-ph

TL;DR: 为大型离子阱量子处理器提供了一种抑制热噪声误差的简单而全面的框架，可实现高达十倍的失真减少。


<details>
  <summary>Details</summary>
Motivation: 为了解决可扩展量子计算中离子阱量子处理器运动加热作为容错操作的关键障碍，特别是随着系统规模的增加，以及现有方法难以抑制其不相干的性质。

Method: 通过对热噪声引起的失真与相空间轨迹的依赖性进行详细分析，提出了一种抑制热噪声误差的框架。

Result: 在最多55个量子比特的系统中，数值模拟显示失真最多可减少一个数量级。

Conclusion: 该研究提出了一个用于抑制大型离子阱量子处理器中热噪声误差的框架，通过数值模拟验证了其有效性，并为实现可扩展的离子阱量子计算提供了实际可行的方法。

Abstract: Trapped-ion processors are leading candidates for scalable quantum
computation. However, motional heating remains a key obstacle to fault-tolerant
operation, especially when system size increases. Heating error is particularly
challenging to suppress due to is incoherence nature, and no general methods
currently exist for mitigating their impact even in systems with more than two
ions. In this work, based on a careful analysis about the dependence of
heating-induced infidelity on phase-space trajectories, we present a simple yet
comprehensive framework for suppressing heating errors in large trapped-ion
quantum processors. Our approach is flexible, allowing various control pulse
bases, ion numbers, and noise levels. Our approach is also compatible with
existing error-mitigation techniques, including those targeting laser phase and
frequency noise. Crucially, it relies on an efficiently computable cost
function that avoids the exponential overhead of full fidelity estimation. We
perform numerical simulations for systems with up to 55 qubits, demonstrating
up to an order-of-magnitude reduction in infidelities. These results offer a
practical route toward robust, large-scale quantum computation with trapped
ions.

</details>


### [209] [SAQR-QC: A Logic for Scalable but Approximate Quantitative Reasoning about Quantum Circuits](https://arxiv.org/abs/2507.13635)
*Nengkun Yu,Jens Palsberg,Thomas Reps*

Main category: quant-ph

TL;DR: SAQR-QC offers a scalable and approximate quantitative reasoning logic for quantum circuits, overcoming the limitations of existing methods by incorporating precision loss and local reasoning.


<details>
  <summary>Details</summary>
Motivation: Existing verification techniques for quantum programs are insufficient and often require exponential time/space, especially for quantum circuits with many qubits.

Method: SAQR-QC: A logic with built-in (deliberate) loss of precision, a mechanism to control accumulated precision loss, and local reasoning steps involving a small number of qubits.

Result: Demonstrated the effectiveness of SAQR-QC through case studies on GHZ circuits (with non-Clifford gates) and quantum phase estimation.

Conclusion: SAQR-QC is effective for verifying quantum circuits like GHZ circuits and quantum phase estimation, addressing scalability and precision issues.

Abstract: Reasoning about quantum programs remains a fundamental challenge, regardless
of the programming model or computational paradigm. Despite extensive research,
existing verification techniques are insufficient--even for quantum circuits, a
deliberately restricted model that lacks classical control, but still underpins
many current quantum algorithms. Many existing formal methods require
exponential time and space to represent and manipulate (representations of)
assertions and judgments, making them impractical for quantum circuits with
many qubits. This paper presents a logic for reasoning in such settings, called
SAQR-QC. The logic supports Scalable but Approximate Quantitative Reasoning
about Quantum Circuits, whence the name. SAQR-QC has three characteristics: (i)
some (deliberate) loss of precision is built into it; (ii) it has a mechanism
to help the accumulated loss of precision during a sequence of reasoning steps
remain small; and (iii) most importantly, to make reasoning scalable, all
reasoning steps are local--i.e., they each involve just a small number of
qubits. We demonstrate the effectiveness of SAQR-QC via two case studies: the
verification of GHZ circuits involving non-Clifford gates, and the analysis of
quantum phase estimation--a core subroutine in Shor's factoring algorithm.

</details>


### [210] [Growing Sparse Quantum Codes from a Seed](https://arxiv.org/abs/2507.13496)
*ChunJun Cao,Brad Lackey*

Main category: quant-ph

TL;DR: 本研究使用“联缀”方法，证明了可以仅通过组合量子重复码来构建量子LDPC码，并提出了一种能生成具有良好距离增长的稀疏子系统码的算法。此外，还发现简单的量子重复码组合足以生成任意CSS码。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过“联缀”操作将较小的量子码组合起来，系统性地构建量子LDPC码或稀疏子系统码，并在增加码距离的同时保持Tanner图的度有界。

Method: 利用量子Lego形式主义中的“联缀”思想，设计了一种迭代算法，可以构造具有界限Tanner图度的稀疏子系统码，且该码的最小距离的增长满足kd^2=O(n)。

Result: 证明了仅通过联缀量子重复码即可构建量子LDPC码。此外，所提出的算法能够构造出稀疏子系统码，其最小距离增长渐进地满足kd^2=O(n)。同时，证明了只需联缀两个量子比特的比特翻转码和相位翻转码即可生成任何CSS码，表明这种组合方式具有很强的能力。

Conclusion: 通过将量子重复码进行“联缀”（conjoining）这一操作，可以构建出量子LDPC码。

Abstract: It is generally unclear whether smaller codes can be "concatenated" to
systematically create quantum LDPC codes or their sparse subsystem code cousins
where the degree of the Tanner graph remains bounded while increasing the code
distance. In this work, we use a slight generalization of concatenation called
conjoining introduced by the quantum lego formalism. We show that by conjoining
only quantum repetition codes, one can construct quantum LDPC codes. More
generally, we provide an efficient iterative algorithm for constructing sparse
subsystem codes with a distance guarantee that asymptotically saturates
$kd^2=O(n)$ in the worst case. Furthermore, we show that the conjoining of even
just two-qubit quantum bit-flip and phase-flip repetition codes is quite
powerful as they can create any CSS code. Therefore, more creative combinations
of these basic code blocks will be sufficient for generating good quantum
codes, including good quantum LDPC codes.

</details>


### [211] [Enhanced image classification via hybridizing quantum dynamics with classical neural networks](https://arxiv.org/abs/2507.13587)
*Ruiyang Zhou,Saubhik Sarkar,Sougato Bose,Abolfazl Bayat*

Main category: quant-ph

TL;DR: 提出了一种将经典神经网络与量子多体系统相结合的混合模型，用于图像分类。该模型利用量子动力学来提高分类精度，并展示了在实现实际量子优势方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 量子计算和机器学习的融合是计算科学中有前景的新兴领域。该研究旨在克服扩展量子计算的挑战，并展示量子模块在提高分类精度方面的关键作用。

Method: 提出了一种结合经典神经网络与量子多体系统非平衡动力学的混合协议，用于图像分类。该协议利用经典神经网络处理高维数据并将其有效编码到量子多体系统，利用量子多体动力学的判别特性增强分类精度，通过将图像映射到近乎正交的量子态来最大化希尔伯特空间中的可分性。

Result: 在多个基准数据集上评估了模型的性能，证明了量子模块在单独依靠经典神经网络无法达到的高分类精度方面发挥的关键作用。

Conclusion: 该混合协议展示了在实现实际量子优势方面的潜力，并为未来量子增强计算技术的发展铺平了道路。

Abstract: The integration of quantum computing and machine learning has emerged as a
promising frontier in computational science. We present a hybrid protocol which
combines classical neural networks with non-equilibrium dynamics of a quantum
many-body system for image classification. This architecture leverages
classical neural networks to efficiently process high-dimensional data and
encode it effectively on a quantum many-body system, overcoming a challenging
task towards scaled up quantum computation. The quantum module further
capitalizes on the discriminative properties of many-body quantum dynamics to
enhance classification accuracy. By mapping images from distinct classes to
nearly-orthogonal quantum states, the system maximizes separability in the
Hilbert space, enabling robust classification. We evaluate the performance of
our model on several benchmark datasets with various number of features and
classes. Moreover, we demonstrate the key role of the quantum module in
achieving high classification accuracy which cannot be accomplished by the
classical neural network alone. This showcases the potential of our hybrid
protocol for achieving practical quantum advantage and paves the way for future
advancements in quantum-enhanced computational techniques.

</details>


### [212] [Forward-Time Equivalent of a "Retrocausal" Diffusion Hidden Variable Model for Quantum Mechanics](https://arxiv.org/abs/2507.13593)
*William S. DeWitt,Benjamin H. Feintzeig*

Main category: quant-ph

TL;DR: 一个声称涉及“逆因果关系”的随机隐变量模型，被证明可以用仅包含初始时间边界条件的前溯方程来等价地描述，并且其引导项可以作为平均场极限来解释。


<details>
  <summary>Details</summary>
Motivation: 反驳“该模型涉及‘逆因果关系’”的观点，并提供一种仅包含初始时间边界条件的前溯动力学解释。

Method: 通过建立一个等价的、仅包含初始时间边界条件的前溯方程组来分析该模型。

Result: 证明了该模型中的引导项可以看作是有限粒子系综中平均成对相互作用的平均场极限。

Conclusion: 该模型可以被表述为前溯动力学的等价形式，该形式仅涉及初始时间边界条件。

Abstract: A recently proposed stochastic hidden variable model for quantum mechanics
has been claimed to involve "retrocausality" due to the appearance of equations
of motion with future-time boundary conditions. We formulate an equivalent
system of forward-time equations of motion that gives rise to the same
trajectories as solutions, but involves only initial-time boundary conditions.
The forward-time dynamics involves a guidance term for the dynamical variables,
determined by the phase-space distribution corresponding to a quantum
wavefunction. We show, however, that this particular guidance term can be
recovered as the mean-field limit of averaged pairwise interactions among an
ensemble of finitely many particles.

</details>


### [213] [Fast computational deep thermalization](https://arxiv.org/abs/2507.13670)
*Shantanav Chakraborty,Soonwon Choi,Soumik Ghosh,Tudor Giurgică-Tiron*

Main category: quant-ph

TL;DR: 本文介绍了一种计算性深度热化，利用低资源复杂度的量子电路生成具有加密属性的结构化量子态，这些状态在部分测量后能够模拟 Haar 随机性，为量子计算和密码学提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 深度热化是量子系统在部分测量后出现类似 Haar 随机性的现象，通常与高复杂性和纠缠性相关。本研究旨在介绍计算性深度热化并构造展现此现象的最快动力学。

Method: 通过构造最快的量子电路动力学，在无限有效温度下实现计算性深度热化，生成具有低纠缠度的量子态（多对数深度），这些量子态对于任何计算能力有限的观察者来说都无法与 Haar 随机状态区分。

Result: 所构造的电路动力学在多对数深度内产生低纠缠度的量子态，并且对于计算能力受限的观察者来说，这些状态与 Haar 随机状态无法区分。重要的是，观察者可以请求对状态进行部分投影测量后得到的相同残余状态的多个副本。这些状态在密码学上是伪随机、伪纠缠的，并且在局部测量下能保持这些性质。

Conclusion: 本文展示了一种计算性深度热化，其中热化行为源于具有加密属性的结构化量子态，而非高度非结构化的集合。制备这些状态的低资源复杂度表明可以使用量子计算机对深度热化进行可扩展模拟。本研究还促进了对超越 BQP 观察者的计算性量子伪随机性的研究。

Abstract: Deep thermalization refers to the emergence of Haar-like randomness from
quantum systems upon partial measurements. As a generalization of quantum
thermalization, it is often associated with high complexity and entanglement.
Here, we introduce computational deep thermalization and construct the fastest
possible dynamics exhibiting it at infinite effective temperature. Our circuit
dynamics produce quantum states with low entanglement in polylogarithmic depth
that are indistinguishable from Haar random states to any computationally
bounded observer. Importantly, the observer is allowed to request many copies
of the same residual state obtained from partial projective measurements on the
state -- this condition is beyond the standard settings of quantum
pseudorandomness, but natural for deep thermalization. In cryptographic terms,
these states are pseudorandom, pseudoentangled, and crucially, retain these
properties under local measurements. Our results demonstrate a new form of
computational thermalization, where thermal-like behavior arises from
structured quantum states endowed with cryptographic properties, instead of
from highly unstructured ensembles. The low resource complexity of preparing
these states suggests scalable simulations of deep thermalization using quantum
computers. Our work also motivates the study of computational quantum
pseudorandomness beyond BQP observers.

</details>


### [214] [Solving wave equation problems on D-Wave quantum annealers](https://arxiv.org/abs/2507.13724)
*Aigerim Bazarkhanova,Alejandro J. Castro,Antonio A. Valido*

Main category: quant-ph

TL;DR: 量子退火器在伪谱方案中求解一维亥姆霍兹方程，并通过定制嵌入技术和全秩、小动态范围的代数系统来提高性能。


<details>
  <summary>Details</summary>
Motivation: 研究量子退火器在伪谱方案中求解一维亥姆霍兹方程的性能，并评估不同编码策略的有效性。

Method: 使用D-Wave系统的量子退火器通过伪谱方案求解一维亥姆霍兹方程，其中解被编码到一组合适的基函数中。

Result: 发现能够检索全秩和动态范围小的代数系统的编码策略能够提高量子退火器的性能，即使在多色驱动和复杂初始条件下。

Conclusion: 通过在伪谱方案中解决一维亥姆霍兹方程，我们强调了开发定制嵌入技术以确保良好病态代数系统的对于量子退火器性能的重要性。

Abstract: We solve the one-dimensional Helmholtz equation in several scenarios using
the quantum annealer provided by the D-Wave systems within a pseudospectral
scheme, where its solution is encoded into certain set of suitable basis
functions. We assess the performance of different strategies of encoding based
on algebraic arguments and the adiabatic condition, and benchmark these against
the classical heuristic simulating annealing algorithm. In particular, we
compute the minimum energy gap, the so-called dynamic range and the mean
squared error to assess the numerical stability, consistency and accuracy of
the solutions returned by each strategy. Our work stresses out the importance
of developing custom embedded techniques ensuring well-conditioned algebraic
systems. In particular, we find out that encoding strategies retrieving
algebraic systems exhibiting full-rank and small dynamic ranges enhance the
performance of the quantum annealer even under polychromatic driving and for
intricate initial conditions. We further discuss the prospect of developing
hybrid quantum-classical schemes enable to meet suitable algebraic and
adiabatic conditions simultaneously.

</details>


### [215] [A machine learning based approach to the identification of spectral densities in quantum open systems](https://arxiv.org/abs/2507.13730)
*Jessica Barr,Shreyasi Mukherjee,Alessandro Ferraro,Mauro Paternostro,Giorgio Zicari*

Main category: quant-ph

TL;DR: 我们提出了一种基于机器学习的方法，通过训练人工神经网络来表征影响开放量子系统动力学的环境，并在一个自旋-玻色子模型上实现了高精度的分类和参数估计。


<details>
  <summary>Details</summary>
Motivation: 提出一种基于机器学习的方法来表征影响开放量子系统动力学的环境。

Method: 通过使用在系统可观察量的时间演化傅里叶变换上训练的人工神经网络，对完全可解的自旋-玻色子模型进行分类（区分亚欧姆、欧姆和超欧姆光谱密度）和回归（估计光谱密度函数的关键参数）。

Result: 机器学习方法实现了高分类准确率和鲁棒的参数估计，证明了其在量子噪声光谱学中的潜力。

Conclusion: 机器学习可以作为探测量子系统中环境特征和推进量子噪声光谱学的有力工具。

Abstract: We present a machine learning-based approach for characterising the
environment that affects the dynamics of an open quantum system. We focus on
the case of an exactly solvable spin-boson model, where the system-environment
interaction, whose strength is encoded in the spectral density, induces pure
dephasing. By using artificial neural networks trained on the
Fourier-transformed time evolution of some observables of the system, we
perform both classification -- distinguishing sub-Ohmic, Ohmic, and super-Ohmic
spectral densities -- and regression -- thus estimating key parameters of the
spectral density function, when the latter is expressed through a power law.
Our results demonstrate high classification accuracy and robust parameter
estimation, highlighting the potential of machine learning as a powerful tool
for probing environmental features in quantum systems and advancing quantum
noise spectroscopy.

</details>


### [216] [Impact of quadrature measurement on quantum coherence](https://arxiv.org/abs/2507.13735)
*Lucía Álvarez,Alfredo Luis*

Main category: quant-ph

TL;DR: This paper studies quadrature coherence using a beam splitter, looking at Gaussian and number states.


<details>
  <summary>Details</summary>
Motivation: To examine the behavior of quadrature coherence under the measurement of the same field quadrature.

Method: The study uses a beam splitter to examine the behavior of quadrature coherence under the measurement of the same field quadrature. The contribution of the field state impinging at the other input port is also considered.

Result: The paper examines the behavior of quadrature coherence for Gaussian and number states.

Conclusion: The paper examines the behavior of quadrature coherence under the measurement of the same field quadrature, considering both Gaussian and number states using a beam splitter.

Abstract: We examine the behavior of quadrature coherence under the measurement of the
same field quadrature. This is carried out with the help of a beam splitter,
that implies the contribution of the field state impinging at the other input
port. We examine the case of Gaussian and number states.

</details>


### [217] [Error exponents for tripartite-to-bipartite entanglement transformations](https://arxiv.org/abs/2507.13778)
*Péter Vrana*

Main category: quant-ph

TL;DR: 研究了在局部操作和经典通信下，从纯三方状态中蒸馏EBits的速率，并确定了确定性转换的误差指数和最优速率。


<details>
  <summary>Details</summary>
Motivation: 考虑从纯三方状态中蒸馏EBits。

Method: 通过局部操作和经典通信从纯三方状态中蒸馏EBits。

Result: 最大速率是两个对应边际的冯诺依曼熵的最小值，并且在渐近随机局部操作和经典通信下，最大速率由一个单参数纠缠度量族给出。

Conclusion: 确定了确定性转换的直接和强反证误差指数以及最优速率。

Abstract: We consider distillation of ebits between a specified pair of subsystems from
pure tripartite states by local operations and classical communication. It is
known that, allowing an asymptotically vanishing error, the maximal rate is the
minimum of the von Neumann entropies of the two corresponding marginals, and
under asymptotic stochastic local operations and classical communication the
maximal rate is given by a minimization over a one-parameter family of
entanglement measures. In this paper, we determine the direct and strong
converse error exponents, and the optimal rate for deterministic
transformations.

</details>


### [218] [Chirally Frustrated Superradiant Phases in a Jaynes-Cummings Trimer](https://arxiv.org/abs/2507.13800)
*Lin-Lin Jiang,Xuan Xie,Lin Tian,Jin-Feng Huang*

Main category: quant-ph

TL;DR: 研究了 JC 三聚体中的挫折量子相，发现手征挫折超辐射相具有单向光子流。


<details>
  <summary>Details</summary>
Motivation: 研究 JC 三聚体中因复杂跃迁振幅（可通过合成规范场工程化）而产生的挫折量子相，该三聚体是光-物质系统中最小的挫折单元。

Method: 通过研究具有复杂跃迁振幅的 JC 三聚体，在半经典极限下获得解析解，并绘制了模型相图，识别出正常相和三种不同的超辐射相。

Result: 识别出一种手征挫折超辐射相，其特征是手征和翻译对称性被破坏，以及单向光子流。

Conclusion: 该研究揭示了在具有复杂跃迁振幅的 Jaynes-Cummings (JC) 三聚体中，如何通过合成规范场和超强耦合实现挫折和对称性破缺。

Abstract: We investigate the emergence of frustrated quantum phases in a
Jaynes-Cummings (JC) trimer with complex hopping amplitudes between the
cavities, which represents the smallest frustrated unit in light-matter
systems. The complex hopping amplitudes that can be engineered via synthetic
gauge fields introduce chiral effects and geometric frustration into the
system. We obtain analytic solutions in the semiclassical limit and map out the
phase diagram of this model, featuring one normal and three distinct
superradiant phases. Among these phases, a chirally frustrated superradiant
phase emerges, characterized by broken chiral and translational symmetries and
unidirectional photon flow. These results reveal how frustration and symmetry
breaking can arise in JC systems with synthetic gauge fields and ultrastrong
coupling.

</details>


### [219] [Quantum Shadows: The Dining Information Brokers](https://arxiv.org/abs/2507.13810)
*Theodore Andronikos,Constantinos Bitsakos,Konstantinos Nikas,Georgios I. Goumas,Nectarios Koziris*

Main category: quant-ph

TL;DR: 这篇论文提出了一个名为“量子用餐信息经纪人问题”的新框架，并提供了一个基于量子纠缠的协议来解决它。该协议允许多个信息经纪人在保持匿名和隐私的同时，并行地共享信息。与现有协议相比，它实现了许多对许多通信、增强的匿名性，并且可以在分布式环境中运行。


<details>
  <summary>Details</summary>
Motivation: 为了解决信息经纪人问题，提出了一种新颖的基于纠缠的量子协议，该协议能够实现所有经纪人之间的完全并行、单步通信交换，并保证所有参与者的匿名性和隐私性。

Method: 该协议利用量子纠缠来实现完全分布式的通信，能够容纳位于不同空间位置的经纪人。

Result: 该协议实现了许多对许多同时信息交换，保证了所有发送者的完全匿名性和可追溯性，并利用量子纠缠以完全分布式的方式运行。

Conclusion: 该协议在安全、可扩展和匿名的通信方面取得了重大进展，在需要隐私和并行性的分布式环境中具有潜在应用。

Abstract: This article introduces the innovative Quantum Dining Information Brokers
Problem, presenting a novel entanglement-based quantum protocol to address it.
The scenario involves $n$ information brokers, all located in distinct
geographical regions, engaging in a metaphorical virtual dinner. The objective
is for each broker to share a unique piece of information with all others
simultaneously. Unlike previous approaches, this protocol enables a fully
parallel, single-step communication exchange among all brokers, regardless of
their physical locations. A key feature of this protocol is its ability to
ensure both the anonymity and privacy of all participants are preserved,
meaning no broker can discern the identity of the sender behind any received
information. At its core, the Quantum Dining Information Brokers Problem serves
as a conceptual framework for achieving anonymous, untraceable, and massively
parallel information exchange in a distributed system. The proposed protocol
introduces three significant advancements. First, while quantum protocols for
one-to-many simultaneous information transmission have been developed, this is,
to the best of our knowledge, one of the first quantum protocols to facilitate
many-to-many simultaneous information exchange. Second, it guarantees complete
anonymity and untraceability for all senders, a critical improvement over
sequential applications of one-to-many protocols, which fail to ensure such
robust anonymity. Third, leveraging quantum entanglement, the protocol operates
in a fully distributed manner, accommodating brokers in diverse spatial
locations. This approach marks a substantial advancement in secure, scalable,
and anonymous communication, with potential applications in distributed
environments where privacy and parallelism are paramount.

</details>


### [220] [Quantum chaos and semiclassical behavior in mushroom billiards I: Spectral statistics](https://arxiv.org/abs/2507.13823)
*Matic Orel,Črt Lozej,Marko Robnik,Hua Yan*

Main category: quant-ph

TL;DR: 蘑菇台球系统在半经典极限下，其能级间隔分布符合Berry-Robnik分布，而在低波数下则可用Berry-Robnik-Brody分布描述，并与新分析理论一致。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索蘑菇台球系统（Mushroom Billiards）中量子混沌的各个方面。由于该系统具有混合相空间（mixed phase space）的特点，包含一个规则分量和一个混沌分量，并且其尺寸可以通过一个参数w来调节，可以从完全可积系统（圆）过渡到完全混沌系统（体育场），因此该系统是研究量子对应物半经典行为的理想模型。本研究关注谱统计（spectral statistics）随系统几何形状和半经典参数的变化。

Method: 该研究通过数值模拟和分析理论相结合的方法，研究了二维蘑菇台球系统（Mushroom Billiards）的量子混沌性质。具体来说，研究了能级统计（spectral statistics）随几何参数w（台球杆宽度）和半经典参数k（波数）的变化。利用Berry-Robnik分布和Berry-Robnik-Brody分布来描述能级间隔分布，并与Yan（2025）提出的适用于混合类型系统的分析理论进行了比较。

Result: 在足够大的波数k下，能级间隔分布可以用Berry-Robnik分布（无需拟合）很好地描述。在较低的k下，Berry-Robnik-Brody分布可以很好地描述其与Berry-Robnik分布的微小偏差，该分布能够捕捉Poincaré-Husimi函数动力学局域化的弱效应。此外，研究采用的分析理论与数值结果在k较大的半经典极限下表现出优异的一致性。

Conclusion: 该研究表明，在足够大的波数k下，能级间隔分布可以用Berry-Robnik分布（无需拟合）很好地描述。在较低的k下，Berry-Robnik-Brody分布可以很好地描述其与Berry-Robnik分布的微小偏差，该分布能够捕捉Poincaré-Husimi函数动力学局域化的弱效应。此外，研究还采用了一种分析理论，该理论适用于混合类型系统，并且在k较大的半经典极限下与数值结果高度一致。

Abstract: We study the aspects of quantum chaos in mushroom billiards introduced by
Bunimovich. This family of billiards classically has the property of mixed
phase space with precisely one entirely regular and one fully chaotic (ergodic)
component, whose size depends on the width w of the stem, and has two limiting
geometries, namely the circle (as the integrable system) and stadium (as the
fully chaotic system). Therefore, this one-parameter system is ideal to study
the semiclassical behavior of the quantum counterpart. Here, in paper I, we
study the spectral statistics as a function of the geometry defined by w, and
as a function of the semiclassical parameter k, which in this case is just the
wavenumber k. We show that at sufficiently large k the level spacing
distribution is excellently described by the Berry-Robnik (BR) distribution
(without fitting). At lower k the small deviations from it can be well
described by the Berry-Robnik-Brody (BRB) distribution, which captures the
effects of weak dynamical localization of Poincar\'e-Husimi functions. We also
employ the analytical theory of the level spacing ratios distribution P(r) for
mixed-type systems, recently obtained by Yan (2025), which does not require a
spectral unfolding procedure, and show excellent agreement with numerics in the
semiclassical limit of large k. In paper II we shall analyze the eigenstates by
means of Poincar\'e-Husimi functions.

</details>


### [221] [Quantifying mixed-state entanglement via partial transpose and realignment moments](https://arxiv.org/abs/2507.13840)
*Poetri Sonya Tarabunga,Tobias Haug*

Main category: quant-ph

TL;DR: 本文提出了一种新的纠缠判据，可以有效地量化和验证大规模、含噪声量子系统中的纠缠，并在量子信息、多体物理和量子密码学等领域取得了重要进展。


<details>
  <summary>Details</summary>
Motivation: 量化混合量子多体系统中的纠缠是一个公认的难题，现有方法难以应用于大规模和含噪声的系统。

Method: 提出并构建了基于部分转置和重排矩的定量纠缠判据，利用SWAP测试或贝尔测量变种进行测量，并开发了相应的有效算法来测试混合态的纠缠度、Schmidt秩、算子Schmidt秩，以及对量子线路深度和哈尔随机态的纠缠特性进行表征。

Result: 开发了新的纠缠判据，实现了对混合态纠缠的有效测试和量化，证明了其在量子信息和多体物理中的广泛应用前景，包括对量子线路的鲁棒认证以及对特定量子态（如哈尔随机态和矩阵乘积态）的纠缠特性表征，并对量子密码学中的安全问题进行了理论上的推进。

Conclusion: 该研究介绍了基于部分转置和重排矩的定量纠缠判据，为纠缠单调量提供了严格界限，并展示了其在量子信息和多体物理中的应用，包括对混合态纠缠的界定、Schmidt秩和算子Schmidt秩的测试、含噪声量子线路深度的认证，以及对哈尔随机态和矩阵乘积态的纠缠特性表征，并对量子密码学中的伪纠缠和伪随机密度矩阵进行了研究。

Abstract: Entanglement plays a crucial role in quantum information science and
many-body physics, yet quantifying it in mixed quantum many-body systems has
remained a notoriously difficult problem. Here, we introduce families of
quantitative entanglement witnesses, constructed from partial transpose and
realignment moments, which provide rigorous bounds on entanglement monotones.
Our witnesses can be efficiently measured using SWAP tests or variants of Bell
measurements, thus making them directly implementable on current hardware.
Leveraging our witnesses, we present several novel results on entanglement
properties of mixed states, both in quantum information and many-body physics.
We develop efficient algorithms to test whether mixed states with bounded
entropy have low or high entanglement, which previously was only possible for
pure states. We also provide an efficient algorithm to test the Schmidt rank
using only two-copy measurements, and to test the operator Schmidt rank using
four-copy measurements. Further, our witnesses enable robust certification of
quantum circuit depth even in the presence of noise, a task which so far has
been limited to noiseless circuits only. Finally, we show that the entanglement
phase diagram of Haar random states, quantified by the partial transpose
negativity, can be fully established solely by computing our witness, a result
that also applies to any state 4-design. Our witnesses can also be efficiently
computed for matrix product states, thus enabling the characterization of
entanglement in extensive many-body systems. Finally, we make progress on the
entanglement required for quantum cryptography, establishing rigorous limits on
pseudoentanglement and pseudorandom density matrices with bounded entropy. Our
work opens new avenues for quantifying entanglement in large and noisy quantum
systems.

</details>


### [222] [Nonequilibrium steady states in multi-bath quantum collision models](https://arxiv.org/abs/2507.13860)
*Ronan McElvogue,Andrew K. Mitchell,Gabriel T. Landi,Steve Campbell*

Main category: quant-ph

TL;DR: 本研究比较了开放量子系统中单浴和双浴碰撞模型的热化动力学。研究发现双浴模型在非马尔可夫情况下能产生非平衡稳态和有限热流，并适用于量子轨迹分析。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统热化的动力学和热力学，特别是趋向非平衡稳态的过程，以及非马尔可夫相互作用的作用。探索不同的碰撞模型（单浴和双浴）如何影响系统的热化过程和稳态特性。

Method: 通过比较单浴和双浴两种碰撞模型来研究开放量子系统的热化动力学。在单浴模型中，环境由独立且相同准备的 the-rmal qubit 组成，并与系统进行有限时间 Δt 的顺序相互作用。在双浴模型中，碰撞 qubit 准备在基态或激发态，环境温度通过系统-环境耦合编码。研究了引入环境内部相互作用时的非马尔可夫动力学，并分析了热流的量子轨迹。

Result: 在Δt→0的极限下，单浴和双浴模型均能使系统达到相同的热稳态。然而，双浴模型描述了根本不同的物理过程，并产生了具有有限热流的非平衡态。当引入环境内部相互作用产生非马尔可夫动力学时，单浴模型系统达到浴的规范温度，而双浴模型系统由于强烈的系统-环境和环境内部关联，趋向于不同的温度。双浴模型特别适用于研究量子轨迹，即使在非马尔可夫情况下也是如此。

Conclusion: 该研究比较了单浴和双浴碰撞模型在开放量子系统热化动力学中的作用，并引入了非马尔可夫动力学。研究发现，尽管两种模型在Δt→0时都能达到相同的热稳态，但双浴模型描述了不同的物理过程，并产生非平衡态和有限的热流。在引入环境内部相互作用后，单浴模型仍达到规范温度，而双浴模型由于强烈的系统-环境和环境内部关联，趋向于不同的温度。双浴模型特别适用于研究非马尔可夫情况下的量子轨迹，并通过双点测量方案展示了热流的轨迹分析。

Abstract: Collision models provide a simple and versatile setting to capture the
dynamics of open quantum systems. The standard approach to thermalisition in
this setting involves an environment of independent and identically-prepared
thermal qubits, interacting sequentially for a finite duration $\Delta t$ with
the system. We compare this to a two-bath scenario in which collisional qubits
are prepared in either their ground or excited states and the environment
temperature is encoded in system-environment couplings. The system reaches the
same thermal steady state for both settings as $\Delta t\to 0$, although even
in this limit they describe fundamentally different physical processes, with
the two-bath setup yielding a nonequilibrium state with finite heat currents.
Non-Markovian dynamics arise when intra-environment interactions in either
setting are introduced. Here, the system in the single-bath setup again reaches
a steady state at the canonical temperature of the bath, but the nonequilibrium
steady state of the two-bath setup tends to a different temperature due to the
generation of strong system-environment and intra-environment correlations. The
two-bath setting is particularly suited to studying quantum trajectories, which
are well-defined also for the non-Markovian case. We showcase this with a
trajectory analysis of the heat currents within a two-point measurement scheme.
Our results provide insights into the dynamics and thermodynamics of
thermalisation towards nonequilibrium steady states and the role of
non-Markovian interactions.

</details>


### [223] [Role of quantum state texture in probing resource theories and quantum phase transition](https://arxiv.org/abs/2507.13862)
*Ayan Patra,Tanoy Kanti Konar,Pritam Halder,Aditi Sen De*

Main category: quant-ph

TL;DR: 本文在量子态纹理资源理论的基础上，提出了一种新的资源单调，并将其应用于多种量子资源。结果表明，纹理能够有效地表征量子相变，并为研究量子临界性提供了一种新的工具。


<details>
  <summary>Details</summary>
Motivation: 在最近开发的量子态纹理资源理论的基础上，展示了最大纹理和最小纹理之间的差值是任何维度中的有效纯度单调，并为现有的纯度量提供了下界。

Method: 提出了一种基于纹理的资源单调，并将其应用于量子相干性、非稳定性和纠缠等领域。介绍了非局域纹理的概念，并将其与纯态下的二体和多体纠缠的几何度量联系起来。

Result: 纹理能够有效地区分量子相变，并且在横向和纵向磁场下对伊辛链的量子相变进行了有效表征。DTDs are often used for specifying the structure of XML documents. They define the allowed elements and attributes, as well as their relationships and order. This helps to ensure that XML documents are well-formed and valid.

Conclusion: 纹理可以作为量子相变的信号，为量化量子临界性提供了一个有力的工具。

Abstract: Building on the recently developed quantum state texture resource theory, we
exhibit that the difference between maximum and minimum textures is a valid
purity monotone in any dimension and provide a lower bound for existing purity
measures. We introduce a texture-based resource monotone applicable across
general convex resource theories, encompassing quantum coherence,
non-stabilizerness, and entanglement. In particular, we propose the notion of
non-local texture, which corresponds to the geometric measure of bipartite and
multipartite entanglement in pure states. Furthermore, we demonstrate that the
texture of the entire ground state or its subsystems can effectively signal
quantum phase transitions in the Ising chain under both transverse and
longitudinal magnetic fields, offering a powerful tool for characterizing
quantum criticality.

</details>


### [224] [Robustness of analogue Hawking radiation in cavities with moving boundaries](https://arxiv.org/abs/2507.13894)
*Alberto García Martín-Caro,Javier Olmedo,Jose M. Sánchez Velázquez*

Main category: quant-ph

TL;DR: 本研究探索了动态卡西米尔系统中热辐射的局限性和鲁棒性，作为霍金辐射的类似物。通过数值分析，研究人员表征了不同配置下腔体中粒子的产生谱，并发现了热特征的出现高度依赖于特定条件。此外，研究还量化了尺寸效应和瞬态动力学对热分布的影响，为区分霍金辐射和实验伪影提供了指导。


<details>
  <summary>Details</summary>
Motivation: 探索动态卡西米尔系统中热辐射的局限性和鲁棒性，作为霍金辐射的类似物。

Method: 通过详细的数值分析，表征了具有移动边界的腔体在各种配置（包括膨胀、坍塌和刚性加速）下粒子产生谱。

Result: 发现在特定膨胀腔体配置中会出现热特征，但它们高度依赖于频带和加速参数。在出现热产生的腔体配置中，推导出了量化与灰体因子理想化热谱偏差的拟合表达式，揭示了与加速持续时间相关的振荡行为。

Conclusion: 通过识别哪些实验设置可以可靠地模拟引力诱导的现象，并量化尺寸效应和瞬态动力学如何修改预期的热分布，提供了区分真实的霍金辐射与实验伪影的综合框架。

Abstract: In this work we explore the limitations and robustness of thermal radiation
in dynamical Casimir systems serving as analogs for Hawking radiation. Through
detailed numerical analysis, we characterize particle production spectra in
cavities with moving boundaries under various configurations, including
expanding, collapsing, and rigidly accelerating scenarios. We find that thermal
signatures emerge in specific expanding cavity configurations but are highly
dependent on frequency bands and acceleration parameters. In those
configurations of the cavity where there is thermal production, we derive
fitting expressions that quantify deviations from idealized thermal spectra
through gray-body factors, revealing oscillatory behaviors tied to acceleration
duration. Our results identify which experimental setups can reliably simulate
gravitationally-induced phenomena and quantify how finite-size effects and
transient dynamics modify the expected thermal distributions, providing a
comprehensive framework for distinguishing genuine Hawking-like radiation from
experimental artifacts.

</details>


### [225] [Exploring critical states of the quantum Rabi model via Hamiltonian variational ansätze](https://arxiv.org/abs/2507.13964)
*Mei Peng,Xu-Dan Xie,Dan-Bo Zhang*

Main category: quant-ph

TL;DR: 使用哈密顿量变分菴兹（HVA）制备量子拉比模型（QRM）的临界态，发现HVA能有效捕获临界态在热力学极限下的行为，且所需资源与系统尺寸呈线性关系，提出VQA可作为探测临界态的新方法。


<details>
  <summary>Details</summary>
Motivation: 为了理解物质相，需要对热力学极限下的量子临界态进行表征。量子模拟器在制备临界态方面的能力关键依赖于量子电路的结构，同时也能为临界态提供新的见解。

Method: 利用哈密顿量变分菴兹（HVA）制备量子拉比模型（QRM）的临界态。

Result: HVA能有效捕获QRM临界态在热力学极限下的行为，所需电路深度与有效系统尺寸呈线性关系。HVA会逐渐将初始状态压缩到目标临界态，且所需块的数量仅与有效系统尺寸呈线性增长。

Conclusion: 文章提出使用变分量子算法（VQA）作为一种新的探测复杂量子临界态的方法。

Abstract: Characterizing quantum critical states towards the thermodynamic limit is
essential for understanding phases of matter. The power of quantum simulators
for preparing the critical states relies crucially on the structure of quantum
circuits and in return provides new insight into the critical states. Here, we
explore the critical states of the quantum Rabi model~(QRM) by preparing them
variationally with Hamiltonian variational ans\"atze~(HVA), in which the
intricated interplay among different quantum fluctuations can be parameterized
at different levels. We find that the required circuit depth scales linearly
with the effective system size, suggesting that HVA can efficiently capture the
behavior of critical states of QRM towards the thermodynamic limit. Moreover,
we reveal that HVA gradually squeeze the initial state to the target critical
state, with a number of blocks increasing only linearly with the effective
system size. Our work suggests variational quantum algorithm as a new probe for
the complicated critical states.

</details>


### [226] [Broadband and long-duration optical memory in Yb:YSO](https://arxiv.org/abs/2507.13973)
*T. Sanchez Mejia,L. Nicolas,A. Gelmini Rodriguez,M. Afzelius*

Main category: quant-ph

TL;DR: 研究人员在Yb:YSO晶体中实现了先进的光学量子存储器，可在125 μs内存储信息，带宽达250 MHz，效率达20%，为量子网络的发展铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 为了充分发挥量子网络在多模存储能力方面的潜力，需要实现宽带宽和长存储时间的同步，以最大化时间域内的多模容量。

Method: 通过优化的光学泵浦方案，结合数值模拟，实现了宽带宽和长存储时间的同步。此外，还提出了一种高效合成光学泵浦波形的方法，以及一种用于光学泵浦的简单且频率灵活的激光系统。

Result: 成功在Yb:YSO晶体中实现了具有250 MHz带宽和125 μs存储时间的原子频率梳光学量子存储器，效率达到20%（短存储时间）和5%（125 μs）。该方法为未来的自旋波存储实验进行了优化，理论带宽极限为288 MHz。

Conclusion: 该研究展示了一种在Yb:YSO晶体中实现的原子频率梳光学量子存储器，其内存带宽为250 MHz，存储时间长达125 μs，效率分别达到20%和5%。

Abstract: Optical quantum memories are essential components for realizing the full
potential of quantum networks. Among these, rare-earth-doped crystal memories
stand out due to their large multimode storage capabilities. To maximize the
multimode capacity in the time domain, it is key to simultaneously achieve
large memory bandwidth and long optical storage time. Here, we demonstrate an
atomic frequency comb optical memory in Yb:YSO, with a memory bandwidth of
250~MHz and a storage time of up to 125 $\mu$s. The efficiency reaches 20 \% at
short storage times, and 5 \% at 125 $\mu$s. These results were enabled by an
optimized optical pumping scheme, guided by numerical modelling. Our approach
is specifically designed for future spin-wave storage experiments, with the
theoretical bandwidth limit set at 288 MHz by the hyperfine structure of
Yb:YSO. Additionally, we introduce an efficient method for synthesizing the
optical pumping waveforms required for generating combs with tens of thousands
of teeth, as well as a simple yet frequency-agile laser setup for optical
pumping across a 10 GHz bandwidth.

</details>


### [227] [The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks](https://arxiv.org/abs/2507.13999)
*Sanidhay Bhambay,Siddarth Koduru Joshi,Thirupathaiah Vasantam,Neil Walton*

Main category: quant-ph

TL;DR: 本研究提出了一种适用于量子网络（特别是QKD网络）的比例公平泵浦策略（PF-PS），以解决资源分配问题。该策略通过动态调整泵浦优先级，平衡了公平性和吞吐量，并在理论和模拟中被证明是有效的，为量子网络的资源优化提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子网络中实际实现加密密钥分发（QKD）时面临的资源分配挑战，特别是通道的時变性、数据速率波动以及多边泵浦导致的密钥生成率（SKR）降低等问题，需要设计自适应的泵浦策略。

Method: 提出了一种比例公平泵浦策略（PF-PS），该策略是4G LTE和5G移动网络中比例公平调度程序的自然延伸，用于量子网络中的加密密钥分发（QKD）网络，并通过理论分析和数值模拟进行了验证。

Result: PF-PS策略能够有效应对量子网络中泵浦的時空约束，并在公平性和吞吐量之间取得良好平衡，最终实现最优的资源分配。

Conclusion: 比例公平泵浦策略（PF-PS）是量子网络中资源分配的有力候选者，因为它能够动态地优先考虑平均密钥生成率较低的用户，并能在公平性和吞吐量之间取得最佳平衡。

Abstract: We address the problem of optimal pumping strategies in quantum networks.
These networks enable secure communication by distributing entangled photon
pairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like
BBM92, generate secret keys from entangled photons. While secure communication
and error correction are essential for any quantum communication channel,
resource contention, optimization, and fairness issues are critical for
networks. In this article, we analyze the performance of quantum networks,
proposing simple distributed algorithms for QKD networks generating secret
keys.
  There are significant advantages of pumping entangled photons in QKD
networks, but challenges arise in practical implementations. The underlying
channels are inherently time-varying, and thus data rates fluctuate between
nodes. Moreover, multiple edges (node pairs) can be pumped simultaneously,
albeit at the cost of a reduced secret key rate (SKR). These temporal and
spatial constraints yield a complex decision-making problem whose solutions may
favor a small set of user pairs to the detriment of overall, long-run network
performance.
  We design adaptive pumping strategies that address these challenges in QKD
networks. In particular, we find that a proportional fairness pumping strategy
(PF-PS) stands out by dynamically prioritizing users with lower average secret
key rates and optimally balancing fairness with throughput. The proposed
algorithm is a natural extension to quantum networks of the Proportional Fair
Scheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis
and numerical simulations confirm that PF-PS is optimal for entangled state
distribution, and thus, when adapted appropriately, proportional fair pumping
is a strong candidate for efficient resource allocation in quantum networks.

</details>


### [228] [Definition of Current in Non-Hermitian Quantum Systems](https://arxiv.org/abs/2507.14014)
*Hiroto Oka*

Main category: quant-ph

TL;DR: 本研究提出了NHQS中满足连续性方程的电流新定义，该定义在电磁场方面与厄密系统中的电流行为相似。


<details>
  <summary>Details</summary>
Motivation: NHQS因其非厄米性而Predicted novel physical phenomena，但其电流的定义在NHQS中并不总是满足连续性方程，因此需要研究新的电流定义。

Method: 通过推导满足连续性方程的电流定义来研究NHQS的电流。

Result: 推导出了满足连续性方程的电流定义，并且该电流在物理量（电磁场）方面与厄密系统中的电流行为相似。

Conclusion: 本研究推导出了满足连续性方程且在物理量（电磁场）方面与厄密系统中的电流行为相似的非厄米量子系统（NHQS）的电流定义。

Abstract: In recent years, non-Hermitian quantum systems (NHQS) have been actively
studied. In conventional quantum mechanics, Hermitisity is a fundamental
property of Hamiltonians. However, it is known that when a system interacts
with its environment, its time evolution can be effectively described by
non-Hermitian Hamiltonians. NHQS are attracting attention because novel
physical phenomena not observed in Hermitian systems are predicted due to its
non-Hermitisity. In this study, I investigated the definition of current in
NHQS. In Hermitian systems, equation of continuity(EOC) holds between the
particle density and the current. However, in NHQS, there are cases where the
conventional definition of current does not satisfy EOC. Therefore, I
considered the definition of current that satisfies EOC in NHQS. As a result, I
derived current that satisfies EOC and behaves similarly to the current in
Hermitian systems with respect to physical quantities (electromagnetic fields).

</details>


### [229] [Fabrication of oriented NV center arrays in diamond via femtosecond laser writing and reorientation](https://arxiv.org/abs/2507.14047)
*Kai Klink,Andrew Raj Kirkpatrick,Yukihiro Tadokoro,Jonas Nils Becker,Shannon Singer Nicley*

Main category: quant-ph

TL;DR: 本研究提出了一种全光学方法，利用飞秒激光退火技术，解决了NV色心随机取向的问题，实现了NV色心阵列的定向排列，提高了其在量子磁场传感中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服NV色心在激光写入过程中产生的随机取向限制其磁场传感灵敏度和信号对比度的问题，提出了一种全光学的取向重排方法。

Method: 通过飞秒激光退火技术，实现了NV色心沿特定晶体轴的定向重排。

Result: 成功实现了NV色心沿光轴的确定性对齐，并在(100)和(111)金刚石衬底上进行了验证，为构建高性能量子器件提供了可能。

Conclusion: 激光烧蚀和退火技术实现了NV色心在(100)和(111)金刚石衬底上的确定性取向排列，为高性能量子器件的制造奠定了基础。

Abstract: Nitrogen-vacancy (NV) centers in diamond are widely recognized as highly
promising solid-state quantum sensors due to their long room temperature
coherence times and atomic-scale size, which enable exceptional sensitivity and
nanoscale spatial resolution under ambient conditions. Ultrafast laser writing
has demonstrated the deterministic spatial control of individual NV$^-$
centers, however, the resulting random orientation of the defect axis limits
the magnetic field sensitivity and signal contrast. Here, we present an
all-optical approach for reorienting laser-written NV$^-$ centers to lie along
a specific crystallographic axis using femtosecond laser annealing. This
technique enables the creation of spatially ordered NV$^-$ arrays with uniform
orientation, for enhancing performance for quantum magnetometry. We achieve
deterministic alignment along the optical axis in both (100)- and
(111)-oriented diamond substrates, paving the way for scalable,
high-performance quantum devices based on orientation-controlled NV$^-$
centers.

</details>


### [230] [Spontaneous emission in dipole approximation -- revisited](https://arxiv.org/abs/2507.14075)
*Paul R. Berman,Peter W. Milonni*

Main category: quant-ph

TL;DR: 本文利用源场理论和薛定谔绘景方法研究了偶极子近似下的自发辐射。研究表明，在不使用RWA和WWA的情况下，微扰理论计算会导致不正确的原子态布居数，但源场理论计算的场满足坡印廷定理。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是研究偶极子近似下的自发辐射，并探索不采用旋转波近似（RWA）和维斯科普夫-维格纳近似（WWA）的后果。

Method: 本文理论上研究了偶极子近似下的自发辐射，同时使用了源场理论和薛定谔绘景方法。

Result: 在不采用RWA和WWA的情况下，通过微扰理论计算了坡印廷矢量和能量密度，并表明其导致了物理上不正确的原子态布居数。但是，用源场理论计算的场在ct不等于R时总是满足坡印廷定理。

Conclusion: 该理论在所有时间内都导致了物理上不正确的原子态布居数，即使使用了收敛因子，并且对所有场频率进行了求和。

Abstract: Spontaneous emission in dipole approximation is studied theoretically using
both source-field theory and a Schrodinger picture approach. Using source-field
theory we obtain formal equations for the Poynting vector and energy density
without making the rotating wave approximation (RWA) and Weisskopf-Wigner
approximation (WWA). The initial condition at t=0 is one in which the atom is
in an excited state and the field in the vacuum state. The source-field
expressions are evaluated within the the RWA and WWA and are found to satisfy
Poynting's theorem. To explore the consequences of not making the RWA and WWA,
the Poynting vector and energy density are calculated using perturbation
theory. We use a Schrodinger picture approach and essentially reproduce and
complement the results of Compagno, Passante, and Persico [J. Mod. Optics 37:8,
1377 (2007)] and those of Power and Thirunamachandran [Phys. Rev. A 45, 54
(1992)] obtained using a Heisenberg picture approach. The theory involves a sum
over field mode frequencies and both finite cutoffs and convergence factors are
used to carry out the sums. It is shown that the perturbation theory
calculation leads to unphysical values for atomic state populations for all
times when a sum over all field frequencies is taken, even if a convergence
factor is used. It is also proved that the fields calculated using source-field
theory always satisfy Poynting's theorem for ct not equal to R, where R is the
distance from the atom.

</details>


### [231] [Efficient Variational Dynamics of Open Quantum Bosonic Systems via Automatic Differentiation](https://arxiv.org/abs/2507.14076)
*Jacopo Tosca,Francesco Carnazza,Luca Giacomelli,Cristiano Ciuti*

Main category: quant-ph

TL;DR: 介绍了一种用于模拟开放量子玻色系统动力学的可扩展变分方法，并成功应用于分析二维Bose-Hubbard格子的临界行为。


<details>
  <summary>Details</summary>
Motivation: 为了模拟量子区域中相互作用的开放量子玻色系统的动力学。

Method: 提出了一种基于多维Wigner相空间表示和变分多高斯（VMG）ansatz的可扩展变分方法，并使用Dirac-Frenkel原理推导了运动方程，利用高斯函数的解析结构和自动微分进行高效计算。

Result: 计算了锂化体谱隙的有限尺寸标度，并揭示了其在热力学极限下消失，表现出临界减速。

Conclusion: 该方法能够捕捉复杂大开放量子系统的动力学行为，并揭示了与二维量子伊辛普适性相变类相关的动力学展缩和动力学指数。

Abstract: We introduce a scalable variational method for simulating the dynamics of
interacting open quantum bosonic systems deep in the quantum regime. The method
is based on a multi-dimensional Wigner phase-space representation and employs a
Variational Multi-Gaussian (VMG) ansatz, whose accuracy is systematically
controlled by the number of Gaussian components. The variational equations of
motion are derived from the Dirac-Frenkel principle and evaluated efficiently
by combining the analytical structure of Gaussian functions with automatic
differentiation. As a key application, we study a driven-dissipative
two-dimensional Bose-Hubbard lattice with two-boson coherent driving and
two-body losses. Using our dynamical approach, we compute the finite-size
scaling of the Liouvillian spectral gap - extracted from the relaxation
dynamics - which vanishes in the thermodynamic limit. Our results reveal
critical slowing down with dynamical exponents of the 2D quantum Ising
universality class, demonstrating the power of our method to capture complex
quantum dynamics in large open systems.

</details>


### [232] [Machine Learning-aided Optimal Control of a noisy qubit](https://arxiv.org/abs/2507.14085)
*Riccardo Cantone,Shreyasi Mukherjee,Luigi Giannelli,Elisabetta Paladino,Giuseppe Falci*

Main category: quant-ph

TL;DR: A machine learning model using a transformer network accurately controls qubits with environmental noise and achieves high-fidelity quantum gates.


<details>
  <summary>Details</summary>
Motivation: To model and control a qubit undergoing Markovian and non-Markovian dynamics from environmental noise, and to achieve high-fidelity single-qubit gates.

Method: A graybox machine-learning framework combining physics-informed equations with a lightweight transformer neural network utilizing self-attention is applied. The model is trained on simulated data to predict observables and used for gradient-based optimal control to identify pulse sequences for single-qubit gates.

Result: The model accurately predicts observables even with memory effects and achieves fidelities above 99% for single-qubit gates at low coupling, remaining above 90% at high coupling.

Conclusion: The graybox machine-learning framework effectively models and controls qubits with Markovian and non-Markovian dynamics, achieving high-fidelity single-qubit gates even in challenging noise conditions.

Abstract: We apply a graybox machine-learning framework to model and control a qubit
undergoing Markovian and non-Markovian dynamics from environmental noise. The
approach combines physics-informed equations with a lightweight transformer
neural network based on the self-attention mechanism. The model is trained on
simulated data and learns an effective operator that predicts observables
accurately, even in the presence of memory effects. We benchmark both
non-Gaussian random-telegraph noise and Gaussian Ornstein-Uhlenbeck noise and
achieve low prediction errors even in challenging noise coupling regimes. Using
the model as a dynamics emulator, we perform gradient-based optimal control to
identify pulse sequences implementing a universal set of single-qubit gates,
achieving fidelities above 99% for the lowest considered value of the coupling
and remaining above 90% for the highest.

</details>


### [233] [Quantum and classical algorithms for SOCP based on the multiplicative weights update method](https://arxiv.org/abs/2507.14127)
*M. Isabel Franco Garrido,Alexander M. Dalzell,Sam McArdle*

Main category: quant-ph

TL;DR: 该研究提出了一种基于乘法权重更新方法的求解二阶锥规划（SOCP）的经典和量子算法。量子算法的查询复杂度接近于线性规划（LP）的复杂度，优于现有的SDP算法。经典算法在样本和查询模型中的复杂度也得到了分析。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是利用SOCP的结构来改进求解算法的性能，并与现有方法进行比较。

Method: 研究遵循了先前应用于半definit规划（SDP）的MW框架，SOCP是SDP的特例。研究表明，SOCP的附加结构可以被利用来通过SOCP特定的算法提供更好的运行时性能。

Result: 量子算法在相干查询方面复杂度接近于解决线性规划（LP）的复杂度，并且优于将现有SDP算法应用于SOCP的方法。经典算法在样本和查询模型中的复杂度为$\\

Conclusion: 该研究为求解二阶锥规划（SOCP）提供了经典的和量子的算法，该算法基于乘法权重（MW）更新方法。

Abstract: We give classical and quantum algorithms for approximately solving
second-order cone programs (SOCPs) based on the multiplicative weights (MW)
update method. Our approach follows the MW framework previously applied to
semidefinite programs (SDPs), of which SOCP is a special case. We show that the
additional structure of SOCPs can be exploited to give better runtime with
SOCP-specific algorithms. For an SOCP with $m$ linear constraints over $n$
variables partitioned into $r \leq n$ second-order cones, our quantum algorithm
requires $\widetilde{O}(\sqrt{r}\gamma^5 + \sqrt{m}\gamma^4)$ (coherent)
queries to the underlying data defining the instance, where $\gamma$ is a
scale-invariant parameter proportional to the inverse precision. This nearly
matches the complexity of solving linear programs (LPs), which are a less
expressive subset of SOCP. It also outperforms (especially if $n \gg r$) the
naive approach that applies existing SDP algorithms onto SOCPs, which has
complexity $\widetilde{O}(\gamma^{4}(n + \gamma \sqrt{n} + \sqrt{m}))$. Our
classical algorithm for SOCP has complexity $\widetilde{O}(n\gamma^4 + m
\gamma^6)$ in the sample-and-query model.

</details>


### [234] [Exploring near critical lattice gauge simulators with Rydberg atoms facilities](https://arxiv.org/abs/2507.14128)
*Avi Kaufman,James Corona,Zane Ozzello,Blake Senseman,Muhammad Asaduzzaman,Yannick Meurice*

Main category: quant-ph

TL;DR: 金伯格原子梯子可用于模拟标量电动力学，并通过特定方法估算量子纠缠熵，尽管存在一些误差来源。


<details>
  <summary>Details</summary>
Motivation: 研究金伯格原子梯子作为标量电动力学（紧致阿贝尔希格斯模型）的格点规范理论的模拟器的潜力，并估算其量子纠缠熵。

Method: 通过优化Mutual Information的滤波来估算量子纠缠熵，并使用累积概率分布将模拟结果与DMRG或精确结果进行比较。

Result: 可以使用少数几千次测量来估算量子纠缠熵。状态制备是主要的误差来源。研究了累积概率分布的大体积行为，并讨论了在未来获得量子优势的计算成本。

Conclusion: 该研究表明，使用金伯格原子梯子作为标量电动力学（也称为紧致阿贝尔希格斯模型）的格点规范理论的模拟器是可行的，并且可以通过优化Mutual Information的滤波来估算量子纠缠熵。

Abstract: We motivate the use of a ladder of Rydberg atoms as an analog simulator for a
lattice gauge theory version of scalar electrodynamics also called the compact
Abelian Higgs model. We demonstrate that by using a few thousand shots from a
single copy of the ladder simulator it is possible to estimate the bipartite
quantum von Neumann entanglement entropy $S^{vN}_A$. The estimation relies on
an optimized filtration of the mutual information associated with the
bitstrings obtained from public facilities of configurable Rydberg arrays named
Aquila. We discuss the limitations associated with finite sampling, sorting
fidelity, adiabatic preparation, ramp-down of the Rabi frequency before
measurement, and readout errors. We use cumulative probability distribution to
compare Aquila results with high accuracy density matrix renormalization group
(DMRG) or exact results. The state preparation appears to be the main source of
error. We discuss the large volume behavior of the cumulative probability
distribution and show examples where for a finite number of shots, there
appears to be some large enough size for which any given state is seen at most
once with high probability. We show that the results presented can be extended
to multipartite entanglement. We briefly discuss the cost of the calculations
for large square arrays in the context of obtaining quantum advantage in the
near future.

</details>


### [235] [On the relation between perspective-neutral, algebraic, and effective quantum reference frames](https://arxiv.org/abs/2507.14131)
*Julian De Vuyst,Philipp A. Hoehn,Artur Tsobanjan*

Main category: quant-ph

TL;DR: 这篇论文证明了三种量子参考系（QRF）方法（有效半经典、代数、视角中立）在处理规范对称性时是等价的，并分析了不确定性和涨落的参考系依赖性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是理解和统一三种不同的量子参考系（QRF）方法（有效半经典、代数和视角中立），这些方法在处理量子理论中的对称性，特别是在量子引力、规范理论和基础物理学等领域中，提供了不同的视角。通过阐明这些方法之间的关系，特别是它们在理想QRF下的等价性，可以为量子对称性提供一个更统一的理解框架。

Method: 该研究通过比较三种不同的QRF方法（有效半经典、代数和视角中立）在处理规范对称性方面的异同，并证明了它们在理想QRF下的等价性。具体而言，论文分析了这些方法在希尔伯特空间、量子相空间和状态空间上的差异，以及它们如何处理外部参考系信息。此外，论文还探讨了QRF变换的半经典对应关系，并应用QRF协方差分析了不确定性和涨落的依赖性。

Result: 该研究表明，在理想量子参考系（QRF）的条件下，有效半经典、代数和视角中立（PN）这三种处理规范对称性的QRF方法是等价的。论文详细阐述了这些方法在量子相空间、代数状态空间和希尔伯特空间等方面的差异，并证明了它们在处理约束和QRF变换时的一致性。研究还发现，不确定性和涨落具有依赖于参考系的依赖性，并为将这些方法扩展到非理想QRF铺平了道路。

Conclusion: 这篇论文证明了在理想量子参考系（QRF）的情况下，有效半经典、代数和视角中立（PN）这三种量子参考系（QRF）方法是等价的，这些方法在处理规范对称性方面有所不同，但都将外部参考系信息视为规范。

Abstract: The framework of internal quantum reference frames (QRFs) constitutes a
universal toolset for dealing with symmetries in quantum theory and has led to
new revelations in quantum gravity, gauge theories and foundational physics.
Multiple approaches have emerged, sometimes differing in scope and the way
symmetries are implemented, raising the question as to their relation. Here, we
investigate the relation between three approaches to QRFs for gauge symmetries,
namely the effective semiclassical, algebraic, and perspective-neutral (PN)
approaches. Rather than constructing Hilbert spaces, as the PN approach, the
effective approach is based on a quantum phase space parametrized by
expectation values and fluctuations, while the emphasis of the algebraic
approach is on the state space of complex linear functionals on a kinematical
algebra. Nevertheless, external frame information is treated as gauge in all
three formalisms, manifested in constraints on states and algebra. We show that
these three approaches are, in fact, equivalent for ideal QRFs, distinguished
by sharp orientations, which is the previous setting of the first two
approaches. Our demonstration pertains to single constraints, including
relativistic ones, and encompasses QRF changes. In particular, the QRF
transformations of the PN framework agree semiclassically with those of the
older effective approach, by which it was inspired. As a physical application,
we explore the QRF covariance of uncertainties and fluctuations, which turn out
to be frame-dependent. This is particularly well-suited for the effective and
algebraic approaches, for which these quantities form a natural basis. Finally,
we pave the way towards extending these two approaches to non-ideal QRFs by
studying the projection and gauge-fixing operations of the Page-Wootters
formalism, built into the PN framework, on algebraic states.

</details>


### [236] [Do mixed states exhibit deep thermalisation?](https://arxiv.org/abs/2507.14135)
*Alan Sherry,Sthitadhi Roy*

Main category: quant-ph

TL;DR: 深层热化在混合态下会失效，但研究提出了新的混合态深层热化范式，并证明其在特定系统中可以实现。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于，传统的深层热化概念在混合初始态下会失效，即使存在微小的初始混合度。为了解决这个问题，需要提出一种适用于混合态的新型深层热化范式。

Method: 该研究首先指出，仅受守恒律约束的最大熵系综在混合初始态下无法实现深层热化。随后，提出了一种适用于混合态的新范式，通过追踪辅助自由度来形成深层热系综，并依赖于初始态的熵。接着，通过对自对偶踢伊辛链（一种可精确求解的系统）的研究，证明了在混合初始态下，该系综能在有限时间内出现。

Result: 研究表明，对于混合初始态，深层热化概念会失败。提出了一种新的混合态深层热化范式，该范式源于对增强系统上的最大熵系综进行追踪，并且系综结构明确取决于初始态的熵。在自对偶踢伊辛链上，该混合态深层热系综在有限时间内可以精确出现。

Conclusion: 该研究引入了一种新的混合态深层热化范式，该范式与纯态范式根本不同。该范式源于对增强系统上的最大熵系综进行追踪，并且系综结构明确取决于初始态的熵。研究表明，这种系综在典型的、局部相互作用的混沌系统中动态出现。对于自对偶踢伊辛链，研究发现混合态深层热系综在有限时间可以精确出现。

Abstract: The notion of $deep$ $thermalisation$, where ensembles of pure states on a
local subsystem, conditioned on measurement outcomes on its complement,
approach universal maximum-entropy ensembles constrained only by conservation
laws, represents a stronger form of ergodicity than conventional
thermalisation. We show that this framework fails dramatically for mixed
initial states, evolved unitarily, even with infinitesimal initial mixedness.
To address this, we introduce a new paradigm of deep thermalisation for mixed
states, fundamentally distinct from that for pure-state ensembles. In our
formulation, the deep thermal ensemble arises by tracing out auxiliary degrees
of freedom from a maximum-entropy ensemble defined on an augmented system, with
the ensemble structure depending explicitly on the entropy of the initial
state. We demonstrate that such ensembles emerge dynamically in generic,
locally interacting chaotic systems. For the self-dual kicked Ising chain,
which we show to be exactly solvable for a class of mixed initial states, we
find exact emergence of the so-defined mixed-state deep thermal ensemble at
finite times. Our results therefore lead to fundamental insights into how
maximum entropy principles and deep thermalisation manifest themselves in
unitary dynamics of states with finite entropy.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [237] [PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning](https://arxiv.org/abs/2507.13355)
*Riadul Islam,Dhandeep Challagundla*

Main category: cs.AR

TL;DR: 利用人工智能（AI）驱动的电子设计自动化（EDA）工具、高性能计算和并行化算法对于下一代微处理器创新至关重要。本研究提出了一种无监督学习方法，用于设计规则检查（DRC）违规预测，解决了现有监督学习方法对数据集的需求和训练时间长的痛点。该方法在准确率上优于传统模型，并在训练时间上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习（ML）和神经网络（NN）模型在设计规则检查（DRC）和光刻热点检测方面需要大量均衡的标注数据集和较长的训练时间，而本研究旨在解决这些挑战。

Method: 提出了一种无监督学习方法，用于设计规则检查（DRC）违规预测。该方法能够使用不平衡数据集，仅需一个类别的标签即可训练模型，并通过设定阈值来判断新数据的分类。

Result: 所提出的无监督模型在 99.95% 的预测测试准确率，相比之下，支持向量机（SVM）和神经网络（NN）模型的准确率分别为 85.44% 和 98.74%。此外，与 SVM 和 NN 模型相比，该方法的训练时间分别低了约 26.3 倍和最多 6003 倍。

Conclusion: 该研究提出了首个无监督设计规则检查（DRC）违规预测方法，该方法可使用不平衡数据集，仅需一个类别即可构建模型，并能通过设置阈值对新数据进行分类。

Abstract: Leveraging artificial intelligence (AI)-driven electronic design and
automation (EDA) tools, high-performance computing, and parallelized algorithms
are essential for next-generation microprocessor innovation, ensuring continued
progress in computing, AI, and semiconductor technology. Machine learning-based
design rule checking (DRC) and lithography hotspot detection can improve
first-pass silicon success. However, conventional ML and neural network
(NN)-based models use supervised learning and require a large balanced dataset
(in terms of positive and negative classes) and training time. This research
addresses those key challenges by proposing the first-ever unsupervised DRC
violation prediction methodology. The proposed model can be built using any
unbalanced dataset using only one class and set a threshold for it, then
fitting any new data querying if they are within the boundary of the model for
classification. This research verified the proposed model by implementing
different computational cores using CMOS 28 nm technology and Synopsys Design
Compiler and IC Compiler II tools. Then, layouts were divided into virtual
grids to collect about 60k data for analysis and verification. The proposed
method has 99.95% prediction test accuracy, while the existing support vector
machine (SVM) and neural network (NN) models have 85.44\% and 98.74\% accuracy,
respectively. In addition, the proposed methodology has about 26.3x and up to
6003x lower training times compared to SVM and NN-models, respectively.

</details>


### [238] [VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation](https://arxiv.org/abs/2507.13369)
*Paul E. Calzada,Zahin Ibnat,Tanvir Rahman,Kamal Kandula,Danyu Lu,Sujan Kumar Saha,Farimah Farahmandi,Mark Tehranipoor*

Main category: cs.AR

TL;DR: 本文作者构建了一个大规模、高质量的 Verilog 数据集，用于改进大型语言模型在硬件设计自动化中的应用，特别是 RTL 代码生成。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在硬件设计自动化（特别是 RTL 代码生成）中日益普及，需要高质量的数据集来训练和微调 LLM。

Method: 通过数据库（DB）创建与管理（PostgreSQL）、代码托管网站（OpenCores 和 GitHub）数据收集，以及代码语法验证、逻辑综合和元数据提取等预处理流程，构建了一个包含 20,392 个 Verilog 样本、751 MB Verilog 代码数据的稳健数据集。

Result: 构建了当时最大的、用于 LLM 微调的高质量 Verilog 数据集，其中包含 20,392 个 Verilog 样本和 751 MB 的代码数据。

Conclusion: 本文构建了一个大规模、高质量的 Verilog 数据集，用于 LLM 在硬件设计自动化领域的微调，为该领域的研究和发展奠定了基础。

Abstract: Large Language Models (LLMs) are gaining popularity for hardware design
automation, particularly through Register Transfer Level (RTL) code generation.
In this work, we examine the current literature on RTL generation using LLMs
and identify key requirements for training and fine-tuning datasets. We
construct a robust Verilog dataset through an automated three-pronged process
involving database (DB) creation and management with PostgreSQL, data
collection from code hosting sites like OpenCores and GitHub, and data
preprocessing to verify the codes' syntax, run logic synthesis, and extract
relevant module metadata. We implement a scalable and efficient DB
infrastructure to support analysis and detail our preprocessing pipeline to
enforce high-quality data before DB insertion. The resulting dataset comprises
20,392 Verilog samples, 751 MB of Verilog code data, which is the largest
high-quality Verilog dataset for LLM fine-tuning to our knowledge. We further
evaluate the dataset, address associated challenges, and explore potential
applications for future research and development in LLM-based hardware
generation.

</details>


### [239] [GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment](https://arxiv.org/abs/2507.13375)
*Chunyuan Zhao,Zizheng Guo,Zuodong Zhang,Yibo Lin*

Main category: cs.AR

TL;DR: A GPU-accelerated framework (GAP-LA) for VLSI circuit layer assignment optimizes timing, power, and congestion simultaneously, outperforming existing methods on large designs.


<details>
  <summary>Details</summary>
Motivation: Existing layer assignment studies are mostly limited to a subset of objectives, making it challenging to simultaneously optimize timing, power, and congestion efficiently with growing design complexity.

Method: The paper proposes a GPU-accelerated performance-driven layer assignment framework, GAP-LA, for holistic optimization of timing, power, and congestion.

Result: GAP-LA achieves 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4% better total negative slack (TNS) while maintaining power and congestion with competitive runtime compared with ISPD 2025 contest winners, especially on designs with up to 12 millions of nets.

Conclusion: GAP-LA can achieve better WNS and TNS while maintaining power and congestion with competitive runtime compared with ISPD 2025 contest winners, especially on large designs.

Abstract: Layer assignment is critical for global routing of VLSI circuits. It converts
2D routing paths into 3D routing solutions by determining the proper metal
layer for each routing segments to minimize congestion and via count. As
different layers have different unit resistance and capacitance, layer
assignment also has significant impacts to timing and power. With growing
design complexity, it becomes increasingly challenging to simultaneously
optimize timing, power, and congestion efficiently. Existing studies are mostly
limited to a subset of objectives. In this paper, we propose a GPU-accelerated
performance-driven layer assignment framework, GAP-LA, for holistic
optimization the aforementioned objectives. Experimental results demonstrate
that we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4%
better total negative slack (TNS) while maintaining power and congestion with
competitive runtime compared with ISPD 2025 contest winners, especially on
designs with up to 12 millions of nets.

</details>


### [240] [4T2R X-ReRAM CiM Array for Variation-tolerant, Low-power, Massively Parallel MAC Operation](https://arxiv.org/abs/2507.13631)
*Fuyuki Kihara,Seiji Uenohara,Satoshi Awamura,Naoko Misawa,Chihiro Matsui,Ken Takeuchi*

Main category: cs.AR

TL;DR: A new 4T2R ReRAM cell and 8T SRAM CiM architecture are proposed to address power consumption and error issues in AI accelerators, showing reduced errors compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Computation-in-Memory (CiM) is a promising technology for AI accelerators due to its high speed and low power consumption. However, existing CiM technologies face challenges with increased power consumption and device-derived errors as row parallelism increases.

Method: The paper proposes a 4T2R ReRAM cell and an 8T SRAM CiM architecture.

Result: The proposed 4T2R ReRAM cell reduces errors compared to conventional 4T4R ReRAM cells, making it more suitable for CiM applications.

Conclusion: The proposed 4T2R ReRAM cell and 8T SRAM CiM are suitable for CiM applications. Adopting the proposed 4T2R ReRAM cell reduces errors due to variation in ReRAM devices compared to conventional 4T4R ReRAM cells.

Abstract: Computation-in-Memory (CiM) is attracting attention as a technology that can
perform MAC calculations required for AI accelerators, at high speed with low
power consumption. However, there is a problem regarding power consumption and
device-derived errors that increase as row parallelism increases. In this
paper, a 4T2R ReRAM cell and an 8T SRAM CiM suitable for CiM is proposed. It is
shown that adopting the proposed 4T2R ReRAM cell reduces the errors due to
variation in ReRAM devices compared to conventional 4T4R ReRAM cells.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [241] [Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms](https://arxiv.org/abs/2507.13455)
*Dean Chen,Armin Pomeroy,Brandon T. Peterson,Will Flanagan,He Kai Lim,Alexandra Stavrakis,Nelson F. SooHoo,Jonathan B. Hopkins,Tyler R. Clites*

Main category: cs.RO

TL;DR: 为了解决柔顺机构在实际应用中易失效的问题，该研究提出了一种新的设计方法，通过集成耦合的多自由度运动限制来提供过载保护，并通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 柔顺机构在精密应用中具有巨大潜力，但其对疲劳和机械故障的固有脆弱性阻碍了其在实际应用中的转化。在服务环境尤为如此，因为那里的载荷复杂且不确定，并且故障成本高昂。在这种情况下，机械硬止动器对于防止屈服和屈曲至关重要。

Method: 提出了一种系统的设计综合方法，通过在单个紧凑的硬止动器表面对中集成耦合的多自由度运动限制，来保证柔顺机构的过载保护。具体来说，我们为优化接触面几何形状提供了一个理论和实践框架，以最大化机构的多自由度工作空间，同时确保机构保持在其弹性范围内。

Result: 将该综合方法应用于骨科植入物的笼式铰链机构的案例研究，并通过数值和实验验证，证明了所导出的设计能够可靠地防止疲劳、屈服和屈曲。

Conclusion: 该研究为在不确定载荷下运行的柔顺系统中精密硬止动器设计奠定了基础，这是实现柔顺机构在实际系统中应用的关键一步。

Abstract: Compliant mechanisms have significant potential in precision applications due
to their ability to guide motion without contact. However, an inherent
vulnerability to fatigue and mechanical failure has hindered the translation of
compliant mechanisms to real-world applications. This is particularly
challenging in service environments where loading is complex and uncertain, and
the cost of failure is high. In such cases, mechanical hard stops are critical
to prevent yielding and buckling. Conventional hard-stop designs, which rely on
stacking single-DOF limits, must be overly restrictive in multi-DOF space to
guarantee safety in the presence of unknown loads. In this study, we present a
systematic design synthesis method to guarantee overload protection in
compliant mechanisms by integrating coupled multi-DOF motion limits within a
single pair of compact hard-stop surfaces. Specifically, we introduce a
theoretical and practical framework for optimizing the contact surface geometry
to maximize the mechanisms multi-DOF working space while still ensuring that
the mechanism remains within its elastic regime. We apply this synthesis method
to a case study of a caged-hinge mechanism for orthopaedic implants, and
provide numerical and experimental validation that the derived design offers
reliable protection against fatigue, yielding, and buckling. This work
establishes a foundation for precision hard-stop design in compliant systems
operating under uncertain loads, which is a crucial step toward enabling the
application of compliant mechanisms in real-world systems.

</details>


### [242] [ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations](https://arxiv.org/abs/2507.13468)
*Shiye Cao,Maia Stiber,Amama Mahmood,Maria Teresa Parreira,Wendy Ju,Micol Spitale,Hatice Gunes,Chien-Ming Huang*

Main category: cs.RO

TL;DR: ERR@HRI 2.0 挑战赛旨在通过多模态数据和机器学习模型来检测和解决 LLM 驱动的对话机器人在人机交互中的错误，以提高对话的可靠性和用户信任度。


<details>
  <summary>Details</summary>
Motivation: 为了解决 LLM 驱动的对话机器人容易出错的问题，例如误解用户意图、过早中断用户或根本不响应，并防止对话中断、避免任务中断和维持用户信任。

Method: 该方法包括使用包含面部、语音和头部运动特征的多模态数据集，对 LLM 驱动的对话机器人故障进行基准测试和检测，并鼓励研究人员开发机器学习模型来检测这些故障。

Result: ERR@HRI 2.0 挑战赛提供了一个包含 16 小时双向人机交互的多模态数据集，其中包含系统视角的机器人错误注释以及用户为解决机器人行为与用户期望不匹配而产生的纠正意图。

Conclusion: 该挑战赛代表了通过社会信号分析改进人机交互中故障检测的又一关键步骤。

Abstract: The integration of large language models (LLMs) into conversational robots
has made human-robot conversations more dynamic. Yet, LLM-powered
conversational robots remain prone to errors, e.g., misunderstanding user
intent, prematurely interrupting users, or failing to respond altogether.
Detecting and addressing these failures is critical for preventing
conversational breakdowns, avoiding task disruptions, and sustaining user
trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal
dataset of LLM-powered conversational robot failures during human-robot
conversations and encourages researchers to benchmark machine learning models
designed to detect robot failures. The dataset includes 16 hours of dyadic
human-robot interactions, incorporating facial, speech, and head movement
features. Each interaction is annotated with the presence or absence of robot
errors from the system perspective, and perceived user intention to correct for
a mismatch between robot behavior and user expectation. Participants are
invited to form teams and develop machine learning models that detect these
failures using multimodal data. Submissions will be evaluated using various
performance metrics, including detection accuracy and false positive rate. This
challenge represents another key step toward improving failure detection in
human-robot interaction through social signal analysis.

</details>


### [243] [SCOPE for Hexapod Gait Generation](https://arxiv.org/abs/2507.13539)
*Jim O'Connor,Jay B. Nash,Derin Gezgin,Gary B. Parker*

Main category: cs.RO

TL;DR: SCOPE通过利用离散余弦变换（DCT）压缩输入数据，提高了进化算法在处理复杂输入时的学习效率和功效，特别是在六足机器人步态学习任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了应对输入空间复杂性增加导致进化算法学习效率下降的挑战，本研究提出了SCOPE。

Method: 该方法利用离散余弦变换（DCT）直接从输入矩阵的特征系数中学习。通过截断DCT返回的系数矩阵，可以在保留原始输入最高能量特征的同时降低输入维度。

Result: 在六足机器人步态学习任务中，SCOPE将时间序列姿态数据的总输入尺寸从2700减少到54（降低了98%），使参考算法的功效提高了20%。

Conclusion: SCOPE能够显著压缩进化控制器输入的尺寸，从而在功效方面获得统计学上的显著提升。

Abstract: Evolutionary methods have previously been shown to be an effective learning
method for walking gaits on hexapod robots. However, the ability of these
algorithms to evolve an effective policy rapidly degrades as the input space
becomes more complex. This degradation is due to the exponential growth of the
solution space, resulting from an increasing parameter count to handle a more
complex input. In order to address this challenge, we introduce Sparse Cosine
Optimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine
Transform (DCT) to learn directly from the feature coefficients of an input
matrix. By truncating the coefficient matrix returned by the DCT, we can reduce
the dimensionality of an input while retaining the highest energy features of
the original input. We demonstrate the effectiveness of this method by using
SCOPE to learn the gait of a hexapod robot. The hexapod controller is given a
matrix input containing time-series information of previous poses, which are
then transformed to gait parameters by an evolved policy. In this task, the
addition of SCOPE to a reference algorithm achieves a 20% increase in efficacy.
SCOPE achieves this result by reducing the total input size of the time-series
pose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of
compressing an input to any output shape, provided that each output dimension
is no greater than the corresponding input dimension. This paper demonstrates
that SCOPE is capable of significantly compressing the size of an input to an
evolved controller, resulting in a statistically significant gain in efficacy.

</details>


### [244] [Improving Low-Cost Teleoperation: Augmenting GELLO with Force](https://arxiv.org/abs/2507.13602)
*Shivakanth Sujit,Luca Nunziante,Dan Ogawa Lillrank,Rousslan Fernand Julien Dossa,Kai Arulkumaran*

Main category: cs.RO

TL;DR: The GELLO teleoperation system was enhanced with force feedback and force data for imitation learning, leading to improved task performance and user preference in robotic manipulation tasks.


<details>
  <summary>Details</summary>
Motivation: To extend the low-cost GELLO teleoperation system with additional force information for improved performance and user experience in robotic manipulation tasks.

Method: The study extended the GELLO teleoperation system with force feedback and incorporated force information into imitation learning models. The system was implemented on a GELLO system with a Franka Panda arm. Policies trained with and without force information were compared on simulated and real dexterous manipulation tasks.

Result: Qualitative user study indicated a preference for the force-feedback controller among users with robotics experience. Task success improved on the majority of tasks when force inputs were included.

Conclusion: The addition of force information to the GELLO teleoperation system improved task success in a majority of tasks, and users with robotics experience preferred the force-feedback controller.

Abstract: In this work we extend the low-cost GELLO teleoperation system, initially
designed for joint position control, with additional force information. Our
first extension is to implement force feedback, allowing users to feel
resistance when interacting with the environment. Our second extension is to
add force information into the data collection process and training of
imitation learning models. We validate our additions by implementing these on a
GELLO system with a Franka Panda arm as the follower robot, performing a user
study, and comparing the performance of policies trained with and without force
information on a range of simulated and real dexterous manipulation tasks.
Qualitatively, users with robotics experience preferred our controller, and the
addition of force inputs improved task success on the majority of tasks.

</details>


### [245] [Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones](https://arxiv.org/abs/2507.13647)
*Minze Li,Wei Zhao,Ran Chen,Mingqiang Wei*

Main category: cs.RO

TL;DR: 通过改进的PSO（PE-PSO）和基于GA的任务分配的多无人机框架，实现了无人机在动态环境下的实时轨迹规划，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAV）在动态环境中进行实时轨迹规划面临计算需求高、响应速度快和适应性强的挑战。传统PSO方法在实时场景下存在过早收敛和延迟问题。

Method: 提出了一种名为"PE-PSO"的增强粒子群优化（PSO）算法，通过引入持久探索机制和基于熵的参数调整策略来克服传统PSO的局限性。同时，提出了一种结合遗传算法（GA）任务分配和分布式PE-PSO的多无人机框架，使用B样条曲线模型化轨迹以保证平滑性并降低复杂度，实现可扩展和协调的轨迹生成。

Result: 仿真结果表明，所提出的分布式PE-PSO框架在轨迹质量、能效、避障和计算时间等多个指标上优于传统的PSO和其他基于群体的规划器，有效支持了复杂环境下的实时多无人机协同作业。

Conclusion: "PE-PSO" 及其多无人机框架在动态环境中实现了高效的实时轨迹规划，在轨迹质量、能效、避障和计算时间方面优于传统方法，证明了其在复杂条件下的实时多无人机作业能力。

Abstract: Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic
environments remains a key challenge due to high computational demands and the
need for fast, adaptive responses. Traditional Particle Swarm Optimization
(PSO) methods, while effective for offline planning, often struggle with
premature convergence and latency in real-time scenarios. To overcome these
limitations, we propose PE-PSO, an enhanced PSO-based online trajectory
planner. The method introduces a persistent exploration mechanism to preserve
swarm diversity and an entropy-based parameter adjustment strategy to
dynamically adapt optimization behavior. UAV trajectories are modeled using
B-spline curves, which ensure path smoothness while reducing optimization
complexity. To extend this capability to UAV swarms, we develop a multi-agent
framework that combines genetic algorithm (GA)-based task allocation with
distributed PE-PSO, supporting scalable and coordinated trajectory generation.
The distributed architecture allows for parallel computation and decentralized
control, enabling effective cooperation among agents while maintaining
real-time performance. Comprehensive simulations demonstrate that the proposed
framework outperforms conventional PSO and other swarm-based planners across
several metrics, including trajectory quality, energy efficiency, obstacle
avoidance, and computation time. These results confirm the effectiveness and
applicability of PE-PSO in real-time multi-UAV operations under complex
environmental conditions.

</details>


### [246] [Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography](https://arxiv.org/abs/2507.13650)
*Yu-Ting Lai,Yasamin Foroutani,Aya Barzelay,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 该研究开发了一种机器人系统，用于治疗白内障手术后的二次白内障，通过精确的囊膜映射和清洁，提高了手术效果并降低了并发症的风险。


<details>
  <summary>Details</summary>
Motivation: 二次白内障是白内障手术后常见的并发症，由残留的晶状体材料增殖引起。该研究旨在开发一种能够进行囊膜清洁手术的机器人系统，以提高手术精度和安全性。

Method: 开发了一个集成了标准经瞳和眼内光学相干断层扫描探头的机器人系统，用于囊膜可视化和工具-组织距离反馈。通过在眼标本上进行实验验证了囊膜映射策略的有效性，并通过在猪眼上进行了清洁策略实验。

Result: 在眼标本实验中，该系统将构建的囊膜模型的均方根误差降低了XX%。在离体猪眼实验中，清洁策略在未造成组织损伤的情况下成功进行了。

Conclusion: 该研究提出了一种集成了标准经瞳和眼内光学相干断层扫描探头的机器人系统，用于白内障手术后的二次白内障治疗。该系统能够实现完整的囊膜映射和实时工具-组织距离反馈，解决了精确囊膜建模的挑战。

Abstract: Secondary cataract is one of the most common complications of vision loss due
to the proliferation of residual lens materials that naturally grow on the lens
capsule after cataract surgery. A potential treatment is capsule cleaning, a
surgical procedure that requires enhanced visualization of the entire capsule
and tool manipulation on the thin membrane. This article presents a robotic
system capable of performing the capsule cleaning procedure by integrating a
standard transpupillary and an intraocular optical coherence tomography probe
on a surgical instrument for equatorial capsule visualization and real-time
tool-to-tissue distance feedback. Using robot precision, the developed system
enables complete capsule mapping in the pupillary and equatorial regions with
in-situ calibration of refractive index and fiber offset, which are still
current challenges in obtaining an accurate capsule model. To demonstrate
effectiveness, the capsule mapping strategy was validated through five
experimental trials on an eye phantom that showed reduced root-mean-square
errors in the constructed capsule model, while the cleaning strategy was
performed in three ex-vivo pig eyes without tissue damage.

</details>


### [247] [A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment](https://arxiv.org/abs/2507.13654)
*Haoran Wang,Yasamin Foroutani,Matthew Nepo,Mercedes Rodriguez,Ji Ma,Jean-Pierre Hubschman,Tsu-Chin Tsao,Jacob Rosen*

Main category: cs.RO

TL;DR: 在模拟玻璃体视网膜手术中，Inside Control方法在20倍或30倍的缩放因子下表现最佳，但最佳选择可能取决于具体任务。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在检验在模拟玻璃体视网膜手术环境中，Inside和Outside控制模式在不同缩放因子下的性能表现。

Method: 本研究使用了IRISS远程手术系统的控制台（驾驶舱），并适配投影了一个模拟的显微镜视图到一个虚拟现实（VR）头显中，以模拟玻璃体视网膜手术环境。五名经验丰富的玻璃体视网膜外科医生和五名没有手术经验的工程师使用该系统执行了玻璃体视网膜手术的常见任务。

Result: 实验结果表明，Inside Control方法在更高缩放因子（20或30）下实现了最佳的总体性能，但最佳缩放因子可能因任务和复杂性而异。

Conclusion: Inside Control方法在更高缩放因子（20或30）下实现了最佳的总体性能，但最佳缩放因子可能因任务和复杂性而异。优化控制方法和缩放因子有望提高手术效率和精度，并降低未来机器人辅助眼内手术的风险。

Abstract: This paper examines the performance of Inside and Outside Control modes at
various scaling factors in a simulated vitreoretinal surgical setting. The
IRISS teleoperated surgical system's console (cockpit) was adapted to project a
simulated microscope view of an intraocular setup to a virtual reality (VR)
headset. Five experienced vitreoretinal surgeons and five engineers with no
surgical experience used the system to perform tasks common to vitreoretinal
surgery. Experimental results indicate that Inside Control methods at higher
scaling factors (20 or 30) achieved the best performance overall, though the
optimal scaling factor may vary by task and complexity. Optimizing control
methods and scaling factors could lead to improvements in surgical efficiency
and accuracy, as well as minimize risks in future robotic-assisted intraocular
procedures.

</details>


### [248] [A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios](https://arxiv.org/abs/2507.13969)
*Maria Eduarda Silva de Macedo,Ana Paula Chiarelli de Souza,Roberto Silvio Ubertino Rosso Jr.,Yuri Kaszubowski Lopes*

Main category: cs.RO

TL;DR: 一种新的多任务自聚集方法，使用视线传感器，让机器人形成紧凑的聚类，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有研究中多任务自聚集方法在形成圆形或非完全自主方面存在的挑战，并提高集群动态对其他群体性能的影响。

Method: 提出了一种多任务自聚集方法，其中均质机器人群体仅依靠视线传感器进行自我组织，形成不同的紧凑聚类。

Result: 该方法实现了多任务自聚集行为的良好扩展性，形成了紧凑的聚类，并且在聚类紧密度方面优于现有研究，同时保持了相当的聚集机器人比例。

Conclusion: 本文提出的多任务自聚集方法能够实现均质机器人形成不同的紧凑聚类，并且仅依赖于视线传感器，同时保持了与其他研究相当的聚集机器人比例。

Abstract: The deployment of simple emergent behaviors in swarm robotics has been
well-rehearsed in the literature. A recent study has shown how self-aggregation
is possible in a multitask approach -- where multiple self-aggregation task
instances occur concurrently in the same environment. The multitask approach
poses new challenges, in special, how the dynamic of each group impacts the
performance of others. So far, the multitask self-aggregation of groups of
robots suffers from generating a circular formation -- that is not fully
compact -- or is not fully autonomous. In this paper, we present a multitask
self-aggregation where groups of homogeneous robots sort themselves into
different compact clusters, relying solely on a line-of-sight sensor. Our
multitask self-aggregation behavior was able to scale well and achieve a
compact formation. We report scalability results from a series of simulation
trials with different configurations in the number of groups and the number of
robots per group. We were able to improve the multitask self-aggregation
behavior performance in terms of the compactness of the clusters, keeping the
proportion of clustered robots found in other studies.

</details>


### [249] [Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion](https://arxiv.org/abs/2507.13662)
*Jing Cheng,Yasser G. Alqaham,Zhenyu Gan,Amit K. Sanyal*

Main category: cs.RO

TL;DR: 该研究提出了一种结合迭代学习控制（ILC）和力矩库（TL）的机器人行走控制框架，该框架具有可扩展性和自适应性。它提高了机器人在各种条件下的行走精度和泛化能力，并显著减少了计算量。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人行走中的关键挑战，例如在存在未建模动力学和外部干扰的情况下实现精确的轨迹跟踪。

Method: 该方法将迭代学习控制（ILC）与受生物启发的力矩库（TL）相结合，用于控制腿部机器人。它通过利用周期性步态的重复性并扩展ILC到非周期性任务来提高精度和泛化能力。控制架构是数据驱动的，结合了基于混合系统轨迹优化的物理模型和实时学习，以补偿模型不确定性和外部干扰。TL存储了学习到的控制配置文件，并能够快速适应速度、地形和重力条件的变化，从而减少了在线计算和重复学习的需求。

Result: 结果表明，该框架可将关节跟踪误差最多降低85%，并能可靠地执行周期性和非周期性步态，包括斜坡穿越和地形适应。与现有方法相比，该框架的学习技能无需在线计算即可执行，且控制更新速率提高了30倍以上。

Conclusion: 该研究提出了一种结合迭代学习控制（ILC）和受生物启发的力矩库（TL）的可扩展自适应控制框架，用于运动腿部机器人。该方法通过利用周期性步态的重复性并将ILC扩展到非周期性任务，提高了在非模型动力学和外部干扰下的精确度和泛化能力。该框架通过数据驱动，结合了基于混合系统轨迹优化的物理模型和实时学习，以补偿模型不确定性和外部干扰。其核心贡献在于开发了一个通用的TL，可以存储学习到的控制配置文件，并能够快速适应速度、地形和重力条件的变化，无需重复学习即可显著减少在线计算量。在双足机器人Cassie和四足机器人A1上的模拟和硬件实验结果表明，该框架在几秒钟内可将关节跟踪误差最多降低85%，并能可靠地执行周期性和非周期性步态，包括斜坡穿越和地形适应。与最先进的全身控制器相比，该框架的学习技能无需在线计算即可执行，控制更新速率比现有方法快30倍以上。

Abstract: This paper presents a scalable and adaptive control framework for legged
robots that integrates Iterative Learning Control (ILC) with a biologically
inspired torque library (TL), analogous to muscle memory. The proposed method
addresses key challenges in robotic locomotion, including accurate trajectory
tracking under unmodeled dynamics and external disturbances. By leveraging the
repetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the
framework enhances accuracy and generalization across diverse locomotion
scenarios. The control architecture is data-enabled, combining a physics-based
model derived from hybrid-system trajectory optimization with real-time
learning to compensate for model uncertainties and external disturbances. A
central contribution is the development of a generalized TL that stores learned
control profiles and enables rapid adaptation to changes in speed, terrain, and
gravitational conditions-eliminating the need for repeated learning and
significantly reducing online computation. The approach is validated on the
bipedal robot Cassie and the quadrupedal robot A1 through extensive simulations
and hardware experiments. Results demonstrate that the proposed framework
reduces joint tracking errors by up to 85% within a few seconds and enables
reliable execution of both periodic and nonperiodic gaits, including slope
traversal and terrain adaptation. Compared to state-of-the-art whole-body
controllers, the learned skills eliminate the need for online computation
during execution and achieve control update rates exceeding 30x those of
existing methods. These findings highlight the effectiveness of integrating ILC
with torque memory as a highly data-efficient and practical solution for legged
locomotion in unstructured and dynamic environments.

</details>


### [250] [SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization](https://arxiv.org/abs/2507.13702)
*Junho Choi,Kihwan Ryoo,Jeewon Kim,Taeyun Kim,Eungchang Lee,Myeongwoo Jeong,Kevin Christiansen Marsim,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种名为SaWa-ML的新型多机器人定位方法，利用UWB传感器数据减少长期漂移误差，并通过自适应权重提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多机器人定位是实现多机器人系统的关键任务。尽管研究人员提出了许多基于优化的多机器人定位方法，但个体机器人里程计估计和优化中使用的机器人间距离测量的特性考虑不足，并且先前研究受到个体机器人里程计估计精度的影响，导致长期漂移误差不可避免。

Method: 提出了一种新颖的视觉-惯性-测距多机器人定位方法，名为SaWa-ML，它能够进行几何结构感知姿态校正和基于权重自适应的鲁棒多机器人定位。

Result: 利用不累积量程误差的UWB传感器数据，首先估计机器人间的相对位置，然后校正每个机器人的位置，从而减少长期漂移误差。通过考虑传感器数据和视觉-惯性里程计估计的特性，为机器人姿态校正设计了自适应权重。

Conclusion: 在真实世界实验中验证了所提出的方法，与最先进的算法相比，性能有显著提高。

Abstract: Multi-robot localization is a crucial task for implementing multi-robot
systems. Numerous researchers have proposed optimization-based multi-robot
localization methods that use camera, IMU, and UWB sensors. Nevertheless,
characteristics of individual robot odometry estimates and distance
measurements between robots used in the optimization are not sufficiently
considered. In addition, previous researches were heavily influenced by the
odometry accuracy that is estimated from individual robots. Consequently,
long-term drift error caused by error accumulation is potentially inevitable.
In this paper, we propose a novel visual-inertial-range-based multi-robot
localization method, named SaWa-ML, which enables geometric structure-aware
pose correction and weight adaptation-based robust multi-robot localization.
Our contributions are twofold: (i) we leverage UWB sensor data, whose range
error does not accumulate over time, to first estimate the relative positions
between robots and then correct the positions of each robot, thus reducing
long-term drift errors, (ii) we design adaptive weights for robot pose
correction by considering the characteristics of the sensor data and
visual-inertial odometry estimates. The proposed method has been validated in
real-world experiments, showing a substantial performance increase compared
with state-of-the-art algorithms.

</details>


### [251] [AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework](https://arxiv.org/abs/2507.13729)
*Yu Yao,Salil Bhatnagar,Markus Mazzola,Vasileios Belagiannis,Igor Gilitschenski,Luigi Palmieri,Simon Razniewski,Marcel Hallgarten*

Main category: cs.RO

TL;DR: 该研究提出了一种基于LLM代理的框架，用于增强真实世界的交通场景。与现有方法不同，该框架通过自然语言描述实现对场景的细粒度控制，即使在小型LLM上也能高效运行。评估结果表明，该框架生成的场景质量与手动创建的相当，能够满足大规模自动驾驶系统评估的需求。


<details>
  <summary>Details</summary>
Motivation: 在测试和评估自动驾驶规划器时，罕见但关键的场景提出了重大挑战。仅依赖真实世界的驾驶场景需要收集海量数据集来捕获这些场景。虽然自动生成交通场景看起来很有前景，但数据驱动的模型需要大量的训练数据，并且往往缺乏对输出的细粒度控制。此外，从头开始生成新颖场景可能会导致与原始训练场景的分布发生偏移，从而破坏评估的有效性，特别是对于基于学习的规划器。为了规避这一点，最近的工作提出通过增强测试集中的原始场景来生成具有挑战性的场景。然而，这涉及到领域专家对手动增强场景的依赖，这种方法无法满足自动驾驶系统评估中对规模的需求。

Method: 本文引入了一种新颖的基于LLM代理的框架，利用自然语言描述来增强真实世界的交通场景，解决了现有方法的局限性。该框架的关键创新在于其代理设计，能够对输出进行细粒度控制，并能在较小的、经济高效的LLM上保持高性能。

Result: 框架能够准确地遵循用户意图，生成高质量的增强场景，可与手动创建的场景相媲美。

Conclusion: LLM代理框架能够通过自然语言描述来增强真实世界的交通场景，可以实现对输出的细粒度控制，并且即使使用较小的、具有成本效益的LLM也能保持高性能。广泛的专家评估证明，该框架能够准确地遵循用户意图，生成与手动创建的场景相媲美的高质量增强场景。

Abstract: Rare, yet critical, scenarios pose a significant challenge in testing and
evaluating autonomous driving planners. Relying solely on real-world driving
scenes requires collecting massive datasets to capture these scenarios. While
automatic generation of traffic scenarios appears promising, data-driven models
require extensive training data and often lack fine-grained control over the
output. Moreover, generating novel scenarios from scratch can introduce a
distributional shift from the original training scenes which undermines the
validity of evaluations especially for learning-based planners. To sidestep
this, recent work proposes to generate challenging scenarios by augmenting
original scenarios from the test set. However, this involves the manual
augmentation of scenarios by domain experts. An approach that is unable to meet
the demands for scale in the evaluation of self-driving systems. Therefore,
this paper introduces a novel LLM-agent based framework for augmenting
real-world traffic scenarios using natural language descriptions, addressing
the limitations of existing methods. A key innovation is the use of an agentic
design, enabling fine-grained control over the output and maintaining high
performance even with smaller, cost-effective LLMs. Extensive human expert
evaluation demonstrates our framework's ability to accurately adhere to user
intent, generating high quality augmented scenarios comparable to those created
manually.

</details>


### [252] [Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery](https://arxiv.org/abs/2507.13787)
*Doina Pisla,Alexandru Pusca,Andrei Caprariu,Adrian Pisla,Bogdan Gherman,Calin Vaida,Damien Chablat*

Main category: cs.RO

TL;DR: Two parallel robot designs for pancreatic surgery were evaluated for stiffness and workspace. One design was chosen for further development.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to design a parallel robot for robotic assisted minimally invasive pancreatic surgery and to select the most suitable architecture based on stiffness and usability criteria.

Method: The paper utilizes Finite Element Method (FEM) simulations to analyze the stiffness of two proposed parallel robot architectures (ATHENA-1 and ATHENA-2). A workspace quantitative analysis is also performed to assess their usability for medical tasks.

Result: FEM simulations indicated differences in stiffness between ATHENA-1 and ATHENA-2, and the workspace analysis provided insights into their usability. Based on these results, one architecture was selected for further development.

Conclusion: The paper proposes two parallel robot architectures, ATHENA-1 and ATHENA-2, for minimally invasive pancreatic surgery. FEM simulations and workspace analysis were conducted to evaluate stiffness and usability. The results were used to select the more suitable architecture for further development.

Abstract: This paper focuses on the design of a parallel robot designed for robotic
assisted minimally invasive pancreatic surgery. Two alternative architectures,
called ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are
proposed. Their kinematic schemes are presented, and the conceptual 3D CAD
models are illustrated. Based on these, two Finite Element Method (FEM)
simulations were performed to determine which architecture has the higher
stiffness. A workspace quantitative analysis is performed to further assess the
usability of the two proposed parallel architectures related to the medical
tasks. The obtained results are used to select the architecture which fit the
required design criteria and will be used to develop the experimental model of
the surgical robot.

</details>


### [253] [Safety Certification in the Latent space using Control Barrier Functions and World Models](https://arxiv.org/abs/2507.13871)
*Mehul Anand,Shishir Kolathaya*

Main category: cs.RO

TL;DR: A new semi-supervised framework uses control barrier certificates in a world model's latent space to create safe controllers from visual data efficiently, reducing the need for extensive labeling.


<details>
  <summary>Details</summary>
Motivation: Traditional methods for synthesizing safe controllers from visual data require extensive supervised labeling, which is often impractical. World models offer a potential solution for scalable and data-efficient safe control.

Method: The paper proposes a semi-supervised framework that learns a neural barrier function and a safe controller by leveraging control barrier certificates (CBCs) in the latent space of a world model. The approach utilizes limited labeled data and vision transformers for latent dynamics modeling.

Result: The framework successfully synthesizes safe visuomotor policies by jointly learning a neural barrier function and a safe controller using limited labeled data and the predictive power of vision transformers for latent dynamics modeling.

Conclusion: Synthesizing safe controllers from visual data can be achieved with a semi-supervised framework that uses control barrier certificates in the latent space of a world model. This approach learns a neural barrier function and a safe controller with limited labeled data, utilizing the predictive capabilities of vision transformers for latent dynamics modeling.

Abstract: Synthesising safe controllers from visual data typically requires extensive
supervised labelling of safety-critical data, which is often impractical in
real-world settings. Recent advances in world models enable reliable prediction
in latent spaces, opening new avenues for scalable and data-efficient safe
control. In this work, we introduce a semi-supervised framework that leverages
control barrier certificates (CBCs) learned in the latent space of a world
model to synthesise safe visuomotor policies. Our approach jointly learns a
neural barrier function and a safe controller using limited labelled data,
while exploiting the predictive power of modern vision transformers for latent
dynamics modelling.

</details>


### [254] [AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery](https://arxiv.org/abs/2507.13903)
*Ziliang Li,Hongming Chen,Yiyang Lin,Biyu Ye,Ximin Lyu*

Main category: cs.RO

TL;DR: 无人机空投任务面临模式切换、系统延迟和控制误差的挑战。该研究提出了一种基于空中机械臂（AM）的自主空投系统，通过引入额外的驱动自由度来补偿无人机跟踪误差，并采用分层扰动补偿策略和非线性模型预测控制（NMPC）来提高轨迹生成精度和鲁棒性，最终在仿真和实验中证明了该系统在空投任务中的敏捷性和精确性。


<details>
  <summary>Details</summary>
Motivation: Autonomous aerial systems are vital for tasks like transport and delivery in complex environments. Airdrop missions face challenges from abrupt control mode switching, system delays, and control errors. This paper addresses these by using an aerial manipulator (AM) to actively compensate for UAV tracking errors and improve airdrop precision.

Method: The proposed approach generates aerial throwing trajectories by imposing smooth and continuous constraints on the parabolic landing point, making them less sensitive to payload release timing. A hierarchical disturbance compensation strategy is incorporated into the Nonlinear Model Predictive Control (NMPC) framework to mitigate parameter changes and improve precision.

Result: Both simulation and real-world experimental results demonstrate that the proposed system achieves greater agility and precision in airdrop missions.

Conclusion: 该研究 presented an autonomous airdrop system based on an aerial manipulator (AM)，which improves agility and precision in airdrop missions through active compensation for UAV tracking errors and hierarchical disturbance compensation integrated into NMPC.

Abstract: Autonomous aerial systems play an increasingly vital role in a wide range of
applications, particularly for transport and delivery tasks in complex
environments. In airdrop missions, these platforms face the dual challenges of
abrupt control mode switching and inherent system delays along with control
errors. To address these issues, this paper presents an autonomous airdrop
system based on an aerial manipulator (AM). The introduction of additional
actuated degrees of freedom enables active compensation for UAV tracking
errors. By imposing smooth and continuous constraints on the parabolic landing
point, the proposed approach generates aerial throwing trajectories that are
less sensitive to the timing of payload release. A hierarchical disturbance
compensation strategy is incorporated into the Nonlinear Model Predictive
Control (NMPC) framework to mitigate the effects of sudden changes in system
parameters, while the predictive capabilities of NMPC are further exploited to
improve the precision of aerial throwing. Both simulation and real-world
experimental results demonstrate that the proposed system achieves greater
agility and precision in airdrop missions.

</details>


### [255] [NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning](https://arxiv.org/abs/2507.13940)
*Qingyi Chen,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 介绍了一种名为神经哈密顿-雅可比可达性学习（HJR）的去中心化多智能体运动规划新方法，该方法通过学习可扩展的神经HJR模型解决了高维配置空间问题，并通过去中心化的轨迹优化框架实现了实时规划，在各种场景下均表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在去中心化（依赖预测、合同共享或通信）和中心化（可扩展性差、实时决策困难）方法之间面临的困境。

Method: 通过学习可扩展的神经HJR模型来解决高维配置空间问题，并结合去中心化的轨迹优化框架来实时解决MAMP任务。

Result: 所提出的方法在12维双臂设置等各种动态系统中表现良好，并在MAMP任务中取得了成功。

Conclusion: 该方法在更高维度的复杂场景下具有可扩展性和数据效率，并在具有挑战性的多代理运动规划任务中优于最先进的技术。

Abstract: Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in
robotics. Despite substantial advancements, existing methods often face a
dilemma. Decentralized algorithms typically rely on predicting the behavior of
other agents, sharing contracts, or maintaining communication for safety, while
centralized approaches struggle with scalability and real-time decision-making.
To address these challenges, we introduce Neural Hamilton-Jacobi Reachability
Learning (HJR) for Decentralized Multi-Agent Motion Planning. Our method
provides scalable neural HJR modeling to tackle high-dimensional configuration
spaces and capture worst-case collision and safety constraints between agents.
We further propose a decentralized trajectory optimization framework that
incorporates the learned HJR solutions to solve MAMP tasks in real-time. We
demonstrate that our method is both scalable and data-efficient, enabling the
solution of MAMP problems in higher-dimensional scenarios with complex
collision constraints. Our approach generalizes across various dynamical
systems, including a 12-dimensional dual-arm setup, and outperforms a range of
state-of-the-art techniques in successfully addressing challenging MAMP tasks.
Video demonstrations are available at https://youtu.be/IZiePX0p1Mc.

</details>


### [256] [A segmented robot grasping perception neural network for edge AI](https://arxiv.org/abs/2507.13970)
*Casper Bröcheler,Thomas Vroom,Derrick Timmermans,Alan van den Akker,Guangzhi Tang,Charalampos S. Kouzinopoulos,Rico Möckel*

Main category: cs.RO

TL;DR: 研究将抓取检测框架在 GAP9 RISC-V 系统芯片上实现并优化，验证了低功耗微控制器在资源受限环境中实现实时抓取操作的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的环境中实现低延迟、低功耗的实时抓取，研究旨在将深度神经网络模型部署到边缘设备上。

Method: 本研究在 GAP9 RISC-V 系统芯片上实现了 Heatmap-Guided Grasp Detection 框架，用于检测 6-DoF 抓取姿态。通过输入降维、模型分区和量化等硬件感知技术对模型进行了优化。

Result: 在 GraspNet-1Billion 基准测试上的实验评估验证了完全在芯片上进行推理的可行性，证明了低功耗微控制器在实时自主操作方面的潜力。

Conclusion: 该研究展示了在低功耗微控制器上实现实时自主抓取操作的可行性，通过在 GAP9 RISC-V 系统芯片上实现和优化 Heatmap-Guided Grasp Detection 框架，实现了完全在芯片上进行推理。

Abstract: Robotic grasping, the ability of robots to reliably secure and manipulate
objects of varying shapes, sizes and orientations, is a complex task that
requires precise perception and control. Deep neural networks have shown
remarkable success in grasp synthesis by learning rich and abstract
representations of objects. When deployed at the edge, these models can enable
low-latency, low-power inference, making real-time grasping feasible in
resource-constrained environments. This work implements Heatmap-Guided Grasp
Detection, an end-to-end framework for the detection of 6-Dof grasp poses, on
the GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware
techniques, including input dimensionality reduction, model partitioning, and
quantisation. Experimental evaluation on the GraspNet-1Billion benchmark
validates the feasibility of fully on-chip inference, highlighting the
potential of low-power MCUs for real-time, autonomous manipulation.

</details>


### [257] [A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems](https://arxiv.org/abs/2507.14043)
*Genliang Li,Yaxin Cui,Jinyu Su*

Main category: cs.RO

TL;DR: 提出了一种改进的蛇优化算法（MISO），通过引入自适应随机扰动、自适应 Levy 飞行和精英领导力结合布朗运动等策略，解决了原算法收敛慢和易陷入局部最优的问题，并在多个测试函数和实际应用（如无人机路径规划）中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 原始蛇优化算法（SO）存在收敛速度慢和容易陷入局部最优的问题。为了克服这些缺点，提出MISO。

Method: 提出了一种结合正弦函数自适应随机扰动策略、尺度因子与领头者自适应 Levy 飞行策略以及精英领袖与布朗运动相结合的位置更新策略的多策略改进蛇优化算法（MISO）。

Result: MISO在30个CEC2017测试函数和CEC2022测试套件上，与11种流行算法进行比较，证明了其有效性。此外，MISO在无人机三维路径规划和6个工程设计问题上的应用结果表明，MISO在解的质量和稳定性方面优于其他算法。

Conclusion: MISO在CEC2017测试函数、CEC2022测试套件以及无人机三维路径规划和工程设计问题上均表现优于其他算法，证明了其在解决复杂优化问题上的有效性和鲁棒性。

Abstract: Metaheuristic algorithms have gained widespread application across various
fields owing to their ability to generate diverse solutions. One such algorithm
is the Snake Optimizer (SO), a progressive optimization approach. However, SO
suffers from the issues of slow convergence speed and susceptibility to local
optima. In light of these shortcomings, we propose a novel Multi-strategy
Improved Snake Optimizer (MISO). Firstly, we propose a new adaptive random
disturbance strategy based on sine function to alleviate the risk of getting
trapped in a local optimum. Secondly, we introduce adaptive Levy flight
strategy based on scale factor and leader and endow the male snake leader with
flight capability, which makes it easier for the algorithm to leap out of the
local optimum and find the global optimum. More importantly, we put forward a
position update strategy combining elite leadership and Brownian motion,
effectively accelerating the convergence speed while ensuring precision.
Finally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test
functions and the CEC2022 test suite, comparing it with 11 popular algorithms
across different dimensions to validate its effectiveness. Moreover, Unmanned
Aerial Vehicle (UAV) has been widely used in various fields due to its
advantages of low cost, high mobility and easy operation. However, the UAV path
planning problem is crucial for flight safety and efficiency, and there are
still challenges in establishing and optimizing the path model. Therefore, we
apply MISO to the UAV 3D path planning problem as well as 6 engineering design
problems to assess its feasibility in practical applications. The experimental
results demonstrate that MISO exceeds other competitive algorithms in terms of
solution quality and stability, establishing its strong potential for
application.

</details>


### [258] [EdgeVLA: Efficient Vision-Language-Action Models](https://arxiv.org/abs/2507.14049)
*Paweł Budzianowski,Wesley Maa,Matthew Freed,Jingxiang Mo,Winston Hsiao,Aaron Xie,Tomasz Młoduchowski,Viraj Tipnis,Benjamin Bolte*

Main category: cs.RO

TL;DR: EVLA 是一种新型方法，它通过消除自回归要求并利用小型语言模型，显著提高了视觉-语言-动作 (VLA) 模型在边缘设备上的推理速度和内存效率，同时保持了模型的表征能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人领域数据稀缺的挑战，并克服将大型视觉-语言模型 (VLM) 部署到资源受限的移动操作系统上的障碍，从而在机器人领域实现可泛化的视觉-动作控制策略。

Method: EVLA通过两个关键创新来提高推理速度：1. 消除对末端执行器位置预测的自回归要求，实现了7倍的推理加速。2. 利用小型语言模型 (SLM) 的效率，在显著降低计算需求的同时，展示了与大型模型相当的训练性能。

Result: EVLA 在保持与 OpenVLA 相当的训练特性的同时，在推理速度和内存效率方面取得了显著的提升，能够在边缘设备上实现实时性能。

Conclusion: Edge VLA (EVLA) 通过消除自回归需求并利用小型语言模型 (SLM)，在保持表征能力的同时，显著提高了视觉-语言-动作 (VLA) 模型在资源受限边缘设备上的推理速度和内存效率，实现了与 OpenVLA 相当的训练性能。

Abstract: Vision-Language Models (VLMs) have emerged as a promising approach to address
the data scarcity challenge in robotics, enabling the development of
generalizable visuomotor control policies. While models like OpenVLA showcase
the potential of this paradigm, deploying large-scale VLMs on
resource-constrained mobile manipulation systems remains a significant hurdle.
This paper introduces Edge VLA (EVLA), a novel approach designed to
significantly enhance the inference speed of Vision-Language-Action (VLA)
models. EVLA maintains the representational power of these models while
enabling real-time performance on edge devices. We achieve this through two key
innovations: 1) Eliminating the autoregressive requirement for end-effector
position prediction, leading to a 7x speedup in inference, and 2) Leveraging
the efficiency of Small Language Models (SLMs), demonstrating comparable
training performance to larger models with significantly reduced computational
demands. Our early results demonstrate that EVLA achieves comparable training
characteristics to OpenVLA while offering substantial gains in inference speed
and memory efficiency. We release our model checkpoints and training
\href{https://github.com/kscalelabs/evla }{codebase} to foster further
research.

</details>


### [259] [Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub](https://arxiv.org/abs/2507.14059)
*Tianyuan Wang,Mark A Post,Mathieu Deremetz*

Main category: cs.RO

TL;DR: STARFAB project is developing a Mobile Inspection Module (MIM) for an orbital warehouse to autonomously inspect and maintain space hardware using various sensors and a modular design.


<details>
  <summary>Details</summary>
Motivation: The motivation is to create a ground demonstration of an orbital automated warehouse (STARFAB) as a hub for sustainable commercial space operations. A critical aspect of this autonomous facility is the ability to monitor, inspect, and assess the condition of stored components and the facility itself, necessitating the development of the MIM.

Method: The STARFAB Mobile Inspection Module (MIM) is designed to be a mobile robot for an orbital automated warehouse. It utilizes Standard Interconnects (SI) for attachment to Walking Manipulators (WM) and can be stored and retrieved autonomously. The MIM is equipped with high-resolution cameras, a 3D profilometer, and a thermal imaging sensor, with provisions for modular sensor expansion. It also includes a grasping tool and torque wrench for maintenance tasks performed by the WM.

Result: The paper details the concept of operations for the MIM as an on-orbit autonomous inspection and maintenance system, the mechanical and electronic design of the MIM, and its sensor package for non-destructive testing. Implementation and testing are still ongoing.

Conclusion: Implementation and testing of the STARFAB Mobile Inspection Module (MIM) is ongoing, with the paper detailing its concept of operations, design, and sensor package for autonomous on-orbit inspection and maintenance.

Abstract: The use of autonomous robots in space is an essential part of the "New Space"
commercial ecosystem of assembly and re-use of space hardware components in
Earth orbit and beyond. The STARFAB project aims to create a ground
demonstration of an orbital automated warehouse as a hub for sustainable
commercial operations and servicing. A critical part of this fully-autonomous
robotic facility will be the capability to monitor, inspect, and assess the
condition of both the components stored in the warehouse, and the STARFAB
facility itself. This paper introduces ongoing work on the STARFAB Mobile
Inspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it
can be carried by Walking Manipulators (WM) as an independently-mobile robot,
and multiple MIMs can be stored and retrieved as needed for operations on
STARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a
thermal imaging sensor, with the capability to add other modular sensors. A
grasping tool and torque wrench are stored within the modular body for use by
an attached WM for maintenance operations. Implementation and testing is still
ongoing at the time of writing. This paper details the concept of operations
for the MIM as an on-orbit autonomous inspection and maintenance system, the
mechanical and electronic design of the MIM, and the sensors package used for
non-destructive testing.

</details>


### [260] [MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation](https://arxiv.org/abs/2507.14061)
*Nataliya Nechyporenko,Yutong Zhang,Sean Campbell,Alessandro Roncone*

Main category: cs.RO

TL;DR: MorphIt 是一种新的机器人形态表示算法，使用球形基元和梯度优化来平衡精度与计算效率，比现有方法效果更好，并提升了机器人的多种能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统通常将物理形态视为固定约束，而非可适应的资源，导致相同的僵化几何表示需要满足计算和精度要求差异巨大的应用。本研究旨在解决这一问题，让机器人能够重新思考其形态表示，以更好地适应多样化的任务需求。

Method: MorphIt 算法使用球形基元来逼近机器人形态，并采用基于梯度的优化框架，该框架具有可调参数，能够显式控制几何保真度与计算成本之间的权衡。

Result: MorphIt 在多项指标上优于基线方法（变分球体集逼近和自适应中轴逼近），用更少的球体实现了更好的网格逼近，并降低了计算开销。实验表明，该方法在碰撞检测精度、接触丰富的交互模拟和狭窄空间导航方面增强了机器人能力。

Conclusion: MorphIt 通过使用球形基元自适应地逼近机器人形态，在几何精度和计算效率之间取得了新的平衡。该方法通过梯度优化框架实现，允许用户控制保真度和计算成本的权衡。与现有方法相比，MorphIt 在网格逼近精度、所需球体数量和计算开销方面均表现更优。实验证明，MorphIt 能够提高机器人进行碰撞检测、接触丰富的交互模拟以及在狭窄空间导航的能力。通过使几何表示能够根据任务需求动态调整，机器人可以利用其物理形态作为一种主动资源，而非固定参数，从而为需要在精度和计算可行性之间持续权衡的操控任务开辟了新的可能性。

Abstract: What if a robot could rethink its own morphological representation to better
meet the demands of diverse tasks? Most robotic systems today treat their
physical form as a fixed constraint rather than an adaptive resource, forcing
the same rigid geometric representation to serve applications with vastly
different computational and precision requirements. We introduce MorphIt, a
novel algorithm for approximating robot morphology using spherical primitives
that balances geometric accuracy with computational efficiency. Unlike existing
approaches that rely on either labor-intensive manual specification or
inflexible computational methods, MorphIt implements an automatic
gradient-based optimization framework with tunable parameters that provides
explicit control over the physical fidelity versus computational cost tradeoff.
Quantitative evaluations demonstrate that MorphIt outperforms baseline
approaches (Variational Sphere Set Approximation and Adaptive Medial-Axis
Approximation) across multiple metrics, achieving better mesh approximation
with fewer spheres and reduced computational overhead. Our experiments show
enhanced robot capabilities in collision detection accuracy, contact-rich
interaction simulation, and navigation through confined spaces. By dynamically
adapting geometric representations to task requirements, robots can now exploit
their physical embodiment as an active resource rather than an inflexible
parameter, opening new frontiers for manipulation in environments where
physical form must continuously balance precision with computational
tractability.

</details>


### [261] [Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation](https://arxiv.org/abs/2507.14099)
*Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Maria Koskinopoulou,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 提出了一种自适应启发式运动规划框架，通过结合启发式运动空间（HMS）和贝叶斯网络来改进自主水下操作的运动规划，实现了更优化的路径和实时规划能力。


<details>
  <summary>Details</summary>
Motivation: 自主运动规划对于动态海洋环境中高效且安全的 水下操作至关重要。当前方法未能有效利用先验运动经验并适应水下环境固有的实时不确定性。

Method: 本框架集成了启发式运动空间（HMS）和贝叶斯网络，利用启发式运动空间中的概率路径图（PRM）算法，通过最小化考虑距离、不确定性、能耗和执行时间的复合成本函数来优化路径。利用 HMS 减少了搜索空间，提高了计算性能和实时规划能力。利用贝叶斯网络根据实时传感器数据和环境条件动态更新不确定性估计，从而优化路径成功率的联合概率。

Result: 通过广泛的模拟和现实世界测试场景，展示了该方法在提高性能和鲁棒性方面的优势。

Conclusion: 该方法显著提高了自主水下机器人的能力，确保了在动态海洋挑战下优化运动规划。

Abstract: Autonomous motion planning is critical for efficient and safe underwater
manipulation in dynamic marine environments. Current motion planning methods
often fail to effectively utilize prior motion experiences and adapt to
real-time uncertainties inherent in underwater settings. In this paper, we
introduce an Adaptive Heuristic Motion Planner framework that integrates a
Heuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning
for autonomous underwater manipulation. Our approach employs the Probabilistic
Roadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite
cost function that accounts for distance, uncertainty, energy consumption, and
execution time. By leveraging HMS, our framework significantly reduces the
search space, thereby boosting computational performance and enabling real-time
planning capabilities. Bayesian Networks are utilized to dynamically update
uncertainty estimates based on real-time sensor data and environmental
conditions, thereby refining the joint probability of path success. Through
extensive simulations and real-world test scenarios, we showcase the advantages
of our method in terms of enhanced performance and robustness. This
probabilistic approach significantly advances the capability of autonomous
underwater robots, ensuring optimized motion planning in the face of dynamic
marine challenges.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [262] [Joint Motion, Angle, and Range Estimation in Near-Field under Array Calibration Imperfections](https://arxiv.org/abs/2507.13463)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 在超大规模MIMO通信中，提出一种新方法，利用角度-多普勒域分析和低复杂度算法，高效精确地估计近场目标的位置和速度，同时降低计算量。


<details>
  <summary>Details</summary>
Motivation: 近场（NF）通信体制下，位置和运动参数的联合估计计算成本高昂。

Method: 提出一种新颖方法，利用二维离散傅里叶变换（2D-DFT）将接收到的二维时空信号投影到角度-多普勒域。分析表明，角度扩展以目标的真实角度为中心，其宽度由目标距离决定；横向运动引起的 متجه多普勒扩展以真实的径向速度为中心，其宽度与横向速度成正比。利用这些频谱特性，开发了一种低复杂度算法，提供角度、距离和速度的粗略估计，随后通过独立应用于每个参数的一维多信号分类（MUSIC）进行细化。

Result: 与最大似然估计相比，在位置和速度估计方面实现了-40 dB的归一化均方误差（NMSE），同时显著降低了计算复杂度。

Conclusion: 所提出的方法通过利用角度-多普勒域中的频谱特性，实现了对近场目标运动参数的准确高效估计，并且计算复杂度显著降低。

Abstract: Ultra-massive multiple-input multiple-output MIMO (UM-MIMO) leverages large
antenna arrays at high frequencies, transitioning communication paradigm into
the radiative near-field (NF), where spherical wavefronts enable full-vector
estimation of both target location and velocity. However, location and motion
parameters become inherently coupled in this regime, making their joint
estimation computationally demanding. To overcome this, we propose a novel
approach that projects the received two-dimensional space-time signal onto the
angle-Doppler domain using a two-dimensional discrete Fourier transform
(2D-DFT). Our analysis reveals that the resulting angular spread is centered at
the target's true angle, with its width determined by the target's range.
Similarly, transverse motion induces a Doppler spread centered at the true
radial velocity, with the width of Doppler spread proportional to the
transverse velocity. Exploiting these spectral characteristics, we develop a
low-complexity algorithm that provides coarse estimates of angle, range, and
velocity, which are subsequently refined using one-dimensional multiple signal
classification (MUSIC) applied independently to each parameter. The proposed
method enables accurate and efficient estimation of NF target motion
parameters. Simulation results demonstrate a normalized mean squared error
(NMSE) of -40 dB for location and velocity estimates compared to maximum
likelihood estimation, while significantly reducing computational complexity.

</details>


### [263] [Passive Body-Area Electrostatic Field (Human Body Capacitance) for Ubiquitous Computing](https://arxiv.org/abs/2507.13520)
*Sizhen Bian,Mengxi Liu,Paul Lukowicz*

Main category: eess.SP

TL;DR: 该论文概述了无源人体身体电容（HBC）传感技术，包括其原理、发展、应用和挑战，并提供了开源资源以推动相关领域的研究。


<details>
  <summary>Details</summary>
Motivation: 旨在为无源HBC传感提供一个集中的概述，并激发缓解环境变化等挑战的技术，同时为下一代可穿戴和环境智能系统提供支持。

Method: 对无源HBC传感的原理、历史演变、硬件架构和应用进行了概述。

Result: 提供了无源HBC传感的全面概述，讨论了关键挑战，并指出了未来的研究方向和机遇。

Conclusion: 该论文总结了无源体域静电场传感（人类身体电容，HBC）的原理、发展、硬件架构和应用，并讨论了环境变化等挑战及传感器融合、硬件增强的未来机遇，最后提供了开源资源以促进相关研究和开发。

Abstract: Passive body-area electrostatic field sensing, also referred to as human body
capacitance (HBC), is an energy-efficient and non-intrusive sensing modality
that exploits the human body's inherent electrostatic properties to perceive
human behaviors. This paper presents a focused overview of passive HBC sensing,
including its underlying principles, historical evolution, hardware
architectures, and applications across research domains. Key challenges, such
as susceptibility to environmental variation, are discussed to trigger
mitigation techniques. Future research opportunities in sensor fusion and
hardware enhancement are highlighted. To support continued innovation, this
work provides open-source resources and aims to empower researchers and
developers to leverage passive electrostatic sensing for next-generation
wearable and ambient intelligence systems.

</details>


### [264] [Space Shift Keying-Enabled ISAC for Efficient Debris Detection and Communication in LEO Satellite Networks](https://arxiv.org/abs/2507.13526)
*Gedeon Ghislain Nkwewo Ngoufo,Khaled Humadi,Elham Baladi,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 本文提出使用SSK调制技术，并分别结合正弦和चirl波形在ISAC系统中进行了性能评估。SSK在通信方面表现良好，但चirl波形在感知能力方面优于正弦波形。


<details>
  <summary>Details</summary>
Motivation: 为了应对LEO轨道碎片带来的轨道安全挑战，ISAC系统被认为是集环境感知和数据通信于一体的解决方案。SSK因其硬件复杂度低和通信性能稳健而被选中用于ISAC。

Method: 本文研究了在ISAC框架下使用SSK调制，并评估了其与正弦和चirl雷达波形结合使用的性能。

Result: SSK可以实现良好的通信性能，并且通信性能不受通信波形的影响。在感知能力方面，चirl波形相比正弦波形具有更好的测距和测速能力。

Conclusion: SSK是一种适用于ISAC的调制方案，并且其性能不受通信波形的影响。然而，不同波形会影响ISAC系统的感知能力，其中正弦波形易于实现但测距能力有限，而चirl波形则可以实现测距并且在测速方面有少量提升。

Abstract: The proliferation of space debris in low Earth orbit (LEO) presents critical
challenges for orbital safety, particularly for satellite constellations.
Integrated sensing and communication (ISAC) systems provide a promising dual
function solution by enabling both environmental sensing and data
communication. This study explores the use of space shift keying (SSK)
modulation within ISAC frameworks, evaluating its performance when combined
with sinusoidal and chirp radar waveforms. SSK is particularly attractive due
to its low hardware complexity and robust communication performance. Our
results demonstrate that both waveforms achieve comparable bit error rate (BER)
performance under SSK, validating its effectiveness for ISAC applications.
However, waveform selection significantly affects sensing capability: while the
sinusoidal waveform supports simpler implementation, its high ambiguity limits
range detection. In contrast, the chirp waveform enables range estimation and
provides a modest improvement in velocity detection accuracy. These findings
highlight the strength of SSK as a modulation scheme for ISAC and emphasize the
importance of selecting appropriate waveforms to optimize sensing accuracy
without compromising communication performance. This insight supports the
design of efficient and scalable ISAC systems for space applications,
particularly in the context of orbital debris monitoring.

</details>


### [265] [Sensing and Stopping Interfering Secondary Users: Validation of an Efficient Spectrum Sharing System](https://arxiv.org/abs/2507.13554)
*Meles Weldegebriel,Zihan Li,Dustin Maas,Greg Hellbourg,Ning Zhang,Neal Patwari*

Main category: eess.SP

TL;DR: StopSec是一种创新的隐私保护协议，通过独特的水印技术，能够快速、准确地识别并停止对主要用户（PU）造成干扰的二次用户（SU），在实际测试中表现出色，即使在干扰信号微弱的情况下也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 提出一种能识别并快速停止干扰PU的二次用户（SU）的隐私保护协议。

Method: StopSec协议设计，引入了轻量级且鲁棒的SU OFDM数据包水印方法。

Result: StopSec能在150毫秒内停止干扰SU，能够同时停止多个干扰用户，即使在干扰比噪声功率低10dB的情况下也能在几秒钟内成功停止干扰。

Conclusion: StopSec可以作为一种有效的频谱共享协议，适用于必须快速自动停止对PU干扰的情况。

Abstract: We present the design and validation of Stoppable Secondary Use (StopSec), a
privacy-preserving protocol with the capability to identify a secondary user
(SU) causing interference to a primary user (PU) and to act quickly to stop the
interference. All users are served by a database that provides a feedback
mechanism from a PU to an interfering SU. We introduce a new lightweight and
robust method to watermark an SU's OFDM packet. Through extensive over-the-air
real-time experiments, we evaluate StopSec in terms of interference detection,
identification, and stopping latency, as well as impact on SUs. We show that
the watermarking method avoids negative impact to the secondary data link and
is robust to real-world time-varying channels. Interfering SUs can be stopped
in under 150 milliseconds, and when multiple users are simultaneously
interfering, they can all be stopped. Even when the interference is 10 dB lower
than the noise power, StopSec successfully stops interfering SUs within a few
seconds of their appearance in the channel. StopSec can be an effective
spectrum sharing protocol for cases when interference to a PU must be quickly
and automatically stopped.

</details>


### [266] [Towards channel foundation models (CFMs): Motivations, methodologies and opportunities](https://arxiv.org/abs/2507.13637)
*Jun Jiang,Yuan Gao,Xinyi Wu,Shugong Xu*

Main category: eess.SP

TL;DR: 提出信道基础模型（CFM），利用自监督学习处理无线通信中的信道相关任务。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统AI模型在无线通信领域依赖标签数据、泛化能力有限和任务特定设计的局限性。

Method: 提出了一种基于自监督学习的信道基础模型（CFM），该模型包含一个预训练的通用信道特征提取器，能够利用大规模无标签数据。

Result: CFM能够有效地利用大规模无标签数据，无需广泛的手动注释，并能处理广泛的信道相关任务。

Conclusion: CFM是未来无线通信中处理与信道相关任务的通用框架。

Abstract: Artificial intelligence (AI) has emerged as a pivotal enabler for
next-generation wireless communication systems. However, conventional AI-based
models encounter several limitations, such as heavy reliance on labeled data,
limited generalization capability, and task-specific design. To address these
challenges, this paper introduces, for the first time, the concept of channel
foundation models (CFMs)-a novel and unified framework designed to tackle a
wide range of channel-related tasks through a pretrained, universal channel
feature extractor. By leveraging advanced AI architectures and self-supervised
learning techniques, CFMs are capable of effectively exploiting large-scale
unlabeled data without the need for extensive manual annotation. We further
analyze the evolution of AI methodologies, from supervised learning and
multi-task learning to self-supervised learning, emphasizing the distinct
advantages of the latter in facilitating the development of CFMs. Additionally,
we provide a comprehensive review of existing studies on self-supervised
learning in this domain, categorizing them into generative, discriminative and
the combined paradigms. Given that the research on CFMs is still at an early
stage, we identify several promising future research directions, focusing on
model architecture innovation and the construction of high-quality, diverse
channel datasets.

</details>


### [267] [Elastic Buffer Design for Real-Time All-Digital Clock Recovery Enabling Free-Running Receiver Clock with Negative and Positive Clock Frequency Offsets](https://arxiv.org/abs/2507.13748)
*Patrick Matalla,Joel Dittmer,Md Salek Mahmud,Christian Koos,Sebastian Randel*

Main category: eess.SP

TL;DR: An elastic buffer design enables all-digital clock recovery for free-running clocks with frequency offsets up to +/-400 ppm, achieving error-free data transmission.


<details>
  <summary>Details</summary>
Motivation: To enable all-digital clock recovery implementation with free-running receiver clocks that can handle clock frequency offsets.

Method: Elastic buffer design for all-digital clock recovery.

Result: Error-free real-time data transmission demonstrated from -400 ppm to +400 ppm.

Conclusion: The elastic buffer design allows for all-digital clock recovery with free-running receiver clocks, handling both negative and positive clock frequency offsets.

Abstract: We present an elastic buffer design that enables all-digital clock recovery
implementation with free-running receiver clock featuring negative and positive
clock frequency offsets. Error-free real-time data transmission is demonstrated
from -400 ppm to +400 ppm.

</details>


### [268] [ISAC: From Human to Environmental Sensing](https://arxiv.org/abs/2507.13766)
*Kai Wu,Zhongqin Wang,Shu-Lin Chen,J. Andrew Zhang,Y. Jay Guo*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Integrated Sensing and Communications (ISAC) is poised to become one of the
defining capabilities of the sixth generation (6G) wireless communications
systems, enabling the network infrastructure to jointly support high-throughput
communications and situational awareness. While recent advances have explored
ISAC for both human-centric applications and environmental monitoring, existing
research remains fragmented across these domains. This paper provides the first
unified review of ISAC-enabled sensing for both human activities and
environment, focusing on signal-level mechanisms, sensing features, and
real-world feasibility. We begin by characterising how diverse physical
phenomena, ranging from human vital sign and motion to precipitation and flood
dynamics, impact wireless signal propagation, producing measurable signatures
in channel state information (CSI), Doppler profiles, and signal statistics. A
comprehensive analysis is then presented across two domains: human sensing
applications including localisation, activity recognition, and vital sign
monitoring; and environmental sensing for rainfall, soil moisture, and water
level. Experimental results from Long-Term Evolution (LTE) sensing under
non-line-of-sight (NLOS) conditions are incorporated to highlight the
feasibility in infrastructure-limited scenarios. Open challenges in signal
fusion, domain adaptation, and generalisable sensing architectures are
discussed to facilitate future research toward scalable and autonomous ISAC.

</details>


### [269] [Simulation for Noncontact Radar-Based Physiological Sensing Using Depth-Camera-Derived Human 3D Model with Electromagnetic Scattering Analysis](https://arxiv.org/abs/2507.13826)
*Kimitaka Sumi,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 本研究提出了一种更准确的雷达呼吸监测信号模拟方法，通过使用真实身体数据提高了精度。


<details>
  <summary>Details</summary>
Motivation: 与以往研究相比，该方法采用了更现实的身体几何和位移模型，以提高模拟精度。

Method: 提出了一种基于真实测量的身体形状和运动数据来模拟呼吸监测过程中调频连续波雷达接收到的信号的方法。

Result: 与传统基于模型的方法相比，该技术在雷达图像、位移和光谱图的相关系数方面分别提高了 7.5%、58.2% 和 3.2%。

Conclusion: 该研究提出了一种通过模拟来生成雷达生理数据集的方法，并通过考虑身体形状和运动等因素来提高非接触传感的准确性。

Abstract: This study proposes a method for simulating signals received by
frequency-modulated continuous-wave radar during respiratory monitoring, using
human body geometry and displacement data acquired via a depth camera. Unlike
previous studies that rely on simplified models of body geometry or
displacement, the proposed approach models high-frequency scattering centers
based on realistic depth-camera-measured body shapes and motions. Experiments
were conducted with six participants under varying conditions, including
varying target distances, seating orientations, and radar types, with
simultaneous acquisition from the radar and depth camera. Relative to
conventional model-based methods, the proposed technique achieved improvements
of 7.5%, 58.2%, and 3.2% in the correlation coefficients of radar images,
displacements, and spectrograms, respectively. This work contributes to the
generation of radar-based physiological datasets through simulation and
enhances our understanding of factors affecting the accuracy of non-contact
sensing.

</details>


### [270] [On two fundamental properties of the zeros of spectrograms of noisy signals](https://arxiv.org/abs/2507.13829)
*Arnaud Poinas,Rémi Bardenet*

Main category: eess.SP

TL;DR: 谱图零点可以揭示信号信息，数学原理可以解释这些现象。


<details>
  <summary>Details</summary>
Motivation: 探究谱图零点在信号存在时，其空间分布变化背后的数学原理，特别是信号边界描绘和零点被捕获的现象。

Method: 通过详细的计算和两个基本的数学论证（零点的强度和 Rouché 定理）来分析信号添加到白高斯噪声中时，谱图零点的空间分布的变化。

Result: 证明了即使是干扰的चिरप信号，只要参数合适，也能在谱图零点中形成易于检测的确定性结构。

Conclusion: 零点和 Rouché 定理可以用来解释信号在噪声背景下的谱图零点分布的变化，包括信号的边界和干扰的存在。

Abstract: The spatial distribution of the zeros of the spectrogram is significantly
altered when a signal is added to white Gaussian noise. The zeros tend to
delineate the support of the signal, and deterministic structures form in the
presence of interference, as if the zeros were trapped. While sophisticated
methods have been proposed to detect signals as holes in the pattern of
spectrogram zeros, few formal arguments have been made to support the
delineation and trapping effects. Through detailed computations for simple toy
signals, we show that two basic mathematical arguments, the intensity of zeros
and Rouch\'e's theorem, allow discussing delineation and trapping, and the
influence of parameters like the signal-to-noise ratio. In particular,
interfering chirps, even nearly superimposed, yield an easy-to-detect
deterministic structure among zeros.

</details>


### [271] [Device-Free Localization Using Commercial UWB Transceivers](https://arxiv.org/abs/2507.13938)
*Hyun Seok Lee*

Main category: eess.SP

TL;DR: 本研究提出了一种深度学习辅助粒子滤波器，用于在具有挑战性的现实世界场景中，通过UWB信号对非UWB设备进行定位。该方法通过分析CIR方差并利用注意力U-Net提取目标相关信息来抑制噪声和杂波，从而实现高精度（约15厘米RMSE）和低延迟（4毫秒）的定位，适用于物联网和汽车应用。


<details>
  <summary>Details</summary>
Motivation: 尽管超宽带（UWB）收发器已实现设备无关定位，但在现实世界场景中，由于信噪比（SNR）低和环境混乱，准确估计目标位置仍然很困难。

Method: 提出了一种深度学习（DL）辅助的粒子滤波器。首先，分析了信道脉冲响应（CIR）方差以捕捉由目标运动引起的变异性。然后，使用基于DL的一维注意力U-Net来提取由目标引起的反射分量并抑制CIR方差剖面内的噪声分量。最后，将多个预处理的CIR方差剖面作为粒子滤波器的输入来估计目标位置。

Result: 所提出的系统在现实世界场景中实现了约15厘米的均方根误差（RMSE）和4毫秒的平均处理时间，并且在性能上优于现有的最先进方法。

Conclusion: 实验结果表明，所提出的系统是物联网和汽车应用的实用且经济高效的解决方案，均方根误差（RMSE）约为15厘米，平均处理时间为4毫秒。此外，与现有的最先进方法相比，所提出的方法在合理的计算成本下提供了最佳性能。

Abstract: Recently, commercial ultra-wideband (UWB) transceivers have enabled not only
measuring device-to-device distance but also tracking the position of a
pedestrian who does not carry a UWB device. UWB-based device-free localization
that does not require dedicated radar equipment is compatible with existing
anchor infrastructure and can be reused to reduce hardware deployment costs.
However, it is difficult to estimate the target's position accurately in
real-world scenarios due to the low signal-to-noise ratio (SNR) and the
cluttered environment. In this paper, we propose a deep learning (DL)-assisted
particle filter to overcome these challenges. First, the channel impulse
response (CIR) variance is analyzed to capture the variability induced by the
target's movement. Then, a DL-based one-dimensional attention U-Net is used to
extract only the reflection components caused by the target and suppress the
noise components within the CIR variance profile. Finally, multiple
preprocessed CIR variance profiles are used as input to a particle filter to
estimate the target's position. Experimental results demonstrate that the
proposed system is a practical and cost-effective solution for IoT and
automotive applications with a root mean square error (RMSE) of about 15 cm and
an average processing time of 4 ms. Furthermore, comparisons with existing
state-of-the-art methods show that the proposed method provides the best
performance with reasonable computational costs.

</details>


### [272] [Distortion-Aware Hybrid Beamforming for Integrated Sensing and Communication](https://arxiv.org/abs/2507.14018)
*Zeyuan Zhang,Yue Xiu,Phee Lep Yeoh,Guangyi Liu,Zixing Wu,Ning Wei*

Main category: eess.SP

TL;DR: 本文提出了一种针对具有非线性功率放大器失真的 ISAC 系统的部分连接混合波束成形设计，通过交替优化和分解算法求解，并在数值上证明了其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决通信速率和感知互信息的最大化问题，该文针对集成传感与通信（ISAC）提出了一个实用的部分连接混合波束成形发射器，并考虑了来自非线性功率放大器的失真。

Method: 该方法首先通过使用流形优化（MO）和我们导出的闭式解来求解三个子问题，然后通过分解算法获得模拟和数字波束成形矩阵。

Result: 数值结果表明，与传统波束成形方法相比，所提出的算法可以改善整体 ISAC 性能。

Conclusion: 所提出的算法可以改进与传统波束成形方法相比的整体 ISAC 性能。

Abstract: This paper investigates a practical partially-connected hybrid beamforming
transmitter for integrated sensing and communication (ISAC) with distortion
from nonlinear power amplification. For this ISAC system, we formulate a
communication rate and sensing mutual information maximization problem driven
by our distortion-aware hybrid beamforming design. To address this non-convex
problem, we first solve for a fully digital beamforming matrix by alternatively
solving three sub-problems using manifold optimization (MO) and our derived
closed-form solutions. The analog and digital beamforming matrices are then
obtained through a decomposition algorithm. Numerical results demonstrate that
the proposed algorithm can improve overall ISAC performance compared to
traditional beamforming methods.

</details>


### [273] [Toward Practical Fluid Antenna Systems: Co-Optimizing Hardware and Software for Port Selection and Beamforming](https://arxiv.org/abs/2507.14035)
*Sai Xu,Kai-Kit Wong,Yanan Du,Hanjiang Hong,Chan-Byoung Chae,Baiyang Liu,Kin-Fai Tong*

Main category: eess.SP

TL;DR: 本文提出了一种软硬件协同设计方法，利用图神经网络（GNN）和随机端口选择（RPS）优化流体天线系统（FAS）中的波束形成和端口选择，并使用FPGA加速器实现低延迟推理。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一种软硬件协同设计方法，以有效地优化流体天线系统（FAS）中的波束形成和端口选择。

Method: 提出了一种将图神经网络（GNN）与随机端口选择（RPS）相结合的方法，以联合优化波束形成和端口选择，同时评估随机选择的优点和局限性。此外，开发了一种基于现场可编程门阵列（FPGA）的指令驱动深度学习加速器，以最小化推理延迟。为进一步提高效率，还引入了一种调度算法，以减少冗余计算并最小化计算核心的空闲时间。

Result: 提出的GNN-RPS方法实现了可观的通信性能，并且基于FPGA的加速器在同时执行多个端口选择的波束形成推理时，保持了低延迟。

Conclusion: 仿真结果表明，所提出的GNN-RPS方法实现了可观的通信性能。此外，实验评估表明，基于FPGA的加速器在同时执行多个端口选择的波束形成推理时，保持了低延迟。

Abstract: This paper proposes a hardware-software co-design approach to efficiently
optimize beamforming and port selection in fluid antenna systems (FASs). To
begin with, a fluid-antenna (FA)-enabled downlink multi-cell multiple-input
multiple-output (MIMO) network is modeled, and a weighted sum-rate (WSR)
maximization problem is formulated. Second, a method that integrates graph
neural networks (GNNs) with random port selection (RPS) is proposed to jointly
optimize beamforming and port selection, while also assessing the benefits and
limitations of random selection. Third, an instruction-driven deep learning
accelerator based on a field-programmable gate array (FPGA) is developed to
minimize inference latency. To further enhance efficiency, a scheduling
algorithm is introduced to reduce redundant computations and minimize the idle
time of computing cores. Simulation results demonstrate that the proposed
GNN-RPS approach achieves competitive communication performance. Furthermore,
experimental evaluations indicate that the FPGA-based accelerator maintains low
latency while simultaneously executing beamforming inference for multiple port
selections.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [274] [Heatwave-driven air conditioning adoption could increase German electricity demand by 14 GW in the near future](https://arxiv.org/abs/2507.13534)
*Leo Semmelmann,Frederik vom Scheidt*

Main category: eess.SY

TL;DR: 由于热浪频发，空调使用量激增，可能在下午增加23%的电力需求，并加剧电网稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 鉴于气候变化导致的热浪加剧，移动空调（AC）系统的采用正在加速。这种快速的大规模采用可能会给电力系统带来额外的压力。

Method: 本研究提出了一种新颖的估算AC系统电力需求的方法，能够达到系统级以及高时间/空间分辨率的特点。该方法结合了天气数据、人口普查数据、社会人口统计学假设、出行模式以及依赖于温度的AC激活函数。研究人员将该方法应用于德国一个近期的热浪情景，分析了196,428个一平方公里网格区域的电力需求。

Result: 在德国，当家庭AC普及率从19%增加到35%时，新购买的移动AC系统的电力需求可能使峰值负荷增加超过14吉瓦（23%），城市热点地区的峰值负荷可能达到每平方公里5.8兆瓦。其时间模式产生明显的下午峰值，这恰逢光伏发电量较低的时段，可能加剧电力系统稳定性挑战。

Conclusion: 气候变化导致的热浪加剧了移动空调（AC）系统的采用，快速的大规模采用可能给电网和电力系统带来额外压力。本研究提出了一种新颖的方法来估算AC系统的电力需求，该方法具有系统级以及高时间/空间分辨率的特点。将该方法应用于德国一个近期的热浪情景，其中家庭AC普及率从目前的19%增加到35%。我们结合天气数据、人口普查数据、社会人口统计学假设、出行模式和依赖于温度的AC激活函数，分析了德国196,428个一平方公里网格区域的影响。我们发现新购买的移动AC系统的电力需求可能使峰值负荷增加超过14吉瓦（23%），城市热点地区的峰值负荷可能达到每平方公里5.8兆瓦。其时间模式产生明显的下午峰值，这恰逢光伏发电量较低的时段，可能加剧电力系统稳定性挑战。我们的研究结果强调了主动进行能源系统规划以应对新出现的用电高峰的紧迫性。

Abstract: Intensifying heatwaves driven by climate change are accelerating the adoption
of mobile air conditioning (AC) systems. A rapid mass adoption of such AC
systems could create additional stress on electricity grids and the power
system. This study presents a novel method to estimate the electricity demand
from AC systems both at system level and at high temporal and spatial
granularity. We apply the method to a near-future heatwave scenario in Germany
in which household AC adoption increases from current 19% to 35% during a
heatwave similar to the one of July 2025. We analyze the effects for 196,428
grid cells of one square kilometer across Germany, by combining weather data,
census data, socio-demographic assumptions, mobility patterns, and
temperature-dependent AC activation functions. We find that electricity demand
of newly purchased mobile AC systems could increase the peak load by over 14 GW
(23%), with urban hot-spots reaching 5.8 MW per square kilometer. The temporal
pattern creates a pronounced afternoon peak that coincides with lower
photovoltaic generation, potentially exacerbating power system stability
challenges. Our findings underscore the urgency for proactive energy system
planning to manage emerging demand peaks.

</details>


### [275] [MD-OFDM: An Energy-Efficient and Low-PAPR MIMO-OFDM Variant for Resource-Constrained Applications](https://arxiv.org/abs/2507.13623)
*Rahul Gulia*

Main category: eess.SY

TL;DR: MD-OFDM 通过选择性激活天线来降低 MIMO-OFDM 的 PAPR 和功耗，适用于物联网等场景，性能优于传统方法但能效略有折衷。


<details>
  <summary>Details</summary>
Motivation: 解决传统 MIMO-OFDM 系统（尤其是使用 MMSE 等复杂均衡器时）面临的高 PAPR 和显著的功耗问题（由于需要多个有源射频链路）。

Method: 提出并对 MD-OFDM 系统进行数学建模，该系统采用每子载波发射天线选择策略。

Result: MD-OFDM 在 BER 和 PAPR 方面优于 MMSE MIMO，但由于频谱复用性降低，在峰值整体能效方面有所权衡。

Conclusion: MD-OFDM 通过在每个子载波上仅激活一个发射天线，有望降低 PAPR、减少功耗并提高 BER 性能，尤其适用于物联网和 LPWAN 等能源受限和成本敏感的场景。

Abstract: Orthogonal Frequency Division Multiplexing (OFDM) combined with
Multiple-Input Multiple-Output (MIMO) techniques forms the backbone of modern
wireless communication systems. While offering high spectral efficiency and
robustness, conventional MIMO-OFDM, especially with complex equalizers like
Minimum Mean Square Error (MMSE), suffers from high Peak-to-Average Power Ratio
(PAPR) and significant power consumption due to multiple active Radio Frequency
(RF) chains. This paper proposes and mathematically models an alternative
system, termed Multi-Dimensional OFDM (MD-OFDM), which employs a per-subcarrier
transmit antenna selection strategy. By activating only one transmit antenna
for each subcarrier, MD-OFDM aims to reduce PAPR, lower power consumption, and
improve Bit Error Rate (BER) performance. We provide detailed mathematical
formulations for BER, Energy Efficiency (EE), and PAPR, and discuss the
suitability of MD-OFDM for various applications, particularly in
energy-constrained and cost-sensitive scenarios such as the Internet of Things
(IoT) and Low-Power Wide Area Networks (LPWAN). Simulation results demonstrate
that MD-OFDM achieves superior BER and significantly lower PAPR compared to
MMSE MIMO, albeit with a trade-off in peak overall energy efficiency due to
reduced spectral multiplexing.

</details>


### [276] [Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations](https://arxiv.org/abs/2507.13672)
*Hang Zhou,Tao Meng,Kun Wang,Chengrui Shi,Renhao Mao,Weijia Wang,Jiakun Lei*

Main category: eess.SY

TL;DR: 本研究提出了一种新颖的安全鲁棒控制框架，用于航天器近距离操作中的碰撞避免，特别是在面对复杂目标和干扰时。该框架利用学习到的神经SDF来隐式表示目标几何，并通过两层控制策略（安全速度生成和安全鲁棒控制）确保操作安全，实验结果表明其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 确保航天器近距离操作（特别是复杂几何目标航天器）在干扰下的碰撞避免安全。

Method: 提出了一种利用隐式神经表示的安全鲁棒控制框架。该框架通过增强的隐式几何正则化方法从点云数据中学习神经符号距离函数（SDF），并采用过逼近策略创建保守的安全边界。在此基础上，构建了一个两层分层控制框架：一个安全速度生成层（利用二阶锥规划和循环不等式）和一个安全鲁棒控制器层（集成了干扰观测器和光滑安全滤波器）。

Result: 通过广泛的数值模拟和蒙特卡洛分析验证，所提出的框架显著提高了安全裕度，并有效避免了传统CBF方法中常见的局部极小值问题。

Conclusion: 该研究提出的框架通过结合神经SDF和两层分层安全鲁棒控制，在航天器近距离操作中实现了更高的安全裕度和对局部极小值的规避，优于传统CBF方法。

Abstract: This study addresses the challenge of ensuring safe spacecraft proximity
operations, focusing on collision avoidance between a chaser spacecraft and a
complex-geometry target spacecraft under disturbances. To ensure safety in such
scenarios, a safe robust control framework is proposed that leverages implicit
neural representations. To handle arbitrary target geometries without explicit
modeling, a neural signed distance function (SDF) is learned from point cloud
data via a enhanced implicit geometric regularization method, which
incorporates an over-apporximation strategy to create a conservative,
safety-prioritized boundary. The target's surface is implicitly defined by the
zero-level set of the learned neural SDF, while the values and gradients
provide critical information for safety controller design. This neural SDF
representation underpins a two-layer hierarchcial safe robust control
framework: a safe velocity generation layer and a safe robust controller layer.
In the first layer, a second-order cone program is formulated to generate
safety-guaranteed reference velocity by explicitly incorporating the
under-approximation error bound. Furthermore, a circulation inequality is
introduced to mitigate the local minimum issues commonly encountered in control
barrier function (CBF) methods. The second layer features an integrated
disturbance observer and a smooth safety filter explicitly compensating for
estimation error, bolstering robustness to external disturbances. Extensive
numerical simulations and Monte Carlo analysis validate the proposed framework,
demonstrating significantly improved safety margins and avoidance of local
minima compared to conventional CBF approaches.

</details>


### [277] [Minimum Clustering of Matrices Based on Phase Alignment](https://arxiv.org/abs/2507.13678)
*Honghao Wu,Kemi Ding,Li Qiu*

Main category: eess.SY

TL;DR: 该研究提出了一种新颖的框架，通过对多智能体系统中的智能体进行分类和聚类，以最小化所需的控制器类型数量，从而在性能和成本之间取得平衡。该方法通过利用相位对齐和分层优化技术，有效解决了传统方法在可扩展性和鲁棒性方面的不足，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 协调多智能体系统需要在同步性能和控制器实现成本之间取得平衡。现有的集中式控制方法虽然在控制器类型较少的情况下能实现高同步性能，但存在可扩展性有限和单点故障等严重缺点。而分布式控制策略的控制器通常依赖于智能体，所需控制器类型随着系统规模的增大而增加。

Method: 提出了一种新颖的基于相位对齐的框架，通过对具有相似同步行为的智能体进行聚类来最小化控制器类型。利用复杂矩阵的内在相位特性，设计了约束聚类问题，并提出了一种结合递归精确搜索和小规模系统分层优化方法的组合，以及针对大规模网络的分布式优化方法。

Result: 通过对一个包含50个智能体的网络的理论分析和应用，证明了所提出算法的有效性。

Conclusion: 该工作通过将具有相似同步行为的智能体进行聚类，提出了最小化控制器类型数量的框架，为大规模多智能体系统提供了一种经济高效的解决方案。

Abstract: Coordinating multi-agent systems requires balancing synchronization
performance and controller implementation costs. To this end, we classify
agents by their intrinsic properties, enabling each group to be controlled by a
uniform controller and thus reducing the number of unique controller types
required. Existing centralized control methods, despite their capability to
achieve high synchronization performance with fewer types of controllers,
suffer from critical drawbacks such as limited scalability and vulnerability to
single points of failure. On the other hand, distributed control strategies,
where controllers are typically agent-dependent, result in the type of required
controllers increasing proportionally with the size of the system.
  This paper introduces a novel phase-alignment-based framework to minimize the
type of controllers by strategically clustering agents with aligned
synchronization behaviors. Leveraging the intrinsic phase properties of complex
matrices, we formulate a constrained clustering problem and propose a
hierarchical optimization method combining recursive exact searches for
small-scale systems and scalable stochastic approximations for large-scale
networks. This work bridges theoretical phase analysis with practical control
synthesis, offering a cost-effective solution for large-scale multi-agent
systems. The theoretical results applied for the analysis of a 50-agent network
illustrate the effectiveness of the proposed algorithms.

</details>


### [278] [Robust Probability Hypothesis Density Filtering: Theory and Algorithms](https://arxiv.org/abs/2507.13687)
*Ming Lei,Shufan Wu*

Main category: eess.SY

TL;DR: 提出了一种创新的minimax鲁棒PHD滤波框架，通过鲁棒算法、自适应参数调整、重尾似然函数和基于分区的加权方法，在多目标跟踪中显著提高了鲁棒性和效率，实验结果证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决多目标跟踪（MTT）在处理模型不确定性、杂波干扰和目标交互时的鲁棒性和效率挑战，克服传统方法（如GM-PHD和CPHD）的局限性。

Method: 提出了一种理论上推导的鲁棒GM-PHD递归算法，采用自适应实时参数调整机制，并引入了广义重尾测量似然函数和基于分区的可信度加权方法。

Result: 在杂波环境中，该方法实现了32.4%的OSPA误差降低和25.3%的基数RMSE降低，同时保持了每步15.3毫秒的实时处理能力。

Conclusion: 该研究提出的新颖的minimax鲁棒PHD滤波框架，为安全关键应用中的可靠多目标跟踪奠定了关键基础。

Abstract: Multi-target tracking (MTT) serves as a cornerstone technology in information
fusion, yet faces significant challenges in robustness and efficiency when
dealing with model uncertainties, clutter interference, and target
interactions. Conventional approaches like Gaussian Mixture PHD (GM-PHD) and
Cardinalized PHD (CPHD) filters suffer from inherent limitations including
combinatorial explosion, sensitivity to birth/death process parameters, and
numerical instability. This study proposes an innovative minimax robust PHD
filtering framework with four key contributions: (1) A theoretically derived
robust GM-PHD recursion algorithm that achieves optimal worst-case error
control under bounded uncertainties; (2) An adaptive real-time parameter
adjustment mechanism ensuring stability and error bounds; (3) A generalized
heavy-tailed measurement likelihood function maintaining polynomial
computational complexity; (4) A novel partition-based credibility weighting
method for extended targets. The research not only establishes rigorous
convergence guarantees and proves the uniqueness of PHD solutions, but also
verifies algorithmic equivalence with standard GM-PHD. Experimental results
demonstrate that in high-clutter environments, this method achieves a
remarkable 32.4% reduction in OSPA error and 25.3% lower cardinality RMSE
compared to existing techniques, while maintaining real-time processing
capability at 15.3 milliseconds per step. This breakthrough lays a crucial
foundation for reliable MTT in safety-critical applications.

</details>


### [279] [Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions](https://arxiv.org/abs/2507.13872)
*Aditya Singh,Aastha Mishra,Manan Tayal,Shishir Kolathaya,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 一种结合梯度下降MPC和CBF安全滤波的新框架，用于在保持高性能的同时确保安全性。


<details>
  <summary>Details</summary>
Motivation: 为了确保在真实环境中运行的自主系统的性能和安全，但现有的方法，如安全滤波器（CBF）在名义策略缺乏安全意识时可能过于保守，而通过动态规划解决有状态约束最优控制问题（SC-OCP）在高维系统中难以处理。

Method: 提出了一种新颖的两阶段框架，首先在成本函数中放宽安全约束作为惩罚，以便通过基于梯度的方法进行快速优化，然后在第二阶段使用基于CBF的二次规划（CBF-QP）来强制执行硬安全约束，并尽量减少对参考的偏差。

Result: 该方法能够合成可扩展、安全且高性能的控制器。

Conclusion: 该方法结合了基于梯度的模型预测控制（MPC）和基于CBF的安全滤波，以协同优化安全性和性能，并已在两个案例研究中得到验证，证明了其为复杂、高维自动驾驶系统合成可扩展、安全且高性能控制器的能力。

Abstract: Ensuring both performance and safety is critical for autonomous systems
operating in real-world environments. While safety filters such as Control
Barrier Functions (CBFs) enforce constraints by modifying nominal controllers
in real time, they can become overly conservative when the nominal policy lacks
safety awareness. Conversely, solving State-Constrained Optimal Control
Problems (SC-OCPs) via dynamic programming offers formal guarantees but is
intractable in high-dimensional systems. In this work, we propose a novel
two-stage framework that combines gradient-based Model Predictive Control (MPC)
with CBF-based safety filtering for co-optimizing safety and performance. In
the first stage, we relax safety constraints as penalties in the cost function,
enabling fast optimization via gradient-based methods. This step improves
scalability and avoids feasibility issues associated with hard constraints. In
the second stage, we modify the resulting controller using a CBF-based
Quadratic Program (CBF-QP), which enforces hard safety constraints with minimal
deviation from the reference. Our approach yields controllers that are both
performant and provably safe. We validate the proposed framework on two case
studies, showcasing its ability to synthesize scalable, safe, and
high-performance controllers for complex, high-dimensional autonomous systems.

</details>


### [280] [Fixed time convergence guarantees for Higher Order Control Barrier Functions](https://arxiv.org/abs/2507.13888)
*Janani S K,Shishir Kolathaya*

Main category: eess.SY

TL;DR: 本文提出了一种新的高阶控制屏障函数（CBFs）设计方法，通过使用特征多项式中的重根来实现固定时间收敛，解决了传统方法在时间敏感应用中的不足。实验证明该方法在机器人系统上表现优于传统方法，提供了可行的、具有可证明的有限时间安全保证的实时控制框架。


<details>
  <summary>Details</summary>
Motivation: 传统高阶CBFs仅能确保渐近安全，但缺乏固定时间收敛机制，这对于自动导航等时间敏感和安全关键应用至关重要。

Method: 通过在特征多项式中使用重根来施加结构化微分约束，推导出确保前向不变性和固定时间可达性的屏障函数及其导数的条件，并为二阶系统提供显式公式。

Result: 在点质量模型、单轮车和自行车模型这三个机器人系统上进行的评估和基准测试结果表明，该方法能够可靠地在期望的时间内强制执行收敛，即使在传统方法失败的情况下也是如此。

Conclusion: 本研究提出了一种用于设计高阶控制屏障函数（CBFs）的新方法，该方法可在用户指定的有限时间内保证收敛到安全集。与仅能确保渐近安全但缺乏固定时间收敛机制的传统高阶CBFs不同，我们的方法通过在特征多项式中使用重根来施加结构化微分约束，从而能够获得具有在规定时间内精确收敛的闭式多项式解。我们推导了确保前向不变性和固定时间可达性的屏障函数及其导数的条件，并为二阶系统提供了显式公式。该方法在点质量模型、单轮车和自行车模型这三个机器人系统上进行了评估，并与现有的高阶CBFs方法进行了基准测试。结果表明，即使在传统方法失败的情况下，我们的方法也能在期望的时间内可靠地强制执行收敛。这项工作为具有可证明的实时安全保证的实时控制提供了一个可行的、鲁棒的框架。

Abstract: We present a novel method for designing higher-order Control Barrier
Functions (CBFs) that guarantee convergence to a safe set within a
user-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic
safety but lack mechanisms for fixed-time convergence, which is critical in
time-sensitive and safety-critical applications such as autonomous navigation.
In contrast, our approach imposes a structured differential constraint using
repeated roots in the characteristic polynomial, enabling closed-form
polynomial solutions with exact convergence at a prescribed time. We derive
conditions on the barrier function and its derivatives that ensure forward
invariance and fixed-time reachability, and we provide an explicit formulation
for second-order systems. Our method is evaluated on three robotic systems - a
point-mass model, a unicycle, and a bicycle model and benchmarked against
existing HOCBF approaches. Results demonstrate that our formulation reliably
enforces convergence within the desired time, even when traditional methods
fail. This work provides a tractable and robust framework for real-time control
with provable finite-time safety guarantees.

</details>


### [281] [A Robust Periodic Controller for Spacecraft Attitude Tracking](https://arxiv.org/abs/2507.13908)
*Frederik Thiele,Felix Biertümpfel,Harald Pfifer*

Main category: eess.SY

TL;DR: 本研究提出了一种新的卫星周期姿态控制方法，考虑了卫星动力学的周期性，实现了恒定的性能和鲁棒性。该方法采用混合灵敏度设计和结构化线性时变输出反馈综合，并通过凸优化解决。在太阳能电站卫星上的仿真结果证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了实现卫星在整个轨道上的恒定性能和鲁棒性要求，在控制综合中必须考虑卫星动力学的周期性。

Method: 该研究采用了一种混合灵敏度控制设计，并结合了物理启发的加权方案。控制器是利用一种新颖的结构化线性时变输出反馈综合方法计算得出的，该方法保证了最优的L2性能，并将综合问题转化为一个凸优化问题，从而避免了传统周期H无穷综合中固有的网格化评估耦合条件。

Result: 该方法通过一个太阳能电站卫星的仿真得到了验证，证明了其在周期卫星姿态控制方面的有效性。

Conclusion: 该研究提出了一种新颖的卫星周期姿态控制方法，该方法通过在控制综合中考虑卫星动力学的周期性，实现了整个轨道上的恒定性能和鲁棒性要求。

Abstract: This paper presents a novel approach for robust periodic attitude control of
satellites. Respecting the periodicity of the satellite dynamics in the
synthesis allows to achieve constant performance and robustness requirements
over the orbit. The proposed design follows a mixed sensitivity control design
employing a physically motivated weighting scheme. The controller is calculated
using a novel structured linear time-periodic output feedback synthesis with
guaranteed optimal L2-performance. The synthesis poses a convex optimization
problem and avoids grid-wise evaluations of coupling conditions inherent for
classical periodic H-infinity-synthesis. Moreover, the controller has a
transparent and easy to implement structure. A solar power plant satellite is
used to demonstrate the effectiveness of the proposed method for periodic
satellite attitude control.

</details>


### [282] [Identifiability Analysis of a Pseudo-Two-Dimensional Model & Single Particle Model-Aided Parameter Estimation](https://arxiv.org/abs/2507.13931)
*L. D. Couto,K. Haghverdi,F. Guo,K. Trad,G. Mulder*

Main category: eess.SY

TL;DR: 一种用于P2D电池模型的参数识别方法，可加快参数估计速度，同时尽量减少精度损失。


<details>
  <summary>Details</summary>
Motivation: 为了在伪二维（P2D）电池模型中准确快速地估计模型参数。

Method: 该方法包括三个关键要素：1. 检查识别数据并包含模型中需要捕获的特定特征。2. 分析P2D模型以评估物理模型参数的可识别性并提出替代参数化以缓解潜在问题。3. 考虑不同的操作条件以激发不同的电池动力学，从而允许使用不同的低阶电池模型。

Result: 在低电流条件下，使用低阶模型估计参数的速度比使用P2D模型快至少500倍，但误差是其两倍。如果精度是必须的，这些估计的参数可用于初始化P2D模型，并将识别时间缩短一半。

Conclusion: 该研究提出了一种参数识别方法，用于在伪二维（P2D）电池模型中准确快速地估计模型参数。该方法包括三个关键要素：检查识别数据并包含模型中需要捕获的特定特征；分析P2D模型以评估物理模型参数的可识别性并提出替代参数化以缓解潜在问题；考虑不同的操作条件以激发不同的电池动力学，从而允许使用不同的低阶电池模型。结果表明，在低电流条件下，使用低阶模型估计参数的速度比使用P2D模型快至少500倍，但误差是其两倍。然而，如果精度是必须的，这些估计的参数可用于初始化P2D模型，并将识别时间缩短一半。

Abstract: This contribution presents a parameter identification methodology for the
accurate and fast estimation of model parameters in a pseudo-two-dimensional
(P2D) battery model. The methodology consists of three key elements. First, the
data for identification is inspected and specific features herein that need to
be captured are included in the model. Second, the P2D model is analyzed to
assess the identifiability of the physical model parameters and propose
alternative parameterizations that alleviate possible issues. Finally, diverse
operating conditions are considered that excite distinct battery dynamics which
allows the use of different low-order battery models accordingly. Results show
that, under low current conditions, the use of low-order models achieve
parameter estimates at least 500 times faster than using the P2D model at the
expense of twice the error. However, if accuracy is a must, these estimated
parameters can be used to initialize the P2D model and perform the
identification in half of the time.

</details>


### [283] [Diffraction and Scattering Modeling for Laser Power Beaming in Lunar Environment](https://arxiv.org/abs/2507.13982)
*Yanni Jiwan-Mercier,Barış Dönmez,Güneş Karabulut-Kurt,Sébastien Loranger*

Main category: eess.SY

TL;DR: 月球尘埃严重影响光学功率传输效率，提高激光源高度可改善传输效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决月球极地陨石坑等太阳光照射有限区域的长期月球任务中对可靠能源输送的需求，以及现有方法对月球尘埃影响理解的不足，本研究旨在通过仿真模型评估月球尘埃对光学功率传输（OPB）的影响。

Method: 该研究引入了一个详细的仿真模型，该模型结合了衍射和静电悬浮的月球表层土的高度相关的散射效应。与之前假设均匀尘埃层或中心对中心传输损耗的方法不同，该模型采用了广义衍射理论和源于粒子密度的折射率梯度来评估光束畸变和衰减。

Result: 仿真结果显示，即使在地面到地面的场景中，月球尘埃也会显著降低能量传输效率。在无尘条件下，50公里传输效率为57%，而在存在175 nm尘埃的条件下，效率降至3.7%。将粒子尺寸增加到250 nm，在6%的效率下，可行的传输距离限制在30公里以内。此外，研究表明提高激光源高度可以改善效率，当源高为12米时，5公里传输效率可达91%，50公里传输效率为25%。

Conclusion: 可靠的能源输送对于长期月球任务至关重要，尤其是在太阳能有限的地区。该研究提出的光学功率传输（OPB）模型考虑了衍射和高度相关的散射效应，表明月球尘埃（尤其是175 nm和250 nm的尘埃）会显著降低能量传输效率。提高激光源高度可以改善效率，在5公里处达到91%，在50公里处达到25%（当激光源高度为12米时）。这些结果强调了在月球OPB设计中考虑系统高度和尘埃模型的重要性，特别是要关注尘埃粒径分布对任务的关键影响。

Abstract: Reliable energy delivery is a critical requirement for
  long-term lunar missions, particularly in regions with limited
  solar access, such as polar craters and during extended lunar
  nights. Optical Power Beaming (OPB) using high-power lasers
  offers a promising alternative to conventional solar power, but
  the effects of suspended lunar dust on beam propagation remain
  poorly understood. This study introduces a detailed simulation
  model that incorporates both diffraction and height-dependent
  scattering by the electrostatically suspended lunar regolith. Un like prior
approaches, which assumed uniform dust layers or
  center-to-center transmission loss, our model uses generalized
  diffraction theory and refractive index gradients derived from
  particle density to assess beam deformation and attenuation. The
  results show that even in ground-to-ground scenarios, lunar dust
  significantly degrades energy transfer efficiency, dropping from
  57% to 3.7% over 50 km in dust-free vs. dusty conditions with
  175 nm particles. Increasing the particle size to 250 nm limits the
  viable transmission range to below 30 km at 6% efficiency. The
  study further demonstrates that raising the laser source height
  can improve efficiency, achieving 91% for a distance of 5 km
  and 25% at 50 km when the source is positioned 12 m above
  ground. These findings underscore the importance of system
  elevation and dust modeling in lunar OPB design and reveal
  the mission-critical role of particle size distribution, especially in
  environments disturbed by human activity.

</details>


### [284] [Smart fault detection in satellite electrical power system](https://arxiv.org/abs/2507.14004)
*Niloofar Nobahari,Alireza Rezaee*

Main category: eess.SY

TL;DR: 本文提出了一种基于MLP神经网络、PCA和KNN的故障检测方法，用于检测无ADCS的低地球轨道（LEO）卫星电力系统中的故障。该方法利用太阳辐射和表面温度等输入数据，预测电流和负载输出，实现了超过99%的准确率，提高了系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要集中在检测卫星电力系统中各个单独组件（如光伏阵列或转换器系统）的故障，而对整个电力系统作为单一实体进行故障检测的关注有限。本文旨在解决这一研究空白，为整个卫星电力系统提供一个整体性的故障诊断解决方案。

Method: 本文提出了一种新的方法，利用多层感知机（MLP）神经网络模型，并结合主成分分析（PCA）和K近邻（KNN）等机器学习技术来对卫星电力系统中的故障进行分类。该模型以太阳辐射和表面温度作为输入，预测电流和负载输出，从而实现故障检测。

Result: 本文提出的方法实现了超过99%的准确率，能够有效识别多个子系统中存在的故障，这标志着与以往方法相比的一个显著进步，因为它提供了一个针对整个卫星电力系统的完整诊断解决方案。

Conclusion: 本文提出的多层感知机（MLP）神经网络模型通过利用太阳辐射和表面温度等输入数据来预测电流和负载输出，实现了对卫星整个电力系统故障的有效分类，准确率超过99%，为整个卫星电力系统提供了完整的诊断解决方案，提高了系统可靠性并降低了任务失败的可能性。

Abstract: This paper presents an new approach for detecting in the electrical power
system of satellites operating in Low Earth Orbit (LEO) without an Attitude
Determination and Control Subsystem (ADCS). Components of these systems are
prone to faults, such as line-to-line faults in the photovoltaic subsystem,
open circuits, and short circuits in the DC-to-DC converter, as well as ground
faults in batteries. In the previous research has largely focused on detecting
faults in each components, such as photovoltaic arrays or converter systems,
therefore, has been limited attention given to whole electrical power system of
satellite as a whole system. Our approach addresses this gap by utilizing a
Multi-Layer Perceptron (MLP) neural network model, which leverages input data
such as solar radiation and surface temperature to predict current and load
outputs. These machine learning techniques that classifiy use different
approaches like Principal Component Analysis (PCA) and K-Nearest Neighbors
(KNN), to classify faults effectively. The model presented achieves over 99%
accuracy in identifying faults across multiple subsystems, marking a notable
advancement from previous approaches by offering a complete diagnostic solution
for the entire satellite power system. This thorough method boosts system
reliability and helps lower the chances of mission failure

</details>


### [285] [Influence of Cell Position on the Capacity of Retired Batteries: Experimental and Statistical Studies](https://arxiv.org/abs/2507.14020)
*Marwan Hassini,Colette Mintsa-Eya,Eduardo Redondo-Iglesias,Pascal Venet*

Main category: eess.SY

TL;DR: 退役电池表现良好，但存在差异。方差分析表明电池位置不影响性能。建议为二次生命电池进行评估和系统开发。


<details>
  <summary>Details</summary>
Motivation: 为了确定退役电池的再利用潜力，了解其使用后的性能至关重要。

Method: 对从电动汽车中提取的三个模块进行测试，评估其性能，并使用方差分析 (ANOVA) 对结果进行统计分析。

Result: 36 个退役电池的平均健康容量为 95%，离散度为 2.4%。

Conclusion: 退役电池表现出很高的性能水平，尽管存在显著差异。电池性能与它们在模块中的位置无关。这些结果表明需要评估退役电池内的离散度，并为二次生命电池开发热管理和平衡系统。

Abstract: Understanding how batteries perform after automotive use is crucial to
determining their potential for reuse. This article presents experimental
results aimed at advancing knowledge of retired battery performance. Three
modules extracted from electric vehicles were tested. Their performance was
assessed, and the results were analyzed statistically using analysis of
variance (ANOVA). The 36 retired cells exhibited a high level of performance,
albeit with significant variation. On average, the cells had a 95% state of
health capacity with a dispersion of 2.4%. ANOVA analysis suggests that cell
performance is not correlated with their position inside the module. These
results demonstrate the need to evaluate dispersion within retired batteries
and to develop thermal management and balancing systems for second-life
batteries.

</details>


### [286] [Reference-Free Iterative Learning Model Predictive Control with Neural Certificates](https://arxiv.org/abs/2507.14025)
*Wataru Hashimoto,Kazumune Hashimoto,Masako Kishida,Shigemasa Takai*

Main category: eess.SY

TL;DR: 一种新的无参考迭代学习MPC方法，使用CLBF学习证书函数来改进终端集和成本，将MPC优化问题转化为非线性规划，提高了计算效率和控制性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有MPC方法中依赖混合整数规划和数值困难的问题，并实现MPC终端组件的渐进式改进和更有效的在线计算。

Method: 提出了一种新颖的无参考迭代学习模型预测控制（MPC）方法。该方法利用从过去控制执行中收集的数据学习基于控制Lyapunov障碍函数（CLBF）概念的证书函数，并利用该函数来定义当前迭代中MPC优化问题的终端集和成本。这使得MPC的终端组件能够通过连续迭代进行渐进式改进。与依赖混合整数规划且存在数值困难的现有方法不同，所提出的方法将MPC优化问题形式化为标准非线性规划，从而实现更有效的在线计算。

Result: 该控制方案迭代地提高了控制性能，并显著提高了在线计算效率。

Conclusion: 该方法满足MPC的递归可行性和渐近稳定性等关键性质，并且在特定假设下，性能成本随迭代次数的增加而非增加。数值实验和PyBullet仿真结果表明，该控制方案能迭代地提高控制性能，并显著提升在线计算效率。

Abstract: In this paper, we propose a novel reference-free iterative learning model
predictive control (MPC). In the proposed method, a certificate function based
on the concept of Control Lyapunov Barrier Function (CLBF) is learned using
data collected from past control executions and used to define the terminal set
and cost in the MPC optimization problem at the current iteration. This scheme
enables the progressive refinement of the MPC's terminal components over
successive iterations. Unlike existing methods that rely on mixed-integer
programming and suffer from numerical difficulties, the proposed approach
formulates the MPC optimization problem as a standard nonlinear program,
enabling more efficient online computation. The proposed method satisfies key
MPC properties, including recursive feasibility and asymptotic stability.
Additionally, we demonstrate that the performance cost is non-increasing with
respect to the number of iterations, under certain assumptions. Numerical
experiments including the simulation with PyBullet confirm that our control
scheme iteratively enhances control performance and significantly improves
online computational efficiency compared to the existing methods.

</details>


### [287] [Physics-guided gated recurrent units for inversion-based feedforward control](https://arxiv.org/abs/2507.14052)
*Mingdao Lin,Max Bolderman,Mircea Lazar*

Main category: eess.SY

TL;DR: 提出PG-GRU模型，结合物理信息和GRU，用于前馈控制，在两质量弹簧阻尼系统实验中效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于逆模型的前馈控制需要精确逆系统模型，以及GRU模型存在可解释性差和易过拟合的问题，本研究提出将GRU与物理信息神经网络（PGNN）结合，以提高模型的物理依据和泛化能力。

Method: 1. 将GRU集成到PGNN框架中，构建PG-GRU模型。
2. 采用两步法设计前馈控制器：首先，利用稳定反演技术设计一个稳定的逆动态线性模型；然后，在残差上训练GRU以识别逆系统。

Result: PG-GRU前馈控制器在两质量弹簧阻尼系统的实验中，其积分绝对误差（IAE）相较于线性的前馈控制器和基于预览的GRU前馈控制器有了约两倍的改进。

Conclusion: 本研究将GRU集成到PGNN框架中，提出了一种新的PG-GRU模型，并设计了一种两步前馈控制方法，在真实的两质量弹簧阻尼系统实验中，其性能比线性前馈和基于预览的GRU前馈控制器有大约两倍的提升（以积分绝对误差衡量）。

Abstract: Inversion-based feedforward control relies on an accurate model that
describes the inverse system dynamics. The gated recurrent unit (GRU), which is
a recent architecture in recurrent neural networks, is a strong candidate for
obtaining such a model from data. However, due to their black-box nature, GRUs
face challenges such as limited interpretability and vulnerability to
overfitting. Recently, physics-guided neural networks (PGNNs) have been
introduced, which integrate the prior physical model structure into the
prediction process. This approach not only improves training convergence, but
also facilitates the learning of a physics-based model. In this work, we
integrate a GRU in the PGNN framework to obtain a PG-GRU, based on which we
adopt a two-step approach to feedforward control design. First, we adopt stable
inversion techniques to design a stable linear model of the inverse dynamics.
Then, a GRU trained on the residual is tailored to inverse system
identification. The resulting PG-GRU feedforward controller is validated by
means of real-life experiments on a two-mass spring-damper system, where it
demonstrates roughly a two-fold improvement compared to the linear feedforward
and a preview-based GRU feedforward in terms of the integral absolute error.

</details>


### [288] [Convex computation of regions of attraction from data using Sums-of-Squares programming](https://arxiv.org/abs/2507.14073)
*Oumayma Khattabi,Matteo Tacchi-Bénard,Sorin Olaru*

Main category: eess.SY

TL;DR: 一种无需模型即可分析自治动力学系统吸引域的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在为未知自治动力学系统提供一种数据驱动的方法来分析区域吸引域（ROA），以克服模型依赖性和多项式结构约束。

Method: 数据驱动的矩-平方和（SoS）层析。

Result: 数值实验表明，该方法能够学习到有影响力的近似集合，为在模型信息有限的情况下进行ROA分析提供了有前景的解决方案。

Conclusion: 本文提出了一种基于矩-平方和（SoS）层析的区域吸引域（ROA）外近似的无模型方法。

Abstract: The paper concentrates on the analysis of the region of attraction (ROA) for
unknown autonomous dynamical systems. The aim is to explore a data-driven
approach based on moment-sum-of-squares (SoS) hierarchy, which enables novel
RoA outer approximations despite the reduced information on the structure of
the dynamics. The main contribution of this work is bypassing the system model
and, consequently, the recurring constraint on its polynomial structure.
Numerical experimentation showcases the influence of data on learned
approximating sets, offering a promising outlook on the potential of this
method.

</details>


### [289] [Integrating Forecasting Models Within Steady-State Analysis and Optimization](https://arxiv.org/abs/2507.14117)
*Aayushya Agarwal,Larry Pileggi*

Main category: eess.SY

TL;DR: 提出一种新方法，将机器学习模型嵌入电力系统仿真中，提高电网在极端天气下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了应对极端天气变化和负荷行为不可预测性带来的挑战，需要一种能够将机器学习预测及其敏感性无缝集成到稳态分析和决策制定策略中的方法。

Method: 提出了一种通用方法，将机器学习预测引擎嵌入基于物理的潮流和电网优化工具中，直接整合训练好的机器学习预测模型的输入和输出来实现。

Result: 通过将机器学习方法与基于物理的电网建模相结合，可以直接从数据中获得敏感性，从而准确预测预测设备对电网变化的响应，并设计出更优的电网调度方案，提高了电网的可靠性。

Conclusion: 该方法通过将机器学习预测模型嵌入基于物理的潮流和电网优化工具中，能够准确捕获负荷和天气事件的行为及敏感性，从而提高电网在随机天气事件下的可靠性。

Abstract: Extreme weather variations and the increasing unpredictability of load
behavior make it difficult to determine power grid dispatches that are robust
to uncertainties. While machine learning (ML) methods have improved the ability
to model uncertainty caused by loads and renewables, accurately integrating
these forecasts and their sensitivities into steady-state analyses and
decision-making strategies remains an open challenge. Toward this goal, we
present a generalized methodology that seamlessly embeds ML-based forecasting
engines within physics-based power flow and grid optimization tools. By
coupling physics-based grid modeling with black-box ML methods, we accurately
capture the behavior and sensitivity of loads and weather events by directly
integrating the inputs and outputs of trained ML forecasting models into the
numerical methods of power flow and grid optimization. Without fitting
surrogate load models, our approach obtains the sensitivities directly from
data to accurately predict the response of forecasted devices to changes in the
grid. Our approach combines the sensitivities of forecasted devices attained
via backpropagation and the sensitivities of physics-defined grid devices. We
demonstrate the efficacy of our method by showcasing improvements in
sensitivity calculations and leveraging them to design a robust power dispatch
that improves grid reliability under stochastic weather events. Our approach
enables the computation of system sensitivities to exogenous factors which
supports broader analyses that improve grid reliability in the presence of load
variability and extreme weather conditions.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [290] [The Hofstadter Butterfly: Bridging Condensed Matter, Topology, and Number Theory](https://arxiv.org/abs/2507.13418)
*Indubala Satija*

Main category: cond-mat.mes-hall

TL;DR: Hofstadter分形蝶是一个艺术与科学的融合体，它优雅地展示了二维晶格中电子的能量谱。该论文从几何和数论的角度探讨了其背后的理论，强调了它在拓扑绝缘体和新物质态研究中的重要性。论文还指出了自然界利用分形来构建蝴蝶图，并将霍尔电导的量子嵌入其中，最终通过一系列数学概念来阐述这一现象。


<details>
  <summary>Details</summary>
Motivation: Hofstadter分形蝶作为艺术与科学的融合，以及其在展示二维晶格中电子能量谱方面的作用，激发了人们对其背后数学原理的探索。

Method: 通过几何学和数论的视角，阐述了蝴蝶分形图的理论框架，并使用具有整数系数的幺模矩阵来简洁地表达。

Result: 该论文揭示了自然界在构建蝴蝶图时利用抽象分形，其中霍尔电导的量子嵌入在梯形的整数斜边中，并通过幺模矩阵、Farey树、Apollonian gasket和毕达哥拉斯三元组树等数学概念得到了体现。

Conclusion: 该论文深入探讨了Hofstadter分形蝶的理论基础，强调了其作为拓扑绝缘体和21世纪物理学中新物质态的范例模型的重要性。

Abstract: Celebrating its golden jubilee, the Hofstadter butterfly fractal emerges as a
remarkable fusion of art and science. This iconic X shaped fractal captivates
physicists, mathematicians, and enthusiasts alike by elegantly illustrating the
energy spectrum of electrons within a two dimensional crystal lattice
influenced by a magnetic field. Enriched with integers of topological origin
that serve as quanta of Hall conductivity, this quantum fractal and its
variations have become paradigm models for topological insulators, novel states
of matter in 21st century physics. This paper delves into the theoretical
framework underlying butterfly fractality through the lenses of geometry and
number theory. Within this poetic mathematics, we witness a rare form of
quantum magic: Natures use of abstract fractals in crafting the butterfly graph
itself. In its simplest form, the butterfly graph tessellates a two dimensional
plane with trapezoids and triangles, where the quanta of Hall conductivity are
embedded in the integer sloped diagonals of the trapezoids. The theoretical
framework is succinctly expressed through unimodular matrices with integer
coefficients, bringing to life abstract constructs such as the Farey tree, the
Apollonian gaskets, and the Pythagorean triplet tree.

</details>


### [291] [Spin-Electric Control of Individual Molecules on Surfaces](https://arxiv.org/abs/2507.13699)
*Paul Greule,Wantong Huang,Máté Stark,Kwan Ho Au-Yeung,Johannes Schwenk,Jose Reina-Gálvez,Christoph Sürgers,Wolfgang Wernsdorfer,Christoph Wolf,Philip Willke*

Main category: cond-mat.mes-hall

TL;DR: 本研究展示了如何通过电场精确控制单个磁性分子的自旋状态，为构建基于分子的量子器件铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 为了在量子信息处理中利用单个磁性分子的特性，需要精确地控制其自旋性质。单个磁性分子因其化学可调性、纳米尺度和自组装成有序阵列的能力，在量子技术中具有应用潜力。

Method: 研究人员使用电子自旋共振结合扫描隧道显微镜（ESR-STM）技术，在表面吸附的分子自旋系统（如酞菁铁FePc及其复合物）上，通过STM针尖进行局部寻址，并利用偏压进行电调谐。

Result: 研究发现了分子共振频率与电压之间显著的非线性关系，这归因于其他分子轨道的能量开启。他们还证明了SEC机制能够实现全电相干自旋控制，通过Rabi振荡测量调整了单分子和耦合Fe-FePc复合物的自旋动力学。

Conclusion: 该研究展示了自旋-电耦合（SEC）在单分子磁体中实现全电相干自旋控制的可行性，为量子信息处理提供了新的途径。

Abstract: Individual magnetic molecules are promising building blocks for quantum
technologies because of their chemical tunability, nanoscale dimensions, and
ability to self-assemble into ordered arrays. However, harnessing their
properties in quantum information processing requires precise local control of
their spin properties. In this work, we present spin-electric coupling (SEC)
for two molecular spin systems, iron phthalocyanine (FePc) and Fe-FePc
complexes, adsorbed on a surface. We use electron spin resonance combined with
scanning tunnelling microscopy (ESR-STM) to locally address them with the STM
tip and electrically tune them using the applied bias voltage. These
measurements reveal a pronounced nonlinear voltage dependence of the resonance
frequency, linked to the energic onset of other molecular orbitals. We
attribute this effect to a transport-mediated exchange field from the magnetic
tip, providing a large, highly localized, and broadly applicable SEC mechanism.
Finally, we demonstrate that the SEC enables all-electrical coherent spin
control: In Rabi oscillation measurements of both single and coupled Fe-FePc
complexes we show that the spin dynamics can be tuned, demonstrating a pathway
towards electrically controlled quantum operation.

</details>


### [292] [Enhancing Coherence with a Clock Transition and Dynamical Decoupling in the Cr$_7$Mn Molecular Nanomagnet](https://arxiv.org/abs/2507.13714)
*Guanchu Chen,Brendan C. Sheehan,Ilija Nikolov,James W. Logan,Charles A. Collett,Gajadhar Joshi,Grigore A. Timco,Jillian E. Denhardt,Kevin R. Kittilstved,Richard E. P. Winpenny,Jonathan R. Friedman*

Main category: cond-mat.mes-hall

TL;DR: 本研究使用Hahn-echo和CPMG脉冲序列研究了Cr7Mn分子磁体的相干时间T2，发现在时钟跃迁（CT）处以及电子自旋回波包调制（ESEEM）区域，T2相干时间均可达微秒级别，并提出了一种新的退相干模型，认为退相干来源于分子内部的多种噪声源。


<details>
  <summary>Details</summary>
Motivation: 分子磁体因其化学可调性、可通过电子自旋共振技术寻址以及长相干时间而被用作自旋量子比特。时钟跃迁（CT）可以提高相干时间T2，并揭示非磁场波动引起的退相干机制。本研究旨在探索Cr7Mn分子磁体的相干时间，并探究退相干的微观机制。

Method: 本研究使用Hahn-echo脉冲序列和CPMG脉冲序列研究了两种Cr7Mn（一种自旋1分子纳米磁体）在零场时钟跃迁附近的性质。通过测量T2相干时间，并分析了ESEEM（电子自旋回波包调制）现象，以探究退相干机制。

Result: 在CT（时钟跃迁）处，Hahn-echo脉冲序列得到的T2相干时间约为1μs。在CT之外的ESEEM（电子自旋回波包调制）区域，T2相干时间高达1.35μs。使用CPMG脉冲序列，在CT处T2提高到约2.8μs，在ESEEM区域可达3.6μs。实验结果表明，T2相干时间与分子在溶剂中的稀释程度以及溶剂是否氘代关系不大，这表明大部分退相干和ESEEM来源于分子内部。

Conclusion: 本研究提出的模型能很好地解释实验结果，该模型考虑了场波动和时钟跃迁频率本身的波动，并将环境视为核拉莫尔进动频率的噪声和横向退化参数E的1/f噪声的组合。这些关于退相干微观起源的信息有助于分子基自旋量子比特的合理设计。

Abstract: Molecular magnets are attractive as spin qubits due to their chemical
tunability, addressability through electron-spin resonance techniques, and long
coherence times. Clock transitions (CTs), for which the system is immune to the
effect of magnetic-field fluctuations to first order, provide a method to
enhance the coherence time $T_2$, and to reveal mechanisms of decoherence that
are not due to such fluctuations. Here we investigate two variants of Cr$_7$Mn,
a spin-1 molecular nanomagnet, at fields near a zero-field CT. We find that at
temperatures $\le$2 K, $T_2\sim1$ $\mu$s at the CT using a Hahn-echo pulse
sequence. Away from the CT, electron-spin-echo envelope modulation (ESEEM)
oscillations due to coupling to nuclear spins are observed and have a $T_2$ as
high as $1.35$ $\mu$s, indicating a distinct mechanism of coherence
preservation. Dynamical decoupling with the CPMG pulse sequence yields
$T_2\sim\!2.8$ $\mu$s at the CT and up to $\sim\!3.6$ $\mu$s in the ESEEM
regime along with a demodulation of the oscillatory behavior. The experimental
values of $T_2$ are largely independent of the degree of dilution of the
molecules in solvent or whether the solvent is deuterated, indicating that much
of the decoherence and ESEEM arises from sources within the molecules
themselves. To account for decoherence, we develop a model that includes not
only field fluctuations but also fluctuations in the CT transition frequency
itself. Our results can be well explained by treating the environment as a
combination of noise at the nuclear Larmor precession frequency and $1/f$ noise
in the transverse anisotropy parameter $E$. Such information about the
microscopic origins of decoherence can aid the rational design of
molecular-based spin qubits.

</details>


### [293] [Resonant two-qubit gates for fermionic simulations with spin qubits](https://arxiv.org/abs/2507.13781)
*Konstantinos Tsoukalas,Alexei Orekhov,Bence Hetényi,Uwe von Lüpke,Jeth Arunseangroj,Inga Seidler,Lisa Sommer,Eoin G. Kelly,Leonardo Massai,Michele Aldeghi,Marta Pita-Vidal,Stephen W. Bedell,Stephan Paredes,Felix J. Schupp,Matthias Mergenthaler,Gian Salis,Andreas Fuhrer,Patrick Harvey-Collard*

Main category: cond-mat.mes-hall

TL;DR: 该研究首次在半导体自旋量子比特中实现了fSim门集，并演示了其在锗双量子比特上的高保真度应用。


<details>
  <summary>Details</summary>
Motivation: 为了探索fSim门集在半导体自旋量子比特中的应用潜力，并为近期的量子模拟算法提升性能。

Method: 该研究提出并演示了一种在自旋量子比特中实现fSim门集的方法，该方法利用结合了基带和共振交换驱动的单脉冲。

Result: 成功在两个锗空穴自旋中实现了共振iSWAP门，保真度达到93.8(5)%，并通过量子过程层析成像技术确认了门的准确性和量子比特退相干是主要的误差来源。

Conclusion: 该研究通过结合基带和共振交换驱动的单脉冲，在锗双量子比特中实现了fSim门集，为基于自旋的量子处理器提供了一条通用且高效的双量子比特门实现路径。

Abstract: In gate-defined semiconductor spin qubits, the highly tunable Heisenberg
exchange interaction is leveraged to implement fermionic two-qubit gates such
as CZ and SWAP. However, the broader family of fermionic simulation (fSim)
gates remains unexplored, and has the potential to enhance the performance of
near-term quantum simulation algorithms. Here, we demonstrate a method to
implement the fSim gate set in spin qubits using a single pulse combining
baseband and resonant exchange drives. This approach minimizes gate duration
and drive amplitude, mitigating decoherence and crosstalk. We validate its
effectiveness by realizing a resonant iSWAP gate between two hole spins in
germanium, achieving a fidelity of 93.8(5)% extracted with interleaved
randomized benchmarking. Quantum process tomography confirms accurate gate
calibration and identifies qubit decoherence as the dominant error source. Our
results establish a practical route toward a versatile and efficient two-qubit
gate set for spin-based quantum processors.

</details>


### [294] [Intraband circular photogalvanic effect in Weyl semimetals](https://arxiv.org/abs/2507.13796)
*L. E. Golub,E. L. Ivchenko*

Main category: cond-mat.mes-hall

TL;DR: 在布尔型半金属中，CPGE的半经典理论与量子力学方法存在差异，需要新的微观机制。


<details>
  <summary>Details</summary>
Motivation: 在有隙系统中，这些机制可以完全解释CPGE电流的所有贡献，但与完整的量子力学方法得到的结果不同。

Method: 应用包含 Berry 散度偶极子、侧跳和斜散射的半经典理论，对布尔型半金属带内吸收的圆光电流效应 (CPGE) 进行定量描述。

Result: 所有先前已知的半经典机制都与完整的量子力学方法得到的结果不同。

Conclusion: 现有准经典和全量子力学方法在所有空间范围的无序势下都存在差异，需要将另一个微观机制引入到CPGE的准经典描述中。

Abstract: We apply the semiclassical theory including the Berry curvature dipole, side
jumps and skew scattering for a quantitative description of the circular
photogalvanic effect (CPGE) in Weyl semimetals at intraband absorption. In
contrast to gapped systems where they completely exhaust all contributions to
the CPGE current, all previously known semiclassical mechanisms give a result
different from that obtained using a complete quantum-mechanical approach. We
show that this difference in the existing quasiclassical and full
quantum-mechanical approaches persists at all spatial ranges of the disorder
potential. Apparently, the implementation of another microscopic mechanism into
the quasiclassical description of the CPGE is required.

</details>


### [295] [Resonant Photoluminescence of Quantum Incompressible Liquids](https://arxiv.org/abs/2507.13816)
*D. A. Shchigarev,A. V. Larionov,L. V. Kulik,E. M. Budanov,I. V. Kukushkin,V. Umansky*

Main category: cond-mat.mes-hall

TL;DR: 二维电子系统中，研究了量子液体的光学性质，发现了光学不变量，并绘制了量子液体的相图。


<details>
  <summary>Details</summary>
Motivation: 研究不可压缩量子液体在二维电子系统中的光学性质，特别是光致发光现象。

Method: 通过研究二维电子系统中由光激发电子和价带空穴组成的激子，以及其共振光致发光来分析不可压缩量子液体。

Result: 量子液体形成于n=1/3，并随着温度降低向n=1/2扩展，发现了光学不变量，证明了激子复合在量子液体中的行为。

Conclusion: 该研究发现了二维电子系统中不可压缩量子液体的共振光致发光现象，并确定了一个与激发能量无关但与电子温度密切相关的光学不变量，可用作量子液体中激子复合的探针。研究结果表明，量子液体形成于n=1/3，并随着温度降低向n=1/2扩展，不同量子液体状态之间的转变是平滑的，没有明确的相边界。

Abstract: We investigate resonant photoluminescence arising from incompressible quantum
liquids formed in two-dimensional electron systems. We demonstrate that, for
excitons composed of a photoexcited electron occupying the upper spin sublevel
of the zeroth Landau level and a valence-band hole, the influence of disorder
potential fluctuations on optical recombination is strongly suppressed,
indicating complete screening of the disorder. We identify an optical invariant
quantity that is insensitive to excitation energy yet strongly dependent on the
electron temperature, serving as a probe of exciton recombination in quantum
liquids. Analysis of this quantity reveals that quantum-liquid formation
initiates at (n = 1/3) as the electron temperature decreases, consistent with
the Laughlin state. Upon further cooling, the range of filling factors
exhibiting quantum-liquid behavior expands continuously from (n = 1/3) toward
(n = 1/2). Transitions between distinct incompressible quantum-liquid states
occur smoothly, without well-defined phase boundaries separating insulating and
conducting regimes. Locally, the system retains quantum-liquid characteristics
even as bulk transport measurements indicate finite conductivity. Finally, we
present a phase diagram delineating the stability region of incompressible
quantum liquids relative to conductive phases.

</details>


### [296] [Tuning the Surface States of $Fe_3O_4$ Nanoparticles for Enhanced Magnetic Anisotropy and Induction Efficacy](https://arxiv.org/abs/2507.13838)
*Kyle A. Portwin,Pablo Galaviz,Xiaoning Li,Chongyan Hao,Lachlan A. Smillie,Mengyun You,Caleb Stamper,Richard Mole,Dehong Yu,Kirrily C. Rule,David L. Cortie,Zhenxiang Cheng*

Main category: cond-mat.mes-hall

TL;DR: 研究表明，通过热处理优化Fe3O4纳米颗粒的表面状态可以显著提高其在生物医学应用中的性能，主要体现在提高磁各向异性和比吸收率，并抑制低温团簇自旋玻璃转变。


<details>
  <summary>Details</summary>
Motivation: 为了提高Fe3O4纳米颗粒在磁性热疗、靶向药物输送和MRI造影剂增强等生物医学应用中的性能，需要研究其表面状态对其感应性能的影响。

Method: 通过同步粉末衍射、中子粉末衍射、热重分析、X射线光电子能谱、X射线吸收能谱和飞行时间非弹性中子散射等技术，研究了热处理对Fe3O4纳米颗粒表面状态的影响，并通过交流磁化率测量评估了表面改性对其磁性能的影响。

Result: 热处理去除了表面水和FeOOH，形成了γ-Fe2O3壳层，增强了磁各向异性，缩短了自旋弛豫时间，使比吸收率提高了140%。此外，增加的各向异性抑制了低温团簇自旋玻璃转变，并提高了阻挡温度。

Conclusion: 表面状态工程是通过优化生物医学应用中的Fe3O4纳米颗粒来提高其性能的有效方法。

Abstract: Magnetite ($Fe_3O_4$) nanoparticles are crucial for biomedical applications,
including magnetic hyperthermia, targeted drug delivery, and MRI contrast
enhancement, due to their biocompatibility and unique physicochemical
properties. Here, we investigate how surface states influence their induction
performance. Heat treatment removes surface water and FeOOH, forming a
${\gamma}$-$Fe_2O_3$ shell, as confirmed by synchrotron powder diffraction,
neutron powder diffraction, thermogravimetric analysis, X-ray photoelectron
spectroscopy, X-ray absorption spectroscopy, and time-of-flight inelastic
neutron spectroscopy. AC magnetic susceptibility measurements reveal that this
surface modification enhances magnetic anisotropy and reduces the spin
relaxation time, leading to a 140% increase in the specific absorption rate.
Additionally, the increased anisotropy suppresses the low-temperature clustered
spin-glass transition and raises the blocking temperature. These findings
highlight surface-state engineering as a powerful approach to optimizing
$Fe_3O_4$ nanoparticles for biomedical applications.

</details>


### [297] [Alignment behavior of 2D diopsides (d-silicates) under the influence of an AC electric field](https://arxiv.org/abs/2507.13962)
*Himakshi Mishra,Bruno Ipaves,Raphael Benjamim de Oliveira,Marcelo Lopes Pereira Junior,Raphael Matozo Tromer,e Douglas Soares Galvao,Chandra Shekar Tiwary*

Main category: cond-mat.mes-hall

TL;DR: 电场可以调控二位二硅酸钙薄片的取向，提高其电导率，为柔性电子应用带来新机遇。


<details>
  <summary>Details</summary>
Motivation: 控制二位二硅酸钙薄片的取向对于优化其在下一代器件中的电子和机械性能至关重要，但缺乏有效的方法来实现这一目标。

Method: 通过外加交流电场，利用压电效应引起的形变驱动二位二硅酸钙薄片在微电极上重新排列，并通过拉曼光谱和电学测试表征其取向变化和电学性质的改善。同时，利用全原子分子动力学模拟解释了薄片在表面的自发排列机制。

Result: 通过电场调控，二位二硅酸钙薄片的电导率提高了20-30%，并且实验观察和分子动力学模拟均证实了薄片在电场作用下的取向性排列。

Conclusion: 本研究证明了使用电场调控二位二硅酸钙（CaMgSi2O6）薄片的取向是一种有前景的方法，可用于优化其在柔性电子、传感器和能源设备中的性能。

Abstract: Controlling the alignment of two dimensional (2D) materials is crucial for
optimizing their electronic and mechanical properties in next generation
devices. This study explores how electric fields can manipulate the orientation
of 2D diopside (CaMgSi2O6) flakes, a flexible silicate material, through a
phenomenon called flexoelectricity, where applied voltage generates mechanical
strain. We exfoliated diopside crystals into ultrathin flakes, placed them on
microelectrodes, and used AC electric fields to induce alignment via acoustic
strain. Raman spectroscopy showed that the flakes reoriented/realigned under
the field, with vibrational peaks weakening most at high frequencies (10 MHz).
Electrical tests revealed this alignment improves conductivity by 20-30%, as
straightened flakes create better pathways for current flow. Fully atomistic
molecular dynamics simulations further explained how these flakes naturally
align on surfaces within picoseconds, matching our experimental observations.
Together, these findings demonstrate a practical way to tune diopside
properties using electric fields, opening doors for its use in flexible
electronics, sensors, and energy devices.

</details>


### [298] [Density Matrix Geometry and Sum Rules](https://arxiv.org/abs/2507.14028)
*Guangyue Ji,David E. Palomino,Nathan Goldman,Tomoki Ozawa,Peter Riseborough,Jie Wang,Bruno Mera*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种新的时变量子几何方法，用于研究热力学系统中的几何效应，统一了解释了物理现象中的求和规则，并提供了新的实验探索途径。


<details>
  <summary>Details</summary>
Motivation: 几何在从异常输运系数到相关求和规则的广泛物理响应中起着基本作用。零温下的霍尔电导量子化和Souza-Wilkens-Martin (SWM) 求和规则是其中的典型例子。SWM 求和规则的有限温度推广已被探讨，并揭示了其与密度矩阵几何的深刻联系。

Method: 利用近期在时变几何框架方面的进展，提出一个适用于热密度矩阵的时变量子几何张量。

Result: 该理论为已知的求和规则提供了一个统一的解释，将其置于涨落耗散定理的框架内，并进一步阐明了它们基本的几何起源。此外，该方法还提供了探索零温区以外量子几何的实验方法。

Conclusion: 该研究提出了一个适用于热密度矩阵的时变量子几何张量，它统一了解释了已知求和规则与涨落耗散定理之间的关系，并阐明了其根本的几何起源。此外，它还提供了在零温区以外探索量子几何的实验可及方法。

Abstract: Geometry plays a fundamental role in a wide range of physical responses, from
anomalous transport coefficients to their related sum rules. Notable examples
include the quantization of the Hall conductivity and the Souza-Wilkens-Martin
(SWM) sum rule -- both valid at zero temperature, independent of interactions
and disorder. The finite-temperature generalization of the SWM sum rule has
been explored in the literature, revealing deep connections to the geometry of
density matrices. Building on recent advances in time-dependent geometric
frameworks, we propose a time-dependent quantum geometric tensor for thermal
density matrices. This formalism provides a unified interpretation of known sum
rules within the framework of the fluctuation-dissipation theorem, further
elucidating their fundamental geometric origin. In addition, it provides
experimentally accessible methods to probe quantum geometry beyond the
zero-temperature regime.

</details>


### [299] [Predicting interface and spin states in armchair graphene nanoribbon junctions](https://arxiv.org/abs/2507.14065)
*Sofia Sanz,Daniel Sánchez-Portal*

Main category: cond-mat.mes-hall

TL;DR: Interface states in graphene nanoribbons depend on width differences and bonding, not just topology. Strain and the Hubbard model affect magnetism. Rules of thumb are provided for design.


<details>
  <summary>Details</summary>
Motivation: To understand and predict interface states and their magnetic properties at junctions between armchair graphene nanoribbons of varying widths, going beyond simple topological classification.

Method: Theoretical analysis using the mean-field Hubbard model to investigate spin states and magnetic behavior at junctions, considering width differences, bonding configurations, and applied strain.

Result: Demonstrated that width differences and bonding configurations are crucial for predicting interface states, showed the effect of strain on topological properties, and revealed the dependence of magnetic behavior on localized states.

Conclusion: The study provides rules of thumb for predicting localized states and magnetic moments at graphene nanoribbon junctions, aiding in the engineering of electronic and magnetic properties through structural design.

Abstract: We present a theoretical analysis of interface states emerging at junctions
between armchair graphene nanoribbons of varying widths. By exploring diverse
width combinations and junction geometries, we demonstrate that predicting the
precise number of interface states requires considerations beyond the
topological classification alone; specifically, the width differences and
bonding configuration at the interface play crucial roles. For junctions
involving ribbons with small gaps, we further examine how an applied strain
affects their topological properties and, consequently, the interface states
formed. The spin states at these junctions are investigated using the
mean-field Hubbard model, revealing how the magnetic behavior at the interface
depends on the number of localized states present. These results are summarized
in a series of ``rules of thumb" to predict the number of localized states and
the magnetic moment at the junction. Our findings contribute to understanding
and engineering localized states in graphene-based devices, providing
guidelines for manipulating electronic and magnetic properties through
structural design.

</details>


### [300] [Emergent topology by Landau level mixing in quantum Hall-superconductor nanostructures](https://arxiv.org/abs/2507.14074)
*Yuriko Baba,Alfredo Levy Yeyati,Pablo Burset*

Main category: cond-mat.mes-hall

TL;DR: 本研究展示了量子霍尔-超导体混合系统中出现的新型拓扑相，这些相由朗道能级混合和自旋-轨道相互作用驱动。研究识别了超越p波超导的新相，并发现了其独特的输运特征，为在量子霍尔器件中实现和探测拓扑提供了新策略。


<details>
  <summary>Details</summary>
Motivation: 为了探索量子霍尔-超导体混合系统中由朗道能级混合和自旋-轨道相互作用驱动的新型拓扑相，并识别超越传统p波超导的相。

Method: 通过数值模拟和有效模型，研究了自旋-轨道耦合和条带几何对控制这些跃迁的作用。

Result: 发现了由朗道能级混合和自旋-轨道相互作用驱动的新型拓扑相，并识别了其独特的输运特征，例如在填充因子ν=1时由电子共隧穿产生的量子化非局域电导，以及在ν=2时与量子化交叉安德烈夫反射共存的可能性。

Conclusion: 本研究揭示了在量子霍尔-超导体混合系统中，由朗道能级混合和自旋-轨道相互作用驱动的新型拓扑相的出现。通过数值模拟和有效模型，我们识别了杂化武尔夫态的区域，这些区域会产生超越传统p波超导的相。

Abstract: We demonstrate the emergence of novel topological phases in quantum
Hall-superconductor hybrid systems driven by Landau level mixing and spin-orbit
interactions. Focusing on a narrow superconducting stripe atop a
two-dimensional electron gas, we identify regimes where the hybridization of
the chiral Andreev states at each side of the stripe leads to different phases
beyond the long sought $p$-wave superconducting one. These topological phases
exhibit distinctive transport signatures, including quantized nonlocal
conductance arising from electron cotunneling at filling factor $\nu=1$, which
can coexist with quantized crossed Andreev reflection at $\nu=2$. A combination
of numerical simulations and effective modelling reveals the role of spin-orbit
coupling and stripe geometry in controlling these transitions. Our findings
suggest new strategies for realizing and detecting topology in proximized
quantum Hall devices.

</details>


### [301] [Fast charge noise sensing using a spectator valley state in a singlet-triplet qubit](https://arxiv.org/abs/2507.14108)
*David W. Kanaar,Yasuo Oda,Mark F. Gyure,J. P. Kestner*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种利用硅单态-三态量子比特监测电荷噪声的方法，可实时监测并提高量子比特性能。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子计算，需要解决半导体自旋量子比特易受电荷噪声影响的问题。通过精确的原位测量电荷噪声，可以实现闭环控制并提高量子比特的性能。

Method: 利用一个初始化在被激发的谷态的单电子的硅单态-三态量子比特，通过交换相互作用耦合到高品质谐振器，实现对量子比特的谷激发作为旁观自由度，并通过谐振器的色散读出，在量子比特操作期间对由电荷噪声引起的电压涨落进行连续的经典测量。

Result: 在实际器件参数下，使用量子限制放大器可在亚微秒内完成测量；即使没有量子限制放大器，通过优化谐振器参数也可在亚毫秒内实现测量。

Conclusion: 该方法能够在量子比特操作期间进行实时监测，有望通过反馈和前馈策略来维持高保真度的量子操作，并且该协议能够保持自旋相干性，还可以与量子逻辑门并行运行。

Abstract: Semiconductor spin qubits are a promising platform for quantum computing but
remain vulnerable to charge noise. Accurate, in situ measurement of charge
noise could enable closed-loop control and improve qubit performance. Here, we
propose a method for real-time detection of charge noise using a silicon
singlet-triplet qubit with one electron initialized in an excited valley state.
This valley excitation acts as a spectator degree of freedom, coupled to a
high-quality resonator via the exchange interaction, which is sensitive to
charge-noise-induced voltage fluctuations. Dispersive readout of the resonator
enables a continuous, classical measurement of exchange fluctuations during
qubit operation. Signal-to-noise analysis shows that, under realistic device
parameters, sub-microsecond measurement times are possible using a
quantum-limited amplifier. Even without such an amplifier, sub-millisecond
performance is achievable with appropriately engineered resonator parameters.
This approach allows the probe to monitor slow drift in exchange in real time,
opening the door to feedback and feedforward strategies for maintaining
high-fidelity quantum operations. Importantly, the protocol preserves spin
coherence and can be run concurrently with qubit logic gates.

</details>


### [302] [Anyonic analogue of optical Mach-Zehnder interferometer](https://arxiv.org/abs/2507.14115)
*Navketan Batra,Zezhu Wei,Smitha Vishweshwara,D. E. Feldman*

Main category: cond-mat.mes-hall

TL;DR: A new Mach-Zehnder interferometer design for anyons simplifies interference signal interpretation and analysis by avoiding drains and limiting anyon paths, with solutions applicable to Jain states and zero-voltage thermal interferometry.


<details>
  <summary>Details</summary>
Motivation: To provide a direct probe of fractional statistics through an interferometry geometry that parallels an optical Mach-Zehnder interferometer and offers advantages over existing schemes.

Method: Proposed a Mach-Zehnder interferometer geometry for anyonic interferometry, allowing for simple exact solutions for electric current and noise.

Result: Presented results for electric current and noise in Jain states and addressed thermal interferometry at zero voltage bias, demonstrating solutions similar to non-interacting electrons but reflecting fractional charge and statistics.

Conclusion: The proposed Mach-Zehnder interferometer geometry for anyonic interferometry offers advantages over existing schemes, providing a straightforward interpretation of interference signals and suppressing bulk-edge coupling effects.

Abstract: Anyonic interferometry is a direct probe of fractional statistics. We propose
an interferometry geometry that parallels an optical Mach-Zehnder
interferometer and offers several advantages over existing interferometry
schemes. In contrast to the currently studied electronic Mach-Zehnder
interferometer, our setup has no drain inside the device so that the trapped
topological charge is time-independent. In contrast to electronic Fabry-P\'erot
interferometry, anyons cannot go around the device more than once. Thus, the
interference signal has a straightforward interpretation in terms of anyonic
statistical phases. The proposed geometry suppresses the undesirable effects of
bulk-edge coupling. Moreover, the setup allows for simple exact solutions for
the electric current and noise for an arbitrary quasiparticle tunneling
strength in a broad range of conditions. The structure of the solutions is
similar to that for non-interacting electrons but reflects fractional charge
and statistics. We present results for electric current and noise in Jain
states and address thermal interferometry at zero voltage bias.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [303] [Complexity of Abduction in Łukasiewicz Logic](https://arxiv.org/abs/2507.13847)
*Katsumi Inoue,Daniil Kozhemiachenko*

Main category: cs.LO

TL;DR: 该研究使用卢卡谢维奇模糊逻辑和区间文字来处理具有真值度的命题，并分析了溯因推理的复杂性，发现子句片段比一般情况更易于处理。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索在具有真值度（例如“电梯已满”、“症状严重”等）的命题的上下文中解释观测值的问题。

Method: 该研究将无限值卢卡谢维奇模糊逻辑与表示变量可能取值集合的“区间文字”（如 p≥c、p≤c 及其否定）相结合，以形式化具有真值度的命题的上下文。

Result: 研究分析了在完整语言和仅包含析取子句的理论的卢卡谢维奇逻辑中，标准溯因推理任务（解识别、解存在和假设的相关性/必要性）的复杂性，并指出与经典命题逻辑相比，子句片段中的溯因比一般情况具有更低的复杂性。

Conclusion: 该研究分析了在包含具有真值度（例如“电梯已满”、“症状严重”等）的命题的上下文中解释观测值的问题，并使用无限值卢卡谢维奇模糊逻辑来形式化这些上下文。研究定义并阐述了在扩展了“区间文字”（如 p≥c、p≤c 及其否定）的语言中，表示变量可能取值集合的 the abductive problems 和 explanations 的概念。

Abstract: We explore the problem of explaining observations in contexts involving
statements with truth degrees such as `the lift is loaded', `the symptoms are
severe', etc. To formalise these contexts, we consider infinitely-valued
{\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction
problems and explanations in the language of {\L}ukasiewicz logic expanded with
`interval literals' of the form $p\geq\mathbf{c}$, $p\leq\mathbf{c}$, and their
negations that express the set of values a variable can have. We analyse the
complexity of standard abductive reasoning tasks (solution recognition,
solution existence, and relevance / necessity of hypotheses) in {\L}ukasiewicz
logic for the case of the full language and for the case of theories containing
only disjunctive clauses and show that in contrast to classical propositional
logic, the abduction in the clausal fragment has lower complexity than in the
general case.

</details>


### [304] [Application Placement with Constraint Relaxation](https://arxiv.org/abs/2507.13895)
*Damiano Azzolini,Marco Duca,Stefano Forti,Francesco Gallo,Antonio Ielo*

Main category: cs.LO

TL;DR: 该研究提出一种利用答案集编程来解决云边网络中多服务应用程序的服务部署问题，特别处理了不可满足的需求和偏好。


<details>
  <summary>Details</summary>
Motivation: 大多数现有解决方案无法处理不可满足的问题实例以及DevOps可能同意放宽以获得解决方案的偏好（即需求）。

Method: 利用答案集编程优化能力来解决将服务部署到云边网络中的计算节点的问题。

Result: 实验结果表明，该方法在模拟环境中对真实网络和应用程序有效。

Conclusion: 该方法在模拟环境中对真实网络和应用程序有效。

Abstract: Novel utility computing paradigms rely upon the deployment of multi-service
applications to pervasive and highly distributed cloud-edge infrastructure
resources. Deciding onto which computational nodes to place services in
cloud-edge networks, as per their functional and non-functional constraints,
can be formulated as a combinatorial optimisation problem. Most existing
solutions in this space are not able to deal with \emph{unsatisfiable} problem
instances, nor preferences, i.e. requirements that DevOps may agree to relax to
obtain a solution. In this article, we exploit Answer Set Programming
optimisation capabilities to tackle this problem. Experimental results in
simulated settings show that our approach is effective on lifelike networks and
applications.

</details>


### [305] [Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity](https://arxiv.org/abs/2507.13946)
*Tadeusz Litak,Katsuhiko Sano*

Main category: cs.LO

TL;DR: 谓词探究逻辑的 $n$ 有界近似的极限问题。$
Casari 公式在不同条件下的示意图有效性。


<details>
  <summary>Details</summary>
Motivation: 在谓词设定中，命题探究逻辑不是其 $n$ 有界近似的极限，正如 Ciardelli 和 Grilletti 所发现的那样，他们还为每个固定的 $n$ 找到了 $n$ 有界探究逻辑 $\mathsf{InqBQ}_{n}$ 的完整公理化。

Method: 我们介绍了这些逻辑的无割标签序列演算。

Result: 在我们逻辑演算中的推导，当某个特定规则不被使用时，可以保证是示意图有效的。

Conclusion: 虽然 Casari 公式在（谓词探究逻辑 $\mathsf{InqBQ}$ 的弱子逻辑的）原子层面是有效的，但它在该逻辑中并非示意图有效，然而在有限有界假设下它是示意图有效的。

Abstract: Propositional inquisitive logic is the limit of its $n$-bounded
approximations. In the predicate setting, however, this does not hold anymore,
as discovered by Ciardelli and Grilletti, who also found complete
axiomatizations of $n$-bounded inquisitive logics $\mathsf{InqBQ}_{n}$, for
every fixed $n$. We introduce cut-free labelled sequent calculi for these
logics. We illustrate the intricacies of \textit{schematic validity} in such
systems by showing that the well-known Casari formula is \textit{atomically}
valid in (a weak sublogic of) predicate inquisitive logic $\mathsf{InqBQ}$,
fails to be schematically valid in it, and yet is schematically valid under the
finite boundedness assumption. The derivations in our calculi, however, are
guaranteed to be schematically valid whenever a single specific rule is not
used.

</details>


### [306] [ChemLog: Making MSOL Viable for Ontological Classification and Learning](https://arxiv.org/abs/2507.13987)
*Simon Flügel,Martin Glauer,Till Mossakowski,Fabian Neuhaus*

Main category: cs.LO

TL;DR: 本研究提出了一种结合逻辑方法和深度学习模型的方法，用于本体分类，特别是在ChEBI本体的肽类分类任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的本体分类方法在许多领域中，使用OWL（本体语言）进行类定义时，表达能力不足。本研究旨在提出一种更具表达力的方法来解决这个问题。

Method: 提出了一种利用单子二阶形式化进行本体分类的方法，并将其应用于ChEBI本体的14个肽类相关类别的分类。同时，利用Transformer深度学习模型对整个ChEBI本体进行分类，并将逻辑方法获得的分类作为训练数据来增强深度学习模型的性能。

Result: 在ChEBI本体的肽类（亚类）分类任务上，结合逻辑方法和深度学习模型的方法，相比单独使用深度学习模型，能够显著提升分类性能。

Conclusion: 所提出的逻辑方法和深度学习模型相结合的方法，在ChEBI本体的肽类（亚类）分类任务上取得了显著的性能提升，并为更广泛的本体分类任务提供了新的思路。

Abstract: Despite its prevalence, in many domains, OWL is not expressive enough to
define ontology classes. In this paper, we present an approach that allows to
use monadic second-order formalisations for ontology classification. As a case
study, we have applied our approach to 14 peptide-related classes from the
chemistry ontology ChEBI. For these classes, a monadic second-order logic
formalisation has been developed and applied both to ChEBI as well as to 119
million molecules from the chemistry database PubChem. While this logical
approach alone is limited to classification for the specified classes (in our
case, (sub)classes of peptides), transformer deep learning models scale
classification to the whole of the ChEBI ontology. We show that when using the
classifications obtained by the logical approach as training data, the
performance of the deep learning models can be significantly enhanced.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [307] [Leveraging the Spatial Hierarchy: Coarse-to-fine Trajectory Generation via Cascaded Hybrid Diffusion](https://arxiv.org/abs/2507.13366)
*Baoshen Guo,Zhiqing Hong,Junyi Li,Shenhao Wang,Jinhua Zhao*

Main category: cs.SI

TL;DR: Cardiff框架通过粗到细的扩散模型生成高保真、保护隐私的城市出行轨迹，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂高维分布和生成真实轨迹方面存在不足，而城市出行轨迹数据因隐私和成本问题难以公开获取。

Method: 提出了一种粗粒度到细粒度的Cascaded混合扩散轨迹合成框架。该框架将生成过程分解为两个层级：1. 离散的路段级：将路段编码为低维潜在嵌入，并设计了一个基于扩散Transformer的潜在去噪网络。2. 连续的精细GPS级：以前一阶段的生成结果为条件，设计了一个带有噪声增强机制的精细GPS级条件去噪网络。

Result: 实验结果表明，Cardiff框架在三个大型真实轨迹数据集上，相较于现有最先进的方法，在多项指标上均表现更优，能够生成高保真度的轨迹，并在隐私保护和数据效用之间实现可调的平衡。

Conclusion: 该研究提出了一种名为Cardiff的混合扩散模型方法，用于生成精细化、保护隐私的城市出行轨迹，有效解决了现有方法在处理复杂高维分布和生成真实轨迹方面的不足。

Abstract: Urban mobility data has significant connections with economic growth and
plays an essential role in various smart-city applications. However, due to
privacy concerns and substantial data collection costs, fine-grained human
mobility trajectories are difficult to become publicly available on a large
scale. A promising solution to address this issue is trajectory synthesizing.
However, existing works often ignore the inherent structural complexity of
trajectories, unable to handle complicated high-dimensional distributions and
generate realistic fine-grained trajectories. In this paper, we propose
Cardiff, a coarse-to-fine Cascaded hybrid diffusion-based trajectory
synthesizing framework for fine-grained and privacy-preserving mobility
generation. By leveraging the hierarchical nature of urban mobility, Cardiff
decomposes the generation process into two distinct levels, i.e., discrete road
segment-level and continuous fine-grained GPS-level: (i) In the segment-level,
to reduce computational costs and redundancy in raw trajectories, we first
encode the discrete road segments into low-dimensional latent embeddings and
design a diffusion transformer-based latent denoising network for segment-level
trajectory synthesis. (ii) Taking the first stage of generation as conditions,
we then design a fine-grained GPS-level conditional denoising network with a
noise augmentation mechanism to achieve robust and high-fidelity generation.
Additionally, the Cardiff framework not only progressively generates
high-fidelity trajectories through cascaded denoising but also flexibly enables
a tunable balance between privacy preservation and utility. Experimental
results on three large real-world trajectory datasets demonstrate that our
method outperforms state-of-the-art baselines in various metrics.

</details>


### [308] [Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio](https://arxiv.org/abs/2507.13368)
*Yaowen Hu,Wenxuan Tu,Yue Liu,Xinhang Wan,Junyi Yan,Taichun Zhou,Xinwang Liu*

Main category: cs.SI

TL;DR: CMV-ND是一种新的深度图聚类方法，通过处理图谱的结构信息来提高聚类性能，尤其是在处理大规模和属性缺失的图谱时。


<details>
  <summary>Details</summary>
Motivation: 为了解决实际应用中图谱规模大且属性缺失的问题，提出CMV-ND方法。

Method: CMV-ND通过递归邻域搜索和邻域差异化策略来处理图结构信息，生成多视图表示，并应用于现有的多视图聚类或DGC方法。

Result: CMV-ND在六个广泛使用的图数据集上进行了实验，结果表明该方法显著提高了多种现有方法的性能。

Conclusion: CMV-ND in 实验中证明了其有效性，能够显著提升多种方法的性能。

Abstract: Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes
in an attribute graph into different clusters, has seen substantial potential
in various industrial scenarios like community detection and recommendation.
However, the real-world attribute graphs, e.g., social networks interactions,
are usually large-scale and attribute-missing. To solve these two problems, we
propose a novel DGC method termed \underline{\textbf{C}}omplementary
\underline{\textbf{M}}ulti-\underline{\textbf{V}}iew
\underline{\textbf{N}}eighborhood \underline{\textbf{D}}ifferentiation
(\textit{CMV-ND}), which preprocesses graph structural information into
multiple views in a complete but non-redundant manner. First, to ensure
completeness of the structural information, we propose a recursive neighborhood
search that recursively explores the local structure of the graph by completely
expanding node neighborhoods across different hop distances. Second, to
eliminate the redundancy between neighborhoods at different hops, we introduce
a neighborhood differential strategy that ensures no overlapping nodes between
the differential hop representations. Then, we construct $K+1$ complementary
views from the $K$ differential hop representations and the features of the
target node. Last, we apply existing multi-view clustering or DGC methods to
the views. Experimental results on six widely used graph datasets demonstrate
that CMV-ND significantly improves the performance of various methods.

</details>


### [309] [H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance](https://arxiv.org/abs/2507.13370)
*Shijun Guo,Haoran Xu,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyi Zhang,Yishan Song,Jiwei Chen*

Main category: cs.SI

TL;DR: 提出分层非侵入式意见引导框架H-NeiFi，通过多智能体强化学习优化信息传播，提高共识速度30.7%，并保持全局收敛。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如直接修改用户观点或强制跨群体连接）会损害用户自主性、引发心理抵触并降低全局共识效率。此外，缺乏长期视角导致促进局部共识反而加剧宏观分裂。

Method: 提出了一种基于社交角色的分层、非侵入式意见引导框架H-NeiFi，该框架包含一个两层动态模型，并引入了一种自适应控制用户通信渠道的非侵入式邻居过滤方法。利用多智能体强化学习（MARL）和长期奖励函数优化信息传播路径，避免直接干预用户互动。

Result: 实验表明，H-NeiFi将共识速度提高了22.0%至30.7%，并且在没有专家的情况下仍能保持全局收敛。

Conclusion: H-NeiFi框架通过保护用户互动自主性，实现了自然且高效的共识引导，为社交网络治理提供了新范式。

Abstract: The openness of social media enables the free exchange of opinions, but it
also presents challenges in guiding opinion evolution towards global consensus.
Existing methods often directly modify user views or enforce cross-group
connections. These intrusive interventions undermine user autonomy, provoke
psychological resistance, and reduce the efficiency of global consensus.
Additionally, due to the lack of a long-term perspective, promoting local
consensus often exacerbates divisions at the macro level. To address these
issues, we propose the hierarchical, non-intrusive opinion guidance framework,
H-NeiFi. It first establishes a two-layer dynamic model based on social roles,
considering the behavioral characteristics of both experts and non-experts.
Additionally, we introduce a non-intrusive neighbor filtering method that
adaptively controls user communication channels. Using multi-agent
reinforcement learning (MARL), we optimize information propagation paths
through a long-term reward function, avoiding direct interference with user
interactions. Experiments show that H-NeiFi increases consensus speed by 22.0%
to 30.7% and maintains global convergence even in the absence of experts. This
approach enables natural and efficient consensus guidance by protecting user
interaction autonomy, offering a new paradigm for social network governance.

</details>


### [310] [Patterns, Models, and Challenges in Online Social Media: A Survey](https://arxiv.org/abs/2507.13379)
*Niccolò Di Marco,Anita Bonetti,Edoardo Di Martino,Edoardo Loru,Jacopo Nudo,Mario Edoardo Pandolfo,Giulio Pecile,Emanuele Sangiorgio,Irene Scalco,Simon Zollo,Matteo Cinelli,Fabiana Zollo,Walter Quattrociocchi*

Main category: cs.SI

TL;DR: This survey synthesizes research on digital platforms, highlighting fragmentation and methodological issues. It aims to create a unified foundation for analyzing online social systems by examining empirical data, methods, and models to enable more robust and comparable studies.


<details>
  <summary>Details</summary>
Motivation: To address the fragmentation, methodological heterogeneity, limited model validation, and weak integration across domains in the study of digital platforms and online social systems.

Method: Systematic synthesis of empirical findings and formal models, examining platform-level regularities, assessing methodological architectures, and evaluating current modeling frameworks.

Result: A clearer understanding of platform-level regularities, methodological architectures, and the explanatory power of current modeling frameworks, aiming to lay the groundwork for more robust analyses.

Conclusion: The survey aims to consolidate a shared empirical baseline and clarify structural constraints for robust, comparable, and actionable analyses of online social systems.

Abstract: The rise of digital platforms has enabled the large scale observation of
individual and collective behavior through high resolution interaction data.
This development has opened new analytical pathways for investigating how
information circulates, how opinions evolve, and how coordination emerges in
online environments. Yet despite a growing body of research, the field remains
fragmented and marked by methodological heterogeneity, limited model
validation, and weak integration across domains. This survey offers a
systematic synthesis of empirical findings and formal models. We examine
platform-level regularities, assess the methodological architectures that
generate them, and evaluate the extent to which current modeling frameworks
account for observed dynamics. The goal is to consolidate a shared empirical
baseline and clarify the structural constraints that shape inference in this
domain, laying the groundwork for more robust, comparable, and actionable
analyses of online social systems.

</details>


### [311] [Characterizing the Dynamics of Conspiracy Related German Telegram Conversations during COVID-19](https://arxiv.org/abs/2507.13398)
*Elisabeth Höldrich,Mathias Angermaier,Jana Lasser,Joao Pinheiro-Neto*

Main category: cs.SI

TL;DR: COVID-19期间，Telegram上的德国阴谋论群组激增，活动与疫情事件和社会压力相关。信息传播呈少数群组主导但群组间联系弱的特点。大量链接指向不可信来源，凸显了其作为虚假信息传播渠道的作用。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨COVID-19大流行期间Telegram平台上的阴谋论的爆炸性增长，以及其对社会信任、民主和公共健康的影响。

Method: 本研究对德国语言的Telegram阴谋论聊天群数据集进行了地理、时间和网络分析，研究了信息如何在区域用户群和有影响力的广播频道之间流动，揭示了去中心化讨论与少数关键行为者驱动的内容传播之间的相互作用。

Result: 研究发现，阴谋论活动在重大的COVID-19相关事件期间激增，与社会压力相关。信息从更大范围的讨论流向地方性讨论。排名前10%的聊天群贡献了94%的转发内容，但它们之间几乎没有相互联系。43%的分享链接指向不可信来源，表明Telegram上的阴谋论讨论是错误信息传播的媒介。

Conclusion: 该研究揭示了在COVID-19大流行期间，Telegram平台上的阴谋论相关聊天内容，重点关注了信息传播的地理、时间和网络结构。研究发现，阴谋论活动在重大疫情事件期间激增，并与社会压力相关。信息从国家或跨国讨论流向地方性社区讨论，少数关键聊天群（占10%）传播了94%的转发内容，但这些群组之间联系很少。此外，43%的分享链接指向不可信来源，表明Telegram上的阴谋论讨论是错误信息传播的媒介。

Abstract: Conspiracy theories have long drawn public attention, but their explosive
growth on platforms like Telegram during the COVID-19 pandemic raises pressing
questions about their impact on societal trust, democracy, and public health.
We provide a geographical, temporal and network analysis of the structure of of
conspiracy-related German-language Telegram chats in a novel large-scale data
set. We examine how information flows between regional user groups and
influential broadcasting channels, revealing the interplay between
decentralized discussions and content spread driven by a small number of key
actors.
  Our findings reveal that conspiracy-related activity spikes during major
COVID-19-related events, correlating with societal stressors and mirroring
prior research on how crises amplify conspiratorial beliefs. By analysing the
interplay between regional, national and transnational chats, we uncover how
information flows from larger national or transnational discourse to localised,
community-driven discussions. Furthermore, we find that the top 10% of chats
account for 94% of all forwarded content, portraying the large influence of a
few actors in disseminating information. However, these chats operate
independently, with minimal interconnection between each other, primarily
forwarding messages to low-traffic groups. Notably, 43% of links shared in the
data set point to untrustworthy sources as identified by NewsGuard, a
proportion far exceeding their share on other platforms and in other discourse
contexts, underscoring the role of conspiracy-related discussions on Telegram
as vector for the spread of misinformation.

</details>


### [312] [Linking Multi-Site Sex Ad Data at the Individual Level to Aid Counter-Trafficking Efforts](https://arxiv.org/abs/2507.13477)
*Nickolas K. Freeman,Gregory J. Bott,Burcu B. Keskin,Jason M. Parton,James J. Cochran*

Main category: cs.SI

TL;DR: 研究人员开发了一种高效的方法，利用网络科学和人工智能技术，整合来自多个网站的性广告数据，过滤错误信息，从而为反人口贩运提供关键情报，已成功帮助识别受害者。


<details>
  <summary>Details</summary>
Motivation: 互联网，特别是成人服务网站（ASWs），已成为性交易的工具。随着像Backpage.com这样的主流网站的关闭，交易活动转移到更多分散且位于美国司法管辖区之外的网站。为了有效打击性交易，需要收集、链接和清理来自这些多源网站的数据，但这面临着广告量大、数据类型多样以及存在通用或被盗用数据等挑战。

Method: 该研究采用网络科学、信息系统和人工智能的技术，将不同网站上的性广告链接起来，形成一个代表个体或独特帖子实体的网络。其关键在于一个边过滤程序，用于识别和移除图中可能错误的链接。

Result: 该研究提出的流程在处理速度上比现有方法更快，能在一小时内处理数百万条广告。该流程生成的数据已被用于反人口贩运行动，帮助识别了60多名潜在受害者，并为他们提供了帮助。与现有方法相比，该研究的方法在生成可操作情报方面有显著提升。

Conclusion: 该研究提出了一种端到端的流程，用于链接来自不同成人服务网站的性广告数据，并通过过滤可能错误的链接来生成可用于反人口贩运的情报。该方法能够高效处理海量数据，并已成功帮助识别了60多名潜在的性交易受害者。

Abstract: The Internet facilitates sex trafficking through adult service websites
(ASWs) that host online advertisements for sexual services (sex ads). Since the
closure of the popular site Backpage.com, the ecosystem of ASWs has expanded to
include multiple competing sites that are hosted outside US jurisdiction.
Gaining intelligence for counter-trafficking efforts requires collecting,
linking, and cleaning the data from multiple sites. However, high ad volumes,
disparate data types, and the existence of generic and misappropriated data
make this process challenging. We present an end-to-end process for linking sex
ad data and filtering potentially erroneous links. Outputs of the developed
process have been used to inform counter-trafficking operations that have
helped identify more than 60 potential victims of sex trafficking, some of whom
are getting help to transition out of the life. Our process leverages concepts
and techniques from network science, information systems, and artificial
intelligence to link ads across sites at the level of an individual or unique
posting entity. Our approach is computationally efficient, allowing millions of
ads to be processed in under an hour. A key component of our process is an edge
filtering procedure that identifies and removes potentially erroneous links in
a graph representation of sex ad data. A comparison of the proposed process to
an existing approach shows that our process is typically more computationally
efficient and yields substantial increases in the number of individuals for
which we can derive actionable intelligence. The proposed process is an
efficient and effective approach for transforming the high volumes of disparate
data from sex ads into intelligence that can save lives. It has been refined
over years of collaboration with practitioners and represents a strong
foundation upon which further counter-trafficking tools can be built.

</details>


### [313] [LLM-Based Community Surveys for Operational Decision Making in Interconnected Utility Infrastructures](https://arxiv.org/abs/2507.13577)
*Adaeze Okeukwu-Ogbonnaya,Rahul Amatapu,Jason Bergtold,George Amariucai*

Main category: cs.SI

TL;DR: 研究利用LLM模拟社区偏好，结合基础设施依赖图，生成更优的灾后修复顺序，以增强社区韧性。


<details>
  <summary>Details</summary>
Motivation: 当前的基础设施修复决策主要依赖于系统约束，但这种方法在影响社区的功能性问题上指导有限，因为这些功能可以按任何顺序修复而不违反系统约束。为了弥补这一差距并提高韧性，有必要整合社区偏好来指导修复顺序。

Method: 本研究提出了一种使用异构功能图（HFG）来表示相互依赖的基础设施系统和社区，该图编码了功能之间的依赖关系，并自然地施加了功能的部分顺序。为了弥合技术标准与社区需求之间的差距，本研究将社区偏好整合到HFG的部分顺序中，形成一个总顺序。研究利用大型语言模型（LLM）作为代理调查工具，通过创建具有不同灾难经历的虚拟人物，并让他们针对多样化的灾难场景提出对社区基础设施修复需求的优先级排序。最后，研究应用学习算法根据LLM生成人物的聚合响应来生成全局顺序。

Result: 该研究成功地展示了如何利用LLM模拟社区偏好，并将其与HFG结合，生成一个考虑了系统约束和社区需求的基础设施修复总顺序。

Conclusion: 该研究提出了一种结合异构功能图（HFG）和社区偏好来确定基础设施修复顺序的方法，以提高灾难响应的韧性。通过利用大型语言模型（LLM）模拟不同社区居民的偏好，并结合学习算法生成整体修复顺序，为实际灾难管理提供了新的思路。

Abstract: We represent interdependent infrastructure systems and communities alike with
a hetero-functional graph (HFG) that encodes the dependencies between
functionalities. This graph naturally imposes a partial order of
functionalities that can inform the sequence of repair decisions to be made
during a disaster across affected communities. However, using such technical
criteria alone provides limited guidance at the point where the functionalities
directly impact the communities, since these can be repaired in any order
without violating the system constraints. To address this gap and improve
resilience, we integrate community preferences to refine this partial order
from the HFG into a total order. Our strategy involves getting the communities'
opinions on their preferred sequence for repair crews to address infrastructure
issues, considering potential constraints on resources. Due to the delay and
cost associated with real-world survey data, we utilize a Large Language Model
(LLM) as a proxy survey tool. We use the LLM to craft distinct personas
representing individuals, each with varied disaster experiences. We construct
diverse disaster scenarios, and each simulated persona provides input on
prioritizing infrastructure repair needs across various communities. Finally,
we apply learning algorithms to generate a global order based on the aggregated
responses from these LLM-generated personas.

</details>


### [314] [Duplicating Deceit: Inauthentic Behavior Among Indian Misinformation Duplicators on X/Twitter](https://arxiv.org/abs/2507.13636)
*Ashfaq Ali Shafin,Bogdan Carbunar*

Main category: cs.SI

TL;DR: 机器人通常被认为是社交媒体上传播虚假信息的罪魁祸首，但本研究发现，绝大多数（超过 99%）的重复发布虚假信息的账户并非机器人。研究人员开发了一个名为 TweeXster 的新工具，可以发现协同进行虚假信息传播的账户网络。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在调查社交媒体上不真实的重复发布现象，即多个账户共享相同的虚假信息推文。

Method: 利用 AltNews（一个印度事实核查组织）验证的虚假信息数据集，分析了来自 5,493 个已知重复发布此类内容的账户的超过 1200 万条帖子。

Result: 研究结果显示，在已知的重复发布虚假信息的账户中，只有不到 1% 的账户表现出机器人行为，这与普遍认为机器人是传播虚假信息主要驱动力的假设相反。TweeXster 框架能够识别出参与重复传播虚假或滥用内容的账户集群。

Conclusion: 该研究发现，社交媒体上的虚假信息传播主要由非机器人账户驱动，而不是普遍认为的机器人。研究提出了一个名为 TweeXster 的框架，用于检测和分析重复传播虚假或滥用内容的活动。

Abstract: This paper investigates inauthentic duplication on social media, where
multiple accounts share identical misinformation tweets. Leveraging a dataset
of misinformation verified by AltNews, an Indian fact-checking organization, we
analyze over 12 million posts from 5,493 accounts known to have duplicated such
content. Contrary to common assumptions that bots are primarily responsible for
spreading false information, fewer than 1\% of these accounts exhibit bot-like
behavior. We present TweeXster, a framework for detecting and analyzing
duplication campaigns, revealing clusters of accounts involved in repeated and
sometimes revived dissemination of false or abusive content.

</details>


### [315] [Automated Route-based Conflation Between Linear Referencing System Maps And OpenStreetMap Using Open-source Tools](https://arxiv.org/abs/2507.13939)
*Gibran Ali,Neal Feierabend,Prarthana Doshi,Whoibin Chung,Simona Babiceanu,Michael Fontaine*

Main category: cs.SI

TL;DR: 本研究开发了一种自动化的开源方法，利用隐马尔可夫模型和维特比搜索，成功将弗吉尼亚州的道路线性参考系统（LRS）地图与开放街图（OSM）匹配，成功率达98%以上，解决了传统方法的昂贵和耗时问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决道路度量在不同地图底图间转移时，传统基于专有算法且需要人工验证的昂贵且耗时的“地图匹配”问题，本研究旨在开发一种自动化的、开源的地图匹配方法。

Method: 该研究使用一种基于隐马尔可夫模型（HMM）和维特比搜索的自动匹配方法，将弗吉尼亚州的LRS路线数据与OSM的地理片段进行匹配。具体步骤包括：逐条加载LRS路线、确定行车方向、对大于12米的间隙进行插值，然后使用Valhalla的地图匹配算法找到对应的OSM片段。

Result: 研究实现了弗吉尼亚州道路网络LRS地图与OSM的自动匹配，匹配成功率超过98%，优于现有的自动化方法，并提供了一个可供复制的开源处理流程。

Conclusion: 该研究成功地将弗吉尼亚州的道路网络线性参考系统（LRS）地图与开放街图（OSM）进行了自动匹配，匹配成功率超过98%，并提出了一个可复制的、无需专有许可证的开源处理流程。

Abstract: Transportation researchers and planners utilize a wide range of roadway
metrics that are usually associated with different basemaps. Conflation is an
important process for transferring these metrics onto a single basemap.
However, conflation is often an expensive and time-consuming process based on
proprietary algorithms that require manual verification.
  In this paper, an automated open-source process is used to conflate two
basemaps: the linear reference system (LRS) basemap produced by the Virginia
Department of Transportation and the OpenStreetMap (OSM) basemap for Virginia.
This process loads one LRS route at a time, determines the correct direction of
travel, interpolates to fill gaps larger than 12 meters, and then uses
Valhalla's map-matching algorithm to find the corresponding points along OSM's
segments. Valhalla's map-matching process uses a Hidden Markov Model (HMM) and
Viterbi search-based approach to find the most likely OSM segments matching the
LRS route.
  This work has three key contributions. First, it conflates the Virginia
roadway network LRS map with OSM using an automated conflation method based on
HMM and Viterbi search. Second, it demonstrates a novel open-source processing
pipeline that could be replicated without the need for proprietary licenses.
Finally, the overall conflation process yields over 98% successful matches,
which is an improvement over most automated processes currently available for
this type of conflation.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [316] [Optically detected magnetic resonance of nitrogen-vacancy centers in microdiamonds inside nanopolycrystalline diamond anvil cell](https://arxiv.org/abs/2507.13634)
*Masahiro Ohkuma,Keigo Arai,Kenji Ohta,Toru Shinmei,Ryo Matsumoto,Yoshihiko Takano,Tetsuo Irifune*

Main category: cond-mat.mtrl-sci

TL;DR: 利用NPD金刚石压砧和NV色心微金刚石，在高压下实现了ODMR测量，可用于压力和磁场成像。


<details>
  <summary>Details</summary>
Motivation: 为了在高压高温条件下进行光学和光谱测量，需要开发一种具有高光学透明度、高硬度和低热导率的材料。

Method: 通过在金刚石压砧中，使用NPD金刚石作为压砧，并结合NV色心微金刚石，实现了光学探测磁共振（ODMR）测量。

Result: 在高达20 GPa的压力下，观测到了NV色心微金刚石的ODMR信号，并发现了共振频率随压力分布的变化，证明了该方法的可行性。

Conclusion: NPD与NV色心微金刚石的结合为高压高温条件下的压力和磁场成像提供了有利条件。

Abstract: We demonstrated optically detected magnetic resonance (ODMR) of
nitrogen-vacancy (NV) centers in microdiamonds inside a diamond anvil cell
pressurized with nanopolycrystalline diamond (NPD) anvils. NPD exhibits high
optical transparency, superior hardness, and low thermal conductivity, making
it suitable for optical and spectroscopic measurements under high-pressure and
high-temperature conditions. We observed the ODMR signal from an ensemble of NV
centers under high pressures, reaching up to 20 GPa, with a culet diameter of
600 $\mu$m. We also performed ODMR measurements on multiple microdiamonds
sealed inside a sample chamber and found that the resonance frequency varied
with the pressure distribution. The combination of NPD and microdiamonds
containing NV centers is auspicious for pressure and magnetic imaging under
concurrent high-pressure and high-temperature conditions.

</details>


### [317] [Moiré-Induced Magnetoelectricity in Twisted Bilayer NiI2](https://arxiv.org/abs/2507.13709)
*Haiyan Zhua,Hongyu Yua,Weiqin Zhua,Guoliang Yua,Changsong Xu,Hongjun Xiang*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Twisted magnetic van der Waals (vdW) materials offer a promising route for
multiferroic engineering, yet modeling large-scale moir\'e superlattices
remains challenging. Leveraging a newly developed SpinGNN++ framework that
effectively handles spin-lattice coupled systems, we develop a comprehensive
interatomic machine learning (ML) potential and apply it to twisted bilayer
NiI2 (TBN). Structural relaxation introduces moir\'e-periodic "bumps" that
modulate the interlayer spacing by about 0.55~\AA{} and in-plane ionic shifts
up to 0.48~\AA{}. Concurrently, our ML potential, which faithfully captures all
key spin interactions, produces reliable magnetic configurations; combined with
the generalized KNB mechanism, it yields accurate spin-driven polarization. For
twist angles 1.89^{\circ} \leq \theta \leq 2.45^{\circ}, both mechanisms become
prominent, yielding rich polarization textures that combine ionic out-of-plane
dipoles with purely electronic in-plane domains. In the rigid (unrelaxed)
bilayer, skyrmions are absent; lattice relaxation is essential for generating
polar-magnetic topologies. In contrast, near {\theta} \approx 60^{\circ},
stacking-dependent ferroelectric displacements dominate, giving rise to polar
meron-antimeron networks. These results reveal cooperative ionic and
spin-driven ferroelectricity in TBN, positioning twisted vdW magnets as
adaptable platforms for tunable multiferroic devices.

</details>


### [318] [Autferroicity: concept, candidates, and applications](https://arxiv.org/abs/2507.13733)
*Jun-Jie Zhang,Ziwen Wang,Shuai Dong*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Autferroicity is a newly proposed form of hybrid ferroicity, which is a
sister branch of multiferroicity. It is characterized by the mutually exclusive
magnetic and polar phases within a single system, giving a unique seesaw-type
magnetoelectric coupling. This perspective provides a theoretical overview of
its underlying concept, phase diagram characteristics, and representative
candidates such as Ti-based trichalcogenide monolayers, while also highlighting
its potential applications in nonvolatile memory devices and true random number
generation.

</details>


### [319] [Phase Transition Under Control: Toward Application-Oriented Luminescence Thermometry and Thermally Activated Emission](https://arxiv.org/abs/2507.13750)
*M. T. Abbas,M. Szymczak,D. Szymanski,J. Zeler,M. Drozd,L. T. K Giang,L. Marciniak*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过控制 LaGaO3:Eu3+ 荧光粉的粒径和掺杂 Al3+、Sc3+ 离子，成功提高了其作为发光温度计的热敏性能，拓宽了热响应范围，并减小了滞后回线，为设计高性能发光温度计提供了新策略。


<details>
  <summary>Details</summary>
Motivation: 旨在克服基于相变的发光温度计在热工作范围窄和存在滞后回线方面的固有局限性，以提高其热敏性能。

Method: 通过固态法和 Pechini 法合成 LaGaO3:Eu3+ 荧光粉，并研究粒径分布、Al3+ 和 Sc3+ 共掺杂对荧光粉热敏性能的影响。

Result: 通过固态法得到的 LaGaO3:Eu3+ 相对热灵敏度达到 18.2% K-1，高于 Pechini 法制备的 3.0% K-1。掺杂 Al3+ 和 Sc3+ 可以将相变温度在 165 K 至 491 K 之间连续调谐，且不显著影响 Eu3+ 的低温光谱性质。

Conclusion: 通过控制 LaGaO3:Eu3+ 荧光粉的粒径和掺杂 Al3+、Sc3+ 离子，可以显著提高其作为发光温度计的热敏性能，包括提高相对热灵敏度和减小滞后回线。该研究还建立了相变温度与离子半径失配参数之间的经验关系，为设计具有特定热响应范围和传感性能的发光温度计提供了理论指导。

Abstract: Phase-transition-based luminescent thermometers are characterized by two
inherent limitations: a narrow thermal operating range and the presence of a
hysteresis loop in the thermometric parameter. In this work, we demonstrate
that controlling the particle size of LaGaO3:Eu3+ phosphors enables significant
enhancement of thermometric performance. Specifically, a reduction in grain
size dispersion leads to an increase in relative thermal sensitivity and
significantly narrows the hysteresis loop. As a result of this approach, the
relative sensitivity was increased to 18.2% K-1 for LaGaO3:Eu3+ synthesized via
the solid-state method, compared to 3.0% K-1 for the counterpart prepared using
the Pechini method. Furthermore, we show that the intentional incorporation of
Al3+ and Sc3+ co-dopant ions allows for continuous tuning of the structural
phase transition temperature from 165 K for 15% Al3+ to 491 K for 2% Sc3+,
without significantly affecting the low-temperature spectroscopic properties of
Eu3+ ions. This ability to shift the phase transition temperature in LaGaO3
offers a practical route to modulate the thermal response range of the
luminescent thermometer, enabling its adaptation to specific application
requirements. The empirical relationship established in this study between the
phase transition temperature and the ionic radius mismatch parameter provides a
predictive tool for the rational design of phase-transition-based phosphors
with tailored thermometric performance. The ability to systematically tune the
phase transition temperature via ionic radius mismatch, together with enhanced
thermometric performance resulting from reduced grain size dispersion,
establishes a coherent strategy for the rational design of high-sensitivity,
low-hysteresis thermal sensors.

</details>


### [320] [Improving structure search with hyperspatial optimization and TETRIS seeding](https://arxiv.org/abs/2507.13791)
*Daviti Gochitashvili,Maxwell Meyers,Cindy Wang,Aleksey N. Kolmogorov*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究将超空间结构全局优化（GOSH）方法扩展到更精确的神经网络势，并评估了其在纳米粒子和晶体固体上的性能。结果表明，虽然四维优化在某些方面（如纳米合金的原子交换）有优势，但计算成本增加；而引入偏差以生成更合理的起始构型则更有效地提高了全局结构搜索的效率。


<details>
  <summary>Details</summary>
Motivation: 过去的几十年里，先进的结构预测方法包括一种非传统的策略，即允许原子置换到额外的维度。最近实现的超空间结构全局优化（GOSH）在加速识别势能表面上的全局最小值方面显示出潜力。

Method: 本研究将GOSH形式主义扩展到更精确的Behler-Parrinello神经网络势，并使其与有效的局部最小化算法兼容，然后在纳米粒子和晶体固体上测试其性能。我们还评估了通过受TETRIS启发的原子块打包实现的、用于生成更符合物理实际的起始构型的适度受控偏差。

Result: 对于具有神经网络势的模型簇，四维优化在几何弛豫路径导航方面提供的改进相当有限，而计算成本的增加却抵消了其带来的好处。然而，在促进纳米合金中的原子交换方面，四维优化具有显著优势。相比之下，通过TETRIS启发的原子块打包实现的、用于生成更符合物理实际的起始构型的偏差，对全局结构搜索的效率有更直接的影响。

Conclusion: 与简单的原子模型相比，在更精确的Behler-Parrinello神经网络势中，四维优化在几何弛豫路径导航方面仅带来适度的改进，并且计算成本的增加很大程度上抵消了其优势。然而，它在促进纳米合金中的原子交换方面提供了显著优势。相比之下，通过受TETRIS启发的原子块打包实现的、用于生成更符合物理实际的起始构型的适度受控偏差，对全局结构搜索的效率产生了更直接的影响。

Abstract: Advanced structure prediction methods developed over the past decades include
an unorthodox strategy of allowing atoms to displace into extra dimensions. A
recently implemented global optimization of structures from hyperspace (GOSH)
has shown promise in accelerating the identification of global minima on
potential energy surfaces defined by simple interatomic models. In this study,
we extend the GOSH formalism to more accurate Behler-Parrinello neural network
(NN) potentials, make it compatible with efficient local minimization
algorithms, and test its performance on nanoparticles and crystalline solids.
For clusters modeled with NN potentials, four-dimensional optimization offers
fairly modest improvement in navigating geometric relaxation pathways and
incurs increased computational cost largely offsetting the benefit, but it
provides a significant advantage in facilitating atom swaps in nanoalloys. In
comparison, the introduction of a moderate, controlled bias for generating more
physically sensible starting configurations, achieved via TETRIS-inspired
packing of atomic blocks, has a more direct impact on the efficiency of global
structure searches. The benchmarked systems are Lennard-Jones clusters, Au or
Cu-Pd-Ag nanoparticles and binary Sn alloys described by NN potentials, and
compounds with covalent B or BC frameworks modeled with density functional
theory

</details>


### [321] [Extension of Second-Principles Density Functional Theory into the time domain](https://arxiv.org/abs/2507.13824)
*Toraya Fernández-Ruiz,Jorge Íñiguez,Javier Junquera,Pablo García-Fernández*

Main category: cond-mat.mtrl-sci

TL;DR: SPDFT方法可用于大规模材料的光学和传输性质计算。


<details>
  <summary>Details</summary>
Motivation: 为了对非常大的系统（数万个原子）进行时间依赖性模拟，并确定其光学和传输性质。

Method: SPDFT方法通过在实时间和实空间中使用Liouville-von Neumann方程计算密度矩阵的演化。

Result: SPDFT方法可以应用于包括金属和绝缘体在内的多种材料，在金刚石和金属锂方面比线性微扰理论有显著改进，可以预测德鲁德峰。

Conclusion: SPDFT方法可以应用于金属和绝缘体，并且在金刚石和金属锂方面比线性微扰理论有显著改进，可以用于计算光谱和传输性质。

Abstract: We present an extension of the second-principles density functional theory
(SPDFT) method to perform time-dependent simulations. Our approach, which
calculates the evolution of the density matrix in real time and real space
using the Liouville-von Neumann equation of motion, allows determining optical
and transport properties for very large systems, involving tens of thousands of
atoms, using very modest computational platforms. In contrast with other
methods, we show that SPDFT can be applied to a wide variety of materials
including both metals and insulators. In particular, we illustrate its
capabilities by obtaining the spectra of SrTiO$_3$, diamond and metallic
lithium. We find that, while SPDFT results in SrTiO$_3$ are quite similar to
those obtained from DFT using linear perturbation theory, we observe
significant improvements over this method in both diamond and metallic lithium.
The inclusion of electron-electron interactions during the evolution of the
density matrix in diamond allows the spectra to more closely resemble those
obtained with the Bethe-Salpeter equation than from perturbation theory. In
lithium time-dependent SPDFT not only predicts interband transitions but also
the Drude peak, opening the possibility of detailed ab initio studies of
transport properties beyond many of the usual approximations.

</details>


### [322] [Real time observation of glass-like carbon formation from SU-8 using X-ray and ultraviolet photoelectron spectroscopy](https://arxiv.org/abs/2507.14053)
*Simon Astley,Jaspa Stritt,Soumen Mandal,Jerome A. Cuenca,D. Andrew Evans,Oliver A. Williams*

Main category: cond-mat.mtrl-sci

TL;DR: 通过XPS/UPS分析SU-8光刻胶热解过程，发现其在500°C以上会转变为类玻璃碳，并伴随电导率增加。


<details>
  <summary>Details</summary>
Motivation: 研究SU-8光刻胶在热解过程中向类玻璃碳转变的结构和元素组成变化，特别是电导率的变化，以理解该过程的机理。

Method: 使用X射线和紫外光电子能谱（XPS/UPS）在超高真空（UHV）条件下，研究SU-8 3005光刻胶在高达1000°C热解过程中结构和元素组成向类玻璃碳的转变。通过分析C 1s光谱的峰不对称性、氧含量以及UPS测量的二次电子切断（SECO）和价带最大值（VBM）来追踪这些变化。

Result: SU-8光刻胶经过500°C以上热解后，其材料结构和组成向富碳导电网络转变，形成了类似玻璃的碳。C 1s光谱的峰不对称性、氧含量和峰位置的变化，以及UPS测量的SECO和VBM的变化，都与XPS数据相关，并在1000°C时观察到零结合能态。

Conclusion: SU-8在高达1000°C的热解过程中，其结构和元素组成会转变为类似玻璃的碳，并伴随着电导率的增加，这可以通过XPS/UPS光谱的变化得到证实。

Abstract: The structural development and change in elemental composition of SU-8 3005
photoresist into glass-like carbon due to pyrolysis up to 1000~$\degree$C is
investigated utilising \textit{in-situ} x-ray and ultraviolet photoelectron
spectroscopy (XPS/UPS) under ultra-high vacuum (UHV). XPS spectra were analysed
in order to investigate changes to elemental composition and physical
structure. Peak asymmetry in the measured C 1s spectra is found to be a clear
indicator of a transition in both physical structure and increased electrical
conductivity. The \textit{in-situ} XPS measurement of pyrolysis is effective in
isolating changes in oxygen composition solely due to the pyrolysis process.
Oxygen concentration, C 1s peak asymmetry and C 1s peak positions are strong
indicators of semiconducting SU-8 transitioning to conducting glass-like
carbon. For SU-8 pyrolysed above temperatures of 500~$\degree$C, a clear
development is observed in the material structure and composition towards a
carbon rich conducting network indicative of glass-like carbon. UPS spectra
were analysed to investigate the changes in secondary electron cut-off (SECO)
and valence band maximum (VBM) as the SU-8 layer is heated in UHV. The changes
in SECO and VBM correlates well with the XPS data and a zero binding energy
state is observed at 1000~$\degree$C.

</details>


### [323] [Ex Situ Fabrication of Superconducting Nanostructures for Low-Temperature STM](https://arxiv.org/abs/2507.14092)
*Adrian Greichgauer,Roozbeh Yazdanpanah,Alexey Taskin,Oliver Breunig,Yoichi Ando,Jens Brede*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Nanofabrication enables flexible experimental design but is often
incompatible with scanning tunneling microscopy and spectroscopy (STM/STS) due
to the latter's stringent surface quality requirements. Here, we present a
fabrication strategy that combines ex situ nanolithography with in situ
ultrahigh-vacuum (UHV) cleaving to produce atomically clean, nanopatterned
superconductor/topological insulator (TI) heterostructures suitable for
high-resolution STM/STS. In our initial Design I, nanoribbons were defined by
etching trenches into a TI film, followed by niobium capping and sample
flipping before cleaving. This enabled STM/STS to be applied in large areas,
although edge quality was limited by etch debris. To overcome this, we
developed Design II, which avoids etching through the film by locally thinning
it, leaving nanoscale ribbons raised above a continuous TI layer, followed
again by Nb capping and sample flipping before cleaving. This method yields
clean, reproducible nanostructures with well-defined superconducting gaps,
demonstrating a reliable fabrication pathway for high-resolution STM/STS
studies of nanoscale topological devices.

</details>


### [324] [Spatiotemporal Order and Parametric Instabilities from First-Principles](https://arxiv.org/abs/2507.14110)
*Daniel Kaplan,Pavel A. Volkov,Jennifer Coulter,Shiwei Zhang,Premala Chandra*

Main category: cond-mat.mtrl-sci

TL;DR: 我们展示了一种利用光诱导时空参量不稳定性来控制晶体结构的方法，适用于手征晶体、铁电体和层状范德华材料，并为设计时间晶体序提供了途径。


<details>
  <summary>Details</summary>
Motivation: 利用光来塑造晶体结构是物理学和材料工程中一个持久的目标。

Method: 我们提出了一个理论框架，包括对所有非中心对称点群中影响参量不稳定的声子模式的完整对称性分析，对材料格局的详细调查，以及从第一性原理计算非线性耦合。

Result: 我们展示了手征晶体、铁电体和层状范德华材料的详细结果。

Conclusion: 我们的研究为在量子材料中实现设计的时间晶体序铺平了道路，该序可以通过时间分辨衍射探针进行检测。

Abstract: Shaping crystal structure with light is an enduring goal of physics and
materials engineering. Here we present calculations in candidate materials
selected by symmetry that allow light-induced spatiotemporal parametric
instabilities. We demonstrate a theoretical framework that includes a complete
symmetry analysis of phonon modes that contribute to parametric instabilities
across all non-centrosymmetric point groups, a detailed survey of the materials
landscape and finally the computation of nonlinear couplings from first
principles. We then showcase detailed results for chiral crystals,
ferroelectrics, and layered van der Waals materials. Our results pave the way
towards realizing designer time-crystalline order in quantum materials,
detectable with time-resolved diffractive probes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [325] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT是一种基于图的新型LLM架构，通过并行处理和优化的任务协调，提高了交通管理的效率，降低了成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于链式的大型语言模型（LLM）交通管理系统（如TrafficGPT）在顺序任务执行、高令牌使用率和可扩展性方面的不足，这些问题导致在复杂现实场景下的效率低下。

Method: 提出了一种名为GraphTrafficGPT的新型基于图的架构，其中任务和依赖关系被表示为有向图的节点和边。该架构包含一个“大脑代理”，负责分解用户查询、构建优化的依赖图，并协调专门的代理（如数据检索、分析、可视化和模拟代理）。通过引入上下文感知令牌管理和支持并发多查询处理，实现了高效的任务协调。

Result: 与TrafficGPT相比，GraphTrafficGPT将令牌消耗降低了50.2%，平均响应延迟降低了19.0%，同时在并发多查询执行方面效率提高了23.0%。

Conclusion: GraphTrafficGPT通过基于图的架构有效解决了现有链式LLM交通管理系统的局限性，在降低令牌消耗和响应延迟方面表现出色，并支持并发多查询执行。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [326] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette通过将偏好分解为属性维度并考虑社区价值观，在Reddit社区中实现了比GPT-4o高46.6%的预测准确性，并提供了可解释的见解。


<details>
  <summary>Details</summary>
Motivation: 当前偏好模型将人类判断视为黑箱，无法理解用户偏好的根本原因，因此需要一种能够分解偏好并以人类可解释的方式进行定制的框架。

Method: PrefPalette框架通过分解偏好为属性维度，并利用反事实属性合成和基于注意力的偏好模型来捕捉不同社会社区对这些属性的动态权重，从而实现人类可解释的偏好预测。

Result: PrefPalette在45个Reddit社区中的平均预测准确性比GPT-4o高出46.6%，并揭示了特定社区的偏好模式（例如，学术社区重视详细和启发性，冲突导向社区重视讽刺和直接，支持性社区重视共情）。

Conclusion: PrefPalette通过为个性化AI提供可解释的、由属性驱动的偏好预测，弥合了AI偏好建模与人类判断的差距，从而提高了预测准确性并促进了对不同社会群体评估框架的理解。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [327] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLM和Prolog的混合方法，用于构建可靠、可解释的专家系统。通过结构化提示提取知识并转换为Prolog，可由专家验证，解决了LLM的幻觉问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在生成看似连贯的信息方面取得了巨大成功，但其缺点也日益显现，例如产生幻觉或自信地生成不正确或无法验证的事实。为了克服这些挑战，本研究旨在开发一种新的方法，能够以受控和透明的方式利用LLM构建专家系统，确保其可靠性和可解释性。

Method: 本文提出了一种新的专家系统开发方法，利用大型语言模型（LLM）进行受控和透明的知识提取。具体而言，该方法首先限制LLM的处理领域，然后采用结构化的提示（prompt-based）提取知识，最后将提取的知识转换为Prolog中的符号表示。这种符号表示可以由人类专家进行验证和纠正，从而确保了系统的可解释性、可扩展性和可靠性。

Result: 通过使用Claude Sonnet 3.7和GPT-4.1进行的定量和定性实验，证明了该方法生成的知识库在事实遵循和语义连贯性方面具有很强的优势。该混合解决方案结合了LLM的记忆能力和符号系统的精确性，为在敏感领域开发可靠的AI应用奠定了基础。

Conclusion: 本文提出了一种将大型语言模型（LLM）与符号系统相结合的混合方法，用于构建可解释、可扩展且可靠的专家系统。该方法通过限制LLM的领域并采用基于提示的提取技术，将知识转换为Prolog中的符号表示，以便人类专家进行验证和纠正。实验结果表明，该方法在事实准确性和语义连贯性方面表现出色，为在敏感领域开发可靠的AI应用奠定了基础。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [328] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: AI 应该从像素和单词转向实体和关系，但关系学习需要更多发展才能普及。


<details>
  <summary>Details</summary>
Motivation: 当前的 AI 模型主要关注像素和单词，而忽略了世界是由具有属性和关系的实体组成的这一事实。最有价值的数据通常是关系型数据，但目前在 AI 领域并未得到充分研究。

Method: 解释了关系学习未被广泛采用的原因，并提出了使其获得广泛应用的方法。

Result: 关系学习在少数受限关系的情况下取得了成功，但尚未普及。需要进一步的研究和发展才能使其发挥应有的作用。tldr: AI 应该从像素和单词转向实体和关系，但关系学习需要更多发展才能普及。

Conclusion: AI 应该专注于建模实体及其关系，而不是仅限于像素和单词。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [329] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: BifrostRAG是一种新的双图RAG系统，通过结合实体关系和文档结构，提高了在复杂法规文本上进行信息检索和问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 目前的合规性检查系统在处理法规文本的语言和结构复杂性方面存在挑战，特别是对于需要跨越多个相互关联条款综合信息的复杂查询。

Method: 提出了一种名为BifrostRAG的双图RAG集成系统，该系统显式地对语言关系（通过实体网络图）和文档结构（通过文档导航器图）进行建模。该架构支持一种混合检索机制，结合了图遍历和基于向量的语义搜索，使大型语言模型能够推理文本的含义和结构。

Result: 在多跳问答数据集上的评估显示，BifrostRAG实现了92.8%的精确率，85.5%的召回率，以及87.3%的F1分数，显著优于仅基于向量或仅基于图的RAG基线方法。

Conclusion: BifrostRAG是一个强大的知识引擎，能够实现LLM驱动的合规性检查。其双图混合检索机制为跨知识密集型工程领域导航复杂技术文档提供了一个可转移的蓝图。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [330] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 通过自动补全和诊断学生步骤的解法，可以有效解决智能辅导系统中因学生合并步骤而导致的错误诊断困难问题。


<details>
  <summary>Details</summary>
Motivation: 在智能辅导系统中，当学生将多个步骤合并为一个时，错误诊断变得困难，因为可能存在大量的路径。本研究旨在解决这个问题。

Method: 本研究提出了一种新的服务设计，通过自动完成学生的中间步骤，并诊断该补全后的解法来解决错误诊断中的组合爆炸问题。

Result: 该方法能够诊断现有服务无法诊断的学生步骤的29.4%，并且与教师诊断的一致性达到97%。

Conclusion: 本研究提出了一种基于最终答案的自动化错误诊断方法，并将其应用于二次方程求解任务，验证了其有效性。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [331] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 提出了一种结合时间逻辑和约束逻辑的ASP新方法，用于解决具有精细时间/数字分辨率的动态系统推理问题。


<details>
  <summary>Details</summary>
Motivation: 解决基于逻辑的方法（如ASP）在具有精细时间与数字分辨率的动态系统方面存在的挑战。

Method: 提出并阐述了一种新颖的、基于时间的和约束的“这里和那里”逻辑扩展及其非单调平衡扩展，这是第一个针对ASP的非单调时间推理与约束相结合的方法。

Result: 一个既能进行鲁棒的非单调时间推理，又能直接集成和操作数字约束的表达系统。

Conclusion: 该研究为在ASP范例中处理高分辨率的复杂动态系统奠定了基础逻辑框架。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [332] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 本研究结合模型追踪与约束模型，提出了一种新的学生解题步骤诊断方法，能够处理学生合并步骤的情况。实验结果表明，该方法在诊断准确性上与教师水平相当。


<details>
  <summary>Details</summary>
Motivation: 为了改进学生在分步任务中的输入诊断，研究者们提出了将模型追踪和约束模型相结合的方法，以应对学生可能合并多个解题步骤的情况，从而提供更全面的诊断。

Method: 本研究提出了一种融合模型追踪和约束模型的方法，通过将约束定义为学生输入与策略步骤的共同属性，实现了对学生多步策略的诊断。研究中设计了一个系统来实现多步策略诊断，并使用包含学生解二次方程步骤的数据集（n=2136）进行了验证。

Result: 实验结果显示，在对包含70个学生步骤的随机样本（包括偏离策略和应用策略的情况）进行分析时，该系统生成的诊断与两位教师的编码结果在所有140个学生步骤上均保持一致。

Conclusion: 本研究提出的融合模型追踪和约束模型的方法，能够对学生的多步解题策略进行诊断，并且在学生合并多个步骤时也能提供准确的诊断。实验结果表明，该系统诊断与教师评分高度一致，证明了该方法的有效性。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [333] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个利用智能手机和智能手表传感器数据的活动日志生成系统，通过多维度上下文信息和轻量级LLM框架，提高了日志生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的活动日志生成方法在准确性、效率和语义丰富性方面存在局限性。

Method: DailyLLM框架集成了结构化提示和高效特征提取，以实现高级活动理解。

Result: DailyLLM在日志生成方面取得了17%的BERTScore精度提升，并实现了近10倍的推理速度提升，优于基于70B参数的SOTA基线模型。

Conclusion: DailyLLM是一个集成了位置、运动、环境和生理信息的多维度上下文的活动日志生成和摘要系统。它使用一个轻量级的基于LLM的框架，通过结构化提示和高效的特征提取来实现高级活动理解。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [334] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: OntView is an open-source ontology viewer that solves the problem of poor visualization in existing tools. It offers an intuitive interface, visualizes inferred knowledge including GCIs, and provides simplification features to manage complexity, making ontologies easier to understand.


<details>
  <summary>Details</summary>
Motivation: The motivation behind OntView is to address the significant challenge posed by the lack of effective visualization tools for ontologies. Existing tools often fail to graphically represent ontology structures in a meaningful and non-overwhelming way, hindering users' comprehension of dependencies and properties within large ontological frameworks.

Method: OntView is an ontology viewer that utilizes a DL reasoner to provide a "What you see is what you meant" paradigm, visualizing inferred knowledge, including General Concept Inclusions (GCI). It offers simplification methods such as creating concept summaries based on importance algorithms, focusing visualizations on TBox elements between classes, and allowing dynamic hiding/showing of branches.

Result: OntView provides users with an intuitive visual representation of ontology concepts and their formal definitions through a user-friendly interface. It uniquely visualizes General Concept Inclusions (GCI) and offers simplification methods to manage information overload, making it easier for users to comprehend complex ontologies.

Conclusion: OntView provides an intuitive visual representation of ontology concepts and their formal definitions through a user-friendly interface, addressing the challenge of effective ontology visualization by incorporating features like GCI visualization and various simplification methods to manage information overload. It has been released under an open-source license.

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [335] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: 该研究提出了CUDA-L1，一个利用强化学习自动优化CUDA内核的框架，在各种GPU上实现了显著的性能提升，并展示了其跨内核的泛化能力和发现新优化技术的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）的快速发展，对GPU计算资源的需求呈指数级增长，因此迫切需要自动化的CUDA优化策略。尽管最近LLM在代码生成方面取得了进展，但目前的SOTA模型在提高CUDA速度方面成功率较低。

Method: 本研究介绍了一个名为CUDA-L1的自动化强化学习框架，用于CUDA优化。

Result: CUDA-L1在CUDA优化任务上实现了性能改进。在NVIDIA A100上训练后，该模型在KernelBench的250个CUDA内核上平均实现了17.7倍的加速，峰值加速达到449倍。此外，该模型在GPU架构之间表现出优良的可移植性，在H100上实现了17.8倍的平均加速，在RTX 3090上实现了19.0倍，在L40上实现了16.5倍，在H800上实现了14.7倍，在H20上实现了13.9倍，尽管它是专门为A100优化的。

Conclusion: 该研究展示了强化学习（RL）如何仅通过基于加速的奖励信号，在没有人类专业知识或领域知识的情况下，将最初性能不佳的大型语言模型（LLM）转变为有效的CUDA优化器。训练好的RL模型能够将获得的推理能力扩展到新的内核，为CUDA操作的自动化优化开辟了可能性，并有望显著提高GPU效率和缓解GPU计算资源日益增长的压力。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


### [336] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: A new hybrid architecture for strategic reasoning combines heuristics using semantic interdependence and rhetorical framing to create context-sensitive narratives, demonstrated with a Meta vs. FTC case study.


<details>
  <summary>Details</summary>
Motivation: To develop an agent-augmented strategic reasoning system that fuses conflicting heuristics into coherent and context-sensitive narratives, unlike traditional decision engines that select the best rule.

Method: A hybrid architecture combining heuristic extraction, semantic activation, and compositional synthesis, inspired by quantum cognition and utilizing semantic interaction modeling and rhetorical framing.

Result: The system fuses conflicting heuristics into coherent and context-sensitive narratives, demonstrated via a Meta vs. FTC case study with preliminary validation through semantic metrics.

Conclusion: The framework is demonstrated via a Meta vs. FTC case study, with preliminary validation through semantic metrics. Limitations and extensions are discussed.

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [337] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: EAGLE是一个轻量级的时间图神经网络框架，通过整合短期和长期模式，在保持高效率的同时提高了预测性能，并且速度比现有方法快50倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有的时间图神经网络（T-GNNs）虽然在建模时间与结构依赖性方面取得了成功，但由于高计算开销而面临可扩展性和效率问题。因此，有必要开发一种更轻量级的框架。

Method:  EAGLE框架整合了短期时间邻近性和长期全局结构模式。它包括一个时间感知模块，该模块聚合节点最近邻居的信息以反映其直接偏好；一个结构感知模块，它利用时间个性化PageRank来捕获全局重要节点的影响；以及一个自适应加权机制来平衡这些属性。EAGLE无需复杂的多跳消息传递或内存密集型机制，从而显著提高了效率。

Result: EAGLE框架在七个真实世界的时间图上进行了广泛的实验，结果表明，与最先进的T-GNNs相比，EAGLE在有效性和效率方面始终表现出卓越的性能，并且比基于Transformer的T-GNNs的速度提高了50倍以上。

Conclusion: EAGLE框架在七个真实世界的时间图上进行了广泛的实验，结果表明，与最先进的T-GNN相比，EAGLE在有效性和效率方面始终表现出卓越的性能，并且比基于Transformer的T-GNNs的速度提高了50倍以上。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [338] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 因果知识迁移框架在多智能体强化学习中，通过零样本迁移恢复动作宏，显著提高了智能体适应非平稳环境的能力，尤其在目标异构的情况下效果显著，但迁移效果受环境复杂性影响。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体强化学习（MARL）在非平稳和目标多变的环境中知识迁移的挑战。传统的知识迁移方法泛化能力不足，且需要昂贵的重新训练，而本研究旨在实现更高效、自适应的知识迁移。

Method: 提出了一种因果知识迁移框架，通过将每次碰撞建模为因果干预，并将其实例化为恢复动作序列（宏），以实现零样本迁移。该框架利用查找模型，根据局部上下文信息（碰撞）查询并应用恢复动作宏，从而在不重新训练的情况下适应环境变化。

Result: 研究发现，采用因果知识迁移框架的智能体在适应新环境时，能够弥合随机探索与完全重新训练策略之间约一半的差距。此外，因果知识迁移的效果与环境复杂性以及智能体目标异构性之间的相互作用密切相关。

Conclusion: 本研究提出的因果知识迁移框架能够使智能体在非平稳环境中进行知识迁移，适应新环境的效率较随机探索提高了约一倍，接近完全重新训练的策略。迁移效果受环境复杂度和智能体异构目标等因素的共同影响。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [339] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: LLM 难以产生新颖且相关的想法。本研究提出了一种模型无关的潜在空间构思框架，无需手工规则即可实现可控、可扩展的创造力，并易于适应不同领域和任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在产生新颖且相关的输时常面临挑战，它们倾向于复制训练中的模式，限制了它们在没有广泛提示工程的情况下进行创造性发散的能力。

Method: 提出一个与模型无关的潜在空间构思框架，通过导航思想的连续嵌入空间来实现可控、可扩展的创造力。

Result: 提出了一个早期原型，概述了概念框架和初步结果，强调了其作为通用联合构思器的潜力。

Conclusion: 该框架有潜力成为人机协作的通用联合构思器。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [340] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 提出了一种结合因果推理和多模态学习的AD诊断新方法ADPC，使用LLM处理临床文本，结合MRI/fMRI图像进行分类，能有效处理混淆变量，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期识别和干预至关重要，但由于多模态数据选择偏差和变量间复杂关系等混淆因素，其诊断仍然是一个重大挑战。

Method: 提出了一种名为ADPC（Alzheimer's Disease Prediction with Cross-modal Causal Intervention）的新型视觉-语言因果干预框架，利用大型语言模型（LLM）总结临床数据，并结合MRI、fMRI图像和文本数据对参与者进行分类（认知正常CN、轻度认知障碍MCI、阿尔茨海默病AD）。该框架通过因果干预消除混淆变量（如神经影像伪影和与年龄相关的生物标志物），避免非因果模型可能产生的虚假相关性。

Result: ADPC在区分CN/MCI/AD病例方面表现出卓越的性能，在大多数评估指标上达到了最先进（SOTA）的水平。

Conclusion: 通过因果推理与多模态学习的结合，为神经系统疾病的诊断提供了新的潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [341] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA是一个创新的本体匹配框架，利用LLMs和RAG技术，通过知识检索和本体精炼来提高匹配性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有本体匹配系统依赖手工规则或专业模型，适应性有限。KROMA旨在通过利用LLMs和RAG来解决这一挑战，以动态丰富语义上下文。

Method: KROMA框架利用大型语言模型（LLMs）和检索增强生成（RAG）技术，通过集成基于双相似性的概念匹配和轻量级本体精炼来动态丰富本体匹配任务的语义上下文，从而优化性能和效率。

Result: 实验结果表明，将知识检索与上下文增强的LLMs相结合，显著提高了本体匹配的性能，优于传统系统和先进的LLM方法，且通信开销相当。

Conclusion: KROMA框架通过结合检索增强生成（RAG）和大型语言模型（LLMs），并集成基于双相似性的概念匹配和轻量级本体精炼步骤，显著提高了本体匹配的性能和效率，超越了传统方法和先进的LLM方法，同时保持了可比较的通信开销。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [342] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: 该研究发布了一个名为 Glucose-ML 的糖尿病数据集集合，包含 10 个公开数据集，旨在解决 AI 开发中的数据瓶颈问题。研究通过比较分析和血糖预测基准测试，揭示了不同数据集对 AI 模型性能的影响，并为开发更可靠的健康 AI 提供了建议。


<details>
  <summary>Details</summary>
Motivation: 为了加速开发透明、可复现和鲁棒的 AI 解决方案，但目前缺乏高质量、大规模的数据集是阻碍糖尿病管理领域 AI 解决方案发展的关键瓶颈。

Method: 本研究提出并整理了一个名为 Glucose-ML 的数据集集合，该集合包含 10 个在过去 7 年内（2018-2025）发布的、公开可用的糖尿病数据集。数据集覆盖了超过 300,000 天的连续血糖监测（CGM）数据，共计 3800 万个血糖样本，来自 4 个国家的 2500 多名参与者，涵盖了 1 型糖尿病、2 型糖尿病、糖尿病前期和非糖尿病人群。此外，研究进行了比较分析以指导数据选择，并以血糖预测任务为案例，对 Glucose-ML 集合中的所有数据集进行了短期血糖预测的基准测试。

Result: 研究表明，相同的 AI 算法在不同数据集上可能产生显著不同的预测结果。通过对 Glucose-ML 集合中的 10 个数据集进行短期血糖预测的基准测试，为该领域常见的 AI 任务提供了性能参考，并为开发更鲁棒的 AI 解决方案提供了指导性建议。

Conclusion: 该研究提出了 Glucose-ML 数据集，包含 10 个公开的糖尿病数据集，旨在促进透明、可复现和鲁棒的 AI 解决方案的开发。研究通过比较分析指导算法开发者进行数据选择，并通过对血糖预测任务的案例研究，为 Glucose-ML 集合中的所有 10 个数据集提供了短期血糖预测基准。研究结果表明，相同的算法在不同数据集上可能产生显著不同的预测结果，并基于这些发现为开发糖尿病或更广泛健康领域的鲁棒 AI 解决方案提供了建议。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [343] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: G-AI-HMS通过结合大型语言模型和计算机视觉技术，显著提高了人力运动模拟的准确性和真实性，特别是在处理复杂的工业任务描述和运动生成方面。


<details>
  <summary>Details</summary>
Motivation: 现有的HMS方法在运动保真度方面存在不足，难以满足对工人行为、安全性和生产力进行经济高效评估的需求。因此，有必要开发一种能够提高模拟质量的新方法。

Method: 本研究提出了G-AI-HMS（Generative-AI-Enabled HMS），该方法整合了文本到文本和文本到运动模型。具体而言，利用大型语言模型将任务描述转化为运动感知语言，并使用计算机视觉技术（姿态估计算法）提取的真实人体运动关节标志点来验证AI增强的运动。通过运动相似性指标比较AI生成的序列与真实人体运动。

Result: G-AI-HMS在涉及八项任务的案例研究中，AI增强的运动在大多数场景下比手动创建的描述展现出更低的误差。在空间准确性方面，AI增强的运动在六项任务中表现更好；在姿态归一化后对齐方面，在四项任务中表现更好；在整体时间相似性方面，在七项任务中表现更好。统计分析表明，AI增强的提示在统计学上显著（p < 0.0001）降低了关节误差和时间错位，同时保持了相当的姿态准确性。

Conclusion: G-AI-HMS通过整合文本到文本和文本到运动模型，显著提高了工业任务中人力运动模拟的保真度，并在大多数场景下优于手动创建的描述，在空间准确性、姿态归一化后对齐和整体时间相似性方面均表现出改进。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [344] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: LLM在桥梁NDE数据分析中展现出提高效率和准确性的潜力，ChatGPT-4和Claude 3.5 Sonnet表现尤为出色。


<details>
  <summary>Details</summary>
Motivation: 传统的NDE数据解读耗时且需要专业知识，可能延误决策过程。LLM的出现为自动化和改进NDE数据分析提供了新的途径，旨在提高桥梁维护和安全评估的效率与准确性。

Method: 本研究探索了多种大型语言模型（LLM）在解读桥梁NDE（无损检测）轮廓图方面的能力。研究人员设计了特定的提示词，用于提升图像描述的质量，并将这些描述应用于解读五种不同的NDE轮廓图。通过评估模型生成详细描述、识别缺陷、提供可行建议以及整体准确性的能力，来衡量模型的表现。研究还对部分LLM生成的高质量图像描述进行了总结，并进一步由其他LLM进行综合概述。

Result: 研究发现，在九个测试的LLM模型中，有四个模型在生成详细图像描述方面表现更优，能够涵盖桥梁状况的广泛信息。其中，ChatGPT-4和Claude 3.5 Sonnet在生成总结性描述方面表现尤为突出。LLM辅助分析在不牺牲准确性的前提下，显著提高了评估效率。

Conclusion: LLM在桥梁检测中的应用，特别是针对NDE（无损检测）数据的分析，显示出巨大潜力，能够提高效率和准确性，从而加快决策过程，改善基础设施管理和安全评估。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [345] [CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education](https://arxiv.org/abs/2507.13814)
*Jianing Zhao,Peng Gao,Jiannong Cao,Zhiyuan Wen,Chen Chen,Jianing Yin,Ruosong Yang,Bo Yuan*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) have demonstrated considerable potential in
improving coding education by providing support for code writing, explanation,
and debugging. However, existing LLM-based approaches generally fail to assess
students' abilities, design learning plans, provide personalized material
aligned with individual learning goals, and enable interactive learning.
Current work mostly uses single LLM agents, which limits their ability to
understand complex code repositories and schedule step-by-step tutoring. Recent
research has shown that multi-agent LLMs can collaborate to solve complicated
problems in various domains like software engineering, but their potential in
the field of education remains unexplored. In this work, we introduce CodeEdu,
an innovative multi-agent collaborative platform that combines LLMs with tool
use to provide proactive and personalized education in coding. Unlike static
pipelines, CodeEdu dynamically allocates agents and tasks to meet student
needs. Various agents in CodeEdu undertake certain functions specifically,
including task planning, personalized material generation, real-time QA,
step-by-step tutoring, code execution, debugging, and learning report
generation, facilitated with extensive external tools to improve task
efficiency. Automated evaluations reveal that CodeEdu substantially enhances
students' coding performance.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [346] [Neural Architecture Search with Mixed Bio-inspired Learning Rules](https://arxiv.org/abs/2507.13485)
*Imane Hamzaoui,Riyadh Baghdadi*

Main category: cs.NE

TL;DR: 通过使用神经架构搜索（NAS）为不同层选择不同的受生物启发的学习规则，可以提高神经网络的准确性和可扩展性，并缩小其与反向传播（BP）模型之间的差距。


<details>
  <summary>Details</summary>
Motivation: 为了克服受生物启发的神经网络在准确性和可扩展性方面落后于基于反向传播（BP）的模型的问题，同时保留其在对抗鲁棒性和能效方面的优势。

Method: 提出了一种结合神经架构搜索（NAS）和受生物启发的学习规则的方法。NAS程序被定制用于搜索能够应用于不同层的受生物启发的学习规则。通过扩大搜索空间以包含这些学习规则，并利用NAS来确定每层的最佳架构和学习规则，从而实现了这一目标。

Result: 在CIFAR-10上达到95.16%的准确率，在CIFAR-100上达到76.48%，在ImageNet16-120上达到43.42%，以及60.51%的ImageNet top-1准确率。这些结果创下了受生物启发的模型的新纪录，并在某些情况下超越了同等的BP模型，同时保持了其鲁棒性优势。

Conclusion: 允许不同层使用不同的受生物启发的学习规则，并通过神经架构搜索（NAS）进行自动发现，可以弥补生物启发神经网络在准确性和可扩展性方面与反向传播（BP）模型之间的差距。研究表明，在不同层中使用不同学习规则的神经网络比在所有层中使用单一规则的神经网络具有更好的准确性。这种方法在CIFAR-10、CIFAR-100和ImageNet等数据集上取得了新的记录，并且在某些情况下超过了同等的BP模型，同时保留了鲁棒性优势。这表明学习规则的层级多样性有助于提高可扩展性和准确性，并鼓励对在同一网络中混合多种受生物启发的学习规则进行进一步研究。

Abstract: Bio-inspired neural networks are attractive for their adversarial robustness,
energy frugality, and closer alignment with cortical physiology, yet they often
lag behind back-propagation (BP) based models in accuracy and ability to scale.
We show that allowing the use of different bio-inspired learning rules in
different layers, discovered automatically by a tailored
neural-architecture-search (NAS) procedure, bridges this gap. Starting from
standard NAS baselines, we enlarge the search space to include bio-inspired
learning rules and use NAS to find the best architecture and learning rule to
use in each layer. We show that neural networks that use different bio-inspired
learning rules for different layers have better accuracy than those that use a
single rule across all the layers. The resulting NN that uses a mix of
bio-inspired learning rules sets new records for bio-inspired models: 95.16% on
CIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on
ImageNet. In some regimes, they even surpass comparable BP-based networks while
retaining their robustness advantages. Our results suggest that layer-wise
diversity in learning rules allows better scalability and accuracy, and
motivates further research on mixing multiple bio-inspired learning rules in
the same network.

</details>


### [347] [Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies](https://arxiv.org/abs/2507.13549)
*Jim O'Connor,Nicholas Lorentzen,Gary B. Parker,Derin Gezgin*

Main category: cs.NE

TL;DR: NEAT 算法进化出了高性能的 Xpilot-AI 赛车控制器，提升了 32% 的单圈表现。


<details>
  <summary>Details</summary>
Motivation: 为 Xpilot-AI 平台的新赛车模式开发高性能赛车控制器，以应对其复杂的物理引擎和灵活的赛道设计。

Method: 利用神经拓扑进化（NEAT）算法，通过进化神经网络的结构和权重来开发自适应控制器。

Result: 进化的控制器在单圈时间上比初始控制器有高达 32% 的提升，并能发展出最优过弯和速度调节等有效的比赛策略。

Conclusion: NEAT 算法在 Xpilot-AI 平台的新赛车模式下能够有效地进化出高性能的赛车控制器，这些控制器能够学习到类似人类的赛车策略，并且在比赛中取得了显著的成绩。

Abstract: This paper investigates the development of high-performance racing
controllers for a newly implemented racing mode within the Xpilot-AI platform,
utilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By
leveraging NEAT's capability to evolve both the structure and weights of neural
networks, we develop adaptive controllers that can navigate complex circuits
under the challenging space simulation physics of Xpilot-AI, which includes
elements such as inertia, friction, and gravity. The racing mode we introduce
supports flexible circuit designs and allows for the evaluation of multiple
agents in parallel, enabling efficient controller optimization across
generations. Experimental results demonstrate that our evolved controllers
achieve up to 32% improvement in lap time compared to the controller's initial
performance and develop effective racing strategies, such as optimal cornering
and speed modulation, comparable to human-like techniques. This work
illustrates NEAT's effectiveness in producing robust control strategies within
demanding game environments and highlights Xpilot-AI's potential as a rigorous
testbed for competitive AI controller evolution.

</details>


### [348] [MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development](https://arxiv.org/abs/2507.13785)
*Mykola Glybovets,Sergii Medvid*

Main category: cs.NE

TL;DR: MorphoNAS是一种受生物形态发生启发的神经架构搜索系统，它能通过简单的规则自组织生成复杂的神经网络，并在图配置生成和强化学习任务中取得了良好效果，展示了其在自适应和高效神经架构搜索方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现代人工神经网络架构搜索方法主要涉及显式和常规的手动工作，而生物神经网络则从紧凑的基因组和相对简单的规则中发展而来。本研究旨在探索一种受生物学启发的、能够通过自组织过程自动生成复杂神经网络架构的方法。

Method: MorphoNAS系统通过模拟自由能原理、反应扩散系统和基因调控网络中的形态发生自组织过程，利用简单的基因组编码形态发生动力学和基于阈值的细胞发育规则，从单个祖细胞生长出复杂的神经网络，整个过程基于局部化学相互作用。

Result: 在结构靶向任务中，MorphoNAS成功找到能够生成预定随机图配置（8-31个节点）的基因组。在CartPole控制任务中，当施加网络尺寸最小化的进化压力时，MorphoNAS能够找到仅包含6-7个神经元的低复杂度解决方案。进化过程成功地平衡了最终解决方案的质量和神经架构搜索的有效性。

Conclusion: 该研究提出的MorphoNAS方法能够通过简单的发育规则生长复杂的特定神经架构，这为自适应和高效的神经架构搜索提供了可行的生物学途径。

Abstract: While biological neural networks develop from compact genomes using
relatively simple rules, modern artificial neural architecture search methods
mostly involve explicit and routine manual work. In this paper, we introduce
MorphoNAS (Morphogenetic Neural Architecture Search), a system able to
deterministically grow neural networks through morphogenetic self-organization
inspired by the Free Energy Principle, reaction-diffusion systems, and gene
regulatory networks. In MorphoNAS, simple genomes encode just morphogens
dynamics and threshold-based rules of cellular development. Nevertheless, this
leads to self-organization of a single progenitor cell into complex neural
networks, while the entire process is built on local chemical interactions. Our
evolutionary experiments focused on two different domains: structural
targeting, in which MorphoNAS system was able to find fully successful genomes
able to generate predefined random graph configurations (8-31 nodes); and
functional performance on the CartPole control task achieving low complexity
6-7 neuron solutions when target network size minimization evolutionary
pressure was applied. The evolutionary process successfully balanced between
quality of of the final solutions and neural architecture search effectiveness.
Overall, our findings suggest that the proposed MorphoNAS method is able to
grow complex specific neural architectures, using simple developmental rules,
which suggests a feasible biological route to adaptive and efficient neural
architecture search.

</details>


### [349] [Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions](https://arxiv.org/abs/2507.14011)
*Paolo Totaro,Alberto Mangiante*

Main category: cs.NE

TL;DR: 本研究提出了一种新的认知建模方法，使用EGO算法和E语言，从生命系统内部视角模拟认知过程。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是提供一种形式化方法来模拟认知过程，该方法将经验视为生命系统维持其生存平衡的内在需求，而非外部观察者的视角。

Method: 该研究基于一个名为环境生成算子（EGO）的算法框架，并使用一种名为E语言的自指语言。EGO模拟认知过程，将其视为在Hebb所理解的神经元组合上的操作。研究中实现并测试了一个EGO原型（EGO-P）。

Result: 研究实现并测试了一个EGO原型（EGO-P），该原型模拟了基于Hebb理论的神经元组合操作，以形式化生命系统的经验认知过程。

Conclusion: 该研究提出了一个名为环境生成算子（EGO）的算法框架，并辅以一种名为E语言的自指语言，用于形式化认知过程模型。该模型从生命系统的角度出发，强调维持生命平衡的内在需求，并将认知过程模拟为基于Hebb理论的神经元组合操作。

Abstract: This article proposes a method to formalise models of cognitive processes
grounded in experience, considering experience from the perspective of a living
system and not from that of an observer of the living system. The perspective
of a living system is defined by the need of the system to preserve the vital
equilibria. The method is based on an algorithmic schema that we call
Environment Generative Operator (EGO) and uses a self-referential language
developed for this purpose which we call E-language. EGO simulates cognitive
processes as operations on neuron assemblies as understood by Hebb. In this
article we present an EGO prototype (EGO-P) which has already been implemented
and tested.

</details>
