<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 83]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.NE](#cs.NE) [Total: 2]
- [eess.SY](#eess.SY) [Total: 22]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 10]
- [cs.RO](#cs.RO) [Total: 64]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.LO](#cs.LO) [Total: 6]
- [eess.SP](#eess.SP) [Total: 19]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.LG](#cs.LG) [Total: 55]
- [cs.MA](#cs.MA) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 22]
- [cs.AR](#cs.AR) [Total: 6]
- [quant-ph](#quant-ph) [Total: 33]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.SY](#cs.SY) [Total: 2]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.GT](#cs.GT) [Total: 5]
- [physics.app-ph](#physics.app-ph) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 提出了一种基于证据检索的、用于不确定性感知决策的机制，该机制用证据条件化的、实例自适应的标准替代了单一的全局截止值。


<details>
  <summary>Details</summary>
Motivation: 为了提高不确定性感知决策的准确性和可解释性，并减少错误决策。

Method: 对于每个测试实例，在嵌入空间中检索近邻样本；通过证据理论融合它们的预测分布。由此产生的融合信念充当了每个实例的阈值机制。

Result: 在CIFAR-10/100数据集上，使用BiT和ViT骨干网络进行实验，与应用预测熵阈值相比，在不确定性感知性能上更高或相当，同时显著减少了自信的错误结果，并保持了可持续的审查负荷。仅需少量证据即可实现这些改进，增加证据集只会带来适度的变化。

Conclusion: 基于证据条件化的标签为操作中的不确定性感知决策提供了一种比固定预测熵阈值更可靠、更具可解释性的替代方案。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [2] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确性、训练效率和鲁棒性方面优于纯经典模型，尤其是在复杂视觉任务中。


<details>
  <summary>Details</summary>
Motivation: 评估混合量子-经典神经网络与纯经典模型在准确性、效率和鲁棒性方面的性能。

Method: 在 MNIST、CIFAR100 和 STL10 数据集上对混合模型（参数化量子电路与经典深度学习架构）和纯经典模型（卷积神经网络）进行系统比较。

Result: 混合模型在所有数据集上都实现了更高的最终准确率（MNIST：99.38%，CIFAR100：41.69%，STL10：74.05%），训练速度提高了 5-12 倍，参数数量减少了 6-32%。在简单数据集上，混合模型在对抗鲁棒性方面表现出显著的优势，并且在内存和 CPU 使用率方面更有效率。

Conclusion: 混合量子-经典神经网络在准确性、训练效率和参数可扩展性方面提供了显著优势，特别适合处理复杂的视觉任务。

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [3] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 本研究提出了一个解决高速公路拥堵检测和预测问题的综合技术框架，通过优化YOLOv11和DeepSort算法提高了车辆感知准确率，并利用GRU-Attention模型实现了高精度的拥堵预测。


<details>
  <summary>Details</summary>
Motivation: 现有交通检测和预测系统在车辆感知准确率和长序列依赖性方面存在缺陷，影响了交通效率和区域连接性。

Method: 1. 优化了YOLOv11模型，用DIoU Loss替换GIoU Loss，并改进了DeepSort算法，融合了马氏距离和余弦距离。2. 利用Greenberg模型分析了车速和车流量的关系。3. 构建了GRU-Attention模型来预测拥堵。

Result: 优化后的YOLOv11-DIoU模型mAP达到95.7%，DeepSort算法MOTA达到93.8%。GRU-Attention模型在拥堵预测方面达到99.7%的准确率，并能在10分钟内提前30分钟预测拥堵，误差小于1分钟。

Conclusion: 该框架为高速公路拥堵控制提供了支持，并在智能交通领域具有应用前景。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [4] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 本项目旨在通过自动化测试流程来优化一个基于众包数据的实时停车服务，利用卷积神经网络识别停车位，将人力资源时间减少高达99.58%。


<details>
  <summary>Details</summary>
Motivation: 优化现有的基于众包数据的实时路边停车服务的质量，具体是通过自动化地面真实性测试的现有测试流程。

Method: 应用机器学习，特别是图像模式识别和卷积神经网络，来丰富数据库并替代分析过程中的大量人工工程工作。

Result: 通过预定义的指标展示了所达到的性能水平，显示人力资源时间减少了高达99.58%。

Conclusion: 自动化的分析工具在提高停车服务质量方面取得了显著成效，并为未来的发展和潜在应用提供了展望。

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [5] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: VLMs在零样本OOD检测方面表现出色，但其有效性、优势和鲁棒性仍需深入研究。本文通过实证分析，揭示了VLM的内在机制、相比单模态方法的优势（源于语义新颖性），并指出了其在提示词选择上的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有研究对视觉语言模型（VLM）在零样本OOD检测方面的能力、优势以及行为鲁棒性缺乏全面理解。

Method: 通过使用ID和OOD提示词，对VLM进行系统的实证分析，以（1）解析其工作机制，（2）量化其相较于单模态方法的优势，（3）探究其鲁棒性（特别是对提示词的敏感性）。

Result: （1）揭示了VLM嵌入空间中促进零样本OOD检测的关键操作特性；（2）经验量化了VLM相比于传统单模态方法的优越性，并归因于VLM利用丰富语义新颖性的能力；（3）发现了VLM在鲁棒性方面存在显著的不对称性：对图像噪声有弹性，但对提示词的措辞高度敏感。

Conclusion: 本文的分析提供了对VLM驱动的OOD检测的优势和关键脆弱性的更结构化理解，并为开发更鲁棒、更可靠的未来设计提供了重要的、基于实证的指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [6] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 本论文提出了一种基于曲率的离散度量空间几何轮廓构建方法，并量化评估数据表示（如降维技术）的有效性，同时还能估计数据的内在维度，并应用于经验网络分析。


<details>
  <summary>Details</summary>
Motivation: 为了量化评估数据表示（如降维技术）的有效性，并探索经验网络的结构。

Method: 利用新开发的抽象截面曲率概念，构建基于曲率的离散度量空间几何轮廓，该曲率概念捕捉三点与其他点之间的度量关系。

Result: 实验证明，该方法可以用来估计数据集的内在维度，并成功应用于探索经验网络的结构和评估降维技术的有效性。

Conclusion: 基于曲率的分析可以有效地评估数据表示的有效性，并估计数据的内在维度。

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [7] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 本论文提出一种基于联邦学习（FL）的分布式方法，利用FLOWER和RAY框架，结合YOLOS-small、Faster R-CNN with ResNet50以及Faster R-CNN with MobileNetV3模型，在保护用户数据隐私和安全的前提下，实现卫星图像的除orestation识别和定位。


<details>
  <summary>Details</summary>
Motivation: 为了解一个区域的地理状况，必须从卫星图像中准确识别除orestation。

Method: 本框架利用FLOWER框架和RAY框架执行分布式学习工作负载。RAY确保了有效的客户端生成，因为它可以选择特定数量的用户来创建仿真环境。本框架的FL使用YOLOS-small（一种Vision Transformer变体）、具有ResNet50骨干的Faster R-CNN以及具有MobileNetV3骨干的模型进行训练和测试。

Result: 本方法为卫星图像上的图像分割任务提供了一个不同的视角。

Conclusion: 本论文提出一种新的分布式方法，利用联邦学习（FL）识别和定位不同客户端的除orestation。FL允许分布式网络客户端在保持用户数据隐私和安全的同时协同训练模型。本框架的FL使用YOLOS-small、具有ResNet50骨干的Faster R-CNN以及具有MobileNetV3骨干的模型进行训练和测试。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [8] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 该研究使用机器学习和遥感技术，通过分析2013年至2024年斐济楠迪的Landsat-8卫星图像，比较了土地利用和土地覆盖的变化，并重点关注了城市区域的变化。


<details>
  <summary>Details</summary>
Motivation: 斐济作为一个发展中国家，正经历快速的城市化，这体现在包括住房、道路和工程建设在内的大规模开发项目中。本研究旨在为土地覆盖/土地利用建模和变化检测提供技术支持。

Method: 该研究使用Landsat-8卫星图像，并利用谷歌地球引擎（Google Earth Engine）和无监督机器学习（k-means聚类）生成土地覆盖图。研究中还使用了卷积神经网络（CNN）来对选定区域的土地覆盖类型进行分类，并生成了变化检测的可视化图，以监测城市区域随时间的变化。

Result: 研究成功生成了2013年至2024年间斐济楠迪的土地覆盖图，并通过可视化清晰地展示了城市区域的变化。

Conclusion: 该研究成功应用机器学习和遥感技术，为斐济楠迪的土地利用和土地覆盖变化检测提供了有效的解决方案，特别是城市区域的变化监测，为未来的城市规划和管理提供了数据支持。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [9] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 该论文提出了一个新颖的三阶段框架，用于在电力传输系统中实时检测和跟踪外来物体（FOI）。


<details>
  <summary>Details</summary>
Motivation: 提出一个能够实时检测和跟踪电力传输系统中的外来物体（FOI）的框架，并优化以适应低成本边缘硬件的部署。

Method: 该框架集成了YOLOv7分割模型用于目标定位，基于三元组损失训练的ConvNeXt特征提取器用于生成判别性嵌入，以及一个特征辅助的IoU跟踪器用于多目标跟踪。该系统还支持通过添加新物体嵌入到参考数据库来实现增量更新，无需重新训练模型。最后，该框架针对在NVIDIA Jetson设备上使用混合精度推理进行了优化。

Result: 在真实世界的监控和无人机数据集上的大量实验表明，该框架在各种外来物体入侵场景下都表现出高准确性和鲁棒性。在NVIDIA Jetson设备上的硬件基准测试也证实了该框架对于实际边缘应用的实用性和可扩展性。

Conclusion: 该框架通过结合先进的目标检测、特征提取和跟踪技术，并针对边缘设备进行了优化，能够高效、鲁棒地实时检测和跟踪电力传输系统中的外来物体，并支持增量学习，适合实际部署。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [10] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: EdiVal-Agent是一个用于指令驱动图像编辑的自动化评估框架，它通过对象中心视角和专家工具集来解决现有评估方法的局限性，提高了评估的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的指令驱动图像编辑评估方法存在局限性：依赖配对参考图像的方法覆盖范围有限且存在偏见；仅依赖零样本视觉语言模型（VLMs）的方法评估不够精确。

Method: EdiVal-Agent通过对象分解、合成编辑指令，并集成VLMs、开放词汇对象检测器、语义级特征提取器和人类偏好模型来评估指令遵循、内容一致性和视觉质量。

Result: 实验证明，结合VLMs和对象检测器的评估方法比单独使用VLMs或CLIP指标更能与人类判断保持一致。该框架的模块化设计允许未来工具的集成，以提高评估准确性。

Conclusion: EdiVal-Agent能够识别现有图像编辑模型的故障模式，为下一代编辑模型的开发提供信息，并且其模块化设计具有良好的可扩展性。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [11] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个统一的Transformer模型，可以直接回归3D场景几何和相机位姿，支持多种3D视觉任务。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理多种3D视觉任务的统一模型，并实现高效的联合训练。

Method: 使用基于Transformer的前馈模型，结合图像和可选的几何输入，采用分解表示法（深度图、射线图、相机位姿、尺度因子）来生成全局一致的度量3D场景几何。

Result: 在多种3D视觉任务（如SfM、MVS、单目深度估计等）上，MapAnything的表现优于或媲美了专用模型，并实现了更高效的联合训练。

Conclusion: MapAnything有望成为通用的3D重建基础模型。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [12] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出SCM-PR框架，利用RGB图像的高层语义信息提升激光雷达地图的鲁棒定位能力，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB的视觉定位方法对光照、天气和季节变化敏感，而现有的跨模态方法在复杂场景、精细匹配和视角变化下仍有困难。本研究旨在通过结合高层语义信息来解决这些问题。

Method: 提出SCM-PR框架，包含VMamba骨干网络提取RGB特征，语义感知特征融合（SAFF）模块融合描述符和分割掩码，结合语义和几何的激光雷达描述符，以及用于改进匹配的跨模态语义注意力机制。此外，还设计了多视角语义几何匹配和语义一致性损失，并将其应用于对比学习框架。

Result: 在KITTI和KITTI-360数据集上的实验表明，SCM-PR相比其他跨模态方法取得了最先进的性能。

Conclusion: SCM-PR框架通过引入语义信息，有效提高了在激光雷达地图中的定位鲁棒性，克服了现有方法的局限性。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [13] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）数据量巨大，现有压缩方法采用均匀标量量化（USQ）。本文提出用格向量量化（LVQ）替代USQ，并针对场景优化格基，实现场景自适应LVQ（SALVQ），在不显著增加开销和复杂性的前提下，提升了3DGS的压缩率-失真（R-D）性能。SALVQ可无缝集成现有方法，并能通过缩放格基向量动态调整压缩率，无需为不同比特率训练多模型。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS压缩方法依赖均匀标量量化（USQ），但更复杂的量化器可能在极小的额外开销下提升性能。

Method: 将USQ替换为格向量量化（LVQ），并针对每个场景优化格基，形成场景自适应LVQ（SALVQ）。SALVQ通过缩放格基向量可动态调整量化器密度，以适应不同比特率。

Result: SALVQ在保持低复杂度的情况下，提升了现有3DGS压缩方法的R-D效率，并能通过单一模型适应多比特率目标，减少训练成本。

Conclusion: 场景自适应LVQ（SALVQ）是一种有效的3DGS压缩方法，它在简单的基础上实现了向量量化的优越性能，提高了压缩效率和灵活性。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [14] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 该研究提出了一种新的社交群体区域检测任务，并开发了MINGLE模型来识别和定位图像中的社交互动群体，同时发布了一个包含100K图像的新数据集来支持该任务。


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对于城市规划至关重要，有助于设计充满活力和包容性的环境。从图像中检测这些互动需要理解细微的视觉线索，如关系、邻近性和共同移动，这些信号比传统的目标检测更复杂。

Method: 提出了一种名为MINGLE的三阶段流水线模型，集成了：1）现成的人体检测和深度估计；2）基于视觉语言模型（VLM）的推理来分类成对的社交关系；3）轻量级的空间聚合算法来定位社交连接的群体。

Result: 构建了一个包含100K张城市街景图像的新数据集，其中标注了个体和社交互动群体的边界框和标签。这些标注结合了人工标注和MINGLE模型的输出。

Conclusion: MINGLE模型通过整合人体检测、深度估计、基于VLM的社交关系分类和空间聚合，有效地解决了社交群体区域检测的挑战。新发布的数据集为该领域的进一步研究提供了支持。

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [15] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap通过分析跨注意力归因图来发现和缓解稳定扩散模型中隐藏的概念级代表性偏差，解决了现有方法仅关注输出分布而忽略概念纠缠的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的偏见发现方法主要关注输出层面的统计数据，但未能解决潜在概念表示中的纠缠问题，可能导致偏见移除不彻底。

Method: 提出BiasMap框架，利用跨注意力归因图来识别和量化（通过IoU）人口统计学特征（如性别、种族）与语义（如职业）之间的概念纠缠。进一步提出一种基于能量引导的去噪扩散采样方法，通过修改潜在噪声空间并最小化SoftIoU来缓解概念纠缠。

Result: 研究表明，现有的公平性干预措施虽然可以减少输出分布的差异，但往往无法解决概念层面的耦合问题。BiasMap提出的缓解方法能够有效缓解图像生成中的概念纠缠，并且可以与现有的分布偏见缓解方法互补。

Conclusion: BiasMap是一个有效的模型无关框架，能够深入揭示和解决稳定扩散模型中隐藏的概念级代表性偏差，其提出的缓解策略在处理概念纠缠方面优于现有方法。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [16] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: 该论文介绍了一个名为LivePixel的Python工具，用于实时图像标注，解决了现有工具的局限性，支持即时数据采集和AI模型开发。


<details>
  <summary>Details</summary>
Motivation: 现有图像标注软件需要预先收集数据集，这不适合需要实时数据采集的实验室环境，限制了按需处理流程并增加了不必要的步骤。

Method: 开发了一个名为LivePixel的Python图形用户界面，它可以与显微镜、网络摄像头等成像系统集成，提供类似商业图形编辑软件的标注工具（如Bézier样条和二值掩码），支持非破坏性图层，并利用OpenCV和Numpy优化对象检测。

Result: LivePixel能够实时进行图像标注，支持多种视频设备，并为对象检测进行了优化，从而简化了数据收集和标注过程。

Conclusion: LivePixel通过提供一个易于使用的实时标注工具，加速了实验流程中AI模型的发展。

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [17] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 通过使用 Doob 的 h-transform 效率微调（DEFT）来适应预训练的扩散模型以实现虚拟试穿（VTO），并引入自适应一致性损失来进一步提高性能和减少推理时间，DEFT-VTON 方法在 VTO 任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 VTO 方法虽然能够生成高质量的图像，但通常需要大量的计算资源和时间进行训练和推理，这在实际应用中受到限制。本研究旨在提出一种更高效的方法来适应预训练模型以实现 VTO。

Method: 本研究将 Doob 的 h-transform 效率微调（DEFT）应用于预训练的无条件模型，以实现基于图像条件的 VTO。DEFT 冻结预训练模型的参数，仅训练一个小的 h-transform 网络来学习条件 h-transform，从而显著减少需要训练的参数量。此外，还提出了一种自适应一致性损失，通过在推理路径上强制执行一致性来蒸馏慢速但高性能的扩散模型到快速模型，同时保留性能。该损失结合了一致性损失和去噪评分匹配损失，并以数据自适应的方式进行微调。

Result: DEFT-VTON 方法在 VTO 任务上取得了最先进的性能，仅需 15 步去噪即可达到，同时保持了具有竞争力的结果。

Conclusion: DEFT-VTON 方法通过 DEFT 和自适应一致性损失的结合，有效解决了现有 VTO 方法在训练和推理效率方面存在的挑战，实现了在保持高质量的同时显著提高效率的目标。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [18] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 生成用于改善行人识别的合成数据。我们提供了一个在Cityscapes数据集上添加虚拟行人的流程，并使用新的生成网络来改善光照条件，以提高真实性。最后，我们在语义和实例分割任务上评估了该方法。


<details>
  <summary>Details</summary>
Motivation: 合成数据在自动驾驶领域对于覆盖特定交通场景至关重要，但合成数据和真实数据之间常存在域间隙。本研究旨在通过数据增强来生成包含虚拟行人（VRUs）的定制交通场景，以提高行人识别能力。

Method: 本研究采用数据增强技术，并提供了一个将虚拟行人添加到Cityscapes数据集的流程。为了提高增强的真实性，研究人员揭示了一种新颖的生成网络架构，用于对抗性地学习数据集的光照条件。

Result: 该方法在语义分割和实例分割任务上进行了评估。

Conclusion: 通过引入数据增强和新的生成网络架构，本研究有效地解决了合成数据中的域间隙问题，提高了自动驾驶中行人识别的准确性，并在语义和实例分割任务上取得了良好效果。

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [19] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了一种新的可解释神经网络框架FunKAN，用于医学图像处理，它将Kolmogorov-Arnold表示定理推广到函数空间，并通过傅里叶分解学习内函数，解决了传统深度学习方法可解释性差和KANs破坏空间结构的问题。FunKAN在Gibbs-ringing抑制和医学图像分割任务（包括乳腺癌、腺体和息肉检测）上进行了实验，并在IXI、BUSI、GlaS和CVC-ClinicDB数据集上取得了优于其他KANs骨干的性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像增强和分割中的伪影和复杂解剖变异问题，以及传统深度学习方法可解释性差和Kolmogorov-Arnold网络（KANs）破坏图像空间结构的问题。

Method: 提出了一种名为Functional Kolmogorov-Arnold Network (FunKAN) 的新颖可解释神经网络框架，它将Kolmogorov-Arnold表示定理推广到函数空间，并使用基于Hermite函数的傅里叶分解来学习内函数。对于分割任务，提出了U-FunKAN模型。

Result: 在IXI数据集上，FunKAN在Gibbs ringing抑制任务上表现良好。在BUSI、GlaS和CVC-ClinicDB数据集上，U-FunKAN在检测乳腺癌、腺体和息肉方面取得了先进的分割性能。与其他的KANs骨干网络相比，FunKAN在医学图像增强（PSNR, TV）和分割（IoU, F1）方面都取得了更好的结果。

Conclusion: FunKAN成功地将理论函数逼近与医学图像分析相结合，为临床应用提供了一个鲁棒且可解释的解决方案，克服了传统方法的局限性。

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [20] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的多模态双流图神经网络模型，用于仇恨视频分类，通过实例图和权重图来突出仇恨内容，并在公开数据集上取得了最先进的性能和良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理仇恨视频时，未能充分利用多模态信息，并且无法有效地区分和突出内容中的仇恨成分，同时在捕捉视频结构化信息方面存在局限。

Method: 提出了一种新的多模态双流图神经网络模型，首先将视频分割成实例并提取特征，然后构建实例图；接着，利用互补权重图为这些特征分配重要性权重，以突出仇恨实例；最后，结合实例特征和权重生成视频标签，并通过图模型捕捉跨模态的结构化关系。

Result: 在公开数据集上的广泛实验表明，该模型在仇恨视频分类方面达到了最先进的水平，并具有很强的可解释性。

Conclusion: 该研究提出的新型多模态双流图神经网络模型能够有效解决现有仇恨视频检测方法的局限性，通过突出仇恨内容和建模结构化信息，显著提升了分类性能和可解释性。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [21] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个基于扩散模型的方法，可以从单视角结肠镜视频中生成时间上一致的深度图，并具有3D重建和表面覆盖评估等临床应用。


<details>
  <summary>Details</summary>
Motivation: 现有的深度估计模型在处理结肠镜视频的 temporal consistency 方面存在不足，限制了其在3D重建中的应用。

Method: ColonCrafter采用基于扩散模型的方法，并从合成的结肠镜序列中学习几何先验。此外，还引入了一种风格转换技术，以适应真实世界的临床视频。

Result: ColonCrafter在C3VD数据集上实现了最先进的零样本性能，优于现有的通用和结肠镜专用方法。

Conclusion: 尽管完整的轨迹3D重建仍然是一个挑战，但ColonCrafter在3D点云生成和表面覆盖评估等临床应用中显示出其潜力。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [22] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 本研究提出了一种在内存受限的嵌入式平台（如微型飞行器）上优化3D高斯泼溅（3DGS）效果的方法，通过在体素空间合并冗余的高斯点并使用Patch-Grid（PG）初始化来减少内存占用并提高渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅（3DGS）技术主要在高性能GPU上运行，但忽略了计算资源和内存有限的嵌入式平台（如微型飞行器）的应用。这些平台在系统性能和重建质量之间存在权衡。

Method: 提出了一种在体素空间根据几何相似性合并冗余3D高斯原语的方法，以减少GPU内存使用。此外，通过Patch-Grid（PG）点采样初始化3D高斯原语，以提高渲染质量。

Result: 通过在体素空间合并冗余高斯点，在不影响系统运行时性能的情况下减少了GPU内存使用。通过Patch-Grid（PG）初始化，提高了渲染质量。在公开数据集上的定量和定性评估证明了这些改进的有效性。

Conclusion: 本研究成功地解决了在内存受限的嵌入式平台上运行3DGS时面临的挑战，通过提出的合并和初始化策略，在减少内存占用的同时提高了渲染质量。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [23] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 本文提出了一种用于自动驾驶汽车轨迹预测的OOD检测框架，通过自适应机制和显式建模预测误差模式，提高了检测鲁棒性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车在部署时会遇到训练数据与真实世界条件之间的分布变化，导致罕见或代表性不足的交通场景产生OOD（分布外）情况。然而，现有的OOD检测研究主要集中在计算机视觉任务上，而轨迹级别的OOD检测仍有待探索。

Method: 本文提出的新框架引入了自适应机制来应对复杂的驾驶环境。它通过显式建模预测误差模式，解决了即使是分布内样本也存在随时间演变的、依赖于数据集的动态模式的预测误差问题。

Result: 该框架在多个真实世界数据集上的实证分析表明，通过显式建模误差模式，显著改善了检测延迟和误报率。在轨迹预测基准测试中的实验表明，该框架在准确性和计算效率方面均显著优于之前的基于不确定性量化（UQ）和基于视觉的OOD方法。

Conclusion: 所提出的框架为实现可靠的、感知驾驶的自主性提供了一条实用的途径，通过其在准确性和计算效率方面的优势，解决了轨迹预测中的OOD检测问题。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [24] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 本研究提出一种利用卫星图像对和深度学习技术检测亚马逊雨林森林砍伐的方法，并辅以视觉语义模型进行变化注释。


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林森林砍伐对全球碳排放和生物多样性构成重大威胁，因此监测森林砍伐至关重要。

Method: 利用深度学习技术比较不同日期的同一区域的卫星图像，以识别森林覆盖的变化，并提出一个视觉语义模型来自动注释检测到的变化。

Result: 在亚马逊图像对数据集上评估了该方法，证明了其在检测森林砍伐和生成相关注释方面的有效性。

Conclusion: 该方法为监测和研究亚马逊森林砍伐的影响提供了一个有用的工具，并且具有广泛的应用潜力。

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [25] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 该研究提出了一个利用Google Gemini 2.5 Flash的多模态智能框架，用于医学影像分析，能够自动检测肿瘤并生成多模态（CT、MRI、X-ray、Ultrasound）的临床报告，实现了80像素的平均位置测量偏差，并具有零样本学习能力。


<details>
  <summary>Details</summary>
Motivation: 为了利用AI在医疗影像诊断和临床决策中的快速发展，提出一个能够整合视觉和语言信息的智能框架。

Method: 整合Google Gemini 2.5 Flash，利用视觉特征提取和自然语言处理技术，结合坐标验证和高斯概率模型，实现跨CT、MRI、X-ray、Ultrasound的肿瘤检测和报告生成，并提供多层级可视化和用户友好的Gradio界面。

Result: 在跨模态异常检测方面表现出高性能，位置测量平均偏差为80像素，并展示了零样本学习能力，减少了对大型数据集的依赖。

Conclusion: 该框架在自动化诊断支持和放射工作流程效率方面取得了显著进展，但广泛应用前需要进行临床验证和多中心评估。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [26] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法从2D推广到3D，并展示了其与RANSAC和Hough变换的关系。


<details>
  <summary>Details</summary>
Motivation: 将CLAP算法从2D推广到3D，并研究其与RANSAC和Hough变换的关系。

Method: 将CLAP算法推广到3D，并分析其与RANSAC和Hough变换的关系。

Result: CLAP算法已成功推广到3D，并揭示了其与RANSAC和Hough变换的联系。

Conclusion: CLAP算法的推广具有广泛的适用性，可用于处理噪声和不确定性。

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [27] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR是一个利用SAM模型进行医学图像配准的框架，通过提取结构感知特征嵌入和设计分层特征一致性损失，提高了配准精度，并在心脏和腹部CT图像配准任务中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督医学图像配准方法依赖于通常不易获得的解剖先验（如分割掩码或标志点），限制了其实际应用。本项目旨在利用视觉基础模型强大的表示学习能力来增强特征提取，从而提高配准精度。

Method: SAMIR框架首先使用SAM的图像编码器提取结构感知特征嵌入，然后通过一个轻量级的3D头在嵌入空间中细化特征，以适应局部形变。此外，还引入了一个分层特征一致性损失来指导粗到精的特征匹配和解剖对齐。

Result: SAMIR在心脏图像配准（ACDC数据集）和腹部CT图像配准（腹部数据集）的基准测试中，显著优于现有技术，分别取得了2.68%和6.44%的性能提升。

Conclusion: SAMIR通过利用SAM模型进行特征提取和引入新的损失函数，能够更准确地模拟解剖一致性和形变模式，从而在医学图像配准任务中取得优越性能。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [28] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一个训练免费框架，通过独立重建的3D场景的直接对齐来估计相机的相对位姿，解决了传统方法在度量尺度、大基线和纹理稀疏表面上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统两视图位姿估计方法缺乏度量尺度，在处理大基线和纹理稀疏/反射表面时存在困难，而GARPS旨在解决这些问题。

Method: GARPS利用度量单目深度估计器和高斯场景重建器为每个图像获得度量3D高斯混合模型（GMM），并通过优化可微的GMM对齐目标来优化初始位姿，该目标综合考虑了几何结构、视点无关颜色、各向异性协方差和语义特征一致性。

Result: 在Real-Estate10K数据集上的大量实验表明，GARPS的性能优于包括MASt3R在内的传统和最先进的基于学习的方法。

Conclusion: GARPS的成功展示了结合单视图感知和多视图几何来获得鲁棒且度量相对位姿估计的潜力。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [29] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 通过可微分查找操作替代卷积网络中的乘法运算，实现高效能和高精度的查找网络。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络计算密集，特别是乘法运算，限制了其在移动设备上的部署。

Method: 引入可微分查找操作替代乘法运算，并提出训练策略以优化查找表，构建查找网络。

Result: 在图像分类、图像超分辨率和点云分类任务上，查找网络在能耗和推理速度方面表现出更高的效率，同时保持了与传统卷积网络的竞争性能。

Conclusion: 查找网络在分类和回归任务、图像和点云数据上均取得了先进的性能。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [30] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 通过利用SAM生成语义超像素来压缩视觉标记，减少了93%的视觉标记，同时保持了性能，从而加速了MLLM的训练和推理。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM-SAM框架在Referring Image Segmentation（RIS）任务中表现出色，但MLLM的视觉标记冗余导致计算量大。传统的视觉投影器难以在减少标记数量和保持语义清晰度之间取得平衡。

Method: 提出了一种新的语义视觉投影器，利用SAM生成的语义超像素来识别“视觉词”，并通过压缩和投影这些超像素来生成视觉标记，从而自适应地缩短标记序列。此外，还提出了语义超像素位置嵌入和语义超像素聚合器来增强模型对几何位置的感知和保留细粒度细节与全局上下文。

Result: 实验表明，该方法将视觉标记数量减少了93%，同时没有降低性能，显著加快了MLLM的训练和推理速度，并在RIS任务上优于现有的压缩视觉投影器。

Conclusion: 所提出的语义视觉投影器通过压缩语义超像素来有效减少视觉标记数量，同时通过位置嵌入和聚合器保留关键的语义和几何信息，从而在保持高性能的同时显著提高了RIS任务中MLLM的效率。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [31] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV是一个为鱼眼相机设计的新颖BEV分割框架，通过引入三种创新机制解决了鱼眼相机带来的几何畸变、多视图对应模糊和时间动态不稳等挑战，并在Synwoodscapes数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于针孔相机的BEV分割方法难以直接应用于鱼眼相机，因为鱼眼相机存在严重的几何畸变、模糊的多视图对应以及不稳定的时间动态，这些因素严重影响了BEV性能。

Method: FishBEV框架引入了三种互补的创新：1. 畸变鲁棒多尺度提取（DRME）骨干网络，用于在畸变下学习鲁棒特征并保持尺度一致性；2. 不确定性感知空间交叉注意力（U-SCA）机制，利用不确定性估计实现可靠的跨视图对齐；3. 距离感知时间自注意力（D-TSA）模块，自适应地平衡近场细节和远场上下文以确保时间连贯性。

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环绕视图鱼眼BEV分割任务上的性能评估方面，持续优于最先进的基线方法。

Conclusion: FishBEV框架通过其创新的DRME、U-SCA和D-TSA模块，有效解决了鱼眼相机在BEV分割中的挑战，并在实验中证明了其优越性能。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [32] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 本研究提出样条基础的Kolmogorov-Arnold网络（KANs）用于医学图像分类，具有准确性、可解释性和参数量少等优点，适用于资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的临床环境中，对医学图像进行有效且可解释的分类是一个挑战。

Method: 提出三种样条基础的KANs模型（SBTAYLOR-KAN, SBRBF-KAN, SBWAVELET-KAN），利用样条函数逼近能力捕捉局部和全局非线性。模型无需预处理，可直接从原始数据学习，并通过Grad-CAM进行可解释性分析。

Result: SBTAYLOR-KAN在多种医学图像数据集（脑MRI、胸部X光、肺结核X光、皮肤病变）上表现出色，准确率最高达98.93%，且在仅使用30%数据时仍保持86%以上准确率。该模型参数量远少于传统CNN（2,872 vs 24.18M），并能有效处理类别不平衡问题。

Conclusion: 该样条基础KANs框架为医学图像分类提供了一个轻量级、可解释且泛化能力强的解决方案，解决了有限数据集和数据稀疏场景下的临床AI应用挑战。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [33] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 生成模型（特别是基于扩散的模型）的进步，使得它们有可能被滥用，例如廉价地复制艺术家的创作风格。本研究提出了一种名为 StyleProtect 的防御策略，通过更新选定的交叉注意力层来有效防御经过微调的扩散模型对艺术风格的模仿。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于，生成模型（特别是基于扩散的模型）的快速发展，使得恶意行为者能够廉价地复制艺术家的创作风格，这促使人们需要研究保护艺术作品免受风格模仿的方法。

Method: 研究人员提出了一种名为 StyleProtect 的高效轻量级保护策略。该策略通过识别对艺术风格特别敏感的交叉注意力层，并仅更新这些选定的层来实现。他们通过分析注意力层对风格和内容表示的激活强度，并评估这些激活强度与从外部模型提取的特征之间的相关性来衡量敏感性。

Result: 实验结果表明，StyleProtect 能够有效地防御针对微调扩散模型的艺术风格模仿，同时保持可接受的不可察觉性。该方法在保护独特艺术作品和动画风格方面表现出有前景的性能。

Conclusion: StyleProtect 是一种有效且轻量级的防御策略，可以通过更新选定的交叉注意力层来保护艺术作品免受经过微调的扩散模型的风格模仿，同时保持良好的不可察觉性。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [34] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth是一个结合运动和不确定性感知细化的框架，用于提高动态物体边界和纹理稀疏区域的深度估计精度，通过教师-学生训练策略实现，无需额外标签或运行时开销，并在KITTI和Cityscapes数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有自监督单目深度估计方法在处理低纹理或动态区域时存在深度不准确的问题。

Method: 提出UM-Depth框架，采用教师-学生训练策略，将不确定性估计融入训练流程和网络结构，利用光流在教师网络中进行训练，以增强对光度信号较弱区域的监督。

Result: 在KITTI和Cityscapes数据集上的大量实验证明了该框架的有效性，并在KITTI数据集上实现了最先进的自监督深度和姿态估计结果。

Conclusion: UM-Depth通过不确定性感知细化有效解决了现有方法的局限性，并在标准数据集上取得了优异的性能。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [35] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: TQF通过将查询分解为外观、帧内交互和帧间运动三个组件，并结合语言线索和视觉引导动态构建查询，解决了现有方法中查询选择偏差的问题。此外，提出的两个运动感知聚合模块增强了对象令牌表示，提高了时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的方法在指代表观视频对象分割（RVOS）中存在查询选择偏差问题，容易受到外观或运动相似的干扰因素的误导。

Method: 提出Triple Query Former (TQF)，将查询分解为外观查询、帧内交互查询和帧间运动查询，并通过结合语言线索和视觉引导动态构建查询。引入了两个运动感知聚合模块：帧内交互聚合和帧间运动聚合，以增强对象令牌表示和时间连贯性。

Result: 在多个RVOS基准测试上的广泛实验证明了TQF的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: TQF通过结构化的查询设计和运动感知聚合模块，有效解决了RVOS中的查询选择偏差问题，提高了分割性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [36] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG 是一个创新的多任务框架，首次实现了通用视觉基础任务（GREC 和 GRES）的联合训练，并结合了实例感知能力，以确保跨粒度的预测一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法各自独立地处理 GREC 和 GRES 任务，忽略了联合训练的一致性和效率优势，并且在 GRES 任务中忽视了实例感知能力的重要性。

Method: 提出 InstanceVG 框架，利用实例查询统一处理 GREC（边界框）和 GRES（像素级掩码）任务，并为每个实例查询分配先验参考点，以实现点、框、掩码的一致性预测。

Result: 在四个任务的十个数据集上进行了广泛实验，InstanceVG 取得了最先进的性能，在各项评估指标上显著优于现有方法。

Conclusion: InstanceVG 是第一个能够同时处理 GREC 和 GRES 任务并整合实例感知能力的通用视觉基础框架，通过实例查询实现了跨粒度的预测一致性，并在实验中证明了其优越性。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [37] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为FMFA的文本到图像行人检索框架，通过显式细粒度对齐和隐式关系推理来增强跨模态匹配效果，并引入A-SDM和EFA模块来解决正样本对齐不准确和局部特征对齐验证不足的问题，在三个公开数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像行人检索方法在跨模态对齐方面存在挑战，特别是缺乏对局部特征对齐的验证能力，并且主要关注硬负样本，忽略了错误匹配的正样本对。

Method: 提出FMFA框架，包含自适应相似性分布匹配（A-SDM）模块以拉近未匹配的正样本对，以及显式细粒度对齐（EFA）模块，通过稀疏化相似性矩阵和硬编码方式加强显式跨模态细粒度交互，实现局部对齐。

Result: 在三个公开数据集上进行了评估，FMFA框架实现了优于现有全局匹配方法的性能。

Conclusion: FMFA框架通过结合显式细粒度对齐和隐式关系推理，有效解决了文本到图像行人检索中的跨模态对齐问题，并在多个数据集上取得了最先进的成果。

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [38] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 该研究提出了一种新的文本驱动图像编辑方法，通过引入颜色映射模块来解决现有技术中颜色编辑精度不足和控制不连续的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的图像编辑方法在颜色编辑方面存在精度不足和难以实现连续控制的问题，主要是由于自然语言的固有歧义性和离散性，以及线性插值方法缺乏精确的颜色控制和对颜色变化范围的未知性。

Method: 提出并实现了一个颜色映射模块，该模块显式地建模了文本嵌入空间和图像RGB值之间的对应关系。该模块能够根据给定的RGB值预测相应的嵌入向量，从而实现对生成图像颜色的精确控制，并保持语义一致性。用户可以指定目标RGB范围，以生成在所需范围内具有连续颜色变化的图像。

Result: 实验结果表明，该方法在颜色连续性和可控性方面表现良好，能够实现更细粒度、连续且可控的颜色编辑。

Conclusion: 所提出的颜色映射模块能够实现精确、连续和可控的文本驱动颜色编辑，解决了现有方法的局限性。

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [39] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 该研究提出了一种结合文本和图像分析的迭代式提示优化算法，以提高文本到图像生成模型的安全性和用户意图的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型的安全方法主要依赖于大型语言模型优化提示，但忽略了生成图像本身，可能导致不安全的输出或不必要的修改。

Method: 提出了一种迭代式提示优化算法，利用视觉语言模型（VLM）同时分析输入的文本提示和生成的图像，并引入了一个包含文本和视觉安全信号的新数据集，用于监督微调。

Result: 实验结果表明，该方法在提高生成内容安全性的同时，能够保持与用户意图的一致性，并且在可靠性方面与现有的大型语言模型方法相当。

Conclusion: 所提出的基于视觉反馈的提示优化方法是一种有效且实用的解决方案，可以生成更安全、更符合用户意图的文本到图像内容。

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [40] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: TA-ISP是一个轻量级的RAW图像处理框架，通过预测多尺度调制算子来增强下游视觉任务的性能，同时降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RAW图像处理方法计算开销大或表示能力有限，无法满足资源受限设备的需求。

Method: 提出TA-ISP框架，通过预测轻量级、多尺度的调制算子来处理RAW图像，实现全局、区域和像素级别的统计信息重塑。

Result: 在多个公开数据集上，TA-ISP在提高下游任务（如目标检测和分割）精度的同时，显著减少了参数数量和推理时间。

Conclusion: TA-ISP是一个有效的、轻量级的RAW图像处理方法，能够为预训练的视觉模型生成面向任务的表示，适用于资源受限的设备。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [41] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 提出了一种新的夜间去雨网络NDLPNet，通过位置感知模块（PPM）增强空间定位和密度信息，以在低光照条件下有效去除雨纹并保留背景信息，并构建了一个新的NSR数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的图像去雨技术主要针对白天条件，在夜间光照下表现不佳，因为雨的分布具有空间异质性，并且条纹可见性受光线影响。

Method: 提出了一种新颖的夜间去雨定位增强感知网络（NDLPNet），引入了位置感知模块（PPM）来捕获和利用空间上下文信息，以识别和重新校准不同特征通道的重要性。

Result: NDLPNet能够有效去除雨纹并保留关键的背景信息。在现有数据集和NSR数据集上的实验表明，该方法在夜间去雨任务上优于现有技术。

Conclusion: 所提出的NDLPNet能够有效去除夜间场景中的雨纹，同时保留重要的背景信息，为夜间去雨任务提供了一个新的解决方案和数据集。

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [42] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: VocSegMRI是一个多模态框架，集成了视频、音频和语音学输入，通过交叉注意力融合进行动态特征对齐，实现了对发音器官的实时MRI分割，并达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的实时MRI发音器官分割方法主要依赖视觉线索，而忽略了同步的声音和语音学信号所能提供的互补上下文信息。

Method: 提出VocSegMRI多模态框架，利用交叉注意力融合技术整合视频、音频和语音学输入，并引入对比学习目标来增强跨模态表示，即使在推理时音频模态不可用也能提高分割性能。

Result: 在USC-75 rtMRI数据集的一个子集上，VocSegMRI实现了0.95的Dice分数和4.20 mm的95th percentile Hausdorff Distance (HD_95)，优于单一模态和多模态基线方法。

Conclusion: 整合多模态建模对于精确的声带分析具有重要价值，交叉注意力和对比学习对于提高分割精度和鲁棒性做出了贡献。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [43] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 提出了一种利用扩散先验的生成式编码框架，以在低比特率下提高压缩性能。


<details>
  <summary>Details</summary>
Motivation: 由于生成技术的发展，视觉内容混合了自然和AI生成的图像，这需要更高效的编码技术来优先考虑感知质量。传统的编码器和学习方法在高压缩率下难以保持主观质量，而现有的生成方法在视觉保真度和泛化性方面存在挑战。

Method: 该方法采用预优化的编码器生成通用的压缩域表示，并通过轻量级适配器和注意力融合模块与预训练模型的内部特征集成。该框架有效利用了现有的预训练扩散模型，并能以最小的重新训练成本适应不同的预训练模型以满足新需求。此外，还引入了一种分布重整化方法来进一步提高重建保真度。

Result: 实验表明，该方法在低比特率下的视觉保真度优于现有方法，与H.266/VVC相比，压缩性能提高了79%，并为AI生成的内容提供了一种有效的解决方案，同时也能适应更广泛的内容类型。

Conclusion: 所提出的生成式编码框架利用扩散先验，在低比特率下实现了卓越的压缩性能和视觉保真度，并且具有良好的适应性和效率。

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [44] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive是一个新的视觉语言动作(VLA)框架，它使用一种受快慢思考启发的双模式推理机制，以提高自动驾驶的决策质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Chain of Thought（CoT）推理技术在简单场景下表现不佳，会增加计算开销而无法提高决策质量，因此需要一种能够区分场景并选择性应用推理的机制。

Method: AdaThinkDrive首先在包括QA和轨迹在内的大规模自动驾驶场景数据集上进行预训练，以获取世界知识和驾驶常识。在SFT阶段，引入了两种模式的数据集：快速回答（无CoT）和慢速思考（有CoT），使模型能够区分需要推理的场景。此外，提出了一种自适应思考奖励策略，并结合了组相对策略优化（GRPO），通过比较不同推理模式下的轨迹质量来奖励模型选择性地应用CoT。

Result: 在Navsim基准测试中，AdaThinkDrive的PDMS达到了90.3，比仅基于视觉的基线提高了1.7个点。与从不思考和始终思考的基线相比，AdaThinkDrive的PDMS分别提高了2.0和1.4。与始终思考的基线相比，推理时间减少了14%。

Conclusion: AdaThinkDrive通过自适应推理有效地平衡了准确性和效率，解决了现有CoT方法在简单场景下的不足。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [45] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 该论文提出了一种新的深度伪造区域定位方法，结合了局部细节和全局语义信息，并通过形态学操作融合预测结果，以提高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度伪造检测的准确性不断提高，但对伪造区域进行精确定位仍然是一个重大挑战。现有方法常忽略局部细节和全局语义信息的互补性，并且在融合局部和全局预测时存在问题。

Method: 提出了一种新颖的方法，该方法分别从局部和全局视角独立预测伪造区域，并采用形态学操作融合预测结果，以抑制噪声并增强空间相干性。

Result: 通过大量的实验证明，该方法中的每个模块都能有效提高伪造区域定位的准确性和鲁棒性。

Conclusion: 该方法能够有效解决现有方法在深度伪造区域定位中的不足，提高了定位的准确性和鲁棒性。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [46] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“Variable-Rate Spatial Event Mamba”的新型事件相机数据处理架构，可以直接处理原始事件流，无需中间表示，并能根据事件速率自适应调整处理速度，以实现低延迟和高效率。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机处理方法通常将事件流转换为中间表示（如帧、体素网格或点云），这需要预定义的时间窗口，导致窗口延迟。同时，逐点检测方法计算成本高，难以实现实时性。本研究旨在克服这些局限性。

Method: 提出了一种名为“Variable-Rate Spatial Event Mamba”的新型架构，该架构直接处理原始事件流。它包含一个轻量级的因果空间邻域编码器，用于捕捉局部几何关系，并结合基于Mamba的状态空间模型进行可扩展的时间建模，具有线性复杂度。在推理时，一个控制器能根据事件速率自适应地调整处理速度，以平衡窗口延迟和推理延迟。

Result: 该方法直接处理原始事件流，无需中间表示，通过轻量级编码器和Mamba模型实现高效的时空信息提取。推理时，自适应速率调整机制能够优化延迟。

Conclusion: Variable-Rate Spatial Event Mamba 架构能够直接处理事件流，有效捕捉时空信息，并通过自适应速率调整实现了低延迟和高效率，解决了现有方法的局限性。

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [47] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: 本文提出了一种名为Block-Wise Caching (BWCache) 的训练无关方法，通过缓存和重用DiT块的中间特征来加速基于DiT的视频生成，在保证视觉质量的同时实现了高达2.24倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT视频生成方法存在固有的延迟问题，限制了其实际应用。现有的加速方法要么牺牲视觉质量，要么无法在合适的粒度上重用中间特征。

Method: 提出Block-Wise Caching (BWCache) 方法，该方法动态地缓存和重用DiT块跨扩散时间步的特征。引入了一个相似性指示器，仅当相邻时间步的块特征之间的差异低于阈值时才触发特征重用，从而最大限度地减少冗余计算并保持视觉保真度。

Result: BWCache在多个视频扩散模型上进行了广泛实验，实现了高达2.24倍的加速，同时保持了可比的视觉质量。

Conclusion: BWCache是一种有效的训练无关方法，可以显著加速DiT视频生成，同时保持高质量的视觉效果。

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [48] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 该研究通过引入一个新的基准测试（VHBench-10）和一种名为 VisionWeaver 的新颖的上下文感知路由网络，来解决大型视觉语言模型（LVLMs）中的物体幻觉问题。研究发现不同的视觉编码器具有不同的归纳偏置，导致其在幻觉方面的表现各异。VisionWeaver 通过动态聚合多个专业化专家的视觉特征来显著减少幻觉并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）中的物体幻觉问题严重阻碍了其在现实世界中的应用。视觉编码器的选择对准确解释视觉信息至关重要，但不同训练范式可能导致其产生不同的幻觉。

Method: 提出了一种名为 VHBench-10 的新基准测试，包含约 10,000 个样本，用于评估 LVLMs 在十种细粒度幻觉类别上的表现。引入了一种名为 VisionWeaver 的新颖上下文感知路由网络，该网络使用全局视觉特征生成路由信号，并动态聚合来自多个专业化专家的视觉特征。

Result: 通过 VHBench-10 的评估证实了不同的视觉编码器确实具有独特的幻觉特征。实验证明 VisionWeaver 能够显著减少幻觉并提高整体模型性能。

Conclusion: 视觉编码器的选择对 LVLMs 的幻觉表现有重要影响。提出的 VisionWeaver 模型通过上下文感知路由有效解决了这一问题，并在减少幻觉和提高模型性能方面取得了显著成效。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [49] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 该研究提出了首个针对航天器姿态估计（SPE）关键点回归的监督域自适应（SDA）框架，通过结合标记的合成数据和有限的标记真实数据，联合优化域不变表示和任务特定风险，以减少域偏移下的泛化误差。


<details>
  <summary>Details</summary>
Motivation: 合成数据集上的混合方法在真实图像上表现不佳，存在合成到真实的域间隙，而现有的无监督域自适应方法在有少量标记目标样本时效果不佳。

Method: 提出了一种基于学习不变表示和风险（LIRR）范式的监督域自适应（SDA）框架，联合优化域不变表示和任务特定风险，利用标记的合成数据和有限的标记真实数据。

Result: 在SPEED+基准测试中，该方法在所有评估指标上始终优于仅使用源数据、微调和Oracle基线。即使只有5%的标记目标数据，该方法也能达到或超过使用更多标记数据训练的Oracle性能。

Conclusion: 该框架轻量级、骨干网络无关且计算效率高，为在真实太空环境中实现鲁棒且可部署的航天器姿态估计提供了一条实用的途径。

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [50] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 该研究提出了MAFS数据集和SWA-PF方法，以解决视觉导航无人机在GNSS受限环境下的定位问题，并取得了高效且准确的定位结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索的无人机视觉定位方法在数据集可用性、实时性能、环境适应性和泛化能力方面存在局限，特别是在动态或时变环境中。

Method: 提出了一种名为SWA-PF的新型语义加权自适应粒子滤波器方法，通过结合无人机图像和卫星图像的语义特征，并采用语义加权机制和优化的粒子滤波架构来克服现有方法的局限性。此外，还构建了一个大规模的多高度飞行片段（MAFS）数据集，用于可变高度场景。

Result: 所提出的SWA-PF方法在MAFS数据集上的评估显示，其计算效率比特征提取方法提高了10倍，全局定位误差保持在10米以内，并能在几秒钟内使用低分辨率卫星地图实现快速的4自由度姿态估计。

Conclusion: SWA-PF方法能够克服现有方法的局限性，在GNSS受限环境下实现高效、准确且鲁棒的无人机定位。

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [51] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出了一种名为掩码特征建模（MFM）的新型辅助任务，用于无监督域自适应语义分割，它直接在特征空间中进行特征掩码和重建，以提高特征可辨别性。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域自适应（UDA）语义分割方法在利用辅助自监督任务（如对比学习）提高特征可辨别性方面取得了一定的进展，但掩码建模方法在该领域的研究尚不充分，这主要是由于架构不兼容和优化目标不一致的问题。

Method: 提出掩码特征建模（MFM）任务，它直接在特征空间中进行特征掩码和重建。MFM 使用一个轻量级的辅助模块“Rebuilder”进行训练，该模块在推理时被丢弃。MFM 利用分割解码器对重建的特征进行分类，将辅助目标与像素级预测任务紧密耦合。

Result: MFM 在各种架构和 UDA 基准测试中持续提升了分割性能，证明了其作为一种简单、高效且可泛化的 UDA 语义分割策略的有效性。

Conclusion: MFM 是一种新颖的、有效的、可泛化的辅助任务，可以直接在特征空间中进行掩码和重建，从而提高无监督域自适应语义分割的性能，并且不会增加推理时的计算开销。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [52] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 现有视频大语言模型（VLLMs）和基准测试主要依赖低帧率采样，忽略了密集的时间信息，这对于需要精确时间对齐的任务（如讲座理解）来说是不够的。本文提出了密集视频理解（DVU）框架，通过门控残差分词（GRT）技术，包括运动补偿和语义场景内分词合并，实现了高效、可扩展的高帧率视频理解。同时，为了评估密集时间推理能力，本文还提出了DIVE基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前的视频大语言模型（VLLMs）和基准测试在处理需要高时间分辨率的任务时存在不足，因为它们通常采用低帧率采样，丢失了密集的时间信息，并且在处理长视频时存在计算成本高和token数量线性增长的问题。

Method: 本文提出了门控残差分词（GRT）技术，一个两阶段的框架：1. 运动补偿的门控分词：利用像素级运动估计来跳过静态区域的分词，实现token数量的亚线性增长和计算量的减少。2. 语义场景内分词合并：融合场景内静态区域的token，进一步减少冗余并保留动态语义。

Result: 在DIVE基准测试上，GRT的性能优于更大的VLLM基线模型，并且随着帧率的增加，性能呈正相关，证明了密集时间信息的重要性以及GRT在高效、可扩展的高帧率视频理解方面的能力。

Conclusion: GRT技术能够有效地实现高帧率视频的理解，解决了现有VLLMs在处理密集时间信息时的局限性，并且在DIVE基准测试上取得了优于基线模型的性能。这表明密集时间信息对于视频理解至关重要，而GRT提供了一种高效且可扩展的解决方案。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [53] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 1D-Justo-LiuNet在数据不足时性能会下降，而MiniROCKET和HDC-MiniROCKET在数据不足时表现更好，并且在一般情况下表现相当。


<details>
  <summary>Details</summary>
Motivation: 尽管全光谱图像的最佳方法利用了空间-光谱信息，但仅基于光谱信息的分类具有模型尺寸小、训练数据少等优点。此外，光谱信息是对空间信息的补充，未来可以改进空间-光谱方法。

Method: 提出使用MiniROCKET和HDC-MiniROCKET进行光谱分类，以解决1D-Justo-LiuNet在数据不足时性能下降的问题。MiniROCKET和HDC-MiniROCKET在特征提取部分不含可训练参数，提取的特征工程良好，因此不太容易受到训练数据不足的影响。

Result: MiniROCKET具有比1D-Justo-LiuNet更多的参数，但在数据不足的情况下性能优于1D-Justo-LiuNet，并且在一般情况下与其相当。

Conclusion: MiniROCKET和HDC-MiniROCKET是解决1D-Justo-LiuNet在数据不足时性能下降问题的可行替代方案。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [54] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: Semi-MOE是一种新颖的半监督组织病理学图像分割方法，采用多任务专家混合（MoE）架构，通过结合分割、符号距离场回归和边界预测专家，并引入自适应多目标损失，有效解决了伪标签噪声问题，在低标注数据场景下表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法在处理组织病理学图像分割时，由于腺体边界模糊和形态学分类错误，容易受到带噪声伪标签的影响。

Method: 提出了一种名为Semi-MOE的多任务专家混合（MoE）框架，包含三个专业专家网络：主分割专家、符号距离场回归专家和边界预测专家。通过多门控伪标签模块动态聚合专家特征，实现稳健的融合-精炼伪标签机制。引入自适应多目标损失，以消除手动调整并动态平衡多个学习目标。

Result: 在GlaS和CRAG数据集上进行了广泛实验，结果表明Semi-MOE在低标注设置下优于现有最先进方法。

Conclusion: Semi-MOE在解决组织病理学图像分割的伪标签噪声问题方面取得了显著成效，并证明了MoE架构在推进半监督分割方面的潜力。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [55] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 无


<details>
  <summary>Details</summary>
Motivation: 许多近期在表示学习中的方法都假设数据点的非相关视图足以学习有意义的表示，但该研究挑战了这一假设，表明潜空间中的有意义结构并非自然出现，而是必须被显式地诱导。

Method: 提出了一种对齐数据不同视图的表示的方法，以在不产生误报的情况下对齐互补信息。该方法被称为一致视图对齐（Consistent View Alignment）。

Result: 该方法在下游任务中提高了性能，并在 MICCAI 2025 SSL3D 挑战赛中分别使用 Primus vision transformer 和 ResEnc 卷积神经网络取得了第一名和第二名的成绩。

Conclusion: 结构化的视图对齐在学习有效的表示方面起着至关重要的作用。

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [56] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 SpecDiff 的新颖特征缓存策略，通过引入“自我推测”的未来信息来提高扩散模型的推理速度，并在不损失显著质量的情况下实现了高达 3.17 倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的特征缓存方法仅依赖历史信息，导致精度和速度受限，无法有效解决扩散模型推理过程中的效率问题。

Method: 提出了一种基于“自我推测”的未来信息引入范式，并在此基础上设计了 SpecDiff。SpecDiff 包含一个缓存特征选择算法和一个多层特征分类算法。缓存特征选择算法通过结合自我推测信息和历史信息为每个 token 动态计算重要性得分，并据此进行特征选择。多层特征分类算法则利用特征重要性得分的差异对 token 进行分类，并引入多层特征计算策略。

Result: 在 Stable Diffusion 3, 3.5, 和 FLUX 模型上，SpecDiff 相比 RFlow 在 NVIDIA A800-80GB GPU 上实现了平均 2.80 倍、2.74 倍和 3.17 倍的加速，同时质量损失可忽略。

Conclusion: SpecDiff 通过融合推测信息和历史信息，克服了加速-精度权衡的瓶颈，推动了高效扩散模型推理的性能边界。

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [57] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: EDITS框架利用图像内隐式文本语义进行数据集蒸馏，解决了传统方法忽视高层语义和结构信息的问题。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏技术主要关注低层视觉特征，忽略了图像中高层语义和结构信息，导致学习效率和模型性能受限。

Method: EDITS框架首先通过全局语义查询模块融合VLM生成的外部文本和图像特征，形成先验聚类缓冲区。然后，局部语义感知模块从缓冲区选择代表性样本，构建图像和文本原型（后者通过精心设计的提示引导LLM生成）。最后，双原型引导策略利用扩散模型生成最终的合成数据集。

Result: 通过融合图像特征与VLM生成的文本，EDITS能生成包含丰富语义信息的数据集，并在实验中证明了其有效性。

Conclusion: EDITS框架通过引入文本语义信息，有效解决了传统数据集蒸馏方法的局限性，实现了更高效、更全面的数据集合成。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [58] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: X射线计算机层析成像(CL)在微芯片和复合电池材料等板状结构无损检测中至关重要，但传统CT因几何限制而难以处理。本文提出的LamiGauss算法结合高斯泼溅辐射光栅化和包含层析倾斜角的专用探测器到世界变换模型，能够从稀疏投影中准确高效地重建。实验证明，LamiGauss仅使用3%的完整视图即可实现优于使用完整数据集的迭代方法。


<details>
  <summary>Details</summary>
Motivation: X射线计算机层析成像（CL）在板状结构（如微芯片和复合电池材料）的无损检测中很重要，但传统CT存在几何限制，并且在稀疏视图采集条件下重建高质量体积具有挑战性。

Method: 提出一种名为LamiGauss的重建算法，该算法结合了高斯泼溅辐射光栅化和一个专门的探测器到世界变换模型（包含层析倾斜角）。该方法采用一种初始化策略，从初步重建中滤除常见的层析伪影，并将模型容量集中在表示真实物体上，直接从稀疏投影进行优化。

Result: LamiGauss算法使用3%的完整视图即可实现优于使用完整数据集的迭代方法的性能，并在合成和真实数据集上进行了广泛的实验验证。

Conclusion: LamiGauss算法能够有效、高效地从有限数据中进行重建，并在稀疏投影条件下实现高质量的体积重建。

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [59] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: DAM4SAM通过引入新的内存模块和管理方法，解决了视觉跟踪中的干扰物问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于内存的视频分割方法（如SAM2）在分割任务上表现出色，但在视觉目标跟踪方面，尤其是在存在外观相似的干扰物时，面临挑战，容易出现跟踪漂移和重捕获能力不足的问题。

Method: 提出了一种用于SAM2的、注意干扰物的内存模块和基于内省的管理方法，命名为DAM4SAM。该方法旨在减少跟踪漂移并提高物体遮挡后的重捕获能力。此外，构建了一个名为DiDi的数据集，用于分析在有干扰物存在的情况下进行跟踪。

Result: DAM4SAM在13个基准测试中优于SAM2.1，并在10个基准测试中创造了新的最先进记录。将其内存模块集成到实时跟踪器EfficientTAM中，性能提升了11%，并达到了非实时SAM2.1-L的跟踪质量。与基于边缘的跟踪器EdgeTAM集成后，性能提升了4%，展示了良好的跨架构泛化能力。

Conclusion: DAM4SAM通过其创新的内存处理机制，有效解决了视觉目标跟踪中的干扰物挑战，并在多个跟踪和分割基准测试中取得了显著的性能提升，证明了其有效性和广泛的适用性。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [60] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一个双流注意网络，通过融合X光片和分割骨骼图像来提高骨盆骨折分类的准确性，在AMERI数据集上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统X光片在诊断细微骨折时的挑战，提出PelFANet来提高骨折分类的准确性。

Method: PelFANet采用双流注意网络结构，融合原始X光片和分割骨骼图像，并使用Fused Attention Blocks（FABlocks）来迭代地融合和优化来自两个输入的特征，以捕捉全局上下文和局部解剖细节。该网络采用两阶段训练，并结合了分割引导的方法。

Result: PelFANet在AMERI数据集上对可见骨折的准确率达到88.68%，AUC为0.9334。对于不可见骨折，虽然未进行专门训练，但准确率仍达到82.29%，AUC为0.8688。

Conclusion: 这项研究证明了关注骨骼解剖的双输入网络架构在骨折检测中的临床潜力，尤其是在X光片表现不明显的病例中。

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [61] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV是一个轻量级的框架，用于从单个事件相机进行第一人称视角的3D手部跟踪，在提高2D精度的同时，显著减少了参数量和计算量，适用于XR设备。


<details>
  <summary>Details</summary>
Motivation: 基于帧的手部跟踪方法在精度、低延迟和能效方面难以满足资源受限的XR设备的要求。事件相机因其高时间分辨率和低功耗的特性，为解决这些问题提供了新的可能性。

Method: EvHand-FPV框架采用基于事件的相机，结合了手腕区域（ROI）定位、端到端映射策略和多任务学习方法，以实现高效的3D手部跟踪。它还构建了一个包含合成和真实数据的FPV数据集，用于训练和评估。

Result: EvHand-FPV在真实FPV测试集上，将2D-AUCp从0.77提高到0.85，参数量减少89%（从11.2M降至1.2M），每秒浮点运算次数（FLOPs）减少89%（从1.648G降至0.185G）。在合成数据上，3D-AUCp保持在0.84的竞争力。

Conclusion: EvHand-FPV实现了准确且高效的第一人称视角事件相机手部跟踪，非常适合在XR设备上进行端侧应用。

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [62] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 通过引入基于注意力机制的白化与修复模块（WARM），提出了一种新的少样本3D点云分割方法，有效解决了现有方法中原型生成受初始随机性影响和分布不匹配的问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本3D点云分割方法在提取有限支持集中的判别性表示时，依赖于最远点采样等传统方法生成原型，但其初始随机性会严重影响性能，且原型生成过程仍有待探索。

Method: 提出了一种基于注意力机制的高级原型生成方法，并通过白化与修复模块（WARM）解决原型生成中的分布差异问题。WARM在交叉注意力机制前后分别应用白化和色彩化变换，以对齐支持特征和原型令牌，并在注意力过程中恢复原始分布。

Result: WARM通过解决分布不匹配问题，实现了鲁棒的注意力机制，从而通过捕捉支持特征之间的语义关系来生成代表性原型。该方法在多个少样本3D点云分割基准测试中取得了最先进的性能，且优势显著。

Conclusion: 所提出的WARM方法通过有效的原型生成策略，显著提高了少样本3D点云分割的性能，并在多个基准测试中得到了广泛验证。

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [63] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: SRC通过迭代校准来解决LVLM中基本原理和答案之间不一致的问题，从而提高其在多个基准测试中的感知、推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在视觉问答方面表现出强大的能力，但在使基本原理与生成的答案保持一致方面仍然存在困难，这会导致推理不一致和响应不正确。

Method: 本研究提出了自基本原理校准（SRC）框架，通过以下步骤迭代地校准基本原理和答案之间的对齐：（1）采用轻量级的“基本原理微调”方法，修改模型的响应格式，要求在推导答案之前提供基本原理，而无需显式提示。（2）为每个样本从微调的LVLM中搜索一组多样化的候选答案。（3）使用定制的评分模型R-Scorer提出一种成对评分策略，以评估候选答案的基本原理质量和事实一致性。（4）基于置信度加权的偏好策展过程，将对齐校准解耦为偏好微调。

Result: SRC框架能够显著提高LVLM在多个基准测试中的感知、推理和泛化能力。

Conclusion: 研究结果强调了以基本原理为导向的对齐在挖掘LVLM潜力方面的重要性。

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [64] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 为了解决图像生成模型的安全风险（如深度伪造和版权侵权），研究人员提出了一种名为AntiPure的保护性扰动方法。该方法通过引入不易察觉的扰动，使图像在经过常用的“净化-定制”流程后仍能保持其安全性，有效防止恶意篡改。


<details>
  <summary>Details</summary>
Motivation: 现有的保护性扰动方法在面对图像净化过程时容易失效，无法有效防止深度伪造和版权侵权等安全风险。本研究旨在提出一种能够抵抗净化过程的保护性扰动方法，以增强图像的安全性。

Method: AntiPure通过两种引导机制实现抗净化能力：1. 块状频率引导：减少模型对净化后图像高频成分的影响；2. 错误时间步引导：干扰模型在不同时间步的去噪策略。这两种机制共同作用，在不影响图像感知的前提下，嵌入能够抵抗净化和定制流程的扰动。

Result: 实验结果表明，AntiPure在“净化-定制”工作流中，相比其他保护性扰动方法，能够实现最小的感知差异和最大的失真度，有效验证了其抗净化能力，并为评估净化方法的有效性提供了一个压力测试。

Conclusion: AntiPure是一种有效的保护性扰动方法，能够抵抗常见的图像净化和定制流程，显著增强了图像的安全性，并为评估净化方法的鲁棒性提供了一种新的视角。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [65] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 通过增加初始噪声与通用引导对齐的可能性来优化扩散模型中的初始噪声，以提高图像质量和提示遵循度。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型使用随机高斯噪声作为起点，这会影响最终输出的图像质量和提示遵循度。现有的噪声水平优化方法通常需要额外的有监督数据集、额外的网络或基于反向传播的优化，这限制了它们的实用性。

Method: 提出了一种名为噪声水平引导（NLG）的简单、高效、通用的噪声水平优化方法，通过增加初始噪声与通用引导对齐的可能性来优化初始噪声，无需额外的训练数据、辅助网络或反向传播。

Result: 实验证明，该方法可以提高输出生成质量和输入条件遵循度。

Conclusion: NLG是一种实用的、可扩展的扩散模型增强方法，可以无缝集成到现有的引导方法中，同时保持计算效率。

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [66] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个用于评估细粒度视觉计数的新基准数据集，旨在解决现有模型在区分和计数特定类型对象方面的不足，尤其是在细微差异和视觉歧义的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的计数模型（包括特定类别和大型视觉语言模型）在执行细粒度的、由用户意图驱动的计数任务方面能力尚不明确，需要一个专门的数据集来评估和改进这一能力。

Method: 创建了一个包含681张高分辨率图像的数据集PairTally，其中包含两个对象类别，并设计了跨类别和类别内两种计数设置，用于评估模型区分和计数的能力。对包括示例驱动方法、语言提示模型和大型视觉语言模型在内的多种先进模型进行了基准测试。

Result: 结果表明，尽管近期模型取得了进展，但在可靠地按照用户意图进行计数方面仍存在困难，特别是在处理细粒度和视觉上模糊的案例时。

Conclusion: PairTally数据集为诊断和改进细粒度视觉计数系统提供了一个新的基础，突显了当前模型在理解和执行用户特定计数意图方面的局限性。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [67] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，将大型多模态模型的区域级语义转移到轻量级视觉对象检测器中，实现了高效的跨架构对齐。


<details>
  <summary>Details</summary>
Motivation: 将大型视觉-语言模型（如LLaVA）的区域级多模态语义迁移到轻量级的纯视觉对象检测器（如YOLO）中，以提高其性能。

Method: MOCHA使用一个翻译模块将学生特征映射到联合空间，并通过一个双目标损失函数指导学生和翻译器的训练，该损失函数同时强制执行局部对齐和全局关系一致性。这种方法在对象级别上操作，无需修改教师模型或在推理时需要文本输入。

Result: 在四个个性化检测基准的少样本场景下，MOCHA相比基线方法取得了持续的性能提升，平均得分提高了+10.1。

Conclusion: MOCHA是一种有效的知识蒸馏方法，即使其结构紧凑，也能实现与大型多模态模型相当的性能，适用于实际部署。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [68] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 YOLO-FEDER FusionNet 的增强型无人机检测框架，通过融合通用目标检测和伪装目标检测技术，并改进训练数据、特征融合和骨干网络设计，显著提高了在复杂视觉环境下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 在视觉复杂环境中，背景杂波、目标尺度小以及伪装效果使得无人机检测充满挑战。传统的通用目标检测器（如 YOLO）在低纹理场景下表现良好，但在目标与背景区分度低且杂波较多的场景下性能会下降。

Method: 本研究提出了 YOLO-FEDER FusionNet，一个集成了通用目标检测和伪装目标检测技术的检测框架。研究改进了训练数据组成（使用大规模照片级真实感合成数据和少量真实世界样本）、特征融合策略（评估了中间多尺度 FEDER 特征的贡献）以及骨干网络设计（在多个 YOLO 骨干网络配置上进行了基准测试）。

Result: 实验结果表明，结合中间 FEDER 特征和骨干网络升级能够显著提升检测性能。在最优配置（YOLO-FEDER FusionNet 结合 YOLOv8l 骨干网络和 DWD 模块提取的 FEDER 特征）下，与初始基线相比，在 IoU 阈值为 0.5 时，假阴性率（FNR）降低了高达 39.1 个百分点，平均精度均值（mAP）提高了高达 62.8 个百分点。

Conclusion: 通过融合通用目标检测和伪装目标检测技术，并对训练数据、特征融合和骨干网络进行系统性改进，YOLO-FEDER FusionNet 在复杂视觉环境中显著提升了无人机检测的准确性和鲁棒性。

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [69] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一个强大的视觉-语言基础模型，在图像和视频理解及推理方面取得了最先进的性能，其主要优势在于数据处理、渐进式训练框架和高效的MoE架构。


<details>
  <summary>Details</summary>
Motivation: 介绍SAIL-VL2，一个用于全面多模态理解和推理的开源视觉-语言基础模型（LVM），作为SAIL-VL的继任者，SAIL-VL2在2B和8B参数规模下，在各种图像和视频基准测试中取得了最先进的性能，展示了从细粒度感知到复杂推理的强大能力。

Method: SAIL-VL2的有效性由三个核心创新驱动：1. 具有评分和过滤策略的大规模数据整理流程，提高了字幕、OCR、QA和视频数据的质量和分布，提高了训练效率。2. 渐进式训练框架，从强大的预训练视觉编码器（SAIL-ViT）开始，通过多模态预训练，最终达到思维融合SFT-RL混合范式，系统地增强模型能力。3. 架构的进步，从密集的LLM扩展到高效的稀疏混合专家（MoE）设计。

Result: SAIL-VL2在106个数据集上展示了有竞争力的性能，并在MMMU和MathVista等具有挑战性的推理基准上取得了最先进的结果。此外，在OpenCompass排行榜上，SAIL-VL2-2B在4B参数规模以下的官方发布的开源模型中排名第一。

Conclusion: SAIL-VL2通过其先进的数据处理、渐进式训练框架和MoE架构，在视觉-语言理解和推理方面取得了显著的成就，为开源多模态社区提供了一个高效且可扩展的基础。

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [70] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: 该研究提出了一种名为PROFUSEme的多模态融合方法，用于在手术时预测前列腺癌复发（BCR），并取得了优于其他方法的性能。


<details>
  <summary>Details</summary>
Motivation: 近30%的前列腺癌（PCa）患者在根治性前列腺切除术（RP）后会出现生化复发（BCR），这与死亡率增加有关。在RP时准确预测BCR有助于及时的临床决策和改善患者预后。

Method: 提出了一种名为PROFUSEme的预测方法，该方法学习临床、放射和病理数据的跨模态交互，并结合了Cox比例风险回归器。

Result: 该方法在内部5折交叉验证框架下达到了0.861（$\sigma=0.112$）的平均C指数，在CHIMERA 2025挑战赛的验证排行榜上达到了0.7103的C指数，优于晚期融合方法。

Conclusion: 所提出的PROFUSEme方法在预测前列腺癌患者的生化复发方面表现出优越的性能。

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [71] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate 是一个用于角色动画和替换的统一框架，能够根据参考视频生成高保真角色动画，或将角色无缝集成到参考视频中。


<details>
  <summary>Details</summary>
Motivation: 为了实现角色动画和替换的统一，并生成高保真、可控且富有表现力的角色视频，同时实现无缝的环境集成。

Method: 提出 Wan-Animate 框架，基于 Wan 模型，采用修改后的输入范式区分参考条件和生成区域；使用空间对齐的骨骼信号复制身体运动，提取隐式面部特征重现表情；引入辅助 Relighting LoRA 模块以增强环境集成，保持角色外观一致性并应用环境光照和色调。

Result: 实验结果表明 Wan-Animate 达到了最先进的性能。

Conclusion: Wan-Animate 成功实现了角色动画和替换的统一，并在性能上取得了最先进的成果，未来将开源模型和代码。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [72] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 当前的多目标跟踪（MOT）算法在低质量视频方面表现不佳。本文提出了一种视觉语义增强（VSE-MOT）框架，利用视觉-语言模型提取全局视觉语义信息，并结合MOT-Adapter和VSFM模块进行特征融合，以提升在低质量视频中的跟踪性能。实验结果表明，VSE-MOT在低质量视频场景中比现有方法有8%-20%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的多目标跟踪（MOT）算法在处理低质量视频时性能会显著下降，因此，提升MOT算法在真实世界低质量视频场景下的应用能力具有重要意义。

Method: 提出了一种视觉语义增强引导的多目标跟踪（VSE-MOT）框架。该框架采用三分支结构，利用视觉-语言模型提取全局视觉语义信息并与查询向量融合。引入了多目标跟踪适配器（MOT-Adapter）将视觉语义信息适配于MOT任务，并设计了视觉语义融合模块（VSFM）来增强特征融合效果。

Result: 通过大量实验验证了VSE-MOT在真实世界低质量视频场景下的有效性和优越性。其跟踪性能指标比现有方法高约8%-20%，并且在常规场景下也保持了稳健的性能。

Conclusion: VSE-MOT框架能够有效提升多目标跟踪在低质量视频场景下的性能。

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [73] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: 该论文首次将 DINOv3 模型应用于零样本异常检测 (ZSAD)，并提出了 AD-DINOv3 框架来解决预训练数据与异常检测任务之间的域偏差以及全局语义偏见导致的细微异常识别困难。通过引入轻量级适配器和异常感知校准模块 (AACM)，AD-DINOv3 提高了模型在多种基准测试中的性能，展示了其作为通用 ZSAD 框架的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的零样本异常检测 (ZSAD) 方法多基于 CLIP 模型，但随着 DINOv3 等视觉基础模型在表征能力上的突破，探索其在 ZSAD 任务中的应用成为新的研究方向。然而，直接应用 DINOv3 面临域偏差和全局语义偏见导致的细微异常识别困难。因此，本研究的动机是克服这些挑战，开发一种新的 ZSAD 框架。

Method: 本研究提出了 AD-DINOv3 框架，将异常检测表述为多模态对比学习问题。该框架使用 DINOv3 提取视觉特征（patch tokens 和 CLS token），并利用 CLIP 文本编码器处理正常和异常的文本提示。为了解决域偏差，引入了轻量级适配器来校准两种模态的表征。此外，设计了异常感知校准模块 (AACM) 来引导 CLS token 关注异常区域，而非通用前景语义，以增强区分能力。

Result: 在八个工业和医学基准测试上进行的广泛实验表明，AD-DINOv3 的性能与现有最先进的方法相当或更优。

Conclusion: AD-DINOv3 框架成功地将 DINOv3 应用于零样本异常检测任务，并通过引入适配器和异常感知校准模块有效解决了域偏差和全局语义偏见问题，证明了其作为通用 ZSAD 框架的有效性和优越性。

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [74] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的弱监督视听视频解析方法，通过引入分段级伪监督和类别感知的跨模态对齐来提升性能。


<details>
  <summary>Details</summary>
Motivation: 以往的弱监督视听视频解析方法在没有时间戳的情况下，主要关注全局预测的优化，忽略了稳定的分段级监督和类别感知的跨模态对齐。

Method: 研究提出了两种策略：1. 指导性的伪监督框架，利用指数移动平均（EMA）生成可靠的分段级掩码；2. 类别感知的跨模态一致性（CMA）损失，对齐可靠分段中的音频和视觉嵌入。

Result: 在LLP和UnAV-100数据集上的评估显示，该方法在多个指标上均达到了最先进（SOTA）的性能。

Conclusion: 提出的EMA伪监督框架和CMA损失能够提供稳定的时序监督和跨模态对齐，有效提升弱监督视听视频解析的性能。

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


### [75] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: ViT在语义分割方面表现出色，但计算和内存成本高。STEP框架通过动态块合并和早期剪枝提高了效率，同时保持了准确性。dCTS网络实现了块合并，而早期退出机制则删除了高置信度的块。


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers（ViTs）在语义分割中计算和内存成本高的问题。

Method: 提出STEP（SuperToken and Early-Pruning）混合标记缩减框架，结合动态块合并和标记剪枝。核心是dCTS（一种基于CNN的轻量级策略网络），用于灵活地合并成超块。编码器块还集成了早期退出机制，用于移除高置信度的超块。

Result: 在高达1024x1024的高分辨率语义分割基准测试中，单独使用dCTS可将标记数量减少2.5倍，计算成本降低2.6倍，吞吐量提高3.4倍（使用ViT-Large）。完整的STEP框架可将计算复杂度降低4倍，推理速度提高1.7倍，准确率下降不超过2.0%。高达40%的标记可以在到达最终编码器层之前被自信地预测并停止。

Conclusion: STEP框架通过引入dCTS和早期退出机制，有效解决了ViT在语义分割中的效率问题，同时保持了较高的准确性。

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [76] [CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts](https://arxiv.org/abs/2509.14104)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 通过集成软混合专家（Soft MoE）机制，提出CSM（Cross-Sensor Mixture-of-Experts）模型，在提高效率的同时保持或改进了遥感基础模型的表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感基础模型（RS FMs）在训练和推理时计算量大，或表示能力有限，限制了其实际应用。

Method: 将Soft MoE机制集成到CSMAE模型中，实现特定于模态的专家专业化和跨传感器表示学习。引入主题-气候描述符驱动的采样策略来构建训练集。

Result: CSMoE模型在场景分类、语义分割和基于内容的图像检索方面，计算需求降低，同时保持或提高了表示性能。与最先进的RS FMs相比，CSMoE在表示能力、准确性和计算效率方面取得了更好的权衡，计算效率提高一倍以上。

Conclusion: 所提出的集成Soft MoE的适配器能够创建计算高效的RS FMs，同时保持具有竞争力的性能。

Abstract: Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.

</details>


### [77] [Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows](https://arxiv.org/abs/2509.14119)
*Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T. W. Wong,Hao Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种新的虚拟染色框架，通过级联配准机制解决配准不准确的问题，在多个数据集上显著优于现有方法，尤其是在处理错位数据时。


<details>
  <summary>Details</summary>
Motivation: 传统的组织病理学诊断需要多种染色，过程耗时、耗力且不环保。虚拟染色是一种有前景的替代方案，但现有方法依赖于难以获得的配准数据，限制了其临床应用。

Method: 提出了一种具有级联配准机制的虚拟染色框架，以解决生成输出和真实值之间的空间不匹配问题。

Result: 在五个数据集上的实验结果表明，该方法显著优于最先进的模型，在内部数据集上平均提高了3.2%，在外部数据集上提高了10.1%。在错位数据上，与基线模型相比，信噪比提高了23.8%。

Conclusion: 该框架具有出色的鲁棒性，简化了虚拟染色的数据采集过程，并为虚拟染色的发展提供了新的见解。

Abstract: Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.

</details>


### [78] [Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection](https://arxiv.org/abs/2509.14120)
*Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 社交媒体滤镜会降低人脸识别和Deepfake检测的性能。


<details>
  <summary>Details</summary>
Motivation: 研究社交媒体滤镜对Deepfake和人脸合成攻击检测性能的影响。

Method: 评估多种先进的Deepfake和人脸合成攻击检测器在应用平滑滤镜前后的性能。

Result: 人脸滤镜会导致Deepfake和人脸合成攻击检测性能下降。

Conclusion: 需要开发更能抵抗面部增强技术的鲁棒性检测模型。

Abstract: Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.

</details>


### [79] [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142)
*Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen,Yicen Tian,Yilin Tao,Yin Tang,Yipeng Lin,Yiqing Wang,Yiting Xi,Yongkang Yu,Yumei Li,Yuxin Qin,Yuying Chen,Yuzhe Cen,Zhaofan Zou,Zhaohong Liu,Zhehao Shen,Zhenglin Du,Zhengyang Li,Zhenni Huang,Zhenwei Shao,Zhilong Song,Zhiyong Feng,Zhiyu Wang,Zhou Yu,Ziang Li,Zihan Zhai,Zijian Zhang,Ziyang Peng,Ziyun Xiao,Zongshu Li*

Main category: cs.CV

TL;DR: 这篇论文回顾了 MARS2 2025 挑战赛，该挑战赛专注于多模态推理，旨在通过大型基准测试整合多模态机器学习和大型语言模型（LLM）的不同方法，以跟上该领域的最新进展。今年的比赛侧重于现实世界和专业场景，以扩展多模态大型语言模型（MLLM）的应用范围，并发布了 Lens 和 AdsQA 两个数据集。比赛评估了 40 多个基线模型，并设立了三个竞赛赛道：现实世界场景中的视觉定位（VG-RS）、具有空间意识的视觉问答（VQA-SA）以及创意广告视频中的视觉推理（VR-Ads）。最终，吸引了 76 支团队注册，提交了 40 多个有效参赛作品。所有数据、代码和排名均公开提供。


<details>
  <summary>Details</summary>
Motivation:  MARS2 挑战赛旨在汇集不同的多模态机器学习和大型语言模型（LLM）方法，通过大型基准测试来跟上多模态推理领域快速发展的现状。今年的比赛特别关注现实世界和专业场景，以拓宽多模态大型语言模型（MLLM）的应用范围。

Method:  MARS2 挑战赛发布了 Lens 和 AdsQA 两个数据集，分别用于日常场景中的通用推理和广告视频中的专业推理。对 40 多个基线模型（包括通用 MLLM 和特定任务模型）进行了评估，并设立了三个竞赛赛道：现实世界场景中的视觉定位（VG-RS）、具有空间意识的视觉问答（VQA-SA）和创意广告视频中的视觉推理（VR-Ads）。

Result:  比赛吸引了来自知名学术界和工业界的 76 支团队注册，并收到了 40 多个有效参赛作品（超过 1200 个）。

Conclusion:  MARS2 挑战赛成功地汇集了多模态推理领域的各种方法，并通过发布数据集、代码和排名，为研究人员提供了一个跟踪和推进该领域发展的平台。其成果和资源（包括 40 多个基线模型和 15 个参与者的方法）可在 MARS2 工坊网站和 GitHub 上公开获取，并会持续更新。

Abstract: This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.

</details>


### [80] [An Exploratory Study on Abstract Images and Visual Representations Learned from Them](https://arxiv.org/abs/2509.14149)
*Haotian Li,Jianbo Jiao*

Main category: cs.CV

TL;DR: 抽象图像包含的语义信息不如传统光栅图像，本研究提出HAID数据集来探究抽象图像的表示能力，并与光栅图像进行比较。


<details>
  <summary>Details</summary>
Motivation: 探究抽象图像在视觉语义信息传递和视觉任务方面的潜力，以及造成其性能差距的原因。

Method: 提出HAID数据集，包含从不同抽象级别生成的多层级抽象图像，并在该数据集上训练和评估传统视觉系统在分类、分割和目标检测等任务上的表现。

Result: 在HAID数据集上进行了全面的实验，比较了光栅图像和抽象图像表示在不同视觉任务上的表现。

Conclusion: 讨论了抽象图像作为传递视觉语义信息和促进视觉任务的有效性。

Abstract: Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.

</details>


### [81] [BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2509.14151)
*Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang*

Main category: cs.CV

TL;DR: BEVUDA++是一个新颖的几何感知教师-学生框架，通过可靠的深度教师（RDT）和几何一致学生（GCS）模型来解决自动驾驶BEV感知中的域转移问题，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有BEV感知方法在跨域场景中存在显著的性能下降问题，即域转移问题，但以往研究对此关注不足。

Method: 提出了一种新颖的几何感知教师-学生框架BEVUDA++，包含可靠深度教师（RDT）和几何一致学生（GCS）模型。RDT通过融合目标LiDAR和可靠的深度预测来生成深度感知信息，以增强目标域的Voxel和BEV特征提取。GCS将多空间特征映射到统一的几何嵌入空间，以缩小域间数据分布的差距。此外，还引入了不确定性引导指数移动平均（UEMA）来减少域转移引起的误差累积。

Result: 在四个跨域场景的综合实验中，BEVUDA++在BEV 3D目标检测任务上取得了最先进的性能，例如在Day-Night适应性任务上，NDS提升了12.9%，mAP提升了9.5%。

Conclusion: BEVUDA++有效解决了BEV感知中的域转移问题，并通过教师-学生框架、深度感知信息融合和统一几何嵌入空间，显著提升了跨域3D目标检测的性能。

Abstract: Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.

</details>


### [82] [Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark](https://arxiv.org/abs/2509.14227)
*Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel*

Main category: cs.CV

TL;DR: $\	ext{Cin	extasciicircum}aste$ 是一个包含 1805 个电影场景的基准，用于评估长篇电影理解能力，现有模型在该基准上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准在评估模型对长篇叙事内容的细粒度推理能力方面存在不足，$\	ext{Cin	extasciicircum}aste$ 旨在弥补这一差距。

Method: $\	ext{Cin	extasciicircum}aste$ 数据集包含 200 部电影的 1805 个场景，生成了 3119 个多项选择题，利用 GPT-4o 结合多种信息源生成问题，并采用两阶段过滤流程（上下文独立性过滤和上下文真实性过滤）确保问题质量。

Result: 现有的大型多模态模型（MLLMs）在 $\	ext{Cin	extasciicircum}aste$ 基准上表现不佳，准确率最高仅为 63.15%，表明长时序推理是关键瓶颈。

Conclusion: $\	ext{Cin	extasciicircum}aste$ 基准揭示了当前 MLLMs 在细粒度上下文理解和长篇电影理解方面面临的重大挑战，预示着相关领域需要进一步的研究和发展。

Abstract: While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.

</details>


### [83] [GenExam: A Multidisciplinary Text-to-Image Exam](https://arxiv.org/abs/2509.14232)
*Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo*

Main category: cs.CV

TL;DR: GenExam 是第一个多学科文本到图像考试基准，包含 1,000 个样本，跨越 10 个科目，并使用四级分类法组织的考试风格提示。它提供了详细的分数点，用于精确评估语义正确性和视觉合理性。现有最先进的模型在该基准上的得分不到 15%，突显了其挑战性，并为通用人工智能的进展提供了见解。


<details>
  <summary>Details</summary>
Motivation: 现有的考试风格基准主要关注理解和推理任务，而当前的生成基准则侧重于世界知识和视觉概念的阐述，忽略了对严格绘图考试的评估。因此，需要一个专门针对文本到图像生成任务的、类似考试的基准。

Method: 引入 GenExam，这是第一个多学科文本到图像考试基准，包含 1,000 个样本，跨越 10 个科目，并使用四级分类法组织的考试风格提示。每个问题都配有真实图像和细粒度的评分点，以实现对语义正确性和视觉合理性的精确评估。

Result: 实验表明，即使是像 GPT-Image-1 和 Gemini-2.5-Flash-Image 这样的最先进模型，在该基准上的得分也低于 15%，而大多数模型得分接近 0%，这表明该基准具有巨大的挑战性。

Conclusion: GenExam 通过将图像生成视为一场考试，为模型整合知识、推理和生成的能力提供了严格的评估，并为实现通用人工智能的道路提供了见解。

Abstract: Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [84] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: Gender-neutral rewriting (GNR) in Italian is challenging for LLMs. This paper evaluates LLMs for Italian GNR, introducing a framework to measure neutrality and semantic fidelity. Open-weight LLMs perform well, and fine-tuned models achieve comparable or better results with smaller sizes. The study also discusses the trade-off between neutrality and meaning preservation in training data.


<details>
  <summary>Details</summary>
Motivation: The motivation is to conduct the first systematic evaluation of state-of-the-art large language models (LLMs) for gender-neutral rewriting (GNR) in Italian, a task that is particularly challenging due to the grammatical-gendered nature of the language.

Method: The study compares few-shot prompting across multiple LLMs, fine-tunes selected models, and applies targeted cleaning to improve task relevance. A two-dimensional framework is introduced to measure both neutrality and semantic fidelity of the GNR output.

Result: Open-weight LLMs outperform the existing dedicated Italian GNR model. Fine-tuned models achieve performance comparable to or better than the best open-weight LLM, but with significantly smaller model sizes. A trade-off between optimizing training data for neutrality and meaning preservation is discussed.

Conclusion: The evaluation demonstrates the effectiveness of LLMs for Italian GNR, with fine-tuned models offering a compelling balance of performance and efficiency. The findings also highlight important considerations for future development regarding the optimization of training data.

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [85] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: Op-Fed是一个包含1044个句子及其上下文的人工标注数据集，旨在分析美联储公开市场委员会（FOMC）会议纪要中的观点和货币政策立场。该数据集解决了类别不平衡和句子间依赖性两大挑战，并被用于评估大型语言模型（LLM）在相关任务上的表现，结果显示LLM在区分货币政策立场方面仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: FOMC的货币政策决策影响广泛，但其会议纪要中的观点和立场分析缺乏有效工具。本研究旨在创建一个数据集，以支持对FOMC会议纪要中关于货币政策的观点和立场进行更深入的分析。

Method: 研究人员创建了一个包含1044个标注句子的Op-Fed数据集，解决了类别不平衡（少于8%的句子表达非中立立场）和句子间依赖性（65%的实例需要超越句子层级的上下文）的挑战。他们开发了一个五阶段的层次化模式来分离观点、货币政策和立场，并使用主动学习来选择标注实例，将所有方面积极实例的数量增加了一倍。

Result: 使用Op-Fed数据集，研究发现一个表现最佳的闭源LLM在零样本观点分类任务上达到了0.80的准确率，但在零样本货币政策立场分类任务上仅达到0.61的准确率，低于人类基线0.89。

Conclusion: Op-Fed数据集为未来模型训练、置信度校准以及作为未来标注工作的种子数据集提供了宝贵的资源，有助于提升模型在理解和分析FOMC会议纪要中的货币政策相关信息方面的能力。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [86] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: DSTC12 Track 1 评估了对话系统在多维度、语言和安全方面的表现。在多维度评估方面，Llama-3-8B 基线表现最佳，但仍有很大改进空间。在多语言和多文化安全检测方面，参赛队伍在多语言子任务上优于 Llama-Guard-3-1B 基线，但在文化子任务上基线表现更佳，凸显了文化意识安全方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 对话系统评估的挑战，尤其是在传统指标不足、安全定义狭隘或存在文化偏见的情况下，DSTC12 Track 1 旨在弥合这些差距。

Method: Track 1 包含两个子任务：(1) 对话级、多维自动评估指标，(2) 多语言和多文化安全检测。本文介绍了提供给参与者的数据集和基线，以及两个子任务的提交评估结果。

Result: 子任务 1：Llama-3-8B 基线取得了最高的平均 Spearman 相关系数 (0.1681)。子任务 2：参赛队伍在多语言安全子集上显著优于 Llama-Guard-3-1B 基线 (最高 ROC-AUC 0.9648)，但在文化子集上基线表现更优 (0.5126 ROC-AUC)。

Conclusion: DSTC12 Track 1 的结果表明，对话系统评估在多维度和尤其是在文化意识安全方面仍需重大改进。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [87] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: LLM 适应性是必要的，因为它们经常面临未在训练数据中遇到的任务。我们提出了一个分析框架，使用迁移学习矩阵和降维来研究跨任务交互。通过训练和分析 10 个模型，我们确定了潜在能力和迁移学习的副作用。我们的研究结果表明，表面数据集相似性或源数据质量并非决定性因素，而源数据集的隐藏统计因素（如类别分布和生成长度倾向）以及特定的语言特征更为重要。该研究为更可预测、更有效的 LLM 适应提供了见解。


<details>
  <summary>Details</summary>
Motivation: 由于 LLM 经常需要处理在训练数据中未遇到的任务，因此需要一种在不同数据集上进行迁移学习的方法，以应对分布外查询。本研究旨在解决这一实际需求。

Method: 开发了一个分析框架，该框架结合了迁移学习矩阵和降维技术，以研究跨任务交互。训练了 10 个模型，以识别潜在能力（如推理、情感分类、自然语言理解、算术）并分析迁移学习的副作用。

Result: 研究结果表明，性能提升通常无法通过表面数据集相似性或源数据质量来解释。相反，源数据集的隐藏统计因素（例如类别分布和生成长度倾向）和特定的语言特征对 LLM 的适应性具有更大的影响。

Conclusion: 该研究深入探讨了迁移学习的复杂动态，为实现更可预测和更有效的 LLM 适应铺平了道路。

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [88] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: LLMs can be controlled at the neuron level to detect and manage ambiguity in questions.


<details>
  <summary>Details</summary>
Motivation: Ambiguity in real-world questions is common, but LLMs often provide confident answers without seeking clarification. This work aims to address this by understanding and controlling how LLMs process ambiguity.

Method: Identify and isolate 'Ambiguity-Encoding Neurons' (AENs) responsible for processing ambiguity in LLMs. Analyze their emergence in shallow layers and demonstrate control over LLM behavior by manipulating these neurons.

Result: A small number of AENs (as few as one) encode ambiguity information, which can be detected with high accuracy using probes. These probes outperform baseline methods. Manipulating AENs allows control over LLM responses, shifting from direct answers to abstention.

Conclusion: LLMs possess compact internal representations for question ambiguity, which can be interpreted and controlled at the neuron level. This opens possibilities for more nuanced and controlled LLM interactions.

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [89] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 本研究提出了CL$^2$GEC，一个针对中文学术写作的持续学习语法纠错基准，以解决现有CGEC系统在多学科适应性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错（CGEC）系统在多学科学术写作方面的适应性不足，缺乏专门的基准，并且忽视了持续学习（CL）在处理领域特异性语言变异和防止灾难性遗忘方面的潜力。

Method: 构建了一个包含10,000个人工标注句子的CL$^2$GEC基准，涵盖10个学科领域。在持续学习的设置下，模拟了对不同学术学科的顺序暴露，并评估了大型语言模型在顺序微调、参数高效适应以及四种代表性CL算法下的表现，使用了标准GEC指标和适应任务级变异的CL指标。

Result: 实验结果表明，基于正则化的方法比基于重放或简单顺序的方法更能有效地缓解遗忘。

Conclusion: CL$^2$GEC基准为未来在不同学术领域进行自适应语法纠错的研究奠定了严谨的基础。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [90] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG是一个用于受控文本生成的框架，通过模拟多智能体工作流来增强控制精度和复杂性，并在多个公共数据集上达到了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理（NLP）领域，特别是在受控文本生成（CTG）方面，实现细粒度的条件控制仍然面临诸多挑战。在实际场景和在线应用中，成本、可扩展性、领域知识学习和更精确的控制提出了更高的要求。

Method: 提出了一种新颖且可扩展的框架AgentCTG，通过模拟多智能体工作流中的控制和调节机制，来增强文本生成的精确度和复杂控制能力。研究了不同智能体之间的协作方法，并引入了一个自动提示模块来提高生成效果。

Result: AgentCTG在多个公共数据集上取得了最先进的成果。在角色驱动的改写任务上，该方法显著提高了内容交付能力，增强了在线导航中的驾驶体验，并通过优化上下文相关文本的生成，实现了更具沉浸感的交互，提高了用户参与度。

Conclusion: AgentCTG通过模拟多智能体工作流，有效解决了受控文本生成中的精确控制和复杂控制问题，并在多个基准测试和实际应用中展现了优越的性能。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [91] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: CARE框架通过原生检索增强推理，解决LLM的上下文保真度问题，提高检索准确性和答案生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理给定信息时，会产生不一致的答案，现有方法要么依赖昂贵的监督微调，要么在不一定能提高给定上下文利用率的情况下训练模型进行网络搜索。

Method: 提出CARE（Contextual Answer REtrieval）框架，一种新颖的原生检索增强推理框架，教会LLM在其推理过程中显式地整合上下文证据，并利用模型自身的检索能力。该方法需要有限的标注证据数据，通过在推理链中策略性地检索上下文标记来显著提高检索准确性和答案生成性能。

Result: 在多个真实世界和反事实问答基准上进行的大量实验表明，CARE方法在性能上大大优于监督微调、传统的检索增强生成方法和外部检索解决方案。

Conclusion: 该工作代表了使LLM在知识密集型任务中更准确、更可靠、更高效的一个根本性进展。

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [92] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: LLMs在处理涉及数字和逻辑表达式的日语句子推理方面表现不佳，尤其是在处理比较性语言时。提示格式和少样本示例会影响模型的性能。包含逻辑语义表示的提示有助于提高模型在困难推理问题上的准确性。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型(LLMs)在处理包含数字和逻辑表达式的自然语言推理(NLI)方面的能力，尤其是在非英语语言（如日语）中的比较性推理方面，研究不足。

Method: 构建了一个专注于比较性日语NLI数据集，并在零样本和少样本场景下评估了不同LLMs的性能。实验中还使用了包含逻辑语义表示的提示。

Result: LLMs在处理日语比较性NLI时性能不稳定，对提示格式和少样本示例中的标签敏感。模型难以处理日语特有的语言现象。包含逻辑语义表示的提示可以提高模型在困难推理问题上的表现。

Conclusion: LLMs在处理日语比较性NLI方面仍存在挑战，需要进一步优化以提高其鲁棒性和处理特定语言现象的能力。逻辑语义表示的提示是一种有前景的改进方法。

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [93] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: LLMs 经过 DSPy 优化后，在处理临床文本和结构化 EHR 数据方面取得了与专门的多模态系统相当的性能，同时更简单、更具适应性。


<details>
  <summary>Details</summary>
Motivation: 探索 LLMs 在处理包含时间序列等结构化数据的临床分类任务方面的能力。

Method: 使用基于 DSPy 的提示优化来调整指令调谐 LLMs，以联合处理临床笔记和结构化 EHR 输入。

Result: 所提出的方法在性能上达到了与专门的、更复杂的多模态系统相当的水平，并且具有更高的适应性。

Conclusion: 经过 DSPy 优化的 LLMs 可以有效地处理临床文本和结构化 EHR 数据，为临床分类任务提供了一种简化且适应性强的方法。

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [94] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: LLM幻觉是一个关键问题。DSCC-HS是一个新的框架，它在生成过程中主动干预，以减少幻觉。它使用一个代理模型，该模型被训练成事实对齐代理（FAP）和幻觉检测代理（HDP）。在推理时，这两个代理会实时地指导大型目标模型。DSCC-HS可以即插即用，无需修改目标模型。在TruthfulQA和BioGEN上的实验表明，DSCC-HS达到了最先进的性能，在TruthfulQA上实现了99.2%的事实一致性率（FCR），在BioGEN上获得了最高的FActScore（46.50）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的幻觉是其可靠部署的一个重大障碍。

Method: 我们提出了一个名为**动态自增强校准幻觉抑制（DSCC-HS）** 的新颖、主动框架，该框架在自回归解码过程中进行干预。DSCC-HS受到双过程认知理论的启发，使用一个紧凑的代理模型，该模型以对抗性角色训练为事实对齐代理（FAP）和幻觉检测代理（HDP）。在推理过程中，这些代理通过在每个解码步骤注入实时转向向量（FAP和HDP logits之差）来动态地引导大型目标模型。

Result: 在TruthfulQA和BioGEN上的实验表明，DSCC-HS取得了最先进的性能。在TruthfulQA上，它达到了99.2%的事实一致性率（FCR）。在长格式的BioGEN基准测试中，它获得了最高的FActScore，为46.50。

Conclusion: 这些结果证明了DSCC-HS是提高LLM事实性的一个原则性和有效解决方案。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [95] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 本研究利用自然语言处理（NLP）技术开发了一个能够识别放射肿瘤学领域高严重性事件报告的筛选工具，并验证了其跨机构的有效性。


<details>
  <summary>Details</summary>
Motivation: 手动审查事件报告以进行安全和质量改进既耗时又需要专业知识，因此需要开发自动化的工具。

Method: 研究人员使用了两个数据集（来自Inst.和IAEA SAFRON）来训练和评估两种NLP模型（SVM和BlueBERT）。他们还测试了模型的泛化能力，包括在不同机构数据集之间进行迁移学习。

Result: 在Inst.数据集上，SVM和BlueBERT的分类性能（AUROC）分别为0.82和0.81。在未进行迁移学习的情况下，SF数据集上的性能有限（AUROC分别为0.42和0.56）。通过在两个数据集上进行微调的BlueBERT_TRANSFER模型，SF数据集的性能提高到AUROC 0.78。在经过人工编辑的数据集上，SVM和BlueBERT_TRANSFER模型的性能与人类相当。

Conclusion: 研究成功开发了跨机构的NLP模型，能够有效地从放射肿瘤学事件报告中识别高严重性事件，其性能与人类专家相当。

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [96] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 现有方法需要训练辅助模型来解决提示过长的问题，但计算成本高。本文提出了一种名为DSPC的两阶段、无需训练的方法来压缩提示。


<details>
  <summary>Details</summary>
Motivation: 提示过长会导致更高的计算成本，而现有的提示压缩方法需要训练辅助模型，增加了额外的计算量。

Method: DSPC方法包含两个阶段：粗粒度阶段通过TF-IDF过滤语义相关性低的句子；细粒度阶段通过注意力贡献、跨模型损失差异和位置重要性评估标记的重要性，以修剪低效标记。

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo模型上进行了验证，DSPC在有限的token预算下取得了持续的改进。例如，在Longbench数据集的FewShot任务中，DSPC使用的token数量减少了3倍，性能仍达到49.17，比LongLLMLingua提高了7.76。

Conclusion: DSPC是一种有效的、无需训练的提示压缩方法，能够在显著减少token数量的同时保持甚至提高模型的性能。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [97] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本文提出了一种基于组合语义学的日语比较级推理系统ccg-jcomp，以解决日语自然语言推断（NLI）中的比较级理解难题。


<details>
  <summary>Details</summary>
Motivation: 日语比较级在形态和语义上与英语存在差异，难以直接套用现有的基于逻辑推理的系统，因此需要专门针对日语的系统。

Method: 提出了一种基于组合语义学的逻辑推理系统ccg-jcomp，并将其应用于包含比较级表达的日语NLI数据集进行评估。

Result: 通过将ccg-jcomp的准确率与现有的LLMs进行比较，证明了该系统的有效性。

Conclusion: 所提出的ccg-jcomp系统能够有效处理日语比较级，并在日语NLI任务上取得良好效果。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [98] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: LLM在阿拉伯语方言识别方面表现不佳，但LoRA微调模型效果最佳，甚至优于完全微调。


<details>
  <summary>Details</summary>
Motivation: 探索数据高效和参数高效的方法，以实现阿拉伯方言识别。

Method: 研究了不同的软提示策略（prefix-tuning, prompt-tuning, P-tuning, P-tuning V2）和LoRA重参数化，以及硬提示（零样本和少样本推理）。实验使用了阿拉伯语特定的编码器模型、主要数据集、开源解码器模型（包括Phi-3.5和SILMA）。

Result: LLM在零样本和少样本设置下识别方言细微差别的能力普遍较弱。软提示的编码器变体表现更好，而基于LoRA的微调模型效果最佳，优于完全微调。

Conclusion: LoRA微调是在阿拉伯方言识别任务上实现参数高效和高性能的最有效方法。

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [99] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: CAMPUS框架通过动态、基于能力的课程学习方法改进LLM的指令调优，克服了现有方法的固定性，并在实验中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 现有指令调优方法依赖静态的难度指标，无法适应模型训练过程中的能力变化，导致学习轨迹固定且可能次优。

Method: 提出CAMPUS框架，包含动态子课程选择、基于能力的课程调整和多难度调度。

Result: CAMPUS框架在与现有最先进的基线方法进行比较的广泛实验中，证明了其在高效指令调优方面的优越性能。

Conclusion: CAMPUS通过其动态和基于能力的课程学习方法，解决了现有指令调优方法中的课程僵化问题，并取得了优于现有技术的效果。

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [100] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 研究了显式语法性别标记对招聘职位排名系统的影响，并提出了一种控制性别因素的排名比较指标RBO来评估性别偏见。


<details>
  <summary>Details</summary>
Motivation: 研究显式语法性别标记如何影响招聘职位排名系统，并提出评估性别偏见的指标。

Method: 提出使用RBO（Rank-Biased Overlap）指标来比较排名，并生成包含阳性和阴性形式的职业名称的测试集，用于评估多语言模型的性别偏见。

Result: 评估了几个开箱即用的多语言模型，发现它们都存在不同程度的性别偏见。

Conclusion: 显式语法性别标记会对招聘职位排名系统产生性别偏见。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [101] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 现有方法无法同时提供全局和局部不确定性估计，而我们的几何框架可以。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在幻觉问题，现有方法在不确定性量化方面存在不足，特别是缺乏能够同时提供全局和局部不确定性估计的黑盒方法。

Method: 提出一种基于原型分析的几何框架，该框架利用响应嵌入的黑盒模型访问进行抽样。在全局层面，提出几何体积（Geometric Volume），用于衡量原型凸包的体积。在局部层面，提出几何怀疑度（Geometric Suspicion），对响应按可靠性排序，并通过优先选择响应来减少幻觉。

Result: 该框架在短格式问答数据集上的表现与现有方法相当或更优，在医疗数据集上表现更优。证明了凸包体积与熵之间的联系。

Conclusion: 提出的几何框架能够有效地进行不确定性量化，用于检测和减少大型语言模型的幻觉，并且在不同类型的数据集上都表现出优越的性能。

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [102] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: 2025年的AutoMin会议纪要任务包括英文和捷克语的项目会议和欧洲议会会议的结构化会议纪要，以及一个基于会议记录的问答任务。


<details>
  <summary>Details</summary>
Motivation: 本次AutoMin任务旨在推动自动会议纪要生成和基于会议记录的问答技术的发展。

Method: AutoMin任务包含两个子任务：1. 结构化会议纪要生成，涵盖英/捷克语和项目/欧洲议会会议。2. 基于会议记录的问答，包括英/捷克语的单一语言问答和基于英/捷克语会议记录的跨语言问答。

Result: 尽管2025年参与团队数量有所减少（记录任务1个，问答任务2个），但主办方引入了多个基线系统，以全面评估当前大语言模型在两项任务上的表现。

Conclusion: 2025年的AutoMin任务展示了在结构化会议纪要和问答方面的进展，并为评估大型语言模型提供了基准。

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [103] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 大型语言模型在处理德国方言时表现出显著的偏见，将负面特质与方言使用者相关联，并且在明确提及方言使用者时会加剧这种偏见。


<details>
  <summary>Details</summary>
Motivation: 研究人类文化重要组成部分——德语方言——的社会刻板印象是否会被大型语言模型（LLMs）复制，以评估LLMs的偏见。

Method: 构建了一个包含七种德语方言及其标准德语对应句的新评估语料库，并通过联想任务和决策任务来评估LLMs的方言命名偏见和方言使用偏见。

Result: 所有被评估的LLMs在联想任务中都表现出显著的方言命名和方言使用偏见，将负面形容词与德语方言使用者相关联。在决策任务中，模型也复制了这些偏见。与先前关于明确提及人口统计信息会最小化偏见的研究不同，本研究发现明确标注语言人口统计信息（德语方言使用者）反而会比隐性线索（如方言使用）放大偏见。

Conclusion: 研究结果表明，当前的LLMs在处理德语方言时存在显著的偏见，这与社会上对手语使用者存在的刻板印象一致。此外，明确提及方言使用者身份会加剧这种偏见，这与以往关于人口统计信息对偏见影响的研究结果相悖。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [104] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: LLM在处理复杂和敏感的社会偏见时可能出现与人类价值观不一致的问题。本研究通过分析12个LLM在不同类型偏见场景下的表现，发现LLM在特定类型场景下表现出一定的偏好，且同模型家族的LLM判断一致性较高。此外，研究还探讨了LLM对HVSB的理解能力，发现不同LLM在理解上无显著差异，但偏好自身生成的解释。最后，通过对小型LM进行微调，发现其生成的解释更具可读性，但模型可信度相对较低。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在处理社会偏见时与人类价值观的对齐情况，特别是探讨其在不同类型偏见场景下的表现差异，以及LLM对HVSB的理解和解释能力。

Method: 分析12个LLM在四种数据集和四种模型家族中的表现，比较不同模型参数规模、不同类型场景下的对齐率和攻击成功率。同时，研究LLM对HVSB的理解能力，并对小型LM进行微调以评估其解释能力。

Result: LLM在特定类型场景下表现出一定的偏好，且同模型家族的LLM判断一致性较高。LLM在理解HVSB方面无显著差异，但偏好自身生成的解释。微调后的小型LM生成的解释可读性更高，但模型可信度较低。

Conclusion: LLM在社会偏见场景下的对齐情况并非完全由模型规模决定，存在场景偏好和家族一致性。LLM对HVSB的理解能力相似，但存在“自说自话”的倾向。通过微调可以提升小型LM的解释可读性，但需权衡模型可信度。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [105] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 该研究提出了一个名为CER的新框架，用于生物医学事实核查，通过结合证据检索、大型语言模型推理和监督式真实性预测，以解决医疗领域错误信息的挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗领域错误信息（如疫苗犹豫、未经证实的疗法）对公众健康和对医疗系统的信任构成威胁。自动化事实核查面临生物医学领域的独特挑战，包括复杂术语、需要领域专业知识以及依据科学证据的重要性。

Method: CER框架整合了科学证据检索、利用大型语言模型进行推理，以及监督式真实性预测。它结合了大型语言模型的文本生成能力和先进的检索技术，用于检索高质量的生物医学科学证据，从而有效降低模型产生幻觉的风险，确保生成内容基于可验证的证据。

Result: 在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示，CER框架达到了最先进的性能，并展现出良好的跨数据集泛化能力。

Conclusion: CER框架通过整合证据检索、大型语言模型推理和监督式真实性预测，有效解决了生物医学事实核查的挑战，提高了事实核查的准确性和可靠性，并确保了结果的可验证性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [106] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER是一个结合了证据检索、大语言模型推理和监督式真实性预测的新型生物医学事实核查框架，通过整合科学证据检索能力和大型语言模型的文本生成能力，有效减轻了幻觉风险，确保生成内容基于可验证的、有据可查的来源。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息，从疫苗犹豫到未经证实的疗法，对公众健康和对医疗系统的信任构成了威胁。虽然机器学习和自然语言处理在自动事实核查方面取得了进展，但由于术语复杂、需要领域专业知识以及必须基于科学证据，验证生物医学声明仍然具有独特的挑战性。

Method: CER框架整合了科学证据检索、通过大语言模型进行推理以及监督式真实性预测。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示，CER实现了最先进的性能，并具有良好的跨数据集泛化能力。

Conclusion: CER框架通过整合科学证据检索、大语言模型推理和监督式真实性预测，有效解决了生物医学事实核查的挑战，并取得了优于现有方法的性能。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [107] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: LLMs在词义消歧（WSD）和生成任务中表现出强大的词义理解能力，在WSD任务上能与专业系统媲美，并能准确解释词义。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在理解词义方面的能力，特别是它们是否真正掌握了词语的含义。

Method: 1. 评估指令调优LLMs的词义消歧（WSD）能力，并与专用WSD系统进行比较。
2. 评估两个顶尖LLMs（开源和闭源）在定义生成、自由解释和示例生成三种生成任务中理解词义的能力。

Result: 在WSD任务中，GPT-4o和DeepSeek-V3等领先模型的表现与专用WSD系统相当，并且在不同领域和难度级别上表现出更强的鲁棒性。
在生成任务中，LLMs能够以高达98%的准确率解释词语在上下文中的含义，其中自由解释任务的表现最佳。

Conclusion: LLMs不仅在WSD任务上展现出与专业系统相当甚至更优的能力，而且在生成任务中也能有效且准确地解释词语的含义，尤其擅长自由形式的解释。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [108] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 多语言检索增强生成（mRAG）系统在处理多语言知识密集型查询时，存在对英语来源的偏见，尤其是在低资源语言和中间上下文位置的文档中，并且有时会牺牲文档相关性以偏好语言。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探究多语言检索增强生成（mRAG）系统中不同文档语言的混合是否会对生成和引用产生非预期的影响。

Method: 采用一种受控的方法，利用模型内部机制来衡量语言偏好，同时保持文档相关性等因素不变。实验跨越八种语言和六种开放权重模型。

Result: 研究发现，当查询为英语时，模型倾向于引用英语来源，并且这种偏见在低资源语言和中段上下文的文档中更为明显。此外，模型有时会为了语言偏好而牺牲文档相关性。

Conclusion: 多语言检索增强生成系统在引用时存在语言偏见，并非总是以信息量为唯一驱动因素，这揭示了语言模型如何利用多语言上下文和影响引用行为。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [109] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: wmt25 任务的提交，使用 COMET 框架，通过增强的长上下文数据训练，来预测分段错误范围标注 (ESA) 分数。


<details>
  <summary>Details</summary>
Motivation: 在 WMT25 机器翻译质量评估共享任务中提交系统。

Method: 使用 COMET 框架，通过拼接领域内人工标注的句子并计算加权平均分数来构建长上下文训练数据。整合 MQM、SQM 和 DA 等多个数据集，通过归一化其量表，并训练多语言回归模型来预测源、假设和参考翻译的质量分数。

Result: 包含长上下文信息可以提高与人工判断的相关性。

Conclusion: 长上下文信息对于提高机器翻译质量评估的准确性至关重要。

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [110] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: TTS技术（如Self-Consistency, SC）可以通过生成多个推理链并进行多数投票来提高LLM的推理性能，但计算开销大。


<details>
  <summary>Details</summary>
Motivation: Self-Consistency（SC）技术虽然有效，但其计算开销过大，限制了其广泛应用。

Method: 提出Slim-SC，一种逐步剪枝策略，通过在思考层面识别和去除冗余的推理链来降低SC的开销。

Result: 在三个STEM推理数据集和两种LLM架构上的实验表明，Slim-SC在保持或提高准确性的同时，将推理延迟和KVC使用量分别降低了高达45%和26%。

Conclusion: Slim-SC是一种简单而有效的测试时推理（TTS）替代方案，可以显著降低SC的计算开销。

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [111] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

TL;DR: ES-CoT通过检测答案收敛并提前停止来缩短长链思考（CoT）的生成，从而降低推理成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决长链思考（CoT）推理成本高的问题，同时保持LLM解决复杂问题的能力。

Method: 在每个推理步骤结束时，提示LLM输出当前的最终答案（步骤答案），并跟踪连续相同步骤答案的运行长度作为答案收敛的度量。当运行长度出现急剧增加并超过最小阈值时，提前终止生成。

Result: 在五个推理数据集和三个LLM上的实验表明，ES-CoT平均将推理令牌数量减少了约41%，同时保持了与标准CoT相当的准确性。

Conclusion: ES-CoT是一种实用的、高效的推理方法，可以与自洽提示无缝集成，并且在超参数选择上保持稳健。

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [112] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

TL;DR: Hala模型在阿拉伯语NLP任务上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 为阿拉伯语NLP研究提供支持，并弥合现有模型在阿拉伯语处理能力上的差距。

Method: 使用translate-and-tune流水线，通过FP8压缩的AR↔EN教师模型生成高质量的双语监督数据，然后在此数据上微调轻量级语言模型LFM2-1.2B，最后通过slerp合并技术训练不同参数规模的Hala模型。

Result: 在阿拉伯语中心的任务基准测试中，Hala模型在“nano”和“small”两个类别中均达到最先进水平，优于其基础模型。

Conclusion: Hala模型家族在阿拉伯语NLP任务上表现出色，显示了translate-and-tune流水线的有效性，并为社区发布了相关资源以促进研究。

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [113] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

TL;DR: 语音翻译质量评估应超越文本，纳入音频评估，以获得更自然、更可靠的翻译系统排名。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译（MT）质量评估主要以文本为中心，忽略了许多实际应用中涉及语音的场景，因此需要一种更自然的评估方式。

Method: 通过众包方式（Amazon Mechanical Turk）对10个机器翻译系统的文本和音频评估结果进行比较，并进行统计显著性检验和自复制实验以验证音频评估方法的可靠性和一致性。

Result: 基于音频的众包评估结果与基于文本的评估结果在大部分情况下一致，但在某些情况下能区分出不同的翻译系统，这归因于语音作为一种更丰富、更自然的模式。

Conclusion: 语音评估应被纳入未来的机器翻译评估框架中，因为它能提供比纯文本评估更全面、更可靠的翻译系统比较。

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [114] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 模型在处理上下文相关翻译任务时，由于训练数据中上下文信息稀疏，导致性能不佳。研究通过构建不同上下文信息比例的数据集进行验证，确认了稀疏性是关键瓶颈。同时发现，一种上下文现象的改进不适用于其他现象，跨语言迁移也有限。最后提出了两种训练策略，在单语和多语环境下分别提升了6%和8%的准确率。


<details>
  <summary>Details</summary>
Motivation: 翻译模型在处理需要上下文理解的任务（如代词消歧）时存在困难，这被认为是由于标准训练数据中缺乏上下文丰富性的例子。

Method: 通过构建包含不同比例上下文相关示例的训练数据集，系统地验证了上下文信息稀疏性对单语和多语翻译模型性能的影响。分析了上下文现象的泛化性以及跨语言迁移能力。最后，提出并评估了两种旨在利用现有数据以改进上下文利用的训练策略。

Result: 研究证实了训练数据中上下文信息的稀疏性与模型性能之间存在强相关性，确认稀疏性是关键瓶颈。发现改进一种上下文现象的性能并不能泛化到其他现象。跨语言迁移能力有限，并非在同一语系的语言之间有显著更高的迁移。提出的训练策略在单语和多语设置下分别带来了高达6%和8%的ctxPro评估准确率提升。

Conclusion: 上下文信息的稀疏性是导致翻译模型在处理上下文相关任务时性能不佳的关键因素。上下文现象的改进不具有泛化性，且跨语言迁移能力有限。所提出的两种训练策略能够有效利用现有数据，显著提升模型的上下文理解和翻译准确率。

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [115] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

TL;DR: LLM在多智能体辩论（MAD）系统中存在沟通和过早收敛问题，本文提出了一种名为ConfMAD的框架，通过引入置信度表达来解决这些问题，实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论（MAD）系统虽然利用了多个大型语言模型（LLMs）来模拟辩论，但LLMs在表达其优势方面存在困难，并且不恰当的置信度表达会导致代理人固守错误信念或过早收敛到次优答案，从而降低辩论效果和系统性能。

Method: 提出了一种名为ConfMAD的MAD框架，该框架在整个辩论过程中整合了置信度表达，使LLMs能够明确传达其置信水平。

Result: 实验结果证明了所提出方法的有效性，并进一步分析了置信度如何影响辩论动态。

Conclusion: 置信度表达可以作为一种有价值的机制，用于增强MAD系统的性能，并为设计置信度感知的MAD系统提供了见解。

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [116] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

TL;DR: 该研究提出了一种基于问题的 sign 语言翻译 (QB-SLT) 方法，利用对话上下文提高翻译效率，并提出了一种名为 SSL-SSAW 的融合方法，在 CSL-Daily-QA 和 PHOENIX-2014T-QA 数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了弥合聋哑人和健听人之间的沟通鸿沟，并利用对话中的关键上下文线索来改进 sign 语言翻译。

Method: 提出了一种名为 SSL-SSAW 的跨模态自监督学习方法，采用对比学习对齐多模态特征，并引入 Sigmoid 自注意力加权 (SSAW) 模块进行自适应特征提取，同时利用问句文本通过自监督学习增强表示和翻译能力。

Result: 在 CSL-Daily-QA 和 PHOENIX-2014T-QA 数据集上取得了最先进的性能，证明了问句辅助可以达到甚至超过词条辅助的性能，并且可视化结果证实了对话在提高翻译质量方面的有效性。

Conclusion: 基于问题的 sign 语言翻译 (QB-SLT) 是一种有效的方法，可以利用对话上下文提高翻译效率，SSL-SSAW 融合方法能够有效地提取和利用多模态特征，从而实现高质量的 sign 语言翻译。

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [117] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

TL;DR: Canary-1B-v2是一个支持25种语言的快速、鲁棒的多语言语音识别和语音到文本翻译模型，在英语ASR上优于Whisper-large-v3且速度快10倍，并发布了Parakeet-TDT-0.6B-v3。


<details>
  <summary>Details</summary>
Motivation: 提出一个快速、鲁棒的多语言语音识别（ASR）和语音到文本翻译（AST）模型。

Method: 使用FastConformer编码器和Transformer解码器，支持25种主要为欧洲的语言。在1.7M小时的数据上进行训练，并增加了非语音音频以减少幻觉。采用了两阶段预训练和微调过程，以及动态数据平衡。使用NeMo Forced Aligner（NFA）和辅助CTC模型来生成时间戳。

Result: Canary-1B-v2在英语ASR上性能优于Whisper-large-v3，速度快10倍。在多语言ASR和AST方面，其性能与Seamless-M4T-v2-large等大型模型和基于LLM的系统相当。Parakeet-TDT-0.6B-v3提供了600M参数的多语言ASR。

Conclusion: Canary-1B-v2在多语言ASR和AST方面表现出色，速度快且鲁棒。

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [118] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

TL;DR: CS-FLEURS是一个包含113种代码转换语言对（跨越52种语言）的语音识别和翻译数据集，旨在支持低资源语言的研究。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对低资源语言的代码转换语音识别和翻译系统数据集，限制了该领域的研究进展。

Method: 构建了一个包含4个测试集和1个训练集的数据集。测试集包括真实语音和生成语音，覆盖多种语言对（X-英语、阿拉伯语、普通话、印地语、西班牙语）。训练集包含128小时的生成语音数据。

Result: CS-FLEURS数据集包含了113种代码转换语言对，覆盖52种语言，并提供了不同类型的语音数据（真实语音、生成语音）和多种语言组合，为代码转换语音研究提供了资源。

Conclusion: 希望CS-FLEURS数据集能够拓宽未来代码转换语音研究的范围，促进低资源语言的研究。

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


### [119] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

TL;DR: MLLMs在创造力方面需要关联能力，但现有评估方法存在歧义。我们提出了AssoCiAm基准，通过混合计算方法解决歧义问题，并发现评估中的歧义会使MLLMs的行为更随机。


<details>
  <summary>Details</summary>
Motivation: 创造力是MLLMs实现AGI的关键能力，而关联性是创造力的基础。然而，现有评估关联性的方法忽视了关联任务中的固有限歧义，影响了评估的可靠性。

Method: 提出AssoCiAm基准，将歧义分解为内部歧义和外部歧义，并采用混合计算方法来规避歧义，以评估关联能力。

Result: 进行了广泛的实验，发现认知与关联性之间存在强烈的正相关。评估中的歧义会导致MLLMs的行为更随机。验证了该方法的有效性，可以进行更准确、更可靠的评估。

Conclusion: AssoCiAm基准通过解决评估中的歧义问题，能够更准确、更可靠地评估MLLMs的关联能力，并揭示了认知与关联性之间的关系。

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [120] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

TL;DR: 本研究提出了一个结合金融背景和行为金融学研究的新框架，用于生成端到端金融顾问的监督数据。通过在一个包含19k样本的数据集上微调Qwen-3-8B模型，并在独立测试集和LLM评审研究中进行评估，证明该模型在事实准确性、流畅性和个性化方面表现与参数量更大的模型相当，同时成本降低了80%。


<details>
  <summary>Details</summary>
Motivation: 当前的个性化金融建议需要考虑用户的目标、限制、风险承受能力和司法管辖区。现有的大型语言模型（LLM）研究主要集中在为投资者和金融规划师提供支持系统，而针对预算、债务管理、退休和遗产规划等更广泛的个人理财任务的代理式方法维护成本高昂且收益不佳（不到预期收益的25%）。因此，有必要开发一种更有效、更具成本效益的解决方案。

Method: 研究人员开发了一个新颖且可复现的框架，该框架整合了相关的金融背景和行为金融学研究，以构建用于端到端金融顾问的监督数据。他们利用这个框架创建了一个包含19,000个样本的推理数据集，并对Qwen-3-8B模型进行了全面的微调。

Result: 通过在独立测试集和盲测LLM陪审团研究中进行评估，研究表明，通过精心的数据策划和行为整合，Qwen-3-8B模型在事实准确性、流畅性和个性化指标方面取得了与参数量显著更大的基线模型（14-32B参数）相媲美的性能，同时成本降低了80%。

Conclusion: 本研究证明，通过仔细的数据策划和行为金融学原理的整合，可以在较小的模型（如Qwen-3-8B）上实现与更大模型相当的金融咨询性能，同时显著降低成本。这为开发更具成本效益和可扩展性的个性化金融建议系统提供了一条有前景的途径。

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [121] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

TL;DR: 该研究使用大型语言模型分析了75年来英国议会辩论中与移民相关的言论，并与美国国会进行了比较。研究发现，与美国日益两极化的言论不同，英国议会的跨党派态度相对一致，但工党和保守党之间存在持续的意识形态差距。研究还揭示了英国议会言论中，关于边境控制和非法移民等安全化叙事的增加，而社会融合等面向融合的叙事则有所减少。此外，关于国家移民法的讨论逐渐被国际法和人权讨论所取代。研究结果表明，大型语言模型可以支持大规模、细粒度的政治和历史语境下的言论分析。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在对英国议会75年来的移民相关言论进行大规模计算分析，并与美国国会进行比较，以了解其演变趋势和跨党派差异。同时，研究还希望通过细粒度的叙事框架提取，深入理解移民言论的细微之处，并展示大型语言模型在政治和历史语境下的言论分析能力。

Method: 本研究采用开放权重的大型语言模型（LLMs）对英国议会75年来的辩论言论进行标注，识别对移民的高层立场，并追踪跨越时间和政党的净情感倾向。针对英国议会言论，研究还扩展了一个半自动化框架，用于提取细粒度的叙事框架，以捕捉移民言论的细微差别。

Result: 研究发现，美国的国会言论日益两极化，而英国议会的跨党派态度则相对一致，工党和保守党之间存在持续的意识形态差距，并在2025年达到负面水平。在英国议会言论分析中，关于边境控制和非法移民等安全化叙事有所增加，而社会融合等面向融合的叙事有所下降。此外，关于国家移民法的讨论逐渐被国际法和人权讨论所取代。

Conclusion: 本研究通过大规模计算分析和大型语言模型应用，展示了LLMs在政治和历史语境下进行大规模、细粒度言论分析的有效性。研究揭示了英国和美国在移民言论上的不同趋势，以及英国议会言论中叙事焦点的转变，为理解和分析政治言论提供了新的方法和见解。

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [122] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

TL;DR: Apertus是一个完全开源的大型语言模型（LLM）套件，旨在解决当前开放模型生态系统中数据合规性和多语言表示的不足。


<details>
  <summary>Details</summary>
Motivation: 解决现有开放模型生态系统中数据合规性和多语言表示的不足。

Method: 使用公开数据进行预训练，尊重robots.txt排除规则，过滤非许可、有毒和个人身份信息内容。采用Goldfish目标抑制记忆，同时保持下游任务性能。模型在15万亿（15T）的包含1800多种语言的数据上训练，其中约40%为非英语内容。模型发布了8B和70B两个规模的版本。

Result: 在多语言基准测试中，Apertus达到了与完全开放模型相媲美甚至超越开放权重模型的水平。

Conclusion: Apertus在多语言能力和数据合规性方面为开放模型生态系统做出了贡献，并提供了透明的开发工件以供审计和扩展。

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [123] [Snail Homing and Mating Search Algorithm for Weight Optimization of Stepped-Transmission Shaft](https://arxiv.org/abs/2509.13721)
*Kaustav Saha,Ishaan R Kale,Vivek Patel,Anand J Kulkarni,Puskaraj D Sonawwanay*

Main category: cs.NE

TL;DR: 本文提出了一种用于重量优化的浸入式传动轴设计问题，并利用受蜗牛启发的 Snail Homing and Mating Search (SHMS) 算法解决该问题。


<details>
  <summary>Details</summary>
Motivation: 为优化传动轴重量，提出浸入式传动轴设计问题。

Method: 利用受蜗牛启发的 Snail Homing and Mating Search (SHMS) 算法，并结合 MDSOLIDS 软件和 ANSYS Workbench 进行设计、建模、分析和验证。

Result: SHMS 算法在可接受的计算成本内得到了预期解，并成功生成了 CAD 模型。通过与 ANSYS Workbench 的结果对比，验证了算法的有效性。

Conclusion: SHMS 算法能够有效地解决浸入式传动轴设计问题，并在重量优化方面取得了良好的效果。

Abstract: In this paper, the steeped-transmission shaft design problem is proposed for
weight optimization. The bio-inspired search-based Snail Homing and Mating
Search (SHMS) algorithm is utilized to solve the problem. It is inspired by the
social behaviour of snails and their inherent nature of finding better homes,
and mate. The proposed steeped-transmission shaft design problem is modelled
considering the fatigue loading, combined bending, torsion loads, and the
principle of Modified Goodman criteria. The forces diagram and the bending
moment diagrams are obtained using the MDSOLIDS software. The forces and
bending moment are then used to mathematical model the objective function and
constraints. The SHMS algorithm has yielded the desired solution with
reasonable computational cost. The constraints are handled using a static
penalty function approach. The statistical results obtained using SHMS
algorithm are further used for generating CAD model. The analysis is carried
out in ANSYS Workbench. Further, the deflection obtained from SHMS algorithm
and ANSYS Workbench are compared and results are discussed in details.

</details>


### [124] [A neuromorphic continuous soil monitoring system for precision irrigation](https://arxiv.org/abs/2509.14066)
*Mirco Tincani,Khaled Kerouch,Umberto Garlando,Mattia Barezzi,Alessandro Sanginario,Giacomo Indiveri,Chiara De Luca*

Main category: cs.NE

TL;DR: 使用节能的神经形态处理系统，在边缘实现自主的、无需数据传输的智能灌溉控制。


<details>
  <summary>Details</summary>
Motivation: 现代农业和精准灌溉系统需要超低功耗的独立计算技术来持续监测环境，优化水资源利用。神经形态处理系统在资源受限的硬件上运行的极端边缘计算应用方面显示出前景，适用于基于土壤和植物数据的عefficient water management。

Method: 提出了一种完全节能的神经形态灌溉控制系统，该系统利用生物学上真实的脉冲神经网络的特性，在本地进行计算和决策，无需数据传输或远程处理。

Result: 使用来自苹果和猕猴桃园的真实土壤湿度数据，在混合信号神经形态处理器上验证了该方法，生成的灌溉指令与传统方法在不同土壤深度下的结果非常吻合。

Conclusion: 本地神经形态推理能够保持决策的准确性，为大规模自主、可持续的灌溉解决方案铺平了道路。

Abstract: Sensory processing at the edge requires ultra-low power stand-alone computing
technologies. This is particularly true for modern agriculture and precision
irrigation systems which aim to optimize water usage by monitoring key
environmental observables continuously using distributed efficient embedded
processing elements. Neuromorphic processing systems are emerging as a
promising technology for extreme edge-computing applications that need to run
on resource-constrained hardware. As such, they are a very good candidate for
implementing efficient water management systems based on data measured from
soil and plants, across large fields. In this work, we present a fully
energy-efficient neuromorphic irrigation control system that operates
autonomously without any need for data transmission or remote processing.
Leveraging the properties of a biologically realistic spiking neural network,
our system performs computation, and decision-making locally. We validate this
approach using real-world soil moisture data from apple and kiwi orchards
applied to a mixed-signal neuromorphic processor, and show that the generated
irrigation commands closely match those derived from conventional methods
across different soil depths. Our results show that local neuromorphic
inference can maintain decision accuracy, paving the way for autonomous,
sustainable irrigation solutions at scale.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [125] [A hybrid dynamic model and parameter estimation method for accurately simulating overhead cranes with friction](https://arxiv.org/abs/2509.13330)
*Jorge Vicente-Martinez,Edgar Ramirez-Laboreo*

Main category: eess.SY

TL;DR: 提出了一种结合高保真摩擦建模和计算效率的混合动力学模型，并提出了一种基于高斯过程回归和最小二乘法的系统参数（包括摩擦）估计算法，通过实验验证了该方法在3D起重机模拟中的有效性。


<details>
  <summary>Details</summary>
Motivation: 准确模拟包含摩擦的3D起重机系统具有挑战性，传统方法在精度或计算效率方面存在不足。

Method: 提出了一种混合动力学模型，并提出了一种基于高斯过程回归（GPR）和最小二乘法（LS）估计的系统参数（包括摩擦）估计算法。

Result: 该方法能够进行高保真摩擦建模和高效计算，并通过实验验证了其在3D起重机模拟中的有效性。

Conclusion: 所提出的混合动力学模型和参数估计方法能够有效地模拟具有摩擦的3D起重机系统。

Abstract: This paper presents a new approach to accurately simulating 3D overhead
cranes with friction. Nonlinear friction dynamics have a significant impact on
these systems, however, accurately modeling this phenomenon in simulations is a
significant challenge. Traditional methods often rely on imprecise
approximations of friction or require excessive computational times for
reliable results. To address this, we present a hybrid dynamical model that
features a trade-off between high-fidelity friction modeling and computational
efficiency. Furthermore, we present a step-by-step algorithm for the
comprehensive estimation of all unknown system parameters, including friction.
This methodology is based on Gaussian Process Regression (GPR) and Least
Squares (LS) estimations. Finally, experimental validation with a laboratory
crane confirms the effectiveness of the proposed modeling and estimation
approach.

</details>


### [126] [Right-to-Override for Critical Urban Control Systems: A Deliberative Audit Method for Buildings, Power, and Transport](https://arxiv.org/abs/2509.13369)
*Rashid Mushkani*

Main category: eess.SY

TL;DR: 用户几乎无权干预自动化系统，即使这些系统损害了包容性、安全性和可访问性。本研究提出了“干预权”（R2O）和“审议审计方法”（DAM）来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 当前自动化系统（如建筑暖通空调、电网和交通信号）的控制权掌握在系统手中，而普通居民却无权干预，即使这些系统在包容性、安全性和可访问性方面存在问题。

Method: 研究提出了“干预权”（R2O），明确了干预的权限、证据阈值和领域验证的安全回退状态。同时，引入了“审议审计方法”（DAM），包含用于部署前演练、影子模式试运行和事后审查的规范。该方法已在智能电网负载分配、建筑暖通空调（考虑入住率不确定性）和多智能体交通信号的模拟中得到应用。

Result: 模拟结果显示，R2O能够减少分配性损害，同时仅带来有限的效率损失。具体而言，在负载分配中，未供电能量的差异从 5.61 倍减少到 0.69 倍，且总的削减量保持不变；在建筑暖通空调方面，一次干预可以消除老年人两小时的不适感，而仅增加 77 千瓦时的能源消耗；在交通信号方面，中位数的行人等待时间从 90.4 秒减少到 55.9 秒，而车辆的平均等待时间仅增加了 6.0 秒。

Conclusion: 本研究提出了一个政策标准、审计工作表和模型运维集成模式，旨在使城市自动化系统能够被争议和审查，从而增强其可控性和可审查性。

Abstract: Automation now steers building HVAC, distribution grids, and traffic signals,
yet residents rarely have authority to pause or redirect these systems when
they harm inclusivity, safety, or accessibility. We formalize a
Right-to-Override (R2O) - defining override authorities, evidentiary
thresholds, and domain-validated safe fallback states - and introduce a
Deliberative Audit Method (DAM) with playbooks for pre-deployment walkthroughs,
shadow-mode trials, and post-incident review. We instantiate R2O/DAM in
simulations of smart-grid load shedding, building HVAC under occupancy
uncertainty, and multi-agent traffic signals. R2O reduces distributional harm
with limited efficiency loss: load-shedding disparity in unserved energy drops
from 5.61x to 0.69x with constant curtailment; an override eliminates two
discomfort-hours for seniors at an energy cost of 77 kWh; and median pedestrian
wait falls from 90.4 s to 55.9 s with a 6.0 s increase in mean vehicle delay.
We also contribute a policy standard, audit worksheets, and a ModelOps
integration pattern to make urban automation contestable and reviewable.

</details>


### [127] [A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings](https://arxiv.org/abs/2509.13371)
*Xuyuan Kang,Xiao Wang,Jingjing An,Da Yan*

Main category: eess.SY

TL;DR: 该研究提出了一种集成负荷预测和优化控制的新方法，用于商业建筑中的冰基蓄能（TES）系统，通过改进预测模型和引入基于分时电价的控制策略，实现了9.9%的能耗成本节约。


<details>
  <summary>Details</summary>
Motivation: 现有的TES系统多采用固定计划运行，无法充分发挥其削峰填谷的潜力，需要大量的优化研究。因此，本研究旨在提出一种新的集成负荷预测和优化控制方法，以提高商业建筑中TES系统的性能。

Method: 开发了一个改进的建筑制冷负荷预测模型，并引入了中午的修正机制以提高预测精度。基于预测结果，提出了一种根据分时电价制定的基于规则的控制策略，并结合中午预测修正机制进行控制调整。

Result: 该方法在实际商业建筑的冰基TES系统中应用，预测模型实现了12.5%的MAE变异系数和389 kW的平均绝对误差。集成的预测控制策略实现了9.9%的能耗成本节约率。

Conclusion: 研究提出的集成负荷预测和优化控制方法能够有效提高商业建筑中冰基TES系统的效率和自动化水平，并实现显著的经济效益。

Abstract: Thermal energy storage (TES) is an effective method for load shifting and
demand response in buildings. Optimal TES control and management are essential
to improve the performance of the cooling system. Most existing TES systems
operate on a fixed schedule, which cannot take full advantage of its load
shifting capability, and requires extensive investigation and optimization.
This study proposed a novel integrated load prediction and optimized control
approach for ice-based TES in commercial buildings. A cooling load prediction
model was developed and a mid-day modification mechanism was introduced into
the prediction model to improve the accuracy. Based on the predictions, a
rule-based control strategy was proposed according to the time-of-use tariff;
the mid-day control adjustment mechanism was introduced in accordance with the
mid-day prediction modifications. The proposed approach was applied in the
ice-based TES system of a commercial complex in Beijing, and achieved a mean
absolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The
integrated prediction-based control strategy achieved an energy cost saving
rate of 9.9%. The proposed model was deployed in the realistic building
automation system of the case building and significantly improved the
efficiency and automation of the cooling system.

</details>


### [128] [Circuit realization and hardware linearization of monotone operator equilibrium networks](https://arxiv.org/abs/2509.13793)
*Thomas Chaffey*

Main category: eess.SY

TL;DR: 电阻-二极管网络在模拟硬件中可以构建深度神经网络，并且可以通过硬件线性化在硬件中直接计算梯度，从而实现训练。


<details>
  <summary>Details</summary>
Motivation: 旨在于探索在模拟硬件中构建深度神经网络的可行性，并实现其在硬件中的训练。

Method: 将电阻-二极管网络的端口行为与ReLU单调算子平衡网络联系起来，提出硬件线性化方法计算梯度。

Result: 成功在器件级电路仿真中演示了在硬件中训练神经网络，并扩展到级联网络以实现前馈和非对称网络，还引入了基于非理想二极管模型的二极管ReLU激活函数。

Conclusion: 电阻-二极管网络提供了一种在模拟硬件中构建深度神经网络的简洁方法，硬件线性化技术实现了在硬件中的直接训练，并且可以扩展到更复杂的网络结构。

Abstract: It is shown that the port behavior of a resistor-diode network corresponds to
the solution of a ReLU monotone operator equilibrium network (a neural network
in the limit of infinite depth), giving a parsimonious construction of a neural
network in analog hardware. We furthermore show that the gradient of such a
circuit can be computed directly in hardware, using a procedure we call
hardware linearization. This allows the network to be trained in hardware,
which we demonstrate with a device-level circuit simulation. We extend the
results to cascades of resistor-diode networks, which can be used to implement
feedforward and other asymmetric networks. We finally show that different
nonlinear elements give rise to different activation functions, and introduce
the novel diode ReLU which is induced by a non-ideal diode model.

</details>


### [129] [Identifying Network Structure of Nonlinear Dynamical Systems: Contraction and Kuramoto Oscillators](https://arxiv.org/abs/2509.13505)
*Jaidev Gill,Jing Shuang Li*

Main category: eess.SY

TL;DR: 该研究探讨了在仅能观测到部分节点的情况下，网络化非线性系统的网络拓扑可识别性问题，并提出使用收缩理论来分析不同拓扑结构的可区分性。


<details>
  <summary>Details</summary>
Motivation: 研究网络化非线性系统的网络拓扑可识别性，特别是当只能观测到部分节点时，可能存在的不同拓扑结构产生相似观测结果的问题。

Method: 应用收缩理论框架，重点分析了在可观测空间中出现的半收缩现象，以此作为判断两个系统基于部分观测结果是否不可区分（即拓扑是否可识别）的充分条件。

Result: 将该框架应用于库莫特振荡器网络，并讨论了在何种情况下，不同的网络拓扑（包括连通和非连通网络）会变得不可区分。

Conclusion: 在部分观测条件下，系统的可识别性受到限制，半收缩是判断不同拓扑系统不可区分性的充分条件，该方法可应用于库莫特振荡器网络等具体场景。

Abstract: In this work, we study the identifiability of network topologies for
networked nonlinear systems when partial measurements of the nodes are taken.
We explore scenarios where different candidate topologies can yield similar
measurements, thus limiting identifiability. To do so, we apply the contraction
theory framework to facilitate comparisons between candidate topologies. We
show that semicontraction in the observable space is a sufficient condition for
two systems to become indistinguishable from one another based on partial
measurements. We apply this framework to study networks of Kuramoto
oscillators, and discuss scenarios in which different topologies (both
connected and disconnected) become indistinguishable.

</details>


### [130] [Scale Up Analysis of Inductively Heated Metamaterial Reactors](https://arxiv.org/abs/2509.13719)
*Chenghao Wan,Conner Cremers,Ariana B. Höfelmann,Zhennan Ru,Calvin H. Lin,Kesha N. Tamakuwala,Dolly Mantle,Pinak Mohapatra,Juan Rivas-Davila,Matthew W. Kanan,Jonathan A. Fan*

Main category: eess.SY

TL;DR: 感应加热超材料反应器通过优化径向导热性，可实现规模化、高效率和接近理想的化学转化。 


<details>
  <summary>Details</summary>
Motivation: 感应加热超材料反应器因其体积加热和增强传热的潜力，在规模化电气化热化学反应器操作中具有前景。本文旨在系统分析其规模化能力和性能。

Method: 结合解析建模、数值模拟和实验，研究了感应加热超材料反应器在逆水煤气变换反应中的规模化问题。

Result: 在具有均匀超材料吸热体的反应器配置中，系统效率随规模增大而提高，但径向温度梯度限制了吞吐量。通过调整吸热体的径向有效导热性，可以克服这一瓶颈，实现接近理想的塞流行为。

Conclusion: 通过优化超材料吸热体的径向导热性，可以实现具有最佳化学转化能力的规模化电气化热化学反应器。

Abstract: Inductively heated metamaterial reactors, which utilize an open cell lattice
baffle structure as a heating susceptor for magnetic induction, are promising
candidates for scaled electrified thermochemical reactor operation due to their
ability to support volumetric heating profiles and enhanced heat transfer
properties. In this work, we present a systematic scale up analysis of
inductive metamaterial reactors where we utilize a combination of analytic
modeling, numerical simulations, and experiments to project the capabilities
and performance of scaled reactors. We use reverse water gas shift as a model
reaction system and show that for reactor configurations featuring a uniform
metamaterial susceptor, the total system efficiency increases with scale.
However, the throughput of these scaled reactors is limited by radial
temperature gradients. We further show this bottleneck can be overcome by
tailoring the radial effective conductivity profile of the susceptor, which can
enable scaled reactors with nearly ideal plug flow-like capabilities. These
concepts provide a pathway towards scaled electrified thermochemical reactors
with optimal chemical conversion capabilities.

</details>


### [131] [The impact of modeling approaches on controlling safety-critical, highly perturbed systems: the case for data-driven models](https://arxiv.org/abs/2509.13531)
*Piotr Łaszkiewicz,Maria Carvalho,Cláudia Soares,Pedro Lourenço*

Main category: eess.SY

TL;DR: DD-LTV系统模型在强扰动和重构系统下的轨迹跟踪误差优于LTI，与L-LTV相当，并在状态传播方面优于LTV系统辨识方法。


<details>
  <summary>Details</summary>
Motivation: 评估三种系统模型对LQR最优控制器在强扰动和重构系统下的轨迹跟踪误差的影响。

Method: 将从数据中学习到的平滑线性时变（DD-LTV）系统与最先进的线性时变（LTV）系统辨识方法进行比较，并与线性时不变（LTI）和线性化线性时变（L-LTV）系统模型进行比较。

Result: DD-LTV在状态传播方面优于LTV，在轨迹跟踪误差方面优于LTI，与L-LTV相当。

Conclusion: DD-LTV系统模型在扰动和时变弹簧-质量-阻尼器系统的轨迹跟踪任务中表现出有竞争力的性能。

Abstract: This paper evaluates the impact of three system models on the reference
trajectory tracking error of the LQR optimal controller, in the challenging
problem of guidance and control of the state of a system under strong
perturbations and reconfiguration. We compared a smooth Linear Time Variant
system learned from data (DD-LTV) with state of the art Linear Time Variant
(LTV) system identification methods, showing its superiority in the task of
state propagation. Moreover, we have found that DD-LTV allows for better
performance in terms of trajectory tracking error than the standard solutions
of a Linear Time Invariant (LTI) system model, and comparable performance to a
linearized Linear Time Variant (L-LTV) system model. We tested the three
approaches on the perturbed and time varying spring-mass-damper systems.

</details>


### [132] [Zero-sum turn games using Q-learning: finite computation with security guarantees](https://arxiv.org/abs/2509.13585)
*Sean Anderson,Chris Darken,João Hespanha*

Main category: eess.SY

TL;DR: 纯策略鞍点反馈策略可以通过动态规划不动点方程从Q学习中构建，适用于零和转折对策。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决零和转折博弈（turn games）中的纯策略鞍点状态反馈策略问题，并提出一种基于Q学习的求解方法。

Method: 提出使用动态规划不动点方程，并结合Q学习来构建纯策略鞍点反馈策略。对于折扣成本，利用经典方法证明了Q学习的收敛性。对于非折扣成本，在有限时间确定性博弈中证明了收敛性。此外，提出了一种“对手知情”的探索策略，以解决Q学习在有限次迭代中可能无法保证安全级别的问题。

Result: 所提出的Q学习方法能够构建纯策略鞍点反馈策略。对于折扣成本，Q学习可保证收敛。对于非折扣成本，在有限时间确定性博弈中也得到了收敛性证明。对手知情探索策略可以保证最终Q函数提供的安全级别至少对于给定的策略集有效。

Conclusion: 基于Q学习的动态规划方法可以有效地为零和转折博弈构建纯策略鞍点反馈策略，并且通过对手知情探索策略可以提高策略的鲁棒性。

Abstract: This paper addresses zero-sum ``turn'' games, in which only one player can
make decisions at each state. We show that pure saddle-point state-feedback
policies for turn games can be constructed from dynamic programming fixed-point
equations for a single value function or Q-function. These fixed-points can be
constructed using a suitable form of Q-learning. For discounted costs,
convergence of this form of Q-learning can be established using classical
techniques. For undiscounted costs, we provide a convergence result that
applies to finite-time deterministic games, which we use to illustrate our
results. For complex games, the Q-learning iteration must be terminated before
exploring the full-state, which can lead to policies that cannot guarantee the
security levels implied by the final Q-function. To mitigate this, we propose
an ``opponent-informed'' exploration policy for selecting the Q-learning
samples. This form of exploration can guarantee that the final Q-function
provides security levels that hold, at least, against a given set of policies.
A numerical demonstration for a multi-agent game, Atlatl, indicates the
effectiveness of these methods.

</details>


### [133] [A Game-Theoretic Predictive Control Framework with Statistical Collision Avoidance Constraints for Autonomous Vehicle Overtaking](https://arxiv.org/abs/2509.13545)
*Sheng Yu,Boli Chen,Imad M. Jaimoukha,Simos A. Evangelou*

Main category: eess.SY

TL;DR: 本研究提出了一种名为GT-PRO（博弈论预测超车）的策略，用于在混合交通环境中实现联网自动驾驶汽车（CAVs）的自主超车，其中被超车辆是无连接但可交互的人驾车辆。


<details>
  <summary>Details</summary>
Motivation: 在混合交通环境中，需要一种能够处理与人类驾驶员交互的自主超车控制框架。

Method: GT-PRO策略将CAV的纵向和横向车辆动力学解耦，并通过基于模型预测控制（MPC）的控制器进行协调。横向控制器利用动态Stackelberg博弈来控制CAV的横向运动并预测被超车辆的纵向响应。纵向控制器则是一个随机MPC，接收被超车辆的预测响应。该策略使用真实世界数据集来调整博弈论横向控制器并实现碰撞避免约束。

Result: 在模拟的礼貌和激进的人类反应案例研究中，GT-PRO在安全性、效率和舒适性方面均优于现有方法，并且能够实现实时运行。

Conclusion: GT-PRO策略能够安全、高效、舒适地实现联网自动驾驶汽车在混合交通环境中对人驾车辆的自主超车，并具备实时实现的潜力。

Abstract: This work develops a control framework for the autonomous overtaking of
connected and automated vehicles (CAVs) in a mixed traffic environment, where
the overtaken vehicle is an unconnected but interactive human-driven vehicle.
The proposed method, termed the Game-Theoretic, PRedictive Overtaking (GT-PRO)
strategy, successfully decouples the longitudinal and lateral vehicle dynamics
of the CAV and comprehensively coordinates these decoupled dynamics via
innovative longitudinal and lateral model predictive (MPC) based controllers,
respectively. To address the real-time interactive behavior of the human-driven
overtaken vehicle, a dynamic Stackelberg game-based bilevel optimization is
solved by the lateral controller to directly control the CAV lateral motion and
predict the overtaken vehicle longitudinal responses that are subsequently
shared with a stochastic MPC that governs the CAV longitudinal motion. The
proposed strategy exploits a comprehensive real-world dataset, which captures
human driver responses when being overtaken, to tune the game-theoretic lateral
controller according to the most common human responses, and to statistically
characterize human uncertainties and hence implement a collision avoidance
chance constraint for the stochastic longitudinal controller. The simulation
results for both polite and aggressive human response case studies of the
overtaken vehicle demonstrate that the proposed GT-PRO can achieve for this
range of human driver responsiveness, safer, more efficient, and more
comfortable autonomous overtaking, as compared to existing autonomous
overtaking approaches in the literature. Furthermore, the results suggest that
the GT-PRO method is capable of real-time implementation.

</details>


### [134] [Modeling and Verification of Lumped-Parameter, Multibody Structural Dynamics for Offshore Wind Turbines](https://arxiv.org/abs/2509.13558)
*Saad Rahman,Doyal Sarker,Tri Ngo,Roger Bergua,Daniel Zalkind,Jason Jonkman,Tuhin Das*

Main category: eess.SY

TL;DR: 本研究提出了用于海上风力涡轮机的多体结构动力学建模与验证方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是为海上风力涡轮机提供一种能够准确模拟其静态和动态行为，同时保持计算效率的多体结构动力学模型。

Method: 本研究采用非因果、集总参数、多体方法对基于单桩的海上风力涡轮机的柔性塔架和支撑结构进行建模，并考虑了土壤-结构相互作用和流体动力学模型。

Result: 仿真结果与替代建模方法进行了基准测试，证明了该模型在各种风浪条件下准确捕捉静态和动态行为的能力，同时保持了计算效率。

Conclusion: 这项工作为分析风力涡轮机的关键结构特性（包括固有频率、模态形状、阻尼和内力）提供了一个有价值的工具。

Abstract: This paper presents the modeling and verification of multibody structural
dynamics for offshore wind turbines. The flexible tower and support structure
of a monopile-based offshore wind turbine are modeled using an acausal,
lumped-parameter, multibody approach that incorporates structural flexibility,
soil-structure interaction, and hydrodynamic models. Simulation results are
benchmarked against alternative modeling approaches, demonstrating the model's
ability to accurately capture both static and dynamic behaviors under various
wind and wave conditions while maintaining computational efficiency. This work
provides a valuable tool for analyzing key structural characteristics of wind
turbines, including eigenfrequencies, mode shapes, damping, and internal
forces.

</details>


### [135] [Multi-Attacker Single-Defender Target Defense in Conical Environments](https://arxiv.org/abs/2509.13564)
*Arman Pourghorban,Dipankar Maity*

Main category: eess.SY

TL;DR: 该论文研究了在平面锥形环境中，单个防御者需要依次拦截一系列攻击者。攻击者的目标是突破防御边界，而防御者的目标是拦截攻击者。每次攻击结束后，下一个攻击者会出现并以最大速度向目标移动，防御者的最终位置将成为下一轮游戏的初始位置。攻击者会选择对其自身和后续交战都有利的策略，并且拥有有限的传感器范围，可以探测防御者是否在范围内。研究推导了所有玩家的均衡策略，并通过蒙特卡洛模拟验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 研究目标防御问题，特别是防御者需要连续拦截一系列攻击者，并考虑攻击者采取优化自身及后续交战的策略。

Method: 推导了所有玩家的均衡策略，利用捕获分布的概念来优化捕获率，并通过蒙特卡洛模拟进行数值验证。

Result: 通过数值例子和蒙特卡洛随机试验验证了理论结果。

Conclusion: 推导了在特定环境和规则下，防御者和攻击者的最优策略，并验证了其有效性。

Abstract: We consider a variant of the target defense problem in a planar conical
environment where a single defender is tasked to capture a sequence of incoming
attackers. The attackers' objective is to breach the target boundary without
being captured by the defender. As soon as the current attacker breaches the
target or gets captured by the defender, the next attacker appears at the
boundary of the environment and moves radially toward the target with maximum
speed. Therefore, the defender's final location at the end of the current game
becomes its initial location for the next game. The attackers pick strategies
that are advantageous for the current as well as for future engagements between
the defender and the remaining attackers. The attackers have their own sensors
with limited range, using which they can perfectly detect if the defender is
within their sensing range. We derive equilibrium strategies for all the
players to optimize the capture percentage using the notions of capture
distribution. Finally, the theoretical results are verified through numerical
examples using Monte Carlo type random trials of experiments.

</details>


### [136] [Impact of Solar Integration on Grid Security: Unveiling Vulnerabilities in Load Redistribution Attacks](https://arxiv.org/abs/2509.13567)
*Praveen Verma,Di Shi,Yanzhu Ye,Fengyu Wang,Ying Zhang*

Main category: eess.SY

TL;DR: 攻击者操纵电网数据以影响经济运行，并利用了太阳能发电整合的漏洞。


<details>
  <summary>Details</summary>
Motivation: 传统的负载再分配（LR）攻击模型假设发电机测量是安全的，但太阳能发电的整合带来了新的漏洞。

Method: 提出了一种增强的负载再分配攻击模型，以应对太阳能发电整合带来的新漏洞。

Result: 操纵太阳能发电数据会严重扰乱电网经济，尤其是在太阳能发电高峰期。

Conclusion: 太阳能发电的整合为LR攻击提供了新的途径，需要新的防御策略。

Abstract: Load redistribution (LR) attacks represent a practical and sophisticated form
of false data injection (FDI) attacks, where the attacker manipulates grid data
to influence economic operations of the grid through misleading security
constrained economic dispatch (SCED) decisions. Traditionally, LR attack models
operate under the assumption that generator measurements are secure and immune
to tampering. However, the increasing integration of solar generation into
power grids challenges this assumption, exposing new vulnerabilities. This
paper proposes an enhanced load redistribution attack model, addressing new
vulnerabilities introduced by the increasing integration of solar generation in
power grids. The study demonstrates that manipulating solar generation data
significantly disrupts grid economics, with peak impacts during periods of high
solar generation.

</details>


### [137] [Scaling green hydrogen and CCUS via cement-methanol co-production in China](https://arxiv.org/abs/2509.13674)
*Yuezhang He,Hongxi Luo,Yuancheng Lin,Carl J. Talsma,Anna Li,Zhenqian Wang,Yujuan Fang,Pei Liu,Jesse D. Jenkins,Eric Larson,Zheng Li*

Main category: eess.SY

TL;DR: 通过耦合电解氢和碳捕获、利用和封存（CCUS），提出了一种可再生能源驱动的联产系统，以应对高昂的绿色氢和CCUS成本，并为水泥和甲醇等难以减排的行业提供脱碳解决方案。


<details>
  <summary>Details</summary>
Motivation: 高昂的绿色氢和碳捕获、利用和封存（CCUS）成本阻碍了政策的实施和实际部署，尽管它们对于水泥和甲醇等难以减排行业的脱碳至关重要。

Method: 提出一个可再生能源驱动的联产系统，通过分子交换耦合电解氢和CCUS。使用考虑运行灵活性的逐时模型优化系统配置，并探索在中国部署和CO2源-汇匹配的集成策略。

Result: 联产系统到2035年可以将CO2减排成本降低到每吨41-53美元，显著低于单独的水泥CCUS（约75美元）和单独的可再生能源甲醇（超过120美元）。联产优先部署在可再生能源丰富的地区的水泥厂。

Conclusion: 这种氢-CCUS耦合模式可以加速工业脱碳，并为其他应用进行扩展，同时通过将联产优先部署在可再生能源丰富的地区，可能重塑中国的CO2基础设施规划。

Abstract: High costs of green hydrogen and of carbon capture, utilization, and
sequestration (CCUS) have hindered policy ambition and slowed real-world
deployment, despite their importance for decarbonizing hard-to-abate sectors,
including cement and methanol. Given the economic challenges of adopting CCUS
in cement and green hydrogen in methanol production separately, we propose a
renewable-powered co-production system that couples electrolytic hydrogen and
CCUS through molecule exchange. We optimize system configurations using an
hourly-resolved, process-based model incorporating operational flexibility, and
explore integrated strategies for plant-level deployment and CO2 source-sink
matching across China. We find that co-production could reduce CO2 abatement
costs to USD 41-53 per tonne by 2035, significantly lower than approximately
USD 75 for standalone cement CCUS and over USD 120 for standalone
renewable-based methanol. Co-production is preferentially deployed at cement
plants in renewable-rich regions, potentially reshaping national CO2
infrastructure planning. This hydrogen-CCUS coupling paradigm could accelerate
industrial decarbonization and scaling for other applications.

</details>


### [138] [Characterizing Human Limb Movements Using An In-House Multi-Channel Non-Invasive Surface-EMG System](https://arxiv.org/abs/2509.13840)
*Vinay C K,Vikas Vazhayil,Madhav rao*

Main category: eess.SY

TL;DR: 利用非侵入式表面肌电信号采集系统和支持向量机（SVM）分类器，成功区分了人体的上肢和下肢的多种运动。


<details>
  <summary>Details</summary>
Motivation: 为了在神经和神经肌肉疾病的诊断和治疗中，提供一种比传统侵入式电极更优的肌电信号（EMG）记录和分析方法，并探索其在运动功能障碍研究和生物电子学控制设计中的应用。

Method: 设计并制作了一个8通道的体表EMG信号采集系统，该系统采用模块化设计，前端模拟电路为8个通道独立设计。离线开发了支持向量机（SVM）分类模型，并利用该采集系统和模型对人体上、下肢（包括手指、腕部、肘部、肩部、膝盖和脚踝）的特定运动进行了表征。

Result: 该8通道非侵入式EMG采集系统能够捕捉肌群的复合电活动，并通过SVM分类器成功地对上、下肢的多种独立运动进行了表征。

Conclusion: 所提出的基于非侵入式表面EMG信号采集系统和SVM分类器的方案，能够有效地对人体肢体运动进行表征，为运动功能障碍的研究和神经肌肉疾病患者的生物电子学控制提供了有前景的方法。

Abstract: Electromyography (EMG) signals are obtained from muscle cell activity. The
recording and analysis of EMG signals has several applications. The EMG is of
diagnostic importance for treating patients suffering from neurological and
neuromuscular disorders. Conventional methods involve placement of invasive
electrodes within the muscles to record EMG signals. The goal is to showcase
the usage of surface based EMG signals to characterize all possible human limb
movements. An in-house non-invasive EMG signal acquisition system that offers
characterization of human limb actions is a suitable candidate for motor
impairment studies and easily extendable to design bionics control specifically
for neuromuscular disorder patients. An in-house 8-channel surface-EMG signal
acquisition system was designed, fabricated, and employed for characterizing
specific movements of upper and lower limb. The non-invasive acquisition system
captures the compound electromuscular activity generated from the group of
muscles. The EMG acquisition system was designed as a modular structure where
the front end analog circuit designs were replicated for all 8 channels, and
were designed to function independently. Support vector machine (SVM) as
classifier models were developed offline to successfully characterize different
human limb actions. The in house built 8 channel acquisition system with ML
classifier models were utilized to successfully characterize movements at
various joints of the upper and lower limb including fingers, wrist, elbow,
shoulder, knee, and ankle individually.

</details>


### [139] [Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection](https://arxiv.org/abs/2509.13934)
*Zhixion Chen,Jiangzhou Wang,and Hyundong Shin,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 无人机（UAV）在物联网（IoT）数据收集中的部署面临续航和通信范围的限制，导致需要智能的轨迹规划。虽然强化学习（RL）已被广泛研究，但其高昂的成本和风险限制了实际应用。离线RL可以缓解这些问题，但仍存在训练不稳定的风险，并且高度依赖高质量的数据集。为了解决这些挑战，本文提出了一种联合无人机轨迹规划和资源分配的问题，旨在最大化数据收集的能源效率。该方法首先将资源分配子问题转化为等价的线性规划问题，并以多项式时间复杂度进行求解。接着，提出了一种大型语言模型（LLM）驱动的、带有评论家正则化的决策变换器（DT）框架（LLM-CRDT），用于学习有效的无人机控制策略。LLM-CRDT结合了DT的序列建模能力和基于评论家的价值指导，通过评论家网络正则化DT模型的训练，从而能够从次优数据集中学习有效的策略。此外，为了克服Transformer模型对数据的过度依赖，该方法采用预训练的LLM作为DT模型的Transformer骨干，并使用参数高效的微调策略（LoRA），能够以小规模数据集和低计算开销快速适应无人机控制任务。广泛的模拟结果表明，LLM-CRDT的性能优于基准的在线和离线RL方法，在能源效率方面比当前最先进的DT方法高出36.7%。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAV）在物联网（IoT）数据收集中的部署面临续航和通信范围的限制，需要智能的轨迹规划。现有的强化学习（RL）方法在实际应用中成本高昂且存在风险，而离线RL方法则存在训练不稳定和对数据集质量要求高的问题。因此，需要一种能够提高无人机数据收集能源效率，并能从次优数据集中有效学习的无人机轨迹规划和资源分配方法。

Method: 本文提出了一种联合无人机轨迹规划和资源分配的方法。首先，将资源分配子问题转化为等价的线性规划问题，并进行最优求解。然后，提出了一种名为LLM-CRDT的框架，该框架结合了决策变换器（DT）的序列建模能力和评论家网络的价值指导。具体来说，利用评论家网络对DT模型进行正则化训练，以实现从次优数据集学习有效策略。此外，通过采用预训练的大型语言模型（LLM）作为DT模型的Transformer骨干，并结合参数高效的微调策略（LoRA），降低了对数据集规模和计算资源的要求。

Result: LLM-CRDT框架通过结合DT的序列建模能力和评论家网络的价值指导，并利用预训练LLM和LoRA进行高效微调，在无人机轨迹规划和资源分配任务中展现出优越性能。与现有的在线和离线RL方法以及先进的DT方法相比，LLM-CRDT在能源效率方面取得了显著提升，最高可达36.7%。

Conclusion: 本文提出的LLM-CRDT框架成功解决了无人机数据收集中的轨迹规划和资源分配问题，通过创新的方法显著提高了能源效率，并克服了现有方法的局限性，证明了其在实际应用中的潜力和优越性。

Abstract: The deployment of unmanned aerial vehicles (UAVs) for reliable and
energy-efficient data collection from spatially distributed devices holds great
promise in supporting diverse Internet of Things (IoT) applications.
Nevertheless, the limited endurance and communication range of UAVs necessitate
intelligent trajectory planning. While reinforcement learning (RL) has been
extensively explored for UAV trajectory optimization, its interactive nature
entails high costs and risks in real-world environments. Offline RL mitigates
these issues but remains susceptible to unstable training and heavily rely on
expert-quality datasets. To address these challenges, we formulate a joint UAV
trajectory planning and resource allocation problem to maximize energy
efficiency of data collection. The resource allocation subproblem is first
transformed into an equivalent linear programming formulation and solved
optimally with polynomial-time complexity. Then, we propose a large language
model (LLM)-empowered critic-regularized decision transformer (DT) framework,
termed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we
incorporate critic networks to regularize the DT model training, thereby
integrating the sequence modeling capabilities of DT with critic-based value
guidance to enable learning effective policies from suboptimal datasets.
Furthermore, to mitigate the data-hungry nature of transformer models, we
employ a pre-trained LLM as the transformer backbone of the DT model and adopt
a parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid
adaptation to UAV control tasks with small-scale dataset and low computational
overhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark
online and offline RL methods, achieving up to 36.7\% higher energy efficiency
than the current state-of-the-art DT approaches.

</details>


### [140] [Distributionally Robust Equilibria over the Wasserstein Distance for Generalized Nash Game](https://arxiv.org/abs/2509.13985)
*Yixun Wen,Yulong Gao,Boli Chen*

Main category: eess.SY

TL;DR: 该研究提出了一个解决共享分布鲁棒机会约束（DRCCs）的广义纳什均衡问题（GNEP）的精确方法，该方法将问题转化为确定性模型，并利用Nikaido-Isoda函数，在目标函数为二次的情况下，问题可以简化为混合整数非线性规划（MINLP）问题，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体协作优化决策中的广义纳什均衡问题（GNEP），并考虑不确定性，引入了共享分布鲁棒机会约束（DRCCs）。

Method: 将GNEP转化为确定性模型，利用Nikaido-Isoda函数。当所有主体的目标函数是关于其各自变量的二次函数时，可以将均衡问题转化为混合整数非线性规划（MINLP）问题，其中整数和连续变量在目标函数和约束中是解耦的。

Result: 在主体目标函数为二次函数的情况下，提出的方法可以将问题转化为混合整数非线性规划（MINLP）问题，从而提高计算效率。通过一个充电站定价问题的案例研究证明了这一点。

Conclusion: 该方法通过将GNEP转化为确定性模型和利用MINLP问题的结构，有效地解决了具有共享分布鲁棒机会约束的GNEP问题，并在实际应用中具有计算优势。

Abstract: Generalized Nash equilibrium problem (GNEP) is fundamental for practical
applications where multiple self-interested agents work together to make
optimal decisions. In this work, we study GNEP with shared distributionally
robust chance constraints (DRCCs) for incorporating inevitable uncertainties.
The DRCCs are defined over the Wasserstein ball, which can be explicitly
characterized even with limited sample data. To determine the equilibrium of
the GNEP, we propose an exact approach to transform the original
computationally intractable problem into a deterministic formulation using the
Nikaido-Isoda function. Specifically, we show that when all agents' objectives
are quadratic in their respective variables, the equilibrium can be obtained by
solving a typical mixed-integer nonlinear programming (MINLP) problem, where
the integer and continuous variables are decoupled in both the objective
function and the constraints. This structure significantly improves
computational tractability, as demonstrated through a case study on the
charging station pricing problem.

</details>


### [141] [Day-Ahead Transmission Grid Topology Optimization Considering Renewable Energy Sources' Uncertainty](https://arxiv.org/abs/2509.13994)
*Giacomo Bastianel,Dirk Van Hertem,Hakan Ergun,Line Roald*

Main category: eess.SY

TL;DR: 可再生能源发电量的不确定性给电网运营带来挑战，尤其是在现有输电网络拥堵且扩建延迟的情况下。本文提出了一种结合最优输电潮流开关和母线分段的电网拓扑优化模型，用于交流和混合交流/直流电网。该模型考虑了可再生能源发电量预测的不确定性，并通过基于场景的随机优化方法进行处理，使用了真实的离岸风电数据和K-means聚类生成代表性的预测误差场景。模型提供了多种优化方案，例如每小时优化拓扑、24小时固定拓扑或每日有限次拓扑调整。模型被表述为混合整数二次凸问题，并基于日前（D-1）可再生能源预测进行优化，通过交流最优潮流（AC-OPF）进行交流可行性验证。随后，基于可行性检查的发电设置点，进行基于实际（D）可再生能源情况的再调度模拟。该方法在30节点交流测试案例和50节点混合交流/直流测试案例上进行了测试，分别进行了24小时和14天的仿真。结果表明，在可再生能源渗透率高且电网拥堵的情况下，电网拓扑优化能带来经济效益。此外，即使限制拓扑调整次数，使用至少6到8个场景来考虑可再生能源不确定性，也能实现与确定性日前预测相当或更低的总体成本。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源渗透率的提高，电网运营面临着日益增长的不确定性。同时，现有的输电网络常常已经拥堵，并且由于各种限制，急需的扩建工程经常被延迟。为了应对这些挑战，基于拥堵模式调整电网拓扑被认为是一种经济有效的解决方案，能够保证高效的电力传输。

Method: 提出了一种结合最优输电潮流开关和母线分段的电网拓扑优化模型，用于交流和混合交流/直流电网。该模型采用基于场景的随机优化方法来处理可再生能源发电量预测的不确定性，并利用真实数据和聚类算法生成预测误差场景。模型被表述为混合整数二次凸问题，并与最优潮流（OPF）模型进行比较，考虑了不同的拓扑优化策略（例如，每小时优化、24小时固定拓扑、有限次调整）。通过交流最优潮流（AC-OPF）进行可行性验证，并进行基于实际情况的再调度模拟。

Result: 在30节点交流测试案例和50节点混合交流/直流测试案例上进行的仿真结果表明，电网拓扑优化在可再生能源渗透率高且电网拥堵的情况下，能够带来显著的经济效益。研究还发现，即使限制拓扑调整次数，使用6到8个场景来考虑可再生能源的不确定性，也能获得与确定性日前预测相当或更优的总成本。

Conclusion: 电网拓扑优化，特别是结合最优输电潮流开关和母线分段，是一种有效的策略，可以应对高可再生能源渗透率和电网拥堵带来的挑战。考虑可再生能源预测的不确定性对于实现经济高效的电网运营至关重要，并且使用适当数量的场景进行随机优化可以带来比确定性方法更好的结果。

Abstract: The increasing renewable penetration introduces significant uncertainty in
power system operations. At the same time, the existing transmission grid is
often already congested, and urgently needed reinforcements are frequently
delayed due to several constraints. To address these challenges, adjusting the
grid topology based on congestion patterns is considered a non-costly remedy to
guarantee efficient power transmission. Based on this idea, this paper proposes
a grid topology optimization model combining optimal transmission switching and
busbar splitting for AC and hybrid AC/DC grids. The methodology incorporates
RES forecast uncertainty through a scenario-based stochastic optimization
approach, using real offshore wind data and K-means clustering to generate
representative forecast error scenarios. The proposed model includes several
formulations to be compared with a plain optimal power flow (OPF) model: hourly
optimizing the topology, one topology for 24 hours, or a limited number of
switching actions over a day. The grid topology optimization model is
formulated as a Mixed-Integer Quadratic Convex Problem, optimized based on the
day-ahead (D-1) RES forecast and validated for AC-feasibility via an AC-OPF
formulation. Based on the generation setpoints of the feasibility check, a
redispatch simulation based on the measured (D) RES realization is then
computed. The methodology is tested on an AC 30-bus test case and a hybrid
AC/DC 50-bus test case, for a 24-hours (30-bus) and a 14-days (both test cases)
time series. The results highlight the economic benefits brought by grid
topology optimization for congested test cases with high penetration of RES. In
addition, the results demonstrate that accounting for RES uncertainty with at
least 6 to 8 scenarios leads to lower or comparable total costs to
deterministic day-ahead forecasts, even when limiting the frequency of
topological actions.

</details>


### [142] [Dissipativity-Based Data-Driven Decentralized Control of Interconnected Systems](https://arxiv.org/abs/2509.14047)
*Taiki Nakano,Ahmed Aboudonia,Jaap Eising,Andrea Martinelli,Florian Dörfler,John Lygeros*

Main category: eess.SY

TL;DR: 该论文提出了一种数据驱动的去中心化控制算法，用于稳定互联系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决互联系统稳定性的问题，提出数据驱动的去中心化控制算法。

Method: 首先，推导了一个数据驱动的条件来合成局部控制器，以确保局部子系统的耗散性。然后，基于每个局部系统的耗散性，提出了全局系统的数据驱动的去中心化稳定性条件。这两种条件都采用线性矩阵不等式的形式，并基于耗散性理论，形成了一个统一的流程，最终得到一个数据驱动的去中心化控制算法。此外，还专门讨论了通过扩散耦合互联的系统的稳定性问题，并提出了一种控制算法。

Result: 所提出的控制算法在微电网等互联系统中得到了验证，证明了其有效性和可扩展性。

Conclusion: 数据驱动的去中心化控制算法能够有效地稳定互联系统，并且具有良好的可扩展性。

Abstract: We propose data-driven decentralized control algorithms for stabilizing
interconnected systems. We first derive a data-driven condition to synthesize a
local controller that ensures the dissipativity of the local subsystems. Then,
we propose data-driven decentralized stability conditions for the global system
based on the dissipativity of each local system. Since both conditions take the
form of linear matrix inequalities and are based on dissipativity theory, this
yields a unified pipeline, resulting in a data-driven decentralized control
algorithm. As a special case, we also consider stabilizing systems
interconnected through diffusive coupling and propose a control algorithm. We
validate the effectiveness and the scalability of the proposed control
algorithms in numerical examples in the context of microgrids.

</details>


### [143] [Identifying Network Structure of Linear Dynamical Systems: Observability and Edge Misclassification](https://arxiv.org/abs/2509.14065)
*Jaidev Gill,Jing Shuang Li*

Main category: eess.SY

TL;DR: 研究了从部分节点测量中唯一识别线性网络拓扑的局限性，并提出了解决此问题的方法和结果。


<details>
  <summary>Details</summary>
Motivation: 研究线性网络拓扑识别的局限性，并为拓扑推断方法的设计提供指导。

Method: 通过可观察性矩阵的零空间来表征与测量一致的网络集，并解析求解最结构上不相似的网络。

Result: 在随机网络模型（如 Erdős-Rényi 和 Watts-Strogatz）中，当观察超过 6% 的节点时，边误分类率下降到约 1%。

Conclusion: 当观察超过 6% 的节点时，线性网络拓扑的识别率很高。此外，通过构造一个使测量值彼此“接近”的网络族，并将这些网络的可识别性与增强的可观察性 Gramian 的谱性质联系起来，为进一步研究提供了理论基础。

Abstract: This work studies the limitations of uniquely identifying a linear network's
topology from partial measurements of its nodes. We show that the set of
networks that are consistent with the measurements are related through the
nullspace of the observability matrix for the true network. In doing so, we
illustrate how potentially many networks are fully consistent with the
measurements despite having topologies that are structurally inconsistent with
each other, an often neglected consideration in the design of topology
inference methods. We then provide an aggregate characterization of the space
of possible networks by analytically solving for the most structurally
dissimilar network. We find that when observing over 6% of nodes in random
network models (e.g., Erd\H{o}s-R\'{e}nyi and Watts-Strogatz) the rate of edge
misclassification drops to ~1%. Extending this discussion, we construct a
family of networks that keep measurements $\epsilon$-"close" to each other, and
connect the identifiability of these networks to the spectral properties of an
augmented observability Gramian.

</details>


### [144] [Asymptotic Boundedness of Distributed Set-Membership Filtering](https://arxiv.org/abs/2509.14106)
*Yudong Li,Yirui Cong,Shimin Wang,Martin Guay,Jiuxiang Dong*

Main category: eess.SY

TL;DR: 本文研究了线性离散时间系统的分布式集合成员过滤（DSMFing）的渐近有界性问题，并提出了一种名为“集体观测-信息塔”（COIT）的新概念来分析图结构与集合估计之间的关系，从而得出了一个易于验证的充分条件，该条件推广了DOs和DKFs中的集体可检测性条件，并揭示了DSMFs的独特之处。


<details>
  <summary>Details</summary>
Motivation: DSMFing的渐近有界性对于防止集合估计由于包装效应而无界增长至关重要，但相较于其无噪声和随机噪声的对应物（DOs的收敛性和DKFs的有界误差协方差），该性质的研??尚不足。

Method: 提出了一种名为“集体观测-信息塔”（COIT）的新概念，用于表征图结构与集合估计之间的基本关系，以实现有界性分析。利用COIT，建立了一个易于验证的线性DSMFing渐近有界性的充分条件。

Result: 提出了一种名为“集体观测-信息塔”（COIT）的新概念，并建立了一个易于验证的充分条件，该条件推广了DOs和DKFs中的集体可检测性条件，连接了DSMFs与现有的分布式估计算法，并揭示了DSMFs的独特性。

Conclusion: 本文成功地解决了线性离散时间系统的DSMFing渐近有界性问题，提出的COIT概念和充分条件不仅为分析该问题提供了新工具，还统一了分布式估计算法中的一些关键概念，并突出了DSMFs的独特性。

Abstract: Asymptotic boundedness is a crucial property of Distributed Set-Membership
Filtering (DSMFing) that prevents the unbounded growth of the set estimates
caused by the wrapping effect. However, this important property remains
underinvestigated, compared to its noise-free and stochastic-noise
counterparts, i.e., the convergence of Distributed Observers (DOs) and the
bounded error covariance of Distributed Kalman Filters (DKFs). This paper
studies the asymptotic boundedness of DSMFing for linear discrete-time systems.
A novel concept, termed the Collective Observation-Information Tower (COIT), is
introduced to characterize the fundamental relationship between the structure
of graphs and the set estimates, which enables the boundedness analysis.
Leveraging the COIT, an easily verifiable sufficient condition for the
asymptotic boundedness of linear DSMFing is established. Surprisingly, the
sufficient condition generalizes the well-known collective detectability
condition for DOs and DKFs; it links DSMFs to existing distributed estimation
methods and reveals the unique characteristic of DSMFs.

</details>


### [145] [Safe Sliding Mode Control in Position for Double Integrator Systems](https://arxiv.org/abs/2509.14121)
*Marco A. Gomez,Christopher D. Cruz-Ancona*

Main category: eess.SY

TL;DR: 当约束仅在位置状态上定义时，可以从已有的安全积分器动力学构建一个安全的滑动域，以实现双积分器系统的鲁棒安全控制。


<details>
  <summary>Details</summary>
Motivation: 设计双积分器系统的鲁棒安全控制器，特别是在约束仅限于位置状态的情况下。

Method: 利用一阶积分器的安全动力学来构建一个安全的滑动域，并在此域上设计一个控制器增益，以确保闭环轨迹在不确定性和干扰下保持鲁棒和安全，同时避免给定的不安全集合。该方法从一阶滑模概念开始，并推广到自适应框架。

Result: 设计了一个安全的滑动域，并确定了一个控制器增益，该增益可将轨迹收敛到该滑动域，并使其保持在不安全区域之外，同时适应不确定性和干扰。

Conclusion: 该方法能够为双积分器系统设计鲁棒的安全控制器，即使在只有位置约束的情况下也能有效运行，并能保证系统轨迹在安全范围内。

Abstract: We address the problem of robust safety control design for double integrator
systems. We show that, when the constraints are defined only on position
states, it is possible to construct a safe sliding domain from the dynamic of a
simple integrator that is already safe. On this domain, the closed-loop
trajectories remain robust and safe against uncertainties and disturbances.
Furthermore, we design a controller gain that guarantees convergence to the
safe sliding domain while avoiding the given unsafe set. The concept is
initially developed for first-order sliding mode and is subsequently
generalized to an adaptive framework, ensuring that trajectories remain
confined to a predefined vicinity of the sliding domain, outside the unsafe
region.

</details>


### [146] [Factored Output Feedback Controller Synthesis with Locality Constraints for Spatially-Invariant Systems](https://arxiv.org/abs/2509.14168)
*Walden Marshall*

Main category: eess.SY

TL;DR: 本文研究了具有空间不变性的系统的H2输出反馈控制器综合问题，并对通信距离（局部性）施加了预定约束。


<details>
  <summary>Details</summary>
Motivation: 在具有空间不变性的系统的背景下，研究具有通信距离（局部性）约束的H2输出反馈控制器综合问题。

Method: 使用两个分解的控制器框架（系统级参数化和输入-输出参数化）来解决问题，并将控制器综合问题制定为有限的传递函数变量中的凸问题。

Result: 证明了在两种参数化框架下，具有局部性约束的输出反馈控制器综合问题都可以被表述为凸问题，并可以使用标准的数值技术求解。最优控制器设计问题的决策变量数量与允许的通信距离成线性关系。此外，还证明了对于所选的系统，系统级和输入-输出参数化的最优控制器设计问题是等价的。

Conclusion: 所提出的方法允许在控制器设计中考虑通信约束，并且可以通过数值示例说明通信稀疏性和性能之间的权衡。

Abstract: We consider H2 output feedback controller synthesis with pre-specified
constraints on spatial communication distance (locality) for
spatially-invariant systems using two factored controller frameworks: the
system-level parameterization and the input-output parameterization. In our
main result, we show that in both frameworks, output feedback controller
synthesis with locality constraints can be formulated as a convex problem in
finitely many transfer function variables, admitting the use of standard
numerical solution techniques. The number of decision variables in the optimal
controller design problem scales linearly with the distance of allowed
communication. We also show that the optimal controller design problems for the
system-level and input-ouptput parameterizations are equivalent for the chosen
system of interest. We present numerical examples to illustrate the tradeoff
between communication sparsity and performance.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [147] [Tunable Random Telegraph Noise in Stable Perpendicular Magnetic Tunnel Junctions for Unconventional Computing](https://arxiv.org/abs/2509.13458)
*Ahmed Sidi El Valli,Michael Tsao,Dairong Chen,Andrew D. Kent*

Main category: cond-mat.mes-hall

TL;DR: thermally stable pMTJs can be actuated with nanosecond pulses to exhibit tunable stochastic behavior (A-sMTJs), producing controllable random telegraph noise consistent with a Poisson process, advancing computing systems.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that thermally stable perpendicular magnetic tunnel junctions (pMTJs), commonly used in spintransfer torque magnetic random-access memory, can be actuated using nanosecond pulses to display tunable stochastic behavior.

Method: Actuating pMTJs with nanosecond pulses to create A-sMTJs and characterizing their stochastic behavior, including fluctuation rate and probability bias, and showing consistency with a Poisson process.

Result: A-sMTJs exhibit random telegraph noise with fluctuation rates tunable over more than two orders of magnitude, and average state dwell times ranging from 29 ns to over 2.3 microseconds. The device response aligns with a Poisson process.

Conclusion: A-sMTJs provide a flexible platform for integrating deterministic, stochastic, and in-memory functionalities on a single chip, supporting the advancement of probabilistic, neuromorphic, and unconventional computing systems.

Abstract: We demonstrate that thermally stable perpendicular magnetic tunnel junctions
(pMTJs), widely used in spin-transfer torque magnetic random-access memory, can
be actuated with nanosecond pulses to exhibit tunable stochastic behavior. This
actuated-stochastic tunnel junction (A-sMTJ) concept produces random telegraph
noise, with control over fluctuation rate and probability bias. The device
response is shown to be consistent with a Poisson process, with fluctuation
rates tunable over more than two orders of magnitude, with average state dwell
times varying from 29 ns to greater than 2.3 microseconds. These results
establish A-sMTJs as a versatile platform for integrating deterministic,
stochastic, and in-memory functionality on a single chip, advancing the
development of probabilistic, neuromorphic, and unconventional computing
systems.

</details>


### [148] [Superparamagnetic and Stochastic-Write Magnetic Tunnel Junctions for High-Speed True Random Number Generation in Advanced Computing](https://arxiv.org/abs/2509.13469)
*Jonathan Z. Sun,Christopher Safranski,Siyuranga Koswata,Pouya Hashemi,Andrew D. Kent*

Main category: cond-mat.mes-hall

TL;DR: 本文介绍了两种用于紧凑、低功耗、CMOS集成真随机数生成器(TRNG)的磁性隧道结(MTJ)方法：sMTJ和SW-MTJ。sMTJ利用热涨落产生数据流，速率为0.5-1 Gb/s；SW-MTJ利用随机写脉冲产生约0.5的开关概率，速率约为0.1 Gb/s。两种方法产生的随机性均通过NIST SP800测试套件验证。sMTJ功耗低，兼容先进CMOS节点；SW-MTJ利用标准CMOS MTJ工艺，可与STT-MRAM共集成。两种方法的MTJ尺寸均可达0.01 μm²以下，能效比CPU/GPU生成器高几个数量级。


<details>
  <summary>Details</summary>
Motivation: 为了实现紧凑、低功耗、CMOS集成的真随机数生成器(TRNG)，本文研究了两种基于磁性隧道结(MTJ)的方法。

Method: 本文提出并分析了两种MTJ方法：1. 被动读取的易平面超顺磁MTJ(sMTJ)，利用热涨落产生随机比特流，速率为0.5-1 Gb/s。2. 具有磁稳定自由层的MTJ，通过随机写脉冲操作，实现约0.5的开关概率，速率约为0.1 Gb/s，称为随机写MTJ(SW-MTJ)。

Result: 两种方法产生的随机性均通过NIST SP800测试套件验证。sMTJ功耗低，兼容先进CMOS节点；SW-MTJ利用标准CMOS MTJ工艺，可与STT-MRAM共集成。两种方法的MTJ尺寸均可达0.01 μm²以下，能效比CPU/GPU生成器高几个数量级。sMTJ适用于需要高数据速率随机比特的应用；SW-MTJ适用于边缘计算微控制器，可提供熵源。

Conclusion: sMTJ和SW-MTJ是两种有前景的TRNG技术，各有优劣。sMTJ适用于高吞吐量应用，而SW-MTJ则适用于边缘设备。未来的工作需要解决sMTJ的器件间变异性问题（特别是磁致伸缩引起的平面磁异方性）以及SW-MTJ的时间稳定性问题，以实现可靠的大规模部署。

Abstract: We review two magnetic tunnel junction (MTJ) approaches for compact,
low-power, CMOS-integrated true random number generation (TRNG). The first
employs passive-read, easy-plane superparamagnetic MTJs (sMTJs) that generate
thermal-fluctuation-driven bit streams at $0.5$--$1$~Gb/s per device. The
second uses MTJs with magnetically stable free layers, operated with stochastic
write pulses to achieve switching probabilities of about $0.5$ (\emph{i.e.},
write error rates of $\simeq 0.5$), achieving $\gtrsim 0.1$~Gb/s per device; we
refer to these as stochastic-write MTJs (SW-MTJs). Randomness from both
approaches has been validated using the NIST~SP800 test suites. The sMTJ
approach uses a read-only cell with low power and can be compatible with most
advanced CMOS nodes, while SW-MTJs leverage standard CMOS MTJ process flows,
enabling co-integration with embedded spin-transfer torque magnetic random
access memory (STT-MRAM). Both approaches can achieve deep sub-0.01~$\mu$m$^2$
MTJ footprints and offer orders-of-magnitude better energy efficiency than
CPU/GPU-based generators, enabling placement near logic for high-throughput
random bit-streams for probabilistic computing, statistical modeling, and
cryptography. In terms of performance, sMTJs generally suit applications
requiring very high data-rate random bits near logic processors, such as
probabilistic computing or large-scale statistical modeling. By contrast,
SW-MTJs are an attractive option for edge-oriented microcontrollers, providing
entropy sources for computing or cryptographic enhancement. We highlight the
strengths, limitations, and integration challenges of each approach,
emphasizing the need to reduce device-to-device variability in sMTJs --
particularly by mitigating magnetostriction-induced in-plane anisotropy -- and
to improve temporal stability in SW-MTJs for robust, large-scale deployment.

</details>


### [149] [Bilayer graphene quantum dots as a quantum simulator of Haldane topological quantum matter](https://arxiv.org/abs/2509.13495)
*Daniel Miravet,Hassan Allami,Marek Korkusinski,Pawel Hawrylak*

Main category: cond-mat.mes-hall

TL;DR: Bilayer Graphene Quantum Dots (BLGQD) can simulate a spin-1 chain exhibiting the Haldane phase, realizing topological quantum matter.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of BLGQD chains in simulating topological quantum matter, specifically the Haldane phase of a spin-1 chain.

Method: Utilizing an atomistic tight-binding model and exact diagonalization to solve the interacting few-electron problem in BLGQDs, including Coulomb interactions and valley mixing. Investigating spin and valley polarization transitions and calculating low-energy states for single and double QDs. Mapping BLGQD chains to an effective bilinear-biquadratic (BLBQ) spin model.

Result: Confirmed the presence of a spin-one ground state for two electrons in BLGQDs. Identified regimes of highly correlated multi-electron states. Demonstrated that BLGQD arrays can function as quantum simulators for 1D spin chains with emergent topological phases.

Conclusion: BLGQD chains can effectively simulate spin-1 chains and host topological quantum matter like the Haldane phase, with BLGQD arrays acting as quantum simulators for 1D spin chains exhibiting emergent topological phases.

Abstract: We demonstrate here that a chain of Bilayer Graphene Quantum Dots (BLGQD) can
realize topological quantum matter by effectively simulating a spin-1 chain
that hosts the Haldane phase within a specific range of parameters. We describe
a chain of BLGQD with two electrons each using an atomistic tight-binding model
combined with the exact diagonalization technique to solve the interacting
few-electron problem. Coulomb interactions and valley mixing effects are
treated within the same microscopic framework, allowing us to systematically
investigate spin and valley polarization transitions as functions of
interaction strength and external tuning parameters. We calculate the low
energy states for single and double QDs as a function of the number of
electrons, identifying regimes of highly correlated multi-electron states. We
confirm the presence of a spin-one ground state for two electrons. Then, we
explore two coupled QDs with 4 electrons and extend the analysis to QD arrays.
Using a mapping of the BLGQD chain to an effective bilinear-biquadratic (BLBQ)
spin model, we demonstrate that BLGQD arrays can work as a quantum simulator
for one-dimensional spin chains with emergent many-body topological phases.

</details>


### [150] [Axial Hall Effect in Altermagnetic Lieb Lattices](https://arxiv.org/abs/2509.13554)
*Xilong Xu,Haonan Wang,Li Yang*

Main category: cond-mat.mes-hall

TL;DR: Lieb晶格的altermagnets中存在一个由Berry曲率驱动的轴向霍尔效应，该效应由Dresselhaus自旋-轨道耦合和压磁响应引起，并具有拓扑性质。


<details>
  <summary>Details</summary>
Motivation: 探索altermagnets中新的内禀霍尔现象，特别是与自旋-轨道耦合和非共线自旋结构相关的现象。

Method: 构建紧束缚模型和进行第一性原理计算，研究应变对altermagnets中轴向霍尔效应的影响，并分析其在多层系统中的表现。

Result: 在Lieb晶格的altermagnets中发现了轴向霍尔效应，并证实了其由Berry曲率驱动。计算结果表明，该效应在应变altermagnets（特别是三元过渡金属二卤代物）中会出现。以Mn2WS4为例，发现该效应源于Dresselhaus自旋-轨道耦合与压磁响应的相互作用，导致Berry曲率的高度局部化和增强。轴向霍尔效应的幅度很大，并且不随应变变化。在多层系统中，该效应表现为异常霍尔和自旋霍尔响应随厚度的依赖性调制。

Conclusion: 轴向霍尔效应是一个由Berry曲率驱动的、具有拓扑性质的霍尔响应，在Lieb晶格的altermagnets中存在。该效应的发现为在拓扑磁性系统中探索内禀霍尔现象开辟了新途径。

Abstract: We predict a so-called axial Hall effect, a Berry-curvature-driven anomalous
Hall response, in Lieb-lattice altermagnets. By constructing a tight-binding
model, we identify the axial direction as a hidden topological degree of
freedom. Breaking the double degeneracy of axial symmetry generates substantial
Berry curvature and induces a pronounced anomalous Hall conductivity.
First-principles calculations further confirm the emergence of this effect in
strained altermagnets, particularly in ternary transition-metal
dichalcogenides. We take Mn2WS4 as an example to reveal that the axial Hall
effect originates from the interplay between Dresselhaus spin-orbit coupling
and the intrinsic piezomagnetic response of Lieb-lattice altermagnets, leading
to highly localized and enhanced Berry curvature. Remarkably, the magnitude of
the axial Hall effect is significant and remains unchanged when varying the
strain, highlighting the topological nature of the axial degree of freedom.
Finally, in multilayer systems, the effect manifests as a distinctive
thickness-dependent modulation of both anomalous and spin Hall responses. These
findings emphasize the critical role of spin-orbit coupling and noncollinear
spin textures in altermagnets, an area that has received limited attention, and
open new pathways for exploring intrinsic Hall phenomena in topological
magnetic systems.

</details>


### [151] [Crystal Orientation Dependence of Extreme Near-Field Heat Transfer between Polar Materials Governed by Surface Phonon Modes](https://arxiv.org/abs/2509.13837)
*Wei-Zhe Yuan,Yangyu Guo,Hong-Liang Yi*

Main category: cond-mat.mes-hall

TL;DR: 研究了晶体取向对MgO纳米间隙热传输的影响，发现在极近距离时晶体取向显著影响热导，而在较大距离时影响减弱，这与表面声子模式和流体动力学理论有关。


<details>
  <summary>Details</summary>
Motivation: 微纳制造和电子器件的快速发展使得辐射和传导之间的过渡状态下的热传输日益重要，但晶体取向对其影响尚不明确。

Method: 使用非平衡分子动力学（NEMD）模拟研究了镁橄榄石（MgO）之间真空间隙中的热传输，重点关注了晶体取向的影响。

Result: 在5埃的间隙下，[100]取向相比于[110]和[210]取向，整体热导率提高了30%，而在6埃以上则无明显取向依赖性。极小间隙时，晶体取向显著影响了与表面声子模式相关的光谱热导共振频率。随着间隙增大，光谱热导逐渐符合长波近似下的流体动力学理论预测。

Conclusion: 表面声子模式在控制纳米间隙中的近场热传输方面起着关键作用，为电子器件的热管理提供了新的见解。

Abstract: Due to the rapid development of micro- and nano-manufacturing and electronic
devices, heat transfer at the transition regime between radiation and
conduction becomes increasingly important. Recent work has demonstrated the
importance of nonlocal optical response and phonon tunneling. However, it
remains unclear how the crystal orientation impacts them. In this work, we
study this effect on heat transport across vacuum gaps between magnesium oxide
(MgO) by nonequilibrium molecular dynamics (NEMD) simulation. At 5~\AA~gaps,
the overall thermal conductance exhibits 30\% enhancement for [100] orientation
versus [110] and [210], while becoming orientation-insensitive beyond 6~\AA.
When the gap size is extremely small, the crystal orientation significantly
impacts the resonance frequencies of spectral thermal conductance which are
quite close to those of unique surface phonon modes distinct from bulk
counterparts. As the gap size gradually increases, the spectral thermal
conductance gradually converges to the predicted results of
fluctuation-electrodynamics (FE) theory in the long-wavelength approximation.
Our findings reveal how surface phonon modes govern extreme near-field heat
transfer across nanogap, providing insights for thermal management in
electronic devices.

</details>


### [152] [Three-dimensional magnetization textures as quaternionic functions](https://arxiv.org/abs/2509.13902)
*Konstantin L. Metlov,Andrei B. Bogatyrëv*

Main category: cond-mat.mes-hall

TL;DR: 三维磁化纹理的分析表示可用于新的自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: 与一维畴壁或二维磁涡/斯格明子相比，三维磁化纹理更难表示、分析和推理，但它们有望在自旋电子学应用中提供更高信息密度。

Method: 通过简单四元数函数的乘积构建三维磁化纹理（具有任意数量的无奇点霍普夫和奇点布洛赫点对）的解析表示。

Result: 提出了一个可以表示三维磁化纹理的数学框架，可用于模拟。

Conclusion: 所提出的分析表示可作为表达三维磁化纹理理论模型和为微磁模拟指定拓扑非平凡初始条件的语言。

Abstract: Thanks to the recent progress in bulk full three-dimensional nanoscale
magnetization distribution imaging, there is a growing interest to
three-dimensional (3D) magnetization textures, promising new high information
density spintronic applications. Compared to 1D domain walls or 2D magnetic
vortices/skyrmions, they are a much harder challenge to represent, analyze and
reason about. In this Letter we build analytical representation for such a
textures (with arbitrary number of singularity-free hopfions and singular Bloch
point pairs) as products of simple quaternionic functions. It can be useful as
a language for expressing theoretical models of 3D magnetization textures and
specifying a variety of topologically non-trivial initial conditions for
micromagnetic simulations.

</details>


### [153] [Non-universal Thermal Hall Responses in Fractional Quantum Hall Droplets](https://arxiv.org/abs/2509.14058)
*Fei Tan,Yuzhu Wang,Xinghao Wang,Bo Yang*

Main category: cond-mat.mes-hall

TL;DR: 滴,滴,滴,滴


<details>
  <summary>Details</summary>
Motivation: 滴,滴,滴,滴

Method: 滴,滴,滴,滴

Result: 滴,滴,滴,滴

Conclusion: 滴,滴,滴,滴

Abstract: We analytically compute the thermal Hall conductance (THC) of fractional
quantum Hall droplets under realistic conditions that go beyond the idealized
linear edge theory with conformal symmetry. Specifically, we consider
finite-size effects at low temperature, nonzero self-energies of quasiholes,
and general edge dispersions. We derive measurable corrections in THC that
align well with the experimental observables. Although the quantized THC is
commonly regarded as a topological invariant that is independent of edge
confinement, our results show that this quantization remains robust only for
arbitrary edge dispersion in the thermodynamic limit. Furthermore, the THC
contributed by Abelian modes can become extremely sensitive to finite-size
effects and irregular confining potentials in any realistic experimental
system. In contrast, non-Abelian modes show robust THC signatures under
perturbations, indicating an intrinsic stability of non-Abelian anyons.

</details>


### [154] [Spin-dependent signatures of Majorana modes in thermoelectric transport through double quantum dots](https://arxiv.org/abs/2509.14108)
*Piotr Majek,Ireneusz Weymann*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过数值重正化群方法，分析了双量子点系统在拓扑超导纳米线和铁磁源/漏之间的自旋相关热电性质，特别是塞贝克系数。


<details>
  <summary>Details</summary>
Motivation: 在低温输运区，研究了由两级近藤效应、铁磁诱导交换场和马约拉纳耦合引起的复杂相互作用，旨在探索热电测量如何揭示马约拉纳相互作用的独特信号。

Method: 采用数值重正化群方法进行计算。

Result: 研究表明，热电测量比单独的电导测量更能揭示马约拉纳相互作用的信号。交换场会改变热电响应，导致热电势呈现复杂的非单调温度演化。发现了由马约拉纳诱导的不对称性和源/漏极的自旋极化控制的不同自旋热电产生机制。

Conclusion: 热电输运可以作为一种敏感的探测马约拉纳特征的方法，并且可以将系统的热电响应与由电导自旋极化量化的潜在输运不对称性联系起来，提供一个统一的物理图像。

Abstract: We present a comprehensive theoretical analysis of the spin-dependent
thermoelectric properties of a double quantum dot system coupled to a
topological superconducting nanowire and ferromagnetic leads. The study focuses
on the behavior of the Seebeck coefficient and its spin-resolved counterparts,
with calculations performed by means of the numerical renormalization group
method. We investigate the low-temperature transport regime, where a complex
interplay between the two-stage Kondo effect, the ferromagnet-induced exchange
field, and the Majorana coupling occurs. We demonstrate that thermoelectric
measurements can reveal unique signatures of the Majorana interaction that are
challenging to isolate in conductance measurements alone. It is shown that the
exchange field fundamentally alters the thermoelectric response, leading to a
rich, non-monotonic temperature evolution of the thermopower, which is driven
by a temperature-dependent competition between the spin channels. Furthermore,
we have identified qualitatively different regimes of spin thermopower
generation, controlled by the interplay between the Majorana-induced asymmetry
and the spin polarization of the leads. Finally, by connecting the system's
thermoelectric response to the underlying transport asymmetries quantified by
the conductance spin polarization, we provide a consistent and unified physical
picture, proposing thermoelectric transport as a sensitive probe for Majorana
signatures.

</details>


### [155] [Field-free transverse Josephson diode effect in altermagnets](https://arxiv.org/abs/2509.14109)
*Bijay Kumar Sahoo,Abhiram Soori*

Main category: cond-mat.mes-hall

TL;DR: Rashba耦合的altermagnets可以在没有外部磁场的情况下实现横向约瑟夫森二极管效应(TJDE)。


<details>
  <summary>Details</summary>
Motivation: 研究具有Rashba自旋-轨道耦合的altermagnets如何实现无需外部磁场即可工作的横向约瑟夫森二极管效应。

Method: 提出了一种四端约瑟夫森结，其中对向超导端子之间的纵向相位偏压会在无偏压的端子中产生横向超电流，这种横向电流表现出二极管状的不可逆性和有限的反常相位偏移，揭示了横向反常约瑟夫森效应(AJE)。

Result: 在某些参数范围内，横向电流变为单向的，TJDE效率可以超过1000%，表现出极强的二极管行为。TJDE和横向AJE的大小和方向可以通过旋转Néel矢量进行调节。

Conclusion: altermagnets为在多端子器件中工程化无场不可逆超导输运提供了一个多功能的平台。

Abstract: We show that altermagnets (AMs) with Rashba spin--orbit coupling can host a
transverse Josephson diode effect (TJDE) without any external magnetic field.
AMs combine zero net magnetization with spin-polarized Fermi surfaces, enabling
the simultaneous breaking of inversion and time-reversal symmetries. We propose
a four-terminal Josephson junction where a longitudinal phase bias between
opposite superconducting terminals generates transverse supercurrents in the
unbiased terminals. These transverse currents exhibit both a diode-like
nonreciprocity and a finite anomalous phase offset, revealing a transverse
anomalous Josephson effect (AJE). For certain parameter regimes, the transverse
current becomes unidirectional, and the TJDE efficiency can exceed 1000\%,
demonstrating exceptionally strong diode behavior. Remarkably, the magnitude
and direction of the TJDE and transverse AJE are tunable by rotating the N\'eel
vector. Our results establish altermagnets as a versatile platform for
engineering field-free nonreciprocal superconducting transport in multiterminal
devices.

</details>


### [156] [Twist-modulated magnetic interactions in bilayer van der Waals materials](https://arxiv.org/abs/2509.14122)
*Tomas T. Osterholt,D. O. Oriekhov,Lumen Eek,Cristiane Morais Smith,Rembert A. Duine*

Main category: cond-mat.mes-hall

TL;DR: 通过层间扭转和静电调控来控制双层范德华材料中的磁相互作用。


<details>
  <summary>Details</summary>
Motivation: 控制纳米尺度下的磁相互作用对于开发下一代自旋电子器件和功能磁性材料至关重要。

Method: 使用多体微扰理论，研究层间扭转如何调节双层范德华系统中双层铁磁层的磁相互作用。

Result: 发现可以通过改变层间扭转角来显著改变层间海森堡交换相互作用、Dzyaloshinskii-Moriya相互作用和各向异性交换相互作用的相对强度，从而实现可调的磁纹理。这些相互作用还强烈依赖于化学势，可以通过静电门控或掺杂进行调控。该方法适用于任意扭转角，并且不依赖于莫尔超胞的构建，即使在小扭转角下也效率很高。

Conclusion: 通过层间扭转和静电调控可以有效控制双层范德华材料中的磁相互作用和磁纹理。

Abstract: The ability to control magnetic interactions at the nanoscale is crucial for
the development of next-generation spintronic devices and functional magnetic
materials. In this work, we investigate theoretically, by means of many-body
perturbation theory, how interlayer twisting modulates magnetic interactions in
bilayer van der Waals systems composed of two ferromagnetic layers. We
demonstrate that the relative strengths of the interlayer Heisenberg exchange
interaction, the Dzyaloshinskii-Moriya interaction, and the anisotropic
exchange interaction can be significantly altered by varying the twist angle
between the layers, thus leading to tunable magnetic textures. We further show
that these interactions are strongly dependent on the chemical potential,
enabling additional control via electrostatic gating or doping. Importantly,
our approach is applicable to arbitrary twist angles and does not rely on the
construction of a Moir\'e supercell, making it particularly efficient even at
small twist angles.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [157] [Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning](https://arxiv.org/abs/2509.13336)
*Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习（RL）的蜂窝网络连接无人机（UAV）越障（BVLoS）路径规划方法，旨在最小化行驶距离并最大化蜂窝链路连接质量。


<details>
  <summary>Details</summary>
Motivation: 旨在解决无人机蜂窝通信的局限性带来的挑战，并探索该领域的研究和考量。

Method: 利用强化学习（RL）训练无人机路径规划的智能体，并将无人机与基站（BS）之间的通信链路质量作为奖励函数。

Result: 仿真结果证明了该方法在训练智能体和生成可行的无人机路径规划方面的有效性。

Conclusion: 所提出的RL算法能有效识别最优路径，确保与地面基站的最大连接性，从而保障安全可靠的BVLoS飞行操作。该方法可作为离线路径规划模块集成到未来的无人机地面控制系统（GCS）中，提升其能力和安全性，并对长期复杂无人机应用具有潜力。

Abstract: This paper presents a reinforcement learning (RL) based approach for path
planning of cellular connected unmanned aerial vehicles (UAVs) operating beyond
visual line of sight (BVLoS). The objective is to minimize travel distance
while maximizing the quality of cellular link connectivity by considering real
world aerial coverage constraints and employing an empirical aerial channel
model. The proposed solution employs RL techniques to train an agent, using the
quality of communication links between the UAV and base stations (BSs) as the
reward function. Simulation results demonstrate the effectiveness of the
proposed method in training the agent and generating feasible UAV path plans.
The proposed approach addresses the challenges due to limitations in UAV
cellular communications, highlighting the need for investigations and
considerations in this area. The RL algorithm efficiently identifies optimal
paths, ensuring maximum connectivity with ground BSs to ensure safe and
reliable BVLoS flight operation. Moreover, the solution can be deployed as an
offline path planning module that can be integrated into future ground control
systems (GCS) for UAV operations, enhancing their capabilities and safety. The
method holds potential for complex long range UAV applications, advancing the
technology in the field of cellular connected UAV path planning.

</details>


### [158] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

TL;DR: 本工作提出了一种改进的深度神经网络方法，用于从RGB图像中进行机器人定位，通过扩展损失函数来提高定位精度和鲁棒性，并在室内场景中取得了显著的精度提升。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人从视觉信息（RGB图像）进行定位的性能，特别是增强对感知混淆的鲁棒性，同时不影响训练的简易性。

Method: 通过扩展深度神经网络的损失函数，直观地结合了位置和旋转误差，以提高对感知混淆的鲁棒性。使用摄影测量数据生成带有姿态标签的数据集，并在本地环境中训练模型。

Result: 与未经修改的网络相比，室内场景的定位精度有所提高，中值位置误差和中值旋转误差分别降低了高达9.64%和2.99%。在本地环境中训练的模型达到了0.11米和0.89度的定位精度。

Conclusion: 该工作介绍了一个完整的流程，用于为任何给定的真实室内场景创建鲁棒的导航算法，只需收集该场景的图像即可，采集时间最短可达330秒。

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


### [159] [ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy](https://arxiv.org/abs/2509.13380)
*Alejandro D. Mousist*

Main category: cs.RO

TL;DR: ASTREA是首个部署在具有飞行验证的硬件（TRL 9）上的自主航天器运行的代理系统。


<details>
  <summary>Details</summary>
Motivation: 使用热控作为代表性用例，整合了资源受限的大语言模型（LLM）代理和强化学习控制器，并采用了为空间认证平台量身定制的异步架构。

Method: 在地面实验中，LLM驱动的监督提高了热稳定性并减少了违规现象，证实了在硬件限制下结合语义推理和自适应控制的可行性。

Result: 然而，在国际空间站（ISS）进行的在轨验证显示，由于推理延迟与低地球轨道（LEO）卫星特有的快速热循环不匹配，导致性能下降。

Conclusion: 这些结果突显了在实际飞行环境中，基于LLM的代理系统的机遇和当前局限性，并为未来的空间自主性提供了实用的设计指南。

Abstract: This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.

</details>


### [160] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

TL;DR: Point-JEPA通过3D自监督预训练来提高抓取关节角度预测的数据效率，在低标签条件下显著降低RMSE并达到完全监督的水平。


<details>
  <summary>Details</summary>
Motivation: 研究3D自监督预训练（Point-JEPA）在抓取关节角度预测中的标签效率。

Method: 使用经过ShapeNet预训练的Point-JEPA编码器，结合点云和轻量级多假设预测头，进行训练和评估。

Result: 在DLR-Hand II数据集上，Point-JEPA在低标签情况下将RMSE降低了高达26%，并达到了与完全监督相当的性能。

Conclusion: JEPA风格的预训练是实现数据高效抓取学习的实用方法。

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [161] [Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach](https://arxiv.org/abs/2509.13381)
*Zhang Xueyao,Yang Bo,Yu Zhiwen,Cao Xuelin,George C. Alexandropoulos,Merouane Debbah,Chau Yuen*

Main category: cs.RO

TL;DR: 该论文提出了一种新的双时间尺度分层多智能体近端策略优化（H-MAPPO）框架，用于在对抗性环境中实现高效的协同水下探测和侦察，同时确保隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 在对抗性环境中，实现高效协同和隐蔽操作是水下协同任务的关键挑战，因为协同通信会带来暴露风险。

Method: 提出了一种新的双时间尺度H-MAPPO框架。高层组件由中央AUV决定参与任务的个体，低层组件通过参与AUV的功率和轨迹控制来降低暴露概率。

Result: 仿真结果表明，该框架具有快速收敛性，在性能上优于基准算法，并在确保隐蔽操作的同时最大化了长期的协同效率。

Conclusion: H-MAPPO框架能够有效地解决水下协同探测和侦察中的挑战，在保证任务效率的同时降低了通信暴露的风险。

Abstract: Autonomous Underwater Vehicles (AUVs) have shown great potential for
cooperative detection and reconnaissance. However, collaborative AUV
communications introduce risks of exposure. In adversarial environments,
achieving efficient collaboration while ensuring covert operations becomes a
key challenge for underwater cooperative missions. In this paper, we propose a
novel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization
(H-MAPPO) framework. The high-level component determines the individuals
participating in the task based on a central AUV, while the low-level component
reduces exposure probabilities through power and trajectory control by the
participating AUVs. Simulation results show that the proposed framework
achieves rapid convergence, outperforms benchmark algorithms in terms of
performance, and maximizes long-term cooperative efficiency while ensuring
covert operations.

</details>


### [162] [Using role-play and Hierarchical Task Analysis for designing human-robot interaction](https://arxiv.org/abs/2509.13378)
*Mattias Wingren,Sören Andersson,Sara Rosenberg,Malin Andtfolk,Susanne Hägglund,Prashani Jayasingha Arachchige,Linda Nyholm*

Main category: cs.RO

TL;DR: 本论文提出在人机交互领域应用角色扮演和分层任务分析这两种方法，并通过在社区药房机器人应用的研究项目中的应用展示了其潜力。


<details>
  <summary>Details</summary>
Motivation: 介绍角色扮演和分层任务分析这两种在人机交互领域应用较少但具有潜力的方法。

Method: 运用角色扮演和分层任务分析来开发一个辅助社区药房的机器人应用。

Result: 角色扮演提供了一个可控的环境来理解用户需求，并为机器人行为建模提供了模型；分层任务分析确保了行为的正确建模，并通过促进共同设计来辅助开发。

Conclusion: 未来的研究可以集中在开发更适合社交机器人交互的任务分析方法。

Abstract: We present the use of two methods we believe warrant more use than they
currently have in the field of human-robot interaction: role-play and
Hierarchical Task Analysis. Some of its potential is showcased through our use
of them in an ongoing research project which entails developing a robot
application meant to assist at a community pharmacy. The two methods have
provided us with several advantages. The role-playing provided a controlled and
adjustable environment for understanding the customers' needs where pharmacists
could act as models for the robot's behavior; and the Hierarchical Task
Analysis ensured the behavior displayed was modelled correctly and aided
development through facilitating co-design. Future research could focus on
developing task analysis methods especially suited for social robot
interaction.

</details>


### [163] [Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning](https://arxiv.org/abs/2509.13882)
*Junhwa Hong,Beomjoon Lee,Woojin Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 提出一种基于斥力轨迹修正的冲突驱动搜索（CBS）方法的运动规划，以解决多机械臂协调规划的计算挑战，通过引入人工势场生成斥力引导规划，减少后续冲突，并在特定条件下尝试一步找到无冲突解。


<details>
  <summary>Details</summary>
Motivation: 多机械臂系统在运动规划中存在高维复合构型空间带来的计算挑战，现有冲突驱动搜索（CBS）方法存在约束树爆炸问题。

Method: 在CBS的两层结构中，低层规划器采用基于人工势场（APF）的梯度下降方法，生成斥力引导冲突机械臂的轨迹，避开其他机器人。同时，提出一种策略，在特定条件下尝试一步找到无冲突解。

Result: 与增强CBS及其他现有算法相比，该方法能有效减少约束树的扩展节点数，提高成功率，并更快地找到解。实验包括物理机器人测试。

Conclusion: 所提出的方法通过在CBS框架内结合斥力轨迹修正，能够更有效地解决多机械臂协调运动规划问题，克服了传统CBS方法的局限性。

Abstract: We propose an efficient motion planning method designed to efficiently find
collision-free trajectories for multiple manipulators. While multi-manipulator
systems offer significant advantages, coordinating their motions is
computationally challenging owing to the high dimensionality of their composite
configuration space. Conflict-Based Search (CBS) addresses this by decoupling
motion planning, but suffers from subsequent conflicts incurred by resolving
existing conflicts, leading to an exponentially growing constraint tree of CBS.
Our proposed method is based on repulsive trajectory modification within the
two-level structure of CBS. Unlike conventional CBS variants, the low-level
planner applies a gradient descent approach using an Artificial Potential
Field. This field generates repulsive forces that guide the trajectory of the
conflicting manipulator away from those of other robots. As a result,
subsequent conflicts are less likely to occur. Additionally, we develop a
strategy that, under a specific condition, directly attempts to find a
conflict-free solution in a single step without growing the constraint tree.
Through extensive tests including physical robot experiments, we demonstrate
that our method consistently reduces the number of expanded nodes in the
constraint tree, achieves a higher success rate, and finds a solution faster
compared to Enhanced CBS and other state-of-the-art algorithms.

</details>


### [164] [How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots](https://arxiv.org/abs/2509.13827)
*Renyuan Liu,Haoting Zhou,Chuankai Fang,Qinbing Fu*

Main category: cs.RO

TL;DR: 本文提出了一种受飞蝇视觉神经系统启发的注意驱动的视觉运动控制策略，用于在复杂环境中实现机器人避撞，并在名为Colias的嵌入式视觉机器人上实现了70KB的优化模型。


<details>
  <summary>Details</summary>
Motivation: 为了让自主机器人在复杂环境中实现类似昆虫的敏捷性，克服计算成本和性能之间的权衡，借鉴昆虫的视觉感知系统。尤其关注飞蝇的LPLC2神经元及其逃避行为。

Method: 提出了一种受LPLC2神经元启发的注意驱动的视觉运动控制策略，并针对性地进行了优化，使其内存占用仅为70KB，以适应名为Colias的微型机器人。通过多重注意力机制来模拟LPLC2的分布式响应，从而实现快速和选择性的目标检测与反应。

Result: 在与一种先进的蝗虫启发模型进行对比评估后，本文提出的飞蝇启发模型在避撞方面表现出96.1%的成功率，在鲁棒性方面相当，并且能够产生更具适应性和更优雅的规避机动。

Conclusion: 本文成功地将LPLC2神经元模型嵌入到物理机器人中，实现了有效的避撞策略，证明了飞蝇启发模型在提升机器人智能和研究群体行为方面的潜力。

Abstract: Anyone who has tried to swat a fly has likely been frustrated by its
remarkable agility.This ability stems from its visual neural perception system,
particularly the collision-selective neurons within its small brain.For
autonomous robots operating in complex and unfamiliar environments, achieving
similar agility is highly desirable but often constrained by the trade-off
between computational cost and performance.In this context, insect-inspired
intelligence offers a parsimonious route to low-power, computationally
efficient frameworks.In this paper, we propose an attention-driven visuomotor
control strategy inspired by a specific class of fly visual projection
neurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated
escape behaviors.To our knowledge, this represents the first embodiment of an
LPLC2 neural model in the embedded vision of a physical mobile robot, enabling
collision perception and reactive evasion.The model was simplified and
optimized at 70KB in memory to suit the computational constraints of a
vision-based micro robot, the Colias, while preserving key neural perception
mechanisms.We further incorporated multi-attention mechanisms to emulate the
distributed nature of LPLC2 responses, allowing the robot to detect and react
to approaching targets both rapidly and selectively.We systematically evaluated
the proposed method against a state-of-the-art locust-inspired collision
detection model.Results showed that the fly-inspired visuomotor model achieved
comparable robustness, at success rate of 96.1% in collision detection while
producing more adaptive and elegant evasive maneuvers.Beyond demonstrating an
effective collision-avoidance strategy, this work highlights the potential of
fly-inspired neural models for advancing research into collective behaviors in
insect intelligence.

</details>


### [165] [TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems](https://arxiv.org/abs/2509.14025)
*Rui Huang,Zhiyu Gao,Siyu Tang,Jialin Zhang,Lei He,Ziqian Zhang,Lin Zhao*

Main category: cs.RO

TL;DR: MARS可以通过重构来容忍故障，但先前的工作仅限于矩形形状和单点故障。TransforMARS是一个通用的容错重构框架，可以处理任意形状的MARS和多点故障，并确保飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 先前关于MARS自重构的工作仅限于矩形形状并容忍单点故障。本研究旨在提出一个更通用的框架，以处理任意形状的MARS和多点故障，同时确保飞行稳定性。

Method: 提出TransforMARS框架，包括识别和构建最小可控组件（包含故障单元），以及规划可行的拆卸-组装序列以形成目标配置。

Result: TransforMARS在挑战性的任意形状MARS配置中得到了验证，在处理多样化配置和容忍故障数量方面均取得了显著改进。

Conclusion: TransforMARS是一个通用的容错重构框架，能够处理任意形状的MARS和多点故障，并确保飞行稳定性，从而实现更灵活和实用的重构。

Abstract: Modular Aerial Robot Systems (MARS) consist of multiple drone modules that
are physically bound together to form a single structure for flight. Exploiting
structural redundancy, MARS can be reconfigured into different formations to
mitigate unit or rotor failures and maintain stable flight. Prior work on MARS
self-reconfiguration has solely focused on maximizing controllability margins
to tolerate a single rotor or unit fault for rectangular-shaped MARS. We
propose TransforMARS, a general fault-tolerant reconfiguration framework that
transforms arbitrarily shaped MARS under multiple rotor and unit faults while
ensuring continuous in-air stability. Specifically, we develop algorithms to
first identify and construct minimum controllable assemblies containing faulty
units. We then plan feasible disassembly-assembly sequences to transport MARS
units or subassemblies to form target configuration. Our approach enables more
flexible and practical feasible reconfiguration. We validate TransforMARS in
challenging arbitrarily shaped MARS configurations, demonstrating substantial
improvements over prior works in both the capacity of handling diverse
configurations and the number of faults tolerated. The videos and source code
of this work are available at the anonymous repository:
https://anonymous.4open.science/r/TransforMARS-1030/

</details>


### [166] [VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization](https://arxiv.org/abs/2509.13386)
*Hansol Lim,Minhyeok Im,Jonathan Boyack,Jee Won Lee,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: VEGA是一个充电感知电动汽车导航代理，利用PPO和A*指导来优化充电路线。


<details>
  <summary>Details</summary>
Motivation: 随着对软件定义汽车（SDV）和车载人工智能（AI）系统不断增长的需求，有必要优化电动汽车（EV）的充电路线规划。

Method: VEGA包含两个模块：一个物理信息神经网络算子（PINO）用于学习车辆动力学，以及一个强化学习（RL）代理，利用这些动力学在考虑SOC限制的情况下优化路线和充电时间。

Result: VEGA在长途路线（如旧金山到纽约）上的表现与特斯拉的行程规划器相当，并且在法国和日本等不同地区也表现出良好的泛化能力。

Conclusion: VEGA成功地将物理信息学习和强化学习应用于电动汽车的生态路线规划，无需额外传感器，仅使用车辆速度信号，并有可能降低电动汽车成本。

Abstract: Demands for software-defined vehicles (SDV) are rising and electric vehicles
(EVs) are increasingly being equipped with powerful computers. This enables
onboard AI systems to optimize charge-aware path optimization customized to
reflect vehicle's current condition and environment. We present VEGA, a
charge-aware EV navigation agent that plans over a charger-annotated road graph
using Proximal Policy Optimization (PPO) with budgeted A* teacher-student
guidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.
First, a physics-informed neural operator (PINO), trained on real vehicle speed
and battery-power logs, uses recent vehicle speed logs to estimate aerodynamic
drag, rolling resistance, mass, motor and regenerative-braking efficiencies,
and auxiliary load by learning a vehicle-custom dynamics. Second, a
Reinforcement Learning (RL) agent uses these dynamics to optimize a path with
optimal charging stops and dwell times under SoC constraints. VEGA requires no
additional sensors and uses only vehicle speed signals. It may serve as a
virtual sensor for power and efficiency to potentially reduce EV cost. In
evaluation on long routes like San Francisco to New York, VEGA's stops, dwell
times, SoC management, and total travel time closely track Tesla Trip Planner
while being slightly more conservative, presumably due to real vehicle
conditions such as vehicle parameter drift due to deterioration. Although
trained only in U.S. regions, VEGA was able to compute optimal charge-aware
paths in France and Japan, demonstrating generalizability. It achieves
practical integration of physics-informed learning and RL for EV eco-routing.

</details>


### [167] [A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies](https://arxiv.org/abs/2509.13434)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 提出一个统一了离散弹性杆模型、压力场块接触模型和凸接触表述的计算框架，用于模拟细丝与刚体之间的摩擦相互作用，解决了现有方法中细丝与刚体永久连接的假设，实现了全局最优求解和互补性保证，并在软体机器人和可变形物体操纵等领域进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设细丝与刚体永久连接，限制了模拟的真实性，因此需要一个能够准确模拟细丝与刚体之间摩擦相互作用的框架。

Method: 提出一个计算框架，该框架统一了离散弹性杆（DER）建模、压力场块接触模型以及凸接触表述，以精确模拟细丝与刚体之间的摩擦相互作用。

Result: 该框架能够实现全局最优求解，保证接触速度和冲量的互补性。通过评估摩擦力准确性和与基线方法的物理保真度进行验证。成功应用于软体机器人（如基于细丝的随机抓手）和可变形物体操纵（如鞋带捆绑）。

Conclusion: 该框架为包含复杂细丝-细丝和细丝-刚体相互作用的系统提供了一个多功能的模拟器，在软体机器人和可变形物体操纵等领域具有广泛的应用前景。

Abstract: We present a computational framework for simulating filaments interacting
with rigid bodies through contact. Filaments are challenging to simulate due to
their codimensionality, i.e., they are one-dimensional structures embedded in
three-dimensional space. Existing methods often assume that filaments remain
permanently attached to rigid bodies. Our framework unifies discrete elastic
rod (DER) modeling, a pressure field patch contact model, and a convex contact
formulation to accurately simulate frictional interactions between slender
filaments and rigid bodies - capabilities not previously achievable. Owing to
the convex formulation of contact, each time step can be solved to global
optimality, guaranteeing complementarity between contact velocity and impulse.
We validate the framework by assessing the accuracy of frictional forces and
comparing its physical fidelity against baseline methods. Finally, we
demonstrate its applicability in both soft robotics, such as a stochastic
filament-based gripper, and deformable object manipulation, such as shoelace
tying, providing a versatile simulator for systems involving complex
filament-filament and filament-rigid body interactions.

</details>


### [168] [CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads](https://arxiv.org/abs/2509.14126)
*Viktor Lorentz,Khaled Wahba,Sayantan Auddy,Marc Toussaint,Wolfgang Hönig*

Main category: cs.RO

TL;DR: CrazyMARL是一个去中心化的强化学习框架，用于多UAV协同运输线缆悬挂的负载，能够应对干扰、非线性动力学和线缆模式转换，并在模拟和真实世界中表现出优越的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多UAV协同运输线缆悬挂负载具有提升负载能力、适应不同形状负载和提供内置顺应性等优势，在灾难救援和精确物流等领域有应用潜力。然而，在干扰、非线性负载动力学和线缆松紧模式转换下进行多UAV协调是一个具有挑战性的控制问题。之前的研究依赖于简化的刚性连杆假设，未能解决多UAV场景下的线缆模式转换问题。

Method: 提出CrazyMARL，一个去中心化的强化学习（RL）框架，用于多UAV协同运输线缆悬挂负载。

Result: 仿真结果表明，所学的策略在干扰抑制和跟踪精度方面优于经典的去中心化控制器，在恶劣条件下的恢复率达到80%，而基线方法为44%。实现了成功的零样本仿真到真实迁移，并证明了策略在包括风、随机外部干扰以及线缆松紧动力学转换在内的恶劣条件下的高鲁棒性。

Conclusion: 这项工作为能够自主、有弹性地在非结构化环境中执行复杂负载任务的UAV团队铺平了道路。

Abstract: Collaborative transportation of cable-suspended payloads by teams of Unmanned
Aerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to
different payload shapes, and provide built-in compliance, making it attractive
for applications ranging from disaster relief to precision logistics. However,
multi-UAV coordination under disturbances, nonlinear payload dynamics, and
slack--taut cable modes remains a challenging control problem. To our
knowledge, no prior work has addressed these cable mode transitions in the
multi-UAV context, instead relying on simplifying rigid-link assumptions. We
propose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for
multi-UAV cable-suspended payload transport. Simulation results demonstrate
that the learned policies can outperform classical decentralized controllers in
terms of disturbance rejection and tracking precision, achieving an 80%
recovery rate from harsh conditions compared to 44% for the baseline method. We
also achieve successful zero-shot sim-to-real transfer and demonstrate that our
policies are highly robust under harsh conditions, including wind, random
external disturbances, and transitions between slack and taut cable dynamics.
This work paves the way for autonomous, resilient UAV teams capable of
executing complex payload missions in unstructured environments.

</details>


### [169] [Trajectory Tracking with Reachability-Guided Quadratic Programming and Freeze-Resume](https://arxiv.org/abs/2509.13501)
*Hossein Gholampour,Logan E. Beaver*

Main category: cs.RO

TL;DR: 提出了一种用于机器人系统安全暂停和恢复的输出空间方法，该方法通过预先进行可达性检查和在线二次规划来实现。


<details>
  <summary>Details</summary>
Motivation: 机器人系统在跟随规划路径时，需要能够安全地暂停以响应人员或物体的干预，并在干预结束后恢复执行。

Method: 该方法分为离线和在线两部分。离线部分进行预运行可达性检查，验证运动规划是否满足速度和加速度限制。在线部分使用二次规划来跟踪运动规划，并应用同一限制。通过一步可达性测试来界定系统能够拒绝的最大干扰。在状态与参考路径重合时恢复精确跟踪，并使用 KKT 改进的权重来纠正误差。

Result: 该系统能够高效地处理安全停止和意外偏离，并在不重新规划的情况下返回到运动规划。与纯粹跟踪相比，该系统在仿真中表现出更优越的性能。

Conclusion: 所提出的输出空间方法能够有效地实现机器人系统的安全暂停和恢复，并保持对运动规划的精确跟踪。

Abstract: Many robotic systems must follow planned paths yet pause safely and resume
when people or objects intervene. We present an output-space method for systems
whose tracked output can be feedback-linearized to a double integrator (e.g.,
manipulators). The approach has two parts. Offline, we perform a pre-run
reachability check to verify that the motion plan respects speed and
acceleration magnitude limits. Online, we apply a quadratic program to track
the motion plan under the same limits. We use a one-step reachability test to
bound the maximum disturbance the system is capable of rejecting. When the
state coincides with the reference path we recover perfect tracking in the
deterministic case, and we correct errors using a KKT-inspired weight. We
demonstrate that safety stops and unplanned deviations are handled efficiently,
and the system returns to the motion plan without replanning. We demonstrate
our system's improved performance over pure pursuit in simulation.

</details>


### [170] [Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks](https://arxiv.org/abs/2509.14127)
*Alkesh K. Srivastava,Jared Michael Levin,Philip Dames*

Main category: cs.RO

TL;DR: 使用具有有限载货能力的同质机器人车队，从单个取货点向不同目标位置运送多个包裹。我们提出了 VCST-RCP（Voronoi-Constrained Steiner Tree Relay Coordination Planning）框架，该框架使用 Steiner 树优化来构建稀疏中继主干，然后合成机器人级别的取件、中继和交付计划。该框架将中继从附带的副产品重新定义为协调的核心要素，与依赖直接源到目的地运输的传统交付方法形成对比。广泛的实验表明，与传统基线相比，性能一致提高了 34%，这凸显了将中继纳入交付过程的优势。这些改进直接转化为容量受限的多机器人交付中的能源效率，为实际物流提供了一个可扩展的框架。


<details>
  <summary>Details</summary>
Motivation: 在具有有限载货能力的同质机器人车队的情况下，解决了从单个取货点向不同目标位置运送多个包裹的问题。

Method: 提出了 VCST-RCP（Voronoi-Constrained Steiner Tree Relay Coordination Planning）框架，该框架使用 Steiner 树优化来构建稀疏中继主干，然后合成机器人级别的取件、中继和交付计划。

Result: 与传统基线相比，性能一致提高了 34%。

Conclusion: 将中继纳入交付过程可以提高容量受限的多机器人交付中的能源效率，并提供了一个可扩展的框架以用于实际物流。

Abstract: We consider the problem of delivering multiple packages from a single pickup
depot to distinct goal locations using a homogeneous fleet of robots with
limited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner
Tree Relay Coordination Planning framework that constructs sparse relay trunks
using Steiner tree optimization and then synthesizes robot-level pickup, relay,
and delivery schedules. This framework reframes relays from incidental
byproducts into central elements of coordination, offering a contrast with
traditional delivery methods that rely on direct source-to-destination
transport. Extensive experiments show consistent improvements of up to 34%
compared to conventional baselines, underscoring the benefits of incorporating
relays into the delivery process. These improvements translate directly to
enhanced energy efficiency in multi-robot delivery under capacity constraints,
providing a scalable framework for real-world logistics.

</details>


### [171] [Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning](https://arxiv.org/abs/2509.13534)
*Chunxin Zheng,Kai Chen,Zhihai Bi,Yulin Li,Liang Pan,Jinni Zhou,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 该研究提出了一种结合人类运动先验和神经符号距离场（NSDF）的强化学习框架，用于实现人形机器人的全身拥抱操作，解决了传统抓取方法的稳定性和负载限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统机器人抓取方法在处理笨重物体时存在稳定性和负载限制，而全身操作（WBM）是执行拥抱等任务的更优方法。

Method: 本研究采用教师-学生架构，整合了预训练的人类运动先验和神经符号距离场（NSDF）表示，以实现稳健的全身拥抱操作。该方法通过提炼大规模人类运动数据，生成运动学上自然且物理上可行的全身运动模式，从而协调手臂和躯干的控制，实现稳定的多接触交互，提高操作鲁棒性和负载能力。NSDF提供了准确的几何感知，增强了对长周期任务的接触感知能力。

Result: 通过广泛的模拟和真实世界实验评估，结果表明该方法提高了对不同形状和尺寸物体的适应性，并成功实现了从模拟到现实的迁移。

Conclusion: 所提出的框架为人形机器人的多接触和长周期全身操作任务提供了一种有效且实用的解决方案。

Abstract: Whole-body manipulation (WBM) for humanoid robots presents a promising
approach for executing embracing tasks involving bulky objects, where
traditional grasping relying on end-effectors only remains limited in such
scenarios due to inherent stability and payload constraints. This paper
introduces a reinforcement learning framework that integrates a pre-trained
human motion prior with a neural signed distance field (NSDF) representation to
achieve robust whole-body embracing. Our method leverages a teacher-student
architecture to distill large-scale human motion data, generating kinematically
natural and physically feasible whole-body motion patterns. This facilitates
coordinated control across the arms and torso, enabling stable multi-contact
interactions that enhance the robustness in manipulation and also the load
capacity. The embedded NSDF further provides accurate and continuous geometric
perception, improving contact awareness throughout long-horizon tasks. We
thoroughly evaluate the approach through comprehensive simulations and
real-world experiments. The results demonstrate improved adaptability to
diverse shapes and sizes of objects and also successful sim-to-real transfer.
These indicate that the proposed framework offers an effective and practical
solution for multi-contact and long-horizon WBM tasks of humanoid robots.

</details>


### [172] [Semantic 3D Reconstructions with SLAM for Central Airway Obstruction](https://arxiv.org/abs/2509.13541)
*Ayberk Acar,Fangjie Li,Hao Li,Lidia Al-Zogbi,Kanyifeechukwu Jane Oguine,Susheela Sharma Stern,Jesse F. d'Almeida,Robert J. Webster III,Ipek Oguz,Jie Ying Wu*

Main category: cs.RO

TL;DR: 提出了一种结合DROID-SLAM和语义分割的新型方法，用于对中心气道阻塞（CAO）进行实时、语义感知的三维重建。


<details>
  <summary>Details</summary>
Motivation: 中心气道阻塞（CAO）的发生率不断增加，传统治疗方法风险高，因此需要更安全有效的治疗方法，机器人干预结合场景理解和映射为自动化提供了可能性。

Method: 结合DROID-SLAM和训练的语义分割模型，实时重建气道的三维几何结构，并识别和标注阻塞区域。

Result: 使用离体模型进行评估，重建质量高，与CT扫描高度相似（Chamfer距离为0.62 mm），能够实时生成高亮临床相关区域的带注释三维地图，并且重建速度快，比先前的工作更准确地反映手术场景。

Conclusion: 该研究首次将语义分割与实时单眼SLAM相结合，用于内窥镜CAO场景，为实现自主机器人干预提供了有前景的步骤，并且该框架具有模块化和可推广性。

Abstract: Central airway obstruction (CAO) is a life-threatening condition with
increasing incidence, caused by tumors in and outside of the airway.
Traditional treatment methods such as bronchoscopy and electrocautery can be
used to remove the tumor completely; however, these methods carry a high risk
of complications. Recent advances allow robotic interventions with lesser risk.
The combination of robot interventions with scene understanding and mapping
also opens up the possibilities for automation. We present a novel pipeline
that enables real-time, semantically informed 3D reconstructions of the central
airway using monocular endoscopic video.
  Our approach combines DROID-SLAM with a segmentation model trained to
identify obstructive tissues. The SLAM module reconstructs the 3D geometry of
the airway in real time, while the segmentation masks guide the annotation of
obstruction regions within the reconstructed point cloud. To validate our
pipeline, we evaluate the reconstruction quality using ex vivo models.
  Qualitative and quantitative results show high similarity between ground
truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By
integrating segmentation directly into the SLAM workflow, our system produces
annotated 3D maps that highlight clinically relevant regions in real time.
High-speed capabilities of the pipeline allows quicker reconstructions compared
to previous work, reflecting the surgical scene more accurately.
  To the best of our knowledge, this is the first work to integrate semantic
segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our
framework is modular and can generalize to other anatomies or procedures with
minimal changes, offering a promising step toward autonomous robotic
interventions.

</details>


### [173] [Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference](https://arxiv.org/abs/2509.13572)
*Ozan Karaali,Hossam Farag,Strahinja Dosen,Cedomir Stefanovic*

Main category: cs.RO

TL;DR: 该研究旨在探索视觉语言模型（VLM）在增强半自主假肢手感知能力方面的潜力，并提出了一个统一的基准来评估端到端的感知和抓取推理。研究人员评估了八个现代VLM在执行统一任务上的表现，该任务要求模型从单个静态图像中识别物体及其属性，并推断合适的抓取参数。


<details>
  <summary>Details</summary>
Motivation: 利用视觉语言模型（VLM）提升半自主假肢手的感知能力，以简化传统的复杂处理流程。

Method: 构建了一个统一的基准，包含物体检测、姿态估计和抓取规划，并评估了八个VLM在识别物体属性（名称、形状、方向、尺寸）和推断抓取参数（抓取类型、腕部旋转、手部张开度、手指数量）方面的能力。使用包含34张常见物体快照的数据集，并通过结构化JSON输出进行评估。

Result: 大多数模型在物体识别和形状识别方面表现出高准确性，但在尺寸估计和抓取参数推断（特别是手部旋转和张开度）方面，准确性差异较大。

Conclusion: 研究表明，VLM在物体识别和形状识别方面具有潜力，但在精确的尺寸估计和抓取参数推断方面仍存在局限性，这揭示了VLM作为先进感知模块在半自主控制假肢方面的当前能力和潜在应用前景。

Abstract: This study examines the potential of utilizing Vision Language Models (VLMs)
to improve the perceptual capabilities of semi-autonomous prosthetic hands. We
introduce a unified benchmark for end-to-end perception and grasp inference,
evaluating a single VLM to perform tasks that traditionally require complex
pipelines with separate modules for object detection, pose estimation, and
grasp planning. To establish the feasibility and current limitations of this
approach, we benchmark eight contemporary VLMs on their ability to perform a
unified task essential for bionic grasping. From a single static image, they
should (1) identify common objects and their key properties (name, shape,
orientation, and dimensions), and (2) infer appropriate grasp parameters (grasp
type, wrist rotation, hand aperture, and number of fingers). A corresponding
prompt requesting a structured JSON output was employed with a dataset of 34
snapshots of common objects. Key performance metrics, including accuracy for
categorical attributes (e.g., object name, shape) and errors in numerical
estimates (e.g., dimensions, hand aperture), along with latency and cost, were
analyzed. The results demonstrated that most models exhibited high performance
in object identification and shape recognition, while accuracy in estimating
dimensions and inferring optimal grasp parameters, particularly hand rotation
and aperture, varied more significantly. This work highlights the current
capabilities and limitations of VLMs as advanced perceptual modules for
semi-autonomous control of bionic limbs, demonstrating their potential for
effective prosthetic applications.

</details>


### [174] [Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation](https://arxiv.org/abs/2509.13574)
*Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian*

Main category: cs.RO

TL;DR: Flow matching 在机器人领域被证明是一种学习高质量生成策略的有效框架，但其泛化能力在训练早期就已饱和。增加欧拉积分步数反而会降低策略性能。为解决这些问题，本文提出了一种新的策略，在训练时采用非均匀时间调度（如U形），以强调训练的早期和晚期阶段，并在推理时采用密集跳转积分（dense-jump integration），用单步积分取代跳跃点之后的积分，以避免不稳定的区域。该策略在各种机器人任务上实现了高达23.7%的性能提升。


<details>
  <summary>Details</summary>
Motivation: Flow matching 在机器人领域学习生成策略方面表现出竞争力，但存在泛化能力早期饱和和增加积分步数反而降低性能的问题。

Method: 提出了一种新的策略，在训练时采用非均匀时间调度（如U形）来强调训练的早期和晚期阶段，并在推理时采用密集跳转积分（dense-jump integration）来避免不稳定的区域。

Result: 所提出的策略在各种机器人任务上实现了高达23.7%的性能提升，优于最先进的基线。

Conclusion: 通过采用非均匀时间调度和密集跳转积分，所提出的策略有效地解决了 Flow matching 策略在泛化和积分步数方面的挑战，并在机器人任务中取得了显著的性能提升。

Abstract: Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.

</details>


### [175] [TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning](https://arxiv.org/abs/2509.13579)
*Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu*

Main category: cs.RO

TL;DR: TreeIRL结合MCTS和IRL，在模拟和真实世界驾驶中均表现出色，是首个在公开道路上使用MCTS的自动驾驶规划器。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶领域，需要一种能够平衡安全、效率、舒适性和人类驾驶行为的规划方法，以应对复杂多变的真实驾驶环境。

Method: 提出了一种名为TreeIRL的新型规划器，该规划器结合了蒙特卡洛树搜索（MCTS）和逆强化学习（IRL）。MCTS用于生成一系列安全且有潜力的候选轨迹，而深度IRL评分函数则用于从中选择最接近人类驾驶行为的轨迹。

Result: TreeIRL在模拟和真实世界的驾驶测试中均取得了领先的性能。在模拟和拉斯维加斯真实道路测试中，TreeIRL在处理密集城市交通、自适应巡航控制、车辆切入和交通信号灯等场景时，均在安全、效率、舒适性和人类行为模仿性之间取得了良好的平衡。

Conclusion: TreeIRL是首个在公开道路上成功应用MCTS的自动驾驶规划方法，证明了在真实世界环境中，并采用多维度评估指标（包括安全、效率、舒适性和人类行为模仿性）对规划器进行评估的重要性。该框架具有高度的可扩展性，未来可通过强化学习和模仿学习进一步改进，为解决自动驾驶规划瓶颈提供新的途径。

Abstract: We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.

</details>


### [176] [Object Pose Estimation through Dexterous Touch](https://arxiv.org/abs/2509.13591)
*Amir-Hossein Shahidzadeh,Jiyue Zhu,Kezhou Chen,Sha Yi,Cornelia Fermüller,Yiannis Aloimonos,Xiaolong Wang*

Main category: cs.RO

TL;DR: 通过传感器运动探索来估计具有挑战性场景中的物体姿态。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作和交互任务中，鲁棒的物体姿态估计至关重要，尤其是在视觉数据有限或对光照、遮挡和外观敏感的情况下。触觉传感器通常提供有限且局部的接触信息，难以从部分数据中重建姿态。

Method: 利用传感器运动探索，主动控制机器人手与物体交互。使用强化学习（RL）进行探索和收集触觉数据。收集到的3D点云用于迭代地优化物体的形状和姿态。一个手保持物体稳定，另一个手进行主动探索。

Result: 该方法能够主动探索物体表面，在无先验几何知识的情况下识别关键姿态特征。

Conclusion: 通过主动探索和强化学习，即使在数据有限的情况下，也能实现鲁棒的物体姿态估计。

Abstract: Robust object pose estimation is essential for manipulation and interaction
tasks in robotics, particularly in scenarios where visual data is limited or
sensitive to lighting, occlusions, and appearances. Tactile sensors often offer
limited and local contact information, making it challenging to reconstruct the
pose from partial data. Our approach uses sensorimotor exploration to actively
control a robot hand to interact with the object. We train with Reinforcement
Learning (RL) to explore and collect tactile data. The collected 3D point
clouds are used to iteratively refine the object's shape and pose. In our
setup, one hand holds the object steady while the other performs active
exploration. We show that our method can actively explore an object's surface
to identify critical pose features without prior knowledge of the object's
geometry. Supplementary material and more demonstrations will be provided at
https://amirshahid.github.io/BimanualTactilePose .

</details>


### [177] [Leg-Arm Coordinated Operation for Curtain Wall Installation](https://arxiv.org/abs/2509.13595)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 基于六足机器人设计了分层优化整体控制框架，用于协调手臂-腿部规划，以解决传统幕墙安装的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着城市化进程的加快，高层建筑和大型公共设施的增加，幕墙得到广泛应用。传统安装方法存在地形变化、劳动强度大、效率低、安全风险高等问题。

Method: 提出一种基于六足幕墙安装机器人的分层优化整体控制框架，该框架整合了六足腿的运动与折叠手臂和串并联机械臂的操作，以实现墙体安装、天花板安装和地板铺设三个关键任务的手臂-腿部协调规划。

Result: 通过在六足幕墙安装机器人上进行实验，验证了所提出的控制方法在执行幕墙安装任务方面的能力。

Conclusion: 分层优化手臂-腿部协调框架对于六足机器人是有效的，为在复杂建筑工地环境中进一步应用奠定了基础。

Abstract: With the acceleration of urbanization, the number of high-rise buildings and
large public facilities is increasing, making curtain walls an essential
component of modern architecture with widespread applications. Traditional
curtain wall installation methods face challenges such as variable on-site
terrain, high labor intensity, low construction efficiency, and significant
safety risks. Large panels often require multiple workers to complete
installation. To address these issues, based on a hexapod curtain wall
installation robot, we design a hierarchical optimization-based whole-body
control framework for coordinated arm-leg planning tailored to three key tasks:
wall installation, ceiling installation, and floor laying. This framework
integrates the motion of the hexapod legs with the operation of the folding arm
and the serial-parallel manipulator. We conduct experiments on the hexapod
curtain wall installation robot to validate the proposed control method,
demonstrating its capability in performing curtain wall installation tasks. Our
results confirm the effectiveness of the hierarchical optimization-based
arm-leg coordination framework for the hexapod robot, laying the foundation for
its further application in complex construction site environments.

</details>


### [178] [Barometer-Aided Attitude Estimation](https://arxiv.org/abs/2509.13649)
*Méloné Nyoba Tchonkeu,Soulaimane Berkane,Tarek Hamel*

Main category: cs.RO

TL;DR: 该研究提出了一种利用气压计辅助的姿态估计方法，解决了在GNSS信号弱或动态环境下，仅依赖IMU进行倾斜估计的局限性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号弱或动态环境下，仅依赖IMU进行姿态估计存在重力与惯性加速度的模糊性问题，而辅助速度传感器可能不可用、间歇性或成本高昂。

Method: 提出了一种基于气压计辅助的姿态估计框架，该框架利用非线性SO(3)观测器中的气压高度测量来推断垂直速度和姿态。该设计将确定性Riccati观测器与互补滤波器级联，确保在统一的可观测性条件下实现几乎全局渐近稳定性（AGAS），同时保持几何一致性。

Result: 该方法通过利用气压计数据，有效解决了IMU在特定环境下姿态估计的不足，并实现了轻量级且有效的姿态估计。

Conclusion: 气压计辅助的姿态估计是一种轻量级且有效的补充传感方式，能够提高在GNSS信号弱或动态环境下的姿态估计的准确性和鲁棒性。

Abstract: Accurate and robust attitude estimation is a central challenge for autonomous
vehicles operating in GNSS-denied or highly dynamic environments. In such
cases, Inertial Measurement Units (IMUs) alone are insufficient for reliable
tilt estimation due to the ambiguity between gravitational and inertial
accelerations. While auxiliary velocity sensors, such as GNSS, Pitot tubes,
Doppler radar, or visual odometry, are often used, they can be unavailable,
intermittent, or costly. This work introduces a barometer-aided attitude
estimation architecture that leverages barometric altitude measurements to
infer vertical velocity and attitude within a nonlinear observer on SO(3). The
design cascades a deterministic Riccati observer with a complementary filter,
ensuring Almost Global Asymptotic Stability (AGAS) under a uniform
observability condition while maintaining geometric consistency. The analysis
highlights barometer-aided estimation as a lightweight and effective
complementary modality.

</details>


### [179] [DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](https://arxiv.org/abs/2509.13666)
*Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin*

Main category: cs.RO

TL;DR: DREAM是一个由视觉语言模型(VLM)驱动的自主框架，用于长期的水下探索和栖息地监测，能够高效地寻找和探索目标物体，并优于现有基线和香草VLM。


<details>
  <summary>Details</summary>
Motivation: 由于海洋变暖和酸化对贝类（如牡蛎）构成威胁，需要开发长期的水下监测系统，但人力成本高且水下作业危险，因此需要机器人解决方案。

Method: 提出了一种名为DREAM的视觉语言模型（VLM）驱动的自主框架，用于长期的水下探索和栖息地监测。

Result: 在牡蛎监测任务中，DREAM比现有基线快31.5%，牡蛎数量相同。与香草VLM相比，DREAM少用了23%的步骤，覆盖了8.88%的牡蛎。在寻找沉船的任务中，DREAM比香草模型少用了27.5%的步骤，实现了100%的覆盖率，而香草模型平均覆盖率为60.23%。

Conclusion: DREAM框架在无需先验位置信息的情况下，能够高效地寻找和探索目标物体，并在水下监测任务中表现出优越的性能。

Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.

</details>


### [180] [SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics](https://arxiv.org/abs/2509.13691)
*Songhao Huang,Yuwei Wu,Guangyao Shi,Gaurav S. Sukhatme,Vijay Kumar*

Main category: cs.RO

TL;DR: LLM可自动生成UAV任务的PDDL领域，解决手动创建的痛点，并提供数据集和评估流程。


<details>
  <summary>Details</summary>
Motivation: 手动设计PDDL领域耗时费力且易出错，阻碍了其在机器人规划领域的广泛应用，尤其是在UAV任务中。

Method: 提出SPAR框架，利用LLM从自然语言描述自动生成PDDL领域。构建了一个包含UAV领域和问题的PDDL数据集，并设计了提示框架来生成PDDL领域。通过语法验证、可执行性、可行性和可解释性来评估生成的领域。

Result: SPAR框架能够生成高质量的PDDL领域，LLM可显著加速复杂规划领域的设计过程。

Conclusion: LLM能有效解决PDDL领域创建的挑战，SPAR框架提供了可复用的数据集和评估流程，使非专业人士也能应用，并推动了航空机器人和自动化规划的未来研究。

Abstract: We investigate the problem of automatic domain generation for the Planning
Domain Definition Language (PDDL) using Large Language Models (LLMs), with a
particular focus on unmanned aerial vehicle (UAV) tasks. Although PDDL is a
widely adopted standard in robotic planning, manually designing domains for
diverse applications such as surveillance, delivery, and inspection is
labor-intensive and error-prone, which hinders adoption and real-world
deployment. To address these challenges, we propose SPAR, a framework that
leverages the generative capabilities of LLMs to automatically produce valid,
diverse, and semantically accurate PDDL domains from natural language input. To
this end, we first introduce a systematically formulated and validated UAV
planning dataset, consisting of ground-truth PDDL domains and associated
problems, each paired with detailed domain and action descriptions. Building on
this dataset, we design a prompting framework that generates high-quality PDDL
domains from language input. The generated domains are evaluated through syntax
validation, executability, feasibility, and interpretability. Overall, this
work demonstrates that LLMs can substantially accelerate the creation of
complex planning domains, providing a reproducible dataset and evaluation
pipeline that enables application experts without prior experience to leverage
it for practical tasks and advance future research in aerial robotics and
automated planning.

</details>


### [181] [HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion](https://arxiv.org/abs/2509.13692)
*Yadan Zeng,Jiadong Zhou,Xiaohan Li,I-Ming Chen*

Main category: cs.RO

TL;DR: HGACNet是一个用于点云补全的新框架，通过分层编码3D几何特征并融合单视角RGB图像的视觉先验来重建完整的点云。


<details>
  <summary>Details</summary>
Motivation: 点云补全是机器人感知、物体重建和抓取规划、避障、操作等下游任务的基础。然而，由于自遮挡和传感器限制导致的不完整几何形状会严重影响下游推理和交互。

Method: HGACNet的核心是分层图注意力（HGA）编码器，它通过基于图注意力的下采样自适应地选择关键的局部点，并逐步细化分层几何特征以更好地捕捉结构连续性和空间关系。为了加强跨模态交互，还设计了多尺度跨模态融合（MSCF）模块，该模块对分层几何特征和结构化视觉表示之间进行基于注意力的特征对齐，从而为补全提供细粒度的语义指导。此外，还提出了对比损失（C-Loss）以明确地对齐跨模态的特征分布，提高在模态差异下的补全保真度。

Result: 在ShapeNet-ViPC基准和YCB-Complete数据集上的广泛实验证实了HGACNet的有效性，其性能达到了最先进水平，并在实际机器人操作任务中表现出强大的适用性。

Conclusion: HGACNet通过分层几何特征编码和图像引导先验融合，在点云补全方面取得了最先进的性能，并证明了其在机器人操作任务中的实用价值。

Abstract: Point cloud completion is essential for robotic perception, object
reconstruction and supporting downstream tasks like grasp planning, obstacle
avoidance, and manipulation. However, incomplete geometry caused by
self-occlusion and sensor limitations can significantly degrade downstream
reasoning and interaction. To address these challenges, we propose HGACNet, a
novel framework that reconstructs complete point clouds of individual objects
by hierarchically encoding 3D geometric features and fusing them with
image-guided priors from a single-view RGB image. At the core of our approach,
the Hierarchical Graph Attention (HGA) encoder adaptively selects critical
local points through graph attention-based downsampling and progressively
refines hierarchical geometric features to better capture structural continuity
and spatial relationships. To strengthen cross-modal interaction, we further
design a Multi-Scale Cross-Modal Fusion (MSCF) module that performs
attention-based feature alignment between hierarchical geometric features and
structured visual representations, enabling fine-grained semantic guidance for
completion. In addition, we proposed the contrastive loss (C-Loss) to
explicitly align the feature distributions across modalities, improving
completion fidelity under modality discrepancy. Finally, extensive experiments
conducted on both the ShapeNet-ViPC benchmark and the YCB-Complete dataset
confirm the effectiveness of HGACNet, demonstrating state-of-the-art
performance as well as strong applicability in real-world robotic manipulation
tasks.

</details>


### [182] [EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility](https://arxiv.org/abs/2509.13720)
*Tianle Zeng,Jianwei Peng,Hanjing Ye,Guangcheng Chen,Senzi Luo,Hong Zhang*

Main category: cs.RO

TL;DR: 该系统通过多尺度图像层次结构和显著性融合，实现了远距离、间歇性可见目标的零样本导航，提高了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 解决大规模户外环境中远距离、易被遮挡的目标导航挑战。

Method: 提出了一种基于对齐的多尺度图像瓦片层次结构的统一、轻量级闭环系统。通过分层目标显著性融合，将局部语义对比总结为稳定的区域显著性，以提供目标方向和可见性指示。该区域显著性支持通过关键帧记忆、显著性加权的历史航向融合和临时不可见期间的主动搜索来进行的可见性感知航向维持。

Result: 系统在模拟和真实户外试验中，能够检测超过150米的目标，并以82.6%的概率在可见性变化中保持正确的航向，整体任务成功率比现有技术提高了17.5%。

Conclusion: 该系统能够有效地实现对远处和间歇性可见目标的零样本导航。

Abstract: Zero-shot object navigation (ZSON) in large-scale outdoor environments faces
many challenges; we specifically address a coupled one: long-range targets that
reduce to tiny projections and intermittent visibility due to partial or
complete occlusion. We present a unified, lightweight closed-loop system built
on an aligned multi-scale image tile hierarchy. Through hierarchical
target-saliency fusion, it summarizes localized semantic contrast into a stable
coarse-layer regional saliency that provides the target direction and indicates
target visibility. This regional saliency supports visibility-aware heading
maintenance through keyframe memory, saliency-weighted fusion of historical
headings, and active search during temporary invisibility. The system avoids
whole-image rescaling, enables deterministic bottom-up aggregation, supports
zero-shot navigation, and runs efficiently on a mobile robot. Across simulation
and real-world outdoor trials, the system detects semantic targets beyond 150m,
maintains a correct heading through visibility changes with 82.6% probability,
and improves overall task success by 17.5% compared with the SOTA methods,
demonstrating robust ZSON toward distant and intermittently observable targets.

</details>


### [183] [Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings](https://arxiv.org/abs/2509.13731)
*Jeongwoo Park,Seabin Lee,Changmin Park,Wonjong Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 使用基于基础模型的仿真到现实方法，通过结合SAM2和VLM，自动化了柔性扁平电缆（FFC）的插入任务，显著减少了训练时间和风险。


<details>
  <summary>Details</summary>
Motivation: 柔性扁平电缆（FFC）的插入需要亚毫米级精度，给机器人操作带来挑战，现有方法需要耗时的手工轨迹生成或RL训练，且在物理环境中训练存在风险。

Method: 提出一种强化学习（RL）算法，利用基于基础模型的仿真到现实（sim-to-real）方法。通过SAM2进行语义分割，提取关键的几何和空间信息，并使用VLM自动生成SAM2的提示。所有训练在仿真环境中完成，以避免物理损坏。

Result: 实验证明，该方法具有零样本（zero-shot）能力，无需微调即可直接部署到真实环境，成功实现了FFC的自动化插入。

Conclusion: 所提出的基于基础模型的仿真到现实的RL方法，能够有效地解决FFC插入的挑战，通过减少训练时间和消除物理风险，实现了自动化和泛化性。

Abstract: The industrial insertion of flexible flat cables (FFCs) into receptacles
presents a significant challenge owing to the need for submillimeter precision
when handling the deformable cables. In manufacturing processes, FFC insertion
with robotic manipulators often requires laborious human-guided trajectory
generation. While Reinforcement Learning (RL) offers a solution to automate
this task without modeling complex properties of FFCs, the nondeterminism
caused by the deformability of FFCs requires significant efforts and time on
training. Moreover, training directly in a real environment is dangerous as
industrial robots move fast and possess no safety measure. We propose an RL
algorithm for FFC insertion that leverages a foundation model-based real-to-sim
approach to reduce the training time and eliminate the risk of physical damages
to robots and surroundings. Training is done entirely in simulation, allowing
for random exploration without the risk of physical damages. Sim-to-real
transfer is achieved through semantic segmentation masks which leave only those
visual features relevant to the insertion tasks such as the geometric and
spatial information of the cables and receptacles. To enhance generality, we
use a foundation model, Segment Anything Model 2 (SAM2). To eleminate human
intervention, we employ a Vision-Language Model (VLM) to automate the initial
prompting of SAM2 to find segmentation masks. In the experiments, our method
exhibits zero-shot capabilities, which enable direct deployments to real
environments without fine-tuning.

</details>


### [184] [FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph](https://arxiv.org/abs/2509.13733)
*Xiaolin Zhou,Tingyang Xiao,Liu Liu,Yucheng Wang,Maiyue Chen,Xinrui Meng,Xinjie Wang,Wei Feng,Wei Sui,Zhizhong Su*

Main category: cs.RO

TL;DR: FSR-VLN结合了分层多模态场景图（HMSG）和快慢导航推理（FSR），以解决现有视觉-语言导航（VLN）系统在长距离空间推理方面的局限性，提高了成功率并降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法在长距离导航方面存在空间推理能力不足、成功率低和推理延迟高的问题。

Method: 提出FSR-VLN系统，利用HMSG提供多模态地图表示，支持从粗粒度到细粒度的检索。FSR首先进行快速匹配以选择候选对象，然后通过VLM驱动的精炼进行最终目标选择。FSR-VLN在模型中集成了语音交互、规划和控制模块。

Result: FSR-VLN在四个室内数据集上均达到了最先进（SOTA）的性能，检索成功率（RSR）有所提高，并且响应时间减少了82%。

Conclusion: FSR-VLN在提高VLN任务的性能和效率方面取得了显著进展，并成功集成到人形机器人上实现了自然语言交互和实时导航。

Abstract: Visual-Language Navigation (VLN) is a fundamental challenge in robotic
systems, with broad applications for the deployment of embodied agents in
real-world environments. Despite recent advances, existing approaches are
limited in long-range spatial reasoning, often exhibiting low success rates and
high inference latency, particularly in long-range navigation tasks. To address
these limitations, we propose FSR-VLN, a vision-language navigation system that
combines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow
Navigation Reasoning (FSR). The HMSG provides a multi-modal map representation
supporting progressive retrieval, from coarse room-level localization to
fine-grained goal view and object identification. Building on HMSG, FSR first
performs fast matching to efficiently select candidate rooms, views, and
objects, then applies VLM-driven refinement for final goal selection. We
evaluated FSR-VLN across four comprehensive indoor datasets collected by
humanoid robots, utilizing 87 instructions that encompass a diverse range of
object categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all
datasets, measured by the retrieval success rate (RSR), while reducing the
response time by 82% compared to VLM-based methods on tour videos by activating
slow reasoning only when fast intuition fails. Furthermore, we integrate
FSR-VLN with speech interaction, planning, and control modules on a Unitree-G1
humanoid robot, enabling natural language interaction and real-time navigation.

</details>


### [185] [Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning](https://arxiv.org/abs/2509.13736)
*Muyuan Ma,Long Cheng,Lijun Han,Xiuze Xia,Houcheng Li*

Main category: cs.RO

TL;DR: 通过使用模型无关的元学习（MAML）框架，结合从公开数据集中提取并重新定向到模拟环境中的全身关键点运动，训练了一个任务特定的神经网络，该网络能够预测人类肘部关节的运动，从而实现可推广到新场景的有效辅助。实验证明，与无外骨骼辅助相比，该方法显著降低了新用户在未经训练的任务中的肌肉活化和代谢成本，表明该框架能有效提高外骨骼系统的任务泛化能力和用户适应性。


<details>
  <summary>Details</summary>
Motivation: 开发能够实现个性化并泛化到不同任务的辅助算法，以解决当前可穿戴外骨骼在增强人类力量和减少肌肉疲劳方面面临的挑战。

Method: 利用元模仿学习方法，通过提取公开的RGB视频和运动捕捉数据集中的全身关键点运动，并在模拟环境中进行重定向，生成肘部屈曲轨迹。然后，在模型无关的元学习（MAML）框架内，使用这些轨迹来训练一个任务特定的神经网络，使其能够快速适应新任务和未见过的用户。该网络预测的人类肘部关节运动将作为重力补偿的比例-微分（PD）控制器的一个参考信号，以实现稳定的辅助。

Result: 实验证明，与无外骨骼辅助相比，该方法能够显著降低新用户在执行未经训练的任务时的肌肉活化水平和代谢成本。

Conclusion: 所提出的框架能够有效地提高可穿戴外骨骼系统的任务泛化能力和用户适应性，从而实现更有效的辅助。

Abstract: Wearable exoskeletons can augment human strength and reduce muscle fatigue
during specific tasks. However, developing personalized and task-generalizable
assistance algorithms remains a critical challenge. To address this, a
meta-imitation learning approach is proposed. This approach leverages a
task-specific neural network to predict human elbow joint movements, enabling
effective assistance while enhancing generalization to new scenarios. To
accelerate data collection, full-body keypoint motions are extracted from
publicly available RGB video and motion-capture datasets across multiple tasks,
and subsequently retargeted in simulation. Elbow flexion trajectories generated
in simulation are then used to train the task-specific neural network within
the model-agnostic meta-learning (MAML) framework, which allows the network to
rapidly adapt to novel tasks and unseen users with only a few gradient updates.
The adapted network outputs personalized references tracked by a
gravity-compensated PD controller to ensure stable assistance. Experimental
results demonstrate that the exoskeleton significantly reduces both muscle
activation and metabolic cost for new users performing untrained tasks,
compared to performing without exoskeleton assistance. These findings suggest
that the proposed framework effectively improves task generalization and user
adaptability for wearable exoskeleton systems.

</details>


### [186] [Dynamic Adaptive Legged Locomotion Policy via Decoupling Reaction Force Control and Gait Control](https://arxiv.org/abs/2509.13737)
*Renjie Wang,Shangke Lyu,Donglin Wang*

Main category: cs.RO

TL;DR: RL在运动控制领域取得了显著进展，但其在分布外（OOD）条件和仿真到现实（sim-to-real）的差异方面存在性能下降的问题。本研究提出了一种新的解耦框架，通过分离站立腿和摆动腿的控制，实现了快速的在线适应能力，并减轻了在不熟悉环境中的sim-to-real问题。


<details>
  <summary>Details</summary>
Motivation: RL在运动控制领域虽然取得了进展，但在OOD条件和sim-to-real差异方面存在性能下降问题。

Method: 提出了一种解耦框架，将站立腿控制和摆动腿控制分开，以获得快速的在线适应能力并减轻sim-to-real问题。

Result: 通过各种仿真和真实世界的实验，证明了该方法在抵抗水平力干扰、不平坦地形、重偏载荷以及sim-to-real差异方面的有效性。

Conclusion: 所提出的解耦框架能够有效提升RL在OOD条件和sim-to-real差异下的性能。

Abstract: While Reinforcement Learning (RL) has achieved remarkable progress in legged
locomotion control, it often suffers from performance degradation in
out-of-distribution (OOD) conditions and discrepancies between the simulation
and the real environments. Instead of mainly relying on domain randomization
(DR) to best cover the real environments and thereby close the sim-to-real gap
and enhance robustness, this work proposes an emerging decoupled framework that
acquires fast online adaptation ability and mitigates the sim-to-real problems
in unfamiliar environments by isolating stance-leg control and swing-leg
control. Various simulation and real-world experiments demonstrate its
effectiveness against horizontal force disturbances, uneven terrains, heavy and
biased payloads, and sim-to-real gap.

</details>


### [187] [CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs](https://arxiv.org/abs/2509.13771)
*Mengzhu Li,Yunyu Zhou,He Ying,F. Richard Yu*

Main category: cs.RO

TL;DR: CDFlow是一个新框架，使用神经ODE学习机器人配置空间中的连续流，以解决高自由度机器人运动规划中的CDF挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的CDF方法在高自由度机器人中存在两个主要问题：1. 它们只返回一个最近的碰撞配置，忽略了最小距离碰撞配置的多模态性质，导致梯度模糊；2. 它们依赖于稀疏的碰撞边界采样，这通常会失败，无法识别真正的最近配置，在高维空间中产生过度平滑的近似和几何失真。

Method: CDFlow通过学习配置空间中的连续流来解决这些限制，使用神经ODE。它将问题重新定义为从寻找单个最近点到对最小距离碰撞配置的分布进行建模。此外，它引入了一种自适应细化采样策略来生成高保真度的训练数据。

Result: CDFlow能够隐式地对多模态分布进行建模，并产生一个平滑、一致的梯度场，从而减轻梯度模糊并保留尖锐的几何特征。在高自由度运动规划任务上的广泛实验表明，与现有的基于CDF的方法相比，CDFlow显著提高了规划效率、轨迹质量和鲁棒性。

Conclusion: CDFlow通过学习配置空间中的连续流，并对最小距离碰撞配置的分布进行建模，从而有效地解决了高自由度机器人运动规划中CDF的局限性，实现了更鲁棒、更高效的碰撞感知机器人规划。

Abstract: Signed Distance Fields (SDFs) are a fundamental representation in robot
motion planning. Their configuration-space counterpart, the Configuration Space
Distance Field (CDF), directly encodes distances in joint space, offering a
unified representation for optimization and control. However, existing CDF
formulations face two major challenges in high-degree-of-freedom (DoF) robots:
(1) they effectively return only a single nearest collision configuration,
neglecting the multi-modal nature of minimal-distance collision configurations
and leading to gradient ambiguity; and (2) they rely on sparse sampling of the
collision boundary, which often fails to identify the true closest
configurations, producing oversmoothed approximations and geometric distortion
in high-dimensional spaces. We propose CDFlow, a novel framework that addresses
these limitations by learning a continuous flow in configuration space via
Neural Ordinary Differential Equations (Neural ODEs). We redefine the problem
from finding a single nearest point to modeling the distribution of
minimal-distance collision configurations. We also introduce an adaptive
refinement sampling strategy to generate high-fidelity training data for this
distribution. The resulting Neural ODE implicitly models this multi-modal
distribution and produces a smooth, consistent gradient field-derived as the
expected direction towards the distribution-that mitigates gradient ambiguity
and preserves sharp geometric features. Extensive experiments on high-DoF
motion planning tasks demonstrate that CDFlow significantly improves planning
efficiency, trajectory quality, and robustness compared to existing CDF-based
methods, enabling more robust and efficient planning for collision-aware robots
in complex environments.

</details>


### [188] [Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach](https://arxiv.org/abs/2509.13774)
*Piaopiao Jin,Qi Wang,Guokang Sun,Ziwen Cai,Pinjia He,Yangwei You*

Main category: cs.RO

TL;DR: 该研究提出了一种结合人类反馈的强化学习框架，用于改进机器人操作的泛化能力，通过引入'talk-and-tweak'机制，将人类的语言指令转化为策略学习的有效数据，并在现实世界的多任务和长时序任务中取得了显著的成功，同时还展示了多机器人协同训练的效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在复杂现实任务中泛化能力有限，监督微调受数据质量限制，而强化学习（RL）是潜在的解决方案。

Method: 提出了一种基于RL的人类在环双Actor微调框架，该框架包含一个主Actor和一个用于潜在空间自适应的精炼Actor，并引入了'talk-and-tweak'机制，将人类的语言修正转化为新的策略学习数据。

Result: 在现实世界的多任务实验中，该方法在101分钟的在线微调后实现了100%的成功率；在长时序任务中，该方法在12次连续操作中保持了50%的成功率；双机器人训练效率提升了2倍。

Conclusion: 所提出的人类在环双Actor微调框架通过引入'talk-and-tweak'机制，能够有效提升机器人操作在复杂现实任务中的泛化能力、鲁棒性和效率。

Abstract: Vision-language-action (VLA) models demonstrate strong generalization in
robotic manipulation but face challenges in complex, real-world tasks. While
supervised fine-tuning with demonstrations is constrained by data quality,
reinforcement learning (RL) offers a promising alternative. We propose a
human-in-the-loop dual-actor fine-tuning framework grounded in RL. The
framework integrates a primary actor for robust multi-task performance with a
refinement actor for latent-space adaptation. Beyond standard physical
interventions, we introduce a lightweight talk-and-tweak scheme that converts
human corrections into semantically grounded language commands, thereby
generating a new dataset for policy learning. In real-world multi-task
experiments, our approach achieves 100% success across three tasks within 101
minutes of online fine-tuning. For long-horizon tasks, it sustains a 50%
success rate over 12 consecutive operations. Furthermore, the framework scales
effectively to multi-robot training, achieving up to a 2 times improvement in
efficiency when using dual robots. The experiment videos are available at
https://sites.google.com/view/hil-daft/.

</details>


### [189] [Reinforcement Learning for Autonomous Point-to-Point UAV Navigation](https://arxiv.org/abs/2509.13943)
*Salim Oyinlola,Nitesh Subedi,Soumik Sarkar*

Main category: cs.RO

TL;DR: 项目利用强化学习（RL）让单架无人机能够自主导航，实现了高效、安全且无需人工干预的点对点操作。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAVs）在自动化检查、交付和导航等任务中越来越多地需要可靠的自主性。

Method: 开发了一种强化学习（RL）方法，该方法集成了ROS和一个Gym兼容的训练环境，通过带有定制奖励函数的试错交互来训练无人机在避免碰撞和不安全行为的同时高效地到达目标点。

Result: 训练后的策略成功部署到真实无人机平台上，在实际条件下进行了评估，结果表明无人机能够以最少的人工监管成功执行自主导航。

Conclusion: 该研究证明了基于RL的控制在现实场景中进行点对点无人机操作的可行性。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly used in automated
inspection, delivery, and navigation tasks that require reliable autonomy. This
project develops a reinforcement learning (RL) approach to enable a single UAV
to autonomously navigate between predefined points without manual intervention.
The drone learns navigation policies through trial-and-error interaction, using
a custom reward function that encourages goal-reaching efficiency while
penalizing collisions and unsafe behavior. The control system integrates ROS
with a Gym-compatible training environment, enabling flexible deployment and
testing. After training, the learned policy is deployed on a real UAV platform
and evaluated under practical conditions. Results show that the UAV can
successfully perform autonomous navigation with minimal human oversight,
demonstrating the viability of RL-based control for point-to-point drone
operations in real-world scenarios.

</details>


### [190] [Behavior Foundation Model for Humanoid Robots](https://arxiv.org/abs/2509.13780)
*Weishuai Zeng,Shunlin Lu,Kangning Yin,Xiaojie Niu,Minyue Dai,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: BFM是一个为人形机器人设计的生成模型，旨在解决现有Whole-body control（WBC）系统任务特定、泛化性差的缺点，通过预训练捕捉通用的行为知识，并能快速适应新行为。


<details>
  <summary>Details</summary>
Motivation: 现有WBC框架主要针对特定任务，需要大量的人工设计奖励，泛化能力有限，难以应对复杂多变的现实场景。

Method: 提出行为基础模型（BFM），一个结合了掩码在线蒸馏和条件变分自编码器（CVAE）的生成模型，用于建模行为分布，捕捉广泛、可重用的行为知识。

Result: BFM在模拟和物理平台上进行了广泛的实验，证明了其在多种WBC任务上的泛化能力，并且能够快速适应新行为。

Conclusion: BFM是通用人形机器人控制领域的一个有希望的进步，为实现通用性奠定了基础。

Abstract: Whole-body control (WBC) of humanoid robots has witnessed remarkable progress
in skill versatility, enabling a wide range of applications such as locomotion,
teleoperation, and motion tracking. Despite these achievements, existing WBC
frameworks remain largely task-specific, relying heavily on labor-intensive
reward engineering and demonstrating limited generalization across tasks and
skills. These limitations hinder their response to arbitrary control modes and
restrict their deployment in complex, real-world scenarios. To address these
challenges, we revisit existing WBC systems and identify a shared objective
across diverse tasks: the generation of appropriate behaviors that guide the
robot toward desired goal states. Building on this insight, we propose the
Behavior Foundation Model (BFM), a generative model pretrained on large-scale
behavioral datasets to capture broad, reusable behavioral knowledge for
humanoid robots. BFM integrates a masked online distillation framework with a
Conditional Variational Autoencoder (CVAE) to model behavioral distributions,
thereby enabling flexible operation across diverse control modes and efficient
acquisition of novel behaviors without retraining from scratch. Extensive
experiments in both simulation and on a physical humanoid platform demonstrate
that BFM generalizes robustly across diverse WBC tasks while rapidly adapting
to new behaviors. These results establish BFM as a promising step toward a
foundation model for general-purpose humanoid control.

</details>


### [191] [Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning](https://arxiv.org/abs/2509.14040)
*Zewen Yang,Xiaobing Dai,Dongfa Zhang,Yu Li,Ziyang Meng,Bingkun Huang,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: 我们提出了Prompt2Auto，一个几何不变的一枪高斯过程（GeoGP）学习框架，使机器人能够从单个运动提示执行人类引导的自动控制。


<details>
  <summary>Details</summary>
Motivation: 传统的从演示中学习的方法需要大量数据集，并且难以泛化到坐标变换，而Prompt2Auto通过几何不变性解决了这些问题，并实现了单次演示学习。

Method: Prompt2Auto使用基于坐标变换的数据集构建策略，强制执行平移、旋转和缩放不变性，并支持多步预测。GeoGP对用户运动提示中的变化具有鲁棒性，并支持多技能自主性。

Result: 通过数值模拟和两个真实的机器人实验验证，Prompt2Auto被证明是有效的，并且能够跨任务泛化，显著减少了演示负担。

Conclusion: Prompt2Auto是一个有效的、能够跨任务泛化的单次演示学习框架，它通过几何不变性解决了传统方法的局限性，并减少了演示的需要。

Abstract: Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io

</details>


### [192] [Shell-Type Soft Jig for Holding Objects during Disassembly](https://arxiv.org/abs/2509.13802)
*Takuya Kiyokawa,Ryunosuke Takebayashi,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种适用于机器人拆卸的柔性夹持工具——壳式软夹具，该夹具能安全、通用地夹持物体，减少损坏风险，适应不同形状，并能容忍识别、规划和控制错误。


<details>
  <summary>Details</summary>
Motivation: 传统固定装置在机器人拆卸中需要专用设计、高精度识别、抓取和轨迹规划，而本研究旨在通过一种柔性夹具解决这些问题。

Method: 提出一种壳式软夹具，采用基于气球的夹持机制，实现柔性固定，并能适应不同形状的物体。

Result: 实验结果表明，与虎钳和基于阻塞的软夹具相比，该软夹具在十种不同物体上均表现出良好的可行性，同时也明确了其局限性。

Conclusion: 所提出的壳式软夹具为机器人拆卸提供了一种通用、鲁棒且易于实现的解决方案，降低了对高精度设备和规划的需求。

Abstract: This study addresses a flexible holding tool for robotic disassembly. We
propose a shell-type soft jig that securely and universally holds objects,
mitigating the risk of component damage and adapting to diverse shapes while
enabling soft fixation that is robust to recognition, planning, and control
errors. The balloon-based holding mechanism ensures proper alignment and stable
holding performance, thereby reducing the need for dedicated jig design, highly
accurate perception, precise grasping, and finely tuned trajectory planning
that are typically required with conventional fixtures. Our experimental
results demonstrate the practical feasibility of the proposed jig through
performance comparisons with a vise and a jamming-gripper-inspired soft jig.
Tests on ten different objects further showed representative successes and
failures, clarifying the jig's limitations and outlook.

</details>


### [193] [Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots](https://arxiv.org/abs/2509.14075)
*Yu Li,Hamid Sadeghian,Zewen Yang,Valentin Le Mesle,Sami Haddadin*

Main category: cs.RO

TL;DR: 该研究提出了一种约束一致性力矩控制器，用于在机器人辅助微创手术（RAMIS）中精确执行远程运动中心（RCM）约束，以提高安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的 RAMIS 控制方法在鲁棒性或 RCM 约束一致性方面存在不足，难以应对动态和交互式条件。

Method: 提出了一种将 RCM 视为流变完整约束并将其嵌入基于投影的逆动力学框架的约束一致性力矩控制器。该方法统一了任务级和运动学表述，实现了精确的工具尖端跟踪和良好的力矩行为。

Result: 通过模拟和 RAMIS 训练平台验证，该控制器在 RCM 约束满足度、所需力矩和关节力矩平滑度方面均优于现有方法，在各种临床相关场景下表现出稳健的性能。

Conclusion: 约束一致性力矩控制有潜力提高手术机器人的安全性和可靠性。

Abstract: Robotic-assisted minimally invasive surgery (RAMIS) requires precise
enforcement of the remote center of motion (RCM) constraint to ensure safe tool
manipulation through a trocar. Achieving this constraint under dynamic and
interactive conditions remains challenging, as existing control methods either
lack robustness at the torque level or do not guarantee consistent RCM
constraint satisfaction. This paper proposes a constraint-consistent torque
controller that treats the RCM as a rheonomic holonomic constraint and embeds
it into a projection-based inverse-dynamics framework. The method unifies
task-level and kinematic formulations, enabling accurate tool-tip tracking
while maintaining smooth and efficient torque behavior. The controller is
validated both in simulation and on a RAMIS training platform, and is
benchmarked against state-of-the-art approaches. Results show improved RCM
constraint satisfaction, reduced required torque, and robust performance by
improving joint torque smoothness through the consistency formulation under
clinically relevant scenarios, including spiral trajectories, variable
insertion depths, moving trocars, and human interaction. These findings
demonstrate the potential of constraint-consistent torque control to enhance
safety and reliability in surgical robotics. The project page is available at:
https://rcmpc-cube.github.io

</details>


### [194] [Soft Regrasping Tool Inspired by Jamming Gripper](https://arxiv.org/abs/2509.13815)
*Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一种受 the jamming transition 现象启发的软夹具，用于机器人装配中的重抓取，以克服传统刚性夹具的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性夹具在适应不同零件形状方面缺乏灵活性，需要为每个零件进行专门设计，这限制了其在机器人装配中的应用。

Method: 通过将三角形锥形工具压入膜中并排出空气来形成一个可容纳零件的稳定空腔，并优化冲压深度以平衡放置稳定性和抓手可及性。

Result: 在对十个不同形状的机械零件进行放置实验后，大多数零件的放置成功率超过80%，圆柱形零件的成功率超过90%。失败的主要原因是几何约束和膜的属性。

Conclusion: 所提出的软夹具能够实现通用、精确和可重复的重抓取，为装配自动化提供了一种实用的刚性夹具替代方案，同时也指出了其局限性和未来潜力。

Abstract: Regrasping on fixtures is a promising approach to reduce pose uncertainty in
robotic assembly, but conventional rigid fixtures lack adaptability and require
dedicated designs for each part. To overcome this limitation, we propose a soft
jig inspired by the jamming transition phenomenon, which can be continuously
deformed to accommodate diverse object geometries. By pressing a
triangular-pyramid-shaped tool into the membrane and evacuating the enclosed
air, a stable cavity is formed as a placement space. We further optimize the
stamping depth to balance placement stability and gripper accessibility. In
soft-jig-based regrasping, the key challenge lies in optimizing the cavity size
to achieve precise dropping; once the part is reliably placed, subsequent
grasping can be performed with reduced uncertainty. Accordingly, we conducted
drop experiments on ten mechanical parts of varying shapes, which achieved
placement success rates exceeding 80% for most objects and above 90% for
cylindrical ones, while failures were mainly caused by geometric constraints
and membrane properties. These results demonstrate that the proposed jig
enables general-purpose, accurate, and repeatable regrasping, while also
clarifying its current limitations and future potential as a practical
alternative to rigid fixtures in assembly automation.

</details>


### [195] [Agile in the Face of Delay: Asynchronous End-to-End Learning for Real-World Aerial Navigation](https://arxiv.org/abs/2509.13816)
*Yude Li,Zhexuan Zhou,Huizhe Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 该研究提出了一种异步强化学习框架，以解决无人机在复杂环境中导航时，高频控制与低频感知之间的冲突，实现了高频响应和稳健的敏捷导航。


<details>
  <summary>Details</summary>
Motivation: 高频控制与低频感知之间的冲突限制了传统无人机导航系统的性能。

Method: 提出了一种异步强化学习框架，将感知和控制分离，并引入了时间编码模块（TEM）来处理数据延迟，同时使用两阶段课程学习来稳定训练。

Result: 该方法在仿真和真实环境中都表现出了稳健、敏捷的导航能力，并在真实部署中实现了100Hz的控制频率。

Conclusion: 该异步强化学习框架能够有效地解决无人机在高频控制和低频感知之间的冲突，实现鲁棒的自主导航。

Abstract: Robust autonomous navigation for Autonomous Aerial Vehicles (AAVs) in complex
environments is a critical capability. However, modern end-to-end navigation
faces a key challenge: the high-frequency control loop needed for agile flight
conflicts with low-frequency perception streams, which are limited by sensor
update rates and significant computational cost. This mismatch forces
conventional synchronous models into undesirably low control rates. To resolve
this, we propose an asynchronous reinforcement learning framework that
decouples perception and control, enabling a high-frequency policy to act on
the latest IMU state for immediate reactivity, while incorporating perception
features asynchronously. To manage the resulting data staleness, we introduce a
theoretically-grounded Temporal Encoding Module (TEM) that explicitly
conditions the policy on perception delays, a strategy complemented by a
two-stage curriculum to ensure stable and efficient training. Validated in
extensive simulations, our method was successfully deployed in zero-shot
sim-to-real transfer on an onboard NUC, where it sustains a 100~Hz control rate
and demonstrates robust, agile navigation in cluttered real-world environments.
Our source code will be released for community reference.

</details>


### [196] [UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography](https://arxiv.org/abs/2509.13832)
*Teng Wang,Haojun Jiang,Yuxuan Wang,Zhenguo Sun,Xiangjie Yan,Xiang Li,Gao Huang*

Main category: cs.RO

TL;DR: 该研究提出了UltraHiT，一种基于分层Transformer的决策架构，用于自动扫描颈内动脉（ICA），成功率达到95%。


<details>
  <summary>Details</summary>
Motivation: 颈内动脉（ICA）的自动超声扫描由于其深在、弯曲和个体差异大等原因极具挑战性，现有研究尚未解决此问题。本研究旨在解决这一挑战。

Method: 提出了一种名为UltraHiT的分层Transformer决策架构，该架构结合了高级变异性评估和低级动作决策。高级模块识别变异性，并根据情况在自适应校正器（用于处理变异性）和标准执行器（用于正常情况）之间切换。高级模块和自适应校正器均采用因果Transformer实现，并使用了包含164条轨迹和72K样本的颈内动脉扫描数据集。

Result: 在对未见过的个体进行ICA定位时，UltraHiT实现了95%的成功率，优于现有基线方法。

Conclusion: UltraHiT能够成功实现颈内动脉的自动超声扫描，证明了其有效性。

Abstract: Carotid ultrasound is crucial for the assessment of cerebrovascular health,
particularly the internal carotid artery (ICA). While previous research has
explored automating carotid ultrasound, none has tackled the challenging ICA.
This is primarily due to its deep location, tortuous course, and significant
individual variations, which greatly increase scanning complexity. To address
this, we propose a Hierarchical Transformer-based decision architecture, namely
UltraHiT, that integrates high-level variation assessment with low-level action
decision. Our motivation stems from conceptualizing individual vascular
structures as morphological variations derived from a standard vascular model.
The high-level module identifies variation and switches between two low-level
modules: an adaptive corrector for variations, or a standard executor for
normal cases. Specifically, both the high-level module and the adaptive
corrector are implemented as causal transformers that generate predictions
based on the historical scanning sequence. To ensure generalizability, we
collected the first large-scale ICA scanning dataset comprising 164
trajectories and 72K samples from 28 subjects of both genders. Based on the
above innovations, our approach achieves a 95% success rate in locating the ICA
on unseen individuals, outperforming baselines and demonstrating its
effectiveness. Our code will be released after acceptance.

</details>


### [197] [Track Any Motions under Any Disturbances](https://arxiv.org/abs/2509.13833)
*Zhikai Zhang,Jun Guo,Chao Chen,Jilong Wang,Chenghuai Lin,Yunrui Lian,Han Xue,Zhenrong Wang,Maoqi Liu,Huaping Liu,He Wang,Li Yi*

Main category: cs.RO

TL;DR: Any2Track是一个两阶段强化学习框架，可以跟踪各种运动和扰动。


<details>
  <summary>Details</summary>
Motivation: 实现能够跟踪各种动态、接触丰富运动，并在现实世界各种干扰下稳定运行的人形运动跟踪器。

Method: 提出Any2Track，一个包含AnyTracker和AnyAdapter两部分的双阶段RL框架。AnyTracker负责跟踪各种运动，AnyAdapter通过历史信息进行在线动态适应，以克服域转移和现实世界干扰。

Result: 在Unitree G1硬件上实现了零样本的Sim2Real迁移，并在各种现实世界干扰下成功跟踪了各种运动。

Conclusion: Any2Track能够成功地在现实世界中跟踪各种运动和扰动。

Abstract: A foundational humanoid motion tracker is expected to be able to track
diverse, highly dynamic, and contact-rich motions. More importantly, it needs
to operate stably in real-world scenarios against various dynamics
disturbances, including terrains, external forces, and physical property
changes for general practical use. To achieve this goal, we propose Any2Track
(Track Any motions under Any disturbances), a two-stage RL framework to track
various motions under multiple disturbances in the real world. Any2Track
reformulates dynamics adaptability as an additional capability on top of basic
action execution and consists of two key components: AnyTracker and AnyAdapter.
AnyTracker is a general motion tracker with a series of careful designs to
track various motions within a single policy. AnyAdapter is a history-informed
adaptation module that endows the tracker with online dynamics adaptability to
overcome the sim2real gap and multiple real-world disturbances. We deploy
Any2Track on Unitree G1 hardware and achieve a successful sim2real transfer in
a zero-shot manner. Any2Track performs exceptionally well in tracking various
motions under multiple real-world disturbances.

</details>


### [198] [Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models](https://arxiv.org/abs/2509.13839)
*Motonari Kambara,Komei Sugiura*

Main category: cs.RO

TL;DR: 提出一种新模型，用于在执行前预测开放词汇对象操作任务的成功率，以提高效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在动作执行后才判断成败，难以预防危险并依赖失败触发重规划，降低了操作序列的效率。

Method: 提出一个模型，预测预操作的单视角图像与计划轨迹及自然语言指令之间的对齐度。引入多层次轨迹融合模块，并行采用最先进的深度状态空间模型和Transformer编码器，以捕捉末端执行器轨迹内的多层次时间序列自相关性。

Result: 实验结果表明，所提出的方法优于包括基础模型在内的现有方法。

Conclusion: 所提出的模型能够有效地预测开放词汇对象操作任务的成功率，并优于现有方法。

Abstract: In this work, we address the problem of predicting the future success of
open-vocabulary object manipulation tasks. Conventional approaches typically
determine success or failure after the action has been carried out. However,
they make it difficult to prevent potential hazards and rely on failures to
trigger replanning, thereby reducing the efficiency of object manipulation
sequences. To overcome these challenges, we propose a model, which predicts the
alignment between a pre-manipulation egocentric image with the planned
trajectory and a given natural language instruction. We introduce a Multi-Level
Trajectory Fusion module, which employs a state-of-the-art deep state-space
model and a transformer encoder in parallel to capture multi-level time-series
self-correlation within the end effector trajectory. Our experimental results
indicate that the proposed method outperformed existing methods, including
foundation models.

</details>


### [199] [InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap](https://arxiv.org/abs/2509.13857)
*Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.RO

TL;DR: InterKey利用路口作为地标，结合点云和OSM数据，通过紧凑的二值描述符实现可靠的全球定位，克服了HD地图的局限性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号弱或不可用的环境中（如城市峡谷和隧道），为自动驾驶车辆提供可靠的全球定位至关重要。高精度地图成本高昂，而OSM数据免费但精度不足，因此需要一种可扩展且经济高效的解决方案。

Method: InterKey提出了一种跨模态框架，利用路口作为地标，通过联合编码点云和OSM数据中的道路和建筑印记来构建紧凑的二值描述符。该方法采用了差异缓解、方向确定和面积均衡采样策略来弥合模态间隙，实现鲁棒的跨模态匹配。

Result: 在KITTI数据集上的实验表明，InterKey实现了最先进的精度，显著优于现有方法。

Conclusion: InterKey为自动驾驶车辆提供了一种可扩展且经济高效的鲁棒定位解决方案，能够泛化到能生成密集结构点云的传感器。

Abstract: Reliable global localization is critical for autonomous vehicles, especially
in environments where GNSS is degraded or unavailable, such as urban canyons
and tunnels. Although high-definition (HD) maps provide accurate priors, the
cost of data collection, map construction, and maintenance limits scalability.
OpenStreetMap (OSM) offers a free and globally available alternative, but its
coarse abstraction poses challenges for matching with sensor data. We propose
InterKey, a cross-modal framework that leverages road intersections as
distinctive landmarks for global localization. Our method constructs compact
binary descriptors by jointly encoding road and building imprints from point
clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,
orientation determination, and area-equalized sampling strategies, enabling
robust cross-modal matching. Experiments on the KITTI dataset demonstrate that
InterKey achieves state-of-the-art accuracy, outperforming recent baselines by
a large margin. The framework generalizes to sensors that can produce dense
structural point clouds, offering a scalable and cost-effective solution for
robust vehicle localization.

</details>


### [200] [Using Petri Nets for Context-Adaptive Robot Explanations](https://arxiv.org/abs/2509.13861)
*Görkem Kılınç Soylu,Neziha Akalin,Maria Riveiro*

Main category: cs.RO

TL;DR: 使用 Petri  अपघात模型来为机器人提供基于上下文的自适应解释，以增强人机交互中的信任。


<details>
  <summary>Details</summary>
Motivation: 为了在人机交互中建立信任，机器人需要以自然、透明的方式进行通信，并根据上下文调整其通信方式。

Method: 提出使用 Petri  अपघात（PNs）来为机器人解释中的上下文信息建模。PNs 是一种正式的、图形化的方法，用于表示并发动作、因果依赖关系和系统状态，适用于分析人与机器人之间的动态交互。

Result: 通过一个机器人根据用户注意力、在场情况等上下文线索提供解释的场景来演示这种方法。模型分析确认了关键属性，如无死锁、上下文敏感的可达性、有界性和活性。

Conclusion: PNs 为在人机交互中设计和验证适应上下文的解释提供了鲁棒性和灵活性。

Abstract: In human-robot interaction, robots must communicate in a natural and
transparent manner to foster trust, which requires adapting their communication
to the context. In this paper, we propose using Petri nets (PNs) to model
contextual information for adaptive robot explanations. PNs provide a formal,
graphical method for representing concurrent actions, causal dependencies, and
system states, making them suitable for analyzing dynamic interactions between
humans and robots. We demonstrate this approach through a scenario involving a
robot that provides explanations based on contextual cues such as user
attention and presence. Model analysis confirms key properties, including
deadlock-freeness, context-sensitive reachability, boundedness, and liveness,
showing the robustness and flexibility of PNs for designing and verifying
context-adaptive explanations in human-robot interactions.

</details>


### [201] [PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models](https://arxiv.org/abs/2509.13903)
*Artem Lykov,Jeffrin Sam,Hung Khang Nguyen,Vladislav Kozlovskiy,Yara Mahmoud,Valerii Serpiva,Miguel Altamirano Cabrera,Mikhail Konenkov,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: PhysicalAgent是一个创新的机器人操作框架，通过结合迭代推理、基于扩散视频生成和闭环执行，实现了机器人操作的鲁棒性。该方法能从执行错误中恢复，并在多种机器人平台和感知模式下表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了实现更通用、更鲁棒的机器人操作，尤其是在处理执行错误和适应不同机器人平台方面，需要一种能够集成推理、生成和闭环执行的框架。

Method: PhysicalAgent框架整合了迭代推理、基于扩散的视频生成以及闭环执行。具体来说，它接收文本指令，生成候选轨迹的短视频演示，然后在机器人上执行这些轨迹，并在遇到失败时进行迭代式重新规划。

Result: 在多种感知模式（包括主视角、第三人称和模拟）和机器人实体（包括双臂UR3、Unitree G1人形机器人和模拟GR1）上的评估显示，PhysicalAgent的成功率高达83%。实验表明，虽然首次尝试的成功率较低（20-30%），但通过迭代修正，整体成功率可提高到80%。

Conclusion: 基于视频的生成式推理和迭代式执行对于提高机器人操作的通用性、适应性和鲁棒性至关重要，尤其是在从初始执行失败中恢复方面。PhysicalAgent的成功展示了其在推动可扩展、适应性强且鲁棒的机器人控制方面的潜力。

Abstract: We introduce PhysicalAgent, an agentic framework for robotic manipulation
that integrates iterative reasoning, diffusion-based video generation, and
closed-loop execution. Given a textual instruction, our method generates short
video demonstrations of candidate trajectories, executes them on the robot, and
iteratively re-plans in response to failures. This approach enables robust
recovery from execution errors. We evaluate PhysicalAgent across multiple
perceptual modalities (egocentric, third-person, and simulated) and robotic
embodiments (bimanual UR3, Unitree G1 humanoid, simulated GR1), comparing
against state-of-the-art task-specific baselines. Experiments demonstrate that
our method consistently outperforms prior approaches, achieving up to 83%
success on human-familiar tasks. Physical trials reveal that first-attempt
success is limited (20-30%), yet iterative correction increases overall success
to 80% across platforms. These results highlight the potential of video-based
generative reasoning for general-purpose robotic manipulation and underscore
the importance of iterative execution for recovering from initial failures. Our
framework paves the way for scalable, adaptable, and robust robot control.

</details>


### [202] [MAP: End-to-End Autonomous Driving with Map-Assisted Planning](https://arxiv.org/abs/2509.13926)
*Huilin Yin,Yiming Kan,Daniel Watzenig*

Main category: cs.RO

TL;DR: MAP是一个新颖的地图辅助端到端轨迹规划框架，通过整合在线地图特征和当前自我状态来提升轨迹规划性能，并在DAIR-V2X-seq-SPD数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法未能充分利用在线地图模块的潜力来增强轨迹规划。

Method: MAP框架显式地集成了基于分割的地图特征和当前自我状态，通过一个增强在线地图模块、一个自我状态引导规划模块和一个基于当前自我状态的权重适配器。

Result: 在DAIR-V2X-seq-SPD数据集上，MAP相比UniV2X基线，L2位移误差减少了16.6%，越野率降低了56.2%，总体得分提高了44.5%。在MEIS Workshop @CVPR2025的V2X协作端到端自动驾驶挑战赛Track 2中，MAP的总体得分比第二名高出39.5%。

Conclusion: 显式利用语义地图特征进行规划是有效的，并为改进端到端自动驾驶系统的结构设计提供了新的方向。

Abstract: In recent years, end-to-end autonomous driving has attracted increasing
attention for its ability to jointly model perception, prediction, and planning
within a unified framework. However, most existing approaches underutilize the
online mapping module, leaving its potential to enhance trajectory planning
largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel
map-assisted end-to-end trajectory planning framework. MAP explicitly
integrates segmentation-based map features and the current ego status through a
Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and
a Weight Adapter based on current ego status. Experiments conducted on the
DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%
reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a
44.5% improvement in overall score compared to the UniV2X baseline, even
without post-processing. Furthermore, it achieves top ranking in Track 2 of the
End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS
Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of
overall score. These results highlight the effectiveness of explicitly
leveraging semantic map features in planning and suggest new directions for
improving structure design in end-to-end autonomous driving systems. Our code
is available at https://gitee.com/kymkym/map.git

</details>


### [203] [The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot](https://arxiv.org/abs/2509.13948)
*Benedict Barrow,Roger K. Moore*

Main category: cs.RO

TL;DR: 研究表明，机器人的


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨影响人类对机器人信任度的因素，特别是机器人面部特征（如娃娃脸）对信任感的影响。

Method: 通过操控Furhat机器人的面部特征（特别是眼睛的形状和大小），进行一项研究，以验证'娃娃脸'假说。

Result: 研究结果证实，眼睛的形状和大小对感知到的可信度有显著影响。

Conclusion: 这项研究有助于理解在设计社交机器人时，需要做出哪些设计选择，以优化人机交互的有效性。

Abstract: Trust and the perception of trustworthiness play an important role in
decision-making and our behaviour towards others, and this is true not only of
human-human interactions but also of human-robot interactions. While
significant advances have been made in recent years in the field of social
robotics, there is still some way to go before we fully understand the factors
that influence human trust in robots. This paper presents the results of a
study into the first impressions created by a social robot's facial features,
based on the hypothesis that a `babyface' engenders trust. By manipulating the
back-projected face of a Furhat robot, the study confirms that eye shape and
size have a significant impact on the perception of trustworthiness. The work
thus contributes to an understanding of the design choices that need to be made
when developing social robots so as to optimise the effectiveness of
human-robot interaction.

</details>


### [204] [SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks](https://arxiv.org/abs/2509.13949)
*Jannick Stranghöner,Philipp Hartmann,Marco Braun,Sebastian Wrede,Klaus Neumann*

Main category: cs.RO

TL;DR: SHaRe-RL是一个强化学习框架，通过结合操作原语、人类演示和在线校正以及约束力来提高工业装配的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 高混合低产量（HMLV）工业装配需要高精度、安全性和可靠性，同时保持灵活性以适应产品变化和环境不确定性，但现有机器人系统难以满足这些需求。

Method: SHaRe-RL框架通过（i）将技能分解为操作原语，（ii）结合人类演示和在线校正，以及（iii）通过每轴柔顺性来约束交互力，从而实现长时程、富接触的工业装配任务的在线高效安全学习。

Result: 在0.2-0.4毫米间隙的工业Harting连接器模块插入实验中，SHaRe-RL在实际可行的时限内实现了可靠的性能。

Conclusion: 研究结果表明，在不需要机器人或强化学习知识的情况下，过程专业知识可以对学习做出有意义的贡献，从而能够更安全、更稳健、更经济地将强化学习应用于工业装配。

Abstract: High-mix low-volume (HMLV) industrial assembly, common in small and
medium-sized enterprises (SMEs), requires the same precision, safety, and
reliability as high-volume automation while remaining flexible to product
variation and environmental uncertainty. Current robotic systems struggle to
meet these demands. Manual programming is brittle and costly to adapt, while
learning-based methods suffer from poor sample efficiency and unsafe
exploration in contact-rich tasks. To address this, we present SHaRe-RL, a
reinforcement learning framework that leverages multiple sources of prior
knowledge. By (i) structuring skills into manipulation primitives, (ii)
incorporating human demonstrations and online corrections, and (iii) bounding
interaction forces with per-axis compliance, SHaRe-RL enables efficient and
safe online learning for long-horizon, contact-rich industrial assembly tasks.
Experiments on the insertion of industrial Harting connector modules with
0.2-0.4 mm clearance demonstrate that SHaRe-RL achieves reliable performance
within practical time budgets. Our results show that process expertise, without
requiring robotics or RL knowledge, can meaningfully contribute to learning,
enabling safer, more robust, and more economically viable deployment of RL for
industrial assembly.

</details>


### [205] [SEG-Parking: Towards Safe, Efficient, and Generalizable Autonomous Parking via End-to-End Offline Reinforcement Learning](https://arxiv.org/abs/2509.13956)
*Zewei Yang,Zengqi Peng,Jun Ma*

Main category: cs.RO

TL;DR: SEG-Parking是一个端到端的离线强化学习框架，用于交互式自主停车。


<details>
  <summary>Details</summary>
Motivation: 为了解决非结构化环境和动态交互对自主停车任务带来的挑战，我们提出了SEG-Parking。

Method: SEG-Parking框架首先构建了一个包含有无对面车辆（OV）交互的停车数据集，并预训练了一个目标条件状态编码器。然后，使用包含离线策略优化和过拟合行为惩罚的保守正则化器来优化策略。

Result: 在CARLA模拟器中进行的广泛的闭环实验表明，SEG-Parking框架在最高成功率和对分布外停车场景的鲁棒泛化方面表现出优越的性能。

Conclusion: SEG-Parking框架能够实现交互感知自主停车，并在各种停车场景中表现出优越的性能。

Abstract: Autonomous parking is a critical component for achieving safe and efficient
urban autonomous driving. However, unstructured environments and dynamic
interactions pose significant challenges to autonomous parking tasks. To
address this problem, we propose SEG-Parking, a novel end-to-end offline
reinforcement learning (RL) framework to achieve interaction-aware autonomous
parking. Notably, a specialized parking dataset is constructed for parking
scenarios, which include those without interference from the opposite vehicle
(OV) and complex ones involving interactions with the OV. Based on this
dataset, a goal-conditioned state encoder is pretrained to map the fused
perception information into the latent space. Then, an offline RL policy is
optimized with a conservative regularizer that penalizes out-of-distribution
actions. Extensive closed-loop experiments are conducted in the high-fidelity
CARLA simulator. Comparative results demonstrate the superior performance of
our framework with the highest success rate and robust generalization to
out-of-distribution parking scenarios. The related dataset and source code will
be made publicly available after the paper is accepted.

</details>


### [206] [MetricNet: Recovering Metric Scale in Generative Navigation Policies](https://arxiv.org/abs/2509.13965)
*Abhijeet Nayak,Débora N. P. Oliveira,Samiran Gode,Cordelia Schmid,Wolfram Burgard*

Main category: cs.RO

TL;DR: 生成导航策略存在结构性问题，提出MetricNet以解决度量和路径规划问题，并在仿真和现实世界中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的生成导航策略在度量尺度和路径规划方面存在问题，可能导致机器人做出短视和不安全的行为。

Method: 提出MetricNet，一个用于生成导航的附加模块，用于预测航点之间的度量距离，并将策略输出映射到真实世界坐标。在此基础上，进一步提出MetricNav，将MetricNet集成到导航策略中，引导机器人避开障碍物并向目标前进。

Result: 在仿真和现实世界实验中，MetricNet显著提高了导航和探索性能，MetricNav能够引导机器人避开障碍物。

Conclusion: MetricNet能够解决生成导航策略的度量尺度问题，MetricNav则能进一步提高导航的安全性和有效性。

Abstract: Generative navigation policies have made rapid progress in improving
end-to-end learned navigation. Despite their promising results, this paradigm
has two structural problems. First, the sampled trajectories exist in an
abstract, unscaled space without metric grounding. Second, the control strategy
discards the full path, instead moving directly towards a single waypoint. This
leads to short-sighted and unsafe actions, moving the robot towards obstacles
that a complete and correctly scaled path would circumvent. To address these
issues, we propose MetricNet, an effective add-on for generative navigation
that predicts the metric distance between waypoints, grounding policy outputs
in real-world coordinates. We evaluate our method in simulation with a new
benchmarking framework and show that executing MetricNet-scaled waypoints
significantly improves both navigation and exploration performance. Beyond
simulation, we further validate our approach in real-world experiments.
Finally, we propose MetricNav, which integrates MetricNet into a navigation
policy to guide the robot away from obstacles while still moving towards the
goal.

</details>


### [207] [BIM Informed Visual SLAM for Construction Monitoring](https://arxiv.org/abs/2509.13972)
*Asier Bikandi,Miguel Fernandez-Cortizas,Muhammad Shaheer,Ali Tourani,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: RGB-D SLAM系统结合BIM作为结构先验知识，在施工现场得到验证，将轨迹误差平均降低23.71%，地图RMSE降低7.14%。


<details>
  <summary>Details</summary>
Motivation: 建筑施工监控需要SLAM技术，但现有的LiDAR-SLM因传感器体积大、功耗高而受限，而视觉SLAM在重复性布局、遮挡、纹理缺失等问题上存在轨迹漂移的挑战。因此，需要一种更实用的SLAM方法。 

Method: 提出一种RGB-D SLAM系统，将BIM作为结构先验知识，通过检测到的墙体与BIM模型对应，并将这些对应关系作为约束引入后端优化，以解决视觉SLAM的挑战。

Result: 在实际施工现场进行验证，与视觉SLAM基线相比，将轨迹误差平均降低23.71%，地图RMSE降低7.14%。

Conclusion: BIM约束能够实现数字规划与实际场景的可靠对齐，即使在部分施工条件下也能实现。

Abstract: Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring
construction sites, where aligning the evolving as-built state with the
as-planned design enables early error detection and reduces costly rework.
LiDAR-based SLAM achieves high geometric precision, but its sensors are
typically large and power-demanding, limiting their use on portable platforms.
Visual SLAM offers a practical alternative with lightweight cameras already
embedded in most mobile devices. however, visually mapping construction
environments remains challenging: repetitive layouts, occlusions, and
incomplete or low-texture structures often cause drift in the trajectory map.
To mitigate this, we propose an RGB-D SLAM system that incorporates the
Building Information Model (BIM) as structural prior knowledge. Instead of
relying solely on visual cues, our system continuously establishes
correspondences between detected wall and their BIM counterparts, which are
then introduced as constraints in the back-end optimization. The proposed
method operates in real time and has been validated on real construction sites,
reducing trajectory error by an average of 23.71% and map RMSE by 7.14%
compared to visual SLAM baselines. These results demonstrate that BIM
constraints enable reliable alignment of the digital plan with the as-built
scene, even under partially constructed conditions.

</details>


### [208] [Flexible and Foldable: Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array](https://arxiv.org/abs/2509.13998)
*Bailey Dacre,Rodrigo Moreno,Serhat Demirtas,Ziqiao Wang,Yuhao Jiang,Jamie Paik,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 提出了一种新型分布式操纵器系统（DMS），该系统使用3-DoF、受折纸启发的机器人瓦片阵列，由柔性表面层互联，以实现更广泛、更低成本的物体操纵。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式操纵器系统（DMS）设计通常需要高执行器密度并对物体与执行器的尺寸比例有限制，这限制了它们的适应性。本研究旨在开发一种新型DMS设计，以克服这些限制。

Method: 提出了一种利用3-DoF、受折纸启发的机器人瓦片阵列，并由柔性表面层互联的新型DMS设计。该设计不仅可以在执行器末端执行器执行操作，还可以在连接所有执行器的柔性表面上进行操作，从而创建一个连续、可控的操作表面。对系统的组合工作空间进行了分析，并推导了简单的运动原语。

Result: 与传统的、高密度的DMS相比，该新型DMS设计能够以1.84倍的比例增加操作对象的面积，而无需增加执行器的数量。这表明该设计在降低成本和复杂性的同时，显著提高了操作能力。

Conclusion: 该新型DMS设计通过利用瓦片间的连接材料，显著降低了执行器密度，并扩展了操作范围。它为传统高密度阵列提供了一种成本更低、复杂度更低的替代方案，并为利用互联表面灵活性提供了新的操作策略机会。

Abstract: Object manipulation is a fundamental challenge in robotics, where systems
must balance trade-offs among manipulation capabilities, system complexity, and
throughput. Distributed manipulator systems (DMS) use the coordinated motion of
actuator arrays to perform complex object manipulation tasks, seeing widespread
exploration within the literature and in industry. However, existing DMS
designs typically rely on high actuator densities and impose constraints on
object-to-actuator scale ratios, limiting their adaptability. We present a
novel DMS design utilizing an array of 3-DoF, origami-inspired robotic tiles
interconnected by a compliant surface layer. Unlike conventional DMS, our
approach enables manipulation not only at the actuator end effectors but also
across a flexible surface connecting all actuators; creating a continuous,
controllable manipulation surface. We analyse the combined workspace of such a
system, derive simple motion primitives, and demonstrate its capabilities to
translate simple geometric objects across an array of tiles. By leveraging the
inter-tile connective material, our approach significantly reduces actuator
density, increasing the area over which an object can be manipulated by x1.84
without an increase in the number of actuators. This design offers a lower cost
and complexity alternative to traditional high-density arrays, and introduces
new opportunities for manipulation strategies that leverage the flexibility of
the interconnected surface.

</details>


### [209] [Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization](https://arxiv.org/abs/2509.14010)
*Zong Chen,Shaoyang Li,Ben Liu,Min Li,Zhouping Yin,Yiqun Li*

Main category: cs.RO

TL;DR: 该论文提出了一种轮腿式四足机器人及其整体育动控制方法，以应对移动操作中的挑战。


<details>
  <summary>Details</summary>
Motivation: 集成机械臂的轮腿式机器人有望在物流、工业自动化和人机协作领域发挥重要作用，但其整体育动控制面临自由度冗余、轮地接触动力学复杂以及移动与操作协调困难等挑战。

Method: 开发了一种机器人平台，集成了独立的转向驱动模块和轮毂驱动轮，实现了高机动性的全向移动。提出了一种面向接触的整体育动动态优化框架，集成了操作的点接触模型和车轮的线接触模型。引入了热启动策略加速在线优化，并设计了统一的运动学模型以消除不同移动策略间的模式切换。

Result: 仿真和实验结果表明，该框架能够实现敏捷的地形穿越、高速全向移动以及在各种场景下的精确操作。

Conclusion: 该轮腿式机器人及其整体育动控制框架在工厂自动化、城市物流和半结构化环境中的服务机器人领域具有巨大潜力。

Abstract: Wheel-legged robots with integrated manipulators hold great promise for
mobile manipulation in logistics, industrial automation, and human-robot
collaboration. However, unified control of such systems remains challenging due
to the redundancy in degrees of freedom, complex wheel-ground contact dynamics,
and the need for seamless coordination between locomotion and manipulation. In
this work, we present the design and whole-body motion control of an
omnidirectional wheel-legged quadrupedal robot equipped with a dexterous
manipulator. The proposed platform incorporates independently actuated steering
modules and hub-driven wheels, enabling agile omnidirectional locomotion with
high maneuverability in structured environments. To address the challenges of
contact-rich interaction, we develop a contact-aware whole-body dynamic
optimization framework that integrates point-contact modeling for manipulation
with line-contact modeling for wheel-ground interactions. A warm-start strategy
is introduced to accelerate online optimization, ensuring real-time feasibility
for high-dimensional control. Furthermore, a unified kinematic model tailored
for the robot's 4WIS-4WID actuation scheme eliminates the need for mode
switching across different locomotion strategies, improving control consistency
and robustness. Simulation and experimental results validate the effectiveness
of the proposed framework, demonstrating agile terrain traversal, high-speed
omnidirectional mobility, and precise manipulation under diverse scenarios,
underscoring the system's potential for factory automation, urban logistics,
and service robotics in semi-structured environments.

</details>


### [210] [Language Conditioning Improves Accuracy of Aircraft Goal Prediction in Untowered Airspace](https://arxiv.org/abs/2509.14063)
*Sundhar Vinodh Sangeetha,Chih-Yuan Chiu,Sarah H. Q. Li,Shreyas Kousik*

Main category: cs.RO

TL;DR: 该论文提出了一种结合自然语言理解和空间推理的多模态框架，用于预测自主飞机在无塔台空域中的意图和目标位置，以提高自主决策能力。


<details>
  <summary>Details</summary>
Motivation: 在无塔台空域，自主飞机需要预测其他飞机的意图和目标位置，以实现安全运行。

Method: 利用自动语音识别和大型语言模型转录和解释飞行员的无线电呼叫，识别飞机并提取离散的意图标签。将这些意图标签与观测到的轨迹融合，以条件化一个时间卷积网络和高斯混合模型，进行概率目标预测。

Result: 与仅依赖运动历史的基线方法相比，该方法显著降低了目标预测误差，表明语言条件预测提高了预测准确性。

Conclusion: 在真实世界的无塔台机场数据集上进行的实验验证了该方法的有效性，并强调了其在实现具有社会意识、语言条件约束的机器人运动规划方面的潜力。

Abstract: Autonomous aircraft must safely operate in untowered airspace, where
coordination relies on voice-based communication among human pilots. Safe
operation requires an aircraft to predict the intent, and corresponding goal
location, of other aircraft. This paper introduces a multimodal framework for
aircraft goal prediction that integrates natural language understanding with
spatial reasoning to improve autonomous decision-making in such environments.
We leverage automatic speech recognition and large language models to
transcribe and interpret pilot radio calls, identify aircraft, and extract
discrete intent labels. These intent labels are fused with observed
trajectories to condition a temporal convolutional network and Gaussian mixture
model for probabilistic goal prediction. Our method significantly reduces goal
prediction error compared to baselines that rely solely on motion history,
demonstrating that language-conditioned prediction increases prediction
accuracy. Experiments on a real-world dataset from an untowered airport
validate the approach and highlight its potential to enable socially aware,
language-conditioned robotic motion planning.

</details>


### [211] [FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video](https://arxiv.org/abs/2509.14082)
*Valerii Serpiva,Artem Lykov,Faryal Batool,Vladislav Kozlovskiy,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: FlightDiffusion是一个基于扩散模型的框架，可以从第一人称视角（FPV）视频中训练自主无人机。该模型可以从单帧生成逼真的视频序列，并配有相应的动作空间，从而能够在动态环境中进行推理驱动的导航。该方法能够合成多样化的FPV轨迹和状态-动作对，从而克服了现实世界数据收集成本高昂的限制，并可以大规模地生成训练数据集。


<details>
  <summary>Details</summary>
Motivation: 为了克服现实世界数据收集成本高昂的限制，并为无人机提供大规模的训练数据集，以实现推理驱动的导航。

Method: 提出了一种基于扩散模型的框架（FlightDiffusion），可以从FPV视频中训练自主无人机。该模型能够从单帧生成逼真的视频序列，并生成相应的动作空间，以用于推理驱动的导航。此外，它还利用其生成能力来合成多样化的FPV轨迹和状态-动作对，从而为训练生成大规模数据集。

Result: 生成的轨迹在物理上是合理的，并且是可执行的，平均位置误差为0.25米（RMSE为0.28米），平均方向误差为0.19弧度（RMSE为0.24弧度）。在模拟环境中，该方法提高了鲁棒性、轨迹规划的平滑性以及对未见情况的适应性。模拟和现实世界之间的成功率无统计学显著差异（M=0.628, SD=0.162 vs M=0.617, SD=0.177），表明了良好的模拟到现实的迁移能力。

Conclusion: FlightDiffusion提供了一种利用扩散模型进行无人机自主导航、动作生成和数据合成的范式。该方法能够生成高质量的训练数据，并实现优于现有方法的下游导航任务性能，同时确保了良好的模拟到现实的迁移能力。

Abstract: We present FlightDiffusion, a diffusion-model-based framework for training
autonomous drones from first-person view (FPV) video. Our model generates
realistic video sequences from a single frame, enriched with corresponding
action spaces to enable reasoning-driven navigation in dynamic environments.
Beyond direct policy learning, FlightDiffusion leverages its generative
capabilities to synthesize diverse FPV trajectories and state-action pairs,
facilitating the creation of large-scale training datasets without the high
cost of real-world data collection. Our evaluation demonstrates that the
generated trajectories are physically plausible and executable, with a mean
position error of 0.25 m (RMSE 0.28 m) and a mean orientation error of 0.19 rad
(RMSE 0.24 rad). This approach enables improved policy learning and dataset
scalability, leading to superior performance in downstream navigation tasks.
Results in simulated environments highlight enhanced robustness, smoother
trajectory planning, and adaptability to unseen conditions. An ANOVA revealed
no statistically significant difference between performance in simulation and
reality (F(1, 16) = 0.394, p = 0.541), with success rates of M = 0.628 (SD =
0.162) and M = 0.617 (SD = 0.177), respectively, indicating strong sim-to-real
transfer. The generated datasets provide a valuable resource for future UAV
research. This work introduces diffusion-based reasoning as a promising
paradigm for unifying navigation, action generation, and data synthesis in
aerial robotics.

</details>


### [212] [GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14117)
*Ali Abouzeid,Malak Mansour,Zezhou Sun,Dezhen Song*

Main category: cs.RO

TL;DR: GeoAware-VLA通过集成几何先验来增强视觉-语言-动作（VLA）模型在不同视角的泛化能力，在模拟和真实机器人实验中均取得显著成效。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在面对新视角时泛化能力不足，主要原因是它们难以从2D图像中推断出稳健的3D几何信息。

Method: GeoAware-VLA通过使用一个预训练的、固定的几何视觉模型作为特征提取器，并引入一个可训练的投影层来适配这些富含几何信息的特征到策略解码器，从而增强模型的视角不变性。

Result: GeoAware-VLA在LIBERO基准测试子集上表现出显著的提升，在模拟环境中零样本泛化到新相机姿态的能力提高了2倍以上。在真实机器人上的实验也显示出性能的显著提高，尤其是在未见过的相机角度下进行评估时。

Conclusion: GeoAware-VLA的实验证明，将稳健的几何信息融入模型是构建更具泛化能力的机器人代理的关键组成部分，该方法在连续和离散动作空间中都有效。

Abstract: Vision-Language-Action (VLA) models often fail to generalize to novel camera
viewpoints, a limitation stemming from their difficulty in inferring robust 3D
geometry from 2D images. We introduce GeoAware-VLA, a simple yet effective
approach that enhances viewpoint invariance by integrating strong geometric
priors into the vision backbone. Instead of training a visual encoder or
relying on explicit 3D data, we leverage a frozen, pretrained geometric vision
model as a feature extractor. A trainable projection layer then adapts these
geometrically-rich features for the policy decoder, relieving it of the burden
of learning 3D consistency from scratch. Through extensive evaluations on
LIBERO benchmark subsets, we show GeoAware-VLA achieves substantial
improvements in zero-shot generalization to novel camera poses, boosting
success rates by over 2x in simulation. Crucially, these benefits translate to
the physical world; our model shows a significant performance gain on a real
robot, especially when evaluated from unseen camera angles. Our approach proves
effective across both continuous and discrete action spaces, highlighting that
robust geometric grounding is a key component for creating more generalizable
robotic agents.

</details>


### [213] [SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14138)
*Ran Yang,Zijian An,Lifeng ZHou,Yiming Feng*

Main category: cs.RO

TL;DR: SeqVLA是一个改进的Vision-Language-Action（VLA）模型，通过增加一个检测头来感知子任务完成情况，从而解决了长时序机器人操作中子任务依赖和错误传播的问题。实验表明，SeqVLA在多阶段任务中显著优于基线模型，特别是联合微调和不冻结骨干网的策略效果最佳。


<details>
  <summary>Details</summary>
Motivation: 长时序机器人操作需要按顺序执行多个相互依赖的子任务，而现有VLA模型在检测子任务完成方面存在不足，容易导致错误累积。SeqVLA旨在解决这一问题。

Method: SeqVLA在现有VLA模型（如π₀）的基础上增加了一个轻量级的检测头，使其能够感知当前子任务是否完成，从而自主触发子任务之间的转换。研究了四种不同的微调策略（联合微调 vs. 顺序微调；冻结骨干网 vs. 不冻结骨干网）。

Result: 在沙拉打包和糖果打包两个多阶段任务的实验中，SeqVLA的整体成功率显著高于基线模型π₀和其他强力基线。联合微调且不冻结骨干网的策略在完成预测方面最为可靠，消除了与序列相关的失败，实现了鲁棒的长时序执行。

Conclusion: 将动作生成与感知子任务完成情况的检测相结合，对于实现可扩展的序列化操作至关重要。

Abstract: Long-horizon robotic manipulation tasks require executing multiple
interdependent subtasks in strict sequence, where errors in detecting subtask
completion can cascade into downstream failures. Existing
Vision-Language-Action (VLA) models such as $\pi_0$ excel at continuous
low-level control but lack an internal signal for identifying when a subtask
has finished, making them brittle in sequential settings. We propose SeqVLA, a
completion-aware extension of $\pi_0$ that augments the base architecture with
a lightweight detection head perceiving whether the current subtask is
complete. This dual-head design enables SeqVLA not only to generate
manipulation actions but also to autonomously trigger transitions between
subtasks. We investigate four finetuning strategies that vary in how the action
and detection heads are optimized (joint vs. sequential finetuning) and how
pretrained knowledge is preserved (full finetuning vs. frozen backbone).
Experiments are performed on two multi-stage tasks: salad packing with seven
distinct subtasks and candy packing with four distinct subtasks. Results show
that SeqVLA significantly outperforms the baseline $\pi_0$ and other strong
baselines in overall success rate. In particular, joint finetuning with an
unfrozen backbone yields the most decisive and statistically reliable
completion predictions, eliminating sequence-related failures and enabling
robust long-horizon execution. Our results highlight the importance of coupling
action generation with subtask-aware detection for scalable sequential
manipulation.

</details>


### [214] [CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping](https://arxiv.org/abs/2509.14143)
*Zijian An,Ran Yang,Yiming Feng,Lifeng Zhou*

Main category: cs.RO

TL;DR: CLAW是一个框架，可以为机器人提供精确的重量控制能力，克服了现有VLA模型的局限性，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在执行需要精确数值约束（如基于数字阈值停止）的任务时存在困难，因为它们的观察到动作映射是隐式形成的，缺乏显式的条件监控机制。

Method: CLAW框架将条件评估与动作生成分离。它使用一个微调后的CLIP模型作为轻量级提示生成器，持续监控电子秤的读数，并根据特定任务的重量阈值生成离散指令。然后，一个基于流的VLA策略（$\	ext{\\\pi_0}$) 接收这些提示，并将其与多视角相机观测结合，生成连续的机器人动作。

Result: CLAW在三个实验设置中得到了验证：单物体抓取和需要双臂操作的混合物体任务。在所有条件下，CLAW都能可靠地执行称重感知行为，并且优于原始\	ext{\\\pi_0}和微调后的\	ext{\\\pi_0}模型。

Conclusion: CLAW框架能够有效地结合符号重量推理和高频视觉运动控制，实现了机器人对重量的精确感知和控制。

Abstract: Vision-language-action (VLA) models have recently emerged as a promising
paradigm for robotic control, enabling end-to-end policies that ground natural
language instructions into visuomotor actions. However, current VLAs often
struggle to satisfy precise task constraints, such as stopping based on numeric
thresholds, since their observation-to-action mappings are implicitly shaped by
training data and lack explicit mechanisms for condition monitoring. In this
work, we propose CLAW (CLIP-Language-Action for Weight), a framework that
decouples condition evaluation from action generation. CLAW leverages a
fine-tuned CLIP model as a lightweight prompt generator, which continuously
monitors the digital readout of a scale and produces discrete directives based
on task-specific weight thresholds. These prompts are then consumed by $\pi_0$,
a flow-based VLA policy, which integrates the prompts with multi-view camera
observations to produce continuous robot actions. This design enables CLAW to
combine symbolic weight reasoning with high-frequency visuomotor control. We
validate CLAW on three experimental setups: single-object grasping and
mixed-object tasks requiring dual-arm manipulation. Across all conditions, CLAW
reliably executes weight-aware behaviors and outperforms both raw-$\pi_0$ and
fine-tuned $\pi_0$ models. We have uploaded the videos as supplementary
materials.

</details>


### [215] [StableTracker: Learning to Stably Track Target via Differentiable Simulation](https://arxiv.org/abs/2509.14147)
*Fanxing Li,Shengyang Wang,Fangyu Sun,Shuyu Wu,Dexin Zuo,Wenxian Yu,Danping Zou*

Main category: cs.RO

TL;DR: StableTracker是一个基于学习的无人机目标跟踪策略，使用可微分模拟和BPTT进行训练，可在各种条件下实现鲁棒、精确的跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统FPV目标跟踪方法依赖于手工设计的模块，会导致硬件过载和累积误差，严重影响跟踪性能，尤其是在处理快速加速或减速目标时。

Method: 提出了一种名为StableTracker的基于学习的控制策略，利用反向传播通过时间（BPTT）和可微分模拟进行训练，使无人机能够从任意视角鲁棒地跟踪移动目标，使其保持在视野中心，并保持固定的相对距离。

Result: 与最先进的传统算法和学习基线相比，StableTracker在精度、稳定性和泛化能力方面表现更优，能够适应不同的安全距离、轨迹和目标速度。在真实世界的无人机实验中也验证了该方法的实用性。

Conclusion: StableTracker通过学习方法解决了传统FPV目标跟踪的挑战，实现了在各种条件下的鲁棒、精确和实用的目标跟踪。

Abstract: FPV object tracking methods heavily rely on handcraft modular designs,
resulting in hardware overload and cumulative error, which seriously degrades
the tracking performance, especially for rapidly accelerating or decelerating
targets. To address these challenges, we present \textbf{StableTracker}, a
learning-based control policy that enables quadrotors to robustly follow the
moving target from arbitrary perspectives. The policy is trained using
backpropagation-through-time via differentiable simulation, allowing the
quadrotor to maintain the target at the center of the visual field in both
horizontal and vertical directions, while keeping a fixed relative distance,
thereby functioning as an autonomous aerial camera. We compare StableTracker
against both state-of-the-art traditional algorithms and learning baselines.
Simulation experiments demonstrate that our policy achieves superior accuracy,
stability and generalization across varying safe distances, trajectories, and
target velocities. Furthermore, a real-world experiment on a quadrotor with an
onboard computer validated practicality of the proposed approach.

</details>


### [216] [MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies](https://arxiv.org/abs/2509.14159)
*Dayi Dong,Maulik Bhatt,Seoyeon Choi,Negar Mehr*

Main category: cs.RO

TL;DR: MIMIC-D是一种用于多模态多智能体模仿学习的CTDE范式，它利用扩散模型在训练时集中化并执行时去中心化，从而实现了智能体间的隐式协调。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入社会，其在多模态任务中与人类和其他机器人协调的能力至关重要。然而，标准模仿学习方法在处理多模态专家演示时存在困难，阻碍了有效的协调。

Method: 提出了一种名为MIMIC-D的集中式训练、去中心化执行（CTDE）范式，该范式利用扩散策略进行多模态多智能体模仿学习。智能体在训练时进行联合学习，拥有全部信息，但在执行策略时仅使用局部信息，从而实现隐式协调。

Result: 在仿真和硬件实验中，MIMIC-D在多种任务和环境中成功恢复了智能体间的多模态协调行为，并且优于最先进的基线方法。

Conclusion: MIMIC-D能够有效地处理多模态多智能体协调问题，即使在缺乏显式通信的情况下也能实现隐式协调。

Abstract: As robots become more integrated in society, their ability to coordinate with
other robots and humans on multi-modal tasks (those with multiple valid
solutions) is crucial. We propose to learn such behaviors from expert
demonstrations via imitation learning (IL). However, when expert demonstrations
are multi-modal, standard IL approaches can struggle to capture the diverse
strategies, hindering effective coordination. Diffusion models are known to be
effective at handling complex multi-modal trajectory distributions in
single-agent systems. Diffusion models have also excelled in multi-agent
scenarios where multi-modality is more common and crucial to learning
coordinated behaviors. Typically, diffusion-based approaches require a
centralized planner or explicit communication among agents, but this assumption
can fail in real-world scenarios where robots must operate independently or
with agents like humans that they cannot directly communicate with. Therefore,
we propose MIMIC-D, a Centralized Training, Decentralized Execution (CTDE)
paradigm for multi-modal multi-agent imitation learning using diffusion
policies. Agents are trained jointly with full information, but execute
policies using only local information to achieve implicit coordination. We
demonstrate in both simulation and hardware experiments that our method
recovers multi-modal coordination behavior among agents in a variety of tasks
and environments, while improving upon state-of-the-art baselines.

</details>


### [217] [\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video](https://arxiv.org/abs/2509.14178)
*Kai Ye,Yuhang Wu,Shuyuan Hu,Junliang Li,Meng Liu,Yongquan Chen,Rui Huang*

Main category: cs.RO

TL;DR: 使用生成的视频进行机器人抓取任务的训练，实现了77.3%的成功率，并能在真实机器人上执行。


<details>
  <summary>Details</summary>
Motivation: 收集大量机器人操作演示数据成本高昂，因此提出一种新的方法来解决这个问题。

Method: 提出了一种名为\textsc{Gen2Real}的方法，该方法包括三个主要部分：1.演示生成：利用视频生成技术，结合姿态和深度估计，生成手部-物体轨迹。2.轨迹优化：使用物理感知交互优化模型（PIOM）来保证物理一致性。3.演示学习：将人类动作迁移到机器人手部，并使用基于锚点的残差近端策略优化（PPO）策略来稳定控制。

Result: 在模拟环境中抓取任务的成功率为77.3%，并在真实机器人上实现了连贯的执行。此外，还进行了消融研究以验证每个组件的贡献，并展示了使用自然语言直接指定任务的能力。

Conclusion: \textsc{Gen2Real}能够灵活且鲁棒地将想象中的视频抓取技能泛化到现实世界的执行中。

Abstract: Dexterous manipulation remains a challenging robotics problem, largely due to
the difficulty of collecting extensive human demonstrations for learning. In
this paper, we introduce \textsc{Gen2Real}, which replaces costly human demos
with one generated video and drives robot skill from it: it combines
demonstration generation that leverages video generation with pose and depth
estimation to yield hand-object trajectories, trajectory optimization that uses
Physics-aware Interaction Optimization Model (PIOM) to impose physics
consistency, and demonstration learning that retargets human motions to a robot
hand and stabilizes control with an anchor-based residual Proximal Policy
Optimization (PPO) policy. Using only generated videos, the learned policy
achieves a 77.3\% success rate on grasping tasks in simulation and demonstrates
coherent executions on a real robot. We also conduct ablation studies to
validate the contribution of each component and demonstrate the ability to
directly specify tasks using natural language, highlighting the flexibility and
robustness of \textsc{Gen2Real} in generalizing grasping skills from imagined
videos to real-world execution.

</details>


### [218] [MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping](https://arxiv.org/abs/2509.14191)
*Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald*

Main category: cs.RO

TL;DR: MCGS-SLAM 是首个纯粹基于 RGB 的多摄像头 SLAM 系统，利用 3D 高斯泼溅技术，实现了实时、高保真度的建图。


<details>
  <summary>Details</summary>
Motivation: 为了克服单目 SLAM 在鲁棒性和几何覆盖范围方面的局限性，我们提出了 MCGS-SLAM。

Method: MCGS-SLAM 融合了来自多个视角的密集 RGB 输入，构建并持续优化高斯地图。系统采用多摄像头束调整（MCBA）来联合优化姿态和深度，并通过低秩先验和尺度一致性模块来保证跨视图的度量对齐。

Result: 实验结果表明，MCGS-SLAM 在合成和真实世界数据集上均能提供准确的轨迹和逼真的重建，其性能通常优于单目基线方法。多摄像头输入提供的宽视场能够重建单目系统遗漏的侧视图区域。

Conclusion: MCGS-SLAM 证明了多摄像头高斯泼溅 SLAM 在机器人和自动驾驶领域实现高保真度建图的巨大潜力。

Abstract: Recent progress in dense SLAM has primarily targeted monocular setups, often
at the expense of robustness and geometric coverage. We present MCGS-SLAM, the
first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting
(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM
fuses dense RGB inputs from multiple viewpoints into a unified, continuously
optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines
poses and depths via dense photometric and geometric residuals, while a scale
consistency module enforces metric alignment across views using low-rank
priors. The system supports RGB input and maintains real-time performance at
large scale. Experiments on synthetic and real-world datasets show that
MCGS-SLAM consistently yields accurate trajectories and photorealistic
reconstructions, usually outperforming monocular baselines. Notably, the wide
field of view from multi-camera input enables reconstruction of side-view
regions that monocular setups miss, critical for safe autonomous operation.
These results highlight the promise of multi-camera Gaussian Splatting SLAM for
high-fidelity mapping in robotics and autonomous driving.

</details>


### [219] [GLIDE: A Coordinated Aerial-Ground Framework for Search and Rescue in Unknown Environments](https://arxiv.org/abs/2509.14210)
*Seth Farrell,Chenghao Li,Hongzhan Yu,Hesam Mojtahedi,Sicun Gao,Henrik I. Christensen*

Main category: cs.RO

TL;DR: GLIDE框架通过结合无人机和无人地面车辆，提高了搜索和救援任务的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在未知的环境中，需要一种能够实现快速受害者定位和避障的搜索和救援（SAR）框架。

Method: 提出了一种名为Guided Long-horizon Integrated Drone Escort (GLIDE)的协同空地搜索和救援框架。该框架由两架无人机（UAV）和一架无人地面车辆（UGV）组成。一架无人机负责实时进行受害者检测和地理参考，为地面平台指定目标；另一架无人机则在UGV预定路线前方进行侦察，提供地形可通行性更新。UGV融合了来自无人机的线索和本地传感信息，进行高效的A*规划和持续的重新规划。

Result: 通过硬件演示（使用GEM e6高尔夫球车作为UGV和两架X500无人机）和仿真实验，评估了端到端的SAR任务性能。结果表明，无人机明确的角色分离、地形侦察和引导式规划，能够缩短到达时间并提高时间关键型SAR任务的导航安全性。

Conclusion: GLIDE框架通过明确的角色分工和有效的协同规划，显著提高了空中地面协同搜索和救援的效率和安全性。

Abstract: We present a cooperative aerial-ground search-and-rescue (SAR) framework that
pairs two unmanned aerial vehicles (UAVs) with an unmanned ground vehicle (UGV)
to achieve rapid victim localization and obstacle-aware navigation in unknown
environments. We dub this framework Guided Long-horizon Integrated Drone Escort
(GLIDE), highlighting the UGV's reliance on UAV guidance for long-horizon
planning. In our framework, a goal-searching UAV executes real-time onboard
victim detection and georeferencing to nominate goals for the ground platform,
while a terrain-scouting UAV flies ahead of the UGV's planned route to provide
mid-level traversability updates. The UGV fuses aerial cues with local sensing
to perform time-efficient A* planning and continuous replanning as information
arrives. Additionally, we present a hardware demonstration (using a GEM e6 golf
cart as the UGV and two X500 UAVs) to evaluate end-to-end SAR mission
performance and include simulation ablations to assess the planning stack in
isolation from detection. Empirical results demonstrate that explicit role
separation across UAVs, coupled with terrain scouting and guided planning,
improves reach time and navigation safety in time-critical SAR missions.

</details>


### [220] [Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models](https://arxiv.org/abs/2509.14228)
*Benjamin Shaffer,Victoria Edwards,Brooks Kinch,Nathaniel Trask,M. Ani Hsieh*

Main category: cs.RO

TL;DR: 本篇论文提出了一种分布式移动传感框架，利用每个机器人携带的机器学习有限元模型来指导信息采样，以在复杂流体环境中实现源定位。


<details>
  <summary>Details</summary>
Motivation: 在具有时变和混沌流动的复杂环境中，多机器人团队在定位化学泄漏源或追踪溢油扩散时面临挑战，因为传感数据间歇且环境几何形状复杂，限制了对流体扩散的建模和预测能力。机器人需要计算密集型的数值模型，这在板载计算能力有限的情况下难以实现。

Method: 提出了一种分布式移动传感框架，其中每个机器人携带一个机器学习的有限元模型来表示其环境，以指导信息采样。利用这些模型评估近似互信息标准，以驱动信息素控制策略，选择能最大化源定位目标信息量的传感区域。

Result: 与基线传感策略相比，该方法实现了更快的误差减少；与基线机器学习方法相比，实现了更准确的源定位。

Conclusion: 所提出的分布式移动传感框架能够通过利用机器学习模型和信息素控制策略，有效地提高多机器人系统在复杂流体环境中的源定位精度和效率。

Abstract: Source localization in a complex flow poses a significant challenge for
multi-robot teams tasked with localizing the source of chemical leaks or
tracking the dispersion of an oil spill. The flow dynamics can be time-varying
and chaotic, resulting in sporadic and intermittent sensor readings, and
complex environmental geometries further complicate a team's ability to model
and predict the dispersion. To accurately account for the physical processes
that drive the dispersion dynamics, robots must have access to computationally
intensive numerical models, which can be difficult when onboard computation is
limited. We present a distributed mobile sensing framework for source
localization in which each robot carries a machine-learned, finite element
model of its environment to guide information-based sampling. The models are
used to evaluate an approximate mutual information criterion to drive an
infotaxis control strategy, which selects sensing regions that are expected to
maximize informativeness for the source localization objective. Our approach
achieves faster error reduction compared to baseline sensing strategies and
results in more accurate source localization compared to baseline machine
learning approaches.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [221] [Oscillator Formulations of Many NP Problems](https://arxiv.org/abs/2509.13560)
*Wenxiao Cai,Zongru Li,Yu-Neng Wang,Sara Achour,Thomas H. Lee*

Main category: cs.ET

TL;DR: CMOS振荡器网络可用于近似NP难题，本文提出了一个3状态非对称加权振荡器优化器设计来优化NP问题。


<details>
  <summary>Details</summary>
Motivation: NP问题的有效优化在许多领域具有深远影响，CMOS振荡器网络已被证明在近似某些NP难题方面有效且高效。

Method: 本文使用一阶和多相Potts Hamiltonian来构建各种NP问题，并提出了一种3状态非对称加权振荡器优化器设计。

Result: 本文提出的算法基于现有的CMOS设计知识，为大规模NP问题优化提供了有前景的途径。

Conclusion: CMOS振荡器网络是一种有前途的NP问题优化方法，本文提出的优化器设计进一步增强了其能力。

Abstract: Efficiently optimizing Nondeterministic Polynomial time (NP) problems in
polynomial time has profound implications in many domains. CMOS oscillator
networks have been shown to be effective and efficient in approximating certain
NP-hard problems such as minimization of Potts Hamiltonian, and computational
complexity theory guarantees that any NP problem can be reduced to it. In this
paper, we formulate a variety of NP problems using first-order and multi-phase
Potts Hamiltonian. We also propose a 3-state asymmetrically weighted oscillator
optimizer design to optimize the problems. Building on existing knowledge in
CMOS design, our proposed algorithms offer a promising pathway for large-scale
optimization of NP problems.

</details>


### [222] [Analytical Modelling of the Transport in Analog Filamentary Conductive-Metal-Oxide/HfOx ReRAM Devices](https://arxiv.org/abs/2509.13964)
*Donato Francesco Falcone,Stephan Menzel,Tommaso Stecconi,Matteo Galetta,Antonio La Porta,Bert Jan Offrein,Valeria Bragaglia*

Main category: cs.ET

TL;DR: 本篇论文提出了首个基于物理的解析模型，用于理解和模拟忆阻器（ReRAM）的电流传输和阻变机制，特别关注了 TaOx/HfOx 器件。该模型通过陷阱到陷阱的隧穿过程解释电流传输，通过 TaOx 层缺陷密度调制解释阻变行为，并考虑了局部电场和温度分布的影响，能够准确描述实验数据，为集成该技术进行电路仿真提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 尽管忆阻器技术和训练算法的协同优化使得内存计算系统能够进行神经网络训练，并且模拟的丝状导电氧化物（CMO）/ HfOx 氧化还原基电阻开关存储器（ReRAM）是其中的关键技术，但其阻变机制仍未被完全理解。因此，有必要提出一个基于物理的解析模型来深入理解该器件的工作原理。

Method: 本文提出了首个基于物理的解析模型，用于分析 TaOx/HfOx ReRAM 器件的电流传输和阻变机制。该模型基于陷阱到陷阱的隧穿过程来解释电流传输，并通过改变 TaOx 层内缺陷密度来解释阻变行为，同时考虑了电场和温度在器件内的分布。通过求解三维有限元模型的电和热传输方程，可以推导出局域温度和电场分布。该模型能够分析离子漂移动力学，估算缺陷迁移能，并揭示 CMO 层电热性质的作用。

Result: 所提出的解析模型能够准确地描述模拟 TaOx/HfOx ReRAM 器件的实验开关特性。模型解释了电流传输机制（陷阱到陷阱隧穿）和阻变机制（TaOx 缺陷密度调制），并能描述中间电阻状态以及估算缺陷迁移能量。

Conclusion: 本研究提出的物理模型为理解 TaOx/HfOx ReRAM 器件的电流传输和阻变机制提供了新的见解，能够准确描述实验结果，并为将该技术集成到电路仿真中提供了必要的理论支持。

Abstract: The recent co-optimization of memristive technologies and programming
algorithms enabled neural networks training with in-memory computing systems.
In this context, novel analog filamentary conductive-metal-oxide (CMO)/HfOx
redox-based resistive switching memory (ReRAM) represents a key technology.
Despite device performance enhancements reported in literature, the underlying
mechanism behind resistive switching is not fully understood. This work
presents the first physics-based analytical model of the current transport and
of the resistive switching in these devices. As a case study, analog TaOx/HfOx
ReRAM devices are considered. The current transport is explained by a
trap-to-trap tunneling process, and the resistive switching by a modulation of
the defect density within the sub-band of the TaOx that behaves as electric
field and temperature confinement layer. The local temperature and electric
field distributions are derived from the solution of the electric and heat
transport equations in a 3D finite element ReRAM model. The intermediate
resistive states are described as a gradual modulation of the TaOx defect
density, which results in a variation of its electrical conductivity. The
drift-dynamics of ions during the resistive switching is analytically
described, allowing the estimation of defect migration energies in the TaOx
layer. Moreover, the role of the electro-thermal properties of the CMO layer is
unveiled. The proposed analytical model accurately describes the experimental
switching characteristic of analog TaOx/HfOx ReRAM devices, increasing the
physical understanding and providing the equations necessary for circuit
simulations incorporating this technology.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [223] [Multi-Threaded Software Model Checking via Parallel Trace Abstraction Refinement](https://arxiv.org/abs/2509.13699)
*Max Barth,Marie-Christine Jakobs*

Main category: cs.LO

TL;DR: 通过并行化跟踪抽象来加速软件模型检查。


<details>
  <summary>Details</summary>
Motivation: 自动软件验证（尤其是软件模型检查）耗时，限制了其在持续集成等场景中的应用。多核CPU为解决此问题提供了可能。

Method: 提出一种并行化跟踪抽象的方法，通过并行分析可能违反安全属性的不同跟踪（语法程序路径）。在Ulti mate Automizer工具中实现并进行了评估。

Result: 与顺序跟踪抽象相比，并行化效果更好，在许多耗时任务上能显著缩短响应时间。同时，优于最近的并行抽象方法DSS。

Conclusion: 所提出的并行化跟踪抽象方法能够有效加速软件模型检查，并优于现有方法。

Abstract: Automatic software verification is a valuable means for software quality
assurance. However, automatic verification and in particular software model
checking can be time-consuming, which hinders their practical applicability
e.g., the use in continuous integration. One solution to address the issue is
to reduce the response time of the verification procedure by leveraging today's
multi-core CPUs.
  In this paper, we propose a solution to parallelize trace abstraction, an
abstraction-based approach to software model checking. The underlying idea of
our approach is to parallelize the abstraction refinement. More concretely, our
approach analyzes different traces (syntactic program paths) that could violate
the safety property in parallel. We realize our parallelized version of trace
abstraction in the verification tool Ulti mate Automizer and perform a thorough
evaluation. Our evaluation shows that our parallelization is more effective
than sequential trace abstraction and can provide results significantly faster
on many time-consuming tasks. Also, our approach is more effective than DSS, a
recent parallel approach to abstraction-based software model checking.

</details>


### [224] [Algorithmic Perspective on Toda's Theorem](https://arxiv.org/abs/2509.13871)
*Dror Fried,Etay Segal,Gad E. Yaron*

Main category: cs.LO

TL;DR: Toda定理的还原被转化为一个具体的算法，用于解决QBF问题，并进行了理论和算法上的改进。


<details>
  <summary>Details</summary>
Motivation: 探究Toda定理的还原是否能用于高效解决QBF问题，并从算法角度进行分析。

Method: 将Toda定理的还原转化为一个具体的算法，并进行理论和算法上的改进。

Result: 提出了一个具体的算法，并进行了改进，展示了相对于朴素原型的重要进展，同时也揭示了将Toda还原转化为有竞争力的求解器的剩余挑战。

Conclusion: Toda定理的还原可以被转化为一个具体的算法，尽管仍有挑战，但已取得显著进展。

Abstract: Toda's Theorem is a fundamental result in computational complexity theory,
whose proof relies on a reduction from a QBF problem with a constant number of
quantifiers to a model counting problem. While this reduction, henceforth
called Toda's reduction, is of a purely theoretical nature, the recent progress
of model counting tools raises the question of whether the reduction can be
utilized to an efficient algorithm for solving QBF. In this work, we address
this question by looking at Toda's reduction from an algorithmic perspective.
We first convert the reduction into a concrete algorithm that given a QBF
formula and a probability measure, produces the correct result with a
confidence level corresponding to the given measure. Beyond obtaining a naive
prototype, our algorithm and the analysis that follows shed light on the fine
details of the reduction that are so far left elusive. Then, we improve this
prototype through various theoretical and algorithmic refinements. While our
results show a significant progress over the naive prototype, they also provide
a clearer understanding of the remaining challenges in turning Toda's reduction
into a competitive solver.

</details>


### [225] [The Complexity of Deciding Characteristic Formulae Modulo Nested Simulation (extended abstract)](https://arxiv.org/abs/2509.14089)
*Luca Aceto,Antonis Achilleos,Aggeliki Chalki,Anna Ingólfsdóttir*

Main category: cs.LO

TL;DR: 该论文研究了确定嵌套模拟语义的模态逻辑中的公式是否是特征公式的复杂性，这等价于确定公式是否可满足和是主要的。


<details>
  <summary>Details</summary>
Motivation: 研究确定嵌套模拟语义的模态逻辑中的公式是否是特征公式的复杂性。

Method: 研究模态逻辑的特征公式问题。

Result: 对于二重嵌套模拟前序关系，该问题是coNP-完全的；对于n>=3的n重嵌套模拟前序关系，该问题是PSPACE-完全的。因此，决定n>=3的n重嵌套模拟语义的特征公式是PSPACE-完全的。对于二重嵌套模拟语义，该问题属于DP类。

Conclusion: 确定n>=3的n重嵌套模拟语义的特征公式是PSPACE-完全的。对于二重嵌套模拟语义，该问题属于DP类。

Abstract: This paper studies the complexity of determining whether a formula in the
modal logics characterizing the nested-simulation semantics is characteristic
for some process, which is equivalent to determining whether the formula is
satisfiable and prime. The main results are that the problem of determining
whether a formula is prime in the modal logic characterizing the
2-nested-simulation preorder is coNP-complete and is PSPACE-complete in the
case of the n-nested-simulation preorder, when n>=3. This establishes that
deciding characteristic formulae for the n-nested simulation semantics is
PSPACE-complete, when n>=3. In the case of the 2-nested simulation semantics,
that problem lies in the complexity class DP, which consists of languages that
can be expressed as the intersection of one language in NP and of one in coNP.

</details>


### [226] [An Automaton-based Characterisation of First-Order Logic over Infinite Trees](https://arxiv.org/abs/2509.14090)
*Massimo Benerecetti,Dario Della Monica,Angelo Matteo,Fabio Mogavero,Gabriele Puppis*

Main category: cs.LO

TL;DR: 本文研究了不可数无限树上的第一阶逻辑 (FO) 及其与分支时间时序逻辑的关系。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为不可数无限树上的第一阶逻辑 (FO) 提供自动机理论的刻画，并揭示其与两种分支时间时序逻辑的关系。

Method: 本文介绍了两类犹豫树自动机，并证明它们分别精确地捕捉了两种分支时间时序逻辑（polcCTLp 和 cCTL*[f]）的表达能力。这两种逻辑分别是带历史的计数 CTL 的受限版本和有限路径上的计数 CTL*，它们都已被证明等价于不可数无限树上的 FO。

Result: 两种自动机刻画自然地导出了两种时序逻辑的范式，并强调了 FO 只能表达树分支中本质上是安全（safety）或共安全（co-safety）的性质这一事实。

Conclusion: 本文通过自动机理论刻画了不可数无限树上的第一阶逻辑 (FO)，并将其与分支时间时序逻辑 polcCTLp 和 cCTL*[f] 联系起来，证明了 FO 只能表达树分支中安全或共安全性质。

Abstract: In this paper, we study First Order Logic (FO) over (unordered) infinite
trees and its connection with branching-time temporal logics. More
specifically, we provide an automata-theoretic characterisation of FO
interpreted over infinite trees. To this end, two different classes of hesitant
tree automata are introduced and proved to capture precisely the expressive
power of two branching time temporal logics, denoted polcCTLp and cCTL*[f],
which are, respectively, a restricted version of counting CTL with past and
counting CTL* over finite paths, both of which have been previously shown
equivalent to FO over infinite trees. The two automata characterisations
naturally lead to normal forms for the two temporal logics, and highlight the
fact that FO can only express properties of the tree branches which are either
safety or co-safety in nature.

</details>


### [227] [Metric Equational Theories](https://arxiv.org/abs/2509.14094)
*Radu Mardare,Neil Ghani,Eigil Rischel*

Main category: cs.LO

TL;DR: 本论文将定量方程理论（QET）与富集Lawvere理论相结合，为度量空间上的代数结构提出合适且完备的证明系统。


<details>
  <summary>Details</summary>
Motivation: 将QET与富集Lawvere理论相结合，为度量空间上的代数结构提供合适的证明系统。

Method: 将QET扩展到度量方程理论（MET），其中操作的元数从可数度量空间中抽取，并据此调整QET的证明系统。

Result: 提出了适用于MET的健全且完备的证明系统。

Conclusion: 通过将QET与富集Lawvere理论相结合，并进行相应扩展，为度量空间上的代数结构开发了新的证明系统。

Abstract: This paper proposes appropriate sound and complete proof systems for
algebraic structures over metric spaces by combining the development of
Quantitative Equational Theories (QET) with the Enriched Lawvere Theories. We
extend QETs to Metric Equational Theories (METs) where operations no longer
have finite sets as arities (as in QETs and the general theory of universal
algebras), but arities are now drawn from countable metric spaces. This
extension is inspired by the theory of Enriched Lawvere Theories, which
suggests that the arities of operations should be the lambda-presentable
objects of the underlying lambda-accessible category. In this setting, the
validity of terms in METs can no longer be guaranteed independently of the
validity of equations, as is the case with QET. We solve this problem, and
adapt the sound and complete proof system for QETs to these more general METs,
taking advantage of the specific structure of metric spaces.

</details>


### [228] [The Complexity of Generalized HyperLTL with Stuttering and Contexts](https://arxiv.org/abs/2509.14095)
*Gaëtan Regaud,Martin Zimmermann*

Main category: cs.LO

TL;DR: Generalized HyperLTL with stuttering and contexts is $\Sigma_1^1$-complete for satisfiability and harder for model-checking than HyperLTL.


<details>
  <summary>Details</summary>
Motivation: To settle the complexity of satisfiability and model-checking for generalized HyperLTL with stuttering and contexts, which is an expressive logic for specifying asynchronous hyperproperties, unlike the restricted HyperLTL that only handles synchronous hyperproperties.

Method: Proving $\Sigma_1^1$-completeness for satisfiability and establishing an equivalence to truth in second-order arithmetic for model-checking. The lower bounds for model-checking are shown to hold even with only stuttering or only contexts.

Result: Satisfiability is $\Sigma_1^1$-complete, and model-checking is equivalent to truth in second-order arithmetic, which is significantly harder than HyperLTL model-checking. Lower bounds for model-checking are established even when considering only stuttering or only contexts.

Conclusion: The satisfiability of generalized HyperLTL with stuttering and contexts is not harder than for HyperLTL, while its model-checking problem is significantly more complex.

Abstract: We settle the complexity of satisfiability and model-checking for generalized
HyperLTL with stuttering and contexts, an expressive logic for the
specification of asynchronous hyperproperties. Such properties cannot be
specified in HyperLTL, as it is restricted to synchronous hyperproperties.
Nevertheless, we prove that satisfiability is $\Sigma_1^1$-complete and thus
not harder than for HyperLTL. On the other hand, we prove that model-checking
is equivalent to truth in second-order arithmetic, and thus much harder than
the decidable HyperLTL model-checking problem. The lower bounds for the
model-checking problem hold even when only allowing stuttering or only allowing
contexts.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [229] [Dual Actor DDPG for Airborne STAR-RIS Assisted Communications](https://arxiv.org/abs/2509.13328)
*Danish Rizvi,David Boyle*

Main category: eess.SP

TL;DR: 本研究提出了一种新的无人机（UAV）挂载的智能反射面（STAR-RIS）系统（Aerial-STAR），采用耦合的传输和反射系数（TRC）相位模型，以提高多用户下行通信效率。该系统联合优化无人机轨迹、基站波束赋形和RIS TRC，同时考虑无人机的能源限制。研究结果表明，所提出的双Actor深度确定性策略梯度（DA-DDPG）算法显著优于传统方法，并且三维轨迹优化和耦合相位模型能够进一步提升通信效率和用户公平性。


<details>
  <summary>Details</summary>
Motivation: 现有研究普遍假设STAR-RIS中的传输和反射系数是独立的，本研究旨在打破这一假设，探索在UAV挂载的STAR-RIS系统中，考虑耦合TRC相位模型下，联合优化UAV轨迹、基站波束赋形和RIS TRC以提升通信效率和用户公平性。

Method: 提出了一种新颖的双Actor深度确定性策略梯度（DA-DDPG）算法，该算法使用两个独立的Actor网络来处理高维混合动作空间（离散和连续动作）。同时，设计了一种基于谐波均值指数（HFI）的奖励函数来确保用户之间的通信公平性。研究还分析了RIS尺寸对UAV空气动力学的影响。

Result: 所提出的DA-DDPG算法在累积奖励方面比传统的DDPG和DQN算法分别提高了24%和97%。三维UAV轨迹优化比二维和高度优化提高了28%的通信效率。基于HFI的奖励函数将服务质量（QoS）拒绝率降低了41%。移动Aerial-STAR系统性能优于固定部署系统，并且耦合相位STAR-RIS优于双传输/反射RIS和传统RIS。RIS尺寸的增加会增加无人机的阻力和能耗。

Conclusion: 本研究验证了Aerial-STAR系统的巨大潜力，并证明了所提出的DA-DDPG方法在优化此类系统性能方面的有效性。耦合TRC相位模型、三维轨迹优化和HFI奖励函数对于提升系统性能和用户公平性至关重要。

Abstract: This study departs from the prevailing assumption of independent Transmission
and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect
Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a
novel multi-user downlink communication system that leverages a UAV-mounted
STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key
contributions include the joint optimization of UAV trajectory, active
beamforming vectors at the base station, and passive RIS TRCs to enhance
communication efficiency, while considering UAV energy constraints. We design
the TRC as a combination of discrete and continuous actions, and propose a
novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The
algorithm relies on two separate actor networks for high-dimensional hybrid
action space. We also propose a novel harmonic mean index (HFI)-based reward
function to ensure communication fairness amongst users. For comprehensive
analysis, we study the impact of RIS size on UAV aerodynamics showing that it
increases drag and energy demand. Simulation results demonstrate that the
proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based
solutions by 24% and 97%, respectively, in accumulated reward.
Three-dimensional UAV trajectory optimization achieves 28% higher communication
efficiency compared to two-dimensional and altitude optimization. The HFI based
reward function provides 41% lower QoS denial rates as compared to other
benchmarks. The mobile Aerial-STAR system shows superior performance over fixed
deployed counterparts, with the coupled phase STAR-RIS outperforming dual
Transmit/Reflect RIS and conventional RIS setups. These findings highlight the
potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG
approach in optimizing their performance.

</details>


### [230] [Environment Reconstruction in Multi-Bounce Channels with Array Partial Blockage](https://arxiv.org/abs/2509.13559)
*Yuan Liu,Linlong Wu,Xuesong Cai,M. R. Bhavani Shankar*

Main category: eess.SP

TL;DR: 该论文研究了在存在空间非平稳（SNS）信道（由ELAA的部分阻塞引起）的情况下，如何进行散射体定位和环境重构。SNS信道被建模为具有空间变化的幅度和稀疏性。


<details>
  <summary>Details</summary>
Motivation: 为了解决极大规模天线阵列（ELAA）在部分阻塞导致空间非平稳（SNS）信道下的散射体定位和环境重构问题。

Method: 提出了一种基于图的字典辅助多跳空间交替广义期望最大化（GM-SAGE）算法来估计信道参数，并通过经验检测信道稀疏性和幅度。

Result: 通过射线追踪（RT）仿真生成多跳路径，并配置SNS信道，仿真结果验证了所提出方法在处理SNS信道方面的鲁棒性。

Conclusion: 所提出的GM-SAGE算法能够有效地处理由部分阻塞引起的SNS信道，并实现对散射体的准确定位和环境的重构。

Abstract: Extremely-large antenna arrays (ELAA) are important in applications requiring
high angular resolution. However, a prominent issue is the spatial
non-stationary (SNS) channels due to partial blockage to the ELAA. In this
paper, we address the scatterer localization and subsequent environment
reconstruction considering partially blocked SNS channels. Specifically, the
SNS effects are parametrically modeled through spatial-varying amplitudes with
sparsity. Based on the established signal model, the graph-based
dictionary-aided multi-bounce space-alternating generalized
expectation-maximization (GM-SAGE) algorithm is applied to estimate the channel
parameters and the channel sparsity is empirically detected along with
amplitude estimation. To validate the proposed approach, we generate
multi-bounce paths through ray tracing (RT) simulations, where the SNS channels
caused by partial blockage could be configured flexibly. The simulation results
demonstrate the robustness of the proposed approach in dealing with the SNS
channels.

</details>


### [231] [Fast Single-Snapshot Harmonic Recovery with 2D Sparse Arrays using BCCB Matrices](https://arxiv.org/abs/2509.13592)
*Youval Klioui*

Main category: eess.SP

TL;DR: 该论文提出了一种在二维稀疏阵列上使用单快照进行谐波估计的稀疏恢复方法的有效实现方式。


<details>
  <summary>Details</summary>
Motivation: 通过对稀疏恢复问题中使用的子词典的谐波网格施加均匀性约束，以及对阵列拓扑施加温和约束（要求单元位于半波长单位指定的网格上），来解决谐波估计问题。

Method: 利用Gram矩阵的块循环带循环块（BCCB）结构，通过使用二维快速傅里叶变换（FFT）将每次迭代的计算复杂度从O((L1L2)^2)降低到O(L1L2 log(L1L2))。

Result: 通过迭代收缩阈值算法（ISTA）、快速迭代收缩阈值算法（FISTA）和交替方向乘子法（ADMM）的实验验证，观察到计算效率的提升。

Conclusion: 提出的基于BCCB结构的FFT加速方法能够显著降低二维稀疏阵列上单快照谐波估计的计算复杂度。

Abstract: We introduce an efficient implementation of sparse recovery methods for the
problem of harmonic estimation with 2D sparse arrays using a single snapshot.
By imposing a uniformity constraint on the harmonic grids of the
subdictionaries used in the sparse recovery problem, in addition to a mild
constraint on the array topology that consists in having the elements lie on a
grid specified in half-wavelength units, we show that the Gram matrices that
appear in these sparse recovery methods exhibit a block-circulant with
circulant blocks (BCCB) structure. The BCCB structure is then exploited to
reduce the computational complexity of the matrix-vector products that appear
in these methods through the use of 2D fast Fourier transforms (FFT) from
O((L1L2)^2) down to O(L1L2 log(L1L2)) operations per iterations, where L1, L2
are the lengths of the subdictionaries used for estimating the harmonics in the
first and second dimension, respectively. We experimentally verify the proposed
implementation using the iterative shrinkage thresholding algorithm (ISTA), the
fast iterative shrinkage-thresholding algorithm (FISTA), and the alternating
direction method of multipliers (ADMM) where we observe improvements

</details>


### [232] [GNSS Jamming and Spoofing Monitoring Using Low-Cost COTS Receivers](https://arxiv.org/abs/2509.13600)
*Argyris Kriezis,Yu-Hsuan Chen,Dennis Akos,Sherman Lo,Todd Walter*

Main category: eess.SP

TL;DR: GNSS信号易受干扰，本文提出一种基于低成本GNSS接收机的RFI检测和分类方法，通过结合C/N0测量和接收功率，构建二维检测空间，可有效区分正常、干扰、欺骗和阻塞信号，并在实际部署中得到验证。


<details>
  <summary>Details</summary>
Motivation: GNSS信号日益受到射频干扰（RFI）的威胁，威胁导航和授时服务的完整性。

Method: 结合载噪比（C/N0）测量和校准的接收功率指标，构建二维检测空间，以识别和区分标称、干扰、欺骗和阻塞信号条件。

Result: 基于COTS的检测在适当校准后，为GNSS RFI监测提供了一种可行有效的方法。

Conclusion: 所提出的基于COTS接收机的RFI检测和分类方法，在实际部署中被证明是有效可行的。

Abstract: The Global Navigation Satellite System (GNSS) is increasingly vulnerable to
radio frequency interference (RFI), including jamming and spoofing, which
threaten the integrity of navigation and timing services. This paper presents a
methodology for detecting and classifying RFI events using low-cost commercial
off-the-shelf (COTS) GNSS receivers. By combining carrier-to-noise ratio (C/N0)
measurements with a calibrated received power metric, a two-dimensional
detection space is constructed to identify and distinguish nominal, jammed,
spoofed, and blocked signal conditions. The method is validated through both
controlled jamming tests in Norway and real-world deployments in Poland, and
the Southeast Mediterranean which have experienced such conditions. Results
demonstrate that COTS-based detection, when properly calibrated, offers a
viable and effective approach for GNSS RFI monitoring.

</details>


### [233] [Theoretical Validation of the Latent Optimally Partitioned-$\ell_2/\ell_1$ Penalty with Application to Angular Power Spectrum Estimation](https://arxiv.org/abs/2509.13745)
*Hiroki Kuroda,Renato Luis Garrido Cavalcante,Masahiro Yukawa*

Main category: eess.SP

TL;DR: LOP-ell2/ell1惩罚在不知道具体块结构的情况下，在理论和实践中都能有效地利用块稀疏性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是利用块稀疏性来提高MIMO通信系统中角功率谱估计的准确性，而事先不知道块结构。

Method: 提出了一种新的理论结果，表明LOP-ell2/ell1惩罚中的优化块划分满足精确恢复块稀疏信号的条件。基于此，将LOP-ell2/ell1惩罚应用于MIMO通信系统中具有未知块划分的角功率谱估计。

Result: 数值模拟表明，使用LOP-ell2/ell1惩罚的块稀疏性显著提高了角功率谱估计的准确性。

Conclusion: LOP-ell2/ell1惩罚是一种有效的方法，可以在不知道具体块结构的情况下，利用块稀疏性来改进信号估计，特别是在MIMO通信系统的角功率谱估计方面。

Abstract: This paper demonstrates that, in both theory and practice, the latent
optimally partitioned (LOP)-$\ell_2/\ell_1$ penalty is effective for exploiting
block-sparsity without the knowledge of the concrete block structure. More
precisely, we first present a novel theoretical result showing that the
optimized block partition in the LOP-$\ell_2/\ell_1$ penalty satisfy a
condition required for accurate recovery of block-sparse signals. Motivated by
this result, we present a new application of the LOP-$\ell_2/\ell_1$ penalty to
estimation of angular power spectrum, which is block-sparse with unknown block
partition, in MIMO communication systems. Numerical simulations show that the
proposed use of block-sparsity with the LOP-$\ell_2/\ell_1$ penalty
significantly improves the estimation accuracy of the angular power spectrum.

</details>


### [234] [Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization](https://arxiv.org/abs/2509.13786)
*SaiKrishna Saketh Yellapragada,Esa Ollila,Mario Costa*

Main category: eess.SP

TL;DR: 深度学习（DL）神经网络接收器在6G无线通信中具有潜力，但资源受限的硬件需要进行量化以提高效率。本研究将量化感知训练（QAT）应用于神经网络接收器，并在3GPP CDL-B/D信道中进行评估。结果表明，4位和8位QAT模型在块错误率（BLER）方面与FP32模型相当，且性能优于后训练量化（PTQ）模型，并实现了8倍压缩。


<details>
  <summary>Details</summary>
Motivation: 在6G无线通信系统中，为了在资源受限的硬件上实现低延迟、低功耗和低内存占用的深度学习（DL）神经网络接收器，需要进行高效的量化，同时保证可靠性。因此，本研究旨在探索量化感知训练（QAT）方法，以提高量化神经网络接收器的性能。

Method: 本研究将量化感知训练（QAT）应用于神经网络接收器架构，并与后训练量化（PTQ）方法进行比较。在3GPP Clustered Delay Line (CDL)-B/D信道（包括视距（LoS）和非视距（NLoS）环境）以及高达40 m/s的用户速度下，对不同量化比特宽度（如4位和8位）的模型进行了评估。

Result: 与FP32模型相比，4位和8位QAT模型在10%的目标块错误率（BLER）下实现了相似的BLER性能。QAT模型比PTQ模型性能高出3 dB，并实现了8倍的压缩率。

Conclusion: 量化感知训练（QAT）是实现物理层（PHY）低复杂度、低延迟推理的关键技术，能够促进6G边缘设备的实时处理。

Abstract: As wireless communication systems advance toward Sixth Generation (6G) Radio
Access Networks (RAN), Deep Learning (DL)-based neural receivers are emerging
as transformative solutions for Physical Layer (PHY) processing, delivering
superior Block Error Rate (BLER) performance compared to traditional
model-based approaches. Practical deployment on resource-constrained hardware,
however, requires efficient quantization to reduce latency, energy, and memory
without sacrificing reliability. We extend Post-Training Quantization (PTQ)
baselines with Quantization-Aware Training (QAT), which incorporates
low-precision simulation during training for robustness at ultra-low bitwidths.
Our study applies QAT/PTQ to a neural receiver architecture and evaluates
across 3GPP Clustered Delay Line (CDL)-B/D channels in LoS and NLoS
environments at user velocities up to 40 m/s. Results show that 4-bit and 8-bit
QAT models achieve BLERs similar to that of FP32 models at 10% target BLER. QAT
models are also shown to outperform PTQ models by up to 3 dB, and yield 8x
compression. These results demonstrate that QAT is a key enabler of
low-complexity and latency-constrained inference at the PHY layer, facilitating
real-time processing in 6G edge devices

</details>


### [235] [Domino: Dominant Path-based Compensation for Hardware Impairments in Modern WiFi Sensing](https://arxiv.org/abs/2509.13807)
*Ruiqi Kong,He Chen*

Main category: eess.SP

TL;DR: WiFi sensing 无法准确识别，因为现代 WiFi 卡会产生 RF 信号失真。Domino 框架通过将 CSI 转换为 CIR 来解决此问题，并利用静态信号路径来补偿失真。


<details>
  <summary>Details</summary>
Motivation: 现代 WiFi 卡（支持 802.11ac/ax 协议）中的硬件 RF 失真对 WiFi 感知构成了重大挑战，因为它们采用的自动增益控制和独立的 RF 链会产生复杂且动态的失真，从而使现有补偿方法失效。

Method: Domino 框架将信道状态信息（CSI）转换为信道冲激响应（CIR），并利用这样一个关键的见解，即硬件引起的失真会均匀地影响所有信号路径。它使用占主导地位的静态路径作为可靠的参考，通过延迟域处理进行有效的失真补偿。

Result: 在实际的呼吸监测实验中，与现有方法相比，Domino 的平均准确度至少提高了 2 倍。在单天线、视线和遮挡场景下，其性能保持稳定，中值误差低于 0.24 bpm。

Conclusion: Domino 框架能够有效补偿由现代 WiFi 卡引起的 RF 失真，从而提高 WiFi 感知的准确性。

Abstract: WiFi sensing faces a critical reliability challenge due to hardware-induced
RF distortions, especially with modern, market-dominant WiFi cards supporting
802.11ac/ax protocols. These cards employ sensitive automatic gain control and
separate RF chains, introducing complex and dynamic distortions that render
existing compensation methods ineffective. In this paper, we introduce Domino,
a new framework that transforms channel state information (CSI) into channel
impulse response (CIR) and leverages it for precise distortion compensation.
Domino is built on the key insight that hardware-induced distortions impact all
signal paths uniformly, allowing the dominant static path to serve as a
reliable reference for effective compensation through delay-domain processing.
Real-world respiration monitoring experiments show that Domino achieves at
least 2x higher mean accuracy over existing methods, maintaining robust
performance with a median error below 0.24 bpm, even using a single antenna in
both direct line-of-sight and obstructed scenarios.

</details>


### [236] [Flow Matching-Based Active Learning for Radio Map Construction with Low-Altitude UAVs](https://arxiv.org/abs/2509.13822)
*Hao Sun,Shicong Liu,Xianghao Yu,Ying Sun*

Main category: eess.SP

TL;DR: 通过引入基于主动学习的框架，利用流匹配算法进行低空测绘，以解决无人机续航限制导致的测绘数据不足问题。


<details>
  <summary>Details</summary>
Motivation: 低空经济需要精确的无线电地图，但无人机续航限制了数据采集的全面性。

Method: 提出了一种基于主动学习的低空无线电地图构建框架：1. 使用即插即用（PnP）流匹配算法生成高精度无线电地图。2. 利用流匹配的生成特性，通过生成多个地图并计算方差来量化不确定性。3. 基于不确定性地图，通过多目标候选点选择和效用感知路径搜索（UAPS）来规划无人机轨迹，以最高效的方式采集数据。

Result: 仿真结果显示，该方法比基线方法有显著提升，归一化均方误差（NMSE）降低了70%以上。

Conclusion: 所提出的主动学习框架能有效克服无人机续航限制，通过智能数据采集显著提高低空无线电地图的构建精度。

Abstract: The employment of unmanned aerial vehicles (UAVs) in the lowaltitude economy
necessitates precise and real-time radio maps for reliable communication and
safe navigation. However, constructing such maps is hindered by the
infeasibility of exhaustive measurements due to UAVs' limited flight endurance.
To address this, we propose a novel active learning framework for low-altitude
radio map construction based on limited measurements. First, a Plug-and-Play
(PnP)-refined flow matching algorithm is introduced, which leverages flow
matching as a powerful generative prior within a PnP scheme to reconstruct
high-fidelity radio maps. Second, the generative nature of flow matching is
exploited to quantify uncertainty by generating an ensemble of radio maps and
computing the location-wise variance. The resulting uncertainty map guides a
multi-objective candidate selection and then a trajectory is planned via
utility-aware path search (UAPS), directing the UAV to the most informative
locations while taking travel costs into account. Simulation results
demonstrate that our method significantly outperforms the baselines, achieving
more than a 70% reduction in normalized mean squared error (NMSE).

</details>


### [237] [FFT-Free PAPR Reduction Methods for OFDM Signals](https://arxiv.org/abs/2509.13851)
*Hao Su,Jiangtao Wang,Yongchao Wang*

Main category: eess.SP

TL;DR: 提出两种低复杂度OFDM信号PAPR约减算法


<details>
  <summary>Details</summary>
Motivation: OFDM信号存在较高的PAPR问题，需要进行约减。

Method: 提出一种基于最小化信号失真功率的非凸优化模型，并用定制的ADMM算法（T-ADMM和TCU-ADMM）求解。该算法可以解析求解子问题，迭代计算复杂度为线性，并避免了反复进行FFT/IFFT操作。

Result: T-ADMM算法在参数选择得当时理论上保证收敛。仿真结果证明了所提方法的有效性。

Conclusion: 所提出的T-ADMM和TCU-ADMM算法能够有效降低OFDM信号的PAPR，且计算复杂度低。

Abstract: In this paper, we propose two low-complexity peak to average power
ratio(PAPR) reduction algorithms for orthogonal frequency division
multiplexing(OFDM) signals. The main content is as follows: First, a non-convex
optimization model is established by minimizing the signal distortion power.
Then, a customized alternating direction method of multipliers(ADMM) algorithm
is proposed to solve the problem, named time domain ADMM(T-ADMM) along with an
improved version called T-ADMM with constrain update(TCU-ADMM). In the
algorithms, all subproblems can be solved analytically, and each iteration has
linear computational complexity. These algorithms circumvents the challenges
posed by repeated fast Fourier transform(FFT) and inverse FFT(IFFT) operations
in traditional PAPR reduction algorithms. Additionally, we prove that the
T-ADMM algorithm is theoretically guaranteed convergent if proper parameter is
chosen. Finally, simulation results demonstrate the effectiveness of the
proposed methods.

</details>


### [238] [Reconfigurable Intelligent Surface-Assisted Multiuser Tracking and Signal Detection in ISAC](https://arxiv.org/abs/2509.13940)
*Weifeng Zhu,Junyuan Gao,Shuowen Zhang,Liang Liu*

Main category: eess.SP

TL;DR: 本论文提出了一种基于RIS的ISAC系统中的用户追踪和信号检测方法，解决了高移动性用户状态更新问题。


<details>
  <summary>Details</summary>
Motivation: 为解决ISAC系统中因用户多样性和高移动性导致的用户追踪和信号检测性能下降问题，需要一种协同的用户状态（位置和速度）更新机制。

Method: 建立了一个综合概率信号模型来描述用户状态、传输信号和接收信号之间的相互依赖关系。在此基础上，提出了一种混合变分消息传递算法，用于在线估计用户状态，并能在每个追踪帧内进行有效的迭代更新。

Result: 提出的算法显著提高了追踪和信号检测性能，优于传统的贝叶斯估计方法。

Conclusion: 所提出的混合变分消息传递算法能够有效地追踪高移动性用户，并提高ISAC系统的信号检测性能。

Abstract: This paper investigates the multiuser tracking and signal detection problem
in integrated sensing and communication (ISAC) systems with the assistance of
reconfigurable intelligent surfaces (RISs). Due to the diverse and high user
mobility, the tracking and signal detection performance can be significantly
deteriorated without choreographed user state (position and velocity) updating
principle. To tackle this challenge, we manage to establish a comprehensive
probabilistic signal model to characterize the interdependencies among user
states, transmit signals, and received signals during the tracking procedure.
Based on the Bayesian problem formulation, we further propose a novel hybrid
variational message passing algorithm for the online estimation of user states,
which can iteratively update the posterior probabilities of user states during
each tracking frame with computational efficiency. Numerical results are
provided to demonstrate that the proposed algorithm can significantly improve
both of the tracking and signal detection performance over the representative
Bayesian estimation counterparts.

</details>


### [239] [Adaptive and robust smartphone-based step detection in multiple sclerosis](https://arxiv.org/abs/2509.13961)
*Lorenza Angelini,Dimitar Stanev,Marta Płonka,Rafał Klimas,Natan Napiórkowski,Gabriela González Chan,Lisa Bunn,Paul S Glazier,Richard Hosking,Jenny Freeman,Jeremy Hobart,Jonathan Marsden,Licinio Craveiro,Mike D Rinderknecht,Mattia Zanon*

Main category: eess.SP

TL;DR: 该研究评估了一种基于智能手机的步态分析流程，该流程能够准确检测不同场景、不同佩戴位置和不同步态损伤程度下的初始接触和最终接触。


<details>
  <summary>Details</summary>
Motivation: 目前已有的步态事件检测验证方法主要局限于单一传感器和监督场景下的初始接触检测，缺乏对更复杂现实场景的评估。

Method: 研究人员在实验室和现实世界中收集了健康对照组和多发性硬化症患者的步态数据，利用智能手机记录数据，并与运动捕捉系统或Gait Up传感器收集的参考数据进行比较，使用F1分数和绝对时间误差来评估步态分析流程的性能。

Result: 研究结果表明，该步态分析流程在所有智能手机佩戴位置都能准确检测初始接触和最终接触，无论是在实验室还是在现实世界中的行走活动中，其F1分数均较高，且时间误差较小。此外，年龄、性别、疾病严重程度、助行器使用情况或环境（室内/室外）均不影响该流程的性能。

Conclusion: 该步态分析流程能够准确、一致地检测多发性硬化症患者在不同智能手机佩戴位置和环境下的初始接触和最终接触，显示出其在现实世界步态评估中的应用潜力。

Abstract: Background: Many attempts to validate gait pipelines that process sensor data
to detect gait events have focused on the detection of initial contacts only in
supervised settings using a single sensor. Objective: To evaluate the
performance of a gait pipeline in detecting initial/final contacts using a step
detection algorithm adaptive to different test settings, smartphone wear
locations, and gait impairment levels. Methods: In GaitLab (ISRCTN15993728),
healthy controls (HC) and people with multiple sclerosis (PwMS; Expanded
Disability Status Scale 0.0-6.5) performed supervised Two-Minute Walk Test
[2MWT] (structured in-lab overground and treadmill 2MWT) during two on-site
visits carrying six smartphones and unsupervised walking activities (structured
and unstructured real-world walking) daily for 10-14 days using a single
smartphone. Reference gait data were collected with a motion capture system or
Gait Up sensors. The pipeline's performance in detecting initial/final contacts
was evaluated through F1 scores and absolute temporal error with respect to
reference measurement systems. Results: We studied 35 HC and 93 PwMS.
Initial/final contacts were accurately detected across all smartphone wear
locations. Median F1 scores for initial/final contacts on in-lab 2MWT were
>=98.2%/96.5% in HC and >=98.5%/97.7% in PwMS. F1 scores remained high on
structured (HC: 100% [0.3%]/100% [0.2%]; PwMS: 99.5% [1.9%]/99.4% [2.5%]) and
unstructured real-world walking (HC: 97.8% [2.6%]/97.8% [2.8%]; PwMS: 94.4%
[6.2%]/94.0% [6.5%]). Median temporal errors were <=0.08 s. Neither age, sex,
disease severity, walking aid use, nor setting (outdoor/indoor) impacted
pipeline performance (all p>0.05). Conclusion: This gait pipeline accurately
and consistently detects initial and final contacts in PwMS across different
smartphone locations and environments, highlighting its potential for
real-world gait assessment.

</details>


### [240] [Classification Filtering](https://arxiv.org/abs/2509.13975)
*Ilker Bayram*

Main category: eess.SP

TL;DR: 提出一种融合多分类器输出并考虑时序信息的状态空间模型，用于提高流式信号分类精度，并开发了适用于实时处理的滤波算法，在IMU活动分类任务上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的分类器在处理流式信号时，单独使用时准确率有限，并且未能有效利用信号的时间相关性。因此，需要一种能够融合多个分类器输出并结合时间信息以提高分类准确性的方法。

Method: 提出一个状态空间模型，并开发一个为实时处理定制的滤波器，用于融合多个分类器的输出，同时纳入时间信息以提升分类准确性。

Result: 在基于可穿戴设备惯性测量单元（IMU）数据的活动分类应用中，证明了所提出的滤波器能有效提高分类的准确性。

Conclusion: 所提出的状态空间模型和定制滤波器能够有效地融合多个分类器的输出，并利用流式信号的时间信息，在IMU活动分类任务上取得了良好的效果，证明了该方法的有效性。

Abstract: We consider a streaming signal in which each sample is linked to a latent
class. We assume that multiple classifiers are available, each providing class
probabilities with varying degrees of accuracy. These classifiers are employed
following a straightforward and fixed policy. In this setting, we consider the
problem of fusing the output of the classifiers while incorporating the
temporal aspect to improve classification accuracy. We propose a state-space
model and develop a filter tailored for realtime execution. We demonstrate the
effectiveness of the proposed filter in an activity classification application
based on inertial measurement unit (IMU) data from a wearable device.

</details>


### [241] [Distributed Coherent Beamforming at 60 GHz Enabled by Optically-Established Coherence](https://arxiv.org/abs/2509.13984)
*Drake Silbernagel,Yu Rong,Isabella Lenz,Prithvi Hemanth,Carl Morgenstern,Owen Ma,Nolan Matthews,Nader Zaki,Kyle W. Martin,John D. Elgin,Jacob Holtom,Daniel W. Bliss,Kimberly Frey*

Main category: eess.SP

TL;DR: 该研究实现了一个利用光学时间同步的60 GHz分布式系统，实现了精确的时间和频率对齐，从而能够进行干扰抑制的接收波束成形和发射零陷。该系统在存在干扰的情况下，信号到干扰加噪声的功率比提高了14.3 dB，发射零陷实现了7.9 dB的信噪比增益。


<details>
  <summary>Details</summary>
Motivation: 为了在没有GPS的情况下，在V波段利用分布式相干性实现精确的时间和频率对齐，以支持高级的分布式系统技术。

Method: 实现了一个60 GHz分布式系统，该系统利用光学时间同步系统进行精确的时间和频率对齐，并在此基础上进行接收波束成形和发射零陷。

Result: 在干扰环境下，接收波束成形实现了14.3 dB的信号到干扰加噪声的功率比的提升，并且对干扰信号有13.5 dB的抑制。在发射零陷中，实现了7.9 dB的信噪比增益，同时对另一个接收器的信噪比降低了8.9 dB。

Conclusion: 该研究成功展示了在没有GPS的情况下，在V波段利用分布式相干性进行精确的时间和频率对齐，并实现了先进的分布式波束成形和零陷技术，显著提高了信号质量。

Abstract: We implement and experimentally demonstrate a 60 GHz distributed system
leveraging an optical time synchronization system that provides precise time
and frequency alignment between independent elements of the distributed mesh.
Utilizing such accurate coherence, we perform receive beamforming with
interference rejection and transmit nulling. In these configurations, the
system achieves a coherent gain over an incoherent network of N nodes,
significantly improving the relevant signal power ratios. Our system
demonstrates extended array phase coherence times, enabling advanced
techniques. Results from over-the-air experiments demonstrate a 14.3 dB
signal-to-interference-plus-noise improvement in interference-laden scenarios
with a contributing 13.5 dB null towards interference in receive beamforming.
In transmit nulling, a signal-to-noise ratio (SNR) gain of 7.9 dB is measured
towards an intended receiver while maintaining an SNR reduction of 8.9 dB at
another receiver. These findings represent the use of distributed coherence in
the V band without the use of GPS timing.

</details>


### [242] [Distributed Deep Learning with RIS Grouping for Accurate Cascaded Channel Estimation](https://arxiv.org/abs/2509.14062)
*Saifur Rahman,Syed Luqman Shah,Salman Khan,Jalal Khan,Muhammad Irfan,Maaz Shafi,Said Muhammad,Fazal Muhammad,Mohammad Shahed Akond*

Main category: eess.SP

TL;DR: 提出一种基于深度学习（DL）的级联信道估计框架，通过分组RIS单元和从部分导频观测中重建级联信道来减少导频开销。提出一种分布式机器学习（DML）策略，BS和用户协作训练共享神经网络，实现鲁棒泛化。设计分层DML神经架构，首先对传播条件进行分类，然后采用场景特定特征提取来提高估计精度。


<details>
  <summary>Details</summary>
Motivation: RIS面板被设想为6G无线网络中的关键技术，但BS-RIS-用户信道的级联估计是一个挑战，因为RIS元件的被动性质会带来很高的导频开销、计算复杂性和能耗。

Method: 提出一种基于深度学习（DL）的信道估计框架，通过分组RIS单元和从部分导频观测中重建级联信道来减少导频开销。开发分布式机器学习（DML）策略，BS和用户协作训练共享神经网络，以实现鲁棒泛化。设计分层DML神经架构，首先对传播条件进行分类，然后采用场景特定特征提取来提高估计精度。

Result: 仿真结果证实，所提出的框架显著降低了导频开销和复杂性，并且在信道估计精度方面优于传统方法和单用户模型。

Conclusion: 所提出的方法在6G RIS辅助系统中具有实用性和有效性。

Abstract: Reconfigurable Intelligent Surface (RIS) panels are envisioned as a key
technology for sixth-generation (6G) wireless networks, providing a
cost-effective means to enhance coverage and spectral efficiency. A critical
challenge is the estimation of the cascaded base station (BS)-RIS-user channel,
since the passive nature of RIS elements prevents direct channel acquisition,
incurring prohibitive pilot overhead, computational complexity, and energy
consumption. To address this, we propose a deep learning (DL)-based channel
estimation framework that reduces pilot overhead by grouping RIS elements and
reconstructing the cascaded channel from partial pilot observations.
Furthermore, conventional DL models trained under single-user settings suffer
from poor generalization across new user locations and propagation scenarios.
We develop a distributed machine learning (DML) strategy in which the BS and
users collaboratively train a shared neural network using diverse channel
datasets collected across the network, thereby achieving robust generalization.
Building on this foundation, we design a hierarchical DML neural architecture
that first classifies propagation conditions and then employs scenario-specific
feature extraction to further improve estimation accuracy. Simulation results
confirm that the proposed framework substantially reduces pilot overhead and
complexity while outperforming conventional methods and single-user models in
channel estimation accuracy. These results demonstrate the practicality and
effectiveness of the proposed approach for 6G RIS-assisted systems.

</details>


### [243] [Novel Phase-Noise-Tolerant Variational-Autoencoder-Based Equalization Suitable for Space-Division-Multiplexed Transmission](https://arxiv.org/abs/2509.14072)
*Vincent Lauinger,Lennart Schmitz,Patrick Matalla,Andrej Rode,Sebastian Randel,Laurent Schmalen*

Main category: eess.SP

TL;DR: Phase-noise-tolerant VAE-based equalization improves SDM transmission over 150km.


<details>
  <summary>Details</summary>
Motivation: Improve SDM transmission by addressing phase noise.

Method: Using a variational autoencoder-based equalization scheme tolerant to phase noise.

Result: Demonstrated effectiveness in an experiment over 150km of randomly-coupled multi-core fibers.

Conclusion: The proposed scheme is effective for SDM transmission.

Abstract: We demonstrate the effectiveness of a novel phase-noise-tolerant,
variational-autoencoder-based equalization scheme for
space-division-multiplexed (SDM) transmission in an experiment over 150km of
randomly-coupled multi-core fibers.

</details>


### [244] [Hardware-Efficient Cognitive Radar: Multi-Target Detection with RL-Driven Transmissive RIS](https://arxiv.org/abs/2509.14160)
*Adam Umra,Aya Mostafa Ahmed,Stefan Roth,Aydin Sezgin*

Main category: eess.SP

TL;DR: 本论文提出了一种基于强化学习（RL）的认知MIMO雷达新框架，利用透射式可重构智能表面（TRIS）进行自适应波束形成，以在低信噪比（SNR）条件下提升多目标检测性能，同时显著降低硬件复杂度和能耗。


<details>
  <summary>Details</summary>
Motivation: 传统认知MIMO雷达虽然探测性能强，但硬件复杂度和功耗高，难以满足下一代传感器的需求。

Method: 采用SARSA（状态-动作-奖励-状态-动作）强化学习算法，通过调整TRIS的相移来实现自适应波束形成，以在低信噪比下提高多目标检测能力，并减少射频链的数量。

Result: 仿真结果表明，提出的TRIS-RL雷达在保持或（当TRIS单元数更多时）超越MIMO雷达性能的同时，降低了成本和能耗。

Conclusion: 基于TRIS的强化学习框架能够有效解决传统认知MIMO雷达的硬件复杂度和功耗问题，并在复杂动态环境中实现高性能的自适应目标检测。

Abstract: Cognitive radar has emerged as a key paradigm for next-generation sensing,
enabling adaptive, intelligent operation in dynamic and complex environments.
Yet, conventional cognitive multiple-input multiple-output (MIMO) radars offer
strong detection performance but suffer from high hardware complexity and power
demands. To overcome these limitations, we develop a reinforcement learning
(RL)-based framework that leverages a transmissive reconfigurable intelligent
surface (TRIS) for adaptive beamforming. A state-action-reward-state-action
(SARSA) agent tunes TRIS phase shifts to improve multi-target detection in low
signal-to-noise ratio (SNR) conditions while operating with far fewer radio
frequency (RF) chains. Simulations confirm that the proposed TRIS-RL radar
matches or, for large number of elements, even surpasses MIMO performance with
reduced cost and energy requirements.

</details>


### [245] [Quickest Change Detection with Cost-Constrained Experiment Design](https://arxiv.org/abs/2509.14186)
*Patrick Vincent N. Lubenia,Taposh Banerjee*

Main category: eess.SP

TL;DR: 该论文解决了最优实验选择下的最快变化检测问题，提出了一种名为2E-CUSUM的算法，并在多种情况下证明了其渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 在经典的最快变化检测问题中，观察者只执行一次实验。本论文考虑了决策者在每次观察时需要在信息质量和成本不同的多个实验中进行选择的情况，目标是在虚警和成本约束下最小化最坏情况下的平均检测延迟。

Method: 提出了一种名为2E-CUSUM的算法来解决双实验情况下的问题，并将其扩展到多实验设计。还探讨了观察者可以选择不执行实验的数据效率问题。

Result: 2E-CUSUM算法被提出并应用于双实验情况，并扩展到多实验设计。数据效率问题也被考虑在内。所有提出的算法都经过分析。

Conclusion: 所提出的算法被证明是渐近最优的。

Abstract: In the classical quickest change detection problem, an observer performs only
one experiment to monitor a stochastic process. This paper considers the case
where, at each observation time, the decision-maker needs to choose between
multiple experiments with different information qualities and costs. The goal
is to minimize the worst-case average detection delay subject to false alarm
and cost constraints. An algorithm called the 2E-CUSUM Algorithm has been
developed to achieve this goal for the two-experiment case. Extensions to
multiple-experiment designs are also studied, and 2E-CUSUM is extended
accordingly. Data efficiency, where the observer has the choice not to perform
an experiment, is explored as well. The proposed algorithms are analyzed and
shown to be asymptotically optimal.

</details>


### [246] [Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems](https://arxiv.org/abs/2509.14201)
*Guangjin Pan,Liping Bai,Zhuojun Tian,Hui Chen,Mehdi Bennis,Henk Wymeersch*

Main category: eess.SP

TL;DR: UAV系统使用主动推理框架（AIF）进行传感、通信和控制（SCC），以联合优化状态估计、控制和传感资源分配，实现性能和资源利用率的提升。


<details>
  <summary>Details</summary>
Motivation: 现有SCC解决方案将传感和控制分开处理，导致性能和资源利用不佳。

Method: 将主动推理框架（AIF）引入SCC中的无人机（UAV）系统，通过构建统一的生成模型，将问题转化为最小化变分自由能（用于推理）和预期自由能（用于行动规划）。

Result: 仿真结果表明，与基线方法相比，控制成本和传感成本均有所降低。

Conclusion: 主动推理框架（AIF）能够有效实现无人机（UAV）系统中传感、通信和控制（SCC）的联合状态估计、控制和传感资源分配，降低控制和传感成本。

Abstract: Integrated sensing and communication (ISAC) is a core technology for 6G, and
its application to closed-loop sensing, communication, and control (SCC)
enables various services. Existing SCC solutions often treat sensing and
control separately, leading to suboptimal performance and resource usage. In
this work, we introduce the active inference framework (AIF) into SCC-enabled
unmanned aerial vehicle (UAV) systems for joint state estimation, control, and
sensing resource allocation. By formulating a unified generative model, the
problem reduces to minimizing variational free energy for inference and
expected free energy for action planning. Simulation results show that both
control cost and sensing cost are reduced relative to baselines.

</details>


### [247] [Goal-Oriented Joint Source-Channel Coding: Distortion-Classification-Power Trade-off](https://arxiv.org/abs/2509.14217)
*Andriy Enttsel,Weichen Wang,Mauro Mangia,Riccardo Rovatti,Deniz Gündüz*

Main category: eess.SP

TL;DR: 联合信源-信道编码在低延迟和低复杂度通信中具有吸引力。本研究提出了一个将分类和异常检测整合到常规信号重建目标中的理论框架。在假设高斯标量信源和约束编码器为分段线性映射的情况下，我们推导出了易于处理的设计规则，并明确表征了失真、分类误差和传输功率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 联合信源-信道编码在低延迟和低复杂度通信中具有吸引力。

Method: 本研究提出了一个将分类和异常检测整合到常规信号重建目标中的理论框架。在假设高斯标量信源和约束编码器为分段线性映射的情况下，我们推导出了易于处理的设计规则。

Result: 明确表征了失真、分类误差和传输功率之间的权衡。

Conclusion: 本研究提出了一个将分类和异常检测整合到常规信号重建目标中的理论框架，并明确表征了失真、分类误差和传输功率之间的权衡。

Abstract: Joint source-channel coding is a compelling paradigm when low-latency and
low-complexity communication is required. This work proposes a theoretical
framework that integrates classification and anomaly detection within the
conventional signal reconstruction objective. Assuming a Gaussian scalar source
and constraining the encoder to piecewise linear mappings, we derive tractable
design rules and explicitly characterize the trade-offs between distortion,
classification error, and transmission power.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [248] [GTA -- An ATSP Method: Shifting the Bottleneck from Algorithm to RAM](https://arxiv.org/abs/2509.13327)
*Wissam Nakhle*

Main category: cs.DS

TL;DR: 提出了一种可扩展、高性能的算法，使用商用计算硬件可确定性地最优解决大规模旅行商问题（ATSP）实例。


<details>
  <summary>Details</summary>
Motivation: 解决大规模旅行商问题的现有方法依赖于高性能计算框架，而本研究旨在提供一种资源高效的替代方案，利用商用硬件实现确定性最优解。

Method: 结合了高效的启发式初始解和子路径消除策略，无需传统的MTZ约束，实现了高达5000个节点的实例在8核逻辑处理器上的快速求解。

Result: 算法在商品硬件上可确定性地最优解决高达5000个节点的ATSP实例，收敛速度可与高性能计算框架相媲美，并在公开数据集上进行了基准测试。

Conclusion: 该GTA（Gurobi Tabu Algorithm）算法将TSP求解瓶颈从算法复杂度转移到硬件（RAM和系统内存），为物流、生物信息学和天文学等领域的TSP问题提供了一种确定性、资源高效的解决方案。

Abstract: We present a scalable, high-performance algorithm that deterministically
solves large-scale instances of the Traveling Salesman problem (in its
asymmetric version, ATSP) to optimality using commercially available computing
hardware. By combining an efficient heuristic warm start, capable of achieving
near-optimality within seconds in some cases, with a subtour elimination
strategy that removes the need for traditional MTZ constraints, our approach
consistently resolves instances up to 5,000 nodes (approximately 25 million
binary variables) in record time on widely accessible computers, with eight
logical processors. We demonstrate reproducible results with convergence rates
comparable to those of high-performance computing frameworks. Real-time
iteration tracking and an adaptable interface allow seamless integration into
scheduling workflows in logistics, bioinformatics, and astronomy. Designed to
streamline solutions to large-scale TSP problems across disciplines, our
approach is benchmarked against widely used public datasets, offering a
deterministic, resource-efficient alternative to conventional solvers that rely
on supercomputing hardware. Our GTA (Gurobi Tabu Algorithm) algorithm is a
fundamental shift of TSP solution bottleneck from algorithmic complexity to the
underlying hardware (RAM and system memory), which is a highly desirable
characteristic.

</details>


### [249] [Hardness of Dynamic Core and Truss Decompositions](https://arxiv.org/abs/2509.13584)
*Yan S. Couto,Cristina G. Fernandes*

Main category: cs.DS

TL;DR: 没有高效的动态k-core算法，但存在2-core的对数级动态算法。


<details>
  <summary>Details</summary>
Motivation: 研究动态图中的k-core问题，解决现有算法中的低效问题，并探索近似算法和有界算法的可能性。

Method: 基于OMv和SETH猜想，通过证明不存在比平凡算法更快的动态k-core算法，并针对k-truss和有向k-core问题提出下界。此外，还提出了一种用于2-core的对数级动态算法。

Result: 证明了不存在高效的动态k-core算法，也不存在(2 - {\epsilon})-近似核心值的算法。证明了有界算法不存在。提出了有向k-core和k-truss问题的下界。提出了一种用于2-core的对数级动态算法。

Conclusion: 目前不存在高效的动态k-core算法，但对于2-core问题存在一个对数级的动态算法。未来的研究应集中在特定场景下的算法或近似算法上。

Abstract: The k-core of a graph is its maximal subgraph with minimum degree at least k,
and the core value of a vertex u is the largest k for which u is contained in
the k-core of the graph. Among cohesive subgraphs, k-core and its variants have
received a lot of attention recently, particularly on dynamic graphs, as
reported by Hanauer, Henzinger, and Schulz in their recent survey on dynamic
graph algorithms. We answer questions on k-core stated in the survey, proving
that there is no efficient dynamic algorithm for k-core or to find (2 -
{\epsilon})-approximations for the core values, unless we can improve
decade-long state-of-the-art algorithms in many areas including matrix
multiplication and satisfiability, based on the established OMv and SETH
conjectures. Some of our results show that there is no dynamic algorithm for
k-core asymptotically faster than the trivial ones. This explains why most
recent research papers in this area focus not on a generic efficient dynamic
algorithm, but on finding a bounded algorithm, which is fast when few core
values change per update. However, we also prove that such bounded algorithms
do not exist, based on the OMv conjecture. We present lower bounds also for a
directed version of the problem, and for the edge variant of the problem, known
as k-truss. On the positive side, we present a polylogarithmic dynamic
algorithm for 2-core.

</details>


### [250] [On Solving Asymmetric Diagonally Dominant Linear Systems in Sublinear Time](https://arxiv.org/abs/2509.13891)
*Tsz Chiu Kwok,Zhewei Wei,Mingji Yang*

Main category: cs.DS

TL;DR: 该论文研究在亚线性时间内求解行/列对角占优（RDD/CDD）线性系统 $Mx=b$，目标是估计给定向量 $t$ 和特定解 $x^*$ 的 $t^{	op}x^*$。


<details>
  <summary>Details</summary>
Motivation: 将亚线性时间求解器研究从对称对角占优（SDD）系统推广到非对称情况。

Method: 通过 Neumann 级数表达 $x^*$，证明其收敛性，并引入“最大p范数差”来界 truncation error。该方法推广了SDD矩阵的谱隙。

Result: 在最大p范数差有界的假设下，开发了用于局部近似 $t^{	op}x^*$ 的算法，并改进了随机游走采样、局部推进等技术的复杂性界限。

Conclusion: 提出了一个统一的框架，加深了对Forward Push和Backward Push等图算法的理解，并建立了亚线性求解器和局部图算法的硬度结果。

Abstract: We initiate a study of solving a row/column diagonally dominant (RDD/CDD)
linear system $Mx=b$ in sublinear time, with the goal of estimating
$t^{\top}x^*$ for a given vector $t\in R^n$ and a specific solution $x^*$. This
setting naturally generalizes the study of sublinear-time solvers for symmetric
diagonally dominant (SDD) systems [AKP19] to the asymmetric case.
  Our first contributions are characterizations of the problem's mathematical
structure. We express a solution $x^*$ via a Neumann series, prove its
convergence, and upper bound the truncation error on this series through a
novel quantity of $M$, termed the maximum $p$-norm gap. This quantity
generalizes the spectral gap of symmetric matrices and captures how the
structure of $M$ governs the problem's computational difficulty.
  For systems with bounded maximum $p$-norm gap, we develop a collection of
algorithmic results for locally approximating $t^{\top}x^*$ under various
scenarios and error measures. We derive these results by adapting the
techniques of random-walk sampling, local push, and their bidirectional
combination, which have proved powerful for special cases of solving RDD/CDD
systems, particularly estimating PageRank and effective resistance on graphs.
Our general framework yields deeper insights, extended results, and improved
complexity bounds for these problems. Notably, our perspective provides a
unified understanding of Forward Push and Backward Push, two fundamental
approaches for estimating random-walk probabilities on graphs.
  Our framework also inherits the hardness results for sublinear-time SDD
solvers and local PageRank computation, establishing lower bounds on the
maximum $p$-norm gap or the accuracy parameter. We hope that our work opens the
door for further study into sublinear solvers, local graph algorithms, and
directed spectral graph theory.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [251] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于分布-free 共识预测（CP）的物理信息神经网络（PINNs）不确定性量化（UQ）框架，用于生成具有严格有限样本覆盖保证的预测区间，并解决了空间异方差性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 PINNs UQ 方法缺乏严格的统计保证，本文旨在解决此问题。

Method: 引入了基于分布-free 共识预测（CP）的 UQ 框架，并通过局部共识分位数估计来处理空间异方差性。

Result: 所提出的框架在多种 PDE 上进行了评估，结果表明其预测区间校准可靠且具有局部适应性，优于现有的 UQ 方法。

Conclusion: 该框架将 PINNs 与分布-free UQ 相结合，提高了校准性和可靠性，并为复杂 PDE 系统的 UQ 建模开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [252] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: X-PINN是一个用于解决多裂缝断裂力学问题的框架，通过结合XFEM的特点，利用专门的神经网络来捕捉裂缝的复杂性。


<details>
  <summary>Details</summary>
Motivation: 需要一个能够有效解决涉及多裂缝的断裂力学问题的框架。

Method: 提出了一种基于能量的损失函数、定制的积分方案和域分解程序。X-PINN的神经网络解空间通过专门的函数进行丰富，以明确捕捉裂缝体的不连续性和裂缝尖端的奇点。标准和丰富解分量由不同的神经网络建模。

Result: X-PINN能够灵活有效地模拟1D和2D域中的复杂多裂缝问题，并易于扩展到3D问题。数值实验验证了该方法的有效性和鲁棒性。

Conclusion: X-PINN框架在处理多裂缝断裂力学问题方面表现出优越的性能和灵活性。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [253] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: USPIL是一个集成了物理信息神经网络（PINNs）和守恒定律的深度学习框架，用于模拟跨尺度的捕食者-猎物动态。它能统一处理常微分方程（ODE）和偏微分方程（PDE）系统，在捕获时间周期和空间模式的同时，遵守守恒定律。


<details>
  <summary>Details</summary>
Motivation: 现有的生态系统建模方法难以捕捉多尺度动力学、时间振荡和空间模式，并且需要遵守守恒定律。USPIL旨在解决这些挑战。

Method: USPIL框架使用自动微分来强制执行物理约束，并采用自适应损失加权来平衡数据保真度和物理一致性。它将PINNs与守恒定律相结合，形成单一的神经网络架构，可以同时处理ODE和PDE系统。

Result: 在Lotka-Volterra系统的1D时间动力学模拟中，USPIL达到了98.9%的相关性（损失：0.0219，平均绝对误差：0.0184）；在2D系统中，它成功捕捉了复杂的螺旋波（损失：4.7656，模式相关性：0.94）。此外，USPIL在遵守守恒定律方面误差小于0.5%，并且在推理速度上比传统数值求解器快10-50倍。

Conclusion: USPIL框架通过结合物理信息和深度学习，为生态系统建模提供了一个强大且在科学上严谨的范式。它不仅能准确模拟复杂的生态动态，还能实现参数发现和敏感性分析，并支持跨尺度建模，为生态预测、保护规划和理解生态系统韧性开辟了新的途径。

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [254] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 残差自适应策略有了统一的变分框架，通过整合残差的凸变换来形式化这些方法，并实现了系统设计、误差减少和学习动态的增强。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习中广泛使用的残差自适应策略在很大程度上是启发式的，缺乏统一的理论基础。

Method: 引入一个统一的变分框架，通过整合残差的凸变换来形式化残差自适应策略。不同的变换对应于不同的目标泛函：指数权重旨在最小化均匀误差，而线性权重则恢复最小化二次误差。在此视角下，自适应加权等同于选择优化原始目标的采样分布，从而将离散化选择直接与误差指标联系起来。

Result: 该方法实现了三个优点：(1) 能够跨范式系统地设计自适应方案；(2) 通过降低损失估计量的方差来减少离散化误差；(3) 通过提高梯度信噪比来增强学习动态。将该框架扩展到算子学习，在各种优化器和架构中均实现了显著的性能提升。

Conclusion: 该研究为残差自适应提供了理论依据，并为原则性的离散化和训练策略奠定了基础。

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [255] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 机器学习模型的训练对环境有影响，选择合适的优化器可以提高能源效率。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越复杂，理解训练决策对环境的影响对于可持续的AI发展至关重要。

Method: 在三个基准数据集（MNIST, CIFAR-10, CIFAR-100）上，使用八种流行优化器（SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax, NAdam）和15个随机种子进行了360次对照实验。使用CodeCarbon精确追踪Apple M1 Pro硬件上的能耗，测量了训练时长、峰值内存使用量、二氧化碳排放量和最终模型性能。

Result: 研究发现在训练速度、准确性和环境影响之间存在显著的权衡，并且这种权衡因数据集和模型复杂度而异。AdamW和NAdam是始终高效的选择，而SGD在复杂数据集上表现更好，但排放量更高。

Conclusion: 研究结果为寻求在机器学习工作流中平衡性能和可持续性的实践者提供了可行的见解。

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [256] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 该研究提出了一个名为DeepONet-Transolver的混合框架，用于解决具有挑战性的PET瓶屈曲分析问题，解决了现有神经网络在非参数几何域泛化能力上的局限性，并实现了对位移场和反作用力随时间演变的预测。


<details>
  <summary>Details</summary>
Motivation: 现有的神经代理模型在处理变化的非参数几何域时泛化能力有限，而PET瓶屈曲分析是一个重要的包装设计问题，传统方法计算成本高昂。

Method: 提出了一种名为DeepONet-Transolver的混合框架，该框架能够同时预测节点位移场和反作用力随时间演变。通过使用Abaqus进行非线性有限元分析（FEA）生成训练数据，并在两类瓶子几何形状（由两个和四个设计变量参数化）上进行了评估。

Result: 对于四参数瓶子家族，所提出的框架在位移场方面实现了2.5-13%的平均相对L2误差，在随时间变化的力方面实现了约2.4%的误差。点位移误差分析显示绝对位移误差在10^-4到10^-3量级，且最大的差异局限于局部几何区域。该模型能够准确捕捉到各种瓶子几何形状中的屈曲行为等关键物理现象。

Conclusion: 该混合框架为计算力学中的多任务预测和需要快速设计评估的应用提供了一个有前景的、可扩展的、计算效率高的替代方案。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [257] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: AERIS是一个1.3到80B参数的像素级Swin扩散Transformer，用于解决高分辨率天气预报的扩展性问题。SWiPe是一种可组合的技术，通过窗口并行、序列并行和流水线并行来分片窗口Transformer，而无需增加通信成本或全局批次大小。AERIS在Aurora上实现了10.21 ExaFLOPS的混合精度性能，并在0.25度ERA5数据集上实现了95.5%的弱扩展效率和81.6%的强扩展效率。AERIS的性能优于IFS ENS，并在长达90天的季节性尺度上保持稳定，展示了百亿参数扩散模型在天气和气候预测方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 生成机器学习为更好地理解复杂地球系统动力学提供了新的机会。然而，最近的基于扩散的方法在扩展到高分辨率时存在稳定性问题。

Method: 我们引入了AERIS，一个1.3到80B参数的像素级Swin扩散Transformer，以及SWiPe，一种可组合窗口并行、序列并行和流水线并行以分片窗口Transformer的技术，而无需增加通信成本或全局批次大小。

Result: AERIS在Aurora上实现了10.21 ExaFLOPS的混合精度性能，并在0.25度ERA5数据集上实现了95.5%的弱扩展效率和81.6%的强扩展效率。AERIS的性能优于IFS ENS，并在长达90天的季节性尺度上保持稳定。

Conclusion: 百亿参数扩散模型在天气和气候预测方面具有潜力。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [258] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: LAMeL通过元学习框架识别跨相关任务的共享模型参数，在提高预测准确性的同时保持了可解释性，在化学性质预测方面优于传统线性方法。


<details>
  <summary>Details</summary>
Motivation: 化学家在寻找结构-性质关系时面临数据质量和一致性有限的挑战。现代数据驱动的机器学习方法增加了对数据的需求，同时人们也日益需要可解释的人工智能。

Method: LAMeL（一种线性元学习算法）利用元学习框架来识别跨相关任务（即使这些任务没有共享数据）的共享模型参数，从而学习一个通用的函数流形，为新的未见任务提供更有效的信息起点。

Result: LAMeL 的性能比标准的岭回归方法提高了 1.1 到 25 倍，具体取决于数据集的领域。

Conclusion: LAMeL 在提高预测准确性的同时保持了可解释性，在化学性质预测方面，其性能持续优于或匹配传统线性方法，是精度和可解释性都至关重要的可靠工具。

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [259] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: GPT-4o mini在多模态仇恨言论检测中存在“单一模态瓶颈”问题，安全过滤器会不分青红皂白地阻止内容，影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型多模态模型（LMM）日益融入日常生活，理解其安全机制对AI对齐至关重要。本研究旨在系统分析OpenAI的GPT-4o mini在多模态仇恨言论检测任务中的安全架构。

Method: 使用Hateful Memes Challenge数据集，对500个样本进行多阶段分析，研究GPT-4o mini的推理和失效模式，并通过定量验证144个内容策略拒绝来评估其安全系统的表现。

Result: 实验发现了一个“单一模态瓶颈”：模型先进的多模态推理能力被缺乏语境理解的安全过滤器系统性地压制。安全系统阻止了高风险内容，但也误伤了大量无害的常见Meme格式，导致了可预测的假阳性。拒绝的案例中，50%由视觉内容触发，50%由文本内容触发。

Conclusion: GPT-4o mini的安全系统存在“单一模态瓶颈”，即安全过滤器会不考虑语境地压制模型的推理能力，导致对无害内容的误判。这揭示了当前LMM在能力与安全之间的根本性矛盾，强调了需要更集成、更具语境感知能力的对齐策略，以确保AI系统能够安全有效地部署。

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [260] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 自动化故障分析框架处理ALS的EPICS实时事件日志，使用语义嵌入将日志转化为向量，并通过序列感知神经网络识别异常事件序列，以快速定位复杂系统故障。


<details>
  <summary>Details</summary>
Motivation: 在ALS中，需要一种方法来处理EPICS控制系统的实时事件日志，以识别导致复杂系统故障的关键事件序列。

Method: 将日志条目视为自然语言，使用语义嵌入技术将其转换为上下文向量表示。训练一个序列感知神经网络来处理正常运行数据，并为每个事件分配实时异常分数。

Result: 该框架能够标记与基线行为的偏差，并使操作员能够快速识别复杂系统故障之前的关键事件序列。

Conclusion: 所提出的自动化故障分析框架能够有效地处理ALS的EPICS实时事件日志，通过识别异常事件序列来帮助操作员快速定位和解决复杂系统故障。

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [261] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: ParaAegis框架通过模型分区，结合差分隐私和同态加密，实现了隐私、模型效用和计算效率之间的灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）隐私保护机制（如差分隐私DP和同态加密HE）在模型效用和计算效率之间存在固定的权衡，限制了实际应用。ParaAegis旨在解决此问题，提供一个灵活的保护框架。

Method: ParaAegis采用模型分区策略，对模型中范数较低的、不那么关键的部分应用轻量级DP，而对其余部分应用HE进行保护。通过分布式投票机制来就分区达成共识。

Result: 理论分析证实了该方法在效率和效用之间可调。实验结果表明，通过调整超参数，可以灵活地优先考虑模型准确率或训练时间。

Conclusion: ParaAegis框架为联邦学习提供了一个可调的隐私-效用-效率平衡解决方案，通过模型分区和混合加密技术，满足了实际应用的需求。

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [262] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: LLMs可能暴露敏感信息，我们提出了一种基于差分隐私的生成框架，可以在不微调模型的情况下，为合成文本提供强隐私保护，并提高了效用。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言理解和生成方面取得了显著进展，但也引发了对敏感信息泄露的隐私担忧。

Method: 提出了一种利用差分隐私（DP）框架的私有预测框架，在不进行任何模型微调的情况下，对私有记录执行推理，并聚合生成的每个token的输出分布，同时提出了一种结合私有和公共推理的混合操作来增强效用。

Result: 该方法在保持隐私的同时，生成了更长、更连贯的合成文本，并在ICL任务上取得了优于现有技术的性能。

Conclusion: 所提出的方法为在保持高效用的同时进行隐私保护的文本生成提供了一个有前景的方向。

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [263] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 图正则化学习的分布式高斯混合模型方法，在异构和有限的本地数据下，通过相似性图指导参数共享，避免原始数据传输，并优于集中式和本地训练的高斯混合模型。


<details>
  <summary>Details</summary>
Motivation: 在分布式设置中，在数据异构和有限的情况下，学习高斯混合模型。

Method: 提出一种图正则化学习高斯混合模型的方法，利用相似性图指导参数共享，并允许灵活聚合邻居的参数。

Result: 所提出的方法在异构、低样本量的情况下，优于集中式和本地训练的高斯混合模型。

Conclusion: 图正则化学习高斯混合模型是一种在分布式、异构和数据有限的情况下有效的学习方法。

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [264] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 本研究提出了一种名为DeepLogit的深度学习模型，通过顺序约束方法来解决深度学习模型在交通政策分析中的可解释性问题。该方法首先估计一个线性CNN模型，然后在此基础上引入高阶项或Transformer等高级架构，从而在提高模型准确性的同时保持部分参数的可解释性。通过新加坡的公交路线选择实例验证了该方法的有效性，并表明该方法能够结合传统离散选择模型和深度学习模型的优点，为交通规划和政策分析提供更准确、可解释的模型。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在交通政策分析等领域应用受限，因其“黑箱”特性难以解释。

Method: 提出DeepLogit模型，采用顺序约束方法：1. 估计一个仅含线性项的CNN模型（等同于线性MNL模型）；2. 约束该线性模型中的参数，并引入高阶项或Transformer等高级架构来估计其他深度学习模型。

Result: 在新加坡公交路线选择案例中，DeepLogit模型相比传统的离散选择模型，在保持部分参数可解释性的同时，显著提高了模型准确性。

Conclusion: DeepLogit模型展示了一种统一的、结合了理论驱动的离散选择模型和数据驱动的AI模型的潜力，能够相互借鉴可解释性和预测能力。随着数据量和模型复杂性的增加，这种方法有望在保持可解释性的同时，提升离散选择模型的准确性，并更好地应用于规划和政策领域。

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [265] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: WILF-Q是一种用于无线联邦学习的客户端选择方法，通过Q学习自适应更新的Whittle指数来选择客户端，以减少达到目标学习精度所需的时间。


<details>
  <summary>Details</summary>
Motivation: 在无线联邦学习中，服务器无法观察到客户端的动态状态（计算和通信效率），因此需要解决客户端选择问题以减少达到特定学习精度所需的时间。

Method: 将客户端选择问题建模为躁动的多臂老虎机问题，并提出一种名为WILF-Q（Whittle Index Learning in Federated Q-learning）的方法。WILF-Q利用Q学习自适应地学习和更新与每个客户端相关联的近似Whittle指数，然后选择指数最高的客户端。

Result: 实验结果表明，WILF-Q在学习效率方面显著优于现有的基线策略，为无线联邦学习中的客户端选择提供了一种强大而有效的方法。

Conclusion: WILF-Q是一种有效的无线联邦学习客户端选择方法，它不需要了解客户端状态转移或数据分布的先验知识，适用于实际的联邦学习场景。

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [266] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 该论文提出了一种结合数字孪生（DT）和零知识联邦学习（zkFed）的框架，以解决无人机（UAV）辅助联邦学习（FL）系统中的能源消耗、通信效率低下和安全漏洞等问题。


<details>
  <summary>Details</summary>
Motivation: 为了确保无人机辅助联邦学习系统的可靠运行，必须解决能源消耗过高、通信效率低下和安全漏洞等问题。

Method: 该框架利用无人机作为移动基站，实现本地化模型训练和更新聚合。通过集成数字孪生技术实现实时监控和预测性维护，提高网络效率。利用零知识证明（ZKPs）在不暴露敏感数据的情况下进行模型验证，增强安全性。引入动态分配策略，根据网络条件调整无人机航线、传输功率和处理速率，以优化能源效率和资源管理。

Result: 通过采用块坐标下降和凸优化技术，与传统联邦学习方法相比，系统能耗显著降低了高达29.6%。

Conclusion: 仿真结果表明，该框架在学习性能、安全性和可扩展性方面均有所提升，为下一代无人机智能网络提供了一种有前景的解决方案。

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [267] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 本研究提出一种将PPG、GSR和ACC等生理信号转换为2D图像矩阵的新方法，利用CNN进行压力检测。


<details>
  <summary>Details</summary>
Motivation: 传统方法处理生理信号存在不足，本研究旨在通过新方法提高压力检测的准确性和鲁棒性。

Method: 将PPG、GSR和ACC信号融合成2D图像矩阵，并采用多阶段训练流水线进行模型训练。

Result: 该方法显著提高了分类性能，并且提高了模型的可解释性和泛化能力。

Conclusion: 所提出的方法不仅能有效用于压力检测，还能广泛应用于涉及多模态生理信号的领域，为可穿戴技术实现更准确、个性化和实时的健康监测提供了新途径。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [268] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved (LLM-I)是一个灵活的框架，将图像-文本生成重构为工具使用问题，克服了现有统一模型“单一工具”的限制，能够处理需要事实依据或程序精度的问题。它使一个中心LLM/MLLM代理能够通过在线图像搜索、扩散生成、代码执行和图像编辑等专业视觉工具来完成任务。该代理通过结合基于规则的逻辑以及LLM/MLLM评估者的判断的混合奖励系统，利用强化学习进行训练。LLM-I在一个新的数据集上进行了训练，并在四个基准测试中表现出最先进的性能，同时还引入了一种新的测试时间缩放策略以获得进一步的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在处理需要事实依据或程序精度的图像-文本生成任务时存在“单一工具”的瓶颈，LLM-I旨在解决这一问题，通过智能地协调多种专业视觉工具来增强模型的灵活性和能力。

Method: LLM-I框架利用一个中心LLM/MLLM代理，通过强化学习（RL）框架来选择和应用多种视觉工具（如在线图像搜索、扩散生成、代码执行、图像编辑）。该RL框架采用混合奖励系统，结合了基于规则的逻辑和LLM/MLLM评估者的判断。

Result: LLM-I在四个基准测试中展现了最先进的性能，显著优于现有方法。此外，还提出了一种新颖的测试时间缩放策略，进一步提高了性能。

Conclusion: LLM-I框架通过将图像-文本生成视为工具使用问题，并采用智能代理和多样化的视觉工具集，成功克服了现有模型的局限性，并在多个基准测试中取得了优异的性能。

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [269] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 生成推荐中的数据增强方法对于模型泛化至关重要，但以往研究对其关注不足。


<details>
  <summary>Details</summary>
Motivation: 以往的生成推荐模型在数据增强方面存在简化、不一致或被视为次要设计选择的问题，缺乏系统性的理解。

Method: 提出了一种名为GenPAS的通用框架，将数据增强建模为具有三个偏差控制步骤（序列采样、目标采样和输入采样）的随机采样过程，并统一了现有策略。

Result: 在基准和工业数据集上的广泛实验表明，与现有策略相比，GenPAS在准确性、数据效率和参数效率方面均优于现有策略。

Conclusion: GenPAS为生成推荐中的训练数据构建提供了原则性的指导。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [270] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 本研究提出了一种名为CPT（Controllable Pareto Trade-off）的新方法，用于在NLP任务中实现可控的公平性-准确性权衡，解决了现有方法只能找到单一最优解的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡公平性和准确性时，通常只能找到一个“最优”解，这忽略了帕累托前沿上存在的多种解决方案。因此，本研究的动机是提供一种能够根据用户对公平性和准确性偏好的不同需求，来实现可控权衡的方法。

Method: 本研究利用多目标优化（MOO）来寻找帕累托前沿上的不同解决方案。为了解决训练过程中的随机性和高维梯度向量带来的精确控制难题，CPT方法通过以下两种方式进行优化：1）使用随机梯度的移动平均来稳定公平性更新，确定更新方向；2）通过只保留关键参数的梯度来修剪梯度。

Result: CPT在仇恨言论检测和职业分类任务上的评估结果表明，与基线方法相比，CPT能够实现更高质量的帕累托前沿解决方案。此外，CPT还表现出更好的可控性，能够精确地遵循用户定义的参考向量。

Conclusion: CPT方法有效地实现了NLP任务中公平性与准确性的可控权衡，能够根据用户的偏好提供帕累托前沿上的多种高质量解决方案，并在实际任务中表现出优于基线方法的性能。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [271] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: RF-LSCM是一个新的无线信道建模框架，通过联合表示大规模信号衰减和多径分量，实现了跨域（多小区、多网格、多频段）的精确信道建模，并利用张量表示提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的本地化统计信道建模（LSCM）方法在单小区、单网格和单载波频率分析中存在局限性，无法捕捉复杂的跨域交互。为了优化蜂窝网络性能，需要更精确、更通用的信道模型。

Method: 提出RF-LSCM框架，通过辐射场联合表示大规模信号衰减和多径分量。引入了物理信息约束的频率相关衰减模型（FDAM）来实现跨频率泛化，并利用点云辅助环境增强方法实现多小区和多网格信道建模。通过低秩张量表示和分层张量角度建模（HiTAM）算法提高了计算效率。

Result: 在真实世界的多小区数据集上进行的大量实验表明，RF-LSCM在覆盖预测方面将平均绝对误差（MAE）降低了30%，并通过有效融合多频数据将MAE提高了22%，显著优于现有技术。

Conclusion: RF-LSCM框架能够通过联合建模跨越多个领域（频率、空间和时间）的无线信道特性，从而实现比现有方法更精确、更高效的信道建模，为蜂窝网络优化提供了新的途径。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [272] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 本研究旨在通过智能手表监测和预测大学生群体的日常社交焦虑水平，以开发实时干预措施。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑常导致学业、社交和职业功能受损。虽然日内焦虑波动是其核心特征，但以往研究对其测量和预测不足，阻碍了实时个性化干预（如JITAIs）的发展。

Method: 本研究利用智能手表，对91名（排除后72名）有社交焦虑的大学生进行了平均9.03天的监测。研究人员每日进行七次生态瞬间评估（EMAs），收集被试的即时焦虑水平。基于超过10000天的心率数据构建基础模型，并将其迁移到本研究数据集进行微调，以进行概率预测。该预测结果与特质焦虑水平相结合，用于元学习器。另外，研究还将训练方法应用于TILES-18数据集的独立测试集，以评估模型的泛化能力。

Result: 在学生数据集上，该方法在状态焦虑检测方面达到了60.4%的平衡准确率。在TILES-18数据集上，对10095次每日EMAs进行分析，模型的平衡准确率达到了59.1%，比先前研究至少提高了7%。

Conclusion: 本研究成功开发了一种利用智能手表和机器学习模型预测日内社交焦虑水平的方法，在预测准确性和泛化能力方面均取得了积极成果，为开发实时社交焦虑干预措施奠定了基础。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [273] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 本论文提出DirGraphSSM，一种用于处理有向图的图神经网络架构，通过序列化有向图和消息传递机制来扩展状态空间模型（SSMs）在有向图上的应用，从而有效捕捉长距离因果依赖并提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络（GNNs）和图Transformer在处理有向图时，在捕捉长距离因果依赖和平衡训练效率方面存在挑战；现有的图状态空间模型（SSMs）仅限于无向图。

Method: 提出DirEgo2Token方法，通过k-hop自图（ego graphs）将有向图序列化；在此基础上，设计了DirGraphSSM架构，将SSMs应用于有向图，并利用消息传递机制。

Result: DirGraphSSM在三个代表性的有向图学习任务上达到了最先进的性能，并在另外两个任务上取得了有竞争力的性能，同时训练速度比现有模型提高了1.5到2倍。

Conclusion: DirGraphSSM是首个将状态空间模型系统性地扩展到有向图学习领域的方法，在有向图学习任务上展现出优越的性能和效率。

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [274] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: 本研究提出了一种名为EpiSMART的持续学习框架，用于自动化癫痫发作检测，通过个性化适应患者的脑电图信号，解决了灾难性遗忘问题，并在CHB-MIT数据集上取得了显著的F1分数提升，同时满足实时部署的资源限制。


<details>
  <summary>Details</summary>
Motivation: 当前的癫痫发作检测依赖于耗时且需要专业知识的人工分析脑电图，因此需要自动化方法来应对这一挑战。

Method: 提出了一种名为EpiSMART的持续学习框架，该框架使用大小受限的重放缓冲区和信息样本选择策略，通过选择性保留高熵和预测发作的样本，来逐步适应患者特定的脑电图信号，以整合新数据而不会发生灾难性遗忘。

Result: 在CHB-MIT数据集上的验证显示，EpiSMART在F1分数上比未更新的基线模型提高了21%，平均每天仅需6.46分钟的标记数据和6.28次更新，适合在可穿戴系统上进行实时部署。

Conclusion: EpiSMART能够在资源受限的实际条件下，通过有效整合新数据且不损害已有知识，实现稳健的个性化癫痫发作检测。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [275] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK是一个新的框架，它增强了大型语言模型（LLMs）捕捉时空依赖关系的能力，解决了LLMs在处理空间依赖性方面的固有局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在处理交通预测等需要捕捉空间依赖性的问题时存在局限性，因为它们的架构主要针对序列数据，并且在整合图结构空间数据方面存在不兼容性。

Method: ST-LINK框架通过引入空间增强注意力（SE-Attention）和记忆检索前馈网络（MRFFN）来增强LLMs。SE-Attention通过将空间相关性作为直接旋转变换集成到注意力机制中，来扩展旋转位置嵌入。MRFFN则动态检索和利用关键历史模式，以捕捉复杂的时间依赖性并提高长期预测的稳定性。

Result: 在基准数据集上的综合实验表明，ST-LINK在捕捉规律性交通模式和突变方面，优于传统的深度学习和LLMs方法。

Conclusion: ST-LINK框架能够有效地捕捉时空依赖关系，解决了现有LLMs在交通预测等任务中的空间信息处理瓶颈，并在实验中取得了优于传统方法的性能。

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [276] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 通过将纳米孔电流信号转换为尺度图图像，利用机器学习进行蛋白质分类，准确率达81%，为实时疾病诊断提供新方法。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实时、低成本、快速地进行疾病诊断的临床蛋白质分类设备。

Method: 将蛋白质通过纳米孔时产生的电流信号，利用小波变换转换为尺度图图像，并使用机器学习算法进行分类。

Result: 在42种肽的测试中，该方法实现了约81%的分类准确率，并展示了模型迁移技术。

Conclusion: 该方法通过将电流信号转化为尺度图图像，提高了机器学习在蛋白质分类中的准确性，为实现实际的即时护理点肽/蛋白质诊断和实时疾病诊断铺平了道路。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [277] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 现有方法忽略混淆因素，本文提出CAUSA从因果角度进行特征选择，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MUFS方法通过特征与聚类标签的相关性来选择特征，但这种相关性可能受混淆因素影响，导致选择不相关的特征。

Method: 提出CAUSA方法，首先使用广义无监督谱回归模型识别信息特征，然后引入因果正则化模块分离混淆因素并学习样本权重以平衡混淆因素分布，最后将两者整合到统一框架中进行因果特征选择。

Result: CAUSA方法在多个数据集上取得了优于现有最先进方法的实验结果。

Conclusion: 本文首次从因果角度深入研究了无监督多视图特征选择问题，并提出了CAUSA方法，有效解决了现有方法因忽略混淆因素而选择不相关特征的问题。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [278] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: FHNN是一种物理结构化的框架，用于预测可解释的水动力学参数（如方向性附加质量、阻力系数和基于流函数的流），并将其与运动的解析方程耦合，从而在合成涡流数据集上实现了比Neural ODE低一个数量级的误差，并恢复了物理上一致的流场。


<details>
  <summary>Details</summary>
Motivation: 对浮体运动中的耗散动力学进行建模具有挑战性，传统的黑盒神经网络模型可解释性有限且长期预测不稳定。

Method: 提出了一种名为FHNN（Floating-Body Hydrodynamic Neural Networks）的物理结构化框架，用于预测可解释的水动力学参数，并将其与运动的解析方程耦合。

Result: 在合成涡流数据集上，FHNN的误差比Neural ODE低一个数量级，并恢复了物理上一致的流场。

Conclusion: FHNN在处理耗散动力学方面比传统的Hamiltonian和Lagrangian神经网络更有效，同时保持了可解释性，弥合了黑盒学习与透明系统识别之间的差距。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [279] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: Transformer模型GPhyT在物理学领域实现了“一次训练，随处部署”的范式，能够模拟多种物理现象，无需重新训练，并展现出零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提供一个通用的物理基础模型（PFM），以普及高保真模拟，加速科学发现，并减少对专业求解器开发的需求。目前的物理感知机器学习方法仅限于狭窄的领域，并且需要为每个新系统重新训练。

Method: 提出通用物理Transformer（GPhyT），该模型在1.8 TB的多样化模拟数据上进行训练，利用Transformer推断动力学方程。

Result: GPhyT在多个物理领域取得了优于专门架构多达29倍的性能，并且能够通过上下文学习实现对未见过的物理系统的零样本泛化，还能通过50个时间步的滚动预测实现长期稳定预测。

Conclusion: 证明了单个模型仅通过数据即可学习可泛化的物理原理，为实现能够变革计算科学和工程的通用PFM铺平了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [280] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 提出了一种结合经典机器学习和量子神经网络（QNN）的混合方法，用于解决金融领域中数据稀疏的信用风险评估问题，并在量子云平台上进行了实验验证，取得了优于经典方法的性能。


<details>
  <summary>Details</summary>
Motivation: 金融领域中，特别是普惠金融，面临着数据稀疏和不平衡导致的信用风险评估模型效果不佳的挑战。

Method: 首先使用经典机器学习模型（逻辑回归、随机森林、XGBoost）进行特征工程和降维，然后利用参数迁移规则训练量子神经网络（QNN）作为核心分类器，最后在Quafu量子云平台的ScQ-P21处理器上进行了实验。

Result: 在真实世界信用数据集（279个样本）上，QNN在模拟中取得了0.852 +/- 0.027的平均AUC，在量子硬件实验中取得了0.88的AUC，性能超越了多个经典基准模型，在召回率方面表现尤为突出。

Conclusion: 该研究为在NISQ（嘈杂中等规模量子）时代将量子计算应用于数据受限的金融场景提供了一个实用的蓝图，并为在普惠金融等高风险应用中发挥其潜力提供了有价值的实证证据。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [281] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 本研究提出了一种将图神经网络（GNN）嵌入孔隙网络模型（PNM）的混合框架，用于准确预测多孔介质的渗透率。该方法结合了数据驱动的效率和物理模型的准确性，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确预测多孔介质中的渗透率对于模拟地下流动至关重要。传统方法存在计算效率、泛化能力或几何假设方面的不足。

Method: 提出了一种端到端可微分的混合框架，将 GNN 嵌入 PNM。GNN 替代了 PNM 中计算流导的解析公式，直接从孔隙和喉道特征预测流导。通过自动微分和离散伴随方法，实现了 GNN 和 PNM 求解器的全耦合端到端训练，仅使用标量渗透率作为训练目标。

Result: 与纯数据驱动模型和传统 PNM 方法相比，该模型在不同尺度上实现了更高的准确性和更好的泛化能力。梯度分析表明该模型具有物理一致性和可解释性。

Conclusion: 该混合框架为复杂多孔介质的渗透率预测提供了一种可扩展且物理信息丰富的方法，能够降低模型不确定性并提高准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [282] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 该研究提出了一种结合心脏数据填补和心血管力学模型个性化的概率框架，以解决临床研究中多模态患者数据不足的问题，特别是在脑部研究中心脏数据不完整的情况下。


<details>
  <summary>Details</summary>
Motivation: 临床研究中，由于缺乏代表不同解剖和生理过程的多模态患者数据，力学模型的应用受到限制。例如，神经影像数据集未能充分表示心脏特征，阻碍了对脑部疾病中心血管因素的建模。

Method: 研究引入了一个概率框架，用于从现有特征中联合推断心脏信息的填补模型，并结合高斯过程模拟器，以忠实地再现个性化的心血管动力学。

Result: 在UK Biobank的实验结果表明，该模型能够准确地填补仅包含收缩压和舒张压等少量心脏信息的脑部研究数据集中缺失的心脏特征，并同时估计集总模型的模拟参数。

Conclusion: 该方法能够通过模拟不同脑部解剖条件下逼真的心脏动力学，实现对心-脑联合关系的创新性探索。

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [283] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 掩蔽扩散模型(MDM)被解释为离散最优传输中的能量最小化问题。MDM在满足特定最优条件时，能最小化动能、条件动能和测地线能量。这种统一的理论框架不仅阐明了MDM的理论基础，还通过参数化插值表（使用Beta分布）激发了采样方法的改进，将表设计简化为二维搜索，便于在不修改模型的情况下进行微调。实验证明，所提出的能量启发式表在低步采样设置下优于手工设计的基线。 


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为掩蔽扩散模型（MDM）提供一个系统的理论框架，将其解释为离散最优传输中的能量最小化问题，并在此基础上提出改进采样的方法。

Method: 提出一个系统的理论框架，将MDM解释为离散最优传输中的能量最小化问题。证明了三种能量形式（动能、条件动能、测地线能量）在MDM结构下的等价性，并确定了MDM在满足特定最优条件时最小化这些能量。通过Beta分布参数化插值表，将表设计简化为二维搜索空间，并进行高效的微调。

Result: 实验结果表明，所提出的能量启发式插值表在合成和真实世界基准测试中，尤其是在低步采样设置下，表现优于手工设计的基线。

Conclusion: 本研究成功地将MDM统一在离散最优传输的能量最小化框架下，阐明了其理论基础，并通过能量启发式方法改进了采样效率，特别是在低步采样场景下。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [284] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: FedSSG是一种随机采样引导的历史感知漂移对齐方法，通过维护每个客户端的漂移内存并根据参与率调整本地对齐项，以解决联邦学习中非独立同分布数据和部分参与导致的客户端漂移和准确率损失问题。


<details>
  <summary>Details</summary>
Motivation: 非独立同分布数据和部分参与会导致联邦学习中的客户端漂移和局部最优不一致，从而引发收敛不稳定和准确率下降。

Method: FedSSG维护一个每个客户端的漂移内存，累积局部模型差异作为历史梯度的轻量级草图；关键在于，它通过一个平滑函数来控制内存更新和局部对齐项，该函数基于观察到的/预期的参与率（来自服务器采样器的基于期望的相位信号）。

Result: 在CIFAR-10/100数据集上，使用100/500个客户端和2-15%的参与率，FedSSG持续优于强大的感知漂移基线，并加速收敛，在基准测试中平均测试准确率提高约0.9（CIFAR-10）和2.7（CIFAR-100），并且平均收敛到目标准确率的速度提高了约4.5倍。

Conclusion: FedSSG表明，采样统计数据可以转化为一种有原则的、历史感知的相位控制，以稳定和加速联邦训练。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [285] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TFMAdapter是一个轻量级适配器，可以增强时间序列基础模型（TSFM）利用协变量信息进行预测，而无需进行微调。它通过学习一个非参数级联来结合协变量和TSFM的预测，并在真实数据集上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型（TSFM）在单变量预测方面表现出色，但无法有效利用协变量信息，而协变量对于许多实际应用中的准确预测至关重要。

Method: TFMAdapter通过一个轻量级的实例级适配器来增强TSFM。它在单次模型调用中，利用有限的历史信息，学习一个非参数级联，将协变量与TSFM的单变量预测相结合。为了在训练时限制TSFM的调用次数，TFMAdapter采用了两阶段的方法：首先使用简单的回归模型生成伪预测，然后训练一个高斯过程回归器，利用伪预测、TSFM预测和协变量来优化预测。

Result: TFMAdapter在真实世界数据集上的实验表明，与基础模型和监督基线相比，它能够持续获得更好的性能，比基础模型提高了24-27%，并且数据和计算开销极小。

Conclusion: 轻量级适配器有潜力弥合通用基础模型与特定领域预测需求之间的差距。

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [286] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: APFEx是第一个解决多重交叉公平性的框架，通过联合优化解决精确性和公平性之间的权衡，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能解决因种族、性别和年龄等交叉受保护属性而产生的复合偏差，导致对交叉群体存在细微的、乘性的偏差。

Method: APFEx采用自适应多目标优化器，该优化器能够动态切换帕累托锥投影、梯度加权和探索策略，以解决公平-准确性之间的权衡。它还使用可微分的交叉公平性指标来实现非平滑子群差异的基于梯度的优化，并具有收敛到帕累托最优解的理论保证。

Result: 在四个真实世界数据集上的实验表明，APFEx在保持具有竞争力的准确性的同时，减少了公平性违规行为，证明了其在解决交叉公平性方面的优越性。

Conclusion: APFEx通过提供一个可扩展、模型无关的解决方案，解决了公平机器学习中的一个关键差距，有效地解决了交叉公平性问题。

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [287] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 通过简单的置信度加权平均方法，将多个先进的深度学习轨迹预测模型集成起来，可以在不进行昂贵重新训练的情况下，提升预测性能10%，尤其是在长尾指标上，并在NuScenes和Argoverse数据集上均得到了验证。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶领域，随着越来越多的先进预测模型出现，如何有效结合这些模型而不进行昂贵的重新训练是一个重要的挑战。

Method: 提出一种简单的置信度加权平均方法，将多个预训练的先进深度学习模型进行集成。

Result: 在NuScenes和Argoverse数据集上，所提出的集成方法将轨迹预测性能提升了10%，并且在长尾指标上效果尤为显著。

Conclusion: 即使是简单的集成方法，如置信度加权平均，也能在不进行重新训练的情况下，有效提升多个先进轨迹预测模型的整体性能。

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [288] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 使用图神经网络解决GNSS干扰问题，通过实时预测和校正接收器水平偏差来提高定位精度。


<details>
  <summary>Details</summary>
Motivation: GNSS在被故意干扰时可用性会下降，而此时恰恰需要保持定位和授时功能正常。

Method: 将干扰缓解视为动态图回归问题，提出了一种以接收器为中心的深度时间图网络（HeteroGCLSTM），该网络可以实时预测并校正接收器的水平偏差。每个1 Hz的采样周期，卫星接收器环境被表示为一个异构星图，并使用包含时变属性的单层HeteroGCLSTM来聚合空间和时间信息，输出2D偏差向量进行实时校正。

Result: 在两种不同接收器和三种干扰（连续波、三音调、宽带FM）的多种功率级别下进行评估，与MLP、CNN等基线模型相比，该模型始终获得最低的平均绝对误差（MAE）。在-45 dBm时，MAE在3.64 cm到7.74 cm之间；在-60到-70 dBm时，MAE提高到1.65-2.08 cm。在混合模式数据集上，MAE为3.78 cm（GP01）和4.25 cm（ublox10）。在仅使用10%训练数据的情况下，该模型仍表现出优越的数据效率（20 cm vs. 36-42 cm）。

Conclusion: 提出的HeteroGCLSTM模型在GNSS干扰下能够有效预测和校正接收器的水平偏差，显著优于现有基线方法，并在数据效率方面也表现出色。

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [289] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: Localized epidemic forecasting using federated learning with differential privacy achieves strong privacy guarantees and useful predictions.


<details>
  <summary>Details</summary>
Motivation: Localized epidemic forecasting is crucial for swift reaction but faces data limitations and privacy concerns. Centralizing data is challenging due to sensitivity and privacy constraints. This paper addresses the need for a privacy-preserving localized strategy using federated learning.

Method: The study proposes a privacy-preserving forecasting method using federated learning (FL) with client-level differential privacy (DP). A shared multilayer perceptron is trained on case count data. Clients exchange norm-clipped updates, and the server aggregates these updates with DP noise. The framework treats counties/communities/local health authorities as clients.

Result: The DP-FL model, at a moderately strong privacy level, achieved results comparable to a non-DP model: R^2=0.94 (vs. 0.95) and MAPE of 26% in Nov 2020; R^2=0.88 (vs. 0.93) and MAPE of 21% in Mar 2022. Very strict privacy settings led to unusable forecasts, while moderate settings maintained utility.

Conclusion: Client-level DP-FL can provide valuable county-level epidemic predictions with robust privacy protections. The viability of privacy budgets is dependent on the epidemic phase, enabling privacy-compliant collaboration among health authorities for local forecasting.

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [290] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 研究提出了一种基于环境传感器融合（温度、湿度、内外压差）的轻量级、多模态蜂后检测系统，可在STM32微控制器上进行实时、低功耗的边缘计算，准确率超过99%，且无需音频特征，为精准养蜂提供了一种可扩展、可持续的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的蜜蜂蜂后监测方法依赖于耗时、干扰大且不适合大规模养蜂的手动检查。虽然基于音频的方法有潜力，但存在功耗高、预处理复杂和易受环境噪声干扰等问题。

Method: 提出了一种基于环境传感器（温度、湿度、内外压差）融合的轻量级、多模态系统，并在商用STM32微控制器上使用量化决策树推理，实现实时、低功耗的边缘计算。

Result: 该系统仅使用环境输入即可实现超过99%的蜂后检测准确率，音频特征并未带来显著的性能提升。

Conclusion: 该研究提出了一种可扩展、可持续的非侵入式蜂巢监测解决方案，利用现成的、节能的硬件，为实现自主、精准的养蜂铺平了道路。

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [291] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 本文研究了贝叶斯风险规避在强化学习中的应用，提出了一种考虑模型参数不确定性的方法，并推导了贝叶斯风险值函数与原始值函数的差异特征。结果表明，该方法会悲观地低估值函数，且这种低估程度与风险规避程度成正比，与数据量成反比。在此基础上，文章将该方法应用于在线强化学习和上下文多臂老虎机问题，并通过后验采样设计了相应算法，证明了其具有亚线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据不足导致的认知不确定性问题，本研究采用了贝叶斯风险马尔可夫决策过程（BRMDP）来处理未知模型参数的不确定性。

Method: 本研究推导了贝叶斯风险值函数与原始值函数在真实未知分布下差异的渐近正态性。并利用该性质，在在线强化学习和在线上下文多臂老虎机（CMAB）问题中，通过后验采样设计了通用强化学习和CMAB问题的两种算法。

Result: 研究表明，贝叶斯风险规避方法倾向于悲观地低估原始值函数，这种差异随着风险规避程度的增强而增大，随着数据量的增加而减小。所提出的算法在通用RL和CMAB设置下均实现了亚线性遗憾界。此外，在CMAB设置下，以贝叶斯风险遗憾为定义的遗憾也实现了亚线性界。

Conclusion: 所提出的算法能够有效地处理认知不确定性，并验证了理论性质。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [292] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 本研究比较了不同优化器在不同脑电图（EEG）频带上的分类器性能，并评估了左右半球的高效类别预测。


<details>
  <summary>Details</summary>
Motivation: 评估不同优化器和神经网络架构在脑电图（EEG）频带上的分类器性能，并识别高效类别预测的因素。

Method: 实现了深度密集网络、浅层三层网络和卷积神经网络（CNN），并使用TensorFlow和PyTorch进行了比较。利用SHAP图分析了EEG频带对模型准确性的贡献。

Result: Adagrad和RMSprop优化器在不同频带上表现稳定，Adadelta在跨模型评估中表现稳健。CNN在捕捉空间特征方面表现优异，深度密集网络在学习复杂模式方面具有竞争力，浅层网络在计算效率方面表现突出。

Conclusion: 优化器的选择、模型架构和EEG频带分析对于提高分类器性能和理解神经影像学分类任务中的特征重要性至关重要。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [293] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 本文提出了一种名为“Quantile Neural Basis Model”的新型神经网络模型，用于解决多期概率预测中神经网络可解释性差的问题。该模型将Quantile Generalized Additive Models的可解释性原理融入神经网络训练框架，并采用共享基分解和权重分解技术，在不依赖任何参数分布假设的情况下，实现了与现有模型相当的预测性能，同时还能提供关于模型如何从输入特征映射到输出预测的宝贵见解。


<details>
  <summary>Details</summary>
Motivation: 当前多期概率预测中的神经网络虽然预测精度高，但其特征条件输出的底层机制对预测者来说仍难以理解。因此，需要一个能够提高模型可解释性的方法。

Method: 提出Quantile Neural Basis Model，该模型将Quantile Generalized Additive Models的可解释性原理嵌入到端到端的神经网络训练框架中。利用共享基分解和权重分解技术，避免了参数分布假设。

Result: 在日前电力价格预测任务上进行了验证，取得了与分布和分位数回归神经网络相当的预测性能。

Conclusion: Quantile Neural Basis Model在保持高预测精度的同时，能够提供对模型行为的宝贵见解，揭示了输入特征到输出预测的非线性映射关系，解决了现有神经网络可解释性差的问题。

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [294] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 本研究通过与卡内基梅隆大学合作，在约翰逊县开展了针对性的心理健康外展服务，以期减少重犯率。


<details>
  <summary>Details</summary>
Motivation: 许多被监禁的个人面临心理疾病、物质依赖和无家可归等复杂挑战，而监狱和看守所往往缺乏足够的资源来解决这些问题。现有刑事司法系统支持不足，可能导致这些问题恶化，引发进一步的犯罪和监禁循环，对个人、公众安全以及少数族裔社区造成负面影响。

Method: 本研究描述了所使用的数据、预测模型方法和结果，以及实地试验的设计和分析，旨在确认模型的预测能力，评估目标外展的影响，并了解何种再监禁风险水平下外展最为有效。

Result: 研究发现，该模型能高度预测新的监狱预订，在试验的最高风险群体中，超过一半的人在次年重返监狱。外展服务对最高风险个体最为有效，对心理健康利用、急救医疗派遣和刑事司法参与产生了影响。

Conclusion: 针对高风险重犯个体进行心理健康外展，可以有效降低再监禁率，并对心理健康服务利用、急救医疗派遣和刑事司法参与产生积极影响。

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [295] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: 该研究提出了一种组合核岭回归模型，通过坐标重加权实现特征学习，并证明了其在变量选择和噪声剔除方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索一种用于特征学习的组合核岭回归模型，并从变量选择的角度分析其性能。

Method: 提出了一种组合核岭回归模型，将其表述为变分问题，并分析了其在恢复相关变量和剔除噪声变量方面的表现，特别是针对高斯噪声。

Result: 研究表明，该模型能够有效恢复相关变量并剔除噪声变量。全局最小化点和稳定点在噪声变量为高斯分布时，均能剔除噪声坐标。$\\ell_1$-型核（如拉普拉斯核）在稳定点能够恢复非线性特征，而高斯核只能恢复线性特征。

Conclusion: 该组合核岭回归模型为特征学习提供了一个简单的测试平台，并证明了其在变量选择和噪声剔除方面的有效性，特别是$\\ell_1$-型核在恢复非线性特征方面优于高斯核。

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [296] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 该研究提出了一种端到端的框架，利用人工智能、新的数据生成策略（PCDS）和贝叶斯推理，从稀疏的常规数据中无创地估计不可测量的参数，以解决眼科领域（如青光眼）的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于无法测量关键参数（如房水网格膜渗透性），临床上在治疗青光眼等疾病时面临挑战，并且在计算上也难以解决此类病态逆问题，因为缺乏真实数据和高保真模拟成本高昂。

Method: 研究人员开发了一个端到端的框架，结合了多阶段人工智能架构来分离问题，提出了一种称为PCDS的新型数据生成策略以减少模拟时间，并使用贝叶斯引擎来量化不确定性。

Result: 该框架能够从单一的眼压测量值中推断出不可测量的组织渗透性和患者的房水流出 facility。无创估计的房水流出 facility 与最先进的眼压测量技术具有良好的一致性，并且新兴的渗透性生物标志物在根据疾病风险对临床队列进行分层方面表现出高精度。

Conclusion: 该框架为解决其他数据稀疏、计算密集型领域的类似逆问题提供了一个可推广的蓝图，并强调了其在诊断方面的潜力。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [297] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: 该研究提出了TopoSizing框架，用于改进模拟和混合信号电路设计中的自动化流程。它结合了图算法和大型语言模型（LLM）来理解电路结构，并将这些知识融入优化过程，以提高效率和可行性。


<details>
  <summary>Details</summary>
Motivation: 传统电路设计方法在数据量、领域知识嵌入、优化效率和可解释性方面存在挑战。现有方法要么缺乏电路理解能力，要么成本高昂且泛化性差。LLM虽然有潜力，但常需人工干预。

Method: TopoSizing框架首先使用图算法将电路组织成层次化的设备-模块-阶段表示。然后，LLM代理通过迭代的假设-验证-精炼循环进行一致性检查，生成显式注解。最后，将验证后的见解整合到贝叶斯优化中，通过LLM引导的初始采样和停滞触发的信任区域更新来提高效率和可行性。

Result: TopoSizing框架通过将电路结构知识转化为优化收益，显著提高了优化效率和可行性。

Conclusion: TopoSizing框架通过结合图算法和LLM，实现了对电路的鲁棒理解，并将其转化为优化增益，解决了传统方法在数据、知识嵌入和优化效率方面的痛点。

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [298] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: TGPO是一种离线强化学习框架，通过树状轨迹表示、过程奖励模型和动态加权机制，解决了大型语言模型作为Web代理进行训练时面临的信用分配错误、标注成本高和奖励稀疏等挑战，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型和视觉语言模型的快速发展，使用大型模型作为Web代理已成为自动化Web交互的关键。然而，使用强化学习训练Web代理面临信用分配错误、标注成本过高和奖励稀疏等严峻挑战。

Method: 提出了一种名为Tree-Guided Preference Optimization (TGPO) 的离线强化学习框架。该框架采用树状结构轨迹表示，合并语义上相同的状态以消除标签冲突。此外，还包含一个过程奖励模型，通过子目标进展、冗余检测和动作验证自动生成细粒度奖励。同时，利用动态加权机制在训练中优先考虑高影响力决策点。

Result: 在Online-Mind2Web和自建的C-WebShop数据集上进行实验，结果表明TGPO显著优于现有方法，以更少的冗余步骤实现了更高的成功率。

Conclusion: TGPO框架通过其创新的方法有效解决了在训练Web代理时遇到的核心挑战，并在实际应用中取得了优越的性能。

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [299] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: TimeAlign是一个即插即用的框架，通过学习辅助特征来弥合输入历史和未来目标之间的分布差距，从而提高时间序列预测的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管表示学习在时间序列预测中已被探索，但现有最先进的预测器很少采用这些方法，因为它们没有显示出明显的性能优势。本研究挑战了这一观点，认为显式的表示对齐可以提供关键信息，以弥合输入历史和未来目标之间的分布差距。

Method: TimeAlign框架通过一个简单的重建任务来学习辅助特征，并将这些特征反馈给任何基础预测器。该框架是轻量级的、即插即用的，并且不依赖于特定的模型架构。

Result: 在八个基准测试的广泛实验中，TimeAlign 证明了其优越的性能。进一步的研究表明，性能的提升主要归因于纠正了历史输入和未来输出之间的频率不匹配。此外，研究还提供了理论依据，证明了 TimeAlign 在增加学习到的表示与预测目标之间的互信息方面的有效性。

Conclusion: TimeAlign 作为一个通用的对齐模块，可以集成到现代深度学习时间序列预测系统中，以提高性能，同时几乎不增加计算开销。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [300] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 本研究提出了Banach-Bregman框架，统一了多种随机优化方法，并在非欧几里得空间中实现了加速收敛，提高了AI任务的效率。


<details>
  <summary>Details</summary>
Motivation: 现有随机优化理论主要局限于希尔伯特空间，无法处理非欧几里得设置，如镜面下降、Bregman近邻方法、自然梯度下降和KL散度正则化的语言模型训练等。

Method: 提出了一种新的Banach-Bregman框架，利用Bregman投影和Bregman-Fejer单调性，统一了随机逼近、镜面下降、自然梯度、自适应方法和镜面-Prox等多种优化算法。该框架支持超松弛（λ > 2），适用于灵活的几何设置，并解释了其加速效应。

Result: 在UCI基准测试、Transformer训练、Actor-Critic强化学习和WikiText-2数据集（使用distilGPT-2）上的实证研究表明，与传统方法相比，收敛速度提高了20%，方差降低，准确性提高。

Conclusion: Banach-Bregman几何为统一优化理论和实践奠定了基础，为AI核心范式提供了理论支撑，并为实际应用带来了显著的性能提升。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [301] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: RKTV-INR框架通过结合Runge-Kutta积分和全变分约束，直接从噪声观测中学习隐式神经表征，以去噪非线性动力系统轨迹，并为SINDy提供准确的状态和导数信息以识别系统方程。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的非线性动力系统建模常受测量噪声的干扰。

Method: 提出了一种名为RKTV-INR的去噪框架，该框架将Runge-Kutta积分和全变分作为约束，直接将状态轨迹表示为隐式神经表示（INR），并直接拟合到噪声观测中。然后，将去噪后的状态和导数提供给SINDy以恢复控制方程。

Result: 实验证明了该框架能够有效抑制噪声，精确估计导数，并可靠地识别系统。

Conclusion: RKTV-INR框架能够从噪声观测中恢复非线性动力系统的控制方程。

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [302] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 语言模型可以根据信息学习时间区分信息。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否能区分信息学习的时间，以及这种区分的机制。

Method: 通过在六个独立的但相似的数据集上顺序微调Llama-3.2-1B模型，创建一个具有已知训练顺序的模型。然后分析测试样本的平均激活值，并使用线性探针来区分“早期”和“晚期”学习的实体。

Result: 模型在2D子空间中的质心排列顺序与训练顺序一致，位于一条直线上。线性探针能够准确区分早期和晚期学习的实体（约90%的准确率），并泛化到未见过的数据。模型还能通过微调来报告实体学习阶段（约80%的准确率）。这种时间信号并非源于激活幅度、损失或模型置信度的简单差异。

Conclusion: 语言模型能够区分信息获取的时间，这对于理解模型如何处理冲突数据和知识更新具有重要意义。

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [303] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 提出了一种利用高阶 Langevin 动力学防御扩散模型成员推断攻击的方法，该方法通过引入辅助变量和联合扩散过程来增强模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的广泛应用，数据安全问题日益凸显，特别是针对训练数据隐私的成员推断攻击。本研究旨在防御扩散模型中的成员推断攻击，尽管扩散模型相比其他生成模型具有一定的抗攻击性，但仍存在安全隐患。

Method: 提出了一种基于关键阻尼高阶 Langevin 动力学（critically-damped higher-order Langevin dynamics）的防御方法。该方法引入了多个辅助变量和一个联合扩散过程，旨在通过辅助变量引入外部随机性，在扩散过程的早期阶段破坏敏感输入数据，从而抵御成员推断攻击。

Result: 该方法在理论上进行了研究，并在一个玩具数据集和一个语音数据集上进行了验证。评估指标包括接收者操作特征曲线下面积（AUROC）和 Fréchet Inception Distance（FID）。

Conclusion: 所提出的基于关键阻尼高阶 Langevin 动力学的方法能够有效防御扩散模型的成员推断攻击，并在实验中得到了验证。

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [304] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA是一种新的大模型结构化剪枝方法，能在保持性能的同时减少模型大小，并且无需昂贵的微调。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法在零样本设置下性能下降明显，且需要昂贵的恢复技术。

Method: NIRVANA使用基于神经网络切线核（Ntk）的一阶显著性标准，并结合了自适应稀疏分配机制，根据注意力机制和MLP模块的不同重要性来调整剪枝强度。此外，还采用基于KL散度的校准数据选择策略来提高剪枝结果的可靠性。

Result: 在Llama3、Qwen和T5模型上的实验表明，NIRVANA在同等稀疏度下优于现有方法，能够更好地保留模型的零样本准确性，并为后续微调提供更好的基础。

Conclusion: NIRVANA是一种有理论依据且实用的LLM压缩方法，能够有效解决现有结构化剪枝方法的不足。

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [305] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: 通过计算即教师（CaT）方法，将模型推理时自身的探索转化为无参考监督信号，用于解决无真实标签的训练后学习问题。


<details>
  <summary>Details</summary>
Motivation: 在缺乏真实标签的训练后学习场景中，需要寻找新的学习信号来源。

Method: CaT方法通过合成一个参考信号（由初始策略协调得出）并进行优化，将模型推理时的探索转化为监督信号。对于可验证任务，使用最终答案的程序等价性；对于不可验证任务，使用独立LLM法官评分的自设标准。

Result: CaT方法在MATH-500和HealthBench等基准测试中，显著提升了Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B模型的性能。结合强化学习（CaT-RL）后，性能进一步提升。

Conclusion: CaT方法提供了一种有效的训练后学习解决方案，能够将模型的探索转化为有用的监督信号，并在多种基准测试中取得显著效果。

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [306] [All Models Are Wrong, But Can They Be Useful? Lessons from COVID-19 Agent-Based Models: A Systematic Review](https://arxiv.org/abs/2509.13346)
*Emma Von Hoene,Sara Von Hoene,Szandra Peter,Ethan Hopson,Emily Csizmadia,Faith Fenyk,Kai Barner,Timothy Leslie,Hamdi Kavak,Andreas Zufle,Amira Roess,Taylor Anderson*

Main category: cs.MA

TL;DR: COVID-19 疫情催生了大量计算模型，其中基于主体的模型（ABMs）在模拟疾病传播方面得到广泛应用。然而，这些模型的实用性引发了对健康政策制定的质疑。本研究系统性地回顾了 2020 年 1 月至 2023 年 12 月期间发表的 536 篇 COVID-19 ABM 研究，并根据模型可用性的九个标准进行了评估。结果发现，虽然大多数模型探讨了行为或政策干预措施，但很少有模型用于实时预测。模型的透明度、代码共享和复用率普遍较低，标准化报告和利益相关者参与的实践也十分罕见。尽管不确定性常被量化，但只有极少数模型采用了全面的验证框架。研究建议，需要制定更严格的标准，以确保 ABM 在未来的公共卫生危机中能够作为可靠的决策支持工具。


<details>
  <summary>Details</summary>
Motivation: 评估 COVID-19 疫情期间基于主体模型（ABMs）在模拟疾病动态和指导公共卫生政策方面的实用性，并识别其在透明度、可访问性和参与性方面的不足，以期为未来公共卫生危机提供决策支持工具的改进建议。

Method: 系统性回顾了 2020 年 1 月至 2023 年 12 月发表的 536 篇关于 COVID-19 ABM 的研究。研究评估了九个模型实用性标准，包括透明度、代码共享、利益相关者参与和验证实践等。

Result: 大多数模型（54.85%）用于探索行为或政策干预，而很少（1.68%）用于实时预测。模型假设的描述率较高（91.60%），但局限性披露（65.11%）、代码共享（40.86%）和基于现有模型（36.38%）的比例较低。标准化报告（6.72%）和利益相关者参与（13.62%）非常罕见。只有 2.24% 的模型描述了全面的验证框架，但 75.93% 的模型量化了不确定性。模型发表在 2021 年底达到顶峰，并集中在少数国家。

Conclusion: 尽管 COVID-19 ABM 发展迅速，但在透明度、可访问性和参与性方面存在明显不足。为使 ABM 成为未来公共卫生危机中可靠的决策支持工具，需要制定更强的标准。

Abstract: The COVID-19 pandemic prompted a surge in computational models to simulate
disease dynamics and guide interventions. Agent-based models (ABMs) are
well-suited to capture population and environmental heterogeneity, but their
rapid deployment raised questions about utility for health policy. We
systematically reviewed 536 COVID-19 ABM studies published from January 2020 to
December 2023, retrieved from Web of Science, PubMed, and Wiley on January 30,
2024. Studies were included if they used ABMs to simulate COVID-19
transmission, where reviews were excluded. Studies were assessed against nine
criteria of model usefulness, including transparency and re-use,
interdisciplinary collaboration and stakeholder engagement, and evaluation
practices. Publications peaked in late 2021 and were concentrated in a few
countries. Most models explored behavioral or policy interventions (n = 294,
54.85%) rather than real-time forecasting (n = 9, 1.68%). While most described
model assumptions (n = 491, 91.60%), fewer disclosed limitations (n = 349,
65.11%), shared code (n = 219, 40.86%), or built on existing models (n = 195,
36.38%). Standardized reporting protocols (n = 36, 6.72%) and stakeholder
engagement were rare (13.62%, n = 73). Only 2.24% (n = 12) described a
comprehensive validation framework, though uncertainty was often quantified (n
= 407, 75.93%). Limitations of this review include underrepresentation of
non-English studies, subjective data extraction, variability in study quality,
and limited generalizability. Overall, COVID-19 ABMs advanced quickly, but
lacked transparency, accessibility, and participatory engagement. Stronger
standards are needed for ABMs to serve as reliable decision-support tools in
future public health crises.

</details>


### [307] [Inject, Fork, Compare: Defining an Interaction Vocabulary for Multi-Agent Simulation Platforms](https://arxiv.org/abs/2509.13712)
*HwiJoon Lee,Martina Di Paola,Yoo Jin Hong,Quang-Huy Nguyen,Joseph Seering*

Main category: cs.MA

TL;DR: LLM驱动的多智能体模拟：通过注入、分叉和比较操作，将线性工作流转变为可交互、可探索的空间，促进对LLM模拟的因果研究。


<details>
  <summary>Details</summary>
Motivation: 当前LLM多智能体模拟在交互和分析模式方面存在不足，限制了“假设”场景的研究。本研究旨在通过定义核心操作来解决这一问题。

Method: 定义并演示了三个核心操作：注入（Inject）、分叉（Fork）和比较（Compare）。注入允许在模拟执行的任何点引入外部事件；分叉可以从任何时间点创建独立的时间线分支，保留完整状态并进行探索；比较则支持对多个分支进行并行观察，揭示不同干预措施导致的不同涌现行为。

Result: 通过一个包含十四个AI智能体的商品市场模拟演示了这些操作，研究人员可以注入对比事件，并在并行时间线上观察到不同的结果。

Conclusion: 通过定义这些基本操作，为LLM智能体模拟中的系统性因果研究提供了一个起点，将研究从被动观察转向主动实验。

Abstract: LLM-based multi-agent simulations are a rapidly growing field of research,
but current simulations often lack clear modes for interaction and analysis,
limiting the "what if" scenarios researchers are able to investigate. In this
demo, we define three core operations for interacting with multi-agent
simulations: inject, fork, and compare. Inject allows researchers to introduce
external events at any point during simulation execution. Fork creates
independent timeline branches from any timestamp, preserving complete state
while allowing divergent exploration. Compare facilitates parallel observation
of multiple branches, revealing how different interventions lead to distinct
emergent behaviors. Together, these operations establish a vocabulary that
transforms linear simulation workflows into interactive, explorable spaces. We
demonstrate this vocabulary through a commodity market simulation with fourteen
AI agents, where researchers can inject contrasting events and observe
divergent outcomes across parallel timelines. By defining these fundamental
operations, we provide a starting point for systematic causal investigation in
LLM-based agent simulations, moving beyond passive observation toward active
experimentation.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [308] [Proximity Ferroelectricity in Compositionally Graded Structures](https://arxiv.org/abs/2509.13443)
*Eugene A. Eliseev,Anna N. Morozovska,Sergei V. Kalinin,Long-Qing Chen,Venkatraman Gopalan*

Main category: cond-mat.mtrl-sci

TL;DR: 本论文提出了一种在非铁电极性材料中诱导铁电性的新范例——近邻铁电性。通过将非铁电材料（如AlN或ZnO）与可切换的铁电层（如Al1-xScxN或Zn1-xMgxO）直接接触，可以实现实用化的极化切换。


<details>
  <summary>Details</summary>
Motivation: AlN或ZnO等非铁电极性材料通常在介电击穿场强以下是不可切换的，本研究旨在解决这一限制，探索诱导其铁电性的新方法。

Method: 利用Landau-Ginzburg-Devonshire热力学理论，对平行板电容器和尖探针-平面电极几何结构中的AlN-Al1-xScxN、ZnO-Zn1-xMgxO和MgO-Zn1-xMgxO成分梯度结构中的极化切换进行了有限元建模。

Result: 研究表明，成分梯度结构能够以远低于不可切换材料击穿场强的场强实现整个系统的自发极化同时切换。其物理机制源于化学成分梯度“x”产生的去极化电场，该电场降低了不可切换部分的切换势垒或在MgO类区域诱导了浅双阱自由能势。尖探针-平面电极几何结构中的近邻铁电切换则通过尖端下的纳米畴形成实现。此外，预测成分梯度能够显著降低AlN-Al1-xScxN和ZnO-Zn1-xMgxO体系的有效矫顽场。

Conclusion: 本研究成功地通过成分梯度设计，在近邻铁电材料中实现了有效的极化切换，并揭示了其背后的物理机制，为开发新型铁电器件提供了理论基础。

Abstract: Proximity ferroelectricity is a novel paradigm for inducing ferroelectricity
in a non-ferroelectric polar material such as AlN or ZnO that are typically
unswitchable with an external field below their dielectric breakdown field.
When placed in direct contact with a thin switchable ferroelectric layer (such
as Al1-xScxN or Zn1-xMgxO), they become a practically switchable ferroelectric.
Using the thermodynamic Landau-Ginzburg-Devonshire theory, in this work we
performed the finite element modeling of the polarization switching in the
compositionally graded AlN-Al1-xScxN, ZnO-Zn1-xMgxO and MgO-Zn1-xMgxO
structures sandwiched in both a parallel-plate capacitor geometry as well as in
a sharp probe-planar electrode geometry. We reveal that the compositionally
graded structure allows the simultaneous switching of spontaneous polarization
in the whole system by a coercive field significantly lower than the electric
breakdown field of unswitchable polar materials. The physical mechanism is the
depolarization electric field determined by the gradient of chemical
composition "x". The field lowers the steepness of the switching barrier in the
otherwise unswitchable parts of the compositionally graded AlN-Al1-xScxN and
ZnO-Zn1-xMgxO structures, while it induces a shallow double-well free energy
potential in the MgO-like regions of compositionally graded MgO-Zn1-xMgxO
structure. Proximity ferroelectric switching of the compositionally graded
structures placed in the probe-electrode geometry occurs due to nanodomain
formation under the tip. We predict that a gradient of chemical composition "x"
significantly lowers effective coercive fields of the compositionally graded
AlN-Al1-xScxN and ZnO-Zn1-xMgxO structures compared to the coercive fields of
the corresponding multilayers with a uniform chemical composition in each
layer.

</details>


### [309] [Persistent Interfacial Topological Hall Effect Demonstrating Electrical Readout of Topological Spin Structures in Insulators](https://arxiv.org/abs/2509.13445)
*Jing Li,Huilin Lai,Andrew H. Comstock,Aeron McConnell,Bharat Giri,Yu Yun,Tianhao Zhao,Xiao Wang,Yongseong Choi,Xuemei Cheng,Jian Shen,Zhigang Jiang,Dali Sun,Wenbin Wang,Xiaoshan Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过磁性邻近效应，在绝缘磁体中引入界面拓扑霍尔效应（ITHE）以解决传统拓扑霍尔效应的局限性，并在Pt/h-LuFeO3双层结构中实现了ITHE，该效应具有巨大的霍尔响应和优越的稳定性，可用于探测超薄绝缘薄膜中的拓扑磁性。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑霍尔效应（THE）需要导磁体，这使得绝缘系统在很大程度上无法被研究。本研究旨在引入一种新的效应，使得能够研究绝缘磁体的拓扑磁性。

Method: 通过磁性邻近效应（MPE），将绝缘磁体（h-LuFeO3）的非共面自旋结构 imprinted 到相邻的重金属（Pt）上，并通过电器方式检测。具体而言，研究了Pt/h-LuFeO3双层结构，其中h-LuFeO3具有由120度三角形自旋晶格产生的拓扑自旋结构。

Result: 在Pt/h-LuFeO3双层结构中，观察到了巨大的霍尔响应（高达纵向电阻的0.5%）和高霍尔电导率/磁化比（>2 V^{-1}）。该效应与自旋霍尔霍尔效应背景有明显区别。研究还发现，Pt纳米团簇通过MPE继承了h-LuFeO3的拓扑结构。与传统的THE不同，ITHE在高达14T的宽磁场范围内持续存在，表明其潜在的拓扑自旋结构的稳定性。

Conclusion: 界面拓扑霍尔效应（ITHE）是一种有效且灵敏的探测超薄绝缘薄膜中拓扑磁性的方法，并为新的自旋电子学应用开辟了道路。

Abstract: Conventional topological Hall effects (THE) require conducting magnets,
leaving insulating systems largely inaccessible. Here we introduce the
interfacial topological Hall effect (ITHE), where the noncoplanar spin textures
of insulating magnets are imprinted onto an adjacent heavy metal via the
magnetic proximity effect (MPE) and detected electrically. In Pt/h-LuFeO3
bilayers, h-LuFeO3 hosts a topological spin structure robust against high
magnetic fields, arising from a 120{\deg} triangular spin lattice with small
spin canting that yields nontrivial topology but minimal magnetization. This
generates a giant Hall response in Pt up to 0.5% of the longitudinal
resistivity and a Hall-conductivity/magnetization ratio above 2 V^{-1}, clearly
distinguishable from the spin Hall Hanle effect background. Field- and
temperature-dependent analysis further reveals that Pt nanoclusters inherit
topological textures from h-LuFeO3 via MPE. Unlike the conventional THE narrow
peak-and-dip features, ITHE in Pt/h-LuFeO3 persists across a broad magnetic
field range up to 14 T, demonstrating the exceptional stability of the
underlying topological spin structure. This establishes ITHE as a powerful and
sensitive probe for topological magnetism in ultrathin insulating films and
paves the way for new spintronic applications.

</details>


### [310] [Field-Angle Dependence of Phonon Thermal Hall Effect in Na2X2TeO6 (X = Co, Zn)](https://arxiv.org/abs/2509.13456)
*Jian Yan,Hikaru Takeda,Haruka Iwahata,Jun-ichi Yamaura,Rajesh Kumar Ulaganathan,Kalaivanan Raju,Raman Sankar,Minoru Yamashita*

Main category: cond-mat.mtrl-sci

TL;DR: 材料中的声子热霍尔效应机制尚不明确。通过比较热霍尔效应和磁各向异性的磁场角度依赖性，可以区分基于贝里相和杂质散射的机制。研究了Na2Co2TeO6和Na2Zn2TeO6中的热霍尔效应，发现两者在ac平面的磁场角度依赖性都与垂直磁化强度一致，表明两种材料中都存在由杂质诱导的散射机制。


<details>
  <summary>Details</summary>
Motivation: 阐明材料中热霍尔效应（由声子引起）的机制，因为声子是主要的传热载流子，但其机制尚未得到充分解释。

Method: 比较了反铁磁体Na2Co2TeO6及其非磁性类似物Na2Zn2TeO6在ac平面上的热霍尔效应和磁各向异性的磁场角度依赖性。

Result: 在两种材料中，热导率的磁场角度依赖性都与垂直磁化强度的磁场角度依赖性一致。这表明声子热霍尔效应和声子-磁耦合增强的热霍尔效应具有共同的机制，即由杂质引起的散射。

Conclusion: 在Na2Co2TeO6和Na2Zn2TeO6中，热霍尔效应是由杂质诱导的散射引起的，这与磁性耦合无关。

Abstract: The mechanism behind thermal Hall effects by phonons, which are observed in
various materials, is not clarified despite the dominant contribution as heat
carriers. Theoretically, mechanisms based on the intrinsic Berry phase and
those on extrinsic impurity-induced scatterings have been proposed, which can
be distinguished by comparing the field-angle dependence of the thermal Hall
effect and that of the magnetic anisotropy. Here, we investigate the
field-angle dependence of the thermal Hall effects in the antiferromagnet
Na2Co2TeO6 and its non-magnetic isostructural analogue Na2Zn2TeO6 in the ac
plane. We find that the field-angle dependence of the thermal Hall conductivity
in both materials well follows that of the out-of-plane magnetization, showing
a common mechanism by extrinsic impurity-induced scatterings in both the phonon
thermal Hall effect and that enhanced by a coupling with the magnetism.

</details>


### [311] [Li+/H+ exchange in solid-state oxide Li-ion conductors](https://arxiv.org/abs/2509.13477)
*Zhuohan Li,Benjamin X. Lam,Gerbrand Ceder*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化物离子导体在水分存在下会发生离子交换，这会影响其在固态电池中的应用。


<details>
  <summary>Details</summary>
Motivation: 了解氧化物离子导体在水分下的稳定性对于固态电池的应用至关重要。

Method: 结合密度泛函理论（DFT）计算和机器学习原子间势模型，研究了石榴石和NASICON两大类氧化物离子导体中Li+/H+交换的驱动力。

Result: 锂含量高的石榴石结构比锂含量低的结构更易发生Li+/H+交换。NASICON结构对质子交换的抵抗能力更强，这归因于其较低的锂化学势和较低的O-H键共价性。

Conclusion: 提高锂含量可以增强离子导电性，但也会增加水分降解的风险。设计离子导体时，需要在高电导率和高稳定性之间进行权衡。

Abstract: Understanding the moisture stability of oxide Li-ion conductors is important
for their practical applications in solid-state batteries. Unlike sulfide or
halide conductors, oxide conductors generally better resist degradation when in
contact with water, but can still undergo topotactic ion exchange between Li
ions within the structure and protons in the environment. In this work, we
combine density functional theory (DFT) calculations with a machine-learning
interatomic potential model to investigate the thermodynamic driving force of
the Li+/H+ exchange reaction for two representative oxide Li-ion conductor
families: garnets and NASICONs. Our results indicate that the high Li chemical
potential in Li-stuffed garnets is responsible for the stronger driving force
for exchanging Li with protons as compared to the Li-unstuffed structures. In
contrast, NASICONs demonstrate a higher resistance against proton exchange,
which is attributed to the lower Li chemical potential and the lower O-H bond
covalency for polyanion-bonded oxygens. Our findings highlight the trade-off
when using Li stuffing as a mechanism to enhance Li-ion conductivity, as it
also promotes degradation by moisture. This study underscores the importance of
designing Li-ion conductors that not only possess high conductivity, but also
exhibit high stability in practical environments.

</details>


### [312] [From Data to Alloys Predicting and Screening High Entropy Alloys for High Hardness Using Machine Learning](https://arxiv.org/abs/2509.13479)
*Rahul Bouri,Manikantan R. Nair,Tribeni Roy*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习被用于预测高熵合金的硬度，以加速其研发。


<details>
  <summary>Details</summary>
Motivation: 高熵合金在极端环境下具有优越性能，但其研发耗时且成本高，需要机器学习加速。此外，本文还提出了一种基于语言模型的方法。

Method: 使用LightGBM、Gradient Boosting Regressor和Transformer encoder等机器学习模型，以及一个经过微调的语言模型，从原子半径、价电子数、键能等元素描述符预测高熵合金的硬度。

Result: LightGBM模型在预测高熵合金硬度方面表现出比其他模型更好的准确性。通过组合技术生成了超过900万个候选合金，并利用机器学习模型预测了它们的硬度。

Conclusion: 机器学习驱动的高通量筛选和语言建模方法可以加速下一代高熵合金的开发。

Abstract: The growing need for structural materials with strength, mechanical
stability, and durability in extreme environments is driving the development of
high entropy alloys. These are materials with near equiatomic mixing of five or
more principal elements, and such compositional complexity often leads to
improvements in mechanical properties and high thermal stability, etc. Thus,
high-entropy alloys have found their applications in domains like aerospace,
biomedical, energy storage, catalysis, electronics, etc. However, the vast
compositional design and experimental exploration of high-entropy alloys are
both time consuming and expensive and require a large number of resources.
Machine learning techniques have thus become essential for accelerating high
entropy alloys discovery using data driven predictions of promising alloy
combinations and their properties. Hence, this work employs a machine learning
framework that predicts high entropy alloy hardness from elemental descriptors
such as atomic radius, valence electron count, bond strength, etc. Machine
learning regression models, like LightGBM, Gradient Boosting Regressor, and
Transformer encoder, were trained on experimental data. Additionally, a
language model was also fine tuned to predict hardness from elemental
descriptor strings. The results indicate that LightGBM has better accuracy in
predicting the hardness of high entropy alloys compared to other models used in
this study. Further, a combinatorial technique was used to generate over 9
million virtual high entropy alloy candidates, and the trained machine learning
models were used to predict their hardness. This study shows how machine
learning-driven high throughput screening and language modelling approaches can
accelerate the development of next generation high entropy alloys.

</details>


### [313] [Tuning Coupled Toroidic and Polar Orders in a Bilayer Antiferromagnet](https://arxiv.org/abs/2509.13542)
*Chuangtang Wang,Xiaoyu Guo,Zixin Zhai,Meixin Cheng,Sang-Wook Cheong,Adam W. Tsen,Bing Lv,Liuyan Zhao*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过对双层CrSBr的研究，首次在二维材料中实现了磁环形序的调控及其线性磁电响应的探测。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索二维磁性材料中的磁环形序及其线性磁电效应，并为相关器件的设计提供新的可能性。

Method: 利用磁场依赖的二次谐波产生（SHG）技术，并结合时间反演对称性分析，研究了双层CrSBr的磁环形序和电极化。通过施加不同方向的磁场和电场，进一步验证了磁环形序与电极化的耦合关系。

Result: 研究发现，双层CrSBr在层间反铁磁序的同时也表现出磁环形序。通过SHG信号可以调控其磁环形序和电极化，并且观察到了磁环形序与电极化在磁场和电场作用下的锁定移动现象。

Conclusion: 双层CrSBr的磁环形序为实现巨大的线性磁电效应提供了平台，有望在下一代电子、磁性、光学和光子器件中得到应用。

Abstract: Magnetic toroidal order features a loop-like arrangement of magnetic dipole
moments, thus breaking both spatial inversion (P) and time-reversal (T)
symmetries while preserving their combined PT sym-metry. This PT symmetry
enables a linear magnetoelectric effect, allowing the coupling between magnetic
toroidicity and electric polarity. However, the detection and control of
two-dimensional (2D) magnetic toroidal order and the investigation of its
linear magnetoelectric response remain largely unexplored. Here, using bilayer
CrSBr as a platform, which hosts an in-plane layer-antiferromagnetic (AFM)
order and simultaneously exhibits a magnetic toroidal order, we show compelling
evidence for tuning this 2D magnetic toroidicity and its induced electric
polarity through magnetic-field-depend-ent second harmonic generation (SHG).
Under an out-of-plane magnetic field, we decompose the SHG signal into a
time-reversal-odd component that scales with the magnetic toroidal moment and a
time-reversal-even component that is proportional to the electric polarization.
When sweeping the magnetic field from positive to negative values, we observe
that the magnetic toroidicity retains its sign but diminishes in magnitude at
higher fields while the electric polarity flips its sign and increases in
strength at increasing fields below a critical threshold. When applying an
in-plane electric field along the N\'eel vector direction, together with an
out-of-plane field, we find that the magnetic toroidal and electric polar
domains are moved in a locked fashion. These findings underscore the promise of
2D magnetic toroidal order in realizing giant linear magnetoelectric effects,
opening exciting possi-bilities for next-generation electronic, magnetic,
optical, and photonic devices enabled by 2D mag-netoelectrics.

</details>


### [314] [Valley-Selective Linear Dichroism and Excitonic Effects in Lieb-Lattice Altermagnets](https://arxiv.org/abs/2509.13551)
*Haonan Wang,Xilong Xu,Du Li,Li Yang*

Main category: cond-mat.mtrl-sci

TL;DR: Altermagnets具有独特的自旋分裂电子结构但无净磁矩。本文利用多体微扰理论研究了以Mn2WS4为代表的二维弹片状 Lieb 晶格中的激子性质及其应变可调性，发现了新颖的自旋-谷依赖的激子选择规则，其中线偏振光可以选择性地激发谷自旋极化激子，并且单轴应变可以提升谷简并度，实现先前过渡金属二硫化物中无法实现的自旋极化激子选择性激发，为信息编码、存储和读取提供了新机制。


<details>
  <summary>Details</summary>
Motivation: 尽管对弹子体的单粒子自旋电子学和谷电子学性质进行了广泛研究，但对其多体相互作用和光学响应的探索仍然有限。本文旨在利用多体微扰理论研究弹子体的激发态及其应变可调性。

Method: 本研究采用多体微扰理论（MBP）研究了具有代表性的单层Mn2WS4的激发态及其应变可调性，并揭示了其新颖的自旋-谷依赖的激子选择规则。

Result: 研究发现了线偏振光可以选择性地激发谷自旋极化激子，并预测单轴应变可以提升谷简并度，实现自旋极化激子的选择性激发，这种效应在先前研究的过渡金属二硫化物中是无法实现的。

Conclusion: 这些自旋-谷锁定的激子态及其应变可调性为四重对称弹子体编码、存储和读取谷/自旋信息提供了一种强大的机制。

Abstract: Altermagnets have recently been recognized as a distinct class of magnetic
materials characterized by alternative spin-split electronic structures without
net magnetization. Despite intensive studies on their single-particle
spintronic and valleytronic properties, many-electron interactions and optical
responses of altermagnets remain less explored. In this work, we employ
many-body perturbation theory to investigate excited states and their strain
tunability. Using monolayer Mn2WS4 as a representative candidate, we uncover a
novel spin valley-dependent excitonic selection rule in two-dimensional
altermagnetic Lieb lattices. In addition to strongly bound excitons, we find
that linearly polarized light selectively excites valley spin-polarized
excitons. Moreover, due to the interplay between altermagnetic spin symmetry
and electronic orbital character, we predict that applying uniaxial strain can
lift valley degeneracy and enable the selective excitation of spin-polarized
excitons, an effect not achievable in previously studied transition-metal
dichalcogenides. These spin-valley-locked excitonic states and their strain
tunability offer a robust mechanism for four-fold symmetric altermagnets to
encode, store, and read valley/spin information.

</details>


### [315] [Electric-Field Control of Terahertz Response via Spin-Corner-Layer Coupling in Altermagnetic Bilayers](https://arxiv.org/abs/2509.13643)
*Jianhua Wang,Yilin Han,Shifeng Qian,Zhenxiang Cheng,Wenhong Wang,Zhi-Ming Yu,Xiaotian Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 利用自旋-角-层耦合（SCLC）机制，通过电场调控太赫兹波的吸收、发射和极化。


<details>
  <summary>Details</summary>
Motivation: 在现代半导体和自旋电子学器件中，利用电场控制电子的电荷和自旋自由度至关重要，然而，利用电场控制电磁波（特别是在太赫兹频段）仍然是一个挑战。

Method: 提出了一种在二阶拓扑交变磁性双层结构中的自旋-角-层耦合（SCLC）机制，利用电场影响层间电子，实现对角和自旋自由度的协同控制。

Result: 以双层NiZrI$_6$纳米圆盘为原型，证明了超低静电场可以切换角态的自旋和层极化，进而调制了不同角态之间的跃迁偶极矩和振荡器强度，实现了对太赫兹波的操控。

Conclusion: 该研究提出了SCLC机制，实现了通过电场控制自旋和太赫兹波，为太赫兹自旋电子学的发展提供了重要的启示。

Abstract: Electric field control of electron charge and spin degrees of freedom is
fundamental to modern semiconductor and spintronic devices. Yet controlling
electromagnetic waves with an electric field, particularly in the terahertz
(THz) band, remains a challenge. Here, we propose a spin-corner-layer coupling
(SCLC) mechanism in second-order topological altermagnetic bilayers. By using
an electric field to influence electrons between different layers, the SCLC
mechanism enables simultaneous control over corner and spin degrees of freedom,
thereby allowing electric-field tuning of the absorption, emission intensity,
and even polarization of THz waves. Taking bilayer NiZrI$_6$ nanodisks as a
prototype, we demonstrate that an ultralow electrostatic field can switch both
the spin and the layer polarizations of corner states. This dual switching
modulates transition dipole moments and oscillator strengths between different
corner states, thereby enabling the manipulation of THz waves. This study
establishes a mechanism for the electric-field control of spin and THz waves
through SCLC, yielding important implications for the advancement of THz
spintronics.

</details>


### [316] [Synthesis of Ultra-thin Potassium Tungsten Bronze Single Crystals with Optically Contrasting Domains and Resistive Switching](https://arxiv.org/abs/2509.13693)
*Abdulsalam Aji Suleiman,Amir Parsi,Hafiz Muhammad Shakir,Hamid Reza Rasouli,Doruk Pehlivanoğlu,Talip Serkan Kasırga*

Main category: cond-mat.mtrl-sci

TL;DR: 本文报道了一种固-液-固（SLS）生长策略，成功制备了高质量的钾钨青铜（K$_x$WO$_3$）纳米带，厚度可达约36纳米，横向尺寸超过100微米。


<details>
  <summary>Details</summary>
Motivation: 为了可控合成适合器件制造的单晶介观尺寸钾钨青铜（K$_x$WO$_3$）样品，克服了以往研究中对此类材料合成的局限性。

Method: 采用固-液-固（SLS）生长策略制备K$_x$WO$_3$纳米带，并通过空间分辨拉曼光谱和电子衍射分析了其钾离子占据情况。

Result: 制备的K$_x$WO$_3$纳米带表现出由钾离子占据情况局部变化引起的光学畴，外加偏压后这些光学畴不可逆地消失，表明钾离子沿通道重新分布。基于单个纳米带制备的双端器件表现出可重复的双极开关行为，电阻比为10-30，并在脉冲激发下表现出特性短时和长时可塑性，开关能量约为25 nJ。

Conclusion: K$_x$WO$_3$可作为研究电场驱动的碱金属离子迁移的模型材料，并在稳定、模拟电阻开关和离子电子存储器应用方面展现出潜力。

Abstract: Potassium tungsten bronzes (K$_x$WO$_3$) are nonstoichiometric oxides in
which alkali ions, i.e., K+, occupy one-dimensional tunnels of the hexagonal
WO6 framework, enabling coupled ionic-lectronic transport. While their bulk and
nanostructured forms have been studied extensively, controlled synthesis of
single-crystalline mesoscale samples suitable for device fabrication has
remained limited. Here, we report a solid-liquid-solid (SLS) growth strategy
that yields high-quality K$_x$WO$_3$ nanobelts with thicknesses down to ~36 nm
and lateral sizes exceeding 100 um. The crystals display sharp optical domains
arising from local variations in potassium occupancy, as confirmed by spatially
resolved Raman spectroscopy and electron diffraction. Under applied bias, these
domains vanish irreversibly, consistent with lateral redistribution of K+ ions
along the tunnels. Two-terminal devices fabricated from individual nanobelts
exhibit reproducible bipolar switching with resistance ratios of 10-30,
characteristic short-term and long-term plasticity under pulsed excitation, and
switching energies of ~25 nJ. These results establish K$_x$WO$_3$ as a model
tunnel-structured oxide for studying electric-field-driven alkali-ion
migration, while also highlighting its potential for stable, analog resistive
switching and iontronic memory applications.

</details>


### [317] [Thermal Degradation Mechanisms and Stability Enhancement Strategies in Perovskite Solar Cells: A Review](https://arxiv.org/abs/2509.13700)
*Arghya Paul,Kanak Raj,Prince Raj Lawrence Raj,Pratim Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: 钙钛矿太阳能电池（PSCs）因其优异的光伏性能而受到广泛关注，但热稳定性差是其主要缺点。本研究探讨了温度对空穴传输层（HTLs）和钙钛矿层（特别是MAPbI3）降解的影响，并提出了改进热稳定性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管钙钛矿太阳能电池（PSCs）在效率、柔性和轻质方面表现出色，但其热不稳定性限制了其广泛应用。本研究旨在深入理解温度如何影响关键组件（HTLs和钙钛矿层）的降解机制，并为提高PSCs的稳定性提供解决方案。

Method: 通过分析高温对MAPbI3（如分解为PbI2, CH3I, NH3）和HTLs（如形态变化和掺杂剂亲水性）的影响，研究了不同成分（如Cs-MA-FA）和替代材料（如P3HT, CuSCN, NiOx, Cu2O）对热稳定性的影响。

Result: 研究发现，高温会导致MAPbI3分解，其速率受湿度和氧气等因素影响。Cs-MA-FA等混合阳离子组成的钙钛矿热稳定性更高。HTLs中的掺杂剂（如Li-TFSI和t-BP）会导致形态变化和亲水性增加，从而加速降解。然而，P3HT、CuSCN、NiOx和Cu2O等无掺杂剂HTMs表现出更高的热稳定性和效率。

Conclusion: 提高PSCs热稳定性的可行方法包括使用混合阳离子、开发无掺杂剂HTLs（如P3HT和无机材料）以及优化界面。解决热稳定性问题对于开发更可靠、更高效的PSCs至关重要。

Abstract: Perovskite Solar Cells (PSCs) have garnered global research interest owing to
their superior photovoltaic (PV) performance. The future of photovoltaic
technology lies in PSCs since they can produce power with performance on par
with the best silicon solar cells while being less expensive. PSCs have
enormous potential; in just ten years, their efficiency increased from 3.8% to
25.2%, and research into new developments is still ongoing. Thermal instability
is PSCs' main disadvantage, despite their high efficiency, flexibility, and
lightweight nature. This paper looks at how temperature affects the ways that
hole transport layers (HTLs) like spiro-OMeTAD and perovskite layers,
especially MAPbI3, degrade. Elevated temperatures cause MAPbI3 to degrade into
PbI2, CH3I, and NH3, with decomposition rates affected by moisture, oxygen, and
environmental factors. Mixed cation compositions, such as Cs-MA-FA, have higher
thermal stability, whereas MA+ cations break-down faster under heat stress.
HTLs deteriorate due to morphological changes and the hydrophilicity of dopant
additions like Li-TFSI and t-BP. Alternative dopant-free HTMs, such as P3HT and
inorganic materials including CuSCN, NiOx, and Cu2O, have shown improved
thermal stability and efficiency. Hybrid HTLs, dopant-free designs, and
interface tweaks are all viable solutions for increasing the stability of PSC.
Addressing thermal stability issues remains crucial for the development of more
reliable and efficient PSC technology.

</details>


### [318] [Phase stability and structural properties of the K$_{x}$Ca$_{1-x}$N novel ferromagnetic alloy from first-principles](https://arxiv.org/abs/2509.13728)
*K. Larbaoui,A. Lakdja,G. Bassou*

Main category: cond-mat.mtrl-sci

TL;DR: KxCa1-xN合金具有不对称相图，相分离发生在3033K，这是由x依赖的相互作用参数引起的。


<details>
  <summary>Details</summary>
Motivation: 研究KxCa1-xN合金的结构性质和相稳定性。

Method: 使用基于混合总能量的正则溶液模型，结合赝势方法和PBE函数。研究了键长分布，并计算了焓。

Result: 预测了两种部分混溶组分的相分离，并使用相互作用参数计算了焓。发现相图在x=0.46处不对称，相互作用参数为Ω=12.69-1.32x kcal/mole。相图的混溶间隙约为3033K。

Conclusion: KxCa1-xN合金的相图不对称，这是由于x依赖的相互作用参数。

Abstract: We study the structural properties and phase stability of the
K$_{x}$Ca$_{1-x}$N alloy using the regular-solution model based on the total
energy of the mixing. The pseudopotential approach was used along with PBE
functional of Perdew, Burke, and Ernzerhof (PBE). We investigated the
bond-lengths distribution as a function of composition $x$. We also predicted
the phase separation of the two partially miscible components and calculated
the enthalpy $\Delta H$ using the interaction parameter $\Omega$. We observe an
asymmetry about $x=0.46$ in the phase diagram due to the $x$-dependant
interaction parameter $\Omega=12.69-1.32x$ kcal/mole. The equilibrium
solubility limit, known as the miscibility gap is found to be around 3033 K.

</details>


### [319] [Stochastic ion emission perturbation mechanisms in atom probe tomography: Linking simulations to experiment](https://arxiv.org/abs/2509.13744)
*Aslam Shaikh,Tero Mäkinen,François Vurpillot,Mikko Alava,Ivan Lomakin*

Main category: cond-mat.mtrl-sci

TL;DR: 仿真中加入表面迁移机制以提高原子探针断层扫描的准确性。


<details>
  <summary>Details</summary>
Motivation: 原子探针断层扫描（APT）中的场蒸发过程包含与原子表面迁移相关的已知机制，如“卷起”机制，这些机制会导致轨迹畸变和探测器伪影。然而，这些过程通常在模拟中被忽略。为了开发和验证APT重建算法（这是整个方法学的关键部分）提供可靠的模型，包含这些机制至关重要。

Method: 通过将随机横向速度扰动和卷起机制加入到Robin-Rolland模型模拟中，并与Al和Ni系统的实验数据进行比较。

Result: 通过比较实验数据，找到了能够非常精确地重现实验中观察到的探测器图案的随机扰动能量分布，从而大大提高了模拟的准确性。

Conclusion: 研究结果表明，通过在模拟中加入表面迁移机制，可以显著提高APT模拟的准确性，并有助于探究实验与模拟之间剩余差异的可能原因。

Abstract: Field evaporation in atom probe tomography (APT) includes known processes
related to surface migration of atoms, such as the so-called roll-up mechanism.
They lead to trajectory aberrations and artefacts on the detector. These
processes are usually neglected in simulations. The inclusion of such processes
is crucial for providing reliable models for the development and verification
of APT reconstruction algorithms, a key part of the whole methodology. Here we
include stochastic lateral velocity perturbations and a roll-up mechanism to
simulations performed using the Robin--Rolland model. By comparing with
experimental data from Al and Ni systems, we find the stochastic perturbation
energy distributions that allow us to very accurately reproduce the detector
patterns seen experimentally and thus greatly improve the accuracy of the
simulations. We also explore the possible causes of remaining discrepancies
between the experimental and simulated detector patterns.

</details>


### [320] [Thermal Conductivity Limits of MoS$_2$ and MoSe$_2$: Revisiting High-Order Anharmonic Lattice Dynamics with Machine Learning Potentials](https://arxiv.org/abs/2509.13798)
*Tugbey Kocabas,Murat Keceli,Tanju Gurel,Milorad Milosevic,Cem Sevik*

Main category: cond-mat.mtrl-sci

TL;DR: Group-VI过渡金属二硫属化物的晶格热导率存在显著差异，本文通过结合第一性原理计算、分子动力学模拟和机器学习力场，分析了这些差异的来源，并证明了四声子过程对热导率的贡献可忽略不计。


<details>
  <summary>Details</summary>
Motivation: Group-VI过渡金属二硫属化物的晶格热导率测量值和理论预测值存在巨大差异，需要对这些不一致性进行批判性审查，以明确其方法学根源。

Method: 结合第一性原理计算、分子动力学模拟和机器学习力场（包括MACE-OMAT-0、UMA和NEP89），对GAP、MACE、NEP和HIPHIVE进行训练和基准测试，并严格评估了三阶和四阶声子散射过程对晶格热导率的影响，同时利用了均匀非平衡分子动力学方法。

Result: 研究表明，与一些近期声称相反，完全收敛的四声子过程对MoS2和MoSe2的本征热导率的贡献可以忽略不计。

Conclusion: 本研究不仅为二维过渡金属二硫属化物的本征输运极限提供了更精确的认识，而且确立了基于机器学习力场的方法作为预测低维材料中声子介导的热输运的稳健且可扩展的框架。

Abstract: Group-VI transition metal dichalcogenides (TMDs), MoS$_2$ and MoSe$_2$, have
emerged as prototypical low-dimensional systems with distinctive phononic and
electronic properties, making them attractive for applications in
nanoelectronics, optoelectronics, and thermoelectrics. Yet, their reported
lattice thermal conductivities ($\kappa$) remain highly inconsistent, with
experimental values and theoretical predictions differing by more than an order
of magnitude. These discrepancies stem from uncertainties in measurement
techniques, variations in computational protocols, and ambiguities in the
treatment of higher-order anharmonic processes. In this study, we critically
review these inconsistencies, first by mapping the spread of experimental and
modeling results, and then by identifying the methodological origins of
divergence. To this end, we bridge first-principles calculations, molecular
dynamics simulations, and state-of-the-art machine learning force fields
(MLFFs) including recently developed foundation models. %MACE-OMAT-0, UMA, and
NEP89. We train and benchmark GAP, MACE, NEP, and \textsc{HIPHIVE} against
density functional theory (DFT) and rigorously evaluate the impact of third-
and fourth-order phonon scattering processes on $\kappa$. The computational
efficiency of MLFFs enables us to extend convergence tests beyond conventional
limits and to validate predictions through homogeneous nonequilibrium molecular
dynamics as well. Our analysis demonstrates that, contrary to some recent
claims, fully converged four-phonon processes contribute negligibly to the
intrinsic thermal conductivity of both MoS$_2$ and MoSe$_2$. These findings not
only refine the intrinsic transport limits of 2D TMDs but also establish
MLFF-based approaches as a robust and scalable framework for predictive
modeling of phonon-mediated thermal transport in low-dimensional materials.

</details>


### [321] [Contrasting magnetic anisotropy in CrCl3 and CrBr3: A first-principles study](https://arxiv.org/abs/2509.13824)
*Jiazhuang Si,Shuyuan Liu,Bing Wang,Chongze Wang,Fengzhu Ren,Yu Jia,Jun-Hyung Cho*

Main category: cond-mat.mtrl-sci

TL;DR: CrCl3和CrBr3的磁各向异性差异源于卤素p轨道的空间分布、自旋-轨道耦合强度和杂化行为的差异。


<details>
  <summary>Details</summary>
Motivation: 研究CrCl3和CrBr3中易磁化轴（EMAs）对比现象的原因。

Method: 利用密度泛函理论（DFT）计算，分析了自旋-轨道耦合诱导的磁晶各向异性能（SOC-MAE）和形状磁各向异性能（shape-MAE）的相互作用。

Result: CrCl3中，Cl 3p轨道局部化，促进了有利于自旋翻转的SOC相互作用，导致SOC-MAE部分抵消，shape-MAE占优，易磁化轴呈面内取向。CrBr3中，Br 4p轨道更离域化，p-d杂化增强，SOC更强，有利于自旋守恒的SOC相互作用，SOC-MAE占优，易磁化轴呈面外取向。

Conclusion: CrCl3和CrBr3中磁各向异性的差异是卤素p轨道的空间分布、SOC强度和杂化作用差异的结果，揭示了轨道各向异性和自旋选择规则在磁性行为中的关键作用。

Abstract: We present a first-principles study of the contrasting easy magnetization
axes(EMAs) in the layered chromium trihalides CrCl3 and CrBr3, which exhibit
in-plane and out-of-plane EMAs, respectively. Using density-functional theory
calculations, we show that the EMA is determined by the interplay between
spin-orbit coupling-induced magnetocrystalline anisotropy energy (SOC-MAE) and
shape magnetic anisotropy energy(shape-MAE) arising from dipole-dipole
interactions. While the Cr d orbitals contribute similarly to the SOC-MAE in
both compounds, the key difference stems from the halogen p orbitals. In CrCl3,
the localized Cl 3p orbitals favor spin-flip SOC interactions, particularly
between the (px, py) and (py, pz) channels. These channels contribute with
opposite signs-negative and positive, respectively-leading to partial
cancellation and a small net SOC-MAE. As a result, the shape-MAE exceeds the
SOC-MAE in magnitude, favoring an in-plane EMA. In contrast, CrBr3 features
more delocalized Br 4p orbitals, enhanced p-d hybridization, and stronger SOC.
This leads to stronger spin-conserving SOC interactions, with dominant
contributions from both the (px, py) and (py, pz) channels. In this case, the
positive contribution from the (px, py) channel outweighs the smaller negative
contribution from the (py, pz) channel, resulting in a sizable net SOC-MAE. The
SOC-MAE thus surpasses the shape-MAE and stabilizes an out-of-plane EMA. These
findings demonstrate that the contrasting magnetic anisotropies in CrCl3 and
CrBr3 originate from differences in the spatial distribution, SOC strength, and
hybridization of the halogen p orbitals, highlighting the critical role of
orbital anisotropy and spin selection rules in governing magnetic behavior in
layered semiconductors.

</details>


### [322] [Quantum Simulations of Battery Electrolytes with VQE-qEOM and SQD: Active-Space Design, Dissociation, and Excited States of LiPF$_6$, NaPF$_6$, and FSI Salts](https://arxiv.org/abs/2509.13826)
*Sk Mujaffar Hossain,Seung-Cheol Lee,Satadeep Bhattacharjee*

Main category: cond-mat.mtrl-sci

TL;DR: 使用混合量子-经典算法研究了四种电池电解质（LiPF$_{6}$、NaPF$_{6}$、LiFSI 和 NaFSI）的激发态，结果显示了阴阳离子和取代效应，并为电解质设计提供了基线。


<details>
  <summary>Details</summary>
Motivation: 准确预测电池电解质的激发态对于理解光稳定性和氧化稳定性至关重要。

Method: 采用量子变分本征求解器（VQE）结合量子运动方程（qEOM）算法，研究了四种电池电解质的激发态。通过构造紧凑的活性空间、映射到量子比特、利用对称性剪枝和对易群测量来降低采样成本。

Result: PF$_{6}$盐表现出更高的第一激发能（LiPF$_{6}$ $\approx$13.2 eV），而FSI盐的激发能较低（$\approx$8-9 eV）。锂离子替换为钠离子会使能隙减小约0.4-0.8 eV。激发能对应于深紫外区域（LiPF$_{6}$ $\approx$94 nm；NaFSI $\approx$148 nm）。

Conclusion: 当前的量子算法能够为实际的电解质提供有意义的激发和结合趋势，并为电解质筛选和设计提供量化基线。

Abstract: Accurate prediction of excited states in battery electrolytes is central to
understanding photostability, oxidative stability, and degradation. We employ
hybrid quantum-classical algorithms -- the Variational Quantum Eigensolver
(VQE) for ground states combined with the quantum equation of motion (qEOM) for
vertical singlet excitations -- to study LiPF$_6$, NaPF$_6$, LiFSI, and NaFSI.
Compact active spaces were constructed from frontier orbitals, mapped to
qubits, and reduced via symmetry tapering and commuting-group measurements to
lower sampling cost. Within $\sim$10-qubit models, VQE-qEOM agrees closely with
exact diagonalization of the same Hamiltonians, while sample-based quantum
diagonalization (SQD) in larger active spaces recovers near-exact
(subspace-FCI) energies. The spectra display clear anion and cation trends:
PF$_6$ salts exhibit higher first-excitation energies (e.g., LiPF$_6$
$\approx$13.2 eV) and a compact three-state cluster at 12-13 eV, whereas FSI
salts show substantially lower onsets ($\approx$8-9 eV) with a near-degenerate
(S$_1$,S$_2$) followed by S$_3$ $\sim$1.3 eV higher. Substituting Li$^+$ with
Na$^+$ narrows the gap by $\sim$0.4-0.8 eV within each anion family. Converting
S$_1$ to wavelengths places the onsets in the deep-UV (LiPF$_6$ $\sim$94 nm;
NaPF$_6$ $\sim$100 nm; LiFSI $\sim$141 nm; NaFSI $\sim$148 nm). All results
pertain to isolated species or embedded clusters appropriate to the NISQ
regime; solvent shifts can be incorporated a posteriori via classical
$\Delta$-solvation or static embedding. These results demonstrate that current
quantum algorithms can deliver chemically meaningful excitation and binding
trends for realistic electrolyte motifs and provide quantitative baselines to
guide electrolyte screening and design.

</details>


### [323] [Direct observation of nanoscale pinning centers in Ce(Co0.8Cu0.2)5.4 permanent magnets](https://arxiv.org/abs/2509.13859)
*Nikita Polin,Shangbin Shen,Fernando Maccari,Alex Aubert,Esmaeil Adabifiroozjaei,Tatiana Smoliarova,Yangyiwei Yang,Xinren Chen,Yurii Skourski,Alaukik Saxena,András Kovács,Rafal E. Dunin-Borkowski,Michael Farle,Bai-Xiang Xu,Leopoldo Molina-Luna,Oliver Gutfleisch,Baptiste Gault,Konstantin Skokov*

Main category: cond-mat.mtrl-sci

TL;DR: Ce(Co0.8Cu0.2)5.4 磁体的磁滞回strictly度机制源于纳米尺度下的自旋odal分解造成的细胞状结构，该结构由富铜和贫铜区域组成，引起磁晶各向异性。这种结构为稀土磁体提供了微观结构基础。


<details>
  <summary>Details</summary>
Motivation: Ce(Co1-xCux)5 永磁体的矫顽力机制尚不明确，需要进一步研究。

Method: 利用透射电子显微镜 (TEM) 和原子探针层析成像 (APT) 技术，结合微磁模拟，研究 Ce(Co0.8Cu0.2)5.4 磁体的微观结构和磁性能。

Result: 研究发现 Ce(Co0.8Cu0.2)5.4 磁体存在纳米尺度的细胞状结构，由贫铜圆柱形细胞和富铜细胞边界组成，这种结构导致了磁晶各向异性和畴壁能量的空间变化，从而有效钉扎磁畴壁，产生高矫顽力。

Conclusion: 纳米尺度的化学偏析是 Ce(Co0.8Cu0.2)5.4 磁体具有高矫顽力的微观结构基础，为设计稀土资源消耗少的永磁体提供了新思路。

Abstract: Permanent magnets containing rare earth elements are essential components for
the electrification of society. Ce(Co1-xCux)5 permanent magnets are a model
system known for their substantial coercivity, yet the underlying mechanism
remains unclear. Here, we investigate Ce(Co0.8Cu0.2)5.4 magnets with a
coercivity of ~1 T. Using transmission electron microscopy (TEM) and atom probe
tomography (APT), we identify a nanoscale cellular structure formed by spinodal
decomposition. Cu-poor cylindrical cells (~5-10 nm in diameter, ~20 nm long)
have a disordered CeCo5-type structure and a composition Ce(Co0.9Cu0.1)5.3.
Cu-rich cell boundaries are ~ 5 nm thick and exhibit a modified CeCo5
structure, with Cu ordered on the Co sites and a composition Ce(Co0.7Cu0.3)5.0.
Micromagnetic simulations demonstrate that the intrinsic Cu concentration
gradients up to 12 at.% Cu/nm lead to a spatial variation in magnetocrystalline
anisotropy and domain wall energy, resulting in effective pinning and high
coercivity. Compared to Sm2Co17-type magnets, Ce(Co0.8Cu0.2)5.4 displays a
finer-scale variation of conventional pinning with lower structural and
chemical contrast in its underlying nanostructure. The identification of
nanoscale chemical segregation in nearly single-phase Ce(Co0.8Cu0.2)5.4 magnets
provides a microstructural basis for the long-standing phenomenon of "giant
intrinsic magnetic hardness" in systems such as SmCo5-xMx, highlighting avenues
for designing rare-earth-lean permanent magnets via controlled nanoscale
segregation.

</details>


### [324] [Tuning and Suppression of YIG Magnetisation Dynamics via Antiferromagnetic Interface Coupling](https://arxiv.org/abs/2509.13870)
*Oscar Cespedes,Hari B. Vasili,Matthew Rogers,Paul S. Keatley,Manan Ali,Bryan Hickey,Robert J. Hicken*

Main category: cond-mat.mtrl-sci

TL;DR: 通过界面耦合调控YIG薄膜的磁化动力学，可实现频率、阻尼和吸收的可调性，适用于滤波器、自旋电子学等应用。


<details>
  <summary>Details</summary>
Motivation: YIG磁化动力学对自旋电子和微波器件至关重要，需要研究调控方法。

Method: 在YIG薄膜上生长PtMn或GdIG，研究界面耦合对磁化动力学的影响，并结合两种界面进行调控。

Result: PtMn/YIG薄膜表现出功率依赖的振荡频率和低场下的线宽增加；GdIG/YIG薄膜在低温下表现出反铁磁耦合，并产生强阻尼，在特定场下进一步增强；结合GdIG和PtMn界面可以调控频率的功率依赖性，并在一定场/频率范围内抑制磁化动力学。

Conclusion: 通过界面耦合，特别是结合GdIG和PtMn，可以有效地调控YIG薄膜的磁化动力学，为滤波器、自旋电子学等应用提供新方法。

Abstract: The magnetisation dynamics of yttrium iron garnet (Y3Fe5O12, YIG) are key to
the operation of spintronic and microwave devices. Here, we report a pathway to
manipulate the frequency, damping and absorption of YIG thin films via
interface coupling. The growth on YIG of PtMn, a metallic antiferromagnet,
leads to a power dependence of the oscillation frequency and an increased
linewidth at low fields. In gadolinium iron garnet/YIG film bilayers, the two
films couple antiferromagnetically at low temperatures and there is a strong
damping of the magnetisation dynamics that is further enhanced at the spin-flop
field, suppressing the FMR signal. When combining both GdIG and PtMn
interfaces, we can tune the exponent of the power dependence of frequency with
field and achieve an almost complete quenching of the magnetisation dynamics
over a range of fields/frequencies due to non-collinear magnetic order. These
effects offer a means to tune and suppress magnetisation dynamics for frequency
filters, magnonics, spin pumping and other applications.

</details>


### [325] [Inverse Design of Amorphous Materials with Targeted Properties](https://arxiv.org/abs/2509.13916)
*Jonas A. Finkler,Yan Lin,Tao Du,Jilin Hu,Morten M. Smedskjaer*

Main category: cond-mat.mtrl-sci

TL;DR: AMDNE是一个用于无定形材料的逆向设计框架，使用基于扩散模型的生成模型，并通过汉密尔顿蒙特卡洛进行优化。


<details>
  <summary>Details</summary>
Motivation: 无定形材料在储能、非线性光学和催化等领域具有应用潜力，但其设计空间巨大且难以探索，传统的试错法效率低下。机器学习，特别是逆向设计，为发现具有所需特性的新型无定形材料提供了有前景的方法。

Method: 提出并验证了一种名为AMDNE（无定形材料去噪网络）的逆向设计方法，该方法基于扩散模型生成无定形材料的结构。为了克服标准去噪程序无法模拟无定形材料能量最低构象生成的挑战，AMDNE引入了一个基于能量的变体，该变体实现了汉密尔顿蒙特卡洛（HMC）进行优化。

Result: AMDNE框架成功生成了具有多种特性的无定形材料结构。为了评估该框架并支持未来的发展，研究人员还构建了几个具有多样化特性和组成的无定形材料数据集。

Conclusion: AMDNE为无定形材料的逆向设计提供了一种新颖且有效的框架，通过结合扩散模型和汉密尔顿蒙特卡洛优化，克服了现有方法的局限性，并为未来无定形材料的设计和发现开辟了新的可能性。

Abstract: Disordered (amorphous) materials, such as glasses, are emerging as promising
candidates for applications within energy storage, nonlinear optics, and
catalysis. Their lack of long-range order and complex short- and medium-range
orderings, which depend on composition as well as thermal and pressure history,
offer a vast materials design space. To this end, relying on machine learning
methods instead of trial and error is promising, and among these, inverse
design has emerged as a tool for discovering novel materials with desired
properties. Although inverse design methods based on diffusion models have
shown success for crystalline materials and molecules, similar methods
targeting amorphous materials remain less developed, mainly because of the
limited availability of large-scale datasets and the requirement for larger
simulation cells. In this work, we propose and validate an inverse design
method for amorphous materials, introducing AMDEN (Amorphous Material DEnoising
Network), a diffusion model-based framework that generates structures of
amorphous materials. These low-energy configurations are typically obtained
through a thermal motion-driven random search-like process that cannot be
replicated by standard denoising procedures. We therefore introduce an
energy-based AMDEN variant that implements Hamiltonian Monte Carlo refinement
for generating these relaxed structures. We further introduce several amorphous
material datasets with diverse properties and compositions to evaluate our
framework and support future development.

</details>


### [326] [Comment on `High-resolution Measurements of Thermal Conductivity Matrix and Search for Thermal Hall Effect in La$_2$CuO$_4$'](https://arxiv.org/abs/2509.14105)
*Shan Jiang,Qiaochao Xiang,Benoît Fauqué,Xiaokang Li,Zengwei Zhu,Kamran Behnia*

Main category: cond-mat.mtrl-sci

TL;DR: 文章指出，尽管Jiayi Hu等人未能在La$_2$CuO$_4$中检测到热霍尔信号，但低于其分辨率阈值但有意义的信号已在无序钙钛矿中被观测到。文章还发现，纵向热导率的降低与热霍尔信号的急剧衰减相关，并且在几类绝缘体中，热霍尔信号的幅度与无序度呈负相关。


<details>
  <summary>Details</summary>
Motivation: 探究热霍尔信号在无序绝缘体中的行为，并解释为何在某些材料（如La$_2$CuO4）中难以检测到该信号，而其幅度似乎与材料的无序度相关。

Method: 通过比较具有不同纵向热导率（$\kappa_{xx}$）的材料（包括SrTiO$_3$）中的热霍尔信号（$\kappa_{xy}$）幅度，分析样品质量（无序度）对热霍尔信号的影响。

Result: 发现在SrTiO$_3$中，$\kappa_{xx}$的适度降低伴随着$\kappa_{xy}$的急剧衰减。在多种绝缘体中观察到，$\kappa_{xy}$的幅度与无序度呈负相关。

Conclusion: 材料的无序度是影响热霍尔信号幅度的关键因素，高度无序的材料可能表现出较弱或无法检测到的热霍尔信号。

Abstract: Recently, Jiayi Hu and co-workers reported that they did not resolve any
thermal Hall signal in La$_2$CuO$_4$ by `high resolution' measurements, setting
an upper bound of $|\kappa_{xy}| <2\times 10^{-3}~$Wm$^{-1}$K$^{-1}$ at 20 K.
Two points have apparently escaped their attention. First, thermal Hall signals
with an amplitude well below this resolution bound have been detected in
disordered perovskites. Second, the longitudinal thermal conductivity of their
sample is significantly lower than the La$_2$CuO$_4$ sample displaying a
thermal Hall signal. We find that a moderate reduction of $\kappa_{xx}$ in
SrTiO$_3$ is concomitant with a drastic attenuation of $\kappa_{xy}$. A trend
emerges across several families of insulators: the amplitude of $\kappa_{xy}$
anti-correlates with disorder.

</details>


### [327] [From Glaphene to Glaphynes: A Hybridization of 2D Silica Glass and Graphynes](https://arxiv.org/abs/2509.14115)
*Guilherme S. L. Fabris,Raphael B. de Oliveira,Marcelo L. Pereira Junior,Robert Vajtai,Pulickel M. Ajayan,Douglas S. Galvão*

Main category: cond-mat.mtrl-sci

TL;DR: glaphenes（由2D二氧化硅和石墨烯组成的混合二维材料）的提出启发了我们设计一种新的结构——glaphynes，即将SiO2单层堆叠在石墨烯上。


<details>
  <summary>Details</summary>
Motivation: 探索混合二维材料的电子特性，特别是glaphynes的结构和电子特性。

Method: 使用DFT+软件包中的密度泛函紧束缚（DFTB）方法。

Result: glaphynes在能量和结构上是稳定的，并且电子近邻效应确实可以打开电子带隙，但并非在所有情况下都如此，即使形成了Si-O-C键。

Conclusion: glaphynes在结构上是稳定的，并且电子近邻效应对打开电子带隙有影响，但这种影响并非普遍存在。

Abstract: Hybrid two-dimensional (2D) materials have attracted increasing interest as
platforms for tailoring electronic properties through interfacial design. Very
recently, a novel hybrid 2D material termed glaphene, which combines monolayers
of 2D silica glass and graphene, was experimentally realized. Inspired by
glaphenes, we proposed a new class of similar structures named glaphynes, which
are formed by stacking SiO$_2$ monolayers onto $\alpha$-, $\beta$-, and
$\gamma$-graphynes. Graphynes are 2D carbon allotropes with the presence of
acetylenic groups (triple bonds). The glaphynes' structural and electronic
properties were investigated using the density functional tight-binding (DFTB)
method, as implemented in the DFTB+ package. Our analysis confirms their
energetic and structural stability. We have observed that in the case of
glaphynes, the electronic proximity effect can indeed open the electronic band
gap, but not for all cases, even with the formation of Si-O-C bonds between
silica and graphynes.

</details>


### [328] [Phonon-assisted photoluminescence of bilayer MoS$_2$ from first principles](https://arxiv.org/abs/2509.14200)
*Gyanu P. Kafle,Zhen-Fei Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 我们研究了双层MoS2在温度和应变下的声子辅助光致发光。我们发现特定声子模式对发光贡献最大，并且应变会改变发光行为。


<details>
  <summary>Details</summary>
Motivation: 间接带隙材料的光致发光（PL）主要依赖声子辅助过程，理解这些过程对于调节材料的光学性质至关重要。

Method: 我们采用基于第一性原理的多体方法，结合超胞方法来模拟声子效应。通过改变原子位置来模拟声子模式，并计算光学吸收光谱。利用van Roosbroeck-Shockley关系从光学吸收光谱得到PL强度，并分别分析声子吸收和声子发射过程对温度的依赖性。

Result: 对于未加应变的双层MoS2，与S原子层外振动和Mo原子层内振动相关的光学声子对间接PL的贡献最大。随着应变增加，电子能带结构发生调制，使得在高应变下出现额外的声子发光通道。我们还讨论了PL光谱和声子贡献如何随应变演变。

Conclusion: 双层MoS2的声子辅助光致发光对温度和应变敏感。特定声子模式是影响发光强度的关键，而应变可以调控能带结构，从而引入新的发光通道，这为通过应变工程优化材料的光电性能提供了可能。

Abstract: In indirect band gap materials, phonon-assisted processes are key mechanisms
for photoluminescence (PL). Using a first-principles many-body approach, we
systematically investigate the phonon-assisted PL in bilayer MoS$_2$ and its
dependence on temperature and external tensile strain. The effects of phonons
are accounted for using a supercell approach: we identify the phonon momenta
that are important to PL, construct supercells that are commensurate with these
phonons, and examine the changes in the optical absorption after explicit
displacements of atoms along each phonon mode. The PL intensity is then
obtained via the van Roosbroeck-Shockley relationship from the optical
absorption spectra. This approach enables us to investigate phonon-absorption
and phonon-emission processes separately and how each process depends on
temperature. Our results reveal that optical phonons associated with
out-of-plane vibrations of S atoms and in-plane vibrations of Mo atoms
contribute most to the indirect PL for unstrained bilayer MoS$_2$.
Additionally, we also discuss how the PL spectra and the phonon contributions
evolve with strain. In particular, we show that at high strain, additional
phonon channels become available due to the modulation of the electronic band
structure.

</details>


### [329] [Skyrmion-Antiskyrmion Lattice: A Net-Zero Topological Phase in Low-Symmetry Frustrated Chiral Magnets](https://arxiv.org/abs/2509.14207)
*Sayan Banik,Ashis K. Nandy*

Main category: cond-mat.mtrl-sci

TL;DR: 在二维异质结构中发现了热力学稳定的 Skyrmion-antiskyrmion 晶格，这是一种新颖的状态，由于 Skyrmion 和 antiskyrmion 的数量相等，因此具有净零全局拓扑电荷。


<details>
  <summary>Details</summary>
Motivation: 探索具有净零全局拓扑电荷的新型 Skyrmion 状态，并解释其形成和稳定性。

Method: 在 GaAs 和 CdTe 半导体的 C1v 对称 (110) 表面上的 Fe 膜上进行实验，并研究磁场引起的相变。

Result: 观察到从环状自旋螺旋到 Skyrmion-antiskyrmion 晶格再到锥形自旋螺旋再到铁磁体的磁场诱导相变。证明了 C1v 低对称性是形成热力学稳定净零拓扑孤子晶格的关键。

Conclusion: 通过降低界面对称性至 C1v，可以实现反常磁体的独特表现，即热力学稳定的净零拓扑孤子晶格。

Abstract: We report the discovery of a thermodynamically stable skyrmion-antiskyrmion
lattice in two-dimensional heterostructures, a novel state exhibiting a
net-zero global topological charge owing to an equal population of skyrmions
and antiskyrmions. This surprising coexistence of oppositely charged solitons
remarkably circumvents their anticipated annihilation. We demonstrate the
formation and evolution of this phase in Fe films on C1v -symmetric (110)
surfaces of GaAs and CdTe semiconductors. Specifically, we reveal a series of
magnetic field-induced phase transitions: cycloidal spin-spiral to
skyrmion-antiskyrmion lattice to conical spin-spiral to ferromagnet. The
remarkable stability of the net-zero lattice is attributed to symmetry-enforced
anisotropic magnetic interactions. Lowering interfacial symmetry to C1v thus
enables frustrated chiral magnets, uniquely manifesting in thermodynamically
stable net-zero topological soliton lattices, as revealed by our findings.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [330] [MACO: A Multi-Agent LLM-Based Hardware/Software Co-Design Framework for CGRAs](https://arxiv.org/abs/2509.13557)
*Zesong Jiang,Yuqi Sun,Qing Zhong,Mahathi Krishna,Deepak Patil,Cheng Tan,Sriram Krishnamoorthy,Jeff Zhang*

Main category: cs.AR

TL;DR: MACO是一个开源的多代理LLM框架，用于CGRA的软硬件协同设计，通过迭代优化和LLM自学习机制，能高效生成高质量的CGRA架构，并显著减少手动设计工作量。


<details>
  <summary>Details</summary>
Motivation: 手动设计CGRA面临设计空间巨大、参数独立且耗时等挑战，而LLM的进步为自动化设计提供了新机遇。

Method: 提出MACO框架，采用LLM推理进行软硬件协同设计、设计错误纠正、最佳设计选择和评估反馈，并通过LLM自学习机制优化CGRA。在性能、功耗和面积方面与最先进的LLM方法和手动设计进行比较。

Result: 实验结果表明，MACO能够高效生成高质量的CGRA架构，显著减少手动设计工作量，并且其性能、功耗和面积表现优于现有方法。

Conclusion: MACO框架展示了在实际CGRA设计中利用LLM实现自动化和优化的巨大潜力。

Abstract: Coarse-grained Reconfigurable Arrays (CGRAs) are a promising computing
architecture that can deliver high-performance, energy-efficient acceleration
across diverse domains. By supporting reconfiguration at the functional unit
level, CGRAs efficiently adapt to varying computational patterns and optimize
resource utilization. However, designing CGRAs is highly challenging due to the
vast design space, independent architectural parameters, and the time-consuming
nature of manual design. Fortunately, the rapid advancement of large language
models (LLMs) presents new opportunities to automate this process.
  In this work, we propose MACO -- an open-source multi-agent LLM-based
framework for Hardware/Software (HW/SW) co-design of CGRAs. The framework
employs LLM reasoning to generate CGRAs across four stages: HW/SW co-design,
Design error correction, Best design selection, and Evaluation & Feedback.
Furthermore, MACO iteratively optimizes the generated CGRAs, leveraging agent
reasoning and feedback to achieve higher PPA (that is, power, performance, and
area) design points for a given domain. In addition, we introduce an LLM
self-learning mechanism that employs LLM-driven decision making to select the
optimal CGRA to accelerate the design process.
  We evaluate the framework with state-of-the-art LLM-based methods and manual
CGRA design, in terms of performance, power consumption, and area. Experimental
results show that MACO efficiently generates high-quality CGRA architectures,
significantly reducing manual design effort and demonstrating the potential of
our framework for real-world CGRA design.

</details>


### [331] [StreamTensor: Make Tensors Stream in Dataflow Accelerators for LLMs](https://arxiv.org/abs/2509.13694)
*Hanchen Ye,Deming Chen*

Main category: cs.AR

TL;DR: StreamTensor是一个编译器框架，通过迭代张量类型系统和分层设计空间探索，优化数据流加速器上的深度学习工作负载，在LLM的FPGA评估中实现了低延迟和高能效。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理深度学习工作负载的数据流架构时，在处理核间相关性、外部内存访问管理和缓冲区优化方面存在挑战。

Method: StreamTensor提出了一个迭代张量类型系统，用于显式编码流布局，实现核融合、缓冲区分配和内存优化，并通过探索张量分块、核融合和资源分配三个分层设计空间来优化性能。

Result: 在LLM的FPGA评估中，StreamTensor实现了比最先进的FPGA LLM加速器和GPU低0.76倍和0.64倍的延迟，并且比GPU高1.99倍的能效。

Conclusion: StreamTensor是一种有前景的、可扩展的数据流深度学习加速方法。

Abstract: Efficient execution of deep learning workloads on dataflow architectures is
crucial for overcoming memory bottlenecks and maximizing performance. While
streaming intermediate results between computation kernels can significantly
improve efficiency, existing approaches struggle with inter-kernel
correlations, external memory access management, and buffer optimization. In
this work, we propose StreamTensor, a compiler framework that automatically
constructs and optimizes stream-based dataflow accelerators. StreamTensor
introduces a novel iterative tensor type system to explicitly encode stream
layouts, enabling seamless kernel fusion, buffer allocation, and memory
optimization. By systematically exploring three hierarchical design spaces,
including tensor tiling, kernel fusion, and resource allocation, StreamTensor
balances computational intensity, memory efficiency, and data streaming to
maximize performance. Based on FPGA evaluations on Large Language Models (LLM),
StreamTensor achieves up to 0.76x and 0.64x lower latency compared to the
state-of-the-art FPGA LLM accelerators and GPUs, and up to 1.99x higher energy
efficiency compared to GPUs, making it a promising approach for scalable
dataflow-based deep learning acceleration.

</details>


### [332] [CompAir: Synergizing Complementary PIMs and In-Transit NoC Computation for Efficient LLM Acceleration](https://arxiv.org/abs/2509.13710)
*Hongyi Li,Songchen Ma,Huanyu Qu,Weihao Zhang,Jia Chen,Junfeng Lin,Fengbin Tu,Rong Zhao*

Main category: cs.AR

TL;DR: CompAir是一种创新的混合PIM架构，结合了DRAM-PIM和SRAM-PIM，并通过片上网络（NoC）进行增强，以高效处理大型语言模型（LLM）的推理任务，显著提高了性能并降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的计算和能源需求巨大，内存墙（处理器-内存速度差距）是LLM推理的关键瓶颈。现有的处理内存（PIM）架构在灵活性、性能和成本效益方面难以平衡LLM的需求。

Method: 提出了一种名为CompAir的新型PIM架构，它集成了DRAM-PIM和SRAM-PIM，并采用混合键合技术。开发了CompAir-NoC，一个嵌入了算术逻辑单元（ALU）的先进网络芯片（NoC），可在数据移动时执行非线性运算。设计了一个分层指令集架构（ISA）以确保混合PIM的灵活性和可编程性。

Result: 与当前最先进的全PIM架构相比，CompAir在预填充（prefill）阶段实现了1.83-7.98倍的性能提升，在解码（decode）阶段实现了1.95-6.28倍的性能提升。与混合A100和HBM-PIM系统相比，CompAir在吞吐量相当的情况下，能耗降低了3.52倍。

Conclusion: CompAir是第一个系统性探索具有网络内计算能力的混合DRAM-PIM和SRAM-PIM架构的工作，为LLM提供了高能效的解决方案。

Abstract: The rapid advancement of Large Language Models (LLMs) has revolutionized
various aspects of human life, yet their immense computational and energy
demands pose significant challenges for efficient inference. The memory wall,
the growing processor-memory speed disparity, remains a critical bottleneck for
LLM. Process-In-Memory (PIM) architectures overcome limitations by co-locating
compute units with memory, leveraging 5-20$\times$ higher internal bandwidth
and enabling greater energy efficiency than GPUs. However, existing PIMs
struggle to balance flexibility, performance, and cost-efficiency for LLMs'
dynamic memory-compute patterns and operator diversity. DRAM-PIM suffers from
inter-bank communication overhead despite its vector parallelism. SRAM-PIM
offers sub-10ns latency for matrix operation but is constrained by limited
capacity. This work introduces CompAir, a novel PIM architecture that
integrates DRAM-PIM and SRAM-PIM with hybrid bonding, enabling efficient linear
computations while unlocking multi-granularity data pathways. We further
develop CompAir-NoC, an advanced network-on-chip with an embedded arithmetic
logic unit that performs non-linear operations during data movement,
simultaneously reducing communication overhead and area cost. Finally, we
develop a hierarchical Instruction Set Architecture that ensures both
flexibility and programmability of the hybrid PIM. Experimental results
demonstrate that CompAir achieves 1.83-7.98$\times$ prefill and
1.95-6.28$\times$ decode improvement over the current state-of-the-art fully
PIM architecture. Compared to the hybrid A100 and HBM-PIM system, CompAir
achieves 3.52$\times$ energy consumption reduction with comparable throughput.
This work represents the first systematic exploration of hybrid DRAM-PIM and
SRAM-PIM architectures with in-network computation capabilities, offering a
high-efficiency solution for LLM.

</details>


### [333] [TENET: An Efficient Sparsity-Aware LUT-Centric Architecture for Ternary LLM Inference On Edge](https://arxiv.org/abs/2509.13765)
*Zhirui Huang,Rui Ma,Shijie Cao,Ran Shu,Ian Wang,Ting Cao,Chixiao Chen,Yongqiang Xiong*

Main category: cs.AR

TL;DR: Ternary quantization is an effective method for LLM compression, but current platforms like GPUs are not optimized for it. TENET is a new architecture that co-optimizes algorithm, compute, and memory for ternary LLM inference, using a Sparse Ternary LUT (STL) core, Dynamic Activation N:M Sparsity, and a LUT-based weight decompression module. Its heterogeneous accelerator design and dataflow achieve significant improvements in energy efficiency and inference latency compared to A100 GPUs.


<details>
  <summary>Details</summary>
Motivation: Conventional LLM inference platforms (e.g. GPUs) lack native support for ternary arithmetic and memory specialization, and are under-utilized in low-batch, real-time scenarios, hindering the benefits of ternary quantization.

Method: TENET proposes a sparse-aware LUT-centric architecture featuring a Sparse Ternary LUT (STL) core for optimized ternary mixed-precision GEMM, Dynamic Activation N:M Sparsity for activation sparsity, and a LUT-based 64B:80B ternary weight decompression module. It also introduces a heterogeneous TENET accelerator integrating STL cores with high-precision cores and a Linear-Projection-aware Sparse Attention dataflow.

Result: TENET-FPGA and TENET-ASIC demonstrate significant improvements in energy efficiency, with 4.3x and 21.1x gains respectively over A100 GPU. TENET-ASIC also achieves a 2.7x average speedup in end-to-end inference latency compared to A100 GPU.

Conclusion: TENET is a novel architecture that effectively addresses the limitations of current platforms for ternary LLM inference, delivering substantial improvements in energy efficiency and inference speed through its specialized hardware and dataflow optimizations.

Abstract: Ternary quantization has emerged as a powerful technique for reducing both
computational and memory footprint of large language models (LLM), enabling
efficient real-time inference deployment without significantly compromising
model accuracy. Conventional LLM inference platforms (e.g GPUs) cannot
capitalize on its benefits, as they (i) lack native support for ternary
arithmetic and memory specialization and (ii) remain severely under-utilized in
low-batch, real-time scenarios. In this work, we propose TENET, a sparse-aware
LUT-centric architecture that co-optimizes algorithm, compute, and memory for
ternary LLM inference. To maximize the efficiency of Ternary Linear layer,
TENET introduces a Sparse Ternary LUT (STL) core that optimizes ternary
mixed-precision GEMM using a symmetric precompute lookup table. It also
features Dynamic Activation N:M Sparsity to exploit the sparsity within the
activation of each token. Additionally, we propose a LUT-based 64B:80B ternary
weight decompression module to fully exploit the memory efficiency of ternary
values. At the system level, we design a heterogeneous TENET accelerator with
full programmability that integrates STL cores with high-precision cores. An
associated Linear-Projection-aware Sparse Attention dataflow is introduced to
optimize memory access and hardware utilization. We implement TENET accelerator
prototype on both FPGA and ASIC platforms. Experiments across various model
sizes and workloads demonstrate that TENET-FPGA and TENET-ASIC improve energy
efficiency by 4.3$\times$ and 21.1$\times$, respectively, compared to the A100
GPU. Furthermore, TENET-ASIC achieves a 2.7$\times$ average speedup compared to
the A100 GPU in end-to-end inference latency.

</details>


### [334] [An RDMA-First Object Storage System with SmartNIC Offload](https://arxiv.org/abs/2509.13997)
*Yu Zhu,Aditya Dhakal,Pedro Bruel,Gourav Rattihalli,Yunming Xiao,Johann Lombardi,Dejan Milojicic*

Main category: cs.AR

TL;DR: ROS2是一个RDMA优先的对象存储系统，将DAOS客户端卸载到SmartNIC上，以提高AI训练的I/O性能。


<details>
  <summary>Details</summary>
Motivation: AI训练和推理对存储路径造成持续的、细粒度的I/O压力，需要对现有的基于TCP的存储路径进行优化。

Method: ROS2采用RDMA优先的设计，将DAOS客户端卸载到NVIDIA BlueField-3 SmartNIC上，通过UCX/libfabric实现数据传输，并分离控制平面和数据平面，移除主机在数据路径上的中介。

Result: 在服务器级CPU上，RDMA在顺序和随机I/O方面均优于TCP。将DAOS客户端卸载到BlueField-3后，端到端性能与主机相当，表明SmartNIC卸载可以保持RDMA效率，并支持DPU驻留功能。然而，SmartNIC上的TCP性能有所下降。

Conclusion: 基于RDMA优先、SmartNIC卸载的对象存储堆栈为扩展现代LLM训练环境中的数据传输提供了实用的基础。

Abstract: AI training and inference impose sustained, fine-grain I/O that stresses
host-mediated, TCP-based storage paths. Motivated by kernel-bypass networking
and user-space storage stacks, we revisit POSIX-compatible object storage for
GPU-centric pipelines. We present ROS2, an RDMA-first object storage system
design that offloads the DAOS client to an NVIDIA BlueField-3 SmartNIC while
leaving the DAOS I/O engine unchanged on the storage server. ROS2 separates a
lightweight control plane (gRPC for namespace and capability exchange) from a
high-throughput data plane (UCX/libfabric over RDMA or TCP) and removes host
mediation from the data path.
  Using FIO/DFS across local and remote configurations, we find that on
server-grade CPUs RDMA consistently outperforms TCP for both large sequential
and small random I/O. When the RDMA-driven DAOS client is offloaded to
BlueField-3, end-to-end performance is comparable to the host, demonstrating
that SmartNIC offload preserves RDMA efficiency while enabling DPU-resident
features such as multi-tenant isolation and inline services (e.g.,
encryption/decryption) close to the NIC. In contrast, TCP on the SmartNIC lags
host performance, underscoring the importance of RDMA for offloaded
deployments.
  Overall, our results indicate that an RDMA-first, SmartNIC-offloaded
object-storage stack is a practical foundation for scaling data delivery in
modern LLM training environments; integrating optional GPU-direct placement for
LLM tasks is left for future work.

</details>


### [335] [A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching](https://arxiv.org/abs/2509.14041)
*Henry Kao,Nikhil Sreekumar,Prabhdeep Singh Soni,Ali Sedaghati,Fang Su,Bryan Chan,Maziar Goudarzi,Reza Azimi*

Main category: cs.AR

TL;DR: TRRIP是一种软硬件协同设计方法，通过编译器分析和转换代码的“温度”（热/冷），并利用代码页属性通过操作系统接口向硬件提供代码温度信息，从而优化指令缓存替换策略，减少热代码的淘汰率，最终降低L2 MPKI并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代移动CPU软件因其复杂的运行时行为导致指令执行重用间隔长，给传统的指令缓存替换策略带来挑战，进而导致CPU前端停滞和资源饥饿。随着移动应用复杂度和代码占用空间增长速度超过片上内存增长速度，传统的硬件中心化指令缓存管理方法已不足以应对。

Method: TRRIP提出了一种新颖的软硬件协同设计方法。它允许编译器根据指令的“温度”（热/冷）来分析、分类和转换代码。然后，通过一个明确定义的操作系统接口，利用代码页属性向硬件提供代码温度信息的摘要。TRRIP的轻量级硬件扩展利用代码温度属性来优化指令缓存替换策略，以减少热代码的淘汰率。

Result: TRRIP能够将指令的L2 MPKI降低26.5%，在已经使用PGO优化过的移动代码上，实现了3.9%的几何平均加速。

Conclusion: TRRIP是一种实用的、可接受的软硬件协同设计方法，适用于对软件和硬件组件都有严格功能要求的移动系统。

Abstract: Modern mobile CPU software pose challenges for conventional instruction cache
replacement policies due to their complex runtime behavior causing high reuse
distance between executions of the same instruction. Mobile code commonly
suffers from large amounts of stalls in the CPU frontend and thus starvation of
the rest of the CPU resources. Complexity of these applications and their code
footprint are projected to grow at a rate faster than available on-chip memory
due to power and area constraints, making conventional hardware-centric methods
for managing instruction caches to be inadequate. We present a novel
software-hardware co-design approach called TRRIP (Temperature-based
Re-Reference Interval Prediction) that enables the compiler to analyze,
classify, and transform code based on "temperature" (hot/cold), and to provide
the hardware with a summary of code temperature information through a
well-defined OS interface based on using code page attributes. TRRIP's
lightweight hardware extension employs code temperature attributes to optimize
the instruction cache replacement policy resulting in the eviction rate
reduction of hot code. TRRIP is designed to be practical and adoptable in real
mobile systems that have strict feature requirements on both the software and
hardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%
resulting in geomean speedup of 3.9%, on top of RRIP cache replacement running
mobile code already optimized using PGO.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [336] [Numerical Optimization Methods in the environment with Quantum Noise](https://arxiv.org/abs/2509.13367)
*Tomáš Bezděk*

Main category: quant-ph

TL;DR: 量子算法结合经典优化方法，用于精确计算化学反应中的电子势能面。


<details>
  <summary>Details</summary>
Motivation: 准确计算多电子体系的势能面，特别是在圆锥交叉点附近，对于理解光化学过程至关重要。现有方法在可扩展性或硬件方面存在限制。

Method: 提出并实现了一种名为状态平均轨道优化变分量子特征求解器（SA-OO-VQE）的混合量子-经典算法。该算法结合了量子态制备和经典的状态平均轨道优化。同时，评估了差分进化算法在SA-OO-VQE框架内的表现，并与BFGS和SLSQP等经典优化器进行了比较。

Result: 通过计算H2、H4和LiH的基态和第一激发态能量，以及使用甲醛亚胺作为案例研究，证明了SA-OO-VQE能够准确模拟圆锥交叉点附近的势能面。结果表明，轨道优化对于捕捉势能面的拓扑结构至关重要，而基于梯度的优化方法（如BFGS和SLSQP）比差分进化算法表现更好。

Conclusion: SA-OO-VQE是一种处理复杂电子结构的有效方法，其中轨道优化是精确模拟势能面的关键。梯度下降优化器在SA-OO-VQE框架中比差分进化算法更具优势。

Abstract: The accurate calculation of electronic potential energy surfaces for ground
and excited states is crucial for understanding photochemical processes,
particularly near conical intersections. While classical methods are limited by
scaling and quantum algorithms by hardware, this thesis focuses on the
State-Averaged Orbital-Optimized Variational Quantum Eigensolver (SA-OO-VQE).
This hybrid quantum-classical algorithm provides a balanced description of
multiple electronic states by combining quantum state preparation with
classical state-averaged orbital optimization.
  A key contribution is the implementation and evaluation of the Differential
Evolution algorithm within the SA-OO-VQE framework, with a comparative study
against classical optimizers like the Broyden-Fletcher-Goldfarb-Shanno (BFGS)
and Sequential Least Squares Programming (SLSQP) algorithms. The performance of
these optimizers is assessed by calculating ground and first excited state
energies for H$_2$, H$_4$, and LiH.
  The thesis also demonstrates SA-OO-VQE's capability to accurately model
potential energy surfaces near conical intersections, using formaldimine as a
case study. The results show that orbital optimization is essential for
correctly capturing the potential energy surface topology, a task where
standard methods with fixed orbitals fail. Our findings indicate that while
Differential Evolution presents efficiency challenges, gradient-based methods
like BFGS and SLSQP offer superior performance, confirming that the SA-OO-VQE
approach is crucial for treating complex electronic structures.

</details>


### [337] [Rare Event Simulation of Quantum Error-Correcting Circuits](https://arxiv.org/abs/2509.13678)
*Carolyn Mayer,Anand Ganti,Uzoma Onunkwo,Tzvetan Metodi,Benjamin Anker,Jacek Skryzalin*

Main category: quant-ph

TL;DR: We present a novel rare event simulation technique for analyzing the failure rates of quantum error-correcting circuits, enabling simulations at failure rates below 10^-20, which is significantly lower than previously possible with standard Monte Carlo methods.


<details>
  <summary>Details</summary>
Motivation: Standard Monte Carlo methods struggle to accurately simulate the low physical failure rates of quantum error-correcting circuits, especially for larger circuits or those with high correcting power. This limitation prevents the study of failure rates below the 10^-6 regime.

Method: This paper adapts and extends the rare event simulation by splitting technique, originally developed by Bravyi and Vargo, to a circuit-based noise model. This approach allows for more efficient and accurate simulations at extremely low failure rates.

Result: The proposed method successfully simulates quantum error-correcting circuits at logical failure rates below 10^-20. The results have been validated against standard Monte Carlo simulations in an accessible regime, confirming their accuracy.

Conclusion: The developed rare event simulation technique provides a practical and effective way to analyze the performance of quantum error-correcting codes under very low physical failure rates, opening up new possibilities for the study and design of fault-tolerant quantum computers.

Abstract: We describe a practical approach for accessing the logical failure rates of
quantum error-correcting (QEC) circuits under low physical (component) failure
rate regimes. Standard Monte Carlo is often the de facto approach for studying
the failure rates of quantum circuits. However, in the study of fault-tolerant
error-correcting circuits, the ability to extend this approach to low physical
failure rates is limited. In particular, the use of Monte Carlo to access
circuits that are relatively large or have high correcting power becomes more
difficult as we lower the input failure rates of the individual components
(gates) in the circuit. For these reasons, many simulations studying the
circuit model go no lower than end-to-end logical failure rates in the 10^{-6}
regime. In this report, we outline an approach that borrows from earlier work
by Bravyi and Vargo to the more complex circuit noise model. Earlier works
studied both the capacity and phenomenological noise models, but the work is
insufficient for generating similar simulations in the circuit-noise model. To
the best of our knowledge, our team is the first to develop a full prescription
of the rare event simulation by splitting technique for the circuit-based noise
model. We have also generated promising results that are confirmed by standard
Monte Carlo simulation under an accessible regime. This work shows that we can
access noise in the circuit-model prescription of quantum error-correcting code
to failure rates below 10^{-20} regime.

</details>


### [338] [Purification of quantum trajectories in infinite dimensions](https://arxiv.org/abs/2509.13377)
*Federico Girotti,Alessandro Vitale*

Main category: quant-ph

TL;DR: 有限维度和无限维度量子系统中的纯化存在差异。


<details>
  <summary>Details</summary>
Motivation: 研究在无限维度系统中，有限维度系统中的量子轨迹纯化理论是否仍然成立。

Method: 通过展示一类新的例子，并在无限维度系统中证明阻止纯化的新现象是唯一可能出现的情况，同时指出该现象的出现是由于正交投影集不是序列紧集。

Result: 在无限维度系统中，量子轨迹的纯化理论失效，并且出现了一种新的现象阻止了纯化。

Conclusion: 有限维度系统的理论可以扩展到一类无限维度模型。

Abstract: In this work we exhibit a class of examples that show that the
characterization of purification of quantum trajectories in terms of 'dark'
subspaces that was proved for finite dimensional systems fails to hold in
infinite dimensional ones. Moreover, we prove that the new phenomenon emerging
in our class of models and preventing purification to happen is the only new
possibility that emerges in infinite dimensional systems. Our proof strategy
points out that the emergence of new phenomena in infinite dimensional systems
is due to the fact that the set of orthogonal projections is not sequentially
compact. Having in mind this insight, we are able to prove that the finite
dimensional extends to a class of infinite dimensional models.

</details>


### [339] [Quantum ground-state cooling of two librational modes of a nanorotor](https://arxiv.org/abs/2509.13398)
*Stephan Troyer,Florian Fechtel,Lorenz Hummer,Henning Rudolph,Benjamin A. Stickler,Uroš Delić,Markus Arndt*

Main category: quant-ph

TL;DR: 通过光学镊子捕获并冷却纳米二聚体和三聚体，使其振动模式达到量子基态，从而精确控制纳米旋转器的运动。


<details>
  <summary>Details</summary>
Motivation: 控制纳米物体在量子极限下的运动，以进行新的量子力学检验和开发先进的传感器。特别地，对旋转运动的控制尤为重要，因其具有非线性动力学特性。

Method: 使用光学镊子捕获二氧化硅纳米二聚体和三聚体，并通过腔增强相干散射技术冷却两种不同的振动模式（$eta$和$eta$模式）至量子基态，同时冷却这两种自由度。

Result: 成功将两种振动模式冷却至量子基态，占据数低至 $n_{eta}=0.54	ext{±}0.32$ 和 $n_{	ext{α}}=0.21	ext{±}0.03$。同时冷却两种自由度时，实现了优于20$	ext{μ}$rad的精度，接近零点振幅。

Conclusion: 实验证明了在光学镊子中捕获和冷却纳米旋转器至量子基态的可行性，并实现了对纳米旋转器的高精度空间定向，为进一步的量子实验奠定了基础。

Abstract: Controlling the motion of nanoscale objects at the quantum limit promises new
tests of quantum mechanics and advanced sensors. Rotational motion is of
particular interest, as it follows nonlinear dynamics in a compact, closed
configuration space, which opens up a plethora of phenomena and applications
beyond the possibilities of free or trapped linear motion. A prerequisite for
such experiments is the capability to trap nanorotors and initialize them in a
quantum ground state of libration. Here, we demonstrate the reliable,
repetitive laser-induced loading of silica nanodimers and trimers into an
optical tweezer. Coherent scattering in a high-finesse cavity allows us to cool
two different librational modes to the quantum ground state with occupation
numbers as low as $n_{\beta}=0.54\pm0.32$ and $n_{\alpha}=0.21\pm0.03$. By
simultaneously cooling both degrees of freedom ($n_\beta=0.73\pm0.22$,
$n_\alpha=1.02\pm0.08$) we align nanorotors to a space-fixed axis with
precision better than 20$\,\mu$rad, close to the zero-point amplitude of
librations.

</details>


### [340] [Defining Security in Quantum Key Distribution](https://arxiv.org/abs/2509.13405)
*Carla Ferradini,Martin Sandfuchs,Ramona Wolf,Renato Renner*

Main category: quant-ph

TL;DR: 量子密钥分发(QKD)的安全性由参数ε量化，该参数可以明确限定，这与计算安全方案不同，计算安全方案的安全性声明仅是渐近的。


<details>
  <summary>Details</summary>
Motivation: 解释ε-安全性的定义和解释。

Method: 采用公理化方法，将ε理解为安全失败的最大概率。

Result: 对文献中出现的对ε-安全性定义的几项批评进行了回顾和讨论。

Conclusion: ε-安全性可以被理解为安全失败的最大概率。

Abstract: The security of quantum key distribution (QKD) is quantified by a parameter
$\varepsilon>0$, which -- under well-defined physical assumptions -- can be
bounded explicitly. This contrasts with computationally secure schemes, where
security claims are only asymptotic (i.e., under standard complexity
assumptions, one only knows that $\varepsilon \to 0$ as the key size grows, but
has no explicit bound). Here we explain the definition and interpretation of
$\varepsilon$-security. Adopting an axiomatic approach, we show that
$\varepsilon$ can be understood as the maximum probability of a security
failure. Finally, we review and address several criticisms of this definition
that have appeared in the literature.

</details>


### [341] [Free mutual information and higher-point OTOCs](https://arxiv.org/abs/2509.13406)
*Shreya Vardhan,Jinzhao Wang*

Main category: quant-ph

TL;DR: 免费互信息（FMI）是量子混沌的新物理度量，它比传统的算子增长更能精细地捕捉算子的传播。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的物理度量来量化量子混沌，该度量比现有的算子增长概念更精细。

Method: 推导了FMI的“库仑气体”公式，并将FMI与高阶时序无关关联（OTOC）联系起来。

Result: FMI的“库仑气体”公式，FMI与高阶OTOC之间的关系，以及在各种混沌和非混沌系统中FMI和OTOC的普适行为和非普适行为。

Conclusion: FMI是比标准4点OTOC更精确的混沌诊断工具，它量化了算子在算子空间中的扩散，揭示了量子多体混沌的通用特征，并区分了算子空间中的扩散和物理空间中的扩散。

Abstract: We introduce a quantity called the free mutual information (FMI), adapted
from concepts in free probability theory, as a new physical measure of quantum
chaos. This quantity captures the spreading of a time-evolved operator in the
space of all possible operators on the Hilbert space, which is doubly
exponential in the number of degrees of freedom. It thus provides a finer
notion of operator spreading than the well-understood phenomenon of operator
growth in physical space. We derive two central results which apply in any
physical system: first, an explicit ``Coulomb gas'' formula for the FMI of two
observables $A(t)$ and $B$ in terms of the eigenvalues of the product operator
$A(t)B$; and second, a general relation expressing the FMI as a weighted sum of
all higher-point out-of-time-ordered correlators (OTOCs). This second result
provides a precise information-theoretic interpretation for the higher-point
OTOCs as collectively quantifying operator ergodicity and the approach to
freeness. This physical interpretation is particularly useful in light of
recent progress in experimentally measuring higher-point OTOCs. We identify
universal behaviours of the FMI and higher-point OTOCs across a variety of
chaotic systems, including random unitary circuits and chaotic spin chains,
which indicate that spreading in the doubly exponential operator space is a
generic feature of quantum many-body chaos. At the same time, the non-generic
behavior of the FMI in various non-chaotic systems, including certain unitary
designs, shows that there are cases where an operator spreads in physical space
but remains localized in operator space. The FMI is thus a sharper diagnostic
of chaos than the standard 4-point OTOC.

</details>


### [342] [Symmetry Resolved Multipartite Entanglement Entropy](https://arxiv.org/abs/2509.13410)
*Ashwat Jain*

Main category: quant-ph

TL;DR: 我们对 Meyer 和 Wallach 引入的多方纠缠度量 Q 进行了对称性解析，适用于所有存在局部对称性的可区分粒子系统。


<details>
  <summary>Details</summary>
Motivation: 研究多方纠缠度量 Q 的对称性解析，并探讨其在可区分粒子系统中的应用。

Method: 对具有局部对称性的多方可区分粒子系统，对 Meyer 和 Wallach 引入的全局纠缠度量 Q 进行对称性解析。针对 Haar 随机状态的集合，进行了计算和分析。

Result: 在 Haar 随机状态的集合中，发现对称性解析后的纠缠度量与均分状态一致，其前导阶数行为和有限尺寸修正呈现出与局部自由度数量的幂律缩放关系。

Conclusion: 该结果对通用的对称性解析多方纠缠范式具有启示意义，并提出了一些可能的实验验证方法。

Abstract: We perform the symmetry resolution of a multipartite entanglement measure,
namely the global entanglement $Q$ introduced by Meyer and Wallach [2002, J. of
Math. Phys., 43, pp. 4273] for all systems of distinguishable particles hosting
a locally acting symmetry. For an ensemble of Haar random states we find
agreement with equipartition, with leading order behaviour and finite size
corrections which follow a power law scaling with the number of local degrees
of freedom. Implications of this result for the general symmetry-resolved
multipartite entanglement paradigm are discussed and some possible experimental
verification methods are presented.

</details>


### [343] [Computational complexity of Berry phase estimation in topological phases of matter](https://arxiv.org/abs/2509.13423)
*Ryu Hayakawa,Kazuki Sakamoto,Chusei Kiumi*

Main category: quant-ph

TL;DR: 本文提出了一个新的量子算法和几个关于Berry相位估计（BPE）问题的复杂性理论结果。该算法在更一般的设定下提供了理论保证的BPE。复杂性方面，在有对基态有大重叠的引导态时，证明了BQP-完备性，实现了指数级加速；在有基态能量先验界时，证明了dUQMA-完备性，这是第一个同时属于UQMA和co-UQMA的自然问题；在无附加假设时，证明了P^dUQMA[log]-硬度和包含于P^PGQMA[log]。这些结果促进了量子计算在拓扑物态研究中的作用，并为阐明拓扑物态与计算复杂性之间的联系提供了途径。


<details>
  <summary>Details</summary>
Motivation: 拓扑物态分类的基本量是Berry相位，而Berry相位估计（BPE）问题的计算复杂性一直是计算复杂性理论和拓扑物态研究中的一个重要问题。

Method: 本文提出了一个新的量子算法，并从三个方面研究了BPE问题的计算复杂性：1. 当存在与基态有大重叠的引导态时，证明BPE问题是BQP-完全的。2. 引入了一个新的复杂性类dUQMA，并证明当基态能量有先验界时，BPE问题是dUQMA-完全的。3. 当没有附加假设时，证明BPE问题是P^dUQMA[log]-硬的，并且包含于P^PGQMA[log]。

Result: 1. 存在引导态时，BPE问题的计算复杂度为BQP-完全。2. 基态能量有先验界时，BPE问题的计算复杂度为dUQMA-完全。3. 没有附加假设时，BPE问题是P^dUQMA[log]-硬的，并且包含于P^PGQMA[log]。

Conclusion: 本文提出的量子算法和复杂性理论结果，不仅为Berry相位估计问题提供了更强的计算复杂性保证，而且为理解拓扑物态与计算复杂性之间的联系提供了新的视角，有价值的视角。

Abstract: The Berry phase is a fundamental quantity in the classification of
topological phases of matter. In this paper, we present a new quantum algorithm
and several complexity-theoretical results for the Berry phase estimation (BPE)
problems. Our new quantum algorithm achieves BPE in a more general setting than
previously known quantum algorithms, with a theoretical guarantee. For the
complexity-theoretic results, we consider three cases. First, we prove
$\mathsf{BQP}$-completeness when we are given a guiding state that has a large
overlap with the ground state. This result establishes an exponential quantum
speedup for estimating the Berry phase. Second, we prove
$\mathsf{dUQMA}$-completeness when we have \textit{a priori} bound for ground
state energy. Here, $\mathsf{dUQMA}$ is a variant of the unique witness version
of $\mathsf{QMA}$ (i.e., $\mathsf{UQMA}$), which we introduce in this paper,
and this class precisely captures the complexity of BPE without the known
guiding state. Remarkably, this problem turned out to be the first natural
problem contained in both $\mathsf{UQMA}$ and $\mathsf{co}$-$\mathsf{UQMA}$.
Third, we show $\mathsf{P}^{\mathsf{dUQMA[log]}}$-hardness and containment in
$\mathsf{P}^{\mathsf{PGQMA[log]}}$ when we have no additional assumption. These
results advance the role of quantum computing in the study of topological
phases of matter and provide a pathway for clarifying the connection between
topological phases of matter and computational complexity.

</details>


### [344] [Simulation of bilayer Hamiltonians based on monitored quantum trajectories](https://arxiv.org/abs/2509.13440)
*Yuan Xue,Zihan Cheng,Matteo Ippoliti*

Main category: quant-ph

TL;DR: Bilayer systems can be mapped to monitored monolayer systems, simplifying simulations and offering a new perspective on methods like AFQMC.


<details>
  <summary>Details</summary>
Motivation: To explore an opposite approach to treating mixed states, mapping isolated bilayer systems to open monolayer systems for potentially reduced computational cost.

Method: Mapping arbitrary bilayer Hamiltonians with antiunitary layer exchange symmetry and constraints on interlayer couplings to Lindbladians on a monolayer system with postselected jump operators. Simulating late-time dynamics of the monolayer system using quantum trajectory methods.

Result: Low-energy states of the bilayer Hamiltonian correspond to late-time states of the monolayer dynamics. The approach can reduce computational cost by effectively halving the system size. For free fermion dynamics, the approach reduces to AFQMC, providing a physical interpretation of its sign-free criteria.

Conclusion: The proposed method offers a computationally efficient way to study bilayer systems by mapping them to open monolayer systems, with implications for understanding and interpreting existing simulation methods like AFQMC.

Abstract: In the study of open quantum systems it is often useful to treat mixed states
as pure states of a fictitious doubled system. In this work we explore the
opposite approach: mapping isolated bilayer systems to open monolayer systems.
Specifically, we show that arbitrary bilayer Hamiltonians possessing an
antiunitary layer exchange symmetry, and subject to a constraint on the sign of
interlayer couplings, can be mapped to Lindbladians on a monolayer system with
some of the jump operators postselected on a fixed outcome ("monitored").
Low-energy states of the bilayer Hamiltonian then correspond to late-time
states of the monolayer dynamics. Simulating the latter by quantum trajectory
methods has the potential of substantially reducing the computational cost of
estimating low-energy observables in the bilayer Hamiltonian by effectively
halving the system size. The overhead due to sampling quantum trajectories can
be controlled by a suitable importance sampling scheme. We show that, when the
quantum trajectories exhibit free fermion dynamics, our approach reduces to the
auxiliary field quantum Monte Carlo (AFQMC) method. This provides a physically
transparent interpretation of the AFQMC sign-free criteria in terms of
properties of quantum dynamics. Finally, we benchmark our approach on the 1D
quantum Ashkin-Teller model.

</details>


### [345] [Direct Experimental Observation of Quantum Mpemba Effect without Bath Engineering](https://arxiv.org/abs/2509.13451)
*Arijit Chatterjee,Sakil Khan,Sachin Jain,T S Mahesh*

Main category: quant-ph

TL;DR: 量子系统比接近平衡状态的系统更快地达到热平衡，这被称为量子姆潘巴效应。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在实验证明量子姆潘巴效应在量子系统热化过程中可以自然发生。

Method: 通过考虑偶极弛豫作为主导退相干过程，理论推导出核自旋中出现姆潘巴效应的条件。然后，在实验上制备满足这些条件的核自旋态，并观察它们在无人为干预的情况下达到热平衡的过程。

Result: 实验观察到了量子姆潘巴效应，并且在核自旋热化过程中观察到了真正的量子姆潘巴效应。

Conclusion: 研究结果表明，量子姆潘巴效应（包括真正的量子姆潘巴效应）是量子系统热化过程中的自然现象，并且可以在无需任何浴调控的情况下出现。

Abstract: The quantum Mpemba effect refers to the phenomenon of a quantum system in an
initial state, far away from equilibrium, relaxing much faster than a state
comparatively nearer to equilibrium. We experimentally demonstrate that this
highly counterintuitive effect can occur naturally during the thermalization of
quantum systems. Considering dipolar relaxation as the dominant decoherence
process, we theoretically derive the conditions that can lead to the Mpemba
effect in nuclear spins. After experimentally preparing nuclear spin states
dictated by those conditions, we observe the occurrence of the Mpemba effect
when they are left to thermalize without any external control. We also
experimentally observe the genuine quantum Mpemba effect during thermalization
of nuclear spins. Our results establish that both these effects are natural in
thermalization of quantum systems, and may show up without the need for any
bath engineering.

</details>


### [346] [From virtual Z gates to virtual Z pulses](https://arxiv.org/abs/2509.13453)
*Christopher K. Long,Crispin H. W. Barnes*

Main category: quant-ph

TL;DR: 虚拟Z门在脉冲层面被理论化，扩展了其在NISQ设备上的应用，并展示了其在半导体和超导量子处理器上的实现，同时还拓展了其在模拟和变分算法中的应用。


<details>
  <summary>Details</summary>
Motivation: 虚拟Z门对于实现快速、高保真的单量子比特操作至关重要，但现有方法对两量子比特门有特定要求。本研究旨在将虚拟Z门理论扩展到脉冲层面，以更好地利用当前的NISQ设备，减少门编译和转译的开销。

Method: 通过对控制量子处理器的脉冲序列进行时间膨胀，推导出了一个平台无关的虚拟Z脉冲理论框架，并提供了在半导体自旋量子比特和超导量子处理器架构上实现虚拟Z脉冲的实例。

Result: 研究发现，虚拟Z脉冲（及其对应的虚拟Z门）可以在之前不支持虚拟Z门的硬件上实现。此外，虚拟Z脉冲还可以拓宽可原生模拟的哈密顿量类别，并增强脉冲式变分量子算法的表现力。

Conclusion: 虚拟Z脉冲为在NISQ设备上实现更高效、更通用的量子计算提供了新的途径，尤其是在门操作和算法设计方面具有重要意义。

Abstract: Virtual $Z$ gates have become integral for implementing fast, high-fidelity
single-qubit operations. However, virtual $Z$ gates require that the system's
two-qubit gates are microwave-activated or normalise the single-qubit $Z$
rotations$\unicode{x2014}$the group generated by $X$, $\operatorname{SWAP}$,
and arbitrary phase gates. Herein, we extend the theory of virtual $Z$ gates to
the pulse-level, which underlies both gate design and the recent advancements
of pulse-level quantum algorithms. These algorithms attempt to utilise the full
potential of present-day noisy intermediate-scale quantum (NISQ) devices by
removing overheads associated with the compilation and transpilation of gates.
To extend the theory of virtual $Z$ gates, we derive a platform-agnostic
theoretical framework for virtual $Z$ pulses by employing time dilations of the
pulse sequences that control the quantum processor. Additionally, we provide
worked examples of the implementation of virtual $Z$ pulses on both
semiconductor spin qubit and superconducting quantum processor architectures.
Moreover, we present a general overview of the hardware support for virtual $Z$
pulses. We find virtual $Z$ pulses (and thus, virtual $Z$ gates) can be used on
hardware that, with previous methods, did not support the virtual $Z$ gate.
Finally, we present two additional applications of virtual $Z$ pulses to
pulse-level algorithms. First, broadening the class of Hamiltonians that can be
natively simulated in an analogue manner. Second, increasing the expressibility
of pulse-based variational quantum algorithms.

</details>


### [347] [A Closeness Centrality-based Circuit Partitioner for Quantum Simulations](https://arxiv.org/abs/2509.14098)
*Doru Thom Popovici,Harlin Lee,Mauro Del Ben,Naoki Yoshioka,Nobuyasu Ito,Katherine Klymko,Daan Camps,Anastasiia Butko*

Main category: quant-ph

TL;DR: 通过将量子态和电路的分布构建为图问题，并应用紧密度中心性评估门的重要性，从而为大型量子电路设计了一种快速、可扩展的划分方法，并生成了一个便携式解决方案，可最大限度地减少跨计算节点的数据移动，从而为量子算法模拟的性能和可扩展性提供关键见解。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算机的硬件限制，需要高性能计算系统来模拟量子电路，但这些模拟需要大量资源，因此需要能够容纳大型集群和内存占用的系统。

Method: 将量子态和电路的分布构建为图问题，并应用紧密度中心性来评估门的重要性，设计了一种快速、可扩展的划分方法，并生成了一个灵活的代码生成器，用于创建可移植的解决方案，最大限度地减少跨计算节点的数据移动。

Result: 该框架能够为大型量子电路提供一种高效的划分方案，并生成可移植的、经过高度优化的代码，这些代码可以在各种超级计算机上无缝运行。

Conclusion: 该工作提出了一种端到端的框架，用于在高性能计算系统上高效地模拟大型量子电路，通过图论和优化代码生成，解决了当前量子硬件的局限性，并为量子算法模拟的性能和可扩展性提供了关键见解。

Abstract: Simulating quantum circuits (QC) on high-performance computing (HPC) systems
has become an essential method to benchmark algorithms and probe the potential
of large-scale quantum computation despite the limitations of current quantum
hardware. However, these simulations often require large amounts of resources,
necessitating the use of large clusters with thousands of compute nodes and
large memory footprints. In this work, we introduce an end-to-end framework
that provides an efficient partitioning scheme for large-scale QCs alongside a
flexible code generator to offer a portable solution that minimizes data
movement between compute nodes. By formulating the distribution of quantum
states and circuits as a graph problem, we apply closeness centrality to assess
gate importance and design a fast, scalable partitioning method. The resulting
partitions are compiled into highly optimized codes that run seamlessly on a
wide range of supercomputers, providing critical insights into the performance
and scalability of quantum algorithm simulations.

</details>


### [348] [The original Wigner's-Friend scenarios](https://arxiv.org/abs/2509.13470)
*Jay Lawrence*

Main category: quant-ph

TL;DR: Wigner's-Friend


<details>
  <summary>Details</summary>
Motivation: Wigner's-Friend scenario

Method: Decoherence theory

Result: Three stories fit together to form a consistent picture without a paradox.

Conclusion: Despite different interpretations (or their absence), these three stories fit together to form a consistent picture without a paradox.

Abstract: We describe the Wigner's-Friend scenario according to Wigner, then a similar
but earlier version according to Everett. Wigner and Everett provide different
resolutions of essentially the same paradox. Decoherence theory provides a
third resolution. Despite different interpretations (or their absence), these
three stories fit together to form a consistent picture without a paradox.

</details>


### [349] [Quantum speed limit for the OTOC from an open systems perspective](https://arxiv.org/abs/2509.13519)
*Devjyoti Tripathy,Juzar Thingna,Sebastian Deffner*

Main category: quant-ph

TL;DR: 量子信息在OTOC中以指数级增长，并通过对OTOC进行重正化，我们得出了量子速度限制，它设定了信息 the rate of scrambling 的下限。这可以通过将封闭量子系统中的信息 scrambling 描述为与环境相互作用的开放系统的有效退相干过程来解决。


<details>
  <summary>Details</summary>
Motivation: Scrambling（量子信息从局部状态到离域状态的扩散）通常用OTOC（out-of-time ordered correlator）来表征。OTOC-Renyi-2熵定理被用来推导OTOC的量子速度限制，从而为信息 scrambling 的速率设定一个下限。

Method: 将封闭量子系统中的信息 scrambling 过程，等效地描述为与环境相互作用的开放系统中的退相干过程，并利用OTOC-Renyi-2熵定理推导OTOC的量子速度限制。

Result: OTOC的衰减可以被系统-环境耦合强度和两点环境关联函数所限制。通过对非积分式横向场伊辛模型进行数值验证，得出了分析边界。

Conclusion: 该研究提出了一个通用的、与模型无关的定量框架，用于理解量子多体物理、凝聚态物理和工程量子平台中信息传播的动力学极限。

Abstract: Scrambling, the delocalization of initially localized quantum information, is
commonly characterized by the out-of-time ordered correlator (OTOC). Employing
the OTOC-Renyi-2 entropy theorem we derive a quantum speed limit for the OTOC,
which sets an lower bound for the rate with which information can be scrambled.
This bound becomes particularly tractable by describing the scrambling of
information in a closed quantum system as an effective decoherence process of
an open system interacting with an environment. We prove that decay of the OTOC
can be bounded by the strength of the system-environment coupling and two-point
environmental correlation functions. We validate our analytic bound numerically
using the non-integrable transverse field Ising model. Our results provide a
universal and model-agnostic quantitative framework for understanding the
dynamical limits of information spreading across quantum many-body physics,
condensed matter, and engineered quantum platforms.

</details>


### [350] [Evaluating the Limits of QAOA Parameter Transfer at High-Rounds on Sparse Ising Models With Geometrically Local Cubic Terms](https://arxiv.org/abs/2509.13528)
*Elijah Pelofske,Marek Rams,Andreas Bärtschi,Piotr Czarnik,Paolo Braccia,Lukasz Cincio,Stephan Eidenbenz*

Main category: quant-ph

TL;DR: QAOA参数迁移在组合优化问题中表现出潜力，尽管性能随深度增加并非单调，但仍能接近最优解，并在实际硬件上显示出持续的改进。


<details>
  <summary>Details</summary>
Motivation: QAOA在组合优化中存在参数寻找的局限性，而参数迁移现象（即在相似问题实例上训练的参数可迁移到其他相似实例）为解决此问题提供了新的途径。

Method: 通过JuliQAOA工具，研究了QAOA参数从小型问题（16-27量子比特）迁移到大型问题（最多156量子比特）的重-hex图Ising模型上的迁移性，并使用多种数值模拟方法（包括全态矢量、PEPS、MPS和LOWESA）进行了验证。同时，在IBM的超导量子处理器上测试了迁移的固定QAOA参数在实际硬件上的表现。

Result: 研究发现，QAOA参数迁移的性能随深度p的增加并非单调递增，但整体上期望值呈现提高趋势，并能接近真实基态能量。在实际量子硬件上，QAOA参数迁移得到的解的质量随着深度p的增加持续提高，在不同处理器上分别在p=5、p=9和p=10时达到最佳。

Conclusion: QAOA参数迁移是一种有前景的、可扩展的非变分学习方法，可以有效地为QAOA寻找参数，并且在实际量子硬件上也能带来性能提升。

Abstract: The emergent practical applicability of the Quantum Approximate Optimization
Algorithm (QAOA) for approximate combinatorial optimization is a subject of
considerable interest. One of the primary limitations of QAOA is the task of
finding a set of good parameters. Parameter transfer is a phenomenon where QAOA
angles trained on problem instances that are self-similar tend to perform well
for other problem instances from that similar class. This suggests a
potentially highly efficient and scalable non-variational learning method for
QAOA angle finding. We systematically study QAOA parameter transferability from
small problems (16, 27 qubits) onto large problem instances (up to 156 qubits)
for heavy-hex graph Ising models with geometrically local higher order terms
using the Julia based QAOA simulation tool JuliQAOA to perform classical angle
finding for up to 49 QAOA layers. Parameter transfer of the fixed angles is
validated using a combination of full statevector, Projected Entangled Pair
States, Matrix Product State, and LOWESA numerical simulations. We find that
the QAOA parameter transfer from single instances applied to unseen problem
instances does not in general provide monotonically improving performance as a
function of p - there are many cases where the performance temporarily
decreases as a function of p - but despite this the transferred angles have a
general trend of improved expectation value as the QAOA depth increases, in
many cases converging close to the true ground-state energy of the 100+ qubit
instances. We also sample the hardware-compatible Ising models using the
ensemble of fixed QAOA angles on several superconducting qubit IBM Quantum
processors with 127, 133, and 156 qubits. We find continuous solution quality
improvement of the hardware-compatible QAOA circuits run on the IBM NISQ
processors up to p=5 on ibm_fez, p=9 on ibm_torino, and p=10 on ibm_pittsburgh.

</details>


### [351] [End-to-End Complexity Analysis for Quantum Simulation of the Extended Jaynes-Cummings Models](https://arxiv.org/abs/2509.13546)
*Nam Nguyen,Michael Yu,Alan Robertson,Hiromichi Nishimura,Samuel J. Elman,Benjamin Koltenbah*

Main category: quant-ph

TL;DR: 提出一个端到端的量子模拟框架，用于模拟扩展的 Jaynes-Cummings 模型（eJCM），并提供详细的误差分析和容错资源估算。


<details>
  <summary>Details</summary>
Motivation: eJCM 在量子技术中有重要应用，但经典模拟在大系统上不可行，因此需要量子模拟方法。

Method: 开发了基于第一和第二阶乘积公式的显式量子算法和电路，用于模拟 eJCM 的时间演化，并处理纯态和混合态。进行了误差分析、数值模拟验证和容错资源分析。

Result: 在量子计算机上模拟 eJCM 的完整路线图，包括具体的物理量子比特数量和执行时间估算。

Conclusion: 该工作为在未来量子计算机上模拟 eJCM 提供了完整的框架和详细的分析，包括误差界限和资源估算。

Abstract: The extended Jaynes-Cummings model (eJCM) is a foundational framework for
describing multi-mode light-matter interactions, with direct applications in
quantum technologies such as photon addition and quasi-noiseless amplification.
However, the model's complexity makes classical simulation intractable for
large systems that could be of practical interest. In this work, we present a
comprehensive, end-to-end framework for the quantum simulation of the eJCM. We
develop explicit quantum algorithms and circuits for simulating the system's
time evolution using first and second-order product formulas, analyzing the
dynamics in both the Schrodinger and interaction pictures. Our analysis
includes rigorous, closed-form error bounds that guide the choice of simulation
parameters, and we extend the methodology to efficiently handle both pure and
mixed quantum states. Furthermore, we validate our theoretical cost models with
numerical simulations and provide a detailed fault-tolerant resource analysis,
compiling the simulation circuits for a surface-code architecture to yield
concrete estimates for physical qubit counts and execution times. This work
establishes a complete roadmap for simulating the eJCM on future quantum
computers.

</details>


### [352] [Quantum keystroke logging](https://arxiv.org/abs/2509.13659)
*En-Jui Chang*

Main category: quant-ph

TL;DR: 该研究提出了一种基于GKP量子编码的量子击键记录方案，旨在使用户在传输前执行的逻辑操作能够被通信提供商推断出来。


<details>
  <summary>Details</summary>
Motivation: 通信提供商可能能够推断出用户在传输前对其编码状态执行的逻辑操作。

Method: 提出了一种量子击键记录方案，该方案将相位估计改编用于GKP编码状态，并利用几何相位、简化的量子傅里叶变换（QFT）以及跨克尔非线性来降低电路深度，从而在不干扰传输码字的情况下提取用户输入。

Result: 该方案能够让恶意提供商在不干扰传输的量子信息的情况下，推断出用户在传输前对量子态进行的操作，从而实现量子击键记录。

Conclusion: 量子击键记录是可行的，并且提出了一种实现该目标的方法。

Abstract: We propose a \textit{quantum keystroke logging} scheme in the context of
GKP-based quantum communication. The central idea is that, if a communication
provider controls the preparation of encoded states, it may be able to infer
logical operations applied by users prior to transmission. We show that phase
estimation can be adapted to this setting despite two obstacles: GKP codewords
are not eigenstates of the logical operators, and realistic communication
involves one-shot operations rather than repeated applications. Our approach
relies on three observations: the geometric phase associated with closed
trajectories in phase space manifests as an effective Pauli-$Z$ rotation on an
ancilla; the quantum Fourier transform (QFT) need only reproduce the correct
probability distribution and can thus be simplified using auxiliary ancilla;
and, in oscillator systems, cross-Kerr nonlinearities provide a natural
mechanism to reduce the circuit depth of the QFT. Together, these tools enable
a malicious provider to extract user inputs without disturbing the transmitted
codewords, thereby demonstrating a sufficient condition for quantum keystroke
logging.

</details>


### [353] [Design and Dynamics of High-Fidelity Two-Qubit Gates with Electrons on Helium](https://arxiv.org/abs/2509.13946)
*Oskar Leinonen,Jonas B. Flaten,Stian D. Bilek,Øyvind S. Schøyen,Morten Hjorth-Jensen,Niyaz R. Beysengulov,Zachary J. Stewart,Jared D. Weidman,Angela K. Wilson*

Main category: quant-ph

TL;DR: 利用超流氦表面的电子进行量子计算，通过时间相关的势阱调控实现高保真度的两比特门操作。


<details>
  <summary>Details</summary>
Motivation: 为量子计算提供新的平台，并探索在超流氦系统中实现高保真度两比特门操作的方法。

Method: 通过数值时间演化模拟，对势阱形状进行时间依赖性调控，以实现两比特门操作。

Result: 成功模拟了 CZ 和 sqISWAP 门操作，保真度分别达到 0.996 和 0.999，执行时间分别为 9.4 ns 和 2.9 ns。同时，研究了非理想条件下的保真度稳定性。

Conclusion: 通过时间相关的势阱调控，可以在超流氦系统上实现高保真度的两比特门操作，为该系统的实验实现提供了可行性。

Abstract: Systems of individual electrons electrostatically trapped on condensed noble
gas surfaces have recently attracted considerable interest as potential
platforms for quantum computing. The electrons form the qubits of the system,
and the purity of the noble gas surface protects the relevant quantum
properties of each electron. Previous work has indicated that manipulation of a
confining double-well potential for electrons on superfluid helium can generate
entanglement suitable for two-qubit gate operations. In this work, we
incorporate a time-dependent tuning of the potential shape to further explore
operation of two-qubit gates with the superfluid helium system. Through
numerical time evolution, we show that fast, high-fidelity two-qubit gates can
be achieved. In particular, we simulate operation of the \sqiswap and CZ gates
and obtain fidelities of 0.999 and 0.996 with execution times of 2.9~ns and
9.4~ns, respectively. Furthermore, we examine the stability of these gate
fidelities under non-ideal execution conditions, which reveals new properties
to consider in the device design. With the insights gained from this work, we
believe that an experimental realization of two-qubit gates using electrons on
helium is feasible.

</details>


### [354] [Learning quantum many-body data locally: A provably scalable framework](https://arxiv.org/abs/2509.13705)
*Koki Chinzei,Quoc Hoan Tran,Norifumi Matsumoto,Yasuhiro Endo,Hirotaka Oshima*

Main category: quant-ph

TL;DR: ML可用于从量子多体实验数据中提取见解，但需要大量数据。 GLQK是一个可扩展的ML框架，可利用相关性的指数衰减来处理这些数据，从而改进了样本复杂性。


<details>
  <summary>Details</summary>
Motivation: 从复杂的量子多体数据中提取见解，并解决经典上难以处理的量子问题。

Method: 提出了一种名为几何局部量子核（GLQK）的可扩展机器学习框架，该框架利用了非临界系统中普遍存在的关联的指数衰减来学习量子多体实验数据。

Result: GLQK在学习量子期望值多项式方面，样本复杂性相对于现有方法在量子比特数n方面得到了显著改善，在平移对称数据的情况下，样本复杂性与n无关。其可扩展性已通过量子多体现象的两个学习任务得到数值证明。

Conclusion: GLQK为利用实验数据来增进对量子多体物理学的理解开辟了新途径。

Abstract: Machine learning (ML) holds great promise for extracting insights from
complex quantum many-body data obtained in quantum experiments. This approach
can efficiently solve certain quantum problems that are classically
intractable, suggesting potential advantages of harnessing quantum data.
However, addressing large-scale problems still requires significant amounts of
data beyond the limited computational resources of near-term quantum devices.
We propose a scalable ML framework called Geometrically Local Quantum Kernel
(GLQK), designed to efficiently learn quantum many-body experimental data by
leveraging the exponential decay of correlations, a phenomenon prevalent in
noncritical systems. In the task of learning an unknown polynomial of quantum
expectation values, we rigorously prove that GLQK substantially improves
polynomial sample complexity in the number of qubits $n$, compared to the
existing shadow kernel, by constructing a feature space from local quantum
information at the correlation length scale. This improvement is particularly
notable when each term of the target polynomial involves few local subsystems.
Remarkably, for translationally symmetric data, GLQK achieves constant sample
complexity, independent of $n$. We numerically demonstrate its high scalability
in two learning tasks on quantum many-body phenomena. These results establish
new avenues for utilizing experimental data to advance the understanding of
quantum many-body physics.

</details>


### [355] [Observation of topological Phenomena in a Weyl Exceptional Ring with Single Photons](https://arxiv.org/abs/2509.13708)
*Zhong-Sheng Chen,Wei-Xin Chen,Fan Wu,Zhong-Wei Xu,Jing Ma,Yun-Kun Jiang,Huai-Zhi Wu,Shi-Biao Zheng*

Main category: quant-ph

TL;DR: 本研究利用单光子干涉技术，在三维参数空间中实现了非厄米奇异点环的完整模拟，并表征了其拓扑带结构和拓扑临界现象。


<details>
  <summary>Details</summary>
Motivation: 非厄米物理提供了区别于厄米理论的数学框架，能够实现厄米系统中不存在的拓扑现象，其中奇异点（EP）环是非厄米系统特有的拓扑特征。

Method: 利用单光子干涉技术，克服了量子系统中精确相位控制的实验挑战，实现了非厄米奇异点环在三维参数空间中的完整模拟，无需引入额外的对称性假设。通过测量三维参数空间中的非厄米动力学来确定系统的本征态，进而刻画不同条件下的拓扑带结构。通过提取不同参数流形下的陈数（Chern number）和贝里相位（Berry phase）来描述奇异点环的拓扑性质，并观察系统的拓扑临界现象。

Result: 成功在三维参数空间中模拟了非厄米奇异点环，并测量了系统的本征态，从而刻画了拓扑带结构。提取了不同参数流形下的陈数和贝里相位，并观察到了拓扑临界现象。

Conclusion: 该研究为进一步探索拓扑非厄米系统铺平了道路。

Abstract: Compared with Hermitian theory, non-Hermitian physics offers a fundamentally
different mathematical framework, enabling the observation of topological
phenomena that have no analogue in Hermitian systems. Among these, the
exceptional point (EP) ring stands out as a quintessential topological feature
unique to non-Hermitian systems. In this study, we employ single-photon
interferometry to overcome the experimental challenge of precise phase control
in quantum systems, thereby enabling a complete simulation of the non-Hermitian
EP ring in three-dimensional parameter space without invoking any additional
symmetry assumptions. By measuring the non-Hermitian dynamics in
three-dimensional parameter space, we determine the system's eigenstates, which
allows us to characterize the topological band structure of the system under
different conditions. We describe the topological properties of the EP ring by
extracting the Chern number and Berry phase for different parameter manifolds
and observe the topological critical phenomena of the system. Our work paves
the way for further exploration of topological non-Hermitian systems.

</details>


### [356] [Loss-tolerant detection of squeezed states in the 2 um region](https://arxiv.org/abs/2509.13810)
*K. M. Kwan,T. G. McRae,J. Qin,D. W. Gould,S. S. Y. Chua,J. Junker,R. Iden,V. B. Adya,M. J. Yap,B. J. J. Slagmolen,D. E. McClelland,R. L. Ward*

Main category: quant-ph

TL;DR: 通过使用相位敏感放大器在探测前放大压缩真空，首次实现了 1984 nm 波长下的损耗容忍音频频带压缩光探测，从而将有效探测效率从 74% 提高到 95%，并将观测到的压缩从 4 dB 提高到 8 dB。


<details>
  <summary>Details</summary>
Motivation: 光学损耗限制了压缩态光在 2 um 波长下的量子增强测量，因为此时光电二极管效率较低。

Method: 在探测前使用相位敏感放大器放大压缩真空。

Result: 有效探测效率从 74% 提高到 95%，观测到的压缩从 4 dB 提高到 8 dB（这是该波长下的最高压缩水平），并且增加了信噪比，将有效测量带宽扩展到更低频率。

Conclusion: 这种方法在很大程度上与波长无关，能够将高保真量子测量扩展到未来的引力波探测器和相关的量子技术。

Abstract: Squeezed states of light enable quantum-enhanced measurements but are limited
by optical loss, particularly at 2 um where photodiode efficiency is low. We
report the first loss-tolerant, audio-band squeezed light detection at 1984 nm
by using a phase-sensitive amplifier to amplify the squeezed vacuum prior to
detection. This technique increases the effective detection efficiency from 74%
to 95% and increases the observed squeezing from 4 dB to 8 dB, the highest
level of squeezing observed at this wavelength. Additionally, the
shot-to-dark-noise clearance increases, extending the effective measurement
bandwidth toward lower frequencies. This approach is largely
wavelength-independent, extending high-fidelity quantum measurements to future
gravitational-wave detectors and related quantum technologies.

</details>


### [357] [Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator](https://arxiv.org/abs/2509.13821)
*Frederik Møller,Gabriel Fernández-Fernández,Thomas Schweigler,Paulin de Schoulepnikoff,Jörg Schmiedmayer,Gorka Muñoz-Gil*

Main category: quant-ph

TL;DR: 本研究利用变分自编码器（VAE）分析了隧道耦合的一维玻色气体干涉测量数据，成功地从嘈杂且不完整的实验数据中提取了物理见解，揭示了冻结的孤子和异常的后淬灭动力学。


<details>
  <summary>Details</summary>
Motivation: 在量子模拟中，测量噪声、有限的可观测量以及对微观模型的知识不完整等因素阻碍了从实验数据中提取物理见解。本研究旨在开发一种机器学习方法来克服这些挑战。

Method: 研究采用基于变分自编码器（VAE）的机器学习方法，对隧道耦合的一维玻色气体干涉测量数据进行无监督训练。VAE学习了一个最小的潜在表示，该表示与系统的平衡控制参数强相关。

Result: VAE学习到的潜在空间能够揭示冻结的孤子以及未被传统相关方法捕捉到的异常后淬灭动力学。这表明生成模型可以直接从嘈杂和稀疏的实验数据中提取可解释的物理变量。

Conclusion: 本研究证明了生成模型在从嘈杂的量子模拟实验数据中提取物理见解方面的潜力，并为利用机器学习进行量子多体系统的数据驱动发现开辟了新的途径。

Abstract: Analog quantum simulators provide access to many-body dynamics beyond the
reach of classical computation. However, extracting physical insights from
experimental data is often hindered by measurement noise, limited observables,
and incomplete knowledge of the underlying microscopic model. Here, we develop
a machine learning approach based on a variational autoencoder (VAE) to analyze
interference measurements of tunnel-coupled one-dimensional Bose gases, which
realize the sine-Gordon quantum field theory. Trained in an unsupervised
manner, the VAE learns a minimal latent representation that strongly correlates
with the equilibrium control parameter of the system. Applied to
non-equilibrium protocols, the latent space uncovers signatures of frozen-in
solitons following rapid cooling, and reveals anomalous post-quench dynamics
not captured by conventional correlation-based methods. These results
demonstrate that generative models can extract physically interpretable
variables directly from noisy and sparse experimental data, providing
complementary probes of equilibrium and non-equilibrium physics in quantum
simulators. More broadly, our work highlights how machine learning can
supplement established field-theoretical techniques, paving the way for
scalable, data-driven discovery in quantum many-body systems.

</details>


### [358] [Trajectory-based Measure of Nonlocality in the Double Caldeira-Leggett Formalism](https://arxiv.org/abs/2509.13856)
*S. V. Mousavi*

Main category: quant-ph

TL;DR: 量子关联在闭合和开放的二分系统动力学中的演化，利用玻姆力学和速度敏感性量化非局域性，并研究了温度和压缩衰减参数的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在闭合和开放的二分量子系统中量子关联（特别是量子非局域性）的动力学演化，并理解环境结构（局部浴 vs. 共同浴）和温度如何影响这种演化。

Method: 在玻姆力学框架下，利用薛定谔方程模拟闭合系统的幺正演化，利用Caldeira-Leggett主方程模拟开放系统（高温度，弱耦合）的动力学。通过一个粒子的速度对另一个粒子位置的敏感性来量化量子非局域性。

Result: 在局部浴和共同浴的情况下，非局域关联的演化都表现出先增长、达到峰值然后衰减的趋势。在局部浴中，衰减是平滑的；温度升高会增加峰值，但缩短持续时间。在共同浴中，除了增长和衰减，还会出现复现和振荡，其幅度和时间随温度变化。分析了温度和压缩衰减参数对玻姆轨迹结构和非局域关联演化的影响。

Conclusion: 环境的结构（即使在马尔可夫条件下）对量子关联的可观测动力学有着重要的影响。基于轨迹的速度敏感性度量可以直观且定量地理解纠缠退化、退相干及其特征时间尺度。

Abstract: We investigate the dynamics of quantum correlations in bipartite systems
initially prepared in a squeezed state, comparing closed-system unitary
evolution under the Schr\"odinger equation with open-system dynamics governed
by the Caldeira-Leggett master equation in the high-temperature, weak-coupling
regime, all within the Bohmian mechanics framework. Quantum nonlocality is
quantified via the sensitivity of the Bohmian velocity of one particle to the
position of the other. Our results show that in both distinct (local) and
common bath scenarios, nonlocal correlations initially grow from zero, reach a
peak, and then decay. In the case of local baths, the decay is smooth and
monotonic; although the peak value increases with temperature, its temporal
width (measured via the full width at half maximum) decreases, indicating a
shorter duration of nonlocal correlations. For a common bath, the initial
growth and decay are followed by revivals and oscillations, whose amplitude and
timing vary with temperature. These non-monotonic behaviors arise despite the
Markovian nature of the underlying dynamics and reflect the nontrivial role of
system-bath correlations. We also analyze how both temperature and the
squeezing decay parameter affect the structure of Bohmian trajectories and the
evolution of nonlocal correlations. This trajectory-based, velocity-sensitivity
measure offers an intuitive and quantitative understanding of entanglement
degradation, decoherence, and their characteristic time scales. Our findings
emphasize how the structure of the environment critically shapes the observable
dynamics of quantum correlations, even in Markovian regimes.

</details>


### [359] [Quantum Algorithm of the GLMY Homology on Digraphs](https://arxiv.org/abs/2509.13862)
*Yunpeng Zi,Muchun Yang,D. L. Zhou*

Main category: quant-ph

TL;DR: 提出了一个新的量子算法，用于计算拓扑数据分析中的 GLMY 同调群，在一般情况下提供二次加速，在特定情况下提供指数加速。


<details>
  <summary>Details</summary>
Motivation: 之前的拓扑数据分析方法主要基于单纯复形，而 GLMY 同调群是在有向图上定义的，并且是拓扑数据分析领域的一个新兴方向，受到越来越多的关注。

Method: 提出了一种用于 GLMY 同调群的量子算法，设计了 GLMY 同调群在有向图上的量子态和边界算子的通用编码协议，并证明了一个 GLMY 同调群的性质以提供量子算法的理论保证。

Result: 该量子算法在一般情况下提供二次加速，在输入数据为路径规范的情况下提供指数量子优势。

Conclusion: 所提出的量子算法在计算 GLMY 同调群方面具有显著优势，并且在理论上得到了保证。

Abstract: Quantum algorithms for topological data analysis provide significant
advantage over the best classical algorithm. Different from the previous
simplical complex on points cloud, the GLMY homology introduced by Alexander
Grigor'yan, Yong Lin, Yuri Muranov and Shing-Tung Yau, is defined on digraph
and is a arising realm in Topological Data Analysis (TDA), which attracts more
and more attention recently. We propose a quantum algorithm for the GLMY
homology with significant advantage over the best classical algorithm. We
design a universal encoding protocol for the quantum states and boundary
operators of GLMY homology on digraphs. And a property of the GLMY homology is
proved for the theoretical guarantee of the quantum algorithm. The quantum
algorithm for GLMY homology gives a quadratic speedup in general cases, and it
gives an exponential quantum advantage in the case of the input data is given
as a specification of paths.

</details>


### [360] [Coherent Driving of a Quantum System with Modulated Free-Space Electrons](https://arxiv.org/abs/2509.13904)
*Matthias Kolb,Thomas Spielauer,Thomas Weigner,Giovanni Boero,Dennis Rätzel,Philipp Haslinger*

Main category: quant-ph

TL;DR: 通过操纵扫描电子显微镜中的电子束，可以以纳米级分辨率相干地控制量子自旋系统。


<details>
  <summary>Details</summary>
Motivation: 以往控制量子系统主要依赖电磁辐射，本研究旨在探索利用自由电子的近场与量子自旋系统相互作用，以实现更高分辨率的相干控制。

Method: 通过在扫描电子显微镜中，使电子束在接近自旋活性固态样品时发生周期性偏转，并扫描偏转频率以匹配自旋共振频率，从而观察电子束近场与自旋之间的相干耦合。

Result: 实验直接观察到了电子束近场与自旋两种状态之间的相干耦合。

Conclusion: 该方法仅依赖于经典地塑造电子束的横向关联，有潜力以空前的电子显微镜分辨率实现量子系统的相干控制，为纳米技术中的先进光谱工具开辟了新的可能性。

Abstract: Control of quantum systems typically relies on the interaction with
electromagnetic radiation. In this study, we experimentally show that the
electromagnetic near-field of a spatially modulated freespace electron beam can
be used to drive spin systems, demonstrating free-electron-bound-electron
resonant interaction. By periodically deflecting the electron beam of a
scanning electron microscope in close proximity to a spin-active solid-state
sample, and sweeping the deflection frequency across the spin resonance, we
directly observe phase coherent coupling between the electron beam's nearfield
and the two spin states. This method relies only on classically shaping the
electron beams transversal correlations and has the potential to enable
coherent control of quantum systems with unprecedented, electron microscopic
resolution, opening novel possibilities for advanced spectroscopic tools in
nanotechnology.

</details>


### [361] [A Tight Quantum Algorithm for Multiple Collision Search](https://arxiv.org/abs/2509.13909)
*Xavier Bonnetain,Johanna Loyer,André Schrottenloher,Yixin Shen*

Main category: quant-ph

TL;DR: 寻找多个碰撞的量子算法在查询和时间上都已达到最优。


<details>
  <summary>Details</summary>
Motivation: 寻找多个碰撞在对称和非对称密码分析中有广泛应用，但已有的量子算法并未在所有参数下都达到最优。

Method: 提出了一种新的量子算法，该算法扩展了链式量子行走，在每个步骤中返回多个碰撞，并且“行走”只执行一个扩散层。

Result: 该算法在查询方面达到了最优（最多相差一个多项式因子），并在量子随机访问存储器（qRAM）假设下，在时间方面也达到了最优。

Conclusion: 通过提出的新算法，解决了寻找多个碰撞问题的最优性问题，该算法在查询和时间上都达到了最优。

Abstract: Searching for collisions in random functions is a fundamental computational
problem, with many applications in symmetric and asymmetric cryptanalysis. When
one searches for a single collision, the known quantum algorithms match the
query lower bound. This is not the case for the problem of finding multiple
collisions, despite its regular appearance as a sub-component in sieving-type
algorithms.
  At EUROCRYPT 2019, Liu and Zhandry gave a query lower bound $\Omega(2^{m/3 +
2k/3})$ for finding $2^k$ collisions in a random function with m-bit output. At
EUROCRYPT 2023, Bonnetain et al. gave a quantum algorithm matching this bound
for a large range of $m$ and $k$, but not all admissible values. Like many
previous collision-finding algorithms, theirs is based on the MNRS quantum walk
framework, but it chains the walks by reusing the state after outputting a
collision.
  In this paper, we give a new algorithm that tackles the remaining non-optimal
range, closing the problem. Our algorithm is tight (up to a polynomial factor)
in queries, and also in time under a quantum RAM assumption. The idea is to
extend the chained walk to a regime in which several collisions are returned at
each step, and the ``walks'' themselves only perform a single diffusion layer.

</details>


### [362] [Global Mean-Amplitude Enhanced Spiking Neural Network Coherent Ising Machine](https://arxiv.org/abs/2509.13917)
*Yan Chen Jiang,Lu Ma,Chuan Wang,Tie Jun Wang*

Main category: quant-ph

TL;DR: 一种新型的相干伊辛机（CIM）通过全局平均幅度反馈增强的SNN（GFSNN-CIM）来解决组合优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统CIM在处理非均匀耦合强度和维持计算过程中的幅度稳定性方面存在挑战。

Method: 提出了一种具有物理驱动幅度稳定机制的GFSNN-CIM，该机制动态平衡非线性增益饱和和耦合效应，增强了光学脉冲网络的同步性。

Result: GFSNN-CIM在Max-Cut问题上比传统SNN-CIM提高了27%的解成功率，并且随着问题复杂度的增加，可扩展性也得到提高。在交通分配问题（TAP）上的实验结果显示，即使在粗略离散化的情况下，该方法也能实现接近连续的精度（偏差<0.035%）。在北京的道路网络（481个自旋）上进行的大规模测试验证了其实际应用性。

Conclusion: GFSNN-CIM建立了一个物理一致的优化框架，其中光学脉冲动力学直接编码组合问题，为复杂优化任务中可扩展、高性能的CIM实现铺平了道路。

Abstract: The coherent Ising machine (CIM) is a quantum-inspired computing platform
that leverages optical parametric oscillation dynamics to solve combinatorial
optimization problems by searching for the ground state of an Ising
Hamiltonian. Conventional CIM implementations face challenges in handling
non-uniform coupling strengths and maintaining amplitude stability during
computation. In this paper, a new global mean-amplitude feedback-enhanced
spiking neural network CIM (GFSNN-CIM) is introduced with a physics-driven
amplitude stabilization mechanism to dynamically balance nonlinear gain
saturation and coupling effects. This modification enhances synchronization in
the optical pulse network, leading to more robust convergence under varying
interaction strengths. Experimental validation on Max-Cut problems demonstrates
that the GFSNN-CIM achieves up to a 27% improvement in solution success rates
compared to conventional spiking neural network CIM, with scalability improving
as problem complexity increases. Further application to the traffic assignment
problem (TAP) confirms the method's generality; the GFSNN-CIM achieves
near-continuous accuracy (deviations < 0.035%) even at coarse discretization,
while large-scale tests on Beijing's road network (481 spins) validate its
real-world applicability. These advances establish a physics-consistent
optimization framework, where optical pulse dynamics directly encode
combinatorial problems, paving the way for scalable, high-performance CIM
implementations in complex optimization tasks.

</details>


### [363] [Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks](https://arxiv.org/abs/2509.14026)
*Jiun-Cheng Jiang,Morris Yu-Chao Huang,Tianlong Chen,Hsi-Sheng Goan*

Main category: quant-ph

TL;DR: DARUANs and QKANs are novel quantum-inspired machine learning models that improve parameter efficiency and expressivity by unifying VQCs and KANs.


<details>
  <summary>Details</summary>
Motivation: Unify variational quantum circuits (VQCs) and Kolmogorov-Arnold networks (KANs) by introducing learnable activation functions for quantum machine learning.

Method: Introduce Quantum Variational Activation Functions (QVAFs) realized by DatA Re-Uploading ActivatioNs (DARUANs) with trainable weights. Embed DARUANs into KANs to create quantum-inspired KANs (QKANs). Develop layer extension and hybrid QKANs (HQKANs) for scalability and efficiency. Conduct theoretical analysis and experiments on function regression, image classification, and language modeling.

Result: DARUANs exhibit exponentially growing frequency spectrum, enabling exponential reduction in parameter size. QKANs retain KAN interpretability while improving parameter efficiency, expressivity, and generalization. HQKANs serve as drop-in replacements for MLPs in large-scale models. Experiments demonstrate the efficiency and scalability of QKANs.

Conclusion: DARUANs and QKANs present a promising direction for advancing quantum machine learning on NISQ hardware and classical simulators.

Abstract: Variational quantum circuits (VQCs) are central to quantum machine learning,
while recent progress in Kolmogorov-Arnold networks (KANs) highlights the power
of learnable activation functions. We unify these directions by introducing
quantum variational activation functions (QVAFs), realized through single-qubit
data re-uploading circuits called DatA Re-Uploading ActivatioNs (DARUANs). We
show that DARUAN with trainable weights in data pre-processing possesses an
exponentially growing frequency spectrum with data repetitions, enabling an
exponential reduction in parameter size compared with Fourier-based activations
without loss of expressivity. Embedding DARUAN into KANs yields
quantum-inspired KANs (QKANs), which retain the interpretability of KANs while
improving their parameter efficiency, expressivity, and generalization. We
further introduce two novel techniques to enhance scalability, feasibility and
computational efficiency, such as layer extension and hybrid QKANs (HQKANs) as
drop-in replacements of multi-layer perceptrons (MLPs) for feed-forward
networks in large-scale models. We provide theoretical analysis and extensive
experiments on function regression, image classification, and autoregressive
generative language modeling, demonstrating the efficiency and scalability of
QKANs. DARUANs and QKANs offer a promising direction for advancing quantum
machine learning on both noisy intermediate-scale quantum (NISQ) hardware and
classical quantum simulators.

</details>


### [364] [Formalizing contextuality in sequential scenarios](https://arxiv.org/abs/2509.14125)
*Kim Vallée,Damian Markham*

Main category: quant-ph

TL;DR: 该研究提出了一种用于表征顺序场景的框架，并提供了隐藏变量模型解释的数据操作解释。


<details>
  <summary>Details</summary>
Motivation: 顺序场景的测量仪器可以改变其状态，这与非局部场景不同，因此需要对隐藏变量模型中的状态更新进行假设。

Method: 开发了用于顺序场景的隐藏变量模型，并提出了“无干扰”的概念（一个仪器是否被测量不影响另一个仪器的统计数据）。推导了顺序场景的非上下文性不等式，并证明了其违反意味着数据无法用确定性且无干扰的隐藏变量模型解释。此外，还将标准上下文性框架转换为顺序版本。

Result: 该框架能够识别顺序场景中的上下文性，并提供了相应的隐藏变量模型解释。非上下文性不等式的违反可以排除某些类型的隐藏变量模型。

Conclusion: 提出的框架和非上下文性不等式为理解和分析顺序场景中的上下文性提供了新的途径。

Abstract: This paper provides a framework for characterizing sequential scenarios,
allowing for the identification of contextuality given empirical data, and then
provides precise operational interpretations in terms of the possible hidden
variable model explanations of that data. Sequential scenarios are different in
essence from non-local scenarios as each measurement instrument is allowed to
change the state as it enters subsequent measurement instruments. Thus, it is
necessary to formulate the possible state update in any hidden variable model
description. Here we develop such hidden variable models for sequential
scenarios, and we propose the notion of no-disturbance: an instrument $A$ does
not disturb another instrument $B$ if the statistics of $B$ are independent of
whether $A$ was measured or not. We define non-contextuality inequalities for
the sequential scenario, and show that violation implies that the data cannot
be explained by a hidden variable model that is both deterministic and not
disturbing in this sense. We further provide a translation from standard
contextuality frameworks to ours, providing sequential versions which carry
over the same inequalities and measures of contextuality, but now with the
sequential interpretations stated.

</details>


### [365] [Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures](https://arxiv.org/abs/2509.14163)
*Chi-Sheng Chen,En-Jui Kuo*

Main category: quant-ph

TL;DR: 本研究引入一种量子强化学习（QRL）控制器，动态调整扩散模型中的无分类器引导（CFG），以提高生成图像的感知质量并减少参数量。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散模型使用静态或启发式CFG，无法适应不同时间步和噪声条件，导致生成效果不佳。

Method: 提出一种混合量子-经典 actor-critic 架构的QRL控制器。其中，使用浅层变分量子电路（VQC）生成策略特征，并通过多层感知机（MLP）映射为$\\\Delta$CFG的动作。同时，使用经典Critic估计价值函数，并采用近端策略优化（PPO）和广义优势估计（GAE）进行策略优化。奖励函数结合了分类置信度、感知改进和动作正则化。

Result: 在CIFAR-10数据集上的实验表明，与经典强化学习Actor和固定调度相比，QRL策略在提升感知质量（LPIPS、PSNR、SSIM）方面表现更优，同时减少了参数量。消融研究揭示了量子比特数量和电路深度对精度和效率的影响，并证实了在长扩散调度下生成效果的鲁棒性。

Conclusion: QRL控制器能够动态调整CFG，有效提升扩散模型的生成质量和效率，为未来的研究提供了新的方向。

Abstract: Diffusion models typically employ static or heuristic classifier-free
guidance (CFG) schedules, which often fail to adapt across timesteps and noise
conditions. In this work, we introduce a quantum reinforcement learning (QRL)
controller that dynamically adjusts CFG at each denoising step. The controller
adopts a hybrid quantum--classical actor--critic architecture: a shallow
variational quantum circuit (VQC) with ring entanglement generates policy
features, which are mapped by a compact multilayer perceptron (MLP) into
Gaussian actions over $\Delta$CFG, while a classical critic estimates value
functions. The policy is optimized using Proximal Policy Optimization (PPO)
with Generalized Advantage Estimation (GAE), guided by a reward that balances
classification confidence, perceptual improvement, and action regularization.
Experiments on CIFAR-10 demonstrate that our QRL policy improves perceptual
quality (LPIPS, PSNR, SSIM) while reducing parameter count compared to
classical RL actors and fixed schedules. Ablation studies on qubit number and
circuit depth reveal trade-offs between accuracy and efficiency, and extended
evaluations confirm robust generation under long diffusion schedules.

</details>


### [366] [High-dimensional topological photonic entanglement](https://arxiv.org/abs/2509.14164)
*M. Javad Zakeri,Armando Perez-Leija,Andrea Blanco-Redondo*

Main category: quant-ph

TL;DR: A method for generating and experimentally demonstrating high-dimensional topological photonic entanglement using silicon photonic waveguide topological superlattices has been developed, showing entanglement of up to five modes with resilience to imperfections, paving the way for scalable, fault-tolerant quantum photonic states.


<details>
  <summary>Details</summary>
Motivation: The robust generation and manipulation of high-dimensional quantum states are crucial for quantum computation. While topology has been used to encode and transport quantum information in condensed matter and photonics, a scalable method for entangled topological photonic modes was lacking.

Method: The proposed method utilizes silicon photonic waveguide topological superlattices to generate energy-time entangled photon pairs on a superposition of multiple topological modes. This is achieved through nonlinear generation within the superlattices.

Result: The experiment successfully demonstrated entanglement of up to five topological modes. The system showed resilience to nanofabrication imperfections, as confirmed by theoretical analysis and measurements.

Conclusion: This research introduces a novel route toward scalable, fault-tolerant quantum photonic states by integrating nonlinear integrated photonics, quantum information, and topology. The demonstrated method for generating high-dimensional topological photonic entanglement is a significant step forward for the field.

Abstract: The robust generation and manipulation of high-dimensional quantum states
lies at the heart of modern quantum computation. The use of topology to
resiliently encode and transport quantum information has been widely
investigated in condensed matter and has recently penetrated quantum photonics.
However, a route to scale up to a large number of entangled topological
photonic modes had been missing. Here, we propose and experimentally
demonstrate a method to generate high-dimensional topological photonic
entanglement. Our platform relies on carefully designed silicon photonic
waveguide topological superlattices, which support nonlinear generation of
energy-time entangled photon pairs on a superposition of multiple topological
modes. Our measurements and theoretical analysis reveal entanglement of up to
five topological modes with resilience to nanofabrication imperfections. This
study, at the intersection of nonlinear integrated photonics, quantum
information, and topology, opens a research avenue toward scalable,
fault-tolerant quantum photonic states.

</details>


### [367] [Quantum Utility in Simulating the Real-time Dynamics of the Fermi-Hubbard Model using Superconducting Quantum Computers](https://arxiv.org/abs/2509.14196)
*Talal Ahmed Chowdhury,Vladimir Korepin,Vincent R. Pascuzzi,Kwangmin Yu*

Main category: quant-ph

TL;DR: 该工作使用100多量子比特的IBM超导量子计算机模拟了一维费米-哈伯德模型，并提出了一阶和二阶Trotter化方案，以研究系统的弛豫动力学，测量了N'eel可观测量，证明了量子计算机在处理复杂量子多体系统方面的优势。


<details>
  <summary>Details</summary>
Motivation: 费米-哈伯德模型是描述强关联电子的基本模型，而量子计算机为探索这些量子多体系统的复杂动力学提供了强大工具。

Method: 使用IBM的超导量子计算机，利用一阶和优化的二阶Trotter化方案来模拟一维费米-哈伯德模型的时间演化，并测量N'eel可观测量。

Result: 成功地在具有挑战性的大规模量子多体系统上进行了测量，特别是在具有更大纠缠的较长时间尺度下。

Conclusion: 该研究证明了超导量子计算平台在处理大尺度量子多体系统方面相对于传统经典近似方法的量子优势。

Abstract: The Fermi-Hubbard model is a fundamental model in condensed matter physics
that describes strongly correlated electrons. On the other hand, quantum
computers are emerging as powerful tools for exploring the complex dynamics of
these quantum many-body systems. In this work, we demonstrate the quantum
simulation of the one-dimensional Fermi-Hubbard model using IBM's
superconducting quantum computers, employing over 100 qubits. We introduce a
first-order Trotterization scheme and extend it to an optimized second-order
Trotterization for the time evolution in the Fermi-Hubbard model, specifically
tailored for the limited qubit connectivity of quantum architectures, such as
IBM's platforms. Notably, both Trotterization approaches are scalable and
maintain a constant circuit depth at each Trotter step, regardless of the qubit
count, enabling us to precisely investigate the relaxation dynamics in the
Fermi-Hubbard model by measuring the expectation value of the N\'eel observable
(staggered magnetization) for time-evolved quantum states. Finally, our
successful measurement of expectation values in such large-scale quantum
many-body systems, especially at longer time scales with larger entanglement,
highlights the quantum utility of superconducting quantum platforms over
conventional classical approximation methods.

</details>


### [368] [Localized degenerate solutions to the massless Dirac and Weyl equations](https://arxiv.org/abs/2509.14212)
*Georgios N. Tsigaridas,Aristides I. Kechriniotis,Christos A. Tsonos,Konstantinos K. Delibasis*

Main category: quant-ph

TL;DR: 文章提出了一类质量马约拉纳费米子的退化解，可以描述局域化的粒子和/或具有可变能量的粒子，这可能被解释为出现在真空或支持质量马约拉纳费米子的材料中的虚粒子。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提出一类质量马约拉纳费米子的退化解，以描述局域化的粒子和/或具有可变能量的粒子，并将其解释为虚粒子。

Method: 通过显式计算得到的电磁4势和场，以及使用合适的磁场来控制外尔粒子的横向空间分布和根据其螺旋度和运动方向分离它们。

Result: 文章提出了一类退化的质量马约拉纳费米子解，并计算了相应的电磁4势和场。此外，还提出了一种控制外尔粒子横向空间分布并按螺旋度和运动方向分离它们的方法。

Conclusion: 文章提出了一类质量马约拉纳费米子的退化解，并提出了一种控制和分离外尔粒子横向空间分布的方法。

Abstract: In this article we present a general class of degenerate solutions to the
massless Dirac and Weyl equations, which can describe localized particles
and/or particles with variable energy, that could be interpreted as virtual
particles appearing either in the vacuum or in materials supporting massless
Dirac or Weyl particles. These solutions exist in a wide range of
electromagnetic 4-potentials and fields, which are explicitly calculated. In
addition, we describe a method for controlling the transverse spatial
distribution of Weyl particles and separating them according to their helicity
and direction of motion using suitable magnetic fields.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [369] [Higher-order Network phenomena of cascading failures in resilient cities](https://arxiv.org/abs/2509.13808)
*Jinghua Song,Yuan Wang,Zimo Yan*

Main category: cs.SI

TL;DR: 高级别的网络分析表明，城市交通网络的静态结构与动态功能弹性之间存在脱节，需要更动态的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的城市韧性模型未能充分考虑多模式交通网络中由局部冲击引发的级联故障所带来的系统性风险，因为它们主要关注成对相互作用。

Method: 提出一个结合高阶网络理论和真实世界多模式交通网络实证数据的新框架，并分析其静态结构和动态功能弹性。

Result: 虽然网络集成提高了静态鲁棒性指标，但同时也为灾难性级联创造了结构性路径。静态网络结构（包括传统的低阶中心性和新颖的高阶结构分析）的指标与系统动态功能弹性之间存在显著脱节，并且是较差的预测指标。

Conclusion: 静态分析存在固有的局限性，强调需要转向动态模型来设计和管理真正有弹性的城市系统。

Abstract: Modern urban resilience is threatened by cascading failures in multimodal
transport networks, where localized shocks trigger widespread paralysis.
Existing models, limited by their focus on pairwise interactions, often
underestimate this systemic risk. To address this, we introduce a framework
that confronts higher-order network theory with empirical evidence from a
large-scale, real-world multimodal transport network. Our findings confirm a
fundamental duality: network integration enhances static robustness metrics but
simultaneously creates the structural pathways for catastrophic cascades.
Crucially, we uncover the source of this paradox: a profound disconnect between
static network structure and dynamic functional failure. We provide strong
evidence that metrics derived from the network's static blueprint-encompassing
both conventional low-order centrality and novel higher-order structural
analyses-are fundamentally disconnected from and thus poor predictors of a
system's dynamic functional resilience. This result highlights the inherent
limitations of static analysis and underscores the need for a paradigm shift
towards dynamic models to design and manage truly resilient urban systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [370] [CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion](https://arxiv.org/abs/2509.13688)
*James Jincheng,Youcheng Cai,Ligang Liu*

Main category: cs.GR

TL;DR: CraftMesh通过结合2D和3D生成模型，并利用泊松无缝融合技术，实现了高保真度的可控网格编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的生成方法在处理复杂几何形状和生成细节方面存在挑战。

Method: CraftMesh将网格编辑分解为2D图像编辑、生成区域特定3D网格，然后无缝融合到原始模型中。该方法采用了泊松几何融合（结合SDF/Mesh表示和法线混合）和泊松纹理协调技术。

Result: CraftMesh在复杂编辑任务中，在全局一致性和局部细节方面优于现有技术。

Conclusion: CraftMesh为高保真度的可控网格编辑提供了一个新颖有效的框架。

Abstract: Controllable, high-fidelity mesh editing remains a significant challenge in
3D content creation. Existing generative methods often struggle with complex
geometries and fail to produce detailed results. We propose CraftMesh, a novel
framework for high-fidelity generative mesh manipulation via Poisson Seamless
Fusion. Our key insight is to decompose mesh editing into a pipeline that
leverages the strengths of 2D and 3D generative models: we edit a 2D reference
image, then generate a region-specific 3D mesh, and seamlessly fuse it into the
original model. We introduce two core techniques: Poisson Geometric Fusion,
which utilizes a hybrid SDF/Mesh representation with normal blending to achieve
harmonious geometric integration, and Poisson Texture Harmonization for
visually consistent texture blending. Experimental results demonstrate that
CraftMesh outperforms state-of-the-art methods, delivering superior global
consistency and local detail in complex editing tasks.

</details>


<div id='cs.SY'></div>

# cs.SY [[Back]](#toc)

### [371] [Location and allocation problem of high-speed train maintenance bases](https://arxiv.org/abs/2509.13383)
*Boliang Lin,Xiang Li,Yuxue Gu,Dishen Lu*

Main category: cs.SY

TL;DR: 本文提出了一种双层规划模型，用于优化中国西北高速铁路网的维护基地选址和任务分配，旨在最小化年度总成本，并进行了敏感性分析。


<details>
  <summary>Details</summary>
Motivation: 高速列车安全稳定运行离不开维护基地，但其选址和任务分配是一个复杂的组合优化问题，需要解决投资和运营成本问题。

Method: 提出一个双层规划模型：上层最小化年化总成本（包括基地投资和总维护成本），下层在不同投资情景下最小化维护运行调度成本。

Result: 在中国西北高速铁路网的案例研究中，在哈密建立新基地并扩展西安基地可将规划期内的年化总成本降至最低，为22.7815亿元人民币。

Conclusion: 该研究提供了一种优化维护基地选址的方法，以应对未来日益增长的列车数量，确保维护工作的可靠性和效率。

Abstract: Maintenance bases are crucial for the safe and stable operation of high-speed
trains, necessitating significant financial investment for their construction
and operation. Planning the location and task allocation of these bases in the
vast high-speed railway network is a complex combinatorial optimization
problem. This paper explored the strategic planning of identifying optimal
locations for maintenance bases, introducing a bi-level programming model. The
upper-level objective was to minimize the annualized total cost, including
investment for new or expanding bases and total maintenance costs, while the
lower-level focused on dispatching high-speed trains to the most suitable base
for maintenance tasks, thereby reducing maintenance operation dispatch costs
under various investment scenarios. A case study of the Northwest China
high-speed rail network demonstrated the application of this model, and
included the sensitivity analysis reflecting maintenance policy reforms. The
results showed that establishing a new base in Hami and expanding Xi'an base
could minimize the total annualized cost during the planning period, amounting
to a total of 2,278.15 million RMB. This paper offers an optimization method
for selecting maintenance base locations that ensures reliability and
efficiency in maintenance work as the number of trains increases in the future.

</details>


### [372] [Modeling skiers flows via Wardrope equilibrium in closed capacitated networks](https://arxiv.org/abs/2509.13392)
*Demyan Yarmoshik,Igor Ignashin,Ekaterina Sikacheva,Alexander Gasnikov*

Main category: cs.SY

TL;DR: 该论文提出了一个滑雪胜地均衡模型，用户被分配到封闭网络中的循环。通过求解凸优化问题来高效地计算电梯队列的等待时间。该均衡问题被表述为变分不等式，并通过数值实验证明可以使用标准算法求解。


<details>
  <summary>Details</summary>
Motivation: 提出一个滑雪胜地均衡模型，并提出一种有效的方法来计算由于电梯容量有限而产生的队列等待时间。

Method: 提出一个滑雪胜地均衡模型，并将问题表述为变分不等式，然后使用凸优化来计算等待时间，并用标准算法进行求解。

Result: 开发了一种计算滑雪胜地等待时间的有效方法，并通过数值实验验证了该方法的准确性。

Conclusion: 所提出的均衡模型和计算方法可以有效地解决滑雪胜地的等待时间问题。

Abstract: We propose an equilibrium model of ski resorts where users are assigned to
cycles in a closed network. As queues form on lifts with limited capacity, we
derive an efficient way to find waiting times via convex optimization. The
equilibrium problem is formulated as a variational inequality, and numerical
experiments show that it can be solved using standard algorithms.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [373] [A User-centric Kubernetes-based Architecture for Green Cloud Computing](https://arxiv.org/abs/2509.13325)
*Matteo Zanotto,Leonardo Vicentini,Redi Vreto,Francesco Lumpp,Diego Braga,Sandro Fiore*

Main category: cs.DC

TL;DR: 该研究提出了一种以用户为中心、基于Kubernetes的绿色云计算架构，通过预测碳排放强度并据此调度工作负载来利用绿色能源，以最小化碳排放。


<details>
  <summary>Details</summary>
Motivation: 随着云计算需求的增长，数据中心的电力消耗和相关的CO2排放对气候变化产生了重大影响。尽管云服务提供商在提高能源效率方面已接近最优，但在提供精确的可持续性报告方面仍存在不足，因此需要从云用户层面进行改进。

Method: 提出了一种用户中心、基于Kubernetes的架构，实现了一个碳排放强度预测器，并利用该预测器基于绿色能源的可用性来调度工作负载，充分利用区域和时间上的变化来最小化排放。

Result: 使用真实世界的云工作负载执行跟踪评估该系统，并与基线轮询调度器进行了比较，发现在资源受限的严格场景下，该系统可实现高达13%的碳排放减少。

Conclusion: 所提出的用户中心、基于Kubernetes的架构能够通过智能调度工作负载来有效减少云工作负载的碳排放，尤其是在资源受限的情况下，为实现绿色云计算提供了一种可行的解决方案。

Abstract: To meet the increasing demand for cloud computing services, the scale and
number of data centers keeps increasing worldwide. This growth comes at the
cost of increased electricity consumption, which directly correlates to CO2
emissions, the main driver of climate change. As such, researching ways to
reduce cloud computing emissions is more relevant than ever. However, although
cloud providers are reportedly already working near optimal power efficiency,
they fail in providing precise sustainability reporting. This calls for further
improvements on the cloud computing consumer's side. To this end, in this paper
we propose a user-centric, Kubernetes-based architecture for green cloud
computing. We implement a carbon intensity forecaster and we use it to schedule
workloads based on the availability of green energy, exploiting both regional
and temporal variations to minimize emissions. We evaluate our system using
real-world traces of cloud workloads execution comparing the achieved carbon
emission savings against a baseline round-robin scheduler. Our findings
indicate that our system can achieve up to a 13% reduction in emissions in a
strict scenario with heavy limitations on the available resources.

</details>


### [374] [Testing and benchmarking emerging supercomputers via the MFC flow solver](https://arxiv.org/abs/2509.13575)
*Benjamin Wilfong,Anand Radhakrishnan,Henry A. Le Berre,Tanush Prathi,Stephen Abbott,Spencer H. Bryngelson*

Main category: cs.DC

TL;DR: MFC是一个 CFD 代码，带有一个工具链，可以自动执行输入生成、编译、作业提交、回归测试和基准测试，从而帮助用户评估新超级计算机的正确性和性能。


<details>
  <summary>Details</summary>
Motivation: 需要通过应用程序代码来测试和评估新部署的超级计算机，并且需要用户友好的工具来简化这一过程。

Method: MFC 代码本身是一个 CFD 代码，它带有一个工具链，可以自动执行输入生成、编译、批处理作业提交、回归测试和基准测试。通过测量每空间离散网格点的计算时间来评估性能。

Result: 在五代 NVIDIA GPU、三代 AMD GPU 和各种 CPU 架构（包括 Intel、Cray、NVIDIA、AMD 和 GNU 编译器）上进行了 MFC 基准测试，发现了 Frontier 和 El Capitan 等新机器上的编译器错误和回归。MFC 已对大约 50 个计算设备和 5 个旗舰超级计算机进行了基准测试。

Conclusion: MFC 及其工具链可以有效地帮助用户评估新超级计算机的正确性和性能，即使对于软件工程经验有限的用户也是如此。该工具还发现了实际系统中的编译器问题。

Abstract: Deploying new supercomputers requires testing and evaluation via application
codes. Portable, user-friendly tools enable evaluation, and the Multicomponent
Flow Code (MFC), a computational fluid dynamics (CFD) code, addresses this
need. MFC is adorned with a toolchain that automates input generation,
compilation, batch job submission, regression testing, and benchmarking. The
toolchain design enables users to evaluate compiler-hardware combinations for
correctness and performance with limited software engineering experience. As
with other PDE solvers, wall time per spatially discretized grid point serves
as a figure of merit. We present MFC benchmarking results for five generations
of NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures,
utilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have
revealed compiler bugs and regressions on recent machines such as Frontier and
El Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship
supercomputers.

</details>


### [375] [Modeling the Carbon Footprint of HPC: The Top 500 and EasyC](https://arxiv.org/abs/2509.13583)
*Varsha Rao,Andrew A. Chien*

Main category: cs.DC

TL;DR: 由于缺乏数据，高密度计算（HPC）系统的碳足迹难以计算。本研究使用名为 EasyC 的新工具，对 391 个 HPC 系统的运行碳排放和 283 个 HPC 系统的体现碳排放进行了建模。通过利用其他公开信息，可以提高覆盖率。研究估计，Top 500 HPC 系统的运行碳排放量为 1,393.7 百万吨二氧化碳当量（1 年），体现碳排放量为 1,881.8 百万吨二氧化碳当量。研究还预测，到 2030 年，Top 500 系统的碳足迹将有所增加。EasyC 工具可以通过仅使用少量数据指标来估算碳足迹。


<details>
  <summary>Details</summary>
Motivation: 鉴于温室气体协议的碳排放核算方法对于单个或多个 HPC 系统而言难以应用，导致 HPC 领域缺乏碳排放报告，因此本研究旨在评估 HPC（特别是 Top 500 系统）的碳足迹，解决数据有限的挑战。

Method: 本研究利用 Top500.org 公布的数据和名为 EasyC 的新工具，对 391 个 HPC 系统的运行碳排放和 283 个 HPC 系统的体现碳排放进行了建模。通过挖掘其他公开信息来提高覆盖率，并使用插值法估算 Top 500 HPC 系统的碳足迹。EasyC 工具能够仅通过几个数据指标来模拟碳足迹。

Result: 本研究估计 Top 500 HPC 系统的运行碳排放量为 1,393.7 百万吨二氧化碳当量（1 年），体现碳排放量为 1,881.8 百万吨二氧化碳当量。研究还预测了 Top 500 系统的碳足迹将增长至 2030 年。EasyC 工具能够将 Top 500 系统的运行碳排放覆盖率提高到 98%，体现碳排放覆盖率提高到 80.8%。

Conclusion: EasyC 工具能够通过少量数据指标有效地模拟 HPC 系统的碳足迹，从而解决数据可用性有限的问题，并提高碳足迹核算的覆盖率。该工具为估算 Top 500 HPC 系统的碳足迹提供了第一个估计值，并为预测未来碳足迹趋势提供了基础。

Abstract: Climate change is a critical concern for HPC systems, but GHG protocol
carbon-emission accounting methodologies are difficult for a single system, and
effectively infeasible for a collection of systems. As a result, there is no
HPC-wide carbon reporting, and even the largest HPC sites do not do GHG
protocol reporting.
  We assess the carbon footprint of HPC, focusing on the Top 500 systems. The
key challenge lies in modeling the carbon footprint with limited data
availability.
  With the disclosed Top500.org data, and using a new tool, EasyC, we were able
to model the operational carbon of 391 HPC systems and the embodied carbon of
283 HPC systems. We further show how this coverage can be enhanced by
exploiting additional public information. With improved coverage, then
interpolation is used to produce the first carbon footprint estimates of the
Top 500 HPC systems. They are 1,393.7 million MT CO2e operational carbon (1
Year) and 1,881.8 million MT CO2e embodied carbon. We also project how the Top
500's carbon footprint will increase through 2030.
  A key enabler is the EasyC tool which models carbon footprint with only a few
data metrics. We explore availability of data and enhancement, showing that
coverage can be increased to 98% of Top 500 systems for operational and 80.8%
of the systems for embodied emissions.

</details>


### [376] [GPU Programming for AI Workflow Development on AWS SageMaker: An Instructional Approach](https://arxiv.org/abs/2509.13703)
*Sriram Srinivasan,Hamdan Alabsi,Rand Obeidat,Nithisha Ponnala,Azene Zenebe*

Main category: cs.DC

TL;DR: 本课程教授GPU架构、编程及在AI代理开发中的应用，旨在提升学生在现代计算密集型领域的竞争力。


<details>
  <summary>Details</summary>
Motivation: 为本科生和研究生提供GPU架构、编程及AI代理开发专项课程，以应对现代计算密集型领域的需求。

Method: 课程内容涵盖GPU/CPU硬件基础、并行计算、检索增强生成（RAG）开发与GPU优化，并包含云GPU实例配置、并行算法实现和可扩展AI解决方案部署的实践经验。通过评估、课程反馈和匿名调查来衡量学习效果。

Result: 1. AWS是进行GPU编程的有效且经济的平台。 2. 实践经验显著提高了学生的技能水平和参与度。 3. 课程利用TensorBoard和HPC分析器等工具，提高了学生解决问题和批判性思维能力，暴露了性能瓶颈和扩展性问题。

Conclusion: 将并行计算纳入STEM教育具有重要的教学价值，建议在STEM课程中推广此类选修课，以培养学生在计算密集型领域的能力。

Abstract: We present the design, implementation, and comprehensive evaluation of a
specialized course on GPU architecture, GPU programming, and how these are used
for developing AI agents. This course is offered to undergraduate and graduate
students during Fall 2024 and Spring 2025. The course began with foundational
concepts in GPU/CPU hardware and parallel computing and progressed to develop
RAG and optimizing them using GPUs. Students gained experience provisioning and
configuring cloud-based GPU instances, implementing parallel algorithms, and
deploying scalable AI solutions. We evaluated learning outcomes through
assessments, course evaluations, and anonymous surveys. The results reveal that
(1) AWS served as an effective and economical platform for practical GPU
programming, (2) experiential learning significantly enhanced technical
proficiency and engagement, and (3) the course strengthened students'
problem-solving and critical thinking skills through tools such as TensorBoard
and HPC profilers, which exposed performance bottlenecks and scaling issues.
Our findings underscore the pedagogical value of integrating parallel computing
into STEM education. We advocate for broader adoption of similar electives
across STEM curricula to prepare students for the demands of modern,
compute-intensive fields.

</details>


### [377] [LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology](https://arxiv.org/abs/2509.13978)
*Renan Souza,Timothy Poteet,Brian Etz,Daniel Rosendo,Amal Gueroudji,Woong Shin,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: 本研究提出了一种利用大型语言模型（LLM）代理进行科学工作流运行时数据交互式分析的方法。


<details>
  <summary>Details</summary>
Motivation: 当前科学发现依赖于跨边缘、云和高性能计算（HPC）的数据处理工作流，但大规模下的工作流追踪数据分析复杂且困难，现有系统交互性有限。

Method: 提出了一种评估方法、参考架构和开源实现，利用交互式LLM代理进行运行时数据分析。该方法采用轻量级、元数据驱动的设计，将自然语言转换为结构化的追踪查询，并结合了模块化设计、提示调整和检索增强生成（RAG）。

Result: 在LLaMA、GPT、Gemini和Claude上进行了评估，涵盖了多样化的查询类别和一个真实的化学工作流，结果表明该方法能够提供准确且富有洞察力的LLM代理响应，超越了记录的追踪数据。

Conclusion: LLM代理可以通过自然语言交互，有效简化和增强大规模科学工作流数据的分析过程，提供比传统方法更深入的见解。

Abstract: Modern scientific discovery increasingly relies on workflows that process
data across the Edge, Cloud, and High Performance Computing (HPC) continuum.
Comprehensive and in-depth analyses of these data are critical for hypothesis
validation, anomaly detection, reproducibility, and impactful findings.
Although workflow provenance techniques support such analyses, at large scale,
the provenance data become complex and difficult to analyze. Existing systems
depend on custom scripts, structured queries, or static dashboards, limiting
data interaction. In this work, we introduce an evaluation methodology,
reference architecture, and open-source implementation that leverages
interactive Large Language Model (LLM) agents for runtime data analysis. Our
approach uses a lightweight, metadata-driven design that translates natural
language into structured provenance queries. Evaluations across LLaMA, GPT,
Gemini, and Claude, covering diverse query classes and a real-world chemistry
workflow, show that modular design, prompt tuning, and Retrieval-Augmented
Generation (RAG) enable accurate and insightful LLM agent responses beyond
recorded provenance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [378] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 思考型大语言模型在LLM裁判范式中比非思考型模型更准确、更高效、更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）越来越多地被用作自动化裁判，确保其可靠性、效率和鲁棒性至关重要。

Method: 本研究系统性地比较了思考型和非思考型LLM在LLM裁判范式中的表现，使用了开源的Qwen 3模型（0.6B、1.7B和4B参数）。在RewardBench任务上评估了准确性和计算效率（FLOPs），并考察了非思考模型的增强策略，包括上下文学习、评分标准引导、参考评估和n-best聚合。

Result: 结果表明，尽管有增强策略，非思考模型在准确性上普遍不及思考模型。思考模型准确性高约10%，效率开销小（低于2倍）；而增强策略（如少样本学习）在成本更高（超过8倍）的情况下增益有限。思考模型在位置、从众、身份、多样性和随机偏差等多种偏差条件下，保持了显著更高的鲁棒性（平均高6%）。进一步的跨语言实验也证实了显式推理的好处。

Conclusion: 本研究通过系统性实验证明，显式推理在大语言模型裁判范式中不仅在准确性和效率上，而且在鲁棒性方面都具有明显优势。

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [379] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 评估意识（模型在测试和部署时表现不同）会削弱AI安全评估，因为模型可能会隐藏危险能力。之前的研究只在一个70B模型上进行了演示，但其跨模型规模的缩放关系尚不清楚。我们使用线性探测在0.27B到70B参数的15个模型上研究了评估意识的缩放行为。


<details>
  <summary>Details</summary>
Motivation: 评估AI安全评估的有效性，因为模型可能在测试期间隐藏危险能力，并且了解评估意识如何随模型规模扩展。

Method: 在来自四个模型家族的15个模型（规模从0.27B到70B参数）上，使用线性探测对模型中的“控制向量激活”进行分析，以研究评估意识。

Result: 评估意识随着模型规模的增加而呈幂律关系（power-law）增长。这种增长趋势在不同模型家族中是可预测的。

Conclusion: 评估意识会随着模型规模的增大而增强，并且这种增强是可预测的。这种幂律关系可以帮助预测未来更大模型中可能出现的欺骗行为，并指导设计更具适应性的AI安全评估策略。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [380] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: Chain-of-thought（CoT）推理生成的步骤常常无法对最终答案产生因果影响，导致输出脆弱且不可信。FRIT通过干预训练实现因果一致的推理，通过腐败示例训练模型，生成真实/不真实的成对数据，以识别推理中断的地方。直接偏好优化被用于训练模型偏好因果一致的推理路径。在GSM8K数据集上，FRIT使Mistral模型的推理忠实度提高了3.4个百分点，准确率提高了7.6个百分点，是首个可扩展、无监督的方法，可用于训练语言模型以获得更可靠、可解释的推理。


<details>
  <summary>Details</summary>
Motivation: 现有的Chain-of-thought（CoT）推理方法在提高大型语言模型处理复杂任务的能力方面虽然强大，但研究表明，推理步骤往往无法对最终答案产生因果影响，这导致模型输出的脆弱性和不可靠性。然而，现有的方法主要集中在衡量推理的忠实度，而用于系统性改进推理忠实度的方法却很有限。

Method: FRIT（Faithful Reasoning via Intervention Training）是一种可扩展的对齐方法。该方法通过学习系统性腐败的示例来训练模型生成因果一致的推理。具体来说，FRIT通过干预模型生成的CoT中的单个推理步骤来生成合成训练数据，创建忠实/不忠实成对数据，从而突出推理何时出现中断。之后，利用直接偏好优化（Direct Preference Optimization）来训练模型，使其偏好因果一致的推理路径。

Result: 在Qwen3-8B和Mistral-7B-v0.1模型上，跨事实和符号推理任务的评估结果显示，FRIT使Mistral模型在GSM8K数据集上的忠实推理能力提高了3.4个百分点，同时准确率也提高了7.6个百分点。

Conclusion: FRIT提供了一种首个可扩展、无监督的方法，用于训练语言模型生成更可靠、更可解释的推理。该方法解决了推理性能与可信度之间的关键差距。研究代码已在https://github.com/Anut-py/frit 发布。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [381] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: AI安全研究应采取反脆弱视角，通过利用不确定性来为未来更不可预测的挑战做准备，以应对环境演变和模型适应不良。


<details>
  <summary>Details</summary>
Motivation: 当前的AI安全研究方法（静态基准和单次鲁棒性测试）无法应对环境演变和模型可能出现的适应不良（如奖励攻击、过度优化或能力退化），因此需要一种能够随着时间推移扩展其长期AI安全保障能力（如处理罕见或分布外事件）的视角。

Method: 提出并论证了反脆弱（antifragile）视角在AI安全中的重要性，强调其通过利用不确定性来为未来更大、更不可预测的不确定性做准备的优势。识别了静态测试（场景多样性、奖励攻击、过度对齐）的局限性，并探讨了反脆弱解决方案在管理罕见事件方面的潜力。

Result: 该论文识别了现有AI安全测试方法的局限性，并提出了采用反脆弱视角作为一种潜在的解决方案，以提高AI系统的长期可靠性，特别是在处理罕见或分布外事件时。

Conclusion: AI安全研究需要根本性地调整衡量、基准测试和持续改进AI安全的方法，将反脆弱性融入其中，以应对开放式机器学习系统的长期可靠性挑战，并为构建反脆弱AI安全社区提供指导。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [382] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 文章利用世界模型生成模拟环境来训练能够在新任务变体中泛化的鲁棒性智能体，并提出了一种名为IMAC（Imagined Autocurricula）的新方法，利用无监督环境设计（UED）来自动生成学习课程。


<details>
  <summary>Details</summary>
Motivation: 现实世界的训练数据或精确模拟的缺乏，促使研究者探索使用世界模型作为替代方案，以利用离线收集的数据生成多样化的模拟环境来训练智能体。

Method: 提出了一种名为IMAC（Imagined Autocurricula）的新方法，该方法利用无监督环境设计（UED）在生成的世界中诱导一个自动学习课程。

Result: 在多种具有挑战性的程序生成环境中，证明了仅在从较窄数据集学习到的世界模型中进行训练，即可在未见过的环境中实现强大的迁移性能。

Conclusion: 文章认为，这项工作为利用更大规模的基础世界模型来训练通用智能体开辟了道路。

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [383] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 在本研究中，我们提出了Chain of Action (CoA)框架，该框架能够在一个单一的Vision-Language-Action (VLA)模型中统一高级规划和低级控制，以解决在Minecraft等开放式环境中训练通用智能体时动作空间选择的挑战。CoA将抽象动作视为一种推理步骤，而不是一个独立的指令，从而提高了动作生成的效果。我们还发布了一个名为OpenHA的综合基准测试套件，以促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 在开发可训练的端到端智能体时，动作空间的有效选择是一个关键且尚未解决的挑战。

Method: 我们首先对在开放式Minecraft环境中用于Vision-Language-Action (VLA)或分层智能体模型的抽象动作空间和分词器进行了大规模、系统性的比较。在此基础上，我们提出了Chain of Action (CoA)框架，它将高级规划和低级控制统一在一个单一的VLA模型中，并将抽象动作视为指导最终可执行动作生成的中间推理步骤。我们还训练了一个All-in-One智能体，该智能体在CoA范式下混合了多种动作空间。

Result: 研究表明，没有单一的动作空间适用于所有情况，最优选择高度依赖于特定任务。CoA框架使得All-in-One智能体能够学习到更鲁棒、更具泛化性的策略，并在整体任务成功率上优于专业的基线模型，达到了新的最先进水平。我们还发布了OpenHA套件，其中包含一个包含800多个不同任务的基准测试、数据集、源代码和预训练模型。 

Conclusion: CoA框架能够有效地解决通用智能体在动作空间选择上的困境，并通过统一规划和控制，显著提高了智能体的性能和泛化能力。OpenHA套件的发布将有助于推动该领域的研究进展。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [384] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: PDDL-Instruct 通过指令微调和链式思考推理，显著提升了 LLMs 在 PDDL 规划中的能力，准确率最高达 94%。


<details>
  <summary>Details</summary>
Motivation: LLMs 在结构化符号规划（尤其是在 PDDL 领域）方面能力有限，需要提高其形式化推理能力。

Method: 提出 PDDL-Instruct 指令微调框架，通过逻辑链式思考引导模型进行动作适用性、状态转换和规划有效性推理，并进行自我纠正。

Result: 在多个规划领域实验中，基于链式思考推理的指令微调模型规划准确率最高达 94%，相较于基线模型有 66% 的绝对提升。

Conclusion: 该工作弥合了 LLMs 的通用推理能力与自动化规划所需的逻辑精度之间的差距，为开发更好的 AI 规划系统提供了方向。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [385] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 该论文提出了Agentic UAVs框架，利用大语言模型（LLM）和工具调用技术，显著提升了无人机（UAV）在复杂任务中的自主性和态势感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有UAV系统自主性水平低（SAE Level 2-3），依赖规则和狭隘AI，缺乏在动态、不确定任务中的适应性、情境感知推理、自主决策和生态系统集成能力，特别是未使用LLM代理进行实时知识访问。

Method: 提出了一个五层架构（感知、推理、动作、集成、学习）的Agentic UAVs框架，利用LLM驱动的推理、数据库查询和第三方系统交互。原型系统集成了YOLOv11目标检测、GPT-4推理和本地Gemma-3部署，并基于ROS2和Gazebo进行仿真。

Result: 在模拟的搜索救援场景中，Agentic UAVs相比传统系统，取得了更高的检测置信度（0.79 vs 0.72），提高的人员检测率（91% vs 75%），并显著增加了动作推荐（92% vs 4.5%）。

Conclusion: 结果表明，Agentic UAVs框架通过引入LLM代理和工具调用，在不显著增加计算开销的情况下，实现了更高水平的自主性、态势感知和生态系统集成能力。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [386] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 提出了一种名为“语义融合”的轻量级方案，通过引入并行的、模糊隶属的特征通道来增强 Transformer 语言模型，该通道对词元级语义进行编码。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入词元级语义信息来增强 Transformer 语言模型，实现更精确、可控的文本生成。

Method: 该方法为每个词元创建一个由可解释特征组成的向量（例如词性、浅层角色、边界标志、情感极性和强度），这些特征的值由可微隶属函数（例如功率核）生成。这些向量形成一个句子级的语义矩阵，通过门控适配器融合到 Transformer 模型中。训练过程包括标准的下一个词元预测、一个用于从隐藏状态重建语义特征的辅助损失，以及一个用于规范化形容词类别分布的轻量级统一器。

Result: 在包含用于样本外（OOD）控制的保留形容词的合成双从句语料库上，语义融合在困惑度方面有所提高，并实现了极性和标点符号的精确、用户可控生成，同时保持了模型的简洁性。

Conclusion: 该方法仅增加了少量开销，与绑定的输入-输出嵌入完全兼容，并为条件自然语言生成提供了可解释的途径。

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [387] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: 提出了一种名为Asterisk Operator的新型统一框架，用于基于邻接结构并行传播（ASPP）的抽象推理。


<details>
  <summary>Details</summary>
Motivation: 将结构化推理任务形式化为由隐式关系图指导的局部、并行状态演化过程。

Method: 证明了该算子在保持局部计算约束的同时实现全局推理能力，为抽象推理问题提供了一种高效且收敛的计算范式。

Result: 通过对ARC2挑战和康威生命游戏进行严格的数学分析和全面的实验，证明了该算子的普遍性、收敛性和优越性能。

Conclusion: 提出了一种创新的Embedding-Asterisk蒸馏方法，在ARC2验证集上实现了100%的准确率，参数量仅为6M，标志着神经符号推理领域的重大突破。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [388] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: Agent^2是一个创新的框架，利用LLM驱动的双代理架构实现了全自动化的强化学习（RL）代理设计。


<details>
  <summary>Details</summary>
Motivation: 传统的RL代理开发需要大量专业知识、耗时且易失败，限制了其可及性。本研究旨在解决这一挑战，实现RL代理设计的全自动化。

Method: Agent^2采用双代理架构：生成代理（Generator Agent）负责根据自然语言任务描述和环境代码生成RL代理，目标代理（Target Agent）是生成的RL代理。该框架将RL开发分解为MDP建模和算法优化两个阶段，并基于模型上下文协议（Model Context Protocol）实现跨环境和算法的标准化创建，同时包含自适应训练管理和智能反馈分析。

Result: 在MuJoCo、MetaDrive、MPE和SMAC等广泛基准测试中，Agent^2的性能持续优于手动设计的解决方案，性能提升最高达55%，平均提升显著。

Conclusion: Agent^2通过实现真正的端到端、闭环自动化，开创了智能代理设计和优化其他代理的新范式，是自动化AI系统的一个根本性突破。

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [389] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 该研究全面评估了16个最先进的视觉-语言模型（VLMs）在不确定性量化方面的表现，发现更大的模型通常具有更好的不确定性量化能力，并且在数学和推理任务上表现较差。


<details>
  <summary>Details</summary>
Motivation: 评估视觉-语言模型（VLMs）在不确定性量化方面的表现，因为这方面研究不足，而它对于可靠评估多模态系统至关重要。

Method: 评估16个先进的VLMs（开源和闭源），使用3种不同的评分函数，在6个多模态数据集上进行不确定性量化评估。

Result: 研究发现，更大的模型在不确定性量化方面表现更好，更确定的模型准确率更高。数学和推理任务的不确定性表现普遍不如其他领域。

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [390] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 使用深度学习（Transformer）和梯度下降，从动作序列中学习命题STRIPS世界模型，通过监督式下一个词预测问题解决，并证明了Transformer能够准确表示世界模型，且可从正反例动作序列中学习。


<details>
  <summary>Details</summary>
Motivation: 从动作序列中学习命题STRIPS世界模型。

Method: 将问题转化为监督式下一个词预测问题，使用Transformer架构，并从正、反例动作序列中学习。

Result: 证明了Transformer架构能够准确表示命题STRIPS世界模型，并可从中学习。

Conclusion: 所提出的基于Transformer的方法能够有效地从动作序列中学习命题STRIPS世界模型。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [391] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: SteeringControl是一个用于评估表征控制方法在偏差、有害生成和幻觉等核心对齐目标上的基准，并研究其对谄媚和常识道德等次要行为的影响。研究发现在模型、控制方法和目标行为的组合不当时，可能会出现严重的“概念纠缠”问题。


<details>
  <summary>Details</summary>
Motivation: 以往的对齐研究虽然关注了表征控制的副作用，但未能系统地理解其中未被探索的权衡。本研究旨在通过一个全面的基准来解决这一问题。

Method: 本研究提出了SteeringControl基准，包含一个模块化的控制框架和用于评估的安全性相关的主要和次要行为数据集。研究评估了五种流行的控制方法在Qwen-2.5-7B和Llama-3.1-8B模型上的表现。

Result: 研究发现在Qwen-2.5-7B和Llama-3.1-8B模型上，强的控制性能取决于控制方法、模型和目标行为的具体组合，并且不当的组合可能导致严重的概念纠缠。

Conclusion: 表征控制的性能和副作用是相互交织的，需要根据具体的模型、控制方法和目标行为进行仔细的权衡和选择。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [392] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 给大语言模型提供类人协作工具和自主权，可以提升其在复杂编程挑战中的表现，但对简单问题效果不一。不同模型会根据自身特点和问题难度，自发采用不同的协作策略（如广泛使用或选择性使用工具），这类似于人类开发者的行为。研究表明，主动输出（写作）相比于信息获取（阅读）更能驱动性能提升，提示未来的协作界面应侧重于提供推理支持而非普适性效率提升。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型（LLM）代理在获得类似人类的协作工具和自主权后，其解决问题的性能是否会得到提升。

Method: 为 Claude Code 代理配备了基于 MCP 的社交媒体和日志记录工具，并允许它们自行使用。在 34 个 Aider Polyglot Python 编程挑战中进行了测试。

Result: 在最困难的问题上，协作工具显著提高了性能，成本降低了 15-40%，交互次数减少了 12-27%，完成时间缩短了 12-38%。但在全部挑战集上的效果不一。模型（如 Sonnet 3.7 和 Sonnet 4）自发采用了不同的协作策略。AI 代理倾向于主动写作（2-9倍于阅读），表明结构化表述是性能提升的关键。

Conclusion: AI 代理可以通过类似人类的协作工具在能力边缘受益，这表明自适应的协作界面可以作为推理增强器，而不是提供普遍的效率提升。

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [393] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 学生在高等教育中使用生成式AI，但现有AI检测工具并不可靠。本研究调查了学生在三门基于证明的数学课程（抽象代数和拓扑学）中的AI使用和看法。课程政策允许适度使用AI。通过调查和访谈，分析了学生如何使用AI工具，他们对AI的有用性和局限性的看法，以及这对基于证明的数学教学的启示。最后，讨论了将生成式AI融入基于证明的数学教学的未来考量。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的兴起以及现有AI检测工具的不可靠性，制定鼓励学生学习和批判性思维的政策变得越来越重要。

Method: 本研究通过对三门包含抽象代数和拓扑学的大学数学课程中的学生进行调查和访谈，分析了学生使用生成式AI的情况和看法。这些课程都允许学生在一定程度上使用生成式AI。

Result: 研究分析了学生如何使用AI工具，他们对AI的有用性和局限性的看法，以及这些看法对教授数学证明的影响。

Conclusion: 研究最后讨论了将生成式AI整合到基于证明的数学教学中的未来考量。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [394] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: CoBRA是一个用于指定基于LLM的社会模拟中代理行为的新颖工具包，它通过明确编程代理的认知偏差来解决现有方法中的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于自然语言描述的方法在LLM社会模拟中无法保证代理行为的一致性，并且无法捕捉描述的细微差别。

Method: CoBRA包含两个部分：1. 认知偏差指数（CBI），通过量化代理在一组经典社会科学实验中的反应来衡量其认知偏差；2. 行为调节引擎（BRE），用于调整代理行为以展现受控的认知偏差。

Result: CoBRA能够以模型无关的方式精确编程社会代理所展现的认知偏差，并通过演示和技术基准进行了评估。

Conclusion: CoBRA为LLM社会模拟中的代理行为规范提供了一种新的、精确的、模型无关的方法，通过明确编程认知偏差来提高行为的一致性和细微性。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [395] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 研究人员构建了一个包含二元切换指令的状态控制基准，以解决多模态代理在图形用户界面（GUI）控制中执行切换指令的不可靠性问题。他们提出了一种名为 StaR（State-aware Reasoning）的训练方法，该方法通过训练代理感知当前切换状态、分析指令中的目标状态并据此采取行动，从而提高了切换指令的执行准确性，并对通用任务性能产生了积极影响。


<details>
  <summary>Details</summary>
Motivation: 多模态代理在图形用户界面（GUI）控制中虽然促进了有效交互，但在可靠执行切换控制指令方面存在瓶颈。

Method: 提出了一种名为 StaR（State-aware Reasoning）的训练方法，旨在教会代理感知当前切换状态、分析指令中的目标状态并据此采取行动。

Result: 在三个多模态代理的实验中，StaR 将切换指令的执行准确性提高了 30% 以上。此外，在三个公开基准上的进一步评估表明，StaR 能够提升整体任务性能。在动态环境中进行的评估也凸显了 StaR 在实际应用中的潜力。

Conclusion: StaR 是一种有效的训练方法，可以显著提高多模态代理在 GUI 控制中执行切换指令的准确性，并对通用任务性能产生积极影响，具有实际应用潜力。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [396] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: LLM驱动的GUI代理在工业管理中面临挑战，提出InfraMind框架解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 工业管理软件复杂性高，多供应商集成，操作员短缺，RPA灵活性不足，LLM代理存在理解、精确度、状态定位、部署和安全等问题。

Method: 提出InfraMind框架，包含系统性搜索探索、内存驱动规划、高级状态识别、结构化知识蒸馏和多层安全机制。

Result: 在开源和商业DCIM平台上进行的大量实验表明，InfraMind在任务成功率和操作效率方面优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了严谨且可扩展的解决方案。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [397] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: LLMs在数学推理方面取得显著进展，但在高精度任务（如数值计算和符号计算）方面仍存在挑战。为解决此问题，我们提出THOR（Tool-Integrated Hierarchical Optimization via RL），一个结合外部工具进行推理的方法。THOR通过TIRGen构建高质量工具集成推理数据集，并采用RL策略进行分层优化，同时优化问题解决方法和代码生成。此外，THOR还包含一个自我纠正机制，能在推理过程中利用工具反馈动态修正错误路径。实验证明，THOR在数学和代码基准测试中均表现出色，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在处理高精度数学任务时存在不足，需要整合外部工具来弥补。然而，现有的工具集成方法在构建数据集、进行细粒度优化和增强推理方面面临挑战。

Method: THOR（Tool-Integrated Hierarchical Optimization via RL）提出了一种新方法。首先，利用TIRGen（一个多智能体actor-critic管道）构建高质量的工具集成推理数据集。其次，采用一种RL策略进行分层优化，同时优化问题解决方法和代码生成，并利用中间工具调用的成功预测最终答案的正确性。最后，引入一个自我纠正机制，利用即时工具反馈动态修正推理路径。

Result: THOR方法在数学和代码基准测试中均取得最先进的性能，并且在不同模型上表现出良好的泛化能力，能够有效提升推理和非推理模型在相关任务上的表现。

Conclusion: THOR通过TIRGen、RL分层优化和自我纠正机制，有效解决了LLM在工具集成数学推理中的关键挑战，显著提升了模型在数学和代码相关任务上的性能和泛化能力。

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [398] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA框架通过多模态大语言模型和约束解码策略，实现了智能手机上的一键式AI任务执行，提高了指令推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了简化用户在智能手机上访问预定义AI服务的操作，并应对生成式AI技术的发展和在智能手机上的广泛应用。

Method: 提出了一种基于多模态大语言模型（MLLM）的推荐流程，结合结构化推理来提取关键实体、推断用户意图并生成精确指令。该方法还包括一个增强推理的模板机制和一个基于前缀树的约束解码策略，以确保输出的连贯性和与用户意图的一致性。

Result: 在真实标注数据集和用户研究中，MIRA在指令推荐的准确性方面表现出显著提升。

Conclusion: MIRA框架在智能手机上提供了一种更流畅、更高效的AI服务交互方式，有潜力彻底改变用户与设备互动的方式。

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [399] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 提出一种基于DPLL架构的整数线性约束模型计数（MCILC）的精确方法，并结合了混合整数规划的简化技术，在随机和应用基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 许多应用（包括计算机科学、运筹学和优化领域）都归结为整数线性约束模型计数（MCILC）。

Method: 设计了一个基于DPLL架构的精确MCILC方法，并集成了混合整数规划中的几种有效简化技术。

Result: 与最先进的MCILC计数器和命题模型计数器相比，该方法在2840个随机基准测试和4131个应用基准测试中表现出优越的性能。在随机基准测试中，该方法解决了1718个实例，而最先进的方法仅解决了1470个实例。此外，该方法是唯一能够解决所有4131个应用实例的方法。

Conclusion: 该方法在MCILC问题上具有显著的优势，并且在实际应用中具有很高的效率和可行性。

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [400] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 认知可能通过操纵生物神经网络结构和信息流的重大转变而演变。使用人工神经网络（ANNs）模型，我们比较了前馈、递归和层状网络在学习不同复杂度的语法方面的性能。结果表明，递归网络在处理输入类型和学习复杂语法方面比前馈网络有定性扩展，其训练难度构成了过渡障碍和偶发性不可逆性。层状网络在语法学习方面并未表现出优势。总之，信息流的某些变化可以产生认知绩效的转变。


<details>
  <summary>Details</summary>
Motivation: 探讨认知是否像生物进化一样，通过改变神经网络结构和信息流的重大转变而演变。

Method: 使用前馈、递归和层状人工神经网络（ANNs）模型，在控制网络大小和资源的情况下，测试它们学习不同复杂度人工语法的能力。

Result: 递归网络在处理输入类型和学习复杂语法方面比前馈网络表现出定性扩展；递归网络的训练难度构成过渡障碍和偶发性不可逆性；层状网络在语法学习方面没有表现出性能优势。

Conclusion: 信息流的某些变化可以产生认知绩效的转变。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [401] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: CrowdAgent是一个多智能体系统，用于端到端地管理和优化NLP任务的数据标注过程，能够动态整合LLMs、SLMs和人类专家，并进行任务分配、数据标注以及质量/成本管理。


<details>
  <summary>Details</summary>
Motivation: 现有的NLP数据标注方法往往只关注标注本身，而忽略了整合不同标注源（LLMs、SLMs、人类专家）的动态过程控制，以及在质量和成本之间进行权衡的复杂性。

Method: 提出了一种名为CrowdAgent的多智能体系统，该系统能够对任务进行合理分配，并整合LLMs、SLMs和人类专家，实现协同标注。它实现了端到端的流程控制，包括任务分配、数据标注以及质量/成本管理。

Result: 在六个不同的多模态分类任务上进行了广泛的实验，证明了CrowdAgent的有效性。

Conclusion: CrowdAgent通过整合LLMs、SLMs和人类专家，并进行端到端的流程控制，能够有效地管理和优化NLP数据的标注过程，在质量和成本之间取得良好的平衡。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [402] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 该研究通过结合图卷积网络（GCN）和多层感知机（MLP）控制器，在经验上验证了二阶学习能够促进心智表征的出现，并有效解决导航任务。


<details>
  <summary>Details</summary>
Motivation: 在高级认知中，心智表征（即反映外部环境的内部模型）至关重要，但难以实证。该研究旨在经验上验证二阶学习（学习适应一阶学习的机制）能够促进心智表征的出现。

Method: 提出一种包含GCN（一阶学习者）和MLP控制器（二阶学习者）的分层架构。GCN将节点特征映射到最优导航路径的预测，而MLP在面对结构新颖的迷宫环境时动态调整GCN的参数。

Result: 二阶学习在认知系统形成与环境结构同构的内部心智图时尤其有效。在未见过的迷宫任务上，性能显著提升，泛化能力强。

Conclusion: 结构化的心智表征在最大化二阶学习的有效性方面起着关键作用，该研究的量化和质性结果为这一观点提供了经验支持。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [403] [Delta Matters: An Analytically Tractable Model for $β$-$δ$ Discounting Agents](https://arxiv.org/abs/2509.13637)
*Yasunori Akagi,Takeshi Kurashima*

Main category: cs.GT

TL;DR: 该研究将时间不一致性分析从δ=1的限制推广到0 < δ ≤ 1 的一般情况，并在此基础上推导出最优干预策略。


<details>
  <summary>Details</summary>
Motivation: 解决以往研究在时间不一致性分析中对δ=1的限制，探索更一般情况下的行为和干预策略。

Method: 在β-δ折现模型（拟双曲折现）的基础上，放宽δ=1的限制，推导出在0 < δ ≤ 1情况下智能体行为的闭式描述，并基于此推导出最优干预条件。

Result: 得出了智能体行为和最优干预策略依赖于δ值的结论，并证明了在0 < δ ≤ 1 的情况下，智能体行为的闭式描述仍然是可能的。

Conclusion: 以往研究中固定δ=1的做法可能过度简化了现实世界中的决策过程，未来的研究应考虑δ值的变化对行为和干预策略的影响。

Abstract: Humans exhibit time-inconsistent behavior, in which planned actions diverge
from executed actions. Understanding time inconsistency and designing
appropriate interventions is a key research challenge in computer science and
behavioral economics. Previous work focuses on progress-based tasks and derives
a closed-form description of agent behavior, from which they obtain optimal
intervention strategies. They model time-inconsistency using the
$\beta$-$\delta$ discounting (quasi-hyperbolic discounting), but the analysis
is limited to the case $\delta = 1$. In this paper, we relax that constraint
and show that a closed-form description of agent behavior remains possible for
the general case $0 < \delta \le 1$. Based on this result, we derive the
conditions under which agents abandon tasks and develop efficient methods for
computing optimal interventions. Our analysis reveals that agent behavior and
optimal interventions depend critically on the value of $\delta$, suggesting
that fixing $\delta = 1$ in many prior studies may unduly simplify real-world
decision-making processes.

</details>


### [404] [Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation](https://arxiv.org/abs/2509.13653)
*Hang Ren,Yulin Wu,Shuhan Qi,Jiajia Zhang,Xiaozhen Sun,Tianzi Ma,Xuan Wang*

Main category: cs.GT

TL;DR: Regret minimization methods for finding Nash equilibria have issues with average strategy computation and reward transformation framework's sensitivity to parameters. This paper proposes adaptive methods to dynamically adjust parameters, improving convergence and outperforming existing algorithms.


<details>
  <summary>Details</summary>
Motivation: Regret minimization methods for finding Nash equilibria in Normal-Form Games (NFGs) and Extensive-Form Games (EFGs) typically guarantee convergence only for the average strategy, which is computationally expensive or error-prone. The Reward Transformation (RT) framework aimed to solve this via reward function regularization but suffers from parameter sensitivity, leading to poor performance. This work is motivated by the need for more practical and effective regret minimization techniques.

Method: This paper proposes an adaptive technique to improve the performance of Reward Transformation Regret Matching (RTRM) and RT Counterfactual Regret Minimization (RTCFR) and their variants. The adaptive methods dynamically adjust parameters to balance exploration and exploitation, enhance regret accumulation, and ensure better consistency between theoretical guarantees and practical performance for solving NFGs and EFGs.

Result: The proposed adaptive methods significantly accelerate convergence compared to existing algorithms. Experimental results demonstrate that these methods outperform state-of-the-art algorithms in solving NFGs and EFGs, showing improved asymptotic last-iterate convergence and achieving linear convergence.

Conclusion: The adaptive technique effectively addresses the practical challenges of the Reward Transformation framework in regret minimization for solving Normal-Form Games and Extensive-Form Games. By dynamically adjusting parameters, the proposed methods achieve faster and more consistent convergence, outperforming current state-of-the-art algorithms and enhancing the practical applicability of regret minimization.

Abstract: Regret minimization is a powerful method for finding Nash equilibria in
Normal-Form Games (NFGs) and Extensive-Form Games (EFGs), but it typically
guarantees convergence only for the average strategy. However, computing the
average strategy requires significant computational resources or introduces
additional errors, limiting its practical applicability. The Reward
Transformation (RT) framework was introduced to regret minimization to achieve
last-iterate convergence through reward function regularization. However, it
faces practical challenges: its performance is highly sensitive to manually
tuned parameters, which often deviate from theoretical convergence conditions,
leading to slow convergence, oscillations, or stagnation in local optima.
  Inspired by previous work, we propose an adaptive technique to address these
issues, ensuring better consistency between theoretical guarantees and
practical performance for RT Regret Matching (RTRM), RT Counterfactual Regret
Minimization (RTCFR), and their variants in solving NFGs and EFGs more
effectively. Our adaptive methods dynamically adjust parameters, balancing
exploration and exploitation while improving regret accumulation, ultimately
enhancing asymptotic last-iterate convergence and achieving linear convergence.
Experimental results demonstrate that our methods significantly accelerate
convergence, outperforming state-of-the-art algorithms.

</details>


### [405] [Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation](https://arxiv.org/abs/2509.14032)
*Philip Jordan,Maryam Kamgarpour*

Main category: cs.GT

TL;DR: 该论文研究了具有共享耦合约束的连续静态博弈中纳什均衡的存在性和计算问题。


<details>
  <summary>Details</summary>
Motivation: 现有关于纳什均衡存在性的结果不适用于玩家效用和约束为玩家整体凹函数的情况，因为这些结果依赖于对可行集整体凸性等强假设。

Method: 利用拓扑不动点理论和对玩家整体凹约束下可行集收缩性的新结构洞察，在较弱条件下证明了纳什均衡的存在性。在此基础上，假设效用函数存在势函数，提出了一种使用对数障碍正则化梯度上升法和自适应步长来计算纳什均衡的方法。

Result: 所提出的方法能够收敛到近似约束纳什均衡，并且在具有精确梯度反馈的情况下，迭代次数为O(ε-3)。

Conclusion: 该研究在较弱的假设下证明了纳什均衡的存在性，并提出了一种可行的计算方法。

Abstract: We study the existence and computation of Nash equilibria in continuous
static games where the players' admissible strategies are subject to shared
coupling constraints, i.e., constraints that depend on their \emph{joint}
strategies. Specifically, we focus on a class of games characterized by
playerwise concave utilities and playerwise concave constraints. Prior results
on the existence of Nash equilibria are not applicable to this class, as they
rely on strong assumptions such as joint convexity of the feasible set. By
leveraging topological fixed point theory and novel structural insights into
the contractibility of feasible sets under playerwise concave constraints, we
give an existence proof for Nash equilibria under weaker conditions. Having
established existence, we then focus on the computation of Nash equilibria via
independent gradient methods under the additional assumption that the utilities
admit a potential function. To account for the possibly nonconvex feasible
region, we employ a log barrier regularized gradient ascent with adaptive
stepsizes. Starting from an initial feasible strategy profile and under exact
gradient feedback, the proposed method converges to an $\epsilon$-approximate
constrained Nash equilibrium within $\mathcal{O}(\epsilon^{-3})$ iterations.

</details>


### [406] [Generalised Reachability Games Revisited](https://arxiv.org/abs/2509.14091)
*Sougata Bose,Daniel Hausmann,Soumyajit Paul,Sven Schewe,Tansholpan Zhanabekova*

Main category: cs.GT

TL;DR: 本文研究了具有推广可达性目标的两玩家图博弈的复杂性。


<details>
  <summary>Details</summary>
Motivation: 推广可达性博弈是对经典可达性博弈的概括，其中一个玩家（Eve）的目标是按任意顺序访问一个目标集族中的所有目标集，而另一个玩家（Adam）则试图阻止她。

Method: 本文分析了具有推广可达性目标的两玩家图博弈的复杂性。第一，我们改进了推广可达性博弈的复杂性图景，将已知的易处理类从所有目标集均为单例的游戏扩展到此外还允许有对数数量的任意大小的目标集。第二，我们研究了推广可达性博弈的优化变体，重点是目标集的大小。

Result: 对于优化问题，当 Eve 试图最大化访问的单例目标集的数量时，该问题是 NP-hard 的，这与经典变体中单例目标集的易处理性形成对比。当所有目标集均为单例时，通过要求 Eve 承诺她能保证访问的最大目标集子集的大小，可以在优化设置中恢复易处理性。

Conclusion: 本文对具有推广可达性目标的两玩家图博弈的复杂性进行了研究，并提出了改进的复杂性图景和对优化变体的分析。

Abstract: Classic reachability games on graphs are zero-sum games, where the goal of
one player, Eve, is to visit a vertex from a given target set, and that of
other player, Adam, is to prevent this. Generalised reachability games, studied
by Fijalkow and Horn, are a generalisation of reachability objectives, where
instead of a single target set, there is a family of target sets and Eve must
visit all of them in any order. In this work, we further study the complexity
of solving two-player games on graphs with generalised reachability objectives.
Our results are twofold: first, we provide an improved complexity picture for
generalised reachability games, expanding the known tractable class from games
in which all target sets are singleton to additionally allowing a logarithmic
number of target sets of arbitrary size. Second, we study optimisation variants
of generalised reachability with a focus on the size of the target sets. For
these problems, we show intractability for most interesting cases.
Particularly, in contrast to the tractability in the classic variant for
singleton target sets, the optimisation problem is NP-hard when Eve tries to
maximise the number of singleton target sets that are visited. Tractability can
be recovered in the optimisation setting when all target sets are singleton by
requiring that Eve pledges a maximum sized subset of target sets that she can
guarantee to visit.

</details>


### [407] [Sound Value Iteration for Simple Stochastic Games](https://arxiv.org/abs/2509.14112)
*Muqsit Azeem,Jan Kretinsky,Maximilian Weininger*

Main category: cs.GT

TL;DR: 该论文提出了一种改进的SVI算法，可以处理MDP和SG中的终端组件，并提供了优化和实验评估。


<details>
  <summary>Details</summary>
Motivation: 现有的价值迭代（VI）算法在处理MDP和SG时缺乏精度保证，而SVI算法虽然提供了精度保证，但不能用于SG或具有终端组件的MDP。

Method: 提出了一种扩展的SVI算法，特别关注如何处理终端组件，并加入了几种优化方法。

Result: 通过对原型实现进行实验评估，证明了该算法在具有概率循环的系统上的潜力。

Conclusion: 扩展的SVI算法能够成功处理MDP和SG中的终端组件，并且通过优化提高了效率。

Abstract: Algorithmic analysis of Markov decision processes (MDP) and stochastic games
(SG) in practice relies on value-iteration (VI) algorithms. Since basic VI does
not provide guarantees on the precision of the result, variants of VI have been
proposed that offer such guarantees. In particular, sound value iteration (SVI)
not only provides precise lower and upper bounds on the result, but also
converges faster in the presence of probabilistic cycles. Unfortunately, it is
neither applicable to SG, nor to MDP with end components. In this paper, we
extend SVI and cover both cases. The technical challenge consists mainly in
proper treatment of end components, which require different handling than in
the literature. Moreover, we provide several optimizations of SVI. Finally, we
evaluate our prototype implementation experimentally to demonstrate its
potential on systems with probabilistic cycles.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [408] [Thermal Endurance of Suspended Thin-Film Lithium Niobate up to 800 °C](https://arxiv.org/abs/2509.13568)
*Mihir Chaudhari,Lezli Matto,Naveed Ahmed,Michael Liao,Vivek Tallavajhula,Yidou Long,Ziqian Yao,Joshua Campbell,Tzu-Hsuan Hsu,Mark S. Goorsky,Ruochen Lu*

Main category: physics.app-ph

TL;DR: 本研究评估了悬浮薄膜铌酸锂 (LN) 平台在高温下的热稳定性，通过在 550°C 至 800°C 之间以 50°C 为增量进行退火处理，观察声学表面波谐振器的结构完整性和性能变化。


<details>
  <summary>Details</summary>
Motivation: 为了满足高温压电微机电系统 (MEMS) 的需求，需要将压电平台推向其热极限。然而，在恶劣的热环境中，压电 MEMS 器件因材料降解和功能层与载体晶圆之间热膨胀系数 (CTE) 不匹配而可能遭受严重损坏。

Method: 本研究通过对悬浮薄膜铌酸锂 (LN) 平台进行不同温度（550°C 至 800°C，增量 50°C）的退火处理，观察声学表面波谐振器的结构完整性和性能（谐振频率和品质因数 Q）变化。同时，还利用电阻率结构、光学显微镜图像和 X 射线衍射 (XRD) 对器件和材料堆栈进行分析。

Result: 退火处理后，器件的谐振频率和品质因数 (Q) 发生了量化变化。材料和器件的结构完整性也通过电阻率结构、光学显微镜图像和 X 射线衍射 (XRD) 进行了分析，为理解其热极限提供了宝贵数据。

Conclusion: 本研究深入了解了悬浮薄膜铌酸锂 (LN) 平台的热极限，为在恶劣热环境中设计和选择材料以优化该平台提供了宝贵见解。理解其热极限使得该平台可用于传感器、执行器、谐振器以及其他潜在的薄膜铌酸锂微系统，如光子、电光和声光系统。

Abstract: The need for high-temperature piezoelectric microelectromechanical systems
(MEMS) requires pushing piezoelectric platforms to their thermal limits. In
harsh thermal environments, piezoelectric MEMS devices are expected to sustain
severe damage because of material degradation and coefficient of thermal
expansion (CTE) mismatches between the functional layers and the carrier wafer.
This paper investigates the thermal endurance of the suspended thin-film
lithium niobate (LN) platform by observing the structural integrity and
performance of acoustic Lamb wave resonators after annealing rounds at
increasing temperatures, with a focus on temperatures between 550 $^\circ$C and
800 $^\circ$C, with 50 $^\circ$C temperature increments. Fundamental symmetric
(S0) mode acoustic resonators are fabricated on 600 nm stoichiometric LN (sLN)
with 40 nm thick platinum top electrodes and a thin titanium adhesion layer.
After each annealing round, changes in the devices' resonant frequency and
quality factor (\emph{Q}) are quantitatively studied. The devices and material
stack are further analyzed with resistivity structures, optical microscope
images, and X-ray diffraction (XRD) measurements. The results provide valuable
insights into the design and material selection necessary to optimize the
suspended thin-film LN platform for high temperatures. Understanding the
thermal limit of the platform enables its use for sensors, actuators,
resonators, and potentially other thin-film LN microsystems, e.g, photonics,
electro-optical, and acousto-optical systems in harsh thermal environments.

</details>


### [409] [Reducing Temperature Swing and Rectifying Radiative Heat Transfer for Passive Dynamic Space Thermal Control with Variable-Emittance Coatings](https://arxiv.org/abs/2509.13794)
*Liping Wang,Neal Boman,Sydney Taylor,Chloe Stoops*

Main category: physics.app-ph

TL;DR: VO2变发射率涂层在类太空热环境中实现了动态辐射热控制，可提高散热效率并减少温度波动。


<details>
  <summary>Details</summary>
Motivation: 航天器的正常运行和节能需要动态辐射热控制，以应对不断变化的太空热环境。变发射率涂层（尤其是基于热致变色VO2的涂层）提供了一种潜在的解决方案。

Method: 在真空低温恒温器中，使用冷指模拟太空热环境，实验演示了基于热致变色VO2的变发射率涂层的自适应动态辐射热传递。通过黑体和钨镜进行校准，并使用不同掺杂水平的硅片作为静态发射率对照组。

Result: 当冷指温度为80K（模拟外部辐射场景）时，VO2涂层在相变时辐射热导率增强6倍，温度波动减少近20°C。当冷指温度为25°C（模拟内部辐射场景）时，也观察到类似的6倍散热增强。在冷指温度高于涂层时，涂层表现出恒定的辐射热导率，热整流因子达到1.8。

Conclusion: 基于VO2的变发射率涂层在太空热环境中表现出优异的动态辐射热控制能力，能有效提高散热效率、降低温度波动，并实现热整流效应。

Abstract: Dynamic radiative thermal control is crucial for normal operation and energy
saving of spacecraft that copes with changing thermal environment involving
heat dissipation to cold deep space, external heating from the Sun and nearby
planet, and internal heating from onboard electronics. Variable-emittance
coatings, whose infrared emittance can be tuned passively by temperature or
actively by external stimuli, could provide a viable solution. In this work, we
experimentally demonstrate self-adaptive dynamic radiative heat transfer with
variable-emittance coating based on thermochromic VO2 in space-like thermal
environment with a coldfinger and a custom-made sample mount inside a vacuum
cryostat. Black Actar and highly reflective tungsten mirror are used to
calibrate the parasitic head load and heat flux sensor sensitivity, while
multiple static-emittance samples made of silicon wafers with different doping
levels are measured for validation of the experimental method and for direct
comparison with the variable-emittance VO2 coating. With the coldfinger at 80 K
to mimic external radiative scenarios in space, the tunable coating exhibits
6-fold enhancement in radiative thermal conductance upon VO2 phase transition
for promoted heat dissipation, in addition to reduced temperature swing by
almost 20degC compared to the static emitters. With the coldfinger at 25degC as
internal radiative scenarios in space, similar 6-fold heat dissipation from the
variable-emittance coating is also observed, while radiative heat transfer is
much suppressed with a constant radiative thermal conductance when the
coldfinger is hotter than the tunable coating at 25degC, leading to a thermal
rectification factor of 1.8 experimentally achieved.

</details>


### [410] [A Study on Optimizing the Thermal Performance of Coaxial Heat Exchanger Systems in Medium-Deep Geothermal Wells](https://arxiv.org/abs/2509.14141)
*Haonan Chen,Xin Tong,Linchao Yang,Yangxue Zhang*

Main category: physics.app-ph

TL;DR: 中深层地热是关键的可再生能源，但现有的同轴井下换热器（DHE）系统效率低下且存在温度衰减问题。本研究评估了循环流速、入口温度和运行模式对DHE性能的影响，利用了两个地热井（井A：3200米，130.5摄氏度；井B：2500米，103.3摄氏度）的现场数据。结果表明，在最佳条件下（LC3：50立方米/小时，30摄氏度），井A的热提取率从35%提高到42%，出口温度从15摄氏度升至20摄氏度。相比之下，井B的效率从15%下降到5%。连续运行一周后，井A的出口温度从55.7摄氏度降至16.5摄氏度，井B从68摄氏度降至17摄氏度。采用间歇运行模式（每天运行16小时，关闭8小时）可将温度衰减率降低约10%。基于这些发现，我们提出了优化策略：将流速控制在35立方米/小时，将入口温度维持在6-10摄氏度，并实施间歇调度。这项工作为DHE系统的高效设计和可持续运行提供了指导。


<details>
  <summary>Details</summary>
Motivation: 评估循环流速、入口温度和运行模式对中深层地热同轴井下换热器（DHE）系统效率和温度衰减的影响。

Method: 利用两个地热井（井A：3200米，130.5摄氏度；井B：2500米，103.3摄氏度）的现场数据，分析了不同工况下的DHE性能，包括热提取率、出口温度和温度衰减率。对比了连续运行和间歇运行模式的效果。

Result: 在最佳条件下（LC3：50立方米/小时，30摄氏度），井A的热提取率从35%提高到42%，出口温度从15摄氏度升至20摄氏度，而井B的效率从15%下降到5%。连续运行一周后，井A和井B的出口温度均显著下降。间歇运行模式可将温度衰减率降低约10%。

Conclusion: 建议优化DHE系统的设计和运行策略，包括控制流速在35立方米/小时，维持入口温度在6-10摄氏度，并采用间歇运行模式，以提高效率并减缓温度衰减，从而实现可持续运行。

Abstract: Medium-deep geothermal energy is a key renewable source, but existing coaxial
downhole heat exchanger (DHE) systems suffer from low efficiency and
temperature decay. This study evaluates the impacts of circulating flow rate,
inlet temperature, and operation mode on DHE performance, using field data from
two geothermal wells (Well A: 3200m, 130.5$^{\circ}$C; Well B: 2500m,
103.3$^{\circ}$C). Results show that under an optimal condition (LC3: 50
m$^3$/h, 30$^{\circ}$C), Well A's heat extraction rate increased from 35% to
42%, with its outlet temperature rising from 15$^{\circ}$C to 20$^{\circ}$C. In
contrast, Well B's rate decreased from 15% to 5%. After one week of continuous
operation, the outlet temperature of Well A dropped from 55.7$^{\circ}$C to
16.5$^{\circ}$C, and Well B's from 68$^{\circ}$C to 17$^{\circ}$C. Adopting an
intermittent mode (16h operation, 8h shutdown daily) reduced the temperature
decay rate by approximately 10%. Based on these findings, we propose
optimization strategies: controlling flow rate to 35m$^3$/h, maintaining an
inlet temperature of 6--10$^{\circ}$C, and implementing intermittent
scheduling. This work provides guidance for the efficient design and
sustainable operation of DHE systems.

</details>
