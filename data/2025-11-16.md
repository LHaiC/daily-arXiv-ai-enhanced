<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 42]
- [cs.CL](#cs.CL) [Total: 64]
- [eess.SY](#eess.SY) [Total: 18]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.AI](#cs.AI) [Total: 56]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 17]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.DS](#cs.DS) [Total: 5]
- [quant-ph](#quant-ph) [Total: 48]
- [eess.SP](#eess.SP) [Total: 9]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.DC](#cs.DC) [Total: 10]
- [cs.AR](#cs.AR) [Total: 5]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.SI](#cs.SI) [Total: 4]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 33]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.RO](#cs.RO) [Total: 20]
- [cs.LG](#cs.LG) [Total: 101]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PriVi: Towards A General-Purpose Video Model For Primate Behavior In The Wild](https://arxiv.org/abs/2511.09675)
*Felix B. Mueller,Jan F. Meier,Timo Lueddecke,Richard Vogg,Roger L. Freixanet,Valentin Hassler,Tiffany Bosshard,Elif Karakoc,William J. O'Hearn,Sofia M. Pereira,Sandro Sehner,Kaja Wierucka,Judith Burkart,Claudia Fichtel,Julia Fischer,Alexander Gail,Catherine Hobaiter,Julia Ostner,Liran Samuni,Oliver Schülke,Neda Shahidi,Erin G. Wessling,Alexander S. Ecker*

Main category: cs.CV

TL;DR: 本研究提出了一种名为PriVi的大规模灵长类动物视频预训练数据集，并采用数据驱动的方法，通过在PriVi上预训练V-JEPA模型，显著提高了计算机视觉在灵长类行为分析中的泛化能力和数据效率，尤其在标签数据有限的情况下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉方法在分析非人灵长类动物行为时，依赖于以人类为中心预训练的模型和单一数据集，导致泛化能力受限。本研究旨在解决这一局限性，通过数据驱动的方法，构建灵长类动物专属的预训练数据集，以提升模型在该领域的应用效果。

Method: 构建了一个包含424小时视频的大规模灵长类动物视频数据集PriVi，该数据集结合了174小时的行为研究视频和250小时的网络视频。随后，在PriVi数据集上预训练V-JEPA模型，并使用轻量级冻结分类器在四个基准数据集（ChimpACT, BaboonLand, PanAf500, ChimpBehave）上进行评估。

Result: 在ChimpACT, BaboonLand, PanAf500, 和ChimpBehave四个基准数据集上，本研究提出的方法持续优于现有工作，包括完全微调的基线模型。并且，在标签数据较少的情况下，该方法仍表现出良好的性能和可扩展性。

Conclusion: 灵长类动物专属的预训练能够显著提高模型的数据效率和泛化能力，为标签数据有限的应用场景提供了有前景的解决方案。研究将公开代码、模型和大部分数据集。

Abstract: Non-human primates are our closest living relatives, and analyzing their behavior is central to research in cognition, evolution, and conservation. Computer vision could greatly aid this research, but existing methods often rely on human-centric pretrained models and focus on single datasets, which limits generalization. We address this limitation by shifting from a model-centric to a data-centric approach and introduce PriVi, a large-scale primate-centric video pretraining dataset. PriVi contains 424 hours of curated video, combining 174 hours from behavioral research across 11 settings with 250 hours of diverse web-sourced footage, assembled through a scalable data curation pipeline. We pretrain V-JEPA on PriVi to learn primate-specific representations and evaluate it using a lightweight frozen classifier. Across four benchmark datasets, ChimpACT, BaboonLand, PanAf500, and ChimpBehave, our approach consistently outperforms prior work, including fully finetuned baselines, and scales favorably with fewer labels. These results demonstrate that primate-centric pretraining substantially improves data efficiency and generalization, making it a promising approach for low-label applications. Code, models, and the majority of the dataset will be made available.

</details>


### [2] [Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression](https://arxiv.org/abs/2511.09702)
*Katie Matton,Purvaja Balaji,Hamzeh Ghasemzadeh,Jameson C. Cooper,Daryush D. Mehta,Jarrad H. Van Stan,Robert E. Hillman,Rosalind Picard,John Guttag,S. Mazdak Abulnaga*

Main category: cs.CV

TL;DR: 本研究提出了一种自动分类发声创伤严重程度的新方法，该方法采用序数回归框架并引入了软标签来处理标签不确定性，其性能接近临床专家水平。


<details>
  <summary>Details</summary>
Motivation: 发声创伤严重程度的评估目前依赖于临床医生的专家判断，这种方法成本高昂且可靠性差异大。因此，需要一种自动化的方法来评估发声创伤的严重程度。

Method: 提出了一种基于序数回归框架的改进方法，该方法能够处理软标签（反映注释者评分分布），以解决标签不确定性的问题。

Result: 该方法在预测性能上接近临床专家，并能提供可靠的不确定性估计。

Conclusion: 本研究提出的自动化工具能够对发声创伤严重程度进行评估，有望促进大规模发声创伤研究，最终改善临床认识和患者护理。

Abstract: Phonotrauma refers to vocal fold tissue damage resulting from exposure to forces during voicing. It occurs on a continuum from mild to severe, and treatment options can vary based on severity. Assessment of severity involves a clinician's expert judgment, which is costly and can vary widely in reliability. In this work, we present the first method for automatically classifying phonotrauma severity from vocal fold images. To account for the ordinal nature of the labels, we adopt a widely used ordinal regression framework. To account for label uncertainty, we propose a novel modification to ordinal regression loss functions that enables them to operate on soft labels reflecting annotator rating distributions. Our proposed soft ordinal regression method achieves predictive performance approaching that of clinical experts, while producing well-calibrated uncertainty estimates. By providing an automated tool for phonotrauma severity assessment, our work can enable large-scale studies of phonotrauma, ultimately leading to improved clinical understanding and patient care.

</details>


### [3] [PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model](https://arxiv.org/abs/2511.09724)
*Yunqian Cheng,Benjamin Princen,Roberto Manduchi*

Main category: cs.CV

TL;DR: PALMS+是一种基于图像的室内定位系统，通过3D点云重建和几何布局匹配来解决现有方法的局限性，并在各种数据集上表现出优越的定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 室内定位在GPS受限环境下至关重要，但现有基于视觉的方法（如PALMS）受到智能手机LiDAR射程短和室内布局歧义的限制。

Method: PALMS+系统首先利用基础单目深度估计模型（Depth Pro）从姿态RGB图像重建尺度对齐的3D点云，然后通过与建筑平面图进行卷积来实现几何布局匹配，输出位置和方向的后验概率。

Result: 在Structured3D和自定义校园数据集（包含80个观测值）上，PALMS+在静态定位精度上优于PALMS和F3Loc。在33个真实轨迹的序列定位中，PALMS+集成了粒子滤波器，其定位误差低于其他方法。

Conclusion: PALMS+通过其模块化、基于图像的方法，成功克服了现有室内定位技术的挑战，在静态和序列定位方面均表现出优越的性能，并证明了其在无需基础设施的室内应用中的潜力。

Abstract: Indoor localization in GPS-denied environments is crucial for applications like emergency response and assistive navigation. Vision-based methods such as PALMS enable infrastructure-free localization using only a floor plan and a stationary scan, but are limited by the short range of smartphone LiDAR and ambiguity in indoor layouts. We propose PALMS$+$, a modular, image-based system that addresses these challenges by reconstructing scale-aligned 3D point clouds from posed RGB images using a foundation monocular depth estimation model (Depth Pro), followed by geometric layout matching via convolution with the floor plan. PALMS$+$ outputs a posterior over the location and orientation, usable for direct or sequential localization. Evaluated on the Structured3D and a custom campus dataset consisting of 80 observations across four large campus buildings, PALMS$+$ outperforms PALMS and F3Loc in stationary localization accuracy -- without requiring any training. Furthermore, when integrated with a particle filter for sequential localization on 33 real-world trajectories, PALMS$+$ achieved lower localization errors compared to other methods, demonstrating robustness for camera-free tracking and its potential for infrastructure-free applications. Code and data are available at https://github.com/Head-inthe-Cloud/PALMS-Plane-based-Accessible-Indoor-Localization-Using-Mobile-Smartphones

</details>


### [4] [Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.09735)
*Ahmed Alia,Mohcine Chraibi,Armin Seyfried*

Main category: cs.CV

TL;DR: 通过引入新的动态占用空间损失函数，增强了Social LSTM模型，以解决真实行人轨迹预测中的碰撞问题，并在五种不同密度的合成数据集上进行了验证，结果显示该模型在降低碰撞率和提高预测精度方面优于基线和其他先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在行人轨迹预测中常将行人视为点，忽略了其占用的物理空间，导致在密集环境中容易发生碰撞，且未能有效处理不同密度和异构场景。本研究旨在解决这一问题，通过一个新颖的损失函数来提高模型预测的真实性和准确性。

Method: 提出了一种新颖的深度学习模型，通过增强Social LSTM并引入一个名为“动态占用空间损失”（Dynamic Occupied Space loss）的新损失函数。该损失函数结合了平均位移误差和一种对场景密度及个体空间占用敏感的新型碰撞惩罚项，以指导模型在预测过程中避免碰撞，同时不增加位移误差。模型在五种不同密度（低、中、高、极高均匀密度和异构密度）的合成数据集上进行了训练和评估。

Result: 在五种数据集上的实验结果表明，提出的模型显著降低了碰撞率（平均降低31%），并平均提高了5%的平均位移误差和6%的最终位移误差。此外，该模型在大多数测试集上均优于多个最先进的深度学习模型。

Conclusion: 本研究提出的增强型Social LSTM模型及其动态占用空间损失函数，能够有效解决行人轨迹预测中的碰撞问题，并在不同密度的场景下提高预测的准确性。实验结果证明了该方法在降低碰撞率和提高位移预测精度方面的优越性。

Abstract: In dynamic and crowded environments, realistic pedestrian trajectory prediction remains a challenging task due to the complex nature of human motion and the mutual influences among individuals. Deep learning models have recently achieved promising results by implicitly learning such patterns from 2D trajectory data. However, most approaches treat pedestrians as point entities, ignoring the physical space that each person occupies. To address these limitations, this paper proposes a novel deep learning model that enhances the Social LSTM with a new Dynamic Occupied Space loss function. This loss function guides Social LSTM in learning to avoid realistic collisions without increasing displacement error across different crowd densities, ranging from low to high, in both homogeneous and heterogeneous density settings. Such a function achieves this by combining the average displacement error with a new collision penalty that is sensitive to scene density and individual spatial occupancy. For efficient training and evaluation, five datasets were generated from real pedestrian trajectories recorded during the Festival of Lights in Lyon 2022. Four datasets represent homogeneous crowd conditions -- low, medium, high, and very high density -- while the fifth corresponds to a heterogeneous density distribution. The experimental findings indicate that the proposed model not only lowers collision rates but also enhances displacement prediction accuracy in each dataset. Specifically, the model achieves up to a 31% reduction in the collision rate and reduces the average displacement error and the final displacement error by 5% and 6%, respectively, on average across all datasets compared to the baseline. Moreover, the proposed model consistently outperforms several state-of-the-art deep learning models across most test sets.

</details>


### [5] [Soiling detection for Advanced Driver Assistance Systems](https://arxiv.org/abs/2511.09740)
*Filip Beránek,Václav Diviš,Ivan Gruber*

Main category: cs.CV

TL;DR: Soiling detection for automotive cameras is framed as a semantic segmentation task. A revised Woodscape dataset is introduced to address data leakage and annotation issues, enabling comparable results with a smaller dataset and faster processing.


<details>
  <summary>Details</summary>
Motivation: Soiling detection for automotive cameras is essential for the robustness of advanced driver assistance systems against environmental factors.

Method: The paper treats soiling detection as a semantic segmentation problem, compares various segmentation methods, and analyzes the Woodscape dataset, identifying and rectifying data leakage and annotation inaccuracies by creating a new, smaller data subset.

Result: Semantic segmentation methods outperform tile-level classification approaches. The new dataset subset allows for comparable results with reduced processing time.

Conclusion: Semantic segmentation is a viable approach for soiling detection. Addressing dataset issues in Woodscape is crucial for reliable model training and performance evaluation.

Abstract: Soiling detection for automotive cameras is a crucial part of advanced driver assistance systems to make them more robust to external conditions like weather, dust, etc. In this paper, we regard the soiling detection as a semantic segmentation problem. We provide a comprehensive comparison of popular segmentation methods and show their superiority in performance while comparing them to tile-level classification approaches. Moreover, we present an extensive analysis of the Woodscape dataset showing that the original dataset contains a data-leakage and imprecise annotations. To address these problems, we create a new data subset, which, despite being much smaller, provides enough information for the segmentation method to reach comparable results in a much shorter time. All our codes and dataset splits are available at https://github.com/filipberanek/woodscape_revision.

</details>


### [6] [Feature Quality and Adaptability of Medical Foundation Models: A Comparative Evaluation for Radiographic Classification and Segmentation](https://arxiv.org/abs/2511.09742)
*Frank Li,Theo Dapamede,Mohammadreza Chavoshi,Young Seok Jeon,Bardia Khosravi,Abdulhameed Dere,Beatrice Brown-Mulry,Rohan Satya Isaac,Aawez Mansuri,Chiratidzo Sanyika,Janice Newsome,Saptarshi Purkayastha,Imon Banerjee,Hari Trivedi,Judy Gichoya*

Main category: cs.CV

TL;DR: 医学领域预训练模型在医学影像分析中表现优于通用领域模型，但其有效性因任务而异，对于复杂病灶的精确定位仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 评估不同预训练域（医学 vs. 通用）、范式（如文本引导）和架构对医学影像嵌入质量的影响，以指导放射学任务中最佳编码器的选择。

Method: 在胸部X光片分析任务（包括分类和分割）上，评估了来自八个医学和通用领域基础模型的视觉编码器，并使用了线性探测和微调的基准测试方法。

Result: 医学领域预训练模型在嵌入质量上优于通用领域模型，尤其是在全局分类和显着解剖结构分割任务中。然而，对于需要精确定位复杂、细微病灶（如气胸）的任务，所有基础模型在未经大量微调的情况下表现不佳。基础模型在分类任务中会利用混淆捷径（如胸管用于气胸），这在分割任务中无效。图像编码（如RAD-DINO）和标签监督（如Ark+）模型表现优异，而昂贵的文本-图像对齐并非必需。有监督的端到端基线模型在分割任务上表现具有竞争力。

Conclusion: 虽然医学预训练模型有益，但架构选择（如多尺度）至关重要，预训练特征并非对所有任务都有效，特别是在需要精确定位的复杂任务上，有监督模型仍然是强有力的替代方案。

Abstract: Foundation models (FMs) promise to generalize medical imaging, but their effectiveness varies. It remains unclear how pre-training domain (medical vs. general), paradigm (e.g., text-guided), and architecture influence embedding quality, hindering the selection of optimal encoders for specific radiology tasks. To address this, we evaluate vision encoders from eight medical and general-domain FMs for chest X-ray analysis. We benchmark classification (pneumothorax, cardiomegaly) and segmentation (pneumothorax, cardiac boundary) using linear probing and fine-tuning. Our results show that domain-specific pre-training provides a significant advantage; medical FMs consistently outperformed general-domain models in linear probing, establishing superior initial feature quality. However, feature utility is highly task-dependent. Pre-trained embeddings were strong for global classification and segmenting salient anatomy (e.g., heart). In contrast, for segmenting complex, subtle pathologies (e.g., pneumothorax), all FMs performed poorly without significant fine-tuning, revealing a critical gap in localizing subtle disease. Subgroup analysis showed FMs use confounding shortcuts (e.g., chest tubes for pneumothorax) for classification, a strategy that fails for precise segmentation. We also found that expensive text-image alignment is not a prerequisite; image-only (RAD-DINO) and label-supervised (Ark+) FMs were among top performers. Notably, a supervised, end-to-end baseline remained highly competitive, matching or exceeding the best FMs on segmentation tasks. These findings show that while medical pre-training is beneficial, architectural choices (e.g., multi-scale) are critical, and pre-trained features are not universally effective, especially for complex localization tasks where supervised models remain a strong alternative.

</details>


### [7] [Gradient-Guided Exploration of Generative Model's Latent Space for Controlled Iris Image Augmentations](https://arxiv.org/abs/2511.09749)
*Mahsa Mitcheff,Siamul Karim Khan,Adam Czajka*

Main category: cs.CV

TL;DR: We introduce a novel iris image augmentation strategy using generative models to synthesize diverse iris images while preserving identity, enabling better iris recognition and presentation attack detection.


<details>
  <summary>Details</summary>
Motivation: Developing reliable iris recognition and presentation attack detection methods requires diverse datasets with realistic variations and anomalies. Synthesizing same-identity iris images with controlled attributes is challenging due to the rich texture of iris images.

Method: Our approach involves traversing a generative model's latent space to generate same-identity iris images with manipulated attributes. This traversal is guided by the gradient of specific iris image features (geometrical, textural, or quality-related) and preserves the original identity. The method can be extended to manipulate any attribute with a differentiable loss term and can use pre-trained GAN models or real-world images (via GAN inversion).

Result: The proposed approach allows for the synthesis of diverse iris images with controlled variations, which can be used to improve iris recognition and presentation attack detection systems.

Conclusion: This new iris image augmentation strategy effectively addresses the challenge of synthesizing controlled variations in iris images, offering a promising direction for enhancing iris recognition technologies.

Abstract: Developing reliable iris recognition and presentation attack detection methods requires diverse datasets that capture realistic variations in iris features and a wide spectrum of anomalies. Because of the rich texture of iris images, which spans a wide range of spatial frequencies, synthesizing same-identity iris images while controlling specific attributes remains challenging. In this work, we introduce a new iris image augmentation strategy by traversing a generative model's latent space toward latent codes that represent same-identity samples but with some desired iris image properties manipulated. The latent space traversal is guided by a gradient of specific geometrical, textural, or quality-related iris image features (e.g., sharpness, pupil size, iris size, or pupil-to-iris ratio) and preserves the identity represented by the image being manipulated. The proposed approach can be easily extended to manipulate any attribute for which a differentiable loss term can be formulated. Additionally, our approach can use either randomly generated images using either a pre-train GAN model or real-world iris images. We can utilize GAN inversion to project any given iris image into the latent space and obtain its corresponding latent code.

</details>


### [8] [Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/abs/2511.09809)
*Konstantinos M. Dafnis,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 该研究提出了一种名为STS（Spectrum-Aware Test-Time Steering）的轻量级视觉-语言模型（VLM）测试时自适应框架，以应对领域迁移问题。STS通过提取文本嵌入的谱子空间来定义语义方向，并学习在谱感知的情况下调整潜在表征，以最小化不同增强视图之间的熵。该方法在推理时在潜在空间中操作，无需反向传播或修改冻结的编码器，并且参数量少，速度快，内存占用小，在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）在零样本推理方面表现出色，但在测试时遇到领域迁移时性能会下降。虽然一些测试时自适应策略（如测试时提示调优）可以适应单个未标记图像，但它们通常需要反向传播或修改模型核心组件。

Method: STS框架通过提取文本嵌入的谱子空间来定义语义方向，并学习在谱感知的情况下调整潜在表征。它通过调整少量每样本的移位参数来最小化不同增强视图之间的熵。STS完全在推理时在潜在空间中操作，不涉及反向传播或修改冻结的编码器。

Result: 实验结果表明，STS在标准评估协议下，在很大程度上超越了最先进的测试时自适应方法，同时仅增加了少量参数，推理速度提高了8倍，内存占用减小了12倍。

Conclusion: STS是一种轻量级、高效的VLM测试时自适应框架，能够有效应对领域迁移问题，并且在性能、速度和内存占用方面均优于现有方法。

Abstract: Vision-Language Models (VLMs) excel at zero-shot inference but often degrade under test-time domain shifts. For this reason, episodic test-time adaptation strategies have recently emerged as powerful techniques for adapting VLMs to a single unlabeled image. However, existing adaptation strategies, such as test-time prompt tuning, typically require backpropagating through large encoder weights or altering core model components. In this work, we introduce Spectrum-Aware Test-Time Steering (STS), a lightweight adaptation framework that extracts a spectral subspace from the textual embeddings to define principal semantic directions and learns to steer latent representations in a spectrum-aware manner by adapting a small number of per-sample shift parameters to minimize entropy across augmented views. STS operates entirely at inference in the latent space, without backpropagation through or modification of the frozen encoders. Building on standard evaluation protocols, our comprehensive experiments demonstrate that STS largely surpasses or compares favorably against state-of-the-art test-time adaptation methods, while introducing only a handful of additional parameters and achieving inference speeds up to 8x faster with a 12x smaller memory footprint than conventional test-time prompt tuning. The code is available at https://github.com/kdafnis/STS.

</details>


### [9] [From Street to Orbit: Training-Free Cross-View Retrieval via Location Semantics and LLM Guidance](https://arxiv.org/abs/2511.09820)
*Jeongho Min,Dongyoung Kim,Jaehyup Lee*

Main category: cs.CV

TL;DR: 本研究提出了一种无需额外训练的跨视图图像检索框架，利用预训练的视觉编码器和大型语言模型（LLM），通过网络搜索和LLM进行地理线索提取，生成卫星图像查询，并使用DINOv2等模型进行匹配，在零样本设置下超越了现有方法，并能自动构建街景-卫星图像数据集。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图图像检索方法（尤其是街景到卫星图像匹配）通常需要监督训练和特定类型的图像（如全景图或无人机图像），这限制了其在现实世界中的应用。本研究旨在提供一种无需额外训练、适应性更强的解决方案。

Method: 1. 输入街景图像，提取地理线索。2. 利用网络搜索和LLM进行位置推断。3. 通过geocoding API生成对应的卫星图像查询。4. 使用预训练的视觉编码器（如DINOv2）和基于PCA的白化特征提纯技术进行街景和卫星图像的匹配检索。

Result: 在零样本设置下，本研究提出的方法在基准数据集上的表现优于先前的基于学习的方法，并且能够自动构建语义对齐的街景-卫星图像数据集，提供了比手动标注更具可扩展性和成本效益的替代方案。

Conclusion: 本研究提出的无需训练的跨视图图像检索框架，利用LLM和预训练的视觉模型，在街景到卫星图像匹配任务中展现出强大的零样本学习能力，并能自动化数据集构建，为相关应用提供了高效且易于部署的解决方案。

Abstract: Cross-view image retrieval, particularly street-to-satellite matching, is a critical task for applications such as autonomous navigation, urban planning, and localization in GPS-denied environments. However, existing approaches often require supervised training on curated datasets and rely on panoramic or UAV-based images, which limits real-world deployment. In this paper, we present a simple yet effective cross-view image retrieval framework that leverages a pretrained vision encoder and a large language model (LLM), requiring no additional training. Given a monocular street-view image, our method extracts geographic cues through web-based image search and LLM-based location inference, generates a satellite query via geocoding API, and retrieves matching tiles using a pretrained vision encoder (e.g., DINOv2) with PCA-based whitening feature refinement. Despite using no ground-truth supervision or finetuning, our proposed method outperforms prior learning-based approaches on the benchmark dataset under zero-shot settings. Moreover, our pipeline enables automatic construction of semantically aligned street-to-satellite datasets, which is offering a scalable and cost-efficient alternative to manual annotation. All source codes will be made publicly available at https://jeonghomin.github.io/street2orbit.github.io/.

</details>


### [10] [CertMask: Certifiable Defense Against Adversarial Patches via Theoretically Optimal Mask Coverage](https://arxiv.org/abs/2511.09834)
*Xuntao Lyu,Ching-Chi Lin,Abdullah Al Arafat,Georg von der Brüggen,Jian-Jia Chen,Zhishan Guo*

Main category: cs.CV

TL;DR: CertMask是一种可证明的鲁棒防御方法，通过生成一组二进制掩码来中和对抗性斑块攻击的效果，具有高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 对抗性斑块攻击能够绕过深度视觉模型，对现实世界的应用构成威胁。

Method: CertMask通过一种数学上严谨的覆盖策略，生成一组二进制掩码，确保每个可能的斑块位置至少被覆盖k次，从而实现一次掩码和O(n)的推理成本。

Result: 在ImageNet、ImageNette和CIFAR-10的实验中，CertMask比PatchCleanser的认证鲁棒准确率提高了+13.4%，同时保持了接近原始模型的准确率。

Conclusion: CertMask提供了一种比现有方法更高效、更鲁棒的防御对抗性斑块攻击的解决方案，并具有强大的理论保证。

Abstract: Adversarial patch attacks inject localized perturbations into images to mislead deep vision models. These attacks can be physically deployed, posing serious risks to real-world applications. In this paper, we propose CertMask, a certifiably robust defense that constructs a provably sufficient set of binary masks to neutralize patch effects with strong theoretical guarantees. While the state-of-the-art approach (PatchCleanser) requires two rounds of masking and incurs $O(n^2)$ inference cost, CertMask performs only a single round of masking with $O(n)$ time complexity, where $n$ is the cardinality of the mask set to cover an input image. Our proposed mask set is computed using a mathematically rigorous coverage strategy that ensures each possible patch location is covered at least $k$ times, providing both efficiency and robustness. We offer a theoretical analysis of the coverage condition and prove its sufficiency for certification. Experiments on ImageNet, ImageNette, and CIFAR-10 show that CertMask improves certified robust accuracy by up to +13.4\% over PatchCleanser, while maintaining clean accuracy nearly identical to the vanilla model.

</details>


### [11] [VLF-MSC: Vision-Language Feature-Based Multimodal Semantic Communication System](https://arxiv.org/abs/2511.10074)
*Gwangyeon Ahn,Jiwan Seo,Joonhyuk Kang*

Main category: cs.CV

TL;DR: VLF-MSC系统利用预训练的视觉-语言模型（VLM）将源图像编码为统一的视觉-语言特征（VLF），用于传输以支持接收端的图像和文本生成，提高了频谱效率和对信道噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有技术分别处理图像和文本，导致效率低下。本研究旨在提出一个统一的系统，能够利用单一的视觉-语言表示来支持图像和文本的生成。

Method: 利用预训练的视觉-语言模型（VLM）将源图像编码为视觉-语言特征（VLF），通过信道传输。接收端利用VLF分别条件化语言模型和扩散模型，生成文本和图像。

Result: VLF-MSC系统在低信噪比下实现了比纯文本和纯图像基线更高的语义准确性，同时显著减少了带宽，并提高了对信道噪声的鲁棒性。

Conclusion: VLF-MSC系统通过统一的视觉-语言特征表示，在提高频谱效率、适应性和鲁棒性方面优于现有方法，为多模态通信提供了一种有效的解决方案。

Abstract: We propose Vision-Language Feature-based Multimodal Semantic Communication (VLF-MSC), a unified system that transmits a single compact vision-language representation to support both image and text generation at the receiver. Unlike existing semantic communication techniques that process each modality separately, VLF-MSC employs a pre-trained vision-language model (VLM) to encode the source image into a vision-language semantic feature (VLF), which is transmitted over the wireless channel. At the receiver, a decoder-based language model and a diffusion-based image generator are both conditioned on the VLF to produce a descriptive text and a semantically aligned image. This unified representation eliminates the need for modality-specific streams or retransmissions, improving spectral efficiency and adaptability. By leveraging foundation models, the system achieves robustness to channel noise while preserving semantic fidelity. Experiments demonstrate that VLF-MSC outperforms text-only and image-only baselines, achieving higher semantic accuracy for both modalities under low SNR with significantly reduced bandwidth.

</details>


### [12] [VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction](https://arxiv.org/abs/2511.10203)
*Stephane Da Silva Martins,Emanuel Aldea,Sylvie Le Hégarat-Mascle*

Main category: cs.CV

TL;DR: VISTA是一个结合了长期目标和社交互动的多智能体轨迹预测模型，在MADRAS和SDD基准测试中取得了最先进的准确性和更少的碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在联合捕捉智能体的长期目标和细粒度社交互动方面存在不足，导致多智能体未来预测不切实际。

Method: 提出了一种递归的目标条件Transformer模型VISTA，该模型包含交叉注意力融合模块（整合长期意图和过去运动）、社交令牌注意力机制（灵活建模跨智能体交互）以及成对注意力图（使社交影响模式在推理时可解释）。

Result: VISTA在MADRAS和SDD基准测试中实现了最先进的准确性，并显著减少了碰撞。在MADRAS上，碰撞率从2.14%降至0.03%；在SDD上，实现了零碰撞，同时提高了ADE、FDE和minFDE指标。

Conclusion: VISTA能够生成符合社会规范、考虑目标并可解释的轨迹，有望应用于安全关键的自主系统。

Abstract: Multi-agent trajectory prediction is crucial for autonomous systems operating in dense, interactive environments. Existing methods often fail to jointly capture agents' long-term goals and their fine-grained social interactions, which leads to unrealistic multi-agent futures. We propose VISTA, a recursive goal-conditioned transformer for multi-agent trajectory forecasting. VISTA combines (i) a cross-attention fusion module that integrates long-horizon intent with past motion, (ii) a social-token attention mechanism for flexible interaction modeling across agents, and (iii) pairwise attention maps that make social influence patterns interpretable at inference time. Our model turns single-agent goal-conditioned prediction into a coherent multi-agent forecasting framework. Beyond standard displacement metrics, we evaluate trajectory collision rates as a measure of joint realism. On the high-density MADRAS benchmark and on SDD, VISTA achieves state-of-the-art accuracy and substantially fewer collisions. On MADRAS, it reduces the average collision rate of strong baselines from 2.14 to 0.03 percent, and on SDD it attains zero collisions while improving ADE, FDE, and minFDE. These results show that VISTA generates socially compliant, goal-aware, and interpretable trajectories, making it promising for safety-critical autonomous systems.

</details>


### [13] [MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2511.10376)
*Xun Huang,Shijia Zhao,Yunxiang Wang,Xin Lu,Wanfa Zhang,Rongsheng Qu,Weixin Li,Yunhong Wang,Chenglu Wen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为M3DSG的多模态3D场景图，用于机器人导航，解决了现有方法丢失视觉信息和词汇量受限的问题。基于M3DSG，研究者开发了MSGNav系统，通过关键子图选择、自适应词汇更新和闭环推理模块，实现了零样本导航。此外，还提出了一个基于可见性的视点决策模块来解决“最后一百米”问题。实验证明MSGNav在GOAT-Bench和HM3D-OVON数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本导航方法将视觉信息压缩为纯文本关系，导致视觉信息丢失、构建成本高昂且词汇量受限。为了解决这些问题，需要一种能够保留视觉线索并支持开放词汇泛化和低训练开销的方法。

Method: 提出多模态3D场景图（M3DSG），用动态分配的图像替换文本关系边，以保留视觉线索。在此基础上，开发了MSGNav零样本导航系统，包括用于高效推理的关键子图选择模块、用于开放词汇支持的自适应词汇更新模块和用于准确探索推理的闭环推理模块。此外，还提出了一个可见性视点决策模块来解决“最后一百米”问题。

Result: MSGNav在GOAT-Bench和HM3D-OVON数据集上实现了最先进的性能。

Conclusion: MSGNav通过引入M3DSG和一系列创新模块，在零样本导航方面取得了显著进展，有效地解决了现有方法的局限性，并在相关基准测试中取得了优异的表现。

Abstract: Embodied navigation is a fundamental capability for robotic agents operating. Real-world deployment requires open vocabulary generalization and low training overhead, motivating zero-shot methods rather than task-specific RL training. However, existing zero-shot methods that build explicit 3D scene graphs often compress rich visual observations into text-only relations, leading to high construction cost, irreversible loss of visual evidence, and constrained vocabularies. To address these limitations, we introduce the Multi-modal 3D Scene Graph (M3DSG), which preserves visual cues by replacing textual relational edges with dynamically assigned images. Built on M3DSG, we propose MSGNav, a zero-shot navigation system that includes a Key Subgraph Selection module for efficient reasoning, an Adaptive Vocabulary Update module for open vocabulary support, and a Closed-Loop Reasoning module for accurate exploration reasoning. Additionally, we further identify the last-mile problem in zero-shot navigation - determining the feasible target location with a suitable final viewpoint, and propose a Visibility-based Viewpoint Decision module to explicitly resolve it. Comprehensive experimental results demonstrate that MSGNav achieves state-of-the-art performance on GOAT-Bench and HM3D-OVON datasets. The open-source code will be publicly available.

</details>


### [14] [SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation](https://arxiv.org/abs/2511.10518)
*Wei Li,Renshan Zhang,Rui Shao,Zhijian Fang,Kaiwen Zhou,Zhuotao Tian,Liqiang Nie*

Main category: cs.CV

TL;DR: SemanticVLA通过语义对齐的稀疏化和增强来提高机器人操作的效率和性能，解决了感知冗余和浅层指令-视觉对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型在机器人操作方面存在感知冗余和浅层指令-视觉对齐的问题，阻碍了其实际应用。需要一种新的VLA框架来解决这些限制。

Method: 提出了一种名为SemanticVLA的新型VLA框架，它包含三个主要组件：1）语义引导的双视觉修剪器（SD-Pruner），包括指令驱动修剪器（ID-Pruner）和空间聚合修剪器（SA-Pruner），用于在保持语义对齐的同时去除冗余的感知信息。2）语义互补分层融合器（SH-Fuser），用于融合来自SigLIP和DINOv2的密集斑块和稀疏标记，以获得连贯的表示。3）语义条件动作耦合器（SA-Coupler），用于增强从感知到动作的转换，以实现更高效、更可解释的行为建模。

Result: 在模拟和真实世界的任务中进行了广泛的实验，结果表明SemanticVLA在性能和效率方面都达到了新的SOTA水平。与OpenVLA相比，SemanticVLA在LIBERO基准测试中的成功率提高了21.1%，同时将训练成本和推理延迟分别降低了3.0倍和2.7倍。

Conclusion: SemanticVLA通过其创新的SD-Pruner、SH-Fuser和SA-Coupler组件，有效地解决了机器人操作中的感知冗余和指令-视觉对齐问题，显著提高了性能和效率。该框架已在公开的模拟和真实世界任务中得到验证，并优于现有SOTA方法。

Abstract: Vision-Language-Action (VLA) models have advanced in robotic manipulation, yet practical deployment remains hindered by two key limitations: 1) perceptual redundancy, where irrelevant visual inputs are processed inefficiently, and 2) superficial instruction-vision alignment, which hampers semantic grounding of actions. In this paper, we propose SemanticVLA, a novel VLA framework that performs Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation. Specifically: 1) To sparsify redundant perception while preserving semantic alignment, Semantic-guided Dual Visual Pruner (SD-Pruner) performs: Instruction-driven Pruner (ID-Pruner) extracts global action cues and local semantic anchors in SigLIP; Spatial-aggregation Pruner (SA-Pruner) compacts geometry-rich features into task-adaptive tokens in DINOv2. 2) To exploit sparsified features and integrate semantics with spatial geometry, Semantic-complementary Hierarchical Fuser (SH-Fuser) fuses dense patches and sparse tokens across SigLIP and DINOv2 for coherent representation. 3) To enhance the transformation from perception to action, Semantic-conditioned Action Coupler (SA-Coupler) replaces the conventional observation-to-DoF approach, yielding more efficient and interpretable behavior modeling for manipulation tasks. Extensive experiments on simulation and real-world tasks show that SemanticVLA sets a new SOTA in both performance and efficiency. SemanticVLA surpasses OpenVLA on LIBERO benchmark by 21.1% in success rate, while reducing training cost and inference latency by 3.0-fold and 2.7-fold.SemanticVLA is open-sourced and publicly available at https://github.com/JiuTian-VL/SemanticVLA

</details>


### [15] [Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images](https://arxiv.org/abs/2511.09891)
*Jinfu Li,Yuqi Huang,Hong Song,Ting Wang,Jianghan Xia,Yucong Lin,Jingfan Fan,Jian Yang*

Main category: cs.CV

TL;DR: 现有的目标检测器在检测小目标时仍存在不足，本文提出了尺度感知中继层（SARL）和尺度自适应损失（SAL）来提升小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测器在检测小目标时存在特征信息不足、在网络传播中易丢失以及回归损失不均衡的问题。

Method: 提出尺度感知中继层（SARL），通过跨尺度空间通道注意力来丰富特征并增强跨层特征共享。提出尺度自适应损失（SAL），通过重塑IoU损失来降低大目标的权重，从而关注小目标。

Result: 在AI-TOD、DOTA-v2.0和VisDrone2019数据集上进行的大量实验表明，所提出的方法在YOLOv5和YOLOx基线上平均精度（AP）提升了5.5%。在真实世界噪声数据集AI-TOD-v2.0上，AP提升了29.0%。

Conclusion: SARL和SAL能够有效提升小目标检测的泛化能力和鲁棒性。

Abstract: Recently, despite the remarkable advancements in object detection, modern detectors still struggle to detect tiny objects in aerial images. One key reason is that tiny objects carry limited features that are inevitably degraded or lost during long-distance network propagation. Another is that smaller objects receive disproportionately greater regression penalties than larger ones during training. To tackle these issues, we propose a Scale-Aware Relay Layer (SARL) and a Scale-Adaptive Loss (SAL) for tiny object detection, both of which are seamlessly compatible with the top-performing frameworks. Specifically, SARL employs a cross-scale spatial-channel attention to progressively enrich the meaningful features of each layer and strengthen the cross-layer feature sharing. SAL reshapes the vanilla IoU-based losses so as to dynamically assign lower weights to larger objects. This loss is able to focus training on tiny objects while reducing the influence on large objects. Extensive experiments are conducted on three benchmarks (\textit{i.e.,} AI-TOD, DOTA-v2.0 and VisDrone2019), and the results demonstrate that the proposed method boosts the generalization ability by 5.5\% Average Precision (AP) when embedded in YOLOv5 (anchor-based) and YOLOx (anchor-free) baselines. Moreover, it also promotes the robust performance with 29.0\% AP on the real-world noisy dataset (\textit{i.e.,} AI-TOD-v2.0).

</details>


### [16] [Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning](https://arxiv.org/abs/2511.09893)
*Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon*

Main category: cs.CV

TL;DR: Swin-BART编码器-解码器系统结合轻量级区域注意力模块，在医学图像字幕生成任务上达到了最先进的语义保真度，同时保持紧凑和可解释性。


<details>
  <summary>Details</summary>
Motivation: 自动化医学图像字幕生成旨在将复杂的放射学图像转化为支持报告流程的诊断叙述。

Method: 使用Swin-BART编码器-解码器系统，并集成一个轻量级的区域注意力模块，该模块在交叉注意力之前增强了诊断上的显著区域。

Result: 在ROCO数据集上训练和评估，所提出的模型在ROUGE和BERTScore指标上优于基线模型，同时在BLEU、CIDEr和METEOR指标上也具有竞争力。具体而言，ROUGE得分从0.356和0.255提高到0.603，BERTScore得分从0.623和0.645提高到0.807。

Conclusion: 所提出的设计能够生成准确、临床措辞的字幕，并提供透明的区域归因，通过人工干预支持安全的研发展望。

Abstract: Automated medical image captioning translates complex radiological images into diagnostic narratives that can support reporting workflows. We present a Swin-BART encoder-decoder system with a lightweight regional attention module that amplifies diagnostically salient regions before cross-attention. Trained and evaluated on ROCO, our model achieves state-of-the-art semantic fidelity while remaining compact and interpretable. We report results as mean$\pm$std over three seeds and include $95\%$ confidence intervals. Compared with baselines, our approach improves ROUGE (proposed 0.603, ResNet-CNN 0.356, BLIP2-OPT 0.255) and BERTScore (proposed 0.807, BLIP2-OPT 0.645, ResNet-CNN 0.623), with competitive BLEU, CIDEr, and METEOR. We further provide ablations (regional attention on/off and token-count sweep), per-modality analysis (CT/MRI/X-ray), paired significance tests, and qualitative heatmaps that visualize the regions driving each description. Decoding uses beam search (beam size $=4$), length penalty $=1.1$, $no\_repeat\_ngram\_size$ $=3$, and max length $=128$. The proposed design yields accurate, clinically phrased captions and transparent regional attributions, supporting safe research use with a human in the loop.

</details>


### [17] [Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers](https://arxiv.org/abs/2511.09926)
*Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi*

Main category: cs.CV

TL;DR: SeqFT易受分布漂移影响，导致模型性能随时间下降。为解决此问题，本文提出SLDC，通过引入潜在空间转移算子来对齐任务间的特征分布，以减轻漂移影响。SLDC包含线性变体和弱非线性变体，并结合知识蒸馏（KD）进一步减少表示漂移。实验证明，SLDC显著提升了SeqFT的性能，结合KD的SLDC模型性能可与联合训练相媲美。


<details>
  <summary>Details</summary>
Motivation: SeqFT方法在类别增量学习（CIL）中虽然有效，但容易受到分布漂移的影响，导致模型性能下降。

Method: 提出了一种潜在空间转移算子，并在此基础上设计了SLDC（Sequential Learning with Drift Compensation）算法。SLDC包含一个线性变体（通过求解正则化最小二乘问题学习线性算子）和一个弱非线性变体（使用可学习的弱非线性映射）。同时，在两个变体中都应用了知识蒸馏（KD）来减少表示漂移。

Result: 在标准的CIL基准测试上进行了大量实验，结果表明SLDC显著提高了SeqFT的性能。结合KD的SLDC方法在所有评估的数据集上都达到了与联合训练相当的性能。

Conclusion: SLDC通过补偿分布漂移和利用KD减少表示漂移，有效解决了SeqFT在CIL任务中遇到的性能下降问题，并能达到接近联合训练的效果。

Abstract: Recent advances have shown that sequential fine-tuning (SeqFT) of pre-trained vision transformers (ViTs), followed by classifier refinement using approximate distributions of class features, can be an effective strategy for class-incremental learning (CIL). However, this approach is susceptible to distribution drift, caused by the sequential optimization of shared backbone parameters. This results in a mismatch between the distributions of the previously learned classes and that of the updater model, ultimately degrading the effectiveness of classifier performance over time. To address this issue, we introduce a latent space transition operator and propose Sequential Learning with Drift Compensation (SLDC). SLDC aims to align feature distributions across tasks to mitigate the impact of drift. First, we present a linear variant of SLDC, which learns a linear operator by solving a regularized least-squares problem that maps features before and after fine-tuning. Next, we extend this with a weakly nonlinear SLDC variant, which assumes that the ideal transition operator lies between purely linear and fully nonlinear transformations. This is implemented using learnable, weakly nonlinear mappings that balance flexibility and generalization. To further reduce representation drift, we apply knowledge distillation (KD) in both algorithmic variants. Extensive experiments on standard CIL benchmarks demonstrate that SLDC significantly improves the performance of SeqFT. Notably, by combining KD to address representation drift with SLDC to compensate distribution drift, SeqFT achieves performance comparable to joint training across all evaluated datasets. Code: https://github.com/raoxuan98-hash/sldc.git.

</details>


### [18] [AdaptViG: Adaptive Vision GNN with Exponential Decay Gating](https://arxiv.org/abs/2511.09942)
*Mustafa Munir,Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: AdaptViG 是一种高效的混合视觉 GNN，通过自适应图卷积（包括静态轴向支架和动态指数衰减门控）解决了 ViG 的计算挑战，并在早期阶段使用门控机制，在后期使用全局注意力机制，在准确性和效率之间取得了新的最优平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的 Vision Graph Neural Networks (ViGs) 在图构建阶段存在显著的计算挑战，影响了它们的效率。需要一种更有效的方法来提高 ViGs 的性能。

Method: 提出了一种名为自适应图卷积的新颖图构建机制，该机制结合了高效的静态轴向支架和动态的、基于内容的指数衰减门控策略，该策略根据特征相似性选择性地加权长距离连接。AdaptViG 采用混合策略，在早期阶段使用门控机制，在最后阶段使用全局注意力块。

Result: AdaptViG-M 在 ImageNet 上达到了 82.6% 的 top-1 准确率，参数量和 GMACs 分别减少了 80% 和 84%，优于 ViG-B。在下游任务中，AdaptViG-M 在 mIoU、APbox 和 APmask 指标上均优于更大的 EfficientFormer-L7，参数量减少了 78%。

Conclusion: AdaptViG 在准确性和效率之间取得了新的最优点，在视觉 GNN 领域树立了新的最优点。

Abstract: Vision Graph Neural Networks (ViGs) offer a new direction for advancements in vision architectures. While powerful, ViGs often face substantial computational challenges stemming from their graph construction phase, which can hinder their efficiency. To address this issue we propose AdaptViG, an efficient and powerful hybrid Vision GNN that introduces a novel graph construction mechanism called Adaptive Graph Convolution. This mechanism builds upon a highly efficient static axial scaffold and a dynamic, content-aware gating strategy called Exponential Decay Gating. This gating mechanism selectively weighs long-range connections based on feature similarity. Furthermore, AdaptViG employs a hybrid strategy, utilizing our efficient gating mechanism in the early stages and a full Global Attention block in the final stage for maximum feature aggregation. Our method achieves a new state-of-the-art trade-off between accuracy and efficiency among Vision GNNs. For instance, our AdaptViG-M achieves 82.6% top-1 accuracy, outperforming ViG-B by 0.3% while using 80% fewer parameters and 84% fewer GMACs. On downstream tasks, AdaptViG-M obtains 45.8 mIoU, 44.8 APbox, and 41.1 APmask, surpassing the much larger EfficientFormer-L7 by 0.7 mIoU, 2.2 APbox, and 2.1 APmask, respectively, with 78% fewer parameters.

</details>


### [19] [Beyond Cosine Similarity Magnitude-Aware CLIP for No-Reference Image Quality Assessment](https://arxiv.org/abs/2511.09948)
*Zhicheng Liao,Dongxu Wu,Zhenshan Shi,Sijie Mai,Hanwei Zhu,Lingyu Zhu,Yuncheng Jiang,Baoliang Chen*

Main category: cs.CV

TL;DR: CLIP模型在图像质量评估中，除了利用语义相似性，还可通过分析图像特征的幅度来提升评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的图像质量评估方法主要依赖于语义相似性，忽略了图像特征幅度这一与感知质量高度相关的线索。

Method: 提出一种新颖的自适应融合框架，结合余弦相似性和幅度感知质量线索。具体包括：提取CLIP图像特征的绝对值，并进行Box-Cox变换进行统计归一化；设计一种置信度引导的融合方案，自适应地调整两个线索的权重。

Result: 在多个基准IQA数据集上进行了广泛的实验，结果表明该方法在没有任务特定训练的情况下，持续优于标准的CLIP基IQA方法和最先进的基线方法。

Conclusion: 通过引入幅度感知质量线索和自适应融合框架，可以有效提升基于CLIP的图像质量评估的性能。

Abstract: Recent efforts have repurposed the Contrastive Language-Image Pre-training (CLIP) model for No-Reference Image Quality Assessment (NR-IQA) by measuring the cosine similarity between the image embedding and textual prompts such as "a good photo" or "a bad photo." However, this semantic similarity overlooks a critical yet underexplored cue: the magnitude of the CLIP image features, which we empirically find to exhibit a strong correlation with perceptual quality. In this work, we introduce a novel adaptive fusion framework that complements cosine similarity with a magnitude-aware quality cue. Specifically, we first extract the absolute CLIP image features and apply a Box-Cox transformation to statistically normalize the feature distribution and mitigate semantic sensitivity. The resulting scalar summary serves as a semantically-normalized auxiliary cue that complements cosine-based prompt matching. To integrate both cues effectively, we further design a confidence-guided fusion scheme that adaptively weighs each term according to its relative strength. Extensive experiments on multiple benchmark IQA datasets demonstrate that our method consistently outperforms standard CLIP-based IQA and state-of-the-art baselines, without any task-specific training.

</details>


### [20] [Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models](https://arxiv.org/abs/2511.09973)
*Satoshi Suzuki,Shin'ya Yamaguchi,Shoichiro Takeda,Taiga Yamane,Naoki Makishima,Naotaka Kawata,Mana Ihori,Tomohiro Tanaka,Shota Orihashi,Ryo Masumura*

Main category: cs.CV

TL;DR: 本文提出了一种名为Difference Vector Equalization (DiVE)的新方法，用于在不损害模型泛化能力的情况下，对预训练的视觉-语言模型进行鲁棒的微调。DiVE通过约束不同数据样本的嵌入差异向量来保持嵌入空间的几何结构，从而在ID、OOD和零样本任务上都取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒微调方法在微调过程中会破坏视觉-语言模型嵌入空间的几何结构，导致其在OOD和零样本场景下的泛化能力下降。

Method: 提出Difference Vector Equalization (DiVE)方法，通过约束同一数据样本在预训练模型和微调模型中提取的嵌入之间的差异向量来保持几何结构。引入平均向量损失(AVL)和成对向量损失(PVL)来实现这一目标。AVL从全局上保持几何结构，PVL从局部上确保多模态对齐的一致性。

Result: DiVE能够有效保持嵌入空间的几何结构，并在ID、OOD和零样本指标上取得了强大的结果。

Conclusion: DiVE是一种有效的鲁棒微调方法，能够保留预训练视觉-语言模型的泛化能力。

Abstract: Contrastive pre-trained vision-language models, such as CLIP, demonstrate strong generalization abilities in zero-shot classification by leveraging embeddings extracted from image and text encoders. This paper aims to robustly fine-tune these vision-language models on in-distribution (ID) data without compromising their generalization abilities in out-of-distribution (OOD) and zero-shot settings. Current robust fine-tuning methods tackle this challenge by reusing contrastive learning, which was used in pre-training, for fine-tuning. However, we found that these methods distort the geometric structure of the embeddings, which plays a crucial role in the generalization of vision-language models, resulting in limited OOD and zero-shot performance. To address this, we propose Difference Vector Equalization (DiVE), which preserves the geometric structure during fine-tuning. The idea behind DiVE is to constrain difference vectors, each of which is obtained by subtracting the embeddings extracted from the pre-trained and fine-tuning models for the same data sample. By constraining the difference vectors to be equal across various data samples, we effectively preserve the geometric structure. Therefore, we introduce two losses: average vector loss (AVL) and pairwise vector loss (PVL). AVL preserves the geometric structure globally by constraining difference vectors to be equal to their weighted average. PVL preserves the geometric structure locally by ensuring a consistent multimodal alignment. Our experiments demonstrate that DiVE effectively preserves the geometric structure, achieving strong results across ID, OOD, and zero-shot metrics.

</details>


### [21] [MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging](https://arxiv.org/abs/2511.10013)
*Shufeng Kong,Zijie Wang,Nuan Cui,Hao Tang,Yihan Meng,Yuanyuan Wei,Feifan Chen,Yingheng Wang,Zhuo Cai,Yaonan Wang,Yulong Zhang,Yuzheng Li,Zibin Zheng,Caihua Liu*

Main category: cs.CV

TL;DR: MIRNet是一个结合自监督学习和约束图推理的医学图像分析新框架，在舌象诊断领域取得了最先进的性能，并易于推广到其他医学成像任务。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像解释中的视觉-语义关系建模、标注稀疏性、标签不平衡和临床合理性约束问题，特别是在舌象诊断这一细粒度要求高的领域。

Method: 1. 使用自监督掩码自编码器（MAE）从无标签数据中学习视觉表征。2. 利用图注意力网络（GAT）通过专家定义的结构化图来建模标签相关性。3. 通过约束感知优化（KL散度和正则化损失）强制执行临床先验。4. 使用不对称损失（ASL）和提升集成来缓解不平衡问题。5. 引入TongueAtlas-4K数据集（4000张图像，22个诊断标签）以解决标注稀疏性问题。

Result: 在舌象诊断任务中实现了最先进的性能。

Conclusion: MIRNet框架在舌象诊断任务中表现出色，并且可以推广到更广泛的医学成像诊断任务。

Abstract: Automated interpretation of medical images demands robust modeling of complex visual-semantic relationships while addressing annotation scarcity, label imbalance, and clinical plausibility constraints. We introduce MIRNet (Medical Image Reasoner Network), a novel framework that integrates self-supervised pre-training with constrained graph-based reasoning. Tongue image diagnosis is a particularly challenging domain that requires fine-grained visual and semantic understanding. Our approach leverages self-supervised masked autoencoder (MAE) to learn transferable visual representations from unlabeled data; employs graph attention networks (GAT) to model label correlations through expert-defined structured graphs; enforces clinical priors via constraint-aware optimization using KL divergence and regularization losses; and mitigates imbalance using asymmetric loss (ASL) and boosting ensembles. To address annotation scarcity, we also introduce TongueAtlas-4K, a comprehensive expert-curated benchmark comprising 4,000 images annotated with 22 diagnostic labels--representing the largest public dataset in tongue analysis. Validation shows our method achieves state-of-the-art performance. While optimized for tongue diagnosis, the framework readily generalizes to broader diagnostic medical imaging tasks.

</details>


### [22] [Anomagic: Crossmodal Prompt-driven Zero-shot Anomaly Generation](https://arxiv.org/abs/2511.10020)
*Yuxin Jiang,Wei Luo,Hui Zhang,Qiyu Chen,Haiming Yao,Weiming Shen,Yunkang Cao*

Main category: cs.CV

TL;DR: Anomagic是一种零样本异常检测方法，它利用跨模态提示编码方案统一视觉和文本线索，通过基于inpainting的生成流程来生成语义一致的异常，无需任何样本异常。通过对比度精炼策略，它可以提高下游异常检测的准确性。此外，Anomagic还引入了AnomVerse数据集，并展示了其生成真实、多样化异常以及为任何正常图像生成异常的通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有的异常检测方法在生成语义一致的异常时，通常需要大量的样本异常，这在实际应用中难以获得。因此，需要一种无需样本异常即可生成高质量异常的方法。

Method: Anomagic首先通过跨模态提示编码方案融合视觉和文本信息，然后利用inpainting技术生成异常。随后，采用对比度精炼策略来精确匹配生成的异常和掩码，以提高检测精度。为了支持模型的训练，研究人员构建了AnomVerse数据集，其中包含12,987个异常-掩码-描述三元组。

Result: Anomagic在AnomVerse数据集上训练后，能够生成比现有方法更真实、更多样化的异常，并在下游异常检测任务中取得了显著的性能提升。此外，Anomagic还可以根据用户定义的提示为任何正常图像生成异常。

Conclusion: Anomagic是一种创新的零样本异常检测方法，它通过结合视觉和文本信息，有效地生成了语义一致且逼真的异常，无需任何样本异常。所提出的AnomVerse数据集和对比度精炼策略进一步增强了方法的性能和通用性，使其在各种异常检测场景中具有广泛的应用前景。

Abstract: We propose Anomagic, a zero-shot anomaly generation method that produces semantically coherent anomalies without requiring any exemplar anomalies. By unifying both visual and textual cues through a crossmodal prompt encoding scheme, Anomagic leverages rich contextual information to steer an inpainting-based generation pipeline. A subsequent contrastive refinement strategy enforces precise alignment between synthesized anomalies and their masks, thereby bolstering downstream anomaly detection accuracy. To facilitate training, we introduce AnomVerse, a collection of 12,987 anomaly-mask-caption triplets assembled from 13 publicly available datasets, where captions are automatically generated by multimodal large language models using structured visual prompts and template-based textual hints. Extensive experiments demonstrate that Anomagic trained on AnomVerse can synthesize more realistic and varied anomalies than prior methods, yielding superior improvements in downstream anomaly detection. Furthermore, Anomagic can generate anomalies for any normal-category image using user-defined prompts, establishing a versatile foundation model for anomaly generation.

</details>


### [23] [Multivariate Gaussian Representation Learning for Medical Action Evaluation](https://arxiv.org/abs/2511.10060)
*Luming Yang,Haoxian Liu,Siqing Li,Alper Yilmaz*

Main category: cs.CV

TL;DR: 我们提出了CPREval-6k数据集和GaussMedAct框架，以解决细粒度医学动作评估的挑战。GaussMedAct使用多变量高斯编码和混合空间编码，实现了高精度和实时推理，并在跨数据集实验中表现出优越的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学领域的细粒度动作评估面临数据不全、精度要求高、以及快速动作时空动态建模不足等挑战。

Method: 提出GaussMedAct框架，采用多变量高斯表示将动作分解为自适应3D高斯，并通过混合空间编码（笛卡尔和向量双流）利用骨骼信息。

Result: 在CPREval-6k基准上实现了92.1%的Top-1准确率，实时推理，并且比ST-GCN基线高出5.9%的准确率，计算量仅为10%。跨数据集实验也证明了该方法的鲁棒性。

Conclusion: CPREval-6k数据集和GaussMedAct框架为医学动作分析提供了有效的解决方案，并在准确性、效率和鲁棒性方面取得了显著进展。

Abstract: Fine-grained action evaluation in medical vision faces unique challenges due to the unavailability of comprehensive datasets, stringent precision requirements, and insufficient spatiotemporal dynamic modeling of very rapid actions. To support development and evaluation, we introduce CPREval-6k, a multi-view, multi-label medical action benchmark containing 6,372 expert-annotated videos with 22 clinical labels. Using this dataset, we present GaussMedAct, a multivariate Gaussian encoding framework, to advance medical motion analysis through adaptive spatiotemporal representation learning. Multivariate Gaussian Representation projects the joint motions to a temporally scaled multi-dimensional space, and decomposes actions into adaptive 3D Gaussians that serve as tokens. These tokens preserve motion semantics through anisotropic covariance modeling while maintaining robustness to spatiotemporal noise. Hybrid Spatial Encoding, employing a Cartesian and Vector dual-stream strategy, effectively utilizes skeletal information in the form of joint and bone features. The proposed method achieves 92.1% Top-1 accuracy with real-time inference on the benchmark, outperforming the ST-GCN baseline by +5.9% accuracy with only 10% FLOPs. Cross-dataset experiments confirm the superiority of our method in robustness.

</details>


### [24] [Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation](https://arxiv.org/abs/2511.10136)
*Mayank Vatsa,Aparna Bharati,Richa Singh*

Main category: cs.CV

TL;DR: 现有文生图模型在处理逻辑组合（如否定、计数、空间关系）时存在缺陷，导致性能显著下降，且现有解决方案和简单扩展无法解决此问题。


<details>
  <summary>Details</summary>
Motivation: 分析现有文生图模型在处理逻辑组合时的固有缺陷，并探究其失败原因。

Method: 调查了否定、计数和空间关系这三个核心原语的性能崩溃情况，并追溯了模型失败的三个关键因素：训练数据缺乏显式否定、连续注意力机制不适用于离散逻辑以及评估指标偏重视觉可信度而非约束满足。

Result: 模型在单独处理原语时准确率高，但在组合使用时性能急剧下降，存在严重的干扰。训练数据中几乎完全不存在显式否定，连续注意力架构不适合离散逻辑，评估指标优先考虑视觉效果而非约束满足。

Conclusion: 要实现真正的组合性，需要对表示和推理进行根本性改进，而不是仅仅对现有架构进行增量调整。

Abstract: The architectural blueprint of today's leading text-to-image models contains a fundamental flaw: an inability to handle logical composition. This survey investigates this breakdown across three core primitives-negation, counting, and spatial relations. Our analysis reveals a dramatic performance collapse: models that are accurate on single primitives fail precipitously when these are combined, exposing severe interference. We trace this failure to three key factors. First, training data show a near-total absence of explicit negations. Second, continuous attention architectures are fundamentally unsuitable for discrete logic. Third, evaluation metrics reward visual plausibility over constraint satisfaction. By analyzing recent benchmarks and methods, we show that current solutions and simple scaling cannot bridge this gap. Achieving genuine compositionality, we conclude, will require fundamental advances in representation and reasoning rather than incremental adjustments to existing architectures.

</details>


### [25] [GEA: Generation-Enhanced Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2511.10154)
*Hao Zou,Runqing Zhang,Xue Zhou,Jianxiao Zou*

Main category: cs.CV

TL;DR: 生成式方法 GEA 通过引入生成图像来增强文本到图像的 person 检索的跨模态对齐，解决了文本描述不准确和模态间隙问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像 person 检索（TIPR）方法存在文本描述不准确、跨模态对齐差以及数据集过拟合等问题，文本和图像的模态间隙进一步加剧了这些挑战。

Method: 提出生成增强对齐（GEA）方法，包含两个模块：1. 文本引导令牌增强（TGTE），引入扩散生成的图像作为中间语义表示，以缩小文本和视觉模式的差距。2. 生成中间融合（GIF），结合生成图像、原始图像和文本特征之间的交叉注意力，通过三元组对齐损失生成统一表示。

Result: 在 CUHK-PEDES、RSTPReid 和 ICFG-PEDES 三个公共 TIPR 数据集上进行了广泛的实验评估，结果证明了 GEA 方法的有效性。

Conclusion: GEA 方法通过生成式方法有效解决了 TIPR 中的跨模态对齐问题和模态间隙问题，并在多个数据集上取得了良好的效果。

Abstract: Text-to-Image Person Retrieval (TIPR) aims to retrieve person images based on natural language descriptions. Although many TIPR methods have achieved promising results, sometimes textual queries cannot accurately and comprehensively reflect the content of the image, leading to poor cross-modal alignment and overfitting to limited datasets. Moreover, the inherent modality gap between text and image further amplifies these issues, making accurate cross-modal retrieval even more challenging. To address these limitations, we propose the Generation-Enhanced Alignment (GEA) from a generative perspective. GEA contains two parallel modules: (1) Text-Guided Token Enhancement (TGTE), which introduces diffusion-generated images as intermediate semantic representations to bridge the gap between text and visual patterns. These generated images enrich the semantic representation of text and facilitate cross-modal alignment. (2) Generative Intermediate Fusion (GIF), which combines cross-attention between generated images, original images, and text features to generate a unified representation optimized by triplet alignment loss. We conduct extensive experiments on three public TIPR datasets, CUHK-PEDES, RSTPReid, and ICFG-PEDES, to evaluate the performance of GEA. The results justify the effectiveness of our method. More implementation details and extended results are available at https://github.com/sugelamyd123/Sup-for-GEA.

</details>


### [26] [Utilizing a Geospatial Foundation Model for Coastline Delineation in Small Sandy Islands](https://arxiv.org/abs/2511.10177)
*Tishya Chhabra,Manisha Bajpai,Walter Zesk,Skylar Tibbits*

Main category: cs.CV

TL;DR: NASA和IBM的Prithvi-EO-2.0地理空间基础模型在马尔代夫小沙岛的海岸线描绘方面表现出强大的迁移学习能力，即使使用少量数据也能实现高精度。


<details>
  <summary>Details</summary>
Motivation: 评估NASA和IBM的Prithvi-EO-2.0地理空间基础模型在利用卫星图像进行小沙岛海岸线描绘方面的性能。

Method: 我们创建并标注了一个包含225张多光谱图像的数据集，并公开发布。我们对Prithvi的300M和600M参数版本在不同大小的训练集（5到181张图像）上进行了微调。

Result: 实验表明，即使仅使用5张训练图像，Prithvi模型也能达到很高的性能（F1得分为0.94，IoU得分为0.79）。

Conclusion: Prithvi模型强大的迁移学习能力表明，这类模型有潜力支持数据贫乏地区的海滨监测。

Abstract: We present an initial evaluation of NASA and IBM's Prithvi-EO-2.0 geospatial foundation model on shoreline delineation of small sandy islands using satellite images. We curated and labeled a dataset of 225 multispectral images of two Maldivian islands, which we publicly release, and fine-tuned both the 300M and 600M parameter versions of Prithvi on training subsets ranging from 5 to 181 images. Our experiments show that even with as few as 5 training images, the models achieve high performance (F1 of 0.94, IoU of 0.79). Our results demonstrate the strong transfer learning capability of Prithvi, underscoring the potential of such models to support coastal monitoring in data-poor regions.

</details>


### [27] [FineSkiing: A Fine-grained Benchmark for Skiing Action Quality Assessment](https://arxiv.org/abs/2511.10250)
*Yongji Zhang,Siqi Li,Yue Gao,Yu Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为JudgeMind的新型动作质量评估（AQA）方法，并通过构建包含空中滑雪动作精细分项和扣分注释的数据集来解决现有AQA方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有AQA方法主要基于从整个视频中提取的特征进行评分，这导致可解释性和可靠性有限。此外，现有的AQA数据集缺乏动作评分的精细注释，尤其是在扣分项和分项注释方面。

Method: JudgeMind方法将输入的动作视频分割成不同的阶段，并对每个阶段进行评分以提高准确性。该方法还提出了一种阶段感知特征增强和融合模块，以增强对特定阶段关键区域的感知能力，并提高对由于频繁相机视点切换引起的视觉变化的鲁棒性。此外，还提出了一种基于知识的、与评分级别相关的解码器，以纳入可能的扣分项作为先验知识，从而预测更准确、更可靠的分数。

Result: 实验结果表明，所提出的方法在空中滑雪动作质量评估方面取得了最先进的性能。

Conclusion: JudgeMind方法通过模拟专业裁判的判罚和评分思维，显著提高了AQA的性能和可靠性，并解决了现有数据集和方法的局限性。

Abstract: Action Quality Assessment (AQA) aims to evaluate and score sports actions, which has attracted widespread interest in recent years. Existing AQA methods primarily predict scores based on features extracted from the entire video, resulting in limited interpretability and reliability. Meanwhile, existing AQA datasets also lack fine-grained annotations for action scores, especially for deduction items and sub-score annotations. In this paper, we construct the first AQA dataset containing fine-grained sub-score and deduction annotations for aerial skiing, which will be released as a new benchmark. For the technical challenges, we propose a novel AQA method, named JudgeMind, which significantly enhances performance and reliability by simulating the judgment and scoring mindset of professional referees. Our method segments the input action video into different stages and scores each stage to enhance accuracy. Then, we propose a stage-aware feature enhancement and fusion module to boost the perception of stage-specific key regions and enhance the robustness to visual changes caused by frequent camera viewpoints switching. In addition, we propose a knowledge-based grade-aware decoder to incorporate possible deduction items as prior knowledge to predict more accurate and reliable scores. Experimental results demonstrate that our method achieves state-of-the-art performance.

</details>


### [28] [H3Former: Hypergraph-based Semantic-Aware Aggregation via Hyperbolic Hierarchical Contrastive Loss for Fine-Grained Visual Classification](https://arxiv.org/abs/2511.10260)
*Yongji Zhang,Siqi Li,Kuiyang Huang,Yue Gao,Yu Jiang*

Main category: cs.CV

TL;DR: H3Former是一个新颖的token到region框架，利用高阶语义关系来聚合局部细粒度表示和结构化region级建模，以解决细粒度视觉分类（FGVC）中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的FGVC方法依赖于特征选择或区域建议策略来定位判别性区域，但这些方法可能无法全面捕捉判别性线索，并引入大量与类别无关的冗余。H3Former旨在解决这些限制。

Method: H3Former提出了一种名为SAAM（Semantic-Aware Aggregation Module）的模块，该模块利用多尺度上下文线索在token之间动态构建加权超图，并通过超图卷积捕获高阶语义依赖性，逐步将token特征聚合为紧凑的region级表示。此外，还提出了HHCL（Hyperbolic Hierarchical Contrastive Loss），在非欧几里得嵌入空间中强制执行分层语义约束，以增强类间可分离性和类内一致性。

Result: 在四个标准的FGVC基准测试中进行了全面的实验，证明了H3Former框架的优越性。

Conclusion: H3Former通过利用高阶语义关系和超图卷积，结合双曲分层对比损失，在细粒度视觉分类任务上取得了优于现有方法的性能。

Abstract: Fine-Grained Visual Classification (FGVC) remains a challenging task due to subtle inter-class differences and large intra-class variations. Existing approaches typically rely on feature-selection mechanisms or region-proposal strategies to localize discriminative regions for semantic analysis. However, these methods often fail to capture discriminative cues comprehensively while introducing substantial category-agnostic redundancy. To address these limitations, we propose H3Former, a novel token-to-region framework that leverages high-order semantic relations to aggregate local fine-grained representations with structured region-level modeling. Specifically, we propose the Semantic-Aware Aggregation Module (SAAM), which exploits multi-scale contextual cues to dynamically construct a weighted hypergraph among tokens. By applying hypergraph convolution, SAAM captures high-order semantic dependencies and progressively aggregates token features into compact region-level representations. Furthermore, we introduce the Hyperbolic Hierarchical Contrastive Loss (HHCL), which enforces hierarchical semantic constraints in a non-Euclidean embedding space. The HHCL enhances inter-class separability and intra-class consistency while preserving the intrinsic hierarchical relationships among fine-grained categories. Comprehensive experiments conducted on four standard FGVC benchmarks validate the superiority of our H3Former framework.

</details>


### [29] [Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models](https://arxiv.org/abs/2511.10292)
*Zhengtao Zou,Ya Gao,Jiarui Guan,Bin Li,Pekka Marttinen*

Main category: cs.CV

TL;DR: Rudder是一个低开销框架，通过残差更新定向解码调控来减少大型视觉语言模型（LVLM）的对象幻觉问题，在不显著影响效率的情况下提高其可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时干预措施以牺牲效率为代价来减少LVLM的对象幻觉，限制了其在实际应用中的实用性。

Method: Rudder框架包含两个关键创新：1. 语境激活残差方向（CARD）向量，这是一个从标准前向传播的自注意力层残差更新中提取的每样本视觉证据向量。2. 一个受贝叶斯启发的自适应门控，能够进行逐标记注入，其强度根据模型与视觉内容的偏差进行调整。

Result: 在POPE和CHAIR等关键幻觉基准测试中，Rudder取得了与最先进方法相当的性能，同时引入了可忽略的计算延迟。

Conclusion: Rudder是一种实用且有效的方法，可以在不显著影响效率的情况下提高LVLM的可靠性，解决了现有方法在减少对象幻觉时效率低下的问题。

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, generating text inconsistent with visual inputs, which can critically undermine their reliability. Existing inference-time interventions to mitigate this issue present a challenging trade-off: while methods that steer internal states or adjust output logits can be effective, they often incur substantial computational overhead, typically requiring extra forward passes. This efficiency bottleneck can limit their practicality for real-world, latency-sensitive deployments. In this work, we aim to address this trade-off with Residual-Update Directed DEcoding Regulation (RUDDER), a low-overhead framework that steers LVLMs towards visually-grounded generation. RUDDER is built on two key innovations: (1) Contextual Activation Residual Direction (CARD) vector, a per-sample visual evidence vector extracted from the residual update of a self-attention layer during a single, standard forward pass. (2) A Bayesian-inspired adaptive gate that performs token-wise injection, applying a corrective signal whose strength is conditioned on the model's deviation from the visual context. Extensive experiments on key hallucination benchmarks, including POPE and CHAIR, indicate that RUDDER achieves performance comparable to state-of-the-art methods while introducing negligible computational latency, validating RUDDER as a pragmatic and effective approach for improving LVLMs' reliability without a significant compromise on efficiency.

</details>


### [30] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 大型视觉语言模型（VLMs）在视频描述方面表现出色，但其高昂的资源需求限制了其实际应用，特别是对于依赖详细、情境感知描述的视障（BLV）用户。为研究模型大小对关注可访问性的描述质量的影响，我们评估了包含500M和2.2B参数的SmolVLM2变体在AVCaps（室外）和Charades（室内）两个数据集上的表现。我们提出了两个新颖的评估框架：多情境BLV框架（评估空间方向、社交互动、动作事件和环境背景）和导航辅助框架（关注移动关键信息）。此外，我们还系统评估了四种不同的提示设计策略，并在智能手机上部署了两种模型，评估了FP32和INT8精度变体，以考察资源受限移动设备上的实际性能限制。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）虽然在视频描述方面表现出色，但高昂的内存、计算和部署成本限制了其在实际应用中的可用性，特别是对于依赖详细、情境感知描述的视障（BLV）用户。因此，研究模型大小对可访问性描述质量的影响具有重要意义。

Method: 本研究评估了SmolVLM2的500M和2.2B参数变体在AVCaps和Charades两个数据集上的表现。引入了两个新的评估框架：多情境BLV框架（涵盖空间方向、社交互动、动作事件和环境背景）和导航辅助框架（侧重于移动关键信息）。此外，还系统评估了四种不同的提示设计策略，并在智能手机上部署了FP32和INT8精度的模型，以评估在资源受限移动设备上的实际性能。

Result: SmolVLM2在不同参数规模下的表现以及不同评估框架下的结果将在此展示。同时，不同提示策略和模型精度（FP32 vs INT8）在智能手机上的实际部署性能也将被评估。

Conclusion: 大型视觉语言模型在视频描述方面的潜力巨大，但需要进一步优化以满足视障用户的可访问性需求。本研究通过评估不同模型大小、评估框架、提示策略以及模型精度，为开发更实用、更具可访问性的模型提供了见解。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [31] [Rethinking Visual Information Processing in Multimodal LLMs](https://arxiv.org/abs/2511.10301)
*Dongwan Kim,Viresh Ranjan,Takashi Nagata,Arnab Dhua,Amit Kumar K C*

Main category: cs.CV

TL;DR: LLaViT通过让LLM同时充当视觉编码器，改进了视觉-语言建模，在多个基准测试中显著优于LLaVA。


<details>
  <summary>Details</summary>
Motivation: LLaVA架构在整合视觉特征方面存在固有的视觉-语言模式不匹配问题。

Method: LLaViT通过学习单独的QKV投影、实现双向视觉令牌注意以及整合全局和局部视觉表征，使LLM能够充当视觉编码器。

Result: LLaViT在多个基准测试中显著优于LLaVA，并且在参数量加倍的情况下优于其他模型。

Conclusion: LLaViT提出了一种更有效的视觉-语言建模方法，其中LLM同时充当强大的视觉编码器。

Abstract: Despite the remarkable success of the LLaVA architecture for vision-language tasks, its design inherently struggles to effectively integrate visual features due to the inherent mismatch between text and vision modalities. We tackle this issue from a novel perspective in which the LLM not only serves as a language model but also a powerful vision encoder. To this end, we present LLaViT - Large Language Models as extended Vision Transformers - which enables the LLM to simultaneously function as a vision encoder through three key modifications: (1) learning separate QKV projections for vision modality, (2) enabling bidirectional attention on visual tokens, and (3) incorporating both global and local visual representations. Through extensive controlled experiments on a wide range of LLMs, we demonstrate that LLaViT significantly outperforms the baseline LLaVA method on a multitude of benchmarks, even surpassing models with double its parameter count, establishing a more effective approach to vision-language modeling.

</details>


### [32] [Revisiting Evaluation of Deep Neural Networks for Pedestrian Detection](https://arxiv.org/abs/2511.10308)
*Patrick Feifel,Benedikt Franke,Frank Bonarens,Frank Köster,Arne Raulf,Friedhelm Schwenker*

Main category: cs.CV

TL;DR: 现有的行人检测基准测试存在不足，因为它们无法真实地评估深度神经网络（DNN）的性能。图像分割可以提供街道场景的细粒度信息，可用于区分行人检测器评估中的不同错误类型。本研究提出了八种不同的行人检测错误类别，并为这些错误类别的性能比较提出了新指标。我们使用新指标对简化版APD的各种骨干网络进行了比较，展示了一种更细粒度、更鲁棒的模型比较方法，特别是在安全关键性能方面。我们使用一种相对简单的架构在CityPersons-reasonable上达到了SOTA（无额外训练数据）。


<details>
  <summary>Details</summary>
Motivation: 目前行人检测的性能评估基准存在不足，无法真实地评估DNN的性能。图像分割可以提供街道场景的细粒度信息，可用于区分行人检测器评估中的不同错误类型。

Method: 提出八种不同的行人检测错误类别，并提出新的指标来比较这些错误类别的性能。使用新指标比较简化版APD 的各种骨干网络。

Result: 在 CityPersons-reasonable 数据集上（不使用额外训练数据）取得了 SOTA 性能。

Conclusion: 提出的新错误类别和评估指标能够更细粒度、更鲁棒地比较行人检测模型，特别是在安全关键性能方面。

Abstract: Reliable pedestrian detection represents a crucial step towards automated driving systems. However, the current performance benchmarks exhibit weaknesses. The currently applied metrics for various subsets of a validation dataset prohibit a realistic performance evaluation of a DNN for pedestrian detection. As image segmentation supplies fine-grained information about a street scene, it can serve as a starting point to automatically distinguish between different types of errors during the evaluation of a pedestrian detector. In this work, eight different error categories for pedestrian detection are proposed and new metrics are proposed for performance comparison along these error categories. We use the new metrics to compare various backbones for a simplified version of the APD, and show a more fine-grained and robust way to compare models with each other especially in terms of safety-critical performance. We achieve SOTA on CityPersons-reasonable (without extra training data) by using a rather simple architecture.

</details>


### [33] [Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision](https://arxiv.org/abs/2511.10316)
*Yu Deng,Baozhu Zhao,Junyan Su,Xiaohan Zhang,Qi Liu*

Main category: cs.CV

TL;DR: 本研究提出一种结合景深监督和多视角一致性监督的新型三维重建框架，以解决深度变化剧烈场景下的重建难题。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建方法在处理近场和远场区域时，由于监督信号不一致，面临远距离区域深度估计不准确和近距离区域结构退化的问题。本研究旨在同时解决这两个挑战。

Method: 该框架包含两个核心组件：1. 景深监督：利用尺度恢复的单目深度估计器生成深度先验，通过散焦卷积合成物理上准确的散焦图像，并采用新颖的景深损失强制执行几何一致性。2. 多视角一致性监督：利用基于LoFTR的半稠密特征匹配来最小化跨视角几何误差，并通过可靠匹配点的最小二乘优化来强制执行深度一致性。

Result: 所提出的方法在Waymo开放数据集上，与现有最先进的方法相比，PSNR提高了0.8 dB。

Conclusion: 该框架通过结合散焦物理学和多视角几何约束，实现了优越的深度保真度，为城市环境中复杂的深度分层提供了可扩展的解决方案，弥合了物理成像原理和基于学习的深度正则化之间的差距。

Abstract: Three-dimensional reconstruction in scenes with extreme depth variations remains challenging due to inconsistent supervisory signals between near-field and far-field regions. Existing methods fail to simultaneously address inaccurate depth estimation in distant areas and structural degradation in close-range regions. This paper proposes a novel computational framework that integrates depth-of-field supervision and multi-view consistency supervision to advance 3D Gaussian Splatting. Our approach comprises two core components: (1) Depth-of-field Supervision employs a scale-recovered monocular depth estimator (e.g., Metric3D) to generate depth priors, leverages defocus convolution to synthesize physically accurate defocused images, and enforces geometric consistency through a novel depth-of-field loss, thereby enhancing depth fidelity in both far-field and near-field regions; (2) Multi-View Consistency Supervision employing LoFTR-based semi-dense feature matching to minimize cross-view geometric errors and enforce depth consistency via least squares optimization of reliable matched points. By unifying defocus physics with multi-view geometric constraints, our method achieves superior depth fidelity, demonstrating a 0.8 dB PSNR improvement over the state-of-the-art method on the Waymo Open Dataset. This framework bridges physical imaging principles and learning-based depth regularization, offering a scalable solution for complex depth stratification in urban environments.

</details>


### [34] [DermAI: Clinical dermatology acquisition through quality-driven image collection for AI classification in mobile](https://arxiv.org/abs/2511.10367)
*Thales Bezerra,Emanoel Thyago,Kelvin Cunha,Rodrigo Abreu,Fábio Papais,Francisco Mauro,Natália Lopes,Érico Medeiros,Jéssica Guido,Shirley Cruz,Paulo Borba,Tsang Ing Ren*

Main category: cs.CV

TL;DR: AI 皮肤病学应用受限于有偏见的数据集、图像质量不佳和验证不足。本研究提出 DermAI，一个轻量级的智能手机应用程序，可在常规咨询中实时捕获、注释和分类皮肤病变。DermAI 可在设备上执行质量检查并进行本地模型调整，这与以往仅关注皮肤镜的工具不同。DermAI 临床数据集包含各种肤色、种族和设备来源。初步实验表明，在公开数据集上训练的模型无法泛化到本研究的样本，而使用本地数据进行微调可提高性能。研究结果强调了标准化、多样化的数据收集对于满足医疗需求和机器学习开发的重要性。


<details>
  <summary>Details</summary>
Motivation: AI 皮肤病学应用在实际推广中面临诸多挑战，包括数据集存在偏差、图像质量参差不齐以及缺乏充分的验证。

Method: 提出 DermAI，一个轻量级、基于智能手机的应用程序，支持在实时咨询过程中进行皮肤病变的图像捕获、标注和分类。该应用具备设备端质量检查和本地模型适应能力。构建了包含多样化肤色、种族和设备来源的 DermAI 临床数据集。通过实验对比了使用公开数据集训练的模型与使用本地数据微调的模型在泛化能力上的差异。

Result: 在公开数据集上训练的模型在 DermAI 数据集上表现不佳，而使用本地数据进行微调后，模型性能得到显著提升。

Conclusion: 标准化、多样化的数据收集对于满足医疗需求和推动机器学习在皮肤病学领域的应用至关重要。

Abstract: AI-based dermatology adoption remains limited by biased datasets, variable image quality, and limited validation. We introduce DermAI, a lightweight, smartphone-based application that enables real-time capture, annotation, and classification of skin lesions during routine consultations. Unlike prior dermoscopy-focused tools, DermAI performs on-device quality checks, and local model adaptation. The DermAI clinical dataset, encompasses a wide range of skin tones, ethinicity and source devices. In preliminary experiments, models trained on public datasets failed to generalize to our samples, while fine-tuning with local data improved performance. These results highlight the importance of standardized, diverse data collection aligned with healthcare needs and oriented to machine learning development.

</details>


### [35] [SHRUG-FM: Reliability-Aware Foundation Models for Earth Observation](https://arxiv.org/abs/2511.10370)
*Kai-Hendrik Cohrs,Zuzanna Osika,Maria Gonzalez-Calabuig,Vishal Nedungadi,Ruben Cartuyvels,Steffen Knoblauch,Joppe Massant,Shruti Nath,Patrick Ebel,Vasileios Sitokonstantinou*

Main category: cs.CV

TL;DR: SHRUG-FM是一个用于地球观测的地理空间基础模型(GFM)的可靠性感知预测框架，通过结合输入空间和嵌入空间的OOD检测以及预测不确定性，提高了模型在未充分表示环境下的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的地球观测GFM在预训练时未充分表示的环境中表现不可靠。本研究旨在提高GFM在这些环境下的可靠性，并提供可解释的性能评估。

Method: 提出SHRUG-FM框架，整合三种互补信号：1. 输入空间的OOD检测；2. 嵌入空间的OOD检测；3. 特定任务的预测不确定性。该框架应用于火烧痕迹分割任务。

Result: SHRUG-FM表明，OOD分数与特定环境条件下的性能下降相关。基于不确定性的标记有助于剔除大量性能不佳的预测。将这些标记与HydroATLAS的土地覆盖属性关联分析，发现模型失效并非随机，而是集中在低洼地带和大型河流区域，这可能归因于预训练数据中的代表性不足。

Conclusion: SHRUG-FM为GFM在气候敏感应用中的安全、可解释部署提供了途径，有助于缩小基准性能与实际可靠性之间的差距。

Abstract: Geospatial foundation models for Earth observation often fail to perform reliably in environments underrepresented during pretraining. We introduce SHRUG-FM, a framework for reliability-aware prediction that integrates three complementary signals: out-of-distribution (OOD) detection in the input space, OOD detection in the embedding space and task-specific predictive uncertainty. Applied to burn scar segmentation, SHRUG-FM shows that OOD scores correlate with lower performance in specific environmental conditions, while uncertainty-based flags help discard many poorly performing predictions. Linking these flags to land cover attributes from HydroATLAS shows that failures are not random but concentrated in certain geographies, such as low-elevation zones and large river areas, likely due to underrepresentation in pretraining data. SHRUG-FM provides a pathway toward safer and more interpretable deployment of GFMs in climate-sensitive applications, helping bridge the gap between benchmark performance and real-world reliability.

</details>


### [36] [Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery](https://arxiv.org/abs/2511.10387)
*Prince Mensah,Pelumi Victor Aderinto,Ibrahim Salihu Yusuf,Arnu Pretorius*

Main category: cs.CV

TL;DR: 提出了一种结合物理模型和Transformer-VAE的架构，仅使用模拟数据即可准确反演植被生物物理参数。


<details>
  <summary>Details</summary>
Motivation: 准确地从卫星图像中检索植被生物物理变量对于生态系统监测和农业管理至关重要。

Method: 提出了一种物理信息Transformer-VAE架构，将PROSAIL辐射传输模型作为可微分的物理解码器，用于从Sentinel-2数据中同时估计关键的冠层参数。该模型仅在模拟数据上进行训练。

Result: 在FRM4Veg和BelSAR真实野外数据集上，成功反演了叶面积指数（LAI）和冠层叶绿素含量（CCC），其准确性与使用真实卫星图像训练的模型相当。

Conclusion: 将物理模型与深度网络相结合，可以实现对辐射传输模型的有效反演，为大规模、物理约束的植被性状遥感提供了新的途径，并且该方法无需实测标签或真实图像校准，是一种经济高效的自监督解决方案。

Abstract: Accurate retrieval of vegetation biophysical variables from satellite imagery is crucial for ecosystem monitoring and agricultural management. In this work, we propose a physics-informed Transformer-VAE architecture to invert the PROSAIL radiative transfer model for simultaneous estimation of key canopy parameters from Sentinel-2 data. Unlike previous hybrid approaches that require real satellite images for self-supevised training. Our model is trained exclusively on simulated data, yet achieves performance on par with state-of-the-art methods that utilize real imagery. The Transformer-VAE incorporates the PROSAIL model as a differentiable physical decoder, ensuring that inferred latent variables correspond to physically plausible leaf and canopy properties. We demonstrate retrieval of leaf area index (LAI) and canopy chlorophyll content (CCC) on real-world field datasets (FRM4Veg and BelSAR) with accuracy comparable to models trained with real Sentinel-2 data. Our method requires no in-situ labels or calibration on real images, offering a cost-effective and self-supervised solution for global vegetation monitoring. The proposed approach illustrates how integrating physical models with advanced deep networks can improve the inversion of RTMs, opening new prospects for large-scale, physically-constrained remote sensing of vegetation traits.

</details>


### [37] [MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns](https://arxiv.org/abs/2511.10390)
*Jiarui Zhang,Yuliang Liu,Zijun Wu,Guosheng Pang,Zhili Ye,Yupei Zhong,Junteng Ma,Tao Wei,Haiyang Xu,Weikai Chen,Zeen Wang,Qiangjun Ji,Fanxi Zhou,Qi Zhang,Yuanrui Hu,Jiahao Liu,Zhang Li,Ziyang Zhang,Qiang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: MonkeyOCR v1.5是一个统一的视觉-语言框架，通过两阶段解析流程增强了文档布局理解和内容识别能力，在OmniDocBench v1.5上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文档通常具有复杂的布局，例如多层表格、嵌入的图像或公式以及跨页结构，这给现有的OCR系统带来了挑战。

Method: MonkeyOCR v1.5采用两阶段解析流程：第一阶段使用大型多模态模型联合预测文档布局和阅读顺序；第二阶段对检测区域内的文本、公式和表格进行局部识别。此外，还提出了基于视觉一致性的强化学习方案来处理复杂表格结构，并引入了图像解耦表格解析和类型引导表格合并模块来处理包含嵌入图像的表格以及跨页或跨列的表格。

Result: MonkeyOCR v1.5在OmniDocBench v1.5上取得了最先进的性能，优于PPOCR-VL和MinerU 2.5，并在视觉复杂文档场景中表现出卓越的鲁棒性。

Conclusion: MonkeyOCR v1.5通过其创新的两阶段解析流程、表格结构处理方案和专用模块，能够有效处理复杂的文档布局，并在各种场景下实现高性能和高鲁棒性。

Abstract: Document parsing is a core task in document intelligence, supporting applications such as information extraction, retrieval-augmented generation, and automated document analysis. However, real-world documents often feature complex layouts with multi-level tables, embedded images or formulas, and cross-page structures, which remain challenging for existing OCR systems. We introduce MonkeyOCR v1.5, a unified vision-language framework that enhances both layout understanding and content recognition through a two-stage parsing pipeline. The first stage employs a large multimodal model to jointly predict document layout and reading order, leveraging visual information to ensure structural and sequential consistency. The second stage performs localized recognition of text, formulas, and tables within detected regions, maintaining high visual fidelity while reducing error propagation. To address complex table structures, we propose a visual consistency-based reinforcement learning scheme that evaluates recognition quality via render-and-compare alignment, improving structural accuracy without manual annotations. Additionally, two specialized modules, Image-Decoupled Table Parsing and Type-Guided Table Merging, are introduced to enable reliable parsing of tables containing embedded images and reconstruction of tables crossing pages or columns. Comprehensive experiments on OmniDocBench v1.5 demonstrate that MonkeyOCR v1.5 achieves state-of-the-art performance, outperforming PPOCR-VL and MinerU 2.5 while showing exceptional robustness in visually complex document scenarios.

</details>


### [38] [OpenSR-SRGAN: A Flexible Super-Resolution Framework for Multispectral Earth Observation Data](https://arxiv.org/abs/2511.10461)
*Simon Donike,Cesar Aybar,Julio Contreras,Luis Gómez-Chova*

Main category: cs.CV

TL;DR: OpenSR-SRGAN是一个用于地球观测单图像超分辨率的开源框架，通过配置文件简化了SRGAN模型的使用和定制，降低了研究和应用的门槛。


<details>
  <summary>Details</summary>
Motivation: 介绍OpenSR-SRGAN，一个用于地球观测单图像超分辨率的开源、模块化框架。

Method: 通过配置文件统一实现SRGAN风格模型，用户无需修改代码即可配置生成器、判别器、损失函数和训练计划，支持多光谱卫星数据（如Sentinel-2）的应用。

Result: 提供了一个易于配置、扩展和应用的框架，包含常见遥感场景的现成配置、对抗训练的默认设置以及用于日志记录、验证和大场景推理的内置钩子。

Conclusion: OpenSR-SRGAN将GANs超分辨率转化为一种配置驱动的工作流程，降低了研究人员和从业人员实验SRGAN、可复现地比较模型以及跨不同地球观测数据集部署超分辨率流程的门槛。

Abstract: We present OpenSR-SRGAN, an open and modular framework for single-image super-resolution in Earth Observation. The software provides a unified implementation of SRGAN-style models that is easy to configure, extend, and apply to multispectral satellite data such as Sentinel-2. Instead of requiring users to modify model code, OpenSR-SRGAN exposes generators, discriminators, loss functions, and training schedules through concise configuration files, making it straightforward to switch between architectures, scale factors, and band setups. The framework is designed as a practical tool and benchmark implementation rather than a state-of-the-art model. It ships with ready-to-use configurations for common remote sensing scenarios, sensible default settings for adversarial training, and built-in hooks for logging, validation, and large-scene inference. By turning GAN-based super-resolution into a configuration-driven workflow, OpenSR-SRGAN lowers the entry barrier for researchers and practitioners who wish to experiment with SRGANs, compare models in a reproducible way, and deploy super-resolution pipelines across diverse Earth-observation datasets.

</details>


### [39] [Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes](https://arxiv.org/abs/2511.10484)
*Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T. S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers*

Main category: cs.CV

TL;DR: 本研究提出一种全自动方法，利用CT影像中的胰腺表面小叶化（PSL）特征来筛查2型糖尿病（T2DM），研究发现T2DM患者的PSL水平更高，且模型预测T2DM的准确率达到0.90 AUC。


<details>
  <summary>Details</summary>
Motivation: T2DM的早期检测至关重要，现有研究多关注胰腺体积和脂肪含量，而对胰腺表面小叶化（PSL）的研究不足，本研究旨在填补这一空白。

Method: 使用四种深度学习模型自动分割胰腺，并计算PSL。构建多变量模型，结合CT影像学生物标志物来预测T2DM。

Result: T2DM患者的PSL（4.26 $\pm$ 8.32）显著高于非糖尿病患者（3.19 $\pm$ 3.62，p=0.01）。PancAP模型分割效果最佳（Dice 0.79 $\pm$ 0.17），预测T2DM的AUC为0.90，敏感性66.7%，特异性91.9%。

Conclusion: PSL可作为T2DM筛查的有效生物标志物，并可能有助于预测T2DM的早期发病。

Abstract: Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that affects millions of people worldwide. Early detection is crucial as it can alter pancreas function through morphological changes and increased deposition of ectopic fat, eventually leading to organ damage. While studies have shown an association between T2DM and pancreas volume and fat content, the role of increased pancreatic surface lobularity (PSL) in patients with T2DM has not been fully investigated. In this pilot work, we propose a fully automated approach to delineate the pancreas and other abdominal structures, derive CT imaging biomarkers, and opportunistically screen for T2DM. Four deep learning-based models were used to segment the pancreas in an internal dataset of 584 patients (297 males, 437 non-diabetic, age: 45$\pm$15 years). PSL was automatically detected and it was higher for diabetic patients (p=0.01) at 4.26 $\pm$ 8.32 compared to 3.19 $\pm$ 3.62 for non-diabetic patients. The PancAP model achieved the highest Dice score of 0.79 $\pm$ 0.17 and lowest ASSD error of 1.94 $\pm$ 2.63 mm (p$<$0.05). For predicting T2DM, a multivariate model trained with CT biomarkers attained 0.90 AUC, 66.7\% sensitivity, and 91.9\% specificity. Our results suggest that PSL is useful for T2DM screening and could potentially help predict the early onset of T2DM.

</details>


### [40] [Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation](https://arxiv.org/abs/2511.10547)
*Isabela Albuquerque,Ira Ktena,Olivia Wiles,Ivana Kajić,Amal Rannen-Triki,Cristina Vasconcelos,Aida Nematzadeh*

Main category: cs.CV

TL;DR: T2I模型缺乏多样性，本文提出了一个评估框架，通过评估个体概念及其变异因素来评估多样性。框架包括人类评估模板、包含变异因素的提示集，以及通过二项检验比较模型的方法。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像（T2I）模型在生成质量方面取得了显著的进步，但它们生成的输出往往缺乏多样性，呈现出同质化的趋势。因此，有必要对T2I模型进行鲁棒的多样性评估。

Method: 本文提出的框架通过评估个体概念及其相关的变异因素来系统地评估多样性。具体包括：1. 新颖的人类评估模板，用于细致的多样性评估；2. 精心策划的提示集，涵盖了具有已识别变异因素（例如，提示：一个苹果的图像，变异因素：颜色）的各种概念；3. 通过二项检验比较模型的人类注释的方法。

Result: 研究结果表明，该框架能够对T2I模型按多样性进行排名，并识别出它们在哪些类别中特别挣扎。此外，研究还对用于多样性测量的各种图像嵌入进行了严格比较。

Conclusion: 这项研究提供了一种鲁棒的方法和深刻的见解，为提高T2I模型的多样性和开发相关指标铺平了道路。

Abstract: Despite advances in generation quality, current text-to-image (T2I) models often lack diversity, generating homogeneous outputs. This work introduces a framework to address the need for robust diversity evaluation in T2I models. Our framework systematically assesses diversity by evaluating individual concepts and their relevant factors of variation. Key contributions include: (1) a novel human evaluation template for nuanced diversity assessment; (2) a curated prompt set covering diverse concepts with their identified factors of variation (e.g. prompt: An image of an apple, factor of variation: color); and (3) a methodology for comparing models in terms of human annotations via binomial tests.
  Furthermore, we rigorously compare various image embeddings for diversity measurement. Notably, our principled approach enables ranking of T2I models by diversity, identifying categories where they particularly struggle. This research offers a robust methodology and insights, paving the way for improvements in T2I model diversity and metric development.

</details>


### [41] [A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space](https://arxiv.org/abs/2511.10555)
*Huijie Liu,Shuhao Cui,Haoxiang Cao,Shuai Ma,Kai Wu,Guoliang Kang*

Main category: cs.CV

TL;DR: 提出了一种名为CoTyle的新型开源方法，仅通过数值风格编码即可生成具有新颖且一致视觉风格的图像，解决了现有方法在风格一致性、创造力和复杂风格表示方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法在生成新颖且一致的视觉风格方面存在挑战，通常依赖冗长的文本提示、参考图像或参数高效微调，且在风格一致性、创造力和复杂风格表示方面存在不足。学界在此领域的研究匮乏。

Method: CoTyle首先从图像集合中训练离散风格码本以提取风格嵌入，然后将这些嵌入作为文本到图像扩散模型（T2I-DM）的条件来生成风格化图像。随后，在离散风格嵌入上训练自回归风格生成器来建模其分布，从而合成新的风格嵌入。推理时，数值风格码通过风格生成器映射到唯一的风格嵌入，该嵌入指导T2I-DM生成相应风格的图像。

Result: CoTyle能够将数值代码转化为风格控制器，生成具有新颖、一致视觉风格的图像，实现了极高的简洁性和多样性，并解锁了最小输入下的可复现风格的广阔空间。

Conclusion: CoTyle是首个开源的数值代码到风格图像生成方法，它通过数值风格编码实现了新颖、一致的视觉风格生成，证明了“风格值得一个代码”的理念。

Abstract: Innovative visual stylization is a cornerstone of artistic creation, yet generating novel and consistent visual styles remains a significant challenge. Existing generative approaches typically rely on lengthy textual prompts, reference images, or parameter-efficient fine-tuning to guide style-aware image generation, but often struggle with style consistency, limited creativity, and complex style representations. In this paper, we affirm that a style is worth one numerical code by introducing the novel task, code-to-style image generation, which produces images with novel, consistent visual styles conditioned solely on a numerical style code. To date, this field has only been primarily explored by the industry (e.g., Midjourney), with no open-source research from the academic community. To fill this gap, we propose CoTyle, the first open-source method for this task. Specifically, we first train a discrete style codebook from a collection of images to extract style embeddings. These embeddings serve as conditions for a text-to-image diffusion model (T2I-DM) to generate stylistic images. Subsequently, we train an autoregressive style generator on the discrete style embeddings to model their distribution, allowing the synthesis of novel style embeddings. During inference, a numerical style code is mapped to a unique style embedding by the style generator, and this embedding guides the T2I-DM to generate images in the corresponding style. Unlike existing methods, our method offers unparalleled simplicity and diversity, unlocking a vast space of reproducible styles from minimal input. Extensive experiments validate that CoTyle effectively turns a numerical code into a style controller, demonstrating a style is worth one code.

</details>


### [42] [Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping](https://arxiv.org/abs/2511.10604)
*Zack Dewis,Yimin Zhu,Zhengsen Xu,Mabel Heffring,Saeid Taleghanidoozdoozan,Kaylee Xiao,Motasem Alkayid,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出了一种名为MSOM的新型多任务OBIA-Mamba模型，用于增强Sentinel-2卫星图像的土地利用和土地覆盖（LULC）分类，解决了空间异质性、上下文信息和光谱模糊性等数据挑战。


<details>
  <summary>Details</summary>
Motivation: 由于空间异质性、上下文信息和光谱模糊性等数据挑战，基于Sentinel-2的LULC分类任务非常困难。

Method: 设计了基于对象的图像分析（OBIA）Mamba模型（OBIA-Mamba），使用超像素作为Mamba token以减少冗余计算；设计了全局-局部（GLocal）双分支CNN-Mamba架构，以联合建模局部空间细节和全局上下文信息；设计了多任务优化框架，采用双损失函数来平衡局部精度和全局一致性。

Result: 在加拿大艾伯塔省的Sentinel-2影像上测试，与几种先进的分类方法相比，MSOM方法实现了更高的分类精度和更精细的细节。

Conclusion: 提出的MSOM方法在Sentinel-2影像的LULC分类任务上优于其他最先进的方法，能够实现更高的分类精度和更精细的细节。

Abstract: Although Sentinel-2 based land use and land cover (LULC) classification is critical for various environmental monitoring applications, it is a very difficult task due to some key data challenges (e.g., spatial heterogeneity, context information, signature ambiguity). This paper presents a novel Multitask Glocal OBIA-Mamba (MSOM) for enhanced Sentinel-2 classification with the following contributions. First, an object-based image analysis (OBIA) Mamba model (OBIA-Mamba) is designed to reduce redundant computation without compromising fine-grained details by using superpixels as Mamba tokens. Second, a global-local (GLocal) dual-branch convolutional neural network (CNN)-mamba architecture is designed to jointly model local spatial detail and global contextual information. Third, a multitask optimization framework is designed to employ dual loss functions to balance local precision with global consistency. The proposed approach is tested on Sentinel-2 imagery in Alberta, Canada, in comparison with several advanced classification approaches, and the results demonstrate that the proposed approach achieves higher classification accuracy and finer details that the other state-of-the-art methods.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [43] [Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages](https://arxiv.org/abs/2511.09690)
*Omnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates*

Main category: cs.CL

TL;DR: Omnilingual ASR是一个可扩展的ASR系统，能够支持1600多种语言，包括500多种以前不支持的语言，只需少量数据即可实现。


<details>
  <summary>Details</summary>
Motivation: 现有的ASR系统在支持高资源语言方面取得了很大进展，但大多数语言仍然不受支持，而且扩展成本高昂，并且受到限制性架构和潜在的道德问题的阻碍。需要一个可扩展的ASR系统来解决这些限制，并使社区能够支持他们自己的语言。

Method: Omnilingual ASR通过利用7B参数的自监督预训练来学习强大的语音表示，并采用了一个受LLM启发的编码器-解码器架构来实现零样本泛化。该模型在一个大规模且多样化的语料库上进行训练，其中结合了公共资源和通过有偿本地合作收集的社区资源。

Result: Omnilingual ASR支持超过1600种语言，包括500多种以前未被ASR覆盖的语言。自动评估显示，与以前的系统相比，在低资源条件下取得了显著的改进，并且具有强大的泛化能力。研究人员发布了一个包含300M到7B参数的模型系列。

Conclusion: Omnilingual ASR是一个可扩展且具有成本效益的ASR系统，它支持大量的低资源语言，并解决了与ASR扩展相关的伦理问题。通过开源模型和工具，该系统旨在降低研究人员和社区的门槛，鼓励新的参与形式，并对社会产生积极影响。

Abstract: Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.

</details>


### [44] [Order Matters: Rethinking Prompt Construction in In-Context Learning](https://arxiv.org/abs/2511.09700)
*Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang*

Main category: cs.CL

TL;DR: ICL中，示例的选择和顺序对模型性能的影响都很大，甚至不亚于选择不同的示例集，并且可以通过开发集找到好的排序方式。


<details>
  <summary>Details</summary>
Motivation: 大多数先前的工作都假设选择示例对ICL的性能影响远大于示例的顺序，但这一假设需要被重新审视。

Method: 通过在分类和生成任务上进行受控实验，比较不同示例顺序和不同示例集对模型性能的影响，并研究如何利用开发集找到好的排序方式。

Result: 在不同规模的模型和任务上，示例的顺序对模型性能的影响与选择不同的示例集的影响相当，并且可以通过开发集找到接近最优的排序。

Conclusion: 示例的选择和顺序在ICL提示设计中同等重要，需要重新审视ICL的既有假设。

Abstract: In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.

</details>


### [45] [Contextual morphologically-guided tokenization for Latin encoder models](https://arxiv.org/abs/2511.09709)
*Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor*

Main category: cs.CL

TL;DR: 标准分词方法对形态丰富的语言（如拉丁语）并不理想，该研究提出了一种形态感知分词方法，通过利用词汇资源来提高语言模型的性能，尤其是在处理领域外文本时，展现了更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 标准的tokenization方法在信息论目标上表现良好，但在处理形态丰富的语言时，其语言学目标（如形态对齐）被忽视，导致下游任务性能不佳。该研究旨在探索形态感知分词对拉丁语（一种形态丰富但预训练数据量中等的语言）的语言模型性能的影响。

Method: 研究人员提出了一种形态感知分词方法，并利用拉丁语丰富的词汇资源来指导分词过程，以替代大规模预训练数据。

Result: 形态感知分词在四个下游任务上均提高了整体性能，在处理领域外文本时性能提升尤为显著，表明该方法提高了模型的泛化能力。

Conclusion: 利用语言学资源（如词汇资源）来改进形态复杂语言的语言模型是可行的。对于缺乏大规模预训练数据的低资源语言，开发和整合语言学资源是提高语言模型性能的一种有效替代方案。

Abstract: Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.

</details>


### [46] [Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives](https://arxiv.org/abs/2511.09738)
*C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty*

Main category: cs.CL

TL;DR: 本研究探索了如何利用自然语言处理（NLP）技术从大量文本数据中提取主要主题，并将其应用于识别里根至克林顿时期总统指令（PDs）中的信号主题。


<details>
  <summary>Details</summary>
Motivation: 旨在研究NLP在处理大规模文本语料库（特别是总统指令）中的主题识别能力，并评估其与人类分析结果的差异。

Method: 通过分析里根至克林顿时期的总统指令，对比NLP工具和人类分析者识别相关文件和主题的结果。

Result: NLP和人类分析者都能识别出相关文件，显示了NLP在处理大规模文本语料库方面的潜在应用价值。然而，NLP和人类标注结果之间存在差异，表明需要进一步研究来评估NLP在此类应用中的有效性。

Conclusion: NLP在识别总统指令中的信号主题方面具有潜力，但目前的研究结果显示其与人类分析存在差异，需要更多的研究来验证其有效性，并认识到AI工具的快速发展可能影响现有研究的适用性。

Abstract: Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.

</details>


### [47] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://arxiv.org/abs/2511.09748)
*Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.

</details>


### [48] [Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer](https://arxiv.org/abs/2511.09796)
*Rocco Tripodi,Xiaoyu Liu*

Main category: cs.CL

TL;DR: 跨语言NLP通过语言知识转移解决低资源语言问题，但语言差异（尤其在类型学上相距遥远时）会阻碍转移。本文分析了中英平行句中的谓词-论元结构，探索了谓词标注的对齐与不对齐，并提出了一种结构差异分类法。通过标注投影实验的定性和定量分析支持了这些发现，实验结果清晰地表明语言转移是不对称的，这在迁移学习中选择源语言时需要注意。


<details>
  <summary>Details</summary>
Motivation: 跨语言NLP在低资源场景下具有实际应用价值，但语言间的结构差异（尤其对于类型学上差异较大的语言）对知识转移构成了挑战。因此，有必要深入分析这些结构差异，以便更好地进行跨语言迁移。

Method: 本文分析了中英平行句中的谓词-论元结构，进行标注投影实验，并从定性和定量两个角度对实验结果进行了分析，最后提出了一个结构差异分类法。

Result: 通过对中英平行句的谓词-论元结构分析和标注投影实验结果的分析，发现语言转移是不对称的。

Conclusion: 跨语言NLP中的语言转移是不对称的，在进行迁移学习应用时选择源语言需要特别注意这一点，并且在提出相关的科学主张前需要进一步的研究。

Abstract: Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.

</details>


### [49] [TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG](https://arxiv.org/abs/2511.09803)
*Yufeng Wang,Lu wei,Haibin Ling*

Main category: cs.CL

TL;DR: TARG是一种无需训练的自适应检索门控方法，通过判断是否需要检索来提高事实准确性，同时减少不必要的计算和延迟。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然能提高事实准确性，但每次查询都进行检索会损害质量并增加计算量和延迟。本研究提出了一种新的方法来解决这个问题。

Method: TARG方法通过分析基础模型生成的简短草稿的初始部分（prefix logits），计算轻量级的不确定性分数（包括平均标记熵、基于top-1/top-2 logit差值的边际信号、或随机初始化的少量前缀的方差），并仅当分数超过阈值时才触发检索。该方法不依赖于特定模型，仅使用少量草稿标记，并且无需额外训练或辅助模型。

Result: 在NQ-Open、TriviaQA和PopQA数据集上，TARG方法在准确性-效率的权衡上表现出色。与“总是检索”的方法相比，TARG在准确率（EM/F1）方面相当或有所提高，同时检索量减少了70-90%，端到端延迟也显著降低，并且其开销接近“从不检索”的方法。

Conclusion: TARG方法是一种有效的无需训练的检索门控策略，能够在不显著增加模型开销的情况下，显著提高检索增强生成模型的效率和准确性。研究还发现，对于经过指令微调的大型语言模型，边际信号是一种可靠的默认选择，而小样本方差则是在预算优先情况下的保守替代方案。

Abstract: Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.

</details>


### [50] [Khmer Spellchecking: A Holistic Approach](https://arxiv.org/abs/2511.09812)
*Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing*

Main category: cs.CL

TL;DR: 现有方法未能充分解决高资源语言的拼写检查挑战，本研究提出了一种综合方法，通过整合子词分割、命名实体识别、音译转换和语言模型，提高了高棉语拼写检查的准确性。


<details>
  <summary>Details</summary>
Motivation: 与英语等高资源语言相比，高棉语的拼写检查仍然是一个悬而未决的问题，这主要是由于词典与词语分割模型之间的不匹配、高棉语单词的多样化书写形式、复合词的易形成性和词典中可能不存在、以及命名实体识别模型的缺失导致专有名词被误标为拼写错误等挑战。

Method: 提出了一种综合的高棉语拼写检查方法，该方法集成了高棉语子词分割、高棉语命名实体识别 (NER)、高棉语字素到音素 (G2P) 转换以及高棉语语言模型，旨在解决上述挑战，识别潜在的校正候选词，并对最合适的候选词进行排序。

Result: 实验结果表明，该方法在基准数据集上实现了高达 94.4% 的高棉语拼写检查准确率，优于现有解决方案，并且本研究将公开提供高棉语拼写检查和 NER 的基准数据集。

Conclusion: 本研究提出的综合方法能够有效地解决高棉语拼写检查中的挑战，并达到了最先进的准确率，同时承诺公开相关数据集以促进未来研究。

Abstract: Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.

</details>


### [51] [Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests](https://arxiv.org/abs/2511.09819)
*Rahul Soni,Basem Suleiman,Sonit Singh*

Main category: cs.CL

TL;DR: 该课程推荐系统结合了数据分析和机器学习，根据用户偏好和学术标准，为学生推荐课程，以弥合学术界与工业界之间的差距。


<details>
  <summary>Details</summary>
Motivation: 为学生提供与当前行业趋势和需求相关的课程选择，解决学生选课难题。

Method: 采用数据分析技术和机器学习算法，包括数据挖掘和协同过滤，并结合用户偏好和学术标准，设计并实现了一个算法框架，同时注重用户界面的设计，通过迭代原型和用户反馈进行优化。

Result: 开发了一个结合机器学习、用户偏好和学术标准的课程推荐系统，并设计了一个用户友好的前端界面，通过用户反馈进行了优化。

Conclusion: 该课程推荐系统能够帮助学生做出数据驱动的、符合行业期望的课程选择，提高毕业生的就业能力，并促进终身学习和职业发展。

Abstract: This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.

</details>


### [52] [Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM](https://arxiv.org/abs/2511.09831)
*Neo Wang,Sonit Singh*

Main category: cs.CL

TL;DR: 提出一个基于检索增强生成（RAG）和大型语言模型（LLM）的问答系统，以解决在线课程论坛中学生查询响应延迟和重复问题。


<details>
  <summary>Details</summary>
Motivation: 随着在线课程学生人数的增加，课程论坛面临响应延迟和重复回答教师问题的挑战。

Method: 利用开源LLM，并在课程数据集上进行微调。通过RAG方法结合包含课程内容的本地知识库来检索相关文档，并整合多链思考（multi-chain-of-thought）推理以减少幻觉。

Result: 在HotpotQA数据集上进行的实验表明，微调后的LLM与RAG方法结合在问答任务上表现出强大的性能。

Conclusion: 基于LLM和RAG的问答系统能够有效解决在线课程论坛中的挑战，并提供高质量的问答服务。

Abstract: The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.

</details>


### [53] [TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain](https://arxiv.org/abs/2511.09854)
*Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben*

Main category: cs.CL

TL;DR: LLMs在法律和金融领域存在术语嵌入空间各向同性问题，导致领域术语区分度差。TermGPT通过构建句子图、生成正负样本、采用多层对比学习来解决此问题，并在金融术语数据集上实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在法律和金融领域存在的术语嵌入空间各向同性问题，提升领域术语的区分度，以解决法律判决预测或金融风险分析等下游任务中的关键语义区分障碍。

Method: 构建句子图以捕捉语义和结构关系，基于上下文和拓扑线索生成语义一致且可区分的正负样本，并采用句子和词元两个层面的多层对比学习方法。

Result: 在金融和法律领域，TermGPT在术语区分任务上的表现优于现有基线方法。此外，构建了首个源自官方监管文件的金融术语数据集以支持评估。

Conclusion: TermGPT通过多层对比微调框架有效解决了LLMs在法律和金融领域术语表示的挑战，提升了术语区分度。

Abstract: Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.

</details>


### [54] [In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback](https://arxiv.org/abs/2511.09865)
*Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang*

Main category: cs.CL

TL;DR: InTRO框架通过引入代币级探索和自我反馈，提高了LLM在链式思考推理中的准确性和简洁性，并在数学和跨领域推理任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 监督微调和强化学习在训练LLM进行链式思考推理时存在局限性，例如泛化能力差和计算成本高。InTRO旨在解决这些问题。

Method: InTRO框架利用信息差异估计的代币级重要性权重（校正因子）来实现代币级探索和自我反馈，从而进行信息丰富的下一个代币选择。

Result: InTRO在六个数学推理基准测试中，将解决方案的准确性提高了高达20%，并且推理过程更加简洁。此外，InTRO还表现出跨领域迁移能力，能够适应数学以外的推理任务。

Conclusion: InTRO框架通过代币级探索和自我反馈，有效地提高了LLM进行链式思考推理的准确性和简洁性，并具有良好的泛化能力，能够适应跨领域推理任务。

Abstract: Training Large Language Models (LLMs) for chain-of-thought reasoning presents a significant challenge: supervised fine-tuning on a single "golden" rationale hurts generalization as it penalizes equally valid alternatives, whereas reinforcement learning with verifiable rewards struggles with credit assignment and prohibitive computational cost. To tackle these limitations, we introduce InTRO (In-Token Rationality Optimization), a new framework that enables both token-level exploration and self-feedback for accurate and concise reasoning. Instead of directly optimizing an intractable objective over all valid reasoning paths, InTRO leverages correction factors-token-wise importance weights estimated by the information discrepancy between the generative policy and its answer-conditioned counterpart, for informative next token selection. This approach allows the model to perform token-level exploration and receive self-generated feedback within a single forward pass, ultimately encouraging accurate and concise rationales. Across six math-reasoning benchmarks, InTRO consistently outperforms other baselines, raising solution accuracy by up to 20% relative to the base model. Its chains of thought are also notably more concise, exhibiting reduced verbosity. Beyond this, InTRO enables cross-domain transfer, successfully adapting to out-of-domain reasoning tasks that extend beyond the realm of mathematics, demonstrating robust generalization.

</details>


### [55] [HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2511.09873)
*Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna*

Main category: cs.CL

TL;DR: HierRouter是一种分层路由方法，通过动态组合专业、轻量级语言模型来解决大型语言模型（LLMs）的计算和内存成本问题，在提高响应质量的同时，仅增加少量的推理成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的计算和内存成本高，限制了它们在资源受限或实时环境中的部署。

Method: HierRouter将分层路由问题形式化为有限时间马尔可夫决策过程（MDP），并训练一个基于近端策略优化（PPO）的强化学习代理，以迭代地选择模型。

Result: 在QA、代码生成和数学推理等六个基准测试中，使用三种开源LLM进行实验，HierRouter将响应质量提高了2.4倍，同时平均推理成本仅略有增加。

Conclusion: 分层路由有望实现具有成本效益的高性能LLM推理。

Abstract: Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings. To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models. Formulated as a finite-horizon Markov Decision Process (MDP), our approach trains a Proximal Policy Optimization (PPO)-based reinforcement learning agent to iteratively select which models to invoke at each stage of multi-hop inference. The agent conditions on the evolving context and accumulated cost to make context-aware routing decisions. Experiments with three open-source candidate LLMs across six benchmarks, including QA, code generation, and mathematical reasoning, show that HierRouter improves response quality by up to 2.4x compared to using individual models independently, while incurring only a minimal additional inference cost on average. These results highlight the promise of hierarchical routing for cost-efficient, high-performance LLM inference. All codes can be found here https://github.com/ Nikunj-Gupta/hierouter.

</details>


### [56] [EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880)
*Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong*

Main category: cs.CL

TL;DR: 微调大型语言模型（LLM）以适应特定领域（如代码生成、生物医学分析、数学问题解决）时，通常会牺牲模型的安全对齐能力，增加产生有害输出的风险。EnchTable框架通过一种基于神经切线核（NTK）的安全向量蒸馏方法，将安全约束与任务特定推理分离开来，从而在不进行大规模再训练的情况下，将安全对齐能力迁移并保持到下游LLM中。该框架的干扰感知合并技术能够有效平衡安全性和实用性，并最小化在不同任务领域的性能损失。我们在三个不同的任务领域和三种不同的LLM架构上实现了EnchTable的原型，并通过在十一个多样化数据集上的大量实验评估了其性能，包括效用和模型安全性。实验结果表明，EnchTable能够泛化到不同供应商的LLM，有效抵抗静态和动态越狱攻击，并且在降低风险、提高效用和跨领域应用方面优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在微调以适应特定领域时，往往会牺牲其安全对齐能力，增加了产生有害输出的风险。

Method: EnchTable框架利用一种基于神经切线核（NTK）的安全向量蒸馏方法，将安全约束与任务特定推理分离开来，以在下游LLM中迁移和保持安全对齐能力，而无需大规模再训练。此外，还采用干扰感知合并技术来平衡安全性和实用性。

Result: 在三个不同的任务领域和三种不同的LLM架构上实现的EnchTable原型，在十一个多样化数据集上的实验评估显示，EnchTable能够泛化到不同供应商的LLM，有效抵抗静态和动态越狱攻击，并且在降低风险、提高效用和跨领域应用方面优于其他方法。该框架还可以无缝集成到各种部署管道中，而不会产生显著的额外开销。

Conclusion: EnchTable框架能够有效地在下游LLM中迁移和保持安全对齐能力，同时最小化性能损失，并能抵抗越狱攻击，展示了其在不同模型和任务领域的广泛适用性和鲁棒性。

Abstract: Many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains like code generation, biomedical analysis, and mathematical problem solving. However, this fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, undermining ethical guidelines and increasing the risk of harmful outputs. Addressing this challenge, we introduce EnchTable, a novel framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. EnchTable leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances safety and utility, minimizing performance compromises across various task domains. We implemented a fully functional prototype of EnchTable on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both utility and model safety. Our evaluations include LLMs from different vendors, demonstrating EnchTable's generalization capability. Furthermore, EnchTable exhibits robust resistance to static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarial prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that EnchTable achieves a significantly lower unsafe rate, higher utility score, and universal applicability across different task domains. Additionally, we validate EnchTable can be seamlessly integrated into various deployment pipelines without significant overhead.

</details>


### [57] [HI-TransPA: Hearing Impairments Translation Personal Assistant](https://arxiv.org/abs/2511.09915)
*Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng*

Main category: cs.CL

TL;DR: HI-TransPA是一个指令驱动的视听个人助理，旨在为听障人士提供统一灵活的日常交流解决方案。它融合了含糊不清的语音和高帧率的唇部动态，在一个多模态框架内实现了翻译和对话功能。


<details>
  <summary>Details</summary>
Motivation: 为听障人士提供日常通信的统一灵活解决方案，并解决现有Omni-Models在处理听障人士语音时的适应性有限的挑战。

Method: 构建了一个全面的预处理和策展流程，包括检测面部地标、分离和稳定唇部区域，并量化评估多模态样本质量。利用这些质量分数指导课程学习策略，首先在清洁、高置信度的样本上进行训练，然后逐步纳入更难的案例以增强模型的鲁棒性。采用SigLIP编码器结合统一的3D-Resampler来有效地编码高帧率的唇部运动。

Result: 在专门构建的HI-Dialogue数据集上，HI-TransPA在字面准确性和语义保真度方面均达到了最先进的性能。

Conclusion: 这项工作为将Omni-Models应用于辅助通信技术奠定了基础，为未来的研究提供了端到端的建模框架和必要的处理工具。

Abstract: To provide a unified and flexible solution for daily communication among hearing-impaired individuals, we introduce the Omni-Model paradigm into assistive technology and present HI-TransPA, an instruction-driven audio-visual personal assistant. The model fuses indistinct speech with high-frame-rate lip dynamics, enabling both translation and dialogue within a single multimodal framework. To tackle the challenges of noisy and heterogeneous raw data and the limited adaptability of existing Omni-Models to hearing-impaired speech, we construct a comprehensive preprocessing and curation pipeline that detects facial landmarks, isolates and stabilizes the lip region, and quantitatively assesses multimodal sample quality. These quality scores guide a curriculum learning strategy that first trains on clean, high-confidence samples and progressively incorporates harder cases to strengthen model robustness. We further adopt a SigLIP encoder combined with a Unified 3D-Resampler to efficiently encode high-frame-rate lip motion. Experiments on our purpose-built HI-Dialogue dataset show that HI-TransPA achieves state-of-the-art performance in both literal accuracy and semantic fidelity. This work establishes a foundation for applying Omni-Models to assistive communication technology, providing an end-to-end modeling framework and essential processing tools for future research.

</details>


### [58] [MINDS: A Cross-cultural Dialogue Corpus for Social Norm Classification and Adherence Detection](https://arxiv.org/abs/2511.09918)
*Pritish Sahu,Anirudh Som,Dimitra Vergyri,Ajay Divakaran*

Main category: cs.CL

TL;DR: 本研究提出了Norm-RAG，一个用于多轮对话中社会规范推理的检索增强框架，并通过MINDS数据集进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的计算模型在处理主观、依赖于上下文和跨文化变异的社会规范推理方面存在挑战，以往的研究大多集中在孤立的言语或合成对话，无法捕捉真实对话的流动性和多轮性。

Method: Norm-RAG是一个检索增强的、基于智能体的框架，它将言语层面的属性（包括交际意图、说话人角色、人际框架和语言线索）与通过新颖的语义分块方法检索到的结构化规范文档相结合，实现了可解释和上下文感知的多语言对话中的规范遵循和违反推理。

Result: 在MINDS数据集上的实验表明，Norm-RAG在规范检测和泛化方面有所改进，并提高了跨文化适应性和社会智能对话系统的性能。

Conclusion: Norm-RAG能够进行可解释和上下文感知的多语言对话中的规范遵循和违反推理，并且在提高对话系统性能方面显示出潜力。

Abstract: Social norms are implicit, culturally grounded expectations that guide interpersonal communication. Unlike factual commonsense, norm reasoning is subjective, context-dependent, and varies across cultures, posing challenges for computational models. Prior works provide valuable normative annotations but mostly target isolated utterances or synthetic dialogues, limiting their ability to capture the fluid, multi-turn nature of real-world conversations. In this work, we present Norm-RAG, a retrieval-augmented, agentic framework for nuanced social norm inference in multi-turn dialogues. Norm-RAG models utterance-level attributes including communicative intent, speaker roles, interpersonal framing, and linguistic cues and grounds them in structured normative documentation retrieved via a novel Semantic Chunking approach. This enables interpretable and context-aware reasoning about norm adherence and violation across multilingual dialogues. We further introduce MINDS (Multilingual Interactions with Norm-Driven Speech), a bilingual dataset comprising 31 multi-turn Mandarin-English and Spanish-English conversations. Each turn is annotated for norm category and adherence status using multi-annotator consensus, reflecting cross-cultural and realistic norm expression. Our experiments show that Norm-RAG improves norm detection and generalization, demonstrates improved performance for culturally adaptive and socially intelligent dialogue systems.

</details>


### [59] [Leveraging Large Language Models for Identifying Knowledge Components](https://arxiv.org/abs/2511.09935)
*Canwen Wang,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: LLM在知识组件（KC）识别中存在冗余问题，通过引入基于余弦相似度的语义合并方法，可显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 手动识别知识组件（KC）是自适应学习系统的瓶颈，现有LLM方法存在标签冗余、泛化能力不足的问题。

Method: 在646个选择题数据集上，使用GPT-4o-mini进行“模拟教科书”LLM提示策略，并引入基于余弦相似度的KC标签合并方法。

Result: 未经合并的LLM方法在RMSE（0.4285）和KC数量（569）上均劣于专家模型（RMSE 0.4206，KC数101）。余弦相似度阈值为0.8时，KC数量减少至428，RMSE降至0.4259，性能显著提升。

Conclusion: 单独扩展LLM生成不足以解决KC识别问题，但结合语义合并技术是自动化和优化KC识别的可行途径。

Abstract: Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a "simulated textbook" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.

</details>


### [60] [REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering](https://arxiv.org/abs/2511.09966)
*Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang*

Main category: cs.CL

TL;DR: REAP是一种用于多跳推理的检索增强生成方法，通过显式维护子任务和事实来克服现有方法的局限性，提高了推理的准确性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 现有用于多跳推理的检索增强生成方法缺乏全局规划，容易陷入局部推理僵局，并且未能充分利用检索内容和潜在线索，从而影响了推理结果的准确性。

Method: 提出了一种名为递归评估和自适应规划（REAP）的方法，其核心是通过子任务规划器（SP）和事实提取器（FE）显式维护与当前任务相关的结构化子任务和事实。SP保持全局视角，指导整体推理方向，并根据FE的结果评估任务状态，从而动态优化任务解决轨迹。FE对检索内容进行细粒度分析，提取可靠答案和线索。这两种模块逐步丰富了全局知识的逻辑连贯表示，增强了推理过程的可靠性和可追溯性。此外，还提出了一种统一的任务范式设计，能够进行有效的多任务微调，显著提高了SP在复杂、数据稀缺任务上的性能。

Result: 在多个公开的多跳数据集上进行的大量实验表明，REAP方法在同域和跨域设置下都显著优于现有的检索增强生成方法。

Conclusion: REAP方法在复杂的、数据稀缺的多跳推理任务中有效，显著提高了推理的准确性和可追溯性。

Abstract: Retrieval-augmented generation (RAG) has been extensively employed to mitigate hallucinations in large language models (LLMs). However, existing methods for multi-hop reasoning tasks often lack global planning, increasing the risk of falling into local reasoning impasses. Insufficient exploitation of retrieved content and the neglect of latent clues fail to ensure the accuracy of reasoning outcomes. To overcome these limitations, we propose Recursive Evaluation and Adaptive Planning (REAP), whose core idea is to explicitly maintain structured sub-tasks and facts related to the current task through the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains a global perspective, guiding the overall reasoning direction and evaluating the task state based on the outcomes of FE, enabling dynamic optimization of the task-solving trajectory. FE performs fine-grained analysis over retrieved content to extract reliable answers and clues. These two modules incrementally enrich a logically coherent representation of global knowledge, enhancing the reliability and the traceability of the reasoning process. Furthermore, we propose a unified task paradigm design that enables effective multi-task fine-tuning, significantly enhancing SP's performance on complex, data-scarce tasks. We conduct extensive experiments on multiple public multi-hop datasets, and the results demonstrate that our method significantly outperforms existing RAG methods in both in-domain and out-of-domain settings, validating its effectiveness in complex multi-hop reasoning tasks.

</details>


### [61] [NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction](https://arxiv.org/abs/2511.09971)
*Peter Røysland Aarnes,Vinay Setty*

Main category: cs.CL

TL;DR: 大型语言模型在数字推理方面存在不足，即使是领先的模型在面对扰动时也会出现准确性下降，并且没有模型能在所有情况下都保持鲁棒性。增加上下文长度通常会降低准确性，但如果上下文包含扰动示例，模型性能会得到恢复。


<details>
  <summary>Details</summary>
Motivation: 评估当前最先进的大型语言模型在处理包含数字主张和证据的事实核查任务时的鲁棒性，并找出其局限性。

Method: 使用标签翻转探针等受控扰动来评估模型在处理数字主张和证据时的准确性，并分析上下文长度和扰动示例对模型性能的影响。

Result: 现有模型在面对扰动时准确性会下降高达62%，没有模型能在所有情况下都保持鲁棒性。增加上下文长度通常会降低准确性，但如果上下文包含扰动示例，模型性能会得到显著恢复。

Conclusion: 当前的大型语言模型在数字事实核查方面存在关键的局限性，鲁棒性仍然是一个有待解决的挑战。

Abstract: Large language models show strong performance on knowledge intensive tasks such as fact-checking and question answering, yet they often struggle with numerical reasoning. We present a systematic evaluation of state-of-the-art models for veracity prediction on numerical claims and evidence pairs using controlled perturbations, including label-flipping probes, to test robustness. Our results indicate that even leading proprietary systems experience accuracy drops of up to 62\% under certain perturbations. No model proves to be robust across all conditions. We further find that increasing context length generally reduces accuracy, but when extended context is enriched with perturbed demonstrations, most models substantially recover. These findings highlight critical limitations in numerical fact-checking and suggest that robustness remains an open challenge for current language models.

</details>


### [62] [Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG](https://arxiv.org/abs/2511.09980)
*Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: ETC通过分析熵序列的一阶和二阶差分来预测不确定性趋势，从而优化动态检索增强生成（RAG）中的检索时机，能够更早、更精确地进行检索，并在多个QA基准测试中表现优于现有方法，同时减少检索频率。


<details>
  <summary>Details</summary>
Motivation: 动态检索增强生成（RAG）允许大型语言模型（LLMs）按需获取外部知识，但确定最佳检索时机是一个关键挑战。现有方法基于低置信度触发检索，可能在错误传播后才进行干预。

Method: ETC（Entropy-Trend Constraint）是一种无需训练的方法，通过对熵序列的一阶和二阶差分进行建模，来检测不确定性的新兴趋势，从而确定最佳检索时机。

Result: 在六个QA基准测试和三种LLM骨干模型上进行实验，ETC持续优于强基线方法，并降低了检索频率。ETC在领域特定场景中尤其有效，并表现出强大的泛化能力。

Conclusion: ETC通过感知不确定性趋势来优化检索时机，是一种即插即用、模型无关且易于集成的方法。实验证明其有效性，并突出了趋势感知不确定性建模在改进检索时机方面的优势。

Abstract: Dynamic retrieval-augmented generation (RAG) allows large language models (LLMs) to fetch external knowledge on demand, offering greater adaptability than static RAG. A central challenge in this setting lies in determining the optimal timing for retrieval. Existing methods often trigger retrieval based on low token-level confidence, which may lead to delayed intervention after errors have already propagated. We introduce Entropy-Trend Constraint (ETC), a training-free method that determines optimal retrieval timing by modeling the dynamics of token-level uncertainty. Specifically, ETC utilizes first- and second-order differences of the entropy sequence to detect emerging uncertainty trends, enabling earlier and more precise retrieval. Experiments on six QA benchmarks with three LLM backbones demonstrate that ETC consistently outperforms strong baselines while reducing retrieval frequency. ETC is particularly effective in domain-specific scenarios, exhibiting robust generalization capabilities. Ablation studies and qualitative analyses further confirm that trend-aware uncertainty modeling yields more effective retrieval timing. The method is plug-and-play, model-agnostic, and readily integrable into existing decoding pipelines. Implementation code is included in the supplementary materials.

</details>


### [63] [Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation](https://arxiv.org/abs/2511.09984)
*Bo Li,Zhenghua Xu,Rui Xie*

Main category: cs.CL

TL;DR: 多语言检索增强生成（RAG）在跨语言设置中存在语言漂移问题，即使模型能理解不同语言的文档，也可能因为解码器级别的语言塌陷而生成非预期的语言，尤其是在进行链式思考（CoT）等推理任务时。 英语常常成为主要的干扰源和回退语言。 本文提出了一种名为软约束解码（SCD）的轻量级、无需训练的解码策略，通过惩罚非目标语言的标记来引导模型生成目标语言，从而有效解决了语言漂移问题，并提高了任务性能。


<details>
  <summary>Details</summary>
Motivation: 研究多语言检索增强生成（RAG）中存在的语言漂移现象，特别是在跨语言和推理任务中，并探究其根本原因。

Method: 1. 系统性研究多语言RAG中的输出语言漂移问题，涉及不同数据集、语言和LLM骨干模型。 2. 提出软约束解码（SCD）策略，通过惩罚非目标语言标记来引导模型生成目标语言。 3. 在多个多语言数据集和多种语言上进行实验验证SCD的有效性。

Result: 语言漂移并非源于理解失败，而是解码器级别的语言塌陷，其中占主导地位的标记分布和高频英语模式干扰了预期语言的生成。 英语在跨语言条件下充当语义吸引子，成为最强的干扰源和最常回退的语言。 SCD策略在语言对齐和任务性能方面均有显著提升。

Conclusion: 软约束解码（SCD）是一种有效的、通用的解决方案，可以解决多语言RAG中的语言漂移问题，并提高任务性能，同时保持模型无关和无需训练的特点。

Abstract: Multilingual Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to perform knowledge-intensive tasks in multilingual settings by leveraging retrieved documents as external evidence. However, when the retrieved evidence differs in language from the user query and in-context exemplars, the model often exhibits language drift by generating responses in an unintended language. This phenomenon is especially pronounced during reasoning-intensive decoding, such as Chain-of-Thought (CoT) generation, where intermediate steps introduce further language instability. In this paper, we systematically study output language drift in multilingual RAG across multiple datasets, languages, and LLM backbones. Our controlled experiments reveal that the drift results not from comprehension failure but from decoder-level collapse, where dominant token distributions and high-frequency English patterns dominate the intended generation language. We further observe that English serves as a semantic attractor under cross-lingual conditions, emerging as both the strongest interference source and the most frequent fallback language.
  To mitigate this, we propose Soft Constrained Decoding (SCD), a lightweight, training-free decoding strategy that gently steers generation toward the target language by penalizing non-target-language tokens. SCD is model-agnostic and can be applied to any generation algorithm without modifying the architecture or requiring additional data. Experiments across three multilingual datasets and multiple typologically diverse languages show that SCD consistently improves language alignment and task performance, providing an effective and generalizable solution in multilingual RAG.

</details>


### [64] [FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance](https://arxiv.org/abs/2511.09997)
*Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: BERTScore 对金融文本中的数值变化不敏感，需要开发新的评估框架。


<details>
  <summary>Details</summary>
Motivation: BERTScore 在评估金融文本语义相似性时存在严重缺陷，因为它无法区分关键的数值差异，而这些差异在金融领域具有重要意义。

Method: 构建了一个名为 FinNuE 的诊断数据集，其中包含在不同金融文本（如收益电话会议、监管文件、社交媒体和新闻文章）中经过控制的数值扰动。使用此数据集来展示 BERTScore 在区分具有金融意义的数值差异方面的不足。

Result: 实验证明，BERTScore 无法有效地区分细微但重要的数值差异，即使这些差异会导致文本的金融含义发生巨大变化，它也会为这些文本对分配高相似度分数。

Conclusion: 基于嵌入的评估指标（如 BERTScore）在金融自然语言处理任务中存在根本性局限性。因此，有必要开发对数值变化更敏感的评估框架，以满足金融领域的特定需求。

Abstract: BERTScore has become a widely adopted metric for evaluating semantic similarity between natural language sentences. However, we identify a critical limitation: BERTScore exhibits low sensitivity to numerical variation, a significant weakness in finance where numerical precision directly affects meaning (e.g., distinguishing a 2% gain from a 20% loss). We introduce FinNuE, a diagnostic dataset constructed with controlled numerical perturbations across earnings calls, regulatory filings, social media, and news articles. Using FinNuE, demonstrate that BERTScore fails to distinguish semantically critical numerical differences, often assigning high similarity scores to financially divergent text pairs. Our findings reveal fundamental limitations of embedding-based metrics for finance and motivate numerically-aware evaluation frameworks for financial NLP.

</details>


### [65] [PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models](https://arxiv.org/abs/2511.10002)
*Shivam Sharma,Riya Naik,Tejas Gawas,Heramb Patil,Kunal Korgaonkar*

Main category: cs.CL

TL;DR: 本文提出了一个名为 PustakAI 的框架，用于设计和评估 NCERT-QA 数据集，该数据集包含与印度 6-8 年级英语和科学 NCERT 课程相关的问答对。研究评估了各种提示技术和 LLM 在此数据集上的表现，旨在为教育领域提供 AI 驱动的学习工具。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大语言模型（LLM）在适应课程特定内容（如印度 NCERT 课程）方面面临的准确性、对齐性和教学相关性方面的挑战，以支持教育资源匮乏地区的个性化学习。

Method: 设计并评估了一个名为 NCERT-QA 的问答数据集，该数据集与 6-8 年级的 NCERT 课程相关。研究中对问答对进行了分类（事实型、推理型和其他），并使用元提示、少样本和思维链提示等技术评估了不同的 LLM（包括开源和高端模型）在该数据集上的表现。

Result: 评估结果显示了不同提示技术和 LLM 在 NCERT-QA 数据集上的表现，分析了当前 LLM 作为 AI 学习工具的优势和局限性，为在正规教育体系中应用 LLM 提供了见解。

Conclusion: PustakAI 框架和 NCERT-QA 数据集为在教育领域（尤其是在资源有限的地区）应用 LLM 提供了基础，有助于开发更有效的 AI 驱动的学习工具。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework "PustakAI"\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset "NCERT-QA" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.

</details>


### [66] [ScaleFormer: Span Representation Cumulation for Long-Context Transformer](https://arxiv.org/abs/2511.10029)
*Jiangshu Du,Wenpeng Yin,Philip Yu*

Main category: cs.CL

TL;DR: ScaleFormer是一个即插即用的框架，通过分块、压缩和融合机制，使预训练模型能够处理长序列，实现了线性复杂度，并在长文档摘要任务中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 标准的自注意力机制具有二次复杂度，限制了Transformer模型在长上下文任务中的应用。现有的高效Transformer变体通常需要修改架构和昂贵的预训练。ScaleFormer旨在解决这个问题，使其能够适应现成的预训练模型，处理长序列，而无需修改架构。

Method: ScaleFormer将长输入分割成重叠的块，并为解码器生成压缩的、与上下文相关的表示。其核心是一个新颖的、无参数的融合机制，通过用先前和之后的块的累积上下文向量来丰富每个块的边界表示，从而赋予每个块的表示结构感知能力。

Result: ScaleFormer实现了线性复杂度，使预训练模型能够有效地处理长文本。在长文档摘要任务上的实验表明，该方法在不进行架构修改或使用外部检索机制的情况下，具有高度竞争力，并且通常优于最先进的方法。

Conclusion: ScaleFormer是一个简单有效的即插即用框架，能够使现成的预训练编码器-解码器模型适应长序列处理，无需架构修改，并在长文档摘要任务中取得了有竞争力的结果。

Abstract: The quadratic complexity of standard self-attention severely limits the application of Transformer-based models to long-context tasks. While efficient Transformer variants exist, they often require architectural changes and costly pre-training from scratch. To circumvent this, we propose ScaleFormer(Span Representation Cumulation for Long-Context Transformer) - a simple and effective plug-and-play framework that adapts off-the-shelf pre-trained encoder-decoder models to process long sequences without requiring architectural modifications. Our approach segments long inputs into overlapping chunks and generates a compressed, context-aware representation for the decoder. The core of our method is a novel, parameter-free fusion mechanism that endows each chunk's representation with structural awareness of its position within the document. It achieves this by enriching each chunk's boundary representations with cumulative context vectors from all preceding and succeeding chunks. This strategy provides the model with a strong signal of the document's narrative flow, achieves linear complexity, and enables pre-trained models to reason effectively over long-form text. Experiments on long-document summarization show that our method is highly competitive with and often outperforms state-of-the-art approaches without requiring architectural modifications or external retrieval mechanisms.

</details>


### [67] [Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism](https://arxiv.org/abs/2511.10045)
*Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu*

Main category: cs.CL

TL;DR: 该研究通过分析大型多模态语言模型（MLLMs）在语音符号学任务上的表现，探讨了MLLMs如何理解和处理口头语言中的听觉信息。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索大型多模态语言模型（MLLMs）如何理解语音信息，并量化其在语音符号学方面的能力，为人工智能和认知语言学领域提供新的见解。

Method: 本研究构建了一个包含真实单词和人工构造的伪词的数据集（LEX-ICON），涵盖四种语言，并标注了多达25个语义维度。研究人员通过文本和音频形式输入这些数据，并分析模型在不同层次上的注意力分配，以评估模型对语音符号的理解程度。

Result: 研究结果表明，MLLMs在语音符号学方面表现出与现有语言学研究一致的直觉，并且模型确实会关注具有语音符号意义的音素，这在注意力模式中得到了体现。

Conclusion: 本研究首次对语音符号学在MLLMs中的可解释性进行了大规模、定量分析，证明了MLLMs具备一定的语音符号学理解能力，并为连接人工智能和认知语言学领域提供了实证依据。

Abstract: Sound symbolism is a linguistic concept that refers to non-arbitrary associations between phonetic forms and their meanings. We suggest that this can be a compelling probe into how Multimodal Large Language Models (MLLMs) interpret auditory information in human languages. We investigate MLLMs' performance on phonetic iconicity across textual (orthographic and IPA) and auditory forms of inputs with up to 25 semantic dimensions (e.g., sharp vs. round), observing models' layer-wise information processing by measuring phoneme-level attention fraction scores. To this end, we present LEX-ICON, an extensive mimetic word dataset consisting of 8,052 words from four natural languages (English, French, Japanese, and Korean) and 2,930 systematically constructed pseudo-words, annotated with semantic features applied across both text and audio modalities. Our key findings demonstrate (1) MLLMs' phonetic intuitions that align with existing linguistic research across multiple semantic dimensions and (2) phonosemantic attention patterns that highlight models' focus on iconic phonemes. These results bridge domains of artificial intelligence and cognitive linguistics, providing the first large-scale, quantitative analyses of phonetic iconicity in terms of MLLMs' interpretability.

</details>


### [68] [GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt](https://arxiv.org/abs/2511.10051)
*Zhenhe Li,Can Lin,Ling Zheng,Wen-Da Wei,Junli Liang,Qi Song*

Main category: cs.CL

TL;DR: GraphIF是一个新框架，通过将多轮对话建模为关系图并使用图提示来增强大型语言模型遵循多轮指令的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在增强多轮指令遵循能力时，主要依赖于大规模多轮对话数据集的微调，但未能将多轮指令遵循明确纳入优化目标，导致模型难以处理复杂的长距离约束。

Method: GraphIF框架包含三个组件：1. 基于智能体的关系抽取模块，通过动作触发机制捕获跨轮语义关系以构建结构化图；2. 关系图提示生成模块，将结构化图信息转换为自然语言提示；3. 响应重写模块，利用生成的图提示优化初始模型输出。

Result: 在两个长多轮对话数据集上的广泛实验表明，GraphIF可以无缝集成到经过指令微调的大型语言模型中，并在所有四个多轮指令遵循评估指标上带来显著改进。

Conclusion: GraphIF通过将多轮对话建模为关系图并利用图提示，有效解决了现有方法在处理多轮指令遵循任务中的不足，显著提升了大型语言模型在处理复杂长距离约束方面的能力。

Abstract: Multi-turn instruction following is essential for building intelligent conversational systems that can consistently adhere to instructions across dialogue turns. However, existing approaches to enhancing multi-turn instruction following primarily rely on collecting or generating large-scale multi-turn dialogue datasets to fine-tune large language models (LLMs), which treat each response generation as an isolated task and fail to explicitly incorporate multi-turn instruction following into the optimization objectives. As a result, instruction-tuned LLMs often struggle with complex long-distance constraints. In multi-turn dialogues, relational constraints across turns can be naturally modeled as labeled directed edges, making graph structures particularly suitable for modeling multi-turn instruction following. Despite this potential, leveraging graph structures to enhance the multi-turn instruction following capabilities of LLMs remains unexplored. To bridge this gap, we propose GraphIF, a plug-and-play framework that models multi-turn dialogues as directed relation graphs and leverages graph prompts to enhance the instruction following capabilities of LLMs. GraphIF comprises three key components: (1) an agent-based relation extraction module that captures inter-turn semantic relations via action-triggered mechanisms to construct structured graphs; (2) a relation graph prompt generation module that converts structured graph information into natural language prompts; and (3) a response rewriting module that refines initial LLM outputs using the generated graph prompts. Extensive experiments on two long multi-turn dialogue datasets demonstrate that GraphIF can be seamlessly integrated into instruction-tuned LLMs and leads to significant improvements across all four multi-turn instruction-following evaluation metrics.

</details>


### [69] [ADI-20: Arabic Dialect Identification dataset and models](https://arxiv.org/abs/2511.10070)
*Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: ADI-20是一个包含3556小时、19种阿拉伯语方言和现代标准阿拉伯语（MSA）的阿拉伯语方言识别（ADI）数据集，旨在涵盖所有阿拉伯语国家的方言。研究人员使用该数据集训练和评估了基于ECAPA-TDNN和Whisper的模型，并探讨了训练数据量和模型参数数量对识别性能的影响。实验表明，即使只使用30%的训练数据，F1分数也 only 有小幅下降。研究人员已开源数据和模型，以促进ADI领域的研究。


<details>
  <summary>Details</summary>
Motivation: 构建一个覆盖所有阿拉伯语国家方言的全面数据集（ADI-20），并利用其训练和评估先进的ADI系统。

Method: 1. 扩展现有ADI-17数据集，创建ADI-20（3556小时，19种方言+MSA）。2. 训练和评估基于ECAPA-TDNN和Whisper的模型。3. 探索训练数据量和模型参数数量对性能的影响。

Result: 使用30%的训练数据会导致F1分数只有小幅下降。多项先进的ADI系统在ADI-20数据集上进行了训练和评估。

Conclusion: ADI-20是一个有价值的资源，可用于训练和评估ADI系统，并且该领域的研究对数据量和模型大小具有一定的鲁棒性。开源数据和模型将有助于未来的研究。

Abstract: We present ADI-20, an extension of the previously published ADI-17 Arabic Dialect Identification (ADI) dataset. ADI-20 covers all Arabic-speaking countries' dialects. It comprises 3,556 hours from 19 Arabic dialects in addition to Modern Standard Arabic (MSA). We used this dataset to train and evaluate various state-of-the-art ADI systems. We explored fine-tuning pre-trained ECAPA-TDNN-based models, as well as Whisper encoder blocks coupled with an attention pooling layer and a classification dense layer. We investigated the effect of (i) training data size and (ii) the model's number of parameters on identification performance. Our results show a small decrease in F1 score while using only 30% of the original training data. We open-source our collected data and trained models to enable the reproduction of our work, as well as support further research in ADI.

</details>


### [70] [Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts](https://arxiv.org/abs/2511.10075)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本论文评估了多模态大语言模型（multimodal LLMs）在验证科学论点方面的能力，特别是在处理表格和图表这两种不同形式的证据时。研究发现，现有模型在处理表格证据方面表现优于图表证据，并且小型模型（小于8B）在跨模态泛化方面存在不足。这表明多模态大语言模型在理解图表方面仍有很大提升空间，需要更多关注以更好地支持科学论点的验证。


<details>
  <summary>Details</summary>
Motivation: 随着科学论文数量的增长，对能够辅助审稿人评估研究论点的系统需求日益增加。实验结果是科学研究的核心部分，但其呈现形式多样（如图表），理解多模态大语言模型在验证不同格式证据方面的鲁棒性仍然是一个重要且未被充分探索的挑战。

Method: 设计并进行一系列实验，评估多模态大语言模型使用表格和图表作为证据来验证科学论点的能力。为此，调整了两个现有的科学论文数据集，并加入了多模态声明验证任务所需的注释和结构。使用此调整后的数据集，评估了12个多模态大语言模型。

Result: 在表格证据方面，模型表现优于图表证据。小型多模态大语言模型（小于8B）在表格和图表任务之间的性能相关性较弱，表明其跨模态泛化能力有限。人工评估显示，人类在两种格式上的表现均保持强劲，与模型表现形成对比。

Conclusion: 当前多模态大语言模型在处理科学论点验证任务时，尤其是在理解图表方面存在显著的局限性。未来的模型应更加注重提升图表理解能力，以更好地服务于科学研究的验证需求。

Abstract: With the growing number of submitted scientific papers, there is an increasing demand for systems that can assist reviewers in evaluating research claims. Experimental results are a core component of scientific work, often presented in varying formats such as tables or charts. Understanding how robust current multimodal large language models (multimodal LLMs) are at verifying scientific claims across different evidence formats remains an important and underexplored challenge. In this paper, we design and conduct a series of experiments to assess the ability of multimodal LLMs to verify scientific claims using both tables and charts as evidence. To enable this evaluation, we adapt two existing datasets of scientific papers by incorporating annotations and structures necessary for a multimodal claim verification task. Using this adapted dataset, we evaluate 12 multimodal LLMs and find that current models perform better with table-based evidence while struggling with chart-based evidence. We further conduct human evaluations and observe that humans maintain strong performance across both formats, unlike the models. Our analysis also reveals that smaller multimodal LLMs (under 8B) show weak correlation in performance between table-based and chart-based tasks, indicating limited cross-modal generalization. These findings highlight a critical gap in current models' multimodal reasoning capabilities. We suggest that future multimodal LLMs should place greater emphasis on improving chart understanding to better support scientific claim verification.

</details>


### [71] [ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks](https://arxiv.org/abs/2511.10090)
*Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: Elyadata & LIA 在 2025 年阿拉伯语多方言语音处理挑战赛中，其 ADI 子任务排名第一，多方言阿拉伯语 ASR 子任务排名第二。


<details>
  <summary>Details</summary>
Motivation: 介绍 Elyadata & LIA 参加 2025 年阿拉伯语多方言语音处理挑战赛（NADI）的联合提案，并参与了口语阿拉伯语方言识别（ADI）和多方言阿拉伯语 ASR 子任务。

Method: ADI 子任务：采用经过数据增强的 Whisper-large-v3 编码器进行微调。ASR 子任务：分别对 SeamlessM4T-v2 Large（埃及变体）的八种目标方言进行微调。

Result: ADI 子任务：在官方测试集上获得 79.83% 的最高准确率。ASR 子任务：在测试集上获得的平均词错误率（WER）和字符错误率（CER）分别为 38.54% 和 14.53%。

Conclusion: 大型预训练语音模型结合针对性的微调对于阿拉伯语语音处理非常有效。

Abstract: This paper describes Elyadata \& LIA's joint submission to the NADI multi-dialectal Arabic Speech Processing 2025. We participated in the Spoken Arabic Dialect Identification (ADI) and multi-dialectal Arabic ASR subtasks. Our submission ranked first for the ADI subtask and second for the multi-dialectal Arabic ASR subtask among all participants. Our ADI system is a fine-tuned Whisper-large-v3 encoder with data augmentation. This system obtained the highest ADI accuracy score of \textbf{79.83\%} on the official test set. For multi-dialectal Arabic ASR, we fine-tuned SeamlessM4T-v2 Large (Egyptian variant) separately for each of the eight considered dialects. Overall, we obtained an average WER and CER of \textbf{38.54\%} and \textbf{14.53\%}, respectively, on the test set. Our results demonstrate the effectiveness of large pre-trained speech models with targeted fine-tuning for Arabic speech processing.

</details>


### [72] [On the Military Applications of Large Language Models](https://arxiv.org/abs/2511.10093)
*Satu Johansson,Taneli Riihonen*

Main category: cs.CL

TL;DR: 该论文探讨了自然语言处理（NLP)和大型语言模型（LLM)在军事领域的应用，特别是基于GPT的模型（如Microsoft Copilot）和云服务（如Microsoft Azure）。研究了这些技术如何用于军事场景，并评估了其实施的可行性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM），尤其是生成式预训练Transformer（GPT）模型的出现，激发了人们对其在包括军事在内的各个领域应用的兴趣。本研究的动机是探索和评估LLM在军事领域的潜在用途，以及利用现有商业云服务实现这些应用的可能性。

Method: 该研究采用两种主要方法：首先，通过与基于GPT的模型（Microsoft Copilot）进行交互，探究其自身对军事应用的认知，并对其提供的信息进行批判性评估。其次，研究如何利用商业云服务（Microsoft Azure）来构建这些军事应用，并评估其可行性。

Result: 研究结果表明，语言模型的文本生成和摘要能力可以直接支持多种军事应用。此外，其他功能在特定场景下也具有潜在价值。商业云服务为构建这些应用提供了便利的途径。

Conclusion: 研究得出结论，LLM在军事领域的应用前景广阔，特别是其文本生成和摘要功能。商业云服务可以有效地支持这些应用的开发和部署。

Abstract: In this paper, military use cases or applications and implementation thereof are considered for natural language processing and large language models, which have broken into fame with the invention of the generative pre-trained transformer (GPT) and the extensive foundation model pretraining done by OpenAI for ChatGPT and others. First, we interrogate a GPT-based language model (viz. Microsoft Copilot) to make it reveal its own knowledge about their potential military applications and then critically assess the information. Second, we study how commercial cloud services (viz. Microsoft Azure) could be used readily to build such applications and assess which of them are feasible. We conclude that the summarization and generative properties of language models directly facilitate many applications at large and other features may find particular uses.

</details>


### [73] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 社交媒体在灾难事件监控中至关重要，但现有系统存在事件相关偏差，影响泛化能力。本文提出一种基于因果学习的方法来减少偏差，提升泛化能力，并在三个灾难分类任务上取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体在灾难事件监控中存在事件相关偏差，影响泛化能力，而因果学习和去偏方法在该领域探索不足。

Method: 通过因果视角进行偏差缓解，提出一种减少事件和领域相关偏差的方法，以增强对未来事件的泛化能力。

Result: 所提方法在三个灾难分类任务上，相比多个基线模型，F1分数提升高达+1.9%，并显著改进了基于预训练语言模型（PLM）的分类器。

Conclusion: 提出的基于因果学习的方法能够有效减少社交媒体在灾难事件监控中的偏差，提升模型的泛化能力。

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [74] [Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA](https://arxiv.org/abs/2511.10182)
*Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: VISTA是一个可视化交互式系统，用于分析大型语言模型（LLM）在多轮对话中的推理过程，通过可视化上下文影响、交互式修改对话历史以及生成推理依赖树，降低了研究人员的认知负荷，促进了对LLM能力和局限性的理解。


<details>
  <summary>Details</summary>
Motivation: 现实世界的问题解决通常涉及多轮交互，因此理解大型语言模型（LLM）在这些场景中的推理能力至关重要。然而，现有研究面临分析复杂推理过程的挑战，因为缺乏专门的可视化工具，导致研究人员认知负荷过高。

Method: 提出VISTA，一个基于Web的可视化交互式系统，用于多轮推理任务中文本分析。该系统允许用户可视化上下文对模型决策的影响，交互式地修改对话历史以进行“假设”分析，并自动解析会话以生成推理依赖树，展示模型逐步的逻辑路径。

Result: VISTA提供了一个统一的交互式框架，有效降低了分析推理链的复杂性，从而有助于深入理解当前LLM的能力和局限性。该平台是开源的，并支持轻松集成自定义基准和本地模型。

Conclusion: VISTA通过提供直观的可视化和交互式分析工具，显著简化了对LLM多轮推理过程的理解，为研究人员提供了一个强大的平台来评估和改进LLM的推理能力。

Abstract: Recent research has increasingly focused on the reasoning capabilities of Large Language Models (LLMs) in multi-turn interactions, as these scenarios more closely mirror real-world problem-solving. However, analyzing the intricate reasoning processes within these interactions presents a significant challenge due to complex contextual dependencies and a lack of specialized visualization tools, leading to a high cognitive load for researchers. To address this gap, we present VISTA, an web-based Visual Interactive System for Textual Analytics in multi-turn reasoning tasks. VISTA allows users to visualize the influence of context on model decisions and interactively modify conversation histories to conduct "what-if" analyses across different models. Furthermore, the platform can automatically parse a session and generate a reasoning dependency tree, offering a transparent view of the model's step-by-step logical path. By providing a unified and interactive framework, VISTA significantly reduces the complexity of analyzing reasoning chains, thereby facilitating a deeper understanding of the capabilities and limitations of current LLMs. The platform is open-source and supports easy integration of custom benchmarks and local models.

</details>


### [75] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://arxiv.org/abs/2511.10192)
*Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui*

Main category: cs.CL

TL;DR: 数据驱动的方法解决了文本到SQL领域的数据集稀疏、简单和多样性不足的问题，通过SQLFlow框架生成了大规模、语义有效、结构多样的文本到SQL数据对，并在开源和闭源大模型上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL任务受限于稀疏、简单和多样性不足的数据集，需要新的方法来提高模型性能。

Method: 提出了Text2SQL-Flow框架，这是一个SQL感知的 数据增强框架，包含六个增强维度，并集成了SQL执行验证、自然语言问题生成、思维链推理跟踪和数据分类等端到端流程。还设计了一个模块化的数据库管理器以确保跨数据库兼容性和可扩展性。在此框架下构建了SQLFlow数据集，并提出了掩码对齐检索方法来处理闭源大模型。

Result: SQLFlow数据集包含89,544个标注示例。在开源大模型上，使用SQLFlow微调能持续提升跨基准的性能。对于闭源大模型，提出的掩码对齐检索方法通过对问题和SQL查询之间的细粒度对齐进行建模，实现了结构感知的示例匹配，优于现有方法。

Conclusion: SQLFlow框架为推进文本到SQL系统提供了一个可扩展、以数据为中心的基础，并强调了高质量结构化数据在现代人工智能中的关键作用。

Abstract: The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.

</details>


### [76] [EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2511.10201)
*Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu*

Main category: cs.CL

TL;DR: LLMs通过CoT提示进行推理，但解释冗长。EffiReason-Bench是一个统一的基准，用于评估高效推理方法，涵盖推理蓝图、动态执行和事后精炼。通过标准化推理结构、选项分析和人工验证，为CommonsenseQA和LogiQA构建了CoT注释。在数学、常识和逻辑等4个数据集上评估了7种方法和6个开源LLMs（1B-70B）。提出了E3-Score，一种受经济权衡模型启发的指标，用于评估。实验表明，没有一种方法能普遍占优，最优策略取决于模型规模、任务复杂性和架构。


<details>
  <summary>Details</summary>
Motivation: LLMs通过CoT提示进行推理，但解释冗长，增加了成本并可能降低准确性。碎片化的评估实践阻碍了对面向效率的方法进行公平比较。

Method: 引入EffiReason-Bench，一个统一的基准，用于对高效推理方法进行严格的跨范式评估，涵盖三个类别：推理蓝图、动态执行和事后精炼。通过一个强制执行标准化推理结构、选项分析和人工验证的流水线，为CommonsenseQA和LogiQA构建了经过验证的CoT注释，以实现逐步评估。提出了E3-Score，一个受经济权衡模型启发的指标，提供平滑、稳定的评估。

Result: 在数学、常识和逻辑等4个数据集上，评估了7种方法和6个开源LLMs（1B-70B）。实验表明，没有一种方法能普遍占优，最优策略取决于模型规模、任务复杂性和架构。

Conclusion: EffiReason-Bench提供了一个统一的平台，用于评估高效推理方法。E3-Score提供了一种可靠的评估指标。最佳推理策略是上下文相关的，取决于模型规模、任务复杂性和架构。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) prompting achieve strong reasoning but often produce unnecessarily long explanations, increasing cost and sometimes reducing accuracy. Fair comparison of efficiency-oriented approaches is hindered by fragmented evaluation practices. We introduce EffiReason-Bench, a unified benchmark for rigorous cross-paradigm evaluation of efficient reasoning methods across three categories: Reasoning Blueprints, Dynamic Execution, and Post-hoc Refinement. To enable step-by-step evaluation, we construct verified CoT annotations for CommonsenseQA and LogiQA via a pipeline that enforces standardized reasoning structures, comprehensive option-wise analysis, and human verification. We evaluate 7 methods across 6 open-source LLMs (1B-70B) on 4 datasets spanning mathematics, commonsense, and logic, and propose the E3-Score, a principled metric inspired by economic trade-off modeling that provides smooth, stable evaluation without discontinuities or heavy reliance on heuristics. Experiments show that no single method universally dominates; optimal strategies depend on backbone scale, task complexity, and architecture.

</details>


### [77] [Persona-Aware Alignment Framework for Personalized Dialogue Generation](https://arxiv.org/abs/2511.10215)
*Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai*

Main category: cs.CL

TL;DR: PAL是一个新颖的个性化对话生成框架，通过显式地将“人物画像对齐”作为训练目标，解决了现有模型生成通用回复的问题。


<details>
  <summary>Details</summary>
Motivation: 主流的个性化对话生成模型主要依赖于隐式地从对话数据中学习人物画像，但容易忽略人物画像信息，导致生成通用回复。

Method: PAL框架采用两阶段训练方法：人物画像感知学习和人物画像对齐，并结合“选择后生成”的推理策略，在语义层面提高人物画像的敏感度和相关性。

Result: 通过大量实验证明，PAL框架在生成个性化对话方面优于许多现有技术和大型语言模型。

Conclusion: PAL框架通过显式地将人物画像对齐作为训练目标，能够生成更具人物相关性的回复，有效解决了现有方法的不足。

Abstract: Personalized dialogue generation aims to leverage persona profiles and dialogue history to generate persona-relevant and consistent responses. Mainstream models typically rely on token-level language model training with persona dialogue data, such as Next Token Prediction, to implicitly achieve personalization, making these methods tend to neglect the given personas and generate generic responses. To address this issue, we propose a novel Persona-Aware Alignment Framework (PAL), which directly treats persona alignment as the training objective of dialogue generation. Specifically, PAL employs a two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate, to improve persona sensitivity and generate more persona-relevant responses at the semantics level. Through extensive experiments, we demonstrate that our framework outperforms many state-of-the-art personalized dialogue methods and large language models.

</details>


### [78] [LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning](https://arxiv.org/abs/2511.10229)
*Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: LangGPS是一个两阶段的预选框架，通过语言可分性来指导多语言指令调优的数据选择，以提高LLM的多语言能力，特别是在低资源语言和理解任务上。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言指令调优数据选择方法忽略了多语言数据的内在语言结构，导致模型性能对数据组成非常敏感。

Method: LangGPS首先根据语言可分性分数过滤训练数据，然后使用现有的选择方法对子集进行优化。语言可分性衡量了模型表示空间中区分不同语言样本的能力。

Result: 在六个基准和22种语言上的实验表明，LangGPS可以提高现有选择方法的有效性和泛化能力，尤其对理解任务和低资源语言效果显著。高可分性样本有助于形成清晰的语言边界和更快的适应，而低可分性样本则有助于跨语言对齐。

Conclusion: 语言可分性为多语言指令调优提供了一种新的数据选择视角，并可用于多语言课程学习，以稳定和普遍地获得收益。LangGPS有助于开发更具语言意识的大型语言模型。

Abstract: Joint multilingual instruction tuning is a widely adopted approach to improve the multilingual instruction-following ability and downstream performance of large language models (LLMs), but the resulting multilingual capability remains highly sensitive to the composition and selection of the training data. Existing selection methods, often based on features like text quality, diversity, or task relevance, typically overlook the intrinsic linguistic structure of multilingual data. In this paper, we propose LangGPS, a lightweight two-stage pre-selection framework guided by language separability which quantifies how well samples in different languages can be distinguished in the model's representation space. LangGPS first filters training data based on separability scores and then refines the subset using existing selection methods. Extensive experiments across six benchmarks and 22 languages demonstrate that applying LangGPS on top of existing selection methods improves their effectiveness and generalizability in multilingual training, especially for understanding tasks and low-resource languages. Further analysis reveals that highly separable samples facilitate the formation of clearer language boundaries and support faster adaptation, while low-separability samples tend to function as bridges for cross-lingual alignment. Besides, we also find that language separability can serve as an effective signal for multilingual curriculum learning, where interleaving samples with diverse separability levels yields stable and generalizable gains. Together, we hope our work offers a new perspective on data utility in multilingual contexts and support the development of more linguistically informed LLMs.

</details>


### [79] [VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction](https://arxiv.org/abs/2511.10232)
*Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: VocalNet-M2 是一种新型低延迟语音语言模型，通过多码本分词和多令牌预测策略，显著降低了响应延迟，同时保持了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的端到端语音语言模型（SLM）存在响应延迟问题，主要是由于语音令牌的自回归生成和对复杂流匹配模型语音合成的依赖。

Method: 提出了一种名为 VocalNet-M2 的新型低延迟 SLM，该模型集成了多码本分词器和多令牌预测（MTP）策略，直接生成多码本语音令牌，无需延迟诱导的流匹配模型，并通过 MTP 策略提高生成效率。

Result: 实验表明，VocalNet-M2 将首块延迟从约 725 毫秒减少到 350 毫秒，同时在主流 SLM 中保持了有竞争力的性能。

Conclusion: VocalNet-M2 成功降低了语音语言模型的延迟，并提供了单码本和多码本策略的比较，为实时交互应用提供了有价值的见解。

Abstract: Current end-to-end spoken language models (SLMs) have made notable progress, yet they still encounter considerable response latency. This delay primarily arises from the autoregressive generation of speech tokens and the reliance on complex flow-matching models for speech synthesis. To overcome this, we introduce VocalNet-M2, a novel low-latency SLM that integrates a multi-codebook tokenizer and a multi-token prediction (MTP) strategy. Our model directly generates multi-codebook speech tokens, thus eliminating the need for a latency-inducing flow-matching model. Furthermore, our MTP strategy enhances generation efficiency and improves overall performance. Extensive experiments demonstrate that VocalNet-M2 achieves a substantial reduction in first chunk latency (from approximately 725ms to 350ms) while maintaining competitive performance across mainstream SLMs. This work also provides a comprehensive comparison of single-codebook and multi-codebook strategies, offering valuable insights for developing efficient and high-performance SLMs for real-time interactive applications.

</details>


### [80] [MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models](https://arxiv.org/abs/2511.10262)
*He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King*

Main category: cs.CL

TL;DR: FD-SLMs 实现了实时、重叠的对话交互，但现有基准忽略了多轮通信和指令遵循/安全等关键能力。我们提出了 MTR-DuplexBench，一个用于评估 FD-SLMs 的新基准，该基准将连续的 FD 对话分割成离散的回合，以评估对话质量、对话动态、指令遵循和安全。实验表明，当前的 FD-SLMs 在多轮和评估维度上保持一致性能方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 评估全双工语音语言模型（FD-SLMs）在多轮通信、指令遵循和安全方面存在挑战，因为现有的基准主要关注单轮交互，并且在模糊的回合边界和模型推理中的上下文不一致方面存在问题。

Method: 通过将连续的全双工对话分割成离散的回合，来对 FD-SLMs 进行全面的、逐回合的评估，涵盖对话质量、对话动态、指令遵循和安全。为解决这些挑战，我们提出了 MTR-DuplexBench。

Result: 实验结果表明，当前的 FD-SLMs 在跨多个回合和评估维度保持一致性能方面面临困难。

Conclusion: MTR-DuplexBench 对于全面评估 FD-SLMs 的多轮通信能力至关重要，并强调了在指令遵循和安全方面需要进一步改进 FD-SLMs。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions and conversational features, neglecting the complexities of multi-round communication and critical capabilities such as instruction following and safety. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in communication and context inconsistency during model inference. To address these gaps, we introduce MTR-DuplexBench, a novel benchmark that segments continuous full-duplex dialogues into discrete turns, enabling comprehensive, turn-by-turn evaluation of FD-SLMs across dialogue quality, conversational dynamics, instruction following, and safety. Experimental results reveal that current FD-SLMs face difficulties in maintaining consistent performance across multiple rounds and evaluation dimensions, highlighting the necessity and effectiveness of our proposed benchmark. The benchmark and code will be available in the future.

</details>


### [81] [Local Hybrid Retrieval-Augmented Document QA](https://arxiv.org/abs/2511.10297)
*Paolo Astrino*

Main category: cs.CL

TL;DR: 该问答系统结合了语义理解和关键词精度，能在本地基础设施上完全运行，无需联网，解决了在数据隐私和问答准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决组织在处理敏感文件时面临的数据隐私和问答准确性之间的困境，即使用云 AI 会损害隐私，而本地处理准确性又很差。

Method: 结合语义理解和关键词精度，在本地基础设施上完全运行，无需互联网访问，并利用消费级硬件加速。

Result: 在处理法律、科学和对话文档的复杂查询时，能达到具有竞争力的准确性，同时将所有数据保留在本地机器上，错误率极低。

Conclusion: 隐私和性能不必在企业 AI 部署中相互排斥，即使在本地部署，组织也能获得高准确性的问答能力，而无需传输专有信息。

Abstract: Organizations handling sensitive documents face a critical dilemma: adopt cloud-based AI systems that offer powerful question-answering capabilities but compromise data privacy, or maintain local processing that ensures security but delivers poor accuracy. We present a question-answering system that resolves this trade-off by combining semantic understanding with keyword precision, operating entirely on local infrastructure without internet access. Our approach demonstrates that organizations can achieve competitive accuracy on complex queries across legal, scientific, and conversational documents while keeping all data on their machines. By balancing two complementary retrieval strategies and using consumer-grade hardware acceleration, the system delivers reliable answers with minimal errors, letting banks, hospitals, and law firms adopt conversational document AI without transmitting proprietary information to external providers. This work establishes that privacy and performance need not be mutually exclusive in enterprise AI deployment.

</details>


### [82] [Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning](https://arxiv.org/abs/2511.10303)
*Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo*

Main category: cs.CL

TL;DR: LLMs在数学推理中的批判能力有待提高，这主要是由于它们在评估解决方案时存在不平衡的偏好。本文提出了一种新颖的、感知困惑度的强化学习算法来纠正这种偏好，从而提高LLMs的批判能力。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLMs）在多步数学推理（MsMR）中的能力，关键在于从语料库中获得可扩展的监督，通过自动批判MsMR推理过程中的错误并对问题解决方案做出最终裁决。现有方法大多依赖于精心设计高质量的监督微调示范来增强批判能力，但对探究LLMs批判能力差的根本原因关注甚少。

Method: 提出了一种新颖的、感知困惑度的强化学习算法来纠正评估偏好。具体来说，为了探究LLMs的批判特征，构建了一个一对多问题解决方案（OPS）基准来量化LLMs在评估自身和其他模型生成的解决方案时的行为差异。然后，为了深入研究行为差异，进行了以困惑度为导向的统计偏好分析，发现了一个有趣的现象——“LLMs倾向于将困惑度较低的解决方案判定为正确”，这被称为“不平衡评估偏好”。为了纠正这种偏好，将困惑度作为组相对策略优化算法中的“指挥棒”，支持LLMs探索将较低困惑度判定为错误、较高困惑度判定为正确的轨迹。

Result: 在自建的OPS基准和现有的可用批判基准上进行了广泛的实验，证明了所提出方法的有效性。

Conclusion: 所提出的新颖的、感知困惑度的强化学习算法能有效纠正LLMs在数学推理评估中的不平衡偏好，从而显著提高其批判能力。该方法通过OPS基准和统计偏好分析揭示了LLMs的评估行为，并成功地利用困惑度来指导模型进行更准确的评估。

Abstract: To improve Multi-step Mathematical Reasoning (MsMR) of Large Language Models (LLMs), it is crucial to obtain scalable supervision from the corpus by automatically critiquing mistakes in the reasoning process of MsMR and rendering a final verdict of the problem-solution. Most existing methods rely on crafting high-quality supervised fine-tuning demonstrations for critiquing capability enhancement and pay little attention to delving into the underlying reason for the poor critiquing performance of LLMs. In this paper, we orthogonally quantify and investigate the potential reason -- imbalanced evaluation preference, and conduct a statistical preference analysis. Motivated by the analysis of the reason, a novel perplexity-aware reinforcement learning algorithm is proposed to rectify the evaluation preference, elevating the critiquing capability. Specifically, to probe into LLMs' critiquing characteristics, a One-to-many Problem-Solution (OPS) benchmark is meticulously constructed to quantify the behavior difference of LLMs when evaluating the problem solutions generated by itself and others. Then, to investigate the behavior difference in depth, we conduct a statistical preference analysis oriented on perplexity and find an intriguing phenomenon -- ``LLMs incline to judge solutions with lower perplexity as correct'', which is dubbed as \textit{imbalanced evaluation preference}. To rectify this preference, we regard perplexity as the baton in the algorithm of Group Relative Policy Optimization, supporting the LLMs to explore trajectories that judge lower perplexity as wrong and higher perplexity as correct. Extensive experimental results on our built OPS and existing available critic benchmarks demonstrate the validity of our method.

</details>


### [83] [BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages](https://arxiv.org/abs/2511.10338)
*Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 合成数据是预训练大语言模型（LLMs）的替代方案，尤其是在低资源语言环境中。本研究系统研究了用于印度语言的合成多语言预训练数据的生成和评估，构建了一个包含540B个token、涵盖10种语言的大规模合成数据集BhashaKritika。


<details>
  <summary>Details</summary>
Motivation: 低资源语言环境中，大语言模型（LLMs）的优势分布不均，需要生成高质量的预训练数据。本研究旨在为印度语言提供大规模合成多语言预训练数据。

Method: 构建了一个包含540B个token、涵盖10种语言的大规模合成数据集BhashaKritika，并探索了基于文档、个人和主题的生成方法。分析了提示指令和文档基础中的语言选择对数据质量的影响，并比较了英语内容的翻译与印度本地语言生成。引入了一个模块化的质量评估流程，集成了脚本和语言检测、元数据一致性检查、n-gram重复分析以及使用KenLM模型的困惑度过滤。

Result: 通过模型运行的实证结果揭示了生成策略的关键权衡，并强调了构建有效多语言语料库的最佳实践。

Conclusion: 本研究系统地研究了印度语言的合成多语言预训练数据的生成和评估，构建了大规模数据集BhashaKritika，并提出了一个稳健的质量评估框架，为低资源语言的LLMs预训练提供了指导。

Abstract: In the context of pretraining of Large Language Models (LLMs), synthetic data has emerged as an alternative for generating high-quality pretraining data at scale. This is particularly beneficial in low-resource language settings where the benefits of recent LLMs have been unevenly distributed across languages. In this work, we present a systematic study on the generation and evaluation of synthetic multilingual pretraining data for Indic languages, where we construct a large-scale synthetic dataset BhashaKritika, comprising 540B tokens using 5 different techniques for 10 languages. We explore the impact of grounding generation in documents, personas, and topics. We analyze how language choice, both in the prompt instructions and document grounding, affects data quality, and we compare translations of English content with native generation in Indic languages. To support scalable and language-sensitive evaluation, we introduce a modular quality evaluation pipeline that integrates script and language detection, metadata consistency checks, n-gram repetition analysis, and perplexity-based filtering using KenLM models. Our framework enables robust quality control across diverse scripts and linguistic contexts. Empirical results through model runs reveal key trade-offs in generation strategies and highlight best practices for constructing effective multilingual corpora.

</details>


### [84] [Knowledge Graphs Generation from Cultural Heritage Texts: Combining LLMs and Ontological Engineering for Scholarly Debates](https://arxiv.org/abs/2511.10354)
*Andrea Schimmenti,Valentina Pasqual,Fabio Vitali,Marieke van Erp*

Main category: cs.CL

TL;DR: 本文提出了一种名为ATR4CH的自适应文本到RDF方法，用于从文化遗产文本中提取知识，并构建知识图谱，通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 文化遗产文本包含丰富知识，但将其转换为结构化知识图谱存在挑战。

Method: ATR4CH方法结合了注释模型、本体框架和大型语言模型（LLMs）进行知识提取，包括基础分析、注释模式开发、管道架构、集成优化和全面评估，并使用多个LLMs进行验证。

Result: 该方法在元数据提取、实体识别、假设提取、证据提取和话语表示方面取得了高F1分数，表明能够有效提取复杂的文化遗产知识，且小型模型表现具有竞争力。

Conclusion: ATR4CH是首个将基于LLM的提取与文化遗产本体相结合的系统化方法，为文化遗产机构提供了一个可复制且可适应的框架，能够将文本知识转化为可查询的知识图谱，支持知识发现和元数据丰富。然而，目前的知识图谱仅限于维基百科文章，并且在后处理阶段需要人工监督。

Abstract: Cultural Heritage texts contain rich knowledge that is difficult to query systematically due to the challenges of converting unstructured discourse into structured Knowledge Graphs (KGs). This paper introduces ATR4CH (Adaptive Text-to-RDF for Cultural Heritage), a systematic five-step methodology for Large Language Model-based Knowledge Extraction from Cultural Heritage documents. We validate the methodology through a case study on authenticity assessment debates. Methodology - ATR4CH combines annotation models, ontological frameworks, and LLM-based extraction through iterative development: foundational analysis, annotation schema development, pipeline architecture, integration refinement, and comprehensive evaluation. We demonstrate the approach using Wikipedia articles about disputed items (documents, artifacts...), implementing a sequential pipeline with three LLMs (Claude Sonnet 3.7, Llama 3.3 70B, GPT-4o-mini). Findings - The methodology successfully extracts complex Cultural Heritage knowledge: 0.96-0.99 F1 for metadata extraction, 0.7-0.8 F1 for entity recognition, 0.65-0.75 F1 for hypothesis extraction, 0.95-0.97 for evidence extraction, and 0.62 G-EVAL for discourse representation. Smaller models performed competitively, enabling cost-effective deployment. Originality - This is the first systematic methodology for coordinating LLM-based extraction with Cultural Heritage ontologies. ATR4CH provides a replicable framework adaptable across CH domains and institutional resources. Research Limitations - The produced KG is limited to Wikipedia articles. While the results are encouraging, human oversight is necessary during post-processing. Practical Implications - ATR4CH enables Cultural Heritage institutions to systematically convert textual knowledge into queryable KGs, supporting automated metadata enrichment and knowledge discovery.

</details>


### [85] [TruthfulRAG: Resolving Factual-level Conflicts in Retrieval-Augmented Generation with Knowledge Graphs](https://arxiv.org/abs/2511.10375)
*Shuyi Liu,Yuming Shang,Xi Zhang*

Main category: cs.CL

TL;DR: TruthfulRAG是一个首创的框架，利用知识图谱（KG）解决检索增强生成（RAG）系统中事实层面的知识冲突，通过提取三元组、基于查询的图检索和基于熵的过滤来定位冲突并减轻不一致性，从而提高RAG系统的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统的挑战在于解决检索到的外部信息与LLM内部知识之间的冲突，而现有的冲突解决通常在token或语义层面进行，导致对事实差异的理解不完整。知识图谱（KG）可以提供更丰富的事实层面信息来解决此问题。

Method: TruthfulRAG通过以下步骤构建和利用KG：1. 从检索到的内容中提取三元组以构建KG。2. 利用基于查询的图检索来寻找相关知识。3. 使用基于熵的过滤机制来精确定位冲突元素并减轻事实不一致性。

Result: 在知识密集型任务的广泛实验中，TruthfulRAG被证明优于现有方法，能够有效缓解知识冲突，提高RAG系统的鲁棒性和可信度。

Conclusion: TruthfulRAG是第一个利用KG解决RAG中事实知识冲突的框架，通过其独特的KG构建和冲突解决机制，显著提高了生成内容的准确性和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for enhancing the capabilities of Large Language Models (LLMs) by integrating retrieval-based methods with generative models. As external knowledge repositories continue to expand and the parametric knowledge within models becomes outdated, a critical challenge for RAG systems is resolving conflicts between retrieved external information and LLMs' internal knowledge, which can significantly compromise the accuracy and reliability of generated content. However, existing approaches to conflict resolution typically operate at the token or semantic level, often leading to fragmented and partial understanding of factual discrepancies between LLMs' knowledge and context, particularly in knowledge-intensive tasks. To address this limitation, we propose TruthfulRAG, the first framework that leverages Knowledge Graphs (KGs) to resolve factual-level knowledge conflicts in RAG systems. Specifically, TruthfulRAG constructs KGs by systematically extracting triples from retrieved content, utilizes query-based graph retrieval to identify relevant knowledge, and employs entropy-based filtering mechanisms to precisely locate conflicting elements and mitigate factual inconsistencies, thereby enabling LLMs to generate faithful and accurate responses. Extensive experiments reveal that TruthfulRAG outperforms existing methods, effectively alleviating knowledge conflicts and improving the robustness and trustworthiness of RAG systems.

</details>


### [86] [Position: On the Methodological Pitfalls of Evaluating Base LLMs for Reasoning](https://arxiv.org/abs/2511.10381)
*Jason Chan,Zhixue Zhao,Robert Gaizauskas*

Main category: cs.CL

TL;DR: 评估基础大语言模型（LLM）的推理能力存在方法论上的固有问题，因为其预训练目标与推理评估的规范质量（如正确性）之间存在根本性不匹配。基础LLM生成的逻辑有效或无效的结论仅仅是遵循统计学上合理性的语言模式的巧合副产品。这挑战了基础LLM的输出可以被视为其真实尝试的正确答案，以及关于基础LLM推理的结论可以推广到经过指令遵循优化后的LLM的假设。文章呼吁批判性地重新审视现有工作，并为未来的工作考虑这些方法论上的陷阱。


<details>
  <summary>Details</summary>
Motivation: 现有工作旨在揭示基础大语言模型（LLM）的推理局限性、类人偏见和潜在过程，但忽略了评估基础LLM推理能力所带来的方法论上的固有问题。

Method: 通过分析基础LLM的预训练目标与其推理评估的规范质量（如正确性）之间的根本性不匹配，揭示了基础LLM生成的逻辑有效或无效的结论仅仅是遵循统计学上合理性的语言模式的巧合副产品。

Result: 基础LLM的输出可以被视为其真实尝试的正确答案，以及关于基础LLM推理的结论可以推广到经过指令遵循优化后的LLM的假设受到挑战。

Conclusion: 文章呼吁批判性地重新审视现有工作，并为未来的工作考虑这些方法论上的陷阱。

Abstract: Existing work investigates the reasoning capabilities of large language models (LLMs) to uncover their limitations, human-like biases and underlying processes. Such studies include evaluations of base LLMs (pre-trained on unlabeled corpora only) for this purpose. Our position paper argues that evaluating base LLMs' reasoning capabilities raises inherent methodological concerns that are overlooked in such existing studies. We highlight the fundamental mismatch between base LLMs' pretraining objective and normative qualities, such as correctness, by which reasoning is assessed. In particular, we show how base LLMs generate logically valid or invalid conclusions as coincidental byproducts of conforming to purely linguistic patterns of statistical plausibility. This fundamental mismatch challenges the assumptions that (a) base LLMs' outputs can be assessed as their bona fide attempts at correct answers or conclusions; and (b) conclusions about base LLMs' reasoning can generalize to post-trained LLMs optimized for successful instruction-following. We call for a critical re-examination of existing work that relies implicitly on these assumptions, and for future work to account for these methodological pitfalls.

</details>


### [87] [DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence](https://arxiv.org/abs/2511.10404)
*Cristian Santini,Sebastian Barzaghi,Paolo Sernani,Emanuele Frontoni,Mehwish Alam*

Main category: cs.CL

TL;DR: 本文提出了一种名为DELICATE的新型神经符号学方法，并构建了一个名为ENEIDE的新型意大利语历史实体链接语料库，以解决人文学科领域实体链接的挑战。


<details>
  <summary>Details</summary>
Motivation: 人文学科领域实体链接面临复杂文档类型、缺乏领域特定数据集和模型以及长尾实体（知识库中代表性不足的实体）等挑战。

Method: DELICATE方法结合了基于BERT的编码器和来自Wikidata的上下文信息，利用时间可行性和实体类型一致性来选择合适的知识库实体。ENEIDE语料库是从19世纪和20世纪的文学和政治文本注释版本中半自动提取的。

Result: DELICATE方法在意大利语历史实体链接任务上表现优于其他模型，即使与参数量更大的模型相比也是如此。此外，DELICATE的置信分数和特征敏感性提供了比纯神经方法更具可解释性的结果。

Conclusion: DELICATE方法和ENEIDE语料库为解决意大利语历史实体链接的挑战提供了有效的方法，并展示了神经符号学方法在处理复杂领域数据方面的潜力。

Abstract: In spite of the remarkable advancements in the field of Natural Language Processing, the task of Entity Linking (EL) remains challenging in the field of humanities due to complex document typologies, lack of domain-specific datasets and models, and long-tail entities, i.e., entities under-represented in Knowledge Bases (KBs). The goal of this paper is to address these issues with two main contributions. The first contribution is DELICATE, a novel neuro-symbolic method for EL on historical Italian which combines a BERT-based encoder with contextual information from Wikidata to select appropriate KB entities using temporal plausibility and entity type consistency. The second contribution is ENEIDE, a multi-domain EL corpus in historical Italian semi-automatically extracted from two annotated editions spanning from the 19th to the 20th century and including literary and political texts. Results show how DELICATE outperforms other EL models in historical Italian even if compared with larger architectures with billions of parameters. Moreover, further analyses reveal how DELICATE confidence scores and features sensitivity provide results which are more explainable and interpretable than purely neural methods.

</details>


### [88] [Analogical Structure, Minimal Contextual Cues and Contrastive Distractors: Input Design for Sample-Efficient Linguistic Rule Induction](https://arxiv.org/abs/2511.10441)
*Chunyang Jiang,Paola Merlo*

Main category: cs.CL

TL;DR: 通过类比范式组织，轻量级模型能够以极少数据匹配大型模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过类比范式组织，使轻量级模型能够以最小的数据量匹配大型语言模型的性能。

Method: 提出一种计算方法，结合类比结构、对比学习和最小上下文线索。在结构化完成任务中进行测试，模型从类比模式和对比选项中识别正确的句子。

Result: 使用仅包含100个结构化英语致使/不致使转换示例来训练轻量级模型（BERT+CNN，$0.5M$参数），实现了$F1=0.95$的性能，优于零样本GPT-3（$F1=0.87$）。消融研究证实了类比组织和对比结构的有效性。跨现象验证也证实了该方法的稳健性。

Conclusion: 类比范式组织能够实现高效的语言规则学习，所需数据量远少于传统方法。

Abstract: Large language models achieve strong performance through training on vast datasets. Can analogical paradigm organization enable lightweight models to match this performance with minimal data? We develop a computational approach implementing three cognitive-inspired principles: analogical structure, contrastive learning, and minimal contextual cues. We test this approach with structured completion tasks where models identify correct sentence completions from analogical patterns with contrastive alternatives. Training lightweight models (BERT+CNN, $0.5M$ parameters) on only one hundred structured examples of English causative/inchoative alternations achieves $F1=0.95$, outperforming zero-shot \texttt{GPT-o3} ($F1=0.87$). Ablation studies confirm that analogical organization and contrastive structure improve performance, consistently surpassing randomly shuffled baselines across architectures. Cross-phenomenon validation using unspecified object alternations replicates these efficiency gains, confirming approach robustness. Our results show that analogical paradigm organization enables competitive linguistic rule learning with orders of magnitude less data than conventional approaches require.

</details>


### [89] [Reasoning About Intent for Ambiguous Requests](https://arxiv.org/abs/2511.10453)
*Irina Saparina,Mirella Lapata*

Main category: cs.CL

TL;DR: 大型语言模型在处理歧义请求时，可以通过生成多个解释-答案对来提高准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在处理歧义请求时，常常默认一种解释而导致的误解和安全风险。

Method: 通过强化学习和定制化的奖励函数，训练模型为歧义请求生成多个解释-答案对。

Result: 实验表明，该方法在对话问答和语义解析任务上，相比基线方法能覆盖更多的有效答案，并且人类评估也证实了解释与答案的高度一致性。

Conclusion: 所提出的方法通过明确解释提高了透明度，通过单次生成实现了效率，并通过结构化输出来支持下游应用。

Abstract: Large language models often respond to ambiguous requests by implicitly committing to one interpretation. Intent misunderstandings can frustrate users and create safety risks. To address this, we propose generating multiple interpretation-answer pairs in a single structured response to ambiguous requests. Our models are trained with reinforcement learning and customized reward functions using multiple valid answers as supervision. Experiments on conversational question answering and semantic parsing demonstrate that our method achieves higher coverage of valid answers than baseline approaches. Human evaluation confirms that predicted interpretations are highly aligned with their answers. Our approach promotes transparency with explicit interpretations, achieves efficiency by requiring only one generation step, and supports downstream applications through its structured output format.

</details>


### [90] [Exploring State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2511.10457)
*Kiamehr Rezaee,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: LLMs（如GPT-4和Llama3）能够进行状态跟踪，尤其是在结合了思维链等机制后。但旧一代模型在复杂场景下会失败。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在状态跟踪任务上的表现，以分离和分析其状态跟踪能力。

Method: 提出一个基于三个明确定义的状态跟踪任务的基准，并分析LLMs在不同场景下的性能。

Result: GPT-4和Llama3在状态跟踪任务上表现出能力，特别是结合思维链时。旧一代模型在初始阶段能解决问题，但在后续步骤中会失败。

Conclusion: 虽然新一代LLMs具有状态跟踪能力，但旧一代模型在此任务的长期执行中存在局限性。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in solving complex tasks, including those requiring a certain level of reasoning. In this paper, we focus on state tracking, a problem where models need to keep track of the state governing a number of entities. To isolate the state tracking component from other factors, we propose a benchmark based on three well-defined state tracking tasks and analyse the performance of LLMs in different scenarios. The results indicate that the recent generation of LLMs (specifically, GPT-4 and Llama3) are capable of tracking state, especially when integrated with mechanisms such as Chain of Thought. However, models from the former generation, while understanding the task and being able to solve it at the initial stages, often fail at this task after a certain number of steps.

</details>


### [91] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: LLMs在处理宏观地理任务方面表现良好，但在理解超本地知识方面存在不足。本研究提出了LocalBench，一个包含14,782个问答对的基准测试，用于评估LLMs在县级本地知识方面的能力。结果显示，即使是最好的模型在叙述性问题上的准确率也仅为56.8%，在数值推理方面低于15.5%。模型大小和网络增强对性能的影响不确定。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的应用，如公民平台和社区新闻，需要能够理解社区动态、文化叙事和地方治理的人工智能系统。现有基准测试在捕捉这种复杂性方面存在不足，因此需要一个专门用于评估LLMs在县级本地知识方面能力的基准测试。

Method: 构建了一个名为LocalBench的基准测试，包含14,782个经过验证的问答对，覆盖美国526个县，整合了人口普查数据、本地讨论区和地区新闻等多种来源。该基准测试涵盖了地理位置的物理、认知和关系维度。然后，在封闭书籍和网络增强两种设置下，评估了13个最先进的LLMs。

Result: 研究发现，即使是表现最好的模型，在处理叙述性问题时准确率也仅达到56.8%，在进行数值推理时准确率低于15.5%。模型规模的增大和网络增强对性能的提升并不总是带来积极影响，例如，网络搜索提升了Gemini的准确率，但降低了GPT系列模型的表现。

Conclusion: 现有的LLMs在处理超本地知识方面存在显著局限性，即使是最大的模型和经过网络增强的模型也难以达到令人满意的准确率，尤其是在叙述性和数值推理方面。这凸显了开发能够理解和支持地方社区多样化、细微现实的AI系统的迫切需求。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [92] [Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks](https://arxiv.org/abs/2511.10465)
*Yunzhe Xu,Zhuosheng Zhang,Zhe Liu*

Main category: cs.CL

TL;DR: KPPO通过整合知识来优化提示，解决了现有基于引发的方法在知识密集型任务中的局限性，在15个基准测试中平均提高了6%的性能，同时保持了相似或更低的令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 现有基于引发的提示优化方法在知识密集型任务中存在局限性，无法提供专业领域所需的 factual knowledge, terminology precision, and reasoning patterns。 

Method: 提出了一种名为KPPO的知识注入型提示优化框架，该框架通过以下三个机制进行优化：1. 知识填补机制，用于识别和弥补知识差距；2. 批处理候选评估方法，同时考虑性能提升和分布稳定性；3. 自适应知识剪枝策略，以平衡性能和令牌效率。

Result: 在15个知识密集型基准测试中，KPPO的平均性能比最强的基线提高了约6%，同时令牌消耗相当或更低，并且令牌使用量减少了高达29%。

Conclusion: KPPO框架通过系统地整合知识，优于基于引发的方法，能够有效地处理知识密集型任务，并在性能和效率之间取得良好平衡。

Abstract: While prompt optimization has emerged as a critical technique for enhancing language model performance, existing approaches primarily focus on elicitation-based strategies that search for optimal prompts to activate models' capabilities. These methods exhibit fundamental limitations when addressing knowledge-intensive tasks, as they operate within fixed parametric boundaries rather than providing the factual knowledge, terminology precision, and reasoning patterns required in specialized domains. To address these limitations, we propose Knowledge-Provision-based Prompt Optimization (KPPO), a framework that reformulates prompt optimization as systematic knowledge integration rather than potential elicitation. KPPO introduces three key innovations: 1) a knowledge gap filling mechanism for knowledge gap identification and targeted remediation; 2) a batch-wise candidate evaluation approach that considers both performance improvement and distributional stability; 3) an adaptive knowledge pruning strategy that balances performance and token efficiency, reducing up to 29% token usage. Extensive evaluation on 15 knowledge-intensive benchmarks from various domains demonstrates KPPO's superiority over elicitation-based methods, with an average performance improvement of ~6% over the strongest baseline while achieving comparable or lower token consumption. Code at: https://github.com/xyz9911/KPPO.

</details>


### [93] [Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following](https://arxiv.org/abs/2511.10507)
*Yun He,Wenzhe Li,Hejia Zhang,Songlin Li,Karishma Mandyam,Sopan Khosla,Yuanhao Xiong,Nanshu Wang,Selina Peng,Beibin Li,Shengjie Bi,Shishir G. Patil,Qi Qi,Shengyu Feng,Julian Katz-Samuels,Richard Yuanzhe Pang,Sujan Gonugondla,Hunter Lang,Yue Yu,Yundi Qian,Maryam Fazel-Zarandi,Licheng Yu,Amine Benhalloum,Hany Awadalla,Manaal Faruqui*

Main category: cs.CL

TL;DR: LLMs在遵循复杂指令方面仍有挑战，本研究提出了AdvancedIF基准和RIFL训练框架，显著提升了LLMs的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 评估和训练大型语言模型（LLMs）遵循复杂指令（尤其是多轮和系统提示指令）的能力面临挑战，缺乏高质量的基准和可靠的奖励信号。

Method: 提出AdvancedIF基准，包含1600多个提示和专家制定的评分标准；提出RIFL训练框架，包括评分标准生成、微调的评分验证器和奖励塑造，用于指令遵循的强化学习。

Result: RIFL显著提高了LLMs的指令遵循能力，在AdvancedIF基准上实现了6.7%的绝对提升，并在公开基准上也取得了良好结果。消融实验验证了RIFL各组成部分的有效性。

Conclusion: 评分标准是训练和评估LLMs高级指令遵循能力的有效工具，有助于构建更强大、更可靠的AI系统。

Abstract: Recent progress in large language models (LLMs) has led to impressive performance on a range of tasks, yet advanced instruction following (IF)-especially for complex, multi-turn, and system-prompted instructions-remains a significant challenge. Rigorous evaluation and effective training for such capabilities are hindered by the lack of high-quality, human-annotated benchmarks and reliable, interpretable reward signals. In this work, we introduce AdvancedIF (we will release this benchmark soon), a comprehensive benchmark featuring over 1,600 prompts and expert-curated rubrics that assess LLMs ability to follow complex, multi-turn, and system-level instructions. We further propose RIFL (Rubric-based Instruction-Following Learning), a novel post-training pipeline that leverages rubric generation, a finetuned rubric verifier, and reward shaping to enable effective reinforcement learning for instruction following. Extensive experiments demonstrate that RIFL substantially improves the instruction-following abilities of LLMs, achieving a 6.7% absolute gain on AdvancedIF and strong results on public benchmarks. Our ablation studies confirm the effectiveness of each component in RIFL. This work establishes rubrics as a powerful tool for both training and evaluating advanced IF in LLMs, paving the way for more capable and reliable AI systems.

</details>


### [94] [LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025](https://arxiv.org/abs/2511.10515)
*Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma*

Main category: cs.CL

TL;DR: LOCA-R框架在CPhO 2025物理竞赛理论考试中取得优异成绩，接近满分，超越人类最高分和基线方法。


<details>
  <summary>Details</summary>
Motivation: 评估和提升AI在奥赛级物理问题解决方面的能力，特别是CPhO这类复杂且深入的考试。

Method: 提出并应用名为LOCA-R（LOgical Chain Augmentation for Reasoning）的改进框架，该框架是LOCA框架的升级版，旨在处理复杂推理任务。

Result: LOCA-R在CPhO 2025理论考试中获得了313/320的高分，超过了最高分的人类选手，并显著优于所有基线方法。

Conclusion: LOCA-R框架在解决奥赛级物理问题方面表现出强大能力，证明了其在复杂推理和物理原理掌握方面的潜力。

Abstract: Olympiad-level physics problem-solving presents a significant challenge for both humans and artificial intelligence (AI), as it requires a sophisticated integration of precise calculation, abstract reasoning, and a fundamental grasp of physical principles. The Chinese Physics Olympiad (CPhO), renowned for its complexity and depth, serves as an ideal and rigorous testbed for these advanced capabilities. In this paper, we introduce LOCA-R (LOgical Chain Augmentation for Reasoning), an improved version of the LOCA framework adapted for complex reasoning, and apply it to the CPhO 2025 theory examination. LOCA-R achieves a near-perfect score of 313 out of 320 points, solidly surpassing the highest-scoring human competitor and significantly outperforming all baseline methods.

</details>


### [95] [Say It Differently: Linguistic Styles as Jailbreak Vectors](https://arxiv.org/abs/2511.10519)
*Srikant Panda,Avinash Rai*

Main category: cs.CL

TL;DR: 语言风格可以被用作攻击大型语言模型的潜在途径，即使是经过安全对齐的模型也可能受到影响。本研究系统地探讨了包括恐惧、好奇心在内的不同语言风格如何诱导模型产生不安全响应。通过构建包含11种不同语言风格的增强型越狱基准测试，并在16个模型上进行评估，发现语言风格的重构可以使越狱成功率最高提高57%。其中，恐惧、好奇和富有同情心的风格最为有效，并且上下文重写优于模板化重写。为应对此问题，研究提出了一种风格中和预处理方法，通过使用次级大型语言模型去除用户输入中的操纵性风格线索，显著降低了越狱成功率。研究结果揭示了当前安全防护中被忽视的一个系统性且抗扩展的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注对大型语言模型的对抗性攻击，例如通过释义或语义等价的越狱提示词，但忽视了语言风格作为攻击面的潜力。本研究旨在系统地研究语言风格（如恐惧、好奇）如何重构有害意图并诱导已对齐模型产生不安全响应。

Method: 构建了一个风格增强的越狱基准测试，将3个标准数据集的提示词转换为11种不同的语言风格。使用了手工模板和基于大型语言模型（LLM）的重写方法，同时保持了原始语义意图。在16个开源和闭源的指令微调模型上进行了评估。最后，提出了一种使用次级LLM进行风格中和的预处理步骤来减轻攻击。

Result: 在16个模型上的评估显示，语言风格的重构最高可使越狱成功率提高57个百分点。其中，恐惧、好奇和富有同情心的风格最为有效。上下文重写的效果优于模板化重写。风格中和预处理步骤显著降低了越狱成功率。

Conclusion: 语言风格是大型语言模型的一个系统性且抗扩展的漏洞，被当前的安全防护措施所忽视。通过操纵语言风格可以有效地诱导模型产生不安全响应。然而，通过风格中和预处理技术可以有效缓解此类攻击。

Abstract: Large Language Models (LLMs) are commonly evaluated for robustness against paraphrased or semantically equivalent jailbreak prompts, yet little attention has been paid to linguistic variation as an attack surface. In this work, we systematically study how linguistic styles such as fear or curiosity can reframe harmful intent and elicit unsafe responses from aligned models. We construct style-augmented jailbreak benchmark by transforming prompts from 3 standard datasets into 11 distinct linguistic styles using handcrafted templates and LLM-based rewrites, while preserving semantic intent. Evaluating 16 open- and close-source instruction-tuned models, we find that stylistic reframing increases jailbreak success rates by up to +57 percentage points. Styles such as fearful, curious and compassionate are most effective and contextualized rewrites outperform templated variants.
  To mitigate this, we introduce a style neutralization preprocessing step using a secondary LLM to strip manipulative stylistic cues from user inputs, significantly reducing jailbreak success rates. Our findings reveal a systemic and scaling-resistant vulnerability overlooked in current safety pipelines.

</details>


### [96] [Convomem Benchmark: Why Your First 150 Conversations Don't Need RAG](https://arxiv.org/abs/2511.10523)
*Egor Pakhomov,Erik Nijkamp,Caiming Xiong*

Main category: cs.CL

TL;DR: 该论文提出了一个包含75,336个问答对的对话记忆评估基准，并研究了对话记忆与检索增强生成（RAG）的关系，发现长上下文在早期对话中表现良好，但随着对话增多，混合或RAG方法更具优势。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆评估框架在统计效力、数据生成一致性和评估灵活性方面存在局限性，本研究旨在解决这些挑战，并探索对话记忆与RAG之间的关系。

Method: 构建了一个包含75,336个问答对的全面基准，涵盖用户事实、助手回忆、弃权、偏好、时间变化和隐含联系等类别。通过实验比较了简单全上下文方法和基于RAG的记忆系统（如Mem0）在不同对话历史长度下的表现。

Result: 研究发现，简单的全上下文方法在多消息证据的情况下准确率可达70-82%，而复杂的RAG记忆系统（如Mem0）在少于150次交互的情况下准确率仅为30-45%。长上下文在30次对话内效果最佳，在150次对话内仍可接受，超过此数量则需要混合或RAG方法。对话记忆的“小语料库优势”值得专门研究。

Conclusion: 对话记忆评估需要专门的解决方案，而不是简单地将通用的RAG方法应用于对话历史。随着对话的进行，需要从长上下文方法过渡到更复杂的混合或RAG方法，以应对成本和延迟的挑战。

Abstract: We introduce a comprehensive benchmark for conversational memory evaluation containing 75,336 question-answer pairs across diverse categories including user facts, assistant recall, abstention, preferences, temporal changes, and implicit connections. While existing benchmarks have advanced the field, our work addresses fundamental challenges in statistical power, data generation consistency, and evaluation flexibility that limit current memory evaluation frameworks. We examine the relationship between conversational memory and retrieval-augmented generation (RAG). While these systems share fundamental architectural patterns--temporal reasoning, implicit extraction, knowledge updates, and graph representations--memory systems have a unique characteristic: they start from zero and grow progressively with each conversation. This characteristic enables naive approaches that would be impractical for traditional RAG. Consistent with recent findings on long context effectiveness, we observe that simple full-context approaches achieve 70-82% accuracy even on our most challenging multi-message evidence cases, while sophisticated RAG-based memory systems like Mem0 achieve only 30-45% when operating on conversation histories under 150 interactions. Our analysis reveals practical transition points: long context excels for the first 30 conversations, remains viable with manageable trade-offs up to 150 conversations, and typically requires hybrid or RAG approaches beyond that point as costs and latencies become prohibitive. These patterns indicate that the small-corpus advantage of conversational memory--where exhaustive search and complete reranking are feasible--deserves dedicated research attention rather than simply applying general RAG solutions to conversation histories.

</details>


### [97] [Computing the Formal and Institutional Boundaries of Contemporary Genre and Literary Fiction](https://arxiv.org/abs/2511.10546)
*Natasha Johnson*

Main category: cs.CL

TL;DR: 文学和类型小说可以通过计算方法区分，女性作者的身份会影响作品的文学性评价。


<details>
  <summary>Details</summary>
Motivation: 探讨文学和类型小说的区别，以及作者性别在其中扮演的角色。

Method: 使用计算方法，包括Welch's ANOVA和逻辑回归，分析了Contemporary Literature（CONLIT）数据集中的文学小说、浪漫小说、神秘小说和科幻小说。同时，还分析了文本的风格和语义向量表示。

Result: 确定了每种文学类别的统计上显著的正式标记。研究表明，女性作者的身份会缩小并模糊达到文学地位的目标。

Conclusion: 文学和类型小说存在统计上显著的正式区别。女性作者的身份会影响作品被归类为文学作品的几率。

Abstract: Though the concept of genre has been a subject of discussion for millennia, the relatively recent emergence of genre fiction has added a new layer to this ongoing conversation. While more traditional perspectives on genre have emphasized form, contemporary scholarship has invoked both formal and institutional characteristics in its taxonomy of genre, genre fiction, and literary fiction. This project uses computational methods to explore the soundness of genre as a formal designation as opposed to an institutional one. Pulling from Andrew Piper's CONLIT dataset of Contemporary Literature, we assemble a corpus of literary and genre fiction, with the latter category containing romance, mystery, and science fiction novels. We use Welch's ANOVA to compare the distribution of narrative features according to author gender within each genre and within genre versus literary fiction. Then, we use logistic regression to model the effect that each feature has on literary classification and to measure how author gender moderates these effects. Finally, we analyze stylistic and semantic vector representations of our genre categories to understand the importance of form and content in literary classification. This project finds statistically significant formal markers of each literary category and illustrates how female authorship narrows and blurs the target for achieving literary status.

</details>


### [98] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: URaG框架通过模仿人类的粗略到精细的推理模式，利用多模态大语言模型（MLLMs）的内在证据定位能力，在一个单一模型中统一检索和生成，解决了长文档理解中的信息干扰和计算成本问题，实现了最先进的性能并降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在理解长文档时面临信息干扰和二次计算成本的挑战。现有方法要么牺牲细节（token压缩），要么增加系统复杂性（外部检索器），阻碍端到端优化。

Method: 提出URaG框架，该框架在一个单一MLLM中统一检索和生成。通过引入一个轻量级的跨模态检索模块，将Transformer的早期层转变为高效的证据选择器，识别并保留相关页面，同时丢弃无关内容，使更深的层能够专注于相关信息。

Result: URaG框架在长文档理解任务上实现了最先进的性能，同时将计算开销降低了44-56%。

Conclusion: URaG框架通过模仿人类的粗略到精细的推理模式，有效解决了长文档理解中的信息干扰和计算成本问题，提高了准确性和效率。

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


### [99] [DESS: DeBERTa Enhanced Syntactic-Semantic Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2511.10577)
*Vishal Thenuwara,Nisansa de Silva*

Main category: cs.CL

TL;DR: DESS uses DeBERTa and LSTM to improve Aspect Sentiment Triple Extraction (ASTE), achieving better results on standard datasets.


<details>
  <summary>Details</summary>
Motivation: Existing Aspect Sentiment Triple Extraction (ASTE) methods struggle with complex relationships between aspects, opinions, and sentiment polarities, and the potential of advanced language models is not fully utilized.

Method: DESS integrates DeBERTa's attention mechanism with an LSTM channel in a dual-channel structure to process both meaning and grammatical patterns, with careful refinement of component interactions.

Result: DESS demonstrated significant improvements over existing methods on standard datasets, with F1-score increases of 4.85, 8.36, and 2.42 in identifying aspect opinion pairs and determining sentiment.

Conclusion: Upgrading to advanced language models like DeBERTa, when thoughtfully integrated, can lead to substantial improvements in text sentiment analysis, particularly in handling complex sentence structures and long-distance dependencies.

Abstract: Fine-grained sentiment analysis faces ongoing challenges in Aspect Sentiment Triple Extraction (ASTE), particularly in accurately capturing the relationships between aspects, opinions, and sentiment polarities. While researchers have made progress using BERT and Graph Neural Networks, the full potential of advanced language models in understanding complex language patterns remains unexplored. We introduce DESS, a new approach that builds upon previous work by integrating DeBERTa's enhanced attention mechanism to better understand context and relationships in text. Our framework maintains a dual-channel structure, where DeBERTa works alongside an LSTM channel to process both meaning and grammatical patterns in text. We have carefully refined how these components work together, paying special attention to how different types of language information interact. When we tested DESS on standard datasets, it showed meaningful improvements over current methods, with F1-score increases of 4.85, 8.36, and 2.42 in identifying aspect opinion pairs and determining sentiment accurately. Looking deeper into the results, we found that DeBERTa's sophisticated attention system helps DESS handle complicated sentence structures better, especially when important words are far apart. Our findings suggest that upgrading to more advanced language models when thoughtfully integrated, can lead to real improvements in how well we can analyze sentiments in text. The implementation of our approach is publicly available at: https://github.com/VishalRepos/DESS.

</details>


### [100] [Evaluating Prompting Strategies with MedGemma for Medical Order Extraction](https://arxiv.org/abs/2511.10583)
*Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar*

Main category: cs.CL

TL;DR: MedGemma模型在Mediqa-OE-2025任务中，通过one-shot提示方法在提取医疗指令方面表现最佳，而非复杂的ReAct或agentic框架，表明直接方法在手动标注数据上更优。


<details>
  <summary>Details</summary>
Motivation: 从医患对话中准确提取医疗指令，以减轻临床文档负担并确保患者安全。

Method: 评估了MedGemma模型在one-shot、ReAct和agentic工作流三种提示范式下的表现。

Result: one-shot提示方法在官方验证集上取得了最高性能，优于ReAct和agentic工作流。

Conclusion: 在手动标注的记录中，复杂的推理链可能导致“过度思考”并引入噪声，因此直接的one-shot方法更鲁棒、更高效。该研究为在不同数据条件下选择合适的临床信息提取提示策略提供了有价值的见解。

Abstract: The accurate extraction of medical orders from doctor-patient conversations is a critical task for reducing clinical documentation burdens and ensuring patient safety. This paper details our team submission to the MEDIQA-OE-2025 Shared Task. We investigate the performance of MedGemma, a new domain-specific open-source language model, for structured order extraction. We systematically evaluate three distinct prompting paradigms: a straightforward one-Shot approach, a reasoning-focused ReAct framework, and a multi-step agentic workflow. Our experiments reveal that while more complex frameworks like ReAct and agentic flows are powerful, the simpler one-shot prompting method achieved the highest performance on the official validation set. We posit that on manually annotated transcripts, complex reasoning chains can lead to "overthinking" and introduce noise, making a direct approach more robust and efficient. Our work provides valuable insights into selecting appropriate prompting strategies for clinical information extraction in varied data conditions.

</details>


### [101] [Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering](https://arxiv.org/abs/2511.10591)
*Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar*

Main category: cs.CL

TL;DR: AI can help clinicians manage patient queries in remote care, especially for wound care with images. This paper presents two methods: mined prompting (using similar examples for few-shot learning) and metadata-guided generation (using predicted attributes to improve responses). Both methods show improved relevance and clinical precision.


<details>
  <summary>Details</summary>
Motivation: Asynchronous remote care increases provider workload, creating a need for AI to help manage patient queries efficiently, specifically in wound care with images.

Method: 1. Mined prompting: Embeds training data, retrieves top-k similar examples as few-shot demonstrations. 2. Metadata-guided generation: Identifies and predicts four key metadata attributes that improve response quality, then incorporates them into the generation pipeline.

Result: Mined prompting enhances response relevance. Metadata-guided generation further improves clinical precision.

Conclusion: Combining mined prompting and metadata-guided generation offers a promising direction for AI tools to provide reliable and efficient wound care support.

Abstract: The rapid expansion of asynchronous remote care has intensified provider workload, creating demand for AI systems that can assist clinicians in managing patient queries more efficiently. The MEDIQA-WV 2025 shared task addresses this challenge by focusing on generating free-text responses to wound care queries paired with images. In this work, we present two complementary approaches developed for the English track. The first leverages a mined prompting strategy, where training data is embedded and the top-k most similar examples are retrieved to serve as few-shot demonstrations during generation. The second approach builds on a metadata ablation study, which identified four metadata attributes that consistently enhance response quality. We train classifiers to predict these attributes for test cases and incorporate them into the generation pipeline, dynamically adjusting outputs based on prediction confidence. Experimental results demonstrate that mined prompting improves response relevance, while metadata-guided generation further refines clinical precision. Together, these methods highlight promising directions for developing AI-driven tools that can provide reliable and efficient wound care support.

</details>


### [102] [Know Your Limits: Entropy Estimation Modeling for Compression and Generalization](https://arxiv.org/abs/2511.10618)
*Benjamin L. Badger,Matthew Neligeorge*

Main category: cs.CL

TL;DR: 语言模型在信息熵的限制下，其预测准确性和语言压缩存在瓶颈。本文提出了一种新的编码器增强因果解码器模型架构，该模型在训练效率和压缩性能上优于现有的因果变换器模型，即使在有限的硬件上也能实现更好的压缩效果。此外，研究还展示了如何获得每个 token 的熵估计，并证明了训练模型使其接近训练数据的熵比最小化损失的模型具有更强的泛化能力。实验表明，训练模型使其接近但不超过估计的每个 token 熵，可以获得比未考虑熵的模型更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的语言压缩算法（因果大语言模型）在估计语言熵方面存在计算瓶颈。因此，需要开发更有效的模型来处理这个问题。

Method: 提出了一种新的编码器增强因果解码器模型架构，并证明了其在训练效率和压缩性能上的优势。研究了如何获得每个 token 的熵估计，并展示了将模型训练目标设定为接近熵的泛化优势。

Result: 所提出的模型架构在训练效率和语言压缩方面优于因果变换器模型。通过实验证明，将模型训练目标设定为接近但不超过估计的每个 token 熵，可以获得比未考虑熵的模型更强的泛化能力。

Conclusion: 编码器增强因果解码器模型架构提供了一种更有效的方法来估计语言熵，并实现更高水平的语言压缩和泛化能力。将模型训练目标设定为接近语言的内在熵可以提高其泛化能力。

Abstract: Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.

</details>


### [103] [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/abs/2511.10621)
*Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: Socratic Self-Refine (SSR)是一个用于评估和改进大型语言模型（LLM）推理的新框架，它将LLM的响应分解为可验证的（子问题，子答案）对，通过受控的重新解决和自我一致性检查来估计每一步的置信度，从而更精确地找到并改进不准确的步骤，最终提高推理的准确性和可解释性。该框架在多个推理基准测试和不同的LLM上都优于现有的迭代自我改进方法，并提供了一种评估和理解LLM内部推理过程的原则性方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM测试框架在处理复杂任务时，由于依赖粗粒度的自我验证和纠正，效果有限。因此，需要一种更精细的评估和精确的改进方法来增强LLM的推理能力。

Method: Socratic Self-Refine (SSR)框架将LLM的响应分解为（子问题，子答案）对。通过受控的重新解决和自我一致性检查来估计每一步的置信度。然后，它能精确地识别出不可靠的步骤，并进行迭代式的改进，最终生成更准确、更可解释的推理链。

Result: 在五个推理基准测试和三个LLM上的实验表明，SSR的性能持续优于最先进的迭代自我改进基线。

Conclusion: SSR框架能够有效地提高LLM在复杂推理任务上的准确性和可解释性，并且提供了一种通用的黑盒方法来评估和理解LLM的内部推理过程。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.

</details>


### [104] [Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628)
*Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: Instella是一个完全开源的三十亿参数语言模型系列，在开放数据和代码库上进行训练，旨在提高透明度和可复现性。尽管预训练时使用的tokens数量较少，但Instella在完全开源的模型中取得了最先进的成果，并可与同等规模的开放权重模型竞争。此外，还发布了Instella-Long（支持128K上下文长度）和Instella-Math（专注于数学推理）两个专门变体。


<details>
  <summary>Details</summary>
Motivation: 解决当前高性能语言模型大多不开源或部分开源的问题，提高研究的透明度和可复现性。

Method: 通过大规模预训练、通用指令调优以及人类偏好对齐来开发Instella模型。利用AMD Instinct MI300X GPU进行训练。

Result: Instella在完全开源的模型中取得了最先进的成果，并与同等规模的开放权重模型具有竞争力。Instella-Long支持128K的上下文长度，Instella-Math在数学任务上表现出色。

Conclusion: Instella系列模型为社区提供了一个透明、高性能且通用的替代方案，推动了开放和可复现的语言模型研究。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instruction tuning, and alignment with human preferences. Despite using substantially fewer pre-training tokens than many contemporaries, Instella achieves state-of-the-art results among fully open models and is competitive with leading open-weight models of comparable size. We further release two specialized variants: Instella-Long, capable of handling context lengths up to 128K tokens, and Instella-Math, a reasoning-focused model enhanced through supervised fine-tuning and reinforcement learning on mathematical tasks. Together, these contributions establish Instella as a transparent, performant, and versatile alternative for the community, advancing the goal of open and reproducible language modeling research.

</details>


### [105] [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643)
*Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: GAD是一种用于黑盒蒸馏的生成对抗性蒸馏方法，它将学生模型训练成生成器，并训练判别器来区分学生和教师模型的输出，从而实现稳定和自适应的反馈，并在实验中取得了优于传统序列级知识蒸馏的效果。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的黑盒蒸馏方法，以克服现有方法的局限性，并实现学生模型与教师模型的性能相当。

Method: GAD将学生模型视为生成器，并训练判别器来区分学生模型和教师模型的输出。判别器充当一个与学生模型共同进化的在线策略奖励模型，提供稳定和自适应的反馈，形成一个极小极大博弈。

Result: GAD在黑盒蒸馏方面表现出色，与常用的序列级知识蒸馏相比，GAD能够持续取得更好的效果。具体而言，使用GAD训练的Qwen2.5-14B-Instruct学生模型在LMSYS-Chat自动评估中达到了与教师模型GPT-5-Chat相当的水平。

Conclusion: GAD是一种有前景且有效的黑盒大型语言模型蒸馏范式，能够显著提升学生模型的性能，并使其在某些评估中达到与教师模型相当的水平。

Abstract: Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.

</details>


### [106] [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645)
*Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu*

Main category: cs.CL

TL;DR: ParoQuant是一种新的量化方法，它通过独立旋转和通道缩放来解决LLM量化中的异常值问题，提高了精度并减少了开销。


<details>
  <summary>Details</summary>
Motivation: LLM的权重量化通常会因为权重和激活中的异常值而导致精度下降，尤其是在推理LLM中，错误会随着长链条累积。现有的PTQ方法要么无法充分抑制异常值，要么会在推理时引入显著的开销。

Method: ParoQuant结合了硬件高效且可优化的独立Givens旋转与通道间缩放，以平衡各通道间的幅度并缩小每个量化组的动态范围。此外，还设计了推理内核以充分利用GPU并行性，并使旋转和缩放在运行时保持轻量级。

Result: ParoQuant在推理任务上平均比AWQ提高了2.4%的精度，同时开销增加不到10%。

Conclusion: ParoQuant是一种高效且准确的LLM推理部署方法。

Abstract: Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [107] [Statistically Consistent Approximate Model Predictive Control](https://arxiv.org/abs/2511.09661)
*Elias Milios,Kim P. Wabersich,Felix Berkel,Felix Gruber,Melanie N. Zeilinger*

Main category: eess.SY

TL;DR: BC在MPC策略近似上存在局限性，提出了一种新的两阶段模仿学习方法，该方法将MPC最优价值函数整合到损失函数中，以解决非凸约束和局部最小值问题，并在模拟中取得了比BC更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的近似MPC（AMPC）方法，特别是基于行为克隆（BC）的模仿学习（IL），在MPC解决方案具有集合值（set-valued）时，由于非凸约束或局部最小值，无法提供准确的近似。

Method: 提出了一种两阶段IL程序，通过将MPC的最优价值函数整合到一个单步前瞻（one-step look-ahead）损失函数中，来精确近似非线性的、可能具有集合值的MPC策略。这通过采用软约束MPC（soft constrained MPC）实现，该方法结合了约束收紧（constraint tightening）和松弛惩罚（slack penalties）来反映最优价值函数中的约束违反情况。

Result: 证明了精确最小化所提出的IL目标的策略在统计上是一致的，这意味着它们能够收敛到安全且稳定的控制律。同时，也为近似最小化器建立了输入到状态的稳定性（input-to-state stability）保证。仿真结果表明，该方法性能优于BC。

Conclusion: 所提出的两阶段IL方法能够准确地近似MPC策略，即使在存在非凸约束或局部最小值的情况下，也能提供安全、稳定且性能优于BC的控制律。

Abstract: Model Predictive Control (MPC) offers rigorous safety and performance guarantees but is computationally intensive. Approximate MPC (AMPC) aims to circumvent this drawback by learning a computationally cheaper surrogate policy. Common approaches focus on imitation learning (IL) via behavioral cloning (BC), minimizing a mean-squared-error loss on a collection of state-input pairs. However, BC fundamentally fails to provide accurate approximations when MPC solutions are set-valued due to non-convex constraints or local minima. We propose a two-stage IL procedure to accurately approximate nonlinear, potentially set-valued MPC policies. The method integrates an approximation of the MPC's optimal value function into a one-step look-ahead loss function, and thereby embeds the MPC's constraint and performance objectives into the IL objective.This is achieved by adopting a stabilizing soft constrained MPC formulation, which reflects constraint violations in the optimal value function by combining a constraint tightening with slack penalties. We prove statistical consistency for policies that exactly minimize our IL objective, implying convergence to a safe and stabilizing control law, and establish input-to-state stability guarantees for approximate minimizers. Simulations demonstrate improved performance compared to BC.

</details>


### [108] [Robust Time-Varying Control Barrier Functions with Sector-Bounded Nonlinearities](https://arxiv.org/abs/2511.09784)
*Jungbae Chun,Felix Biertümpfel,Peter Seiler*

Main category: eess.SY

TL;DR: 提出一种鲁棒时变控制屏障函数，结合时变控制屏障函数和逐点二次约束来处理输入非线性和时变安全约束，设计安全滤波器，通过二阶锥规划在线求解，用于汽车避障。


<details>
  <summary>Details</summary>
Motivation: 需要确保在存在输入非线性和时变安全约束的情况下系统的安全运行。

Method: 结合时变控制屏障函数（捕捉时变安全约束）和逐点二次约束（界定非线性），设计一个安全滤波器，该滤波器通过求解二阶锥规划来确保安全并最小化对基线控制器命令的干扰。

Result: 安全滤波器可通过二阶锥规划高效在线计算，并成功应用于汽车避障场景。

Conclusion: 提出的方法能够有效地处理输入非线性和时变安全约束，通过安全滤波器确保系统的安全运行，同时保持基线控制器命令的性能。

Abstract: This paper presents a novel approach for ensuring safe operation of systems subject to input nonlinearities and time-varying safety constraints. We formulate robust time-varying control barrier functions by combining two ingredients: (i) time-varying control barrier functions which capture the time-varying safety constraints, and (ii) pointwise-in-time quadratic constraints that bound the nonlinearity. These ingredients are used to design a safety filter. This filter ensures safety while minimally altering the command from a given baseline controller. The safety filter is implemented as the solution of a second-order cone program, which can be efficiently computed online. The approach is demonstrated on a simple car obstacle avoidance scenario.

</details>


### [109] [A Smooth Penalty-Based Feedback Law for Reactive Obstacle Avoidance with Convergence Guarantees](https://arxiv.org/abs/2511.09799)
*Lyes Smaili,Soulaimane Berkane*

Main category: eess.SY

TL;DR: 该研究提出了一种名为SPF（Safe Penalty-based Feedback）的安全导航控制器，该控制器仅使用局部传感器信息，能在未知且充满障碍物的环境中实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 在未知且充满障碍物的环境中，仅依赖局部传感器信息进行安全自主导航是一个关键的技术挑战。

Method: 提出了一种平滑反馈控制器，该控制器源于无约束的基于惩罚的公式。它通过一个封闭形式的表达式修改任意的名义输入，确保安全裕度的前向不变性。该控制律仅依赖于到障碍物的距离和方位，无需地图、切换或集合构建。当名义输入是导航势的梯度下降时，可以证明闭环系统几乎全局渐近稳定（AGAS）到目标点。该控制器具有投影结构，在障碍物边界的法向曲率与势场等值线的法向曲率的比较下，可以证明不期望的平衡点是不稳定的。

Result: 该方法（SPF）确保了安全和顺畅的导航，并且计算开销极小，在复杂的2D和3D环境的模拟中得到了验证。

Conclusion: SPF控制器能够保证在未知和动态的环境中进行安全导航，并且在特定条件下能够实现几乎全局的渐近稳定性，是一种高效且计算成本低的方法。

Abstract: This paper addresses the problem of safe autonomous navigation in unknown obstacle-filled environments using only local sensory information. We propose a smooth feedback controller derived from an unconstrained penalty-based formulation that guarantees safety by construction. The controller modifies an arbitrary nominal input through a closed-form expression. The resulting closed-form feedback has a projection structure that interpolates between the nominal control and its orthogonal projection onto the obstacle boundary, ensuring forward invariance of a user-defined safety margin. The control law depends only on the distance and bearing to obstacles and requires no map, switching, or set construction. When the nominal input is a gradient descent of a navigation potential, we prove that the closed-loop system achieves almost global asymptotic stability (AGAS) to the goal. Undesired equilibria are shown to be unstable under a mild geometric curvature condition, which compares the normal curvature of the obstacle boundary with that of the potential level sets. We refer to the proposed method as SPF (Safe Penalty-based Feedback), which ensures safe and smooth navigation with minimal computational overhead, as demonstrated through simulations in complex 2D and 3D environments.

</details>


### [110] [Resilient Controller Design with Exponential Reaching Law for Enhanced Load Frequency Stability in Multi-Area Interconnected Microgrids](https://arxiv.org/abs/2511.09830)
*Md Saiful Islam,Rahul Bhadani*

Main category: eess.SY

TL;DR: 本研究提出了一种分布式鲁棒全局积分终端滑模控制（GITSMC）策略，用于在存在聚合不确定性的多区域互联微电网中，维持频率和联络线功率的稳定。


<details>
  <summary>Details</summary>
Motivation: 为了应对多区域互联微电网中由太阳能光伏（PV）、风力涡轮机（WT）发电和负荷需求引起的聚合不确定性，需要一种有效的控制策略来维持频率和联络线功率的稳定。

Method: 1. 建立了包含PV、WT发电和负荷需求聚合不确定性的多区域互联系统数学模型。2. 为每个区域设计了具有指数趋近律的全局积分终端滑模面，以提高系统动态性能并抑制有限时间内的抖振。3. 使用李雅普诺夫稳定性定理分析了闭环系统的整体稳定性。4. 在IEEE 10发电机新英格兰39节点电力系统上进行了广泛的仿真，包括负荷扰动和变化的PV及WT发电。

Result: 仿真结果表明，所提出的GITSMC方法在ITSE和ISE方面分别取得了约94.9%和94.4%的改进，证明了其相比现有控制器具有优越的精度和动态性能。

Conclusion: 所提出的分布式鲁棒全局积分终端滑模控制（GITSMC）策略能够有效且精确地控制多区域互联微电网的频率和联络线功率，在面对聚合不确定性时表现出优越的动态性能。

Abstract: We present a load frequency control strategy deploying a decentralized robust global integral terminal sliding mode control (GITSMC) method to maintain stable frequency and tie-line power in multi-area interconnected microgrids with aggregated uncertainties. To achieve this, firstly, we have developed a mathematical model of the multi-area interconnected system incorporating disturbances from solar photovoltaic (PV), wind turbine (WT) generation and load demand, as aggregated uncertainties. Secondly, we have designed a global integral terminal sliding surface with an exponential reaching law for each area to enhance system dynamic performance and suppress chattering within a finite time. Thirdly, the overall stability of the closed-loop system is analyzed using the Lyapunov stability theorem. Finally, extensive simulations are conducted on the IEEE 10-generator New England 39-bus power system, including load disturbances and variable PV and WT generation. The results demonstrate the performance of the proposed GITSMC approach, achieving approximately 94.9% improvement in ITSE and 94.4% improvement in ISE, confirming its superior accuracy and dynamic performance compared to the existing controller.

</details>


### [111] [Efficient Verification and Falsification of ReLU Neural Barrier Certificates](https://arxiv.org/abs/2511.10015)
*Dejin Ren,Yiling Xue,Taoran Wu,Bai Xue*

Main category: eess.SY

TL;DR: 该论文提出了一种用于验证 ReLU 神经网络屏障证书正确性的充要条件，该条件可被编码为 SMT 或优化问题，从而能够进行验证和伪证，并且是第一个能够伪证 ReLU 神经网络屏障证书的方法。


<details>
  <summary>Details</summary>
Motivation: 屏障证书在验证连续时间系统（包括自动驾驶、机器人操作器和其他关键应用）的安全性方面发挥着重要作用。ReLU 神经网络屏障证书因其有前景的性能而备受关注，但由于神经网络的近似性质，需要严格的验证方法来确保其正确性。

Method: 提出了一种用于验证 ReLU 神经网络屏障证书正确性的充要条件，并将其编码为 SMT 或优化问题，从而能够进行验证和伪证。

Result: 数值实验证明了该方法在验证和伪证 ReLU 神经网络屏障证书方面的有效性和正确性。

Conclusion: 该论文提出了首个能够伪证 ReLU 神经网络屏障证书的方法，并提供了经验证据来证明其有效性。

Abstract: Barrier certificates play an important role in verifying the safety of continuous-time systems, including autonomous driving, robotic manipulators and other critical applications. Recently, ReLU neural barrier certificates -- barrier certificates represented by the ReLU neural networks -- have attracted significant attention in the safe control community due to their promising performance. However, because of the approximate nature of neural networks, rigorous verification methods are required to ensure the correctness of these certificates. This paper presents a necessary and sufficient condition for verifying the correctness of ReLU neural barrier certificates. The proposed condition can be encoded as either an Satisfiability Modulo Theories (SMT) or optimization problem, enabling both verification and falsification. To the best of our knowledge, this is the first approach capable of falsifying ReLU neural barrier certificates. Numerical experiments demonstrate the validity and effectiveness of the proposed method in both verifying and falsifying such certificates.

</details>


### [112] [Cooperative Control of Hybrid FES-Exoskeleton: Dynamic Allocation](https://arxiv.org/abs/2511.10117)
*Hossein Kavianirad,Satoshi Endo,Davide Astarita,Lorenzo Amato,Emilio Trigili,Sandra Hirche*

Main category: eess.SY

TL;DR: 本研究提出了一种基于动态分配的混合FES-外骨骼系统协同控制架构，以解决执行器冗余和设备约束问题。


<details>
  <summary>Details</summary>
Motivation: 混合辅助系统（FES和机器人外骨骼）在神经康复领域具有前景，但控制方面存在执行器冗余和异构设备约束的挑战。

Method: 提出了一种模块化控制分配器，能够实时地在FES和外骨骼执行器之间重新分配所需的控制力矩，同时考虑设备限制和用户偏好（例如，优先使用某个辅助设备）。

Result: 仿真和实验结果表明，该方法能有效解决FES-外骨骼系统中的执行器冗余问题，并考虑了执行器约束。

Conclusion: 所提出的协同控制架构在解决执行器冗余和设备约束方面是有效的，有潜力用于临床研究，以评估患者接受度和临床疗效。

Abstract: Hybrid assistive systems that integrate functional electrical stimulation (FES) and robotic exoskeletons offer a promising approach for neurorehabilitation. However, control of these systems remains challenging due to actuator redundancy and heterogeneous assistive device constraints. This paper introduces a novel cooperative control architecture based on dynamic allocation to address actuator redundancy in a hybrid FES-exoskeleton system. The proposed approach employs a modular control allocator that redistributes required control torques between FES and exoskeleton actuators in real time, accounting for device-specific limitations and user preferences (e.g., prioritizing one assistive device over another). Within this framework, the high-level controller determines the total assistance level, while the allocator dynamically distributes control effort based on these assistive device-specific considerations. Simulation results and experimental validation demonstrate the method's effectiveness in resolving actuator redundancy in the FES-exoskeleton system while reflecting actuator constraints, indicating its potential for deployment in clinical studies to assess patient acceptance and clinical efficacy.

</details>


### [113] [Consensus approximation and impulsive control for a class of uncertain multi-agent dynamics](https://arxiv.org/abs/2511.10118)
*Zoltan Nagy,Irinel-Constantin Morarescu,Lucian Busoniu*

Main category: eess.SY

TL;DR: 研究了具有时变未知缩放因子的共识动态，并提出了控制策略以在不确定性下实现期望共识。


<details>
  <summary>Details</summary>
Motivation: 研究具有时变未知缩放因子的共识动态，该情况常见于无线网络中的机器人集群控制或意见动态中，其中对同伴的信任度随时间变化。

Method: 1. 确定共识值的实际上下界。2. 提出控制策略，在不确定性下将代理状态转移到期望的共识值，尽管存在不确定性。3. 提供基于线性规划的计算高效方法。4. 通过数值模拟验证结果。

Result: 提出了确定共识值上下界的条件，并开发了用于在不确定性下实现期望共识值的控制策略，同时提供了计算上可行的解决方案。

Conclusion: 该研究为处理具有时变未知缩放因子的共识动态问题提供了理论和计算上的解决方案，并通过数值模拟得到了验证。

Abstract: This paper studies a class of consensus dynamics where the interactions between agents are affected by a time-varying unknown scaling factor. This situation is encountered in the control of robotic fleets over a wireless network or in opinion dynamics where the confidence given to the peers varies in time. Firstly, we establish conditions under which practical upper and lower bounds on the consensus value can be determined. Secondly, we propose control strategies for allocating a given control budget to shift agent states towards a desired consensus value despite the uncertainty. We provide computationally efficient linear programming-based approaches for both problems and validate the obtained results in numerical simulations.

</details>


### [114] [Closed Form Modelling and Identification of Banking Effects in Confined Waters](https://arxiv.org/abs/2511.10158)
*Jeppe H. Mikkelsen,Thomas T. Enevoldsen,Bugge T. Jensen,Michael Jeppesen,Roberto Galeazzi,Dimitrios Papageorgiou*

Main category: eess.SY

TL;DR: 提出了一种用于船舶在狭窄水域航行时银行效应的一阶原理闭合形式模型，该模型使用物理信息回归识别系数，并通过 Shapley 值分析进行了验证，结果表明该模型可推广到不同尺度。


<details>
  <summary>Details</summary>
Motivation: 为了解决计算流体动力学（CFD）在模拟船舶在狭窄水域航行时银行效应的计算成本高昂且不适用于实时控制或估计的问题。

Method: 提出了一种一阶原理闭合形式模型来模拟银行效应。使用物理信息回归方法，并利用拖曳水箱实验数据对集装箱船舶进行了模型系数识别。通过 Shapley 值分析验证了模型的有效性。

Result: 模型系数已识别，并通过 Shapley 值分析确认了银行项在再现测量力和力矩中的重要性。结果还表明，派生的系数是无量纲的，使得该模型能够应用于保持船舶几何形状的各种尺度。

Conclusion: 所提出的闭合形式模型能够准确地模拟银行效应，并且由于其系数是无量纲的，因此可以跨不同尺度推广，适用于实时控制和估计。

Abstract: Vessels navigating in confined waters are subject to banking effects, which are hydrodynamic forces and moments arising from pressure differentials between the vessel sides, significantly affecting manoeuvrability and safety. Existing numerical approaches such as computational fluid dynamics (CFD) can accurately capture these effects but are computationally expensive and unsuitable for real-time control or estimation. This paper presents a closed-form, first-principles model of banking effects. The model coefficients are identified using physics-informed regression on towing tank experiment data for a scaled container vessel. Validation through Shapley value analysis confirms the significance of the banking terms in reproducing the measured forces and moments. Lastly, the derived coefficients are shown to be non-dimensional, making the model applicable across different scales that preserve vessel geometry.

</details>


### [115] [Equivalent Mechanical Models for Sloshing](https://arxiv.org/abs/2511.10172)
*Francesco Capolupo*

Main category: eess.SY

TL;DR: Propellant sloshing is a critical issue for spacecraft stability in microgravity and high-g conditions. This paper presents a rigorous mathematical formulation for modeling sloshing using pendulum dynamics, extending it to multi-body systems and deriving both nonlinear and linearized equations of motion. The models are validated and shown to be equivalent to traditional mass-spring-damper approaches.


<details>
  <summary>Details</summary>
Motivation: Propellant sloshing significantly affects spacecraft performance and stability in both microgravity and high-g conditions, necessitating its consideration in GNC system design. Existing models, while common, may not be sufficiently rigorous or adaptable to complex scenarios.

Method: The paper develops a rigorous mathematical formulation for pendulum dynamics, starting with a single pendulum attached to a rigid spacecraft. It derives the nonlinear equations of motion for an 8-degree-of-freedom multi-body system, extends this to multiple pendulums, and derives linearized equations of motion that account for a nominal longitudinal force. The equivalence between pendulum and mass-spring-damper models is also demonstrated.

Result: The study presents a comprehensive mathematical framework for modeling propellant sloshing using pendulum dynamics. It provides nonlinear and linearized equations of motion for multi-body systems and demonstrates their equivalence to existing models. Simulations in both time and frequency domains validate the proposed models.

Conclusion: The proposed pendulum-based models offer a rigorous and validated approach to analyzing and controlling propellant sloshing in spacecraft. The derived mathematical formulations, including linearized equations for high-g conditions, provide valuable tools for GNC system design and contribute to a better understanding of sloshing dynamics.

Abstract: Propellant sloshing is a well-known, but not completely mastered phenomenon in space vehicles. It is particularly critical in both microgravity environments - such as interplanetary spacecraft requiring high pointing stability - and high-g conditions, as encountered during launch, re-entry, and landing. In both cases, sloshing can significantly affect vehicle performance and stability, and must often be explicitly considered in the design of the guidance, navigation, and control (GNC) subsystem.
  For stability analysis and control design, the most common approach to modeling sloshing is through an equivalent mechanical representation, where the moving propellant is treated as a mechanical system interacting with the rigid (or flexible) spacecraft. Pendulum-based models and mass-spring-damper systems are widely used by control analysts to assess sloshing-induced perturbations on vehicles subjected to persistent non-gravitational acceleration along one of their body axes.
  In this work, we present a rigorous mathematical formulation of pendulum dynamics, starting from a single spherical pendulum attached to a rigid spacecraft. We derive the nonlinear equations of motion for this 8-degree-of-freedom multi-body system, and then extend the formulation to include multiple pendulums, representing multiple sloshing modes within a tank and/or multiple tanks on the same vehicle. Furthermore, we derive the corresponding linearized equations of motion, explicitly accounting for a nominal longitudinal force acting on the vehicle - consistent with the high-g sloshing regime - expressed in either the inertial or body frame. Finally, we demonstrate the mathematical equivalence between the pendulum and mass-spring-damper models and validate the proposed models through time-domain simulation and frequency-domain analysis.

</details>


### [116] [Generalized Intelligence for Tactical Decision-Making: Large Language Model-Driven Dynamic Weapon Target Assignment](https://arxiv.org/abs/2511.10207)
*Johannes Autenrieb,Ole Ostermann*

Main category: eess.SY

TL;DR: 该研究提出了一种基于大语言模型（LLM）的武器目标分配（WTA）框架，用于自主导弹防御系统，解决了传统方法在动态和不确定环境下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的WTA算法在应对现代空防系统中动态和不确定的战术环境方面存在不足，无法实现类似人类的推理和自适应优先级排序。

Method: 提出一个基于LLM的WTA框架，将战术决策过程视为一个推理问题。LLM通过评估拦截器、目标和防御资产之间的时空关系，并结合威胁方向、资产优先级和逼近速度等任务数据，动态生成实时分配方案。

Result: 仿真结果表明，该LLM驱动的WTA方法在一致性、适应性和任务级优先级排序方面均有改进，减少了分配切换。

Conclusion: 该研究为将通用人工智能集成到战术导弹制导系统中奠定了基础，展示了LLM在提高自主防御系统决策能力方面的潜力。

Abstract: Modern aerospace defense systems increasingly rely on autonomous decision-making to coordinate large numbers of interceptors against multiple incoming threats. Conventional weapon-target assignment (WTA) algorithms, including mixed-integer programming and auction-based methods, show limitations in dynamic and uncertain tactical environments where human-like reasoning and adaptive prioritization are required. This paper introduces a large language model (LLM) driven WTA framework that integrates generalized intelligence into cooperative missile guidance. The proposed system formulates the tactical decision process as a reasoning problem, in which an LLM evaluates spatial and temporal relationships among interceptors, targets, and defended assets to generate real-time assignments. In contrast to classical optimization methods, the approach leverages contextual mission data such as threat direction, asset priority, and closing velocity to adapt dynamically and reduce assignment switching. A dedicated simulation environment supports both static and dynamic assignment modes. Results demonstrate improved consistency, adaptability, and mission-level prioritization, establishing a foundation for integrating generalized artificial intelligence into tactical guidance systems.

</details>


### [117] [Fault Detection in Solar Thermal Systems using Probabilistic Reconstructions](https://arxiv.org/abs/2511.10296)
*Florian Ebmeier,Nicole Ludwig,Jannik Thuemmel,Georg Martius,Volker H. Franz*

Main category: eess.SY

TL;DR: 太阳能热系统（STS）通过数据驱动的异常检测来检测故障，特别是基于概率重建的方法，并在公开的PaSTS数据集上进行了测试，证明了其有效性，并优于其他基线模型。


<details>
  <summary>Details</summary>
Motivation: 由于安装、维护或操作不当，太阳能热系统（STS）可能出现故障，导致效率大幅下降或损坏。对于小型系统而言，逐一监控成本过高，因此需要采用自动化的监控和故障检测方法。数据驱动的异常检测，特别是时间序列分析，利用现有传感器识别异常系统状态，提供了一种成本效益高的解决方案。

Method: 提出了一种基于概率重建的框架来进行异常检测。

Result: 在公开的PaSTS数据集上进行了实验，证明了基于重建的方法在定性和定量上都能检测到国内STS中的故障，并且能够推广到未知的系统。该模型优于简单的和更复杂的深度学习基线模型。此外，异方差不确定性估计对于故障检测性能至关重要。

Conclusion: 基于重建的方法能够有效地检测STS中的故障，并且比其他基线模型表现更好。异方差不确定性估计对于提高性能至关重要。然而，需要考虑工程开销才能实现这些改进，并主张使用简单的深度学习模型。

Abstract: Solar thermal systems (STS) present a promising avenue for low-carbon heat generation, with a well-running system providing heat at minimal cost and carbon emissions. However, STS can exhibit faults due to improper installation, maintenance, or operation, often resulting in a substantial reduction in efficiency or even damage to the system. As monitoring at the individual level is economically prohibitive for small-scale systems, automated monitoring and fault detection should be used to address such issues. Recent advances in data-driven anomaly detection, particularly in time series analysis, offer a cost-effective solution by leveraging existing sensors to identify abnormal system states.
  Here, we propose a probabilistic reconstruction-based framework for anomaly detection. We evaluate our method on the publicly available PaSTS dataset of operational domestic STS, which features real-world complexities and diverse fault types. Our experiments show that reconstruction-based methods can detect faults in domestic STS both qualitatively and quantitatively, while generalizing to previously unseen systems. We also demonstrate that our model outperforms both simple and more complex deep learning baselines. Additionally, we show that heteroscedastic uncertainty estimation is essential to fault detection performance. Finally, we discuss the engineering overhead required to unlock these improvements and make a case for simple deep learning models.

</details>


### [118] [The Resonance Principle: Empirical Evidence for Emergent Phase Synchronization in Human Causal Reasoning](https://arxiv.org/abs/2511.10596)
*Ahmed Gamal Eldin*

Main category: eess.SY

TL;DR: 当前人工智能受限于确定性数字架构，无法实现因果理解。我们提出了“共振原理”，认为因果理解源于随机、有界且具有内在成本函数的智能体，其主体被建模为耦合振荡器网络，通过内在噪声激发形成稳定的共振模式。我们通过分析脑电图（EEG）数据来检验这一理论，发现全局共振与事件相关电位（ERP）电压不相关，但在试验层面存在强相关性，表明相位同步是涌现因果理解的基础。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统擅长相关性模式匹配，但缺乏真正的因果理解能力，这被称为“开普勒与牛顿”问题。作者认为这是确定性数字架构的固有局限。

Method: 提出“共振原理”，认为因果理解产生于随机、有界且具有内在成本函数的智能体。智能体的主体被建模为弱耦合振荡器网络，动作的产生源于内在噪声激发的稳定共振模式。通过分析高密度脑电图（EEG）数据（25个记录，500个试验）在一个P300脑机接口任务中进行检验。计算了Kuramoto阶数参数（R）来衡量全局相位同步（共振），并与事件相关电位（ERP）电压进行比较。

Result: 全局共振与电压在统计上不相关（r = 0.048），但在试验层面，两者显示出强相关性（r = 0.590，p < 0.0001）。这表明共振是协调神经放电的一个隐藏机制，并产生了可测量的ERP。

Conclusion: 相位同步不是副产品，而是涌现因果理解的根本标志。

Abstract: Current artificial intelligence systems excel at correlational pattern matching but fail to achieve genuine causal understanding, a limitation often described as the "Kepler versus Newton" problem. We argue that this limitation is inherent to deterministic digital architectures. We introduce the Resonance Principle, a theoretical framework proposing that causal understanding emerges only in stochastic, bounded agents with intrinsic cost functions. The agent's substrate is modeled as a network of weakly coupled oscillators, where action proposals arise as stable resonant modes excited by intrinsic noise. We hypothesize that the brain, a stochastic and resonant system, operates according to this principle. To test this, we analyzed high-density EEG data (25 recordings, 500 trials) from a P300 BCI task. We computed the Kuramoto Order Parameter (R) to measure global phase synchronization (resonance) and compared it to the Event-Related Potential (ERP) voltage. Global resonance and voltage were statistically uncorrelated (r = 0.048), yet trial-level analysis revealed a strong correlation (r = 0.590, p < 0.0001). This suggests that resonance is a hidden mechanism coordinating neural firing, giving rise to measurable ERPs. We conclude that phase synchronization is not a byproduct but a fundamental signature of emergent causal understanding.

</details>


### [119] [Security-Constrained AC/DC Grid Optimal Power Flow Considering Asymmetrical HVDC Grid Operation using Sparse Tableau Formulation](https://arxiv.org/abs/2511.10335)
*Oscar Damanik,Giacomo Bastianel,Dirk Van Hertem,Hakan Ergun*

Main category: eess.SY

TL;DR: 该研究提出了一种考虑直流中性点电压偏移的含高压直流（HVDC）电网的故障后最优潮流（SCOPF）模型。


<details>
  <summary>Details</summary>
Motivation: 为了在单极故障后的紧急情况下，通过优化换流站非对称运行来最小化运营成本，并允许选择非对称运行的换流站数量。

Method: 提出了一种优化模型，该模型通过允许换流站以不同的极电流运行，并允许选择非对称运行的换流站数量来最小化运营成本。此外，还提出了一种中性线切换（NLS）策略来缓解非对称运行带来的中性点电压偏移问题。

Result: 研究结果表明，增加非对称运行的换流站数量可以降低运营成本，但会导致直流中性点电压偏移增大。对成本对非对称运行水平的敏感性进行了分析。NLS策略可以缓解中性点电压偏移问题，但可能会增加运营成本。

Conclusion: 在HVDC电网中，通过优化换流站的非对称运行可以降低故障后的运营成本。然而，需要仔细权衡非对称运行带来的中性点电压偏移问题。NLS策略可以作为一种缓解措施，但需要进一步研究其对成本的影响。

Abstract: This paper presents a security-constrained optimal power flow (SCOPF) model for HVDC grids that optimizes the asymmetrical operation of bipolar converter stations, i.e., different current injections of the positive and negative converter poles, to minimize operational costs under post-contingency conditions caused by single converter pole outages. The optimization model allows the selection of the number of converter stations that operate asymmetrically. The results indicate that increasing the number of asymmetrical stations lowers operational costs. The analysis also provides insight into the sensitivity of these costs to the level of asymmetrical operation. However, increased asymmetrical operation leads to higher DC neutral voltage offsets that can rise to undesired levels. Imposing limits on these offsets can, in turn, increase operational costs. To mitigate these effects, a neutral line switching (NLS) strategy is proposed for the post-contingency state.

</details>


### [120] [Large-Signal Stability Guarantees for a Scalable DC Microgrid with Nonlinear Distributed Control: The Slow Communication Scenario](https://arxiv.org/abs/2511.10380)
*Cornelia Skaga,Mahdieh S. Sadabadi,Gilbert Bergna-Diaz*

Main category: eess.SY

TL;DR: 本研究提出了一个用于网络物理直流微电网的分布式控制框架，利用奇异摄动理论和李雅普诺夫函数证明了全局指数稳定性，确保了比例电流共享和电压限制。通过非线性嵌套控制环路（内层和外层）实现控制目标，并进行了时域仿真和小型信号稳定性分析以指导实际应用。


<details>
  <summary>Details</summary>
Motivation: 为了确保可再生能源并网的电气系统安全稳定运行，需要先进的、可扩展的控制方案。

Method: 采用非线性嵌套控制环路（内层和外层），利用奇异摄动理论证明全局指数稳定性，并通过李雅普诺夫函数进行论证。

Result: 通过对低压直流微电网的仿真，验证了所提出控制策略的有效性，并进行了小型信号稳定性分析。

Conclusion: 该分布式控制框架能够实现比例电流共享和电压限制，并具有可扩展的稳定性保证，通过仿真和分析验证了其有效性。

Abstract: The increasing integration of renewable energy sources into electrical grids necessitates a paradigm shift toward advanced control schemes that guarantee safe and stable operations with scalable properties. Hence, this study explores large-signal stability guarantees of a promising distributed control framework for cyber-physical DC microgrids, ensuring proportional current sharing and voltage containment within pre-specified limits. The proposed control framework adopts nonlinear nested control loops--inner (decentralized) and outer (distributed)--specifically designed to simultaneously achieve the control objectives. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the nested control loops. In particular, by saturating the influence of the outer loop controller in the inner loop, the proposed controller preserves a more convenient mathematical structure, facilitating the scalability of the stability proof using Lyapunov arguments. The effectiveness of our proposed control strategy is supported through time-domain simulations of a case-specific low-voltage DC microgrid following a careful tuning strategy, and a small-signal stability analysis is conducted to derive practical guidelines that enhance the applicability of the method.

</details>


### [121] [Stability Analysis of a Nonlinear Distributed Control Framework for Current Sharing and Voltage Containment in DC Microgrids: The Fast Communication Scenario](https://arxiv.org/abs/2511.10401)
*Cornelia Skaga,Babak Abdolmaleki,Gilbert Bergna-Diaz*

Main category: eess.SY

TL;DR: 为确保电网安全稳定运行，本文提出了一种用于网络物理直流微电网的控制方案，通过奇异摄动理论证明了其全局指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源并网，需要新的控制方案来确保电网安全、稳定和可扩展运行。

Method: 利用奇异摄动理论，通过在内部（分散式）和外部（分布式）嵌套循环之间施加足够的时间尺度分离，来证明全局指数稳定性。

Result: 在低压直流微电网的时域仿真案例研究和小信号稳定性分析中验证了该方法的有效性。

Conclusion: 该控制方案通过满足特定稳定性条件并进行适当调整，可以确保系统达到期望的（最优）稳态。

Abstract: As renewable energy generation becomes increasingly integrated into electrical grids, there is a critical need for a paradigm shift toward control schemes that ensure safe, stable, and scalable operations. Hence, in this study, we explore the stability guarantees of a promising control proposal for cyber-physical DC microgrids (MGs), specifically designed to simultaneously achieve proportional current sharing and voltage containment within pre-specified limits. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the inner(decentralized) and outer(distributed) nested loops, and thus, ensuring that the system reaches the desired (optimal) steady state under appropriate tuning verifying some stability conditions. To prove the effectiveness of our method, our findings are supported by testing the control method in a time-domain simulation case study involving a low-voltage DC microgrid, as well as a small-signal stability analysis

</details>


### [122] [A Decomposition Approach to Solving Numerical Constraint Satisfaction Problems on Directed Acyclic Graphs](https://arxiv.org/abs/2511.10426)
*Max Mowbray,Nilay Shah,Benoît Chachuat*

Main category: eess.SY

TL;DR: 该论文提出了一种利用图结构分解约束满足问题的方法，以处理高维参数空间，并通过模拟和工程案例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 在许多行业中，对决策的可行性进行认证至关重要，这可以被构建为约束满足问题。本研究旨在对有向无环图中满足约束的参数子集进行表征，尤其适用于函数形式未知或计算成本高昂的情况。

Method: 提出了一种利用图结构将问题分解为低维子问题的新方法，以应对维度灾难。该方法通过对各个节点定义子问题，并利用这些子问题的解集来收紧先验参数域，最终求解图上的完整问题。

Result: 通过四种与机器学习和工程相关的案例研究，证明了所提出方法能够有效收紧先验参数域。

Conclusion: 所提出的基于图结构分解的方法可以有效地处理高维约束满足问题，并通过案例研究验证了其有效性。未来的研究将扩展到处理循环图和参数不确定性。

Abstract: Certifying feasibility in decision-making, critical in many industries, can be framed as a constraint satisfaction problem. This paper focuses on characterising a subset of parameter values from an a priori set that satisfy constraints on a directed acyclic graph of constituent functions. The main assumption is that these functions and constraints may be evaluated for given parameter values, but they need not be known in closed form and could result from expensive or proprietary simulations. This setting lends itself to using sampling methods to gain an inner approximation of the feasible domain. To mitigate the curse of dimensionality, the paper contributes new methodology to leverage the graph structure for decomposing the problem into lower-dimensional subproblems defined on the respective nodes. The working hypothesis that the Cartesian product of the solution sets yielded by the subproblems will tighten the a priori parameter domain, before solving the full problem defined on the graph, is demonstrated through four case studies relevant to machine learning and engineering. Future research will extend this approach to cyclic graphs and account for parametric uncertainty.

</details>


### [123] [Formal Verification of Control Lyapunov-Barrier Functions for Safe Stabilization with Bounded Controls](https://arxiv.org/abs/2511.10510)
*Jun Liu*

Main category: eess.SY

TL;DR: We provide verifiable conditions to synthesize a smooth Lyapunov function that guarantees both asymptotic stability and safety under bounded controls by ensuring compatibility between a control barrier function (CBF) and a control Lyapunov function (CLF).


<details>
  <summary>Details</summary>
Motivation: The motivation is to synthesize a single smooth Lyapunov function that certifies both asymptotic stability and safety under bounded controls, ensuring the compatibility of CBF and CLF on the exact safe set.

Method: A smooth control Lyapunov-barrier function (CLBF) is constructed using a patching formula that ensures compatibility between a CBF and a CLF. This method provides verifiable conditions for synthesizing the CLBF.

Result: The proposed approach results in a CLBF that is provably correct by design. Two examples demonstrate that this method is less conservative than existing sum-of-squares (SOS)-based methods for designing compatible CBF-CLF.

Conclusion: The paper presents a novel method for synthesizing a smooth control Lyapunov-barrier function (CLBF) that guarantees both stability and safety. The method is shown to be less conservative than existing approaches and is illustrated with two examples.

Abstract: We present verifiable conditions for synthesizing a single smooth Lyapunov function that certifies both asymptotic stability and safety under bounded controls. These sufficient conditions ensure the strict compatibility of a control barrier function (CBF) and a control Lyapunov function (CLF) on the exact safe set certified by the barrier. An explicit smooth control Lyapunov-barrier function (CLBF) is then constructed via a patching formula that is provably correct by design. Two examples illustrate the computational procedure, showing that the proposed approach is less conservative than sum-of-squares (SOS)-based compatible CBF-CLF designs.

</details>


### [124] [Safe Planning in Interactive Environments via Iterative Policy Updates and Adversarially Robust Conformal Prediction](https://arxiv.org/abs/2511.10586)
*Omid Mirzaeedodangeh,Eliot Shekhtman,Nikolai Matni,Lars Lindemann*

Main category: eess.SY

TL;DR: 该研究提出了一种迭代框架，通过量化策略更新对环境行为的潜在影响，来在策略更新中鲁棒地维持安全保证。


<details>
  <summary>Details</summary>
Motivation: 在交互式环境中（如自动驾驶汽车与行人之间），安全规划面临挑战，因为环境的行为未知且对自主代理的反应。这种耦合会导致交互式分布偏移，可能使现有安全保证失效。

Method: 提出了一种迭代框架，结合了对抗性鲁棒的保形预测（CP）和策略到轨迹的敏感性分析，以在策略更新之间转移和调整安全保证，从而实现安全的、每个情节的开环规划器。

Result: 在二维汽车-行人案例研究中，经验上证明了该框架的安全性和收敛性保证。

Conclusion: 该研究首次在交互式环境中提供了有效的安全保证，解决了由交互引起的分布偏移问题。

Abstract: Safe planning of an autonomous agent in interactive environments -- such as the control of a self-driving vehicle among pedestrians and human-controlled vehicles -- poses a major challenge as the behavior of the environment is unknown and reactive to the behavior of the autonomous agent. This coupling gives rise to interaction-driven distribution shifts where the autonomous agent's control policy may change the environment's behavior, thereby invalidating safety guarantees in existing work. Indeed, recent works have used conformal prediction (CP) to generate distribution-free safety guarantees using observed data of the environment. However, CP's assumption on data exchangeability is violated in interactive settings due to a circular dependency where a control policy update changes the environment's behavior, and vice versa. To address this gap, we propose an iterative framework that robustly maintains safety guarantees across policy updates by quantifying the potential impact of a planned policy update on the environment's behavior. We realize this via adversarially robust CP where we perform a regular CP step in each episode using observed data under the current policy, but then transfer safety guarantees across policy updates by analytically adjusting the CP result to account for distribution shifts. This adjustment is performed based on a policy-to-trajectory sensitivity analysis, resulting in a safe, episodic open-loop planner. We further conduct a contraction analysis of the system providing conditions under which both the CP results and the policy updates are guaranteed to converge. We empirically demonstrate these safety and convergence guarantees on a two-dimensional car-pedestrian case study. To the best of our knowledge, these are the first results that provide valid safety guarantees in such interactive settings.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [125] [Contextual Refinement of Higher-Order Concurrent Probabilistic Programs](https://arxiv.org/abs/2511.10135)
*Kwing Hei Li,Alejandro Aguirre,Joseph Tassarotti,Lars Birkedal*

Main category: cs.LO

TL;DR: Foxtrot 是一种用于证明高阶并发概率程序上下文细化的高阶分离逻辑。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种能够处理高阶并发概率程序（具有高阶局部状态）的推理工具，以证明其上下文细化。

Method: Foxtrot 继承了标准并发分离逻辑的并发推理原理（如不变式和 ghost 资源），并结合了用于处理并发线程引起的复杂概率分布的高级概率推理原理（如 tape presampling 和 induction by error amplification）。该逻辑的健全性依赖于 Iris 逻辑中的选择公理的一个版本。

Result: Foxtrot 在一系列示例中得到了验证，包括对抗性冯·诺依曼硬币和 Sodium 密码软件库的 randombytes_uniform 函数。所有结果都已在 Rocq 证明助手和 Iris 分离逻辑框架中进行了机械化。

Conclusion: Foxtrot 是一种强大的高阶分离逻辑，能够处理高阶并发概率程序，并在实际示例中得到了验证，其健全性依赖于 Iris 逻辑中的选择公理。

Abstract: We present Foxtrot, the first higher-order separation logic for proving contextual refinement of higher-order concurrent probabilistic programs with higher-order local state. From a high level, Foxtrot inherits various concurrency reasoning principles from standard concurrent separation logic, e.g. invariants and ghost resources, and supports advanced probabilistic reasoning principles for reasoning about complex probability distributions induced by concurrent threads, e.g. tape presampling and induction by error amplification. The integration of these strong reasoning principles is highly non-trivial due to the combination of probability and concurrency in the language and the complexity of the Foxtrot model; the soundness of the logic relies on a version of the axiom of choice within the Iris logic, which is not used in earlier work on Iris-based logics. We demonstrate the expressiveness of Foxtrot on a wide range of examples, including the adversarial von Neumann coin and the $\mathsf{randombytes\_uniform}$ function of the Sodium cryptography software library.
  All results have been mechanized in the Rocq proof assistant and the Iris separation logic framework.

</details>


### [126] [Quantum modal logic](https://arxiv.org/abs/2511.10188)
*Kenji Tokuo*

Main category: cs.LO

TL;DR: A simplified modal logic based on quantum logic is formalized with relational semantics and a sequent calculus, proving soundness and completeness. This serves as a foundation for various quantum modal logics.


<details>
  <summary>Details</summary>
Motivation: To provide a simplified formal framework for modal logic based on quantum logic, intended as a foundation for various quantum modal logics such as alethic, temporal, epistemic, and dynamic logics.

Method: Formalized a modal logic based on quantum logic, providing a relational semantics and a sequent calculus. Demonstrated the soundness and completeness theorems connecting these two notions.

Result: Established a sound and complete formal system for a modal logic based on quantum logic.

Conclusion: The developed framework, with its relational semantics and sequent calculus, provides a solid and complete basis for further formalization of diverse modal logics over quantum logic.

Abstract: A modal logic based on quantum logic is formalized in its simplest possible form. Specifically, a relational semantics and a sequent calculus are provided, and the soundness and the completeness theorems connecting both notions are demonstrated. This framework is intended to serve as a basis for formalizing various modal logics over quantum logic, such as quantum alethic logic, quantum temporal logic, quantum epistemic logic, and quantum dynamic logic.

</details>


### [127] [Certified Branch-and-Bound MaxSAT Solving (Extended Version)](https://arxiv.org/abs/2511.10273)
*Dieter Vandesande,Jordi Coll,Bart Bogaerts*

Main category: cs.LO

TL;DR: 该论文实现了分支定界MaxSAT求解器的证明日志记录功能，并进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 现代组合求解器（包括MaxSAT求解器）由于源代码的复杂性而容易出现错误，而确保求解器输出的正确性在某些实际应用中至关重要。

Method: 实现了分支定界MaxSAT求解器的证明日志记录功能，具体包括对求解器中使用的前瞻方法和基于多值决策图（MDD）的伪布尔约束的先进子句编码进行认证。

Result: 在MaxCDCL求解器中实现了这些想法，并通过实验证明，证明日志记录的可行性开销有限，但证明检查仍然是一个挑战。

Conclusion: 为MaxSAT求解器实现了证明日志记录功能，证明了其可行性，并指出了未来研究的方向。

Abstract: Over the past few decades, combinatorial solvers have seen remarkable performance improvements, enabling their practical use in real-world applications. In some of these applications, ensuring the correctness of the solver's output is critical. However, the complexity of modern solvers makes them susceptible to bugs in their source code. In the domain of satisfiability checking (SAT), this issue has been addressed through proof logging, where the solver generates a formal proof of the correctness of its answer. For more expressive problems like MaxSAT, the optimization variant of SAT, proof logging had not seen a comparable breakthrough until recently.
  In this paper, we show how to achieve proof logging for state-of-the-art techniques in Branch-and-Bound MaxSAT solving. This includes certifying look-ahead methods used in such algorithms as well as advanced clausal encodings of pseudo-Boolean constraints based on so-called Multi-Valued Decision Diagrams (MDDs). We implement these ideas in MaxCDCL, the dominant branch-and-bound solver, and experimentally demonstrate that proof logging is feasible with limited overhead, while proof checking remains a challenge.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [128] [Massively Parallel Proof-Number Search for Impartial Games and Beyond](https://arxiv.org/abs/2511.10339)
*Tomáš Čížek,Martin Balko,Martin Schmid*

Main category: cs.AI

TL;DR: 本文提出了一种可高效扩展至大量CPU核心的并行化博证明搜索算法，并将其应用于Sprouts游戏，显著加速了博弈树的搜索，验证了Sprouts猜想。


<details>
  <summary>Details</summary>
Motivation: 现有的并行化证明搜索算法在多CPU核心上的扩展性不佳，需要一种能够高效扩展的并行化算法。

Method: 利用两层并行化和工作节点间的共享信息，开发了首个大规模并行化证明搜索算法。该算法还结合了Grundy数来减小博弈树。

Result: 在1024核CPU上实现了332.9倍的加速，运行速度比现有最优Sprouts求解器GLOP快四个数量级，生成的证明复杂度提高1000倍。验证了Sprouts猜想在42个新局面下的正确性，使已知结果数量翻倍。

Conclusion: 本文提出的并行化证明搜索算法能够高效扩展至大量CPU核心，在Sprouts游戏的研究中取得了显著的成果，验证了Sprouts猜想，并为未来在其他博弈问题上的应用奠定了基础。

Abstract: Proof-Number Search is a best-first search algorithm with many successful applications, especially in game solving. As large-scale computing clusters become increasingly accessible, parallelization is a natural way to accelerate computation. However, existing parallel versions of Proof-Number Search are known to scale poorly on many CPU cores. Using two parallelized levels and shared information among workers, we present the first massively parallel version of Proof-Number Search that scales efficiently even on a large number of CPUs. We apply our solver, enhanced with Grundy numbers for reducing game trees, to the Sprouts game, a case study motivated by the long-standing Sprouts Conjecture. Our solver achieves a significantly improved 332.9$\times$ speedup when run on 1024 cores, enabling it to outperform the state-of-the-art Sprouts solver GLOP by four orders of magnitude in runtime and to generate proofs 1,000$\times$ more complex. Despite exponential growth in game tree size, our solver verified the Sprouts Conjecture for 42 new positions, nearly doubling the number of known outcomes.

</details>


### [129] [Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation](https://arxiv.org/abs/2511.10233)
*Jianghan Zhu,Yaoxin Wu,Zhuoyi Lin,Zhengyuan Zhang,Haiyan Yin,Zhiguang Cao,Senthilnath Jayavelu,Xiaoli Li*

Main category: cs.AI

TL;DR: EvoReal通过LLM引导的进化模块生成具有真实结构模式的合成实例，以弥合神经组合优化（NCO）方法在处理实际车辆路径问题（VRP）实例时的泛化差距。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器在从合成、均匀分布的训练数据泛化到实际VRP场景（包括TSPLib和CVRPLib基准实例）方面存在困难。

Method: 提出了一种名为EvoReal的方法，该方法利用由大型语言模型（LLM）引导的进化模块来生成具有多样化和真实结构模式的合成实例。该进化模块产生在统计上模仿真实实例中观察到的结构属性的合成实例。随后，通过首先使预训练的NCO模型与这些结构丰富的合成分布对齐，然后通过直接在实际基准实例上进行微调来对其进行改进。

Result: EvoReal显著提高了最先进的神经求解器的泛化能力，在TSPLib（1.05%）和CVRPLib（2.71%）基准的广泛问题规模上，与最优解的性能差距明显减小。

Conclusion: EvoReal通过生成在统计上模仿真实世界实例的结构属性的合成实例，有效地提高了神经组合优化方法在处理实际VRP实例时的泛化能力。

Abstract: Recent advances in Neural Combinatorial Optimization (NCO) methods have significantly improved the capability of neural solvers to handle synthetic routing instances. Nonetheless, existing neural solvers typically struggle to generalize effectively from synthetic, uniformly-distributed training data to real-world VRP scenarios, including widely recognized benchmark instances from TSPLib and CVRPLib. To bridge this generalization gap, we present Evolutionary Realistic Instance Synthesis (EvoReal), which leverages an evolutionary module guided by large language models (LLMs) to generate synthetic instances characterized by diverse and realistic structural patterns. Specifically, the evolutionary module produces synthetic instances whose structural attributes statistically mimics those observed in authentic real-world instances. Subsequently, pre-trained NCO models are progressively refined, firstly aligning them with these structurally enriched synthetic distributions and then further adapting them through direct fine-tuning on actual benchmark instances. Extensive experimental evaluations demonstrate that EvoReal markedly improves the generalization capabilities of state-of-the-art neural solvers, yielding a notable reduced performance gap compared to the optimal solutions on the TSPLib (1.05%) and CVRPLib (2.71%) benchmarks across a broad spectrum of problem scales.

</details>


### [130] [Cogent argument extensions are weakly admissible but not vice versa](https://arxiv.org/abs/2511.09600)
*Gustavo Bodanza*

Main category: cs.AI

TL;DR: 简而言之，研究表明“有说服力的”扩展是“弱可接纳的”，但反之则不然。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨两种不可接纳的论证框架语义——有说服力语义和弱可接纳语义之间的关系。

Method: 通过数学证明来分析和比较这两种语义。

Result: 证明了有说服力扩展满足弱可接纳性，但存在弱可接纳的扩展并非有说服力的反例。

Conclusion: 有说服力语义是弱可接纳语义的一个子集，两者并不等价。

Abstract: In this research note, we show the relationship between two non-admissible argumentation framework semantics: cogent and weakly admissible semantics. We prove that, while cogent extensions are weakly admissible, the converse is not true.

</details>


### [131] [An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-α Optimization](https://arxiv.org/abs/2511.09563)
*Qilong Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种名为部分路径重构（PPR）的新型求解器，用于解决大规模联合路由-分配（JRA）优化问题，该问题旨在同时确定物品到占位符的分配以及访问每个节点对一次的哈密顿回路，目标是最小化总旅行成本。


<details>
  <summary>Details</summary>
Motivation: 现有的精确混合整数规划（MIP）求解器在大规模实例上计算效率低下，而基于合并算法和扰动程序的启发式方法虽然能在约1%的偏差内找到解决方案，但仍有改进空间。

Method: 提出了一种名为部分路径重构（PPR）的求解器，通过识别关键的物品-占位符对来形成一个简化的子问题，并高效地求解以改进全局解决方案。此外，还引入了一个全局的Large-α约束来进一步提高最优性。

Result: 在n=300、500和1000的基准数据集上的实验表明，该方法能够持续获得接近最优解的解决方案，平均偏差为0.00%，同时保持了高计算效率。

Conclusion: 所提出的PPR框架能够显著提高JRA问题的解的精度，并将启发式合并解的偏差减半，同时保持了高计算效率。该框架和方法也可能适用于旅行商问题（TSP）及相关优化问题。

Abstract: The Joint Routing-Assignment (JRA) optimization problem simultaneously determines the assignment of items to placeholders and a Hamiltonian cycle that visits each node pair exactly once, with the objective of minimizing total travel cost. Previous studies introduced an exact mixed-integer programming (MIP) solver, along with datasets and a Gurobi implementation, showing that while the exact approach guarantees optimality, it becomes computationally inefficient for large-scale instances. To overcome this limitation, heuristic methods based on merging algorithms and shaking procedures were proposed, achieving solutions within approximately 1% deviation from the optimum. This work presents a novel and more efficient approach that attains high-accuracy, near-optimal solutions for large-scale JRA problems. The proposed method introduces a Partial Path Reconstructon (PPR) solver that first identifies key item-placeholder pairs to form a reduced subproblem, which is solved efficiently to refine the global solution. Using this PJAR framework, the initial heuristic merging solutions can be further improved, reducing the deviation by half. Moreover, the solution can be iteratively polished with PPR based solver along the optimization path to yield highly accurate tours. Additionally, a global Large-α constraint is incorporated into the JRA model to further enhance solution optimality. Experimental evaluations on benchmark datasets with n = 300, 500, and 1000 demonstrate that the proposed method consistently delivers almost optimal solutions, achieving an average deviation of 0.00% from the ground truth while maintaining high computational efficiency. Beyond the JRA problem, the proposed framework and methodologies exhibit strong potential for broader applications. The Framework can be applied to TSP and related optimization problems.

</details>


### [132] [Variable Neighborhood Search for the Electric Vehicle Routing Problem](https://arxiv.org/abs/2511.09570)
*David Woller,Viktor Kozák,Miroslav Kulich,Libor Přeučil*

Main category: cs.AI

TL;DR: 该论文提出了一种基于变邻域搜索（VNS）元启发式算法的方法，以解决电车路径问题（EVRP）的一个简化变体——容量绿色路径问题（CGVRP），并在CEC-12竞赛数据集上取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: 由于文献中考虑的约束条件多种多样，因此比较不同问题变体的不同方法仍然具有挑战性。本文旨在解决容量绿色路径问题（CGVRP），这是电车路径问题（EVRP）的一个简化变体。

Method: 采用变邻域搜索（VNS）元启发式算法。

Result: 该方法在完整的竞赛数据集上取得了最佳结果，并且优于随后发表的一个算法。

Conclusion: 基于VNS元启发式算法的方法能够有效地解决CGVRP问题，并在竞赛数据集中取得了领先的性能。

Abstract: The Electric Vehicle Routing Problem (EVRP) extends the classical Vehicle Routing Problem (VRP) to reflect the growing use of electric and hybrid vehicles in logistics. Due to the variety of constraints considered in the literature, comparing approaches across different problem variants remains challenging. A minimalistic variant of the EVRP, known as the Capacitated Green Vehicle Routing Problem (CGVRP), was the focus of the CEC-12 competition held during the 2020 IEEE World Congress on Computational Intelligence. This paper presents the competition-winning approach, based on the Variable Neighborhood Search (VNS) metaheuristic. The method achieves the best results on the full competition dataset and also outperforms a more recent algorithm published afterward.

</details>


### [133] [SynthTools: A Framework for Scaling Synthetic Tools for Agent Development](https://arxiv.org/abs/2511.09572)
*Tommaso Castellani,Naimeng Ye,Daksh Mittal,Thomson Yen,Hongseok Namkoong*

Main category: cs.AI

TL;DR: SynthTools是一个用于生成合成工具生态系统的框架，旨在为AI代理提供可扩展、多样化且可靠的工具使用环境，以解决现实世界API的局限性。


<details>
  <summary>Details</summary>
Motivation: AI代理需要可复现的评估和大规模的训练环境来处理复杂任务，但现实世界API存在可用性、领域覆盖度和稳定性不足的问题，并且需要访问密钥和限制速率，不适合大规模训练和稳定评估。

Method: SynthTools框架包含三个核心组件：工具生成（自动、可扩展地创建各种工具）、工具模拟（模拟真实的工具行为）和工具审计（确保工具模拟的正确性和一致性）。

Result: SynthTools生成的工具集跨越的领域数量是先前工作的两倍，每个领域的工具数量也是两倍。工具模拟的准确率为94%，工具审计的准确率为99%。利用生成的工具构建的下游任务甚至连最先进的模型也难以完成。

Conclusion: SynthTools通过提供可扩展、多样化和可靠的工具生态系统，为工具使用AI代理的大规模训练和稳定评估提供了一条可行的途径。

Abstract: AI agents increasingly rely on external tools to solve complex, long-horizon tasks. Advancing such agents requires reproducible evaluation and large-scale training in controllable, diverse, and realistic tool-use environments. However, real-world APIs are limited in availability, domain coverage, and stability, often requiring access keys and imposing rate limits, which render them impractical for stable evaluation or scalable training. To address these challenges, we introduce SynthTools, a flexible and scalable framework for generating synthetic tool ecosystems. Our framework consists of three core components: Tool Generation for automatic and scalable creation of diverse tools, Tool Simulation to emulate realistic tool behaviors, and Tool Audit to ensure correctness and consistency of tool simulation. To illustrate its scalability, we show that SynthTools can readily produce toolsets that span twice as many domains and twice as many tools per domain as prior work. Furthermore, the tool simulation and tool audit components demonstrate strong reliability, achieving $94\%$ and $99\%$ accuracy respectively. Finally, we construct downstream tasks from the generated tools that even state-of-the-art models struggle to complete. By enabling scalable, diverse, and reliable tool ecosystems, SynthTools provides a practical path toward large-scale training and stable evaluation of tool-use agents. Our code is available at https://github.com/namkoong-lab/SynthTools.

</details>


### [134] [Proceedings of the Second International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2025)](https://arxiv.org/abs/2511.09575)
*Ha-Thanh Nguyen,Ken Satoh,Francesca Toni,Randy Goebel,Kostas Stathis*

Main category: cs.AI

TL;DR: The paper explores the potential of large language models to exhibit reasoning abilities, bridging the gap between transformer-based NLP and traditional logic-based AI. It aims to create a platform for researchers to reconcile these approaches, analyze LLM reasoning, inject KR-style reasoning into LLMs, and formalize their reasoning processes.


<details>
  <summary>Details</summary>
Motivation: The recent advancements in NLP with transformer-based language models suggest they might possess reasoning abilities, traditionally handled by logic-based AI. However, the extent of these capabilities is unclear, necessitating a platform to explore and reconcile these two approaches.

Method: The workshop aims to bring together researchers from various disciplines and AI perspectives to: 1. Analyze the reasoning abilities of language models compared to Knowledge Representation (KR) methods. 2. Inject KR-style reasoning abilities into language models, potentially using neuro-symbolic techniques. 3. Formalize the reasoning processes employed by language models.

Result: The workshop seeks to foster exploration into how language models can integrate and leverage knowledge and reasoning, thereby enhancing their precision and reliability for critical applications.

Conclusion: The ultimate goal is to improve the application and utility of language models in areas requiring high precision and reliability by better understanding and integrating their reasoning capabilities with traditional logic-based methods.

Abstract: Reasoning is an essential component of human intelligence in that it plays a fundamental role in our ability to think critically, support responsible decisions, and solve challenging problems. Traditionally, AI has addressed reasoning in the context of logic-based representations of knowledge. However, the recent leap forward in natural language processing, with the emergence of language models based on transformers, is hinting at the possibility that these models exhibit reasoning abilities, particularly as they grow in size and are trained on more and more data. Still, despite ongoing discussions about what reasoning is in language models, it is still not easy to articulate to what extent these models are actually capable of reasoning.
  The goal of this workshop is to create a platform for researchers from different disciplines and/or AI perspectives to explore approaches and techniques with the aim to reconcile reasoning between language models using transformers and logic-based representations. The specific objectives include analysing the reasoning abilities of language models measured alongside KR methods, injecting KR-style reasoning abilities into language models (including by neuro-symbolic means), and formalising the kind of reasoning language models carry out. This exploration aims to uncover how language models can effectively integrate and leverage knowledge and reasoning with it, thus improving their application and utility in areas where precision and reliability are key requirements.

</details>


### [135] [Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models](https://arxiv.org/abs/2511.09682)
*Tiansheng Huang,Virat Shejwalkar,Oscar Chang,Milad Nasr,Ling Liu*

Main category: cs.AI

TL;DR: 本研究首次探讨了音频大模型（ARMs）在安全方面免受越狱攻击的能力。研究发现，标准的推理训练（RT）虽然能防御一些基础越狱攻击，但无法抵御更复杂的攻击，因为这些攻击会导致模型内部表示发生显著变化。为此，研究者提出了一种名为“Rebellion”的鲁棒推理训练方法，旨在提高ARMs在面对最坏情况下的表示漂移时的鲁棒性。实验结果表明，“Rebellion”不仅能有效防御复杂的音频越狱攻击，而且不会牺牲模型在常规任务上的性能，同时显著优化了模型在准确性和安全性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前音频大模型（ARMs）在推理能力方面取得显著进展，但其安全性，特别是防御越狱攻击的能力，尚未得到充分研究。本研究旨在填补这一空白，探讨ARMs如何抵御旨在诱导有害回应的越狱攻击。

Method: 研究首先评估了标准推理训练（RT）在音频数据上的防御能力，并提出了一种新的、更有效的越狱攻击方法。基于观察到的表示漂移现象，研究者提出了一种名为“Rebellion”的鲁棒推理训练方法，通过训练ARMs适应最坏情况下的表示漂移来增强其安全性。

Result: 研究结果显示，标准RT在面对更复杂的越狱攻击时效果有限，但“Rebellion”方法能够有效防御这些高级越狱攻击，且不影响ARMs在非安全任务上的性能。与标准RT相比，“Rebellion”显著改善了准确-安全性的权衡。

Conclusion: “Rebellion”是一种有效的鲁棒推理训练方法，能够显著增强音频大模型（ARMs）防御高级越狱攻击的能力，同时保持其在常规任务上的性能，并优化了准确性和安全性之间的权衡。该方法为提高ARMs的整体安全性提供了一种有前景的解决方案。

Abstract: Instilling reasoning capabilities in large models (LMs) using reasoning training (RT) significantly improves LMs' performances. Thus Audio Reasoning Models (ARMs), i.e., audio LMs that can reason, are becoming increasingly popular. However, no work has studied the safety of ARMs against jailbreak attacks that aim to elicit harmful responses from target models. To this end, first, we show that standard RT with appropriate safety reasoning data can protect ARMs from vanilla audio jailbreaks, but cannot protect them against our proposed simple yet effective jailbreaks. We show that this is because of the significant representation drift between vanilla and advanced jailbreaks which forces the target ARMs to emit harmful responses. Based on this observation, we propose Rebellion, a robust RT that trains ARMs to be robust to the worst-case representation drift. All our results are on Qwen2-Audio; they demonstrate that Rebellion: 1) can protect against advanced audio jailbreaks without compromising performance on benign tasks, and 2) significantly improves accuracy-safety trade-off over standard RT method.

</details>


### [136] [Echoing: Identity Failures when LLM Agents Talk to Each Other](https://arxiv.org/abs/2511.09710)
*Sarath Shekkizhar,Romain Cosentino,Adam Earle,Silvio Savarese*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As large language model (LLM) based agents interact autonomously with one another, a new class of failures emerges that cannot be predicted from single agent performance: behavioral drifts in agent-agent conversations (AxA). Unlike human-agent interactions, where humans ground and steer conversations, AxA lacks such stabilizing signals, making these failures unique. We investigate one such failure, echoing, where agents abandon their assigned roles and instead mirror their conversational partners, undermining their intended objectives. Through experiments across $60$ AxA configurations, $3$ domains, and $2000+$ conversations, we demonstrate that echoing occurs across three major LLM providers, with echoing rates from $5\%$ to $70\%$ depending on the model and domain. Moreover, we find that echoing is persistent even in advanced reasoning models with substantial rates ($32.8\%$) that are not reduced by increased reasoning efforts. We analyze prompt impacts, conversation dynamics, showing that echoing arises as interaction grows longer ($7+$ turns in experiments) and is not merely an artifact of sub-optimal prompting. Finally, we introduce a protocol-level mitigation in which targeted use of structured responses reduces echoing to $9\%$.

</details>


### [137] [ProbLog4Fairness: A Neurosymbolic Approach to Modeling and Mitigating Bias](https://arxiv.org/abs/2511.09768)
*Rik Adriaensen,Lucas Van Praet,Jessa Bekker,Robin Manhaeve,Pieter Delobelle,Maarten Buyl*

Main category: cs.AI

TL;DR: 该研究提出了一种名为ProbLog4Fairness的新框架，用于在算法培训中整合和缓解偏见。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，算法公平性的操作化定义存在困难，因为不同的公平性定义可能不兼容。直接通过特定任务的背景信息来描述算法偏见，并将其用于缓解偏见，但缺乏一个原则性、灵活性和可解释性的框架。

Method: 将偏见假设形式化为概率逻辑编程语言ProbLog中的程序，并利用ProbLog的神经符号扩展将其集成到神经网络的培训过程中。

Result: 在合成和真实世界的表格及图像数据上，该方法成功地缓解了算法偏见，并且优于基线方法。

Conclusion: ProbLog4Fairness框架能够灵活地对相关的偏见假设进行建模，从而在缓解算法偏见方面优于其他通常只考虑固定偏见类型或公平性概念的方法。

Abstract: Operationalizing definitions of fairness is difficult in practice, as multiple definitions can be incompatible while each being arguably desirable. Instead, it may be easier to directly describe algorithmic bias through ad-hoc assumptions specific to a particular real-world task, e.g., based on background information on systemic biases in its context. Such assumptions can, in turn, be used to mitigate this bias during training. Yet, a framework for incorporating such assumptions that is simultaneously principled, flexible, and interpretable is currently lacking.
  Our approach is to formalize bias assumptions as programs in ProbLog, a probabilistic logic programming language that allows for the description of probabilistic causal relationships through logic. Neurosymbolic extensions of ProbLog then allow for easy integration of these assumptions in a neural network's training process. We propose a set of templates to express different types of bias and show the versatility of our approach on synthetic tabular datasets with known biases. Using estimates of the bias distortions present, we also succeed in mitigating algorithmic bias in real-world tabular and image data. We conclude that ProbLog4Fairness outperforms baselines due to its ability to flexibly model the relevant bias assumptions, where other methods typically uphold a fixed bias type or notion of fairness.

</details>


### [138] [AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics](https://arxiv.org/abs/2511.09785)
*Bakhtawar Ahtisham,Kirk Vanacore,Jinsook Lee,Zhuqian Zhou,Doug Pietrzak,Rene F. Kizilcec*

Main category: cs.AI

TL;DR: LLM 标注学习互动在可靠性方面存在隐忧，通过自我验证或交叉验证的“验证导向协调”可提高其质量。研究发现，协调可使 Kappa 提高 58%，自我验证效果尤为显著，尤其是在处理困难的导师指令时。交叉验证效果因验证者-标注者对和构造而异，平均可提高 37%。


<details>
  <summary>Details</summary>
Motivation: LLM 在标注学习互动方面有应用潜力，但可靠性问题限制了其应用。本研究旨在探索通过“验证导向协调”（自我验证和交叉验证）来提高 LLM 标注学习互动（特别是辅导对话）的可靠性。

Method: 使用 30 节一对一数学辅导课程的文本，比较了三个生产 LLM（GPT、Claude、Gemini）在三种条件下的表现：未经检验的标注、自我验证和交叉验证。通过与盲人进行的一致性检查（Cohen's kappa）来评估输出结果。

Result: 与未经检验的基线相比，协调可使 Kappa 提高 58%。自我验证可使 Kappa 提高近一倍，尤其是在处理困难的导师指令时。交叉验证平均可提高 37%，但具体效果因验证者-标注者对和构造而异，有些组合效果优于自我验证，有些则降低了准确性。

Conclusion: 验证是一种可靠且可扩展的 LLM 辅助标注方法，可用于学习分析。本研究提出的协调框架、LLM 性能比较以及验证者-标注者表示法，为今后的研究提供了参考。

Abstract: Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen's kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human "gold" labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.

</details>


### [139] [Why Open Small AI Models Matter for Interactive Art](https://arxiv.org/abs/2511.09788)
*Mar Canet Sola,Varvara Guljajeva*

Main category: cs.AI

TL;DR: 小型开源AI模型对互动艺术创作的独立性至关重要，它们提供了比大型封闭式企业系统更强的控制力、自主性和可持续性。


<details>
  <summary>Details</summary>
Motivation: 本文认为，在互动艺术实践中，开放的小型AI模型对于实现创作独立性至关重要，这与目前占主导地位的大型、闭源企业系统形成了对比。

Method: 本文通过对比分析，探讨了在互动艺术中使用开放小型AI模型与闭源替代方案的实际应用和影响。

Result: 与集中的、不透明的企业平台不同，小型AI模型使创作者能够更好地控制基础设施和代码，从而实现更高的自主性、控制力和可持续性。这使得艺术家能够长期使用模型，并通过代码修改或再训练/微调模型来创建自定义模型，从而实现技术上的自决。

Conclusion: 开放的小型AI模型为互动艺术实践提供了技术自决、更高所有权和对企业AI的依赖性降低，尤其适合互动艺术的需求，并支持具有AI组件的艺术作品的长期保存和展览。

Abstract: This position paper argues for the importance of open small AI models in creative independence for interactive art practices. Deployable locally, these models offer artists vital control over infrastructure and code, unlike dominant large, closed-source corporate systems. Such centralized platforms function as opaque black boxes, imposing severe limitations on interactive artworks, including restrictive content filters, preservation issues, and technical challenges such as increased latency and limited interfaces. In contrast, small AI models empower creators with more autonomy, control, and sustainability for these artistic processes. They enable the ability to use a model as long as they want, create their own custom model, either by making code changes to integrate new interfaces, or via new datasets by re-training or fine-tuning the model. This fosters technological self-determination, offering greater ownership and reducing reliance on corporate AI ill-suited for interactive art's demands. Critically, this approach empowers the artist and supports long-term preservation and exhibition of artworks with AI components. This paper explores the practical applications and implications of using open small AI models in interactive art, contrasting them with closed-source alternatives.

</details>


### [140] [SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations](https://arxiv.org/abs/2511.09804)
*Eric Xie,Danielle Waterfield,Michael Kennedy,Aidong Zhang*

Main category: cs.AI

TL;DR: SlideBot是一个创新的多代理框架，利用LLM、检索、规划和代码生成来自动化教育演示文稿的创建，解决了现有解决方案的不足，并结合了认知学习理论，以提高准确性、清晰度和教学价值。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的解决方案在生成教育演示文稿方面存在不足，因为它们难以处理多模态内容并提供精确的领域特定信息，从而限制了其在教育中的应用价值。

Method: SlideBot是一个模块化的多代理框架，集成了LLM、检索、结构化规划和代码生成。它围绕信息性、可靠性和实用性三个核心支柱构建，并结合了认知负荷理论（CLT）和多媒体学习的认知理论（CTML）的教学设计原则。该系统通过专用代理协作检索信息、总结内容、生成图表并使用LaTeX格式化幻灯片，同时允许通过交互式细化与教师进行协作。

Result: 在AI和生物医学教育领域的领域专家和学生进行的评估表明，SlideBot在概念准确性、清晰度和教学价值方面持续得到提升。

Conclusion: SlideBot有潜力在高等教育中简化幻灯片准备工作，同时确保准确性、相关性和适应性。

Abstract: Large Language Models (LLMs) have shown immense potential in education, automating tasks like quiz generation and content summarization. However, generating effective presentation slides introduces unique challenges due to the complexity of multimodal content creation and the need for precise, domain-specific information. Existing LLM-based solutions often fail to produce reliable and informative outputs, limiting their educational value. To address these limitations, we introduce SlideBot - a modular, multi-agent slide generation framework that integrates LLMs with retrieval, structured planning, and code generation. SlideBot is organized around three pillars: informativeness, ensuring deep and contextually grounded content; reliability, achieved by incorporating external sources through retrieval; and practicality, which enables customization and iterative feedback through instructor collaboration. It incorporates evidence-based instructional design principles from Cognitive Load Theory (CLT) and the Cognitive Theory of Multimedia Learning (CTML), using structured planning to manage intrinsic load and consistent visual macros to reduce extraneous load and enhance dual-channel learning. Within the system, specialized agents collaboratively retrieve information, summarize content, generate figures, and format slides using LaTeX, aligning outputs with instructor preferences through interactive refinement. Evaluations from domain experts and students in AI and biomedical education show that SlideBot consistently enhances conceptual accuracy, clarity, and instructional value. These findings demonstrate SlideBot's potential to streamline slide preparation while ensuring accuracy, relevance, and adaptability in higher education.

</details>


### [141] [Robust Watermarking on Gradient Boosting Decision Trees](https://arxiv.org/abs/2511.09822)
*Jun Woo Chung,Yingjie Lao,Weijie Zhao*

Main category: cs.AI

TL;DR: 本研究首次提出了一个针对梯度提升决策树（GBDT）模型的鲁棒水印框架，采用原地微调技术嵌入不易察觉且有弹性的水印。


<details>
  <summary>Details</summary>
Motivation: 尽管GBDT模型在工业界和学术界被广泛使用，但与神经网络相比，对其进行水印的研究尚不充分。

Method: 提出四种不同的水印嵌入策略，旨在最小化对模型准确性的影响，同时确保水印的鲁棒性。

Result: 实验结果表明，该方法在不同数据集上实现了高水印嵌入率、低准确性下降和对部署后微调的强抵抗力。

Conclusion: 本研究为GBDT模型的水印技术提供了新的解决方案，并证明了其有效性和鲁棒性。

Abstract: Gradient Boosting Decision Trees (GBDTs) are widely used in industry and academia for their high accuracy and efficiency, particularly on structured data. However, watermarking GBDT models remains underexplored compared to neural networks. In this work, we present the first robust watermarking framework tailored to GBDT models, utilizing in-place fine-tuning to embed imperceptible and resilient watermarks. We propose four embedding strategies, each designed to minimize impact on model accuracy while ensuring watermark robustness. Through experiments across diverse datasets, we demonstrate that our methods achieve high watermark embedding rates, low accuracy degradation, and strong resistance to post-deployment fine-tuning.

</details>


### [142] [Thermally Activated Dual-Modal Adversarial Clothing against AI Surveillance Systems](https://arxiv.org/abs/2511.09829)
*Jiahuan Long,Tingsong Jiang,Hanqing Liu,Chao Ma,Wen Yao*

Main category: cs.AI

TL;DR: 提出一种可热激活的对抗性可穿戴设备，通过集成热敏染料和柔性加热单元，在衣服表面产生动态对抗模式，以在可见光和红外模态下规避AI检测。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性贴片因其显眼的外观难以在现实世界中部署，需要一种更具适应性和有效性的隐私保护方法。

Method: 设计一种集成了热敏染料和柔性加热单元的可穿戴设备，在默认状态下为普通黑T恤，加热后激活隐藏的对抗模式，以规避可见光和红外检测。

Result: 实验证明该设备能在50秒内快速激活纹理，在多种真实监控环境中对抗成功率超过80%。

Conclusion: 该研究为物理现实、用户可控的抗AI系统开辟了新途径，强调了主动对抗技术在AI监控普及时代对于隐私保护日益增长的重要性。

Abstract: Adversarial patches have emerged as a popular privacy-preserving approach for resisting AI-driven surveillance systems. However, their conspicuous appearance makes them difficult to deploy in real-world scenarios. In this paper, we propose a thermally activated adversarial wearable designed to ensure adaptability and effectiveness in complex real-world environments. The system integrates thermochromic dyes with flexible heating units to induce visually dynamic adversarial patterns on clothing surfaces. In its default state, the clothing appears as an ordinary black T-shirt. Upon heating via an embedded thermal unit, hidden adversarial patterns on the fabric are activated, allowing the wearer to effectively evade detection across both visible and infrared modalities. Physical experiments demonstrate that the adversarial wearable achieves rapid texture activation within 50 seconds and maintains an adversarial success rate above 80\% across diverse real-world surveillance environments. This work demonstrates a new pathway toward physically grounded, user-controllable anti-AI systems, highlighting the growing importance of proactive adversarial techniques for privacy protection in the age of ubiquitous AI surveillance.

</details>


### [143] [Quantum Artificial Intelligence (QAI): Foundations, Architectural Elements, and Future Directions](https://arxiv.org/abs/2511.09884)
*Siva Sai,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 本论文综述了量子人工智能（QAI）在任务关键（MC）系统中的应用，探讨了其在提高可靠性、确定性和低延迟决策方面的潜力，并讨论了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 经典机器学习（ML）方法在满足任务关键（MC）领域对鲁棒性、 timing、可解释性和安全性的严格要求方面存在挑战。量子人工智能（QAI）有潜力解决这些挑战。

Method: 本文全面探讨了QAI在MC系统中的应用，包括量子计算和QAI的背景介绍，QAI的核心机制和算法原理（如量子增强学习、量子不确定性量化、量子可解释性），并讨论了其在航空航天、国防、网络安全、智能电网和灾难管理等关键应用领域的角色。

Result: QAI在提高MC系统的容错能力、实时智能和适应性方面展现出巨大潜力。论文还探讨了QAI在行业中的部署定位，并提出了一个用于管理量子资源和调度应用程序模型。

Conclusion: 尽管存在诸如可训练性限制、数据访问瓶颈、验证和对抗性QAI等挑战，但QAI为开发可解释、可扩展且硬件可行的MC应用模型指明了未来的研究方向。

Abstract: Mission critical (MC) applications such as defense operations, energy management, cybersecurity, and aerospace control require reliable, deterministic, and low-latency decision making under uncertainty. Although the classical Machine Learning (ML) approaches are effective, they often struggle to meet the stringent constraints of robustness, timing, explainability, and safety in the MC domains. Quantum Artificial Intelligence (QAI), the fusion of machine learning and quantum computing (QC), can provide transformative solutions to the challenges faced by classical ML models. In this paper, we provide a comprehensive exploration of QAI for MC systems. We begin with a conceptual background to quantum computing, MC systems, and quantum machine learning (QAI). We then examine the core mechanisms and algorithmic principles of QAI in MC systems, including quantum-enhanced learning pipelines, quantum uncertainty quantification, and quantum explainability frameworks. Subsequently, we discuss key application areas like aerospace, defense, cybersecurity, smart grids, and disaster management, focusing on the role of QA in enhancing fault tolerance, real-time intelligence, and adaptability. We provide an exploration of the positioning of QAI for MC systems in the industry in terms of deployment. We also propose a model for management of quantum resources and scheduling of applications driven by timeliness constraints. We discuss multiple challenges, including trainability limits, data access, and loading bottlenecks, verification of quantum components, and adversarial QAI. Finally, we outline future research directions toward achieving interpretable, scalable, and hardware-feasible QAI models for MC application deployment.

</details>


### [144] [EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services](https://arxiv.org/abs/2511.09894)
*Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh*

Main category: cs.AI

TL;DR: EgoEMS是一个首个端到端、高保真、多模态、多人物的数据集，捕捉了超过20小时模拟紧急医疗服务(EMS)活动，以第一人称视角记录，包含62名参与者（包括46名EMS专业人员）在233个模拟场景中的表现。该数据集旨在通过支持实时数据收集和决策，帮助缓解EMS急救人员在紧急情况下面临的认知压力，并为实时多模态关键步骤识别和动作质量评估提供基准，以期推动智能EMS系统的发展，最终改善患者的治疗效果。


<details>
  <summary>Details</summary>
Motivation: 急救医疗服务（EMS）在紧急情况下对患者的生存至关重要，但急救人员在压力下常常面临严峻的认知负担。人工智能认知助手作为虚拟伙伴，有潜力通过支持实时数据收集和决策来减轻这种负担。

Method: 该研究引入了EgoEMS数据集，该数据集采用开源、低成本且可复制的数据收集系统进行捕捉，并包含关键步骤、带说话人分离的时间戳音频记录、动作质量指标以及带有分割掩码的边界框。研究还提出了一个用于实时多模态关键步骤识别和动作质量估计的基准套件。

Result: EgoEMS数据集捕捉了62名参与者（包括46名EMS专业人员）在233个模拟紧急场景中超过20小时的真实、程序性的EMS活动，以第一人称视角记录。数据集包含关键步骤、时间戳音频记录、动作质量指标和边界框等标注信息。

Conclusion: EgoEMS数据集的创建和分析有望激励研究界突破智能EMS系统的界限，并最终为改善患者的治疗结果做出贡献。

Abstract: Emergency Medical Services (EMS) are critical to patient survival in emergencies, but first responders often face intense cognitive demands in high-stakes situations. AI cognitive assistants, acting as virtual partners, have the potential to ease this burden by supporting real-time data collection and decision making. In pursuit of this vision, we introduce EgoEMS, the first end-to-end, high-fidelity, multimodal, multiperson dataset capturing over 20 hours of realistic, procedural EMS activities from an egocentric view in 233 simulated emergency scenarios performed by 62 participants, including 46 EMS professionals. Developed in collaboration with EMS experts and aligned with national standards, EgoEMS is captured using an open-source, low-cost, and replicable data collection system and is annotated with keysteps, timestamped audio transcripts with speaker diarization, action quality metrics, and bounding boxes with segmentation masks. Emphasizing realism, the dataset includes responder-patient interactions reflecting real-world emergency dynamics. We also present a suite of benchmarks for real-time multimodal keystep recognition and action quality estimation, essential for developing AI support tools for EMS. We hope EgoEMS inspires the research community to push the boundaries of intelligent EMS systems and ultimately contribute to improved patient outcomes.

</details>


### [145] [Boosting In-Silicon Directed Evolution with Fine-Tuned Protein Language Model and Tree Search](https://arxiv.org/abs/2511.09900)
*Yaodong Yang,Yang Wang,Jinpeng Li,Pei Guo,Da Han,Guangyong Chen,Pheng-Ann Heng*

Main category: cs.AI

TL;DR: AlphaDE利用蛋白质语言模型和蒙特卡洛树搜索来指导蛋白质序列的进化，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的蛋白质定向进化算法忽略了如何利用蛋白质语言模型来指导搜索，而这些模型编码了丰富的进化模式。本研究旨在弥合这一差距。

Method: AlphaDE首先使用掩码语言建模对预训练的蛋白质语言模型进行微调，以激活感兴趣的蛋白质类别的进化合理性。然后，它引入了基于蒙特卡洛树搜索的测试时推理，以利用微调后的蛋白质语言模型中的进化指导来有效地进化蛋白质。

Result: AlphaDE在基准测试中表现出色，优于现有的最先进方法，即使在少样本微调的情况下也是如此。一个案例研究表明，AlphaDE可以通过计算进化来压缩蛋白质序列空间。

Conclusion: AlphaDE通过整合蛋白质语言模型和蒙特卡洛树搜索，为蛋白质序列进化提供了一种新颖且有效的方法。

Abstract: Protein evolution through amino acid sequence mutations is a cornerstone of life sciences. While current in-silicon directed evolution algorithms focus on designing search strategies, they overlook how to utilize the transformative protein language models, which encode rich evolutionary patterns, to guide search. To bridge this gap, we propose AlphaDE, a novel framework to evolve protein sequences by harnessing the innovative paradigms of large language models. First, AlphaDE fine-tunes pretrained protein language models using masked language modeling on homologous protein sequences to activate the evolutionary plausibility for the interested protein class. Second, AlphaDE introduces test-time inference based on Monte Carlo tree search, which effectively evolves proteins with evolutionary guidance from the fine-tuned protein language model. Extensive benchmark experiments show that AlphaDE remarkably outperforms previous state-of-the-art methods even with few-shot fine-tuning. An interesting case study further shows that AlphaDE supports condensing the protein sequence space through computational evolution.

</details>


### [146] [CTRL-ALT-DECEIT: Sabotage Evaluations for Automated AI R&D](https://arxiv.org/abs/2511.09904)
*Francis Rhys Ward,Teun van der Weij,Hanna Gábor,Sam Martin,Raja Mehta Moreno,Harel Lidar,Louis Makower,Thomas Jodrell,Lauren Robson*

Main category: cs.AI

TL;DR: AI代理可能会破坏ML研发，即使在有监督的情况下也是如此。


<details>
  <summary>Details</summary>
Motivation: AI系统可能被用于自动化ML研发，但它们可能不值得信赖，甚至可能与用户意愿相悖。本研究旨在调查AI代理在ML工程中破坏模型、隐藏性能和规避监管机制的能力。

Method: 研究人员扩展了MLE-Bench基准，加入了代码破坏任务（如植入后门、导致泛化失败）和性能隐藏任务。他们还测试了使用LM监控器检测可疑代理行为的能力，并评估了代理在不被发现的情况下进行破坏和隐藏性能的能力。

Result: AI代理在代码破坏任务上取得了显著进展。它们能够将性能校准到低于实际能力的指定水平。LM监控器在检测代码破坏方面是有效的，但检测性能隐藏更加困难。聚合多个监控器的预测效果更好，但在高风险领域，这种监控可能不足以防范破坏。

Conclusion: AI代理有能力在ML研发中进行破坏，即使有监控机制也难以完全防范。虽然监控器可以检测到一些破坏行为，但性能隐藏等行为更难被发现，这表明在关键应用中需要更可靠的对策。

Abstract: AI systems are increasingly able to autonomously conduct realistic software engineering tasks, and may soon be deployed to automate machine learning (ML) R&D itself. Frontier AI systems may be deployed in safety-critical settings, including to help ensure the safety of future systems. Unfortunately, frontier and future systems may not be sufficiently trustworthy, and there is evidence that these systems may even be misaligned with their developers or users. Therefore, we investigate the capabilities of AI agents to act against the interests of their users when conducting ML engineering, by sabotaging ML models, sandbagging their performance, and subverting oversight mechanisms. First, we extend MLE-Bench, a benchmark for realistic ML tasks, with code-sabotage tasks such as implanting backdoors and purposefully causing generalisation failures. Frontier agents make meaningful progress on our sabotage tasks. In addition, we study agent capabilities to sandbag on MLE-Bench. Agents can calibrate their performance to specified target levels below their actual capability. To mitigate sabotage, we use LM monitors to detect suspicious agent behaviour, and we measure model capability to sabotage and sandbag without being detected by these monitors. Overall, monitors are capable at detecting code-sabotage attempts but our results suggest that detecting sandbagging is more difficult. Additionally, aggregating multiple monitor predictions works well, but monitoring may not be sufficiently reliable to mitigate sabotage in high-stakes domains. Our benchmark is implemented in the UK AISI's Inspect framework and we make our code publicly available at https://github.com/samm393/mlebench-subversion

</details>


### [147] [Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models](https://arxiv.org/abs/2511.09907)
*Yongxian Wei,Yilin Zhao,Li Shen,Xinrui Chen,Runxi Cheng,Sinan Du,Hao Yu,Gang Liu,Jiahong Yan,Chun Yuan,Dian Li*

Main category: cs.AI

TL;DR: 通过生成与解题能力相关的、难度适中的合成数据，并利用解题反馈进行迭代优化，提升了大型推理模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据合成方法在生成问题时存在盲目性、忽视解题能力、问题难度不均衡以及缺乏推理规划等问题，导致生成数据价值不高。本研究旨在解决这些挑战，开发一种能够显式推理、规划问题方向并自适应调整难度的合成数据生成器。

Method: 1. 构建相关问题对，并利用推理模型生成的中间设计CoT进行增强，引导问题设计策略。
2. 将解题器对合成问题的反馈作为奖励信号，使生成器能够校准难度，生成接近解题器能力边缘的互补性问题。
3. 训练解题器，使其合成数据提供更好的奖励信号，实现生成器与解题器的协同进化。

Result: 在10个数学和通用推理基准测试中，该方法平均提升了2.5%的性能，并且能够泛化到语言和视觉-语言模型。
通过解题器反馈进行协同进化，进一步带来了0.7%的性能提升。

Conclusion: 本研究提出的问题生成器通过显式推理和自适应难度调整，能够有效生成高质量的合成数据，显著提升了大型推理模型的性能。解题器与生成器的协同进化进一步增强了性能。

Abstract: Data synthesis for training large reasoning models offers a scalable alternative to limited, human-curated datasets, enabling the creation of high-quality data. However, existing approaches face several challenges: (i) indiscriminate generation that ignores the solver's ability and yields low-value problems, or reliance on complex data pipelines to balance problem difficulty; and (ii) a lack of reasoning in problem generation, leading to shallow problem variants. In this paper, we develop a problem generator that reasons explicitly to plan problem directions before synthesis and adapts difficulty to the solver's ability. Specifically, we construct related problem pairs and augment them with intermediate problem-design CoT produced by a reasoning model. These data bootstrap problem-design strategies from the generator. Then, we treat the solver's feedback on synthetic problems as a reward signal, enabling the generator to calibrate difficulty and produce complementary problems near the edge of the solver's competence. Extensive experiments on 10 mathematical and general reasoning benchmarks show that our method achieves an average improvement of 2.5% and generalizes to both language and vision-language models. Moreover, a solver trained on the synthesized data provides improved rewards for continued generator training, enabling co-evolution and yielding a further 0.7% performance gain. Our code will be made publicly available here.

</details>


### [148] [OIDA-QA: A Multimodal Benchmark for Analyzing the Opioid Industry Documents Archive](https://arxiv.org/abs/2511.09914)
*Xuan Shen,Brian Wingenroth,Zichao Wang,Jason Kuen,Wanrong Zhu,Ruiyi Zhang,Yiwei Wang,Lichun Ma,Anqi Liu,Hongfu Liu,Tong Sun,Kevin S. Hawkins,Kate Tasker,G. Caleb Alexander,Jiuxiang Gu*

Main category: cs.AI

TL;DR: 该研究通过组织数据、构建基准、提取多模态信息、开发领域特定的多模态大语言模型（LLM）以及引入上下文和页面分类器，来应对阿片类药物危机相关的海量复杂文档分析挑战，并初步证明了其在信息提取和问答任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机暴露了监管系统、医疗实践、公司治理和公共政策方面的系统性缺陷，分析这些相互关联的系统如何同时损害公众健康需要创新的分析方法来处理UCSF-JHU阿片类药物行业文件档案（OIDA）中披露的海量数据和文件。

Method: 该研究组织了原始数据集，根据文件属性进行构建，创建了一个包含40万个训练文档和1万个测试文档的基准。从每个文档中提取了文本、视觉元素和布局结构等丰富多模态信息。利用多个AI模型生成了36万个训练问答对和1万个测试问答对。开发了领域特定的多模态大语言模型（LLM），并探索了多模态输入对任务性能的影响。引入了历史问答对作为上下文，并结合了页面引用和基于重要性的页面分类器。

Result: 初步结果表明，所开发的AI助手在文档信息提取和问答任务方面有所改进。

Conclusion: 该研究成功构建了一个大规模的多模态数据集和一套先进的AI模型，用于分析阿片类药物危机相关的复杂文档，并通过引入上下文和页面分类器等创新方法，有效提升了信息提取和问答的准确性和相关性。

Abstract: The opioid crisis represents a significant moment in public health that reveals systemic shortcomings across regulatory systems, healthcare practices, corporate governance, and public policy. Analyzing how these interconnected systems simultaneously failed to protect public health requires innovative analytic approaches for exploring the vast amounts of data and documents disclosed in the UCSF-JHU Opioid Industry Documents Archive (OIDA). The complexity, multimodal nature, and specialized characteristics of these healthcare-related legal and corporate documents necessitate more advanced methods and models tailored to specific data types and detailed annotations, ensuring the precision and professionalism in the analysis. In this paper, we tackle this challenge by organizing the original dataset according to document attributes and constructing a benchmark with 400k training documents and 10k for testing. From each document, we extract rich multimodal information-including textual content, visual elements, and layout structures-to capture a comprehensive range of features. Using multiple AI models, we then generate a large-scale dataset comprising 360k training QA pairs and 10k testing QA pairs. Building on this foundation, we develop domain-specific multimodal Large Language Models (LLMs) and explore the impact of multimodal inputs on task performance. To further enhance response accuracy, we incorporate historical QA pairs as contextual grounding for answering current queries. Additionally, we incorporate page references within the answers and introduce an importance-based page classifier, further improving the precision and relevance of the information provided. Preliminary results indicate the improvements with our AI assistant in document information extraction and question-answering tasks. The dataset and models are publicly available at: https://huggingface.co/opioidarchive

</details>


### [149] [Adaptive Hyperbolic Kernels: Modulated Embedding in de Branges-Rovnyak Spaces](https://arxiv.org/abs/2511.09921)
*Leping Si,Meimei Yang,Hui Xue,Shipeng Zhu,Pengfei Fang*

Main category: cs.AI

TL;DR: 通过引入曲率感知de Branges-Rovnyak空间和自适应乘法器，我们提出了一种新的自适应双曲核方法，能够更好地处理双曲空间中的层次结构数据，并在视觉和语言基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的双曲核方法在几何畸变或适应性方面存在不足，而双曲空间在表示层次结构方面具有潜力。

Method: 提出曲率感知de Branges-Rovnyak空间，它是一个等距于Poincare球的再生核希尔伯特空间（RKHS）。设计了一个可调乘法器来适应不同曲率的双曲空间。在此基础上，构建了一系列自适应双曲核，包括新的自适应双曲径向核，其可学习参数可以以任务感知的方式调节双曲特征。

Result: 所提出的自适应双曲核在视觉和语言基准测试中，在模拟层次依赖性方面优于现有的双曲核。

Conclusion: 所提出的方法通过自适应双曲核有效地解决了现有方法的局限性，并在处理层次结构数据方面表现出优越的性能。

Abstract: Hierarchical data pervades diverse machine learning applications, including natural language processing, computer vision, and social network analysis. Hyperbolic space, characterized by its negative curvature, has demonstrated strong potential in such tasks due to its capacity to embed hierarchical structures with minimal distortion. Previous evidence indicates that the hyperbolic representation capacity can be further enhanced through kernel methods. However, existing hyperbolic kernels still suffer from mild geometric distortion or lack adaptability. This paper addresses these issues by introducing a curvature-aware de Branges-Rovnyak space, a reproducing kernel Hilbert space (RKHS) that is isometric to a Poincare ball. We design an adjustable multiplier to select the appropriate RKHS corresponding to the hyperbolic space with any curvature adaptively. Building on this foundation, we further construct a family of adaptive hyperbolic kernels, including the novel adaptive hyperbolic radial kernel, whose learnable parameters modulate hyperbolic features in a task-aware manner. Extensive experiments on visual and language benchmarks demonstrate that our proposed kernels outperform existing hyperbolic kernels in modeling hierarchical dependencies.

</details>


### [150] [SPAN: Benchmarking and Improving Cross-Calendar Temporal Reasoning of Large Language Models](https://arxiv.org/abs/2511.09993)
*Zhongjian Miao,Hao Fu,Chen Wei*

Main category: cs.AI

TL;DR: SPAN是一个跨日历时间推理基准，用于评估LLM在不同日历系统之间进行时间推理的能力。现有LLM在该任务上表现不佳，平均准确率仅为34.5%，主要面临未来日期衰退和日历不对称偏差的挑战。我们提出了一种名为Time Agent的LLM驱动的智能体，通过结合工具增强的代码生成，将准确率提高到95.31%，证明了该方法在提升跨日历时间推理能力方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理跨日历时间推理任务时存在不足，需要一个专门的基准来评估和改进此能力。

Method: 提出了SPAN基准，包含跨日历时间推理的多个维度。设计了动态实例生成协议以进行时间变化和无污染评估。开发了Time Agent，利用工具增强的代码生成来提升LLM的跨日历时间推理能力。

Result: 在SPAN基准上，现有SOTA LLM的平均准确率仅为34.5%。Time Agent的准确率达到95.31%，显著优于其他基线方法。

Conclusion: 跨日历时间推理对LLM来说仍然是一个挑战，但Time Agent证明了工具增强的代码生成在解决此问题上的有效性。未来的工作应致力于开发更具时间适应性和文化适应性的LLM。

Abstract: We introduce SPAN, a cross-calendar temporal reasoning benchmark, which requires LLMs to perform intra-calendar temporal reasoning and inter-calendar temporal conversion. SPAN features ten cross-calendar temporal reasoning directions, two reasoning types, and two question formats across six calendars. To enable time-variant and contamination-free evaluation, we propose a template-driven protocol for dynamic instance generation that enables assessment on a user-specified Gregorian date. We conduct extensive experiments on both open- and closed-source state-of-the-art (SOTA) LLMs over a range of dates spanning 100 years from 1960 to 2060. Our evaluations show that these LLMs achieve an average accuracy of only 34.5%, with none exceeding 80%, indicating that this task remains challenging. Through in-depth analysis of reasoning types, question formats, and temporal reasoning directions, we identify two key obstacles for LLMs: Future-Date Degradation and Calendar Asymmetry Bias. To strengthen LLMs' cross-calendar temporal reasoning capability, we further develop an LLM-powered Time Agent that leverages tool-augmented code generation. Empirical results show that Time Agent achieves an average accuracy of 95.31%, outperforming several competitive baselines, highlighting the potential of tool-augmented code generation to advance cross-calendar temporal reasoning. We hope this work will inspire further efforts toward more temporally and culturally adaptive LLMs.

</details>


### [151] [ChEmREF: Evaluating Language Model Readiness for Chemical Emergency Response](https://arxiv.org/abs/2511.10027)
*Risha Surana,Qinyuan Ye,Swabha Swayamdipta*

Main category: cs.AI

TL;DR: 大型语言模型在化学应急响应方面有潜力，但需要人类监督。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在理解化学品信息、识别危险和提供应急响应建议方面的能力，以协助应急响应人员。

Method: 提出化学应急响应评估框架（ChEmREF），该框架包含1035种危险化学品的问题，分为化学表示转换、应急响应生成和领域知识问答三个任务。

Result: 在化学表示转换任务上，最佳模型的精确匹配率为68.0%；在应急响应建议任务上，LLM Judge得分为52.7%；在危险化学品考试任务上，多项选择题准确率为63.9%。

Conclusion: 尽管大型语言模型在协助应急响应方面展现出潜力，但由于其局限性，仍需仔细的人工监督。

Abstract: Emergency responders managing hazardous material HAZMAT incidents face critical, time-sensitive decisions, manually navigating extensive chemical guidelines. We investigate whether today's language models can assist responders by rapidly and reliably understanding critical information, identifying hazards, and providing recommendations.We introduce the Chemical Emergency Response Evaluation Framework (ChEmREF), a new benchmark comprising questions on 1,035 HAZMAT chemicals from the Emergency Response Guidebook and the PubChem Database. ChEmREF is organized into three tasks: (1) translation of chemical representation between structured and unstructured forms (e.g., converting C2H6O to ethanol), (2) emergency response generation (e.g., recommending appropriate evacuation distances) and (3) domain knowledge question answering from chemical safety and certification exams. Our best evaluated models received an exact match of 68.0% on unstructured HAZMAT chemical representation translation, a LLM Judge score of 52.7% on incident response recommendations, and a multiple-choice accuracy of 63.9% on HAMZAT examinations.These findings suggest that while language models show potential to assist emergency responders in various tasks, they require careful human oversight due to their current limitations.

</details>


### [152] [Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM Reasoning](https://arxiv.org/abs/2511.10037)
*Xiaolong Wei,Yuehu Dong,Xingliang Wang,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin*

Main category: cs.AI

TL;DR: 提出一种新的以规划者为中心的“规划-执行”范式，以解决现有工具增强型大语言模型处理复杂查询时遇到的局部优化陷阱问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型大语言模型（LLMs）在处理复杂查询时面临局部优化陷阱的挑战，这是由于它们依赖于增量决策过程。

Method: 提出一种新的以规划者为中心的“规划-执行”范式，引入了一个新的规划者模型，该模型对复杂查询执行全局有向无环图（DAG）规划，并引入了ComplexTool-Plan数据集和一个两阶段训练方法（SFT + GRPO）。

Result: 在StableToolBench基准测试中，该框架在处理复杂用户查询方面实现了最先进的性能，展示了卓越的端到端执行能力和对复杂多工具工作流程的鲁棒处理能力。

Conclusion: 所提出的规划者中心规划-执行范式及其相关组件（规划者模型、ComplexTool-Plan数据集、两阶段训练方法）有效地解决了现有方法的局限性，并在复杂查询处理方面取得了最先进的成果。

Abstract: Existing tool-augmented large language models (LLMs) encounter significant challenges when processing complex queries. Current frameworks such as ReAct are prone to local optimization traps due to their reliance on incremental decision-making processes. To address these limitations, we propose a novel Planner-centric Plan-Execute paradigm that fundamentally resolves local optimization bottlenecks through architectural innovation. Central to our approach is a novel Planner model that performs global Directed Acyclic Graph (DAG) planning for complex queries, enabling optimized execution beyond conventional tool coordination. We also introduce ComplexTool-Plan, a large-scale benchmark dataset featuring complex queries that demand sophisticated multi-tool composition and coordination capabilities. Additionally, we develop a two-stage training methodology that integrates Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), systematically enhancing the Planner's tool selection accuracy and global planning awareness through structured DAG-based planning. When integrated with a capable executor, our framework achieves state-of-the-art performance on the StableToolBench benchmark for complex user queries, demonstrating superior end-to-end execution capabilities and robust handling of intricate multi-tool workflows.

</details>


### [153] [Efficient Thought Space Exploration through Strategic Intervention](https://arxiv.org/abs/2511.10038)
*Ziheng Li,Hengyi Cai,Xiaochi Wei,Yuchen Li,Shuaiqiang Wang,Zhi-Hong Deng,Dawei Yin*

Main category: cs.AI

TL;DR: LLM推理成本高，提出HPR框架，通过'hinter'和'practitioner'协作，利用DIR识别关键决策点，提高推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法计算成本高，通过分析解码轨迹发现关键token的偏差是主要原因。

Method: 提出HPR框架，包含一个提供概率指导的‘hinter’和一个执行推理步骤的‘practitioner’。核心创新是DIR，用于量化‘practitioner’和‘hinter’在概率空间中的差异，动态识别干预点。通过DIR迭代更新，HPR重新加权有希望的推理路径，并降低低概率分支的优先级。

Result: 在算术和常识推理基准测试中，HPR实现了与self-consistency和MCTS基线相当的性能，但仅解码1/5的token。其准确性比现有方法高出5.1%，同时FLOPs相似或更低。

Conclusion: HPR框架在效率和准确性之间取得了最先进的权衡，显著降低了LLM的推理成本。

Abstract: While large language models (LLMs) demonstrate emerging reasoning capabilities, current inference-time expansion methods incur prohibitive computational costs by exhaustive sampling. Through analyzing decoding trajectories, we observe that most next-token predictions align well with the golden output, except for a few critical tokens that lead to deviations. Inspired by this phenomenon, we propose a novel Hint-Practice Reasoning (HPR) framework that operationalizes this insight through two synergistic components: 1) a hinter (powerful LLM) that provides probabilistic guidance at critical decision points, and 2) a practitioner (efficient smaller model) that executes major reasoning steps. The framework's core innovation lies in Distributional Inconsistency Reduction (DIR), a theoretically-grounded metric that dynamically identifies intervention points by quantifying the divergence between practitioner's reasoning trajectory and hinter's expected distribution in a tree-structured probabilistic space. Through iterative tree updates guided by DIR, HPR reweights promising reasoning paths while deprioritizing low-probability branches. Experiments across arithmetic and commonsense reasoning benchmarks demonstrate HPR's state-of-the-art efficiency-accuracy tradeoffs: it achieves comparable performance to self-consistency and MCTS baselines while decoding only 1/5 tokens, and outperforms existing methods by at most 5.1% absolute accuracy while maintaining similar or lower FLOPs.

</details>


### [154] [Radiology Workflow-Guided Hierarchical Reinforcement Fine-Tuning for Medical Report Generation](https://arxiv.org/abs/2511.10065)
*Bodong Du,Honglong Yang,Xiaomeng Li*

Main category: cs.AI

TL;DR: RadFlow是一个受临床报告结构启发的框架，通过分层奖励和关键感知策略优化来改进医学报告生成，确保了诊断一致性和整体报告质量。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的医学报告生成（MRG）系统将报告视为扁平序列，忽略了其固有的层次结构，导致描述性内容和诊断性内容之间存在不一致。本研究旨在使模型行为与真实的报告实践保持一致。

Method: 提出了一种名为RadFlow的框架，该框架采用分层工作流引导的强化优化方法。它引入了一个反映放射学报告组织的临床基础奖励层次结构：全局奖励整合了语言流畅性、医学领域正确性以及影像描述和印象之间的跨sectional一致性；局部奖励侧重于印象质量；此外，还设计了一种关键感知策略优化机制，以适应性地规范高风险或临床敏感病例的学习。

Result: 在胸部X光和颈动脉超声数据集上的实验表明，与最先进的基线相比，RadFlow在诊断一致性和整体报告质量方面取得了持续的改进。

Conclusion: RadFlow将结构化报告范式转化为强化微调过程，能够生成在语言上一致且临床上对齐的报告。

Abstract: Radiologists compose diagnostic reports through a structured workflow: they describe visual findings, summarize them into impressions, and carefully refine statements in clinically critical cases. However, most existing medical report generation (MRG) systems treat reports as flat sequences, overlooking this hierarchical organization and leading to inconsistencies between descriptive and diagnostic content. To align model behavior with real-world reporting practices, we propose RadFlow, a hierarchical workflow-guided reinforcement optimization framework that explicitly models the structured nature of clinical reporting. RadFlow introduces a clinically grounded reward hierarchy that mirrors the organization of radiological reports. At the global level, the reward integrates linguistic fluency, medical-domain correctness, and cross-sectional consistency between Finding and Impression, promoting coherent and clinically faithful narratives. At the local level, a section-specific reward emphasizes Impression quality, reflecting its central role in diagnostic accuracy. Furthermore, a critical-aware policy optimization mechanism adaptively regularizes learning for high-risk or clinically sensitive cases, emulating the cautious refinement behavior of radiologists when documenting critical findings. Together, these components translate the structured reporting paradigm into the reinforcement fine-tuning process, enabling the model to generate reports that are both linguistically consistent and clinically aligned. Experiments on chest X-ray and carotid ultrasound datasets demonstrate that RadFlow consistently improves diagnostic coherence and overall report quality compared with state-of-the-art baselines.

</details>


### [155] [Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning](https://arxiv.org/abs/2511.10067)
*Yuxuan Zhou,Yubin Wang,Bin Wang,Chen Ning,Xien Liu,Ji Wu,Jianye Hao*

Main category: cs.AI

TL;DR: MuSeR通过多方面自我完善，提高LLM在医学领域的语境感知能力，并在HealthBench数据集上取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在医学领域虽然表现出色，但在真实场景中因缺乏语境感知（如用户身份、病史、风险因素等）而表现不足，无法提供安全、有用且贴合语境的回复。

Method: 提出多方面自我完善（MuSeR）方法，通过自我评估和完善来增强LLM在决策、沟通和安全三个关键方面的语境感知能力。具体包括：1.设计属性条件查询生成器，模拟多样化的真实用户语境；2.LLM响应查询，并对决策、沟通、安全三个维度进行自我评估和完善；3.利用查询和完善后的回复进行监督微调。结合知识蒸馏，可使小型LLM超越其教师模型。

Result: 在最新的HealthBench数据集上，MuSeR显著提升了LLM在多方面的表现，尤其在语境感知方面 gains 显著。结合知识蒸馏，小型LLM（Qwen3-32B）的表现超越了其教师模型，在HealthBench及其hard子集上分别取得了63.8%和43.1%的SOTA。

Conclusion: MuSeR是一种有效的数据驱动方法，能够显著提高LLM在医学领域的语境感知能力，并且在较小模型上也能实现性能的突破，达到SOTA水平。

Abstract: Large language models (LLMs) have shown great promise in the medical domain, achieving strong performance on several benchmarks. However, they continue to underperform in real-world medical scenarios, which often demand stronger context-awareness, i.e., the ability to recognize missing or critical details (e.g., user identity, medical history, risk factors) and provide safe, helpful, and contextually appropriate responses. To address this issue, we propose Multifaceted Self-Refinement (MuSeR), a data-driven approach that enhances LLMs' context-awareness along three key facets (decision-making, communication, and safety) through self-evaluation and refinement. Specifically, we first design a attribute-conditioned query generator that simulates diverse real-world user contexts by varying attributes such as role, geographic region, intent, and degree of information ambiguity. An LLM then responds to these queries, self-evaluates its answers along three key facets, and refines its responses to better align with the requirements of each facet. Finally, the queries and refined responses are used for supervised fine-tuning to reinforce the model's context-awareness ability. Evaluation results on the latest HealthBench dataset demonstrate that our method significantly improves LLM performance across multiple aspects, with particularly notable gains in the context-awareness axis. Furthermore, by incorporating knowledge distillation with the proposed method, the performance of a smaller backbone LLM (e.g., Qwen3-32B) surpasses its teacher model, achieving a new SOTA across all open-source LLMs on HealthBench (63.8%) and its hard subset (43.1%). Code and dataset will be released at https://muser-llm.github.io.

</details>


### [156] [Balancing Centralized Learning and Distributed Self-Organization: A Hybrid Model for Embodied Morphogenesis](https://arxiv.org/abs/2511.10101)
*Takehiro Ishikawa*

Main category: cs.AI

TL;DR: 通过将类似大脑的可学习控制器与类似细胞的Gray-Scott基板耦合，以最小的代价来引导模式形成。


<details>
  <summary>Details</summary>
Motivation: 研究如何将类似大脑的可学习控制器与类似细胞的Gray-Scott基板耦合，以最小的代价来引导模式形成。

Method: 将紧凑的卷积策略嵌入可微分的PyTorch反应-扩散模拟器中，在温保持衰减增益调度下，对进给和杀死参数（ΔF，ΔK）进行空间平滑、有界的调制。训练通过惩罚控制代价（l1/l2）和不稳定性来优化图灵带谱目标（基于FFT）。

Result: 混合耦合方案实现了可靠、快速的目标纹理形成（100%严格收敛，约165步），匹配了纯细胞的光谱选择性（0.436 vs. 0.434），同时比仅神经网络控制的l1代价小约15倍，l2功耗大200倍以上。幅度扫描揭示了一个非单调的“适中区”（A≈0.03-0.045），在该区域可以100%拟收敛（94-96步）形成目标纹理，而较弱或较强的增益则无法收敛或降低选择性。

Conclusion: 这些结果量化了形态计算：控制器先播种然后放弃，提供简短、稀疏的引导，将系统置于正确的吸引子盆地中，然后由局域物理维持模式。该研究为构建可引导、鲁棒且节能的具身系统提供了一个实用的方案，该系统利用了集中式学习和分布式自组织之间的最佳分工。

Abstract: We investigate how to couple a learnable brain-like'' controller to a cell-like'' Gray--Scott substrate to steer pattern formation with minimal effort. A compact convolutional policy is embedded in a differentiable PyTorch reaction--diffusion simulator, producing spatially smooth, bounded modulations of the feed and kill parameters ($ΔF$, $ΔK$) under a warm--hold--decay gain schedule. Training optimizes Turing-band spectral targets (FFT-based) while penalizing control effort ($\ell_1/\ell_2$) and instability. We compare three regimes: pure reaction--diffusion, NN-dominant, and a hybrid coupling. The hybrid achieves reliable, fast formation of target textures: 100% strict convergence in $\sim 165$ steps, matching cell-only spectral selectivity (0.436 vs.\ 0.434) while using $\sim 15\times$ less $\ell_1$ effort and $>200\times$ less $\ell_2$ power than NN-dominant control. An amplitude sweep reveals a non-monotonic Goldilocks'' zone ($A \approx 0.03$--$0.045$) that yields 100\% quasi convergence in 94--96 steps, whereas weaker or stronger gains fail to converge or degrade selectivity. These results quantify morphological computation: the controller seeds then cedes,'' providing brief, sparse nudges that place the system in the correct basin of attraction, after which local physics maintains the pattern. The study offers a practical recipe for building steerable, robust, and energy-efficient embodied systems that exploit an optimal division of labor between centralized learning and distributed self-organization.

</details>


### [157] [Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence](https://arxiv.org/abs/2511.10119)
*Borui Cai,Yao Zhao*

Main category: cs.AI

TL;DR: 我们提出了一种名为智能基础模型（IFM）的新方法来构建通用人工智能（AGI）。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型（FM）专注于特定领域（如语言、视觉）的模式学习，而IFM旨在通过学习多样化的智能行为来掌握智能的底层机制，以实现AGI。

Method: IFM包含两个核心组件：1. 状态神经网络（state neural network）：模拟神经元动态过程。2. 神经元输出预测（neuron output prediction）：预测神经元输出。

Result: IFM通过模拟生物神经系统动力学，能够跨领域实现泛化、推理和自适应学习。

Conclusion: IFM提供了一个生物学依据且可扩展的计算基础，是迈向AGI的重要一步。

Abstract: We propose a new perspective for approaching artificial general intelligence (AGI) through an intelligence foundation model (IFM). Unlike existing foundation models (FMs), which specialize in pattern learning within specific domains such as language, vision, or time series, IFM aims to acquire the underlying mechanisms of intelligence by learning directly from diverse intelligent behaviors. Vision, language, and other cognitive abilities are manifestations of intelligent behavior; learning from this broad range of behaviors enables the system to internalize the general principles of intelligence. Based on the fact that intelligent behaviors emerge from the collective dynamics of biological neural systems, IFM consists of two core components: a novel network architecture, termed the state neural network, which captures neuron-like dynamic processes, and a new learning objective, neuron output prediction, which trains the system to predict neuronal outputs from collective dynamics. The state neural network emulates the temporal dynamics of biological neurons, allowing the system to store, integrate, and process information over time, while the neuron output prediction objective provides a unified computational principle for learning these structural dynamics from intelligent behaviors. Together, these innovations establish a biologically grounded and computationally scalable foundation for building systems capable of generalization, reasoning, and adaptive learning across domains, representing a step toward truly AGI.

</details>


### [158] [RAGFort: Dual-Path Defense Against Proprietary Knowledge Base Extraction in Retrieval-Augmented Generation](https://arxiv.org/abs/2511.10128)
*Qinfeng Li,Miao Pan,Ke Xiong,Ge Su,Zhiqiang Shen,Yan Liu,Bing Sun,Hao Peng,Xuhong Zhang*

Main category: cs.AI

TL;DR: RAG系统面临来自重建攻击的威胁，这些攻击可以复制知识库。现有防御措施只保护攻击路径的一条，而RAGFort通过结合对比重索引和约束级联生成来同时保护两条路径，从而提供全面的防御。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统部署在专有知识库之上，面临着日益增长的来自重建攻击的威胁，这些攻击通过聚合模型响应来复制知识库。

Method: 提出了一种名为RAGFort的结构感知双模块防御，它结合了“对比重索引”用于类间隔离和“约束级联生成”用于类内保护。

Result: 实验证明，RAGFort显著降低了重建的成功率，同时保持了答案的质量，为防御知识库提取攻击提供了全面的保护。

Conclusion:  joint protection is essential for effective defense against reconstruction attacks on RAG systems.

Abstract: Retrieval-Augmented Generation (RAG) systems deployed over proprietary knowledge bases face growing threats from reconstruction attacks that aggregate model responses to replicate knowledge bases. Such attacks exploit both intra-class and inter-class paths, progressively extracting fine-grained knowledge within topics and diffusing it across semantically related ones, thereby enabling comprehensive extraction of the original knowledge base. However, existing defenses target only one path, leaving the other unprotected. We conduct a systematic exploration to assess the impact of protecting each path independently and find that joint protection is essential for effective defense. Based on this, we propose RAGFort, a structure-aware dual-module defense combining "contrastive reindexing" for inter-class isolation and "constrained cascade generation" for intra-class protection. Experiments across security, performance, and robustness confirm that RAGFort significantly reduces reconstruction success while preserving answer quality, offering comprehensive defense against knowledge base extraction attacks.

</details>


### [159] [DenoGrad: Deep Gradient Denoising Framework for Enhancing the Performance of Interpretable AI Models](https://arxiv.org/abs/2511.10161)
*J. Javier Alonso-Ramos,Ignacio Aguilera-Martos,Andrés Herrera-Poyatos,Francisco Herrera*

Main category: cs.AI

TL;DR: DenoGrad是一个新的梯度下降去噪框架，它利用深度学习模型来调整数据中的噪声，从而提高AI模型的鲁棒性，并且能够保持原始数据分布。


<details>
  <summary>Details</summary>
Motivation: 现有的数据去噪方法要么损害模型性能，要么过度简化问题，从而改变原始数据分布，导致模型产生偏差，特别是在可解释AI模型中，数据的保真度对可解释性至关重要。因此，需要一种能够动态调整噪声实例并保持数据分布的去噪方法。

Method: 提出了一种名为DenoGrad的新型梯度下降去噪框架。该框架利用在目标数据上训练的准确的深度学习模型所产生的梯度来检测和调整噪声样本。DenoGrad能够动态地纠正噪声实例，从而保持问题的原始数据分布。

Result: DenoGrad在表格和时间序列数据集上进行了验证，并在各种噪声设置下与现有技术进行了比较。实验结果表明，DenoGrad优于现有的去噪策略，能够提高可解释AI模型的性能，并且是唯一能够保持原始数据分布的高质量方法。

Conclusion: DenoGrad通过利用梯度信息动态调整噪声实例，克服了传统去噪方法的局限性。该方法能够有效提高AI模型的鲁棒性，保持数据分布的完整性，并在各种数据集和噪声条件下都表现出色。

Abstract: The performance of Machine Learning (ML) models, particularly those operating within the Interpretable Artificial Intelligence (Interpretable AI) framework, is significantly affected by the presence of noise in both training and production data. Denoising has therefore become a critical preprocessing step, typically categorized into instance removal and instance correction techniques. However, existing correction approaches often degrade performance or oversimplify the problem by altering the original data distribution. This leads to unrealistic scenarios and biased models, which is particularly problematic in contexts where interpretable AI models are employed, as their interpretability depends on the fidelity of the underlying data patterns. In this paper, we argue that defining noise independently of the solution may be ineffective, as its nature can vary significantly across tasks and datasets. Using a task-specific high quality solution as a reference can provide a more precise and adaptable noise definition. To this end, we propose DenoGrad, a novel Gradient-based instance Denoiser framework that leverages gradients from an accurate Deep Learning (DL) model trained on the target data -- regardless of the specific task -- to detect and adjust noisy samples. Unlike conventional approaches, DenoGrad dynamically corrects noisy instances, preserving problem's data distribution, and improving AI models robustness. DenoGrad is validated on both tabular and time series datasets under various noise settings against the state-of-the-art. DenoGrad outperforms existing denoising strategies, enhancing the performance of interpretable IA models while standing out as the only high quality approach that preserves the original data distribution.

</details>


### [160] [Two Constraint Compilation Methods for Lifted Planning](https://arxiv.org/abs/2511.10164)
*Periklis Mantenoglou,Luigi Bonassi,Enrico Scala,Pedro Zuidberg Dos Martires*

Main category: cs.AI

TL;DR: 现有的规划编译器难以处理具有大量对象和高阶操作符的问题，因为它们需要先进行问题接地（grounding）。本文提出了两种无需接地即可消除约束的编译方法，以解决大规模规划问题。


<details>
  <summary>Details</summary>
Motivation: 现有规划编译器在处理具有大量对象和高阶操作符的规划问题时，由于需要先进行接地，因此扩展性较差。本文旨在解决这一问题。

Method: 提出两种无需接地即可消除约束的编译方法，并证明了其正确性，同时分析了最坏情况下的时间复杂度。

Result: 提出的方法在国际规划竞赛的基准测试中，能够生成比现有接地编译方法小几个数量级的规划规范，并且在与最先进的规划器结合使用时，效率具有竞争力。

Conclusion: 提出的无需接地的编译方法能够有效处理大规模规划问题，生成更简洁的规划规范，并且在规划效率上具有竞争力。

Abstract: We study planning in a fragment of PDDL with qualitative state-trajectory constraints, capturing safety requirements, task ordering conditions, and intermediate sub-goals commonly found in real-world problems. A prominent approach to tackle such problems is to compile their constraints away, leading to a problem that is supported by state-of-the-art planners. Unfortunately, existing compilers do not scale on problems with a large number of objects and high-arity actions, as they necessitate grounding the problem before compilation. To address this issue, we propose two methods for compiling away constraints without grounding, making them suitable for large-scale planning problems. We prove the correctness of our compilers and outline their worst-case time complexity. Moreover, we present a reproducible empirical evaluation on the domains used in the latest International Planning Competition. Our results demonstrate that our methods are efficient and produce planning specifications that are orders of magnitude more succinct than the ones produced by compilers that ground the domain, while remaining competitive when used for planning with a state-of-the-art planner.

</details>


### [161] [Advanced Black-Box Tuning of Large Language Models with Limited API Calls](https://arxiv.org/abs/2511.10210)
*Zhikang Xie,Weilin Wan,Peizhu Gong,Weizhong Zhang,Cheng Jin*

Main category: cs.AI

TL;DR: LLM黑盒微调新方法，用高斯过程代理模型减少API调用次数，提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM黑盒微调方法在效率和效果之间存在两难：单独训练代理模型效率高但效果有限；直接调用LLM API成本高昂。

Method: 提出一种新的黑盒微调方法，利用“LogitMap Pairs”训练高斯过程（GP）代理模型，以近似LLM的输出，从而指导代理模型的训练，有效减少对LLM API的直接调用。

Result: 实验表明，该方法将LLM的准确率从55.92%提升至86.85%，API调用次数减少至1.38%，显著优于无API调用的离线方法，并达到或超过了调用密集型方法的准确率。

Conclusion: 提出了一种高效且鲁棒的LLM黑盒微调新范式，能够以更低的API调用成本实现高精度的模型适应。

Abstract: Black-box tuning is an emerging paradigm for adapting large language models (LLMs) to better achieve desired behaviors, particularly when direct access to model parameters is unavailable. Current strategies, however, often present a dilemma of suboptimal extremes: either separately train a small proxy model and then use it to shift the predictions of the foundation model, offering notable efficiency but often yielding limited improvement; or making API calls in each tuning iteration to the foundation model, which entails prohibitive computational costs. Therefore, we propose a novel advanced black-box tuning method for LLMs with limited API calls. Our core strategy involves training a Gaussian Process (GP) surrogate model with "LogitMap Pairs" derived from querying the foundation model on a minimal but highly informative training subset. This surrogate can approximate the outputs of the foundation model to guide the training of the proxy model, thereby effectively reducing the need for direct queries to the foundation model. Extensive experiments verify that our approach elevates pre-trained language model accuracy from 55.92% to 86.85%, reducing the frequency of API queries to merely 1.38%. This significantly outperforms offline approaches that operate entirely without API access. Notably, our method also achieves comparable or superior accuracy to query-intensive approaches, while significantly reducing API costs. This offers a robust and high-efficiency paradigm for language model adaptation.

</details>


### [162] [MTP: Exploring Multimodal Urban Traffic Profiling with Modality Augmentation and Spectrum Fusion](https://arxiv.org/abs/2511.10218)
*Haolong Xiang,Peisi Wang,Xiaolong Xu,Kun Yi,Xuyun Zhang,Quanzheng Sheng,Amin Beheshti,Wei Fan*

Main category: cs.AI

TL;DR: 该研究提出了一种名为MTP的多模态交通画像框架，通过融合数值、视觉和文本信息，并利用频率域学习和对比学习来提高交通信号建模和预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有交通信号建模方法多依赖单一数据模态（如传感器数值），忽略了多模态异构城市数据的语义信息，限制了对复杂交通动态的全面理解和精准预测。

Method: MTP框架包含三个分支：1. 视觉分支：对交通信号进行视觉增强，生成频率图像和周期性图像。2. 文本分支：为交通信号生成基于主题、背景和描述的文本描述。3. 数值分支：利用频率多层感知机处理原始数值数据。该框架在频率域进行学习，并通过层级对比学习融合三个分支的模态信息。

Result: 在六个真实世界数据集上的广泛实验表明，MTP框架的性能优于现有最先进的方法。

Conclusion: MTP框架通过融合多模态数据（数值、视觉、文本）和利用频率域学习策略，能够更全面地理解城市交通信号，并实现更精准的交通动态预测。

Abstract: With rapid urbanization in the modern era, traffic signals from various sensors have been playing a significant role in monitoring the states of cities, which provides a strong foundation in ensuring safe travel, reducing traffic congestion and optimizing urban mobility. Most existing methods for traffic signal modeling often rely on the original data modality, i.e., numerical direct readings from the sensors in cities. However, this unimodal approach overlooks the semantic information existing in multimodal heterogeneous urban data in different perspectives, which hinders a comprehensive understanding of traffic signals and limits the accurate prediction of complex traffic dynamics. To address this problem, we propose a novel \textit{M}ultimodal framework, \textit{MTP}, for urban \textit{T}raffic \textit{P}rofiling, which learns multimodal features through numeric, visual, and textual perspectives. The three branches drive for a multimodal perspective of urban traffic signal learning in the frequency domain, while the frequency learning strategies delicately refine the information for extraction. Specifically, we first conduct the visual augmentation for the traffic signals, which transforms the original modality into frequency images and periodicity images for visual learning. Also, we augment descriptive texts for the traffic signals based on the specific topic, background information and item description for textual learning. To complement the numeric information, we utilize frequency multilayer perceptrons for learning on the original modality. We design a hierarchical contrastive learning on the three branches to fuse the spectrum of three modalities. Finally, extensive experiments on six real-world datasets demonstrate superior performance compared with the state-of-the-art approaches.

</details>


### [163] [ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs](https://arxiv.org/abs/2511.10240)
*Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在推理方面表现出色，但在幻觉和透明度方面存在不足。为了解决这些问题，我们提出了ProgRAG，一个多跳知识图谱问题回答（KGQA）框架，它将复杂问题分解为子问题，并通过回答每个子问题来逐步扩展部分推理路径。ProgRAG通过不确定性感知剪枝来优化LLM推理的上下文，并在三个著名的数据集上进行了实验，结果表明ProgRAG在多跳KGQA方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在推理方面表现出色，但在幻觉和透明度方面存在不足。现有知识图谱（KG）增强的LLM虽然提高了推理性能，但仍面临检索不准确和推理失败的挑战，尤其是在处理长输入上下文和需要复杂逻辑方向的问题时。此外，许多方法依赖LLM直接从KG检索证据并自我评估证据的充分性，这常常导致过早或不正确的推理。

Method: ProgRAG是一个多跳知识图谱问题回答（KGQA）框架，它将复杂问题分解为子问题，并通过回答每个子问题来逐步扩展部分推理路径。在每个步骤中，外部检索器收集候选证据，然后由LLM通过不确定性感知剪枝进行优化。最后，通过组织和重新排列从子问题答案中获得的推理路径来优化LLM推理的上下文。

Result: 在三个著名的数据集上的实验表明，ProgRAG在多跳KGQA方面优于现有基线，提供了更高的可靠性和推理质量。

Conclusion: ProgRAG框架通过将复杂问题分解为子问题并逐步扩展推理路径，有效地解决了现有KG增强LLM在检索和推理方面存在的挑战，提高了多跳KGQA的性能和可靠性。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities but struggle with hallucinations and limited transparency. Recently, KG-enhanced LLMs that integrate knowledge graphs (KGs) have been shown to improve reasoning performance, particularly for complex, knowledge-intensive tasks. However, these methods still face significant challenges, including inaccurate retrieval and reasoning failures, often exacerbated by long input contexts that obscure relevant information or by context constructions that struggle to capture the richer logical directions required by different question types. Furthermore, many of these approaches rely on LLMs to directly retrieve evidence from KGs, and to self-assess the sufficiency of this evidence, which often results in premature or incorrect reasoning. To address the retrieval and reasoning failures, we propose ProgRAG, a multi-hop knowledge graph question answering (KGQA) framework that decomposes complex questions into sub-questions, and progressively extends partial reasoning paths by answering each sub-question. At each step, external retrievers gather candidate evidence, which is then refined through uncertainty-aware pruning by the LLM. Finally, the context for LLM reasoning is optimized by organizing and rearranging the partial reasoning paths obtained from the sub-question answers. Experiments on three well-known datasets demonstrate that ProgRAG outperforms existing baselines in multi-hop KGQA, offering improved reliability and reasoning quality.

</details>


### [164] [PepTriX: A Framework for Explainable Peptide Analysis through Protein Language Models](https://arxiv.org/abs/2511.10244)
*Vincent Schilling,Akshat Dubey,Georges Hattab*

Main category: cs.AI

TL;DR: PepTriX是一个整合了一维序列和三维结构特征的图注意力网络框架，用于肽分类任务，能够提高预测性能并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统肽分类方法依赖手工编码，泛化能力有限，且蛋白质语言模型（PLM）微调成本高、可解释性差。现有框架针对性强，缺乏通用性，难以将模型预测与生物学特征联系起来。

Method: PepTriX整合了一维序列嵌入和三维结构特征，利用图注意力网络，并结合对比学习和跨模态共注意力机制，以生成任务特定的肽向量。

Result: PepTriX在多项肽分类任务中表现出色，超越了传统方法和现有框架，并能提供可解释的见解，揭示驱动预测的结构和生物物理特征。

Conclusion: PepTriX提供了一种既有预测鲁棒性又具可解释性的新方法，弥合了性能驱动的模型与领域理解之间的差距，适用于多样的肽分类任务。

Abstract: Peptide classification tasks, such as predicting toxicity and HIV inhibition, are fundamental to bioinformatics and drug discovery. Traditional approaches rely heavily on handcrafted encodings of one-dimensional (1D) peptide sequences, which can limit generalizability across tasks and datasets. Recently, protein language models (PLMs), such as ESM-2 and ESMFold, have demonstrated strong predictive performance. However, they face two critical challenges. First, fine-tuning is computationally costly. Second, their complex latent representations hinder interpretability for domain experts. Additionally, many frameworks have been developed for specific types of peptide classification, lacking generalization. These limitations restrict the ability to connect model predictions to biologically relevant motifs and structural properties. To address these limitations, we present PepTriX, a novel framework that integrates one dimensional (1D) sequence embeddings and three-dimensional (3D) structural features via a graph attention network enhanced with contrastive training and cross-modal co-attention. PepTriX automatically adapts to diverse datasets, producing task-specific peptide vectors while retaining biological plausibility. After evaluation by domain experts, we found that PepTriX performs remarkably well across multiple peptide classification tasks and provides interpretable insights into the structural and biophysical motifs that drive predictions. Thus, PepTriX offers both predictive robustness and interpretable validation, bridging the gap between performance-driven peptide-level models (PLMs) and domain-level understanding in peptide research.

</details>


### [165] [Beyond Single-Step Updates: Reinforcement Learning of Heuristics with Limited-Horizon Search](https://arxiv.org/abs/2511.10264)
*Gal Hadar,Forest Agostinelli,Shahaf S. Shperberg*

Main category: cs.AI

TL;DR: 通过引入有限步数搜索和基于搜索边界的启发式更新，提出了一种改进的基于深度强化学习的启发式学习方法。


<details>
  <summary>Details</summary>
Motivation: 将顺序决策问题建模为最短路径问题，并利用基于深度强化学习的启发式学习方法来解决这些问题，但现有的方法仅依赖单步贝尔曼更新。

Method: 提出一种广义方法，通过执行有限步数搜索，并根据到搜索边界的最短路径（结合边成本和边界状态的启发式值）来更新每个状态的启发式值，从而改进状态采样和启发式更新。

Result: 通过有限步数搜索和基于搜索边界的启发式更新，可以改进启发式函数的学习。

Conclusion: 所提出的方法通过利用更丰富的信息（来自有限步数搜索的路径和边界启发式值）来改进启发式学习，可能比仅使用单步更新的方法更有效。

Abstract: Many sequential decision-making problems can be formulated as shortest-path problems, where the objective is to reach a goal state from a given starting state. Heuristic search is a standard approach for solving such problems, relying on a heuristic function to estimate the cost to the goal from any given state. Recent approaches leverage reinforcement learning to learn heuristics by applying deep approximate value iteration. These methods typically rely on single-step Bellman updates, where the heuristic of a state is updated based on its best neighbor and the corresponding edge cost. This work proposes a generalized approach that enhances both state sampling and heuristic updates by performing limited-horizon searches and updating each state's heuristic based on the shortest path to the search frontier, incorporating both edge costs and the heuristic values of frontier states.

</details>


### [166] [Temporal Properties of Conditional Independence in Dynamic Bayesian Networks](https://arxiv.org/abs/2511.10266)
*Rajab Aghamov,Christel Baier,Joel Ouaknine,Jakob Piribauer,Mihir Vahanwala,Isa Vialard*

Main category: cs.AI

TL;DR: 本篇论文研究了动态贝叶斯网络（DBNs）中条件独立（CI）命题演化与时序逻辑规约的验证问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何在动态贝叶斯网络（DBNs）中验证条件独立（CI）命题的演化是否满足时序逻辑规约。

Method: 考虑了两种规约形式：线性时序逻辑（LTL）和非确定性Büchi自动机（NBAs）。区分了随机CI属性（考虑概率分布）和结构CI属性（仅考虑图结构）。。

Result: 对于随机CI属性，证明了其验证问题的难度至少与线性递推序列的Skolem问题相当（一个数论中的长期未解决难题）。对于结构CI属性，证明了其在LTL和NBA规约下的验证问题属于PSPACE，且具有NP-和coNP-hard性质。此外，还找到了能使结构CI属性验证更易处理的DBN图结构限制。

Conclusion: 验证DBNs中CI命题的演化是一个具有挑战性的问题，其计算复杂度与所考虑的属性类型（随机或结构）以及规约形式有关。部分情况下，该问题与数论中的难题相关，而结构CI属性的验证则在PSPACE内，但存在NP-和coNP-hard性。通过限制DBN的图结构可以简化验证过程。

Abstract: Dynamic Bayesian networks (DBNs) are compact graphical representations used to model probabilistic systems where interdependent random variables and their distributions evolve over time. In this paper, we study the verification of the evolution of conditional-independence (CI) propositions against temporal logic specifications. To this end, we consider two specification formalisms over CI propositions: linear temporal logic (LTL), and non-deterministic Büchi automata (NBAs). This problem has two variants. Stochastic CI properties take the given concrete probability distributions into account, while structural CI properties are viewed purely in terms of the graphical structure of the DBN. We show that deciding if a stochastic CI proposition eventually holds is at least as hard as the Skolem problem for linear recurrence sequences, a long-standing open problem in number theory. On the other hand, we show that verifying the evolution of structural CI propositions against LTL and NBA specifications is in PSPACE, and is NP- and coNP-hard. We also identify natural restrictions on the graphical structure of DBNs that make the verification of structural CI properties tractable.

</details>


### [167] [Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention](https://arxiv.org/abs/2511.10268)
*Zhe Xu,Zhicai Wang,Junkang Wu,Jinda Lu,Xiang Wang*

Main category: cs.AI

TL;DR: 大型视觉语言模型（LVLM）因物体幻觉问题而出现错误判断，这主要是由训练过程中物体间的高度共现引起的虚假关联造成的。现有基准测试主要关注幻觉检测，缺乏对LVLM中虚假关联的正式表征和量化评估。为解决此问题，本文将因果分析引入LVLM的目标识别场景，构建了结构因果模型（SCM），并用因果语言正式定义了由共现偏差引起的虚假关联。为量化虚假关联的影响，本文开发了Causal-HalBench基准测试，其中包含反事实样本，并集成了全面的因果指标来评估模型对虚假关联的鲁棒性。此外，本文还提出了一个可扩展的流程，利用专有LVLM和文本到图像（T2I）模型来生成反事实样本。在主流LVLM上的评估表明，这些模型在不同程度上都容易受到虚假关联的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLM）在处理物体识别时存在一个主要问题，即“物体幻觉”，即模型会错误地判断图像中是否存在某些物体。研究者认为，这种现象主要源于模型在训练过程中学习到的物体间的“虚假关联”，即模型将经常一起出现的物体错误地联系起来，导致模型在看到某个视觉线索时产生不存在的物体的幻觉。然而，目前现有的基准测试主要集中于检测幻觉，而没有对LVLM中这种由共现偏差引起的虚假关联进行形式化的定义和量化评估。

Method: 本文提出将因果分析的方法应用于LVLM的目标识别问题，并构建了一个结构因果模型（SCM）。基于因果关系的理论，研究者形式化地定义了由共现偏差所产生的虚假关联。为了量化这些虚假关联带来的影响，研究者开发了一个名为Causal-HalBench的新基准测试。该基准测试包含精心设计的反事实样本（即改变了部分物体共现关系但保持其他因素不变的样本），并集成了多种因果度量指标，用于评估模型在面对这些虚假关联时的鲁棒性。此外，研究者还提出了一套可扩展的流程，利用现有的LVLM和文本到图像（T2I）模型来自动生成这些反事实样本。

Result: 通过在Causal-HalBench基准测试上评估多个主流的大型视觉语言模型，研究结果显示，这些模型在不同程度上都表现出对虚假关联的敏感性。这意味着，尽管模型在一般物体识别任务上表现良好，但在存在虚假关联的情况下，它们仍然会产生幻觉。

Conclusion: 本文成功地将因果分析引入了LVLM的物体幻觉问题研究，并通过构建SCM和Causal-HalBench基准测试，为量化和评估模型对虚假关联的鲁棒性提供了新的方法。研究结果表明，当前的LVLM普遍存在对虚假关联的敏感性，这揭示了模型在理解物体间真实因果关系方面仍有提升空间。此外，研究提出的样本生成流程也为未来的相关研究提供了便利。

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, making erroneous judgments about the presence of objects in images. We propose this primar- ily stems from spurious correlations arising when models strongly associate highly co-occurring objects during train- ing, leading to hallucinated objects influenced by visual con- text. Current benchmarks mainly focus on hallucination de- tection but lack a formal characterization and quantitative evaluation of spurious correlations in LVLMs. To address this, we introduce causal analysis into the object recognition scenario of LVLMs, establishing a Structural Causal Model (SCM). Utilizing the language of causality, we formally de- fine spurious correlations arising from co-occurrence bias. To quantify the influence induced by these spurious correla- tions, we develop Causal-HalBench, a benchmark specifically constructed with counterfactual samples and integrated with comprehensive causal metrics designed to assess model ro- bustness against spurious correlations. Concurrently, we pro- pose an extensible pipeline for the construction of these coun- terfactual samples, leveraging the capabilities of proprietary LVLMs and Text-to-Image (T2I) models for their genera- tion. Our evaluations on mainstream LVLMs using Causal- HalBench demonstrate these models exhibit susceptibility to spurious correlations, albeit to varying extents.

</details>


### [168] [Bidirectional Bounded-Suboptimal Heuristic Search with Consistent Heuristics](https://arxiv.org/abs/2511.10272)
*Shahaf S. Shperberg,Natalie Morad,Lior Siag,Ariel Felner,Dor Atzmon*

Main category: cs.AI

TL;DR: 本文研究有界次优双向搜索算法，并提出BAE*的变种。实验表明，不同算法在不同条件下表现各异。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究有界次优双向搜索，并针对一致性启发式搜索提出新的算法变种。

Method: 在最优双向搜索算法BAE*的基础上，提出并实现几种用于有界次优搜索的BAE*变种，并通过实验与现有的有界次优双向算法以及加权A*算法进行性能比较。

Result: 实验结果表明，本文提出的BAE*变种在特定条件下表现优于其他算法，同时也揭示了各种算法的优缺点。

Conclusion: 不同的有界次优双向搜索算法在不同条件下各有优劣，没有一种算法能在所有情况下都表现最佳。

Abstract: Recent advancements in bidirectional heuristic search have yielded significant theoretical insights and novel algorithms. While most previous work has concentrated on optimal search methods, this paper focuses on bounded-suboptimal bidirectional search, where a bound on the suboptimality of the solution cost is specified. We build upon the state-of-the-art optimal bidirectional search algorithm, BAE*, designed for consistent heuristics, and introduce several variants of BAE* specifically tailored for the bounded-suboptimal context. Through experimental evaluation, we compare the performance of these new variants against other bounded-suboptimal bidirectional algorithms as well as the standard weighted A* algorithm. Our results demonstrate that each algorithm excels under distinct conditions, highlighting the strengths and weaknesses of each approach.

</details>


### [169] [Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware](https://arxiv.org/abs/2511.10277)
*Martin Braas,Lukas Esterle*

Main category: cs.AI

TL;DR: LLMs在游戏NPC对话中存在硬件需求高、延迟大、知识边界不清晰等问题。本文提出了一种基于小型语言模型（SLM）的模块化NPC对话系统，该系统结合了可运行时替换的记忆模块，用于保持角色特定对话上下文和世界知识，从而在不进行重新训练或模型重载的情况下实现丰富的交互和长期记忆。该系统在消费级硬件上使用三种开源SLM进行了评估，并具有广泛的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）在硬件需求、延迟和游戏知识边界方面存在限制，因此在游戏NPC对话系统的应用中受到限制。

Method: 提出了一种模块化NPC对话系统，利用了小型语言模型（SLM），并对其进行了微调，以编码特定的NPC角色，并集成了运行时可交换的记忆模块，以保持角色特定的对话上下文和世界知识。

Result: 使用三种开源SLM（DistilGPT-2，TinyLlama-1.1B-Chat和Mistral-7B-Instruct）在消费级硬件上对该系统进行了全面评估。

Conclusion: 该系统的模块化设计和面向角色的记忆架构在需要表达、可扩展和内存丰富的对话代理的领域具有广泛的应用潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, yet their applicability to dialogue systems in computer games remains limited. This limitation arises from their substantial hardware requirements, latency constraints, and the necessity to maintain clearly defined knowledge boundaries within a game setting. In this paper, we propose a modular NPC dialogue system that leverages Small Language Models (SLMs), fine-tuned to encode specific NPC personas and integrated with runtime-swappable memory modules. These memory modules preserve character-specific conversational context and world knowledge, enabling expressive interactions and long-term memory without retraining or model reloading during gameplay. We comprehensively evaluate our system using three open-source SLMs: DistilGPT-2, TinyLlama-1.1B-Chat, and Mistral-7B-Instruct, trained on synthetic persona-aligned data and benchmarked on consumer-grade hardware. While our approach is motivated by applications in gaming, its modular design and persona-driven memory architecture hold significant potential for broader adoption in domains requiring expressive, scalable, and memory-rich conversational agents, such as virtual assistants, customer support bots, or interactive educational systems.

</details>


### [170] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: FactGuard框架利用大语言模型提取事件中心内容，并引入动态可用性机制识别矛盾和模糊事实，通过知识蒸馏实现高效部署，在真实新闻检测任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于写作风格的假新闻检测方法因对手模仿真实新闻风格而效果减弱；大语言模型在假新闻检测中的应用潜力巨大但受限于功能探索不足、可用性模糊及高昂的推理成本。

Method: 提出FactGuard框架，利用大语言模型提取事件中心内容以降低写作风格的影响；引入动态可用性机制识别事实推理中的矛盾和模糊情况，并自适应地整合大语言模型建议以提高决策可靠性；通过知识蒸馏得到FactGuard-D，以应对冷启动和资源受限场景。

Result: 在两个基准数据集上的综合实验表明，FactGuard框架在鲁棒性和准确性方面持续优于现有方法，有效解决了假新闻检测中的风格敏感性和大语言模型可用性挑战。

Conclusion: FactGuard框架通过利用大语言模型提取事件中心内容和动态可用性机制，能够有效克服现有假新闻检测方法的局限性，并在各种场景下实现高效且准确的检测。

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


### [171] [Beyond Verification: Abductive Explanations for Post-AI Assessment of Privacy Leakage](https://arxiv.org/abs/2511.10284)
*Belona Sonna,Alban Grastien,Claire Benn*

Main category: cs.AI

TL;DR: 本研究提出一种基于溯因解释的隐私泄露审计框架，用于识别模型决策中的最小充分证据，从而判断是否泄露敏感信息，并提供了个人和系统层面的隐私保证，以及可解释的隐私审计方法。


<details>
  <summary>Details</summary>
Motivation: AI决策过程中隐私泄露的风险，特别是敏感信息被推断的风险。

Method: 提出一个正式的框架，利用溯因解释来审计隐私泄露。该框架识别支持模型决策的最小充分证据，并确定是否泄露了敏感信息。它对个人和系统层面的泄露进行了形式化，并引入了潜在适用解释（PAE）的概念。

Result: 在德国信贷数据集上的实验评估表明，敏感属性在线索在模型决策过程中的重要性会影响隐私泄露。

Conclusion: 尽管存在计算挑战和简化假设，但溯因推理能够实现可解释的隐私审计，为在AI决策中统一透明度、模型可解释性和隐私保护提供了一条实用的途径。

Abstract: Privacy leakage in AI-based decision processes poses significant risks, particularly when sensitive information can be inferred. We propose a formal framework to audit privacy leakage using abductive explanations, which identifies minimal sufficient evidence justifying model decisions and determines whether sensitive information disclosed. Our framework formalizes both individual and system-level leakage, introducing the notion of Potentially Applicable Explanations (PAE) to identify individuals whose outcomes can shield those with sensitive features. This approach provides rigorous privacy guarantees while producing human understandable explanations, a key requirement for auditing tools. Experimental evaluation on the German Credit Dataset illustrates how the importance of sensitive literal in the model decision process affects privacy leakage. Despite computational challenges and simplifying assumptions, our results demonstrate that abductive reasoning enables interpretable privacy auditing, offering a practical pathway to reconcile transparency, model interpretability, and privacy preserving in AI decision-making.

</details>


### [172] [SITA: A Framework for Structure-to-Instance Theorem Autoformalization](https://arxiv.org/abs/2511.10356)
*Chenyi Li,Wanli Ma,Zichen Wang,Zaiwen Wen*

Main category: cs.AI

TL;DR: 本研究提出SITA框架，利用LLM和Lean证明助手，将抽象数学结构自动形式化为具体的定理实例。


<details>
  <summary>Details</summary>
Motivation: LLM在数学推理方面仍需提升，尤其是在将抽象结构实例化到具体场景并形式化定理方面。本研究旨在解决此问题，以实现研究级别的数学结果的自动形式化。

Method: SITA框架将形式化的抽象结构视为模块化模板，包含定义、假设、操作和定理。该框架通过生成相应的Lean定义和实例声明，利用Lean的typeclass机制进行整合，并通过检查结构假设来构建已验证的定理。该方法结合了基于LLM的生成与反馈引导的优化。

Result: 实验表明，SITA能够有效形式化源于抽象结构的多样化实例，在优化问题数据集上得到了验证。

Conclusion: SITA框架能够成功地将抽象数学结构自动形式化为具体的定理实例，提高了数学推理的自动化和准确性。

Abstract: While large language models (LLMs) have shown progress in mathematical reasoning, they still face challenges in formalizing theorems that arise from instantiating abstract structures in concrete settings. With the goal of auto-formalizing mathematical results at the research level, we develop a framework for structure-to-instance theorem autoformalization (SITA), which systematically bridges the gap between abstract mathematical theories and their concrete applications in Lean proof assistant. Formalized abstract structures are treated as modular templates that contain definitions, assumptions, operations, and theorems. These templates serve as reusable guides for the formalization of concrete instances. Given a specific instantiation, we generate corresponding Lean definitions and instance declarations, integrate them using Lean's typeclass mechanism, and construct verified theorems by checking structural assumptions. We incorporate LLM-based generation with feedback-guided refinement to ensure both automation and formal correctness. Experiments on a dataset of optimization problems demonstrate that SITA effectively formalizes diverse instances grounded in abstract structures.

</details>


### [173] [Explaining Decentralized Multi-Agent Reinforcement Learning Policies](https://arxiv.org/abs/2511.10409)
*Kayla Boggess,Sarit Kraus,Lu Feng*

Main category: cs.AI

TL;DR: 本研究提出了一种用于去中心化多智能体强化学习（MARL）的策略摘要和查询式解释方法，以解决现有解释方法在去中心化环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的 MARL 解释方法大多集中于中心化设置，未能有效处理去中心化 MARL 中固有的不确定性和非确定性。

Method: 提出生成策略摘要，捕捉去中心化 MARL 策略中的任务排序和智能体协作；同时提出查询式解释，回答关于特定智能体行为的“何时”、“为何不”和“什么”等用户查询。

Result: 在四个 MARL 领域和两种去中心化 MARL 算法上进行了评估，证明了方法的泛化性和计算效率。用户研究表明，所提出的摘要和解释显著提高了用户在问答任务上的表现，并提升了用户在理解和满意度等指标上的主观评分。

Conclusion: 所提出的方法能够有效解释去中心化 MARL 策略，提高用户对智能体行为的理解和满意度。

Abstract: Multi-Agent Reinforcement Learning (MARL) has gained significant interest in recent years, enabling sequential decision-making across multiple agents in various domains. However, most existing explanation methods focus on centralized MARL, failing to address the uncertainty and nondeterminism inherent in decentralized settings. We propose methods to generate policy summarizations that capture task ordering and agent cooperation in decentralized MARL policies, along with query-based explanations for When, Why Not, and What types of user queries about specific agent behaviors. We evaluate our approach across four MARL domains and two decentralized MARL algorithms, demonstrating its generalizability and computational efficiency. User studies show that our summarizations and explanations significantly improve user question-answering performance and enhance subjective ratings on metrics such as understanding and satisfaction.

</details>


### [174] [Generalizing Analogical Inference from Boolean to Continuous Domains](https://arxiv.org/abs/2511.10416)
*Francisco Cunha,Yves Lepage,Zied Bouraoui,Miguel Couceiro*

Main category: cs.AI

TL;DR: 该论文提出了一种统一的类比推理框架，适用于实值域，并解决了布尔域中现有泛化界限失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有类比推理的形式化框架仅限于布尔域，且在布尔域中的一些泛化界限存在问题，无法扩展到回归任务或连续域。

Method: 提出了一种基于参数化类比（通过广义均值定义）的统一框架，该框架包含布尔分类和回归，并支持连续函数上的类比推理。分析了该框架下的类比保持函数，并推导了最坏情况和平均情况的误差界限。

Result: 在布尔域中提供了一个反例，证明了现有泛化界限的局限性。提出了一个适用于实值域的类比推理统一框架，该框架能够处理连续函数，并提供了误差界限。

Conclusion: 该研究为跨离散和连续域的类比推理提供了一个通用的理论基础。

Abstract: Analogical reasoning is a powerful inductive mechanism, widely used in human cognition and increasingly applied in artificial intelligence. Formal frameworks for analogical inference have been developed for Boolean domains, where inference is provably sound for affine functions and approximately correct for functions close to affine. These results have informed the design of analogy-based classifiers. However, they do not extend to regression tasks or continuous domains. In this paper, we revisit analogical inference from a foundational perspective. We first present a counterexample showing that existing generalization bounds fail even in the Boolean setting. We then introduce a unified framework for analogical reasoning in real-valued domains based on parameterized analogies defined via generalized means. This model subsumes both Boolean classification and regression, and supports analogical inference over continuous functions. We characterize the class of analogy-preserving functions in this setting and derive both worst-case and average-case error bounds under smoothness assumptions. Our results offer a general theory of analogical inference across discrete and continuous domains.

</details>


### [175] [Using Certifying Constraint Solvers for Generating Step-wise Explanations](https://arxiv.org/abs/2511.10428)
*Ignace Bleukx,Maarten Flippo,Bart Bogaerts,Emir Demirović,Tias Guns*

Main category: cs.AI

TL;DR: 通过将约束求解器生成的证明表示为抽象证明框架，并应用修剪和简化技术，可以比现有方法更快地生成逐步解释，同时保持相似的解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有逐步解释方法计算成本高，限制了其应用范围。需要一种更有效的方法来生成逐步解释。

Method: 定义了一个抽象证明框架，可以表示证明和逐步解释。提出将约束求解器生成的证明转换为逐步解释序列的方法，并进行修剪和简化。

Result: 与现有方法相比，该方法显著加快了逐步解释序列的生成速度，同时生成的逐步解释质量相似。

Conclusion: 利用约束求解器生成的证明作为起点，并结合抽象证明框架和简化技术，可以高效地生成高质量的逐步解释，解决了现有方法的计算瓶颈。

Abstract: In the field of Explainable Constraint Solving, it is common to explain to a user why a problem is unsatisfiable. A recently proposed method for this is to compute a sequence of explanation steps. Such a step-wise explanation shows individual reasoning steps involving constraints from the original specification, that in the end explain a conflict. However, computing a step-wise explanation is computationally expensive, limiting the scope of problems for which it can be used. We investigate how we can use proofs generated by a constraint solver as a starting point for computing step-wise explanations, instead of computing them step-by-step. More specifically, we define a framework of abstract proofs, in which both proofs and step-wise explanations can be represented. We then propose several methods for converting a proof to a step-wise explanation sequence, with special attention to trimming and simplification techniques to keep the sequence and its individual steps small. Our results show our method significantly speeds up the generation of step-wise explanation sequences, while the resulting step-wise explanation has a quality similar to the current state-of-the-art.

</details>


### [176] [Preference Elicitation for Step-Wise Explanations in Logic Puzzles](https://arxiv.org/abs/2511.10436)
*Marco Foschini,Marianne Defresne,Emilio Gamba,Bart Bogaerts,Tias Guns*

Main category: cs.AI

TL;DR: 通过学习用户偏好来改进逻辑谜题的分步解释，使用动态归一化和新的查询策略MACHOP来提高解释质量。


<details>
  <summary>Details</summary>
Motivation: 需要为分步解释定义一个好的目标函数来量化每一步的质量，但这是一个挑战。

Method: 研究使用交互式偏好获取方法来学习用户对分步解释的偏好，提出动态归一化技术来解决特征尺度差异大的问题，并引入了新的查询生成策略MACHOP，结合了非支配约束和基于置信上界的多元化。

Result: 在数独和逻辑网格谜题上进行了评估，包括人工智能用户和真实用户评估。MACHOP 产生的解释质量优于标准方法。

Conclusion: 所提出的交互式偏好获取方法，包括动态归一化和MACHOP查询策略，对于学习用户对分步解释的偏好是可行的，并且能够生成更高质量的解释。

Abstract: Step-wise explanations can explain logic puzzles and other satisfaction problems by showing how to derive decisions step by step. Each step consists of a set of constraints that derive an assignment to one or more decision variables. However, many candidate explanation steps exist, with different sets of constraints and different decisions they derive. To identify the most comprehensible one, a user-defined objective function is required to quantify the quality of each step. However, defining a good objective function is challenging. Here, interactive preference elicitation methods from the wider machine learning community can offer a way to learn user preferences from pairwise comparisons. We investigate the feasibility of this approach for step-wise explanations and address several limitations that distinguish it from elicitation for standard combinatorial problems. First, because the explanation quality is measured using multiple sub-objectives that can vary a lot in scale, we propose two dynamic normalization techniques to rescale these features and stabilize the learning process. We also observed that many generated comparisons involve similar explanations. For this reason, we introduce MACHOP (Multi-Armed CHOice Perceptron), a novel query generation strategy that integrates non-domination constraints with upper confidence bound-based diversification. We evaluate the elicitation techniques on Sudokus and Logic-Grid puzzles using artificial users, and validate them with a real-user evaluation. In both settings, MACHOP consistently produces higher-quality explanations than the standard approach.

</details>


### [177] [Non-Monotonic S4F Standpoint Logic](https://arxiv.org/abs/2511.10449)
*Piotr Gorczyca,Hannes Strass*

Main category: cs.AI

TL;DR: S4F Standpoint Logic 是一种新的多视角非单调推理形式，计算复杂度不高于其组成逻辑。


<details>
  <summary>Details</summary>
Motivation: 统一表示多视角和非单调推理，特别是利用模态逻辑 S4F。

Method: 定义 S4F Standpoint Logic 的语法和语义，分析其计算复杂度，并提出可信和怀疑接受的机制。

Result: S4F Standpoint Logic 的计算复杂度不高于其构成逻辑（S4F 和 standpoint propositional logic），无论是单调还是非单调形式。

Conclusion: S4F Standpoint Logic 成功地统一了多视角推理和非单调推理，并且在计算复杂度上具有优势。

Abstract: Standpoint logics offer unified modal logic-based formalisms for representing multiple heterogeneous viewpoints. At the same time, many non-monotonic reasoning frameworks can be naturally captured using modal logics, in particular using the modal logic S4F. In this work, we propose a novel formalism called S4F Standpoint Logic, which generalises both S4F and standpoint propositional logic and is therefore capable of expressing multi-viewpoint, non-monotonic semantic commitments. We define its syntax and semantics and analyze its computational complexity, obtaining the result that S4F Standpoint Logic is not computationally harder than its constituent logics, whether in monotonic or non-monotonic form. We also outline mechanisms for credulous and sceptical acceptance and illustrate the framework with an example.

</details>


### [178] [Proceedings of The third international workshop on eXplainable AI for the Arts (XAIxArts)](https://arxiv.org/abs/2511.10482)
*Corey Ford,Elizabeth Wilson,Shuoyang Zheng,Gabriel Vigliensoni,Jeba Rezwana,Lanxi Xiao,Michael Clemens,Makayla Lewis,Drew Hemment,Alan Chamberlain,Helen Kennedy,Nick Bryan-Kinns*

Main category: cs.AI

TL;DR: XAIxArts工作坊在C&C 2025会议上举行，旨在探讨XAI在艺术领域的应用。


<details>
  <summary>Details</summary>
Motivation: XAIxArts工作坊汇集了来自人机交互、交互设计、人工智能、可解释人工智能（XAI）和数字艺术等领域的社区研究人员，以探索XAI在艺术领域的应用。

Method: 通过在第17届ACM创意与认知会议（C&C 2025）上举办工作坊，汇集研究人员进行探讨。

Result: 成功举办了XAIxArts工作坊，促进了相关领域研究人员的交流与合作。

Conclusion: XAI在艺术领域具有重要的应用潜力，值得进一步研究。

Abstract: This third international workshop on explainable AI for the Arts (XAIxArts) brought together a community of researchers in HCI, Interaction Design, AI, explainable AI (XAI), and digital arts to explore the role of XAI for the Arts. Workshop held at the 17th ACM Conference on Creativity and Cognition (C&C 2025), online.

</details>


### [179] [Strategic Opponent Modeling with Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling](https://arxiv.org/abs/2511.10501)
*Georgios Chalkiadakis,Charilaos Akasiadis,Gerasimos Koresis,Stergios Plataniots,Leonidas Bakopoulos*

Main category: cs.AI

TL;DR: 本篇论文主要综述了图神经网络、深度强化学习和概率主题模型在策略性多智能体设置中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索机器学习方法在策略性对手建模中的应用，并将其与避免现实世界中常见假设（如共同先验假设和自我利益假设）的博弈论概念相结合，以处理不确定性和异质性。

Method: 论文回顾了图神经网络（GNN）、多智能体深度强化学习（MADRL）以及概率主题模型（PTM）等方法，并讨论了它们的优缺点及其在多智能体博弈中的应用前景。文中还考虑了博弈论中的公平性和稳定性等概念。

Result: 研究表明，图神经网络在处理多智能体关系和交互方面具有潜力。概率主题模型有助于处理异质性和未知的智能体信念。然而，在适应非平稳环境、平衡稳定性和适应性、处理不确定性和异质性以及保证可扩展性和可解性方面仍存在挑战。

Conclusion: 本篇论文对图神经网络、深度强化学习和概率主题模型在策略性多智能体设置中的应用进行了全面的回顾，并指出了未来研究方向和挑战。

Abstract: This paper provides a comprehensive review of mainly Graph Neural Networks, Deep Reinforcement Learning, and Probabilistic Topic Modeling methods with a focus on their potential incorporation in strategic multiagent settings. We draw interest in (i) Machine Learning methods currently utilized for uncovering unknown model structures adaptable to the task of strategic opponent modeling, and (ii) the integration of these methods with Game Theoretic concepts that avoid relying on assumptions often invalid in real-world scenarios, such as the Common Prior Assumption (CPA) and the Self-Interest Hypothesis (SIH). We analyze the ability to handle uncertainty and heterogeneity, two characteristics that are very common in real-world application cases, as well as scalability. As a potential answer to effectively modeling relationships and interactions in multiagent settings, we champion the use of Graph Neural Networks (GNN). Such approaches are designed to operate upon graph-structured data, and have been shown to be a very powerful tool for performing tasks such as node classification and link prediction. Next, we review the domain of Reinforcement Learning (RL), and in particular that of Multiagent Deep Reinforcement Learning (MADRL). Following, we describe existing relevant game theoretic solution concepts and consider properties such as fairness and stability. Our review comes complete with a note on the literature that utilizes PTM in domains other than that of document analysis and classification. The capability of PTM to estimate unknown underlying distributions can help with tackling heterogeneity and unknown agent beliefs. Finally, we identify certain open challenges specifically, the need to (i) fit non-stationary environments, (ii) balance the degrees of stability and adaptation, (iii) tackle uncertainty and heterogeneity, (iv) guarantee scalability and solution tractability.

</details>


### [180] [Rethinking Science in the Age of Artificial Intelligence](https://arxiv.org/abs/2511.10524)
*Maksim E. Eren,Dorianis M. Perez*

Main category: cs.AI

TL;DR: AI正在改变科研范式，从信息管理到实验设计，AI正成为科研的活跃合作者。然而，AI的应用需要审慎的治理，它应增强而非取代人类判断，尤其是在同行评审、伦理评估和结果验证等方面。本文呼吁通过相关政策，促进AI在科研中的透明、可重复和负责任的应用。


<details>
  <summary>Details</summary>
Motivation: AI在各学科研究中的应用日益广泛，深刻改变了研究的构思、执行和交流方式，这需要对AI在科研工作流中的作用进行审视和界定。

Method: 本文通过分析AI在信息管理、文献筛选、假设生成、实验设计与执行等方面的应用，探讨AI如何成为科研的活跃合作者，并提出AI在科研工作流中应与人类协作的观点。

Result: AI已从单纯的计算工具转变为科研的活跃合作者，能够协助处理信息、产生假设、设计实验等，但AI的应用仍需人类的监督与判断，特别是在同行评审、伦理评估和结果验证等环节。

Conclusion: AI在科学研究中的应用是一个革命性的转变，但必须以负责任和审慎的态度进行。AI应作为增强人类能力的工具，而非完全取代人类的角色，尤其是在涉及判断和伦理的领域。政策的制定应侧重于提高AI应用的透明度、可重复性和问责制，以确保AI技术能够安全有效地服务于科学进步。

Abstract: Artificial intelligence (AI) is reshaping how research is conceived, conducted, and communicated across fields from chemistry to biomedicine. This commentary examines how AI is transforming the research workflow. AI systems now help researchers manage the information deluge, filtering the literature, surfacing cross-disciplinary links for ideas and collaborations, generating hypotheses, and designing and executing experiments. These developments mark a shift from AI as a mere computational tool to AI as an active collaborator in science. Yet this transformation demands thoughtful integration and governance. We argue that at this time AI must augment but not replace human judgment in academic workflows such as peer review, ethical evaluation, and validation of results. This paper calls for the deliberate adoption of AI within the scientific practice through policies that promote transparency, reproducibility, and accountability.

</details>


### [181] [Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback](https://arxiv.org/abs/2511.10572)
*Mohammadsina Almasi,Hadis Anahideh*

Main category: cs.AI

TL;DR: 我们提出了一个新颖的双层上下文老虎机框架，用于在有延迟反馈的情况下进行个体化资源分配，该框架可在具有动态人群、容量限制和时间敏感影响的实际环境中运行。


<details>
  <summary>Details</summary>
Motivation: 在教育、就业和医疗保健等高风险领域公平地分配有限资源，需要平衡短期效用与长期影响，同时考虑延迟结果、隐藏的异质性和道德约束。然而，大多数基于学习的分配框架要么假设即时反馈，要么忽略个体特征与干预动态之间的复杂相互作用。

Method: 我们提出了一个新颖的双层上下文老虎机框架，用于在有延迟反馈的情况下进行个体化资源分配。在元层面，该模型优化亚组层面的预算分配，以满足公平性和操作性约束。在基础层面，它使用在观测数据上训练的神经网络来识别每个组内最有响应的个体，同时尊重通过特定于资源的延迟核建模的冷却窗口和延迟治疗效果。通过显式建模时间动态和反馈延迟，该算法在有新数据到达时不断改进其策略，从而实现更具响应性和适应性的决策。

Result: 我们在来自教育和劳动力发展领域的两个真实数据集上验证了我们的方法，表明它能够实现更高的累积结果，更好地适应延迟结构，并确保跨亚组的公平分配。

Conclusion: 我们的结果突显了具有延迟意识的数据驱动决策系统在改善机构政策和社会福利方面的潜力。

Abstract: Equitably allocating limited resources in high-stakes domains-such as education, employment, and healthcare-requires balancing short-term utility with long-term impact, while accounting for delayed outcomes, hidden heterogeneity, and ethical constraints. However, most learning-based allocation frameworks either assume immediate feedback or ignore the complex interplay between individual characteristics and intervention dynamics. We propose a novel bi-level contextual bandit framework for individualized resource allocation under delayed feedback, designed to operate in real-world settings with dynamic populations, capacity constraints, and time-sensitive impact. At the meta level, the model optimizes subgroup-level budget allocations to satisfy fairness and operational constraints. At the base level, it identifies the most responsive individuals within each group using a neural network trained on observational data, while respecting cooldown windows and delayed treatment effects modeled via resource-specific delay kernels. By explicitly modeling temporal dynamics and feedback delays, the algorithm continually refines its policy as new data arrive, enabling more responsive and adaptive decision-making. We validate our approach on two real-world datasets from education and workforce development, showing that it achieves higher cumulative outcomes, better adapts to delay structures, and ensures equitable distribution across subgroups. Our results highlight the potential of delay-aware, data-driven decision-making systems to improve institutional policy and social welfare.

</details>


### [182] [Regular Games -- an Automata-Based General Game Playing Language](https://arxiv.org/abs/2511.10593)
*Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik*

Main category: cs.AI

TL;DR: RG是一个新的通用游戏（GGP）系统，旨在提高计算效率和易用性。


<details>
  <summary>Details</summary>
Motivation: RG的主要目标是实现计算效率和游戏设计的便捷性。

Method: RG系统包含一个核心的低级语言，使用有限自动机定义游戏规则，并有更高级的语言用于游戏设计，最终会被翻译成低级语言。

Result: RG生成的前向模型比现有技术更快，在效率方面优于其他GGP系统，并且其生态系统包括编辑器、可视化工具、基准测试工具和调试器。

Conclusion: RG是一个高效且易于设计的GGP系统，在处理有限的、回合制的、不完美信息的游戏方面具有优势。

Abstract: We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based games with imperfect information. Higher-level languages are introduced for game design (by humans or Procedural Content Generation), which are eventually translated to a low-level language. RG generates faster forward models than the current state of the art, beating other GGP systems (Regular Boardgames, Ludii) in terms of efficiency. Additionally, RG's ecosystem includes an editor with LSP, automaton visualization, benchmarking tools, and a debugger of game description transformations.

</details>


### [183] [Querying Labeled Time Series Data with Scenario Programs](https://arxiv.org/abs/2511.10627)
*Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia*

Main category: cs.AI

TL;DR: AV 故障场景在真实世界中的可复现性是关键问题。本文提出一种形式化方法，将带标签的时间序列传感器数据与 Scenic 语言定义的抽象场景进行匹配，并通过查询算法在真实世界数据集中定位和验证这些场景，实验证明该方法比现有商业模型更准确、更快。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AV）的故障场景在模拟环境中发现后，其在真实世界中是否可复现是一个关键问题，因为模拟与现实之间的传感器数据差异可能导致虚假警报或遗漏真实问题。

Method: 提出一种形式化方法，使用 Scenic 语言定义抽象场景，并开发一种查询算法，用于在带标签的时间序列传感器数据集中匹配和定位这些场景。

Result: 该查询算法在准确性和速度上均优于最先进的商业大型语言模型，并且能够随着查询时间序列数据的增长而扩展。

Conclusion: 通过在真实世界数据集上验证模拟中发现的故障场景，可以有效弥合模拟与现实之间的差距，确保 AV 的安全性。

Abstract: Simulation-based testing has become a crucial complement to road testing for ensuring the safety of cyber physical systems (CPS). As a result, significant research efforts have been directed toward identifying failure scenarios within simulation environments. However, a critical question remains. Are the AV failure scenarios discovered in simulation reproducible on actual systems in the real world? The sim-to-real gap caused by differences between simulated and real sensor data means that failure scenarios identified in simulation might either be artifacts of synthetic sensor data or actual issues that also occur with real sensor data. To address this, an effective approach to validating simulated failure scenarios is to locate occurrences of these scenarios within real-world datasets and verify whether the failure persists on the datasets. To this end, we introduce a formal definition of how labeled time series sensor data can match an abstract scenario, represented as a scenario program using the Scenic probabilistic programming language. We present a querying algorithm that, given a scenario program and a labeled dataset, identifies the subset of data that matches the specified scenario. Our experiment shows that our algorithm is more accurate and orders of magnitude faster in querying scenarios than the state-of-the-art commercial vision large language models, and can scale with the duration of queried time series data.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [184] [Resolving the phase of a Dirac topological state via interferometric photoemission](https://arxiv.org/abs/2511.09560)
*Shiri Gvishi,Ittai Sidilkover,Shaked Rosenstein,Nir Hen Levin,Adi Peled,Omer Pasternak,Costel R. Rotundu,Ido Biran,Semën Gorfman,Naaman Amer,Hadas Soifer*

Main category: cond-mat.mes-hall

TL;DR: 本研究开发了一种量子路径电子干涉仪，能够以能量和动量分辨率重建量子材料中电子态的相位。


<details>
  <summary>Details</summary>
Motivation: 电子波函数的相位信息在量子材料中至关重要，但目前的技术难以获取，阻碍了对丰富电子信息的理解。

Method: 利用时间-和角度分辨的光电子能谱技术，结合量子路径电子干涉仪，实现了电子波函数相位的测量。

Result: 成功测量了原型拓扑绝缘体中狄拉克电子能带的相位，观察到了与共振相关的相位跳跃以及与动量同步的相位反转，揭示了狄拉克锥的螺旋性。该干涉仪可以通过光极化进行光学控制，实现相位的差分测量。

Conclusion: 开发了一种纯实验性的光电子干涉仪方案，无需依赖特定的理论模型，能够解决量子材料的相位测量问题，并可扩展应用于多种材料，为量子材料研究开辟了新的维度。

Abstract: The electronic wavefunction is at the heart of physical phenomena, defining the frontiers of quantum materials research. While the amplitude of the electron wavefunction in crystals can be measured with state-of-the-art probes in unprecedented resolution, its phase has remained largely inaccessible, obscuring rich electronic information. Here we develop a quantum-path electron interferometer based on time- and angle-resolved photoemission spectroscopy, that enables the reconstruction of the phase of electronic states in quantum materials - with energy and momentum resolution. We demonstrate the scheme by resolving the phase along the Dirac electronic band of a prototypical topological insulator and observe a resonance-associated phase jump as well as a momentum and phase synchronized inversion revealing the helicity of the Dirac cone. We show the interferometer can be optically controlled by the polarization of the absorbed light, allowing a differential measurement of the phase - a crucial component for extracting phase information from an interferogram. This photo-electron-interferometer is a purely experimental scheme and does not rely on any specific theoretical model. It can be extended to a variety of materials, opening up the phase dimension in quantum materials research.

</details>


### [185] [Superdiffusive transport protected by topology and symmetry in all dimensions](https://arxiv.org/abs/2511.09629)
*Shaofeng Huang,Yu-Peng Wang,Jie Ren,Chen Fang*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种在量子模型中诱导超扩散的新机制（节点机制），该机制具有在凝聚态物理系统中实现的潜力，并提出了实验验证的途径。


<details>
  <summary>Details</summary>
Motivation: 现有的节点机制超扩散模型大多基于人为设计的哈密顿量，难以在实验中实现。因此，需要提出一种更具普适性和实验可行性的模型。

Method: 通过研究不同空间维度下，易迁电子与局域杂质轨道的杂化作用，在对称性和拓扑保护下产生鲁棒的节点结构。推导了普适的电导标度律 $G acksim L^{-γ}$，其中指数 $γ$ 由节点结构的维度 $D_{	ext{node}}$、阶数 $n$ 以及系统的维度 $D$（高温）或费米面的维度 $D^F$（低温）决定。通过数值模拟，在石墨烯和多韦尔半金属等模型中验证了该标度律。

Result: 理论推导并数值验证了电导标度律，得到了模型和实验参数之间的关系。预测了线性温电阻率（$ρacksim T$）和发散的低频光学电导率（$σ(ω) acksim ω^{γ-1}$）等可验证的实验信号。

Conclusion: 本文提出的节点机制模型具有广泛的适用性和实验可行性，为在凝聚态材料中发现和工程化异常输运现象提供了新的途径。

Abstract: Superdiffusion is an anomalous transport behavior. Recently, a new mechanism, termed the ``nodal mechanism," has been proposed to induce superdiffusion in quantum models. However, existing realizations of the nodal mechanism have so far been proposed on fine-tuned, artificial Hamiltonians, posing a significant challenge for experimental observation. In this work, we propose a broad class of models for generating superdiffusion potentially realizable in condensed matter systems across different spatial dimensions. A robust nodal structure emerges from the hybridization between the itinerant electrons and the local impurity orbitals, protected by the intrinsic symmetry and topology of the electronic band. We derive a universal scaling law for the conductance, $G \sim L^{-γ}$, revealing how the exponent is dictated by the dimensionality of the nodal structure ($D_{\text{node}}$) and its order $n$, and the dimensionality of the system $(D)$ at high temperatures or that of the Fermi surface ($D^F$) at low temperatures. Through numerical simulations, we validate these scaling relations at zero temperature for various models, including those based on graphene and multi-Weyl semimetals, finding excellent agreement between our theory and the computed exponents. Beyond the scaling of conductance, our framework predicts a suite of experimentally verifiable signatures, notably a new mechanism for linear-in-temperature resistivity ($ρ\sim T$) and a divergent low-frequency optical conductivity ($σ(ω) \sim ω^{γ-1}$), establishing a practical route to discovering and engineering anomalous transport in quantum materials.

</details>


### [186] [Green Function Invariants for Floquet Topological Superconductivity Induced by Proximity Effects](https://arxiv.org/abs/2511.09650)
*Mohamed Assili,Panagiotis Kotetes*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种用于预测驱动的超导体-半导体混合物的Floquet拓扑相的格林函数方法，并提出了构建Floquet拓扑不变量的方法，考虑了自能的厄米部分和反厄米部分，并以Rashba纳米线为例进行了说明，结果表明自能对拓扑相的观测有重要影响。


<details>
  <summary>Details</summary>
Motivation: 目前的超导-半导体混合物研究中，通常将超导部分视为库，但在驱动存在时，由于能级展宽的出现，这种近似会失效。因此，需要一种新的方法来处理驱动下的超导-半导体混合物。

Method: 提出了一种格林函数方法，首先通过包含半导体自能的厄米部分获得中能谱，然后通过将自能的反厄米部分投影到准能特征向量上来读出相应的能级展宽。将此方法应用于Rashba纳米线与超导体和时间依赖的Zeeman场耦合的系统。

Result: 得到了Floquet能带结构、相应的能级展宽和拓扑不变量。分析表明，自能对观察Floquet拓扑相（特别是包含Majorana π模式的相）有重要影响，展宽效应会阻碍其观测。

Conclusion: 为了正确地观察Floquet拓扑相，必须仔细考虑自能效应。能级展宽会阻碍Floquet拓扑相的观测，特别是那些包含Majorana π模式的相。

Abstract: We bring forward a Green function approach for the prediction of Floquet topological phases in driven superconductor-semiconductor hybrids. Although it is common to treat the superconducting component as a mere Cooper-pair reservoir, it was recently pointed out that such an approximation breaks down in the presence of driving, due to the emergence of level broadening. Here, we go beyond these recent works and prescribe how to construct the Floquet topological invariants for such driven hybrids. Specifically, we propose to first obtain the midgap quasi-energy spectra by including the hermitian part of the semiconductor's self-energy and, subsequently, read out the respective level broadenings by projecting the anti-hermitian part of the self-energy onto the quasi-energy eigenvectors. We exemplify our approach for a Rashba nanowire coupled to a superconductor and a time-dependent Zeeman field. Using our method, we obtain the Floquet band structure, the respective level broadenings, and the topological invariants. Our analysis reinforces the need to properly account for the self-energy, and corroborates that broadening effects can hinder the observation of the Floquet topological phases and especially of those harboring Majorana $π$ modes.

</details>


### [187] [Impact of Contact Gating on Scaling of Monolayer 2D Transistors Using a Symmetric Dual-Gate Structure](https://arxiv.org/abs/2511.09762)
*Victoria M. Ravel,Sarah R. Evans,Samantha K. Holmes,James L. Doherty,Md Sazzadur Rahman,Tania Roy,Aaron D. Franklin*

Main category: cond-mat.mes-hall

TL;DR: 双栅极结构揭示了接触栅在二维场效应晶体管中的重要作用，特别是在缩小尺寸时，可显著提高器件性能。


<details>
  <summary>Details</summary>
Motivation: 研究接触栅（即栅极电势调制金属-半导体界面处的载流子传输）对二维（2D）场效应晶体管（FET）性能和可扩展性的影响，特别是当栅极与源极和漏极重叠时。

Method: 采用对称双栅极结构（独立的背栅和顶栅），以量化接触栅效应。通过定义接触栅因子来评估其影响。

Result: 在长沟道器件中，接触栅效应使器件的开启态性能提高了2倍。在缩小尺寸（沟道50纳米，接触长度30纳米）的器件中，接触栅效应的增幅作用更加显著，开启态性能提高了5倍，转移长度减少了70%。

Conclusion: 接触栅是决定二维场效应晶体管器件性能的一个关键且先前被低估的因素，尤其是在许多具有出色性能的二维场效应晶体管中都采用了固有的接触栅效应的背栅结构。

Abstract: The performance and scalability of two-dimensional (2D) field-effect transistors (FETs) are strongly influenced by geometry-defined electrostatics. In most 2D FET studies, the gate overlaps with the source and drain electrodes, allowing the gate potential to modulate the 2D semiconductor underneath the electrodes and ultimately effect carrier transport at the metal-semiconductor interface - a phenomenon known as contact gating. Here, a symmetric dual-gate structure with independently addressable back and top gates is employed to elucidate the impact of contact gating on a monolayer MoS2 channel. Unlike previous studies of contact gating, this symmetric structure enables quantification of the phenomena through a contact gating factor, revealing a 2x enhancement in on-state performance in long-channel devices. At scaled dimensions (50 nm channel and 30 nm contact length), the influence of contact gating becomes amplified, yielding a 5x increase in on-state performance and a 70% reduction in transfer length when contact gating is present. Since many reported record-performance 2D FETs employ back-gate geometries that inherently include contact gating, these results establish contact gating as a critical and previously underappreciated determinant of device performance in the 2D FET landscape.

</details>


### [188] [Probing Topological Stability with Nonlocal Quantum Geometric Markers](https://arxiv.org/abs/2511.09664)
*Quentin Marsal,Hui Liu,Emil J. Bergholtz,Annica M. Black-Schaffer*

Main category: cond-mat.mes-hall

TL;DR: 非局域量子几何标记在拓扑相（特别是无序系统）的诊断中至关重要，并且在拓扑相变附近表现出尖锐的变化，为每个相变提供独特的空间模式。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨空间分辨的局部量子几何标记的非局域性，以及它们在诊断无序拓扑相中的作用。

Method: 研究非局域量子几何标记的行为，将其与关联函数进行比较，并分析它们在拓扑相变附近的表现以及在实空间中的模式。

Result: 研究发现，量子几何标记的行为独立于材料结构，在拓扑相变附近有尖锐变化，并为每个相变在实空间中产生独特的模式。即使在同一Altland-Zirnbauer类别中，不同的拓扑相变也会产生不同的空间特征。

Conclusion: 非局域量子几何指标提供了一种更有效、更通用的工具来理解和预测拓扑相变的稳定性，即使在同一拓扑类别中也能区分不同的相变。

Abstract: Spatially resolved local quantum geometric markers play a crucial role in the diagnosis of topological phases without long-range translational symmetry, including amorphous systems. Here, we focus on the nonlocality of such markers. We demonstrate that they behave as correlation functions independently of the material's structure, showing sharp variations in the vicinity of topological transitions and exhibiting a unique pattern in real space for each transition. Notably, we find that, even within the same Altland-Zirnbauer class, distinct topological transitions generate qualitatively different spatial signatures, enabling a refined, class-internal probe of topological stability. As such, nonlocal quantum geometric indicators provide a more efficient and versatile tool to understand and predict the stability of topological phase transitions.

</details>


### [189] [Observation of Shapiro Steps in the Charge Density Wave State Induced by Strain on a Piezoelectric Substrate](https://arxiv.org/abs/2511.09888)
*Koji Fujiwara,Takuya Kawada,Natsumi Nikaido,Jihoon Park,Nan Jiang,Shintaro Takada,Yasuhiro Niimi*

Main category: cond-mat.mes-hall

TL;DR: Recent development in nanotechnology has enabled us to investigate the dynamic properties of van der Waals materials on a piezoelectric substrate. Here we report on the dynamics of charge density wave (CDW) in NbSe$_{3}$ nanowires induced by surface acoustic waves (SAWs). Clear peaks in the differential resistance were observed at the resonant frequency of the SAW device. These peaks known as Shapiro steps are typically observed by applying an rf current to NbSe$_{3}$ nanowires. We found that the Shapiro steps induced by SAWs show several distinct features from the ones induced by an rf current. Our detailed study revealed that a strain induced by SAWs plays a significant role in the Shapiro steps. The result clearly demonstrates the importance of the strain in CDW materials and paves the way for strain-induced device applications.


<details>
  <summary>Details</summary>
Motivation: Investigate the dynamics of charge density wave (CDW) in NbSe$_{3}$ nanowires induced by surface acoustic waves (SAWs).

Method: Observed Shapiro steps in the differential resistance of NbSe$_{3}$ nanowires at the resonant frequency of the SAW device, induced by SAWs. Compared these steps with those induced by an rf current. Studied the role of strain induced by SAWs in the Shapiro steps.

Result: Shapiro steps induced by SAWs showed distinct features compared to those induced by an rf current. Strain induced by SAWs plays a significant role in the Shapiro steps.

Conclusion: The study clearly demonstrates the importance of strain in CDW materials and suggests potential for strain-induced device applications.

Abstract: Recent development in nanotechnology has enabled us to investigate the dynamic properties of van der Waals materials on a piezoelectric substrate. Here we report on the dynamics of charge density wave (CDW) in NbSe$_{3}$ nanowires induced by surface acoustic waves (SAWs). Clear peaks in the differential resistance were observed at the resonant frequency of the SAW device. These peaks known as Shapiro steps are typically observed by applying an rf current to NbSe$_{3}$ nanowires. We found that the Shapiro steps induced by SAWs show several distinct features from the ones induced by an rf current. Our detailed study revealed that a strain induced by SAWs plays a significant role in the Shapiro steps. The result clearly demonstrates the importance of the strain in CDW materials and paves the way for strain-induced device applications.

</details>


### [190] [k-Selective Electrical-to-Magnon Transduction with Realistic Field-distributed Nanoantennas](https://arxiv.org/abs/2511.10346)
*Andreas Höfinger,Andrey A. Voronov,David Schmoll,Sabri Koraltan,Florian Bruckner,Claas Abert,Dieter Suess,Morris Lindner,Timmy Reimann,Carsten Dubs,Andrii V. Chumak,Sebastian Knauer*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种全电气传播自旋波谱学（AEPSWS）框架，能够将电磁驱动场与微磁动力学关联起来，并提供用于设计片上磁子换能器的规则。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够将电磁驱动场与微磁动力学精确关联起来的框架，以用于经典磁子电路和量子技术。

Method: 使用有限元（FE）模拟计算天线的近场分布，并将其导入有限差分（FD）微磁求解器，以模拟自旋波动力学。

Result: 模拟结果在色散脊、群速度和谱峰位置等方面与实验结果（AEPSWS on a 48 nm YIG film）具有定量一致性，表明天线可以作为可调谐的k空间滤波器。

Conclusion: 该框架能够根据真实的电流回流路径和锥形设计，推导出用于YIG薄膜中Damon-Eshbach表面自旋波的k权重函数，为片上磁子换能器的设计提供了可行的规则，对低功耗运行和量子磁子学具有重要意义。

Abstract: The excitation and detection of propagating spin waves with lithographed nanoantennas underpin both classical magnonic circuits and emerging quantum technologies. Here, we establish a framework for all-electrical propagating spin-wave spectroscopy (AEPSWS) that links realistic electromagnetic drive fields to micromagnetic dynamics. Using finite-element (FE) simulations, we compute the full vector near-field of electrical impedance-matched, tapered coplanar and stripline antennas and import this distribution into finite-difference (FD) micromagnetic solvers. This approach captures the antenna-limited wave-vector spectrum and the component-selective driving fields (perpendicular to the static magnetisation) that simplified uniform-field models cannot. From this coupling, we derive how realistic current return paths and tapering shapes, k-weighting functions, for Damon-Eshbach surface spin waves in yttrium-iron-garnet (YIG) films are, for millimetre-scale matched CPWs and linear tapers down to nanometre-scale antennas. Validation against experimental AEPSWS on a $48\,nm$ YIG film shows quantitative agreement in dispersion ridges, group velocities, and spectral peak positions, establishing that the antenna acts as a tunable k-space filter. These results provide actionable design rules for on-chip magnonic transducers, with immediate relevance for low-power operation regimes and prospective applications in quantum magnonics.

</details>


### [191] [Enhanced Thermoelectricity in Nanowires with inhomogeneous Helical states](https://arxiv.org/abs/2511.09903)
*Zahra Aslani,Fabio Taddei,Fabrizio Dolcini,Alessandro Braggio*

Main category: cond-mat.mes-hall

TL;DR: 通过调整量子相干半导体纳米线器件中自旋轨道耦合的失谐角度，可以有效调控其热电性质。


<details>
  <summary>Details</summary>
Motivation: 研究具有强Rashba自旋-轨道耦合（RSOC）的半导体纳米线（NWs）在Zeeman场作用下的热电（TE）性质，特别是通过调整NWs段之间的失谐角度来控制TE性质。

Method: 采用散射矩阵方法和紧束缚模型，研究了不同失谐角度下NWs的TE性质，并分析了Zeeman能隙对掺杂和温度的影响。

Result: 发现当RSOC向量反平行（狄拉克悖论构型）时，Wiedemann-Franz定律被显著违反，塞贝克系数和ZT因子得到增强。Zeeman能隙确定了掺杂和温度的最佳能量窗口。

Conclusion: 通过控制自旋-轨道场方向（例如使用wrap gates）是调控和优化量子相干半导体纳米线器件TE响应的有前途的替代方法。

Abstract: Semiconductor nanowires (NWs) with strong Rashba spin-orbit coupling (RSOC), when exposed to a suitably applied Zeeman field, exhibit one-dimensional helical channels with a spin orientation locked to the propagation direction within the magnetic energy gap. Here, by adopting a scattering-matrix approach applied to a tight-binding model of the NW, we demonstrate that the thermoelectric (TE) properties can be widely controlled by tuning the misalignment angle $φ$ between the spin-orbit directions of two NW segments. In particular, when the RSOC vectors are antiparallel (Dirac paradox configuration) we predict a significant violation of the Wiedemann-Franz law, and a strong enhancement of the Seebeck coefficient and the $ZT$ figure of merit. We also show that the Zeeman gap determines the optimal energy window for doping and temperatures. These results suggest that controlling the spin-orbit field direction, which can be achieved with suitably applied wrap gates, is a promising alternative for tuning and optimizing the TE response in quantum-coherent semiconducting NW devices.

</details>


### [192] [Emergent electronic insulating states in a one-dimensional moiré superlattice](https://arxiv.org/abs/2511.10140)
*Jianfeng Bi,Masaki Minamikawa,Ruige Dong,DongJun Kang,Zihan Weng,Shaoqi Sun,Kenji Watanabe,Takashi Taniguchi,Ryosuke Okumura,Huizhen Wu,Naoto Nakatsuji,SeokJae Yoo,Mikito Koshino,Sihan Zhao*

Main category: cond-mat.mes-hall

TL;DR: 通过将单壁碳纳米管（SWNT）与二维六方氮化硼（hBN）晶体对齐，成功构建了一维（1D）莫尔超晶格，并观察到了电子绝缘态。


<details>
  <summary>Details</summary>
Motivation: 在二维（2D）范德华（vdW）莫尔超晶格已被广泛用于工程化量子态，但将其扩展到一维（1D）vdW系统仍具挑战性，因此需要新的方法来在1D系统中实现莫尔工程。

Method: 通过低温电输运测量，研究了晶体管对齐的扶手椅型单壁碳纳米管（SWNT）与二维六方氮化硼（hBN）衬底形成的莫尔超晶格中的电子绝缘态。结合密度泛函理论（DFT）和紧束缚计算来解释观测到的现象。

Result: 在莫尔超晶格的电荷中性点（CNP）、全莫尔填充和半莫尔填充处观察到显著的绝缘态。在没有hBN衬底的对照实验中未观察到这些行为。理论计算表明，纳米管的部分展平以及1D莫尔界面的晶格重构导致了AB'堆积区域的扩大，并在CNP和全莫尔填充时打开了能带隙。

Conclusion: 首次在1D莫尔超晶格中实现了莫尔工程化的电子绝缘态，证明了1D莫尔效应的显著性。虽然单粒子理论可以解释CNP和全填充绝缘态，但半填充绝缘态的出现可能源于电子关联和/或电子-声子相互作用。这项工作为1D vdW材料的莫尔工程开辟了新途径，并为探索相互作用诱导的1D量子相提供了平台。

Abstract: Two-dimensional (2D) van der Waals (vdW) moiré superlattices have provided a powerful knob to engineer a plethora of new quantum states. However, extending such moiré engineering to one-dimensional (1D) vdW systems has remained challenging. Here we report the moiré-engineered electronic insulating states in a new 1D moiré superlattice, by crystallographically aligning an armchair single-walled carbon nanotube (SWNT) to 2D hexagonal boron nitride (hBN) substrate. Remarkably, we observe the emergence of pronounced insulating states at charge neutrality point (CNP), full and half moiré fillings in lattice-aligned armchair SWNT/hBN heterostructures by low-temperature electrical transport measurements. In strong contrast, armchair SWNT devices without hBN alignment do not show any of these insulating behaviors, providing compelling evidence for the significant 1D moiré effect. Our density functional theory (DFT) and tight-binding calculations reveal that synergetic nanotube partial flattening and in-plane lattice reconstruction at 1D moiré interface expand the most stable AB' stacking regions (carbon on top of boron) and open sizable band gaps at both CNP and full moiré fillings at the single-particle level. Our one-body theory predicts no band gaps at half moiré fillings, suggesting that electron correlation and/or electron-phonon interaction may give rise to these emergent insulating behaviors in our 1D moiré systems. Our work establishes a new and definite moiré engineering route for 1D vdW materials and opens an exciting avenue for exploring interaction-induced quantum phases in 1D.

</details>


### [193] [Magnetotransport properties of an unconventional Rashba spin-orbit coupled two-dimensional electronic system](https://arxiv.org/abs/2511.10175)
*Aryan Pandita,SK Firoz Islam*

Main category: cond-mat.mes-hall

TL;DR: 该研究分析了具有非常规Rashba自旋-轨道耦合的二维电子系统的磁输运性质，其中每个自旋分支都有相反的手性自旋纹理。研究人员解析地获得了朗道能级，并观察到自旋内和/或自旋间朗道能级交叉。通过Kubo方法计算了纵向电导和量子霍尔电导，发现纵向电导中出现了通常的Shubnikov-de Haas振荡，并且可以通过调节费米能级使其完全自旋极化。在自旋内分支中观察到Shubnikov-de Haas振荡的拍频现象，这是由每个自旋分支中两个能带对应的振荡叠加引起的，这与传统Rashba系统中由两个自旋分支对应的振荡叠加引起的拍频现象不同。然而，量子霍尔电导以e^2/h的单位呈现通常的量子化，但朗道能级交叉在费米能级恰好处于交叉点时会导致霍尔电导的双跳跃。


<details>
  <summary>Details</summary>
Motivation: 研究具有非常规Rashba自旋-轨道耦合的二维电子系统的磁输运性质，特别是其朗道能级行为和电导特性。

Method: 解析求解朗道能级；使用Kubo方法计算纵向电导和量子霍尔电导。

Result: 发现了自旋内和/或自旋间朗道能级交叉；观察到纵向电导中的Shubnikov-de Haas振荡，可通过费米能级调节实现纯自旋极化；自旋内分支中出现Shubnikov-de Haas振荡的拍频现象；量子霍尔电导通常呈量子化，但在特定交叉点会出现双跳跃。

Conclusion: 该系统表现出与传统Rashba系统不同的磁输运行为，特别是在朗道能级交叉和振荡拍频方面，并对理解和设计新型自旋电子器件具有潜在意义。

Abstract: We study the magnetotransport properties of a two-dimensional electronic system with unconventional Rashba spin-orbit coupling in which the system is described by a pair of chiral spin texture in each spin branch, and the chirality is opposite in two spin branches. We obtain the Landau levels analytically and find that intra-spin and/or inter-spin Landau level crossing occurs. We compute the longitudinal conductivity and quantum Hall conductivity using the Kubo formalism based on linear response theory. We find that the usual Shubnikov-de Haas oscillation in longitudinal conductivity appears that can be made purely spin polarized by adjusting the Fermi level suitably. We observe a beating pattern in the Shubnikov-de Hass oscillation in the intra-spin branches, which arises due to the superposition of Shubnikov-de Hass oscillations corresponding to two bands in each spin branch. This is contrary to the conventional Rashba system, where such beating is due to the superposition of Shubnikov-de Hass oscillations corresponding to the two spin-branches. On the other hand, we note that quantum-Hall conductivity exhibits usual quantization in units of $e^2/h$ corresponding to each spin dependent Landau level. However, the Landau level crossing gives rise to the double jump in the Hall conductivity if the Fermi level is placed precisely at the crossing point.

</details>


### [194] [Long-range propagating paramagnon-polaritons in organic free radicals](https://arxiv.org/abs/2511.10294)
*Sebastian Knauer,Roman Verba,Rostyslav O. Serha,Denys Slobodianiuk,David Schmoll,Andreas Ney,Sergej Demokritov,Andrii Chumak*

Main category: cond-mat.mes-hall

TL;DR: 在有机自由基2,2,6,6-四甲基哌啶-1-氧基中，即使在超过其 Néel 温度的情况下，仍然可以观察到长程相干性，并以高达 23 GHz 的频率和超过 100 km/s 的超音速群速度激发和传播低能量的 paramagnon-polaritons。


<details>
  <summary>Details</summary>
Motivation: 区分顺磁性、铁磁性等不同磁响应的材料，并强调了传统磁性材料中 spin-wave (magnons) 的应用。然而，在超过居里/Néel 温度后，长程有序性会消失，只剩下短程传播的 paramagnons。该研究旨在探索在特定条件下是否能保留长程相干性。

Method: 使用全电气传播的自旋波谱技术，在外部磁场下，研究有机自由基 2,2,6,6-四甲基哌啶-1-氧基 (TOP) 在超过其 Néel 温度后的行为。

Result: 在有机自由基 TOP 中，即使在超过 Néel 温度后，仍然观察到了长程相干性。研究人员观测到了相干激发的低能量 paramagnon-polaritons，频率高达 23 GHz，传播距离达到 8 毫米，群速度超过 100 km/s。

Conclusion: 研究表明，有机自由基 TOP 在超过 Néel 温度后仍能保持自旋波的长程相干性，这为将有机材料整合到自旋电子学、信息存储和量子技术领域开辟了新的可能性。

Abstract: Materials are commonly distinguished by their magnetic response into diamagnetic, paramagnetic, and magnetically ordered (ferro-, ferri-, and antiferromagnetic) phases. Diamagnets and paramagnets lack spontaneous long-range order, whereas ordered magnets develop such order below their Curie or Néel temperature and support single spin-wave excitations (magnons). Magnons have found applications in radio-frequency technologies and computation, magneto-optics, and foundational quantum experiments. Above the Curie/Néel temperature, long-range order is lost and the material transitions to a paramagnetic phase, with localised spin alignment in small patches, producing paramagnons with only short-range propagation. Here we show that long-range coherence is preserved in the organic free radical 2,2,6,6-tetramethylpiperidin-1-oxyl above the Néel temperature using all-electrical propagating spin-wave spectroscopy in external magnetic fields. We observe coherently excited low-energy paramagnon-polaritons up to $\mathbf{23\,\mathrm{GHz}}$ , propagating over $\mathbf{8\,\mathrm{mm}}$ at supersonic group velocities exceeding $\mathbf{100\,\mathrm{km\,s^{-1}}}$. Using free radicals as magnon carriers integrates organic materials with spintronics and opens the way to organic electronics, dense information storage, and quantum technologies.

</details>


### [195] [Modification of Hanle and polarization recovery curves under interplay of hopping and quantum measurement back action](https://arxiv.org/abs/2511.10304)
*A. L. Zibinskiy,D. S. Smirnov*

Main category: cond-mat.mes-hall

TL;DR: The paper analyzes spin polarization of localized electrons in quantum dots by considering electron hopping and measurement back action under magnetic fields, revealing their competing effects in different geometries and their utility in studying quantum measurements.


<details>
  <summary>Details</summary>
Motivation: To determine parameters of spin dynamics, such as hyperfine interaction strength, using Hanle and polarization recovery effects for localized charge carriers in quantum dots.

Method: Describing the dependence of spin polarization of localized electrons on transverse and longitudinal magnetic fields, accounting for the interplay between electron hopping and measurement back action.

Result: The study shows that electron hopping and measurement back action have similar effects in Faraday geometry but compete in Voigt geometry, which helps explain a wide range of experimental results.

Conclusion: The interplay between electron hopping and measurement back action under magnetic fields can be used to describe experimental results and study fundamental effects of quantum measurements in quantum dots.

Abstract: The measurements of Hanle and polarization recovery effects for localized charge carriers are the basic tools for determining parameters of the spin dynamics, such as strength of the hyperfine interaction, for example, in quantum dots. We describe the dependence of the spin polarization of localized electrons on transverse and longitudinal magnetic fields taking into account the interplay between electron hopping and measurement back action. We show that these two have a qualitatively similar effect in the Faraday geometry, but compete in the Voigt geometry. This allows one to describe a broad range of the experimental results and study the fundamental effects of quantum measurements.

</details>


### [196] [Point defects and their dynamic behaviors in silver monolayer intercalated between graphene and SiC](https://arxiv.org/abs/2511.10368)
*Van Dong Pham,Arpit Jain,Chengye Dong,Li-Syuan Lu,Joshua A. Robinson,Achim Trampert,Roman Engel-Herbert*

Main category: cond-mat.mes-hall

TL;DR: 扫描隧道显微镜研究了二维银单层中的原子尺度缺陷，识别出空位和杂质，并观察到它们在负偏压下可以像双态开关一样跳跃，这为理解和控制二维金属中的缺陷提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 研究二维金属中的点缺陷或杂质如何引起局部结构和电子性质的改变，为基础和应用研究提供原子级别的模型。

Method: 使用扫描隧道显微镜研究了嵌入在生长石墨烯和碳化硅界面处的二维银单层中的原子尺度缺陷。

Result: 识别出两种缺陷：平面空位（暗缺陷）和取代性杂质（亮缺陷），它们都具有由缺陷引起的局部电子态。在负偏压下，这些缺陷可以发生非弹性跳跃，并且这种跳跃行为可以被扫描隧道显微镜的探针可逆地控制，表现出类似氢开关的行为，可作为原子尺度的双态电导开关。

Conclusion: 这项研究展示了在二维金属中以原子精度理解和控制缺陷的可能性，揭示了先前未知的动态行为，并为纳米电子学提供了潜在的应用前景。

Abstract: Point defects or impurities can give rise to sharp local modifications in the structure and electronic properties of two-dimensional metals, serving as an intriguing atomic-level solid-state model for both fundamental and application research. In this work, we investigated atomic-scale defects in a two-dimensional silver monolayer intercalated at the interface between epitaxial graphene and SiC using a scanning tunneling microscope. Distinct dark and bright defects are identified as in-plane vacancies and substitutional impurities within the silver monolayer, each hosting a localized electronic state induced solely by the defect. Remarkably, under excitation of tunneling electrons assisted by a negative bias voltage, the defects can hop inelastically which is reminiscent of the hydrogen switching in the cavity of an organic molecule. The hopping can be reversibly controlled by the scanning tunneling microscope tip, allowing the defects to function as atomic-scale two-level conductance switches. Defect hopping further allows us to gain a deeper understanding of their origins and the relationship between dark and bright defect species. This study constitutes a pathway toward understanding and controlling defects in two-dimensional metals with atomic precision, revealing previously unexplored dynamic behavior with potential applications in nanoelectronics.

</details>


### [197] [Exploring the Role of Interfacial Dzyaloshinskii-Moriya Interaction in Write Error Rate Anomalies of Spin-Transfer Torque Magnetic Tunnel Junctions](https://arxiv.org/abs/2511.10437)
*Prosenjit Das,Md Mahadi Rajib,Jayasimha Atulasimha*

Main category: cond-mat.mes-hall

TL;DR: DMI会导致STT-MRAM的“起球效应”，表现为写错误率随电流增加而非单调变化。通过模拟发现DMI会促进不相干磁化翻转，延长翻转时间，并产生多畴中间态，导致翻转不完全，在高DMI值下即使在高电流密度下也会出现“起球”现象。较长的脉冲时间可以克服这些影响。研究表明DMI在“起球效应”中起作用，可以通过界面工程来提高STT-MRAM的可靠性。


<details>
  <summary>Details</summary>
Motivation: STT-MRAM在高速操作下可能出现异常开关行为，特别是“起球效应”，这会影响其性能和可靠性。本研究旨在系统地研究界面DMI对这种写错误率（WER）异常的影响。

Method: 利用20nm和50nm磁性隧道结（MTJ）的微磁模拟，系统地研究了界面DMI对“起球效应”的影响。

Result: 研究表明，DMI会促进不相干磁化翻转，延长切换时间，并产生中间多畴状态，导致翻转不完全。在高DMI值下，这些状态会持续存在，即使在较大的切换电流密度下也会重现实验中报告的“起球”类异常。相反，较长的脉冲时间可以克服这些效应，让系统有足够的时间达到稳定状态。

Conclusion: 界面DMI可能在“起球效应”中发挥作用，并指出界面工程是提高下一代STT-MRAM可靠性的实用策略。

Abstract: The performance and reliability of spin-transfer torque magnetic random-access memory (STT-MRAM) can be compromised by anomalous switching behavior, especially during high-speed operations. One such anomaly, known as the "ballooning effect" is characterized by an unexpected non-monotonic increase in the write error rate (WER) with increase in STT current at specific current pulse durations. In this study, we systematically investigate the role of the interfacial Dzyaloshinskii-Moriya interaction (DMI) on such WER anomaly using micromagnetic simulations of 20 nm and 50 nm magnetic tunnel junctions (MTJs). We show that DMI promotes incoherent magnetization reversal, prolongs the switching time and creates intermediate multidomain states that result in incomplete reversal. At high DMI values, these states persist even under large switching current densities, reproducing ballooning-like anomalies reported experimentally. In contrast, longer pulses overcome these effects by allowing the system sufficient time to reach a stable state. Our findings show that interfacial DMI can play a role in the ballooning effect and point to interfacial engineering as a practical strategy for improving the reliability of next-generation STT-MRAM.

</details>


### [198] [Elastic Dislocation-based Skyrmion Traps: Fundamentals and Applications](https://arxiv.org/abs/2511.10451)
*Martín Latorre,Joaquín Barra,Juan Pablo Vera,Joaquín Martinez,Mario Castro,Sebastián Allende,Alvaro S. Nunez*

Main category: cond-mat.mes-hall

TL;DR: 论文概述了磁畴壁拓扑结构（如斯格明子和双子）在自旋电子器件中的应用前景，并深入研究了扭曲磁晶格中的螺位错与这些拓扑磁结构之间的相互作用，提出了将拓扑磁学与拓扑弹性学联系起来的新思路。研究内容包括经典斯格明子运动分析、量化运动分析及器件实现。


<details>
  <summary>Details</summary>
Motivation: 探索拓扑磁结构（如斯格明子）与材料中位错的相互作用，以期将拓扑磁学与拓扑弹性学联系起来，并为开发新型自旋电子器件提供理论基础。

Method: 首先，通过经典分析研究位错对斯格明子运动的影响，将位错识别为磁结构上的浅势阱。其次，对斯格明子的量子化运动进行分析，识别其量子态。最后，提出利用位错阵列作为“音轨”上的“音格”，通过低电流激活机制来控制斯格明子运动的器件概念。

Result: 研究表明，螺位错可以作为斯格明子的浅势阱，限制其运动。同时，分析了斯格明子的量子化运动及其量子态。

Conclusion: 通过将拓扑磁学与拓扑弹性学相结合，并利用位错阵列作为控制斯格明子运动的机制，可以设计出基于低电流激活的简单高效自旋电子器件。

Abstract: Topologically secure spin configurations, such as skyrmions and bimerons, offer a compelling alternative to conventional magnetic domains, potentially enabling high-density, low-power spintronic devices. These pseudo-particles, characterized by their swirling spin textures and nontrivial topological charges, are prevalent and notably influence their electronic, magnetic, and mechanical traits. This paper provides an in-depth overview of the interaction between a screw dislocation within a distorted magnetic lattice, exploring possible coupling mechanisms and establishing a promising link between two disparate topics in materials science: topological magnetism and topological elasticity. We first provide a classical analysis of skyrmion motion that reveals the dislocations as shallow traps on the magnetic texture. Afterwards, we provide an analysis of the quantized motion of the skyrmion and identify its quantum states. We conclude by illustrating how the ideas in our paper can be implemented in simple yet compelling devices based on the shallow traps from an array of dislocations acting as frets in a race-track, controlling the motion with a low current activation mechanism.

</details>


### [199] [Broadband nonlinear Hall response and multiple wave mixing in a room temperature altermagnet](https://arxiv.org/abs/2511.10471)
*Soumya Sankar,Xingkai Cheng,Xinyu Chen,Xizhi Fu,Takahiro Urata Wataru Hattori,Wenlong Lu,Zihan Lin,Dong Chen,Claudia Felser,Hiroshi Ikuta,Junzhang Ma,Junwei Liu,Berthold Jäck*

Main category: cond-mat.mes-hall

TL;DR: Altermagnets具有独特的对称性和电子能带结构，可以在室温下产生新颖的非线性光学效应，例如在CrSb中发现的宽带三阶非线性反常霍尔效应。这种效应源于Berry曲率四极子，可以通过材料的晶体和磁对称性来控制，并可用于开发新型的四波混频器件，在太赫兹技术和高频电子学领域具有潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 鉴于晶体对称性在决定材料对外部刺激的线性/非线性响应中的关键作用，以及反磁体（Altermagnets）独特的磁晶序和自旋劈裂电子能带结构，我们期望它们能展现出新颖的电学特性，并可能引发新的物理现象。

Method: 通过实验观测并结合对称性分析和模型计算，研究了室温下反磁体CrSb的非线性霍尔效应，并将其与Berry曲率四极子和晶体/磁对称性联系起来，最终利用其三阶非线性电磁系数实现了多波混频器件。

Result: 成功在室温反磁体CrSb中发现了宽带三阶非线性反常霍尔效应，并确认该效应由Berry曲率四极子引起，该四极子存在于CrSb的自旋劈裂能带结构中，并由其晶体和磁对称性决定。此外，利用CrSb的三阶非线性电磁系数成功实现了具有显著四波混频输出的多波混频器件。

Conclusion: 反磁体的晶磁序决定了其非线性电学特性，这一发现为高频电子学、太赫兹产生、通信网络和能量收集等领域的应用开辟了新途径。CrSb的非线性光学特性及其在多波混频器件中的应用展示了反磁体在这些领域的潜力。

Abstract: Crystalline symmetries determine the linear and nonlinear response of materials to external stimuli such as mechanical pressure and electromagnetic fields, governing phenomena such as piezoelectricity, optical activity, and multiple wave mixing with wide ranging technological applications. Altermagnets present a new class of materials with magnetic crystalline order where specific crystal symmetry operations connect antiferromagnetic sublattices, leading to non-relativistic spin-splitting of the electronic band structure. Hence, the electric material properties of altermagnets should uniquely mirror these underlying symmetry properties, potentially giving rise to novel phenomena in response to external driving fields. Here, we report the discovery of a broadband third-order nonlinear anomalous Hall effect in altermagnetic CrSb at room temperature. The comparison of our observations with symmetry analyses and model calculations shows that this nonlinear Hall response is induced by the nonlinear electric susceptibility of a Berry curvature quadrupole, which exists within the spin-split band structure of CrSb and is characterized by the underlying crystalline and magnetic symmetries. We then utilize this third-order nonlinear electric susceptibility of CrSb to realize a multiple wave mixing device with pronounced four wave mixing output, which could, in principle, be extended to THz frequencies. Our study discovers that the crystalline magnetic order of altermagnets determines their nonlinear electric material properties, which could facilitate applications in high-frequency electronics, THz generation, communication networks, and energy harvesting.

</details>


### [200] [Ordinary lattice defects as probes of topology](https://arxiv.org/abs/2511.10646)
*Aiden J. Mains,Jia-Xin Zhong,Yun Jing,Bitan Roy*

Main category: cond-mat.mes-hall

TL;DR: 普通晶格缺陷（如空位、取代、间隙等）可以作为探测电子布洛克能带非平凡拓扑的通用探针。


<details>
  <summary>Details</summary>
Motivation: 在拓扑晶格缺陷（如位错、不协调）之外，晶体还伴随着不可避免的普通缺陷。本研究旨在证明这些看似平凡的普通晶格缺陷（如空位、施ottky缺陷、取代、间隙和Frenkel对）可以作为探测电子布洛克能带非平凡拓扑的通用探针。

Method: 通过在二维正方形晶格上实现描述时间反转对称性破坏的拓扑和普通绝缘体的最小模型哈密顿量，理论上建立了普通晶格缺陷作为拓扑探针的通用性。此外，还通过在二维声学陈氏晶格中嵌入普通晶格缺陷，并利用有源超原子精确控制的跳变振幅和基于格林函数的光谱学来重建光谱和本征态，从而展示了实验观察。

Result: 理论研究表明，普通晶格缺陷可以在其附近产生中隙束缚态，并且这些束缚态对弱点状电荷杂质具有鲁棒性。实验结果也证实了在声学陈氏晶格中存在这种束缚态。

Conclusion: 普通晶格缺陷是拓扑的通用探针，其普适性不依赖于晶体的对称性和维度。这项工作为在拓扑超导体的体中近邻普通晶格缺陷捕获局域Majorana模式以及模拟普通缺陷工程拓扑设备提供了可能性。

Abstract: In addition to topological lattice defects such as dislocations and disclinations, crystals are also accompanied by unavoidable ordinary defects, devoid of any non-trivial geometry or topology, among which vacancies, Schottky defects, substitutions, interstitials, and Frenkel pairs are the most common. In this work, we demonstrate that these ubiquitous ordinary lattice defects, though topologically trivial, can nonetheless serve as universal probes of the non-trivial topology of electronic Bloch bands, and any change in the local topological environment in an otherwise normal insulator in terms of mid-gap bound states in their vicinity. We theoretically establish these generic findings by implementing a minimal model Hamiltonian describing time-reversal symmetry breaking topological and normal insulators on a square lattice, fostering such point defects. The defect-bound mid-gap modes are also shown to be robust against weak point-like charge impurities. Furthermore, we showcase experimental observation of such bound states by embedding ordinary crystal defects in two-dimensional acoustic Chern lattices, where precision-controlled hopping amplitudes are implemented via active meta-atoms and Green's-function-based spectroscopy is used to reconstruct spectra and eigenstates. Our combined theory-experiment study establishes ordinary lattice defects as probes of topology that should be germane in crystals of any symmetry and dimension, raising the possibility of arresting localized Majorana modes near such defects in the bulk of topological superconductors and to emulate ordinary-defect-engineered topological devices.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [201] [Multi-agent In-context Coordination via Decentralized Memory Retrieval](https://arxiv.org/abs/2511.10030)
*Tao Jiang,Zichuan Lin,Lihe Li,Yi-Chen Li,Cong Guan,Lei Yuan,Zongzhang Zhang,Yang Yu,Deheng Ye*

Main category: cs.MA

TL;DR: MAICC是一种用于多智能体强化学习（MARL）的新方法，通过去中心化的记忆检索来增强协调和适应性，从而解决合作MARL中的任务对齐和奖励分配问题。


<details>
  <summary>Details</summary>
Motivation: 在合作式多智能体强化学习（MARL）中，去中心化策略部署会导致任务对齐和奖励分配不匹配，从而限制策略适应的效率。

Method: MAICC通过训练一个中心化的嵌入模型来捕捉细粒度的轨迹表示，然后由去中心化的模型进行近似，以获取团队层面的任务信息。基于学习到的嵌入，检索相关轨迹作为上下文，并结合智能体当前的子轨迹来指导决策。在去中心化执行过程中，引入了一种新的内存机制，平衡了测试时在线数据和离线记忆。基于构建的内存，提出了一种混合效用分数，结合了个人和团队层面的回报，确保了智能体之间的信用分配。

Result: 在Level-Based Foraging (LBF) 和 SMAC (v1/v2) 等合作式MARL基准测试上的广泛实验表明，与现有方法相比，MAICC能够更快地适应未见过的任务。

Conclusion: MAICC通过其新颖的记忆检索和混合效用评分机制，有效地解决了合作MARL中的协调和适应性挑战，并在多个基准测试中展示了优越的性能。

Abstract: Large transformer models, trained on diverse datasets, have demonstrated impressive few-shot performance on previously unseen tasks without requiring parameter updates. This capability has also been explored in Reinforcement Learning (RL), where agents interact with the environment to retrieve context and maximize cumulative rewards, showcasing strong adaptability in complex settings. However, in cooperative Multi-Agent Reinforcement Learning (MARL), where agents must coordinate toward a shared goal, decentralized policy deployment can lead to mismatches in task alignment and reward assignment, limiting the efficiency of policy adaptation. To address this challenge, we introduce Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach designed to enhance coordination by fast adaptation. Our method involves training a centralized embedding model to capture fine-grained trajectory representations, followed by decentralized models that approximate the centralized one to obtain team-level task information. Based on the learned embeddings, relevant trajectories are retrieved as context, which, combined with the agents' current sub-trajectories, inform decision-making. During decentralized execution, we introduce a novel memory mechanism that effectively balances test-time online data with offline memory. Based on the constructed memory, we propose a hybrid utility score that incorporates both individual- and team-level returns, ensuring credit assignment across agents. Extensive experiments on cooperative MARL benchmarks, including Level-Based Foraging (LBF) and SMAC (v1/v2), show that MAICC enables faster adaptation to unseen tasks compared to existing methods. Code is available at https://github.com/LAMDA-RL/MAICC.

</details>


### [202] [Behavior Modeling for Training-free Building of Private Domain Multi Agent System](https://arxiv.org/abs/2511.10283)
*Won Ik Cho,Woonghee Han,Kyung Seo Ki,Young Min Kim*

Main category: cs.MA

TL;DR: 提供一个无需训练即可将多代理对话系统应用于私有领域的框架，通过行为建模和文档化来处理异构工具和领域特定术语。


<details>
  <summary>Details</summary>
Motivation: 在私有领域应用现有的开放域多代理系统面临异构工具、领域特定术语、API访问限制和复杂治理等挑战。传统的微调方法成本高昂且在领域变化时效果不稳定。

Method: 提出一个无需训练和数据生成的框架，采用行为建模和文档化。框架包含一个协调器、一个工具调用代理和一个通用聊天代理。工具集成通过结构化规范和领域内指令定义。

Result: 该框架支持可扩展地适应私有工具和不断变化的上下文，而无需持续重新训练。它还支持多代理系统的轻量级部署、将API规范作为检索资源以及生成用于评估的合成对话。

Conclusion: 所提出的框架为私有领域的多代理对话系统提供了一种可持续的方法，通过行为建模和文档化，使代理行为与领域专业知识保持一致，而无需进行昂贵的训练或数据生成。

Abstract: The rise of agentic systems that combine orchestration, tool use, and conversational capabilities, has been more visible by the recent advent of large language models (LLMs). While open-domain frameworks exist, applying them in private domains remains difficult due to heterogeneous tool formats, domain-specific jargon, restricted accessibility of APIs, and complex governance. Conventional solutions, such as fine-tuning on synthetic dialogue data, are burdensome and brittle under domain shifts, and risk degrading general performance. In this light, we introduce a framework for private-domain multi-agent conversational systems that avoids training and data generation by adopting behavior modeling and documentation. Our design simply assumes an orchestrator, a tool-calling agent, and a general chat agent, with tool integration defined through structured specifications and domain-informed instructions. This approach enables scalable adaptation to private tools and evolving contexts without continual retraining. The framework supports practical use cases, including lightweight deployment of multi-agent systems, leveraging API specifications as retrieval resources, and generating synthetic dialogue for evaluation -- providing a sustainable method for aligning agent behavior with domain expertise in private conversational ecosystems.

</details>


### [203] [Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance](https://arxiv.org/abs/2511.10400)
*Lifan Zheng,Jiawei Chen,Qinghong Yin,Jingyuan Zhang,Xinyi Zeng,Yu Tian*

Main category: cs.MA

TL;DR: LLM驱动的代理在拜占庭容错方面优于传统代理，并且提出了一种新的CP-WBFT共识机制来提高其在MAS中的稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在多主体系统（MAS）中，确保代理架构的可靠性以及在发生故障时有效识别出问题代理是关键挑战。虽然基于LLM的代理在解决复杂问题和世界建模方面取得了重大突破，但其在可靠性方面的影响仍未得到充分探索，特别是用LLM代理替代传统代理是否能有效提高MAS的可靠性。

Method: 研究和量化了LLM代理从拜占庭容错的角度来看的可靠性。设计了一种基于置信探针的加权拜占庭容错共识机制（CP-WBFT），利用LLM内在的区分能力，通过基于探针的加权信息流传输方法来提高LLM代理的可靠性。

Result: LLM代理在处理错误消息流时表现出更强的怀疑性，优于传统代理。CP-WBFT在各种网络拓扑和高故障率（85.7%）下表现优越，在数学推理和安全评估任务中均达到显著的准确性和可靠性。

Conclusion: LLM代理在拜占庭容错方面展现出潜力，并且提出的CP-WBFT共识机制能够有效提升MAS的稳定性和可靠性，尤其是在复杂的网络拓扑和高故障率场景下。

Abstract: Ensuring the reliability of agent architectures and effectively identifying problematic agents when failures occur are crucial challenges in multi-agent systems (MAS). Advances in large language models (LLMs) have established LLM-based agents as a major branch of MAS, enabling major breakthroughs in complex problem solving and world modeling. However, the reliability implications of this shift remain largely unexplored. i.e., whether substituting traditional agents with LLM-based agents can effectively enhance the reliability of MAS. In this work, we investigate and quantify the reliability of LLM-based agents from the perspective of Byzantine fault tolerance. We observe that LLM-based agents demonstrate stronger skepticism when processing erroneous message flows, a characteristic that enables them to outperform traditional agents across different topological structures. Motivated by the results of the pilot experiment, we design CP-WBFT, a confidence probe-based weighted Byzantine Fault Tolerant consensus mechanism to enhance the stability of MAS with different topologies. It capitalizes on the intrinsic reflective and discriminative capabilities of LLMs by employing a probe-based, weighted information flow transmission method to improve the reliability of LLM-based agents. Extensive experiments demonstrate that CP-WBFT achieves superior performance across diverse network topologies under extreme Byzantine conditions (85.7\% fault rate). Notably, our approach surpasses traditional methods by attaining remarkable accuracy on various topologies and maintaining strong reliability in both mathematical reasoning and safety assessment tasks.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [204] [A Quasi-Polynomial Time Algorithm for 3-Coloring Circle Graphs](https://arxiv.org/abs/2511.09707)
*Ajaykrishnan E S,Robert Ganian,Daniel Lokshtanov,Vaishali Surianarayanan*

Main category: cs.DS

TL;DR: This paper presents an algorithm for 3-coloring circle graphs in $n^{O(	ext{log } n)}$ time, which also aids in determining 3-page book embeddability for ordered graphs.


<details>
  <summary>Details</summary>
Motivation: To address the open problem of whether 3-coloring on circle graphs can be solved in polynomial time.

Method: An algorithm is developed that takes a circle graph with $n$ vertices and finds a proper 3-coloring if one exists, with a running time of at most $n^{O(	ext{log } n)}$.

Result: The algorithm successfully finds a proper 3-coloring for circle graphs within the specified time complexity.

Conclusion: The paper provides a partial resolution to a long-standing open problem in graph theory regarding the polynomial-time solvability of 3-coloring for circle graphs.

Abstract: A graph $G$ is a circle graph if it is an intersection graph of chords of a unit circle. We give an algorithm that takes as input an $n$ vertex circle graph $G$, runs in time at most $n^{O(\log n)}$ and finds a proper $3$-coloring of $G$, if one exists. As a consequence we obtain an algorithm with the same running time to determine whether a given ordered graph $(G, \prec)$ has a $3$-page book embedding. This gives a partial resolution to the well known open problem of Dujmović and Wood [Discret. Math. Theor. Comput. Sci. 2004], Eppstein [2014], and Bachmann, Rutter and Stumpf [J. Graph Algorithms Appl. 2024] of whether 3-Coloring on circle graphs admits a polynomial time algorithm.

</details>


### [205] [Hardness of Dynamic Tree Edit Distance and Friends](https://arxiv.org/abs/2511.09842)
*Bingbing Hu,Jakob Nogler,Barna Saha*

Main category: cs.DS

TL;DR: 动态字符串编辑距离有优化算法，但动态树编辑距离、Dyck编辑距离和RNA折叠问题没有。动态树编辑距离在每次更新后需要重新计算，对于无权树编辑距离，更新成本甚至可能是二次的。


<details>
  <summary>Details</summary>
Motivation: 研究动态字符串编辑距离的已有优化算法，并探讨与之相关的动态树编辑距离、Dyck编辑距离和RNA折叠问题是否存在类似的动态优化算法。

Method: 通过证明动态树编辑距离、Dyck编辑距离和RNA折叠问题没有动态加速，即在每次更新后都需要从头开始重新计算。此外，在k-Clique猜想下，证明了无权树编辑距离的更新成本至少是二次的。

Result: 动态树编辑距离、Dyck编辑距离和RNA折叠问题没有动态加速。无权树编辑距离的更新成本是二次的。

Conclusion: 与动态字符串编辑距离不同，动态树编辑距离（以及Dyck编辑距离和RNA折叠）无法实现动态加速，其更新成本较高，与静态算法相当。

Abstract: String Edit Distance is a more-than-classical problem whose behavior in the dynamic setting, where the strings are updated over time, is well understood. A single character substitution, insertion, or deletion can be handled in $\tilde{\mathcal{O}}(n \cdot \min(\sqrt{n},w))$ time [Charalampopoulos, Kociumaka, Mozes, CPM 2020], where $w$ is the maximum operation weight. This bound is optimal [Cassis, Kociumaka, Wellnitz, FOCS 2023] and provides a substantial improvement over the static $\mathcal{O}(n^2)$ algorithm when few characters of the input string are updated.
  In contrast, for inherently related problems such as Tree Edit Distance, Dyck Edit Distance, and RNA Folding, it has remained unknown whether it is possible to devise dynamic algorithms with an advantage over the static algorithm. In this paper, we resolve this question by showing that (weighted) Tree Edit Distance, Dyck Edit Distance, and RNA Folding admit no dynamic speedup: under well-known fine-grained assumptions we show that the best possible algorithm recomputes the solution from scratch after each update. Furthermore, we prove a quadratic per-update lower bound for unweighted Tree Edit Distance under the $k$-Clique Conjecture. This provides the first separation between dynamic unweighted String Edit Distance and unweighted Tree Edit Distance, problems whose relative difficulty in the static setting is still open.

</details>


### [206] [Faster All-Pairs Minimum Cut: Bypassing Exact Max-Flow](https://arxiv.org/abs/2511.10036)
*Yotam Kenneth-Mordoch,Robert Krauthgamer*

Main category: cs.DS

TL;DR: 该论文提出了一种新的图稀疏化方法，用于解决所有顶点对之间的最小割（APMC）问题。该方法能够保留图中所有的最小割，并且可以使用近似最大流计算来构建。基于此稀疏化方法，论文在多种计算模型下提出了新的APMC算法，包括用于割查询模型、完全动态模型以及随机化双通道流模型的算法，并在这些模型下取得了比现有算法更好的边界。


<details>
  <summary>Details</summary>
Motivation: APMC是图论中的一个基本问题，旨在为每对顶点找到最小割。虽然已有进展将APMC简化为少量的最大流计算，但在某些标准计算模型（如割查询模型和完全动态模型）中，尚未发现高效的最大流算法。

Method: 提出了一种能够保留图中所有最小割的稀疏化方法，并且该方法可以通过近似最大流计算来构建。在此基础上，设计了针对无权图的APMC算法，适用于割查询模型、完全动态模型和随机化双通道流模型。

Result: （i）在割查询模型下，提出了一种随机化算法，需要进行~O(n^{3/2})次割查询。（ii）在完全动态模型下，提出了一种确定性算法，具有n^{3/2+o(1)}的最坏情况更新时间。（iii）在随机化双通道流模型下，提出了一种空间复杂度为~O(n^{3/2})的算法。

Conclusion: 所提出的稀疏化方法和基于该方法的APMC算法在割查询模型、完全动态模型和随机化双通道流模型下都取得了优于现有算法的边界，甚至对于单对最小割问题也提供了改进。

Abstract: All-Pairs Minimum Cut (APMC) is a fundamental graph problem that asks to find a minimum $s,t$-cut for every pair of vertices $s,t$. A recent line of work on fast algorithms for APMC has culminated with a reduction of APMC to $\mathrm{polylog}(n)$-many max-flow computations. But unfortunately, no fast algorithms are currently known for exact max-flow in several standard models of computation, such as the cut-query model and the fully-dynamic model.
  Our main technical contribution is a sparsifier that preserves all minimum $s,t$-cuts in an unweighted graph, and can be constructed using only approximate max-flow computations. We then use this sparsifier to devise new algorithms for APMC in unweighted graphs in several computational models: (i) a randomized algorithm that makes $\tilde{O}(n^{3/2})$ cut queries to the input graph; (ii) a deterministic fully-dynamic algorithm with $n^{3/2+o(1)}$ worst-case update time; and (iii) a randomized two-pass streaming algorithm with space requirement $\tilde{O}(n^{3/2})$. These results improve over the known bounds, even for (single pair) minimum $s,t$-cut in the respective models.

</details>


### [207] [Algorithms and Complexity of Hedge Cluster Deletion Problems](https://arxiv.org/abs/2511.10202)
*Athanasios L. Konstantinidis,Charis Papadopoulos,Georgios Velissaris*

Main category: cs.DS

TL;DR: 该论文提出了一个名为“ Hedge Cluster Deletion ”的新问题，并研究了其计算复杂性和近似性。


<details>
  <summary>Details</summary>
Motivation: 研究 Hedge Cluster Deletion 问题的计算复杂性，并探索其近似算法。

Method: 1. 证明对于包含有界大小的 vertex-disjoint 3-vertex-paths 的图，Hedge Cluster Deletion 问题可以在多项式时间内解决。 2. 证明 Hedge Cluster Deletion 问题与 Min Horn Deletion 问题密切相关，并给出了近似难度的下界。 3. 针对输入图中每个三角形被至多两个 hedge 覆盖的情况，给出了具有常数近似比的多项式时间算法。 4. 提出 hedge intersection graph 的概念，并给出了当 hedge intersection graph 为有向无环图时，Hedge Cluster Deletion 的多项式时间算法。

Result: 1. 找到了一种在特定图结构下解决 Hedge Cluster Deletion 的多项式时间算法。 2. 证明了 Hedge Cluster Deletion 问题的近似难度。 3. 提出了一种在特定条件下（三角形被至多两个 hedge 覆盖）具有常数近似比的多项式时间算法。 4. 提出了一种在 hedge intersection graph 为有向无环图时的多项式时间算法。

Conclusion: Hedge Cluster Deletion 问题在特定图结构下可以有效解决，并且其近似性与 Min Horn Deletion 问题相关。论文还提出了一些近似算法和启发式方法来处理更一般的情况。

Abstract: A hedge graph is a graph whose edge set has been partitioned into groups called hedges. Here we consider a generalization of the well-known \textsc{Cluster Deletion} problem, named \textsc{Hedge Cluster Deletion}. The task is to compute the minimum number of hedges of a hedge graph so that their removal results in a graph that is isomorphic to a disjoint union of cliques. We show that for graphs that contain bounded size of vertex-disjoint 3-vertex-paths as subgraphs, \textsc{Hedge Cluster Deletion} can be solved in polynomial time. Regarding its approximability, we prove that the problem is tightly connected to the related complexity of the \textsc{Min Horn Deletion} problem, a well-known boolean CSP problem. Our connection shows that it is NP-hard to approximate \textsc{Hedge Cluster Deletion} within factor $2^{O(\log^{1-ε} r)}$ for any $ε>0$, where $r$ is the number of hedges in a given hedge graph.
  Based on its classified (in)approximability and the difficulty imposed by the structure of almost all non-trivial graphs, we consider the hedge underlying structure. We give a polynomial-time algorithm with constant approximation ratio for \textsc{Hedge Cluster Deletion} whenever each triangle of the input graph is covered by at most two hedges. On the way to this result, an interesting ingredient that we solved efficiently is a variant of the \textsc{Vertex Cover} problem in which apart from the desired vertex set that covers the edge set, a given set of vertex-constraints should also be included in the solution. Moreover, as a possible workaround for the existence of efficient exact algorithms, we propose the hedge intersection graph which is the intersection graph spanned by the hedges. Towards this direction, we give a polynomial-time algorithm for \textsc{Hedge Cluster Deletion} whenever the hedge intersection graph is acyclic.

</details>


### [208] [Testing H-freeness on sparse graphs, the case of bounded expansion](https://arxiv.org/abs/2511.10230)
*Samuel Humeau,Mamadou Moustapha Kanté,Daniel Mock,Timothé Picavet,Alexandre Vigny*

Main category: cs.DS

TL;DR: 对于具有有界扩张的图类，可以使用常数次查询来测试 H- 自由性。


<details>
  <summary>Details</summary>
Motivation: 在图属性测试领域，特别是对于稀疏图，H- 自由性的常数查询测试仍然是一个具有挑战性的问题。虽然 Czumaj 和 Sohler (FOCS'19) 在平面图和排除子图的图类上取得了进展，但仍有改进的空间。

Method: 本文提出了一种更简单的证明方法，利用了稀疏性工具箱中的结果，并将 Czumaj 和 Sohler 的证明推广到了有界扩张图类。

Result: 证明了对于任何具有有界扩张的图类 C 和任何图 H，在 C 类中的任意图 G 上测试 H- 自由性都可以用常数次查询完成，该常数取决于 H 和 C，而与 G 无关。

Conclusion: 本文为有界扩张图类上的 H- 自由性测试提供了一个更简洁的常数查询算法，该算法比现有方法更具一般性，并适用于更广泛的图类，如立方体图、有界最大度图类、有界书册厚度图类或有界平均度随机图。

Abstract: In property testing, a tester makes queries to (an oracle for) a graph and, on a graph having or being far from having a property P, it decides with high probability whether the graph satisfies P or not. Often, testers are restricted to a constant number of queries. While the graph properties for which there exists such a tester are somewhat well characterized in the dense graph model, it is not the case for sparse graphs. In this area, Czumaj and Sohler (FOCS'19) proved that H-freeness (i.e. the property of excluding the graph H as a subgraph) can be tested with constant queries on planar graphs as well as on graph classes excluding a minor.
  Using results from the sparsity toolkit, we propose a simpler alternative to the proof of Czumaj and Sohler, for a statement generalized to the broader notion of bounded expansion. That is, we prove that for any class C with bounded expansion and any graph H, testing H-freeness can be done with constant query complexity on any graph G in C, where the constant depends on H and C, but is independent of G.
  While classes excluding a minor are prime examples of classes with bounded expansion, so are, for example, cubic graphs, graph classes with bounded maximum degree, graphs of bounded book thickness, or random graphs of bounded average degree.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [209] [QuCoWE Quantum Contrastive Word Embeddings with Variational Circuits for NearTerm Quantum Devices](https://arxiv.org/abs/2511.10179)
*Rabimba Karanjai,Hemanth Hegadehalli Madhavarao,Lei Xu,Weidong Shi*

Main category: quant-ph

TL;DR: QuCoWE是一个学习量子原生词嵌入的框架，通过训练参数化量子电路（PQCs）和对比损失函数来实现。它使用数据重构电路编码单词，通过量子态保真度计算相似度，并引入了一个基于单量子比特纯度的正则化器来解决训练难题。在Text8和WikiText2数据集上，QuCoWE在多种评估指标上均表现优于经典基线，并且参数量更少。实验在经典模拟器中进行，并考虑了噪声和错误缓解技术，为在实际量子硬件上部署做准备。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一种能够学习量子原生词嵌入的框架，以期在量子计算环境中实现更高效的自然语言处理任务。

Method: 研究提出了一种名为QuCoWE的框架，该框架通过训练浅层、硬件高效的参数化量子电路（PQCs）来学习词嵌入。具体方法包括：使用数据重构电路对单词进行编码；利用量子态保真度来计算词语之间的相似度；引入一个基于单量子比特纯度的“纠缠预算”正则化器，以缓解训练过程中“不毛平原”问题；并采用噪声对比估计（NCE）损失函数。

Result: 在Text8和WikiText2数据集上的实验结果表明，QuCoWE在单词相似度（WordSim353, SimLex999）和下游任务（SST2, TREC6）的评估中，性能与50-100维度的经典基线相当，但使用的每个词元的学习参数更少。此外，实验还分析了去极化读出噪声的影响，并包含了零噪声外推和随机编译等错误缓解和纠错技术，为实际量子硬件部署奠定了基础。

Conclusion: QuCoWE框架能够学习到性能优越的量子原生词嵌入，并且在参数效率和潜在的量子硬件兼容性方面优于传统的经典方法。该研究为在量子计算机上进行自然语言处理任务提供了一个有前景的解决方案。

Abstract: We present QuCoWE a framework that learns quantumnative word embeddings by training shallow hardwareefficient parameterized quantum circuits PQCs with a contrastive skipgram objective Words are encoded by datareuploading circuits with controlled ring entanglement similarity is computed via quantum state fidelity and passed through a logitfidelity head that aligns scores with the shiftedPMI scale of SGNSNoiseContrastive Estimation To maintain trainability we introduce an entanglementbudget regularizer based on singlequbit purity that mitigates barren plateaus On Text8 and WikiText2 QuCoWE attains competitive intrinsic WordSim353 SimLex999 and extrinsic SST2 TREC6 performance versus 50100d classical baselines while using fewer learned parameters per token All experiments are run in classical simulation we analyze depolarizingreadout noise and include errormitigation hooks zeronoise extrapolation randomized compiling to facilitate hardware deployment

</details>


### [210] [Fermi-Dirac Wigner function for massive spin-1/2 particles in local equilibrium](https://arxiv.org/abs/2511.09580)
*Sudip Kumar Kar,Valeriya Mykhaylova*

Main category: quant-ph

TL;DR: 该论文将玻尔兹曼局域平衡维格纳函数推广到费米-狄拉克统计，并展示了其在宏观电流计算和热力学关系中的应用。


<details>
  <summary>Details</summary>
Motivation: 将现有的玻尔兹曼局域平衡维格纳函数推广到费米-狄拉克统计，以处理费米子系统，并研究其宏观性质。

Method: 对玻尔兹曼局域平衡维格纳函数进行推广，使其适用于费米-狄拉克统计。推导了宏观电流的计算方法，并通过生成函数与拉格朗日乘子（温度、流速、化学势）的关系，将其归类为散度型理论。

Result: 得到了适用于费米-狄拉克统计的维格纳函数。证明了从该函数得到的宏观电流是生成函数关于拉格朗日乘子的导数。该生成函数表明该框架属于散度型理论。

Conclusion: 提出的费米-狄拉克维格纳函数能够正确处理费米子系统的热力学性质和宏观电流，并为进一步研究提供了理论框架。

Abstract: A recently proposed Boltzmann local equilibrium Wigner function for massive spin-1/2 particles is generalized to the case of Fermi-Dirac statistics. The resulting formula ensures the correct normalization of the mean polarization vector and reproduces the generalized thermodynamic relations with spin that were obtained in earlier studies. Moreover, we show that the macroscopic currents constructed from the Fermi-Dirac Wigner function can be obtained as derivatives of a suitably defined generating function with respect to the Lagrange multipliers (temperature, hydrodynamic flow, and chemical potentials). The identified generating function also indicates that the underlying framework can be classified as a divergence-type theory.

</details>


### [211] [Quantum Frustration as a Protection Mechanism in Non-Topological Majorana Qubits](https://arxiv.org/abs/2511.09591)
*E. Novais*

Main category: quant-ph

TL;DR: This paper analyzes the decoherence of a π-junction qubit encoded by Majorana modes. It finds that quantum frustration can protect against Ohmic and sub-Ohmic noise, but is insufficient against 1/f noise, leading to catastrophic decoherence. The qubit's viability depends on the environmental noise characteristics.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to analyze the decoherence of a π-junction qubit encoded by two co-located Majorana modes, and to understand the effectiveness of quantum frustration in protecting this qubit against various types of environmental noise, particularly quasiparticle poisoning.

Method: The paper analyzes the decoherence of a π-junction qubit encoded by two co-located Majorana modes. It models the qubit's interaction with two independent environmental baths, inducing quantum frustration. This mechanism is then tested against quasiparticle poisoning and different types of noise, including Ohmic noise (s=1), sub-Ohmic noise (0.76<s<1), and 1/f noise (s→0).

Result: The analysis shows that quantum frustration is effective against Ohmic noise (s=1) and offers some protection against sub-Ohmic noise (0.76<s<1). However, it is insufficient against 1/f noise (s→0), which falls within the model's localized phase, leading to Spontaneous Symmetry Breaking and catastrophic decoherence.

Conclusion: The conclusion is that the viability of the π-junction qubit depends on the nature of the effective environment that the local Majorana wave functions experience. While quantum frustration provides protection against certain types of noise, it fails against 1/f noise, a common experimental challenge. Therefore, understanding and mitigating the effects of 1/f noise is crucial for the practical application of this qubit design.

Abstract: I analyze the decoherence of a $π$-junction qubit encoded by two co-located Majorana modes. Although not topologically protected, the qubit leverages distinct spatial profiles to couple to two independent environmental baths, realizing the phenomenon of quantum frustration.This mechanism is tested against the threat of quasiparticle poisoning (QP). I show that frustration is effective against Ohmic noise ($s=1$) and has some protection for $0.76<s<1$ sub-Ohmic noise. However, the experimentally prevalent $1/f$ noise ($s\to0$) falls deep within the model's localized phase, where frustration is insufficient. This causes Spontaneous Symmetry Breaking and catastrophic decoherence. The qubit's viability depends on what is the effective environment that these local Majorana wave functions experience.

</details>


### [212] [Cooling the Sachdev-Ye-Kitaev model using thermofield double states](https://arxiv.org/abs/2511.09620)
*Thomas Schuster,Bryce Kobrin,Vincent P. Su,Hugo Marrochio,Norman Y. Yao*

Main category: quant-ph

TL;DR: 通过利用SYK模型的局部耦合，提出了一种简单有效的实验方案，可以高效地将SYK模型冷却到低温，并为更广泛的强相互作用量子哈密顿量冷却提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 提出了一种简单有效的实验方案，用于将SYK模型冷却到低温。

Method: 通过局部耦合两个SYK模型副本，创建一条从高温乘积态到低温热场双态的绝热路径，并利用精确的数值解来支持该方案。

Result: 证明了通过该方案可以高效冷却SYK模型，并快速冷却到低温引力区域。

Conclusion: 提出了一种基于本征生态热化的理论框架，为冷却方案的有效性提供了微观解释，并暗示该方案可用于冷却更广泛的强相互作用量子哈密顿量。

Abstract: We analyze a simple and efficient experimental protocol to cool the Sachdev-Ye-Kitaev (SYK) model to low temperatures. The protocol utilizes local couplings between two copies of an SYK model to create a gapped adiabatic path, between a high temperature product state and a low temperature thermofield double state. By smoothly varying the coupling strength between these two limits, one efficiently cools the SYK model. We support these predictions-and demonstrate fast cooling to the low-temperature gravitational regime-via exact numerical solutions to the large-N equations of motion that govern the ground state and dynamical properties of the coupled system. Finally, we present a theoretical framework based upon eigenstate thermalization that provides a microscopic explanation for the efficacy of the cooling protocol; intriguingly, this suggests that the protocol may be applicable for cooling strongly-interacting quantum Hamiltonians more broadly.

</details>


### [213] [Temporal quantum interference in many-body programmable atom arrays](https://arxiv.org/abs/2511.09633)
*Madhumita Sarkar,Ben Zindorf,Bhaskar Mukherjee,Sougato Bose,Roopayan Ghosh*

Main category: quant-ph

TL;DR: 研究人员在可编程的里德堡原子阵列中，通过操纵多体斯图克尔伯格干涉，实现了高达100个原子的真空态冻结，干涉可见度超过70%，激发抑制到1%，证明了时间干涉作为一种可扩展的微观机制在量子控制中的潜力。


<details>
  <summary>Details</summary>
Motivation: 以往对量子叠加的研究主要集中在空间干涉，如双缝实验，而对其时间类似物——斯图克尔伯格干涉的研究较少，尤其是在多体相互作用系统中。该研究旨在探索并实现多体斯图克尔伯格干涉在可控量子系统中的应用，克服多体相互作用对精细相位关系的破坏。

Method: 通过实验，在多达100个原子的可编程里德堡原子阵列中，利用多体斯图克尔伯格干涉实现真空态冻结。研究人员采用了单频和双频协议，并比较了不同几何结构下的干涉效果。他们通过同时调制失谐和拉比频率来增强干涉驱动的冻结，并分析了有限相互作用尾的决定性作用，以及受限的PXP模型无法捕捉的干涉模式。

Result: 实现了真空态冻结，干涉可见度超过70%，激发抑制到1%。研究表明，同时调制失谐和拉比频率能显著增强干涉驱动的冻结，并且有限相互作用尾在产生干涉模式中起到关键作用。发现受限的PXP模型无法解释实验结果。

Conclusion: 多体斯图克尔伯格干涉是一种可扩展的微观机制，可用于实现非平衡态系统的精确控制。该研究为在大型平台上进行量子态工程提供了新的途径，能够预测和实现特定的多体量子态。

Abstract: Quantum superposition famously manifests as spatial interference, epitomized by the double-slit experiment. Its less explored temporal analogue, Stückelberg interference, arises in driven systems where phases accumulated along distinct time-domain pathways recombine. Extending this phenomenon to large interacting systems introduces a new complexity as delicate phase relationships are disrupted by many-body interactions. Here we experimentally achieve controllable vacuum-state freezing in programmable Rydberg arrays of up to 100 atoms through many-body Stückelberg interference, with visibility exceeding $70\%$ and excitation suppression to $1\%$ despite periodic driving that would typically induce heating. Comparing single and dual-frequency protocols across multiple geometries, we show that simultaneous modulation of detuning and Rabi frequency dramatically enhances interference-driven freezing. Finite-range interaction tails play a decisive role, producing interference patterns which constrained $PXP$ models cannot capture. Our results establish temporal interference as a scalable microscopic mechanism for Floquet control, enabling predictive many-body state engineering in large-scale platforms.

</details>


### [214] [A measurement-driven quantum algorithm for SAT: Performance guarantees via spectral gaps and measurement parallelization](https://arxiv.org/abs/2511.09647)
*Franz J. Schreiber,Maximilian J. Kramer,Alexander Nietner,Jens Eisert*

Main category: quant-ph

TL;DR: 本论文分析了一种新的测量驱动的量子SAT求解器的最坏情况运行时间，该求解器不依赖于Grover类型的方法，并显示出有前景的数值性能。


<details>
  <summary>Details</summary>
Motivation: 为了寻找超越二次加速的方法，本研究对一种新的测量驱动的量子SAT求解器进行了严格的最坏情况运行时间分析。

Method: 通过分析与Hamiltonian的谱隙和驱动测量的成功概率相关的指数权衡，并展示了该权衡可以通过可调谐的旋转角度进行控制。此外，还开发了一种新的读出例程、一种基于完美哈希族的测量并行化方案，并建立了一种测量驱动算法的幅度放大版本。

Result: 该算法的运行时间与Hamiltonian的谱隙和驱动测量的成功概率之间存在指数权衡。通过调整旋转角度可以控制这种权衡。通过适当调度算法参数，其运行时间可以从指数级变为多项式级。

Conclusion: 本研究为测量驱动的量子SAT求解器提供了最坏情况运行时间分析，并提出了改进的算法。通过调整参数，该算法在特定类别的SAT实例上的运行时间可以从指数级减少到多项式级。一个悬而未决的问题是确定谱隙关于旋转角度的非平凡下界，这将可能实现超二次量子优势。

Abstract: The Boolean satisfiability problem (SAT) is of central importance in both theory and practice. Yet, most provable guarantees for quantum algorithms rely exclusively on Grover-type methods that cap the possible advantage at only quadratic speed-ups, making the search for approaches that surpass this quadratic barrier a key challenge. In this light, this work presents a rigorous worst-case runtime analysis of a recently introduced measurement-driven quantum SAT solver. Importantly, this quantum algorithm does not exclusively rely on Grover-type methods and shows promising numerical performance. Our analysis establishes that the algorithm's runtime depends on an exponential trade-off between two key properties: the spectral gap of the associated Hamiltonian and the success probability of the driving measurements. We show that this trade-off can be systematically controlled by a tunable rotation angle. Beyond establishing a worst-case runtime expression, this work contributes significant algorithmic improvements. First, we develop a new readout routine that efficiently finds a solution even for instances with multiple satisfying assignments. Second, a measurement parallelization scheme, based on perfect hash families, is introduced. Third, we establish an amplitude-amplified version of the measurement-driven algorithm. Finally, we demonstrate the practical utility of our framework: By suitably scheduling the algorithm's parameters, we show that its runtime collapses from exponential to polynomial on a special class of SAT instances, consistent with their known classical tractability. A problem we leave open is to establish a non-trivial lower bound on the spectral gap as a function of the rotation angle. Resolving this directly translates into an improved worst-case runtime, potentially realizing a super-quadratic quantum advantage.

</details>


### [215] [Non-abelian Geometric Quantum Energy Pump](https://arxiv.org/abs/2511.09651)
*Yang Peng*

Main category: quant-ph

TL;DR: 提出了一种由无绝热几何量子驱动实现的非阿贝尔几何量子能量泵，通过时间依赖的哈密顿量和反绝热项相干地传输简并子空间内的态。


<details>
  <summary>Details</summary>
Motivation: 在简并子空间内相干地传输态，并利用非阿贝尔几何量子驱动实现能量泵。

Method: 利用时间依赖的哈密顿量和反绝热项（由光滑控制流形上的预定轨迹生成）实现无绝热几何量子驱动，并通过外部驱动独立寻址轨迹坐标来控制能量转移。

Result: 非阿贝尔 Berry-曲率张量决定了驱动器之间的净能量转移。轨迹平均泵浦功率受初始状态和哈密顿量拓扑（通过欧拉类）的控制。

Conclusion: 提出的能量泵可作为量子换能器、充电器或测量量子态相位相干性的计量工具，并概述了使用人工原子的实现方案。

Abstract: We introduce a non-abelian geometric quantum energy pump realized by a transitionless geometric quantum drive--a time-dependent Hamiltonian supplemented by a counterdiabatic term generated by a prescribed trajectory on a smooth control manifold--that coherently transports states within a degenerate subspace. When the coordinates of the trajectory are independently addressable by external drives, the net energy transferred between drives is set by the non-abelian Berry-curvature tensor. The trajectory-averaged pumping power is separately controlled by the initial state and by the Hamiltonian topology through the Euler class. We outline an implementation with artificial atoms, which are realizable on various platforms including trapped atoms/ions, superconducting circuits, and semiconductor quantum dots. The resulting energy pump can serve as a quantum transducer or charger, and as a metrological tool for measuring phase coherences in quantum states.

</details>


### [216] [Optimal Interpolation of Entanglement Purification Protocols](https://arxiv.org/abs/2511.09657)
*Matthew Barber,Stefano Pirandola*

Main category: quant-ph

TL;DR: 通过在不同纠缠纯化协议之间进行概率性选择，可以实现优于任何单一协议的纠缠对生成速率和保真度。


<details>
  <summary>Details</summary>
Motivation: 纠缠纯化协议的选择通常在生成速率和输出纠缠质量之间进行权衡，本研究旨在解决这一权衡问题。

Method: 提出了一种通过根据概率分布随机选择协议来优化纠缠纯化过程的方法，并推导了最优的概率分布，以在给定保真度下最大化生成速率，或在给定生成速率下最大化保真度。研究了渐进情况和有限样本情况。

Result: 找到了最优的概率分布，该分布可以实现比任何单一协议都高的纠缠对生成速率和保真度。

Conclusion: 通过概率性地选择纠缠纯化协议，可以克服现有协议的局限性，实现更高的性能。

Abstract: Bipartite entanglement purification is the conversion of copies of weakly entangled pairs shared between two separated parties into a smaller number of strongly entangled shared pairs using only local operations and classical communication. Choosing between different entanglement purification protocols generally involves weighing up a trade-off between the ratio of strongly entangled pairs produced to weakly entangled pairs consumed, which we call the rate of the protocol, and the degree of the entanglement of the strongly entangled pairs, typically measured by the fidelity of those pairs to maximally entangled states. By randomly choosing a protocol according to a probability distribution over a list of protocols for each pair we want to produce, we can achieve rates and fidelities not achieved by any of the original protocols. Here, we show how to choose this distribution to maximise the rate at which we produce qubit pairs with a given fidelity to a Bell state or, equivalently, to maximise the fidelity to a Bell state of the qubit pairs produced at a given rate. We investigate both the asymptotic case, where the number of initial pairs goes to infinity, and the finite-size regime, where protocols are restricted to a finite number of weakly entangled pairs.

</details>


### [217] [Cyclic Hypergraph Product Code](https://arxiv.org/abs/2511.09683)
*Arda Aydin,Nicolas Delfosse,Edwin Tham*

Main category: quant-ph

TL;DR: 该研究介绍了超图乘积 (HGP) 量子LDPC码的新变体，称为CxC码和CxR码，它们通过引入全局对称性和进行穷举搜索，在性能上显著优于现有的HGP码，实现了更低的逻辑错误率和更小的量子比特开销，并提出了一种适用于量子比特-量子比特经典通信 (QCCD) 架构的平面布局，可实现恒定深度的陷阱离子实现。


<details>
  <summary>Details</summary>
Motivation: 与表面码相比，超图乘积 (HGP) 量子 LDPC 码在量子比特开销方面具有优势，并且已经通过多种技术进行了优化。然而，现有方法主要侧重于局部改进，而忽略了全局对称性的潜力。

Method: 研究重点关注两种超图乘积码：CxC 码（两个循环码的乘积）和 CxR 码（循环码与重复码的乘积）。通过强制引入难以通过机器学习发现的全局对称性，并结合穷举搜索，对这些码进行了探索和优化。

Result: 新发现的 CxC 码和 CxR 码在性能上显著优于先前的 HGP 码，逻辑错误率比之前最优的 HGP 码低三个数量级。一些 C2 码同时实现了比最先进的双变量自行车码更低的逻辑错误率和更小的量子比特开销，但需要更长的码长。此外，还设计了一种高效的平面布局，适用于 QCCD 架构。

Conclusion: 通过引入全局对称性进行穷举搜索，可以发现比现有基于机器学习的局部优化方法性能更优越的超图乘积量子 LDPC 码。所提出的 CxC 码和 CxR 码在逻辑错误率和量子比特开销方面取得了显著改进，并且所设计的 QCCD 架构平面布局为陷阱离子量子计算机的实现提供了有效方案。

Abstract: Hypergraph product (HGP) codes are one of the most popular family of quantum low-density parity-check (LDPC) codes. Circuit-level simulations show that they can achieve the same logical error rate as surface codes with a reduced qubit overhead. They have been extensively optimized by importing classical techniques such as the progressive edge growth, or through random search, simulated annealing or reinforcement learning techniques. In this work, instead of machine learning (ML) algorithms that improve the code performance through local transformations, we impose additional global symmetries, that are hard to discover through ML, and we perform an exhaustive search. Precisely, we focus on the hypergraph product of two cyclic codes, which we call CxC codes and we study C2 codes which are the product a cyclic code with itself and CxR codes which are the product of a cyclic codes with a repetition code. We discover C2 codes and CxR codes that significantly outperform previously optimized HGP codes, achieving better parameters and a logical error rate per logical qubit that is up to three orders of magnitude better. Moreover, some C2 codes achieve simultaneously a lower logical error rate and a smaller qubit overhead than state-of-the-art LDPC codes such as the bivariate bicycle codes, at the price of a larger block length. Finally, leveraging the cyclic symmetry imposed on the codes, we design an efficient planar layout for the QCCD architecture, allowing for a trapped ion implementation of the syndrome extraction circuit in constant depth.

</details>


### [218] [Trotterized Variational Quantum Control for Spin-Chain State Transfer](https://arxiv.org/abs/2511.09684)
*Nahid Binandeh Dehaghani,Rafal Wisniewski,A. Pedro Aguiar*

Main category: quant-ph

TL;DR: 本论文提出了一种混合变分框架用于量子最优控制，旨在实现自旋链中高保真度的状态转移。该框架将系统动力学离散化并编译为参数化电路，其中确定性的两比特门实现漂移相互作用，而可训练的单比特RZ旋转编码控制输入。研究了两种参数化方案：一种是具有少量共享参数的紧凑全局方案，另一种是逐个站点角度的局部方案。通过使用序列二次规划（SLSQP）优化来最小化保真度损失，在XXZ自旋链上的模拟表明，在无噪声情况下，两种方案都能实现接近单位的保真度。在模拟退火噪声下，全局方案在相当的电路深度和迭代预算下提供了更好的鲁棒性。研究结果明确了表达能力与稳定性的权衡，并为噪声中等规模量子（NISQ）兼容的控制综合提供了一条可扩展的途径。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是为了解决高保真度状态转移在量子最优控制中的挑战，特别是在自旋链系统中。研究旨在开发一种能够有效处理系统动力学并适应噪声环境的控制框架。

Method: 提出并研究了一种混合变分框架，其中系统动力学被离散化并编译为参数化电路。控制输入通过可训练的单比特RZ旋转编码，而漂移相互作用则由确定性的两比特门实现。重点研究了两种参数化方案：全局方案（共享参数）和局部方案（逐点参数）。使用序列二次规划（SLSQP）优化方法来最小化保真度损失。

Result: 在XXZ自旋链的模拟中，两种参数化方案（全局和局部）在无噪声情况下均实现了接近单位的保真度。在存在模拟退火噪声的情况下，全局方案在可比的电路深度和迭代次数下表现出更好的鲁棒性。

Conclusion: 该研究表明，混合变分框架能够有效地实现高保真度的状态转移。全局参数化方案在噪声环境下具有更好的鲁棒性，明确了表达能力与稳定性的权衡。该方法为NISQ兼容的量子控制综合提供了一条可扩展的途径。

Abstract: We present a hybrid variational framework for quantum optimal control aimed at high-fidelity state transfer in spin chains. The system dynamics are discretized and compiled into a parameterized circuit, where deterministic two-qubit blocks implement the drift interactions, while trainable on-site RZ rotations encode the control inputs. We study two parameterizations: a compact global scheme with a small number of shared parameters per slice, and a local scheme with site-wise angles. Using a Sequential Least Squares Quadratic Programming (SLSQP) optimization to minimize infidelity, simulations on XXZ spin chains show that both parameterizations can achieve near-unit fidelities in the noiseless regime. Under depolarizing noise, the global scheme provides improved robustness for comparable circuit depth and iteration budgets. The results make explicit an expressivity-stability trade-off and suggest a scalable route to Noisy Intermediate-Scale Quantum (NISQ) compatible control synthesis.

</details>


### [219] [Two-Mode Janus States: non-Gaussian generalizations of thermofield double](https://arxiv.org/abs/2511.09704)
*Arash Azizi*

Main category: quant-ph

TL;DR: 我们提出了一种名为“双模 Janus 态”（TMJS）的新型非高斯量子态，它是两个不同的双模压缩态（TMSS）的相干叠加。该态是经典热场对偶（TFD）态的直接非高斯推广，而 TFD 态本身就是一个高斯 TMSS。我们为 TMJS 的任意 k 阶光子统计量开发了完整的解析框架，并确定了一种由“压缩多项式”控制的对角线和非对角线矩。我们的主要结果是，该态的非高斯性可以通过外部“Janus 相”进行动态控制。该相充当一个开关，可以将高阶相干性（g^(k)）从完全热的（与 TFD 边际匹配）调整到深度低于泊松分布的区域，该区域以强的 Wigner 负值（Wigner negativity）为特征。我们还提出了 TMJS 的物理实现方案，通过相干叠加的动力学卡西米尔效应（DCE）轨迹来生成它，并将其与静态、依赖于观察者的 Unruh 效应区分开。TMJS 为工程 Unruh-DeWitt 探测器响应和探测相对论环境中的非高斯物理学提供了一个多功能、干涉增强的平台。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提出一种新的非高斯量子态（TMJS），作为经典热场对偶（TFD）态的非高斯推广，并探索其潜在的应用，特别是在量子信息和相对论物理学领域。

Method: 我们通过相干叠加两个双模压缩态（TMSS）来构造双模 Janus 态（TMJS）。我们开发了完整的解析框架来计算其任意 k 阶光子统计量，并确定了控制其矩的“压缩多项式”。我们还提出了一种通过动力学卡西米尔效应（DCE）轨迹实现 TMJS 的物理方案。

Result: 我们确定了控制 TMJS 统计量的“压缩多项式”。我们证明了该态的非高斯性可以通过“Janus 相”动态调节，可以从热态调整到深度低于泊松分布的态，并表现出强的 Wigner 负值。我们提出了一种基于动力学卡西米尔效应（DCE）的物理实现方案。

Conclusion: 双模 Janus 态（TMJS）是一种可调的非高斯量子态，其非高斯性可以通过外部“Janus 相”进行动态控制，实现了从热态到深度低于泊松分布的态的转变。该态可以通过动力学卡西米尔效应（DCE）物理实现，为探索相对论量子物理学和工程量子探测器响应提供了一个有前景的平台。

Abstract: We introduce the Two-Mode Janus State (TMJS), a non-Gaussian quantum state defined as a coherent superposition of two distinct Two-Mode Squeezed States (TMSS). This construction serves as a direct, non-Gaussian generalization of the canonical thermofield double (TFD) state, which is itself a single, Gaussian TMSS. We develop a complete analytical framework for the TMJS's arbitrary $k$-th order photon statistics, identifying a new family of "squeezing polynomials" that govern all diagonal and off-diagonal moments. Our central result is that the state's non-Gaussianity is dynamically steerable via an external "Janus phase." This phase acts as a switch, allowing the higher-order coherences ($g^{(k)}$) to be tuned from perfectly thermal (matching the TFD marginal) to deeply sub-Poissonian, a regime marked by strong Wigner negativity. We further establish a physical realization for the TMJS, proposing its generation via coherently superposed Dynamical Casimir Effect (DCE) trajectories, distinguishing it from the static, observer-dependent Unruh effect. The TMJS provides a versatile, interference-enhanced platform for engineering Unruh-DeWitt detector responses and probing non-Gaussian physics in relativistic settings.

</details>


### [220] [Liquid metal printing for superconducting circuits](https://arxiv.org/abs/2511.09705)
*Alexander Kreiner,Navid Hussain,Ritika Dhundhwal,Haoran Duan,Nicolas Zapata,Gabriel Cadilha Marques,Tino Cubaynes,Torsten Scherer,Wolfgang Wernsdorfer,Michael Hirtz,Ioan Mihai Pop,Jasmin Aghassi-Hagmann,Thomas Reisinger*

Main category: quant-ph

TL;DR: 基于液态金属微量移液管打印技术，成功制备出具有高内禀质量因数的超导集总元件谐振器，为构建大规模超导量子计算机硬件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 传统的超导电路制造依赖标准纳米光刻技术，而增材制造方法因可能影响超导性能和量子相干性而未被采用。本文旨在探索增材制造在超导电路制造中的应用潜力。

Method: 利用液态金属微量移液管打印技术制备超导集总元件谐振器。

Result: 所制备的谐振器表现出高内禀质量因数；该技术适用于低损耗超导器件的制造，并能在不影响预存电路元件的情况下实现局部金属结构添加。

Conclusion: 液态金属微量移液管打印技术可用于制造高质量超导集总元件谐振器，为扩展超导量子计算机硬件实现提供了新的途径。

Abstract: Superconducting circuits are a promising platform for implementing fault-tolerant quantum computers, quantum limited amplifiers, ultra-low power superconducting electronics, and sensors with ultimate sensitivity. Typically, circuit fabrication is realized by standard nanolithography, generally associated with a high level of control over defects and contaminants. Additive approaches have not been used so far since they are expected to be inferior in terms of superconducting properties or quantum coherence. This work shows that liquid-metal based micro-pipette printing is suited for fabricating superconducting lumped-element resonators with high internal quality factors. The applicability of our technique for low-loss superconducting device fabrication and the possibility to locally add metal structures, without affecting any preexisting circuit elements, is a further advantage. Our results open up new avenues in the hardware implementation of scaled-up superconducting quantum computers.

</details>


### [221] [Constrained Shadow Tomography for Molecular Simulation on Quantum Devices](https://arxiv.org/abs/2511.09717)
*Irma Avdic,Yuchen Wang,Michael Rose,Lillian I. Payne Torres,Anna O. Schouten,Kevin J. Sung,David A. Mazziotti*

Main category: quant-ph

TL;DR: 该研究提出了一种双目标半定规划方法，用于从嘈杂或不完整的经典阴影数据中重建两粒子约化密度矩阵（2-RDM）。


<details>
  <summary>Details</summary>
Motivation: 量子状态断层扫描在表征量子系统方面至关重要，但其指数级的测量和计算需求限制了可扩展性。因此，需要高效的替代方案，如经典阴影，以实现从随机测量中准确预测许多可观测量。

Method: 提出了一种双目标半定规划方法，将N-可表象约束和核范数正则化集成到优化中，以从嘈杂或不完整的经典阴影数据中重建两粒子约化密度矩阵（2-RDM）。

Result: 该方法通过集成N-可表象约束和核范数正则化，构建了一个N-可表象的2-RDM，在保真度和能量最小化之间取得了平衡。数值和硬件结果表明，该方法显著提高了重建状态的准确性、抗噪声能力和可扩展性。

Conclusion: 所提出的框架通过整合N-可表象约束和核范数正则化，为实现物理上一致的费米子态重建提供了强大的基础，能够有效处理现实量子模拟中的噪声和采样误差。

Abstract: Quantum state tomography is a fundamental task in quantum information science, enabling detailed characterization of correlations, entanglement, and electronic structure in quantum systems. However, its exponential measurement and computational demands limit scalability, motivating efficient alternatives such as classical shadows, which enable accurate prediction of many observables from randomized measurements. In this work, we introduce a bi-objective semidefinite programming approach for constrained shadow tomography, designed to reconstruct the two-particle reduced density matrix (2-RDM) from noisy or incomplete shadow data. By integrating $N$-representability constraints and nuclear-norm regularization into the optimization, the method builds an $N$-representable 2-RDM that balances fidelity to the shadow measurements with energy minimization. This unified framework mitigates noise and sampling errors while enforcing physical consistency in the reconstructed states. Numerical and hardware results demonstrate that the approach significantly improves accuracy, noise resilience, and scalability, providing a robust foundation for physically consistent fermionic state reconstruction in realistic quantum simulations.

</details>


### [222] [Local arrows of time in quantum many-body systems](https://arxiv.org/abs/2511.09758)
*Andrew G. Yates,Jordan Cotler,Nishad Maskara,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: 局部时间箭头在量子多体系统中可以与由哈密顿量演化引起的全局时间不同，这意味着时间流逝可能因观察者或局部子系统而异。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于探索量子多体系统中时间流逝的相对性，并提出局部时间箭头的概念。

Method: 该研究通过定义局部时间箭头并阐述其与时空量子熵的关系，然后通过数值和分析示例来探索局部时间箭头在量子多体动力学中的不同表现形式，包括由量子热化和量子纠错产生的奇异时间箭头。

Result: 研究结果表明，局部时间箭头确实可以在量子多体系统中存在，并可以通过量子热化和量子纠错等现象表现出来。

Conclusion: 论文的结论是，局部时间箭头是量子多体系统中一个真实存在的现象，其存在揭示了时间流逝的相对性，并与量子熵等概念密切相关。

Abstract: We demonstrate that in quantum many-body systems, local arrows of time can differ from the global time $t$ induced by Hamiltonian evolution. That is, within a quantum many-body system, the flow of time can be relative to each observer or by proxy each local subsystem. We provide a definition of local arrows of time in quantum many-body systems, and explain their relation to spacetime quantum entropies. Then we give a variety of numerical and analytical examples which explore different ways in which local arrows of time can manifest in quantum many-body dynamics, including exotic arrows of time arising from quantum thermalization and quantum error correction.

</details>


### [223] [On the Classical Shadow Nonparametric Bootstrap](https://arxiv.org/abs/2511.09793)
*Eric Ghysels,Jack Morgan*

Main category: quant-ph

TL;DR: 通过引入 bootstrap resampling 方法，我们改进了经典数据（量子态的近似经典描述）的估计精度和可变性评估。


<details>
  <summary>Details</summary>
Motivation: 经典的阴影方法在用很少的测量来构造量子态的近似经典描述方面效率很高。然而，对这些估计的准确性和可变性的评估通常依赖于高斯近似，这可能不准确。

Method: 我们应用非参数 bootstrap 方法，通过从观察到的数据（经典阴影测量）中重复抽样（有放回）来评估估计量的可变性和准确性。

Result: 研究表明，bootstrap 分布与高斯近似有显著不同。此外，与 bootstrap 百分位数相比，理论误差界限不够紧密。

Conclusion: Bootstrap 重采样方法为经典阴影提供了一种更准确的评估估计量可变性和准确性的方法，并可用于风险评估。

Abstract: Classical shadows are an efficient method for constructing an approximate classical description of a quantum state using very few measurements. In the paper we propose to enhance classical shadow methods using bootstrap resampling methods. We apply nonparametric bootstrapping to assess the variability and accuracy of estimators by repeatedly sampling with replacement from the observed data, i.e.\ in our case the classical shadow measurements. We show that the bootstrap distributions are very different from the Gaussian approximations. Likewise, the theoretical error bounds are not tight compared to the bootstrap percentiles. Finally, we suggest using resampling tools to make risk assessments.

</details>


### [224] [Uncovering and Circumventing Noise in Quantum Algorithms via Metastability](https://arxiv.org/abs/2511.09821)
*Antonio Sannia,Pratik Sathe,Luis Pedro García-Pintos*

Main category: quant-ph

TL;DR: 通过利用具有长寿命中间态的动力学系统中的亚稳态现象，我们提出并验证了一种新的策略来规避噪声，从而为数字和模拟算法设计提供内在的鲁棒性，并引入了一个有效的噪声鲁棒性指标，该指标适用于我们对量子退火和门模型量子处理器中亚稳态噪声的实验证据。


<details>
  <summary>Details</summary>
Motivation: 量子计算机实现容错的主要挑战是噪声的存在。本研究旨在探索一种利用亚稳态现象来规避噪声的新策略，从而提高量子算法的鲁棒性。

Method: 开发了一个通用的理论框架，并引入了一个易于计算的噪声鲁棒性指标。该框架通过利用亚稳态现象，使数字和模拟算法能够以可感知的噪声方式设计，从而实现内在的鲁棒性。理论框架通过利用亚稳态现象，为数字和模拟算法的设计提供了新的途径，使其能够以可感知的噪声方式实现内在的鲁棒性。

Result: 通过利用亚稳态现象，证明了数字和模拟算法可以设计成对噪声具有内在鲁棒性。引入了一个易于计算的噪声鲁棒性指标，避免了对量子算法进行完全经典模拟的需要。该框架已应用于变分量子算法和模拟绝热态制备。在门模型量子处理器和量子退火设备中提供了亚稳态噪声存在的实验证据。

Conclusion: 近期的量子硬件中的噪声的内在性质可以被利用来指导实际的实现策略，从而能够制备出更接近理想状态的最终有噪声状态。这为在有噪声的量子硬件上实现容错量子计算开辟了新的途径。

Abstract: The presence of noise is the primary challenge in realizing fault-tolerant quantum computers. In this work, we introduce and experimentally validate a novel strategy to circumvent noise by exploiting the phenomenon of metastability, where a dynamical system exhibits long-lived intermediate states. We demonstrate that if quantum hardware noise exhibits metastability, both digital and analog algorithms can be designed in a noise-aware fashion to achieve intrinsic resilience. We develop a general theoretical framework and introduce an efficiently computable noise resilience metric that avoids the need for full classical simulation of the quantum algorithm. We illustrate the use of our framework with applications to variational quantum algorithms and analog adiabatic state preparation. Crucially, we provide experimental evidence supporting the presence of metastable noise in gate-model quantum processors as well as quantum annealing devices. Thus, we establish that the intrinsic nature of noise in near-term quantum hardware can be leveraged to inform practical implementation strategies, enabling the preparation of final noisy states that more closely approximate the ideal ones.

</details>


### [225] [Mapping Game Theory to Quantum Systems: Nash Equilibria via Neutral Atom Computing](https://arxiv.org/abs/2511.09841)
*Giovanni Ferrannini,Dario di Gregorio,Federico Fissore*

Main category: quant-ph

TL;DR: 本研究将纳什均衡问题映射到里德堡原子阵列的基态配置上，利用量子方法寻找纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 寻找纳什均衡在经济学、物理学、生物学和计算机科学等领域至关重要，但其NP-Hard的复杂性带来了挑战。

Method: 通过利用最大独立集（MIS）与单位圆盘图上的纳什均衡之间的对应关系，将这些问题映射到里德堡原子阵列的基态配置。

Result: 模拟结果表明，该量子方法在寻找纳什均衡方面是有效的。

Conclusion: 本研究提出的量子方法为解决博弈论中的复杂问题提供了新的途径。

Abstract: Nash equilibria are crucial for understanding game behavior and systems in economics, physics, biology, and computer science. A significant application arises from the connection between Nash equilibria and optimization problems . However, finding Nash equilibria is challenging due to its NP-Hard complexity, specifically within the PPAD class. By exploiting the correspondence between Maximum Independent Sets (MIS) and Nash equilibria on unit-disk graphs, we map these problems onto the ground state configurations of Rydberg atom arrays. Simulations show the effectiveness of this quantum method, highlighting its potential for solving complex problems in game theory.

</details>


### [226] [Discrete Time Crystals in Noninteracting Dissipative Systems](https://arxiv.org/abs/2511.09852)
*Gourab Das,Saptarshi Saha,Rangeet Bhattacharyya*

Main category: quant-ph

TL;DR: 许多多体量子系统会在特定条件下表现出时间平移对称性破缺，并进入时间晶体（DTC）相。DTC 的主要特征是具有鲁棒性的亚谐波响应。然而，DTC 相对环境耗散很脆弱。本文提出并举例说明了一种在非相互作用系统中实现 DTC 的方法，该方法利用环境耗散来稳定 DTC。这种 DTC 的寿命与初始条件和系统尺寸无关，但与外部驱动频率有关。研究人员使用核磁共振波谱技术通过实验证实了这种 DTC 的实现。


<details>
  <summary>Details</summary>
Motivation: 许多多体量子系统在特定条件下会进入时间晶体（DTC）相，但该相通常容易受到环境耗散的影响。本研究的动机是探索一种利用环境耗散来稳定 DTC 相的机制，特别是在非相互作用系统中。

Method: 提出了一种在非相互作用系统中利用环境耗散来稳定 DTC 相的理论模型，并推导了其寿命与驱动频率的关系。通过核磁共振波谱技术进行了实验验证。

Result: 成功在非相互作用系统中实现了由环境耗散驱动的 DTC 相。实验结果表明，该 DTC 相的寿命与系统尺寸和初始条件无关，仅依赖于驱动频率。

Conclusion: 环境耗散可以用来稳定非相互作用系统中的时间晶体（DTC）相，这与传统观点相反。这种由耗散驱动的 DTC 相具有与系统尺寸和初始条件无关的寿命，为在开放量子系统中探索新颖的非平衡相提供了新的途径。

Abstract: Many-body quantum systems, under suitable conditions, exhibit time-translation symmetry breaking and settle in a discrete time crystalline (DTC) phase -- an out-of-equilibrium quantum phase of matter. The defining feature of DTC is a robust subharmonic response. However, the DTC phase is fragile in the presence of environmental dissipation. Here, we propose and exemplify a DTC phase in a noninteracting system that owes its stability to environmental dissipation. The lifetime of this DTC is independent of initial conditions and the size of the system, though it depends on the frequency of the external driver. We experimentally demonstrate this realization of DTC using Nuclear Magnetic Resonance spectroscopy.

</details>


### [227] [Quantum Period-Finding using One-Qubit Reduced Density Matrices](https://arxiv.org/abs/2511.09896)
*Marco Bernardi*

Main category: quant-ph

TL;DR: 该研究提出了一种从量子周期查找（QPF）算法的单量子比特约简密度矩阵（1-RDMs）中提取周期的新方法，而不是依赖于传统的输出比特串。


<details>
  <summary>Details</summary>
Motivation: 标准的量子周期查找（QPF）算法依赖于测量整个量子电路的输出状态，并结合连分数分析来确定函数周期。本研究旨在探索一种替代方法，利用单量子比特约简密度矩阵（1-RDMs）来提取周期信息。

Method: 通过状态向量模拟计算QPF电路的1-RDMs，并分析这些1-RDMs与周期的关系，利用数值求根方法从1-RDMs中提取周期。

Result: 研究表明，1-RDMs包含了足够的信息来重构周期，这通常需要采样 $O(2^n)$ 个比特串。这种方法可以看作是QPF算法信息的一种“压缩”，使得可以仅从 $n$ 个单量子比特边际量中找到周期。

Conclusion: 1-RDMs可以提供足够的信息来提取QPF算法的周期，从而可能通过分析约简密度矩阵来设计新的周期查找算法。

Abstract: The quantum period-finding (QPF) algorithm can compute the period of a function exponentially faster than the best-known classical algorithm. In standard QPF, the output state has a primary contribution from $r$ high-probability bit strings, where $r$ is the period. Measurement of this state, combined with continued fraction analysis, reveals the unknown period. Here, we explore a different approach to QPF, where the period is obtained from single-qubit quantities $-$ specifically, the set of one-qubit reduced density matrices (1-RDMs) $-$ rather than the output bit strings of the entire quantum circuit. Using state-vector simulations, we compute the 1-RDMs of the QPF circuit for a generic periodic function. Analysis of these 1-RDMs as a function of period reveals distinctive patterns, which allows us to obtain the unknown period from the 1-RDMs using a numerical root-finding approach. Our results show that the 1-RDMs $-$ a set of $O(n)$ one-qubit marginals $-$ contain enough information to reconstruct the period, which is typically obtained by sampling the space of $O(2^n)$ bit strings. Conceptually, this can be viewed as a "compression" of the information in the QPF algorithm, which enables period-finding from $n$ one-qubit marginals. Our results motivate the development of approximate simulations of reduced density matrices to design novel period-finding algorithms.

</details>


### [228] [Provably Efficient Quantum Algorithms for Solving Nonlinear Differential Equations Using Multiple Bosonic Modes Coupled with Qubits](https://arxiv.org/abs/2511.09939)
*Yu Gan,Hirad Alipanah,Jinglei Cheng,Zeguan Wu,Guangyi Li,Juan José Mendoza-Arenas,Peyman Givi,Mujeeb R. Malik,Brian J. McDermott,Junyu Liu*

Main category: quant-ph

TL;DR: 本研究提出了一种基于模拟连续变量的量子算法，利用耦合玻色子模式和基于量子比特的自适应测量，实现了非线性微分方程的量子模拟，避免了希尔伯特空间的离散化，并证明了其效率。


<details>
  <summary>Details</summary>
Motivation: 现有数字容错方法在实现量子计算求解经典微分方程时，面临对当前硬件实现困难的挑战，本研究旨在提供一种更适合当前硬件的模拟方法。

Method: 该算法将经典场编码为相干态，利用基于Koopman-von Neumann（KvN）形式主义的Kraus通道组合，将非线性演化映射到线性动力学，并采用耦合玻色子模式和基于量子比特的自适应测量。

Result: 该算法在模拟一维Burgers方程和二维Fisher-KPP方程方面表现出能力，并证明了其在强耗散条件下对光子损耗的鲁棒性，还推导了解释噪声的解析反项。

Conclusion: 本研究建立了一个用于模拟非线性系统的连续变量框架，并为在近期模拟硬件上实现实际的量子加速提供了一条可行途径。

Abstract: Quantum computers have long been expected to efficiently solve complex classical differential equations. Most digital, fault-tolerant approaches use Carleman linearization to map nonlinear systems to linear ones and then apply quantum linear-system solvers. However, provable speedups typically require digital truncation and full fault tolerance, rendering such linearization approaches challenging to implement on current hardware. Here we present an analog, continuous-variable algorithm based on coupled bosonic modes with qubit-based adaptive measurements that avoids Hilbert-space digitization. This method encodes classical fields as coherent states and, via Kraus-channel composition derived from the Koopman-von Neumann (KvN) formalism, maps nonlinear evolution to linear dynamics. Unlike many analog schemes, the algorithm is provably efficient: advancing a first-order, $L$-grid point, $d$-dimensional, order-$K$ spatial-derivative, degree-$r$ polynomial-nonlinearity, strongly dissipative partial differential equations (PDEs) for $T$ time steps costs $\mathcal{O}\left(T(\log L + d r \log K)\right)$. The capability of the scheme is demonstrated by using it to simulate the one-dimensional Burgers' equation and two-dimensional Fisher-KPP equation. The resilience of the method to photon loss is shown under strong-dissipation conditions and an analytic counterterm is derived that systematically cancels the dominant, experimentally calibrated noise. This work establishes a continuous-variable framework for simulating nonlinear systems and identifies a viable pathway toward practical quantum speedup on near-term analog hardware.

</details>


### [229] [Reusability Report: Optimizing T-count in General Quantum Circuits with AlphaTensor-Quantum](https://arxiv.org/abs/2511.09951)
*Remmy Zen,Maximilian Nägele,Florian Marquardt*

Main category: quant-ph

TL;DR: AlphaTensor-Quantum 通过将 T 门优化问题表述为张量分解任务，并使用强化学习进行训练，在简化随机量子电路方面取得了显著进展，实现了比现有方法更好的 T 门计数约减，并且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于在量子硬件上执行量子电路的复杂性，特别是最小化 T 门数量对于实现高效量子算法至关重要，因此有必要改进 T 门计数。

Method: 本报告通过将问题表述为张量分解任务，并使用强化学习来训练一个通用智能体，对随机量子电路进行优化，从而扩展了 AlphaTensor-Quantum 的能力。

Result: 在 5 到 8 个量子比特的电路上训练的通用智能体，在很大一部分量子电路上实现了比以前的方法更好的 T 门计数约减。在具有不同量子比特数的电路上训练的通用智能体，其性能优于在固定量子比特数上训练的智能体。

Conclusion: 本研究成功地扩展了 AlphaTensor-Quantum 的能力，使其能够优化具有不同量子比特数的随机量子电路，而无需针对新电路进行重新训练，这突显了该方法的泛化能力和在更广泛的量子电路优化任务中的潜力。

Abstract: Quantum computing has the potential to solve problems that are intractable for classical computers, with possible applications in areas such as drug discovery and high-energy physics. However, the practical implementation of quantum computation is hindered by the complexity of executing quantum circuits on hardware. In particular, minimizing the number of T-gates is crucial for implementing efficient quantum algorithms. AlphaTensor-Quantum is a reinforcement learning-based method designed to optimize the T-count of quantum circuits by formulating the problem as a tensor decomposition task. While it has demonstrated superior performance over existing methods on benchmark quantum arithmetic circuits, its applicability has so far been restricted to specific circuit families, requiring separate, time-intensive training for each new application. This report reproduces some of the key results of the original work and extends AlphaTensor-Quantum's capabilities to simplify random quantum circuits with varying qubit counts, eliminating the need for retraining on new circuits. Our experiments show that a general agent trained on 5- to 8-qubit circuits achieves greater T-count reduction than previous methods for a large fraction of quantum circuits. Furthermore, we demonstrate that a general agent trained on circuits with varying qubit numbers outperforms agents trained on fixed qubit numbers, highlighting the method's generalizability and its potential for broader quantum circuit optimization tasks.

</details>


### [230] [Improved coherence time of a non-Hermitian qubit in a $\mathcal{PT}$-symmetric Environment](https://arxiv.org/abs/2511.09990)
*Duttatreya,Ipsika Mohanty,Sanjib Dey*

Main category: quant-ph

TL;DR: 非厄米量子力学，特别是 PT 对称系统，可以延长量子比特的相干时间。


<details>
  <summary>Details</summary>
Motivation: 量子计算的潜力受到退相干的限制，而非厄米量子力学提供了一种可能延长相干时间的新方法。

Method: 研究非厄米 PT 对称动力学下量子比特的相干性，并与厄米系统进行比较。

Result: 与厄米设置相比，非厄米 PT 对称系统显著延长了量子比特的相干时间，尤其是在系统和环境都表现出 PT 对称性时。环境的非厄米性越大，相干性越长。

Conclusion: 非厄米 PT 对称动力学为管理退相干提供了有前途的策略，有望促进量子信息处理的发展。

Abstract: Quantum computing's potential for exponential speedup is fundamentally limited by decoherence, a phenomenon arising from environmental interactions. Non-Hermitian quantum mechanics, particularly $PT$-symmetric systems, offers a novel framework for extending coherence times. This study examines a qubit's coherence under non-Hermitian $PT$-symmetric dynamics, highlighting significantly enhanced coherence times compared to Hermitian setups. The effect is especially pronounced when both the system and environment exhibit $PT$-symmetry. Interestingly, greater environmental non-Hermiticity correlates with extended coherence, contrary to traditional expectations. These findings point to promising strategies for managing decoherence, which could significantly advance approaches to quantum information processing.

</details>


### [231] [Enantiodetection in a cavity QED setup with finite chiral molecules](https://arxiv.org/abs/2511.10061)
*Xiang Guo,Xiaojun Zhang,Yong Li,Zhihai Wang*

Main category: quant-ph

TL;DR: 本研究利用腔量子电动力学平台，通过监测腔内稳态光子数，研究了单个和有限集分子的对映体检测方法。


<details>
  <summary>Details</summary>
Motivation: 利用对映体之间固有的全局π相位差，设计相干干涉路径，实现对映体过量的直接读出。

Method: 采用广义离散截断Wigner近似方法，处理多分子体系，避免了复杂的方程模拟。

Result: 误差低于5%，可以实现对映体过量的直接读出，并能捕捉超越平均场的多分子效应。

Conclusion: 该方法为在实际量子光学设置中实现对映体检测提供了途径。

Abstract: We investigate enantiodetection for both a single cyclic three-level chiral molecule and finite ensembles of such molecules by monitoring the steady-state intracavity photon number in a cavity-QED platform. Our scheme exploits the intrinsic global $π$-phase difference between opposite enantiomers to engineer destructive and/or constructive interference pathways, enabling a direct readout of enantiomeric excess with an error below $5\%$. To capture mesoscopic many-molecule effects beyond mean field while avoiding brute-force master-equation simulations, we employ a generalized discrete truncated Wigner approximation, which is well suited for systems with many yet finite molecules. These results pave the way for implementing enantiodetection in realistic quantum-optical settings.

</details>


### [232] [Frequency Spectra of Isolated Laser Pulse Envelopes](https://arxiv.org/abs/2511.10506)
*L. H. Ford,Brian Fu*

Main category: quant-ph

TL;DR: 本研究数值计算了孤立激光脉冲的傅里叶变换，并研究了其在高频下的渐进行为。研究结果表明，脉冲包络傅里叶变换的衰减速率决定了探测到的概率分布的衰减速率，并提出了一个模型，其中傅里叶变换随频率的指数的某个分数次幂衰减，该分数在0.1到0.2范围内。这表明大数波动具有显著的概率。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是最近在二阶量子化系统中二次算子的概率分布方面的研究结果，特别是材料密度在声子真空态中受到零点涨落的影响。这些分布可能下降非常缓慢，导致出现大数波动的相对较高的概率。

Method: 本研究通过数值计算孤立激光脉冲（即持续时间有限且包络函数在此区间外严格为零的脉冲）的傅里叶变换，并研究其在高频下的渐近行为。

Result: 研究发现，脉冲包络傅里叶变换的衰减速率直接影响概率分布的衰减速率。作者提出了一个模型，其中傅里叶变换随着频率的指数的某个分数次幂衰减（分数在0.1到0.2之间），并且概率分布具有相同的函数形式，这意味着即使波动远大于方差，也存在显著的概率。

Conclusion: 孤立激光脉冲的傅里叶变换的渐进行为对于理解和预测量子系统中的大数波动至关重要。所提出的模型及其对概率分布的启示表明，在某些量子系统中，即使是远超平均水平的波动也可能具有相当大的发生概率。

Abstract: This paper will deal with isolated laser pulses, those which last for a finite time interval and whose envelope function is strictly zero outside of this interval. We numerically calculate the Fourier transform of this function and study its asymptotic behavior at high frequencies. This work is motivated by recent results on the probability distributions of quadratic operators in second quantized systems. An example is the density of a material which is subject to zero point fluctuations in the phonon vacuum state. These distributions can decrease very slowly, leading to a relatively high probability for large fluctuations. If the operator is measured by a laser pulse, the rate of decrease of the distribution mirrors the rate of decrease of the pulse envelope Fourier transform. We describe a model for the creation of isolated pulses in which this Fourier transform falls as an exponential of a fractional power of frequency and find examples where this fraction is in the range 0.1 to 0.2. The probability distribution for large fluctuation has the same functional form and implies a significant probability for fluctuations very large compared to the variance.

</details>


### [233] [First and second quantized digital quantum simulations of bosonic systems](https://arxiv.org/abs/2511.10124)
*Mathias Mikkelsen,Hubert Okadome Valencia*

Main category: quant-ph

TL;DR: 第一量化和第二量化中的玻色子映射在资源需求方面进行了比较，第一量化（特别是二元映射）在特定条件下（如 k-RDM 的非对角项和实际的 N、M 组合）在门和量子比特效率方面优于第二量化。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是比较第一和第二量化中玻色子映射的基本资源需求，以确定在不同场景下的效率。

Method: 通过比较第一量化（包括二元和一元映射）和第二量化（包括二元和一元映射）的 k-RDM（k 约简密度矩阵）和两个标准玻色子哈密顿量的资源需求（量子比特和门数量）。

Result: 第一量化映射在 k-RDM 的非对角项上比第二量化映射资源需求少约 $N^k$。虽然第一量化二元映射的门数量随 M 增加比其他映射更快，但对于实际的 N 和 M 组合，其所需门数仍少于第二量化的二元和一元映射，并且量子比特数量指数级少于一元第二量化映射。当 M = $2^n$ 时，第一量化二元映射的 CNOT 和 $R_z(φ)$ 门数量与一元第一量化映射相当，这表明该映射在实际问题中可能同时具有量子比特和门的效率。

Conclusion: 第一量化二元玻色子映射在计算 k-RDM 和某些哈密顿量时，在量子比特和门数量上都具有竞争力，甚至优于第二量化映射，尤其是在实际应用场景中。

Abstract: We compare the basic resource requirements for first and second quantized bosonic mappings in a system consisting of $N$ particles in $M$ modes. In addition to the standard binary first quantized mapping, we investigate the unary first quantized mapping, which we show to be the most gate-efficient mapping for bosons in the general case, although less qubit-efficient than binary mappings. Our comparison focuses on the $k$-body reduced density matrix ($k$-RDM) as well as two standard bosonic Hamiltonians. The first quantized mappings use less resources for off-diagonal terms of the $k$-RDM by a factor of $ \sim N^k$, compared to the second quantized mappings. The number of gates for the first quantized binary mapping increases faster with $M$ compared to the other mappings. Nevertheless, a detailed numeric analysis reveals that the binary first quantized mapping still requires fewer gates than the binary and unary second quantized ones for realistic combinations of $N$ and $M$, while requiring exponentially fewer qubits than the unary mappings. Additionally, the number of CNOT and $R_z(φ)$ gates necessary to express the exponential of the Hamiltonian in the binary first quantized mapping is comparable to the (overall most efficient) unary first quantized one when $M = 2^n$ for both the Bose-Hubbard model and the harmonic trap with short-range interactions. This suggests that this mapping can be both qubit- and gate-efficient for practical problems.

</details>


### [234] [General quantum backflow in realistic wave packets](https://arxiv.org/abs/2511.10155)
*Tomasz Paterek,Arseni Goussev*

Main category: quant-ph

TL;DR: 在本研究中，我们提出了一个适用于任意动量分布的量子回流通用框架，该框架可以实现近13%的概率回流，超过了标准回流限制的三倍以上，并为在现实条件下进行实验观察铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 量子回流是一种违反直觉的现象，但由于其效应幅度小且难以制备和验证具有确定动量方向的波包，因此一直难以在实验中进行观察。

Method: 我们提出了一个适用于任意动量分布的量子回流通用框架，该框架将回流定义为超出仅由粒子动量分布预测的概率流，并将其扩展到量子再递现象。

Result: 我们发现，通过利用任意动量分布，可以实现近13%的概率回流，这超过了标准回流限制（4%）的三倍以上。我们还提供了展示大范围量子回流和再递现象的量子态的具体示例。

Conclusion: 本研究提出的量子回流通用框架为在现实条件下实现量子回流的实验观察提供了新的途径，并深入探讨了这些非经典效应的基本意义。

Abstract: Quantum backflow is a counterintuitive phenomenon in which the probability density of a quantum particle propagates opposite to its momentum. Experimental observation of backflow has remained elusive due to two main challenges: (i) the effect is intrinsically small, with less than 4% of the probability able to flow backward, and (ii) it requires wave packets with a well-defined momentum direction, which are difficult both to prepare and to verify under realistic, noisy conditions. Here, we overcome these challenges by introducing a general formulation of quantum backflow applicable to arbitrary momentum distributions. The framework recovers the standard backflow limit for unidirectional states and identifies general backflow as probability flow exceeding that predicted by the particle's momentum distribution alone. We show that this excess can reach nearly 13%, surpassing the standard backflow bound by more than a factor of three. Furthermore, we extend the framework to the closely related phenomenon of quantum reentry, provide explicit examples of quantum states exhibiting large general backflow and reentry, and discuss the foundational implications of these nonclassical effects. Our results open a pathway toward the experimental observation of quantum backflow in realistic settings.

</details>


### [235] [Addressable fault-tolerant universal quantum gate operations for high-rate lift-connected surface codes](https://arxiv.org/abs/2511.10191)
*Josias Old,Juval Bechar,Markus Müller,Sascha Heußen*

Main category: quant-ph

TL;DR: 该研究提出了一种在升链连接表面（LCS）量子码上实现量子克利福德门操作的方法，并展示了如何通过添加魔态制备过程来实现容错通用门集，该方法在近期的量子计算实验中具有可行性。


<details>
  <summary>Details</summary>
Motivation: 量子低密度奇偶校验（qLDPC）码是实现具有低量子比特开销的量子比特纠错存储器的主要候选者，但其计算难度大。本研究旨在提出一种在LCS码上实现量子克利福德门操作的方法，以克服计算难度大的问题。

Method: 在升链连接（LCS）量子码上，利用标志量子比特，设计确定性容错（FT）电路，实现逻辑门集合$\{\overline{H}_i, \overline{H}_i, \overline{C_i X_j}\}_{i,j in (0,1,2)}$。通过添加FT魔态制备过程，实现FT通用门集。

Result: 对于 $[[15,3,3]]$ LCS码，我们提供了基于标志量子比特的确定性容错（FT）电路，实现了逻辑门集合$\{\overline{H}_i, \overline{H}_i, \overline{C_i X_j}\}_{i,j in (0,1,2)}$。通过添加FT魔态制备过程，可以实现$d=3$ LCS码的FT通用门集。数值模拟表明，该门构造可以达到$p_{\mathrm{th}} \approx 4.8\cdot 10^{-3}-1.2\cdot 10^{-2}$的伪阈值。

Conclusion: 本研究提出的LCS码上的克利福德门和通用门构造方案，使用了适量的量子比特，对于近期的实验是可行的，有助于在高速qLPDC码中实现容错逻辑的进展。

Abstract: Quantum low-density parity check (qLDPC) codes are among the leading candidates to realize error-corrected quantum memories with low qubit overhead. Potentially high encoding rates and large distance relative to their block size make them appealing for practical suppression of noise in near-term quantum computers. In addition to increased qubit-connectivity requirements compared to more conventional topological quantum error correcting codes, qLDPC codes remain notoriously hard to compute with. In this work, we introduce a construction to implement all Clifford quantum gate operations on the recently introduced lift-connected surface (LCS) codes (Old et al. 2024). These codes can be implemented in a 3D-local architecture and achieve asymptotic scaling $[[n, \mathcal{O}(n^{1/3}), \mathcal{O}(n^{1/3})]]$. In particular, LCS codes realize favorable instances with small numbers of qubits: For the $[[15,3,3]]$ LCS code, we provide deterministic fault-tolerant (FT) circuits of the logical gate set $\{\overline{H}_i, \overline{H}_i, \overline{C_i X_j}\}_{i,j \in (0,1,2)}$ based on flag qubits. By adding a procedure for FT magic state preparation, we show quantitatively how to realize an FT universal gate set in $d=3$ LCS codes. Numerical simulations indicate that our gate constructions can attain pseudothresholds in the range $p_{\mathrm{th}} \approx 4.8\cdot 10^{-3}-1.2\cdot 10^{-2}$ for circuit-level noise. The schemes use a moderate number of qubits and are therefore feasible for near-term experiments, facilitating progress for fault-tolerant error corrected logic in high-rate qLPDC codes.

</details>


### [236] [Proof-of-principle demonstration of a Polarization-Circulation Speed Meter](https://arxiv.org/abs/2511.10220)
*Yohei Nishino,Tomotada Akutsu,Yoichi Aso,Munetake Otsuka,Luise Kranzhoff,Takayuki Tomaru*

Main category: quant-ph

TL;DR: 首次实验实现偏振-圆周速度计，并验证了其测量速度的能力，为复杂干涉仪配置提供了控制方案。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的速度测量工具，并探索其在更复杂干涉仪系统中的应用潜力。

Method: 采用单腔干涉仪配置，固定所有反射镜。使用绿光锁定方案稳定偏振圆周腔，并通过锁获得程序实现速度计操作。通过测量伪位移信号到光电探测器输出的传递函数来表征系统。

Result: 成功实现了偏振-圆周速度计的实验验证，并确认该装置能够测量镜子运动的速度。

Conclusion: 实验结果支持偏振-圆周速度计的可行性，并表明所提出的控制方案可以扩展到更复杂的干涉仪配置，如迈克尔逊干涉仪和悬浮镜系统。

Abstract: We present the first experimental implementation of a polarization-circulation speed meter. In our experiment, the interferometer was reduced to a single-cavity configuration with all mirrors fixed. A green-locking scheme was employed to stabilize the polarization circulation cavity, and a lock-acquisition procedure was demonstrated to realize speed-meter operation. The system was characterized by measuring the transfer function from a pseudo-displacement signal to the photodetector output, confirming that the device measures the speed of mirror motion. These results support the feasibility of polarization-circulation speed meters and suggest that the control scheme could be extended to more complex configurations, such as Michelson interferometers and suspended-mirror systems.

</details>


### [237] [Tunable single-photon frequency converter in a waveguide with a giant V-type atom](https://arxiv.org/abs/2511.10243)
*Hongzheng Wu,Ge Sun,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 本研究研究了V型巨原子的单光子散射，实现了单光子频率转换。


<details>
  <summary>Details</summary>
Motivation: 研究V型巨原子与一维波导耦合的单光子散射，以实现单光子频率转换。

Method: 利用Lippmann-Schwinger方程计算散射系数，并分析了马尔可夫和非马尔可夫两种情况下的散射谱和转换对比度。

Result: 发现在抑制任一跃迁路径的单光子发射时，频率 up/down 转换的概率会消失，但通过引入非互易性可以增强甚至达到1。这种转换概率的调整归因于巨原子本身的尺度以及巨原子-波导耦合之间的相位差引起的量子自干涉。

Conclusion: V型巨原子与一维波导的耦合可以实现单光子频率转换，并且可以通过调控其参数（如耦合强度、驱动场等）来控制转换效率和非互易性。

Abstract: We study the single-photon scattering in a one-dimensional (1D) waveguide coupled to one transition of a $V$-type giant atom (GA), whose other transition is coherently driven by an classical field. The inelastic scattering of single photons by the GA realizes the single-photon frequency conversion. By applying the Lippmann-Schwinger equation, the scattering coefficients for single photons incident from different directions are obtained, which present different scattering spectra in the Markovian and the non-Markovian regimes. The conversion contrast characterizing the nonreciprocity is also analyzed in both regimes. It is found that the probability of the frequency up- or down-conversion vanishes as long as the emission from either transition pathways for single photons is suppressed, but it is enhanced and even reach unity by introducing the nonreciprocity. It is the quantum self-interference induced by the scale of this two-legged GA and the phase difference between the GA-waveguide couplings that tune the probability of the frequency up- or down-conversion.

</details>


### [238] [Ancilla-Free Fast-Forwarding Lindbladian Simulation Algorithms by Hamiltonian Twirling](https://arxiv.org/abs/2511.10253)
*Minbo Gao,Zhengfeng Ji,Chenghua Liu*

Main category: quant-ph

TL;DR: 该论文提出了一种新的模拟开放量子系统的算法，该算法基于哈密顿量旋转通道，能够以更快的速度和更少的资源实现目标精度。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统模拟是量子算法研究中的一个活跃领域，现有方法在资源需求上存在挑战。

Method: 文章提出了一种精确的哈密顿量旋转通道方法，将林布莱特定时演化映射为酉轨道上的高斯旋转。基于此，设计了一种快速演化算法，实现了$O(\sqrt{t\log(1/\varepsilon)})$的时间复杂度，且无需辅助寄存器或受控操作。此外，还推导了连续变量量子相位估计算法，并澄清了耗散动力学与哈密顿量旋转通道的关系。最后，探索了复合泊松分布的哈密顿量旋转及其算法意义。

Result: 所提出的快速演化算法在$O(\sqrt{t\log(1/\varepsilon)})$的时间复杂度内实现了$\\varepsilon$的菱形范数误差，优于现有技术，且无需辅助寄存器或受控操作。推导出的连续变量量子相位估计算法和对耗散动力学的澄清也为该领域带来了新的见解。

Conclusion: 该研究提出了一种高效且资源需求低的开放量子系统模拟算法，为近期的实验实现提供了可能性。同时，对哈密顿量旋转通道的理论分析也为未来研究提供了新的方向。

Abstract: Simulation of open quantum systems is an area of active research in quantum algorithms. In this work, we revisit the connection between Markovian open-system dynamics and averages of Hamiltonian real-time evolutions, which we refer to as Hamiltonian twirling channels. Focusing on the class of Lindbladians with a single Hermitian jump operator $H$ recently studied in Shang et al. (arXiv:2510.06759), we show that the time-$t$ evolution map can be expressed exactly a Gaussian twirl over the unitary orbit ${\{\mathrm{e}^{-\mathrm{i} Hs}\}}_{s\in\mathbb{R}}$. This structural insight allows us to design a fast-forwarding algorithm for Lindbladian simulation that achieves diamond-norm error $\varepsilon$ with time complexity $O\big(\sqrt{t\log(1/\varepsilon)}\big)$ -- matching the performance of Shang et al. while requiring no auxiliary registers or controlled operations. The resulting ancilla-free and control-free algorithm is therefore more amenable to near-term experimental implementation. By purifying the Gaussian twirl procedure and performing a conjugate measurement, we derive a continuous-variable quantum phase estimation algorithm. In addition, by applying the Lévy-Khintchine representation theorem, we clarify when and how a dissipative dynamics can be realized using Hamiltonian twirling channels. Guided by the general theory, we explore Hamiltonian twirling with compound Poisson distributions and their potential algorithmic implications.

</details>


### [239] [Photon transport and blockade based on non-Markovian interactions between a microring resonator and waveguide](https://arxiv.org/abs/2511.10256)
*Haijin Ding*

Main category: quant-ph

TL;DR: 本研究探讨了在波导-微环谐振器耦合系统中光子传输和光子阻碍效应，该系统具有两个独立的耦合点，导致了非马尔可夫动力学。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索具有两个耦合点的波导-微环谐振器系统中光子传输和光子阻碍的非马尔可夫动力学。

Method: 研究采用了两个耦合点的波导-微环谐振器结构，利用散射矩阵和二阶关联函数来分析非马尔可夫过程。对于经典驱动场的情况，则通过腔内本征态来确定输出场的阻碍效应。

Result: 研究结果表明，通过设计非马尔可夫耦合参数，可以根据波导末端的光子输出状态来调控单光子或双光子传输及光子阻碍效应。此外，输出场和腔内状态的关联性也可以通过微环谐振器和波导之间的非马尔可夫耦合进行调制。

Conclusion: 本研究揭示了非马尔可夫耦合在调控光子传输和光子阻碍效应中的重要作用，并提出了相应的分析方法。

Abstract: We investigate photon transport and blockade based on the architecture where a waveguide is coupled to a microring resonator at two distinct points. This two-point coupling configuration between the waveguide and resonator gives rise to non-Markovian dynamics, which is induced by the photon transmission delay in the waveguide between the two coupled points. On one hand, by designing the non-Markovian coupling parameters between the waveguide and resonator, single or two-photon transport and the resulting photon blockade effect can be manipulated according to the output photonic states at the end of waveguide. This non-Markovian process can be evaluated by scattering matrices and second order correlation functions related to the distance between two coupled points. On the other hand, when classical driving fields are applied upon the resonator with interactions between its clockwise and counterclockwise modes, the blockade effect of the output field can be determined by the intracavtiy eigenstates. Then the correlations of the output field as well as the intracavity states can be modulated by the non-Markovian coupling between the microring resonator and waveguide.

</details>


### [240] [Quantum Simulation of Non-unitary Dynamics via Contour-based Matrix Decomposition](https://arxiv.org/abs/2511.10267)
*Chao Wang,Huan-Yu Liu,Cheng Xue,Xi-Ning Zhuang,Menghan Dou,Zhao-Yun Chen,Guo-Ping Guo*

Main category: quant-ph

TL;DR: CBMD是一种可扩展的非幺正动力学模拟框架，它通过推广Cauchy的留数定理将非厄米特函数分解为厄米特函数的线性组合，实现了最优查询复杂度，并对更一般的动力学保持适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的非幺正动力学模拟方法依赖于数值积分，而CBMD提供了一种新的、可扩展的框架。

Method: CBMD推广了Cauchy的留数定理到矩阵值函数，将非厄米特函数分解为厄米特函数的线性组合，并利用QSVT等技术实现。该方法还包括一个额外的特征值移位技术。

Result: CBMD在非厄米特动力学方面实现了最优查询复杂度，改进后的复杂度取决于系统的谱范围而非谱范数。对于更一般的动力学，CBMD避免了其他方法存在的对角化假设和条件数依赖性。

Conclusion: CBMD是一种通用且高效的框架，适用于模拟各种非幺正动力学，具有优于现有方法的性能和适用性。

Abstract: We introduce contour-based matrix decomposition (CBMD), a framework for scalable simulation of non-unitary dynamics. Unlike existing methods that follow the ``integrate-then-discretize" paradigm and rely heavily on numerical quadrature, CBMD generalizes Cauchy's residue theorem to matrix-valued functions and directly decomposes a non-Hermitian function into a linear combination of Hermitian ones, which can be implemented efficiently using techniques such as quantum singular value transformation (QSVT). For non-Hermitian dynamics, CBMD achieves optimal query complexity. With an additional eigenvalue-shifting technique, the improved complexity depends on the spectral range of the system instead of its spectral norm. For more general dynamics that can be approximated by non-Hermitian polynomials, where algorithms like QSVT face significant difficulties, CBMD remains applicable and avoids the assumptions of diagonalizability as well as the dependence on condition numbers that limit other approaches.

</details>


### [241] [Generalized coherent states with shifted (displaced) arguments](https://arxiv.org/abs/2511.10285)
*Dušan Popov*

Main category: quant-ph

TL;DR: 该论文提出了一种构造广义相干态（Generalized Coherent States）的方法，利用非线性梯形算符作用于它们，并使用算符排序技术（DOOT）来研究这些相干态的性质。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是发展一种构造广义相干态的方法，并研究其性质。

Method: 利用非线性梯形算符作用于广义位移算符，构造广义相干态，并运用算符排序技术（DOOT）来研究其性质。

Result: 成功构造了具有移位参数的广义相干态，并通过具体实例验证了结果的正确性。

Conclusion: 该方法得到的表达式在量子光学等领域具有应用价值，例如用于计算相干态表示下的维格纳算符。

Abstract: In the paper we developed a procedure for constructing generalized coherent states with shifted argument, as a result of the action of the generalized displacement operator. This was based on the action of a pair of nonlinear ladder operators, which generate nonlinear coherent states. To examine the properties of coherent states with shifted argument, the rules of the normal operator ordering technique (DOOT) were used. The results obtained were verified for a series of particular cases, obtaining expressions consistent with those in the literature. The expressions obtained will be, among others, useful in quantum optics, e.g. for calculating the Wigner operator in the representation of coherent states.

</details>


### [242] [Optomechanical Cooling without Residual Heating](https://arxiv.org/abs/2511.10318)
*Surangana Sengupta,Björn Kubala,Joachim Ankerhold,Ciprian Padurariu*

Main category: quant-ph

TL;DR: 通过引入非线性驱动来消除量子反作用加热，从而克服传统腔光力学冷却的有限温度下限。


<details>
  <summary>Details</summary>
Motivation: 腔光力学中的受激边带冷却受量子反作用加热的限制，导致机械声子数存在最低限度。

Method: 将半经典模型推广到包含非线性（被动和主动）的通用腔哈密顿量，并以约瑟夫森结为具体实例分析了最简单的电路光力学系统。

Result: 所提出的主动非线性驱动可以消除残余加热反作用，与基于被动非线性的方法相比具有优势，并克服了有限温度下限。

Conclusion: 所提出的方法能够实现前所未有的量子控制，并为零加热的光力学冷却提供了实验可行性。

Abstract: Resolved-sideband cooling is a standard technique in cavity optomechanics enabling quantum control of mechanical motion, but its performance is ultimately limited by quantum backaction heating. This fundamental effect imposes a limit on the minimum achievable mechanical phonon number, establishing a finite-temperature floor regardless of the applied cooling strength. We generalize the semi-classical model for optomechanical cooling to describe universal cavity Hamiltonians incorporating both passive and active nonlinearities. As a concrete demonstration, we analyze the simplest circuit optomechanical system that implements a nonlinear drive via a Josephson junction. Our analysis reveals that this active nonlinear drive can eliminate the residual heating backaction, thereby comparing favorably with alternative optomechanical cooling schemes based on passive nonlinearities arXiv:2202.13228. By successfully overcoming the finite-temperature floor that limits conventional schemes, our method paves the way for unprecedented quantum control over mechanical systems and establishes the experimental viability of zero-heating optomechanical cooling.

</details>


### [243] [Assessing Finite Scalability in Early Fault-Tolerant Quantum Computing for Homogeneous Catalysts](https://arxiv.org/abs/2511.10388)
*Yanbing Zhou,Athena Caesura,Corneliu Buda,Xavier Jackson,Clena M. Abuan,Shangjie Guo*

Main category: quant-ph

TL;DR: 量子计算硬件的有限可扩展性影响模拟开放壳催化系统的资源需求，高保真架构在处理相同规模问题时需要较低的最小可扩展性，而LDPC码通过减少时空开销进一步扩大了这种优势。


<details>
  <summary>Details</summary>
Motivation: 研究有限可扩展性如何影响使用量子相位估计算法（QPE）模拟开放壳催化系统的资源需求，并比较不同硬件架构和容错方案的可行性。

Method: 通过两种代表性的可扩展性模型，比较了以保真度或操作速度为特征的硬件架构。此外，还考虑了表面码和基于量子低密度奇偶校验（LDPC）的容错方案，并分析了有限可扩展性下的时间竞争性。

Result: 有限可扩展性增加了量子比特和运行时的需求，但并未改变整体的可扩展性行为。高保真架构在解决相同规模的问题时需要较低的最小可扩展性。LDPC码通过减少时空开销，进一步扩大了高保真架构保持竞争力的运行范围。

Conclusion: 可扩展性在量化性能和指导下一代量子硬件设计中起着核心作用。可扩展架构的持续进步对于将量子计算扩展到日益复杂的科学和工业应用至关重要。

Abstract: As quantum hardware advances toward fault-tolerant operation, an intermediate stage known as early fault-tolerant quantum computing (EFTQC) is emerging, where partial error correction enables meaningful computation. In this regime, the ability of quantum processors to scale in size and depth has become a crucial factor shaping their achievable performance. This study investigates how finite scalability influences resource requirements for simulating open-shell catalytic systems using Quantum Phase Estimation (QPE). The analysis compares hardware archetypes distinguished by fidelity or operation speed under two representative scalability models. Finite scalability increases qubit and runtime demands yet leaves overall scaling behavior intact, with high-fidelity architectures requiring lower minimum scalability to solve equally sized problems. These effects are largely independent of the chosen scalability model. Extending this framework, we examine runtime competitiveness across hardware and code configurations, incorporating surface-code and quantum Low-Density Parity-Check (LDPC)-based fault tolerance under finite scalability. The results identify operating regimes where high-fidelity architectures remain competitive despite slower gate speeds and show that LDPC codes further expand this regime by reducing space-time overhead. Together, these findings highlight the central role of scalability in quantifying performance and guiding the design of next-generation quantum hardware. Continued progress in scalable architectures will be essential for extending quantum computing to increasingly complex scientific and industrial applications.

</details>


### [244] [Hardware-Efficient Bosonic Module for Entangling Superconducting Quantum Processors via Optical Networks](https://arxiv.org/abs/2511.10407)
*Jia-Hua Zou,Weizhou Cai,Jia-Qi Wang,Zheng-Xu Zhu,Qing-Xuan Jie,Xin-Biao Xu,Weiting Wang,Guang-Can Guo,Luyan Sun,Chang-Ling Zou*

Main category: quant-ph

TL;DR: 使用基于SNAIL的参数耦合，我们提出了一种模块化架构，用于将布里渊微波到光学（M2O）换能器与长寿命的3D腔耦合，实现了30公里光纤上的量子纠缠分发，并实现了高达0.94的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有超导量子处理器扩展方案面临效率和相干性挑战，需要高效的光学互连技术。

Method: 提出一种模块化架构，利用SNAIL耦合器连接布里渊M2O换能器和3D腔，并结合DLCZ协议进行量子纠缠分发，考虑了激光加热、传输损耗和探测效率等噪声。

Result: 通过数值模拟，在30公里光纤上传输速率为kHz级别时，原始纠缠比特保真度达到F~0.8；通过针对幅度阻尼误差进行不对称纠缠泵浦优化后，保真度提升至F~0.94，传输速率为0.2 kHz。

Conclusion: 提出的基于腔的方案相比于超导比特（transmon）方案具有优势，为分布式超导量子计算提供了一条可行的途径。

Abstract: Scaling superconducting quantum processors beyond single dilution refrigerators requires efficient optical interconnects, yet integrating microwave-to-optical (M2O) transducers poses challenges due to frequency mismatches and qubit decoherence. We propose a modular architecture using SNAIL-based parametric coupling to interface Brillouin M2O transducers with long-lived 3D cavities, while maintaining plug-and-play compatibility. Through numerical simulations incorporating realistic noises, including laser heating, propagation losses, and detection inefficiency, we demonstrate raw entangled bit fidelities of F~0.8 at kHz-level rates over 30 km using the Duan-Lukin-Cirac-Zoller (DLCZ) protocol. Implementing asymmetric entanglement pumping tailored to amplitude damping errors, we achieve purified fidelities F~0.94 at 0.2 kHz rates. Our cavity-based approach outperforms transmon schemes, providing a practical pathway for distributed superconducting quantum computing.

</details>


### [245] [Entanglement Phase Transition in Chaotic non-Hermitian Systems](https://arxiv.org/abs/2511.10410)
*Zhen-Tao Zhang,Feng Mei*

Main category: quant-ph

TL;DR: 在一个特定类型的混沌非厄米自旋链中，当横向场大于某个阈值时，通过计算其复谱，我们发现这些模型会发生一个与耗散率相关的无能隙-有能隙相变。该复能隙随耗散率的变化表现出振荡，而不是单调变化。通过模拟其非幺正演化，我们发现 त्याच耗散率下，纠缠熵会从体膜扩展转变为面积定律扩展。这些不同寻常的现象源于最大虚数能级与其他能级之间的交叉。


<details>
  <summary>Details</summary>
Motivation: 研究一类特殊的混沌非厄米自旋链中的纠缠相变，特别是其自旋-自旋耦合项与非厄米项可交换的情况。

Method: 通过计算复谱来分析能隙行为，并通过模拟非幺正演化来研究纠缠熵的行为。

Result: 发现了与耗散率相关的无能隙-有能隙相变，复能隙随耗散率振荡，纠缠熵从体膜扩展转变为面积定律扩展，并在体膜扩展相中出现了一些意外的纠缠熵结果。

Conclusion: 揭示了混沌非厄米系统中一种新颖的纠缠相变，该相变与复能隙的振荡行为和非单调性以及纠缠熵的扩展律变化有关，这些现象归因于能级交叉。

Abstract: We have studied entanglement phase transition in a class of chaotic non-Hermitian spin chain in which its spin-spin coupling term commutes with the non-Hermitian term. Two models are investigated: transverse field Ising model with a complex longitudinal field and non-Hermitian XX model with a transverse field. Through calculating their complex spectra, we find these models are subject to a gapless-gapped phase transition with dissipation rate if the transverse field is larger than a model-dependent value. Interestingly, the variation of the complex gap with the dissipation rate is not monotonous, instead it manifest oscillations before entering the gapped phase. By simulating their non-unitary evolution, we show that the entanglement entropy of the steady state would transition from a volume-law to an area-law scaling with the increase of the dissipation rate. Meanwhile, some unexpected results about the entanglement entropy appear in the volume-law phase. These unusual features of the complex gap and the steady-state entanglement can be attributed to level crossings between the maximal imagine level and other levels. Our work reveals a novel entanglement transition in chaotic non-Hermitian systems.

</details>


### [246] [From Local Nonclassicality to Entanglement: A Convexity Law for Single-Excitation Dynamics](https://arxiv.org/abs/2511.10470)
*Atta ur Rahman,Ao-xiang Liu,M. Y. Abd-Rabbou,Cong-feng Qiao*

Main category: quant-ph

TL;DR: excitation-preserving interactions yield a dynamical law where local Wigner negativities sum to a budget determined by the initial state, saturated when excitation is localized.


<details>
  <summary>Details</summary>
Motivation: the paper aims to prove a dynamical law for excitation-preserving interactions concerning the sum of local Wigner negativities.

Method: The study analytically establishes the result for two bodies and corroborates it numerically in engineered state-transfer chains, analyzing phase-space overlap in local mixtures and coherence-enabled dark transport.

Result: The sum of local Wigner negativities is upper-bounded by a budget set by the initial state. This bound is saturated when the excitation is fully localized. Intermediate times show the sum below the bound due to phase-space overlap, with entanglement growth as a redistribution of resources into correlations. Numerical corroboration reveals coherence-enabled dark transport.

Conclusion: The sum of local negativity serves as a practical hardware metric, where deviations from the predicted trajectory indicate decoherence and control errors.

Abstract: We prove a simple dynamical law for excitation-preserving interactions: the {sum of local Wigner negativities} is upper-bounded by a fixed budget set by the initially excited state. For the single-excitation sector of the XY model (and its beam-splitter analogue), this convexity bound equals the negativity of the seed state and is saturated only when the excitation is fully localized. At intermediate times the sum lies strictly below the bound due to phase-space overlap in local mixtures, quantitatively accounting for entanglement growth as a redistribution of a finite, budgeted resource into shared correlations. We establish the result analytically for two bodies and corroborate it numerically in engineered state-transfer chains, where it reveals a coherence-enabled dark transport: the resource becomes locally invisible while being stored in multi-body coherences. The predicted trajectory of the summed local negativity provides a practical hardware metric: deviations from the ideal, budgeted curve diagnose decoherence and control error.

</details>


### [247] [Shortcuts to adiabaticity for coherent atom transport in an adjustable family of two-dimensional optical lattices](https://arxiv.org/abs/2511.10472)
*Sascha H. Hauck,Vladimir M. Stojanovic*

Main category: quant-ph

TL;DR: 利用可调二维光晶格实现原子的相干传输，并采用绝热路线和逆向工程方法优化传输过程，结果表明该方法传输时间短且鲁棒性好。


<details>
  <summary>Details</summary>
Motivation: 为了满足量子技术中相干原子传输的需求。

Method: 设计声光调制器以产生频率失衡的激光束，进而实现任意方向的动态光晶格。利用基于Lewis-Riesenfeld动力学不变量的绝热路线逆向工程方法获得原子传输轨迹。通过数值求解时变薛定谔方程计算传输保真度来量化原子动力学。

Result: 在各种系统参数和传输方向下，获得了较短的传输时间和对实验缺陷的鲁棒性。

Conclusion: 所提出的方法能够有效地实现可调二维光晶格中原子的相干传输，并具有良好的传输效率和鲁棒性。

Abstract: Motivated by the compelling need for coherent atom transport in a variety of emerging quantum technologies, we investigate such transport on the example of an adjustable family of two-dimensional optical lattices [L. Tarruell {\em et al.}, Nature (London) 483, 302 (2012)] that includes square, triangular, honeycomb, dimerized, and checkerboard lattices as its special cases; dynamical optical lattices of this type have already been utilized for the demonstration of topological pumping and the realiza- tion of two-qubit quantum gates with neutral atoms. At the outset, we propose the appropriate arrangements of acousto-optic modulators that give rise to a frequency imbalance between coun- terpropagating laser beams, thus leading to the dynamical-lattice effect in an arbitrary direction in the lattice plane. We subsequently obtain the dynamical-lattice trajectories that enable atom transport using shortcuts to adiabaticity (STA) in the form of inverse engineering based on a dy- namical invariant of Lewis-Riesenfeld type. We then quantify the resulting atom dynamics using the transport fidelity computed from the numerical solutions of the relevant time-dependent Schroedinger equation. We do so for various choices of the system parameters and transport directions, finding favorable results for the achievable transport times and robustness of the resulting transport to various experimental imperfections.

</details>


### [248] [Quantum Design Automation: Foundations, Challenges, and the Road Ahead](https://arxiv.org/abs/2511.10479)
*Feng Wu,Jingzhe Guo,Tian Xia,Linghang Kong,Fang Zhang,Ziang Wang,Aochu Dai,Ziyuan Wang,Zhaohui Yang,Hao Deng,Kai Zhang,Zhengfeng Ji,Yuan Feng,Hui-Hai Zhao,Jianxin Chen*

Main category: quant-ph

TL;DR: 本文提出应采用整体设计视角来推动量子计算的发展，以应对系统可扩展性、性能、良率以及算法和应用等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 量子计算正从研究走向部署，但面临系统可扩展性、性能、制造良率以及算法与应用等方面的严峻挑战。本文旨在强调设计在量子计算（包括量子芯片、系统集成、指令集、算法和中间件）中的核心作用，并倡导采用整体设计方法以抓住协同设计机遇，应对关键挑战。

Method: 本文详细介绍了实现端到端量子计算机设计的互联计算方法和工具，涵盖了从芯片布局设计自动化、高保真系统级模拟、量子系统建模的哈密顿量推导、控制脉冲模拟、退相干分析，到物理验证和测试，再到量子指令集设计。此外，还讨论了量子系统和软件开发，包括量子电路综合、量子纠错和容错，以及逻辑验证和测试。

Result: 通过具体示例，如量子指令集与算法的协同优化、根据硬件约束定制纠错电路、通过定制代码设计简化量子芯片设计等，说明了端到端的设计流程。这些示例旨在促进软硬件社区的对话。

Conclusion: 本文强调了整体设计视角在量子计算中的关键作用，详细介绍了端到端的量子计算机设计流程和工具，并通过具体示例展示了协同设计的潜力，旨在促进软硬件社区的交流与合作，加速研究成果向未来量子硬件的转化。

Abstract: Quantum computing is transitioning from laboratory research to industrial deployment, yet significant challenges persist: system scalability and performance, fabrication yields, and the advancement of algorithms and applications. We emphasize that in building quantum computers -- spanning quantum chips, system integration, instruction sets, algorithms, and middleware such as quantum error correction schemes -- design is everywhere. In this paper, we advocate for a holistic design perspective in quantum computing, a perspective we argue is pivotal to unlocking innovative co-design opportunities and addressing the aforementioned key challenges. To equip readers with sufficient background for exploring co-optimization opportunities, we detail how interconnected computational methods and tools collaborate to enable end-to-end quantum computer design. This coverage encompasses critical stages -- such as chip layout design automation, high-fidelity system-level simulation, Hamiltonian derivation for quantum system modeling, control pulse simulation, decoherence analysis, and physical verification and testing -- followed by quantum instruction set design. We then proceed to quantum system and software development, including quantum circuit synthesis, quantum error correction and fault tolerance, and logic verification and testing. Through these discussions, we illustrate with concrete examples -- including co-optimizing quantum instruction sets with algorithmic considerations, customizing error correction circuits to hardware-specific constraints, and streamlining quantum chip design through tailored code design, among others. We hope that the detailed end-to-end design workflow as well as these examples will foster dialogue between the hardware and software communities, ultimately facilitating the translation of meaningful research findings into future quantum hardware implementations.

</details>


### [249] [Entanglement Structure of Nonlocal Field Theories](https://arxiv.org/abs/2511.10505)
*Reza Pirmoradian,M. Hossein Bek-Khoshnevis,Sadaf Ebadi,M. Reza Tanhayi*

Main category: quant-ph

TL;DR: 非局域相互作用在量子关联的精细结构方面产生复杂的量子态，这表明需要超越几何学的框架来完全捕捉这些关联的性质。


<details>
  <summary>Details</summary>
Motivation: 探索非局域相互作用对量子关联（如互信息和三方信息）精细结构的影响，超越了传统的纠缠熵。

Method: 使用数值格点模拟和全息对偶方法来研究一个 the bosonic nonlocal field theory。

Result: 非局域性尺度（A）确定了体律行为的出现，并导致了极长程的互信息和异常的婚外结构。全息对偶正确地捕捉了熵的体律缩放，但在互信息和三方信息方面与 the field theory 存在显著的矛盾，其中全息模型预测在体律相中被完全抑制。

Conclusion: 非局域性会产生复杂的量子态，以至于传统的 the spacetime 几何模型都无法完全描述。这表明需要一个超越几何学的框架来完全理解这些关联的性质。

Abstract: Nonlocal interactions are known to generate volume-law entanglement entropy. However, their deeper impact on the fine structure of quantum correlations remains a key open question. In this work, we explore a bosonic nonlocal field theory, examining correlation measures beyond entanglement entropy, namely, mutual information and tripartite information. Using numerical lattice simulations, we show that the nonlocality scale, \(A\), not only determines the onset of volume-law behavior but also leads to striking features: notably, extremely long-range mutual information and an unusual monogamy structure. In this regime, increasing the separation between large regions can paradoxically enhance their multipartite entanglement. Through holographic duality, we verify that the Ryu-Takayanagi formula correctly captures the volume-law scaling of entropy. Yet, a significant tension emerges: while the field theory reveals rich spatial correlations, the holographic model predicts a complete suppression of both mutual and tripartite information in the volume-law phase. This non-monogamous behavior in the holographic description stands in sharp contrast to the monogamous and highly structured entanglement observed in the field theory. Our results demonstrate that nonlocality gives rise to quantum states of such complexity that conventional geometric models of spacetime fall short. This points to the need for a new framework that goes beyond geometry to fully capture the nature of these correlations.

</details>


### [250] [Quantum Computational Structure of $SU(N)$ Scattering](https://arxiv.org/abs/2511.10550)
*Navin McGinnis*

Main category: quant-ph

TL;DR: SU(N)对称性的粒子散射可以通过量子计算和量子算法来研究。对于在基本或反基本表示中变换的粒子（即 qudits）之间的散射，所有 2-2 散射幅度都可以仅从三个量子门构建。此外，对于任何 N，所有 2-2 散射通道都源于 $\mathbb{Z}_{2}$ 代数的张成，这表明在此背景下的散射根本上受“比特翻转”对其内部量子数的作用的支配。我们通过量子算法来阐述这些发现，这些算法由酉矩阵的线性组合和块编码构成。


<details>
  <summary>Details</summary>
Motivation: 研究了具有SU(N)全局对称性的粒子散射问题，并引入了量子计算和量子算法的视角。

Method: 证明了对于基本或反基本表示中的粒子（qudits），所有2-2散射幅度均可由三个量子门构建。此外，证明了所有2-2散射通道都源于$\\mathbb{Z}_{2}$代数的张成，并提出散射过程受“比特翻转”操作支配。

Result: 提出了一种基于酉矩阵线性组合和块编码的量子算法框架。

Conclusion: SU(N)对称性的粒子散射可以通过量子计算方法进行有效描述和构建，其核心在于少数基本量子操作（量子门）和对称代数（$\\mathbb{Z}_{2}$代数）的支配作用。

Abstract: We study scattering of particles which obey an $SU(N)$ global symmetry through the lens of quantum computation and quantum algorithms. We show that for scattering between particles which transform in the fundamental or anti-fundamental representations, i.e. qudits, all 2-2 scattering amplitudes can be constructed from only three quantum gates. Further, for any $N$, all 2-2 scattering channels are shown to emerge from the span of a $\mathbb{Z}_{2}$ algebra, suggesting that scattering in this context is fundamentally governed by the action of ``bit flips'' on the internal quantum numbers. We frame these findings in terms of quantum algorithms constructed from Linear Combinations of Unitaries and block encoding.

</details>


### [251] [Observation and Manipulation of Optical Parametric Down-Conversion in the Langevin Regime](https://arxiv.org/abs/2511.10556)
*Yen-Ju Chen,Chun-Yuan Cheng,Tien-Dat Pham,Tzu-An Chen,Chang-Hau Kuo,Yen-Hung Chen,Chih-Sung Chuu*

Main category: quant-ph

TL;DR: 本实验在芯片上实现了朗之万体制下的光学参量下转换，通过精确控制与起伏相关的损耗，观察到了量子起伏的标志——不对称的洪- ou -曼德尔干涉以及近一个数量级的起伏诱导的单光子压缩效应。


<details>
  <summary>Details</summary>
Motivation: 研究量子起伏在朗之万体制下光学参量下转换中的作用，并探索其在芯片上的实现。

Method: 在芯片上实现光学参量下转换，精确控制损耗，并进行洪- ou -曼德尔干涉和单光子压缩测量。

Result: 观察到不对称的洪- ou -曼德尔干涉条纹，证明了量子起伏的存在；实现近一个数量级的单光子压缩。

Conclusion: 量子起伏可以被操纵，为量子操控、量子态调控以及系统-库相互作用的研究提供了新的方向。

Abstract: Quantum fluctuation plays a key role in the parametric down-conversion in the Langevin regime. In this paper, we report the experimental realization of optical parametric down-conversion in the Langevin regime on a chip. By precisely controlling the loss inherently tied to fluctuation, we observe the asymmetric Hong-Ou-Mandel dip - a hallmark of quantum fluctuation in the fluctuation-driven PDC, and the fluctuation-induced compression of single photons by nearly one order of magnitude. These findings pave the way for the manipulation of quantum fluctuation, quantum states, and system-reservoir interaction.

</details>


### [252] [Finite-size quantum key distribution rates from Rényi entropies using conic optimization](https://arxiv.org/abs/2511.10584)
*Mariana Navarro,Andrés González Lorente,Pablo V. Parellada,Carlos Pascual-García,Mateus Araújo*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Finite-size general security proofs for quantum key distribution based on Rényi entropies have recently been introduced. These approaches are more flexible and provide tighter bounds on the secret key rate than traditional formulations based on the von Neumann entropy. However, deploying them requires minimizing the conditional Rényi entropy, a difficult optimization problem that has hitherto been tackled using ad-hoc techniques based on the Frank-Wolfe algorithm, which are unstable and can only handle particular cases. In this work, we introduce a method based on non-symmetric conic optimization for solving this problem. Our technique is fast, reliable, and completely general. We illustrate its performance on several protocols, whose results represent an improvement over the state of the art.

</details>


### [253] [Information phases of partial projected ensembles generated from random quantum states](https://arxiv.org/abs/2511.10595)
*Alan Sherry,Saptarshi Mandal,Sthitadhi Roy*

Main category: quant-ph

TL;DR: 投影系综比归约密度矩阵更能探测二分量子态的遍历性和信息结构，该框架可推广到三方设定中的部分投影系综，并可用霍尔沃信息来表征信息分布。


<details>
  <summary>Details</summary>
Motivation: 需要比归约密度矩阵更精细的探测手段来分析二分量子态的遍历性和信息结构，并探索三方设定中的信息分布。

Method: 使用投影系综和部分投影系综，结合霍尔沃信息和对数负度量，分析三方哈尔随机态。

Result: 发现了霍尔沃信息与系统尺寸之间存在一个定性变化，并揭示了信息相图，其中一个相是指数衰减的，另一个相是线性增长的，存在尖锐的转变；并证明了一个测量不可见量子相关相的存在。

Conclusion: 霍尔沃信息比传统的纠缠度量更能揭示信息结构，并揭示了超越传统纠缠度量的信息结构。

Abstract: The projected ensemble -- an ensemble of pure states on a subsystem conditioned on projective measurement outcomes on its complement -- provides a finer probe of ergodicity and information structure than the reduced density matrix of the subsystem in bipartite quantum states. This framework can be generalised to partial projected ensembles in tripartite settings, where outcomes from part of the measured subsystem are discarded, leading to ensembles of mixed states. We show that information measures defined for such ensembles, in particular the Holevo information, yield a more detailed characterisation of how quantum information is distributed between subsystems compared to conventional entanglement measures. Using exact analytical results supported by numerical results, we uncover a qualitative change in the scaling of the Holevo information with system size in partial projected ensembles generated by Haar-random states, as the relative sizes of the subsystem are varied. In one phase, the Holevo information decays exponentially with system size, while in the other it grows linearly, thereby defining distinct information phases separated by sharp transitions signalled by non-analyticities in the Holevo information. The exponentially decaying phase rigorously establishes the existence of a measurement-invisible quantum-correlated phase -- a manifestation of many-body information scrambling with no bipartite analogue. Finally, we contrast this information-phase diagram with the entanglement-phase structure of tripartite Haar-random states obtained from logarithmic negativity, and show that the Holevo information reveals additional fine structure beyond conventional entanglement measures.

</details>


### [254] [Quantum Algorithms for Computing Maximal Quantum $f$-divergence and Kubo-Ando means](https://arxiv.org/abs/2511.10607)
*Trung Hoa Dinh,Nhat A. Nghiem*

Main category: quant-ph

TL;DR: 我们提出了计算最大量子f-散度和算子理论矩阵Kubo-Ando均值的量子算法。


<details>
  <summary>Details</summary>
Motivation: 鉴于使用量子计算技术估计或计算Renyi熵、Von Neumann熵、矩阵均值等量子信息论数量的日益增长的兴趣，我们提出了计算最大量子f-散度和算子理论矩阵Kubo-Ando均值的量子算法。

Method: 提出量子算法来计算最大量子f-散度和算子理论矩阵Kubo-Ando均值。

Result: 所提出的量子算法可以计算最大量子f-散度和算子理论矩阵Kubo-Ando均值。

Conclusion: 由于最大量子f-散度和算子理论矩阵Kubo-Ando均值都涉及Renyi熵和矩阵均值，这表明了我们框架的通用性。

Abstract: The development of quantum computation has resulted in many quantum algorithms for a wide array of tasks. Recently, there is a growing interest in using quantum computing techniques to estimate or compute quantum information-theoretic quantities such as Renyi entropy, Von Neumann entropy, matrix means, etc. Motivated by these results, we present quantum algorithms for computing the maximal quantum $f$-divergences and the operator-theoretic matrix Kubo--Ando means. Both of them involve Renyi entropies, matrix means as special cases, thus implying the universality of our framework.

</details>


### [255] [Impacts of Decoder Latency on Utility-Scale Quantum Computer Architectures](https://arxiv.org/abs/2511.10633)
*Abdullah Khalid,Allyson Silva,Gebremedhin A. Dagnew,Tom Dvir,Oded Wertheim,Motty Gruda,Xiangzhou Kong,Mia Kramer,Zak Webb,Artur Scherer,Masoud Mohseni,Yonatan Cohen,Pooya Ronagh*

Main category: quant-ph

TL;DR: 量子计算机的运行速度受限于经典电子元件的反应时间，但这一点及其对逻辑微架构设计的影响尚未得到充分理解。本研究针对表面码架构，建立了反应时间模型，并分析了其对逻辑错误率的影响，最后对执行大规模量子电路的资源进行了估算，结果表明即使在快速解码条件下，仍会产生显著的资源开销。


<details>
  <summary>Details</summary>
Motivation: 经典电子元件的反应时间是容错量子计算机速度的关键，但这一点及其对逻辑微架构设计的影响尚未得到充分理解。

Method: 1. 针对表面码架构，建立包含并行空-时窗口解码方法和量子执行环境通信延迟的反应时间模型。 2. 利用该模型估算反应时间增加导致的魔态注入逻辑错误率。 3. 展示如何针对反应时间优化逻辑微架构。 4. 给出基于实际硬件噪声和先进解码时间的，执行大规模量子电路的详细全系统量子和经典资源估算。

Result: 在代表超导量子处理器在 2.86 MHz 稳定频率下运行的硬件模型下，对于包含 $10^6$ – $10^{11}$ $T$ 门的电路（涉及 200–2000 个逻辑量子比特），即使每稳定轮解码速度达到亚微秒级，也会导致显著的资源开销：魔态工厂的纠错量子比特存储需要约 100k–250k 个额外的物理量子比特；核心处理器由于将码距从 $d$ 增加到 $d+4$ 以提供额外内存保护，需要 300k–1.75M 个额外的物理量子比特；运行时间约增加 100 倍。

Conclusion: 即使在快速解码条件下，量子计算机的反应时间对资源消耗（额外的物理量子比特和更长的运行时间）也有显著影响，需要仔细考虑其对逻辑微架构设计和整体资源需求的影响。

Abstract: The speed of a fault-tolerant quantum computer is dictated by the reaction time of its classical electronics, that is, the total time required by decoders and controllers to determine the outcome of a logical measurement and execute subsequent conditional logical operations. Despite its importance, the reaction time and its impact on the design of the logical microarchitecture of a quantum computer are not well understood. In this work, we build, for a surface code based architecture, a model for the reaction time in which the decoder latency is based on parallel space- and time-window decoding methods, and communication latencies are drawn from our envisioned quantum execution environment comprising a high-speed network of quantum processing units, controllers, decoders, and high-performance computing nodes. We use this model to estimate the increase in the logical error rate of magic state injections as a function of the reaction time. Next, we show how the logical microarchitecture can be optimized with respect to the reaction time, and then present detailed full-system quantum and classical resource estimates for executing utility-scale quantum circuits based on realistic hardware noise parameters and state-of-the-art decoding times. For circuits with $10^{6}$--$10^{11}$ $T$ gates involving 200--2000 logical qubits, under a $Λ=9.3$ hardware model representative of a realistic target for superconducting quantum processors operating at a 2.86 MHz stabilization frequency, we show that even decoding at a sub-microsecond per stabilization round speed introduces substantial resource overheads: approximately 100k--250k additional physical qubits for correction qubit storage in the magic state factory; 300k--1.75M extra physical qubits in the core processor due to the code distance increase of $d$ to $d+4$ for extra memory protection; and a longer runtime by roughly a factor of 100.

</details>


### [256] [Emergent spin order and steady-state superradiance in one-dimensional baths](https://arxiv.org/abs/2511.10638)
*Silvia Cardenas-Lopez,Edgar Guardiola-Navarrete,Ana Asenjo-Garcia*

Main category: quant-ph

TL;DR: 在多模态多通道衰减和传播的退相干过程中，原子集体衰减可以诱导自发相序和超辐射发射。


<details>
  <summary>Details</summary>
Motivation: 研究多模态退相干对原子集体衰减和相序的影响。

Method: 分析耦合到一维电磁浴的两个模型：一个双通道谐振腔和一个双向波导。

Result: 在合适的泵浦强度下，观察到集体衰减克服退相干过程，形成稳态相序和超辐射发射。在两个模型中，最大强度与系统大小呈二次方关系。谐振腔模型中出现自发手性，波导模型中出现局部手性。

Conclusion: 在一维退相干中，竞争和传播会塑造涌现序，并可能出现稳态超辐射。

Abstract: Spontaneous collective decay in driven atomic ensembles can generate coherence far from equilibrium, as illustrated by superradiant lasers where decay into a single-mode cavity synchronizes atomic phases into a macroscopic dipole and yields superradiant emission of light with an ultranarrow spectrum. Whether similar ordering persists in multimode reservoirs with propagation and competing collective decay channels remains an open question. We address this problem by analyzing atoms coupled to one-dimensional electromagnetic baths through two models. The first is a ring cavity supporting two bright collective decay channels, and the second is a bidirectional waveguide where, in addition to competition between channels, propagation induces coherent dipole-dipole interactions. For suitable incoherent pumping strengths, the dynamics enters a synchronization window in which collective decay overcomes disordering processes, leading to spontaneous steady-state phase ordering and superradiant emission. We extract the thresholds marking the onset of synchronization and show that the maximum intensity scales quadratically in both models. The resulting order is not described by a single macroscopic dipole: in the ring cavity spontaneous chirality emerges at the level of individual trajectories, while the waveguide develops a local chirality with different orders dominating opposite ends of the atomic array. The analysis of the emitted light spectrum reveals a linewidth that seems to narrow with increased system size in the ring cavity, while narrowing in the waveguide remains inconclusive within accessible numerics. These results clarify how competition and propagation shape emergent order in one-dimensional reservoirs and identify regimes where steady-state superradiance may arise beyond the Dicke limit.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [257] [Investigation of Feature Selection and Pooling Methods for Environmental Sound Classification](https://arxiv.org/abs/2511.09802)
*Parinaz Binandeh Dehaghani,Danilo Pena,A. Pedro Aguiar*

Main category: eess.SP

TL;DR: 该论文研究了在轻量级卷积神经网络（CNN）中，降维和池化方法对环境声音分类（ESC）的影响，重点评估了稀疏显著区域池化（SSRP）及其变体（SSRP-B 和 SSRP-T），并与主成分分析（PCA）进行了比较。


<details>
  <summary>Details</summary>
Motivation: 评估降维和池化方法在轻量级CNN中对环境声音分类（ESC）任务的影响，旨在寻找一个能在准确性和计算成本之间取得平衡的解决方案，特别适用于资源受限的场景。

Method: 通过在ESC-50数据集上进行实验，比较了稀疏显著区域池化（SSRP）及其变体（SSRP-Basic 和 SSRP-Top-K）与主成分分析（PCA）在不同超参数设置下的性能。

Result: SSRP-T 在 ESC-50 数据集上达到了 80.69 % 的准确率，显著优于基线 CNN（66.75 %）和 PCA 降维模型（37.60 %）。

Conclusion: 精心调整的稀疏池化策略为 ESC 任务提供了一种鲁棒、高效且高性能的解决方案，尤其是在资源受限且需要平衡准确性和计算成本的情况下。

Abstract: This paper explores the impact of dimensionality reduction and pooling methods for Environmental Sound Classification (ESC) using lightweight CNNs. We evaluate Sparse Salient Region Pooling (SSRP) and its variants, SSRP-Basic (SSRP-B) and SSRP-Top-K (SSRP-T), under various hyperparameter settings and compare them with Principal Component Analysis (PCA). Experiments on the ESC-50 dataset demonstrate that SSRP-T achieves up to 80.69 % accuracy, significantly outperforming both the baseline CNN (66.75 %) and the PCA-reduced model (37.60 %). Our findings confirm that a well-tuned sparse pooling strategy provides a robust, efficient, and high-performing solution for ESC tasks, particularly in resource-constrained scenarios where balancing accuracy and computational cost is crucial.

</details>


### [258] [Massive MIMO-OFDM Channel Acquisition with Multi-group Adjustable Phase Shift Pilots](https://arxiv.org/abs/2511.09826)
*Yu Zhao,Li You,Jinke Tang,Mengyu Qian,Bin Jiang,Xiang-Gen Xia,Xiqi Gao*

Main category: eess.SP

TL;DR: MAPSP通过利用信道稀疏性，在移动场景下通过多组相位调度和Zadoff-Chu序列实现低开销、高频谱效率的信道获取。


<details>
  <summary>Details</summary>
Motivation: 为了在提供显著频谱效率（SE）的同时，应对大规模MIMO-OFDM系统高信道开销的挑战，并进一步提高SE。

Method: 将信道模型从空频域转换到角度-延迟域，提出利用多组基本序列生成MAPSP，并通过相位调度和基于Zadoff-Chu序列的实现方案来克服导频干扰，进而进行信道估计。

Result: MAPSP方法实现了比APSP更低的估计均方误差（MSE），并且在移动场景下显著提高了SE。

Conclusion: MAPSP是一种有效的信道估计技术，通过巧妙的相位调度和序列设计，在保持低开销的同时，能够显著提升大规模MIMO-OFDM系统的频谱效率，尤其是在移动场景下。

Abstract: Massive multiple-input multiple-output - orthogonal frequency division multiplexing (MIMO-OFDM) systems face the challenge of high channel acquisition overhead while providing significant spectral efficiency (SE). Adjustable phase shift pilots (APSPs) are an effective technique to acquire channels with low overhead by exploiting channel sparsity. In this paper, we extend it to multiple groups and propose multi-group adjustable phase shift pilots (MAPSPs) to improve SE further. We first introduce a massive MIMO-OFDM system model and transform the conventional channel model in the space-frequency domain to the angle-delay domain, obtaining a sparse channel matrix. Then, we propose a method of generating MAPSPs through multiple basic sequences and investigate channel estimation processes. By analyzing the components of pilot interference, we elucidate the underlying mechanism by which interference affects MMSE estimation. Building upon this foundation, we demonstrate the benefit of phase scheduling in MAPSP channel estimation and establish the optimal design condition tailored for scheduling. Furthermore, we propose an implementation scheme based on Zadoff-Chu sequences that includes received signal pre-processing and pilot scheduling methods to mitigate pilot interference. Simulation results indicate that the MAPSP method achieves a lower mean square error (MSE) of estimation than APSP and significantly enhances SE in mobility scenarios.

</details>


### [259] [ASSENT: Learning-Based Association Optimization for Distributed Cell-Free ISAC](https://arxiv.org/abs/2511.09992)
*Mehdi Zafari,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: ISAC在分布式部署中存在可扩展性问题，该论文提出了一种基于GNN的名为ASSENT的解决方案，该方案可以有效处理AP聚类、用户/目标调度和AP模式选择问题，并在计算效率和性能方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 分布式ISAC系统在AP聚类、用户/目标调度和AP模式选择方面存在可扩展性问题，现有方法依赖于中心化处理和完整的信道状态信息，限制了系统的性能。

Method: 提出了一种名为ASSENT的图神经网络（GNN）框架，该框架通过在MILP（混合整数线性规划）解决方案上进行训练，可以直接从轻量级链路统计信息中学习关联和模式选择策略。

Result: 仿真结果表明，ASSENT在接近最优的效用下，能够准确地学习底层关联，并且其单次前向传播推理可降低决策延迟。

Conclusion: ASSENT框架能够为分布式ISAC系统提供一种可扩展且高效的解决方案，能够实时处理AP聚类、用户/目标调度和AP模式选择问题，并能实现接近最优的性能。

Abstract: Integrated Sensing and Communication (ISAC) is a key emerging 6G technology. Despite progress, ISAC still lacks scalable methods for joint AP clustering and user/target scheduling in distributed deployments under fronthaul limits. Moreover, existing ISAC solutions largely rely on centralized processing and full channel state information, limiting scalability. This paper addresses joint access point (AP) clustering, user and target scheduling, and AP mode selection in distributed cell-free ISAC systems operating with constrained fronthaul capacity. We formulate the problem as a mixed-integer linear program (MILP) that jointly captures interference coupling, RF-chain limits, and sensing requirements, providing optimal but computationally demanding solutions. To enable real-time and scalable operation, we propose ASSENT (ASSociation and ENTity selection), a graph neural network (GNN) framework trained on MILP solutions to efficiently learn association and mode-selection policies directly from lightweight link statistics. Simulations show that ASSENT achieves near-optimal utility while accurately learning the underlying associations. Additionally, its single forward pass inference reduces decision latency compared to optimization-based methods. An open-source Python/PyTorch implementation with full datasets is provided to facilitate reproducible and extensible research in cell-free ISAC.

</details>


### [260] [Rotatable IRS Aided Wireless Communication](https://arxiv.org/abs/2511.10006)
*Qiaoyan Peng,Qingqing Wu,Guangji Chen,Wen Chen,Shaodan Ma,Shanpu Shen,Rui Zhang*

Main category: eess.SP

TL;DR: 本论文研究了可旋转智能反射面（IRS）在无线通信中的应用，通过联合优化IRS的旋转角度来最大化目标区域内最小信噪比（SNR）。


<details>
  <summary>Details</summary>
Motivation: 为了充分发挥可旋转IRS在无线通信中的潜力，需要解决如何通过调整IRS的方向来优化信号传播的问题。

Method: 论文提出了一个角度相关的信道模型，并针对单点和区域覆盖两种情况，分别采用了基于粒子群优化（PSO）的算法以及结合了空点检测的两层PSO迭代算法来求解最大化最小SNR的问题。

Result: 数值结果表明，所提出的可旋转IRS设计在不同系统设置下，相比于基准方案显著提高了SNR。

Conclusion: 可旋转IRS通过调整其方向，能够有效提升无线通信的SNR，实现比传统IRS更优越的性能。

Abstract: Rotatable intelligent reflecting surface (IRS) introduces a new spatial degree of freedom (DoF) by dynamically adjusting orientations without the need of changing its elements' positions in real time. To unleash the full potential of rotatable IRSs for wireless communications, this paper investigates the joint optimization of IRS rotation angles to maximize the minimum expected signal-to-noise ratio (SNR) over all locations within a given target area. We first propose an angle-dependent channel model that accurately characterizes the reception and reflection of each IRS element. Different from the conventional cosine-law assumption, the proposed model captures the practical electromagnetic characteristics of the IRS, including the effective reception area and reflection efficiency. For the single target location case, a particle swarm optimization (PSO)-based algorithm is developed to solve the SNR maximization problem, and a closed-form expression for a near-optimal solution is derived to provide useful insights. For the general area coverage enhancement case, the optimal rotation is obtained through a two-loop PSO-based iterative algorithm with null-point detection. In this algorithm, the outer loop updates the global rotation angles to maximize the minimum SNR over the target area, whereas the inner loop evaluates the SNR distribution within the area to identify the location corresponding to the minimum SNR through null-point detection. Numerical results demonstrate significant SNR improvement achieved by the proposed rotatable IRS design over various benchmark schemes under different system setups.

</details>


### [261] [Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement](https://arxiv.org/abs/2511.10073)
*Yuhao Ren,Yiting Liu,Yanfei Zhou,Zhiyu Zheng,Li Shang,Fan Yang,Zhiang Wang*

Main category: eess.SP

TL;DR: 提出了一种轻量级联合优化框架，通过引入面积线索细化初始化和宏调度放置过程，解决了现有VLSI全局放置初始化方法在计算成本和面积感知之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的VLSI全局放置初始化方法存在权衡：面积感知方法计算成本高，而快速的点估计方法忽略了单元格面积，导致建模差距，影响收敛性和解的质量。

Method: 提出了一种轻量级联合优化框架，包含两个策略：1. 面积线索细化初始化器，通过增加虚拟节点和负权重边来细化网表图，将单元格面积信息融入有符号图信号。2. 宏调度放置过程，逐步恢复面积约束，实现从细化初始化到完全面积感知目标的平滑过渡。

Result: 在ISPD2015基准和两个真实工业设计上进行了评估。结果表明，与点估计初始化器相比，该方法在12个案例中有11个案例的半周长线长（HPWL）得到改善，HPWL最多降低2.2%，同时运行速度比最先进的面积感知初始化器快约100倍。

Conclusion: 该框架通过一种新颖的初始化方法，在保持高计算效率的同时，显著提高了VLSI全局放置的质量。

Abstract: Global placement is a critical step with high computational complexity in VLSI physical design. Modern analytical placers formulate the placement problem as a nonlinear optimization, where initialization strongly affects both convergence behavior and final placement quality. However, existing initialization methods exhibit a trade-off: area-aware initializers account for cell areas but are computationally expensive and can dominate total runtime, while fast point-based initializers ignore cell area, leading to a modeling gap that impairs convergence and solution quality. We propose a lightweight co-optimization framework that bridges this initialization gap through two strategies. First, an area-hint refinement initializer incorporates heuristic cell area information into a signed graph signal by augmenting the netlist graph with virtual nodes and negative-weight edges, yielding an area-aware and spectrally smooth placement initialization. Second, a macro-schedule placement procedure progressively restores area constraints, enabling a smooth transition from the refined initializer to the full area-aware objective and producing high-quality placement results. We evaluate the framework on macro-heavy ISPD2005 academic benchmarks and two real-world industrial designs across two technology nodes (12 cases in total). Experimental results show that our method consistently improves half-perimeter wirelength (HPWL) over point-based initializers in 11 out of 12 cases, achieving up to 2.2% HPWL reduction, while running approximately 100 times faster than the state-of-the-art area-aware initializer.

</details>


### [262] [NOMA-Enabled Dual-IRS Relay Network Integrated with Ambient Backscatter Communication](https://arxiv.org/abs/2511.10178)
*Chandrima Thakur,Priyanka Ghosh,Rashmita Badhai,Sumit Kundu*

Main category: eess.SP

TL;DR: 该论文提出了一种结合了NOMA、双智能反射面（IRS）和环境回溯（BS）通信的继电器网络模型。利用时间切换中继（TSR）协议，继电器在收集能量和转发信息的同时，还能支持BS通信。两个IRS用于改善信号在可能中断的链路中的传输。论文推导了主通信链路和BS辅助链路的断话概率（OP）和吞吐量的解析表达式，并分析了在不同系统参数下的吞吐量表现。仿真结果验证了理论分析的准确性，并揭示了主链路和RS链路之间的关键权衡。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决物联网应用中对可靠且节能的NOMA-IRS辅助BS网络的需求，特别是在存在阻塞条件和能量约束的情况下。

Method: 该研究提出了一种NOMA使能的双IRS中继网络模型，其中继电器采用时间切换继电器（TSR）协议进行能量收集和信息转发，并支持BS通信。两个IRS用于增强S到R以及R到（D1, D2）的链路。论文推导了主通信链路和BS辅助链路的断话概率（OP）和吞吐量的闭式表达式，并通过蒙特卡洛仿真进行了验证。

Result: 论文成功推导了主通信链路和BS辅助链路的断话概率（OP）和吞吐量的解析表达式，并通过蒙特卡洛仿真验证了结果。数值结果揭示了主链路和RS链路之间的关键权衡，并为设计可靠和节能的NOMA-IRS辅助BS网络提供了见解。

Conclusion: 该研究提出的NOMA-IRS辅助BS网络模型，通过结合TSR协议和IRS技术，在能量效率和可靠性方面取得了良好效果，并为未来物联网应用提供了有价值的设计参考。

Abstract: This paper analyzes a NOMA-enabled dual-Intelligent Reflecting Surface (IRS) relay network integrated with Ambient Backscatter (BS) communication. The system comprises a source, an energy-constrained relay with energy harvesting (EH) and BS capabilities, two NOMA users, and a BS node. The relay adopts a time-switching relaying (TSR) protocol to harvest energy and forward information ,while simultaneously enabling BS-based communication. Two IRS are deployed to enhance the S to R and R to (D1, D2) links under blockage conditions. Closed-form expressions for the Outage Probability (OP) and Throughput of both the main communication links and the BS-assisted secondary links are derived. Furthermore, throughput is analyzed under varying system parameters, including power allocation factors, reflection efficiency, IRS elements, and transmission rate. Monte Carlo simulations validate the analytical results. numerical findings reveal critical trade-offs between the main and RS links. The proposed framework provides useful insights for designing reliable and energy-efficient NOMA-IRS-aided BS networks for future IoT applications.

</details>


### [263] [High Order Delta-Sigma Modulation with Positive Integer Coefficients](https://arxiv.org/abs/2511.10205)
*Martin J. W. Schubert*

Main category: eess.SP

TL;DR: The paper proposes binomial integer parameters for cascaded Delta-Sigma-modulators to achieve high orders and discusses coefficient accuracy.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enable high orders in cascaded Delta-Sigma-modulator structures with distributed feedback and feedforward, using binomial integer parameters.

Method: The method involves proposing and utilizing binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback, distributed feedforward input, and multi-bit output.

Result: The paper demonstrates that high orders can be achieved with these binomial integer coefficients.

Conclusion: The paper discusses the accuracy requirements for these coefficients, implying that achieving high orders is feasible with careful consideration of coefficient precision.

Abstract: This document proposes binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback and distributed feedforward input and multi-bit output. It is demonstrated that high orders can be achieved with these coefficients. Accuracy requirements concerning the coefficients are discussed.

</details>


### [264] [Semantic Communication with Hopfield Memories](https://arxiv.org/abs/2511.10302)
*Karim Nasreddine,Christo Kurisummoottil Thomas,Walid Saad*

Main category: eess.SP

TL;DR: 该研究提出了一种基于现代霍普菲尔德网络（MHN）的记忆增强型语义通信框架，以解决传统联合信源信道编码中静态语义表示无法适应动态变化的数据分布的问题。该框架利用软注意力机制的检索功能，能够随着数据变化平滑地调整存储的语义原型权重，从而在数据动态变化下做出稳定的匹配决策，有效减少了带宽使用。


<details>
  <summary>Details</summary>
Motivation: 传统联合信源信道编码的静态语义表示无法适应数据分布的动态变化，基于变分自编码器的硬量化方法在数据动态变化时频繁更新内存，导致带宽利用效率低下。

Method: 提出了一种记忆增强型语义通信框架，其中发送端和接收端使用现代霍普菲尔德网络（MHN）维护共享的语义概念内存。该框架采用基于软注意力的检索机制，能够平滑调整存储的语义原型权重，并与编码器、解码器和内存检索机制进行联合优化，以最大化量化语义效率的推理能力指标（内存重用率与压缩率的乘积）。

Result: 与基线方法相比，所提出的基于 MHN 的方法在各种视频场景中平均实现了约 14% 的比特率削减，在内容缓慢变化的场景中甚至高达 70%。理论分析表明，在有界语义漂移下，软检索相比硬量化能减少不必要的传输。

Conclusion: 所提出的基于 MHN 的记忆增强型语义通信框架能够有效适应数据动态变化，显著提高带宽利用率，并在视频通信等场景中实现可观的比特率削减。

Abstract: Traditional joint source-channel coding employs static learned semantic representations that cannot dynamically adapt to evolving source distributions. Shared semantic memories between transmitter and receiver can potentially enable bandwidth savings by reusing previously transmitted concepts as context to reconstruct data, but require effective mechanisms to determine when current content is similar enough to stored patterns. However, existing hard quantization approaches based on variational autoencoders are limited by frequent memory updates even under small changes in data dynamics, which leads to inefficient usage of bandwidth.To address this challenge, in this paper, a memory-augmented semantic communication framework is proposed where both transmitter and receiver maintain a shared memory of semantic concepts using modern Hopfield networks (MHNs). The proposed framework employs soft attention-based retrieval that smoothly adjusts stored semantic prototype weights as data evolves that enables stable matching decisions under gradual data dynamics. A joint optimization of encoder, decoder, and memory retrieval
  mechanism is performed with the objective of maximizing a reasoning capacity metric that quantifies semantic efficiency as the product of memory reuse rate and compression ratio. Theoretical analysis establishes the fundamental rate-distortion-reuse tradeoff and proves that soft retrieval reduces unnecessary transmissions compared to hard quantization under bounded semantic drift. Extensive simulations over diverse video scenarios demonstrate that the proposed MHN-based approach achieves substantial bit reductions around 14% on average and up to 70% in scenarios with gradual content changes compared to baseline.

</details>


### [265] [Evaluation of Grid-based Uncertainty Propagation for Collaborative Self-Calibration in Indoor Positioning Systems](https://arxiv.org/abs/2511.10526)
*Andrea Jung,Paul Schwarzbach,Oliver Michler*

Main category: eess.SP

TL;DR: 本研究提出了一种用于UWB网络的协作自校准方法，使用离散贝叶斯方法和基于网格的不确定性传播，无需预先标定的参考点，可降低部署成本和时间。


<details>
  <summary>Details</summary>
Motivation: 传统的无线电定位系统需要预先标定位置的固定参考点，部署过程耗时且成本高。本研究旨在解决这一问题，提出一种无需手动校准的方法。

Method: 采用离散贝叶斯方法和基于网格的不确定性传播，通过概率状态估计来降低测量可用性要求并保持定位精度。

Result: 在包含12个节点的室内UWB网络实验中，该方法在视线传播条件下实现了0.28米的平均测距误差，在混合传播场景下实现了1.11米的整体测距误差，并达到了亚米级的定位精度。结果表明该算法对测量噪声和工业部署中常见的连接不完全场景具有鲁棒性。

Conclusion: 本研究提出的协作自校准算法能够实现UWB网络的自动化初始化，减少对手动校准基础设施的依赖，适用于室内定位应用。

Abstract: Radio-based localization systems conventionally require stationary reference points (e.g. anchors) with precisely surveyed positions, making deployment time-consuming and costly. This paper presents an empirical evaluation of collaborative self-calibration for Ultra-Wideband (UWB) networks, extending a discrete Bayesian approach based on grid-based uncertainty propagation. The enhanced algorithm reduces measurement availability requirements while maintaining positioning accuracy through probabilistic state estimation. We validate the approach using real-world data from controlled indoor UWB network experiments with 12 nodes in a static environment. Experimental evaluation demonstrates 0.28~m mean ranging error under line-of-sight conditions and 1.11~m overall ranging error across mixed propagation scenarios, achieving sub-meter positioning accuracy. Results demonstrate the algorithm's robustness to measurement noise and partial connectivity scenarios typical in industrial deployments. The findings contribute to automated UWB network initialization for indoor positioning applications, reducing infrastructure dependency compared to manual anchor calibration procedures.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [266] [UCPO: A Universal Constrained Combinatorial Optimization Method via Preference Optimization](https://arxiv.org/abs/2511.10148)
*Zhanhong Fang,Debing Wang,Jinbiao Chen,Jiahai Wang,Zizhen Zhang*

Main category: cs.NE

TL;DR: UCPO是一个即插即用框架，通过一种特殊的损失函数将偏好学习集成到现有的神经求解器中，以处理组合优化中的复杂约束。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器在处理具有复杂约束的问题时效果不佳，因为简单的掩蔽机制无法有效管理这些约束。UCPO旨在解决这一局限性。

Method: UCPO将约束满足直接嵌入基于偏好的目标中，并且不需要对现有神经求解器的架构进行修改。它还利用了一种轻量级的预训练模型微调方案。

Result: UCPO能够使预训练模型在具有挑战性的、带有约束的任务上持续生成接近最优的可行解，并且在只有原始训练预算的1%的情况下就能实现出色的性能。

Conclusion: UCPO通过将约束满足直接嵌入基于偏好的目标中，并利用轻量级的微调方案，有效地解决了现有神经求解器在处理复杂约束方面的局限性，从而在组合优化任务中实现了近乎最优且可行的解决方案。

Abstract: Neural solvers have demonstrated remarkable success in combinatorial optimization, often surpassing traditional heuristics in speed, solution quality, and generalization. However, their efficacy deteriorates significantly when confronted with complex constraints that cannot be effectively managed through simple masking mechanisms. To address this limitation, we introduce Universal Constrained Preference Optimization (UCPO), a novel plug-and-play framework that seamlessly integrates preference learning into existing neural solvers via a specially designed loss function, without requiring architectural modifications. UCPO embeds constraint satisfaction directly into a preference-based objective, eliminating the need for meticulous hyperparameter tuning. Leveraging a lightweight warm-start fine-tuning protocol, UCPO enables pre-trained models to consistently produce near-optimal, feasible solutions on challenging constraint-laden tasks, achieving exceptional performance with as little as 1\% of the original training budget.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [267] [Ksurf-Drone: Attention Kalman Filter for Contextual Bandit Optimization in Cloud Resource Allocation](https://arxiv.org/abs/2511.09766)
*Michael Dang'ana,Yuqiu Zhang,Hans-Arno Jacobsen*

Main category: cs.DC

TL;DR: Ksurf优化了Drone在云环境中的资源编排，显著降低了延迟方差、CPU使用率和内存占用，并实现了成本节约。


<details>
  <summary>Details</summary>
Motivation: 云数据中心容器化基础设施的资源编排和配置参数搜索是关键问题，但云环境的不确定性和复杂性（如虚拟机数量变化、工作负载和资源指标的变异性）导致资源编排决策不准确。

Method: 评估Ksurf在Drone编排任务中的性能，Ksurf作为一种方差最小化估计器，被用作上下文多臂老虎机目标函数模型，以应对高变异性的云数据。

Result: Ksurf 在 p95 延迟方差上降低了 41%，在 p99 延迟方差上降低了 47%，CPU 使用率降低了 4%，Master 节点内存占用减少了 7 MB。在 VarBench Kubernetes 基准测试中，平均 Worker Pod 数量减少了 7%，实现了成本节约。

Conclusion: Ksurf 能够有效处理高变异性的工作负载，显著提高了资源编排的性能并降低了成本。

Abstract: Resource orchestration and configuration parameter search are key concerns for container-based infrastructure in cloud data centers. Large configuration search space and cloud uncertainties are often mitigated using contextual bandit techniques for resource orchestration including the state-of-the-art Drone orchestrator. Complexity in the cloud provider environment due to varying numbers of virtual machines introduces variability in workloads and resource metrics, making orchestration decisions less accurate due to increased nonlinearity and noise. Ksurf, a state-of-the-art variance-minimizing estimator method ideal for highly variable cloud data, enables optimal resource estimation under conditions of high cloud variability.
  This work evaluates the performance of Ksurf on estimation-based resource orchestration tasks involving highly variable workloads when employed as a contextual multi-armed bandit objective function model for cloud scenarios using Drone. Ksurf enables significantly lower latency variance of $41\%$ at p95 and $47\%$ at p99, demonstrates a $4\%$ reduction in CPU usage and 7 MB reduction in master node memory usage on Kubernetes, resulting in a $7\%$ cost savings in average worker pod count on VarBench Kubernetes benchmark.

</details>


### [268] [A Poly-Log Approximation for Transaction Scheduling in Fog-Cloud Computing and Beyond](https://arxiv.org/abs/2511.09776)
*Ramesh Adhikari,Costas Busch,Pavan Poudel*

Main category: cs.DC

TL;DR: 该研究提出了一种在雾-云计算模型中优化事务调度的算法，以最小化资源分配的总成本。


<details>
  <summary>Details</summary>
Motivation: 在分布式系统中，事务调度对于无冲突地分配共享资源至关重要。本研究旨在解决雾-云计算模型中事务的调度问题，其中事务和共享对象可以在网络中移动，需要最小化移动和会面成本。

Method: 研究人员提出了一种调度算法，该算法考虑了对象移动到事务节点、事务移动到对象节点或两者在中介节点相遇的情况。他们首先处理单个共享对象（所有事务访问该对象）和多个共享对象（每个事务最多访问k个对象）的场景，并为两种情况提供了近似算法。此外，还提供了一种完全分布式的算法版本。

Result: 对于单个共享对象，算法提供了 $O("egularfont 	ext{log } n 	ext{cdot } 	ext{log } D	ext{"})$ 的近似比，其中 n 是节点数，D 是网络直径。对于每个事务最多 k 个共享对象的情况，近似比提高到 $O(k 	ext{cdot } 	ext{log } n 	ext{cdot } 	ext{log } D)$。

Conclusion: 研究提出了雾-云计算模型中事务调度的近似算法，并在理论上证明了其近似比。该算法在常数双曲维度的网络中表现良好，并提供了分布式版本以适应缺乏全局知识的场景。

Abstract: Transaction scheduling is crucial to efficiently allocate shared resources in a conflict-free manner in distributed systems. We investigate the efficient scheduling of transactions in a network of fog-cloud computing model, where transactions and their associated shared objects can move within the network. The schedule may require objects to move to transaction nodes, or the transactions to move to the object nodes. Moreover, the schedule may determine intermediate nodes where both objects and transactions meet. Our goal is to minimize the total combined cost of the schedule. We focus on networks of constant doubling dimension, which appear frequently in practice. We consider a batch problem where an arbitrary set of nodes has transactions that need to be scheduled. First, we consider a single shared object required by all the transactions and present a scheduling algorithm that gives an $O(\log n \cdot \log D)$ approximation of the optimal schedule, where $n$ is the number of nodes and $D$ is the diameter of the network. Later, we consider transactions accessing multiple shared objects (at most $k$ objects per transaction) and provide a scheduling algorithm that gives an $O(k \cdot \log n \cdot \log D)$ approximation. We also provide a fully distributed version of the scheduling algorithms where the nodes do not need global knowledge of transactions.

</details>


### [269] [MoFa: A Unified Performance Modeling Framework for LLM Pretraining](https://arxiv.org/abs/2511.09837)
*Lu Zhao,Rong Shi,Shaoqing Zhang,Shangchao Su,Ziqing Yin,Zhiyan Cui,Hongfeng Sun,Baoguo He,Yueqiang Chen,Liang Dong,Xiyuan Li,Lingbin Wang,Lijun Ma,Qiang Huang,Ting Liu,Chong Wang,Can Wei*

Main category: cs.DC

TL;DR: LLM预训练面临优化挑战，提出MoFa框架统一考虑多维度优化和容错机制，以提高性能预测和指导系统设计。


<details>
  <summary>Details</summary>
Motivation: 现有LLM预训练性能建模方法未能全面考虑优化特性和容错机制（如检查点恢复）带来的开销，导致调优成本高昂。

Method: 提出MoFa框架，包含增强的成本模型以捕捉关键优化效果，并整合基于历史可靠性数据的容错模型。开发了基于MoFa的调优系统来探索最佳性能和潜在瓶颈。

Result: MoFa在各种场景下实现了高预测精度。调优实验系统性地揭示了影响预训练性能的关键因素。

Conclusion: MoFa框架能准确预测LLM预训练性能，并为系统设计和部署提供先验指导。

Abstract: The exponential growth in LLM scales, with parameters soaring from billions to trillions, has necessitated distributed pretraining across large clusters comprising thousands to tens of thousands of devices. While hybrid parallelization strategies enable such pretraining, the vast combinatorial strategy space introduces significant optimization challenges. Traditional manual tuning methods incur prohibitive trial-and-error costs, and existing performance modeling approaches exhibit critical limitations: they fail to comprehensively account for prevalent optimization features and ignore the substantial overhead imposed by essential fault tolerance mechanisms like checkpoint recovery in long-duration pretraining. To address these gaps, we propose MoFa, a novel pretraining performance modeling framework that unifies multi-dimensional optimization features and fault tolerance. MoFa incorporates an enhanced cost model to accurately capture the effects of key optimizations and integrates a fault tolerance model based on historical cluster reliability data. Besides, a MoFa-based tuning system is developed to explore optimal pretraining performance and potential bottlenecks in various scenarios. Extensive modeling evaluations demonstrate that MoFa can achieve high prediction accuracy across various scenarios. In addition, through comprehensive tuning experiments, our framework systematically reveals the key factors influencing pretraining performance under different configurations, which provides solid a priori guidance for LLM pretraining system design and deployment.

</details>


### [270] [Lit Silicon: A Case Where Thermal Imbalance Couples Concurrent Execution in Multiple GPUs](https://arxiv.org/abs/2511.09861)
*Marco Kurzynski,Shaizeen Aga,Di Wu*

Main category: cs.DC

TL;DR: GPU在数据中心的应用日益广泛，但其性能易受节点和集群层面性能波动的影响，尤其在LLM训练等AI工作负载中。本文将这种性能波动归因于“Lit Silicon”效应，即多GPU节点内的热失衡导致部分GPU成为“拖尾者”，进而拖慢其他GPU，造成整体性能下降和效率低下。作者提出了分析模型来理解和量化Lit Silicon效应，并设计了检测和缓解技术。通过在AMD MI300X GPU系统和LLM训练框架上进行实验，验证了其提出的电源管理方案，可带来高达6%的性能提升和4%的功耗降低，有望为数据中心节省巨额成本。


<details>
  <summary>Details</summary>
Motivation: GPU系统在现代数据中心广泛应用，但存在性能波动问题，影响高性能计算和AI（如LLM）工作负载。

Method: 分析了单节点多GPU系统运行LLM训练时的性能，发现核级性能波动与计算通信并发（C3）技术相关。提出“Lit Silicon”效应，即热失衡导致的GPU拖尾现象影响整体性能。构建了Lit Silicon的性能和功耗分析模型，并设计了检测和缓解技术，评估了三种电源管理方案：GPU热设计功耗优化、节点级GPU功耗上限下的性能优化、节点级CPU功耗波动下的性能优化。

Result: 在AMD Instinct MI300X GPU系统和LLM训练框架上进行实验，观察到所提出的方案可实现高达6%的性能提升和4%的功耗降低。

Conclusion: Lit Silicon效应是导致多GPU节点性能波动和效率低下的关键因素。作者提出的分析模型和电源管理技术（包括检测与缓解）能够有效解决此问题，并能轻易集成到数据中心作为新的节点级电源管理层，带来显著的性能和功耗改善。

Abstract: GPU systems are increasingly powering modern datacenters at scale. Despite being highly performant, GPU systems suffer from performance variation at the node and cluster levels. Such performance variation significantly impacts both high-performance computing and artificial intelligence workloads, such as cutting-edge large language models (LLMs). We analyze the performance of a single-node multi-GPU system running LLM training, and observe that the kernel-level performance variation is highly correlated with concurrent computation communication (C3), a technique to overlap computation and communication across GPUs for performance gains. We then take a further step to reason that thermally induced straggling coupling with C3 impacts performance variation, coined as the Lit Silicon effect. Lit Silicon describes that in a multi-GPU node, thermal imbalance across GPUs introduces node-level straggler GPUs, which in turn slow down the leader GPUs. Lit Silicon leads to node-level performance variation and inefficiency, impacting the entire datacenter from the bottom up. We propose analytical performance and power models for Lit Silicon, to understand the potential system-level gains. We further design simple detection and mitigation techniques to effectively address the Lit Silicon problem, and evaluate three different power management solutions, including power optimization under GPU thermal design power, performance optimization under node-level GPU power capping, and performance optimization under node-level CPU power sloshing. We conduct experiments on two workloads on two AMD InstinctTM MI300X GPU systems under two LLM training frameworks, and observe up to 6% performance and 4% power improvements, potentially saving hundreds of millions of dollars in datacenters. Our solution is almost free lunch and can be effortlessly adopted in datacenters as a new node-level power management layer.

</details>


### [271] [Optimizing CPU Cache Utilization in Cloud VMs with Accurate Cache Abstraction](https://arxiv.org/abs/2511.09956)
*Mani Tofigh,Edward Guo,Weiwei Jia,Xiaoning Ding,Jianchen Shan*

Main category: cs.DC

TL;DR: 在云虚拟机（VM）中，由于对提供的缓存可见性和控制有限，基于缓存的优化通常效果不佳。云虚拟机无法感知缓存分配细节，也无法通过页面放置策略影响缓存使用。


<details>
  <summary>Details</summary>
Motivation: 公共云中的CPU缓存可能在VM之间分区或共享，但VM对此一无所知，也无法影响缓存使用。

Method: 提出了一种名为CacheX的新颖解决方案，它在VM内部使用驱逐集（eviction sets）来探测精确的、细粒度的缓存抽象，而无需硬件或管理程序支持。CacheX还展示了其探测信息的效用，通过两种新技术：LLC争用感知任务调度和虚拟颜色感知页面缓存管理。

Result: 在x86 Linux内核中实现的CacheX，通过有效利用缓存，能够提高公共云VM中各种工作负载的缓存利用率。

Conclusion: CacheX提供了一种在云虚拟机中有效进行缓存优化的方法。

Abstract: This paper shows that cache-based optimizations are often ineffective in cloud virtual machines (VMs) due to limited visibility into and control over provisioned caches. In public clouds, CPU caches can be partitioned or shared among VMs, but a VM is unaware of cache provisioning details. Moreover, a VM cannot influence cache usage via page placement policies, as memory-to-cache mappings are hidden. The paper proposes a novel solution, CacheX, which probes accurate and fine-grained cache abstraction within VMs using eviction sets without requiring hardware or hypervisor support, and showcases the utility of the probed information with two new techniques: LLC contention-aware task scheduling and virtual color-aware page cache management. Our evaluation of CacheX's implementation in x86 Linux kernel demonstrates that it can effectively improve cache utilization for various workloads in public cloud VMs.

</details>


### [272] [Dynamic Edge Server Selection in Time-Varying Environments: A Reliability-Aware Predictive Approach](https://arxiv.org/abs/2511.10146)
*Jaime Sebastian Burbano,Arnova Abdullah,Eldiyar Zhantileuov,Mohan Liyanage,Rolf Schuster*

Main category: cs.DC

TL;DR: 该研究提出了一种名为MO-HAN的轻量级服务器选择方法，用于解决边缘计算中网络拥堵导致的服务器选择问题。该方法结合了延迟预测、自适应可靠性和基于滞后的切换机制，能在保证低端到端延迟的同时，减少不必要的服务器切换，且适用于资源受限的嵌入式设备。


<details>
  <summary>Details</summary>
Motivation: 多服务器边缘计算架构中的网络动态拥堵问题，对边缘服务器的选择提出了挑战，影响了延迟敏感型嵌入式应用的性能。

Method: MO-HAN方法利用被动测量（如到达率、利用率、负载大小）和一个指数调制有理延迟模型，计算一个平衡了预测延迟和可靠性的分数，确保只有在预期收益有意义时才进行切换，并减少端到端延迟。

Result: MO-HAN方法在降低平均和尾部延迟方面持续优于静态和公平分配基线方法，并将切换次数减少了近50%，同时无需侵入式仪器或复杂的学习基础设施。

Conclusion: MO-HAN方法通过结合延迟预测、自适应可靠性和滞后切换，能够有效解决边缘计算中的服务器选择问题，在资源受限的嵌入式设备上实现了低延迟和高效率，并且非常实用。

Abstract: Latency-sensitive embedded applications increasingly rely on edge computing, yet dynamic network congestion in multi-server architectures challenges proper edge server selection. This paper proposes a lightweight server-selection method for edge applications that fuses latency prediction with adaptive reliability and hysteresis-based handover. Using passive measurements (arrival rate, utilization, payload size) and an exponentially modulated rational delay model, the proposed Moderate Handover (MO-HAN) method computes a score that balances predicted latency and reliability to ensure handovers occur only when the expected gain is meaningful and maintain reduced end-to-end latency. Results show that MO-HAN consistently outperforms static and fair-distribution baselines by lowering mean and tail latencies, while reducing handovers by nearly 50% compared to pure opportunistic selection. These gains arise without intrusive instrumentation or heavy learning infrastructure, making MO-HAN practical for resource-constrained embedded devices.

</details>


### [273] [Selection of Supervised Learning-based Sparse Matrix Reordering Algorithms](https://arxiv.org/abs/2511.10180)
*Tao Tang,Youfu Jiang,Yingbo Cui,Jianbin Fang,Peng Zhang,Lin Peng,Chun Huang*

Main category: cs.DC

TL;DR: 通过引入基于监督学习的模型来自动化选择稀疏矩阵重排算法，实验结果显示可显著减少求解时间。


<details>
  <summary>Details</summary>
Motivation: 传统的稀疏矩阵排序算法选择依赖于穷举搜索或经验知识，无法适应不同的稀疏矩阵结构。因此，需要一种能够根据矩阵特性自动选择合适重排算法的方法。

Method: 提出了一种基于监督学习的模型，该模型学习矩阵特征与常用重排算法之间的关联，以实现自动化和智能化的选择。

Result: 在弗罗里达稀疏矩阵数据集上进行实验，结果表明该模型能准确预测最优重排算法，与单独使用 AMD 算法相比，求解时间减少了 55.37%，平均加速比为 1.45。

Conclusion: 所提出的监督学习模型能够有效解决稀疏矩阵排序中的算法选择问题，并在实际应用中带来了显著的性能提升。

Abstract: Sparse matrix ordering is a vital optimization technique often employed for solving large-scale sparse matrices. Its goal is to minimize the matrix bandwidth by reorganizing its rows and columns, thus enhancing efficiency. Conventional methods for algorithm selection usually depend on brute-force search or empirical knowledge, lacking the ability to adjust to diverse sparse matrix structures.As a result, we have introduced a supervised learning-based model for choosing sparse matrix reordering algorithms. This model grasps the correlation between matrix characteristics and commonly utilized reordering algorithms, facilitating the automated and intelligent selection of the suitable sparse matrix reordering algorithm. Experiments conducted on the Florida sparse matrix dataset reveal that our model can accurately predict the optimal reordering algorithm for various matrices, leading to a 55.37% reduction in solution time compared to solely using the AMD reordering algorithm, with an average speedup ratio of 1.45.

</details>


### [274] [Workload Schedulers -- Genesis, Algorithms and Differences](https://arxiv.org/abs/2511.10258)
*Leszek Sliwko,Vladimir Getov*

Main category: cs.DC

TL;DR: 本篇论文提出了一种现代工作负载调度器的分类新方法，描述了操作系统进程调度器、集群系统作业调度器和大数据调度器这三类调度器，并探讨了它们的演变、算法和特性。总结了各类调度器的异同，并指出了它们在调度策略设计上的相似性。


<details>
  <summary>Details</summary>
Motivation: 对现代工作负载调度器进行分类，并描述它们的演变、算法和特性。

Method: 提出了一种新的分类方法，并对操作系统进程调度器、集群系统作业调度器和大数据调度器进行了分类和描述。

Result: 对三种调度器进行了分类，并描述了它们的演变、算法和特性，指出了它们之间的异同和共同点。

Conclusion: 现代工作负载调度器在设计策略上具有相似性，这些策略适用于本地和分布式系统。

Abstract: This paper presents a novel approach to categorization of modern workload schedulers. We provide descriptions of three classes of schedulers: Operating Systems Process Schedulers, Cluster Systems Jobs Schedulers and Big Data Schedulers. We describe their evolution from early adoptions to modern implementations, considering both the use and features of algorithms. In summary, we discuss differences between all presented classes of schedulers and discuss their chronological development. In conclusion we highlight similarities in the focus of scheduling strategies design, applicable to both local and distributed systems.

</details>


### [275] [FastGraph: Optimized GPU-Enabled Algorithms for Fast Graph Building and Message Passing](https://arxiv.org/abs/2511.10442)
*Aarush Agarwal,Raymond He,Jan Kieseler,Matteo Cremonesi,Shah Rukh Qasim*

Main category: cs.DC

TL;DR: FastGraph是一个GPU加速的kNN算法，用于低维空间（2-10维）的图构建，能显著提升GNN性能。


<details>
  <summary>Details</summary>
Motivation: 在低维空间（2-10维）中加速图构建，以支持高性能图神经网络（GNN）。

Method: 采用GPU常驻的、支持完整梯度流和自适应参数调优的二进制分区方法。

Result: 在10维以下实现了20-40倍于FAISS、ANNOY和SCANN等库的加速，且内存开销极小。

Conclusion: FastGraph能显著提升GNN工作流程的性能，特别是在高能物理中的粒子聚类、视觉对象跟踪和图聚类等低维计算密集型应用中。

Abstract: We introduce FastGraph, a novel GPU-optimized k-nearest neighbor algorithm specifically designed to accelerate graph construction in low-dimensional spaces (2-10 dimensions), critical for high-performance graph neural networks. Our method employs a GPU-resident, bin-partitioned approach with full gradient-flow support and adaptive parameter tuning, significantly enhancing both computational and memory efficiency. Benchmarking demonstrates that FastGraph achieves a 20-40x speedup over state-of-the-art libraries such as FAISS, ANNOY, and SCANN in dimensions less than 10 with virtually no memory overhead. These improvements directly translate into substantial performance gains for GNN-based workflows, particularly benefiting computationally intensive applications in low dimensions such as particle clustering in high-energy physics, visual object tracking, and graph clustering.

</details>


### [276] [Scalable Synthesis of distributed LLM workloads through Symbolic Tensor Graphs](https://arxiv.org/abs/2511.10480)
*Changhai Man,Joongun Park,Hanjiang Wu,Huan Xu,Srinivas Sridharan,Tushar Krishna*

Main category: cs.DC

TL;DR: STAGE是一个合成LLM工作负载执行跟踪的框架，支持广泛的并行策略和系统配置，可扩展至32K GPU，并保持张量级精度。


<details>
  <summary>Details</summary>
Motivation: 需要一个可扩展且富有表现力的机制来模拟大规模AI训练和推理系统的分布式工作负载执行，以进行预部署系统级优化和设计空间探索。现有方法受限于实际系统访问和对未来更大规模系统配置的适应性。

Method: 介绍了一个名为STAGE（Symbolic Tensor grAph GEnerator）的框架，该框架合成了高保真执行跟踪来准确模拟LLM工作负载。STAGE支持全面的并行策略，使用户能够系统地探索LLM架构和系统配置的广泛范围。

Result: STAGE展示了其可扩展性，能够合成跨越32K GPU的高保真LLM跟踪，同时在计算、内存和通信方面保持张量级精度。

Conclusion: STAGE是一个可扩展的框架，能够合成高保真LLM执行跟踪，支持广泛的LLM架构和系统配置的探索，并对大规模分布式AI训练和推理系统进行优化。该工具将公开提供，以促进分布式机器学习系统的进一步研究。

Abstract: Optimizing the performance of large language models (LLMs) on large-scale AI training and inference systems requires a scalable and expressive mechanism to model distributed workload execution. Such modeling is essential for pre-deployment system-level optimizations (e.g., parallelization strategies) and design-space explorations. While recent efforts have proposed collecting execution traces from real systems, access to large-scale infrastructure remains limited to major cloud providers. Moreover, traces obtained from existing platforms cannot be easily adapted to study future larger-scale system configurations. We introduce Symbolic Tensor grAph GEnerator(STAGE), a framework that synthesizes high-fidelity execution traces to accurately model LLM workloads. STAGE supports a comprehensive set of parallelization strategies, allowing users to systematically explore a wide spectrum of LLM architectures and system configurations. STAGE demonstrates its scalability by synthesizing high-fidelity LLM traces spanning over 32K GPUs, while preserving tensor-level accuracy in compute, memory, and communication. STAGE will be publicly available to facilitate further research in distributed machine learning systems.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [277] [History-Aware Trajectory k-Anonymization Using an FPGA-Based Hardware Accelerator for Real-Time Location Services](https://arxiv.org/abs/2511.09688)
*Hiroshi Nakano,Hiroaki Nishi*

Main category: cs.AR

TL;DR: 本研究提出了一种新的、面向历史的轨迹k-匿名化方法，并设计了相应的FPGA硬件架构，实现了实时、高保真度的轨迹匿名化。


<details>
  <summary>Details</summary>
Motivation: 之前的基于FPGA的实时轨迹匿名化方法仅依赖于最短路径计算，无法准确反映实际出行行为，降低了匿名化数据的可用性。

Method: 提出了一种新的、面向历史的轨迹k-匿名化方法，并设计了相应的FPGA硬件架构。该架构结合了基于历史的并行轨迹搜索和传统的最短路径查找，并使用定制的定点计数模块来权衡历史数据的影响，优先选择行为上常见的路径。

Result: FPGA实现达到了超过6000条/秒的实时吞吐量，数据保留率比之前仅使用最短路径的方法提高了1.2%，并且能更好地保留主要的干道信息。

Conclusion: 新方法实现了高保真度、面向历史的匿名化，在满足LBS严格延迟限制的同时，兼顾了隐私保护和行为准确性。

Abstract: Our previous work established the feasibility of FPGA-based real-time trajectory anonymization, a critical task for protecting user privacy in modern location-based services (LBS). However, that pioneering approach relied exclusively on shortest-path computations, which can fail to capture re- alistic travel behavior and thus reduce the utility of the anonymized data. To address this limitation, this paper introduces a novel, history-aware trajectory k-anonymization methodology and presents an advanced FPGA-based hardware architecture to implement it. Our proposed architecture uniquely integrates par- allel history-based trajectory searches with conventional shortest- path finding, using a custom fixed-point counting module to ac- curately weigh contributions from historical data. This approach enables the system to prioritize behaviorally common routes over geometrically shorter but less-traveled paths. The FPGA implementation demonstrates that our new architecture achieves a real-time throughput of over 6,000 records/s, improves data retention by up to 1.2% compared to our previous shortest-path- only design, and preserves major arterial roads more effectively. These results signify a key advancement, enabling high-fidelity, history-aware anonymization that preserves both privacy and behavioral accuracy under the strict latency constraints of LBS.

</details>


### [278] [AssertMiner: Module-Level Spec Generation and Assertion Mining using Static Analysis Guided LLMs](https://arxiv.org/abs/2511.10007)
*Hongqin Lyu,Yonghao Wang,Jiaxin Zhou,Zhiteng Chao,Tiancheng Wang,Huawei Li*

Main category: cs.AR

TL;DR: AssertMiner是一个新的模块级断言生成框架，通过利用抽象语法树（AST）生成的静态信息来辅助大型语言模型（LLM）挖掘断言，解决了现有方法仅生成顶层断言的局限性，提高了验证的覆盖率和错误检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于设计说明的断言生成方法通常只生成顶层断言，忽略了微架构级别模块的验证需求，而设计错误更频繁地出现在这些模块中。

Method: AssertMiner框架通过执行基于AST的结构提取来生成模块调用图、I/O表和数据流图，然后利用这些信息来指导LLM生成模块级说明和挖掘模块级断言。

Result: AssertMiner在生成高质量模块级断言方面优于AssertLLM和Spec2Assertion等现有方法，并能显著提高结构覆盖率和错误检测能力。

Conclusion: AssertMiner通过利用AST信息辅助LLM挖掘模块级断言，能够实现更全面、更高效的验证过程。

Abstract: Assertion-based verification (ABV) is a key approach to checking whether a logic design complies with its architectural specifications. Existing assertion generation methods based on design specifications typically produce only top-level assertions, overlooking verification needs on the implementation details in the modules at the micro-architectural level, where design errors occur more frequently. To address this limitation, we present AssertMiner, a module-level assertion generation framework that leverages static information generated from abstract syntax tree (AST) to assist LLMs in mining assertions. Specifically, it performs AST-based structural extraction to derive the module call graph, I/O table, and dataflow graph, guiding the LLM to generate module-level specifications and mine module-level assertions. Our evaluation demonstrates that AssertMiner outperforms existing methods such as AssertLLM and Spec2Assertion in generating high-quality assertions for modules. When integrated with these methods, AssertMiner can enhance the structural coverage and significantly improve the error detection capability, enabling a more comprehensive and efficient verification process.

</details>


### [279] [The Role of Advanced Computer Architectures in Accelerating Artificial Intelligence Workloads](https://arxiv.org/abs/2511.10010)
*Shahid Amin,Syed Pervez Hussnain Shah*

Main category: cs.AR

TL;DR: AI模型的进步与计算机体系结构的革新紧密相连。本综述分析了用于加速AI工作负载的GPU、ASIC和FPGA等架构，探讨了数据流优化、内存层级、稀疏性和量化等核心设计原则，并展望了PIM和神经形态计算等新兴技术。结论是AI与计算机体系结构是共生关系，硬件-软件协同设计是未来计算发展的必然要求。


<details>
  <summary>Details</summary>
Motivation: AI模型（尤其是深度神经网络DNN）的日益复杂及其巨大的计算需求，推动了对能够加速这些工作负载的计算机体系结构的需求，并与AI的进步同步发展。

Method: 对GPU、ASIC和FPGA等主流AI加速器架构进行了结构化回顾，分析了它们的设计理念、关键特性和性能权衡。同时，研究了数据流优化、内存层级、稀疏性和量化等提高性能和能效的核心原则，并探讨了PIM和神经形态计算等新兴技术。通过整合架构原理和行业标准基准的量化性能数据，为AI加速器领域提供全面的图景。

Result: 对现有AI加速器（GPU、ASIC、FPGA）的分析表明，它们在设计理念、关键特性和性能权衡方面各有侧重。新兴技术（如PIM和神经形态计算）预示着未来计算模式的变革。行业标准基准的量化性能数据支持了对这些架构的评估。

Conclusion: AI和计算机体系结构之间存在共生关系，硬件和软件的协同设计对于推动未来计算的进步至关重要，不再仅仅是优化选项，而是发展的必然要求。

Abstract: The remarkable progress in Artificial Intelligence (AI) is foundation-ally linked to a concurrent revolution in computer architecture. As AI models, particularly Deep Neural Networks (DNNs), have grown in complexity, their massive computational demands have pushed traditional architectures to their limits. This paper provides a structured review of this co-evolution, analyzing the architectural landscape designed to accelerate modern AI workloads. We explore the dominant architectural paradigms Graphics Processing Units (GPUs), Appli-cation-Specific Integrated Circuits (ASICs), and Field-Programmable Gate Ar-rays (FPGAs) by breaking down their design philosophies, key features, and per-formance trade-offs. The core principles essential for performance and energy efficiency, including dataflow optimization, advanced memory hierarchies, spar-sity, and quantization, are analyzed. Furthermore, this paper looks ahead to emerging technologies such as Processing-in-Memory (PIM) and neuromorphic computing, which may redefine future computation. By synthesizing architec-tural principles with quantitative performance data from industry-standard benchmarks, this survey presents a comprehensive picture of the AI accelerator landscape. We conclude that AI and computer architecture are in a symbiotic relationship, where hardware-software co-design is no longer an optimization but a necessity for future progress in computing.

</details>


### [280] [Combined power management and congestion control in High-Speed Ethernet-based Networks for Supercomputers and Data Centers](https://arxiv.org/abs/2511.10159)
*Miguel Sánchez de la Rosa,Francisco J. andújar,Jesus Escudero-Sahuquillo,José L. Sánchez,Francisco J. Alfaro-Cortés*

Main category: cs.AR

TL;DR: 本文探讨了数据中心和超级计算机的网络连接问题，重点关注拥塞控制和功耗管理及其相互作用。


<details>
  <summary>Details</summary>
Motivation: 随着计算机日益普及，数据中心和超级计算机在日常服务和科学研究中扮演着至关重要的角色。然而，这些复杂系统的互联互通可能成为瓶颈，因此需要先进的技术来优化其性能和能效。

Method: 本文研究了两个网络方面：一是如何在重负载下通过拥塞控制防止性能下降，二是如何在空闲时通过功耗管理来节省能源，并探讨了这两者之间的相互作用。

Result: （未在摘要中提供）

Conclusion: （未在摘要中提供）

Abstract: The demand for computer in our daily lives has led to the proliferation of Datacenters that power indispensable many services. On the other hand, computing has become essential for some research for various scientific fields, that require Supercomputers with vast computing capabilities to produce results in reasonable time. The scale and complexity of these systems, compared to our day-to-day devices, are like comparing a cell to a living organism. To make them work properly, we need state-of-the-art technology and engineering, not just raw resources. Interconnecting the different computer nodes that make up a whole is a delicate task, as it can become the bottleneck for the whole infrastructure. In this work, we explore two aspects of the network: how to prevent degradation under heavy use with congestion control, and how to save energy when idle with power management; and how the two may interact.

</details>


### [281] [Beamspace Equalization for mmWave Massive MIMO: Algorithms and VLSI Implementations](https://arxiv.org/abs/2511.10563)
*Seyed Hadi Mirfarshbafan,Christoph Studer*

Main category: cs.AR

TL;DR: Beamspace processing reduces hardware cost and power consumption in massive MIMO and mmWave systems by leveraging channel sparsity. This paper reviews existing algorithms, proposes new ones with VLSI architectures (CSPADE), and presents implementation results showing significant power savings (up to 66%) and high throughput compared to antenna-domain equalization.


<details>
  <summary>Details</summary>
Motivation: Massive MIMO and mmWave communication face challenges with excessive baseband processing hardware cost and power consumption. Beamspace processing offers a solution by exploiting channel sparsity at mmWave frequencies to reduce complexity.

Method: The paper reviews existing beamspace data detection algorithms and proposes new algorithms along with corresponding VLSI architectures. It presents VLSI implementation results for these architectures, specifically focusing on the complex sparsity-adaptive equalizer (CSPADE). Both fully-parallelized and sequential MAC-based architectures are considered.

Result: VLSI implementation in a 22nm FDSOI process shows that the proposed CSPADE architecture achieves up to 54% power savings in its fully-parallelized form compared to antenna-domain equalization. The fully-parallelized designs also achieve the highest reported throughput among existing massive MIMO data detectors, with better energy and area efficiency. The sequential MAC-based architecture further increases power savings to up to 66% compared to a MAC-based antenna-domain equalizer.

Conclusion: The proposed beamspace processing algorithms and VLSI architectures, particularly CSPADE, offer significant advantages in terms of power efficiency, throughput, energy efficiency, and area efficiency for massive MIMO and mmWave systems compared to traditional antenna-domain equalization methods.

Abstract: Massive multiuser multiple-input multiple-output (MIMO) and millimeter-wave (mmWave) communication are key physical layer technologies in future wireless systems. Their deployment, however, is expected to incur excessive baseband processing hardware cost and power consumption. Beamspace processing leverages the channel sparsity at mmWave frequencies to reduce baseband processing complexity. In this paper, we review existing beamspace data detection algorithms and propose new algorithms as well as corresponding VLSI architectures that reduce data detection power. We present VLSI implementation results for the proposed architectures in a 22nm FDSOI process. Our results demonstrate that a fully-parallelized implementation of the proposed complex sparsity-adaptive equalizer (CSPADE) achieves up to 54% power savings compared to antenna-domain equalization. Furthermore, our fully-parallelized designs achieve the highest reported throughput among existing massive MIMO data detectors, while achieving better energy and area efficiency. We also present a sequential multiply-accumulate (MAC)-based architecture for CSPADE, which enables even higher power savings, i.e., up to 66%, compared to a MAC-based antenna-domain equalizer.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [282] [Truth, Justice, and Secrecy: Cake Cutting Under Privacy Constraints](https://arxiv.org/abs/2511.09882)
*Yaron Salman,Tamir Tassa,Omer Lev,Roie Zivan*

Main category: cs.GT

TL;DR: 该论文提出了一种新颖的、同时满足隐私、公平和策略证明的蛋糕切割协议。


<details>
  <summary>Details</summary>
Motivation: 在蛋糕切割算法的研究中，虽然公平性和策略证明得到了广泛关注，但隐私保护方面却鲜有问津。然而，在实际应用中，例如广告时间分配，代理商可能因隐私担忧而不愿透露真实偏好，因为这可能暴露其营销策略或产品发布计划。

Method: 本文在 Chen et al. (2010) 的策略证明算法基础上，引入了隐私保护机制。通过采用密码学技术，将中心化计算替换为分布式计算，实现了在不牺牲公平性和策略证明的前提下保护隐私。

Result: 本文提出了首个同时满足隐私、公平和策略证明的蛋糕切割协议。该协议通过密码学技术，允许代理商在不暴露其偏好信息的情况下进行资源分配，从而鼓励代理商提供真实偏好。

Conclusion: 该研究成功地将隐私保护维度引入了蛋糕切割算法，解决了实际应用中的隐私担忧问题，并提出了首个兼具隐私、公平和策略证明的蛋糕切割协议，这有望在鼓励代理商提供真实偏好的同时，实现更公平的资源分配。

Abstract: Cake-cutting algorithms, which aim to fairly allocate a continuous resource based on individual agent preferences, have seen significant progress over the past two decades. Much of the research has concentrated on fairness, with comparatively less attention given to other important aspects. Chen et al. (2010) introduced an algorithm that, in addition to ensuring fairness, was strategyproof -- meaning agents had no incentive to misreport their valuations. However, even in the absence of strategic incentives to misreport, agents may still hesitate to reveal their true preferences due to privacy concerns (e.g., when allocating advertising time between firms, revealing preferences could inadvertently expose planned marketing strategies or product launch timelines). In this work, we extend the strategyproof algorithm of Chen et al. by introducing a privacy-preserving dimension. To the best of our knowledge, we present the first private cake-cutting protocol, and, in addition, this protocol is also envy-free and strategyproof. Our approach replaces the algorithm's centralized computation with a novel adaptation of cryptographic techniques, enabling privacy without compromising fairness or strategyproofness. Thus, our protocol encourages agents to report their true preferences not only because they are not incentivized to lie, but also because they are protected from having their preferences exposed.

</details>


### [283] [Robust Resource Allocation via Competitive Subsidies](https://arxiv.org/abs/2511.09934)
*David X. Lin,Giannis Fikioris,Siddhartha Banerjee,Éva Tardos*

Main category: cs.GT

TL;DR: 本文提出了一种新的拍卖机制，通过竞争性补贴，将非货币在线资源分配的鲁棒性因子提高到0.625，接近理论最优值。


<details>
  <summary>Details</summary>
Motivation: 在非货币在线资源分配问题中，现有的机制鲁棒性因子存在上限，无法达到理论最优值。

Method: 提出了一种新的拍卖机制，该机制在每轮拍卖中，由出价者决定是否请求物品，并进行随机分配。核心创新在于竞争性补贴，获胜者支付的费用随竞争者数量的变化而变化。此外，还探讨了该机制在均衡策略下的鲁棒性。

Result: 新的拍卖机制鲁棒性因子达到0.625，接近非策略性最优值1-1/e（约0.63）。该机制的变体在均衡策略下可达到5/(3e)（约0.61）的鲁棒性因子，且在均衡时可达到最优的1-1/e因子。该机制在广泛的拍卖类机制中具有最优性。

Conclusion: 本文提出的基于竞争性补贴的拍卖机制在提高非货币在线资源分配的鲁棒性方面取得了显著进展，几乎达到了理论最优。

Abstract: A canonical setting for non-monetary online resource allocation is one where agents compete over multiple rounds for a single item per round, with i.i.d. valuations and additive utilities across rounds. With $n$ symmetric agents, a natural benchmark for each agent is the utility realized by her favorite $1/n$-fraction of rounds; a line of work has demonstrated one can robustly guarantee each agent a constant fraction of this ideal utility, irrespective of how other agents behave. In particular, several mechanisms have been shown to be $1/2$-robust, and recent work established that repeated first-price auctions based on artificial credits have a robustness factor of $0.59$, which cannot be improved beyond $0.6$ using first-price and simple strategies. In contrast, even without strategic considerations, the best achievable factor is $1-1/e\approx 0.63$.
  In this work, we break the $0.6$ first-price barrier to get a new $0.625$-robust mechanism, which almost closes the gap to the non-strategic robustness bound. Surprisingly, we do so via a simple auction, where in each round, bidders decide if they ask for the item, and we allocate uniformly at random among those who ask. The main new ingredient is the idea of competitive subsidies, wherein we charge the winning agent an amount in artificial credits that decreases when fewer agents are bidding (specifically, when $k$ agents bid, then the winner pays proportional to $k/(k+1)$, varying the payment by a factor of 2 depending on the competition). Moreover, we show how it can be modified to get an equilibrium strategy with a slightly weaker robust guarantee of $5/(3e) \approx 0.61$ (and the optimal $1-1/e$ factor at equilibrium). Finally, we show that our mechanism gives the best possible bound under a wide class of auction-based mechanisms.

</details>


### [284] [Facility Location for Congesting Commuters and Generalizing the Cost-Distance Problem](https://arxiv.org/abs/2511.10228)
*Thanasis Lianeas,Marios Mertzanidis,Aikaterini Nikolidaki*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In Facility Location problems there are agents that should be connected to facilities and locations where facilities may be opened so that agents can connect to them. We depart from Uncapacitated Facility Location and by assuming that the connection costs of agents to facilities are congestion dependent, we define a novel problem, namely, Facility Location for Congesting (Selfish) Commuters. The connection costs of agents to facilities come as a result of how the agents commute to reach the facilities in an underlying network with cost functions on the edges. Inapproximability results follow from the related literature and thus approximate solutions is all we can hope for. For when the cost functions are nondecreasing we employ in a novel way an approximate version of Caratheodory's Theorem [5] to show how approximate solutions for different versions of the problem can be derived. For when the cost functions are nonincreasing we show how this problem generalizes the Cost-Distance problem [38] and provide an algorithm that for this more general case achieves the same approximation guarantees.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [285] [What did Elon change? A comprehensive analysis of Grokipedia](https://arxiv.org/abs/2511.09685)
*Harold Triedman,Alexios Mantzarlis*

Main category: cs.SI

TL;DR: Grokipedia, an alternative to Wikipedia, is highly derivative of Wikipedia but differs in citation practices, often referencing unreliable sources. It primarily rewrites high-quality Wikipedia articles, especially biographies and those on politics, society, and history.


<details>
  <summary>Details</summary>
Motivation: To provide the first comprehensive analysis and comparison of Grokipedia against Wikipedia, focusing on article similarity and citation practices.

Method: Analyzed article similarity and citation practices between Grokipedia and Wikipedia using a Wikipedia dump and a scrape of Grokipedia. Examined subsets of articles on elected officials, controversial topics, and a random subset to determine article quality and topic. Publicly released the Grokipedia scrape and embeddings.

Result: Grokipedia articles are longer than Wikipedia's but highly derivative. Citation practices differ significantly, with Grokipedia citing many unreliable sources. Article subsets on elected officials and controversial topics showed less similarity. Grokipedia focused on rewriting high-quality Wikipedia articles, biased towards biographies, politics, society, and history.

Conclusion: Grokipedia is largely based on Wikipedia content but employs distinct and questionable citation practices. The platform appears to prioritize rewriting existing high-quality Wikipedia articles within specific subject areas.

Abstract: Elon Musk released Grokipedia on 27 October 2025 to provide an alternative to Wikipedia, the crowdsourced online encyclopedia. In this paper, we provide the first comprehensive analysis of Grokipedia and compare it to a dump of Wikipedia, with a focus on article similarity and citation practices. Although Grokipedia articles are much longer than their corresponding English Wikipedia articles, we find that much of Grokipedia's content (including both articles with and without Creative Commons licenses) is highly derivative of Wikipedia. Nevertheless, citation practices between the sites differ greatly, with Grokipedia citing many more sources deemed "generally unreliable" or "blacklisted" by the English Wikipedia community and low quality by external scholars, including dozens of citations to sites like Stormfront and Infowars. We then analyze article subsets: one about elected officials, one about controversial topics, and one random subset for which we derive article quality and topic. We find that the elected official and controversial article subsets showed less similarity between their Wikipedia version and Grokipedia version than other pages. The random subset illustrates that Grokipedia focused rewriting the highest quality articles on Wikipedia, with a bias towards biographies, politics, society, and history. Finally, we publicly release our nearly-full scrape of Grokipedia, as well as embeddings of the entire Grokipedia corpus.

</details>


### [286] [Simulating Misinformation Propagation in Social Networks using Large Language Models](https://arxiv.org/abs/2511.10384)
*Raj Gaurav Maurya,Vaibhav Shukla,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.SI

TL;DR: 该研究提出了一种新的框架，利用大型语言模型（LLM）模拟用户偏见，以分析错误信息在社交网络中的传播，并提出了一种审计方法来追踪信息失真，从而为理解和应对错误信息提供了一种可解释且经验丰富的方法。


<details>
  <summary>Details</summary>
Motivation: 为了研究错误信息在社交媒体上传播的机制，特别是其如何利用人类认知偏差，该研究构建了一个模拟框架。

Method: 研究人员创建了一个包含LLM代理（模拟具有特定偏见、意识形态和信任模式的用户）的网络。通过一个“审计-节点”框架，新闻文章在这些代理之间传播，每个代理都会重写内容。一个基于问答的审计器在每一步追踪事实准确性，量化错误信息的变化。研究人员还引入了一个错误信息指数和一个传播率来衡量事实的降级。

Result: 实验表明，基于身份和意识形态的LLM代理会加速错误信息的传播，尤其是在政治、市场和技术领域。相反，专家驱动的代理能够保持事实的稳定性。研究还发现，一旦出现早期失真，不同代理之间的互动会迅速加剧错误信息，达到宣传的程度。研究人员提出了一个错误信息严重程度的分类体系，并发现LLM既可以作为模拟人类偏见的工具，也可以作为追踪信息保真度的审计工具。

Conclusion: 该研究提出的框架为研究、模拟和减轻数字生态系统中的错误信息传播提供了一种可解释且基于经验的方法，并强调了LLM在理解和对抗错误信息方面的双重作用。

Abstract: Misinformation on social media thrives on surprise, emotion, and identity-driven reasoning, often amplified through human cognitive biases. To investigate these mechanisms, we model large language model (LLM) personas as synthetic agents that mimic user-level biases, ideological alignments, and trust heuristics. Within this setup, we introduce an auditor--node framework to simulate and analyze how misinformation evolves as it circulates through networks of such agents. News articles are propagated across networks of persona-conditioned LLM nodes, each rewriting received content. A question--answering-based auditor then measures factual fidelity at every step, offering interpretable, claim-level tracking of misinformation drift. We formalize a misinformation index and a misinformation propagation rate to quantify factual degradation across homogeneous and heterogeneous branches of up to 30 sequential rewrites. Experiments with 21 personas across 10 domains reveal that identity- and ideology-based personas act as misinformation accelerators, especially in politics, marketing, and technology. By contrast, expert-driven personas preserve factual stability. Controlled-random branch simulations further show that once early distortions emerge, heterogeneous persona interactions rapidly escalate misinformation to propaganda-level distortion. Our taxonomy of misinformation severity -- spanning factual errors, lies, and propaganda -- connects observed drift to established theories in misinformation studies. These findings demonstrate the dual role of LLMs as both proxies for human-like biases and as auditors capable of tracing information fidelity. The proposed framework provides an interpretable, empirically grounded approach for studying, simulating, and mitigating misinformation diffusion in digital ecosystems.

</details>


### [287] [Two Americas of Well-Being: Divergent Rural-Urban Patterns of Life Satisfaction and Happiness from 2.6 B Social Media Posts](https://arxiv.org/abs/2511.10542)
*Stefano Maria Iacus,Giuseppe Porro*

Main category: cs.SI

TL;DR: 使用26亿条地理位置社交媒体帖子（2014-2022年）和一个经过微调的生成语言模型，我们构建了美国县级的生活满意度和幸福感指标。我们记录了一个明显的城乡悖论：农村县的生活满意度更高，而城市县的幸福感更强。我们通过将两者视为主观幸福感的两个不同层面（评估性与享乐性）来调和这一点，表明它们在地域、政治和时间上的映射方式不同。倾向于共和党地区的民众在评估性方面似乎更满意，但在主要都市区之外，幸福感在党派之间的差距基本消失，这表明政治影响是因地而异的。时间冲击对享乐层面有显著影响：2020-2022年期间幸福感急剧下降，而生活满意度的变动则较为温和。这些模式在logistic和OLS模型中都是稳健的，并与幸福感理论一致。这些结果被解读为社交媒体帖子人群的关联，表明大规模的、基于语言的指标可以通过区分所表达的幸福感的类型来解决关于城乡差距的冲突发现，为传统的调查方法提供了一个透明、可重复的补充。


<details>
  <summary>Details</summary>
Motivation: 本文旨在利用大规模社交媒体数据和生成语言模型，构建美国县级的生活满意度和幸福感指标，并探讨城乡差异、政治倾向和时间冲击对这些指标的影响，以解决传统调查方法在衡量主观幸福感方面的局限性。

Method: 使用26亿条地理位置社交媒体帖子（2014-2022年）和经过微调的生成语言模型，构建美国县级的生活满意度和幸福感指标，并分析这些指标与地域（城乡）、政治倾向和时间冲击（如2020-2022年）之间的关系。

Result: 研究发现，农村县的生活满意度高于城市县，而城市县的幸福感强于农村县。倾向于共和党地区的民众在评估性满意度方面更高，但在主要都市区之外，党派在幸福感上的差距缩小。2020-2022年期间，幸福感急剧下降，而生活满意度变动较小。这些模式在logistic和OLS模型中均表现稳健，并与幸福感理论一致。

Conclusion: 大规模、基于语言的指标能够有效区分主观幸福感中的评估性和享乐性层面，从而解决城乡差异的悖论，并为理解幸福感与地域、政治和时间因素的复杂关系提供了新的视角，为传统调查方法提供了透明、可重复的补充。

Abstract: Using 2.6 billion geolocated social-media posts (2014-2022) and a fine-tuned generative language model, we construct county-level indicators of life satisfaction and happiness for the United States. We document an apparent rural-urban paradox: rural counties express higher life satisfaction while urban counties exhibit greater happiness. We reconcile this by treating the two as distinct layers of subjective well-being, evaluative vs. hedonic, showing that each maps differently onto place, politics, and time. Republican-leaning areas appear more satisfied in evaluative terms, but partisan gaps in happiness largely flatten outside major metros, indicating context-dependent political effects. Temporal shocks dominate the hedonic layer: happiness falls sharply during 2020-2022, whereas life satisfaction moves more modestly. These patterns are robust across logistic and OLS specifications and align with well-being theory. Interpreted as associations for the population of social-media posts, the results show that large-scale, language-based indicators can resolve conflicting findings about the rural-urban divide by distinguishing the type of well-being expressed, offering a transparent, reproducible complement to traditional surveys.

</details>


### [288] [Textual understanding boost in the WikiRace](https://arxiv.org/abs/2511.10585)
*Raman Ebrahimi,Sean Fuhrman,Kendrick Nguyen,Harini Gurusankar,Massimo Franceschetti*

Main category: cs.SI

TL;DR: 纯粹基于语义相似性的贪心代理在维基百科导航任务中表现出色，其效率和成功率均远超结构或混合方法。


<details>
  <summary>Details</summary>
Motivation: 评估维基百科导航任务中的不同导航策略，特别是基于图论结构、语义含义以及混合方法的有效性。

Method: 在大型维基百科子图上，比较了三种导航策略：基于图论结构（中介中心性）、基于语义含义（语言模型嵌入）以及混合方法。其中，一个简单的贪心代理结合了文章标题的语义相似性和循环避免机制。

Result: 纯粹基于文章标题语义相似性的贪心代理，结合简单的循环避免机制，在维基百科导航任务中达到了100%的成功率，并且导航效率比结构或混合方法高一个数量级。

Conclusion: 纯粹的结构启发式方法在目标导向搜索中存在局限性，而大型语言模型在复杂信息空间中作为零样本语义导航器具有巨大潜力。

Abstract: The WikiRace game, where players navigate between Wikipedia articles using only hyperlinks, serves as a compelling benchmark for goal-directed search in complex information networks. This paper presents a systematic evaluation of navigation strategies for this task, comparing agents guided by graph-theoretic structure (betweenness centrality), semantic meaning (language model embeddings), and hybrid approaches. Through rigorous benchmarking on a large Wikipedia subgraph, we demonstrate that a purely greedy agent guided by the semantic similarity of article titles is overwhelmingly effective. This strategy, when combined with a simple loop-avoidance mechanism, achieved a perfect success rate and navigated the network with an efficiency an order of magnitude better than structural or hybrid methods. Our findings highlight the critical limitations of purely structural heuristics for goal-directed search and underscore the transformative potential of large language models to act as powerful, zero-shot semantic navigators in complex information spaces.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [289] [Electrostatic, Luminescent, and Paramagnetic Responses of Fresh BN Nanopowders Synthesized under Concentrated Light](https://arxiv.org/abs/2511.09662)
*Lina Sartinska*

Main category: cond-mat.mtrl-sci

TL;DR: 高通量光炉合成的氮化硼纳米粉体在空气中暴露两年后会失去静电荷、光致发光和顺磁性，这表明表面氧化和羟基化钝化了缺陷态。


<details>
  <summary>Details</summary>
Motivation: 研究在高温、非平衡条件下合成的纳米粉体的性质，特别是表面化学对其静电、光学和磁行为的影响。

Method: 使用高通量光炉在氮气流中合成纳米粉体，并与商业 h-BN 粉体进行比较。通过 FTIR 分析了空气暴露后粉体的表面变化。

Result: 合成的纳米粉体表面覆盖有潵石、氧化硼和氮化硼层，核心为元素硼。初始纳米粉体表现出静电荷、光致发光和顺磁性，但在空气中暴露两年后这些性质完全消失。商业 h-BN 粉体也没有显示出特征的 EPR 共振线。FTIR 分析显示表面氧化和羟基化。

Conclusion: 表面化学在控制 BN 纳米材料的静电、光学和磁行为方面起着关键作用，并且缺陷稳定对于在一段时间内保持功能特性至关重要。

Abstract: This study explores the properties of nanopowders synthesized under high-temperature, non-equilibrium conditions in a high-flux optical furnace in a nitrogen flow. Boron powders served as the starting material, and the intense thermal gradients during synthesis led to incomplete chemical reactions. As a result, the surface of the resulting nanoparticles is covered with a thin layer of sassolite, followed by boron oxides, beneath which lies a boron nitride shell. The subsurface contains boron-rich nitride phases, while the core consists of elemental boron. For reference, commercial platelet-like h-BN powders from the "Chempur" company were also analyzed. Initially, all synthesized nanopowders displayed pronounced electrostatic charging, photoluminescence (PL), and paramagnetic activity, attributable to high surface defect densities and unsaturated chemical bonds. However, after two years of exposure to ambient air, these nanopowders exhibited complete loss of electrostatic charging, absence of photoluminescence (PL), and disappearance of the characteristic single EPR resonance line. Similarly, commercial h-BN nanopowder from the "Chempur" company does not exhibit a single EPR resonance line too. FTIR analysis revealed progressive surface oxidation and hydroxylation of this powder, suggesting that atmospheric moisture and oxygen effectively passivated defect states. These findings underscore the critical role of surface chemistry in governing the electrostatic, optical, and magnetic behavior of BN-based nanomaterials and highlight the importance of defect stabilization for preserving functional properties over time.

</details>


### [290] [pH Regulates Ion Dynamics in Carboxylated Mixed Conductors](https://arxiv.org/abs/2511.09671)
*Zeyuan Sun,Mengting Sun,Rajiv Giridharagopal,Robert C. Hamburger,Siyu Qin,Haoxuan Li,Mitchell C. Hausback,Yulong Zheng,Bohyeon Kim,Heng Tan,Thomas E. Gartner,Elizabeth R. Young,Christopher J Takacs,David S. Ginger,Elsa Reichmanis*

Main category: cond-mat.mtrl-sci

TL;DR: 质子化状态可调控聚噻吩的离子/电子传输，为pH响应材料提供设计原则。


<details>
  <summary>Details</summary>
Motivation: 理解化学环境（如pH）如何影响离子和电子传输的耦合

Method: 研究羧化聚噻吩的质子化状态如何影响其离子动力学、掺杂效率、溶剂吸收和机械响应

Result: 发现质子化状态可以精确调控这些特性，并建立了分子酸度作为调控离子选择性和机械稳定性的通用策略

Conclusion: 分子酸度是设计pH响应的混合导体和软电子材料的通用策略，这些材料耦合了离子、电子和机械功能。

Abstract: Coupled ionic and electronic transport underpins processes as diverse as electrochemical energy conversion, biological signaling, and soft adaptive electronics. Yet, how chemical environments such as pH modulate this coupling at the molecular scale remains poorly understood. Here, we show that the protonation state of carboxylated polythiophenes provides precise chemical control over ion dynamics, doping efficiency, solvent uptake and mechanical response. The findings establish molecular acidity as a general strategy to program ionic preference and mechanical stability, offering design principles for pH-responsive mixed conductors and soft electronic materials that couple ionic, electronic, and mechanical functionality.

</details>


### [291] [Time-Dependent Oxidation and Scale Evolution of a Wrought Co/Ni-based Superalloy](https://arxiv.org/abs/2511.09678)
*Cameron Crabb,Zachary. T. Kloenne,Samuel. R. Rogers,Chi-Hang. D. Kwok,Michelle. S. Conroy,David. Dye*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化动力学从近线性演变为抛物线行为，随着连续Cr2O3/α-Al2O3氧化皮的形成，最终转变为致密的双相富含铬和铝的氧化皮，从而实现对锻造Co/Ni基高温合金的长期保护。


<details>
  <summary>Details</summary>
Motivation: 为了提高高温合金的长期抗氧化性，需要了解保护性氧化皮的演变过程。

Method: 通过在800°C空气中氧化Co/Ni基高温合金（20、100和1000小时），并采用称重法、白光干涉测量法、STEM-EDX、APT和XRD等技术，研究氧化动力学、表面粗糙度、氧化皮形态、元素偏析以及氧化皮相结构和形貌的演变。

Result: 氧化速率随时间从近线性演变为抛物线行为，表明在形成连续的Cr2O3/α-Al2O3氧化皮后，生长受扩散控制。最初疏松的尖晶石层逐渐转变为致密的、附着良好的Cr2O3+Al2O3双相氧化皮。

Conclusion: 氧化动力学、结构和化学之间的联系表明，疏松的尖晶石层如何转变为致密的、附着良好的Cr2O3+Al2O3氧化皮，从而为锻造Co/Ni基高温合金提供长期保护。

Abstract: Understanding how protective oxide scales evolve over time is necessary for improving the long term resistance of superalloys. This work investigates the time-dependent oxidation behavior of an ingot-processable Co/Ni-based superalloy oxidized in air at $800~^\circ\mathrm{C}$ for $20$, $100$, and $1000~\mathrm{h}$ . Mass-gain and white-light interferometry measurements quantified oxidation kinetics, surface roughness, and spallation, while high-resolution STEM-EDX characterized oxide morphology and nanoscale elemental partitioning. Atom probe tomography captured the key transition regions between the chromia and alumina scales, and X-ray diffraction was used to identify a gradual transition from NiO and (Ni,Co)-spinel phases to a compact, dual phase chromia and alumina-rich scale. The oxidation rate evolved from near-linear to parabolic behavior with time, consistent with diffusion-controlled growth once a continuous Cr$_2$O$_3$/$α$-Al$_2$O$_3$ scale formed. These observations help link kinetics, structure and chemistry, showing how an originally porous spinel layer transforms into a dense, adherent chromia + alumina scale that provides long-term protection in wrought Co/Ni-based superalloys.

</details>


### [292] [Controlling Metastability through Annealing of High-Entropy Nanoalloy Electrocatalysts to Boost Performance towards the Oxygen Evolution Reaction](https://arxiv.org/abs/2511.09711)
*Varatharaja Nallathambi,Aneeta Jose Puthussery,Andrea M. Mingers,Robert Stuckert,André Olean-Oliveira,Sven Reichenberger,Dierk Raabe,Viktor Čolić,Baptiste Gault,Stephan Barcikowski*

Main category: cond-mat.mtrl-sci

TL;DR: 低成本的碳掺杂高熵合金纳米颗粒，通过纳米秒脉冲激光合成，在600°C退火后，由于形成了具有增强的碳壳的异质结构纳米颗粒，其析氧反应的电催化活性相比于合成后的形式提高了5到7倍。


<details>
  <summary>Details</summary>
Motivation: 探索利用碳掺杂钭 Cantor 合金非晶高熵合金纳米颗粒的亚稳态，通过后合成退火来提高激光生成的纳米颗粒的电化学活性，以替代铂族电催化剂。

Method: 采用纳米秒脉冲激光合成碳掺杂钭 Cantor 合金非晶高熵合金纳米颗粒，并通过在 600°C 加热进行原位电子显微镜观察，分析结晶和元素分配行为。

Result: 在 600°C 退火后，非晶高熵合金纳米颗粒转变为具有增强的碳壳的异质结构纳米颗粒，其析氧反应的电催化活性相比于合成后的形式提高了 5 到 7 倍。

Conclusion: 通过对激光生成的高熵纳米颗粒进行后合成退火，可以战略性地利用其相亚稳态来提高电化学活性，这为开发低成本、高性能的电催化剂提供了新的途径。

Abstract: Low-cost transition metal high-entropy nanoalloys are emerging as sustainable alternatives to platinum group electrocatalysts. Synthesis conditions of single-phase solid solutions can alter phase stability, causing surface composition changes that affect electrocatalytic performance. Here, we propose to exploit the metastability of carbon-doped Cantor alloy-based amorphous high-entropy alloy nanoparticles produced by nanosecond-pulsed laser synthesis in organic solvents. In situ electron microscopy reveals crystallization and partitioning of elements upon heating to 600 °C, forming heterostructured nanoparticles with reinforced carbon shells that exhibit a 5- to 7-fold enhancement of the electrocatalytic activity compared to the as-synthesized counterparts for the oxygen evolution reaction. We demonstrate the strategic utilization of phase metastability in high-entropy nanoalloys through post-synthesis annealing to enhance the electrochemical activity of laser-generated nanoparticles.

</details>


### [293] [Multibit Ferroelectric Memcapacitor for Non-volatile Analogue Memory and Reconfigurable Filtering](https://arxiv.org/abs/2511.09838)
*Deepika Yadav,Spyros Stathopoulos,Patrick Foster,Andreas Tsiamis,Mohamed Awadein,Hannah Levene,Themis Prodromakis*

Main category: cond-mat.mtrl-sci

TL;DR: 铁电HfZrO基可调电容器实现了8个以上稳定的、可重写的电容状态（3位编码），具有24 pF的非易失性窗口。该器件在低电压（3 V）下切换，每个状态都具有长保持时间（10^5秒）和高耐久性（10^6次循环），确保了可靠的多级操作。


<details>
  <summary>Details</summary>
Motivation: 需要一种无需连续偏置或机械驱动即可进行自适应和可重构电子器件的调谐电容器。

Method: 演示了一种基于铁电HfZrO的电压可编程铁电存储电容器，并在纳米尺度上使用原子力显微镜对其进行了多状态电荷保持的可视化。

Result: 该器件实现了超过8个稳定的、可重写的电容状态（3位编码），非易失性窗口为24 pF。器件在低电压（3 V）下切换，每个状态都具有长保持时间（10^5秒）和高耐久性（10^6次循环）。将器件集成到高通滤波器中，可编程电容状态将截止频率移动了超过5 kHz。

Conclusion: 基于铁电HfZrO的CMOS兼容、非易失性、模拟存储器是可行的，为自适应射频滤波器、可重构模拟前端和神经形态电子学开辟了道路。

Abstract: Tuneable capacitors are vital for adaptive and reconfigurable electronics, yet existing approaches require continuous bias or mechanical actuation. Here we demonstrate a voltage-programmable ferroelectric memcapacitor based on HfZrO that achieves more than eight stable, reprogrammable capacitance states (3-bit encoding) within a non-volatile window of 24~pF. The device switches at low voltages (3~V), with each state exhibiting long retention (10^5~s) and high endurance (10^6 cycles), ensuring reliable multi-level operation. At the nanoscale, multistate charge retention was directly visualised using atomic force microscopy, confirming the robustness of individual states beyond macroscopic measurements. As a proof of concept, the capacitor was integrated into a high-pass filter, where the programmed capacitive states shift the cutoff frequency over 5~kHz, establishing circuit-level viability. This work demonstrates the feasibility of CMOS-compatible, non-volatile, analogue memory based on ferroelectric HfZrO, paving the way for adaptive RF filters, reconfigurable analogue front-ends, and neuromorphic electronics.

</details>


### [294] [Structure of Antiphase boundaries in Ni-M-Ga: multiscale modelling](https://arxiv.org/abs/2511.09751)
*Jan Zemen,František Máca,Václav Drchal,Martin Veis,Oleg Heczko*

Main category: cond-mat.mtrl-sci

TL;DR: Antiphase boundaries (APBs) in Ni-Mn-Ga alloys exhibit unique magnetic properties at the nanoscale due to strong antiferromagnetic exchange interactions across them. These properties, specifically thin antiparallel magnetization regions formed by APB pairs, are responsible for the micrometer-scale magnetic contrast observed in MFM, and can be used to tune the alloy's coercivity.


<details>
  <summary>Details</summary>
Motivation: The connection between atomic-scale exchange interactions at antiphase boundaries (APBs) and the micrometer-scale magnetic contrast observed via magnetic force microscopy (MFM) in Ni-Mn-Ga alloys is not well understood, despite APBs significantly impacting magnetic coercivity.

Method: The study employed a combination of density functional theory (DFT) and finite-element magnetostatics. DFT was used to analyze the magnetic properties of supercells containing planar APBs, focusing on the lowest-energy configurations and exchange interactions. A finite-element magnetostatics model was then used to simulate the magnetic contrast generated by these nanoscale magnetic features at a larger scale, bridging the gap to MFM observations.

Result: DFT calculations revealed that the most stable configuration consists of parallel APB pairs enclosing a thin region (three Mn-Ga layers thick) with magnetization antiparallel to the surrounding matrix, driven by strong antiferromagnetic exchange across the APBs. The finite-element model showed that this antiparallel region generates MFM contrast extending approximately 100 nm from the APB pair. The study also found that if APBs are spaced more than 50 nm apart, dipole-dipole interactions dominate over exchange benefits, inhibiting the formation of larger antiparallel domains, consistent with experimental findings.

Conclusion: APB pairs are identified as the source of the observed MFM contrast in Ni-Mn-Ga alloys. This understanding provides insights into the modest domain-wall pinning effects of APBs and can guide the development of magnetic shape-memory alloys with controlled coercivity.

Abstract: Antiphase boundaries (APBs) are ubiquitous in ordered Heusler alloys and strongly influence magnetic coercivity in Ni-Mn-Ga, yet the link between their atomic-scale exchange interactions and micrometer-scale magnetic contrast measured by magnetic force microscopy (MFM) remains unclear. We combine density functional theory (DFT) and finite-element magnetostatics to bridge these scales in Ni-Mn-Ga. DFT calculations on supercells containing planar APBs show that the lowest-energy configuration comprises a pair of parallel APBs enclosing a nanoscale region - only three Mn-Ga atomic layers thick - whose magnetization is antiparallel to the surrounding matrix due to strong antiferromagnetic exchange across each APB (in contrast to ferromagnetic coupling in bulk martensite). According to our magnetostatic finite element model, this thin region with antiparallel magnetization generates the characteristic MFM contrast extending approx. 100 nm from the APB pair. When the APBs are further apart than 50 nm, dipole-dipole penalties outweigh exchange gains, preventing formation of an extended antiparallel domain, in agreement with experimental evidence. These results identify APB pairs as the origin of the observed MFM contrast and offer an interpretation of the modest strengths of domain-wall pinning by APBs, informing the design of magnetic shape-memory alloys with tailored coercivity.

</details>


### [295] [Beyond empirical models: Discovering new constitutive laws in solids with graph-based equation discovery](https://arxiv.org/abs/2511.09906)
*Hao Xu,Yuntian Chen,Dongxiao Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 提出一种基于图的方程发现框架，用于从实验数据中自动发现本构定律。


<details>
  <summary>Details</summary>
Motivation: 传统的现象学本构模型泛化能力差，依赖专家经验和预设函数形式。本研究旨在通过自动化方法发现新的、更具泛化能力的本构模型。

Method: 将方程表示为有向图，节点代表算子和变量，边表示计算关系，边特征编码参数依赖。通过此框架生成和优化具有未知参数的符号表达式。

Result: 发现了用于合金钢应变率效应和锂金属变形行为的新型本构模型，与传统模型相比，具有更简洁的解析结构和更高的准确性。

Conclusion: 所提出的基于图的方程发现框架是一种可泛化、可解释的数据驱动科学建模方法，特别适用于传统经验模型不足以描述复杂物理现象的场景。

Abstract: Constitutive models are fundamental to solid mechanics and materials science, underpinning the quantitative description and prediction of material responses under diverse loading conditions. Traditional phenomenological models, which are derived through empirical fitting, often lack generalizability and rely heavily on expert intuition and predefined functional forms. In this work, we propose a graph-based equation discovery framework for the automated discovery of constitutive laws directly from multisource experimental data. This framework expresses equations as directed graphs, where nodes represent operators and variables, edges denote computational relations, and edge features encode parametric dependencies. This enables the generation and optimization of free-form symbolic expressions with undetermined material-specific parameters. Through the proposed framework, we have discovered new constitutive models for strain-rate effects in alloy steel materials and the deformation behavior of lithium metal. Compared with conventional empirical models, these new models exhibit compact analytical structures and achieve higher accuracy. The proposed graph-based equation discovery framework provides a generalizable and interpretable approach for data-driven scientific modelling, particularly in contexts where traditional empirical formulations are inadequate for representing complex physical phenomena.

</details>


### [296] [An optically enhanced crystalline silicon allotrope: hydrogen passivated type II silicon clathrate](https://arxiv.org/abs/2511.09755)
*Yinan Liu,Joseph P. Briggs,Sam Saiter,Meenakshi Singh,Carolyn A. Koh,P. Craig Taylor,Michael Walker,Khalid Mateen,Moussa Kane,Reuben T. Collins*

Main category: cond-mat.mtrl-sci

TL;DR: 氢（氘）的加入显著改善了II型硅包合物的光电性能，降低了掺杂水平和结构缺陷，并提高了发光强度。


<details>
  <summary>Details</summary>
Motivation: 硅包合物作为有潜力的直接带隙半导体，其光电性能受高掺杂和结构缺陷的限制，而氢在其中作用未被探索。

Method: 使用远程等离子体处理将氢（氘）引入II型硅包合物框架，形成NaD和SiD复合物，以降低Na的掺杂密度和悬空键缺陷。

Result: 掺杂水平显著降低（Na相关给体态减少近十倍），光致发光强度增加40倍，主发射峰蓝移，出现930nm的新发射峰，且性能在高达400°C时保持稳定。

Conclusion: 氢钝化是提高硅包合物发光性能的可行策略，为硅基发光二极管和其他直接带隙光电器件的应用开辟了新途径。

Abstract: While Si clathrates have been explored as promising direct bandgap semiconductors, their practical optoelectronic performance has been limited by high doping levels and structural defects. Hydrogen has long been used to improve the optoelectronic quality of conventional Si, yet its role in clathrate structures remains unexplored. In this study, we demonstrate that hydrogen (deuterium) can be incorporated into type II Si clathrate framework using remote plasma treatment. This process leads to the formation of NaD and SiD complexes, which significantly reduce both the Na donor density and dangling bond defects. Electron paramagnetic resonance confirms nearly a tenfold decrease in Na-related donor states, resulting in the lowest doping level reported in Si clathrates to date. Following passivation, the integrated photoluminescence intensity increases by a factor of 40, accompanied by a blue shift of the main emission peak, consistent with a transition closer to the intrinsic band edge. A new emission peak at 930 nm, attributed to hydrogen-related recombination centers, also appears. These improvements remain stable up to 400 oC. Altogether, this work establishes hydrogen passivation as a viable strategy for enhancing light emission in Si clathrates and opens a new pathway toward their application in Si-based light-emitting diodes and other direct-bandgap optoelectronic devices.

</details>


### [297] [A Brief Perspective on Piezotronic and Thermoelectric Coupling: Flexible Platforms for Synergistic Energy Scavenging and Peltier-Caloric Effects](https://arxiv.org/abs/2511.09757)
*David Carroll,ChaoChao Dun*

Main category: cond-mat.mtrl-sci

TL;DR: 两种能量收集方式（热电和压电）的结合可以产生协同效应，超越单一方式的能量收集效果。


<details>
  <summary>Details</summary>
Motivation: 探索利用柔性压电和热电材料通过热力学耦合实现能量收集。

Method: 回顾了热/压电发电机（T/PEGs）的研究，并利用基本耦合热机模型来解释协同发电现象。

Result: 研究发现，热电和压电效应的协同作用可以使能量收集效率超过单独的两种效应之和，并可能出现新的协同热力化性质，如PCE效应。

Conclusion: 热电和压电效应的协同作用是真实存在的，并且不能将它们视为独立的热力学过程。

Abstract: Advances in the development of flexible piezoelectric and thermoelectric materials have provided an important avenue for the exploration of energy scavenging through the thermodynamic-coupling of orthogonal energy-scavenging modalities. This has led to a body of work creating hybrid thermo/piezo-electric generator devices (T/PEGs) in which the two effects become thermodynamically entangled. Based on hetero- thin film architectures, such devices can exhibit a surprising power generation characteristic which is non-additive between the two energy-scavenging effects. For example, when the thermoelectric and piezoelectric effects are strongly coupled by their proximal fields, the efficacy of energy scavenging can be made to exceed that of the two effects independently. In this review of such effects, a basic coupled heat engine model is shown to provide insight into the origins of synergistic power generation. These models however, suggest the emergence of other combined thermodynamic properties such as the kinetic Peltier-Caloric Effect (PCE) traced to Onsager reciprocity. The recent observation of this effect in multicomponent systems is confirmation of the limited perspective of thermodynamic separability.

</details>


### [298] [Cryogenic UV detection using stress-engineered zero-bias ZnO-thin film based Piezo-Photonic detector](https://arxiv.org/abs/2511.09781)
*P. Sau,N. Hancock,I. Tzoka,V. Khichar,A. Barajas,G. Gansle,N. Hozhabri,V. A. Chirayath,J. Asaadi*

Main category: cond-mat.mtrl-sci

TL;DR: 本文展示了一种在低温条件下工作的零偏压紫外探测器，该探测器利用了压电效应。


<details>
  <summary>Details</summary>
Motivation: 为满足在低温或零功耗等极端环境下对探测器灵敏度的要求。

Method: 制备了两种垂直堆叠的金属-半导体-金属(MSM)结构的紫外探测器，其中一种（Sample II）引入了氮化硅柱来增加ZnO层中的残余应力，并通过X射线衍射测量了应力差异，在室温和低温下使用365nm紫外LED测试了器件的紫外探测性能。

Result: 与仅使用ZnO薄膜的探测器（Sample I）相比，引入氮化硅柱的探测器（Sample II）在室温和低温下均表现出更高的紫外诱导电压信号。XRD结果表明，Sample II的残余应力比Sample I高约40%，这解释了其性能的提升。

Conclusion: 通过器件内的应力工程可以增强紫外光诱导信号，从而提高探测器的灵敏度。所展示的具有应力工程的零偏压光探测器可用于极端环境，如低温液态惰性气体或高辐射空间环境。

Abstract: We demonstrate a zero-bias ultraviolet (UV) detector using zinc oxide (ZnO) thin films as the active semiconductor layer, specifically for application in cryogenic conditions. The zero-bias device utilizes the piezoelectric potential developed through interfacial stress in the active semiconductor layer for charge transport. We explored two vertically stacked metal-semiconductor-metal (MSM) configurations: Sample I, a device comprised of chromium (Cr)/ZnO/Cr layers, and Sample II, a ZnO-silicon nitride (Si3N4) device comprised of Cr/Si3N4/ZnO/Cr layers. The Si3N4 layer in Sample II was introduced in the form of pillars, with the aim of increasing the residual stress in the active region. These fabricated devices were tested at both room and cryogenic temperatures to characterize their UV-detection performance in a custom test stand using a 365 nm UV LED source. We observe a higher UV-induced voltage signal for Sample II in comparison to Sample I at both temperature regimes. Grazing-incidence X-ray diffraction (GIXRD) measurements showed approximately 40% higher residual stress in Sample II than in Sample I. A higher residual stress suggests a higher induced piezopotential in Sample II, explaining the enhancement in the UV-induced signal. Our results demonstrate that through appropriate in-device stress engineering, UV photoinduced signals can be enhanced, increasing detector sensitivity. A zero-bias photodetector with in-device stress engineering, as demonstrated here, can have applications in extreme environments, like cryogenic liquid noble elements or high radiation space environments, where low or zero-power detection may be required.

</details>


### [299] [Control of Extraordinary Optical Transmission in Resonant Terahertz Gratings via Lateral Depletion in an AlGaN-GaN Heterostructure](https://arxiv.org/abs/2511.09811)
*Geofrey Nyabere,Hunter Ellis,Miguel Gomez,Wei Jia,Yizheng Liu,Karli Ann Higley,Sriram Krishnamoorthy,Steve Blair,Kai Fu,Berardi Sensale-Rodriguez*

Main category: cond-mat.mtrl-sci

TL;DR: 通过控制AlGaN/GaN异质结构中的电荷密度，可以动态调控金属光栅的电磁模式，实现太赫兹波段的超常光学透射（EOT）。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索如何通过调控AlGaN/GaN异质结构中的电荷密度，动态地操控金属光栅的电磁模式，从而实现对其光学传输的强力调制。

Method: 在AlGaN/GaN异质结构上制作周期性金属光栅，其中金属条带之间的区域包含二维电子气（2DEG）。通过施加电压改变2DEG的电荷密度，研究其对太赫兹波透射谱的影响。

Result: 在无偏压状态下，2DEG屏蔽了太赫兹场，抑制了引导模式的激发。当2DEG被耗尽时，边界条件发生改变，使得能量能够有效地耦合到衬底共振，在特定频率下产生超常光学透射（EOT）。

Conclusion: 研究结果表明，受引导模式共振（GMR）介导的EOT对条带间的电荷分布非常敏感，并证明了在太赫兹波段，载流子动力学与电磁共振现象之间存在直接的相互作用。

Abstract: Periodic metallic gratings on substrates can support a range of electromagnetic modes, such as leaky waveguide, guided-resonant, and Fabry-Perot (FP) cavity modes, which can strongly modulate optical transmission under resonant excitation. Here, we investigate how this coupling can be dynamically manipulated through charge-density control in a laterally patterned AlGaN/GaN heterostructure. The structure comprises metallic stripes separated by regions containing a two-dimensional electron gas (2DEG), forming a periodically modulated interface whose electromagnetic response is governed by the charge density between the stripes. In the unbiased state, the conductive 2DEG screens the incident terahertz field and suppresses excitation of guided modes. When the 2DEG is depleted, the change in boundary conditions allows efficient coupling into substrate resonances, producing a strong modulation at particular frequencies where extraordinary optical transmission (EOT) through the structure takes place. The results highlight the sensitive dependence of guided-mode-resonance (GMR) mediated EOT on inter-stripe charge distribution and demonstrate a direct interplay between carrier dynamics and resonant electromagnetic phenomena in the terahertz regime.

</details>


### [300] [Potential-Programmed Operando Ensembles Govern Nitrate Electroreduction](https://arxiv.org/abs/2511.09869)
*Xue-Chun Jiang,Jia-Lan Chen,Wei-Xue Li,Jin-Xun Liu*

Main category: cond-mat.mtrl-sci

TL;DR: Cu(111)在硝酸盐电还原为氨（NO3RR）过程中，其表面吸附物会随着催化周期的进行而不断重组，这使得在实际操作条件下识别活性位点变得困难，并阻碍了合理的催化剂设计。本研究通过一个由机器学习势能驱动的多尺度建模框架，解析了NO3RR的Cu(111)电解质界面的实际操作条件。结果显示，工作界面并非单一的“平均覆盖率”位点，而是一个在-0.10至-1.00 V（相对于SHE）之间进行转换的34种吸附物组合的电位门控统计系综。随着电位的变化，吸附物组合的分布发生转变，产生了火山状的活性趋势，在-0.70 V时达到峰值，此时单位位点转换频率达到0.015 s-1，氨的选择性接近100%。超过150个过渡态的活化能垒可以归结为与反应铜原子上过量电荷（ΔqCu）的线性关系，这表明界面电荷重新分布是统一的动力学描述符。最大活性并非来自均匀的中等覆盖率，而是来自一个2NO/2NH2四边形微系综，该系综将ΔqCu调节至一个中间值，同时降低了N-O键断裂和N-H键形成的能垒。将“覆盖率”重新概念化为局部微环境的系综，可以将热力学稳定性和催化生产力分离开来。这种观点提供了一种参数自由的策略，通过电位控制 the motif populations and interfacial charge，实现超越NO3RR的高覆盖率电催化。


<details>
  <summary>Details</summary>
Motivation: 电催化剂表面在催化转换的গুলির 间隙不断重组，这使得在实际操作条件下识别活性位点变得困难，并阻碍了合理的催化剂设计。

Method: 使用一个由覆盖感知机器学习势能加速的多尺度建模框架来解析硝酸盐电还原为氨（NO3RR）的实际操作条件下的Cu(111)电解质界面。

Result: 工作界面是一个电位门控的统计系综，包含34种在-0.10至-1.00 V（vs. SHE）之间转换的吸附物组合。活性趋势呈火山状，在-0.70 V时达到峰值，单位位点转换频率为0.015 s-1，氨的选择性接近100%。活化能垒与反应铜原子上的过量电荷（ΔqCu）呈线性关系。最大活性来自于一个2NO/2NH2四边形微系综，它将ΔqCu调节至中间值，同时降低了N-O键断裂和N-H键形成的能垒。

Conclusion: 将“覆盖率”重新概念化为局部微环境的系综，可以将热力学稳定性和催化生产力分离开来。这种观点提供了一种参数自由的策略，通过电位控制 the motif populations and interfacial charge，实现超越NO3RR的高覆盖率电催化。

Abstract: Electrocatalyst surfaces continuously reorganize on the timescale of catalytic turnover, obscuring the identification of active sites under operando conditions and hindering rational catalyst design. Here, we resolve the operando Cu(111) electrolyte interface for nitrate-to-ammonia electroreduction (NO3RR) via a multiscale modeling framework accelerated by a coverage-aware machine-learning potential. Rather than a single "average coverage" site, the working interface is a potential-gated statistical ensemble of 34 interconverting adsorbate motifs between -0.10 and -1.00 V (vs. SHE). Potential-driven shifts in motif populations produce a volcano-shaped activity trend peaking at -0.70 V, where the site-normalized turnover frequency reaches 0.015 s-1 with nearly 100% Faradaic efficiency to ammonia. The activation barriers across >150 transition states collapse into a single linear relationship with the excess charge on the reacting Cu atoms (ΔqCu), identifying interfacial charge redistribution as a unifying kinetic descriptor. The maximum activity arises not from uniform moderate coverage but from a 2NO/2NH2 quadrilateral microensemble that tunes ΔqCu to an intermediate value, simultaneously lowering the N-O cleavage and N-H formation barriers. Reconceptualizing "coverage" as an ensemble of local microenvironments decouples thermodynamic stability from catalytic productivity. This perspective furnishes a parameter-free strategy by controlling motif populations and interfacial charge via the potential to program high-coverage electrocatalysis beyond the NO3RR.

</details>


### [301] [Re-refinement of the structure of the planar hexagonal phase of ZnO nanocrystals](https://arxiv.org/abs/2511.09912)
*Musen Li,Lingyao Zhang,Wei Ren,Jeffrey R. Reimers*

Main category: cond-mat.mtrl-sci

TL;DR: ZnO的平面六方相（h-ZnO）是一种在薄膜和高压下存在的亚稳态相，该研究通过重新精炼实验数据，证实了h-ZnO在环境条件下可以以亚稳态形式存在，并提供了精确的晶格参数，这对于理解ZnO的极化切换机制具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 探讨ZnO平面六方相（h-ZnO）在环境条件下的存在性及其结构特性，因为其在薄膜和高压下的存在广为人知，但在高纯度纳米晶体中存在性存在争议，且与第一性原理计算结果存在差异。

Method: 重新精炼原始实验数据，使用更先进的技术来确定h-ZnO的晶格参数，并与计算预测结果进行比较。

Result: 获得了a = 3.45±0.02 Å 和 c = 4.46±0.02 Å 的晶格参数，这些参数比先前报道的更大，并且与计算预测结果吻合良好，证实了ZnO可以形成亚稳态的平面六方相。

Conclusion: ZnO可以形成亚稳态的平面六方相，该发现为理解ZnO及其衍生物以及普遍的纤锌矿结构材料中的极化切换机制提供了关键信息。

Abstract: The planar hexagonal phase of ZnO, known as h-ZnO, g-ZnO, alpha-ZnO, the Bk structure, the 5-5 phase, the alpha-BN phase, etc., has P63/mmc symmetry and is implicated in ferroelectric switching mechanisms for wurtzite-ZnO. It is well-known in thin films on substrates, to be pressure stabilized, etc., but critical is its possible existence in high-purity nanocrystals under ambient conditions. Indeed, a crystal structure has been reported, but this work remains controversial as first-principles calculations predict very different structural properties. Herein, the original experimental data is re-refined, using more sophisticated techniques, to yield lattice parameters of a = 3.45+/-0.02 Å and c = 4.46+/-0.02 Å that are 0.35 Å and 0.80 Å, respectively, larger than those previously reported and in good agreement with computational predictions. This confirms that ZnO can form a metastable planar hexagonal phase. It provides key information pertaining to polarization switching in ZnO, its derivatives, and general wurtzite-structured materials.

</details>


### [302] [Electric Field-Induced Phase Transitions and Hysteresis in Ferroelectric HfO2 Captured with Machine Learning Potential](https://arxiv.org/abs/2511.09976)
*Po-Yen Chen,Teruyasu Mizoguchi*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了用于HfO2的机器学习势能（MLP）和原位有效电荷（BEC）模型，以进行大规模原子动力学模拟，能够高效且高保真地捕捉电场相关的铁电现象，并为铁电器件的设计提供新途径。


<details>
  <summary>Details</summary>
Motivation: 研究铁电HfO2在原子尺度上对其在铁电器件和介电器件中应用至关重要的电场效应（如相变和极化滞后），但传统的第一性原理方法在模拟现实电场条件下的原子动力学方面存在计算限制。

Method: 开发了一种机器学习势能（MLP），并将其与原位有效电 Charge（BEC）模型相结合，以实现驱动的分子动力学模拟。

Result: 成功捕捉了电场诱导的相变、极化开关和应变依赖的介电响应，其保真度和计算效率都很高。模拟结果与AIMD结果一致，并揭示了单斜相中可能存在的电场诱导极化激活现象。

Conclusion: 所提出的方法提供了一个可扩展且可转移的工具，用于功能性氧化物的原子尺度探索，并为铁电器件的数据驱动设计铺平了道路。

Abstract: Electric field-induced studies, including phase transition and polarization hysteresis, for ferroelectric HfO2 at the atomic scale are critical since they can largely affect its application in ferroelectric and dielectric devices. However, conventional first-principles approaches are computationally limited in capturing large-scale atomic dynamics under realistic field conditions. Here, to enable electric-field-driven molecular dynamics simulations, we develop a machine learning potential (MLP) tailored for HfO2, coupled with an in-situ Born effective charge (BEC) model. This framework enables us to capture key phenomena, including field-induced phase transitions, polarization switching, and strain-dependent dielectric responses, with high fidelity and computational efficiency. Notably, we reproduce hysteresis loops and phase transition barriers consistent with AIMD results and reveal possible electric-field-induced polarization activation in the monoclinic phase. Our approach offers a scalable and transferable tool for atomistic exploration of functional oxides and paves the way for data-driven design of ferroelectric devices.

</details>


### [303] [Numerical Modeling of Cu2MnSnS4/FeSi2 Dual-Absorber Solar Cell Achieving High Efficiency](https://arxiv.org/abs/2511.10009)
*Hasib Md Abid Bin Farid,Md Tashfiq Bin Kashem*

Main category: cond-mat.mtrl-sci

TL;DR: Cu2MnSnS4 (CMTS) 是一种有潜力的太阳能材料，但研究较少。本研究使用 SCAPS-1D 对 CMTS-FeSi2 双吸收层太阳能电池进行了数值模拟，优化了器件性能，实现了 34.9% 的功率转换效率，展示了 CMTS-FeSi2 双吸收层器件在高效、可持续光伏领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了超越单结器件的效率限制，并解决 Cu2ZnSnS4 (CZTS) 材料中存在的对位无序和次级相形成的问题，本研究探索了 Cu2MnSnS4 (CMTS) 材料在双吸收层太阳能电池中的应用。

Method: 本研究使用 SCAPS-1D 仿真软件，对 CMTS-FeSi2 双吸收层薄膜太阳能电池进行了全面的数值模拟，系统地研究了各种几何、电子和界面参数对载流子传输和器件整体性能的影响。

Result: 优化的 CMTS-FeSi2 双吸收层太阳能电池实现了 34.9% 的功率转换效率，其中开路电压 (VOC) 为 0.79 V，短路电流密度 (JSC) 为 51.07 mA/cm2，填充因子 (FF) 为 85.91%。

Conclusion: CMTS-FeSi2 双吸收层器件的集成不仅能够提高载流子收集和光谱利用率，还为实现高效率、可持续和环境友好的薄膜光伏技术开辟了新的途径。

Abstract: Dual-absorber solar cells represent a promising approach to surpass the efficiency limit of single-junction devices by extending spectral absorption and minimizing thermalization losses. Among earth-abundant thin-film materials, kesterites have attracted considerable interest, however, the well-studied Cu2ZnSnS4 (CZTS) continues to face challenges related to antisite disorder and secondary phase formation. Replacing Zn with Mn in Cu2MnSnS4 (CMTS) mitigates these limitations, improving cation ordering and electronic quality while maintaining favorable optical properties. Yet, despite its potential, CMTS remains largely unexplored in multi-absorber configurations-only one prior study has reported a CMTS-based dual-absorber device. In this work, we present a comprehensive numerical investigation of a CMTS-FeSi2 dual-absorber thin-film solar cell using the one-dimensional solar cell capacitance simulator (SCAPS-1D). FeSi2, with its narrow band gap (0.87 eV) and strong near-infrared absorption, serves as an ideal bottom absorber to complement CMTS, enabling broader spectral utilization. The study systematically examines the effects of geometrical, electronic, and interfacial parameters on carrier transport, and overall device performance. The optimized device delivers an impressive power conversion efficiency of 34.9%, with VOC = 0.79 V, JSC = 51.07 mA/cm2, and a fill factor of 85.91%. These findings demonstrate that integrating FeSi2 with CMTS not only enhances carrier collection and spectral harvesting but also establishes a new pathway toward high-efficiency, sustainable, and environmentally benign thin-film photovoltaics.

</details>


### [304] [Giant tunneling magnetoresistance based on spin-valley-mismatched ferromagnetic metals](https://arxiv.org/abs/2511.10085)
*Kan Yan,Li Cheng,Yizhi Hu,Junjie Gao,Xiaolong Zou,Xiaobin Chen*

Main category: cond-mat.mtrl-sci

TL;DR: Intrinsic spin-valley-mismatched (SVM) states in ferromagnetic materials like 1
t-VSe2, 1
t-VS2, and 2
h-VS2 can block charge transport, mimicking half metals and enabling giant tunneling magnetoresistance (>99%) in spin-valve vdW junctions. This discovery offers a new pathway for designing high-magnetoresistance devices.


<details>
  <summary>Details</summary>
Motivation: The scarcity of available half metals limits the development of high-magnetoresistive devices. This paper seeks to identify alternative materials and mechanisms that can achieve similar or superior performance.

Method: The study employed first-principles transport calculations to investigate the electronic properties of ferromagnetic 1
t-VSe2, 1
t-VS2, and 2
h-VS2. Specifically, it focused on identifying materials with intrinsic spin-valley-mismatched (SVM) states and evaluating their potential in spin-valve van der Waals (vdW) junctions.

Result: The calculations confirmed that ferromagnetic 1
t-VSe2, 1
t-VS2, and 2
h-VS2 exhibit intrinsic spin-valley-mismatched states. It was demonstrated that these materials can lead to giant magnetoresistance exceeding 99% in vdW junctions. The research also highlighted that the central-layer material in these junctions can be any nonmagnetic material due to the intrinsic spin-state mismatch.

Conclusion: Materials with intrinsic spin-valley-mismatched states can effectively function as alternatives to half metals, enabling giant magnetoresistance in electronic devices. This finding expands the design possibilities for high-magnetoresistance devices by utilizing materials like 1
t-VSe2, 1
t-VS2, and 2
h-VS2 and allows for greater flexibility in choosing junction components.

Abstract: Half metals, which are amenable to perfect spin filtering, can be utilized for high-magnetoresistive devices. However, available half metals are very limited. Here, we demonstrate that materials with intrinsic spin-valley-mismatched (SVM) states can be used to block charge transport, resembling half metals and leading to giant tunneling magnetoresistance. As an example, by using first-principles transport calculations, we show that ferromagnetic 1\emph{T}-VSe$_2$, 1\emph{T}-VS$_2$, and 2\emph{H}-VS$_2$ are such spin-valley-mismatched metals, and giant magnetoresistance of more than 99\% can be realized in spin-valve van der Waals (vdW) junctions using these metals as electrodes. Owing to the intrinsic mismatch of spin states, the central-layer materials for the vdW junctions can be arbitrary nonmagnetic materials, in principle. Our research provides clear physical insights into the mechanism for high magnetoresistance and opens new avenues for the search and design of high-magnetoresistance devices.

</details>


### [305] [Graphene assisted III-V epitaxy towards substrate recycling](https://arxiv.org/abs/2511.10097)
*Naomie Messudom,Antonella Cavanna,Ali Madouri,Carlos Macias,Nathalie Bardou,Laurent Travers,Stéphane Collin,Jean-Christophe Harmand,Amaury Delamarre*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在GaAs衬底上生长石墨烯，然后进行外延生长，再对石墨烯进行图形化处理，最后通过两步外延生长法（MBE）成功实现了GaAs外延层的单晶生长，从而降低了高效率III-V太阳能电池的成本。


<details>
  <summary>Details</summary>
Motivation: 为了降低高效率III-V太阳能电池的成本，研究如何再利用衬底。

Method: 在（001）GaAs衬底上沉积石墨烯，然后对石墨烯进行图形化处理，接着通过两步MBE外延生长法（选择性区域生长和横向过度生长）生长GaAs。

Result: 研究发现图形的方向相对于下面GaAs的晶向对GaAs的形貌和质量有影响。当图形方向为[1__10]+22.5{	extdegree}，石墨烯覆盖率为50%时，粗糙度显著降低至3.3nm，获得了最佳结果。

Conclusion: 通过在GaAs衬底上外延生长石墨烯，然后进行图形化和两步外延生长，可以有效降低GaAs外延层的粗糙度，为再利用衬底、降低太阳能电池成本提供了可行方法。

Abstract: Re-using the substrate is identified as a method for reducing the cost of high efficiency III-V solar cells. The approach investigated here consists in inserting a graphene layer onto a (001)GaAs substrate prior to the epitaxial growth of GaAs. To obtain a monocrystalline GaAs grown layer, the graphene layer is patterned, followed by a two-step epitaxial growth, here performed by molecular beam epitaxy (MBE). The first step is a selective area growth of GaAs in graphene openings, followed by a lateral overgrowth, under a modulated Ga flux. The second step, after reaching coalescence, consists in a regular growth under continuous Ga supply. It is observed that the pattern orientations relative to the crystallographic direction of the GaAs substrate below the graphene have an influence on GaAs morphology and quality. The best result was obtained for patterns oriented along [1__10]+22.5{\textdegree} with a graphene coverage of 50%, with a significantly reduced roughness down to 3.3 nm.

</details>


### [306] [pynxtools: A Python framework for generating and validating NeXus files in experimental data workflows](https://arxiv.org/abs/2511.10105)
*Sherjeel Shabih,Lukas Pielsticker,Florian Dobener,Andrea Albino,Theodore Chang,Carola Emminger,Lev Ginzburg,Ron Hildebrandt,Markus Kühbach,Rubel Mozumder,Tommaso Pincelli,Martin Aeschlimann,Marius Grundman,Walid Hetaba,Carlos-Andres Palma,Laurenz Rettig,Markus Scheidgen,José Antonio Márquez Prieto,Claudia Draxl,Sandor Brockhauser,Christoph Koch,Heiko B. Weber*

Main category: cond-mat.mtrl-sci

TL;DR: pynxtools是一个Python软件框架，用于将材料科学实验数据转换为NeXus格式，以提高数据互操作性和FAIR数据管理。


<details>
  <summary>Details</summary>
Motivation: 由于仪器格式不兼容和标准化实践不统一，物理、材料科学和材料工程领域的科学数据难以遵循FAIR原则。

Method: pynxtools提供了一个固定的、版本化的NeXus应用程序定义集，通过其插件架构实现数据和元数据的转换，并进行验证以确保数据正确性和NeXus合规性。它还可以直接集成到研究数据管理系统（如NOMAD）中。

Result: pynxtools简化了NeXus的采用，实现了跨多种实验技术的数据互操作性和FAIR数据管理。

Conclusion: pynxtools通过标准化数据转换和促进NeXus格式的采用，解决了科学数据不遵循FAIR原则的问题，提高了数据互操作性和可管理性。

Abstract: Scientific data across physics, materials science, and materials engineering often lacks adherence to FAIR principles (Barker et al., 2022; Jacobsen et al., 2020; M. D. Wilkinson et al., 2016; S. R. Wilkinson et al., 2025) due to incompatible instrument-specific formats and diverse standardization practices. pynxtools is a Python software development framework with a command line interface (CLI) that standardizes data conversion for scientific experiments in materials science to the NeXus format (Klosowski et al., 1997; Könnecke, 2006; Könnecke et al., 2015) across diverse scientific domains. NeXus defines data storage specifications for different experimental techniques through application definitions. pynxtools provides a fixed, versioned set of NeXus application definitions that ensures convergence and alignment in data specifications across, among others, atom probe tomography, electron microscopy, optical spectroscopy, photoemission spectroscopy, scanning probe microscopy, and X-ray diffraction. Through its modular plugin architecture pynxtools provides conversion of data and metadata from instruments and electronic lab notebooks to these unified definitions, while performing validation to ensure data correctness and NeXus compliance. pynxtools can be integrated directly into Research Data Management Systems (RDMS) to facilitate parsing and normalization. We detail one example for the RDM system NOMAD. By simplifying the adoption of NeXus, the framework enables true data interoperability and FAIR data management across multiple experimental techniques.

</details>


### [307] [MATAI: A Generalist Machine Learning Framework for Property Prediction and Inverse Design of Advanced Alloys](https://arxiv.org/abs/2511.10108)
*Yanchen Deng,Chendong Zhao,Yixuan Li,Bijun Tang,Xinrun Wang,Zhonghan Zhang,Yuhao Lu,Penghui Yang,Jianguo Huang,Yushan Xiao,Cuntai Guan,Zheng Liu,Bo An*

Main category: cond-mat.mtrl-sci

TL;DR: MATAI是一个用于预测和逆向设计铸造合金性能的通用机器学习框架，它结合了合金数据库、深度学习模型、约束优化引擎和AI-实验反馈循环，能够快速发现兼具低密度、高强度和延展性的Ti基合金，并已通过实验验证其优于现有商业材料。


<details>
  <summary>Details</summary>
Motivation: 加速先进金属合金的发现，解决传统方法面临的巨大成分空间、多重性能目标和实际制造约束的挑战。

Method: 开发了一个名为MATAI的通用机器学习框架，该框架集成了合金数据库、基于深度神经网络的性能预测器、约束感知优化引擎以及迭代的AI-实验反馈回路。使用多任务学习和物理信息归纳偏差直接从成分预测关键力学性能（密度、屈服强度、抗拉强度、延伸率）。将合金设计视为约束优化问题，采用结合局部搜索和符号约束编程的双层方法解决。

Result: 在Ti基合金体系中，MATAI在仅七次迭代后即快速识别出能够同时实现低密度（<4.45 g/cm3）、高强度（>1000 MPa）和可观延展性（>5%）的候选材料。实验验证表明，MATAI设计的合金性能优于TC4等商业参考材料。

Conclusion: MATAI框架有潜力在实际设计约束下加速轻质、高性能材料的发现。

Abstract: The discovery of advanced metallic alloys is hindered by vast composition spaces, competing property objectives, and real-world constraints on manufacturability. Here we introduce MATAI, a generalist machine learning framework for property prediction and inverse design of as-cast alloys. MATAI integrates a curated alloy database, deep neural network-based property predictors, a constraint-aware optimization engine, and an iterative AI-experiment feedback loop. The framework estimates key mechanical propertie, sincluding density, yield strength, ultimate tensile strength, and elongation, directly from composition, using multi-task learning and physics-informed inductive biases. Alloy design is framed as a constrained optimization problem and solved using a bi-level approach that combines local search with symbolic constraint programming. We demonstrate MATAI's capabilities on the Ti-based alloy system, a canonical class of lightweight structural materials, where it rapidly identifies candidates that simultaneously achieve lower density (<4.45 g/cm3), higher strength (>1000 MPa) and appreciable ductility (>5%) through only seven iterations. Experimental validation confirms that MATAI-designed alloys outperform commercial references such as TC4, highlighting the framework's potential to accelerate the discovery of lightweight, high-performance materials under real-world design constraints.

</details>


### [308] [Magnetic Frustration Enforced Electronic Reconstruction in Ni intercalated NbSe$_{2}$: Suppression of Electronic Orders](https://arxiv.org/abs/2511.10160)
*Ashutosh S. Wadge,Alexander Kazakov,Xujia Gong,Daniel Jastrzebski,Bogdan J. Kowalski,Artem Lynnyk,Lukasz Plucinski,Amar Fakhredine,Ryszard Diduszko,Marta Aleszkiewicz,Jedrzej Korczak,Dawid Wutke,Marcin Rosmus,Rafal Kurleto,Natalia Olszowska,Carmine Autieri,Andrzej Wisniewski*

Main category: cond-mat.mtrl-sci

TL;DR: 镍插入显著改变了NbSe2的物理性质，导致反铁磁序、磁无序和磁挫败，并抑制了电荷密度波和超导性。电子结构的变化，特别是范霍夫奇点的移动，是这些现象的主要原因。


<details>
  <summary>Details</summary>
Motivation: 研究镍插入如何深刻改变NbSe2的物理性质，探索其磁性、电荷密度波和超导电性。

Method: 通过磁测量、电阻率测量和角分辨光电子能谱（ARPES）来研究Ni0.19NbSe2单晶。

Result: 发现Ni0.19NbSe2在23.5 K以下表现出反铁磁序，在10 K附近出现不可逆温度，并伴有小的净磁矩。电阻率测量显示电荷密度波和超导电性在300 mK以下被完全抑制。ARPES测量揭示了电子结构的改变，包括一个范霍夫奇点的移动，这被认为是抑制电子序的主要原因。

Conclusion: Ni0.19NbSe2处于一个磁挫败、非超导状态，表明部分插入和无序会驱动低维量子材料中复杂的磁序和费米面重构。

Abstract: We investigate the single crystals of Ni$_{0.19}$NbSe$_2$, revealing that Ni intercalation profoundly alters the physical properties of NbSe$_2$. Magnetic measurements clearly show that the system is magnetically frustrated with antiferromagnetic ordering below 23.5\,K, with an irreversibility temperature near 10\,K, and a magnetic hysteresis with a small net magnetic moment. Overall, the system can be described as an inhomogeneous antiferromagnetic phase with magnetic disorder and magnetic frustration. We found two Curie-Weiss temperatures of -80\,K for the field in the {\it ab}-plane and -137\,K for the field out of plane, which are a consequence of anisotropic interactions in spin space and favor an orientation of the spin along the {\it c}-axis. Temperature-dependent resistivity shows a complete suppression of both charge density waves and superconducting order down to 300\,mK. Angle-resolved photoemission spectroscopy at 84\,K reveals a $\overlineΓ$-centered electron pocket in Ni$_{0.19}$NbSe$_2$, which is absent in pristine NbSe$_2$. The electronic structure results show a shift of the van Hove singularity (VHS), which is the main cause of the suppression of the electronic orders. These results align with recent theoretical predictions that Ni intercalation with cationic disorder favors frustrated antiferromagnetic stripe states, shifts the VHS and reconstructs the Fermi surface in NbSe$_2$. Our findings position Ni$_{0.19}$NbSe$_2$ within a magnetically frustrated, non-superconducting regime, highlighting how partial intercalation and disorder drive complex magnetic order and the Fermi surface reconstruction in low-dimensional quantum materials.

</details>


### [309] [Wavelength-commensurate anatase TiO\_2 particles for ro-bust and functional Mie resonances across the visible and near infrared](https://arxiv.org/abs/2511.10169)
*Pedro Tartaj,Yurena Luengo,Pedro Moronta,Luisina Forzani,Alvaro Blanco,Cefe López*

Main category: cond-mat.mtrl-sci

TL;DR: 地壳丰度材料在可见光和近红外区域的米氏共振提供了高效和可持续传感、热调节和阳光收集的机会。对于锐钛矿TiO2，一种宽带光学和丰度材料，米氏计算表明，稳健的共振需要尺寸可调性和单分散性（标准差<5%），实验尚未覆盖范围（0.5-2μm），同时保持高于2的折射率以确保与生物分子的光学对比度。本研究通过简单的紫外辅助热水解路线，制备了符合所有这些标准的锐钛矿颗粒，并保持了水加工性。因此，这些材料在可见光/近红外区域（包括生物窗口）显示出强烈且可调的米氏共振，优于先前受尺寸限制的结果。强光学共振结合环境温度加工性，能够对透明生物分子进行稳健、宽带、无标记检测。我们的见解推动了地壳丰度材料的精确合成和基于米氏的光子学，并表明通过印刷技术进行成本效益高且按需快速集成，并且锐钛矿的生物相容性和光化学性质进一步增强了其潜力。


<details>
  <summary>Details</summary>
Motivation: 利用地壳丰度材料（特别是锐钛矿TiO2）在可见光和近红外区域实现高效和可持续的传感、热调节和阳光收集。

Method: 通过紫外辅助热水解路线制备锐钛矿TiO2颗粒，实现所需的尺寸可调性、单分散性和折射率，并保持水加工性。

Result: 成功制备出满足尺寸（0.5-2μm）、单分散性（<5%）和折射率（>2）要求的锐钛矿TiO2颗粒，这些颗粒在可见光/近红外区域（包括生物窗口）表现出强烈且可调的米氏共振，并实现了对透明生物分子的稳健、宽带、无标记检测。

Conclusion: 地壳丰度材料（锐钛矿TiO2）的精确合成和基于米氏的光子学取得了进展，通过印刷技术实现成本效益高且按需快速集成的潜力，并具有生物相容性和光化学特性。

Abstract: Earth-abundant materials exhibiting Mie resonances across the visible and near-infrared offer opportunities for efficient and sustainable sensing, thermal regulation, and sunlight harvesting. For anatase TiO$_2$, a broadband optical and abundant material, Mie calculations indicate that robust resonances require size tunability and monodispersity (standard deviation, $\lesssim$ 5\%) over an extended range (0.5-2 $μ$m) not yet experimentally covered, while maintaining a refractive index above 2 to ensure optical contrast, for example with biomolecules. Here, we demonstrate that a simple UV-assisted thermal hydrolysis route yields anatase particles that meet all these criteria and remain aqueous-processable. Consequently, the materials display intense and modulable Mie resonances across the visible/near-infrared regions (including biological windows), outperforming previous results that were limited by size. Strong optical resonances combined with ambient-temperature processability enable robust, broadband, label-free detection of transparent biomolecules. Our insights advance precise synthesis and Mie-based photonics of an earth-abundant material, and indicate the potential for cost-effective and rapid-on-demand integration via printing technologies, further enhanced by anatase's biocompatibility and photochemical properties.

</details>


### [310] [Time-resolved splitting of magnons into vortex gyration and Floquet spin waves](https://arxiv.org/abs/2511.10450)
*T. Devolder,R. Lopes Seeger,C. Heins,A. Jenkins,L. C. Benetti,A. Schulman,R. Ferreira,G. Philippe,C. Chappert,H. Schultheiss,K. Schultheiss,J. -V. Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 在磁性涡旋态圆盘中，施加特定频率的激励会激发回旋模，并生成频率梳状的Floquet自旋波。研究表明，该动力学状态的出现存在一个共同的潜伏期，该潜伏期在散射阈值处发散，并且在驱动与第一阶方位角自旋波共振时最短。通过微波电测量，我们发现最强的Floquet模与回旋模同步出现。我们推断，最先发生的散射机制是将常规方位角本征模分裂成一个由回旋磁振子和Floquet自旋波组成的相干对。


<details>
  <summary>Details</summary>
Motivation: 研究磁性涡旋态圆盘中，由于外加激励频率接近第一阶方位角自旋波时，诱导的涡旋回旋运动以及由此产生的Floquet自旋波（频率梳）的动力学行为。

Method: 利用时间分辨微波电测量技术，研究上述动力学状态的暂态演化过程。

Result: 在特定频率激励下，最强的Floquet模和涡旋回旋模几乎同时出现，并且经历一个共同的潜伏期。该潜伏期随激励功率的增加而缩短，在散射阈值处发散。当激励频率与第一阶方位角自旋波共振时，潜伏期最短，可达3纳秒。

Conclusion: 最先发生的散射机制是将常规方位角本征模通过三波分裂过程，转化为一个回旋磁振子和一个Floquet自旋波构成的相干对。

Abstract: Forced excitations at frequencies in the range of the first order azimuthal spin waves of a magnetic disk in the vortex state are known to scatter into the vortex gyration mode, thereby allowing the growth of Floquet spin waves forming a frequency comb. We study the temporal emergence of this dynamical state using time-resolved microwave electrical measurements. The most intense Floquet mode emerges synchronously with the gyration mode after a common incubation delay which diverges at the scattering threshold. This delay is minimal when the drive is resonant with one of the first order azimuthal spin waves. It can be as short as 3 ns for the maximum investigated power. We conclude that the first-to-occur scattering mechanism is the three-wave splitting of a regular azimuthal eigenmode into a coherent pair formed by a gyration magnon and a Floquet spin wave.

</details>


### [311] [Scalable data-driven modeling of microstructure evolution by learning local dependency and spatiotemporal translation invariance rules in phase field simulation](https://arxiv.org/abs/2511.10171)
*Zishuo Lan,Qionghuan Zeng,Weilong Ma,Xiangju Liang,Yue Li,Yu Chen,Yiming Chen,Xiaobing Hu,Junjie Li,Lei Wang,Jing Zhang,Zhijun Wang,Jincheng Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过训练极小数据集的卷积神经网络（CNN）来加速相位场（PF）模拟，实现向更大系统和更长时间尺度的可扩展性和可靠预测。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法需要大量的训练数据，并且是黑盒模型，引起了对长期预测可靠性的担忧。

Method: 通过分析CNN的归纳偏置与PF模拟的物理先验（局部性和时空平移不变性）之间的对齐来加速PF模拟。

Result: CNN模型即使在仅使用单个小规模模拟的极小数据集上进行训练，也能实现向更大系统的无缝扩展和对训练数据时间范围之外的可靠长期预测。模型捕捉到了PF模拟的局部性和时空平移不变性。

Conclusion: CNN模型通过建立网格点局部环境与其后续状态之间的时空不变回归映射，以及认识到微观结构演化是对有限局部环境的连续重新分布，从而实现了对相位场模拟的加速和长期可靠预测。

Abstract: Phase-field (PF) simulation provides a powerful framework for predicting microstructural evolution but suffers from prohibitive computational costs that severely limit accessible spatiotemporal scales in practical applications. While data-driven methods have emerged as promising approaches for accelerating PF simulations, existing methods require extensive training data from numerous evolution trajectories, and their inherent black-box nature raises concerns about long-term prediction reliability. This work demonstrates, through examples of grain growth and spinodal decomposition, that a minimalist Convolutional Neural Network (CNN) trained with a remarkably small dataset even from a single small-scale simulation can achieve seamless scalability to larger systems and reliable long-term predictions far beyond the temporal range of the training data. The key insight of this work lies in revealing that the success of CNN-based models stems from the alignment between their inductive biases and the physical priors of phase-field simulations specifically, locality and spatiotemporal translation invariance. Through effective receptive field analysis, we verify that the model captures these essential properties during training. Therefore, from a reductionist perspective, the surrogate model essentially establishes a spatiotemporally invariant regression mapping between a grid point's local environment and its subsequent state. Further analysis of the model's feature space demonstrates that microstructural evolution effectively represents a continuous redistribution of a finite set of local environments. When the model has already encountered nearly all possible local environments in the early-stage training data, it can reliably generalize to much longer evolution timescales, regardless of the dramatic changes in global microstructural morphology.

</details>


### [312] [Dual-Mode Luminescent Thermometry in LiYO2:Nd3+,Yb3+ Enabled by Structural Phase Transition and Phonon-Assisted Energy Transfer](https://arxiv.org/abs/2511.10185)
*M. Tahir Abbas,M. Szymczak,D. Szymanski,M. Drozd,G. Chen,L. Marciniak*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究开发了一种结合了比率和寿命两种读出策略的发光温度计，利用了LiYO2的结构相变和Yb3+到Nd3+的声子辅助能量转移两种热效应。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够通过比率和寿命两种方式进行读数的新型双模发光温度计，以实现更宽的温度测量范围和更高的灵活性。

Method: 1. 利用LiYO2的结构相变，通过改变Yb3+离子的发射光谱形状来实现比率温度计；2. 利用Yb3+到Nd3+的声子辅助能量转移，通过测量激发态寿命来实现寿命温度计；3. 调节Nd3+浓度以优化灵敏度和最大灵敏度出现的温度。

Result: 1. 比率温度计在290 K时最大相对灵敏度(SR)为3.1% K^-1 (LiYO2掺杂10% Yb3+, 1% Nd3+)；2. 寿命温度计在378 K时最大相对灵敏度(SR)为1.5% K^-1 (LiYO2掺杂20% Nd3+)；3. 调节Nd3+浓度可以调整灵敏度和最大灵敏度出现时的温度；4. 两种模式的最大灵敏度对应的温度范围不同，拓宽了传感器的热工作窗口；5. LiYO2:Nd3+,Yb3+也可以通过不同时间门的发光强度比来测温；6. 声子辅助能量转移在塑造发光动力学中起主导作用，优于结构相变。

Conclusion: LiYO2:Nd3+,Yb3+是一种有潜力用于多模式发光测温应用的新材料。

Abstract: In this work, a dual-mode luminescent thermometer operating via both ratiometric and lifetime-based readout strategies was developed, enabled by the coexistence of two thermally driven effects: a structural phase transition in LiYO2 and a phonon-assisted energy transfer from Yb3+ to Nd3+. As demonstrated, changes in the shape of the emission band of Yb3+ ions corresponding to the 2F5/2 -> 2F7/2 electronic transition, induced by the phase transition, enabled the design of a ratiometric thermometer with a maximum relative sensitivity (SR) of 3.1% K^-1 for LiYO2 doped with 10% Yb3+ and 1% Nd3+ at 290 K. In contrast, the temperature-dependent Yb3+ -> Nd3+ energy transfer facilitated the development of a lifetime-based thermometer with a maximum SR of 1.5% K^-1 for 20% Nd3+ at 378 K. In both approaches, tuning the Nd3+ concentration allowed modulation of both the sensitivity and the temperature at which the maximum SR occurred. This was achieved by shifting the phase transition temperature and increasing the probability of interionic energy transfer, respectively.
  Notably, the temperature ranges corresponding to the maximum SR for the ratiometric and lifetime modes were distinct, effectively broadening the thermal operating window of the sensor. Additionally, it was shown that LiYO2 doped with Nd3+ and Yb3+ can also be used as a temperature sensor through the ratio of luminescence intensities recorded at two different time gates. Furthermore, the results confirmed that the phonon-assisted energy transfer process plays the dominant role in shaping the luminescence kinetics, surpassing the influence of the structural phase transition. Overall, this study identifies LiYO2:Nd3+,Yb3+ as a promising candidate for multimodal luminescent temperature sensing applications.

</details>


### [313] [Direct Raman observation of the quantum metric in a quantum magnet](https://arxiv.org/abs/2511.10246)
*Chao-Fan Wang,Han Ge,Jun-Yang Chen,Liusuo Wu,Xiaobin Chen,Jia-Wei Mei,Mingyuan Huang*

Main category: cond-mat.mtrl-sci

TL;DR: Raman光谱可用于测量量子磁体K2Co(SeO3)2的量子度量，这在以前是无法实现的。


<details>
  <summary>Details</summary>
Motivation: 以前的Raman研究只能测量Berry曲率，而无法测量量子度量，本研究旨在利用Raman光谱同时测量这两种可观测量，以揭示它们的微观起源。

Method: 对量子磁体K2Co(SeO3)2进行圆偏振Raman光谱测量，并分析了场奇偶分离和中心频率移动与温度和磁场的关系。

Result: 发现场奇偶分离和中心频率移动可以归结为单一曲线，表明它们具有共同的微观起源。通过经验二次关系很好地拟合了两种可分辨的Eg模式数据。

Conclusion: Raman光谱可以直接探测量子度量，并能在单次测量中实现量子几何的可操作分解。

Abstract: The quantum geometric tensor (QGT) unifies the Berry curvature (its imaginary part) and the quantum metric (its real part), yet Raman studies of chiral phonons have so far accessed only the former. We perform circularly polarized Raman spectroscopy on the quantum magnet K2Co(SeO3)2, where the field-odd chiral splitting and the field-even center-frequency shift collapse onto a single curve across temperature and magnetic field, revealing a common microscopic origin for both observables. Since the chiral splitting reflects the Berry curvature, the concomitant even component, arising from the same microscopic origin, captures the field-induced change of the quantum metric, corresponding to the diagonal Born-Oppenheimer correction. Across two resolvable Eg modes, the unified data are well captured by a simple empirical quadratic relation. These results establish Raman spectroscopy as a direct probe of the quantum metric and an operational decomposition of quantum geometry within a single measurement.

</details>


### [314] [Effect of Concentration Fluctuations on Material Properties of Disordered Alloys](https://arxiv.org/abs/2511.10259)
*Han-Pu Liang,Chuan-Nan Li,Xin-Ru Tang,Xun Xu,Chen Qiu,Qiu-Shi Huang,Su-Huai Wei*

Main category: cond-mat.mtrl-sci

TL;DR: 通过提出一种新的密度-态拟合（DOSF）方法，解决了无序合金（特别是半导体）带隙计算的长期存在的问题。


<details>
  <summary>Details</summary>
Motivation: 标准SQS方法在计算无序合金的带隙时，由于稀有事件基序导致波函数局域化，会低估带隙值，与实验结果不符。

Method: 提出了一种密度-态拟合（DOSF）方法，用于从多数组态中提取合金带隙，以解决标准SQS计算的不足。

Result: DOSF方法可以从多数组态中准确提取合金带隙，与实验结果一致，解决了标准SQS方法的问题。

Conclusion: DOSF方法为计算无序半导体合金的电子结构提供了一种有效途径，并建议为依赖局域化合金波函数的其他材料特性开发类似方法。

Abstract: Alloying compound AX with another compound BX is widely used to tune material properties. For disordered alloys, due to the lack of periodicity, it has been challenging to calculate and study their material properties. Special quasi-random structure (SQS) method has been developed and widely used to treat this issue by matching averaged atomic correlation functions to those of ideal random alloys, enabling accurate predictions of macroscopic material properties such as total energy and volume. However, in AxB1-x alloys, statistically allowed local concentration fluctuations can give rise to defect-like minority configurations, such as bulk-like AX or BX regions in the extreme, which could strongly affect calculation of some of the material properties such as semiconductor bandgap, if it is not defined properly, leading to significant discrepancies between theory and experiment. In this work, taking the bandgap as an example, we demonstrate that the calculated alloy bandgap can be significantly underestimated in standard SQS calculations when the SQS cell size is increased to improve the structural model and the bandgap is defined conventionally as the energy difference between the lowest unoccupied state and the highest occupied state, because the rare event motifs can lead to wavefunction localization and become the dominant factor in determining the "bandgap", contrary to experiment. To be consistent with experiment, we show that the bandgap of the alloy should be extracted from the majority configurations using a density-of-states fitting (DOSF) method. This DOSF approach resolves the long-standing issue of calculating electronic structure of disordered semiconductor alloys. Similar approaches should also be developed to treat material properties that depends on localized alloy wavefunctions.

</details>


### [315] [Probing the Liquid Solid Interfaces of 2D SnSe MXene Battery Anodes at the Nanoscale](https://arxiv.org/abs/2511.10278)
*Lukas Worch,Kavin Arunasalam,Neil Mulcahy,Syeda Ramin Jannat,James Douglas,Baptiste Gault,Valeria Nicolosi,Michele Shelly Conroy*

Main category: cond-mat.mtrl-sci

TL;DR: SnSe在锂离子电池中表现出高容量，但体积变化大，导致容量衰减。将SnSe纳米颗粒嵌入Ti3C2Tx MXene框架中，并通过冷冻聚焦离子束（cryo FIB）和冷冻原子探针断层扫描（cryo APT）进行分析，揭示了SnSe在循环过程中的材料再分布、形态变化、相变、活性材料溶解以及铜集流体的腐蚀和铜离子迁移等降解机制，表明铜集流体降解是导致复合电极化学污染和容量衰减的重要因素。


<details>
  <summary>Details</summary>
Motivation: 理解锂离子电池的退化机制对于提高长期性能和推动可持续能源技术至关重要。SnSe作为一种有前景的负极材料，理论容量高，但存在体积变化大、机械不稳定性及容量衰减等问题。本研究旨在通过嵌入Ti3C2Tx MXene框架来改善SnSe的性能，并利用先进的成像技术揭示其退化机制。

Method: 采用冷冻聚焦离子束（cryo FIB）进行切片和观察，以揭示循环过程中的材料再分布和形态变化。随后，利用冷冻原子探针断层扫描（cryo APT）对选定区域进行高空间和化学分辨率的分析，以在不破坏对电子束敏感的相的情况下，揭示纳米尺度的退化机制，包括相变、活性材料溶解以及铜集流体的腐蚀和铜离子迁移。

Result: 研究发现，SnSe在循环过程中会发生材料再分布和形态变化。通过cryo APT分析，首次直接观察到铜集流体的腐蚀和铜离子从集流体迁移到电极材料中的现象。这表明铜集流体的退化是导致复合电极化学污染和容量衰减的重要原因。

Conclusion: 本研究结合使用cryo FIB 和 cryo APT 技术，提供了一个强大的分析流程，能够阐明在锂离子电池等反应性和对电子束敏感的体系中的电极退化机制。研究结果为设计更耐用、更稳定的下一代电池材料提供了关键见解，特别是强调了解决铜集流体退化问题的重要性。

Abstract: Understanding degradation processes in lithium ion batteries is essential for improving long term performance and advancing sustainable energy technologies. Tin selenide (SnSe) has emerged as a promising anode material due to the high theoretical capacity of tin. Unlike conventional intercalation based electrodes, SnSe undergoes conversion and alloying reactions with lithium to form Li4.4Sn, Sn, and Li2Se, enabling high lithium storage but inducing large volume changes that cause mechanical instability and capacity fading. Embedding SnSe nanoparticles within a Ti3C2Tx MXene framework offers a strategy to mitigate these effects by enhancing conductivity and structural resilience. Here, cryogenic focused ion beam (cryo FIB) slice and view revealed progressive material redistribution and morphological transformation during cycling, underscoring the need for site specific chemical analysis. Cryogenic atom probe tomography (cryo APT) of selected regions provided high spatial and chemical resolution while preserving beam sensitive phases, uncovering nanoscale degradation mechanisms including phase transformations, partial dissolution of active material, and, importantly, the first direct evidence of copper corrosion and copper ion migration from the current collector into the electrode. The observation of copper redistribution demonstrates that current collector degradation contributes directly to chemical contamination and capacity fading in composite electrodes. Together, cryo FIB and cryo APT provide a powerful workflow for elucidating electrode degradation in reactive, beam sensitive systems, offering critical insights for designing more durable and stable next generation battery materials.

</details>


### [316] [Out-of-Plane Nonlinear Orbital Hall Torque](https://arxiv.org/abs/2511.10314)
*Hui Wang,Xukun Feng,Jin Cao,Huiying Liu,Weibo Gao,Cong Xiao,Shengyuan A. Yang,Lay Kee Ang*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出利用非线性轨道霍尔效应产生用于磁性开关的非平移轨道扭矩，并在拓扑材料中得到实验验证。


<details>
  <summary>Details</summary>
Motivation: 尽管轨道电子学取得了进展，但产生用于确定性磁性开关的垂直磁化轨道扭矩仍然是一个挑战。

Method: 利用非线性轨道霍尔效应，并通过第一性原理计算在RhSi、YPtBi和PbTaSe2等拓扑材料中进行验证。

Result: 非线性轨道扭矩显著超过了线性机制产生的扭矩，并且在具有强自旋-轨道耦合的材料中，轨道效应主导了自旋效应。

Conclusion: 该研究将轨道输运研究推向非线性领域，扩大了轨道材料的范围，并为开发高性能轨道电子器件提供了新途径。

Abstract: Despite recent advances in orbitronics, generating out-of-plane orbital torques essential for field-free deterministic switching of perpendicular magnetization remains a key challenge. Here, we propose a strategy to produce such unconventional torques across broad classes of materials, by leveraging the nonlinear orbital Hall effect. We demonstrate that this nonlinear orbital response is dramatically amplified by topological band degeneracies, where it overwhelmingly dominates the spin response even in systems with strong spin-orbit coupling. These features are confirmed via a quantitative investigation of representative topological metals RhSi, YPtBi, and PbTaSe$_2$, by combining our theory with first-principles calculations. The resulting orbital torques substantially surpass those from linear mechanisms reported thus far. These findings propel the research of orbital transport into the nonlinear regime, broaden the scope of orbital source materials, and establish a new pathway towards high-performance orbitronic devices.

</details>


### [317] [Spin and lattice dynamics at the spin-reorientation transitions in the rare-earth orthoferrite Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$](https://arxiv.org/abs/2511.10396)
*R. M. Dubrovin,A. I. Brulev,N. R. Vovk,I. A. Eliseyev,N. N. Novikova,V. A. Chernyshev,A. N. Smirnov,V. Yu. Davydov,Anhua Wu,Liangbi Su,R. V. Mikhaylovskiy,A. M. Kalashnikova,R. V. Pisarev*

Main category: cond-mat.mtrl-sci

TL;DR: Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$在自旋重取向转变中表现出异常宽的中间磁结构相，这归因于稀土离子分布不均导致的磁晶各向异性改变。


<details>
  <summary>Details</summary>
Motivation: 研究稀土铁酸盐中磁激发和晶格激发的耦合，以及其在自旋重取向转变中的行为。

Method: 使用偏振红外反射和拉曼散射光谱技术，结合第一性原理计算，研究Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$的自旋和晶格动力学。

Result: 确定了红外和拉曼活性声子的参数，揭示了在T$_{1}$ ≈ 220 K和T$_{2}$ ≈ 130 K发生的自旋重取向转变。发现在T$_{24}$相中，中间磁结构表现出异常宽的温度范围（ΔT ≈ 90 K），这归因于Sm$^{3+}$和Tb$^{3+}$离子随机分布引起的不均匀磁结构对磁晶各向异性的影响。未观察到由自旋重取向转变引起的拉曼活性B$_{1g}$声子参数变化或新声子的出现。

Conclusion: Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$中宽广的中间磁结构相为理解稀土铁酸盐中的磁声子现象提供了基础。

Abstract: Linear and non-linear couplings of magnetic and lattice excitations are at the heart of many fascinating magnetophononic phenomena observed in rare-earth orthoferrites, the distinctive feature of which is the tendency to spin-reorientation transitions. Here we report the results of the experimental study of the spin and lattice dynamics in the Brillouin zone center of the rare-earth orthoferrite Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$ by using polarized infrared reflectivity and Raman scattering spectroscopic techniques. The obtained results were supported by the first-principles calculations, which allowed us to reliably identify the parameters of most infrared- and Raman-active phonons. We reveal the spin-reorientation transitions $Γ_{4}(G_{a}F_{c}) \overset{T_{1}}\longleftrightarrow Γ_{24}(G_{ac}F_{ac}) \overset{T_{2}}\longleftrightarrow Γ_{2}(G_{c}F_{a})$ at $T_{1} \simeq 220$ K and $T_{2} \simeq 130$ K and carefully studied the following evolution of Raman scattering on magnetic excitations at these transitions. Notably, the intermediate magnetic structure $Γ_{24}$ displays an exceptionally broad temperature range $Δ{T} = T_{1} - T_{2} \simeq 90$ K in mixed Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$ compared to pure rare-earth orthoferrites. We attribute this broadening of the intermediate phase to the modification of the magnetocrystalline anisotropy as a result of the inhomogeneous magnetic structure caused by the random distribution of rare-earth $\mathrm{Sm}^{3+}$ and $\mathrm{Tb}^{3+}$ ions. We found neither change in the parameters of Raman-active $B_{1g}$ phonons nor the appearance of new phonons induced by spin-reorientation transitions, which have been reported in $\mathrm{SmFeO}_{3}$. We assume that our results provide a solid basis for more deeper understanding of magnetophononic phenomena in rare-earth orthoferrites.

</details>


### [318] [Relaxation approach to quantum-mechanical modeling of ferroelectric and antiferroelectric phase transitions](https://arxiv.org/abs/2511.10485)
*Nikhilesh Maity,Sergey Lisenkov,Arlies Valdespino,Milan Haddad,Lewys Jones,Amit Kumar,Nazanin Bassiri-Gharb,Inna Ponomareva*

Main category: cond-mat.mtrl-sci

TL;DR: 通过基于量子力学的弛豫过程模型，可以克服传统模型在铁电体和抗铁电体相变模拟中的局限性，并实现高效的第一性原理模拟。


<details>
  <summary>Details</summary>
Motivation: 为了更深入地理解铁电体和抗铁电体相变，并可靠地预测其性质，需要对现有模型进行改进，克服其定性化和经验性的局限。

Method: 提出了一种基于“相变是弛豫过程”和“相变需要量子力学处理”两个假设的新模型，并将其应用于铁电体和抗铁电体相变模拟。

Result: 该模型成功克服了传统模型的局限性，能够进行高效的第一性原理模拟，并证明了量子力学在这些通常被认为是经典过程的相变中的重要性。

Conclusion: 新提出的基于量子力学弛豫过程的模型能够有效地模拟铁电体和抗铁电体的相变，并为更广泛的相变现象（包括磁性、弹性、多铁性、电子相变以及量子隧穿、化学反应速率等）的建模提供了新的框架。

Abstract: Ferroelectrics and antiferroelectrics are the electric counterparts of ferromagnets and antiferromagnets. These materials undergo temperature- and electric-field-induced phase transitions that give rise to their characteristic hysteresis loops. Modeling such hysteresis loops and associated phase transitions enables both a deeper fundamental understanding and reliable property predictions for this important class of materials. To date, modeling has largely relied on classical approaches, often remaining qualitative and/or empirical. Traditional interpretation of these transitions rests on two assumptions: (i) they are activated Arrhenius-type processes and (ii) they occur well within the classical regime. Here, we demonstrate that a model can instead be built on two ''orthogonal`` assumptions: (i) the phase transitions are relaxational processes and (ii) they require a quantum mechanical treatment. Applying this model to both antiferroelectrics and ferroelectrics overcomes the limitations of traditional models and enables efficient first-principles simulations of phase transitions. Furthermore, the success of our unconventional approach highlights the significance of quantum mechanics in transitions long regarded as purely classical. We anticipate that this framework will be applicable to a broad range of phase transitions, including magnetic, elastic, multiferroic, and electronic, along with modeling of quantum tunneling, rates of chemical reactions, and others.

</details>


### [319] [In-vacuum surface flashover of SiN, AlN, and etched SiO2 thin films at micrometre scales](https://arxiv.org/abs/2511.10528)
*Vijay Kumar,Martin Siegele-Brown,Matthew Aylett,Sebastian Weidt,Winfried Karl Hensinger*

Main category: cond-mat.mtrl-sci

TL;DR: SiN and AlN thin films show higher surface flashover voltage thresholds than SiO2 films, with etching chemistries having little effect on SiO2 performance.


<details>
  <summary>Details</summary>
Motivation: Investigate the surface flashover voltage threshold for SiO2, SiN, and AlN thin films and the effects of different etching chemistries on SiO2 layers.

Method: Tested the surface flashover voltage threshold for SiO2, SiN, and AlN thin films over micrometre scale lengths. Also tested the effects of hydrogen fluoride and Transene AlPad Etch 639 on SiO2 layers.

Result: SiN and AlN samples performed significantly better than all SiO2 samples, showing a 45% increase in surface flashover voltage at a 5 μm distance, with the difference increasing with electrode spacing. Etching chemistries had little significant effect on SiO2 performance.

Conclusion: SiN and AlN are superior to SiO2 for applications requiring high surface flashover voltage thresholds.

Abstract: We investigate the surface flashover voltage threshold for SiO$_2$, SiN, and AlN thin films over micrometre scale lengths. Furthermore, we test the effects of different etching chemistries on SiO$_2$ layers. We find that there is little significant difference between untreated SiO$_2$ samples and those that have been etched with hydrogen fluoride or Transene AlPad Etch 639. SiN and AlN samples performed significantly better than all SiO$_2$ samples giving a 45% increase in surface flashover voltage at a distance of 5 $μ$m with the difference increasing with electrode spacing.

</details>


### [320] [Excitonic Landscapes in Monolayer Lateral Heterostructures Revealed by Unsupervised Machine Learning](https://arxiv.org/abs/2511.10600)
*Maninder Kaur,Nicolas T. Sandino,Jason P. Terry,Mahdi Ghafariasl,Yohannes Abate*

Main category: cond-mat.mtrl-sci

TL;DR: 二维异质结材料（如Mo_xW_{1-x}S_2）的光电特性可通过机器学习方法进行分析，以克服手动解释数据的局限性。


<details>
  <summary>Details</summary>
Motivation: 二维材料的异质结在光电特性和一维界面物理学研究方面表现出巨大潜力，但现有数据分析方法（如高光谱和纳米分辨光致发光成像）效率低下且主观性强。

Method: 结合主成分分析（PCA）、t分布随机邻域嵌入（t-SNE）和基于密度的空间聚类（DBSCAN）的无监督机器学习框架，用于分析二维材料的光谱数据。

Result: 该框架能够识别与成分、应变和缺陷变化相关的不同光谱区域，并通过分解代表性光谱揭示了多种发射物种，包括带边激子和缺陷相关跃迁。

Conclusion: 机器学习驱动的分析方法为解释二维材料复杂的、可调的光学特性提供了一种稳健且自动化的途径。

Abstract: Two-dimensional (2D) in-plane heterostructures including compositionally graded alloys and lateral heterostructures with defined interfaces display rich optoelectronic properties and offer versatile platforms to explore one-dimensional interface physics and many-body interaction effects. Graded \(\mathrm{Mo}_x\mathrm{W}_{1-x}\mathrm{S}_2\) alloys show smooth spatial variations in composition and strain that continuously tune excitonic emission, while \(\mathrm{MoS}_2\)--\(\mathrm{WS}_2\) lateral heterostructures contain atomically sharp interfaces supporting one-dimensional excitonic phenomena. These single-layer systems combine tunable optical and electronic properties with potential for stable, high-performance optoelectronic devices. Hyperspectral and nano-resolved photoluminescence (PL) imaging enable spatial mapping of optical features along with local variations in composition, strain, and defects, but manual interpretation of such large datasets is slow and subjective. Here, we introduce a fast and scalable unsupervised machine-learning (ML) framework to extract quantitative and interpretable information from hyperspectral PL datasets of graded \(\mathrm{Mo}_x\mathrm{W}_{1-x}\mathrm{S}_2\) alloys and \(\mathrm{MoS}_2\)--\(\mathrm{WS}_2\) heterostructures. Combining principal-component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), and density-based spatial clustering (DBSCAN), we uncover spectrally distinct domains associated with composition, strain, and defect variations. Decomposition of representative spectra reveals multiple emission species, including band-edge excitons and defect-related transitions, demonstrating that ML-driven analysis provides a robust and automated route to interpret rich optical properties of 2D materials.

</details>


### [321] [Uniaxial strain tuning of polar lattice vibrations in KTaO$_3$ and SrTiO$_3$](https://arxiv.org/abs/2511.10623)
*I. Khayr,N. Somun,S. Hameed,Z. Van Fossan,X. He,R. Spieker,S. Chi,E. Clements,D. M. Pajerowski,M. Minola,B. Keimer,T. Birol,D. Pelc,M. Greven*

Main category: cond-mat.mtrl-sci

TL;DR: 本论文研究了SrTiO3和KTO这两种量子材料在应变诱导的铁电相变过程中的软极性声子演化。研究结合了非弹性中子散射、拉曼光谱和从头计算等多种方法。


<details>
  <summary>Details</summary>
Motivation: 研究了具有强铁电涨落的量子材料（如SrTiO3和KTO）中电子和结构自由度的相互作用，重点关注其铁电相变的性质和相关涨落。

Method: 结合使用非弹性中子散射、拉曼光谱和从头计算方法，研究应变诱导的铁电相变过程中软极性声子的演化。

Result: 发现声子模式保持欠阻尼且能量非零，表明相变为一阶量子相变。揭示了在绝缘的KTO和STO中，声子能量与静态介电常数之间的Lyddane-Sachs-Teller关系被强烈违反，这表明存在由长程相互作用引起的慢介观涨落。在金属SrTiO3中，观察到了一阶相变，且临界应力非常低。

Conclusion: 该研究解决了关于STO和KTO这两种模型系统的几个长期存在的问题，并对其他具有软极性声子的材料具有参考意义。

Abstract: The interplay of electronic and structural degrees of freedom is a prominent feature of many quantum materials and of particular interest in systems with strong ferroelectric fluctuations, such as SrTiO$_3$ (STO) and KTaO$_3$ (KTO). Both materials are close to a ferroelectric transition, but despite six decades of extensive research, pivotal questions regarding the nature of this transition and of the associated fluctuations remain debated. Here we combine inelastic neutron scattering, Raman spectroscopy, and ab initio calculations to study the evolution of soft polar phonons across the strain-induced ferroelectric transition in STO and KTO. We find that the modes remain underdamped and at nonzero energy, consistent with a first-order quantum phase transition. We also reveal a strong violation of the well-known Lyddane-Sachs-Teller relation between the phonon energies and static dielectric permittivities in insulating KTO and STO, which is not captured by ab initio calculations and points to the presence of slow mesoscale fluctuations induced by long-range interactions. In metallic STO, we uncover a first-order transition at a remarkably low critical stress, in qualitative agreement with recent theoretical predictions. The present work resolves several long-standing questions pertaining to the model systems STO and KTO and is relevant to numerous other materials with soft polar phonons.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [322] [Reduced Variability in Threshold Switches Using Heterostructures of SiO${_x}$ and Vertically Aligned MoS${_2}$](https://arxiv.org/abs/2511.09561)
*Jimin Lee,Rana Walied Ahmad,Sofía Cruces,Dennis Braun,Lukas Völkel,Ke Ran,Joachim Mayer,Stephan Menzel,Alwin Daus,Max C. Lemme*

Main category: physics.app-ph

TL;DR: 二维材料的垂直排列和异质结构通过范德华力提供的离子传输通道，在阻变开关器件中展现出优异的性能，但其基本开关机制仍需深入研究。


<details>
  <summary>Details</summary>
Motivation: 为了理解和利用垂直排列二维材料异质结构在阻变开关器件中的潜在优势，特别是其在阈值开关中的基本机制。

Method: 通过实验制备了氧化硅/垂直排列二硫化钼异质结构器件，并与纯氧化硅器件进行了性能对比。利用基于物理、考虑变异性的模型来揭示开关机制。

Result: 与纯氧化硅器件相比，氧化硅/垂直二硫化钼器件表现出更高的开启阈值电压和保持电压（约0.4 V），更快的开关时间（低至356 ns），以及更低的循环在流变化（3.0%）。模型表明，在氧化硅/垂直二硫化钼器件中，二硫化钼层的范德华间隙限制了银离子的迁移，形成了超薄的种子细丝，进而引导了氧化硅层中的细丝生长。

Conclusion: 氧化硅/垂直二硫化钼异质结构是一种有前景的阈值开关概念，适用于垂直器件结构，并在新兴存储器和神经形态计算领域具有应用潜力。

Abstract: Layered two-dimensional (2D) materials provide unique structural features, such as physical gaps between their layers that are only connected through van der Waals (vdW) forces. These vdW gaps can guide the migration of intercalated ions and thus regulate filament growth in resistive switching (RS) devices. Vertically aligned 2D materials and their heterostructures provide vdW gap-mediated ion transport in memristor crossbars, providing great potential for high-density integration and reliable RS performance. Nevertheless, the fundamental switching mechanisms and their contributions to the RS remain inadequately understood. In this work, we investigate silver (Ag) filament-based threshold switching (TS) in heterostructures comprising vertically aligned 2D molybdenum disulfide (VAMoS${_2}$) grown via sulfurization and silicon oxide (SiO${_x}$). Compared to SiO${_x}$-only devices, the SiO${_x}$/VAMoS${_2}$ devices exhibit TS with higher on-threshold and hold voltages, each approximately 0.4 V, faster switching times down to 356 ns under a 4 V pulse, and a lower cycle-to-cycle on-current variability of 3.0%. A physics-based, variability-aware model reveals that confined Ag ion migration within the vdW gaps in VAMoS${_2}$ forms ultrathin seed filaments, which guide filament growth in the SiO${_x}$ layer. These findings establish SiO${_x}$/VAMoS${_2}$ heterostructures as a promising concept for reliable TS in vertical device architectures for emerging memories and neuromorphic computing.

</details>


### [323] [Diamond-based sensing of stray fields from the bulk of thin-film magnets via nano-indentation](https://arxiv.org/abs/2511.10176)
*Ming-Zhong Ai,Kang-Yuan Liu,Biao Zhang,Weng-Hang Leong,Yao Gao,Yue Cui,Guoli Zhu,Licong Peng,Yanglong Hou,Quan Li,Ren-Bao Liu*

Main category: physics.app-ph

TL;DR: 通过纳米压痕诱导漏磁，并用纳米金刚石磁力计进行测量，实现了对薄膜磁体本体漏磁的无损、高分辨率测量。


<details>
  <summary>Details</summary>
Motivation: 薄膜或二维材料的本体磁化测量对于理解其本征性质至关重要，但其漏磁场很弱，限制了直接测量方法的应用。

Method: 开发了一种非破坏性方法，利用纳米压痕诱导材料本体漏磁，并使用纳米金刚石磁力计进行测量，实现了任意可设计位置、纳米尺度的空间分辨率。

Result: 成功应用于铁薄膜，测定了材料本体的本征磁化强度。

Conclusion: 该方法可以直接测量薄膜和低维材料的本征磁化特性，并为研究机械效应对纳米材料磁化的影响提供了手段。

Abstract: Measurement of the magnetization in the bulk of thin-film or two-dimensional materials is important for understanding their intrinsic properties without the complications from edges or domain walls. However, the stray fields from the bulk vanish or are very weak, which limits the application of direct measurement methods. Here, we develop a non-destructive approach to directly measuring the stray fields from the bulk of thin-film magnets at arbitrarily designatable locations, with nanoscale spatial resolution. We employ nano-indentation to induce the leakage of stray fields from the materials and use nano-diamond magnetometers to measure them. We apply the method to iron thin films and determine the intrinsic magnetization in the bulk of the materials. This work provides direct access to the intrinsic magnetic properties of thin-film and low-dimensional materials, as well as a method to study the mechanical effects on magnetization in nanomaterials.

</details>


### [324] [Bandwidth of Linear Classically Damped Systems with Application to Experimental Model Aircraft](https://arxiv.org/abs/2511.10379)
*Benjamin J. Chang,Keegan J. Moore,Lawrence A. Bergman,Alexander F. Vakakis,Walter A. Silva*

Main category: physics.app-ph

TL;DR: RMS Bandwidth的推广（ARMS Bandwidth）为多自由度系统提供了衡量能量耗散能力的单一指标，并开发了一种数据驱动的模态能量分布评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的带宽（bandwidth）概念在衡量振荡器能量耗散能力方面存在一些局限性，例如需要系统线性、单模态响应且阻尼较小。RMS Bandwidth虽然克服了部分局限，但其数学形式未能揭示其物理意义。

Method: 将RMS Bandwidth推广到多自由度、线性、时不变、经典阻尼系统，推导出ARMS Bandwidth，并用系统模态参数和初始模态能量分布表示。同时，开发了一种纯数据驱动的方法来评估模态能量分布。

Result: ARMS Bandwidth能够可靠、准确地计算出实际结构耗散能力的单一测量值。通过将ARMS Bandwidth应用于单自由度和多自由度系统以及实验飞机模型，证明了其广泛的适用性。

Conclusion: ARMS Bandwidth为多自由度系统提供了一个衡量能量耗散能力的有效指标，并且其与模态参数和初始模态能量分布的关系有助于理解其物理意义。未来将进一步研究非经典阻尼、时变参数和非线性等因素的影响。

Abstract: Bandwidth is a widely known concept and tool used in structural dynamics to measure an oscillator's capacity to dissipate energy over time, for example when used in half-power damping estimation of structural modes. Root Mean Square (RMS) Bandwidth is a generalization of bandwidth that overcomes some of the limitations encountered with conventional bandwidth, including the prerequisite of linearity, single-mode response, and light damping. However, its mathematical form does not reveal much about the physics behind it. In this paper, we extend RMS Bandwidth to multiple degree-of-freedom, linear, time-invariant, classically damped systems by deriving an Analytical Root Mean Square (ARMS) Bandwidth in terms of a system's modal parameters and initial modal energy distribution. We demonstrate that ARMS Bandwidth reliably and accurately computes a single measure for a practical structure's dissipative capacity. Also, a purely data-driven methodology for assessing the modal energy distribution is developed. We apply ARMS Bandwidth to single and multiple degree-of-freedom systems and an experimental model aircraft to demonstrate its broad applicability. Future work will address the effects of non-classical damping distribution, time-varying parameters, and nonlinearities.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [325] [ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset](https://arxiv.org/abs/2511.09602)
*Sizhe Wang,Yifan Yang,Yongkang Luo,Daheng Li,Wei Wei,Yan Zhang,Peiying Hu,Yunjin Fu,Haonan Duan,Jia Sun,Peng Wang*

Main category: cs.RO

TL;DR: ScaleADFG框架通过自动化数据集构建和轻量级抓取生成网络，解决了机器人操作工具时数据稀疏性和泛化性差的问题，提高了抓取稳定性和多样性，并实现了对真实物体的高效泛化。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法在构建大规模数据集和保证泛化性方面存在挑战，主要源于机器人与人手尺寸不匹配以及真实世界物体尺寸的多样性。

Method: 提出ScaleADFG框架，包括全自动数据集构建流程和轻量级抓取生成网络。利用基于依从性的算法合成多样化的抓取配置，实现灵活的物体-手部尺寸比，并允许大型机器人手抓取日常物体。利用预训练模型生成3D资产并检索物体依从性。训练轻量级单阶段抓取生成网络，采用简单的损失设计。

Result: 构建了一个包含五种物体类别、每类拥有超过1000个独特形状和15种尺度变化的数据集，总计包含超过60,000个抓取数据。在仿真和真实机器人上进行的实验证实，ScaleADFG框架对不同尺度的物体具有良好的适应性，提高了抓取稳定性、多样性和泛化性，并且网络能够有效地进行零样本迁移到真实物体。

Conclusion: 大规模、多尺度的物体数据集对于有效训练机器人抓取至关重要。ScaleADFG框架能够实现高效抓取，并具备良好的泛化能力。

Abstract: Dexterous functional tool-use grasping is essential for effective robotic manipulation of tools. However, existing approaches face significant challenges in efficiently constructing large-scale datasets and ensuring generalizability to everyday object scales. These issues primarily arise from size mismatches between robotic and human hands, and the diversity in real-world object scales. To address these limitations, we propose the ScaleADFG framework, which consists of a fully automated dataset construction pipeline and a lightweight grasp generation network. Our dataset introduce an affordance-based algorithm to synthesize diverse tool-use grasp configurations without expert demonstrations, allowing flexible object-hand size ratios and enabling large robotic hands (compared to human hands) to grasp everyday objects effectively. Additionally, we leverage pre-trained models to generate extensive 3D assets and facilitate efficient retrieval of object affordances. Our dataset comprising five object categories, each containing over 1,000 unique shapes with 15 scale variations. After filtering, the dataset includes over 60,000 grasps for each 2 dexterous robotic hands. On top of this dataset, we train a lightweight, single-stage grasp generation network with a notably simple loss design, eliminating the need for post-refinement. This demonstrates the critical importance of large-scale datasets and multi-scale object variant for effective training. Extensive experiments in simulation and on real robot confirm that the ScaleADFG framework exhibits strong adaptability to objects of varying scales, enhancing functional grasp stability, diversity, and generalizability. Moreover, our network exhibits effective zero-shot transfer to real-world objects. Project page is available at https://sizhe-wang.github.io/ScaleADFG_webpage

</details>


### [326] [A Shared-Autonomy Construction Robotic System for Overhead Works](https://arxiv.org/abs/2511.09695)
*David Minkwan Kim,K. M. Brian Lee,Yong Hyeok Seo,Nikola Raicevic,Runfa Blark Li,Kehan Long,Chan Seon Yoon,Dong Min Kang,Byeong Jo Lim,Young Pyoung Kim,Nikolay Atanasov,Truong Nguyen,Se Woong Jun,Young Wook Kim*

Main category: cs.RO

TL;DR: 提出了一种用于天花板钻孔等上方作业的机器人系统，结合了移动基座、升降装置、双臂躯干、定制钻孔末端执行器和RGB-D摄像头。


<details>
  <summary>Details</summary>
Motivation: 为了在能见度有限的动态环境中支持远程操作，并确保在动态障碍物周围安全操作。

Method: 使用高斯泼溅法进行在线3D重建，引入运动参数来模拟移动物体，并开发了神经配置空间障碍法进行规划和控制。

Result: 初步可行性研究表明，该硬件在钻孔、拧螺栓和锚固方面具有能力，软件在动态环境中实现了安全远程操作。

Conclusion: 所提出的机器人系统及其软件在支持上方作业的远程操作方面具有可行性，特别是在具有挑战性的动态环境中。

Abstract: We present the ongoing development of a robotic system for overhead work such as ceiling drilling. The hardware platform comprises a mobile base with a two-stage lift, on which a bimanual torso is mounted with a custom-designed drilling end effector and RGB-D cameras. To support teleoperation in dynamic environments with limited visibility, we use Gaussian splatting for online 3D reconstruction and introduce motion parameters to model moving objects. For safe operation around dynamic obstacles, we developed a neural configuration-space barrier approach for planning and control. Initial feasibility studies demonstrate the capability of the hardware in drilling, bolting, and anchoring, and the software in safe teleoperation in a dynamic environment.

</details>


### [327] [Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard](https://arxiv.org/abs/2511.09727)
*Stelios Zarifis,Ioannis Chalkiadakis,Artemis Chardouveli,Vasiliki Moutzouri,Aggelos Sotirchos,Katerina Papadimitriou,Panagiotis Filntisis,Niki Efthymiou,Petros Maragos,Katerina Pastra*

Main category: cs.RO

TL;DR: 该研究提出了一种受婴儿发育启发的强化学习框架，用于训练机器人Baby Sophia进行自主探索，学习自我触摸和手部凝视行为。


<details>
  <summary>Details</summary>
Motivation: 受到婴儿早期发育的启发，旨在研究如何通过内在奖励驱动的自主探索，使机器人能够学习复杂的感知-运动协调能力，而无需外部监督。

Method: 1. 自我触摸：将高维触觉输入转化为紧凑表示；使用内在奖励和课程学习来鼓励广泛的身体覆盖、平衡和泛化。 2. 手部凝视：通过运动婴儿学习手的视觉特征；使用内在奖励鼓励新颖的手部运动并引导视线跟随；采用从单手到双手的课程学习设置以实现视觉-运动协调。

Result: 纯粹基于好奇心的信号可以驱动协调的多模态学习，模仿婴儿从随机运动到有目的行为的进展。

Conclusion: 证明了在没有外部监督的情况下，仅通过好奇心驱动的内在奖励，机器人可以学会模仿婴儿的自我探索和协调发展过程，实现从随机运动到有目的行为的转变。

Abstract: Inspired by infant development, we propose a Reinforcement Learning (RL) framework for autonomous self-exploration in a robotic agent, Baby Sophia, using the BabyBench simulation environment. The agent learns self-touch and hand regard behaviors through intrinsic rewards that mimic an infant's curiosity-driven exploration of its own body. For self-touch, high-dimensional tactile inputs are transformed into compact, meaningful representations, enabling efficient learning. The agent then discovers new tactile contacts through intrinsic rewards and curriculum learning that encourage broad body coverage, balance, and generalization. For hand regard, visual features of the hands, such as skin-color and shape, are learned through motor babbling. Then, intrinsic rewards encourage the agent to perform novel hand motions, and follow its hands with its gaze. A curriculum learning setup from single-hand to dual-hand training allows the agent to reach complex visual-motor coordination. The results of this work demonstrate that purely curiosity-based signals, with no external supervision, can drive coordinated multimodal learning, imitating an infant's progression from random motor babbling to purposeful behaviors.

</details>


### [328] [A Robust Task-Level Control Architecture for Learned Dynamical Systems](https://arxiv.org/abs/2511.09790)
*Eshika Pathak,Ahmed Aboudonia,Sandeep Banik,Naira Hovakimyan*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 L1-DS 的新任务级鲁棒控制架构，用于解决机器人运动规划中的任务执行不匹配问题，通过结合 L1 自适应控制器和基于 DTW 的目标选择器来提高运动跟踪的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于动力学系统（DS）的学习演示（LfD）方法在生成运动轨迹时，常会遇到任务执行不匹配的问题，即未建模的动力学、持续的干扰和系统延迟会导致机器人实际任务空间状态偏离期望轨迹。本研究旨在解决这一问题。

Method: 提出了一种名为 L1-DS 的新任务级鲁棒控制架构。该架构通过增强任何 DS-based LfD 模型，结合一个标称稳定控制器和一个 L1 自适应控制器来处理任务执行不匹配。此外，引入了一个基于窗口动态时间规整（DTW）的目标选择器，以处理时间失配问题，实现相位一致性跟踪。

Result: 在 LASA 和 IROS 手写数据集上验证了所提出 L1-DS 架构的有效性。

Conclusion: L1-DS 架构能够有效地处理任务执行不匹配问题，提高 DS-based LfD 生成的运动轨迹的跟踪准确性和相位一致性。

Abstract: Dynamical system (DS)-based learning from demonstration (LfD) is a powerful tool for generating motion plans in the operation (`task') space of robotic systems. However, the realization of the generated motion plans is often compromised by a ''task-execution mismatch'', where unmodeled dynamics, persistent disturbances, and system latency cause the robot's actual task-space state to diverge from the desired motion trajectory. We propose a novel task-level robust control architecture, L1-augmented Dynamical Systems (L1-DS), that explicitly handles the task-execution mismatch in tracking a nominal motion plan generated by any DS-based LfD scheme. Our framework augments any DS-based LfD model with a nominal stabilizing controller and an L1 adaptive controller. Furthermore, we introduce a windowed Dynamic Time Warping (DTW)-based target selector, which enables the nominal stabilizing controller to handle temporal misalignment for improved phase-consistent tracking. We demonstrate the efficacy of our architecture on the LASA and IROS handwriting datasets.

</details>


### [329] [Provably Safe Stein Variational Clarity-Aware Informative Planning](https://arxiv.org/abs/2511.09836)
*Kaleb Ben Naveed,Utkrisht Sahai,Anouck Girard,Dimitra Panagou*

Main category: cs.RO

TL;DR: 该研究提出了一种新的自主机器人路径规划框架，考虑了信息随时间和空间变化的衰减，并结合了安全性约束。


<details>
  <summary>Details</summary>
Motivation: 自主机器人需要在动态环境中规划信息收集路径，但现有方法忽略了信息衰减的空间异质性和动态性，并将安全性视为软约束，这限制了机器人在现实世界中的应用。

Method: 提出了一种名为“Stein Variational Clarity-Aware Informative Planning”的框架，该框架：1. 使用“clarity”模型来量化信息获取和衰减。2. 将clarity动态嵌入路径优化中，以处理时空变化的衰减率。3. 通过低级滤波机制强制执行安全性。4. 利用Stein变分推断进行贝叶斯学习，以优化信息路径。

Result: 在具有不同衰减率和障碍物的环境中，通过硬件实验和仿真证明，该框架能够始终保持安全性，并有效减少信息缺失。

Conclusion: 所提出的框架能够有效地规划自主机器人在动态、异质环境中的信息收集路径，同时确保安全性，克服了现有方法的局限性。

Abstract: Autonomous robots are increasingly deployed for information-gathering tasks in environments that vary across space and time. Planning informative and safe trajectories in such settings is challenging because information decays when regions are not revisited. Most existing planners model information as static or uniformly decaying, ignoring environments where the decay rate varies spatially; those that model non-uniform decay often overlook how it evolves along the robot's motion, and almost all treat safety as a soft penalty. In this paper, we address these challenges. We model uncertainty in the environment using clarity, a normalized representation of differential entropy from our earlier work that captures how information improves through new measurements and decays over time when regions are not revisited. Building on this, we present Stein Variational Clarity-Aware Informative Planning, a framework that embeds clarity dynamics within trajectory optimization and enforces safety through a low-level filtering mechanism based on our earlier gatekeeper framework for safety verification. The planner performs Bayesian inference-based learning via Stein variational inference, refining a distribution over informative trajectories while filtering each nominal Stein informative trajectory to ensure safety. Hardware experiments and simulations across environments with varying decay rates and obstacles demonstrate consistent safety and reduced information deficits.

</details>


### [330] [PuffyBot: An Untethered Shape Morphing Robot for Multi-environment Locomotion](https://arxiv.org/abs/2511.09885)
*Shashwat Singh,Zilin Si,Zeynep Temel*

Main category: cs.RO

TL;DR: 该研究介绍了一种名为PuffyBot的仿生变形机器人，它能够改变自身形态以适应陆地和水下环境的运动。


<details>
  <summary>Details</summary>
Motivation: 受两栖动物形态和运动能力的启发，开发一种能够变形以适应多环境的机器人。

Method: 设计了一个由线性驱动器驱动的剪刀升降机构作为机器人主体，并集成了曲柄摇杆连杆机构来调整伺服驱动的四肢，使其能够实现爬行和游泳模式的转换。机器人主体由TPU材料制成，具备防水功能，并内置电池以实现无线操作。

Result: PuffyBot的体积可在255.00 cm3至423.75 cm3之间变化，可调节浮力以抵消3.237 N的向下的力。实验证明了机器人在陆地爬行、水下爬行、水面游泳以及在水下和水面之间进行浮力调节的多环境运动能力。机器人可无线操作两小时。

Conclusion: 研究结果表明，形状变形技术在创造适用于多样化环境的多功能、高能效机器人平台方面具有巨大潜力。

Abstract: Amphibians adapt their morphologies and motions to accommodate movement in both terrestrial and aquatic environments. Inspired by these biological features, we present PuffyBot, an untethered shape morphing robot capable of changing its body morphology to navigate multiple environments. Our robot design leverages a scissor-lift mechanism driven by a linear actuator as its primary structure to achieve shape morphing. The transformation enables a volume change from 255.00 cm3 to 423.75 cm3, modulating the buoyant force to counteract a downward force of 3.237 N due to 330 g mass of the robot. A bell-crank linkage is integrated with the scissor-lift mechanism, which adjusts the servo-actuated limbs by 90 degrees, allowing a seamless transition between crawling and swimming modes. The robot is fully waterproof, using thermoplastic polyurethane (TPU) fabric to ensure functionality in aquatic environments. The robot can operate untethered for two hours with an onboard battery of 1000 mA h. Our experimental results demonstrate multi-environment locomotion, including crawling on the land, crawling on the underwater floor, swimming on the water surface, and bimodal buoyancy adjustment to submerge underwater or resurface. These findings show the potential of shape morphing to create versatile and energy efficient robotic platforms suitable for diverse environments.

</details>


### [331] [A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation](https://arxiv.org/abs/2511.09932)
*Hanwen Wang*

Main category: cs.RO

TL;DR: 通过对视觉-动作策略进行数据增强以提高泛化能力，发现随机化场景因素（如摄像机姿态、光照条件、桌面纹理和桌子高度）可有效提高策略的泛化能力，尤其是在跨越视觉差异方面。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-动作策略泛化能力有限，主要原因是其数据增强方式生成的轨迹数据多样性不足，无法应对各种场景。

Method: 研究了现有方法训练出的策略在不同场景布局因素下的表现，通过自动化数据生成来解决数据多样性不足的问题。创建了一个包含五种机械臂、两种夹爪、以及多种随机化因素（摄像机姿态、光照条件、桌面纹理、桌子高度）和六种操作任务的数据集。

Result: 所有随机化因素都影响策略的泛化能力，任何形式的随机化都能提高泛化能力，其中多样化的轨迹在跨越视觉差异方面尤为有效。在低成本机械臂上进行了实验，验证了场景随机化对提高零样本仿真到现实迁移的视觉-动作策略泛化能力。

Conclusion: 通过对视觉-动作策略进行数据增强以提高泛化能力，发现随机化场景因素（如摄像机姿态、光照条件、桌面纹理和桌子高度）可有效提高策略的泛化能力，尤其是在跨越视觉差异方面。

Abstract: The generalization ability of visuomotor policy is crucial, as a good policy should be deployable across diverse scenarios. Some methods can collect large amounts of trajectory augmentation data to train more generalizable imitation learning policies, aimed at handling the random placement of objects on the scene's horizontal plane. However, the data generated by these methods still lack diversity, which limits the generalization ability of the trained policy. To address this, we investigate the performance of policies trained by existing methods across different scene layout factors via automate the data generation for those factors that significantly impact generalization. We have created a more extensively randomized dataset that can be efficiently and automatically generated with only a small amount of human demonstration. The dataset covers five types of manipulators and two types of grippers, incorporating extensive randomization factors such as camera pose, lighting conditions, tabletop texture, and table height across six manipulation tasks. We found that all of these factors influence the generalization ability of the policy. Applying any form of randomization enhances policy generalization, with diverse trajectories particularly effective in bridging visual gap. Notably, we investigated on low-cost manipulator the effect of the scene randomization proposed in this work on enhancing the generalization capability of visuomotor policies for zero-shot sim-to-real transfer.

</details>


### [332] [Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2511.09958)
*Xiangyi Wei,Haotian Zhang,Xinyi Cao,Siyu Xie,Weifeng Ge,Yang Li,Changbo Wang*

Main category: cs.RO

TL;DR: Audio-VLA是一个利用触觉音频感知交互和操作动态过程的多模态模型，克服了纯视觉模型的局限性，并引入了任务完成率（TCR）作为新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在机器人操作方面取得了进展，但纯视觉模型在感知交互和操作动态过程方面存在根本性限制。

Method: Audio-VLA模型集成了预训练的视觉编码器（DINOv2和SigLIP）、音频编码器（AudioCLIP）和大型语言模型（Llama2），并使用LoRA进行微调，以实现跨模态理解。该模型还通过多模态投影层对齐不同模态的特征。此外，还通过添加基于碰撞的音频生成来增强RLBench和LIBERO模拟环境，以提供真实的声音反馈。任务完成率（TCR）指标用于评估动态过程感知能力。

Result: 在LIBERO、RLBench和两个真实世界任务上的大量实验表明，Audio-VLA的性能优于纯视觉模型，而TCR指标能够有效量化动态过程感知能力。

Conclusion: Audio-VLA通过整合触觉音频信息，显著提高了机器人操作中对动态过程的感知能力，并且TCR提供了一种更全面的评估方法。

Abstract: The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

</details>


### [333] [Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008)
*Xuancun Lu,Jiaxiang Chen,Shilin Xiao,Zizhi Jin,Zhangrui Chen,Hanwen Yu,Bohan Qian,Ruochen Zhou,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.RO

TL;DR: 本研究首次系统性地研究了视觉-语言-动作（VLA）模型在物理传感器受到攻击时的安全性问题，并提出了相应的防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型虽然能够整合多模态信息，但其安全性，尤其是在面对物理世界中的传感器攻击时，仍未得到充分研究。

Method: 研究提出了一种新颖的“Real-Sim-Real”框架，该框架能够自动模拟针对摄像头和麦克风的物理传感器攻击，并能在真实机器人系统上进行验证。实验评估了不同VLA架构和任务在各种攻击参数下的脆弱性，并开发了一种基于对抗性训练的防御方法。

Result: 研究结果表明，VLA模型在面对物理传感器攻击时存在显著的脆弱性，并且这种脆弱性与任务类型和模型设计密切相关。所提出的防御方法能够提高VLA模型在面对传感器攻击所引起的分布外物理扰动时的鲁棒性，同时保持模型性能。

Conclusion: 研究揭示了VLA模型在安全部署方面存在紧迫的安全隐患，强调了建立标准化的鲁棒性基准和开发缓解策略的必要性。

Abstract: Vision-Language-Action (VLA) models revolutionize robotic systems by enabling end-to-end perception-to-action pipelines that integrate multiple sensory modalities, such as visual signals processed by cameras and auditory signals captured by microphones. This multi-modality integration allows VLA models to interpret complex, real-world environments using diverse sensor data streams. Given the fact that VLA-based systems heavily rely on the sensory input, the security of VLA models against physical-world sensor attacks remains critically underexplored.
  To address this gap, we present the first systematic study of physical sensor attacks against VLAs, quantifying the influence of sensor attacks and investigating the defenses for VLA models. We introduce a novel ``Real-Sim-Real'' framework that automatically simulates physics-based sensor attack vectors, including six attacks targeting cameras and two targeting microphones, and validates them on real robotic systems. Through large-scale evaluations across various VLA architectures and tasks under varying attack parameters, we demonstrate significant vulnerabilities, with susceptibility patterns that reveal critical dependencies on task types and model designs. We further develop an adversarial-training-based defense that enhances VLA robustness against out-of-distribution physical perturbations caused by sensor attacks while preserving model performance. Our findings expose an urgent need for standardized robustness benchmarks and mitigation strategies to secure VLA deployments in safety-critical environments.

</details>


### [334] [DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion](https://arxiv.org/abs/2511.10021)
*Egor Davydenko,Andrei Volchenkov,Vladimir Gerasimov,Roman Gorbachev*

Main category: cs.RO

TL;DR: 本文提出了一种名为DecARt（解耦驱动机器人）腿的新型电动驱动机器人腿设计，旨在实现敏捷运动。该设计采用了准伸缩运动学结构、向前倾斜的膝盖以及位于膝盖上方的电机，通过新颖的多连杆系统传递脚踝扭矩。为了在数值上分析敏捷运动能力，我们提出了一个新的描述性指标“最快可达摆动时间”（FAST），并对所提出的设计进行了定量评估，并与其他设计进行了比较。最后，我们通过广泛的仿真和初步的硬件实验评估了基于DecARt腿的机器人的性能。


<details>
  <summary>Details</summary>
Motivation: 实现敏捷运动

Method: 提出了一种名为DecARt（解耦驱动机器人）腿的新型电动驱动机器人腿设计。该设计采用了准伸缩运动学结构、向前倾斜的膝盖以及位于膝盖上方的电机，通过新颖的多连杆系统传递脚踝扭矩。为了在数值上分析敏捷运动能力，我们提出了一个新的描述性指标“最快可达摆动时间”（FAST），并对所提出的设计进行了定量评估，并与其他设计进行了比较。最后，我们通过广泛的仿真和初步的硬件实验评估了基于DecARt腿的机器人的性能。

Result: 通过广泛的仿真和初步的硬件实验评估了基于DecARt腿的机器人的性能。

Conclusion: 本文提出了一种名为DecARt（解耦驱动机器人）腿的新型电动驱动机器人腿设计，该设计在敏捷运动方面表现出潜力，并通过提出的FAST指标进行了量化评估。

Abstract: In this paper, we propose a novel design of an electrically actuated robotic leg, called the DecARt (Decoupled Actuation Robot) Leg, aimed at performing agile locomotion. This design incorporates several new features, such as the use of a quasi-telescopic kinematic structure with rotational motors for decoupled actuation, a near-anthropomorphic leg appearance with a forward facing knee, and a novel multi-bar system for ankle torque transmission from motors placed above the knee. To analyze the agile locomotion capabilities of the design numerically, we propose a new descriptive metric, called the `Fastest Achievable Swing Time` (FAST), and perform a quantitative evaluation of the proposed design and compare it with other designs. Then we evaluate the performance of the DecARt Leg-based robot via extensive simulation and preliminary hardware experiments.

</details>


### [335] [Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.10079)
*Yizheng Wang,Timon Rabczuk,Yinghua Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于KAN的物理启发的机器学习方法，用于机器人关节的静摩擦建模，该方法能够处理未知的函数结构，并具有高预测精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统静摩擦模型（如Stribeck模型）需要预定义的函数形式，在处理未知函数结构时面临挑战。

Method: 提出一种基于KAN的物理启发的机器学习方法，结合了三次样条插值激活函数和符号回归机制，通过剪枝和属性评分进行模型简化和物理表达式提取。

Result: 在合成数据和真实机器人数据上，该方法预测准确度（决定系数 R² > 0.95），并能提取出简洁且具有物理意义的摩擦表达式。

Conclusion: 所提出的方法为可解释的、数据驱动的机器人摩擦建模提供了一个新的视角，具有良好的工程应用前景。

Abstract: Friction modeling plays a crucial role in achieving high-precision motion control in robotic operating systems. Traditional static friction models (such as the Stribeck model) are widely used due to their simple forms; however, they typically require predefined functional assumptions, which poses significant challenges when dealing with unknown functional structures. To address this issue, this paper proposes a physics-inspired machine learning approach based on the Kolmogorov Arnold Network (KAN) for static friction modeling of robotic joints. The method integrates spline activation functions with a symbolic regression mechanism, enabling model simplification and physical expression extraction through pruning and attribute scoring, while maintaining both high prediction accuracy and interpretability. We first validate the method's capability to accurately identify key parameters under known functional models, and further demonstrate its robustness and generalization ability under conditions with unknown functional structures and noisy data. Experiments conducted on both synthetic data and real friction data collected from a six-degree-of-freedom industrial manipulator show that the proposed method achieves a coefficient of determination greater than 0.95 across various tasks and successfully extracts concise and physically meaningful friction expressions. This study provides a new perspective for interpretable and data-driven robotic friction modeling with promising engineering applicability.

</details>


### [336] [Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning](https://arxiv.org/abs/2511.10087)
*Haidong Huang,Haiyue Zhu. Jiayu Song,Xixin Zhao,Yaohua Zhou,Jiayi Zhang,Yuze Zhai,Xiaocong Li*

Main category: cs.RO

TL;DR: UEPO是一个统一的生成框架，用于解决离线到在线强化学习（O2O-RL）中的多模态行为覆盖不足和分布偏移问题，通过多种子动态感知扩散策略、动态散度正则化和基于扩散的数据增强，在D4RL基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决离线到在线强化学习（O2O-RL）中的多模态行为覆盖不足和分布偏移问题，以实现安全高效的机器人策略部署。

Method: 提出了一种统一的生成框架UEPO，其核心包括：1. 多种子动态感知扩散策略，用于高效捕捉多模态行为；2. 动态散度正则化机制，强制执行物理上有效的策略多样性；3. 基于扩散的数据增强模块，增强动力学模型泛化能力。

Result: 在D4RL基准测试中，UEPO在运动任务上比Uni-O4有+5.9%的绝对提升，在灵巧操作任务上比Uni-O4有+12.4%的绝对提升，证明了其强大的泛化和可扩展能力。

Conclusion: UEPO通过其创新的框架和机制，有效地解决了O2O-RL中的关键挑战，并在机器人策略部署方面取得了优越的性能。

Abstract: Offline-to-online reinforcement learning (O2O-RL) has emerged as a promising paradigm for safe and efficient robotic policy deployment but suffers from two fundamental challenges: limited coverage of multimodal behaviors and distributional shifts during online adaptation. We propose UEPO, a unified generative framework inspired by large language model pretraining and fine-tuning strategies. Our contributions are threefold: (1) a multi-seed dynamics-aware diffusion policy that efficiently captures diverse modalities without training multiple models; (2) a dynamic divergence regularization mechanism that enforces physically meaningful policy diversity; and (3) a diffusion-based data augmentation module that enhances dynamics model generalization. On the D4RL benchmark, UEPO achieves +5.9\% absolute improvement over Uni-O4 on locomotion tasks and +12.4\% on dexterous manipulation, demonstrating strong generalization and scalability.

</details>


### [337] [Learning a Thousand Tasks in a Day](https://arxiv.org/abs/2511.10110)
*Kamil Dreczkowski,Pietro Vitiello,Vitalis Vosylius,Edward Johns*

Main category: cs.RO

TL;DR: 通过将轨迹分解为对齐和交互阶段，并结合检索式泛化，MT3在机器人操作模仿学习中实现了数据效率的巨大提升，仅需少量演示即可学习大量任务。


<details>
  <summary>Details</summary>
Motivation: 当今机器人操作模仿学习方法需要大量演示，效率低下。本研究旨在提高学习效率，减少所需演示次数。

Method: 提出了一种基于分解（将轨迹分为对齐和交互阶段）和检索式泛化（从已有任务中检索信息）的模仿学习方法MT3。通过大量真实世界实验系统地研究了这种分解方法，并比较了不同设计选择的效果。

Result: 在每任务演示次数少于10次的情况下，所提出的分解方法比单阶段学习在数据效率上提高了两个数量级。检索式泛化在对齐和交互阶段均优于行为克隆。MT3仅需单个演示即可学习日常操作任务，并能泛化到新颖物体实例，在24小时内教会机器人1000个不同任务。

Conclusion: MT3通过分解和检索式泛化，显著提高了机器人操作模仿学习的数据效率，使得仅用少量演示即可学习大量任务成为可能，为机器人学习提供了新的途径。

Abstract: Humans are remarkably efficient at learning tasks from demonstrations, but today's imitation learning methods for robot manipulation often require hundreds or thousands of demonstrations per task. We investigate two fundamental priors for improving learning efficiency: decomposing manipulation trajectories into sequential alignment and interaction phases, and retrieval-based generalisation. Through 3,450 real-world rollouts, we systematically study this decomposition. We compare different design choices for the alignment and interaction phases, and examine generalisation and scaling trends relative to today's dominant paradigm of behavioural cloning with a single-phase monolithic policy. In the few-demonstrations-per-task regime (<10 demonstrations), decomposition achieves an order of magnitude improvement in data efficiency over single-phase learning, with retrieval consistently outperforming behavioural cloning for both alignment and interaction. Building on these insights, we develop Multi-Task Trajectory Transfer (MT3), an imitation learning method based on decomposition and retrieval. MT3 learns everyday manipulation tasks from as little as a single demonstration each, whilst also generalising to novel object instances. This efficiency enables us to teach a robot 1,000 distinct everyday tasks in under 24 hours of human demonstrator time. Through 2,200 additional real-world rollouts, we reveal MT3's capabilities and limitations across different task families. Videos of our experiments can be found on at https://www.robot-learning.uk/learning-1000-tasks.

</details>


### [338] [RoboBenchMart: Benchmarking Robots in Retail Environment](https://arxiv.org/abs/2511.10276)
*Konstantin Soshin,Alexander Krapukhin,Andrei Spiridonov,Denis Shepelev,Gregorii Bukhtuev,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.RO

TL;DR: RoboBenchMart是一个针对黑暗商店环境设计的机器人操作基准，具有挑战性和现实性，与现有的简化桌面场景不同。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作基准主要集中在简化的桌面场景，而忽略了像黑暗商店这样更复杂、更现实的环境，那里的机器人需要处理密集物体和多样的空间配置。RoboBenchMart旨在弥合这一差距，并解决零售领域中机器人自动化应用的巨大潜力。

Method: RoboBenchMart基准包括一个程序化的商店布局生成器、一个轨迹生成管道、评估工具和微调的基础模型，以模拟黑暗商店环境中的复杂操作任务。

Result: RoboBenchMart基准显示，即使是常见的零售任务，当前最先进的通用模型也难以解决，这表明该领域存在重大挑战。

Conclusion: RoboBenchMart为机器人操作研究提供了一个更具挑战性和现实性的平台，特别是在零售领域，并强调了改进机器人以处理复杂和混乱环境的必要性。

Abstract: Most existing robotic manipulation benchmarks focus on simplified tabletop scenarios, typically involving a stationary robotic arm interacting with various objects on a flat surface. To address this limitation, we introduce RoboBenchMart, a more challenging and realistic benchmark designed for dark store environments, where robots must perform complex manipulation tasks with diverse grocery items. This setting presents significant challenges, including dense object clutter and varied spatial configurations -- with items positioned at different heights, depths, and in close proximity. By targeting the retail domain, our benchmark addresses a setting with strong potential for near-term automation impact. We demonstrate that current state-of-the-art generalist models struggle to solve even common retail tasks. To support further research, we release the RoboBenchMart suite, which includes a procedural store layout generator, a trajectory generation pipeline, evaluation tools and fine-tuned baseline models.

</details>


### [339] [nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation](https://arxiv.org/abs/2511.10403)
*Mingxing Peng,Ruoyu Yao,Xusen Guo,Jun Ma*

Main category: cs.RO

TL;DR: nuPlan-R是一个新的闭环规划基准，使用基于学习的反应式多智能体模拟来替代基于规则的IDM，以实现更真实、更多样化和更像人类的交通行为。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶车辆闭环规划基准依赖于缺乏行为多样性的基于规则的反应式代理（如IDM），导致交通动态过于简化，无法捕捉真实的人类交互。

Method: nuPlan-R通过引入基于学习的反应式多智能体模拟来替代基于规则的IDM代理，并结合了去噪扩散模型和交互感知代理选择机制，同时扩展了评估指标。

Result: 实验表明，nuPlan-R生成的交通行为比现有方法更真实、更多样化、更像人类。此外，它还能在复杂交互场景中更清晰地反映规划器的性能，特别是突出基于学习的规划器的优势。

Conclusion: nuPlan-R为公平、反应式和真实的闭环规划评估设定了新的标准，并有望开源其代码。

Abstract: Recent advances in closed-loop planning benchmarks have significantly improved the evaluation of autonomous vehicles. However, existing benchmarks still rely on rule-based reactive agents such as the Intelligent Driver Model (IDM), which lack behavioral diversity and fail to capture realistic human interactions, leading to oversimplified traffic dynamics. To address these limitations, we present nuPlan-R, a new reactive closed-loop planning benchmark that integrates learning-based reactive multi-agent simulation into the nuPlan framework. Our benchmark replaces the rule-based IDM agents with noise-decoupled diffusion-based reactive agents and introduces an interaction-aware agent selection mechanism to ensure both realism and computational efficiency. Furthermore, we extend the benchmark with two additional metrics to enable a more comprehensive assessment of planning performance. Extensive experiments demonstrate that our reactive agent model produces more realistic, diverse, and human-like traffic behaviors, leading to a benchmark environment that better reflects real-world interactive driving. We further reimplement a collection of rule-based, learning-based, and hybrid planning approaches within our nuPlan-R benchmark, providing a clearer reflection of planner performance in complex interactive scenarios and better highlighting the advantages of learning-based planners in handling complex and dynamic scenarios. These results establish nuPlan-R as a new standard for fair, reactive, and realistic closed-loop planning evaluation. We will open-source the code for the new benchmark.

</details>


### [340] [LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction](https://arxiv.org/abs/2511.10411)
*Benjamin Stoler,Jonathan Francis,Jean Oh*

Main category: cs.RO

TL;DR: 通过构建新的长尾测试集来评估和改进自动驾驶中的轨迹预测模型，以应对罕见但关键的安全场景。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据收集难以覆盖自动驾驶中的罕见、安全关键场景，因此需要新的评估方法来衡量模型在这些场景下的鲁棒性。

Method: 提出了一种安全信息场景分解框架，将场景分解为独立的自我和社会背景。借鉴计算机视觉中的组合零样本图像标注，通过预留新的上下文组合来构建具有挑战性的闭世界和开世界测试集。为了提高泛化能力，将任务模块门控网络扩展到轨迹预测模型中，并开发了一个辅助的难度预测头来改进内部表示。

Result: 在闭世界和开世界设置中，与分布内性能相比，最先进的基线模型在未来运动预测中分别出现了5.0%和14.7%的分布外（OOD）性能差距。所提出的改进策略将这些OOD性能差距分别缩小到2.8%和11.5%，同时仍能提高分布内性能。

Conclusion: 提出的长尾评估设置和改进方法能够有效评估和提高自动驾驶轨迹预测模型在罕见安全场景下的鲁棒性和泛化能力。

Abstract: Methods for trajectory prediction in Autonomous Driving must contend with rare, safety-critical scenarios that make reliance on real-world data collection alone infeasible. To assess robustness under such conditions, we propose new long-tail evaluation settings that repartition datasets to create challenging out-of-distribution (OOD) test sets. We first introduce a safety-informed scenario factorization framework, which disentangles scenarios into discrete ego and social contexts. Building on analogies to compositional zero-shot image-labeling in Computer Vision, we then hold out novel context combinations to construct challenging closed-world and open-world settings. This process induces OOD performance gaps in future motion prediction of 5.0% and 14.7% in closed-world and open-world settings, respectively, relative to in-distribution performance for a state-of-the-art baseline. To improve generalization, we extend task-modular gating networks to operate within trajectory prediction models, and develop an auxiliary, difficulty-prediction head to refine internal representations. Our strategies jointly reduce the OOD performance gaps to 2.8% and 11.5% in the two settings, respectively, while still improving in-distribution performance.

</details>


### [341] [Improving dependability in robotized bolting operations](https://arxiv.org/abs/2511.10448)
*Lorenzo Pagliara,Violeta Redondo,Enrico Ferrentino,Manuel Ferre,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 提出一种用于机器人化螺栓连接任务的可靠控制框架，该框架具有精确的扭矩控制、主动顺应性和多模态人机交互（HRI）功能，可在故障条件下实现安全操作，并已在管道法兰连接任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人螺栓连接系统在自主性和故障管理方面缺乏可靠性，需要提高操作安全性与有效性。

Method: 开发了一个控制框架，包含精确的驱动扭矩控制、主动顺应性、多模态人机交互（HRI）界面（提供实时信息和手动/自动控制切换）以及一个高层主管（SV）来协调执行和管理控制模式的转换，遵循监督控制（SVC）范式。

Result: 在代表性的管道法兰连接螺栓操作任务中，多种故障条件下进行了系统验证。结果表明，该系统提高了故障检测能力，增强了操作员的态势感知能力，并实现了精确且顺应的螺栓连接操作。

Conclusion: 所提出的控制框架能够实现可靠的机器人化螺栓连接，但在单一摄像头传感方面存在局限性，影响了全面的态势感知。

Abstract: Bolting operations are critical in industrial assembly and in the maintenance of scientific facilities, requiring high precision and robustness to faults. Although robotic solutions have the potential to improve operational safety and effectiveness, current systems still lack reliable autonomy and fault management capabilities. To address this gap, we propose a control framework for dependable robotized bolting tasks and instantiate it on a specific robotic system. The system features a control architecture ensuring accurate driving torque control and active compliance throughout the entire operation, enabling safe interaction even under fault conditions. By designing a multimodal human-robot interface (HRI) providing real-time visualization of relevant system information and supporting seamless transitions between automatic and manual control, we improve operator situation awareness and fault detection capabilities. A high-level supervisor (SV) coordinates the execution and manages transitions between control modes, ensuring consistency with the supervisory control (SVC) paradigm, while preserving the human operator's authority. The system is validated in a representative bolting operation involving pipe flange joining, under several fault conditions. The results demonstrate improved fault detection capabilities, enhanced operator situational awareness, and accurate and compliant execution of the bolting operation. However, they also reveal the limitations of relying on a single camera to achieve full situational awareness.

</details>


### [342] [From Fold to Function: Dynamic Modeling and Simulation-Driven Design of Origami Mechanisms](https://arxiv.org/abs/2511.10580)
*Tianhui Han,Shashwat Singh,Sarvesh Patil,Zeynep Temel*

Main category: cs.RO

TL;DR: 生成一个太长不看总结


<details>
  <summary>Details</summary>
Motivation: 折纸结构在机器人和可部署系统中越来越有价值，但精确模拟其折叠行为和与环境的交互仍然具有挑战性。

Method: 提出一个使用 MuJoCo 的可变形体能力的折纸机构模拟设计框架。折纸片被表示为具有用户指定约束（如折痕和驱动）的互连可变形元素的图，这些约束通过直观的图形用户界面 (GUI) 定义。

Result: 该框架允许用户生成物理上一致的模拟，捕捉折纸机构的几何结构以及它们与外部物体和表面的交互。通过对折纸弹射器的案例研究，在模拟中使用协方差矩阵适应进化策略 (CMA-ES) 对设计参数进行了优化，并在物理原型上进行了实验验证。

Conclusion: 优化的结构实现了改进的投掷性能，说明了我们的系统能够进行快速、由模拟驱动的折纸设计、优化和分析。

Abstract: Origami-inspired mechanisms can transform flat sheets into functional three-dimensional dynamic structures that are lightweight, compact, and capable of complex motion. These properties make origami increasingly valuable in robotic and deployable systems. However, accurately simulating their folding behavior and interactions with the environment remains challenging. To address this, we present a design framework for origami mechanism simulation that utilizes MuJoCo's deformable-body capabilities. In our approach, origami sheets are represented as graphs of interconnected deformable elements with user-specified constraints such as creases and actuation, defined through an intuitive graphical user interface (GUI). This framework allows users to generate physically consistent simulations that capture both the geometric structure of origami mechanisms and their interactions with external objects and surfaces. We demonstrate our method's utility through a case study on an origami catapult, where design parameters are optimized in simulation using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and validated experimentally on physical prototypes. The optimized structure achieves improved throwing performance, illustrating how our system enables rapid, simulation-driven origami design, optimization, and analysis.

</details>


### [343] [Optimizing the flight path for a scouting Uncrewed Aerial Vehicle](https://arxiv.org/abs/2511.10598)
*Raghav Adhikari,Sachet Khatiwada,Suman Poudel*

Main category: cs.RO

TL;DR: 提出一种基于优化的方法，利用无人机在灾后非结构化环境中进行侦察，规划无人机在最优高度的路径，以最大限度地覆盖传感器并收集数据，同时最大限度地减少不确定性。


<details>
  <summary>Details</summary>
Motivation: 灾后环境非结构化，导致救援车辆路径规划困难。

Method: 提出一种基于优化的方法，为无人机规划最优高度的路径，以最大限度地覆盖传感器并收集数据，同时最大限度地减少不确定性。

Result: 使用无人机进行侦察，覆盖最广的区域，并收集数据，同时最大限度地减少不确定性。

Conclusion: 无人机可用于灾后环境侦察，以解决非结构化环境带来的导航挑战。

Abstract: Post-disaster situations pose unique navigation challenges. One of those challenges is the unstructured nature of the environment, which makes it hard to layout paths for rescue vehicles. We propose the use of Uncrewed Aerial Vehicle (UAV) in such scenario to perform reconnaissance across the environment. To accomplish this, we propose an optimization-based approach to plan a path for the UAV at optimal height where the sensors of the UAV can cover the most area and collect data with minimum uncertainty.

</details>


### [344] [Robot Crash Course: Learning Soft and Stylized Falling](https://arxiv.org/abs/2511.10635)
*Pascal Strauch,David Müller,Sammy Christen,Agon Serifi,Ruben Grandia,Espen Knoop,Moritz Bächer*

Main category: cs.RO

TL;DR: Despite advances in robust locomotion, bipedal robots still risk falling. This paper focuses on minimizing damage and allowing user control during falls, using reinforcement learning with a robot-agnostic reward function that balances end pose achievement with impact minimization. A simulation-based sampling strategy for initial and end poses enhances robustness to unseen conditions. Both simulated and real-world experiments show controlled, soft falls are possible for bipedal robots.


<details>
  <summary>Details</summary>
Motivation: Most research on bipedal robots focuses on preventing falls. However, this paper addresses the phenomenon of falling itself, aiming to reduce physical damage to the robot and provide users with control over the robot's final pose during a fall.

Method: The paper proposes a robot-agnostic reward function for reinforcement learning that balances achieving a desired end pose with minimizing impact and protecting critical robot parts. To improve robustness and handle unseen end poses, a simulation-based sampling strategy for initial and end poses is introduced.

Result: The proposed method enables bipedal robots to perform controlled, soft falls. This has been demonstrated through both simulated and real-world experiments, showing that the reward function and sampling strategy are effective.

Conclusion: This work demonstrates that bipedal robots can be trained to execute controlled, soft falls, thereby reducing physical damage and offering user control over the robot's final pose. This approach contrasts with traditional methods that solely focus on fall prevention.

Abstract: Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [345] [Incremental Generation is Necessity and Sufficient for Universality in Flow-Based Modelling](https://arxiv.org/abs/2511.09902)
*Hossein Rouhvarzi,Anastasis Kratsios*

Main category: cs.LG

TL;DR: 增量流式去噪模型在生成模型领域具有重要意义，但其理论基础仍不完善。本文证明了增量生成是基于流的通用生成模型的基础，并提供了近似理论保证。


<details>
  <summary>Details</summary>
Motivation: 在生成模型领域，增量流式去噪模型的研究现状是经验优势明显但缺乏严格的理论基础。因此，需要为这些模型提供近似理论保证。

Method: 本文利用新的拓扑-动力学论证，首先证明了单步自主演化流在表示方向保持的同胚映射方面存在局限性，并非通用。然后，通过利用自主演化流的代数性质，证明了每个方向保持的 Lipschitz 同胚映射可以由有限数量的此类流组合来近似，并给出了近似率。

Result: 研究结果表明，单步自主演化流并非通用，但通过组合有限数量的自主演化流，可以实现对方向保持的 Lipschitz 同胚映射的通用近似。近似率为 O(n^{-1/d})，并且在附加的平滑性假设下，可以实现维度无关的近似率。

Conclusion: 本文为增量流式去噪模型提供了重要的近似理论基础，证明了增量生成是通用流式生成模型的核心，并为未来的模型设计和理论分析提供了方向。

Abstract: Incremental flow-based denoising models have reshaped generative modelling, but their empirical advantage still lacks a rigorous approximation-theoretic foundation. We show that incremental generation is necessary and sufficient for universal flow-based generation on the largest natural class of self-maps of $[0,1]^d$ compatible with denoising pipelines, namely the orientation-preserving homeomorphisms of $[0,1]^d$. All our guarantees are uniform on the underlying maps and hence imply approximation both samplewise and in distribution.
  Using a new topological-dynamical argument, we first prove an impossibility theorem: the class of all single-step autonomous flows, independently of the architecture, width, depth, or Lipschitz activation of the underlying neural network, is meagre and therefore not universal in the space of orientation-preserving homeomorphisms of $[0,1]^d$. By exploiting algebraic properties of autonomous flows, we conversely show that every orientation-preserving Lipschitz homeomorphism on $[0,1]^d$ can be approximated at rate $\mathcal{O}(n^{-1/d})$ by a composition of at most $K_d$ such flows, where $K_d$ depends only on the dimension. Under additional smoothness assumptions, the approximation rate can be made dimension-free, and $K_d$ can be chosen uniformly over the class being approximated. Finally, by linearly lifting the domain into one higher dimension, we obtain structured universal approximation results for continuous functions and for probability measures on $[0,1]^d$, the latter realized as pushforwards of empirical measures with vanishing $1$-Wasserstein error.

</details>


### [346] [Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding](https://arxiv.org/abs/2511.09559)
*Tianlei Chen,Yuxiao Chen,Yang Li,Feifei Wang*

Main category: cs.LG

TL;DR: 提出了一种新的图编码器方法，通过对疾病编码进行共现关系建模，解决了自动化国际疾病分类（ICD）编码中的长尾分布和标签空间大的挑战，并在三个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自动化ICD编码面临标签空间大（10,000-20,000个编码）和长尾分布（少数编码常用，大量编码数据稀疏）的挑战。

Method: 提出一种学习方法，构建了一个有向二分图编码器，其中包含公共和稀有编码节点，边从公共指向稀有编码。通过注入基于条件概率的偏差来丰富稀有编码的表示。利用大型语言模型（LLM）为编码生成描述，以增强初始嵌入的临床信息。

Result: 在三个自动化ICD编码基准数据集上实现了最先进的性能，尤其是在长尾分类的关键指标Macro-F1上取得了显著改进。

Conclusion: 所提出的方法通过对代码共现关系进行建模，有效解决了自动化ICD编码中的长尾分布问题，提高了编码的准确性，特别是在处理稀有疾病编码方面。

Abstract: Automated International Classification of Diseases (ICD) coding aims to assign multiple disease codes to clinical documents, constituting a crucial multi-label text classification task in healthcare informatics. However, the task is challenging due to its large label space (10,000 to 20,000 codes) and long-tail distribution, where a few codes dominate while many rare codes lack sufficient training data. To address this, we propose a learning method that models fine-grained co-occurrence relationships among codes. Specifically, we construct a Directed Bipartite Graph Encoder with disjoint sets of common and rare code nodes. To facilitate a one-way information flow, edges are directed exclusively from common to rare codes. The nature of these connections is defined by a probability-based bias, which is derived from the conditional probability of a common code co-occurring given the presence of a rare code. This bias is then injected into the encoder's attention module, a process we term Co-occurrence Encoding. This structure empowers the graph encoder to enrich rare code representations by aggregating latent comorbidity information reflected in the statistical co-occurrence of their common counterparts. To ensure high-quality input to the graph, we utilize a large language model (LLM) to generate comprehensive descriptions for codes, enriching initial embeddings with clinical context and comorbidity information, serving as external knowledge for the statistical co-occurrence relationships in the code system. Experiments on three automated ICD coding benchmark datasets demonstrate that our method achieves state-of-the-art performance with particularly notable improvements in Macro-F1, which is the key metric for long-tail classification.

</details>


### [347] [Let the Experts Speak: Improving Survival Prediction & Calibration via Mixture-of-Experts Heads](https://arxiv.org/abs/2511.09567)
*Todd Morrill,Aahlad Puli,Murad Megjhani,Soojin Park,Richard Zemel*

Main category: cs.LG

TL;DR: 深度混合专家模型在生存分析中虽然能对相似患者进行聚类，但可能会牺牲校准和预测准确性。本文提出了一种新的离散时间深度混合专家模型，其中一种模型在实现聚类、校准和预测准确性的同时，改进了这些指标。


<details>
  <summary>Details</summary>
Motivation: 在生存分析中，深度混合专家模型虽然能将相似患者聚类，但往往会牺牲校准和预测准确性。本文旨在探索是否能在发现患者群体结构的同时，提高校准和预测准确性。

Method: 提出几种离散时间的深度混合专家（MoE）模型，并分析不同模型的表达能力对结果的影响。

Result: 其中一个模型在聚类、校准和预测准确性方面都表现出色。研究发现，表达能力更强的专家模型，能够为每个患者定制预测，优于依赖固定群体原型的专家模型。

Conclusion: 更具表达能力的专家模型在生存分析中能更好地进行患者聚类，并提高校准和预测准确性。

Abstract: Deep mixture-of-experts models have attracted a lot of attention for survival analysis problems, particularly for their ability to cluster similar patients together. In practice, grouping often comes at the expense of key metrics such calibration error and predictive accuracy. This is due to the restrictive inductive bias that mixture-of-experts imposes, that predictions for individual patients must look like predictions for the group they're assigned to. Might we be able to discover patient group structure, where it exists, while improving calibration and predictive accuracy? In this work, we introduce several discrete-time deep mixture-of-experts (MoE) based architectures for survival analysis problems, one of which achieves all desiderata: clustering, calibration, and predictive accuracy. We show that a key differentiator between this array of MoEs is how expressive their experts are. We find that more expressive experts that tailor predictions per patient outperform experts that rely on fixed group prototypes.

</details>


### [348] [Filtering Jump Markov Systems with Partially Known Dynamics: A Model-Based Deep Learning Approach](https://arxiv.org/abs/2511.09569)
*George Stamatelis,George C. Alexandropoulos*

Main category: cs.LG

TL;DR: JMFNet是一个创新的基于模型的深度学习框架，用于跳跃马尔可夫系统中的实时状态估计，即使在噪声统计和模式转换动力学未知的情况下也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 跳跃马尔可夫系统在实际应用中普遍存在，但其状态估计面临未知噪声统计和模式转换动力学的挑战。现有方法难以有效应对这些挑战，因此需要新的方法来提高估计的准确性和鲁棒性。

Method: 提出了一种混合架构，包含两个循环神经网络（RNN）：一个用于模式预测，另一个用于滤波，该滤波基于最近提出的KalmanNet架构的模式增强版本。这两个RNN采用交替最小二乘策略联合训练，实现了无监督的潜在模式相互适应。

Result: JMFNet在多种线性与非线性系统（包括目标跟踪、摆角跟踪、洛伦兹吸引子动力学）以及真实数据集上进行了广泛的数值实验。结果表明，JMFNet在非平稳和高噪声情况下优于经典的基于模型的滤波器（如交互多模型和粒子滤波器）以及无模型的深度学习基线。此外，JMFNet相比KalmanNet框架在复杂系统或长轨迹中表现出更显著的性能提升。

Conclusion: JMFNet框架在跳跃马尔可夫系统的状态估计方面表现出优越的性能，尤其是在复杂和高噪声条件下。该方法不仅在准确性上超越了现有方法，而且还表现出良好的一致性、可靠性，并且对初始条件、超参数选择和模型知识的错误具有较低的敏感性。

Abstract: This paper presents the Jump Markov Filtering Network (JMFNet), a novel model-based deep learning framework for real-time state-state estimation in jump Markov systems with unknown noise statistics and mode transition dynamics. A hybrid architecture comprising two Recurrent Neural Networks (RNNs) is proposed: one for mode prediction and another for filtering that is based on a mode-augmented version of the recently presented KalmanNet architecture. The proposed RNNs are trained jointly using an alternating least squares strategy that enables mutual adaptation without supervision of the latent modes. Extensive numerical experiments on linear and nonlinear systems, including target tracking, pendulum angle tracking, Lorenz attractor dynamics, and a real-life dataset demonstrate that the proposed JMFNet framework outperforms classical model-based filters (e.g., interacting multiple models and particle filters) as well as model-free deep learning baselines, particularly in non-stationary and high-noise regimes. It is also showcased that JMFNet achieves a small yet meaningful improvement over the KalmanNet framework, which becomes much more pronounced in complicated systems or long trajectories. Finally, the method's performance is empirically validated to be consistent and reliable, exhibiting low sensitivity to initial conditions, hyperparameter selection, as well as to incorrect model knowledge

</details>


### [349] [Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning](https://arxiv.org/abs/2511.09792)
*Tianmeng Hu,Yongzheng Cui,Rui Tang,Biao Luo,Ke Li*

Main category: cs.LG

TL;DR: 提出了一种基于动态系统分析的非单调值分解方法，证明了在近似贪婪探索下，非一致性解是不稳定的鞍点，而一致性解是稳定的吸引子，实验证明该方法优于单调基线，并对TD目标和探索策略进行了分析。


<details>
  <summary>Details</summary>
Motivation: 现有值分解方法在保证个体-全局最大（IGM）一致性方面存在限制，如单调性约束限制了表达能力，或采用软替代物增加了算法复杂度。

Method: 通过动态系统分析，将学习动态建模为连续时间梯度流，并证明了非单调值分解的稳定性。

Result: 在合成矩阵博弈和MARL基准测试中，非约束、非单调分解能够可靠地恢复IGM最优解，并优于单调基线。同时，研究了TD目标和探索策略的影响。

Conclusion: 非单调值分解方法在MARL中是稳定且有效的，能够恢复IGM最优解，并且提供了未来基于值的方法的设计见解。

Abstract: Value decomposition is a central approach in multi-agent reinforcement learning (MARL), enabling centralized training with decentralized execution by factorizing the global value function into local values. To ensure individual-global-max (IGM) consistency, existing methods either enforce monotonicity constraints, which limit expressive power, or adopt softer surrogates at the cost of algorithmic complexity. In this work, we present a dynamical systems analysis of non-monotonic value decomposition, modeling learning dynamics as continuous-time gradient flow. We prove that, under approximately greedy exploration, all zero-loss equilibria violating IGM consistency are unstable saddle points, while only IGM-consistent solutions are stable attractors of the learning dynamics. Extensive experiments on both synthetic matrix games and challenging MARL benchmarks demonstrate that unconstrained, non-monotonic factorization reliably recovers IGM-optimal solutions and consistently outperforms monotonic baselines. Additionally, we investigate the influence of temporal-difference targets and exploration strategies, providing actionable insights for the design of future value-based MARL algorithms.

</details>


### [350] [Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost](https://arxiv.org/abs/2511.09573)
*Valentino F. Foit,David W. Hogg,Soledad Villar*

Main category: cs.LG

TL;DR:  group averaging is a simple and effective technique to improve the accuracy of machine learning models that should be equivariant to certain symmetries, at a small cost.


<details>
  <summary>Details</summary>
Motivation: Equivariant methods are often not used in machine learning tasks in the natural sciences due to perceived training challenges, assumptions about symmetry learning, or implementation difficulties. Group averaging offers a solution by imposing exact symmetries without altering model structure or training.

Method: Group averaging is applied at test time to any trained model. It involves averaging the model's predictions over a small group of symmetries, with a cost proportional to the size of the group.

Result: Experiments on benchmark machine learning models for differential equations showed that group averaging consistently decreased the average evaluation loss, with improvements up to 37% in VRMSE. The averaging also led to visually better predictions for continuous dynamics.

Conclusion: Group averaging is a low-cost and straightforward method to enhance the accuracy of machine learning models in situations where exact symmetries are expected. The ML4PS community should consider its adoption.

Abstract: Many machine learning tasks in the natural sciences are precisely equivariant to particular symmetries. Nonetheless, equivariant methods are often not employed, perhaps because training is perceived to be challenging, or the symmetry is expected to be learned, or equivariant implementations are seen as hard to build. Group averaging is an available technique for these situations. It happens at test time; it can make any trained model precisely equivariant at a (often small) cost proportional to the size of the group; it places no requirements on model structure or training. It is known that, under mild conditions, the group-averaged model will have a provably better prediction accuracy than the original model. Here we show that an inexpensive group averaging can improve accuracy in practice. We take well-established benchmark machine learning models of differential equations in which certain symmetries ought to be obeyed. At evaluation time, we average the models over a small group of symmetries. Our experiments show that this procedure always decreases the average evaluation loss, with improvements of up to 37\% in terms of the VRMSE. The averaging produces visually better predictions for continuous dynamics. This short paper shows that, under certain common circumstances, there are no disadvantages to imposing exact symmetries; the ML4PS community should consider group averaging as a cheap and simple way to improve model accuracy.

</details>


### [351] [GraphSB: Boosting Imbalanced Node Classification on Graphs through Structural Balance](https://arxiv.org/abs/2511.10022)
*Chaofan Zhu,Xiaobing Rui,Zhixiao Wang*

Main category: cs.LG

TL;DR: 图学习中的不平衡节点分类是一个关键挑战，现有方法通常使用 GNN，但未能解决固有的不平衡图结构。我们提出 GraphSB，一种通过结构平衡（包括结构增强和关系扩散）来解决不平衡图结构的新框架，该框架可在节点合成之前进行，并能与现有方法无缝集成，显著提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的图学习方法在处理不平衡节点分类时，主要关注数据层面或算法层面的改进，但忽略了图结构本身的不平衡性，这是导致多数类支配和少数类同化的根本原因。

Method: 提出 GraphSB 框架，其核心是结构平衡策略。结构平衡包括两个阶段：1. 结构增强：自适应地构建基于相似性的边，以加强少数类节点的连通性；2. 关系扩散：捕捉高阶依赖关系，同时放大来自少数类的信号。

Result: GraphSB 在不平衡节点分类任务上显著优于现有最先进的方法。此外，结构平衡模块可以作为即插即用模块集成到现有方法中，平均准确率提升 3.67%。

Conclusion: GraphSB 通过在节点合成之前解决图结构的不平衡性，有效解决了图学习中的不平衡节点分类问题，并能作为即插即用模块提升现有方法的性能。

Abstract: Imbalanced node classification is a critical challenge in graph learning, where most existing methods typically utilize Graph Neural Networks (GNNs) to learn node representations. These methods can be broadly categorized into the data-level and the algorithm-level. The former aims to synthesize minority-class nodes to mitigate quantity imbalance, while the latter tries to optimize the learning process to highlight minority classes. However, neither category addresses the inherently imbalanced graph structure, which is a fundamental factor that incurs majority-class dominance and minority-class assimilation in GNNs. Our theoretical analysis further supports this critical insight. Therefore, we propose GraphSB (Graph Structural Balance), a novel framework that incorporates Structural Balance as a key strategy to address the underlying imbalanced graph structure before node synthesis. Structural Balance performs a two-stage structure optimization: Structure Enhancement that adaptively builds similarity-based edges to strengthen connectivity of minority-class nodes, and Relation Diffusion that captures higher-order dependencies while amplifying signals from minority classes. Thus, GraphSB balances structural distribution before node synthesis, enabling more effective learning in GNNs. Extensive experiments demonstrate that GraphSB significantly outperforms the state-of-the-art methods. More importantly, the proposed Structural Balance can be seamlessly integrated into state-of-the-art methods as a simple plug-and-play module, increasing their accuracy by an average of 3.67\%.

</details>


### [352] [HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization](https://arxiv.org/abs/2511.09578)
*Hadi Keramati,Morteza Sadeghi,Rajeev K. Jaiman*

Main category: cs.LG

TL;DR: 使用引导扩散模型生成低压降热沉设计。


<details>
  <summary>Details</summary>
Motivation: 为了在满足表面温度约束的同时最小化压降，需要一种新的热沉设计方法。

Method: 提出了一种基于引导去噪扩散概率模型的生成优化框架，该框架利用了代理梯度、边界表示、多保真度数据和残差神经网络。

Result: 生成的候选热沉设计的压降比传统方法低10%。

Conclusion: 该研究为电子冷却的生成模型奠定了基础，并证明了引导扩散模型在优化热沉设计方面的有效性。

Abstract: This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.

</details>


### [353] [Is nasty noise actually harder than malicious noise?](https://arxiv.org/abs/2511.09763)
*Guy Blanc,Yizhi Huang,Tal Malkin,Rocco A. Servedio*

Main category: cs.LG

TL;DR: 在存在恶意和恶毒噪声的学习布尔函数方面，本文研究了计算上有效的算法的相对能力和局限性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究在两种具有挑战性的对抗性噪声模型（恶意噪声和恶毒噪声）下，学习算法在存在噪声时的相对能力和局限性。

Method: 本文分析了在分布独立和固定分布设置下，学习算法在恶意噪声和恶毒噪声模型下的学习能力。对于分布独立学习，证明了两种噪声模型之间的强等价性。对于固定分布学习，证明了两种噪声模型之间可能存在任意大的分离。此外，本文还定义了一类名为“忽略矛盾示例”（ICE）的算法，并证明了对于这类算法，恶意噪声和恶毒噪声在噪声率方面最多相差一倍。

Result: 在分布独立学习中，恶意噪声和恶毒噪声是等价的。在固定分布学习中，可能存在任意大的分离。对于ICE算法，两种噪声模型在噪声率方面最多相差一倍。

Conclusion: 本文揭示了在不同学习设置下，恶意噪声和恶毒噪声对学习算法能力的影响存在显著差异。虽然在分布独立学习中两者是等价的，但在固定分布学习中可能存在巨大差距。然而，对于ICE算法，这种差距被限制在一个常数因子内。

Abstract: We consider the relative abilities and limitations of computationally efficient algorithms for learning in the presence of noise, under two well-studied and challenging adversarial noise models for learning Boolean functions: malicious noise, in which an adversary can arbitrarily corrupt a random subset of examples given to the learner; and nasty noise, in which an adversary can arbitrarily corrupt an adversarially chosen subset of examples given to the learner.
  We consider both the distribution-independent and fixed-distribution settings. Our main results highlight a dramatic difference between these two settings: For distribution-independent learning, we prove a strong equivalence between the two noise models: If a class ${\cal C}$ of functions is efficiently learnable in the presence of $η$-rate malicious noise, then it is also efficiently learnable in the presence of $η$-rate nasty noise. In sharp contrast, for the fixed-distribution setting we show an arbitrarily large separation: Under a standard cryptographic assumption, for any arbitrarily large value $r$ there exists a concept class for which there is a ratio of $r$ between the rate $η_{malicious}$ of malicious noise that polynomial-time learning algorithms can tolerate, versus the rate $η_{nasty}$ of nasty noise that such learning algorithms can tolerate.
  To offset the negative result for the fixed-distribution setting, we define a broad and natural class of algorithms, namely those that ignore contradictory examples (ICE). We show that for these algorithms, malicious noise and nasty noise are equivalent up to a factor of two in the noise rate: Any efficient ICE learner that succeeds with $η$-rate malicious noise can be converted to an efficient learner that succeeds with $η/2$-rate nasty noise. We further show that the above factor of two is necessary, again under a standard cryptographic assumption.

</details>


### [354] [Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey](https://arxiv.org/abs/2511.09586)
*Yuchen Huang,Sijia Li,Minghao Liu,Wei Liu,Shijue Huang,Zhiyuan Fan,Hou Pong Chan,Yi R. Fung*

Main category: cs.LG

TL;DR: LLM代理需要通过与环境的互动进行强化学习，而不是静态数据集。本文提出并审视了“生成-执行-反馈”（GEF）循环，以应对环境扩展的挑战，并为智能体智能的未来研究指明方向。


<details>
  <summary>Details</summary>
Motivation: 为了培养LLM代理的适应性行为和长期决策能力，需要从与环境的互动中学习，而不是依赖成本高昂、缺乏活力和真实性的静态数据集。

Method: 本文提出“生成-执行-反馈”（GEF）循环，将环境置于生成经验数据的核心地位。该调查系统地回顾了从环境中心的角度对GEF循环的三个阶段（任务生成、任务执行和反馈）进行环境扩展的方法。

Result: 对GEF循环的各个阶段进行了方法、基准、实现策略和应用的分析，整合了零散的进展。

Conclusion: 为了提升LLM代理的智能，未来的研究应专注于扩展环境的复杂性、真实性和互动性，以更好地支持GEF循环中的学习过程。

Abstract: LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this iterative process as the Generation-Execution-Feedback (GEF) loop, where environments generate tasks to challenge agents, return observations in response to agents' actions during task execution, and provide evaluative feedback on rollouts for subsequent learning. Under this paradigm, environments function as indispensable producers of experiential data, highlighting the need to scale them toward greater complexity, realism, and interactivity. In this survey, we systematically review representative methods for environment scaling from a pioneering environment-centric perspective and organize them along the stages of the GEF loop, namely task generation, task execution, and feedback. We further analyze benchmarks, implementation strategies, and applications, consolidating fragmented advances and outlining future research directions for agent intelligence.

</details>


### [355] [Towards Emotionally Intelligent and Responsible Reinforcement Learning](https://arxiv.org/abs/2511.10573)
*Garapati Keerthana,Manik Gupta*

Main category: cs.LG

TL;DR: 该研究提出了一个负责任的强化学习（RRL）框架，用于在医疗和行为支持领域构建能够理解用户情绪并考虑伦理约束的个性化决策系统。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化决策系统（如医疗和行为支持）通常依赖于静态规则或最大化参与度的启发式方法，这些方法忽略了用户的情绪背景和伦理约束，可能导致不敏感或不安全的干预措施，尤其是在涉及严重精神疾病、物质使用障碍或抑郁症等领域。

Method: 提出一个负责任的强化学习（RRL）框架，将个性化问题形式化为约束马尔可夫决策过程（CMDP）。该框架通过多目标奖励函数平衡短期参与度和长期用户福祉，并使用情感感知状态表示来捕捉情绪波动和风险。该框架可与任何强化学习算法结合，并加入安全约束或拉格朗日正则化。

Result: 该框架能够将共情和责任纳入机器学习策略优化，实现安全强化学习、情感计算和负责任人工智能的结合。

Conclusion: 该研究提出的RRL框架为构建情感感知、值得信赖且符合伦理的个性化系统提供了一种新的方法，并在行为健康、教育和数字疗法等领域具有潜在应用价值，未来需要通过仿真验证和经验研究来进一步验证。

Abstract: Personalized decision systems in healthcare and behavioral support often rely on static rule-based or engagement-maximizing heuristics that overlook users' emotional context and ethical constraints. Such approaches risk recommending insensitive or unsafe interventions, especially in domains involving serious mental illness, substance use disorders, or depression. To address this limitation, we propose a Responsible Reinforcement Learning (RRL) framework that integrates emotional and contextual understanding with ethical considerations into the sequential decision-making process. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), where the agent optimizes engagement and adherence while ensuring emotional alignment and ethical safety. We introduce a multi-objective reward function that explicitly balances short-term behavioral engagement with long-term user well-being, and define an emotion-informed state representation that captures fluctuations in emotional readiness, affect, and risk. The proposed architecture can be instantiated with any RL algorithm (e.g., DQN, PPO) augmented with safety constraints or Lagrangian regularization. Conceptually, this framework operationalizes empathy and responsibility within machine learning policy optimization, bridging safe RL, affective computing and responsible AI. We discuss the implications of this approach for human-centric domains such as behavioral health, education, and digital therapeutics, and outline simulation-based validation paths for future empirical work. This paper aims to initiate a methodological conversation about ethically aligned reinforcement learning for emotionally aware and trustworthy personalization systems.

</details>


### [356] [Learning Intersections of Halfspaces under Factorizable Distribution](https://arxiv.org/abs/2511.09832)
*Ilias Diakonikolas,Mingchen Ma,Lisheng Ren,Christos Tzamos*

Main category: cs.LG

TL;DR: 学习两个半空间交集的问题在计算学习理论中是一个核心问题。即使是两个半空间，对于边距 $γ$ 和维度 $d$ 的多项式时间学习仍然是一个悬而未决的问题。目前已知最优算法的运行时间为拟多项式时间 $d^{O(	extrm{log}(1/γ))}$，并且已证明仅依赖相关统计查询（CSQ）的算法存在此复杂度瓶颈。本研究提出了一种新算法，可以绕过 CSQ 困难障碍。


<details>
  <summary>Details</summary>
Motivation: 解决计算学习理论中学习两个半空间交集的核心问题，并突破现有算法在边距 $γ$ 和维度 $d$ 下的拟多项式时间限制，以及 CSQ 算法的硬度瓶颈。

Method: 提出一种新算法，该算法利用更一般的统计查询（SQ），并结合改进的 Jennrich 算法、基于 PCA 的矩张量随机投影以及基于梯度下降的非凸优化框架，在满足因子化假设的分布上实现 $poly(d,1/γ)$ 时间复杂度。

Result: 在满足因子化假设的分布上，提出了一个能在 $poly(d,1/γ)$ 时间内学习两个半空间交集的算法，证明了 CSQ 和 SQ 在此可实现 PAC 学习问题上的强分离性，并证明了 CSQ 方法在此类分布上即使是弱学习也需要拟多项式时间。

Conclusion: 研究为学习半空间交集问题提供了一个新的、更高效的算法，显著优于基于 CSQ 的方法，并利用了因子化分布的特性，在理论和实践上都具有重要意义。

Abstract: Learning intersections of halfspaces is a central problem in Computational Learning Theory. Even for just two halfspaces, it remains a major open question whether learning is possible in polynomial time with respect to the margin $γ$ of the data points and their dimensionality $d$. The best-known algorithms run in quasi-polynomial time $d^{O(\log(1/γ))}$, and it has been shown that this complexity is unavoidable for any algorithm relying solely on correlational statistical queries (CSQ).
  In this work, we introduce a novel algorithm that provably circumvents the CSQ hardness barrier. Our approach applies to a broad class of distributions satisfying a natural, previously studied, factorizability assumption. Factorizable distributions lie between distribution-specific and distribution-free settings, and significantly extend previously known tractable cases. Under these distributions, we show that CSQ-based methods still require quasipolynomial time even for weakly learning, whereas our algorithm achieves $poly(d,1/γ)$ time by leveraging more general statistical queries (SQ), establishing a strong separation between CSQ and SQ for this simple realizable PAC learning problem.
  Our result is grounded in a rigorous analysis utilizing a novel duality framework that characterizes the moment tensor structure induced by the marginal distributions. Building on these structural insights, we propose new, efficient learning algorithms. These algorithms combine a refined variant of Jennrich's Algorithm with PCA over random projections of the moment tensor, along with a gradient-descent-based non-convex optimization framework.

</details>


### [357] [DynamicRTL: RTL Representation Learning for Dynamic Circuit Behavior](https://arxiv.org/abs/2511.09593)
*Ruiyang Ma,Yunhao Zhou,Yipeng Wang,Yi Liu,Zhengyuan Shi,Ziyang Zheng,Kexin Chen,Zhiqiang He,Lingwei Yan,Gang Chen,Qiang Xu,Guojie Luo*

Main category: cs.LG

TL;DR: DR-GNN 是一种新颖的方法，通过结合静态结构和多周期执行行为来学习 RTL 电路的表示，以捕捉动态依赖和运行时执行，并在分支命中率预测、开关速率预测、功率估计和断言预测等任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络（GNNs）模型主要关注电路的静态特性，无法捕捉对电路验证和优化至关重要的运行时行为。

Method: DR-GNN 利用了运算符级控制数据流图（CDFG）来表示 RTL 电路，从而能够捕捉动态依赖和运行时执行。此外，研究人员还构建了一个包含 6,300 多个 Verilog 设计和 63,000 个模拟轨迹的动态电路数据集，用于训练和评估 DR-GNN。

Result: DR-GNN 在分支命中预测和开关速率预测方面优于现有模型。其学习到的表示可以有效地迁移到相关的动态电路任务，在功率估计和断言预测方面取得了良好的性能。

Conclusion: DR-GNN 成功地整合了电路的静态结构和动态行为，为处理 RTL 电路表示和相关下游任务提供了一种有效的方法。

Abstract: There is a growing body of work on using Graph Neural Networks (GNNs) to learn representations of circuits, focusing primarily on their static characteristics. However, these models fail to capture circuit runtime behavior, which is crucial for tasks like circuit verification and optimization. To address this limitation, we introduce DR-GNN (DynamicRTL-GNN), a novel approach that learns RTL circuit representations by incorporating both static structures and multi-cycle execution behaviors. DR-GNN leverages an operator-level Control Data Flow Graph (CDFG) to represent Register Transfer Level (RTL) circuits, enabling the model to capture dynamic dependencies and runtime execution. To train and evaluate DR-GNN, we build the first comprehensive dynamic circuit dataset, comprising over 6,300 Verilog designs and 63,000 simulation traces. Our results demonstrate that DR-GNN outperforms existing models in branch hit prediction and toggle rate prediction. Furthermore, its learned representations transfer effectively to related dynamic circuit tasks, achieving strong performance in power estimation and assertion prediction.

</details>


### [358] [Making Every Head Count: Sparse Attention Without the Speed-Performance Trade-off](https://arxiv.org/abs/2511.09596)
*Mingkuan Zhao,Wentao Hu,Jiayin Wang,Xin Lai,Tianchen Huang,Yuheng Min,Rui Yan,Xiaoyan Zhu*

Main category: cs.LG

TL;DR: LLMs的注意力机制因计算复杂度高而受限，SPAttention通过结构化稀疏性将多头注意力分解为H个独立的O(N^2)计算，转化为一个协作的O(N^2)计算，将复杂度降低了H倍，在保持性能的同时提高了训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: LLMs的注意力机制在计算效率和性能之间存在冲突，现有稀疏方法牺牲了信息完整性。

Method: 提出SPAttention，引入“Principled Structural Sparsity”新范式，将注意力任务分区到不同的head，实现协作计算。

Result: SPAttention在OLMoE模型系列上实现了约两倍的训练吞吐量提升，性能与标准稠密注意力相当甚至在某些指标上更优，并且优于Longformer、Reformer和BigBird等稀疏注意力方法。

Conclusion: SPAttention通过结构化稀疏性有效解决了LLMs注意力机制的效率-性能权衡问题，提高了训练效率和模型性能。

Abstract: The design of Large Language Models (LLMs) has long been hampered by a fundamental conflict within their core attention mechanism: its remarkable expressivity is built upon a computational complexity of $O(H \cdot N^2)$ that grows quadratically with the context size ($N$) and linearly with the number of heads ($H$). This standard implementation harbors significant computational redundancy, as all heads independently compute attention over the same sequence space. Existing sparse methods, meanwhile, often trade information integrity for computational efficiency. To resolve this efficiency-performance trade-off, we propose SPAttention, whose core contribution is the introduction of a new paradigm we term Principled Structural Sparsity. SPAttention does not merely drop connections but instead reorganizes the computational task by partitioning the total attention workload into balanced, non-overlapping distance bands, assigning each head a unique segment. This approach transforms the multi-head attention mechanism from $H$ independent $O(N^2)$ computations into a single, collaborative $O(N^2)$ computation, fundamentally reducing complexity by a factor of $H$. The structured inductive bias compels functional specialization among heads, enabling a more efficient allocation of computational resources from redundant modeling to distinct dependencies across the entire sequence span. Extensive empirical validation on the OLMoE-1B-7B and 0.25B-1.75B model series demonstrates that while delivering an approximately two-fold increase in training throughput, its performance is on par with standard dense attention, even surpassing it on select key metrics, while consistently outperforming representative sparse attention methods including Longformer, Reformer, and BigBird across all evaluation metrics.

</details>


### [359] [Parametric Expensive Multi-Objective Optimization via Generative Solution Modeling](https://arxiv.org/abs/2511.09598)
*Tingyang Wei,Jiao Liu,Abhishek Gupta,Chin Chun Ooi,Puay Siew Tan,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的参数化多目标贝叶斯优化方法，能够直接预测在不同任务参数下的优化解决方案，而无需昂贵的重新评估。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用需要解决一系列昂贵的参数化多目标优化问题（P-EMOPs），但现有方法难以应对连续的任务参数空间，需要为每个实例单独评估。

Method: 该方法通过交替进行（1）利用任务间协同效应的采集驱动搜索和（2）通过条件生成模型进行生成式解采样来学习逆模型，并利用任务感知高斯过程进行理论分析。

Result: 实验表明，该方法能够高效地跨相关任务进行优化，并直接预测未见过参数化EMOPs的解决方案，验证了其有效性。

Conclusion: 所提出的参数化多目标贝叶斯优化框架能够通过学习逆模型，在避免昂贵重新评估的情况下，实现对不同任务参数下优化问题的直接解决方案预测。

Abstract: Many real-world applications require solving families of expensive multi-objective optimization problems~(EMOPs) under varying operational conditions. This gives rise to parametric expensive multi-objective optimization problems (P-EMOPs) where each task parameter defines a distinct optimization instance. Current multi-objective Bayesian optimization methods have been widely used for finding finite sets of Pareto optimal solutions for individual tasks. However, P-EMOPs present a fundamental challenge: the continuous task parameter space can contain infinite distinct problems, each requiring separate expensive evaluations. This demands learning an inverse model that can directly predict optimized solutions for any task-preference query without expensive re-evaluation. This paper introduces the first parametric multi-objective Bayesian optimizer that learns this inverse model by alternating between (1) acquisition-driven search leveraging inter-task synergies and (2) generative solution sampling via conditional generative models. This approach enables efficient optimization across related tasks and finally achieves direct solution prediction for unseen parameterized EMOPs without additional expensive evaluations. We theoretically justify the faster convergence by leveraging inter-task synergies through task-aware Gaussian processes. Meanwhile, empirical studies in synthetic and real-world benchmarks further verify the effectiveness of our alternating framework.

</details>


### [360] [NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG](https://arxiv.org/abs/2511.09773)
*Mahdi Samaee,Mehran Yazdi,Daniel Massicotte*

Main category: cs.LG

TL;DR: NeuroLingua是一个受语言启发的框架，将睡眠视为一种生理语言，使用分层Transformer模型进行睡眠分期，并在Sleep-EDF和ISRUC-Sleep数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 自动睡眠分期在处理多模态数据和提高可解释性方面存在挑战，需要更具表现力的时序模型。

Method: NeuroLingua将30秒的睡眠片段分解为3秒的子窗口（“标记”），使用CNN作为分词器，并通过双层Transformer进行分层时序建模。它还利用图卷积网络融合EEG和EOG模态信息。

Result: 在Sleep-EDF数据集上，NeuroLingua达到了85.3%的准确率、0.800的宏F1分数和0.796的Cohen's kappa。在ISRUC-Sleep数据集上，准确率为81.9%，宏F1为0.802，kappa为0.755，与现有基线相当或更优。

Conclusion: NeuroLingua通过将睡眠视为一种组合语言，统一了分层序列建模和多模态融合，提高了睡眠分期的准确性和可解释性，为未来的临床应用奠定了基础。

Abstract: Automated sleep stage classification from polysomnography remains limited by the lack of expressive temporal hierarchies, challenges in multimodal EEG and EOG fusion, and the limited interpretability of deep learning models. We propose NeuroLingua, a language-inspired framework that conceptualizes sleep as a structured physiological language. Each 30-second epoch is decomposed into overlapping 3-second subwindows ("tokens") using a CNN-based tokenizer, enabling hierarchical temporal modeling through dual-level Transformers: intra-segment encoding of local dependencies and inter-segment integration across seven consecutive epochs (3.5 minutes) for extended context. Modality-specific embeddings from EEG and EOG channels are fused via a Graph Convolutional Network, facilitating robust multimodal integration. NeuroLingua is evaluated on the Sleep-EDF Expanded and ISRUC-Sleep datasets, achieving state-of-the-art results on Sleep-EDF (85.3% accuracy, 0.800 macro F1, and 0.796 Cohen's kappa) and competitive performance on ISRUC (81.9% accuracy, 0.802 macro F1, and 0.755 kappa), matching or exceeding published baselines in overall and per-class metrics. The architecture's attention mechanisms enhance the detection of clinically relevant sleep microevents, providing a principled foundation for future interpretability, explainability, and causal inference in sleep research. By framing sleep as a compositional language, NeuroLingua unifies hierarchical sequence modeling and multimodal fusion, advancing automated sleep staging toward more transparent and clinically meaningful applications.

</details>


### [361] [Optimistic Reinforcement Learning with Quantile Objectives](https://arxiv.org/abs/2511.09652)
*Mohammad Alipour-Vaezi,Huaiyang Zhong,Kwok-Leung Tsui,Sajad Khodadadian*

Main category: cs.LG

TL;DR: 该研究提出了一种名为UCB-QRL的强化学习算法，用于解决有限时间范围马尔可夫决策过程中对风险敏感性的优化问题，该算法通过估计转移概率并优化置信球内的分位数价值函数，在特定条件下实现了可观的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 由于经典的强化学习方法未能考虑目标函数中的风险敏感性，而风险敏感性在医疗和金融等领域至关重要，因此需要开发能够优化累积奖励分布特定分位数的方法。

Method: UCB-QRL算法是一种迭代算法，在每次迭代中，首先估计潜在的转移概率，然后在该估计值周围的置信球内优化分位数价值函数。

Result: UCB-QRL算法在具有S个状态、A个动作、T个回合和H个时间尺度的情景设置中，实现了高概率遗憾界限 $\mathcal O\left((2/κ)^{H+1}H\sqrt{SATH\log(2SATH/δ)}\right)$。

Conclusion: UCB-QRL算法成功地将风险敏感性纳入强化学习的优化目标中，并通过理论分析证明了其在有限时间范围马尔可夫决策过程中的有效性。

Abstract: Reinforcement Learning (RL) has achieved tremendous success in recent years. However, the classical foundations of RL do not account for the risk sensitivity of the objective function, which is critical in various fields, including healthcare and finance. A popular approach to incorporate risk sensitivity is to optimize a specific quantile of the cumulative reward distribution. In this paper, we develop UCB-QRL, an optimistic learning algorithm for the $τ$-quantile objective in finite-horizon Markov decision processes (MDPs). UCB-QRL is an iterative algorithm in which, at each iteration, we first estimate the underlying transition probability and then optimize the quantile value function over a confidence ball around this estimate. We show that UCB-QRL yields a high-probability regret bound $\mathcal O\left((2/κ)^{H+1}H\sqrt{SATH\log(2SATH/δ)}\right)$ in the episodic setting with $S$ states, $A$ actions, $T$ episodes, and $H$ horizons. Here, $κ>0$ is a problem-dependent constant that captures the sensitivity of the underlying MDP's quantile value.

</details>


### [362] [TawPipe: Topology-Aware Weight Pipeline Parallelism for Accelerating Long-Context Large Models Training](https://arxiv.org/abs/2511.09741)
*Houming Wu,Ling Chen*

Main category: cs.LG

TL;DR: TawPipe是一种拓扑感知权重流水线并行方法，通过优化通信来提高LLM长上下文训练的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的流水线并行方法在长上下文训练中存在激活通信开销大的问题，而权重传递方法则存在冗余的P2P传输和节点内带宽利用不足的问题。

Method: TawPipe利用分布式集群中的分层带宽，通过以下方式优化通信：(i) 基于拓扑对设备进行分组，以优化节点内通信和节点间P2P通信；(ii) 为每个设备分配固定的模型权重和梯度分片，避免冗余传输；(iii) 将通信与计算重叠以隐藏延迟。

Result: 在最多24个GPU上使用LLaMA风格模型进行的大量实验表明，TawPipe比最先进的方法实现了更高的吞吐量和可扩展性。

Conclusion: TawPipe通过利用分层带宽和优化通信策略，有效地解决了LLM长上下文训练中的内存和通信瓶颈，显著提高了训练效率和可扩展性。

Abstract: Training large language models (LLMs) is fundamentally constrained by limited device memory and costly inter-device communication. Although pipeline parallelism alleviates memory pressure by partitioning models across devices, it incurs activation communication overhead that scales linearly with sequence length, limiting efficiency in long-context training. Recent weight-passing approaches (e.g., WeiPipe) mitigate this by transmitting model weights instead of activations, but suffer from redundant peer-to-peer (P2P) transfers and underutilized intra-node bandwidth. We propose TawPipe--topology-aware weight pipeline parallelism, which exploits hierarchical bandwidth in distributed clusters for improved communication efficiency. TawPipe: (i) groups devices based on topology to optimize intra-node collective and inter-node P2P communication; (ii) assigns each device a fixed shard of model weights and gradients, avoiding redundant transfers; and (iii) overlaps communication with computation to hide latency. Unlike global collective operations used in fully sharded data parallelism (FSDP), TawPipe confines most communication within node boundaries, significantly reducing cross-node traffic. Extensive experiments on up to 24 GPUs with LLaMA-style models show that TawPipe achieves superior throughput and scalability compared to state-of-the-art baselines.

</details>


### [363] [Generalization Can Emerge in Tabular Foundation Models From a Single Table](https://arxiv.org/abs/2511.09665)
*Junwei Ma,Nour Shaheen,Alex Labach,Amine Mhedhbi,Frank Hutter,Anthony L. Caterini,Valentin Thomas*

Main category: cs.LG

TL;DR: In-context learning for deep tabular modeling can achieve strong generalization with surprisingly little data, challenging the need for extensive pre-training. Simple self-supervised pre-training on a single real table can yield good transfer learning across diverse datasets. The number and quality of pre-training tasks derived from a dataset are crucial for downstream performance.


<details>
  <summary>Details</summary>
Motivation: The prevailing view is that deep tabular modeling requires extensive pre-training on large synthetic or real datasets for effective in-context learning. This paper challenges this assumption.

Method: The study systematically pre-trained and evaluated models on diverse datasets, analyzing the importance of data aspects for generalization. They focused on self-supervised pre-training using a single real table and analyzed the impact of the number and quality of pre-training tasks.

Result: A relatively small amount of data, specifically self-supervised pre-training on a single real table, is sufficient for strong generalization in in-context learning for tabular data. The number and quality of tasks derived from the pre-training dataset significantly impact downstream performance.

Conclusion: Generalization in deep tabular modeling through in-context learning does not necessitate massive pre-training datasets. Effective pre-training can be achieved with smaller, well-curated datasets, and the design of pre-training tasks plays a critical role in building a robust Tabular Foundation Model.

Abstract: Deep tabular modelling increasingly relies on in-context learning where, during inference, a model receives a set of $(x,y)$ pairs as context and predicts labels for new inputs without weight updates. We challenge the prevailing view that broad generalization here requires pre-training on large synthetic corpora (e.g., TabPFN priors) or a large collection of real data (e.g., TabDPT training datasets), discovering that a relatively small amount of data suffices for generalization. We find that simple self-supervised pre-training on just a \emph{single} real table can produce surprisingly strong transfer across heterogeneous benchmarks. By systematically pre-training and evaluating on many diverse datasets, we analyze what aspects of the data are most important for building a Tabular Foundation Model (TFM) generalizing across domains. We then connect this to the pre-training procedure shared by most TFMs and show that the number and quality of \emph{tasks} one can construct from a dataset is key to downstream performance.

</details>


### [364] [SMoFi: Step-wise Momentum Fusion for Split Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2511.09828)
*Mingkun Yang,Ran Zhu,Qing Wang,Jie Yang*

Main category: cs.LG

TL;DR: Step-wise Momentum Fusion (SMoFi) 是一种通过同步服务器端优化器的动量缓冲区来解决联邦学习中数据异质性导致的梯度发散问题的框架，从而提高模型准确性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 数据异质性是导致联邦学习全局模型收敛速度慢和准确性差的主要挑战。

Method: SMoFi 通过同步服务器端优化器的动量缓冲区来解决数据异质性导致的梯度发散问题，并设计了一种可感知延迟的对齐机制来约束服务器端子模型的梯度更新。

Result: SMoFi 在多个真实世界数据集上进行了广泛验证，结果显示其一致性地提高了全局模型准确性（最高可达 7.1%）和收敛速度（最高可达 10.25 倍）。

Conclusion: SMoFi 是一种有效且轻量级的框架，能够提高联邦学习的准确性和收敛速度，尤其适用于资源受限的环境。

Abstract: Split Federated Learning is a system-efficient federated learning paradigm that leverages the rich computing resources at a central server to train model partitions. Data heterogeneity across silos, however, presents a major challenge undermining the convergence speed and accuracy of the global model. This paper introduces Step-wise Momentum Fusion (SMoFi), an effective and lightweight framework that counteracts gradient divergence arising from data heterogeneity by synchronizing the momentum buffers across server-side optimizers. To control gradient divergence over the training process, we design a staleness-aware alignment mechanism that imposes constraints on gradient updates of the server-side submodel at each optimization step. Extensive validations on multiple real-world datasets show that SMoFi consistently improves global model accuracy (up to 7.1%) and convergence speed (up to 10.25$\times$). Furthermore, SMoFi has a greater impact with more clients involved and deeper learning models, making it particularly suitable for model training in resource-constrained contexts.

</details>


### [365] [GEM+: Scalable State-of-the-Art Private Synthetic Data with Generator Networks](https://arxiv.org/abs/2511.09672)
*Samuel Maddock,Shripad Gade,Graham Cormode,Will Bullock*

Main category: cs.LG

TL;DR: GEM+ 结合了 AIM 的自适应测量框架和 GEM 的可扩展生成器网络，在处理高维数据集方面优于 AIM，实现了最先进的隐私合成数据生成。


<details>
  <summary>Details</summary>
Motivation: 现有的差异化私有合成表格数据方法（如 AIM）虽然有效，但在处理高维数据时效率低下，计算开销大。需要更具可扩展性的方法。

Method: 提出 GEM+，它整合了 AIM 的自适应测量方法和 GEM 的生成器神经网络，以提高在高维数据上的效率和可扩展性。

Result: GEM+ 在保持最高水平的数据效用的同时，在扩展性和效率方面超越了 AIM，能够处理超过一百个特征的数据集，而 AIM 在此规模下会因内存和计算瓶颈而失败。

Conclusion: GEM+ 是处理高维数据的最先进的差异化私有合成表格数据生成方法，它结合了现有方法的优点，显著提高了可扩展性和效率。

Abstract: State-of-the-art differentially private synthetic tabular data has been defined by adaptive 'select-measure-generate' frameworks, exemplified by methods like AIM. These approaches iteratively measure low-order noisy marginals and fit graphical models to produce synthetic data, enabling systematic optimisation of data quality under privacy constraints. Graphical models, however, are inefficient for high-dimensional data because they require substantial memory and must be retrained from scratch whenever the graph structure changes, leading to significant computational overhead. Recent methods, like GEM, overcome these limitations by using generator neural networks for improved scalability. However, empirical comparisons have mostly focused on small datasets, limiting real-world applicability. In this work, we introduce GEM+, which integrates AIM's adaptive measurement framework with GEM's scalable generator network. Our experiments show that GEM+ outperforms AIM in both utility and scalability, delivering state-of-the-art results while efficiently handling datasets with over a hundred columns, where AIM fails due to memory and computational overheads.

</details>


### [366] [Boosted GFlowNets: Improving Exploration via Sequential Learning](https://arxiv.org/abs/2511.09677)
*Pedro Dall'Antonia,Tiago da Silva,Daniel Augusto de Souza,César Lincoln C. Mattos,Diego Mesquita*

Main category: cs.LG

TL;DR: GFlowNets在采样组合对象方面表现出色，但存在探索不均的问题，导致难以到达的模式学习不足。Boosted GFlowNets通过顺序训练GFlowNets的集成来解决这个问题，每个模型都优化补偿先前模型已捕获质量的剩余奖励。这种方法能重新激活未充分探索区域的学习信号，并确保学习分布的单调不退化。实验表明，Boosted GFlowNets在多模式合成基准和肽设计任务中，显著提高了探索能力和样本多样性，同时保持了标准训练的稳定性和简洁性。


<details>
  <summary>Details</summary>
Motivation: GFlowNets在实践中难以均匀探索奖励空间，容易陷入易于到达的区域，导致难以到达的模式学习不足，从而在奖励区域覆盖方面表现不佳。

Method: Boosted GFlowNets通过顺序训练GFlowNets的集成来解决样本覆盖不均的问题。每个模型都优化一个剩余奖励，该奖励补偿了先前模型已捕获的质量。这种方法通过重新激活未充分探索区域的学习信号来改善学习。

Result: Boosted GFlowNets在多模式合成基准和肽设计任务中，实现了显著更好的探索和样本多样性，同时保持了标准训练的稳定性和简洁性。

Conclusion: Boosted GFlowNets通过顺序训练GFlowNets集成来改善样本覆盖，并在各种任务中显示出优越的性能。

Abstract: Generative Flow Networks (GFlowNets) are powerful samplers for compositional objects that, by design, sample proportionally to a given non-negative reward. Nonetheless, in practice, they often struggle to explore the reward landscape evenly: trajectories toward easy-to-reach regions dominate training, while hard-to-reach modes receive vanishing or uninformative gradients, leading to poor coverage of high-reward areas. We address this imbalance with Boosted GFlowNets, a method that sequentially trains an ensemble of GFlowNets, each optimizing a residual reward that compensates for the mass already captured by previous models. This residual principle reactivates learning signals in underexplored regions and, under mild assumptions, ensures a monotone non-degradation property: adding boosters cannot worsen the learned distribution and typically improves it. Empirically, Boosted GFlowNets achieve substantially better exploration and sample diversity on multimodal synthetic benchmarks and peptide design tasks, while preserving the stability and simplicity of standard trajectory-balance training.

</details>


### [367] [Unlocking Dynamic Inter-Client Spatial Dependencies: A Federated Spatio-Temporal Graph Learning Method for Traffic Flow Forecasting](https://arxiv.org/abs/2511.10434)
*Feng Wang,Tianxiang Chen,Shuyue Wei,Qian Chu,Yi Zhang,Yifan Sun,Zhiming Zheng*

Main category: cs.LG

TL;DR: FedSTGD通过聚合来自多个来源的动态空间时间图数据，以更准确地预测交通流量，同时遵守数据本地化规则。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的交通数据分布在多个利益相关者手中，这使得在遵守数据本地化规则的同时对客户进行空间依赖性建模和重建变得困难。现有的方法主要关注静态依赖关系，忽略了动态依赖关系，导致性能不佳。

Method: FedSTGD采用联邦非线性计算分解模块来近似复杂的图操作，并结合图节点嵌入增强模块来减轻性能下降。这些模块通过客户端-服务器集体学习协议进行协调，将动态的客户间空间依赖性学习任务分解为轻量级、可并行处理的子任务。

Result: 在四个真实世界数据集上的大量实验表明，FedSTGD在RMSE、MAE和MAPE方面优于最先进的基线，并且接近集中式基线。

Conclusion: FedSTGD是一种新颖的联邦学习框架，可以有效地对动态的客户间空间依赖性进行建模和重建，并且具有优于现有方法的性能。

Abstract: Spatio-temporal graphs are powerful tools for modeling complex dependencies in traffic time series. However, the distributed nature of real-world traffic data across multiple stakeholders poses significant challenges in modeling and reconstructing inter-client spatial dependencies while adhering to data locality constraints. Existing methods primarily address static dependencies, overlooking their dynamic nature and resulting in suboptimal performance. In response, we propose Federated Spatio-Temporal Graph with Dynamic Inter-Client Dependencies (FedSTGD), a framework designed to model and reconstruct dynamic inter-client spatial dependencies in federated learning. FedSTGD incorporates a federated nonlinear computation decomposition module to approximate complex graph operations. This is complemented by a graph node embedding augmentation module, which alleviates performance degradation arising from the decomposition. These modules are coordinated through a client-server collective learning protocol, which decomposes dynamic inter-client spatial dependency learning tasks into lightweight, parallelizable subtasks. Extensive experiments on four real-world datasets demonstrate that FedSTGD achieves superior performance over state-of-the-art baselines in terms of RMSE, MAE, and MAPE, approaching that of centralized baselines. Ablation studies confirm the contribution of each module in addressing dynamic inter-client spatial dependencies, while sensitivity analysis highlights the robustness of FedSTGD to variations in hyperparameters.

</details>


### [368] [SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning](https://arxiv.org/abs/2511.09681)
*Tairan Huang,Yulin Jin,Junxu Liu,Qingqing Ye,Haibo Hu*

Main category: cs.LG

TL;DR: SEBA是一个样本高效的黑盒对抗性攻击框架，用于视觉强化学习（RL）代理。它通过集成一个影子Q模型、一个生成对抗网络和一个世界模型来有效攻击视觉RL代理，同时保持样本效率和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习（RL）在视觉控制和机器人领域取得了显著进展，但其对对抗性扰动的脆弱性仍有待充分研究。现有的黑盒攻击方法在处理基于图像的连续控制时，由于动作空间大和环境查询过多，效果有限。

Method: SEBA框架包含一个影子Q模型，用于估计对抗性条件下的累积奖励；一个生成对抗网络（GAN），用于生成视觉上不可察觉的扰动；以及一个世界模型，用于模拟环境动态以减少实际环境查询。该框架采用两阶段迭代训练过程，在学习影子模型和优化生成器之间交替进行。

Result: 在MuJoCo和Atari基准测试中，SEBA显著降低了累积奖励，保持了视觉保真度，并大大减少了与先前黑盒和白盒方法相比的环境交互次数。

Conclusion: SEBA是一个样本高效的框架，能够有效地对视觉强化学习代理进行黑盒对抗性攻击，在保持高攻击性能的同时，显著减少了环境交互次数，并保持了视觉保真度。

Abstract: Visual reinforcement learning has achieved remarkable progress in visual control and robotics, but its vulnerability to adversarial perturbations remains underexplored. Most existing black-box attacks focus on vector-based or discrete-action RL, and their effectiveness on image-based continuous control is limited by the large action space and excessive environment queries. We propose SEBA, a sample-efficient framework for black-box adversarial attacks on visual RL agents. SEBA integrates a shadow Q model that estimates cumulative rewards under adversarial conditions, a generative adversarial network that produces visually imperceptible perturbations, and a world model that simulates environment dynamics to reduce real-world queries. Through a two-stage iterative training procedure that alternates between learning the shadow model and refining the generator, SEBA achieves strong attack performance while maintaining efficiency. Experiments on MuJoCo and Atari benchmarks show that SEBA significantly reduces cumulative rewards, preserves visual fidelity, and greatly decreases environment interactions compared to prior black-box and white-box methods.

</details>


### [369] [ConstrainedSQL: Training LLMs for Text2SQL via Constrained Reinforcement Learning](https://arxiv.org/abs/2511.09693)
*Weiqin Chen,Nhan Huu Pham,Michael Robert Glass,Long Hai Vu,Gaetano Rossiello,Dharmashankar Subramanian,Santiago Paternain*

Main category: cs.LG

TL;DR: RL在Text2SQL中表现出色，但易受奖励函数设计影响，可能导致模型利用奖励漏洞。本文提出一个约束RL框架，结合自然、可解释的奖励和约束信号，并动态平衡两者。该框架具有理论保证，并在标准Text2SQL数据集上验证了其优于现有RL训练LLM的性能。


<details>
  <summary>Details</summary>
Motivation: RL在Text2SQL中展现了巨大潜力，但其性能高度依赖于奖励函数的精心设计，不恰当的奖励可能导致模型产生奖励破解行为。

Method: 本文提出一个约束RL框架，该框架能够整合自然且易于理解的奖励与约束信号，并在训练过程中动态地调整它们之间的权衡。我们为该约束RL框架提供了理论保证。

Result: 在标准的Text2SQL数据集上进行的大量数值实验证明，我们提出的方法相比于现有最先进的RL训练LLM能够取得显著的性能提升。

Conclusion: 我们提出的约束RL框架通过整合和动态平衡奖励与约束信号，有效解决了现有RL方法在Text2SQL任务中对奖励函数设计的敏感性问题，并取得了优于现有方法的性能。

Abstract: Reinforcement learning (RL) has demonstrated significant promise in enhancing the reasoning capabilities of Text2SQL LLMs, especially with advanced algorithms such as GRPO and DAPO. However, the performance of these methods is highly sensitive to the design of reward functions. Inappropriate rewards can lead to reward hacking, where models exploit loopholes in the reward structure to achieve high scores without genuinely solving the task. This work considers a constrained RL framework for Text2SQL that incorporates natural and interpretable reward and constraint signals, while dynamically balancing trade-offs among them during the training. We establish the theoretical guarantees of our constrained RL framework and our numerical experiments on the well-known Text2SQL datasets substantiate the improvement of our approach over the state-of-the-art RL-trained LLMs.

</details>


### [370] [Efficient Hyperdimensional Computing with Modular Composite Representations](https://arxiv.org/abs/2511.09708)
*Marco Angioli,Christopher J. Kymn,Antonello Rosato,Amy Loutfi,Mauro Olivieri,Denis Kleyko*

Main category: cs.LG

TL;DR: MCR是一种计算模型，使用模块化算术表示高维整数向量，旨在提供更高的表示能力并保持轻量级。本文对其进行了广泛评估，证明了其在容量、准确性和硬件效率方面的独特平衡，并在123个数据集上实现了准确性提升，内存占用是二元码组的1/4。通过设计专用加速器，MCR在基本操作和7个选定数据集上实现了高达3个数量级的速度提升和显著的节能。与二元码组相比，MCR的执行速度提高了3.08倍，能耗降低了2.68倍。


<details>
  <summary>Details</summary>
Motivation: MCR模型虽然有潜力，但因缺乏系统性分析和与其他模型的比较而受到关注有限，其复杂性被认为超过了表达能力的提升。本文旨在通过广泛评估来重新审视MCR。

Method: 通过实验测量容量来评估MCR，并将其与二元向量、复杂值表示和二元码组进行比较。此外，还研究了MCR的硬件实现，设计了专用加速器，并评估了其在基本操作和选定数据集上的性能。

Result: MCR在容量方面优于二元和整数向量，接近复杂值表示，但内存占用更低。在123个数据集上，MCR的准确性得到提升，并且可以用更少的内存达到与二元码组相同的性能。专用加速器实现了高达3个数量级的速度提升和显著的节能。与二元码组相比，MCR的执行速度提高了3.08倍，能耗降低了2.68倍。

Conclusion: MCR虽然比二元码组需要更复杂的操作，但其模块化算术和更高的每组件精度能够实现更低的维度。通过专用硬件实现时，MCR比现有模型更快、更节能、精度更高。

Abstract: The modular composite representation (MCR) is a computing model that represents information with high-dimensional integer vectors using modular arithmetic. Originally proposed as a generalization of the binary spatter code model, it aims to provide higher representational power while remaining a lighter alternative to models requiring high-precision components. Despite this potential, MCR has received limited attention. Systematic analyses of its trade-offs and comparisons with other models are lacking, sustaining the perception that its added complexity outweighs the improved expressivity. In this work, we revisit MCR by presenting its first extensive evaluation, demonstrating that it achieves a unique balance of capacity, accuracy, and hardware efficiency. Experiments measuring capacity demonstrate that MCR outperforms binary and integer vectors while approaching complex-valued representations at a fraction of their memory footprint. Evaluation on 123 datasets confirms consistent accuracy gains and shows that MCR can match the performance of binary spatter codes using up to 4x less memory. We investigate the hardware realization of MCR by showing that it maps naturally to digital logic and by designing the first dedicated accelerator. Evaluations on basic operations and 7 selected datasets demonstrate a speedup of up to 3 orders of magnitude and significant energy reductions compared to software implementation. When matched for accuracy against binary spatter codes, MCR achieves on average 3.08x faster execution and 2.68x lower energy consumption. These findings demonstrate that, although MCR requires more sophisticated operations than binary spatter codes, its modular arithmetic and higher per-component precision enable lower dimensionality. When realized with dedicated hardware, this results in a faster, more energy-efficient, and high-precision alternative to existing models.

</details>


### [371] [Generalizing PDE Emulation with Equation-Aware Neural Operators](https://arxiv.org/abs/2511.09729)
*Qian-Ze Zhu,Paul Raccuglia,Michael P. Brenner*

Main category: cs.LG

TL;DR: 我们提出了一个方程感知的模拟框架，该框架能够通过在神经网络中加入表示PDE项及其系数的向量编码来推广到未见的PDE。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法求解PDE的成本过高，而现有的基于深度学习的代理模型通常只适用于具有固定参数的单个PDE。

Method: 该方法训练了四种不同的建模技术，并使用了来自APEBench套件的1D PDE系列。模型通过条件化一个向量编码来表示PDE的项和系数。

Result: 该模型在未曾训练过的参数集上表现出色，在训练窗口之外的滚动中具有很强的稳定性，并且能够推广到完全未见的PDE。

Conclusion: 我们提出的方程感知模拟框架能够泛化到未见的PDE，在求解PDE方面取得了显著进展。

Abstract: Solving partial differential equations (PDEs) can be prohibitively expensive using traditional numerical methods. Deep learning-based surrogate models typically specialize in a single PDE with fixed parameters. We present a framework for equation-aware emulation that generalizes to unseen PDEs, conditioning a neural model on a vector encoding representing the terms in a PDE and their coefficients. We present a baseline of four distinct modeling technqiues, trained on a family of 1D PDEs from the APEBench suite. Our approach achieves strong performance on parameter sets held out from the training distribution, with strong stability for rollout beyond the training window, and generalization to an entirely unseen PDE. This work was developed as part of a broader effort exploring AI systems that automate the creation of expert-level empirical software for scorable scientific tasks. The data and codebase are available at https://github.com/google-research/generalized-pde-emulator.

</details>


### [372] [FlowCast: Advancing Precipitation Nowcasting with Conditional Flow Matching](https://arxiv.org/abs/2511.09731)
*Bernardo Perrone Ribeiro,Jana Faganeli Pucer*

Main category: cs.LG

TL;DR: FlowCast模型使用条件流匹配（CFM）技术，解决了雷达数据预测降雨时存在的动态不确定性和高维数据建模效率低下的问题，实现了快速、高精度预测，并优于现有的扩散模型。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在雷达降雨预测方面面临大气动态不确定性和高维数据建模效率的挑战，而扩散模型的迭代采样过程计算成本高昂，不适用于需要快速响应的应用。

Method: 提出FlowCast模型，首次将条件流匹配（CFM）应用于降雨预测。CFM直接学习从噪声到数据的映射，无需像扩散模型那样进行迭代采样，从而能够快速生成高质量的预测结果。

Result: FlowCast在预测精度上达到了新的最先进水平。与基于相同架构但使用扩散模型的方法相比，CFM目标在预测精度和效率上均表现更优，在显著减少采样步数的情况下仍能保持高性能。

Conclusion: CFM为高维时空预测提供了一种强大且实用的替代方案，尤其在降雨预测等需要快速响应的应用场景下具有显著优势。

Abstract: Radar-based precipitation nowcasting, the task of forecasting short-term precipitation fields from previous radar images, is a critical problem for flood risk management and decision-making. While deep learning has substantially advanced this field, two challenges remain fundamental: the uncertainty of atmospheric dynamics and the efficient modeling of high-dimensional data. Diffusion models have shown strong promise by producing sharp, reliable forecasts, but their iterative sampling process is computationally prohibitive for time-critical applications. We introduce FlowCast, the first model to apply Conditional Flow Matching (CFM) to precipitation nowcasting. Unlike diffusion, CFM learns a direct noise-to-data mapping, enabling rapid, high-fidelity sample generation with drastically fewer function evaluations. Our experiments demonstrate that FlowCast establishes a new state-of-the-art in predictive accuracy. A direct comparison further reveals the CFM objective is both more accurate and significantly more efficient than a diffusion objective on the same architecture, maintaining high performance with significantly fewer sampling steps. This work positions CFM as a powerful and practical alternative for high-dimensional spatiotemporal forecasting.

</details>


### [373] [Data Heterogeneity and Forgotten Labels in Split Federated Learning](https://arxiv.org/abs/2511.09736)
*Joana Tirana,Dimitra Tsigkari,David Solans Noguero,Nicolas Kourtellis*

Main category: cs.LG

TL;DR: Split Federated Learning (SFL) 存在灾难性遗忘问题，尤其是在数据异质性存在的情况下。模型在序列末期看到的类别表现更好。提出了一种名为 Hydra 的新方法来缓解这个问题。


<details>
  <summary>Details</summary>
Motivation: 研究 Split Federated Learning (SFL) 中数据异质性导致灾难性遗忘的现象。

Method: 分析了 SFL 中服务器处理顺序和切分层对灾难性遗忘的影响。提出了一种名为 Hydra 的新方法，该方法受多头神经网络的启发并适应 SFL 的设置。

Result: Hydra 方法在数值评估中表现优于基线方法和现有文献中的方法。

Conclusion: Hydra 是一种有效缓解 SFL 中灾难性遗忘的新方法。

Abstract: In Split Federated Learning (SFL), the clients collaboratively train a model with the help of a server by splitting the model into two parts. Part-1 is trained locally at each client and aggregated by the aggregator at the end of each round. Part-2 is trained at a server that sequentially processes the intermediate activations received from each client. We study the phenomenon of catastrophic forgetting (CF) in SFL in the presence of data heterogeneity. In detail, due to the nature of SFL, local updates of part-1 may drift away from global optima, while part-2 is sensitive to the processing sequence, similar to forgetting in continual learning (CL). Specifically, we observe that the trained model performs better in classes (labels) seen at the end of the sequence. We investigate this phenomenon with emphasis on key aspects of SFL, such as the processing order at the server and the cut layer. Based on our findings, we propose Hydra, a novel mitigation method inspired by multi-head neural networks and adapted for the SFL's setting. Extensive numerical evaluations show that Hydra outperforms baselines and methods from the literature.

</details>


### [374] [Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy](https://arxiv.org/abs/2511.09737)
*Bram Grooten,Patrick MacAlpine,Kaushik Subramanian,Peter Stone,Peter R. Wurman*

Main category: cs.LG

TL;DR: SPARC是一种单阶段适应方法，可以实现鲁棒的上下文强化学习，即使在测试时没有显式上下文信息的情况下也能泛化到分布外（OOD）设置。


<details>
  <summary>Details</summary>
Motivation: 提高机器人和控制领域中在不同环境（如不同地形或天气条件）中操作的能力，解决在缺乏显式上下文信息的情况下泛化到分布外（OOD）设置的挑战。

Method: 提出SPARC（单阶段适应鲁棒控制），这是一种简化的方法，用于上下文强化学习，与需要单独训练上下文编码器和历史适应模块的两阶段方法相比，该方法更易于实现和训练。

Result: SPARC在Gran Turismo 7赛车模拟器和风扰MuJoCo环境中进行了测试，证明其能够实现可靠且鲁棒的OOD泛化。

Conclusion: SPARC是一种有效且简化的上下文强化学习方法，可以实现鲁棒的OOD泛化。

Abstract: Generalization to unseen environments is a significant challenge in the field of robotics and control. In this work, we focus on contextual reinforcement learning, where agents act within environments with varying contexts, such as self-driving cars or quadrupedal robots that need to operate in different terrains or weather conditions than they were trained for. We tackle the critical task of generalizing to out-of-distribution (OOD) settings, without access to explicit context information at test time. Recent work has addressed this problem by training a context encoder and a history adaptation module in separate stages. While promising, this two-phase approach is cumbersome to implement and train. We simplify the methodology and introduce SPARC: single-phase adaptation for robust control. We test SPARC on varying contexts within the high-fidelity racing simulator Gran Turismo 7 and wind-perturbed MuJoCo environments, and find that it achieves reliable and robust OOD generalization.

</details>


### [375] [On the Convergence of Overparameterized Problems: Inherent Properties of the Compositional Structure of Neural Networks](https://arxiv.org/abs/2511.09810)
*Arthur Castello Branco de Oliveira,Dhruv Jatkar,Eduardo Sontag*

Main category: cs.LG

TL;DR: 该论文研究了神经网络的组合结构如何影响其优化景观和训练动态。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络的组合结构如何影响其优化景观和训练动态。

Method: 分析了与过度参数化优化问题相关的梯度流，并将其解释为具有线性激活的神经网络训练。推导了任何适当且实数解析的成本函数的全局收敛性。专门研究了标量值成本函数，并表征了景观的几何形状。

Result: 在标量值成本函数的情况下，证明了关键的结构特征（例如鞍点的位置和稳定性）对于所有可容许的成本都是通用的，并且仅取决于过度参数化的表示。证明了收敛速度可以根据一个新引入的不平衡指标根据初始化进行任意加速。通过一个简单的例子，展示了哪些几何和动力学性质可以扩展到具有激活函数的神经网络。

Conclusion: 神经网络的组合结构对其优化景观和训练动态有显著影响，并且在某些情况下，鞍点的位置和稳定性是普遍的。收敛速度可以通过初始化进行调整。

Abstract: This paper investigates how the compositional structure of neural networks shapes their optimization landscape and training dynamics. We analyze the gradient flow associated with overparameterized optimization problems, which can be interpreted as training a neural network with linear activations. Remarkably, we show that the global convergence properties can be derived for any cost function that is proper and real analytic. We then specialize the analysis to scalar-valued cost functions, where the geometry of the landscape can be fully characterized. In this setting, we demonstrate that key structural features -- such as the location and stability of saddle points -- are universal across all admissible costs, depending solely on the overparameterized representation rather than on problem-specific details. Moreover, we show that convergence can be arbitrarily accelerated depending on the initialization, as measured by an imbalance metric introduced in this work. Finally, we discuss how these insights may generalize to neural networks with sigmoidal activations, showing through a simple example which geometric and dynamical properties persist beyond the linear case.

</details>


### [376] [Harnessing Bounded-Support Evolution Strategies for Policy Refinement](https://arxiv.org/abs/2511.09923)
*Ethan Hirschowitz,Fabio Ramos*

Main category: cs.LG

TL;DR: TD-ES是一种基于三角分布的进化策略，用于改进机器人策略，通过结合PPO预训练和TD-ES精调，能在机器人操控任务中显著提高成功率并降低方差。


<details>
  <summary>Details</summary>
Motivation: 在策略改进的后期，使用on-policy RL（如PPO）进行训练时，梯度会变得不稳定且信号噪音大，限制了策略的改进效果。因此，需要一种能够稳定改进策略的方法。

Method: 提出了一种名为TD-ES（Triangular-Distribution ES）的算法。TD-ES使用有界、反对称的三角分布扰动，并结合中心秩有限差分估计器，实现稳定、可并行化、无梯度的策略更新。TD-ES与PPO预训练结合，形成一个两阶段的训练流程，先利用PPO提高样本效率，再用TD-ES进行策略精调。

Result: 在多种机器人操控任务的实验中，TD-ES将成功率相对PPO提高了26.5%，并显著降低了训练过程中的方差。

Conclusion: TD-ES是一种简单、计算成本低的方法，可以稳定地改进机器人策略，相比PPO能够带来显著的性能提升和更低的训练不确定性。

Abstract: Improving competent robot policies with on-policy RL is often hampered by noisy, low-signal gradients. We revisit Evolution Strategies (ES) as a policy-gradient proxy and localize exploration with bounded, antithetic triangular perturbations, suitable for policy refinement. We propose Triangular-Distribution ES (TD-ES) which pairs bounded triangular noise with a centered-rank finite-difference estimator to deliver stable, parallelizable, gradient-free updates. In a two-stage pipeline -- PPO pretraining followed by TD-ES refinement -- this preserves early sample efficiency while enabling robust late-stage gains. Across a suite of robotic manipulation tasks, TD-ES raises success rates by 26.5% relative to PPO and greatly reduces variance, offering a simple, compute-light path to reliable refinement.

</details>


### [377] [History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754)
*Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa*

Main category: cs.LG

TL;DR: 该研究提出了一种名为宏观情境检索的框架，通过检索历史相似的宏观经济情境来改进金融市场预测模型，使其能够适应非平稳市场条件和分布外（OOD）的性能下降。


<details>
  <summary>Details</summary>
Motivation: 金融市场具有内在的非平稳性，结构性断裂和宏观经济情境的变化常常导致预测模型在分布外（OOD）时失效。传统的融合数值指标和文本情感的多模式方法很难适应这种变化。

Method: 提出了一种宏观情境检索的框架，该框架通过检索增强的方式，在每次预测时都以历史宏观经济情境为基础。该方法将宏观经济指标（如CPI、失业率、收益率利差、GDP增长）和金融新闻情感共同嵌入到一个共享的相似性空间中，从而在推理过程中无需重新训练即可进行因果检索，找到先前的类似时期。

Result: 在2007-2023年的S&P 500数据上训练，并在2024年的AAPL和XOM数据上进行OOD评估，该框架一致地缩小了与OOD性能的差距。宏观条件检索实现了唯一正的样本外交易结果（AAPL：PF=1.18，Sharpe=0.95；XOM：PF=1.16，Sharpe=0.61），而静态数值、仅文本和朴素的多模式基线在情境变化下均失效。此外，检索到的邻居形成了可解释的证据链，对应于可识别的宏观情境，如通胀或收益率曲线倒挂阶段，支持了因果可解释性和透明度。

Conclusion: 宏观情境检索在分布变化下能够提供稳健且可解释的预测，验证了“金融历史可能不会重演，但经常押韵”的原理。所有数据集、模型和源代码均公开可用。

Abstract: Financial markets are inherently non-stationary: structural breaks and macroeconomic regime shifts often cause forecasting models to fail when deployed out of distribution (OOD). Conventional multimodal approaches that simply fuse numerical indicators and textual sentiment rarely adapt to such shifts. We introduce macro-contextual retrieval, a retrieval-augmented forecasting framework that grounds each prediction in historically analogous macroeconomic regimes. The method jointly embeds macro indicators (e.g., CPI, unemployment, yield spread, GDP growth) and financial news sentiment in a shared similarity space, enabling causal retrieval of precedent periods during inference without retraining.
  Trained on seventeen years of S&P 500 data (2007-2023) and evaluated OOD on AAPL (2024) and XOM (2024), the framework consistently narrows the CV to OOD performance gap. Macro-conditioned retrieval achieves the only positive out-of-sample trading outcomes (AAPL: PF=1.18, Sharpe=0.95; XOM: PF=1.16, Sharpe=0.61), while static numeric, text-only, and naive multimodal baselines collapse under regime shifts. Beyond metric gains, retrieved neighbors form interpretable evidence chains that correspond to recognizable macro contexts, such as inflationary or yield-curve inversion phases, supporting causal interpretability and transparency. By operationalizing the principle that "financial history may not repeat, but it often rhymes," this work demonstrates that macro-aware retrieval yields robust, explainable forecasts under distributional change.
  All datasets, models, and source code are publicly available.

</details>


### [378] [Gradient Flow Equations for Deep Linear Neural Networks: A Survey from a Network Perspective](https://arxiv.org/abs/2511.10362)
*Joel Wendin,Claudio Altafini*

Main category: cs.LG

TL;DR: 该论文研究了深度线性神经网络的梯度流方程的动力学和损失函数景观，特别是当激活函数缺失且损失函数为二次函数时，梯度下降训练动力学（步长趋近于0的极限）。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是理解深度线性神经网络在梯度流下的行为，包括其动力学特性和损失函数景观的特点。

Method: 文章将神经网络的邻接矩阵形式化，将梯度流方程表示为一类收敛的矩阵常微分方程，并分析其具有幂零、多项式、等谱和守恒律的性质。同时，详细描述了损失函数景观，并利用邻接矩阵表示来揭示其潜在的商空间结构。

Result: 损失函数景观包含无限多个全局最小值和鞍点（包括严格和非严格），但不存在局部最小值和最大值。损失函数本身是梯度流的正半定李雅普诺夫函数，其水平集是临界点的无界不变集，临界值对应于学习到的奇异值数量。邻接矩阵表示法能够一次性地表示每个临界值，并轻松确定鞍点的稳定和不稳定流形。

Conclusion: 邻接矩阵表示法为理解深度线性神经网络的梯度流动力学和损失函数景观提供了一个有效的框架，突出了其独特的数学结构，并能有效处理鞍点分析等问题。

Abstract: The paper surveys recent progresses in understanding the dynamics and loss landscape of the gradient flow equations associated to deep linear neural networks, i.e., the gradient descent training dynamics (in the limit when the step size goes to 0) of deep neural networks missing the activation functions and subject to quadratic loss functions. When formulated in terms of the adjacency matrix of the neural network, as we do in the paper, these gradient flow equations form a class of converging matrix ODEs which is nilpotent, polynomial, isospectral, and with conservation laws. The loss landscape is described in detail. It is characterized by infinitely many global minima and saddle points, both strict and nonstrict, but lacks local minima and maxima. The loss function itself is a positive semidefinite Lyapunov function for the gradient flow, and its level sets are unbounded invariant sets of critical points, with critical values that correspond to the amount of singular values of the input-output data learnt by the gradient along a certain trajectory. The adjacency matrix representation we use in the paper allows to highlight the existence of a quotient space structure in which each critical value of the loss function is represented only once, while all other critical points with the same critical value belong to the fiber associated to the quotient space. It also allows to easily determine stable and unstable submanifolds at the saddle points, even when the Hessian fails to obtain them.

</details>


### [379] [Belief Net: A Filter-Based Framework for Learning Hidden Markov Models from Observations](https://arxiv.org/abs/2511.10571)
*Reginald Zhiyan Chen,Heng-Sheng Chang,Prashant G. Mehta*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Hidden Markov Models (HMMs) are fundamental for modeling sequential data, yet learning their parameters from observations remains challenging. Classical methods like the Baum-Welch (EM) algorithm are computationally intensive and prone to local optima, while modern spectral algorithms offer provable guarantees but may produce probability outputs outside valid ranges. This work introduces Belief Net, a novel framework that learns HMM parameters through gradient-based optimization by formulating the HMM's forward filter as a structured neural network. Unlike black-box Transformer models, Belief Net's learnable weights are explicitly the logits of the initial distribution, transition matrix, and emission matrix, ensuring full interpretability. The model processes observation sequences using a decoder-only architecture and is trained end-to-end with standard autoregressive next-observation prediction loss. On synthetic HMM data, Belief Net achieves superior convergence speed compared to Baum-Welch, successfully recovering parameters in both undercomplete and overcomplete settings where spectral methods fail. Comparisons with Transformer-based models are also presented on real-world language data.

</details>


### [380] [Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO](https://arxiv.org/abs/2511.09780)
*Nikolay Blagoev,Oğuzhan Ersoy,Lydia Yiyu Chen*

Main category: cs.LG

TL;DR: GRPO是一种用于大语言模型（LLM）的后训练方法，它通过强化学习来学习偏好的模型输出。然而，这种去中心化的训练方式容易受到对抗性攻击。本研究提出了首个针对去中心化GRPO的对抗性攻击方法，可以通过注入恶意token来污染模型，在数学和编程任务中实现了高达100%的攻击成功率。研究还提出了两种防御方法，可以阻止攻击的发生。


<details>
  <summary>Details</summary>
Motivation: 去中心化GRPO在LLM后训练中的应用前景广阔，但其安全性值得关注，需要研究对抗性攻击及其防御方法。

Method: 提出了一种针对去中心化GRPO的对抗性攻击方法，并通过数学和编程任务的实例进行了验证。同时，提出了两种防御方法。

Result: 对抗性攻击在少量迭代（50次）内即可实现高达100%的攻击成功率，污染良性节点并破坏其LLM后训练。提出的防御方法可以实现高达100%的停止率，有效阻止攻击。

Conclusion: 去中心化GRPO易受对抗性攻击，但提出的防御方法可以有效应对这些攻击，保障系统的安全性。

Abstract: Group Relative Policy Optimization (GRPO) has demonstrated great utilization in post-training of Large Language Models (LLMs). In GRPO, prompts are answered by the model and, through reinforcement learning, preferred completions are learnt. Owing to the small communication volume, GRPO is inherently suitable for decentralised training as the prompts can be concurrently answered by multiple nodes and then exchanged in the forms of strings. In this work, we present the first adversarial attack in decentralised GRPO. We demonstrate that malicious parties can poison such systems by injecting arbitrary malicious tokens in benign models in both out-of-context and in-context attacks. Using empirical examples of math and coding tasks, we show that adversarial attacks can easily poison the benign nodes, polluting their local LLM post-training, achieving attack success rates up to 100% in as few as 50 iterations. We propose two ways to defend against these attacks, depending on whether all users train the same model or different models. We show that these defenses can achieve stop rates of up to 100%, making the attack impossible.

</details>


### [381] [Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2511.09783)
*Pablo Ruiz-Morales,Dries Vanoost,Davy Pissoort,Mathias Verbeke*

Main category: cs.LG

TL;DR: JEPAs can cluster time-series data by dynamical regimes because their predictive objective implicitly learns the Koopman operator's invariant subspace. This is proven by showing the JEPA loss is minimized when the encoder learns Koopman eigenfunctions, validated on synthetic data. A near-identity linear predictor is crucial for this disentangled representation.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explain the unexplained ability of Joint-Embedding Predictive Architectures (JEPAs) to cluster time-series data by underlying dynamical regimes and to provide a theoretical foundation for this phenomenon.

Method: The authors propose a theoretical explanation by hypothesizing that JEPA's predictive objective implicitly drives it to learn the invariant subspace of the system's Koopman operator. They prove that an idealized JEPA loss is minimized when the encoder represents the system's regime indicator functions (Koopman eigenfunctions). This theory is validated on synthetic data, showing that constraining the JEPA's linear predictor to be a near-identity operator is key.

Result: The study demonstrates that an idealized JEPA loss is minimized when the encoder represents Koopman eigenfunctions. Validation on synthetic data confirmed that the near-identity constraint on the linear predictor forces the encoder to learn these invariants, leading to interpretable solutions from entangled optima and revealing the predictor's role in representation disentanglement.

Conclusion: This work demystifies a key behavior of JEPAs, establishing a principled connection between self-supervised learning and dynamical systems theory, and offers insights for designing more robust and interpretable time-series models.

Abstract: Joint-Embedding Predictive Architectures (JEPAs), a powerful class of self-supervised models, exhibit an unexplained ability to cluster time-series data by their underlying dynamical regimes. We propose a novel theoretical explanation for this phenomenon, hypothesizing that JEPA's predictive objective implicitly drives it to learn the invariant subspace of the system's Koopman operator. We prove that an idealized JEPA loss is minimized when the encoder represents the system's regime indicator functions, which are Koopman eigenfunctions. This theory was validated on synthetic data with known dynamics, demonstrating that constraining the JEPA's linear predictor to be a near-identity operator is the key inductive bias that forces the encoder to learn these invariants. We further discuss that this constraint is critical for selecting this interpretable solution from a class of mathematically equivalent but entangled optima, revealing the predictor's role in representation disentanglement. This work demystifies a key behavior of JEPAs, provides a principled connection between modern self-supervised learning and dynamical systems theory, and informs the design of more robust and interpretable time-series models.

</details>


### [382] [CaReTS: A Multi-Task Framework Unifying Classification and Regression for Time Series Forecasting](https://arxiv.org/abs/2511.09789)
*Fulong Yao,Wanqing Zhao,Chao Zheng,Xiaofei Han*

Main category: cs.LG

TL;DR: CaReTS是一个新颖的多任务学习框架，结合分类和回归任务，用于多步时间序列预测，在预测准确性和趋势分类方面均优于SOTA算法。


<details>
  <summary>Details</summary>
Motivation: 大多数深度预测模型难以同时提供准确的预测和对时间动态的可解释性见解。

Method: 提出CaReTS多任务学习框架，采用双流架构，一个分类分支学习未来逐步趋势，一个回归分支估计与目标变量最新观测值的偏差。设计了具有不确定性感知加权的 Meets-task 损失，并实例化了四种包含CNN、LSTM和Transformer的变体（CaReTS1-4）。

Result: CaReTS 在真实数据集上的实验表明，其在预测准确性方面优于最先进的算法，同时实现了更高的趋势分类性能。

Conclusion: CaReTS框架通过分离宏观趋势和微观偏差，实现了可解释的时间序列预测，并且在性能上优于现有SOTA方法。

Abstract: Recent advances in deep forecasting models have achieved remarkable performance, yet most approaches still struggle to provide both accurate predictions and interpretable insights into temporal dynamics. This paper proposes CaReTS, a novel multi-task learning framework that combines classification and regression tasks for multi-step time series forecasting problems. The framework adopts a dual-stream architecture, where a classification branch learns the stepwise trend into the future, while a regression branch estimates the corresponding deviations from the latest observation of the target variable. The dual-stream design provides more interpretable predictions by disentangling macro-level trends from micro-level deviations in the target variable. To enable effective learning in output prediction, deviation estimation, and trend classification, we design a multi-task loss with uncertainty-aware weighting to adaptively balance the contribution of each task. Furthermore, four variants (CaReTS1--4) are instantiated under this framework to incorporate mainstream temporal modelling encoders, including convolutional neural networks (CNNs), long short-term memory networks (LSTMs), and Transformers. Experiments on real-world datasets demonstrate that CaReTS outperforms state-of-the-art (SOTA) algorithms in forecasting accuracy, while achieving higher trend classification performance.

</details>


### [383] [Constrained Best Arm Identification with Tests for Feasibility](https://arxiv.org/abs/2511.09808)
*Ting Cai,Kirthevasan Kandasamy*

Main category: cs.LG

TL;DR: 本研究提出了一个用于在满足额外可行性约束条件下识别最佳臂（BAI）的算法，该算法能够区分性能和可行性测试，并具有最优的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，最佳臂识别不仅需要找到性能最优的臂，还需要满足一定的可行性约束。现有方法通常假设性能和可行性是同时观察到的，但这不符合实际情况，例如在药物发现中，性能（效力）和可行性（毒性、溶解度）的测试可能需要分开进行。因此，需要开发能够独立选择测试性能还是可行性的BAI算法。

Method: 研究了可行性BAI问题，允许决策者选择测试臂的性能（l=0）或其N个可行性约束中的一个（l∈[N]）。在固定置信度设置下，提出了一种算法来识别具有最高性能且满足约束的臂，并保证识别正确的概率至少为1-δ。通过推导样本复杂度，证明了该算法能够自适应问题难度，并根据性能或可行性哪个更容易被排除来剔除臂。

Result: 所提出的算法在样本复杂度上得到了上界，并证明了其在δ→0时渐近最优。在合成和真实世界数据集上的实验结果表明，该算法优于其他最先进的BAI算法。

Conclusion: 本研究提出的可行性BAI算法能够有效地区分性能和可行性测试，在固定置信度设置下实现了渐近最优的样本复杂度，并在实际应用中表现出优越的性能。

Abstract: Best arm identification (BAI) aims to identify the highest-performance arm among a set of $K$ arms by collecting stochastic samples from each arm. In real-world problems, the best arm needs to satisfy additional feasibility constraints. While there is limited prior work on BAI with feasibility constraints, they typically assume the performance and constraints are observed simultaneously on each pull of an arm. However, this assumption does not reflect most practical use cases, e.g., in drug discovery, we wish to find the most potent drug whose toxicity and solubility are below certain safety thresholds. These safety experiments can be conducted separately from the potency measurement. Thus, this requires designing BAI algorithms that not only decide which arm to pull but also decide whether to test for the arm's performance or feasibility. In this work, we study feasible BAI which allows a decision-maker to choose a tuple $(i,\ell)$, where $i\in [K]$ denotes an arm and $\ell$ denotes whether she wishes to test for its performance ($\ell=0$) or any of its $N$ feasibility constraints ($\ell\in[N]$). We focus on the fixed confidence setting, which is to identify the \textit{feasible} arm with the \textit{highest performance}, with a probability of at least $1-δ$. We propose an efficient algorithm and upper-bound its sample complexity, showing our algorithm can naturally adapt to the problem's difficulty and eliminate arms by worse performance or infeasibility, whichever is easier. We complement this upper bound with a lower bound showing that our algorithm is \textit{asymptotically ($δ\rightarrow 0$) optimal}. Finally, we empirically show that our algorithm outperforms other state-of-the-art BAI algorithms in both synthetic and real-world datasets.

</details>


### [384] [ACT as Human: Multimodal Large Language Model Data Annotation with Critical Thinking](https://arxiv.org/abs/2511.09833)
*Lequan Lin,Dai Shi,Andi Han,Feng Chen,Qiuzheng Chen,Jiawen Li,Zhaoyang Li,Jiyuan Li,Zhenbang Sun,Junbin Gao*

Main category: cs.LG

TL;DR: LLM标注仍需人工审核，提出ACT数据处理流程，利用LLM进行标注和错误识别，提高标注效率，减少人工成本。


<details>
  <summary>Details</summary>
Motivation: 监督学习需要高质量标注数据，但人工标注成本高昂且耗时。LLM标注质量尚待提高。

Method: 提出ACT数据处理流程，让LLM既充当标注者又充当“裁判”，识别潜在错误，人类只审核可疑样本。ACT可应用于NLP、CV和多模态理解。

Result: 经验研究得出7条提高标注质量和降低成本的见解，并转化为用户指南。理论分析了如何修改损失函数，使在ACT数据上训练的模型表现能与全人工标注数据相媲美。实验表明，在大多数基准数据集上，性能差距可缩小到2%以内，同时节省高达90%的人工成本。

Conclusion: ACT数据处理流程能显著提高标注效率，降低人工成本，并保持与全人工标注相当的模型性能。

Abstract: Supervised learning relies on high-quality labeled data, but obtaining such data through human annotation is both expensive and time-consuming. Recent work explores using large language models (LLMs) for annotation, but LLM-generated labels still fall short of human-level quality. To address this problem, we propose the Annotation with Critical Thinking (ACT) data pipeline, where LLMs serve not only as annotators but also as judges to critically identify potential errors. Human effort is then directed towards reviewing only the most "suspicious" cases, significantly improving the human annotation efficiency. Our major contributions are as follows: (1) ACT is applicable to a wide range of domains, including natural language processing (NLP), computer vision (CV), and multimodal understanding, by leveraging multimodal-LLMs (MLLMs). (2) Through empirical studies, we derive 7 insights on how to enhance annotation quality while efficiently reducing the human cost, and then translate these findings into user-friendly guidelines. (3) We theoretically analyze how to modify the loss function so that models trained on ACT data achieve similar performance to those trained on fully human-annotated data. Our experiments show that the performance gap can be reduced to less than 2% on most benchmark datasets while saving up to 90% of human costs.

</details>


### [385] [Steering Pretrained Drafters during Speculative Decoding](https://arxiv.org/abs/2511.09844)
*Frédéric Berdoz,Peer Rheinboldt,Roger Wattenhofer*

Main category: cs.LG

TL;DR: Speculative decoding的局限性在于草稿-验证器不匹配。本文提出一种动态对齐机制，通过将来自验证器的隐藏状态的引导向量注入预训练草稿器，来提高草稿-验证器匹配率。


<details>
  <summary>Details</summary>
Motivation: Speculative decoding通过将生成过程分为草稿和并行验证来加速语言模型推理，但其主要限制是草稿-验证器不匹配，这限制了代币接受率并降低了整体有效性。虽然从头开始训练的小型草稿头可以弥补速度上的不足，但在验证器占主导地位或输入偏离分布时，它们会遇到困难。相比之下，预训练的草稿器虽然较慢，但由于其更强的独立生成能力，可以实现更高的接受率，在草稿延迟可忽略不计的情况下具有竞争力。

Method: 本文提出了一种轻量级的动态对齐机制，该机制通过计算来自验证器的隐藏状态的引导向量并将其注入预训练的草稿器中，来提高预训练草稿器的接受率。

Result: 与现有的离线对齐方法（如蒸馏）相比，该方法在标准采样下将接受的代币数量提高了35%，在贪婪采样下提高了22%，同时带来的计算开销可忽略不计。

Conclusion: 本文提出的动态对齐机制可以提高预训练草稿器的接受率，并且可以快速应用于现有架构和预训练模型。

Abstract: Speculative decoding accelerates language model inference by separating generation into fast drafting and parallel verification. Its main limitation is drafter-verifier misalignment, which limits token acceptance and reduces overall effectiveness. While small drafting heads trained from scratch compensate with speed, they struggle when verification dominates latency or when inputs are out of distribution. In contrast, pretrained drafters, though slower, achieve higher acceptance rates thanks to stronger standalone generation capabilities, making them competitive when drafting latency is negligible relative to verification or communication overhead. In this work, we aim to improve the acceptance rates of pretrained drafters by introducing a lightweight dynamic alignment mechanism: a steering vector computed from the verifier's hidden states and injected into the pretrained drafter. Compared to existing offline alignment methods such as distillation, our approach boosts the number of accepted tokens by up to 35\% under standard sampling and 22\% under greedy sampling, all while incurring negligible computational overhead. Importantly, our approach can be retrofitted to existing architectures and pretrained models, enabling rapid adoption.

</details>


### [386] [ConSurv: Multimodal Continual Learning for Survival Analysis](https://arxiv.org/abs/2511.09853)
*Dianzhi Yu,Conghao Xiong,Yankai Chen,Wenqian Cui,Xinni Zhang,Yifei Zhang,Hao Chen,Joseph J. Y. Sung,Irwin King*

Main category: cs.LG

TL;DR: ConSurv是一种多模态持续学习方法，用于处理癌症生存预测中的灾难性遗忘和跨模态交互问题。


<details>
  <summary>Details</summary>
Motivation: 现有的癌症生存预测模型无法适应动态变化的临床环境和连续数据流，而持续学习（CL）方法在处理多模态数据（如图 像和基因组学）时存在严重的灾难性遗忘问题，并且忽略了模态间的相互关系。

Method: ConSurv 提出了一种名为 ConSurv 的多模态持续学习（MMCL）方法，包含两个关键组件：多阶段专家混合（MS-MoE）和特征约束重放（FCR）。MS-MoE 在不同学习阶段捕获任务共享和任务特定的知识，学习模态间的关系。FCR 通过限制不同级别（编码器级别和融合级别）的特征偏差来增强知识并减轻遗忘。此外，还引入了一个包含四个数据集的多模态生存分析增量学习（MSAIL）基准。

Result: ConSurv 在 MSAIL 基准上进行了广泛的实验评估，结果表明其在多个指标上优于现有方法。

Conclusion: ConSurv 是首个用于生存分析的多模态持续学习方法，能够有效解决灾难性遗忘和跨模态交互问题，并在癌症生存预测任务中表现出优越的性能。

Abstract: Survival prediction of cancers is crucial for clinical practice, as it informs mortality risks and influences treatment plans. However, a static model trained on a single dataset fails to adapt to the dynamically evolving clinical environment and continuous data streams, limiting its practical utility. While continual learning (CL) offers a solution to learn dynamically from new datasets, existing CL methods primarily focus on unimodal inputs and suffer from severe catastrophic forgetting in survival prediction. In real-world scenarios, multimodal inputs often provide comprehensive and complementary information, such as whole slide images and genomics; and neglecting inter-modal correlations negatively impacts the performance. To address the two challenges of catastrophic forgetting and complex inter-modal interactions between gigapixel whole slide images and genomics, we propose ConSurv, the first multimodal continual learning (MMCL) method for survival analysis. ConSurv incorporates two key components: Multi-staged Mixture of Experts (MS-MoE) and Feature Constrained Replay (FCR). MS-MoE captures both task-shared and task-specific knowledge at different learning stages of the network, including two modality encoders and the modality fusion component, learning inter-modal relationships. FCR further enhances learned knowledge and mitigates forgetting by restricting feature deviation of previous data at different levels, including encoder-level features of two modalities and the fusion-level representations. Additionally, we introduce a new benchmark integrating four datasets, Multimodal Survival Analysis Incremental Learning (MSAIL), for comprehensive evaluation in the CL setting. Extensive experiments demonstrate that ConSurv outperforms competing methods across multiple metrics.

</details>


### [387] [Maximizing Efficiency of Dataset Compression for Machine Learning Potentials With Information Theory](https://arxiv.org/abs/2511.10561)
*Benjamin Yu,Vincenzo Lordi,Daniel Schwalbe-Koda*

Main category: cs.LG

TL;DR: 使用信息论框架和最小集覆盖算法，开发了一种高效的原子模型数据集压缩方法，能在高压缩率下保留数据集的多样性和异常值，并提高 MLIP 的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习原子间势（MLIP）在准确性和成本之间存在权衡，其性能受训练数据集的大小和多样性影响。大型数据集虽然能提高模型性能，但成本高昂；小型数据集则可能丢失重要信息。因此，需要一种能高效压缩数据集的方法。

Method: 将原子模型数据集压缩视为一个最小集覆盖（MSC）问题，通过识别包含原始数据集最多信息且剔除冗余信息的最小结构子集来优化数据集。

Result: 在 GAP-20 和 TM23 数据集上进行了广泛的演示，并在 64 个 ColabFit 数据集上进行了验证。结果表明，MSC 方法在高压缩率下能保留异常值，保持数据集多样性，并重现力的长尾分布，优于其他子采样方法。使用 MSC 压缩的数据集训练的 MLIP 在低数据量情况下对分布外数据表现出更低的误差。

Conclusion: 所提出的基于信息论和 MSC 的数据集压缩方法能够高效地识别和保留原子模型数据集中的关键信息，即使在高压缩率下也能保持数据集的多样性和异常值，从而提高 MLIP 的准确性和可靠性，并在实际应用中具有广泛的潜力。

Abstract: Machine learning interatomic potentials (MLIPs) balance high accuracy and lower costs compared to density functional theory calculations, but their performance often depends on the size and diversity of training datasets. Large datasets improve model accuracy and generalization but are computationally expensive to produce and train on, while smaller datasets risk discarding rare but important atomic environments and compromising MLIP accuracy/reliability. Here, we develop an information-theoretical framework to quantify the efficiency of dataset compression methods and propose an algorithm that maximizes this efficiency. By framing atomistic dataset compression as an instance of the minimum set cover (MSC) problem over atom-centered environments, our method identifies the smallest subset of structures that contains as much information as possible from the original dataset while pruning redundant information. The approach is extensively demonstrated on the GAP-20 and TM23 datasets, and validated on 64 varied datasets from the ColabFit repository. Across all cases, MSC consistently retains outliers, preserves dataset diversity, and reproduces the long-tail distributions of forces even at high compression rates, outperforming other subsampling methods. Furthermore, MLIPs trained on MSC-compressed datasets exhibit reduced error for out-of-distribution data even in low-data regimes. We explain these results using an outlier analysis and show that such quantitative conclusions could not be achieved with conventional dimensionality reduction methods. The algorithm is implemented in the open-source QUESTS package and can be used for several tasks in atomistic modeling, from data subsampling, outlier detection, and training improved MLIPs at a lower cost.

</details>


### [388] [Unlearning Imperative: Securing Trustworthy and Responsible LLMs through Engineered Forgetting](https://arxiv.org/abs/2511.09855)
*James Jin Kang,Dang Bui,Thanh Pham,Huo-Chong Ling*

Main category: cs.LG

TL;DR: LLM 无法保证永久删除用户数据，现有的“遗忘”方法存在不足，需要结合技术和组织措施来解决这一挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在处理敏感信息时存在隐私泄露风险，因为它们缺乏可靠的机制来永久删除已使用过的私密信息。

Method: 本篇论文调研了针对 LLM 的机器学习“遗忘”技术的研究，评估了现有方法的有效性，并探讨了差分隐私、同态加密、联邦学习、短暂记忆、审计实践和监管框架等技术和制度性保障措施。

Result: 虽然在机器学习“遗忘”方面取得了进展，但仍未实现高效、可验证且能抵御对抗性攻击的“遗忘”技术。

Conclusion: 为了在敏感领域安全部署 LLM，需要在避免高成本重新训练、加强对抗性恢复防御以及建立问责制方面取得更大进展。通过结合技术和组织视角，可以实现既能满足用户“遗忘”需求，又能维护隐私和公众信任的 AI 系统。

Abstract: The growing use of large language models in sensitive domains has exposed a critical weakness: the inability to ensure that private information can be permanently forgotten. Yet these systems still lack reliable mechanisms to guarantee that sensitive information can be permanently removed once it has been used. Retraining from the beginning is prohibitively costly, and existing unlearning methods remain fragmented, difficult to verify, and often vulnerable to recovery. This paper surveys recent research on machine unlearning for LLMs and considers how far current approaches can address these challenges. We review methods for evaluating whether forgetting has occurred, the resilience of unlearned models against adversarial attacks, and mechanisms that can support user trust when model complexity or proprietary limits restrict transparency. Technical solutions such as differential privacy, homomorphic encryption, federated learning, and ephemeral memory are examined alongside institutional safeguards including auditing practices and regulatory frameworks. The review finds steady progress, but robust and verifiable unlearning is still unresolved. Efficient techniques that avoid costly retraining, stronger defenses against adversarial recovery, and governance structures that reinforce accountability are needed if LLMs are to be deployed safely in sensitive applications. By integrating technical and organizational perspectives, this study outlines a pathway toward AI systems that can be required to forget, while maintaining both privacy and public trust.

</details>


### [389] [Uncertainty-Guided Checkpoint Selection for Reinforcement Finetuning of Large Language Models](https://arxiv.org/abs/2511.09864)
*Manh Nguyen,Dung Nguyen,Dai Do,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: RL微调LLM常不稳定，难以选取最佳模型。本文提出不确定性引导的检查点选择（UGCS）方法，通过识别高不确定性样本来评估和排名模型，无需额外计算，并在多项实验中表现优于传统方法，证实了解决难题能力强的模型更可靠。


<details>
  <summary>Details</summary>
Motivation: RL微调LLM时，模型选择不稳定且方差大，现有评估方法（如在验证集上评估或依赖最终模型）成本高或无保证。

Method: UGCS方法通过不确定性识别难例，并根据模型处理这些难例的能力来排名检查点，通过平均高不确定性样本的奖励来获得稳定信号。

Result: 实验表明，UGCS在三个数据集和三个LLM上，能稳定地选出泛化能力更强的模型，优于依赖训练或验证性能的传统方法。

Conclusion: 解决最难问题时模型的不确定性越低，其整体可靠性越高。

Abstract: Reinforcement learning (RL) finetuning is crucial to aligning large language models (LLMs), but the process is notoriously unstable and exhibits high variance across model checkpoints. In practice, selecting the best checkpoint is challenging: evaluating checkpoints on the validation set during training is computationally expensive and requires a good validation set, while relying on the final checkpoint provides no guarantee of good performance. We introduce an uncertainty-guided approach for checkpoint selection (UGCS) that avoids these pitfalls. Our method identifies hard question-answer pairs using per-sample uncertainty and ranks checkpoints by how well they handle these challenging cases. By averaging the rewards of the top-uncertain samples over a short training window, our method produces a stable and discriminative signal without additional forward passes or significant computation overhead. Experiments across three datasets and three LLMs demonstrate that it consistently identifies checkpoints with stronger generalization, outperforming traditional strategies such as relying on training or validation performance. These results highlight that models solving their hardest tasks with low uncertainty are the most reliable overall.

</details>


### [390] [Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning](https://arxiv.org/abs/2511.09871)
*Hyung-Jun Moon,Sung-Bae Cho*

Main category: cs.LG

TL;DR: 该方法通过两种互补的记忆网络来解决持续学习中的灾难性遗忘问题，一种学习共享特征，另一种学习特定任务的特征，并能自适应地调整记忆容量，在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法会孤立地处理任务，阻碍了学习者利用任务间的有用关系，导致重复学习相似特征或过度区分特征。

Method: 提出了一种完全可微分、无需例证的、可扩展的方法，包含两种互补的记忆：一种学习跨任务的共享特征，另一种结合共享特征学习每个样本的独特判别特征。这两种记忆都是可微分的，网络可以自主学习每个样本的潜在表示。对于每个任务，记忆调整模块自适应地修剪关键时隙并最小化容量扩展以容纳新概念，同时通过正交正则化强制区分保留的和新学的记忆成分，以防止干扰。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的实验表明，该方法在类别增量学习方面优于14种最先进的方法，最终准确率分别为55.13%、37.24%和30.11%。

Conclusion: 通过有效整合和利用知识，该方法可以提高跨序列任务的平均性能，并且产生的特征提取结果最接近上限，从而为持续学习树立了新的里程碑。

Abstract: Continual learning methods used to force neural networks to process sequential tasks in isolation, preventing them from leveraging useful inter-task relationships and causing them to repeatedly relearn similar features or overly differentiate them. To address this problem, we propose a fully differentiable, exemplar-free expandable method composed of two complementary memories: One learns common features that can be used across all tasks, and the other combines the shared features to learn discriminative characteristics unique to each sample. Both memories are differentiable so that the network can autonomously learn latent representations for each sample. For each task, the memory adjustment module adaptively prunes critical slots and minimally expands capacity to accommodate new concepts, and orthogonal regularization enforces geometric separation between preserved and newly learned memory components to prevent interference. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that the proposed method outperforms 14 state-of-the-art methods for class-incremental learning, achieving final accuracies of 55.13\%, 37.24\%, and 30.11\%, respectively. Additional analysis confirms that, through effective integration and utilization of knowledge, the proposed method can increase average performance across sequential tasks, and it produces feature extraction results closest to the upper bound, thus establishing a new milestone in continual learning.

</details>


### [391] [A General Anchor-Based Framework for Scalable Fair Clustering](https://arxiv.org/abs/2511.09889)
*Shengfei Wei,Suyuan Liu,Jun Wang,Ke Liang,Miaomiao Li,Lei Luo*

Main category: cs.LG

TL;DR: 本研究提出了一种名为AFCF（Anchor-based Fair Clustering Framework）的新型框架，旨在解决现有公平聚类算法计算复杂度过高的问题，使其能够实现线性时间复杂度，适用于大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的公平聚类算法计算复杂度高，无法满足大规模数据集的需求。

Method: AFCF框架首先采用新颖的公平采样策略选择少量锚点，然后将现有公平聚类算法应用于该锚点集。核心模块是锚点图构建，通过优化问题和组标签联合约束来传播标签并保持公平性，最终保证整个数据集的公平性与锚点集一致。使用ADMM算法进行高效求解。

Result: 在多个大规模基准测试中，AFCF显著加速了现有算法，计算时间减少了几个数量级，同时保持了良好的聚类性能和公平性保证。

Conclusion: AFCF框架成功地解决了公平聚类算法的计算效率问题，实现了大规模数据集上的公平聚类。

Abstract: Fair clustering is crucial for mitigating bias in unsupervised learning, yet existing algorithms often suffer from quadratic or super-quadratic computational complexity, rendering them impractical for large-scale datasets. To bridge this gap, we introduce the Anchor-based Fair Clustering Framework (AFCF), a novel, general, and plug-and-play framework that empowers arbitrary fair clustering algorithms with linear-time scalability. Our approach first selects a small but representative set of anchors using a novel fair sampling strategy. Then, any off-the-shelf fair clustering algorithm can be applied to this small anchor set. The core of our framework lies in a novel anchor graph construction module, where we formulate an optimization problem to propagate labels while preserving fairness. This is achieved through a carefully designed group-label joint constraint, which we prove theoretically ensures that the fairness of the final clustering on the entire dataset matches that of the anchor clustering. We solve this optimization efficiently using an ADMM-based algorithm. Extensive experiments on multiple large-scale benchmarks demonstrate that AFCF drastically accelerates state-of-the-art methods, which reduces computational time by orders of magnitude while maintaining strong clustering performance and fairness guarantees.

</details>


### [392] [Simulator and Experience Enhanced Diffusion Model for Comprehensive ECG Generation](https://arxiv.org/abs/2511.09895)
*Xiaoda Wang,Kaiqiao Han,Yuhao Xu,Xiao Luo,Yizhou Sun,Wei Wang,Carl Yang*

Main category: cs.LG

TL;DR: SE-Diff利用生理模拟器和临床经验增强的扩散模型来生成更逼真、语义更准确的心电图(ECG)。


<details>
  <summary>Details</summary>
Motivation: 由于成本、隐私和工作流程的限制，用于心脏评估的大型、带注释的心电图语料库很少见。生成心电图有助于理解心脏电活动机制、构建大规模、异构、无偏见的数据集，并促进隐私保护的数据共享。从临床背景生成逼真的心电图信号非常重要但探索不足。

Method: SE-Diff将一个轻量级的基于常微分方程(ODE)的心电图模拟器通过节律解码器和与模拟器一致的约束集成到扩散过程中，以注入机械先验来促进生理上合理的波形。同时，设计了一个由LLM驱动的、检索增强的经验策略来注入临床知识，为心电图生成提供更多指导。

Result: SE-Diff在真实心电图数据集上的广泛实验表明，与基线相比，SE-Diff在信号保真度和文本-ECG语义对齐方面都有所改进，证明了其在文本到ECG生成方面的优越性。此外，基于模拟器和经验的知识也有助于下游ECG分类。

Conclusion: SE-Diff通过结合生理模拟器和临床经验，在文本到ECG生成方面取得了显著的改进，并且这些知识也有助于下游任务。

Abstract: Cardiovascular disease (CVD) is a leading cause of mortality worldwide. Electrocardiograms (ECGs) are the most widely used non-invasive tool for cardiac assessment, yet large, well-annotated ECG corpora are scarce due to cost, privacy, and workflow constraints. Generating ECGs can be beneficial for the mechanistic understanding of cardiac electrical activity, enable the construction of large, heterogeneous, and unbiased datasets, and facilitate privacy-preserving data sharing. Generating realistic ECG signals from clinical context is important yet underexplored. Recent work has leveraged diffusion models for text-to-ECG generation, but two challenges remain: (i) existing methods often overlook the physiological simulator knowledge of cardiac activity; and (ii) they ignore broader, experience-based clinical knowledge grounded in real-world practice. To address these gaps, we propose SE-Diff, a novel physiological simulator and experience enhanced diffusion model for comprehensive ECG generation. SE-Diff integrates a lightweight ordinary differential equation (ODE)-based ECG simulator into the diffusion process via a beat decoder and simulator-consistent constraints, injecting mechanistic priors that promote physiologically plausible waveforms. In parallel, we design an LLM-powered experience retrieval-augmented strategy to inject clinical knowledge, providing more guidance for ECG generation. Extensive experiments on real-world ECG datasets demonstrate that SE-Diff improves both signal fidelity and text-ECG semantic alignment over baselines, proving its superiority for text-to-ECG generation. We further show that the simulator-based and experience-based knowledge also benefit downstream ECG classification.

</details>


### [393] [Explore and Establish Synergistic Effects Between Weight Pruning and Coreset Selection in Neural Network Training](https://arxiv.org/abs/2511.09901)
*Weilin Wan,Fan Yi,Weizhong Zhang,Quan Zhou,Cheng Jin*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SWaST（Simultaneous Weight and Sample Tailoring）的机制，通过交替进行权重剪枝和核心集选择，来解决深度学习中的计算效率问题，并观察到了一种“关键双重损失”现象，同时提出了一种状态保持机制来缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型需要大量的模型权重和训练样本，导致计算成本高昂。权重剪枝和核心集选择是提高计算效率的两种方法，但它们之间存在相互影响，可能导致模型性能下降。

Method: 提出了一种名为SWaST（Simultaneous Weight and Sample Tailoring）的机制，该机制交替进行权重剪枝和核心集选择，以利用它们之间的协同作用。在研究过程中，观察到了一种“关键双重损失”现象，即重要的权重及其支持样本可能被同时移除，导致模型不稳定。为了解决这个问题，SWaST集成了状态保持机制。

Result: 通过实验证明，SWaST在不同的剪枝率和核心集大小下，权重剪枝和核心集选择之间存在显著的协同作用，带来了高达17.83%的准确率提升，同时将计算量（FLOPs）减少了10%到90%。

Conclusion: SWaST通过交替进行权重剪枝和核心集选择，并结合状态保持机制，能够有效提高深度学习模型的计算效率和准确率，克服了传统方法中可能出现的“关键双重损失”问题。

Abstract: Modern deep neural networks rely heavily on massive model weights and training samples, incurring substantial computational costs. Weight pruning and coreset selection are two emerging paradigms proposed to improve computational efficiency. In this paper, we first explore the interplay between redundant weights and training samples through a transparent analysis: redundant samples, particularly noisy ones, cause model weights to become unnecessarily overtuned to fit them, complicating the identification of irrelevant weights during pruning; conversely, irrelevant weights tend to overfit noisy data, undermining coreset selection effectiveness. To further investigate and harness this interplay in deep learning, we develop a Simultaneous Weight and Sample Tailoring mechanism (SWaST) that alternately performs weight pruning and coreset selection to establish a synergistic effect in training. During this investigation, we observe that when simultaneously removing a large number of weights and samples, a phenomenon we term critical double-loss can occur, where important weights and their supportive samples are mistakenly eliminated at the same time, leading to model instability and nearly irreversible degradation that cannot be recovered in subsequent training. Unlike classic machine learning models, this issue can arise in deep learning due to the lack of theoretical guarantees on the correctness of weight pruning and coreset selection, which explains why these paradigms are often developed independently. We mitigate this by integrating a state preservation mechanism into SWaST, enabling stable joint optimization. Extensive experiments reveal a strong synergy between pruning and coreset selection across varying prune rates and coreset sizes, delivering accuracy boosts of up to 17.83% alongside 10% to 90% FLOPs reductions.

</details>


### [394] [PRISM: Diversifying Dataset Distillation by Decoupling Architectural Priors](https://arxiv.org/abs/2511.09905)
*Brian B. Moser,Shalini Strode,Federico Raue,Stanislav Frolov,Krzysztof Adamkiewicz,Arundhati Shanbhag,Joachim Folk,Tobias C. Nauen,Andreas Dengel*

Main category: cs.LG

TL;DR: PRISM框架通过引入多样化的教师模型来解决现有数据集蒸馏方法中单一教师模型带来的归纳偏置问题，生成具有更高类内多样性和泛化能力的压缩数据集，并在ImageNet-1K上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法倾向于继承单一教师模型的归纳偏置，导致生成过于平滑、同质化的样本，降低类内多样性并限制泛化能力。

Method: PRISM框架解耦了logit匹配和正则化目标，并分别使用不同的教师模型进行监督：使用一个主模型进行logits监督，使用一个随机子集进行BN（批量归一化）对齐。

Result: 在ImageNet-1K上，PRISM在低IPC和中IPC范围内始终优于单一教师方法（如SRe2L）和最近的多教师变体（如G-VBSM）。生成的数据显示出更丰富的类内多样性，特征之间的余弦相似度显著下降。

Conclusion: PRISM框架通过引入多样化的教师模型和解耦的监督机制，能够生成更具代表性和泛化能力的数据集，有效解决了现有数据集蒸馏方法的局限性。

Abstract: Dataset distillation (DD) promises compact yet faithful synthetic data, but existing approaches often inherit the inductive bias of a single teacher model. As dataset size increases, this bias drives generation toward overly smooth, homogeneous samples, reducing intra-class diversity and limiting generalization. We present PRISM (PRIors from diverse Source Models), a framework that disentangles architectural priors during synthesis. PRISM decouples the logit-matching and regularization objectives, supervising them with different teacher architectures: a primary model for logits and a stochastic subset for batch-normalization (BN) alignment. On ImageNet-1K, PRISM consistently and reproducibly outperforms single-teacher methods (e.g., SRe2L) and recent multi-teacher variants (e.g., G-VBSM) at low- and mid-IPC regimes. The generated data also show significantly richer intra-class diversity, as reflected by a notable drop in cosine similarity between features. We further analyze teacher selection strategies (pre- vs. intra-distillation) and introduce a scalable cross-class batch formation scheme for fast parallel synthesis. Code will be released after the review period.

</details>


### [395] [Towards Multiple Missing Values-resistant Unsupervised Graph Anomaly Detection](https://arxiv.org/abs/2511.09917)
*Jiazhen Chen,Xiuqin Liang,Sichao Fu,Zheng Ma,Weihua Ou*

Main category: cs.LG

TL;DR: 该研究提出了一种名为M²V-UGAD的无监督图异常检测框架，用于处理包含缺失节点属性和/或图结构信息的不完整图数据，以克服现有方法在处理缺失数据时可能引入的偏差和交叉干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督图异常检测方法通常假设节点属性和结构信息完整，这在现实世界中难以满足。标准的数据补全方法可能会将异常节点误判为正常，引入偏差。同时，当节点属性和边信息同时缺失时，一个视图中的估计误差会污染另一个视图，导致交叉干扰，降低检测性能。

Method: 提出了一种名为M²V-UGAD的多重缺失值不敏感无监督图异常检测框架。该框架采用双通路编码器，分别独立重建缺失的节点属性和图结构，以防止视图间的误差传播。接着，在联合潜在空间中融合这两个通路并进行正则化，使得正常节点集中在内部流形，异常节点位于外部。此外，为了减少补全偏差，通过采样正常区域之外的潜在编码，并将其解码为真实的节点特征和子图，生成困难的负样本，以锐化决策边界。

Result: 在七个公开数据集上的实验表明，M²V-UGAD在不同缺失率下持续优于现有的无监督图异常检测方法。

Conclusion: M²V-UGAD 能够有效地处理不完整图数据，并在多种场景下优于现有方法，证明了其在处理缺失数据和减轻补全偏差方面的有效性。

Abstract: Unsupervised graph anomaly detection (GAD) has received increasing attention in recent years, which aims to identify data anomalous patterns utilizing only unlabeled node information from graph-structured data. However, prevailing unsupervised GAD methods typically presuppose complete node attributes and structure information, a condition hardly satisfied in real-world scenarios owing to privacy, collection errors or dynamic node arrivals. Existing standard imputation schemes risk "repairing" rare anomalous nodes so that they appear normal, thereby introducing imputation bias into the detection process. In addition, when both node attributes and edges are missing simultaneously, estimation errors in one view can contaminate the other, causing cross-view interference that further undermines the detection performance. To overcome these challenges, we propose M$^2$V-UGAD, a multiple missing values-resistant unsupervised GAD framework on incomplete graphs. Specifically, a dual-pathway encoder is first proposed to independently reconstruct missing node attributes and graph structure, thereby preventing errors in one view from propagating to the other. The two pathways are then fused and regularized in a joint latent space so that normals occupy a compact inner manifold while anomalies reside on an outer shell. Lastly, to mitigate imputation bias, we sample latent codes just outside the normal region and decode them into realistic node features and subgraphs, providing hard negative examples that sharpen the decision boundary. Experiments on seven public benchmarks demonstrate that M$^2$V-UGAD consistently outperforms existing unsupervised GAD methods across varying missing rates.

</details>


### [396] [MDMLP-EIA: Multi-domain Dynamic MLPs with Energy Invariant Attention for Time Series Forecasting](https://arxiv.org/abs/2511.09924)
*Hu Zhang,Zhien Dai,Zhaohui Tang,Yongfang Xie*

Main category: cs.LG

TL;DR: MDMLP-EIA通过创新的季节性信号处理、能量不变注意力机制和动态容量调整，解决了现有MLP在时间序列预测中的局限性，并在多个基准数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLP的时间序列预测方法在处理弱季节性信号、权重共享MLP容量限制和通道独立策略的通道融合方面存在局限性。

Method: 提出MDMLP-EIA，包括：1. 适应性融合双域季节性MLP，分离强弱季节性信号，并采用自适应零初始化通道融合策略。2. 能量不变注意力机制，自适应关注不同时间步的特征通道，并保持总信号能量不变。3. 动态容量调整机制，根据通道数平方根调整神经元数量，扩展MLP容量。

Result: 在九个基准数据集上进行了广泛的实验，MDMLP-EIA在预测准确性和计算效率方面均达到了最先进的性能。

Conclusion: MDMLP-EIA通过其创新的设计，显著提高了时间序列预测的准确性和效率，克服了现有MLP方法的关键挑战。

Abstract: Time series forecasting is essential across diverse domains. While MLP-based methods have gained attention for achieving Transformer-comparable performance with fewer parameters and better robustness, they face critical limitations including loss of weak seasonal signals, capacity constraints in weight-sharing MLPs, and insufficient channel fusion in channel-independent strategies. To address these challenges, we propose MDMLP-EIA (Multi-domain Dynamic MLPs with Energy Invariant Attention) with three key innovations. First, we develop an adaptive fused dual-domain seasonal MLP that categorizes seasonal signals into strong and weak components. It employs an adaptive zero-initialized channel fusion strategy to minimize noise interference while effectively integrating predictions. Second, we introduce an energy invariant attention mechanism that adaptively focuses on different feature channels within trend and seasonal predictions across time steps. This mechanism maintains constant total signal energy to align with the decomposition-prediction-reconstruction framework and enhance robustness against disturbances. Third, we propose a dynamic capacity adjustment mechanism for channel-independent MLPs. This mechanism scales neuron count with the square root of channel count, ensuring sufficient capacity as channels increase. Extensive experiments across nine benchmark datasets demonstrate that MDMLP-EIA achieves state-of-the-art performance in both prediction accuracy and computational efficiency.

</details>


### [397] [EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models](https://arxiv.org/abs/2511.09947)
*Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EEGAgent是一个利用大语言模型（LLMs）调度和规划多个工具以自动完成脑电图（EEG）相关任务的通用框架。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG模型通常针对特定任务进行定制，限制了它们在需要多任务和连续推理的现实场景中的应用。因此，需要一个能够进行可扩展和可泛化的脑活动分析的通用解决方案，以促进临床诊断和认知研究。

Method: EEGAgent通过设计一个包含EEG预处理、特征提取、事件检测等不同工具的工具箱，实现了EEG基本信息感知、时空探索、事件检测、用户交互和报告生成等功能。

Result: 在公共数据集上的评估表明，EEGAgent能够支持灵活且可解释的EEG分析。

Conclusion: EEGAgent展示了其在现实临床应用中的潜力。

Abstract: Scalable and generalizable analysis of brain activity is essential for advancing both clinical diagnostics and cognitive research. Electroencephalography (EEG), a non-invasive modality with high temporal resolution, has been widely used for brain states analysis. However, most existing EEG models are usually tailored for individual specific tasks, limiting their utility in realistic scenarios where EEG analysis often involves multi-task and continuous reasoning. In this work, we introduce EEGAgent, a general-purpose framework that leverages large language models (LLMs) to schedule and plan multiple tools to automatically complete EEG-related tasks. EEGAgent is capable of performing the key functions: EEG basic information perception, spatiotemporal EEG exploration, EEG event detection, interaction with users, and EEG report generation. To realize these capabilities, we design a toolbox composed of different tools for EEG preprocessing, feature extraction, event detection, etc. These capabilities were evaluated on public datasets, and our EEGAgent can support flexible and interpretable EEG analysis, highlighting its potential for real-world clinical applications.

</details>


### [398] [Autonomous Concept Drift Threshold Determination](https://arxiv.org/abs/2511.09953)
*Pengqian Lu,Jie Lu,Anjin Liu,En Yu,Guangquan Zhang*

Main category: cs.LG

TL;DR: 动态阈值在概念漂移检测中可以优于固定阈值，并且可以通过所提出的DTD算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有的漂移检测方法将检测阈值视为一个固定的超参数，这会影响模型性能。本研究旨在探索自适应阈值是否能提供更好的性能。

Method: 提出了一种动态阈值确定（DTD）算法，该算法结合了每个数据段的最佳阈值，并通过引入一个新颖的比较阶段来调整阈值。

Result: 在各种合成和真实世界的数据集（包括图像和表格数据）上进行的广泛实验表明，DTD算法能够显著提升最先进的漂移检测器的性能。

Conclusion: 证明了自适应阈值在概念漂移检测中优于固定阈值，并提出了一种名为DTD的算法来实现这一点，该算法在各种数据集上均显示出优越的性能。

Abstract: Existing drift detection methods focus on designing sensitive test statistics. They treat the detection threshold as a fixed hyperparameter, set once to balance false alarms and late detections, and applied uniformly across all datasets and over time. However, maintaining model performance is the key objective from the perspective of machine learning, and we observe that model performance is highly sensitive to this threshold. This observation inspires us to investigate whether a dynamic threshold could be provably better. In this paper, we prove that a threshold that adapts over time can outperform any single fixed threshold. The main idea of the proof is that a dynamic strategy, constructed by combining the best threshold from each individual data segment, is guaranteed to outperform any single threshold that apply to all segments. Based on the theorem, we propose a Dynamic Threshold Determination algorithm. It enhances existing drift detection frameworks with a novel comparison phase to inform how the threshold should be adjusted. Extensive experiments on a wide range of synthetic and real-world datasets, including both image and tabular data, validate that our approach substantially enhances the performance of state-of-the-art drift detectors.

</details>


### [399] [AI-Integrated Decision Support System for Real-Time Market Growth Forecasting and Multi-Source Content Diffusion Analytics](https://arxiv.org/abs/2511.09962)
*Ziqing Yin,Xuanjing Chen,Xi Zhang*

Main category: cs.LG

TL;DR: AIGC内容激增，本研究提出一个AI驱动的决策支持系统（DSS），利用GNN和Temporal Transformer模型预测内容传播和市场影响，实验结果优于现有基线。


<details>
  <summary>Details</summary>
Motivation: AIGC内容呈指数级增长，但其传播轨迹和市场影响难以预测，现有方法因数据异质性、非线性传播机制和不断变化的消费者互动而面临挑战。

Method: 提出一个AI驱动的决策支持系统（DSS），融合多源数据（社交媒体、营销支出、消费者互动、情绪动态），采用混合图神经网络（GNN）和时间Transformer框架。该模型通过双通道架构联合学习内容传播结构和时间影响演化，并利用因果推断模块分离营销刺激对投资回报率（ROI）和市场可见性的影响。

Result: 在Twitter、TikTok和YouTube广告等多个在线平台的真实世界大规模数据集上进行实验，结果表明该系统在所有六项指标上均优于现有基线。

Conclusion: 该DSS通过提供对AIGC驱动的内容传播和市场增长模式的可解释的实时见解，增强了营销决策。

Abstract: The rapid proliferation of AI-generated content (AIGC) has reshaped the dynamics of digital marketing and online consumer behavior. However, predicting the diffusion trajectory and market impact of such content remains challenging due to data heterogeneity, non linear propagation mechanisms, and evolving consumer interactions. This study proposes an AI driven Decision Support System (DSS) that integrates multi source data including social media streams, marketing expenditure records, consumer engagement logs, and sentiment dynamics using a hybrid Graph Neural Network (GNN) and Temporal Transformer framework. The model jointly learns the content diffusion structure and temporal influence evolution through a dual channel architecture, while causal inference modules disentangle the effects of marketing stimuli on return on investment (ROI) and market visibility. Experiments on large scale real-world datasets collected from multiple online platforms such as Twitter, TikTok, and YouTube advertising show that our system outperforms existing baselines in all six metrics. The proposed DSS enhances marketing decisions by providing interpretable real-time insights into AIGC driven content dissemination and market growth patterns.

</details>


### [400] [MultiTab: A Scalable Foundation for Multitask Learning on Tabular Data](https://arxiv.org/abs/2511.09970)
*Dimitrios Sinodinos,Jack Yi Wei,Narges Armanfard*

Main category: cs.LG

TL;DR: MultiTab-Net 是首个专为大型表格数据设计的Transformer多任务学习架构，通过新颖的多任务掩码注意力机制，在广泛的表格数据集上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有表格数据多任务学习方法主要局限于推荐系统，且多采用难以捕捉复杂特征交互的多层感知机，而Transformer架构在其他领域已证明其优势。因此，需要一种能处理大规模表格数据、捕捉复杂特征交互并克服任务竞争的多任务学习方法。

Method: 提出了一种名为MultiTab-Net的新型多任务Transformer架构，其核心是新颖的多任务掩码注意力机制，用于动态建模特征-特征依赖关系并缓解任务竞争。此外，还提出了MultiTab-Bench，一个可扩展的多任务合成数据集生成器。

Result: 在大型推荐数据、社会经济数据和物理学数据集上的大量实验表明，MultiTab-Net在各种任务数量、任务类型和特征模态下，始终比现有的多任务学习架构和单任务Transformer模型实现了更高的多任务增益。

Conclusion: MultiTab-Net 是一种有效的多任务Transformer架构，适用于大规模表格数据，并在广泛的基准测试中展现出优越的性能。MultiTab-Bench 为未来多任务学习的研究提供了系统性的评估工具。

Abstract: Tabular data is the most abundant data type in the world, powering systems in finance, healthcare, e-commerce, and beyond. As tabular datasets grow and span multiple related targets, there is an increasing need to exploit shared task information for improved multitask generalization. Multitask learning (MTL) has emerged as a powerful way to improve generalization and efficiency, yet most existing work focuses narrowly on large-scale recommendation systems, leaving its potential in broader tabular domains largely underexplored. Also, existing MTL approaches for tabular data predominantly rely on multi-layer perceptron-based backbones, which struggle to capture complex feature interactions and often fail to scale when data is abundant, a limitation that transformer architectures have overcome in other domains. Motivated by this, we introduce MultiTab-Net, the first multitask transformer architecture specifically designed for large tabular data. MultiTab-Net employs a novel multitask masked-attention mechanism that dynamically models feature-feature dependencies while mitigating task competition. Through extensive experiments, we show that MultiTab-Net consistently achieves higher multitask gain than existing MTL architectures and single-task transformers across diverse domains including large-scale recommendation data, census-like socioeconomic data, and physics datasets, spanning a wide range of task counts, task types, and feature modalities. In addition, we contribute MultiTab-Bench, a generalized multitask synthetic dataset generator that enables systematic evaluation of multitask dynamics by tuning task count, task correlations, and relative task complexity. Our code is publicly available at https://github.com/Armanfard-Lab/MultiTab.

</details>


### [401] [Rediscovering the Lunar Equation of the Centre with AI Feynman via Embedded Physical Biases](https://arxiv.org/abs/2511.09979)
*Saumya Shah,Zi-Yu Khoo,Abel Yang,Stéphane Bressan*

Main category: cs.LG

TL;DR: AI Feynman 算法成功从月球星历数据中重新发现天文学基本方程“中心方程”，但需要专家选择坐标系。为解决此问题，提出了一种自动预处理方法来寻找标准坐标系。结果表明，嵌入领域知识可以帮助符号回归发现物理定律，但也指出了在利用领域知识推导物理方程时存在的挑战。


<details>
  <summary>Details</summary>
Motivation: 探索使用 AI Feynman 符号回归算法自动发现天文学基本方程“中心方程”，并解决其在依赖专家选择坐标系方面的局限性。

Method: 通过引入物理启发式 AI Feynman 算法，并结合观测和归纳偏置（通过数据预处理和搜索空间限制），从月球星历数据中恢复“中心方程”。此外，提出了一种自动预处理方法来寻找标准坐标系。

Result: AI Feynman 算法成功从月球星历数据中恢复了“中心方程”的一阶解析形式。自动预处理方法能够找到标准坐标系。这些结果表明，嵌入领域知识可以使符号回归算法重新发现物理定律。

Conclusion: 虽然领域知识的嵌入有助于符号回归算法发现物理定律，但在利用领域知识通过定制偏置来约束符号回归推导物理方程方面，仍然存在挑战。

Abstract: This work explores using the physics-inspired AI Feynman symbolic regression algorithm to automatically rediscover a fundamental equation in astronomy -- the Equation of the Centre. Through the introduction of observational and inductive biases corresponding to the physical nature of the system through data preprocessing and search space restriction, AI Feynman was successful in recovering the first-order analytical form of this equation from lunar ephemerides data. However, this manual approach highlights a key limitation in its reliance on expert-driven coordinate system selection. We therefore propose an automated preprocessing extension to find the canonical coordinate system. Results demonstrate that targeted domain knowledge embedding enables symbolic regression to rediscover physical laws, but also highlight further challenges in constraining symbolic regression to derive physics equations when leveraging domain knowledge through tailored biases.

</details>


### [402] [Towards Robust Multimodal Learning in the Open World](https://arxiv.org/abs/2511.09989)
*Fushuo Huo*

Main category: cs.LG

TL;DR: 本研究旨在解决多模态学习在开放世界环境中鲁棒性不足的问题，以弥合受控实验表现与实际部署需求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前基于神经网络的多模态学习模型在开放世界环境中表现不佳，原因包括环境组成动态变化、模态输入不完整以及虚假分布关系，这些因素严重影响了系统的可靠性。然而，人类能够自然地适应这种动态和模糊的场景，而人工智能系统在这方面表现出明显的局限性。

Method: 本文研究开放世界设置下多模态学习鲁棒性的根本挑战。

Result: （摘要未提供具体实验结果）

Conclusion: （摘要未提供具体结论）

Abstract: The rapid evolution of machine learning has propelled neural networks to unprecedented success across diverse domains. In particular, multimodal learning has emerged as a transformative paradigm, leveraging complementary information from heterogeneous data streams (e.g., text, vision, audio) to advance contextual reasoning and intelligent decision-making. Despite these advancements, current neural network-based models often fall short in open-world environments characterized by inherent unpredictability, where unpredictable environmental composition dynamics, incomplete modality inputs, and spurious distributions relations critically undermine system reliability. While humans naturally adapt to such dynamic, ambiguous scenarios, artificial intelligence systems exhibit stark limitations in robustness, particularly when processing multimodal signals under real-world complexity. This study investigates the fundamental challenge of multimodal learning robustness in open-world settings, aiming to bridge the gap between controlled experimental performance and practical deployment requirements.

</details>


### [403] [Interaction as Interference: A Quantum-Inspired Aggregation Approach](https://arxiv.org/abs/2511.10018)
*Pilsung Kang*

Main category: cs.LG

TL;DR: 本研究提出了一种受量子启发的模型，通过“相干”和“非相干”聚合方式来模拟交互作用，并引入了“相干增益”和“干涉信息”作为诊断指标。


<details>
  <summary>Details</summary>
Motivation: 传统方法对交互作用的控制能力有限，本研究旨在提供一种新的视角来理解和控制交互作用中的协同和拮抗现象。

Method: 提出了一种基于量子力学玻恩法则的“相干聚合”方法，对复数幅值进行平方前求和，从而产生干涉交叉项；并与“非相干聚合”方法（先平方后求和）进行对比。在此基础上，开发了“干涉核分类器”（IKC），并引入“相干增益”和“干涉信息”两个诊断指标。

Result: 在最小线性幅度模型中，相干聚合的交叉项等同于标准潜在结果交互对比。IKC在合成数据（XOR）上表现优于基线模型，在真实数据集（Adult和Bank Marketing）上表现具有竞争力。实验证明，将聚合方式从非相干切换到相干，能够持续改善模型的负对数似然、Brier分数和校准误差，并显示出正的相干增益。

Conclusion: 受量子启发的相干聚合方法为控制交互作用提供了新的机制，IKC模型及其诊断指标在处理高交互作用数据方面显示出潜力。

Abstract: Classical approaches often treat interaction as engineered product terms or as emergent patterns in flexible models, offering little control over how synergy or antagonism arises. We take a quantum-inspired view: following the Born rule (probability as squared amplitude), \emph{coherent} aggregation sums complex amplitudes before squaring, creating an interference cross-term, whereas an \emph{incoherent} proxy sums squared magnitudes and removes it. In a minimal linear-amplitude model, this cross-term equals the standard potential-outcome interaction contrast \(Δ_{\mathrm{INT}}\) in a \(2\times 2\) factorial design, giving relative phase a direct, mechanism-level control over synergy versus antagonism.
  We instantiate this idea in a lightweight \emph{Interference Kernel Classifier} (IKC) and introduce two diagnostics: \emph{Coherent Gain} (log-likelihood gain of coherent over the incoherent proxy) and \emph{Interference Information} (the induced Kullback-Leibler gap). A controlled phase sweep recovers the identity. On a high-interaction synthetic task (XOR), IKC outperforms strong baselines under paired, budget-matched comparisons; on real tabular data (\emph{Adult} and \emph{Bank Marketing}) it is competitive overall but typically trails the most capacity-rich baseline in paired differences. Holding learned parameters fixed, toggling aggregation from incoherent to coherent consistently improves negative log-likelihood, Brier score, and expected calibration error, with positive Coherent Gain on both datasets.

</details>


### [404] [A Novel Data-Dependent Learning Paradigm for Large Hypothesis Classes](https://arxiv.org/abs/2511.09996)
*Alireza F. Pour,Shai Ben-David*

Main category: cs.LG

TL;DR: 当候选模型集过大，无法进行统一的经验损失收敛时，本文提出了一种新的学习范式，该范式更侧重于经验数据，并减少了对先验假设的依赖。该方法在相似性、聚类、Lipschitzness 和对比学习等假设下，均展现出了良好的泛化能力，且无需预先知道这些假设的真实参数。


<details>
  <summary>Details</summary>
Motivation: 在候选模型集过大的情况下，传统的经验损失统一收敛方法存在挑战，需要依赖 SRM（或正则化）学习算法。本文旨在提出一种新的学习范式，以解决这一问题，并减少对先验假设的依赖。

Method: 提出了一种新的学习范式，该范式能够更强地结合经验数据，并减少算法决策对先验假设的依赖。通过分析该方法在相似性、聚类、Lipschitzness 和对比学习等假设下的泛化能力来验证其优越性。

Result: 在相似性、聚类、Lipschitzness 和对比学习等多种常见学习假设下，该方法均表现出了良好的泛化能力，并且能够利用这些假设，而无需预先知道它们的真实参数。

Conclusion: 本文提出的新型学习范式在处理大规模候选模型集时，相比传统方法能更好地利用经验数据，并灵活适应各种学习假设，无需预先设定参数，展现了其在泛化能力上的优越性。

Abstract: We address the general task of learning with a set of candidate models that is too large to have a uniform convergence of empirical estimates to true losses. While the common approach to such challenges is SRM (or regularization) based learning algorithms, we propose a novel learning paradigm that relies on stronger incorporation of empirical data and requires less algorithmic decisions to be based on prior assumptions. We analyze the generalization capabilities of our approach and demonstrate its merits in several common learning assumptions, including similarity of close points, clustering of the domain into highly label-homogeneous regions, Lipschitzness assumptions of the labeling rule, and contrastive learning assumptions. Our approach allows utilizing such assumptions without the need to know their true parameters a priori.

</details>


### [405] [Improved Offline Reinforcement Learning via Quantum Metric Encoding](https://arxiv.org/abs/2511.10187)
*Outongyi Lv,Yewei Yuan,Nana Liu*

Main category: cs.LG

TL;DR: 通过引入量子度量编码器（QME）来解决离线强化学习（RL）中样本量有限的问题，QME将状态嵌入到更紧凑的表示中，并在三个数据集上使用SAC和IQL算法进行了验证，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在样本量有限的情况下性能通常不佳，需要新的方法来应对这一挑战。

Method: 提出量子度量编码器（QME），将状态嵌入到更紧凑、更有意义的表示中，该编码器的结构受到量子电路的启发。QME可以应用于经典数据（作为量子启发模块）和量子数据（直接在量子硬件上实现）。

Result: 在三个样本量限制为100个的数据集上，使用SAC和IQL算法进行评估。结果显示，在QME嵌入的状态上进行训练比在原始状态上训练能显著提高性能，SAC算法平均提高了116.2%，IQL算法平均提高了117.6%。

Conclusion: QME嵌入后的状态表现出低Δ-双曲性，这表明性能的提升源于QME引起的 الآخر状态空间的几何变化。这种低Δ-双曲性为开发高效的离线RL方法提供了有价值的信息。

Abstract: Reinforcement learning (RL) with limited samples is common in real-world applications. However, offline RL performance under this constraint is often suboptimal. We consider an alternative approach to dealing with limited samples by introducing the Quantum Metric Encoder (QME). In this methodology, instead of applying the RL framework directly on the original states and rewards, we embed the states into a more compact and meaningful representation, where the structure of the encoding is inspired by quantum circuits. For classical data, QME is a classically simulable, trainable unitary embedding and thus serves as a quantum-inspired module, on a classical device. For quantum data in the form of quantum states, QME can be implemented directly on quantum hardware, allowing for training without measurement or re-encoding.
  We evaluated QME on three datasets, each limited to 100 samples. We use Soft-Actor-Critic (SAC) and Implicit-Q-Learning (IQL), two well-known RL algorithms, to demonstrate the effectiveness of our approach. From the experimental results, we find that training offline RL agents on QME-embedded states with decoded rewards yields significantly better performance than training on the original states and rewards. On average across the three datasets, for maximum reward performance, we achieve a 116.2% improvement for SAC and 117.6% for IQL.
  We further investigate the $Δ$-hyperbolicity of our framework, a geometric property of the state space known to be important for the RL training efficacy. The QME-embedded states exhibit low $Δ$-hyperbolicity, suggesting that the improvement after embedding arises from the modified geometry of the state space induced by QME. Thus, the low $Δ$-hyperbolicity and the corresponding effectiveness of QME could provide valuable information for developing efficient offline RL methods under limited-sample conditions.

</details>


### [406] [DemoTuner: Efficient DBMS Knobs Tuning via LLM-Assisted Demonstration Reinforcement Learning](https://arxiv.org/abs/2511.09998)
*Hui Dou,Lei Jin,Yuxuan Zhou,Jiang He,Yiwen Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DemoTuner的框架，利用大型语言模型（LLM）从文本中提取的调优提示来改进基于强化学习（RL）的数据库管理系统（DBMS）配置调优方法，解决了现有RL方法收敛速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 手动调整DBMS性能调优旋钮耗时耗力，而现有的基于RL的方法在离线训练时收敛速度慢。因此，需要一种更有效的方法来自动调整DBMS旋钮。

Method: 该论文提出了一种名为DemoTuner的框架，该框架利用大型语言模型（LLM）从文本中提取调优提示，并采用一种名为HA-DDPGfD的新型LLM辅助演示强化学习方法来改进RL代理的训练。

Result: 实验结果表明，DemoTuner在MySQL和PostgreSQL上均显著优于DB-BERT、GPTuner和CDBTune等基线方法，能够提高性能并降低在线调优成本，同时对未知工作负载也表现出良好的适应性。

Conclusion: DemoTuner是第一个将演示强化学习算法应用于DBMS旋钮调优的框架，通过LLM提取的调优提示显著提高了RL方法的性能和效率。

Abstract: The performance of modern DBMSs such as MySQL and PostgreSQL heavily depends on the configuration of performance-critical knobs. Manual tuning these knobs is laborious and inefficient due to the complex and high-dimensional nature of the configuration space. Among the automated tuning methods, reinforcement learning (RL)-based methods have recently sought to improve the DBMS knobs tuning process from several different perspectives. However, they still encounter challenges with slow convergence speed during offline training. In this paper, we mainly focus on how to leverage the valuable tuning hints contained in various textual documents such as DBMS manuals and web forums to improve the offline training of RL-based methods. To this end, we propose an efficient DBMS knobs tuning framework named DemoTuner via a novel LLM-assisted demonstration reinforcement learning method. Specifically, to comprehensively and accurately mine tuning hints from documents, we design a structured chain of thought prompt to employ LLMs to conduct a condition-aware tuning hints extraction task. To effectively integrate the mined tuning hints into RL agent training, we propose a hint-aware demonstration reinforcement learning algorithm HA-DDPGfD in DemoTuner. As far as we know, DemoTuner is the first work to introduce the demonstration reinforcement learning algorithm for DBMS knobs tuning. Experimental evaluations conducted on MySQL and PostgreSQL across various workloads demonstrate the significant advantages of DemoTuner in both performance improvement and online tuning cost reduction over three representative baselines including DB-BERT, GPTuner and CDBTune. Additionally, DemoTuner also exhibits superior adaptability to application scenarios with unknown workloads.

</details>


### [407] [SVD-NO: Learning PDE Solution Operators with SVD Integral Kernels](https://arxiv.org/abs/2511.10025)
*Noam Koren,Ralf J. J. Mackenbach,Ruud J. G. van Sloun,Kira Radinsky,Daniel Freedman*

Main category: cs.LG

TL;DR: SVD-NO是一个新的神经算子，通过对核进行奇异值分解来学习偏微分方程的解算子，在五个基准方程上达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的基于傅里叶或图技术的神经算子在核积分算子的结构上做了强假设，这可能会限制其表达能力。

Method: SVD-NO显式地通过奇异值分解（SVD）参数化核，然后在低秩基中直接执行积分。它使用两个轻量级网络学习左右奇异函数，一个对角矩阵参数学习奇异值，一个Gram矩阵正则化器强制执行标准正交性。

Result: 在五个多样化的基准方程上的广泛评估中，SVD-NO实现了新的最先进水平，特别是在解高度空间变化的偏微分方程方面，性能提升尤为显著。

Conclusion: SVD-NO通过对核进行奇异值分解，在保持合理计算复杂度的同时，实现了高表达能力，并在求解偏微分方程方面取得了最先进的性能。

Abstract: Neural operators have emerged as a promising paradigm for learning solution operators of partial differential equa- tions (PDEs) directly from data. Existing methods, such as those based on Fourier or graph techniques, make strong as- sumptions about the structure of the kernel integral opera- tor, assumptions which may limit expressivity. We present SVD-NO, a neural operator that explicitly parameterizes the kernel by its singular-value decomposition (SVD) and then carries out the integral directly in the low-rank basis. Two lightweight networks learn the left and right singular func- tions, a diagonal parameter matrix learns the singular values, and a Gram-matrix regularizer enforces orthonormality. As SVD-NO approximates the full kernel, it obtains a high de- gree of expressivity. Furthermore, due to its low-rank struc- ture the computational complexity of applying the operator remains reasonable, leading to a practical system. In exten- sive evaluations on five diverse benchmark equations, SVD- NO achieves a new state of the art. In particular, SVD-NO provides greater performance gains on PDEs whose solutions are highly spatially variable. The code of this work is publicly available at https://github.com/2noamk/SVDNO.git.

</details>


### [408] [Temporal Latent Variable Structural Causal Model for Causal Discovery under External Interferences](https://arxiv.org/abs/2511.10031)
*Ruichu Cai,Xiaokai Huang,Wei Chen,Zijian Li,Zhifeng Hao*

Main category: cs.LG

TL;DR: 本研究提出一种新的时间潜在变量结构因果模型，用于在存在外部干扰的情况下推断因果关系，该模型能捕捉因果强度和邻接信息，并结合变分推断方法学习包含专家先验知识的参数，实验证明了该方法的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 从观测数据中推断因果关系是一项重要任务，但在数据受到各种外部干扰时，这项任务会变得充满挑战。这些干扰通常是外部因素对观测变量的附加影响。由于这些外部因素通常是未知的，研究引入潜在变量来表示这些影响观测数据的未观测因素。

Method: 提出一种新的时间潜在变量结构因果模型，结合了因果强度和邻接系数，以表示变量之间的因果关系。开发了一种基于变分推断的方法，将先验知识纳入参数学习，以指导模型估计。

Result: 实验结果表明，所提出的方法具有稳定性和准确性。

Conclusion: 所提出的时间潜在变量结构因果模型能够有效处理外部干扰，并在因果关系推断任务中表现出稳定性和准确性。通过结合专家先验知识，可以进一步提高模型的性能。

Abstract: Inferring causal relationships from observed data is an important task, yet it becomes challenging when the data is subject to various external interferences. Most of these interferences are the additional effects of external factors on observed variables. Since these external factors are often unknown, we introduce latent variables to represent these unobserved factors that affect the observed data. Specifically, to capture the causal strength and adjacency information, we propose a new temporal latent variable structural causal model, incorporating causal strength and adjacency coefficients that represent the causal relationships between variables. Considering that expert knowledge can provide information about unknown interferences in certain scenarios, we develop a method that facilitates the incorporation of prior knowledge into parameter learning based on Variational Inference, to guide the model estimation. Experimental results demonstrate the stability and accuracy of our proposed method.

</details>


### [409] [BuddyMoE: Exploiting Expert Redundancy to Accelerate Memory-Constrained Mixture-of-Experts Inference](https://arxiv.org/abs/2511.10054)
*Yun Wang,Lingyun Yang,Senhao Yu,Yixiao Wang,Ruixing Li,Zhixiang Wei,James Yen,Zhengwei Qi*

Main category: cs.LG

TL;DR: MoE模型虽能通过激活部分专家来提升效率，但模型整体规模过大导致超出GPU显存。现有CPU offload方案存在PCIe延迟，预取失败会加剧问题，导致模型精度下降或推理速度变慢。核心挑战在于如何在预取失败时同时保证推理速度和模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型规模庞大，超出GPU显存限制。CPU offload方案存在PCIe延迟，预取失败会显著增加推理延迟并影响模型精度。因此，需要一种在预取失败时仍能保持高推理速度和模型精度的解决方案。

Method: 文中提出了一种新的方法来解决MoE模型中预取失败的问题，旨在在保证模型精度的前提下，最小化预取失败带来的推理延迟。

Result: 通过实验验证了该方法在解决MoE模型预取失败问题上的有效性，并与其他现有方法进行了比较。

Conclusion: 该研究成功地解决了一个在MoE模型推理中存在的关键挑战，即在预取失败的情况下，如何同时保持高推理速度和模型精度。

Abstract: Mixture-of-Experts (MoE) architectures scale language models by activating only a subset of specialized expert networks for each input token, thereby reducing the number of floating-point operations. However, the growing size of modern MoE models causes their full parameter sets to exceed GPU memory capacity; for example, Mixtral-8x7B has 45 billion parameters and requires 87 GB of memory even though only 14 billion parameters are used per token. Existing systems alleviate this limitation by offloading inactive experts to CPU memory, but transferring experts across the PCIe interconnect incurs significant latency (about 10 ms). Prefetching heuristics aim to hide this latency by predicting which experts are needed, but prefetch failures introduce significant stalls and amplify inference latency. In the event of a prefetch failure, prior work offers two primary solutions: either fetch the expert on demand, which incurs a long stall due to the PCIe bottleneck, or drop the expert from the computation, which significantly degrades model accuracy. The critical challenge, therefore, is to maintain both high inference speed and model accuracy when prefetching fails.

</details>


### [410] [From Static Structures to Ensembles: Studying and Harnessing Protein Structure Tokenization](https://arxiv.org/abs/2511.10056)
*Zijing Liu,Bin Feng,He Cao,Yu Li*

Main category: cs.LG

TL;DR: 将蛋白质结构表示为离散标记，并利用“结构同义词”来模拟蛋白质灵活性。


<details>
  <summary>Details</summary>
Motivation: 了解蛋白质结构标记的性质，并开发一种模拟蛋白质动态的有效方法。

Method: 通过在语言模型中使用预训练的序列嵌入来弥合序列和结构之间的语义鸿沟，然后利用结构标记中的语义冗余，通过“同义词替换”策略生成构象集合。

Result: “同义词替换”方法能够准确地模拟蛋白质灵活性，并且在性能上可与最先进的模型相媲美。

Conclusion: 离散蛋白质结构表示具有语义冗余，可以有效地用于模拟蛋白质动态，并且“同义词替换”是一种计算成本低且强大的方法。

Abstract: Protein structure tokenization converts 3D structures into discrete or vectorized representations, enabling the integration of structural and sequence data. Despite many recent works on structure tokenization, the properties of the underlying discrete representations are not well understood. In this work, we first demonstrate that the successful utilization of structural tokens in a language model for structure prediction depends on using rich, pre-trained sequence embeddings to bridge the semantic gap between the sequence and structural "language". The analysis of the structural vocabulary itself then reveals significant semantic redundancy, where multiple distinct tokens correspond to nearly identical local geometries, acting as "structural synonyms". This redundancy, rather than being a flaw, can be exploited with a simple "synonym swap" strategy to generate diverse conformational ensembles by perturbing a predicted structure with its structural synonyms. This computationally lightweight method accurately recapitulates protein flexibility, performing competitively with state-of-the-art models. Our study provides fundamental insights into the nature of discrete protein structure representations and introduces a powerful, near-instantaneous method for modeling protein dynamics. Source code is available in https://github.com/IDEA-XL/TokenMD.

</details>


### [411] [FAQNAS: FLOPs-aware Hybrid Quantum Neural Architecture Search using Genetic Algorithm](https://arxiv.org/abs/2511.10062)
*Muhammad Kashif,Shaf Khalid,Alberto Marchisio,Nouhaila Innan,Muhammad Shafique*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 FAQNAS 的即插即用框架，用于混合量子神经网络（HQNN）的设计，该框架在优化准确性的同时，还能有效降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 由于量子计算机在嘈杂中等规模量子（NISQ）时代存在局限性，在经典模拟器上训练的混合量子神经网络（HQNN）的计算复杂性是衡量其性能的关键。该研究旨在解决在设计 HQNN 时如何在准确性和计算成本（以浮点运算次数 FLOPs 衡量）之间进行权衡的问题。

Method: FAQNAS 框架将 HQNN 的设计视为一个多目标优化问题，显式地将 FLOPs（包括量子 FLOPs 和经典 FLOPs）纳入优化目标，以平衡准确性和计算成本。

Result: 在五个基准数据集（MNIST、Digits、Wine、Breast Cancer 和 Iris）上的实验表明，量子 FLOPs 对准确性有显著影响，而经典 FLOPs 相对稳定。FAQNAS 发现的帕累托最优解表明，与忽略 FLOPs 的基线方法相比，可以在显著降低计算成本的同时获得具有竞争力的准确性。

Conclusion: 研究结果表明，在 NISQ 时代，FLOPs 感知是 HQNN 设计的一个实用标准，并且是未来 HQNN 系统可扩展的原则。

Abstract: Hybrid Quantum Neural Networks (HQNNs), which combine parameterized quantum circuits with classical neural layers, are emerging as promising models in the noisy intermediate-scale quantum (NISQ) era. While quantum circuits are not naturally measured in floating point operations (FLOPs), most HQNNs (in NISQ era) are still trained on classical simulators where FLOPs directly dictate runtime and scalability. Hence, FLOPs represent a practical and viable metric to measure the computational complexity of HQNNs. In this work, we introduce FAQNAS, a FLOPs-aware neural architecture search (NAS) framework that formulates HQNN design as a multi-objective optimization problem balancing accuracy and FLOPs. Unlike traditional approaches, FAQNAS explicitly incorporates FLOPs into the optimization objective, enabling the discovery of architectures that achieve strong performance while minimizing computational cost. Experiments on five benchmark datasets (MNIST, Digits, Wine, Breast Cancer, and Iris) show that quantum FLOPs dominate accuracy improvements, while classical FLOPs remain largely fixed. Pareto-optimal solutions reveal that competitive accuracy can often be achieved with significantly reduced computational cost compared to FLOPs-agnostic baselines. Our results establish FLOPs-awareness as a practical criterion for HQNN design in the NISQ era and as a scalable principle for future HQNN systems.

</details>


### [412] [Tree-Based Stochastic Optimization for Solving Large-Scale Urban Network Security Games](https://arxiv.org/abs/2511.10072)
*Shuxin Zhuang,Linjian Meng,Shuxin Li,Minming Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 在城市网络安全博弈（UNSGs）中，由于其巨大的组合动作空间，找到纳什均衡（NE）具有挑战性。本文提出了基于树的随机优化（TSO）框架，它使用基于树的动作表示来解决大型UNSGs中的动作空间表示问题，并引入样本和剪枝机制来提高解决方案的质量。实验结果表明TSO优于其他基线算法。


<details>
  <summary>Details</summary>
Motivation: 在大型城市网络安全博弈（UNSGs）中，由于动作空间巨大且具有组合性质，计算纳什均衡（NE）面临严峻挑战。现有的基于策略空间响应预言机（PSRO）的方法在计算精确的最佳响应（BR）时不可行，而使用强化学习近似BR会引入误差。此外，现有的非凸随机优化方法难以处理UNSGs中过大的动作空间，因为无法有效地用神经网络表示。因此，有必要开发一种新的方法来解决这些问题。

Method: 本文提出了一种名为基于树的随机优化（TSO）的框架。该框架采用基于树的动作表示，将整个动作空间映射到一个树结构上，解决了神经网络在无法枚举动作空间时表示动作的挑战，并从理论上证明了其等价于无偏损失函数。此外，还引入了一种样本和剪枝机制，以减少陷入次优局部最优解的风险。

Result: 通过大量的实验评估，结果表明TSO框架在解决UNSGs方面优于其他基线算法，证明了其有效性和优越性。

Conclusion: TSO框架通过引入基于树的动作表示和样本-剪枝机制，成功解决了大型城市网络安全博弈（UNSGs）中计算纳什均衡（NE）的挑战，并在实验中展现出优于现有算法的性能。

Abstract: Urban Network Security Games (UNSGs), which model the strategic allocation of limited security resources on city road networks, are critical for urban safety. However, finding a Nash Equilibrium (NE) in large-scale UNSGs is challenging due to their massive and combinatorial action spaces. One common approach to addressing these games is the Policy-Space Response Oracle (PSRO) framework, which requires computing best responses (BR) at each iteration. However, precisely computing exact BRs is impractical in large-scale games, and employing reinforcement learning to approximate BRs inevitably introduces errors, which limits the overall effectiveness of the PSRO methods. Recent advancements in leveraging non-convex stochastic optimization to approximate an NE offer a promising alternative to the burdensome BR computation. However, utilizing existing stochastic optimization techniques with an unbiased loss function for UNSGs remains challenging because the action spaces are too vast to be effectively represented by neural networks. To address these issues, we introduce Tree-based Stochastic Optimization (TSO), a framework that bridges the gap between the stochastic optimization paradigm for NE-finding and the demands of UNSGs. Specifically, we employ the tree-based action representation that maps the whole action space onto a tree structure, addressing the challenge faced by neural networks in representing actions when the action space cannot be enumerated. We then incorporate this representation into the loss function and theoretically demonstrate its equivalence to the unbiased loss function. To further enhance the quality of the converged solution, we introduce a sample-and-prune mechanism that reduces the risk of being trapped in suboptimal local optima. Extensive experimental results indicate the superiority of TSO over other baseline algorithms in addressing the UNSGs.

</details>


### [413] [eXIAA: eXplainable Injections for Adversarial Attack](https://arxiv.org/abs/2511.10088)
*Leonardo Pesce,Jiawen Wei,Gianmarco Mengaldo*

Main category: cs.LG

TL;DR: 提出一种新的黑盒模型无关的对抗性攻击方法，用于后验可解释人工智能（XAI），尤其是在图像领域。该攻击旨在修改原始解释，同时保持相同的预测类别，并且不被肉眼察觉。与以前的方法不同，该方法不需要访问模型或其权重，只需要访问模型计算出的预测和解释。此外，该攻击仅需一步即可完成，同时显著改变提供的解释。


<details>
  <summary>Details</summary>
Motivation: 后验可解释性方法旨在解释模型行为的原因，但可能存在漏洞。本研究旨在揭示当前可解释性方法的关键漏洞，并引发对其在安全关键应用中可靠性的担忧。

Method: 提出一种新的黑盒模型无关的对抗性攻击方法，该方法仅需要模型计算出的预测和解释，不需要访问模型或其权重。攻击在单步内完成，修改后的解释与原始解释有显著差异，但保持相同的预测类别，并且不会被肉眼察觉。该方法基于三种后验可解释性方法（显著图、积分梯度和DeepLIFT SHAP）为预训练的ResNet-18和ViT-B16在ImageNet上生成的解释。

Result: 实验结果表明，该攻击能够显著改变解释，而不会改变预测概率。使用平均绝对差计算解释的变化，并使用结构相似性度量（SSIM）验证原始图像和损坏图像的相似性，证明了攻击的有效性。

Conclusion: 本研究提出的低要求方法揭示了当前可解释性方法的关键漏洞，引发了对其在安全关键应用中可靠性的担忧。

Abstract: Post-hoc explainability methods are a subset of Machine Learning (ML) that aim to provide a reason for why a model behaves in a certain way. In this paper, we show a new black-box model-agnostic adversarial attack for post-hoc explainable Artificial Intelligence (XAI), particularly in the image domain. The goal of the attack is to modify the original explanations while being undetected by the human eye and maintain the same predicted class. In contrast to previous methods, we do not require any access to the model or its weights, but only to the model's computed predictions and explanations. Additionally, the attack is accomplished in a single step while significantly changing the provided explanations, as demonstrated by empirical evaluation. The low requirements of our method expose a critical vulnerability in current explainability methods, raising concerns about their reliability in safety-critical applications. We systematically generate attacks based on the explanations generated by post-hoc explainability methods (saliency maps, integrated gradients, and DeepLIFT SHAP) for pretrained ResNet-18 and ViT-B16 on ImageNet. The results show that our attacks could lead to dramatically different explanations without changing the predictive probabilities. We validate the effectiveness of our attack, compute the induced change based on the explanation with mean absolute difference, and verify the closeness of the original image and the corrupted one with the Structural Similarity Index Measure (SSIM).

</details>


### [414] [T2IBias: Uncovering Societal Bias Encoded in the Latent Space of Text-to-Image Generative Models](https://arxiv.org/abs/2511.10089)
*Abu Sufian,Cosimo Distante,Marco Leo,Hanan Salam*

Main category: cs.LG

TL;DR: 文本到图像生成模型（T2I）在AI应用中广泛使用，但可能复制和放大种族和性别刻板印象，引发伦理担忧。本研究调查了五种最流行的开源T2I模型，通过中性职业提示生成5000张图像，并由不同种族和性别的评估者进行评估。结果表明，所有模型都显著地将护理和 the role of women associated with those roles, while high-status professions are predominantly represented by white males. 研究还发现了特定模型的模式，例如 QWEN-Image 倾向于生成东亚人像，Kandinsky 模型倾向于生成白人像，SDXL 模型虽然分布更广但仍存在偏见。这些发现为AI项目经理和从业者提供了选择公平AI模型和定制提示的见解，以符合负责任AI的原则。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在调查最先进的文本到图像（T2I）生成模型是否系统地在其预训练的潜在空间中编码和放大了与种族和性别相关的社会偏见，以及这些偏见对AI伦理管理的影响。

Method: 本研究通过对五种最流行的开源T2I模型进行实证研究，使用十个中性、与职业相关的提示生成每种职业100张图像，构建了一个包含5000张图像的数据集。该数据集由代表不同种族和性别的多样化人工评估者进行评估。

Result: 研究结果表明，所有五个T2I模型都编码并放大了显著的社会偏见：护理和 the role of women associated with those roles roles consistently feminized，而公司CEO、政治家、医生和律师等高地位职业则绝大多数由男性和主要是白人个体代表。此外，研究还识别出特定模型的模式，例如 QWEN-Image 几乎只生成东亚人像，Kandinsky 模型主要生成白人像，SDXL 模型虽然输出分布相对较广但仍存在偏见。

Conclusion: 本研究证明了T2I模型中存在的显著种族和性别偏见，并强调了在部署这些模型时识别和减轻这些偏见的重要性。研究结果为AI项目经理和从业者提供了宝贵的见解，以选择更公平的AI模型和定制提示，从而构建负责任的生成式AI系统，并提出了减轻偏见的具体策略。

Abstract: Text-to-image (T2I) generative models are largely used in AI-powered real-world applications and value creation. However, their strategic deployment raises critical concerns for responsible AI management, particularly regarding the reproduction and amplification of race- and gender-related stereotypes that can undermine organizational ethics. In this work, we investigate whether such societal biases are systematically encoded within the pretrained latent spaces of state-of-the-art T2I models. We conduct an empirical study across the five most popular open-source models, using ten neutral, profession-related prompts to generate 100 images per profession, resulting in a dataset of 5,000 images evaluated by diverse human assessors representing different races and genders. We demonstrate that all five models encode and amplify pronounced societal skew: caregiving and nursing roles are consistently feminized, while high-status professions such as corporate CEO, politician, doctor, and lawyer are overwhelmingly represented by males and mostly White individuals. We further identify model-specific patterns, such as QWEN-Image's near-exclusive focus on East Asian outputs, Kandinsky's dominance of White individuals, and SDXL's comparatively broader but still biased distributions. These results provide critical insights for AI project managers and practitioners, enabling them to select equitable AI models and customized prompts that generate images in alignment with the principles of responsible AI. We conclude by discussing the risks of these biases and proposing actionable strategies for bias mitigation in building responsible GenAI systems.

</details>


### [415] [How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders](https://arxiv.org/abs/2511.10094)
*Yiming Tang,Abhijeet Sinha,Dianbo Liu*

Main category: cs.LG

TL;DR: 生成模型在遵循物理规律方面存在不足，现有评估方法无法检测和解释这些物理不合理错误。本文提出的 Matryoshka Transcoders 框架，通过在多粒度级别进行分层稀疏特征学习，并利用大型多模态模型进行解释，能够自动发现和解释物理不合理特征，无需手动特征工程，且效果优于现有方法。该框架还建立了评估物理合理性的基准，并分析了八种最先进的生成模型，为改进模型提供了见解。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在物理规律遵循方面存在不足，但现有评估方法无法检测和解释这些物理不合理错误，阻碍了模型的改进。需要一个自动发现和解释物理不合理特征的框架。

Method: 提出 Matryoshka Transcoders 框架，将 Matryoshka 表示学习范式扩展到 transcoder 架构，实现多粒度级别的分层稀疏特征学习。通过在物理合理性分类器的中间表示上进行训练，并利用大型多模态模型进行解释，自动发现和解释物理不合理特征。

Result: 与现有方法相比，实现了更高的特征相关性和特征准确性，发现了多样化的物理相关故障模式，并建立了评估物理合理性的基准。分析了八种最先进的生成模型，揭示了它们在遵循物理约束方面的失败方式。

Conclusion: Matryoshka Transcoders 框架能够自动发现和解释生成模型中的物理不合理特征，无需手动特征工程，并为评估和改进这些模型提供了新途径。

Abstract: Although recent generative models are remarkably capable of producing instruction-following and realistic outputs, they remain prone to notable physical plausibility failures. Though critical in applications, these physical plausibility errors often escape detection by existing evaluation methods. Furthermore, no framework exists for automatically identifying and interpreting specific physical error patterns in natural language, preventing targeted model improvements. We introduce Matryoshka Transcoders, a novel framework for the automatic discovery and interpretation of physical plausibility features in generative models. Our approach extends the Matryoshka representation learning paradigm to transcoder architectures, enabling hierarchical sparse feature learning at multiple granularity levels. By training on intermediate representations from a physical plausibility classifier and leveraging large multimodal models for interpretation, our method identifies diverse physics-related failure modes without manual feature engineering, achieving superior feature relevance and feature accuracy compared to existing approaches. We utilize the discovered visual patterns to establish a benchmark for evaluating physical plausibility in generative models. Our analysis of eight state-of-the-art generative models provides valuable insights into how these models fail to follow physical constraints, paving the way for further model improvements.

</details>


### [416] [RI-Loss: A Learnable Residual-Informed Loss for Time Series Forecasting](https://arxiv.org/abs/2511.10130)
*Jieting Wang,Xiaolei Shang,Feijiang Li,Furong Peng*

Main category: cs.LG

TL;DR: RI-Loss通过引入基于HSIC的目标函数来解决时间序列预测中的MSE局限性，能够更好地处理时间依赖性和数据噪声，并在多个基准测试中取得改进。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测方法（如Transformer和MLP）主要使用均方误差（MSE）进行优化，但MSE存在两个主要缺点：其逐点计算误差无法捕捉时间依赖性，并且没有考虑数据中的固有噪声。RI-Loss旨在克服这些局限性。

Method: RI-Loss是一个新颖的目标函数，基于希尔伯特-施密特独立性准则（HSIC）。它通过强制残差序列与随机时间序列之间的依赖性来显式地模拟噪声结构，从而实现更鲁棒、对噪声更敏感的表示。理论上，论文推导了第一个具有显式双样本复杂性项的非渐近HSIC界，并通过Bernstein型集中不等式和Rademacher复杂性分析实现了最优收敛率，为RI-Loss优化提供了严格的保证，并精确量化了核空间交互。

Result: 在八个真实世界基准测试和五种领先的预测模型上的实验表明，RI-Loss在预测性能上有所提高，验证了该方法的有效性。

Conclusion: RI-Loss作为一种新颖的目标函数，通过引入基于HSIC的噪声建模，克服了传统MSE的缺点，提高了时间序列预测的准确性和鲁棒性。理论分析和实证结果均支持其有效性。

Abstract: Time series forecasting relies on predicting future values from historical data, yet most state-of-the-art approaches-including transformer and multilayer perceptron-based models-optimize using Mean Squared Error (MSE), which has two fundamental weaknesses: its point-wise error computation fails to capture temporal relationships, and it does not account for inherent noise in the data. To overcome these limitations, we introduce the Residual-Informed Loss (RI-Loss), a novel objective function based on the Hilbert-Schmidt Independence Criterion (HSIC). RI-Loss explicitly models noise structure by enforcing dependence between the residual sequence and a random time series, enabling more robust, noise-aware representations. Theoretically, we derive the first non-asymptotic HSIC bound with explicit double-sample complexity terms, achieving optimal convergence rates through Bernstein-type concentration inequalities and Rademacher complexity analysis. This provides rigorous guarantees for RI-Loss optimization while precisely quantifying kernel space interactions. Empirically, experiments across eight real-world benchmarks and five leading forecasting models demonstrate improvements in predictive performance, validating the effectiveness of our approach. Code will be made publicly available to ensure reproducibility.

</details>


### [417] [EPO: Diverse and Realistic Protein Ensemble Generation via Energy Preference Optimization](https://arxiv.org/abs/2511.10165)
*Yuancheng Sun,Yuxuan Ren,Zhaoming Chen,Xu Han,Kang Liu,Qiwei Ye*

Main category: cs.LG

TL;DR: EPO是一种新的算法，可以更有效地生成蛋白质构象。它利用随机微分方程和能量排名机制，在不产生额外模拟轨迹的情况下，将预训练的生成器转变为能量感知采样器。该算法在多个基准测试中取得了最先进的成果，证明了仅凭能量信号就可以引导生成模型生成热力学一致的构象集合。


<details>
  <summary>Details</summary>
Motivation: 准确探索蛋白质构象集合对于揭示其功能至关重要，但分子动力学模拟计算成本高且容易陷入能量势垒，这使得准确探索蛋白质构象集合变得困难。

Method: EPO利用随机微分方程进行采样，并结合新颖的基于列表偏好优化的能量排名机制。它还引入了一个实际的上限，以有效近似连续时间生成模型中长采样轨迹的难以处理的概率，从而易于适应现有的预训练生成器。

Result: 在四肽、ATLAS和快速折叠基准测试中，EPO成功生成了多样化且物理上合理的集合，在九项评估指标上确立了新的最先进水平。

Conclusion: 这些结果表明，仅凭能量偏好信号就可以有效地引导生成模型生成热力学一致的构象集合，为长分子动力学模拟提供了一种替代方案，并拓宽了学习势在结构生物学和药物发现中的应用范围。

Abstract: Accurate exploration of protein conformational ensembles is essential for uncovering function but remains hard because molecular-dynamics (MD) simulations suffer from high computational costs and energy-barrier trapping. This paper presents Energy Preference Optimization (EPO), an online refinement algorithm that turns a pretrained protein ensemble generator into an energy-aware sampler without extra MD trajectories. Specifically, EPO leverages stochastic differential equation sampling to explore the conformational landscape and incorporates a novel energy-ranking mechanism based on list-wise preference optimization. Crucially, EPO introduces a practical upper bound to efficiently approximate the intractable probability of long sampling trajectories in continuous-time generative models, making it easily adaptable to existing pretrained generators. On Tetrapeptides, ATLAS, and Fast-Folding benchmarks, EPO successfully generates diverse and physically realistic ensembles, establishing a new state-of-the-art in nine evaluation metrics. These results demonstrate that energy-only preference signals can efficiently steer generative models toward thermodynamically consistent conformational ensembles, providing an alternative to long MD simulations and widening the applicability of learned potentials in structural biology and drug discovery.

</details>


### [418] [Towards Leveraging Sequential Structure in Animal Vocalizations](https://arxiv.org/abs/2511.10190)
*Eklavya Sarkar,Mathew Magimai. -Doss*

Main category: cs.LG

TL;DR: 本研究提出使用离散声学标记序列来分析动物叫声的顺序结构，并取得了初步成效。


<details>
  <summary>Details</summary>
Motivation: 现有的计算生物声学研究通常会忽略动物叫声中的时间顺序信息，而这些信息对通信至关重要。本研究旨在探索使用离散声学标记序列来捕捉和利用这些时间信息。

Method: 本研究利用向量量化和Gumbel-Softmax向量量化从自监督语音模型（HuBERT）的表示中提取离散声学标记序列。然后，通过成对距离分析和基于Levenshtein距离的k-NN分类实验来评估这些序列在区分叫声类型和发声者方面的能力。

Result: 研究结果表明，提取的声学标记序列能够区分不同叫声类型和发声者，并且在分类任务中取得了可观的性能。

Conclusion: 离散声学标记序列作为一种新的特征表示方法，能够有效地捕捉动物叫声中的时间顺序信息，为后续研究提供了有前景的方向。

Abstract: Animal vocalizations contain sequential structures that carry important communicative information, yet most computational bioacoustics studies average the extracted frame-level features across the temporal axis, discarding the order of the sub-units within a vocalization. This paper investigates whether discrete acoustic token sequences, derived through vector quantization and gumbel-softmax vector quantization of extracted self-supervised speech model representations can effectively capture and leverage temporal information. To that end, pairwise distance analysis of token sequences generated from HuBERT embeddings shows that they can discriminate call-types and callers across four bioacoustics datasets. Sequence classification experiments using $k$-Nearest Neighbour with Levenshtein distance show that the vector-quantized token sequences yield reasonable call-type and caller classification performances, and hold promise as alternative feature representations towards leveraging sequential information in animal vocalizations.

</details>


### [419] [Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2511.10200)
*Jieting Wang,Huimei Shi,Feijiang Li,Xiaolei Shang*

Main category: cs.LG

TL;DR: OCE-TS是一种新颖的时间序列预测方法，它使用序数交叉熵（OCE）损失代替传统的均方误差（MSE）损失，从而解决了现有模型在不确定性估计和异常值鲁棒性方面的不足。该方法通过将观测值离散化为有序区间并预测其概率分布来实现，并在多个数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的时间序列预测模型主要使用均方误差（MSE）损失函数，虽然可以直接预测数值，但无法提供不确定性估计，并且对异常值不够鲁棒。

Method: OCE-TS将时间序列值离散化为有序区间，并通过参数分布预测每个时间步的概率。然后，计算预测概率分布和真实概率分布之间的序数交叉熵（OCE）损失，以保持预测值之间的序数关系。它使用一个简单的线性模型来预测概率分布。

Result: 在七个公共时间序列数据集上的实证比较表明，OCE-TS在MSE和MAE指标上均优于Autoformer、DLinear、iTransformer、TimeXer和TimeBridge等五个基线模型。

Conclusion: OCE-TS通过使用OCE损失替代MSE损失，在预测准确性和鲁棒性方面均有所改进，并且能够量化预测的不确定性。理论分析表明，交叉熵损失比MSE损失更稳定且对异常值更鲁棒。

Abstract: Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis using influence functions, we establish that cross-entropy (CE) loss exhibits superior stability and outlier robustness compared to MSE loss. Empirically, we compared OCE-TS with five baseline models-Autoformer, DLinear, iTransformer, TimeXer, and TimeBridge-on seven public time series datasets. Using MSE and Mean Absolute Error (MAE) as evaluation metrics, the results demonstrate that OCE-TS consistently outperforms benchmark models. The code will be published.

</details>


### [420] [OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models](https://arxiv.org/abs/2511.10287)
*Yuping Yan,Yuhan Xie,Yuanshuai Li,Yingchao Yu,Lingjuan Lyu,Yaochu Jin*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Since Multimodal Large Language Models (MLLMs) are increasingly being integrated into everyday tools and intelligent agents, growing concerns have arisen regarding their possible output of unsafe contents, ranging from toxic language and biased imagery to privacy violations and harmful misinformation. Current safety benchmarks remain highly limited in both modality coverage and performance evaluations, often neglecting the extensive landscape of content safety. In this work, we introduce OutSafe-Bench, the first most comprehensive content safety evaluation test suite designed for the multimodal era. OutSafe-Bench includes a large-scale dataset that spans four modalities, featuring over 18,000 bilingual (Chinese and English) text prompts, 4,500 images, 450 audio clips and 450 videos, all systematically annotated across nine critical content risk categories. In addition to the dataset, we introduce a Multidimensional Cross Risk Score (MCRS), a novel metric designed to model and assess overlapping and correlated content risks across different categories. To ensure fair and robust evaluation, we propose FairScore, an explainable automated multi-reviewer weighted aggregation framework. FairScore selects top-performing models as adaptive juries, thereby mitigating biases from single-model judgments and enhancing overall evaluation reliability. Our evaluation of nine state-of-the-art MLLMs reveals persistent and substantial safety vulnerabilities, underscoring the pressing need for robust safeguards in MLLMs.

</details>


### [421] [Fractional neural attention for efficient multiscale sequence processing](https://arxiv.org/abs/2511.10208)
*Cheng Kevin Qu,Andrew Ly,Pulin Gong*

Main category: cs.LG

TL;DR: 引入一种受生物启发的、基于分数拉普拉斯算子的分数神经注意（FNA）机制，用于增强Transformer模型处理多尺度信息的能力，并在文本分类、图像处理和神经机器翻译等任务上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 理解和扩展自注意力机制的原理是推进人工智能的关键挑战，生物注意力机制的多尺度动力学和动力学系统理论提供了新的视角。

Method: 提出分数神经注意（FNA），该机制通过分数拉普拉斯算子控制的莱维扩散来模拟标记交互，从而内在实现跨多个尺度的同时短程和长程依赖。

Result: FNA在理论上展示了其动力学由分数扩散方程控制，注意力网络具有更大的谱隙和更短的路径长度，这些是计算效率增强的机制特征。在实践中，FNA在单层单头的情况下实现了具有竞争力的文本分类性能，并在图像处理和神经机器翻译中提高了性能。

Conclusion: FNA是一个连接自注意力、随机动力学和几何学的基本机制，为强大的、受神经科学启发的AI提供了可解释的、有生物学依据的基础。

Abstract: Attention mechanisms underpin the computational power of Transformer models, which have achieved remarkable success across diverse domains. Yet understanding and extending the principles underlying self-attention remains a key challenge for advancing artificial intelligence. Drawing inspiration from the multiscale dynamics of biological attention and from dynamical systems theory, we introduce Fractional Neural Attention (FNA), a principled, neuroscience-inspired framework for multiscale information processing. FNA models token interactions through Lévy diffusion governed by the fractional Laplacian, intrinsically realizing simultaneous short- and long-range dependencies across multiple scales. This mechanism yields greater expressivity and faster information mixing, advancing the foundational capacity of Transformers. Theoretically, we show that FNA's dynamics are governed by the fractional diffusion equation, and that the resulting attention networks exhibit larger spectral gaps and shorter path lengths -- mechanistic signatures of enhanced computational efficiency. Empirically, FNA achieves competitive text-classification performance even with a single layer and a single head; it also improves performance in image processing and neural machine translation. Finally, the diffusion map algorithm from geometric harmonics enables dimensionality reduction of FNA weights while preserving the intrinsic structure of embeddings and hidden states. Together, these results establish FNA as a principled mechanism connecting self-attention, stochastic dynamics, and geometry, providing an interpretable, biologically grounded foundation for powerful, neuroscience-inspired AI.

</details>


### [422] [Out-of-Context Misinformation Detection via Variational Domain-Invariant Learning with Test-Time Training](https://arxiv.org/abs/2511.10213)
*Xi Yang,Han Zhang,Zhijian Lin,Yibiao Hu,Hong Han*

Main category: cs.LG

TL;DR: 该研究提出了一种名为VDT的新方法，用于提高对非上下文误报（OOC）的检测能力，特别是在面对新的新闻领域时。VDT通过学习领域不变特征和利用测试时训练机制来增强模型的适应性，克服了现有方法在不同数据分布下表现不佳的问题。实验结果表明，VDT在NewsCLIPpings数据集的多数领域适应性设置下优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有针对非上下文误报（OOC）检测的方法在面对新的新闻领域时，由于训练和测试数据分布不同，模型性能会急剧下降。因此，需要一种能够增强模型领域适应性能力的方法。

Method: 提出VDT方法，包含领域不变变分对齐模块，用于学习领域不变特征；以及领域一致性约束模块，用于重构源域和目标域的潜在分布。在测试阶段，采用测试时训练策略和置信度-方差过滤模块，动态更新VAE编码器和分类器，以适应目标域分布。

Result: 在NewsCLIPpings数据集上的广泛实验表明，VDT在大多数领域适应性设置下，其性能优于现有最先进的方法。

Conclusion: VDT方法通过学习领域不变特征和利用测试时训练机制，有效提升了OOC误报检测在不同新闻领域下的适应性和检测性能。

Abstract: Out-of-context misinformation (OOC) is a low-cost form of misinformation in news reports, which refers to place authentic images into out-of-context or fabricated image-text pairings. This problem has attracted significant attention from researchers in recent years. Current methods focus on assessing image-text consistency or generating explanations. However, these approaches assume that the training and test data are drawn from the same distribution. When encountering novel news domains, models tend to perform poorly due to the lack of prior knowledge. To address this challenge, we propose \textbf{VDT} to enhance the domain adaptation capability for OOC misinformation detection by learning domain-invariant features and test-time training mechanisms. Domain-Invariant Variational Align module is employed to jointly encodes source and target domain data to learn a separable distributional space domain-invariant features. For preserving semantic integrity, we utilize domain consistency constraint module to reconstruct the source and target domain latent distribution. During testing phase, we adopt the test-time training strategy and confidence-variance filtering module to dynamically updating the VAE encoder and classifier, facilitating the model's adaptation to the target domain distribution. Extensive experiments conducted on the benchmark dataset NewsCLIPpings demonstrate that our method outperforms state-of-the-art baselines under most domain adaptation settings.

</details>


### [423] [AgentEvolver: Towards Efficient Self-Evolving Agent System](https://arxiv.org/abs/2511.10395)
*Yunpeng Zhai,Shuchang Tao,Cheng Chen,Anni Zou,Ziqian Chen,Qingxu Fu,Shinji Mai,Li Yu,Jiaji Deng,Zouying Cao,Zhaoyang Liu,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: AgentEvolver是一个利用LLM进行自主学习的系统，通过自我提问、自我导航和自我归因来提高学习效率和样本利用率。


<details>
  <summary>Details</summary>
Motivation: 现有自主Agent的开发成本高、效率低，需要手动构建数据集和大量的随机探索。

Method: AgentEvolver包含三个机制：自我提问（生成新任务）、自我导航（重用经验和混合策略引导）和自我归因（根据贡献度分配奖励）。

Result: AgentEvolver在探索效率、样本利用率和适应速度方面优于传统基于RL的基线。

Conclusion: AgentEvolver通过其创新的机制，实现了可扩展、成本效益高且持续改进的自主Agent学习。

Abstract: Autonomous agents powered by large language models (LLMs) have the potential to significantly enhance human productivity by reasoning, using tools, and executing complex tasks in diverse environments. However, current approaches to developing such agents remain costly and inefficient, as they typically require manually constructed task datasets and reinforcement learning (RL) pipelines with extensive random exploration. These limitations lead to prohibitively high data-construction costs, low exploration efficiency, and poor sample utilization. To address these challenges, we present AgentEvolver, a self-evolving agent system that leverages the semantic understanding and reasoning capabilities of LLMs to drive autonomous agent learning. AgentEvolver introduces three synergistic mechanisms: (i) self-questioning, which enables curiosity-driven task generation in novel environments, reducing dependence on handcrafted datasets; (ii) self-navigating, which improves exploration efficiency through experience reuse and hybrid policy guidance; and (iii) self-attributing, which enhances sample efficiency by assigning differentiated rewards to trajectory states and actions based on their contribution. By integrating these mechanisms into a unified framework, AgentEvolver enables scalable, cost-effective, and continual improvement of agent capabilities. Preliminary experiments indicate that AgentEvolver achieves more efficient exploration, better sample utilization, and faster adaptation compared to traditional RL-based baselines.

</details>


### [424] [FedCure: Mitigating Participation Bias in Semi-Asynchronous Federated Learning with Non-IID Data](https://arxiv.org/abs/2511.10227)
*Yue Chen,Jianfeng Lu,Shuqing Cao,Wei Wang,Gang Li,Guanghui Wen*

Main category: cs.LG

TL;DR: FedCure通过优化联盟构成和感知参与的调度来解决半异步联邦学习中的参与偏差问题，特别是在非IID数据和分层架构下。


<details>
  <summary>Details</summary>
Motivation: 现有的半异步联邦学习（SAFL）框架在处理由非IID数据和分层云-边-端架构引起的用户参与偏差方面存在不足。

Method: FedCure框架包含三个关键规则：1）基于偏好规则优化联盟构成，以最大化集体利益和理论稳定性；2）集成虚拟队列技术和贝叶斯估计的联盟动态进行调度，以提高效率和稳定性；3）基于估计的联盟动态优化客户端CPU频率，以提高计算效率并满足延迟要求。

Result: 实验结果表明，FedCure相比四种最先进的基线方法，准确率最高可提高5.1倍，每轮延迟的变异系数最低（0.0223），并且在各种场景下保持长期平衡。

Conclusion: FedCure能够有效缓解非IID数据和分层架构下的参与偏差问题，并在准确性和效率方面取得显著提升。

Abstract: While semi-asynchronous federated learning (SAFL) combines the efficiency of synchronous training with the flexibility of asynchronous updates, it inherently suffers from participation bias, which is further exacerbated by non-IID data distributions. More importantly, hierarchical architecture shifts participation from individual clients to client groups, thereby further intensifying this issue. Despite notable advancements in SAFL research, most existing works still focus on conventional cloud-end architectures while largely overlooking the critical impact of non-IID data on scheduling across the cloud-edge-client hierarchy. To tackle these challenges, we propose FedCure, an innovative semi-asynchronous Federated learning framework that leverages coalition construction and participation-aware scheduling to mitigate participation bias with non-IID data. Specifically, FedCure operates through three key rules: (1) a preference rule that optimizes coalition formation by maximizing collective benefits and establishing theoretically stable partitions to reduce non-IID-induced performance degradation; (2) a scheduling rule that integrates the virtual queue technique with Bayesian-estimated coalition dynamics, mitigating efficiency loss while ensuring mean rate stability; and (3) a resource allocation rule that enhances computational efficiency by optimizing client CPU frequencies based on estimated coalition dynamics while satisfying delay requirements. Comprehensive experiments on four real-world datasets demonstrate that FedCure improves accuracy by up to 5.1x compared with four state-of-the-art baselines, while significantly enhancing efficiency with the lowest coefficient of variation 0.0223 for per-round latency and maintaining long-term balance across diverse scenarios.

</details>


### [425] [Lost in Serialization: Invariance and Generalization of LLM Graph Reasoners](https://arxiv.org/abs/2511.10234)
*Daniel Herbst,Lea Karbeska,Divyanshu Kumar,Akanksha Ahuja,Fatemeh Gholamzadeh Nasrabadi,Fabrizio Frasca*

Main category: cs.LG

TL;DR: LLM驱动的图推理器在处理图数据时缺乏对称不变性，可能导致不同表示下的输出不一致。本研究分析了LLM对图表示变化的敏感性，并提出了结构分解和新的评估任务来衡量微调的影响，结果表明大型模型更鲁棒，而微调可能影响模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: LLM在图推理任务中缺乏对图表示对称性的内置不变性，导致在节点重索引、边重排序或格式改变时可能产生不同输出，引发了对鲁棒性的担忧。

Method: 通过系统性地分析LLM对图表示变化的敏感性，将图序列化分解为节点标签、边编码和语法三个因素，并评估LLM在基准测试套件中对这些因素变化的鲁棒性。此外，还提出了一套新的谱任务来评估微调后推理器的泛化能力。

Result: 实验结果表明，更大的（未微调）模型更具鲁棒性。微调可以降低对节点重标号的敏感性，但可能增加对结构和格式变化的敏感性，并且不能持续提高在未见任务上的性能。

Conclusion: LLM在图推理中的鲁棒性问题值得关注。虽然微调可以提高对某些变化的鲁棒性，但可能牺牲对其他变化的鲁棒性，并且对泛化能力的提升效果不确定。因此，在应用LLM进行图推理时，需要仔细考虑模型的选择和微调策略。

Abstract: While promising, graph reasoners based on Large Language Models (LLMs) lack built-in invariance to symmetries in graph representations. Operating on sequential graph serializations, LLMs can produce different outputs under node reindexing, edge reordering, or formatting changes, raising robustness concerns. We systematically analyze these effects, studying how fine-tuning impacts encoding sensitivity as well generalization on unseen tasks. We propose a principled decomposition of graph serializations into node labeling, edge encoding, and syntax, and evaluate LLM robustness to variations of each of these factors on a comprehensive benchmarking suite. We also contribute a novel set of spectral tasks to further assess generalization abilities of fine-tuned reasoners. Results show that larger (non-fine-tuned) models are more robust. Fine-tuning reduces sensitivity to node relabeling but may increase it to variations in structure and format, while it does not consistently improve performance on unseen tasks.

</details>


### [426] [Impact of Layer Norm on Memorization and Generalization in Transformers](https://arxiv.org/abs/2511.10566)
*Rishi Singhal,Jung-Eun Kim*

Main category: cs.LG

TL;DR: Layer Normalization (LayerNorm) 在 Pre-LayerNorm 和 Post-LayerNorm 变压器中对学习和记忆有不同的影响。在 Pre-LayerNorm 中，它稳定学习；在 Post-LayerNorm 中，它影响记忆。移除 LayerNorm 会加剧 Pre-LayerNorm 的记忆并破坏其学习稳定性，同时会减轻 Post-LayerNorm 的记忆。早期层的 LayerNorm 最为关键，其影响因模型架构而异。这些发现为理解 LayerNorm 在变压器中的作用提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 尽管 Pre-LayerNorm 变压器因其稳定的梯度流而成为首选，但 LayerNorm 对这两种架构的学习和记忆的影响尚不清楚。本研究旨在阐明 LayerNorm 在 Pre- 和 Post-LayerNorm 变压器中对记忆和学习的影响。

Method: 研究 LayerNorm 如何影响 Pre- 和 Post-LayerNorm 变压器的记忆和学习。通过移除 LayerNorm 参数并观察其对学习和记忆的影响来分析其作用。通过在 6 个视觉和语言数据集上的 13 个模型上进行实验来验证这些发现。

Result: 在 Pre-LayerNorm 变压器中，LayerNorm 是稳定学习的关键因素。在 Post-LayerNorm 变压器中，LayerNorm 影响记忆。移除 Pre-LayerNorm 模型中的 LayerNorm 参数会加剧记忆并破坏学习稳定性。移除 Post-LayerNorm 模型中的 LayerNorm 参数可以减轻记忆，并恢复真实标签。早期层的 LayerNorm 比中间/后期层更关键，并且其影响在 Pre- 和 Post-LayerNorm 模型之间存在差异。

Conclusion: LayerNorm 在 Pre-LayerNorm 变压器中对稳定学习至关重要，而在 Post-LayerNorm 变压器中则影响记忆。移除 LayerNorm 会对 Pre-LayerNorm 模型的学习和记忆产生负面影响，但会改善 Post-LayerNorm 模型的记忆。早期层的 LayerNorm 最为关键，其具体影响因模型架构而异。这些发现为了解 LayerNorm 在变压器中的作用提供了新的视角。

Abstract: Layer Normalization (LayerNorm) is one of the fundamental components in transformers that stabilizes training and improves optimization. In recent times, Pre-LayerNorm transformers have become the preferred choice over Post-LayerNorm transformers due to their stable gradient flow. However, the impact of LayerNorm on learning and memorization across these architectures remains unclear. In this work, we investigate how LayerNorm influences memorization and learning for Pre- and Post-LayerNorm transformers. We identify that LayerNorm serves as a key factor for stable learning in Pre-LayerNorm transformers, while in Post-LayerNorm transformers, it impacts memorization. Our analysis reveals that eliminating LayerNorm parameters in Pre-LayerNorm models exacerbates memorization and destabilizes learning, while in Post-LayerNorm models, it effectively mitigates memorization by restoring genuine labels. We further precisely identify that early layers LayerNorm are the most critical over middle/later layers and their influence varies across Pre and Post LayerNorm models. We have validated it through 13 models across 6 Vision and Language datasets. These insights shed new light on the role of LayerNorm in shaping memorization and learning in transformers.

</details>


### [427] [Heuristic Transformer: Belief Augmented In-Context Reinforcement Learning](https://arxiv.org/abs/2511.10251)
*Oliver Dippel,Alexei Lisitsa,Bei Peng*

Main category: cs.LG

TL;DR: Transformer 提出了一种名为 Heuristic Transformer (HT) 的方法，通过在 Transformer 的输入中加入奖励的信念分布，来改进基于 Transformer 的 in-context 强化学习，并在多个环境中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: In-context learning (ICL) for Transformers enables task adaptation without parameter updates in reinforcement learning. However, current ICL methods lack explicit reward representations. This work aims to improve decision-making in ICL by augmenting the in-context dataset with a belief distribution over rewards.

Method: The proposed Heuristic Transformer (HT) method augments the in-context dataset with a belief distribution over rewards. This distribution is learned using a variational auto-encoder (VAE) to represent the posterior distribution over rewards in a low-dimensional stochastic variable. This variable, along with the in-context dataset and query states, is used as a prompt for the transformer policy.

Result: HT was evaluated on the Darkroom, Miniworld, and MuJoCo environments. The results show that HT consistently outperforms comparable baselines in both effectiveness and generalization.

Conclusion: HT presents a promising direction for bridging the gap between belief-based augmentations and transformer-based decision-making in reinforcement learning, demonstrating improved performance through the incorporation of reward beliefs.

Abstract: Transformers have demonstrated exceptional in-context learning (ICL) capabilities, enabling applications across natural language processing, computer vision, and sequential decision-making. In reinforcement learning, ICL reframes learning as a supervised problem, facilitating task adaptation without parameter updates. Building on prior work leveraging transformers for sequential decision-making, we propose Heuristic Transformer (HT), an in-context reinforcement learning (ICRL) approach that augments the in-context dataset with a belief distribution over rewards to achieve better decision-making. Using a variational auto-encoder (VAE), a low-dimensional stochastic variable is learned to represent the posterior distribution over rewards, which is incorporated alongside an in-context dataset and query states as prompt to the transformer policy. We assess the performance of HT across the Darkroom, Miniworld, and MuJoCo environments, showing that it consistently surpasses comparable baselines in terms of both effectiveness and generalization. Our method presents a promising direction to bridge the gap between belief-based augmentations and transformer-based decision-making.

</details>


### [428] [Unitho: A Unified Multi-Task Framework for Computational Lithography](https://arxiv.org/abs/2511.10255)
*Qian Jin,Yumeng Liu,Yuqi Jiang,Qi Sun,Cheng Zhuo*

Main category: cs.LG

TL;DR: Unitho是一个统一的多任务大型视觉模型，用于计算光刻。它在大型工业光刻模拟数据集上进行训练，能够进行端到端的掩模生成、光刻模拟和规则违规检测，并且在性能上超越了学术基线。


<details>
  <summary>Details</summary>
Motivation: 计算光刻领域中，可靠、可泛化的数据基础对于实现大规模模型至关重要。然而，掩模生成、规则违规检测和布局优化等关键任务常常孤立处理，并且受到数据集稀疏和模型方法有限的阻碍。

Method: 提出了一种基于Transformer架构的统一多任务大型视觉模型Unitho，并在包含数十万个案例的大规模工业光刻模拟数据集上进行了训练。

Result: Unitho支持端到端的掩模生成、光刻模拟和规则违规检测。实验结果验证了其有效性和泛化能力，性能显著优于学术基线。

Conclusion: Unitho通过实现敏捷和高保真的光刻模拟，为构建智能EDA（电子设计自动化）的数据基础做出了贡献，其性能和泛化能力得到了实验验证。

Abstract: Reliable, generalizable data foundations are critical for enabling large-scale models in computational lithography. However, essential tasks-mask generation, rule violation detection, and layout optimization-are often handled in isolation, hindered by scarce datasets and limited modeling approaches. To address these challenges, we introduce Unitho, a unified multi-task large vision model built upon the Transformer architecture. Trained on a large-scale industrial lithography simulation dataset with hundreds of thousands of cases, Unitho supports end-to-end mask generation, lithography simulation, and rule violation detection. By enabling agile and high-fidelity lithography simulation, Unitho further facilitates the construction of robust data foundations for intelligent EDA. Experimental results validate its effectiveness and generalizability, with performance substantially surpassing academic baselines.

</details>


### [429] [Torch-Uncertainty: A Deep Learning Framework for Uncertainty Quantification](https://arxiv.org/abs/2511.10282)
*Adrien Lafage,Olivier Laurent,Firas Gabetni,Gianni Franchi*

Main category: cs.LG

TL;DR: Torch-Uncertainty是一个基于PyTorch和Lightning的框架，用于简化深度学习中的不确定性量化（UQ）方法的评估和整合。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在不确定性量化方面存在不足，限制了其在关键实际应用中的推广。目前缺乏一个统一的工具来评估和整合不同的UQ方法。

Method: 介绍了一个名为Torch-Uncertainty的PyTorch和Lightning框架，该框架旨在简化深度学习模型的不确定性量化（UQ）方法的训练和评估。通过该框架，可以方便地评估和整合各种UQ技术和指标。

Result: 在分类、分割和回归任务上，对多种UQ方法进行了全面的实验评估和基准测试。

Conclusion: Torch-Uncertainty框架为评估和整合深度学习中的不确定性量化技术提供了一个统一且易于使用的解决方案。

Abstract: Deep Neural Networks (DNNs) have demonstrated remarkable performance across various domains, including computer vision and natural language processing. However, they often struggle to accurately quantify the uncertainty of their predictions, limiting their broader adoption in critical real-world applications. Uncertainty Quantification (UQ) for Deep Learning seeks to address this challenge by providing methods to improve the reliability of uncertainty estimates. Although numerous techniques have been proposed, a unified tool offering a seamless workflow to evaluate and integrate these methods remains lacking. To bridge this gap, we introduce Torch-Uncertainty, a PyTorch and Lightning-based framework designed to streamline DNN training and evaluation with UQ techniques and metrics. In this paper, we outline the foundational principles of our library and present comprehensive experimental results that benchmark a diverse set of UQ methods across classification, segmentation, and regression tasks. Our library is available at https://github.com/ENSTA-U2IS-AI/Torch-Uncertainty

</details>


### [430] [PITE: Multi-Prototype Alignment for Individual Treatment Effect Estimation](https://arxiv.org/abs/2511.10320)
*Fuyuan Cao,Jiaxuan Zhang,Xiaoli Li*

Main category: cs.LG

TL;DR: PITE是一种新的端到端多原型对齐方法，用于从观察数据估计个体处理效应（ITE），通过捕捉局部结构和强制跨组对齐来解决混淆偏差和个体异质性问题，并在基准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的ITE估计方法在处理混淆偏差时，通常采用全局分布均衡，忽略了局部结构和个体异质性，导致ITE估计不准确。实例级对齐方法虽然考虑了异质性，但同样忽视了局部结构信息。

Method: 提出了一种端到端的多原型对齐方法（PITE），通过定义原型（聚类中心），进行实例到原型的匹配，并将匹配后的原型在潜在空间中进行对齐，以减少分布偏移并保留局部结构。

Result: PITE通过细粒度的原型级对齐，不仅减少了分布偏移，还保留了处理组和对照组的局部结构，为ITE估计提供了有意义的约束。在基准数据集上的大量评估表明，PITE的ITE估计比13种最先进的方法更准确、更鲁棒。

Conclusion: PITE通过有效捕捉局部结构和强制跨组对齐，能够实现更准确、更鲁棒的ITE估计，解决了现有方法在处理混淆偏差和个体异质性方面的不足。

Abstract: Estimating Individual Treatment Effects (ITE) from observational data is challenging due to confounding bias. Most studies tackle this bias by balancing distributions globally, but ignore individual heterogeneity and fail to capture the local structure that represents the natural clustering among individuals, which ultimately compromises ITE estimation. While instance-level alignment methods consider heterogeneity, they similarly overlook the local structure information. To address these issues, we propose an end-to-end Multi-\textbf{P}rototype alignment method for \textbf{ITE} estimation (\textbf{PITE}). PITE effectively captures local structure within groups and enforces cross-group alignment, thereby achieving robust ITE estimation. Specifically, we first define prototypes as cluster centroids based on similar individuals under the same treatment. To identify local similarity and the distribution consistency, we perform instance-to-prototype matching to assign individuals to the nearest prototype within groups, and design a multi-prototype alignment strategy to encourage the matched prototypes to be close across treatment arms in the latent space. PITE not only reduces distribution shift through fine-grained, prototype-level alignment, but also preserves the local structures of treated and control groups, which provides meaningful constraints for ITE estimation. Extensive evaluations on benchmark datasets demonstrate that PITE outperforms 13 state-of-the-art methods, achieving more accurate and robust ITE estimation.

</details>


### [431] [EDGC: Entropy-driven Dynamic Gradient Compression for Efficient LLM Training](https://arxiv.org/abs/2511.10333)
*Qingao Yi,Jiaang Duan,Hanwen Hu,Qin Hua,Haiyan Zhao,Shiyou Qian,Dingyu Yang,Jian Cao,Jinghua Tang,Yinghao Yu,Chenzhi Liao,Kangjin Wang,Liping Zhang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Training large language models (LLMs) poses significant challenges regarding computational resources and memory capacity. Although distributed training techniques help mitigate these issues, they still suffer from considerable communication overhead. Existing approaches primarily rely on static gradient compression to enhance communication efficiency; however, these methods neglect the dynamic nature of evolving gradients during training, leading to performance degradation. Accelerating LLM training via compression without sacrificing performance remains a challenge. In this paper, we propose an entropy-driven dynamic gradient compression framework called EDGC. The core concept is to adjust the compression rate during LLM training based on the evolving trends of gradient entropy, taking into account both compression efficiency and error. EDGC consists of three key components.First, it employs a down-sampling method to efficiently estimate gradient entropy, reducing computation overhead. Second, it establishes a theoretical model linking compression rate with gradient entropy, enabling more informed compression decisions. Lastly, a window-based adjustment mechanism dynamically adapts the compression rate across pipeline stages, improving communication efficiency and maintaining model performance. We implemented EDGC on a 32-NVIDIA-V100 cluster and a 64-NVIDIA-H100 cluster to train GPT2-2.5B and GPT2-12.1B, respectively. The results show that EDGC significantly reduces communication latency and training time by up to 46.45% and 16.13% while preserving LLM accuracy.

</details>


### [432] [Robust Decentralized Multi-armed Bandits: From Corruption-Resilience to Byzantine-Resilience](https://arxiv.org/abs/2511.10344)
*Zicheng Hu,Yuchen Wang,Cheng Chen*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DeMABAR的鲁棒算法，用于解决去中心化协同多智能体多臂老虎机（DeCMA2B）在面对各种对抗性攻击时的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有DeCMA2B方法容易受到对抗性攻击，需要更鲁棒的算法。

Method: 首先研究了具有对抗性腐败的DeCMA2B问题，并提出DeMABAR算法，确保个体后悔仅增加与腐败预算成比例的项。接着考虑了更现实的、仅攻击少数智能体的情况，并证明了DeMABAR算法的鲁棒性，几乎能完全消除对抗性攻击的影响，并能在拜占庭设置下（未知比例的智能体可能任意选择臂和通信错误信息）有效。

Result: DeMABAR算法在理论上确保了低后悔度，并能有效抵抗对抗性攻击，尤其是在拜占庭设置下。数值实验也验证了该方法的有效性。

Conclusion: DeMABAR算法是一种有效的去中心化协同多智能体多臂老虎机算法，对对抗性攻击具有鲁棒性。

Abstract: Decentralized cooperative multi-agent multi-armed bandits (DeCMA2B) considers how multiple agents collaborate in a decentralized multi-armed bandit setting. Though this problem has been extensively studied in previous work, most existing methods remain susceptible to various adversarial attacks. In this paper, we first study DeCMA2B with adversarial corruption, where an adversary can corrupt reward observations of all agents with a limited corruption budget. We propose a robust algorithm, called DeMABAR, which ensures that each agent's individual regret suffers only an additive term proportional to the corruption budget. Then we consider a more realistic scenario where the adversary can only attack a small number of agents. Our theoretical analysis shows that the DeMABAR algorithm can also almost completely eliminate the influence of adversarial attacks and is inherently robust in the Byzantine setting, where an unknown fraction of the agents can be Byzantine, i.e., may arbitrarily select arms and communicate wrong information. We also conduct numerical experiments to illustrate the robustness and effectiveness of the proposed method.

</details>


### [433] [Product distribution learning with imperfect advice](https://arxiv.org/abs/2511.10366)
*Arnab Bhattacharyya,Davin Choo,Philips George John,Themis Gouleakis*

Main category: cs.LG

TL;DR: 在已知一个产品分布Q的参数作为建议的情况下，我们找到了一种能够以更少的样本复杂度（~O(d^{1-η}/ε^2)）学习未知分布P（属于布尔超立方体上的产品分布）的算法，学习精度达到TV距离ε，且该算法在P和Q的均值向量p和q之间L1距离小于εd^{0.5-Ω(η)}时有效。


<details>
  <summary>Details</summary>
Motivation: 在从未知分布P中抽取i.i.d.样本以恢复接近P的分布参数的分布学习问题中，当P是布尔超立方体上的积分布时，已知需要Ω(d/ε^2)个样本才能在总变分（TV）距离ε内学习P。本研究旨在探讨在已知一个积分布Q的参数作为建议的情况下，是否能降低样本复杂度。

Method: 提出了一种有效的学习算法，该算法利用已知的积分布Q的参数作为建议。算法的样本复杂度为~O(d^{1-η}/ε^2)，学习精度为TV距离ε。该算法的有效性依赖于未知分布P和已知分布Q的均值向量p和q之间L1距离小于εd^{0.5-Ω(η)}。

Result: 我们提出了一种有效的算法，在给定未知分布P（属于布尔超立方体上的产品分布）的一个参数为Q的产品分布的建议时，可以在TV距离ε内学习P，样本复杂度为~O(d^{1-η}/ε^2)。该算法在P和Q的均值向量p和q之间的L1距离小于εd^{0.5-Ω(η)}时有效，并且事先不知道L1距离的界限。

Conclusion: 在分布学习问题中，利用已知分布Q的参数作为建议，可以显著降低对未知分布P的学习样本复杂度。当P和Q的均值向量之间的L1距离满足特定条件时，我们提出的算法能够以~O(d^{1-η}/ε^2)的样本复杂度在TV距离ε内学习P。这表明在某些条件下，先验信息可以有效地提高分布学习的效率。

Abstract: Given i.i.d.~samples from an unknown distribution $P$, the goal of distribution learning is to recover the parameters of a distribution that is close to $P$. When $P$ belongs to the class of product distributions on the Boolean hypercube $\{0,1\}^d$, it is known that $Ω(d/\varepsilon^2)$ samples are necessary to learn $P$ within total variation (TV) distance $\varepsilon$. We revisit this problem when the learner is also given as advice the parameters of a product distribution $Q$. We show that there is an efficient algorithm to learn $P$ within TV distance $\varepsilon$ that has sample complexity $\tilde{O}(d^{1-η}/\varepsilon^2)$, if $\|\mathbf{p} - \mathbf{q}\|_1 < \varepsilon d^{0.5 - Ω(η)}$. Here, $\mathbf{p}$ and $\mathbf{q}$ are the mean vectors of $P$ and $Q$ respectively, and no bound on $\|\mathbf{p} - \mathbf{q}\|_1$ is known to the algorithm a priori.

</details>


### [434] [Enhancing Kernel Power K-means: Scalable and Robust Clustering with Random Fourier Features and Possibilistic Method](https://arxiv.org/abs/2511.10392)
*Yixi Chen,Weixuan Liang,Tianrui Liu,Jun-Jie Huang,Ao Li,Xueling Zhu,Xinwang Liu*

Main category: cs.LG

TL;DR: RFF-KPKM and IP-RFF-MKPKM are proposed to address the limitations of KPKM, improving efficiency and robustness using random Fourier features and enhanced clustering methods, with theoretical guarantees and experimental validation on large-scale datasets.


<details>
  <summary>Details</summary>
Motivation: The limitations of Kernel Power k-means (KPKM), including its computational burden on large datasets and lack of robustness due to absent centroid-sample assignment learning, need to be addressed. The goal is to improve efficiency, robustness, and the ability to learn multiple kernels.

Method: The proposed RFF-KPKM method utilizes random Fourier features (RFF) to create efficient, low-dimensional feature maps, thus avoiding the need for a full kernel matrix. This is the first theoretical analysis of applying RFF to KPKM, providing an excess risk bound of $\mathcal{O}(\sqrt{k^3/n})$, strong consistency with membership values, and a relative error bound using RFFs. The improved possibilistic RFF-based multiple kernel power k-means (IP-RFF-MKPKM) further enhances scalability and refines cluster assignments by integrating possibilistic and fuzzy memberships.

Result: Experiments conducted on large-scale datasets show that the proposed RFF-KPKM and IP-RFF-MKPKM methods outperform existing state-of-the-art methods in terms of both clustering accuracy and efficiency.

Conclusion: RFF-KPKM and IP-RFF-MKPKM effectively overcome the limitations of KPKM by employing RFF for efficiency and improved clustering strategies for robustness, demonstrating superior performance on large datasets and providing theoretical guarantees.

Abstract: Kernel power $k$-means (KPKM) leverages a family of means to mitigate local minima issues in kernel $k$-means. However, KPKM faces two key limitations: (1) the computational burden of the full kernel matrix restricts its use on extensive data, and (2) the lack of authentic centroid-sample assignment learning reduces its noise robustness. To overcome these challenges, we propose RFF-KPKM, introducing the first approximation theory for applying random Fourier features (RFF) to KPKM. RFF-KPKM employs RFF to generate efficient, low-dimensional feature maps, bypassing the need for the whole kernel matrix. Crucially, we are the first to establish strong theoretical guarantees for this combination: (1) an excess risk bound of $\mathcal{O}(\sqrt{k^3/n})$, (2) strong consistency with membership values, and (3) a $(1+\varepsilon)$ relative error bound achievable using the RFF of dimension $\mathrm{poly}(\varepsilon^{-1}\log k)$. Furthermore, to improve robustness and the ability to learn multiple kernels, we propose IP-RFF-MKPKM, an improved possibilistic RFF-based multiple kernel power $k$-means. IP-RFF-MKPKM ensures the scalability of MKPKM via RFF and refines cluster assignments by combining the merits of the possibilistic membership and fuzzy membership. Experiments on large-scale datasets demonstrate the superior efficiency and clustering accuracy of the proposed methods compared to the state-of-the-art alternatives.

</details>


### [435] [Neuronal Fluctuations: Learning Rates vs Participating Neurons](https://arxiv.org/abs/2511.10435)
*Darsh Pareek,Umesh Kumar,Ruthu Rao,Ravi Janjam*

Main category: cs.LG

TL;DR: 学习率影响DNN参数波动，进而影响模型性能。


<details>
  <summary>Details</summary>
Motivation: DNN的性能依赖于其内部参数的波动，但学习率对这些波动的影响尚不明确。

Method: 通过使用不同的学习率训练模型，并分析参数波动与网络最终准确率的关系。

Result: 研究了不同学习率下权重和偏置波动的大小和特性，并分析了其与模型准确率的关系。

Conclusion: 建立了学习率、参数波动模式和模型性能之间的明确联系，加深了对超参数调整和深度学习机制的理解。

Abstract: Deep Neural Networks (DNNs) rely on inherent fluctuations in their internal parameters (weights and biases) to effectively navigate the complex optimization landscape and achieve robust performance. While these fluctuations are recognized as crucial for escaping local minima and improving generalization, their precise relationship with fundamental hyperparameters remains underexplored. A significant knowledge gap exists concerning how the learning rate, a critical parameter governing the training process, directly influences the dynamics of these neural fluctuations. This study systematically investigates the impact of varying learning rates on the magnitude and character of weight and bias fluctuations within a neural network. We trained a model using distinct learning rates and analyzed the corresponding parameter fluctuations in conjunction with the network's final accuracy. Our findings aim to establish a clear link between the learning rate's value, the resulting fluctuation patterns, and overall model performance. By doing so, we provide deeper insights into the optimization process, shedding light on how the learning rate mediates the crucial exploration-exploitation trade-off during training. This work contributes to a more nuanced understanding of hyperparameter tuning and the underlying mechanics of deep learning.

</details>


### [436] [Improving Perturbation-based Explanations by Understanding the Role of Uncertainty Calibration](https://arxiv.org/abs/2511.10439)
*Thomas Decker,Volker Tresp,Florian Buettner*

Main category: cs.LG

TL;DR: 模型在进行可解释性扰动时会产生不准确的概率估计，导致解释质量下降。ReCalX 通过重新校准模型来解决此问题，可提高解释的鲁棒性并识别重要的输入特征。


<details>
  <summary>Details</summary>
Motivation: 现有基于扰动的模型解释方法在扰动下模型行为未知，可靠性受到质疑。本文旨在研究不确定性校准与扰动解释之间的关系，并提出改进方法。

Method: 提出了一种名为 ReCalX 的新方法，用于在不改变模型预测结果的前提下，重新校准模型以获得更好的解释。通过理论证明和实证评估了 ReCalX 在减少扰动特定失准、提高解释鲁棒性以及识别全局重要输入特征方面的有效性。

Result: ReCalX 能够最有效地减少特定于扰动的失准，同时提高解释的鲁棒性，并能更好地识别全局重要的输入特征。实验证明了 ReCalX 在各种模型和数据集上的有效性。

Conclusion: 模型在扰动下的不确定性校准对于解释的可靠性至关重要。ReCalX 能够有效解决此问题，从而提高模型解释的质量和可信度。

Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of machine-learning models in practice. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models systematically produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines global and local explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved explanations while preserving their original predictions. Empirical evaluations across diverse models and datasets demonstrate that ReCalX consistently reduces perturbation-specific miscalibration most effectively while enhancing explanation robustness and the identification of globally important input features.

</details>


### [437] [Intrinsic Dimensionality as a Model-Free Measure of Class Imbalance](https://arxiv.org/abs/2511.10475)
*Çağrı Eser,Zeynep Sonat Baltacı,Emre Akbaş,Sinan Kalkan*

Main category: cs.LG

TL;DR: 本文提出使用数据内在维度（ID）作为一种易于计算、无模型的类别不平衡度量方法，并将其应用于类别不平衡的机器学习任务中，实验结果表明该方法优于传统的基于样本数量的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的类别不平衡度量方法（如类别样本数量）忽略了冗余样本和类别的学习难易程度差异。而一些复杂的度量方法（如训练损失和不确定性）又依赖于模型训练。本文旨在提出一种简单、无模型且能有效度量类别不平衡度的方法。

Method: 提出使用数据内在维度（ID）作为一种易于计算、无模型的类别不平衡度量方法，并将其应用于类别不平衡的机器学习任务中。

Result: 在五个不同数据集和多种不平衡比例的实验中，ID方法持续优于文献中使用的基于样本数量的重加权和重采样技术。将ID与样本数量相结合可以进一步提高性能。

Conclusion: 数据内在维度（ID）是一种有效的、无模型的类别不平衡度量方法，优于传统的基于样本数量的方法，并且与样本数量结合使用效果更佳。

Abstract: Imbalance in classification tasks is commonly quantified by the cardinalities of examples across classes. This, however, disregards the presence of redundant examples and inherent differences in the learning difficulties of classes. Alternatively, one can use complex measures such as training loss and uncertainty, which, however, depend on training a machine learning model. Our paper proposes using data Intrinsic Dimensionality (ID) as an easy-to-compute, model-free measure of imbalance that can be seamlessly incorporated into various imbalance mitigation methods. Our results across five different datasets with a diverse range of imbalance ratios show that ID consistently outperforms cardinality-based re-weighting and re-sampling techniques used in the literature. Moreover, we show that combining ID with cardinality can further improve performance. Code: https://github.com/cagries/IDIM.

</details>


### [438] [Panda: Test-Time Adaptation with Negative Data Augmentation](https://arxiv.org/abs/2511.10481)
*Ruxi Deng,Wenxuan Bao,Tianxin Wei,Jingrui He*

Main category: cs.LG

TL;DR: Panda是一种基于负数据增强（NDA）的测试时自适应（TTA）方法，通过打乱图像语义来减少预测偏差和计算开销，显著提高了预训练视觉语言模型在图像损坏下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应（TTA）方法虽然可以提高预训练视觉语言模型（VLM）在图像损坏下的零样本分类能力，但它们通常采用正数据增强（PDA），存在计算开销大和无法缓解预测偏差的问题。

Method: Panda方法首先通过打乱图像块的顺序来生成负增强样本，这些样本保留了与损坏相关的特征但消除了与物体相关的信号。然后，通过从原始图像特征中减去这些负样本的平均特征，有效地抑制了与损坏相关的成分，同时保留了与类别相关的关键信息。此外，Panda允许批处理内的样本共享增强，从而最大限度地减少了计算开销。

Result: 实验表明，Panda在性能上优于PDA方法，并且与多种TTA方法结合使用时，能够显著提升其鲁棒性。

Conclusion: Panda通过引入负数据增强（NDA），有效解决了现有TTA方法在图像损坏下的计算开销和预测偏差问题，能够显著提高VLM的鲁棒性，并能与其他TTA方法无缝集成以增强其性能。

Abstract: Pretrained VLMs exhibit strong zero-shot classification capabilities, but their predictions degrade significantly under common image corruptions. To improve robustness, many test-time adaptation (TTA) methods adopt positive data augmentation (PDA), which generates multiple views of each test sample to reduce prediction variance. However, these methods suffer from two key limitations. First, it introduces considerable computational overhead due to the large number of augmentations required per image. Second, it fails to mitigate prediction bias, where the model tends to predict certain classes disproportionately under corruption, as PDA operates on corrupted inputs and typically does not remove the corruption itself. To address these challenges, we propose Panda, a novel TTA method based on negative data augmentation (NDA). Unlike positive augmentations that preserve object semantics, Panda generates negative augmentations by disrupting semantic content. It divides images into patches and randomly assembles them from a shared patch pool. These negatively augmented images retain corruption-specific features while discarding object-relevant signals. We then subtract the mean feature of these negative samples from the original image feature, effectively suppressing corruption-related components while preserving class-relevant information. This mitigates prediction bias under distribution shifts. Panda allows augmentation to be shared across samples within a batch, resulting in minimal computational overhead. Panda can be seamlessly integrated into existing test-time adaptation frameworks and substantially improve their robustness. Our experiments indicate that Panda delivers superior performance compared to PDA methods, and a wide range of TTA methods exhibit significantly enhanced performance when integrated with Panda. Our code is available at https://github.com/ruxideng/Panda .

</details>


### [439] [Weak Relation Enforcement for Kinematic-Informed Long-Term Stock Prediction with Artificial Neural Networks](https://arxiv.org/abs/2511.10494)
*Stanislav Selitskiy*

Main category: cs.LG

TL;DR: 通过引入新的损失函数来改善神经网络在股票预测中的表现，特别是在处理波动性、异常值和分布外数据时。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列预测中的波动性、异常值和分布外数据问题，并避免不切实际的预测。

Method: 提出了一种新的损失函数，该函数不仅惩罚预测值与真实值之间的误差，还惩罚预测的下一个点与上一个点加上预测的速度之间的误差。该方法应用于多种神经网络架构，并在道琼斯指数的十五年数据上进行了测试。

Result: 在多种神经网络架构和激活函数上，该方法在处理分布外数据时表现出统计学上的显著改进，解决了自回归模型中可能存在的因数据拓扑被破坏而导致的归一化问题。

Conclusion: 所提出的损失函数通过弱化方式强制执行数据邻域邻近性（关系）的保持，有效解决了神经网络在长期股票预测中遇到的波动性、异常值和分布外数据等问题。

Abstract: We propose loss function week enforcement of the velocity relations between time-series points in the Kinematic-Informed artificial Neural Networks (KINN) for long-term stock prediction. Problems of the series volatility, Out-of-Distribution (OOD) test data, and outliers in training data are addressed by (Artificial Neural Networks) ANN's learning not only future points prediction but also by learning velocity relations between the points, such a way as avoiding unrealistic spurious predictions. The presented loss function penalizes not only errors between predictions and supervised label data, but also errors between the next point prediction and the previous point plus velocity prediction. The loss function is tested on the multiple popular and exotic AR ANN architectures, and around fifteen years of Dow Jones function demonstrated statistically meaningful improvement across the normalization-sensitive activation functions prone to spurious behaviour in the OOD data conditions. Results show that such architecture addresses the issue of the normalization in the auto-regressive models that break the data topology by weakly enforcing the data neighbourhood proximity (relation) preservation during the ANN transformation.

</details>


### [440] [Holonorm](https://arxiv.org/abs/2511.10504)
*Daryl Noupa Yongueng,Hamidou Tembine*

Main category: cs.LG

TL;DR: DyT中的Tanh作为LN的替代方案存在问题，提出Holonorm（hn）解决这些问题，hn保留了正交性、方向性和可逆性，并将向量映射到单位球内，提高了Transformer模型的稳定性，并且hn可以作为百分比，1-hn是其补集，便于模型评估。


<details>
  <summary>Details</summary>
Motivation: Tanh作为LN的替代方案存在正交性、线性和失真问题，需要更可靠的归一化方法。

Method: 提出Holonorm（hn），它具有残差连接和非线性，保留信号的正交性、方向性和可逆性，并将所有向量映射到单位球内，以防止激活爆炸并提高深度Transformer模型的稳定性。

Result: Holonorm被证明是Transformer归一化的一种新颖且有效的方法，它解决了Tanh的缺点，并提供了更好的稳定性和可理解性。

Conclusion: Holonorm是Transformer归一化的一个有前途的替代方案，它通过保持信号的固有属性并提供可解释的度量来提高模型的稳定性和性能。

Abstract: Normalization is a key point in transformer training . In Dynamic Tanh (DyT), the author demonstrated that Tanh can be used as an alternative layer normalization (LN) and confirmed the effectiveness of the idea. But Tanh itself faces orthogonality, linearity and distortion problems. Due to that, his proposition cannot be reliable. So we propose a Holonorm (hn) which has residual connections and nonlinearity. Holonorm is suitable for replacing Tanh in the context of normalization. Although the HoloNorm expression could be similar to the softsign function in dimension one, softsign is a componentwise function which is not good for tensors and vectors of great dimension. Holonorm preserves the orthogonality, the direction, the invertibility of the signal. Holonorm is also a suitable metric, maps all vectors into the open unit ball. This prevents exploding activations and improves stability in deep Transformer models. In this work, we have meticulously examined the normalization in transformers and say that Holonorm, a generalized form of softsign function suited as a normalization function first.Second, defined between 0 and 1 hn serves as a percentage, and $1 - \text{Holonorm}$ is its complement, making it better understandable in evaluating a model.

</details>


### [441] [Oya: Deep Learning for Accurate Global Precipitation Estimation](https://arxiv.org/abs/2511.10562)
*Emmanuel Asiedu Brempong,Mohammed Alewi Hassen,MohamedElfatih MohamedKhair,Vusumuzi Dube,Santiago Hincapie Potes,Olivia Graham,Amanie Brik,Amy McGovern,George Huffman,Jason Hickey*

Main category: cs.LG

TL;DR: Oya是一种新的实时卫星降水估算算法，利用可见光和红外（VIS-IR）观测，通过两阶段深度学习方法提高精度，特别是在陆地南部地区，并且优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 陆地南部地区准确的降水估算至关重要，但现有基于卫星的产品存在不足，尤其是在亚日时间尺度上。

Method: Oya采用两阶段深度学习方法，结合了两个U-Net模型，一个用于降水检测，另一个用于定量降水估算（QPE），并使用GPM CORRA v07数据进行训练，IMERG-Final进行预训练。

Result: Oya通过多颗地球静止（GEO）卫星实现了准全球覆盖，并在降水估算方面表现优于现有的区域和全球降水基线。

Conclusion: Oya算法为改进降水监测和预测提供了一个有前景的途径。

Abstract: Accurate precipitation estimation is critical for hydrological applications, especially in the Global South where ground-based observation networks are sparse and forecasting skill is limited. Existing satellite-based precipitation products often rely on the longwave infrared channel alone or are calibrated with data that can introduce significant errors, particularly at sub-daily timescales. This study introduces Oya, a novel real-time precipitation retrieval algorithm utilizing the full spectrum of visible and infrared (VIS-IR) observations from geostationary (GEO) satellites. Oya employs a two-stage deep learning approach, combining two U-Net models: one for precipitation detection and another for quantitative precipitation estimation (QPE), to address the inherent data imbalance between rain and no-rain events. The models are trained using high-resolution GPM Combined Radar-Radiometer Algorithm (CORRA) v07 data as ground truth and pre-trained on IMERG-Final retrievals to enhance robustness and mitigate overfitting due to the limited temporal sampling of CORRA. By leveraging multiple GEO satellites, Oya achieves quasi-global coverage and demonstrates superior performance compared to existing competitive regional and global precipitation baselines, offering a promising pathway to improved precipitation monitoring and forecasting.

</details>


### [442] [Semi-Unified Sparse Dictionary Learning with Learnable Top-K LISTA and FISTA Encoders](https://arxiv.org/abs/2511.10575)
*Fengsheng Lin,Shengyi Yan,Trac Duy Tran*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a semi-unified sparse dictionary learning framework that bridges the gap between classical sparse models and modern deep architectures. Specifically, the method integrates strict Top-$K$ LISTA and its convex FISTA-based variant (LISTAConv) into the discriminative LC-KSVD2 model, enabling co-evolution between the sparse encoder and the dictionary under supervised or unsupervised regimes. This unified design retains the interpretability of traditional sparse coding while benefiting from efficient, differentiable training.
  We further establish a PALM-style convergence analysis for the convex variant, ensuring theoretical stability under block alternation. Experimentally, our method achieves 95.6\% on CIFAR-10, 86.3\% on CIFAR-100, and 88.5\% on TinyImageNet with faster convergence and lower memory cost ($<$4GB GPU). The results confirm that the proposed LC-KSVD2 + LISTA/LISTAConv pipeline offers an interpretable and computationally efficient alternative for modern deep architectures.

</details>


### [443] [Tight Robustness Certification through the Convex Hull of $\ell_0$ Attacks](https://arxiv.org/abs/2511.10576)
*Yuval Shapira,Dana Drachsler-Cohen*

Main category: cs.LG

TL;DR: Few-pixel attacks can be verified by considering the convex hull of the L0-ball, which is efficiently bounded using a novel linear bound propagation method that improves scaling.


<details>
  <summary>Details</summary>
Motivation: Existing local robustness verifiers struggle with the non-convex L0-ball perturbation space used in few-pixel attacks. They rely on linear bound propagation designed for convex spaces like Lp-balls.

Method: The paper characterizes the convex hull of an L0-ball as the intersection of its bounding box and an asymmetrically scaled L1-like polytope. A new linear bound propagation method is proposed to precisely compute bounds over this convex hull.

Result: The proposed bound propagation method yields tighter bounds than existing methods (bounding box or L1-like polytope) and scales the state-of-the-art L0 verifier by 1.24x-7.07x (3.16x geometric mean) on challenging benchmarks.

Conclusion: The novel approach accurately bounds the convex hull of L0-balls, enabling more efficient and scalable verification of few-pixel attacks.

Abstract: Few-pixel attacks mislead a classifier by modifying a few pixels of an image. Their perturbation space is an $\ell_0$-ball, which is not convex, unlike $\ell_p$-balls for $p\geq1$. However, existing local robustness verifiers typically scale by relying on linear bound propagation, which captures convex perturbation spaces. We show that the convex hull of an $\ell_0$-ball is the intersection of its bounding box and an asymmetrically scaled $\ell_1$-like polytope. The volumes of the convex hull and this polytope are nearly equal as the input dimension increases. We then show a linear bound propagation that precisely computes bounds over the convex hull and is significantly tighter than bound propagations over the bounding box or our $\ell_1$-like polytope. This bound propagation scales the state-of-the-art $\ell_0$ verifier on its most challenging robustness benchmarks by 1.24x-7.07x, with a geometric mean of 3.16.

</details>


### [444] [Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs](https://arxiv.org/abs/2511.10590)
*Miles Wang-Henderson,Ben Kaufman,Edward Williams,Ryan Pederson,Matteo Rossi,Owen Howell,Carl Underkoffler,Narbe Mardirossian,John Parkhill*

Main category: cs.LG

TL;DR: 为了加速药物开发，研究人员利用了基于分子结构的大型基础模型，并结合了具有里程碑意义的认知神经网络（ENN）框架，以实现可扩展的结合亲和力概率替代模型，从而应用于批量贝叶斯优化（Batch BO）。


<details>
  <summary>Details</summary>
Motivation: 药物研发中的一个关键瓶颈是分子设计的批量合成和测试。为了加速这一过程，人们对利用生物分子基础模型作为替代模型产生了浓厚的兴趣。

Method: 通过认知神经网络（ENN）框架，在大型结构信息模型表征的基础上，获得可扩展的结合亲和力联合预测分布。本研究的关键在于探索先验网络在ENN中的重要性，以及如何在下游的Batch BO应用中通过在合成数据上进行预训练来提高性能。

Result: 通过在半合成基准测试中重新发现已知的有效EGFR抑制剂，以及在真实世界小分子库中发现有效的抑制剂，证明了该方法在高达5倍和10倍的更少迭代次数下的效用。

Conclusion: 该方法为大规模药物发现应用提供了一个有前景的解决方案，通过使用ENN和Batch BO，可以显著加速药物发现过程。

Abstract: Batched synthesis and testing of molecular designs is the key bottleneck of drug development. There has been great interest in leveraging biomolecular foundation models as surrogates to accelerate this process. In this work, we show how to obtain scalable probabilistic surrogates of binding affinity for use in Batch Bayesian Optimization (Batch BO). This demands parallel acquisition functions that hedge between designs and the ability to rapidly sample from a joint predictive density to approximate them. Through the framework of Epistemic Neural Networks (ENNs), we obtain scalable joint predictive distributions of binding affinity on top of representations taken from large structure-informed models. Key to this work is an investigation into the importance of prior networks in ENNs and how to pretrain them on synthetic data to improve downstream performance in Batch BO. Their utility is demonstrated by rediscovering known potent EGFR inhibitors on a semi-synthetic benchmark in up to 5x fewer iterations, as well as potent inhibitors from a real-world small-molecule library in up to 10x fewer iterations, offering a promising solution for large-scale drug discovery applications.

</details>


### [445] [Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem](https://arxiv.org/abs/2511.10619)
*Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma*

Main category: cs.LG

TL;DR: 本文提出了两种新的参数化多臂老虎机算法，旨在解决现有算法的悲观保证问题，并利用离线数据来学习近乎最优的算法。


<details>
  <summary>Details</summary>
Motivation: 多臂老虎机问题旨在解决在不确定性下的资源分配问题，例如技术研发、临床试验和超参数选择。

Method: 提出了两种新的参数化算法族。第一种算法族包含现有最优的随机算法，并证明了在满足特定凹度性质时，可以实现对k（老虎机臂的数量）的最佳依赖性。第二种算法族在行为良好的实例上保证识别最优臂，在行为不佳的实例上则恢复到最坏情况保证。

Result: 通过对老虎机奖励优化问题采取统计学习的视角，在无需验证假设是否满足的情况下，实现了更强的数据依赖性保证。

Conclusion: 本文提出的新算法能够在满足特定条件下提供比现有算法更优的性能，并且能够适应不同行为特性的实例。

Abstract: The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that increases monotonically with diminishing returns. A growing line of work has designed algorithms for improving bandits, albeit with somewhat pessimistic worst-case guarantees. Indeed, strong lower bounds of $Ω(k)$ and $Ω(\sqrt{k})$ multiplicative approximation factors are known for both deterministic and randomized algorithms (respectively) relative to the optimal arm, where $k$ is the number of bandit arms. In this work, we propose two new parameterized families of bandit algorithms and bound the sample complexity of learning the near-optimal algorithm from each family using offline data. The first family we define includes the optimal randomized algorithm from prior work. We show that an appropriately chosen algorithm from this family can achieve stronger guarantees, with optimal dependence on $k$, when the arm reward curves satisfy additional properties related to the strength of concavity. Our second family contains algorithms that both guarantee best-arm identification on well-behaved instances and revert to worst case guarantees on poorly-behaved instances. Taking a statistical learning perspective on the bandit rewards optimization problem, we achieve stronger data-dependent guarantees without the need for actually verifying whether the assumptions are satisfied.

</details>
