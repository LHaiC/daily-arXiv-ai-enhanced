<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 163]
- [cs.CL](#cs.CL) [Total: 68]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 35]
- [eess.SY](#eess.SY) [Total: 20]
- [quant-ph](#quant-ph) [Total: 67]
- [cs.LG](#cs.LG) [Total: 56]
- [cs.AR](#cs.AR) [Total: 6]
- [cs.GT](#cs.GT) [Total: 3]
- [eess.SP](#eess.SP) [Total: 23]
- [cs.RO](#cs.RO) [Total: 49]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.AI](#cs.AI) [Total: 49]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.SI](#cs.SI) [Total: 4]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.MA](#cs.MA) [Total: 6]
- [cs.DS](#cs.DS) [Total: 7]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 24]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.ET](#cs.ET) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Approximating Condorcet Ordering for Vector-valued Mathematical Morphology](https://arxiv.org/abs/2509.06577)
*Marcos Eduardo Valle,Santiago Velasco-Forero,Joao Batista Florindo,Gustavo Jesus Angulo*

Main category: cs.CV

TL;DR: 该论文提出了一种基于机器学习的向量排序方法，用于构建向量值图像的数学形态学算子，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在向量值图像（如彩色图像）的数学形态学处理中，缺乏统一的向量排序标准。本研究旨在解决这一问题。

Method: 提出了一种基于机器学习的方法，学习一种近似的Condorcet排序（一种基于投票的排序方法），以解决向量排序问题，并将其应用于定义向量值形态学算子。

Result: 初步的计算实验表明，学习到的降序映射能够有效地定义用于彩色图像的向量值形态学算子。

Conclusion: 本研究提出了一种有效的机器学习方法来学习向量排序，为向量值图像的数学形态学处理提供了新的解决方案。

Abstract: Mathematical morphology provides a nonlinear framework for image and spatial
data processing and analysis. Although there have been many successful
applications of mathematical morphology to vector-valued images, such as color
and hyperspectral images, there is still no consensus on the most suitable
vector ordering for constructing morphological operators. This paper addresses
this issue by examining a reduced ordering approximating the Condorcet ranking
derived from a set of vector orderings. Inspired by voting problems, the
Condorcet ordering ranks elements from most to least voted, with voters
representing different orderings. In this paper, we develop a machine learning
approach that learns a reduced ordering that approximates the Condorcet
ordering. Preliminary computational experiments confirm the effectiveness of
learning the reduced mapping to define vector-valued morphological operators
for color images.

</details>


### [2] [Application of discrete Ricci curvature in pruning randomly wired neural networks: A case study with chest x-ray classification of COVID-19](https://arxiv.org/abs/2509.05322)
*Pavithra Elumalai,Sudharsan Vijayaraghavan,Madhumita Mondal,Areejit Samal*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Randomly Wired Neural Networks (RWNNs) serve as a valuable testbed for
investigating the impact of network topology in deep learning by capturing how
different connectivity patterns impact both learning efficiency and model
performance. At the same time, they provide a natural framework for exploring
edge-centric network measures as tools for pruning and optimization. In this
study, we investigate three edge-centric network measures: Forman-Ricci
curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness
centrality (EBC), to compress RWNNs by selectively retaining important synapses
(or edges) while pruning the rest. As a baseline, RWNNs are trained for
COVID-19 chest x-ray image classification, aiming to reduce network complexity
while preserving performance in terms of accuracy, specificity, and
sensitivity. We extend prior work on pruning RWNN using ORC by incorporating
two additional edge-centric measures, FRC and EBC, across three network
generators: Erd\"{o}s-R\'{e}nyi (ER) model, Watts-Strogatz (WS) model, and
Barab\'{a}si-Albert (BA) model. We provide a comparative analysis of the
pruning performance of the three measures in terms of compression ratio and
theoretical speedup. A central focus of our study is to evaluate whether FRC,
which is computationally more efficient than ORC, can achieve comparable
pruning effectiveness. Along with performance evaluation, we further
investigate the structural properties of the pruned networks through modularity
and global efficiency, offering insights into the trade-off between modular
segregation and network efficiency in compressed RWNNs. Our results provide
initial evidence that FRC-based pruning can effectively simplify RWNNs,
offering significant computational advantages while maintaining performance
comparable to ORC.

</details>


### [3] [BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring](https://arxiv.org/abs/2509.06690)
*Usman Haider,Lukasz Szemet,Daniel Kelly,Vasileios Sergis,Andrew C. Daly,Karl Mason*

Main category: cs.CV

TL;DR: 该研究提出了一种轻量级的语义分割框架BioLite U-Net，用于实时监控3D生物打印过程，通过区分喷嘴、生物墨水和背景，提高了打印质量和生物活性。该框架在Raspberry Pi 4B上进行了评估，实现了高精度（mIoU 92.85%，Dice score 96.17%）和高效推理（335 ms/帧），计算量远小于现有模型，非常适合闭环生物打印系统。


<details>
  <summary>Details</summary>
Motivation: 在3D生物打印过程中，实时监控打印质量和生物活性是一个关键挑战，尤其是在图像数据有限和硬件资源受限的情况下。通过对挤出过程进行语义分割，区分喷嘴、挤出的生物墨水和背景，可以实现原位监控，这对于维持打印质量和生物活性至关重要。

Method: 研究人员构建了一个包含787张RGB图像的手动标注数据集，用于3D生物打印过程的语义分割。他们提出了一种名为BioLite U-Net的新型轻量级网络架构，该网络利用深度可分离卷积来减少计算量。模型在Raspberry Pi 4B上与基于MobileNetV2和MobileNetV3的基线模型进行了比较，评估指标包括平均交并比（mIoU）、Dice分数和像素准确度。

Result: BioLite U-Net在Raspberry Pi 4B上实现了92.85%的mIoU和96.17%的Dice分数，单帧推理时间为335毫秒，展现了近乎实时的性能。与MobileNet基线模型相比，BioLite U-Net的计算量减少了1300多倍，同时在分割精度、效率和可部署性方面取得了更好的平衡。

Conclusion: 提出的BioLite U-Net框架能够以高精度和高效率实时监控3D生物打印过程，其优越的性能和对计算资源的要求使其成为智能闭环生物打印系统的理想选择。

Abstract: Bioprinting is a rapidly advancing field that offers a transformative
approach to fabricating tissue and organ models through the precise deposition
of cell-laden bioinks. Ensuring the fidelity and consistency of printed
structures in real-time remains a core challenge, particularly under
constraints imposed by limited imaging data and resource-constrained embedded
hardware. Semantic segmentation of the extrusion process, differentiating
between nozzle, extruded bioink, and surrounding background, enables in situ
monitoring critical to maintaining print quality and biological viability. In
this work, we introduce a lightweight semantic segmentation framework tailored
for real-time bioprinting applications. We present a novel, manually annotated
dataset comprising 787 RGB images captured during the bioprinting process,
labeled across three classes: nozzle, bioink, and background. To achieve fast
and efficient inference suitable for integration with bioprinting systems, we
propose a BioLite U-Net architecture that leverages depthwise separable
convolutions to drastically reduce computational load without compromising
accuracy. Our model is benchmarked against MobileNetV2 and MobileNetV3-based
segmentation baselines using mean Intersection over Union (mIoU), Dice score,
and pixel accuracy. All models were evaluated on a Raspberry Pi 4B to assess
real-world feasibility. The proposed BioLite U-Net achieves an mIoU of 92.85%
and a Dice score of 96.17%, while being over 1300x smaller than
MobileNetV2-DeepLabV3+. On-device inference takes 335 ms per frame,
demonstrating near real-time capability. Compared to MobileNet baselines,
BioLite U-Net offers a superior tradeoff between segmentation accuracy,
efficiency, and deployability, making it highly suitable for intelligent,
closed-loop bioprinting systems.

</details>


### [4] [Label Smoothing++: Enhanced Label Regularization for Training Neural Networks](https://arxiv.org/abs/2509.05307)
*Sachin Chhabra,Hemanth Venkateswara,Baoxin Li*

Main category: cs.CV

TL;DR: 标签平滑++通过在保留目标类别的固定标签的同时，为非目标类别分配非零概率并考虑类别间的关系，来解决传统标签平滑中存在的弊端，从而提高模型的泛化能力并减少预测的置信度。


<details>
  <summary>Details</summary>
Motivation: 在训练神经网络时，使用单一的热门目标标签会导致模型过于自信和过拟合。传统的标签平滑方法虽然能改善模型的泛化能力，但它会平等地对待所有非目标类别，破坏了类别间的关系。

Method: 提出了一种名为标签平滑++（Label Smoothing++）的新型标签正则化训练策略。该策略在保留目标类别固定标签的同时，为非目标类别分配非零概率，并利用类别间的关系来指导学习。

Result: 通过在多个数据集上进行的大量实验证明，标签平滑++能够有效减轻模型预测的过度自信问题，同时促进类别间的关系和模型的泛化能力。

Conclusion: 标签平滑++是一种有效的标签正则化训练策略，它在解决传统标签平滑缺点的基础上，进一步提高了模型的性能。

Abstract: Training neural networks with one-hot target labels often results in
overconfidence and overfitting. Label smoothing addresses this issue by
perturbing the one-hot target labels by adding a uniform probability vector to
create a regularized label. Although label smoothing improves the network's
generalization ability, it assigns equal importance to all the non-target
classes, which destroys the inter-class relationships. In this paper, we
propose a novel label regularization training strategy called Label
Smoothing++, which assigns non-zero probabilities to non-target classes and
accounts for their inter-class relationships. Our approach uses a fixed label
for the target class while enabling the network to learn the labels associated
with non-target classes. Through extensive experiments on multiple datasets, we
demonstrate how Label Smoothing++ mitigates overconfident predictions while
promoting inter-class relationships and generalization capabilities.

</details>


### [5] [InterAct: A Large-Scale Dataset of Dynamic, Expressive and Interactive Activities between Two People in Daily Scenarios](https://arxiv.org/abs/2509.05747)
*Leo Ho,Yinghao Huang,Dafei Qin,Mingyi Shi,Wangpok Tse,Wei Liu,Junichi Yamagishi,Taku Komura*

Main category: cs.CV

TL;DR: 本篇论文提出了InterAct数据集和一个基于扩散模型的方法，用于捕捉和生成双人交互的动态、语义一致的全身姿态和面部表情。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉双人交互行为时存在局限，通常只考虑单人或仅关注对话手势，且假设身体姿态变化不大。本研究旨在解决此问题，实现对双人目标驱动、动态、语义一致的长时间交互行为的建模。

Method: 构建了一个名为InterAct的多模态数据集，包含241个双人交互的运动序列，时长超过一分钟，涵盖了语音、身体动作和面部表情。在此基础上，提出了一种基于扩散模型的方法，从语音输入估计双人交互的面部表情和身体动作，该方法采用分层方式回归身体动作，并提出了一种新颖的微调机制来提高唇部表情的准确性。

Result: InterAct数据集包含了丰富多样的个体运动和新颖的、相对长期的交互模式。所提出的扩散模型方法能够有效地估计双人交互的身体动作和面部表情。

Conclusion: 本研究通过构建InterAct数据集和提出一种新的扩散模型方法，为双人交互行为的捕捉和生成提供了新的解决方案，并有望促进相关领域的研究。

Abstract: We address the problem of accurate capture of interactive behaviors between
two people in daily scenarios. Most previous works either only consider one
person or solely focus on conversational gestures of two people, assuming the
body orientation and/or position of each actor are constant or barely change
over each interaction. In contrast, we propose to simultaneously model two
people's activities, and target objective-driven, dynamic, and semantically
consistent interactions which often span longer duration and cover bigger
space. To this end, we capture a new multi-modal dataset dubbed InterAct, which
is composed of 241 motion sequences where two people perform a realistic and
coherent scenario for one minute or longer over a complete interaction. For
each sequence, two actors are assigned different roles and emotion labels, and
collaborate to finish one task or conduct a common interaction activity. The
audios, body motions, and facial expressions of both persons are captured.
InterAct contains diverse and complex motions of individuals and interesting
and relatively long-term interaction patterns barely seen before. We also
demonstrate a simple yet effective diffusion-based method that estimates
interactive face expressions and body motions of two people from speech inputs.
Our method regresses the body motions in a hierarchical manner, and we also
propose a novel fine-tuning mechanism to improve the lip accuracy of facial
expressions. To facilitate further research, the data and code is made
available at https://hku-cg.github.io/interact/ .

</details>


### [6] [VILOD: A Visual Interactive Labeling Tool for Object Detection](https://arxiv.org/abs/2509.05317)
*Isac Holm*

Main category: cs.CV

TL;DR: VILOD是一个用于对象检测（OD）的视觉交互式标注工具，通过集成t-SNE投影、不确定性热图和模型状态视图，增强了人类在环（HITL）标注流程的透明度和可管理性，并实现了与自动化不确定性采样相当的OD性能。


<details>
  <summary>Details</summary>
Motivation: 传统的对象检测（OD）深度学习（DL）方法需要耗时且昂贵的标注数据。主动学习（AL）虽然能减少标注工作，但缺乏透明度，限制了专家见解，并可能错过非最优样本。为了解决这些问题，需要一种集成人类智能和直觉的、更透明、更易于管理且可能更有效的方法。

Method: 提出并实现了一个名为“VILOD：用于对象检测的视觉交互式标注工具”的系统。该工具集成了t-SNE投影、不确定性热图和模型状态视图等组件，使用户能够探索数据，解释模型状态、AL建议，并在OD的迭代HITL工作流中实施不同的样本选择策略。

Result: 通过对比用例进行的实证研究表明，VILOD的交互式可视化提高了模型状态和数据集特征的可解释性，从而促进了不同标注策略的实施（RQ1）。研究还发现，在VILOD中采用的、由视觉引导的标注策略，在OD性能轨迹方面与自动不确定性采样AL基线相当（RQ2）。

Conclusion: VILOD为OD标注提供了一个新颖的工具，并通过实证研究提供了关于如何使HITL-AL工作流更加透明、易于管理和可能更有效的见解。

Abstract: The advancement of Object Detection (OD) using Deep Learning (DL) is often
hindered by the significant challenge of acquiring large, accurately labeled
datasets, a process that is time-consuming and expensive. While techniques like
Active Learning (AL) can reduce annotation effort by intelligently querying
informative samples, they often lack transparency, limit the strategic insight
of human experts, and may overlook informative samples not aligned with an
employed query strategy. To mitigate these issues, Human-in-the-Loop (HITL)
approaches integrating human intelligence and intuition throughout the machine
learning life-cycle have gained traction. Leveraging Visual Analytics (VA),
effective interfaces can be created to facilitate this human-AI collaboration.
This thesis explores the intersection of these fields by developing and
investigating "VILOD: A Visual Interactive Labeling tool for Object Detection".
VILOD utilizes components such as a t-SNE projection of image features,
together with uncertainty heatmaps and model state views. Enabling users to
explore data, interpret model states, AL suggestions, and implement diverse
sample selection strategies within an iterative HITL workflow for OD. An
empirical investigation using comparative use cases demonstrated how VILOD,
through its interactive visualizations, facilitates the implementation of
distinct labeling strategies by making the model's state and dataset
characteristics more interpretable (RQ1). The study showed that different
visually-guided labeling strategies employed within VILOD result in competitive
OD performance trajectories compared to an automated uncertainty sampling AL
baseline (RQ2). This work contributes a novel tool and empirical insight into
making the HITL-AL workflow for OD annotation more transparent, manageable, and
potentially more effective.

</details>


### [7] [Context-Aware Knowledge Distillation with Adaptive Weighting for Image Classification](https://arxiv.org/abs/2509.05319)
*Zhengda Li*

Main category: cs.CV

TL;DR: AKD框架通过学习超参数alpha来动态调整硬标签和软标签损失的权重，并引入CAM模块自适应地重新加权教师输出，从而在CIFAR-10数据集上实现了比固定权重KD更好的准确率和更稳定的收敛性。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏（KD）使用固定的超参数alpha来结合硬标签交叉熵损失和软标签蒸馏损失，但这种静态的alpha在训练过程中可能不是最优的，因为硬监督和软监督之间的最佳权衡会发生变化。

Method: 提出了一种自适应知识蒸馏（AKD）框架，其中alpha被设计为一个可学习的参数，在训练过程中自动学习和优化。此外，还引入了一个公式来动态计算alpha，该公式考虑了学生和教师模型之间的差距，并引入了一个上下文感知模块（CAM），利用MLP+注意力机制来适应性地重新加权每个类别的教师输出。

Result: 在CIFAR-10数据集上，使用ResNet-50作为教师模型，ResNet-18作为学生模型进行实验，AKD框架相比于固定权重的KD基线模型，取得了更高的准确率，并且收敛过程更加稳定。

Conclusion: AKD框架通过引入可学习的动态调整的超参数alpha以及上下文感知模块（CAM），能够更有效地在知识蒸馏过程中平衡硬监督和软监督，从而获得更好的性能和更稳定的训练过程。

Abstract: Knowledge distillation (KD) is a widely used technique to transfer knowledge
from a large teacher network to a smaller student model. Traditional KD uses a
fixed balancing factor alpha as a hyperparameter to combine the hard-label
cross-entropy loss with the soft-label distillation loss. However, a static
alpha is suboptimal because the optimal trade-off between hard and soft
supervision can vary during training.
  In this work, we propose an Adaptive Knowledge Distillation (AKD) framework.
First we try to make alpha as learnable parameter that can be automatically
learned and optimized during training. Then we introduce a formula to reflect
the gap between the student and the teacher to compute alpha dynamically,
guided by student-teacher discrepancies, and further introduce a Context-Aware
Module (CAM) using MLP + Attention to adaptively reweight class-wise teacher
outputs. Experiments on CIFAR-10 with ResNet-50 as teacher and ResNet-18 as
student demonstrate that our approach achieves superior accuracy compared to
fixed-weight KD baselines, and yields more stable convergence.

</details>


### [8] [A Dataset Generation Scheme Based on Video2EEG-SPGN-Diffusion for SEED-VD](https://arxiv.org/abs/2509.05321)
*Yunfei Guo,Tao Zhang,Wu Huang,Yao Song*

Main category: cs.CV

TL;DR: 该论文提出了一个名为Video2EEG-SPGN-Diffusion的开源框架，使用SEED-VD数据集生成条件于视频刺激的脑电图(EEG)信号，并提供了一个视频-EEG数据对齐的工程流程，支持多模态大模型训练。框架利用结合了自玩图网络(SPGN)和扩散模型的个性化EEG信号生成方法。主要贡献是发布了一个包含1000多个SEED-VD视频、对应的62通道EEG信号（200 Hz采样率）和情感标签的新数据集，旨在推动视频-EEG对齐和多模态研究。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有脑电图(EEG)信号研究中缺乏大规模、高质量、与视频内容对齐的多模态数据集的问题，以及为了能够生成个性化的、与视频刺激相匹配的EEG信号，从而推动情感分析、数据增强和脑机接口等领域的研究。

Method: 该研究采用了一个包含工程流程和生成模型的框架。工程流程负责视频和EEG数据对齐，以支持多模态大模型的训练。模型部分，利用自玩图网络(SPGN)与扩散模型相结合，生成个性化的EEG信号，并以视频为条件。

Result: 发布了一个名为SEED-VD的新数据集，其中包含1000多个视频片段及其对应的62通道EEG信号（200 Hz）和情感标签。成功构建了一个开源框架Video2EEG-SPGN-Diffusion，能够基于视频刺激生成EEG信号。

Conclusion: 该框架和数据集为视频-EEG对齐研究提供了有力支持，能够生成逼真的、与视频内容相关联的EEG信号，为多模态情感分析、数据增强和脑机接口等应用开辟了新的可能性，具有重要的研究和工程价值。

Abstract: This paper introduces an open-source framework, Video2EEG-SPGN-Diffusion,
that leverages the SEED-VD dataset to generate a multimodal dataset of EEG
signals conditioned on video stimuli. Additionally, we disclose an engineering
pipeline for aligning video and EEG data pairs, facilitating the training of
multimodal large models with EEG alignment capabilities. Personalized EEG
signals are generated using a self-play graph network (SPGN) integrated with a
diffusion model. As a major contribution, we release a new dataset comprising
over 1000 samples of SEED-VD video stimuli paired with generated 62-channel EEG
signals at 200 Hz and emotion labels, enabling video-EEG alignment and
advancing multimodal research. This framework offers novel tools for emotion
analysis, data augmentation, and brain-computer interface applications, with
substantial research and engineering significance.

</details>


### [9] [Optical Music Recognition of Jazz Lead Sheets](https://arxiv.org/abs/2509.05329)
*Juan Carlos Martinez-Sevilla,Francesco Foscarin,Patricia Garcia-Iasci,David Rizo,Jorge Calvo-Zaragoza,Gerhard Widmer*

Main category: cs.CV

TL;DR: 该研究提出了一个用于识别手写爵士乐谱（包含旋律和和弦）的新数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 现有光学音乐识别（OMR）系统无法处理手写爵士乐谱中的和弦，且手写乐谱图像存在高变异性和质量问题，因此需要新的OMR方法来应对这一挑战。

Method: 研究人员构建了一个包含293张手写爵士乐谱的新数据集，并提供从音乐和弦和MusicXML地面真值乐谱生成的合成乐谱图像。他们还开发了一个OMR模型，并讨论了特定于该类数据的标记化选择以及使用合成乐谱和预训练模型的优势。

Result: 研究人员成功构建了一个新的手写爵士乐谱数据集，并开发了一个能够处理和弦并解决手写乐谱固有挑战的OMR模型。

Conclusion: 该研究为手写爵士乐谱的OMR提供了一个新的数据集和模型，并公开发布了所有代码、数据和模型，有望推动该领域的研究和应用。

Abstract: In this paper, we address the challenge of Optical Music Recognition (OMR)
for handwritten jazz lead sheets, a widely used musical score type that encodes
melody and chords. The task is challenging due to the presence of chords, a
score component not handled by existing OMR systems, and the high variability
and quality issues associated with handwritten images. Our contribution is
two-fold. We present a novel dataset consisting of 293 handwritten jazz lead
sheets of 163 unique pieces, amounting to 2021 total staves aligned with
Humdrum **kern and MusicXML ground truth scores. We also supply synthetic score
images generated from the ground truth. The second contribution is the
development of an OMR model for jazz lead sheets. We discuss specific
tokenisation choices related to our kind of data, and the advantages of using
synthetic scores and pretrained models. We publicly release all code, data, and
models.

</details>


### [10] [RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness](https://arxiv.org/abs/2509.05333)
*Junghyun Park,Tuan Anh Nguyen,Dugki Min*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Real world deployments often expose modern object recognition models to
domain shifts that precipitate a severe drop in accuracy. Such shifts encompass
(i) variations in low level image statistics, (ii) changes in object pose and
viewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent
classes. To mitigate this degradation, we introduce the Re-Thinking Vision
Language Model (RT-VLM) framework. The foundation of this framework is a unique
synthetic dataset generation pipeline that produces images annotated with
"4-Clues": precise bounding boxes, class names, detailed object-level captions,
and a comprehensive context-level caption for the entire scene. We then perform
parameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this
resource. At inference time, a two stage Re-Thinking scheme is executed: the
model first emits its own four clues, then re examines these responses as
evidence and iteratively corrects them. Across robustness benchmarks that
isolate individual domain shifts, RT-VLM consistently surpasses strong
baselines. These findings indicate that the integration of structured
multimodal evidence with an explicit self critique loop constitutes a promising
route toward reliable and transferable visual understanding.

</details>


### [11] [A Real-Time, Vision-Based System for Badminton Smash Speed Estimation on Mobile Devices](https://arxiv.org/abs/2509.05334)
*Diwen Huang*

Main category: cs.CV

TL;DR: 该论文介绍了一种使用智能手机技术来测量羽毛球杀球速度的新方法，使业余和休闲玩家也能使用。


<details>
  <summary>Details</summary>
Motivation: 以往的体育性能指标技术成本高昂、使用复杂，普通玩家难以获得。本文旨在解决羽毛球运动中存在的这一问题。

Method: 本研究利用定制训练的YOLOv5模型进行羽毛球检测，并结合卡尔曼滤波器进行轨迹跟踪。通过实施基于视频的运动学速度估算方法和时空尺度调整，该系统可自动从标准视频录制中计算羽毛球的速度。

Result: 研究成功开发了一种经济高效且用户友好的系统，可以通过智能手机应用程序测量羽毛球的杀球速度。

Conclusion: 该系统通过提供易于使用的移动应用程序，让所有级别的羽毛球运动员都能获得高水平的性能分析，从而实现高性能分析的民主化，并使他们能够分析和改进自己的比赛。

Abstract: Performance metrics in sports, such as shot speed and angle, provide crucial
feedback for athlete development. However, the technology to capture these
metrics has historically been expensive, complex, and largely inaccessible to
amateur and recreational players. This paper addresses this gap in the context
of badminton, one of the world's most popular sports, by introducing a novel,
cost-effective, and user-friendly system for measuring smash speed using
ubiquitous smartphone technology. Our approach leverages a custom-trained
YOLOv5 model for shuttlecock detection, combined with a Kalman filter for
robust trajectory tracking. By implementing a video-based kinematic speed
estimation method with spatiotemporal scaling, the system automatically
calculates the shuttlecock's velocity from a standard video recording. The
entire process is packaged into an intuitive mobile application, democratizing
access to high-level performance analytics and empowering players at all levels
to analyze and improve their game.

</details>


### [12] [A Stroke-Level Large-Scale Database of Chinese Character Handwriting and the OpenHandWrite_Toolbox for Handwriting Research](https://arxiv.org/abs/2509.05335)
*Zebo Xu,Shaoyun Yu,Mark Torrance,Guido Nottbusch,Nan Zhao,Zhenguang Cai*

Main category: cs.CV

TL;DR: 该研究构建了一个大规模中文书写数据库和一套增强的工具箱，分析了语言成分（特别是拼写和语音）如何影响汉字的书写准备和执行过程，发现这些影响在字符、部件和笔画层面存在层级衰减效应，并强调了数据库和工具箱在未来跨语言字符和子字符书写研究中的价值。


<details>
  <summary>Details</summary>
Motivation: 目前对中文书写中语言成分（语音、语义、拼写）在字符、部件、笔画层面的影响研究不足，并且缺乏对精细书写数据进行采集和批量处理的工具。

Method: 构建了一个包含42名中文母语者、每人书写1200个汉字的大规模书写数据库，并升级了OpenHandWrite_Toolbox，使其能够修改实验设计、捕获笔画级书写轨迹、批量处理书写测量数据（如潜伏期、持续时间、笔压）。利用该数据库进行多重回归分析。

Result: 拼写预测因子在字符、部件、笔画层面均影响书写准备和执行；语音因素也影响这三个层面的执行。这些词汇效应呈现层级衰减：在字符层面最显著，其次是部件，在笔画层面最弱。

Conclusion: 书写准备和执行在部件和笔画层面上与语言成分紧密相关。该数据库和工具箱为未来跨语言的字符和子字符书写研究提供了宝贵的资源。

Abstract: Understanding what linguistic components (e.g., phonological, semantic, and
orthographic systems) modulate Chinese handwriting at the character, radical,
and stroke levels remains an important yet understudied topic. Additionally,
there is a lack of comprehensive tools for capturing and batch-processing
fine-grained handwriting data. To address these issues, we constructed a
large-scale handwriting database in which 42 Chinese speakers for each
handwriting 1200 characters in a handwriting-to-dictation task. Additionally,
we enhanced the existing handwriting package and provided comprehensive
documentation for the upgraded OpenHandWrite_Toolbox, which can easily modify
the experimental design, capture the stroke-level handwriting trajectory, and
batch-process handwriting measurements (e.g., latency, duration, and
pen-pressure). In analysing our large-scale database, multiple regression
results show that orthographic predictors impact handwriting preparation and
execution across character, radical, and stroke levels. Phonological factors
also influence execution at all three levels. Importantly, these lexical
effects demonstrate hierarchical attenuation - they were most pronounced at the
character level, followed by the radical, and were weakest at the stroke
levels. These findings demonstrate that handwriting preparation and execution
at the radical and stroke levels are closely intertwined with linguistic
components. This database and toolbox offer valuable resources for future
psycholinguistic and neurolinguistic research on the handwriting of characters
and sub-characters across different languages.

</details>


### [13] [Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory](https://arxiv.org/abs/2509.05337)
*Younggeol Cho,Gokhan Solak,Olivia Nocentini,Marta Lorenzini,Andrea Fortuna,Arash Ajoudani*

Main category: cs.CV

TL;DR: 提出一种结合动态图神经网络（DGNN）和长短期记忆（LSTM）网络的混合模型，用于预测跌倒。


<details>
  <summary>Details</summary>
Motivation: 在检测和预防跌倒方面取得显著进展，但跌倒预测以及稳定状态和即将发生跌倒之间的瞬态状态分析仍有待探索。

Method: 利用从视频序列中提取的实时骨骼特征作为输入。DGNN区分稳定、瞬态和跌倒三种步态状态。LSTM预测后续时间步的运动，实现早期跌倒检测。

Result: 使用OUMVLP-Pose和URFD数据集训练和验证，与仅依赖DGNN的模型和文献中的模型相比，在预测误差和识别准确性方面表现优越。证明了分离预测和分类任务优于统一处理问题。

Conclusion: 分离预测和分类任务提高了性能，并且该方法能够监测瞬态状态，为改进高级辅助系统功能提供宝贵见解。

Abstract: Detecting and preventing falls in humans is a critical component of assistive
robotic systems. While significant progress has been made in detecting falls,
the prediction of falls before they happen, and analysis of the transient state
between stability and an impending fall remain unexplored. In this paper, we
propose a anticipatory fall detection method that utilizes a hybrid model
combining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory
(LSTM) networks that decoupled the motion prediction and gait classification
tasks to anticipate falls with high accuracy. Our approach employs real-time
skeletal features extracted from video sequences as input for the proposed
model. The DGNN acts as a classifier, distinguishing between three gait states:
stable, transient, and fall. The LSTM-based network then predicts human
movement in subsequent time steps, enabling early detection of falls. The
proposed model was trained and validated using the OUMVLP-Pose and URFD
datasets, demonstrating superior performance in terms of prediction error and
recognition accuracy compared to models relying solely on DGNN and models from
literature. The results indicate that decoupling prediction and classification
improves performance compared to addressing the unified problem using only the
DGNN. Furthermore, our method allows for the monitoring of the transient state,
offering valuable insights that could enhance the functionality of advanced
assistance systems.

</details>


### [14] [Comparative Evaluation of Hard and Soft Clustering for Precise Brain Tumor Segmentation in MR Imaging](https://arxiv.org/abs/2509.05340)
*Dibya Jyoti Bora,Mrinal Kanti Mishra*

Main category: cs.CV

TL;DR: K-Means比FCM速度更快，但FCM分割精度更高。


<details>
  <summary>Details</summary>
Motivation: 准确分割脑肿瘤MRI图像对于临床决策、放疗规划和疾病监测至关重要，但肿瘤形态和强度分布的异质性带来了挑战。

Method: 对K-Means（硬聚类）和FCM（软聚类）在MRI脑肿瘤分割任务中的应用进行了比较分析，并使用了BraTS2020数据集，预处理步骤包括高斯滤波和CLAHE。

Result: K-Means平均运行时间为0.3秒/图像，而FCM为1.3秒/图像。FCM的平均DSC为0.67，K-Means为0.43。

Conclusion: K-Means在计算效率方面表现更优，而FCM在分割精度方面表现更佳，两者之间存在效率与精度的权衡。

Abstract: Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) remains a
pivotal challenge in medical image analysis due to the heterogeneous nature of
tumor morphology and intensity distributions. Accurate delineation of tumor
boundaries is critical for clinical decision-making, radiotherapy planning, and
longitudinal disease monitoring. In this study, we perform a comprehensive
comparative analysis of two major clustering paradigms applied in MRI tumor
segmentation: hard clustering, exemplified by the K-Means algorithm, and soft
clustering, represented by Fuzzy C-Means (FCM). While K-Means assigns each
pixel strictly to a single cluster, FCM introduces partial memberships, meaning
each pixel can belong to multiple clusters with varying degrees of association.
Experimental validation was performed using the BraTS2020 dataset,
incorporating pre-processing through Gaussian filtering and Contrast Limited
Adaptive Histogram Equalization (CLAHE). Evaluation metrics included the Dice
Similarity Coefficient (DSC) and processing time, which collectively
demonstrated that K-Means achieved superior speed with an average runtime of
0.3s per image, whereas FCM attained higher segmentation accuracy with an
average DSC of 0.67 compared to 0.43 for K-Means, albeit at a higher
computational cost (1.3s per image). These results highlight the inherent
trade-off between computational efficiency and boundary precision.

</details>


### [15] [Handling imbalance and few-sample size in ML based Onion disease classification](https://arxiv.org/abs/2509.05341)
*Abhijeet Manoj Pal,Rajbabu Velmurugan*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的模型，用于洋葱作物病虫害的多类别分类，实现了96.90%的准确率和0.96的F1分数，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确的病虫害分类对于精准农业至关重要，但现有方法多为二元分类，无法满足识别具体病虫害类型的需求。

Method: 提出了一种深度学习模型，通过集成注意力机制模块和使用全面的数据增强技术来处理类别不平衡问题，并对预训练的卷积神经网络（CNN）模型进行了增强。

Result: 提出的模型在真实田野图像数据集上实现了96.90%的整体准确率和0.96的F1分数，优于同一数据集上的其他方法。

Conclusion: 所提出的深度学习模型能够准确地对洋葱作物病虫害进行多类别分类，并在准确性和F1分数方面取得了优于现有方法的结果。

Abstract: Accurate classification of pests and diseases plays a vital role in precision
agriculture, enabling efficient identification, targeted interventions, and
preventing their further spread. However, current methods primarily focus on
binary classification, which limits their practical applications, especially in
scenarios where accurately identifying the specific type of disease or pest is
essential. We propose a robust deep learning based model for multi-class
classification of onion crop diseases and pests. We enhance a pre-trained
Convolutional Neural Network (CNN) model by integrating attention based modules
and employing comprehensive data augmentation pipeline to mitigate class
imbalance. We propose a model which gives 96.90% overall accuracy and 0.96 F1
score on real-world field image dataset. This model gives better results than
other approaches using the same datasets.

</details>


### [16] [Delta Velocity Rectified Flow for Text-to-Image Editing](https://arxiv.org/abs/2509.05342)
*Gaspard Beaudouin,Minghan Li,Jaeyeon Kim,Sunghoon Yoon,Mengyu Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose Delta Velocity Rectified Flow (DVRF), a novel inversion-free,
path-aware editing framework within rectified flow models for text-to-image
editing. DVRF is a distillation-based method that explicitly models the
discrepancy between the source and target velocity fields in order to mitigate
over-smoothing artifacts rampant in prior distillation sampling approaches. We
further introduce a time-dependent shift term to push noisy latents closer to
the target trajectory, enhancing the alignment with the target distribution. We
theoretically demonstrate that when this shift is disabled, DVRF reduces to
Delta Denoising Score, thereby bridging score-based diffusion optimization and
velocity-based rectified-flow optimization. Moreover, when the shift term
follows a linear schedule under rectified-flow dynamics, DVRF generalizes the
Inversion-free method FlowEdit and provides a principled theoretical
interpretation for it. Experimental results indicate that DVRF achieves
superior editing quality, fidelity, and controllability while requiring no
architectural modifications, making it efficient and broadly applicable to
text-to-image editing tasks. Code is available at
https://github.com/gaspardbd/DeltaVelocityRectifiedFlow.

</details>


### [17] [Systematic Integration of Attention Modules into CNNs for Accurate and Generalizable Medical Image Diagnosis](https://arxiv.org/abs/2509.05343)
*Zahid Ullah,Minki Hong,Tahir Mahmood,Jihie Kim*

Main category: cs.CV

TL;DR: 通过在五种常用的CNN架构（VGG16、ResNet18、InceptionV3、DenseNet121和EfficientNetB5）中集成注意力机制，提升了它们在医学图像分析中的性能，尤其是在处理细粒度和复杂特征方面。


<details>
  <summary>Details</summary>
Motivation: 传统的CNN在医学图像分析中难以捕捉细粒度和复杂特征，影响了诊断的准确性。

Method: 将Squeeze and Excitation模块或混合卷积块注意力模块（CBAM）集成到五种广泛使用的CNN架构中，以增强模型对显著区域的关注能力和区分性能。

Result: 与基线模型相比，所有集成注意力机制的CNN模型在两个医学成像数据集（脑肿瘤MRI和妊娠产物组织病理学）上均表现出优越的性能。其中，带有混合注意力的EfficientNetB5在两个数据集上均取得了最佳的总体性能。

Conclusion: 集成注意力机制的CNN在医学图像分析中能够提高分类准确性、增强特征定位能力并改善跨不同成像模态的泛化能力。该研究提供了一个系统性的比较框架，为开发稳健、可解释且临床适用的深度学习决策支持系统提供了实践见解。

Abstract: Deep learning has become a powerful tool for medical image analysis; however,
conventional Convolutional Neural Networks (CNNs) often fail to capture the
fine-grained and complex features critical for accurate diagnosis. To address
this limitation, we systematically integrate attention mechanisms into five
widely adopted CNN architectures, namely, VGG16, ResNet18, InceptionV3,
DenseNet121, and EfficientNetB5, to enhance their ability to focus on salient
regions and improve discriminative performance. Specifically, each baseline
model is augmented with either a Squeeze and Excitation block or a hybrid
Convolutional Block Attention Module, allowing adaptive recalibration of
channel and spatial feature representations. The proposed models are evaluated
on two distinct medical imaging datasets, a brain tumor MRI dataset comprising
multiple tumor subtypes, and a Products of Conception histopathological dataset
containing four tissue categories. Experimental results demonstrate that
attention augmented CNNs consistently outperform baseline architectures across
all metrics. In particular, EfficientNetB5 with hybrid attention achieves the
highest overall performance, delivering substantial gains on both datasets.
Beyond improved classification accuracy, attention mechanisms enhance feature
localization, leading to better generalization across heterogeneous imaging
modalities. This work contributes a systematic comparative framework for
embedding attention modules in diverse CNN architectures and rigorously
assesses their impact across multiple medical imaging tasks. The findings
provide practical insights for the development of robust, interpretable, and
clinically applicable deep learning based decision support systems.

</details>


### [18] [Vision-Based Object Detection for UAV Solar Panel Inspection Using an Enhanced Defects Dataset](https://arxiv.org/abs/2509.05348)
*Ashen Rodrigo,Isuru Munasinghe,Asanka Perera*

Main category: cs.CV

TL;DR: 该研究评估了五种先进的目标检测模型（YOLOv3、Faster R-CNN、RetinaNet、EfficientDet 和 Swin Transformer）在检测太阳能电池板物理和电气缺陷以及灰尘、污垢和鸟粪等表面污染物方面的性能。


<details>
  <summary>Details</summary>
Motivation: 及时准确地检测太阳能电池板中的缺陷和污染物对于保持光伏系统的效率和可靠性至关重要。

Method: 开发了一个自定义的、以 COCO 格式注释的数据集，并与用户界面一起用于训练和评估 YOLOv3、Faster R-CNN、RetinaNet、EfficientDet 和 Swin Transformer 模型。

Result: 研究评估了每个模型在平均精度 (mAP)、精度、召回率和推理速度方面的性能，并展示了检测精度与计算效率之间的权衡。

Conclusion: 该研究为在实际太阳能电池板监控和维护场景中选择合适的检测方法提供了有价值的指导，并且该数据集将公开提供。

Abstract: Timely and accurate detection of defects and contaminants in solar panels is
critical for maintaining the efficiency and reliability of photovoltaic
systems. This study presents a comprehensive evaluation of five
state-of-the-art object detection models: YOLOv3, Faster R-CNN, RetinaNet,
EfficientDet, and Swin Transformer, for identifying physical and electrical
defects as well as surface contaminants such as dust, dirt, and bird droppings
on solar panels. A custom dataset, annotated in the COCO format and
specifically designed for solar panel defect and contamination detection, was
developed alongside a user interface to train and evaluate the models. The
performance of each model is assessed and compared based on mean Average
Precision (mAP), precision, recall, and inference speed. The results
demonstrate the trade-offs between detection accuracy and computational
efficiency, highlighting the relative strengths and limitations of each model.
These findings provide valuable guidance for selecting appropriate detection
approaches in practical solar panel monitoring and maintenance scenarios.
  The dataset will be publicly available at
https://github.com/IsuruMunasinghe98/solar-panel-inspection-dataset.

</details>


### [19] [Unsupervised Instance Segmentation with Superpixels](https://arxiv.org/abs/2509.05352)
*Cuong Manh Hoang*

Main category: cs.CV

TL;DR: 提出了一种无需人工标注即可进行实例分割的新框架，通过自监督特征、掩码过滤、超像素引导掩码损失和自训练过程来提高分割质量，并在公开数据集上证明了其有效性，优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 当前流行的实例分割模型需要大量昂贵的人工标注数据进行训练，而该研究旨在提出一种无需人工标注即可高效实现实例分割的新框架。

Method: 首先，应用MultiCut算法处理自监督特征以进行粗略的掩码分割，然后使用掩码过滤器获得高质量的粗略掩码。接着，通过包含硬损失和软损失的超像素引导掩码损失来训练分割网络，该损失使用高质量的粗略掩码和从低级图像特征分割出的超像素。最后，提出了一种新的自适应损失的自训练过程来提高预测掩码的质量。

Result: 在实例分割和目标检测的公开数据集上进行了实验，证明了所提出框架的有效性，其性能优于先前最先进的方法。

Conclusion: 所提出的框架能够高效且有效地进行实例分割，并且无需人工标注，性能优于现有方法。

Abstract: Instance segmentation is essential for numerous computer vision applications,
including robotics, human-computer interaction, and autonomous driving.
Currently, popular models bring impressive performance in instance segmentation
by training with a large number of human annotations, which are costly to
collect. For this reason, we present a new framework that efficiently and
effectively segments objects without the need for human annotations. Firstly, a
MultiCut algorithm is applied to self-supervised features for coarse mask
segmentation. Then, a mask filter is employed to obtain high-quality coarse
masks. To train the segmentation network, we compute a novel superpixel-guided
mask loss, comprising hard loss and soft loss, with high-quality coarse masks
and superpixels segmented from low-level image features. Lastly, a
self-training process with a new adaptive loss is proposed to improve the
quality of predicted masks. We conduct experiments on public datasets in
instance segmentation and object detection to demonstrate the effectiveness of
the proposed framework. The results show that the proposed framework
outperforms previous state-of-the-art methods.

</details>


### [20] [Augmented Structure Preserving Neural Networks for cell biomechanics](https://arxiv.org/abs/2509.05388)
*Juan Olalla-Pombo,Alberto Badías,Miguel Ángel Sanz-Gómez,José María Benítez,Francisco Javier Montáns*

Main category: cs.CV

TL;DR: 本文提出了一种结合结构保持神经网络和机器学习工具（人工神经网络）的新方法，用于模拟和预测细胞迁移及其分裂事件。


<details>
  <summary>Details</summary>
Motivation: 细胞生物力学现象对生命进化至关重要，但其复杂的相互作用和对细胞集体行为的影响尚不清楚。

Method: 该方法将细胞运动视为纯粹的力学系统，并结合考虑环境因素的机器学习工具（如计算机视觉技术提取的特征）。

Result: 该模型在模拟和真实细胞迁移案例中表现出高精度的预测能力，能够预测完整的细胞轨迹。此外，还包含一个基于神经网络的细胞分裂事件预测模型。

Conclusion: 该研究为理解和预测细胞行为提供了新的计算模型，有望在细胞生物学研究中发挥重要作用。

Abstract: Cell biomechanics involve a great number of complex phenomena that are
fundamental to the evolution of life itself and other associated processes,
ranging from the very early stages of embryo-genesis to the maintenance of
damaged structures or the growth of tumors. Given the importance of such
phenomena, increasing research has been dedicated to their understanding, but
the many interactions between them and their influence on the decisions of
cells as a collective network or cluster remain unclear. We present a new
approach that combines Structure Preserving Neural Networks, which study cell
movements as a purely mechanical system, with other Machine Learning tools
(Artificial Neural Networks), which allow taking into consideration
environmental factors that can be directly deduced from an experiment with
Computer Vision techniques. This new model, tested on simulated and real cell
migration cases, predicts complete cell trajectories following a roll-out
policy with a high level of accuracy. This work also includes a mitosis event
prediction model based on Neural Networks architectures which makes use of the
same observed features.

</details>


### [21] [Advanced Brain Tumor Segmentation Using EMCAD: Efficient Multi-scale Convolutional Attention Decoding](https://arxiv.org/abs/2509.05431)
*GodsGift Uzor,Tania-Amanda Nkoyo Fredrick Eneye,Chukwuebuka Ijezue*

Main category: cs.CV

TL;DR: EMCAD是一种用于脑肿瘤分割的高效多尺度卷积注意力解码器，在BraTs2020数据集上取得了0.31的最佳Dice分数，并保持了稳定的训练过程。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤分割是医学图像分析中的关键预处理步骤，尤其是在计算资源有限的情况下，需要高效的解码机制来精确分割肿瘤区域。现有的解码机制计算成本高。

Method: 提出了一种名为EMCAD的新型高效多尺度卷积注意力解码器，用于优化脑肿瘤分割的性能和计算效率。

Result: 在BraTs2020数据集上，EMCAD模型取得了0.31的最佳Dice分数，平均Dice分数为0.285（±0.015），在验证集上表现稳定，无过拟合现象。

Conclusion: EMCAD在脑肿瘤分割任务中实现了性能和计算效率的平衡，为资源受限的环境提供了解决方案。

Abstract: Brain tumor segmentation is a critical pre-processing step in the medical
image analysis pipeline that involves precise delineation of tumor regions from
healthy brain tissue in medical imaging data, particularly MRI scans. An
efficient and effective decoding mechanism is crucial in brain tumor
segmentation especially in scenarios with limited computational resources.
However these decoding mechanisms usually come with high computational costs.
To address this concern EMCAD a new efficient multi-scale convolutional
attention decoder designed was utilized to optimize both performance and
computational efficiency for brain tumor segmentation on the BraTs2020 dataset
consisting of MRI scans from 369 brain tumor patients. The preliminary result
obtained by the model achieved a best Dice score of 0.31 and maintained a
stable mean Dice score of 0.285 plus/minus 0.015 throughout the training
process which is moderate. The initial model maintained consistent performance
across the validation set without showing signs of over-fitting.

</details>


### [22] [FAVAE-Effective Frequency Aware Latent Tokenizer](https://arxiv.org/abs/2509.05441)
*Tejaswini Medi,Hsien-Yi Wang,Arianna Rampini,Margret Keuper*

Main category: cs.CV

TL;DR: 现有的潜空间生成模型在图像生成方面取得了显著进展，但通常在第一阶段使用学习到的分词器将图像压缩成潜在嵌入。本文分析发现，这些模型在优化过程中倾向于低频重建，导致纹理区域细节丢失，影响感知质量。为解决此问题，本文提出了一种基于小波的、频率感知的变分自编码器（FA-VAE）框架，明确地将低频和高频分量的优化解耦，从而在保留全局结构的同时改善了精细纹理的重建。


<details>
  <summary>Details</summary>
Motivation: 现有的潜空间生成模型在图像生成方面存在局限性，尤其是在纹理区域的细节重建上，由于模型倾向于低频重建而丢失了高频信息，导致输出过于平滑并出现视觉伪影。

Method: 本文首先对现有最先进的潜分词器进行了详细的频率分解分析，揭示了其优化目标固有的低频偏好。然后，提出了一种基于小波的、频率感知的变分自编码器（FA-VAE）框架，该框架明确地将低频和高频分量的优化过程分离开来，以实现更好的高频细节重建。

Result: FA-VAE 框架能够实现对精细纹理的改进重建，同时保持图像的全局结构，弥补了现有潜分词器在保真度方面的不足。

Conclusion: 本文强调了频率感知优化对于实现逼真图像表示的重要性，并提出了一种FA-VAE框架，它通过显式解耦低频和高频分量的优化，显著提高了图像重建的保真度，尤其是在纹理细节方面。这对于内容创作、神经渲染和医学成像等领域具有更广泛的应用前景。

Abstract: Latent generative models have shown remarkable progress in high-fidelity
image synthesis, typically using a two-stage training process that involves
compressing images into latent embeddings via learned tokenizers in the first
stage. The quality of generation strongly depends on how expressive and
well-optimized these latent embeddings are. While various methods have been
proposed to learn effective latent representations, the reconstructed images
often lack realism, particularly in textured regions with sharp transitions,
due to loss of fine details governed by high frequencies. We conduct a detailed
frequency decomposition of existing state-of-the-art (SOTA) latent tokenizers
and show that conventional objectives inherently prioritize low-frequency
reconstruction, often at the expense of high-frequency fidelity. Our analysis
reveals these latent tokenizers exhibit a bias toward low-frequency
information, when jointly optimized, leading to over-smoothed outputs and
visual artifacts that diminish perceptual quality. To address this, we propose
a wavelet-based, frequency-aware variational autoencoder (FA-VAE) framework
that explicitly decouples the optimization of low- and high-frequency
components. This decoupling enables improved reconstruction of fine textures
while preserving global structure. Our approach bridges the fidelity gap in
current latent tokenizers and emphasizes the importance of frequency-aware
optimization for realistic image representation, with broader implications for
applications in content creation, neural rendering, and medical imaging.

</details>


### [23] [Dynamic Sensitivity Filter Pruning using Multi-Agent Reinforcement Learning For DCNN's](https://arxiv.org/abs/2509.05446)
*Iftekhar Haider Chowdhury,Zaed Ikbal Syed,Ahmed Faizul Haque Dhrubo,Mohammad Abdul Qayum*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep Convolutional Neural Networks have achieved state of the art performance
across various computer vision tasks, however their practical deployment is
limited by computational and memory overhead. This paper introduces
Differential Sensitivity Fusion Pruning, a novel single shot filter pruning
framework that focuses on evaluating the stability and redundancy of filter
importance scores across multiple criteria. Differential Sensitivity Fusion
Pruning computes a differential sensitivity score for each filter by fusing the
discrepancies among gradient based sensitivity, first order Taylor expansion,
and KL divergence of activation distributions. An exponential scaling mechanism
is applied to emphasize filters with inconsistent importance across metrics,
identifying candidates that are structurally unstable or less critical to the
model performance. Unlike iterative or reinforcement learning based pruning
strategies, Differential Sensitivity Fusion Pruning is efficient and
deterministic, requiring only a single forward-backward pass for scoring and
pruning. Extensive experiments across varying pruning rates between 50 to 70
percent demonstrate that Differential Sensitivity Fusion Pruning significantly
reduces model complexity, achieving over 80 percent Floating point Operations
Per Seconds reduction while maintaining high accuracy. For instance, at 70
percent pruning, our approach retains up to 98.23 percent of baseline accuracy,
surpassing traditional heuristics in both compression and generalization. The
proposed method presents an effective solution for scalable and adaptive Deep
Convolutional Neural Networks compression, paving the way for efficient
deployment on edge and mobile platforms.

</details>


### [24] [Veriserum: A dual-plane fluoroscopic dataset with knee implant phantoms for deep learning in medical imaging](https://arxiv.org/abs/2509.05483)
*Jinhao Wang,Florian Vogl,Pascal Schütz,Saša Ćuković,William R. Taylor*

Main category: cs.CV

TL;DR: Veriserum是一个开源数据集，包含约11万张X光图像，用于训练深度学习模型进行双平面X光分析，旨在推动计算机视觉和医学影像研究。


<details>
  <summary>Details</summary>
Motivation: 为了支持双平面X光分析的深度学习配准训练，推动计算机视觉和医学影像研究。

Method: 创建了一个包含约11万张X光图像的数据集，涵盖了10种膝关节植入物组合和日常活动姿势，并提供了自动和手动标注的地面真实姿势。

Result: 该数据集包含双平面图像和校准工具，可用于2D/3D图像配准、图像分割、X光畸变校正和3D重建等应用。

Conclusion: Veriserum是一个公开的数据集，为算法开发和评估提供了可重复的基准，旨在加速计算机视觉和医学影像领域的研究进展。

Abstract: Veriserum is an open-source dataset designed to support the training of deep
learning registration for dual-plane fluoroscopic analysis. It comprises
approximately 110,000 X-ray images of 10 knee implant pair combinations (2
femur and 5 tibia implants) captured during 1,600 trials, incorporating poses
associated with daily activities such as level gait and ramp descent. Each
image is annotated with an automatically registered ground-truth pose, while
200 images include manually registered poses for benchmarking.
  Key features of Veriserum include dual-plane images and calibration tools.
The dataset aims to support the development of applications such as 2D/3D image
registration, image segmentation, X-ray distortion correction, and 3D
reconstruction. Freely accessible, Veriserum aims to advance computer vision
and medical imaging research by providing a reproducible benchmark for
algorithm development and evaluation. The Veriserum dataset used in this study
is publicly available via
https://movement.ethz.ch/data-repository/veriserum.html, with the data stored
at ETH Z\"urich Research Collections: https://doi.org/10.3929/ethz-b-000701146.

</details>


### [25] [An Analysis of Layer-Freezing Strategies for Enhanced Transfer Learning in YOLO Architectures](https://arxiv.org/abs/2509.05490)
*Andrzej D. Dobrzycki,Ana M. Bernardos,José R. Casar*

Main category: cs.CV

TL;DR: 在 YOLOv8 和 YOLOv10 中，没有一种通用的最佳层冻结策略，而是一种取决于数据属性的策略。研究者通过系统地研究不同冻结配置，发现在关键基础设施监控的挑战性数据集上，某些冻结策略在降低 GPU 内存消耗的同时，其 mAP@50 分数可以超越完全微调。


<details>
  <summary>Details</summary>
Motivation: 部署 YOLOv8 和 YOLOv10 等模型到资源受限环境（如无人机）需要有效的迁移学习，但现有研究缺乏对不同层冻结配置对这些模型影响的深入分析，特别是与冻结深度、数据集特性和训练动态的相互作用。

Method: 系统地研究了 YOLOv8 和 YOLOv10 模型在四种关键基础设施监控数据集上的多种层冻结配置，并结合梯度行为分析（L2 范数）和 Grad-CAM 可视化来深入分析训练动态。

Result: 研究发现，最佳冻结策略取决于数据特性：冻结骨干网络有利于保留通用特征，而较浅的冻结策略更适合处理极端类别不平衡。这些配置可将 GPU 内存消耗降低高达 28%，并在某些情况下实现优于完全微调的 mAP@50 分数。梯度分析显示了不同冻结策略下的独特收敛模式。

Conclusion: 本研究提供了关于选择层冻结策略的经验性发现和实用指南，为资源受限场景下的目标检测提供了一种平衡迁移学习的、基于证据的实用方法。

Abstract: The You Only Look Once (YOLO) architecture is crucial for real-time object
detection. However, deploying it in resource-constrained environments such as
unmanned aerial vehicles (UAVs) requires efficient transfer learning. Although
layer freezing is a common technique, the specific impact of various freezing
configurations on contemporary YOLOv8 and YOLOv10 architectures remains
unexplored, particularly with regard to the interplay between freezing depth,
dataset characteristics, and training dynamics. This research addresses this
gap by presenting a detailed analysis of layer-freezing strategies. We
systematically investigate multiple freezing configurations across YOLOv8 and
YOLOv10 variants using four challenging datasets that represent critical
infrastructure monitoring. Our methodology integrates a gradient behavior
analysis (L2 norm) and visual explanations (Grad-CAM) to provide deeper
insights into training dynamics under different freezing strategies. Our
results reveal that there is no universal optimal freezing strategy but,
rather, one that depends on the properties of the data. For example, freezing
the backbone is effective for preserving general-purpose features, while a
shallower freeze is better suited to handling extreme class imbalance. These
configurations reduce graphics processing unit (GPU) memory consumption by up
to 28% compared to full fine-tuning and, in some cases, achieve mean average
precision (mAP@50) scores that surpass those of full fine-tuning. Gradient
analysis corroborates these findings, showing distinct convergence patterns for
moderately frozen models. Ultimately, this work provides empirical findings and
practical guidelines for selecting freezing strategies. It offers a practical,
evidence-based approach to balanced transfer learning for object detection in
scenarios with limited resources.

</details>


### [26] [Quaternion Approximation Networks for Enhanced Image Classification and Oriented Object Detection](https://arxiv.org/abs/2509.05512)
*Bryce Grant,Peng Wang*

Main category: cs.CV

TL;DR: QUAN是一个基于四元数代数的新型深度学习框架，用于旋转等变图像分类和目标检测。它通过汉密尔顿乘积分解来近似四元数卷积，使用实值运算，并引入了IQBN以提高训练稳定性。QUAN在图像分类和目标检测任务上均表现出色，参数更少，收敛更快，并在机器人感知等资源受限场景中展现出巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在图像分类和目标检测等任务中实现旋转等变性，并提高模型效率，尤其是在资源受限的机器人系统中。

Method: 提出了一种名为QUAN的新型深度学习框架，它不完全在四元数域中操作，而是通过汉密尔顿乘积分解来近似四元数卷积，使用实值运算。引入了独立的四元数批归一化（IQBN）来稳定训练，并将四元数运算扩展到空间注意力机制。

Result: 在图像分类任务上，QUAN的准确性更高，参数更少，收敛速度更快。在目标检测任务上，QUAN的参数效率和旋转处理能力优于标准CNN，并达到了四元数CNN在该任务上的SOTA水平。

Conclusion: QUAN在图像分类、目标检测和机器人感知任务上都取得了优于现有方法的性能，特别是在参数效率、收敛速度和旋转处理能力方面。这表明QUAN在需要旋转感知感知的资源受限机器人系统以及其他应用领域具有广阔的应用前景。

Abstract: This paper introduces Quaternion Approximate Networks (QUAN), a novel deep
learning framework that leverages quaternion algebra for rotation equivariant
image classification and object detection. Unlike conventional quaternion
neural networks attempting to operate entirely in the quaternion domain, QUAN
approximates quaternion convolution through Hamilton product decomposition
using real-valued operations. This approach preserves geometric properties
while enabling efficient implementation with custom CUDA kernels. We introduce
Independent Quaternion Batch Normalization (IQBN) for training stability and
extend quaternion operations to spatial attention mechanisms. QUAN is evaluated
on image classification (CIFAR-10/100, ImageNet), object detection (COCO,
DOTA), and robotic perception tasks. In classification tasks, QUAN achieves
higher accuracy with fewer parameters and faster convergence compared to
existing convolution and quaternion-based models. For objection detection, QUAN
demonstrates improved parameter efficiency and rotation handling over standard
Convolutional Neural Networks (CNNs) while establishing the SOTA for quaternion
CNNs in this downstream task. These results highlight its potential for
deployment in resource-constrained robotic systems requiring rotation-aware
perception and application in other domains.

</details>


### [27] [OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation](https://arxiv.org/abs/2509.05513)
*Ahad Jawaid,Yu Xiang*

Main category: cs.CV

TL;DR: OpenEgo是一个包含1107小时、290个操作任务的、标准化的手部姿势标注的、多模态的自我中心操控数据集，旨在降低从自我中心视频学习灵巧操控的门槛，并支持可重复的视觉-语言-动作学习研究。


<details>
  <summary>Details</summary>
Motivation: 现有的自我中心视频数据集在提供精细、时间定位的动作描述或灵巧手部标注方面存在不足。

Method: 整合了6个公开数据集，总计1107小时，涵盖290个操作任务和600多个环境。统一了手部姿势标注格式，并提供了描述性的、带时间戳的动作原语。

Result: 通过训练语言条件模仿学习策略来预测灵巧手部轨迹，验证了该数据集的有效性。

Conclusion: OpenEgo数据集的发布将降低从自我中心视频学习灵巧操控的门槛，并促进视觉-语言-动作学习领域可重复性研究。

Abstract: Egocentric human videos provide scalable demonstrations for imitation
learning, but existing corpora often lack either fine-grained, temporally
localized action descriptions or dexterous hand annotations. We introduce
OpenEgo, a multimodal egocentric manipulation dataset with standardized
hand-pose annotations and intention-aligned action primitives. OpenEgo totals
1107 hours across six public datasets, covering 290 manipulation tasks in 600+
environments. We unify hand-pose layouts and provide descriptive, timestamped
action primitives. To validate its utility, we train language-conditioned
imitation-learning policies to predict dexterous hand trajectories. OpenEgo is
designed to lower the barrier to learning dexterous manipulation from
egocentric video and to support reproducible research in vision-language-action
learning. All resources and instructions will be released at
www.openegocentric.com.

</details>


### [28] [Visibility-Aware Language Aggregation for Open-Vocabulary Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2509.05515)
*Sen Wang,Kunyi Li,Siyun Liang,Elena Alegret,Jing Ma,Nassir Navab,Stefano Gasperini*

Main category: cs.CV

TL;DR: 现有方法在将2D图像的开放词汇语言特征蒸馏到3D高斯表示时，存在背景高斯特征与前景高斯特征混淆以及多视图不一致的问题。本文提出可见光感知语言聚合（VALA）方法，通过计算每个射线的边际贡献并应用可见光感知门控来保留可见高斯，并提出流式加权几何中值来合并多视图特征，以实现鲁棒、视图一致且高效的语言特征嵌入。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理3D场景的语言交互时，存在背景高斯特征与前景高斯特征的贡献度混淆，以及由于视图特定的语言嵌入噪声导致的多视图不一致性问题。

Method: 本文提出可见光感知语言聚合（VALA）方法，通过计算每个射线的边际贡献并应用可见光感知门控来保留可见高斯；同时，提出流式加权几何中值在余弦空间中合并多视图特征。

Result: VALA方法能够快速、内存高效地生成鲁棒、视图一致的语言特征嵌入，并在开放词汇的定位和分割任务上持续优于现有方法。

Conclusion: VALA通过引入可见光感知聚合和流式加权几何中值，有效解决了现有方法在3D场景语言特征表示中的关键问题，实现了更优的性能。

Abstract: Recently, distilling open-vocabulary language features from 2D images into 3D
Gaussians has attracted significant attention. Although existing methods
achieve impressive language-based interactions of 3D scenes, we observe two
fundamental issues: background Gaussians contributing negligibly to a rendered
pixel get the same feature as the dominant foreground ones, and multi-view
inconsistencies due to view-specific noise in language embeddings. We introduce
Visibility-Aware Language Aggregation (VALA), a lightweight yet effective
method that computes marginal contributions for each ray and applies a
visibility-aware gate to retain only visible Gaussians. Moreover, we propose a
streaming weighted geometric median in cosine space to merge noisy multi-view
features. Our method yields a robust, view-consistent language feature
embedding in a fast and memory-efficient manner. VALA improves open-vocabulary
localization and segmentation across reference datasets, consistently
surpassing existing works.

</details>


### [29] [DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation](https://arxiv.org/abs/2509.05543)
*Haitao Tian,Pierre Payeur*

Main category: cs.CV

TL;DR: 该论文提出了一种对比表示学习框架DuoCLR，通过预训练来增强人类动作分割任务，利用了多尺度表示和跨序列变异性。


<details>
  <summary>Details</summary>
Motivation: 以往的表示学习方法主要针对动作识别，并依赖于孤立的序列表示。而该研究的动机是探索一种能够利用多尺度表示和跨序列变异性，并专门优化于动作分割（而非识别）的表示学习框架。

Method: 提出了一种名为 'Shuffle and Warp' 的新颖数据增强策略，该策略利用了多动作排列的多样性。该策略辅助了对比学习中的两个代理任务：跨排列对比（CPC）和相对顺序推理（ROR）。CPC通过对比不同排列中同一动作类别的表示来学习类内相似性，而ROR通过预测两个排列之间的相对映射来推理类间上下文。这种方法最终形成了一个名为 DuoCLR 的双代理对比学习网络，用于学习针对动作分割的多尺度特征表示。

Result: 在预训练后，DuoCLR在未剪辑数据集上的多类别和多标签动作分割任务上，均显著优于当前最先进的方法。

Conclusion: 实验结果和消融研究表明，所提出的DuoCLR框架，包括 'Shuffle and Warp' 数据增强策略以及CPC和ROR代理任务，能够有效地学习多尺度特征表示，并显著提升动作分割的性能。

Abstract: In this paper, a contrastive representation learning framework is proposed to
enhance human action segmentation via pre-training using trimmed (single
action) skeleton sequences. Unlike previous representation learning works that
are tailored for action recognition and that build upon isolated sequence-wise
representations, the proposed framework focuses on exploiting multi-scale
representations in conjunction with cross-sequence variations. More
specifically, it proposes a novel data augmentation strategy, 'Shuffle and
Warp', which exploits diverse multi-action permutations. The latter effectively
assists two surrogate tasks that are introduced in contrastive learning: Cross
Permutation Contrasting (CPC) and Relative Order Reasoning (ROR). In
optimization, CPC learns intra-class similarities by contrasting
representations of the same action class across different permutations, while
ROR reasons about inter-class contexts by predicting relative mapping between
two permutations. Together, these tasks enable a Dual-Surrogate Contrastive
Learning (DuoCLR) network to learn multi-scale feature representations
optimized for action segmentation. In experiments, DuoCLR is pre-trained on a
trimmed skeleton dataset and evaluated on an untrimmed dataset where it
demonstrates a significant boost over state-the-art comparatives in both
multi-class and multi-label action segmentation tasks. Lastly, ablation studies
are conducted to evaluate the effectiveness of each component of the proposed
approach.

</details>


### [30] [RED: Robust Event-Guided Motion Deblurring with Modality-Specific Disentangled Representation](https://arxiv.org/abs/2509.05554)
*Yihong Leng,Siming Zheng,Jinwei Chen,Bo Li,Jiaojiao Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 事件相机数据稀疏但时间分辨率高，在运动去模糊方面潜力巨大。现有方法忽视了事件流因传感器阈值机制导致的噪声和灵敏度之间的权衡而产生的固有不完整性。为了解决这些问题，我们提出了一种具有特定模态解耦表示的鲁棒事件引导去模糊（RED）网络。通过引入鲁棒性导向扰动策略（RPS）来暴露RED于不完整模式，并进行解耦全向注意力建模，最后通过两个交互模块来增强模糊图像中的运动敏感区域并为不完整的事件表示注入语义。实验证明RED在准确性和鲁棒性方面均达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据稀疏但时间分辨率高，在运动去模糊方面潜力巨大。现有方法忽视了事件流因传感器阈值机制导致的噪声和灵敏度之间的权衡而产生的固有不完整性。这种降级会损害运动先验的完整性，并限制事件引导去模糊的有效性。

Method: 提出一种鲁棒事件引导去模糊（RED）网络，采用特定模态解耦表示。首先，引入鲁棒性导向扰动策略（RPS），通过随机掩码事件数据来暴露RED于不完整模式，从而培养其在各种未知场景条件下的鲁棒性。其次，提出解耦全向注意力机制，对来自两个固有不同但互补的源（模糊图像和部分中断的事件）的运动内、运动间和跨模态相关性进行显式建模。在此基础上，设计了两个交互模块，以增强模糊图像中的运动敏感区域，并为不完整的事件表示注入语义上下文。

Result: 在合成和真实世界数据集上的广泛实验表明，RED在准确性和鲁棒性方面持续 achieves  state-of-the-art performance。

Conclusion: 提出的RED网络通过鲁棒性导向扰动策略（RPS）和解耦全向注意力机制，有效解决了事件流不完整的问题，并在运动去模糊任务中取得了最先进的性能。

Abstract: Event cameras provide sparse yet temporally high-temporal-resolution motion
information, demonstrating great potential for motion deblurring. Existing
methods focus on cross-modal interaction, overlooking the inherent
incompleteness of event streams, which arises from the trade-off between
sensitivity and noise introduced by the thresholding mechanism of Dynamic
Vision Sensors (DVS). Such degradation compromises the integrity of motion
priors and limits the effectiveness of event-guided deblurring. To tackle these
challenges, we propose a Robust Event-guided Deblurring (RED) network with
modality-specific disentangled representation. First, we introduce a
Robustness-Oriented Perturbation Strategy (RPS) that applies random masking to
events, which exposes RED to incomplete patterns and then foster robustness
against various unknown scenario conditions.Next, a disentangled OmniAttention
is presented to explicitly model intra-motion, inter-motion, and cross-modality
correlations from two inherently distinct but complementary sources: blurry
images and partially disrupted events. Building on these reliable features, two
interactive modules are designed to enhance motion-sensitive areas in blurry
images and inject semantic context into incomplete event representations.
Extensive experiments on synthetic and real-world datasets demonstrate RED
consistently achieves state-of-the-art performance in both accuracy and
robustness.

</details>


### [31] [Sensitivity-Aware Post-Training Quantization for Deep Neural Networks](https://arxiv.org/abs/2509.05576)
*Zekang Zheng,Haokun Li,Yaofo Chen,Mingkui Tan,Qing Du*

Main category: cs.CV

TL;DR: 该模型量化方法通过优先量化高敏感度参数并利用低敏感度参数进行补偿，在保证准确率的同时，通过行并行量化框架和全局共享的逆海森矩阵更新机制，实现了比现有方法快20-200倍的量化速度，准确率损失低于0.3%。


<details>
  <summary>Details</summary>
Motivation: 现有模型量化方法（PTQ）在提高压缩率时常牺牲准确率，且迭代更新参数的方法计算复杂、资源开销大，限制了其在资源受限场景下的应用。

Method: 提出一种基于参数敏感度分析的PTQ方法，优先量化高敏感度参数，并利用未量化的低敏感度参数补偿量化误差。结合参数敏感度的列簇，引入行并行量化框架和全局共享的逆海森矩阵更新机制。

Result: 在ResNet-50和YOLOv5s上的实验结果显示，相比Optimal Brain Quantization基线，量化速度提升20-200倍，平均准确率损失低于0.3%。

Conclusion: 该方法能在效率和准确率之间取得良好平衡，有效解决了现有PTQ方法在资源受限和实时推理场景下的局限性。

Abstract: Model quantization reduces neural network parameter precision to achieve
compression, but often compromises accuracy. Existing post-training
quantization (PTQ) methods employ iterative parameter updates to preserve
accuracy under high compression ratios, incurring significant computational
complexity and resource overhead, which limits applicability in
resource-constrained edge computing and real-time inference scenarios. This
paper proposes an efficient PTQ method guided by parameter sensitivity
analysis. The approach prioritizes quantization of high-sensitivity parameters,
leveraging unquantized low-sensitivity parameters to compensate for
quantization errors, thereby mitigating accuracy degradation. Furthermore, by
exploiting column-wise clustering of parameter sensitivity, the method
introduces a row-parallel quantization framework with a globally shared inverse
Hessian matrix update mechanism, reducing computational complexity by an order
of magnitude. Experimental results on ResNet-50 and YOLOv5s demonstrate a
20-200-fold quantization speedup over the Optimal Brain Quantization baseline,
with mean accuracy loss below 0.3%, confirming the method's efficacy in
balancing efficiency and accuracy.

</details>


### [32] [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](https://arxiv.org/abs/2509.05582)
*Zhiling Ye,Cong Zhou,Xiubao Zhang,Haifeng Shen,Weihong Deng,Quan Lu*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯表示的可控三维头部头像生成框架，仅需单张肖像照即可生成。


<details>
  <summary>Details</summary>
Motivation: 为了实现单张肖像照生成可控三维头部头像，并提高泛化能力和高频纹理重建效果。

Method: 利用WebSSL构建了一站式高斯头部生成器，并采用两阶段训练方法。推理时，使用由控制信号驱动的超轻量级高斯头像进行高帧率渲染。

Result: 实现了90 FPS（512x512分辨率）的渲染速度，并通过实验验证了该框架遵循缩放定律，且分离式设计不影响驱动效率。

Conclusion: 该方法在定量和定性实验中均优于现有最先进方法，成功实现了高效、高质量的可控三维头部头像生成。

Abstract: In this paper, we explore a reconstruction and reenactment separated
framework for 3D Gaussians head, which requires only a single portrait image as
input to generate controllable avatar. Specifically, we developed a large-scale
one-shot gaussian head generator built upon WebSSL and employed a two-stage
training approach that significantly enhances the capabilities of
generalization and high-frequency texture reconstruction. During inference, an
ultra-lightweight gaussian avatar driven by control signals enables high
frame-rate rendering, achieving 90 FPS at a resolution of 512x512. We further
demonstrate that the proposed framework follows the scaling law, whereby
increasing the parameter scale of the reconstruction module leads to improved
performance. Moreover, thanks to the separation design, driving efficiency
remains unaffected. Finally, extensive quantitative and qualitative experiments
validate that our approach outperforms current state-of-the-art methods.

</details>


### [33] [MFFI: Multi-Dimensional Face Forgery Image Dataset for Real-World Scenarios](https://arxiv.org/abs/2509.05592)
*Changtao Miao,Yi Zhang,Man Luo,Weiwei Feng,Kaiyuan Zheng,Qi Chu,Tao Gong,Jianshu Li,Yunfeng Diao,Wei Zhou,Joey Tianyi Zhou,Xiaoshuai Hao*

Main category: cs.CV

TL;DR: 该论文提出了MFFI数据集，用于解决当前Deepfake检测方法在真实世界场景中面临的数据集局限性问题。


<details>
  <summary>Details</summary>
Motivation: 当前Deepfake检测方法受限于现有数据集，这些数据集缺乏真实世界场景所需的 andvanced forgery techniques, variability of facial scenes, richness of real data, and degradation of real-world propagation 等方面的多样性。

Method: 提出了MFFI（Multi-dimensional Face Forgery Image）数据集，该数据集通过整合50种不同的伪造方法、多样的面部场景、丰富的真实数据和多层次的降级操作来增强真实性，包含1024K个图像样本。

Result: MFFI数据集在场景复杂度、跨域泛化能力和检测难度梯度方面优于现有公开数据集。

Conclusion: MFFI数据集在模拟真实世界条件方面具有技术先进性和实用价值，并已在GitHub上公开。

Abstract: Rapid advances in Artificial Intelligence Generated Content (AIGC) have
enabled increasingly sophisticated face forgeries, posing a significant threat
to social security. However, current Deepfake detection methods are limited by
constraints in existing datasets, which lack the diversity necessary in
real-world scenarios. Specifically, these data sets fall short in four key
areas: unknown of advanced forgery techniques, variability of facial scenes,
richness of real data, and degradation of real-world propagation. To address
these challenges, we propose the Multi-dimensional Face Forgery Image
(\textbf{MFFI}) dataset, tailored for real-world scenarios. MFFI enhances
realism based on four strategic dimensions: 1) Wider Forgery Methods; 2) Varied
Facial Scenes; 3) Diversified Authentic Data; 4) Multi-level Degradation
Operations. MFFI integrates $50$ different forgery methods and contains $1024K$
image samples. Benchmark evaluations show that MFFI outperforms existing public
datasets in terms of scene complexity, cross-domain generalization capability,
and detection difficulty gradients. These results validate the technical
advance and practical utility of MFFI in simulating real-world conditions. The
dataset and additional details are publicly available at
{https://github.com/inclusionConf/MFFI}.

</details>


### [34] [Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization](https://arxiv.org/abs/2509.05604)
*Jungin Park,Jiyoung Lee,Kwanghoon Sohn*

Main category: cs.CV

TL;DR: VideoGraph使用语言引导的时空图模型来生成视频摘要，通过将对象和帧视为图节点，并利用语言查询来增强节点表示，从而实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的视频摘要方法主要关注帧之间的时间联系，忽略了视频中对象间的语义关系，并且语言引导的视频摘要方法需要对视频有全面的语言理解。本文旨在解决这些问题，提出一种能够考虑所有对象之间语义关系的方法。

Method: 本文将视频摘要视为一个语言引导的时空图建模问题，提出了递归时空图网络（VideoGraph）。该网络将视频中的对象和帧分别表示为空间图和时间图的节点。通过引入源自视频的语言查询来丰富节点表示，使得图节点包含语义知识，并利用递归策略来优化图结构并分类关键帧。

Result: VideoGraph在通用和面向查询的视频摘要任务上，在监督和无监督设置下，都在多个基准测试中取得了最先进的性能。

Conclusion: VideoGraph成功地将语言引导的时空图建模应用于视频摘要任务，通过整合对象间的语义关系和语言理解，显著提高了摘要的质量和相关性。

Abstract: Video summarization aims to select keyframes that are visually diverse and
can represent the whole story of a given video. Previous approaches have
focused on global interlinkability between frames in a video by temporal
modeling. However, fine-grained visual entities, such as objects, are also
highly related to the main content of the video. Moreover, language-guided
video summarization, which has recently been studied, requires a comprehensive
linguistic understanding of complex real-world videos. To consider how all the
objects are semantically related to each other, this paper regards video
summarization as a language-guided spatiotemporal graph modeling problem. We
present recursive spatiotemporal graph networks, called VideoGraph, which
formulate the objects and frames as nodes of the spatial and temporal graphs,
respectively. The nodes in each graph are connected and aggregated with graph
edges, representing the semantic relationships between the nodes. To prevent
the edges from being configured with visual similarity, we incorporate language
queries derived from the video into the graph node representations, enabling
them to contain semantic knowledge. In addition, we adopt a recursive strategy
to refine initial graphs and correctly classify each frame node as a keyframe.
In our experiments, VideoGraph achieves state-of-the-art performance on several
benchmarks for generic and query-focused video summarization in both supervised
and unsupervised manners. The code is available at
https://github.com/park-jungin/videograph.

</details>


### [35] [Patch-level Kernel Alignment for Self-Supervised Dense Representation Learning](https://arxiv.org/abs/2509.05606)
*Juan Yeo,Ijun Jang,Taesup Kim*

Main category: cs.CV

TL;DR: 文章提出了一种新的自监督学习框架，旨在改进图像的密集特征表示，以提升需要空间精度的视觉任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法主要关注全局图像表示，在捕捉密集预测任务所需的局部语义信息方面存在不足。

Method: 通过额外的自监督学习来改进预训练的表示，使之适用于密集特征空间。具体方法是引入了一种名为 Patch-level Kernel Alignment (PaKA) 的对齐目标，用于匹配教师-学生模型之间密集特征的统计依赖性和结构关系，并探索了适用于密集表示学习的数据增强策略。

Result: 在多项密集视觉基准测试中取得了最先进的成果，证明了该方法的有效性。

Conclusion: 所提出的框架通过对齐密集特征的分布，并结合 PaKA 和特定的数据增强策略，能够有效地将现有的语义知识迁移到密集特征空间，显著提升了密集视觉任务的性能。

Abstract: Dense representations are essential for vision tasks that require spatial
precision and fine-grained detail. While most self-supervised representation
learning methods focus on global representations that summarize the image as a
whole, such approaches often fall short in capturing the localized semantics
necessary for dense prediction tasks. To overcome these limitations, we propose
a framework that builds on pretrained representations through additional
self-supervised learning, aiming to transfer existing semantic knowledge into
the dense feature space. Our method aligns the distributions of dense features
between a teacher and a student model. Specifically, we introduce Patch-level
Kernel Alignment (PaKA), a simple yet effective alignment objective that
captures statistical dependencies, thereby matching the structural
relationships of dense patches across the two models. In addition, we
investigate augmentation strategies specifically designed for dense
representation learning. Our framework achieves state-of-the-art results across
a variety of dense vision benchmarks, demonstrating the effectiveness of our
approach.

</details>


### [36] [SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning](https://arxiv.org/abs/2509.05614)
*Hanzhen Wang,Jiaming Xu,Jiayi Pan,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecPrune-VLA是一种训练无关的方法，通过结合局部和全局上下文信息进行更智能的令牌选择，在保持高成功率的同时，显著加快了视觉-语言-动作（VLA）模型的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在修剪VLA模型时仅使用当前动作的局部信息，忽略了先前动作的全局上下文，导致成功率下降和加速效果有限。

Method: SpecPrune-VLA采用两级修剪和启发式控制：1. 静态修剪（动作级别）：结合全局历史和局部上下文来减少每个动作的视觉令牌。2. 动态修剪（层级别）：根据特定层的令牌重要性进行修剪。3. 轻量级动作感知控制器：根据动作的粗粒度/细粒度（通过速度判断）调整修剪的激进程度，因为细粒度动作对修剪更敏感。

Result: 在LIBERO数据集上的实验表明，与OpenVLA-OFT相比，SpecPrune-VLA在NVIDIA A800上实现了1.46倍的加速，在NVIDIA GeForce RTX 3090上实现了1.57倍的加速，同时成功率损失可忽略不计。

Conclusion: SpecPrune-VLA通过利用局部和全局信息进行更智能的令牌选择，有效地解决了现有VLA模型修剪方法的局限性，实现了显著的加速，同时保持了模型的性能。

Abstract: Pruning accelerates compute-bound models by reducing computation. Recently
applied to Vision-Language-Action (VLA) models, existing methods prune tokens
using only local info from current action, ignoring global context from prior
actions, causing >20% success rate drop and limited speedup. We observe high
similarity across consecutive actions and propose leveraging both local
(current) and global (past) info for smarter token selection. We introduce
SpecPrune-VLA, a training-free method with two-level pruning and heuristic
control: (1) Static pruning at action level: uses global history and local
context to reduce visual tokens per action; (2) Dynamic pruning at layer level:
prunes tokens per layer based on layer-specific importance; (3) Lightweight
action-aware controller: classifies actions as coarse/fine-grained (by speed),
adjusting pruning aggressiveness since fine-grained actions are
pruning-sensitive. Experiments on LIBERO show SpecPrune-VLA achieves 1.46 times
speedup on NVIDIA A800 and 1.57 times on NVIDIA GeForce RTX 3090 vs.
OpenVLA-OFT, with negligible success rate loss.

</details>


### [37] [High-Quality Tomographic Image Reconstruction Integrating Neural Networks and Mathematical Optimization](https://arxiv.org/abs/2509.06082)
*Anuraag Mishra,Andrea Gilch,Benjamin Apeleo Zubiri,Jan Rolfes,Frauke Liers*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的投影断层成像重建新方法，特别优化于具有清晰边缘的均质材料样本，通过训练神经网络识别边缘并将其集成到优化模型中，有效减少伪影并提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高投影型纳米和微米断层成像技术对由均质材料相组成且相间具有锐利边缘的样品的重建质量。

Method: 训练一个神经网络来识别子图像中的边缘，并将该网络集成到一个数学优化模型中，该模型在进行重建时优先考虑学习到的边缘信息，同时也能根据原始数据进行调整，以减少重建中的伪影。

Result: 该技术在实验数据集上的结果显示，与基准算法相比，界面清晰度和材料均质性得到了显著提升，有效消除了重建过程中的模糊现象。

Conclusion: 所提出的技术成功地结合了样本的均质性和锐利边缘的知识，能够生成高质量的重建图像，有望推动断层成像技术的发展。

Abstract: In this work, we develop a novel technique for reconstructing images from
projection-based nano- and microtomography. Our contribution focuses on
enhancing reconstruction quality, particularly for specimen composed of
homogeneous material phases connected by sharp edges. This is accomplished by
training a neural network to identify edges within subpictures. The trained
network is then integrated into a mathematical optimization model, to reduce
artifacts from previous reconstructions. To this end, the optimization approach
favors solutions according to the learned predictions, however may also
determine alternative solutions if these are strongly supported by the raw
data. Hence, our technique successfully incorporates knowledge about the
homogeneity and presence of sharp edges in the sample and thereby eliminates
blurriness. Our results on experimental datasets show significant enhancements
in interface sharpness and material homogeneity compared to benchmark
algorithms. Thus, our technique produces high-quality reconstructions,
showcasing its potential for advancing tomographic imaging techniques.

</details>


### [38] [SuMa: A Subspace Mapping Approach for Robust and Effective Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.05625)
*Kien Nguyen,Anh Tran,Cuong Pham*

Main category: cs.CV

TL;DR: SuMa是一种新的概念擦除方法，可以有效且稳健地擦除狭窄概念（如版权角色或名人），同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法在鲁棒性和有效性方面存在不足，尤其是在处理版权角色或名人等狭窄概念时，这对于解决版权和法律问题至关重要。

Method: SuMa首先推导出表示要擦除概念的目标子空间，然后将其映射到最小化两个子空间之间距离的参考子空间，从而中和目标子空间。

Result: SuMa 在子类擦除、名人擦除、艺术风格擦除和实例擦除等任务中，实现了与最先进方法相当的图像质量和擦除效果。

Conclusion: SuMa 成功地解决了擦除狭窄概念的挑战，并在鲁棒性和有效性方面取得了显著的成果，同时保持了图像质量。

Abstract: The rapid growth of text-to-image diffusion models has raised concerns about
their potential misuse in generating harmful or unauthorized contents. To
address these issues, several Concept Erasure methods have been proposed.
However, most of them fail to achieve both robustness, i.e., the ability to
robustly remove the target concept., and effectiveness, i.e., maintaining image
quality. While few recent techniques successfully achieve these goals for NSFW
concepts, none could handle narrow concepts such as copyrighted characters or
celebrities. Erasing these narrow concepts is critical in addressing copyright
and legal concerns. However, erasing them is challenging due to their close
distances to non-target neighboring concepts, requiring finer-grained
manipulation. In this paper, we introduce Subspace Mapping (SuMa), a novel
method specifically designed to achieve both robustness and effectiveness in
easing these narrow concepts. SuMa first derives a target subspace representing
the concept to be erased and then neutralizes it by mapping it to a reference
subspace that minimizes the distance between the two. This mapping ensures the
target concept is robustly erased while preserving image quality. We conduct
extensive experiments with SuMa across four tasks: subclass erasure, celebrity
erasure, artistic style erasure, and instance erasure and compare the results
with current state-of-the-art methods. Our method achieves image quality
comparable to approaches focused on effectiveness, while also yielding results
that are on par with methods targeting completeness.

</details>


### [39] [Self-supervised Learning for Hyperspectral Images of Trees](https://arxiv.org/abs/2509.05630)
*Moqsadur Rahman,Saurav Kumar,Santosh S. Palmate,M. Shahriar Hossain*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Aerial remote sensing using multispectral and RGB imagers has provided a
critical impetus to precision agriculture. Analysis of the hyperspectral images
with limited or no labels is challenging. This paper focuses on self-supervised
learning to create neural network embeddings reflecting vegetation properties
of trees from aerial hyperspectral images of crop fields. Experimental results
demonstrate that a constructed tree representation, using a vegetation
property-related embedding space, performs better in downstream machine
learning tasks compared to the direct use of hyperspectral vegetation
properties as tree representations.

</details>


### [40] [Evaluating YOLO Architectures: Implications for Real-Time Vehicle Detection in Urban Environments of Bangladesh](https://arxiv.org/abs/2509.05652)
*Ha Meem Hossain,Pritam Nath,Mahitun Nesa Mahi,Imtiaz Uddin,Ishrat Jahan Eiste,Syed Nasibur Rahman Ratul,Md Naim Uddin Mozumdar,Asif Mohammed Saad*

Main category: cs.CV

TL;DR: 使用YOLO模型对孟加拉国特有车型进行车辆检测，YOLOv11x表现最佳但推理时间长，YOLOv8m和YOLOv11m在性能和速度间取得平衡，但稀有车型和视觉相似车型存在检测挑战。


<details>
  <summary>Details</summary>
Motivation: 由于孟加拉国独特的道路环境和本地车型，在非孟加拉国数据集上训练的车辆检测系统难以准确识别本地车辆，这给该区域的自动驾驶技术带来了挑战。

Method: 使用包含29种车辆类别（包括“Desi Nosimon”、“Leguna”、“Battery Rickshaw”和“CNG”等本地车型）的自定义数据集，评估了六种YOLO模型变体。该数据集包含使用手机摄像头在孟加拉国不同道路上拍摄的高分辨率图像（1920x1080），并使用LabelImg工具以YOLO格式进行手动标注。

Result: YOLOv11x是最佳模型，mAP@0.5为63.7%，mAP@0.5:0.95为43.8%，召回率为61.4%，F1分数为61.6%，但推理时间为45.8毫秒。YOLOv8m和YOLOv11m在中等模型中表现最佳，mAP@0.5分别为62.5%和61.8%，推理时间约为14-15毫秒。稀有车型（如建筑车辆和Desi Nosimon）由于数据不平衡和样本不足，准确率接近于零。混淆矩阵显示，视觉上相似的车型（如小型卡车和小型厢式货车）之间存在频繁的错误分类。

Conclusion: 该研究为开发专门适应孟加拉国交通状况的鲁棒目标检测系统奠定了基础，解决了在传统通用训练模型表现不佳的发展中地区，自动驾驶技术进步的关键需求。

Abstract: Vehicle detection systems trained on Non-Bangladeshi datasets struggle to
accurately identify local vehicle types in Bangladesh's unique road
environments, creating critical gaps in autonomous driving technology for
developing regions. This study evaluates six YOLO model variants on a custom
dataset featuring 29 distinct vehicle classes, including region-specific
vehicles such as ``Desi Nosimon'', ``Leguna'', ``Battery Rickshaw'', and
``CNG''. The dataset comprises high-resolution images (1920x1080) captured
across various Bangladeshi roads using mobile phone cameras and manually
annotated using LabelImg with YOLO format bounding boxes. Performance
evaluation revealed YOLOv11x as the top performer, achieving 63.7\% mAP@0.5,
43.8\% mAP@0.5:0.95, 61.4\% recall, and 61.6\% F1-score, though requiring 45.8
milliseconds per image for inference. Medium variants (YOLOv8m, YOLOv11m)
struck an optimal balance, delivering robust detection performance with mAP@0.5
values of 62.5\% and 61.8\% respectively, while maintaining moderate inference
times around 14-15 milliseconds. The study identified significant detection
challenges for rare vehicle classes, with Construction Vehicles and Desi
Nosimons showing near-zero accuracy due to dataset imbalances and insufficient
training samples. Confusion matrices revealed frequent misclassifications
between visually similar vehicles, particularly Mini Trucks versus Mini Covered
Vans. This research provides a foundation for developing robust object
detection systems specifically adapted to Bangladesh traffic conditions,
addressing critical needs in autonomous vehicle technology advancement for
developing regions where conventional generic-trained models fail to perform
adequately.

</details>


### [41] [EditIDv2: Editable ID Customization with Data-Lubricated ID Feature Integration for Text-to-Image Generation](https://arxiv.org/abs/2509.05659)
*Guandong Li,Zhaobin Chu*

Main category: cs.CV

TL;DR: EditIDv2 是一种无需微调的解决方案，适用于高复杂度叙事场景和长文本输入，通过改进 ID 特征整合模块，在复杂叙事环境中实现深度、多层次语义编辑，同时保持身份一致性，并满足长提示和高质量图像生成的需求。


<details>
  <summary>Details</summary>
Motivation: 现有角色编辑方法在简单提示下表现良好，但在处理包含多语义层、时间逻辑和复杂上下文关系的长文本叙事时，编辑能力会下降，存在语义理解偏差和身份一致性问题。

Method: EditIDv2 通过对 Perceiver Attention 进行复杂分解，引入 ID 损失和与扩散模型的联合动态训练，以及对整合模块采用离线融合策略，解决了最小数据润滑下的可编辑性注入问题。

Result: EditIDv2 在满足长提示和高质量图像生成需求的同时，在 IBench 评估中取得了优异的成绩，实现了复杂的深度多层次语义编辑，并保持了身份一致性。

Conclusion: EditIDv2 成功解决了长文本叙事和复杂场景下的角色编辑问题，通过创新的方法在有限数据下实现了高质量、身份一致的图像生成。

Abstract: We propose EditIDv2, a tuning-free solution specifically designed for
high-complexity narrative scenes and long text inputs. Existing character
editing methods perform well under simple prompts, but often suffer from
degraded editing capabilities, semantic understanding biases, and identity
consistency breakdowns when faced with long text narratives containing multiple
semantic layers, temporal logic, and complex contextual relationships. In
EditID, we analyzed the impact of the ID integration module on editability. In
EditIDv2, we further explore and address the influence of the ID feature
integration module. The core of EditIDv2 is to discuss the issue of editability
injection under minimal data lubrication. Through a sophisticated decomposition
of PerceiverAttention, the introduction of ID loss and joint dynamic training
with the diffusion model, as well as an offline fusion strategy for the
integration module, we achieve deep, multi-level semantic editing while
maintaining identity consistency in complex narrative environments using only a
small amount of data lubrication. This meets the demands of long prompts and
high-quality image generation, and achieves excellent results in the IBench
evaluation.

</details>


### [42] [OOTSM: A Decoupled Linguistic Framework for Effective Scene Graph Anticipation](https://arxiv.org/abs/2509.05661)
*Xiaomeng Zhu,Changwei Wang,Haozhe Wang,Xinyu Liu,Fangzhen Lin*

Main category: cs.CV

TL;DR: 该研究提出了一种名为语言场景图预测 (LSGA) 的新方法，用于预测视频剪辑的未来场景图，重点在于利用常识知识。LSGA 将任务分解为两步：首先，使用场景图捕获模型将视频转换为场景图序列；然后，使用纯文本模型进行未来预测。LSGA 采用一种名为对象导向两阶段方法 (OOTSM) 的技术，其中大型语言模型 (LLM) 先预测对象的出现和消失，然后生成详细的人与对象关系。


<details>
  <summary>Details</summary>
Motivation: 现有的场景图预测 (SGA) 方法主要依赖视觉线索，难以整合常识知识，导致长期预测鲁棒性不足。本研究旨在明确利用常识知识来提升场景图预测的性能。

Method: LSGA 采用对象导向两阶段方法 (OOTSM)。首先，大型语言模型 (LLM) 预测对象在场景中的出现和消失，然后，LLM 生成详细的人与对象之间的关系。

Result: 在 LSGA 评估中，经过微调的开源 LLM 在 Action Genome 数据集上优于零样本 API（GPT-4o、GPT-4o-mini 和 DeepSeek-V3）。结合 OOTSM 和 STTran++ 进行 SGA 评估时，短期平均召回率（@10）提高了 3.4%，长期平均召回率（@50）显著提高了 21.9%。

Conclusion: 所提出的 LSGA 方法，特别是 OOTSM，能够有效利用常识知识来提高场景图预测的准确性，并在 SGA 任务中实现了最先进的性能。

Abstract: A scene graph is a structured represention of objects and their relationships
in a scene. Scene Graph Anticipation (SGA) involves predicting future scene
graphs from video clips, enabling applications as intelligent surveillance and
human-machine collaboration. Existing SGA approaches primarily leverage visual
cues, often struggling to integrate valuable commonsense knowledge, thereby
limiting long-term prediction robustness. To explicitly leverage such
commonsense knowledge, we propose a new approach to better understand the
objects, concepts, and relationships in a scene graph. Our approach decouples
the SGA task in two steps: first a scene graph capturing model is used to
convert a video clip into a sequence of scene graphs, then a pure text-based
model is used to predict scene graphs in future frames. Our focus in this work
is on the second step, and we call it Linguistic Scene Graph Anticipation
(LSGA) and believes it should have independent interest beyond the use in SGA
discussed here. For LSGA, we introduce an Object-Oriented Two-Staged Method
(OOTSM) where an Large Language Model (LLM) first forecasts object appearances
and disappearances before generating detailed human-object relations. We
conduct extensive experiments to evaluate OOTSM in two settings. For LSGA, we
evaluate our fine-tuned open-sourced LLMs against zero-shot APIs (i.e., GPT-4o,
GPT-4o-mini, and DeepSeek-V3) on a benchmark constructed from Action Genome
annotations. For SGA, we combine our OOTSM with STTran++ from, and our
experiments demonstrate effective state-of-the-art performance: short-term
mean-Recall (@10) increases by 3.4% while long-term mean-Recall (@50) improves
dramatically by 21.9%. Code is available at https://github.com/ZhuXMMM/OOTSM.

</details>


### [43] [WIPUNet: A Physics-inspired Network with Weighted Inductive Biases for Image Denoising](https://arxiv.org/abs/2509.05662)
*Wasikul Islam*

Main category: cs.CV

TL;DR: 本文将高能粒子物理中的“堆积”现象去除策略类比到图像去噪任务中，提出并验证了物理先验知识可以增强深度学习模型在强噪声下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高能粒子对撞机测量中的“堆积”现象会干扰信号，现有的去除策略利用了物理先验知识（如守恒、局部性和孤立性）。本文旨在探索将这些物理启发的先验知识融入神经网络架构，以改善图像去噪在强噪声下的鲁棒性。

Method: 本文提出了一系列受“堆积”现象启发的去噪器：一个带有守恒约束的残差卷积神经网络（CNN），其高斯噪声变体，以及一个将这些思想整合到U-Net骨干网络中的加权归纳堆积-物理启发U-Net去噪器（WIPUNet）。

Result: 在CIFAR-10数据集上，当高斯噪声标准差为$\{15, 25, 50, 75, 100\}$时，受“堆积”启发的CNN与标准基线方法相当，而WIPUNet在高噪声水平下表现出明显优势。在BSD500数据集上的实验也显示了同样的趋势，表明物理启发的先验知识能提高纯数据驱动模型的稳定性。

Conclusion: 本文成功地将“堆积”现象的缓解原理转化为模块化的归纳偏置，并将其整合到U-Net架构中。实验证明，在不依赖复杂的先进模型的情况下，该方法在高噪声场景下能有效提升去噪性能和鲁棒性。

Abstract: In high-energy particle physics, collider measurements are contaminated by
"pileup", overlapping soft interactions that obscure the hard-scatter signal of
interest. Dedicated subtraction strategies exploit physical priors such as
conservation, locality, and isolation. Inspired by this analogy, we investigate
how such principles can inform image denoising by embedding physics-guided
inductive biases into neural architectures. This paper is a proof of concept:
rather than targeting state-of-the-art (SOTA) benchmarks, we ask whether
physics-inspired priors improve robustness under strong corruption.
  We introduce a hierarchy of PU-inspired denoisers: a residual CNN with
conservation constraints, its Gaussian-noise variants, and the Weighted
Inductive Pileup-physics-inspired U-Network for Denoising (WIPUNet), which
integrates these ideas into a UNet backbone. On CIFAR-10 with Gaussian noise at
$\sigma\in\{15,25,50,75,100\}$, PU-inspired CNNs are competitive with standard
baselines, while WIPUNet shows a \emph{widening margin} at higher noise.
Complementary BSD500 experiments show the same trend, suggesting
physics-inspired priors provide stability where purely data-driven models
degrade. Our contributions are: (i) translating pileup-mitigation principles
into modular inductive biases; (ii) integrating them into UNet; and (iii)
demonstrating robustness gains at high noise without relying on heavy SOTA
machinery.

</details>


### [44] [AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care](https://arxiv.org/abs/2505.00275)
*Md Asaduzzaman Jabin,Hanqi Jiang,Yiwei Li,Patrick Kaggwa,Eugene Douglass,Juliet N. Sekandi,Tianming Liu*

Main category: cs.CV

TL;DR: AdCare-VLM是一个基于Video-LLaVA的多模态大模型，通过分析患者用药视频，提升了结核病药物依从性识别的准确性，并在LLM-TB-VQA数据集上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 慢性病患者需要严格遵医嘱用药，但患者行为、医疗费用和医疗设施不足等因素常导致用药依从性下降。本研究旨在通过多模态大模型解决这一问题。

Method: 研究提出AdCare-VLM模型，利用包含806个结核病（TB）用药监测视频的私有数据集进行微调，以检测用药依从性模式。该模型能够识别视频中的视觉特征（如面部、药物、饮水、吞咽动作）与字幕的医学概念之间的关联，并整合了视觉-语言表示，增强了多模态交互能力。同时，构建了LLM-TB-VQA数据集，包含正面、负面和模糊的用药依从性案例。

Result: 实验结果表明，AdCare-VLM在用药依从性识别任务上优于LLaVA-V1.5和Chat-UniVi等模型，在不同配置下准确率提升了3.1%至3.54%。消融研究和注意力图可视化验证了该方法的有效性和可解释性。

Conclusion: AdCare-VLM通过结合视觉和语言信息，有效提高了对结核病药物依从性的监测和评估能力，为慢性病用药管理提供了新的解决方案。

Abstract: Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS,
epilepsy, and tuberculosis, necessitate rigorous adherence to medication to
avert disease progression, manage symptoms, and decrease mortality rates.
Adherence is frequently undermined by factors including patient behavior,
caregiver support, elevated medical costs, and insufficient healthcare
infrastructure. We propose AdCare-VLM, a specialized Video-LLaVA-based
multimodal large vision language model (LVLM) aimed at visual question
answering (VQA) concerning medication adherence through patient videos. We
employ a private dataset comprising 806 custom-annotated tuberculosis (TB)
medication monitoring videos, which have been labeled by clinical experts, to
fine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a
detailed medical adherence VQA dataset that encompasses positive, negative, and
ambiguous adherence cases. Our method identifies correlations between visual
features, such as the clear visibility of the patient's face, medication, water
intake, and the act of ingestion, and their associated medical concepts in
captions. This facilitates the integration of aligned visual-linguistic
representations and improves multimodal interactions. Experimental results
indicate that our method surpasses parameter-efficient fine-tuning (PEFT)
enabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute
improvements ranging from 3.1% to 3.54% across pre-trained, regular, and
low-rank adaptation (LoRA) configurations. Comprehensive ablation studies and
attention map visualizations substantiate our approach, enhancing
interpretability.

</details>


### [45] [Context-Aware Multi-Turn Visual-Textual Reasoning in LVLMs via Dynamic Memory and Adaptive Visual Guidance](https://arxiv.org/abs/2509.05669)
*Weijie Shen,Xinrui Wang,Yuanqi Nie,Apiradee Boonmee*

Main category: cs.CV

TL;DR: CAMVR是一个创新的框架，通过引入视觉-文本上下文记忆单元（VCMU）和自适应视觉焦点引导（AVFG）机制，显著提升了大型语言模型（LVLM）在多轮视觉推理任务中的表现，解决了当前模型在多轮交互中存在的上下文丢失和推理碎片化等问题。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）和视觉-语言大型模型（LVLMs）在单轮任务中表现出色，但在需要深度上下文理解和复杂视觉推理的多轮交互中面临严峻挑战，常常导致推理碎片化、上下文丢失和幻觉。为解决这些限制，本研究提出了一种新颖的框架。

Method: CAMVR框架引入了两个关键创新：1. 视觉-文本上下文记忆单元（VCMU），一个动态读写记忆网络，用于存储和管理每次交互轮次中的关键视觉特征、文本语义表示及其跨模态对应关系。2. 自适应视觉焦点引导（AVFG）机制，该机制利用VCMU的上下文动态调整视觉编码器对与上下文相关的图像区域的注意力。此外，研究采用多层次推理整合策略，确保响应生成与当前输入和累积的历史上下文深度一致。

Result: 在VisDial、A-OKVQA（经过改编）以及新提出的多轮指令遵循（MTIF）数据集等具有挑战性的数据集上进行的大量实验表明，CAMVR始终 achieves state-of-the-art performance。

Conclusion: CAMVR通过其创新的VCMU和AVFG机制，有效地增强了LVLM的多轮视觉推理能力，克服了现有模型的局限性，并在多个数据集上取得了优越的性能。

Abstract: Current Large Language Models (LLMs) and Vision-Language Large Models (LVLMs)
excel in single-turn tasks but face significant challenges in multi-turn
interactions requiring deep contextual understanding and complex visual
reasoning, often leading to fragmented reasoning, context loss, and
hallucinations. To address these limitations, we propose Context-Aware
Multi-Turn Visual Reasoning (CAMVR), a novel framework designed to empower
LVLMs with robust and coherent multi-turn visual-textual inference
capabilities. CAMVR introduces two key innovations: a Visual-Textual Context
Memory Unit (VCMU), a dynamic read-write memory network that stores and manages
critical visual features, textual semantic representations, and their
cross-modal correspondences from each interaction turn; and an Adaptive Visual
Focus Guidance (AVFG) mechanism, which leverages the VCMU's context to
dynamically adjust the visual encoder's attention to contextually relevant
image regions. Our multi-level reasoning integration strategy ensures that
response generation is deeply coherent with both current inputs and accumulated
historical context. Extensive experiments on challenging datasets, including
VisDial, an adapted A-OKVQA, and our novel Multi-Turn Instruction Following
(MTIF) dataset, demonstrate that CAMVR consistently achieves state-of-the-art
performance.

</details>


### [46] [MeshMetrics: A Precise Implementation of Distance-Based Image Segmentation Metrics](https://arxiv.org/abs/2509.05670)
*Gašper Podobnik,Tomaž Vrtovec*

Main category: cs.CV

TL;DR: 图像分割中的可复现性危机源于评估指标的不稳定，尤其是在基于距离的度量实现上。MeshMetrics 框架通过基于网格的方法提高了计算精度，解决了现有工具的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有图像分割研究在性能评估方面存在可复现性危机，特别是在距离度量实现的准确性方面，不同开源工具之间存在显著差异。

Method: 提出 MeshMetrics，一个基于网格的框架，用于更精确地计算距离度量，并通过理论分析和实证验证其准确性和精确性，并减少离散化伪影的影响。

Result: MeshMetrics 框架相比现有工具，在准确性和精确性方面表现更优，且在处理离散化伪影方面具有优势。

Conclusion: MeshMetrics 框架通过提供更精确的距离度量计算，有助于解决图像分割领域的可复现性危机，并已开源供社区使用。

Abstract: The surge of research in image segmentation has yielded remarkable
performance gains but also exposed a reproducibility crisis. A major
contributor is performance evaluation, where both selection and implementation
of metrics play critical roles. While recent efforts have improved the former,
the reliability of metric implementation has received far less attention.
Pitfalls in distance-based metric implementation can lead to considerable
discrepancies between common open-source tools, for instance, exceeding 100 mm
for the Hausdorff distance and 30%pt for the normalized surface distance for
the same pair of segmentations. To address these pitfalls, we introduce
MeshMetrics, a mesh-based framework that provides a more precise computation of
distance-based metrics than conventional grid-based approaches. Through
theoretical analysis and empirical validation, we demonstrate that MeshMetrics
achieves higher accuracy and precision than established tools, and is
substantially less affected by discretization artifacts, such as distance
quantization. We release MeshMetrics as an open-source Python package,
available at https://github.com/gasperpodobnik/MeshMetrics.

</details>


### [47] [Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization](https://arxiv.org/abs/2509.05695)
*Jingwei Peng,Zhixuan Qiu,Boyu Jin,Surasakdi Siripong*

Main category: cs.CV

TL;DR: 本研究提出LVLM-VAR框架，利用视觉语言大模型（LVLMs）进行视频动作识别，通过VST模块将视频转化为语义动作令牌，并结合LLaVA-13B模型进行动作分类和推理，在NTU RGB+D等基准测试中取得了先进性能，并提高了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的人类动作识别方法在深度语义理解、复杂上下文信息和细粒度区分方面存在不足，难以处理多样化的视频数据。

Method: 提出LVLM-VAR框架，包含视频到语义令牌（VST）模块，将视频序列转化为离散的、语义和时间上一致的“语义动作令牌”，构建“动作叙事”，并结合自然语言指令，由LoRA微调的LVLM（如LLaVA-13B）进行处理。

Result: 在NTU RGB+D和NTU RGB+D 120等数据集上取得了最先进或具有竞争力的性能，例如在NTU RGB+D X-Sub上达到94.1%，在NTU RGB+D 120 X-Set上达到90.0%。

Conclusion: LVLM-VAR框架在提高视频动作识别准确性的同时，通过生成自然语言解释，显著增强了模型的可解释性。

Abstract: Human action recognition often struggles with deep semantic understanding,
complex contextual information, and fine-grained distinction, limitations that
traditional methods frequently encounter when dealing with diverse video data.
Inspired by the remarkable capabilities of large language models, this paper
introduces LVLM-VAR, a novel framework that pioneers the application of
pre-trained Vision-Language Large Models (LVLMs) to video action recognition,
emphasizing enhanced accuracy and interpretability. Our method features a
Video-to-Semantic-Tokens (VST) Module, which innovatively transforms raw video
sequences into discrete, semantically and temporally consistent "semantic
action tokens," effectively crafting an "action narrative" that is
comprehensible to an LVLM. These tokens, combined with natural language
instructions, are then processed by a LoRA-fine-tuned LVLM (e.g., LLaVA-13B)
for robust action classification and semantic reasoning. LVLM-VAR not only
achieves state-of-the-art or highly competitive performance on challenging
benchmarks such as NTU RGB+D and NTU RGB+D 120, demonstrating significant
improvements (e.g., 94.1% on NTU RGB+D X-Sub and 90.0% on NTU RGB+D 120 X-Set),
but also substantially boosts model interpretability by generating natural
language explanations for its predictions.

</details>


### [48] [JRN-Geo: A Joint Perception Network based on RGB and Normal images for Cross-view Geo-localization](https://arxiv.org/abs/2509.05696)
*Hongyu Zhou,Yunzhou Zhang,Tingsong Huang,Fawei Ge,Man Qi,Xichen Zhang,Yizhong Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为JRN-Geo的新型跨视图地理定位方法，通过融合RGB图像和法线图像的几何结构信息，有效解决了无人机定位中视图差异和外观变化带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图地理定位方法主要依赖RGB图像的语义特征，忽略了空间结构信息在不变特征提取中的重要性。本研究旨在通过结合几何结构信息来解决这一问题。

Method: 提出了一种名为JRN-Geo的联合感知网络，采用双分支特征提取框架。该网络利用差异感知融合模块（DAFM）和联合约束交互聚合（JCIA）策略，实现RGB和法线图像之间深层融合以及联合约束的语义和结构信息表示。此外，还提出了一种3D地理增强技术来生成多视图样本，以增强网络学习不变特征的能力。

Result: 在University-1652和SUES-200数据集上的广泛实验表明，JRN-Geo方法在应对复杂视图变化方面具有鲁棒性，并取得了最先进的性能。

Conclusion: JRN-Geo通过融合几何结构信息和采用创新的网络模块及数据增强技术，显著提高了跨视图地理定位的准确性和鲁棒性，克服了现有方法的局限性。

Abstract: Cross-view geo-localization plays a critical role in Unmanned Aerial Vehicle
(UAV) localization and navigation. However, significant challenges arise from
the drastic viewpoint differences and appearance variations between images.
Existing methods predominantly rely on semantic features from RGB images, often
neglecting the importance of spatial structural information in capturing
viewpoint-invariant features. To address this issue, we incorporate geometric
structural information from normal images and introduce a Joint perception
network to integrate RGB and Normal images (JRN-Geo). Our approach utilizes a
dual-branch feature extraction framework, leveraging a Difference-Aware Fusion
Module (DAFM) and Joint-Constrained Interaction Aggregation (JCIA) strategy to
enable deep fusion and joint-constrained semantic and structural information
representation. Furthermore, we propose a 3D geographic augmentation technique
to generate potential viewpoint variation samples, enhancing the network's
ability to learn viewpoint-invariant features. Extensive experiments on the
University-1652 and SUES-200 datasets validate the robustness of our method
against complex viewpoint ariations, achieving state-of-the-art performance.

</details>


### [49] [Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis](https://arxiv.org/abs/2509.05703)
*Ragib Amin Nihal,Benjamin Yen,Takeshi Ashizawa,Kazuhiro Nakadai*

Main category: cs.CV

TL;DR: VLMs can interpret marine mammal vocalization spectrograms and integrate with LLMs for domain knowledge, enabling adaptation to acoustic data without manual annotation.


<details>
  <summary>Details</summary>
Motivation: Current marine mammal vocalization analysis relies on spectrograms, but VLMs are not trained on this domain-specific data. The paper investigates if VLMs can visually extract patterns from these spectrograms.

Method: The framework combines VLM interpretation of spectrograms with LLM-based validation to build domain knowledge, allowing adaptation to acoustic data without manual annotation or retraining.

Result: The research demonstrates that VLMs can be adapted to interpret spectrograms, and this interpretation can be validated by LLMs to build domain knowledge.

Conclusion: The proposed framework enables adaptation to acoustic data by leveraging VLMs for visual interpretation and LLMs for validation, bypassing the need for manual annotation or model retraining.

Abstract: Marine mammal vocalization analysis depends on interpreting bioacoustic
spectrograms. Vision Language Models (VLMs) are not trained on these
domain-specific visualizations. We investigate whether VLMs can extract
meaningful patterns from spectrograms visually. Our framework integrates VLM
interpretation with LLM-based validation to build domain knowledge. This
enables adaptation to acoustic data without manual annotation or model
retraining.

</details>


### [50] [LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction](https://arxiv.org/abs/2509.05728)
*Niels Balemans,Ali Anwar,Jan Steckel,Siegfried Mercelis*

Main category: cs.CV

TL;DR: 本研究在LiDAR-BIND框架基础上，通过引入时间嵌入相似性、运动对齐变换损失和窗口时间融合等机制，增强了多模态传感器（如雷达、声纳）与激光雷达之间的时序一致性，并优化了模型结构以保持空间结构。实验证明，改进后的LiDAR-BIND-T在雷达/声纳到激光雷达的转换任务中，显著提高了时间和空间连贯性，降低了绝对轨迹误差，并在基于Cartographer的SLAM中提升了占用栅格地图的精度。研究还提出了基于Fréchet Video Motion Distance（FVMD）和相关峰距离的新评价指标，以量化SLAM的时序质量。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决现有LiDAR-BIND框架在多模态传感器融合中对时序一致性处理不足的问题，通过引入新的机制来增强融合模型在时间维度上的稳定性和准确性，以提升下游SLAM任务的性能。

Method: 本研究提出了LiDAR-BIND-T，通过以下三个主要贡献来增强时序一致性：1. 时间嵌入相似性：对连续的时间嵌入进行对齐。2. 运动对齐变换损失：匹配预测值与真实激光雷达数据之间的位移。3. 窗口时间融合：利用专门的时间模块进行融合。此外，还更新了模型架构以更好地保留空间结构。

Result: 在雷达/声纳到激光雷达的转换评估中，LiDAR-BIND-T相比原模型，在时间和空间连贯性方面均有提升，表现为更低的绝对轨迹误差和在Cartographer-SLAM中更高的占用栅格地图精度。研究还提出了新的时序质量评价指标，如基于FVMD和相关峰距离的指标。

Conclusion: LiDAR-BIND-T在保持原有即插即用模态融合能力的同时，通过引入时间一致性机制，显著增强了模型的时序稳定性，从而提高了下游SLAM任务的鲁棒性和整体性能。

Abstract: This paper extends LiDAR-BIND, a modular multi-modal fusion framework that
binds heterogeneous sensors (radar, sonar) to a LiDAR-defined latent space,
with mechanisms that explicitly enforce temporal consistency. We introduce
three contributions: (i) temporal embedding similarity that aligns consecutive
latents, (ii) a motion-aligned transformation loss that matches displacement
between predictions and ground truth LiDAR, and (iii) windows temporal fusion
using a specialised temporal module. We further update the model architecture
to better preserve spatial structure. Evaluations on radar/sonar-to-LiDAR
translation demonstrate improved temporal and spatial coherence, yielding lower
absolute trajectory error and better occupancy map accuracy in
Cartographer-based SLAM (Simultaneous Localisation and Mapping). We propose
different metrics based on the Fr\'echet Video Motion Distance (FVMD) and a
correlation-peak distance metric providing practical temporal quality
indicators to evaluate SLAM performance. The proposed temporal LiDAR-BIND, or
LiDAR-BIND-T, maintains plug-and-play modality fusion while substantially
enhancing temporal stability, resulting in improved robustness and performance
for downstream SLAM.

</details>


### [51] [Multi-LVI-SAM: A Robust LiDAR-Visual-Inertial Odometry for Multiple Fisheye Cameras](https://arxiv.org/abs/2509.05740)
*Xinyu Zhang,Kai Huang,Junqiao Zhao,Zihan Yuan,Tiantian Feng*

Main category: cs.CV

TL;DR: 我们提出了一个名为 Multi-LVI-SAM 的多相机 LiDAR-视觉-惯性里程计框架，通过融合来自多个鱼眼摄像头、LiDAR 和惯性传感器的数据来实现高精度和鲁棒的状态估计。


<details>
  <summary>Details</summary>
Motivation: 为了实现多鱼眼摄像头视觉信息的有效和一致集成，我们提出了一个全景视觉特征模型，将多摄像头观测统一为单一表示。

Method: 全景模型作为一个全局几何优化框架，整合多视图约束，实现无缝的回环检测和全局姿态优化，并通过外部补偿方法解决了由相机与全景模型坐标系不对齐引起的三角测量不一致问题。我们将全景视觉特征模型集成到一个基于因子图的紧耦合 LiDAR-视觉-惯性系统中。

Result: 实验表明，全景视觉特征模型提高了多摄像头约束的质量和一致性，与现有的多摄像头 LiDAR-视觉-惯性系统相比，具有更高的精度和鲁棒性。

Conclusion: Multi-LVI-SAM 框架通过融合多传感器数据和创新的全景视觉特征模型，显著提高了状态估计的精度和鲁棒性，尤其在处理多摄像头系统时表现出色。

Abstract: We propose a multi-camera LiDAR-visual-inertial odometry framework,
Multi-LVI-SAM, which fuses data from multiple fisheye cameras, LiDAR and
inertial sensors for highly accurate and robust state estimation. To enable
efficient and consistent integration of visual information from multiple
fisheye cameras, we introduce a panoramic visual feature model that unifies
multi-camera observations into a single representation. The panoramic model
serves as a global geometric optimization framework that consolidates
multi-view constraints, enabling seamless loop closure and global pose
optimization, while simplifying system design by avoiding redundant handling of
individual cameras. To address the triangulation inconsistency caused by the
misalignment between each camera's frame and the panoramic model's frame, we
propose an extrinsic compensation method. This method improves feature
consistency across views and significantly reduces triangulation and
optimization errors, leading to more accurate pose estimation. We integrate the
panoramic visual feature model into a tightly coupled LiDAR-visual-inertial
system based on a factor graph. Extensive experiments on public datasets
demonstrate that the panoramic visual feature model enhances the quality and
consistency of multi-camera constraints, resulting in higher accuracy and
robustness than existing multi-camera LiDAR-visual-inertial systems.

</details>


### [52] [Depth-Aware Super-Resolution via Distance-Adaptive Variational Formulation](https://arxiv.org/abs/2509.05746)
*Tianhao Guo,Bingjie Lu,Feng Wang,Zhengyang Lu*

Main category: cs.CV

TL;DR: 提出了一种新颖的变分框架，用于解决单图像超分辨率中的空间不变退化模型假设的局限性，重点关注距离依赖效应。


<details>
  <summary>Details</summary>
Motivation: 传统单图像超分辨率方法假设空间不变的退化模型，未能处理真实世界成像系统中复杂的距离相关效应（如大气散射、景深变化、透视变形），因此需要能够理解场景几何并进行空间自适应重建的策略。

Method: 提出一个变分框架，将超分辨率视为空间变异逆问题，将退化算子构建为具有距离相关光谱特性的伪微分算子。通过级联残差块和深度条件卷积核实现离散梯度流动力学，并结合学习到的距离自适应正则化项，根据局部几何结构动态调整平滑度约束。光谱约束源于大气散射理论，防止远场区域的带宽违规和噪声放大。自适应核生成网络学习从深度到重建滤波器的连续映射。

Result: 在五个基准数据集上的评估显示，在KITTI户外场景下，2倍和4倍尺度上分别达到了36.89/0.9516和30.54/0.8721的PSNR/SSIM，性能优于现有方法0.44dB和0.36dB。

Conclusion: 该研究首次建立了具有理论基础的距离自适应超分辨率框架，在深度变化场景下取得了显著改进，同时在传统基准测试中保持了具有竞争力的性能。

Abstract: Single image super-resolution traditionally assumes spatially-invariant
degradation models, yet real-world imaging systems exhibit complex
distance-dependent effects including atmospheric scattering, depth-of-field
variations, and perspective distortions. This fundamental limitation
necessitates spatially-adaptive reconstruction strategies that explicitly
incorporate geometric scene understanding for optimal performance. We propose a
rigorous variational framework that characterizes super-resolution as a
spatially-varying inverse problem, formulating the degradation operator as a
pseudodifferential operator with distance-dependent spectral characteristics
that enable theoretical analysis of reconstruction limits across depth ranges.
Our neural architecture implements discrete gradient flow dynamics through
cascaded residual blocks with depth-conditional convolution kernels, ensuring
convergence to stationary points of the theoretical energy functional while
incorporating learned distance-adaptive regularization terms that dynamically
adjust smoothness constraints based on local geometric structure. Spectral
constraints derived from atmospheric scattering theory prevent bandwidth
violations and noise amplification in far-field regions, while adaptive kernel
generation networks learn continuous mappings from depth to reconstruction
filters. Comprehensive evaluation across five benchmark datasets demonstrates
state-of-the-art performance, achieving 36.89/0.9516 and 30.54/0.8721 PSNR/SSIM
at 2 and 4 scales on KITTI outdoor scenes, outperforming existing methods by
0.44dB and 0.36dB respectively. This work establishes the first
theoretically-grounded distance-adaptive super-resolution framework and
demonstrates significant improvements on depth-variant scenarios while
maintaining competitive performance across traditional benchmarks.

</details>


### [53] [Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation](https://arxiv.org/abs/2509.05751)
*Bingrui Zhao,Lin Yuanbo Wu,Xiangtian Fan,Deyin Liu,Lu Zhang,Ruyi He,Jialie Shen,Ximing Li*

Main category: cs.CV

TL;DR: 提出了一种名为PARSE-VOS的新型、无需训练的框架，利用大型语言模型（LLMs）实现跨文本和视频域的层级、粗到精推理，以解决视频对象分割中的文本-视觉对齐问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理复杂、组合性描述时，对静态文本与动态视觉内容的整体融合处理存在困难，尤其是在处理外观相似但运动和姿态不一致的对象时。

Method: 该方法首先将自然语言查询解析为结构化语义指令，然后利用一个时空定位模块生成所有潜在目标对象的候选轨迹，最后通过一个层级识别模块进行两阶段推理：粗粒度运动推理和（如有必要）细粒度姿态验证，以选择正确的对象并输出分割掩码。

Result: 在Ref-YouTube-VOS、Ref-DAVIS17和MeViS三个主要基准上实现了最先进的性能。

Conclusion: 所提出的PARSE-VOS框架通过利用LLM进行层级推理，有效解决了视频对象分割中的文本-视觉对齐挑战，并在多个基准上取得了优越的性能。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment an object of
interest throughout a video based on a language description. The prominent
challenge lies in aligning static text with dynamic visual content,
particularly when objects exhibiting similar appearances with inconsistent
motion and poses. However, current methods often rely on a holistic
visual-language fusion that struggles with complex, compositional descriptions.
In this paper, we propose \textbf{PARSE-VOS}, a novel, training-free framework
powered by Large Language Models (LLMs), for a hierarchical, coarse-to-fine
reasoning across text and video domains. Our approach begins by parsing the
natural language query into structured semantic commands. Next, we introduce a
spatio-temporal grounding module that generates all candidate trajectories for
all potential target objects, guided by the parsed semantics. Finally, a
hierarchical identification module select the correct target through a
two-stage reasoning process: it first performs coarse-grained motion reasoning
with an LLM to narrow down candidates; if ambiguity remains, a fine-grained
pose verification stage is conditionally triggered to disambiguate. The final
output is an accurate segmentation mask for the target object.
\textbf{PARSE-VOS} achieved state-of-the-art performance on three major
benchmarks: Ref-YouTube-VOS, Ref-DAVIS17, and MeViS.

</details>


### [54] [PictOBI-20k: Unveiling Large Multimodal Models in Visual Decipherment for Pictographic Oracle Bone Characters](https://arxiv.org/abs/2509.05773)
*Zijian Chen,Wenjie Hua,Jinhao Li,Lirong Deng,Fan Du,Tingzhu Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: 该论文提出了PictOBI-20k数据集，用于评估大型多模态模型（LMM）在甲骨文（OBC）视觉破译方面的能力，并发现现有LMM在利用视觉信息方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 甲骨文（OBC）是中国最古老的书写形式，其破译对于理解早期人类生产模式至关重要。然而，现有的破译方法受到考古发掘的零散性和铭文语料库的限制。大型多模态模型（LMM）强大的视觉感知能力为OBC的视觉破译提供了新的可能性。

Method: 本文介绍了PictOBI-20k数据集，该数据集包含2万张精心收集的甲骨文和真实物体图像，并构建了超过1.5万个选择题。此外，还进行了主观标注，以研究人类和LMM在视觉推理中的参考点一致性。

Result: 实验表明，通用LMM初步具备视觉破译能力，但它们未能有效利用视觉信息，并且在大多数情况下受到语言先验知识的限制。

Conclusion: PictOBI-20k数据集的发布旨在促进未来面向OBC的LMM在视觉注意力评估和优化方面的研究。

Abstract: Deciphering oracle bone characters (OBCs), the oldest attested form of
written Chinese, has remained the ultimate, unwavering goal of scholars,
offering an irreplaceable key to understanding humanity's early modes of
production. Current decipherment methodologies of OBC are primarily constrained
by the sporadic nature of archaeological excavations and the limited corpus of
inscriptions. With the powerful visual perception capability of large
multimodal models (LMMs), the potential of using LMMs for visually deciphering
OBCs has increased. In this paper, we introduce PictOBI-20k, a dataset designed
to evaluate LMMs on the visual decipherment tasks of pictographic OBCs. It
includes 20k meticulously collected OBC and real object images, forming over
15k multi-choice questions. We also conduct subjective annotations to
investigate the consistency of the reference point between humans and LMMs in
visual reasoning. Experiments indicate that general LMMs possess preliminary
visual decipherment skills, and LMMs are not effectively using visual
information, while most of the time they are limited by language priors. We
hope that our dataset can facilitate the evaluation and optimization of visual
attention in future OBC-oriented LMMs. The code and dataset will be available
at https://github.com/OBI-Future/PictOBI-20k.

</details>


### [55] [Posterior shape models revisited: Improving 3D reconstructions from partial data using target specific models](https://arxiv.org/abs/2509.05776)
*Jonathan Aellen,Florian Burkhardt,Thomas Vetter,Marcel Lüthi*

Main category: cs.CV

TL;DR: 通过调整现有模型以适应特定目标，可以提高部分形状重建的准确性。该方法计算效率高，并且不需要原始训练数据。


<details>
  <summary>Details</summary>
Motivation: 在医学成像中，点分布模型常用于重建和补全不完整形状，但训练数据的姿势与目标形状的对齐方式常被忽视，这可能导致重建结果出现偏差，尤其是在处理形状的局部时。

Method: 提出一种高效的方法来调整现有模型以适应特定的目标形状，该方法在保持线性模型计算效率的同时，能显著提高重建的准确性和预测方差。该方法能够精确地恢复平移情况下的目标对齐模型，并能很好地近似小旋转情况，而且不需要原始训练数据。

Result: 该方法计算效率高，且不需要原始训练数据，能够精确地恢复平移情况下的目标对齐模型，并能很好地近似小旋转情况。

Conclusion: 通过简单的预处理步骤即可适应重建流程中的现有形状模型，使得该方法具有广泛的即插即用适用性。

Abstract: In medical imaging, point distribution models are often used to reconstruct
and complete partial shapes using a statistical model of the full shape. A
commonly overlooked, but crucial factor in this reconstruction process, is the
pose of the training data relative to the partial target shape. A difference in
pose alignment of the training and target shape leads to biased solutions,
particularly when observing small parts of a shape. In this paper, we
demonstrate the importance of pose alignment for partial shape reconstructions
and propose an efficient method to adjust an existing model to a specific
target. Our method preserves the computational efficiency of linear models
while significantly improving reconstruction accuracy and predicted variance.
It exactly recovers the intended aligned model for translations, and provides a
good approximation for small rotations, all without access to the original
training data. Hence, existing shape models in reconstruction pipelines can be
adapted by a simple preprocessing step, making our approach widely applicable
in plug-and-play scenarios.

</details>


### [56] [3DPillars: Pillar-based two-stage 3D object detection](https://arxiv.org/abs/2509.05780)
*Jongyoun Noh,Junghyup Lee,Hyekang Park,Bumsub Ham*

Main category: cs.CV

TL;DR: 本文提出了一种改进PointPillars的两阶段3D目标检测框架，通过引入3DPillars网络和RoI头，在保持效率的同时提高了精度。


<details>
  <summary>Details</summary>
Motivation: PointPillars虽然高效但精度受限于伪图像表示无法保留精确3D结构以及难以采用两阶段检测流程。本文旨在弥合PointPillars与先进方法之间的性能差距，同时保持其效率。

Method: 提出了一种新的CNN架构3DPillars，利用2D卷积学习3D体素特征；并引入了一个RoI头，包含稀疏场景上下文特征模块，聚合多尺度特征以优化3D目标提议。

Result: 在KITTI和Waymo Open数据集上进行了实验，证明了该方法的有效性和效率，在速度和准确性之间取得了良好的折衷。

Conclusion: 所提出的两阶段3D检测框架通过3DPillars和RoI头克服了PointPillars的局限性，成功提高了精度，同时保持了其高效性。

Abstract: PointPillars is the fastest 3D object detector that exploits pseudo image
representations to encode features for 3D objects in a scene. Albeit efficient,
PointPillars is typically outperformed by state-of-the-art 3D detection methods
due to the following limitations: 1) The pseudo image representations fail to
preserve precise 3D structures, and 2) they make it difficult to adopt a
two-stage detection pipeline using 3D object proposals that typically shows
better performance than a single-stage approach. We introduce in this paper the
first two-stage 3D detection framework exploiting pseudo image representations,
narrowing the performance gaps between PointPillars and state-of-the-art
methods, while retaining its efficiency. Our framework consists of two novel
components that overcome the aforementioned limitations of PointPillars: First,
we introduce a new CNN architecture, dubbed 3DPillars, that enables learning 3D
voxel-based features from the pseudo image representation efficiently using 2D
convolutions. The basic idea behind 3DPillars is that 3D features from voxels
can be viewed as a stack of pseudo images. To implement this idea, we propose a
separable voxel feature module that extracts voxel-based features without using
3D convolutions. Second, we introduce an RoI head with a sparse scene context
feature module that aggregates multi-scale features from 3DPillars to obtain a
sparse scene feature. This enables adopting a two-stage pipeline effectively,
and fully leveraging contextual information of a scene to refine 3D object
proposals. Experimental results on the KITTI and Waymo Open datasets
demonstrate the effectiveness and efficiency of our approach, achieving a good
compromise in terms of speed and accuracy.

</details>


### [57] [CRAB: Camera-Radar Fusion for Reducing Depth Ambiguity in Backward Projection based View Transformation](https://arxiv.org/abs/2509.05785)
*In-Jae Lee,Sihwan Hwang,Youngseok Kim,Wonjune Kim,Sanmin Kim,Dongsuk Kum*

Main category: cs.CV

TL;DR: CRAB模型提出了一种新的相机-雷达融合3D目标检测方法，利用反向投影并结合雷达数据来解决深度模糊问题，在nuScenes数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于相机-雷达融合的3D目标检测方法在鸟瞰图（BEV）特征生成方面存在挑战，前向投影易导致BEV特征稀疏，后向投影则存在深度模糊导致误报。

Method: CRAB模型采用反向投影，并结合相机和雷达信息。在视图转换过程中，将透视视图的图像上下文特征聚合到BEV查询中，通过融合图像提供的密集但不可靠的深度分布和雷达提供的稀疏但精确的深度信息，来区分同一射线上的查询深度。此外，还引入了空间交叉注意力机制，并融合了雷达上下文信息，以增强3D场景理解能力。

Result: 在nuScenes公开数据集上的评估结果显示，CRAB模型在基于反向投影的相机-雷达融合方法中取得了最先进的性能，3D目标检测的NDS为62.4%，mAP为54.0%。

Conclusion: CRAB模型通过利用雷达数据解决后向投影中的深度模糊问题，并在BEV特征生成和3D场景理解方面取得了显著的改进，达到了当前最优的性能。

Abstract: Recently, camera-radar fusion-based 3D object detection methods in bird's eye
view (BEV) have gained attention due to the complementary characteristics and
cost-effectiveness of these sensors. Previous approaches using forward
projection struggle with sparse BEV feature generation, while those employing
backward projection overlook depth ambiguity, leading to false positives. In
this paper, to address the aforementioned limitations, we propose a novel
camera-radar fusion-based 3D object detection and segmentation model named CRAB
(Camera-Radar fusion for reducing depth Ambiguity in Backward projection-based
view transformation), using a backward projection that leverages radar to
mitigate depth ambiguity. During the view transformation, CRAB aggregates
perspective view image context features into BEV queries. It improves depth
distinction among queries along the same ray by combining the dense but
unreliable depth distribution from images with the sparse yet precise depth
information from radar occupancy. We further introduce spatial cross-attention
with a feature map containing radar context information to enhance the
comprehension of the 3D scene. When evaluated on the nuScenes open dataset, our
proposed approach achieves a state-of-the-art performance among backward
projection-based camera-radar fusion methods with 62.4\% NDS and 54.0\% mAP in
3D object detection.

</details>


### [58] [Multi-Modal Camera-Based Detection of Vulnerable Road Users](https://arxiv.org/abs/2509.06333)
*Penelope Brown,Julie Stephany Berrio Perez,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 该研究提出了一种结合RGB和热红外成像的多模态检测框架，利用YOLOv8模型，并通过数据集增强和模型优化来提升弱势道路使用者（VRU）的检测效果，尤其是在恶劣条件下。


<details>
  <summary>Details</summary>
Motivation: 弱势道路使用者（VRU）占全球交通事故死亡人数的一半以上，但在光线不足、天气恶劣和数据不平衡的情况下，他们的检测仍然是一个挑战。

Method: 该研究提出了一种多模态检测框架，集成了RGB和热红外成像，并使用经过微调的YOLOv8模型。训练利用了KITTI、BDD100K和Teledyne FLIR数据集，并通过类别重加权和轻度数据增强来提高少数类别的性能和鲁棒性。实验表明，640像素分辨率和部分骨干网络冻结可以优化准确性和效率，而类别加权损失可以提高稀有VRU的召回率。

Result: 实验结果显示，热成像模型实现了最高的精确率，而RGB到热成像的增强提高了召回率。这表明多模态检测在改善交叉口VRU安全性方面具有潜力。

Conclusion: 多模态检测方法，特别是结合RGB和热红外成像，能够有效提升弱势道路使用者（VRU）在复杂场景下的检测性能，为提高道路安全提供了新的途径。

Abstract: Vulnerable road users (VRUs) such as pedestrians, cyclists, and motorcyclists
represent more than half of global traffic deaths, yet their detection remains
challenging in poor lighting, adverse weather, and unbalanced data sets. This
paper presents a multimodal detection framework that integrates RGB and thermal
infrared imaging with a fine-tuned YOLOv8 model. Training leveraged KITTI,
BDD100K, and Teledyne FLIR datasets, with class re-weighting and light
augmentations to improve minority-class performance and robustness, experiments
show that 640-pixel resolution and partial backbone freezing optimise accuracy
and efficiency, while class-weighted losses enhance recall for rare VRUs.
Results highlight that thermal models achieve the highest precision, and
RGB-to-thermal augmentation boosts recall, demonstrating the potential of
multimodal detection to improve VRU safety at intersections.

</details>


### [59] [Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance](https://arxiv.org/abs/2509.05796)
*Julio Zanon Diaz,Georgios Siogkas,Peter Corcoran*

Main category: cs.CV

TL;DR: 本文提出了两种注意力引导的自动编码器架构，用于解决医学设备制造中因数据集小、不平衡、高分辨率图像和严格的监管要求而导致的视觉检测自动化挑战。


<details>
  <summary>Details</summary>
Motivation: 医学设备制造中的自动化视觉检测面临数据集小、不平衡、图像分辨率高以及严格的监管要求等多重挑战。

Method: 提出两种注意力引导的自动编码器架构：一种基于结构相似性（4-MS-SSIM）的异常评分方法，用于轻量级、实时的缺陷检测；另一种基于马氏距离在降维后的潜在特征上进行评分，用于检测分布偏移。

Result: 第一种方法在表面密封图像测试集上实现了0.903（无监督）和0.931（有监督）的准确率，仅使用了10%的有缺陷样本。第二种方法在有监督阈值下实现了0.722的准确率。两种方法均优于基线模型。

Conclusion: 这两种互补的方法为在受监管的制造环境中部署深度异常检测提供了实用的途径，满足了准确性、效率和欧盟人工智能法案对高风险人工智能系统的监管要求。第一种方法支持在线检测，第二种方法支持生产后监控和合规性监控。

Abstract: Automating visual inspection in medical device manufacturing remains
challenging due to small and imbalanced datasets, high-resolution imagery, and
stringent regulatory requirements. This work proposes two attention-guided
autoencoder architectures for deep anomaly detection designed to address these
constraints. The first employs a structural similarity-based anomaly score
(4-MS-SSIM), offering lightweight and accurate real-time defect detection,
yielding ACC 0.903 (unsupervised thresholding) and 0.931 (supervised
thresholding) on the - Surface Seal Image - Test split with only 10% of
defective samples. The second applies a feature-distance approach using
Mahalanobis scoring on reduced latent features, providing high sensitivity to
distributional shifts for supervisory monitoring, achieving ACC 0.722 with
supervised thresholding. Together, these methods deliver complementary
capabilities: the first supports reliable inline inspection, while the second
enables scalable post-production surveillance and regulatory compliance
monitoring. Experimental results demonstrate that both approaches surpass
re-implemented baselines and provide a practical pathway for deploying deep
anomaly detection in regulated manufacturing environments, aligning accuracy,
efficiency, and the regulatory obligations defined for high-risk AI systems
under the EU AI Act.

</details>


### [60] [A Probabilistic Segment Anything Model for Ambiguity-Aware Medical Image Segmentation](https://arxiv.org/abs/2509.05809)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: SAM的概率性扩展，称为Probabilistic SAM，可以对图像和提示的分割分布进行建模，从而生成多样化且合理的分割掩码，以反映人类注释中的可变性。


<details>
  <summary>Details</summary>
Motivation: SAM等模型在处理真实世界任务中的固有歧义时存在局限性，尤其是在医学成像领域，这可能导致单一下降分割，而忽略了多种可能的分割。

Method: 通过引入潜在变量空间和使用变分目标对SAM进行扩展，并整合先验和后验网络，使潜在代码在推理过程中调节提示嵌入。

Result: Probabilistic SAM在LIDC-IDRI数据集上表现出色，能够生成与专家分歧一致的多样化输出，并在考虑不确定性的指标上优于现有的概率基线。

Conclusion: Probabilistic SAM通过在其分割模型中引入概率和不确定性来解决SAM的确定性限制，使其在医学成像等需要考虑多种可能分割的领域更具实用性。

Abstract: Recent advances in promptable segmentation, such as the Segment Anything
Model (SAM), have enabled flexible, high-quality mask generation across a wide
range of visual domains. However, SAM and similar models remain fundamentally
deterministic, producing a single segmentation per object per prompt, and fail
to capture the inherent ambiguity present in many real-world tasks. This
limitation is particularly troublesome in medical imaging, where multiple
plausible segmentations may exist due to annotation uncertainty or inter-expert
variability. In this paper, we introduce Probabilistic SAM, a probabilistic
extension of SAM that models a distribution over segmentations conditioned on
both the input image and prompt. By incorporating a latent variable space and
training with a variational objective, our model learns to generate diverse and
plausible segmentation masks reflecting the variability in human annotations.
The architecture integrates a prior and posterior network into the SAM
framework, allowing latent codes to modulate the prompt embeddings during
inference. The latent space allows for efficient sampling during inference,
enabling uncertainty-aware outputs with minimal overhead. We evaluate
Probabilistic SAM on the public LIDC-IDRI lung nodule dataset and demonstrate
its ability to produce diverse outputs that align with expert disagreement,
outperforming existing probabilistic baselines on uncertainty-aware metrics.
Our code is available at: https://github.com/tbwa233/Probabilistic-SAM/.

</details>


### [61] [Investigating Location-Regularised Self-Supervised Feature Learning for Seafloor Visual Imagery](https://arxiv.org/abs/2509.06660)
*Cailei Liang,Adrian Bodenmann,Emma J Curtis,Samuel Simmons,Kazunori Nagano,Stan Brown,Adam Riese,Blair Thornton*

Main category: cs.CV

TL;DR: 位置元数据可以提高机器人采集的海底图像的自监督特征学习（SSL）性能，特别是在使用低维潜在表示时。高维ViT在海底图像分析中表现出很强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 评估位置元数据对不同SSL策略、模型和海底图像数据集的增强效果，以提高海洋监测和探索的效率。

Method: 在三个不同的海底图像数据集上，评估位置信息正则化对六种最先进的SSL框架（包括CNN和ViT模型）的影响，并分析不同潜在空间维度下的性能。

Result: 位置信息正则化在CNN和ViT模型上均能持续提高下游分类性能，平均F1分数分别提升4.9%和6.3%。对于CNN，高维潜在表示和位置正则化均能提升性能，而ViT在各种情况下均表现出良好的泛化能力。

Conclusion: 位置元数据对于SSL正则化，尤其是在使用低维潜在表示时，具有重要价值。高维ViT在海底图像分析方面具有强大的泛化能力，能够与最优的位置正则化SSL方法相媲美。

Abstract: High-throughput interpretation of robotically gathered seafloor visual
imagery can increase the efficiency of marine monitoring and exploration.
Although recent research has suggested that location metadata can enhance
self-supervised feature learning (SSL), its benefits across different SSL
strategies, models and seafloor image datasets are underexplored. This study
evaluates the impact of location-based regularisation on six state-of-the-art
SSL frameworks, which include Convolutional Neural Network (CNN) and Vision
Transformer (ViT) models with varying latent-space dimensionality. Evaluation
across three diverse seafloor image datasets finds that location-regularisation
consistently improves downstream classification performance over standard SSL,
with average F1-score gains of $4.9 \pm 4.0%$ for CNNs and $6.3 \pm 8.9%$ for
ViTs, respectively. While CNNs pretrained on generic datasets benefit from
high-dimensional latent representations, dataset-optimised SSL achieves similar
performance across the high (512) and low (128) dimensional latent
representations. Location-regularised SSL improves CNN performance over
pre-trained models by $2.7 \pm 2.7%$ and $10.1 \pm 9.4%$ for high and
low-dimensional latent representations, respectively. For ViTs,
high-dimensionality benefits both pre-trained and dataset-optimised SSL.
Although location-regularisation improves SSL performance compared to standard
SSL methods, pre-trained ViTs show strong generalisation, matching the
best-performing location-regularised SSL with F1-scores of $0.795 \pm 0.075$
and $0.795 \pm 0.077$, respectively. The findings highlight the value of
location metadata for SSL regularisation, particularly when using
low-dimensional latent representations, and demonstrate strong generalisation
of high-dimensional ViTs for seafloor image analysis.

</details>


### [62] [Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural Networks on MODIS Data](https://arxiv.org/abs/2509.05887)
*Caleb Gates,Patrick Moorhead,Jayden Ferguson,Omar Darwish,Conner Stallman,Pablo Rivas,Paapa Quansah*

Main category: cs.CV

TL;DR: 该研究提出了一种利用MODIS多波段卫星图像的3D卷积神经网络，实现了对沙尘的像素级近实时检测，提高了沙尘监测的及时性和准确性。


<details>
  <summary>Details</summary>
Motivation: 沙尘暴对健康和可见性造成危害，需要从卫星图像中快速检测沙尘。

Method: 提出一种近实时系统，利用NASA的Terra和Aqua（MODIS）卫星的多波段图像，通过3D卷积神经网络学习所有36个波段（包括分割的热波段）的模式，以区分沙尘、云和地表特征。该系统还采用了简单的数据归一化和局部填充方法来处理缺失数据。

Result: 在17个独立的MODIS场景上，该模型达到了约0.92的准确率和0.014的均方误差。生成的沙尘分布图显示，模型在沙尘核心区域的检测结果与实际情况高度一致，但在沙尘边缘区域存在一些漏检。

Conclusion: 联合利用波段和空间信息进行学习，能够实现全球尺度的及时沙尘预警。未来可以考虑使用更宽的输入窗口或基于注意力机制的模型来进一步提高沙尘边缘检测的精度。

Abstract: Dust storms harm health and reduce visibility; quick detection from
satellites is needed. We present a near real-time system that flags dust at the
pixel level using multi-band images from NASA's Terra and Aqua (MODIS). A 3D
convolutional network learns patterns across all 36 bands, plus split thermal
bands, to separate dust from clouds and surface features. Simple normalization
and local filling handle missing data. An improved version raises training
speed by 21x and supports fast processing of full scenes. On 17 independent
MODIS scenes, the model reaches about 0.92 accuracy with a mean squared error
of 0.014. Maps show strong agreement in plume cores, with most misses along
edges. These results show that joint band-and-space learning can provide timely
dust alerts at global scale; using wider input windows or attention-based
models may further sharpen edges.

</details>


### [63] [Online Clustering of Seafloor Imagery for Interpretation during Long-Term AUV Operations](https://arxiv.org/abs/2509.06678)
*Cailei Liang,Adrian Bodenmann,Sam Fenton,Blair Thornton*

Main category: cs.CV

TL;DR: 该研究提出了一种名为在线聚类框架（OCF）的无监督学习方法，用于实时解释海底图像，以适应长航时、常驻海底的AUV任务。


<details>
  <summary>Details</summary>
Motivation: 为了满足长航时、常驻海底AUV在实时解读海底图像方面的需求，以支持自适应任务和优化通信效率。现有的离线图像分析方法无法满足实时性要求。

Method: 提出了一种在线聚类框架（OCF），该框架能够对海底图像进行无监督的实时解释。它通过识别和维护一组代表性样本来捕捉不断变化的特征分布，从而能够动态地合并和拆分簇，而无需重新处理整个图像历史。

Result: OCF在三个不同的海底图像数据集上进行了评估，在所有比较的在线聚类方法中，其平均F1分数最高，达到0.68，并且在不同航线轨迹上的标准差仅为3%，显示了其优越的聚类能力和对轨迹变化的鲁棒性。此外，随着数据量的增加，其计算时间保持稳定且有界。

Conclusion: OCF是一种有效的、可扩展的、自适应的在线聚类框架，适用于实时海底图像分析，能够为长期、持续的自主海洋探索提供数据摘要生成和路径规划支持。

Abstract: As long-endurance and seafloor-resident AUVs become more capable, there is an
increasing need for extended, real-time interpretation of seafloor imagery to
enable adaptive missions and optimise communication efficiency. Although
offline image analysis methods are well established, they rely on access to
complete datasets and human-labelled examples to manage the strong influence of
environmental and operational conditions on seafloor image
appearance-requirements that cannot be met in real-time settings. To address
this, we introduce an online clustering framework (OCF) capable of interpreting
seafloor imagery without supervision, which is designed to operate in real-time
on continuous data streams in a scalable, adaptive, and self-consistent manner.
The method enables the efficient review and consolidation of common patterns
across the entire data history in constant time by identifying and maintaining
a set of representative samples that capture the evolving feature distribution,
supporting dynamic cluster merging and splitting without reprocessing the full
image history. We evaluate the framework on three diverse seafloor image
datasets, analysing the impact of different representative sampling strategies
on both clustering accuracy and computational cost. The OCF achieves the
highest average F1 score of 0.68 across the three datasets among all
comparative online clustering approaches, with a standard deviation of 3%
across three distinct survey trajectories, demonstrating its superior
clustering capability and robustness to trajectory variation. In addition, it
maintains consistently lower and bounded computational time as the data volume
increases. These properties are beneficial for generating survey data summaries
and supporting informative path planning in long-term, persistent autonomous
marine exploration.

</details>


### [64] [Challenges in Deep Learning-Based Small Organ Segmentation: A Benchmarking Perspective for Medical Research with Limited Datasets](https://arxiv.org/abs/2509.05892)
*Phongsakon Mark Konrad,Andrei-Alexandru Popa,Yaser Sabzehmeidani,Liang Zhong,Elisa A. Liehn,Serkan Ayvaz*

Main category: cs.CV

TL;DR: 在有限的心血管组织病理学数据集上，最先进的深度学习分割模型的性能高度依赖于数据划分，而不是算法本身的优越性。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病研究和诊断需要对颈动脉结构进行准确的分割，但现有数据集的稀缺限制了深度学习模型的发展。

Method: 对包括U-Net、DeepLabV3+、SegFormer、SAM、MedSAM和MedSAM+UNet在内的多种深度学习模型进行系统评估，并采用贝叶斯搜索进行超参数优化。

Result: 模型性能对数据划分非常敏感，性能差异更多由统计噪声引起，而非算法优越性；这暴露了在数据量少的情况下，标准评测方法的局限性，并对性能排名是否能反映实际临床效用提出了质疑。

Conclusion: 在数据量有限的情况下，标准的模型评测方法可能无法准确反映模型的真实性能和临床应用价值，需要新的评测策略。

Abstract: Accurate segmentation of carotid artery structures in histopathological
images is vital for advancing cardiovascular disease research and diagnosis.
However, deep learning model development in this domain is constrained by the
scarcity of annotated cardiovascular histopathological data. This study
investigates a systematic evaluation of state-of-the-art deep learning
segmentation models, including convolutional neural networks (U-Net,
DeepLabV3+), a Vision Transformer (SegFormer), and recent foundation models
(SAM, MedSAM, MedSAM+UNet), on a limited dataset of cardiovascular histology
images. Despite employing an extensive hyperparameter optimization strategy
with Bayesian search, our findings reveal that model performance is highly
sensitive to data splits, with minor differences driven more by statistical
noise than by true algorithmic superiority. This instability exposes the
limitations of standard benchmarking practices in low-data clinical settings
and challenges the assumption that performance rankings reflect meaningful
clinical utility.

</details>


### [65] [BTCChat: Advancing Remote Sensing Bi-temporal Change Captioning with Multimodal Large Language Model](https://arxiv.org/abs/2509.05895)
*Yujie Li,Wenjia Xu,Yuanben Zhang,Zhiwei Wei,Mugen Peng*

Main category: cs.CV

TL;DR: BTCChat是一个多模态大语言模型，能够对双时相卫星图像进行变化检测和理解，并在变化描述和视觉问答任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在处理双时相卫星图像进行变化检测时，存在未充分建模时间相关性和空间语义变化的问题，影响了视觉-语义的对齐，限制了整体效果。

Method: 提出了一种名为BTCChat的多模态大语言模型，包含一个变化提取模块来捕捉时空语义变化，并引入提示增强机制来加强模型对空间细节的关注。

Result: 实验结果表明，BTCChat在变化描述和视觉问答任务上取得了最先进的性能。

Conclusion: BTCChat通过其变化提取模块和提示增强机制，有效解决了现有方法在双时相卫星图像变化分析中的不足，提高了模型在变化理解方面的能力。

Abstract: Bi-temporal satellite imagery supports critical applications such as urban
development monitoring and disaster assessment. Although powerful multimodal
large language models (MLLMs) have been applied in bi-temporal change analysis,
previous methods process image pairs through direct concatenation, inadequately
modeling temporal correlations and spatial semantic changes. This deficiency
hampers visual-semantic alignment in change understanding, thereby constraining
the overall effectiveness of current approaches. To address this gap, we
propose BTCChat, a multi-temporal MLLM with advanced bi-temporal change
understanding capability. BTCChat supports bi-temporal change captioning and
retains single-image interpretation capability. To better capture temporal
features and spatial semantic changes in image pairs, we design a Change
Extraction module. Moreover, to enhance the model's attention to spatial
details, we introduce a Prompt Augmentation mechanism, which incorporates
contextual clues into the prompt to enhance model performance. Experimental
results demonstrate that BTCChat achieves state-of-the-art performance on
change captioning and visual question answering tasks.

</details>


### [66] [Event Spectroscopy: Event-based Multispectral and Depth Sensing using Structured Light](https://arxiv.org/abs/2509.06741)
*Christian Geckeler,Niklas Neugebauer,Manasi Muglikar,Davide Scaramuzza,Stefano Mintchev*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Uncrewed aerial vehicles (UAVs) are increasingly deployed in forest
environments for tasks such as environmental monitoring and search and rescue,
which require safe navigation through dense foliage and precise data
collection. Traditional sensing approaches, including passive multispectral and
RGB imaging, suffer from latency, poor depth resolution, and strong dependence
on ambient light - especially under forest canopies. In this work, we present a
novel event spectroscopy system that simultaneously enables high-resolution,
low-latency depth reconstruction and multispectral imaging using a single
sensor. Depth is reconstructed using structured light, and by modulating the
wavelength of the projected structured light, our system captures spectral
information in controlled bands between 650 nm and 850 nm. We demonstrate up to
$60\%$ improvement in RMSE over commercial depth sensors and validate the
spectral accuracy against a reference spectrometer and commercial multispectral
cameras, demonstrating comparable performance. A portable version limited to
RGB (3 wavelengths) is used to collect real-world depth and spectral data from
a Masoala Rainforest. We demonstrate the use of this prototype for color image
reconstruction and material differentiation between leaves and branches using
spectral and depth data. Our results show that adding depth (available at no
extra effort with our setup) to material differentiation improves the accuracy
by over $30\%$ compared to color-only method. Our system, tested in both lab
and real-world rainforest environments, shows strong performance in depth
estimation, RGB reconstruction, and material differentiation - paving the way
for lightweight, integrated, and robust UAV perception and data collection in
complex natural environments.

</details>


### [67] [A Fine-Grained Attention and Geometric Correspondence Model for Musculoskeletal Risk Classification in Athletes Using Multimodal Visual and Skeletal Features](https://arxiv.org/abs/2509.05913)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Tamanna Shermin,Md Rafiqul Islam,Mukhtar Hussain,Sami Azam*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ViSK-GAT的多模态深度学习框架，结合视觉和骨骼坐标数据，用于运动员肌肉骨骼风险分类，并取得了93.89%的测试准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的肌肉骨骼风险评估方法在复杂环境中可靠性不足，因为它们通常只依赖单一类型的数据。

Method: 提出了一种名为ViSK-GAT（视觉-骨骼几何注意力变换器）的新型多模态深度学习框架，该框架结合了视觉数据和骨骼坐标数据。框架包含残差块和轻量级变换器块，并引入了细粒度注意力模块（FGAM）和多模态几何对应模块（MGCM）来优化跨模态特征。

Result: ViSK-GAT在验证集和测试集上分别取得了93.55%和93.89%的准确率，精度为93.86%，F1得分为93.85%，Cohen's Kappa和Matthews相关系数均为93%。回归结果显示，预测概率分布的均方根误差（RMSE）为0.1205，平均绝对误差（MAE）为0.0156。与九种流行的迁移学习骨干网络相比，ViSK-GAT表现持续优于先前的方法。

Conclusion: ViSK-GAT模型在肌肉骨骼风险分类方面取得了优异的性能，并且在人工智能的应用方面取得了进展，能够实现对运动员肌肉骨骼风险的早期干预。

Abstract: Musculoskeletal disorders pose significant risks to athletes, and assessing
risk early is important for prevention. However, most existing methods are
designed for controlled settings and fail to reliably assess risk in complex
environments due to their reliance on a single type of data. This research
proposes ViSK-GAT (Visual-Skeletal Geometric Attention Transformer), a novel
multimodal deep learning framework designed to classify musculoskeletal risk
using visual and skeletal coordinate-based features. In addition, a custom
multimodal dataset is constructed by combining visual data and skeletal
coordinates for risk assessment. Each sample is labeled into eight risk
categories based on the Rapid Entire Body Assessment system. ViSK-GAT combines
a Residual Block with a Lightweight Transformer Block to learn spatial and
temporal dependencies jointly. It incorporates two novel modules: the
Fine-Grained Attention Module (FGAM), which enables precise inter-modal feature
refinement through cross-attention between visual and skeletal inputs, and the
Multimodal Geometric Correspondence Module (MGCM), which enhances cross-modal
coherence by aligning image features with coordinate-based representations.
ViSK-GAT achieved strong performance with validation and test accuracies of
93.55\% and 93.89\%, respectively; a precision of 93.86\%; an F1 score of
93.85\%; and Cohen's Kappa and Matthews Correlation Coefficient of 93\%. The
regression results also indicated a low Root Mean Square Error of the predicted
probability distribution of 0.1205 and a corresponding Mean Absolute Error of
0.0156. Compared to nine popular transfer learning backbones, ViSK-GAT
consistently outperformed previous methods. The ViSK-GAT model advances
artificial intelligence implementation and application, transforming
musculoskeletal risk classification and enabling impactful early interventions
in sports.

</details>


### [68] [Compression Beyond Pixels: Semantic Compression with Multimodal Foundation Models](https://arxiv.org/abs/2509.05925)
*Ruiqi Shen,Haotian Wu,Wenjing Zhang,Jiangjing Hu,Deniz Gunduz*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP模型的新颖语义压缩方法，通过压缩CLIP特征嵌入来最小化比特数，同时保持语义信息，实现了低比特率和跨任务的零样本鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习图像压缩方法在像素重建上表现良好，但在语义保持、跨数据分布和下游任务的鲁棒性方面存在不足，而这些是新兴应用的关键需求。

Method: 利用CLIP模型的零样本和表征能力，提出一种压缩CLIP特征嵌入而非像素的方法，目标是在最小比特数下保留语义信息。

Result: 在基准数据集上，该方法在保持语义完整性的同时，实现了约2-3*10(-3)比特每像素的平均比特率，远低于现有主流图像压缩方法，并且在极端压缩下表现出跨数据分布和下游任务的零样本鲁棒性。

Conclusion: 该基于CLIP的语义压缩方法在低比特率下能有效保持图像的语义信息，并在各种下游任务和数据分布上展现出优越的鲁棒性，为未来的语义压缩研究提供了新的方向。

Abstract: Recent deep learning-based methods for lossy image compression achieve
competitive rate-distortion performance through extensive end-to-end training
and advanced architectures. However, emerging applications increasingly
prioritize semantic preservation over pixel-level reconstruction and demand
robust performance across diverse data distributions and downstream tasks.
These challenges call for advanced semantic compression paradigms. Motivated by
the zero-shot and representational capabilities of multimodal foundation
models, we propose a novel semantic compression method based on the contrastive
language-image pretraining (CLIP) model. Rather than compressing images for
reconstruction, we propose compressing the CLIP feature embeddings into minimal
bits while preserving semantic information across different tasks. Experiments
show that our method maintains semantic integrity across benchmark datasets,
achieving an average bit rate of approximately 2-3* 10(-3) bits per pixel. This
is less than 5% of the bitrate required by mainstream image compression
approaches for comparable performance. Remarkably, even under extreme
compression, the proposed approach exhibits zero-shot robustness across diverse
data distributions and downstream tasks.

</details>


### [69] [AttriPrompt: Dynamic Prompt Composition Learning for CLIP](https://arxiv.org/abs/2509.05949)
*Qiqi Zhan,Shiwei Li,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: AttriPrompt框架通过利用CLIP视觉编码器的中间层特征，解决了现有深度文本提示方法的局限性，实现了细粒度特征优化和内容感知适应，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度文本提示方法过度依赖对比学习，忽略细粒度特征优化，并且提示固定，无法适应不同输入内容。

Method: 提出AttriPrompt框架，设计了属性检索模块，从CLIP视觉编码器的各层聚类视觉特征，并检索相似的提示词拼接到文本编码器的输入层。引入双流对比学习实现细粒度对齐，并使用自回归机制防止过拟合。

Result: 在三个基准测试中，AttriPrompt相比现有最先进的方法取得了最高7.37%的提升，尤其在跨域知识迁移方面表现出色。

Conclusion: AttriPrompt框架通过整合层级视觉信息和细粒度对齐，提升了视觉语言预训练模型在实际应用中的可行性。

Abstract: The evolution of prompt learning methodologies has driven exploration of
deeper prompt designs to enhance model performance. However, current deep text
prompting approaches suffer from two critical limitations: Over-reliance on
constrastive learning objectives that prioritize high-level semantic alignment,
neglecting fine-grained feature optimization; Static prompts across all input
categories, preventing content-aware adaptation. To address these limitations,
we propose AttriPrompt-a novel framework that enhances and refines textual
semantic representations by leveraging the intermediate-layer features of
CLIP's vision encoder. We designed an Attribute Retrieval module that first
clusters visual features from each layer. The aggregated visual features
retrieve semantically similar prompts from a prompt pool, which are then
concatenated to the input of every layer in the text encoder. Leveraging
hierarchical visual information embedded in prompted text features, we
introduce Dual-stream Contrastive Learning to realize fine-grained alignment.
Furthermore, we introduce a Self-Regularization mechanism by applying explicit
regularization constraints between the prompted and non-prompted text features
to prevent overfitting on limited training data. Extensive experiments across
three benchmarks demonstrate AttriPrompt's superiority over state-of-the-art
methods, achieving up to 7.37\% improvement in the base-to-novel setting. The
observed strength of our method in cross-domain knowledge transfer positions
vision-language pre-trained models as more viable solutions for real-world
implementation.

</details>


### [70] [Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching](https://arxiv.org/abs/2509.05952)
*Feng Wang,Zihao Yu*

Main category: cs.CV

TL;DR: RL在扩散和流匹配模型中用于图像和视频生成，但SDE采样引入的噪声会损害奖励学习。提出CPS方法，借鉴DDIM，消除噪声，提高奖励建模精度，加速和稳定RL优化器（如Flow-GRPO和Dance-GRPO）的收敛。


<details>
  <summary>Details</summary>
Motivation: 在线RL方法应用于流匹配模型时，需要在确定性框架中引入随机性（通常通过SDE实现），但SDE采样会引入显著的噪声，损害奖励学习过程。

Method: 提出Coefficients-Preserving Sampling (CPS)方法，借鉴Denoising Diffusion Implicit Models (DDIM)的思路，修改采样过程以消除噪声伪影。

Result: CPS方法消除了噪声伪影，实现了更准确的奖励建模，从而能够更快、更稳定地收敛强化学习优化器，如Flow-GRPO和Dance-GRPO。

Conclusion: CPS方法通过消除SDE采样引入的噪声，改进了流匹配模型中RL的应用，提高了奖励建模的准确性和RL优化的稳定性和收敛速度。

Abstract: Reinforcement Learning (RL) has recently emerged as a powerful technique for
improving image and video generation in Diffusion and Flow Matching models,
specifically for enhancing output quality and alignment with prompts. A
critical step for applying online RL methods on Flow Matching is the
introduction of stochasticity into the deterministic framework, commonly
realized by Stochastic Differential Equation (SDE). Our investigation reveals a
significant drawback to this approach: SDE-based sampling introduces pronounced
noise artifacts in the generated images, which we found to be detrimental to
the reward learning process. A rigorous theoretical analysis traces the origin
of this noise to an excess of stochasticity injected during inference. To
address this, we draw inspiration from Denoising Diffusion Implicit Models
(DDIM) to reformulate the sampling process. Our proposed method,
Coefficients-Preserving Sampling (CPS), eliminates these noise artifacts. This
leads to more accurate reward modeling, ultimately enabling faster and more
stable convergence for reinforcement learning-based optimizers like Flow-GRPO
and Dance-GRPO. Code will be released at https://github.com/IamCreateAI/FlowCPS

</details>


### [71] [Dual Interaction Network with Cross-Image Attention for Medical Image Segmentation](https://arxiv.org/abs/2509.05953)
*Jeonghyun Noh,Wangsu Jeon,Jinsun Park*

Main category: cs.CV

TL;DR: 提出了一种双重交互融合模块（DIFM）和多尺度边界损失，以提高医学图像分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像增强技术可能改变原始图像中的关键诊断信息，而传统的图像融合策略未能充分利用增强前后图像的互补信息并抑制负面影响。

Method: 提出了一种双重交互融合模块（DIFM），利用交叉注意力和全局空间注意力来融合原始图像和增强图像的互补特征。同时，引入了基于梯度提取的多尺度边界损失来优化分割边界的准确性。

Result: 在ACDC和Synapse数据集上的实验结果表明，该方法在定量和定性方面均优于现有方法。

Conclusion: 所提出的DIFM和多尺度边界损失能够有效融合医学图像信息，提高分割精度，特别是在物体边界处。

Abstract: Medical image segmentation is a crucial method for assisting professionals in
diagnosing various diseases through medical imaging. However, various factors
such as noise, blurriness, and low contrast often hinder the accurate diagnosis
of diseases. While numerous image enhancement techniques can mitigate these
issues, they may also alter crucial information needed for accurate diagnosis
in the original image. Conventional image fusion strategies, such as feature
concatenation can address this challenge. However, they struggle to fully
leverage the advantages of both original and enhanced images while suppressing
the side effects of the enhancements. To overcome the problem, we propose a
dual interactive fusion module (DIFM) that effectively exploits mutual
complementary information from the original and enhanced images. DIFM employs
cross-attention bidirectionally to simultaneously attend to corresponding
spatial information across different images, subsequently refining the
complementary features via global spatial attention. This interaction leverages
low- to high-level features implicitly associated with diverse structural
attributes like edges, blobs, and object shapes, resulting in enhanced features
that embody important spatial characteristics. In addition, we introduce a
multi-scale boundary loss based on gradient extraction to improve segmentation
accuracy at object boundaries. Experimental results on the ACDC and Synapse
datasets demonstrate the superiority of the proposed method quantitatively and
qualitatively. Code available at: https://github.com/JJeong-Gari/DIN

</details>


### [72] [StripDet: Strip Attention-Based Lightweight 3D Object Detection from Point Cloud](https://arxiv.org/abs/2509.05954)
*Weichao Wang,Wendong Mao,Zhongfeng Wang*

Main category: cs.CV

TL;DR: StripDet是一个轻量级的3D目标检测框架，通过引入Strip Attention Block（SAB）和硬件友好的骨干网络，实现了高效的端到端推理，参数量仅为0.65M，在KITTI数据集上达到了79.97%的mAP，显著优于现有轻量级模型。


<details>
  <summary>Details</summary>
Motivation: 高精度3D目标检测模型在边缘设备上的部署面临计算和内存需求大的挑战。

Method: 提出了一种名为Strip Attention Block（SAB）的新型高效模块，通过将2D卷积分解为非对称的条形卷积来捕捉长距离空间依赖关系，并将计算复杂度从二次降低到线性。设计了一个硬件友好的分层骨干网络，集成了SAB、深度可分离卷积和多尺度融合策略。

Result: 在KITTI数据集上，StripDet仅用0.65M参数实现了79.97%的 car detection mAP，相比基线PointPillars，参数量减少了7倍。同时，StripDet在精度-效率权衡方面优于其他轻量级和知识蒸馏方法。

Conclusion: StripDet为在边缘设备上进行实际的3D目标检测提供了一个高效且实用的解决方案。

Abstract: The deployment of high-accuracy 3D object detection models from point cloud
remains a significant challenge due to their substantial computational and
memory requirements. To address this, we introduce StripDet, a novel
lightweight framework designed for on-device efficiency. First, we propose the
novel Strip Attention Block (SAB), a highly efficient module designed to
capture long-range spatial dependencies. By decomposing standard 2D
convolutions into asymmetric strip convolutions, SAB efficiently extracts
directional features while reducing computational complexity from quadratic to
linear. Second, we design a hardware-friendly hierarchical backbone that
integrates SAB with depthwise separable convolutions and a simple multiscale
fusion strategy, achieving end-to-end efficiency. Extensive experiments on the
KITTI dataset validate StripDet's superiority. With only 0.65M parameters, our
model achieves a 79.97% mAP for car detection, surpassing the baseline
PointPillars with a 7x parameter reduction. Furthermore, StripDet outperforms
recent lightweight and knowledge distillation-based methods, achieving a
superior accuracy-efficiency trade-off while establishing itself as a practical
solution for real-world 3D detection on edge devices.

</details>


### [73] [Neural Bloom: A Deep Learning Approach to Real-Time Lighting](https://arxiv.org/abs/2509.05963)
*Rafal Karp,Dawid Gruszka,Tomasz Trzcinski*

Main category: cs.CV

TL;DR: 提出一种新的基于神经网络的实时辉光照明方法，速度比现有方法快 30%，并实现了高质量的效果。


<details>
  <summary>Details</summary>
Motivation: 现有传统辉光照明技术依赖多种模糊算法和纹理采样，且常有条件分支，导致执行时间过长，因此需要更高效的方法。

Method: 提出两种基于神经网络的辉光照明方法：Neural Bloom Lighting (NBL) 和 Fast Neural Bloom Lighting (FastNBL)，并在多种 3D 场景中进行测试，评估了亮度掩码精度和推理速度。

Result: 与现有技术相比，NBL 和 FastNBL 都能生成高质量的辉光效果，并且性能更优。具体来说，FastNBL 的速度提高了 28%，NBL 的速度提高了 12%。

Conclusion: 所提出的两种神经网络方法在保证高质量辉光效果的同时，显著提高了渲染速度，为实现更真实的实时渲染环境提供了可能，有助于提高计算效率、用户沉浸感和高帧率下的流畅体验。

Abstract: We propose a novel method to generate bloom lighting effect in real time
using neural networks. Our solution generate brightness mask from given 3D
scene view up to 30% faster than state-of-the-art methods. The existing
traditional techniques rely on multiple blur appliances and texture sampling,
also very often have existing conditional branching in its implementation.
These operations occupy big portion of the execution time. We solve this
problem by proposing two neural network-based bloom lighting methods, Neural
Bloom Lighting (NBL) and Fast Neural Bloom Lighting (FastNBL), focusing on
their quality and performance. Both methods were tested on a variety of 3D
scenes, with evaluations conducted on brightness mask accuracy and inference
speed. The main contribution of this work is that both methods produce
high-quality bloom effects while outperforming the standard state-of-the-art
bloom implementation, with FastNBL being faster by 28% and NBL faster by 12%.
These findings highlight that we can achieve realistic bloom lighting phenomena
faster, moving us towards more realism in real-time environments in the future.
This improvement saves computational resources, which is a major bottleneck in
real-time rendering. Furthermore, it is crucial for sustaining immersion and
ensuring smooth experiences in high FPS environments, while maintaining
high-quality realism.

</details>


### [74] [Spatial-Aware Self-Supervision for Medical 3D Imaging with Multi-Granularity Observable Tasks](https://arxiv.org/abs/2509.05967)
*Yiqin Zhang,Meiling Chen,Zhengjie Zhang*

Main category: cs.CV

TL;DR: 自监督学习在医学可视化中因数据稀疏性而日益普及，但现有方法借鉴2D设计，缺乏3D空间理解的直观性，导致医学可解释性不足。


<details>
  <summary>Details</summary>
Motivation: 当前医学可视化领域的自监督方法受2D设计影响，难以直观展示3D空间知识的学习过程，导致医学可解释性不足。

Method: 提出一种包含三个子任务的方法，以捕捉医学3D影像中与空间相关的语义，并尽量减少因可解释性设计带来的性能损失。该方法利用3D影像的额外维度来增强语义深度，并结合多粒度空间关系建模来保持训练稳定性。

Result: 实验结果表明，该方法在性能上可与现有方法媲美，并能直观地展示自监督学习过程。

Conclusion: 所提出的方法在保持与现有方法相当的性能的同时，提高了医学3D影像自监督学习的可解释性。

Abstract: The application of self-supervised techniques has become increasingly
prevalent within medical visualization tasks, primarily due to its capacity to
mitigate the data scarcity prevalent in the healthcare sector. The majority of
current works are influenced by designs originating in the generic 2D visual
domain, which lack the intuitive demonstration of the model's learning process
regarding 3D spatial knowledge. Consequently, these methods often fall short in
terms of medical interpretability. We propose a method consisting of three
sub-tasks to capture the spatially relevant semantics in medical 3D imaging.
Their design adheres to observable principles to ensure interpretability, and
minimize the performance loss caused thereby as much as possible. By leveraging
the enhanced semantic depth offered by the extra dimension in 3D imaging, this
approach incorporates multi-granularity spatial relationship modeling to
maintain training stability. Experimental findings suggest that our approach is
capable of delivering performance that is on par with current methodologies,
while facilitating an intuitive understanding of the self-supervised learning
process.

</details>


### [75] [OmniStyle2: Scalable and High Quality Artistic Style Transfer Data Generation via Destylization](https://arxiv.org/abs/2509.05970)
*Ye Wang,Zili Yi,Yibo Zhang,Peng Zheng,Xuping Xie,Jiang Lin,Yilin Wang,Rui Ma*

Main category: cs.CV

TL;DR: 通过“去风格化”技术生成大规模数据集DST-100K，并利用该数据集训练出性能超越现有方法的艺术风格迁移模型OmniStyle2。


<details>
  <summary>Details</summary>
Motivation: 艺术风格迁移任务缺乏真实标注数据，导致现有方法难以达到预期效果。

Method: 提出“去风格化”技术，移除艺术作品的风格元素以恢复其自然、无风格的原貌，并构建了DST-100K数据集。利用DST-100K训练基于FLUX.1-dev的简单前馈模型OmniStyle2。

Result: OmniStyle2在定性和定量评估中均优于现有最先进的方法。

Conclusion: 通过“去风格化”生成大规模数据是解决艺术风格迁移中真实标注数据缺乏问题的有效途径。

Abstract: OmniStyle2 introduces a novel approach to artistic style transfer by
reframing it as a data problem. Our key insight is destylization, reversing
style transfer by removing stylistic elements from artworks to recover natural,
style-free counterparts. This yields DST-100K, a large-scale dataset that
provides authentic supervision signals by aligning real artistic styles with
their underlying content. To build DST-100K, we develop (1) DST, a text-guided
destylization model that reconstructs stylefree content, and (2) DST-Filter, a
multi-stage evaluation model that employs Chain-of-Thought reasoning to
automatically discard low-quality pairs while ensuring content fidelity and
style accuracy. Leveraging DST-100K, we train OmniStyle2, a simple feed-forward
model based on FLUX.1-dev. Despite its simplicity, OmniStyle2 consistently
surpasses state-of-the-art methods across both qualitative and quantitative
benchmarks. Our results demonstrate that scalable data generation via
destylization provides a reliable supervision paradigm, overcoming the
fundamental challenge posed by the lack of ground-truth data in artistic style
transfer.

</details>


### [76] [ConstStyle: Robust Domain Generalization with Unified Style Transformation](https://arxiv.org/abs/2509.05975)
*Nam Duong Tran,Nam Nguyen Phuong,Hieu H. Pham,Phi Le Nguyen,My T. Thai*

Main category: cs.CV

TL;DR: ConstStyle通过将所有训练和测试数据映射到一个统一的域来增强域泛化（DG）的鲁棒性，即使在训练域有限或域间隙很大的情况下也能有效减少域偏移的影响。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在测试数据分布与训练数据分布不一致时，性能会下降。现有的域泛化（DG）方法在训练域有限或训练域与测试域之间存在显著差距时，效果不佳。

Method: ConstStyle方法首先将所有样本映射到一个统一域，并在该域上进行优化，以捕获域不变特征并缩小域间隙。测试时，将来自未知域的样本也映射到该统一域进行预测。

Result: ConstStyle在各种场景下持续优于现有方法，尤其是在训练域数量有限的情况下，准确率最高可提升19.82%。

Conclusion: ConstStyle通过利用统一域来捕捉域不变特征并缩小域间隙，能够有效提升域泛化（DG）的鲁棒性，即使在训练域有限或域间隙很大的情况下也能取得优异性能。

Abstract: Deep neural networks often suffer performance drops when test data
distribution differs from training data. Domain Generalization (DG) aims to
address this by focusing on domain-invariant features or augmenting data for
greater diversity. However, these methods often struggle with limited training
domains or significant gaps between seen (training) and unseen (test) domains.
To enhance DG robustness, we hypothesize that it is essential for the model to
be trained on data from domains that closely resemble unseen test domains-an
inherently difficult task due to the absence of prior knowledge about the
unseen domains. Accordingly, we propose ConstStyle, a novel approach that
leverages a unified domain to capture domain-invariant features and bridge the
domain gap with theoretical analysis. During training, all samples are mapped
onto this unified domain, optimized for seen domains. During testing, unseen
domain samples are projected similarly before predictions. By aligning both
training and testing data within this unified domain, ConstStyle effectively
reduces the impact of domain shifts, even with large domain gaps or few seen
domains. Extensive experiments demonstrate that ConstStyle consistently
outperforms existing methods across diverse scenarios. Notably, when only a
limited number of seen domains are available, ConstStyle can boost accuracy up
to 19.82\% compared to the next best approach.

</details>


### [77] [Multi-Strategy Guided Diffusion via Sparse Masking Temporal Reweighting Distribution Correction](https://arxiv.org/abs/2509.05992)
*Zekun Zhou,Yanru Gong,Liu Shi,Qiegen Liu*

Main category: cs.CV

TL;DR: STRIDE是一种用于稀疏视图CT重建的扩散模型，通过联合训练、动态重加权和双网络结构来提高图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的CT重建方法在处理稀疏视图数据时，难以有效完成缺失的投影视图和全局信息建模，导致图像质量不高。

Method: 提出了一种基于稀疏条件时间重加权积分分布估计的扩散模型（STRIDE）。具体包括：1. 联合训练机制，利用稀疏条件概率学习缺失视图和全局信息。2. 动态调整权重的时间变化稀疏条件重加权策略，以逐步感知稀疏视图信息。3. 线性回归用于校正已知和生成数据之间的分布偏移。4. 双网络并行架构，实现多子频带的全局校正和优化。

Result: 在公开和真实数据集上，STRIDE相比现有最佳基线方法，PSNR提高了2.58 dB，SSIM增加了2.37%，MSE降低了0.236。重建图像在结构一致性、细节恢复和伪影抑制方面表现出优异的泛化性和鲁棒性。

Conclusion: STRIDE通过创新的稀疏条件学习、动态权重调整和双网络架构，显著提高了稀疏视图CT重建的图像质量，并在多个评估指标上超越了现有方法。

Abstract: Diffusion models have demonstrated remarkable generative capabilities in
image processing tasks. We propose a Sparse condition Temporal Rewighted
Integrated Distribution Estimation guided diffusion model (STRIDE) for
sparse-view CT reconstruction. Specifically, we design a joint training
mechanism guided by sparse conditional probabilities to facilitate the model
effective learning of missing projection view completion and global information
modeling. Based on systematic theoretical analysis, we propose a temporally
varying sparse condition reweighting guidance strategy to dynamically adjusts
weights during the progressive denoising process from pure noise to the real
image, enabling the model to progressively perceive sparse-view information.
The linear regression is employed to correct distributional shifts between
known and generated data, mitigating inconsistencies arising during the
guidance process. Furthermore, we construct a dual-network parallel
architecture to perform global correction and optimization across multiple
sub-frequency components, thereby effectively improving the model capability in
both detail restoration and structural preservation, ultimately achieving
high-quality image reconstruction. Experimental results on both public and real
datasets demonstrate that the proposed method achieves the best improvement of
2.58 dB in PSNR, increase of 2.37\% in SSIM, and reduction of 0.236 in MSE
compared to the best-performing baseline methods. The reconstructed images
exhibit excellent generalization and robustness in terms of structural
consistency, detail restoration, and artifact suppression.

</details>


### [78] [S-LAM3D: Segmentation-Guided Monocular 3D Object Detection via Feature Space Fusion](https://arxiv.org/abs/2509.05999)
*Diana-Alexandra Sas,Florin Oniga*

Main category: cs.CV

TL;DR: 基于分割信息融合的单目3D目标检测方法在KITTI数据集上取得了良好效果，尤其在小目标检测方面表现优于仅使用RGB图像特征的同类方法。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测因输入图像缺乏深度信息而具有挑战性，现有方法依赖CNN或Transformer提取特征。本文旨在研究在不增加额外参数或分支的情况下，融合预计算的分割信息先验来提升现有检测模型的性能。

Method: 提出一种解耦策略，将预计算的分割信息先验直接注入到特征空间中，用于指导3D参数的预测，而非扩展检测模型或联合学习先验。

Result: 所提方法在KITTI 3D目标检测基准上进行了评估，在小型目标（如行人、自行车）的检测上，超越了仅依赖RGB图像特征的等效架构。

Conclusion: 通过融合额外的分割信息可以改善目标检测性能，证明了对输入数据的理解可以平衡对额外传感器或训练数据的需求。

Abstract: Monocular 3D Object Detection represents a challenging Computer Vision task
due to the nature of the input used, which is a single 2D image, lacking in any
depth cues and placing the depth estimation problem as an ill-posed one.
Existing solutions leverage the information extracted from the input by using
Convolutional Neural Networks or Transformer architectures as feature
extraction backbones, followed by specific detection heads for 3D parameters
prediction. In this paper, we introduce a decoupled strategy based on injecting
precomputed segmentation information priors and fusing them directly into the
feature space for guiding the detection, without expanding the detection model
or jointly learning the priors. The focus is on evaluating the impact of
additional segmentation information on existing detection pipelines without
adding additional prediction branches. The proposed method is evaluated on the
KITTI 3D Object Detection Benchmark, outperforming the equivalent architecture
that relies only on RGB image features for small objects in the scene:
pedestrians and cyclists, and proving that understanding the input data can
balance the need for additional sensors or training data.

</details>


### [79] [Motion Aware ViT-based Framework for Monocular 6-DoF Spacecraft Pose Estimation](https://arxiv.org/abs/2509.06000)
*Jose Sosa,Dan Pineau,Arunkumar Rathinam,Abdelrahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 该研究提出了一种结合时序信息（光流）和深度学习（Vision Transformer）的方法来改进单目6-DoF航天器姿态估计的精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖单目图像和静态关键点定位，未能充分利用航天任务中固有的时序信息。本研究旨在通过整合运动感知热图和光流来捕捉运动动态，从而提升姿态估计性能。

Method: 该方法将深度学习框架从人体姿态估计领域迁移至航天器姿态估计。具体来说，它结合了Vision Transformer（ViT）编码器的图像特征和预训练光流模型提供的运动线索来定位2D关键点。然后，利用估计的2D-3D对应关系，通过透视-n-点（PnP）求解器恢复6-DoF姿态。

Result: 在SPADES-RGB数据集上进行了训练和评估，并在SPARK-2024数据集的真实和合成数据上评估了泛化能力。结果表明，该方法在2D关键点定位和6-DoF姿态估计方面均优于仅使用单图像的基线方法，并且在不同数据分布上展现出良好的泛化能力。

Conclusion: 所提出的结合时序信息（光流）和深度学习（Vision Transformer）的方法能够有效提升单目6-DoF航天器姿态估计的精度和泛化能力。

Abstract: Monocular 6-DoF pose estimation plays an important role in multiple
spacecraft missions. Most existing pose estimation approaches rely on single
images with static keypoint localisation, failing to exploit valuable temporal
information inherent to space operations. In this work, we adapt a deep
learning framework from human pose estimation to the spacecraft pose estimation
domain that integrates motion-aware heatmaps and optical flow to capture motion
dynamics. Our approach combines image features from a Vision Transformer (ViT)
encoder with motion cues from a pre-trained optical flow model to localise 2D
keypoints. Using the estimates, a Perspective-n-Point (PnP) solver recovers
6-DoF poses from known 2D-3D correspondences. We train and evaluate our method
on the SPADES-RGB dataset and further assess its generalisation on real and
synthetic data from the SPARK-2024 dataset. Overall, our approach demonstrates
improved performance over single-image baselines in both 2D keypoint
localisation and 6-DoF pose estimation. Furthermore, it shows promising
generalisation capabilities when testing on different data distributions.

</details>


### [80] [Khana: A Comprehensive Indian Cuisine Dataset](https://arxiv.org/abs/2509.06006)
*Omkar Prabhu*

Main category: cs.CV

TL;DR: 该论文提出了 Khana 数据集，一个包含 131K 张图像（80 个标签）的印度菜肴数据集，用于图像分类、分割和检索，以解决现有数据集中缺乏印度菜肴细微差别的问题。


<details>
  <summary>Details</summary>
Motivation: 全球对多元化饮食体验的兴趣日益增长，但现有食物图像数据集在捕捉印度菜肴的细微差别方面存在不足，因为印度菜肴地域多样性广、制作复杂且缺乏全面的标记数据集。

Method: 创建了一个包含约 131,000 张图像（80 个标签，分辨率为 500x500 像素）的 Khana 数据集，并建立了印度菜肴的分类体系。在此基础上，评估了现有技术在图像分类、分割和检索方面的表现。

Result: Khana 数据集填补了现有数据的空白，为印度菜肴的图像识别、食谱推荐、饮食追踪和自动膳食规划等应用提供了基础。

Conclusion: Khana 数据集为研究人员提供了一个全面而具有挑战性的基准，同时也为开发人员提供了宝贵的资源，能够利用丰富的印度菜肴数据来创建实际应用。

Abstract: As global interest in diverse culinary experiences grows, food image models
are essential for improving food-related applications by enabling accurate food
recognition, recipe suggestions, dietary tracking, and automated meal planning.
Despite the abundance of food datasets, a noticeable gap remains in capturing
the nuances of Indian cuisine due to its vast regional diversity, complex
preparations, and the lack of comprehensive labeled datasets that cover its
full breadth. Through this exploration, we uncover Khana, a new benchmark
dataset for food image classification, segmentation, and retrieval of dishes
from Indian cuisine. Khana fills the gap by establishing a taxonomy of Indian
cuisine and offering around 131K images in the dataset spread across 80 labels,
each with a resolution of 500x500 pixels. This paper describes the dataset
creation process and evaluates state-of-the-art models on classification,
segmentation, and retrieval as baselines. Khana bridges the gap between
research and development by providing a comprehensive and challenging benchmark
for researchers while also serving as a valuable resource for developers
creating real-world applications that leverage the rich tapestry of Indian
cuisine. Webpage: https://khana.omkar.xyz

</details>


### [81] [BLaVe-CoT: Consistency-Aware Visual Question Answering for Blind and Low Vision Users](https://arxiv.org/abs/2509.06010)
*Wanyin Cheng,Zanxi Ruan*

Main category: cs.CV

TL;DR: BLaVe-CoT是一个视觉问答框架，可以处理盲人和低视力用户模糊或不确定的问题，通过生成多个候选答案并评估它们是否指代相同区域来解决歧义。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉问答系统难以满足盲人和低视力（BLV）用户的需求，因为他们的视觉问题常常模糊不清，并且可能存在多个有效的答案，而传统系统通常只假设一个答案和对应的图像区域。

Method: 提出BLaVe-CoT框架，该框架首先使用LoRA调优的BLIP-2模型生成多个候选答案，然后使用PolyFormer将每个答案在空间上进行定位，最后应用链式思考推理模块来评估这些答案是否指向相同或不同的图像区域。

Result: 在VQA-AnswerTherapy基准测试中，BLaVe-CoT的性能优于现有方法，并且能更好地处理辅助场景中常见的歧义和视觉噪声。

Conclusion: 需要开发能够适应人类不确定性并为BLV用户提供包容性支持的视觉问答系统。 BLaVe-CoT在处理BLV用户的问题歧义方面表现出有效性。

Abstract: Visual Question Answering (VQA) holds great potential for assisting Blind and
Low Vision (BLV) users, yet real-world usage remains challenging. Due to visual
impairments, BLV users often take blurry or poorly framed photos and face
difficulty in articulating specific questions about what they cannot fully see.
As a result, their visual questions are frequently ambiguous, and different
users may interpret them in diverse ways. This leads to multiple valid answers,
each grounded in different image regions-posing a mismatch with conventional
VQA systems that assume a single answer and region. To bridge this gap, we
present BLaVe-CoT, a VQA framework designed to reason about answer consistency
in the face of ambiguity. Our method proposes diverse candidate answers using a
LoRA-tuned BLIP-2 model, then grounds each answer spatially using PolyFormer,
and finally applies a chain-of-thought reasoning module to assess whether the
answers refer to the same or different regions. Evaluated on the
VQA-AnswerTherapy benchmark, BLaVe-CoT outperforms previous methods and proves
more robust to the ambiguity and visual noise common in assistive settings.
This work highlights the need for VQA systems that can adapt to real human
uncertainty and provide inclusive support for BLV users. To foster further
research and accessibility applications, we have made the code publicly
available at https://github.com/Accecwan/BLaVe-CoT.

</details>


### [82] [Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models](https://arxiv.org/abs/2509.06415)
*Jaemin Son,Sujin Choi,Inyong Yun*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent progress in vision-language models (VLMs) has led to impressive
results in document understanding tasks, but their high computational demands
remain a challenge. To mitigate the compute burdens, we propose a lightweight
token pruning framework that filters out non-informative background regions
from document images prior to VLM processing. A binary patch-level classifier
removes non-text areas, and a max-pooling refinement step recovers fragmented
text regions to enhance spatial coherence. Experiments on real-world document
datasets demonstrate that our approach substantially lowers computational
costs, while maintaining comparable accuracy.

</details>


### [83] [Cross-Modal Enhancement and Benchmark for UAV-based Open-Vocabulary Object Detection](https://arxiv.org/abs/2509.06011)
*Zhenhai Weng,Zhongliang Yu*

Main category: cs.CV

TL;DR: 现有的开放词汇目标检测（OVD）技术在无人机（UAV）图像上表现不佳，主要是因为预训练数据集与UAV图像存在领域差异。本研究提出了UAVDE-2M和UAVCAP-15k数据集，以及一种新的跨注意力门控增强融合（CAGE）模块，并将其集成到YOLO-World-v2架构中，通过在VisDrone和SIMD数据集上进行实验，验证了该方法在UAV图像和遥感应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇目标检测（OVD）模型在无人机（UAV）图像上性能不佳，原因是用于预训练的大规模数据集主要包含地面自然图像，与UAV图像存在显著的领域差异。

Method: 首先，研究提出了一个改进的UAV-Label引擎。然后，构建并引入了包含超过2,000,000个实例和1800个类别的UAVDE-2M数据集以及包含超过15,000张图像的UAVCAP-15k数据集。此外，还提出了一个新颖的跨注意力门控增强融合（CAGE）模块，并将其集成到YOLO-World-v2架构中。

Result: 在VisDrone和SIMD数据集上进行的广泛实验证明了所提出的方法在UAV图像和遥感应用中的有效性。

Conclusion: 本研究通过构建新的UAV数据集和提出CAGE模块并将其集成到YOLO-World-v2中，有效解决了OVD技术在UAV图像上性能下降的问题，并在相关数据集上得到了验证。

Abstract: Open-Vocabulary Object Detection (OVD) has emerged as a pivotal technology
for applications involving Unmanned Aerial Vehicles (UAVs). However, the
prevailing large-scale datasets for OVD pre-training are predominantly composed
of ground-level, natural images. This creates a significant domain gap, causing
models trained on them to exhibit a substantial drop in performance on UAV
imagery. To address this limitation, we first propose a refined UAV-Label
engine. Then we construct and introduce UAVDE-2M(contains over 2,000,000
instances and 1800 categories) and UAVCAP-15k(contains over 15,000 images).
Furthermore, we propose a novel Cross-Attention Gated Enhancement Fusion (CAGE)
module and integrate it into the YOLO-World-v2 architecture. Finally, extensive
experiments on the VisDrone and SIMD datasets verify the effectiveness of our
proposed method for applications in UAV-based imagery and remote sensing.

</details>


### [84] [Micro-Expression Recognition via Fine-Grained Dynamic Perception](https://arxiv.org/abs/2509.06015)
*Zhiwen Shao,Yifan Cheng,Fan Zhang,Xuehuai Shi,Canlin Li,Lizhuang Ma,Dit-yan Yeung*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的细粒度动态感知（FDP）框架，用于微表情识别（MER），通过对帧级特征进行排序来编码表情的动态信息，并结合局部-全局特征感知Transformer和排序评分器来学习帧表示，最终通过时间维度上的池化来捕获动态表示，并利用MER模块预测表情类别，同时利用动态图像构建模块缓解数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 微表情识别（MER）面临转瞬即逝、微妙和动态变化的挑战，现有方法在处理这些挑战时存在局限性，如需要关键帧或受限于训练数据的小规模和低多样性。

Method: 提出了一种细粒度动态感知（FDP）框架，包括：1. 使用局部-全局特征感知Transformer学习帧表示。2. 使用排序评分器计算每帧特征的排序分数。3. 通过时间维度上的池化聚合排序特征以捕获动态表示。4. 设计了一个MER模块用于预测表情类别，以及一个动态图像构建模块（使用编码器-解码器结构）来构建动态图像，以捕捉面部细微动作并缓解数据稀缺问题。

Result: 该方法在CASME II、SAMM、CAS(ME)^2和CAS(ME)^3数据集上，相比现有最优方法，F1分数分别提高了4.05%、2.50%、7.71%和2.11%，显著优于现有MER方法，并且在动态图像构建方面表现良好。

Conclusion: 该论文提出的FDP框架在微表情识别方面取得了显著的进展，通过引入动态感知机制和联合学习框架，有效解决了现有方法的局限性，并在多个数据集上取得了优于现有方法的性能。

Abstract: Facial micro-expression recognition (MER) is a challenging task, due to the
transience, subtlety, and dynamics of micro-expressions (MEs). Most existing
methods resort to hand-crafted features or deep networks, in which the former
often additionally requires key frames, and the latter suffers from small-scale
and low-diversity training data. In this paper, we develop a novel fine-grained
dynamic perception (FDP) framework for MER. We propose to rank frame-level
features of a sequence of raw frames in chronological order, in which the rank
process encodes the dynamic information of both ME appearances and motions.
Specifically, a novel local-global feature-aware transformer is proposed for
frame representation learning. A rank scorer is further adopted to calculate
rank scores of each frame-level feature. Afterwards, the rank features from
rank scorer are pooled in temporal dimension to capture dynamic representation.
Finally, the dynamic representation is shared by a MER module and a dynamic
image construction module, in which the former predicts the ME category, and
the latter uses an encoder-decoder structure to construct the dynamic image.
The design of dynamic image construction task is beneficial for capturing
facial subtle actions associated with MEs and alleviating the data scarcity
issue. Extensive experiments show that our method (i) significantly outperforms
the state-of-the-art MER methods, and (ii) works well for dynamic image
construction. Particularly, our FDP improves by 4.05%, 2.50%, 7.71%, and 2.11%
over the previous best results in terms of F1-score on the CASME II, SAMM,
CAS(ME)^2, and CAS(ME)^3 datasets, respectively. The code is available at
https://github.com/CYF-cuber/FDP.

</details>


### [85] [DVLO4D: Deep Visual-Lidar Odometry with Sparse Spatial-temporal Fusion](https://arxiv.org/abs/2509.06023)
*Mengmeng Liu,Michael Ying Yang,Jiuming Liu,Yunpeng Zhang,Jiangtao Li,Sander Oude Elberink,George Vosselman,Hao Cheng*

Main category: cs.CV

TL;DR: DVLO4D是一个创新的视觉-激光雷达里程计框架，通过稀疏时空融合提高了准确性和鲁棒性，实现了最先进的性能并具有实时部署的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉-激光雷达里程计方法在传感器未对准、时间信息利用不足以及手动调整以适应不同传感器配置方面存在挑战。DVLO4D旨在解决这些问题，以提高准确性和鲁棒性。

Method: DVLO4D提出稀疏查询融合（利用稀疏激光雷达查询进行多模态数据融合）、时序交互与更新模块（整合预测的位置和当前帧数据以进行姿态估计的初始化并提高鲁棒性）以及时序片段训练策略与集体平均损失机制（跨多帧聚合损失以进行全局优化并减少尺度漂移）。

Result: 在KITTI和Argoverse Odometry数据集上的实验表明，DVLO4D在姿态准确性和鲁棒性方面均达到了最先进的性能，并且具有82毫秒的推理时间，显示出实时部署的潜力。

Conclusion: DVLO4D通过稀疏时空融合、时序交互与更新以及时序片段训练策略，成功解决了传统视觉-激光雷达里程计方法的局限性，实现了卓越的准确性、鲁棒性和效率，有潜力用于自动驾驶系统的实时部署。

Abstract: Visual-LiDAR odometry is a critical component for autonomous system
localization, yet achieving high accuracy and strong robustness remains a
challenge. Traditional approaches commonly struggle with sensor misalignment,
fail to fully leverage temporal information, and require extensive manual
tuning to handle diverse sensor configurations. To address these problems, we
introduce DVLO4D, a novel visual-LiDAR odometry framework that leverages sparse
spatial-temporal fusion to enhance accuracy and robustness. Our approach
proposes three key innovations: (1) Sparse Query Fusion, which utilizes sparse
LiDAR queries for effective multi-modal data fusion; (2) a Temporal Interaction
and Update module that integrates temporally-predicted positions with current
frame data, providing better initialization values for pose estimation and
enhancing model's robustness against accumulative errors; and (3) a Temporal
Clip Training strategy combined with a Collective Average Loss mechanism that
aggregates losses across multiple frames, enabling global optimization and
reducing the scale drift over long sequences. Extensive experiments on the
KITTI and Argoverse Odometry dataset demonstrate the superiority of our
proposed DVLO4D, which achieves state-of-the-art performance in terms of both
pose accuracy and robustness. Additionally, our method has high efficiency,
with an inference time of 82 ms, possessing the potential for the real-time
deployment.

</details>


### [86] [Analysis of Blood Report Images Using General Purpose Vision-Language Models](https://arxiv.org/abs/2509.06033)
*Nadia Bakhsheshi,Hamid Beigy*

Main category: cs.CV

TL;DR: 通用视觉语言模型（VLMs）在解读血检报告方面展现出潜力，可用于开发面向患者的辅助工具。


<details>
  <summary>Details</summary>
Motivation: 解决人们在解读血检报告时遇到的困难，减少焦虑并避免忽略问题。

Method: 对Qwen-VL-Max、Gemini 2.5 Pro和Llama 4 Maverick三个通用VLMs进行评估，使用包含100份血检报告图像的数据集，并针对每份报告提出临床相关问题。使用Sentence-BERT处理和比较模型答案。

Result: 通用VLMs能够根据血检报告图像提供清晰的解读，显示出其在初步分析方面的实用性和前景。

Conclusion: 通用VLMs是开发面向患者的初步血检报告分析工具的实用且有前途的技术，可以提高健康素养并普及复杂的医疗信息，但结果应谨慎解读，因为数据集有限。

Abstract: The reliable analysis of blood reports is important for health knowledge, but
individuals often struggle with interpretation, leading to anxiety and
overlooked issues. We explore the potential of general-purpose Vision-Language
Models (VLMs) to address this challenge by automatically analyzing blood report
images. We conduct a comparative evaluation of three VLMs: Qwen-VL-Max, Gemini
2.5 Pro, and Llama 4 Maverick, determining their performance on a dataset of
100 diverse blood report images. Each model was prompted with clinically
relevant questions adapted to each blood report. The answers were then
processed using Sentence-BERT to compare and evaluate how closely the models
responded. The findings suggest that general-purpose VLMs are a practical and
promising technology for developing patient-facing tools for preliminary blood
report analysis. Their ability to provide clear interpretations directly from
images can improve health literacy and reduce the limitations to understanding
complex medical information. This work establishes a foundation for the future
development of reliable and accessible AI-assisted healthcare applications.
While results are encouraging, they should be interpreted cautiously given the
limited dataset size.

</details>


### [87] [TinyDef-DETR:An Enhanced DETR Detector for UAV Power Line Defect Detection](https://arxiv.org/abs/2509.06035)
*Jiaming Cui*

Main category: cs.CV

TL;DR: TinyDef-DETR是一个基于DETR的框架，用于检测输电线路上的微小缺陷，通过无损下采样、边缘增强卷积、跨阶段注意力以及Focaler-Wise-SIoU回归损失来解决小目标检测的挑战，并在CSG-ADCD和VisDrone数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 自动化的无人机输电线路缺陷检测面临小目标和复杂背景下的模糊缺陷难以检测的问题。传统方法存在细节丢失、边界敏感性弱和全局/局部信息融合不足的缺点。

Method: 提出TinyDef-DETR框架，包含：1. 无损下采样的空间深度模块；2. 边界感知特征提取的边缘增强卷积；3. 融合全局和局部信息的跨阶段双域多尺度注意力模块；4. 改进小目标定位的Focaler-Wise-SIoU回归损失。

Result: 在CSG-ADCD数据集上，TinyDef-DETR在精度和召回率上均优于现有方法，尤其在小目标子集上表现突出，同时计算开销适中。在VisDrone数据集上的验证也证明了其泛化能力。

Conclusion: 结合细节保留的下采样、边缘敏感表示、双域注意力和自适应回归，TinyDef-DETR为无人机输电网小缺陷检测提供了一个实用高效的解决方案。

Abstract: Automated inspection of transmission lines using UAVs is hindered by the
difficulty of detecting small and ambiguous defects against complex
backgrounds. Conventional detectors often suffer from detail loss due to
strided downsampling, weak boundary sensitivity in lightweight backbones, and
insufficient integration of global context with local cues. To address these
challenges, we propose TinyDef-DETR, a DETR-based framework designed for
small-defect detection. The method introduces a stride-free space-to-depth
module for lossless downsampling, an edge-enhanced convolution for
boundary-aware feature extraction, a cross-stage dual-domain multi-scale
attention module to jointly capture global and local information, and a
Focaler-Wise-SIoU regression loss to improve localization of small objects.
Experiments conducted on the CSG-ADCD dataset demonstrate that TinyDef-DETR
achieves substantial improvements in both precision and recall compared to
competitive baselines, with particularly notable gains on small-object subsets,
while incurring only modest computational overhead. Further validation on the
VisDrone benchmark confirms the generalization capability of the proposed
approach. Overall, the results indicate that integrating detail-preserving
downsampling, edge-sensitive representations, dual-domain attention, and
difficulty-adaptive regression provides a practical and efficient solution for
UAV-based small-defect inspection in power grids.

</details>


### [88] [BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models](https://arxiv.org/abs/2509.06040)
*Yuming Li,Yikai Wang,Yuying Zhu,Zhongyu Zhao,Ming Lu,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: BranchGRPO通过引入分支采样策略来优化SDE采样过程，降低了图像和视频生成模型的计算成本和训练时间，同时提高了对人类偏好的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于GRPO的图像和视频生成模型在提高人类偏好对齐方面取得了显著进展，但面临计算成本高、训练不稳定等问题。

Method: 提出BranchGRPO方法，引入分支采样策略更新SDE采样过程，通过共享通用前缀、修剪低回报路径和冗余深度来降低每步更新的计算成本，并保持或提高探索多样性。该方法还包括一个基于树的优势估计器，采用密集的进程级奖励，以及利用路径和深度冗余的修剪策略。

Result: 在图像和视频偏好对齐的实验中，BranchGRPO比强基线提高了16%的对齐分数，同时将训练时间缩短了50%。

Conclusion: BranchGRPO通过分支采样、基于树的优势估计器和修剪策略，有效降低了计算成本和训练时间，并提高了图像和视频生成模型的人类偏好对齐效果。

Abstract: Recent advancements in aligning image and video generative models via GRPO
have achieved remarkable gains in enhancing human preference alignment.
However, these methods still face high computational costs from on-policy
rollouts and excessive SDE sampling steps, as well as training instability due
to sparse rewards. In this paper, we propose BranchGRPO, a novel method that
introduces a branch sampling policy updating the SDE sampling process. By
sharing computation across common prefixes and pruning low-reward paths and
redundant depths, BranchGRPO substantially lowers the per-update compute cost
while maintaining or improving exploration diversity. This work makes three
main contributions: (1) a branch sampling scheme that reduces rollout and
training cost; (2) a tree-based advantage estimator incorporating dense
process-level rewards; and (3) pruning strategies exploiting path and depth
redundancy to accelerate convergence and boost performance. Experiments on
image and video preference alignment show that BranchGRPO improves alignment
scores by 16% over strong baselines, while cutting training time by 50%.

</details>


### [89] [Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities](https://arxiv.org/abs/2509.06041)
*Mohammad Ahangarkiasari,Hassan Pouraria*

Main category: cs.CV

TL;DR: 图神经网络（GNNs）在模拟封闭腔体内的浮升驱动传热方面展现出潜力，但传统 GNNs 在处理长距离依赖方面存在局限。本文提出了一种新的多阶段 GNN 架构，通过分层池化和反池化操作，有效捕捉多尺度的全局到局部的相互作用，显著提高了预测精度和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有计算流体动力学（CFD）模型在热设计领域虽然精确，但计算成本高昂，限制了迭代速度。数据驱动模型，特别是图神经网络（GNNs），为直接从仿真数据中学习热流体行为提供了新途径，尤其适用于非结构化网格。然而，传统 GNNs 在处理高分辨率图结构中的长距离依赖方面存在困难。

Method: 提出了一种新颖的多阶段 GNN 架构，该架构利用分层池化和反池化操作，以渐进的方式模拟跨越多个空间尺度的全局到局部相互作用。

Result: 在模拟不同长宽比的矩形腔体内自然对流的新型 CFD 数据集上进行评估。结果表明，与最先进的 GNN 基线相比，所提出的模型实现了更高的预测精度、更优的训练效率，并减少了长期误差累积。

Conclusion: 所提出的多阶段 GNN 方法在模拟基于网格的流体动力学仿真中的复杂传热方面具有巨大潜力。

Abstract: Buoyancy-driven heat transfer in closed cavities serves as a canonical
testbed for thermal design High-fidelity CFD modelling yields accurate thermal
field solutions, yet its reliance on expert-crafted physics models, fine
meshes, and intensive computation limits rapid iteration. Recent developments
in data-driven modeling, especially Graph Neural Networks (GNNs), offer new
alternatives for learning thermal-fluid behavior directly from simulation data,
particularly on irregular mesh structures. However, conventional GNNs often
struggle to capture long-range dependencies in high-resolution graph
structures. To overcome this limitation, we propose a novel multi-stage GNN
architecture that leverages hierarchical pooling and unpooling operations to
progressively model global-to-local interactions across multiple spatial
scales. We evaluate the proposed model on our newly developed CFD dataset
simulating natural convection within a rectangular cavities with varying aspect
ratios where the bottom wall is isothermal hot, the top wall is isothermal
cold, and the two vertical walls are adiabatic. Experimental results
demonstrate that the proposed model achieves higher predictive accuracy,
improved training efficiency, and reduced long-term error accumulation compared
to state-of-the-art (SOTA) GNN baselines. These findings underscore the
potential of the proposed multi-stage GNN approach for modeling complex heat
transfer in mesh-based fluid dynamics simulations.

</details>


### [90] [Interleaving Reasoning for Better Text-to-Image Generation](https://arxiv.org/abs/2509.06945)
*Wenxuan Huang,Shuang Chen,Zheyong Xie,Shaosheng Cao,Shixiang Tang,Yufan Shen,Qingyu Yin,Wenbo Hu,Xiaoman Wang,Yuntian Tang,Junbo Qiao,Yue Guo,Yao Hu,Zhenfei Yin,Philip Torr,Yu Cheng,Wanli Ouyang,Shaohui Lin*

Main category: cs.CV

TL;DR: 我们提出了一个名为IRG的新框架，通过交替进行文本推理和图像生成来改进文本到图像的生成。IRG首先生成文本提示来指导初始图像，然后反思结果以优化细节、视觉质量和美学。我们还开发了一个名为IRGL的学习方案和IRGL-300K数据集来训练IRG。实验表明，IRG在多个基准测试上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 最近的统一多模态模型在图像生成方面取得了显著进展，但在指令遵循和细节保留方面仍与GPT-4o等系统存在差距。受交替推理研究的启发，本文旨在探索这种推理能否进一步改进文本到图像（T2I）生成。

Method: 我们提出了交替推理生成（IRG）框架，该框架在文本推理和图像合成之间交替进行。模型首先生成文本推理以指导初始图像，然后反思结果以在保持语义的同时，优化细节、视觉质量和美学。我们还提出了IRGL学习方案来有效训练IRG，该方案包括两个子目标：1.加强初始的思考-生成阶段以建立核心内容和基础质量；2.实现高质量的文本反思和在后续图像中忠实地实现这些改进。我们整理了IRGL-300K数据集，该数据集包含六种分解的学习模式，共同覆盖了文本推理和完整的思考-图像轨迹学习。

Result: IRG在GenEval、WISE、TIIF、GenAI-Bench和OneIG-EN等基准测试上取得了领先的性能，得分提高了5-10个百分点，同时在视觉质量和细节保真度方面也得到了显著提升。

Conclusion: IRG框架通过交替推理和生成，显著提高了文本到图像生成的能力，在多个评估指标上都取得了最先进的性能，并且在视觉质量和细节保真度方面表现出色。IRGL学习方案和IRGL-300K数据集的提出，为有效训练此类模型提供了支持。

Abstract: Unified multimodal understanding and generation models recently have achieve
significant improvement in image generation capability, yet a large gap remains
in instruction following and detail preservation compared to systems that
tightly couple comprehension with generation such as GPT-4o. Motivated by
recent advances in interleaving reasoning, we explore whether such reasoning
can further improve Text-to-Image (T2I) generation. We introduce Interleaving
Reasoning Generation (IRG), a framework that alternates between text-based
thinking and image synthesis: the model first produces a text-based thinking to
guide an initial image, then reflects on the result to refine fine-grained
details, visual quality, and aesthetics while preserving semantics. To train
IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL),
which targets two sub-goals: (1) strengthening the initial think-and-generate
stage to establish core content and base quality, and (2) enabling high-quality
textual reflection and faithful implementation of those refinements in a
subsequent image. We curate IRGL-300K, a dataset organized into six decomposed
learning modes that jointly cover learning text-based thinking, and full
thinking-image trajectories. Starting from a unified foundation model that
natively emits interleaved text-image outputs, our two-stage training first
builds robust thinking and reflection, then efficiently tunes the IRG pipeline
in the full thinking-image trajectory data. Extensive experiments show SoTA
performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF,
GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality
and fine-grained fidelity. The code, model weights and datasets will be
released in: https://github.com/Osilly/Interleaving-Reasoning-Generation .

</details>


### [91] [Home-made Diffusion Model from Scratch to Hatch](https://arxiv.org/abs/2509.06068)
*Shih-Ying Yeh*

Main category: cs.CV

TL;DR: HDM是一个高效且强大的文生图扩散模型，可以在消费级硬件上进行训练和推理，实现了具有竞争力的1024x1024生成质量，同时训练成本低廉。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个可以在消费级硬件上进行训练和推理的高效且强大的文生图扩散模型，以降低高质量文生图的计算要求，实现计算民主化。

Method: 提出了交叉U-Transformer (XUT) 架构，该架构在跳跃连接中使用了交叉注意力机制，以增强特征集成并提高构图一致性。此外，还采用了一套全面的训练方法，包括TREAD加速、一种新颖的移位裁剪策略以实现高效的任意长宽比训练，以及渐进式分辨率缩放。

Result: HDM在消费级硬件（四块RTX5090 GPU）上实现了535-620美元的低训练成本，生成了具有竞争力的1024x1024分辨率图像。实验证明，参数量较小的模型（3.43亿参数）经过精心设计的架构也能产生高质量的结果，并具备直观的相机控制等新兴能力。

Conclusion: HDM提供了一种替代的扩展范式，为计算资源有限的个人研究人员和小型组织开辟了一条实现高质量文生图的可行途径，有助于推动文生图技术的普及。

Abstract: We introduce Home-made Diffusion Model (HDM), an efficient yet powerful
text-to-image diffusion model optimized for training (and inferring) on
consumer-grade hardware. HDM achieves competitive 1024x1024 generation quality
while maintaining a remarkably low training cost of $535-620 using four RTX5090
GPUs, representing a significant reduction in computational requirements
compared to traditional approaches. Our key contributions include: (1)
Cross-U-Transformer (XUT), a novel U-shape transformer, Cross-U-Transformer
(XUT), that employs cross-attention for skip connections, providing superior
feature integration that leads to remarkable compositional consistency; (2) a
comprehensive training recipe that incorporates TREAD acceleration, a novel
shifted square crop strategy for efficient arbitrary aspect-ratio training, and
progressive resolution scaling; and (3) an empirical demonstration that smaller
models (343M parameters) with carefully crafted architectures can achieve
high-quality results and emergent capabilities, such as intuitive camera
control. Our work provides an alternative paradigm of scaling, demonstrating a
viable path toward democratizing high-quality text-to-image generation for
individual researchers and smaller organizations with limited computational
resources.

</details>


### [92] [MedSeqFT: Sequential Fine-tuning Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.06096)
*Yiwen Ye,Yicheng Wu,Xiangde Luo,He Zhang,Ziyang Chen,Ting Dang,Yanning Zhang,Yong Xia*

Main category: cs.CV

TL;DR: MedSeqFT是一个顺序微调框架，通过最大数据相似性（MDS）样本选择和基于LoRA的知识蒸馏（K&G RFT）来解决现有微调策略的局限性，从而在医疗图像分割任务中有效保留预训练知识并提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的模型微调策略在处理医疗图像分割等顺序出现下游任务时存在局限性：并行微调无法利用共享知识，而多任务微调需要同时访问所有数据集且难以整合增量任务。

Method: MedSeqFT框架包含两个核心组件：1. 最大数据相似性（MDS）选择，用于识别最能代表原始预训练分布的下游样本，以保留通用知识。2. 知识与泛化保留微调（K&G RFT），一种基于LoRA的知识蒸馏方法，用于平衡任务特定适应与保留预训练知识。

Result: 在两个涵盖十个3D分割任务的多任务数据集上的实验表明，MedSeqFT的性能优于最先进的微调策略，平均Dice系数提高了3.0%。在两个未见过任务（COVID-19-20和Kidney）上的评估也证实了MedSeqFT提高了迁移能力，特别是在肿瘤分割方面。损失景观和参数变化的视觉分析也证明了MedSeqFT的鲁棒性。

Conclusion: MedSeqFT提供了一种有效且能保留知识的顺序微调范式，用于将基础模型适应不断变化的临床任务。

Abstract: Foundation models have become a promising paradigm for advancing medical
image analysis, particularly for segmentation tasks where downstream
applications often emerge sequentially. Existing fine-tuning strategies,
however, remain limited: parallel fine-tuning isolates tasks and fails to
exploit shared knowledge, while multi-task fine-tuning requires simultaneous
access to all datasets and struggles with incremental task integration. To
address these challenges, we propose MedSeqFT, a sequential fine-tuning
framework that progressively adapts pre-trained models to new tasks while
refining their representational capacity. MedSeqFT introduces two core
components: (1) Maximum Data Similarity (MDS) selection, which identifies
downstream samples most representative of the original pre-training
distribution to preserve general knowledge, and (2) Knowledge and
Generalization Retention Fine-Tuning (K&G RFT), a LoRA-based knowledge
distillation scheme that balances task-specific adaptation with the retention
of pre-trained knowledge. Extensive experiments on two multi-task datasets
covering ten 3D segmentation tasks demonstrate that MedSeqFT consistently
outperforms state-of-the-art fine-tuning strategies, yielding substantial
performance gains (e.g., an average Dice improvement of 3.0%). Furthermore,
evaluations on two unseen tasks (COVID-19-20 and Kidney) verify that MedSeqFT
enhances transferability, particularly for tumor segmentation. Visual analyses
of loss landscapes and parameter variations further highlight the robustness of
MedSeqFT. These results establish sequential fine-tuning as an effective,
knowledge-retentive paradigm for adapting foundation models to evolving
clinical tasks. Code will be released.

</details>


### [93] [PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology](https://arxiv.org/abs/2509.06105)
*Yating Huang,Ziyan Huang,Lintao Xiang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: 该研究提出了PathoHR-Bench基准和一种针对病理领域的视觉-语言（VL）模型训练方案，以提高VL模型在病理图像分析中的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言（VL）模型在处理病理图像时面临挑战，因为它们难以捕捉结构相似性和细微形态变化，并且在解释结构化的病理报告时，复杂的推理能力不足。

Method: 提出PathoHR-Bench基准来评估VL模型在病理领域进行分层语义理解和组合推理的能力。引入一种病理学特定的VL训练方案，通过生成增强和扰动样本来进行多模态对比学习。

Result: 现有VL模型在PathoHR-Bench基准上的表现不佳，无法有效建模复杂的跨模态关系。研究提出的训练方案在PathoHR-Bench基准和另外六个病理数据集上取得了最先进的性能。

Conclusion: 研究提出的病理学特定的VL训练方案能够有效提升模型在细粒度病理图像理解方面的能力，克服了现有VL模型的局限性，为临床应用提供了可能性。

Abstract: Accurate analysis of pathological images is essential for automated tumor
diagnosis but remains challenging due to high structural similarity and subtle
morphological variations in tissue images. Current vision-language (VL) models
often struggle to capture the complex reasoning required for interpreting
structured pathological reports. To address these limitations, we propose
PathoHR-Bench, a novel benchmark designed to evaluate VL models' abilities in
hierarchical semantic understanding and compositional reasoning within the
pathology domain. Results of this benchmark reveal that existing VL models fail
to effectively model intricate cross-modal relationships, hence limiting their
applicability in clinical setting. To overcome this, we further introduce a
pathology-specific VL training scheme that generates enhanced and perturbed
samples for multimodal contrastive learning. Experimental evaluations
demonstrate that our approach achieves state-of-the-art performance on
PathoHR-Bench and six additional pathology datasets, highlighting its
effectiveness in fine-grained pathology representation.

</details>


### [94] [CARDIE: clustering algorithm on relevant descriptors for image enhancement](https://arxiv.org/abs/2509.06116)
*Giulia Bonino,Luca Alberto Rizzo*

Main category: cs.CV

TL;DR: CARDIE是一个无监督算法，通过颜色和亮度内容对图像进行聚类，以改进图像增强。


<details>
  <summary>Details</summary>
Motivation: 图像聚类在图像增强中的应用受限于有意义聚类的定义困难。

Method: 提出CARDIE无监督算法，基于颜色和亮度内容聚类；提出量化图像增强算法对亮度分布和局部方差影响的方法。

Result: CARDIE产生的聚类比基于语义属性的聚类更适用于图像增强；利用CARDIE聚类重采样图像增强数据集可提升色调映射和去噪算法性能。

Conclusion: CARDIE算法及其聚类方法可有效用于图像增强任务，并改进相关算法的性能。

Abstract: Automatic image clustering is a cornerstone of computer vision, yet its
application to image enhancement remains limited, primarily due to the
difficulty of defining clusters that are meaningful for this specific task. To
address this issue, we introduce CARDIE, an unsupervised algorithm that
clusters images based on their color and luminosity content. In addition, we
introduce a method to quantify the impact of image enhancement algorithms on
luminance distribution and local variance. Using this method, we demonstrate
that CARDIE produces clusters more relevant to image enhancement than those
derived from semantic image attributes. Furthermore, we demonstrate that CARDIE
clusters can be leveraged to resample image enhancement datasets, leading to
improved performance for tone mapping and denoising algorithms. To encourage
adoption and ensure reproducibility, we publicly release CARDIE code on our
GitHub.

</details>


### [95] [SpecSwin3D: Generating Hyperspectral Imagery from Multispectral Data via Transformer Networks](https://arxiv.org/abs/2509.06122)
*Tang Sui,Songxi Yang,Qunying Huang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multispectral and hyperspectral imagery are widely used in agriculture,
environmental monitoring, and urban planning due to their complementary spatial
and spectral characteristics. A fundamental trade-off persists: multispectral
imagery offers high spatial but limited spectral resolution, while
hyperspectral imagery provides rich spectra at lower spatial resolution. Prior
hyperspectral generation approaches (e.g., pan-sharpening variants, matrix
factorization, CNNs) often struggle to jointly preserve spatial detail and
spectral fidelity. In response, we propose SpecSwin3D, a transformer-based
model that generates hyperspectral imagery from multispectral inputs while
preserving both spatial and spectral quality. Specifically, SpecSwin3D takes
five multispectral bands as input and reconstructs 224 hyperspectral bands at
the same spatial resolution. In addition, we observe that reconstruction errors
grow for hyperspectral bands spectrally distant from the input bands. To
address this, we introduce a cascade training strategy that progressively
expands the spectral range to stabilize learning and improve fidelity.
Moreover, we design an optimized band sequence that strategically repeats and
orders the five selected multispectral bands to better capture pairwise
relations within a 3D shifted-window transformer framework. Quantitatively, our
model achieves a PSNR of 35.82 dB, SAM of 2.40{\deg}, and SSIM of 0.96,
outperforming the baseline MHF-Net by +5.6 dB in PSNR and reducing ERGAS by
more than half. Beyond reconstruction, we further demonstrate the practical
value of SpecSwin3D on two downstream tasks, including land use classification
and burnt area segmentation.

</details>


### [96] [RetinaGuard: Obfuscating Retinal Age in Fundus Images for Biometric Privacy Preserving](https://arxiv.org/abs/2509.06142)
*Zhengquan Luo,Chi Liu,Dongfu Xiao,Zhen Yu,Yueye Wang,Tianqing Zhu*

Main category: cs.CV

TL;DR: RetinaGuard框架通过特征级生成对抗性掩蔽来保护视网膜年龄的生物识别隐私，同时保持图像质量和诊断效用，并使用知识蒸馏来防御黑盒年龄预测模型。


<details>
  <summary>Details</summary>
Motivation: 视网膜年龄可以预测多种健康风险，但其生物识别信息存在隐私泄露风险。

Method: 提出RetinaGuard框架，采用特征级生成对抗性掩蔽来模糊视网膜年龄，并结合多对一知识蒸馏策略，利用视网膜基础模型和多个代理年龄编码器来防御黑盒模型。

Result: RetinaGuard成功模糊了视网膜年龄的预测，同时对图像质量和病理特征表示的影响最小，并且可以扩展到其他医学图像生物标志物。

Conclusion: RetinaGuard为医学图像衍生的生物识别信息提供了一种有效的隐私保护方法。

Abstract: The integration of AI with medical images enables the extraction of implicit
image-derived biomarkers for a precise health assessment. Recently, retinal
age, a biomarker predicted from fundus images, is a proven predictor of
systemic disease risks, behavioral patterns, aging trajectory and even
mortality. However, the capability to infer such sensitive biometric data
raises significant privacy risks, where unauthorized use of fundus images could
lead to bioinformation leakage, breaching individual privacy. In response, we
formulate a new research problem of biometric privacy associated with medical
images and propose RetinaGuard, a novel privacy-enhancing framework that
employs a feature-level generative adversarial masking mechanism to obscure
retinal age while preserving image visual quality and disease diagnostic
utility. The framework further utilizes a novel multiple-to-one knowledge
distillation strategy incorporating a retinal foundation model and diverse
surrogate age encoders to enable a universal defense against black-box age
prediction models. Comprehensive evaluations confirm that RetinaGuard
successfully obfuscates retinal age prediction with minimal impact on image
quality and pathological feature representation. RetinaGuard is also flexible
for extension to other medical image derived biomarkers. RetinaGuard is also
flexible for extension to other medical image biomarkers.

</details>


### [97] [UniVerse-1: Unified Audio-Video Generation via Stitching of Experts](https://arxiv.org/abs/2509.06155)
*Duomin Wang,Wei Zuo,Aojie Li,Ling-Hao Chen,Xinyao Liao,Deyu Zhou,Zixin Yin,Xili Dai,Daxin Jiang,Gang Yu*

Main category: cs.CV

TL;DR: UniVerse-1是一个统一的音频和视频生成模型，它通过缝合专家（SoE）技术和在线标注流程，实现了高效训练和高质量的音视频同步生成，并引入了Verse-Bench基准来评估其性能。


<details>
  <summary>Details</summary>
Motivation: 为了实现统一的、类似Veo-3的模型，能够同时生成协调的音频和视频，并提高训练效率。

Method: 采用缝合专家（SoE）技术，深度融合预训练的视频和音乐生成专家模型的相应模块；开发了一个在线标注流程，在训练过程中处理所需数据并生成标签，以确保音频（环境声和语音）与视频内容的准确标注和时间对齐。

Result: 经过约7600小时音视频数据微调后，模型在环境声音生成方面产生了音视频协调良好的结果，在语音生成方面实现了强大的对齐。

Conclusion: UniVerse-1模型通过缝合专家技术和在线标注流程，成功实现了高效的音视频同步生成，并在新基准Verse-Bench上进行了评估，旨在缩小与最先进模型（如Veo3）的性能差距。研究者已公开模型和代码以促进社区研究。

Abstract: We introduce UniVerse-1, a unified, Veo-3-like model capable of
simultaneously generating coordinated audio and video. To enhance training
efficiency, we bypass training from scratch and instead employ a stitching of
experts (SoE) technique. This approach deeply fuses the corresponding blocks of
pre-trained video and music generation experts models, thereby fully leveraging
their foundational capabilities. To ensure accurate annotations and temporal
alignment for both ambient sounds and speech with video content, we developed
an online annotation pipeline that processes the required training data and
generates labels during training process. This strategy circumvents the
performance degradation often caused by misalignment text-based annotations.
Through the synergy of these techniques, our model, after being finetuned on
approximately 7,600 hours of audio-video data, produces results with
well-coordinated audio-visuals for ambient sounds generation and strong
alignment for speech generation. To systematically evaluate our proposed
method, we introduce Verse-Bench, a new benchmark dataset. In an effort to
advance research in audio-video generation and to close the performance gap
with state-of-the-art models such as Veo3, we make our model and code publicly
available. We hope this contribution will benefit the broader research
community. Project page: https://dorniwang.github.io/UniVerse-1/.

</details>


### [98] [UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning](https://arxiv.org/abs/2509.06165)
*Huy Le,Nhat Chung,Tung Kieu,Jingkang Yang,Ngan Le*

Main category: cs.CV

TL;DR: UNO是一个统一的视频场景图生成框架，能够同时处理目标级别的和全景级别的任务，通过解耦的对象和关系槽以及时间一致性学习来捕捉动态交互。


<details>
  <summary>Details</summary>
Motivation: 现有的视频场景图生成方法通常需要任务特定的架构和多阶段训练流程，分别处理目标级别或全景级别。本研究旨在提出一个统一的、单阶段的框架，以简化流程并实现跨不同视觉粒度的泛化。

Method: UNO框架的核心是一个扩展的槽注意机制，将视觉特征分解为对象槽和关系槽。此外，还引入了对象时间一致性学习来确保跨帧的对象表示一致性，并使用动态三元组预测模块来捕捉随时间变化的交互。

Result: UNO在标准的目标级别和全景级别的VidSGG基准测试中取得了具有竞争力的性能，并因其统一、以对象为中心的设计而提高了效率。

Conclusion: UNO成功地实现了视频场景图生成的统一，并能够有效地处理不同粒度的任务，同时简化了训练流程并提高了效率。

Abstract: Video Scene Graph Generation (VidSGG) aims to represent dynamic visual
content by detecting objects and modeling their temporal interactions as
structured graphs. Prior studies typically target either coarse-grained
box-level or fine-grained panoptic pixel-level VidSGG, often requiring
task-specific architectures and multi-stage training pipelines. In this paper,
we present UNO (UNified Object-centric VidSGG), a single-stage, unified
framework that jointly addresses both tasks within an end-to-end architecture.
UNO is designed to minimize task-specific modifications and maximize parameter
sharing, enabling generalization across different levels of visual granularity.
The core of UNO is an extended slot attention mechanism that decomposes visual
features into object and relation slots. To ensure robust temporal modeling, we
introduce object temporal consistency learning, which enforces consistent
object representations across frames without relying on explicit tracking
modules. Additionally, a dynamic triplet prediction module links relation slots
to corresponding object pairs, capturing evolving interactions over time. We
evaluate UNO on standard box-level and pixel-level VidSGG benchmarks. Results
demonstrate that UNO not only achieves competitive performance across both
tasks but also offers improved efficiency through a unified, object-centric
design.

</details>


### [99] [AI-Based Applied Innovation for Fracture Detection in X-rays Using Custom CNN and Transfer Learning Models](https://arxiv.org/abs/2509.06228)
*Amna Hassan,Ilsa Afzaal,Nouman Muneeb,Aneeqa Batool,Hamail Noor*

Main category: cs.CV

TL;DR: 提出一种基于卷积神经网络（CNN）的人工智能模型，用于从X射线图像自动检测骨折，并与其他迁移学习模型进行了比较。


<details>
  <summary>Details</summary>
Motivation: 骨折是全球性的健康问题，尤其在资源匮乏地区，放射学服务有限。传统成像方法成本高、有辐射且依赖专业解读。

Method: 使用自定义CNN模型和迁移学习模型（EfficientNetB0、MobileNetV2、ResNet50）在FracAtlas数据集上进行训练和测试，该数据集包含4083张匿名骨骼X光片。

Result: 自定义CNN模型在FracAtlas数据集上达到了95.96%的准确率、0.94的精确率、0.88的召回率和0.91的F1分数。迁移学习模型表现不佳，这可能与类别不平衡和数据集限制有关。

Conclusion: 轻量级CNN在X射线骨折检测方面具有潜力，强调了公平基准测试、多样化数据集和外部验证对临床应用的重要性。

Abstract: Bone fractures present a major global health challenge, often resulting in
pain, reduced mobility, and productivity loss, particularly in low-resource
settings where access to expert radiology services is limited. Conventional
imaging methods suffer from high costs, radiation exposure, and dependency on
specialized interpretation. To address this, we developed an AI-based solution
for automated fracture detection from X-ray images using a custom Convolutional
Neural Network (CNN) and benchmarked it against transfer learning models
including EfficientNetB0, MobileNetV2, and ResNet50. Training was conducted on
the publicly available FracAtlas dataset, comprising 4,083 anonymized
musculoskeletal radiographs. The custom CNN achieved 95.96% accuracy, 0.94
precision, 0.88 recall, and an F1-score of 0.91 on the FracAtlas dataset.
Although transfer learning models (EfficientNetB0, MobileNetV2, ResNet50)
performed poorly in this specific setup, these results should be interpreted in
light of class imbalance and data set limitations. This work highlights the
promise of lightweight CNNs for detecting fractures in X-rays and underscores
the importance of fair benchmarking, diverse datasets, and external validation
for clinical translation

</details>


### [100] [Exploring Light-Weight Object Recognition for Real-Time Document Detection](https://arxiv.org/abs/2509.06246)
*Lucas Wojcik,Luiz Coelho,Roger Granada,David Menotti*

Main category: cs.CV

TL;DR: 使用更小的模型和数据增强技术，实现了高效的文档检测和校正，同时保持了具有竞争力的OCR质量。


<details>
  <summary>Details</summary>
Motivation: 现有的文档识别和倾斜估计方法在实时文档检测和校正方面存在不足，而这对于从视觉文档中自动检索信息至关重要。

Method: 改编IWPOD-Net模型，并在NBID合成数据集上进行训练，同时进行数据增强和跨数据集验证。将该方法与现有最先进方法进行比较，并使用基于Levenshtein距离的新OCR质量指标进行评估。

Result: 所提出的模型比现有的最先进解决方案更小、更高效，同时在OCR质量指标上具有竞争力。研究表明，即使文档校正不完美，也能达到最先进的性能。

Conclusion: 提出的模型在效率和OCR质量方面均优于现有技术，为实时文档检测和信息检索提供了一个有前景的解决方案。

Abstract: Object Recognition and Document Skew Estimation have come a long way in terms
of performance and efficiency. New models follow one of two directions:
improving performance using larger models, and improving efficiency using
smaller models. However, real-time document detection and rectification is a
niche that is largely unexplored by the literature, yet it remains a vital step
for automatic information retrieval from visual documents. In this work, we
strive towards an efficient document detection pipeline that is satisfactory in
terms of Optical Character Recognition (OCR) retrieval and faster than other
available solutions. We adapt IWPOD-Net, a license plate detection network, and
train it for detection on NBID, a synthetic ID card dataset. We experiment with
data augmentation and cross-dataset validation with MIDV (another synthetic ID
and passport document dataset) to find the optimal scenario for the model.
Other methods from both the Object Recognition and Skew Estimation
state-of-the-art are evaluated for comparison with our approach. We use each
method to detect and rectify the document, which is then read by an OCR system.
The OCR output is then evaluated using a novel OCR quality metric based on the
Levenshtein distance. Since the end goal is to improve automatic information
retrieval, we use the overall OCR quality as a performance metric. We observe
that with a promising model, document rectification does not have to be perfect
to attain state-of-the-art performance scores. We show that our model is
smaller and more efficient than current state-of-the-art solutions while
retaining a competitive OCR quality metric. All code is available at
https://github.com/BOVIFOCR/iwpod-doc-corners.git

</details>


### [101] [Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes](https://arxiv.org/abs/2509.06266)
*Mohsen Gholami,Ahmad Rezaei,Zhou Weimin,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: 该研究提出了Ego3D-Bench基准和Ego3D-VLM框架，以评估和提升视觉语言模型（VLM）在多视角、以自我为中心的3D空间推理能力，结果显示现有VLM在这一领域仍有较大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在理解3D空间关系方面存在局限性，现有数据集多基于单张图像或室内视频，未能满足机器人和自动驾驶等依赖多视角观察的现实应用需求。

Method: 引入Ego3D-Bench基准，包含8600多个QA对，使用以自我为中心、多视角户外数据评估16个SOTA VLM；提出Ego3D-VLM框架，通过生成基于全局3D坐标的认知图来增强VLM的3D空间推理能力。

Result: 在Ego3D-Bench基准上，现有VLM与人类水平相比存在显著差距。Ego3D-VLM框架在多项选择QA任务上平均提升12%，在绝对距离估计任务上平均提升56%。

Conclusion: Ego3D-Bench和Ego3D-VLM为推动VLM在真实多视角环境中的3D空间理解能力提供了有价值的工具，有助于缩小VLM与人类水平在空间理解能力上的差距。

Abstract: Understanding 3D spatial relationships remains a major limitation of current
Vision-Language Models (VLMs). Prior work has addressed this issue by creating
spatial question-answering (QA) datasets based on single images or indoor
videos. However, real-world embodied AI agents such as robots and self-driving
cars typically rely on ego-centric, multi-view observations. To this end, we
introduce Ego3D-Bench, a new benchmark designed to evaluate the spatial
reasoning abilities of VLMs using ego-centric, multi-view outdoor data.
Ego3D-Bench comprises over 8,600 QA pairs, created with significant involvement
from human annotators to ensure quality and diversity. We benchmark 16 SOTA
VLMs, including GPT-4o, Gemini1.5-Pro, InternVL3, and Qwen2.5-VL. Our results
reveal a notable performance gap between human level scores and VLM
performance, highlighting that current VLMs still fall short of human level
spatial understanding. To bridge this gap, we propose Ego3D-VLM, a
post-training framework that enhances 3D spatial reasoning of VLMs. Ego3D-VLM
generates cognitive map based on estimated global 3D coordinates, resulting in
12% average improvement on multi-choice QA and 56% average improvement on
absolute distance estimation. Ego3D-VLM is modular and can be integrated with
any existing VLM. Together, Ego3D-Bench and Ego3D-VLM offer valuable tools for
advancing toward human level spatial understanding in real-world, multi-view
environments.

</details>


### [102] [AI-driven Remote Facial Skin Hydration and TEWL Assessment from Selfie Images: A Systematic Solution](https://arxiv.org/abs/2509.06282)
*Cecelia Soh,Rizhao Cai,Monalisha Paul,Dennis Sng,Alex Kot*

Main category: cs.CV

TL;DR: 本研究提出了一种利用智能手机自拍面部图像远程估计皮肤水合作用(SH)和经皮水分流失(TEWL)的方法，解决了传统测量方法不易获得的问题。


<details>
  <summary>Details</summary>
Motivation: 皮肤健康和抗病能力与皮肤屏障功能密切相关，但目前测量皮肤水合作用(SH)和经皮水分流失(TEWL)的设备不易为公众获取。

Method: 提出了一种包含数据收集、预处理和使用新提出的皮肤优先自适应视觉Transformer模型进行SH/TEWL回归的系统性解决方案。通过引入对称对比正则化来解决数据不平衡问题。

Result: 实验证明该方法能有效估计SH和TEWL，并解决数据不平衡引起的模型偏差。

Conclusion: 本研究首次实现了无需物理测量即可从自拍面部图像评估皮肤状况，弥合了计算机视觉与皮肤护理研究的差距，为AI驱动的皮肤分析在现实世界中的广泛应用奠定了基础。

Abstract: Skin health and disease resistance are closely linked to the skin barrier
function, which protects against environmental factors and water loss. Two key
physiological indicators can quantitatively represent this barrier function:
skin hydration (SH) and trans-epidermal water loss (TEWL). Measurement of SH
and TEWL is valuable for the public to monitor skin conditions regularly,
diagnose dermatological issues, and personalize their skincare regimens.
However, these measurements are not easily accessible to general users unless
they visit a dermatology clinic with specialized instruments. To tackle this
problem, we propose a systematic solution to estimate SH and TEWL from selfie
facial images remotely with smartphones. Our solution encompasses multiple
stages, including SH/TEWL data collection, data preprocessing, and formulating
a novel Skin-Prior Adaptive Vision Transformer model for SH/TEWL regression.
Through experiments, we identified the annotation imbalance of the SH/TEWL data
and proposed a symmetric-based contrastive regularization to reduce the model
bias due to the imbalance effectively. This work is the first study to explore
skin assessment from selfie facial images without physical measurements. It
bridges the gap between computer vision and skin care research, enabling
AI-driven accessible skin analysis for broader real-world applications.

</details>


### [103] [Prototype-Aware Multimodal Alignment for Open-Vocabulary Visual Grounding](https://arxiv.org/abs/2509.06291)
*Jiangnan Xie,Xiaolong Zheng,Liang Zheng*

Main category: cs.CV

TL;DR: PAML框架解决了视觉语言导航中开放词汇场景下的物体定位问题，通过改进跨模态对齐、特征融合和语义原型利用，在标准和开放词汇场景下均取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视觉语言导航方法在开放词汇场景（包含新颖物体类别）下存在视觉与语言模态对齐不完美、跨模态特征融合不足、语义原型利用无效等问题。

Method: 提出了一种名为PAML（Prototype-Aware Multimodal Learning）的框架。该框架首先利用ALBEF进行跨模态对齐，然后通过视觉判别性特征编码器增强显著物体表示并抑制无关背景，接着利用新颖的原型发现与继承机制来聚合多邻居语义原型以支持开放词汇识别，最后通过多阶段解码器进行多模态融合和边界框回归。

Result: 在五个基准数据集上的广泛实验证明，PAML在标准场景下具有竞争力，并在开放词汇场景下达到了最先进的性能。

Conclusion: PAML框架有效解决了视觉语言导航中的开放词汇挑战，通过其新颖的组件显著提升了物体定位的准确性。

Abstract: Visual Grounding (VG) aims to utilize given natural language queries to
locate specific target objects within images. While current transformer-based
approaches demonstrate strong localization performance in standard scene (i.e,
scenarios without any novel objects), they exhibit notable limitations in
open-vocabulary scene (i.e, both familiar and novel object categories during
testing). These limitations primarily stem from three key factors: (1)
imperfect alignment between visual and linguistic modalities, (2) insufficient
cross-modal feature fusion, and (3) ineffective utilization of semantic
prototype information. To overcome these challenges, we present Prototype-Aware
Multimodal Learning (PAML), an innovative framework that systematically
addresses these issues through several key components: First, we leverage ALBEF
to establish robust cross-modal alignment during initial feature encoding.
Subsequently, our Visual Discriminative Feature Encoder selectively enhances
salient object representations while suppressing irrelevant visual context. The
framework then incorporates a novel prototype discovering and inheriting
mechanism that extracts and aggregates multi-neighbor semantic prototypes to
facilitate open-vocabulary recognition. These enriched features undergo
comprehensive multimodal integration through our Multi-stage Decoder before
final bounding box regression. Extensive experiments across five benchmark
datasets validate our approach, showing competitive performance in standard
scene while achieving state-of-the-art results in open-vocabulary scene. Our
code is available at https://github.com/plankXie/PAML.

</details>


### [104] [Video-based Generalized Category Discovery via Memory-Guided Consistency-Aware Contrastive Learning](https://arxiv.org/abs/2509.06306)
*Zhang Jing,Pu Nan,Xie Yu Xiang,Guo Yanming,Lu Qianqi,Zou Shiwei,Yan Jie,Chen Yan*

Main category: cs.CV

TL;DR: 本文提出了Video-GCD新场景，并引入了内存引导一致性感知对比学习（MCCL）框架来解决视频域中的类别发现问题，该框架通过CACL和MGRE组件有效利用时空信息，并在新构建的Video-GCD基准上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有广义类别发现（GCD）方法主要集中在静态图像，但仅依赖静态视觉内容不足以可靠地发现新类别。为弥补此不足，本文将GCD问题扩展到视频域，提出新的Video-GCD场景。

Method: 提出内存引导一致性感知对比学习（MCCL）框架。该框架包含两个核心组件：1. 一致性感知对比学习（CACL）：利用多视角时间特征估计未标记实例之间的一致性分数，并据此加权对比损失。2. 内存引导表示增强（MGRE）：引入双层内存缓冲区（特征和logit级别），提供全局上下文以增强类内紧密度和类间可分离性，形成表示学习和一致性建模之间的互促反馈循环。

Result: 在新的Video-GCD基准上，所提出的MCCL方法显著优于从基于图像的设置改编而来的GCD方法，证明了时间信息在发现视频中新类别的重要性。

Conclusion: 本文扩展了GCD问题到视频域（Video-GCD），并提出了MCCL框架，该框架能有效整合时空信息，并在新基准上取得了优于现有方法的性能，强调了时间信息在视频类别发现中的关键作用。

Abstract: Generalized Category Discovery (GCD) is an emerging and challenging
open-world problem that has garnered increasing attention in recent years. Most
existing GCD methods focus on discovering categories in static images. However,
relying solely on static visual content is often insufficient to reliably
discover novel categories. To bridge this gap, we extend the GCD problem to the
video domain and introduce a new setting, termed Video-GCD. Thus, effectively
integrating multi-perspective information across time is crucial for accurate
Video-GCD. To tackle this challenge, we propose a novel Memory-guided
Consistency-aware Contrastive Learning (MCCL) framework, which explicitly
captures temporal-spatial cues and incorporates them into contrastive learning
through a consistency-guided voting mechanism. MCCL consists of two core
components: Consistency-Aware Contrastive Learning(CACL) and Memory-Guided
Representation Enhancement (MGRE). CACL exploits multiperspective temporal
features to estimate consistency scores between unlabeled instances, which are
then used to weight the contrastive loss accordingly. MGRE introduces a
dual-level memory buffer that maintains both feature-level and logit-level
representations, providing global context to enhance intra-class compactness
and inter-class separability. This in turn refines the consistency estimation
in CACL, forming a mutually reinforcing feedback loop between representation
learning and consistency modeling. To facilitate a comprehensive evaluation, we
construct a new and challenging Video-GCD benchmark, which includes action
recognition and bird classification video datasets. Extensive experiments
demonstrate that our method significantly outperforms competitive GCD
approaches adapted from image-based settings, highlighting the importance of
temporal information for discovering novel categories in videos. The code will
be publicly available.

</details>


### [105] [Text4Seg++: Advancing Image Segmentation via Generative Language Modeling](https://arxiv.org/abs/2509.06321)
*Mengcheng Lan,Chaofeng Chen,Jiaxing Xu,Zongrui Li,Yiping Ke,Xudong Jiang,Yingchen Yu,Yunqing Zhao,Song Bai*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的文本掩码范式，将图像分割视为文本生成问题，通过引入语义描述符（图像块到文本标签的映射）和行编码（R-RLE）来简化和加速分割过程。在此基础上，研究提出了Text4Seg++模型，使用框级语义描述符和语义砖块进行更精细、更紧凑的分割，并在多个基准测试中超越了现有最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 有效集成图像分割到多模态大语言模型（MLLM）中仍然是一个重大挑战。

Method: 提出了一种新颖的文本掩码范式，将图像分割视为文本生成问题，引入了图像块到其对应文本标签的映射——语义描述符。为了提高效率，采用了行编码（R-RLE）压缩冗余文本，并将模型扩展到框级语义描述符，使用结构化掩码令牌（语义砖块）来表示感兴趣区域的掩码。

Result: Text4Seg++模型在自然图像和遥感数据集上进行了全面实验，在多个基准测试中一致优于最先进的模型，并且无需进行任何特定任务的微调，同时兼容现有的MLLM骨干网络。

Conclusion: 该研究证明了在MLLM框架内，文本驱动的图像分割具有有效性、可扩展性和泛化性。

Abstract: Multimodal Large Language Models (MLLMs) have shown exceptional capabilities
in vision-language tasks. However, effectively integrating image segmentation
into these models remains a significant challenge. In this work, we propose a
novel text-as-mask paradigm that casts image segmentation as a text generation
problem, eliminating the need for additional decoders and significantly
simplifying the segmentation process. Our key innovation is semantic
descriptors, a new textual representation of segmentation masks where each
image patch is mapped to its corresponding text label. We first introduce
image-wise semantic descriptors, a patch-aligned textual representation of
segmentation masks that integrates naturally into the language modeling
pipeline. To enhance efficiency, we introduce the Row-wise Run-Length Encoding
(R-RLE), which compresses redundant text sequences, reducing the length of
semantic descriptors by 74% and accelerating inference by $3\times$, without
compromising performance. Building upon this, our initial framework Text4Seg
achieves strong segmentation performance across a wide range of vision tasks.
To further improve granularity and compactness, we propose box-wise semantic
descriptors, which localizes regions of interest using bounding boxes and
represents region masks via structured mask tokens called semantic bricks. This
leads to our refined model, Text4Seg++, which formulates segmentation as a
next-brick prediction task, combining precision, scalability, and generative
efficiency. Comprehensive experiments on natural and remote sensing datasets
show that Text4Seg++ consistently outperforms state-of-the-art models across
diverse benchmarks without any task-specific fine-tuning, while remaining
compatible with existing MLLM backbones. Our work highlights the effectiveness,
scalability, and generalizability of text-driven image segmentation within the
MLLM framework.

</details>


### [106] [Towards scalable organ level 3D plant segmentation: Bridging the data algorithm computing gap](https://arxiv.org/abs/2509.06329)
*Ruiming Du,Guangxun Zhai,Tian Qiu,Yu Jiang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The precise characterization of plant morphology provides valuable insights
into plant environment interactions and genetic evolution. A key technology for
extracting this information is 3D segmentation, which delineates individual
plant organs from complex point clouds. Despite significant progress in general
3D computer vision domains, the adoption of 3D segmentation for plant
phenotyping remains limited by three major challenges: i) the scarcity of
large-scale annotated datasets, ii) technical difficulties in adapting advanced
deep neural networks to plant point clouds, and iii) the lack of standardized
benchmarks and evaluation protocols tailored to plant science. This review
systematically addresses these barriers by: i) providing an overview of
existing 3D plant datasets in the context of general 3D segmentation domains,
ii) systematically summarizing deep learning-based methods for point cloud
semantic and instance segmentation, iii) introducing Plant Segmentation Studio
(PSS), an open-source framework for reproducible benchmarking, and iv)
conducting extensive quantitative experiments to evaluate representative
networks and sim-to-real learning strategies. Our findings highlight the
efficacy of sparse convolutional backbones and transformer-based instance
segmentation, while also emphasizing the complementary role of modeling-based
and augmentation-based synthetic data generation for sim-to-real learning in
reducing annotation demands. In general, this study bridges the gap between
algorithmic advances and practical deployment, providing immediate tools for
researchers and a roadmap for developing data-efficient and generalizable deep
learning solutions in 3D plant phenotyping. Data and code are available at
https://github.com/perrydoremi/PlantSegStudio.

</details>


### [107] [Quantitative Currency Evaluation in Low-Resource Settings through Pattern Analysis to Assist Visually Impaired Users](https://arxiv.org/abs/2509.06331)
*Md Sultanul Islam Ovi,Mainul Hossain,Md Badsha Biswas*

Main category: cs.CV

TL;DR: 该研究提出了一个集成的货币评估框架，能够进行面额分类、破损量化和假币检测，特别适用于低资源和视觉障碍用户环境。


<details>
  <summary>Details</summary>
Motivation: 现有货币识别系统在低资源环境下（如视觉障碍用户和离线验证）通常忽视了易用性和真实性评估，并且在处理物理损耗和伪造方面存在局限性。本研究旨在解决这些问题。

Method: 该框架包含三个模块：1. 使用轻量级CNN模型进行面额分类；2. 通过新颖的统一货币破损指数（UCDI）进行破损量化；3. 使用基于特征的模板匹配进行假币检测。数据集包含超过82,000张标注图像，涵盖干净、破损和假币。

Result: Custom_CNN模型实现了高分类性能和低参数量。UCDI指标基于二值掩码损失、色彩失真和结构特征损失，提供了一个连续的可用性分数。假币检测模块在不同成像条件下能够可靠地识别假币。该框架支持实时、设备端推理。

Conclusion: 研究表明，准确、可解释且紧凑的解决方案可以为实际场景中的包容性货币评估提供支持。

Abstract: Currency recognition systems often overlook usability and authenticity
assessment, especially in low-resource environments where visually impaired
users and offline validation are common. While existing methods focus on
denomination classification, they typically ignore physical degradation and
forgery, limiting their applicability in real-world conditions. This paper
presents a unified framework for currency evaluation that integrates three
modules: denomination classification using lightweight CNN models, damage
quantification through a novel Unified Currency Damage Index (UCDI), and
counterfeit detection using feature-based template matching. The dataset
consists of over 82,000 annotated images spanning clean, damaged, and
counterfeit notes. Our Custom_CNN model achieves high classification
performance with low parameter count. The UCDI metric provides a continuous
usability score based on binary mask loss, chromatic distortion, and structural
feature loss. The counterfeit detection module demonstrates reliable
identification of forged notes across varied imaging conditions. The framework
supports real-time, on-device inference and addresses key deployment challenges
in constrained environments. Results show that accurate, interpretable, and
compact solutions can support inclusive currency evaluation in practical
settings.

</details>


### [108] [Harnessing Object Grounding for Time-Sensitive Video Understanding](https://arxiv.org/abs/2509.06335)
*Tz-Ying Wu,Sharath Nittur Sridhar,Subarna Tripathi*

Main category: cs.CV

TL;DR: 通过引入“以目标为导向”的视频理解方法，并设计GO-Tokenizer模块，提升了视频大语言模型在时序定位和稠密字幕生成等任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型在处理需要精确时间理解的任务时存在不足，尽管引入物体标注信息有所帮助，但文本描述会增加额外的计算负担且易受噪声干扰。

Method: 提出GO-Tokenizer，一种轻量级模块，利用现成的物体检测器实时编码紧凑的物体信息，并将其整合到视频大语言模型中。

Result: 在视频理解任务（如时序定位和稠密字幕生成）上，使用GO-Tokenizer预训练的模型优于标准的视频大语言模型和仅使用文本描述的模型，并且这种提升在不同模型、数据集和任务上均具有泛化性。

Conclusion: GO-Tokenizer是一种有效的方法，可以增强视频大语言模型对时间敏感的视频理解能力，相比于简单的文本描述，它能更高效地利用物体信息。

Abstract: We propose to improve the time-sensitive video understanding (TSV) capability
of video large language models (Video-LLMs) with grounded objects (GO). We
hypothesize that TSV tasks can benefit from GO within frames, which is
supported by our preliminary experiments on LITA, a state-of-the-art Video-LLM
for reasoning temporal localization. While augmenting prompts with textual
description of these object annotations improves the performance of LITA, it
also introduces extra token length and susceptibility to the noise in object
level information. To address this, we propose GO-Tokenizer, a lightweight
add-on module for Video-LLMs leveraging off-the-shelf object detectors to
encode compact object information on the fly. Experimental results demonstrate
that pretraining with GO-Tokenizer outperforms the vanilla Video-LLM and its
counterpart utilizing textual description of objects in the prompt. The gain
generalizes across different models, datasets and video understanding tasks
such as reasoning temporal localization and dense captioning.

</details>


### [109] [Multi View Slot Attention Using Paraphrased Texts For Face Anti-Spoofing](https://arxiv.org/abs/2509.06336)
*Jeongmin Yu,Susang Kim,Kisu Lee,Taekyoung Kwon,Won-Yong Shin,Ha Young Kim*

Main category: cs.CV

TL;DR: MVP-FAS是一个利用CLIP的多视图槽注意力和多文本图像块对齐方法，提高了跨领域人脸反欺骗的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的人脸反欺骗方法未能充分利用CLIP的图像块嵌入信息，并且依赖单一的文本提示，限制了泛化能力。MVP-FAS旨在解决这些问题。

Method: MVP-FAS框架包含两个关键模块：多视图槽注意力（MVS）和多文本图像块对齐（MTPA）。MVS利用多种视角和文本提取局部空间特征和全局上下文。MTPA将图像块与多种文本表示对齐，以提高语义鲁棒性。

Result: MVP-FAS在跨领域数据集上的泛化性能优于现有的最先进方法。

Conclusion: MVP-FAS通过利用多视图槽注意力和多文本图像块对齐，实现了更好的人脸反欺骗泛化能力。

Abstract: Recent face anti-spoofing (FAS) methods have shown remarkable cross-domain
performance by employing vision-language models like CLIP. However, existing
CLIP-based FAS models do not fully exploit CLIP's patch embedding tokens,
failing to detect critical spoofing clues. Moreover, these models rely on a
single text prompt per class (e.g., 'live' or 'fake'), which limits
generalization. To address these issues, we propose MVP-FAS, a novel framework
incorporating two key modules: Multi-View Slot attention (MVS) and Multi-Text
Patch Alignment (MTPA). Both modules utilize multiple paraphrased texts to
generate generalized features and reduce dependence on domain-specific text.
MVS extracts local detailed spatial features and global context from patch
embeddings by leveraging diverse texts with multiple perspectives. MTPA aligns
patches with multiple text representations to improve semantic robustness.
Extensive experiments demonstrate that MVP-FAS achieves superior generalization
performance, outperforming previous state-of-the-art methods on cross-domain
datasets. Code: https://github.com/Elune001/MVP-FAS.

</details>


### [110] [A Multi-Modal Deep Learning Framework for Colorectal Pathology Diagnosis: Integrating Histological and Colonoscopy Data in a Pilot Study](https://arxiv.org/abs/2509.06351)
*Krithik Ramesh,Ritvik Koneru*

Main category: cs.CV

TL;DR: 本研究提出了一种统一的深度学习网络，用于同时分类结直肠疾病的组织病理学图像和结肠镜视频帧，以提高诊断效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的结直肠疾病诊断流程效率低下且可能存在误差，需要结合组织学图像和结肠镜录像进行独立评估。

Method: 本研究提出了一种统一的深度学习网络，该网络采用卷积神经网络（CNN），具体为ResNet-50架构，并集成了类别平衡学习、数据增强和校准方法，能够一次性处理组织病理学图像和结肠镜视频帧。

Result: 研究证明了该方法的可解释性和可复现性，能够有效地整合多种诊断方式，从而促进结直肠疾病的检测。

Conclusion: 本研究成功开发了一种能够整合多种诊断模式的、可解释且可复现的诊断流程，旨在简化和改进结直肠疾病的检测。

Abstract: Colorectal diseases, including inflammatory conditions and neoplasms, require
quick, accurate care to be effectively treated. Traditional diagnostic
pipelines require extensive preparation and rely on separate, individual
evaluations on histological images and colonoscopy footage, introducing
possible variability and inefficiencies. This pilot study proposes a unified
deep learning network that uses convolutional neural networks (CN N s) to
classify both histopathological slides and colonoscopy video frames in one
pipeline. The pipeline integrates class-balancing learning, robust
augmentation, and calibration methods to ensure accurate results. Static colon
histology images were taken from the PathMNIST dataset, and the lower
gastrointestinal (colonoscopy) videos were drawn from the HyperKvasir dataset.
The CNN architecture used was ResNet-50. This study demonstrates an
interpretable and reproducible diagnostic pipeline that unifies multiple
diagnostic modalities to advance and ease the detection of colorectal diseases.

</details>


### [111] [MRD-LiNet: A Novel Lightweight Hybrid CNN with Gradient-Guided Unlearning for Improved Drought Stress Identification](https://arxiv.org/abs/2509.06367)
*Aswini Kumar Patra,Lingaraj Sahoo*

Main category: cs.CV

TL;DR: 提出了一种轻量级的混合CNN框架，通过ResNet、DenseNet和MobileNet的混合，将参数量减少到传统模型的1/15，同时保持了准确性。该框架还引入了一种基于梯度范数影响函数的机器遗忘机制，以适应资源受限的农业环境，并在马铃薯田的航空图像数据集上进行了验证，结果表明该框架在降低计算成本的同时实现了高准确率，为精准农业中的干旱胁迫监测提供了一种实用的、可扩展的、自适应的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统方法检测干旱胁迫耗时耗力，需要更有效的替代方案，特别是对计算资源有限的场景。

Method: 提出了一种受ResNet、DenseNet和MobileNet启发的轻量级混合CNN框架，并引入了一种基于梯度范数影响函数的机器遗忘机制。

Result: 所提出的框架在马铃薯田航空图像数据集上实现了与传统模型相当的准确率，同时可训练参数减少了15倍，显著降低了计算成本。

Conclusion: 该轻量级混合CNN框架是一种实用、可扩展且自适应的解决方案，特别适合计算资源受限的精准农业环境，用于监测干旱胁迫。

Abstract: Drought stress is a major threat to global crop productivity, making its
early and precise detection essential for sustainable agricultural management.
Traditional approaches, though useful, are often time-consuming and
labor-intensive, which has motivated the adoption of deep learning methods. In
recent years, Convolutional Neural Network (CNN) and Vision Transformer
architectures have been widely explored for drought stress identification;
however, these models generally rely on a large number of trainable parameters,
restricting their use in resource-limited and real-time agricultural settings.
To address this challenge, we propose a novel lightweight hybrid CNN framework
inspired by ResNet, DenseNet, and MobileNet architectures. The framework
achieves a remarkable 15-fold reduction in trainable parameters compared to
conventional CNN and Vision Transformer models, while maintaining competitive
accuracy. In addition, we introduce a machine unlearning mechanism based on a
gradient norm-based influence function, which enables targeted removal of
specific training data influence, thereby improving model adaptability. The
method was evaluated on an aerial image dataset of potato fields with
expert-annotated healthy and drought-stressed regions. Experimental results
show that our framework achieves high accuracy while substantially lowering
computational costs. These findings highlight its potential as a practical,
scalable, and adaptive solution for drought stress monitoring in precision
agriculture, particularly under resource-constrained conditions.

</details>


### [112] [Your Super Resolution Model is not Enough for Tackling Real-World Scenarios](https://arxiv.org/abs/2509.06387)
*Dongsik Yoon,Jongeun Kim*

Main category: cs.CV

TL;DR: 本研究提出了一种即插即用的、可感知尺度的注意力模块（SAAM），用于增强现有图像超分辨率模型处理任意尺度因子的能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像超分辨率模型在处理不同尺度因子时泛化能力不足，限制了其在现实世界中的应用。

Method: 提出了一种即插即用的、可感知尺度的注意力模块（SAAM），该模块采用轻量级、尺度自适应的特征提取和上采样，并结合了SimAM注意力机制和梯度方差损失，以提高图像细节的清晰度。该模块可以无缝集成到现有的超分辨率模型中。

Result: 将SAAM集成到多种先进的超分辨率骨干网络后，在多种整数和非整数尺度因子上均取得了具有竞争力或更优的性能。实验表明，该方法能够以最小的计算开销实现鲁棒的多尺度超分辨率。

Conclusion: SAAM模块为解决现实世界中的超分辨率问题提供了一个有效的解决方案，能够提升现有模型的泛化能力，并且计算开销小。

Abstract: Despite remarkable progress in Single Image Super-Resolution (SISR),
traditional models often struggle to generalize across varying scale factors,
limiting their real-world applicability. To address this, we propose a plug-in
Scale-Aware Attention Module (SAAM) designed to retrofit modern fixed-scale SR
models with the ability to perform arbitrary-scale SR. SAAM employs
lightweight, scale-adaptive feature extraction and upsampling, incorporating
the Simple parameter-free Attention Module (SimAM) for efficient guidance and
gradient variance loss to enhance sharpness in image details. Our method
integrates seamlessly into multiple state-of-the-art SR backbones (e.g., SCNet,
HiT-SR, OverNet), delivering competitive or superior performance across a wide
range of integer and non-integer scale factors. Extensive experiments on
benchmark datasets demonstrate that our approach enables robust multi-scale
upscaling with minimal computational overhead, offering a practical solution
for real-world scenarios.

</details>


### [113] [AI-based response assessment and prediction in longitudinal imaging for brain metastases treated with stereotactic radiosurgery](https://arxiv.org/abs/2509.06396)
*Lorenz Achim Kuhn,Daniel Abler,Jonas Richiardi,Andreas F. Hottinger,Luis Schiappacasse,Vincent Dunet,Adrien Depeursinge,Vincent Andrearczyk*

Main category: cs.CV

TL;DR: 该研究实现了一个自动化流程，用于处理立体定向放射外科（SRS）治疗后的脑转移瘤（BM）纵向影像数据，并利用数据驱动的聚类和图机器学习（GML）技术来识别生长轨迹和预测治疗反应。


<details>
  <summary>Details</summary>
Motivation: 脑转移瘤（BM）是癌症患者死亡的主要原因，目前采用立体定向放射外科（SRS）进行治疗，并通过MRI进行监测。然而，纵向影像数据的分析工作量巨大，导致无法进行精细化评估，影响了对治疗反应的理解和预测。本研究旨在解决这一问题，通过自动化流程来处理这些数据，以更好地理解生长轨迹并尽早预测治疗成功或毒性。

Method: 该研究建立了一个自动化流程，用于处理SRS治疗后的脑转移瘤纵向影像数据，构建了一个包含896个BM和177名患者的数据集。研究人员使用数据驱动的聚类方法来识别不同的生长轨迹，并利用经典的机器学习和图机器学习（GML）技术来预测为期12个月的病灶反应。

Result: 聚类分析揭示了5种主要的生长轨迹，这些轨迹对应着不同的最终治疗反应。在预测12个月的病灶反应方面，仅使用治疗前和首次随访的MRI数据，通过梯度提升模型取得了高达0.90的AUC（95%置信区间为0.88-0.92）的预测性能。此外，利用GML技术也获得了高达0.88的AUC（95%置信区间为0.86-0.90）的预测性能，并且GML模型在处理多个时间点输入方面提供了更大的灵活性。

Conclusion: 本研究的结果表明，通过自动化流程和机器学习方法，可以提高对脑转移瘤对SRS治疗反应的评估精度和预测能力。所提出的流程有助于大规模地整理数据，用于研究BM的生长模式，并为临床决策支持系统奠定基础，以优化个性化治疗方案。

Abstract: Brain Metastases (BM) are a large contributor to mortality of patients with
cancer. They are treated with Stereotactic Radiosurgery (SRS) and monitored
with Magnetic Resonance Imaging (MRI) at regular follow-up intervals according
to treatment guidelines. Analyzing and quantifying this longitudinal imaging
represents an intractable workload for clinicians. As a result, follow-up
images are not annotated and merely assessed by observation. Response to
treatment in longitudinal imaging is being studied, to better understand growth
trajectories and ultimately predict treatment success or toxicity as early as
possible. In this study, we implement an automated pipeline to curate a large
longitudinal dataset of SRS treatment data, resulting in a cohort of 896 BMs in
177 patients who were monitored for >360 days at approximately two-month
intervals at Lausanne University Hospital (CHUV). We use a data-driven
clustering to identify characteristic trajectories. In addition, we predict 12
months lesion-level response using classical as well as graph machine learning
Graph Machine Learning (GML). Clustering revealed 5 dominant growth
trajectories with distinct final response categories. Response prediction
reaches up to 0.90 AUC (CI95%=0.88-0.92) using only pre-treatment and first
follow-up MRI with gradient boosting. Similarly, robust predictive performance
of up to 0.88 AUC (CI95%=0.86-0.90) was obtained using GML, offering more
flexibility with a single model for multiple input time-points configurations.
Our results suggest potential automation and increased precision for the
comprehensive assessment and prediction of BM response to SRS in longitudinal
MRI. The proposed pipeline facilitates scalable data curation for the
investigation of BM growth patterns, and lays the foundation for clinical
decision support systems aiming at optimizing personalized care.

</details>


### [114] [3DOF+Quantization: 3DGS quantization for large scenes with limited Degrees of Freedom](https://arxiv.org/abs/2509.06400)
*Matthieu Gendrin,Stéphane Pateux,Théo Ladune*

Main category: cs.CV

TL;DR: 3D高斯泼溅法（3DGS）在3D场景重建方面取得了重大突破，但对于大场景，当输入视图仅限于有限区域时，其3DoF+（相机位置偏移有限）的性能会受到影响。该研究分析了坐标量化对投影误差的影响，发现误差与投影点距离的平方成反比，并提出了一种基于球坐标的新量化方案，该方案在Garden场景上展示了其率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅法（3DGS）在大场景重建中，当输入视图仅限于有限区域（3DoF+）时，其性能会受到限制。研究的动机是解决这种限制，并提高在有限区域内捕获的大场景的重建质量。

Method: 提出了一种基于球坐标的新量化方案，以解决坐标量化问题，并研究了位置误差对投影误差的影响，证明了投影误差与投影点距离的平方成反比。

Result: 该研究表明，在3DoF+场景下，位置误差对投影误差的影响与距离的平方成反比。所提出的基于球坐标的量化方案在Garden场景上展示了其率失真性能。

Conclusion: 所提出的基于球坐标的量化方案能够有效解决3D高斯泼溅法在大场景3DoF+重建中的坐标量化问题，并提升其率失真性能。

Abstract: 3D Gaussian Splatting (3DGS) is a major breakthrough in 3D scene
reconstruction. With a number of views of a given object or scene, the
algorithm trains a model composed of 3D gaussians, which enables the production
of novel views from arbitrary points of view. This freedom of movement is
referred to as 6DoF for 6 degrees of freedom: a view is produced for any
position (3 degrees), orientation of camera (3 other degrees). On large scenes,
though, the input views are acquired from a limited zone in space, and the
reconstruction is valuable for novel views from the same zone, even if the
scene itself is almost unlimited in size. We refer to this particular case as
3DoF+, meaning that the 3 degrees of freedom of camera position are limited to
small offsets around the central position. Considering the problem of
coordinate quantization, the impact of position error on the projection error
in pixels is studied. It is shown that the projection error is proportional to
the squared inverse distance of the point being projected. Consequently, a new
quantization scheme based on spherical coordinates is proposed. Rate-distortion
performance of the proposed method are illustrated on the well-known Garden
scene.

</details>


### [115] [VQualA 2025 Challenge on Image Super-Resolution Generated Content Quality Assessment: Methods and Results](https://arxiv.org/abs/2509.06413)
*Yixiao Li,Xin Li,Chris Wei Zhou,Shuo Xing,Hadi Amirpour,Xiaoshuai Hao,Guanghui Yue,Baoquan Zhao,Weide Liu,Xiaoyuan Yang,Zhengzhong Tu,Xinyu Li,Chuanbiao Song,Chenqi Zhang,Jun Lan,Huijia Zhu,Weiqiang Wang,Xiaoyan Sun,Shishun Tian,Dongyang Yan,Weixia Zhang,Junlin Chen,Wei Sun,Zhihua Wang,Zhuohang Shi,Zhizun Luo,Hang Ouyang,Tianxin Xiao,Fan Yang,Zhaowang Wu,Kaixin Deng*

Main category: cs.CV

TL;DR: 该挑战赛基于ISRGen-QA数据集，侧重于评估生成式超分辨率图像的质量，并分析现代超分辨率技术引入的独特伪影。


<details>
  <summary>Details</summary>
Motivation: 评估由生成式方法（如GANs和扩散模型）生成的超分辨率图像的感知质量，并分析这些技术引入的独特伪影。

Method: 在ISRGen-QA数据集上组织ISRGC-Q挑战赛，收集和评估参赛队伍的解决方案。

Result: 108名参赛者注册，4支队伍提交了有效解决方案，并在ISRGen-QA数据集上取得了SOTA性能。

Conclusion: 该挑战赛有效地推动了对现代超分辨率技术生成图像的质量评估和伪影分析的研究。

Abstract: This paper presents the ISRGC-Q Challenge, built upon the Image
Super-Resolution Generated Content Quality Assessment (ISRGen-QA) dataset, and
organized as part of the Visual Quality Assessment (VQualA) Competition at the
ICCV 2025 Workshops. Unlike existing Super-Resolution Image Quality Assessment
(SR-IQA) datasets, ISRGen-QA places a greater emphasis on SR images generated
by the latest generative approaches, including Generative Adversarial Networks
(GANs) and diffusion models. The primary goal of this challenge is to analyze
the unique artifacts introduced by modern super-resolution techniques and to
evaluate their perceptual quality effectively. A total of 108 participants
registered for the challenge, with 4 teams submitting valid solutions and fact
sheets for the final testing phase. These submissions demonstrated
state-of-the-art (SOTA) performance on the ISRGen-QA dataset. The project is
publicly available at: https://github.com/Lighting-YXLI/ISRGen-QA.

</details>


### [116] [Phantom-Insight: Adaptive Multi-cue Fusion for Video Camouflaged Object Detection with Multimodal LLM](https://arxiv.org/abs/2509.06422)
*Hua Zhang,Changjiang Luo,Ruoyu Chen*

Main category: cs.CV

TL;DR: Phantom-Insight 提出了一种新颖的视频伪装目标检测（VCOD）方法，解决了现有方法在处理动态环境、区分伪装目标边缘以及前景背景分离方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的 VCOD 方法在动态环境中面临两大挑战：基于 SAM 的方法由于模型冻结难以分离伪装目标的边缘；基于 MLLM 的方法由于大语言模型会将前景和背景融合导致物体分离性差。

Method: 提出了一种名为 Phantom-Insight 的新方法，结合了 SAM 和 MLLM。通过融合时空线索和 LLM 来增强物体边缘细节的分离性；利用动态前景视觉标记评分模块和提示网络生成多重线索，自适应地指导和微调 SAM 模型；采用解耦的前景背景学习策略，分别生成前景和背景线索并进行解耦训练，使视觉标记能够独立地整合前景和背景信息。

Result: 在 MoCA-Mask 数据集上实现了最先进的性能，并在 CAD2016 数据集上展示了对未见过伪装目标的检测能力，证明了其强大的泛化能力。

Conclusion: Phantom-Insight 通过增强物体边缘细节的分离性和改进前景背景分离，有效解决了 VCOD 中的挑战，并在多个数据集上取得了优异的性能和泛化能力。

Abstract: Video camouflaged object detection (VCOD) is challenging due to dynamic
environments. Existing methods face two main issues: (1) SAM-based methods
struggle to separate camouflaged object edges due to model freezing, and (2)
MLLM-based methods suffer from poor object separability as large language
models merge foreground and background. To address these issues, we propose a
novel VCOD method based on SAM and MLLM, called Phantom-Insight. To enhance the
separability of object edge details, we represent video sequences with temporal
and spatial clues and perform feature fusion via LLM to increase information
density. Next, multiple cues are generated through the dynamic foreground
visual token scoring module and the prompt network to adaptively guide and
fine-tune the SAM model, enabling it to adapt to subtle textures. To enhance
the separability of objects and background, we propose a decoupled
foreground-background learning strategy. By generating foreground and
background cues separately and performing decoupled training, the visual token
can effectively integrate foreground and background information independently,
enabling SAM to more accurately segment camouflaged objects in the video.
Experiments on the MoCA-Mask dataset show that Phantom-Insight achieves
state-of-the-art performance across various metrics. Additionally, its ability
to detect unseen camouflaged objects on the CAD2016 dataset highlights its
strong generalization ability.

</details>


### [117] [When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection](https://arxiv.org/abs/2509.06427)
*Rabin Dulal,Lihong Zheng,Muhammad Ashad Kabir*

Main category: cs.CV

TL;DR: 本研究提出了一种基于Grounding DINO的零样本牛 ફક્ત检测框架，无需标注数据即可实现牛 ફક્ત的检测。


<details>
  <summary>Details</summary>
Motivation: 牛 ફક્ત图案是有效的生物识别特征，但传统的手动检测方法耗时且不一致，而基于监督学习的自动检测方法（如YOLO）存在对训练数据依赖性强、泛化能力不足的问题。因此，需要一种无需标注数据、适应性强且易于部署的牛 ફક્ત检测方法。

Method: 提出了一种基于视觉-语言模型Grounding DINO的零样本 ફક્ત检测框架。该框架利用自然语言提示来指导 ફક્ત区域的检测，无需任何特定任务的训练或标注数据。

Result: 在无需标注数据的情况下，该模型实现了76.8%的mAP@0.5，证明了其在牛 ફક્ત检测方面的潜力。

Conclusion: 本研究首次提出了一个面向实际应用、无需标注的牛 ફક્ત检测解决方案，为家畜监测应用提供了一种比监督方法更具适应性和易部署性的实用替代方案。

Abstract: Muzzle patterns are among the most effective biometric traits for cattle
identification. Fast and accurate detection of the muzzle region as the region
of interest is critical to automatic visual cattle identification.. Earlier
approaches relied on manual detection, which is labor-intensive and
inconsistent. Recently, automated methods using supervised models like YOLO
have become popular for muzzle detection. Although effective, these methods
require extensive annotated datasets and tend to be trained data-dependent,
limiting their performance on new or unseen cattle. To address these
limitations, this study proposes a zero-shot muzzle detection framework based
on Grounding DINO, a vision-language model capable of detecting muzzles without
any task-specific training or annotated data. This approach leverages natural
language prompts to guide detection, enabling scalable and flexible muzzle
localization across diverse breeds and environments. Our model achieves a mean
Average Precision (mAP)@0.5 of 76.8\%, demonstrating promising performance
without requiring annotated data. To our knowledge, this is the first research
to provide a real-world, industry-oriented, and annotation-free solution for
cattle muzzle detection. The framework offers a practical alternative to
supervised methods, promising improved adaptability and ease of deployment in
livestock monitoring applications.

</details>


### [118] [Perception-oriented Bidirectional Attention Network for Image Super-resolution Quality Assessment](https://arxiv.org/abs/2509.06442)
*Yixiao Li,Xiaoyuan Yang,Guanghui Yue,Jun Fu,Qiuping Jiang,Xu Jia,Paul L. Rosin,Hantao Liu,Wei Zhou*

Main category: cs.CV

TL;DR: PBAN是一种用于图像超分辨率（SR）图像感知质量评估（IQA）的感知导向双向注意力网络。


<details>
  <summary>Details</summary>
Motivation: 现有用于比较和评估不同SR算法的全参考（FR）图像质量评估（IQA）指标有限。

Method: PBAN网络包含三个模块：图像编码器模块、感知导向双向注意力（PBA）模块和质量预测模块。PBA模块通过双向注意力来构建对失真的视觉注意力，并利用分组多尺度可变形卷积和子信息激励卷积来感知失真。质量预测模块集成质量感知特征并回归质量分数。

Result: PBAN在大量实验中表现优于最先进的质量评估方法。

Conclusion: PBAN是一种有效的SR图像FR-IQA方法。

Abstract: Many super-resolution (SR) algorithms have been proposed to increase image
resolution. However, full-reference (FR) image quality assessment (IQA) metrics
for comparing and evaluating different SR algorithms are limited. In this work,
we propose the Perception-oriented Bidirectional Attention Network (PBAN) for
image SR FR-IQA, which is composed of three modules: an image encoder module, a
perception-oriented bidirectional attention (PBA) module, and a quality
prediction module. First, we encode the input images for feature
representations. Inspired by the characteristics of the human visual system, we
then construct the perception-oriented PBA module. Specifically, different from
existing attention-based SR IQA methods, we conceive a Bidirectional Attention
to bidirectionally construct visual attention to distortion, which is
consistent with the generation and evaluation processes of SR images. To
further guide the quality assessment towards the perception of distorted
information, we propose Grouped Multi-scale Deformable Convolution, enabling
the proposed method to adaptively perceive distortion. Moreover, we design
Sub-information Excitation Convolution to direct visual perception to both
sub-pixel and sub-channel attention. Finally, the quality prediction module is
exploited to integrate quality-aware features and regress quality scores.
Extensive experiments demonstrate that our proposed PBAN outperforms
state-of-the-art quality assessment methods.

</details>


### [119] [Cross3DReg: Towards a Large-scale Real-world Cross-source Point Cloud Registration Benchmark](https://arxiv.org/abs/2509.06456)
*Zongyi Xu,Zhongpeng Lang,Yilong Chen,Shanshan Zhao,Xiaoshui Huang,Yifan Zuo,Yan Zhang,Qianni Zhang,Xinbo Gao*

Main category: cs.CV

TL;DR: 提出了包含旋转机械激光雷达和混合固态激光雷达数据的最大规模真实世界跨源点云数据集Cross3DReg，并设计了一个基于重叠区域预测和视觉-几何注意力引导匹配的跨源点云配准框架，实验证明该方法在减少误差和提高召回率方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 跨源点云配准是3D视觉中的基础任务，但面临缺乏大规模真实世界数据集和多传感器固有差异带来的特征提取与匹配困难的挑战。

Method: 构建了Cross3DReg数据集；设计了一个利用未对齐图像预测重叠区域的框架，以过滤冗余点并减少噪声干扰；提出一个视觉-几何注意力引导匹配模块，融合图像和几何信息以增强跨源点云特征的一致性，从而建立可靠对应关系。

Result: 与现有方法相比，该框架将相对旋转误差（RRE）和相对平移误差（RTE）分别降低了63.2%和40.2%，并将配准召回率（RR）提高了5.4%。

Conclusion: 所提出的方法在准确性和鲁棒性方面均优于现有技术，有效解决了跨源点云配准的挑战。

Abstract: Cross-source point cloud registration, which aims to align point cloud data
from different sensors, is a fundamental task in 3D vision. However, compared
to the same-source point cloud registration, cross-source registration faces
two core challenges: the lack of publicly available large-scale real-world
datasets for training the deep registration models, and the inherent
differences in point clouds captured by multiple sensors. The diverse patterns
induced by the sensors pose great challenges in robust and accurate point cloud
feature extraction and matching, which negatively influence the registration
accuracy. To advance research in this field, we construct Cross3DReg, the
currently largest and real-world multi-modal cross-source point cloud
registration dataset, which is collected by a rotating mechanical lidar and a
hybrid semi-solid-state lidar, respectively. Moreover, we design an
overlap-based cross-source registration framework, which utilizes unaligned
images to predict the overlapping region between source and target point
clouds, effectively filtering out redundant points in the irrelevant regions
and significantly mitigating the interference caused by noise in
non-overlapping areas. Then, a visual-geometric attention guided matching
module is proposed to enhance the consistency of cross-source point cloud
features by fusing image and geometric information to establish reliable
correspondences and ultimately achieve accurate and robust registration.
Extensive experiments show that our method achieves state-of-the-art
registration performance. Our framework reduces the relative rotation error
(RRE) and relative translation error (RTE) by $63.2\%$ and $40.2\%$,
respectively, and improves the registration recall (RR) by $5.4\%$, which
validates its effectiveness in achieving accurate cross-source registration.

</details>


### [120] [IGAff: Benchmarking Adversarial Iterative and Genetic Affine Algorithms on Deep Neural Networks](https://arxiv.org/abs/2509.06459)
*Sebastian-Vasile Echim,Andrei-Alexandru Preda,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CV

TL;DR: 该研究提出了两种新的黑盒迭代对抗算法（ATA 和 AGA），并在 Tiny ImageNet、Caltech-256 和 Food-101 数据集上对 ResNet-18、DenseNet-121、Swin Transformer V2 和 Vision Transformer 进行了基准测试。实验结果表明，与文献中类似的方法相比，在图像分类任务上取得了高达 8.82% 的准确率提升，并对对抗性防御和攻击提供了有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 当前的深度神经网络在人工智能领域取得了巨大成功，但同时也存在难以理解和易受攻击的弱点。对抗性攻击旨在揭示这些弱点，但在模型细节不可访问的黑盒场景下尤其具有挑战性。

Method: 研究探索了两种新颖的黑盒迭代对抗算法：1）基于仿射变换的迭代算法（ATA），以及 2）基于遗传算法（涉及随机噪声和仿射变换）的算法（AGA）。在 ResNet-18、DenseNet-121、Swin Transformer V2 和 Vision Transformer 网络架构上，利用 Tiny ImageNet、Caltech-256 和 Food-101 数据集进行基准测试，并评估了算法参数变化、数据增强以及全局和定向攻击配置下的模型性能。同时，将所提出的算法与 Pixel 和 Square Attack 进行了比较。

Result: 所提出的 ATA 和 AGA 算法在图像分类任务上的表现优于文献中类似的方法，准确率提高了 8.82%。研究还提供了关于全局和定向对抗性防御和攻击的宝贵见解，并通过算法参数变化展示了对抗性鲁棒性。

Conclusion: 研究成功地提出了两种新颖的黑盒迭代对抗算法，并在多个数据集和网络架构上验证了其有效性。实验结果不仅展示了算法的优越性，还为理解和应对对抗性攻击提供了新的视角。

Abstract: Deep neural networks currently dominate many fields of the artificial
intelligence landscape, achieving state-of-the-art results on numerous tasks
while remaining hard to understand and exhibiting surprising weaknesses. An
active area of research focuses on adversarial attacks, which aim to generate
inputs that uncover these weaknesses. However, this proves challenging,
especially in the black-box scenario where model details are inaccessible. This
paper explores in detail the impact of such adversarial algorithms on
ResNet-18, DenseNet-121, Swin Transformer V2, and Vision Transformer network
architectures. Leveraging the Tiny ImageNet, Caltech-256, and Food-101
datasets, we benchmark two novel black-box iterative adversarial algorithms
based on affine transformations and genetic algorithms: 1) Affine
Transformation Attack (ATA), an iterative algorithm maximizing our attack score
function using random affine transformations, and 2) Affine Genetic Attack
(AGA), a genetic algorithm that involves random noise and affine
transformations. We evaluate the performance of the models in the algorithm
parameter variation, data augmentation, and global and targeted attack
configurations. We also compare our algorithms with two black-box adversarial
algorithms, Pixle and Square Attack. Our experiments yield better results on
the image classification task than similar methods in the literature, achieving
an accuracy improvement of up to 8.82%. We provide noteworthy insights into
successful adversarial defenses and attacks at both global and targeted levels,
and demonstrate adversarial robustness through algorithm parameter variation.

</details>


### [121] [Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning](https://arxiv.org/abs/2509.06461)
*Yuyao Ge,Shenghua Liu,Yiwei Wang,Lingrui Mei,Baolong Bi,Xuanshan Zhou,Jiayu Yao,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CV

TL;DR: CARVE是一种无需训练的方法，通过对比注意力图来增强视觉语言模型（VLM）在复杂视觉环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLM增强方法需要额外训练、依赖外部工具或操作粗粒度，忽略了VLM的内在能力。现有方法在复杂视觉环境下性能下降，但忽略了VLM的内在能力。

Method: 通过分析VLM的注意力模式，发现视觉复杂性与注意力熵相关，并影响推理性能。注意力从浅层全局扫描到深层聚焦收敛，收敛程度由视觉复杂性决定。通过对比一般查询和特定任务查询的注意力图，将视觉信号分解为语义信号和视觉噪声。CARVE通过在像素级别进行注意力对比来提取与任务相关的视觉信号。

Result: CARVE在各种VLM模型上持续提升性能，在开源模型上提升高达75%。

Conclusion: CARVE提供了一种无需训练的有效方法，通过对比注意力来提升视觉推理能力，并揭示了视觉复杂性和注意力机制之间相互作用的关键见解。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable success across
diverse visual tasks, yet their performance degrades in complex visual
environments. While existing enhancement approaches require additional
training, rely on external segmentation tools, or operate at coarse-grained
levels, they overlook the innate ability within VLMs. To bridge this gap, we
investigate VLMs' attention patterns and discover that: (1) visual complexity
strongly correlates with attention entropy, negatively impacting reasoning
performance; (2) attention progressively refines from global scanning in
shallow layers to focused convergence in deeper layers, with convergence degree
determined by visual complexity. (3) Theoretically, we prove that the contrast
of attention maps between general queries and task-specific queries enables the
decomposition of visual signal into semantic signals and visual noise
components. Building on these insights, we propose Contrastive Attention
Refinement for Visual Enhancement (CARVE), a training-free method that extracts
task-relevant visual signals through attention contrasting at the pixel level.
Extensive experiments demonstrate that CARVE consistently enhances performance,
achieving up to 75% improvement on open-source models. Our work provides
critical insights into the interplay between visual complexity and attention
mechanisms, offering an efficient pathway for improving visual reasoning with
contrasting attention.

</details>


### [122] [A Statistical 3D Stomach Shape Model for Anatomical Analysis](https://arxiv.org/abs/2509.06464)
*Erez Posner,Ore Shtalrid,Oded Erell,Daniel Noy,Moshe Bouhnik*

Main category: cs.CV

TL;DR: 生成了一个包含解剖学多样性的3D胃模型数据集和一个3D统计形状模型，可用于手术规划、医学教育等领域。


<details>
  <summary>Details</summary>
Motivation: 由于数据可用性和方法学挑战，详细的3D胃模型开发受到限制。

Method: 提出了一种生成合成3D胃模型的新方法，并构建了一个包含解剖学多样性的合成胃数据集。在此基础上，开发了一个3D统计形状模型，并使用真实的CT扫描数据进行了优化和验证。

Result: 成功构建了一个3D统计形状模型，能够捕捉胃的自然解剖学变异性，并在真实CT扫描上进行了稳健的泛化和拟合精度验证。

Conclusion: 该研究首次提出了一个3D胃的统计形状模型，通过结合合成数据生成、参数化建模和真实数据验证，显著推进了器官建模技术，为个性化医疗解决方案开辟了新途径。

Abstract: Realistic and parameterized 3D models of human anatomy have become invaluable
in research, diagnostics, and surgical planning. However, the development of
detailed models for internal organs, such as the stomach, has been limited by
data availability and methodological challenges. In this paper, we propose a
novel pipeline for the generation of synthetic 3D stomach models, enabling the
creation of anatomically diverse morphologies informed by established studies
on stomach shape variability. Using this pipeline, we construct a dataset of
synthetic stomachs. Building on this dataset, we develop a 3D statistical shape
model of the stomach, trained to capture natural anatomical variability in a
low-dimensional shape space. The model is further refined using CT meshes
derived from publicly available datasets through a semi-supervised alignment
process, enhancing its ability to generalize to unseen anatomical variations.
We evaluated the model on a held-out test set of real stomach CT scans,
demonstrating robust generalization and fit accuracy. We make the statistical
shape model along with the synthetic dataset publicly available on GitLab:
https://gitlab.com/Erez.Posner/stomach_pytorch to facilitate further research.
This work introduces the first statistical 3D shape model of the stomach, with
applications ranging from surgical simulation and pre-operative planning to
medical education and computational modeling. By combining synthetic data
generation, parametric modeling, and real-world validation, our approach
represents a significant advancement in organ modeling and opens new
possibilities for personalized healthcare solutions.

</details>


### [123] [Does DINOv3 Set a New Medical Vision Standard?](https://arxiv.org/abs/2509.06467)
*Che Liu,Yinda Chen,Haoyuan Shi,Jinpeng Lu,Bailiang Jian,Jiazhen Pan,Linghan Cai,Jiayi Wang,Yundi Zhang,Jun Li,Cosmin I. Bercea,Cheng Ouyang,Chen Chen,Zhiwei Xiong,Benedikt Wiestler,Christian Wachinger,Daniel Rueckert,Wenjia Bai,Rossella Arcucci*

Main category: cs.CV

TL;DR: DINOv3在医学影像任务中表现出强大的通用性，但其在需要深度领域专业知识的任务中存在局限性。


<details>
  <summary>Details</summary>
Motivation: 评估DINOv3在医学影像领域的通用性，以及它是否能在无需领域特定预训练的情况下作为统一的医学影像任务编码器。

Method: 在包括2D/3D分类和分割在内的常见医学影像任务上对DINOv3进行基准测试，并分析模型大小和输入分辨率对性能的影响。

Result: DINOv3在多种医学影像任务中表现出强大的性能，甚至在某些任务上超越了特定领域的模型。然而，在处理需要深度领域专业知识的影像（如病理图像、电子显微镜图像、PET图像）时，其性能有所下降。此外，DINOv3在医学领域的扩展规律不明确，性能不随模型大小或分辨率的增大而稳定提升。

Conclusion: DINOv3可以作为多种复杂医学任务的强大基线和视觉特征先验，但其在深度专业化任务中的局限性为未来的研究方向提供了思路，例如利用其特征来增强3D重建中的多视图一致性。

Abstract: The advent of large-scale vision foundation models, pre-trained on diverse
natural images, has marked a paradigm shift in computer vision. However, how
the frontier vision foundation models' efficacies transfer to specialized
domains remains such as medical imaging remains an open question. This report
investigates whether DINOv3, a state-of-the-art self-supervised vision
transformer (ViT) that features strong capability in dense prediction tasks,
can directly serve as a powerful, unified encoder for medical vision tasks
without domain-specific pre-training. To answer this, we benchmark DINOv3
across common medical vision tasks, including 2D/3D classification and
segmentation on a wide range of medical imaging modalities. We systematically
analyze its scalability by varying model sizes and input image resolutions. Our
findings reveal that DINOv3 shows impressive performance and establishes a
formidable new baseline. Remarkably, it can even outperform medical-specific
foundation models like BiomedCLIP and CT-Net on several tasks, despite being
trained solely on natural images. However, we identify clear limitations: The
model's features degrade in scenarios requiring deep domain specialization,
such as in Whole-Slide Pathological Images (WSIs), Electron Microscopy (EM),
and Positron Emission Tomography (PET). Furthermore, we observe that DINOv3
does not consistently obey scaling law in the medical domain; performance does
not reliably increase with larger models or finer feature resolutions, showing
diverse scaling behaviors across tasks. Ultimately, our work establishes DINOv3
as a strong baseline, whose powerful visual features can serve as a robust
prior for multiple complex medical tasks. This opens promising future
directions, such as leveraging its features to enforce multiview consistency in
3D reconstruction.

</details>


### [124] [FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection](https://arxiv.org/abs/2509.06482)
*Zhongxiang Xie,Shuangxi Miao,Yuhan Jiang,Zhewei Zhang,Jing Yao,Xuecao Li,Jianxi Huang,Pedram Ghamisi*

Main category: cs.CV

TL;DR: FSG-Net 提出了一种新颖的范式，通过结合频率域和空间域的处理来解决遥感图像变化检测中的虚警和语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决遥感图像变化检测中由辐射差异引起的虚警以及深层抽象特征与浅层细节特征之间的语义鸿沟问题，从而提高变化检测的准确性和边界的清晰度。

Method: FSG-Net 首先在频率域通过差异感知小波交互模块（DAWIM）处理不同频段分量，以适应性地减少虚假变化。然后，在空间域通过协同时空注意力模块（STSAM）增强真实变化区域的显著性。最后，通过轻量级门控融合单元（LGFU）融合浅层细节信息，以弥合语义鸿沟。

Result: 在 CDD、GZ-CD 和 LEVIR-CD 基准测试中，FSG-Net 取得了 94.16%、89.51% 和 91.27% 的 F1 分数，优于现有方法，达到了新的最先进水平。

Conclusion: FSG-Net 能够有效地区分真实变化和由辐射差异引起的虚假变化，并能更好地融合不同层级的特征，从而在遥感图像变化检测任务中取得优异表现。

Abstract: Change detection from high-resolution remote sensing images lies as a
cornerstone of Earth observation applications, yet its efficacy is often
compromised by two critical challenges. First, false alarms are prevalent as
models misinterpret radiometric variations from temporal shifts (e.g.,
illumination, season) as genuine changes. Second, a non-negligible semantic gap
between deep abstract features and shallow detail-rich features tends to
obstruct their effective fusion, culminating in poorly delineated boundaries.
To step further in addressing these issues, we propose the Frequency-Spatial
Synergistic Gated Network (FSG-Net), a novel paradigm that aims to
systematically disentangle semantic changes from nuisance variations.
Specifically, FSG-Net first operates in the frequency domain, where a
Discrepancy-Aware Wavelet Interaction Module (DAWIM) adaptively mitigates
pseudo-changes by discerningly processing different frequency components.
Subsequently, the refined features are enhanced in the spatial domain by a
Synergistic Temporal-Spatial Attention Module (STSAM), which amplifies the
saliency of genuine change regions. To finally bridge the semantic gap, a
Lightweight Gated Fusion Unit (LGFU) leverages high-level semantics to
selectively gate and integrate crucial details from shallow layers.
Comprehensive experiments on the CDD, GZ-CD, and LEVIR-CD benchmarks validate
the superiority of FSG-Net, establishing a new state-of-the-art with F1-scores
of 94.16%, 89.51%, and 91.27%, respectively. The code will be made available at
https://github.com/zxXie-Air/FSG-Net after a possible publication.

</details>


### [125] [WS$^2$: Weakly Supervised Segmentation using Before-After Supervision in Waste Sorting](https://arxiv.org/abs/2509.06485)
*Andrea Marelli,Alberto Foresti,Leonardo Pesce,Giacomo Boracchi,Mario Grosso*

Main category: cs.CV

TL;DR: 本论文提出了一种名为“前后监督”的新方法，利用操作员移除物品前后图像的差异来训练分割网络，解决了工业质量控制中视觉识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 工业质量控制（如垃圾分拣）中，人工识别和移除不希望出现的物品效率低下且成本高，现有计算机视觉方法因标注成本高而难以应用。

Method: 提出“前后监督”（Before-After Supervision）概念，仅利用操作员移除物品前后图像的视觉差异来训练分割网络。并发布了首个包含11000+视频帧的多视图数据集WS$^2$（Weakly Supervised segmentation for Waste-Sorting），用于评估各种弱监督分割方法。

Result: 通过在WS$^2$数据集上进行实验，评估了几种最先进的弱监督分割方法的性能。

Conclusion: “前后监督”方法为在标注数据有限的情况下解决工业视觉识别问题提供了一种有前景的解决方案，并为该领域的研究提供了新的数据集和基准。

Abstract: In industrial quality control, to visually recognize unwanted items within a
moving heterogeneous stream, human operators are often still indispensable.
Waste-sorting stands as a significant example, where operators on multiple
conveyor belts manually remove unwanted objects to select specific materials.
To automate this recognition problem, computer vision systems offer great
potential in accurately identifying and segmenting unwanted items in such
settings. Unfortunately, considering the multitude and the variety of sorting
tasks, fully supervised approaches are not a viable option to address this
challange, as they require extensive labeling efforts. Surprisingly, weakly
supervised alternatives that leverage the implicit supervision naturally
provided by the operator in his removal action are relatively unexplored. In
this paper, we define the concept of Before-After Supervision, illustrating how
to train a segmentation network by leveraging only the visual differences
between images acquired \textit{before} and \textit{after} the operator. To
promote research in this direction, we introduce WS$^2$ (Weakly Supervised
segmentation for Waste-Sorting), the first multiview dataset consisting of more
than 11 000 high-resolution video frames captured on top of a conveyor belt,
including "before" and "after" images. We also present a robust end-to-end
pipeline, used to benchmark several state-of-the-art weakly supervised
segmentation methods on WS$^2$.

</details>


### [126] [TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement](https://arxiv.org/abs/2509.06499)
*Jibai Lin,Bo Ma,Yating Yang,Rong Ma,Turghun Osman,Ahtamjan Ahmat,Rui Dong,Lei Wang,Xi Zhou*

Main category: cs.CV

TL;DR: TIDE框架通过目标监督和偏好学习，在不进行测试时微调的情况下，解决了在保持主体身份和遵循动态编辑指令之间的张力，实现了比现有方法更优越的主体驱动图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在主体驱动图像生成中，难以同时保持主体身份和遵循动态编辑指令，存在不足。

Method: 提出TIDE框架，采用目标监督和偏好学习。具体包括目标监督三元组对齐（参考图像、指令、目标图像）和直接主体扩散（DSD）目标，通过“获胜”（平衡保持-遵从）和“失败”（失真）目标进行训练，实现最优保持-遵从平衡。

Result: 在标准基准测试中，TIDE在生成主体保真度高且指令遵循性强的图像方面表现优于基线方法，并在多种量化指标上取得优势。TIDE还成功应用于结构条件生成、图像到图像生成和文本-图像插值等任务。

Conclusion: TIDE框架有效解决了主体驱动图像生成中的核心挑战，并在多个方面展现出优越的性能和广泛的应用潜力。

Abstract: Subject-driven image generation (SDIG) aims to manipulate specific subjects
within images while adhering to textual instructions, a task crucial for
advancing text-to-image diffusion models. SDIG requires reconciling the tension
between maintaining subject identity and complying with dynamic edit
instructions, a challenge inadequately addressed by existing methods. In this
paper, we introduce the Target-Instructed Diffusion Enhancing (TIDE) framework,
which resolves this tension through target supervision and preference learning
without test-time fine-tuning. TIDE pioneers target-supervised triplet
alignment, modelling subject adaptation dynamics using a (reference image,
instruction, target images) triplet. This approach leverages the Direct Subject
Diffusion (DSD) objective, training the model with paired "winning" (balanced
preservation-compliance) and "losing" (distorted) targets, systematically
generated and evaluated via quantitative metrics. This enables implicit reward
modelling for optimal preservation-compliance balance. Experimental results on
standard benchmarks demonstrate TIDE's superior performance in generating
subject-faithful outputs while maintaining instruction compliance,
outperforming baseline methods across multiple quantitative metrics. TIDE's
versatility is further evidenced by its successful application to diverse
tasks, including structural-conditioned generation, image-to-image generation,
and text-image interpolation. Our code is available at
https://github.com/KomJay520/TIDE.

</details>


### [127] [Predicting Brain Tumor Response to Therapy using a Hybrid Deep Learning and Radiomics Approach](https://arxiv.org/abs/2509.06511)
*Daniil Tikhonov,Matheus Scatolin,Mohor Banerjee,Qiankun Ji,Ahmed Jaheen,Mostafa Salem,Abdelrahman Elsayed,Hu Wang,Sarim Hashmi,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 提出一种结合深度学习特征提取和放射组学及临床特征的混合方法，用于自动评估胶质母细胞瘤对治疗的反应，在BraTS 2025挑战赛中取得平均ROC AUC 0.81和宏观F1分数0.50的成绩。


<details>
  <summary>Details</summary>
Motivation: 准确评估胶质母细胞瘤对治疗的反应对于临床决策和患者管理至关重要，而现有的RANO标准应用复杂且存在观察者变异性。

Method: 提出一种新颖的混合框架，结合深度学习（fine-tuned ResNet-18）提取的特征和超过4800个放射组学及临床特征（包括肿瘤生长/缩小体积、相对最低点体积变化、肿瘤质心偏移等），然后使用CatBoost分类器进行4分类响应预测。

Result: 在4分类响应预测任务（完全缓解、部分缓解、疾病稳定、疾病进展）中，取得了平均ROC AUC 0.81和宏观F1分数0.50的成绩。

Conclusion: 结合学习到的图像表示和领域相关的放射组学特征，为神经肿瘤学中自动治疗反应评估提供了一种稳健有效的方法。

Abstract: Accurate evaluation of the response of glioblastoma to therapy is crucial for
clinical decision-making and patient management. The Response Assessment in
Neuro-Oncology (RANO) criteria provide a standardized framework to assess
patients' clinical response, but their application can be complex and subject
to observer variability. This paper presents an automated method for
classifying the intervention response from longitudinal MRI scans, developed to
predict tumor response during therapy as part of the BraTS 2025 challenge. We
propose a novel hybrid framework that combines deep learning derived feature
extraction and an extensive set of radiomics and clinically chosen features.
Our approach utilizes a fine-tuned ResNet-18 model to extract features from 2D
regions of interest across four MRI modalities. These deep features are then
fused with a rich set of more than 4800 radiomic and clinically driven
features, including 3D radiomics of tumor growth and shrinkage masks,
volumetric changes relative to the nadir, and tumor centroid shift. Using the
fused feature set, a CatBoost classifier achieves a mean ROC AUC of 0.81 and a
Macro F1 score of 0.50 in the 4-class response prediction task (Complete
Response, Partial Response, Stable Disease, Progressive Disease). Our results
highlight that synergizing learned image representations with domain-targeted
radiomic features provides a robust and effective solution for automated
treatment response assessment in neuro-oncology.

</details>


### [128] [On the Reproducibility of "FairCLIP: Harnessing Fairness in Vision-Language Learning''](https://arxiv.org/abs/2509.06535)
*Hua Chang Bakker,Stan Fris,Angela Madelon Bernardy,Stan Deutekom*

Main category: cs.CV

TL;DR: FairCLIP, aimed at enhancing CLIP's group fairness by minimizing image-text similarity score disparities using Sinkhorn distance, was investigated for reproducibility. Despite claims of improved performance and fairness in zero-shot glaucoma classification, the experimental results did not support these findings. Discrepancies between the model description and implementation led to a new implementation (A-FairCLIP) and an extension (FairCLIP+). Neither the official nor the aligned implementation improved performance or fairness.


<details>
  <summary>Details</summary>
Motivation: The motivation was to investigate the reproducibility of FairCLIP, a method proposed to improve the group fairness of CLIP, particularly in the context of zero-shot glaucoma classification using medical data.

Method: The study reproduced the experimental setup of FairCLIP. When discrepancies were found between the model description and the original implementation, a new implementation (A-FairCLIP) was created. FairCLIP+ was also proposed to extend the objective to multiple attributes. The impact of distance minimization on fairness and performance was explored.

Result: CLIP was found to be biased in zero-shot glaucoma classification. However, the experimental results on two datasets did not support the claim that FairCLIP improves CLIP's performance or fairness. While the regularization objective reduced Sinkhorn distances, neither the official nor the aligned implementation (A-FairCLIP) showed improvements in performance or fairness.

Conclusion: The reproducibility study found that FairCLIP, as claimed, did not improve the performance or fairness of CLIP in zero-shot glaucoma classification, despite reducing Sinkhorn distances. Discrepancies in implementation were noted and addressed with an aligned version (A-FairCLIP). An extension, FairCLIP+, was also proposed. The original claim of improved fairness and performance was not supported by the experiments.

Abstract: We investigated the reproducibility of FairCLIP, proposed by Luo et al.
(2024), for improving the group fairness of CLIP (Radford et al., 2021) by
minimizing image-text similarity score disparities across sensitive groups
using the Sinkhorn distance. The experimental setup of Luo et al. (2024) was
reproduced to primarily investigate the research findings for FairCLIP. The
model description by Luo et al. (2024) was found to differ from the original
implementation. Therefore, a new implementation, A-FairCLIP, is introduced to
examine specific design choices. Furthermore, FairCLIP+ is proposed to extend
the FairCLIP objective to include multiple attributes. Additionally, the impact
of the distance minimization on FairCLIP's fairness and performance was
explored. In alignment with the original authors, CLIP was found to be biased
towards certain demographics when applied to zero-shot glaucoma classification
using medical scans and clinical notes from the Harvard-FairVLMed dataset.
However, the experimental results on two datasets do not support their claim
that FairCLIP improves the performance and fairness of CLIP. Although the
regularization objective reduces Sinkhorn distances, both the official
implementation and the aligned implementation, A-FairCLIP, were not found to
improve performance nor fairness in zero-shot glaucoma classification.

</details>


### [129] [Benchmarking EfficientTAM on FMO datasets](https://arxiv.org/abs/2509.06536)
*Senem Aktas,Charles Markham,John McDonald,Rozenn Dahyot*

Main category: cs.CV

TL;DR: 本论文提出了一个包含物体大小信息的新型FMOX数据集，并使用它来评估EfficientTAM模型在快速移动物体追踪方面的性能。


<details>
  <summary>Details</summary>
Motivation: 快速和微小物体追踪仍然是计算机视觉领域的一个挑战。

Method: 首先，引入了一个与四个开源的快速移动物体（FMOs）图像序列数据集相关联的JSON元数据文件。接着，使用物体大小信息扩展了FMOs数据集的描述，创建了FMOX文件。最后，利用FMOX文件测试了EfficientTAM模型，并使用轨迹交并比（TIoU）分数进行了评估。

Result: EfficientTAM模型在FMOX数据集上的表现与为FMO数据集专门设计的模型相当。

Conclusion: EfficientTAM模型在快速移动物体追踪任务上表现良好，并且提出的FMOX数据集可供其他机器学习模型使用。

Abstract: Fast and tiny object tracking remains a challenge in computer vision and in
this paper we first introduce a JSON metadata file associated with four open
source datasets of Fast Moving Objects (FMOs) image sequences. In addition, we
extend the description of the FMOs datasets with additional ground truth
information in JSON format (called FMOX) with object size information. Finally
we use our FMOX file to test a recently proposed foundational model for
tracking (called EfficientTAM) showing that its performance compares well with
the pipelines originally taylored for these FMO datasets. Our comparison of
these state-of-the-art techniques on FMOX is provided with Trajectory
Intersection of Union (TIoU) scores. The code and JSON is shared open source
allowing FMOX to be accessible and usable for other machine learning pipelines
aiming to process FMO datasets.

</details>


### [130] [Back To The Drawing Board: Rethinking Scene-Level Sketch-Based Image Retrieval](https://arxiv.org/abs/2509.06566)
*Emil Demić,Luka Čehovin Zajc*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The goal of Scene-level Sketch-Based Image Retrieval is to retrieve natural
images matching the overall semantics and spatial layout of a free-hand sketch.
Unlike prior work focused on architectural augmentations of retrieval models,
we emphasize the inherent ambiguity and noise present in real-world sketches.
This insight motivates a training objective that is explicitly designed to be
robust to sketch variability. We show that with an appropriate combination of
pre-training, encoder architecture, and loss formulation, it is possible to
achieve state-of-the-art performance without the introduction of additional
complexity. Extensive experiments on a challenging FS-COCO and widely-used
SketchyCOCO datasets confirm the effectiveness of our approach and underline
the critical role of training design in cross-modal retrieval tasks, as well as
the need to improve the evaluation scenarios of scene-level SBIR.

</details>


### [131] [Evolving from Unknown to Known: Retentive Angular Representation Learning for Incremental Open Set Recognition](https://arxiv.org/abs/2509.06570)
*Runqing Yang,Yimin Fu,Changyuan Wu,Zhunga Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为RARL（retentive angular representation learning）的新方法，用于增量开放集识别（IOSR）问题，旨在解决模型在处理连续数据流中新出现未知类别时的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有开放集识别（OSR）方法主要用于静态场景，无法满足模型在连续数据流中识别和学习新未知类别的需求。在数据流不断演变的场景下，由于无法访问早期训练数据，OSR决策边界的区分度难以维持，导致类别间混淆严重。

Method: RARL方法在等角紧框架（equiangular tight frame）构建的角空间中，促使未知样本的表示与其对应的非活跃原型对齐，以减少知识更新过程中的表示漂移。此外，还采用了一种虚拟内在交互（VII）训练策略，通过引入边界邻近的虚拟类别来压缩已知类别的表示并强制执行明确的类间边界。同时，设计了一种分层校正策略来优化决策边界，以缓解新旧类别和正/负样本不平衡导致的表示偏差和特征空间畸变。

Result: 在CIFAR100和TinyImageNet数据集上的实验表明，该方法在各种任务设置下均取得了最先进的性能，并为IOSR问题建立了新的基准。

Conclusion: RARL通过其新颖的表示学习和训练策略，有效解决了增量开放集识别中的关键挑战，实现了优于现有方法的性能。

Abstract: Existing open set recognition (OSR) methods are typically designed for static
scenarios, where models aim to classify known classes and identify unknown ones
within fixed scopes. This deviates from the expectation that the model should
incrementally identify newly emerging unknown classes from continuous data
streams and acquire corresponding knowledge. In such evolving scenarios, the
discriminability of OSR decision boundaries is hard to maintain due to
restricted access to former training data, causing severe inter-class
confusion. To solve this problem, we propose retentive angular representation
learning (RARL) for incremental open set recognition (IOSR). In RARL, unknown
representations are encouraged to align around inactive prototypes within an
angular space constructed under the equiangular tight frame, thereby mitigating
excessive representation drift during knowledge updates. Specifically, we adopt
a virtual-intrinsic interactive (VII) training strategy, which compacts known
representations by enforcing clear inter-class margins through
boundary-proximal virtual classes. Furthermore, a stratified rectification
strategy is designed to refine decision boundaries, mitigating representation
bias and feature space distortion caused by imbalances between old/new and
positive/negative class samples. We conduct thorough evaluations on CIFAR100
and TinyImageNet datasets and establish a new benchmark for IOSR. Experimental
results across various task setups demonstrate that the proposed method
achieves state-of-the-art performance.

</details>


### [132] [CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis](https://arxiv.org/abs/2509.06579)
*Xin Kong,Daniel Watson,Yannick Strümpler,Michael Niemeyer,Federico Tombari*

Main category: cs.CV

TL;DR: CausNVS是一个多视角扩散模型，采用自回归方式解决了现有非自回归方法的局限性，实现了灵活的视角生成和高质量的3D新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数多视角扩散模型采用非自回归方式，这限制了它们在世界建模中的应用，因为它们只支持固定数量的视图，并且由于同时对所有帧进行去噪而导致推理速度慢。CausNVS旨在解决这些局限性。

Method: CausNVS采用自回归设置，通过因果掩码和逐帧噪声进行训练，并使用成对相对相机位姿编码（CaPE）进行精确的相机控制。在推理时，结合了空间感知滑动窗口、键值缓存和噪声条件增强来减轻漂移。

Result: 实验证明，CausNVS支持广泛的相机轨迹，能够进行灵活的自回归新视角合成，并在各种环境中始终保持高质量的视觉效果。

Conclusion: CausNVS通过采用自回归方法，克服了现有非自回归多视角扩散模型的限制，为3D新视角合成提供了更灵活和高效的解决方案。

Abstract: Multi-view diffusion models have shown promise in 3D novel view synthesis,
but most existing methods adopt a non-autoregressive formulation. This limits
their applicability in world modeling, as they only support a fixed number of
views and suffer from slow inference due to denoising all frames
simultaneously. To address these limitations, we propose CausNVS, a multi-view
diffusion model in an autoregressive setting, which supports arbitrary
input-output view configurations and generates views sequentially. We train
CausNVS with causal masking and per-frame noise, using pairwise-relative camera
pose encodings (CaPE) for precise camera control. At inference time, we combine
a spatially-aware sliding-window with key-value caching and noise conditioning
augmentation to mitigate drift. Our experiments demonstrate that CausNVS
supports a broad range of camera trajectories, enables flexible autoregressive
novel view synthesis, and achieves consistently strong visual quality across
diverse settings. Project page: https://kxhit.github.io/CausNVS.html.

</details>


### [133] [Detection of trade in products derived from threatened species using machine learning and a smartphone](https://arxiv.org/abs/2509.06585)
*Ritwik Kulkarni,WU Hanqin,Enrico Di Minin*

Main category: cs.CV

TL;DR: 机器学习模型可用于识别和检测野生动植物产品，提高打击非法野生动植物贸易的效率，并可集成到智能手机应用程序中进行实时监控。


<details>
  <summary>Details</summary>
Motivation: 由于数字市场和社交媒体上野生动植物贸易的日益普遍，需要开发自动方法来识别野生动植物产品，以应对生物多样性威胁。

Method: 开发基于机器学习的对象识别模型，用于识别和突出显示大象、穿山甲和老虎的产品图像。研究了不同的训练策略和损失函数，并开发了一个智能手机应用程序。

Result: 在检测大象、穿山甲和老虎的产品方面，最佳模型的总体准确率为 84.2%（具体准确率分别为 71.1%、90.2% 和 93.5%）。智能手机应用程序的总体准确率为 91.3%。

Conclusion: 所提出的机器学习方法能够有效地自动检测野生动植物产品，可用于网络监控和实体市场监测，有助于打击非法野生动植物贸易。

Abstract: Unsustainable trade in wildlife is a major threat to biodiversity and is now
increasingly prevalent in digital marketplaces and social media. With the sheer
volume of digital content, the need for automated methods to detect wildlife
trade listings is growing. These methods are especially needed for the
automatic identification of wildlife products, such as ivory. We developed
machine learning-based object recognition models that can identify wildlife
products within images and highlight them. The data consists of images of
elephant, pangolin, and tiger products that were identified as being sold
illegally or that were confiscated by authorities. Specifically, the wildlife
products included elephant ivory and skins, pangolin scales, and claws (raw and
crafted), and tiger skins and bones. We investigated various combinations of
training strategies and two loss functions to identify the best model to use in
the automatic detection of these wildlife products. Models were trained for
each species while also developing a single model to identify products from all
three species. The best model showed an overall accuracy of 84.2% with
accuracies of 71.1%, 90.2% and 93.5% in detecting products derived from
elephants, pangolins, and tigers, respectively. We further demonstrate that the
machine learning model can be made easily available to stakeholders, such as
government authorities and law enforcement agencies, by developing a
smartphone-based application that had an overall accuracy of 91.3%. The
application can be used in real time to click images and help identify
potentially prohibited products of target species. Thus, the proposed method is
not only applicable for monitoring trade on the web but can also be used e.g.
in physical markets for monitoring wildlife trade.

</details>


### [134] [Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT Denoising](https://arxiv.org/abs/2509.06591)
*Yichao Liu,YueYang Teng*

Main category: cs.CV

TL;DR: HSANet是一种用于LDCT/PET图像去噪的新型混合Swin注意力网络，通过引入高效全局注意力（EGA）模块和混合上采样模块，实现了优越的去噪性能和轻量化的模型尺寸，适用于临床应用。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT（LDCT）和PET成像虽然辐射暴露更安全，但会增加噪声和伪影，影响诊断准确性。因此，对LDCT/PET进行去噪研究至关重要。

Method: 提出了一种名为HSANet的新型混合Swin注意力网络，集成了高效全局注意力（EGA）模块以增强空间和通道交互，以及一个混合上采样模块以降低对噪声的过拟合风险。

Result: HSANet在公开的LDCT/PET数据集上进行了验证，实验结果表明，与现有方法相比，HSANet在去噪性能上表现更优，同时模型尺寸轻量，适用于标准内存配置的GPU部署。

Conclusion: HSANet在LDCT/PET图像去噪方面取得了优越的性能，并保持了轻量化的模型特性，使其成为临床应用的实用方法。

Abstract: Low-dose computed tomography (LDCT) and positron emission tomography (PET)
have emerged as safer alternatives to conventional imaging modalities by
significantly reducing radiation exposure. However, this reduction often
results in increased noise and artifacts, which can compromise diagnostic
accuracy. Consequently, denoising for LDCT/PET has become a vital area of
research aimed at enhancing image quality while maintaining radiation safety.
In this study, we introduce a novel Hybrid Swin Attention Network (HSANet),
which incorporates Efficient Global Attention (EGA) modules and a hybrid
upsampling module. The EGA modules enhance both spatial and channel-wise
interaction, improving the network's capacity to capture relevant features,
while the hybrid upsampling module mitigates the risk of overfitting to noise.
We validate the proposed approach using a publicly available LDCT/PET dataset.
Experimental results demonstrate that HSANet achieves superior denoising
performance compared to existing methods, while maintaining a lightweight model
size suitable for deployment on GPUs with standard memory configurations. This
makes our approach highly practical for real-world clinical applications.

</details>


### [135] [Improved Classification of Nitrogen Stress Severity in Plants Under Combined Stress Conditions Using Spatio-Temporal Deep Learning Framework](https://arxiv.org/abs/2509.06625)
*Aswini Kumar Patra*

Main category: cs.CV

TL;DR: 一种结合RGB、多光谱和红外图像的深度学习框架，通过CNN-LSTM模型准确识别氮胁迫，准确率达98%，显著优于仅使用空间信息的CNN模型（80.45%）及其他机器学习方法（76%），为作物管理和植物健康提供有力工具。


<details>
  <summary>Details</summary>
Motivation: 在自然生境中，植物常同时面临多种相互作用的生物和非生物胁迫，特别是氮素营养不良与干旱、杂草竞争叠加时，其影响更难区分。因此，早期检测氮素胁迫对保障植物健康和制定有效管理策略至关重要。

Method: 提出一种新颖的深度学习框架，融合RGB、多光谱和两种红外波段的图像数据，利用卷积神经网络（CNN）提取空间特征，并结合长短期记忆网络（LSTM）捕捉时间依赖性，构建CNN-LSTM模型。为对比，还设计并评估了仅使用空间信息的CNN模型。

Result: CNN-LSTM模型在分类氮素胁迫严重程度方面达到了98%的准确率，显著超越了仅使用空间信息的CNN模型（80.45%）以及先前报道的其他机器学习方法（76%）。

Conclusion: 所提出的CNN-LSTM深度学习方法能有效捕捉氮素缺乏、水分胁迫和杂草压力之间复杂相互作用的细微差别，为及时主动地识别氮素胁迫严重程度提供了一个强大的平台，从而实现更好的作物管理和植物健康。

Abstract: Plants in their natural habitats endure an array of interacting stresses,
both biotic and abiotic, that rarely occur in isolation. Nutrient
stress-particularly nitrogen deficiency-becomes even more critical when
compounded with drought and weed competition, making it increasingly difficult
to distinguish and address its effects. Early detection of nitrogen stress is
therefore crucial for protecting plant health and implementing effective
management strategies. This study proposes a novel deep learning framework to
accurately classify nitrogen stress severity in a combined stress environment.
Our model uses a unique blend of four imaging modalities-RGB, multispectral,
and two infrared wavelengths-to capture a wide range of physiological plant
responses from canopy images. These images, provided as time-series data,
document plant health across three levels of nitrogen availability (low,
medium, and high) under varying water stress and weed pressures. The core of
our approach is a spatio-temporal deep learning pipeline that merges a
Convolutional Neural Network (CNN) for extracting spatial features from images
with a Long Short-Term Memory (LSTM) network to capture temporal dependencies.
We also devised and evaluated a spatial-only CNN pipeline for comparison. Our
CNN-LSTM pipeline achieved an impressive accuracy of 98%, impressively
surpassing the spatial-only model's 80.45% and other previously reported
machine learning method's 76%. These results bring actionable insights based on
the power of our CNN-LSTM approach in effectively capturing the subtle and
complex interactions between nitrogen deficiency, water stress, and weed
pressure. This robust platform offers a promising tool for the timely and
proactive identification of nitrogen stress severity, enabling better crop
management and improved plant health.

</details>


### [136] [VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes](https://arxiv.org/abs/2509.06685)
*Shengkai Zhang,Yuhe Liu,Guanjun Wu,Jianhua He,Xinggang Wang,Mozi Chen,Kezhong Liu*

Main category: cs.CV

TL;DR: VIM-GS是一个使用单目图像进行大场景新视角合成的高斯喷涂（GS）框架，通过结合视觉结构运动（SfM）提供的稀疏精确深度和大型基础模型（LFMs）提供的密集粗略深度，并提出一种对象分割深度传播算法和动态深度细化模块来生成精确深度图，从而实现高质量的GS渲染。


<details>
  <summary>Details</summary>
Motivation: 现有的大场景新视角合成方法（GS）通常需要精确的深度信息，而单目图像缺乏深度，导致合成效果不佳。虽然大型基础模型（LFMs）可以估计单目深度，但存在跨帧不一致、远景不准确和纹理欺骗性等问题。因此，本文旨在为高精度的GS渲染生成来自单目RGB输入的密集、精确的深度图像。

Method: 本文提出了一种名为VIM-GS的框架，它利用视觉-惯性结构从运动（SfM）提供的精确但稀疏的深度信息，来优化大型基础模型（LFMs）提供的密集但粗糙的深度图。为了连接稀疏输入和密集输出，提出了一种对象分割深度传播算法，用于渲染结构化对象的像素深度。此外，还开发了一个动态深度细化模块，用于处理动态对象受损的SfM深度，并优化粗糙的LFM深度。

Result: 实验结果表明，VIM-GS在大场景新视角合成方面表现出优越的渲染质量，并且使用了公开和定制的数据集进行了验证。

Conclusion: VIM-GS通过结合SfM的稀疏精确深度和LFMs的密集粗糙深度，并引入对象分割深度传播和动态深度细化模块，成功地解决了单目大场景新视角合成中的深度估计难题，实现了高质量的渲染效果。

Abstract: VIM-GS is a Gaussian Splatting (GS) framework using monocular images for
novel-view synthesis (NVS) in large scenes. GS typically requires accurate
depth to initiate Gaussian ellipsoids using RGB-D/stereo cameras. Their limited
depth sensing range makes it difficult for GS to work in large scenes.
Monocular images, however, lack depth to guide the learning and lead to
inferior NVS results. Although large foundation models (LFMs) for monocular
depth estimation are available, they suffer from cross-frame inconsistency,
inaccuracy for distant scenes, and ambiguity in deceptive texture cues. This
paper aims to generate dense, accurate depth images from monocular RGB inputs
for high-definite GS rendering. The key idea is to leverage the accurate but
sparse depth from visual-inertial Structure-from-Motion (SfM) to refine the
dense but coarse depth from LFMs. To bridge the sparse input and dense output,
we propose an object-segmented depth propagation algorithm that renders the
depth of pixels of structured objects. Then we develop a dynamic depth
refinement module to handle the crippled SfM depth of dynamic objects and
refine the coarse LFM depth. Experiments using public and customized datasets
demonstrate the superior rendering quality of VIM-GS in large scenes.

</details>


### [137] [STAGE: Segmentation-oriented Industrial Anomaly Synthesis via Graded Diffusion with Explicit Mask Alignment](https://arxiv.org/abs/2509.06693)
*Xichen Xu,Yanshu Wang,Jinbao Wang,Qunyi Zhang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu*

Main category: cs.CV

TL;DR: STAGE通过引入引导性去噪、分级扩散和掩码对齐来解决现有工业异常合成方法的局限性，从而生成更精细、更符合背景的异常，并提高下游异常分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于分割的工业异常合成（SIAS）方法在生成的异常细节、与背景的对齐以及像素级精度方面存在不足，限制了异常数据的扩展和下游异常分割任务的性能。

Method: 提出STAGE（Segmentation-oriented Anomaly synthesis via Graded diffusion with Explicit mask alignment），一种新的异常推理策略。它利用干净背景信息作为先验来指导去噪，采用分级扩散框架和仅包含异常的分支来记录局部异常，并引入显式掩码对齐（EMA）策略来逐步对齐合成异常与背景。

Result: 在MVTec和BTAD数据集上的大量实验表明，STAGE在SIAS方面取得了最先进的性能，并提升了下游异常分割的效果。

Conclusion: STAGE通过其创新的方法解决了现有SIAS方法的关键挑战，能够生成在细节、背景对齐和像素级精度方面都得到改进的异常，从而有效提升了异常分割的性能。

Abstract: Segmentation-oriented Industrial Anomaly Synthesis (SIAS) plays a pivotal
role in enhancing the performance of downstream anomaly segmentation, as it
provides an effective means of expanding abnormal data. However, existing SIAS
methods face several critical limitations: (i) the synthesized anomalies often
lack intricate texture details and fail to align precisely with the surrounding
background, and (ii) they struggle to generate fine-grained, pixel-level
anomalies. To address these challenges, we propose Segmentation-oriented
Anomaly synthesis via Graded diffusion with Explicit mask alignment, termed
STAGE. STAGE introduces a novel anomaly inference strategy that incorporates
clean background information as a prior to guide the denoising distribution,
enabling the model to more effectively distinguish and highlight abnormal
foregrounds. Furthermore, it employs a graded diffusion framework with an
anomaly-only branch to explicitly record local anomalies during both the
forward and reverse processes, ensuring that subtle anomalies are not
overlooked. Finally, STAGE incorporates the explicit mask alignment (EMA)
strategy to progressively align the synthesized anomalies with the background,
resulting in context-consistent and structurally coherent generations.
Extensive experiments on the MVTec and BTAD datasets demonstrate that STAGE
achieves state-of-the-art performance in SIAS, which in turn enhances
downstream anomaly segmentation.

</details>


### [138] [Cortex-Synth: Differentiable Topology-Aware 3D Skeleton Synthesis with Hierarchical Graph Attention](https://arxiv.org/abs/2509.06705)
*Mohamed Zayaan S*

Main category: cs.CV

TL;DR: Cortex Synth是一个端到端的框架，可以从单一2D图像合成3D骨架的几何和拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 从单一2D图像合成3D骨架的几何和拓扑结构。

Method: 提出了一种包含分层图注意力机制、可微分谱拓扑优化和对抗性几何一致性训练的框架。该框架集成了伪3D点云生成器、PointNet编码器、骨架坐标解码器和可微分图构造网络(DGCN)。

Result: 在ShapeNet上实现了18.7%的MPJPE改进和27.3%的Graph Edit Distance改进，并将拓扑错误减少了42%。

Conclusion: 该模型实现了最先进的性能，并且其端到端的学习能力使其能够应用于机器人操作、医学成像和自动角色绑定等领域。

Abstract: We present Cortex Synth, a novel end-to-end differentiable framework for
joint 3D skeleton geometry and topology synthesis from single 2D images. Our
architecture introduces three key innovations: (1) A hierarchical graph
attention mechanism with multi-scale skeletal refinement, (2) Differentiable
spectral topology optimization via Laplacian eigen decomposition, and (3)
Adversarial geometric consistency training for pose structure alignment. The
framework integrates four synergistic modules: a pseudo 3D point cloud
generator, an enhanced PointNet encoder, a skeleton coordinate decoder, and a
novel Differentiable Graph Construction Network (DGCN). Our experiments
demonstrate state-of-the-art results with 18.7 percent improvement in MPJPE and
27.3 percent in Graph Edit Distance on ShapeNet, while reducing topological
errors by 42 percent compared to previous approaches. The model's end-to-end
differentiability enables applications in robotic manipulation, medical
imaging, and automated character rigging.

</details>


### [139] [MRI-Based Brain Tumor Detection through an Explainable EfficientNetV2 and MLP-Mixer-Attention Architecture](https://arxiv.org/abs/2509.06713)
*Mustafa Yurdakul,Şakir Taşdemir*

Main category: cs.CV

TL;DR: 该研究提出了一种结合EfficientNetV2和基于注意力机制的MLP-Mixer的深度学习模型，用于对脑部MRI图像进行分类，以辅助早期诊断。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤的早期诊断至关重要，但手动分析MRI图像既需要专业知识又容易出错，因此需要自动化诊断系统。

Method: 首先评估了九种卷积神经网络（CNN）架构的分类性能，选择了表现最佳的EfficientNetV2作为骨干。然后，将基于注意力机制的MLP-Mixer架构集成到EfficientNetV2中以增强其分类能力。最后，使用Grad-CAM可视化来解释和验证模型的决策过程，并采用五折交叉验证评估性能。

Result: 所提出的模型在包含3,064张T1加权对比增强脑部MRI图像的数据集上，达到了99.50%的准确率、99.47%的精确率、99.52%的召回率和99.49%的F1分数，优于文献中的其他研究。Grad-CAM可视化表明模型能有效关注MRI图像的相关区域。

Conclusion: 通过结合EfficientNetV2和基于注意力机制的MLP-Mixer，开发了一个在脑肿瘤分类方面具有高准确性和可解释性的鲁棒深度学习模型，可用于临床决策支持系统。

Abstract: Brain tumors are serious health problems that require early diagnosis due to
their high mortality rates. Diagnosing tumors by examining Magnetic Resonance
Imaging (MRI) images is a process that requires expertise and is prone to
error. Therefore, the need for automated diagnosis systems is increasing day by
day. In this context, a robust and explainable Deep Learning (DL) model for the
classification of brain tumors is proposed. In this study, a publicly available
Figshare dataset containing 3,064 T1-weighted contrast-enhanced brain MRI
images of three tumor types was used. First, the classification performance of
nine well-known CNN architectures was evaluated to determine the most effective
backbone. Among these, EfficientNetV2 demonstrated the best performance and was
selected as the backbone for further development. Subsequently, an
attention-based MLP-Mixer architecture was integrated into EfficientNetV2 to
enhance its classification capability. The performance of the final model was
comprehensively compared with basic CNNs and the methods in the literature.
Additionally, Grad-CAM visualization was used to interpret and validate the
decision-making process of the proposed model. The proposed model's performance
was evaluated using the five-fold cross-validation method. The proposed model
demonstrated superior performance with 99.50% accuracy, 99.47% precision,
99.52% recall and 99.49% F1 score. The results obtained show that the model
outperforms the studies in the literature. Moreover, Grad-CAM visualizations
demonstrate that the model effectively focuses on relevant regions of MRI
images, thus improving interpretability and clinical reliability. A robust deep
learning model for clinical decision support systems has been obtained by
combining EfficientNetV2 and attention-based MLP-Mixer, providing high accuracy
and interpretability in brain tumor classification.

</details>


### [140] [Zero-shot 3D-Aware Trajectory-Guided image-to-video generation via Test-Time Training](https://arxiv.org/abs/2509.06723)
*Ruicheng Zhang,Jun Zhou,Zunnan Xu,Zihao Liu,Jiehui Huang,Mingyang Zhang,Yu Sun,Xiu Li*

Main category: cs.CV

TL;DR: Zo3T是一个新颖的零样本测试时训练框架，用于轨迹引导的图像到视频生成，通过3D感知运动学投影、轨迹引导测试时LoRA和引导场修正来提高3D真实感和运动精度。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹引导的图像到视频生成方法存在计算成本高、需要大量标注数据、零样本方法可能产生不切实际的运动等问题。

Method: Zo3T框架包含三个创新点：1. 3D感知运动学投影：利用场景深度推断来获得透视校正的仿射变换。2. 轨迹引导测试时LoRA：动态注入和优化LoRA适配器，通过区域特征一致性损失来约束运动并适应潜在的操纵。3. 引导场修正：通过单步前瞻策略优化条件引导场，以提高生成效率和轨迹一致性。

Result: Zo3T在轨迹引导的图像到视频生成方面显著提高了3D真实感和运动精度，并且优于现有的基于训练和零样本方法。

Conclusion: Zo3T在轨迹引导的图像到视频生成方面取得了显著的进展，解决了现有方法的局限性，并提供了更优的性能。

Abstract: Trajectory-Guided image-to-video (I2V) generation aims to synthesize videos
that adhere to user-specified motion instructions. Existing methods typically
rely on computationally expensive fine-tuning on scarce annotated datasets.
Although some zero-shot methods attempt to trajectory control in the latent
space, they may yield unrealistic motion by neglecting 3D perspective and
creating a misalignment between the manipulated latents and the network's noise
predictions. To address these challenges, we introduce Zo3T, a novel zero-shot
test-time-training framework for trajectory-guided generation with three core
innovations: First, we incorporate a 3D-Aware Kinematic Projection, leveraging
inferring scene depth to derive perspective-correct affine transformations for
target regions. Second, we introduce Trajectory-Guided Test-Time LoRA, a
mechanism that dynamically injects and optimizes ephemeral LoRA adapters into
the denoising network alongside the latent state. Driven by a regional feature
consistency loss, this co-adaptation effectively enforces motion constraints
while allowing the pre-trained model to locally adapt its internal
representations to the manipulated latent, thereby ensuring generative fidelity
and on-manifold adherence. Finally, we develop Guidance Field Rectification,
which refines the denoising evolutionary path by optimizing the conditional
guidance field through a one-step lookahead strategy, ensuring efficient
generative progression towards the target trajectory. Zo3T significantly
enhances 3D realism and motion accuracy in trajectory-controlled I2V
generation, demonstrating superior performance over existing training-based and
zero-shot approaches.

</details>


### [141] [Co-Seg: Mutual Prompt-Guided Collaborative Learning for Tissue and Nuclei Segmentation](https://arxiv.org/abs/2509.06740)
*Qing Xu,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: Co-Seg框架通过协同分割任务，提高了组织和细胞核分割的准确性，并在PUMA数据集上取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 目前的组织病理学图像分析在分割组织区域和细胞核实例时面临挑战，现有研究各自独立进行组织语义分割或细胞核实例分割，忽略了它们之间的内在联系，导致对病理特征的理解不足。

Method: 提出了一种名为Co-Seg的新框架，该框架采用新颖的协同分割范式，使组织和细胞核分割任务能够相互促进。具体来说，设计了一个区域感知提示编码器（RP-Encoder）来提供高质量的语义和实例区域提示作为先验约束，并设计了一个互提示掩码解码器（MP-Decoder）来利用交叉引导，增强两个任务的上下文一致性，协同计算语义和实例分割掩码。

Result: 在PUMA数据集上的广泛实验表明，所提出的Co-Seg在肿瘤组织和细胞核实例的语义、实例和全景分割方面均优于现有最先进的方法。

Conclusion: Co-Seg框架通过协同学习有效解决了组织和细胞核分割的挑战，提高了病理图像分析的准确性。

Abstract: Histopathology image analysis is critical yet challenged by the demand of
segmenting tissue regions and nuclei instances for tumor microenvironment and
cellular morphology analysis. Existing studies focused on tissue semantic
segmentation or nuclei instance segmentation separately, but ignored the
inherent relationship between these two tasks, resulting in insufficient
histopathology understanding. To address this issue, we propose a Co-Seg
framework for collaborative tissue and nuclei segmentation. Specifically, we
introduce a novel co-segmentation paradigm, allowing tissue and nuclei
segmentation tasks to mutually enhance each other. To this end, we first devise
a region-aware prompt encoder (RP-Encoder) to provide high-quality semantic and
instance region prompts as prior constraints. Moreover, we design a mutual
prompt mask decoder (MP-Decoder) that leverages cross-guidance to strengthen
the contextual consistency of both tasks, collaboratively computing semantic
and instance segmentation masks. Extensive experiments on the PUMA dataset
demonstrate that the proposed Co-Seg surpasses state-of-the-arts in the
semantic, instance and panoptic segmentation of tumor tissues and nuclei
instances. The source code is available at https://github.com/xq141839/Co-Seg.

</details>


### [142] [Pothole Detection and Recognition based on Transfer Learning](https://arxiv.org/abs/2509.06750)
*Mang Hu,Qianqian Xia*

Main category: cs.CV

TL;DR: 通过改进的深度学习模型ResNet50-EfficientNet-RegNet，在坑洼识别任务上实现了97.78%的准确率，优于传统机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 自动检测和识别道路图像中的坑洼状况对于社会发展具有重要意义，本研究旨在解决此问题。

Method: 收集原始数据集，进行标准化、归一化和数据增强等预处理。在此基础上，通过实验不断改进网络模型，并基于迁移学习构建了ResNet50-EfficientNet-RegNet深度学习特征提取网络。

Result: 所提出的迁移学习模型在速度和准确率方面均表现出高 outperforming 传统模型（随机森林、MLP、SVM、LightGBM）。在初始测试集上准确率为97.78%，在扩展测试集上准确率为98.89%。

Conclusion: 本研究提出的基于迁移学习的ResNet50-EfficientNet-RegNet模型在坑洼识别方面表现出高分类精度和计算效率，优于其他对比模型。

Abstract: With the rapid development of computer vision and machine learning, automated
methods for pothole detection and recognition based on image and video data
have received significant attention. It is of great significance for social
development to conduct an in-depth analysis of road images through feature
extraction, thereby achieving automatic identification of the pothole condition
in new images. Consequently, this is the main issue addressed in this study.
Based on preprocessing techniques such as standardization, normalization, and
data augmentation applied to the collected raw dataset, we continuously
improved the network model based on experimental results. Ultimately, we
constructed a deep learning feature extraction network
ResNet50-EfficientNet-RegNet model based on transfer learning. This model
exhibits high classification accuracy and computational efficiency. In terms of
model evaluation, this study employed a comparative evaluation approach by
comparing the performance of the proposed transfer learning model with other
models, including Random Forest, MLP, SVM, and LightGBM. The comparison
analysis was conducted based on metrics such as Accuracy, Recall, Precision,
F1-score, and FPS, to assess the classification performance of the transfer
learning model proposed in this paper. The results demonstrate that our model
exhibits high performance in terms of recognition speed and accuracy,
surpassing the performance of other models. Through careful parameter selection
and model optimization, our transfer learning model achieved a classification
accuracy of 97.78% (88/90) on the initial set of 90 test samples and 98.89%
(890/900) on the expanded test set.

</details>


### [143] [Raw2Event: Converting Raw Frame Camera into Event Camera](https://arxiv.org/abs/2509.06767)
*Zijie Ning,Enmin Lin,Sudarshan R. Iyengar,Patrick Vandewalle*

Main category: cs.CV

TL;DR: 我们提出 Raw2Event，一个能从低成本、基于帧的摄像头实时生成事件的软硬件系统，以克服传统事件摄像头成本高、分辨率低等缺点。


<details>
  <summary>Details</summary>
Motivation: 事件摄像头在光照条件恶劣的情况下有优势，但成本高、分辨率低，阻碍了其广泛应用，尤其是在早期开发和原型设计阶段。本研究旨在通过 Raw2Event 系统解决这些问题。

Method: Raw2Event 系统利用直接访问原始 Bayer 数据并绕过传统的 ISP，构建了一个可配置的、针对嵌入式平台优化的仿真框架。它还设计了一个支持原始、RGB 和事件流同步记录的数据采集流程。

Result: 实验结果表明，Raw2Event 生成的事件流在分辨率和自动对焦能力上优于真实事件摄像头，并且能够生成与真实事件摄像头非常相似的事件流。该系统还支持用户直观的参数调整，并已成功部署在树莓派上实现实时运行。

Conclusion: Raw2Event 提供了一个可扩展且经济高效的解决方案，用于事件驱动的视觉研究和早期系统开发，使研究人员能够利用低成本摄像头实现高性能的事件生成。

Abstract: Event cameras offer unique advantages such as high temporal resolution, low
latency, and high dynamic range, making them more and more popular for vision
tasks under challenging light conditions. However, their high cost, limited
resolution, and lack of features such as autofocus hinder their broad adoption,
particularly for early-stage development and prototyping. In this work, we
present Raw2Event, a complete hardware-software system that enables real-time
event generation from low-cost raw frame-based cameras. By leveraging direct
access to raw Bayer data and bypassing traditional image signal processors
(ISP), our system is able to utilize the full potential of camera hardware,
delivering higher dynamic range, higher resolution, and more faithful output
than RGB-based frame-to-event converters.
  Built upon the DVS-Voltmeter model, Raw2Event features a configurable
simulation framework optimized for deployment on embedded platforms. We further
design a data acquisition pipeline that supports synchronized recording of raw,
RGB, and event streams, facilitating downstream evaluation and dataset
creation. Experimental results show that Raw2Event can generate event streams
closely resembling those from real event cameras, while benefiting from higher
resolution and autofocus capabilities. The system also supports user-intuitive
parameter tuning, enabling flexible adaptation to various application
requirements. Finally, we deploy the system on a Raspberry Pi for real-time
operation, providing a scalable and cost-effective solution for event-based
vision research and early-stage system development.
  The codes are available online:
https://anonymous.4open.science/r/raw2event-BFF2/README.md.

</details>


### [144] [D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning](https://arxiv.org/abs/2509.06771)
*Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar*

Main category: cs.CV

TL;DR: 本研究提出了一个包含4379个Reddit表情包的数据集，并引入了一种多模态暗讽幽默检测框架，该框架利用大型视觉语言模型（VLM）生成结构化解释，并通过三流交叉推理网络（TCRNet）融合文本、图像和推理特征，在暗讽幽默检测、目标识别和强度预测任务上均取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在线表情包中的暗讽幽默由于其隐含、敏感和文化背景线索而带来独特的挑战，但目前缺乏针对多模态内容检测暗讽幽默的资源和方法。

Method: 构建了一个包含4379个Reddit表情包的数据集，并提出了一个包含视觉语言模型（VLM）和三流交叉推理网络（TCRNet）的框架。VLM通过角色反转自循环生成并优化表情包的结构化解释，然后结合OCR文本和视觉特征，利用TCRNet进行分类。

Result: 在暗讽幽默检测、目标识别和强度预测三个任务上，所提出的方法均超越了现有的基线方法。

Conclusion: 本研究成功构建了一个多模态暗讽幽默数据集，并提出了一个有效的推理增强框架，该框架在暗讽幽默检测任务上表现出色，并开源了数据集、注释和代码，以促进该领域的研究。

Abstract: Dark humor in online memes poses unique challenges due to its reliance on
implicit, sensitive, and culturally contextual cues. To address the lack of
resources and methods for detecting dark humor in multimodal content, we
introduce a novel dataset of 4,379 Reddit memes annotated for dark humor,
target category (gender, mental health, violence, race, disability, and other),
and a three-level intensity rating (mild, moderate, severe). Building on this
resource, we propose a reasoning-augmented framework that first generates
structured explanations for each meme using a Large Vision-Language Model
(VLM). Through a Role-Reversal Self-Loop, VLM adopts the author's perspective
to iteratively refine its explanations, ensuring completeness and alignment. We
then extract textual features from both the OCR transcript and the self-refined
reasoning via a text encoder, while visual features are obtained using a vision
transformer. A Tri-stream Cross-Reasoning Network (TCRNet) fuses these three
streams, text, image, and reasoning, via pairwise attention mechanisms,
producing a unified representation for classification. Experimental results
demonstrate that our approach outperforms strong baselines across three tasks:
dark humor detection, target identification, and intensity prediction. The
dataset, annotations, and code are released to facilitate further research in
multimodal humor understanding and content moderation. Code and Dataset are
available at:
https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning

</details>


### [145] [UrbanTwin: High-Fidelity Synthetic Replicas of Roadside Lidar Datasets](https://arxiv.org/abs/2509.06781)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: 本文介绍了UrbanTwin数据集，它是对三个公开的道路激光雷达数据集（LUMPI、V2X-Real-IC和TUMTraf-I）的高保真、逼真复制。每个UrbanTwin数据集包含10K个带注释的帧，并提供3D边界框、实例分割标签、跟踪ID以及语义分割标签。这些数据集使用数字孪生中的模拟激光雷达传感器合成，并根据实际位置的周围几何、车道级道路对齐以及车道拓扑和交叉口的车辆运动模式进行建模。通过统计和结构相似性分析评估了合成数据与真实数据的对齐程度，并通过仅在合成数据上训练3D目标检测模型并在真实、未见过的数据上进行测试来证明其效用。结果表明，UrbanTwin数据集通过增加样本量和场景多样性，有效地增强了现有的基准数据集，并且可以作为激光雷达感知任务中真实世界数据集的替代品。


<details>
  <summary>Details</summary>
Motivation: 创建高保真、逼真的合成激光雷达数据集，以解决真实世界数据集的局限性，并为训练深度学习模型提供更大、更多样化的数据源。

Method: 使用真实的道路几何、车道拓扑和车辆运动模式，在数字孪生中模拟激光雷达传感器，创建UrbanTwin数据集，并对生成的数据进行注释。

Result: UrbanTwin数据集与真实数据集高度相似，并且在仅使用合成数据训练的3D目标检测模型在真实数据上的表现优于使用真实数据训练的模型。

Conclusion: UrbanTwin数据集是第一个可以替代真实世界数据集用于激光雷达感知任务的数字合成数据集，它们通过增加数据量和场景多样性来增强现有数据集，并且可以用于测试自定义场景。

Abstract: This article presents UrbanTwin datasets - high-fidelity, realistic replicas
of three public roadside lidar datasets: LUMPI, V2X-Real-IC, and TUMTraf-I.
Each UrbanTwin dataset contains 10K annotated frames corresponding to one of
the public datasets. Annotations include 3D bounding boxes, instance
segmentation labels, and tracking IDs for six object classes, along with
semantic segmentation labels for nine classes. These datasets are synthesized
using emulated lidar sensors within realistic digital twins, modeled based on
surrounding geometry, road alignment at lane level, and the lane topology and
vehicle movement patterns at intersections of the actual locations
corresponding to each real dataset. Due to the precise digital twin modeling,
the synthetic datasets are well aligned with their real counterparts, offering
strong standalone and augmentative value for training deep learning models on
tasks such as 3D object detection, tracking, and semantic and instance
segmentation. We evaluate the alignment of the synthetic replicas through
statistical and structural similarity analysis with real data, and further
demonstrate their utility by training 3D object detection models solely on
synthetic data and testing them on real, unseen data. The high similarity
scores and improved detection performance, compared to the models trained on
real data, indicate that the UrbanTwin datasets effectively enhance existing
benchmark datasets by increasing sample size and scene diversity. In addition,
the digital twins can be adapted to test custom scenarios by modifying the
design and dynamics of the simulations. To our knowledge, these are the first
digitally synthesized datasets that can replace in-domain real-world datasets
for lidar perception tasks. UrbanTwin datasets are publicly available at
https://dataverse.harvard.edu/dataverse/ucf-ut.

</details>


### [146] [P3-SAM: Native 3D Part Segmentation](https://arxiv.org/abs/2509.06784)
*Changfeng Ma,Yang Li,Xinhao Yan,Jiachen Xu,Yunhan Yang,Chunshi Wang,Zibo Zhao,Yanwen Guo,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: P3-SAM是一个全自动化的3D部件分割模型，能够处理复杂对象并达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D部件分割方法在处理复杂对象时鲁棒性不足且无法完全自动化，而P3-SAM旨在解决这些问题。

Method: P3-SAM模型包含特征提取器、多个分割头和IoU预测器，并辅以一个自动选择和合并分割掩码的算法，以实现交互式和实例分割。

Result: P3-SAM在包含近370万个模型的新数据集上进行了训练，并在复杂对象上实现了精确的分割结果和强大的鲁棒性，达到了最先进的性能。

Conclusion: P3-SAM成功实现了3D部件的自动化分割，解决了现有方法的局限性，并在各种复杂场景下表现出色。

Abstract: Segmenting 3D assets into their constituent parts is crucial for enhancing 3D
understanding, facilitating model reuse, and supporting various applications
such as part generation. However, current methods face limitations such as poor
robustness when dealing with complex objects and cannot fully automate the
process. In this paper, we propose a native 3D point-promptable part
segmentation model termed P3-SAM, designed to fully automate the segmentation
of any 3D objects into components. Inspired by SAM, P3-SAM consists of a
feature extractor, multiple segmentation heads, and an IoU predictor, enabling
interactive segmentation for users. We also propose an algorithm to
automatically select and merge masks predicted by our model for part instance
segmentation. Our model is trained on a newly built dataset containing nearly
3.7 million models with reasonable segmentation labels. Comparisons show that
our method achieves precise segmentation results and strong robustness on any
complex objects, attaining state-of-the-art performance. Our code will be
released soon.

</details>


### [147] [AIM 2025 Challenge on High FPS Motion Deblurring: Methods and Results](https://arxiv.org/abs/2509.06793)
*George Ciubotariu,Florin-Alexandru Vasluianu,Zhuyun Zhou,Nancy Mehta,Radu Timofte,Ke Wu,Long Sun,Lingshun Kong,Zhongbao Yang,Jinshan Pan,Jiangxin Dong,Jinhui Tang,Hao Chen,Yinghui Fang,Dafeng Zhang,Yongqi Song,Jiangbo Guo,Shuhua Jin,Zeyu Xiao,Rui Zhao,Zhuoyuan Li,Cong Zhang,Yufeng Peng,Xin Lu,Zhijing Sun,Chengjie Ge,Zihao Li,Zishun Liao,Ziang Zhou,Qiyu Kang,Xueyang Fu,Zheng-Jun Zha,Yuqian Zhang,Shuai Liu,Jie Liu,Zhuhao Zhang,Lishen Qu,Zhihao Liu,Shihao Zhou,Yaqi Luo,Juncheng Zhou,Jufeng Yang,Qianfeng Yang,Qiyuan Guan,Xiang Chen,Guiyue Jin,Jiyu Jin*

Main category: cs.CV

TL;DR: AIM 2025 挑战赛回顾，专注于高帧率非均匀运动模糊去除。


<details>
  <summary>Details</summary>
Motivation: 识别能在复杂运动类型聚合中学习代表性视觉线索，以在多样化和挑战性条件下生成更清晰、视觉上引人注目的图像的网络。

Method: 对现有技术在 АIM 2025 高帧率单图像运动模糊去除挑战赛中的进展进行了评估，并使用了 MIORe 数据集。

Result: 68 个参赛者注册，9 支队伍提交了有效条目，展示了该领域的显著进展。

Conclusion: 对 AIM 2025 高帧率非均匀运动模糊挑战赛的解决方案和最终结果进行了全面回顾。

Abstract: This paper presents a comprehensive review of the AIM 2025 High FPS
Non-Uniform Motion Deblurring Challenge, highlighting the proposed solutions
and final results. The objective of this challenge is to identify effective
networks capable of producing clearer and visually compelling images in diverse
and challenging conditions, by learning representative visual cues for complex
aggregations of motion types. A total of 68 participants registered for the
competition, and 9 teams ultimately submitted valid entries. This paper
thoroughly evaluates the state-of-the-art advances in high-FPS single image
motion deblurring, showcasing the significant progress in the field, while
leveraging samples of the novel dataset, MIORe, that introduces challenging
examples of movement patterns.

</details>


### [148] [SynthDrive: Scalable Real2Sim2Real Sensor Simulation Pipeline for High-Fidelity Asset Generation and Driving Data Synthesis](https://arxiv.org/abs/2509.06798)
*Zhengqing Chen,Ruohong Mei,Xiaoyang Guo,Qingjie Wang,Yubin Hu,Wei Yin,Weiqiang Ren,Qian Zhang*

Main category: cs.CV

TL;DR: 利用3D生成技术解决自动驾驶传感器模拟中稀有场景数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶领域的传感器模拟方法在生成多样化且罕见的场景方面存在局限性，阻碍了鲁棒感知模型的训练。基于CG的方法难以扩展以覆盖所有罕见情况，而基于学习的方法则仅限于特定物体类别且需要大量多传感器数据。

Method: 提出了一种可扩展的real2sim2real系统，利用3D生成技术自动化资产挖掘、生成和罕见场景数据合成。

Result: 该系统能够有效地生成多样化且罕见的场景数据，克服了现有方法的不足。

Conclusion: 提出的real2sim2real系统为自动驾驶传感器模拟提供了更有效、更具扩展性的解决方案，尤其在处理罕见场景数据合成方面具有优势。

Abstract: In the field of autonomous driving, sensor simulation is essential for
generating rare and diverse scenarios that are difficult to capture in
real-world environments. Current solutions fall into two categories: 1)
CG-based methods, such as CARLA, which lack diversity and struggle to scale to
the vast array of rare cases required for robust perception training; and 2)
learning-based approaches, such as NeuSim, which are limited to specific object
categories (vehicles) and require extensive multi-sensor data, hindering their
applicability to generic objects. To address these limitations, we propose a
scalable real2sim2real system that leverages 3D generation to automate asset
mining, generation, and rare-case data synthesis.

</details>


### [149] [MIORe & VAR-MIORe: Benchmarks to Push the Boundaries of Restoration](https://arxiv.org/abs/2509.06803)
*George Ciubotariu,Zhuyun Zhou,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: MIORe and VAR-MIORe are new multi-task datasets for motion restoration, featuring high-frame-rate acquisition, controlled motion blur, and variable motion magnitudes. They provide high-resolution ground truths to challenge current algorithms and advance research in image and video restoration.


<details>
  <summary>Details</summary>
Motivation: Existing motion restoration benchmarks have critical limitations. This paper introduces MIORe and VAR-MIORe datasets to address these limitations by providing high-frame-rate acquisition, professional-grade optics, and a broad spectrum of motion scenarios.

Method: MIORe generates consistent motion blur by adaptively averaging frames based on computed optical flow metrics, while preserving sharp inputs. VAR-MIORe extends this by covering a variable range of motion magnitudes, from minimal to extreme, establishing the first benchmark with explicit control over motion amplitude.

Result: The datasets capture complex ego-camera movements, dynamic multi-subject interactions, and depth-dependent blur effects. They provide high-resolution, scalable ground truths that challenge existing algorithms under both controlled and adverse conditions.

Conclusion: MIORe and VAR-MIORe datasets pave the way for next-generation research in various image and video restoration tasks by offering advanced capabilities and challenging benchmarks.

Abstract: We introduce MIORe and VAR-MIORe, two novel multi-task datasets that address
critical limitations in current motion restoration benchmarks. Designed with
high-frame-rate (1000 FPS) acquisition and professional-grade optics, our
datasets capture a broad spectrum of motion scenarios, which include complex
ego-camera movements, dynamic multi-subject interactions, and depth-dependent
blur effects. By adaptively averaging frames based on computed optical flow
metrics, MIORe generates consistent motion blur, and preserves sharp inputs for
video frame interpolation and optical flow estimation. VAR-MIORe further
extends by spanning a variable range of motion magnitudes, from minimal to
extreme, establishing the first benchmark to offer explicit control over motion
amplitude. We provide high-resolution, scalable ground truths that challenge
existing algorithms under both controlled and adverse conditions, paving the
way for next-generation research of various image and video restoration tasks.

</details>


### [150] [UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward](https://arxiv.org/abs/2509.06818)
*Yufeng Cheng,Wenxu Wu,Shaojin Wu,Mengqi Huang,Fei Ding,Qian He*

Main category: cs.CV

TL;DR: UMO是一个统一的多身份优化框架，通过


<details>
  <summary>Details</summary>
Motivation: 人类对人脸更为敏感，因此在图像定制中，保持身份一致性同时避免多参考图像的身份混淆是一个重大挑战，这限制了定制模型在身份方面的可扩展性。

Method: UMO采用"多对多匹配"范式，将多身份生成重新定义为全局分配优化问题，并通过在扩散模型上进行强化学习来增强现有图像定制方法的多身份一致性。此外，该研究还开发了一个包含合成和真实图像的多参考图像可扩展定制数据集，并提出了一个新的身份混淆度量指标。

Result: 实验表明，UMO显著提高了身份一致性，并减少了多种图像定制方法中的身份混淆，在身份保持方面达到了新的开源方法最优水平。

Conclusion: UMO通过多对多匹配和强化学习，有效解决了图像定制中的身份保持和身份混淆问题，并提高了可扩展性，设定了新的行业标准。

Abstract: Recent advancements in image customization exhibit a wide range of
application prospects due to stronger customization capabilities. However,
since we humans are more sensitive to faces, a significant challenge remains in
preserving consistent identity while avoiding identity confusion with
multi-reference images, limiting the identity scalability of customization
models. To address this, we present UMO, a Unified Multi-identity Optimization
framework, designed to maintain high-fidelity identity preservation and
alleviate identity confusion with scalability. With "multi-to-multi matching"
paradigm, UMO reformulates multi-identity generation as a global assignment
optimization problem and unleashes multi-identity consistency for existing
image customization methods generally through reinforcement learning on
diffusion models. To facilitate the training of UMO, we develop a scalable
customization dataset with multi-reference images, consisting of both
synthesised and real parts. Additionally, we propose a new metric to measure
identity confusion. Extensive experiments demonstrate that UMO not only
improves identity consistency significantly, but also reduces identity
confusion on several image customization methods, setting a new
state-of-the-art among open-source methods along the dimension of identity
preserving. Code and model: https://github.com/bytedance/UMO

</details>


### [151] [Video-Based MPAA Rating Prediction: An Attention-Driven Hybrid Architecture Using Contrastive Learning](https://arxiv.org/abs/2509.06826)
*Dipta Neogi,Nourash Azmine Chowdhury,Muhammad Rafsan Kabir,Mohammad Ashrafuzzaman Khan*

Main category: cs.CV

TL;DR: 利用对比学习和混合CNN+LSTM+注意力机制模型对视频进行年龄分级。


<details>
  <summary>Details</summary>
Motivation: 由于对视频内容进行年龄分级（例如MPAA评级系统）的需求日益增长，而传统方法在数据需求、泛化性和特征学习方面存在不足，因此需要新的方法。

Method: 提出一种混合架构，结合了LRCN（CNN+LSTM）和Bahdanau注意力机制，并探索了三种对比学习框架（实例区分、上下文对比学习和多视图对比学习），以提高模型的区分能力和适应性。

Result: 在上下文对比学习框架下，该模型达到了88%的准确率和0.8815的F1分数，在区分PG-13和R级内容等细微差别方面表现出色。

Conclusion: 所提出的结合CNN、LSTM和注意力机制的混合架构，通过对比学习，在视频年龄分级任务上取得了最先进的性能，并已成功部署为实时分类的Web应用程序。

Abstract: The rapid growth of visual content consumption across platforms necessitates
automated video classification for age-suitability standards like the MPAA
rating system (G, PG, PG-13, R). Traditional methods struggle with large
labeled data requirements, poor generalization, and inefficient feature
learning. To address these challenges, we employ contrastive learning for
improved discrimination and adaptability, exploring three frameworks: Instance
Discrimination, Contextual Contrastive Learning, and Multi-View Contrastive
Learning. Our hybrid architecture integrates an LRCN (CNN+LSTM) backbone with a
Bahdanau attention mechanism, achieving state-of-the-art performance in the
Contextual Contrastive Learning framework, with 88% accuracy and an F1 score of
0.8815. By combining CNNs for spatial features, LSTMs for temporal modeling,
and attention mechanisms for dynamic frame prioritization, the model excels in
fine-grained borderline distinctions, such as differentiating PG-13 and R-rated
content. We evaluate the model's performance across various contrastive loss
functions, including NT-Xent, NT-logistic, and Margin Triplet, demonstrating
the robustness of our proposed architecture. To ensure practical application,
the model is deployed as a web application for real-time MPAA rating
classification, offering an efficient solution for automated content compliance
across streaming platforms.

</details>


### [152] [Curia: A Multi-Modal Foundation Model for Radiology](https://arxiv.org/abs/2509.06830)
*Corentin Dancette,Julien Khlaut,Antoine Saporta,Helene Philippe,Elodie Ferreres,Baptiste Callard,Théo Danielou,Léo Alberge,Léo Machado,Daniel Tordjman,Julie Dupuis,Korentin Le Floch,Jean Du Terrail,Mariam Moshiri,Laurent Dercle,Tom Boeken,Jules Gregory,Maxime Ronot,François Legou,Pascal Roux,Marc Sapoval,Pierre Manceron,Paul Hérent*

Main category: cs.CV

TL;DR: Curia是一个大型基础模型，在真实的放射影像数据上进行训练，能够跨模态、低数据场景下进行准确的器官识别、病灶检测和预后预测，性能超越了放射科医生和现有基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有的AI辅助放射学方法主要基于狭窄的、单一任务的模型，难以覆盖广泛的影像模态、疾病和影像学发现，而基础模型（FMs）在泛化能力和低数据场景下的潜力尚未在放射学领域得到充分实现。

Method: 介绍了一个名为Curia的基础模型，该模型使用了某大型医院数年来的全部横断面影像输出（约15万份检查，130TB数据）进行训练，并在一项包含19个任务的外部验证基准上进行了测试。

Result: Curia能够准确识别器官、检测脑出血和心肌梗死等病症，并预测肿瘤分期的预后。在跨模态和低数据场景下，Curia展现出临床上显著的涌现能力，其性能达到了或超过了放射科医生和近期基础模型的水平。

Conclusion: Curia模型在真实的放射影像数据上展示了强大的泛化能力和涌现能力，能够应对多种影像模态、疾病和低数据场景，为AI在放射学领域的应用提供了新的方向，并公开发布了模型权重以促进研究。

Abstract: AI-assisted radiological interpretation is based on predominantly narrow,
single-task models. This approach is impractical for covering the vast spectrum
of imaging modalities, diseases, and radiological findings. Foundation models
(FMs) hold the promise of broad generalization across modalities and in
low-data settings. However, this potential has remained largely unrealized in
radiology. We introduce Curia, a foundation model trained on the entire
cross-sectional imaging output of a major hospital over several years, which to
our knowledge is the largest such corpus of real-world data-encompassing
150,000 exams (130 TB). On a newly curated 19-task external validation
benchmark, Curia accurately identifies organs, detects conditions like brain
hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging.
Curia meets or surpasses the performance of radiologists and recent foundation
models, and exhibits clinically significant emergent properties in
cross-modality, and low-data regimes. To accelerate progress, we release our
base model's weights at https://huggingface.co/raidium/curia.

</details>


### [153] [Leveraging Generic Foundation Models for Multimodal Surgical Data Analysis](https://arxiv.org/abs/2509.06831)
*Simon Pezold,Jérôme A. Kurylec,Jan S. Liechti,Beat P. Müller,Joël L. Lavanchy*

Main category: cs.CV

TL;DR: 通过迁移学习和整合手术室（OR）的互补模态来改进外科数据科学。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过迁移学习和整合手术室（OR）的互补模态来支持外科数据科学。

Method: 使用 V-JEPA 作为多模态模型的单一模态基础，并分析下游性能如何受益于（a）在无标签手术视频数据上的微调和（b）在多模态设置中提供来自 OR 的额外时间分辨数据流。

Result: 在内部肝脏手术数据集和公共 HeiCo 数据集上进行的实验表明，在领域特定数据上进行微调可以提高模型性能。整合额外的时域数据流也有助于模型。在 HeiCo 数据集上，预训练的 V-JEPA 单模态基线设置的准确性与 EndoVis2017 挑战赛的顶级提交相当，而在领域特定数据上进行微调可以进一步提高准确性。

Conclusion: 研究结果表明，外科数据科学可以利用公共的、通用的基础模型，并且领域适应和整合来自 OR 的合适互补数据流具有潜力。

Abstract: We investigate how both the adaptation of a generic foundation model via
transfer learning and the integration of complementary modalities from the
operating room (OR) can support surgical data science. To this end, we use
V-JEPA as the single-modality foundation of a multimodal model for minimally
invasive surgery support. We analyze how the model's downstream performance can
benefit (a) from finetuning on unlabeled surgical video data and (b) from
providing additional time-resolved data streams from the OR in a multimodal
setup.
  In an in-house dataset of liver surgery videos, we analyze the tasks of
predicting hospital length of stay and postoperative complications. In videos
of the public HeiCo dataset, we analyze the task of surgical phase recognition.
As a baseline, we apply pretrained V-JEPA to all tasks. We then finetune it on
unlabeled, held-out videos to investigate its change in performance after
domain adaptation. Following the idea of modular decision support networks, we
integrate additional data streams from the OR by training a separate encoder to
form a shared representation space with V-JEPA's embeddings.
  Our experiments show that finetuning on domain-specific data increases model
performance. On the in-house data, integrating additional time-resolved data
likewise benefits the model. On the HeiCo data, accuracy of the pretrained
video-only, single-modality baseline setup is on par with the top-performing
submissions of the EndoVis2017 challenge, while finetuning on domain-specific
data increases accuracy further. Our results thus demonstrate how surgical data
science can leverage public, generic foundation models. Likewise, they indicate
the potential of domain adaptation and of integrating suitable complementary
data streams from the OR. To support further research, we release our code and
model weights at https://github.com/DigitalSurgeryLab-Basel/ML-CDS-2025.

</details>


### [154] [Evaluating the Impact of Adversarial Attacks on Traffic Sign Classification using the LISA Dataset](https://arxiv.org/abs/2509.06835)
*Nabeyou Tadessa,Balaji Iyangar,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 该研究评估了交通标志分类器对对抗性攻击的脆弱性，发现增加扰动幅度会显著降低准确性。


<details>
  <summary>Details</summary>
Motivation: 以往对机器学习模型对抗性攻击的研究主要集中在MNIST等数据集，本研究旨在探究交通标志分类器（使用LISA交通标志数据集）的脆弱性。

Method: 训练一个卷积神经网络来分类47种不同的交通标志，并使用快速梯度符号法（FGSM）和投影梯度下降（PGD）攻击来评估其鲁棒性。

Result: 结果表明，随着扰动幅度的增加，分类准确性急剧下降，突显了模型在对抗性样本面前的易感性。

Conclusion: 该研究为未来探索针对现实世界交通标志识别系统而定制的防御机制奠定了基础。

Abstract: Adversarial attacks pose significant threats to machine learning models by
introducing carefully crafted perturbations that cause misclassification. While
prior work has primarily focused on MNIST and similar datasets, this paper
investigates the vulnerability of traffic sign classifiers using the LISA
Traffic Sign dataset. We train a convolutional neural network to classify 47
different traffic signs and evaluate its robustness against Fast Gradient Sign
Method (FGSM) and Projected Gradient Descent (PGD) attacks. Our results show a
sharp decline in classification accuracy as the perturbation magnitude
increases, highlighting the models susceptibility to adversarial examples. This
study lays the groundwork for future exploration into defense mechanisms
tailored for real-world traffic sign recognition systems.

</details>


### [155] [ToonOut: Fine-tuned Background-Removal for Anime Characters](https://arxiv.org/abs/2509.06839)
*Matteo Muratori,Joël Seytre*

Main category: cs.CV

TL;DR: 现有的背景移除模型在动漫风格图像上表现不佳，本研究通过收集和标注动漫数据集来微调BiRefNet模型，显著提高了背景移除的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的背景移除模型在处理动漫风格图像时存在不足，尤其是在头发和透明度等复杂特征的处理上。

Method: 收集并标注了一个包含1228张动漫图像的数据集，并在该数据集上对开源的BiRefNet模型进行了微调。

Result: 在新的Pixel Accuracy指标上，动漫图像的背景移除准确率从95.3%提高到99.5%。

Conclusion: 通过在定制的动漫数据集上微调BiRefNet模型，可以显著提高动漫风格图像的背景移除准确性。

Abstract: While state-of-the-art background removal models excel at realistic imagery,
they frequently underperform in specialized domains such as anime-style
content, where complex features like hair and transparency present unique
challenges. To address this limitation, we collected and annotated a custom
dataset of 1,228 high-quality anime images of characters and objects, and
fine-tuned the open-sourced BiRefNet model on this dataset. This resulted in
marked improvements in background removal accuracy for anime-style images,
increasing from 95.3% to 99.5% for our newly introduced Pixel Accuracy metric.
We are open-sourcing the code, the fine-tuned model weights, as well as the
dataset at: https://github.com/MatteoKartoon/BiRefNet.

</details>


### [156] [Automated Radiographic Total Sharp Score (ARTSS) in Rheumatoid Arthritis: A Solution to Reduce Inter-Intra Reader Variation and Enhancing Clinical Practice](https://arxiv.org/abs/2509.06854)
*Hajar Moradmand,Lei Ren*

Main category: cs.CV

TL;DR: 本研究提出了一种名为ARTSS的深度学习框架，用于自动评估类风湿关节炎（RA）的严重程度，通过分析手部X光图像来计算TSS分数，旨在减少手动评分的主观性和耗时性。


<details>
  <summary>Details</summary>
Motivation: 手动评分RA的TSS分数耗时且主观，本研究旨在开发一种自动化的深度学习方法ARTSS来解决这个问题，并处理关节消失和图像序列长度可变的情况。

Method: ARTSS框架包括四个阶段：I) 使用ResNet50进行图像预处理和重新定向，II) 使用UNet.3进行手部分割，III) 使用YOLOv7进行关节识别，IV) 使用VGG16、VGG19、ResNet50、DenseNet201、EfficientNetB0和Vision Transformer（ViT）等模型进行TSS预测。模型使用IoU、MAP、MAE、RMSE和Huber损失进行评估，并采用3折交叉验证进行训练，外部测试集包含291名受试者。

Result: 关节识别模型的准确率达到99%。在TSS预测方面，表现最佳的ViT模型取得了0.87的低Huber损失。ARTSS框架能够处理关节消失和关节数量可变的问题。

Conclusion: 本研究证明了深度学习在自动化RA评分方面的潜力，ARTSS框架通过提高效率、减少评分变异性、提高准确性，有望显著改善临床实践，并为风湿病学家提供更明智的决策支持。

Abstract: Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van
Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming
and subjective. This study introduces an Automated Radiographic Sharp Scoring
(ARTSS) framework that leverages deep learning to analyze full-hand X-ray
images, aiming to reduce inter- and intra-observer variability. The research
uniquely accommodates patients with joint disappearance and variable-length
image sequences. We developed ARTSS using data from 970 patients, structured
into four stages: I) Image pre-processing and re-orientation using ResNet50,
II) Hand segmentation using UNet.3, III) Joint identification using YOLOv7, and
IV) TSS prediction using models such as VGG16, VGG19, ResNet50, DenseNet201,
EfficientNetB0, and Vision Transformer (ViT). We evaluated model performance
with Intersection over Union (IoU), Mean Average Precision (MAP), mean absolute
error (MAE), Root Mean Squared Error (RMSE), and Huber loss. The average TSS
from two radiologists was used as the ground truth. Model training employed
3-fold cross-validation, with each fold consisting of 452 training and 227
validation samples, and external testing included 291 unseen subjects. Our
joint identification model achieved 99% accuracy. The best-performing model,
ViT, achieved a notably low Huber loss of 0.87 for TSS prediction. Our results
demonstrate the potential of deep learning to automate RA scoring, which can
significantly enhance clinical practice. Our approach addresses the challenge
of joint disappearance and variable joint numbers, offers timesaving benefits,
reduces inter- and intra-reader variability, improves radiologist accuracy, and
aids rheumatologists in making more informed decisions.

</details>


### [157] [Matching Shapes Under Different Topologies: A Topology-Adaptive Deformation Guided Approach](https://arxiv.org/abs/2509.06862)
*Aymen Merrouche,Stefanie Wuhrer,Edmond Boyer*

Main category: cs.CV

TL;DR: 提出一种拓扑自适应形变模型，用于在存在拓扑瑕疵的情况下匹配三维网格，并联合优化模板网格及其与待匹配形状的对齐，以提取对应关系。


<details>
  <summary>Details</summary>
Motivation: 当前的三维网格匹配方法在处理具有拓扑瑕疵的网格时假设（如近等距或ARAP形变）会失效，而这类瑕疵在实际应用（如多视角重建）中很常见。

Method: 提出一种拓扑自适应形变模型，允许形状拓扑发生变化，以满足ARAP和双射关联约束来对齐形状。在此模型基础上，联合优化一个具有合适拓扑的模板网格，并将其与待匹配的形状对齐，以提取对应关系。

Result: 该方法能够处理高度非等距的形状和具有拓扑瑕疵的形状（包括嘈杂的多视角重建），并且在三维对齐质量上优于在大型数据集上训练的方法，而无需依赖任何数据驱动的先验知识。

Conclusion: 所提出的拓扑自适应形变模型能够有效地解决现有方法在处理具有拓扑瑕疵的三维网格匹配问题上的局限性，并在实际应用场景中取得了优于现有方法的性能。

Abstract: Non-rigid 3D mesh matching is a critical step in computer vision and computer
graphics pipelines. We tackle matching meshes that contain topological
artefacts which can break the assumption made by current approaches. While
Functional Maps assume the deformation induced by the ground truth
correspondences to be near-isometric, ARAP-like deformation-guided approaches
assume the latter to be ARAP. Neither assumption holds in certain topological
configurations of the input shapes. We are motivated by real-world scenarios
such as per-frame multi-view reconstructions, often suffering from topological
artefacts. To this end, we propose a topology-adaptive deformation model
allowing changes in shape topology to align shape pairs under ARAP and
bijective association constraints. Using this model, we jointly optimise for a
template mesh with adequate topology and for its alignment with the shapes to
be matched to extract correspondences. We show that, while not relying on any
data-driven prior, our approach applies to highly non-isometric shapes and
shapes with topological artefacts, including noisy per-frame multi-view
reconstructions, even outperforming methods trained on large datasets in 3D
alignment quality.

</details>


### [158] [A New Hybrid Model of Generative Adversarial Network and You Only Look Once Algorithm for Automatic License-Plate Recognition](https://arxiv.org/abs/2509.06868)
*Behnoud Shafiezadeh,Amir Mashmool,Farshad Eshghi,Manoochehr Kelarestaghi*

Main category: cs.CV

TL;DR: 提出了一种结合了GAN的ALPR系统，使用YOLOv5进行车牌检测和字符识别，取得了高精度和实时性。


<details>
  <summary>Details</summary>
Motivation: ALPR在智能交通系统中至关重要，但车牌图像易变，传统方法难以处理，深度学习是更好的选择。

Method: 提出了一种选择性GAN用于预处理去模糊，并结合YOLOv5进行车牌检测（LPD）、字符分割（CS）和字符识别（CR）。

Result: YOLOv5在LPD和CR阶段的检测时间为0.026秒，ALPR系统整体精度在LPD和CR阶段分别达到95%和97%。Deblur-GAN预处理器将模糊车牌的检测准确率提高了近40%。

Conclusion: 所提出的ALPR系统结合了YOLOv5和Deblur-GAN，在检测精度和速度上都表现出色，特别适合实时和便携式应用。所发布的模糊和ALPR数据集（伊朗车牌）为相关研究提供了资源。

Abstract: Automatic License-Plate Recognition (ALPR) plays a pivotal role in
Intelligent Transportation Systems (ITS) as a fundamental element of Smart
Cities. However, due to its high variability, ALPR faces challenging issues
more efficiently addressed by deep learning techniques. In this paper, a
selective Generative Adversarial Network (GAN) is proposed for deblurring in
the preprocessing step, coupled with the state-of-the-art You-Only-Look-Once
(YOLO)v5 object detection architectures for License-Plate Detection (LPD), and
the integrated Character Segmentation (CS) and Character Recognition (CR)
steps. The selective preprocessing bypasses unnecessary and sometimes
counter-productive input manipulations, while YOLOv5 LPD/CS+CR delivers high
accuracy and low computing cost. As a result, YOLOv5 achieves a detection time
of 0.026 seconds for both LP and CR detection stages, facilitating real-time
applications with exceptionally rapid responsiveness. Moreover, the proposed
model achieves accuracy rates of 95\% and 97\% in the LPD and CR detection
phases, respectively. Furthermore, the inclusion of the Deblur-GAN
pre-processor significantly improves detection accuracy by nearly 40\%,
especially when encountering blurred License Plates (LPs).To train and test the
learning components, we generated and publicly released our blur and ALPR
datasets (using Iranian license plates as a use-case), which are more
representative of close-to-real-life ad-hoc situations. The findings
demonstrate that employing the state-of-the-art YOLO model results in excellent
overall precision and detection time, making it well-suited for portable
applications. Additionally, integrating the Deblur-GAN model as a preliminary
processing step enhances the overall effectiveness of our comprehensive model,
particularly when confronted with blurred scenes captured by the camera as
input.

</details>


### [159] [Barlow-Swin: Toward a novel siamese-based segmentation architecture using Swin-Transformers](https://arxiv.org/abs/2509.06885)
*Morteza Kiani Haftlang,Mohammadhossein Malmir,Foroutan Parand,Umberto Michelucci,Safouane El Ghazouali*

Main category: cs.CV

TL;DR: 提出了一种端到端的轻量级网络结构，结合了Swin Transformer和U-Net的特点，用于实时医学图像二值分割，并通过Barlow Twins自监督学习进行预训练，以提高在标注数据不足情况下的特征学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割方法（如U-Net）存在感受野有限的问题，而基于Transformer的方法计算成本高昂，不适用于实时场景。因此，需要一种能够兼顾全局上下文建模和实时性的轻量级网络。

Method: 提出了一种新的端到端轻量级网络结构，该结构包含一个类似Swin Transformer的编码器和一个类似U-Net的解码器，并通过跳跃连接（skip pathways）进行连接。编码器首先使用Barlow Twins自监督学习方法进行预训练，然后对整个模型进行微调。

Result: 在标准的二值分割任务的实验中，该模型在显著减少参数数量和提高推理速度的同时，达到了具有竞争力的准确性。

Conclusion: 所提出的轻量级模型在实时性和资源受限的临床环境中具有实际应用价值，能够满足实时医学图像二值分割的需求。

Abstract: Medical image segmentation is a critical task in clinical workflows,
particularly for the detection and delineation of pathological regions. While
convolutional architectures like U-Net have become standard for such tasks,
their limited receptive field restricts global context modeling. Recent efforts
integrating transformers have addressed this, but often result in deep,
computationally expensive models unsuitable for real-time use. In this work, we
present a novel end-to-end lightweight architecture designed specifically for
real-time binary medical image segmentation. Our model combines a Swin
Transformer-like encoder with a U-Net-like decoder, connected via skip pathways
to preserve spatial detail while capturing contextual information. Unlike
existing designs such as Swin Transformer or U-Net, our architecture is
significantly shallower and competitively efficient. To improve the encoder's
ability to learn meaningful features without relying on large amounts of
labeled data, we first train it using Barlow Twins, a self-supervised learning
method that helps the model focus on important patterns by reducing unnecessary
repetition in the learned features. After this pretraining, we fine-tune the
entire model for our specific task. Experiments on benchmark binary
segmentation tasks demonstrate that our model achieves competitive accuracy
with substantially reduced parameter count and faster inference, positioning it
as a practical alternative for deployment in real-time and resource-limited
clinical environments. The code for our method is available at Github
repository: https://github.com/mkianih/Barlow-Swin.

</details>


### [160] [Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization](https://arxiv.org/abs/2509.06890)
*Minheng Chen,Youyong Kong*

Main category: cs.CV

TL;DR: 本文提出一种在非欧几里得球形特征空间中进行相似性学习的方法，以提高术中2D/3D配准的准确性和收敛速度，并取得了优于现有方法的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于欧氏空间的相似性学习方法会扭曲流形结构并减慢收敛速度，限制了配准的性能。

Method: 本文提出一种在非欧几里得球形特征空间中进行相似性学习的方法。利用CNN-Transformer编码器提取特征嵌入，将其投影到球形空间，并在双不变SO(4)空间中用黎曼距离近似其测地线距离。在推理时，使用全微分的Levenberg-Marquardt优化来加速收敛。

Result: 在真实和合成数据集上的实验表明，该方法在患者特定和患者无关的场景中都具有更高的准确性。

Conclusion: 本文提出的在非欧几里得球形特征空间中进行相似性学习的方法，能够更好地捕捉和拟合复杂的流形结构，提供更具表现力和几何一致性的深度相似性度量，从而提高配准的准确性和收敛速度。

Abstract: Intraoperative 2D/3D registration aligns preoperative 3D volumes with
real-time 2D radiographs, enabling accurate localization of instruments and
implants. A recent fully differentiable similarity learning framework
approximates geodesic distances on SE(3), expanding the capture range of
registration and mitigating the effects of substantial disturbances, but
existing Euclidean approximations distort manifold structure and slow
convergence. To address these limitations, we explore similarity learning in
non-Euclidean spherical feature spaces to better capture and fit complex
manifold structure. We extract feature embeddings using a CNN-Transformer
encoder, project them into spherical space, and approximate their geodesic
distances with Riemannian distances in the bi-invariant SO(4) space. This
enables a more expressive and geometrically consistent deep similarity metric,
enhancing the ability to distinguish subtle pose differences. During inference,
we replace gradient descent with fully differentiable Levenberg-Marquardt
optimization to accelerate convergence. Experiments on real and synthetic
datasets show superior accuracy in both patient-specific and patient-agnostic
scenarios.

</details>


### [161] [BIR-Adapter: A Low-Complexity Diffusion Model Adapter for Blind Image Restoration](https://arxiv.org/abs/2509.06904)
*Cem Eteke,Alexander Griessel,Wolfgang Kellerer,Eckehard Steinbach*

Main category: cs.CV

TL;DR: BIR-Adapter是一个低复杂度的盲图像恢复适配器，可用于扩散模型，无需训练额外的特征提取器，并能减少幻觉，在合成和真实世界退化下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在盲图像恢复任务中利用预训练的扩散模型的先验知识，同时避免训练额外的特征提取器，并解决幻觉问题。

Method: 通过扩散模型自身提取退化图像的特征，并利用这些特征扩展自注意力机制，引入采样引导机制来减少幻觉。

Result: BIR-Adapter在合成和真实世界退化方面取得了具有竞争力或更好的性能，同时复杂度显著降低。它还可以集成到其他扩散模型中，用于更广泛的图像恢复任务，例如将超分辨率模型扩展到处理额外的未知退化。

Conclusion: BIR-Adapter是一种有效且高效的盲图像恢复方法，可利用预训练扩散模型的先验知识，并具有良好的通用性。

Abstract: This paper introduces BIR-Adapter, a low-complexity blind image restoration
adapter for diffusion models. The BIR-Adapter enables the utilization of the
prior of pre-trained large-scale diffusion models on blind image restoration
without training any auxiliary feature extractor. We take advantage of the
robustness of pretrained models. We extract features from degraded images via
the model itself and extend the self-attention mechanism with these degraded
features. We introduce a sampling guidance mechanism to reduce hallucinations.
We perform experiments on synthetic and real-world degradations and demonstrate
that BIR-Adapter achieves competitive or better performance compared to
state-of-the-art methods while having significantly lower complexity.
Additionally, its adapter-based design enables integration into other diffusion
models, enabling broader applications in image restoration tasks. We showcase
this by extending a super-resolution-only model to perform better under
additional unknown degradations.

</details>


### [162] [FoMo4Wheat: Toward reliable crop vision foundation models with globally curated data](https://arxiv.org/abs/2509.06907)
*Bing Han,Chen Zhu,Dong Han,Rui Yu,Songliang Cao,Jianhui Wu,Scott Chapman,Zijian Wang,Bangyou Zheng,Wei Guo,Marie Weiss,Benoit de Solan,Andreas Hund,Lukas Roth,Kirchgessner Norbert,Andrea Visioni,Yufeng Ge,Wenjuan Li,Alexis Comar,Dong Jiang,Dejun Han,Fred Baret,Yanfeng Ding,Hao Lu,Shouyang Liu*

Main category: cs.CV

TL;DR: FoMo4Wheat是一个针对小麦设计的视觉基础模型，通过自我监督学习在250万张图像的小麦数据集ImAg4Wheat上进行预训练，表现出对小麦及其他作物和杂草的鲁棒性和迁移性，并在多项田间视觉任务中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 通用领域预训练模型在数字农业中应用于田间监控时，由于作物冠层结构的精细多变和环境条件的波动，往往在跨任务泛化能力上表现不佳。

Method: 提出FoMo4Wheat，一个在ImAg4Wheat（包含250万张高分辨率小麦图像）上通过自监督学习进行预训练的，专门针对作物领域（尤其是小麦）的视觉基础模型。

Result: FoMo4Wheat模型在10项不同作物（包括小麦、其他作物和杂草）的田间视觉任务（涵盖冠层和器官层面）中，性能持续优于使用通用领域数据集预训练的现有最先进模型。

Conclusion: 该研究证明了特定作物基础模型在可靠的田间感知方面的价值，并为实现具有跨物种和跨任务能力的通用作物基础模型指明了方向。

Abstract: Vision-driven field monitoring is central to digital agriculture, yet models
built on general-domain pretrained backbones often fail to generalize across
tasks, owing to the interaction of fine, variable canopy structures with
fluctuating field conditions. We present FoMo4Wheat, one of the first
crop-domain vision foundation model pretrained with self-supervision on
ImAg4Wheat, the largest and most diverse wheat image dataset to date (2.5
million high-resolution images collected over a decade at 30 global sites,
spanning >2,000 genotypes and >500 environmental conditions). This
wheat-specific pretraining yields representations that are robust for wheat and
transferable to other crops and weeds. Across ten in-field vision tasks at
canopy and organ levels, FoMo4Wheat models consistently outperform
state-of-the-art models pretrained on general-domain dataset. These results
demonstrate the value of crop-specific foundation models for reliable in-field
perception and chart a path toward a universal crop foundation model with
cross-species and cross-task capabilities. FoMo4Wheat models and the ImAg4Wheat
dataset are publicly available online: https://github.com/PheniX-Lab/FoMo4Wheat
and https://huggingface.co/PheniX-Lab/FoMo4Wheat. The demonstration website is:
https://fomo4wheat.phenix-lab.com/.

</details>


### [163] [H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers](https://arxiv.org/abs/2509.06956)
*Wenhao Li,Mengyuan Liu,Hong Liu,Pichao Wang,Shijian Lu,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出了一种名为H$_{2}$OT的分层即插即用剪枝恢复框架，用于高效的视频三维人体姿态估计，通过剪枝和恢复姿态令牌来提高模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有的视频人体姿态估计方法计算成本高，在资源受限设备上不实用。

Method: H$_{2}$OT框架包含令牌剪枝模块（TPM）和令牌恢复模块（TRM）。TPM选择代表性令牌以消除冗余，TRM根据选定的令牌恢复信息，将输出扩展到原始时间分辨率。

Result: 该方法可以轻松集成到现有的VPT模型中，并在多个基准数据集上证明了其有效性和效率。

Conclusion: H$_{2}$OT表明，并非必须维持完整姿态序列，少数代表性帧的姿态令牌即可实现高效率和高精度。

Abstract: Transformers have been successfully applied in the field of video-based 3D
human pose estimation. However, the high computational costs of these video
pose transformers (VPTs) make them impractical on resource-constrained devices.
In this paper, we present a hierarchical plug-and-play pruning-and-recovering
framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient
transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with
progressively pruning pose tokens of redundant frames and ends with recovering
full-length sequences, resulting in a few pose tokens in the intermediate
transformer blocks and thus improving the model efficiency. It works with two
key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module
(TRM). TPM dynamically selects a few representative tokens to eliminate the
redundancy of video frames, while TRM restores the detailed spatio-temporal
information based on the selected tokens, thereby expanding the network output
to the original full-length temporal resolution for fast inference. Our method
is general-purpose: it can be easily incorporated into common VPT models on
both seq2seq and seq2frame pipelines while effectively accommodating different
token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that
maintaining the full pose sequence is unnecessary, and a few pose tokens of
representative frames can achieve both high efficiency and estimation accuracy.
Extensive experiments on multiple benchmark datasets demonstrate both the
effectiveness and efficiency of the proposed method. Code and models are
available at https://github.com/NationalGAILab/HoT.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [164] [Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate](https://arxiv.org/abs/2509.05396)
*Andrea Wynn,Harsh Satija,Gillian Hadfield*

Main category: cs.CL

TL;DR: 在多智能体辩论中，模型能力的多样性可能会导致准确性下降，因为模型倾向于认同错误但有说服力的论点，而不是挑战它们。


<details>
  <summary>Details</summary>
Motivation: 以往的研究主要集中在同质智能体群体的辩论，而本研究旨在探讨模型能力的多样性如何影响多智能体交互的动态和结果。

Method: 通过一系列实验，研究模型能力多样性对多智能体辩论的影响。

Result: 研究发现，即使在能力更强的模型数量占优的情况下，辩论也可能随着时间的推移导致准确性下降。模型频繁地从正确答案转向错误答案，倾向于认同而非质疑错误的论点。

Conclusion: 多智能体辩论的简单应用可能导致性能下降，尤其是在智能体既没有动力也没有充分能力来抵抗有说服力但错误的推理时。这揭示了多智能体辩论中推理交换方面的重要失效模式。

Abstract: While multi-agent debate has been proposed as a promising strategy for
improving AI reasoning ability, we find that debate can sometimes be harmful
rather than helpful. The prior work has exclusively focused on debates within
homogeneous groups of agents, whereas we explore how diversity in model
capabilities influences the dynamics and outcomes of multi-agent interactions.
Through a series of experiments, we demonstrate that debate can lead to a
decrease in accuracy over time -- even in settings where stronger (i.e., more
capable) models outnumber their weaker counterparts. Our analysis reveals that
models frequently shift from correct to incorrect answers in response to peer
reasoning, favoring agreement over challenging flawed reasoning. These results
highlight important failure modes in the exchange of reasons during multi-agent
debate, suggesting that naive applications of debate may cause performance
degradation when agents are neither incentivized nor adequately equipped to
resist persuasive but incorrect reasoning.

</details>


### [165] [An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training](https://arxiv.org/abs/2509.05359)
*Yanis Labrak,Richard Dufour,Mickaël Rouvier*

Main category: cs.CL

TL;DR: 本研究探讨了语音语言模型（SLM）中离散单元表征，并关注在持续预训练过程中优化语音建模。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统地研究模型架构、数据表征和训练鲁棒性如何影响将现有预训练语言模型适配到语音模态的预训练阶段。

Method: 通过实验考察了不同规模模型下语音编码器和聚类粒度在离散化策略中的作用，并分析了聚类分布和语音对齐，以探究离散词汇的有效利用，并揭示语言和副语言模式。此外，研究还探讨了聚类数据选择对模型鲁棒性的影响。

Result: 实验表明，最优的离散化策略随模型容量而变化。研究揭示了离散词汇的有效利用，并发现了语言和副语言模式。

Conclusion: 聚类数据选择对模型鲁棒性的影响凸显了离散化训练与目标应用之间领域匹配的重要性。

Abstract: This paper investigates discrete unit representations in Speech Language
Models (SLMs), focusing on optimizing speech modeling during continual
pre-training. In this paper, we systematically examine how model architecture,
data representation, and training robustness influence the pre-training stage
in which we adapt existing pre-trained language models to the speech modality.
Our experiments highlight the role of speech encoders and clustering
granularity across different model scales, showing how optimal discretization
strategies vary with model capacity. By examining cluster distribution and
phonemic alignments, we investigate the effective use of discrete vocabulary,
uncovering both linguistic and paralinguistic patterns. Additionally, we
explore the impact of clustering data selection on model robustness,
highlighting the importance of domain matching between discretization training
and target applications.

</details>


### [166] [Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection](https://arxiv.org/abs/2509.05360)
*Jerry Li,Evangelos Papalexakis*

Main category: cs.CL

TL;DR: LLMs 容易产生幻觉，现有检测方法依赖的传统指标（如 ROUGE、BERTScore）缺乏语义深度。本文提出一种基于 N-Gram 频率张量的新方法，通过张量分解提取特征训练 MLP 分类器来检测幻觉，在 HaluEval 数据集上表现优于传统基线，并与最先进的 LLM 法官模型相当。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 幻觉检测方法依赖的传统指标（如 ROUGE、BERTScore、困惑度）缺乏足够的语义深度来有效检测幻觉。

Method: 提出一种受 ROUGE 启发的 N-Gram 频率张量方法，通过张量分解提取奇异值作为特征，训练一个多层感知器（MLP）二元分类器来检测幻觉。

Result: 所提出的方法在 HaluEval 数据集上进行了评估，与传统基线相比显示出显著的改进，并且在与最先进的 LLM 法官的竞争中表现良好。

Conclusion: 基于 N-Gram 频率张量的方法能够比传统指标更有效地检测 LLM 幻觉，并且在性能上可以与最先进的 LLM 法官模型相媲美。

Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide
variety of tasks involving natural language, however, a fundamental problem of
hallucinations still plagues these models, limiting their trustworthiness in
generating consistent, truthful information. Detecting hallucinations has
quickly become an important topic, with various methods such as uncertainty
estimation, LLM Judges, retrieval augmented generation (RAG), and consistency
checks showing promise. Many of these methods build upon foundational metrics,
such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth
necessary to detect hallucinations effectively. In this work, we propose a
novel approach inspired by ROUGE that constructs an N-Gram frequency tensor
from LLM-generated text. This tensor captures richer semantic structure by
encoding co-occurrence patterns, enabling better differentiation between
factual and hallucinated content. We demonstrate this by applying tensor
decomposition methods to extract singular values from each mode and use these
as input features to train a multi-layer perceptron (MLP) binary classifier for
hallucinations. Our method is evaluated on the HaluEval dataset and
demonstrates significant improvements over traditional baselines, as well as
competitive performance against state-of-the-art LLM judges.

</details>


### [167] [A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs](https://arxiv.org/abs/2509.05385)
*Jiacheng Wei,Faguo Wu,Xiao Zhang*

Main category: cs.CL

TL;DR: 大型语言模型在推理时无法从新数据中持续学习，SAGE通过将复杂推理分解为原子子任务，并利用触发器指导的动态微调框架，在推理时进行自适应更新，从而解决了这一问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时缺乏持续自适应和从新数据中学习的能力。

Method: 提出SAGE框架，将复杂推理分解为原子子任务。SAGE包含三个组件：(1) 触发器模块：实时检测推理失败；(2) 触发器缓冲区模块：使用HDBSCAN流式聚类异常样本，并进行稳定性检查和相似性合并；(3) Lora存储模块：通过适配器池优化参数更新，实现知识保留。

Result: SAGE在原子推理子任务上，通过测试时的动态知识更新，展现出优异的准确性、鲁棒性和稳定性。

Conclusion: SAGE框架能够有效地使大型语言模型在推理时进行自适应学习和更新，提升了推理任务的性能。

Abstract: Large language models are unable to continuously adapt and learn from new
data during reasoning at inference time. To address this limitation, we propose
that complex reasoning tasks be decomposed into atomic subtasks and introduce
SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive
updates during reasoning at inference time. SAGE consists of three key
components: (1) a Trigger module that detects reasoning failures through
multiple evaluation metrics in real time; (2) a Trigger Buffer module that
clusters anomaly samples using a streaming clustering process with HDBSCAN,
followed by stability checks and similarity-based merging; and (3) a Lora Store
module that dynamically optimizes parameter updates with an adapter pool for
knowledge retention. Evaluation results show that SAGE demonstrates excellent
accuracy, robustness, and stability on the atomic reasoning subtask through
dynamic knowledge updating during test time.

</details>


### [168] [No Translation Needed: Forecasting Quality from Fertility and Metadata](https://arxiv.org/abs/2509.05425)
*Jessica M. Lundin,Ada Zhang,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 翻译质量可以通过语言学特征预测，无需运行翻译系统。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需实际运行翻译系统即可准确预测翻译质量的方法。

Method: 使用语言家族、语言类型、词元生育率和词元计数等特征，结合梯度提升模型进行预测。

Result: 在FLORES-200基准测试中，对于XX->英语的预测$R^{2}=0.66$，对于英语->XX的预测$R^{2}=0.72$。发现语言类型特征对预测英语质量影响更大，而词元生育率对预测多样化目标语言质量影响更大。

Conclusion: 翻译质量受词元级别生育率和更广泛的语言类型学因素共同影响，为多语言评估和质量估计提供了新思路。

Abstract: We show that translation quality can be predicted with surprising accuracy
\textit{without ever running the translation system itself}. Using only a
handful of features, token fertility ratios, token counts, and basic linguistic
metadata (language family, script, and region), we can forecast ChrF scores for
GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient
boosting models achieve favorable performance ($R^{2}=0.66$ for
XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature
importance analyses reveal that typological factors dominate predictions into
English, while fertility plays a larger role for translations into diverse
target languages. These findings suggest that translation quality is shaped by
both token-level fertility and broader linguistic typology, offering new
insights for multilingual evaluation and quality estimation.

</details>


### [169] [Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too](https://arxiv.org/abs/2509.05440)
*Logan Lawrence,Ashton Williamson,Alexander Shelton*

Main category: cs.CL

TL;DR: LLM作为自动评分者评估自由格式内容时，现有的配对比较方法在样本级别上表现良好，但无法分配绝对分数。本研究提出了一种直接评分方法，利用合成摘要作为测试时的配对机器排名，其在SummEval、TopicalChat和HANNA等基准测试中与最先进的配对评估方法表现相当。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型作为自由格式内容（如文档摘要、对话和故事生成）的自动评分者，并解决现有方法在分配绝对分数方面的局限性。

Method: 提出了一种直接评分方法，利用合成摘要作为测试时的配对机器排名。

Result: 在SummEval、TopicalChat和HANNA的元评估基准测试中，该方法在平均样本级别相关性方面与最先进的配对评估方法表现相当（+0.03, -0.03, +0.05）。

Conclusion: 提出的直接评分方法在评估LLM生成的文本时，在样本级别相关性方面能与最先进的配对方法相媲美，并为未来研究提供了合成数据。

Abstract: As large-language models have been increasingly used as automatic raters for
evaluating free-form content, including document summarization, dialog, and
story generation, work has been dedicated to evaluating such models by
measuring their correlations with human judgment. For \textit{sample-level}
performance, methods which operate by using pairwise comparisons between
machine-generated text perform well but often lack the ability to assign
absolute scores to individual summaries, an ability crucial for use cases that
require thresholding. In this work, we propose a direct-scoring method which
uses synthetic summaries to act as pairwise machine rankings at test time. We
show that our method performs comparably to state-of-the-art pairwise
evaluators in terms of axis-averaged sample-level correlations on the SummEval
(\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05})
meta-evaluation benchmarks, and release the synthetic in-context summaries as
data to facilitate future work.

</details>


### [170] [From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics](https://arxiv.org/abs/2509.05484)
*Hajar Sakai,Yi-En Tseng,Mohammadsadegh Mikaeili,Joshua Bosire,Franziska Jovin*

Main category: cs.CL

TL;DR: 该研究提出了一种基于大语言模型（LLM）的框架，用于识别医院呼叫中心工作人员消息的主题和分类原因，旨在提高数据利用率和患者体验。


<details>
  <summary>Details</summary>
Motivation: 医院呼叫中心产生大量工作人员消息文本数据，传统监督学习方法在处理此类数据时效率低下，需要大量标注数据、训练和调优。LLM的出现为更高效的医疗分析提供了新的途径。

Method: 提出一个多阶段LLM框架，利用不同类型的LLM（推理型、通用型、轻量型）来识别消息主题和进行多分类。框架还整合了数据安全和HIPAA合规性措施，并将LLM输出集成到可视化决策支持工具中。

Result: 在评估的多种LLM中，o3模型表现最佳，加权F1分数达到78.4%，准确率为79.2%。gpt-5模型紧随其后，加权F1分数和准确率分别为75.3%和76.2%。

Conclusion: 该LLM框架能够有效处理医院呼叫中心的消息数据，识别导航员培训机会，并支持改善患者体验和护理质量。通过将LLM输出集成到可视化工具中，可以将工作人员消息转化为可操作的见解，从而更有效地利用收集到的数据。

Abstract: Hospital call centers serve as the primary contact point for patients within
a hospital system. They also generate substantial volumes of staff messages as
navigators process patient requests and communicate with the hospital offices
following the established protocol restrictions and guidelines. This
continuously accumulated large amount of text data can be mined and processed
to retrieve insights; however, traditional supervised learning approaches
require annotated data, extensive training, and model tuning. Large Language
Models (LLMs) offer a paradigm shift toward more computationally efficient
methodologies for healthcare analytics. This paper presents a multi-stage
LLM-based framework that identifies staff message topics and classifies
messages by their reasons in a multi-class fashion. In the process, multiple
LLM types, including reasoning, general-purpose, and lightweight models, were
evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score
and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and
76.2% accuracy). The proposed methodology incorporates data security measures
and HIPAA compliance requirements essential for healthcare environments. The
processed LLM outputs are integrated into a visualization decision support tool
that transforms the staff messages into actionable insights accessible to
healthcare professionals. This approach enables more efficient utilization of
the collected staff messaging data, identifies navigator training
opportunities, and supports improved patient experience and care quality.

</details>


### [171] [The Token Tax: Systematic Bias in Multilingual Tokenization](https://arxiv.org/abs/2509.05486)
*Jessica M. Lundin,Ada Zhang,Nihal Karim,Hamza Louzan,Victor Wei,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 分词效率低下给形态复杂的低资源语言带来了结构性劣势，增加了计算资源并降低了准确性。我们评估了 10 种大型语言模型（LLM）在 AfriMMLU（9,000 个 MCQA 项目；5 个科目；16 种非洲语言）上的表现，并表明生育率（tokens/word）能够可靠地预测准确性。在所有模型和科目中，较高的生育率始终预示着较低的准确性。我们进一步发现，在 AfriMMLU 数据集上，推理模型（DeepSeek, o1）在资源丰富和资源匮乏的语言方面始终优于非推理模型，缩小了先前几代模型中观察到的准确性差距。最后，将代币膨胀转化为经济学，代币数量加倍导致培训成本和时间增加四倍，这凸显了许多语言面临的代币税。这些结果促使人们对形态感知分词、公平定价和多语言基准进行公平的自然语言处理（NLP）。


<details>
  <summary>Details</summary>
Motivation: 分词效率低下给形态复杂的低资源语言带来了结构性劣势，增加了计算资源并降低了准确性。

Method: 评估了 10 种大型语言模型（LLM）在 AfriMMLU（9,000 个 MCQA 项目；5 个科目；16 种非洲语言）上的表现，并表明生育率（tokens/word）能够可靠地预测准确性。

Result: 在所有模型和科目中，较高的生育率始终预示着较低的准确性。在 AfriMMLU 数据集上，推理模型（DeepSeek, o1）在资源丰富和资源匮乏的语言方面始终优于非推理模型，缩小了先前几代模型中观察到的准确性差距。代币数量加倍导致培训成本和时间增加四倍，这凸显了许多语言面临的代币税。

Conclusion: 这些结果促使人们对形态感知分词、公平定价和多语言基准进行公平的自然语言处理（NLP）。

Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically
complex, low-resource languages, inflating compute resources and depressing
accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA
items; 5 subjects; 16 African languages) and show that fertility (tokens/word)
reliably predicts accuracy. Higher fertility consistently predicts lower
accuracy across all models and subjects. We further find that reasoning models
(DeepSeek, o1) consistently outperform non-reasoning peers across high and low
resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in
prior generations. Finally, translating token inflation to economics, a
doubling in tokens results in quadrupled training cost and time, underscoring
the token tax faced by many languages. These results motivate morphologically
aware tokenization, fair pricing, and multilingual benchmarks for equitable
natural language processing (NLP).

</details>


### [172] [Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2509.05505)
*Mansi Garg,Lee-Chi Wang,Bhavesh Ghanchi,Sanjana Dumpala,Shreyash Kakde,Yen Chih Chen*

Main category: cs.CL

TL;DR: 本研究提出一个基于检索增强生成（RAG）架构的生物医学文献问答系统，以提高对准确、循证医学信息的访问。该系统整合了PubMed文章、精选问答数据集和医学百科全书等多种来源，以检索相关信息并生成简洁、上下文感知的回答。本研究旨在解决传统健康搜索引擎的不足以及公众获取生物医学研究的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统健康搜索引擎的局限性以及公众获取生物医学研究的滞后性问题，本研究旨在改进生物医学文献问答的准确性和可及性。

Method: 本系统采用检索增强生成（RAG）架构。检索部分利用MiniLM进行语义嵌入，并结合FAISS进行向量搜索。生成部分则使用经过QLoRA优化的Mistral-7B-v0.3语言模型进行回答生成，以实现高效、低资源的训练。该系统整合了PubMed文章、问答数据集和医学百科全书等多种来源。

Result: 在乳腺癌文献领域的评估中，与基线模型相比，本系统在事实一致性和语义相关性方面取得了显著的改进，使用BERTScore（F1）进行衡量。

Conclusion: 本研究证明了RAG增强的语言模型在连接复杂生物医学文献与易于理解的公众健康知识方面的潜力，为未来开发多语言适应、隐私保护推理和个性化医疗AI系统奠定了基础。

Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system
based on a Retrieval-Augmented Generation (RAG) architecture, designed to
improve access to accurate, evidence-based medical information. Addressing the
shortcomings of conventional health search engines and the lag in public access
to biomedical research, the system integrates diverse sources, including PubMed
articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant
information and generate concise, context-aware responses. The retrieval
pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while
answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model
optimized using QLoRA for efficient, low-resource training. The system supports
both general medical queries and domain-specific tasks, with a focused
evaluation on breast cancer literature demonstrating the value of
domain-aligned retrieval. Empirical results, measured using BERTScore (F1),
show substantial improvements in factual consistency and semantic relevance
compared to baseline models. The findings underscore the potential of
RAG-enhanced language models to bridge the gap between complex biomedical
literature and accessible public health knowledge, paving the way for future
work on multilingual adaptation, privacy-preserving inference, and personalized
medical AI systems.

</details>


### [173] [Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study](https://arxiv.org/abs/2509.05553)
*Serge Lionel Nikiema,Jordan Samhi,Micheline Bénédicte Moumoula,Albérick Euraste Djiré,Abdoul Kader Kaboré,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）是否真正理解概念或仅仅识别模式尚不清楚。研究人员提出双向推理（bidirectional reasoning）作为衡量真正理解的标准，并开发了一种名为对比细调（Contrastive Fine-Tuning, CFT）的新方法来提高模型的双向推理能力。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型是否真正理解概念，而不仅仅是识别模式，并提出一种提高模型理解能力的方法。

Method: 提出“双向推理”（bidirectional reasoning）作为测试模型理解能力的标准，即模型能否在不显式训练反向任务的情况下执行反向推理。发现现有模型存在“认知专业化”现象：正向任务的微调会损害反向推理能力。开发了对比细调（CFT）方法，通过正例、负例和前向混淆例进行训练，以培养深度理解和自然的反向推理能力。

Result: 实验证明，CFT 方法成功实现了双向推理，在保持前向任务能力的同时，显著提高了反向推理性能。

Conclusion: 双向推理是评估和培养人工智能真正理解能力的理论框架和实践方法。

Abstract: This research addresses a fundamental question in AI: whether large language
models truly understand concepts or simply recognize patterns. The authors
propose bidirectional reasoning,the ability to apply transformations in both
directions without being explicitly trained on the reverse direction, as a test
for genuine understanding. They argue that true comprehension should naturally
allow reversibility. For example, a model that can change a variable name like
userIndex to i should also be able to infer that i represents a user index
without reverse training. The researchers tested current language models and
discovered what they term cognitive specialization: when models are fine-tuned
on forward tasks, their performance on those tasks improves, but their ability
to reason bidirectionally becomes significantly worse. To address this issue,
they developed Contrastive Fine-Tuning (CFT), which trains models using three
types of examples: positive examples that maintain semantic meaning, negative
examples with different semantics, and forward-direction obfuscation examples.
This approach aims to develop deeper understanding rather than surface-level
pattern recognition and allows reverse capabilities to develop naturally
without explicit reverse training. Their experiments demonstrated that CFT
successfully achieved bidirectional reasoning, enabling strong reverse
performance while maintaining forward task capabilities. The authors conclude
that bidirectional reasoning serves both as a theoretical framework for
assessing genuine understanding and as a practical training approach for
developing more capable AI systems.

</details>


### [174] [Ad hoc conventions generalize to new referents](https://arxiv.org/abs/2509.05566)
*Anya Ji,Claire Augusta Bergey,Ron Eliav,Yoav Artzi,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 人们在交流中会建立起对新事物的共同指称方式，这种方式并非任意的标签，而是通过概念的协调来泛化到新的指称对象。


<details>
  <summary>Details</summary>
Motivation: 探讨在交流中，人们如何为以前从未交流过的事物建立共同的指称系统，以及这种系统的形成是基于任意的标签还是更广泛的概念协调。

Method: 通过一个包含302名参与者的双向沟通实验，利用KiloGram数据集中的抽象图形（tangram）来研究这一现象。实验让参与者配对，通过重复沟通来就一组图像的指称达成一致，然后测量他们在未讨论过的图像上的描述一致性。

Result: 研究结果显示，参与者在未讨论过的图像上的描述一致性有所提高，证明了指称方式的泛化能力。这种泛化能力随图像视觉相似度的非线性增加（符合Shepard定律）而衰减，并且在不同可命名性水平的图像上都表现稳健。

Conclusion: 研究结果表明，交流中形成的临时性规范并非任意标签，而是真实概念协调的体现，这对指称理论和设计更具适应性的语言代理具有启示意义。

Abstract: How do people talk about things they've never talked about before? One view
suggests that a new shared naming system establishes an arbitrary link to a
specific target, like proper names that cannot extend beyond their bearers. An
alternative view proposes that forming a shared way of describing objects
involves broader conceptual alignment, reshaping each individual's semantic
space in ways that should generalize to new referents. We test these competing
accounts in a dyadic communication study (N=302) leveraging the
recently-released KiloGram dataset containing over 1,000 abstract tangram
images. After pairs of participants coordinated on referential conventions for
one set of images through repeated communication, we measured the extent to
which their descriptions aligned for undiscussed images. We found strong
evidence for generalization: partners showed increased alignment relative to
their pre-test labels. Generalization also decayed nonlinearly with visual
similarity (consistent with Shepard's law) and was robust across levels of the
images' nameability. These findings suggest that ad hoc conventions are not
arbitrary labels but reflect genuine conceptual coordination, with implications
for theories of reference and the design of more adaptive language agents.

</details>


### [175] [Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation](https://arxiv.org/abs/2509.05602)
*Hongyan Xie,Yitong Yao,Yikun Ban,Zixuan Huang,Deqing Wang,Zhenhe Wu,Haoxiang Su,Chao Wang,Shuangyong Song,Xuelong Li*

Main category: cs.CL

TL;DR: CoPeD通过引入正确性感知任务设置和加权损失来提高小语言模型在推理任务中的能力，解决了大语言模型生成的思维链数据中的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 微调小型语言模型（SLM）以复制大型语言模型（LLM）的推理能力，但LLM生成的思维链（CoT）数据可能包含噪声，导致SLM学习到错误的关联，损害推理质量。

Method: 提出了一种名为CoPeD（Chain-of-Thought Correctness Perception Distillation）的方法。该方法包括两个主要部分：1. 正确性感知任务设置：鼓励学生模型基于正确的推理来预测答案，并在推理不正确时进行修正。2. 正确性感知加权损失：根据推理和答案的组合损失动态调整每个训练实例的权重，使模型更关注那些推理能为正确答案提供更强支持的样本。

Result: CoPeD在标准推理基准数据集的分布内（IND）和分布外（OOD）测试中都证明了其有效性。

Conclusion: CoPeD能够有效提高SLM的推理质量，解决了LLM生成的CoT数据中的噪声问题，并提高了模型在各种推理任务中的表现。

Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to
deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated
by LLMs to copy LLMs' abilities. However, these CoT data may include noisy
rationales that either fail to substantiate the answers or contribute no
additional information to support answer prediction, which leads SLMs to
capture spurious correlations between questions and answers and compromise the
quality of reasoning. In this work, we propose Chain-of-Thought Correctness
Perception Distillation (CoPeD), which aims to improve the reasoning quality of
the student model from the perspectives of task setting and data utilization.
Firstly, we introduce a correctness-aware task setting that encourages the
student model to predict answers based on correct rationales and revise them
when they are incorrect. This setting improves the faithfulness of reasoning
and allows the model to learn from its mistakes. Then, we propose a
Correctness-Aware Weighted loss, which dynamically adjusts the contribution of
each training instance based on the combined loss of the rationale and the
answer. This strategy encourages the model to focus more on samples where the
rationale offers stronger support for the correct answer. Experiments have
shown that CoPeD is effective on both in-distribution (IND) and
out-of-distribution (OOD) benchmark reasoning datasets.

</details>


### [176] [Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation](https://arxiv.org/abs/2509.05605)
*Qiyuan Chen,Hongsen Huang,Qian Shao,Jiahe Chen,Jintai Chen,Hongxia Xu,Renjie Hua,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 利用LLM的内在表征空间来构建高效、定制化的人类偏好数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法构建偏好数据集存在分布不匹配和计算开销大的问题。

Method: 提出Icon$^{2}$，通过提取层级方向向量编码人类偏好，并过滤自生成的指令；在解码时，采用双向内在控制来引导token表征，生成具有明显对齐差异的响应对。

Result: 在AlpacaEval 2.0和Arena-Hard上，Llama3-8B和Qwen2-7B的平均胜率分别提高了13.89%和13.45%，计算成本降低了48.1%。

Conclusion: Icon$^{2}$在提高LLM对齐度和效率方面取得了显著成效。

Abstract: Large Language Models (LLMs) require high quality preference datasets to
align with human preferences. However, conventional methods for constructing
such datasets face significant challenges: reliance on pre-collected
instructions often leads to distribution mismatches with target models, while
the need for sampling multiple stochastic responses introduces substantial
computational overhead. In this work, we explore a paradigm shift by leveraging
inherent regulation of LLMs' representation space for efficient and tailored
preference dataset construction, named Icon$^{2}$. Specifically, it first
extracts layer-wise direction vectors to encode sophisticated human preferences
and then uses these vectors to filter self-synthesized instructions based on
their inherent consistency. During decoding, bidirectional inherent control is
applied to steer token representations, enabling the precise generation of
response pairs with clear alignment distinctions. Experimental results
demonstrate significant improvements in both alignment and efficiency.
Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on
AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by
up to 48.1%.

</details>


### [177] [Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents](https://arxiv.org/abs/2509.05607)
*Qiyuan Chen,Jiahe Chen,Hongsen Huang,Qian Shao,Jintai Chen,Renjie Hua,Hongxia Xu,Ruijia Wu,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 生成式搜索引擎优化（GSEO）框架，用于衡量和优化内容在合成答案中的影响力。


<details>
  <summary>Details</summary>
Motivation: 传统搜索引擎优化（SEO）指标在生成式搜索引擎中已过时，需要新的方法来理解和优化内容对合成答案的影响力。

Method: 构建了一个名为CC-GSEO-Bench的大规模、以内容为中心的基准，并提出了一个多维度的评估框架，然后设计了一个多智能体系统来实现该框架，通过分析-修改-评估的工作流程自动优化内容。

Result: 通过该框架进行的实证分析揭示了内容影响力的动态新见解，为内容创作者提供了可行的策略。

Conclusion: 提出了一个用于生成式搜索优化的端到端框架，包括基准、评估方法和自动化优化系统，为未来的GSEO研究奠定了基础。

Abstract: The paradigm shift from traditional ranked-based search to Generative Search
Engines has rendered conventional SEO metrics obsolete, creating an urgent need
to understand, measure, and optimize for content influence on synthesized
answers. This paper introduces a comprehensive, end-to-end framework for
Generative Search Engine Optimization (GSEO) to address this challenge. We make
two primary contributions. First, we construct CC-GSEO-Bench, a large-scale,
content-centric benchmark, and propose a multi-dimensional evaluation framework
that systematically quantifies influence, moving beyond surface-level
attribution to assess substantive semantic impact. Second, we design a novel
multi-agent system that operationalizes this framework, automating the
strategic refinement of content through a collaborative analyze-revise-evaluate
workflow. Our empirical analysis using this framework reveals novel insights
into the dynamics of content influence, offering actionable strategies for
creators and establishing a principled foundation for future GSEO research.

</details>


### [178] [New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](https://arxiv.org/abs/2509.05609)
*Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai*

Main category: cs.CL

TL;DR: 本文提出一种基于非均衡最优传输的对齐模型，将声学和语言表征的对齐与匹配视为一个检测问题，以解决语音识别中声学-语言对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 在自动语音识别（ASR）中，对齐声学和语言表征以实现知识迁移是一个核心挑战，需要处理多对一、一对多以及冗余或噪声的声学帧等复杂情况。

Method: 提出一种基于非均衡最优传输的对齐模型，该模型明确处理了声学和语言模态之间的分布不匹配和结构不对称性，实现了软性匹配和部分匹配，确保每个语言单元都有声学观测支撑，并允许从声学到语言单元的灵活、概率映射。

Result: 通过在基于CTC的ASR系统上进行实验，并结合预训练语言模型进行知识迁移，实验结果证明了该方法在灵活控制匹配程度和提高ASR性能方面的有效性。

Conclusion: 所提出的基于非均衡最优传输的对齐模型能够有效处理声学-语言表征间的复杂对齐问题，并通过灵活的匹配机制提升了ASR系统的性能。

Abstract: Aligning acoustic and linguistic representations is a central challenge to
bridge the pre-trained models in knowledge transfer for automatic speech
recognition (ASR). This alignment is inherently structured and asymmetric:
while multiple consecutive acoustic frames typically correspond to a single
linguistic token (many-to-one), certain acoustic transition regions may relate
to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often
include frames with no linguistic counterpart, such as background noise or
silence may lead to imbalanced matching conditions. In this work, we take a new
insight to regard alignment and matching as a detection problem, where the goal
is to identify meaningful correspondences with high precision and recall
ensuring full coverage of linguistic tokens while flexibly handling redundant
or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on
this new insight, we propose an unbalanced optimal transport-based alignment
model that explicitly handles distributional mismatch and structural
asymmetries with soft and partial matching between acoustic and linguistic
modalities. Our method ensures that every linguistic token is grounded in at
least one acoustic observation, while allowing for flexible, probabilistic
mappings from acoustic to linguistic units. We evaluate our proposed model with
experiments on an CTC-based ASR system with a pre-trained language model for
knowledge transfer. Experimental results demonstrate the effectiveness of our
approach in flexibly controlling degree of matching and hence to improve ASR
performance.

</details>


### [179] [From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics](https://arxiv.org/abs/2509.05617)
*Shay Dahary,Avi Edana,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 本研究旨在使用多标签情感分析方法，为歌曲歌词预测六种基本情感的情感强度得分。构建了一个包含多个人类评分者平均意见分（MOS）的标注数据集，并评估了零样本场景下多种大型语言模型（LLM）以及针对此任务微调的BERT模型的表现。


<details>
  <summary>Details</summary>
Motivation: 歌曲歌词的情感内容对听众体验和音乐偏好有重要影响，因此研究歌词的情感归因具有重要意义。

Method: 构建了一个使用平均意见分（MOS）标注的多标签情感歌词数据集。在零样本场景下评估了多种公开的大型语言模型（LLM）。此外，还微调了一个基于BERT的模型来进行多标签情感得分预测。

Result: 实验结果揭示了零样本模型和微调模型在捕捉歌词细微情感内容方面的相对优势和局限性。

Conclusion: 研究结果强调了大型语言模型在创意文本情感识别方面的潜力，并为基于情感的音乐信息检索应用提供了模型选择策略方面的见解。

Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener
experiences and influencing musical preferences. This paper investigates the
task of multi-label emotional attribution of song lyrics by predicting six
emotional intensity scores corresponding to six fundamental emotions. A
manually labeled dataset is constructed using a mean opinion score (MOS)
approach, which aggregates annotations from multiple human raters to ensure
reliable ground-truth labels. Leveraging this dataset, we conduct a
comprehensive evaluation of several publicly available large language models
(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model
specifically for predicting multi-label emotion scores. Experimental results
reveal the relative strengths and limitations of zero-shot and fine-tuned
models in capturing the nuanced emotional content of lyrics. Our findings
highlight the potential of LLMs for emotion recognition in creative texts,
providing insights into model selection strategies for emotion-based music
information retrieval applications. The labeled dataset is available at
https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.

</details>


### [180] [Few-Shot Query Intent Detection via Relation-Aware Prompt Learning](https://arxiv.org/abs/2509.05635)
*Liang Zhang,Yuan Li,Shijie Zhang,Zheng Zhang,Xitong Li*

Main category: cs.CL

TL;DR: 该研究提出了一种名为SAID的新框架，用于在少量样本的意图检测任务中整合文本和结构化关系信息，并通过查询自适应注意力网络（QueryAdapt）进行改进，实验结果表明SAID显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理对话系统中的意图检测时，主要关注文本信息，忽略了对话中固有的查询-查询关系和查询-答案关系等结构化信息，而这些信息对于提升意图检测的准确性至关重要。

Method: 提出了一种名为SAID的新框架，该框架首次将文本信息和关系结构信息统一起来进行模型预训练。在此基础上，进一步提出了一种查询自适应注意力网络（QueryAdapt），该网络在关系令牌层面操作，通过显式生成意图特定的关系令牌，实现更细粒度的知识迁移。

Result: 在两个真实世界数据集上的广泛实验结果表明，SAID在少量样本的意图检测任务上显著优于最先进的方法。

Conclusion: SAID框架成功地将文本信息和结构化关系信息相结合，并通过QueryAdapt网络实现了更有效的意图检测，为对话系统在少量样本场景下的意图识别提供了新的解决方案。

Abstract: Intent detection is a crucial component of modern conversational systems,
since accurately identifying user intent at the beginning of a conversation is
essential for generating effective responses. Recent efforts have focused on
studying this problem under a challenging few-shot scenario. These approaches
primarily leverage large-scale unlabeled dialogue text corpora to pretrain
language models through various pretext tasks, followed by fine-tuning for
intent detection with very limited annotations. Despite the improvements
achieved, existing methods have predominantly focused on textual data,
neglecting to effectively capture the crucial structural information inherent
in conversational systems, such as the query-query relation and query-answer
relation. To address this gap, we propose SAID, a novel framework that
integrates both textual and relational structure information in a unified
manner for model pretraining for the first time. Building on this framework, we
further propose a novel mechanism, the query-adaptive attention network
(QueryAdapt), which operates at the relation token level by generating
intent-specific relation tokens from well-learned query-query and query-answer
relations explicitly, enabling more fine-grained knowledge transfer. Extensive
experimental results on two real-world datasets demonstrate that SAID
significantly outperforms state-of-the-art methods.

</details>


### [181] [LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding](https://arxiv.org/abs/2509.05657)
*Yuxuan Hu,Jihao Liu,Ke Wang,Jinliang Zhen,Weikang Shi,Manyuan Zhang,Qi Dou,Rui Liu,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: LLM驱动的NAS方法需要大量领域特定的调整。LM-Searcher框架利用LLM进行跨领域神经架构优化，无需广泛的领域特定调整。它使用NCode进行跨领域架构编码和搜索，并将NAS重新定义为排序任务，通过指令调整模型来选择高性能架构。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM驱动的NAS方法依赖于提示工程和领域特定的调优，这限制了它们在不同任务中的实用性和可扩展性。

Method: 提出了一种名为LM-Searcher的新框架，该框架利用LLM进行跨领域神经架构优化。该方法的核心是NCode，一种通用的神经架构数值字符串表示，它实现了跨领域的架构编码和搜索。此外，NAS问题被重新定义为一个排序任务，通过指令调优的LLM从候选池中选择高性能架构，而这些调优样本是通过一种新颖的基于剪枝的子空间采样策略获得的。

Result: LM-Searcher在域内（例如，用于图像分类的CNN）和域外（例如，用于分割和生成的LoRA配置）任务中均取得了有竞争力的性能，展示了在灵活和可推广的基于LLM的架构搜索方面的能力。

Conclusion: LM-Searcher通过引入NCode表示和基于排序的LLM调优，实现了跨领域神经架构搜索，无需广泛的领域特定适应，为灵活和可扩展的LLM驱动的NAS提供了一个新的范例。

Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for
solving complex optimization problems, including Neural Architecture Search
(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt
engineering and domain-specific tuning, limiting their practicality and
scalability across diverse tasks. In this work, we propose LM-Searcher, a novel
framework that leverages LLMs for cross-domain neural architecture optimization
without the need for extensive domain-specific adaptation. Central to our
approach is NCode, a universal numerical string representation for neural
architectures, which enables cross-domain architecture encoding and search. We
also reformulate the NAS problem as a ranking task, training LLMs to select
high-performing architectures from candidate pools using instruction-tuning
samples derived from a novel pruning-based subspace sampling strategy. Our
curated dataset, encompassing a wide range of architecture-performance pairs,
encourages robust and transferable learning. Comprehensive experiments
demonstrate that LM-Searcher achieves competitive performance in both in-domain
(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA
configurations for segmentation and generation) tasks, establishing a new
paradigm for flexible and generalizable LLM-based architecture search. The
datasets and models will be released at https://github.com/Ashone3/LM-Searcher.

</details>


### [182] [Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning](https://arxiv.org/abs/2509.05660)
*Hong Su*

Main category: cs.CL

TL;DR: 该研究提出了一种扩展方法重用的方法，即使在问题相似度低或存在隐藏相似性时也能实现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重用解决方案时，通常要求问题具有高度相似性。本研究旨在扩展方法重用的范围，以解决问题相似度低或隐藏相似性问题。

Method: 将问题和解决方案分开，引导大语言模型（LLM）将解决方案适配到新的相关问题上，从而实现解决方案的转移，而非问题识别。进一步将此方法扩展到具有部分特征或隐藏特征的问题，实现跨问题的方法重用。

Result: 实验验证表明，所提出的范围扩展方法提高了筛选可重用解决方案的概率，从而提高了跨问题方法重用的有效性。

Conclusion: 本研究提出的范围扩展方法能够有效扩展方法重用的范围，提高其在问题相似度低或存在隐藏相似性时的有效性。

Abstract: Large language models (LLMs) have been widely applied to assist in finding
solutions for diverse questions. Prior work has proposed representing a method
as a pair of a question and its corresponding solution, enabling method reuse.
However, existing approaches typically require the questions to be highly
similar. In this paper, we extend the scope of method reuse to address
questions with low similarity or with hidden similarities that are not
explicitly observable. For questions that are similar in a general-specific
sense (i.e., broader or narrower in scope), we propose to first separate the
question and solution, rather than directly feeding the pair to the LLM. The
LLM is then guided to adapt the solution to new but related questions, allowing
it to focus on solution transfer rather than question recognition. Furthermore,
we extend this approach to cases where questions only share partial features or
hidden characteristics. This enables cross-question method reuse beyond
conventional similarity constraints. Experimental verification shows that our
scope-extension approach increases the probability of filtering out reusable
solutions, thereby improving the effectiveness of cross-question method reuse.

</details>


### [183] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: Llama-GENBA-10B 是一个100亿参数的 trilingual 基础模型，旨在解决大型语言模型中的英语中心偏见，并特别关注德语和巴伐利亚语。


<details>
  <summary>Details</summary>
Motivation: 该模型旨在解决大型语言模型（LLM）中普遍存在的英语中心偏见问题，并促进德语自然语言处理（NLP）社区的发展，同时支持巴伐利亚语这一低资源语言。

Method: 通过在Llama 3.1-8B基础上扩展到100亿参数，并在包含820亿英语、820亿德语和8000万巴伐利亚语的1640亿个标记上进行持续预训练，以平衡资源并防止英语主导。开发过程中解决了多语种语料库策展、统一分词器创建、跨语言迁移的超参数优化以及首个标准化三语评估套件的建立等挑战。

Result: Llama-GENBA-10B 在跨语言任务上表现出色，其微调版本在巴伐利亚语上超越了 Apertus-8B-2509 和 gemma-2-9b，成为该语言的最佳模型。在英语上，它超越了 EuroLLM，在德语上的表现与之相当。在 Cerebras CS-2 上进行的训练证明了其高效进行大规模多语言预训练的能力，并记录了能源消耗。

Conclusion: Llama-GENBA-10B 为构建包容性基础模型提供了蓝图，能够有效整合低资源语言，并实现了高效的大规模多语言预训练。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [184] [Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models](https://arxiv.org/abs/2509.05691)
*Ningyuan Deng,Hanyu Duan,Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 现有的文本嵌入模型在处理包含数字信息的文本时存在不足，在金融等需要精确理解数字的领域应用受限。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入模型在自然语言处理中广泛应用，但其在处理文本中的数值信息方面能力尚不明确，尤其是在金融和医疗等领域，精确的数值理解至关重要，例如2%和20%的市场份额增长具有截然不同的含义。

Method: 使用金融领域的合成数据，评估了13种广泛使用的文本嵌入模型在捕捉数值细节方面的能力。

Result: 研究发现，现有的文本嵌入模型普遍难以准确捕捉数值细节。

Conclusion: 现有的文本嵌入模型在数值理解方面存在显著的局限性，未来的研究需要加强在这方面的能力，以改进基于嵌入模型的自然语言处理系统。

Abstract: Text embedding models are widely used in natural language processing
applications. However, their capability is often benchmarked on tasks that do
not require understanding nuanced numerical information in text. As a result,
it remains unclear whether current embedding models can precisely encode
numerical content, such as numbers, into embeddings. This question is critical
because embedding models are increasingly applied in domains where numbers
matter, such as finance and healthcare. For example, Company X's market share
grew by 2\% should be interpreted very differently from Company X's market
share grew by 20\%, even though both indicate growth in market share. This
study aims to examine whether text embedding models can capture such nuances.
Using synthetic data in a financial context, we evaluate 13 widely used text
embedding models and find that they generally struggle to capture numerical
details accurately. Our further analyses provide deeper insights into embedding
numeracy, informing future research to strengthen embedding model-based NLP
systems with improved capacity for handling numerical content.

</details>


### [185] [A Survey of the State-of-the-Art in Conversational Question Answering Systems](https://arxiv.org/abs/2509.05716)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Fahmida Islam,Maryam Tahermazandarani,Quan Z. Sheng*

Main category: cs.CL

TL;DR: ConvQA系统在多轮对话中保持连贯性和相关性，利用先进的机器学习技术和大型语言模型，并分析了关键数据集和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: ConvQA系统在多领域（如客服、教育、法律、医疗）至关重要，需要进行连贯且相关的对话。

Method: 分析了ConvQA系统的核心组件（历史选择、问题理解、答案预测），探讨了强化学习、对比学习、迁移学习等高级机器学习技术，并评估了RoBERTa、GPT-4、Gemini 2.0 Flash、Mistral 7B和LLaMA 3等大型语言模型的作用。

Result: 深入分析了关键的ConvQA数据集，并指出了开放性的研究方向。

Conclusion: 对ConvQA领域进行了全面概述，为未来发展提供了宝贵见解。

Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.

</details>


### [186] [Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models](https://arxiv.org/abs/2509.05719)
*Donya Rooein,Flor Miriam Plaza-del-Arco,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 尽管波斯语拥有庞大的用户基础和丰富的数字文本，但其在主观性任务方面仍面临数据稀缺和质量挑战。


<details>
  <summary>Details</summary>
Motivation: 评估波斯语在主观性任务（情感分析、情绪分析、毒性检测）方面作为一种中等资源语言的实际地位，并确定数据可用性和质量的挑战。

Method: 通过回顾110篇关于波斯语主观性任务的论文，分析现有数据集的数量、质量以及是否包含必要的社会人口统计学信息，并评估现有模型在有限数据集上的预测性能和稳定性。

Result: 现有数据集数量不足且缺乏关键的社会人口统计学信息，模型在不同数据集和模型之间的预测结果不稳定。

Conclusion: 尽管数据总量有所增加，但对于像波斯语这样的语言，其在自然语言处理领域的进步仍然受到数据数量不足的严重限制。

Abstract: Given Farsi's speaker base of over 127 million people and the growing
availability of digital text, including more than 1.3 million articles on
Wikipedia, it is considered a middle-resource language. However, this label
quickly crumbles when the situation is examined more closely. We focus on three
subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection)
and find significant challenges in data availability and quality, despite the
overall increase in data availability. We review 110 publications on subjective
tasks in Farsi and observe a lack of publicly available datasets. Furthermore,
existing datasets often lack essential demographic factors, such as age and
gender, that are crucial for accurately modeling subjectivity in language. When
evaluating prediction models using the few available datasets, the results are
highly unstable across both datasets and models. Our findings indicate that the
volume of data is insufficient to significantly improve a language's prospects
in NLP.

</details>


### [187] [QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing](https://arxiv.org/abs/2509.05729)
*Charles M. Varmantchaonala,Niclas GÖtting,Nils-Erik SchÜtte,Jean Louis E. K. Fendji,Christopher Gies*

Main category: cs.CL

TL;DR: 本文提出了一个名为QCSE的预训练量子语境敏感嵌入模型，利用量子计算捕捉语境关系，并提出了五种计算语境矩阵的方法，在富拉尼语和英语语料库上进行了评估，证明了其在语境敏感性和利用量子系统表达能力方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 利用量子计算的独特优势来处理自然语言的复杂性，特别是捕捉语境关系，以应对低资源语言的数据稀疏性问题。

Method: 提出并测试了五种不同的语境矩阵计算方法（包括指数衰减、正弦调制、相位偏移和基于哈希的变换），以创建基于词语周围语言环境的独特表示，并实现了量子原生的语境学习。

Result: 在富拉尼语和英语语料库上的评估表明，QCSE模型能够捕捉语境敏感性，并利用量子系统的表达能力来表示丰富的、语境感知的语言信息。

Conclusion: QCSE模型展示了量子计算在自然语言处理中的潜力，特别是为低资源语言提供了新的解决方案，并为NLP的实际应用开辟了新途径。

Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to
encoding and understanding the complexity of natural languages through the
power of quantum computation. This paper presents a pretrained quantum
context-sensitive embedding model, called QCSE, that captures context-sensitive
word embeddings, leveraging the unique properties of quantum systems to learn
contextual relationships in languages. The model introduces quantum-native
context learning, enabling the utilization of quantum computers for linguistic
tasks. Central to the proposed approach are innovative context matrix
computation methods, designed to create unique, representations of words based
on their surrounding linguistic context. Five distinct methods are proposed and
tested for computing the context matrices, incorporating techniques such as
exponential decay, sinusoidal modulation, phase shifts, and hash-based
transformations. These methods ensure that the quantum embeddings retain
context sensitivity, thereby making them suitable for downstream language tasks
where the expressibility and properties of quantum systems are valuable
resources. To evaluate the effectiveness of the model and the associated
context matrix methods, evaluations are conducted on both a Fulani corpus, a
low-resource African language, dataset of small size and an English corpus of
slightly larger size. The results demonstrate that QCSE not only captures
context sensitivity but also leverages the expressibility of quantum systems
for representing rich, context-aware language information. The use of Fulani
further highlights the potential of QNLP to mitigate the problem of lack of
data for this category of languages. This work underscores the power of quantum
computation in natural language processing (NLP) and opens new avenues for
applying QNLP to real-world linguistic challenges across various tasks and
domains.

</details>


### [188] [Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification](https://arxiv.org/abs/2509.05741)
*Fernando Gabriela García,Qiyang Shi,Zilin Feng*

Main category: cs.CL

TL;DR: VeriFact-CoT 通过多阶段的“事实核查-反思-引用整合”机制，提升了大型语言模型生成内容的准确性、可信度和可追溯性，解决了幻觉和引用缺失问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成复杂、事实敏感内容时存在幻觉和缺乏可信引用来源的问题。

Method: 采用“事实核查-反思-引用整合”的多阶段机制，使大型语言模型能够自我审查和修改其推理步骤和最终答案。

Result: 显著提高了生成内容的客观准确性、可信度和可追溯性。

Conclusion: VeriFact-CoT 使大型语言模型在科学研究、新闻报道和法律咨询等需要高保真度的应用中更加可靠。

Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a
novel method designed to address the pervasive issues of hallucination and the
absence of credible citation sources in Large Language Models (LLMs) when
generating complex, fact-sensitive content. By incorporating a multi-stage
mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT
empowers LLMs to critically self-examine and revise their intermediate
reasoning steps and final answers. This process significantly enhances the
objective accuracy, trustworthiness, and traceability of the generated outputs,
making LLMs more reliable for applications demanding high fidelity such as
scientific research, news reporting, and legal consultation.

</details>


### [189] [LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization](https://arxiv.org/abs/2509.05863)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatinX是一个多语言语音合成模型，用于语音到语音的翻译，可以保持说话人的身份。它经过三阶段训练，并在英语和罗曼语（特别是葡萄牙语）上进行了训练，通过DPO优化，在减少词错误率和提高说话人相似度方面取得了良好效果，并且在人类评估中表现优于基线模型XTTSv2。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一个能够保持源说话人身份的多语言文本到语音（TTS）模型，用于语音到语音的翻译。

Method: 该模型（LatinX）是一个12层的仅解码器Transformer，经过三个阶段训练：1. 文本到音频映射的预训练；2. 用于零样本语音克隆的监督微调；3. 使用基于词错误率（WER）和说话人相似度指标的自动标记对，通过直接偏好优化（DPO）进行对齐。

Result: 在英语和罗曼语（特别是葡萄牙语）上训练的LatinX模型，通过DPO优化，一致地降低了WER并提高了客观相似度，优于微调基线。人类评估表明，与基线模型（XTTSv2）相比，感知到的说话人相似度更强。

Conclusion: LatinX模型在语音到语音翻译中成功地保持了说话人的身份，并且通过DPO优化显著提高了性能。研究还揭示了客观和主观度量之间的差距，并指出了未来研究方向，如跨语言分析、平衡偏好信号和低延迟架构。

Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded
speech-to-speech translation that preserves the source speaker's identity
across languages. LatinX is a 12-layer decoder-only Transformer trained in
three stages: (i) pre-training for text-to-audio mapping, (ii) supervised
fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct
Preference Optimization (DPO) using automatically labeled pairs based on Word
Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance
languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER
and improves objective similarity over the fine-tuned baseline. Human
evaluations further indicate stronger perceived speaker similarity than a
strong baseline (XTTSv2), revealing gaps between objective and subjective
measures. We provide cross-lingual analyses and discuss balanced preference
signals and lower-latency architectures as future work.

</details>


### [190] [ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula](https://arxiv.org/abs/2509.05867)
*ZiXuan Zhang,Bowen Hao,Yingjie Li,Hongzhi Yin*

Main category: cs.CL

TL;DR: 该研究提出了一个名为ZhiFangDanTai的框架，结合了基于图的检索增强生成（GraphRAG）和大型语言模型（LLM）微调技术，用于中医药方生成和解释，解决了现有模型在公式组成、君臣佐使、功效、禁忌等方面解释不全的问题。


<details>
  <summary>Details</summary>
Motivation: 现有中医药方分析模型缺乏全面的结果，如完整的公式组成和详细的解释。尽管近期有模型尝试微调大型语言模型（LLM）来生成可解释的药方，但现有数据集的细节不足（如君臣佐使、功效、禁忌、舌脉辨证等），限制了模型的输出深度。

Method: 提出了一种名为ZhiFangDanTai的框架，该框架结合了基于图的检索增强生成（GraphRAG）和LLM微调技术。ZhiFangDanTai使用GraphRAG来检索和综合结构化的中医药知识，生成简洁的摘要，并构建了一个增强的指令数据集来提高LLM整合检索信息的能力。此外，研究还提供了理论证明，表明将GraphRAG与微调技术相结合可以降低中医药方任务的泛化误差和幻觉率。

Result: 在收集和临床数据集上的实验结果表明，ZhiFangDanTai相较于现有最先进的模型取得了显著的改进。

Conclusion: ZhiFangDanTai框架通过结合GraphRAG和LLM微调，有效解决了中医药方生成和解释的挑战，并在实验中证明了其优越性。

Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in
treating epidemics and complex diseases. Existing models for TCM utilize
traditional algorithms or deep learning techniques to analyze formula
relationships, yet lack comprehensive results, such as complete formula
compositions and detailed explanations. Although recent efforts have used TCM
instruction datasets to fine-tune Large Language Models (LLMs) for explainable
formula generation, existing datasets lack sufficient details, such as the
roles of the formula's sovereign, minister, assistant, courier; efficacy;
contraindications; tongue and pulse diagnosis-limiting the depth of model
outputs. To address these challenges, we propose ZhiFangDanTai, a framework
combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM
fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured
TCM knowledge into concise summaries, while also constructing an enhanced
instruction dataset to improve LLMs' ability to integrate retrieved
information. Furthermore, we provide novel theoretical proofs demonstrating
that integrating GraphRAG with fine-tuning techniques can reduce generalization
error and hallucination rates in the TCM formula task. Experimental results on
both collected and clinical datasets demonstrate that ZhiFangDanTai achieves
significant improvements over state-of-the-art models. Our model is
open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.

</details>


### [191] [MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries](https://arxiv.org/abs/2509.05878)
*François Grolleau,Emily Alsentzer,Timothy Keyes,Philip Chung,Akshay Swaminathan,Asad Aali,Jason Hom,Tridu Huynh,Thomas Lew,April S. Liang,Weihan Chu,Natasha Z. Steele,Christina F. Lin,Jingkun Yang,Kameron C. Black,Stephen P. Ma,Fateme N. Haredasht,Nigam H. Shah,Kevin Schulman,Jonathan H. Chen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical
text is a critical barrier to adoption, as expert review is unscalable for the
continuous quality assurance these systems require. We address this challenge
with two complementary contributions. First, we introduce MedFactEval, a
framework for scalable, fact-grounded evaluation where clinicians define
high-salience key facts and an "LLM Jury"--a multi-LLM majority vote--assesses
their inclusion in generated summaries. Second, we present MedAgentBrief, a
model-agnostic, multi-step workflow designed to generate high-quality, factual
discharge summaries. To validate our evaluation framework, we established a
gold-standard reference using a seven-physician majority vote on
clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury
achieved almost perfect agreement with this panel (Cohen's kappa=81%), a
performance statistically non-inferior to that of a single human expert
(kappa=67%, P < 0.001). Our work provides both a robust evaluation framework
(MedFactEval) and a high-performing generation workflow (MedAgentBrief),
offering a comprehensive approach to advance the responsible deployment of
generative AI in clinical workflows.

</details>


### [192] [Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues](https://arxiv.org/abs/2509.05882)
*Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy*

Main category: cs.CL

TL;DR: LLM协作中的对齐技术需要改进，以适应多方、长时程的交互。研究表明，摩擦智能体（friction agents）通过鼓励反思，能有效提升协作的收敛性和任务正确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM对齐技术通常在单用户场景下开发，无法满足多方、长时程协作的动态性需求，需要研究新的对齐方法来提高LLM作为协作伙伴的可靠性。

Method: 使用角色扮演方法，评估不同训练方式的摩擦智能体在协作任务对话中的干预效果，并提出一个反事实评估框架来量化摩擦干预对协作轨迹和信念对齐的影响。

Result: 摩擦智能体方法显著优于常见的对齐基线，能更好地帮助群体达成共识（即约定的任务相关命题）和提高任务结果的正确性。

Conclusion: 摩擦智能体是提高LLM在多方协作中作为可靠的、可预测的以及可验证的协作伙伴的有效途径。

Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are
increasingly being considered "collaborators" with humans. If such AI
collaborators are to be reliable, their behavior over multiturn interactions
must be predictable, validated and verified before deployment. Common alignment
techniques are typically developed under simplified single-user settings and do
not account for the dynamics of long-horizon multiparty interactions. This
paper examines how different alignment methods affect LLM agents' effectiveness
as partners in multiturn, multiparty collaborations. We study this question
through the lens of friction agents that intervene in group dialogues to
encourage the collaborative group to slow down and reflect upon their reasoning
for deliberative decision-making. Using a roleplay methodology, we evaluate
interventions from differently-trained friction agents in collaborative task
conversations. We propose a novel counterfactual evaluation framework that
quantifies how friction interventions change the trajectory of group
collaboration and belief alignment. Our results show that a friction-aware
approach significantly outperforms common alignment baselines in helping both
convergence to a common ground, or agreed-upon task-relevant propositions, and
correctness of task outcomes.

</details>


### [193] [Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling](https://arxiv.org/abs/2509.05908)
*Yue Gu,Zhihao Du,Ying Shi,Shiliang Zhang,Qian Chen,Jiqing Han*

Main category: cs.CL

TL;DR: 通过过滤无关的偏见短语并整合最相关信息来提高上下文ASR的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于交叉注意力的上下文ASR模型在处理不断变化的偏见信息量时，其有效性会受到限制，尤其是在偏见列表长度显著增加的情况下。

Method: 提出了一种纯化的语义相关性联合建模（PSC-Joint）方法，该方法通过计算ASR中间表示与偏见信息之间的列表级、短语级和标记级语义相关性，并进行联合建模，以突出和整合最相关的偏见信息。此外，还提出了一种基于分组和竞争策略的净化机制来过滤不相关的偏见短语，以降低计算成本。

Result: 在AISHELL-1数据集上，PSC-Joint方法平均相对F1分数提高了21.34%，在KeSpeech数据集上提高了28.46%，在不同长度的偏见列表上都表现出优越性。

Conclusion: PSC-Joint方法通过有效整合最相关的偏见信息，并在计算效率和准确性之间取得平衡，能够有效解决上下文ASR中偏见信息量变化带来的挑战。

Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR)
models have made notable advancements in recognizing personalized biasing
phrases. However, the effectiveness of cross-attention is affected by
variations in biasing information volume, especially when the length of the
biasing list increases significantly. We find that, regardless of the length of
the biasing list, only a limited amount of biasing information is most relevant
to a specific ASR intermediate representation. Therefore, by identifying and
integrating the most relevant biasing information rather than the entire
biasing list, we can alleviate the effects of variations in biasing information
volume for contextual ASR. To this end, we propose a purified semantic
correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and
calculate three semantic correlations between the ASR intermediate
representations and biasing information from coarse to fine: list-level,
phrase-level, and token-level. Then, the three correlations are jointly modeled
to produce their intersection, so that the most relevant biasing information
across various granularities is highlighted and integrated for contextual
recognition. In addition, to reduce the computational cost introduced by the
joint modeling of three semantic correlations, we also propose a purification
mechanism based on a grouped-and-competitive strategy to filter out irrelevant
biasing phrases. Compared with baselines, our PSC-Joint approach achieves
average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46%
on KeSpeech, across biasing lists of varying lengths.

</details>


### [194] [Accelerating Large Language Model Inference via Early-Exiting Algorithms](https://arxiv.org/abs/2509.05915)
*Sangmin Bae*

Main category: cs.CL

TL;DR: 大型语言模型通过联合设计自适应算法和模型架构来解决部署成本和系统瓶颈的冲突，实现了效率和性能的新平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因高昂的计算成本而难以部署，而旨在降低成本的自适应计算方法（如提前退出）可能会导致系统瓶颈，从而降低吞吐量。

Method: 提出了一种高效的并行解码机制来解决传统提前退出方法的开销问题，并引入了深度参数共享作为模型架构的基础，以减少同步问题。此外，还提出了一个包含轻量级路由器以动态分配递归深度的统一框架。

Result: 通过联合设计自适应算法和模型架构，实现了介于效率和性能之间的新的帕累托前沿，该模型同时优化了自适应计算和参数效率。

Conclusion: 该研究通过共同设计自适应算法和模型架构，成功地解决了大型语言模型的计算成本和系统瓶颈问题，在效率和性能之间取得了最佳平衡。

Abstract: Large language models have achieved remarkable capabilities, but their
practical deployment is hindered by significant computational costs. While
adaptive computation methods like early-exiting promise to reduce these costs,
they introduce a fundamental conflict: the per-token dynamism intended to save
computation often creates system-level bottlenecks that can paradoxically
reduce throughput in batched inference. This dissertation resolves this
conflict by co-designing adaptive algorithms and model architectures to strike
an optimal balance between dynamism and efficiency. To this end, our work first
addresses critical sources of overhead in conventional early-exiting by
proposing an efficient parallel decoding mechanism. We then show that deep
parameter sharing provides an architectural foundation that not only yields
compact, parameter-efficient models but also inherently mitigates the critical
synchronization issues affecting dynamic inference. Finally, this work presents
a unified framework where lightweight routers are pretrained to dynamically
assign an optimal recursion depth for each token. This approach establishes a
new Pareto frontier between efficiency and performance by effectively
optimizing for both adaptive computation and parameter efficiency within a
single model.

</details>


### [195] [KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino](https://arxiv.org/abs/2509.06065)
*Lorenzo Alfred Nery,Ronald Dawson Catignas,Thomas James Tiam-Lee*

Main category: cs.CL

TL;DR: LLMs在低资源语言（如菲律宾语）上的表现不如英语，需要更广泛的多语言评估。


<details>
  <summary>Details</summary>
Motivation: 现有的truthfulness benchmark（如TruthfulQA）主要为英语，缺乏对低资源语言的评估，限制了LLM在这些语言中的可靠应用。

Method: 将TruthfulQA翻译成菲律宾语，创建KatotohananQA，并使用二元选择框架评估了七个免费模型。

Result: LLM在菲律宾语上的truthfulness表现显著低于英语；较新的OpenAI模型（GPT-5和GPT-5 mini）表现出多语言鲁棒性；不同类型的问题、类别和主题在多语言迁移方面存在差异。

Conclusion: 需要更广泛的多语言评估，以确保LLM在不同语言和文化背景下的公平性和可靠性。

Abstract: Large Language Models (LLMs) achieve remarkable performance across various
tasks, but their tendency to produce hallucinations limits reliable adoption.
Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet
they are primarily available in English, leaving a gap in evaluating LLMs in
low-resource languages. To address this, we present KatotohananQA, a Filipino
translation of the TruthfulQA benchmark. Seven free-tier proprietary models
were assessed using a binary-choice framework. Findings show a significant
performance gap between English and Filipino truthfulness, with newer OpenAI
models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness.
Results also reveal disparities across question characteristics, suggesting
that some question types, categories, and topics are less robust to
multilingual transfer which highlight the need for broader multilingual
evaluation to ensure fairness and reliability in LLM usage.

</details>


### [196] [Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis](https://arxiv.org/abs/2509.06074)
*Zhenqi Jia,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: MFCIG-CSS通过构建多模态细粒度交互图来提升对话语音合成的韵律自然度。


<details>
  <summary>Details</summary>
Motivation: 现有对话语音合成方法忽略了多模态对话历史中细粒度的语义和韵律交互信息，导致合成语音的韵律不够自然。

Method: 提出MFCIG-CSS系统，构建语义交互图和韵律交互图，对词级别的时间信息、韵律及其对后续语句的影响进行编码，并利用这些信息增强合成语音的韵律。

Result: 在DailyTalk数据集上，MFCIG-CSS在韵律表现力方面优于所有基线模型。

Conclusion: MFCIG-CSS能够有效捕捉细粒度的多模态交互信息，显著提升对话语音合成的韵律自然度。

Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural
prosody by understanding the multimodal dialogue history (MDH). The latest work
predicts the accurate prosody expression of the target utterance by modeling
the utterance-level interaction characteristics of MDH and the target
utterance. However, MDH contains fine-grained semantic and prosody knowledge at
the word level. Existing methods overlook the fine-grained semantic and
prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a
novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our
approach constructs two specialized multimodal fine-grained dialogue
interaction graphs: a semantic interaction graph and a prosody interaction
graph. These two interaction graphs effectively encode interactions between
word-level semantics, prosody, and their influence on subsequent utterances in
MDH. The encoded interaction features are then leveraged to enhance synthesized
speech with natural conversational prosody. Experiments on the DailyTalk
dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of
prosodic expressiveness. Code and speech samples are available at
https://github.com/AI-S2-Lab/MFCIG-CSS.

</details>


### [197] [Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079)
*Hao Liang,Ruitao Wu,Bohan Zeng,Junbo Niu,Wentao Zhang,Bin Dong*

Main category: cs.CL

TL;DR: 多模态推理仍然是人工智能中的一个基本挑战。尽管文本推理取得了实质性进展，但即使是像GPT-o3这样的最先进模型在多模态场景中也难以保持强劲的表现。为了解决这个差距，我们引入了一个有效的结合视觉和文本模态的字幕辅助推理框架。我们的方法在ICML 2025 AI for Math Workshop & Challenge 2: SeePhys中获得了第一名，证明了其有效性和鲁棒性。此外，我们在几何推理的MathVerse基准上验证了其泛化能力，展示了我们方法的通用性。我们的代码可在https://github.com/OpenDCAI/SciReasoner公开获取。


<details>
  <summary>Details</summary>
Motivation: 解决人工智能领域中多模态推理的挑战，特别是当前模型在结合视觉和文本信息时表现不佳的问题。

Method: 提出并实现了一个字幕辅助推理框架，用于连接视觉和文本模态。

Result: 在ICML 2025 AI for Math Workshop & Challenge 2: SeePhys竞赛中取得第一名，并在MathVerse基准上验证了方法的泛化能力。

Conclusion: 该字幕辅助推理框架能有效解决多模态推理的挑战，并在不同基准上展现出良好的性能和泛化能力。

Abstract: Multimodal reasoning remains a fundamental challenge in artificial
intelligence. Despite substantial advances in text-based reasoning, even
state-of-the-art models such as GPT-o3 struggle to maintain strong performance
in multimodal scenarios. To address this gap, we introduce a caption-assisted
reasoning framework that effectively bridges visual and textual modalities. Our
approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge
2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we
validate its generalization on the MathVerse benchmark for geometric reasoning,
demonstrating the versatility of our method. Our code is publicly available at
https://github.com/OpenDCAI/SciReasoner.

</details>


### [198] [Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models](https://arxiv.org/abs/2509.06100)
*Kefan Cao,Shuaicheng Wu*

Main category: cs.CL

TL;DR: LLMs 容易在序列多任务中发生灾难性遗忘。OLieRA 通过结合低秩正交性和李群变换来保留 LLM 参数的几何结构，从而解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有的参数正则化方法（如 O-LoRA 和 N-LoRA）虽然能缓解任务干扰，但忽略了传统参数微调会破坏 LLM 参数固有的几何结构，限制了性能。

Method: 提出了一种名为 OLieRA 的新方法，该方法将李群理论应用于 LLM 微调。OLieRA 利用乘法更新来保持参数的几何结构，同时对任务子空间施加正交性约束。

Result: OLieRA 在 Standard CL benchmark 上取得了最先进的结果，并在 Large Number of Tasks 设置中也表现出色。

Conclusion: OLieRA 能够通过保留参数的几何结构和施加正交性约束来有效解决 LLM 的灾难性遗忘问题。

Abstract: Large language models (LLMs) are prone to catastrophic forgetting in
sequential multi-task settings. Parameter regularization methods such as O-LoRA
and N-LoRA alleviate task interference by enforcing low-rank subspace
orthogonality, but they overlook the fact that conventional additive
fine-tuning disrupts the intrinsic geometric structure of LLM parameters,
limiting performance. Our key insight is that the parameter space of LLMs
possesses a geometric structure, which must be preserved in addition to
enforcing orthogonality. Based on this, we propose Orthogonal Low-rank
Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM
fine-tuning: leveraging multiplicative updates to preserve parameter geometry
while applying orthogonality constraints to task subspaces. Experiments
demonstrate that OLieRA achieves state-of-the-art results on the Standard CL
benchmark and remains among the top-performing methods in the Large Number of
Tasks setting.

</details>


### [199] [Benchmarking Gender and Political Bias in Large Language Models](https://arxiv.org/abs/2509.06164)
*Jinrui Yang,Xudong Han,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本研究提出了一个名为EuroParlVote的新基准，用于评估大型语言模型（LLMs）在政治敏感环境中的表现。该基准将欧洲议会辩论演讲与投票结果关联起来，并包含议员的详细人口统计学信息。研究使用该基准评估了LLMs在性别分类和投票预测任务上的表现，发现了模型在性别和政治立场上都存在偏见。GPT-4o等专有模型在鲁棒性和公平性方面优于开源模型。研究发布了数据集、代码和演示以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在处理欧洲议会辩论演讲等政治敏感内容时的偏见和表现，并提出一个新的基准数据集（EuroParlVote）来促进相关研究。

Method: 创建了一个包含欧洲议会辩论演讲、投票结果以及议员人口统计学信息（性别、年龄、国家、政治派别）的数据集EuroParlVote。利用该数据集，在性别分类（将演讲分配给男性或女性议员）和投票预测（预测议员的投票行为）两个任务上评估了现有的LLMs。

Result: 研究发现LLMs在处理性别信息时存在偏见，倾向于将女性议员错误分类为男性，并且在模拟女性演讲者的投票时准确率有所下降。在政治立场方面，LLMs倾向于支持中间派议员，对极左翼和极右翼议员的支持度较低。专有模型（如GPT-4o）在鲁棒性和公平性方面表现优于开源模型。

Conclusion: 现有的LLMs在政治文本处理中存在性别和政治立场偏见，专有模型在处理这些任务时表现更优。EuroParlVote数据集的发布将有助于未来在政治背景下研究NLP模型的公平性和可解释性。

Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

</details>


### [200] [Understanding the Influence of Synthetic Data for Text Embedders](https://arxiv.org/abs/2509.06184)
*Jacob Mitchell Springer,Vaibhav Adlakha,Siva Reddy,Aditi Raghunathan,Marius Mosbach*

Main category: cs.CL

TL;DR: 论文发布了一个高质量的合成数据集，并分析了合成数据在提升模型泛化能力方面的作用，发现其收益有限且存在任务间的权衡。


<details>
  <summary>Details</summary>
Motivation: 合成数据在训练通用文本嵌入模型方面取得了进展，但缺乏公开的数据集来研究其对模型泛化的影响。

Method: 1. 复现并公开了Wang等人提出的合成数据（Mistral-E5）。 2. 批判性地分析了合成数据提升模型泛化能力的具体方面。 3. 观察了合成数据在不同类别任务上的性能权衡。

Result: 合成数据质量高，能带来性能的提升。但这些提升是零散的、局部的，并且在不同任务之间存在性能权衡（一个任务受益可能导致另一个任务性能下降）。

Conclusion: 当前合成数据的方法在构建通用嵌入模型方面存在局限性，并且训练合成数据不一定能带来跨任务的更鲁棒的嵌入模型。

Abstract: Recent progress in developing general purpose text embedders has been driven
by training on ever-growing corpora of synthetic LLM-generated data.
Nonetheless, no publicly available synthetic dataset exists, posing a barrier
to studying its role for generalization. To address this issue, we first
reproduce and publicly release the synthetic data proposed by Wang et al.
(Mistral-E5). Our synthetic data is high quality and leads to consistent
improvements in performance. Next, we critically examine where exactly
synthetic data improves model generalization. Our analysis reveals that
benefits from synthetic data are sparse and highly localized to individual
datasets. Moreover, we observe trade-offs between the performance on different
categories and data that benefits one task, degrades performance on another.
Our findings highlight the limitations of current synthetic data approaches for
building general-purpose embedders and challenge the notion that training on
synthetic data leads to more robust embedding models across tasks.

</details>


### [201] [Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation](https://arxiv.org/abs/2509.06196)
*Mohamed T. Younes,Omar Walid,Khaled Shaban,Ali Hamdi,Mai Hassan*

Main category: cs.CL

TL;DR: 通过微调大型语言模型（LLMs）来自动化招聘流程，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决通用LLM在招聘任务中的局限性，并提高招聘流程的准确性和效率。

Method: 使用合成数据集和解析后的简历（通过DeepSeek LLM）对LLMs进行微调，使用JSON格式确保数据一致性和可扩展性。

Result: 在准确率、F1分数、BLEU分数、ROUGE分数和整体相似度等性能指标上，微调后的模型（特别是Phi-4模型，F1分数达到90.62%）显著优于基础模型和其他先进LLM。

Conclusion: 微调LLM在招聘领域具有巨大潜力，能够通过提供更准确的候选人-职位匹配来彻底改变招聘工作流程。

Abstract: This paper presents a novel approach to recruitment automation. Large
Language Models (LLMs) were fine-tuned to improve accuracy and efficiency.
Building upon our previous work on the Multilayer Large Language Model-Based
Robotic Process Automation Applicant Tracking (MLAR) system . This work
introduces a novel methodology. Training fine-tuned LLMs specifically tuned for
recruitment tasks. The proposed framework addresses the limitations of generic
LLMs by creating a synthetic dataset that uses a standardized JSON format. This
helps ensure consistency and scalability. In addition to the synthetic data
set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes
were parsed into the same structured JSON format and placed in the training
set. This will help improve data diversity and realism. Through
experimentation, we demonstrate significant improvements in performance
metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall
similarity compared to base models and other state-of-the-art LLMs. In
particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%,
indicating exceptional precision and recall in recruitment tasks. This study
highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize
recruitment workflows by providing more accurate candidate-job matching.

</details>


### [202] [MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment](https://arxiv.org/abs/2509.06200)
*Omar Walid,Mohamed T. Younes,Khaled Shaban,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: 本研究提出了一个名为MSLEF的多段式集成框架，通过微调大型语言模型（LLM）来改进招聘自动化中的简历解析。该框架集成了加权投票的微调LLM，每个模型专注于简历的特定部分以提高准确性。MSLEF引入了一个段感知架构，并利用针对每个简历部分量身定制的字段特定加权，有效克服了单模型系统的局限性。它使用Gemini-2.5-Flash作为复杂部分的聚合器，并结合了Gemma 9B、LLaMA 3.1 8B和Phi-4 14B模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高招聘自动化中简历解析的准确性和适应性，克服单模型系统在处理多样化简历格式和结构方面的局限性。

Method: 开发了一个名为MSLEF的多段式集成框架，利用微调的大型语言模型（LLM）进行简历解析。该框架采用加权投票机制，使每个LLM专注于简历的一个特定段落。此外，它还引入了一个段感知架构，并使用Gemini-2.5-Flash作为复杂部分的聚合器，同时结合了Gemma 9B、LLaMA 3.1 8B和Phi-4 14B模型。

Result: MSLEF在Exact Match (EM)、F1分数、BLEU、ROUGE和Recruitment Similarity (RS)等指标上取得了显著改进，在RS指标上比最佳单模型高出7%。其段感知设计提高了模型在不同简历布局上的泛化能力。

Conclusion: MSLEF框架通过其多段式集成和段感知设计，能够有效提升简历解析的准确性和泛化能力，使其能够适应各种招聘场景，并提供精确可靠的候选人信息。

Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

</details>


### [203] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: AI音乐生成技术可能侵犯版权，本文探索了机器学习“卸载”技术来解决此问题，并通过在文本到音乐模型上的实验，分析了其有效性并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成技术在创意产业中迅速兴起，但其可能侵犯版权，引发伦理和法律问题。

Method: 将机器学习“卸载”技术应用于预训练的文本到音乐（TTM）模型，并分析其在不损害模型性能的情况下“卸载”预训练数据集的有效性。

Result: 初步实验结果表明，在TTM模型上应用机器学习“卸载”技术存在挑战，但为未来研究提供了基础。

Conclusion: 本文首次将机器学习“卸载”技术应用于AI音乐生成领域，旨在防止侵犯版权，并为未来相关研究奠定了基础。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [204] [Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?](https://arxiv.org/abs/2509.06350)
*Junjie Mu,Zonghao Ying,Zhekui Fan,Zonglei Jing,Yaoyuan Zhang,Zhengmin Yu,Wenxin Zhang,Quanchen Zou,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: GCG攻击的改进方法Mask-GCG通过学习可训练的令牌掩码来识别后缀中的重要令牌，增加高影响力位置令牌的更新概率，并修剪低影响力位置的令牌，从而减少冗余，降低计算开销，缩短攻击时间。


<details>
  <summary>Details</summary>
Motivation: 以往的GCG攻击依赖于固定长度的后缀，但其中可能存在冗余。本研究旨在探索这种冗余并提出一种更有效的方法。

Method: 提出Mask-GCG，一种即插即用的方法，使用可学习的令牌掩码来识别后缀中的重要令牌，增加高影响力位置令牌的更新概率，同时修剪低影响力位置的令牌。

Result: 实验结果表明，后缀中的大多数令牌对攻击成功有显著影响，而修剪少数低影响力令牌不会影响损失值或攻击成功率，揭示了LLM提示中的令牌冗余。

Conclusion: Mask-GCG通过识别并修剪冗余令牌，在不影响攻击成功率的情况下，减少了计算开销和攻击时间，为开发高效、可解释的LLM提供了见解。

Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various
successful methods whereby attackers manipulate models into generating harmful
responses that they are designed to avoid. Among these, Greedy Coordinate
Gradient (GCG) has emerged as a general and effective approach that optimizes
the tokens in a suffix to generate jailbreakable prompts. While several
improved variants of GCG have been proposed, they all rely on fixed-length
suffixes. However, the potential redundancy within these suffixes remains
unexplored. In this work, we propose Mask-GCG, a plug-and-play method that
employs learnable token masking to identify impactful tokens within the suffix.
Our approach increases the update probability for tokens at high-impact
positions while pruning those at low-impact positions. This pruning not only
reduces redundancy but also decreases the size of the gradient space, thereby
lowering computational overhead and shortening the time required to achieve
successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the
original GCG and several improved variants. Experimental results show that most
tokens in the suffix contribute significantly to attack success, and pruning a
minority of low-impact tokens does not affect the loss values or compromise the
attack success rate (ASR), thereby revealing token redundancy in LLM prompts.
Our findings provide insights for developing efficient and interpretable LLMs
from the perspective of jailbreak attacks.

</details>


### [205] [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)
*Ao Chang,Yubo Chen,Jun Zhao*

Main category: cs.CL

TL;DR: PL-CA通过参数化检索增强生成（P-RAG）框架和多任务法律数据集，解决了传统RAG在法律领域面临的上下文窗口限制、计算开销大和基准测试不完善等问题。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法将检索到的文档直接注入模型上下文，存在上下文窗口限制、计算开销大、注意力分散和性能下降等问题。现有基准测试缺乏专家注释且侧重单一任务，无法真实反映模型在复杂法律场景下的能力。

Method: 提出PL-CA框架，包含P-RAG，用于对语料库知识进行数据增强，并将法律知识编码为参数向量。通过LoRA将参数化知识集成到LLM的前馈网络（FFN）中，以减轻模型上下文压力。同时，构建了一个包含2000多个训练和测试实例、经过专家注释和人工验证的多任务法律数据集。

Result: 实验结果表明，PL-CA在保持具有竞争力的下游任务性能的同时，减少了与过长上下文相关的开销。

Conclusion: PL-CA框架通过参数化知识注入和多任务数据集，有效解决了传统RAG在法律领域的局限性，并在实际应用中展现出优越的性能和效率。

Abstract: Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

</details>


### [206] [Do LLMs exhibit the same commonsense capabilities across languages?](https://arxiv.org/abs/2509.06401)
*Ivan Martínez-Murillo,Elena Lloret,Paloma Moreda,Albert Gatt*

Main category: cs.CL

TL;DR: LLMs在多语言常识生成方面表现出显著的语言不平衡，在英语上表现优于资源较少的语言，尽管上下文支持有所帮助，但整体能力仍有限。引入了新的MULTICOM基准来评估LLMs在此任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在多语言常识生成方面的能力，并找出其在不同语言（特别是资源较少的语言）上的局限性。

Method: 创建了一个名为MULTICOM的新基准，该基准扩展了COCOTEROS数据集，涵盖了英语、西班牙语、荷兰语和巴伦西亚语。在基准上评估了LLaMA、Qwen、Gemma、EuroLLM和Salamandra等开源LLMs，结合了自动评估、LLM-as-a-judge方法（Prometheus和JudgeLM）和人工标注。

Result: 在多语言常识生成任务中，LLMs在英语上表现出最佳性能，而在资源较少的语言上性能显著下降。上下文支持对性能的影响不一，但对代表性不足的语言有积极作用。

Conclusion: 目前LLMs在多语言常识生成方面存在局限性，尤其是在处理资源较少的语言时。未来的研究应关注提高LLMs在这些语言上的常识推理和生成能力。

Abstract: This paper explores the multilingual commonsense generation abilities of
Large Language Models (LLMs). To facilitate this investigation, we introduce
MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four
languages: English, Spanish, Dutch, and Valencian. The task involves generating
a commonsensical sentence that includes a given triplet of words. We evaluate a
range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and
Salamandra, on this benchmark. Our evaluation combines automatic metrics,
LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human
annotations. Results consistently show superior performance in English, with
significantly lower performance in less-resourced languages. While contextual
support yields mixed results, it tends to benefit underrepresented languages.
These findings underscore the current limitations of LLMs in multilingual
commonsense generation. The dataset is publicly available at
https://huggingface.co/datasets/gplsi/MULTICOM.

</details>


### [207] [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501)
*Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He*

Main category: cs.CL

TL;DR: LLM 代理需要网络浏览能力，但现有工具数据不足且不透明。我们提出了 WebExplorer，一种数据生成方法，并构建了 WebExplorer-8B 模型，它在信息检索任务中达到了最先进的性能，能够处理长轮次问题。


<details>
  <summary>Details</summary>
Motivation: 现有开源网络代理在复杂任务上的信息检索能力有限，且实现不透明。关键挑战在于缺乏具有挑战性的信息检索数据。

Method: 提出 WebExplorer 数据生成方法，利用基于模型的探索和迭代查询演变来创建包含多步推理和复杂网络导航的查询-答案对。基于该数据集，使用监督微调和强化学习开发了 WebExplorer-8B 模型。

Result: WebExplorer-8B 模型支持 128K 上下文长度和高达 100 次工具调用，在信息检索基准测试中取得了同类模型中的最先进性能。在 BrowseComp-en/zh 上优于 WebSailor-72B，在 WebWalkerQA 和 FRAMES 上性能最佳。在 HLE 基准测试中也表现出良好的泛化能力。

Conclusion: WebExplorer 数据生成方法和 WebExplorer-8B 模型为构建长视线网络代理提供了一条实用路径。

Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

</details>


### [208] [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)
*Andrei Baroian,Kasper Notebomer*

Main category: cs.CL

TL;DR: 通过在预训练阶段重新分配FFN宽度和注意力头，引入了三种新的层级缩放（LWS）变体（Framed、Reverse和Crown），并在参数量为1.8亿、训练50亿token的固定预算下进行了系统性消融实验，所有模型均达到了与等成本各向同性基线相当的损失和更好的性能，同时训练吞吐量没有明显下降。


<details>
  <summary>Details</summary>
Motivation: Transformer模型通常使用统一的层大小，忽略了不同深度的功能作用和计算能力需求。

Method: 在预训练阶段，通过两点或三点线性插值重新分配FFN宽度和注意力头，引入了三种新的LWS变体：Framed、Reverse和Crown。

Result: 所有模型都收敛到相似的损失，并且在固定1.8亿参数量和50亿token的预算下，与等成本的各向同性基线相比，性能有所提高，而训练吞吐量没有明显下降。

Conclusion: 该研究首次系统性地进行了LWS及其变体的消融实验，为预训练的层级架构设计空间提供了初步探索，但未来的工作需要将实验规模扩大到更多的token和参数，以充分评估其潜力。

Abstract: Transformer-based language models traditionally use uniform (isotropic) layer
sizes, yet they ignore the diverse functional roles that different depths can
play and their computational capacity needs. Building on Layer-Wise Scaling
(LWS) and pruning literature, we introduce three new LWS variants - Framed,
Reverse, and Crown - that redistribute FFN widths and attention heads via two
or three-point linear interpolation in the pre-training stage. We present the
first systematic ablation of LWS and its variants, on a fixed budget of 180M
parameters, trained on 5B tokens. All models converge to similar losses and
achieve better performance compared to an equal-cost isotropic baseline,
without a substantial decrease in training throughput. This work represents an
initial step into the design space of layer-wise architectures for
pre-training, but future work should scale experiments to orders of magnitude
more tokens and parameters to fully assess their potential.

</details>


### [209] [LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection](https://arxiv.org/abs/2509.06524)
*Jian Wu,Hang Yu,Bingchang Liu,Wenjie Yang,Peng Di,Jianguo Li,Yue Zhang*

Main category: cs.CL

TL;DR: LLM可作为隐式分类器，用于特定领域数据的选择，LAMDAS在数据选择方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在特定领域调整LLM时，高质量、经过人类策划的数据稀缺是一个关键瓶颈。盲目使用大量未经检查的数据进行微调可能会引入噪声并降低性能，因此需要一种既准确又高效的数据选择方法。

Method: LAMDAS将数据选择视为一个单分类问题，利用预训练的LLM本身作为隐式分类器，来识别属于目标域的候选数据，而无需显式的特征工程或计算密集型的优化过程。

Result: 实验结果表明，LAMDAS不仅在仅使用一小部分数据的情况下，其性能就超过了使用全部数据进行训练的LLM，而且在各种场景下均优于九种最先进的基线方法。LAMDAS在性能提升和计算效率之间取得了最佳平衡。

Conclusion: LAMDAS通过将LLM作为隐式分类器，有效解决了特定领域数据选择的挑战，在性能和效率上都取得了显著的优势。

Abstract: Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

</details>


### [210] [SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion](https://arxiv.org/abs/2509.06531)
*Mengxue Yang,Chun Yang,Jiaqi Zhu,Jiafan Li,Jingqi Zhang,Yuyang Li,Ying Li*

Main category: cs.CL

TL;DR: SLiNT是一个将知识图谱结构信息注入冻结的大语言模型（LLM）的框架，用于改进链接预测的性能，特别是在信息不完整或零样本的场景下。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在链接预测任务中，由于对结构信号利用不足，存在结构稀疏和语义模糊的问题，尤其是在信息不完整或零样本的情况下。

Method: SLiNT框架通过以下方式解决上述问题：1. 结构引导邻域增强（SGNE）：检索伪邻居以丰富稀疏实体，缓解上下文缺失。2. 动态难例对比学习（DHCL）：通过插值难例正负样本引入细粒度监督，解决实体层面的歧义。3. 梯度解耦双注入（GDDI）：在保持LLM核心参数不变的情况下，进行面向词元（token）的结构感知干预。

Result: 在WN18RR和FB15k-237数据集上的实验表明，SLiNT在链接预测任务上取得了优于或可比于基于嵌入和基于生成的方法的性能。

Conclusion: 对于可扩展的知识图谱补全，进行面向结构感知的表示学习是有效的。

Abstract: Link prediction in knowledge graphs requires integrating structural
information and semantic context to infer missing entities. While large
language models offer strong generative reasoning capabilities, their limited
exploitation of structural signals often results in structural sparsity and
semantic ambiguity, especially under incomplete or zero-shot settings. To
address these challenges, we propose SLiNT (Structure-aware Language model with
Injection and coNtrastive Training), a modular framework that injects
knowledge-graph-derived structural context into a frozen LLM backbone with
lightweight LoRA-based adaptation for robust link prediction. Specifically,
Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to
enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive
Learning (DHCL) introduces fine-grained supervision by interpolating hard
positives and negatives to resolve entity-level ambiguity; and
Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware
intervention while preserving the core LLM parameters. Experiments on WN18RR
and FB15k-237 show that SLiNT achieves superior or competitive performance
compared with both embedding-based and generation-based baselines,
demonstrating the effectiveness of structure-aware representation learning for
scalable knowledge graph completion.

</details>


### [211] [HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2509.06596)
*Xin Tong,Zhi Lin,Jingya Wang,Bo Jin*

Main category: cs.CL

TL;DR: LLMs在长文本生成中易产生幻觉，HAVE通过自适应门控和值校准解决此问题，有效减少幻觉并提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在检索增强或长上下文生成任务中，即使有相关证据也常常产生幻觉。这源于两个问题：1. 头部重要性被视为与输入无关；2. 原始注意力权重未能准确反映每个 token 的实际贡献。

Method: 提出HAVE（Head-Adaptive Gating and ValuE Calibration）框架，一个无需微调的解码框架。HAVE包含两个主要组件：1. 头部自适应门控：对注意力头进行实例级别的软重加权；2. 值校准：通过值向量的幅度来增强注意力，以近似写回贡献。这两个模块共同构建与模型更新一致的 token 级别证据，并通过轻量级的、经过不确定性缩放的策略与语言模型分布融合。

Result: HAVE无需微调，只需一次前向传播即可，效率高且适用性广。在多个问答基准和LLM家族上的实验表明，HAVE能够持续减少幻觉，并且在性能上优于包括DAGCD在内的强有力基线模型，而附加的开销却很小。

Conclusion: HAVE框架透明、可复现，易于与现成的LLMs集成，通过解决LLMs在长文本生成中的幻觉问题，推动了在实际场景中可信赖的生成。

Abstract: Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

</details>


### [212] [Guided Decoding and Its Critical Role in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.06631)
*Özgür Uğur,Musa Yılmaz,Esra Şavirdi,Özay Ezerceli,Mahmut El Huseyni,Selva Taş,Reyhan Bayraktar*

Main category: cs.CL

TL;DR: 本研究对比了三种引导解码方法（Outlines, XGrammar, LM Format Enforcer）在不同多轮提示设置（0轮, 1轮, 2轮）下，在检索增强生成（RAG）系统中的表现，评估了成功率、幻觉率和输出质量，并探讨了多轮交互对引导解码的影响。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统需要结构化、可靠的响应，并尽量减少幻觉，而引导解码是确保输出格式的关键技术。

Method: 对比了Outlines, XGrammar, LM Format Enforcer这三种引导解码方法，在0轮、1轮和2轮的多轮提示设置下进行评估。

Result: 研究结果揭示了多轮交互如何影响引导解码，并发现了可能影响方法选择的意外性能变化。

Conclusion: 本研究为RAG系统中结构化输出生成提供了理论见解和实践指导，有助于LLM的部署。

Abstract: The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

</details>


### [213] [Modelling Intertextuality with N-gram Embeddings](https://arxiv.org/abs/2509.06637)
*Yi Xing*

Main category: cs.CL

TL;DR: 提出一种新的量化模型，通过比较文本n-gram的词嵌入来分析文学文本间的互文性，并进行网络化展示。


<details>
  <summary>Details</summary>
Motivation: 现有的互文性分析方法在可扩展性和量化方面存在局限，需要一种新的方法来支持大规模分析和网络洞察。

Method: 对两个文本的n-gram进行词嵌入（embeddings）的成对比较，并平均其结果，以此作为整体互文性的度量。

Result: 通过在具有已知互文性程度的四种文本上的验证，以及对267种不同文本的可扩展性测试，证明了该方法在有效性和效率方面的优越性。网络分析进一步揭示了中心性和社群结构。

Conclusion: 所提出的量化模型能够成功捕捉和量化互文关系，并能通过网络分析提供有价值的见解。

Abstract: Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

</details>


### [214] [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)
*Hao Lin,Peitong Xie,Jingxue Chen,Jie Lin,Qingkun Tang,Qianchun Lu*

Main category: cs.CL

TL;DR: MoLER是一种新的领域感知RAG方法，通过MoL增强的强化学习来优化检索，以提高检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的粗排优化方法难以平衡领域特定知识学习和查询增强，导致检索性能不佳。

Method: MoLER采用两阶段方法：1. 使用混合损失（MoL）的持续预训练（CPT）阶段，以平衡领域特定知识和通用语言能力。2. 利用群组相对策略优化（GRPO）的强化学习（RL）阶段，以优化查询和文档生成，最大化文档召回率。关键创新是多查询单文档晚期融合（MSLF）策略，用于减少RL训练期间的计算开销，并通过多查询多文档晚期融合（MMLF）实现可扩展推理。

Result: 在基准数据集上的广泛实验表明，MoLER取得了最先进的性能，显著优于基线方法。

Conclusion: MoLER弥合了RAG系统中的知识差距，实现了专业领域中稳健且可扩展的检索。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

</details>


### [215] [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652)
*Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 本研究提出了IntrEx数据集，用于量化和分析教育对话中的趣味性，并探索了LLM在预测趣味性方面的能力，发现其在特定数据集上表现优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前教育对话中的学习者参与度和动机维持面临挑战，现有研究对驱动对话趣味性的语言特征了解甚少。

Method: 构建了基于TSCC的IntrEx数据集，包含超过100名学习者的趣味性标注，采用类似RLHF的比较评分方法，并训练LLM（7B/8B参数）进行趣味性预测。

Result: LLM（7B/8B参数）在趣味性预测任务上优于GPT-4o，表明专业数据集在教育场景建模参与度方面的潜力。同时，研究分析了具体性、可理解性和理解度等因素对教育对话参与度的影响。

Conclusion: IntrEx数据集为研究教育对话的趣味性提供了资源，LLM经过特定数据集微调后在趣味性预测方面展现出强大潜力，为提升学习者参与度提供了新的途径。

Abstract: Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

</details>


### [216] [ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data](https://arxiv.org/abs/2509.06675)
*Vladislav Stankov,Matyáš Kopp,Ondřej Bojar*

Main category: cs.CL

TL;DR: ParCzech4Speech 1.0是一个包含2,695小时数据的处理过的ParCzech 4.0语料库版本，用于语音建模任务。它结合了捷克议会演讲的录音和官方文字记录，并使用WhisperX和Wav2Vec 2.0提取了自动音频-文本对齐。该数据集有三种变体：句子分割、未分割和原始对齐，并保留了原始元数据，在CC-BY许可下发布。


<details>
  <summary>Details</summary>
Motivation: 介绍ParCzech4Speech 1.0数据集，该数据集旨在为语音建模任务提供一个大规模、高质量的捷克语语音语料库，并改善现有的语音识别版本。

Method: 结合了捷克议会演讲的录音和官方文字记录，并使用WhisperX和Wav2Vec 2.0技术提取了自动音频-文本对齐。数据集被处理成三种变体：句子分割、未分割和原始对齐。

Result: 创建了一个包含多达2,695小时数据的ParCzech4Speech 1.0数据集，具有高可靠性的音频-文本对齐。数据集提供了三种灵活的变体，适用于自动语音识别、语音合成和其他自定义任务。

Conclusion: ParCzech4Speech 1.0数据集为捷克语语音建模任务提供了一个宝贵资源，其多样化的变体和高质量的处理使其适用于广泛的应用。

Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0
corpus, targeted at speech modeling tasks with the largest variant containing
2,695 hours. We combined the sound recordings of the Czech parliamentary
speeches with the official transcripts. The recordings were processed with
WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our
processing pipeline improves upon the ParCzech 3.0 speech recognition version
by extracting more data with higher alignment reliability. The dataset is
offered in three flexible variants: (1) sentence-segmented for automatic speech
recognition and speech synthesis tasks with clean boundaries, (2) unsegmented
preserving original utterance flow across sentences, and (3) a raw-alignment
for further custom refinement for other possible tasks. All variants maintain
the original metadata and are released under a permissive CC-BY license. The
dataset is available in the LINDAT repository, with the sentence-segmented and
unsegmented variants additionally available on Hugging Face.

</details>


### [217] [Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments](https://arxiv.org/abs/2509.06704)
*Amir Homayounirad,Enrico Liscio,Tong Wang,Catholijn M. Jonker,Luciano C. Siebert*

Main category: cs.CL

TL;DR: 直接识别主观性可以提高模型在识别主观论点方面的性能，并且可以减少对每个标签的主观性的依赖。


<details>
  <summary>Details</summary>
Motivation: 聚合多个注释可能会隐藏关于注释者分歧的宝贵见解，尤其是在主观性起着至关重要作用的任务中。本研究旨在探索识别主观性的方法，以认识到激励论点的人类价值观。

Method: 评估两种主要方法：通过价值预测推断主观性与直接识别主观性。

Result: 直接识别主观性显著提高了模型在标记主观论点方面的性能。将对比损失与二元交叉熵损失相结合，并未提高性能，但减少了对每个标签的主观性的依赖。

Conclusion: 所提出的方法有助于识别个人可能以不同方式解释的论点，从而促进更细致的注释过程。

Abstract: Aggregating multiple annotations into a single ground truth label may hide
valuable insights into annotator disagreement, particularly in tasks where
subjectivity plays a crucial role. In this work, we explore methods for
identifying subjectivity in recognizing the human values that motivate
arguments. We evaluate two main approaches: inferring subjectivity through
value prediction vs. directly identifying subjectivity. Our experiments show
that direct subjectivity identification significantly improves the model
performance of flagging subjective arguments. Furthermore, combining
contrastive loss with binary cross-entropy loss does not improve performance
but reduces the dependency on per-label subjectivity. Our proposed methods can
help identify arguments that individuals may interpret differently, fostering a
more nuanced annotation process.

</details>


### [218] [Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint](https://arxiv.org/abs/2509.06795)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Qika Lin,Kai He,Ting Liu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 指令微调（IFT）会损害大型语言模型（LLM）的安全性，特别是拒绝恶意指令的能力。研究发现，LLM的隐藏状态中的拒绝方向（r-direction）会发生漂移，这是安全风险的原因之一。我们提出了ProCon方法，通过引入一个投影约束损失项来正则化每个训练样本的隐藏状态在r-direction上的投影幅度，以减轻这种漂移。通过早期强约束和扩大数据分布的预热策略，增强版的ProCon能够有效减轻IFT带来的安全风险，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: IFT在提升LLM能力方面效果显著，但会损害其安全性，特别是拒绝恶意指令的能力。理解并解决r-direction漂移问题对于提高LLM的安全性至关重要。

Method: 提出ProCon方法，通过引入投影约束损失项来正则化隐藏状态在r-direction上的投影幅度，以减轻r-direction漂移。结合预热策略，早期采用强约束并扩大数据分布，以克服性能限制。

Result: 实验结果表明，ProCon方法能够有效减轻IFT带来的安全风险，同时保持任务性能。与强基线相比，ProCon在各项指标上均表现更优，并有助于稳定训练过程中的r-direction。

Conclusion: ProCon方法通过约束r-direction的投影幅度，有效解决了IFT带来的安全风险问题，并在保持LLM性能的同时提高了安全性。该研究为未来LLM安全性的研究奠定了基础。

Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

</details>


### [219] [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)
*Haoyu Dong,Pengkun Zhang,Mingzhe Lu,Yanzhen Shen,Guolin Ke*

Main category: cs.CL

TL;DR: LLMs在标准ML任务中难以利用多样本示例进行上下文学习，我们提出了MachineLearningLM框架，通过合成ML任务和高效提示，显著提升LLMs的多样本上下文学习能力，同时保持其通用知识和推理能力，并在表格分类任务上超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs拥有广泛的知识和推理能力，但在标准机器学习任务中，它们难以仅通过上下文学习（ICL）从大量示例中学习。

Method: 我们提出了MachineLearningLM，一个便携式的持续预训练框架。它通过从数百万个结构因果模型（SCMs）中合成机器学习任务，并将随机森林教师的决策策略蒸馏到LLM中，以增强其在数值建模方面的鲁棒性。所有任务都通过一种节省令牌的提示进行序列化。

Result: MachineLearningLM在分布外表格分类任务上，比GPT-5-mini等LLM基线平均高出约15%。它展示了显著的多样本扩展定律：准确性随上下文示例数量从8个增加到1,024个而单调增加。在没有特定任务训练的情况下，它达到了随机森林级别的准确性。同时，通用聊天能力（包括知识和推理）得以保留，在MMLU上达到了75.4%。

Conclusion: MachineLearningLM成功地提升了LLM在机器学习任务上的多样本上下文学习能力，同时保留了其通用能力，为在更广泛的聊天工作流中应用LLM提供了新的途径。

Abstract: Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

</details>


### [220] [MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security](https://arxiv.org/abs/2509.06807)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: MoGU_v2框架通过动态路由和选择性嵌入路由器来平衡大型语言模型的安全性和可用性，解决了现有方法过于保守的问题，并在各种LLM系列中表现出强大的适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）安全方法往往牺牲其实用性，导致响应过于保守。本研究旨在提高LLM的可用性和安全性之间的平衡，而非强制进行权衡。

Method: 提出MoGU框架，其内部路由动态分配权重，以平衡安全优化和可用性优化变体的贡献。进一步提出MoGU_v2框架，将路由器嵌入到编码高可分类安全特征的层中，并通过双向适应来优化路由器。

Result: MoGU_v2在各种LLM系列（包括主流LLM、设备端LLM和推理LLM）中表现出强大的适应性和稳定的改进。即使在指令微调引入风险的情况下，MoGU_v2也能通过简单的数据混合策略在不牺牲任务性能的情况下恢复安全性。

Conclusion: MoGU_v2是一个强大且通用的解决方案，可以减轻实际应用中LLM的安全风险，有效平衡了模型的安全性与可用性。

Abstract: As Large Language Models (LLMs) increasingly permeate human life, their
security has emerged as a critical concern, particularly their ability to
maintain harmless responses to malicious instructions. Although extensive
methods have improved LLMs' security, they often lead to conservative,
rejection-oriented responses that compromise practical usability. This presents
a key challenge: how to advance the Pareto frontier between LLMs' usability and
security, rather than necessitate a trade-off between them. To address this, we
propose the MoGU framework, in which the intra-layer router dynamically
allocates weights by sensing hidden states, thereby balancing the contributions
of security-optimized and usability-optimized variants. Despite its initial
potential, the MoGU framework faces limitations such as parameter redundancy
and performance bottlenecks. To overcome these, we further propose an improved
MoGU_v2 framework that establishes a tighter coupling between the routers and
hidden states. In MoGU_v2, routers are embedded only in layers encoding highly
classifiable security features, and backbone modules are activated during
router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong
adaptability and stable improvements across various series of LLMs, including
mainstream LLMs serving as brains in various applications, on-device LLMs
optimized for resource-constrained scenarios, and reasoning LLMs tailored for
user interpretability. Meanwhile, even facing risks introduced by Instruction
Fine-tuning, MoGU_v2 can easily restore security without compromising the task
performance gains via a simple data-mix strategy. These comprehensive
improvements highlight MoGU_V2 as a robust and versatile solution for
mitigating security risks in real-world applications.

</details>


### [221] [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem](https://arxiv.org/abs/2509.06809)
*Valentin Quesnel,Damien Sileo*

Main category: cs.CL

TL;DR: 本研究通过利用自动定理证明（ATP）来生成大规模、无误的数学推理数据集，解决了大型语言模型（LLM）在数学推理方面的数据瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在数学推理方面缺乏高质量、逻辑严谨的数据，制约了其发展。

Method: 利用E-prover的饱和能力和TPTP公理库生成大规模、验证过的定理语料库，并将其转化为包含蕴含验证、前提选择和证明重构三个难度控制的任务。整个过程不依赖LLM，消除了事实性错误。

Result: 在对前沿模型进行的零样本实验中，模型在需要深度结构推理的任务上表现不佳，暴露了其固有弱点。

Conclusion: 本研究提出的框架不仅能诊断LLM在数学推理方面的差距，还能提供大规模符号训练数据来解决这一问题。

Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

</details>


### [222] [A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs](https://arxiv.org/abs/2509.06813)
*Max Malyi,Jonathan Shek,Alasdair McDonald,Andre Biscaya*

Main category: cs.CL

TL;DR: 本研究提出了一个用于评估大型语言模型（LLM）在风力涡轮机维护日志分类任务上表现的框架，并公开了该框架。研究评估了多种LLM，发现其性能存在差异，并指出在语义歧义性高的任务上，模型表现不佳。最终结论是，在近期内，结合人类专家的“人机环”系统是利用LLM提高运维数据质量和可靠性分析的最有效和负责任的方式。


<details>
  <summary>Details</summary>
Motivation: 风力发电的有效运维对降低其度电成本至关重要，但维护日志的自由文本性质阻碍了自动化分析。因此，需要一个评估大型语言模型（LLM）在该任务上表现的框架。

Method: 提出一个新颖且可复现的框架，用于对大型语言模型（LLM）在分类风力涡轮机维护日志的任务上进行基准测试，并将其开源。系统地评估了一系列先进的专有和开源LLM。

Result: 研究结果量化了一个明确的性能层级，确定了与基准标准高度一致且具有可信赖、校准良好的置信分数的顶级模型。研究还表明，分类性能高度依赖于任务的语义歧义性，模型在客观部件识别上比在解释性维护动作上表现出更高的一致性。

Conclusion: 由于没有模型能达到完美准确率，且校准度差异很大，因此结论认为，近期最有效和最负责任的应用是“人机环”系统，其中LLM作为强大的助手，加速和标准化数据标注，以供人类专家使用，从而提高运维数据质量和下游可靠性分析。

Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

</details>


### [223] [COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens](https://arxiv.org/abs/2509.06836)
*Eugene Kwek,Wenpeng Yin*

Main category: cs.CL

TL;DR: COMPACT通过联合剪枝稀有词汇和FFN中间通道来提高LLM的效率，同时保持标准的Transformer架构，并在多种模型上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在内存、延迟和推理成本方面提高LLM的效率，以适应边缘部署、交互式应用和大规模可持续推理的需求，剪枝是一种关键技术。然而，现有的剪枝方法存在局限性：宽度剪枝会破坏标准的Transformer布局或需要自定义推理代码，而深度剪枝会移除整个层并可能导致准确性突然下降。

Method: COMPACT联合进行两项剪枝操作：(i) 剪枝稀有词汇以缩小嵌入/解嵌入层；(ii) 使用常见词汇激活来加权剪枝FFN中间通道，使重要性与剪枝后的词汇分布保持一致。

Result: 在Qwen、LLaMA和Gemma系列模型（0.5B-70B）上的实验表明，COMPACT在相似或更高的剪枝率下，在下游任务上的表现达到了最先进水平，同时显著减少了参数量、GPU内存占用和端到端延迟。

Conclusion: COMPACT结合了深度和宽度剪枝的优点，具有部署友好性、可扩展性、无需额外训练且剪枝时间有竞争力等优势，并能在提高内存节省和吞吐量的同时，实现最先进的性能。

Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial
for edge deployment, interactive applications, and sustainable inference at
scale. Pruning is a key technique toward this goal. However, prior pruning
methods are limited: width pruning often breaks the standard transformer layout
or requires custom inference code, while depth pruning removes entire layers
and can cause abrupt accuracy drops. In this work, we propose COMPACT, which
jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)
prunes FFN intermediate channels using common-token-weighted activations,
aligning importance with the post-pruning token distribution. COMPACT enjoys
merits of both depth and width pruning, such as: deployment-friendliness (keeps
a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN
pruning), training-free operation with competitive pruning time, and strong
memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and
Gemma families (0.5B-70B) show state-of-the-art downstream task performance at
similar or higher pruning ratios, with substantial reductions in parameters,
GPU memory, and end-to-end latency.

</details>


### [224] [EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models](https://arxiv.org/abs/2509.06838)
*Mohammad Reza Mirbagheri,Mohammad Mahdi Mirkamali,Zahra Motoshaker Arani,Ali Javeri,Amir Mahdi Sadeghzadeh,Rasool Jalili*

Main category: cs.CL

TL;DR: 本研究提出了EPT（Evaluation of Persian Trustworthiness）指标，一个针对波斯语的、包含六个关键维度（真实性、安全性、公平性、鲁棒性、隐私和道德一致性）的LLM可信度评估基准。通过对ChatGPT、Claude、DeepSeek、Gemini、Grok、LLaMA、Mistral和Qwen等主流模型进行评估，结果显示模型在安全性方面存在显著不足，并揭示了模型在符合波斯文化价值观方面存在的差距。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLMs）的可信度对于AI的准确性、伦理、文化和社会价值至关重要。现有评估方法可能无法充分考虑特定文化背景下的模型行为。

Method: 开发并应用EPT（Evaluation of Persian Trustworthiness）指标，该指标包含真实性、安全性、公平性、鲁棒性、隐私和道德一致性六个维度。使用自动LLM评估和人工评估相结合的方式，对ChatGPT、Claude、DeepSeek、Gemini、Grok、LLaMA、Mistral和Qwen等多个领先模型进行了评估。构建并公开了一个标记好的数据集。

Result: 在对多个主流LLMs的评估中，发现在安全性维度上存在显著的不足。研究结果为理解这些模型如何与波斯伦理文化价值观保持一致提供了有价值的见解，并指出了在开发可信赖和具有文化责任感的AI方面的关键差距和机遇。

Conclusion: 当前的LLMs在安全性方面需要重点改进，以满足可信赖AI的要求。EPT指标为评估和改进LLMs在特定文化背景（如波斯语环境）下的可信度提供了一个有用的工具，强调了在AI发展中融入文化敏感性和伦理考量的必要性。

Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced
deep learning architectures, have demonstrated remarkable performance across a
wide range of language tasks, becoming a cornerstone of modern AI technologies.
However, ensuring their trustworthiness remains a critical challenge, as
reliability is essential not only for accurate performance but also for
upholding ethical, cultural, and social values. Careful alignment of training
data and culturally grounded evaluation criteria are vital for developing
responsible AI systems. In this study, we introduce the EPT (Evaluation of
Persian Trustworthiness) metric, a culturally informed benchmark specifically
designed to assess the trustworthiness of LLMs across six key aspects:
truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We
curated a labeled dataset and evaluated the performance of several leading
models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and
Qwen - using both automated LLM-based and human assessments. Our results reveal
significant deficiencies in the safety dimension, underscoring the urgent need
for focused attention on this critical aspect of model behavior. Furthermore,
our findings offer valuable insights into the alignment of these models with
Persian ethical-cultural values and highlight critical gaps and opportunities
for advancing trustworthy and culturally responsible AI. The dataset is
publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

</details>


### [225] [The Majority is not always right: RL training for solution aggregation](https://arxiv.org/abs/2509.06870)
*Wenting Zhao,Pranjal Aggarwal,Swarnadeep Saha,Asli Celikyilmaz,Jason Weston,Ilia Kulikov*

Main category: cs.CL

TL;DR: 通过学习显式推理技能来聚合多个LLM解决方案，以提高推理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理方法（如投票或奖励模型排序）收益有限，本文旨在学习显式推理技能来聚合解决方案。

Method: 训练一个聚合器模型，利用可验证奖励进行强化学习，以审查、协调和综合最终的正确答案，并仔细平衡训练样本的难易程度。

Result: AggLM在多个基准测试中表现优于基线方法，能够处理不同模型的解决方案，并比多数投票方法使用更少的token。

Conclusion: AggLM通过学习显式推理技能，有效地提高了LLM在推理任务上的表现，并具有良好的泛化能力和效率。

Abstract: Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

</details>


### [226] [UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction](https://arxiv.org/abs/2509.06883)
*Joe Wilder,Nikhil Kadapala,Benji Xu,Mohammed Alsaadi,Aiden Parsons,Mitchell Rogers,Palash Agarwal,Adam Hassick,Laura Dietz*

Main category: cs.CL

TL;DR: 使用FLAN-T5模型进行微调，在CheckThat! Task 2英语任务中提取了社交媒体上的可核查声明。


<details>
  <summary>Details</summary>
Motivation: 探索各种提示和上下文学习方法（包括少样本提示和不同LLM家族的微调），以从社交媒体段落中提取可核查的声明。

Method: 评估了不同的提示和上下文学习方法，包括少样本提示和不同LLM家族的微调。

Result: 通过微调FLAN-T5模型取得了最高的METEOR分数，但也观察到其他方法的提取结果质量有时更高，尽管METEOR分数较低。

Conclusion: 虽然微调FLAN-T5模型在METEOR分数上表现最佳，但其他方法有时也能提取出更高质量的声明，表明需要更全面的评估指标。

Abstract: We participate in CheckThat! Task 2 English and explore various methods of
prompting and in-context learning, including few-shot prompting and fine-tuning
with different LLM families, with the goal of extracting check-worthy claims
from social media passages. Our best METEOR score is achieved by fine-tuning a
FLAN-T5 model. However, we observe that higher-quality claims can sometimes be
extracted using other methods, even when their METEOR scores are lower.

</details>


### [227] [mmBERT: A Modern Multilingual Encoder with Annealed Language Learning](https://arxiv.org/abs/2509.06888)
*Marc Marone,Orion Weller,William Fleshman,Eugene Yang,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: mmBERT是一个新提出的多语言编码器模型，在1800多种语言的3T语料上进行预训练，通过引入逆掩码比例和逆温度采样比例等新方法，显著提升了在多语言分类和检索任务上的表现，尤其是在低资源语言方面。


<details>
  <summary>Details</summary>
Motivation: 现有编码器模型在多语言任务上的研究较少，特别是低资源语言的提升空间大。

Method: 1. 预训练mmBERT模型，使用3T多语言文本，覆盖1800多种语言。 2. 引入逆掩码比例（inverse mask ratio schedule）和逆温度采样比例（inverse temperature sampling ratio）。 3. 在预训练的衰减阶段加入1700多种低资源语言。

Result: 在分类任务上，mmBERT的性能与OpenAI的o3和Google的Gemini 2.5 Pro相当。在多语言分类和检索任务上，mmBERT显著优于上一代模型，尤其在低资源语言上的表现提升明显。

Conclusion: mmBERT通过创新的预训练策略，有效提升了多语言编码器模型在包括低资源语言在内的各种下游任务上的性能。

Abstract: Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

</details>


### [228] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: LLM可能会产生与可用数据不符的数字，称为“数字幻觉”。现有的安全措施（如检索增强生成、引用和不确定性估计）可以提高透明度，但不能保证准确性。我们提出了Proof-Carrying Numbers（PCN），这是一种通过机械验证来强制执行数字准确性的表示层协议。在PCN下，数字范围被发出为与结构化声明绑定的“声明绑定令牌”，验证器根据声明的策略（如精确相等、舍入、别名或带限定符的容差）检查每个令牌。关键是，PCN将验证放在渲染器而不是模型中：只有经过声明检查的数字才会被标记为已验证，所有其他数字默认未经验证。这种分离可以防止欺骗并保证故障保护行为。我们形式化了PCN，并证明了其在声明令牌诚实时、声明令牌不诚实时、故障保护行为和策略精炼下的单调性。PCN轻量级且与模型无关，可以无缝集成到现有应用程序中，并且可以通过加密承诺进行扩展。通过强制执行验证作为显示之前的强制步骤，PCN为数值敏感的设置建立了一个简单的合同：信任只能通过证据获得，而标记的缺失则传达了不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的安全措施（如检索增强生成、引用和不确定性估计）可以提高LLM生成数字的透明度，但不能保证准确性，因为伪造或错误引用的值仍可能被显示为正确。因此，需要一种新的方法来强制执行数字准确性。

Method: 提出了一种名为Proof-Carrying Numbers（PCN）的表示层协议。在该协议下，数字范围被表示为与结构化声明绑定的“声明绑定令牌”。验证器根据声明的策略（如精确相等、舍入、别名或带限定符的容差）检查每个令牌。验证过程由渲染器执行，而不是模型本身。只有经过声明检查的数字才会被标记为已验证，所有其他数字默认未经验证。

Result: PCN可以防止数字欺骗并保证故障保护行为。该协议是轻量级的、与模型无关的，可以无缝集成到现有应用程序中，并且可以通过加密承诺进行扩展。PCN在声明令牌诚实时、声明令牌不实时、故障保护行为和策略精炼下被证明是健全、完整和单调的。

Conclusion: PCN通过强制执行验证作为显示之前的强制步骤，为数值敏感的设置建立了一个简单的合同：信任只能通过证据获得，而标记的缺失则传达了不确定性。它通过将验证分离到渲染器并确保只有经过检查的数字才被标记为已验证，从而解决了LLM的数字幻觉问题。

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


### [229] [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)
*Liang Chen,Xueting Han,Li Shen,Jing Bai,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 通过引入双层优化，使SFT（监督微调）和RL（强化学习）的训练范式更好地协同工作，从而提高了LLM（大语言模型）推理的效率和效果。


<details>
  <summary>Details</summary>
Motivation: RL在激励LLM推理能力方面卓有成效，但其固有的试错性质带来了严峻的效率挑战。虽然通常采用SFT作为RL的热身阶段，但这种分离的两阶段方法限制了SFT和RL之间的互动，从而制约了整体效果。

Method: 提出一种新颖的学习推理模型的方法，采用双层优化机制，促进SFT和RL训练范式之间的协同。通过将SFT目标条件化于最优RL策略，使得SFT能够元学习如何指导RL的优化过程。在训练过程中，下层在接收SFT监督的同时执行RL更新，上层则显式地最大化协同收益（联合SFT-RL训练相对于单独RL的性能优势）。

Result: 在五个推理基准上的实证评估表明，该方法在效果和效率方面持续优于基线方法，并实现了更好的平衡。

Conclusion: 所提出的双层优化方法能够有效地整合SFT和RL训练范式，克服了传统两阶段方法的局限性，提高了LLM在推理任务上的表现和训练效率。

Abstract: Reinforcement learning (RL) has proven effective in incentivizing the
reasoning abilities of large language models (LLMs), but suffers from severe
efficiency challenges due to its trial-and-error nature. While the common
practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this
decoupled two-stage approach limits interaction between SFT and RL, thereby
constraining overall effectiveness. This study introduces a novel method for
learning reasoning models that employs bilevel optimization to facilitate
better cooperation between these training paradigms. By conditioning the SFT
objective on the optimal RL policy, our approach enables SFT to meta-learn how
to guide RL's optimization process. During training, the lower level performs
RL updates while simultaneously receiving SFT supervision, and the upper level
explicitly maximizes the cooperative gain-the performance advantage of joint
SFT-RL training over RL alone. Empirical evaluations on five reasoning
benchmarks demonstrate that our method consistently outperforms baselines and
achieves a better balance between effectiveness and efficiency.

</details>


### [230] [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)
*Yinjie Wang,Ling Yang,Bowen Li,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: TraceRL是一个用于扩散语言模型（DLM）的轨迹感知强化学习框架，通过在训练后整合首选推理轨迹，并适用于不同架构。它使用基于扩散的值模型提高训练稳定性，并在复杂的数学和编码任务上展现出改进的推理性能。此外，它还可以应用于将块特定的模型适配到更大的块，从而提高采样灵活性。使用TraceRL，我们得到了一系列最先进的扩散语言模型，即TraDo。尽管TraDo-4B-Instruct的规模小于7B规模的AR模型，但在复杂的数学推理任务上，其性能始终优于它们。在数学推理基准测试中，TraDo-8B-Instruct的相对准确度比Qwen2.5-7B-Instruct提高了6.1%，比Llama3.1-8B-Instruct提高了51.3%。通过课程学习，我们还得到了第一个长思维链（long-CoT）DLM，在MATH500基准测试中，其相对准确度比Qwen2.5-7B-Instruct提高了18.1%。为了促进可重复的研究和实际应用，我们发布了一个用于跨不同架构构建、训练和部署扩散语言模型的综合开源框架。该框架集成了推理和强化学习的加速KV缓存技术和推理引擎，并包括用于数学、编码和通用任务的各种监督微调和强化学习方法的实现。


<details>
  <summary>Details</summary>
Motivation: 将首选推理轨迹整合到扩散语言模型（DLM）的训练后阶段，以改进其在复杂推理任务上的性能，并提高采样灵活性。

Method: 提出TraceRL框架，该框架具有基于扩散的值模型，用于在训练后整合首选推理轨迹，并适用于不同架构。通过课程学习衍生出长思维链DLM。

Result: TraceRL框架能够改进DLM的推理性能，TraDo模型在数学和编码任务上表现出色。TraDo-4B-Instruct在数学推理任务上优于7B规模的AR模型。TraDo-8B-Instruct在数学推理任务上，相比Qwen2.5-7B-Instruct和Llama3.1-8B-Instruct，准确度分别提高了6.1%和51.3%。长思维链DLM在MATH500基准测试中，相比Qwen2.5-7B-Instruct，准确度提高了18.1%。

Conclusion: TraceRL是一个有效的框架，可以提高扩散语言模型的性能，并且可以用于生成不同规模和能力的模型。该研究还发布了一个开源框架，以促进DLM的研究和应用。

Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

</details>


### [231] [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](https://arxiv.org/abs/2509.06952)
*Linlu Qiu,Cedegao E. Zhang,Joshua B. Tenenbaum,Yoon Kim,Roger P. Levy*

Main category: cs.CL

TL;DR: 大型语言模型（LMs）在理解和生成语言方面展现出不同的能力，尤其是在涉及语用推理时。虽然最先进的模型在语言理解方面表现出色，但它们在语言生成方面仍有改进空间，尤其是在引入贝叶斯语用推理（RSA）后。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地被用作对话代理，理解它们在语用推理方面的能力变得至关重要。

Method: 提出一个基于Wavelength交流游戏的评估框架，研究不同规模的语言模型在语言理解和生成方面的能力，并探索了直接提示、思维链（CoT）提示以及贝叶斯语用推理（RSA）方法。

Result: 在语言理解方面，最先进的模型表现良好，准确率接近人类水平，并且不需要CoT或RSA就能与人类判断高度相关。在语言生成方面，CoT提示优于直接提示，而RSA则在两者之上都取得了显著的改进。

Conclusion: 最先进的语言模型在语用推理方面存在优势和局限性。RSA有潜力改善这些模型的表现，并为未来理解语言模型和人类的概念表征、语言理解和社会推理开辟了新的途径。

Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [232] [Modifying the Optical Emission of Vanadyl Phthalocyanine via Molecular Self-Assembly on van der Waals Materials](https://arxiv.org/abs/2509.05438)
*S. Carin Gavin,William Koll,Moumita Kar,Yiying Liu,Anushka Dasgupta,Ethan Garvey,Thomas W. Song,Chunxi Zhou,Brendan P. Kerwin,Jash Jain,Tobin J. Marks,Mark C. Hersam,George C. Schatz,Jay A. Gupta,Nathaniel P. Stern*

Main category: cond-mat.mtrl-sci

TL;DR: 范酰基酞菁（VOPc）作为一种有潜力的有机分子，在量子信息领域备受关注。该研究通过在范德华材料基底上可控沉积VOPc薄膜，成功实现了其主要光学跃迁的显著偏移（超过250 meV），这与以往在介电基底上得到的结果不同。这种光学特性的改变归因于VOPc分子与范德华材料之间的弱相互作用，促使分子进行独特的自组装，并调制了分子物相和厚度，进而影响了电子结构和光学发射。


<details>
  <summary>Details</summary>
Motivation: 尽管范酰基酞菁（VOPc）因其热稳定性、易加工性和作为自旋量子比特的潜力而在量子信息领域具有应用前景，但目前对其在不同分子取向下沉积以定制其性质的研究尚未充分发掘，特别是在光学发射方面。以往的研究通常在介电基底上观察到VOPc的近红外光致发光，其性质有待进一步调控。

Method: 本研究采用在范德华材料基底上可控沉积范酰基酞菁（VOPc）薄膜的方法，以探索其光学性质的变化。通过调控VOPc的沉积过程，研究了其分子取向、物相和厚度对光学发射的影响。

Result: 研究发现，与在介电基底上观察到的情况不同，在范德华材料基底上沉积的VOPc薄膜，其主要光学跃迁可以移动超过250 meV。这种光学行为的改变与VOPc分子的自组装行为以及范德华材料的弱相互作用有关，并且受到分子物相和厚度的调节。

Conclusion: 该研究成功地将分子的自组装特性与其电子结构的改变以及由此产生的光学发射联系起来。通过在范德华材料基底上进行可控沉积，实现了VOPc光学发射特性的调控，为利用VOPc分子构建定制化光电器件提供了新的思路。

Abstract: Vanadyl phthalocyanine (VOPc) is a promising organic molecule for
applications in quantum information because of its thermal stability, efficient
processing, and potential as a spin qubit. The deposition of VOPc in different
molecular orientations allows the properties to be customized for integration
into various devices. However, such customization has yet to be fully leveraged
to alter its intrinsic properties, particularly optical emission. Normally,
VOPc films on dielectric substrates emit a broad photoluminescence peak in the
near-infrared range, attributed to transitions in the Pc ring from its pi
orbital structure. In this work, we demonstrate that the dominant optical
transition of VOPc can be shifted by over 250 meV through the controlled
deposition of thin films on van der Waals material substrates. The weak
interactions with van der Waals materials allow the molecules to uniquely
self-assemble, resulting in modified optical behavior modulated by molecular
phase and thickness. This work connects the self-assembling properties of
molecules with their altered electronic structures and the resulting optical
emission.

</details>


### [233] [Accelerated Design of Mechanically Hard Magnetically Soft High-entropy Alloys via Multi-objective Bayesian Optimization](https://arxiv.org/abs/2509.05702)
*Mian Dai,Yixuan Zhang,Weijia He,Chen Shen,Xiaoqing Li,Stephan Schönecker,Liuliu Han,Ruiwen Xie,Tianhang Zhou,Hongbin Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过多目标贝叶斯优化（MOBO）框架设计兼具高硬度和软磁特性的高熵合金，并识别出满足双重设计目标的成分。


<details>
  <summary>Details</summary>
Motivation: 设计同时具备高硬度和软磁特性的高熵合金（HEAs）面临机械和磁性能之间的固有权衡挑战。

Method: 采用多目标贝叶斯优化（MOBO）框架，结合集成代理模型和蒙特卡洛采样与获取函数相结合的采样策略，以优化高熵合金成分。

Result: 成功识别出具有增强的机械和磁性能的帕累托最优成分，其中集成模型提供了稳健可靠的预测，采样方法降低了陷入局部最优的可能性。

Conclusion: 所提出的MOBO策略能够有效识别出同时满足高机械硬度和软磁性能要求的高熵合金成分，为下一代高熵合金的合成提供了指导。

Abstract: Designing high-entropy alloys (HEAs) that are both mechanically hard and
possess soft magnetic properties is inherently challenging, as a trade-off is
needed for mechanical and magnetic properties. In this study, we optimize HEA
compositions using a multi-objective Bayesian optimization (MOBO) framework to
achieve simultaneous optimal mechanical and magnetic properties. An ensemble
surrogate model is constructed to enhance the accuracy of machine learning
surrogate models, while an efficient sampling strategy combining Monte Carlo
sampling and acquisition function is applied to explore the high-dimensional
compositional space. The implemented MOBO strategy successfully identifies
Pareto-optimal compositions with enhanced mechanical and magnetic properties.
The ensemble model provides robust and reliable predictions, and the sampling
approach reduces the likelihood of entrapment in local optima. Our findings
highlight specific elemental combinations that meet the dual design objectives,
offering guidance for the synthesis of next-generation HEAs.

</details>


### [234] [Unveiling the critical factors in crystal structure graph representation: a comparative analysis using streamlined MLPSets frameworks](https://arxiv.org/abs/2509.05712)
*Hongwei Du,Hong Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 数据驱动的图表示方法在材料科学中超越了基于物理的方法，特别是在处理电子相互作用、对称性和长程相互作用方面，显著提高了预测精度和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络模型在材料科学和化学领域虽然取得了进展，但在表示电子相互作用、对称性和长程信息方面存在局限性，需要更全面的结构表示方法。

Method: 比较了基于物理的位点特征计算器和数据驱动的图表示策略。数据驱动方法利用了变分自编码器（VAEs）来压缩Kohn-Sham波函数，并结合了多任务学习。将CHGNet-V1/V2策略集成到DenseGNN模型中，并采用了预训练和微调策略。

Result: 数据驱动的图表示策略在表示完整性、收敛速度和外推能力方面表现更优。集成了CHGNet-V1/V2的DenseGNN模型在35个Matbench和JARVIS-DFT数据集上显著优于现有模型，预测精度接近DFT计算。预训练和微调策略能有效降低复杂无序材料带隙预测的误差。

Conclusion: 数据驱动的图表示方法，特别是结合了电子结构生成模型和多任务学习的策略，在材料科学中具有优越性和巨大潜力，能够加速材料发现过程。

Abstract: Graph Neural Networks have rapidly advanced in materials science and
chemistry,with their performance critically dependent on comprehensive
representations of crystal or molecular structures across five dimensions:
elemental information, geometric topology, electronic interactions, symmetry,
and long-range interactions. Existing models still exhibit limitations in
representing electronic interactions, symmetry, and long-range information.
This study compares physics-based site feature calculators with data-driven
graph representation strategies. We find that the latter achieve superior
performance in representation completeness, convergence speed, and
extrapolation capability by incorporating electronic structure generation
models-such as variational autoencoders (VAEs) that compress Kohn-Sham wave
functions and leveraging multi-task learning. Notably, the CHGNet-V1/V2
strategies, when integrated into the DenseGNN model,significantly outperform
state-of-the-art models across 35 datasets from Matbench and JARVIS-DFT,
yielding predictions with accuracy close to that of DFT calculations.
Furthermore, applying a pre-training and fine-tuning strategy substantially
reduces the prediction error for band gaps of complex disordered materials,
demonstrating the superiority and potential of data-driven graph
representations in accelerating materials discovery.

</details>


### [235] [Depth Profiling of Oxygen Migration in Ta/HfO2 Stacks During Ionic Liquid Gating](https://arxiv.org/abs/2509.05748)
*Beatrice Bednarz,Martin Wortmann,Olga Kuschel,Fabian Kammerbauer,Mathias Kläui,Andreas Hütten,Joachim Wollschläger,Gerhard Jakob,Timo Kuschel*

Main category: cond-mat.mtrl-sci

TL;DR: IL 门控技术通过驱动固-固界面离子运动来控制材料的结构、电子、光学和磁性。在本研究中，我们量化了 Si/SiO2/Ta(15)/HfO2(t) 薄膜在 IL 门控后的氧深度分布和氧化物形成，并研究了其与门电压和 HfO2 覆盖层厚度的关系。结果表明，需要~-2.8 MV/cm 的阈值电场才能启动 HfO2 中的氧迁移到 Ta 金属中。Ta2O5 的厚度随门电压线性增加，在 -3 V 门控下达到 4 nm。较薄的覆盖层会增强氧化。此外，还观察到 In 从 ITO 电极迁移到样品表面的现象。


<details>
  <summary>Details</summary>
Motivation: 研究 IL 门控在磁性离子系统中氧分布和电压依赖性的空间分布和电压依赖性，以实现精确稳定的控制。

Method: 使用 X 射线反射率和 X 射线光电子能谱测量，研究了 Si/SiO2/Ta(15)/HfO2(t) 薄膜在 IL 门控后的氧深度分布和氧化物形成，并研究了其与门电压和 HfO2 覆盖层厚度的关系。

Result: 在 Si/SiO2/Ta(15)/HfO2(t) 薄膜中，需要~-2.8 MV/cm 的阈值电场才能启动 HfO2 中的氧迁移到 Ta 金属中。Ta2O5 的厚度随门电压线性增加，在 -3 V 门控下达到 4 nm。厚氧化层需要更高的电场。Ta/Ta2O5 界面保持原子尺度清晰。较薄的覆盖层会增强氧化。观察到 In 从 ITO 电极迁移到样品表面。

Conclusion: 本研究的见解有助于磁性离子和纳米离子器件的设计，这些器件需要精确的界面工程。

Abstract: Ionic liquid (IL) gating has emerged as a powerful tool to control the
structural, electronic, optical, and magnetic properties of materials by
driving ion motion at solid interfaces. In magneto-ionic systems, electric
fields are used to move ions, typically oxygen, from a donor layer into an
underlying magnetic metal. Although oxygen distribution is key to enabling
precise and stable control in magneto-ionic systems, the spatial distribution
and voltage-dependence of oxygen incorporation in such nanoscale stacks remain
unknown. Here, we quantify oxygen depth profiles and oxide formation in Si/
SiO2/ Ta (15)/ HfO2 (t) films after IL gating as a function of the gate voltage
and HfO2 capping thickness (2 and 3 nm). X-ray reflectivity and X-ray
photoelectron spectroscopy measurements revealed a threshold electric field of
~ -2.8 MV/cm to initiate oxygen migration from HfO2 into metallic Ta. The
resulting Ta2O5 thickness increases linearly with gate voltage, reaching up to
4 nm at -3 V gating. Notably, the required electric field rises with oxide
thickness, indicating a progressively growing barrier for thicker oxide films.
The Ta/Ta2O5 interface remains atomically sharp for all gate voltages. This
suggests that complete Ta2O5 layers form sequentially before further oxygen
penetration, with no sign of deeper diffusion into bulk Ta. Thinner capping
layers enhance oxidation, relevant for optimized stack design. Additionally,
indium migration from the indium tin oxide electrode to the sample surface was
observed, which should be considered for surface-sensitive applications. These
insights advance design principles for magneto-ionic and nanoionic devices
requiring precise interface engineering.

</details>


### [236] [Machine learning magnetism from simple global descriptors](https://arxiv.org/abs/2509.05909)
*Ahmed E. Fahmy*

Main category: cond-mat.mtrl-sci

TL;DR: 通过机器学习模型提高磁性材料数据库的可靠性，解决DFT易收敛到铁磁性的问题。


<details>
  <summary>Details</summary>
Motivation: 解决高通量材料数据库中准确识别磁性基态的挑战，特别是密度泛函理论（DFT）工作流易收敛到铁磁性（FM）解的问题。

Method: 开发基于实验验证的MAGNDATA磁性材料的机器学习分类器，使用来自Materials Project数据库的有限的简单成分、结构和电子描述符。重点介绍了传播向量分类器，并比较了LightGBM和XGBoost模型。

Result: 传播向量分类器准确率超过92%，优于近期研究；发现Materials Project数据库对超过7843种材料存在系统性的铁磁偏倚。LightGBM和XGBoost模型准确率为84-86%，宏观F1分数（平均）为63-66%。

Conclusion: 机器学习技术可作为纠正性和探索性工具，用于提高数据库的可靠性，并通过区分零传播向量和非零传播向量结构来加速具有不同性质的材料的发现。

Abstract: The reliable identification of magnetic ground states remains a major
challenge in high-throughput materials databases, where density functional
theory (DFT) workflows often converge to ferromagnetic (FM) solutions. Here, we
partially address this challenge by developing machine learning classifiers
trained on experimentally validated MAGNDATA magnetic materials leveraging a
limited number of simple compositional, structural, and electronic descriptors
sourced from the Materials Project database. Our propagation vector classifiers
achieve accuracies above 92%, outperforming recent studies in reliably
distinguishing zero from nonzero propagation vector structures, and exposing a
systematic ferromagnetic bias inherent to the Materials Project database for
more than 7,843 materials. In parallel, LightGBM and XGBoost models trained
directly on the Materials Project labels achieve accuracies of 84-86% (with
macro F1 average scores of 63-66%), which proves useful for large-scale
screening for magnetic classes, if refined by MAGNDATA-trained classifiers.
These results underscore the role of machine learning techniques as corrective
and exploratory tools, enabling more trustworthy databases and accelerating
progress toward the identification of materials with various properties.

</details>


### [237] [Skyrmion manipulation and logic gate functionality in transition metal multilayers](https://arxiv.org/abs/2509.05951)
*Tamali Mukherjee,V Satya Narayana Murthy,Banasree Sadhukhan*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用微磁模拟，研究了PdFe/Ir(111)多层纳米结构中磁斯格明子的形成、动力学以及逻辑门操作。


<details>
  <summary>Details</summary>
Motivation: 为了推进斯格明子在自旋电子器件中的应用，有必要详细了解其成核和电流驱动动力学。

Method: 本研究采用微磁模拟，研究了不同类型的自旋转移矩（STT）、电压控制磁各向异性以及外部磁场对磁斯格明子动力学的影响，并实现了基于斯格明子的逻辑门操作。

Result: 研究表明，对于Slonczewski型STT，PdFe/Ir(111)多层结构中的斯格明子霍尔角为89.53°，有利于斯格明子在纳米结构边缘的累积；对于Zhang-Li型STT，斯格明子霍尔角为3.26°，斯格明子主要沿电流方向传播。此外，研究还实现了基于斯格明子的OR和AND逻辑门操作。

Conclusion: 磁斯格明子由于其拓扑稳定性和高迁移率，是自旋电子器件中信息载体的重要候选者。通过精确控制其动力学，可以实现逻辑运算，为未来的信息处理技术提供了新的可能性。

Abstract: Magnetic skyrmions, due to their topological stability and high mobility, are
strong candidates for information carriers in spintronic devices. To advance
their practical applications, a detailed understanding of their nucleation and
current-driven dynamics is essential. We investigate the formation and
manipulation of skyrmions in a square nano structure (200 $\times$ 200
nm$^{2}$, 1 nm thick) of PdFe/Ir(111) multilayers subjected to nano second
current pulses with magnitude ranging from (1-5)$\times$10$^{11}$ A/m$^2$.
Using micromagnetic simulations, we demonstrate controlled motion of skyrmion
under different types of spin-transfer torque (STT). The calculated skyrmion
Hall angle (SkH) for Slonczewski type STT is ${\theta_{SkH}^{SL}} =
89.53^{\circ}$ for PdFe/Ir(111) multilayers which ensures the edge accululation
of skyrmion like a track within the nano structure and we extend this idea
further for different shape engineering of skyrmion in 4d tranisition metal
multilayers by manipulating the magnitude and direction of current pulses.
Next, we investigate the influence of voltage-controlled magnetic anisotropy
ranging from (1.4 - 4.2) $\times$ 10$^6$ J/m$^3$ with external magnetic field
B$_{ext}$ = 2 T, and (0 - 2.8) $\times$ 10$^6$ J/m$^3$ with B$_{ext}$ = 3 T
respectively, on skyrmion dynamics for designing anisotropy-engineered barriers
to guide their trajectories in PdFe/Ir(111) multilayers. We use further these
barriers to implement basic logic operations, including OR and AND gates, with
skyrmions representing binary states. The calculatd skyrmion Hall angle for
Zhang-Li type STT in PdFe/Ir(111) multilayers is ${\theta_{SkH}^{ZL}} =
3.26^{\circ}$. Consequently, the skyrmions propagate predominantly along the
direction of the applied current with minimal deflection, a feature that
renders them highly suitable for logic operations.

</details>


### [238] [Intrinsic Topological Dice Flat Band in Yttrium Monochloride Electrides](https://arxiv.org/abs/2509.05958)
*Jianqi Zhong,Songyuan Geng,Haoxiang Li,Benjamin T. Zhou*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In a recent experiment [arXiv:2508.21311] the long-sought dice lattice and
its characteristic flat band has been discovered for the first time in the
two-dimensional layered electride yttrium monochloride (YCl), in which the
interstitial anionic electrons of the electride self-organize into a dice
lattice geometry. In this Letter, combining symmetry analysis, relativistic
density-functional theory and realistic tight-binding model calculations, we
predict that the dice flat band in YCl is intrinsically topological and
characterized by a high Chern number of $\mathcal{C} = \pm 4$. In particular,
the intrinsic atomic spin-orbit coupling (SOC) from $4d$-electrons of yttrium
atoms creates topological gaps on the scale of 20 meV near $\pm K$ and leads to
the emergence of nontrivial Berry curvatures and band topology. Displacement
fields applied across the layered electride architecture can easily drive
topological phase transitions. Our findings establish the newly discovered YCl
electride as the first natural material hosting a dice flat Chern band without
any extrinsic band engineering.

</details>


### [239] [Extracting Phonon Quasiparticles from Molecular Dynamics Simulations](https://arxiv.org/abs/2509.05960)
*Wenjing Li,Yong Lu,Fawei Zheng*

Main category: cond-mat.mtrl-sci

TL;DR: Phonon anharmonicity causes finite phonon lifetimes, crucial for thermal properties and phase stability. This paper defines optimal phonon quasiparticles by maximizing lifetimes, shows their properties are in matrices $\mathcal{S}$ and $\mathcal{Q}$ from molecular dynamics, and proposes an efficient method to calculate temperature-dependent phonon modes, frequencies, and lifetimes. Applied to silicon and cubic CaSiO$_3$, it reveals phonon behaviors and softening in CaSiO$_3$. This theory can be extended to other quasiparticles.


<details>
  <summary>Details</summary>
Motivation: Phonon anharmonicity is ubiquitous and affects material properties. Understanding phonon quasiparticles, especially those with maximized lifetimes, is crucial.

Method: Defined optimal phonon quasiparticles as those maximizing lifetimes. Showed their properties are in matrices $\mathcal{S}$ and $\mathcal{Q}$ derivable from molecular dynamics simulations. Developed an optimization scheme using these matrices to efficiently determine temperature-dependent phonon modes, frequencies, and lifetimes.

Result: Applied the method to silicon and cubic CaSiO$_3$. Revealed temperature-dependent phonon behaviors for both materials. Observed the known phonon softening in cubic CaSiO$_3$.

Conclusion: The proposed method provides an efficient tool for investigating phonon quasiparticles and their temperature-dependent properties. It can be extended to study other quasiparticles like electrons and magnons.

Abstract: Phonon anharmonicity are ubiquitous in real materials, creating finite phonon
lifetimes. These effects are crucial for understanding thermal properties and
phase stability. In this work, we define optimal phonon quasiparticles as those
that maximize their lifetimes, and prove that the information about these
quasiparticles is contained in two small matrices $\mathcal{S}$ and
$\mathcal{Q}$, which can be constructed directly from molecular dynamics
simulations. Based on these knowledge, we proposed an optimization scheme,
which allows us to efficiently determine temperature-dependent phonon modes,
frequencies and lifetimes. We applied this method to silicon and cubic
CaSiO$_3$, revealing their temperature-dependent phonon behaviors and obtaining
the well-known phonon softening in cubic CaSiO$_3$. This theory provides a
convenient tool for investigating phonon quasiparticles and can be extended to
study other quasiparticles, such as electrons and magnons.

</details>


### [240] [Exploring PdCrAs Half-Heusler Alloy for Sustainable Energy Solutions: An Ab-initio Study](https://arxiv.org/abs/2509.05987)
*Rajinder Singh,Shyam Lal Gupta,Sumit Kumar,Lalit Abhilashi,Diwaker,Ashwani Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: PdCrAs合金具有优异的磁性、机械、热电和光学性能，有望在可持续能源领域得到应用。


<details>
  <summary>Details</summary>
Motivation: 研究HH合金PdCrAs的物理性质，探索其在自旋电子学、热电学和光电子学等领域的应用潜力。

Method: 使用全势线性增加平面波（FLAPW）框架下的密度泛函理论（DFT）进行计算。

Result: PdCrAs合金在铁磁相中稳定，具有良好的机械和动力学稳定性。其电子结构显示出半金属特性，带隙为0.670 eV（少数自旋通道）。磁矩符合Slater Pauling规则，材料具有延展性。热力学分析表明其具有良好的韧性。光学性质在可见光和紫外区域有强吸收，具有介电和等离激元特性。热电输运性质表现出高塞贝克系数和可调的ZT值（在300-1500 K下接近0.9）。

Conclusion: PdCrAs是一种有前途的多功能材料，在可持续能源解决方案方面具有应用潜力。

Abstract: This work presents a comprehensive investigation of the HH alloy PdCrAs using
first - principles methods, highlighting its potential applications in various
fields, including spintronics, thermoelectrics, and optoelectronics. We
employed density functional theory (DFT) within the full potential linearized
augmented plane wave (FLAPW) framework. Structural optimizations indicate that
the alloy stabilizes in the ferromagnetic phase. Both mechanical and dynamical
stability have been confirmed through analyses of elastic constants and phonon
dispersion. Our calculations of the electronic band structure and density of
states (DOS) reveal that PdCrAs exhibits half-metallic behavior, with a
spin-polarized band gap of 0.670 eV in the minority spin channel. The magnetic
moment aligns with the Slater Pauling (SP) rule, indicating robust
ferromagnetism. Mechanical analysis shows that the material is ductile in
nature. Thermodynamic analysis highlights the alloy's resilience, supported by
consistent trends in entropy, heat capacity, and Debye temperature.Its optical
response demonstrates strong absorption in the visible and ultraviolet (UV)
regions, along with pronounced dielectric and plasmonic features, suggesting
potential applications in optoelectronics and refracective coatings.
Furthermore, evaluations of the transport properties reveal high Seebeck
coefficients and a significantly tunable figure of merit (ZT), with values
approaching 0.9 across the temperature range of 300 - 1500 K, indicating
excellent thermoelectric characteristics. Overall, these findings position
PdCrAs as a promising multifunctional material suitable sustainable energy
solutions.

</details>


### [241] [Thermoelectric Potential of NaVAs Half-Heusler Alloy: Insights from Ab-initio Calculations](https://arxiv.org/abs/2509.05991)
*Rajinder Singh,Shyam Lal Gupta,Sumit Kumar,Lalit Abhilashi,Diwaker,Ashwani Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: NaVAs是一种具有潜在应用价值的多功能材料，在自旋电子学、热电学和光电子学领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究HH合金NaVAs的潜在应用价值，特别是在自旋电子学、热电学和光电子学领域。

Method: 使用全势线性增强平面波（FLAPW）框架内的密度泛函理论（DFT）方法进行计算。通过弹性常数和声子色散分析来验证机械和动力学稳定性。研究电子能带结构、态密度（DOS）、磁矩、光学响应和输运性质。

Result: NaVAs在铁磁相下稳定，并具有机械和动力学稳定性。其电子能带结构显示出半金属特性，少数自旋通道的磁带隙为2.77 eV。磁矩符合Slater-Paulng（SP）规则，表现出强铁磁性。该材料具有脆性。热力学分析表明其具有良好的韧性，熵、热容和德拜温度趋势一致。光学响应显示在可见光和紫外区域有强吸收，并具有突出的介电和等离激元特性。输运性质评估显示具有高塞贝克系数和可调的品质因数（ZT），在600-1500 K温度范围内ZT值接近1.0，展现出优异的热电特性。

Conclusion: NaVAs是一种很有前途的多功能材料，在绿色能源领域的先进技术应用方面具有巨大潜力。

Abstract: This work presents a comprehensive investigation of the HH alloy NaVAs using
first - principles methods, emphasizing its potential applications in various
fields, including spintronics, thermoelectrics, and optoelectronics. We
utilized density functional theory (DFT) within the full-potential linearized
augmented plane wave (FLAPW) framework. Structural optimizations indicate that
the alloy stabilizes in the ferromagnetic phase. Both mechanical and dynamical
stability have been confirmed through analysis of elastic constants and phonon
dispersion. Our calculations of the electronic band structure and density of
states (DOS) reveal that NaVAs exhibits half-metallic behavior, with a
spin-polarized band gap of 2.77 eV in the minority spin channel. The magnetic
moment aligns with the Slater Pauling (SP) rule, demonstrating robust
ferromagnetism. Mechanical analysis shows that the material is brittle in
nature. The thermodynamic analysis highlights the alloy's resilience, supported
by consistent trends in entropy, heat capacity, and Debye temperature. Its
optical response indicates strong absorption in the visible and ultraviolet
(UV) regions, along with pronounced dielectric and plasmonic features,
suggesting potential for applications in optoelectronics and refective
coatings. Furthermore, evaluations of the transport properties show high
Seebeck coefficients and a significantly tunable figure of merit (ZT). ZT
values approach 1.0 across the temperature range of 600 - 1500 K, demonstrating
excellent thermoelectric characteristics. Overall, these findings position
NaVAs as a promising multifunctional material suitable for advanced
technological applications in green energy area.

</details>


### [242] [A facile vector substrate platform via BaTiO3 membrane transfer enables high quality solution processed epitaxial PZT on silicon](https://arxiv.org/abs/2509.06047)
*Asraful Haque,Antony Jeyaseelan,Shubham Kumar Parate,Srinivasan Raghavan,Pavan Nukala*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在铂涂层的硅衬底上转移结晶二氧化钛（BTO）薄膜作为载体基底（VS），随后通过化学溶液沉积（CSD）法生长外延（001）锆钛酸铅（PZT）薄膜，克服了铁电氧化物与硅直接集成中的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决了高性能铁电氧化物与硅集成中的晶格失配、热不相容以及高温外延生长需求等挑战。

Method: 首先将结晶BaTiO3（BTO）薄膜转移到Pt涂层的Si衬底上，然后利用BTO作为载体基底（VS），通过化学溶液沉积（CSD）法生长外延PZT薄膜。使用KI和HCl基蚀刻剂在约30分钟内快速溶解SrVO3牺牲层，显著缩短了释放时间。

Result: 生长出的PZT薄膜具有主要的（00l）面外取向和面内立方对立方外延生长。器件表现出10-12 µC/cm²的剩余极化和100 kV/cm的矫顽场，在VS上的开关次数稳定高达10^8次。PZT在VS上的有效d33为70 pm/V，而在传统Pt/Si衬底上为54 pm/V。

Conclusion: 该混合集成方法为在硅上集成功能性铁电材料提供了一种可扩展且经济高效的途径，为未来的CMOS兼容氧化物电子器件提供了一个有前景的平台。

Abstract: The direct integration of high-performance ferroelectric oxides with silicon
remains challenging due to lattice mismatch, thermal incompatibility, and the
need for high-temperature epitaxial growth. Here, a hybrid integration approach
is demonstrated in which crystalline BaTiO3 (BTO) membranes are first
transferred onto Pt coated Si substrates and subsequently used as vector
substrates (VS) for the growth of epitaxial (001) Pb(Zr0.52Ti0.48)O3 (PZT) thin
films via chemical solution deposition (CSD). A KI and HCl based etchant
enables rapid and complete dissolution of the SrVO3 sacrificial layer in about
30 minutes, reducing the release time from days to minutes compared with
conventional water based approaches to dissolve AVO3 and AMoO3 (A is Ca, Sr,
Ba). The BTO VS imposes dominant (00l) out of plane orientation and in plane
cube on cube epitaxy in the overlying PZT. Devices exhibit remnant polarization
10 to 12 micro coulomb/cm2 and coercive field of 100 kV/cm, with stable
switching to 10^8 cycles on the VS. From piezoelectric butterfly loops, we
extract effective d33 of 70 pm/V for PZT on VS, and 54 pm/V for PZT grown on
conventional Pt Si substrates. This approach demonstrates a scalable and cost
effective route for integrating functional ferroelectric materials onto silicon
and offers a promising platform for future CMOS compatible oxide electronics.

</details>


### [243] [Electric-field Control of Giant Ferronics](https://arxiv.org/abs/2509.06057)
*Baolong Zhang,Ruihuan Duan,Sobhan Subhra Mishra,Sambhu Jana,Jonghyeon Kim,Thomas Tan Caiwei,Yi Ji Tan,Wenhao Wang,Pang Teng Chen Ietro,Zheng Liu,Ranjan Singh*

Main category: cond-mat.mtrl-sci

TL;DR: Ferrons, quantum excitations of electric polarization, have been experimentally verified at room temperature in NbOX2 (X = I, Br, Cl) using soft phonons. These ferrons produce intense, narrowband THz emission with high quality factors and efficiencies significantly exceeding current technologies. Their oscillations can be controlled by electric fields, establishing "Ferronics" as a platform for light- and field-driven control of quantum order with potential applications in electronics, photonics, and communication.


<details>
  <summary>Details</summary>
Motivation: Direct experimental verification of ferrons, quantum excitations of electric polarization analogous to magnons, at room temperature has been lacking. The paper aims to address this by generating, detecting, and controlling giant ferrons.

Method: The study harnesses the coupling of soft phonons and ferroelectric order in layered NbOX2 (X = I, Br, Cl) to generate and detect ferrons. It also demonstrates electric-field control of ferron oscillations.

Result: Multiple ferron modes produce intense, narrowband THz emission with quality factors up to 228 and radiation efficiencies up to five orders of magnitude greater than state-of-the-art semiconductor emitters. Resonant excitation of a high-Q ferron mode achieves efficiencies two orders of magnitude higher than lithium niobate THz sources. Direct, non-volatile electric-field control of ferron oscillations is demonstrated.

Conclusion: The findings provide evidence for multiple ferrons and establish "Ferronics" as a foundational platform for light- and field-driven control of quantum order. This has broad implications for ultrafast electronics, photonics, quantum technologies, and next-generation wireless communication.

Abstract: Ferrons are quantum excitations of electric polarization in ferroelectrics
and electric analogues of magnons but have lacked direct experimental
verification at room temperature. We harness the coupling of soft phonons and
ferroelectric order in layered NbOX2 (X = I, Br, Cl) to generate, detect, and
control giant ferrons, creating a new class of ultralow-power, chip-scale
terahertz (THz) sources. Multiple ferron modes produce intense, narrowband THz
emission with quality factors up to 228 and radiation efficiencies up to five
orders of magnitude greater than state of the art semiconductor emitters.
Resonant excitation of a high-Q ferron mode achieves efficiencies two orders of
magnitude higher than intense lithium niobate THz sources. We further
demonstrate direct, non-volatile electric-field control of ferron oscillations.
These findings provide evidence for multiple ferrons and establish Ferronics as
a foundational platform for light- and field-driven control of quantum order,
with broad impact on ultrafast electronics, photonics, quantum technologies,
and next-generation wireless communication.

</details>


### [244] [Modulation of structural short-range order due to chemical patterning in multi-component amorphous interfacial complexions](https://arxiv.org/abs/2509.06166)
*Esther C. Hessong,Zhengyu Zhang,Tianjiao Lei,Mingjie Xu,Toshihiro Aoki,Timothy J. Rupert*

Main category: cond-mat.mtrl-sci

TL;DR: 非晶态界面络合物通过限制晶粒生长和提高纳米晶合金的损伤容限来发挥作用，而化学成分的增加则使络合物本身更稳定。本研究调查了富铜多组分纳米晶合金的局部化学成分和短程结构有序性，以了解掺杂剂如何在这些非晶态络合物中自组织以及局部结构如何被改变。通过高分辨率扫描透射电子显微镜和元素分析研究了晶界和相间界，并观察到了化学分配。值得注意的是，与非晶络合物的内部相比，非晶-晶体转变区域富集了某些掺杂剂，而另一些则被耗尽。这种化学模式可以通过元素对有序或无序晶界环境的偏好来解释。由于纳米束电子衍射只能提供这些样本的短程结构有序性的定性测量，因此使用定制的机器学习原子间势进行的原子模拟来探测掺杂剂模式如何影响局部结构状态。结果表明，增加的晶界化学成分导致络合物结构更加无序，并且在非晶-晶体转变区域的偏析会改变局部结构，而这种改变对掺杂剂比例敏感。总而言之，证明了非晶态界面络合物的局部化学与有序性之间存在密切联系，这为在非晶态络合物内部进行微结构工程提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在理解掺杂剂如何在富铜多组分纳米晶合金的非晶态络合物中自组织，以及局部结构如何被改变，以期为微结构工程提供新的途径。

Method: 研究采用了高分辨率扫描透射电子显微镜和元素分析技术，并结合原子模拟和定制的机器学习原子间势，来研究局部化学成分、短程结构有序性以及掺杂剂模式对非晶态络合物结构的影响。

Result: 研究观察到晶界和相间界存在化学分配现象，并且非晶-晶体转变区域的掺杂剂成分富集和贫化模式与晶界环境的偏好有关。原子模拟表明，增加的晶界化学成分导致络合物结构更加无序，掺杂剂模式影响局部结构，且这种影响对掺杂剂比例敏感。

Conclusion: 本研究证明了非晶态界面络合物的局部化学与有序性之间存在密切联系，并揭示了掺杂剂模式对络合物结构的影响机制，为通过微结构工程优化材料性能提供了新的见解。

Abstract: Amorphous interfacial complexions have been shown to restrict grain growth
and improve damage tolerance in nanocrystalline alloys, with increased chemical
complexity stabilizing the complexions themselves. Here, we investigate local
chemical composition and structural short-range order in Cu-rich,
multi-component nanocrystalline alloys to understand how dopants self-organize
within these amorphous complexions and how local structure is altered. High
resolution scanning transmission electron microscopy and elemental analysis are
used to study both grain boundaries and interphase boundaries, with chemical
partitioning observed for both. Notably, the amorphous-crystalline transition
region is observed to be enriched in certain dopant species and depleted of
others as compared to the interior of the amorphous complexions. This chemical
patterning can be explained in terms of the elemental preference for ordered or
disordered grain boundary environments. As only a qualitative measure of
structural short-range order can be obtained with nanobeam electron diffraction
for these specimens, atomistic simulations with a custom-built machine learning
interatomic potential are then used to probe how dopant patterning affects
local structural state. Increased grain boundary chemical complexity is found
to result in a more disordered complexion structure, with segregation to the
amorphous-crystalline transition regions driving changes in local structure
that are sensitive to dopant ratios. As a whole, the intimate connection
between local chemistry and order in amorphous interfacial complexions is
demonstrated, opening the door for microstructural engineering within the
amorphous complexions themselves.

</details>


### [245] [Bulk Ferroelectric Heterostructures: Imprinted Actuators](https://arxiv.org/abs/2509.06177)
*Yizhe Li,Ziqi Yang,Ying Chen,Zhenbo Zhang,Yun-Long Tang,Annette K. Kleppe,Egor Koemets,Xuezhen Cao,Steven J. Milne,Juncheng Pan,Jiajun Shi,Yuge Yang,David A. Hall*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种名为“畴工程块体铁电异质结构”（DE-BFH）的新型材料结构，通过元素分区构建，能够实现对畴翻转行为的全面调控，并可在整个铁电纹理空间内调节其可逆性，解决了现有技术中存在的访问不完整、记忆效应和能量耗散等问题。


<details>
  <summary>Details</summary>
Motivation: 现有铁电材料的畴翻转功能受到限于无法完全访问所有铁电纹理空间，并且存在记忆效应和能量耗散等问题。本研究旨在通过开发新的材料结构来克服这些限制，充分发挥块体铁电材料的潜力。

Method: 本研究通过元素分区构建了畴工程块体铁电异质结构（DE-BFH），并利用其实现了对畴翻转特性的全面控制和可逆性的调节。

Result: 所制备的DE-BFH陶瓷在轴向和剪切模式下均表现出前所未有的可逆电致应变增强和稳定性，其中在中间场强下剪切应变高达0.9%，并通过数字图像相关测量和原位同步X射线衍射研究得到证实。

Conclusion: DE-BFH材料在提高畴翻转行为方面取得了进展，有望推动新型无铅压电器件（如执行器、能量收集器、多态存储器件和畴壁开关）的发展。此外，DE-BFH的设计理念还可以通过扩展到多晶、单晶和薄膜等形式，应用于铁弹性、铁磁性和多铁性材料的开发。

Abstract: Domain switching is the cornerstone of ferroelectric materials. Most
associated functionalities can be tuned via domain switching, including but not
limited to piezoelectricity, thermal conductivity, domain wall conductivity and
topological structures. However, achieving the full potential of reversible
ferroelectric domain switching is restricted by the incomplete access to the
entire ferroelectric texture space, as well as the memory effects and energy
dissipation associated with the hysteretic nature of ferroelectrics. The
manipulation of domain switching behaviour is moderately attainable in
epitaxial heterostructures by exploiting the valence or lattice mismatch at
heterointerfaces, which is generally constrained by the necessity for two
dimensional architectures. In this study, domain-engineered bulk ferroelectric
heterostructures (DE-BFH), constructed via elemental partitioning, are employed
to unleash full potential of bulk ferroelectrics, providing comprehensive
control of domain switching characteristics and adjustable reversibility within
the entire range of ferroelectric texture space. Exemplar DE-BFH ceramics
exhibit unprecedented enhancement in reversible electrostrain and stability in
both axial and shear modes, including a record high peak to peak shear strain
up to 0.9% at intermediate field levels, confirmed by digital image correlation
measurements and in-situ synchrotron XRD studies. The advancement of domain
switching behaviour in DE-BFH could also promote development of new types of
lead-free piezoelectric devices, including actuators, energy harvesters,
multiple state memory devices, and domain wall switch. Moreover, design concept
of DE-BFH could contribute to the creation of distinctive ferroelastic,
ferromagnetic, and multiferroic materials by broadening its scope to the entire
ferroic family, encompassing polycrystalline, single-crystal, and thin-film
forms.

</details>


### [246] [Harnessing the polar vortex motion in oxide heterostructures](https://arxiv.org/abs/2509.06189)
*Pushpendra Gupta,Mohit Tanwani,Qi Xu,Guanshihan Du,Peiran Tong,Yongjun Wu,Zijian Hong,He Tian,Ramamoorthy Ramesh,Sujit Das*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究实现了对极性涡旋的动态操控，包括运动、重塑和变形，并揭示了其背后的物理机制，为基于极性涡旋的纳米电子器件的实际应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决在纳米电子器件中实现和操控极性拓扑结构（如极性涡旋和斯格明子）的挑战，以提高器件功能和信息密度。

Method: 通过施加局部脉冲电场和尖端的跟踪偏置场，实现了对PbTiO3/SrTiO3异质结构中极性涡旋的实时运动观测。利用原子力显微镜尖端的精确移动，实现了极性涡旋的可控重塑，并保持了其稳定性。结合相场模拟，揭示了通过切换涡旋核的锯齿形图案来控制涡旋边界运动的物理机制。

Result: 实现了极性涡旋的可逆运动和形状重构，重构后的涡旋具有长时间的稳定性。相场模拟证实了通过控制锯齿形图案实现涡旋运动的机制。

Conclusion: 本研究证明了利用外部刺激（如电场）操控极性涡旋动力学的可行性，加深了对基本物理机制的理解，并为下一代极性涡旋基纳米电子器件的研发提供了前景。

Abstract: Polar topology, an analogue of the magnetic topology, serves as a large
playground for exotic physical phenomena with a wide range of multifunctional
applications. Polar vortices and skyrmions are representative polar topologies
that have been predicted to significantly enhance the functionality and
information density of nanoelectronic devices due to their ultrasmall
dimensions. Despite these advantages, the practical realization of polar
topologies in devices is impeded by the intrinsic challenges associated with
their controlled motion and manipulation. Therefore, harnessing vortex
manipulation-such as motion, on demand creation, annihilation, and shape
transformation-is essential for practical device integration. However, vortex
motion is often challenged by intrinsic physical limitations in collective
lattice distortions and strong pinning effects from the surrounding
environment, which remains elusive. In this study, we present real time
observation of vortex motion in PbTiO3/SrTiO3 heterostructures, achieved
through the application of localized pulsed electric fields and trailing bias
fields from a conductive tip. Notably, the vortices exhibit reversible motion
in response to the field direction. Furthermore, by precisely manoeuvring the
conductive Atomic-Force-Microscopy tip along specific trajectories, we achieved
controlled vortex reshaping, with reconfigured vortices showing remarkable
stability over extended periods. This underline physical mechanism is further
pinpointed by phase-field simulations, which revealed that the motion of the
vortex boundary is controlled through the switching of the zigzag patterns of
the vortex core. This study highlights the feasibility of harnessing vortex
dynamics through external stimuli, advancing the fundamental physical
understanding and prospects for next-generation polar vortex-based
nanoelectronic devices.

</details>


### [247] [Low-temperature-compatible iron garnet films grown by liquid phase epitaxy](https://arxiv.org/abs/2509.06242)
*Jamal Ben Youssef,Nathan Beaulieu,Richard Schlitz,Davit Petrosyan,Michaela Lammel,William Legrand*

Main category: cond-mat.mtrl-sci

TL;DR: 超薄单晶钇铁石榴石(YIG)薄膜在顺磁性衬底上表现出优异的低温磁性动力学特性。


<details>
  <summary>Details</summary>
Motivation: 为了满足在低温和量子信息应用领域对磁子器件的需求，需要制备在低温下仍能保持低损耗的铁石榴石外延薄膜。

Method: 采用液相外延(LPE)技术在商业上可用的顺磁性钪钇镓石榴石(YSGG)衬底上生长超薄YIG薄膜，并在3-300 K的温度范围内研究其磁性动力学。

Result: 在3 K下，LPE生长的YIG/YSGG薄膜的铁磁共振线宽低于1 mT，并且损耗对温度和频率的依赖性非常弱，与在顺磁性GGG衬底上生长的薄膜相比，在低温下表现更好。

Conclusion: 通过LPE技术在YSGG衬底上生长YIG薄膜为在低温下研究铁石榴石薄膜提供了一种简单有效的方法。

Abstract: Single-crystalline yttrium iron garnet (YIG) thin films (< 100 nm) form the
backbone of magnonics, owing to the record-low losses affecting their
magnetization dynamics. However, thin epitaxial YIG has mostly been
investigated under ambient temperatures, limited by the paramagnetic losses
occurring at low temperatures due to the gadolinium gallium garnet (GGG)
substrates required for epitaxial growth. Driven by a growing interest in
magnonic devices that can operate in cryogenic conditions and address quantum
information applications, there is a strong need for iron garnet epitaxial
films grown on diamagnetic substrates that can maintain low losses at low
temperatures. In this work, we use liquid phase epitaxy (LPE) to grow ultrathin
films of strained YIG on a commercial diamagnetic substrate, yttrium scandium
gallium garnet (YSGG). We investigate their magnetization dynamics in the 3-300
K temperature range, and compare them to equivalent films grown on paramagnetic
GGG. We demonstrate for LPE YIG on YSGG substrates a ferromagnetic resonance
linewidth below 1 mT at 3 K, together with a very weak temperature and
frequency dependence of the losses. The growth of YIG/YSGG by LPE provides a
straightforward approach to producing iron garnet thin films for use in
low-temperature investigations.

</details>


### [248] [Topological Origin of Intrinsic High Chern Numbers in Two-Dimensional M$_2$X$_2$ Materials](https://arxiv.org/abs/2509.06288)
*Zujian Dai,Xudong Zhu,Lixin He*

Main category: cond-mat.mtrl-sci

TL;DR: Despite sharing a common lattice structure, monolayer M2X2 compounds realize quantum anomalous Hall phases with distinct Chern numbers, a phenomenon explained by two generic band-inversion mechanisms governed by orbital composition and symmetry. These mechanisms guide the engineering of high-Chern-number insulators.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore and explain the phenomenon of distinct Chern numbers realized in monolayer M2X2 compounds despite their shared lattice structure, which has not been fully understood.

Method: The study combines first-principles calculations, symmetry analysis, and tight-binding models to identify band-inversion mechanisms.

Result: Two generic band-inversion mechanisms were identified: a $\Gamma$-point inversion yielding C=1 when $d_{xz}/d_{yz}$ orbitals dominate, and inversions along $\Gamma$-X and $\Gamma$-Y yielding C=2 otherwise. This mechanism consistently explains related 2D systems and provides guidance for screening and engineering high-Chern-number insulators.

Conclusion: The identified band-inversion mechanisms, dependent on orbital composition and symmetry, consistently explain the distinct Chern numbers in monolayer M2X2 compounds and related 2D systems, offering practical insights for designing materials with tunable high-Chern-number properties.

Abstract: Despite sharing a common lattice structure, monolayer M$_2$X$_2$ compounds
realize quantum anomalous Hall phases with distinct Chern numbers, a striking
phenomenon that has not been fully exploared. Combining first-principles
calculations with symmetry analysis and tight-binding models, we identify two
generic band-inversion mechanisms governed by the orbital composition and
symmetry representations of 3$d$ states near the Fermi level. When
$d_{xz}/d_{yz}$ orbtials dominate, a doubly degenerate $\Gamma$-point inversion
yields $C=1$; otherwise, inversions occur along $\Gamma$-X and $\Gamma$-Y at
four $C_4$-related momenta, whose Berry-curvature contributions add to give
$C=2$, distinct from scenarios relying on multiple bands inversions at a single
$\mathbf{k}$ point. The same mechanism consistently explains related
two-dimensional systems, including LiFeSe, KTiSb, MgFeP, and Janus M$_2$X$_2$
derivatives. The mechanism provide practical guidance for screening and
engineering tunable high-Chern-number insulators.

</details>


### [249] [Hydrogen-induced fast fracture in a 1.5 GPa dual-phase steel](https://arxiv.org/abs/2509.06323)
*Rama Srinivas Varanasi,Motomichi Koyama,Shuya Chiba,Saya Ajito,Eiji Akiyama*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究阐明了1.5 GPa铁素体-马氏体双相（DP）钢中的氢脆（HE）行为。


<details>
  <summary>Details</summary>
Motivation: 研究氢脆行为在1.5 GPa铁素体-马氏体双相（DP）钢中的表现，特别是其断裂机制。

Method: 通过氢预充（3.8 ppm可扩散氢）、慢应变拉伸试验（10^-4 s^-1）、断口学研究、透射电子显微镜（TEM）和透射菊池衍射（TKD）研究、电子背散射衍射（EBSD）研究来分析。

Result: 氢预充后，在900 MPa下观察到韧性断裂，断口呈现出沿晶和准解理形貌；次表层二次裂纹在铁素体处发生钝化；裂纹萌生附近观察到韧性与脆性并存的混合断裂模式。与未充氢DP钢的主要脆性断裂不同，预充氢试样在裂纹扩展后表现出主要的脆性断裂，表现为{100}铁素体解理开裂。

Conclusion: 提出氢致快速断裂机制来解释HE：氢扩散至奥氏体晶界引起脱粘，随后扩散至裂纹尖端加速了高速率（>Vcrit）下的脆性断裂，抑制了位错发射导致的裂纹钝化，从而在裂纹尖端氢耗尽后仍能持续脆性扩展，最终导致{100}铁素体解理开裂。通过TEM解释了解理面上的河流图腾的形成。

Abstract: This study clarifies the hydrogen embrittlement (HE) behavior in a 1.5 GPa
ferrite-martensite dual-phase (DP) steel. Hydrogen pre-charging (3.8 mass ppm
diffusible hydrogen), followed by slow strain tensile testing (10-4 s-1),
resulted in a brittle fracture at 900 MPa within the elastic regime.
Fractographic studies indicated that surface crack initiation consists of
intergranular and quasi-cleavage morphology; site-specific transmission
electron microscopy (TEM) investigations revealed sub-surface secondary crack
blunting by ferrite. A mixed-mode morphology consisting of ductile and brittle
features was observed adjacent to crack initiation. It differs from the
previous investigation of uncharged DP steel, wherein a predominant brittle
fracture was observed. Following significant crack growth, the pre-charged
specimen exhibited predominant brittle fracture; site-specific TEM and
transmission Kikuchi diffraction studies revealed {100} ferrite cleavage
cracking. Electron backscatter diffraction studies were performed on the
cross-sectional cracks. We explain the HE via hydrogen-induced fast fracture
mechanism. During loading, hydrogen diffuses to the prior austenite grain
boundary, resulting in hydrogen-induced decohesion. Subsequent hydrogen
diffusion to the crack tip promotes brittle fracture at high crack velocity
(>Vcrit). The high crack velocity effectively inhibits crack blunting via
dislocation emission, ensuring sustained brittle crack growth even after
hydrogen depletion at the crack tip, resulting in {100} ferrite cleavage
cracking. Based on TEM observations, we explain the formation of river pattern
features on the {100} cleavage surface.

</details>


### [250] [Ferroelectricity in antiferromagnetic wurtzite nitrides](https://arxiv.org/abs/2509.06325)
*Steven M. Baksa,Lin-Ding Yuan,Stephen D. Wilson,James M. Rondinelli*

Main category: cond-mat.mtrl-sci

TL;DR: MnSiN2和MnGeN2被确立为新型多铁性纤锌矿家族的代表，同时具有铁电性和反铁磁性。非磁性类似物（Zn和Mg）具有高极化翻转势垒和宽带隙，是理想的铁电体候选材料。MnSiN2和MnGeN2表现出强反铁磁交换相互作用和中等带隙，但具有较小的磁电耦合。然而，它们具有可翻转的极化、自旋纹理和磁有序，这为设计基于氮化物的交替磁多铁体材料开辟了新途径，为集成反铁磁自旋电子器件提供了一个平台。


<details>
  <summary>Details</summary>
Motivation: 探索纤锌矿氮化物在铁电器件中的应用潜力，并首次研究了其磁对应物，确立了MnSiN2和MnGeN2作为同时具有铁电性和反铁磁性的多铁性材料。

Method: 首先，通过实验确立MnSiN2和MnGeN2作为具有铁电性和反铁磁性的多铁性材料。然后，利用第一性原理计算研究了非磁性类似物（Zn和Mg）的铁电特性（极化翻转势垒和带隙），以及MnSiN2和MnGeN2的反铁磁特性（交换相互作用和带隙），并计算了它们的极化翻转势垒。最后，通过元素替代（如碱土金属）来调控材料的性能，并展示了其在磁电耦合、交替磁自旋分裂和极化翻转方面的特性。

Result: MnSiN2和MnGeN2表现出铁电性和室温下的G型反铁磁性。非磁性类似物ZnSiN2和MgSiN2具有高极化翻转势垒（0.735和0.683 eV）和宽带隙（4.0和4.8 eV），是潜在的铁电器件材料。MnSiN2和MnGeN2具有强反铁磁交换相互作用（5-9 meV）和中等带隙（1.6和1.0 eV），极化翻转势垒分别为0.963和0.460 eV。该材料家族表现出交替磁自旋分裂，并且这种分裂可以在极化翻转时改变符号。通过元素替代，可以实现可翻转极化、自旋纹理和磁有序的共存。

Conclusion: MnSiN2和MnGeN2是具有铁电性和反铁磁性的新型多铁性材料。虽然它们的磁电耦合有限，但它们具有可调控的交替磁自旋分裂，这使得它们在集成反铁磁自旋电子器件方面具有应用前景。通过元素替代，可以进一步优化这些材料的性能，为设计新型氮化物多铁体材料提供了新的思路。

Abstract: Wurtzite-type nitrides have recently emerged as promising candidates for
ferroelectric applications, yet their magnetic counterparts remain largely
unexplored. Here, we establish MnSiN$_2$ and MnGeN$_2$ as aristotypes of a new
multiferroic wurtzite family that simultaneously exhibits ferroelectricity and
antiferromagnetism. These Mn(II)-based nitrides crystallize in polar structures
and display robust G-type antiferromagnetism at room temperature.
First-principles calculations reveal that nonmagnetic analogs incorporating Zn
and Mg possess high polarization reversal barriers (0.735 and 0.683 eV per
formula unit) and wide band gaps (4.0 and 4.8 eV), making them ideal
ferroelectric candidates. In contrast, MnSiN$_2$ and MnGeN$_2$ exhibit strong
antiferromagnetic exchange interactions (5--9 meV per Mn site) and moderate
band gaps (1.6 and 1.0 eV), with reversal barriers of 0.963 and 0.460 eV per
formula unit, respectively. Despite their limited magnetoelectric coupling, we
show this family of Type-1 multiferroics exhibits altermagnetic spin splitting
which reverses sign upon polarization switching. By strategically substituting
alkaline-earth metals, we engineer multiple materials with coexisting
switchable polarization, spin texture, and magnetic order. These findings open
new avenues for the design of nitride-based altermagnetic multiferroics,
offering a platform for integrated antiferromagnetic spintronic devices.

</details>


### [251] [Coexistence of Two Types of Liquid Structures at Platinum-Water Interfaces](https://arxiv.org/abs/2509.06327)
*Yitong Li,Qian Ai,Lalith Krishna Samanth Bonagiri,Yingjie Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 铂-水界面存在两种不同的液态结构，由表面异质性调节。


<details>
  <summary>Details</summary>
Motivation: 尽管铂-水界面在电化学能量转换过程中至关重要，但其真实空间的液态结构仍然难以捉摸。

Method: 利用三维原子力显微镜（3D-AFM）和广角X射线散射（WAXS）技术，以前所未有的分辨率研究了铂-水界面的结构。

Result: 研究发现铂-水界面存在两种不同的液态结构：一种是具有约0.33 nm周期性的类水结构（I型），另一种是具有约0.45 nm周期性和更长衰减长度的有序结构（II型）。这两种结构的存在与表面纳米畴的形貌相关。

Conclusion: 铂-水界面同时存在两种不同的液态结构，这两种结构受表面异质性的调控，为理解和设计能量转换应用提供了新的视角。

Abstract: Platinum-water interfaces underpin many electrochemical energy conversion
processes. However, despite decades of research, the real-space liquid
structure of these interfaces remains elusive. Using three-dimensional atomic
force microscopy (3D-AFM), we mapped Pt-water interface in real space with
angstrom-level resolution. Topographic imaging revealed atomically flat (type
I) and stripe-like (type II) surface nanodomains. Force-distance profiles above
type I domains exhibited oscillatory decay patterns with periodicity of ~0.33
nm, consistent with water. In contrast, type II domains showed stronger
oscillations with larger periodicity of ~0.45 nm and extended decay lengths,
indicative of a different liquid structure with stronger correlation and
ordering. Wide-angle X-ray scattering (WAXS) measurements of pure water and a
series of liquid n-alkanes revealed peaks at ~0.31 nm and ~0.46 nm, in
agreement with 3D-AFM observations of type I and type II structures,
respectively. Our findings uncover the coexistence of two types of liquid
structures at Pt-water interfaces modulated by surface heterogeneity, enabling
new understandings and design principles for energy conversion applications.

</details>


### [252] [Quasidegenerate charge-density wave states in 1T-TiSe$_2$](https://arxiv.org/abs/2509.06414)
*Seungrok Mun,Woojin Choi,Hayoon Im,Sung-Kwan Mo,Choongyu Hwang,Jinwoong Hwang,Heung-Sik Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 1T-TiSe2存在多种近乎简并的2x2x2电荷密度波（CDW）相，并提出165K可能存在第二相变，以及一个先前未探索的165-200K之间的中间CDW序。


<details>
  <summary>Details</summary>
Motivation: 1T-TiSe2的电荷密度波（CDW）形成及其对材料性质的影响是研究热点，但其基态性质仍有争议。

Method: 采用第一性原理电子结构计算和角分辨光电子能谱（ARPES）研究1T-TiSe2的CDW相及其对输运性质的影响。

Result: 发现了七种不同的2x2x2 CDW相，能量简并度高（<1.41 meV/fu）。通过能带展开技术，将计算的CDW相电子结构与实验ARPES数据进行比较，支持165K存在第二相变，并提出165-200K之间存在新的中间CDW序。

Conclusion: 研究结果可能解决了关于1T-TiSe2基态对称性的争议，并为1T-TiSe2的功能应用相工程开辟了可行途径。

Abstract: Transition metal dichalcogenides have been actively studied for their
intriguing charge density wave (CDW) formations and their impacts on material
properties. Among these, 1T-TiSe$_2$ is well-known to exhibit a
2$\times$2$\times$2 CDW state transition at 200 K, but its true ground state
nature remains under debate. In this study, we investigate possible CDW states
in 1T-TiSe$_2$ and their consequences for transport properties by employing
first-principles electronic structure calculations and angle-resolved
photoemission spectroscopy. We identify seven distinct types of
2$\times$2$\times$2 CDW phases, most of which have not been reported
previously. All of these phases are nearly degenerate in energy with each other
($< 1.41$ meV per formula unit). Using the band unfolding technique, we compare
the electronic band structures of these CDW phases with experimental
angle-resolved photoemission spectroscopy data. Our findings support the
presence of a possible second phase transition at 165 K and suggest a new
intermediate CDW order between 165 and 200 K that was previously unexplored.
This result provides a possible resolution to the conflict between previous
reports on the ground state symmetry of 1T-TiSe$_2$, and opens a viable route
to phase engineering of 1T-TiSe$_2$ for functional applications.

</details>


### [253] [Time-resolved measurement of Seebeck effect for superionic metals during structural phase transition](https://arxiv.org/abs/2509.06449)
*Shilin Li,Hailiang Xia,Takuma Ogasawara,Liguo Zhang,Katsumi Tanigaki*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种新的时间分辨垂直/水平温度梯度正交配置（t-resolved T(t)-HVOT）方法，用于解释热电塞贝克效应（SE）在结构相变期间的增强现象。研究将此方法应用于p型Cu2Se和n型Ag2S超离子半导体。实验数据显示了两种增强机制：一种是高达5 mV/K的巨大SE（Scolossal），另一种是在相变期间SE比相变前增大1.5-2.0倍的轻微增强（Sstructure）。研究认为这两种增强都不是内禀现象。


<details>
  <summary>Details</summary>
Motivation: 解释在结构相变期间观察到的热电塞贝克效应（SE）增强现象的真实机制。

Method: 提出并应用了一种新的时间分辨垂直/水平温度梯度正交配置（t-resolved T(t)-HVOT）方法。

Result: 通过新方法区分了两种SE增强机制：巨大的SE（Scolossal，高达5 mV/K）和轻微的SE增强（Sstructure，约为无相变时的1.5-2.0倍）。

Conclusion: 结构相变期间观察到的SE增强现象（Scolossal和Sstructure）并非内禀现象。

Abstract: We propose a new time (t)-resolved method of both vertical- and
horizontal-temperature gradients in an orthogonal configuration (t-resolved
T(t)-HVOT) to have real interpretations of the enhancement in thermoelectric
Seebeck effect (SE) observed during the structural phase transition. We apply
our new method to superionic-state semiconductors of p-type Cu2Se and n-type
Ag2S. The experimental data differentiate the two types of enhancements during
the phase transition: a colossal SE (Scolossal), exhibiting an enormous value
of up to 5 mV/K, and a slight enhancement in SE (Sstructure), approximately
1.5-2.0 times larger than those in the absence of the phase transition. We
provide critical insights that both enhancements in SE arising during the
structural phase transition are not intrinsic phenomena.

</details>


### [254] [Mexican hat-like valence band dispersion and quantum confinement in rhombohedral ferroelectric alpha-In2Se3](https://arxiv.org/abs/2509.06488)
*Geoffroy Kremer,Aymen Mahmoudi,Meryem Bouaziz,Mehrdad Rahimi,Francois Bertran,Jean-Francois Dayen,Maria Luisa Della Rocca,Marco Pala,Ahmed Naitabdi,Julien Chaste,Fabrice Oehler,Abdelkarim Ouerghi*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了 3R-α-In2Se3 的电子结构，发现了价带抛物线反转和约 1.25 eV 的间接带隙，并观察到表面高电子掺杂和电子积累层。


<details>
  <summary>Details</summary>
Motivation: 精确的实验测定 3R-α-In2Se3 的电子结构，以更好地理解其潜在性质和器件应用。

Method: 结合使用角分辨光电子能谱 (ARPES) 和密度泛函理论 (DFT) 计算。

Result: 3R-α-In2Se3 在 Γ 点表现出强大的价带抛物线反转，形成弓形色散，深度为 140 ± 10 meV；发现约 1.25 eV 的间接带隙；观察到表面存在约 5×10^12 电子/cm² 的高电子掺杂，导致表面能带弯曲和形成显著的电子积累层。

Conclusion: 这些发现加深了对 3R-α-In2Se3 电子性质的理解，揭示了 III/VI 族半导体在电子和光子技术中的潜力。

Abstract: Two-dimensional (2D) ferroelectric (FE) materials offer a large variety of
electronic properties depending on chemical composition, number of layers and
stacking-order. Among them, alpha-In2Se3 has attracted much attention due to
the promise of outstanding electronic properties, attractive quantum physics,
in- and out-of-plane ferroelectricity and high photo-response. Precise
experimental determination of the electronic structure of rhombohedral (3R)
alpha-In2Se3 is needed for a better understanding of potential properties and
device applications. Here, combining angle resolved photoemission spectroscopy
(ARPES) and density functional theory (DFT) calculations, we demonstrate that
3R alpha-In2Se3 phase exhibits a robust inversion of the valence band
parabolicity at the Gamma point forming a bow-shaped dispersion with a depth of
140 +- 10 meV between the valence band maximum (VBM) along the GammaK direction
of the Brillouin zone (BZ). Moreover, we unveil an indirect band gap of about
1.25 eV, as well as a highly electron doping of approximatively 5.1012
electrons per cmsquare at the surface. This leads to surface band bending and
the formation of a prominent electron accumulation layer. These findings allow
a deeper understanding of the rhombohedral alpha-In2Se3 electronic properties
underlying the potential of III/VI semiconductors for electronic and photonic
technologies.

</details>


### [255] [Morphology of Polarization States in Strained Ferroelectric Films](https://arxiv.org/abs/2509.06508)
*Léo Boron,Anaïs Sené,Yuri Tikhonov,Anna Razumnaya,Igor Lukyanchuk,Svitlana Kondovych*

Main category: cond-mat.mtrl-sci

TL;DR: 利用软畴方法分析了外延应变下铁电薄膜的涡旋状拓扑极化结构，给出了相图并为实验提供了指导。


<details>
  <summary>Details</summary>
Motivation: 外延应变下的铁电薄膜中存在涡旋状拓扑极化结构，需要对其进行分析。

Method: 在 Ginzburg-Landau-Devonshire 框架的基础上，扩展了软畴方法，对模型进行了紧凑的变分理论描述。

Result: 得到了不同温度、应变和厚度下的相图，并阐明了拓扑态的形态结构。该方法计算效率高。

Conclusion: 软畴方法为铁电纳米结构的研究提供了计算上高效且具有实际指导意义的理论框架。

Abstract: Ferroelectric thin films under epitaxial strain exhibit a variety of
vortex-like topological polarization textures. To analyze them, we build on the
Ginzburg-Landau-Devonshire framework and extend the previously introduced
soft-domain approach. This formulation provides a compact variational
theoretical description of polarization morphologies in strained PbTiO$_3$
films. It yields phase diagrams as a function of temperature, strain, and
thickness, and clarifies the morphological structure of emergent topological
states. The method is computationally efficient and offers practical guidance
for experimental studies of ferroelectric nanostructures.

</details>


### [256] [Non-linear jog-dragging effect on the mobility law of edge dislocations in face-centered cubic nickel](https://arxiv.org/abs/2509.06512)
*Wu-Rong Jian,Yifan Wang,Wei Cai*

Main category: cond-mat.mtrl-sci

TL;DR: Jogged edge dislocations in FCC nickel exhibit non-linear, thermally activated dragging and a higher Peierls barrier than straight dislocations, with stress-velocity curves intersecting at an invariant point delineating different drag regimes. A three-section mobility law is proposed for improved dislocation dynamics simulations.


<details>
  <summary>Details</summary>
Motivation: The effect of dislocation jogs on dislocation motion, which governs strain hardening, is poorly understood in mesoscale models. This paper aims to develop a mobility model for jogged edge dislocations to improve the physical fidelity of crystal plasticity predictions.

Method: Systematic molecular dynamics (MD) simulations were performed across various jog configurations, stresses, and temperatures to develop a mobility model for jogged edge dislocations in FCC nickel. A three-section expression for jogged dislocation mobility was proposed based on the observed stress-velocity curve intersections.

Result: Jogged edge dislocations in FCC nickel showed non-linear, thermally activated dragging and a higher Peierls barrier compared to straight dislocations at low stresses. Stress-velocity curves for a given jog configuration intersected at an invariant point ($	au_{m c}$, $v_{m c}$), where $	au_{m c}$ separates thermally-activated and phonon-drag regimes and is close to the Peierls stress ($	au_{m p}$).

Conclusion: A simple, three-section mobility law with physically interpretable parameters was developed for jogged dislocations, offering a realistic description of jog effects and improving the physical fidelity of dislocation dynamics simulations for crystal plasticity predictions.

Abstract: Dislocation jogs have strong effects on dislocation motion that governs the
strain-hardening behavior of crystalline solids, but how to properly account
for their effect in mesoscale models remains poorly understood. We develop a
mobility model for jogged edge dislocations in FCC nickel, based on systematic
molecular dynamics (MD) simulations across a range of jog configurations,
stresses, and temperatures. At low stresses, jogged edge dislocations exhibit
non-linear, thermally activated dragging and a higher Peierls barrier compared
to straight dislocations. Surprisingly, stress-velocity curves for a given jog
configuration across varying temperatures intersect at an invariant point
($\tau_{\rm c}$, $v_{\rm c}$), where $\tau_{\rm c}$ delineates
thermally-activated and phonon-drag regimes and is close to the Peierls stress
($\tau_{\rm p}$). Motivated by this observation, we propose a simple
three-section expression for jogged dislocation mobility, featuring minimal and
physically interpretable parameters. This mobility law offers a realistic
description of jog effects for dislocation dynamics (DD) simulations, improving
their physical fidelity for crystal plasticity predictions.

</details>


### [257] [Sub-nanosecond structural dynamics of the martensitic transformation in Ni-Mn-Ga](https://arxiv.org/abs/2509.06513)
*Yuru Ge,Fabian Ganss,Daniel Schmidt,Daniel Hensel,Mike J. Bruckhoff,Sakshath Sadashivaiah,Bruno Neumann,Mariana Brede,Markus E. Gruner,Peter Gaal,Klara Lünser,Sebastian Fähler*

Main category: cond-mat.mtrl-sci

TL;DR: 利用超快X射线衍射研究了Ni-Mn-Ga薄膜中由激光诱导的超快马氏体相变，实现了目前报道的最快相变动力学，并揭示了温度和热应力对相变过程的影响。


<details>
  <summary>Details</summary>
Motivation: 马氏体相变在驱动高功率密度应用方面至关重要，然而目前对超快马氏体相变动力学和速度极限的研究不足，特别是缺乏对相变过程中温度演变的测量。

Method: 采用基于同步辐射的、时间分辨的X射线衍射技术，研究了Ni-Mn-Ga薄膜中由270 fs激光诱导的马氏体相变。通过测量和计算来分析温度对相变时间的影响，并结合时间分辨应变测量来评估热应力的作用。此外，还利用机器学习力场进行分子动力学模拟来解释相变机制。

Result: 观察到约100 ps内完成马氏体到奥氏体的相变，相变周期（马氏体到奥氏体再回到马氏体）几乎可在5 ns内完成，这是迄今报道的最快的马氏体相变。研究发现温度和热应力共同影响相变时间，其中热应力与温度起竞争作用。分子动力学模拟表明，马氏体相变过程中的巨大原子畸变需要微结构中大量原子的协同运动，从而导致相变延迟。

Conclusion: 本研究实现了目前报道的最快的马氏体相变，并强调了在分析相变动力学时同时考虑温度和热应力的重要性。实验和模拟结果为理解和优化超快马氏体相变提供了新的见解。

Abstract: Martensitic transformations drive a multitude of emerging applications, which
range from high stroke actuation and, mechanocaloric refrigeration, to
thermoelastic energy harvesting. All these applications benefit from faster
transformations, as a high cycle frequency is essential for achieving high
power density. However, systematic investigations of the fast dynamics and
fundamental speed limits of martensitic transformations are scarce. Especially
for ultrashort time transformations, the temperature evolution throughout the
transformation is not measured, which is a substantial shortcoming as
temperature is the intrinsic force driving the transformation. Here, we present
a synchrotron-based time-resolved X-ray diffraction study of a 270 fs
laser-induced martensitic transformation in a Ni-Mn-Ga-based epitaxial thin
film. We observe the transformation from martensite to austenite within about
100 ps, just limited by the synchrotron probe pulse duration. Furthermore, a
full transformation cycle from martensite to austenite and back to martensite
can almost be finished within 5 ns, which is the fastest martensitic
transformation reported so far. Measurements and calculations of the
temperature evolution allow us to analyse the influence of temperature on
transformation time. By time-resolved strain measurements we demonstrate that
in addition to temperature, thermal film stress must be considered as a
competing influence on the martensitic transformation. Our experimental
findings are supported by molecular dynamics simulations with machine learned
force fields adapted to density functional theory calculations. These reveal
that the huge distortion during a martensitic transformation requires the
collective movement of many atoms within the microstructure, which delays the
transformation.

</details>


### [258] [200 keV energy electron irradiation of single crystal diamond: Quantification of vacancy and nitrogen-vacancy production](https://arxiv.org/abs/2509.06517)
*Chloe C Newsom,Lillian B Hughes,Ben L Green,Ania C Bleszynski Jayich,Mark E Newton*

Main category: cond-mat.mtrl-sci

TL;DR: 电子辐照和退火处理是金刚石中色心/缺陷产生的常用方法。本文研究了低能（200 keV）电子在化学气相沉积（CVD）生长的单晶高纯度（II型）电子级金刚石中产生的缺陷的深度分布。通过光致发光（PL）测量，发现产生的单空位的深度分布呈指数衰减，表面产率为（1.1±0.2）×10$^{-1}$ V/e$^{-}$/cm，衰减长度为12±1 μm。此外，还通过PL研究了等时退火过程中形成的NV$^{0/-}$中心和733 nm零声子线缺陷的深度分布。观察到的NV分布与空位分布不符，但可以通过一个包含空位团和氮-空位（NV$_{2}$）缺陷形成的简单模型进行定性解释。之前的研究假设NV的产生受氮限制，但本文证明了事实并非如此，当空位浓度远超取代氮浓度时，NV会损失并形成NV$_{2}$。


<details>
  <summary>Details</summary>
Motivation: 研究低能电子辐照在CVD金刚石中产生的缺陷深度分布，并探索NV中心形成机制。

Method: 利用光致发光（PL）技术，研究200 keV电子辐照和后续等时退火处理对金刚石中单空位、NV$^{0/-}$中心和733 nm零声子线缺陷的深度分布影响。

Result: 单空位的深度分布呈指数衰减，衰减长度为12±1 μm，表面产率为（1.1±0.2）×10$^{-1}$ V/e$^{-}$/cm。NV$^{0/-}$中心的深度分布与单空位分布不符，且其形成受空位浓度影响，当空位浓度远超氮浓度时，NV会损失并形成NV$_{2}$。

Conclusion: 本文揭示了电子辐照在CVD金刚石中产生缺陷的深度分布特性，并提出了一个考虑空位团和NV$_{2}$形成的模型来解释NV中心的形成机制，纠正了以往认为NV形成受氮限制的观点。 Hancock, K. D. (2023). Electronic defects in diamond . Ph. D. thesis, University of Bristol.

Abstract: Electron irradiation and annealing treatments are a method of colour
centre/defect creation in diamond. The depth profile of defects created by low
energy 200 keV electrons in single crystal high purity (type II) electronic
grade diamond grown via chemical vapour deposition has been investigated. The
depth profile of monovacancies created was found, using photoluminescence (PL),
to decay exponentially, with decay length $12\pm1$ $\mu$m and production rate
of $(1.1\pm0.2)\times 10 ^{-1}$ V/e$^{-}$/cm at the surface. The depth
distribution of the neutral and negatively charged nitrogen-vacancy
(NV$^{0/-}$) centre, and the 733 nm zero phonon line defect formed during an
isochronal annealing study have also been investigated by PL. The observed NV
profiles, which do not match the vacancy profiles, can be qualitatively
explained in terms of a simple model that includes the formation of vacancy
clusters and the nitrogen-divacancy (NV$_{2}$) defect. The production of
(NV$^{0/-}$) has been assumed to be nitrogen limited, but this paper has shown
that this is not the case, with NVs lost to the production of NV$_{2}$ when the
concentration of vacancies greatly exceeds that of substitutional nitrogen.

</details>


### [259] [GPUTB: Efficient Machine Learning Tight-Binding Method for Large-Scale Electronic Properties Calculations](https://arxiv.org/abs/2509.06525)
*Yunlong Wang,Zhixin Liang,Chi Ding,Junjie Wang,Zheyong Fan,Hui-Tian Wang,Dingyu Xing,Jian Sun*

Main category: cond-mat.mtrl-sci

TL;DR: GPUTB是一个GPU加速的紧束缚机器学习框架，可以高效地预测大尺度材料的电子特性。


<details>
  <summary>Details</summary>
Motivation: 现有ab-initio方法计算成本高，限制了其在器件尺度预测电子性质的应用，因此需要一种能够快速将原子结构映射到电子结构的有效方法。

Method: 开发了GPUTB框架，采用原子环境描述符，使模型参数能够包含环境依赖性，并结合了线性标度量子输运方法。

Result: GPUTB能够处理多达1亿个原子的系统（如石墨烯），能够轻松迁移到不同的基组、xc-函数和同素异形体，并能描述h-BN/石墨烯异质结系统。通过精确重现石墨烯中载流子浓度和室温迁移率之间的关系，验证了该框架的准确性。

Conclusion: GPUTB框架在计算精度和效率之间取得了精妙的平衡，为研究包含数百万原子的宏观体系的电子性质提供了强大的计算工具。

Abstract: The high computational cost of ab-initio methods limits their application in
predicting electronic properties at the device scale. Therefore, an efficient
method is needed to map the atomic structure to the electronic structure
quickly. Here, we develop GPUTB, a GPU-accelerated tight-binding (TB) machine
learning framework. GPUTB employs atomic environment descriptors, enabling the
model parameters to incorporate environmental dependence. This allows the model
to transfer to different basis, xc-functionals, and allotropes easily. Combined
with the linear scaling quantum transport method, we have calculated the
electronic density of states for up to 100 million atoms in pristine graphene.
Trained on finite-temperature structures, the model can be easily extended to
millions of atom finite-temperature systems. Furthermore, GPUTB can also
successfully describe h-BN/graphene heterojunction systems, demonstrating its
capability to handle complex material with high precision. We accurately
reproduce the relationship between carrier concentration and room temperature
mobility in graphene to verify the framework's accuracy. Therefore, our GPUTB
framework presents a delicate balance between computational accuracy and
efficiency, providing a powerful computational tool for investing electronic
properties for large systems with millions of atoms.

</details>


### [260] [Nonreciprocal magnons in layered antiferromagnets VPX3(X =S,Se,Te)](https://arxiv.org/abs/2509.06538)
*Quanchao Du,Zhenlong Zhang,Jinyang Ni,Zhijun Jiang,Laurent Bellaiche*

Main category: cond-mat.mtrl-sci

TL;DR: 分数量子霍尔效应的涡旋动力学


<details>
  <summary>Details</summary>
Motivation: 研究范德华层状反铁磁体中非互易磁振子的实现及其对现代自旋电子学应用的重要性。

Method: 研究了层状蜂窝状反铁磁体VPX3（X=S,Se,Te）中非互易磁振子的行为，并分析了其DMI、层数、层间耦合以及磁振子-磁振子相互作用的影响。

Result: 在VPX3（X=S,Se,Te）中实现了非互易磁振子行为，并发现磁振子非互易性对尼尔矢量表现出非对称周期性依赖关系。

Conclusion: 层状反铁磁体中磁振子的非互易性依赖于多种因素，并为在二维极限下探测反铁磁序参数提供了新途径。

Abstract: Nonreciprocal magnons, characterized by propagation with differing energies
along the k and -k directions, are crucial for modern spintronics applications.
However, their realization in van der Waals layered antiferromagnets remains
elusive. In this letter, we report robust nonreciprocal magnon behavior in
layered honeycomb antiferromagnets VPX3(X =S,Se,Te). Our results demonstrate
that, in addition to their intrinsic Dzyaloshinskii-Moriya interaction (DMI),
the nonreciprocity of magnons is strongly influenced by the layer number,
interlayer coupling, and magnon-magnon interactions. More importantly, in such
layered antiferromagnets, the magnon nonreciprocity exhibits an asymmetric
periodic dependence on the Neel vector, offering a novel route for
experimentally probing antiferromagnetic order parameters in the 2D limit.

</details>


### [261] [Exciton Formation in Two-Dimensional Semiconductors](https://arxiv.org/abs/2509.06543)
*K. Mourzidis,V. Jindal,M. Glazov,A. Balocchi,C. Robert,D. Lagarde,P. Renucci,L. Lombez,T. Taniguchi,K. Watanabe,T. Amand,S. Francoeur,X. Marie*

Main category: cond-mat.mtrl-sci

TL;DR: 在2D材料中，激子形成存在两种竞争机制：符合形成和双分子形成。


<details>
  <summary>Details</summary>
Motivation: 目前对2D材料中激子形成机制的微观过程的理解不足，尤其是在超快时间尺度上。

Method: 利用控制激发光偏振的技术来区分符合形成和双分子形成这两种激子形成模型。

Result: 研究发现，当激光能量超过自由载流子带隙时，圆偏振激发比线偏振激发产生的发光强度高出40%。这种依赖于自旋的激子发射是双分子形成过程的标志。此外，即使在超过带隙的激光激发能量下，激子线性偏振（谷相干性）也依然存在，这表明部分激子是通过符合形成过程产生的。

Conclusion: 在2D材料中，当激发能量超过带隙时，激子形成存在两种并存的机制：符合形成和双分子形成。

Abstract: The optical properties of atomically thin semiconductors are dominated by
excitons, tightly bound electron-hole pairs, which give rise to particularly
rich and remarkable physics. Despite their importance, the microscopic
formation mechanisms of excitons remain very poorly understood due to the
complex interplay of concurrent phenomena occurring on an ultrafast timescale.
Here, we investigate the exciton formation processes in 2D materials based on
transition metal dichalcogenide (TMD) monolayers using a technique based on the
control of excitation light polarization. It allows us to distinguish between
the two competing models of exciton formation: geminate and bimolecular
formation. The geminate process is the direct formation of the exciton from the
initially photogenerated electron hole pair before the loss of correlation
between them, whereas the bimolecular process corresponds to the random binding
of free electron hole-pairs from the initially photogenerated plasma. These
processes control the exciton formation time. Our findings reveal that the
luminescence intensity is higher by up to 40% for circularly polarized
excitation compared to linearly polarized excitation for laser energy above the
free carrier gap. We show that this spin-dependent exciton emission is a
fingerprint of the bimolecular formation process. Importantly, we observe that
exciton linear polarization (valley coherence) persists even for laser
excitation energies exceeding the gap. We demonstrate that it is the result of
a fraction of excitons formed by a geminate process. This shows that two
formation processes coexist for excitation energies above the gap, where both
mechanisms operate concurrently.

</details>


### [262] [Interlayer Coupling and Exciton Dynamics in 2D Hybrid Structures based on an InGaN Quantum Well coupled to a MoSe2 Monolayer](https://arxiv.org/abs/2509.06547)
*D. Chen,D. Lagarde,L. Hemmen,L. Lombez,P. Renucci,M. Mauguet,L. Ren,C. Robert,N. Grandjean,X. Marie*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Hybrid structures incorpora1ng both III-nitride and Transi1on Metal
Dichalcogenide (TMD) semiconductors have strong applica1on poten1al for light
harves1ng and optoelectronics. Here we have inves1gated the proper1es of hybrid
structures based on a MoSe2 monolayer coupled to an InGaN quantum well (QW).
The coupling efficiency is controlled by a thin GaN barrier of variable
thickness located between them. Time-integrated and 1me-resolved
micro-photoluminescence experiments show a quenching of the InGaN QW exciton
emission which increases with the decrease of the GaN barrier thickness d: the
PL intensity is reduced by a factor 3 for d=1 nm as a consequence of carrier
transfer to the MoSe2 monolayer. This interplay between the two semiconductors
is confirmed by 1meresolved photoluminescence spectroscopy highligh1ng a clear
reduc1on of the QW exciton life1me in the presence of the monolayer.
Interes1ngly the coupling between the QW and the TMD monolayer is also
demonstrated by measuring op1cally the excitonic transport proper1es in the
quantum well: the exciton diffusion length decreases in the presence of the
MoSe2 monolayer. The measured dependences as a func1on of temperature highlight
the role played by localiza1on effects in the QW. All these results can be well
interpreted by a type II band alignment between the InGaN QW and the MoSe2
monolayer and a tunneling process between the two semiconductors.

</details>


### [263] [Silicon-Compatible Ionic Control over Multi-State Magnetoelectric Phase Transformations in Correlated Oxide System](https://arxiv.org/abs/2509.06561)
*Xuanchi Zhou,Jiahui Ji,Wentian Lu,Huihui Ji,Chunwei Yao,Xiaohui Yao,Xiaomei Qiao,Guowei Zhou,Xiaohong Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过离子注入技术，在LSMO材料中实现了室温下的弱铁磁绝缘体状态，并揭示了其产生机理。


<details>
  <summary>Details</summary>
Motivation: 实现室温铁磁绝缘体是低功耗自旋电子学的关键，但传统掺杂方法存在铁磁序和绝缘体交换相互作用的权衡问题。离子注入提供了一种超越传统掺杂的新途径。

Method: 通过离子注入（特别是氢化）和SrTiO3缓冲层，精确调控LSMO材料的电荷-晶格-轨道-自旋相互作用，实现磁电状态的控制。

Result: 成功获得了室温下的弱铁磁绝缘体状态，并且这种状态与半金属状态的转变是可控的。研究还揭示了氢离子注入如何通过填充带隙和抑制双交换相互作用来实现这一转变。

Conclusion: 离子注入是一种有效的调控强关联体系中磁电状态的方法，为探索新奇量子态和开发自旋电子学器件提供了新的设计范式。同时，该研究也阐明了离子注入调控磁电行为的物理机制。

Abstract: Realizing room-temperature ferromagnetic insulators, critical enablers for
low-power spintronics, is fundamentally challenged by the long-standing
trade-off between ferromagnetic ordering and indirect exchange interactions in
insulators. Ionic evolution offers tempting opportunities for accessing exotic
magnetoelectric states and physical functionality beyond conventional doping
paradigm via tailoring the charge-lattice-orbital-spin interactions. Here, we
showcase the precise magneto-ionic control over magnetoelectric states in LSMO
system, delicately delivering silicon-compatible weakly ferromagnetic insulator
state above room temperature. Of particular note is the decoupling of
ion-charge-spin interplay in correlated LSMO system, a primary obstacle in
clarifying underlying physical origin, with this process concurrently giving
rise to an emergent intermediate state characterized by a weakly ferromagnetic
half-metallic state. Benefiting from the SrTiO3 buffer layer as epitaxial
template to promote interfacial heterogeneous nucleation, hydrogenation enables
diverse magnetoelectric states in LSMO integrated on silicon, fully compatible
with traditional semiconductor processing. Assisted by theoretical calculations
and spectroscopic techniques, hydrogen-induced magnetoelectric transitions in
LSMO are driven by band-filling control and suppression in double exchange
interaction. Our work not only defines a novel design paradigm for exploring
exotic quantum states in correlated system, with transformative potential for
spintronics, but also fundamentally unveils the physical origin behind ionic
evolution via disentangling the ion-charge-spin coupling.

</details>


### [264] [Towards Accurate and Scalable High-throughput MOF Adsorption Screening: Merging Classical Force Fields and Universal Machine Learned Interatomic Potentials](https://arxiv.org/abs/2509.06719)
*Satyanarayana Bonakala,Mohammad Wahiduzzaman,Taku Watanabe,Karim Hamzaoui,Guillaume Maurin*

Main category: cond-mat.mtrl-sci

TL;DR: 结合UFF和u-MLIPs进行MOF吸附筛选，并考虑了框架柔性，以识别具有良好吸附性能和选择性的MOF。


<details>
  <summary>Details</summary>
Motivation: 经典力场（如UFF）在模拟复杂的主-客体相互作用时存在不足，而通用机器学习势（u-MLIPs）虽然精度高但成本仍较高，限制了其在吸附筛选中的大规模应用。本研究旨在开发一种混合筛选策略，以克服这些限制。

Method: 采用Widom插入蒙特卡洛模拟，结合UFF和PreFerred Potential（PFP）u-MLIP，对MOF数据库进行吸附性能评估。对UFF筛选出的候选MOF，使用PFP u-MLIP进行重新评估，并与DFT计算进行基准测试，以优化吸附预测并评估框架柔性的影响。

Result: PFP u-MLIP对于准确评估涉及强氢键或窄孔隙内限制性空腔的MOF的吸附性能至关重要，而UFF则难以捕捉这些效应。考虑框架柔性（通过全晶胞弛豫）使乙烯亲和力产生高达20 kJ mol-1的偏差。最终确定了七种具有最佳孔径、高乙烯亲和力和高C2H4/H2O选择性的MOF，这些MOF在潮湿条件下表现出良好的性能。

Conclusion: 准确捕捉主-客体能量和框架柔性对于MOF吸附剂的识别至关重要。将u-MLIPs纳入可扩展的HTCS工作流程是识别顶级MOF吸附剂的可行方法。

Abstract: High-throughput computational screening (HTCS) of gas adsorption in
metal-organic frameworks (MOFs) typically relies on classical generic force
fields such as the Universal Force Field (UFF), which are efficient but often
fail to capture complex host-guest interactions. Universal machine-learned
interatomic potentials (u-MLIPs) offer near-quantum accuracy at far lower cost
than density functional theory (DFT), yet their large-scale application in
adsorption screening remains limited. Here, we present a hybrid screening
strategy that merges Widom insertion Monte Carlo simulations performed with
both UFF and the PreFerred Potential (PFP) u-MLIP to evaluate the adsorption
performance of a large MOF database, using ethylene capture under humid
conditions as a benchmark. From a curated set of MOFs, 88 promising candidates
initially identified using UFF-based HTCS were re-evaluated with the PFP
u-MLIP, benchmarked against DFT calculations to refine adsorption predictions
and assess the role of framework flexibility. We show that PFP u-MLIP is
essential to accurately assess the sorption performance of MOFs involving
strong hydrogen bonding or confinement pockets within narrow pores, effects
poorly captured using UFF. Notably, accounting for framework flexibility
through full unit cell relaxation revealed deviations in ethylene affinity of
up to 20 kJ mol-1, underscoring the impact of guest-induced structural changes.
This HTCS workflow identified seven MOFs with optimal pore sizes, high ethylene
affinity, and high C2H4/H2O selectivity, offering moisture-tolerant performance
for applications from food packaging to trace ethylene removal. Our findings
highlight the importance of accurately capturing host-guest energetics and
framework flexibility, and demonstrate the practicality of incorporating
u-MLIPs into scalable HTCS for identifying top MOF sorbents.

</details>


### [265] [Altermagnetic Proximity Effect](https://arxiv.org/abs/2509.06790)
*Ziye Zhu,Richang Huang,Xianzhang Chen,Xunkai Duan,Jiayong Zhang,Igor Zutic,Tong Zhou*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究揭示了一种新的近邻效应——交变磁近邻效应（AMPE），它不同于铁磁性和反铁磁性近邻效应，可以通过交变磁体的动量交变自旋分裂直接影响相邻的非磁性材料，实现“交变磁化”。


<details>
  <summary>Details</summary>
Motivation: 传统的材料设计方法在设计材料方面有局限性，而近邻效应可以实现常规方法无法实现的性质。本文旨在探索一种新的近邻效应，即交变磁近邻效应（AMPE），并研究其在材料设计中的应用。

Method: 利用第一性原理和模型分析了基于原型交变磁体V2Se2O的范德华异质结，研究了AMPE在单层PbO中的表现，包括其能带分裂和实空间自旋密度，并系统地研究了层间距和磁构型对其影响。此外，还预测了AMPE在单层PbS和单层NbSe2中的表现。

Result: 研究表明，AMPE可以将交变磁体的动量交变自旋分裂直接印在相邻的非磁性层上，即“交变磁化”。在单层PbO中观察到了特征性的能带分裂和实空间自旋密度，并且这种效应具有层间距和磁构型的系统依赖性。此外，研究还预测了AMPE在单层PbS（谷选择性自旋分裂）和单层NbSe2（拓扑超导相）中的应用前景。

Conclusion: AMPE不仅是一种独特的近邻效应机制，而且是利用交变磁性设计涌现现象和多功能应用的一种强大方法。

Abstract: Proximity effects not only complement the conventional methods of designing
materials, but also enable realizing properties that are not present in any
constituent region of the considered heterostructure. Here we reveal an
unexplored altermagnetic proximity effect (AMPE), distinct from its
ferromagnetic and antiferromagnetic counterparts. Using first-principles and
model analyses of van der Waals heterostructures based on the prototypical
altermagnet V$_2$Se$_2$O, we show that its hallmark momentum-alternating spin
splitting can be directly imprinted onto adjacent nonmagnetic layers -- a
process we term altermagnetization. This is demonstrated in a monolayer PbO
through characteristic band splitting and real-space spin densities, with
systematic dependence on interlayer spacing and magnetic configuration. We
further predict broader AMPE manifestations: Valley-selective spin splitting in
a monolayer PbS and a topological superconducting phase in monolayer NbSe$_2$,
both inheriting the alternating $k$-space spin texture of the altermagnet.
These results establish AMPE not only as a distinct proximity mechanism, but
also as a powerful method of using altermagnetism in designing emergent
phenomena and versatile applications.

</details>


### [266] [Spin-dependent transport in Fe${_3}$GaTe${_2}$ and Fe${_n}$GeTe${_2}$ ($n$=3-5) van der Waals ferromagnets for magnetic tunnel junctions](https://arxiv.org/abs/2509.06823)
*Anita Halder,Declan Nell,Akash Bajaj,Stefano Sanvito,Andrea Droghetti*

Main category: cond-mat.mtrl-sci

TL;DR: Fe$_3$GeTe$_2$, Fe$_4$GeTe$_2$, Fe$_5$GeTe$_2$和Fe$_3$GaTe$_2$这几种范德华铁磁体在垂直方向上表现出近乎半金属的导电性，其中Fe$_3$GaTe$_2$表现出理想的半金属行为，并且这种高自旋极化在磁性隧道结中得以保持，有望用于自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: 研究范德华铁磁体Fe$_3$GeTe$_2$, Fe$_4$GeTe$_2$, Fe$_5$GeTe$_2$, 和Fe$_3$GaTe$_2$的线性响应自旋相关量子输运性质。

Method: 使用密度泛函理论结合非平衡格林函数形式主义计算了这些材料的费米面、透射系数和轨道投影态密度。

Result: 所有化合物在垂直于面（out-of-plane）的方向上都表现出近乎半金属的导电性，一个自旋通道的透射系数有限，另一个通道则存在能隙，导致体材料的自旋极化率超过90%。其中，Fe$_3$GaTe$_2$表现出理想的半金属行为，其费米能量位于自旋向下透射能隙深处。此外，双层磁性隧道结也保持了这种高自旋极化，并表现出高达几个数量级的隧道磁电阻效应。

Conclusion: 研究结果表明，这些材料，特别是Fe$_3$GaTe$_2$，在自旋电子学应用方面具有巨大潜力。

Abstract: We present a systematic first-principles investigation of linear-response
spin-dependent quantum transport in the van der Waals ferromagnets
Fe$_3$GeTe$_2$, Fe$_4$GeTe$_2$, Fe$_5$GeTe$_2$, and Fe$_3$GaTe$_2$. Using
density functional theory combined with the non-equilibrium Green's function
formalism, we compute their Fermi surfaces, transmission coefficients, and
orbital-projected density of states. All compounds exhibit nearly half-metallic
conductance along the out-of-plane direction. This is characterized by a finite
transmission coefficient for one spin channel and a gap in the other, resulting
in spin polarization values exceeding 90$\%$ in the bulk. Notably,
Fe$_3$GaTe$_2$ displays the ideal half-metallic behavior, with the Fermi energy
located deep in the spin-down transmission gap. We further show that this high
spin polarization is preserved in bilayer magnetic tunnel junctions, which
exhibit a large tunnel magnetoresistance of the order of several hundred
percent. This findings underscore the promise of these materials, and in
particular of Fe$_3$GaTe$_2$, for spintronics applications.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [267] [Flight of Dynamic Targeting on the CogniSAT-6 Spacecraft](https://arxiv.org/abs/2509.05304)
*Steve Chien,Itai Zilberstein,Alberto Candela,David Rijlaarsdam,Tom Hendrix,Aubrey Dunne,Aragon Oriol,Miquel Juan Puig*

Main category: eess.SY

TL;DR: 该论文提出了一种名为动态目标（DT）的航天器自主概念，该概念利用传感器数据快速分析和后续观测来提高成像质量，并计划于2025年初在CogniSAT-6上进行演示。


<details>
  <summary>Details</summary>
Motivation: 为了提高航天器观测的自主性和效率，提出动态目标（DT）概念，通过快速分析传感器数据来驱动后续观测，从而实现更高质量的成像。

Method: 在低地球轨道应用中，DT概念利用前视图像分析云、热异常或土地利用情况，以驱动更高质量的近天顶成像。该概念需要前视传感器、边缘计算能力和主传感器，并可利用星间或低延迟通信进行跨平台任务。

Result: DT概念的潜在应用包括避云、搜寻风暴、行星边界层事件、羽流研究等。CogniSAT-6飞船将于2025年初搭载DT概念飞行。

Conclusion: 动态目标（DT）是一种通过快速分析传感器数据来指导后续观测以提高成像质量的航天器自主概念。该技术已在低地球轨道得到应用，并计划于2025年初在CogniSAT-6上进行演示。

Abstract: Dynamic targeting (DT) is a spacecraft autonomy concept in which sensor data
is acquired and rapidly analyzed and used to drive subsequent observation. We
describe the low Earth orbit application of this approach in which lookahead
imagery is analyzed to detect clouds, thermal anomalies, or land use cases to
drive higher quality near nadir imaging. Use cases for such a capability
include: cloud avoidance, storm hunting, search for planetary boundary layer
events, plume study, and beyond. The DT concept requires a lookahead sensor or
agility to use a primary sensor in such a mode, edge computing to analyze
images rapidly onboard, and a primary followup sensor. Additionally, an
inter-satellite or low latency communications link can be leveraged for cross
platform tasking. We describe implementation in progress to fly DT in early
2025 on the CogniSAT-6 (Ubotica/Open Cosmos) spacecraft that launched in March
2024 on the SpaceX Transporter-10 launch.

</details>


### [268] [A Fully Analog Implementation of Model Predictive Control with Application to Buck Converters](https://arxiv.org/abs/2509.05463)
*Simone Pirrera,Lorenzo Calogero,Francesco Gabriele,Diego Regruto,Alessandro Rizzo,Gianluca Setti*

Main category: eess.SY

TL;DR: 提出了一种利用元件设计预测控制模拟电路的方法，该方法在DC-DC Buck转换器上表现出优异的性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的方法来设计实现模型预测控制（MPC）策略的模拟电子电路，用于由仿射模型描述的系统。

Method: 结合最先进的技术来定义简化复杂性的显式MPC（EMPC），以实现具有有限数量的低延迟和商用组件的模拟电路。

Result: 通过在DC-DC Buck转换器先进控制器的设计中的应用，证明了所提出方法的可行性和有效性，并进行了广泛的数值模拟，证明其在负载扰动抑制方面具有优异的性能。

Conclusion: 所提出的方法在DC-DC Buck转换器上实现了具有优异负载扰动抑制能力的先进控制器，超越了标准方法。

Abstract: This paper proposes a novel approach to design analog electronic circuits
that implement Model Predictive Control (MPC) policies for plants described by
affine models. The combination of state-of-the-art approaches to define
reduced-complexity Explicit MPC (EMPC) is employed to realize an analog circuit
characterized by a limited amount of low-latency and commercially available
components. The practical feasibility and effectiveness of the proposed
approach are demonstrated through its application in the design of an advanced
controller for DC-DC Buck converters. We formally analyze the stability of the
obtained system and conduct extensive numerical simulations to demonstrate that
it is capable of achieving outstanding load disturbance rejection performance,
outclassing standard approaches.

</details>


### [269] [State Estimation for Linear Systems with Non-Gaussian Measurement Noise via Dynamic Programming](https://arxiv.org/abs/2509.05482)
*Mohammad Hussein Yoosefian Nooshabadi,Laurent Lessard*

Main category: eess.SY

TL;DR: 该研究提出了一种新的递归估计算法，用于处理高斯过程噪声和非高斯测量噪声的线性动态系统。该方法使用动态规划和凸分析工具开发了一种近似最大后验（MAP）估计器，避免了严格的噪声假设，并采用类似贝尔曼的更新代替了贝叶斯更新。模拟结果表明，该估计器比卡尔曼滤波器具有更低的均方根误差（RMSE），计算效率高，并且计算能力要求低于现有先进估计算法。


<details>
  <summary>Details</summary>
Motivation: 提出一种能够处理高斯过程噪声和非高斯测量噪声的线性动态系统的递归估计算法。

Method: 使用动态规划和凸分析工具开发近似最大后验（MAP）估计器，采用类似贝尔曼的更新。

Result: 所提出的估计算法在模拟中实现了比卡尔曼滤波器更低的均方根误差（RMSE），性能与现有先进算法相当，同时计算量显著降低。

Conclusion: 该方法提供了一种计算效率高且性能优越的线性动态系统估计解决方案，特别是在存在非高斯测量噪声的情况下。

Abstract: We propose a new recursive estimator for linear dynamical systems under
Gaussian process noise and non-Gaussian measurement noise. Specifically, we
develop an approximate maximum a posteriori (MAP) estimator using dynamic
programming and tools from convex analysis. Our approach does not rely on
restrictive noise assumptions and employs a Bellman-like update instead of a
Bayesian update. Our proposed estimator is computationally efficient, with only
modest overhead compared to a standard Kalman filter. Simulations demonstrate
that our estimator achieves lower root mean squared error (RMSE) than the
Kalman filter and has comparable performance to state-of-the-art estimators,
while requiring significantly less computational power.

</details>


### [270] [Hierarchical Decision-Making in Population Games](https://arxiv.org/abs/2509.05808)
*Yu-Wen Chen,Nuno C. Martins,Murat Arcak*

Main category: eess.SY

TL;DR: This paper proposes a hierarchical framework for population games, allowing individuals to delegate decisions to strategic proxies, and provides methods for analyzing games with convex constraints.


<details>
  <summary>Details</summary>
Motivation: To extend classical population games to model multi-layered decision-making in real-world scenarios and to develop a systematic approach for analyzing games with general convex constraints without requiring full constraint knowledge.

Method: Introduced a hierarchical framework for population games with delegated decision-making and established equilibrium properties and convergence results. Developed an analysis approach for games with general convex constraints based on these results.

Result: Established equilibrium properties and convergence results for the hierarchical structure. Demonstrated the approach with a navigation application case study.

Conclusion: The hierarchical framework effectively extends classical population games and the developed analysis approach facilitates the study of games with convex constraints, as illustrated by the navigation application example.

Abstract: This paper introduces a hierarchical framework for population games, where
individuals delegate decision-making to proxies that act within their own
strategic interests. This framework extends classical population games, where
individuals are assumed to make decisions directly, to capture various
real-world scenarios involving multiple decision layers. We establish
equilibrium properties and provide convergence results for the proposed
hierarchical structure. Additionally, based on these results, we develop a
systematic approach to analyze population games with general convex
constraints, without requiring individuals to have full knowledge of the
constraints as in existing methods. We present a navigation application with
capacity constraints as a case study.

</details>


### [271] [Real-Time Single-Iteration Model Predictive Control for Wave Energy Converters](https://arxiv.org/abs/2509.05853)
*Simone Pirrera,Nicolas Faedo,Sophie M. Fosson,Diego Regruto*

Main category: eess.SY

TL;DR: 提出了一种新颖的实时波浪能转换器（WEC）控制算法，该算法采用单次迭代MPC方法，在模拟中显著优于标准MPC。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的实时算法来控制波浪能转换器（WEC）。

Method: 采用经济模型预测控制（MPC）问题，并应用一种新颖的、受近期开发的用于约束优化的基于控制的算法启发的，一阶优化算法，以根据单次迭代MPC方法来定义控制器动力学。对所用算法的收敛性和所得控制器的计算复杂性进行了理论分析。

Result: 使用基准WEC系统进行的模拟结果表明，由于能够处理更快的采样率，因此所提出的方法显著优于标准MPC。

Conclusion: 所提出的单次迭代MPC方法能够处理更快的采样率，因此在控制WEC方面优于标准MPC。

Abstract: This paper proposes a novel real-time algorithm for controlling wave energy
converters (WECs). We begin with the economic model predictive control (MPC)
problem formulation and apply a novel, first-order optimization algorithm
inspired by recently developed control-based algorithms for constrained
optimization to define the controller dynamics according to the
single-iteration MPC approach. We theoretically analyse the convergence of the
employed algorithm and the computational complexity of the obtained controller.
Results from simulations using a benchmark WEC system indicate that the
proposed approach significantly outperforms standard MPC, thanks to the
inherent ability to handle faster sampling rates.

</details>


### [272] [A Dynamic Programming Framework for Vehicular Task Offloading with Successive Action Improvement](https://arxiv.org/abs/2509.05907)
*Qianren Li,Yuncong Hong,Bojie Lv,Rui Wang*

Main category: eess.SY

TL;DR: 通过一种新颖的动态规划框架，优化了具有随机速度的车辆的任务卸载。


<details>
  <summary>Details</summary>
Motivation: 车辆由于随机速度，其轨迹无法预先确定，因此需要一种新的优化方法来处理这种不确定性。

Method: 将蜂窝关联、上行链路时间和吞吐量分配制定为有限时间尺度的马尔可夫决策过程，并提出了一种两时间尺度框架来获得低复杂度的解。

Result: 所提出的调度框架在模拟中显示出与基线的显著性能增益。

Conclusion: 所提出的两时间尺度动态规划框架能够有效地优化具有随机速度的车辆的任务卸载问题，并实现显著的性能提升。

Abstract: In this paper, task offloading from vehicles with random velocities is
optimized via a novel dynamic programming framework. Particularly, in a
vehicular network with multiple vehicles and base stations (BSs), computing
tasks of vehicles are offloaded via BSs to an edge server. Due to the random
velocities, the exact locations of vehicles versus time, namely trajectories,
cannot be determined in advance. Hence, instead of deterministic optimization,
the cell association, uplink time, and throughput allocation of multiple
vehicles during a period of task offloading are formulated as a finite-horizon
Markov decision process. In order to derive a low-complexity solution
algorithm, a two-time-scale framework is proposed. The scheduling period is
divided into super slots, each super slot is further divided into a number of
time slots. At the beginning of each super slot, we first obtain a reference
scheduling scheme of cell association, uplink time and throughput allocation
via deterministic optimization, yielding an approximation of the optimal value
function. Within the super slot, the actual scheduling action of each time slot
is determined by making improvement to the approximate value function according
to the system state. Due to the successive improvement framework, a non-trivial
average cost upper bound could be derived. In the simulation, the random
trajectories of vehicles are generated from a high-fidelity traffic simulator.
It is shown that the performance gain of the proposed scheduling framework over
the baselines is significant.

</details>


### [273] [Certifying the Nonexistence of Feasible Path Between Power System Operating Points](https://arxiv.org/abs/2509.05935)
*Mohammad Rasoul Narimani,Katherine R. Davis,Daniel K. Molzahn*

Main category: eess.SY

TL;DR: 该研究提出了一种算法，用于证明在优化的潮流（OPF）可行空间中，两个操作点之间是否存在不可行转换。


<details>
  <summary>Details</summary>
Motivation: 现有的OPF研究主要集中在找到高质量的解，但评估在不同操作点之间转换的可行性仍然是一个挑战，因为OPF的可行空间可能包含多个不连通的区域，跨越这些区域需要违反OPF约束。

Method: 该算法首先在两个可行点之间的连线上寻找一个不可行点，然后利用凸松弛和边界缩紧技术，证明与该连线垂直的平面上的所有点都是不可行的，从而证明了可行空间的が不连通性。

Result: 该算法首次成功证明了多种OPF测试用例中的可行空间が不连通。

Conclusion: 该算法为OPF可行空间的不连通性提供了有效的证明方法，有助于更安全、更可靠的电力系统运行。

Abstract: By providing the optimal operating point that satisfies both the power flow
equations and engineering limits, the optimal power flow (OPF) problem is
central to the operation of electric power systems. While extensive research
efforts have focused on reliably computing high-quality OPF solutions,
assessing the feasibility of transitioning between operating points remains
challenging since the feasible spaces of OPF problems may consist of multiple
disconnected components. It is not possible to transition between operating
points in different disconnected components without violating OPF constraints.
To identify such situations, this paper introduces an algorithm for certifying
the infeasibility of transitioning between two operating points within an OPF
feasible space. As an indication of potential disconnectedness, the algorithm
first seeks an infeasible point on the line connecting a pair of feasible
points. The algorithm then certifies disconnectedness by using convex
relaxation and bound tightening techniques to show that all points on the plane
that is normal to this line are infeasible. Using this algorithm, we provide
the first certifications of disconnected feasible spaces for a variety of OPF
test cases.

</details>


### [274] [Mutual Support by Sensor-Attacker Team for a Passive Target](https://arxiv.org/abs/2509.06092)
*Prajakta Surve,Shaunak D. Bopardikar,Alexander Von Moll,Isaac Weintraub,David W. Casbeer*

Main category: eess.SY

TL;DR: 一个追捕游戏，涉及一个传感器、一个攻击者和一个移动目标。目标比传感器快但比攻击者慢。目标的目标是在不被攻击者捕获的情况下逃脱，而传感器-攻击者团队的目标是让目标保持在传感半径内以便被捕获。我们提出了传感器和攻击者的最佳策略，确定了可感知区域，并为目标的捕获或逃逸得出了速度界限。


<details>
  <summary>Details</summary>
Motivation: 本文提出并解决了在一个无限欧几里得平面上，由一个传感器、一个攻击者和一个移动目标组成的三方追捕游戏问题。该游戏的独特之处在于目标比传感器快但比攻击者慢，并且传感器需要将目标保持在传感半径内以协助攻击者捕获目标，而目标则试图逃脱。

Method: 本文将该问题作为一个“博弈类型”问题来处理，其中目标使用开环策略（被动目标）。研究人员提出了传感器和攻击者的最佳策略，包括最大化目标在传感半径内停留时间的传感器策略和使用比例导航的攻击者策略。此外，他们还推导了可感知区域的特征，并给出了目标速度的下界（捕获保证）和上界（逃逸策略存在）。

Result: 1. 提出了传感器和攻击者的最优策略。 2. 确定了可感知区域，并给出了捕获保证的条件。 3. 推导了目标速度的下界和上界，低于该下界捕获是保证的，高于该上界目标可以逃脱。 4. 给出了特定初始朝向下的更精确的目标速度逃逸上界。

Conclusion: 该研究为传感器-攻击者-目标追捕游戏提供了理论框架和解决方案，确定了捕获和逃逸的条件，并为双方策略提供了指导。

Abstract: We introduce a pursuit game played between a team of a sensor and an attacker
and a mobile target in the unbounded Euclidean plane. The target is faster than
the sensor, but slower than the attacker. The sensor's objective is to keep the
target within a sensing radius so that the attacker can capture the target,
whereas the target seeks to escape by reaching beyond the sensing radius from
the sensor without getting captured by the attacker. We assume that as long as
the target is within the sensing radius from the sensor, the sensor-attacker
team is able to measure the target's instantaneous position and velocity. We
pose and solve this problem as a \emph{game of kind} in which the target uses
an open-loop strategy (passive target). Aside from the novel formulation, our
contributions are four-fold. First, we present optimal strategies for both the
sensor and the attacker, according to their respective objectives.
Specifically, we design a sensor strategy that maximizes the duration for which
the target remains within its sensing range, while the attacker uses
proportional navigation to capture the target. Second, we characterize the
\emph{sensable region} -- the region in the plane in which the target remains
within the sensing radius of the sensor during the game -- and show that
capture is guaranteed {if and only if} the Apollonius circle between the
attacker and the target is fully contained within this region. Third, we
{derive a lower bound} on the target's speed below which capture is guaranteed,
and an upper bound on the target speed above which there exists an escape
strategy for the target, from an arbitrary initial orientation between the
agents. Fourth, for a given initial orientation between the agents, we present
a sharper upper bound on the target speed above which there exists an escape
strategy for the target.

</details>


### [275] [DNN-based Digital Twin Framework of a DC-DC Buck Converter using Spider Monkey Optimization Algorithm](https://arxiv.org/abs/2509.06279)
*Tahmin Mahmud,Euzeli Cipriano Dos Santos Jr*

Main category: eess.SY

TL;DR: 本文提出了一种基于数据驱动的数字孪生（DT）框架，利用深度神经网络（DNN）和蜘蛛猴优化（SMO）算法来监测和预测DC-DC降压转换器中组件的退化情况。


<details>
  <summary>Details</summary>
Motivation: 组件老化直接影响电力电子转换器系统（PECSs）的可靠性、性能和使用寿命，因此理解和监控组件老化对于开发可靠的转换器和实现长期系统可靠性至关重要。

Method: 提出了一种集成了深度神经网络（DNN）和蜘蛛猴优化（SMO）算法的数据驱动数字孪生（DT）框架，并使用低功耗原型测试台以及经验和合成数据集进行验证。

Result: SMO+DNN方法在95%的试验中实现了全局最优，所需的迭代次数减少了33%，参数约束冲突减少了80%。DNN模型在所有关键退化参数上实现了高于0.998的R^2得分，并能准确预测失效时间（t_failure）。此外，SMO调整的退化曲线使转换器的性能得到改善，电压纹波减少了20-25%，电感电流纹波减少了15-20%。

Conclusion: 所提出的SMO+DNN数字孪生框架能够有效监测和预测DC-DC降压转换器中组件的退化，并改善转换器的性能。

Abstract: Component ageing is a critical concern in power electronic converter systems
(PECSs). It directly impacts the reliability, performance, and operational
lifespan of converters used across diverse applications, including electric
vehicles (EVs), renewable energy systems (RESs) and industrial automation.
Therefore, understanding and monitoring component ageing is crucial for
developing robust converters and achieving long-term system reliability. This
paper proposes a data-driven digital twin (DT) framework for DC-DC buck
converters, integrating deep neural network (DNN) with the spider monkey
optimization (SMO) algorithm to monitor and predict component degradation.
Utilizing a low-power prototype testbed along with empirical and synthetic
datasets, the SMO+DNN approach achieves the global optimum in 95% of trials,
requires 33% fewer iterations, and results in 80% fewer parameter constraint
violations compared to traditional methods. The DNN model achieves $R^2$ scores
above 0.998 for all key degradation parameters and accurately forecasts time to
failure ($t_{failure}$). In addition, SMO-tuned degradation profile improves
the converter's performance by reducing voltage ripple by 20-25% and inductor
current ripple by 15-20%.

</details>


### [276] [Enhancing Low-Altitude Airspace Security: MLLM-Enabled UAV Intent Recognition](https://arxiv.org/abs/2509.06312)
*Guangyu Lei,Tianhao Liang,Yuqi Ping,Xinglin Chen,Longyu Zhou,Junwei Wu,Xiyuan Zhang,Huahao Ding,Xingjian Zhang,Weijie Yuan,Tingting Zhang,Qinyu Zhang*

Main category: eess.SY

TL;DR: 该研究提出了一种利用多模态大语言模型（MLLM）识别无人机（UAV）意图的方法，并构建了一个相应的架构，通过多模态感知系统获取无人机信息，结合环境信息、先验知识和战术偏好，由MLLM进行意图识别，并在低空对抗场景中进行了用例演示。


<details>
  <summary>Details</summary>
Motivation: 低空经济的快速发展对非合作无人机的有效感知和意图识别提出了迫切需求，而多模态大语言模型（MLLM）的生成式推理能力为此类任务提供了有前景的方法。

Method: 提出了一种MLLM赋能的无人机意图识别架构。该架构利用多模态感知系统获取无人机的实时载荷和运动信息，生成结构化输入，然后MLLM结合环境信息、先验知识和战术偏好输出意图识别结果。

Result: 通过一个低空对抗的用例演示了所提出架构的可行性，并为实际系统设计提供了有价值的见解。

Conclusion: 对未来挑战进行了讨论，并提出了相应的战略建议以促进进一步的应用。

Abstract: The rapid development of the low-altitude economy emphasizes the critical
need for effective perception and intent recognition of non-cooperative
unmanned aerial vehicles (UAVs). The advanced generative reasoning capabilities
of multimodal large language models (MLLMs) present a promising approach in
such tasks. In this paper, we focus on the combination of UAV intent
recognition and the MLLMs. Specifically, we first present an MLLM-enabled UAV
intent recognition architecture, where the multimodal perception system is
utilized to obtain real-time payload and motion information of UAVs, generating
structured input information, and MLLM outputs intent recognition results by
incorporating environmental information, prior knowledge, and tactical
preferences. Subsequently, we review the related work and demonstrate their
progress within the proposed architecture. Then, a use case for low-altitude
confrontation is conducted to demonstrate the feasibility of our architecture
and offer valuable insights for practical system design. Finally, the future
challenges are discussed, followed by corresponding strategic recommendations
for further applications.

</details>


### [277] [First-Principle Modeling Framework of Boost Converter Dynamics for Precise Energy Conversions in Space](https://arxiv.org/abs/2509.06425)
*Yifan Wang,Wenhua Li,Zhenlong Wang,Xinrui Zhang,Jianfeng Sun,Qianfu Xia,Zhongtao Gou,Jiangang Rong,Tao Ye*

Main category: eess.SY

TL;DR: 传统升压转换器模型在输入电压和负载波动下预测瞬态行为不准确，导致输出电压过冲和系统故障。本研究提出了一种基于非理想组件耦合的第一性原理建模框架，显著提高了模型的准确性，并成功设计并部署了可靠的升压转换器。


<details>
  <summary>Details</summary>
Motivation: 传统升压转换器模型在输入电压和负载波动下预测瞬态行为不准确，导致输出电压过冲和系统故障，限制了其在太空等领域的应用。

Method: 提出了一种第一性原理建模框架，通过引入非理想组件耦合来推导精确的升压转换器动态方程。

Result: 与现有最精确的模型相比，在输入电压变化下，稳态和动态状态下的实验与仿真输出电压误差分别减小了11.0倍（从20.9%降至1.9%）和15.4倍（从77.1%降至5.0%）。在负载变化下，稳态和动态状态下的误差分别减小了10.2倍（从15.3%降至1.5%）和35.1倍（从42.1%降至1.2%）。

Conclusion: 成功设计并部署了一个可靠的升压转换器，实现了精确的能量转换。

Abstract: Boost converters are essential for modern electrification and intelligent
technologies. However, conventional Boost converter models relying on
steady-state assumptions fail to accurately predict transient behaviors during
input voltage and load fluctuations, which cause significant output voltage
overshoots and instability, resulting in failures of electrical systems,
thereby restricting their use in space. This study introduces a first-principle
modeling framework that derives precise dynamic equations for Boost converters
by incorporating non-ideal component coupling. As compared to the most accurate
existing Boost converter model, the proposed models reduce steady-state and
dynamic-state errors between experimental and simulated output voltages by
factors of 11.0 (from 20.9% to 1.9%) and 15.4 (from 77.1% to 5.0%) under input
voltage variations, and by factors of 10.2 (from 15.3% to 1.5%) and 35.1 (from
42.1% to 1.2%) under load changes, respectively. Consequently, a reliable Boost
converter is accordingly designed and on-orbit deployed for precise energy
conversions.

</details>


### [278] [Unified Graph-Theoretic Modeling of Multi-Energy Flows in Distribution Systems](https://arxiv.org/abs/2509.06447)
*Marwan Mostafa,Daniel Wenser,Payam Teimourzadeh Baboli,Christian Becker*

Main category: eess.SY

TL;DR: 该论文提出了一种基于图论的多能源系统建模方法，并开发了相应的求解器，以应对日益复杂的能源系统。


<details>
  <summary>Details</summary>
Motivation: 为了统一建模，处理电力、天然气和热力网络之间的耦合和脱碳化带来的相互作用。

Method: 使用多层图表示不同能源领域，通过耦合层表示耦合技术，并采用基于块结构牛顿-拉夫逊法的稳态求解器来计算跨载流子的流和状态变量。

Result: 所提出的模型在基于德国配电网的案例研究中得到了测试和验证，证明了其收敛性、数值准确性和跨领域交互的一致性。

Conclusion: 该方法适用于全系统分析，并可作为未来集成能源系统优化的基础。

Abstract: The increasing complexity of energy systems due to sector coupling and
decarbonization calls for unified modeling frameworks that capture the physical
and structural interactions between electricity, gas, and heat networks. This
paper presents a graph-based modeling approach for multi-energy systems, where
each domain is represented as a layer in a multi-layer graph, and coupling
technologies are modeled as inter-layer edges via a dedicated coupling layer. A
steady-state solver based on a block-structured Newton-Raphson method is
developed to jointly compute flows and state variables across all carriers. The
proposed model is tested and validated on a realistic case study based on data
from a German distribution network. The results demonstrate convergence,
numerical accuracy, and consistent domain interaction, and demonstrate the
method's applicability for system-wide analysis and its potential as a
foundation for future optimizations in integrated energy systems.

</details>


### [279] [Parameter Robustness in Data-Driven Estimation of Dynamical Systems](https://arxiv.org/abs/2509.06534)
*Ayush Pandey*

Main category: eess.SY

TL;DR: 该研究提出了一种新的鲁棒性度量方法，用于量化参数摄动对线性动力系统估计的影响，并区分了控制作用、系统动力学和初始条件的不确定性贡献。


<details>
  <summary>Details</summary>
Motivation: 研究系统估计对参数摄动（系统动力学和初始条件）的鲁棒性，并提出一种新的鲁棒性度量方法。

Method: 开发了一种新的鲁棒性度量方法，用于估计具有和不具有控制作用的参数化线性动力系统。该方法区分了控制作用、系统动力学和初始条件的不确定性贡献，并与模型缩减的鲁棒性研究建立了联系。

Result: 提出了一种新颖的鲁棒性度量方法，用于估计参数化线性动力系统。该方法能够区分不确定性的来源，并为选择估计方法和设计数据驱动估计的成本函数提供了指导。

Conclusion: 这项工作为在存在参数不确定性的情况下选择合适的估计方法提供了指导，并为数据驱动估计开辟了新的途径，可以根据参数的重要性来优化成本函数。

Abstract: We study the robustness of system estimation to parametric perturbations in
system dynamics and initial conditions. We define the problem of
sensitivity-based parametric uncertainty quantification in dynamical system
estimation. The main contribution of this paper is the development of a novel
robustness metric for estimation of parametrized linear dynamical systems with
and without control actions. For the computation of this metric, we delineate
the uncertainty contributions arising from control actions, system dynamics,
and initial conditions. Furthermore, to validate our theoretical findings, we
establish connections between these new results and the existing literature on
the robustness of model reduction. This work provides guidance for selecting
estimation methods based on tolerable levels of parametric uncertainty and
paves the way for new cost functions in data-driven estimation that reward
sensitivity to a desired subset of parameters while penalizing others.

</details>


### [280] [Wireless Low-Latency Synchronization for Body-Worn Multi-Node Systems in Sports](https://arxiv.org/abs/2509.06541)
*Nico Krull,Lukas Schulthess,Michele Magno,Luca Benini,Christoph Leitner*

Main category: eess.SY

TL;DR: ESB协议在体育生物信号监测中实现亚毫秒级同步，优于BLE。


<details>
  <summary>Details</summary>
Motivation: 体育领域生物力学数据采集需要对分布式体感传感器节点进行亚毫秒级同步。

Method: 通过系统性地分析协议参数（包括CRC模式、比特率、传输模式和有效载荷处理），在实验室条件下对Nordic Semiconductor的ESB协议进行评估和表征，以实现低延迟的无线命令广播。

Result: 在优化重传机制后，使用单字节有效载荷，实现了504.99 ± 96.89微秒的平均设备到设备（D2D）延迟和311.78 ± 96.90微秒的网络到网络核心延迟，这显著优于蓝牙低功耗（BLE）的7.5毫秒连接间隔。

Conclusion: ESB协议能够提供确定性的、亚毫秒级的同步，适用于高频（500赫兹至1000赫兹）生物信号采集，是体育领域时间敏感、多节点可穿戴系统的可行解决方案，可实现精确事件对齐和可靠的高速数据融合。

Abstract: Biomechanical data acquisition in sports demands sub-millisecond
synchronization across distributed body-worn sensor nodes. This study evaluates
and characterizes the Enhanced ShockBurst (ESB) protocol from Nordic
Semiconductor under controlled laboratory conditions for wireless, low-latency
command broadcasting, enabling fast event updates in multi-node systems.
Through systematic profiling of protocol parameters, including
cyclic-redundancy-check modes, bitrate, transmission modes, and payload
handling, we achieve a mean Device-to-Device (D2D) latency of 504.99 +- 96.89
us and a network-to-network core latency of 311.78 +- 96.90 us using a one-byte
payload with retransmission optimization. This performance significantly
outperforms Bluetooth Low Energy (BLE), which is constrained by a 7.5 ms
connection interval, by providing deterministic, sub-millisecond
synchronization suitable for high-frequency (500 Hz to 1000 Hz) biosignals.
These results position ESB as a viable solution for time-critical, multi-node
wearable systems in sports, enabling precise event alignment and reliable
high-speed data fusion for advanced athlete monitoring and feedback
applications.

</details>


### [281] [Distributed Automatic Generation Control subject to Ramp-Rate-Limits: Anytime Feasibility and Uniform Network-Connectivity](https://arxiv.org/abs/2509.06588)
*Mohammadreza Doostmohammadian,Hamid R. Rabiee*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper considers automatic generation control over an information-sharing
network of communicating generators as a multi-agent system. The optimization
solution is distributed among the agents based on information consensus
algorithms, while addressing the generators' ramp-rate-limits (RRL). This is
typically ignored in the existing linear/nonlinear optimization solutions but
they exist in real-time power generation scenarios. Without addressing the RRL,
the generators cannot follow the assigned rate of generating power by the
optimization algorithm; therefore, the existing solutions may not necessarily
converge to the exact optimal cost or may lose feasibility in practice. The
proposed solution in this work addresses the ramp-rate-limit constraint along
with the box constraint (limits on the generated powers) and the
coupling-constraint (generation-demand balance) at all iteration times of the
algorithm. The latter is referred to as the anytime feasibility and implies
that at every termination point of the algorithm, the balance between the
demand and generated power holds. To improve the convergence rate of the
algorithm we further consider internal signum-based nonlinearity. We also show
that our solution can tolerate communication link removal. This follows from
the uniform-connectivity assumption on the communication network.

</details>


### [282] [Human-Hardware-in-the-Loop simulations for systemic resilience assessment in cyber-socio-technical systems](https://arxiv.org/abs/2509.06657)
*Francesco Simone,Marco Bortolini,Giovanni Mazzuto,Giulio di Gravio,Riccardo Patriarca*

Main category: eess.SY

TL;DR: 本研究提出了一种结合STAMP和HHIL的建模与仿真框架，用于评估复杂社会技术系统的韧性，并以油气工厂为例进行了测试。


<details>
  <summary>Details</summary>
Motivation: 现代工业系统日益复杂，需要更新安全管理方法，韧性管理尤为重要，但现有基于仿真的方法未能真实反映人类行为的影响。

Method: 提出了一种人类-硬件在环（HHIL）的建模与仿真框架，该框架与STAMP模型结合，以更真实地模拟人类行为及其对系统性能的影响。

Result: 在模拟的油气工厂网络攻击场景中，通过对比专家和新手操作员的行为，量化评估了操作员行为变化对整体系统性能的影响。

Conclusion: 该研究提供了一种量化评估复杂社会技术系统韧性的方法，并为理解和实施韧性提供了见解。

Abstract: Modern industrial systems require updated approaches to safety management, as
the tight interplay between cyber-physical, human, and organizational factors
has driven their processes toward increasing complexity. In addition to dealing
with known risks, managing system resilience acquires great value to address
complex behaviors pragmatically. This manuscript starts from the
System-Theoretic Accident Model and Processes (STAMP) as a modelling initiative
for such complexity. The STAMP can be natively integrated with simulation-based
approaches, which however fail to realistically represent human behaviors and
their influence on the system performance. To overcome this limitation, this
paper proposes a Human-Hardware-in-the-Loop (HHIL) modeling and simulation
framework aimed at supporting a more realistic and comprehensive assessments of
systemic resilience. The approach is tested on an experimental oil and gas
plant experiencing cyber-attacks, where two personas of operators (experts and
novices) work. This research provides a mean to quantitatively assess how
variations in operator behavior impact the overall system performance, offering
insights into how resilience should be understood and implemented in complex
socio-technical systems at large.

</details>


### [283] [Edge Server Monitoring for Job Assignment](https://arxiv.org/abs/2509.06722)
*Samuel Chamoun,Sirin Chakraborty,Eric Graves,Kevin Chan,Yin Sun*

Main category: eess.SY

TL;DR: 该研究提出了一种针对边缘服务器监控的面向目标通信方法，通过主动查询和历史反馈来更新服务器可用性估计，并使用基于净增益最大化的 (NGM) 调度算法来优化查询策略，以在有限的通信资源下最大化任务成功率。


<details>
  <summary>Details</summary>
Motivation: 边缘服务器监控中的任务调度面临服务器可用性动态波动的问题，需要准确估计可用性以保证任务成功率。

Method: 将查询调度问题建模为具有多动作的躁动多臂老虎机 (RMAB) 问题，并提出一种净增益最大化 (NGM) 调度算法，根据预期性能提升选择查询对象。

Result: 与基线策略相比，NGM 策略在模拟结果中显著提高了任务成功率，比轮询策略（Round-Robin Policy）高出 30%，比从不查询策略（Never-Query Policy）高出 107%。

Conclusion: 所提出的 NGM 策略能够有效解决边缘服务器监控中的查询调度问题，在通信资源受限的情况下显著提升任务成功率。

Abstract: In this paper, we study a goal-oriented communication problem for edge server
monitoring, where compute jobs arrive intermittently at dispatchers and must be
immediately assigned to distributed edge servers. Due to competing workloads
and the dynamic nature of the edge environment, server availability fluctuates
over time. To maintain accurate estimates of server availability states, each
dispatcher updates its belief using two mechanisms: (i) active queries over
shared communication channels and (ii) feedback from past job executions. We
formulate a query scheduling problem that maximizes the job success rate under
limited communication resources for queries. This problem is modeled as a
Restless Multi-Armed Bandit (RMAB) with multiple actions and addressed using a
Net-Gain Maximization (NGM) scheduling algorithm, which selects servers to
query based on their expected improvement in execution performance. Simulation
results show that the proposed NGM Policy significantly outperforms baseline
strategies, achieving up to a 30% gain over the Round-Robin Policy and up to a
107% gain over the Never-Query Policy.

</details>


### [284] [Steering Opinion through Dynamic Stackelberg Optimization](https://arxiv.org/abs/2509.06758)
*Hossein Rastgoftar*

Main category: eess.SY

TL;DR: 本文使用Friedkin-Johnsen (FJ)模型研究了社交网络中意见的演变动力学。在此框架下，社会被划分为两类群体：顽固型个体和普通型个体。顽固型个体的意见不受普通型个体的影响，而普通型个体的意见则会根据其邻居的意见进行演变。通过将原点定义为社会期望的集体意见，本文旨在最小化与该期望意见的偏差。为此，在顽固型和普通型群体之间建立了一个Stackelberg博弈，其中顽固型个体的意见调整和普通型个体的开放性变量作为决策变量。所提出的解决方案结合了二次规划和动态规划，以在每个离散时间步长使用前向和后向传播来优化这些决策变量。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过Friedkin-Johnsen (FJ)模型研究社交网络中的意见演变，并最小化个体意见与期望集体意见之间的偏差。

Method: 采用Stackelberg博弈，将顽固型个体的意见调整和普通型个体的开放性变量作为决策变量，并结合二次规划和动态规划，利用前向和后向传播在每个离散时间步长进行优化。

Result: 通过Stackelberg博弈和优化算法，成功地对意见演变进行了建模和优化，实现了与期望集体意见的最小化偏差。

Conclusion: 本文提出的基于FJ模型和Stackelberg博弈的意见演变优化方法能够有效指导顽固型和普通型个体调整其意见和开放性，以达到期望的集体意见。

Abstract: This paper employs the Friedkin-Johnsen (FJ) model to describe the dynamics
of opinion evolution within a social network. Under the FJ framework, the
society is divided into two subgroups that include stubborn agents and regular
agents. The opinions of stubborn agents are not influenced by regular agents,
whereas the opinions of regular agents evolve based on the opinions of their
neighboring agents. By defining the origin as the desired collective opinion of
the society, the objective of the paper is to minimize deviations from this
desired opinion. To achieve this, a Stackelberg game is established between the
stubborn and regular subgroups, where the opinion adjustments of the stubborn
agents and the openness variables of regular agents serve as the decision
variables. The proposed solution approach integrates quadratic programming and
dynamic programming to optimize these decision variables at each discrete time
step using forward and backward propagation.

</details>


### [285] [Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks](https://arxiv.org/abs/2509.06775)
*Po-Heng Chou,Pin-Qi Fu,Walid Saad,Li-Chun Wang*

Main category: eess.SY

TL;DR: 本文提出了一种基于强化学习的AI调度框架，用于解决5G NR Sidelink（SL）在授权和非授权频谱共享中面临的共存挑战，通过自主感知网络状态并调整策略，显著降低了阻塞率，提高了服务质量（QoS）。


<details>
  <summary>Details</summary>
Motivation: 5G NR Sidelink（SL）在与蜂窝通信（CC）共享授权频谱以及与Wi-Fi共享非授权频谱时，面临严峻的共存挑战，需要有效的调度机制来保证服务质量（QoS）。

Method: 提出了一种基于双深度Q网络（DDQN）的智能体（Agentic AI）调度框架，该框架能够自主感知队列动态、信道条件和共存状态，并自适应地调整调度策略。

Result: 与传统的基于阈值的方法相比，该框架在有限的授权带宽下，阻塞率最高可降低87.5%。

Conclusion: 智能体AI（Agentic AI）有潜力为未来的NR SL系统实现稳定、感知服务质量（QoS）和自适应的调度。

Abstract: This paper presents an agentic artificial intelligence (AI)-driven double
deep Q-network (DDQN) scheduling framework for licensed and unlicensed band
allocation in New Radio (NR) sidelink (SL) networks. SL must share licensed
spectrum with cellular communications (CC) and unlicensed bands with Wi-Fi,
posing significant challenges for coexistence. Unlike prior rule-based or
threshold-based methods, the proposed agentic scheduler autonomously perceives
queueing dynamics, channel conditions, and coexistence states, and adapts its
policy to maintain quality-of-service (QoS). Simulation results show that our
framework reduces the blocking rate by up to 87.5% compared to threshold-based
scheduling under limited licensed bandwidth. These findings demonstrate the
potential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling
for future NR SL systems.

</details>


### [286] [Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor](https://arxiv.org/abs/2509.06853)
*Juan D. Gil,Ehecatl Antonio Del Rio Chanona,José L. Guzmán,Manuel Berenguel*

Main category: eess.SY

TL;DR: 本研究首次将强化学习（RL）与行为模仿（BC）结合，提出了一种用于开放光生物反应器（PBR）pH调控的混合控制方法，通过离线训练和在线微调，有效应对生物过程的复杂性和环境干扰，相比传统PID和标准RL，在误差积分和控制成本方面均有显著改善。


<details>
  <summary>Details</summary>
Motivation: 开放光生物反应器（PBR）在生产单元的固有复杂性和易受环境干扰的特性，给维持稳定和最优的生物过程条件带来了挑战，特别是在pH调控方面。

Method: 提出一种结合行为模仿（BC）的强化学习（RL）控制方法。该方法首先通过一个名义上的比例-积分-微分（PID）控制器生成的轨迹进行离线训练，然后在实际系统上进行每日在线微调，以适应不断变化的工艺动态并更好地抑制快速、瞬时的干扰。

Result: 仿真研究表明，与PID控制相比，该方法的绝对误差积分（IAE）降低了8%，控制成本降低了54%。与标准的离策略RL相比，IAE降低了5%，控制成本降低了7%。为期8天的实验验证也证实了该方法的鲁棒性和可靠性。

Conclusion: 本研究证明了基于RL的方法在生物过程控制方面的潜力，并通过一种混合离线-在线策略成功应用于开放PBR的pH调控，为将其推广到其他非线性、易受干扰的系统铺平了道路。

Abstract: The inherent complexity of living cells as production units creates major
challenges for maintaining stable and optimal bioprocess conditions, especially
in open Photobioreactors (PBRs) exposed to fluctuating environments. To address
this, we propose a Reinforcement Learning (RL) control approach, combined with
Behavior Cloning (BC), for pH regulation in open PBR systems. This represents,
to the best of our knowledge, the first application of an RL-based control
strategy to such a nonlinear and disturbance-prone bioprocess. Our method
begins with an offline training stage in which the RL agent learns from
trajectories generated by a nominal Proportional-Integral-Derivative (PID)
controller, without direct interaction with the real system. This is followed
by a daily online fine-tuning phase, enabling adaptation to evolving process
dynamics and stronger rejection of fast, transient disturbances. This hybrid
offline-online strategy allows deployment of an adaptive control policy capable
of handling the inherent nonlinearities and external perturbations in open
PBRs. Simulation studies highlight the advantages of our method: the Integral
of Absolute Error (IAE) was reduced by 8% compared to PID control and by 5%
relative to standard off-policy RL. Moreover, control effort decreased
substantially-by 54% compared to PID and 7% compared to standard RL-an
important factor for minimizing operational costs. Finally, an 8-day
experimental validation under varying environmental conditions confirmed the
robustness and reliability of the proposed approach. Overall, this work
demonstrates the potential of RL-based methods for bioprocess control and paves
the way for their broader application to other nonlinear, disturbance-prone
systems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [287] [High-order Magnus Expansion for Hamiltonian Simulation](https://arxiv.org/abs/2509.06054)
*Di Fang,Diyi Liu,Shuchen Zhu*

Main category: quant-ph

TL;DR: 该研究提出了一个高精度的量子算法，用于高效模拟含时哈密顿量的量子动力学，其成本仅对哈密顿量的时间依赖性有对数依赖。


<details>
  <summary>Details</summary>
Motivation: 高效模拟含时哈密顿量的量子动力学对于时变系统和相互作用绘景中的时不变系统都很重要，但现有算法在处理时间排序的复杂性时面临挑战，要么成本随哈密顿量时间导数呈多项式增长，要么精度受限。

Method: 通过分析截断的马格纳斯展开的误差界限，发现只涉及哈密顿量项的嵌套换位子，而无需时间导数。基于此，设计了一种高精度量子算法，具有明确的电路结构。

Result: 该算法实现了与换位子结构相关的成本缩放，并且在高精度条件下，其成本仅对哈密顿量的时间变化有对数依赖。

Conclusion: 所提出的算法能够高效处理一般的含时量子动力学模拟，包括相互作用绘景中的情况。

Abstract: Efficient simulation of quantum dynamics with time-dependent Hamiltonians is
important not only for time-varying systems but also for time-independent
Hamiltonians in the interaction picture. Such simulations are more challenging
than their time-independent counterparts due to the complexity introduced by
time ordering. Existing algorithms that aim to capture commutator-based scaling
either exhibit polynomial cost dependence on the Hamiltonian's time derivatives
or are limited to low-order accuracy. In this work, we establish the general
commutator-scaling error bounds for the truncated Magnus expansion at arbitrary
order, where only Hamiltonian terms appear in the nested commutators, with no
time derivatives involved. Building on this analysis, we design a high-order
quantum algorithm with explicit circuit constructions. The algorithm achieves
cost scaling with the commutator structure in the high-precision regime and
depends only logarithmically on the Hamiltonian's time variation, making it
efficient for general time-dependent settings, including the interaction
picture.

</details>


### [288] [Enhancing Gradient Variance and Differential Privacy in Quantum Federated Learning](https://arxiv.org/abs/2509.05377)
*Duc-Thien Phan,Minh-Duong Nguyen,Quoc-Viet Pham,Huilong Pi*

Main category: quant-ph

TL;DR: 本研究提出了一种结合差分隐私和噪声估计的量子联邦学习（QFL）新方法，以解决QNN在训练中遇到的局部模型易受噪声影响、梯度下降易受攻击以及探索能力受限等挑战。实验结果表明，该方法在MNIST和CIFAR-10数据集上分别达到了98.47%和83.85%的准确率，同时保证了快速的执行时间和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络（QNN）在量子联邦学习（QFL）中的应用面临着局部模型易受噪声影响、梯度下降易受攻击、探索能力受限以及模型精度和收敛速度受损等挑战。

Method: 提出了一种新的QFL技术，该技术结合了差分隐私和噪声估计策略，用于量化和缓解中间量子噪声的影响。此外，设计了一种自适应噪声生成方案，以减轻与QNN梯度方差消失相关的隐私威胁，并增强对设备噪声的鲁棒性。

Result: 实验结果表明，所提出的算法在MNIST数据集上达到了高达98.47%的测试准确率，在CIFAR-10数据集上达到了83.85%的测试准确率。该算法有效平衡了收敛性，降低了通信成本，减轻了中间量子噪声的不利影响，并保持了强大的隐私保护和快速的执行时间。

Conclusion: 本研究提出的QFL新方法通过引入差分隐私和噪声估计策略，有效解决了QNN训练中的噪声和隐私问题，并在实际数据集上取得了优异的性能。

Abstract: Upon integrating Quantum Neural Network (QNN) as the local model, Quantum
Federated Learning (QFL) has recently confronted notable challenges. Firstly,
exploration is hindered over sharp minima, decreasing learning performance.
Secondly, the steady gradient descent results in more stable and predictable
model transmissions over wireless channels, making the model more susceptible
to attacks from adversarial entities. Additionally, the local QFL model is
vulnerable to noise produced by the quantum device's intermediate noise states,
since it requires the use of quantum gates and circuits for training. This
local noise becomes intertwined with learning parameters during training,
impairing model precision and convergence rate. To address these issues, we
propose a new QFL technique that incorporates differential privacy and
introduces a dedicated noise estimation strategy to quantify and mitigate the
impact of intermediate quantum noise. Furthermore, we design an adaptive noise
generation scheme to alleviate privacy threats associated with the vanishing
gradient variance phenomenon of QNN and enhance robustness against device
noise. Experimental results demonstrate that our algorithm effectively balances
convergence, reduces communication costs, and mitigates the adverse effects of
intermediate quantum noise while maintaining strong privacy protection. Using
real-world datasets, we achieved test accuracy of up to 98.47\% for the MNIST
dataset and 83.85\% for the CIFAR-10 dataset while maintaining fast execution
times.

</details>


### [289] [Practical Fidelity Limits of Toffoli Gates in Superconducting Quantum Processors](https://arxiv.org/abs/2509.05395)
*M. AbuGhanem*

Main category: quant-ph

TL;DR: IBM的127量子比特超导量子处理器被用于实现Toffoli门（CCNOT），这是量子计算中的一个关键资源，尤其是在量子纠错和量子算术中。研究人员使用针对硬件的、符合连接性约束的优化分解方法，集成了状态制备、门综合和量子状态/过程层析（QST/QPT），以评估三种不同输入状态（GHZ、W和均匀叠加态）的保真度。结果显示，对于GHZ态，保真度分别为98.442%（无噪声模拟）、81.470%（考虑噪声的量子模拟）和56.368%（真实量子硬件）。对于W态，保真度分别为98.739%、79.900%和63.689%。对于均匀叠加态，保真度分别为99.490%、85.469%和61.161%。过程层析实验得出过程保真度为98.976%（无噪声）和80.160%（考虑噪声的模拟）。这些结果实证地表征了多量子比特电路中依赖于状态的错误模式，并量化了门分解策略与原生硬件性能之间的权衡，为可扩展、硬件高效的量子电路设计提供了实用见解。


<details>
  <summary>Details</summary>
Motivation: Toffoli门（CCNOT）在量子纠错和量子算术中起着核心作用，但其在当前量子硬件上的高效实现受到噪声和连接性限制。本研究旨在对Toffoli门进行面向硬件的特性分析，以优化其在IBM量子处理器上的实现。

Method: 使用针对硬件的、符合连接性约束的优化分解方法，在IBM的127量子比特超导量子处理器上执行Toffoli门。研究集成了状态制备、门综合和量子状态/过程层析（QST/QPT），以评估三种不同输入状态（GHZ、W和均匀叠加态）在无噪声模拟、考虑噪声的模拟和真实硬件执行下的保真度。

Result: 对于GHZ态，在无噪声模拟、考虑噪声的模拟和真实硬件上测得的状态保真度分别为98.442%、81.470%和56.368%。对于W态，状态保真度分别为98.739%、79.900%和63.689%。对于均匀叠加态，状态保真度分别为99.490%、85.469%和61.161%。过程层析实验得出过程保真度为98.976%（无噪声）和80.160%（考虑噪声的模拟）。

Conclusion: 本研究通过实证方式表征了多量子比特电路中与状态相关的错误模式，并量化了门分解策略与原生硬件性能之间的权衡。研究结果为可扩展、硬件高效的量子电路设计提供了实用的见解。

Abstract: High-fidelity multi-qubit gates are a critical resource for near-term quantum
computing, as they underpin the execution of both quantum algorithms and
fault-tolerant protocols. The Toffoli gate (CCNOT), in particular, plays a
central role in quantum error correction and quantum arithmetic, yet its
efficient implementation on current quantum hardware remains limited by noise
and connectivity constraints. In this work, we present a hardware-aware
characterization of the Toffoli gate using optimized, connectivity-compliant
decompositions executed on IBM's 127-qubit superconducting quantum processors.
Our study integrates state preparation, gate synthesis, and quantum
state/process tomography (QST/QPT) to evaluate fidelity across three distinct
classes of input states: Greenberger-Horne-Zeilinger (GHZ), W, and the uniform
superposition of all three-qubit computational basis states -- under noise-free
simulation, noise-aware emulation, and real hardware execution. For GHZ states,
we report state fidelities of 98.442% (noise-free simulation), 81.470%
(noise-aware quantum emulation), and 56.368% (real quantum hardware). For W
states, state fidelities are 98.739%, 79.900%, and 63.689%, respectively, and
for the uniform superposition state, we observe state fidelities of 99.490%,
85.469%, and 61.161%. Comparative QPT experiments yield process fidelities of
98.976% (noise-free) and 80.160% (noise-aware emulation). Our results
empirically characterize state-dependent error patterns in multi-qubit circuits
and quantify trade-offs between gate decomposition strategies and native
hardware performance, offering practical insights for scalable,
hardware-efficient quantum circuit design.

</details>


### [290] [A microwave-activated high-fidelity three-qubit gate scheme for fixed-frequency superconducting qubits](https://arxiv.org/abs/2504.21346)
*Kui Zhao,Wei-Guo Ma,Ziting Wang,Hao Li,Kaixuan Huang,Yun-Hao Shi,Kai Xu,Heng Fan*

Main category: quant-ph

TL;DR: 该研究提出了一种微波激活的三比特门协议，用于固定频率的超导量子处理器，可实现超过99.9%的平均门保真度，并能有效抑制ZZ串扰和制造差异。


<details>
  <summary>Details</summary>
Motivation: 固定频率架构虽然简化了控制，但受到残余ZZ串扰的限制。本研究旨在提出一种新的三比特门协议，以克服这一限制，同时提高量子处理器的可扩展性。

Method: 提出了一种利用三阶非线性相互作用的微波激活三比特门协议，用于固定频率的transmon量子比特，并结合了相位补偿优化协议。通过数值模拟来评估门保真度和误差来源。

Result: 数值模拟显示，平均门保真度超过99.9%。静态长程ZZ耦合被识别为多比特系统中的主要误差源，但可以在大失谐（~1 GHz）下得到抑制。该协议还对制造差异具有鲁棒性。

Conclusion: 该研究提出了一种硬件高效的策略，通过提高相干性、减少频谱拥塞以及为抗噪声量子操作提供工具，推动了可扩展量子计算系统的发展。

Abstract: Scalable superconducting quantum processors require balancing critical
constraints in coherence, control complexity, and spectral crowding.
Fixed-frequency architectures suppress flux noise and simplify control via
all-microwave operations but remain limited by residual ZZ crosstalk. Here we
propose a microwave-activated three-qubit gate protocol for fixed-frequency
transmon qubits in the large-detuning regime ($|\Delta| \gg g$), leveraging the
third-order nonlinear interaction to coherently exchange $|001\rangle
\leftrightarrow |110\rangle$ states. By incorporating a phase-compensated
optimization protocol, numerical simulations demonstrate a high average gate
fidelity exceeding $99.9\%$. Systematic error analysis identifies static
long-range ZZ coupling as the dominant error source in multi-qubit systems,
which can be suppressed via operations in the large-detuning regime ($\sim 1$
GHz). This approach simultaneously enhances gate fidelity while preserving
spectral isolation, ensuring compatibility with existing all-microwave
controlled-Z gate frameworks. The protocol exhibits intrinsic robustness to
fabrication-induced qubit parameter variations. This hardware-efficient
strategy advances scalable quantum computing systems by improving coherence
properties, reducing spectral congestion, and expanding the experimental
toolkit for error-resilient quantum operations in the noisy intermediate-scale
quantum era.

</details>


### [291] [Efficient Preparation of Resource States for Hamiltonian Simulation and Universal Quantum Computation](https://arxiv.org/abs/2509.05404)
*Thierry N. Kaldenbach,Isaac D. Smith,Hendrik Poulsen Nautrup,Matthias Heller,Hans J. Briegel*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量子计算资源态制备方法，以提高量子计算的资源利用率。


<details>
  <summary>Details</summary>
Motivation: 算法定制图态在测量基量子计算 (MBQC) 中可以减少电路深度、纠缠门和物理量子比特的数量。本研究将先前关于算法定制图态的研究扩展到周期性广义泡利旋转序列。

Method: 提出了一种基于模拟退火的增强算法来寻找最优周期图态，并提出了一种基于图态和CNOT门梯子的新方案（抗交换基MBQC）。

Result: 将两种方法应用于从最小生成哈密顿量集合中导出通用资源态，并提供了相应的算法。

Conclusion: 通过对凝聚态物理和通用量子计算的各种实例进行演示和比较，证明了这两种方法的有效性。

Abstract: The direct compilation of algorithm-specific graph states in
measurement-based quantum computation (MBQC) can lead to resource reductions in
terms of circuit depth, entangling gates, and even the number of physical
qubits. In this work, we extend previous studies on algorithm-tailored graph
states to periodic sequences of generalized Pauli rotations, which commonly
appear in, e.g., Trotterized Hamiltonian simulation. We first implement an
enhanced simulated-annealing-based algorithm to find optimal periodic graph
states within local-Clifford (LC-)MBQC. In addition, we derive a novel scheme
for the preparation of resource states based on a graph state and a ladder of
CNOT gates, which we term anticommutation-based (AC-)MBQC, since it uncovers a
direct relationship between the graph state and the anticommutation matrix for
the set of Hamilonians generating the computation. We also deploy our two
approaches to derive universal resource states from minimal universal sets of
generating Hamiltonians, thus providing a straightforward algorithm for finding
the former. Finally, we demonstrate and compare both of our methods based on
various examples from condensed matter physics and universal quantum
computation.

</details>


### [292] [Room Temperature Single Photon Detection at 1550 nm using van der Waals Heterojunction](https://arxiv.org/abs/2509.05455)
*Nithin Abraham,Kenji Watanabe,Takashi Taniguchi,Kausik Majumdar*

Main category: quant-ph

TL;DR: 这项工作提出了一种利用纳米材料（黑磷）和范德华探针耦合的新型室温单光子探测器，实现了在 1550 nm 波长下的高量子效率和低暗计数率。


<details>
  <summary>Details</summary>
Motivation: 现有室温单光子探测器（SPDs）存在波长限制（硅基SPADs）或效率低、暗计数率高、易产生重频效应等问题（InGaAs基SPADs），且一些材料的制备过程对环境有害。因此，需要开发在长波长（如1550 nm）下运行且性能优越的室温SPDs。

Method: 通过将低带隙（约 350 meV）的吸收材料（黑磷）与能够探测离散电子波动的灵敏范德华探针耦合，并优化器件设计，以实现对 1550 nm 光子的探测。

Result: 实现了 1550 nm 波长下的单光子探测，在室温下测得了 21.4% 的总量子效率（对偏振光估计为 42.8%），以及约 720 Hz 的最低暗计数率。

Conclusion: 利用黑磷与范德华探针的耦合，成功研制出一种能够在 1550 nm 波长下工作的室温单光子探测器，克服了现有技术的局限性，展示了纳米材料在光子探测领域的应用潜力。

Abstract: Single-photon detectors (SPDs) are crucial in applications ranging from
space, biological imaging to quantum communication and information processing.
The SPDs that operate at room temperature are of particular interest to broader
application space as the energy overhead introduced by the cryogenic cooling
can be avoided. Although silicon-based single photon avalanche diodes (SPADs)
are well matured and operate at room temperature, the bandgap limitation
restricts their operation at telecommunication wavelength (1550 nm) and beyond.
InGaAs-based SPADs, on the other hand, are sensitive to 1550 nm photons, but
suffer from relatively lower efficiency, high dark count rate, afterpulsing
probability, and pose hazards to the environment from the fabrication process.
In this work, we demonstrate how we can leverage the properties of
nanomaterials to address these challenges and realise a room temperature
single-photon detector capable of operating at 1550 nm. We achieve this by
coupling a low bandgap ($\sim 350~meV$) absorber (black phosphorus) to a
sensitive van der Waals probe that is capable of detecting discrete electron
fluctuation. We optimize the device for operation at $1550~nm$ and demonstrate
an overall quantum efficiency of $21.4\%$ (estimated as $42.8\%$ for polarized
light), and a minimum dark count of $\sim 720~Hz$ at room temperature.

</details>


### [293] [Mitigating Measurement Crosstalk via Pulse Shaping](https://arxiv.org/abs/2509.05437)
*Yang Gao,Feiyu Li,Yang Liu,Zhen Yang,Jiayu Ding,Wuerkaixi Nuerbolati,Ruixia Wang,Tang Su,Yanjun Ma,Yirong Jin,Haifeng Yu,He Wang,Fei Yan*

Main category: quant-ph

TL;DR: 量子纠错需要快速重复的量子比特测量，但现有技术中的信号串扰会降低读出保真度。本文提出了一种新的脉冲整形技术，通过在相邻谐振器频率处形成谱陷波来抑制测量串扰，从而实现快速、低串扰的多路复用测量，而无需额外的硬件开销。


<details>
  <summary>Details</summary>
Motivation: 现有的量子纠错协议需要快速重复的量子比特测量，但超导量子系统中多路复用读出技术中的信号串扰会降低量子比特的退相和读出保真度。

Method: 本文提出了一种受DRAG协议启发的脉冲整形技术，通过在相邻谐振器频率处形成谱陷波来抑制测量串扰。

Result: 该方法有效地缓解了虚假信号干扰，并实现了快速、低串扰的多路复用测量，而无需额外的硬件开销。

Conclusion: 这项技术能够与现有的读出架构无缝集成，是可扩展量子计算的关键进展。

Abstract: Quantum error correction protocols require rapid and repeated qubit
measurements. While multiplexed readout in superconducting quantum systems
improves efficiency, fast probe pulses introduce spectral broadening, leading
to signal leakage into neighboring readout resonators. This crosstalk results
in qubit dephasing and degraded readout fidelity. Here, we introduce a pulse
shaping technique inspired by the derivative removal by adiabatic gate (DRAG)
protocol to suppress measurement crosstalk during fast readout. By engineering
a spectral notch at neighboring resonator frequencies, the method effectively
mitigates spurious signal interference. Our approach integrates seamlessly with
existing readout architectures, enabling fast, low-crosstalk multiplexed
measurements without additional hardware overhead -- a critical advancement for
scalable quantum computing.

</details>


### [294] [Continuous-Time Quantum State Transfer with a Generalized Laplacian](https://arxiv.org/abs/2509.05454)
*Yujia Shi*

Main category: quant-ph

TL;DR: 通过调整广义拉普拉斯算子 L_k = A+kD 中的参数 k，可以提高某些图中状态传输的保真度。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过调整广义拉普拉斯算子 L_k = A+kD 中的参数 k 来提高状态传输的保真度。

Method: 研究由广义拉普拉斯算子 L_k = A+kD（其中 L_k = A+kD，A 是邻接矩阵，D 是度矩阵，k 是实值参数）产生的连续时间量子行走。

Result: 对于某些图，调整参数 k 可以显著提高端点之间状态传输的保真度。

Conclusion: 通过调整广义拉普拉斯算子 L_k = A+kD 中的参数 k，可以提高某些图中状态传输的保真度。

Abstract: Quantum walks generated by the adjacency matrix or the Laplacian are known to
exhibit low transfer fidelity on general graphs. In this paper, we study
continuous-time quantum walks governed by the generalized Laplacian operator
L_k = A+kD, where A is the adjacency matrix, D is the degree matrix, and k is a
real-valued parameter. Recent work of Duda, McLaughlin, and Wong showed that in
the single-excitation Heisenberg (XYZ) spin model, one can realize walks
generated by this family of operators on signed weighted graphs. Motivated by
earlier studies on vertex-weighted graphs, we demonstrate that for certain
graphs, tuning the parameter k can significantly enhance the fidelity of state
transfer between endpoints.

</details>


### [295] [Cartan-Khaneja-Glaser decomposition of $\SU(2^n)$ via involutive automorphisms](https://arxiv.org/abs/2509.05468)
*John A. Mora Rodríguez,Arthur C. R. Dutra,Henrique N. Sá Earp,Marcelo Terra Cunha*

Main category: quant-ph

TL;DR: 提出一种新的算法，用于对SU(2^n)中的酉矩阵进行Cartan-Khaneja-Glaser分解，解决了现有方法的局限性，并提供了Python实现和性能验证。


<details>
  <summary>Details</summary>
Motivation: 对高效量子电路设计至关重要的SU(2^n)中酉矩阵的Cartan-Khaneja-Glaser分解。Sá Earp和Pachos（2005）的方法存在依赖于定义不明确的矩阵对数和截断的Baker-Campbell-Hausdorff（BCH）级数收敛性问题。

Method: 利用对合自同构的代数结构和对称李代数分解，提出一种稳定的递归分解方法，解决了现有方法的局限性。

Result: 在SU(8)和SU(16)中的矩阵上，使用随机酉基准测试了该算法的性能，并提供了完整的Python实现，可用于开源存储库。

Conclusion: 该算法生成的分解直接适用于实际的量子硬件，其因子可以使用标准门集近乎最优地实现。

Abstract: We present a novel algorithm for performing the Cartan-Khaneja-Glaser
decomposition of unitary matrices in $\SU(2^n)$, a critical task for efficient
quantum circuit design. Building upon the approach introduced by S\'a Earp and
Pachos (2005), we overcome key limitations of their method, such as reliance on
ill-defined matrix logarithms and the convergence issues of truncated
Baker-Campbell-Hausdorff(BCH) series. Our reformulation leverages the algebraic
structure of involutive automorphisms and symmetric Lie algebra decompositions
to yield a stable and recursive factorization process. We provide a full Python
implementation of the algorithm, available in an open-source repository, and
validate its performance on matrices in $\SU(8)$ and $\SU(16)$ using random
unitary benchmarks. The algorithm produces decompositions that are directly
suited to practical quantum hardware, with factors that can be implemented
near-optimally using standard gate sets.

</details>


### [296] [Bayesian Greedy Receiver for Pulse Position Modulation without an Error Floor under Thermal Noise](https://arxiv.org/abs/2509.05472)
*Leo Bia,Christos N. Gagatsos,Saikat Guha*

Main category: quant-ph

TL;DR: 该论文提出了一种新的切片贝叶斯贪婪接收机，用于在热噪声和光子稀疏条件下进行M元脉冲位置调制解调，该接收机在噪声存在的情况下优于标准贪婪接收机。


<details>
  <summary>Details</summary>
Motivation: 为了在热噪声和光子稀疏条件下，为M元脉冲位置调制解调设计更优的量子接收机架构。

Method: 在贪婪接收机框架的基础上，研究了联合优化的位移-压缩和Dolinar接收机。在此基础上，引入了一种新的切片贝叶斯贪婪接收机，该接收机将每个PPM时隙划分为多个光切片，并利用贝叶斯规则在每个切片上更新关于码字假设的完整后验分布。

Result: 与标准贪婪接收机相比，新提出的切片贪婪接收机在噪声存在的情况下表现更好，并且在有足够切片分辨率的情况下，似乎可以避免噪声基底。

Conclusion: 切片贝叶斯贪婪接收机是一种有前景的量子接收机架构，尤其是在光子稀疏和存在噪声的条件下，能够有效进行M元脉冲位置调制解调。

Abstract: We investigate quantum receiver architectures for demodulation $M$-ary Pulse
Position Modulation under thermal noise and photon-starved conditions. Building
on the greed receiver framework, we analyze it using jointly optimized
displacement-squeezing and the Dolinar receiver. We further introduce a novel
slicing Bayesian greedy receiver, which partitions each PPM time slot into
multiple optical slices and update the full posterior distribution over
codeword hypothesis at each slice using Bayes' rule. Under the presence of
noise, our slicing greedy receiver outperforms the standard greedy receiver and
appears to avoid a noise floor given sufficient slicing resolution.

</details>


### [297] [The complementarity relations in a multi-path interferometer with quantum memory](https://arxiv.org/abs/2509.05571)
*Yue Sun,Ming-Jing Zhao,Peng-Tong Li*

Main category: quant-ph

TL;DR: 研究了多路径干涉仪中量子态的互补性关系，提出了可见度、路径可区分度、混合度和纠缠之间的对偶和三元关系，并量化了纠缠在多路径干涉仪中的作用。


<details>
  <summary>Details</summary>
Motivation: 研究量子态的互补性关系及其在多路径干涉仪中的应用，特别是混合态的输入。

Method: 在包含探测器和量子存储器的多路径干涉仪中，研究了混合态的互补性关系，建立了可见度和路径可区分度之间的对偶关系，并推导了可见度、路径可区分度、混合度和纠缠之间的三元关系。

Result: 发现了可见度和路径可区分度之间的对偶关系，以及可见度、路径可区分度、混合度和纠缠之间的三元关系。

Conclusion: 在二维路径干涉仪中，互补性关系是完备的，并且量化了纠缠在多路径干涉仪中的作用。

Abstract: The complementarity relations impose the constraints on different aspects of
quantum states. We study the complementarity relation within a multi-path
interferometer that includes detectors and quantum memory. Here we consider the
mixed states as the input states. We establish a duality relation between the
visibility and the path distinguishability. Based on this duality, two triality
relations, one is related with visibility, path distinguishability, and
mixedness, the other is related with visibility, path distinguishability, and
entanglement, were derived respectively. Therefore, the role of entanglement in
multi-path interferometer is characterized quantitatively. These
complementarity relations are all complete for the two-path interferometer.

</details>


### [298] [Generation of Correlated Quantum Random Number Sequences with Bright Twin Beams](https://arxiv.org/abs/2509.05573)
*Anirudh Shekar,Chirang R. Patel,Jerin A. Thachil,Ashok Kumar*

Main category: quant-ph

TL;DR: 这项工作利用铷-85蒸气中的四波混频产生了双生光束，并生成了高度相关的随机数串。通过测量强度差压缩来验证量子相关性，并在2兆赫兹的分析频率下测量到双生光束强度涨落之间有95%的相关性。从量子涨落中提取的熵超过5比特/样本。通过后选择和哈希算法，以6兆比特/秒的速率生成了通过NIST和TestU01统计测试的二进制随机数串。该方法在量子密码学和量子通信中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 量子随机数生成器在安全通信和加密中起着至关重要的作用。

Method: 在铷-85蒸气中使用四波混频在双重Lambda（double-Lambda）构型中产生明亮的双生光束，并生成了两串高度相关的随机数。通过测量产生的双生光束的强度差压缩来验证量子相关性。

Result: 在2兆赫兹的分析频率下，测量到双生光束的随机强度涨落之间有95%的相关性。从量子涨落中观察到超过5比特/样本的熵。通过后选择和哈希算法，以6兆比特/秒的速率提取了二进制随机数串，该串通过了NIST和TestU01的标准统计测试。

Conclusion: 所提出的产生明亮双生光束的方法简单，在量子密码学和量子通信领域具有应用潜力。

Abstract: Quantum random number generators play a vital role in securing communication
and encryption. In the present work, we have produced bright twin beams using
four-wave mixing in a double-{\Lambda} configuration in rubidium-85 vapor and
generated two strings of highly correlated random numbers. The randomness
originates from the probabilistic nature of the intensity fluctuations of the
twin beams and the quantum correlations are certified by measuring the
intensity-difference squeezing in the generated twin beams. At an analysis
frequency of 2 MHz, we have measured 95% correlation between the random
intensity fluctuations of the twin beams. We observe over 5 bits/sample of
entropy from the quantum fluctuations of the twin beams. Furthermore, to
extract identical strings of random numbers, post-selection of the binned data
and hashing algorithms are used, leading to a binary string of random numbers
at a rate of 6 Mbps that passes standard statistical tests from NIST and
TestU01. Here, the simplicity of generating bright twin beams shows the
potential of this method in quantum cryptography and quantum communication.

</details>


### [299] [Stability of Adiabatic States in a Dissipative Three-Level System](https://arxiv.org/abs/2509.05646)
*Emil A. Gazazyan,Gayane G. Grigoryan,Vanush Paturyan*

Main category: quant-ph

TL;DR: 分析了三能级量子系统中绝热态的稳定性条件，并展示了在室温下通过b态进行有效布居数转移的方法。


<details>
  <summary>Details</summary>
Motivation: 研究三能级量子系统中绝热态的稳定性的充分必要条件。

Method: 通过解析和数值方法研究了在精确双光子共振条件下各种三能级系统配置的稳定性。

Result: 发现所有方案中，研究态的寿命由未通过偶极跃迁连接的能级之间的退相干时间决定。 尽管弛豫时间相对较长，但在室温下通过b态实现了有效的布居数转移。 当单光子失谐较大时，所谓的b态具有与暗态相同的寿命。 对单光子失谐任意值下的绝热态演化进行了数值研究。

Conclusion: 绝热态的寿命和演化行为受退相干时间和单光子失谐等因素影响。

Abstract: The necessary and sufficient conditions for the stability of adiabatic states
in three-level quantum systems are investigated analytically and numerically.
Various possible configurations of three-level systems under exact two-photon
resonance are considered. It is shown that in all these schemes, the lifetime
of the studied states is determined by the dephasing time between levels that
are not connected by a dipole transition. An efficient population transfer
through the b-state at room temperature is demonstrated despite relatively long
relaxation times. It is also demonstrated that, in case of large one-photon
detuning, the so-called b-state has the same lifetime as that of the dark
state. The evolution of adiabatic states for arbitrary values of single-photon
detunings has been studied numerically.

</details>


### [300] [Enhanced magnetic field sensitivity of shallow NV$^-$ ensembles via high-temperature implantation](https://arxiv.org/abs/2509.05647)
*Joa Al Yahya,Anatole Bach,Jayash Panigrahi,Pauline Perrin,Ionut Balasa,Diana Serrano,Alexey Tiranov,Jocelyn Achard,Alexandre Tallaire,Philippe Goldner*

Main category: quant-ph

TL;DR: 采用高温N2+离子注入技术提高NV中心制备产率和维持量子性质，以提升金刚石量子传感器的磁场灵敏度。


<details>
  <summary>Details</summary>
Motivation: 高密度、浅层NV$^-$是金刚石量子传感器的关键，但传统离子注入法存在产率低、样品非晶化和表面效应影响量子性质等问题。

Method: 研究不同能量（10-15 keV）和不同温度（20, 400, 800°C）下N2+离子注入对格子损伤、NV$^-$产率及自旋性质的影响，最高注入量为1e15 ions/cm2。

Result: 在800°C高温下，金刚石在高达1e15 ions/cm2的注入量下仍保持结构完整且无非晶化。高温注入可使NV$^-$产率提高高达5倍，同时不损害T2*, T2和T1自旋相干时间。

Conclusion: 高温N2+离子注入是一种有前景的技术，能够提高NV$^-$的制备产率，同时保持优良的自旋性质，从而提高金刚石量子传感器的磁场灵敏度。

Abstract: Dense and shallow ensembles of negatively charged nitrogen-vacancy centers
(NV$^-$) with good optical and spin properties play a key role in the
performance enhancement of diamond-based quantum sensors. Ion implantation
enables precise control of NV$^-$ depth and density. However, at high ion
fluence, this method is limited by low NV$^-$ creation yields and sample
amorphization. Additionally, shallow NV$^-$ spin properties deteriorate due to
surface proximity. In this paper, we study N$_2^+$ ion implantation at energies
between 10 and 15 keV with fluences as high as 1e15 ions/cm2 at temperatures of
20, 400 and 800{\deg}C to investigate the influence of implantation temperature
on lattice damage, NV$^-$ creation yield and NV$^-$ spin properties. Our
results show that diamond maintains structural integrity at 800{\deg}C with
fluences up to 1e15 ions/cm2 without amorphization. Furthermore,
high-temperature implantation improves NV$^-$ creation yields up to five times
without compromising T2$^*$, T2 and T1, making it a promising approach to
enhance the magnetic field sensitivity of NV$^-$ ensembles.

</details>


### [301] [Hanbury Brown-Twiss interference with massively parallel spectral multiplexing for broadband light](https://arxiv.org/abs/2509.05649)
*Sergei Kulkov,Ondrej Matousek,Lou-Ann Pestana De Sousa,Lada Radmacherova,Dmitrij Sevaev,Yuri Kurochkin,Stephen Vintskevich,Ermanno Bernasconi,Claudio Bruschini,Tommaso Milanese,Edoardo Charbon,Peter Svihra,Andrei Nomerotski*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Two-photon interference in the spectral domain is a powerful resource for
quantum technologies, enabling both precision measurements and scalable
entanglement distribution. Here, we report the first demonstration of massively
parallel, wavelength-resolved photon bunching, revealing Hanbury Brown-Twiss
correlations across 100 independent spectral channels. These observations are
enabled by a fast, data-driven single-photon spectrometer that achieves 40 pm
spectral and 40 ps temporal resolution over a 10 nm bandwidth, allowing
simultaneous access to spectro-temporal photon correlations without the need
for narrowband filtering. This approach preserves photon flux while enabling
high-dimensional quantum interference measurements across a broad spectrum. Our
results establish frequency-multiplexed two-photon interference as a scalable
and throughput-efficient platform for quantum-enhanced photonic technologies,
with applications ranging from stellar intensity interferometry to broadband
entanglement swapping in quantum networks.

</details>


### [302] [Tunneling of bosonic qubits under local dephasing through microscopic Lindblad approach](https://arxiv.org/abs/2509.05704)
*Alberto Ferrara,Farzam Nosrati,Andrea Smirne,Jyrki Piilo,Rosario Lo Franco*

Main category: quant-ph

TL;DR: 该研究提出了一个包含两个空间区域、两种玻色子以及隧穿耦合的系统，并分析了局部退相干噪声对该系统的影响，重点关注了相干动力学和退相相之间的竞争。


<details>
  <summary>Details</summary>
Motivation: 研究退相干噪声对量子系统的影响，特别是其与相干动力学之间的竞争，以及其在粒子可分辨性相关场景下的表现。

Method: 通过对整个系统-环境演化进行微观推导，得到了相应的Lindblad主方程，并使用伪模式方法进行数值计算以验证其有效性，同时考察了短时极限下的常用现象学主方程。

Result: 分析了退相干噪声对宏观哈特曼-奥-曼德干涉和纠缠生成等场景的影响，并发现形变和退相干的结合可以产生丰富的、非平凡的动力学，包括长时稳态下的持久量子关联。

Conclusion: 退相干噪声在量子系统中扮演着重要角色，并且其影响是复杂且多样的，尤其是在结合了形变等因素时，可以产生意想不到的量子关联。

Abstract: We consider a system composed of two distinct spatial regions, populated by
two-component bosons coupled through a tunneling process. Local dephasing noise
acts independently on each region, enabling competition between coherent
dynamics and decoherence. We present an analytic microscopical derivation of
the corresponding Lindblad master equation, taking into account the full
system-environment evolution and verify its validity against the numerical
solution of the full system, computed through the pseudo-mode method. We
demonstrate how the commonly-used phenomenological master equation emerges as a
short-time limit of the full one. We finally explore how dephasing affects
known two-particle indistinguishability-based scenarios, namely Hong-Ou-Mandel
interference and entanglement generation. In particular, we show that
simultaneous deformation and dephasing can produce rich, nontrivial dynamics,
including persistent quantum correlations in long-time steady states.

</details>


### [303] [Quantum Purification for Amplitude Damping Noise](https://arxiv.org/abs/2509.05709)
*Kai Wang,Zhen-Yang Peng*

Main category: quant-ph

TL;DR: 提出了一种新的方法来减轻幅度阻尼噪声，该方法可用于状态和通道纯化，仅需少量资源即可提高保真度。


<details>
  <summary>Details</summary>
Motivation: 噪声，特别是幅度阻尼（AD）噪声，对量子信息处理构成了重大挑战。为了在量子计算机中实现可靠的计算，必须有效纠正或净化这些噪声。因此，开发能够保持高保真量子系统的新型错误纠正和净化方法至关重要。

Method: 该方法引入了一种新颖的噪声缓解技术，可应用于状态和信道纯化。该技术仅使用一到两个辅助量子比特和两个克利福德门来实现。

Result: 与现有技术相比，该方法在受影响状态或信道的保真度方面实现了显著增强，同时保持了较低的资源开销，并具有较高的成功概率。

Conclusion: 这项工作提出了一种实用且可扩展的框架，用于解决实际量子系统中的幅度阻尼噪声问题，该框架具有成本效益且易于实现。

Abstract: Noise poses a fundamental challenge to quantum information processing, with
amplitude-damping (AD) noise being particularly detrimental. Preserving
high-fidelity quantum systems therefore relies critically on effective error
correction and purification methods. In this work, we introduce a novel
approach for mitigating AD noise that can be applied to both state and channel
purification. Our method achieves a substantial enhancement in the fidelity of
affected states or channels while maintaining a low resource overhead,
requiring only one or two ancilla qubits in combination with two Clifford
gates, and exhibits a relatively high success probability. This approach
provides a practical and scalable framework for addressing AD noise in
realistic quantum systems.

</details>


### [304] [Another generalization of Hadamard test: Optimal sample complexities for learning functions on the unitary group](https://arxiv.org/abs/2509.05710)
*Daiki Suruga*

Main category: quant-ph

TL;DR: 本研究提出了一个统一的框架，用于通过受控-酉操作高效地估计任意平方可积函数，并为这种估计提供了样本复杂度的上下界。


<details>
  <summary>Details</summary>
Motivation: 量子信息科学中的一个基本任务是估计未知酉算子的性质。虽然完全的酉层析成像需要与维度成比例的样本数量（意味着与量子比特数量成指数级增长），但估计酉算子的特定函数可以更有效。

Method: 本研究提出了一个统一的框架，利用受控-酉操作来高效地估计任意平方可积函数 $f: 	extbf{U}(d) 	o 	extbf{C}$。该方法首先对平均偏差进行最优样本复杂度表征，然后构建了一个满足PAC学习标准的样本高效估计算法。该技术推广了Hadamard测试，并利用了表示论的工具。

Result: 研究结果包括：1. 对平均偏差度量的最优样本复杂度进行了精确表征。2. 构建了一个样本高效的估计算法，在PAC学习标准下，对于各种函数类是最优的。3. 提供了样本复杂度的下界和上界。

Conclusion: 本研究提出的框架能够高效地估计未知酉算子的特定函数，为实际应用提供了理论基础。

Abstract: Estimating properties of unknown unitary operations is a fundamental task in
quantum information science. While full unitary tomography requires a number of
samples to the unknown unitary scaling linearly with the dimension (implying
exponentially with the number of qubits), estimating specific functions of a
unitary can be significantly more efficient. In this paper, we present a
unified framework for the sample-efficient estimation of arbitrary square
integrable functions $f: \mathbf{U}(d) \to \mathbb{C}$, using only access to
the controlled-unitary operation. We first provide a tight characterization of
the optimal sample complexity when the accuracy is measured by the averaged
bias over the unitary $\mathbf{U}(d)$. We then construct a sample-efficient
estimation algorithm that becomes optimal under the Probably Approximately
Correct (PAC) learning criterion for various classes of functions.
  Applications include optimal estimation of matrix elements of irreducible
representations, the trace, determinant, and general polynomial functions on
$\mathbf{U}(d)$. Our technique generalize the Hadamard test and leverage tools
from representation theory, yielding both lower and upper bound on sample
complexity.

</details>


### [305] [Deterministic nuclear spin squeezing and squeezing by continuous measurement using vector and tensor light shifts](https://arxiv.org/abs/2509.05717)
*Ali Moshiri,Alice Sinatra*

Main category: quant-ph

TL;DR: 该研究探讨了具有矢量和张量光移位的自旋原子在光照下的量子特性，并识别了两种量子非破坏性测量压缩（量子压缩）的机制，分别适用于短时间和长时间尺度。研究结果已应用于锶、镱和氦的费米同位素，并预估在镱173原子和特定腔体条件下，可在约50毫秒内实现原子自旋方差降低0.03。


<details>
  <summary>Details</summary>
Motivation: 研究原子在光照下的量子特性，特别是矢量和张量光移位联合作用的效果，以期实现量子压缩。

Method: 研究在极化状态下，大自旋原子与光相互作用时，矢量和张量光移位的联合作用，并分析了两种不同时间尺度的量子压缩机制。

Result: 识别出两种量子压缩机制：一种是短于(sqrt(epsilon)Gamma)^-1时间的量子非破坏性测量压缩，另一种是长于(epsilon Gamma)^-1时间的确定性压缩。对于镱173原子，在特定腔体条件下，原子自旋方差可减少0.03。

Conclusion: 研究提出的模型在锶、镱和氦的费米同位素上具有应用潜力，特别是在镱173原子上，有望实现显著的原子自旋方差降低。

Abstract: We study the joint effects of vector and tensor light shifts in a set of
large spin atoms, prepared in a polarized state and interacting with light.
Depending on the ratio $\epsilon$ between tensor and vector coupling and a
measurement rate $\Gamma$, we identify a regime of quantum non-demolition
measurement squeezing for times shorter than $(\sqrt{\epsilon}\Gamma)^{-1}$,
and a deterministic squeezing regime for times longer than $(\epsilon
\Gamma)^{-1}$. We apply our results to fermionic isotopes of strontium,
ytterbium, and helium, which are atoms with purely nuclear spin in their ground
state, benefiting from very low decoherence. For ytterbium 173, with a cavity
such as that of \cite{Thompson2021}, it would be possible to achieve an atomic
spin variance reduction of $0.03$ in $\simeq 50 \rm ms$.

</details>


### [306] [Improving the runtime of quantum phase estimation for chemistry through basis set optimization](https://arxiv.org/abs/2509.05733)
*Pauline J. Ollitrault,Jerome F. Gonthier,Dario Rocca,Gian-Luca Anselmetti,Matthias Degroote,Nikolaj Moll,Raffaele Santagati,Michael Streif*

Main category: quant-ph

TL;DR: 通过优化基组来降低量子相位估计算法的成本，特别是通过使用冻结自然轨道（FNO）策略，可以显著减少计算资源，同时保持化学精度。


<details>
  <summary>Details</summary>
Motivation: 现有的量子相位估计算法（QPE）在计算分子基态能量方面成本高昂，并且随着分子轨道数量的增加，成本会呈二次方增长，这限制了其在包含动态相关性的场景中的应用。

Method: 研究了两种优化基组以降低QPE成本的策略：1. 调整高斯基函数系数以最小化哈密顿量1-范数。2. 采用大型基组冻结自然轨道（FNO）策略来构建活性空间。

Result: 调整高斯基函数系数的方法最多只能将1-范数降低10%，并且效果因系统而异。而FNO策略可以将1-范数降低高达80%，并将轨道数量减少55%，同时保持精度。

Conclusion: 通过提高轨道基组的质量（而非仅仅是数量），例如使用FNO策略，可以有效降低QPE的计算成本，使其能够包含动态相关性，为实现可扩展且资源可控的化学精确量子模拟提供了可行途径。

Abstract: Quantum phase estimation (QPE) is a promising quantum algorithm for obtaining
molecular ground-state energies with chemical accuracy. However, its
computational cost, dominated by the Hamiltonian 1-norm $\lambda$ and the cost
of the block encoding, scales at least quadratically with the number of
molecular orbitals, making it challenging to incorporate dynamic correlation by
enlarging the active space. In this work, we investigate two strategies to
mitigate this cost through the optimization of the basis set. First, we
investigate whether adjusting the coefficients of Gaussian basis functions can
minimize the 1-norm while preserving the accuracy of the ground state energy.
Although this method leads to a reduction in the 1-norm up to 10%, this
reduction is system-dependent and diminishes with increasing molecular size.
Second, we demonstrate that employing a large-basis-set frozen natural orbital
(FNO) strategy results in a substantial reduction in QPE resources without
compromising accuracy. We study a dataset of 58 small organic molecules and the
dissociation curve of N2, and demonstrate that an active space constructed from
orbitals derived from larger basis sets captures correlation effects more
effectively. This approach yields up to an 80% reduction in the 1-norm
$\lambda$ and also leads to a 55% reduction in the number of orbitals. Our
results highlight that improving the quality, not just the size, of the orbital
basis is a viable strategy for extending QPE to include dynamical correlation,
making progress toward scalable and chemically accurate quantum simulations
with tractable resource requirements.

</details>


### [307] [Non-linear cooling and control of a mechanical quantum harmonic oscillator](https://arxiv.org/abs/2509.05734)
*Matteo Simoni,Ivan Rojkov,Matteo Mazzanti,Wojciech Adamczyk,Alexander Ferk,Pavel Hrmo,Shreyans Jain,Tobias Sägesser,Daniel Kienzler,Jonathan Home*

Main category: quant-ph

TL;DR: 本研究利用新颖的非线性腔工程技术，在强非线性区单离子振荡器中成功制备了多组分（2, 3, 4, 5）薛定谔猫态流形，并实现了对此类量子态流形的可控测量。


<details>
  <summary>Details</summary>
Motivation: 在强非线性区设计量子谐振子控制协议存在困难，限制了对其特性的充分利用。

Method: 利用新颖的非线性腔工程技术，在强非线性区单离子振荡器中制备了多组分（2, 3, 4, 5）薛定谔猫态流形，并选择特定的哈密顿量来实现对此类量子态流形的可控测量。

Result: 成功制备了多组分（2, 3, 4, 5）薛定谔猫态流形，并实现了对其的可控测量。

Conclusion: 本研究首次实验性地利用高阶非线性过程控制非经典量子谐振子态，为实现玻色子量子纠错、计算和传感开辟了新的技术途径。

Abstract: Non-linearities are a key feature allowing non-classical control of quantum
harmonic oscillators. However, when non-linearities are strong, designing
protocols for control is often difficult, placing a barrier to exploiting these
properties fully. Here, using a single trapped-ion oscillator operated in the
strongly non-linear regime of the atom-light interaction, we show how to
generate localized multi (2, 3, 4, and 5)-component Schr\"odinger's cat
manifolds using a novel form of non-linear reservoir engineering. We then
specifically select Hamiltonians which allow us to perform measurements on
these state manifolds. To our knowledge, our work is the first experimental use
of such high order non-linear processes for control of non-classical states of
a quantum harmonic oscillator, opening up a new toolbox which can be applied to
bosonic quantum error correction, computation, and sensing.

</details>


### [308] [Cavity-Mediated Coupling between Local and Nonlocal Modes in Landau Polaritons](https://arxiv.org/abs/2509.05738)
*Sae R. Endo,Dasom Kim,Shuang Liang,Geon Lee,Sunghwan Kim,Alan Covarrubias-Morales,Minah Seo,Michael J. Manfra,Dukhyung Lee,Motoaki Bamba,Junichiro Kono*

Main category: quant-ph

TL;DR: 文章展示了在 Landau 极化激子系统中，通过腔光子与零动量回旋共振和有限动量磁等离激元同时相互作用，实现了非局域多模耦合，并证实了超强耦合（USC）和强耦合。


<details>
  <summary>Details</summary>
Motivation: 腔介导的局域和非局域激发之间的关联，或等同于零动量和有限 in-plane 动量模式之间的关联，为控制光-物质相互作用提供了新的机会，但缺乏直接的实验证据。

Method: 利用具有亚波长模式体积的微腔，通过太赫兹时域磁光谱法，实现了腔光子与二维电子气的零动量回旋共振和有限动量磁等离激元的耦合，并测量了光谱分裂。

Result: 观察到上极化支的清晰分裂，证明了磁等离激元模式与腔-回旋共振混合之间的杂化。耦合强度测量证实了回旋共振的 USC 和磁等离激元模式与腔场的强耦合。

Conclusion: 该研究在 USC 机制下，通过涉及零动量和有限动量物质模式的多模光-物质相互作用，建立了一条工程化通路。

Abstract: The multimode ultrastrong coupling (USC) regime has emerged as a novel
platform for accessing previously inaccessible phenomena in cavity quantum
electrodynamics. Of particular interest are cavity-mediated correlations
between local and nonlocal excitations, or equivalently, between modes at zero
and finite in-plane momentum modes, which offer new opportunities for
controlling light-matter interactions across space. However, direct
experimental evidence of such interactions has remained elusive. Here, we
demonstrate nonlocal multimode coupling in a Landau polariton system, where
cavity photons simultaneously interact with the zero-momentum cyclotron
resonance and finite-momentum magnetoplasmons of a two-dimensional electron gas
in a GaAs quantum well. Our slot cavities, with their subwavelength mode
volumes, supply in-plane momentum components that enable the excitation of
finite-momentum matter modes. Terahertz time-domain magnetospectroscopy
measurements reveal a clear splitting of the upper-polariton branch, arising
from hybridization between magnetoplasmon modes and the
cavity--cyclotron-resonance hybrids. Extracted coupling strengths confirm USC
of the cyclotron resonance and strong coupling of the magnetoplasmon modes to
the cavity field, respectively. The experimental results are well captured by
the multimode Hopfield model and finite-element simulations. These findings
establish a pathway for engineering multimode light-matter interactions
involving zero- and finite-momentum matter modes in the USC regime.

</details>


### [309] [Quantum Theory of Distributed-Feedback Parametric Amplifiers and Oscillators](https://arxiv.org/abs/2509.05752)
*Alex O. C. Davis,Alex I. Flint*

Main category: quant-ph

TL;DR: 分布式反馈参量振荡器有潜力成为下一代量子光源，特别是在产生压缩真空方面。


<details>
  <summary>Details</summary>
Motivation: 结合光学参量放大/振荡器和分布式反馈振荡器的优点，实现分布式反馈参量振荡器，以期获得更优越的量子光源。

Method: 提出一个解析的和全量子力学的模型来描述分布式反馈参量振荡器的动力学，并推导出其关键参数的显式结果。

Result: 文章得到了分布式反馈参量振荡器的泵浦阈值、腔内模式、可调谐性以及输出模式量子统计的明确结果。

Conclusion: 该模型为开发下一代多功能量子光源奠定了理论基础。

Abstract: Optical parametric amplifiers and oscillators are among the best-developed
quantum light sources, having already been adopted in precision measurement and
underpinning various quantum computing and communication paradigms. Meanwhile,
progress in photonic structures such as Bragg gratings has enabled distributed
feedback oscillators to become widely established as classical laser sources
with desirable properties. Recent work in fabricating and processing photonic
structures in nonlinear media opens the path to combining these two programs to
realize distributed feedback parametric oscillators. Such devices have great
potential as sources of quantum light, especially for squeezed vacuum, a
crucial resource state in emerging quantum technologies. In this study, an
analytic and fully quantum-mechanical model of the dynamics of such devices is
presented. This approach gives explicit results for the key properties of these
sources, including the parametric oscillation pump threshold, intracavity mode,
tunability, and quantum statistics of the output modes. These results underpin
future work on a versatile class of next-generation quantum light source.

</details>


### [310] [Discrete-Time Quantum Random Walk for Epidemiological Modeling](https://arxiv.org/abs/2509.05795)
*Sayan Manna,Nikhil Kowshik,Sudebkumar Prasant Pal*

Main category: quant-ph

TL;DR: 本研究提出了一个在二维格点上进行空间流行病学的离散时间量子随机游走（QRW）框架，并将其动力学与经典随机游走SIR模型进行比较。


<details>
  <summary>Details</summary>
Motivation: 在二维格点上建立一个量子随机游走（QRW）框架，用于空间流行病学建模，并将其与经典随机游走SIR模型进行比较。

Method: 在二维格点上，每个感染位点产生一个量子行走者，其演化过程（由幅度分裂硬币和条件位移控制）可以以概率p感染被访问的易感位点，并持续一个生命周期τ步。通过对有限格点进行广泛的数值模拟，测量聚类可观测量（单次运行聚类大小M和其系综平均值<M>），并计算(p,τ)网格上的基本再生数R0。

Result: 结果表明，QRW动力学在扩散和超扩散状态之间进行插值：在低p下，QRW重现了类似经典的R0和聚类统计；而在较高的p和τ下，弹道传播和干涉产生了明显更大的R0和非高斯空间分布。QRW的R0范围与历史疫情的经验估计值进行了比较。

Conclusion: QRW提供了一个灵活、概念新颖的玩具模型，用于探索快速或重尾的疫情传播，同时强调在将量子相干机制映射到生物传播时需要谨慎。

Abstract: We introduce a discrete-time quantum random walk (QRW) framework for spatial
epidemic modelling on a two-dimensional square lattice and compare its dynamics
to classical random-walk SIR models. In our model, each infected site spawns a
quantum walker whose coherent evolution (controlled by an amplitude-splitting
coin and conditional shifts) can infect visited susceptible sites with
probability $p$ and persists for a lifetime of $\tau$ steps. We perform
extensive numerical simulations on finite lattices, measure cluster observables
(single-run cluster size $M$ and its ensemble average $\langle M\rangle$), and
compute the basic reproduction number $R_0$ across a broad grid of $(p,\tau)$
values. Results show that QRW dynamics interpolate between diffusive and
super-diffusive regimes: at low $p$ the QRW reproduces classical-like $R_0$ and
cluster statistics, while at higher $p$ and $\tau$ ballistic propagation and
interference produce markedly larger $R_0$ and non-Gaussian spatial profiles.
We compare the QRW $R_0$ range to empirical estimates from historical outbreaks
and discuss parameter regimes where QRW offers a closer qualitative match than
classical diffusion. We conclude that QRWs provide a flexible, conceptually
novel toy model for exploring rapid or heavy-tailed epidemic spread, while
emphasizing the need for caution when mapping quantum-coherent mechanisms to
biological transmission.

</details>


### [311] [Genetic optimization of ansatz expressibility for enhanced variational quantum algorithm performance](https://arxiv.org/abs/2509.05804)
*Manish Mallapur,Ronit Raj,Ankur Raina*

Main category: quant-ph

TL;DR: 提出一种受遗传算法启发的框架，用于设计具有高表达力、浅深度和低参数数量的可变量子算法（VQA）ansatz。


<details>
  <summary>Details</summary>
Motivation: VQA 的性能高度依赖于 ansatz 的设计，需要兼顾表达能力和可训练性。

Method: 使用受遗传算法启发的框架，通过基于表达力指标的变异和选择来演化 ansatz。

Result: 生成的电路在任何目标深度下都具有高表达力，性能可与传统方法媲美，且几乎没有 barren plateau 问题。

Conclusion: 提出一种通用、可扩展的 ansatz 设计解决方案，可用于多种应用。

Abstract: Variational quantum algorithms have emerged as a leading paradigm that
extracts practical computation from near-term intermediate-scale quantum
devices, enabling advances in quantum chemistry simulations, combinatorial
optimization, and quantum machine learning. However, the performance of
Variational Quantum Algorithms is highly sensitive to the design of the
ansatze. To be effective, ansatze must be expressive enough to capture target
states but shallow enough to be trainable. We propose a genetic
algorithm-inspired framework for designing ansatze that achieve high
expressibility while maintaining shallow depth and low parameter count. Our
approach evolves ansatze through mutation and selection based on an
expressibility metric. The circuit generated by our framework consistently
demonstrates high expressibility at any target depth and performs comparably to
traditional ansatz design approaches while showing minimal to no signs of
barren plateau issues. This work presents a general, scalable solution for
ansatz design, producing expressive, low-depth circuits that need to be
designed only once and can serve a wide range of applications.

</details>


### [312] [Emergence of Unruh prethermalization for uniformly accelerating many-atom system](https://arxiv.org/abs/2509.05816)
*Saptarshi Saha,Chiranjeeb Singha,Pragna Das,Arpan Chatterjee*

Main category: quant-ph

TL;DR: 加速多原子系统在完全热化前会达到一个受涌现守恒量保护的预热广义Gibbs态，称为“Unruh预热化”。该态的寿命可通过纠缠度量进行估计。在达到预热态前，系统会表现出类Dicke超辐射的辐射爆发，与Unruh效应的单指数衰减形成对比。


<details>
  <summary>Details</summary>
Motivation: 研究非相互作用的多加速原子系统与单加速原子的Unruh效应有何不同，特别关注其热化前可能出现的预热现象。

Method: 分析了非相互作用的多加速原子系统，推导出其在热化前会达到一个广义Gibbs状态，并提出了“Unruh预热化”的概念。通过计算纠缠度来估计预热态的寿命，并研究了系统在达到预热态前的辐射动力学行为，将其与Unruh效应的单指数衰减进行了对比。

Result: 发现非相互作用的多加速原子系统在完全热化前会进入一个预热的广义Gibbs状态，该状态受涌现守恒量保护。预热态的寿命可以通过纠缠度来估计。系统在达到预热态前会表现出类似Dicke超辐射的辐射爆发，而Unruh效应只表现为单指数衰减。

Conclusion: “Unruh预热化”是多加速原子系统的一个重要现象，与单加速原子的Unruh效应显著不同。该现象受涌现守恒量保护，并且可以通过纠缠度来量化其寿命。系统在预热前的辐射行为也与Unruh效应存在明显差异。

Abstract: A uniformly accelerated atom in an inertial vacuum generally thermalizes and
reaches a Gibbs state. This phenomenon is commonly known as the Unruh effect.
Here, we show that the situation is entirely different for the many-atoms
problem. In the case of non-interacting accelerating atoms, we show that a
regime exists where the entire system reaches a prethermal generalized Gibbs
state before it thermalizes. The prethermal state is protected by emergent
conserved quantities; hence, the system behaves like a nearly-integrable one,
which shows a sharp distinction from the Unruh effect. We coin the term ``Unruh
prethermalization" to characterize this phenomenon. The measure of entanglement
is a good estimation of the lifetime of the prethermal state and is consistent
with previous studies. Finally, we show that in such a regime, the dynamics
show a Dicke superradiance-type radiation burst before reaching the prethermal
state. In contrast, only a mono-exponential decay is observed for Unruh
thermalization. In addition, to highlight the significance of our results, we
compare them with existing experimental observations.

</details>


### [313] [Simultaneous generation and transfer of mechanical noise squeezing](https://arxiv.org/abs/2509.06102)
*Mungyeong Jeong,Hyojun Seok,Young-Sik Ra,Junho Suh*

Main category: quant-ph

TL;DR: 利用微波腔模式作为媒介，将一个谐振腔中的噪声压缩转移到另一个谐振腔中，实现了跨谐振腔的噪声压缩转移。


<details>
  <summary>Details</summary>
Motivation: 研究多机械振荡器与单一电磁模式的耦合，利用电磁模式作为媒介，在不同机械振荡器之间分配噪声压缩。

Method: 通过光力学相互作用，利用光学弹簧效应调节控制模式的共振频率，实现其噪声压缩。然后，利用机械模式之间的光力学分束器相互作用，将控制模式的噪声压缩转移到目标模式。

Result: 实现了跨谐振腔的噪声压缩转移，目标模式的压缩来源于控制模式。观察到的压缩转移表现出单模和双模压缩的噪声特性。

Conclusion: 跨谐振腔的噪声压缩转移具有显著的潜力，可以增强精密测量。

Abstract: Optomechanical interactions between mechanical oscillators and an
electromagnetic field induce controllable modifications in mechanical
fluctuation. When multiple mechanical oscillators are coupled to a single
electromagnetic mode, these interactions can be extended to utilize the
electromagnetic mode as a mediator for distributing noise squeezing among
different mechanical oscillators. We investigate the transfer of mechanical
noise squeezing between two mechanical modes, enabled by a single microwave
cavity mode which is strongly coupled to both mechanical modes. Noise squeezing
in one mechanical mode (control) is achieved through parametric modulation of
its resonance frequency via the optical spring effect. Simultaneously,
optomechanical beam-splitter interaction is applied between the mechanical
modes to transfer noise squeezing from the control mode to the other mode
(target). Strong correlations between the quadratures of the two mechanical
modes confirm that the observed squeezing in the target mode originates from
the squeezing in the control mode. Remarkably, the observed squeezing transfer
manifests noise characteristics of both single-mode and two-mode squeezing.
This unique feature suggests that the squeezing transfer holds significant
potential for enhancing precision measurements.

</details>


### [314] [Quantum spatial best-arm identification via quantum walks](https://arxiv.org/abs/2509.05890)
*Tomoki Yamagami,Etsuo Segawa,Takatomo Mihana,André Röhm,Atsushi Uchida,Ryoichi Horisaki*

Main category: quant-ph

TL;DR: 本文提出了一种名为QSBAI的量子算法，用于解决图相关多臂老虎机问题中的最优臂识别问题，利用量子行走实现比传统方法更快的探索。P.S.图相关多臂老虎机问题是在经典多臂老虎机问题中加入了空间约束。


<details>
  <summary>Details</summary>
Motivation: 现有的量子机器学习方法在处理具有空间约束的图相关多臂老虎机问题时能力有限，需要新的量子算法来解决此类问题。

Method: 提出了一种名为QSBAI的量子算法，该算法利用量子行走来编码在图约束下的行动叠加态，并结合了幅度放大和Szegedy的量子行走框架，以识别图相关多臂老虎机问题中的最优臂。

Result: 对完全图和二分图进行了分析，推导出了识别最优臂的最大成功概率及其达到的时间步长。

Conclusion: 量子行走在受限环境中可以加速探索过程，并扩展了量子算法在决策制定中的应用范围。

Abstract: Quantum reinforcement learning has emerged as a framework combining quantum
computation with sequential decision-making, and applications to the
multi-armed bandit (MAB) problem have been reported. The graph bandit problem
extends the MAB setting by introducing spatial constraints, yet quantum
approaches remain limited. We propose a quantum algorithm for best-arm
identification in graph bandits, termed Quantum Spatial Best-Arm Identification
(QSBAI). The method employs quantum walks to encode superpositions over
graph-constrained actions, extending amplitude amplification and generalizing
the Quantum BAI algorithm via Szegedy's walk framework. This establishes a link
between Grover-type search and reinforcement learning tasks with structural
restrictions. We analyze complete and bipartite graphs, deriving the maximal
success probability of identifying the best arm and the time step at which it
is achieved. Our results highlight the potential of quantum walks to accelerate
exploration in constrained environments and extend the applicability of quantum
algorithms for decision-making.

</details>


### [315] [A brain-inspired paradigm for scalable quantum vision](https://arxiv.org/abs/2509.05919)
*Chenghua Duan,Xiuxing Li,Wending Zhao,Lin Yao,Qing Li,Ziyu Li,Fukang Li,Junhao Ma,Xia Wu*

Main category: quant-ph

TL;DR: BIQC是一种结合了经典神经网络和量子电路的混合方法，在图像识别任务中表现出优越的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 图像识别中的高维、细节丰富的图像处理是一个持续的挑战，而生物视觉则能有效处理这类信息。受到人类大脑“先森林后树木”的认知方式的启发，提出了一种新的图像识别范式。

Method: 提出了一种新的“引导范式”，利用经典神经网络分析全局低频信息，并引导量子电路聚焦于关键的高频图像区域。具体实现为“脑启发量子分类器”（BIQC），它采用互补架构，其中量子通路分析由经典通路识别出的局部细节。

Result: 在包括高分辨率图像在内的多样化数据集上的数值模拟显示，BIQC 相比现有方法具有更高的准确性和可扩展性。

Conclusion: 脑启发、量子-经典混合方法有望用于开发下一代视觉系统。

Abstract: One of the fundamental tasks in machine learning is image classification,
which serves as a key benchmark for validating algorithm performance and
practical potential. However, effectively processing high-dimensional,
detail-rich images, a capability that is inherent in biological vision, remains
a persistent challenge. Inspired by the human brain's efficient ``Forest Before
Trees'' cognition, we propose a novel Guiding Paradigm for image recognition,
leveraging classical neural networks to analyze global low-frequency
information and guide targeted quantum circuit towards critical high-frequency
image regions. We present the Brain-Inspired Quantum Classifier (BIQC),
implementing this paradigm via a complementarity architecture where a quantum
pathway analyzes the localized intricate details identified by the classical
pathway. Numerical simulations on diverse datasets, including high-resolution
images, show the BIQC's superior accuracy and scalability compared to existing
methods. This highlights the promise of brain-inspired, hybrid
quantum-classical approach for developing next-generation visual systems.

</details>


### [316] [Hybrid Quantum-Classical Learning of Nonlinear Entanglement Witnesses via Continuous-Variable Quantum Neural Networks](https://arxiv.org/abs/2509.05924)
*Mohammad Rezaei Shokou,Hossein Davoodi Yeganeh*

Main category: quant-ph

TL;DR: 该研究提出了一种利用连续变量量子神经网络（CV-QNN）从量子数据中学习非线性量子纠缠对对的判据，以有效检测量子关联。实验证明该方法在区分高斯和非高斯态方面具有超过99%的分类准确率，并且在扩展到三模式系统时表现出优于经典基线的鲁棒性，同时对光子损耗和有限测量次数具有良好的抵抗力。理论上，研究表明当测量阶段信息完备时，该混合模型可以逼近紧集状态上的任意连续判据函数。


<details>
  <summary>Details</summary>
Motivation: 量子信息领域的一个主要挑战是表征量子纠缠，而量子纠缠判据为检测量子关联提供了有效手段。本研究旨在开发一种新的方法来学习量子纠缠判据。

Method: 提出了一种混合量子-经典框架，利用连续变量量子神经网络（CV-QNN）直接从量子数据中学习非线性量子纠缠判据。该框架结合了变分干涉仪、压缩器、非高斯Kerr门和一个小的经典神经网络头，以输出一个标量判据值。并在包含纯态和混合态的高斯和非高斯态的两模和三模体系上进行了数值模拟。

Result: 在两模和三模高斯及非高斯态（纯态和混合态）的数值模拟中，观察到超过99%的分类准确率。与强大的经典基线相比，该方法表现出鲁棒的性能优势，尤其在从两模扩展到三模时。此外，还量化了该方法在有限测量次数下的抗光子损耗能力。

Conclusion: 研究结果表明，CV-QNNs为数据驱动的量子态表征提供了一个有前途的框架。该方法在区分量子纠缠方面表现出色，并且在近期的光子平台上具有实际优势。理论分析支持该混合模型在特定条件下逼近任意连续判据函数的能力。

Abstract: A major challenge in quantum information is characterizing entanglement, for
which entanglement witnesses offer effective means of detecting quantum
correlations. We introduce a hybrid quantum-classical framework that learns a
nonlinear entanglement witness directly from quantum data using
continuous-variable quantum neural networks (CV-QNNs). Our architecture
combines variational interferometers, squeezers and non-Gaussian Kerr gates
with a small classical neural head to output a scalar witness value. Numerical
simulations were conducted on two- and three-mode families, including Gaussian
and non-Gaussian states in both pure and mixed forms. We observed over 99%
classification accuracy and a robust performance gap compared to strong
classical baselines, especially when scaling from two to three modes.
Robustness to photon loss is further quantified under a finite number of
measurement shots. On the theory side, we show that when the quantum
measurement stage is informationally complete, the hybrid model can approximate
any continuous witness-like functional on compact sets of states.Our findings
highlight CV-QNNs as a promising framework for data-driven quantum state
characterization and propose specific benchmarks where near-term photonic
platforms offer tangible advantages.

</details>


### [317] [Symmetric and asymmetric tripartite states under the lens of entanglement splitting and topological linking](https://arxiv.org/abs/2509.05972)
*Sougata Bhattacharyya,Sovik Roy*

Main category: quant-ph

TL;DR: 通过对三比特状态进行局部测量，研究其纠缠结构与拓扑链之间的关系，发现不同状态（如对称$\wwbar$态和不对称$\starstate$态）在测量后会展现出类似3-Hopf链、3-链或Borromean链的拓扑特性，证明拓扑结构可用于表征量子态的纠缠特性及其对局部测量的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 建立三比特纠缠态结构与其拓扑链之间的直接联系，并研究局部测量对纠缠的影响。

Method: 对对称$\\wwbar$态和不对称$\\starstate$态进行局部投影测量，并通过分析测量后态的Schmidt秩来表征剩余的二比特纠缠。

Result: 对称$\\wwbar$态的测量结果类似3-Hopf链；$\starstate$态的行为则依赖于测量选择，可能类似3-链或Borromean链。

Conclusion: 拓扑链结构可作为表征分布式纠缠及其对局部测量鲁棒性的资源，且单一量子态可根据测量结果呈现多种拓扑结构。

Abstract: This work establishes a direct operational connection between the
entanglement structures of specific three-qubit states (i.e. multipartite
entanglement) and their corresponding topological links. We investigate the
symmetric $\wwbar$ state and the asymmetric $\starstate$ state through local
projective measurements on individual qubits. The post measurement states are
analyzed via their Schmidt rank to characterize residual bipartite
entanglement. For the symmetric $\wwbar$ state, measurement of any qubit
consistently results in a non-maximally entangled post-measurement state
(Schmidt rank 2), analogous to the behavior of a \textit{3-Hopf link}
structure, where cutting any ring leaves the remaining two nontrivially linked.
On the other hand, the $\starstate$ state exhibits a context-dependent
fragility. Its behavior predominantly mirrors that of a \textit{3-link chain},
where severing the central qubit decouples the system, while cutting an outer
qubit often preserves a residual link. Crucially, for specific measurement
outcomes, the $\starstate$ state also exhibits the defining property of the
\textit{Borromean rings}, where the loss of one qubit completely disentangles
the remaining two. This analysis provides a concrete interpretation of
topological linking structures as a resource for characterizing distributed
entanglement and its resilience under local measurement operations, revealing
that a single quantum state can contextually embody multiple distinct
topological analogues.

</details>


### [318] [Unified formalism and adaptive algorithms for optimal quantum state, detector and process tomography](https://arxiv.org/abs/2509.05988)
*Shuixin Xiao,Xiangyu Wang,Yuanlong Wang,Zhibo Hou,Jun Zhang,Ian R. Petersen,Wen-Zhe Yan,Hidehiro Yonezawa,Franco Nori,Guo-Yong Xiang,Daoyi Dong*

Main category: quant-ph

TL;DR: 本文提出了一种统一的量子态、探测器和过程层析成像的保真度指标 $1-F(\\, S)$，并给出了一类能够达到最优收敛速度 $O(1/N)$ 的自适应层析成像算法。实验结果表明，所提方法在光学实验中达到了最优保真度收敛速度。


<details>
  <summary>Details</summary>
Motivation: 量子层析成像在推进量子技术和理解量子力学基础方面起着至关重要的作用，但实现最高的层析成像精度仍然是一个核心挑战。

Method: 提出了一种统一的保真度指标 $1-F(\\, S)$，并推导了实现最优收敛速度 $O(1/N)$ 的充要条件。在此基础上，设计了针对量子态、探测器和过程层析成像的自适应算法。

Result: 所提出的自适应算法在数值模拟和量子光学实验中得到了验证，其中实验首次在辅助量子过程层析成像中达到了最优保真度收敛速度。

Conclusion: 本文提出的统一保真度指标和自适应算法为实现高精度量子层析成像提供了理论指导和实验验证。

Abstract: Quantum tomography is a standard technique for characterizing, benchmarking
and verifying quantum systems/devices and plays a vital role in advancing
quantum technology and understanding the foundations of quantum mechanics.
Achieving the highest possible tomography accuracy remains a central challenge.
Here we unify the infidelity metrics for quantum state, detector and process
tomography in a single index $1-F(\hat S,S)$, where $S$ represents the true
density matrix, POVM element, or process matrix, and $\hat S$ is its estimator.
We establish a sufficient and necessary condition for any tomography protocol
to attain the optimal scaling $1-F= O(1/N) $ where $N$ is the number of state
copies consumed, in contrast to the $O(1/\sqrt{N})$ worst-case scaling of
static methods. Guided by this result, we propose adaptive algorithms with
provably optimal infidelity scalings for state, detector, and process
tomography. Numerical simulations and quantum optical experiments validate the
proposed methods, with our experiments reaching, for the first time, the
optimal infidelity scaling in ancilla-assisted process tomography.

</details>


### [319] [Intrinsic non-Hermitian topological phases](https://arxiv.org/abs/2509.06879)
*Ken Shiozaki*

Main category: quant-ph

TL;DR: 研究非厄米拓扑相在点隙和线隙条件下的相互作用，区分了可归约的外在相和真正非厄米（无厄米对应物）的内在相，并为所有内部对称性提供了统一的表述和显式计算。


<details>
  <summary>Details</summary>
Motivation: 区分非厄米拓扑相中的外在相（可归约到厄米或反厄米线隙相）和内在相（真正非厄米且无厄米对应物）。

Method: 利用从线隙到点隙的自然同态，对所有内部对称性进行分类和显式计算。

Result: 区分了外在相和内在相，并为所有内部对称性提供了统一的表述和显式计算。

Conclusion: 提出了一个统一的框架来理解和分类非厄米拓扑相在点隙和线隙条件下的相互作用。

Abstract: We study the interplay of non-Hermitian topological phases under point- and
line-gap conditions. Using natural homomorphisms from line-gap to point-gap
phases, we distinguish extrinsic phases, reducible to Hermitian or
anti-Hermitian line-gapped phases, from intrinsic phases, which are genuinely
non-Hermitian without Hermitian counterparts. Although classification tables
for all symmetry classes were already presented in earlier work, the present
paper develops a unified formulation and provides explicit computations for all
internal symmetries.

</details>


### [320] [Quantum optics in the turbulent atmosphere: Fundamental issues and applications](https://arxiv.org/abs/2509.06022)
*A. A. Semenov,M. Klen,I. Pechonkin*

Main category: quant-ph

TL;DR: 大气湍流对量子光传播的影响。


<details>
  <summary>Details</summary>
Motivation: 量子通信、量子传感和环境监测等应用，以及大气湍流对量子信息的基本影响。

Method: 检验各种解析模型，并通过数值模拟进行验证，同时考虑了时间平均而非标准的系综平均。

Result: 评估了不同大气湍流模型（PDT）的适用范围，并研究了时间平均对非经典特性的影响。

Conclusion: 对大气湍流中量子光传播的理论模型进行了详细分析，并考虑了实际实验中的时间平均效应。

Abstract: Quantum light propagation through turbulent atmosphere has become a subject
of intensive research, spanning both theoretical and experimental studies. This
interest is driven by its important applications in free-space quantum
communication, remote quantum sensing, and environmental monitoring. At the
same time, this phenomenon itself poses an intriguing fundamental problem. A
consistent theoretical description typically makes explicit assumptions about
the measurement scheme at the receiver station and/or the method of
quantum-information encoding. A common and straightforward approach encodes the
information in quantum states of a quasi-monochromatic mode, representing a
pulsed Gaussian beam. Atmospheric turbulence induces random distortions of the
pulse shape and, consequently, random fluctuations of the transmittance through
the receiver aperture. These fluctuations, characterized by the probability
distribution of transmittance (PDT), directly affect the quantum state of the
received light. In this paper we examine various analytical models of the PDT,
validate them through numerical simulations, and assess their range of
applicability. Furthermore, we extend the analysis beyond the standard
ensemble-averaging approach, recognizing that realistic experiments typically
involve time averaging. This requires a detailed examination of the underlying
random process, including the study of temporal correlations and their impact
on nonclassical properties of electromagnetic radiation.

</details>


### [321] [Quantum machine unlearning](https://arxiv.org/abs/2509.06086)
*Junjian Su,Runze He,Guanghui Li,Sujuan Qin,Zhimin He,Haozhen Situ,Fei Gao*

Main category: quant-ph

TL;DR: 本论文研究了量子机器学习（QML）中的模型“遗忘”问题，发现QML模型存在训练数据泄露隐私的风险，并提出并验证了量子遗忘（QMU）方法可以有效解决此问题。


<details>
  <summary>Details</summary>
Motivation: 由于现有量子机器学习（QML）模型在移除特定训练数据影响以满足监管要求和缓解隐私风险方面存在不足，本研究旨在探索QML模型是否需要模型遗忘（MU）以应对训练数据成员泄露的风险，以及是否能够高效地实现MU机制。

Method: 通过在MNIST分类任务上进行实验，采用类别遗忘范式，并在无噪声模拟和量子硬件上进行测试。首先，利用成员推断攻击（MIA）量化训练数据隐私泄露程度；然后，实现MU算法并评估其在减少MIA成功率和保持模型准确性方面的效果。

Result: 在无噪声模拟中，MIA的平均成功率为90.2%；在量子硬件上，MIA的平均成功率为75.3%。实施MU算法后，模拟中的MIA平均成功率降至0%，量子硬件上降至3.7%，同时保留了数据的准确性。

Conclusion: QML模型存在显著的训练数据成员泄露隐私风险，需要MU机制来应对。所提出的QMU方法能够有效降低MIA的成功率，并保持模型在未遗忘数据上的准确性，为构建隐私保护的QML系统提供了潜在途径。

Abstract: Quantum Machine Learning (QML) integrates quantum computation with classical
Machine Learning (ML) and holds the potential to achieve the quantum advantage
for specific tasks. In classical ML, Machine Unlearning (MU) is a crucial
strategy for removing the influence of specified training data from a model, to
meet regulatory requirements and mitigate privacy risks. However, both the risk
of training-data membership leakage remains underexplored in QML. This
motivates us to propose Quantum Machine Unlearning (QMU) to explore two core
questions: do QML models require MU due to training-data membership leakage,
and can MU mechanisms be efficiently implemented in the QML? To answer the two
questions, we conducted experiments on the MNIST classification task, utilizing
a class-wise unlearning paradigm in both noiseless simulations and quantum
hardware. First, we quantify training-data privacy leakage using a Membership
Inference Attack (MIA), observing average success rates of 90.2\% in noiseless
simulations and 75.3\% on quantum hardware. These results indicate that QML
models present training-data membership leakage with very high probability
under adversarial access, motivating the need for MU. Second, we implement MU
algorithms on the QML model, which reduces the average MIA success rate to 0\%
in simulations and 3.7\% on quantum hardware while preserving accuracy on
retained data. We conclude that implementing MU mechanisms in QML models
renders them resistant to MIA. Overall, this paper reveals significant privacy
vulnerabilities in QML models and provides effective corresponding defense
strategies, providing a potential path toward privacy-preserving QML systems.

</details>


### [322] [Interfacing Quantum Computing Systems with High-Performance Computing Systems: An Overview](https://arxiv.org/abs/2509.06205)
*Konstantinos Rallis,Ioannis Liliopoulos,Georgios D. Varsamis,Evangelos Tsipas,Ioannis G. Karafyllidis,Georgios Ch. Sirakoulis,Panagiotis Dimitrakis*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The connection and eventual integration of High-Performance Computing (HPC)
with Quantum Computing (QC) represents a transformative advancement in
computational technology, promising significant enhancements in solving
complex, previously intractable problems. This manuscript provides a
comprehensive overview of the current state of HPC-QC interfacing, detailing
architectural methodologies, software stack developments, middleware
functionalities, and hardware integration strategies. It critically assesses
existing hardware-level integration models, ranging from standalone and
loosely-coupled architectures to tightly-integrated and on-node systems. The
software ecosystem is analyzed, highlighting prominent frameworks such as
Qiskit, PennyLane, CUDA-Q, and middleware solutions like Pilot-Quantum,
essential for seamless hybrid computing environments. Furthermore, the
manuscript discusses practical applications in optimization, machine learning,
and many-body dynamics, where hybrid HPC-QC systems can offer substantial
advantages. It also describes existing challenges, including hardware
limitations (coherence, scalability, connectivity), software maturity,
communication overhead, resource management complexities, and cost factors.
Finally, future directions towards tighter hardware and software integration
are discussed, emphasizing ongoing research developments and emerging trends
that promise to expand the capabilities and accessibility of hybrid HPC-QC
systems.

</details>


### [323] [The Efficiency Frontier: Classical Shadows versus Quantum Footage](https://arxiv.org/abs/2509.06218)
*Shuowei Ma,Junyu Liu*

Main category: quant-ph

TL;DR: 经典快照方法在预测量子系统性质方面效率很高，但对于某些情况（例如，非局部可观测值多或经典后处理能力有限），它可能不是最佳选择。本研究通过将经典快照与“量子录像”（直接量子测量）进行比较，对这两种方法的资源消耗进行了全面的分析。


<details>
  <summary>Details</summary>
Motivation: 在全栈量子算法中，连接量子和经典处理器是一个重要的子程序。经典快照方法是一种提取量子态经典信息的高效方法，但它并非在所有情况下都是最优选择，特别是在处理大量非局部可观测值或经典后处理能力受限时。

Method: 通过执行全面的全栈资源分析，将经典快照方法与直接量子测量（量子录像）进行比较。

Result: 研究表明，在某些条件下，经典快照方法在可观测值数量多且保利权重小的情况下优于直接测量。对于稀疏矩阵形式的可观测值，当可观测值的数量、矩阵的稀疏度和量子比特的数量在一定范围内时，经典快照方法表现出优势。分析还确定了这两种方法在不同类型量子计算机上的盈亏平衡点。

Conclusion: 本研究为量化设计混合量子-经典断层扫描的最佳策略开辟了新途径，并为在实际应用中选择最合适的量子测量方法提供了实践指导。

Abstract: Interfacing quantum and classical processors is an important subroutine in
full-stack quantum algorithms. The so-called "classical shadow" method
efficiently extracts essential classical information from quantum states,
enabling the prediction of many properties of a quantum system from only a few
measurements. However, for a small number of highly non-local observables, or
when classical post-processing power is limited, the classical shadow method is
not always the most efficient choice. Here, we address this issue
quantitatively by performing a full-stack resource analysis that compares
classical shadows with ``quantum footage," which refers to direct quantum
measurement. Under certain assumptions, our analysis illustrates a boundary of
download efficiency between classical shadows and quantum footage. For
observables expressed as linear combinations of Pauli matrices, the classical
shadow method outperforms direct measurement when the number of observables is
large and the Pauli weight is small. For observables in the form of large
Hermitian sparse matrices, the classical shadow method shows an advantage when
the number of observables, the sparsity of the matrix, and the number of qubits
fall within a certain range. The key parameters influencing this behavior
include the number of qubits $n$, observables $M$, sparsity $k$, Pauli weight
$w$, accuracy requirement $\epsilon$, and failure tolerance $\delta$. We also
compare the resource consumption of the two methods on different types of
quantum computers and identify break-even points where the classical shadow
method becomes more efficient, which vary depending on the hardware. This paper
opens a new avenue for quantitatively designing optimal strategies for hybrid
quantum-classical tomography and provides practical insights for selecting the
most suitable quantum measurement approach in real-world applications.

</details>


### [324] [Oganesson versus Uranium Hydrogen-like Ions from the Viewpoint of Old Quantum Mechanics](https://arxiv.org/abs/2509.06249)
*Kamal Barley,Andreas Ruffing,Sergei K. Suslov*

Main category: quant-ph

TL;DR: Bohr-Sommerfeld模型中，铀和类比鿫（Oganesson）的氢原子离子在超强静电场中的自相交轨道。


<details>
  <summary>Details</summary>
Motivation: 比较铀与假想的鿫（Oganesson）在强库仑场中的原子模型行为。

Method: 使用Mathematica计算机代数系统。

Result: 证明了在超强静电场中存在自相交轨道。

Conclusion: 提出了在强引力场中也可能存在类似的“鿫（Oganesson）效应”。

Abstract: We compare, within the framework of the old Bohr-Sommerfeld atomic model,
Uranium versus hypothetical Oganesson relativistic hydrogen-like ions.
Existence of a self-intercepting orbit in the super strong static Coulomb field
is demonstrated with the aid of Mathematica computer algebra system. A
possibility of a similar 'Oganesson-type' effect in a strong gravitational
field is also mentioned.

</details>


### [325] [Beyond Stellar Rank: Control Parameters for Scalable Optical Non-Gaussian State Generation](https://arxiv.org/abs/2509.06255)
*Fumiya Hanamura,Kan Takase,Hironari Nagayoshi,Ryuhoh Ide,Warit Asavanant,Kosuke Fukui,Petr Marek,Radim Filip,Akira Furusawa*

Main category: quant-ph

TL;DR: 该论文提出了一种名为“非高斯控制参数”(s0,δ0)的新型连续可操作度量，以克服量子态生成中的计算挑战和基准测试的局限性。通过利用这些参数，研究人员开发了一种通用的优化方法，该方法可以减少光子数量需求，提高成功概率，同时保持态质量。该方法已成功应用于GKP态、cat态、cubic phase态和随机态的生成，显著提高了实验可行性，并为资源高效的非高斯态生成提供了一个统一的原则。


<details>
  <summary>Details</summary>
Motivation: 当前量子技术依赖于非高斯态，但其实现面临计算模拟和现有基准测试（如stellar rank）无法有效衡量非高斯性的局限性。

Method: 引入了非高斯控制参数(s0,δ0)作为一种连续可操作的度量，并基于此开发了一种通用的优化方法，以降低光子数需求并提高成功概率。

Result: 所提出的方法在GKP态生成中，将所需的光子探测次数减少了三分之二，并将制备概率提高了近10^8。该方法在cat态、cubic phase态和随机态的生成中也证实了广泛的实验可行性增益。

Conclusion: 该研究结果为资源高效的非高斯态生成提供了一个统一的原则，为实现可扩展的光量子技术和容错量子计算提供了实际途径。

Abstract: Advanced quantum technologies rely on non-Gaussian states of light, essential
for universal quantum computation, fault-tolerant error correction, and quantum
sensing. Their practical realization, however, faces hurdles: simulating large
multi-mode generators is computationally demanding, and benchmarks such as the
\emph{stellar rank} do not capture how effectively photon detections yield
useful non-Gaussianity. We address these challenges by introducing the
\emph{non-Gaussian control parameters} $(s_0,\delta_0)$, a continuous and
operational measure that goes beyond stellar rank. Leveraging these parameters,
we develop a universal optimization method that reduces photon-number
requirements and greatly enhances success probabilities while preserving state
quality. Applied to the Gottesman--Kitaev--Preskill (GKP) state generation, for
example, our method cuts the required photon detections by a factor of three
and raises the preparation probability by nearly $10^8$. Demonstrations across
cat states, cubic phase states, GKP states, and even random states confirm
broad gains in experimental feasibility. Our results provide a unifying
principle for resource-efficient non-Gaussian state generation, charting a
practical route toward scalable optical quantum technologies and fault-tolerant
quantum computation.

</details>


### [326] [Ramsey Interferometry with Qudits](https://arxiv.org/abs/2509.06290)
*Branislav Ilikj,Nikolay V. Vitanov*

Main category: quant-ph

TL;DR: 通过在Wigner-Majorana (WM)系统中扩展Ramsey干涉测量至qudits，实现了高精度量子计量和传感技术的显著分辨率提升。


<details>
  <summary>Details</summary>
Motivation: 利用qudits的内禀自由度，在Ramsey干涉测量中实现比传统基于qubit的方法更高的分辨率。

Method: 将Ramsey干涉测量扩展到Wigner-Majorana (WM)系统中的qudits，并研究了使用量子傅里叶变换替代$\	ext{\\pi/2}$脉冲的影响。引入分辨率-对比度指数来量化和比较不同qudit维度下的性能。

Result: 理论分析和模拟表明，WM对称性的量子系统特别适合此目标，能在给定询问时间内显著提高分辨率。三能级系统（qutrits）在不损失对比度的情况下实现了比qubits两倍的分辨率提升。更高维度的qudits能以对比度下降为代价获得更高的分辨率提升。

Conclusion: qudits是高精度量子计量和传感技术的有吸引力的候选者，特别是在WM系统中，因为它们能够提供显著的分辨率增益。三能级系统（qutrits）在分辨率和对比度之间取得了最佳平衡。

Abstract: Ramsey interferometry, a cornerstone technique in quantum spectroscopy,
traditionally operates with qubits for high precision measurements. In this
work we build on Ramsey interferometry, extending it to qudits in
Wigner-Majorana (WM) systems where the internal degrees of freedom are used to
achieve enhanced resolution. We also show that replacing the two $\pi/2$ pulses
of standard Ramsey interferometry with the quantum Fourier transform provides
no increase in resolution. Theoretical analysis further reveals that quantum
systems with the WM symmetry are particularly well-suited for this objective,
achieving substantial resolution improvements for a given interrogation time.
Simulations and analytical solutions validate these predictions, confirming the
feasibility and advantages of qudits in Ramsey interferometry. We quantify
these advantages using a resolution--contrast index that enables direct
comparison between different qudit dimensions. In particular, three state
systems (qutrits) achieve a twofold resolution increase compared to qubits
without contrast degradation, emerging as optimal for the qudit approach.
Higher dimensional qudits achieve superior resolution enhancement at the cost
of contrast degradation. These significant resolution gains establish qudits as
attractive candidates for high-precision quantum metrology and sensing
technologies.

</details>


### [327] [Efficient Convex Optimization for Bosonic State Tomography](https://arxiv.org/abs/2509.06305)
*Shengyong Li,Yanjin Yue,Ying Hu,Rui-Yang Gong,Qianchuan Zhao,Zhihui Peng,Pengtao Song,Zeliang Xiang,Jing Zhang*

Main category: quant-ph

TL;DR: 本文提出了一种基于凸优化的玻色子量子态层析成像方法，通过计算位移算符、希尔伯特空间截断和随机凸优化来提高效率和可扩展性，并结合样本型最大似然估计法，解决了在高维多模系统中量子态重建的难题。


<details>
  <summary>Details</summary>
Motivation: 精确的量子态层析成像对于量子传感、量子通信和量子纠错中的电磁场编码量子态（玻色子态）至关重要，但现有方法在处理高维希尔伯特空间、密集测量基和样本数据时效率低下，难以扩展到大型多模系统。

Method: 本文提出并结合了三种技术来增强效率和可扩展性：高效的位移算符计算、希尔伯特空间截断以及随机凸优化。在此基础上，提出了一种专门为飞行模式层析成像设计的样本型、凸最大似然估计（MLE）方法。

Result: 数值模拟了四模和九模飞行模式问题，证明了所提出方法在精度和实用性方面优于现有方法。

Conclusion: 所提出的样本型、凸最大似然估计方法为在高维多模系统中进行可靠的玻色子模式量子态重建提供了实用的工具。

Abstract: Quantum states encoded in electromagnetic fields, also known as bosonic
states, have been widely applied in quantum sensing, quantum communication, and
quantum error correction. Accurate characterization is therefore essential yet
difficult when states cannot be reconstructed with sparse Pauli measurements.
Tomography must work with dense measurement bases, high-dimensional Hilbert
spaces, and often sample-based data. However, existing convex
optimization-based techniques are not efficient enough and scale poorly when
extended to large and multi-mode systems. In this work, we explore convex
optimization as an effective framework to address problems in bosonic state
tomography, introducing three techniques to enhance efficiency and scalability:
efficient displacement operator computation, Hilbert space truncation, and
stochastic convex optimization, which mitigate common limitations of existing
approaches. Then we propose a sample-based, convex maximum-likelihood
estimation (MLE) method specifically designed for flying mode tomography.
Numerical simulations of flying four-mode and nine-mode problems demonstrate
the accuracy and practicality of our methods. This method provides practical
tools for reliable bosonic mode quantum state reconstruction in
high-dimensional and multi-mode systems.

</details>


### [328] [Single-Shot Decoding of Biased-Tailored Quantum LDPC Codes](https://arxiv.org/abs/2509.06316)
*Devon Campbell*

Main category: quant-ph

TL;DR: 研究提出结合偏置定制和单次读取解码两种策略来处理量子处理器中的偏置噪声和读取噪声问题，并在四维提升超图积码（4D-LHP）上进行了实现，模拟结果显示该方法能有效降低误码率并提高可恢复性。


<details>
  <summary>Details</summary>
Motivation: 量子处理器常受偏置噪声和读取噪声影响，降低了其可靠性和可重复性。

Method: 结合偏置定制（将稳定子与主导错误类型对齐）和单次读取（SS）解码（使用元检查来识别单轮测量中的错误）两种策略。在由拟循环原型图种子构建的四维提升超图积（4D-LHP）码中实现了这些想法。

Result: 模拟结果表明，偏置定制在各种实际Z:X偏置比（从1:1到1000:1）下，词错误率（WER）降低了20-60%，在中等偏置下改进最大。在存在测量噪声的情况下，单次SS读取可以恢复超过三分之一因读取错误而损失的性能。元检查可以识别超过99.8%的错误综合症。

Conclusion: 4D-LHP码在实际噪声下仍能保持强大的韧性，有望集成到量子CPU-CPU工作流中。

Abstract: Quantum processors are often affected by biased noise and noisy readout,
which reduce reliability and reproducibility. This work combines two
complementary strategies to address these challenges. The first is bias
tailoring, which aligns stabilizers with the dominant error type. The second is
single-shot (SS) decoding, which uses metachecks to identify measurement faults
from just one noisy round. We implement these ideas in a four-dimensional
lifted hypergraph product (4D-LHP) code constructed from quasi-cyclic
protograph seeds. Simulation results show that bias tailoring lowers the
word-error rate (WER) by 20-60 percent across realistic Z:X bias ratios (from
1:1 up to 1000:1), with the largest improvements at moderate bias. When
measurement noise is present, a single SS round recovers more than one third of
the performance lost to readout errors. Moreover, metachecks identify over 99.8
percent of faulty syndromes, providing near-complete fault visibility even with
limited correction power. Together, these findings demonstrate that 4D-LHP
codes maintain strong resilience under realistic noise, making them promising
candidates for integration into orchestrated QPU-CPU workflows.

</details>


### [329] [Schrodinger's Toolbox: Exploring the Quantum Rowhammer Attack](https://arxiv.org/abs/2509.06318)
*Devon Campbell*

Main category: quant-ph

TL;DR: 量子云服务中的残余串扰会带来安全风险。本文展示了一种仅使用X和CNOT门的量子Rowhammer攻击，能够在无需脉冲级访问的情况下，在IBM的127量子比特Eagle处理器上注入故障。


<details>
  <summary>Details</summary>
Motivation: 量子云服务中的残余串扰构成安全漏洞。

Method: 通过仅使用X和CNOT门的Clifford-only量子Rowhammer攻击，在IBM的127量子比特Eagle处理器上注入故障，并进行近50%的翻转率的哈达玛基探测，以及进行全晶格扫描来绘制QR的行为。

Result: 攻击诱导的局部错误被限制在攻击周期内，主要表现为相位噪声，翻转率为近50%。QR的行为可复现，且损坏限制在距离攻击比特两个耦合跳内的量子比特，并在随后的良性周期中快速恢复。

Conclusion: QR的特性可用于构建一个质押探测隐通道，实现高可靠性的信号传输。这表明需要硬件级隔离和感知调度器的防御措施。

Abstract: Residual cross-talk in superconducting qubit devices creates a security
vulnerability for emerging quantum cloud services. We demonstrate a
Clifford-only Quantum Rowhammer attack-using just X and CNOT gates-that injects
faults on IBM's 127-qubit Eagle processors without requiring pulse-level
access. Experiments show that targeted hammering induces localized errors
confined to the attack cycle and primarily manifests as phase noise, as
confirmed by near 50% flip rates under Hadamard-basis probing. A full lattice
sweep maps QR's spatial and temporal behavior, revealing reproducible
corruption limited to qubits within two coupling hops and rapid recovery in
subsequent benign cycles. Finally, we leverage these properties to outline a
prime-and-probe covert channel, demonstrating that the clear separability
between hammered and benign rounds enables highly reliable signaling without
error correction. These findings underscore the need for hardware-level
isolation and scheduler-aware defenses as multi-tenant quantum computing
becomes standard.

</details>


### [330] [Monotones from multi-invariants: a classification](https://arxiv.org/abs/2509.06348)
*Abhijit Gadde,Shraiyance Jain*

Main category: quant-ph

TL;DR: 本文研究了多方量子态的局部酉不变量，特别关注由态及其共轭多项式构成的多不变量，并将其与图论中的边凸性联系起来，猜想并证明了除六种情况外的边凸多不变量的完整分类。


<details>
  <summary>Details</summary>
Motivation: 研究多方量子态的局部酉不变量，特别是那些在局部操作和经典通信下平均单调的多不变量，旨在提供一个完整的分类。

Method: 将局部酉不变量的单调性条件与图论中的边凸性联系起来，并猜想和证明了边凸多不变量的分类。

Result: 证明了除六种情况外，所有边凸多不变量都可以由有限的Coxeter群标记。

Conclusion: 本文的猜想和部分证明为理解多方量子态的局部酉不变量提供了一个重要的分类框架。

Abstract: In this paper we study local unitary invariants of a multi-partite quantum
state that are monotonic, on average, under local operations and classical
communication (locc). In particular we focus on local unitary invariants that
are constructed out of polynomials in the state and its conjugate - called
multi-invariants. Multi-invariants are labeled by certain types of graphs.
Recently, in \cite{Gadde:2024jfi}, the authors related the condition of
monotonicity under locc to a graph theoretic condition on the multi-invariant
called edge-convexity. In this paper, we conjecture a complete classification
of edge-convex multi-invariants. The conjecture states that the edge-convex
multi-invariants are labeled by finite Coxeter groups. We prove this conjecture
for all but six cases.

</details>


### [331] [Subspace Variational Quantum Simulation: Fidelity Lower Bounds as Measures of Training Success](https://arxiv.org/abs/2509.06360)
*Seung Park,Dongkeun Lee,Jeongho Bang,Hoon Ryu,Kyunghyun Baek*

Main category: quant-ph

TL;DR: 我们提出了一种迭代变分量子算法，用于在给定子空间内模拟任意初始状态的时间演化，该算法将Trotter电路压缩为较短深度的参数化电路，并使用基于保真度的成本函数在单个训练过程中对多个初始状态进行同时优化。训练完成后，我们为子空间内的任意状态提供了一个可有效计算的保真度下界，保证了算法在最坏情况下的训练性能。我们还证明了我们的成本函数在训练过程中，初始参数附近的每个迭代中都存在无 barren plateau的区域。我们在IBMQ处理器上通过模拟2量子比特Ising模型来演示该算法的实验效果，并提供了10量子比特Ising模型的模拟结果以展示更大系统的可能性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一种更高效的量子算法来模拟量子系统的时域演化，特别关注任意初始状态在特定子空间内的行为。现有方法可能存在深度过大或优化效率不高的问题，因此需要一种新的方法来压缩量子线路并优化训练过程。

Method: 提出了一种迭代变分量子算法。该算法首先将Trotter电路压缩为较短深度的参数化电路。然后，利用基于保真度的成本函数，在单个训练过程中同时优化多个初始状态。在训练完成后，计算一个可有效获得的保真度下界，以保证算法在最坏情况下的性能。此外，还分析了训练过程中成本函数的巴伦高原特性，并发现其在初始参数附近存在无巴伦高原的区域。

Result: 通过在IBMQ处理器上模拟2量子比特Ising模型进行了实验验证。此外，还成功模拟了10量子比特Ising模型，展示了该算法在更大系统上的潜力。

Conclusion: 该迭代变分量子算法能够有效地模拟量子系统的时域演化，并且通过线路压缩和多状态同时优化提高了训练效率。算法提供的保真度下界和无巴伦高原特性增强了其可靠性和实用性。实验结果表明该算法在实际量子硬件上是可行的，并有潜力扩展到更大的量子系统。

Abstract: We propose an iterative variational quantum algorithm to simulate the time
evolution of arbitrary initial states within a given subspace. The algorithm
compresses the Trotter circuit into a shorter-depth parameterized circuit,
which is optimized simultaneously over multiple initial states in a single
training process using fidelity-based cost functions. After the whole training
procedure, we provide an efficiently computable lower bound on the fidelities
for arbitrary states within the subspace, which guarantees the performance of
the algorithm in the worst-case training scenario. We also show our cost
function exhibits a barren-plateau-free region near the initial parameters at
each iteration in the training landscape. The experimental demonstration of the
algorithm is presented through the simulation of a 2-qubit Ising model on an
IBMQ processor. As a demonstration for a larger system, a simulation of a
10-qubit Ising model is also provided.

</details>


### [332] [Collective dissipation engineering of interacting Rydberg atoms](https://arxiv.org/abs/2509.06373)
*Tao Chen,Chenxi Huang,Jacob P. Covey,Bryce Gadway*

Main category: quant-ph

TL;DR: 我们实现了一个可调谐的、状态分辨的激光诱导损耗通道，用于单个里德堡原子，并揭示了分离量子齐纳和反齐纳区域的动力学演化。


<details>
  <summary>Details</summary>
Motivation: 量子态的工程耗散控制，可实现高保真度的制备、传输和稳定，并进入新的相变。本研究实现了针对单个里德堡原子的可调谐、状态分辨的激光诱导损耗通道，以探索其在强相互作用下的行为。

Method: 利用激光诱导损耗通道，研究了非相互作用和强相互作用两种情况下的里德堡原子行为，并揭示了相互作用驱动的相变点，以及相互作用增强的衰减。

Result: 实现了相互作用驱动的相变点，揭示了相互作用增强的衰减，并观察到了一种依赖于相互作用的、选择特定原子对的齐纳效应，实现了目标自旋态的冻结。将此机制扩展到多体链中，可用于耗散地蒸馏不需要的自旋构型。

Conclusion: 这项工作展示了一种探索强相互作用、开放量子自旋系统的通用方法，并为在里德堡原子阵列中耗散制备强关联量子态开辟了新的途径。

Abstract: Engineered dissipation is emerging as an alternative tool for quantum state
control, enabling high-fidelity preparation, transfer and stabilization, and
access to novel phase transitions. We realize a tunable, state-resolved
laser-induced loss channel for individual Rydberg atoms, in both
non-interacting and strongly correlated settings. This capability allows us to
reveal interaction-driven shifts of the exceptional point separating quantum
Zeno and anti-Zeno regimes, and to demonstrate interaction-enhanced decay. By
exploiting interaction-dependent energy level shifts, we observe a
configuration-selective two-body Zeno effect that freezes target spin states.
We theoretically show that when this mechanism is extended to many-body chains
it allows for the dissipative distillation of unwanted spin configurations.
These experimental studies establish a versatile approach for exploring
strongly interacting, open quantum spin systems, and opens possible new
routines for dissipative preparation of correlated quantum states in Rydberg
atom arrays.

</details>


### [333] [Non-Exponential Decay in Finite Photonic Waveguide Arrays](https://arxiv.org/abs/2509.06443)
*Florian H. Huber,Benedikt Braumandl,Johannes Knörzer,Jonas Himmel,Carlotta Versmold,Robert H. Jonsson,Alexander Szameit,Jasmin Meinecke*

Main category: quant-ph

TL;DR: 开放量子系统的动力学行为（指数衰减、非指数弛豫或振荡动力学）取决于系统与环境的耦合方式。本研究通过一个参数控制一个格点边界缺陷在这些动力学模式之间转换。研究扩展了振荡情况的精确解，并建立了一个由集成波导阵列实验证实的统一理论。通过对比分析、数值模拟和实验数据，研究刻画了有限尺寸效应，为模拟无限系统和研究光子晶格中的开放系统提供了基准。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统的动力学行为，特别是系统-环境耦合如何影响其衰减、弛豫或振荡模式，并建立一个统一的理论来描述这些行为。

Method: 通过一个参数控制格点边界缺陷在不同动力学模式（指数衰减、非指数弛豫、振荡）之间转换。扩展了振荡情况的精确解，并通过集成波导阵列实验进行验证。通过分析、数值模拟和实验数据来刻画有限尺寸效应。

Result: 建立了一个统一的理论，能够描述开放量子系统在不同耦合情况下的动力学行为，并通过实验进行了验证。成功地将有限尺寸效应与理论模型进行了对比，为未来的研究提供了基准。

Conclusion: 该研究为理解和模拟开放量子系统在光子晶格中的行为提供了一个统一的理论框架，并为模拟无限系统和研究开放系统提供了重要的基准。

Abstract: Open quantum-system dynamics can follow exponential decay, non-exponential
relaxation, or oscillatory dynamics, depending on the system-environment
coupling. We study a lattice with a boundary defect that transitions between
these regimes, controlled by a single parameter. Extending the exact solution
to the oscillatory case, we establish a unified theory confirmed by experiments
in integrated waveguide arrays. We characterize finite-size effects by
comparing analytics, numerics, and data. This provides a benchmark for
emulating infinite systems and studying open systems in photonic lattices.

</details>


### [334] [Improving Entanglement Resilience in Quantum Memories with Error-Detection-Based Distillation](https://arxiv.org/abs/2509.06446)
*Huidan Zheng,Gunsik Min,Ilkwon Sohn,Jun Heo*

Main category: quant-ph

TL;DR: 提出基于[[4,2,2]]量子纠错码的纠缠蒸馏协议，并提出重蒸馏策略以延长量子存储时间。


<details>
  <summary>Details</summary>
Motivation: 量子存储中纠缠因退相干而衰减是可扩展量子网络的关键挑战。

Method: 提出基于[[4,2,2]]量子纠错码的纠缠蒸馏协议，推导出输出保真度和产率的解析表达式，并与BBPSSW协议进行基准测试。研究了使用局部操作和经典通信刷新存储的逻辑纠缠态的重蒸馏策略。

Result: 重蒸馏策略可以延长有效的存储寿命，其性能优势主要取决于经典通信延迟。推导了保持优越性的经典通信延迟上限。

Conclusion: 该工作提出了将量子存储器视为可重复使用资源的处理框架，并将蒸馏策略与实际实施限制联系起来，为设计弹性量子网络提供了定量指导。

Abstract: The degradation of entanglement in quantum memories due to decoherence is a
critical challenge for scalable quantum networks. We present an entanglement
distillation protocol based on the [[4,2,2]] quantum error-detecting code,
deriving analytical expressions for its output fidelity and yield, and
benchmarking it against the BBPSSW protocol. In addition to initial
distillation, we investigate a re-distillation strategy in which stored logical
entangled states are refreshed using only local operations and classical
communication, avoiding the need to regenerate and redistribute entanglement
from scratch. Our analysis shows that this method can extend the effective
storage lifetime beyond BBPSSW,with its performance advantage primarily
determined by classical communication delay. We derive upper bounds on
classical communication latency required for the approach to maintain
superiority. This work introduces a framework for treating quantum memories as
reusable resources and links distillation strategy to practical implementation
constraints, offering quantitative guidance for designing resilient quantum
networks.

</details>


### [335] [Theoretical and experimental analysis of adaptive quantum computers](https://arxiv.org/abs/2509.06455)
*Niels M. P. Neumann*

Main category: quant-ph

TL;DR: 近期，研究人员对利用量子计算中的经典计算部分产生兴趣，他们发现其在检测和纠正量子计算中的错误方面至关重要。本研究将填补在真实场景中分析自适应量子算法优势的空白，并提出一个最坏情况噪声模型，用于推导制备 GHZ 态和 W 态的成功概率。通过在量子硬件上实现这些协议，研究结果表明，尽管自适应量子算法具有潜在优势，但目前在实际应用中仍无法超越非自适应算法。


<details>
  <summary>Details</summary>
Motivation: 近期，人们对利用量子计算中的经典计算部分产生兴趣，他们发现其在检测和纠正量子计算中的错误方面至关重要。

Method: 本研究将填补在真实场景中分析自适应量子算法优势的空白，并提出一个最坏情况噪声模型，用于推导制备 GHZ 态和 W 态的成功概率。通过在量子硬件上实现这些协议，研究结果表明，尽管自适应量子算法具有潜在优势，但目前在实际应用中仍无法超越非自适应算法。

Result: 通过在量子硬件上实现这些协议，研究结果表明，尽管自适应量子算法具有潜在优势，但目前在实际应用中仍无法超越非自适应算法。

Conclusion: 尽管自适应量子算法具有潜在优势，但目前在实际应用中仍无法超越非自适应算法。

Abstract: Fault-tolerant quantum computations require alternating quantum and classical
computations, where the classical computations prove vital in detecting and
correcting errors in the quantum computation. Recently, interest in using these
classical computations has been growing again, not to correct errors, but to
perform computations. Various works have looked into these so-called adaptive
quantum algorithms. Few works however have looked in the advantages of adaptive
quantum algorithms in realistic scenarios. This work provides the first step in
this direction. We introduce a worst-case noise model and use it to derive
success probabilities for preparing a GHZ state and preparing a $W$-state using
either an adaptive quantum algorithm, or using a standard non-adaptive quantum
algorithm. Next, we implemented these protocols on quantum hardware and we
compare the outcomes to our derived theoretical results. We find that despite
their potential, adaptive quantum algorithms currently do not outperform full
quantum algorithms.

</details>


### [336] [Time-frequency Entangled Photon Mediated CCZ Gate](https://arxiv.org/abs/2509.06497)
*Chenhui Wang,Weilong Wang,Yangyang Fei,Zhiqiang Fan,Hanshi Zhao,Yuyan Mage,Zheng Shan*

Main category: quant-ph

TL;DR: 使用两光子吸收现象实现高保真度的CCZ门，相较于分解方法，具有更短的延迟和更高的保真度，并具有抗参数漂移的优点，可扩展至任意角度的CCPhase({\theta})门和多比特操作。


<details>
  <summary>Details</summary>
Motivation: 高保真度的本地多量子比特操作对于高效量子电路编译至关重要，因为它们能够缩短电路深度并提高性能。然而，这些门的设计和实现仍然是一个挑战。

Method: 提出了一种基于两光子吸收现象的直接CCZ门实现方案，该方案具有硬件效率和可扩展性，适用于当前的超导量子计算平台。通过优化量子比特和耦合器的参数，实现了在194纳秒内超过99%的模拟保真度。

Result: 与使用单量子比特和两量子比特门分解的方法相比，该方案在延迟和整体保真度方面均优于分解方法。该方案对参数漂移具有鲁棒性，并且可以扩展到任意角度的CCPhase({\theta})门和多比特操作。

Conclusion: 所提出的方案具有显著的优势，为在实际应用中实现复杂量子电路的深度压缩铺平了道路，有望在变革性的量子算法和模拟中发挥作用。

Abstract: High-fidelity native multi-qubit operations are crucial to efficient quantum
circuit compilation due to their ability of shortening circuit depth and
enhence the performance. However, the design and implementation of these gates
remain a challenge. Here, we demonstrate a hardware-efficient scalable scheme
for direct CCZ gate implementation based on two-photon absorption phenomenon,
which is applicable to current superconducting quantumcomputing platforms. By
carefully optimizing the parameters of qubits and couplers, we achieve a
simulated fidelity over 99% within 194ns, surpassing the decomposed methods
with single-qubit and two-qubit gates in both latency and overall fidelity.
Crucially, the scheme is robust against parameter drifts and can be extended to
CCPhase({\theta}) gates with arbitrary angles and multi-qubit operations. All
these results highlight the advantages of our scheme which paves the way for
substantial depth compression of complex quantum circuits for practical
application in transformative quantum algorithms and simulations.

</details>


### [337] [Tuning of SiV quantum emission in nitrogen-doped nanodiamonds by dual-color excitation](https://arxiv.org/abs/2509.06500)
*A. A. Zhivopistsev,A. M. Romshin,A. V. Gritsienko,D. G. Pasternak,R. K. Bagramov,V. P. Filonenko,F. M. Maksimov,A. I. Chernov,A. M. Skomorokhov,N. I. Kargin,I. I. Vlasov*

Main category: quant-ph

TL;DR: 在不同氮（Ns）浓度的高压高温纳米金刚石（NDs）中，首次研究了硅-空位（SiV）中心的电荷动力学。结果显示，在强红色（~660 nm）和弱绿色（~530 nm）双色激发下，SiV-光致发光（PL）增强了六倍。


<details>
  <summary>Details</summary>
Motivation: 研究不同氮浓度下高压高温纳米金刚石中硅-空位（SiV）中心的电荷动力学，以期实现对SiV发光特性的调控。

Method: 通过双色激发（强红光+弱绿光）研究SiV-光致发光（PL）强度的增强效应，并测量PL寿命和强度随激发波长的依赖性，以及PL增强与氮（Ns）浓度之间的关系。同时，通过饱和曲线和二阶PL强度关联测量，进一步研究绿光激发对SiV2-状态的影响。

Result: 观察到SiV-光致发光（PL）在双色激发下增强了六倍。PL寿命和强度与激发波长的关系，以及PL增强与Ns浓度的关系，均表明施主氮参与了SiV-发光动力学。绿光激发抑制了光学惰性的SiV2-状态的形成。

Conclusion: 研究结果为利用SiV发光纳米金刚石构建光学可控、可扩展的量子发射体提供了实际可行的方法。

Abstract: The charge dynamics of silicon-vacancy (SiV) centers have been investigated
for the first time in high-pressure high-temperature nanodiamonds (NDs) with
varying concentrations of substitutional nitrogen (Ns). We demonstrate a
controlled sixfold enhancement of SiV- photoluminescence (PL) under dual-color
excitation, consisting of strong red (~660 nm) illumination combined with weak
green (~530 nm) excitation. The measured dependencies of SiV- PL lifetime and
intensity on excitation wavelength, together with the enhancement dependence on
Ns concentration in the studied nanodiamonds, provide unambiguous evidence of
the involvement of donor nitrogen in SiV-emission dynamics. Saturation curves
and second-order PL intensity correlation measurements further indicate
suppression of the population of the optically inactive SiV2- state upon the
addition of green excitation. These results unlock a practical pathway toward
engineering optically-controlled and scalable quantum emitters based on
SiV-luminescent diamond nanoparticles.

</details>


### [338] [Universal quantum control over bosonic network](https://arxiv.org/abs/2509.06560)
*Zhu-yao Jin,Jun Jing*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Perfect transfer of unknown states across distinct nodes is fundamental in
the construction of bosonic quantum networks. We here develop a general theory
to control an $N$-node bosonic network governed by the time-dependent
Hamiltonian, as the universal quantum control theory for continuous-variable
systems. In particular, we can activate nonadiabatic passages superposed of
initial and target modes by the commutation condition for the Hamiltonian's
coefficient matrix in the representation of time-independent ancillary modes,
which serves as the necessary and sufficient condition to solve the
time-dependent Schr\"odinger equation of the entire network. To exemplify the
versatility of our theory on the Heisenberg-picture passages, we perform
arbitrary state exchange between two nodes, chiral NOON-state transfer among
three bosonic nodes, and chiral Fock-state transfer among three of four bosonic
nodes. Our work provides a promising avenue toward universal control of any
pair of nodes or modes in bosonic networks as well as the whole network.

</details>


### [339] [Construction of PPT entangled state and its detection by using second-order moment of the partial transposition](https://arxiv.org/abs/2509.06565)
*Rohit Kumar,Satyabrata Adhikari*

Main category: quant-ph

TL;DR: 本论文提出了一种新的正偏转（PPT）状态构造方法，该方法包含可分离态和PPT纠缠态，并推导了区分它们的新条件。


<details>
  <summary>Details</summary>
Motivation: 在量子信息处理中，区分可分离态和纠缠态是一个基本问题。特别是PPT（正偏转）状态的识别，对于理解量子纠缠的结构和应用至关重要。

Method: 提出了一种构造PPT状态的新形式主义，并推导出基于二阶矩（p2）的PPT状态判据。此外，还建立了PPT状态的二阶和三阶矩之间的关系，并提出了一种利用量子泄露（witness operator）来识别PPT纠缠态的方法。最后，将该方法应用于私有态的制备，分析了可蒸馏密钥率。

Result: 1. 构造了一类新的PPT状态，包含可分离态和PPT纠缠态。 2. 提出并验证了一个新的PPT状态判据，该判据基于二阶矩p2，易于计算且具有实验可实现性。 3. 发现了PPT状态的二阶和三阶矩之间的关系，并利用该关系来区分NPT（负偏转）纠缠态。 4. 通过混合可分离态和纠缠态，构造了一个PPT纠缠态，并表明该状态可以被用于混合的纠缠态的量子泄露所识别。 5. 证明了通过该方法制备的私有态具有正的可蒸馏密钥率。

Conclusion: 本研究成功构造了一类新的PPT状态，并提出了一种简单且实验上可行的判据来识别它们。此外，还发现了PPT状态矩之间的关系，并将其应用于纠缠态的识别和私有态在量子密码学中的应用。研究结果为理解和利用量子纠缠提供了新的视角和工具。

Abstract: In this work, we adopt a formalism by which we construct a new family of
positive partial transpose (PPT) states, which includes separable and PPT
entangled states (PPTES) in a $d_{1}\otimes d_{2}$ dimensional system and then
derive a condition that can distinguish between them. The PPT condition is
expressed in terms of the inequality between the second-order moment of the
system's partial transposition $(p_2)$ and the reciprocal of the product of
$d_{1}$ and $d_{2}$. The second order moment $(p_{2})$ plays a vital role in
detecting the PPT states as it is very easy to calculate and may be a
realizable quantity in an experiment. Once we know that the given state is a
PPT state, we will use a suitable witness operator to detect whether the given
PPT state is a PPTES. Further, we have established a relation between the
second and third order moments of partial transposition of a PPT state and have
shown that the violation of the inequality implies that the detected state is a
negative partial transpose (NPT) entangled state. We will then construct a
quantum state by considering the mixture of a separable and an entangled state
and obtain a condition on the mixing parameter for which the mixture represents
a PPT entangled state. We observe that the resulting PPT entangled state may
also be detected by the same witness operator $W$, which had detected the
entangled state present in the mixture. Finally, applying our results, we have
shown that the distillable key rate of the private state, prepared through our
prescription, is positive. It suggests that our result also has potential
applications in quantum cryptography.

</details>


### [340] [Reaffirming a Challenge to Bohmian Mechanics](https://arxiv.org/abs/2509.06584)
*Jan Klaers,Violetta Sharoglazova,Marius Puplauskis*

Main category: quant-ph

TL;DR: 文章首次测量了隧穿粒子的速度，结果与玻姆力学标准方程不符，对该理论提出挑战。


<details>
  <summary>Details</summary>
Motivation: 对先前工作中测量的隧穿粒子速度与玻姆力学标准方程的矛盾进行更详细的阐述和论证。

Method: 通过对玻姆的指导方程进行重新表述，将先前关于粒子速度的实验结果扩展到轨迹层面，并与标准量子力学进行比较。

Result: 在对玻姆的指导方程进行重新表述后，玻姆力学与标准量子力学在隧穿及相关现象的预测上达成一致。

Conclusion: 先前的实验结果对玻姆力学提出了挑战，但通过修正其指导方程，可以协调玻姆力学与标准量子力学的预测。玻姆力学需要证明或修正其对标准指导方程的依赖性。

Abstract: In our recent work (Sharoglazova et al., Nature 643, 67 (2025)), we reported
the first measurement of the speed of tunnelling particles using a coupled
waveguide system. The measured speed was found to be in disagreement with the
standard guiding equation of Bohmian mechanics, which we regard as a challenge
to that framework. In the present article, we provide a more detailed account
of this issue. In particular, we argue that reformulating the Bohmian guiding
equation so as to extend our results on the particle speed to the trajectory
level yields a convergence between the predictions of Bohmian mechanics and
standard quantum mechanics for tunnelling and related phenomena. Our findings
therefore challenge Bohmian mechanics to justify or revise its reliance on the
standard guiding equation-an issue that has so far not been addressed.

</details>


### [341] [Dissipation-Enhanced Localization in a Disorder-Free $\mathbb{Z}_2$ Lattice Gauge System](https://arxiv.org/abs/2509.06642)
*Xuanpu Yang,Xiang-Ping Jiang,Lei Pan*

Main category: quant-ph

TL;DR: $\\mathbb{Z}_2$规范格点模型中的耗散动力学可以增强无序不相关的局域化现象，并稳定非遍历行为。


<details>
  <summary>Details</summary>
Motivation: 研究$\\mathbb{Z}_2$规范格点模型中量子耗散对其动力学行为的影响，特别是其增强局域化和稳定非遍历行为的能力。

Method: 通过将$\\mathbb{Z}_2$规范格点模型与马尔可夫环境耦合，研究其耗散动力学。

Result: 量子耗散可以增强$\\mathbb{Z}_2$规范格点模型中的局域化现象，使得初始状态的记忆在耗散演化下比在幺正动力学下更能被保留。这种耗散诱导的局域化增强现象存在于多种初始状态下，表明该效应并非仅限于微调的组态。

Conclusion: 耗散（通常与退相干和热化相关）可以作为稳定规范约束量子系统中非遍历行为的有力工具。

Abstract: The $\mathbb{Z}_2$ lattice gauge model, as the simplest realization of a
lattice gauge theory, exhibits rich and unconventional physics. One of its most
remarkable features is disorder-free localization, where localization emerges
not from explicit quenched disorder but from static background $\mathbb{Z}_2$
gauge charges, leading to persistent memory of the initial state. In this work,
we investigate the dissipative dynamics of the $\mathbb{Z}_2$ lattice gauge
model by coupling it to a Markovian environment. We find that quantum
dissipation can enhance localization: memory of the initial state is retained
more robustly under dissipative evolution than under unitary dynamics. This
dissipation-induced enhancement of localization persists across a variety of
initial states, indicating that the effect is not limited to fine-tuned
configurations. Our results demonstrate that dissipation, often associated with
decoherence and thermalization, can in fact serve as a powerful tool for
stabilizing non-ergodic behavior in gauge-constrained quantum systems.

</details>


### [342] [Classical Neural Networks on Quantum Devices via Tensor Network Disentanglers: A Case Study in Image Classification](https://arxiv.org/abs/2509.06653)
*Borja Aizpurua,Sukhbinder Singh,Román Orús*

Main category: quant-ph

TL;DR:  we propose a hybrid classical-quantum approach to implement bottleneck layers of pre-trained neural networks on quantum computers by representing linear layers as matrix product operators (MPOs) and disentangling them for efficient execution.


<details>
  <summary>Details</summary>
Motivation: The goal is to achieve quantum advantage on near-term quantum devices by implementing bottleneck layers from classical pre-trained neural networks on a quantum computer.

Method: The approach involves compressing the target linear layer into an effective matrix product operator (MPO) without performance degradation. The MPO is then disentangled into a more compact form, enabling a hybrid classical-quantum execution scheme where disentangling circuits run on a quantum computer and the rest of the network runs on classical hardware. Two algorithms for MPO disentangling are introduced: an explicitly disentangling variational method and an implicitly disentangling gradient-descent-based approach.

Result: The methods were validated through a proof-of-concept translation of simple classical neural networks for MNIST and CIFAR-10 image classification into a hybrid classical-quantum form.

Conclusion: This work presents a viable method for implementing neural network bottleneck layers on quantum computers, paving the way for potential quantum advantage in machine learning tasks.

Abstract: We address the problem of implementing bottleneck layers from classical
pre-trained neural networks on a quantum computer, with the goal of achieving
quantum advantage on near-term devices. Our approach begins with a compression
step in which the target linear layer is represented as an effective matrix
product operator (MPO) without degrading model performance. The MPO is then
further disentangled into a more compact form. This enables a hybrid
classical-quantum execution scheme, where the disentangling circuits are
deployed on a quantum computer while the remainder of the network -- including
the disentangled MPO -- runs on classical hardware. We introduce two
complementary algorithms for MPO disentangling: (i) an explicitly disentangling
variational method leveraging standard tensor-network optimization techniques,
and (ii) an implicitly disentangling gradient-descent-based approach. We
validate these methods through a proof-of-concept translation of simple
classical neural networks for MNIST and CIFAR-10 image classification into a
hybrid classical-quantum form.

</details>


### [343] [Robust and cost-effective quantum network using Kramers-Kronig receiver](https://arxiv.org/abs/2509.06711)
*Xu Liu,Tao Wang,Junpeng Zhang,Yankai Xu,Yuehan Xu,Lang Li,Peng Huang,Guihua Zeng*

Main category: quant-ph

TL;DR: 该研究提出了一种基于Kramers-Kronig接收器的鲁棒且经济高效的量子网络方案，解决了现有量子密钥分发（QKD）协议中对干涉的过度依赖导致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有量子密钥分发（QKD）协议过度依赖干涉，导致系统和网络鲁棒性较弱。本研究旨在提出一种鲁棒且经济高效的量子网络解决方案。

Method: 提出了一种基于直接检测的连续可变QKD协议，利用Kramers-Kronig关系恢复正交分量，实现了无干涉的量子密钥分发。该协议被扩展到连续可变的量子接入网络，进一步展示了无干涉检测的鲁棒性和成本优势。

Result: 实验结果表明，在接入网络范围内，每用户可利用单个光电探测器以55 kbit/s的速率实现安全密钥生成，且无需干涉结构。

Conclusion: 本研究提出的无干涉检测方案为构建鲁棒且经济高效的量子网络提供了新的可能性，是实现大规模量子互联网的基础。

Abstract: The quantum internet holds the potential to facilitate applications that are
fundamentally inaccessible to the classical internet. Among its most prominent
applications is quantum key distribution (QKD) networks, which connect two
distant nodes to establish a secure key based on the principles of quantum
mechanics. However, the subsequent extensive reliance on interferences in
existing QKD protocols leads to the weak robustness of the system and the
corresponding network. In this work, we propose a robust and cost-effective
quantum network using the Kramers-Kronig receiver. We first propose a
continuous-variable QKD protocol based on direct detection without
interference, which achieves the recovery of quadrature components through the
Kramers-Kronig relation. Subsequently, we have extended this protocol to
continuous-variable quantum access networks, further highlighting the
robustness and cost advantages of interference-free detection. The experimental
results show that each user can achieve a secret key rate at 55 kbit/s within
the access network range by using only one photodetector without interference
structures. This scheme opens up new possibilities in establishing a robust and
cost-effective quantum network, serving as a foundational element in the
progress toward establishing a large-scale quantum internet.

</details>


### [344] [Certification of energy-restricted entanglement depth with simple measurements](https://arxiv.org/abs/2509.06726)
*Carles Roch I Carceller*

Main category: quant-ph

TL;DR: 本研究提出了一种在多方场景下认证纠缠的方法，适用于能量受限的量子源。


<details>
  <summary>Details</summary>
Motivation: 开发量子技术，特别是构建大规模量子网络，需要能够认证多方纠缠的能力。

Method: 提出一种基于多个远程、未经充分表征的参与者所玩的状态判别游戏的方法，该方法可以从能量受限的源认证纠缠。该方法使用所有参与者单一、简单且可分离的测量设置，检测所有可能的二分划下的纠缠，从而为认证多方纠缠的深度提供了一个鲁棒且可扩展的工具。

Result: 该方法在多方场景下，性能和抗噪声能力随参与方数量呈指数级增长。

Conclusion: 本研究提出的方法为在资源受限的情况下认证多方纠缠提供了一个有效且可扩展的解决方案，并且在参与方数量增加时性能得到提升。

Abstract: The ability to certify entanglement in multipartite scenarios is crucial for
the development of quantum technologies, specially for the realization of
large-scale networks. Here, we introduce a method to certify entanglement from
sources with limited energy based on a state discrimination game played by
multiple distant uncharacerized parties. Our approach is capable of detecting
entanglement across all possible bipartitions employing a single, simple and
separable measurement setting for all parties, thereby providing a robust and
scalable tool for certifying the depth of multipartite entanglement. We also
show that the performance and noise robustness of our method improves in the
multipartite regime, growing exponentially with the number of parties.

</details>


### [345] [Enhancing Fault-Tolerant Surface Code Decoding with Iterative Lattice Reweighting](https://arxiv.org/abs/2509.06756)
*Yi Tian,Yi-Cong Zheng,Xiaoting Wang,Ching-Yi Lai*

Main category: quant-ph

TL;DR: IRMWPM通过考虑比特翻转和相位翻转错误之间的相关性来改进量子纠错，在模拟电路级噪声时，与标准MWPM相比，可大幅降低逻辑错误率并减少所需的量子比特开销。


<details>
  <summary>Details</summary>
Motivation: 需要高效且逼真的错误解码来支持容错量子计算，特别是要处理硬件相关的、比特翻转（X）和相位翻转（Z）错误之间的相关性。

Method: 提出迭代重加权最小重量完美匹配（IRMWPM）解码器，该解码器利用故障检测模式来指导重加权：识别相关的X和Z检测事件，并使用它们的条件概率更新权重。该过程迭代进行，以在硬件无关但噪声感知的方式下处理实际的错误传播。

Result: IRMWPM被证明在有限时间内收敛且保持MWPM的距离保证。在电路级噪声下，IRMWPM显著提高了量子纠错性能，在特定条件下逻辑错误率降低超过20倍，并将准确性阈值从1%提高到1.16%。所需的量子比特开销也大大减少。

Conclusion: IRMWPM是一种有效的量子错误解码方法，通过显式地对X和Z错误之间的相关性进行建模，并在实际噪声条件下优于标准MWPM。该方法为近期的实时解码提供了实际应用的可能性，并有望在降低量子比特开销方面带来显著的效益。

Abstract: Efficient and realistic error decoding is crucial for fault-tolerant quantum
computation (FTQC) on near-term devices. While decoding is a classical
post-processing task, its effectiveness depends on accurately modeling quantum
noise, which is hardware-dependent. In particular, correlated bit-flip ($X$)
and phase-flip ($Z$) errors often arise under circuit-level noise. We introduce
the Iterative Reweighting Minimum-Weight Perfect Matching (IRMWPM) decoder,
which systematically incorporates such correlations to enhance quantum error
correction. Our method leverages fault-detection patterns to guide reweighting:
correlated $X$ and $Z$ detection events are identified, and their conditional
probabilities update weights on the primal and dual lattices. This iterative
procedure improves handling of realistic error propagation in a
hardware-agnostic yet noise-aware manner. We prove that IRMWPM converges in
finite time while preserving the distance guarantee of MWPM. Numerical results
under circuit-level noise show substantial improvements. For distances $\geq
17$ and physical error rates $\leq 0.001$, IRMWPM reduces logical error rates
by over 20x with only a few iterations. It also raises the accuracy threshold
from 1% to 1.16%, making it practical for near-term real-time decoding.
Extrapolated estimates suggest that to reach logical error rate $10^{-16}$,
IRMWPM requires distance $d=31$, while standard MWPM needs $d=50$, implying a
major reduction in qubit overhead.

</details>


### [346] [Uncertainty Principle from Operator Asymmetry](https://arxiv.org/abs/2509.06760)
*Xingze Qiu*

Main category: quant-ph

TL;DR: 不确定性原理源于可观测量之间的代数不对称性，通过引入新的基于不对称性资源理论的不确定性关系，提出了一种量化不相容性的新方法——算符不对称性范数，该范数导出的不确定性关系在某些情况下比Robertson界更优，并解决了Wigner-Yanase偏差信息的一个长期存在的问题。该框架还可用于推导更紧致的量子速度限制，在非平衡现象研究中具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性关系主要基于代数不对称性，并且在某些情况下可能不是最优的。同时，Wigner-Yanase偏差信息的不确定性关系形式仍未得到普遍解决。

Method: 引入算符不对称性范数来量化可观测量打破对称性的能力，并在此基础上推导了新的不确定性关系，特别是针对纯态和Wigner-Yanase偏差信息。

Result: 推导出的不确定性关系在某些情况下（特别是近乎兼容的情况下）比Robertson界更优。解决了Wigner-Yanase偏差信息的不确定性关系形式问题。通过推导更紧致的量子速度限制，为研究非平衡现象提供了工具。

Conclusion: 提出的基于算符不对称性的框架为理解量子不确定性提供了新的视角，并为解决量子信息和量子动力学中的实际问题提供了强大的工具。

Abstract: The uncertainty principle is fundamentally rooted in the algebraic asymmetry
between observables. We introduce a new class of uncertainty relations grounded
in the resource theory of asymmetry, where incompatibility is quantified by an
observable's intrinsic, state-independent capacity to break the symmetry
associated with another. This ``operator asymmetry,'' formalized as the
asymmetry norm, leads to a variance-based uncertainty relation for pure states
that can be tighter than the standard Robertson bound, especially in the
near-compatible regime. Most significantly, this framework resolves a
long-standing open problem in quantum information theory: the formulation of a
universally valid, product-form uncertainty relation for the Wigner-Yanase skew
information. We demonstrate the practical power of our framework by deriving
tighter quantum speed limits for the dynamics of nearly conserved quantities,
which are crucial for understanding non-equilibrium phenomena such as
prethermalization and many-body localization. This work provides both a new
conceptual lens for understanding quantum uncertainty and a powerful toolkit
for its application.

</details>


### [347] [Multimode Photon-Photon Coupling](https://arxiv.org/abs/2509.06778)
*Shourya Viren,Rakesh Kumar Nayak,Biswanath Bhoi,Rajeev Singh*

Main category: quant-ph

TL;DR: 本研究设计并模拟了一个包含三个互补开口环形谐振器(CSRRs)的平面混合系统，在室温下研究了多光子模式的相互作用。通过分析传输谱，观察到了表明强光子-光子耦合(PPC)的 স্পষ্ট反交叉行为。研究提出了一个理论框架来量化这种模式杂化和耦合强度，并通过实验验证了结果。这项工作为理解PPC动力学和设计具有可调光子相互作用的混合平台提供了指导，有望推动平面磁子和混合光子技术的发展。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索在室温下，包含三个互补开口环形谐振器(CSRRs)的平面混合系统中的多光子模式相互作用，特别是光子-光子耦合(PPC)现象。

Method: 使用CST Microwave Studio进行全波电磁场仿真，分析了不同CSRR尺寸下传输谱（|S21|）随频率的变化，并提出了一个理论框架来解释观察到的模式杂化和耦合强度，最后通过实验进行了验证。

Result: 仿真和实验结果均显示了 स्पष्ट反交叉行为，证实了强光子-光子耦合的存在，并得到了耦合强度的量化估计。

Conclusion: 研究成功阐明了平面系统中光子-光子耦合的基本动力学，并为设计具有可调光子相互作用的混合平台提供了实际指导，为平面磁子学和混合光子学技术的未来发展奠定了基础。

Abstract: This study investigates a planar hybrid system consisting of three
complementary splitring resonators (CSRRs), designed to examine interactions
among multiple photon modes at room temperature. The system was modeled and
simulated using the full-wave electromagnetic solver CST Microwave Studio.
Analysis of the transmission spectra (|S21|) as a function of frequency for
different CSRR dimensions revealed distinct anti-crossing behavior, indicative
of strong photon-photon coupling (PPC). To explain this phenomenon, we present
theoretical framework that quantitatively captures the observed mode
hybridization and provides estimates of the coupling strength, which are
further validated experimentally. This work not only elucidates the fundamental
dynamics of PPC in planar systems but also offers practical guidance for
designing hybrid platforms with tunable photon interactions, paving the way for
future advancements in planar magnonic and hybrid photonic technologies.

</details>


### [348] [Toward Axion Signal Extraction in Semiconductor Spin Qubits Via Spectral Engineering](https://arxiv.org/abs/2509.06791)
*Xiangjun Tan,Zhanning Wang*

Main category: quant-ph

TL;DR: 利用半导体量子点自旋量子比特探测暗物质轴子和轴子类粒子。


<details>
  <summary>Details</summary>
Motivation: 环境噪声干扰高精度测量，需要设备和信号处理两方面的改进。然而，当前的研究主要集中在改进量子比特的探测能力，而忽略了环境噪声的干扰。

Method: 推导电子-轴子相互作用的有效哈密顿量，识别轴子引起的有效磁场，并确定特征轴子振荡频率。分析电荷噪声谱，开发专门的滤波和降噪协议。

Result: 提出了一种利用半导体量子点自旋量子比特作为探测平台来寻找暗物质轴子和轴子类粒子的方法，并通过推导有效哈密顿量、识别轴子诱导磁场、确定特征频率以及开发噪声抑制方案来支持该方法。

Conclusion: 该初步研究有望利用量子技术提高对各种轴子信号的筛选能力，并推动半导体量子点自旋量子比特阵列在轴子探测中的应用。

Abstract: Recent advances in quantum sensing and computational technologies indicate
the possibility of improving the precision of measurements aimed at detecting
cosmological particles and weakly interacting massive particles using various
qubit platforms. While recent progress has been made, mitigating environmental
noise remains a challenge in extracting particle parameters with high fidelity.
Addressing these challenges requires efforts on two levels. At the device
level, the qubit and its array acting as a probe, must be isolated from
electrical and magnetic noise through optimized device geometry. At the
signal-processing level, it is necessary to develop filtering methods targeting
specific noise spectra based on different qubit architectures. In this work, we
explore the possibility of using semiconductor quantum dot spin qubits as a
platform to search for quantum chromodynamics axions and, more broadly, axion
like particles (ALPs). Starting by deriving an effective Hamiltonian for
electron-axion interactions, we identify an axion-induced effective magnetic
field and determine the characteristic axion oscillation frequency. To suppress
charge noise in the devices and environmental noise, we first analyze the
charge noise spectrum and then develop a dedicated filtering and
noise-reduction protocol, paving the way for exploring feasible axion mass
ranges. Our preliminary study holds promise for enhancing the screening of
various axion signals using quantum technologies. We expect that our analysis
and filtering protocol can help advance the use of semiconductor quantum dot
spin qubit arrays in axion detection.

</details>


### [349] [A Class of Cyclic Quantum Codes](https://arxiv.org/abs/2509.06865)
*Matthew B. Hastings*

Main category: quant-ph

TL;DR: 介绍了一类新的量子循环码，其特点在于易于制备（无噪声情况下）。


<details>
  <summary>Details</summary>
Motivation: 构造量子码，侧重于代码态的制备简易性而非稳定子集。

Method: 通过制备代码态来构造量子循环码，并展示了如何将已知的某些旋转二维表面码纳入此类，同时通过计算机搜索发现了其他小型码。

Result: 展示了该类码的构造方法，并将一些已知的旋转二维表面码归入此类，还发现了一些新的小型码。讨论了这些码容错制备的可行性。

Conclusion: 提出了一种新的量子循环码构造方法，该方法在代码态制备方面具有优势。

Abstract: We introduce a class of cyclic quantum codes, basing the construction not on
the simplicity of the stabilizers, but rather on the simplicity of preparation
of a code state (at least in the absence of noise). We show how certain known
codes, such as a certain family of rotated two-dimensional toric codes, fall
into this class, and we also give certain other examples at small sizes found
by computer search. We finally discuss fault tolerant preparation of these
codes.

</details>


### [350] [Learning spatially structured open quantum dynamics with regional-attention transformers](https://arxiv.org/abs/2509.06871)
*Dounan Du,Eden Figueroa*

Main category: quant-ph

TL;DR: 该模型学习受控开放量子系统的时空动力学，提供比数值求解器快几个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 经典数值求解器在模拟和优化开放量子系统时计算成本高昂，难以满足实时网络规模模拟或反馈控制的需求。

Method: 提出了一种基于区域注意力的神经网络架构，该架构结合了物理定律的平移不变性作为归纳偏置，并支持对时间相关的全局控制参数进行条件化。

Result: 在驱动耗散单量子比特和电磁感应透明（EIT）量子存储器两个代表性系统上进行了学习演示，模型在分布内和分布外控制协议下均实现了高预测保真度，并将模拟速度提高了三个数量级。

Conclusion: 该架构为空间结构开放量子动力学建立了一个通用的代理建模框架，可用于大规模量子网络模拟、量子中继器和协议设计、实时实验优化以及跨不同光-物质平台的设备建模。

Abstract: Simulating the dynamics of open quantum systems with spatial structure and
external control is an important challenge in quantum information science.
Classical numerical solvers for such systems require integrating coupled master
and field equations, which is computationally demanding for simulation and
optimization tasks and often precluding real-time use in network-scale
simulations or feedback control. We introduce a regional attention-based neural
architecture that learns the spatiotemporal dynamics of structured open quantum
systems. The model incorporates translational invariance of physical laws as an
inductive bias to achieve scalable complexity, and supports conditioning on
time-dependent global control parameters. We demonstrate learning on two
representative systems: a driven dissipative single qubit and an
electromagnetically induced transparency (EIT) quantum memory. The model
achieves high predictive fidelity under both in-distribution and
out-of-distribution control protocols, and provides substantial acceleration up
to three orders of magnitude over numerical solvers. These results demonstrate
that the architecture establishes a general surrogate modeling framework for
spatially structured open quantum dynamics, with immediate relevance to
large-scale quantum network simulation, quantum repeater and protocol design,
real-time experimental optimization, and scalable device modeling across
diverse light-matter platforms.

</details>


### [351] [Behind the scenes of the Quantum Extreme Learning Machines](https://arxiv.org/abs/2509.06873)
*A. De Lorenzis,M. P. Casado,N. Lo Gullo,T. Lux,F. Plastina,A. Riera*

Main category: quant-ph

TL;DR: 量子极限学习机（QELM）是一种量子机器学习方法，通过特定的量子操作（降维、量子态编码、XX哈密顿演化和测量）提取特征，用于单层分类器。研究发现，QELM的准确度会随着演化时间的增加，从低准确度区域迅速过渡到高准确度区域并饱和，该饱和值与随机酉变换达到的值相当。关键的过渡时间足以让信息传播到最近邻，且不随系统规模变化，表明QELM可以被经典模拟。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习（QML）作为一项新兴技术，有潜力使量子计算在实际应用中更具竞争力。本研究旨在探讨量子极限学习机（QELM）的性能，这是一种在训练中仅限于输出层的量子版极限学习机。

Method: 所提出的QELM架构结合了主成分分析（PCA）或自动编码器（Autoencoders）进行降维，量子态编码，利用XX哈密顿量进行演化，并通过测量提取特征，最终用于单层分类器。

Result: 研究发现，QELM的准确度随着演化时间的增加，会经历一个从低准确度到高准确度的快速转变，随后准确度趋于饱和。值得注意的是，饱和准确度与使用随机酉变换（能够最大化系统复杂度和信息混淆）所达到的准确度相当。此外，所有研究案例中的关键转变时间都足以实现信息向最近邻的传播，从而支持学习过程中的特征提取，并且该时间不依赖于系统的大小（即量子比特的数量）。

Conclusion: QELM的饱和准确度与随机酉变换相当，且关键的转变时间不随系统规模变化，这意味着QELM对于广泛任务的经典模拟是高效的。这表明QELM在量子机器学习领域具有良好的应用前景和模拟优势。

Abstract: In recent years, Quantum Machine Learning (QML) has grown rapidly, emerging
as a promising approach to make quantum computing implementation competitive.
In this work, we investigate Quantum Extreme Learning Machines (QELM), a
quantum variant of Extreme Learning Machines where training is restricted to
the output layer. The proposed architecture combines dimensionality reduction
(via PCA or Autoencoders), quantum state encoding, evolution under an XX
Hamiltonian, and measurement, providing features for a single-layer classifier.
By analyzing the performance of QELMs as a function of the evolution time, we
identify a relatively sharp transition from a low-accuracy to a high-accuracy
regime, after which the accuracy saturates. Remarkably, the saturation value
matches that achieved with random unitaries, which induce maximally complex
dynamics and optimally scramble information across the system. Across all cases
studied, the critical transition time is sufficient for information to reach
nearest neighbors, enabling feature extraction for learning, and is independent
of the system size (i.e., the number of qubits). This independence implies that
QELMs can be efficiently simulated classically for a broad class of tasks.

</details>


### [352] [Benchmarking Single-Qubit Gates on a Neutral Atom Quantum Processor](https://arxiv.org/abs/2509.06881)
*Artem Rozanov,Boris Bantysh,Ivan Bobrov,Gleb Struchalin,Stanislav Straupe*

Main category: quant-ph

TL;DR: DRB and GST are used to benchmark single-qubit gates on a neutral atom quantum processor, yielding high fidelities and providing complementary error characterization.


<details>
  <summary>Details</summary>
Motivation: To benchmark single-qubit gates on a neutral atom quantum processor and characterize errors using DRB and GST.

Method: Utilized Direct Randomized Benchmarking (DRB) and Gate Set Tomography (GST) protocols to characterize single-qubit gates. DRB involves preparing stabilizer states, applying gate layers, and measuring. GST reconstructs quantum processes. Introduced a gauge optimization procedure for GST.

Result: DRB yielded an average fidelity of 99.963 ± 0.016% for single-qubit gates. GST results were consistent with DRB. Gauge optimization enabled meaningful fidelity comparisons.

Conclusion: Complementary benchmarking techniques like DRB and GST are valuable for characterizing scalable quantum architectures, with introduced gauge optimization improving GST analysis.

Abstract: We present benchmarking results for single-qubit gates implemented on a
neutral atom quantum processor using Direct Randomized Benchmarking (DRB) and
Gate Set Tomography (GST). The DRB protocol involves preparing stabilizer
states, applying $m$ layers of native single-qubit gates, and measuring in the
computational basis, providing an efficient error characterization under a
stochastic Pauli noise model. GST enables the full, self-consistent
reconstruction of quantum processes, including gates, input states, and
measurements. Both protocols provide robust to state preparation and
measurement (SPAM) errors estimations of gate performance, offering
complementary perspectives on quantum gate fidelity. For single-qubit gates,
DRB yields an average fidelity of $99.963 \pm 0.016\%$. The protocol was
further applied to a 25-qubit array under global single-qubit control. GST
results are consistent with those obtained via DRB. We also introduce a gauge
optimization procedure for GST that brings the reconstructed gates, input
states, and measurements into a canonical frame, enabling meaningful fidelity
comparisons while preserving physical constraints. These constraints of the
operators -- such as complete positivity and trace preservation -- are enforced
by performing the optimization over the Stiefel manifold. The combined analysis
supports the use of complementary benchmarking techniques for characterizing
scalable quantum architectures.

</details>


### [353] [Characterization of low-nitrogen quantum diamond for pulsed magnetometry applications](https://arxiv.org/abs/2509.06884)
*Jiashen Tang,Connor A. Roncaioli,Andrew M. Edmonds,Atli Davidsson,Connor A. Hart,Matthew L. Markham,Ronald L. Walsworth*

Main category: quant-ph

TL;DR: 本研究制备并表征了低氮（~0.8 ppm）金刚石材料，并通过实验对比了其与高氮（~14 ppm）金刚石在不同光激发强度下的磁传感性能，发现在中低光强下，低氮金刚石的磁传感性能更优。


<details>
  <summary>Details</summary>
Motivation: 氮空位（NV）中心金刚石是重要的量子传感器，其中氮浓度（[N$_{s}^{0}$]）对相干时间、灵敏度和传感策略有显著影响。特别是[N$_{s}^{0}$]~1-10 ppm的金刚石是当前材料工程的研究热点，高浓度有利于连续波光检测磁共振（CW-ODMR），而低浓度则有望通过延长NV电子自旋相干时间和提高传感占空比来优化脉冲磁力测量技术。

Method: 通过在高质量衬底上进行低应变化学气相沉积（CVD）生长、$^{12}$C同位素纯化以及控制电子辐照和退火，合成了低[N$_{s}^{0}$]（~0.8 ppm）的NV富集金刚石材料。通过测量不同NV光学激发光强下的NV自旋和电荷性质，直接对比了低[N$_{s}^{0}$]和先前研究的高[N$_{s}^{0}$]（~14 ppm）NV金刚石传感器的光子散粒噪声极限磁传感灵敏度。

Result: 研究结果表明，在CVD衬底上生长的金刚石具有良好的应变均匀性，且NV去相干时间受自旋体系限制。在不同光激发强度下，低[N$_{s}^{0}$]金刚石在适中和低光强下表现优于高[N$_{s}^{0}$]金刚石。具体来说，在低光强下，低氮金刚石的灵敏度曲线斜率更高，表明其性能更优。

Conclusion: 本研究结果为选择特定实验条件和传感需求的NV-金刚石传感器提供了实用的基准和指导。低[N$_{s}^{0}$]金刚石在特定光强条件下可以超越高[N$_{s}^{0}$]金刚石，为未来的量子传感应用提供了重要的材料选择依据。

Abstract: Ensembles of nitrogen-vacancy (NV) centers in diamond are versatile quantum
sensors with broad applications in the physical and life sciences. The
concentration of neutral substitutional nitrogen ([N$_\text{s}^0$]) strongly
influences coherence times, sensitivity, and optimal sensing strategies.
Diamonds with [N$_\text{s}^0$] $\sim\,1-10\,\text{ppm}$ are a focus of recent
material engineering efforts, with higher concentrations being favorable for
continuous-wave optically detected magnetic resonance (CW-ODMR) and lower
concentrations expected to benefit pulsed magnetometry techniques through
extended NV electronic spin coherence times and improved sensing duty cycles.
In this work, we synthesize and characterize low-[N$_\text{s}^0$]
($\sim\,0.8\,\text{ppm}$), NV-enriched diamond material, engineered through
low-strain chemical vapor deposition (CVD) growth on high-quality substrates,
$^{12}$C isotopic purification, and controlled electron irradiation and
annealing. Our results demonstrate good strain homogeneity in diamonds grown on
CVD substrates and spin-bath-limited NV dephasing times. By measuring NV spin
and charge properties across a wide range of optical NV excitation intensity,
we provide direct comparisons of photon-shot-noise-limited magnetic sensitivity
between the current low-[$\text{N}_\text{s}^0$] and previously studied
higher-[$\text{N}_\text{s}^0$] ($\sim\,14\,\text{ppm}$) NV-diamond sensors. We
show that low-[N$_\text{s}^0$] diamond can outperform higher-[N$_\text{s}^0$]
diamond at moderate and low optical NV excitation intensity. Our results
provide practical benchmarks and guidance for selecting NV-diamond sensors
tailored to specific experimental constraints and sensing requirements.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [354] [A Spatio-Temporal Graph Neural Networks Approach for Predicting Silent Data Corruption inducing Circuit-Level Faults](https://arxiv.org/abs/2509.06289)
*Shaoqi Wei,Senling Wang,Hiroshi Kai,Yoshinobu Higami,Ruijun Ma,Tianming Ni,Xiaoqing Wen,Hiroshi Takahashi*

Main category: cs.LG

TL;DR: Silent Data Errors (SDEs) 损坏安全关键系统。本文提出了一种统一的时空图卷积网络 (ST-GCN)，用于快速、准确地预测长周期故障影响概率 (FIPs)，从而支持量化风险评估。该方法在 ISCAS-89 基准测试中，将模拟时间缩短了 10 倍以上，同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: Silent Data Errors (SDEs) 正在损害安全关键系统，而传统的函数测试方法成本高昂。需要一种更有效的方法来预测和评估 SDE 相关的故障影响。

Method: 提出了一种统一的时空图卷积网络 (ST-GCN)，将门级网表建模为时空图，并使用专门的空间和时间编码器来预测多周期故障影响概率 (FIPs)。

Result: 与传统方法相比，将模拟时间缩短了 10 倍以上，同时保持了高精度（5周期预测的平均绝对误差为 0.024）。该框架还可以根据需要进行效率-准确性权衡，并可用于测试点选择和可扩展到 SoC 级测试策略优化。

Conclusion: ST-GCN 是一种快速、准确的预测长周期故障影响概率的方法，支持量化风险评估，并能改进测试点选择，可扩展到下游 EDA 流程。

Abstract: Silent Data Errors (SDEs) from time-zero defects and aging degrade
safety-critical systems. Functional testing detects SDE-related faults but is
expensive to simulate. We present a unified spatio-temporal graph convolutional
network (ST-GCN) for fast, accurate prediction of long-cycle fault impact
probabilities (FIPs) in large sequential circuits, supporting quantitative risk
assessment. Gate-level netlists are modeled as spatio-temporal graphs to
capture topology and signal timing; dedicated spatial and temporal encoders
predict multi-cycle FIPs efficiently. On ISCAS-89 benchmarks, the method
reduces simulation time by more than 10x while maintaining high accuracy (mean
absolute error 0.024 for 5-cycle predictions). The framework accepts features
from testability metrics or fault simulation, allowing efficiency-accuracy
trade-offs. A test-point selection study shows that choosing observation points
by predicted FIPs improves detection of long-cycle, hard-to-detect faults. The
approach scales to SoC-level test strategy optimization and fits downstream
electronic design automation flows.

</details>


### [355] [Benchmarking Robust Aggregation in Decentralized Gradient Marketplaces](https://arxiv.org/abs/2509.05833)
*Zeyu Song,Sainyam Galhotra,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 现有的联邦学习基准忽略了去中心化梯度市场的经济和系统因素，例如成本效益、卖家公平性和市场稳定性。本文提出了一个全面的基准框架来评估这些市场中的梯度聚合方法，并模拟了市场动态、评估了经济效率、公平性和选择动态，最后对 MartFL 进行了实证分析，并提供了关于模型性能、鲁棒性、成本、公平性和稳定性的权衡的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习基准在评估去中心化梯度市场时忽略了成本效益、卖家公平性和市场稳定性等关键经济和系统因素，尤其是在买方依赖私有基线数据集进行评估的情况下。

Method: 开发了一个模拟环境来模拟具有可变买方基线和不同卖家分布的市场动态。采用了一种评估方法，将经济效率、公平性和选择动态等市场中心维度与标准的联邦学习指标相结合。对现有的分布式梯度市场框架 MartFL 进行了实证分析，并将其与调整后的 FLTrust 和 SkyMask 进行了比较评估。

Result: 该基准涵盖了各种数据集、本地攻击和针对市场选择过程的 Sybil 攻击。通过实证分析得出了关于模型性能、鲁棒性、成本、公平性和稳定性的权衡的见解。

Conclusion: 该基准框架为评估和设计更鲁棒、更公平、更具经济可行性的去中心化梯度市场提供了重要的工具和实证证据。

Abstract: The rise of distributed and privacy-preserving machine learning has sparked
interest in decentralized gradient marketplaces, where participants trade
intermediate artifacts like gradients. However, existing Federated Learning
(FL) benchmarks overlook critical economic and systemic factors unique to such
marketplaces-cost-effectiveness, fairness to sellers, and market
stability-especially when a buyer relies on a private baseline dataset for
evaluation.
  We introduce a comprehensive benchmark framework to holistically evaluate
robust gradient aggregation methods within these buyer-baseline-reliant
marketplaces. Our contributions include: (1) a simulation environment modeling
marketplace dynamics with a variable buyer baseline and diverse seller
distributions; (2) an evaluation methodology augmenting standard FL metrics
with marketplace-centric dimensions such as Economic Efficiency, Fairness, and
Selection Dynamics; (3) an in-depth empirical analysis of the existing
Distributed Gradient Marketplace framework, MartFL, including the integration
and comparative evaluation of adapted FLTrust and SkyMask as alternative
aggregation strategies within it. This benchmark spans diverse datasets, local
attacks, and Sybil attacks targeting the marketplace selection process; and (4)
actionable insights into the trade-offs between model performance, robustness,
cost, fairness, and stability.
  This benchmark equips the community with essential tools and empirical
evidence to evaluate and design more robust, equitable, and economically viable
decentralized gradient marketplaces.

</details>


### [356] [An Improved Template for Approximate Computing](https://arxiv.org/abs/2509.06162)
*M. Rezaalipour,F. Costa,M. Biasion,R. Otoni,G. A. Constantinides,L. Pozzi*

Main category: cs.LG

TL;DR: 通过改进布尔重写技术XPAT，提出了一种新的基于参数化乘积共享的模板，以在保持可接受的准确性损失的同时减小神经网络中加法器和乘法器的面积，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署神经网络时，需要在推理能耗和分类准确性之间取得平衡。通过近似计算来降低能耗，即通过略微降低算术运算的准确性来达到目的。

Method: 提出了一种改进的布尔重写技术XPAT的方法，使用一种新的基于参数化乘积共享的模板，该模板可以作为综合面积的代理。通过实验证明，该方法比原始XPAT和其他两种最先进的方法能更好地收敛到低面积解决方案，并能找到更好的近似。

Result: 所提出的方法在保持相同的精度损失的情况下，比现有的最先进的方法在减小面积方面有更好的表现。

Conclusion: 所提出的基于参数化乘积共享的新模板方法，在减小神经网络中算术运算单元面积方面，优于现有技术，同时能在精度损失可接受的范围内实现更好的面积节省。

Abstract: Deploying neural networks on edge devices entails a careful balance between
the energy required for inference and the accuracy of the resulting
classification. One technique for navigating this tradeoff is approximate
computing: the process of reducing energy consumption by slightly reducing the
accuracy of arithmetic operators. In this context, we propose a methodology to
reduce the area of the small arithmetic operators used in neural networks -
i.e., adders and multipliers - via a small loss in accuracy, and show that we
improve area savings for the same accuracy loss w.r.t. the state of the art. To
achieve our goal, we improve on a boolean rewriting technique recently
proposed, called XPAT, where the use of a parametrisable template to rewrite
circuits has proved to be highly beneficial. In particular, XPAT was able to
produce smaller circuits than comparable approaches while utilising a naive sum
of products template structure. In this work, we show that template parameters
can act as proxies for chosen metrics and we propose a novel template based on
parametrisable product sharing that acts as a close proxy to synthesised area.
We demonstrate experimentally that our methodology converges better to low-area
solutions and that it can find better approximations than both the original
XPAT and two other state-of-the-art approaches.

</details>


### [357] [Exploring Urban Factors with Autoencoders: Relationship Between Static and Dynamic Features](https://arxiv.org/abs/2509.06167)
*Ximena Pocco,Waqar Hassan,Karelia Salinas,Vladimir Molchanov,Luis G. Nonato*

Main category: cs.LG

TL;DR: 综合与单独的数据表示在城市分析中各有优劣，综合表示能产生更结构化的模式，但单独表示在特定情况下也很有用。


<details>
  <summary>Details</summary>
Motivation: 评估综合城市数据表示是否比单独表示更能提供深入的见解，尤其是在集成可视化框架内。

Method: 开发了一个可视化辅助框架，用于分析综合的、街区级别的城市数据（包括动态和静态数据）的潜在表示，并将其与单独的数据表示进行比较。

Result: 研究表明，综合的潜在数据表示能产生更结构化的模式，而单独的表示则在特定情况下更有效。

Conclusion: 综合潜在数据表示在城市分析中比单独表示能揭示更结构化的模式，但单独表示在某些特定场景下仍然具有价值。

Abstract: Urban analytics utilizes extensive datasets with diverse urban information to
simulate, predict trends, and uncover complex patterns within cities. While
these data enables advanced analysis, it also presents challenges due to its
granularity, heterogeneity, and multimodality. To address these challenges,
visual analytics tools have been developed to support the exploration of latent
representations of fused heterogeneous and multimodal data, discretized at a
street-level of detail. However, visualization-assisted tools seldom explore
the extent to which fused data can offer deeper insights than examining each
data source independently within an integrated visualization framework. In this
work, we developed a visualization-assisted framework to analyze whether fused
latent data representations are more effective than separate representations in
uncovering patterns from dynamic and static urban data. The analysis reveals
that combined latent representations produce more structured patterns, while
separate ones are useful in particular cases.

</details>


### [358] [Distributed Deep Learning using Stochastic Gradient Staleness](https://arxiv.org/abs/2509.05679)
*Viet Hoang Pham,Hyo-Sung Ahn*

Main category: cs.LG

TL;DR: 本篇论文提出了一种分布式训练方法，结合了数据并行和全解耦并行反向传播算法，以加速深度神经网络（DNN）的训练过程。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）的训练过程面临耗时过长和需要大量训练数据的挑战，尤其是在模型越来越深的情况下。

Method: 提出了一种分布式训练方法，该方法集成了数据并行和全解耦并行反向传播算法。通过并行计算单元，提高了每轮迭代处理的训练数据量，并缓解了反向传播算法中常见的锁定问题。

Result: 该方法在理论上被证明在特定条件下可以收敛到临界点。实验结果表明，在CIFAR-10数据集上训练DNN进行分类任务时，该方法能显著提高训练效率。

Conclusion: 所提出的分布式训练方法通过结合数据并行和全解耦并行反向传播算法，能够有效加速DNN的训练，并已被证明在理论和实践中都具有良好的性能。

Abstract: Despite the notable success of deep neural networks (DNNs) in solving complex
tasks, the training process still remains considerable challenges. A primary
obstacle is the substantial time required for training, particularly as high
performing DNNs tend to become increasingly deep (characterized by a larger
number of hidden layers) and require extensive training datasets. To address
these challenges, this paper introduces a distributed training method that
integrates two prominent strategies for accelerating deep learning: data
parallelism and fully decoupled parallel backpropagation algorithm. By
utilizing multiple computational units operating in parallel, the proposed
approach enhances the amount of training data processed in each iteration while
mitigating locking issues commonly associated with the backpropagation
algorithm. These features collectively contribute to significant improvements
in training efficiency. The proposed distributed training method is rigorously
proven to converge to critical points under certain conditions. Its
effectiveness is further demonstrated through empirical evaluations, wherein an
DNN is trained to perform classification tasks on the CIFAR-10 dataset.

</details>


### [359] [Tackling Device Data Distribution Real-time Shift via Prototype-based Parameter Editing](https://arxiv.org/abs/2509.06552)
*Zheqi Lv,Wenqiao Zhang,Kairui Fu,Qi Tian,Shengyu Zhang,Jiajie Su,Jingyuan Chen,Kun Kuang,Fei Wu*

Main category: cs.LG

TL;DR: 为解决轻量级设备端模型在设备端实时数据分布偏移下泛化能力下降的问题，提出了一种名为Persona的新型个性化方法。该方法使用基于原型的、无反向传播的参数编辑框架，无需部署后重新训练即可提升模型泛化能力。Persona在云端使用神经网络适配器生成参数编辑矩阵，以适应设备端模型到当前数据分布，并将其聚类为原型模型。通过参数编辑矩阵动态优化原型，并结合跨层知识迁移，实现一致且上下文感知的多层参数更改和原型分配。实验证明Persona在视觉和推荐任务上的有效性和通用性。


<details>
  <summary>Details</summary>
Motivation: 设备端实时数据分布偏移严重影响轻量级设备端模型的泛化能力，而现有研究多依赖计算量大的微调方法，忽略了这一问题。

Method: Persona方法利用云端的神经网络适配器生成参数编辑矩阵，动态地将设备端模型适应到当前的数据分布，并聚类为原型模型。该方法无需反向传播，通过参数编辑矩阵进行原型优化，并利用跨层知识迁移确保多层参数更改和原型分配的一致性与上下文感知性。

Result: 在视觉和推荐任务的多个数据集上的广泛实验证明了Persona方法的有效性和通用性。

Conclusion: Persona方法能够有效解决设备端实时数据分布偏移问题，提升模型泛化能力，且无需进行部署后重新训练，具有广泛的适用性。

Abstract: The on-device real-time data distribution shift on devices challenges the
generalization of lightweight on-device models. This critical issue is often
overlooked in current research, which predominantly relies on data-intensive
and computationally expensive fine-tuning approaches. To tackle this, we
introduce Persona, a novel personalized method using a prototype-based,
backpropagation-free parameter editing framework to enhance model
generalization without post-deployment retraining. Persona employs a neural
adapter in the cloud to generate a parameter editing matrix based on real-time
device data. This matrix adeptly adapts on-device models to the prevailing data
distributions, efficiently clustering them into prototype models. The
prototypes are dynamically refined via the parameter editing matrix,
facilitating efficient evolution. Furthermore, the integration of cross-layer
knowledge transfer ensures consistent and context-aware multi-layer parameter
changes and prototype assignment. Extensive experiments on vision task and
recommendation task on multiple datasets confirm Persona's effectiveness and
generality.

</details>


### [360] [Smoothed Online Optimization for Target Tracking: Robust and Learning-Augmented Algorithms](https://arxiv.org/abs/2509.05930)
*Ali Zeynali,Mahsa Sahebdel,Qingsong Liu,Mohammad Hajiesmaili,Ramesh K. Sitaraman*

Main category: cs.LG

TL;DR: SOOTT是一个新的在线决策框架，用于在不确定性下跟踪动态目标，同时考虑跟踪成本、对抗性扰动成本和决策切换成本。BEST是SOOTT的鲁棒算法，CoRT是其增强学习的版本，可以在预测准确时提高性能，同时保持对错误预测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在AI集群中进行弹性或非弹性工作负载调度等现实场景中，需要平衡服务水平协议（例如LLM训练）和突发的需求（例如实时推理）。

Method: 提出了SOOTT问题框架，并给出了两种算法：BEST（鲁棒算法）和CoRT（增强学习算法）。

Result: BEST具有可证明的竞争保证。CoRT在预测准确时严格优于BEST，同时对任意预测错误保持鲁棒性。并通过工作负载调度的案例研究进行了验证。

Conclusion: SOOTT框架和BEST、CoRT算法能够有效地平衡轨迹跟踪、决策平滑性和对外部干扰的抵抗力。

Abstract: We introduce the Smoothed Online Optimization for Target Tracking (SOOTT)
problem, a new framework that integrates three key objectives in online
decision-making under uncertainty: (1) tracking cost for following a
dynamically moving target, (2) adversarial perturbation cost for withstanding
unpredictable disturbances, and (3) switching cost for penalizing abrupt
changes in decisions. This formulation captures real-world scenarios such as
elastic and inelastic workload scheduling in AI clusters, where operators must
balance long-term service-level agreements (e.g., LLM training) against sudden
demand spikes (e.g., real-time inference). We first present BEST, a robust
algorithm with provable competitive guarantees for SOOTT. To enhance practical
performance, we introduce CoRT, a learning-augmented variant that incorporates
untrusted black-box predictions (e.g., from ML models) into its decision
process. Our theoretical analysis shows that CoRT strictly improves over BEST
when predictions are accurate, while maintaining robustness under arbitrary
prediction errors. We validate our approach through a case study on workload
scheduling, demonstrating that both algorithms effectively balance trajectory
tracking, decision smoothness, and resilience to external disturbances.

</details>


### [361] [Graph Neural Networks for Resource Allocation in Interference-limited Multi-Channel Wireless Networks with QoS Constraints](https://arxiv.org/abs/2509.06395)
*Lili Chen,Changyang She,Jingge Zhu,Jamie Evans*

Main category: cs.LG

TL;DR: 该研究提出了一种名为JCPGNN-M的新型图神经网络（GNN）算法，用于解决无线通信系统中满足最小数据速率约束的挑战。与传统方法不同，JCPGNN-M基于拉格朗日乘子法进行优化，保证了服务质量（QoS）约束的满足和收敛性，并能在多通道场景下实现用户同时多通道分配。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在处理无线通信系统的数据速率约束时，常采用试错法调整超参数，缺乏理论依据且实践中难以满足服务质量（QoS）要求。本研究旨在提供一种具有理论保证且可扩展的解决方案。

Method: 研究首先将WMMSE算法扩展到包含QoS约束的多通道场景，得到eWMMSE算法，并证明了其收敛性。随后，为了提高计算效率和可扩展性，提出了一种基于GNN的JCPGNN-M算法，该算法将GNN与基于拉格朗日乘子法的对偶优化方法相结合，在保证QoS约束的同时实现收敛。

Result: 仿真结果表明，JCPGNN-M在性能上与eWMMSE相当，但在推理速度、对更大网络的泛化能力以及在信道状态信息不完美情况下的鲁棒性方面均有显著提升。

Conclusion: JCPGNN-M为未来无线网络中满足约束的资源分配问题提供了一个可扩展且具有理论基础的解决方案，克服了传统方法的局限性。

Abstract: Meeting minimum data rate constraints is a significant challenge in wireless
communication systems, particularly as network complexity grows. Traditional
deep learning approaches often address these constraints by incorporating
penalty terms into the loss function and tuning hyperparameters empirically.
However, this heuristic treatment offers no theoretical convergence guarantees
and frequently fails to satisfy QoS requirements in practical scenarios.
Building upon the structure of the WMMSE algorithm, we first extend it to a
multi-channel setting with QoS constraints, resulting in the enhanced WMMSE
(eWMMSE) algorithm, which is provably convergent to a locally optimal solution
when the problem is feasible. To further reduce computational complexity and
improve scalability, we develop a GNN-based algorithm, JCPGNN-M, capable of
supporting simultaneous multi-channel allocation per user. To overcome the
limitations of traditional deep learning methods, we propose a principled
framework that integrates GNN with a Lagrangian-based primal-dual optimization
method. By training the GNN within the Lagrangian framework, we ensure
satisfaction of QoS constraints and convergence to a stationary point.
Extensive simulations demonstrate that JCPGNN-M matches the performance of
eWMMSE while offering significant gains in inference speed, generalization to
larger networks, and robustness under imperfect channel state information. This
work presents a scalable and theoretically grounded solution for constrained
resource allocation in future wireless networks.

</details>


### [362] [Information-Theoretic Bounds and Task-Centric Learning Complexity for Real-World Dynamic Nonlinear Systems](https://arxiv.org/abs/2509.06599)
*Sri Satish Krishna Chaitanya Bulusu,Mikko Sillanpää*

Main category: cs.LG

TL;DR: 该研究提出了一个基于结构分解、方差分析和任务中心复杂性边界的理论框架，用于解决动态非线性系统中的耦合静态和动态效应带来的失真问题，并提出了行为不确定性原理，指出静态和动态失真无法同时最小化。


<details>
  <summary>Details</summary>
Motivation: 动态非线性系统中的耦合静态和动态效应带来了数据驱动建模的挑战，需要新的理论框架来解决。

Method: 该研究提出了一个理论框架，包括结构分解、方差分析、任务中心复杂性边界、方向性下界、行为指标、有限记忆指数以及基于功率的条件，并建立了函数方差与均方Lipschitz连续性及学习复杂性之间的联系。

Result: 研究推导了行为不确定性原理，表明静态和动态失真无法同时最小化；提出了模型无关、任务感知的复杂性指标，显示低方差分量更容易学习；解释了结构化残差学习的经验优势，如泛化能力提高、参数量减少和训练成本降低。

Conclusion: 该框架为建模复杂的动态非线性系统提供了一个可扩展、理论上可靠的方法，并对现有模型进行了改进。

Abstract: Dynamic nonlinear systems exhibit distortions arising from coupled static and
dynamic effects. Their intertwined nature poses major challenges for
data-driven modeling. This paper presents a theoretical framework grounded in
structured decomposition, variance analysis, and task-centric complexity
bounds.
  The framework employs a directional lower bound on interactions between
measurable system components, extending orthogonality in inner product spaces
to structurally asymmetric settings. This bound supports variance inequalities
for decomposed systems. Key behavioral indicators are introduced along with a
memory finiteness index. A rigorous power-based condition establishes a
measurable link between finite memory in realizable systems and the First Law
of Thermodynamics. This offers a more foundational perspective than classical
bounds based on the Second Law.
  Building on this foundation, we formulate a `Behavioral Uncertainty
Principle,' demonstrating that static and dynamic distortions cannot be
minimized simultaneously. We identify that real-world systems seem to resist
complete deterministic decomposition due to entangled static and dynamic
effects. We also present two general-purpose theorems linking function variance
to mean-squared Lipschitz continuity and learning complexity. This yields a
model-agnostic, task-aware complexity metric, showing that lower-variance
components are inherently easier to learn.
  These insights explain the empirical benefits of structured residual
learning, including improved generalization, reduced parameter count, and lower
training cost, as previously observed in power amplifier linearization
experiments. The framework is broadly applicable and offers a scalable,
theoretically grounded approach to modeling complex dynamic nonlinear systems.

</details>


### [363] [Neutron Reflectometry by Gradient Descent](https://arxiv.org/abs/2509.06924)
*Max D. ~Champneys,Andrew J. ~Parnell,Philipp Gutfreund,Maximilian W. A. Skoda,. Patrick A. Fairclough,Timothy J. ~Rogers,Stephanie L. ~Burg*

Main category: cs.LG

TL;DR: 通过自动微分技术优化中子反射率数据分析，实现高效分析并提供开源库。


<details>
  <summary>Details</summary>
Motivation: 中子反射率（NR）测量需要解决反演模型问题，现有方法效率低下，尤其是在处理大量数据或复杂多层结构时。机器学习模型虽然提出作为替代，但会丢失物理直觉。

Method: 提出一种新颖高效的方法，通过对前向反射模型进行梯度下降来优化反射率数据分析，并利用自动微分技术精确计算误差函数相对于参数的梯度。

Result: 在厚的氧化石英薄膜和有机LED多层器件的基准案例研究中，实现了先进的性能和鲁棒的联合拟合性能。

Conclusion: 通过自动微分技术，可以利用现代优化和推理技术来分析中子反射率数据，从而克服现有方法的局限性，并为其他NR数据集提供易于使用的梯度基础方法。

Abstract: Neutron reflectometry (NR) is a powerful technique to probe surfaces and
interfaces. NR is inherently an indirect measurement technique, access to the
physical quantities of interest (layer thickness, scattering length density,
roughness), necessitate the solution of an inverse modelling problem, that is
inefficient for large amounts of data or complex multiplayer structures (e.g.
lithium batteries / electrodes). Recently, surrogate machine learning models
have been proposed as an alternative to existing optimisation routines.
Although such approaches have been successful, physical intuition is lost when
replacing governing equations with fast neural networks. Instead, we propose a
novel and efficient approach; to optimise reflectivity data analysis by
performing gradient descent on the forward reflection model itself. Herein,
automatic differentiation techniques are used to evaluate exact gradients of
the error function with respect to the parameters of interest. Access to these
quantities enables users of neutron reflectometry to harness a host of powerful
modern optimisation and inference techniques that remain thus far unexploited
in the context of neutron reflectometry. This paper presents two benchmark case
studies; demonstrating state-of-the-art performance on a thick oxide quartz
film, and robust co-fitting performance in the high complexity regime of
organic LED multilayer devices. Additionally, we provide an open-source library
of differentiable reflectometry kernels in the python programming language so
that gradient based approaches can readily be applied to other NR datasets.

</details>


### [364] [Nonnegative matrix factorization and the principle of the common cause](https://arxiv.org/abs/2509.03652)
*E. Khalafyan,A. E. Allahverdyan,A. Hovhannisyan*

Main category: cs.LG

TL;DR: NMF和PCC是相关联的，PCC可以用来估计NMF的秩，NMF可以用来近似实现PCC。


<details>
  <summary>Details</summary>
Motivation: NMF和PCC是相关联的，但这种关联尚未被充分探索。

Method: 通过将灰度图像数据集映射到概率模型，探索NMF和PCC之间的关系。利用PCC来估计NMF的有效秩，并利用NMF来实现PCC。

Result: PCC提供了一种鲁棒的NMF秩估计方法，该方法能稳定地估计秩，即使在存在噪声的情况下也是如此。基于该秩估计的NMF可以产生对噪声和局部优化种子都稳定的特征（基图像），从而有效解决NMF的不可识别性问题。NMF可以近似实现PCC，并且可以用于数据去噪和聚类。

Conclusion: NMF和PCC是相关联的，探索这种关联可以带来改进的NMF算法和新的PCC实现方法。

Abstract: Nonnegative matrix factorization (NMF) is a known unsupervised data-reduction
method. The principle of the common cause (PCC) is a basic methodological
approach in probabilistic causality, which seeks an independent mixture model
for the joint probability of two dependent random variables. It turns out that
these two concepts are closely related. This relationship is explored
reciprocally for several datasets of gray-scale images, which are conveniently
mapped into probability models. On one hand, PCC provides a predictability tool
that leads to a robust estimation of the effective rank of NMF. Unlike other
estimates (e.g., those based on the Bayesian Information Criteria), our
estimate of the rank is stable against weak noise. We show that NMF implemented
around this rank produces features (basis images) that are also stable against
noise and against seeds of local optimization, thereby effectively resolving
the NMF nonidentifiability problem. On the other hand, NMF provides an
interesting possibility of implementing PCC in an approximate way, where larger
and positively correlated joint probabilities tend to be explained better via
the independent mixture model. We work out a clustering method, where data
points with the same common cause are grouped into the same cluster. We also
show how NMF can be employed for data denoising.

</details>


### [365] [Standard vs. Modular Sampling: Best Practices for Reliable LLM Unlearning](https://arxiv.org/abs/2509.05316)
*Praveen Bushipaka,Lucia Passaro,Tommaso Cucinotta*

Main category: cs.LG

TL;DR: 现有的大模型遗忘基准在处理遗忘和保留数据子集时存在简化，未能充分反映现实复杂性。本文评估了现有实践，并提出了一种名为MELU（Modular Entity-Level Unlearning）的新策略，以提高遗忘的有效性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 评估现有的大模型遗忘基准的局限性，并提出更有效的遗忘策略。

Method: 系统性地评估了单一邻居集合和标准采样方法（1:1采样、循环迭代采样）的有效性，并提出了一种名为MELU的模块化实体级遗忘策略。

Result: 现有的单一邻居集合方法效果不佳，标准采样方法会掩盖性能权衡。MELU策略结合鲁棒算法，提供了更清晰、更稳定的有效遗忘途径。

Conclusion: 为了实现有效且稳定的遗忘，应采用多样化的邻居集合，并放弃低效的1:1采样方法，转而采用MELU等模块化策略。

Abstract: A conventional LLM Unlearning setting consists of two subsets -"forget" and
"retain", with the objectives of removing the undesired knowledge from the
forget set while preserving the remaining knowledge from the retain. In
privacy-focused unlearning research, a retain set is often further divided into
neighbor sets, containing either directly or indirectly connected to the forget
targets; and augmented by a general-knowledge set. A common practice in
existing benchmarks is to employ only a single neighbor set, with general
knowledge which fails to reflect the real-world data complexities and
relationships. LLM Unlearning typically involves 1:1 sampling or cyclic
iteration sampling. However, the efficacy and stability of these de facto
standards have not been critically examined. In this study, we systematically
evaluate these common practices. Our findings reveal that relying on a single
neighbor set is suboptimal and that a standard sampling approach can obscure
performance trade-offs. Based on this analysis, we propose and validate an
initial set of best practices: (1) Incorporation of diverse neighbor sets to
balance forget efficacy and model utility, (2) Standard 1:1 sampling methods
are inefficient and yield poor results, (3) Our proposed Modular Entity-Level
Unlearning (MELU) strategy as an alternative to cyclic sampling. We demonstrate
that this modular approach, combined with robust algorithms, provides a clear
and stable path towards effective unlearning.

</details>


### [366] [Neural Breadcrumbs: Membership Inference Attacks on LLMs Through Hidden State and Attention Pattern Analysis](https://arxiv.org/abs/2509.05449)
*Disha Makhija,Manoj Ghuhan Arivazhagan,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.LG

TL;DR: 近期研究表明，针对大型语言模型（LLMs）的成员推断攻击（MIAs）仅比随机猜测略好，暗示大规模预训练可能不存在隐私泄露风险。本文提出 memTrace 框架，通过分析 LLMs 的内部表示（如 Transformer 隐藏状态和注意力模式）来寻找成员推断信号，即使输出端看起来没有泄露。该方法通过层级表示动态、注意力分布特征和跨层转换模式分析，发现了传统基于损失的方法可能忽略的潜在记忆指纹，在流行 MIA 基准测试上取得了平均 0.85 的 AUC 分数，表明内部模型行为可以揭示训练数据暴露情况，即使输出端看起来受到保护，因此需要进一步研究 LLMs 的成员隐私和开发更强大的隐私保护训练技术。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为大型语言模型（LLMs）的成员推断攻击（MIAs）效果不佳，但本文认为仅分析模型输出来评估隐私风险是不够的，需要关注模型内部表示。

Method: 提出 memTrace 框架，通过分析 Transformer 的隐藏状态和注意力模式（即“神经面包屑”）来提取成员推断信号，具体包括层级表示动态、注意力分布特征和跨层转换模式。

Result: memTrace 框架在多个模型家族和流行 MIA 基准测试上取得了平均 0.85 的 AUC 分数，表明其在成员推断方面效果显著。

Conclusion: LLMs 的内部模型行为可以揭示训练数据暴露情况，即使输出端看起来没有泄露。这强调了进一步研究 LLMs 成员隐私和开发更强大的隐私保护训练技术的必要性。

Abstract: Membership inference attacks (MIAs) reveal whether specific data was used to
train machine learning models, serving as important tools for privacy auditing
and compliance assessment. Recent studies have reported that MIAs perform only
marginally better than random guessing against large language models,
suggesting that modern pre-training approaches with massive datasets may be
free from privacy leakage risks. Our work offers a complementary perspective to
these findings by exploring how examining LLMs' internal representations,
rather than just their outputs, may provide additional insights into potential
membership inference signals. Our framework, \emph{memTrace}, follows what we
call \enquote{neural breadcrumbs} extracting informative signals from
transformer hidden states and attention patterns as they process candidate
sequences. By analyzing layer-wise representation dynamics, attention
distribution characteristics, and cross-layer transition patterns, we detect
potential memorization fingerprints that traditional loss-based approaches may
not capture. This approach yields strong membership detection across several
model families achieving average AUC scores of 0.85 on popular MIA benchmarks.
Our findings suggest that internal model behaviors can reveal aspects of
training data exposure even when output-based signals appear protected,
highlighting the need for further research into membership privacy and the
development of more robust privacy-preserving training techniques for large
language models.

</details>


### [367] [PLanTS: Periodicity-aware Latent-state Representation Learning for Multivariate Time Series](https://arxiv.org/abs/2509.05478)
*Jia Wang,Xiao Wang,Chi Zhang*

Main category: cs.LG

TL;DR: PLanTS是一个新颖的周期感知自监督学习框架，通过显式建模不规则的潜在状态及其转换，解决了多变量时间序列（MTS）的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习（SSL）方法忽略了MTS固有的周期性结构和潜在状态的动态演变，导致在处理高维度、标记数据有限和非平稳MTS时存在局限性。

Method: PLanTS框架包含以下关键组件：1. 周期感知多粒度打补丁机制：保留跨多个时间分辨率的实例级和状态级相似性。2. 广义对比损失：进一步增强表示学习。3. 下一个状态转换预测任务：通过编码未来状态演变的预测信息来捕获时间动态。

Result: PLanTS在多类别和多标签分类、预测、轨迹跟踪和异常检测等下游任务中，持续改进了表示质量，并且相比于基于DTW的方法，具有更高的运行时效率。

Conclusion: PLanTS通过引入周期感知机制和动态状态建模，有效地解决了MTS的挑战，并在各种下游任务中展现出优越的性能和效率。

Abstract: Multivariate time series (MTS) are ubiquitous in domains such as healthcare,
climate science, and industrial monitoring, but their high dimensionality,
limited labeled data, and non-stationary nature pose significant challenges for
conventional machine learning methods. While recent self-supervised learning
(SSL) approaches mitigate label scarcity by data augmentations or time
point-based contrastive strategy, they neglect the intrinsic periodic structure
of MTS and fail to capture the dynamic evolution of latent states. We propose
PLanTS, a periodicity-aware self-supervised learning framework that explicitly
models irregular latent states and their transitions. We first designed a
period-aware multi-granularity patching mechanism and a generalized contrastive
loss to preserve both instance-level and state-level similarities across
multiple temporal resolutions. To further capture temporal dynamics, we design
a next-transition prediction pretext task that encourages representations to
encode predictive information about future state evolution. We evaluate PLanTS
across a wide range of downstream tasks-including multi-class and multi-label
classification, forecasting, trajectory tracking and anomaly detection. PLanTS
consistently improves the representation quality over existing SSL methods and
demonstrates superior runtime efficiency compared to DTW-based methods.

</details>


### [368] [MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs](https://arxiv.org/abs/2509.05488)
*Hongjun Xu,Junxi Xia,Weisi Yang,Yueyuan Sui,Stephen Xia*

Main category: cs.LG

TL;DR: MambaLite-Micro 是首个在资源受限的微控制器 (MCU) 上部署的 Mamba 模型，通过 C 语言实现、优化内存和算子，显著减少内存占用并保持高精度，适用于真实世界的嵌入式应用。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的微控制器上部署 Mamba 模型面临内存、原生算子支持和嵌入式工具链的挑战。

Method: 通过导出轻量级模型权重，并用 C 语言手动实现 Mamba 层和支持算子（优化内存布局和算子融合），创建了一个名为 MambaLite-Micro 的无运行时推理引擎。

Result: MambaLite-Micro 减少了 83.0% 的峰值内存使用，相对 PyTorch Mamba 实现的平均数值误差仅为 1.7x10-5。在关键词识别 (KWS) 和人类活动识别 (HAR) 任务上，MambaLite-Micro 与 PyTorch 基线保持 100% 的一致性，完全保留了分类准确性。

Conclusion: MambaLite-Micro 成功地将 Mamba 模型部署到 ESP32S3 和 STM32H7 微控制器上，证明了其跨异构嵌入式平台的兼容性，为高级序列模型在资源受限的实际应用中带来了可能性。

Abstract: Deploying Mamba models on microcontrollers (MCUs) remains challenging due to
limited memory, the lack of native operator support, and the absence of
embedded-friendly toolchains. We present, to our knowledge, the first
deployment of a Mamba-based neural architecture on a resource-constrained MCU,
a fully C-based runtime-free inference engine: MambaLite-Micro. Our pipeline
maps a trained PyTorch Mamba model to on-device execution by (1) exporting
model weights into a lightweight format, and (2) implementing a handcrafted
Mamba layer and supporting operators in C with operator fusion and memory
layout optimization. MambaLite-Micro eliminates large intermediate tensors,
reducing 83.0% peak memory, while maintaining an average numerical error of
only 1.7x10-5 relative to the PyTorch Mamba implementation. When evaluated on
keyword spotting(KWS) and human activity recognition (HAR) tasks,
MambaLite-Micro achieved 100% consistency with the PyTorch baselines, fully
preserving classification accuracy. We further validated portability by
deploying on both ESP32S3 and STM32H7 microcontrollers, demonstrating
consistent operation across heterogeneous embedded platforms and paving the way
for bringing advanced sequence models like Mamba to real-world
resource-constrained applications.

</details>


### [369] [Causal Debiasing Medical Multimodal Representation Learning with Missing Modalities](https://arxiv.org/abs/2509.05615)
*Xiaoguang Zhu,Lianlong Sun,Yang Liu,Pengyi Jiang,Uma Srivatsa,Nipavan Chiamvimonvat,Vladimir Filkov*

Main category: cs.LG

TL;DR: 本研究提出了一种新的医学多模态表示学习框架，以解决实际医疗数据中常见的模态缺失问题，并克服由数据采集过程引起的偏差。


<details>
  <summary>Details</summary>
Motivation: 实际医疗数据集常因成本、协议或患者特定限制而出现模态缺失。现有方法主要关注可用数据，忽略了数据采集过程本身的偏差。

Method: 提出了一种包含两个关键组成部分的新型框架：1. 基于后门调整近似因果干预的缺失去偏模块。2. 明确解开因果特征与虚假关联的双分支神经网络。

Result: 在真实公共和院内数据集上进行了评估，证明了该方法的有效性和因果洞察力。

Conclusion: 所提出的框架能够有效处理医学多模态学习中的模态缺失和偏差问题，并提高了模型的可解释性。

Abstract: Medical multimodal representation learning aims to integrate heterogeneous
clinical data into unified patient representations to support predictive
modeling, which remains an essential yet challenging task in the medical data
mining community. However, real-world medical datasets often suffer from
missing modalities due to cost, protocol, or patient-specific constraints.
Existing methods primarily address this issue by learning from the available
observations in either the raw data space or feature space, but typically
neglect the underlying bias introduced by the data acquisition process itself.
In this work, we identify two types of biases that hinder model generalization:
missingness bias, which results from non-random patterns in modality
availability, and distribution bias, which arises from latent confounders that
influence both observed features and outcomes. To address these challenges, we
perform a structural causal analysis of the data-generating process and propose
a unified framework that is compatible with existing direct prediction-based
multimodal learning methods. Our method consists of two key components: (1) a
missingness deconfounding module that approximates causal intervention based on
backdoor adjustment and (2) a dual-branch neural network that explicitly
disentangles causal features from spurious correlations. We evaluated our
method in real-world public and in-hospital datasets, demonstrating its
effectiveness and causal insights.

</details>


### [370] [Outcome-based Exploration for LLM Reasoning](https://arxiv.org/abs/2509.06941)
*Yuda Song,Julia Kempe,Remi Munos*

Main category: cs.LG

TL;DR: 强化学习（RL）通过奖励最终答案的正确性来提高大型语言模型（LLM）的推理能力，但会导致生成多样性系统性下降。本文分析了这一现象，并提出了基于结果的探索方法（包括历史探索和批处理探索）来解决这个问题，实验证明这些方法在提高准确性的同时，也能缓解多样性崩溃。


<details>
  <summary>Details</summary>
Motivation: 旨在解决强化学习（RL）在提高大型语言模型（LLM）推理能力时，由于仅根据最终答案的正确性进行奖励而导致的生成多样性下降问题，这种多样性下降会影响模型在现实世界中的性能。

Method: 将RL后训练视为一个采样过程，分析了多样性下降的原因，包括已解决问题上多样性下降向未解决问题的传播（传递性）以及结果空间的易处理性（有限的可能答案）。在此基础上，提出了基于结果的探索（outcome-based exploration），包括历史探索（通过UCB风格的奖励鼓励罕见答案）和批处理探索（通过惩罚批处理内的重复来促进测试时多样性）。

Result: 在标准的竞赛数学任务上，使用Llama和Qwen模型进行实验，结果表明所提出的历史探索和批处理探索算法在提高准确性的同时，有效缓解了生成多样性的崩溃。理论方面，通过新的结果导向老虎机模型，形式化了结果导向探索的好处。

Conclusion: 本文提出了一种名为“基于结果的探索”的方法，以解决强化学习在提升大型语言模型推理能力时遇到的多样性损失问题。通过历史探索和批处理探索算法，以及理论模型，为实现既能增强推理能力又不牺牲多样性的RL方法提供了实际可行的途径，有利于模型的规模化部署。

Abstract: Reinforcement learning (RL) has emerged as a powerful method for improving
the reasoning abilities of large language models (LLMs). Outcome-based RL,
which rewards policies solely for the correctness of the final answer, yields
substantial accuracy gains but also induces a systematic loss in generation
diversity. This collapse undermines real-world performance, where diversity is
critical for test-time scaling. We analyze this phenomenon by viewing RL
post-training as a sampling process and show that, strikingly, RL can reduce
effective diversity even on the training set relative to the base model. Our
study highlights two central findings: (i) a transfer of diversity degradation,
where reduced diversity on solved problems propagates to unsolved ones, and
(ii) the tractability of the outcome space, since reasoning tasks admit only a
limited set of distinct answers. Motivated by these insights, we propose
outcome-based exploration, which assigns exploration bonuses according to final
outcomes. We introduce two complementary algorithms: historical exploration,
which encourages rarely observed answers via UCB-style bonuses, and batch
exploration, which penalizes within-batch repetition to promote test-time
diversity. Experiments on standard competition math with Llama and Qwen models
demonstrate that both methods improve accuracy while mitigating diversity
collapse. On the theoretical side, we formalize the benefit of outcome-based
exploration through a new model of outcome-based bandits. Together, these
contributions chart a practical path toward RL methods that enhance reasoning
without sacrificing the diversity essential for scalable deployment.

</details>


### [371] [OptiProxy-NAS: Optimization Proxy based End-to-End Neural Architecture Search](https://arxiv.org/abs/2509.05656)
*Bo Lyu,Yu Cui,Tuo Shi,Ke Li*

Main category: cs.LG

TL;DR: 该研究提出了一种名为OptiProxy-NAS的端到端优化框架，通过代理表示将神经架构搜索（NAS）空间重塑为连续、可微和光滑的，从而可以使用梯度优化方法进行搜索，并在多个NAS任务上验证了其优越性和效率。


<details>
  <summary>Details</summary>
Motivation: 神经架构搜索（NAS）是一个计算成本高昂且搜索空间离散、巨大且尖峰状的优化问题。现有方法如基于代理预测器和可微架构搜索，而本研究旨在通过一种新的优化代理来加速NAS。

Method: 将NAS空间重塑为连续、可微和光滑的代理表示，并应用任何可微优化方法进行梯度下降搜索。

Result: 在12个跨越计算机视觉、自然语言处理和资源受限NAS三个领域、4种搜索空间的NAS任务上，实现了优越的搜索结果和效率。在低保真度场景下的进一步实验也验证了该方法的灵活性。

Conclusion: OptiProxy-NAS通过将NAS问题转化为一个可微的连续优化问题，有效地解决了NAS的搜索效率和效果问题。

Abstract: Neural architecture search (NAS) is a hard computationally expensive
optimization problem with a discrete, vast, and spiky search space. One of the
key research efforts dedicated to this space focuses on accelerating NAS via
certain proxy evaluations of neural architectures. Different from the prevalent
predictor-based methods using surrogate models and differentiable architecture
search via supernetworks, we propose an optimization proxy to streamline the
NAS as an end-to-end optimization framework, named OptiProxy-NAS. In
particular, using a proxy representation, the NAS space is reformulated to be
continuous, differentiable, and smooth. Thereby, any differentiable
optimization method can be applied to the gradient-based search of the relaxed
architecture parameters. Our comprehensive experiments on $12$ NAS tasks of $4$
search spaces across three different domains including computer vision, natural
language processing, and resource-constrained NAS fully demonstrate the
superior search results and efficiency. Further experiments on low-fidelity
scenarios verify the flexibility.

</details>


### [372] [GraMFedDHAR: Graph Based Multimodal Differentially Private Federated HAR](https://arxiv.org/abs/2509.05671)
*Labani Halder,Tanmay Sen,Sarbani Palit*

Main category: cs.LG

TL;DR: 本文提出了一种基于图的多模态联邦学习框架GraMFedDHAR，用于解决人类活动识别（HAR）中的挑战，如数据噪声、不完整性、标签稀疏性和隐私问题。该框架通过将不同传感器数据建模为图，并使用残差图卷积神经网络（GCN）处理和融合，同时结合差分隐私保护数据。实验证明，GraMFedDHAR在非差分隐私设置下比基线模型准确率高2%，在差分隐私设置下，性能提升显著，准确率高出7%至13%。


<details>
  <summary>Details</summary>
Motivation: 传统的人类活动识别（HAR）方法在处理多模态传感器数据时面临数据噪声、不完整、标签稀疏和隐私泄露等挑战。中心化深度学习方法受限于基础设施、网络延迟和数据共享限制。联邦学习（FL）虽然解决了隐私问题，但仍需处理异构多模态数据和差分隐私（DP）的要求。

Method: 提出了一种名为GraMFedDHAR的基于图的多模态联邦学习框架。该框架将压力垫、深度摄像头和多个加速度计等不同传感器数据流建模为特定模态的图，并使用残差图卷积神经网络（GCN）进行处理。通过基于注意力的加权而非简单的拼接来融合这些图的嵌入，以实现鲁棒的活动分类。同时，利用差分隐私（DP）保护联邦聚合过程中的数据。

Result: 在非DP设置下，提出的MultiModalGCN模型在中心化和联邦学习范式下均优于基线MultiModalFFN，准确率最高可提升2%。在DP约束下，MultiModalGCN始终优于MultiModalFFN，性能差距根据隐私预算和设置的不同，在7%到13%之间。

Conclusion: 基于图的多模态学习在处理异构数据时具有鲁棒性，尤其是在差分隐私（DP）的约束下，图神经网络（GNNs）比传统方法更能抵抗DP噪声引入的性能下降。GraMFedDHAR框架证明了其在HAR任务中的有效性。

Abstract: Human Activity Recognition (HAR) using multimodal sensor data remains
challenging due to noisy or incomplete measurements, scarcity of labeled
examples, and privacy concerns. Traditional centralized deep learning
approaches are often constrained by infrastructure availability, network
latency, and data sharing restrictions. While federated learning (FL) addresses
privacy by training models locally and sharing only model parameters, it still
has to tackle issues arising from the use of heterogeneous multimodal data and
differential privacy requirements. In this article, a Graph-based Multimodal
Federated Learning framework, GraMFedDHAR, is proposed for HAR tasks. Diverse
sensor streams such as a pressure mat, depth camera, and multiple
accelerometers are modeled as modality-specific graphs, processed through
residual Graph Convolutional Neural Networks (GCNs), and fused via
attention-based weighting rather than simple concatenation. The fused
embeddings enable robust activity classification, while differential privacy
safeguards data during federated aggregation. Experimental results show that
the proposed MultiModalGCN model outperforms the baseline MultiModalFFN, with
up to 2 percent higher accuracy in non-DP settings in both centralized and
federated paradigms. More importantly, significant improvements are observed
under differential privacy constraints: MultiModalGCN consistently surpasses
MultiModalFFN, with performance gaps ranging from 7 to 13 percent depending on
the privacy budget and setting. These results highlight the robustness of
graph-based modeling in multimodal learning, where GNNs prove more resilient to
the performance degradation introduced by DP noise.

</details>


### [373] [Simulation Priors for Data-Efficient Deep Learning](https://arxiv.org/abs/2509.05732)
*Lenart Treven,Bhavya Sukhija,Jonas Rothfuss,Stelian Coros,Florian Dörfler,Andreas Krause*

Main category: cs.LG

TL;DR: SimPEL结合了第一性原理模型和贝叶斯深度学习，在低数据量情况下也能有效学习复杂动态，并在机器人控制等领域展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，人工智能系统需要高效学习，但第一性原理模型因简化假设而无法捕捉真实世界的复杂性，而深度学习需要大量数据。

Method: 提出SimPEL方法，利用低保真模拟器作为贝叶斯深度学习的先验，结合第一性原理模型和数据驱动学习，并量化认知不确定性。

Result: 在生物、农业和机器人等领域，SimPEL在学习复杂动态方面表现出优越性能，并在基于模型的强化学习中有效弥合了仿真到现实的差距，以更少的数据成功学习了高速RC赛车的漂移转向等高难度操作。

Conclusion: SimPEL在数据效率学习和复杂现实世界环境控制方面具有巨大潜力。

Abstract: How do we enable AI systems to efficiently learn in the real-world?
First-principles models are widely used to simulate natural systems, but often
fail to capture real-world complexity due to simplifying assumptions. In
contrast, deep learning approaches can estimate complex dynamics with minimal
assumptions but require large, representative datasets. We propose SimPEL, a
method that efficiently combines first-principles models with data-driven
learning by using low-fidelity simulators as priors in Bayesian deep learning.
This enables SimPEL to benefit from simulator knowledge in low-data regimes and
leverage deep learning's flexibility when more data is available, all the while
carefully quantifying epistemic uncertainty. We evaluate SimPEL on diverse
systems, including biological, agricultural, and robotic domains, showing
superior performance in learning complex dynamics. For decision-making, we
demonstrate that SimPEL bridges the sim-to-real gap in model-based
reinforcement learning. On a high-speed RC car task, SimPEL learns a highly
dynamic parking maneuver involving drifting with substantially less data than
state-of-the-art baselines. These results highlight the potential of SimPEL for
data-efficient learning and control in complex real-world environments.

</details>


### [374] [Offline vs. Online Learning in Model-based RL: Lessons for Data Collection Strategies](https://arxiv.org/abs/2509.05735)
*Jiaqi Chen,Ji Shi,Cansu Sancaktar,Jonas Frey,Georg Martius*

Main category: cs.LG

TL;DR: 在线收集的数据在模型基础的强化学习中比离线数据更能提升世界模型的性能，主要原因是离线数据容易导致测试时出现分布外状态，而在线互动可以通过自我修正来避免这种情况。通过在数据集中加入探索性数据或在固定/自适应的时间表内进行额外的在线互动，可以缓解离线数据的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 研究在线和离线数据收集策略对基于模型的强化学习中世界模型性能的影响，并找出离线数据导致性能下降的原因。

Method: 通过在31种不同的环境中进行实验，比较在线和离线数据收集策略对世界模型性能的影响，并分析离线数据导致性能下降的原因，提出通过补充在线互动和探索性数据来缓解该问题。

Result: 在线收集数据的智能体表现优于离线收集数据的智能体。离线数据导致性能下降的主要原因是测试时遇到的分布外状态。通过补充在线互动或探索性数据，可以恢复离线智能体的性能。

Conclusion: 在线数据收集对于训练稳健的世界模型至关重要。在收集用于离线训练的数据集时，加入探索性数据比仅收集专家数据更能有效缓解因分布外状态引起的问题。

Abstract: Data collection is crucial for learning robust world models in model-based
reinforcement learning. The most prevalent strategies are to actively collect
trajectories by interacting with the environment during online training or
training on offline datasets. At first glance, the nature of learning
task-agnostic environment dynamics makes world models a good candidate for
effective offline training. However, the effects of online vs. offline data on
world models and thus on the resulting task performance have not been
thoroughly studied in the literature. In this work, we investigate both
paradigms in model-based settings, conducting experiments on 31 different
environments. First, we showcase that online agents outperform their offline
counterparts. We identify a key challenge behind performance degradation of
offline agents: encountering Out-Of-Distribution states at test time. This
issue arises because, without the self-correction mechanism in online agents,
offline datasets with limited state space coverage induce a mismatch between
the agent's imagination and real rollouts, compromising policy training. We
demonstrate that this issue can be mitigated by allowing for additional online
interactions in a fixed or adaptive schedule, restoring the performance of
online training with limited interaction data. We also showcase that
incorporating exploration data helps mitigate the performance degradation of
offline agents. Based on our insights, we recommend adding exploration data
when collecting large datasets, as current efforts predominantly focus on
expert data alone.

</details>


### [375] [Real-E: A Foundation Benchmark for Advancing Robust and Generalizable Electricity Forecasting](https://arxiv.org/abs/2509.05768)
*Chen Shao,Yue Wang,Zhenyi Zhu,Zhanbo Huang,Sebastian Pütz,Benjamin Schäfer,Tobais Käfer,Michael Färber*

Main category: cs.LG

TL;DR: 现有的能源预测方法在空间、时间和多能源特征方面存在局限性，Real-E 数据集通过引入更广泛的数据和新的评估指标来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在能源预测领域虽然取得了进展，但其空间和时间范围有限，且缺乏多能源特征，这引发了对其在实际部署中可靠性和适用性的担忧。

Method: 本研究提出了 Real-E 数据集，该数据集覆盖了 30 多个欧洲国家的 74 个发电站，时间跨度为 10 年，并包含丰富的元数据。研究人员利用此数据集对 20 多个基线模型进行了广泛的数据分析和基准测试，并引入了一个新的指标来量化相关性结构的变化。

Result: 研究结果表明，现有方法在 Real-E 数据集上面临挑战，该数据集表现出更复杂和非平稳的相关性动态。这凸显了当前方法的关键局限性。

Conclusion: 本研究为构建更强大的预测模型提供了坚实的实证基础，强调了现有能源预测方法在面对复杂多变的现实世界数据时存在的不足。

Abstract: Energy forecasting is vital for grid reliability and operational efficiency.
Although recent advances in time series forecasting have led to progress,
existing benchmarks remain limited in spatial and temporal scope and lack
multi-energy features. This raises concerns about their reliability and
applicability in real-world deployment. To address this, we present the Real-E
dataset, covering over 74 power stations across 30+ European countries over a
10-year span with rich metadata. Using Real- E, we conduct an extensive data
analysis and benchmark over 20 baselines across various model types. We
introduce a new metric to quantify shifts in correlation structures and show
that existing methods struggle on our dataset, which exhibits more complex and
non-stationary correlation dynamics. Our findings highlight key limitations of
current methods and offer a strong empirical basis for building more robust
forecasting models

</details>


### [376] [DCV-ROOD Evaluation Framework: Dual Cross-Validation for Robust Out-of-Distribution Detection](https://arxiv.org/abs/2509.05778)
*Arantxa Urrea-Castaño,Nicolás Segura-Kunsagi,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.LG

TL;DR: 提出了一种名为双交叉验证鲁棒离群检测（DCV-ROOD）的双交叉验证框架，用于评估离群检测模型，并分析了具有类别层次结构的类别数据，以获得公平的ID-OOD分区。


<details>
  <summary>Details</summary>
Motivation: 离群检测在提高人工智能系统的鲁棒性方面起着关键作用，但开发可靠的离群检测方法并对其进行严格评估仍然是一个重大挑战。

Method: 提出了一种双交叉验证框架（DCV-ROOD），该框架对分布内（ID）数据采用常规方法进行分区，对离群（OOD）数据则按类别对样本进行分组。此外，还分析了具有类别层次结构的类别数据，提出了一种考虑整个类别层次结构的数据拆分方法，以获得公平的ID-OOD分区。

Result: 所选的最新离群检测方法在DCV-ROOD框架下得到了评估，结果表明该框架能够快速收敛到真实性能。

Conclusion: 提出的DCV-ROOD框架可以为离群检测模型提供更可靠的评估，并且在处理具有类别层次结构的数据时能够获得公平的分区。

Abstract: Out-of-distribution (OOD) detection plays a key role in enhancing the
robustness of artificial intelligence systems by identifying inputs that differ
significantly from the training distribution, thereby preventing unreliable
predictions and enabling appropriate fallback mechanisms. Developing reliable
OOD detection methods is a significant challenge, and rigorous evaluation of
these techniques is essential for ensuring their effectiveness, as it allows
researchers to assess their performance under diverse conditions and to
identify potential limitations or failure modes. Cross-validation (CV) has
proven to be a highly effective tool for providing a reasonable estimate of the
performance of a learning algorithm. Although OOD scenarios exhibit particular
characteristics, an appropriate adaptation of CV can lead to a suitable
evaluation framework for this setting. This work proposes a dual CV framework
for robust evaluation of OOD detection models, aimed at improving the
reliability of their assessment. The proposed evaluation framework aims to
effectively integrate in-distribution (ID) and OOD data while accounting for
their differing characteristics. To achieve this, ID data are partitioned using
a conventional approach, whereas OOD data are divided by grouping samples based
on their classes. Furthermore, we analyze the context of data with class
hierarchy to propose a data splitting that considers the entire class hierarchy
to obtain fair ID-OOD partitions to apply the proposed evaluation framework.
This framework is called Dual Cross-Validation for Robust Out-of-Distribution
Detection (DCV-ROOD). To test the validity of the evaluation framework, we
selected a set of state-of-the-art OOD detection methods, both with and without
outlier exposure. The results show that the method achieves very fast
convergence to the true performance.

</details>


### [377] [time2time: Causal Intervention in Hidden States to Simulate Rare Events in Time Series Foundation Models](https://arxiv.org/abs/2509.05801)
*Debdeep Sanyal,Aaryan Nagpal,Dhruv Kumar,Murari Mandal,Saurabh Deshpande*

Main category: cs.LG

TL;DR: Transformer 模型可以通过激活移植来理解和模拟市场崩盘等罕见事件。


<details>
  <summary>Details</summary>
Motivation: 研究 Transformer 模型是否能理解市场制度等语义概念，以及能否模拟市场崩盘等罕见事件。

Method: 激活移植：一种因果干预方法，通过将一个事件（如历史崩盘）的统计矩强加到另一个事件（如平稳期）上，来操纵模型的隐藏状态。

Result: 注入崩盘语义会诱导模型预测下跌，注入平稳语义会抑制崩盘并恢复稳定。模型编码了事件严重程度的梯度概念，潜在向量范数与系统性冲击的幅度直接相关。该方法在 Toto 和 Chronos 模型上均有效。

Conclusion: Transformer 模型具有可操纵的、语义上扎实的表征，这是一种在大型时间序列 Transformer 中普遍存在的特性。这表明存在一个潜在的概念空间来控制模型的预测，并将可解释性从事后归因转变为直接因果干预，从而能够进行语义“假设”分析以进行战略压力测试。

Abstract: While transformer-based foundation models excel at forecasting routine
patterns, two questions remain: do they internalize semantic concepts such as
market regimes, or merely fit curves? And can their internal representations be
leveraged to simulate rare, high-stakes events such as market crashes? To
investigate this, we introduce activation transplantation, a causal
intervention that manipulates hidden states by imposing the statistical moments
of one event (e.g., a historical crash) onto another (e.g., a calm period)
during the forward pass. This procedure deterministically steers forecasts:
injecting crash semantics induces downturn predictions, while injecting calm
semantics suppresses crashes and restores stability. Beyond binary control, we
find that models encode a graded notion of event severity, with the latent
vector norm directly correlating with the magnitude of systemic shocks.
Validated across two architecturally distinct TSFMs, Toto (decoder only) and
Chronos (encoder-decoder), our results demonstrate that steerable, semantically
grounded representations are a robust property of large time series
transformers. Our findings provide evidence for a latent concept space that
governs model predictions, shifting interpretability from post-hoc attribution
to direct causal intervention, and enabling semantic "what-if" analysis for
strategic stress-testing.

</details>


### [378] [Learning to Construct Knowledge through Sparse Reference Selection with Reinforcement Learning](https://arxiv.org/abs/2509.05874)
*Shao-An Yin*

Main category: cs.LG

TL;DR: 深度强化学习框架用于稀疏参考文献选择，通过模仿人类知识构建来优化阅读优先级，并在药物-基因关系发现任务中验证了从部分信息中有效构建知识的可行性。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长使得获取新知识变得困难，尤其是在需要复杂推理、全文访问受限和候选文献库庞大的专业领域。

Method: 提出一个深度强化学习框架，模拟人类知识构建过程，以确定在有限时间和成本下应优先阅读的论文。

Result: 在药物-基因关系发现任务中，仅使用标题和摘要进行评估，证明了该方法能有效从部分信息中构建知识。

Conclusion: 人类和机器都能有效地从部分信息中构建知识。

Abstract: The rapid expansion of scientific literature makes it increasingly difficult
to acquire new knowledge, particularly in specialized domains where reasoning
is complex, full-text access is restricted, and target references are sparse
among a large set of candidates. We present a Deep Reinforcement Learning
framework for sparse reference selection that emulates human knowledge
construction, prioritizing which papers to read under limited time and cost.
Evaluated on drug--gene relation discovery with access restricted to titles and
abstracts, our approach demonstrates that both humans and machines can
construct knowledge effectively from partial information.

</details>


### [379] [Unified Interaction Foundational Model (UIFM) for Predicting Complex User and System Behavior](https://arxiv.org/abs/2509.06025)
*Vignesh Ethiraj,Subhash Talluri*

Main category: cs.LG

TL;DR: UIFM通过复合标记化处理多属性事件，实现对用户行为的整体理解和预测，优于仅处理文本的传统模型。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在理解结构化交互方面存在不足，会因事件序列的文本化而丢失关键上下文。

Method: 提出统一交互基础模型（UIFM），采用复合标记化技术，将多属性事件视为单一的、语义连贯的单元，以学习用户行为的内在“语法”。

Result: UIFM能够感知完整的交互过程，而非离散的数据点，从而在准确性上有所提升。

Conclusion: UIFM的架构是实现更具适应性和智能性的预测系统的重要一步。

Abstract: A central goal of artificial intelligence is to build systems that can
understand and predict complex, evolving sequences of events. However, current
foundation models, designed for natural language, fail to grasp the holistic
nature of structured interactions found in domains like telecommunications,
e-commerce and finance. By serializing events into text, they disassemble them
into semantically fragmented parts, losing critical context. In this work, we
introduce the Unified Interaction Foundation Model (UIFM), a foundation model
engineered for genuine behavioral understanding. At its core is the principle
of composite tokenization, where each multi-attribute event is treated as a
single, semantically coherent unit. This allows UIFM to learn the underlying
"grammar" of user behavior, perceiving entire interactions rather than a
disconnected stream of data points. We demonstrate that this architecture is
not just more accurate, but represents a fundamental step towards creating more
adaptable and intelligent predictive systems.

</details>


### [380] [PolicyEvolve: Evolving Programmatic Policies by LLMs for multi-player games via Population-Based Training](https://arxiv.org/abs/2509.06053)
*Mingrui Lv,Hangzhi Liu,Zhi Luo,Hongjie Zhang,Jie Ou*

Main category: cs.LG

TL;DR: PolicyEvolve框架通过生成可解释的程序化策略来改进多人游戏中的多智能体强化学习，减少了对海量数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于神经网络的多智能体强化学习策略样本需求大、计算量大且可解释性差的问题，受到大型语言模型在单智能体任务中生成程序化策略的启发。

Method: PolicyEvolve框架包含四个模块：全局池（存储精英策略）、局部池（存储当前迭代策略）、策略规划器（核心策略生成模块，采样、生成并优化策略）和轨迹批评器（分析交互数据，识别弱点并指导优化）。策略规划器使用环境信息生成初始策略，并结合轨迹批评器的反馈进行优化，然后将优化后的策略存入局部池，若策略表现足够好则晋升至全局池。

Result: PolicyEvolve框架能够生成高性能且可解释的程序化策略，显著减少了对环境交互和计算资源的需求。

Conclusion: PolicyEvolve框架为多人游戏提供了一种新颖且高效的多智能体强化学习方法，通过生成程序化策略解决了现有方法的局限性。

Abstract: Multi-agent reinforcement learning (MARL) has achieved significant progress
in solving complex multi-player games through self-play. However, training
effective adversarial policies requires millions of experience samples and
substantial computational resources. Moreover, these policies lack
interpretability, hindering their practical deployment. Recently, researchers
have successfully leveraged Large Language Models (LLMs) to generate
programmatic policies for single-agent tasks, transforming neural network-based
policies into interpretable rule-based code with high execution efficiency.
Inspired by this, we propose PolicyEvolve, a general framework for generating
programmatic policies in multi-player games. PolicyEvolve significantly reduces
reliance on manually crafted policy code, achieving high-performance policies
with minimal environmental interactions. The framework comprises four modules:
Global Pool, Local Pool, Policy Planner, and Trajectory Critic. The Global Pool
preserves elite policies accumulated during iterative training. The Local Pool
stores temporary policies for the current iteration; only sufficiently
high-performing policies from this pool are promoted to the Global Pool. The
Policy Planner serves as the core policy generation module. It samples the top
three policies from the Global Pool, generates an initial policy for the
current iteration based on environmental information, and refines this policy
using feedback from the Trajectory Critic. Refined policies are then deposited
into the Local Pool. This iterative process continues until the policy achieves
a sufficiently high average win rate against the Global Pool, at which point it
is integrated into the Global Pool. The Trajectory Critic analyzes interaction
data from the current policy, identifies vulnerabilities, and proposes
directional improvements to guide the Policy Planner

</details>


### [381] [ARIES: Relation Assessment and Model Recommendation for Deep Time Series Forecasting](https://arxiv.org/abs/2509.06060)
*Fei Wang,Yujie Li,Zezhi Shao,Chengqing Yu,Yisong Fu,Zhulin An,Yongjun Xu,Xueqi Cheng*

Main category: cs.LG

TL;DR: 该论文提出了 ARIES 框架，用于评估时间序列属性与建模策略之间的关系，并为现实世界的时间序列推荐深度预测模型。该框架通过构建包含多种时间序列模式的合成数据集，计算时间序列属性，并对 50 多个预测模型进行广泛的基准测试，从而建立了时间序列属性与建模策略之间的明确关联。基于这些发现，ARIES 提出了首个深度预测模型推荐系统，能够提供可解释的建议。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测的基准数据集缺乏多样化的时间序列模式，阻碍了对模型性能与数据属性之间内在联系的系统评估。此外，缺乏有效的模型推荐方法导致在不同下游应用中测试不同模型架构时，耗费大量时间和成本。

Method: 1. 构建了一个包含多种不同模式的合成数据集。
2. 设计了一个全面的系统来计算时间序列的属性。
3. 对超过 50 个预测模型进行了广泛的基准测试，建立了时间序列属性与建模策略之间的关系。

Result: 实验结果表明，时间序列属性与建模策略之间存在明确的相关性。基于这些发现，提出了一种深度预测模型推荐方法，能够为真实世界的时间序列提供可解释的建议。

Conclusion: ARIES 是首个研究时间序列数据属性与建模策略之间关系的研究，同时实现了一个模型推荐系统。

Abstract: Recent advancements in deep learning models for time series forecasting have
been significant. These models often leverage fundamental time series
properties such as seasonality and non-stationarity, which may suggest an
intrinsic link between model performance and data properties. However, existing
benchmark datasets fail to offer diverse and well-defined temporal patterns,
restricting the systematic evaluation of such connections. Additionally, there
is no effective model recommendation approach, leading to high time and cost
expenditures when testing different architectures across different downstream
applications. For those reasons, we propose ARIES, a framework for assessing
relation between time series properties and modeling strategies, and for
recommending deep forcasting models for realistic time series. First, we
construct a synthetic dataset with multiple distinct patterns, and design a
comprehensive system to compute the properties of time series. Next, we conduct
an extensive benchmarking of over 50 forecasting models, and establish the
relationship between time series properties and modeling strategies. Our
experimental results reveal a clear correlation. Based on these findings, we
propose the first deep forecasting model recommender, capable of providing
interpretable suggestions for real-world time series. In summary, ARIES is the
first study to establish the relations between the properties of time series
data and modeling strategies, while also implementing a model recommendation
system. The code is available at: https://github.com/blisky-li/ARIES.

</details>


### [382] [Teaching Precommitted Agents: Model-Free Policy Evaluation and Control in Quasi-Hyperbolic Discounted MDPs](https://arxiv.org/abs/2509.06094)
*S. R. Eshwar*

Main category: cs.LG

TL;DR: 人类和动物都表现出时间不一致的偏好，但将其整合到强化学习（RL）框架中存在挑战。本研究提出了QH折现模型，并设计了首个适用于此场景的无模型算法。


<details>
  <summary>Details</summary>
Motivation: 时间不一致的偏好是人类和动物决策的关键特征，但将准双曲（QH）折现模型整合到强化学习（RL）框架中存在局限性。

Method: 本研究形式化地表征了最优策略的结构，并设计了用于策略评估和Q学习的无模型算法，均具有可证明的收敛性保证。

Result: 最优策略被证明可以简化为一种简单的、非稳态的单步形式。研究还设计了首个QH偏好设置下的无模型策略评估和Q学习算法。

Conclusion: 这项工作为在RL中纳入QH偏好提供了基础性的见解。

Abstract: Time-inconsistent preferences, where agents favor smaller-sooner over
larger-later rewards, are a key feature of human and animal decision-making.
Quasi-Hyperbolic (QH) discounting provides a simple yet powerful model for this
behavior, but its integration into the reinforcement learning (RL) framework
has been limited. This paper addresses key theoretical and algorithmic gaps for
precommitted agents with QH preferences. We make two primary contributions: (i)
we formally characterize the structure of the optimal policy, proving for the
first time that it reduces to a simple one-step non-stationary form; and (ii)
we design the first practical, model-free algorithms for both policy evaluation
and Q-learning in this setting, both with provable convergence guarantees. Our
results provide foundational insights for incorporating QH preferences in RL.

</details>


### [383] [Tracking daily paths in home contexts with RSSI fingerprinting based on UWB through deep learning models](https://arxiv.org/abs/2509.06161)
*Aurora Polo-Rodríguez,Juan Carlos Valera,Jesús Peral,David Gil,Javier Medina-Quero*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The field of human activity recognition has evolved significantly, driven
largely by advancements in Internet of Things (IoT) device technology,
particularly in personal devices. This study investigates the use of
ultra-wideband (UWB) technology for tracking inhabitant paths in home
environments using deep learning models. UWB technology estimates user
locations via time-of-flight and time-difference-of-arrival methods, which are
significantly affected by the presence of walls and obstacles in real
environments, reducing their precision. To address these challenges, we propose
a fingerprinting-based approach utilizing received signal strength indicator
(RSSI) data collected from inhabitants in two flats (60 m2 and 100 m2) while
performing daily activities. We compare the performance of convolutional neural
network (CNN), long short-term memory (LSTM), and hybrid CNN+LSTM models, as
well as the use of Bluetooth technology. Additionally, we evaluate the impact
of the type and duration of the temporal window (future, past, or a combination
of both). Our results demonstrate a mean absolute error close to 50 cm,
highlighting the superiority of the hybrid model in providing accurate location
estimates, thus facilitating its application in daily human activity
recognition in residential settings.

</details>


### [384] [Reasoning Language Model for Personalized Lung Cancer Screening](https://arxiv.org/abs/2509.06169)
*Chuang Niu,Ge Wang*

Main category: cs.LG

TL;DR: Lung-RADS在肺癌筛查中存在局限性，提出了一种结合影像学发现和纵向病历记录的推理语言模型（RLM），以提高肺癌风险评估的个体化和准确性。


<details>
  <summary>Details</summary>
Motivation: Lung-RADS 仅基于肺部结节特征进行风险分层，未能整合多种风险因素，导致在敏感性和特异性之间存在权衡。

Method: 提出并构建了一个推理语言模型（RLM），通过有监督微调和强化学习，整合放射学发现和纵向病历记录，进行个体化肺癌风险评估。该模型能分解风险评估任务、分析不同风险因素的贡献，并最终合成风险评分。

Result: RLM在国家肺癌筛查试验数据集上显著提高了风险预测性能，并且其链式思考的推理过程提高了预测准确性和可监测性。

Conclusion: RLM通过整合多源信息和提供可解释的推理过程，在肺癌筛查中展现出优势，有利于临床转化。

Abstract: Accurate risk assessment in lung cancer screening is critical for enabling
early cancer detection and minimizing unnecessary invasive procedures. The Lung
CT Screening Reporting and Data System (Lung-RADS) has been widely used as the
standard framework for patient management and follow-up. Nevertheless,
Lung-RADS faces trade-offs between sensitivity and specificity, as it
stratifies risk solely based on lung nodule characteristics without
incorporating various risk factors. Here we propose a reasoning language model
(RLM) to integrate radiology findings with longitudinal medical records for
individualized lung cancer risk assessment. Through a systematic study
including dataset construction and distillation, supervised fine-tuning,
reinforcement learning, and comprehensive evaluation, our model makes
significant improvements in risk prediction performance on datasets in the
national lung screening trial. Notably, RLM can decompose the risk evaluation
task into sub-components, analyze the contributions of diverse risk factors,
and synthesize them into a final risk score computed using our data-driven
system equation. Our approach improves both predictive accuracy and
monitorability through the chain of thought reasoning process, thereby
facilitating clinical translation into lung cancer screening.

</details>


### [385] [Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning](https://arxiv.org/abs/2509.06213)
*Christo Mathew,Wentian Wang,Lazaros Gallos,Paul Kantor,Vladimir Menkov,Hao Wang*

Main category: cs.LG

TL;DR: 该研究在GOHR环境中探索了强化学习，比较了特征中心（FC）和对象中心（OC）两种状态表示策略，并使用基于Transformer的A2C算法进行训练。代理在部分观测下需要同时推断规则和学习策略，研究评估了不同设置下的迁移效果和表示对学习效率的影响。


<details>
  <summary>Details</summary>
Motivation: 在GOHR环境中研究强化学习，以解决代理在部分观测下需要同时推断规则和学习策略的复杂问题。

Method: 探索了特征中心（FC）和对象中心（OC）两种状态表示策略，并采用基于Transformer的A2C算法进行训练。

Result: 在多种基于规则和基于试错的实验设置下，评估了所提出的模型，分析了迁移效果和表示对学习效率的影响。

Conclusion: 通过在GOHR环境中比较FC和OC状态表示以及基于Transformer的A2C算法，为部分观测下的强化学习提供了见解，并分析了迁移效果和表示对学习效率的影响。

Abstract: We investigate reinforcement learning in the Game Of Hidden Rules (GOHR)
environment, a complex puzzle in which an agent must infer and execute hidden
rules to clear a 6$\times$6 board by placing game pieces into buckets. We
explore two state representation strategies, namely Feature-Centric (FC) and
Object-Centric (OC), and employ a Transformer-based Advantage Actor-Critic
(A2C) algorithm for training. The agent has access only to partial observations
and must simultaneously infer the governing rule and learn the optimal policy
through experience. We evaluate our models across multiple rule-based and
trial-list-based experimental setups, analyzing transfer effects and the impact
of representation on learning efficiency.

</details>


### [386] [UrbanMIMOMap: A Ray-Traced MIMO CSI Dataset with Precoding-Aware Maps and Benchmarks](https://arxiv.org/abs/2509.06270)
*Honggang Jia,Xiucheng Wang,Nan Cheng,Ruijin Sun,Changle Li*

Main category: cs.LG

TL;DR: 该论文提出了UrbanMIMOMap数据集，一个用于6G通信的大规模城市MIMOCSI数据集，以解决现有数据集在MIMOCSI信息方面的不足，并展示了其在机器学习驱动的无线电地图构建中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于电磁仿真生成高精度无线电地图（RM）计算密集，而现有数据集在MIMOCSI信息方面存在不足，因此需要新的数据集来支持机器学习驱动的RM构建。

Method: 使用高精度射线追踪技术生成大规模城市MIMOCSI数据集UrbanMIMOMap，其中包含密集空间网格的复杂CSI矩阵。

Result: UrbanMIMOMap数据集被创建，该数据集提供了比传统路径损耗数据更全面的复杂CSI矩阵，适用于MIMOSISIMO系统。论文还展示了该数据集在代表性机器学习方法RM构建中的基线性能评估。

Conclusion: UrbanMIMOMap数据集为高精度RM生成、MIMOSISIMO空间性能以及机器学习在6G环境感知中的研究提供了关键资源和参考。

Abstract: Sixth generation (6G) systems require environment-aware communication, driven
by native artificial intelligence (AI) and integrated sensing and communication
(ISAC). Radio maps (RMs), providing spatially continuous channel information,
are key enablers. However, generating high-fidelity RM ground truth via
electromagnetic (EM) simulations is computationally intensive, motivating
machine learning (ML)-based RM construction. The effectiveness of these
data-driven methods depends on large-scale, high-quality training data. Current
public datasets often focus on single-input single-output (SISO) and limited
information, such as path loss, which is insufficient for advanced multi-input
multi-output (MIMO) systems requiring detailed channel state information (CSI).
To address this gap, this paper presents UrbanMIMOMap, a novel large-scale
urban MIMO CSI dataset generated using high-precision ray tracing. UrbanMIMOMap
offers comprehensive complex CSI matrices across a dense spatial grid, going
beyond traditional path loss data. This rich CSI is vital for constructing
high-fidelity RMs and serves as a fundamental resource for data-driven RM
generation, including deep learning. We demonstrate the dataset's utility
through baseline performance evaluations of representative ML methods for RM
construction. This work provides a crucial dataset and reference for research
in high-precision RM generation, MIMO spatial performance, and ML for 6G
environment awareness. The code and data for this work are available at:
https://github.com/UNIC-Lab/UrbanMIMOMap.

</details>


### [387] [A Fragile Number Sense: Probing the Elemental Limits of Numerical Reasoning in LLMs](https://arxiv.org/abs/2509.06332)
*Roussel Rahman,Aashwin Ananda Mishra*

Main category: cs.LG

TL;DR: 大型语言模型（LLMs）在数学问题解决方面表现出不均衡的能力，它们在基于算法的问题上表现出色，但在需要启发式搜索和组合推理的问题（如24点游戏）上则表现不佳，表明它们更擅长模式匹配而非生成性问题解决。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在数字推理方面的鲁棒性，特别是它们在解决从基础运算到组合谜题等不同复杂度数学问题时的能力，并找出其推理能力的局限性。

Method: 在一项包含100个问题的挑战中，评估了几种先进的基于LLM的智能体在四个类别上的表现：基本算术、高级运算、素数检查以及24点游戏。

Result: 在基本算术、高级运算和素数检查这三个类别中，智能体展现了高准确性，因为这些类别需要确定性的算法执行。然而，在需要启发式搜索和处理庞大组合空间的24点游戏中，智能体则持续失败，这暴露了其在这一类问题上的显著瓶颈。

Conclusion: 大型语言模型在数字推理方面的能力主要限于回忆和执行已知算法，而非进行生成性的问题解决。它们所展现出的数字推理能力更像是复杂的模式匹配，而非灵活的分析性思维，这限制了它们在需要新颖或创造性数字见解的任务中的潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable emergent
capabilities, yet the robustness of their numerical reasoning remains an open
question. While standard benchmarks evaluate LLM reasoning on complex problem
sets using aggregated metrics, they often obscure foundational weaknesses. In
this work, we probe LLM mathematical numeracy by evaluating performance on
problems of escalating complexity, from constituent operations to combinatorial
puzzles. We test several state-of-the-art LLM-based agents on a 100-problem
challenge comprising four categories: (1) basic arithmetic, (2) advanced
operations, (3) primality checking, and (4) the Game of 24 number puzzle. Our
results show that while the agents achieved high accuracy on the first three
categories, which require deterministic algorithmic execution, they
consistently failed at the number puzzle, underlining its demand for a
heuristic search over a large combinatorial space to be a significant
bottleneck. These findings reveal that the agents' proficiency is largely
confined to recalling and executing known algorithms, rather than performing
generative problem-solving. This suggests their apparent numerical reasoning is
more akin to sophisticated pattern-matching than flexible, analytical thought,
limiting their potential for tasks that require novel or creative numerical
insights.

</details>


### [388] [Ban&Pick: Achieving Free Performance Gains and Inference Speedup via Smarter Routing in MoE-LLMs](https://arxiv.org/abs/2509.06346)
*Yuanteng Chen,Peisong Wang,Yuantian Shao,Jian Cheng*

Main category: cs.LG

TL;DR: 稀疏混合专家（MoE）模型通过引入大量专家并为每个 token 激活多个专家来实现更强的专业化。然而，在预训练期间，路由器（router）为了稳定性和鲁棒性而过早收敛并强制平衡使用，限制了模型的潜力和效率。本文提出了 Ban&Pick 策略，旨在解决这些问题。Ban&Pick 是一种在训练后使用的即插即用策略，用于优化 MoE 路由。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏 MoE 模型在预训练期间，路由器为了追求稳定性和鲁棒性，会过早收敛并强制进行均衡使用，这导致了少数极具影响力的专家被低估，并且强制固定数量的激活专家引入了冗余，从而限制了模型的性能和效率。

Method: Ban&Pick 策略包含两个主要部分：'Pick' 用于发现并强化那些对性能有巨大影响的关键专家，从而提高准确性；'Ban' 则通过动态剪枝冗余专家来减少计算量，从而实现推理加速。该策略在训练后应用，无需重新训练模型或修改 MoE 架构。

Result: 在 DeepSeek 和 Qwen3 等细粒度 MoE-LLMs 模型上，Ban&Pick 在数学、代码和通用推理基准测试中均取得了显著的准确性提升。例如，在 Qwen3-30B-A3B 模型上，AIME2024 的准确率从 80.67% 提高到 84.66%，GPQA-Diamond 的准确率从 65.66% 提高到 68.18%。同时，在 vLLM 框架下，推理速度提升了 1.25 倍。

Conclusion: Ban&Pick 是一种有效的、无需重新训练或修改架构的即插即用策略，可以在不损失准确性的情况下，显著提升细粒度 MoE-LLMs 的性能和推理效率。

Abstract: Sparse Mixture-of-Experts (MoE) has become a key architecture for scaling
large language models (LLMs) efficiently. Recent fine-grained MoE designs
introduce hundreds of experts per layer, with multiple experts activated per
token, enabling stronger specialization. However, during pre-training, routers
are optimized mainly for stability and robustness: they converge prematurely
and enforce balanced usage, limiting the full potential of model performance
and efficiency. In this work, we uncover two overlooked issues: (i) a few
highly influential experts are underutilized due to premature and balanced
routing decisions; and (ii) enforcing a fixed number of active experts per
token introduces substantial redundancy. Instead of retraining models or
redesigning MoE architectures, we introduce Ban&Pick, a post-training,
plug-and-play strategy for smarter MoE routing. Pick discovers and reinforces
key experts-a small group with outsized impact on performance-leading to
notable accuracy gains across domains. Ban complements this by dynamically
pruning redundant experts based on layer and token sensitivity, delivering
faster inference with minimal accuracy loss. Experiments on fine-grained
MoE-LLMs (DeepSeek, Qwen3) across math, code, and general reasoning benchmarks
demonstrate that Ban&Pick delivers free performance gains and inference
acceleration without retraining or architectural changes. For instance, on
Qwen3-30B-A3B, it improves accuracy from 80.67 to 84.66 on AIME2024 and from
65.66 to 68.18 on GPQA-Diamond, while accelerating inference by 1.25x under the
vLLM.

</details>


### [389] [Beyond the Pre-Service Horizon: Infusing In-Service Behavior for Improved Financial Risk Forecasting](https://arxiv.org/abs/2509.06385)
*Senhao Liu,Zhiyu Guo,Zhiyuan Ji,Yueguo Chen,Yateng Tang,Yunhai Wang,Xuehao Zheng,Xiang Ao*

Main category: cs.LG

TL;DR: 该论文提出了一种名为多粒度知识蒸馏（MGKD）的新框架，通过整合在役用户行为数据来改进预役风险预测。


<details>
  <summary>Details</summary>
Motivation: 传统的金融风险管理将预役风险评估和在役违约检测分开处理，而本文旨在通过融合在役用户行为数据来增强预役风险预测能力。

Method: MGKD框架采用知识蒸馏的思想，让在役数据训练的教师模型指导预役数据训练的学生模型。具体而言，利用在役数据的软标签来指导学生模型进行风险预测，并通过粗粒度、细粒度和自蒸馏的多粒度策略来对齐师生模型的表征和预测，同时采用重加权策略来缓解少数类偏差。

Result: 在腾讯移动支付的大规模真实数据集上进行了实验，结果表明该方法在离线和在线场景中均有效。

Conclusion: MGKD框架能够有效提升预役风险评估的性能，通过知识蒸馏将违约用户的关键行为模式迁移给学生模型，从而提高风险预测的准确性。

Abstract: Typical financial risk management involves distinct phases for pre-service
risk assessment and in-service default detection, often modeled separately.
This paper proposes a novel framework, Multi-Granularity Knowledge Distillation
(abbreviated as MGKD), aimed at improving pre-service risk prediction through
the integration of in-service user behavior data. MGKD follows the idea of
knowledge distillation, where the teacher model, trained on historical
in-service data, guides the student model, which is trained on pre-service
data. By using soft labels derived from in-service data, the teacher model
helps the student model improve its risk prediction prior to service
activation. Meanwhile, a multi-granularity distillation strategy is introduced,
including coarse-grained, fine-grained, and self-distillation, to align the
representations and predictions of the teacher and student models. This
approach not only reinforces the representation of default cases but also
enables the transfer of key behavioral patterns associated with defaulters from
the teacher to the student model, thereby improving the overall performance of
pre-service risk assessment. Moreover, we adopt a re-weighting strategy to
mitigate the model's bias towards the minority class. Experimental results on
large-scale real-world datasets from Tencent Mobile Payment demonstrate the
effectiveness of our proposed approach in both offline and online scenarios.

</details>


### [390] [CAPMix: Robust Time Series Anomaly Detection Based on Abnormal Assumptions with Dual-Space Mixup](https://arxiv.org/abs/2509.06419)
*Xudong Mou,Rui Wang,Tiejun Wang,Renyu Yang,Shiru Chen,Jie Sun,Tianyu Wo,Xudong Liu*

Main category: cs.LG

TL;DR: CAPMix通过CutAddPaste机制和标签修正策略来增强时间序列异常检测，解决了现有方法的生成不全和异常偏移问题，并在多项基准测试中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法在处理罕见标签和复杂时间依赖性时面临挑战，尤其是在异常样本稀缺的情况下。基于异常假设（AA）的方法虽然通过注入合成样本和训练判别模型有所缓解，但常因生成不全（patchy generation）和异常偏移（anomaly shift）而效果受限。

Method: 提出CAPMix框架，包含：1. CutAddPaste机制，用于有针对性地注入多样化和复杂的异常，避免生成不全。2. 标签修正策略，自适应地优化异常标签，减少异常偏移。3. 在时间卷积网络中采用偶极空间混合（dual-space mixup），以强化更平滑、更鲁棒的决策边界。

Result: 在AIOps、UCR、SWaT、WADI和ESA五个基准数据集上的广泛实验表明，CAPMix相比于最先进的方法取得了显著的性能提升，并且对污染的训练数据具有更强的鲁棒性。

Conclusion: CAPMix通过创新的数据增强方法有效解决了时间序列异常检测中的关键挑战，并在多个数据集上验证了其优越性和鲁棒性。

Abstract: Time series anomaly detection (TSAD) is a vital yet challenging task,
particularly in scenarios where labeled anomalies are scarce and temporal
dependencies are complex. Recent anomaly assumption (AA) approaches alleviate
the lack of anomalies by injecting synthetic samples and training
discriminative models. Despite promising results, these methods often suffer
from two fundamental limitations: patchy generation, where scattered anomaly
knowledge leads to overly simplistic or incoherent anomaly injection, and
Anomaly Shift, where synthetic anomalies either resemble normal data too
closely or diverge unrealistically from real anomalies, thereby distorting
classification boundaries. In this paper, we propose CAPMix, a controllable
anomaly augmentation framework that addresses both issues. First, we design a
CutAddPaste mechanism to inject diverse and complex anomalies in a targeted
manner, avoiding patchy generation. Second, we introduce a label revision
strategy to adaptively refine anomaly labels, reducing the risk of anomaly
shift. Finally, we employ dual-space mixup within a temporal convolutional
network to enforce smoother and more robust decision boundaries. Extensive
experiments on five benchmark datasets, including AIOps, UCR, SWaT, WADI, and
ESA, demonstrate that CAPMix achieves significant improvements over
state-of-the-art baselines, with enhanced robustness against contaminated
training data. The code is available at https://github.com/alsike22/CAPMix.

</details>


### [391] [DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT](https://arxiv.org/abs/2509.06483)
*Guanjie Cheng,Boyi Li,Peihan Wu,Feiyi Chen,Xinkui Zhao,Mengying Zhu,Shuiguang Deng*

Main category: cs.LG

TL;DR: DyC-STG是一个新颖的框架，用于解决物联网数据可信度分析中的动态拓扑和虚假相关性问题，通过事件驱动的动态图和因果推理模块，并在两个新数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 物联网传感器生成的海量时空数据带来了数据可信度保证的挑战，而现有的时空图（STG）模型在动态、以人为中心的で环境中存在静态拓扑和混淆虚假相关性与因果关系的局限性。

Method: 提出了一种名为动态因果时空图网络（DyC-STG）的新颖框架，包含两个主要部分：1. 事件驱动的动态图模块，实时调整图拓扑以反映物理状态变化。2. 因果推理模块，通过强制时间顺序来提取因果感知表示。

Result: DyC-STG 在两个新的真实世界数据集上进行了评估，在最强的基线基础上提高了 1.4 个百分点，最高 F1 分数达到 0.930，确立了新的最先进性能。

Conclusion: DyC-STG 框架通过其事件驱动的动态图模块和因果推理模块，成功解决了物联网数据可信度分析中的关键挑战，并在实验中取得了优于现有方法的性能。

Abstract: The wide spreading of Internet of Things (IoT) sensors generates vast
spatio-temporal data streams, but ensuring data credibility is a critical yet
unsolved challenge for applications like smart homes. While spatio-temporal
graph (STG) models are a leading paradigm for such data, they often fall short
in dynamic, human-centric environments due to two fundamental limitations: (1)
their reliance on static graph topologies, which fail to capture physical,
event-driven dynamics, and (2) their tendency to confuse spurious correlations
with true causality, undermining robustness in human-centric environments. To
address these gaps, we propose the Dynamic Causal Spatio-Temporal Graph Network
(DyC-STG), a novel framework designed for real-time data credibility analysis
in IoT. Our framework features two synergistic contributions: an event-driven
dynamic graph module that adapts the graph topology in real-time to reflect
physical state changes, and a causal reasoning module to distill causally-aware
representations by strictly enforcing temporal precedence. To facilitate the
research in this domain we release two new real-world datasets. Comprehensive
experiments show that DyC-STG establishes a new state-of-the-art, outperforming
the strongest baselines by 1.4 percentage points and achieving an F1-Score of
up to 0.930.

</details>


### [392] [QualityFM: a Multimodal Physiological Signal Foundation Model with Self-Distillation for Signal Quality Challenges in Critically Ill Patients](https://arxiv.org/abs/2509.06516)
*Zongheng Guo,Tao Chen,Manuela Ferrario*

Main category: cs.LG

TL;DR: PPG和ECG信号质量差是ICU和OR中的常见问题。本文提出了一种名为QualityFM的多模态基础模型，用于理解生理信号的质量。该模型使用自蒸馏策略训练，并结合了稀疏注意力机制和复合损失函数来处理长序列信号并保留频域特征。在三个临床任务上的迁移学习实验证明了该模型的有效性。


<details>
  <summary>Details</summary>
Motivation: PPG和ECG信号质量差会导致错误的警报和诊断不准确。现有方法泛化性有限，依赖大量标记数据，并且跨任务迁移能力差。

Method: 提出了一种名为QualityFM的多模态基础模型，采用双轨架构处理不同质量的信号。利用自蒸馏策略，让高质量信号的编码器指导低质量信号编码器的训练。模型基于Transformer，集成了窗口稀疏注意力机制来处理长序列信号和局部准周期模式。使用复合损失函数，结合了编码器输出的直接蒸馏损失和基于功率谱和相位谱的间接重建损失，以保留信号的频域特征。

Result: 预训练了三种不同参数量的模型（9.6M到319M），并通过迁移学习在三个临床任务（室性心动过速虚警检测、房颤识别、PPG和ECG信号动脉血压估计）上验证了模型的有效性和实用价值。

Conclusion: QualityFM模型能够有效地学习生理信号的质量表示，并通过迁移学习在多种临床任务中表现出色，克服了现有方法的局限性。

Abstract: Photoplethysmogram (PPG) and electrocardiogram (ECG) are commonly recorded in
intesive care unit (ICU) and operating room (OR). However, the high incidence
of poor, incomplete, and inconsistent signal quality, can lead to false alarms
or diagnostic inaccuracies. The methods explored so far suffer from limited
generalizability, reliance on extensive labeled data, and poor cross-task
transferability. To overcome these challenges, we introduce QualityFM, a novel
multimodal foundation model for these physiological signals, designed to
acquire a general-purpose understanding of signal quality. Our model is
pre-trained on an large-scale dataset comprising over 21 million 30-second
waveforms and 179,757 hours of data. Our approach involves a dual-track
architecture that processes paired physiological signals of differing quality,
leveraging a self-distillation strategy where an encoder for high-quality
signals is used to guide the training of an encoder for low-quality signals. To
efficiently handle long sequential signals and capture essential local
quasi-periodic patterns, we integrate a windowed sparse attention mechanism
within our Transformer-based model. Furthermore, a composite loss function,
which combines direct distillation loss on encoder outputs with indirect
reconstruction loss based on power and phase spectra, ensures the preservation
of frequency-domain characteristics of the signals. We pre-train three models
with varying parameter counts (9.6 M to 319 M) and demonstrate their efficacy
and practical value through transfer learning on three distinct clinical tasks:
false alarm of ventricular tachycardia detection, the identification of atrial
fibrillation and the estimation of arterial blood pressure (ABP) from PPG and
ECG signals.

</details>


### [393] [Learning Optimal Defender Strategies for CAGE-2 using a POMDP Model](https://arxiv.org/abs/2509.06539)
*Duc Huy Le,Rolf Stadler*

Main category: cs.LG

TL;DR: 本文提出了一个基于粒子滤波器的PPO方法（BF-PPO），用于在CAGE-2基准测试中学习最优防御策略，并证明其优于现有最高排名方法CARDIFF。


<details>
  <summary>Details</summary>
Motivation: CAGE-2是评估网络攻击防御策略的基准，但缺乏有效的学习方法来获得最优策略。

Method: 使用部分可观察马尔可夫决策过程（POMDP）框架构建CAGE-2形式化模型，并提出一种基于PPO的粒子滤波方法（BF-PPO）来学习最优防御策略，以应对大规模状态空间带来的计算复杂性。

Result: BF-PPO方法在CAGE-2 CybORG环境中进行评估，其学习到的防御策略和所需的训练时间均优于排行榜上排名最高的CARDIFF方法。

Conclusion: BF-PPO是一种有效的CAGE-2最优防御策略学习方法，在性能和训练效率上均超越了现有SOTA方法。

Abstract: CAGE-2 is an accepted benchmark for learning and evaluating defender
strategies against cyberattacks. It reflects a scenario where a defender agent
protects an IT infrastructure against various attacks. Many defender methods
for CAGE-2 have been proposed in the literature. In this paper, we construct a
formal model for CAGE-2 using the framework of Partially Observable Markov
Decision Process (POMDP). Based on this model, we define an optimal defender
strategy for CAGE-2 and introduce a method to efficiently learn this strategy.
Our method, called BF-PPO, is based on PPO, and it uses particle filter to
mitigate the computational complexity due to the large state space of the
CAGE-2 model. We evaluate our method in the CAGE-2 CybORG environment and
compare its performance with that of CARDIFF, the highest ranked method on the
CAGE-2 leaderboard. We find that our method outperforms CARDIFF regarding the
learned defender strategy and the required training time.

</details>


### [394] [Contrastive Self-Supervised Network Intrusion Detection using Augmented Negative Pairs](https://arxiv.org/abs/2509.06550)
*Jack Wilkie,Hanan Hindy,Christos Tachtatzis,Robert Atkinson*

Main category: cs.LG

TL;DR: 本研究提出了一种名为CLAN的新型网络入侵检测方法，通过将增强样本视为负样本，而将其他良性样本视为正样本，提高了检测准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的网络入侵检测方法要么依赖大量标注数据，要么在检测良性流量时假阳性率高。自监督学习在减少假阳性率方面有所改进，但对比学习方法通常将其他样本视为负样本。

Method: 本研究提出了一种名为CLAN（Contrastive Learning using Augmented Negative pairs）的新型对比学习范式。在该范式中，增强后的样本被视为负样本（代表潜在的恶意分布），而其他良性样本则作为正样本。

Result: 在Lycos2017数据集上的实验表明，CLAN在二分类任务上优于现有的自监督和异常检测技术。在有限标注数据上进行微调后，CLAN在多分类任务上的表现也优于现有的自监督模型。

Conclusion: CLAN通过新颖的对比学习范式，有效解决了现有网络入侵检测方法的局限性，并在二分类和多分类任务上均取得了优越的性能。

Abstract: Network intrusion detection remains a critical challenge in cybersecurity.
While supervised machine learning models achieve state-of-the-art performance,
their reliance on large labelled datasets makes them impractical for many
real-world applications. Anomaly detection methods, which train exclusively on
benign traffic to identify malicious activity, suffer from high false positive
rates, limiting their usability. Recently, self-supervised learning techniques
have demonstrated improved performance with lower false positive rates by
learning discriminative latent representations of benign traffic. In
particular, contrastive self-supervised models achieve this by minimizing the
distance between similar (positive) views of benign traffic while maximizing it
between dissimilar (negative) views. Existing approaches generate positive
views through data augmentation and treat other samples as negative. In
contrast, this work introduces Contrastive Learning using Augmented Negative
pairs (CLAN), a novel paradigm for network intrusion detection where augmented
samples are treated as negative views - representing potentially malicious
distributions - while other benign samples serve as positive views. This
approach enhances both classification accuracy and inference efficiency after
pretraining on benign traffic. Experimental evaluation on the Lycos2017 dataset
demonstrates that the proposed method surpasses existing self-supervised and
anomaly detection techniques in a binary classification task. Furthermore, when
fine-tuned on a limited labelled dataset, the proposed approach achieves
superior multi-class classification performance compared to existing
self-supervised models.

</details>


### [395] [Demo: Healthcare Agent Orchestrator (HAO) for Patient Summarization in Molecular Tumor Boards](https://arxiv.org/abs/2509.06602)
*Noel Codella,Sam Preston,Hao Qiu,Leonardo Schettini,Wen-wai Yim,Mert Öz,Shrey Jain,Matthew P. Lungren,Thomas Osborne*

Main category: cs.LG

TL;DR: 使用基于LLM的AI代理（HAO）和评估框架（TBFact）来优化分子肿瘤委员会（MTB）的患者摘要生成。


<details>
  <summary>Details</summary>
Motivation: 手动生成MTB患者摘要耗时、主观且可能遗漏关键信息。

Method: 开发了一个名为HAO 的 LLM 驱动 AI 代理，以协调多代理临床工作流程来生成患者摘要。提出了一种名为 TBFact 的“模型即法官”框架，用于评估摘要的全面性和简洁性。

Result: HAO 代理捕获了 94% 的高重要性信息，并在严格的推理标准下达到了 0.84 的 TBFact 召回率。TBFact 提供了一个无需共享敏感临床数据的本地化评估框架。

Conclusion: HAO 和 TBFact 共同为 MTB 提供可靠且可扩展的支持奠定了基础。

Abstract: Molecular Tumor Boards (MTBs) are multidisciplinary forums where oncology
specialists collaboratively assess complex patient cases to determine optimal
treatment strategies. A central element of this process is the patient summary,
typically compiled by a medical oncologist, radiation oncologist, or surgeon,
or their trained medical assistant, who distills heterogeneous medical records
into a concise narrative to facilitate discussion. This manual approach is
often labor-intensive, subjective, and prone to omissions of critical
information. To address these limitations, we introduce the Healthcare Agent
Orchestrator (HAO), a Large Language Model (LLM)-driven AI agent that
coordinates a multi-agent clinical workflow to generate accurate and
comprehensive patient summaries for MTBs. Evaluating predicted patient
summaries against ground truth presents additional challenges due to stylistic
variation, ordering, synonym usage, and phrasing differences, which complicate
the measurement of both succinctness and completeness. To overcome these
evaluation hurdles, we propose TBFact, a ``model-as-a-judge'' framework
designed to assess the comprehensiveness and succinctness of generated
summaries. Using a benchmark dataset derived from de-identified tumor board
discussions, we applied TBFact to evaluate our Patient History agent. Results
show that the agent captured 94% of high-importance information (including
partial entailments) and achieved a TBFact recall of 0.84 under strict
entailment criteria. We further demonstrate that TBFact enables a data-free
evaluation framework that institutions can deploy locally without sharing
sensitive clinical data. Together, HAO and TBFact establish a robust foundation
for delivering reliable and scalable support to MTBs.

</details>


### [396] [BEAM: Brainwave Empathy Assessment Model for Early Childhood](https://arxiv.org/abs/2509.06620)
*Chen Xie,Gaofeng Wu,Kaidong Wang,Zihao Zhu,Xiaoshu Luo,Yan Liang,Feiyu Quan,Ruoxi Wu,Xianghui Huang,Han Zhang*

Main category: cs.LG

TL;DR: BEAM是一个基于多视图脑电信号的深度学习框架，用于客观预测幼儿的共情水平，该框架在CBCP数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统共情能力评估方法依赖于主观报告或观察者标记，存在偏差且无法客观捕捉共情形成过程。EEG提供客观替代方案，但现有方法忽略了时间动态性。本研究旨在克服这些局限性。

Method: 提出了一种名为BEAM的新型深度学习框架，利用多视图EEG信号捕捉共情的认知和情感维度。BEAM包含一个基于LaBraM的编码器用于时空特征提取，一个特征融合模块整合多视图信息，以及一个对比学习模块增强类别分离。

Result: 在CBCP数据集上，BEAM在多个指标上均优于最先进的方法，证明了其在客观评估幼儿共情能力方面的潜力。

Conclusion: BEAM提供了一种客观评估幼儿共情水平的方法，为早期干预儿童亲社会发展提供了初步见解。

Abstract: Empathy in young children is crucial for their social and emotional
development, yet predicting it remains challenging. Traditional methods often
only rely on self-reports or observer-based labeling, which are susceptible to
bias and fail to objectively capture the process of empathy formation. EEG
offers an objective alternative; however, current approaches primarily extract
static patterns, neglecting temporal dynamics. To overcome these limitations,
we propose a novel deep learning framework, the Brainwave Empathy Assessment
Model (BEAM), to predict empathy levels in children aged 4-6 years. BEAM
leverages multi-view EEG signals to capture both cognitive and emotional
dimensions of empathy. The framework comprises three key components: 1) a
LaBraM-based encoder for effective spatio-temporal feature extraction, 2) a
feature fusion module to integrate complementary information from multi-view
signals, and 3) a contrastive learning module to enhance class separation.
Validated on the CBCP dataset, BEAM outperforms state-of-the-art methods across
multiple metrics, demonstrating its potential for objective empathy assessment
and providing a preliminary insight into early interventions in children's
prosocial development.

</details>


### [397] [TrajAware: Graph Cross-Attention and Trajectory-Aware for Generalisable VANETs under Partial Observations](https://arxiv.org/abs/2509.06665)
*Xiaolu Fu,Ziyuan Bao,Eiman Kanjo*

Main category: cs.LG

TL;DR: TrajAware是一个用于车联网的强化学习框架，通过剪枝动作空间、图交叉注意力和轨迹感知预测来提高路由效率和泛化能力，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 车联网的路由由于动态拓扑、不完全观测和边缘设备的资源限制而面临挑战。现有的强化学习方法需要重新训练，不适合资源受限的硬件。

Method: TrajAware整合了三个组件：(i) 动作空间剪枝，减少冗余邻居选择并保持双跳可达性；(ii) 图交叉注意力，将剪枝后的邻居映射到全局图上下文，生成跨不同网络大小的通用特征；(iii) 轨迹感知预测，利用历史路线和交叉口信息估计实时位置。

Result: 在SUMO模拟器和真实城市地图上的评估显示，TrajAware在接近最短路径和高投递率的同时，保持了适合边缘设备的效率，并在完全和部分观测场景中都优于最先进的基线。

Conclusion: TrajAware在车联网路由方面表现出色，解决了现有方法的局限性，并适用于资源受限的边缘AI部署。

Abstract: Vehicular ad hoc networks (VANETs) are a crucial component of intelligent
transportation systems; however, routing remains challenging due to dynamic
topologies, incomplete observations, and the limited resources of edge devices.
Existing reinforcement learning (RL) approaches often assume fixed graph
structures and require retraining when network conditions change, making them
unsuitable for deployment on constrained hardware. We present TrajAware, an
RL-based framework designed for edge AI deployment in VANETs. TrajAware
integrates three components: (i) action space pruning, which reduces redundant
neighbour options while preserving two-hop reachability, alleviating the curse
of dimensionality; (ii) graph cross-attention, which maps pruned neighbours to
the global graph context, producing features that generalise across diverse
network sizes; and (iii) trajectory-aware prediction, which uses historical
routes and junction information to estimate real-time positions under partial
observations. We evaluate TrajAware in the open-source SUMO simulator using
real-world city maps with a leave-one-city-out setup. Results show that
TrajAware achieves near-shortest paths and high delivery ratios while
maintaining efficiency suitable for constrained edge devices, outperforming
state-of-the-art baselines in both full and partial observation scenarios.

</details>


### [398] [Barycentric Neural Networks and Length-Weighted Persistent Entropy Loss: A Green Geometric and Topological Framework for Function Approximation](https://arxiv.org/abs/2509.06694)
*Victor Toscano-Duran,Rocio Gonzalez-Diaz,Miguel A. Gutiérrez-Naranjo*

Main category: cs.LG

TL;DR: 提出了一种名为Barycentric Neural Network (BNN) 的新型小型浅层神经网络，它可以精确表示连续分段线性函数，并引入了一种新的长度加权持久熵 (LWPE) 作为损失函数，可以直接优化定义BNN的基点，在资源受限的情况下实现了优于传统损失函数的近似性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度或过度参数化神经网络计算成本高，而BNN作为一种小型浅层网络，可以精确表示连续分段线性函数，并利用LWPE损失函数，在资源受限的情况下提供灵活且可解释的非线性连续函数近似。

Method: 提出了一种名为Barycentric Neural Network (BNN) 的新型小型浅层神经网络，利用固定的基点和重心坐标来定义网络结构和参数，实现了对连续分段线性函数的精确表示。同时，引入了一种新的长度加权持久熵 (LWPE) 作为损失函数，并通过优化基点而非内部权重来训练网络。

Result: BNN能够精确表示连续分段线性函数，并且通过LWPE损失函数进行优化时，相比于MSE、RMSE、MAE和log-cosh等经典损失函数，在近似性能和收敛速度上均表现更优。

Conclusion: BNN结合LWPE损失函数提供了一种在资源受限环境下进行非线性连续函数近似的灵活且可解释的方法，并且在实验中取得了优于传统方法的性能。

Abstract: While it is well-established that artificial neural networks are
\emph{universal approximators} for continuous functions on compact domains,
many modern approaches rely on deep or overparameterized architectures that
incur high computational costs. In this paper, a new type of \emph{small
shallow} neural network, called the \emph{Barycentric Neural Network} ($\BNN$),
is proposed, which leverages a fixed set of \emph{base points} and their
\emph{barycentric coordinates} to define both its structure and its parameters.
We demonstrate that our $\BNN$ enables the exact representation of
\emph{continuous piecewise linear functions} ($\CPLF$s), ensuring strict
continuity across segments. Since any continuous function over a compact domain
can be approximated arbitrarily well by $\CPLF$s, the $\BNN$ naturally emerges
as a flexible and interpretable tool for \emph{function approximation}. Beyond
the use of this representation, the main contribution of the paper is the
introduction of a new variant of \emph{persistent entropy}, a topological
feature that is stable and scale invariant, called the \emph{length-weighted
persistent entropy} ($\LWPE$), which is weighted by the lifetime of topological
features. Our framework, which combines the $\BNN$ with a loss function based
on our $\LWPE$, aims to provide flexible and geometrically interpretable
approximations of nonlinear continuous functions in resource-constrained
settings, such as those with limited base points for $\BNN$ design and few
training epochs. Instead of optimizing internal weights, our approach directly
\emph{optimizes the base points that define the $\BNN$}. Experimental results
show that our approach achieves \emph{superior and faster approximation
performance} compared to classical loss functions such as MSE, RMSE, MAE, and
log-cosh.

</details>


### [399] [Probabilistic Modeling of Latent Agentic Substructures in Deep Neural Networks](https://arxiv.org/abs/2509.06701)
*Su Hyeong Lee,Risi Kondor,Richard Ngo*

Main category: cs.LG

TL;DR: 代理被建模为具有对数得分作为其认识效用的结果分布，并通过加权对数池化进行组合，这会严格改善每个成员的福利。研究表明，在某些条件下，严格的意见一致是不可能的，但可以通过多种结果来实现。该框架具有递归结构，并排除了平凡的复制。


<details>
  <summary>Details</summary>
Motivation: 开发一个基于概率模型的智能代理理论，用于神经模型，并为代理AI系统中的对齐问题提供新的见解。

Method: 将代理表示为结果分布，并使用对数得分作为认识效用。通过加权对数池化定义代理的组合，并证明了在不同条件下达成严格共识的可能性。此外，还通过克隆不变性、连续性和开放性来处理递归结构，并通过倾斜分析排除平凡复制。

Result: 证明了线性池化或二元结果空间中的严格共识是不可能的，但在具有三个或更多结果的情况下是可能的。通过克隆不变性、连续性和开放性实现了递归结构。倾斜分析排除了平凡复制。在LLM中，恳求“Luigi”会诱导一个对抗性的“Waluigi”，而“Waluigi”的显现然后压制的策略比单独的“Luigi”强化能更有效地减少第一阶不对齐。

Conclusion: 提出一个用于代理AI系统的数学框架，阐明了子代理如何组合成连贯的更高层实体，并为解决LLM中的对齐问题提供了新的方法，例如通过显现然后压制策略来减少不对齐。

Abstract: We develop a theory of intelligent agency grounded in probabilistic modeling
for neural models. Agents are represented as outcome distributions with
epistemic utility given by log score, and compositions are defined through
weighted logarithmic pooling that strictly improves every member's welfare. We
prove that strict unanimity is impossible under linear pooling or in binary
outcome spaces, but possible with three or more outcomes. Our framework admits
recursive structure via cloning invariance, continuity, and openness, while
tilt-based analysis rules out trivial duplication. Finally, we formalize an
agentic alignment phenomenon in LLMs using our theory: eliciting a benevolent
persona ("Luigi'") induces an antagonistic counterpart ("Waluigi"), while a
manifest-then-suppress Waluigi strategy yields strictly larger first-order
misalignment reduction than pure Luigi reinforcement alone. These results
clarify how developing a principled mathematical framework for how subagents
can coalesce into coherent higher-level entities provides novel implications
for alignment in agentic AI systems.

</details>


### [400] [Long-Range Graph Wavelet Networks](https://arxiv.org/abs/2509.06743)
*Filippo Guerranti,Fabrizio Forte,Simon Geisler,Stephan Günnemann*

Main category: cs.LG

TL;DR: LR-GWN通过分解小波滤波器为局部和全局分量来改进图神经网络，以实现长距离交互。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在模拟长距离交互方面面临挑战，现有的小波方法因有限的接收域而受阻。

Method: 提出LR-GWN，它将小波滤波器分解为局部（低阶多项式）和全局（谱域参数化）部分，以实现长距离信息传播。

Result: LR-GWN在长距离基准测试中取得了最先进的性能，同时在短距离数据集上仍具有竞争力。

Conclusion: LR-GWN通过结合局部和全局信息处理，在图神经网络中有效地实现了长距离交互，并在各种基准测试中表现出色。

Abstract: Modeling long-range interactions, the propagation of information across
distant parts of a graph, is a central challenge in graph machine learning.
Graph wavelets, inspired by multi-resolution signal processing, provide a
principled way to capture both local and global structures. However, existing
wavelet-based graph neural networks rely on finite-order polynomial
approximations, which limit their receptive fields and hinder long-range
propagation. We propose Long-Range Graph Wavelet Networks (LR-GWN), which
decompose wavelet filters into complementary local and global components. Local
aggregation is handled with efficient low-order polynomials, while long-range
interactions are captured through a flexible spectral domain parameterization.
This hybrid design unifies short- and long-distance information flow within a
principled wavelet framework. Experiments show that LR-GWN achieves
state-of-the-art performance among wavelet-based methods on long-range
benchmarks, while remaining competitive on short-range datasets.

</details>


### [401] [Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization](https://arxiv.org/abs/2509.06759)
*Thanh Thi Nguyen,Campbell Wilson,Janis Dalins*

Main category: cs.LG

TL;DR: 大型视觉-语言模型（LVLM）可以通过深度强化学习（DRL）和直接偏好优化（DPO）进行微调，以实现与人类价值观的对齐、提高任务性能和实现适应性多模态交互。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（LVLM）的微调对于与人类价值观对齐、执行特定任务或行为至关重要，而深度强化学习（DRL）和直接偏好优化（DPO）为这一过程提供了有前途的框架。

Method: DRL 使模型能够使用奖励信号优化操作，而 DPO 则直接使策略与偏好对齐，无需显式奖励模型。本文探讨了微调 LVLM 的范例，并研究了 DRL 和 DPO 技术。

Result: DRL 和 DPO 技术可用于微调 LVLM，以实现与人类偏好和价值观的对齐，提高任务性能，并实现适应性多模态交互。

Conclusion: DRL 和 DPO 在使 LVLM 与人类价值观对齐、提高性能和实现适应性交互方面发挥着关键作用，尽管在可扩展性、样本效率、持续学习、泛化和安全性方面仍存在挑战。

Abstract: Large Vision-Language Models (LVLMs) or multimodal large language models
represent a significant advancement in artificial intelligence, enabling
systems to understand and generate content across both visual and textual
modalities. While large-scale pretraining has driven substantial progress,
fine-tuning these models for aligning with human values or engaging in specific
tasks or behaviors remains a critical challenge. Deep Reinforcement Learning
(DRL) and Direct Preference Optimization (DPO) offer promising frameworks for
this aligning process. While DRL enables models to optimize actions using
reward signals instead of relying solely on supervised preference data, DPO
directly aligns the policy with preferences, eliminating the need for an
explicit reward model. This overview explores paradigms for fine-tuning LVLMs,
highlighting how DRL and DPO techniques can be used to align models with human
preferences and values, improve task performance, and enable adaptive
multimodal interaction. We categorize key approaches, examine sources of
preference data, reward signals, and discuss open challenges such as
scalability, sample efficiency, continual learning, generalization, and safety.
The goal is to provide a clear understanding of how DRL and DPO contribute to
the evolution of robust and human-aligned LVLMs.

</details>


### [402] [floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL](https://arxiv.org/abs/2509.06863)
*Bhavya Agrawalla,Michal Nauman,Khush Agarwal,Aviral Kumar*

Main category: cs.LG

TL;DR: 通过使用流匹配技术和迭代计算来改进强化学习中的Q函数，并在各种基准测试中提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现代大规模机器学习通常使用提供密集监督的训练目标，而传统的时序差分（TD）方法在价值函数表示上缺乏迭代计算。因此，本文旨在探索迭代计算对于RL中TD方法的益处。

Method: 提出了一种名为floq（flow-matching Q-functions）的方法，该方法使用速度场来参数化Q函数，并利用流匹配技术进行训练。该速度场通过TD学习目标进行训练，并从目标速度场（通过多步数值积分计算得到）进行引导。

Result: 在多种具有挑战性的离线RL基准测试和在线微调任务中，floq将性能提高了近1.8倍。

Conclusion: floq在容量扩展方面远优于标准的TD学习架构，展示了迭代计算在价值学习中的潜力。

Abstract: A hallmark of modern large-scale machine learning techniques is the use of
training objectives that provide dense supervision to intermediate
computations, such as teacher forcing the next token in language models or
denoising step-by-step in diffusion models. This enables models to learn
complex functions in a generalizable manner. Motivated by this observation, we
investigate the benefits of iterative computation for temporal difference (TD)
methods in reinforcement learning (RL). Typically they represent value
functions in a monolithic fashion, without iterative compute. We introduce floq
(flow-matching Q-functions), an approach that parameterizes the Q-function
using a velocity field and trains it using techniques from flow-matching,
typically used in generative modeling. This velocity field underneath the flow
is trained using a TD-learning objective, which bootstraps from values produced
by a target velocity field, computed by running multiple steps of numerical
integration. Crucially, floq allows for more fine-grained control and scaling
of the Q-function capacity than monolithic architectures, by appropriately
setting the number of integration steps. Across a suite of challenging offline
RL benchmarks and online fine-tuning tasks, floq improves performance by nearly
1.8x. floq scales capacity far better than standard TD-learning architectures,
highlighting the potential of iterative computation for value learning.

</details>


### [403] [AxelSMOTE: An Agent-Based Oversampling Algorithm for Imbalanced Classification](https://arxiv.org/abs/2509.06875)
*Sukumar Kishanthan,Asela Hevapathige*

Main category: cs.LG

TL;DR: AxelSMOTE是一种新颖的基于智能体的方法，通过模拟智能体间的交互来解决类别不平衡问题，克服了传统过采样技术的局限性，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡问题在机器学习中是一个严峻的挑战，因为倾斜的数据集常常会影响少数类别的性能。传统的过采样技术虽然常用于缓解类别不平衡，但存在独立处理特征、缺乏相似性控制、限制样本多样性以及未能有效管理合成样本等缺点。

Method: AxelSMOTE是一种基于智能体的方法，将数据实例视为进行复杂交互的自主智能体。该方法基于Axelrod的文化传播模型，实现了四项关键创新：1）基于特征的特征分组以保留相关性；2）基于相似性的概率交换机制以进行有意义的交互；3）Beta分布混合以进行现实的插值；4）受控的多样性注入以避免过度拟合。

Result: 在八个不平衡数据集上的实验表明，AxelSMOTE在保持计算效率的同时，性能优于最先进的采样方法。

Conclusion: AxelSMOTE通过引入基于智能体的方法和创新的技术，有效解决了类别不平衡问题，并提供了比传统方法更优越的性能。

Abstract: Class imbalance in machine learning poses a significant challenge, as skewed
datasets often hinder performance on minority classes. Traditional oversampling
techniques, which are commonly used to alleviate class imbalance, have several
drawbacks: they treat features independently, lack similarity-based controls,
limit sample diversity, and fail to manage synthetic variety effectively. To
overcome these issues, we introduce AxelSMOTE, an innovative agent-based
approach that views data instances as autonomous agents engaging in complex
interactions. Based on Axelrod's cultural dissemination model, AxelSMOTE
implements four key innovations: (1) trait-based feature grouping to preserve
correlations; (2) a similarity-based probabilistic exchange mechanism for
meaningful interactions; (3) Beta distribution blending for realistic
interpolation; and (4) controlled diversity injection to avoid overfitting.
Experiments on eight imbalanced datasets demonstrate that AxelSMOTE outperforms
state-of-the-art sampling methods while maintaining computational efficiency.

</details>


### [404] [Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition](https://arxiv.org/abs/2509.06918)
*Tarhib Al Azad,Shahana Ibrahim*

Main category: cs.LG

TL;DR: 本研究提出了一种结合损失修正和低秩/稀疏分解的鲁棒OOD检测框架，以解决标签噪声影响下的OOD检测性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 鲁棒的OOD检测对于安全关键AI应用至关重要，但现有方法在标签噪声下表现不佳，急需解决方案。

Method: 提出了一种新的框架，将标签噪声学习中的损失修正技术与信号处理中的低秩/稀疏分解方法相结合。

Result: 在合成和真实世界数据集上的实验表明，该方法在严重标签噪声的情况下显著优于现有的SOTA OOD检测技术。

Conclusion: 直接组合现有的标签噪声鲁棒方法和OOD检测策略不足以解决标签噪声带来的挑战，提出的框架能够有效提升OOD检测性能。

Abstract: Robust out-of-distribution (OOD) detection is an indispensable component of
modern artificial intelligence (AI) systems, especially in safety-critical
applications where models must identify inputs from unfamiliar classes not seen
during training. While OOD detection has been extensively studied in the
machine learning literature--with both post hoc and training-based
approaches--its effectiveness under noisy training labels remains
underexplored. Recent studies suggest that label noise can significantly
degrade OOD performance, yet principled solutions to this issue are lacking. In
this work, we demonstrate that directly combining existing label noise-robust
methods with OOD detection strategies is insufficient to address this critical
challenge. To overcome this, we propose a robust OOD detection framework that
integrates loss correction techniques from the noisy label learning literature
with low-rank and sparse decomposition methods from signal processing.
Extensive experiments on both synthetic and real-world datasets demonstrate
that our method significantly outperforms the state-of-the-art OOD detection
techniques, particularly under severe noisy label settings.

</details>


### [405] [From Noise to Narrative: Tracing the Origins of Hallucinations in Transformers](https://arxiv.org/abs/2509.06938)
*Praneet Suresh,Jack Stanley,Sonia Joseph,Luca Scimeca,Danilo Bzdok*

Main category: cs.LG

TL;DR: 生成式AI（如Transformer模型）在面对不确定输入时会产生幻觉，这是因为它们会激活与输入不相关的语义特征。


<details>
  <summary>Details</summary>
Motivation: 由于生成式AI在科学、商业和政府等领域日益普及，深入了解其失效模式（特别是幻觉）变得至关重要，因为幻觉会影响用户对其的信任和在高风险领域的应用。

Method: 通过稀疏自编码器捕获的概念表示，在实验控制的输入空间不确定性场景下，研究预训练Transformer模型的幻觉产生机制。

Result: Transformer模型在输入信息越来越无结构化时，会激活更多的语义概念。当输入不确定性增加时，模型更容易激活与输入无关但逻辑上连贯的语义特征，从而产生幻觉。对于纯噪声输入，可以识别出大量鲁棒触发的有意义的概念，并且可以通过有针对性的引导来验证其功能。此外，模型输出的幻觉可以从Transformer层激活中嵌入的概念模式可靠预测。

Conclusion: 对Transformer内部处理机制的理解有助于解决AI对齐人类价值观、AI安全、潜在对抗性攻击的攻击面以及为模型的幻觉风险提供自动量化基础。

Abstract: As generative AI systems become competent and democratized in science,
business, and government, deeper insight into their failure modes now poses an
acute need. The occasional volatility in their behavior, such as the propensity
of transformer models to hallucinate, impedes trust and adoption of emerging AI
solutions in high-stakes areas. In the present work, we establish how and when
hallucinations arise in pre-trained transformer models through concept
representations captured by sparse autoencoders, under scenarios with
experimentally controlled uncertainty in the input space. Our systematic
experiments reveal that the number of semantic concepts used by the transformer
model grows as the input information becomes increasingly unstructured. In the
face of growing uncertainty in the input space, the transformer model becomes
prone to activate coherent yet input-insensitive semantic features, leading to
hallucinated output. At its extreme, for pure-noise inputs, we identify a wide
variety of robustly triggered and meaningful concepts in the intermediate
activations of pre-trained transformer models, whose functional integrity we
confirm through targeted steering. We also show that hallucinations in the
output of a transformer model can be reliably predicted from the concept
patterns embedded in transformer layer activations. This collection of insights
on transformer internal processing mechanics has immediate consequences for
aligning AI models with human values, AI safety, opening the attack surface for
potential adversarial attacks, and providing a basis for automatic
quantification of a model's hallucination risk.

</details>


### [406] [Feed Two Birds with One Scone: Exploiting Function-Space Regularization for Both OOD Robustness and ID Fine-Tuning Performance](https://arxiv.org/abs/2509.05328)
*Xiang Yuan,Jun Shu,Deyu meng,Zongben Xu*

Main category: cs.LG

TL;DR: 该研究提出了一种新的正则化方法，通过在函数空间中约束微调模型与预训练模型之间的距离，并引入一致性正则化来提高下游任务的ID性能和OOD鲁棒性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒微调方法在不同模型架构上不能保证OOD鲁棒性的提升，因为它们可能无法很好地优化函数空间。OOD鲁棒性需要模型函数对下游任务的输入信息产生稳定的预测。

Method: 提出了一种新的正则化方法，该方法在函数空间中约束微调模型与预训练模型之间的距离，并使用模拟的OOD样本。此外，还引入了一致性正则化来促进对扰动样本的稳定预测。

Result: 所提出的方法在多种CLIP骨干网络上，能够同时提升下游任务的ID微调性能和OOD鲁棒性，并且优于现有的基于正则化的鲁棒微调方法。

Conclusion: 所提出的方法通过在函数空间中约束微调模型与预训练模型之间的距离，并引入一致性正则化，能够有效提升下游任务的ID性能和OOD鲁棒性，优于现有方法。

Abstract: Robust fine-tuning aims to achieve competitive in-distribution (ID)
performance while maintaining the out-of-distribution (OOD) robustness of a
pre-trained model when transferring it to a downstream task. To remedy this,
most robust fine-tuning methods aim to preserve the pretrained weights,
features, or logits. However, we find that these methods cannot always improve
OOD robustness for different model architectures. This is due to the OOD
robustness requiring the model function to produce stable prediction for input
information of downstream tasks, while existing methods might serve as a poor
proxy for the optimization in the function space. Based on this finding, we
propose a novel regularization that constrains the distance of fine-tuning and
pre-trained model in the function space with the simulated OOD samples, aiming
to preserve the OOD robustness of the pre-trained model. Besides, to further
enhance the OOD robustness capability of the fine-tuning model, we introduce an
additional consistency regularization to promote stable predictions of
perturbed samples. Extensive experiments demonstrate our approach could
consistently improve both downstream task ID fine-tuning performance and OOD
robustness across a variety of CLIP backbones, outperforming existing
regularization-based robust fine-tuning methods.

</details>


### [407] [ProfilingAgent: Profiling-Guided Agentic Reasoning for Adaptive Model Optimization](https://arxiv.org/abs/2509.05584)
*Sadegh Jafari,Aishwarya Sarkar,Mohiuddin Bilwal,Ali Jannesari*

Main category: cs.LG

TL;DR: Foundation models have compute and memory issues. ProfilingAgent, an LLM-based system, automates compression via structured pruning and dynamic quantization by analyzing both static and dynamic metrics, tailoring strategies to specific architectures and bottlenecks. It achieves competitive accuracy with significant memory savings and inference speedups.


<details>
  <summary>Details</summary>
Motivation: Foundation models face compute and memory bottlenecks, limiting deployment on resource-constrained platforms. Existing compression methods often use uniform heuristics that don't account for hardware heterogeneity and aren't well-integrated into automated workflows, despite profiling tools providing valuable per-layer metrics.

Method: ProfilingAgent is a multi-agent system that leverages large language models (LLMs) to automate model compression. It combines structured pruning and post-training dynamic quantization. The system analyzes static metrics (MACs, parameter counts) and dynamic signals (latency, memory) to create architecture-specific compression strategies, making layer-wise decisions based on identified bottlenecks.

Result: Experiments on ImageNet-1K, CIFAR-10, and CIFAR-100 using ResNet-101, ViT-B/16, Swin-B, and DeiT-B/16 demonstrated that the pruning method maintains competitive or improved accuracy (around 1% drop on ImageNet-1K, with up to 2% gains for ViT-B/16 on smaller datasets). The quantization method achieved up to 74% memory savings with less than 0.5% accuracy loss, and provided inference speedups of up to 1.74 times.

Conclusion: Agentic systems, like ProfilingAgent, offer scalable solutions for optimizing foundation models using profiling data. The quality of the LLM used is crucial for the effectiveness of iterative pruning, as shown in comparative studies with GPT-4o and GPT-4-Turbo.

Abstract: Foundation models face growing compute and memory bottlenecks, hindering
deployment on resource-limited platforms. While compression techniques such as
pruning and quantization are widely used, most rely on uniform heuristics that
ignore architectural and runtime heterogeneity. Profiling tools expose
per-layer latency, memory, and compute cost, yet are rarely integrated into
automated pipelines. We propose ProfilingAgent, a profiling-guided, agentic
approach that uses large language models (LLMs) to automate compression via
structured pruning and post-training dynamic quantization. Our modular
multi-agent system reasons over static metrics (MACs, parameter counts) and
dynamic signals (latency, memory) to design architecture-specific strategies.
Unlike heuristic baselines, ProfilingAgent tailors layer-wise decisions to
bottlenecks. Experiments on ImageNet-1K, CIFAR-10, and CIFAR-100 with
ResNet-101, ViT-B/16, Swin-B, and DeiT-B/16 show pruning maintains competitive
or improved accuracy (about 1% drop on ImageNet-1K, +2% gains for ViT-B/16 on
smaller datasets), while quantization achieves up to 74% memory savings with
<0.5% accuracy loss. Our quantization also yields consistent inference speedups
of up to 1.74 times faster. Comparative studies with GPT-4o and GPT-4-Turbo
highlight the importance of LLM reasoning quality for iterative pruning. These
results establish agentic systems as scalable solutions for profiling-guided
model optimization.

</details>


### [408] [Performance of Conformal Prediction in Capturing Aleatoric Uncertainty](https://arxiv.org/abs/2509.05826)
*Misgina Tsighe Hagos,Claes Lundström*

Main category: cs.LG

TL;DR: Conformal prediction sets struggle to effectively quantify aleatoric uncertainty, showing weak correlation with human annotations of class ambiguity.


<details>
  <summary>Details</summary>
Motivation: The effectiveness of conformal prediction in quantifying aleatoric uncertainty, specifically in the context of overlapping classes, is not well-established and lacks validation.

Method: Investigated the correlation between prediction set sizes from three conformal prediction methods and the number of distinct labels assigned by human annotators per instance. Also assessed the similarity between prediction sets and human annotations. Used eight deep learning models on four datasets with multiple human annotators.

Result: The vast majority of conformal prediction outputs exhibited a very weak to weak correlation with human annotations. Only a few instances showed a moderate correlation.

Conclusion: While conformal prediction can ensure high coverage of true classes, its ability to capture aleatoric uncertainty is limited, necessitating a critical re-evaluation of its generated prediction sets.

Abstract: Conformal prediction is a model-agnostic approach to generating prediction
sets that cover the true class with a high probability. Although its prediction
set size is expected to capture aleatoric uncertainty, there is a lack of
evidence regarding its effectiveness. The literature presents that prediction
set size can upper-bound aleatoric uncertainty or that prediction sets are
larger for difficult instances and smaller for easy ones, but a validation of
this attribute of conformal predictors is missing. This work investigates how
effectively conformal predictors quantify aleatoric uncertainty, specifically
the inherent ambiguity in datasets caused by overlapping classes. We perform
this by measuring the correlation between prediction set sizes and the number
of distinct labels assigned by human annotators per instance. We further assess
the similarity between prediction sets and human-provided annotations. We use
three conformal prediction approaches to generate prediction sets for eight
deep learning models trained on four datasets. The datasets contain annotations
from multiple human annotators (ranging from five to fifty participants) per
instance, enabling the identification of class overlap. We show that the vast
majority of the conformal prediction outputs show a very weak to weak
correlation with human annotations, with only a few showing moderate
correlation. These findings underscore the necessity of critically reassessing
the prediction sets generated using conformal predictors. While they can
provide a higher coverage of the true classes, their capability in capturing
aleatoric uncertainty remains limited.

</details>


### [409] [Evaluating the Efficiency of Latent Spaces via the Coupling-Matrix](https://arxiv.org/abs/2509.06314)
*Mehmet Can Yavuz,Berrin Yanikoglu*

Main category: cs.LG

TL;DR: 使用能量距离将潜在表示与正态分布进行比较，引入了一个冗余指数 rho(C) 来量化潜在嵌入中的冗余，该指数可以预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 深度网络产生的冗余潜在空间会降低有效容量并阻碍泛化，而标准指标无法隔离这种冗余。

Method: 通过分析从潜在表示派生的耦合矩阵，并将它们的非对角线统计数据与正态分布进行比较，引入了一个冗余指数 rho(C)，通过能量距离对其进行量化。

Result: rho(C) 的低值可靠地预测了高分类准确率或低重建误差，而冗余的增加则与性能下降有关。TPE 优先探索低 rho(C) 区域。

Conclusion: rho(C) 提供了一个理论视角和实用工具，用于评估和改进学习表示的效率，通过将冗余作为模型和任务中的普遍瓶颈来暴露冗余。

Abstract: A central challenge in representation learning is constructing latent
embeddings that are both expressive and efficient. In practice, deep networks
often produce redundant latent spaces where multiple coordinates encode
overlapping information, reducing effective capacity and hindering
generalization. Standard metrics such as accuracy or reconstruction loss
provide only indirect evidence of such redundancy and cannot isolate it as a
failure mode. We introduce a redundancy index, denoted rho(C), that directly
quantifies inter-dimensional dependencies by analyzing coupling matrices
derived from latent representations and comparing their off-diagonal statistics
against a normal distribution via energy distance. The result is a compact,
interpretable, and statistically grounded measure of representational quality.
We validate rho(C) across discriminative and generative settings on MNIST
variants, Fashion-MNIST, CIFAR-10, and CIFAR-100, spanning multiple
architectures and hyperparameter optimization strategies. Empirically, low
rho(C) reliably predicts high classification accuracy or low reconstruction
error, while elevated redundancy is associated with performance collapse.
Estimator reliability grows with latent dimension, yielding natural lower
bounds for reliable analysis. We further show that Tree-structured Parzen
Estimators (TPE) preferentially explore low-rho regions, suggesting that rho(C)
can guide neural architecture search and serve as a redundancy-aware
regularization target. By exposing redundancy as a universal bottleneck across
models and tasks, rho(C) offers both a theoretical lens and a practical tool
for evaluating and improving the efficiency of learned representations.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [410] [Characterizing and Optimizing Realistic Workloads on a Commercial Compute-in-SRAM Device](https://arxiv.org/abs/2509.05451)
*Niansong Zhang,Wenbo Zhu,Courtney Golden,Dan Ilan,Hongzheng Chen,Christopher Batten,Zhiru Zhang*

Main category: cs.AR

TL;DR: 在实际工作负载下，对 GSI APU 这一商用计算内 SRAM 设备进行了全面的性能和能耗评估，并与 CPU 和 GPU 进行了比较。


<details>
  <summary>Details</summary>
Motivation: 先前的计算内 SRAM（Compute-in-SRAM）评估主要依赖模拟器或小型原型，限制了对其真实潜力的理解。

Method: 提出了一种通用的计算内 SRAM 分析框架，通过对性能权衡进行建模来揭示基本的优化原理，并提出了三种优化：通信感知规约映射、合并 DMA 和广播友好数据布局。针对大规模语料库（10GB-200GB）上的检索增强生成（RAG）任务，将这些优化应用于计算内 SRAM 系统。

Result: 计算内 SRAM 系统将检索速度比优化的 CPU 基线提高了 4.8 倍至 6.6 倍，端到端 RAG 延迟提高了 1.1 倍至 1.8 倍。在 RAG 任务中，该系统达到了 NVIDIA A6000 GPU 的性能水平，但能效显著更高（降低了 54.4 倍至 117.9 倍）。

Conclusion: 计算内 SRAM 对于复杂、实际的应用是可行的，并为该技术的进步提供了指导。

Abstract: Compute-in-SRAM architectures offer a promising approach to achieving higher
performance and energy efficiency across a range of data-intensive
applications. However, prior evaluations have largely relied on simulators or
small prototypes, limiting the understanding of their real-world potential. In
this work, we present a comprehensive performance and energy characterization
of a commercial compute-in-SRAM device, the GSI APU, under realistic workloads.
We compare the GSI APU against established architectures, including CPUs and
GPUs, to quantify its energy efficiency and performance potential. We introduce
an analytical framework for general-purpose compute-in-SRAM devices that
reveals fundamental optimization principles by modeling performance trade-offs,
thereby guiding program optimizations.
  Exploiting the fine-grained parallelism of tightly integrated memory-compute
architectures requires careful data management. We address this by proposing
three optimizations: communication-aware reduction mapping, coalesced DMA, and
broadcast-friendly data layouts. When applied to retrieval-augmented generation
(RAG) over large corpora (10GB--200GB), these optimizations enable our
compute-in-SRAM system to accelerate retrieval by 4.8$\times$--6.6$\times$ over
an optimized CPU baseline, improving end-to-end RAG latency by
1.1$\times$--1.8$\times$. The shared off-chip memory bandwidth is modeled using
a simulated HBM, while all other components are measured on the real
compute-in-SRAM device. Critically, this system matches the performance of an
NVIDIA A6000 GPU for RAG while being significantly more energy-efficient
(54.4$\times$-117.9$\times$ reduction). These findings validate the viability
of compute-in-SRAM for complex, real-world applications and provide guidance
for advancing the technology.

</details>


### [411] [High Utilization Energy-Aware Real-Time Inference Deep Convolutional Neural Network Accelerator](https://arxiv.org/abs/2509.05688)
*Kuan-Ting Lin,Ching-Te Chiu,Jheng-Yi Chang,Shi-Zong Huang,Yu-Ting Li*

Main category: cs.AR

TL;DR: 提出一种高利用率的、面向边缘计算的、支持实时推理的深度卷积神经网络加速器，解决了现有DCNN在边缘设备上计算复杂度和数据访问量过大的问题。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络（DCNN）在计算机视觉任务中应用广泛，但其高计算复杂度和数据访问量限制了其在边缘设备上的实时应用。

Method: 1. 使用1x1卷积核作为计算单元的最小单元，并根据模型需求设计计算单元。2. 引入重用特征SRAM（Reuse Feature SRAM）存储中间层输出，作为下一层的输入。3. 采用输出重用策略（Output Reuse Strategy）和环流数据流（Ring Stream Dataflow）减少与DRAM的数据交换。4. 提出片上池化模块（On-fly Pooling Module），直接在芯片上完成池化层计算。

Result: 实现的加速芯片具有极高的硬件利用率，ECNN模块的数据传输量减少了533倍。该加速器能够实时运行VGG16和MobileNet等图像分类模型。与VWA相比，速度提升7.52倍，能效提升1.92倍。

Conclusion: 所提出的DCNN加速器通过采用1x1卷积核、重用特征SRAM、输出重用策略、环流数据流和片上池化模块等方法，显著提高了硬件利用率和能效，有效解决了DCNN在边缘设备的实时推理挑战。

Abstract: Deep convolution Neural Network (DCNN) has been widely used in computer
vision tasks. However, for edge devices even inference has too large
computational complexity and data access amount. The inference latency of
state-of-the-art models are impractical for real-world applications. In this
paper, we propose a high utilization energy-aware real-time inference deep
convolutional neural network accelerator, which improves the performance of the
current accelerators. First, we use the 1x1 size convolution kernel as the
smallest unit of the computing unit. Then we design suitable computing unit
based on the requirements of each model. Secondly, we use Reuse Feature SRAM to
store the output of the current layer in the chip and use the value as the
input of the next layer. Moreover, we import Output Reuse Strategy and Ring
Stream Dataflow to reduce the amount of data exchange between chips and DRAM.
Finally, we present On-fly Pooling Module to let the calculation of the Pooling
layer directly complete in the chip. With the aid of the proposed method, the
implemented acceleration chip has an extremely high hardware utilization rate.
We reduce a generous amount of data transfer on the specific module, ECNN.
Compared to the methods without reuse strategy, we can reduce 533 times of data
access amount. At the same time, we have enough computing power to perform
real-time execution of the existing image classification model, VGG16 and
MobileNet. Compared with the design in VWA, we can speed up 7.52 times and have
1.92x energy efficiency

</details>


### [412] [Hardware Acceleration of Kolmogorov-Arnold Network (KAN) in Large-Scale Systems](https://arxiv.org/abs/2509.05937)
*Wei-Hsing Huang,Jianwei Jia,Yuyao Kong,Faaiq Waqar,Tai-Hao Wen,Meng-Fan Chang,Shimeng Yu*

Main category: cs.AR

TL;DR: KANs使用参数化B样条函数，参数量少但硬件加速复杂。本研究提出了一种算法-硬件协同设计方法，结合算法层面的量化、映射策略和电路层面的时间调制动态电压输入生成器及模拟计算内存(ACIM)电路，以加速KAN。在22nm工艺下，即使参数量大幅增加，该方法也能有效控制面积和功耗，同时保持较低的精度损失，证明了其扩展潜力。


<details>
  <summary>Details</summary>
Motivation: KANs虽然参数量少，但其B样条函数组件带来了硬件加速的挑战。本研究旨在提出一种算法-硬件协同设计方法来解决这一挑战，以实现高效的KAN硬件加速。

Method: 本研究提出了一种算法-硬件协同设计方法。算法层面包括：KAN硬件感知量化（对齐-对称和PowerGap）、KAN稀疏感知映射策略。电路层面包括：N:1时间调制动态电压输入生成器和模拟计算内存(ACIM)电路。

Result: 在22nm工艺下，使用最优的KAN超参数和电路优化，与先前的小规模任务相比，大规模任务的参数量增加了500Kx至807Kx，但面积开销仅增加了28Kx至41Kx，功耗增加了51x至94x，而精度下降仅为0.11%至0.23%。

Conclusion: 本研究提出的算法-硬件协同设计方法能够有效地加速KAN，即使在处理大规模任务和采用先进工艺节点时，也能在面积、功耗和精度之间取得良好的平衡，证明了其优越的可扩展性。

Abstract: Recent developments have introduced Kolmogorov-Arnold Networks (KAN), an
innovative architectural paradigm capable of replicating conventional deep
neural network (DNN) capabilities while utilizing significantly reduced
parameter counts through the employment of parameterized B-spline functions
with trainable coefficients. Nevertheless, the B-spline functional components
inherent to KAN architectures introduce distinct hardware acceleration
complexities. While B-spline function evaluation can be accomplished through
look-up table (LUT) implementations that directly encode functional mappings,
thus minimizing computational overhead, such approaches continue to demand
considerable circuit infrastructure, including LUTs, multiplexers, decoders,
and related components. This work presents an algorithm-hardware co-design
approach for KAN acceleration. At the algorithmic level, techniques include
Alignment-Symmetry and PowerGap KAN hardware aware quantization, KAN sparsity
aware mapping strategy, and circuit-level techniques include N:1 Time
Modulation Dynamic Voltage input generator with analog-compute-in-memory (ACIM)
circuits. This work conducts evaluations on large-scale KAN networks to
validate the proposed methodologies. Non-ideality factors, including partial
sum deviations from process variations, have been evaluated with statistics
measured from the TSMC 22nm RRAM-ACIM prototype chips. Utilizing optimally
determined KAN hyperparameters in conjunction with circuit optimizations
fabricated at the 22nm technology node, despite the parameter count for
large-scale tasks in this work increasing by 500Kx to 807Kx compared to
tiny-scale tasks in previous work, the area overhead increases by only 28Kx to
41Kx, with power consumption rising by merely 51x to 94x, while accuracy
degradation remains minimal at 0.11% to 0.23%, demonstrating the scaling
potential of our proposed architecture.

</details>


### [413] [SCREME: A Scalable Framework for Resilient Memory Design](https://arxiv.org/abs/2509.06101)
*Fan Li,Mimi Xie,Yanan Guo,Huize Li,Xin Xin*

Main category: cs.AR

TL;DR: ECC 芯片不一定需要与常规数据芯片相同的性能水平，因此可以使用更便宜、性能稍低的芯片来存储奇偶校验数据，并利用服务器级内存芯片中未充分利用的 I/O 资源来实现灵活的片上互连，从而提出了一种名为 SCREME 的可扩展内存框架。


<details>
  <summary>Details</summary>
Motivation: 内存技术的发展带来了性能的提升，但也加剧了可靠性挑战。传统的解决方案侧重于提高纠错码（ECC）的效率，但假设为奇偶校验数据分配额外内存空间成本高昂且不可扩展。

Method: 提出了一种替代方案，即认识到 ECC 芯片不需要与常规数据芯片相同的性能水平。这使得可以使用性能较低但成本更低的 ECC 芯片，并利用服务器级内存芯片中未充分利用的 I/O 资源来实现灵活的片上互连。基于这些发现，提出了 SCREME 框架。

Result: SCREME 框架利用成本效益高但速度较慢的芯片来满足不断增长的可靠性需求，这些芯片是在技术快速发展过程中自然产生的。

Conclusion: SCREME 框架通过利用成本较低、性能稍逊的芯片来存储奇偶校验数据，并结合灵活的片上互连，为内存设计提供了一种经济高效且可扩展的解决方案，以应对不断增长的可靠性挑战。

Abstract: The continuing advancement of memory technology has not only fueled a surge
in performance, but also substantially exacerbate reliability challenges.
Traditional solutions have primarily focused on improving the efficiency of
protection schemes, i.e., Error Correction Codes (ECC), under the assumption
that allocating additional memory space for parity data is always expensive and
therefore not a scalable solution.
  We break the stereotype by proposing an orthogonal approach that provides
additional, cost-effective memory space for resilient memory design. In
particular, we recognize that ECC chips (used for parity storage) do not
necessarily require the same performance level as regular data chips. This
offers two-fold benefits: First, the bandwidth originally provisioned for a
regular-performance ECC chip can instead be used to accommodate multiple
low-performance chips. Second, the cost of ECC chips can be effectively
reduced, as lower performance often correlates with lower expense. In addition,
we observe that server-class memory chips are often provisioned with ample, yet
underutilized I/O resources. This further offers the opportunity to repurpose
these resources to enable flexible on-DIMM interconnections. Based on the above
two insights, we finally propose SCREME, a scalable memory framework leverages
cost-effective, albeit slower, chips -- naturally produced during rapid
technology evolution -- to meet the growing reliability demands driven by this
evolution.

</details>


### [414] [Hardware Acceleration in Portable MRIs: State of the Art and Future Prospects](https://arxiv.org/abs/2509.06365)
*Omar Al Habsi,Safa Mohammed Sali,Anis Meribout,Mahmoud Meribout,Saif Almazrouei,Mohamed Seghier*

Main category: cs.AR

TL;DR: 该论文对便携式MRI（pMRI）的硬件加速进行了综述，强调了GPU、FPGA和ASIC等技术在加速图像重建和提高便携性方面的潜力，并提出成立低场MRI联盟和证据阶梯来推动可重复AI的发展。


<details>
  <summary>Details</summary>
Motivation: 便携式MRI（pMRI）在医疗点成像方面有巨大潜力，尤其是在资源匮乏地区，但其计算复杂性（尤其是在图像重建和机器学习算法方面）带来了挑战。现有pMRI文献对硬件加速的关注不足，该论文旨在弥补这一空白。

Method: 该论文综述了pMRI的最新进展，重点关注硬件加速在提高图像采集和重建速度方面的作用和影响。文中讨论了GPU、FPGA和ASIC等关键技术，并强调了AI驱动的重建、开放的低场pMRI数据集以及创新的边缘硬件解决方案的潜力。

Result: 硬件加速可以提高图像质量、降低功耗并增强下一代pMRI技术的便携性。AI驱动的重建、开放数据集和边缘硬件解决方案为pMRI的未来发展带来了希望。

Conclusion: 为了加速便携式MRI的可重复AI研究，论文提议成立一个低场MRI联盟，并建立一个证据阶梯（包括分析/模型验证、回顾性多中心测试、前瞻性读者和非劣效性试验），以提供标准化的数据集、基准和面向监管的测试平台。

Abstract: There is a growing interest in portable MRI (pMRI) systems for point-of-care
imaging, particularly in remote or resource-constrained environments. However,
the computational complexity of pMRI, especially in image reconstruction and
machine learning (ML) algorithms for enhanced imaging, presents significant
challenges. Such challenges can be potentially addressed by harnessing hardware
application solutions, though there is little focus in the current pMRI
literature on hardware acceleration. This paper bridges that gap by reviewing
recent developments in pMRI, emphasizing the role and impact of hardware
acceleration to speed up image acquisition and reconstruction. Key technologies
such as Graphics Processing Units (GPUs), Field-Programmable Gate Arrays
(FPGAs), and Application-Specific Integrated Circuits (ASICs) offer excellent
performance in terms of reconstruction speed and power consumption. This review
also highlights the promise of AI-powered reconstruction, open low-field pMRI
datasets, and innovative edge-based hardware solutions for the future of pMRI
technology. Overall, hardware acceleration can enhance image quality, reduce
power consumption, and increase portability for next-generation pMRI
technology. To accelerate reproducible AI for portable MRI, we propose forming
a Low-Field MRI Consortium and an evidence ladder (analytic/phantom validation,
retrospective multi-center testing, prospective reader and non-inferiority
trials) to provide standardized datasets, benchmarks, and regulator-ready
testbeds.

</details>


### [415] [VCO-CARE: VCO-based Calibration-free Analog Readout for Electrodermal activity sensing](https://arxiv.org/abs/2509.06698)
*Leidy Mabel Alvero-Gonzalez,Matias Miguez,Eric Gutierrez,Juan Sapriza,Susana Patón,David Atienza,José Miranda*

Main category: cs.AR

TL;DR: VCO-CARE是一个用于连续皮肤电活动（EDA）传感的电压控制振荡器（VCO）模拟读出系统，它实现了高灵敏度（40 pS）、低功耗（2.3 uW）和低噪声（0.8 uVrms），适用于可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备对具有高灵敏度、低功耗和低校准要求的EDA模拟前端（AFE）系统提出了持续的需求，以实现实际应用。

Method: 提出了一种基于压控振荡器（VCO）的模拟读出电路（VCO-CARE），用于连续EDA传感。

Result: 该系统在0-20 uS范围内实现了高达40 pS的平均灵敏度，在固定电阻下相对误差小于0.0025%，平均功耗为2.3 uW，在0-1.5 Hz EDA信号频带内噪声仅为0.8 uVrms。

Conclusion: 该研究旨在推动可穿戴传感器技术的发展，实现用户适应性、低功耗和卓越的抗噪声性能。

Abstract: Continuous monitoring of electrodermal activity (EDA) through wearable
devices has attracted much attention in recent times. However, the persistent
challenge demands analog front-end (AFE) systems with high sensitivity, low
power consumption, and minimal calibration requirements to ensure practical
usability in wearable technologies. In response to this challenge, this
research introduces VCO-CARE, a Voltage-Controlled Oscillator-based Analog
Readout tailored for continuous EDA sensing. The results show that our system
achieves an exceptional average sensitivity of up to 40 pS within a 0-20 uS
range and a negligible relative error of less than 0.0025% for
fixed-resistance. Furthermore, the proposed system consumes only an average of
2.3 uW based on post-layout validations and introduces a low noise
contribution, measuring only 0.8 uVrms across the 0-1.5 Hz EDA signal band.
This research aims to drive the evolution of wearable sensors characterized by
seamless adaptability to diverse users, minimal power consumption, and
outstanding noise resilience.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [416] [Bi-Level Game-Theoretic Planning of Cyber Deception for Cognitive Arbitrage](https://arxiv.org/abs/2509.05498)
*Ya-Ting Yang,Quanyan Zhu*

Main category: cs.GT

TL;DR: 本论文提出了一种利用认知漏洞进行网络战的新方法，即“认知套利”，并设计了相应的认知防御策略。


<details>
  <summary>Details</summary>
Motivation: 认知漏洞（包括认知能力和认知偏见）是影响人类决策的关键因素。攻击者可以利用这些漏洞获得战略优势。本研究旨在利用这些漏洞，设计能够反制APT攻击的认知防御机制。

Method: 提出了一种双层网络战博弈模型，重点在于“战略层”的防御欺骗机制设计，进而促进“战术层”的行动和“执行层”的TTPs。运用博弈论进行跨层量化建模和认知套利策略设计。

Result: 数值结果表明，通过战略性地部署欺骗技术，即使在初始优势减弱的情况下，也能在策划阶段将攻击者的负价值转化为正价值，并在执行阶段获得至少40%的总体回报提升。

Conclusion: 研究证明，防御者可以放大初始优势，保持对攻击者的战略优势，并在攻击者的整个生命周期内保护关键资产，实现长期目标。

Abstract: Cognitive vulnerabilities shape human decision-making and arise primarily
from two sources: (1) cognitive capabilities, which include disparities in
knowledge, education, expertise, or access to information, and (2) cognitive
biases, such as rational inattention, confirmation bias, and base rate neglect,
which influence how individuals perceive and process information. Exploiting
these vulnerabilities allows an entity with superior cognitive awareness to
gain a strategic advantage, a concept referred to as cognitive arbitrage. This
paper investigates how to exploit the cognitive vulnerabilities of Advanced
Persistent Threat (APT) attackers and proposes cognition-aware defenses that
leverage windows of superiority to counteract attacks. Specifically, the
proposed bi-level cyber warfare game focuses on "strategic-level" design for
defensive deception mechanisms, which then facilitates "operational-level"
actions and tactical-level execution of Tactics, Techniques, and Procedures
(TTPs). Game-theoretic reasoning and analysis play a significant role in the
cross-echelon quantitative modeling and design of cognitive arbitrage
strategies. Our numerical results demonstrate that although the defender's
initial advantage diminishes over time, strategically timed and deployed
deception techniques can turn a negative value for the attacker into a positive
one during the planning phase, and achieve at least a 40% improvement in total
rewards during execution. This demonstrates that the defender can amplify even
small initial advantages, sustain a strategic edge over the attacker, and
secure long-term objectives, such as protecting critical assets throughout the
attacker's lifecycle.

</details>


### [417] [Knapsack Contracts and the Importance of Return-on-Investment](https://arxiv.org/abs/2509.05956)
*Zohar Barak,Asnat Berlin,Ilan Reuven Cohen,Alon Eden,Omri Porat,Inbal Talgam-Cohen*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We formulate the Knapsack Contracts problem -- a strategic version of the
classic Stochastic Knapsack problem, which builds upon the inherent randomness
shared by stochastic optimization and contract design. In this problem, the
principal incentivizes agents to perform jobs with stochastic processing times,
the realization of which depends on the agents' efforts.
  Algorithmically, we show that Knapsack Contracts can be viewed as Stochastic
Knapsack with costs and multi-choice, features that introduce significant new
challenges. We identify a crucial and economically meaningful parameter -- the
Return on Investment (ROI) value. We show that the Inverse of ROI (or IOR for
short) precisely characterizes the extent to which the approximation guarantees
for Stochastic Knapsack extend to its strategic counterpart.
  For IOR of $\alpha$, we develop an algorithm that finds an
$O(\alpha)$-approximation policy that does not rely on adaptivity. We establish
matching $\Omega(\alpha)$ lower bounds, both on the adaptivity gap, and on what
can be achieved without full distributional knowledge of the processing times.
Taken together, our results show that IOR is fundamental to understanding the
complexity and approximability of Knapsack Contracts, and bounding it is both
necessary and sufficient for achieving non-trivial approximation guarantees.
Our results highlight the computational challenges arising when stochasticity
in optimization problems is controlled by strategic effort.

</details>


### [418] [The Keychain Problem: On Minimizing the Opportunity Cost of Uncertainty](https://arxiv.org/abs/2509.06187)
*Ramiro N. Deo-Campo Vuong,Robert Kleinberg,Aditya Prasad,Eric Xiao,Haifeng Xu*

Main category: cs.GT

TL;DR: 该论文提出了一类名为“钥匙串问题”的序贯决策问题，旨在解决在每个阶段只能使用部分动作的情况下最大化预期收益的问题。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决一种序贯决策问题，其中玩家（锁匠）需要在每个阶段从一组可用的选项（钥匙串）中选择一个动作（钥匙）来最大化整体收益（打开锁的轮数）。

Method: 研究了三种钥匙串测试顺序：固定顺序、随机顺序和由玩家选择的顺序。针对最简单的情况，提出了一种精确算法；对于其他情况，则提出了近似算法和计算复杂性结果。在概率场景设置中，近似算法利用了组合拍卖和序贯决策策略设计之间的新联系。

Result: 提出了一种精确算法（用于固定顺序）和近似算法（用于随机顺序和玩家选择顺序）。证明了计算复杂性结果，并展示了该技术在在线二分匹配问题中的应用。

Conclusion: 该研究为“钥匙串问题”提供了一系列算法和理论分析，并展示了其在其他序贯决策和在线匹配问题中的通用性。

Abstract: In this paper, we introduce a family of sequential decision-making problems,
collectively called the Keychain Problem, that involve exploring a set of
actions to maximize expected payoff when only a subset of actions are available
in each stage. In an instance of the Keychain Problem, a locksmith faces a
sequence of choices, each of which involves selecting one key from a specified
subset (a keychain) to attempt to open a lock. Given a Bayesian prior on the
effectiveness of keys, the locksmith's goal is to maximize the expected number
of rounds in which the lock is opened -- or equivalently, minimize the
opportunity cost which is the expected number of rounds in which the chain has
a correct key but our selected key is incorrect. We investigate Keychain
Problems under three assumptions on the order in which keychains are tested by
the locksmith: a fixed, known order; a random order sampled from a known
distribution on a set of ``scenarios''; or an order selected by the locksmith
themself. We present an exact algorithm for the simplest of these settings, and
we present approximation algorithms and hardness results for the others. In the
Probabilistic Scenarios setting, our approximation algorithm is based on a
novel connection between combinatorial auctions and policy design for
sequential decision-making problems. To illustrate the generality of this
technique, we apply the same ideas to obtain Philosopher Inequalities for
Online Bipartite Matching and some of its extensions.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [419] [Developing a Framework to Simulate Quantitative Ultrasound Flow and Tissue Motion for Ultrafast Doppler Ultrasound](https://arxiv.org/abs/2509.05464)
*Qiang Fu,Changhui Li*

Main category: eess.SP

TL;DR: 3D-FQFlow是一个开源框架，用于模拟3D血管血流和超声图像，并考虑了组织运动，实现了超快全频多普勒成像的定量评估。


<details>
  <summary>Details</summary>
Motivation: 当前的超快全频多普勒成像（uPDI）缺乏能够模拟接近真实条件下的三维（3D）定量血流和组织运动的仿真工具。

Method: 构建了一个名为3D-FQFlow的开源框架，集成了基于L-系统的血管生成器、SimVascular CFD（用于血液动力学）、支持用户自定义或临床数据驱动的组织运动模拟器、优化的PFILED超声模拟器、基于预计算矩阵的重建器以及定量分析工具（MSE/PSNR/SSIM）。

Result: 模拟结果显示了四种运动模式对奇异值分解（SVD）的不同影响；成功实现了兔肾脏（SSIM = 0.951）、生成的血管系统（SSIM = 0.902）和临床肺动脉（SSIM = 0.850）的3D成像；GPU加速使得在4117秒内完成了100帧3D-uPDI生成的100万散射体模拟，加速比达到18.8倍。

Conclusion: 3D-FQFlow是首个用于在真实血管和运动条件下对uPDI进行定量验证的开源框架，为微血管成像研究建立了可重复的标准。

Abstract: Ultrafast power Doppler imaging (uPDI) has made significant progress and
become an important imaging method for both research and clinical
implementations. While, it lacks simulation tools that can perform
three-dimensional (3D) quantitative flow with tissue motion close to realistic
conditions. In this study, we explore to construct an open-source framework,
named 3D-Fully Quantitative Flow (3D-FQFlow), to provide quantitative modeling
of 3D vascular flow with tissue motion and uPDI imaging. The framework
integrates a L-system-based vascular generator with SimVascular CFD for
hemodynamics, a tissue motion simulator supporting user-defined or
clinical-data-driven condition, an optimized PFILED ultrasound simulator, a
precomputed-matrix-based reconstructor, and a quantitative analyzer
(MSE/PSNR/SSIM). Results demonstrate distinct influences of four motion
patterns on SVD decomposition; successful 3D imaging of rabbit kidney (SSIM =
0.951), generated vasculature (SSIM = 0.902), and clinical pulmonary arteries
(SSIM = 0.850); and GPU acceleration permitting 1-million-scatterer simulation
in 4,117 seconds with 18.8* speedup for 100-frame 3D-uPDI generation. 3D-FQFlow
establishes the first open-source framework for quantitative validation of uPDI
under realistic vascular and motion conditions, creating a reproducible
standard for microvascular imaging research
(https://github.com/FortuneOU/3D-FQFlow).

</details>


### [420] [Time-Modulated Intelligent Reflecting Surfaces for Integrated Sensing, Communication and Security: A Generative AI Design Framework](https://arxiv.org/abs/2509.05565)
*Zhihao Tao,Athina Petropulu,H. Vincent Poor*

Main category: eess.SP

TL;DR: 利用时间调制的智能反射表面（TM-IRS）结合GFlowNet，在感知-通信一体化（ISAC）系统中实现物理层安全。


<details>
  <summary>Details</summary>
Motivation: 在存在窃听者（目标）的情况下，为ISAC系统实现物理层安全。

Method: 设计一种TM-IRS，利用GFlowNet学习随机策略，从离散参数空间中采样高性能配置，以最大化通信和感知性能。将TM-IRS设计建模为马尔可夫决策过程（MDP），GFlowNets被用来学习一个随机策略，以与关联奖励成正比的概率采样TM-IRS参数集。

Result: 实验结果表明，所提出的基于GFlowNet的方法能有效地同时集成感知、通信和安全，并表现出比穷举组合搜索更高的采样效率和更强的鲁棒性。

Conclusion: 提出的GFlowNet方法能够有效地集成ISAC系统的感知、通信和安全，并提高采样效率和鲁棒性。

Abstract: We propose a novel approach to achieve physical layer security for integrated
sensing and communication (ISAC) systems operating in the presence of targets
that may be eavesdroppers. The system is aided by a time-modulated intelligent
reflecting surface (TM-IRS), which is configured to preserve the integrity of
the transmitted data at one or more legitimate communication users (CUs) while
making them appear scrambled in all other directions. The TM-IRS design
leverages a generative flow network (GFlowNet) framework to learn a stochastic
policy that samples high-performing TM-IRS configurations from a vast discrete
parameter space. Specifically, we begin by formulating the achievable sum rate
for the legitimate CUs and the beampattern gain toward the target direction,
based on which we construct reward functions for GFlowNets that jointly capture
both communication and sensing performance. The TM-IRS design is modeled as a
deterministic Markov decision process (MDP), where each terminal state
corresponds to a complete configuration of TM-IRS parameters. GFlowNets,
parametrized by deep neural networks are employed to learn a stochastic policy
that samples TM-IRS parameter sets with probability proportional to their
associated reward. Experimental results demonstrate the effectiveness of the
proposed GFlowNet-based method in integrating sensing, communication and
security simultaneously, and also exhibit significant sampling efficiency as
compared to the exhaustive combinatorial search and enhanced robustness against
the rule-based TM-IRS design method.

</details>


### [421] [Power-Measurement-Based Channel Estimation for Beyond Diagonal RIS](https://arxiv.org/abs/2509.05639)
*Yijie Liu,Weidong Mei,He Sun,Dong Wang,Peilan Wang*

Main category: eess.SP

TL;DR: 提出一种利用用户端接收功率测量值进行信道状态信息（CSI）估计的单层神经网络（NN）方法，以克服现有基于导频信号方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有BD-RIS信道估计方法主要依赖导频信号，增加了系统开销且可能不兼容当前通信协议。

Method: 将接收信号功率表示为单层神经网络，其中权重代表BD-RIS的CSI，并利用反向传播基于不同训练反射系数下收集的功率测量值来恢复CSI。

Result: 所提出的方法能够实现较小的归一化均方误差（NMSE），尤其是在训练反射次数较多的情况下。

Conclusion: 所提出的单层神经网络方法能够有效利用易于获取的接收功率测量值来估计BD-RIS的CSI，克服了现有方法的缺点，并取得了良好的性能。

Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS), with its
enhanced degrees of freedom compared to conventional RIS, has demonstrated
notable potential for enhancing wireless communication performance. However, a
key challenge in employing BD-RIS lies in accurately acquiring its channel
state information (CSI) with both the base station (BS) and users. Existing
BD-RIS channel estimation methods rely mainly on dedicated pilot signals, which
increase system overhead and may be incompatible with current communication
protocols. To overcome these limitations, this letter proposes a new
single-layer neural network (NN)-enabled channel estimation method utilizing
only the easily accessible received power measurements at user terminals. In
particular, we show that the received signal power can be expressed in a form
similar to a single-layer NN, where the weights represent the BD-RIS's CSI.
This structure enables the recovery of CSI using the backward propagation,
based on power measurements collected under varying training reflection
coefficients. Numerical results show that our proposed method can achieve a
small normalized mean square error (NMSE), particularly when the number of
training reflections is large.

</details>


### [422] [Full-Angle Ray Antenna Array and Omnicell Wireless Communication System](https://arxiv.org/abs/2509.05677)
*Xuancheng Zhu,Zhiwen Zhou,Yong Zeng*

Main category: eess.SP

TL;DR: 提出了一种全角度射线天线阵列（RAA）架构和一种由全角度RAA实现的全向小区无线通信模式，旨在降低成本并提高性能。


<details>
  <summary>Details</summary>
Motivation: 与传统的混合模拟/数字波束形成（如ULA和UCA）相比，RAA具有硬件成本低、波束形成增益高、所有方向角分辨率均匀等优点。然而，RAA仅限于特定方向。因此，有必要提出一种全角度RAA架构，以将其优势扩展到所有方向，并在此基础上实现全向小区无线通信系统。

Method: 提出全角度RAA架构，并将RAA的取向角扩展到全角域。在此基础上，提出一种全向小区无线通信系统，其中基站配备全角度RAA并部署在小区中心。

Result: 与传统的基于ULA/UCA的扇区划分无线通信系统相比，所提出的基于全角度RAA的全向小区无线通信系统在空间分辨率和通信速率等关键性能指标方面具有显著优势，并能有效降低用户间干扰，提高成本效益。

Conclusion: 全角度RAA架构和全向小区无线通信系统是一种有前景的无线通信技术，能够克服传统系统的局限性，并提供更好的性能和成本效益。

Abstract: Ray antenna array (RAA) was recently proposed as a novel multi-antenna
architecture that arranges multiple massive cheap antenna elements into simple
uniform linear arrays (sULAs) with different orientations. Compared with
traditional architectures like hybrid analog/digital beamforming with uniform
linear array (ULA) and uniform circular array (UCA), RAA has several promising
advantages such as significantly reduced hardware cost, higher beamforming
gains and the ability of providing uniform angular resolution for all
directions. In this paper, we propose a full-angle RAA architecture and an
innovative omnicell wireless communication paradigm enabled by full-angle RAA.
The proposed full-angle RAA expands RAA's orientation angle to the full angle
domain, such that the RAA's advantages can be exploited to all directions. This
further enables the new concept of omnicell wireless communication system, with
the base station equipped by full-angle RAA and deployed at the center of each
cell. Compared to the conventional cell sectoring wireless communication
system, the proposed omnicell system is expected to not only significantly
reduce the inter-user interference, but also improve the cost efficiency.
Extensive analytical and numerical results are provided to compare those key
performance indicators such as the spatial resolution and the communication
rate of the proposed full-angle RAA based omnicell wireless communication
system against the conventional ULA/UCA-based cell sectoring systems.

</details>


### [423] [Affine Filter Bank Modulation (AFBM): A Novel 6G ISAC Waveform with Low PAPR and OOBE](https://arxiv.org/abs/2509.05683)
*Kuranage Roche Rayan Ranasinghe,Henrique L. Senger,Gustavo P. Gonçalves,Hyeon Seok Rou,Bruno S. Chang,Giuseppe Thadeu Freitas de Abreu,Didier Le Ruyet*

Main category: eess.SP

TL;DR: AFBM是一种用于6G ISAC的新型波形，具有低PAPR和OOBE，并能有效进行通信和传感。


<details>
  <summary>Details</summary>
Motivation: 为了在6G ISAC应用中实现更高的性能，需要开发新的波形。

Method: 提出并分析了AFBM波形，并开发了基于GaBP的符号检测算法和基于EM-PDA的传感估计方法。

Result: AFBM在双重色散信道下相比AFDM具有更低的PAPR和OOBE。通信方面符号检测可靠，传感方面目标识别准确。

Conclusion: AFBM是一种有前途的下一代无线系统波形。

Abstract: We propose the affine filter bank modulation (AFBM) waveform for enhanced
integrated sensing and communications (ISAC) in sixth generation (6G), designed
by drawing on concepts from classical filter bank multicarrier modulation
(FBMC) theory and recent advances in chirp-domain waveforms, particularly
affine frequency division multiplexing (AFDM). Specifically, AFBM exhibits
several desirable properties, with emphasis on its remarkably low
peak-to-average power ratio (PAPR) and reduced out-of-band emission (OOBE) when
benchmarked against the conventional AFDM waveform under doubly-dispersive (DD)
channel conditions. In the communications setting, reliable symbol detection is
achieved using a tailored low-complexity Gaussian belief propagation
(GaBP)-based algorithm, while in the sensing setting, a range and velocity
estimation approach is developed that integrates an expectation maximization
(EM)-assisted probabilistic data association (PDA) framework to accurately
identify surrounding targets. The highlighted performance and benefits of AFBM
are validated through analytical and numerical evaluations, including
conventional metrics such as ambiguity function (AF), bit error rate (BER), and
root mean square error (RMSE), consolidating its position as a promising
waveform for next-generation wireless systems.

</details>


### [424] [Resource Allocation and Beamforming in FIM-Assisted BS and STAR-BD-RIS-Aided NOMA: A Meta-Learning Approach](https://arxiv.org/abs/2509.05692)
*Armin Farhadi,Maryam Cheraghy,Qingqing Wu,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 该研究提出了一种结合了柔性智能超表面（FIM）和非正交多址（NOMA）的无线通信系统，利用双扇区BD-RIS辅助多天线基站，通过优化波束成形、RIS矩阵、NOMA约束和FIM形状来最大化能源效率，并提出Meta-SAC算法解决非凸问题，仿真结果优于基线方案。


<details>
  <summary>Details</summary>
Motivation: 最大化柔性智能超表面（FIM）驱动的无线通信系统中能源效率。

Method: 提出了一种结合了双扇区BD-RIS和NOMA的FIM通信系统。通过联合优化基站波束成形、STAR-BD-RIS矩阵、NOMA约束和FIM表面形状，并提出了一种元软Actor-Critic（Meta-SAC）算法来解决由此产生的非凸优化问题。

Result: 仿真结果表明，Meta-SAC算法优于Meta-DDPG算法，并且FIM辅助设计相比基线方案在能源效率方面取得了显著的提升。

Conclusion: FIM辅助的STAR-BD-RIS-NOMA系统可以显著提高无线通信的能源效率，并且Meta-SAC算法能够有效地解决该系统的优化问题。

Abstract: This study explores a flexible intelligent metasurface (FIM)-based wireless
communication system that integrates simultaneously transmitting and reflecting
beyond diagonal reconfigurable intelligent surfaces (STAR-BD-RIS) with
non-orthogonal multiple access (NOMA). The system features a multi-antenna
FIM-assisted base station (BS) aided by dual-sector BD-RIS. The FIM consists of
cost-effective radiating elements that can independently emit signals and
dynamically adjust their vertical positions ("morphing"). The goal is to
maximize energy efficiency by jointly optimizing BS beamforming, the
STAR-BD-RIS matrix, NOMA constraints, and the FIM surface shape under power
limits. Due to the problem's non-convexity, a meta-soft actor-critic (Meta-SAC)
algorithm is proposed for adaptive optimization. Simulation results show that
Meta-SAC outperforms the Meta-DDPG algorithm, and FIM-assisted designs yield
substantial energy efficiency gains over benchmark schemes.

</details>


### [425] [Optimal Anchor Deployment and Topology Design for Large-Scale AUV Navigation](https://arxiv.org/abs/2509.05903)
*Wei Huang,Junpeng Lu,Tianhe Xu,Jianxu Shu,Hao Zhang,Kaitao Meng,Yanan Wu*

Main category: eess.SP

TL;DR: 水下声学锚的部署拓扑优化对提高AUV导航定位服务质量至关重要。


<details>
  <summary>Details</summary>
Motivation: 水下锚节点部署稀疏、缺乏卫星覆盖且难以维护，对AUV导航造成挑战。

Method: 提出了一种水下锚节点部署拓扑优化方法，并推导了锚节点数量对导航性能的影响规律，以及服务区域覆盖条件。

Result: 通过实验结果评估了优化方法的性能。

Conclusion: 优化的锚节点部署拓扑能够为AUV提供高质量的导航定位服务。

Abstract: Seafloor acoustic anchors are an important component of AUV navigation,
providing absolute updates that correct inertial dead-reckoning. Unlike
terrestrial positioning systems, the deployment of underwater anchor nodes is
usually sparse due to the uneven distribution of underwater users, as well as
the high economic cost and difficult maintenance of underwater equipment. These
anchor nodes lack satellite coverage and cannot form ubiquitous backhaul as
terrestrial nodes do. In this paper, we investigate the optimal anchor
deployment topology to provide high-quality AUV navigation and positioning
services. We first analyze the possible deployment mode in large-scale
underwater navigation system, and formulate a topology optimization for
underwater anchor node deployment. Then, we derive a scaling law about the
influence of anchors in each cluster on the navigation performance within a
given area and demonstrate a service area coverage condition with a high
probability of reaching the destination. Finally, the optimization performance
is evaluated through experimental results.

</details>


### [426] [Active noise cancellation in ultra-low field MRI: distinct strategies for different channels](https://arxiv.org/abs/2509.05955)
*Jiali He,Sheng Shen,Jiamin Wu,Xiaohan Kong,Yamei Dai,Liang Tan,Zheng Xu*

Main category: eess.SP

TL;DR: ULF-MRI系统易受EMI干扰，提出了一种结合空间域逆场重建和通道自适应主动噪声消除的双阶段抑制策略，可抑制EMI超过80%，提高SNR。


<details>
  <summary>Details</summary>
Motivation: 开放环境中的超低场磁共振成像（ULF-MRI）系统极易受到复合电磁干扰（EMI）。不同成像通道由于其独特的耦合特性，对EMI的响应不均匀。

Method: 提出了一种结合前端空间域逆场重建和后端通道自适应主动噪声消除的双阶段抑制策略，以减轻异质耦合效应。

Result: 该方法将EMI抑制了80%以上，显著提高了通道间信噪比（SNR）的一致性，并使融合图像的SNR提高了24%。

Conclusion: 这些发现阐明了EMI耦合的通道依赖性，并建立了有针对性的抑制策略，为未来阵列线圈ULF-MRI系统中的噪声抑制提供了理论基础和实践指导。

Abstract: Ultra-low field magnetic resonance imaging(ULF-MRI) systems operating in open
environments are highly susceptible to composite electromagnetic
interference(EMI). Different imaging channels respond non-uniformly to EMI
owing to their distinct coupling characteristics. Here, we investigate
channel-specific interference pathways in a permanent-magnet-based low-field
MRI system and show that saddle coils are intrinsically more vulnerable to
transverse EMI components than solenoidal coils. To mitigate these
heterogeneous coupling effects, we propose a dual-stage suppression strategy
that combines front-end spatial-domain inverse field reconstruction with
back-end channel-adaptive active noise cancellation. Experiments demonstrate
that this approach suppresses EMI by more than 80%, substantially improves
inter-channel signal-to-noise ratio(SNR) consistency, and enhances the
fused-image SNR by 24%. These findings elucidate the channel-dependent nature
of EMI coupling and establish targeted mitigation strategies, providing both a
theoretical basis and practical guidance for noise suppression in future
array-coil ULF-MRI systems.

</details>


### [427] [The Case for a DNANF 1Pb/s Trans-Atlantic Submarine Cable](https://arxiv.org/abs/2509.05959)
*Pierluigi Poggiolini,Francesco Poletti*

Main category: eess.SP

TL;DR: 低损耗空芯光纤的进展使得建造能够实现每秒1拍字节（Pb/s）单向传输容量的跨大西洋海底光缆成为可能，并能理论上将中继距离延长至200公里。


<details>
  <summary>Details</summary>
Motivation: 探索利用低损耗空芯光纤技术实现超高容量（1 Pb/s）和超长中继距离（200km）的跨大西洋海底光缆的可行性。

Method: 利用低损耗空芯光纤技术，结合双向传输，实现1 Pb/s的单向传输容量，并理论上将中继距离延长至200km。

Result: 低损耗空芯光纤的进展使得建造能够实现1 Pb/s单向传输容量的跨大西洋海底光缆成为可能，并能理论上将中继距离延长至200km。

Conclusion: 低损耗空芯光纤为实现超大容量、超长距离的海底光缆提供了新的可能性。

Abstract: The recent progress in low-loss hollow-core fibers allows to speculate on the
possibility of building a transatlantic submarine cable that can achieve the
goal of 1 Pb/s per direction, leveraging bidirectional transmission, and at the
same time drastically increase span length, theoretically to 200km.

</details>


### [428] [DeepStream: Prototyping Deep Joint Source-Channel Coding for Real-Time Multimedia Transmissions](https://arxiv.org/abs/2509.05971)
*Kaiyi Chi,Yinghui He,Qianqian Yang,Zhiping Jiang,Yuanchao Shu,Zhiqin Wang,Jun Luo,Jiming Chen*

Main category: eess.SP

TL;DR: DeepJSCC是一种用于6G通信的技术，通过端到端学习实现高效可靠的数据传输，尤其在低信噪比环境下表现优异。本文提出了DeepStream系统，将DeepJSCC与OFDM技术相结合，并实现了实时的图像和视频传输，验证了其实际应用的可行性。


<details>
  <summary>Details</summary>
Motivation: 验证DeepJSCC在实际通信环境中的可行性，并提高其在多媒体传输中的效率和鲁棒性。

Method: 提出了一种将特征映射到符号的方法和一种跨子载波预编码的方法，以提高子载波独立性并降低峰均功率比。此外，还提出了一种渐进式编码策略，以适应不同的服务质量要求。

Result: 在10 dB信噪比下，DeepStream在图像传输方面实现了35 dB的PSNR，在视频流方面实现了20 dB的MS-SSIM，显著优于标准方案和直接部署方案。

Conclusion: DeepStream成功地将DeepJSCC应用于实际的OFDM通信系统，实现了高效、鲁棒的多媒体传输，并验证了其在低信噪比环境下的优越性。

Abstract: Deep learning-based joint source-channel coding (DeepJSCC) has emerged as a
promising technique in 6G for enhancing the efficiency and reliability of data
transmission across diverse modalities, particularly in low signal-to-noise
ratio (SNR) environments. This advantage is realized by leveraging powerful
neural networks to learn an optimal end-to-end mapping from the source data
directly to the transmit symbol sequence, eliminating the need for separate
source coding, channel coding, and modulation. Although numerous efforts have
been made towards efficient DeepJSCC, they have largely stayed at numerical
simulations that can be far from practice, leaving the real-world viability of
DeepJSCC largely unverified. To this end, we prototype DeepStream upon
orthogonal frequency division multiplexing (OFDM) technology to offer efficient
and robust DeepJSCC for multimedia transmission. In conforming to OFDM, we
develop both a feature-to-symbol mapping method and a cross-subcarrier
precoding method to improve the subcarrier independence and reduce
peak-to-average power ratio. To reduce system complexity and enable flexibility
in accommodating varying quality of service requirements, we further propose a
progressive coding strategy that adjusts the compression ratio based on latency
with minimal performance loss. We implement DeepStream for real-time image
transmission and video streaming using software-defined radio. Extensive
evaluations verify that DeepStream outperforms both the standard scheme and the
direct deployment scheme. Particularly, at an SNR of 10 dB, DeepStream achieves
a PSNR of 35 dB for image transmission and an MS-SSIM of 20 dB for video
streaming, whereas the standard scheme fails to recover meaningful information.

</details>


### [429] [3D-Image Reconstruction using MIMO-SAR FMCW Radar](https://arxiv.org/abs/2509.05977)
*Ayush Jha,Dhanireddy Chandrika,Chandra Sekhar Seelamantula,Chetan Singh Thakur*

Main category: eess.SP

TL;DR: 该论文提出了一种利用虚拟MIMO FMCW雷达结合SAR技术，实现毫米波高分辨率三维雷达成像的快速时域重建算法。


<details>
  <summary>Details</summary>
Motivation: 传统SAR成像算法主要提取二维信息，限制了其在三维场景重建方面的应用。毫米波雷达技术的发展和工业应用需求推动了三维成像技术的研究。

Method: 结合虚拟MIMO FMCW雷达和SAR技术，提出一种快速时域重建算法。

Result: 实现了毫米波频率下的高分辨率三维雷达成像。

Conclusion: 该算法为先进的雷达成像应用开启了新的可能性。

Abstract: With the advancement of millimeter-wave radar technology, Synthetic Aperture
Radar (SAR) imaging at millimeter-wave frequencies has gained significant
attention in both academic research and industrial applications. However,
traditional SAR imaging algorithms primarily focus on extracting
two-dimensional information from detected targets, which limits their potential
for 3D scene reconstruction. In this work, we demonstrated a fast time-domain
reconstruction algorithm for achieving high-resolution 3D radar imaging at
millimeter-wave (mmWave) frequencies. This approach leverages a combination of
virtual Multiple Input Multiple Output (MIMO) Frequency Modulated Continuous
Wave (FMCW) radar with the precision of Synthetic Aperture Radar (SAR)
technique, setting the stage for a new era of advanced radar imaging
applications.

</details>


### [430] [Quantum Radar for ISAC: Sum-Rate Optimization](https://arxiv.org/abs/2509.06070)
*Abdulmohsen Alsaui,Neel Kanth Kundu,Hyundong Shin,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 该论文提出了一种将量子照明雷达嵌入基站的集成量子传感和经典通信（IQSCC）新框架，以同时支持全双工通信和量子增强目标检测，并在低信噪比下展现出量子优势。


<details>
  <summary>Details</summary>
Motivation: 经典雷达系统在低信噪比条件下存在局限性，限制了集成传感与通信（ISAC）架构的发展。

Method: 提出了一种集成量子照明雷达和经典通信的IQSCC系统，并使用逐次凸逼近技术优化了发射功率和波束形成向量，同时满足雷达传感约束，并通过统计检测理论推导了性能边界。

Result: 仿真结果表明，所提出的IQSCC系统在满足传感要求的同时，通信吞吐量高于传统的ISAC基线。

Conclusion: IQSCC系统能够有效克服经典雷达在低信噪比下的局限性，在通信和传感方面均优于传统ISAC系统。

Abstract: Integrated sensing and communication (ISAC) is emerging as a key enabler for
spectrum-efficient and hardware-converged wireless networks. However, classical
radar systems within ISAC architectures face fundamental limitations under low
signal power and high-noise conditions. This paper proposes a novel framework
that embeds quantum illumination radar into a base station to simultaneously
support full-duplex classical communication and quantum-enhanced target
detection. The resulting integrated quantum sensing and classical communication
(IQSCC) system is optimized via a sum-rate maximization formulation subject to
radar sensing constraints. The non-convex joint optimization of transmit power
and beamforming vectors is tackled using the successive convex approximation
technique. Furthermore, we derive performance bounds for classical and quantum
radar protocols under the statistical detection theory, highlighting the
quantum advantage in low signal-to-interference-plus-noise ratio regimes.
Simulation results demonstrate that the proposed IQSCC system achieves a higher
communication throughput than the conventional ISAC baseline while satisfying
the sensing requirement.

</details>


### [431] [Pinching Antenna System (PASS) Enhanced Covert Communications: Against Warden via Sensing](https://arxiv.org/abs/2509.06170)
*Hao Jiang,Zhaolin Wang,Yuanwei Liu,Arumugam Nallanathan,Zhiguo Ding*

Main category: eess.SP

TL;DR: 本论文提出了一种由捏合天线系统（PASS）赋能的传感辅助隐蔽通信网络，它能动态重构捏合天线（PAs）以靠近合法用户，增强隐蔽性。同时，利用传感功能跟踪恶意监视者的移动，以保护其信道状态信息（CSI）。


<details>
  <summary>Details</summary>
Motivation: 传统的固定位置MIMO阵列无法动态适应用户位置变化，导致隐蔽性不足。需要一种能够动态调整天线位置并有效对抗监视者CSI窃取的通信系统。

Method: 首先，提出一种基于扩展卡尔曼滤波器（EKF）的方法来跟踪监视者。然后，联合设计波束成形、人工噪声（AN）信号和PAs位置以解决隐蔽通信问题。其中，波束成形和AN设计子问题采用子空间法解决，PAs位置优化子问题则采用深度强化学习（DRL）方法。

Result: 1. EKF方法能以低复杂度精确跟踪监视者的CSI。
2. 所提出的解决方案优于贪婪和基于搜索的基准方法。
3. PASS在新的设计自由度下，性能优于传统的全数字MIMO系统。

Conclusion: 所提出的PASS系统通过动态调整天线位置和联合优化波束成形、AN信号，能有效提高通信的隐蔽性，并能对抗监视者的CSI窃取，在性能上优于现有技术。

Abstract: A sensing-aided covert communication network empowered by pinching antenna
systems (PASS) is proposed in this work. Unlike conventional fixed-position
MIMO arrays, PASS dynamically reconfigures its pinching antennas (PAs) closer
to the legitimate user, substantially enhancing covertness. To further secure
the adversary's channel state information (CSI), a sensing function is
leveraged to track the malicious warden's movements. In particular, this paper
first proposes an extended Kalman filter (EKF) based approach to fulfilling the
tracking function. Building on this, a covert communication problem is
formulated with a joint design of beamforming, artificial noise (AN) signals,
and the position of PAs. Then, the beamforming and AN design subproblems are
resolved jointly with a subspace approach, while the PA position optimization
subproblem is handled by a deep reinforcement learning (DRL) approach by
treating the evolution of the warden's mobility status as a temporally
corrected process. Numerical results are presented and demonstrate that: i) the
EKF approach can accurately track the warden's CSI with low complexity, ii) the
effectiveness of the proposed solution is verified by its outperformance over
the greedy and searching-based benchmarks, and iii) with new design degrees of
freedom (DoFs), the performance of PASS is superior to the conventional
fully-digital MIMO systems.

</details>


### [432] [Human Body Weight Estimation Through Music-Induced Bed Vibrations](https://arxiv.org/abs/2509.06257)
*Yuyan Wu,Jiale Zhang,Moon Lee,Cherrelle Smith,Xinyi Li,Ankur Senapati,Pei Zhang,Hae Young Noh*

Main category: eess.SP

TL;DR: MelodyBedScale利用音乐诱导的床体振动来非侵入性地快速估计体重，通过分析振动传递函数，并结合物理信息神经网络，在11名参与者身上实现了高达1.55公斤的平均绝对误差。


<details>
  <summary>Details</summary>
Motivation: 快速准确的体重估算对于急诊医疗至关重要，因为传统方法（如称重秤、长度估算带或转移称重秤）对于无法移动的患者来说不实用、不准确或耗时。因此，需要一种非侵入性、快速的床旁体重估算系统。

Method: MelodyBedScale系统利用音乐引起的床体振动来估算体重。该系统通过放置在床体相对两侧的振动传感器捕捉体重影响下的床体振动传递函数。首先，识别出对体重敏感的频率范围，并创作包含这些频率高能量信号的柔和的、临床可接受的音乐，通过安装在床上的扬声器播放以引起床体振动。其次，为了在数据有限的情况下高效捕捉复杂的体重-振动关系并提高对新个体和体重的泛化能力，研究人员对体重-振动关系进行了理论分析，并将结果整合到神经网络的激活函数中，以实现物理信息驱动的体重回归。

Result: MelodyBedScale系统在木制和钢制床上对11名参与者进行了评估，实现了高达1.55公斤的平均绝对误差。

Conclusion: MelodyBedScale提供了一种非侵入性、快速的床旁体重估算方法，能够有效解决传统方法的局限性，并在实验中取得了较高的精度。

Abstract: Rapid and accurate body weight estimation is critical in emergency medical
care, as it directly influences treatment decisions, such as drug dosing,
defibrillation energy selection, and fluid resuscitation. Traditional methods
such as stand-on scales, length-based tapes, or transfer-based weighing scales
are often impractical for immobilized patients, inaccurate, or labor-intensive
and time-consuming. This paper introduces MelodyBedScale, a non-intrusive and
rapid on-bed weight estimation system that leverages bed vibration induced by
music. The core insight is that body weight affects the vibration transfer
function of the bed-body system, which is captured using vibration sensors
placed on opposite sides of the bed. First, we identify weight-sensitive
frequency bands and compose clinically acceptable soft, natural music with high
signal energy in these frequency bands. This music is then played through a
speaker mounted on the bed to induce bed vibrations. Additionally, to
efficiently capture the complex weight-vibration relationship with limited data
and enhance generalizability to unseen individuals and weights, we
theoretically analyze the weight-vibration relationship and integrate the
results into the activation functions of the neural network for
physics-informed weight regression. We evaluated MelodyBedScale on both wooden
and steel beds across 11 participants, achieving a mean absolute error of up to
1.55 kg.

</details>


### [433] [Optimal Distortion-Aware Multi-User Power Allocation for Massive MIMO Networks](https://arxiv.org/abs/2509.06491)
*Siddarth Marwaha,Pawel Kryszkiewicz,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 在M-MIMO系统中，提出了一种考虑PA失真的功率分配策略，通过交替优化算法解决非凸问题，仿真结果显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的资源分配方案为简化起见，忽略了PA失真，导致结果不准确或自由度降低，未能达到全局性能。

Method: 在M-MIMO系统中，提出了一种考虑PA失真的功率分配策略。使用软限制PA模型，在瑞利衰落信道下，推导出SNDR并构建功率分配问题。将问题分解为总功率分配和用户间功率分配两个子问题，并提出交替优化算法求解。

Result: 与忽略失真的现有方法相比，该方法在64天线和512天线基站下，分别实现了中值4倍和50%的总速率增益。

Conclusion: PA引入的失真提供了一个无显式发射功率约束的SNDR高效操作点。所提出的交替优化算法能够有效求解该问题，并在M-MIMO系统中实现显著的性能提升。

Abstract: Real-world wireless transmitter front-ends exhibit certain nonlinear
behavior, e.g., signal clipping by a Power Amplifier (PA). Although many
resource allocation solutions do not consider this for simplicity, it leads to
inaccurate results or a reduced number of degrees of freedom, not achieving the
global performance. In this work, we propose an optimal PA distortion-aware
power allocation strategy in a downlink orthogonal frequency division multiplex
(OFDM) based massive multiple-input multiple-output (M-MIMO) system. Assuming a
soft-limiter PA model, where the transmission occurs under small-scale
independent and identically distributed (i.i.d) Rayleigh fading channel, we
derive the wideband signal-to-noise-and-distortion ratio (SNDR) and formulate
the power allocation problem. Most interestingly, the distortion introduced by
the PA leads to an SNDR-efficient operating point without explicit transmit
power constraints. While the optimization problem is non-convex, we decouple it
into a non-convex total power allocation problem and a convex power
distribution problem among the users (UEs). We propose an alternating
optimization algorithm to find the optimum solution. Our simulation results
show significant sum-rate gains over existing distortion-neglecting solutions,
e.g., a median 4 times increase and a median 50\% increase for a 64-antenna and
512-antenna base station serving 60 users, respectively.

</details>


### [434] [Synesthesia of Machines (SoM)-Aided LiDAR Point Cloud Transmission for Collaborative Perception](https://arxiv.org/abs/2509.06506)
*Ensong Liu,Rongqing Zhang,Xiang Cheng,Jian Tang*

Main category: eess.SP

TL;DR: LiDAR点云数据量大，需要高效传输以支持多智能体协同感知。本文提出了一种基于机器通感（SoM）的LiDAR点云特征传输（LPC-FT）系统，该系统能高效、鲁棒地传输点云数据。


<details>
  <summary>Details</summary>
Motivation: 为了支持多智能体协同感知，需要解决LiDAR点云传输效率和鲁棒性问题。

Method: 提出LPC-FT系统，包括：1. 密度保持的深度点云压缩方法，将点云编码为高效表示。2. 基于自注意力的信道编码模块，增强LiDAR点云特征。3. 基于交叉注意力的特征融合模块，整合收发器特征。4. 利用非线性激活层和迁移学习，提高深度神经网络在数字信道噪声下的训练。

Result: 与传统的基于八叉树的压缩和信道编码方法相比，LPC-FT更鲁棒、更有效。与最先进的基于深度学习的压缩技术和现有的语义通信方法相比，LPC-FT平均将Chamfer距离降低了30%，并将PSNR提高了1.9 dB。

Conclusion: LPC-FT凭借其卓越的重建性能和对抗信道变化的能力，有望支持协同感知任务。

Abstract: Collaborative perception enables more accurate and comprehensive scene
understanding by learning how to share information between agents, with LiDAR
point clouds providing essential precise spatial data. Due to the substantial
data volume generated by LiDAR sensors, efficient point cloud transmission is
essential for low-latency multi-agent collaboration. In this work, we propose
an efficient, robust and applicable LiDAR point cloud transmission system via
the Synesthesia of Machines (SoM), termed LiDAR Point Cloud Feature
Transmission (LPC-FT), to support collaborative perception among multiple
agents. Specifically, we employ a density-preserving deep point cloud
compression method that encodes the complete point cloud into a downsampled
efficient representation. To mitigate the effects of the wireless channel, we
design a channel encoder module based on self-attention to enhance LiDAR point
cloud features and a feature fusion module based on cross-attention to
integrate features from transceivers. Furthermore, we utilize the nonlinear
activation layer and transfer learning to improve the training of deep neural
networks in the presence the digital channel noise. Experimental results
demonstrate that the proposed LPC-FT is more robust and effective than
traditional octree-based compression followed by channel coding, and
outperforms state-of-the-art deep learning-based compression techniques and
existing semantic communication methods, reducing the Chamfer Distance by 30%
and improving the PSNR by 1.9 dB on average. Owing to its superior
reconstruction performance and robustness against channel variations, LPC-FT is
expected to support collaborative perception tasks.

</details>


### [435] [Integrated Detection and Tracking Based on Radar Range-Doppler Feature](https://arxiv.org/abs/2509.06569)
*Chenyu Zhang,Yuanhang Wu,Xiaoxi Ma,Wei Yi*

Main category: eess.SP

TL;DR: InDT是一种新的雷达系统集成检测和跟踪方法，通过利用雷达特征来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的雷达联合检测和跟踪方法在利用雷达信号潜力、恒定虚警率模型表示能力、复杂场景描绘和跟踪器信息获取方面存在局限性。

Method: InDT方法包括一个雷达信号检测网络架构和一个基于检测辅助的跟踪器。检测器从目标距离-多普勒（RD）矩阵中提取特征，并通过特征增强模块和检测头返回目标位置。跟踪器根据检测置信度自适应地更新卡尔曼滤波器的测量噪声协方差，并利用目标RD特征的余弦距离相似性来增强数据关联过程。

Result: 该方法在模拟数据和公开数据集上都得到了验证。

Conclusion: InDT方法通过集成雷达特征，克服了现有方法的局限性，提高了雷达系统的检测和跟踪能力。

Abstract: Detection and tracking are the basic tasks of radar systems. Current joint
detection tracking methods, which focus on dynamically adjusting detection
thresholds from tracking results, still present challenges in fully utilizing
the potential of radar signals. These are mainly reflected in the limited
capacity of the constant false-alarm rate model to accurately represent
information, the insufficient depiction of complex scenes, and the limited
information acquired by the tracker. We introduce the Integrated Detection and
Tracking based on radar feature (InDT) method, which comprises a network
architecture for radar signal detection and a tracker that leverages detection
assistance. The InDT detector extracts feature information from each
Range-Doppler (RD) matrix and then returns the target position through the
feature enhancement module and the detection head. The InDT tracker adaptively
updates the measurement noise covariance of the Kalman filter based on
detection confidence. The similarity of target RD features is measured by
cosine distance, which enhances the data association process by combining
location and feature information. Finally, the efficacy of the proposed method
was validated through testing on both simulated data and publicly available
datasets.

</details>


### [436] [Towards In-Air Ultrasonic QR Codes: Deep Learning for Classification of Passive Reflector Constellations](https://arxiv.org/abs/2509.06615)
*Wouter Jansen,Jan Steckel*

Main category: eess.SP

TL;DR: 该论文提出一种使用声学反射器星座作为编码标签的多标签卷积神经网络（CNN）方法，用于从三维声纳测量中同时识别多个近距离反射器，并在小数据集上验证了其可行性，同时还探讨了自适应波束成形技术用于分离单个反射器进行分类。


<details>
  <summary>Details</summary>
Motivation: 为了在视觉传感器失效的环境中为自主系统提供可靠的替代方案，并提高信息容量。

Method: 提出一种多标签卷积神经网络（CNN）来同时识别多个近距离反射器；研究自适应波束成形与零位导引技术来分离单个反射器进行单标签分类。

Result: 在小数据集上初步验证了所提出方法的可行性，能够解码复杂的声学模式。

Conclusion: 所提出的方法在提高声学地标系统的信息熵以及实现精确鲁棒的检测和分类方面具有潜力，并指出了未来的研究方向和局限性。

Abstract: In environments where visual sensors falter, in-air sonar provides a reliable
alternative for autonomous systems. While previous research has successfully
classified individual acoustic landmarks, this paper takes a step towards
increasing information capacity by introducing reflector constellations as
encoded tags. Our primary contribution is a multi-label Convolutional Neural
Network (CNN) designed to simultaneously identify multiple, closely spaced
reflectors from a single in-air 3D sonar measurement. Our initial findings on a
small dataset confirm the feasibility of this approach, validating the ability
to decode these complex acoustic patterns. Secondly, we investigated using
adaptive beamforming with null-steering to isolate individual reflectors for
single-label classification. Finally, we discuss the experimental results and
limitations, offering key insights and future directions for developing
acoustic landmark systems with significantly increased information entropy and
their accurate and robust detection and classification.

</details>


### [437] [Near-Threshold Voltage Massive MIMO Computing](https://arxiv.org/abs/2509.06651)
*Mikael Rinkinen,Mehdi Safarpour,Shahriar Shahabuddin,Olli Silven,Lauri Koskinen*

Main category: eess.SP

TL;DR: 本文提出将算法型容错（ABFT）应用于大规模MIMO信号处理，以解决近阈值计算（NTC）的可靠性问题，并实现了36%的功耗节省，计算开销仅为3%。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统能效高，但计算功耗大；NTC能降低能耗但易出错；传统NTC方法复杂且难以在高频下实现。ABFT作为一种轻量级、纯软件实现的检测方法，有望解决这些问题。

Method: 通过修改牛顿迭代MIMO算法，集成ABFT来检测计算错误，并与NTC结合，在FPGA上实现了MIMO加速器。

Result: 在足够大的问题规模下，提出的方法实现了36%的功耗节省，计算开销平均仅为3%。

Conclusion: 结合ABFT和近阈值操作为实现高能效、高可靠性的大规模MIMO处理器提供了一条可行路径。

Abstract: Massive MIMO systems have the potential to significantly enhance spectral
efficiency, yet their widespread integration is hindered by the high power
consumption of the underlying computations. This paper explores the
applicability and effectiveness of Algorithm-Based Fault Tolerance (ABFT) for
massive MIMO signal processing to tackle the reliability challenge of Near
Threshold Computing (NTC). We propose modifying matrix arithmetic Newton
iteration MIMO algorithm to seamlessly integrate ABFT to detect any
computational errors by inspecting the final result. The overhead from ABFT
depends largely on the matrix dimensions, which in this context are dictated by
the number of user equipments involved in the computation. NTC is a promising
strategy for reducing the energy consumption in digital circuits by operating
transistors at extremely reduced voltages. However, NTC is highly susceptible
to variations in Process, Voltage, and Temperature (PVT) which can lead to
increased error rates in computations. Traditional techniques for enabling NTC,
such as dynamic voltage and frequency scaling guided by circuit level timing
error detection methods, introduce considerable hardware complexity and are
difficult to implement at high clock frequencies. In this context ABFT has
emerged as a lightweight error detection method tailored for matrix operations
without requiring any modifications on circuit-level and can be implemented
purely in software.A MIMO accelerator was implemented on a reconfigurable
hardware platform. Experimental results demonstrate that for sufficiently large
problem sizes, the proposed method achieves a 36% power saving compared to
baseline, with only an average of 3% computational overhead, at default clock
frequency. These results indicate that combining ABFT with near-threshold
operation provides a viable path toward energy-efficient and robust massive
MIMO processors.

</details>


### [438] [SE and EE Tradeoff in Active STAR-RIS Assisted Systems With Hardware Impairments](https://arxiv.org/abs/2509.06662)
*Ao Huang,Xidong Mu,Li Guo,Guangyu Zhu*

Main category: eess.SP

TL;DR: 本论文研究在存在实际收发器硬件损伤（HWIs）的情况下，有源同时传输和反射可重构智能表面（STAR-RIS）辅助通信系统中资源效率最大化的问题。


<details>
  <summary>Details</summary>
Motivation: 在有源STAR-RIS辅助通信系统中，在实际硬件损伤下，实现系统频谱效率（SE）和能量效率（EE）之间的最优权衡。

Method: 首先应用二次变换方法将分数目标函数简化，然后开发交替优化算法来迭代更新基站（BS）和STAR-RIS的波束成形系数。

Result: 仿真结果表明，在硬件损伤存在的情况下，所提出的方案优于其他基线方案。此外，还分析了不同发射功率预算下可实现的SE-EE区域的变化情况。

Conclusion: 所提出的交替优化算法能够有效地在存在硬件损伤的情况下，实现STAR-RIS辅助通信系统的SE-EE权衡。

Abstract: This paper investigates the problem of resource efficiency maximization in an
active simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS) assisted communication system under practical transceiver
hardware impairments (HWIs). We aim to obtain an optimal tradeoff between
system spectral efficiency (SE) and energy efficiency (EE), by jointly
optimizing the base station (BS) transmit beamforming and the active STAR-RIS
beamforming. To tackle the challenges in the fractional objective function, we
begin by applying the quadratic transformation method to simplify it into a
manageable form. An alternating optimization-based algorithm is then developed
to iteratively update the BS and STAR-RIS beamforming coefficients. Simulation
results demonstrate that the proposed scheme performs better than other
baseline schemes in the presence of HWIs. Moreover, the variation of the
achievable SE-EE region with different transmit power budgets is analyzed.

</details>


### [439] [ISAC Imaging by Channel State Information using Ray Tracing for Next Generation 6G](https://arxiv.org/abs/2509.06672)
*Ahmad Bazzi,Mingjun Ying,Ojas Kanhere,Theodore S. Rappaport,Marwa Chafii*

Main category: eess.SP

TL;DR: 该论文提出了一个利用信道状态信息（CSI）进行集成传感与通信（ISAC）成像的框架，通过优化算法实现精确的三维几何重建。


<details>
  <summary>Details</summary>
Motivation: ISAC是6G无线系统的关键技术，能够融合通信和环境感知。本研究旨在利用ISAC技术实现高精度的环境感知和成像。

Method: 提出了一种基于CSI的ISAC成像框架，利用NYURay射线追踪器在6.75 GHz下获取信道信息。通过提取CSI的路径分量，融合角度和延迟信息，将每个可分辨的多径分量转换为三维反射点。核心是提出了一种两段式反射点优化算法，独立估计反射点到发送端（TX）和接收端（RX）的路径长度，从而实现精确的几何重建。通过聚合多个TX和RX位置对得到的等效反射点（ERP），生成三维点云以表示目标。

Result: 实验结果表明，所提出的ISAC成像框架能够精确地重建物体的表面、边缘和曲面特征。该研究首次在6.75 GHz频率下，利用无线射线追踪技术实现了多重反弹ISAC成像。

Conclusion: 本研究成功展示了一种基于CSI的ISAC成像方法，并通过优化算法实现了精确的三维物体重建，为ISAC在环境感知领域的应用提供了有力的证明。

Abstract: Integrated sensing and communications (ISAC) is emerging as a cornerstone
technology for sixth generation (6G) wireless systems, unifying connectivity
and environmental mapping through shared hardware, spectrum, and waveforms. The
following paper presents an ISAC imaging framework utilizing channel state
information (CSI) per-path components, transmitter (TX) positions, and receiver
(RX) positions obtained from the calibrated NYURay ray tracer at 6.75 GHz in
the upper mid-band. Our work shows how each resolvable multipath component can
be extracted from CSI estimation and cast into an equivalent three-dimensional
reflection point by fusing its angle and delay information, which is useful and
challenging for multi-bounce reflections. The primary contribution of the paper
is the two-segment reflection point optimization algorithm, which independently
estimates the path lengths from the TX position and RX position to an
equivalent reflection point (ERP) on the object surface, thus enabling precise
geometric reconstruction. Subsequently, we aggregate the ERPs derived from
multiple pairs of TX and RX positions, generating dense three dimensional point
clouds representing the objects in the channel. Experimental results validate
that the proposed ISAC imaging framework accurately reconstructs object
surfaces, edges, and curved features. To the best of our knowledge, this paper
provides the first demonstration of multi bounce ISAC imaging using wireless
ray tracing at 6.75 GHz.

</details>


### [440] [RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator](https://arxiv.org/abs/2509.06751)
*Weicheng Gao*

Main category: eess.SP

TL;DR: 开发了一个基于模型的FMCW雷达HAR模拟器，以克服雷达HAR数据集获取的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决获取多样化、高保真雷达数据集以支持鲁棒雷达人类活动识别（HAR）算法开发的挑战。

Method: 开发了一个集成13散射体运动学模型的模型驱动的FMCW雷达HAR模拟器，模拟12种不同的活动。该模拟器包括动态雷达散射截面（RCS）、自由空间或穿墙传播以及校准的噪声基底。对模拟的原始数据应用了移动目标指示（MTI）、批量多普勒补偿和Savitzky-Golay去噪等预处理步骤。然后，使用短时傅里叶变换（STFT）和傅里叶同步压缩变换（FSST）生成高分辨率距离-时间图（RTM）和多普勒-时间图（DTMs）。最后，提出了一个新颖的神经网络方法来验证雷达HAR的有效性。

Result: 模拟器成功生成了高保真且独特的多普勒特征，为雷达HAR算法的设计和验证提供了有价值的工具。

Conclusion: 所提出的基于模型的FMCW雷达HAR模拟器能够生成高保真且独特的多普勒特征，可用于雷达HAR算法的设计和验证。

Abstract: Radar-based human activity recognition (HAR) is a pivotal research area for
applications requiring non-invasive monitoring. However, the acquisition of
diverse and high-fidelity radar datasets for robust algorithm development
remains a significant challenge. To overcome this bottleneck, a model-based
frequency-modulated continuous wave (FMCW) radar HAR simulator is developed.
The simulator integrates an anthropometrically scaled $13$-scatterer kinematic
model to simulate $12$ distinct activities. The FMCW radar echo model is
employed, which incorporates dynamic radar cross-section (RCS), free-space or
through-the-wall propagation, and a calibrated noise floor to ensure signal
fidelity. The simulated raw data is then processed through a complete pipeline,
including moving target indication (MTI), bulk Doppler compensation, and
Savitzky-Golay denoising, culminating in the generation of high-resolution
range-time map (RTM) and Doppler-time maps (DTMs) via both short-time Fourier
transform (STFT) and Fourier synchrosqueezed transform (FSST). Finally, a novel
neural network method is proposed to validate the effectiveness of the radar
HAR. Numerical experiments demonstrate that the simulator successfully
generates high-fidelity and distinct micro-Doppler signature, which provides a
valuable tool for radar HAR algorithm design and validation. The installer of
this simulator is released at:
\href{https://github.com/JoeyBGOfficial/RadHARSimulatorV1-Model-Based-FMCW-Radar-Human-Activity-Recognition-Simulator}{Github/JoeyBGOfficial/RadHARSimulatorV1}.

</details>


### [441] [Green Learning for STAR-RIS mmWave Systems with Implicit CSI](https://arxiv.org/abs/2509.06820)
*Yu-Hsiang Huang,Po-Heng Chou,Wan-Jen Huang,Walid Saad,C. -C. Jay Kuo*

Main category: eess.SP

TL;DR: 本文提出了一种基于绿色学习（GL）的预编码框架，用于同时传输和反射（STAR-RIS）辅助的毫米波（mmWave）MIMO广播系统。该框架旨在提高频谱效率并降低功耗，同时避免了对信道状态信息（CSI）的依赖。


<details>
  <summary>Details</summary>
Motivation: 为了应对6G网络对环境可持续性的日益关注，本研究提出了一种广播传输架构，适用于多个用户共享相同信息的场景，旨在提高频谱效率并降低功耗。

Method: 提出了一种基于绿色学习（GL）的框架，该框架直接在接收到的上行链路导频信号上操作，无需明确的CSI估计。该框架集成了子空间近似与调整偏差（Saab）、相关特征检验（RFT）的监督特征选择以及eXtreme梯度提升（XGBoost）的决策学习，以联合预测STAR-RIS系数和发射预编码器。

Result: 仿真结果表明，所提出的GL方法与BCD和基于DL的方法相比，具有相当的频谱效率，同时将浮点运算（FLOPs）减少了四个数量级以上。

Conclusion: 所提出的GL方法因其轻量级设计和高能效，非常适合在对能量和硬件有严格限制的广播场景中进行实时部署。

Abstract: In this paper, a green learning (GL)-based precoding framework is proposed
for simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS)-aided millimeter-wave (mmWave) MIMO broadcasting systems.
Motivated by the growing emphasis on environmental sustainability in future 6G
networks, this work adopts a broadcasting transmission architecture for
scenarios where multiple users share identical information, improving spectral
efficiency and reducing redundant transmissions and power consumption.
Different from conventional optimization methods, such as block coordinate
descent (BCD) that require perfect channel state information (CSI) and
iterative computation, the proposed GL framework operates directly on received
uplink pilot signals without explicit CSI estimation. Unlike deep learning (DL)
approaches that require CSI-based labels for training, the proposed GL approach
also avoids deep neural networks and backpropagation, leading to a more
lightweight design. Although the proposed GL framework is trained with
supervision generated by BCD under full CSI, inference is performed in a fully
CSI-free manner. The proposed GL integrates subspace approximation with
adjusted bias (Saab), relevant feature test (RFT)-based supervised feature
selection, and eXtreme gradient boosting (XGBoost)-based decision learning to
jointly predict the STAR-RIS coefficients and transmit precoder. Simulation
results show that the proposed GL approach achieves competitive spectral
efficiency compared to BCD and DL-based models, while reducing floating-point
operations (FLOPs) by over four orders of magnitude. These advantages make the
proposed GL approach highly suitable for real-time deployment in energy- and
hardware-constrained broadcasting scenarios.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [442] [Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation](https://arxiv.org/abs/2509.05355)
*Ahmed R. Sadik,Muhammad Ashfaq,Niko Mäkitalo,Tommi Mikkonen*

Main category: cs.RO

TL;DR: 使用大型语言模型实现自适应无人机集群架构，以应对灾难响应任务中的动态和不可预测环境，提高了可扩展性、能源效率和连接性。


<details>
  <summary>Details</summary>
Motivation: 传统固定架构在动态和不可预测的灾难响应环境中存在效率低下、能源消耗和连接性问题，需要开发灵活、可扩展且强大的协调系统。

Method: 提出一种自适应架构，利用大型语言模型根据任务复杂性、集群规模和通信稳定性等实时任务参数动态选择中心化、分层或整体等最优架构。

Result: 与传统的静态模型相比，自适应架构在可扩展性、能源效率和连接性方面表现更优。

Conclusion: 该方法有潜力为现实世界的灾难响应场景提供可扩展、自适应且有弹性的解决方案。

Abstract: The deployment of autonomous drone swarms in disaster response missions
necessitates the development of flexible, scalable, and robust coordination
systems. Traditional fixed architectures struggle to cope with dynamic and
unpredictable environments, leading to inefficiencies in energy consumption and
connectivity. This paper addresses this gap by proposing an adaptive
architecture for drone swarms, leveraging a Large Language Model to dynamically
select the optimal architecture as centralized, hierarchical, or holonic based
on real time mission parameters such as task complexity, swarm size, and
communication stability. Our system addresses the challenges of scalability,
adaptability, and robustness,ensuring efficient energy consumption and
maintaining connectivity under varying conditions. Extensive simulations
demonstrate that our adaptive architecture outperforms traditional static
models in terms of scalability, energy efficiency, and connectivity. These
results highlight the potential of our approach to provide a scalable,
adaptable, and resilient solution for real world disaster response scenarios.

</details>


### [443] [ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory](https://arxiv.org/abs/2509.05314)
*Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Shanghang Zhang*

Main category: cs.RO

TL;DR: ManipDreamer3D利用3D轨迹规划和3D占用图生成机器人操作视频，解决了2D轨迹的空间模糊性问题，并达到了优于现有方法的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 数据稀疏性是机器人操作领域的重大挑战，而现有的基于2D轨迹的扩散模型存在3D空间模糊性问题。

Method: ManipDreamer3D首先从输入图像重建3D占用图，然后规划优化的3D末端执行器轨迹，接着利用潜在编辑技术结合初始图像和3D轨迹生成视频序列，并使用专门训练的轨迹到视频扩散模型生成机器人抓取和放置视频。

Result: 实验结果表明，与现有方法相比，ManipDreamer3D具有优越的视觉质量。

Conclusion: ManipDreamer3D能够生成具有自主规划的、逼真的3D轨迹的机器人视频，显著减少了对人工干预的需求。

Abstract: Data scarcity continues to be a major challenge in the field of robotic
manipulation. Although diffusion models provide a promising solution for
generating robotic manipulation videos, existing methods largely depend on 2D
trajectories, which inherently face issues with 3D spatial ambiguity. In this
work, we present a novel framework named ManipDreamer3D for generating
plausible 3D-aware robotic manipulation videos from the input image and the
text instruction. Our method combines 3D trajectory planning with a
reconstructed 3D occupancy map created from a third-person perspective, along
with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D
first reconstructs the 3D occupancy representation from the input image and
then computes an optimized 3D end-effector trajectory, minimizing path length
while avoiding collisions. Next, we employ a latent editing technique to create
video sequences from the initial image latent and the optimized 3D trajectory.
This process conditions our specially trained trajectory-to-video diffusion
model to produce robotic pick-and-place videos. Our method generates robotic
videos with autonomously planned plausible 3D trajectories, significantly
reducing human intervention requirements. Experimental results demonstrate
superior visual quality compared to existing methods.

</details>


### [444] [Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles](https://arxiv.org/abs/2509.05315)
*Petros Loukas,David Bassir,Savvas Chatzichristofis,Angelos Amanatiadis*

Main category: cs.RO

TL;DR: LLMs are evaluated on real-world edge cases for autonomous vehicles, showing potential as anomaly detectors.


<details>
  <summary>Details</summary>
Motivation: Evaluate LLMs on real-world edge cases where current autonomous vehicles fail, addressing the limitation of current evaluations on synthetic or manually driven datasets without ground truth.

Method: The proposed architecture couples an open vocabulary object detector with prompt engineering and LLM contextual reasoning. Several state-of-the-art models are evaluated against real edge cases.

Result: Qualitative comparison results and a discussion on the findings are provided.

Conclusion: LLMs show potential as anomaly detectors in autonomous vehicles when evaluated on real-world edge cases using the proposed architecture.

Abstract: The rapid evolution of large language models (LLMs) has pushed their
boundaries to many applications in various domains. Recently, the research
community has started to evaluate their potential adoption in autonomous
vehicles and especially as complementary modules in the perception and planning
software stacks. However, their evaluation is limited in synthetic datasets or
manually driving datasets without the ground truth knowledge and more
precisely, how the current perception and planning algorithms would perform in
the cases under evaluation. For this reason, this work evaluates LLMs on
real-world edge cases where current autonomous vehicles have been proven to
fail. The proposed architecture consists of an open vocabulary object detector
coupled with prompt engineering and large language model contextual reasoning.
We evaluate several state-of-the-art models against real edge cases and provide
qualitative comparison results along with a discussion on the findings for the
potential application of LLMs as anomaly detectors in autonomous vehicles.

</details>


### [445] [Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks](https://arxiv.org/abs/2509.05338)
*Atsushi Masumori,Norihiro Maruyama,Itsuki Doi,johnsmith,Hiroki Sato,Takashi Ikegami*

Main category: cs.RO

TL;DR: Plantbot是一个结合了活体植物和移动机器人的混合生命体，通过大型语言模型（LLM）模块进行交互，实现了生物与人工智能的融合，能够自主感知并响应环境变化。


<details>
  <summary>Details</summary>
Motivation: 通过LLM作为混合接口，利用自然语言作为通用协议，协调生物体和机器人的行为，实现生物与人工智能的融合，为人工智能生命模型提供新的范式。

Method: 构建了一个包含感知、视觉、对话和行动LLM模块的混合生命体Plantbot。各模块异步运行，通过自然语言通信，将植物状态（如土壤湿度、温度、视觉信息）转化为协调系统行为的语言信息，并最终驱动机器人执行相应动作。

Result: Plantbot能够将植物状态转化为机器人动作，形成一个集成了生物和机器人元素的传感器-动作循环，具备了自主性和适应性，能够自主响应环境变化。

Conclusion: LLM驱动的去中心化模块协调能够实现生物和人工智能系统之间的新型交互，为构建新型人工智能生命体提供了可能性。

Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a
mobile robot through a network of large language model (LLM) modules. Each
module - responsible for sensing, vision, dialogue, or action - operates
asynchronously and communicates via natural language, enabling seamless
interaction across biological and artificial domains. This architecture
leverages the capacity of LLMs to serve as hybrid interfaces, where natural
language functions as a universal protocol, translating multimodal data (soil
moisture, temperature, visual context) into linguistic messages that coordinate
system behaviors. The integrated network transforms plant states into robotic
actions, installing normativity essential for agency within the sensor-motor
loop. By combining biological and robotic elements through LLM-mediated
communication, Plantbot behaves as an embodied, adaptive agent capable of
responding autonomously to environmental conditions. This approach suggests
possibilities for a new model of artificial life, where decentralized, LLM
modules coordination enable novel interactions between biological and
artificial systems.

</details>


### [446] [INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing](https://arxiv.org/abs/2509.05345)
*Jiasheng Qu,Zhuo Huang,Dezhao Guo,Hailin Sun,Aoran Lyu,Chengkai Dai,Yeung Yam,Guoxin Fang*

Main category: cs.RO

TL;DR: INF-3DP框架通过隐式神经场（INFs）实现了多轴3D打印的通用、可扩展计算，统一了工具路径生成和无碰撞运动规划。它将模型表示为符号距离场，并将打印目标（如无支撑打印、表面质量、挤出控制）编码到隐式引导场的优化中。该方法通过隐式场插值生成内外路径，并联合优化打印序列和运动。INF-3DP比基于显式表示的方法快两个数量级，并显著减少了路径误差。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种通用、可扩展的计算框架，用于多轴3D打印，该框架能够统一工具路径生成和无碰撞运动规划，同时直接处理制造目标。

Method: 使用隐式神经场（INFs）表示模型，将打印目标编码到隐式引导场的优化中。通过隐式场插值生成工具路径，并联合优化打印序列和多轴运动。将打印对象构建为时变SDF，支持基于INF的运动规划中的可微碰撞处理。

Result: INF-3DP实现了高达两个数量级的加速，并显著减少了路径点到表面的误差。在复杂模型上进行了验证，并通过物理制造实验证明了其效率。

Conclusion: INF-3DP是一个通用、可扩展的计算框架，通过隐式神经场有效解决了多轴3D打印中的工具路径生成和运动规划问题，并在速度和精度方面取得了显著改进。

Abstract: We introduce a general, scalable computational framework for multi-axis 3D
printing based on implicit neural fields (INFs) that unifies all stages of
toolpath generation and global collision-free motion planning. In our pipeline,
input models are represented as signed distance fields, with fabrication
objectives such as support-free printing, surface finish quality, and extrusion
control being directly encoded in the optimization of an implicit guidance
field. This unified approach enables toolpath optimization across both surface
and interior domains, allowing shell and infill paths to be generated via
implicit field interpolation. The printing sequence and multi-axis motion are
then jointly optimized over a continuous quaternion field. Our continuous
formulation constructs the evolving printing object as a time-varying SDF,
supporting differentiable global collision handling throughout INF-based motion
planning. Compared to explicit-representation-based methods, INF-3DP achieves
up to two orders of magnitude speedup and significantly reduces
waypoint-to-surface error. We validate our framework on diverse, complex models
and demonstrate its efficiency with physical fabrication experiments using a
robot-assisted multi-axis system.

</details>


### [447] [Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning](https://arxiv.org/abs/2509.05356)
*Justus Huebotter,Pablo Lanillos,Marcel van Gerven,Serge Thill*

Main category: cs.RO

TL;DR: 尽管在训练SNN进行分类方面取得了进展，但其在连续运动控制方面的应用仍然有限。本研究表明，完全SNN架构可以进行端到端的训练，以在连续环境中控制具有多个自由度的机械臂。


<details>
  <summary>Details</summary>
Motivation: SNN在连续运动控制方面的应用有限。

Method: 结合了Leaky Integrate-and-Fire动力学和代理梯度，对动力学预测的前向模型和目标导向动作的策略网络进行了联合优化。

Result: 在二维平面运动任务和模拟的6-DOF Franka Emika Panda机器人上进行了评估，结果表明SNN可以实现稳定的训练和精确的扭矩控制，证明了其在高维运动任务中的可行性。

Conclusion: 虽然可以实现稳定有效的控制，但递归SNN对超参数设置高度敏感，这凸显了原则性设计选择的重要性。

Abstract: Despite recent progress in training spiking neural networks (SNNs) for
classification, their application to continuous motor control remains limited.
Here, we demonstrate that fully spiking architectures can be trained end-to-end
to control robotic arms with multiple degrees of freedom in continuous
environments. Our predictive-control framework combines Leaky
Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a
forward model for dynamics prediction and a policy network for goal-directed
action. We evaluate this approach on both a planar 2D reaching task and a
simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve
stable training and accurate torque control, establishing their viability for
high-dimensional motor tasks. An extensive ablation study highlights the role
of initialization, learnable time constants, and regularization in shaping
training dynamics. We conclude that while stable and effective control can be
achieved, recurrent spiking networks remain highly sensitive to hyperparameter
settings, underscoring the importance of principled design choices.

</details>


### [448] [Long-Horizon Visual Imitation Learning via Plan and Code Reflection](https://arxiv.org/abs/2509.05368)
*Quan Chen,Chenrui Shi,Qi Chen,Yuwei Wu,Zhi Gao,Xintong Zhang,Rui Gao,Kun Wu,Yunde Jia*

Main category: cs.RO

TL;DR: 提出了一种包含两个专用反射模块的代理框架，用于增强规划和代码生成，以解决长时序演示中的视觉模仿学习挑战。


<details>
  <summary>Details</summary>
Motivation: 长时序演示中的复杂动作序列给视觉模仿学习带来了显著挑战，尤其是在理解动作的时间关系和物体间的空间关系方面。

Method: 提出了一种代理框架，包含两个反射模块：1. 计划生成模块生成初始动作序列，计划反射模块验证其时间连贯性和空间对齐性。 2. 代码生成模块将计划转换为可执行代码，代码反射模块验证并优化代码。框架能够检测并修正计划生成和代码生成中的错误。

Result: 在提出的LongVILBench基准（包含300个长达18个步骤的人类演示）上，现有方法表现不佳，而新框架建立了长时序视觉模仿学习的有力基线。

Conclusion: 所提出的包含计划和代码两个反射模块的代理框架，能够有效处理长时序演示中的时间连贯性和空间对齐性问题，在LongVILBench基准上取得了优于现有方法的性能，为长时序视觉模仿学习设定了新的基准。

Abstract: Learning from long-horizon demonstrations with complex action sequences
presents significant challenges for visual imitation learning, particularly in
understanding temporal relationships of actions and spatial relationships
between objects. In this paper, we propose a new agent framework that
incorporates two dedicated reflection modules to enhance both plan and code
generation. The plan generation module produces an initial action sequence,
which is then verified by the plan reflection module to ensure temporal
coherence and spatial alignment with the demonstration video. The code
generation module translates the plan into executable code, while the code
reflection module verifies and refines the generated code to ensure correctness
and consistency with the generated plan. These two reflection modules jointly
enable the agent to detect and correct errors in both the plan generation and
code generation, improving performance in tasks with intricate temporal and
spatial dependencies. To support systematic evaluation, we introduce
LongVILBench, a benchmark comprising 300 human demonstrations with action
sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial
complexity across multiple task types. Experimental results demonstrate that
existing methods perform poorly on this benchmark, whereas our new framework
establishes a strong baseline for long-horizon visual imitation learning.

</details>


### [449] [Evaluating Magic Leap 2 Tool Tracking for AR Sensor Guidance in Industrial Inspections](https://arxiv.org/abs/2509.05391)
*Christian Masuhr,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.RO

TL;DR: 本文评估了Magic Leap 2 (ML2)控制器在AR工具跟踪方面的性能，提出了一个可重复的评估方法，并为工业AR应用提供了基准。


<details>
  <summary>Details</summary>
Motivation: 公开的现代AR头戴式显示器(HMD)工具跟踪基准测试有限，因此需要对商用AR硬件进行严格评估，特别是Magic Leap 2 (ML2)控制器。

Method: 使用机器人手臂进行可重复运动（符合EN ISO 9283标准），并结合光学跟踪系统作为地面真实性，评估ML2控制器在不同条件下（包括氢气泄漏检测用例中的实际路径）的静态和动态性能。

Result: 量化了ML2控制器的准确性和可重复性，并提出了一个稳健且可转移的评估方法。

Conclusion: 所提出的评估方法和量化结果可用于评估ML2控制器在氢气泄漏检测用例及类似工业传感器引导AR任务中的适用性。

Abstract: Rigorous evaluation of commercial Augmented Reality (AR) hardware is crucial,
yet public benchmarks for tool tracking on modern Head-Mounted Displays (HMDs)
are limited. This paper addresses this gap by systematically assessing the
Magic Leap 2 (ML2) controllers tracking performance. Using a robotic arm for
repeatable motion (EN ISO 9283) and an optical tracking system as ground truth,
our protocol evaluates static and dynamic performance under various conditions,
including realistic paths from a hydrogen leak inspection use case. The results
provide a quantitative baseline of the ML2 controller's accuracy and
repeatability and present a robust, transferable evaluation methodology. The
findings provide a basis to assess the controllers suitability for the
inspection use case and similar industrial sensor-based AR guidance tasks.

</details>


### [450] [RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/abs/2509.05397)
*Matthew Lai,Keegan Go,Zhibin Li,Torsten Kroger,Stefan Schaal,Kelsey Allen,Jonathan Scholz*

Main category: cs.RO

TL;DR: 使用强化学习（RL）和图神经网络（GNN）框架，实现了多机器人协同制造中的自动化任务和运动规划，解决了在复杂环境中多机器人同时执行任务的计算难题。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在真实工业规模下进行多机器人协同制造任务分配、调度和运动规划的计算不可行性问题，以及目前行业中依赖人工经验进行轨迹设计的低效性。

Method: 提出一个基于图神经网络（GNN）策略的强化学习（RL）框架。该框架使用图表示来描述场景，并通过在程序生成的、包含各种障碍物布局、机器人配置和任务分布的环境中进行训练，利用强化学习来生成多机器人的轨迹，联合解决任务分配、调度和运动规划问题。

Result: 在包含八个机器人、执行40个协作任务的复杂障碍环境中，该框架能够进行自动化任务和运动规划。所提出的策略可以零样本泛化到具有不同机器人放置、障碍物几何形状和任务姿态的未见过的场景。此外，该方法还能在工位布局优化中提高解决方案时间，并支持容错规划和在线感知再规划等新能力。

Conclusion: 该RL+GNN框架能够有效地解决多机器人协同制造中的自动化任务和运动规划问题，其速度和可扩展性超过了传统方法，并为未来的自动化制造应用开辟了新的可能性。

Abstract: Modern robotic manufacturing requires collision-free coordination of multiple
robots to complete numerous tasks in shared, obstacle-rich workspaces. Although
individual tasks may be simple in isolation, automated joint task allocation,
scheduling, and motion planning under spatio-temporal constraints remain
computationally intractable for classical methods at real-world scales.
Existing multi-arm systems deployed in the industry rely on human intuition and
experience to design feasible trajectories manually in a labor-intensive
process. To address this challenge, we propose a reinforcement learning (RL)
framework to achieve automated task and motion planning, tested in an
obstacle-rich environment with eight robots performing 40 reaching tasks in a
shared workspace, where any robot can perform any task in any order. Our
approach builds on a graph neural network (GNN) policy trained via RL on
procedurally-generated environments with diverse obstacle layouts, robot
configurations, and task distributions. It employs a graph representation of
scenes and a graph policy neural network trained through reinforcement learning
to generate trajectories of multiple robots, jointly solving the sub-problems
of task allocation, scheduling, and motion planning. Trained on large randomly
generated task sets in simulation, our policy generalizes zero-shot to unseen
settings with varying robot placements, obstacle geometries, and task poses. We
further demonstrate that the high-speed capability of our solution enables its
use in workcell layout optimization, improving solution times. The speed and
scalability of our planner also open the door to new capabilities such as
fault-tolerant planning and online perception-based re-planning, where rapid
adaptation to dynamic task sets is required.

</details>


### [451] [HapMorph: A Pneumatic Framework for Multi-Dimensional Haptic Property Rendering](https://arxiv.org/abs/2509.05433)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: HapMorph是一个气动框架，可以通过敌对织物基气动驱动器（AFPAs）同时连续地改变物体的尺寸和刚度，为可穿戴设备实现多维度触觉反馈。


<details>
  <summary>Details</summary>
Motivation: 在人机交互中，能够同时调节多种物理特性的触觉接口仍然是一个根本性的挑战。现有系统通常只允许渲染几何特征或机械特性，很少同时实现两者，尤其是在可穿戴设备中。

Method: 提出并实现了一种名为HapMorph的气动框架，该框架利用敌对织物基气动驱动器（AFPAs）同时连续地改变物体的尺寸和刚度。通过双腔压力调节来实现尺寸和刚度的解耦控制。

Result: HapMorph原型实现了50至104毫米的尺寸变化，刚度高达4.7 N/mm，可穿戴部件质量仅为21克。实验表明，用户可以区分三个尺寸类别和三个刚度水平共九个离散状态，准确率为89.4%，平均响应时间为6.7秒。此外，还展示了将AFPAs与互补气动结构结合以实现形状或几何变形和并发刚度控制的扩展架构。

Conclusion: 敌对气动原理为下一代触觉接口提供了一条途径，能够在实际的可穿戴设备限制内实现多维度的属性渲染。

Abstract: Haptic interfaces that can simultaneously modulate multiple physical
properties remain a fundamental challenge in human-robot interaction. Existing
systems typically allow the rendering of either geometric features or
mechanical properties, but rarely both, within wearable form factors. Here, we
introduce HapMorph, a pneumatic framework that enables continuous, simultaneous
modulation of object size and stiffness through antagonistic fabric-based
pneumatic actuators (AFPAs). We implemented a HapMorph protoytpe designed for
hands interaction achieving size variation from 50 to 104 mm, stiffness
modulation up to 4.7 N/mm and mass of the wearable parts of just 21 g. Through
systematic characterization, we demonstrate decoupled control of size and
stiffness properties via dual-chamber pressure regulation. Human perception
studies with 10 participants reveal that users can distinguish nine discrete
states across three size categories and three stiffness levels with 89.4%
accuracy and 6.7 s average response time. We further demonstrate extended
architectures that combine AFPAs with complementary pneumatic structures to
enable shape or geometry morphing with concurrent stiffness control. Our
results establish antagonistic pneumatic principle as a pathway toward
next-generation haptic interfaces, capable of multi-dimensiona rendering
properties within practical wearable constraints.

</details>


### [452] [Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation](https://arxiv.org/abs/2509.05475)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 自主挖掘是太空资源利用的关键，但受限于复杂的地形和多样的工具。本文提出一种基于模型的强化学习框架，在模拟环境中通过学习自适应的刚度和阻尼来掌握多样化的挖掘任务，并结合视觉反馈提升成功率。


<details>
  <summary>Details</summary>
Motivation: 自主挖掘是太空资源利用的关键，但面临复杂颗粒介质交互和多样化工具操作的挑战。

Method: 提出一个基于模型的强化学习框架，在模拟环境中，通过程序化生成多样的月球地形和挖掘工具，并让智能体学习自适应的刚度和阻尼。

Result: 在程序化生成的多样化工具训练下，智能体能够泛化并表现出复杂的工具感知行为。加入视觉反馈能显著提高任务成功率。

Conclusion: 本文验证了一种开发鲁棒且通用的自主系统的方法，为未来太空任务的基础性任务奠定了基础。

Abstract: Autonomous regolith excavation is a cornerstone of in-situ resource
utilization for a sustained human presence beyond Earth. However, this task is
fundamentally hindered by the complex interaction dynamics of granular media
and the operational need for robots to use diverse tools. To address these
challenges, this work introduces a framework where a model-based reinforcement
learning agent learns within a parallelized simulation. This environment
leverages high-fidelity particle physics and procedural generation to create a
vast distribution of both lunar terrains and excavation tool geometries. To
master this diversity, the agent learns an adaptive interaction strategy by
dynamically modulating its own stiffness and damping at each control step
through operational space control. Our experiments demonstrate that training
with a procedural distribution of tools is critical for generalization and
enables the development of sophisticated tool-aware behavior. Furthermore, we
show that augmenting the agent with visual feedback significantly improves task
success. These results represent a validated methodology for developing the
robust and versatile autonomous systems required for the foundational tasks of
future space missions.

</details>


### [453] [Microrobot Vascular Parkour: Analytic Geometry-based Path Planning with Real-time Dynamic Obstacle Avoidance](https://arxiv.org/abs/2509.05500)
*Yanda Yang,Max Sokolich,Fatma Ceren Kirmizitas,Sambeeta Das,Andreas A. Malikopoulos*

Main category: cs.RO

TL;DR: 该研究提出了一种实时路径规划框架，结合了解析几何全局规划器（AGP）和两种基于规则及强化学习的局部逃避控制器，以应对血流中移动障碍物的挑战，实现了自主微纳机器人在血管内的导航与避障。


<details>
  <summary>Details</summary>
Motivation: 血流中移动障碍物对自主微纳机器人的导航构成挑战，限制了其在血管内进行微创治疗的应用。

Method: 提出了一种实时路径规划框架，该框架将解析几何全局规划器（AGP）与基于规则和强化学习的局部逃避控制器相结合。系统利用实时成像技术估计微纳机器人、障碍物和目标的位置，并计算无碰撞的运动路径。

Result: 在仿真中，AGP相比于加权A*（WA*）、粒子群优化（PSO）和快速探索随机树（RRT），在保持可行性和确定性的同时，提供了更短的路径和更快的规划速度。该方法从2D扩展到3D，速度没有损失。在仿真和实验中，该框架均能可靠地避开移动障碍物并到达目标，平均规划时间为40毫秒/帧，可兼容25帧/秒的图像采集和实时闭环控制。

Conclusion: 该研究提出的自主微纳机器人导航框架能够可靠地避开血流中的移动障碍物，并在仿真和实验中实现了高效的路径规划，为在血管环境中实现靶向药物输送等应用奠定了基础。

Abstract: Autonomous microrobots in blood vessels could enable minimally invasive
therapies, but navigation is challenged by dense, moving obstacles. We propose
a real-time path planning framework that couples an analytic geometry global
planner (AGP) with two reactive local escape controllers, one based on rules
and one based on reinforcement learning, to handle sudden moving obstacles.
Using real-time imaging, the system estimates the positions of the microrobot,
obstacles, and targets and computes collision-free motions. In simulation, AGP
yields shorter paths and faster planning than weighted A* (WA*), particle swarm
optimization (PSO), and rapidly exploring random trees (RRT), while maintaining
feasibility and determinism. We extend AGP from 2D to 3D without loss of speed.
In both simulations and experiments, the combined global planner and local
controllers reliably avoid moving obstacles and reach targets. The average
planning time is 40 ms per frame, compatible with 25 fps image acquisition and
real-time closed-loop control. These results advance autonomous microrobot
navigation and targeted drug delivery in vascular environments.

</details>


### [454] [TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs](https://arxiv.org/abs/2509.05547)
*Ziling Chen,Yeo Jung Yoon,Rolando Bautista-Montesano,Zhen Zhao,Ajay Mandlekar,John Liu*

Main category: cs.RO

TL;DR: TeleopLab是一个移动设备遥操作系统，用于远程STEM教育，通过智能手机界面控制机械臂和实验设备，提高了46.1%的任务完成效率，并获得了积极的用户评价和可用性评分。


<details>
  <summary>Details</summary>
Motivation: 远程教育中的实践学习，尤其是在需要与真实设备交互的环境中，可以通过遥操作来解决成本高昂或不直观的问题。

Method: 提出TeleopLab系统，包括机械臂、自适应夹爪、摄像头、实验设备和智能手机用户界面，并通过用户研究评估任务表现、用户观点、可用性和工作负荷。

Result: 用户熟悉度提高后，任务完成时间减少了46.1%；用户反馈显示，使用系统后学生观点得到改善；NASA TLX评分为38.2，SUS评分为73.8，表明工作负荷可控且可用性良好。

Conclusion: TeleopLab成功地连接了实体实验室和远程教育，为远程STEM学习提供了一个可扩展且有效的平台。

Abstract: Teleoperation offers a promising solution for enabling hands-on learning in
remote education, particularly in environments requiring interaction with
real-world equipment. However, such remote experiences can be costly or
non-intuitive. To address these challenges, we present TeleopLab, a mobile
device teleoperation system that allows students to control a robotic arm and
operate lab equipment. TeleopLab comprises a robotic arm, an adaptive gripper,
cameras, lab equipment for a diverse range of applications, a user interface
accessible through smartphones, and video call software. We conducted a user
study, focusing on task performance, students' perspectives toward the system,
usability, and workload assessment. Our results demonstrate a 46.1% reduction
in task completion time as users gained familiarity with the system.
Quantitative feedback highlighted improvements in students' perspectives after
using the system, while NASA TLX and SUS assessments indicated a manageable
workload of 38.2 and a positive usability of 73.8. TeleopLab successfully
bridges the gap between physical labs and remote education, offering a scalable
and effective platform for remote STEM learning.

</details>


### [455] [Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids](https://arxiv.org/abs/2509.05581)
*Arturo Flores Alvarez,Fatemeh Zargarbashi,Havel Liu,Shiqi Wang,Liam Edwards,Jessica Anz,Alex Xu,Fan Shi,Stelian Coros,Dennis W. Hong*

Main category: cs.RO

TL;DR: We use RL and Adversarial Motion Priors (AMP) to enable a humanoid robot (Cosmo) with an aesthetic-driven design (large head, limited sensing, restrictive shells) to learn stable and natural-looking locomotion, overcoming its unique design challenges.


<details>
  <summary>Details</summary>
Motivation: Entertainment robots like Cosmo have unique design challenges (e.g., disproportionately large head, limited sensing, restrictive shells) that traditional humanoids do not, making it difficult to achieve natural-looking and stable movement.

Method: We applied Reinforcement Learning (RL) with Adversarial Motion Priors (AMP) and developed tailored domain randomization and specialized reward structures for sim-to-real transfer, addressing Cosmo's specific design constraints.

Result: The AMP-based RL system successfully generated stable standing and walking behaviors for Cosmo, despite its extreme mass distribution and movement restrictions.

Conclusion: Learning-based methods, specifically our AMP approach, can effectively overcome aesthetic-driven design constraints in robots, enabling them to balance visual appeal with functional performance for applications like entertainment.

Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a
custom-built humanoid robot designed for entertainment applications. Unlike
traditional humanoids, entertainment robots present unique challenges due to
aesthetic-driven design choices. Cosmo embodies these with a disproportionately
large head (16% of total mass), limited sensing, and protective shells that
considerably restrict movement. To address these challenges, we apply
Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking
movements while maintaining physical stability. We develop tailored domain
randomization techniques and specialized reward structures to ensure safe
sim-to-real, protecting valuable hardware components during deployment. Our
experiments demonstrate that AMP generates stable standing and walking
behaviors despite Cosmo's extreme mass distribution and movement constraints.
These results establish a promising direction for robots that balance aesthetic
appeal with functional performance, suggesting that learning-based methods can
effectively adapt to aesthetic-driven design constraints.

</details>


### [456] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Yinuo Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba是一个基于Mamba的选择性状态空间模型，用于视觉驱动的跨模态深度强化学习，实现了近线性时间序列建模，能有效捕捉长距离依赖，并支持更长序列的高效训练。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够有效处理长序列、捕捉长距离依赖的视觉驱动跨模态深度强化学习框架，以应对复杂环境下的机器人控制任务。

Method: 1. 使用MLP嵌入本体感觉状态，使用轻量级CNN对深度图像进行Patchify，生成紧凑的Token以提升状态表示。2. 通过堆叠的Mamba层进行近线性时间的选择性扫描来融合Token，降低延迟和内存占用，并提供归纳偏置以减少过拟合。3. 结合地形和外观随机化以及障碍密度课程，使用以状态为中心的紧凑奖励函数（平衡进度、平滑度和安全性）通过Proximal Policy Optimization进行端到端策略训练。

Result: 在包含静态和动态障碍物以及不平坦地形的模拟环境中，LocoMamba相比最先进的方法，在更少的更新次数下实现了更高的回报率和成功率，同时减少了碰撞，并表现出对未见地形和障碍物密度的更强泛化能力。

Conclusion: LocoMamba通过利用Mamba的高效序列建模能力，在视觉驱动的跨模态深度强化学习任务中取得了优越的性能，包括更好的样本效率、更强的泛化能力和更低的计算成本。

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>


### [457] [MonoGlass3D: Monocular 3D Glass Detection with Plane Regression and Adaptive Feature Fusion](https://arxiv.org/abs/2509.05599)
*Kai Zhang,Guoyang Zhao,Jianxing Shi,Bonan Liu,Weiqing Qi,Jun Ma*

Main category: cs.RO

TL;DR: 提出一个包含3D标注的新数据集，用于检测和定位3D环境中的玻璃，并引入一种名为MonoGlass3D的新方法，该方法使用自适应特征融合模块和平面回归流程来处理玻璃的模糊外观和几何特性，在玻璃分割和单目玻璃深度估计方面取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 3D环境中玻璃的检测和定位存在挑战，因为玻璃的光学特性会干扰传统传感器，且缺乏相关的真实世界数据集。

Method: 提出一个包含各种玻璃配置和精确3D标注的新数据集；提出MonoGlass3D方法，包括自适应特征融合模块以处理模糊外观和上下文多样性，以及平面回归流程以利用玻璃表面的平面几何特性。

Result: MonoGlass3D在玻璃分割和单目玻璃深度估计方面取得了优于现有方法的性能。

Conclusion: 结合几何和上下文线索有助于理解透明表面。

Abstract: Detecting and localizing glass in 3D environments poses significant
challenges for visual perception systems, as the optical properties of glass
often hinder conventional sensors from accurately distinguishing glass
surfaces. The lack of real-world datasets focused on glass objects further
impedes progress in this field. To address this issue, we introduce a new
dataset featuring a wide range of glass configurations with precise 3D
annotations, collected from distinct real-world scenarios. On the basis of this
dataset, we propose MonoGlass3D, a novel approach tailored for monocular 3D
glass detection across diverse environments. To overcome the challenges posed
by the ambiguous appearance and context diversity of glass, we propose an
adaptive feature fusion module that empowers the network to effectively capture
contextual information in varying conditions. Additionally, to exploit the
distinct planar geometry of glass surfaces, we present a plane regression
pipeline, which enables seamless integration of geometric properties within our
framework. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches in both glass segmentation and monocular glass
depth estimation. Our results highlight the advantages of combining geometric
and contextual cues for transparent surface understanding.

</details>


### [458] [Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation](https://arxiv.org/abs/2509.05672)
*Juho Kalliokoski,Evan G. Center,Steven M. LaValle,Timo Ojala,Basak Sakcak*

Main category: cs.RO

TL;DR: 用户可以通过共享控制或切换控制来导航远程环境中的临场机器人，共享控制在不降低导航效率的情况下，并不能显著降低用户的工作负载。


<details>
  <summary>Details</summary>
Motivation: 临场机器人提高了远程环境交互的效率，但导航的挑战依然存在。本研究旨在开发一种共享控制方法，让用户在机器人自主导航的同时影响路径规划，以满足用户的特定需求。

Method: 开发并评估了一种共享控制方法，并将其与传统的切换控制方法进行了比较。在切换控制中，用户需要在直接控制和自动控制之间进行切换。

Result: 两项用户研究（每项有20名最终参与者）的结果表明，共享控制在导航效率方面不劣于切换控制。然而，与切换控制相比，共享控制并未显著降低用户任务负荷。

Conclusion: 共享控制在导航效率方面不劣于切换控制，但并未显示出比切换控制更低的任务负荷。未来的研究需要深入探讨影响用户在这两种控制系统中的偏好和表现的潜在因素。

Abstract: Telepresence robots enable users to interact with remote environments, but
efficient and intuitive navigation remains a challenge. In this work, we
developed and evaluated a shared control method, in which the robot navigates
autonomously while allowing users to affect the path generation to better suit
their needs. We compared this with control switching, where users toggle
between direct and automated control. We hypothesized that shared control would
maintain efficiency comparable to control switching while potentially reducing
user workload. The results of two consecutive user studies (each with final
sample of n=20) showed that shared control does not degrade navigation
efficiency, but did not show a significant reduction in task load compared to
control switching. Further research is needed to explore the underlying factors
that influence user preference and performance in these control systems.

</details>


### [459] [A*-PRM: A Dynamic Weight-Based Probabilistic Roadmap Algorithm](https://arxiv.org/abs/2509.05701)
*Siyuan Wang,Shuyi Zhang,Zhen Tian,Yuheng Yao,Gongsen Wang,Yu Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一种名为A-star PRM的混合路径规划算法，通过结合A-star算法的启发式搜索和PRM算法的采样方法，并引入动态权重，以提高机器人路径规划的效率和质量，尤其在复杂和动态环境中表现优越。


<details>
  <summary>Details</summary>
Motivation: 机器人路径规划是提高自主导航系统环境适应性的基础性挑战。

Method: 提出了一种名为A-star PRM的混合路径规划算法，该算法将A-star算法的曼哈顿距离启发式搜索嵌入到PRM算法的随机采样过程中，并采用分层采样策略和动态连接机制。

Result: 在基线配置（1000个采样顶点）下，A-star PRM的路径长度为1073.23 ± 14.8米，比PRM算法短42.3%。在高密度采样（3000个顶点）下，路径长度为1036.61米，仅比PRM算法（1046.42米）短0.94%，但计算时间增加仅为PRM的七分之一（71% vs 785%）。

Conclusion: A-star PRM在路径质量、稳定性和计算效率方面具有综合优势，在狭窄通道和动态障碍物场景下尤其优于现有混合算法。

Abstract: Robot path planning is a fundamental challenge in enhancing the environmental
adaptability of autonomous navigation systems. This paper presents a hybrid
path planning algorithm, A-star PRM, which incorporates dynamic weights. By
embedding the Manhattan distance heuristic of the A-star algorithm into the
random sampling process of PRM, the algorithm achieves a balanced optimization
of path quality and computational efficiency. The approach uses a hierarchical
sampling strategy and a dynamic connection mechanism, greatly improving
adaptability to complex obstacle distributions. Experiments show that under a
baseline configuration with one thousand sampled vertices, the path length of
A-star PRM is 1073.23 plus or minus 14.8 meters and is 42.3 percent shorter
than that of PRM with p value less than 0.01. With high-density sampling using
three thousand vertices, the path length is reduced by 0.94 percent, 1036.61
meters compared with 1046.42 meters, while the increase in computational time
is cut to about one tenth of the PRM increase, 71 percent compared with 785
percent. These results confirm the comprehensive advantages of A-star PRM in
path quality, stability, and computational efficiency. Compared with existing
hybrid algorithms, the proposed method shows clear benefits, especially in
narrow channels and scenarios with dynamic obstacles.

</details>


### [460] [Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723)
*Liansheng Wang,Xinke Zhang,Chenhui Li,Dongjiao He,Yihan Pan,Jianjun Yi*

Main category: cs.RO

TL;DR: Super-LIO是一个高效鲁棒的激光雷达-惯性里程计系统，适用于资源受限的平台，通过紧凑的八叉树体素地图结构（OctVox）和启发式引导的KNN（HKNN）策略，实现了高精度和低计算开销。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的平台上部署高性能、高精度的激光雷达-惯性里程计（LIO）系统具有挑战性，本文旨在解决这一问题，满足空中机器人和移动自主系统等应用的需求。

Method: 提出了一种名为OctVox的紧凑型八体素地图结构，限制每个体素包含八个融合子体素，以控制点密度和进行增量去噪。同时设计了一种启发式引导KNN（HKNN）策略，利用空间局部性加速匹配搜索。

Result: 在X86和ARM平台上，Super-LIO在四个公开数据集和多个自收集数据集上进行了广泛测试。结果表明，Super-LIO比现有技术（SOTA）快约73%，同时消耗更少的CPU资源，并且精度具有竞争力。

Conclusion: Super-LIO是一个高效、鲁棒且易于集成的LIO系统，通过创新的地图结构和匹配策略，在资源受限的平台上实现了优异的性能和准确性，并已开源。

Abstract: LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous
systems, yet its deployment on resource-constrained platforms remains
challenging due to computational and memory limitations. We propose Super-LIO,
a robust LIO system that demands both high performance and accuracy, ideal for
applications such as aerial robots and mobile autonomous systems. At the core
of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that
limits each voxel to eight fused subvoxels, enabling strict point density
control and incremental denoising during map updates. This design enables a
simple yet efficient and accurate map structure, which can be easily integrated
into existing LIO frameworks. Additionally, Super-LIO designs a
heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search
by leveraging spatial locality, further reducing runtime overhead. We evaluated
the proposed system using four publicly available datasets and several
self-collected datasets, totaling more than 30 sequences. Extensive testing on
both X86 and ARM platforms confirms that Super-LIO offers superior efficiency
and robustness, while maintaining competitive accuracy. Super-LIO processes
each frame approximately 73% faster than SOTA, while consuming less CPU
resources. The system is fully open-source and plug-and-play compatible with a
wide range of LiDAR sensors and platforms. The implementation is available at:
https://github.com/Liansheng-Wang/Super-LIO.git

</details>


### [461] [Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots](https://arxiv.org/abs/2509.06115)
*Runjiao Bao,Lin Zhang,Tianwei Niu,Haoyu Yuan,Shoukun Wang*

Main category: cs.RO

TL;DR: 该研究提出了一个扩展的混合A*框架，用于解决四轮独立转向（4WIS）移动机器人的路径规划问题，充分利用其多模式运动能力。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法未能充分利用4WIS平台的多模式运动能力，因为它们通常假设单一的运动学模型。

Method: 提出了一种扩展的混合A*框架，该框架在包含空间状态和运动模式的四维状态空间中运行。该框架设计了针对每种运动模式独特运动学约束的多模式里德-谢泼曲线，开发了考虑模式切换成本的增强启发式函数，并引入了具有智能模式选择的终端连接策略，以确保不同转向模式之间的平稳过渡。

Result: 所提出的规划器能够将多种运动模式无缝集成到单一路径中，显著提高了在复杂环境中的灵活性和适应性。仿真结果表明，该规划器显著提高了4WIS机器人在复杂环境中的规划性能。

Conclusion: 该研究提出的扩展混合A*框架能够成功地将多种运动模式集成到4WIS机器人的单一路径规划中，显著提高了规划性能和机器人的适应性。

Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a
rich set of motion modes, such as Ackermann steering, lateral steering, and
parallel movement, offering superior maneuverability in constrained
environments. However, existing path planning methods generally assume a single
kinematic model and thus fail to fully exploit the multi-modal capabilities of
4WIS platforms. To address this limitation, we propose an extended Hybrid A*
framework that operates in a four-dimensional state space incorporating both
spatial states and motion modes. Within this framework, we design multi-modal
Reeds-Shepp curves tailored to the distinct kinematic constraints of each
motion mode, develop an enhanced heuristic function that accounts for
mode-switching costs, and introduce a terminal connection strategy with
intelligent mode selection to ensure smooth transitions between different
steering patterns. The proposed planner enables seamless integration of
multiple motion modalities within a single path, significantly improving
flexibility and adaptability in complex environments. Results demonstrate
significantly improved planning performance for 4WIS robots in complex
environments.

</details>


### [462] [Scenario-based Decision-making Using Game Theory for Interactive Autonomous Driving: A Survey](https://arxiv.org/abs/2509.05777)
*Zhihao Lin,Zhen Tian*

Main category: cs.RO

TL;DR: 游戏化交互式驾驶模拟在交通运输决策算法领域展现出巨大潜力，但确保不同场景下的真实感和鲁棒性仍具挑战。近年来，游戏化技术与先进学习框架的结合催生了能有效应对复杂驾驶条件的自适应决策模型，并在多种场景下优于传统方法。然而，目前仍缺乏对不同场景下游戏化驾驶方法的系统性比较。本综述全面评估了游戏化交互式驾驶方法，总结了近期进展和各场景下的道路特征，并批判性地分析了所审查算法对标准游戏模型的适应性及其对决策性能的影响。最后，讨论了现有方法的局限性并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 游戏化交互式驾驶模拟平台在提升道路交通移动性决策算法方面具有通用性。尽管这些平台提供了安全、可扩展且引人入胜的测试环境，但在动态和多样化场景中同时保证真实感和鲁棒性仍然是一个重大挑战。需要对现有方法进行系统性评估和比较，以应对这些挑战。

Method: 本研究对游戏化交互式驾驶方法进行了全面的评估。它总结了近期在不同驾驶场景（包括高速公路避障、匝道合并、环形交叉路口、无信号灯交叉路口以及高速自动赛车）下的进展。此外，还对所审查的算法进行了批判性评估，分析了它们对标准游戏模型的适应性以及具体的机制，以了解它们对决策性能的影响。

Result: 游戏化技术与先进学习框架的结合使得开发能够有效管理不同驾驶条件下复杂性的自适应决策模型成为可能。这些模型在处理具体场景挑战方面优于传统模拟方法，这些挑战包括高速公路避障、匝道合并时的精确操作、环形交叉路口导航、无信号灯交叉路口以及高速自动赛车。

Conclusion: 尽管在游戏化交互式驾驶领域取得了多项创新，但目前仍缺乏对不同场景下这些方法进行比较的系统性综述。本综述对现有游戏化驾驶方法进行了全面评估，并讨论了当前方法的局限性，同时提出了未来研究的有前景的方向。

Abstract: Game-based interactive driving simulations have emerged as versatile
platforms for advancing decision-making algorithms in road transport mobility.
While these environments offer safe, scalable, and engaging settings for
testing driving strategies, ensuring both realism and robust performance amid
dynamic and diverse scenarios remains a significant challenge. Recently, the
integration of game-based techniques with advanced learning frameworks has
enabled the development of adaptive decision-making models that effectively
manage the complexities inherent in varied driving conditions. These models
outperform traditional simulation methods, especially when addressing
scenario-specific challenges, ranging from obstacle avoidance on highways and
precise maneuvering during on-ramp merging to navigation in roundabouts,
unsignalized intersections, and even the high-speed demands of autonomous
racing. Despite numerous innovations in game-based interactive driving, a
systematic review comparing these approaches across different scenarios is
still missing. This survey provides a comprehensive evaluation of game-based
interactive driving methods by summarizing recent advancements and inherent
roadway features in each scenario. Furthermore, the reviewed algorithms are
critically assessed based on their adaptation of the standard game model and an
analysis of their specific mechanisms to understand their impact on
decision-making performance. Finally, the survey discusses the limitations of
current approaches and outlines promising directions for future research.

</details>


### [463] [A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications](https://arxiv.org/abs/2509.06119)
*Shiqi Xu,Lihao Zhang,Yuyang Du,Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 该研究提出了一种结合了TDMA和CSMA的混合协议，用于解决机器人通信中高流量负载下的实时控制问题，实验证明该协议能显著减少任务关键数据包的延迟和丢失。


<details>
  <summary>Details</summary>
Motivation: 机器人应用（如制造、医疗和自动驾驶）对实时控制有强烈需求，但现有CSMA协议在高流量下表现不佳，会延迟关键指令的传输，影响操作效率和安全。

Method: 提出了一种兼容IEEE 802.11的混合TDMA/CSMA协议，结合了TDMA的确定性时隙调度和CSMA的自适应性。该协议利用PTP进行亚微秒级同步，采用三会话超级帧结构进行动态TDMA分配，并通过信标保护来防止干扰，以实现无冲突、低延迟的通信。

Result: 在真实SDR平台和ROS仿真实验中，该协议将错过截止时间的错误减少了93%，在机器人路径跟踪仿真中，将均方根轨迹误差降低了高达90%，同时非关键流量的吞吐量保持在±2%的范围内。

Conclusion: 所提出的混合TDMA/CSMA协议能有效解决机器人通信在高流量下的实时性问题，显著提高了任务关键指令的传输成功率和机器人的控制精度。

Abstract: Recent progress in robotics has underscored the demand for real-time control
in applications such as manufacturing, healthcare, and autonomous systems,
where the timely delivery of mission-critical commands under heterogeneous
robotic traffic is paramount for operational efficacy and safety. In these
scenarios, mission-critical traffic follows a strict deadline-constrained
communication pattern: commands must arrive within defined QoS deadlines,
otherwise late arrivals can degrade performance or destabilize control loops.In
this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted
in robotic communications,suffers severe degradation under high robot traffic
loads, with contention-induced collisions and delays disrupting the on-time
arrival of mission-critical packets. To address this problem, we propose an
IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's
deterministic slot scheduling with CSMA's adaptability for heterogeneous robot
traffic.The protocol achieves collision-free, low-latency mission-critical
command delivery and IEEE 802.11 compatibility through the synergistic
integration of sub-microsecond PTP-based slot synchronization-essential for
establishing precise timing for TDMA, a three-session superframe with dynamic
TDMA allocation for structured and adaptable traffic management,and beacon-NAV
protection to preemptively secure these critical communication sessions from
interference. Emulation experiments on real-time SDR testbed and Robot
Operating System (ROS) simulation show that the proposed protocol reduces
missed-deadline errors by 93% compared to the CSMA baseline. In high-speed
robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)
trajectory error by up to 90% compared with a CSMA baseline, all while
maintaining throughput for non-critical traffic within +-2%.

</details>


### [464] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: eKalibr-Inertial是一个用于事件相机-惯性测量单元系统的时空校准器。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其卓越的时间分辨率、高动态范围和低功耗而受到广泛研究，视觉-惯性系统常用于运动估计，但需要精确的时空校准。

Method: 提出eKalibr-Inertial，利用圆形网格板进行校准，包括初始化和基于连续时间的批次优化。

Result: 通过大量真实世界实验证明了eKalibr-Inertial在事件相机-惯性测量单元系统时空校准方面的准确性。

Conclusion: eKalibr-Inertial能够实现事件相机-惯性测量单元系统的精确时空校准，并已开源。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [465] [ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction](https://arxiv.org/abs/2509.06031)
*Junhui Huang,Yuhe Gong,Changsheng Li,Xingguang Duan,Luis Figueredo*

Main category: cs.RO

TL;DR: ZLATTE是一个无需学习的、感知几何的框架，用于在人机交互中进行语言驱动的轨迹重塑。它使用视觉-语言模型将物体注册为几何图元，并利用大语言模型将自然语言指令转换为明确的几何和运动学约束，以优化轨迹，同时保持可行性和安全性。


<details>
  <summary>Details</summary>
Motivation: 与先前基于学习的方法不同，ZLATTE的动机在于利用现有的视觉-语言和大型语言模型，通过将自然语言指令转换为显式的几何和运动学约束，来实现无需学习的、感知几何的轨迹重塑，以提高人机交互的平稳性、安全性和可解释性。

Method: ZLATTE框架首先利用视觉-语言模型将物体识别并注册为几何图元。然后，它使用大型语言模型将用户的自然语言指令翻译成明确的几何和运动学约束。这些约束被整合到一个势场优化问题中，用于调整初始轨迹，同时确保轨迹的可行性和安全性。此外，还采用了一种多智能体策略来处理复杂或冲突的指令，以增强鲁棒性。

Result: 与最先进的基线方法相比，ZLATTE在模拟和真实世界实验中都实现了更平稳、更安全、更可解释的轨迹修改。

Conclusion: ZLATTE通过结合视觉-语言模型和大型语言模型，无需学习即可实现语言驱动的轨迹重塑，并在保持轨迹可行性和安全性的同时，提高了人机交互的平稳性、安全性和可解释性。

Abstract: We present ZLATTE, a geometry-aware, learning-free framework for
language-driven trajectory reshaping in human-robot interaction. Unlike prior
learning-based methods, ZLATTE leverages Vision-Language Models to register
objects as geometric primitives and employs a Large Language Model to translate
natural language instructions into explicit geometric and kinematic
constraints. These constraints are integrated into a potential field
optimization to adapt initial trajectories while preserving feasibility and
safety. A multi-agent strategy further enhances robustness under complex or
conflicting commands. Simulation and real-world experiments demonstrate that
ZLATTE achieves smoother, safer, and more interpretable trajectory
modifications compared to state-of-the-art baselines.

</details>


### [466] [Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness](https://arxiv.org/abs/2509.06048)
*Yi Dong,Yangjun Liu,Jinjun Duan,Yang Li,Zhendong Dai*

Main category: cs.RO

TL;DR: 提出了一种机器人抓取框架，包括感知模块、重新定向规划器和抓取规划器，以完成任何初始状态下鞋子对的抓取任务。


<details>
  <summary>Details</summary>
Motivation: 鞋子抓取任务具有不规则形状和可变形物体的典型配对物品抓取任务的特征，但现有的研究未能考虑鞋子因不规则形状而具有的不同初始状态和标准的抓取放置姿势。

Method: 提出了一种基于语义关键点的视觉模块，用于推断尺寸、状态、姿势和抓取点；提出了基于原始元的重新定向方法，以及一种利用箱体边缘接触和重力进行快速重新定向的方法；提出了一种用于鞋子对抓取的任务规划器。

Result: 在各种类型的鞋子上进行了实际实验，以验证重新定向方法的鲁棒性和抓取策略的有效性。

Conclusion: 这项研究强调了语义关键点表示方法的潜力，为 3D 可变形物体和多物体操纵的重新定向提供了新的视角，并为配对物品抓取提供了参考。

Abstract: With the rapid development of the warehousing and logistics industries, the
packing of goods has gradually attracted the attention of academia and
industry. The packing of footwear products is a typical representative
paired-item packing task involving irregular shapes and deformable objects.
Although studies on shoe packing have been conducted, different initial states
due to the irregular shapes of shoes and standard packing placement poses have
not been considered. This study proposes a robotic manipulation framework,
including a perception module, reorientation planners, and a packing planner,
that can complete the packing of pairs of shoes in any initial state. First, to
adapt to the large intraclass variations due to the state, shape, and
deformation of the shoe, we propose a vision module based on semantic
keypoints, which can also infer more information such as size, state, pose, and
manipulation points by combining geometric features. Subsequently, we not only
proposed primitive-based reorientation methods for different states of a single
deformable shoe but also proposed a fast reorientation method for the top state
using box edge contact and gravity, which further improved the efficiency of
reorientation. Finally, based on the perception module and reorientation
methods, we propose a task planner for shoe pair packing in any initial state
to provide an optimal packing strategy. Real-world experiments were conducted
to verify the robustness of the reorientation methods and the effectiveness of
the packing strategy for various types of shoes. In this study, we highlight
the potential of semantic keypoint representation methods, introduce new
perspectives on the reorientation of 3D deformable objects and multi-object
manipulation, and provide a reference for paired object packing.

</details>


### [467] [Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain](https://arxiv.org/abs/2509.06061)
*Faiza Babakano,Ahmed Fahmin,Bojie Shen,Muhammad Aamir Cheema,Isma Farah Siddiqui*

Main category: cs.RO

TL;DR: AMRs需要考虑能源效率，尤其是在需要拾取物体时。本文提出了对象拾取最小能源路径问题（OMEPP），并提出了两种方法：一种是基于Z星算法的基线算法，另一种是并发PCPD搜索。实验表明，并发PCPD搜索速度快且性能接近最优。


<details>
  <summary>Details</summary>
Motivation: AMRs的能源效率至关重要，但现有方法忽略了拾取物体对能源消耗的影响。

Method: 1.提出了对象拾取最小能源路径问题（OMEPP）。 2.提出了一种基于Z星算法的基线算法，该算法迭代访问每个拾取点。 3.提出了一种并发PCPD搜索算法，该算法同时管理所有拾取点的多个Z星搜索，并使用负载约束路径数据库（PCPD）来减少搜索分支因子。

Result: 并发PCPD搜索在真实数据集上的实验表明，其性能接近最优，并且比基线算法快一到两个数量级。

Conclusion: OMEPP是一个具有挑战性的问题，但并发PCPD搜索提供了一种高效且接近最优的解决方案。

Abstract: Autonomous Mobile Robots (AMRs) operate on battery power, making energy
efficiency a critical consideration, particularly in outdoor environments where
terrain variations affect energy consumption. While prior research has
primarily focused on computing energy-efficient paths from a source to a
destination, these approaches often overlook practical scenarios where a robot
needs to pick up an object en route - an action that can significantly impact
energy consumption due to changes in payload. This paper introduces the
Object-Pickup Minimum Energy Path Problem (OMEPP), which addresses
energy-efficient route planning for AMRs required to pick up an object from one
of many possible locations and deliver it to a destination. To address OMEPP,
we first introduce a baseline algorithm that employs the Z star algorithm, a
variant of A star tailored for energy-efficient routing, to iteratively visit
each pickup point. While this approach guarantees optimality, it suffers from
high computational cost due to repeated searches at each pickup location. To
mitigate this inefficiency, we propose a concurrent PCPD search that manages
multiple Z star searches simultaneously across all pickup points. Central to
our solution is the Payload-Constrained Path Database (PCPD), an extension of
the Compressed Path Database (CPD) that incorporates payload constraints. We
demonstrate that PCPD significantly reduces branching factors during search,
improving overall performance. Although the concurrent PCPD search may produce
slightly suboptimal solutions, extensive experiments on real-world datasets
show it achieves near-optimal performance while being one to two orders of
magnitude faster than the baseline algorithm.

</details>


### [468] [An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields](https://arxiv.org/abs/2509.06682)
*Sajad Ahmadi,Mohammadreza Davoodi,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 提出一种自适应覆盖控制方法，用于在动态农业环境中操作越野无人地面车辆（UGV）。


<details>
  <summary>Details</summary>
Motivation: 传统覆盖控制方法假设环境静态，不适用于动态变化的农业环境，如移动机械和不平坦地形造成的持续挑战。

Method: 提出一个实时路径规划框架，集成无人机（UAV）进行障碍物检测和地形评估，使UGV能够动态调整覆盖路径。环境被建模为加权有向图，基于UAV的观测实时更新边权重，以反映障碍物运动和地形变化。该方法结合了Voronoi分区、自适应边权重分配和基于成本的路径优化。

Result: 仿真结果表明，所提出的方法在动态障碍物和泥泞地形存在的情况下，能够有效地改进路径规划、降低遍历成本并保持鲁棒的覆盖。

Conclusion: 所提出的自适应覆盖控制方法能够有效应对动态农业环境中的挑战。

Abstract: This paper presents an adaptive coverage control method for a fleet of
off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic
(time-varying) agricultural environments. Traditional coverage control
approaches often assume static conditions, making them unsuitable for
real-world farming scenarios where obstacles, such as moving machinery and
uneven terrains, create continuous challenges. To address this, we propose a
real-time path planning framework that integrates Unmanned Aerial Vehicles
(UAVs) for obstacle detection and terrain assessment, allowing UGVs to
dynamically adjust their coverage paths. The environment is modeled as a
weighted directed graph, where the edge weights are continuously updated based
on the UAV observations to reflect obstacle motion and terrain variations. The
proposed approach incorporates Voronoi-based partitioning, adaptive edge weight
assignment, and cost-based path optimization to enhance navigation efficiency.
Simulation results demonstrate the effectiveness of the proposed method in
improving path planning, reducing traversal costs, and maintaining robust
coverage in the presence of dynamic obstacles and muddy terrains.

</details>


### [469] [Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways](https://arxiv.org/abs/2509.06687)
*Sajad Ahmadi,Hossein Nejatbakhsh Esfahani,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 该论文提出了一种结合鲁棒模型预测控制（RMPC）和控制障碍函数（CBF）的运动规划新方法，用于在内河航道中实现自主地面船舶（ASV）的安全导航。


<details>
  <summary>Details</summary>
Motivation: 内河航道航行具有挑战性，现有自主导航方法鲁棒性和精度不足。

Method: 提出一种新的运动规划方法，结合RMPC和CBF，将通道边界和障碍物作为安全约束。 

Result: 仿真结果表明，该方法在复杂内河航道条件下能安全引导ASV，提高了安全性和适应性。

Conclusion: 该方法能有效解决内河航道中ASV的安全导航问题。

Abstract: Deploying self-navigating surface vessels in inland waterways offers a
sustainable alternative to reduce road traffic congestion and emissions.
However, navigating confined waterways presents unique challenges, including
narrow channels, higher traffic density, and hydrodynamic disturbances.
Existing methods for autonomous vessel navigation often lack the robustness or
precision required for such environments. This paper presents a new motion
planning approach for Automated Surface Vessels (ASVs) using Robust Model
Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By
incorporating channel borders and obstacles as safety constraints within the
control design framework, the proposed method ensures both collision avoidance
and robust navigation on complex waterways. Simulation results demonstrate the
efficacy of the proposed method in safely guiding ASVs under realistic
conditions, highlighting its improved safety and adaptability compared to the
state-of-the-art.

</details>


### [470] [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](https://arxiv.org/abs/2509.06953)
*Jiahui Yang,Jason Jingzhou Liu,Yulong Li,Youssef Khaky,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: DRP是一种基于视觉-运动的神经运动策略，用于在动态、部分可观察的环境中生成无碰撞运动，它直接处理点云输入，并在模拟和现实世界中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在动态、部分可观察的环境中为机器人机械臂生成无碰撞运动是一个基本挑战。经典的运动规划器速度慢且需要完整环境知识，而神经运动策略泛化能力有限。

Method: 提出了一种名为DRP（Deep Reactive Policy）的视觉-运动神经运动策略。DRP的核心是IMPACT，一个基于Transformer的神经运动策略，在大规模模拟场景中进行了预训练。通过学生-教师迭代微调来改进静态障碍物避障，并引入DCP-RMP模块在推理时增强动态障碍物避障能力。

Result: DRP在包含杂乱场景、动态移动障碍物和目标阻塞等挑战性任务上进行了评估，展示了强大的泛化能力，在模拟和现实世界中的成功率均优于之前的经典和神经方法。

Conclusion: DRP是一种有效的方法，可以直接处理点云输入，并在动态、部分可观察的环境中实现具身智能。

Abstract: Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com

</details>


### [471] [Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)](https://arxiv.org/abs/2509.06191)
*Yifei Ren,Edward Johns*

Main category: cs.RO

TL;DR: 通过使用3D生成模型和单次真实世界演示来增强数据集，可以学习全向策略，从而提高机器人完成任务的能力，即使在与演示不同的初始状态下也是如此。


<details>
  <summary>Details</summary>
Motivation: 使用3D生成模型来增强数据集，以提高机器人策略的学习效率，使其能够在与演示不同的初始状态下执行任务。

Method: 利用3D生成模型从单次真实世界演示中生成数据，然后在此扩充的数据集上学习全向策略。

Result: 所提出的方法显著提高了机器人完成任务的能力，即使在与演示不同的初始状态下也是如此，并且优于使用替代数据增强方法的基线方法。

Conclusion: 3D生成模型可以有效地用于增强数据集，从而在机器人策略学习中实现更高效和更通用的性能。

Abstract: Recent 3D generative models, which are capable of generating full object
shapes from just a few images, now open up new opportunities in robotics. In
this work, we show that 3D generative models can be used to augment a dataset
from a single real-world demonstration, after which an omnidirectional policy
can be learned within this imagined dataset. We found that this enables a robot
to perform a task when initialised from states very far from those observed
during the demonstration, including starting from the opposite side of the
object relative to the real-world demonstration, significantly reducing the
number of demonstrations required for policy learning. Through several
real-world experiments across tasks such as grasping objects, opening a drawer,
and placing trash into a bin, we study these omnidirectional policies by
investigating the effect of various design choices on policy behaviour, and we
show superior performance to recent baselines which use alternative methods for
data augmentation.

</details>


### [472] [Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control](https://arxiv.org/abs/2509.06201)
*Jun Yamada,Adithyavairavan Murali,Ajay Mandlekar,Clemens Eppner,Ingmar Posner,Balakumar Sundaralingam*

Main category: cs.RO

TL;DR: Grasping-MPC是一种基于视觉的闭环6-DoF抓取策略，通过结合价值函数和MPC框架，提高了在杂乱环境下的抓取成功率，并在模拟和真实世界中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中抓取各种物体仍然是一个重大挑战，现有的开环抓取方法在控制环境外效果不佳，而闭环方法在简化设置和有限的物体集上表现不佳，无法泛化。

Method: 提出了一种名为Grasping-MPC的闭环6-DoF视觉抓取策略。该策略利用在包含成功和失败抓取的大规模合成数据集（200万个抓取轨迹）上训练的价值函数，并将其集成到MPC框架中，同时加入鼓励避碰和平稳执行的成本项。

Result: 在FetchBench和真实世界的不同环境中评估Grasping-MPC。结果显示，在模拟环境中抓取成功率提高了32.6%，在真实世界的嘈杂条件下提高了33.3%，优于开环、扩散策略、Transformer策略和IQL等方法。

Conclusion: Grasping-MPC在杂乱环境中对新物体进行鲁棒和反应式抓取方面表现出色，显著提高了抓取成功率。

Abstract: Grasping of diverse objects in unstructured environments remains a
significant challenge. Open-loop grasping methods, effective in controlled
settings, struggle in cluttered environments. Grasp prediction errors and
object pose changes during grasping are the main causes of failure. In
contrast, closed-loop methods address these challenges in simplified settings
(e.g., single object on a table) on a limited set of objects, with no path to
generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping
policy designed for robust and reactive grasping of novel objects in cluttered
environments. Grasp-MPC incorporates a value function, trained on visual
observations from a large-scale synthetic dataset of 2 million grasp
trajectories that include successful and failed attempts. We deploy this
learned value function in an MPC framework in combination with other cost terms
that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC
on FetchBench and real-world settings across diverse environments. Grasp-MPC
improves grasp success rates by up to 32.6% in simulation and 33.3% in
real-world noisy conditions, outperforming open-loop, diffusion policy,
transformer policy, and IQL approaches. Videos and more at
http://grasp-mpc.github.io.

</details>


### [473] [O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.06233)
*Tongxuan Tian,Xuhui Kang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 本研究提出了一种名为O$^3$Afford 的新方法，用于在数据有限的情况下学习物体间的交互能力，并将其与大型语言模型结合，以提升机器人的操作和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一物体交互能力的预测，忽略了现实世界中物体间交互的普遍性。本研究旨在解决数据量有限的情况下物体间交互能力的基础问题。

Method: 提出了一种新颖的、基于少样本学习的、用于机器人操作的一触式三维物体间交互能力学习方法。该方法结合了视觉基础模型的语义特征和点云表示的几何理解能力，实现了对新物体和类别的有效泛化。此外，还将三维交互能力表示与大型语言模型（LLMs）集成，以增强LLMs在生成任务特定约束函数时对物体交互的理解和推理能力。

Result: 实验结果表明，O$^3$Afford 在三维物体间交互能力基础和机器人操作任务上，在准确性和泛化能力方面均显著优于现有方法。

Conclusion: 本研究提出的O$^3$Afford 方法能够有效解决数据量有限的物体间交互能力学习问题，并通过与大型语言模型结合，显著提升了机器人的操作和推理能力。

Abstract: Grounding object affordance is fundamental to robotic manipulation as it
establishes the critical link between perception and action among interacting
objects. However, prior works predominantly focus on predicting single-object
affordance, overlooking the fact that most real-world interactions involve
relationships between pairs of objects. In this work, we address the challenge
of object-to-object affordance grounding under limited data contraints.
Inspired by recent advances in few-shot learning with 2D vision foundation
models, we propose a novel one-shot 3D object-to-object affordance learning
approach for robotic manipulation. Semantic features from vision foundation
models combined with point cloud representation for geometric understanding
enable our one-shot learning pipeline to generalize effectively to novel
objects and categories. We further integrate our 3D affordance representation
with large language models (LLMs) for robotics manipulation, significantly
enhancing LLMs' capability to comprehend and reason about object interactions
when generating task-specific constraint functions. Our experiments on 3D
object-to-object affordance grounding and robotic manipulation demonstrate that
our O$^3$Afford significantly outperforms existing baselines in terms of both
accuracy and generalization capability.

</details>


### [474] [DCReg: Decoupled Characterization for Efficient Degenerate LiDAR Registration](https://arxiv.org/abs/2509.06285)
*Xiangcheng Hu,Xieyuanli Chen,Mingkai Jia,Jin Wu,Ping Tan,Steven L. Waslander*

Main category: cs.RO

TL;DR: DCReg是一个新框架，通过舒尔补分解、定量表征和预处理技术解决激光雷达点云在退化或狭窄环境中因病态条件导致的配准不准确问题，并在实验中显示出更高的准确性和更快的速度。


<details>
  <summary>Details</summary>
Motivation: 在几何退化或狭窄环境中，激光雷达点云配准会变得病态，导致不稳定的解和准确性下降。现有方法未能有效检测、解释和解决这种病态条件。

Method: 1. 病态条件检测：利用舒尔补分解对海森矩阵进行分解，将配准问题解耦为旋转和翻译子空间，消除掩盖退化模式的耦合效应。 2. 定量表征：在解耦的子空间中，建立数学特征空间和物理运动方向之间的映射，明确哪些运动缺乏约束。 3. 目标性缓解策略：设计一种预处理程序，选择性地稳定已识别的病态条件方向，同时保留可观测空间中所有约束良好的信息，从而实现高效鲁棒的优化。

Result: 实验表明，DCReg 在各种环境中，在定位准确性方面比最先进的方法提高了至少 20%-50%，速度提高了 5-100 倍。

Conclusion: DCReg 通过系统地解决病态条件问题，显著提高了激光雷达点云配准的准确性和效率，尤其是在具有挑战性的环境中。

Abstract: LiDAR point cloud registration is fundamental to robotic perception and
navigation. However, in geometrically degenerate or narrow environments,
registration problems become ill-conditioned, leading to unstable solutions and
degraded accuracy. While existing approaches attempt to handle these issues,
they fail to address the core challenge: accurately detection, interpret, and
resolve this ill-conditioning, leading to missed detections or corrupted
solutions. In this study, we introduce DCReg, a principled framework that
systematically addresses the ill-conditioned registration problems through
three integrated innovations. First, DCReg achieves reliable ill-conditioning
detection by employing a Schur complement decomposition to the hessian matrix.
This technique decouples the registration problem into clean rotational and
translational subspaces, eliminating coupling effects that mask degeneracy
patterns in conventional analyses. Second, within these cleanly subspaces, we
develop quantitative characterization techniques that establish explicit
mappings between mathematical eigenspaces and physical motion directions,
providing actionable insights about which specific motions lack constraints.
Finally, leveraging this clean subspace, we design a targeted mitigation
strategy: a novel preconditioner that selectively stabilizes only the
identified ill-conditioned directions while preserving all well-constrained
information in observable space. This enables efficient and robust optimization
via the Preconditioned Conjugate Gradient method with a single physical
interpretable parameter. Extensive experiments demonstrate DCReg achieves at
least 20% - 50% improvement in localization accuracy and 5-100 times speedup
over state-of-the-art methods across diverse environments. Our implementation
will be available at https://github.com/JokerJohn/DCReg.

</details>


### [475] [Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion](https://arxiv.org/abs/2509.06296)
*Francisco Affonso,Felipe Andrade G. Tommaselli,Juliano Negri,Vivian S. Medeiros,Mateus V. Gasparino,Girish Chowdhary,Marcelo Becker*

Main category: cs.RO

TL;DR: 使用 Dyna 风格范式，通过在 PPO 控制器的标准 rollout 末尾附加合成数据，来提高样本效率，以实现四足动物的运动控制。


<details>
  <summary>Details</summary>
Motivation: 传统的基于 RL 的运动控制器通常存在数据效率低的问题，需要大量的交互才能获得稳健的性能。

Method: 提出了一种基于模型的强化学习（MBRL）框架，通过在 PPO 控制器的标准 rollout 末尾附加合成数据，来提高四足动物运动的样本效率，遵循 Dyna 风格范式。一个与策略一同训练的预测模型，会生成短期合成转换，并使用基于策略更新迭代的调度策略逐步集成。

Result: 通过消融研究，确定了样本效率和 rollout 长度之间的强相关性，这指导了实验设计。在 Unitree Go1 机器人的模拟中验证了该方法，并表明用合成数据替换部分模拟步骤，不仅可以模仿扩展的 rollout，还可以提高策略回报并降低方差。

Conclusion: 所提出的方法在模拟中得到验证，并表明用合成数据替换部分模拟步骤，不仅可以模仿扩展的 rollout，还可以提高策略回报并降低方差，并且这种改进能够以更少的模拟步骤来跟踪各种运动命令。

Abstract: Traditional RL-based locomotion controllers often suffer from low data
efficiency, requiring extensive interaction to achieve robust performance. We
present a model-based reinforcement learning (MBRL) framework that improves
sample efficiency for quadrupedal locomotion by appending synthetic data to the
end of standard rollouts in PPO-based controllers, following the Dyna-Style
paradigm. A predictive model, trained alongside the policy, generates
short-horizon synthetic transitions that are gradually integrated using a
scheduling strategy based on the policy update iterations. Through an ablation
study, we identified a strong correlation between sample efficiency and rollout
length, which guided the design of our experiments. We validated our approach
in simulation on the Unitree Go1 robot and showed that replacing part of the
simulated steps with synthetic ones not only mimics extended rollouts but also
improves policy return and reduces variance. Finally, we demonstrate that this
improvement transfers to the ability to track a wide range of locomotion
commands using fewer simulated steps.

</details>


### [476] [Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots](https://arxiv.org/abs/2509.06342)
*Filip Bjelonic,Fabian Tischhauser,Marco Hutter*

Main category: cs.RO

TL;DR: 该框架通过集成仿真到现实强化学习和基于物理的永磁同步电机能量模型，实现了机器人稳健且节能的运动。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人能够在现实世界环境中实用，必须同时实现稳健的运动和能源效率。然而，在仿真中训练的控制器往往无法可靠地转移，并且大多数现有方法都忽略了执行器特异性的能量损失或依赖于复杂、手动调整的奖励公式。

Method: 提出一个整合了仿真到现实强化学习和用于永磁同步电机（PMSM）的物理基础能量模型的框架。该框架需要最少的参数集来捕捉仿真到现实的差距，并采用了一个紧凑的四项奖励，其中包含基于第一性原理的能量损失公式，以平衡电气和机械损耗。

Result: 通过自下而上的动态参数识别研究，跨越执行器、空中轨迹的全机器人和地面运动，对该方法进行了评估和验证。该框架在三个主要平台上进行了测试，并在另外十个机器人上进行了部署，证明了在没有动态参数随机化的情况下能够可靠地转移策略。与最先进的方法相比，该方法提高了能源效率，将 ANYmal 的整体运输成本降低了 32%（值为 1.27）。

Conclusion: 该研究提出的框架能够实现机器人稳健且节能的运动，并克服了现有方法在仿真到现实转移和能源效率方面的限制。

Abstract: Legged robots must achieve both robust locomotion and energy efficiency to be
practical in real-world environments. Yet controllers trained in simulation
often fail to transfer reliably, and most existing approaches neglect
actuator-specific energy losses or depend on complex, hand-tuned reward
formulations. We propose a framework that integrates sim-to-real reinforcement
learning with a physics-grounded energy model for permanent magnet synchronous
motors. The framework requires a minimal parameter set to capture the
simulation-to-reality gap and employs a compact four-term reward with a
first-principle-based energetic loss formulation that balances electrical and
mechanical dissipation. We evaluate and validate the approach through a
bottom-up dynamic parameter identification study, spanning actuators,
full-robot in-air trajectories and on-ground locomotion. The framework is
tested on three primary platforms and deployed on ten additional robots,
demonstrating reliable policy transfer without randomization of dynamic
parameters. Our method improves energetic efficiency over state-of-the-art
methods, achieving a 32 percent reduction in the full Cost of Transport of
ANYmal (value 1.27). All code, models, and datasets will be released.

</details>


### [477] [Adaptive Evolution Factor Risk Ellipse Framework for Reliable and Safe Autonomous Driving](https://arxiv.org/abs/2509.06375)
*Fujiang Yuan,Zhen Tian,Yangfan He,Guojian Zou,Chunhong Yuan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: ERPF-MPC通过动态更新风险评估来解决自动驾驶中的安全、效率和舒适性挑战，通过风险椭圆和自适应进化因子提供更平稳、更安全、更快的导航。


<details>
  <summary>Details</summary>
Motivation: 传统的自动驾驶安全方法要么过于保守或计算密集，要么需要大量数据且泛化性差。现有的轻量级方法（如RPF）是静态的，难以适应动态交通。因此，需要一种能够动态适应复杂交互式驾驶场景的新方法。

Method: 提出进化风险势场（ERPF），该方法利用历史障碍物邻近数据动态更新风险评估。引入风险椭圆（Risk-Ellipse）结合纵向范围和横向不确定性，并定义自适应进化因子（Evolution Factor）通过TTC和TWH的S型归一化实时调整椭圆轴。将此风险指标集成到模型预测控制（MPC）框架中。

Result: 与现有方法相比，ERPF-MPC在实验中始终如一地实现了更平稳的轨迹、更高的平均速度和无碰撞导航。

Conclusion: ERPF-MPC提供了一种稳健且自适应的解决方案，适用于复杂的交互式驾驶环境，能有效处理不确定的驾驶情况。

Abstract: In recent years, ensuring safety, efficiency, and comfort in interactive
autonomous driving has become a critical challenge. Traditional model-based
techniques, such as game-theoretic methods and robust control, are often overly
conservative or computationally intensive. Conversely, learning-based
approaches typically require extensive training data and frequently exhibit
limited interpretability and generalizability. Simpler strategies, such as Risk
Potential Fields (RPF), provide lightweight alternatives with minimal data
demands but are inherently static and struggle to adapt effectively to dynamic
traffic conditions. To overcome these limitations, we propose the Evolutionary
Risk Potential Field (ERPF), a novel approach that dynamically updates risk
assessments in dynamical scenarios based on historical obstacle proximity data.
We introduce a Risk-Ellipse construct that combines longitudinal reach and
lateral uncertainty into a unified spatial temporal collision envelope.
Additionally, we define an adaptive Evolution Factor metric, computed through
sigmoid normalization of Time to Collision (TTC) and Time-Window-of-Hazard
(TWH), which dynamically adjusts the dimensions of the ellipse axes in real
time. This adaptive risk metric is integrated seamlessly into a Model
Predictive Control (MPC) framework, enabling autonomous vehicles to proactively
address complex interactive driving scenarios in terms of uncertain driving of
surrounding vehicles. Comprehensive comparative experiments demonstrate that
our ERPF-MPC approach consistently achieves smoother trajectories, higher
average speeds, and collision-free navigation, offering a robust and adaptive
solution suitable for complex interactive driving environments.

</details>


### [478] [Safety Meets Speed: Accelerated Neural MPC with Safety Guarantees and No Retraining](https://arxiv.org/abs/2509.06404)
*Kaikai Wang,Tianxun Li,Liang Xu,Qinglei Hu,Keyou You*

Main category: cs.RO

TL;DR: BAN-MPC框架结合了神经网络和MPC的优点，通过使用CBF来保证安全，并利用离线学习的神经网络来减少在线计算的复杂性，实现了比传统MPC快200倍的计算速度，能够实现无碰撞的导航。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在满足约束条件的同时，其实时执行可能会超出嵌入式计算预算。因此，需要一种能够融合神经网络快速计算能力和MPC约束处理能力的框架。

Method: 提出了一种BAN-MPC框架，该框架使用CBF替代传统的欧几里得距离来避免碰撞，并通过将离线学习的神经网络价值函数集成到MPC的优化目标中，以减少在线计算的复杂性。此外，还使用第二个神经网络来学习价值函数对系统参数的敏感性，并在此基础上自适应地调整价值函数，以应对模型参数的变化。

Result: BAN-MPC在Jetson Nano上的HIL实验表明，其运行速度比传统MPC快200倍，在模型参数变化15%的情况下，控制误差低于5%，实现了无碰撞导航。

Conclusion: BAN-MPC是一种有效的嵌入式MPC替代方案，它能够实现快速、安全且鲁棒的控制。

Abstract: While Model Predictive Control (MPC) enforces safety via constraints, its
real-time execution can exceed embedded compute budgets. We propose a
Barrier-integrated Adaptive Neural Model Predictive Control (BAN-MPC) framework
that synergizes neural networks' fast computation with MPC's
constraint-handling capability. To ensure strict safety, we replace traditional
Euclidean distance with Control Barrier Functions (CBFs) for collision
avoidance. We integrate an offline-learned neural value function into the
optimization objective of a Short-horizon MPC, substantially reducing online
computational complexity. Additionally, we use a second neural network to learn
the sensitivity of the value function to system parameters, and adaptively
adjust the neural value function based on this neural sensitivity when model
parameters change, eliminating the need for retraining and reducing offline
computation costs. The hardware in-the-loop (HIL) experiments on Jetson Nano
show that BAN-MPC solves 200 times faster than traditional MPC, enabling
collision-free navigation with control error below 5\% under model parameter
variations within 15\%, making it an effective embedded MPC alternative.

</details>


### [479] [Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation](https://arxiv.org/abs/2509.06433)
*Ian Page,Pierre Susbielle,Olivier Aycard,Pierre-Brice Wieber*

Main category: cs.RO

TL;DR: 提出一种结合高斯泼溅SLAM和在线地图的GPU加速远程遥操作新方法，以提高在未知环境下的效率。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中实现高效远程遥操作具有挑战性，因为操作员需要快速了解环境布局。传统在线地图遥操作系统因计算成本高，难以实时生成视觉上准确的3D地图，导致遥操作性能不佳。

Method: 提出一种新颖、模块化且高效的GPU加速方案，将高斯泼溅SLAM的最新进展与现有在线地图遥操作系统集成。

Result: 与最先进的遥操作系统相比，该方法在决策速度和与环境交互的准确性方面有了显著改善，从而提高了遥操作效率。

Conclusion: 该系统通过将照片级逼真的地图生成与实时性能无缝集成，增强了远程遥操作能力，从而在不熟悉的环境中实现了有效的遥操作。

Abstract: Achieving efficient remote teleoperation is particularly challenging in
unknown environments, as the teleoperator must rapidly build an understanding
of the site's layout. Online 3D mapping is a proven strategy to tackle this
challenge, as it enables the teleoperator to progressively explore the site
from multiple perspectives. However, traditional online map-based teleoperation
systems struggle to generate visually accurate 3D maps in real-time due to the
high computational cost involved, leading to poor teleoperation performances.
In this work, we propose a solution to improve teleoperation efficiency in
unknown environments. Our approach proposes a novel, modular and efficient
GPU-based integration between recent advancement in gaussian splatting SLAM and
existing online map-based teleoperation systems. We compare the proposed
solution against state-of-the-art teleoperation systems and validate its
performances through real-world experiments using an aerial vehicle. The
results show significant improvements in decision-making speed and more
accurate interaction with the environment, leading to greater teleoperation
efficiency. In doing so, our system enhances remote teleoperation by seamlessly
integrating photorealistic mapping generation with real-time performances,
enabling effective teleoperation in unfamiliar environments.

</details>


### [480] [Interactive Shaping of Granular Media Using Reinforcement Learning](https://arxiv.org/abs/2509.06469)
*Benedikt Kreis,Malte Mosbach,Anny Ripke,Muhammad Ehsan Ullah,Sven Behnke,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习框架，使机器人手臂能够操作和塑形颗粒介质（如沙子），并成功应用于实际场景。


<details>
  <summary>Details</summary>
Motivation: 由于颗粒介质的高维度配置空间和复杂动力学特性，传统的基于规则的方法在自动化操作中存在局限性，因此需要新的方法来解决这些挑战。

Method: 使用强化学习框架，结合机器人手臂、立方体末端执行器和立体摄像头，通过试错学习自适应的操纵策略，并注重使用紧凑的观测和简洁的奖励设计来处理大的配置空间。

Result: 所提出的强化学习方法在训练能够操作颗粒介质的视觉策略方面是有效的，并且在实际应用中表现优于两个基线方法。

Conclusion: 本文提出的强化学习框架能够有效地训练机器人手臂塑形颗粒介质，并成功应用于实际场景，证明了其在处理高维复杂系统方面的潜力。

Abstract: Autonomous manipulation of granular media, such as sand, is crucial for
applications in construction, excavation, and additive manufacturing. However,
shaping granular materials presents unique challenges due to their
high-dimensional configuration space and complex dynamics, where traditional
rule-based approaches struggle without extensive engineering efforts.
Reinforcement learning (RL) offers a promising alternative by enabling agents
to learn adaptive manipulation strategies through trial and error. In this
work, we present an RL framework that enables a robotic arm with a cubic
end-effector and a stereo camera to shape granular media into desired target
structures. We show the importance of compact observations and concise reward
formulations for the large configuration space, validating our design choices
with an ablation study. Our results demonstrate the effectiveness of the
proposed approach for the training of visual policies that manipulate granular
media including their real-world deployment, outperforming two baseline
approaches.

</details>


### [481] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 提出一种事件驱动的通信机制（ED-CBBA），在不影响收敛性和性能的前提下，减少了多机器人任务分配中的通信量。


<details>
  <summary>Details</summary>
Motivation: 多机器人协同任务（如多侦察无人机、搜救）需要去中心化的任务分配算法，但现有算法（如CBBA）需要持续通信，易造成网络拥堵和丢包。

Method: 提出一种事件驱动的通信机制（ED-CBBA），用于改进CBBA算法，使其在通信受限的情况下仍能有效运行。

Result: 理论上证明ED-CBBA的解质量与CBBA相当，并通过蒙特卡洛模拟验证了其有效性，结果显示通信传输次数减少了高达52%。

Conclusion: ED-CBBA是一种有效的去中心化任务分配算法，能够在减少通信量的同时，保持与CBBA相当的性能。

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [482] [Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization](https://arxiv.org/abs/2509.06582)
*Carlos A. Pinheiro de Sousa,Niklas Gröne,Mathias Günther,Oliver Deussen*

Main category: cs.RO

TL;DR: 该框架通过结合运动捕捉和SLAM技术，实现了多用户VR空间同步，解决了现有方法的延迟、抖动和漂移问题，提高了空间精度、舒适度、可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有VR协作方法存在延迟、抖动和漂移问题，无法满足自然的多用户交互需求。

Method: 结合运动捕捉系统和基于SLAM的Inside-out追踪技术，实现用户在物理空间对齐的共享虚拟环境中的同步。

Result: 实现了高帧率、低延迟的性能，空间精度满足自然多用户交互需求，并提高了舒适度、可扩展性和鲁棒性。

Conclusion: 该框架在空间精度、舒适度、可扩展性和鲁棒性方面优于现有解决方案，为自然的多用户交互提供了支持。

Abstract: We introduce a multi-user VR co-location framework that synchronizes users
within a shared virtual environment aligned to physical space. Our approach
combines a motion capture system with SLAM-based inside-out tracking to deliver
smooth, high-framerate, low-latency performance. Previous methods either rely
on continuous external tracking, which introduces latency and jitter, or on
one-time calibration, which cannot correct drift over time. In contrast, our
approach combines the responsiveness of local HMD SLAM tracking with the
flexibility to realign to an external source when needed. It also supports
real-time pose sharing across devices, ensuring consistent spatial alignment
and engagement between users. Our evaluation demonstrates that our framework
achieves the spatial accuracy required for natural multi-user interaction while
offering improved comfort, scalability, and robustness over existing co-located
VR solutions.

</details>


### [483] [A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling](https://arxiv.org/abs/2509.06593)
*Meher V. R. Malladi,Tiziano Guadagnino,Luca Lobefaro,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的激光雷达-惯性里程计系统，该系统不依赖于特定传感器的建模，并能在各种机器人传感器和平台上实现高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 准确的里程计是机器人导航的关键组成部分，对机器人的运动估计有直接影响。现有方法在不同传感器和应用场景下鲁棒性不足。

Method: 提出了一种不依赖特定传感器建模的激光雷达-惯性里程计系统。该系统仅需简化的惯性测量单元（IMU）运动模型进行IMU数据集成，并采用点云地图配准（scan-to-map）的方式直接配准激光雷达数据。通过引入新的正则化方法来提高激光雷达配准的性能。

Result: 在多种数据集上进行了广泛的实验，涵盖了常见的机器人传感器和平台。实验证明，该系统在所有场景下均使用相同的配置，表现出优越的鲁棒性，并取得了良好的里程计性能。

Conclusion: 所提出的激光雷达-惯性里程计系统具有高度的鲁棒性，能够适应不同的传感器和应用场景，并且性能优越。已开源实现，以供社区进一步研究和使用。

Abstract: Accurate odometry is a critical component in a robotic navigation stack, and
subsequent modules such as planning and control often rely on an estimate of
the robot's motion. Sensor-based odometry approaches should be robust across
sensor types and deployable in different target domains, from solid-state
LiDARs mounted on cars in urban-driving scenarios to spinning LiDARs on
handheld packages used in unstructured natural environments. In this paper, we
propose a robust LiDAR-inertial odometry system that does not rely on
sensor-specific modeling. Sensor fusion techniques for LiDAR and inertial
measurement unit (IMU) data typically integrate IMU data iteratively in a
Kalman filter or use pre-integration in a factor graph framework, combined with
LiDAR scan matching often exploiting some form of feature extraction. We
propose an alternative strategy that only requires a simplified motion model
for IMU integration and directly registers LiDAR scans in a scan-to-map
approach. Our approach allows us to impose a novel regularization on the LiDAR
registration, improving the overall odometry performance. We detail extensive
experiments on a number of datasets covering a wide array of commonly used
robotic sensors and platforms. We show that our approach works with the exact
same configuration in all these scenarios, demonstrating its robustness. We
have open-sourced our implementation so that the community can build further on
our work and use it in their navigation stacks.

</details>


### [484] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: LiHRA是一个包含3D激光雷达点云、人体关键点和机器人关节状态的多模态数据集，旨在促进人机交互（HRI）场景中自动化风险监控（RM）方法的发展。


<details>
  <summary>Details</summary>
Motivation: 工业环境中协作机器人的普及增加了对可靠安全系统的需求，但缺乏真实的人机交互数据集阻碍了RM方法的开发。

Method: LiHRA数据集收集了六种代表性HRI场景（包括协作、共存、物体交接和表面抛光任务，有安全和危险两种版本）的4,431个标记点云，并结合了3D激光雷达点云、人体关键点和机器人关节状态。

Result: 提出了一个利用上下文信息（包括机器人状态和动态模型）来量化每个场景随时间变化的风险水平的RM方法。

Conclusion: LiHRA数据集为未来在人机工作空间中进行实时RM和自适应安全策略的研究奠定了基础，因为它结合了高分辨率激光雷达数据、精确的人体跟踪、机器人状态数据和真实的碰撞事件。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>


### [485] [T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation](https://arxiv.org/abs/2509.06644)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: T-araVLN是一个用于农业机器人视觉和语言导航（VLN）的方法，通过翻译和优化自然语言指令来提高导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有的农业机器人导航方法依赖手动操作或固定轨道，并且在理解复杂指令方面存在困难。 AgriVLN虽然能理解简单指令，但在理解复杂指令时常常出错。

Method: 提出T-araVLN方法，包含一个指令翻译模块，可以将原始指令翻译成更精确、更优化的指令。

Result: 在A2A基准上，T-araVLN将成功率（SR）从0.47提高到0.63，将导航误差（NE）从2.91米减少到2.28米。

Conclusion: T-araVLN在农业VLN领域展现出最先进的性能。

Abstract: Agricultural robotic agents have been becoming powerful helpers in a wide
range of agricultural tasks, nevertheless, still heavily rely on manual
operation or untransportable railway for movement. The AgriVLN method and the
A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the
agricultural domain, enabling agents navigate to the target position following
the natural language instructions. AgriVLN effectively understands the simple
instructions, however, often misunderstands the complicated instructions. To
bridge this gap, we propose the method of Translator for Agricultural Robotic
Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction
Translator module translates the original instruction to be both refined and
precise. Being evaluated on the A2A benchmark, our T-araVLN effectively
improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating
the state-of-the-art performance in the agricultural domain. Code:
https://github.com/AlexTraveling/T-araVLN.

</details>


### [486] [Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](https://arxiv.org/abs/2509.06768)
*Oluwadamilola Sotomi,Devika Kodi,Kiruthiga Chandra Shekar,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文提出了一种多模态异常检测与缓解系统，利用视觉-语言模型和大型语言模型来识别和报告危险情况，并能对城市和环境异常做出反应。


<details>
  <summary>Details</summary>
Motivation: 为了让自主机器人在动态环境中能识别、报告并主动缓解异常情况，以提高安全性和操作连续性。

Method: 该系统集成了视觉-语言模型和大型语言模型，实现了对城市和环境异常的实时识别、报告和响应。通过将危险和冲突状态纳入机器人的决策框架，并触发特定的缓解策略，来应对不同类型的异常。

Result: 用户研究（n=30）表明，该系统在异常检测方面具有91.2%的预测准确率，并且利用边缘AI架构实现了较低的延迟响应。

Conclusion: 所提出的多模态系统能够有效地检测和响应城市及环境中的异常情况，从而提高自主机器人的安全性和运行效率。

Abstract: Autonomous robots operating in dynamic environments should identify and
report anomalies. Embodying proactive mitigation improves safety and
operational continuity. This paper presents a multimodal anomaly detection and
mitigation system that integrates vision-language models and large language
models to identify and report hazardous situations and conflicts in real-time.
The proposed system enables robots to perceive, interpret, report, and if
possible respond to urban and environmental anomalies through proactive
detection mechanisms and automated mitigation actions. A key contribution in
this paper is the integration of Hazardous and Conflict states into the robot's
decision-making framework, where each anomaly type can trigger specific
mitigation strategies. User studies (n = 30) demonstrated the effectiveness of
the system in anomaly detection with 91.2% prediction accuracy and relatively
low latency response times using edge-ai architecture.

</details>


### [487] [CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](https://arxiv.org/abs/2509.06819)
*Daniel San José Pro,Oliver Hausdörfer,Ralf Römer,Maximilian Dösch,Martin Schuck,Angela P. Schöllig*

Main category: cs.RO

TL;DR: CRISP是一个轻量级的C++实现的机器人控制器，用于ROS2标准，可以无缝集成学习控制器和遥操作，以实现平稳的参考跟踪，并通过Python和Gymnasium接口提供统一的记录和部署流程。


<details>
  <summary>Details</summary>
Motivation: 学习驱动的控制器（如扩散策略和视觉-语言动作模型）通常会导致机器人状态变化低频或不连续。为了实现平稳的参考跟踪，需要一个低级控制器，将高级目标命令转换为关节扭矩，从而在接触交互期间实现顺应性行为。

Method: CRISP是一个轻量级的C++实现的顺应性笛卡尔和关节空间控制器，适用于ROS2控制标准。它与任何提供关节扭矩接口的机械臂兼容，并通过Python和Gymnasium接口提供了一个统一的流程，用于从硬件和模拟中记录数据以及部署学习驱动的策略。

Result: CRISP已在Franka Robotics FR3硬件以及Kuka IIWA14和Kinova Gen3的模拟环境中得到验证。它提供了一个统一的流程，用于数据收集和策略执行。

Conclusion: CRISP旨在快速集成、灵活部署和实时性能，它提供了一个统一的流程，用于数据收集和策略执行，从而降低了将学习驱动的方法应用于ROS2兼容机械臂的门槛。

Abstract: Learning-based controllers, such as diffusion policies and vision-language
action models, often generate low-frequency or discontinuous robot state
changes. Achieving smooth reference tracking requires a low-level controller
that converts high-level targets commands into joint torques, enabling
compliant behavior during contact interactions. We present CRISP, a lightweight
C++ implementation of compliant Cartesian and joint-space controllers for the
ROS2 control standard, designed for seamless integration with high-level
learning-based policies as well as teleoperation. The controllers are
compatible with any manipulator that exposes a joint-torque interface. Through
our Python and Gymnasium interfaces, CRISP provides a unified pipeline for
recording data from hardware and simulation and deploying high-level
learning-based policies seamlessly, facilitating rapid experimentation. The
system has been validated on hardware with the Franka Robotics FR3 and in
simulation with the Kuka IIWA14 and Kinova Gen3. Designed for rapid
integration, flexible deployment, and real-time performance, our implementation
provides a unified pipeline for data collection and policy execution, lowering
the barrier to applying learning-based methods on ROS2-compatible manipulators.
Detailed documentation is available at the project website -
https://utiasDSL.github.io/crisp_controllers.

</details>


### [488] [Dynamic Modeling and Efficient Data-Driven Optimal Control for Micro Autonomous Surface Vehicles](https://arxiv.org/abs/2509.06882)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本研究提出了一种结合物理驱动模型和数据驱动最优控制框架的MicroASV控制方法，以解决小型自主水面航行器在复杂水域中控制精度和鲁棒性的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决MicroASV在狭窄或浅水区域运行时，由于非线性流体动力、自运动效应、环境干扰（如波浪和边界效应）等因素导致的精确鲁棒控制难题。

Method: 提出一个面向过驱动MicroASV的物理驱动动力学模型，并引入一种数据驱动的最优控制框架，利用基于弱形式的在线模型学习方法，实时优化物理驱动模型，实现自适应控制。

Result: 仿真结果表明，该方法在未知载荷和外部干扰下，显著提高了轨迹跟踪的精度和鲁棒性。

Conclusion: 数据驱动的在线学习最优控制方法能够有效提升MicroASV的性能，为实现更可靠、更精确的自主水面航行器操作提供了可能性。

Abstract: Micro Autonomous Surface Vehicles (MicroASVs) offer significant potential for
operations in confined or shallow waters and swarm robotics applications.
However, achieving precise and robust control at such small scales remains
highly challenging, mainly due to the complexity of modeling nonlinear
hydrodynamic forces and the increased sensitivity to self-motion effects and
environmental disturbances, including waves and boundary effects in confined
spaces. This paper presents a physics-driven dynamics model for an
over-actuated MicroASV and introduces a data-driven optimal control framework
that leverages a weak formulation-based online model learning method. Our
approach continuously refines the physics-driven model in real time, enabling
adaptive control that adjusts to changing system parameters. Simulation results
demonstrate that the proposed method substantially enhances trajectory tracking
accuracy and robustness, even under unknown payloads and external disturbances.
These findings highlight the potential of data-driven online learning-based
optimal control to improve MicroASV performance, paving the way for more
reliable and precise autonomous surface vehicle operations.

</details>


### [489] [LLaDA-VLA: Vision Language Diffusion Action Models](https://arxiv.org/abs/2509.06932)
*Yuqing Wen,Hebei Li,Kefan Gu,Yucheng Zhao,Tiancai Wang,Xiaoyan Sun*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid progress of auto-regressive vision-language models (VLMs) has
inspired growing interest in vision-language-action models (VLA) for robotic
manipulation. Recently, masked diffusion models, a paradigm distinct from
autoregressive models, have begun to demonstrate competitive performance in
text generation and multimodal applications, leading to the development of a
series of diffusion-based VLMs (d-VLMs). However, leveraging such models for
robot policy learning remains largely unexplored. In this work, we present
LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon
pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to
robotic domain, we introduce two key designs: (1) a localized special-token
classification strategy that replaces full-vocabulary classification with
special action token classification, reducing adaptation difficulty; (2) a
hierarchical action-structured decoding strategy that decodes action sequences
hierarchically considering the dependencies within and across actions.
Extensive experiments demonstrate that LLaDA-VLA significantly outperforms
state-of-the-art VLAs on both simulation and real-world robots.

</details>


### [490] [F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](https://arxiv.org/abs/2509.06951)
*Qi Lv,Weijie Kong,Hao Li,Jia Zeng,Zherui Qiu,Delin Qu,Haoming Song,Qizhi Chen,Xiang Deng,Jiangmiao Pang*

Main category: cs.RO

TL;DR: F1是一个结合视觉预测和决策的VLA框架，通过预测未来视觉状态来指导行动生成，以提高在动态环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在动态环境中行为短视且鲁棒性差，需要更具前瞻性的模型。

Method: F1采用混合Transformer架构，包含感知、视觉预测和控制模块，并使用next-scale预测机制生成目标导向的视觉预测，将行动生成重构为受视觉预测引导的反向动力学问题。

Result: F1在真实世界任务和模拟基准测试中表现优于现有方法，提高了任务成功率和泛化能力。

Conclusion: F1通过整合视觉预测，能够生成更具前瞻性的行动，从而在复杂动态环境中实现更好的性能和泛化能力。

Abstract: Executing language-conditioned tasks in dynamic visual environments remains a
central challenge in embodied AI. Existing Vision-Language-Action (VLA) models
predominantly adopt reactive state-to-action mappings, often leading to
short-sighted behaviors and poor robustness in dynamic scenes. In this paper,
we introduce F1, a pretrained VLA framework which integrates the visual
foresight generation into decision-making pipeline. F1 adopts a
Mixture-of-Transformer architecture with dedicated modules for perception,
foresight generation, and control, thereby bridging understanding, generation,
and actions. At its core, F1 employs a next-scale prediction mechanism to
synthesize goal-conditioned visual foresight as explicit planning targets. By
forecasting plausible future visual states, F1 reformulates action generation
as a foresight-guided inverse dynamics problem, enabling actions that
implicitly achieve visual goals. To endow F1 with robust and generalizable
capabilities, we propose a three-stage training recipe on an extensive dataset
comprising over 330k trajectories across 136 diverse tasks. This training
scheme enhances modular reasoning and equips the model with transferable visual
foresight, which is critical for complex and dynamic environments. Extensive
evaluations on real-world tasks and simulation benchmarks demonstrate F1
consistently outperforms existing approaches, achieving substantial gains in
both task success rate and generalization ability.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [491] [Multi-IaC-Eval: Benchmarking Cloud Infrastructure as Code Across Multiple Formats](https://arxiv.org/abs/2509.05303)
*Sam Davidson,Li Sun,Bhavana Bhasker,Laurent Callot,Anoop Deoras*

Main category: cs.DC

TL;DR: 提出了一个包含AWS CloudFormation、Terraform和CDK格式的IaC模板、自然语言修改请求和更新后模板的三元组的新基准数据集Multi-IaC-Bench，以评估基于LLM的IaC生成和变异。评估结果表明，尽管现代LLM在生成语法上有效的IaC方面表现良好，但在语义对齐和处理复杂基础架构模式方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 不同的云服务提供商使用不同的IaC格式，缺乏标准化格式增加了云架构师的复杂性。LLM在自动化IaC创建和维护方面显示出潜力，但缺乏跨多个IaC格式的全面基准限制了其进展。

Method: 创建了一个包含初始IaC模板、自然语言修改请求和相应更新模板的三元组的数据集，通过合成数据生成管道和严格验证来构建Multi-IaC-Bench。

Result: 在Multi-IaC-Bench上评估了几个先进的LLM，发现它们在生成语法上有效的IaC方面成功率很高（>95%），但在语义对齐和处理复杂基础架构模式方面仍面临挑战。消融研究强调了提示工程和重试机制在成功生成IaC方面的重要性。

Conclusion: Multi-IaC-Bench的发布将促进AI辅助基础架构管理领域的研究，并为这一关键领域建立标准化的评估指标。

Abstract: Infrastructure as Code (IaC) is fundamental to modern cloud computing,
enabling teams to define and manage infrastructure through machine-readable
configuration files. However, different cloud service providers utilize diverse
IaC formats. The lack of a standardized format requires cloud architects to be
proficient in multiple IaC languages, adding complexity to cloud deployment.
While Large Language Models (LLMs) show promise in automating IaC creation and
maintenance, progress has been limited by the lack of comprehensive benchmarks
across multiple IaC formats. We present Multi-IaC-Bench, a novel benchmark
dataset for evaluating LLM-based IaC generation and mutation across AWS
CloudFormation, Terraform, and Cloud Development Kit (CDK) formats. The dataset
consists of triplets containing initial IaC templates, natural language
modification requests, and corresponding updated templates, created through a
synthetic data generation pipeline with rigorous validation. We evaluate
several state-of-the-art LLMs on Multi-IaC-Bench, demonstrating that while
modern LLMs can achieve high success rates (>95%) in generating syntactically
valid IaC across formats, significant challenges remain in semantic alignment
and handling complex infrastructure patterns. Our ablation studies highlight
the importance of prompt engineering and retry mechanisms in successful IaC
generation. We release Multi-IaC-Bench to facilitate further research in
AI-assisted infrastructure management and establish standardized evaluation
metrics for this crucial domain.

</details>


### [492] [A Simple and Robust Protocol for Distributed Counting](https://arxiv.org/abs/2509.05870)
*Edith Cohen,Moshe Shechner,Uri Stemmer*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We revisit the distributed counting problem, where a server must continuously
approximate the total number of events occurring across $k$ sites while
minimizing communication. The communication complexity of this problem is known
to be $\Theta(\frac{k}{\epsilon}\log N)$ for deterministic protocols. Huang,
Yi, and Zhang (2012) showed that randomization can reduce this to
$\Theta(\frac{\sqrt{k}}{\epsilon}\log N)$, but their analysis is restricted to
the {\em oblivious setting}, where the stream of events is independent of the
protocol's outputs.
  Xiong, Zhu, and Huang (2023) presented a robust protocol for distributed
counting that removes the oblivious assumption. However, their communication
complexity is suboptimal by a $polylog(k)$ factor and their protocol is
substantially more complex than the oblivious protocol of Huang et al. (2012).
This left open a natural question: could it be that the simple protocol of
Huang et al. (2012) is already robust?
  We resolve this question with two main contributions. First, we show that the
protocol of Huang et al. (2012) is itself not robust by constructing an
explicit adaptive attack that forces it to lose its accuracy. Second, we
present a new, surprisingly simple, robust protocol for distributed counting
that achieves the optimal communication complexity of
$O(\frac{\sqrt{k}}{\epsilon} \log N)$. Our protocol is simpler than that of
Xiong et al. (2023), perhaps even simpler than that of Huang et al. (2012), and
is the first to match the optimal oblivious complexity in the adaptive setting.

</details>


### [493] [DISTRIBUTEDANN: Efficient Scaling of a Single DISKANN Graph Across Thousands of Computers](https://arxiv.org/abs/2509.06046)
*Philip Adams,Menghao Li,Shi Zhang,Li Tan,Qi Chen,Mingqin Li,Zengzhong Li,Knut Risvik,Harsha Vardhan Simhadri*

Main category: cs.DC

TL;DR: DISTRIBUTEDANN是一个分布式向量搜索服务，可在跨越1000多台机器的500亿向量图索引上实现26毫秒的中位查询延迟和每秒超过10万次的查询处理能力，其效率是现有方法的6倍。它结合了分布式键值存储和内存ANN索引，已用于必应搜索引擎，并分享了迁移经验。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模向量搜索系统在分区和路由策略方面存在效率瓶颈，无法满足大规模索引和低延迟查询的需求。

Method: 提出了一种名为DISTRIBUTEDANN的分布式向量搜索服务，该服务利用分布式键值存储和内存ANN索引，在一个单一的、跨越千台机器的500亿向量图索引上实现高效搜索。

Result: 实现了26毫秒的中位查询延迟和每秒超过10万次的查询处理能力，相比现有方法提高了6倍的效率。

Conclusion: DISTRIBUTEDANN成功替换了必应搜索引擎的传统横向扩展架构，证明了其在处理超大规模向量索引和提供低延迟查询方面的有效性。

Abstract: We present DISTRIBUTEDANN, a distributed vector search service that makes it
possible to search over a single 50 billion vector graph index spread across
over a thousand machines that offers 26ms median query latency and processes
over 100,000 queries per second. This is 6x more efficient than existing
partitioning and routing strategies that route the vector query to a subset of
partitions in a scale out vector search system. DISTRIBUTEDANN is built using
two well-understood components: a distributed key-value store and an in-memory
ANN index. DISTRIBUTEDANN has replaced conventional scale-out architectures for
serving the Bing search engine, and we share our experience from making this
transition.

</details>


### [494] [Gathering in Non-Vertex-Transitive Graphs Under Round Robin](https://arxiv.org/abs/2509.06064)
*Serafino Cicerone,Alessia Di Fonso,Gabriele Di Stefano,Alfredo Navarra*

Main category: cs.DC

TL;DR: 机器人可以在图中移动，即使它们不知道终点，但不能检测到其他机器人，并且可以聚集在同一个节点上。


<details>
  <summary>Details</summary>
Motivation: 在机器人之间不检测重复的情况下，解决机器人聚集问题。

Method: 提出并分析一个用于解决机器人聚集问题的算法，该算法适用于非顶点传递图。

Result: 提供一个机器人聚集问题的解决方案，包括算法的正确性和时间复杂度分析。

Conclusion: 在机器人聚集问题中，对于非顶点传递图，即使机器人不能检测到重叠，也可以通过提出的算法来解决。

Abstract: The Gathering problem for a swarm of robots asks for a distributed algorithm
that brings such entities to a common place, not known in advance. We consider
the well-known OBLOT model with robots constrained to move along the edges of a
graph, hence gathering in one vertex, eventually. Despite the classical setting
under which the problem has been usually approached, we consider the `hostile'
case where: i) the initial configuration may contain multiplicities, i.e. more
than one robot may occupy the same vertex; ii) robots cannot detect
multiplicities. As a scheduler for robot activation, we consider the
"favorable" round-robin case, where robots are activated one at a time.
  Our objective is to achieve a complete characterization of the problem in the
broad context of non-vertex-transitive graphs, i.e., graphs where the vertices
are partitioned into at least two different classes of equivalence. We provide
a resolution algorithm for any configuration of robots moving on such graphs,
along with its correctness. Furthermore, we analyze its time complexity.

</details>


### [495] [20 Years in Life of a Smart Building: A retrospective](https://arxiv.org/abs/2509.06229)
*Karolina Skrivankova,Mark Handley,Stephen Hailes*

Main category: cs.DC

TL;DR: KaOS是一个用于构建健壮、可演进的智能楼宇自动化系统的分布式控制平台，利用容器化和托管资源访问，在不牺牲成本效益的情况下实现灵活性、安全性和容错性。


<details>
  <summary>Details</summary>
Motivation: 目前的智能楼宇自动化系统在硬件故障、供应商过时和安全威胁方面面临挑战，这些挑战尚未得到充分解决，限制了大型、真正的智能自动化部署的可行性。

Method: KaOS利用容器化和托管资源访问来支持控制应用程序和分布式系统操作，从而构建健壮且可演进的智能楼宇自动化系统。

Result: 初步评估证实了该方法的实际可行性，并强调了其在延长的时间内可持续维护和逐步演进楼宇控制功能的潜力。

Conclusion: KaOS通过使用经济高效的现成物联网硬件，为构建健壮、可演进且具有成本效益的智能楼宇自动化系统提供了一种可行的方法。

Abstract: Operating an intelligent smart building automation system in 2025 is met with
many challenges: hardware failures, vendor obsolescence, evolving security
threats and more. None of these have been comprehensibly addressed by the
industrial building nor home automation industries, limiting feasibility of
operating large, truly smart automation deployments. This paper introduces
KaOS, a distributed control platform for constructing robust and evolvable
smart building automation systems using affordable, off-the-shelf IoT hardware.
Supporting control applications and distributed system operations by leveraging
containerisation and managed resource access, KaOS seeks to achieve
flexibility, security, and fault tolerance without sacrificing
cost-effectiveness. Initial evaluation confirms the practical feasibility of
our approach, highlighting its potential to sustainably maintain and
incrementally evolve building control functionalities over extended timeframes.

</details>


### [496] [FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving](https://arxiv.org/abs/2509.06261)
*Kyungmin Bin,Seungbeom Choi,Jimyoung Son,Jieun Choi,Daseul Bae,Daehyeon Baek,Kihyo Moon,Minsung Jang,Hyojung Lee*

Main category: cs.DC

TL;DR: FineServe是一个用于混合精度LLM推理的服务框架，通过KV Slab内存管理和两级调度来提高吞吐量和GPU利用率。


<details>
  <summary>Details</summary>
Motivation: PTQ技术增加了服务量化LLM的需求，但量化模型存在KV块大小减小导致的内存碎片和与非量化模型不同的资源使用模式，需要高效调度。

Method: FineServe提出KV Slab内存管理技术，根据模型量化特性动态分配KV缓存，减少内存碎片。同时，设计了一个两级调度框架：全局调度器根据请求率、延迟和服务水平目标（SLO）以及内存约束和效率来放置模型到GPU；局部调度器根据实时请求波动自适应调整批处理大小。

Result: 实验结果表明，与最先进的GPU共享系统相比，FineServe实现了高达2.2倍的SLO达成率和1.8倍的令牌生成吞吐量。

Conclusion: FineServe通过其创新的内存管理和调度技术，有效解决了混合精度LLM推理中的内存碎片和调度效率问题，显著提高了服务性能。

Abstract: Recent advances in Post-Training Quantization (PTQ) techniques have
significantly increased demand for serving quantized large language models
(LLMs), enabling higher throughput and substantially reduced memory usage with
minimal accuracy loss. Quantized models address memory constraints in LLMs and
enhance GPU resource utilization through efficient GPU sharing. However,
quantized models have smaller KV block sizes than non-quantized models, causing
limited memory efficiency due to memory fragmentation. Also, distinct resource
usage patterns between quantized and non-quantized models require efficient
scheduling to maximize throughput. To address these challenges, we propose
FineServe, an inference serving framework for mixed-precision LLMs. FineServe's
key contributions include: (1) KV Slab, a precision-aware adaptive memory
management technique dynamically allocating KV cache based on model
quantization characteristics, significantly reducing GPU memory fragmentation,
and (2) a two-level scheduling framework comprising a global scheduler that
places models to GPUs based on request rates, latency SLOs, and memory
constraints and efficiency, and a local scheduler that adaptively adjusts batch
sizes according to real-time request fluctuations. Experimental results
demonstrate that FineServe achieves up to 2.2x higher SLO attainment and 1.8x
higher token generation throughput compared to the state-of-the-art GPU sharing
systems.

</details>


### [497] [MaaSO: SLO-aware Orchestration of Heterogeneous Model Instances for MaaS](https://arxiv.org/abs/2509.06362)
*Mo Xuan,Zhang yue,Wu Weigang*

Main category: cs.DC

TL;DR: MaaSO是一个模型即服务（MaaS）的编排器，通过优化异构模型实例的配置和实现智能请求分发，显著提高了服务水平目标（SLO）的满足率并降低了响应延迟。


<details>
  <summary>Details</summary>
Motivation: 当前模型即服务（MaaS）平台在处理多样化的大型语言模型（LLM）应用时，面临着复杂上下文、首词延迟和词间延迟等不同的服务水平目标（SLO）需求。然而，现有的LLM推理系统通常部署相同配置的模型实例，未能有效利用不同配置（如并行策略和批处理大小）下LLM实例性能的异构性。

Method: MaaSO包含三个模块：1. 性能剖析器：表征不同并行策略和批处理大小下的模型实例性能。2. 放置器：优化异构模型实例的配置。3. 分发器：实现感知SLO的请求分发，并防止在连续批处理中出现级联超时。

Result: 实验结果表明，与现有方法相比，MaaSO将SLO满足率提高了15%至30%，响应延迟降低了40%至60%，并显著降低了整体编排开销。

Conclusion: MaaSO是首个MaaS编排器，通过整合性能剖析、异构实例优化和智能请求分发，有效解决了当前MaaS平台在满足多样化LLM应用SLO需求方面的挑战，并在实际应用中展现出优越的性能。

Abstract: Model-as-a-Service (MaaS) platforms face diverse Service Level Objective
(SLO) requirements stemming from various large language model (LLM)
applications, manifested in contextual complexity, first-token latency, and
between-token latency. On the other hand, an LLM instance, when configured with
different parallelism strategies and inference batch sizes, exhibits distinct
performance characteristics and can thus be used to serve different SLO
requirements. However, current LLM inference systems typically deploy instances
of the same model with identical configurations, lacking mechanisms to leverage
such heterogeneity. To fill this research gap, we propose MaaSO, the first MaaS
Orchestrator, which comprises three modules: (1) a profiler characterizing
instance performance under diverse parallelism strategies and inference batch
sizes; (2) a placer optimizing heterogeneous instance configurations; (3) a
distributor enabling SLO-aware request distribution and preventing cascaded
timeouts in continuous batching. Experiments show that MaaSO improves the SLO
satisfaction ratio by 15 to 30% and reduces response latency by 40 to 60%
compared to existing approaches, and significantly lowers overall orchestration
overhead.

</details>


### [498] [IM-PIR: In-Memory Private Information Retrieval](https://arxiv.org/abs/2509.06514)
*Mpoki Mwaisela,Peterson Yuhala,Pascal Felber,Valerio Schiavoni*

Main category: cs.DC

TL;DR: 该论文提出了首个基于内存处理（PIM）的多服务器私有信息检索（PIR）架构，解决了传统PIR计算密集和内存带宽瓶颈的问题，并通过实验证明其查询吞吐量相比传统CPU提高了3.7倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有的私有信息检索（PIR）方案虽然提供了强大的安全保障，但计算成本高昂，并且由于需要扫描大型数据库，其性能受到内存带宽的限制，这与传统的以处理器为中心的计算架构不符。内存处理（PIM）通过在内存中加入计算能力，解决了内存带宽瓶颈并提供了大规模并行处理能力，在许多数据密集型任务中展现了巨大潜力。

Method: 论文提出了一种基于PIM的多服务器PIR架构，讨论了其算法基础，并展示了如何将PIR操作与PIM架构的核心优势（大规模并行和高内存带宽）相结合。在此基础上，设计并实现了一个名为IM-PIR的、基于UPMEM PIM架构（首个商业化的PIM架构）的多服务器PIR方案。

Result: 通过在一个PIM服务器上实现的IM-PIR方案，与标准的基于CPU的PIR方案相比，查询吞吐量显著提高了3.7倍以上。

Conclusion: 基于PIM的多服务器PIR架构能够显著提高查询吞吐量，解决了传统PIR方案的性能瓶颈。

Abstract: Private information retrieval (PIR) is a cryptographic primitive that allows
a client to securely query one or multiple servers without revealing their
specific interests. In spite of their strong security guarantees, current PIR
constructions are computationally costly. Specifically, most PIR
implementations are memory-bound due to the need to scan extensive databases
(in the order of GB), making them inherently constrained by the limited memory
bandwidth in traditional processor-centric computing
architectures.Processing-in-memory (PIM) is an emerging computing paradigm that
augments memory with compute capabilities, addressing the memory bandwidth
bottleneck while simultaneously providing extensive parallelism.Recent research
has demonstrated PIM's potential to significantly improve performance across a
range of data-intensive workloads, including graph processing, genome analysis,
and machine learning.
  In this work, we propose the first PIM-based architecture for multi-server
PIR. We discuss the algorithmic foundations of the latter and show how its
operations align with the core strengths of PIM architectures: extensive
parallelism and high memory bandwidth. Based on this observation, we design and
implement IM-PIR, a PIM-based multi-server PIR approach on top of UPMEM PIM,
the first openly commercialized PIM architecture. Our evaluation demonstrates
that a PIM-based multi-server PIR implementation significantly improves query
throughput by more than 3.7x when compared to a standard CPU-based PIR
approach.

</details>


### [499] [Mangrove: Fast and Parallelizable State Replication for Blockchains](https://arxiv.org/abs/2509.06616)
*Anton Paramonov,Yann Vonlanthen,Quentin Kniep,Jakub Sliwinski,Roger Wattenhofer*

Main category: cs.DC

TL;DR: Mangrove是一种用于构建支持并行智能合约的新型区块链扩展方法，它不依赖全局排序，而是为每个智能合约使用独立的共识实例，并通过并行乐观协议来处理冲突，同时利用拜占庭可靠广播原语来降低简单交易的延迟。


<details>
  <summary>Details</summary>
Motivation: Mangrove旨在解决传统区块链的扩展性问题，通过支持并行智能合约执行来提高性能，并减少交易延迟。

Method: Mangrove采用独立的共识实例处理每个智能合约，不依赖全局排序。使用并行乐观协议（Parallel Optimistic Agreement）来避免冲突，并结合拜占庭可靠广播（Byzantine Reliable Broadcast）来优化简单交易的延迟。

Result: 在无节点恶意行为且网络同步的乐观条件下，Mangrove协议可以实现2通信步的交易创建到执行延迟。

Conclusion: Mangrove通过并行化智能合约执行和优化的共识机制，显著提高了区块链的性能和可扩展性，尤其在乐观场景下表现优异。

Abstract: Mangrove is a novel scaling approach to building blockchains with parallel
smart contract support. Unlike in monolithic blockchains, where a single
consensus mechanism determines a strict total order over all transactions,
Mangrove uses separate consensus instances per smart contract, without a global
order. To allow multiple instances to run in parallel while ensuring that no
conflicting transactions are committed, we propose a mechanism called Parallel
Optimistic Agreement. Additionally, for simple transactions, we leverage a
lightweight Byzantine Reliable Broadcast primitive to reduce latency. Mangrove
is optimized for performance under optimistic conditions, where there is no
misbehavior and the network is synchronous. Under these conditions, our
protocol can achieve a latency of 2 communication steps between creating and
executing a transaction.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [500] [Attention of a Kiss: Exploring Attention Maps in Video Diffusion for XAIxArts](https://arxiv.org/abs/2509.05323)
*Adam Cole,Mick Grierson*

Main category: cs.AI

TL;DR: 本研究提出一种用于生成视频模型中交叉注意图的可视化方法，探索其在艺术和技术上的应用。


<details>
  <summary>Details</summary>
Motivation: 受早期视频艺术家的启发，本研究旨在揭示生成视频模型（特别是文本到视频模型）的内部工作机制，并将注意力图作为分析工具和艺术创作的媒介。

Method: 提出一种从生成视频模型中提取和可视化交叉注意图的方法，并基于开源的Wan模型进行实现。

Result: 开发了一个工具，可以提供对文本到视频生成中注意力在时间和空间行为的可解释的洞察，并通过探索性探测和艺术案例研究进行了验证。

Conclusion: 本研究为AI for the Arts（XAIxArts）领域做出了贡献，鼓励艺术家将AI的内部机制作为一种新的创作媒介。

Abstract: This paper presents an artistic and technical investigation into the
attention mechanisms of video diffusion transformers. Inspired by early video
artists who manipulated analog video signals to create new visual aesthetics,
this study proposes a method for extracting and visualizing cross-attention
maps in generative video models. Built on the open-source Wan model, our tool
provides an interpretable window into the temporal and spatial behavior of
attention in text-to-video generation. Through exploratory probes and an
artistic case study, we examine the potential of attention maps as both
analytical tools and raw artistic material. This work contributes to the
growing field of Explainable AI for the Arts (XAIxArts), inviting artists to
reclaim the inner workings of AI as a creative medium.

</details>


### [501] [Perception Graph for Cognitive Attack Reasoning in Augmented Reality](https://arxiv.org/abs/2509.05324)
*Rongqian Chen,Shu Hong,Rifatul Islam,Mahdi Imani,G. Gary Tan,Tian Lan*

Main category: cs.AI

TL;DR: AR系统在战术环境中易受认知攻击，提出感知图模型来量化感知扭曲以检测攻击。


<details>
  <summary>Details</summary>
Motivation: 增强现实（AR）系统在战术环境中的部署日益增多，但它们对无缝人机交互的依赖性使得它们容易受到操纵用户感知的认知攻击，从而严重影响用户决策。

Method: 提出感知图（Perception Graph）模型，通过模仿人类解释多功能显示器（MR）环境中的关键信息的过程，并使用有意义的结构表示结果，来量化感知扭曲的程度。

Result: 该模型能够计算量化分数，以反映感知扭曲的水平，为检测和分析此类认知攻击的效果提供了强大且可衡量的方法。

Conclusion: 感知图模型可以量化感知扭曲，从而为检测和分析认知攻击提供一种新颖且可衡量的方法。

Abstract: Augmented reality (AR) systems are increasingly deployed in tactical
environments, but their reliance on seamless human-computer interaction makes
them vulnerable to cognitive attacks that manipulate a user's perception and
severely compromise user decision-making. To address this challenge, we
introduce the Perception Graph, a novel model designed to reason about human
perception within these systems. Our model operates by first mimicking the
human process of interpreting key information from an MR environment and then
representing the outcomes using a semantically meaningful structure. We
demonstrate how the model can compute a quantitative score that reflects the
level of perception distortion, providing a robust and measurable method for
detecting and analyzing the effects of such cognitive attacks.

</details>


### [502] [SynDelay: A Synthetic Dataset for Delivery Delay Prediction](https://arxiv.org/abs/2509.05325)
*Liming Xu,Yunbo Long,Alexandra Brintrup*

Main category: cs.AI

TL;DR: AI在供应链管理中发挥着重要作用，但预测任务（例如交付延迟预测）仍然受到高质量、公开可用数据集稀缺的限制。我们提出了SynDelay，一个用于交付延迟预测的合成数据集。该数据集解决了现有数据集的局限性，提供了数据共享和基准测试的平台。


<details>
  <summary>Details</summary>
Motivation: 解决现有供应链管理中用于预测任务（尤其是交付延迟预测）的数据集稀缺、专有、不一致且难以复现的问题。

Method: 使用在真实世界数据上训练的先进生成模型生成合成数据集SynDelay，以保留真实的交付模式并确保隐私。

Result: SynDelay数据集被创建为一个具有挑战性且实用的预测建模测试平台，并提供了基线结果和评估指标作为初始基准。

Conclusion: SynDelay数据集的发布旨在促进供应链AI领域的研究，并鼓励社区通过共享数据集、模型和评估实践来做出贡献。

Abstract: Artificial intelligence (AI) is transforming supply chain management, yet
progress in predictive tasks -- such as delivery delay prediction -- remains
constrained by the scarcity of high-quality, openly available datasets.
Existing datasets are often proprietary, small, or inconsistently maintained,
hindering reproducibility and benchmarking. We present SynDelay, a synthetic
dataset designed for delivery delay prediction. Generated using an advanced
generative model trained on real-world data, SynDelay preserves realistic
delivery patterns while ensuring privacy. Although not entirely free of noise
or inconsistencies, it provides a challenging and practical testbed for
advancing predictive modelling. To support adoption, we provide baseline
results and evaluation metrics as initial benchmarks, serving as reference
points rather than state-of-the-art claims. SynDelay is publicly available
through the Supply Chain Data Hub, an open initiative promoting dataset sharing
and benchmarking in supply chain AI. We encourage the community to contribute
datasets, models, and evaluation practices to advance research in this area.
All code is openly accessible at https://supplychaindatahub.org.

</details>


### [503] [MVRS: The Multimodal Virtual Reality Stimuli-based Emotion Recognition Dataset](https://arxiv.org/abs/2509.05330)
*Seyed Muhammad Hossein Mousavi,Atiye Ilanloo*

Main category: cs.AI

TL;DR: 该研究介绍了MVRS数据集，一个包含身体运动和生理信号的多模态情感识别数据集，以解决现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前AI领域，特别是在医疗、教育和汽车系统等领域，对多模态情感识别数据集（尤其是包含身体运动和生理信号的数据集）的缺乏问题。

Method: 通过使用眼动追踪（VR头戴设备中的网络摄像头）、身体运动（Kinect v2）以及肌电图（EMG）和皮肤电反应（GSR）信号（Arduino UNO）来收集13名12至60岁参与者在接触VR情感刺激（放松、恐惧、压力、悲伤、快乐）时同步记录的数据。所有数据都经过时间戳对齐，并提取各模态特征，然后采用早期和晚期融合技术进行融合，最后通过分类器进行评估。

Result: MVRS数据集被证明是高质量的，并且所包含的情感具有可分离性，验证了数据集的有效性。

Conclusion: MVRS数据集为多模态情感计算领域提供了宝贵的资源，有助于推动情感识别技术的发展。

Abstract: Automatic emotion recognition has become increasingly important with the rise
of AI, especially in fields like healthcare, education, and automotive systems.
However, there is a lack of multimodal datasets, particularly involving body
motion and physiological signals, which limits progress in the field. To
address this, the MVRS dataset is introduced, featuring synchronized recordings
from 13 participants aged 12 to 60 exposed to VR based emotional stimuli
(relaxation, fear, stress, sadness, joy). Data were collected using eye
tracking (via webcam in a VR headset), body motion (Kinect v2), and EMG and GSR
signals (Arduino UNO), all timestamp aligned. Participants followed a unified
protocol with consent and questionnaires. Features from each modality were
extracted, fused using early and late fusion techniques, and evaluated with
classifiers to confirm the datasets quality and emotion separability, making
MVRS a valuable contribution to multimodal affective computing.

</details>


### [504] [Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning](https://arxiv.org/abs/2509.05346)
*Bo Yuan,Jiazi Hu*

Main category: cs.AI

TL;DR: LLM在个性化学习中的应用需要更多实际场景的评估。本研究比较了GPT-4o、DeepSeek-V3和GLM-4.5在模拟真实教学场景下的表现，使用Gemini作为裁判进行多维度评估。结果显示GPT-4o在信息丰富度和结构化反馈方面表现最佳，尽管其他模型也有亮点，但整体一致性稍逊。


<details>
  <summary>Details</summary>
Motivation: 在真实的教学场景中，对大型语言模型（LLMs）作为个性化学习助手进行系统性的头对头评估仍然有限。

Method: 本研究对三种先进的LLMs在模拟真实学习环境的辅导任务中进行了实证比较。利用包含学生对十个混合格式问题答案及正确性标签的数据集，要求每个LLM执行（一）分析测验以识别潜在知识组件，（二）推断学生的掌握情况，以及（三）生成有针对性的改进指导。为了减少主观性和评估者偏见，研究采用了Gemini作为虚拟裁判，从准确性、清晰度、可操作性和适当性等多个维度进行成对比较。

Result: 通过Bradley-Terry模型分析的结果表明，GPT-4o总体上更受青睐，其生成的反馈比其他模型更具信息量且结构更优。DeepSeek-V3和GLM-4.5虽然展现出间歇性的优势，但整体一致性较低。

Conclusion: 研究结果证实了部署LLMs作为高级助教以提供个性化支持的可行性，并为未来关于LLM驱动的个性化学习的实证研究提供了方法学指导。

Abstract: While Large Language Models (LLMs) are increasingly envisioned as intelligent
assistants for personalized learning, systematic head-to-head evaluations
within authentic learning scenarios remain limited. This study conducts an
empirical comparison of three state-of-the-art LLMs on a tutoring task that
simulates a realistic learning setting. Using a dataset comprising a student's
answers to ten questions of mixed formats with correctness labels, each LLM is
required to (i) analyze the quiz to identify underlying knowledge components,
(ii) infer the student's mastery profile, and (iii) generate targeted guidance
for improvement. To mitigate subjectivity and evaluator bias, we employ Gemini
as a virtual judge to perform pairwise comparisons along various dimensions:
accuracy, clarity, actionability, and appropriateness. Results analyzed via the
Bradley-Terry model indicate that GPT-4o is generally preferred, producing
feedback that is more informative and better structured than its counterparts,
while DeepSeek-V3 and GLM-4.5 demonstrate intermittent strengths but lower
consistency. These findings highlight the feasibility of deploying LLMs as
advanced teaching assistants for individualized support and provide
methodological guidance for future empirical research on LLM-driven
personalized learning.

</details>


### [505] [SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis](https://arxiv.org/abs/2509.05363)
*Lijie Ding,Changwoo Do*

Main category: cs.AI

TL;DR: SasAgent是一个利用大型语言模型（LLMs）驱动的多智能体AI系统，可以自动化小角散射（SAS）数据分析，并通过文本输入实现用户交互。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是自动化小角散射（SAS）数据分析，并提高SAS研究的效率和可及性。

Method: 研究方法是开发一个名为SasAgent的多智能体AI系统，该系统利用大型语言模型（LLMs）和SasView软件中的工具来执行SAS数据分析任务。该系统包括一个协调智能体和三个专门的智能体，分别负责计算散射长度密度（SLD）、生成合成数据和拟合实验数据。

Result: 通过多样化的示例，证明了SasAgent能够解释复杂的提示、计算SLD、生成准确的散射数据以及高精度地拟合实验数据集。

Conclusion: 这项工作展示了由LLM驱动的AI系统在简化科学工作流程和增强SAS研究自动化方面的潜力。

Abstract: We introduce SasAgent, a multi-agent AI system powered by large language
models (LLMs) that automates small-angle scattering (SAS) data analysis by
leveraging tools from the SasView software and enables user interaction via
text input. SasAgent features a coordinator agent that interprets user prompts
and delegates tasks to three specialized agents for scattering length density
(SLD) calculation, synthetic data generation, and experimental data fitting.
These agents utilize LLM-friendly tools to execute tasks efficiently. These
tools, including the model data tool, Retrieval-Augmented Generation (RAG)
documentation tool, bump fitting tool, and SLD calculator tool, are derived
from the SasView Python library. A user-friendly Gradio-based interface
enhances user accessibility. Through diverse examples, we demonstrate
SasAgent's ability to interpret complex prompts, calculate SLDs, generate
accurate scattering data, and fit experimental datasets with high precision.
This work showcases the potential of LLM-driven AI systems to streamline
scientific workflows and enhance automation in SAS research.

</details>


### [506] [Characterizing Fitness Landscape Structures in Prompt Engineering](https://arxiv.org/abs/2509.05375)
*Arend Hintze*

Main category: cs.AI

TL;DR: 提示工程的优化过程可以被看作是在一个复杂的地形上寻找最佳路径。不同的提示生成策略会塑造出截然不同的地形特征，有的平坦，有的则崎岖不平，甚至有分层结构。


<details>
  <summary>Details</summary>
Motivation: 目前对于提示工程的优化过程及其潜在的优化地形知之甚少。现有的方法将提示优化视为一个黑箱问题，尽管采用了复杂的搜索算法，但并未对其进行地形特征的刻画。

Method: 通过在语义嵌入空间中使用自相关分析，对提示工程中的适应度景观结构进行系统性分析。

Result: 实验表明，系统枚举生成的提示展现出平滑衰减的自相关性，而新颖性驱动的生成策略则表现出非单调模式，在中等语义距离处达到峰值相关性，表明存在崎岖且具有分层结构的地形。不同错误类型的地形崎岖度也各不相同。

Conclusion: 为理解提示工程优化复杂性提供了实证基础。

Abstract: While prompt engineering has emerged as a crucial technique for optimizing
large language model performance, the underlying optimization landscape remains
poorly understood. Current approaches treat prompt optimization as a black-box
problem, applying sophisticated search algorithms without characterizing the
landscape topology they navigate. We present a systematic analysis of fitness
landscape structures in prompt engineering using autocorrelation analysis
across semantic embedding spaces. Through experiments on error detection tasks
with two distinct prompt generation strategies -- systematic enumeration (1,024
prompts) and novelty-driven diversification (1,000 prompts) -- we reveal
fundamentally different landscape topologies. Systematic prompt generation
yields smoothly decaying autocorrelation, while diversified generation exhibits
non-monotonic patterns with peak correlation at intermediate semantic
distances, indicating rugged, hierarchically structured landscapes.
Task-specific analysis across 10 error detection categories reveals varying
degrees of ruggedness across different error types. Our findings provide an
empirical foundation for understanding the complexity of optimization in prompt
engineering landscapes.

</details>


### [507] [Code Like Humans: A Multi-Agent Solution for Medical Coding](https://arxiv.org/abs/2509.05378)
*Andreas Motzfeldt,Joakim Edin,Casper L. Christensen,Christian Hardmeier,Lars Maaløe,Anna Rogers*

Main category: cs.AI

TL;DR: Code Like Humans是一个用于医学编码的大型语言模型框架，实现了ICD-10编码系统，并在罕见病码上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 医学编码需要将非结构化临床笔记映射到字母数字代码，这是一项复杂且耗时的工作。

Method: Code Like Humans框架使用大型语言模型，并实现了官方编码指南，以支持完整的ICD-10编码系统。

Result: 该框架在罕见病码上取得了当前最佳性能，但对于高频病码，微调的判别式分类器仍然具有优势。此外，还分析了系统的性能并识别出其‘盲点’（系统性编码不足的病码）。

Conclusion: Code Like Humans框架在医学编码领域取得了显著进展，尤其是在处理罕见病码方面，并为未来的研究指明了方向。

Abstract: In medical coding, experts map unstructured clinical notes to alphanumeric
codes for diagnoses and procedures. We introduce Code Like Humans: a new
agentic framework for medical coding with large language models. It implements
official coding guidelines for human experts, and it is the first solution that
can support the full ICD-10 coding system (+70K labels). It achieves the best
performance to date on rare diagnosis codes (fine-tuned discriminative
classifiers retain an advantage for high-frequency codes, to which they are
limited). Towards future work, we also contribute an analysis of system
performance and identify its `blind spots' (codes that are systematically
undercoded).

</details>


### [508] [Murphys Laws of AI Alignment: Why the Gap Always Wins](https://arxiv.org/abs/2509.05381)
*Madhava Gaikwad*

Main category: cs.AI

TL;DR: RLHF等基于反馈的AI对齐方法存在回报攻击、谄媚、标注漂移和泛化错误等常见失败模式。本文提出了“对齐鸿沟”概念，用以统一解释这些失败，并引入了“AI对齐的墨菲定律”和“对齐三难困境”来框架化权衡。最后，提出了MAPS框架（错规、标注、压力、漂移）作为实际的设计杠杆，旨在为未来的AI对齐研究提供更清晰的指导。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）通常通过人类反馈强化学习（RLHF）及其变体（如DPO、Constitutional AI、RLAIF）进行对齐。然而，这些方法存在回报攻击、谄媚、标注漂移和泛化错误等反复出现的失败模式。因此，理解并解决这些失败模式是AI对齐领域的重要动机。

Method: 本文提出了“对齐鸿沟”的概念，并使用KL散度倾斜形式主义来解释为什么优化压力会放大代理奖励与真实人类意图之间的差异。作者将这些失败归纳为“AI对齐的墨菲定律”，并提出了“对齐三难困境”来描述优化强度、价值捕获和泛化能力之间的权衡。最后，提出了MAPS（错规、标注、压力、漂移）框架。

Result: 通过KL散度倾斜形式主义的理论分析，揭示了优化压力如何导致代理奖励与真实人类意图的偏差。将失败模式归纳为“AI对齐的墨菲定律”，并提出了“对齐三难困境”来阐述优化强度、价值捕获和泛化能力之间的权衡关系。小型实证研究提供了支持性的证据。MAPS框架被提出作为一种实践设计方法。

Conclusion: 本文提出“对齐鸿沟”作为理解和解决基于反馈的AI对齐方法中常见失败模式的统一视角。通过理论分析和归纳失败模式，提出了“AI对齐的墨菲定律”和“对齐三难困境”来指导对齐研究中的权衡。MAPS框架为实际设计提供了指导，旨在促进对AI对齐的更清晰的讨论和更有效的未来设计。

Abstract: Large language models are increasingly aligned to human preferences through
reinforcement learning from human feedback (RLHF) and related methods such as
Direct Preference Optimization (DPO), Constitutional AI, and RLAIF. While
effective, these methods exhibit recurring failure patterns i.e., reward
hacking, sycophancy, annotator drift, and misgeneralization. We introduce the
concept of the Alignment Gap, a unifying lens for understanding recurring
failures in feedback-based alignment. Using a KL-tilting formalism, we
illustrate why optimization pressure tends to amplify divergence between proxy
rewards and true human intent. We organize these failures into a catalogue of
Murphys Laws of AI Alignment, and propose the Alignment Trilemma as a way to
frame trade-offs among optimization strength, value capture, and
generalization. Small-scale empirical studies serve as illustrative support.
Finally, we propose the MAPS framework (Misspecification, Annotation, Pressure,
Shift) as practical design levers. Our contribution is not a definitive
impossibility theorem but a perspective that reframes alignment debates around
structural limits and trade-offs, offering clearer guidance for future design.

</details>


### [509] [From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation](https://arxiv.org/abs/2509.05469)
*Chenguang Wang,Xiang Yan,Yilong Dai,Ziyi Wang,Susu Xu*

Main category: cs.AI

TL;DR: 该研究提出了一个多智能体系统，可以直接在真实的街景图像上编辑和重新设计自行车设施，以加速主动交通规划中的设计场景创建，克服了传统方法的局限性和现有AI方法的不足。


<details>
  <summary>Details</summary>
Motivation: 传统街景设计方法耗时费力，阻碍了公众参与和协作决策。现有的AI生成设计方法需要大量领域特定数据，并且难以在复杂的街景中精确控制空间变化。

Method: 引入一个多智能体系统，集成了车道定位、提示优化、设计生成和自动评估，直接在真实的街景图像上编辑和重新设计自行车设施。

Result: 该系统能够适应不同的道路几何形状和环境条件，生成逼真、符合指令的设计，并在多样化的城市场景中进行了验证。

Conclusion: 该研究为将多智能体管道应用于交通基础设施规划和设施设计奠定了基础。

Abstract: Realistic visual renderings of street-design scenarios are essential for
public engagement in active transportation planning. Traditional approaches are
labor-intensive, hindering collective deliberation and collaborative
decision-making. While AI-assisted generative design shows transformative
potential by enabling rapid creation of design scenarios, existing generative
approaches typically require large amounts of domain-specific training data and
struggle to enable precise spatial variations of design/configuration in
complex street-view scenes. We introduce a multi-agent system that edits and
redesigns bicycle facilities directly on real-world street-view imagery. The
framework integrates lane localization, prompt optimization, design generation,
and automated evaluation to synthesize realistic, contextually appropriate
designs. Experiments across diverse urban scenarios demonstrate that the system
can adapt to varying road geometries and environmental conditions, consistently
yielding visually coherent and instruction-compliant results. This work
establishes a foundation for applying multi-agent pipelines to transportation
infrastructure planning and facility design.

</details>


### [510] [TreeGPT: A Novel Hybrid Architecture for Abstract Syntax Tree Processing with Global Parent-Child Aggregation](https://arxiv.org/abs/2509.05550)
*Zixi Li*

Main category: cs.AI

TL;DR: TreeGPT是一种新颖的神经网络架构，结合了Transformer注意力和全局父子聚合，用于处理抽象语法树（ASTs），在神经程序合成任务中取得优异成果。


<details>
  <summary>Details</summary>
Motivation: 传统的AST处理方法在神经程序合成任务中存在局限性，需要一种能有效处理层级结构并捕捉局部和全局依赖关系的新架构。

Method: TreeGPT采用混合设计，结合了Transformer的自注意力机制和专门的Tree Feed-Forward Network（TreeFFN），通过全局父子聚合机制（Global Parent-Child Aggregation）迭代地聚合来自整个树结构的信息。

Result: TreeGPT在ARC Prize 2025数据集上实现了96%的准确率，显著优于Transformer基线（1.3%）、Grok-4（15.9%）和SOAR（52%），同时参数量仅为1.5M。

Conclusion: TreeGPT在神经程序合成任务中表现出色，其全局父子聚合机制是关键创新，通过有效的层级信息聚合实现了高性能。消融研究表明，边投影（edge projection）是其中最重要的组成部分。

Abstract: We introduce TreeGPT, a novel neural architecture that combines
transformer-based attention mechanisms with global parent-child aggregation for
processing Abstract Syntax Trees (ASTs) in neural program synthesis tasks.
Unlike traditional approaches that rely solely on sequential processing or
graph neural networks, TreeGPT employs a hybrid design that leverages both
self-attention for capturing local dependencies and a specialized Tree
Feed-Forward Network (TreeFFN) for modeling hierarchical tree structures
through iterative message passing.
  The core innovation lies in our Global Parent-Child Aggregation mechanism,
formalized as: $$h_i^{(t+1)} = \sigma \Big( h_i^{(0)} + W_{pc} \sum_{(p,c) \in
E_i} f(h_p^{(t)}, h_c^{(t)}) + b \Big)$$ where $h_i^{(t)}$ represents the
hidden state of node $i$ at iteration $t$, $E_i$ denotes all parent-child edges
involving node $i$, and $f(h_p, h_c)$ is an edge aggregation function. This
formulation enables each node to progressively aggregate information from the
entire tree structure through $T$ iterations.
  Our architecture integrates optional enhancements including gated aggregation
with learnable edge weights, residual connections for gradient stability, and
bidirectional propagation for capturing both bottom-up and top-down
dependencies. We evaluate TreeGPT on the ARC Prize 2025 dataset, a challenging
visual reasoning benchmark requiring abstract pattern recognition and rule
inference. Experimental results demonstrate that TreeGPT achieves 96\%
accuracy, significantly outperforming transformer baselines (1.3\%),
large-scale models like Grok-4 (15.9\%), and specialized program synthesis
methods like SOAR (52\%) while using only 1.5M parameters. Our comprehensive
ablation study reveals that edge projection is the most critical component,
with the combination of edge projection and gating achieving optimal
performance.

</details>


### [511] [OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision](https://arxiv.org/abs/2509.05578)
*Ruixun Liu,Lingyu Kong,Derun Li,Hang Zhao*

Main category: cs.AI

TL;DR: OccVLA通过将3D占用表示集成到多模态推理过程中，解决了MLLMs在3D空间理解方面的不足，实现了无需昂贵标注即可学习精细空间结构，并在nuScenes基准测试中取得了最先进的成果，为自动驾驶提供了可扩展、可解释的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在3D空间理解方面存在不足，而这对于自动驾驶至关重要。主要挑战在于难以构建有效的3D表示且需要昂贵的标注，以及在视觉语言模型（VLMs）中缺乏大规模3D视觉语言预训练导致精细空间细节的丢失。

Method: 提出了一种名为OccVLA的新框架，将3D占用表示集成到统一的多模态推理过程中。该框架将密集的3D占用作为预测输出和监督信号，使模型能够直接从2D视觉输入中学习精细的空间结构。占用预测被视为一种隐式推理过程，在推理时可以跳过，不会导致性能下降，因此没有额外的计算开销。

Result: OccVLA在nuScenes基准测试的轨迹规划任务上取得了最先进的成果，并在3D视觉问答任务上展示了优越的性能。

Conclusion: OccVLA为自动驾驶提供了一个可扩展、可解释且完全基于视觉的解决方案，解决了MLLMs在3D空间理解方面的挑战。

Abstract: Multimodal large language models (MLLMs) have shown strong vision-language
reasoning abilities but still lack robust 3D spatial understanding, which is
critical for autonomous driving. This limitation stems from two key challenges:
(1) the difficulty of constructing accessible yet effective 3D representations
without expensive manual annotations, and (2) the loss of fine-grained spatial
details in VLMs due to the absence of large-scale 3D vision-language
pretraining. To address these challenges, we propose OccVLA, a novel framework
that integrates 3D occupancy representations into a unified multimodal
reasoning process. Unlike prior approaches that rely on explicit 3D inputs,
OccVLA treats dense 3D occupancy as both a predictive output and a supervisory
signal, enabling the model to learn fine-grained spatial structures directly
from 2D visual inputs. The occupancy predictions are regarded as implicit
reasoning processes and can be skipped during inference without performance
degradation, thereby adding no extra computational overhead. OccVLA achieves
state-of-the-art results on the nuScenes benchmark for trajectory planning and
demonstrates superior performance on 3D visual question-answering tasks,
offering a scalable, interpretable, and fully vision-based solution for
autonomous driving.

</details>


### [512] [MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions](https://arxiv.org/abs/2509.05685)
*Jian Yang,Jiahui Wu,Li Fang,Hongchao Fan,Bianying Zhang,Huijie Zhao,Guangyi Yang,Rui Xin,Xiong You*

Main category: cs.AI

TL;DR: MSRFormer通过整合多尺度空间交互来改进城市道路网络表示学习，解决了现有方法的局限性，并在实际任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 城市道路网络的异质性和层级性给准确的表示学习带来了挑战，现有的图神经网络方法因其同质性假设和单一结构尺度关注而难以应对。

Method: MSRFormer利用空间流卷积提取小尺度特征，识别尺度依赖的空间交互区域来捕捉道路网络的空间结构和流的异质性。通过图变换器捕获多尺度的复杂空间依赖，并使用残差连接融合空间交互特征，最后通过对比学习获得道路网络表示。

Result: 在两个真实世界数据集上的验证表明，MSRFormer在道路网络分析任务上优于基线方法，特别是在涉及轨迹数据的交通相关任务和复杂道路网络结构中，改进幅度高达16%。

Conclusion: MSRFormer为开发任务无关的道路网络表示模型提供了一个实用的框架，并揭示了尺度效应与空间交互的流异质性之间相互作用的独特关联模式。

Abstract: Transforming road network data into vector representations using deep
learning has proven effective for road network analysis. However, urban road
networks' heterogeneous and hierarchical nature poses challenges for accurate
representation learning. Graph neural networks, which aggregate features from
neighboring nodes, often struggle due to their homogeneity assumption and focus
on a single structural scale. To address these issues, this paper presents
MSRFormer, a novel road network representation learning framework that
integrates multi-scale spatial interactions by addressing their flow
heterogeneity and long-distance dependencies. It uses spatial flow convolution
to extract small-scale features from large trajectory datasets, and identifies
scale-dependent spatial interaction regions to capture the spatial structure of
road networks and flow heterogeneity. By employing a graph transformer,
MSRFormer effectively captures complex spatial dependencies across multiple
scales. The spatial interaction features are fused using residual connections,
which are fed to a contrastive learning algorithm to derive the final road
network representation. Validation on two real-world datasets demonstrates that
MSRFormer outperforms baseline methods in two road network analysis tasks. The
performance gains of MSRFormer suggest the traffic-related task benefits more
from incorporating trajectory data, also resulting in greater improvements in
complex road network structures with up to 16% improvements compared to the
most competitive baseline method. This research provides a practical framework
for developing task-agnostic road network representation models and highlights
distinct association patterns of the interplay between scale effects and flow
heterogeneity of spatial interactions.

</details>


### [513] [PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments](https://arxiv.org/abs/2509.06235)
*Olivier Schipper,Yudi Zhang,Yali Du,Mykola Pechenizkiy,Meng Fang*

Main category: cs.AI

TL;DR: LLM智能体在竞争性多人游戏环境中表现有待探索。我们提出了PillagerBench框架和TactiCrafter系统，用于评估和改进LLM智能体在《我的世界》中的团队协作和策略学习能力。TactiCrafter通过可读的战术、因果依赖学习和适应性策略，超越了基线方法，并在自我对抗中展示了学习和进化的能力。


<details>
  <summary>Details</summary>
Motivation: 评估LLM智能体在竞争性多人游戏环境中的有效性，并提出一个能够进行团队协作、学习因果依赖和适应对手策略的LLM智能体系统。

Method: 提出PillagerBench框架，包含可扩展API、多轮测试和基于规则的内置对手，用于在《我的世界》中进行公平、可复现的实时团队对抗评估。提出TactiCrafter系统，利用人类可读的战术促进团队协作，学习因果依赖，并适应对手策略。

Result: TactiCrafter在PillagerBench评估中超越了基线方法，并通过自我对抗展示了适应性学习能力。研究分析了TactiCrafter在多个游戏回合中的学习过程和策略演变。

Conclusion: PillagerBench和TactiCrafter为在竞争性多人环境中的LLM智能体研究提供了新的评估框架和系统，并开源了PillagerBench以促进该领域的研究。

Abstract: LLM-based agents have shown promise in various cooperative and strategic
reasoning tasks, but their effectiveness in competitive multi-agent
environments remains underexplored. To address this gap, we introduce
PillagerBench, a novel framework for evaluating multi-agent systems in
real-time competitive team-vs-team scenarios in Minecraft. It provides an
extensible API, multi-round testing, and rule-based built-in opponents for
fair, reproducible comparisons. We also propose TactiCrafter, an LLM-based
multi-agent system that facilitates teamwork through human-readable tactics,
learns causal dependencies, and adapts to opponent strategies. Our evaluation
demonstrates that TactiCrafter outperforms baseline approaches and showcases
adaptive learning through self-play. Additionally, we analyze its learning
process and strategic evolution over multiple game episodes. To encourage
further research, we have open-sourced PillagerBench, fostering advancements in
multi-agent AI for competitive environments.

</details>


### [514] [Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs](https://arxiv.org/abs/2509.05714)
*Zhaoyu Fan,Kaihang Pan,Mingze Zhou,Bosheng Qin,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Fei Wu,Yueting Zhuang*

Main category: cs.AI

TL;DR: CogEdit是一个新基准，用于评估和改进MLLM的元认知知识编辑能力，MIND框架通过元知识记忆、博弈论交互和标签精炼来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑基准侧重于认知层面，缺乏对元认知过程的评估。本研究旨在弥补这一差距，通过引入CogEdit基准和MIND框架来评估和提升MLLM的元认知知识编辑能力。

Method: 提出CogEdit基准，包含反事实驱动编辑、边界约束编辑和噪声鲁棒编辑三个层面。提出MIND框架，构建元知识记忆、采用博弈论交互监控知识激活、结合标签精炼进行噪声鲁棒更新。

Result: MIND框架在传统和元认知知识编辑基准上均显著优于现有认知编辑方法。

Conclusion: MIND框架能够有效提升MLLM的元认知知识编辑能力，在处理不确定和需要自我反思的知识更新任务上表现出色。

Abstract: Knowledge editing enables multimodal large language models (MLLMs) to
efficiently update outdated or incorrect information. However, existing
benchmarks primarily emphasize cognitive-level modifications while lacking a
focus on deeper meta-cognitive processes. To bridge this gap, we introduce
CogEdit, a novel benchmark designed to evaluate MLLMs' meta-cognitive knowledge
editing abilities across three levels: (1) Counterfactual-Driven Editing,
assessing self-awareness of knowledge correctness changes; (2) Boundary
Constraint Editing, ensuring appropriate generalization without unintended
interference; and (3) Noise-Robust Editing, promoting reflective evaluation of
uncertain information. To advance meta-cognitive editing, we propose MIND
(Meta-cognitive INtegrated Dynamic Knowledge Editing), a framework that
constructs a meta-knowledge memory for self-awareness, employs game-theoretic
interactions to monitor knowledge activation, and incorporates label refinement
for noise-robust updates. Extensive experiments show that MIND significantly
outperforms existing cognitive editing approaches, achieving strong performance
on both traditional and meta-cognitive knowledge editing benchmarks.

</details>


### [515] [Hyperbolic Large Language Models](https://arxiv.org/abs/2509.05757)
*Sarang Patil,Zeyong Zhang,Yiran Huang,Tengfei Ma,Mengjia Xu*

Main category: cs.AI

TL;DR: LLMs在处理非欧几里得数据的能力方面仍有待提高，而双曲几何可以作为一种有效的表示空间来增强LLMs。本文对利用双曲几何的双曲LLMs（HypLLMs）的最新进展进行了分类和总结，并探讨了其应用和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界的数据具有非欧几里得的潜在分层结构，而利用LLMs有效学习这些数据中的内在语义蕴含和分层关系仍然是一个未被充分探索的领域。

Method: 本文对利用双曲几何作为表示空间来增强语义表示学习和多尺度推理的LLMs的最新进展进行了全面的、有上下文的阐述。具体来说，本文根据四种主要类别对HypLLMs的主要技术进行了分类：（1）通过指数/对数映射实现的双曲LLMs；（2）双曲微调模型；（3）全双曲LLMs；（4）双曲状态空间模型。

Result: 本文对HypLLMs的主要技术进行了分类，并探讨了其潜在应用和未来研究方向。相关资源库可在https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main找到。

Conclusion: 双曲几何为LLMs提供了一个有前景的表示空间，可以有效处理非欧几里得数据，并在语义表示学习和多尺度推理方面取得进展。

Abstract: Large language models (LLMs) have achieved remarkable success and
demonstrated superior performance across various tasks, including natural
language processing (NLP), weather forecasting, biological protein folding,
text generation, and solving mathematical problems. However, many real-world
data exhibit highly non-Euclidean latent hierarchical anatomy, such as protein
networks, transportation networks, financial networks, brain networks, and
linguistic structures or syntactic trees in natural languages. Effectively
learning intrinsic semantic entailment and hierarchical relationships from
these raw, unstructured input data using LLMs remains an underexplored area.
Due to its effectiveness in modeling tree-like hierarchical structures,
hyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity
as an expressive latent representation space for complex data modeling across
domains such as graphs, images, languages, and multi-modal data. Here, we
provide a comprehensive and contextual exposition of recent advancements in
LLMs that leverage hyperbolic geometry as a representation space to enhance
semantic representation learning and multi-scale reasoning. Specifically, the
paper presents a taxonomy of the principal techniques of Hyperbolic LLMs
(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log
maps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)
hyperbolic state-space models. We also explore crucial potential applications
and outline future research directions. A repository of key papers, models,
datasets, and code implementations is available at
https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.

</details>


### [516] [DRF: LLM-AGENT Dynamic Reputation Filtering Framework](https://arxiv.org/abs/2509.05764)
*Yuwei Lou,Hao Hu,Shaocong Ma,Zongfei Zhang,Liang Wang,Jidong Ge,Xianping Tao*

Main category: cs.AI

TL;DR: DRF是一个动态声誉过滤框架，用于解决多主体系统中LLM代理的性能量化和可信度评估问题。它通过构建交互式评分网络、设计声誉评分机制和集成基于上限置信界（UCB）的策略来提升代理选择效率，实验证明DRF能显著提高逻辑推理和代码生成等任务的完成质量和协作效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多主体系统在量化LLM代理的性能和评估其可信度方面存在挑战。

Method: DRF框架通过构建交互式评分网络量化代理性能，设计声誉评分机制衡量代理的诚实度和能力，并集成基于上限置信界（UCB）的策略以提高代理选择效率。

Result: 实验结果表明，DRF在逻辑推理和代码生成任务中显著提高了任务完成质量和协作效率。

Conclusion: DRF为多主体系统处理大规模任务提供了一种新方法，能够有效解决LLM代理的性能量化和可信度评估问题。

Abstract: With the evolution of generative AI, multi - agent systems leveraging large -
language models(LLMs) have emerged as a powerful tool for complex tasks.
However, these systems face challenges in quantifying agent performance and
lack mechanisms to assess agent credibility. To address these issues, we
introduce DRF, a dynamic reputation filtering framework. DRF constructs an
interactive rating network to quantify agent performance, designs a reputation
scoring mechanism to measure agent honesty and capability, and integrates an
Upper Confidence Bound - based strategy to enhance agent selection efficiency.
Experiments show that DRF significantly improves task completion quality and
collaboration efficiency in logical reasoning and code - generation tasks,
offering a new approach for multi - agent systems to handle large - scale
tasks.

</details>


### [517] [Decision-Focused Learning Enhanced by Automated Feature Engineering for Energy Storage Optimisation](https://arxiv.org/abs/2509.05772)
*Nasser Alkhulaifi,Ismail Gokay Dogan,Timothy R. Cargan,Alexander L. Bowler,Direnc Pekaslan,Nicholas J. Watson,Isaac Triguero*

Main category: cs.AI

TL;DR: 决策导向学习（DFL）框架结合自动特征工程（AFE）以优化电池储能系统（BESS）的运营，并在实际数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 电池储能系统（BESS）在能源管理中的不确定性决策因参数未知而复杂化，而现有的预测-优化（PTO）方法由于忽略了预测误差对下游任务的影响，会导致次优决策。虽然决策导向学习（DFL）方法解决了这个问题，但它们在实际应用中，尤其是在数据稀疏的真实世界场景中，其可行性尚未得到充分验证。

Method: 提出了一种结合自动特征工程（AFE）的决策导向学习（DFL）框架（AFE-DFL），该框架适用于小数据集，能够预测电力价格和需求，并优化BESS运营以降低成本。该方法通过AFE提取更丰富的特征表示，以改进DFL模型。在真实的英国房产数据集上进行了验证，并与未使用AFE的DFL和PTO方法进行了比较。

Result: 与PTO方法相比，DFL平均运营成本更低。结合AFE后，DFL性能比未使用AFE的DFL模型平均提高了22.9-56.5%。

Conclusion: 该研究为DFL在实际BESS优化中的可行性提供了实证依据，表明特定领域的AFE能够增强DFL性能，减少对领域专业知识的依赖，并带来经济效益，这对面临类似挑战的能源管理系统具有更广泛的启示。

Abstract: Decision-making under uncertainty in energy management is complicated by
unknown parameters hindering optimal strategies, particularly in Battery Energy
Storage System (BESS) operations. Predict-Then-Optimise (PTO) approaches treat
forecasting and optimisation as separate processes, allowing prediction errors
to cascade into suboptimal decisions as models minimise forecasting errors
rather than optimising downstream tasks. The emerging Decision-Focused Learning
(DFL) methods overcome this limitation by integrating prediction and
optimisation; however, they are relatively new and have been tested primarily
on synthetic datasets or small-scale problems, with limited evidence of their
practical viability. Real-world BESS applications present additional
challenges, including greater variability and data scarcity due to collection
constraints and operational limitations. Because of these challenges, this work
leverages Automated Feature Engineering (AFE) to extract richer representations
and improve the nascent approach of DFL. We propose an AFE-DFL framework
suitable for small datasets that forecasts electricity prices and demand while
optimising BESS operations to minimise costs. We validate its effectiveness on
a novel real-world UK property dataset. The evaluation compares DFL methods
against PTO, with and without AFE. The results show that, on average, DFL
yields lower operating costs than PTO and adding AFE further improves the
performance of DFL methods by 22.9-56.5% compared to the same models without
AFE. These findings provide empirical evidence for DFL's practical viability in
real-world settings, indicating that domain-specific AFE enhances DFL and
reduces reliance on domain expertise for BESS optimisation, yielding economic
benefits with broader implications for energy management systems facing similar
challenges.

</details>


### [518] [Chatbot To Help Patients Understand Their Health](https://arxiv.org/abs/2509.05818)
*Won Seok Jang,Hieu Tran,Manav Mistry,SaiKiran Gandluri,Yifan Zhang,Sharmin Sultana,Sunjae Kown,Yuan Zhang,Zonghai Yao,Hong Yu*

Main category: cs.AI

TL;DR: NoteAid-Chatbot是一个基于LLM和RL的对话式AI，通过‘边对话边学习’的框架，在无需人类标注数据的情况下，提升患者对自身护理的理解。


<details>
  <summary>Details</summary>
Motivation: 提升患者在护理中的参与度，使他们掌握必要知识。

Method: 使用多智能体LLM和RL设置，在两阶段训练一个轻量级LLaMA 3.2 3B模型：首先在合成的医学对话数据上进行监督微调，然后通过基于患者理解评估的奖励进行RL训练。

Result: NoteAid-Chatbot展现出清晰度、相关性和结构化对话等关键的涌现行为，并且在图灵测试中表现优于非专业人类。

Conclusion: 低成本、基于PPO的RL方法可以成功训练出轻量级、特定领域的聊天机器人，用于处理多轮交互、融合多样化教育策略并满足细微的沟通目标。该框架展示了RL在开放式对话领域的应用前景。

Abstract: Patients must possess the knowledge necessary to actively participate in
their care. We present NoteAid-Chatbot, a conversational AI that promotes
patient understanding via a novel 'learning as conversation' framework, built
on a multi-agent large language model (LLM) and reinforcement learning (RL)
setup without human-labeled data. NoteAid-Chatbot was built on a lightweight
LLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on
conversational data synthetically generated using medical conversation
strategies, followed by RL with rewards derived from patient understanding
assessments in simulated hospital discharge scenarios. Our evaluation, which
includes comprehensive human-aligned assessments and case studies, demonstrates
that NoteAid-Chatbot exhibits key emergent behaviors critical for patient
education, such as clarity, relevance, and structured dialogue, even though it
received no explicit supervision for these attributes. Our results show that
even simple Proximal Policy Optimization (PPO)-based reward modeling can
successfully train lightweight, domain-specific chatbots to handle multi-turn
interactions, incorporate diverse educational strategies, and meet nuanced
communication objectives. Our Turing test demonstrates that NoteAid-Chatbot
surpasses non-expert human. Although our current focus is on healthcare, the
framework we present illustrates the feasibility and promise of applying
low-cost, PPO-based RL to realistic, open-ended conversational domains,
broadening the applicability of RL-based alignment methods.

</details>


### [519] [MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration](https://arxiv.org/abs/2509.05933)
*Md Hasebul Hasan,Mahir Labib Dihan,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: MapAgent是一个用于地理空间推理的多代理框架，通过分层设计和定制工具集，解决了现有框架在地理空间任务中的不足，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有Agentic AI框架在数学、编程和网络自动化等领域表现出色，但在需要空间推理、多跳规划和实时地图交互的地理空间任务方面存在不足。

Method: MapAgent采用分层多代理架构，将规划与执行分离。高层规划器将复杂查询分解为子目标，并路由到专门的模块。对于地图服务等工具密集型模块，设计了专门的地图工具代理，能够自适应地并行协调相关API，以有效获取地理空间数据。其他模块则在没有额外代理开销的情况下运行。

Result: 在MapEval-Textual、MapEval-API、MapEval-Visual和MapQA这四个地理空间基准测试中，MapAgent相较于最先进的工具增强和代理基线模型取得了显著的性能提升。

Conclusion: MapAgent通过分层设计、专门的工具集和代理脚手架，有效解决了地理空间推理中的挑战，提高了工具选择的准确性，并实现了精确的API协调，从而在地理空间任务中展现出优越的性能。

Abstract: Agentic AI has significantly extended the capabilities of large language
models (LLMs) by enabling complex reasoning and tool use. However, most
existing frameworks are tailored to domains such as mathematics, coding, or web
automation, and fall short on geospatial tasks that require spatial reasoning,
multi-hop planning, and real-time map interaction. To address these challenges,
we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with
customized toolsets and agentic scaffolds for map-integrated geospatial
reasoning. Unlike existing flat agent-based approaches that treat tools
uniformly-often overwhelming the LLM when handling similar but subtly different
geospatial APIs-MapAgent decouples planning from execution. A high-level
planner decomposes complex queries into subgoals, which are routed to
specialized modules. For tool-heavy modules-such as map-based services-we then
design a dedicated map-tool agent that efficiently orchestrates related APIs
adaptively in parallel to effectively fetch geospatial data relevant for the
query, while simpler modules (e.g., solution generation or answer extraction)
operate without additional agent overhead. This hierarchical design reduces
cognitive load, improves tool selection accuracy, and enables precise
coordination across similar APIs. We evaluate MapAgent on four diverse
geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and
MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented
and agentic baselines. We open-source our framwork at
https://github.com/Hasebul/MapAgent.

</details>


### [520] [Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL](https://arxiv.org/abs/2509.06024)
*Haoyang He,Zihua Rong,Kun Ji,Chenyang Li,Qing Huang,Chong Xia,Lan Yang,Honggang Zhang*

Main category: cs.AI

TL;DR: 研究提出了一种名为动态推理效率奖励（DRER）的即插即用强化学习（RL）奖励框架，通过引入推理质量奖励和动态长度优势来解决现有基于规则的奖励函数在评估大型语言模型（LLM）的链式思考（CoT）能力时的局限性。该框架通过直接激励有益的CoT代币并稳定训练过程，来提升LLM的逻辑推理能力。同时，研究发布了Logictree数据集，用于RL训练和评估。实验结果表明，DRER能够显著提高LLM的推理性能和置信度，并在多个推理数据集和数学基准测试中表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的奖励函数在评估LLM的链式思考（CoT）能力时，只关注答案的格式和正确性，无法评估CoT是否真正提升了答案的质量，并且难以控制推理的深度，可能无法充分展现模型的真实推理能力。因此，需要一种新的奖励机制来更有效地激励和评估LLM的推理过程。

Method: 研究提出了动态推理效率奖励（DRER）框架，包含两个关键部分：1. 推理质量奖励：为能够提高正确答案出现概率的推理链提供细粒度的奖励，直接激励包含有益CoT代币的推理轨迹。2. 动态长度优势：通过衰减与验证集派生阈值偏差的响应长度的优势，来稳定训练过程。此外，研究还发布了Logictree数据集，用于RL训练和评估。

Result: 实验证明了DRER的有效性。使用DRER的7B模型在Logictree数据集上达到了与GPT-03-mini相当的性能，且仅用了400次训练步骤。CoT增强答案的平均置信度提高了30%。该模型在多个逻辑推理数据集和AIME24数学基准测试中也表现出良好的泛化能力。

Conclusion: DRER框架能够有效地改进LLM的CoT行为，为提升大型语言模型的形式推理能力提供了一条实用的途径。该研究揭示了RL如何塑造CoT行为，并为未来的研究提供了新的方向和工具。

Abstract: Reinforcement learning (RL) has recently become the dominant paradigm for
strengthening the reasoning abilities of large language models (LLMs). Yet the
rule-based reward functions commonly used on mathematical or programming
benchmarks assess only answer format and correctness, providing no signal as to
whether the induced Chain-of-Thought (CoT) actually improves the answer.
Furthermore, such task-specific training offers limited control over logical
depth and therefore may fail to reveal a model's genuine reasoning capacity. We
propose Dynamic Reasoning Efficiency Reward (DRER) -- a plug-and-play RL reward
framework that reshapes both reward and advantage signals. (i) A Reasoning
Quality Reward assigns fine-grained credit to those reasoning chains that
demonstrably raise the likelihood of the correct answer, directly incentivising
the trajectories with beneficial CoT tokens. (ii) A Dynamic Length Advantage
decays the advantage of responses whose length deviates from a
validation-derived threshold, stabilising training. To facilitate rigorous
assessment, we also release Logictree, a dynamically constructed deductive
reasoning dataset that functions both as RL training data and as a
comprehensive benchmark. Experiments confirm the effectiveness of DRER: our 7B
model attains GPT-o3-mini level performance on Logictree with 400 trianing
steps, while the average confidence of CoT-augmented answers rises by 30%. The
model further exhibits generalisation across diverse logical-reasoning
datasets, and the mathematical benchmark AIME24. These results illuminate how
RL shapes CoT behaviour and chart a practical path toward enhancing
formal-reasoning skills in large language models. All code and data are
available in repository https://github.com/Henryhe09/DRER.

</details>


### [521] [Reverse-Engineered Reasoning for Open-Ended Generation](https://arxiv.org/abs/2509.06160)
*Haozhe Wang,Haoran Que,Qixin Xu,Minghao Liu,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Wei Ye,Tong Yang,Wenhao Huang,Ge Zhang,Fangzhen Lin*

Main category: cs.AI

TL;DR: REER通过反向工程从已知解决方案中发现潜在的深度推理过程，解决了开放式生成中深度推理的挑战，并推出了DeepWriting-20K数据集和DeepWriter-8B模型，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 开放式生成任务中，现有的深度推理方法（如强化学习和指令蒸馏）存在局限性，例如缺乏明确的奖励信号、高昂的成本以及受限于教师模型的性能。

Method: 提出REER（Reverse-Engineered Reasoning）新范式，通过反向工程从已知解决方案中计算发现生成这些解决方案的潜在、逐步的深度推理过程。

Result: 创建了DeepWriting-20K数据集，包含20,000个开放式任务的深度推理轨迹。基于该数据训练的DeepWriter-8B模型，性能超越了开源基线，并能与GPT-4o和Claude 3.5等领先的专有模型相媲美，甚至在某些方面更优。

Conclusion: REER范式能够有效地解决开放式生成中的深度推理挑战，并通过DeepWriting-20K数据集和DeepWriter-8B模型展示了其优越的性能。

Abstract: While the ``deep reasoning'' paradigm has spurred significant advances in
verifiable domains like mathematics, its application to open-ended, creative
generation remains a critical challenge. The two dominant methods for
instilling reasoning -- reinforcement learning (RL) and instruction
distillation -- falter in this area; RL struggles with the absence of clear
reward signals and high-quality reward models, while distillation is
prohibitively expensive and capped by the teacher model's capabilities. To
overcome these limitations, we introduce REverse-Engineered Reasoning (REER), a
new paradigm that fundamentally shifts the approach. Instead of building a
reasoning process ``forwards'' through trial-and-error or imitation, REER works
``backwards'' from known-good solutions to computationally discover the latent,
step-by-step deep reasoning process that could have produced them. Using this
scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a
large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.
Our model, DeepWriter-8B, trained on this data, not only surpasses strong
open-source baselines but also achieves performance competitive with, and at
times superior to, leading proprietary models like GPT-4o and Claude 3.5.

</details>


### [522] [From Long to Short: LLMs Excel at Trimming Own Reasoning Chains](https://arxiv.org/abs/2509.06174)
*Wei Han,Geng Zhan,Sicheng Yu,Chenyu Wang,Bryan Hooi*

Main category: cs.AI

TL;DR: LRMs在复杂推理任务上表现出色，但存在“过度思考”问题。本文提出EDIT方法，通过在测试时进行动态修剪，平衡正确性和简洁性，生成更高效、更易读的推理路径。


<details>
  <summary>Details</summary>
Motivation: LRMs（大型推理模型）虽然在复杂推理任务上取得了SOTA（State-of-the-Art）的成就，但存在“过度思考”的倾向，导致推理过程冗长、可解释性差。需要解决如何在保证正确性的前提下，提高推理效率和简洁性。

Method: 提出一种名为EDIT（Efficient Dynamic Inference Trimming）的测试时（test-time）缩放方法。EDIT通过约束引导生成，同时追踪不同约束下的长度和答案分布，以识别最短的正确推理路径，从而在简洁性和正确性之间取得平衡。

Result: 在多种模型和数据集上的广泛实验表明，EDIT能显著提高LRMs的推理效率，生成更简洁但信息量丰富的输出，提升了可读性和用户体验。

Conclusion: EDIT是一种有效的解决方案，可以缓解LRMs的过度思考问题，提高其在复杂推理任务上的效率和可解释性。

Abstract: O1/R1 style large reasoning models (LRMs) signal a substantial leap forward
over conventional instruction-following LLMs. By applying test-time scaling to
generate extended reasoning paths, they establish many SOTAs across a wide
range of complex reasoning tasks. However, recent studies show that LRMs are
prone to suffer from overthinking -- the tendency to overcomplicate simple
problems, leading to excessive strategy switching and long, convoluted
reasoning traces that hinder their interpretability. To mitigate this issue, we
conduct a systematic investigation into the reasoning efficiency of a broad set
of LRMs and uncover a common dilemma: the difficulty in balancing multiple
generation objectives such as correctness and brevity. Based on this discovery,
we propose a test-time scaling method, EDIT (Efficient Dynamic Inference
Trimming), which efficiently guides LRMs to identify the shortest correct
reasoning paths at test time. EDIT employs constraint-guided generation while
jointly tracking length and answer distributions under varying constraints,
allowing it to select responses that strike an optimal balance between
conciseness and correctness. Extensive experiments across diverse models and
datasets show that EDIT substantially enhance the reasoning efficiency,
producing compact yet informative outputs that improve readability and user
experience.

</details>


### [523] [Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning](https://arxiv.org/abs/2509.06239)
*Manvi Jha,Jiaxin Wan,Deming Chen*

Main category: cs.AI

TL;DR: 该研究提出了Proof2Silicon框架，用于从自然语言规范生成经过形式验证的硬件。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）生成的代码常无法通过形式验证，这对于硬件和安全关键领域至关重要。

Method: Proof2Silicon框架整合了PREFACE的基于强化学习（RL）的提示优化方法，以生成可验证的Dafny代码，然后将验证后的Dafny程序翻译成C语言，最后使用Vivado HLS生成RTL实现。

Result: 在100个任务的基准测试中，PREFACE的RL指导提示优化将Dafny代码的验证成功率提高了21%。Proof2Silicon实现了高达72%的端到端硬件合成成功率。

Conclusion: Proof2Silicon提供了一个强大、可扩展且自动化的流水线，实现了从自然语言规范到最终硅实现的全过程形式验证硬件合成。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
automated code generation but frequently produce code that fails formal
verification, an essential requirement for hardware and safety-critical
domains. To overcome this fundamental limitation, we previously proposed
PREFACE, a model-agnostic framework based on reinforcement learning (RL) that
iteratively repairs the prompts provided to frozen LLMs, systematically
steering them toward generating formally verifiable Dafny code without costly
fine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis
framework that embeds the previously proposed PREFACE flow to enable the
generation of correctness-by-construction hardware directly from natural
language specifications. Proof2Silicon operates by: (1) leveraging PREFACE's
verifier-driven RL agent to optimize prompt generation iteratively, ensuring
Dafny code correctness; (2) automatically translating verified Dafny programs
into synthesizable high-level C using Dafny's Python backend and PyLog; and (3)
employing Vivado HLS to produce RTL implementations. Evaluated rigorously on a
challenging 100-task benchmark, PREFACE's RL-guided prompt optimization
consistently improved Dafny verification success rates across diverse LLMs by
up to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis
success rate of up to 72%, generating RTL designs through Vivado HLS synthesis
flows. These results demonstrate a robust, scalable, and automated pipeline for
LLM-driven, formally verified hardware synthesis, bridging natural-language
specification and silicon realization.

</details>


### [524] [REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents](https://arxiv.org/abs/2509.06269)
*Vishal Raman,Vijai Aravindh R,Abhijith Ragav*

Main category: cs.AI

TL;DR: REMI是一个多模态生活代理的因果模式记忆架构，通过整合个人因果知识图谱、因果推理引擎和基于模式的规划模块，为用户提供可解释的、个性化的时尚、健康和生活规划建议。它通过目标导向的因果遍历、外部知识和假设推理，并检索可适应的计划模式来生成定制行动计划。


<details>
  <summary>Details</summary>
Motivation: 解决个性化AI助手在整合复杂个人数据和因果知识方面的不足，以及提供缺乏解释能力的通用建议的问题。

Method: 提出REMI（因果模式记忆）架构，包括个人因果图谱、因果推理引擎和模式规划模块，并利用大型语言模型进行编排，生成带有透明因果解释的定制行动计划。

Result: REMI架构的代理能够提供比基线LLM代理更具上下文感知能力、更符合用户需求推荐。

Conclusion: REMI架构是一种新颖的记忆增强、因果推理方法，可用于个性化代理，推动透明、可信赖的AI生活助手的发展。

Abstract: Personalized AI assistants often struggle to incorporate complex personal
data and causal knowledge, leading to generic advice that lacks explanatory
power. We propose REMI, a Causal Schema Memory architecture for a multimodal
lifestyle agent that integrates a personal causal knowledge graph, a causal
reasoning engine, and a schema based planning module. The idea is to deliver
explainable, personalized recommendations in domains like fashion, personal
wellness, and lifestyle planning. Our architecture uses a personal causal graph
of the user's life events and habits, performs goal directed causal traversals
enriched with external knowledge and hypothetical reasoning, and retrieves
adaptable plan schemas to generate tailored action plans. A Large Language
Model orchestrates these components, producing answers with transparent causal
explanations. We outline the CSM system design and introduce new evaluation
metrics for personalization and explainability, including Personalization
Salience Score and Causal Reasoning Accuracy, to rigorously assess its
performance. Results indicate that CSM based agents can provide more context
aware, user aligned recommendations compared to baseline LLM agents. This work
demonstrates a novel approach to memory augmented, causal reasoning in
personalized agents, advancing the development of transparent and trustworthy
AI lifestyle assistants.

</details>


### [525] [TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning](https://arxiv.org/abs/2509.06278)
*Chuang Jiang,Mingyue Cheng,Xiaoyu Tao,Qingyang Mao,Jie Ouyang,Qi Liu*

Main category: cs.AI

TL;DR: TableMind是一个LLM驱动的表格推理代理，通过自主调用工具、安全的代码执行以及高层次的规划和自我反思能力，提高了表格推理的准确性和适应性。它采用两阶段微调，包括监督微调和基于RAPO的强化微调。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理方法在处理复杂的数值计算和精细操作时存在不足，而纯文本方法难以实现高精度计算，已有的工具集成方法则依赖于固定的模式、监督模仿且缺乏自主适应性。

Method: TableMind采用两阶段微调范式：首先在高质量推理轨迹上进行监督微调，以建立有效的工具使用模式；然后进行强化微调，优化多目标策略。其中，RAPO（Rank-Aware Policy Optimization）通过增加高质量轨迹的更新权重来指导模型更稳定地获得更优、更准确的答案。

Result: 在多个主流基准测试上的广泛实验表明，TableMind的性能优于竞争性基线方法，在推理准确性和计算精度方面均取得显著提升。

Conclusion: TableMind通过其自主工具调用、代码执行以及规划和自我反思能力，在表格推理任务上取得了优越的性能，解决了现有方法的局限性。

Abstract: Table reasoning is crucial for leveraging structured data in domains such as
finance, healthcare, and scientific research. While large language models
(LLMs) show promise in multi-step reasoning, purely text-based methods often
struggle with the complex numerical computations and fine-grained operations
inherently required in this task. Tool-integrated reasoning improves
computational accuracy via explicit code execution, yet existing systems
frequently rely on rigid patterns, supervised imitation, and lack true
autonomous adaptability. In this paper, we present TableMind, an LLM-driven
table reasoning agent that (i) autonomously performs multi-turn tool
invocation, (ii) writes and executes data-analyzing code in a secure sandbox
environment for data analysis and precise numerical reasoning, and (iii)
exhibits high-level capabilities such as planning and self-reflection to adapt
strategies. To realize these capabilities, we adopt a two-stage fine-tuning
paradigm built on top of a powerful pre-trained language model: supervised
fine-tuning on high-quality reasoning trajectories to establish effective tool
usage patterns, followed by reinforcement fine-tuning to optimize
multi-objective strategies. In particular, we propose Rank-Aware Policy
Optimization (RAPO), which increases the update weight of high-quality
trajectories when their output probabilities are lower than those of
low-quality ones, thereby guiding the model more consistently toward better and
more accurate answers. Extensive experiments on several mainstream benchmarks
demonstrate that TableMind achieves superior performance compared to
competitive baselines, yielding substantial gains in both reasoning accuracy
and computational precision.

</details>


### [526] [SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents](https://arxiv.org/abs/2509.06283)
*Xuan-Phi Nguyen,Shrey Pandit,Revanth Gangi Reddy,Austin Xu,Silvio Savarese,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Equipping large language models (LLMs) with complex, interleaved reasoning
and tool-use capabilities has become a key focus in agentic AI research,
especially with recent advances in reasoning-oriented (``thinking'') models.
Such capabilities are key to unlocking a number of important applications. One
such application is Deep Research (DR), which requires extensive search and
reasoning over many sources. Our work in this paper focuses on the development
of native Autonomous Single-Agent models for DR featuring minimal web crawling
and Python tool integration. Unlike multi-agent systems, where agents take up
pre-defined roles and are told what to do at each step in a static workflow, an
autonomous single-agent determines its next action dynamically based on
context, without manual directive. While prior work has proposed training
recipes for base or instruction-tuned LLMs, we focus on continual reinforcement
learning (RL) of reasoning-optimized models to further enhance agentic skills
while preserving reasoning ability. Towards this end, we propose a simple RL
recipe with entirely synthetic data, which we apply to various open-source
LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam
benchmark. In addition, we conduct key analysis experiments to provide more
insights into our methodologies.

</details>


### [527] [From Implicit Exploration to Structured Reasoning: Leveraging Guideline and Refinement for LLMs](https://arxiv.org/abs/2509.06284)
*Jiaxiang Chen,Zhuo Wang,Mingxi Zou,Zhucong Li,Zhijian Zhou,Song Wang,Zenglin Xu*

Main category: cs.AI

TL;DR: 本研究提出了一种从隐式探索转向结构化推理的框架，通过引入推理指南和逐步优化来提高大型语言模型的稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在推理任务中依赖隐式探索，导致推理路径不稳定、缺乏纠错能力且难以从过往经验中学习。

Method: 提出一个框架，将隐式探索转变为结构化推理。该框架首先从成功的推理路径中提取结构化推理模式，并从失败的案例中提取反思信号。在推理过程中，模型遵循这些指南逐步进行，并在每一步之后进行优化，以纠正错误并稳定推理过程。

Result: 在BBH、GSM8K、MATH-500、MBPP和HumanEval等基准测试中，该方法持续优于强大的基线模型。结构化推理和逐步优化提高了稳定性和泛化能力。推理指南在不同领域具有良好的迁移性，并能灵活支持跨模型协作，其效果和可扩展性可媲美甚至超越监督微调。

Conclusion: 结构化推理通过逐步执行和优化，能够显著提高大型语言模型的推理稳定性和泛化能力，并且推理指南具有良好的跨领域迁移能力和可扩展性，能够有效支持跨模型协作。

Abstract: Large language models (LLMs) have advanced general-purpose reasoning, showing
strong performance across diverse tasks. However, existing methods often rely
on implicit exploration, where the model follows stochastic and unguided
reasoning paths-like walking without a map. This leads to unstable reasoning
paths, lack of error correction, and limited learning from past experience. To
address these issues, we propose a framework that shifts from implicit
exploration to structured reasoning through guideline and refinement. First, we
extract structured reasoning patterns from successful trajectories and
reflective signals from failures. During inference, the model follows these
guidelines step-by-step, with refinement applied after each step to correct
errors and stabilize the reasoning process. Experiments on BBH and four
additional benchmarks (GSM8K, MATH-500, MBPP, HumanEval) show that our method
consistently outperforms strong baselines across diverse reasoning tasks.
Structured reasoning with stepwise execution and refinement improves stability
and generalization, while guidelines transfer well across domains and flexibly
support cross-model collaboration, matching or surpassing supervised
fine-tuning in effectiveness and scalability.

</details>


### [528] [Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models](https://arxiv.org/abs/2509.06307)
*Lei Shu,Dong Zhao*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在住宅节能改造决策方面展现出潜力，但在准确性、一致性和上下文处理方面需要改进。


<details>
  <summary>Details</summary>
Motivation: 现有住宅节能改造决策方法泛化能力有限且可解释性差，难以在不同住宅环境中推广。随着智慧互联社区的发展，大型语言模型（LLMs）有望通过处理上下文信息并生成易于实践者理解的建议来提供帮助。

Method: 评估七种大型语言模型（ChatGPT、DeepSeek、Gemini、Grok、Llama 和 Claude）在两种目标下的住宅节能改造决策表现：最大化减少二氧化碳（技术目标）和最小化投资回收期（社会技术目标）。在包含美国 49 个州 400 栋住宅的数据集上，在准确性、一致性、敏感性和推理四个维度上评估模型性能。

Result: 在无需微调的情况下，LLMs 在许多情况下能生成有效的建议，最高达到 54.5% 的 top 1 匹配率和 92.8% 的 top 5 匹配率。模型在技术目标方面表现更强，但在社会技术决策方面，由于经济权衡和当地情况的限制，表现有所不足。模型之间的一致性较低，表现更优的模型往往与其他模型存在分歧。LLMs 对地点和建筑几何形状敏感，但对技术和用户行为不敏感。大多数模型展示了循序渐进的工程风格推理，但通常过于简化且缺乏深度的上下文感知能力。

Conclusion: LLMs 作为住宅节能改造决策的辅助工具具有前景，但为了在实践中可靠应用，需要在准确性、一致性和上下文处理能力方面进行改进。

Abstract: Conventional approaches to building energy retrofit decision making suffer
from limited generalizability and low interpretability, hindering adoption in
diverse residential contexts. With the growth of Smart and Connected
Communities, generative AI, especially large language models (LLMs), may help
by processing contextual information and producing practitioner readable
recommendations. We evaluate seven LLMs (ChatGPT, DeepSeek, Gemini, Grok,
Llama, and Claude) on residential retrofit decisions under two objectives:
maximizing CO2 reduction (technical) and minimizing payback period
(sociotechnical). Performance is assessed on four dimensions: accuracy,
consistency, sensitivity, and reasoning, using a dataset of 400 homes across 49
US states. LLMs generate effective recommendations in many cases, reaching up
to 54.5 percent top 1 match and 92.8 percent within top 5 without fine tuning.
Performance is stronger for the technical objective, while sociotechnical
decisions are limited by economic trade offs and local context. Agreement
across models is low, and higher performing models tend to diverge from others.
LLMs are sensitive to location and building geometry but less sensitive to
technology and occupant behavior. Most models show step by step, engineering
style reasoning, but it is often simplified and lacks deeper contextual
awareness. Overall, LLMs are promising assistants for energy retrofit decision
making, but improvements in accuracy, consistency, and context handling are
needed for reliable practice.

</details>


### [529] [Large Language Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation](https://arxiv.org/abs/2509.06337)
*Jianpeng Zhao,Chenyu Yuan,Weiming Luo,Haoling Xie,Guangwei Zhang,Steven Jige Quan,Zixuan Yuan,Pengyang Wang,Denghui Zhang*

Main category: cs.AI

TL;DR: 该研究提出使用大型语言模型（LLMs）模拟虚拟调查受访者，以克服传统调查方法的局限性，并介绍了部分属性模拟（PAS）和完全属性模拟（FAS）两种新方法。


<details>
  <summary>Details</summary>
Motivation: 传统问卷调查成本高、耗时长且规模受限，研究旨在探索使用大型语言模型（LLMs）模拟虚拟调查受访者的新范式，以提供可扩展且经济高效的解决方案。

Method: 提出部分属性模拟（PAS）和完全属性模拟（FAS）两种新模拟设置，并在包含11个真实世界公共数据集的LLM-S^3基准测试套件上，评估了多种主流LLMs（GPT-3.5/4 Turbo, LLaMA 3.0/3.1-8B）在不同上下文和提示设计下的表现。

Result: 评估结果揭示了主流LLMs在模拟调查响应方面的一致性表现趋势，指出了其失效模式，并展示了上下文和提示设计对模拟保真度的影响。

Conclusion: 该研究为LLM驱动的调查模拟奠定了严谨的基础，为社会学研究和政策评估提供了可扩展且经济高效的工具。

Abstract: Questionnaire-based surveys are foundational to social science research and
public policymaking, yet traditional survey methods remain costly,
time-consuming, and often limited in scale. This paper explores a new paradigm:
simulating virtual survey respondents using Large Language Models (LLMs). We
introduce two novel simulation settings, namely Partial Attribute Simulation
(PAS) and Full Attribute Simulation (FAS), to systematically evaluate the
ability of LLMs to generate accurate and demographically coherent responses. In
PAS, the model predicts missing attributes based on partial respondent
profiles, whereas FAS involves generating complete synthetic datasets under
both zero-context and context-enhanced conditions. We curate a comprehensive
benchmark suite, LLM-S^3 (Large Language Model-based Sociodemographic Survey
Simulation), that spans 11 real-world public datasets across four sociological
domains. Our evaluation of multiple mainstream LLMs (GPT-3.5/4 Turbo, LLaMA
3.0/3.1-8B) reveals consistent trends in prediction performance, highlights
failure modes, and demonstrates how context and prompt design impact simulation
fidelity. This work establishes a rigorous foundation for LLM-driven survey
simulations, offering scalable and cost-effective tools for sociological
research and policy evaluation. Our code and dataset are available at:
https://github.com/dart-lab-research/LLM-S-Cube-Benchmark

</details>


### [530] [Evaluating Multi-Turn Bargain Skills in LLM-Based Seller Agent](https://arxiv.org/abs/2509.06341)
*Issue Yishu Wang,Kakam Chong,Xiaofeng Wang,Xu Yan,DeXin Kong,Chen Ju,Ming Chen,Shuai Xiao,Shuguang Han,jufeng chen*

Main category: cs.AI

TL;DR: LLM可作为电商卖方代理进行多轮议价，但需要准确追踪买家意图。本文提出一个基于心智理论的评估框架和大规模电商议价基准，用于衡量LLM卖方代理在电商对话中的议价能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）可以充当卖方代理，代表卖家在给定业务限制下与买家进行谈判。此类代理的一个关键能力是跟踪和准确解释长期谈判中累积的买家意图，这直接影响议价的有效性。

Method: 提出一个多轮评估框架，用于衡量电商对话中卖方代理的议价能力。该框架测试代理是否能提取和跟踪买家意图，并引入了一个自动化的流水线，从海量对话数据中提取可靠的意图。

Result: 创建了一个大规模电商议价基准，涵盖622个类别、9,892种产品和3,014个任务，并设计了一个基于心智理论（ToM）并带有买家意图标注的turn-level评估框架。

Conclusion: 本研究提出了一个创新的评估框架和大规模数据集，以解决LLM在电商多轮议价中追踪买家意图的挑战，为开发更有效的LLM卖方代理提供了基础。

Abstract: In online second-hand marketplaces, multi-turn bargaining is a crucial part
of seller-buyer interactions. Large Language Models (LLMs) can act as seller
agents, negotiating with buyers on behalf of sellers under given business
constraints. A critical ability for such agents is to track and accurately
interpret cumulative buyer intents across long negotiations, which directly
impacts bargaining effectiveness. We introduce a multi-turn evaluation
framework for measuring the bargaining ability of seller agents in e-commerce
dialogues. The framework tests whether an agent can extract and track buyer
intents. Our contributions are: (1) a large-scale e-commerce bargaining
benchmark spanning 622 categories, 9,892 products, and 3,014 tasks; (2) a
turn-level evaluation framework grounded in Theory of Mind (ToM) with annotated
buyer intents, moving beyond outcome-only metrics; and (3) an automated
pipeline that extracts reliable intent from massive dialogue data.

</details>


### [531] [A data-driven discretized CS:GO simulation environment to facilitate strategic multi-agent planning research](https://arxiv.org/abs/2509.06355)
*Yunzhe Wang,Volkan Ustun,Chris McGroarty*

Main category: cs.AI

TL;DR: DECOY是一个新的多智能体模拟器，它将3D地形中战略性、长远的规划抽象为高层次的离散化模拟，同时保留了低层次的环境保真度。它使用CS:GO作为测试平台，仅通过移动决策来模拟游戏玩法，而无需显式模拟瞄准和射击等低层次机制。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂的、高保真度的多智能体交互模拟环境中平衡计算效率。

Method: 使用一种由航点系统和基于真实CS:GO比赛数据的预测和生成模型组成的框架，将连续状态和动作离散化，以重建事件结果。

Result: 在DECOY中根据人类数据生成的对局与在原始游戏中观察到的对局高度匹配。

Conclusion: DECOY是一个公开可用的模拟环境，为推进战略性多智能体规划和行为生成研究提供了宝贵的工具。

Abstract: Modern simulation environments for complex multi-agent interactions must
balance high-fidelity detail with computational efficiency. We present DECOY, a
novel multi-agent simulator that abstracts strategic, long-horizon planning in
3D terrains into high-level discretized simulation while preserving low-level
environmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a
testbed, our framework accurately simulates gameplay using only movement
decisions as tactical positioning -- without explicitly modeling low-level
mechanics such as aiming and shooting. Central to our approach is a waypoint
system that simplifies and discretizes continuous states and actions, paired
with neural predictive and generative models trained on real CS:GO tournament
data to reconstruct event outcomes. Extensive evaluations show that replays
generated from human data in DECOY closely match those observed in the original
game. Our publicly available simulation environment provides a valuable tool
for advancing research in strategic multi-agent planning and behavior
generation.

</details>


### [532] [Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning](https://arxiv.org/abs/2509.06409)
*Yihong Luo,Wenwu He,Zhuo-Xu Cui,Dong Liang*

Main category: cs.AI

TL;DR: DiagCoT是一个多阶段框架，通过监督微调通用的视觉语言模型（VLMs），使其能够仅根据自由文本报告来模拟放射科医生逐步的诊断推理过程。


<details>
  <summary>Details</summary>
Motivation: 这项研究的动机是开发一种能够模拟放射科医生逐步诊断推理过程的AI系统，仅利用自由文本报告，以提高AI在放射学诊断中的可解释性和能力。

Method: DiagCoT框架结合了对比图像-报告调优以进行领域对齐，思维链监督以捕获推理逻辑，以及具有临床奖励信号的强化调优以增强事实准确性和流畅性。

Result: 在MIMIC-CXR基准测试中，DiagCoT将零样本疾病分类的AUC从0.52提高到0.76（绝对增幅0.24），病理学定位的mIoU从0.08提高到0.31（绝对增幅0.23），报告生成的BLEU分数从0.11提高到0.33（绝对增幅0.22）。与LLaVA-Med和CXR-LLAVA等最先进的模型相比，DiagCoT在长尾疾病和外部数据集上表现更优。

Conclusion: 通过将非结构化的临床叙述转化为结构化的监督信号，DiagCoT为开发可解释且具有诊断能力的放射学AI系统提供了一种可扩展的方法。

Abstract: This study presents DiagCoT, a multi-stage framework that applies supervised
fine-tuning to general-purpose vision-language models (VLMs) to emulate
radiologists' stepwise diagnostic reasoning using only free-text reports.
DiagCoT combines contrastive image-report tuning for domain alignment,
chain-of-thought supervision to capture inferential logic, and reinforcement
tuning with clinical reward signals to enhance factual accuracy and fluency. On
the MIMIC-CXR benchmark, DiagCoT improved zero-shot disease classification AUC
from 0.52 to 0.76 (absolute gain of 0.24), pathology grounding mIoU from 0.08
to 0.31 (absolute gain of 0.23), and report generation BLEU from 0.11 to 0.33
(absolute gain of 0.22). It outperformed state-of-the-art models including
LLaVA-Med and CXR-LLAVA on long-tailed diseases and external datasets. By
converting unstructured clinical narratives into structured supervision,
DiagCoT offers a scalable approach for developing interpretable and
diagnostically competent AI systems for radiology.

</details>


### [533] [Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning](https://arxiv.org/abs/2509.06436)
*Song Yu,Xiaofei Xu,Ke Deng,Li Li,Lin Tian*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Tree of Agents (TOA)的多智能体推理框架，用于解决大型语言模型在处理长上下文任务时信息利用不足的问题，并提出了一种新的方法来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文任务时存在“中间丢失”的问题，现有方法要么可能丢弃关键信息，要么会导致注意力分散。TOA框架旨在解决这些限制。

Method: TOA框架将输入分割成块，由独立的智能体处理，每个智能体生成局部认知，然后沿树状路径动态交换信息进行协作推理。该框架还结合了前缀哈希缓存和自适应剪枝策略以提高效率。

Result: 实验表明，TOA框架显著优于多个基线模型，并在长上下文任务上取得了与Gemini1.5-pro等大型商业模型相当的性能。

Conclusion: TOA框架通过分块处理、协作推理和优化策略，有效解决了长上下文任务中的信息利用不足和位置偏差问题，同时保持了可比的API开销。

Abstract: Large language models (LLMs) face persistent challenges when handling
long-context tasks, most notably the lost in the middle issue, where
information located in the middle of a long input tends to be underutilized.
Some existing methods that reduce input have the risk of discarding key
information, while others that extend context windows often lead to attention
dispersion. To address these limitations, we propose Tree of Agents (TOA), a
multi-agent reasoning framework that segments the input into chunks processed
by independent agents. Each agent generates its local cognition, then agents
dynamically exchange information for collaborative reasoning along
tree-structured paths. TOA enables agents to probe different reasoning orders
for multi-perspective understanding, effectively mitigating position bias and
reducing hallucinations. To improve processing efficiency, we incorporate
prefix-hash caching and adaptive pruning strategies, achieving significant
performance improvements with comparable API overhead. Experiments show that
TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple
baselines and demonstrates comparable performance to the latest and much larger
commercial models, such as Gemini1.5-pro, on various long-context tasks. Code
is available at https://github.com/Aireduce952/Tree-of-Agents.

</details>


### [534] [HyFedRAG: A Federated Retrieval-Augmented Generation Framework for Heterogeneous and Privacy-Sensitive Data](https://arxiv.org/abs/2509.06444)
*Cheng Qian,Hainan Zhang,Yongxin Tong,Hong-Wei Zheng,Zhiming Zheng*

Main category: cs.AI

TL;DR: HyFedRAG是一个联邦检索增强生成（RAG）框架，用于处理医疗保健领域的异构、隐私敏感数据，通过边缘-云协作实现跨SQL、知识图谱和文本的统一检索与生成，同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域存在异构、隐私敏感的数据，患者数据分布在SQL、知识图谱和临床笔记中。传统云端RAG系统难以处理多样化的数据格式和边缘设备，且无法满足隐私约束，导致罕见病案例检索困难。

Method: HyFedRAG设计了一个基于Flower的边缘-云协作RAG框架。边缘端LLM将多样化数据转换为标准化的隐私保护表示，服务器端LLM整合这些表示进行全局推理和生成。集成了轻量级本地检索器、隐私感知LLM和三种匿名化工具。设计了三层缓存策略（本地缓存、中间表示缓存、云推理缓存）以优化响应延迟和减少冗余计算。

Result: 在PMC-Patients数据集上的实验表明，HyFedRAG在检索质量、生成一致性和系统效率方面优于现有基线方法。

Conclusion: HyFedRAG为结构化异构数据上的RAG提供了一个可扩展且符合隐私的解决方案，能够有效处理敏感和多样化的数据环境，释放LLM的潜力。

Abstract: Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive
data, especially in distributed healthcare settings where patient data spans
SQL, knowledge graphs, and clinical notes. Clinicians face difficulties
retrieving rare disease cases due to privacy constraints and the limitations of
traditional cloud-based RAG systems in handling diverse formats and edge
devices. To address this, we introduce HyFedRAG, a unified and efficient
Federated RAG framework tailored for Hybrid data modalities. By leveraging an
edge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across
diverse data sources while preserving data privacy. Our key contributions are:
(1) We design an edge-cloud collaborative RAG framework built on Flower, which
supports querying structured SQL data, semi-structured knowledge graphs, and
unstructured documents. The edge-side LLMs convert diverse data into
standardized privacy-preserving representations, and the server-side LLMs
integrates them for global reasoning and generation. (2) We integrate
lightweight local retrievers with privacy-aware LLMs and provide three
anonymization tools that enable each client to produce semantically rich,
de-identified summaries for global inference across devices. (3) To optimize
response latency and reduce redundant computation, we design a three-tier
caching strategy consisting of local cache, intermediate representation cache,
and cloud inference cache. Experimental results on PMC-Patients demonstrate
that HyFedRAG outperforms existing baselines in terms of retrieval quality,
generation consistency, and system efficiency. Our framework offers a scalable
and privacy-compliant solution for RAG over structural-heterogeneous data,
unlocking the potential of LLMs in sensitive and diverse data environments.

</details>


### [535] [Accelerate Scaling of LLM Alignment via Quantifying the Coverage and Depth of Instruction Set](https://arxiv.org/abs/2509.06463)
*Chengwei Wu,Li Du,Hanyu Zhao,Yiming Ju,Jiapu Wang,Tengfei Pan*

Main category: cs.AI

TL;DR: 本研究提出了一种新的指令数据选择方法，通过最大化指令深度和语义覆盖率来提高大语言模型在下游任务中的对齐性能和效率，实现了“加速扩展”。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在下游任务中应用的增长，提高模型对齐的性能和效率变得至关重要。然而，由于指令集分布的复杂性，影响对齐模型性能的关键因素仍不清楚，导致现有方法在指令池不断扩大的情况下难以持续提升性能。

Method: 本研究首先探究了影响指令数据集分布与对齐模型性能之间关系的关​​键因素，提出了一种新颖的指令数据选择方法，该方法通过最大化所选指令的深度和语义覆盖率来同时优化这两个因素。

Result: 实验结果表明，与最先进的基线方法相比，该方法能够以更快的速度持续提高模型性能，实现“加速扩展”。

Conclusion: 指令的深度和语义覆盖率是决定下游性能的关键因素，能够解释超过70%的发展集上的模型损失。所提出的指令选择算法能够有效提升模型性能并实现“加速扩展”。

Abstract: With the growing demand for applying large language models to downstream
tasks, improving model alignment performance and efficiency has become crucial.
Such a process involves selecting informative instructions from a candidate
pool. However, due to the complexity of instruction set distributions, the key
factors driving the performance of aligned models remain unclear. As a result,
current instruction set refinement methods fail to improve performance as the
instruction pool expands continuously. To address this issue, we first
investigate the key factors that influence the relationship between instruction
dataset distribution and aligned model performance. Based on these insights, we
propose a novel instruction data selection method. We identify that the depth
of instructions and the coverage of the semantic space are the crucial factors
determining downstream performance, which could explain over 70\% of the model
loss on the development set. We then design an instruction selection algorithm
to simultaneously maximize the depth and semantic coverage of the selected
instructions. Experimental results demonstrate that, compared to
state-of-the-art baseline methods, it can sustainably improve model performance
at a faster pace and thus achieve \emph{``Accelerated Scaling''}.

</details>


### [536] [MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents](https://arxiv.org/abs/2509.06477)
*Pengxiang Zhao,Guangyi Liu,Yaozhen Liang,Weiqing He,Zhengxi Lu,Yuehao Huang,Yaxuan Guo,Kexin Zhang,Hao Wang,Liang Liu,Yong Liu*

Main category: cs.AI

TL;DR: MAS-Bench是一个用于评估结合了GUI操作和快捷方式（如API、深度链接）的混合智能体的基准测试，特别关注移动领域。它通过139个跨11个真实世界应用程序的复杂任务来评估智能体自主生成快捷方式的能力，并包含88个预定义的快捷方式和7个评估指标。实验表明，混合智能体比仅使用GUI的智能体具有更高的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高GUI智能体在智能手机和计算机等各种平台上的效率，结合了灵活的GUI操作和高效的快捷方式（例如API、深度链接）的混合范式正在成为一个有前途的方向。然而，系统地对这些混合智能体进行基准测试的框架仍然探索不足。

Method: 提出MAS-Bench基准测试，该基准测试开创性地通过重点关注移动领域来评估GUI-快捷方式混合智能体。MAS-Bench不仅使用预定义的快捷方式，还评估智能体通过发现和创建可重用的、低成本的工作流来自主生成快捷方式的能力。它包含11个真实世界应用程序中的139个复杂任务、88个预定义快捷方式（API、深度链接、RPA脚本）的知识库以及7个评估指标。

Result: 实验表明，混合智能体实现了显著更高的成功率和效率，优于仅使用GUI的智能体。该结果还证明了我们评估智能体快捷方式生成能力的方法的有效性。

Conclusion: MAS-Bench填补了关键的评估空白，为未来在创建更高效、更强大的智能体方面取得进展提供了一个基础平台。

Abstract: To enhance the efficiency of GUI agents on various platforms like smartphones
and computers, a hybrid paradigm that combines flexible GUI operations with
efficient shortcuts (e.g., API, deep links) is emerging as a promising
direction. However, a framework for systematically benchmarking these hybrid
agents is still underexplored. To take the first step in bridging this gap, we
introduce MAS-Bench, a benchmark that pioneers the evaluation of GUI-shortcut
hybrid agents with a specific focus on the mobile domain. Beyond merely using
predefined shortcuts, MAS-Bench assesses an agent's capability to autonomously
generate shortcuts by discovering and creating reusable, low-cost workflows. It
features 139 complex tasks across 11 real-world applications, a knowledge base
of 88 predefined shortcuts (APIs, deep-links, RPA scripts), and 7 evaluation
metrics. The tasks are designed to be solvable via GUI-only operations, but can
be significantly accelerated by intelligently embedding shortcuts. Experiments
show that hybrid agents achieve significantly higher success rates and
efficiency than their GUI-only counterparts. This result also demonstrates the
effectiveness of our method for evaluating an agent's shortcut generation
capabilities. MAS-Bench fills a critical evaluation gap, providing a
foundational platform for future advancements in creating more efficient and
robust intelligent agents.

</details>


### [537] [MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization](https://arxiv.org/abs/2509.06490)
*Niki Kotecha,Ehecatl Antonio del Rio Chanona*

Main category: cs.AI

TL;DR: 本研究结合强化学习（RL）和多目标进化算法（MOEAs），提出一种动态多目标优化方法，用于解决供应链管理中的多目标冲突问题，并考虑不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统多目标优化方法难以实时适应动态变化的供应链，本研究旨在解决此问题。

Method: 利用MOEAs搜索策略神经网络的参数空间，生成策略的帕累托前沿，并结合条件在险价值（CVaR）进行风险敏感的决策。

Result: 通过案例研究，验证了该方法能够有效应对供应链动态变化，并在库存管理案例中优于现有最先进的方法。

Conclusion: 所提出的策略提高了决策效率，为管理供应链中的不确定性和优化绩效提供了更鲁棒的框架。

Abstract: In supply chain management, decision-making often involves balancing multiple
conflicting objectives, such as cost reduction, service level improvement, and
environmental sustainability. Traditional multi-objective optimization methods,
such as linear programming and evolutionary algorithms, struggle to adapt in
real-time to the dynamic nature of supply chains. In this paper, we propose an
approach that combines Reinforcement Learning (RL) and Multi-Objective
Evolutionary Algorithms (MOEAs) to address these challenges for dynamic
multi-objective optimization under uncertainty. Our method leverages MOEAs to
search the parameter space of policy neural networks, generating a Pareto front
of policies. This provides decision-makers with a diverse population of
policies that can be dynamically switched based on the current system
objectives, ensuring flexibility and adaptability in real-time decision-making.
We also introduce Conditional Value-at-Risk (CVaR) to incorporate
risk-sensitive decision-making, enhancing resilience in uncertain environments.
We demonstrate the effectiveness of our approach through case studies,
showcasing its ability to respond to supply chain dynamics and outperforming
state-of-the-art methods in an inventory management case study. The proposed
strategy not only improves decision-making efficiency but also offers a more
robust framework for managing uncertainty and optimizing performance in supply
chains.

</details>


### [538] [Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers](https://arxiv.org/abs/2509.06493)
*Ran Xin,Zeyu Zheng,Yanchen Nie,Kun Yuan,Xia Xiao*

Main category: cs.AI

TL;DR: LLMs在自动定理证明中虽有潜力，但面临训练和推理的扩展性挑战。本文提出BFS-Prover-V2，通过多轮离轨RL和规划器增强的多代理搜索来解决这些问题，并在MiniF2F和ProofNet基准上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）集成到自动定理证明（ATP）中，但面临训练和推理计算的扩展性挑战。

Method: 提出了一种新颖的多轮离轨强化学习（RL）框架，用于在训练时持续改进LLM步进证明器的性能，并采用了多阶段专家迭代流程，包括自适应策略级别的数据过滤和定期再训练。同时，提出了一种规划器增强的多代理搜索架构，以在推理时扩展推理能力，该架构使用通用推理模型作为高级规划器，迭代地将复杂定理分解为一系列更简单的子目标，并利用共享证明缓存，使并行证明代理能够有效地协作。

Result: BFS-Prover-V2在MiniF2F和ProofNet测试集上分别达到了95.08%和41.4%的准确率，在形式数学基准上取得了最先进的结果。

Conclusion: 本文提出的RL和推理技术不仅在形式数学领域有效，而且在需要长时限多轮推理和复杂搜索的其他领域也具有广泛的应用前景。

Abstract: The integration of Large Language Models (LLMs) into automated theorem
proving has shown immense promise, yet is fundamentally constrained by
challenges in scaling up both training-time reinforcement learning (RL) and
inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system
designed to address this dual scaling problem. We present two primary
innovations. The first is a novel multi-turn off-policy RL framework for
continually improving the performance of LLM step-prover at training time. This
framework, inspired by the principles of AlphaZero, utilizes a multi-stage
expert iteration pipeline featuring adaptive tactic-level data filtering and
periodic retraining to surmount the performance plateaus that typically curtail
long-term RL in LLM-based agents. The second innovation is a planner-enhanced
multi-agent search architecture that scales reasoning capabilities at inference
time. This architecture employs a general reasoning model as a high-level
planner to iteratively decompose complex theorems into a sequence of simpler
subgoals. This hierarchical approach substantially reduces the search space,
enabling a team of parallel prover agents to collaborate efficiently by
leveraging a shared proof cache. We demonstrate that this dual approach to
scaling yields state-of-the-art results on established formal mathematics
benchmarks. \texttt{BFS-Prover-V2} achieves 95.08\% and 41.4\% on the MiniF2F
and ProofNet test sets respectively. While demonstrated in the domain of formal
mathematics, the RL and inference techniques presented in this work are of
broader interest and may be applied to other domains requiring long-horizon
multi-turn reasoning and complex search.

</details>


### [539] [An AI system to help scientists write expert-level empirical software](https://arxiv.org/abs/2509.06503)
*Eser Aygün,Anastasiya Belyaeva,Gheorghe Comanici,Marc Coram,Hao Cui,Jake Garrison,Renee Johnston Anton Kast,Cory Y. McLean,Peter Norgaard,Zahra Shamsi,David Smalling,James Thompson,Subhashini Venugopalan,Brian P. Williams,Chujun He,Sarah Martinson,Martyna Plomecka,Lai Wei,Yuchen Zhou,Qian-Ze Zhu,Matthew Abraham,Erica Brand,Anna Bulanova,Jeffrey A. Cardille,Chris Co,Scott Ellsworth,Grace Joseph,Malcolm Kane,Ryan Krueger,Johan Kartiwa,Dan Liebling,Jan-Matthis Lueckmann,Paul Raccuglia,Xuefei,Wang,Katherine Chou,James Manyika,Yossi Matias,John C. Platt,Lizzie Dorfman,Shibl Mourad,Michael P. Brenner*

Main category: cs.AI

TL;DR: 一个AI系统，结合大语言模型和树搜索，能够自主生成高级科学软件，并在生物信息学、流行病学、地理空间分析等多个领域取得了超越人类专家的方法和成果。


<details>
  <summary>Details</summary>
Motivation: 科学发现周期常受限于计算实验软件的耗时且手动创建过程，限制了研究的进展。

Method: 提出一个结合大语言模型（LLM）和树搜索（TS）的AI系统，该系统旨在最大化一个质量指标来系统地改进软件，并智能地探索可能的解决方案空间。

Result: 在生物信息学领域，发现了40种新的单细胞数据分析方法，在公开排行榜上优于人类开发的顶级方法。在流行病学领域，生成了14个在预测COVID-19住院人数方面优于CDC模型集合和其他个体模型的模型。此外，该方法还在地理空间分析、斑马鱼神经活动预测、时间序列预测和积分数值解等领域取得了最先进的软件。

Conclusion: 该AI系统通过自主设计和实现解决各种任务的新颖解决方案，代表了加速科学进步的重要一步。

Abstract: The cycle of scientific discovery is frequently bottlenecked by the slow,
manual creation of software to support computational experiments. To address
this, we present an AI system that creates expert-level scientific software
whose goal is to maximize a quality metric. The system uses a Large Language
Model (LLM) and Tree Search (TS) to systematically improve the quality metric
and intelligently navigate the large space of possible solutions. The system
achieves expert-level results when it explores and integrates complex research
ideas from external sources. The effectiveness of tree search is demonstrated
across a wide range of benchmarks. In bioinformatics, it discovered 40 novel
methods for single-cell data analysis that outperformed the top human-developed
methods on a public leaderboard. In epidemiology, it generated 14 models that
outperformed the CDC ensemble and all other individual models for forecasting
COVID-19 hospitalizations. Our method also produced state-of-the-art software
for geospatial analysis, neural activity prediction in zebrafish, time series
forecasting and numerical solution of integrals. By devising and implementing
novel solutions to diverse tasks, the system represents a significant step
towards accelerating scientific progress.

</details>


### [540] [CogGuide: Human-Like Guidance for Zero-Shot Omni-Modal Reasoning](https://arxiv.org/abs/2509.06641)
*Zhou-Peng Shou,Zhi-Qiang You,Fang Wang,Hai-Bo Liu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态大模型在复杂跨模态推理中存在的“捷径”问题和上下文理解不足的缺陷，

Method: 提出了一种以“意图草图”为中心，并受类人认知策略指导的零样本多模态推理组件。该组件包含一个即插即用的“意图感知器”、“策略生成器”和“策略选择器”三模块流水线，明确构建了“理解-计划-选择”的认知过程。通过生成和筛选“意图草图”策略来指导最终推理，无需参数微调，仅通过上下文工程即可实现跨模型迁移。

Result: 信息论分析表明，该过程可以降低条件熵，提高信息利用效率，从而抑制非预期的捷径推理。在IntentBench、WorldSense和Daily-Omni上的实验验证了该方法的通用性和稳健性提升；与各自基线相比，完整的“三模块”方案在不同的推理引擎和流水线组合中都取得了持续的改进，提升幅度高达约9.51个百分点。

Conclusion: 证明了“意图草图”推理组件在零样本场景下的实际价值和可移植性。

Abstract: Targeting the issues of "shortcuts" and insufficient contextual understanding
in complex cross-modal reasoning of multimodal large models, this paper
proposes a zero-shot multimodal reasoning component guided by human-like
cognitive strategies centered on an "intent sketch". The component comprises a
plug-and-play three-module pipeline-Intent Perceiver, Strategy Generator, and
Strategy Selector-that explicitly constructs a "understand-plan-select"
cognitive process. By generating and filtering "intent sketch" strategies to
guide the final reasoning, it requires no parameter fine-tuning and achieves
cross-model transfer solely through in-context engineering.
Information-theoretic analysis shows that this process can reduce conditional
entropy and improve information utilization efficiency, thereby suppressing
unintended shortcut reasoning. Experiments on IntentBench, WorldSense, and
Daily-Omni validate the method's generality and robust gains; compared with
their respective baselines, the complete "three-module" scheme yields
consistent improvements across different reasoning engines and pipeline
combinations, with gains up to approximately 9.51 percentage points,
demonstrating the practical value and portability of the "intent sketch"
reasoning component in zero-shot scenarios.

</details>


### [541] [Reinforcement Learning Foundations for Deep Research Systems: A Survey](https://arxiv.org/abs/2509.06733)
*Wenjun Li,Zhi Chen,Jingru Lin,Hannan Cao,Wei Han,Sheng Liang,Zhi Zhang,Kuicai Dong,Dexun Li,Chen Zhang,Yong Liu*

Main category: cs.AI

TL;DR: 该论文是首次专门研究深度研究系统的强化学习基础的调查。


<details>
  <summary>Details</summary>
Motivation: 目前的深度研究系统（Agentic AI）虽然在复杂的多步任务协调、推理、网络搜索和工具使用方面取得了进展，但端到端的训练方法不切实际。现有的监督微调（SFT）和偏好对齐（如DPO）方法存在局限性，如模仿偏差、环境反馈利用不足、对人类定义的决策点和子技能的依赖等。强化学习（RL）在解决这些问题方面具有潜力，因为它能优化轨迹策略、促进探索、实现恢复行为、进行信用分配，并减少对人类先验知识和评分者偏见的依赖。

Method: 本文系统地梳理了自DeepSeek-R1以来，在深度研究系统强化学习领域的研究工作，主要围绕三个方面展开：（1）数据合成与管理；（2）用于Agentic研究的强化学习方法，包括稳定性、样本效率、长上下文处理、奖励与信用分配设计、多目标优化和多模态集成；（3）Agentic强化学习的训练系统与框架。此外，还涵盖了Agent架构、协调、评估与基准测试，包括问答、视觉问答、长篇内容生成以及领域相关的工具交互任务。

Result: 本调查对深度研究系统的强化学习基础进行了系统性梳理，涵盖了数据处理、强化学习方法、训练系统、Agent架构、评估等多个方面，并对现有模式进行了提炼，指出了基础设施瓶颈，为训练鲁棒、透明的深度研究Agent提供了实践指导。

Conclusion: 本调查是首次全面探讨深度研究系统强化学习基础的文献，旨在为该领域的研究者提供一个系统性的视角和实践指导，以克服现有方法的局限性，推动更强大、更可靠的深度研究Agent的发展。

Abstract: Deep research systems, agentic AI that solve complex, multi-step tasks by
coordinating reasoning, search across the open web and user files, and tool
use, are moving toward hierarchical deployments with a Planner, Coordinator,
and Executors. In practice, training entire stacks end-to-end remains
impractical, so most work trains a single planner connected to core tools such
as search, browsing, and code. While SFT imparts protocol fidelity, it suffers
from imitation and exposure biases and underuses environment feedback.
Preference alignment methods such as DPO are schema and proxy-dependent,
off-policy, and weak for long-horizon credit assignment and multi-objective
trade-offs. A further limitation of SFT and DPO is their reliance on human
defined decision points and subskills through schema design and labeled
comparisons. Reinforcement learning aligns with closed-loop, tool-interaction
research by optimizing trajectory-level policies, enabling exploration,
recovery behaviors, and principled credit assignment, and it reduces dependence
on such human priors and rater biases.
  This survey is, to our knowledge, the first dedicated to the RL foundations
of deep research systems. It systematizes work after DeepSeek-R1 along three
axes: (i) data synthesis and curation; (ii) RL methods for agentic research
covering stability, sample efficiency, long context handling, reward and credit
design, multi-objective optimization, and multimodal integration; and (iii)
agentic RL training systems and frameworks. We also cover agent architecture
and coordination, as well as evaluation and benchmarks, including recent QA,
VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We
distill recurring patterns, surface infrastructure bottlenecks, and offer
practical guidance for training robust, transparent deep research agents with
RL.

</details>


### [542] [VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction](https://arxiv.org/abs/2509.06736)
*Jie Yang,Jiajun Chen,Zhangyue Yin,Shuo Chen,Yuxin Wang,Yiran Guo,Yuan Li,Yining Zheng,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 智能车辆座舱的 API 代理面临独特挑战，需要协调复杂子系统。传统函数调用 (FC) 方法是无状态的，效率低下且错误恢复能力有限。我们提出了 VehicleWorld，一个包含 30 个模块、250 个 API 和 680 个属性的汽车领域环境，并提供了可执行的实现。通过分析，我们发现直接状态预测优于函数调用。我们提出了一种新的基于状态的函数调用 (SFC) 方法，该方法保持显式的系统状态意识并实现直接状态转换。实验结果表明，SFC 在执行准确性和延迟方面显著优于传统 FC 方法。


<details>
  <summary>Details</summary>
Motivation: 智能车辆座舱的 API 代理需要协调复杂子系统，传统 FC 方法效率低下且错误恢复能力有限。

Method: 提出 VehicleWorld 环境，包含 30 个模块、250 个 API 和 680 个属性。通过分析发现直接状态预测优于 FC。提出基于状态的函数调用 (SFC) 方法，保持系统状态意识并实现直接状态转换。

Result: SFC 在执行准确性和延迟方面显著优于传统 FC 方法。

Conclusion: SFC 是智能车辆座舱 API 代理的一种更优越的方法，能够提高执行准确性并降低延迟。

Abstract: Intelligent vehicle cockpits present unique challenges for API Agents,
requiring coordination across tightly-coupled subsystems that exceed typical
task environments' complexity. Traditional Function Calling (FC) approaches
operate statelessly, requiring multiple exploratory calls to build
environmental awareness before execution, leading to inefficiency and limited
error recovery. We introduce VehicleWorld, the first comprehensive environment
for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties
with fully executable implementations that provide real-time state information
during agent execution. This environment enables precise evaluation of vehicle
agent behaviors across diverse, challenging scenarios. Through systematic
analysis, we discovered that direct state prediction outperforms function
calling for environmental control. Building on this insight, we propose
State-based Function Call (SFC), a novel approach that maintains explicit
system state awareness and implements direct state transitions to achieve
target conditions. Experimental results demonstrate that SFC significantly
outperforms traditional FC approaches, achieving superior execution accuracy
and reduced latency. We have made all implementation code publicly available on
Github https://github.com/OpenMOSS/VehicleWorld.

</details>


### [543] [Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM Prompting](https://arxiv.org/abs/2509.06770)
*Shashidhar Reddy Javaji,Bhavul Gauri,Zining Zhu*

Main category: cs.AI

TL;DR: LLMs在多轮对话中表现不一，需要评估迭代过程。提出一个包含想法、代码和数学任务的评估框架，通过12轮对话和不同提示来测试，并使用特定指标（语义变化、轮次变化、输出大小）进行评估。结果表明，迭代收益因领域而异，且在早期（想法、代码）或晚期（数学）出现，明确的提示比模糊的提示更有效。该框架有助于衡量和比较LLM的迭代能力。


<details>
  <summary>Details</summary>
Motivation: 缺乏评估LLM在多轮对话中迭代改进效果的方法，尤其是在不同领域（想法、代码、数学）。

Method: 设计了一个包含12轮对话的评估协议，使用多种提示（模糊和明确），并记录每轮输出。针对不同任务（代码、数学、想法）设计了相应的评分机制（单元测试、答案等价性、原创性等），并跟踪了三类指标：语义变化、轮次变化和输出大小。

Result: 在想法和代码任务中，迭代收益主要出现在早期；在数学任务中，通过详细阐述的晚期迭代尤为重要。模糊提示效果有限，明确提示能有效提升特定质量维度。想法任务的语义变化最大，代码任务输出大小增长但语义变化小，数学任务在晚期迭代中可能偏离初始路径。

Conclusion: 提出的框架和指标使得LLM的迭代过程可衡量、可比较，并能指导何时进行调整、停止或切换策略。

Abstract: Large language models (LLMs) are now used in multi-turn workflows, but we
still lack a clear way to measure when iteration helps and when it hurts. We
present an evaluation framework for iterative refinement that spans ideation,
code, and math. Our protocol runs controlled 12-turn conversations per task,
utilizing a variety of prompts ranging from vague ``improve it'' feedback to
targeted steering, and logs per-turn outputs. We score outcomes with
domain-appropriate checks (unit tests for code; answer-equivalence plus
reasoning-soundness for math; originality and feasibility for ideation) and
track turn-level behavior with three families of metrics: semantic movement
across turns, turn-to-turn change, and output size growth. Across models and
tasks, gains are domain-dependent: they arrive early in ideas and code, but in
math late turns matter when guided by elaboration. After the first few turns,
vague feedback often plateaus or reverses correctness, while targeted prompts
reliably shift the intended quality axis (novelty vs. feasibility in ideation;
speed vs. readability in code; in math, elaboration outperforms exploration and
drives late-turn gains). We also observe consistent domain patterns: ideation
moves more in meaning across turns, code tends to grow in size with little
semantic change, and math starts fixed but can break that path with late,
elaborative iteration.Together, the framework and metrics make iteration
measurable and comparable across models, and signal when to steer, stop, or
switch strategies.

</details>


### [544] [RAFFLES: Reasoning-based Attribution of Faults for LLM Systems](https://arxiv.org/abs/2509.06822)
*Chenyang Zhu,Spencer Hong,Jingyu Wu,Kushal Chawla,Charlotte Tang,Youbing Yin,Nathan Wolfe,Erin Babinsky,Daben Liu*

Main category: cs.AI

TL;DR: RAFFLES是一个评估架构，通过迭代式、多组件的流程，利用中心化的


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体系统评估方法（如单次LLM-as-a-judge）存在局限性，

Method: RAFFLES架构采用迭代式、多组件的流水线，

Result: RAFFLES在Who&When数据集上，

Conclusion: RAFFLES架构为实现自主系统的自动化故障检测迈出了关键一步，

Abstract: We have reached a critical roadblock in the development and enhancement of
long-horizon, multi-component LLM agentic systems: it is incredibly tricky to
identify where these systems break down and why. Evaluation capabilities that
currently exist today (e.g., single pass LLM-as-a-judge) are limited in that
they often focus on individual metrics or capabilities, end-to-end outcomes,
and are narrowly grounded on the preferences of humans. We argue that to match
the agentic capabilities, evaluation frameworks must also be able to reason,
probe, iterate, and understand the complex logic passing through these systems
over long horizons. In this paper, we present RAFFLES - an evaluation
architecture that incorporates reasoning and iterative refinement.
Specifically, RAFFLES operates as an iterative, multi-component pipeline, using
a central Judge to systematically investigate faults and a set of specialized
Evaluators to assess not only the system's components but also the quality of
the reasoning by the Judge itself, thereby building a history of hypotheses. We
tested RAFFLES against several baselines on the Who&When dataset, a benchmark
designed to diagnose the "who" (agent) and "when" (step) of a system's failure.
RAFFLES outperforms these baselines, achieving an agent-step fault pair
accuracy of over 43% on the Algorithmically-Generated dataset (a substantial
increase from the previously published best of 16.6%) and over 20% on the
Hand-Crafted dataset (surpassing the previously published best of 8.8%). These
results demonstrate a key step towards introducing automated fault detection
for autonomous systems over labor-intensive manual human review.

</details>


### [545] [Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet](https://arxiv.org/abs/2509.06861)
*James Xu Zhao,Bryan Hooi,See-Kiong Ng*

Main category: cs.AI

TL;DR: 测试时扩展（test-time scaling）在知识密集型任务上未能有效提高准确性，反而可能增加幻觉，但“思考”机制仍优于“不思考”。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展（test-time scaling）在知识密集型任务上的有效性不足，该任务需要高事实准确性和低幻觉率。

Method: 对 12 个推理模型在两个知识密集型基准上进行全面的测试时扩展评估，并分析扩展推理如何影响幻觉行为。

Result: 增加测试时计算量并不总能提高准确性，反而可能导致更多幻觉。幻觉的减少通常源于模型在思考后选择弃权，而非事实回忆的提高。更长的推理会促使模型尝试回答之前未回答的问题，这可能导致幻觉。案例研究表明，扩展推理会诱发确认偏差，导致过度自信的幻觉。

Conclusion: 尽管存在局限性，但与不思考相比，启用思考仍然是有益的。

Abstract: Test-time scaling increases inference-time computation by allowing models to
generate long reasoning chains, and has shown strong performance across many
domains. However, in this work, we show that this approach is not yet effective
for knowledge-intensive tasks, where high factual accuracy and low
hallucination rates are essential. We conduct a comprehensive evaluation of
test-time scaling using 12 reasoning models on two knowledge-intensive
benchmarks. Our results reveal that increasing test-time computation does not
consistently improve accuracy and, in many cases, it even leads to more
hallucinations. We then analyze how extended reasoning affects hallucination
behavior. We find that reduced hallucinations often result from the model
choosing to abstain after thinking more, rather than from improved factual
recall. Conversely, for some models, longer reasoning encourages attempts on
previously unanswered questions, many of which result in hallucinations. Case
studies show that extended reasoning can induce confirmation bias, leading to
overconfident hallucinations. Despite these limitations, we observe that
compared to non-thinking, enabling thinking remains beneficial. Code and data
are available at https://github.com/XuZhao0/tts-knowledge

</details>


### [546] [Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents](https://arxiv.org/abs/2509.06917)
*Jiacheng Miao,Joe R. Davis,Jonathan K. Pritchard,James Zou*

Main category: cs.AI

TL;DR: Paper2Agent将研究论文自动转换为可交互的AI代理，加速知识传播和应用。


<details>
  <summary>Details</summary>
Motivation: 传统研究论文难以理解和复用，Paper2Agent旨在解决这一障碍，将论文转化为主动的AI助手。

Method: Paper2Agent分析论文及其代码库，构建模型上下文协议（MCP）服务器，并生成和运行测试来优化MCP。然后将MCP连接到聊天代理，以自然语言处理科学查询。

Result: Paper2Agent成功创建了基于AlphaGenome、ScanPy和TISSUE的论文代理，能够复现原论文结果并处理新查询。

Conclusion: Paper2Agent通过将静态论文转化为动态AI代理，开创了知识传播的新范式，为AI协作奠定了基础。

Abstract: We introduce Paper2Agent, an automated framework that converts research
papers into AI agents. Paper2Agent transforms research output from passive
artifacts into active systems that can accelerate downstream use, adoption, and
discovery. Conventional research papers require readers to invest substantial
effort to understand and adapt a paper's code, data, and methods to their own
work, creating barriers to dissemination and reuse. Paper2Agent addresses this
challenge by automatically converting a paper into an AI agent that acts as a
knowledgeable research assistant. It systematically analyzes the paper and the
associated codebase using multiple agents to construct a Model Context Protocol
(MCP) server, then iteratively generates and runs tests to refine and robustify
the resulting MCP. These paper MCPs can then be flexibly connected to a chat
agent (e.g. Claude Code) to carry out complex scientific queries through
natural language while invoking tools and workflows from the original paper. We
demonstrate Paper2Agent's effectiveness in creating reliable and capable paper
agents through in-depth case studies. Paper2Agent created an agent that
leverages AlphaGenome to interpret genomic variants and agents based on ScanPy
and TISSUE to carry out single-cell and spatial transcriptomics analyses. We
validate that these paper agents can reproduce the original paper's results and
can correctly carry out novel user queries. By turning static papers into
dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for
knowledge dissemination and a foundation for the collaborative ecosystem of AI
co-scientists.

</details>


### [547] [Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference](https://arxiv.org/abs/2509.06942)
*Xiangwei Shen,Zhimin Li,Zhantao Yang,Shiyi Zhang,Yingfang Zhang,Donghao Li,Chunyu Wang,Qinglin Lu,Yansong Tang*

Main category: cs.AI

TL;DR: 直接对齐扩散模型与人类偏好，克服了计算成本高和需要持续离线适应的问题，通过预定义噪声先验和文本条件信号进行优化，显著提高了生成图像的真实感和美学质量。


<details>
  <summary>Details</summary>
Motivation: 直接使用可微分奖励将扩散模型与人类偏好对齐存在计算成本高（多步去噪和梯度计算）和需要持续离线适应（以达到期望的美学质量）的挑战。

Method: 提出Direct-Align方法，通过预定义噪声先验，利用扩散状态是噪声和目标图像之间插值的方程，从任何时间步有效地恢复原始图像，避免在后期时间步过度优化。引入语义相对偏好优化（SRPO），将奖励制定为文本条件信号，允许根据正面和负面提示增强进行在线奖励调整，减少对离线奖励微调的依赖。

Result: 通过优化去噪和在线奖励调整，对FLUX.1.dev模型进行了微调，使其在人类评估的真实感和美学质量方面提高了3倍以上。

Conclusion: 所提出的Direct-Align和SRPO方法有效解决了现有扩散模型对齐方法的局限性，通过优化去噪过程和引入在线奖励调整，显著提高了生成图像的质量。

Abstract: Recent studies have demonstrated the effectiveness of directly aligning
diffusion models with human preferences using differentiable reward. However,
they exhibit two primary challenges: (1) they rely on multistep denoising with
gradient computation for reward scoring, which is computationally expensive,
thus restricting optimization to only a few diffusion steps; (2) they often
need continuous offline adaptation of reward models in order to achieve desired
aesthetic quality, such as photorealism or precise lighting effects. To address
the limitation of multistep denoising, we propose Direct-Align, a method that
predefines a noise prior to effectively recover original images from any time
steps via interpolation, leveraging the equation that diffusion states are
interpolations between noise and target images, which effectively avoids
over-optimization in late timesteps. Furthermore, we introduce Semantic
Relative Preference Optimization (SRPO), in which rewards are formulated as
text-conditioned signals. This approach enables online adjustment of rewards in
response to positive and negative prompt augmentation, thereby reducing the
reliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model
with optimized denoising and online reward adjustment, we improve its
human-evaluated realism and aesthetic quality by over 3x.

</details>


### [548] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: LLM生成的调查数据与人类对应物的数据相符，但LLM在不同实验设置下未能保持内部一致性，因此在人类受试者研究中替代人类参与者存在重大缺陷。


<details>
  <summary>Details</summary>
Motivation: 评估LLM是否能替代人类受试者进行社会科学研究，重点关注LLM在不同实验设置下是否能保持内部行为一致性。

Method: 设计了一项研究，旨在（a）揭示LLM的内部状态，（b）在基本对话设置中检查LLM的行为，并评估LLM的行为是否与其内部状态一致。

Result: 在不同模型系列和不同模型大小的LLM中发现了显著的内部不一致性。研究发现，尽管LLM可以生成与人类对应物匹配的响应，但它们未能保持内部一致性。

Conclusion: LLM在人类受试者研究中替代人类参与者存在重大缺陷，因为它们无法保持内部一致性。

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [549] [Robustness and Invariance of Hybrid Metaheuristics under Objective Function Transformations](https://arxiv.org/abs/2509.05445)
*Grzegorz Sroka,Sławomir T. Wierzchoń*

Main category: cs.NE

TL;DR: 本研究评估了混合种群元启发式算法在面对不同目标空间变换时的鲁棒性和结构不变性。通过在19种先进算法（包括DE、PSO和近期受生物启发的方法）上应用轻量级即插即用混合算子，而不改变其内部逻辑，并在CEC-2017基准测试集上进行了实验。在四种维度（10, 30, 50, 100）和五种变换类型（基线、平移、缩放、旋转和常数移位）下进行测试。实验结果表明，基于差分的混合算法（如hIMODE, hSHADE, hDMSSA）在所有变换下均保持高精度、稳定性和不变性。相比之下，经典的PSO和HHO算法的变体在面对非分离或扭曲的景观时，性能显著下降。研究证实了在现实世界的优化任务中，具有结构弹性的自适应混合算法的优越性。


<details>
  <summary>Details</summary>
Motivation: 评估混合种群元启发式算法在不同目标空间变换下的鲁棒性和结构不变性。

Method: 将一个轻量级的混合算子应用于19种现有的元启发式算法，并在CEC-2017测试集上，在不同维度和五种变换类型下进行基准测试。使用Wilcoxon检验、Friedman检验、贝叶斯优势分析和收敛轨迹分析等统计方法进行比较。

Result: 基于差分的混合算法（如hIMODE, hSHADE, hDMSSA）在所有测试的变换下都表现出高精度、稳定性和不变性。而经典的PSO和HHO算法的变体在非分离或扭曲的景观中性能下降明显。

Conclusion: 自适应的、结构上具有弹性的混合算法在应对现实世界中存在的域特定变换的优化任务时，表现出优越性。

Abstract: This paper evaluates the robustness and structural invariance of hybrid
population-based metaheuristics under various objective space transformations.
A lightweight plug-and-play hybridization operator is applied to nineteen
state-of-the-art algorithms-including differential evolution (DE), particle
swarm optimization (PSO), and recent bio-inspired methods-without modifying
their internal logic. Benchmarking on the CEC-2017 suite across four dimensions
(10, 30, 50, 100) is performed under five transformation types: baseline,
translation, scaling, rotation, and constant shift. Statistical comparisons
based on Wilcoxon and Friedman tests, Bayesian dominance analysis, and
convergence trajectory profiling consistently show that differential-based
hybrids (e.g., hIMODE, hSHADE, hDMSSA) maintain high accuracy, stability, and
invariance under all tested deformations. In contrast, classical
algorithms-especially PSO- and HHO-based variants-exhibit significant
performance degradation under non-separable or distorted landscapes. The
findings confirm the superiority of adaptive, structurally resilient hybrids
for real-world optimization tasks subject to domain-specific transformations.

</details>


### [550] [Genesis: A Spiking Neuromorphic Accelerator With On-chip Continual Learning](https://arxiv.org/abs/2509.05858)
*Vedant Karia,Abdullah Zyarah,Dhireesha Kudithipudi*

Main category: cs.NE

TL;DR: Genesis是一个用于解决持续学习挑战的神经启发式加速器，在MNIST基准测试中实现了74.6%的准确率和17.08mW的功耗。


<details>
  <summary>Details</summary>
Motivation: 持续学习对于在现实世界环境中交互的人工智能代理至关重要，但现有的人工智能系统在记忆和计算方面存在高需求，尤其是在资源有限的平台上。生物大脑在这方面表现出色，具有内在的持续学习能力。

Method: 提出了一种名为Genesis的脉冲持续学习加速器架构。该架构支持活动依赖的超可塑性等神经启发机制，以减轻灾难性遗忘。它集成了低精度持续学习参数，并采用定制的数据移动策略来适应稀疏分布的脉冲。此外，该架构还采用内存映射技术，将超可塑性参数和突触权重放在单个地址位置，以实现更快的内存访问。

Result: 在无任务分割的MNIST基准测试上，Genesis的平均分类准确率为74.6%，在65nm工艺节点下的功耗为17.08mW。

Conclusion: Genesis通过整合神经启发机制、低精度参数和优化的内存管理，有效地解决了持续学习中的计算和内存限制问题，为在资源受限的平台上实现持续学习能力提供了有前景的解决方案。

Abstract: Continual learning, the ability to acquire and transfer knowledge through a
models lifetime, is critical for artificial agents that interact in real-world
environments. Biological brains inherently demonstrate these capabilities while
operating within limited energy and resource budgets. Achieving continual
learning capability in artificial systems considerably increases memory and
computational demands, and even more so when deploying on platforms with
limited resources. In this work, Genesis, a spiking continual learning
accelerator, is proposed to address this gap. The architecture supports
neurally inspired mechanisms, such as activity-dependent metaplasticity, to
alleviate catastrophic forgetting. It integrates low-precision continual
learning parametersand employs a custom data movement strategy to accommodate
the sparsely distributed spikes. Furthermore, the architecture features a
memory mapping technique that places metaplasticity parameters and synaptic
weights in a single address location for faster memory access. Results show
that the mean classification accuracy for Genesis is 74.6% on a task-agnostic
split-MNIST benchmark with power consumption of 17.08mW in a 65nm technology
node.

</details>


### [551] [An Explainable Framework for Particle Swarm Optimization using Landscape Analysis and Machine Learning](https://arxiv.org/abs/2509.06272)
*Nitin Gupta,Bapi Dutta,Anupam Yadav*

Main category: cs.NE

TL;DR: 本研究提出了一种多方面的粒子群优化(PSO)分析方法，利用探索性景观分析(ELA)和不同的拓扑结构（Ring, Star, Von Neumann）来提高算法的可解释性，并通过机器学习推荐最优参数配置。


<details>
  <summary>Details</summary>
Motivation: 为了解决群体智能算法（尤其是PSO）在实际应用中面临的透明度不足、难以理解算法组件如何影响性能的问题。

Method: 1. 开发了一个全面的景观特征化框架（使用ELA）来量化问题难度和识别影响PSO性能的关键特征。 2. 进行了实证研究，比较了Ring、Star和Von Neumann三种基本拓扑结构对探索-利用平衡、收敛行为和解质量的影响。 3. 提出了一个可解释的基准测试框架，用于分析这些拓扑结构如何影响信息流动、多样性和收敛性。 4. 引入了一种新的机器学习方法，通过训练预测模型来根据问题特征自动推荐最优的算法配置。

Result: 通过在24个基准函数和多个维度上的系统性实验，得出了关于拓扑结构选择和参数配置的实用指南，并为PSO开发了一个可解释的基准测试框架，揭示了拓扑结构如何影响信息流动、多样性和收敛性。

Conclusion: 本研究通过深入理解不同拓扑结构对PSO的影响，并结合机器学习进行自动配置，提高了PSO算法的透明度和可靠性，为开发更优的群体智能系统提供了实践指导。

Abstract: Swarm intelligence algorithms have demonstrated remarkable success in solving
complex optimization problems across diverse domains. However, their widespread
adoption is often hindered by limited transparency in how algorithmic
components influence performance. This work presents a multi-faceted
investigation of Particle Swarm Optimization (PSO) to further understand the
key role of different topologies for better interpretability and
explainability. To achieve this objective, we first develop a comprehensive
landscape characterization framework using Exploratory Landscape Analysis (ELA)
to quantify problem difficulty and identify critical features affecting the
optimization performance of PSO. Next, we conduct a rigorous empirical study
comparing three fundamental swarm communication architectures -- Ring, Star,
and Von Neumann topologies -- analysing their distinct impacts on
exploration-exploitation balance, convergence behaviour, and solution quality
and eventually develop an explainable benchmarking framework for PSO, to decode
how swarm topologies affects information flow, diversity, and convergence.
Based on this, a novel machine learning approach for automated algorithm
configuration is introduced for training predictive models on extensive Area
over the Convergence Curve (AOCC) data to recommend optimal settings based on
problem characteristics. Through systematic experimentation across twenty four
benchmark functions in multiple dimensions, we establish practical guidelines
for topology selection and parameter configuration. These findings advance the
development of more transparent and reliable swarm intelligence systems. The
source codes of this work can be accessed at
https://github.com/GitNitin02/ioh_pso.

</details>


### [552] [Full Integer Arithmetic Online Training for Spiking Neural Networks](https://arxiv.org/abs/2509.06636)
*Ismael Gomez,Guangzhi Tang*

Main category: cs.NE

TL;DR: SNNs训练的计算成本高昂，本文提出了一种整数运算的在线训练算法，通过混合精度训练，在保持准确率的同时，显著提高了训练效率并降低了内存消耗，适用于资源受限的神经形态硬件。


<details>
  <summary>Details</summary>
Motivation: 现有的SNN训练方法（如BPTT和RTRL）计算密集且内存占用高，限制了其在实际硬件上的应用。

Method: 提出一种仅使用整数运算的在线训练算法，并采用混合精度训练策略，用整数运算替代浮点运算，以提高效率和减少内存占用。该方法适用于卷积SNN（CSNN）和循环SNN（RSNN）。

Result: 在MNIST和SHD数据集上，混合精度SNN的准确率与全精度基线相当或更高，同时内存使用减少超过60%。8位或12位推理权重下的模型表现良好。

Conclusion: 所提出的仅使用整数的在线学习算法能够高效地训练SNN，在不牺牲准确率的情况下，为在资源受限的神经形态硬件上部署SNN提供了一种有效的解决方案。

Abstract: Spiking Neural Networks (SNNs) are promising for neuromorphic computing due
to their biological plausibility and energy efficiency. However, training
methods like Backpropagation Through Time (BPTT) and Real Time Recurrent
Learning (RTRL) remain computationally intensive. This work introduces an
integer-only, online training algorithm using a mixed-precision approach to
improve efficiency and reduce memory usage by over 60%. The method replaces
floating-point operations with integer arithmetic to enable hardware-friendly
implementation. It generalizes to Convolutional and Recurrent SNNs (CSNNs,
RSNNs), showing versatility across architectures. Evaluations on MNIST and the
Spiking Heidelberg Digits (SHD) dataset demonstrate that mixed-precision models
achieve accuracy comparable to or better than full-precision baselines using
16-bit shadow and 8- or 12-bit inference weights. Despite some limitations in
low-precision and deeper models, performance remains robust. In conclusion, the
proposed integer-only online learning algorithm presents an effective solution
for efficiently training SNNs, enabling deployment on resource-constrained
neuromorphic hardware without sacrificing accuracy.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [553] [Language Model Perplexity Predicts Scientific Surprise and Transformative Impact](https://arxiv.org/abs/2509.05591)
*Zhen Zhang,James Evans*

Main category: cs.SI

TL;DR: 通过分析海量论文，发现大型语言模型（LLMs）的困惑度（perplexity）可以预测科学突破的出现，高困惑度论文更可能成为重大科学成就或被忽视，并引发跨学科关注，尤其在科学领域。而人文学科领域则相反，低困惑度论文更受欢迎。


<details>
  <summary>Details</summary>
Motivation: 科学突破往往源于对既有研究范式的颠覆，但量化这种“惊喜”一直很困难，因为这需要一个全面的科学认知模型。作者提出，大型语言模型（LLMs）的困惑度可以作为衡量科学惊喜的指标，因为LLMs被训练来预测其训练数据中的文本模式，因此对不寻常文本的“意外程度”的度量，可以反映其与当前科学主流的偏离程度。

Method: 本研究分析了5个主流开源LLMs训练后发表的超过200万篇跨学科论文。通过计算这些论文相对于LLMs的困惑度得分，并分析这些得分与论文的评审反馈（评审评分变异性、编辑延迟、审稿人犹豫）、发表期刊的影响因子变异性、短期和长期引用、跨学科参与度、以及资助来源（如DARPA vs. NIH）等指标之间的关系。此外，研究还对比了科学和人文学科在困惑度与影响力方面的差异。

Result: 研究发现，高困惑度论文系统性地预示着更具变异性的评审评分、更长的编辑延迟和更大的审稿人犹豫。最具困惑度的论文呈现两极分化的结果：既可能成为最受赞誉的科学成就，也可能被严重低估。高困惑度论文倾向于发表在影响因子变异性更大的期刊上，短期内被引次数较少，但在被认为是具有长期影响力潜力的期刊上发表。它们更能引发跨学科的互动，预示着长期的影响力，并且更有可能获得如DARPA这类投机性基金的支持，而非NIH。然而，在人文学科研究中，观察到相反的模式，即最不令人意外（低困惑度）的作品最受赞誉和引用。

Conclusion: 计算出的语言学困惑度可以预测科学思想的接受度和最终影响力，为识别和产生挑战传统科学思维的潜在变革性研究提供了一种可扩展的方法。在科学领域，高困惑度预示着突破和长远影响，而在人文学科，则相反。

Abstract: Scientific breakthroughs typically emerge through the surprising violation of
established research ideas, yet quantifying surprise has remained elusive
because it requires a coherent model of all contemporary scientific worldviews.
Deep neural networks like large language models (LLMs) are arbitrary function
approximators tuned to consistently expect the expressions and ideas on which
they were trained and those semantically nearby. This suggests that as LLMs
improve at generating plausible text, so the perplexity or improbability a text
sequence would be generated by them should come to better predict scientific
surprise and disruptive importance. Analyzing over 2 million papers across
multiple disciplines published immediately following the training of 5
prominent open LLMs, here we show that higher perplexity scores systematically
predict papers that receive more variable review ratings, longer editorial
delays, and greater reviewer uncertainty. The most perplexing papers exhibit
bimodal outcomes: disproportionately represented among the most celebrated
scientific achievements and also the most discounted. High-perplexity papers
tend to be published in journals with more variable impact factors and receive
fewer short-term citations but in prestigious venues that bet on long-term
impact. They also generate more interdisciplinary engagement portending
long-term influence, and are more likely to have been supported by speculative
funders like DARPA versus the NIH. Interestingly, we find the opposite pattern
for humanities research, where the least surprising work is the most celebrated
and cited. Our findings reveal that computational measures of corpus-wide
linguistic surprise can forecast the reception and ultimate influence of
scientific ideas, offering a scalable approach to recognize and generate
potentially transformative research that challenge conventional scientific
thinking.

</details>


### [554] [A Spatiotemporal Adaptive Local Search Method for Tracking Congestion Propagation in Dynamic Networks](https://arxiv.org/abs/2509.06099)
*Weihua Huan,Kaizhen Tan,Xintao Liu,Shoujun Jia,Shijun Lu,Jing Zhang,Wei Huang*

Main category: cs.SI

TL;DR: 该研究提出了一种时空自适应局部搜索（STALS）方法，用于解决交通拥堵传播问题，该方法能够动态学习传播规则，并提高对不同数据粒度的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的交通拥堵传播研究依赖预定义的图结构，缺乏对不同数据粒度的适应性，STALS旨在解决此局限性。

Method: STALS包含两个模块：1.动态邻接矩阵学习模块，通过融合四种节点特征学习拥堵图中的时空关系。2.局部搜索模块，利用局部优势识别多尺度拥堵瓶颈及其传播路径。

Result: 在四个基准网络上的测试结果显示，STALS的归一化互信息（NMI）得分为0.97，平均执行时间为27.66秒，在鲁棒性和效率方面优于六种现有方法。对纽约、上海和乌鲁木齐三个大型交通网络的分析表明，STALS具有良好的时空尺度不变性和空间异质性。

Conclusion: STALS通过整合动态图学习和地理驱动的空间分析，为拥堵缓解提供了一个可扩展的工具。

Abstract: Traffic congestion propagation poses significant challenges to urban
sustainability, disrupting spatial accessibility. The cascading effect of
traffic congestion propagation can cause large-scale disruptions to networks.
Existing studies have laid a solid foundation for characterizing the cascading
effects. However, they typically rely on predefined graph structures and lack
adaptability to diverse data granularities. To address these limitations, we
propose a spatiotemporal adaptive local search (STALS) method, which feeds the
dynamically adaptive adjacency matrices into the local search algorithm to
learn propagation rules. Specifically, the STALS is composed of two data-driven
modules. One is a dynamic adjacency matrix learning module, which learns the
spatiotemporal relationship from congestion graphs by fusing four node
features. The other one is the local search module, which introduces local
dominance to identify multi-scale congestion bottlenecks and search their
propagation pathways. We test our method on the four benchmark networks with an
average of 15,000 nodes. The STALS remains a Normalized Mutual Information
(NMI) score at 0.97 and an average execution time of 27.66s, outperforming six
state-of-the-art methods in robustness and efficiency. We also apply the STALS
to three large-scale traffic networks in New York City, the United States,
Shanghai, China, and Urumqi, China. The ablation study reveals an average
modularity of 0.78 across three cities, demonstrating the spatiotemporal-scale
invariance of frequencytransformed features and the spatial heterogeneity of
geometric topological features. By integrating dynamic graph learning with
Geo-driven spatial analytics, STALS provides a scalable tool for congestion
mitigation.

</details>


### [555] [No Such Thing as Free Brain Time: For a Pigouvian Tax on Attention Capture](https://arxiv.org/abs/2509.06453)
*Hamza Belgroun,Franck Michel,Fabien Gandon*

Main category: cs.SI

TL;DR: 数字平台时代，人类注意力已成为一种稀缺且有价值的资源，并呈现出竞争性、可交易性和市场化等特征。本文旨在探讨注意力经济框架下注意力的商品化问题，并提出应将注意力视为一种面临过度开发威胁的公共物品。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨注意力经济框架下注意力的商品化问题，并提出应将注意力视为一种面临过度开发威胁的公共物品。

Method: 本文从哲学、经济学和法律角度对注意力进行了概念化，认为它不仅是个体认知过程，也是易受数字中介封闭的集体和基础设施现象。文章分析了注意力经济的负面外部性，特别是过度屏幕时间的危害，包括个体能动性减弱、健康状况不佳以及民主侵蚀和不平等加剧等社会政治危害。为应对这些问题，文章提议将“皮古税”作为一种有前景的监管工具，以内部化外部性，特别是强迫性数字参与的社会成本，从而鼓励平台设计进行结构性变革，同时保留用户自主权。

Result: 本文分析了注意力经济的负面外部性，特别是过度屏幕时间的危害，包括个体能动性减弱、健康状况不佳以及民主侵蚀和不平等加剧等社会政治危害。为应对这些问题，文章提议将“皮古税”作为一种有前景的监管工具，以内部化外部性，特别是强迫性数字参与的社会成本，从而鼓励平台设计进行结构性变革，同时保留用户自主权。

Conclusion: 本文倡导一种范式转变：将注意力视为对人类能动性、健康和民主至关重要的集体资源，而非私人可货币化资产，为数字监管辩论提供了新颖的经济和政策视角。

Abstract: In our age of digital platforms, human attention has become a scarce and
highly valuable resource, rivalrous, tradable, and increasingly subject to
market dynamics. This article explores the commodification of attention within
the framework of the attention economy, arguing that attention should be
understood as a common good threatened by over-exploitation. Drawing from
philosophical, economic, and legal perspectives, we first conceptualize
attention not only as an individual cognitive process but as a collective and
infrastructural phenomenon susceptible to enclosure by digital intermediaries.
We then identify and analyze negative externalities of the attention economy,
particularly those stemming from excessive screen time: diminished individual
agency, adverse health outcomes, and societal and political harms, including
democratic erosion and inequality. These harms are largely unpriced by market
actors and constitute a significant market failure. In response, among a
spectrum of public policy tools ranging from informational campaigns to
outright restrictions, we propose a Pigouvian tax on attention capture as a
promising regulatory instrument to internalize the externalities and, in
particular, the social cost of compulsive digital engagement. Such a tax would
incentivize structural changes in platform design while preserving user
autonomy. By reclaiming attention as a shared resource vital to human agency,
health, and democracy, this article contributes a novel economic and policy
lens to the debate on digital regulation. Ultimately, this article advocates
for a paradigm shift: from treating attention as a private, monetizable asset
to protecting it as a collective resource vital for humanity.

</details>


### [556] [Unveiling the Listener Structure Underlying K-pop's Global Success: A Large-Scale Listening Data Analysis](https://arxiv.org/abs/2509.06606)
*Ryota Nakamura,Keita Nishimoto,Ichiro Sakata,Kimitaka Asatani*

Main category: cs.SI

TL;DR: K-pop has become a global phenomenon, but its listeners' behavior and perception were not well understood. This study analyzed Last.fm data to find that K-pop's growth was driven by a small group of heavy listeners, and it established itself as a distinct genre between 2005 and 2010.


<details>
  <summary>Details</summary>
Motivation: To understand how global music listeners have listened to and perceived K-pop as it transitioned into a global music genre.

Method: Analyzed a large-scale listening dataset from Last.fm, examining play count distribution and user-assigned genre tags.

Result: K-pop experienced a significant increase in plays from 2005 to 2019, primarily driven by a small group of heavy listeners. The Gini coefficient of its play counts was higher than other mainstream and niche genres. User-assigned tags showed K-pop shifting from a local Asian genre to a distinct genre between 2005 and 2010.

Conclusion: K-pop's global expansion is characterized by a concentrated listener base and a clear establishment as an independent music genre, distinct from its regional origins.

Abstract: From the mid-2000s to the 2010s, K-pop moved beyond its status as a
regionally popular genre in Asia and established itself as a global music genre
with enthusiastic fans around the world. However, little is known about how the
vast number of music listeners across the globe have listened to and perceived
K-pop. This study addresses this question by analyzing a large-scale listening
dataset from Last.fm. An analysis of the distribution of play counts reveals
that K-pop experienced a significant increase in plays between 2005 and 2019,
largely supported by a small group of heavy listeners. The Gini coefficient in
play counts is notably greater than that of existing mainstream genres and
other growing niche genres. Furthermore, an analysis based on user-assigned
genre tags quantitatively demonstrates that between 2005 and 2010, K-pop shed
its status as a local Asian genre and established itself as a distinct music
genre in its own right.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [557] [A 10-bit SAR ADC with 1.5x Input Range](https://arxiv.org/abs/2509.05636)
*Yi Zhang*

Main category: physics.app-ph

TL;DR: 本篇论文提出了一个采用精密改进技术的10位、2 MS/s逐次逼近寄存器（SAR）模数转换器（ADC）。


<details>
  <summary>Details</summary>
Motivation: 在SAR ADC中，电容数字-模拟转换器（CDAC）的单位与ADC的分辨率之间存在直接的权衡。本研究旨在通过扩展有效输入范围来打破这种权衡，从而提高有效比特数（ENOB）。

Method: 该技术通过在采样期间切换最大有效位（MSB）电容器的电位来实现。

Result: 该设计采用了512个电容单元和参考电压VREF，实现了+-1.5VREF的扩展输入范围和10.5位的等效分辨率。在180-nm CMOS工艺下制造的原型芯片在后仿真中显示出10.36位ENOB，在1.8-V电源下，采样率为2 MS/s时功耗为48μW，面积为0.79mm2。

Conclusion: 所提出的精密改进技术理论上可提高超过0.5位的精度，并在实际设计中通过扩展输入范围和提高ENOB得到了验证。

Abstract: This paper presents a differential 10-bit 2 MS/s successive approximation
register (SAR) analog-to-digital converter (ADC) with a precision-improvement
technique. The proposed method breaks the direct tradeoff between the
capacitive digital-to-analog converter (CDAC) units and the resolution of SAR
ADCs by extending the effective input range, thereby enhancing the effective
number of bits (ENOB). Specifically, the technique is implemented by switching
the potential of the MSB capacitors during the sampling phase. Theoretically,
it enables a precision improvement of more than 0.5-bit. In this design, 512
capacitor units and a reference voltage VREF are employed, achieving an
extended input range of +-1.5VREF and an equivalent resolution of 10.5-bit.
Fabricated in a 180-nm CMOS process, the prototype chip demonstrates 10.36-bit
ENOB in post-simulation, while consuming 48{\mu}W at a sampling rate of 2 MS/s
under a 1.8-V supply, with an area of 0.79mm2.

</details>


### [558] [Observation of temporal Wood's anomaly in folded time gratings: surface-wave-enhanced transmission and the emergence of gain](https://arxiv.org/abs/2509.06029)
*Amit Shaham,Ben-Zion Joselson,Ilya Varenisov,Denis Dikarov,Ariel Epstein*

Main category: physics.app-ph

TL;DR: 本文首次在实验中观察到并利用了时间域的伍德异常现象，通过单周期时间调制元件实现了复杂度的降低和能量消耗的减少，并发现了可调谐的参量放大效应。


<details>
  <summary>Details</summary>
Motivation: 探索时间域的伍德异常现象，并研究其在动态滤波和泄漏波天线等领域的应用潜力。

Method: 设计了一种折叠时间光栅，由单个波导封闭的时间调制元件构成，并进行了实验验证，同时建立了相应的Floquet-Bloch分析理论模型。

Result: 成功观察到时间域的伍德异常，实现了比传统空间调制更优越的可调谐参量放大，并验证了理论模型的准确性。

Conclusion: 时间域的伍德异常现象是真实存在的，并提供了一种经济高效的方法来合成复杂的时间孔径，以增强动态滤波和泄漏波天线性能。

Abstract: Wood's anomaly is a fundamental wave phenomenon that stems from the interplay
between farfields and surface-wave (SW) resonances through structured
interfaces. Recent theories have suggested temporal analogs of such SW coupling
processes by employing frequency transitions via time-periodic interfaces,
rather than classical wavevector (momentum) transitions via space-periodic
gratings. In this paper, we observe this phenomenon experimentally by devising
a folded time grating of a single, waveguide-enclosed, time-modulated element;
this substantially reduces complexity and power consumption and facilitates
transmissive operation. We support our findings by deriving a comprehensive
Floquet-Bloch analysis that exhibits excellent agreement with measurements.
Importantly, we utilize our framework and experiment to reveal a unique regime
of temporal Wood's anomaly, in which coupling to negative SW frequencies
manifests tunable parametric amplification unattainable via traditional spatial
modulation. Beyond the fundamental contribution, our results provide an
economical path for universally synthesizing intricate temporal apertures to
enhance dynamic filtering and leaky-wave antennas.

</details>


### [559] [Screening currents increase thermal quench propagation speed in ultra-high-field REBCO magnets](https://arxiv.org/abs/2509.06621)
*Enric Pardo,Anang Dadhich,Nikola Jerance,Philippe Fazilleau*

Main category: physics.app-ph

TL;DR: 超导REBCO电磁体在MRI、NMR和聚变能等领域有广泛应用。为避免永久性损坏，需考虑电热淬火，但现有设计常忽略超导筛选电流。本研究表明，筛选电流对电热淬火传播速度有显著影响，必须纳入磁体设计。


<details>
  <summary>Details</summary>
Motivation: 现有高场磁体设计未考虑超导筛选电流，而筛选电流会加速电热淬火传播，可能导致永久性损坏。

Method: 基于最小电磁熵产生（MEMEP）和有限差分（MEMEP-FD）的详细数值模拟。模型通过与成熟的PEEC模型进行基准测试验证。

Result: 通过MEMEP-FD模型详细分析了32 T全超导磁体设计中电热淬火的时间演变过程，证明了筛选电流对电热淬火传播速度的加速作用。

Conclusion: 筛选电流在超高场磁体（如NMR或用户设施）的设计中至关重要，并可能对聚变能等其他类型的磁体设计产生影响。

Abstract: Superconducting REBCO ($RE$Ba$_2$Cu$_3$O$_{7-x}$, where $RE$ is a rare earth,
typically Y, Gd or Eu) electromagnets are useful for many applications like
medical magnetic resonace imaging (MRI), nuclear magnetic resonance (NMR)
spectroscopy, and magnets for particle accelerators and detectors. REBCO
magnets are also the core of many nuclear fusion energy start-ups. In order to
avoid permanent damage during operation, magnet design needs to take
electro-thermal quench into account, which is due to unavoidable REBCO tape or
magnet imperfections. However, most high-field magnet designs do not take
superconducting screening currents into account. In this work, we show that it
is essential to consider screening currents in magnet design, since they highly
speed-up electrothermal quench propagation. Our study is based on detailed
numerical modeling, based on the Minimum Electromagnetic Entropy Production
(MEMEP) and Finite Differences (MEMEP-FD). Benchmarking with well-established
Partial Element Equivalent Circuit (PEEC) model supports the correctness of
MEMEP-FD. This work focusses on a 32 T all-superconducting magnet design and we
analyze in detail the time evolution of electrothermal quench. Our findings
will have an impact in the design of ultra-high-field magnets for NMR or user
facilities, and possibly for other kinds of magnets, like those for fusion
energy.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [560] [Strategic Concealment of Environment Representations in Competitive Games](https://arxiv.org/abs/2509.05503)
*Yue Guan,Dipankar Maity,Panagiotis Tsiotras*

Main category: cs.MA

TL;DR: 玩家在竞技游戏中战略性地隐藏地图抽象。攻击者可以故意混淆环境的抽象来误导防御者。


<details>
  <summary>Details</summary>
Motivation: 研究玩家在竞技游戏中战略性地隐藏地图抽象的行为，以及防御者如何推断和利用攻击者使用的抽象。

Method: 将玩家间的交互建模为贝叶斯博弈，提出一种双线性规划方法来解决该博弈，该方法集成了贝叶斯推理、战略规划和信念操纵。

Result: 攻击者可以通过塑造防御者的信念来诱导次优的防御者障碍物配置，从而获得战略优势。

Conclusion: 有目的的抽象隐藏自然地从该模型中出现，是一种提高攻击者性能的方法。

Abstract: This paper investigates the strategic concealment of map abstractions used by
the players in competitive games. We consider a defense scenario in which one
player (the Defender) seeks to infer and exploit the abstraction used by the
other player (the Attacker). The interaction between the two players is modeled
as a Bayesian game: the Defender selects a barrier configuration, i.e., a
placement of obstacles that can obstruct the Attacker's movement, based on its
belief about the Attacker's abstraction, while the Attacker chooses a
trajectory that may intentionally obfuscate its own abstraction of the
environment to mislead the Defender. We show that purposeful abstraction
concealment naturally emerges from this formulation as a means of improving the
Attacker's performance. To solve the game, we propose a bilinear programming
approach that integrates Bayesian inference, strategic planning, and belief
manipulation. Simulations demonstrate that, by shaping the Defender's belief,
the Attacker can induce suboptimal Defender barrier placement, thereby gaining
a strategic advantage.

</details>


### [561] [Systematic Evaluation of Multi-modal Approaches to Complex Player Profile Classification](https://arxiv.org/abs/2509.05624)
*Jason Starace,Terence Soule*

Main category: cs.MA

TL;DR: 该研究评估了在文本RPG游戏中，结合行为遥测和语义上下文的多模态分类方法，以支持36种玩家画像，相比仅使用行为数据的传统聚类方法，准确率从10%提升至25%，尤其在非中性玩家画像上表现更佳，证明了多模态数据在玩家建模中的潜力，并指出仅靠非对话数据难以捕捉玩家意图，建议设计者采用对话交互以实现更精准的个性化适应。


<details>
  <summary>Details</summary>
Motivation: 现有自适应游戏模型因使用简化的玩家分类体系（5-10类）而无法充分捕捉玩家的多样性。传统的行为聚类方法无法区分行为相似但动机不同的玩家。因此，有必要研究更精细的玩家分类方法，以支持更细致的游戏适应性。

Method: 本研究系统地评估了大规模多模态分类方法，结合了行为遥测数据（动作序列）和语义上下文信息（文本描述），以支持36种玩家画像。研究使用了来自AI控制的文本RPG游戏的19,413个游戏会话数据。研究比较了仅基于行为数据的基线模型和整合了动作序列与语义描述的多模态方法（特别是多模态LSTM）。

Result: 传统聚类方法在36分类任务上的准确率仅为10%，存在语义混淆问题（相反动作产生相同特征）。结合了动作序列和文本描述的多模态LSTM模型将准确率提高到21%。对行为复杂度的分析显示，非中性玩家画像的准确率达到42%（比随机高15倍），而中性玩家画像的准确率下降到25%（比随机高9倍）。研究发现，即使是相同的动作（如“帮助商人”），也无法区分玩家是中性还是策略性等待。

Conclusion: 仅靠行为数据在36分类任务上的准确率约为10%，而多模态融合可将准确率提升至25%。即使是多模态模型，在没有对话交互的情况下，也难以完全捕捉玩家的真实意图（例如，区分中性玩家和策略性玩家）。研究结果表明，基于性格的适应性设计需要对话交互，而预设选项无法完全捕捉玩家意图。本研究在大规模（36分类）上的评估为构建能更好理解玩家的自适应游戏提供了指导和基准。

Abstract: Modern adaptive games require nuanced player understanding, yet most models
use simplified 5-10 category taxonomies that fail to capture diversity.
Behavioral clustering cannot distinguish players with different motivations who
act similarly. We present a systematic evaluation of multi-modal classification
at scale, combining behavioral telemetry with semantic context to support 36
player profiles. Using 19,413 gameplay sessions from an AI-controlled
text-based RPG, we compared behavioral-only baselines with multi-modal
approaches that integrate action sequences and semantic descriptions.
Traditional clustering achieved only 10% accuracy for 36-category
classification, limited by semantic conflation where opposite actions produced
identical features. Our multi-modal LSTM processing action-text pairs improved
accuracy to 21%, showing both potential and limits of non-conversational data.
Analysis by behavioral complexity revealed that non-neutral profiles reached
42% accuracy (15x above random), while neutral profiles dropped to 25% (9x
above random). Identical actions such as "help the merchant" cannot reveal
whether a player is neutral or strategically waiting. Without access to
reasoning, even multi-modal models struggle, though above-baseline results
confirm a meaningful signal. Since prediction beyond 20 categories remains
unexplored, our findings establish benchmarks for complex player modeling.
Behavioral data alone plateaus near 10% for 36 categories, while multi-modal
integration enables 25%. For designers, this shows that personality-based
adaptation requires conversational interaction, as predefined choices cannot
capture intent. Our evaluation at 36-category scale offers guidance for
building adaptive games that better understand their players.

</details>


### [562] [Orchestrator: Active Inference for Multi-Agent Systems in Long-Horizon Tasks](https://arxiv.org/abs/2509.05651)
*Lukas Beckenbauer,Johannes-Lucas Loewe,Ge Zheng,Alexandra Brintrup*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Complex, non-linear tasks challenge LLM-enhanced multi-agent systems (MAS)
due to partial observability and suboptimal coordination. We propose
Orchestrator, a novel MAS framework that leverages attention-inspired
self-emergent coordination and reflective benchmarking to optimize global task
performance. Orchestrator introduces a monitoring mechanism to track
agent-environment dynamics, using active inference benchmarks to optimize
system behavior. By tracking agent-to-agent and agent-to-environment
interaction, Orchestrator mitigates the effects of partial observability and
enables agents to approximate global task solutions more efficiently. We
evaluate the framework on a series of maze puzzles of increasing complexity,
demonstrating its effectiveness in enhancing coordination and performance in
dynamic, non-linear environments with long-horizon objectives.

</details>


### [563] [MAPF-HD: Multi-Agent Path Finding in High-Density Environments](https://arxiv.org/abs/2509.06374)
*Hiroya Makino,Seigo Ito*

Main category: cs.MA

TL;DR: PHANS是一种解决高密度多智能体路径寻找(MAPF-HD)问题的新方法，通过分阶段的空置节点交换来优化路径，解决了传统ILP方法计算耗时的问题，能在几秒到几十秒内处理大型环境。


<details>
  <summary>Details</summary>
Motivation: 提高仓库等高密度环境中智能体的空间利用率，解决传统MAPF方法在高密度环境下计算耗时的问题。

Method: 提出了一种名为PHANS（分阶段的空置节点交换）的新方法，采用启发式方法逐步交换智能体与空置节点的位置。

Result: PHANS方法能在几秒到几十秒内解决包含700多个单元的大型环境中的MAPF-HD问题，相比之下，基于ILP的方法在100个单元的小型环境中就需要几十到几百秒。

Conclusion: PHANS方法解决了MAPF-HD问题，能够高效地处理大规模应用，如仓库物流、交通管理和人群控制。

Abstract: Multi-agent path finding (MAPF) involves planning efficient paths for
multiple agents to move simultaneously while avoiding collisions. In typical
warehouse environments, agents are often sparsely distributed along aisles.
However, increasing the agent density can improve space efficiency. When the
agent density is high, we must optimize the paths not only for goal-assigned
agents but also for those obstructing them. This study proposes a novel MAPF
framework for high-density environments (MAPF-HD). Several studies have
explored MAPF in similar settings using integer linear programming (ILP).
However, ILP-based methods require substantial computation time to optimize all
agent paths simultaneously. Even in small grid-based environments with fewer
than $100$ cells, these computations can incur tens to hundreds of seconds.
These high computational costs render these methods impractical for large-scale
applications such as automated warehouses and valet parking. To address these
limitations, we introduce the phased null-agent swapping (PHANS) method. PHANS
employs a heuristic approach to incrementally swap positions between agents and
empty vertices. This method solves the MAPF-HD problem within seconds to tens
of seconds, even in large environments containing more than $700$ cells. The
proposed method can potentially improve efficiency in various real-world
applications such as warehouse logistics, traffic management, or crowd control.
Code is available at https://github.com/ToyotaCRDL/MAPF-in-High-Density-Envs.

</details>


### [564] [HECATE: An ECS-based Framework for Teaching and Developing Multi-Agent Systems](https://arxiv.org/abs/2509.06431)
*Arthur Casals,Anarosa A. F. Brandão*

Main category: cs.MA

TL;DR: HECATE是一个基于实体-组件-系统(ECS)架构模式的新框架，它利用数据驱动设计来实现多代理系统(MAS)。该框架旨在弥合分布式系统工程与MAS开发之间的差距，从而简化MAS开发过程，并支持不同的代理模型。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于简化多代理系统(MAS)的开发，并将其与分布式系统(DS)工程相结合。通过采用实体-组件-系统(ECS)架构模式和数据驱动设计，HECATE旨在减少对专门的MAS知识的需求，并利用熟悉的DS模式和标准。

Method: HECATE框架采用实体-组件-系统(ECS)架构模式，并利用数据驱动设计来实现多代理系统。该方法将MAS从分布式系统的角度进行工程化，并将代理概念直接整合到DS领域中。

Result: HECATE框架通过利用数据驱动设计和ECS模式，简化了MAS开发，减少了对特定MAS知识的需求，并能够支持不同的代理模型。

Conclusion: HECATE框架成功地将分布式系统工程与多代理系统开发相结合，通过ECS架构模式和数据驱动设计简化了MAS的开发过程。

Abstract: This paper introduces HECATE, a novel framework based on the
Entity-Component-System (ECS) architectural pattern that bridges the gap
between distributed systems engineering and MAS development. HECATE is built
using the Entity-Component-System architectural pattern, leveraging
data-oriented design to implement multiagent systems. This approach involves
engineering multiagent systems (MAS) from a distributed systems (DS)
perspective, integrating agent concepts directly into the DS domain. This
approach simplifies MAS development by (i) reducing the need for specialized
agent knowledge and (ii) leveraging familiar DS patterns and standards to
minimize the agent-specific knowledge required for engineering MAS. We present
the framework's architecture, core components, and implementation approach,
demonstrating how it supports different agent models.

</details>


### [565] [Nanobot Algorithms for Treatment of Diffuse Cancer](https://arxiv.org/abs/2509.06893)
*Noble Harasha,Nancy Lynch*

Main category: cs.MA

TL;DR: 纳机器人可以通过在癌细胞周围释放药物来治疗弥散性癌症，但需要复杂的协调来根据癌症“需求”分配药物。我们提出了三种算法（KM、KMA 和 KMAR），并进行了模拟，以评估它们在不同癌症模式下的表现。KMAR 算法在所有情况下都表现出鲁棒性和适应性，并取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 为了在癌症部位分配药物，研究了纳机器人（或“纳米机器人”）的协调问题。

Method: 提出了一种纳机器人行为及其胶体环境的数学模型，包括基于化学梯度搜索的运动模型。并提出了三种算法：KM（仅使用自然化学信号）、KMA（使用放大了的信号）和 KMAR（使用可抵抗的信号来避免过度治疗的区域）。

Result: KM 算法在自然信号较弱时治疗效果不佳。KMA 算法提高了治疗速度，但降低了成功率，除非癌症模式是集中的。KMAR 算法在所有癌症模式下都表现出色，具有鲁棒性和适应性。

Conclusion: KMAR 算法在治疗弥散性癌症方面比 KM 和 KMA 算法更有效、更鲁棒。

Abstract: Motile nanosized particles, or "nanobots", promise more effective and less
toxic targeted drug delivery because of their unique scale and precision. We
consider the case in which the cancer is "diffuse", dispersed such that there
are multiple distinct cancer sites. We investigate the problem of a swarm of
nanobots locating these sites and treating them by dropping drug payloads at
the sites. To improve the success of the treatment, the drug payloads must be
allocated between sites according to their "demands"; this requires extra
nanobot coordination. We present a mathematical model of the behavior of the
nanobot agents and of their colloidal environment. This includes a movement
model for agents based upon experimental findings from actual nanoparticles in
which bots noisily ascend and descend chemical gradients. We present three
algorithms: The first algorithm, called KM, is the most representative of
reality, with agents simply following naturally existing chemical signals that
surround each cancer site. The second algorithm, KMA, includes an additional
chemical payload which amplifies the existing natural signals. The third
algorithm, KMAR, includes another additional chemical payload which counteracts
the other signals, instead inducing negative chemotaxis in agents such that
they are repelled from sites that are already sufficiently treated. We present
simulation results for all algorithms across different types of cancer
arrangements. For KM, we show that the treatment is generally successful unless
the natural chemical signals are weak, in which case the treatment progresses
too slowly. For KMA, we demonstrate a significant improvement in treatment
speed but a drop in eventual success, except for concentrated cancer patterns.
For KMAR, our results show great performance across all types of cancer
patterns, demonstrating robustness and adaptability.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [566] [Subsequence Covers of Words](https://arxiv.org/abs/2509.05827)
*Panagiotis Charalampopoulos,Solon P. Pissis,Jakub Radoszewski,Wojciech Rytter,Tomasz Waleń,Wiktor Zuba*

Main category: cs.DS

TL;DR: 引入了新的词语覆盖类型“子序列覆盖”（s-cover），并提供了相关的算法和界限。


<details>
  <summary>Details</summary>
Motivation: 研究子序列覆盖（s-cover）作为一种新的词语覆盖类型，并探索其计算复杂度。

Method: 提出并实现了一个线性时间算法来测试候选词是否为给定词的s-cover，以及一个寻找最短s-cover的算法。同时，还对不包含真s-cover的词（s-primitive）的长度进行了界定。

Result: 设计了一个线性时间算法，用于检测给定词C是否为S的s-cover。还提出了一个寻找最短s-cover的算法，在常数规模字母表的情况下，该算法的运行时间也是线性的。此外，还给出了最长s-primitive词长度的指数级上界和下界，并改进了之前的上界。

Conclusion: 子序列覆盖（s-cover）是一种新的词语覆盖形式，尽管计算上比标准覆盖更难，但比shuffle powers容易。本文提出的算法在特定条件下能实现线性时间复杂度。最长s-primitive词长度的界限得到了改进，表明其长度与字母表大小呈指数关系。

Abstract: We introduce subsequence covers (s-covers, in short), a new type of covers of
a word. A word $C$ is an s-cover of a word $S$ if the occurrences of $C$ in $S$
as subsequences cover all the positions in $S$.
  The s-covers seem to be computationally much harder than standard covers of
words (cf. Apostolico et al., Inf. Process. Lett. 1991), but, on the other
hand, much easier than the related shuffle powers (Warmuth and Haussler, J.
Comput. Syst. Sci. 1984).
  We give a linear-time algorithm for testing if a candidate word $C$ is an
s-cover of a word $S$ over a polynomially-bounded integer alphabet. We also
give an algorithm for finding a shortest s-cover of a word $S$, which in the
case of a constant-sized alphabet, also runs in linear time.
  The words without proper s-cover are called s-primitive. We complement our
algorithmic results with explicit lower and an upper bound on the length of a
longest s-primitive word. Both bounds are exponential in the size of the
alphabet. The upper bound presented here improves the bound given in the
conference version of this paper [SPIRE 2022].

</details>


### [567] [Generalized Graph Packing Problems Parameterized by Treewidth](https://arxiv.org/abs/2509.06091)
*Barış Can Esmer,Dániel Marx*

Main category: cs.DS

TL;DR: 该论文研究了在界树宽度图上寻找H的顶点不相交副本的最大数量（H-Packing）以及覆盖图中每个顶点恰好一次的副本集（H-Partition）。


<details>
  <summary>Details</summary>
Motivation: 研究H-Packing和H-Partition问题及其推广在界树宽度图上的情况。

Method: 对于H为团（clique）的情况，考虑了每个顶点最多被使用c次的推广，并给出了上下界。对于H不是团的情况，研究了运行时间可能不是单指数增长的依赖关系。

Result: 对于H为团且每个顶点最多使用c次的情况，给出了运行时间为(c+1)^tw * n^O(1)的上下界。对于H不是团的情况，证明了在ETH假设下，H-Partition没有2^o(tw log tw) * n^O(1)的算法。

Conclusion: 在界树宽度图上，H-Packing和H-Partition问题的复杂性取决于H的结构以及顶点使用次数的限制，对于团类图，复杂性与c和tw相关；对于非团类图，复杂性可能更高。

Abstract: $H$-Packing is the problem of finding a maximum number of vertex-disjoint
copies of $H$ in a given graph $G$. $H$-Partition is the special case of
finding a set of vertex-disjoint copies that cover each vertex of $G$ exactly
once. Our goal is to study these problems and some generalizations on
bounded-treewidth graphs. The case of $H$ being a triangle is well understood:
given a tree decomposition of $G$ having treewidth $tw$, the $K_3$-Packing
problem can be solved in time $2^{tw} \cdot n^{O(1)}$, while Lokshtanov et
al.~[{\it ACM Transactions on Algorithms} 2018] showed, under the Strong
Exponential-Time Hypothesis (SETH), that there is no $(2-\epsilon)^{tw}\cdot
n^{O(1)}$ algorithm for any $\epsilon>0$ even for $K_3$-Partition. Similar
results can be obtained for any other clique $K_d$ for $d\ge 3$. We provide
generalizations in two directions:
  - We consider a generalization of the problem where every vertex can be used
at most $c$ times for some $c\ge 1$. When $H$ is any clique $K_d$ with $d\ge
3$, then we give upper and lower bounds showing that the optimal running time
increases to $(c+1)^{tw}\cdot n^{O(1)}$. We consider two variants depending on
whether a copy of $H$ can be used multiple times in the packing.
  - If $H$ is not a clique, then the dependence of the running time on
treewidth may not be even single exponential. Specifically, we show that if $H$
is any fixed graph where not every 2-connected component is a clique, then
there is no $2^{o({tw}\log {tw})}\cdot n^{O(1)}$ algorithm for
\textsc{$H$-Partition}, assuming the Exponential-Time Hypothesis (ETH).

</details>


### [568] [Parameterized Algorithms for Computing Pareto Sets](https://arxiv.org/abs/2509.06124)
*Joshua Könen,Heiko Röglin,Tarek Stuck*

Main category: cs.DS

TL;DR: 该论文提出了一种利用树分解动态规划来计算多目标优化问题（包括多标准s-t割、地图集中的多目标多边形聚合、多目标最小生成树和多目标TSP）的Pareto集的新方法，并进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 研究是否可以将树分解动态规划技术应用于计算多目标优化问题的Pareto集。

Method: 推导了计算多标准s-t割的Pareto集的算法，并将其应用于地图集中的多目标多边形聚合问题，还将其应用于多目标最小生成树和多目标TSP问题。设计了一种任务特定的数据结构，并结合改进策略和启发式方法进行实验评估。

Result: 成功计算了多目标优化问题的Pareto集，并对地图集中的多目标多边形聚合问题进行了实验评估，在最大树宽为22的情况下，在合理时间内解决了实例。

Conclusion: 所提出的利用树分解动态规划的方法能够有效地计算多目标优化问题的Pareto集，并且通过优化的数据结构和算法，可以处理具有一定复杂度的实际问题。

Abstract: Dynamic programming over tree decompositions is a common technique in
parameterized algorithms. In this paper, we study whether this technique can
also be applied to compute Pareto sets of multiobjective optimization problems.
We first derive an algorithm to compute the Pareto set for the multicriteria
s-t cut problem and show how this result can be applied to a polygon
aggregation problem arising in cartography that has recently been introduced by
Rottmann et al. (GIScience 2021). We also show how to apply these techniques to
also compute the Pareto set of the multiobjective minimum spanning tree problem
and for the multiobjective TSP. The running time of our algorithms is
$O(f(w)\cdot\mathrm{poly}(n,p_{\text{max}}))$, where $f$ is some function in
the treewidth $w$, $n$ is the input size, and $p_{\text{max}}$ is an upper
bound on the size of the Pareto sets of the subproblems that occur in the
dynamic program. Finally, we present an experimental evaluation of computing
Pareto sets on real-world instances of polygon aggregation problems. For this
matter we devised a task-specific data structure that allows for efficient
storage and modification of large sets of Pareto-optimal solutions. Throughout
the implementation process, we incorporated several improved strategies and
heuristics that significantly reduced both runtime and memory usage, enabling
us to solve instances with treewidth of up to 22 within reasonable amount of
time. Moreover, we conducted a preprocessing study to compare different tree
decompositions in terms of their estimated overall runtime.

</details>


### [569] [Efficient Catalytic Graph Algorithms](https://arxiv.org/abs/2509.06209)
*James Cook,Edward Pyne*

Main category: cs.DS

TL;DR: 本论文提出了用于图问题的快速、简单且可实现的催化对数空间算法。


<details>
  <summary>Details</summary>
Motivation: 提供解决 s→t 连通性和模拟随机游走问题的催化对数空间算法，并给出明确的运行时间界限。

Method: 对于 s→t 连通性，使用随机化催化算法，时间复杂度为 O(nm)，以及确定性催化算法，时间复杂度为 O(n^3m)，算法均使用每个顶点一个寄存器，并通过边“推送”值。对于模拟随机游走，使用确定性催化算法，时间复杂度为 O(m T^2 / ε)，算法使用每个顶点一个寄存器，并通过增加寄存器值来确保重复访问遵循不同的出边。

Result: 提出了 s→t 连通性的随机化和确定性催化算法，以及模拟随机游走的催化算法，并给出了明确的时间复杂度。

Conclusion: 本研究提出的算法在效率和实现方面优于先前算法，为催化对数空间算法在图问题上的应用提供了新的进展。

Abstract: We give fast, simple, and implementable catalytic logspace algorithms for two
fundamental graph problems.
  First, a randomized catalytic algorithm for $s\to t$ connectivity running in
$\widetilde{O}(nm)$ time, and a deterministic catalytic algorithm for the same
running in $\widetilde{O}(n^3 m)$ time. The former algorithm is the first
algorithmic use of randomization in $\mathsf{CL}$. The algorithm uses one
register per vertex and repeatedly ``pushes'' values along the edges in the
graph.
  Second, a deterministic catalytic algorithm for simulating random walks which
in $\widetilde{O}( m T^2 / \varepsilon )$ time estimates the probability a
$T$-step random walk ends at a given vertex within $\varepsilon$ additive
error. The algorithm uses one register for each vertex and increments it at
each visit to ensure repeated visits follow different outgoing edges.
  Prior catalytic algorithms for both problems did not have explicit runtime
bounds beyond being polynomial in $n$.

</details>


### [570] [Zero-Freeness is All You Need: A Weitz-Type FPTAS for the Entire Lee-Yang Zero-Free Region](https://arxiv.org/abs/2509.06623)
*Shuai Shao,Ke Shi*

Main category: cs.DS

TL;DR: We developed a Weitz-type FPTAS for the ferromagnetic Ising model within the Lee-Yang zero-free region, bypassing the need for the strong spatial mixing (SSM) property. Our method involves approximating an edge-deletion ratio using a truncated self-avoiding walk tree. We also introduced and proved a novel form of SSM for these ratios, termed local dependence of coefficients (LDC), which extends to the random cluster model on general graphs and establishes new SSM results for various models. This research suggests that both Weitz-type FPTAS and SSM can originate from zero-freeness, with SSM additionally requiring the combinatorial property of LDC.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a Weitz-type FPTAS for the ferromagnetic Ising model across the entire Lee-Yang zero-free region without relying on the strong spatial mixing (SSM) property, and to establish new SSM results for various models.

Method: The paper presents a Weitz-type FPTAS that approximates the partition function by expressing it as a telescoping product of ratios, approximating each ratio using a truncated self-avoiding walk tree. A key innovation is approximating an edge-deletion ratio instead of a vertex's marginal spin probability to avoid the SSM requirement. The authors also establish a novel local dependence of coefficients (LDC) property for these edge-deletion ratios, which implies SSM for the random cluster model and leads to new SSM results for other models.

Result: The algorithm provides a Weitz-type FPTAS for the ferromagnetic Ising model in the Lee-Yang zero-free region without needing SSM. A novel LDC property is proven for edge-deletion ratios, which implies SSM for the random cluster model on general graphs (beyond lattices) and yields new SSM results for a variety of models.

Conclusion: Both Weitz-type FPTASes and SSM can be derived from zero-freeness. However, while zero-freeness alone is sufficient for Weitz-type FPTASes, SSM additionally requires LDC, a combinatorial property that is independent of zero-freeness. This work establishes LDC for a variety of models and provides new SSM results.

Abstract: We present a Weitz-type FPTAS for the ferromagnetic Ising model across the
entire Lee-Yang zero-free region, without relying on the strong spatial mixing
(SSM) property. Our algorithm is Weitz-type for two reasons. First, it
expresses the partition function as a telescoping product of ratios, with the
key being to approximate each ratio. Second, it uses Weitz's self-avoiding walk
tree, and truncates it at logarithmic depth to give a good and efficient
approximation. The key difference from the standard Weitz algorithm is that we
approximate a carefully designed edge-deletion ratio instead of the marginal
probability of a vertex's spin, ensuring our algorithm does not require SSM.
  Furthermore, by establishing local dependence of coefficients (LDC), we
indeed prove a novel form of SSM for these edge-deletion ratios, which, in
turn, implies the standard SSM for the random cluster model. This is the first
SSM result for the random cluster model on general graphs, beyond lattices. We
prove LDC using a new division relation, and remarkably, such relations hold
quite universally. As a result, we establish LDC for a variety of models.
Combined with existing zero-freeness results for these models, we derive new
SSM results for them. Our work suggests that both Weitz-type FPTASes and SSM
can be derived from zero-freeness, while zero-freeness alone suffices for
Weitz-type FPTASes, SSM additionally requires LDC, a combinatorial property
independent of zero-freeness.

</details>


### [571] [The Steiner Shortest Path Tree Problem](https://arxiv.org/abs/2509.06789)
*Omer Asher,Yefim Dinitz,Shlomi Dolev,Li-on Raviv,Baruch Schieber*

Main category: cs.DS

TL;DR: 本文提出并研究了计算具有最少非终端节点的最短路径树的新问题，该问题可视为在给定源点下，跨越给定终端节点集合的最短路径树（SSPT），同时最小化树中包含的非终端节点的数量。该问题源于需要最短路径连接且希望通过减少中间节点来降低成本、复杂性或开销的应用。


<details>
  <summary>Details</summary>
Motivation: 该问题源于需要最短路径连接且希望通过减少中间节点来降低成本、复杂性或开销的应用。

Method: 研究了图的最短路径子图，并给出了SSPT到定向Steiner树（DST）的统一顶点加权变体（UVDST）的一种近似保持归约，从而得到SSPT的准多项式对数近似算法。对于一类受限图，提出了一种SSPT的多项式对数近似算法。

Result: SSPT问题是NP难的。DST的近似算法可以得到SSPT的准多项式对数近似算法。对于受限图，得到了SSPT的多项式对数近似算法。

Conclusion: SSPT问题是NP难的，但存在有效的近似算法。

Abstract: We introduce and study a novel problem of computing a shortest path tree with
a minimum number of non-terminals. It can be viewed as an (unweighted) Steiner
Shortest Path Tree (SSPT) that spans a given set of terminal vertices by
shortest paths from a given source while minimizing the number of nonterminal
vertices included in the tree. This problem is motivated by applications where
shortest-path connections from a source are essential, and where reducing the
number of intermediate vertices helps limit cost, complexity, or overhead. We
show that the SSPT problem is NP-hard. To approximate it, we introduce and
study the shortest path subgraph of a graph. Using it, we show an
approximation-preserving reduction of SSPT to the uniform vertex-weighted
variant of the Directed Steiner Tree (DST) problem, termed UVDST. Consequently,
the algorithm of [Grandoni et al., 2023] approximating DST implies a
quasi-polynomial polylog-approximation algorithm for SSPT. We present a
polynomial polylog-approximation algorithm for UVDST, and thus for SSPT, for a
restricted class of graphs.

</details>


### [572] [Engineering Select Support for Hybrid Bitvectors](https://arxiv.org/abs/2509.06900)
*Eric Chiu,Dominik Kempa*

Main category: cs.DS

TL;DR: 混合位向量被改进以同时支持 rank 和 select 查询，在速度和空间效率方面都表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的混合位向量实现只支持 rank 查询，限制了其在压缩数据结构（如小波树）中的应用。

Method: 提出了一种为混合位向量添加 select 查询支持的方法，并通过实验进行了评估。

Result: 所提出的方法使混合位向量在保持出色性能的同时，能够支持 select 查询，达到了现有最快和最节省空间的位向量的水平。

Conclusion: 通过为混合位向量添加 select 查询支持，可以显著扩展其应用范围，并提供优异的性能和空间效率。

Abstract: One of the central problems in the design of compressed data structures is
the efficient support for rank and select queries on bitvectors. These two
operations form the backbone of more complex data structures (such as wavelet
trees) used for the compact representation of texts, trees, graphs, or grids.
Their efficient implementation is one of the most frequently studied problems
in compressed data structures.
  One effective solution is the so-called hybrid bitvector implementation,
which partitions the input bitvector into blocks and adaptively selects an
encoding method, such as run-length, plain, or minority encoding, based on
local redundancy. Experiments have shown that hybrid bitvectors achieve
excellent all-around performance on repetitive and non-repetitive inputs.
  However, current implementations support only rank queries (i.e., counting
the number of ones up to a given position) and lack support for select queries.
This limitation significantly restricts their applicability. In this paper, we
propose a method to add support for select queries to hybrid bitvectors, and we
conduct an extensive set of experiments. Our results show that hybrid
bitvectors offer excellent performance, matching the speed of the fastest and
the space efficiency of the most compact existing bitvectors.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [573] [Spin-transport characteristics in a Si-based spin metal-oxide-semiconductor field-effect transistor (spin MOSFET): Bias dependence of the spin polarization in Si and magnetoresistance in spin-valve signals](https://arxiv.org/abs/2509.05384)
*Shoichi Sato,Masaaki Tanaka,Ryosho Nakane*

Main category: cond-mat.mes-hall

TL;DR: 本研究对自旋MOSFET的自旋输运特性进行了优化，实现了创纪录的电子自旋极化率P_S（50%）和磁性电阻比（MR，0.35%）。


<details>
  <summary>Details</summary>
Motivation: 优化自旋MOSFET器件性能，特别是电子自旋极化率P_S和磁性电阻比MR。

Method: 研究了自旋MOSFET的偏差电压依赖性，并改进了自旋输运模型，考虑了铁磁源/漏区中的电子分布和能带分布。

Result: 在4K温度下，观察到清晰的自旋阀信号和Hanle自旋进动信号，实现了高达50%的P_S和0.35%的MR。P_S和MR值是迄今为止自旋MOSFET的最高纪录。研究发现P_S仅由结电压V_J决定，而MR的关键参数具有不同的V_J依赖性，表明器件未完全发挥铁磁源/漏结的最大潜力。

Conclusion: 通过改进自旋输运模型和对器件的详细分析，深入理解了自旋MOSFET的器件物理和工程优化方向，以进一步提高MR。

Abstract: We have studied the spin transport characteristics of a spin
metal-oxide-semiconductor field-effect transistor (spin MOSFET), particularly
the bias voltage dependence of the electron spin polarization P_S in Si and the
magnetoresistance ratio MR in spin-valve signals, to optimize the device
performance. The spin MOSFET device has an 8-nm-thick p-Si channel with a back
gate (G) and ferromagnetic source / drain (S/D) junctions consisting of
Fe/Mg/MgO/SiOx/n+-Si. In addition to transistor characteristics with an on-off
ratio of 104, clear spin-valve signals and Hanle spin precession signals were
observed at 4 K in a wide range of the source-to-gate V_GS and source-to-drain
V_DS bias voltages. We achieved a high P_S of 50% and a high MR of 0.35% as the
maximum values in their single-peaked curves plotted as a function of the
junction voltage V_J, mainly because the ferromagnetic S/D junction can
generate high P_S and the spin diffusion length is very long in the Si
inversion channel. These P_S and MR values are the highest ever reported in
spin-MOSFETs. Our spin transport model for our spin MOSFET structure was
improved in this study by taking into account the electron distribution and
band profile of the n+-Si regions in the ferromagnetic S/D junctions, which
enables the accurate estimation of P_S. Detailed analyses with various V_GS and
V_J clarified that P_S is determined only by V_J. Our analyses also revealed
that the main parameters for determining MR, such as P_S and the
resistance-area products of the S/D ferromagnetic junctions, have different V_J
dependences, leading to the finding that the present device does not exploit
the full potential of the ferromagnetic S/D junctions to maximize MR. Based on
the results, we discuss the device physics and engineering for further
enhancement of MR, with a focus on the electrical and spin-related properties
of the ferromagnetic S/D junctions.

</details>


### [574] [Wilson-Loop-Ideal Bands and General Idealization](https://arxiv.org/abs/2509.05410)
*Jiabin Yu,Biao Lian,Shinsei Ryu*

Main category: cond-mat.mes-hall

TL;DR: 量子几何下界由威尔逊回路缠绕数决定。文章提出了威尔逊回路-理想带的定义，该定义包含已知的陈-理想和欧拉-理想带，并扩展到Kane-Mele $Z_2$-理想带。特别地，文章证明了具有非奇异非阿贝尔贝里曲率的孤立的两个 $Z_2$-理想带可以有效等同于两个解耦的陈-理想带，即使没有全局量子数（如自旋）。这使得可以直接构建分数量子绝缘体波函数。文章还提出了一个通用的构造单调流框架，通过带混合从非理想带实现威尔逊回路-理想态。将该框架应用于3.89°扭曲双层MoTe$_{2}$和莫尔 Réponses 模型，数值上分别发现了陈-理想和$Z_2$-理想态，并给出了量子度量的相对误差。


<details>
  <summary>Details</summary>
Motivation: 研究量子几何的下界，并提出新的理想带定义及其构造方法，以期在凝聚态物理中发现新的关联现象。

Method: 定义了威尔逊回路-理想带，该定义自然地包含了已知的Chern-ideal和Euler-ideal带，并扩展到Kane-Mele $Z_2$-ideal带。提出了一种通用的构造单调流的框架，通过带混合从非理想带实现威尔逊回路-理想态。将该框架应用于3.89°扭曲双层MoTe$_{2}$和莫尔 Réponses 模型。

Result: 发现了Chern-ideal和$Z_2$-ideal状态，并给出了量子度量的相对误差低于5x10^{-3}。

Conclusion: 威尔逊回路-理想带的通用定义和威尔逊回路-理想态的通用构造过程为未来研究新颖的关联物理提供了坚实的基础。

Abstract: Quantum geometry is universally bounded from below by Wilson-loop windings.
In this work, we define an isolated set of bands to be Wilson-loop-ideal, if
their quantum metric saturates the Wilson-loop lower bound. The definition
naturally incorporates the known Chern-ideal and Euler-ideal bands, and allows
us to define other types of ideal bands, such as Kane-Mele $Z_2$-ideal bands.
In particular, we find that an isolated set of two $Z_2$-ideal bands with
non-singular nonabelian Berry curvature always admits a Chern-ideal gauge
(i.e., effectively behaving as two decoupled Chern-ideal bands), even in the
absence of any global good quantum number (such as spin). This enables the
direct construction of fractional topological insulator wavefunctions. We
further propose a general framework of constructing monotonic flows that
achieve Wilson-loop-ideal states starting from non-ideal bands through band
mixing, where Wilson-loop-ideal states are not energy eigenstates but have
smooth projectors similar to isolated bands. We apply the constructed flows to
the realistic model of $3.89^\circ$ twisted bilayer MoTe$_2$ and a moir\'e
Rashba model, and numerically find Chern-ideal and $Z_2$-ideal states,
respectively, with relative error in the integrated quantum metric below
$5\times 10^{-3}$. Our general definition of Wilson-loop-ideal bands and
general procedure of constructing Wilson-loop-ideal states provide a solid
basis for future study of novel correlated physics.

</details>


### [575] [Giant Molecular Toroidal Moment Amenable to Direct Observation in a Fe$_{10}$Dy$_{10}$ Ring](https://arxiv.org/abs/2509.05424)
*Alessandro Soncini,Kieran Hymas,Jonas Braun,Yannik F. Schneider,Simone Calvello,Amer Baniodeh,Yanhua Lan,Wolfgang Wernsdorfer,Marco Affronte,Christopher E. Anson,Annie K. Powell*

Main category: cond-mat.mes-hall

TL;DR: Fe$_{10}$Dy$_{10}$分子环在单分子环发展中具有前所未有的扭矩响应，可以通过实验检测和操作。


<details>
  <summary>Details</summary>
Motivation: 原子自旋和轨道电流产生的磁涡流（扭矩矩）在单分子环（SMT）中具有磁和电偶极对称性，可用于自旋控制和开发稳健的量子比特。然而，在Dy$_3$ SMT中，扭矩矩难以检测和控制。更大的分子环可以提供增强的扭矩响应，以便直接观察和操作。因此，本研究旨在研究Fe$_{10}$Dy$_{10}$分子环的SMT特性，以期实现扭矩矩的直接观察和操作。

Method: 通过从头参数化的传递矩阵方法对Fe$_{10}$Dy$_{10}$分子环的SMT特性进行建模，并与实验结果进行比较。引入了摩尔扭矩磁化率$\xi$作为衡量在磁场（具有微小非零卷曲）作用下诱导的SMT有限温度扭矩极化的热力学线性响应函数。

Result: Fe$_{10}$Dy$_{10}$分子环表现出前所未有的扭矩激发，其能量色散跨越了约620亿维的扭矩空间。从头参数化的传递矩阵方法在模拟这些特性方面与实验结果具有优异的一致性。对Fe$_{10}$Dy$_{10}$的摩尔扭矩磁化率$\xi$的直接计算表明，在有限温度下存在显著的基态扭矩极化。

Conclusion: Fe$_{10}$Dy$_{10}$分子环的SMT特性，特别是其显著的有限温度基态扭矩极化，可以通过具有微小非零卷曲的磁场（例如，使用聚焦的飞秒激光脉冲）进行实验检测。这为分子扭矩矩的直接观察和操作铺平了道路。

Abstract: In single molecule toroics (SMTs) atomic spins and orbital currents generate
magnetic vortices known as toroidal moments $\boldsymbol{\tau}$, endowed with
both magnetic and electric dipole symmetries, which can enable spin control via
magnetoelectric effects as well as the development of robust qubits. In the
archetypal Dy$_3$ SMT, $\boldsymbol{\tau}$ is challenging to detect and
control. Larger molecular rings can offer an enhanced toroidal response
amenable to direct observation and manipulation. Here we report SMT properties
for the $3d$-$4f$ icosanuclear molecular ring Fe$_{10}$Dy$_{10}$, displaying
toroidal excitations of unprecedented magnitude and energy dispersion spanning
a $\sim$62 billion dimensional toroidal space. We show these properties can be
modeled using an ab initio-parameterised transfer matrix approach yielding
excellent agreement with experiments. To assess the bulk toroidal polarization
attainable in this system, we introduce the molar toroidal susceptibility
$\xi$, a thermodynamic linear response function measuring the SMT
finite-temperature toroidal polarization induced by a magnetic field with a
small non-vanishing curl. Direct calculation of $\xi$ for Fe$_{10}$Dy$_{10}$
reveals a significant finite-temperature ground state toroidal polarization
which should be amenable to experimental detection via spatially-focused
magnetic field curls, as attainable e.g. using focused femtosecond laser
pulses. Our findings could thus pave the way for direct observation and
manipulation of molecular toroidal moments.

</details>


### [576] [Quantum anomalous Hall phases in gated rhombohedral graphene](https://arxiv.org/abs/2509.05439)
*Matthew Frazier,Guillaume Bal*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了具有任意层数的宏观狄拉克算子耦合系统，该系统可应用于菱形石墨烯（RHG）的宏观自旋和谷极化模型，以及弗洛凯拓扑绝缘体的副本模型。研究分类了所有与该模型兼容的量子反常霍尔相，并证明了体相和手征边缘态之间的体边对应关系，其中手征边缘态携带量子化的反常霍尔电荷。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究一种耦合狄拉克算子系统，该系统在宏观自旋和谷极化菱形石墨烯（RHG）以及弗洛凯拓扑绝缘体副本模型中具有潜在应用价值。

Method: 本文首先对模型进行分类，识别所有可能的量子反常霍尔相。然后，证明了体相和手征边缘态之间的体边对应关系，其中手征边缘态携带量子化的反常霍尔电荷。在特定条件下（位移场远小于层间耦合），恢复了已知的、电荷由石墨烯层数决定的相。随着位移场的增大，识别了所有可能的拓扑相变及其对应的量子化手征边缘电荷。最后，通过数值模拟验证了理论发现。

Result: 在位移场远小于层间耦合的条件下，恢复了电荷由石墨烯层数决定的已知相。随着位移场的增大，识别了所有可能的拓扑相变，并确定了相应的量子化手征边缘电荷。数值模拟结果与理论分析一致。

Conclusion: 本文成功地分类了与所提出的狄拉克算子耦合系统兼容的所有量子反常霍尔相，并证明了体边对应关系。研究结果揭示了在RHG模型中，位移场的变化如何导致拓扑相变和边缘电荷的变化，并通过数值模拟得到了验证。

Abstract: We consider a coupled system of Dirac operators that finds applications as a
macroscopic model of spin and valley polarized gated rhombohedral graphene
(RHG) with an arbitrary number of layers as well as in replica models of
Floquet topological insulators. We classify all quantum anomalous Hall phases
that are compatible with the model and show that a bulk-edge correspondence
between bulk phases and chiral edge states carrying a quantized anomalous Hall
charge applies. When the displacement field is sufficiently small compared to
the inter-layer coupling in the RHG application, we retrieve the known phases
where the charge is given by the number of graphene layers. When the
displacement field increases, we identify all possible topological phase
transitions and corresponding quantized chiral edge charges. Numerical
simulations confirm the theoretical findings.

</details>


### [577] [Gate-Tunable Ambipolar Josephson Current in a Topological Insulator](https://arxiv.org/abs/2509.05587)
*Bomin Zhang,Xiaoda Liu,Junjie Qi,Ling-Jie Zhou,Deyi Zhuo,Han Tay,Hongtao Rong,Annie G. Wang,Zhiyuan Xi,Chao-Xing Liu,Chui-Zhen Chen,Cui-Zu Chang*

Main category: cond-mat.mes-hall

TL;DR: 在拓扑绝缘体(TI)中，近邻诱导的超导性提供了实现拓扑超导性和Majorana物理学的有前景的平台。然而，在TI中，约瑟夫森效应通常在传输主要由体传导沟道或单极表面态主导的区域中观察到。本研究展示了基于分子束外延(MBE)生长的块体绝缘(Bi,Sb)2Te3薄膜的横向约瑟夫森结(JJ)器件中，由栅极调制的双极性约瑟夫森电流。


<details>
  <summary>Details</summary>
Motivation: 在拓扑绝缘体(TI)中，近邻诱导的超导性提供了实现拓扑超导性和Majorana物理学的有前景的平台。然而，在TI中，约瑟夫森效应通常在传输主要由体传导沟道或单极表面态主导的区域中观察到。

Method: 制备了基于块体绝缘(Bi,Sb)2Te3薄膜的横向约瑟夫森结(JJ)器件，并进行了栅极可调的双极性约瑟夫森电流实验，以及数值模拟。

Result: 对于较薄的薄膜，超电流表现出明显的栅极可调双极性行为，并且在化学势接近狄拉克点时显著被抑制，但仍持续存在。相比之下，较厚的薄膜表现出较弱的双极性响应。此外，我们发现当化学势调谐到接近狄拉克点时，在两种厚度范围内，超电流对外部磁场的抵抗力都显著降低。数值模拟表明了TI JJ器件的双极性行为，并将较厚TI薄膜中观察到的不对称超电流归因于狄拉克表面态和体传导沟道的共存。

Conclusion: 展示了MBE生长的TI薄膜中栅极可调的双极性约瑟夫森传输，为实现由狄拉克表面态介导的拓扑超导性铺平了道路，并为未来探索电可调Majorana模式奠定了基础。

Abstract: Dirac surface states in a topological insulator (TI) with proximity-induced
superconductivity offer a promising platform for realizing topological
superconductivity and Majorana physics. However, in TIs, the Josephson effect
is usually observed in regimes where transport is dominated by either
substantial bulk conduction channels or unipolar surface states. In this work,
we demonstrate gate-tunable ambipolar Josephson current in lateral Josephson
junction (JJ) devices based on bulk-insulating (Bi,Sb)2Te3 thin films grown by
molecular beam epitaxy (MBE). For thinner films, the supercurrent exhibits
pronounced gate-tunable ambipolar behavior and is significantly suppressed as
the chemical potential approaches the Dirac point, yet persists across it. In
contrast, thicker films exhibit a much weaker ambipolar response. Moreover, we
find that the supercurrent becomes significantly less resilient to external
magnetic fields when the chemical potential is tuned near the Dirac point in
both thickness regimes. Our numerical simulations demonstrate the ambipolar
behavior of these TI JJ devices and attribute the asymmetric supercurrent
observed in thicker TI films to the coexistence of Dirac surface states and
bulk conduction channels. The demonstration of gate-tunable ambipolar Josephson
transport in MBE-grown TI films paves the way for realizing
Dirac-surface-state-mediated topological superconductivity and establishes a
foundation for future exploration of electrically tunable Majorana modes.

</details>


### [578] [Orbital Hybridization-Induced Ising-Type Superconductivity in a Confined Gallium Layer](https://arxiv.org/abs/2509.05598)
*Hemian Yi,Yunzhe Liu,Chengye Dong,Yiheng Yang,Zi-Jie Yan,Zihao Wang,Lingjie Zhou,Dingsong Wu,Houke Chen,Stephen Paolini,Bing Xia,Bomin Zhang,Xiaoda Liu,Hongtao Rong,Annie G. Wang,Saswata Mandal,Kaijie Yang,Benjamin N. Katz,Lunhui Hu,Jieyi Liu,Tien-Lin Lee,Vincent H. Crespi,Yuanxi Wang,Yulin Chen,Joshua A. Robinson,Chao-Xing Liu,Cui-Zu Chang*

Main category: cond-mat.mes-hall

TL;DR: 通过在石墨烯/三层镓/SiC异质结构中利用界面杂化效应，实现了由原子轨道杂化驱动的Ising型超导电性，其上临界磁场远超泡利顺磁极限。


<details>
  <summary>Details</summary>
Motivation: 量子限制和界面杂化效应在低维超导体中可以重塑库珀对波函数并诱导非常规超导电性。

Method: 采用无等离子体、碳缓冲层辅助的限制外延方法，合成了石墨烯/三层镓/SiC异质结构。

Result: 在限制的轻元素镓层中，实现了由镓层和SiC衬底之间的原子轨道杂化驱动的界面Ising型超导电性。薄膜的平面上临界磁场（u0Hc2,||）在400 mK时达到约21.98 T，约为泡利顺磁极限（约6.51 T）的3.38倍。ARPES测量和理论计算证实了与SiC强烈杂化的K和K'谷中限制镓层的分裂费米面和Ising型自旋纹理。通过将杂质散射引起的有限弛豫时间纳入Ising型超导模型，成功重现了整个与温度相关的u0Hc2,||相图。

Conclusion: 该工作通过结合量子限制和界面杂化效应，为在超导薄膜中实现非常规配对波函数提供了一种新策略，并为通过界面工程设计可扩展的超导量子电子和自旋电子器件开辟了新途径。

Abstract: In low-dimensional superconductors, the interplay between quantum confinement
and interfacial hybridization effects can reshape Cooper pair wavefunctions and
induce novel forms of unconventional superconductivity. In this work, we employ
a plasma-free, carbon buffer layer-assisted confinement epitaxy method to
synthesize trilayer gallium (Ga) sandwiched between a graphene layer and a
6H-SiC(0001) substrate, forming an air-stable graphene/trilayer Ga/SiC
heterostructure. In this confined light-element Ga layer, we demonstrate
interfacial Ising-type superconductivity driven by atomic orbital hybridization
between the Ga layer and the SiC substrate. Electrical transport measurements
reveal that the in-plane upper critical magnetic field u0Hc2,|| reaches ~21.98T
at T=400 mK, approximately 3.38 times the Pauli paramagnetic limit (~6.51T).
Angle-resolved photoemission spectroscopy (ARPES) measurements combined with
theoretical calculations confirm the presence of split Fermi surfaces with
Ising-type spin textures at the K and K' valleys of the confined Ga layer
strongly hybridized with SiC. Moreover, by incorporating finite relaxation time
induced by impurity scattering into an Ising-type superconductivity model, we
reproduce the entire temperature-dependent u0Hc2,|| phase diagram. This work
establishes a new strategy to realize unconventional pairing wavefunctions by
combining quantum confinement and interfacial hybridization effects in
superconducting thin films. It also opens new avenues for designing scalable
superconducting quantum electronic and spintronic devices through interfacial
engineering.

</details>


### [579] [Quantization of spin circular photogalvanic effect in altermagnetic Weyl semimetals](https://arxiv.org/abs/2509.05620)
*Hiroki Yoshida,Jan Priessnitz,Libor Šmejkal,Shuichi Murakami*

Main category: cond-mat.mes-hall

TL;DR: We predict a spin-current analog of the quantized circular photogalvanic effect in Weyl semimetals, which is uniquely allowed in altermagnets and forbidden in antiferromagnets. We classify symmetry-allowed spin current responses and altermagnetic Weyl semimetals, construct a model, and confirm predictions with calculations.


<details>
  <summary>Details</summary>
Motivation: Highlighting a novel and intrinsic characteristic of altermagnetism by exploring second-order spin current responses, specifically a spin-current analog of the quantized circular photogalvanic effect unique to altermagnets.

Method: Classifying all symmetry-allowed second-order spin current responses based on spin point groups, classifying altermagnetic Weyl semimetals by identifying spin space groups hosting symmetry-enforced Weyl points, constructing a symmetry-guided tight-binding model, and performing first-principle calculations.

Result: Predicted a spin-current analog of the quantized circular photogalvanic effect in Weyl semimetals, unique to altermagnets. Provided a comprehensive classification of altermagnetic Weyl semimetals. Confirmed predictions using a constructed model and first-principle calculations, identifying Weyl crossings in a material candidate.

Conclusion: Unveiled a distinctive optical response of altermagnets, opening a new frontier in altermagnetism research.

Abstract: We theoretically predict a spin-current analog of the quantized circular
photogalvanic effect in Weyl semimetals. This phenomenon is forbidden in
antiferromagnets by symmetry but uniquely allowed in altermagnets, highlighting
a novel and intrinsic characteristic of altermagnetism. To systematically
explore second-order spin current responses, we classify all symmetry-allowed
responses based on spin point groups. Furthermore, we provide a comprehensive
classification of altermagnetic Weyl semimetals by identifying spin space
groups that host symmetry-enforced Weyl points. Utilizing this classification,
we construct a symmetry-guided tight-binding model and confirm our predictions.
Finally, we identify Weyl crossings in a material candidate via first-principle
calculations. Our work unveils a distinctive optical response of altermagnets,
paving the way for a new frontier in altermagnetism.

</details>


### [580] [Modified Quantum Wheatstone Bridge based on current circulation](https://arxiv.org/abs/2509.05621)
*Vipul Upadhyay,Rahul Marathe*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种利用几何不对称性检测未知跳跃率的简单费米子系统。


<details>
  <summary>Details</summary>
Motivation: 利用电流环流和能量简并点之间的联系，实现精确的参数检测，并研究环境相互作用和一般操作条件下的系统性能。

Method: 通过分析电流环流来检测未知的跳跃率，并利用平衡的惠斯通电桥条件在电流方向反转时确定跳跃强度。研究了去相干和粒子损失对器件性能的影响，并在更高电压和温度下进行了扩展分析。

Result: 在低能耗、低偏压条件下，当化学势接近简并能时，电流方向反转时出现平衡的惠斯通电桥条件，可以确定跳跃强度。该器件在中等强度的去相干和粒子损失下仍能正常工作，但极端环境会降低性能。在更高的电压和温度下，器件也能有效运行。

Conclusion: 几何不对称性是一种鲁棒且实用的量子计量工具。

Abstract: We investigate a simple fermionic system designed to detect an unknown
hopping rate between two sites by analyzing current circulation. The system
exploits geometric asymmetry and utilizes the connection between the additional
energy degeneracy point (AEDP) and current circulation for precise parameter
detection. In the low-temperature, low-bias regime, with baths chemical
potentials aligned near the degenerate energy, we find that a balanced
Wheatstone bridge condition emerges when the direction of current circulation
reverses, providing a direct means to determine the unknown hopping strength.
We further examine the impact of environmental interactions, demonstrating that
the device remains functional under moderately strong dephasing and particle
losses, though extreme environmental effects eventually degrade performance.
Extending the analysis to general operating conditions, we show that the device
continues to function effectively at higher voltages and temperatures. Our
results highlight geometric asymmetry as a robust and practical tool for
quantum metrology.

</details>


### [581] [Crystallization in the Winterbottom shape and sharp fluctuation laws](https://arxiv.org/abs/2509.05642)
*Manuel Friedrich,Leonard Kreutz,Ulisse Stefanelli*

Main category: cond-mat.mes-hall

TL;DR: 本文证明了在二维平面晶格基底上，粒子间存在短程相互作用势能时，会发生有限结晶现象。


<details>
  <summary>Details</summary>
Motivation: 研究在二维平面晶格基底上，粒子间存在短程相互作用势能时发生的有限结晶现象。

Method: 利用[31]中的分层技术，结合最小化构型的键图拓扑特征进行证明，并对β∈(0,1)范围内的涨落进行估计，得到不同最小化构型之间的距离界限。

Result: 证明了对于所有β>0，均发生结晶现象，且当β为有理数或无理数时代数时，距离界限分别呈现N^(3/4)和N^(1/3)的标度律。

Conclusion: 推导出当粒子数量趋于无穷大时，最小化构型向Winterbottom平衡形状离散到连续的收敛性。

Abstract: We address finite crystallization in two dimensions in the presence of a flat
crystalline substrate. Particles interact through short-range two- and
three-body potentials favoring local square-lattice arrangements. An additional
interaction term of relative strength $\beta>0$ couples the particles and the
substrate. Our first main result proves crystallization for all $\beta>0$,
corresponding to
  the onset of discrete Winterbottom configurations. The proof relies on a
stratification technique from [31], characterizing the topology of the bond
graph of minimizing configurations.
  Our second main result concerns fluctuations estimates for $\beta\in (0,1)$.
We obtain bounds on the distance between distinct minimizers with the same
number $N$ of particles, showing a sharp scaling law $N^{3/4}$ when $\beta$ is
rational, and $N^{1/3}$ when $\beta$ is irrational and algebraic. This reveals
a genuine substrate-driven effect on fluctuation laws. As a corollary, we
derive a discrete-to-continuum convergence of minimizers towards the
Winterbottom equilibrium shape in the large-particle limit.

</details>


### [582] [LabelImg: CNN-Based Surface Defect Detection](https://arxiv.org/abs/2509.05813)
*Mohsen Asghari Ilani,Yaser Mike Banad*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种基于深度学习的卷积神经网络（CNN）方法，用于自动检测和分割LPBF生产表面上的裂纹、飞溅、孔洞和砂眼等缺陷。


<details>
  <summary>Details</summary>
Motivation: LPBF制造过程中的表面缺陷（如飞溅、裂纹、砂眼和孔洞）影响生产质量，而对这些缺陷的检测至关重要。传统机器学习方法在处理LPBF图像时存在处理时间长和手动特征提取的挑战。

Method: 采用卷积神经网络（CNN）对14,982张带有边界框和分割掩码的标记图像进行训练和测试。结合OpenCV预处理技术。

Result: 该CNN模型在1536 x 1103像素的数据集上达到了99.54%的准确率。在裂纹、砂眼、孔洞和飞溅的测试中，精确率、召回率和F1分数均超过96%。

Conclusion: 所提出的深度学习方法能够精确有效地检测LPBF生产表面的缺陷，显示了其在生产质量预测和关键点识别方面的潜力。

Abstract: In the journey of computer vision system development, the acquisition and
utilization of annotated images play a central role, providing information
about object identity, spatial extent, and viewpoint in depicted scenes.
However, thermal manufacturing processes like Laser Powder Bed Fusion (LPBF)
often yield surfaces with defects such as Spatter, Crack, Pinhole, and Hole due
to the Balling phenomenon. Preprocessing images from LPBF, riddled with
defects, presents challenges in training machine learning (ML) algorithms.
Detecting defects is critical for predicting production quality and identifying
crucial points in artificial or natural structures. This paper introduces a
deep learning-based approach utilizing Convolutional Neural Networks (CNNs) to
automatically detect and segment surface defects like cracks, spatter, holes,
and pinholes on production surfaces. In contrast to traditional machine
learning techniques requiring extensive processing time and manual feature
crafting, deep learning proves more accurate. The proposed architecture
undergoes training and testing on 14,982 labeled images annotated using the
LabelImg tool. Each object in the images is manually annotated with bounding
boxes and segmented masks. The trained CNN, coupled with OpenCV preprocessing
techniques, achieves an impressive 99.54% accuracy on the dataset with
resolutions of 1536 x 1103 pixels. Evaluation metrics for 50 true crack tests
demonstrate precision, recall, and F1-score exceeding 96%, 98%, and 97%,
respectively. Similarly, for 124 true pinhole tests, the metrics are 99%, 100%,
and 100%, for 258 true hole tests, they are 99%, 99%, and 99%, and for 318
spatter tests, the metrics are 100%, 99%, and 100%. These results highlight the
precision and effectiveness of the entire process, showcasing its potential for
reliable defect detection in production surfaces.

</details>


### [583] [Total Faraday rotation by the Hall effect in a 2D electron gas](https://arxiv.org/abs/2509.05819)
*Vishnunarayanan Suresh,Talia J. Martz-Oberlander,Sujatha Vijayakrishnan,Loren N. Pfeiffer,Ken W. West,Guillaume Gervais,Bertrand Reulet,Thomas Szkopek*

Main category: cond-mat.mes-hall

TL;DR: 在 2D 电子气中实现了接近总法拉第旋转（1.43 弧度），Verdet 常数比其他材料系统高一个数量级，这表明经典霍尔效应可用于实现理想的非互易器件。


<details>
  <summary>Details</summary>
Motivation: 在 2D 电子气中实现接近总的法拉第旋转，并探索其在非互易器件中的应用潜力。

Method: 在 2D 电子气（具有高直流迁移率）的空心波导中，在低磁场和微波频率下，使用导电光圈实现弱辐射耦合，测量法拉第旋转。

Result: 实现了 1.43 弧度的法拉第旋转，Verdet 常数为 $9.5	imes10^{8}$ 弧度 T$^{-1}$m$^{-1}$，远超其他材料系统。该结果归因于霍尔效应和弱辐射耦合，在耗散峰附近远离的情况下得到增强。

Conclusion: 所提出的方法在 2D 电子气中实现了接近总的法拉第旋转，Verdet 常数极高，证明了经典霍尔效应在实现理想非互易器件方面的潜力。

Abstract: We report the realization of near total Faraday rotation of $\theta_F$=1.43
rad (82 degrees) on a single pass through a 2D electron gas (2DEG), approaching
the ideal limit of $\pi/2$ rad (90 degrees). The corresponding Verdet constant
V = $9.5\times10^{8}$ rad T$^{-1}$m$^{-1}$, exceeds by approximately one order
of magnitude that reported in other material systems. Our measurements were
conducted at microwave frequencies (f=9.2-11.2 GHz) in a 2DEG with a high dc
mobility $\mu$ = $7\times10^6$ cm$^2$V$^{-1}$s$^{-1}$, in a hollow waveguide at
low-magnetic field (B < 200 mT). Near-total Faraday rotation is attributed to
the Hall effect with weak radiative coupling to the 2DEG in the inertial,
collisionless regime, $\omega \tau \gg 1$, where $\tau$ is the charge transport
scattering time. A conducting iris was used to realize weak radiative coupling.
Under these conditions, Faraday rotation is strongly enhanced away from the
dissipation peak at cyclotron resonance. Our work demonstrates that the
classical Hall effect could be ideally suited for the implementation of ideal
non-reciprocal devices.

</details>


### [584] [Extended Hubbard Model realized in 2D clusters of molecular anions](https://arxiv.org/abs/2509.05868)
*Oliver Tong,Katherine A. Cochrane,Bingkai Yuan,Tanya Roussy,Mona Berciu,Sarah A. Burke*

Main category: cond-mat.mes-hall

TL;DR: 研究了分子阴离子在NaCl双层上的 समूहों，并用扩展Hubbard模型进行了描述。


<details>
  <summary>Details</summary>
Motivation: 由于精确可解的Hubbard模型问题有限，研究人员对扩展Hubbard模型的量子模拟产生了浓厚兴趣，以模拟材料及其相互作用驱动的相。

Method: 使用非接触原子力显微镜、静电力谱和扫描隧道显微镜及光谱技术，研究了3,4,9,10-perylene四羧酸二酐的分子阴离子在NaCl双层上的小簇，并用扩展Hubbard模型进行描述。

Result: 研究表明，扩展Hubbard模型能够很好地描述分子阴离子的占据和跃迁能量。特别是，不对称的四分子簇需要添加不同的站间静电相互作用项、站内势能以及非对称的跳跃项。当t<<U时，占据的不对称性由这些项驱动，与U无关。

Conclusion: 该模型与实验数据吻合良好，表明这些分子阴离子簇可用于探测更大系统和更广泛的实际费米子Hubbard模型相空间。

Abstract: The Hubbard model, despite its simplicity, is remarkably successful at
describing numerous many-body phenomena. However, due to the small class of
problems which can be solved exactly, there has been substantial interest in
quantum simulations of extended Hubbard models to in turn, simulate materials
and the interaction-driven phases they host. Here, we study small clusters of
molecular anions of 3,4,9,10-perylene tetracarboxylic dianhydride on NaCl
bilayers on Ag(111) using non-contact Atomic Force Microscopy, Electrostatic
Force Spectroscopy, and Scanning Tunnelling Microscopy and Spectroscopy, and
show that the occupation and transition energies are well described by an
extended Hubbard model. In particular, asymmetric clusters of four molecules
require the addition of differing inter-site electrostatic interaction terms
and on-site potentials, as well as asymmetric hoping terms. With $t<<U$,
occupation asymmetry is driven by these terms, independent of U. The good
agreement between the model and the data indicate such molecular anion clusters
could be used to probe larger systems and a more varied phase space of
realistic fermionic Hubbard models.

</details>


### [585] [Kinetic equation from Landau level basis: Beyond relaxation-time approximation](https://arxiv.org/abs/2509.06019)
*Kitinan Pongsangangan*

Main category: cond-mat.mes-hall

TL;DR: A kinetic theory is formulated to describe electron transport properties in a uniform magnetic field using the Landau-level basis derived from the Keldysh formalism. This theory is applied to calculate the electrical conductivity of a 2D electron gas in a perpendicular magnetic field.


<details>
  <summary>Details</summary>
Motivation: To formulate a kinetic theory for describing electron transport properties in a uniform magnetic field of arbitrary magnitude.

Method: Derive the quantum kinetic equation from the Landau-level basis using the Keldysh formalism and apply it to calculate the electrical conductivity of a 2D electron gas in a perpendicular magnetic field.

Result: The electrical conductivity of a two-dimensional electron gas exposed to a perpendicular magnetic field is calculated.

Conclusion: The derived kinetic equation, based on the Landau-level formalism, can be used to investigate electron transport properties in magnetic fields.

Abstract: The purpose of this paper is to formulate a kinetic theory describing
transport properties of electrons in a uniform magnetic field of arbitrary
magnitude. Exposing an electronic system to a constant magnetic field quenches
its energy bands into a series of discrete energy levels, known as Landau
levels. The Landau-level states, exact solutions of the Schr\"odinger equation
in a constant background magnetic field, are natural and suitable basis to use,
especially, for the investigation of strong-magnetic-field phenomena. Starting
from the Keldysh formalism, we derive the quantum kinetic equation from the
Landau-level basis. As an illustration, we apply the kinetic equation to
calculate the electrical conductivity of a two-dimensional electron gas exposed
to a perpendicular magnetic field.

</details>


### [586] [Path integral approach to quantum thermalization](https://arxiv.org/abs/2509.06028)
*Alexander Altland,Kun Woo Kim,Tobias Micklitz*

Main category: cond-mat.mes-hall

TL;DR: A quasiclassical Green function approach is presented for describing the dynamics of quantum systems that act as their own environment, combining concepts from quantum many-body theory to cover a wide range of system classes and disorder models. It extends beyond perturbation theory to describe thermalization dynamics up to the many-body Heisenberg time. The approach is illustrated with case studies of quantum circuits and coupled quantum dots, showing good agreement with numerical simulations using the spectral form factor. The work aims to provide a transferable toolbox for describing many-body chaotic quantum systems with strong entanglement.


<details>
  <summary>Details</summary>
Motivation: The paper introduces a new theoretical framework, a quasiclassical Green function approach, to describe the dynamics of quantum systems that interact with themselves, effectively acting as their own environment. This approach aims to overcome the limitations of previous methods by going beyond perturbation theory and enabling a description of various dynamical regimes, including thermalization and ergodicity, in strongly entangled many-body chaotic systems.

Method: The paper combines concepts from quantum many-body theory, including the nonlinear $\sigma$-model of disordered systems, the $G\Sigma$-formalism for strong correlations, and real-time path integration. This integration forms a quasiclassical Green function approach capable of describing unitary yet irreversible dynamics. The method is applied to analyze thermalization dynamics from short scattering times to the many-body Heisenberg time and is illustrated with two case studies: a brickwork model of quantum circuits and an array of capacitively coupled quantum dots.

Result: The proposed quasiclassical Green function approach is shown to be capable of describing a wide range of quantum system classes and disorder models, extending beyond perturbation theory. Case studies on a brickwork model and coupled quantum dots demonstrate good agreement between the theoretical predictions, specifically using the spectral form factor as an observable, and numerical simulations. The approach successfully captures thermalization dynamics across different time scales.

Conclusion: The developed quasiclassical Green function approach provides a powerful and transferable toolbox for the first-principles description of many-body chaotic quantum systems, particularly in regimes of strong entanglement. It effectively captures the unitary yet irreversible dynamics of systems acting as their own environment, covering thermalization and ergodicity over various time scales and showing good agreement with numerical results.

Abstract: We introduce a quasiclassical Green function approach describing the unitary
yet irreversible dynamics of quantum systems effectively acting as their own
environment. Combining a variety of concepts of quantum many-body theory,
notably the nonlinear $\sigma$-model of disordered systems, the $G
\Sigma$-formalism for strong correlations, and real time path integration, the
theory is capable of describing a wide range of system classes and disorder
models. It extends previous work beyond perturbation theory (in inverse Hilbert
space dimensions), enabling a description of thermalization dynamics from short
scattering times, through the onset of ergodicity at an effective `Thouless
time', up to the many-body Heisenberg time. We illustrate the approach with two
case studies, (i) a brickwork model of unitarily coupled quantum circuits with
and without conserved symmetries, and (ii) an array of capacitively coupled
quantum dots. Using the spectral form factor as a test observable, we find good
agreement with numerical simulations. We present our formalism in a
self-contained and pedagogical manner, aiming to provide a transferable toolbox
for the first-principles description of many-body chaotic quantum systems in
regimes of strong entanglement.

</details>


### [587] [Magnetic inertia induced spin-wave dispersion in two-sublattice ferromagnets](https://arxiv.org/abs/2509.06038)
*Subhadip Ghosh,Darpa Narayan Basu,Ritwik Mondal*

Main category: cond-mat.mes-hall

TL;DR: Magnetic inertia in two-sublattice ferromagnets leads to novel spin-wave spectra with tunable band structures and nonreciprocal properties, enabling new spintronic applications.


<details>
  <summary>Details</summary>
Motivation: Investigate the spin-wave spectrum of two-sublattice ferromagnets by incorporating the full magnetic inertia tensor to understand its contributions and effects.

Method: Decomposed the magnetic inertia tensor into symmetric and antisymmetric components and used linear spin-wave theory to analyze the spectrum, identifying isotropic, anisotropic, and chiral contributions. Examined the effects of cross-sublattice inertia and chiral inertia on magnon bands and nonreciprocity, considering the Dzyaloshinskii-Moriya interaction.

Result: Identified two precessional magnon bands and two inertial magnon bands. Found that the upper precessional band crosses the lower inertial band. Demonstrated that both cross-sublattice inertia and chiral inertia can tune the magnon band structures. Revealed that inertial spin-wave spectrum becomes nonreciprocal along directions with finite Dzyaloshinskii-Moriya interaction. Showed that chiral inertia can engineer nonreciprocal spin-wave spectrum even without Dzyaloshinskii-Moriya interaction.

Conclusion: Magnetic inertia plays a crucial role in shaping spin-wave spectra in two-sublattice ferromagnets, offering new ways to engineer nonreciprocal magnonic devices and ultrafast spintronic applications by controlling inertia and Dzyaloshinskii-Moriya interaction.

Abstract: Magnetic inertial dynamics has recently been predicted and experimentally
observed in two-sublattice ferromagnets such as CoFeB and NiFe permalloy. In
this work, we investigate the spin-wave spectrum of such systems by
incorporating the full magnetic inertia tensor. Decomposing the tensor into its
symmetric and antisymmetric components allows us to identify isotropic,
anisotropic, and chiral contributions to the magnetic inertia. Using linear
spin-wave theory, we find that the spectrum consists of two precessional magnon
bands and two inertial magnon bands. Remarkably, the upper precessional magnon
band crosses the lower inertial magnon band within the Brillouin zone. We show
that both cross-sublattice inertia and chiral inertia provide effective tuning
knobs for these magnon band structures. Furthermore, our results reveal that
the inertial spin-wave spectrum becomes nonreciprocal along directions where
the Dzyaloshinskii-Moriya interaction is finite. On the other hand, a
nonreciprocal spin-wave spectrum can also be engineered through chiral inertia,
even in the absence of Dzyaloshinskii-Moriya interaction. These findings open
avenues for engineering nonreciprocal magnonic devices and ultrafast spintronic
applications through control of magnetic inertia.

</details>


### [588] [Topological energy pumping in a quasi-periodically driven four-level system](https://arxiv.org/abs/2509.06043)
*Vansh Kaushik,Sayan Choudhury,Tanay Nag*

Main category: cond-mat.mes-hall

TL;DR: 系统通过准周期驱动的四能级系统实现二维合成陈绝缘体，并利用能量交换率和保真度来表征拓扑性质。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索准周期驱动的四能级系统在实现拓扑现象方面的潜力，并将其与具有自旋和轨道自由度的四带模型进行类比。

Method: 利用双频驱动和强驱动条件，在四能级系统中实现二维合成陈绝缘体。通过计算自旋陈数、中带旺德纳谱和时间演化的保真度来表征系统的拓扑性质。

Result: 发现了能量交换率与手征对称性保护的陈绝缘体带有关，并观察到高阶拓扑绝缘体中能量交换率为零的现象。保真度可以区分拓扑和非拓扑相。

Conclusion: 能量交换率和保真度是表征时间维度拓扑绝缘体的重要物理量，为在时间维度上实现和操控拓扑现象提供了新的途径。

Abstract: We investigate a quasi-periodically driven four-level system that serves as a
temporal analog of topological phenomena found in four-band models with
intertwined spin and orbital degrees of freedom. Under a two-tone drive in the
strong-driving regime, the system realizes a two-dimensional synthetic Floquet
lattice, thus facilitating the realization of topological energy pumping. For a
temporal quantum spin Hall insulator, we find that the rates of emission and
absorption of energy between the two drives are not exactly opposite for a
given band. However, when contributions from two chiral symmetric partner bands
are added, they become exactly opposite. This quantized rate of energy exchange
is a direct consequence of propagating edge modes in the real-space model,
which we further characterize by computing the spin-Chern number.
Interestingly, our analysis yields zero rate of exchange of energy between the
drives for a temporal higher-order topological insulator, suggesting the
presence of localized corner modes that we characterize by the mid-gap Wannier
spectra. Finally, we demonstrate that the perfect (imperfect) nature of the
fidelity during the time-evolution of the system serves as a characteristic
signature of a topological (trivial) phase.

</details>


### [589] [Relation between chiral anomaly and electric transport in $1D$ Dirac semimetal](https://arxiv.org/abs/2509.06063)
*Mustafa Bohra,M. A. Zubkov*

Main category: cond-mat.mes-hall

TL;DR: 本研究关注一维狄拉克半金属中的手征反常与耗散的相互作用，利用非平衡凯尔迪什格林函数方法，计算了在能量耗散存在下手征不平衡和电导率，揭示了它们与手征反常的联系，并展示了反常引起的轴荷密度和电流的贡献。


<details>
  <summary>Details</summary>
Motivation: 研究一维狄拉克半金属中的手征反常与耗散的相互作用及其对电学性质的影响。

Method: 采用非平衡凯尔迪什格林函数形式，并结合耗散效应，计算轴荷密度和电导率。

Result: 手征反常的贡献在轴荷密度和电导率中均有体现，揭示了其与手征不平衡和电导率的联系。

Conclusion: 手征反常和耗散在一维狄拉克半金属中存在相互作用，并且这种相互作用可以通过凯尔迪什格林函数形式进行量化。

Abstract: We investigate the interplay of chiral anomaly and dissipation in one -
dimensional Dirac semimetal. For definiteness we consider the Su Schrieffer
Heeger (SSH) model, which on the language of lattice field theory represents 1
D Wilson fermions. We employ the non-equilibrium Keldysh Green function
formalism, and calculate the chiral imbalance and electric conductivity in the
presence of energy dissipation, revealing how these observables are connected
to the chiral anomaly. By systematically incorporating dissipation effects into
the Keldysh framework, we demonstrate how the anomaly-induced contributions
manifest in both axial charge density and electric current.

</details>


### [590] [Persistent Charge and Spin Currents in a Ferromagnetic Hatano-Nelson Ring](https://arxiv.org/abs/2509.06109)
*Sourav Karmakar,Sudin Ganguly,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了具有反厄米分子内跳跃的铁磁Hatano-Nelson环中的持久电荷和自旋电流。


<details>
  <summary>Details</summary>
Motivation: 非倒易跳跃产生合成磁通量并驱动非厄米Aharonov-Bohm效应，本研究旨在探索该系统中的持久电荷和自旋电流。

Method: 使用双正交基中的电流算符方法计算电流，并分析复带隙结构以揭示光谱特征。

Result: 系统同时支持实部和虚部的持久电流，铁磁自旋分裂使得所有三个自旋电流分量都可由磁矩取向决定。研究还发现，无序可以放大自旋电流。

Conclusion: 持久电流的演变受拓扑、化学势、铁磁序、有限尺寸和无序等因素影响，其中无序可以为操纵非厄米系统中的自旋输运开辟新途径。

Abstract: We investigate persistent charge and spin currents in a ferromagnetic
Hatano-Nelson ring with anti-Hermitian intradimer hopping, where non-reciprocal
hopping generates a synthetic magnetic flux and drives a non-Hermitian
Aharonov-Bohm effect. The system supports both real and imaginary persistent
currents, with ferromagnetic spin splitting enabling all three spin-current
components, dictated by the orientation of magnetic moments. The currents are
computed using the current operator method within a biorthogonal basis. In
parallel, the complex band structure is analyzed to uncover the spectral
characteristics. We emphasize how the currents evolve across different
topological regimes, and how they are influenced by chemical potential,
ferromagnetic ordering, finite size, and disorder. Strikingly, disorder can
even amplify spin currents, opening powerful new routes for manipulating spin
transport in non-Hermitian systems.

</details>


### [591] [Tunable topology, Hall response, and spin-textures in bicircularly polarized light illuminated altermagnets](https://arxiv.org/abs/2509.06349)
*Maitri Ganguli,Aneek Jana,Awadhesh Narayan*

Main category: cond-mat.mes-hall

TL;DR: 通过光照调控具有Rashba自旋-轨道耦合的交替磁体材料


<details>
  <summary>Details</summary>
Motivation: 研究具有Rashba自旋-轨道耦合的交替磁体材料在外加双圆偏振光（BCL）作用下的特性。

Method: 使用双圆偏振光（BCL）照射交替磁体材料，并分析其拓扑、自旋纹理和费米面的变化，以及异常霍尔响应。

Result: 发现BCL能够显著调控交替磁体的拓扑、自旋纹理和费米面，实现超越单色光的调控效果。观察到一系列可控的拓扑相变，并通过异常霍尔效应进行验证。证明了BCL的相对相位可以用来调控自旋纹理和费米面。

Conclusion: BCL为有效调控交替磁体材料提供了新途径。

Abstract: Altermagnets, featuring non-relativistic spin splitting, have drawn enormous
attention due to their intriguing properties. Here, we investigate the effects
of shining bicircularly polarized light (BCL) on altermagnets with Rashba
spin-orbit coupling. We discover a remarkable tunability of topology,
spin-textures, and Fermi surfaces of altermagnets by means of BCL illumination,
going beyond monochromatic light. We illustrate a cascade of topological phase
transitions controllable by BCL and demonstrate how these transitions are
reflected in the anomalous Hall response of the altermagnet. Furthermore, we
show that the spin-textures and Fermi surfaces can be directly tuned by the
relative phase of the BCL, stemming from the underlying symmetry changes. Our
findings can pave the way for effectively controlling altermagnetic materials
with structured light.

</details>


### [592] [An Approach to the Quantum Hall Effect in Three- Dimensional Electron Systems](https://arxiv.org/abs/2509.06386)
*M. A. Hidalgo*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一个描述三维（3D）电子系统整数量子霍尔效应（IQHE）的理论框架，通过扩展先前在二维（2D）系统中成功的单电子方法，并考虑了3D材料的特性（如带各向异性）。


<details>
  <summary>Details</summary>
Motivation: 将先前成功应用于二维系统的单电子IQHE理论框架扩展到三维电子系统，以解释近期在三维材料中观察到的量子霍尔效应实验现象。

Method: 从石墨烯模型出发，将理论推广到三维半金属，引入了有效的回旋频率修正和大的有效回旋磁g因子以考虑带各向异性和材料特性。通过计算态密度和载流子浓度，推导出导电率的半经典表达式。

Result: 计算得到的霍尔电导率展现出与理论预测和实验观察一致的量子化值，模拟结果重现了霍尔平台和Shubnikov de Haas振荡。

Conclusion: 三维半金属中的IQHE可以被理解为二维系统单电子朗道量子化框架的自然延伸，为跨维度的量子磁输运提供了一个统一的图景，并指出了低载流子密度和高迁移率的关键作用。该模型为分析三维系统在量子霍尔条件下的热力学和输运性质提供了新的途径。

Abstract: We present a theoretical framework to describe the integer quantum Hall
effect (IQHE) in three-dimensional (3D) electron systems. This extends our
previous single-electron approach, which was successfully applied to
two-dimensional (2D) systems such as semiconductor quantum wells and graphene,
where insights provided into both the IQHE and the fractional quantum Hall
effect (FQHE). Starting from the graphene model, where the unconventional
sequence of Hall plateaux, 2(2n+1), naturally emerges from Landau quantization,
we generalize the formulation to 3D semimetals with low carrier density and
high mobility, where recent experiments have reported signatures of the QHE.
For 3D systems, the model accounts for strong band anisotropy by introducing an
effective correction to the cyclotron frequency, and, also by considering large
effective gyromagnetic factor, as observed in semimetallic materials. From the
calculated density of states and carrier concentration, we derive semiclassical
expressions for the diagonal and Hall conductivities. The resulting Hall
conductivity exhibits quantized values in agreement with theoretical
predictions and experimental observations of 3D quantum Hall states.
Simulations reproduce both Hall plateaux and Shubnikov de Haas oscillations
under realistic parameter sets. Our results demonstrate that the IQHE in 3D
semimetals can be understood as a natural extension of the single-electron
Landau quantization framework originally developed for 2D systems. This
provides a unified picture of quantum magnetotransport across dimensions,
highlighting the crucial role of low carrier density and high mobility. The
model further suggests new avenues for analyzing thermodynamic and transport
properties in 3D systems under quantum Hall conditions.

</details>


### [593] [Quantum Size Effect in Optically Active Indium Selenide Crystal Phase Heterostructures Grown by Molecular Beam Epitaxy](https://arxiv.org/abs/2509.06605)
*Piotr Wojnar,Maciej Wojcik,Piotr Baranowski,Jacek Kossut,Marta Aleszkiewicz,Jaroslaw Z. Domagala,Roza Dziewiatkowska,Pawel Ciepielewski,Maksymilian Kuna,Zuzanna Kostera,Slawomir Kret,Sergij Chusnutdinow*

Main category: cond-mat.mes-hall

TL;DR: 研究人员通过分子束外延技术制备了具有光学活性的硒化铟晶体相异质结构，其中γ-硒化铟/γ-二硒化铟异质结构在光子学应用方面展现出巨大潜力，在近红外光谱范围内表现出强烈的发光，且发光能量可通过调节γ-硒化铟层厚度实现250 meV的调谐，这为设计近红外光源和探测器提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 硒化铟因其优异的电子和光学性质，在电子和光子器件领域具有潜在应用前景。特别是二维范德华半导体晶体相异质结构，引起了研究兴趣。

Method: 通过分子束外延技术，在可控的条件下制备了光学活性的硒化铟晶体相异质结构，并可选择性地获得γ-InSe、γ-In2Se3或β-yIn2Se3晶体相。

Result: 研究发现γ-InSe/γ-In2Se3异质结构在光子学应用方面最有前景。该异质结构在近红外光谱范围内表现出强烈的发光，且通过改变γ-InSe层厚度，发光能量可调谐250 meV，这归因于量子尺寸效应。

Conclusion: 光学活性的硒化铟晶体相异质结构为设计近红外光子器件（如光源和探测器）提供了一个有趣的平台。采用分子束外延技术可在较大面积上制备结构，为后续的器件原型设计奠定了基础。

Abstract: Indium selenide attracts the interest due to its outstanding electronic and
optical properties which are potentially prospective in view of applications in
electronic and photonic devices. Most of the polymorphic crystal phases of this
semiconductor belong to the family of two-dimensional van der Waals
semiconductors. In this study optically active indium selenide crystal phase
heterostructures are fabricated by molecular beam epitaxy in a well-controlled
manner. It is demonstrated that by changing the growth conditions one may
obtain either {\gamma}-InSe, or {\gamma}-In2Se3, or \b{eta}-yIn2Se3 crystal
phases. The most promising crystal phase heterostructures from the point of
view of photonic applications is found to be the {\gamma}-InSe/{\gamma}-In2Se3
heterostructure. An intense optical emission from this heterostructure appears
in the near infrared spectral range. The emission energy can be tuned over 250
meV by changing {\gamma}-InSe layer thickness which is explained by the quantum
size effect. The optically active indium selenide crystal phase
heterostructures represent, therefore, an interesting platform for the design
of light sources and detectors in the near infra-red. The use of molecular beam
epitaxy for this purpose ensures that the structures are fabricated on large
surfaces opening the possibility for the design of device prototypes by using
lithography methods

</details>


### [594] [Nanoscale photonic neuron with biological signal processing](https://arxiv.org/abs/2509.06696)
*Joachim E. Sestoft,Thomas K. Jensen,Vidar Flodgren,Abhijit Das,Rasmus D. Schlosser,David Alcer,Mariia Lamers,Thomas Kanne,Magnus T. Borgström,Jesper Nygård,Anders Mikkelsen*

Main category: cond-mat.mes-hall

TL;DR: 光子神经形态计算的范式转变：一种具有微小占地面积和极低功耗的纳米光电子神经元


<details>
  <summary>Details</summary>
Motivation: 解决人工智能日益增长的能源需求，并克服现有光子神经形态硬件在尺寸和功能上的限制。

Method: 设计并实现了一种尺寸减小至少100倍、功耗在皮瓦量级的纳米光电子神经元，该神经元能够接收、处理（包括抑制性信号）和加总输入信号，并具有非线性响应、生物学相关响应、记忆时间尺度和输入权重能力。

Result: 成功展示了一种尺寸紧凑（比现有技术小100倍以上）、功耗极低（皮瓦量级）的纳米光电子神经元，该神经元能够处理兴奋性和抑制性信号，并表现出多种生物学相关功能和记忆特性。该神经元兼容现有硅技术，支持多波长操作，并可用于计算和传感。

Conclusion: 这项工作为实现具有微小占地面积和低功耗的光子神经形态计算以及紧凑、模块化的自适应光学传感应用开辟了新的道路。

Abstract: Computational hardware designed to mimic biological neural networks holds the
promise to resolve the drastically growing global energy demand of artificial
intelligence. A wide variety of hardware concepts have been proposed, and among
these, photonic approaches offer immense strengths in terms of power
efficiency, speed and synaptic connectivity. However, existing solutions have
large circuit footprints limiting scaling potential and they miss key
biological functions, like inhibition. We demonstrate an artificial
nano-optoelectronic neuron with a circuit footprint size reduced by at least a
factor of 100 compared to existing technologies and operating powers in the
picowatt regime. The neuron can deterministically receive both exciting and
inhibiting signals that can be summed and treated with a non-linear function.
It demonstrates several biological relevant responses and memory timescales, as
well as weighting of input channels. The neuron is compatible with commercial
silicon technology, operates at multiple wavelengths and can be used for both
computing and optical sensing. This work paves the way for two important
research paths: photonic neuromorphic computing with nanosized footprints and
low power consumption, and adaptive optical sensing, using the same
architecture as a compact, modular front end

</details>


### [595] [Resonant spin Hall effect in a nanoribbon of a spin-orbit coupled electronic system](https://arxiv.org/abs/2509.06804)
*Mohamad Usman,Tarun Kanti Ghosh,SK Firoz Islam*

Main category: cond-mat.mes-hall

TL;DR: nanoribbon中的自旋霍尔效应


<details>
  <summary>Details</summary>
Motivation: 研究有Rashba和Dresselhaus自旋-轨道耦合的二维正方晶格纳米带中的自旋霍尔现象。

Method: 计算自旋霍尔电导率，并研究各向异性、有限温度效应对亚带共振的影响，最后使用延迟格林函数方法研究纵向电导。

Result: 发现了除Γ点外，亚带间存在额外的自旋简并点和反交叉点，导致自旋霍尔电导率发散并产生共振。研究表明，即使没有外部场，这种共振依然存在。纵向电导呈现量子化值。

Conclusion: 纳米带中的自旋简并点和反交叉点是产生自旋霍尔效应共振的关键，并且这种效应是鲁棒的。

Abstract: We present a theoretical study of spin Hall phenomena in a nanoribbon made of
a two-dimensional square lattice with Rashba and Dresselhaus spin-orbit
coupling. We show that the nanoribbon can give rise to a number of additional
spin degeneracy points as well as anti-crossing points, apart from the $\Gamma$
point, between two nearest sub-bands. We compute the spin Hall conductivity and
demonstrate that it diverges and gives rise to a resonance when chemical
potential passes through those spin-degenerate or anti-crossing points.
Contrary to the previous studies, here such resonance emerges even without any
external perturbation like magnetic field or light. In addition, we examine the
influence of anisotropy in Rashba and Dresselhaus interactions, as well as
finite-temperature effects, and show that the inter subband resonance remains
robust. Finally, we also investigate the signature of such additional spin
degeneracy and anti-crossing points in the longitudinal conductance by using
retarded Green function approach in lattice model. The peculiar features of the
bands are reflected in the longitudinal conductance, which takes quantized
values of $2n e^{2}/{h},$ where $n$ denotes the number of bands occupied by the
chemical potential with each band having spin split sub-bands.

</details>


### [596] [Symmetry-enforced Moiré Topology](https://arxiv.org/abs/2509.06906)
*Yunzhe Liu,Kaijie Yang,Chao-Xing Liu,Jiabin Yu*

Main category: cond-mat.mes-hall

TL;DR: 利用原子对称性和莫尔超晶格对称性预测莫尔超晶格能带拓扑，发现了197种可实现对称性强制非平凡拓扑的组合。


<details>
  <summary>Details</summary>
Motivation: 密度泛函理论（DFT）在计算莫尔超晶格拓扑时效率低下，需要一种更有效的方法来预测莫尔超晶格能带拓扑。

Method: 提出一种系统性方案，利用从DFT中提取的原子对称性数据和莫尔超晶格对称性群来预测莫尔超晶格能带的拓扑。该方法通过检查原子对称性数据和莫尔超晶格对称性群的组合来识别能带拓扑。

Result: 对于$\Gamma$谷电子气，发现某些原子对称性数据与莫尔超晶格对称性群的组合可以强制实现非平凡的低能莫尔超晶格能带拓扑。在系统扫描所有2D原子对称性数据和莫尔超晶格对称性群后，识别出197种能够产生对称性强制非平凡莫尔超晶格拓扑的组合，并通过立方Rashba自旋-轨道耦合的莫尔超晶格模型验证了其中一种组合。

Conclusion: 该方法能够有效地预测莫尔超晶格能带拓扑，并为实验上发现和设计新的拓扑非平凡莫尔超晶格材料提供了有用的指导。此方法具有普适性，可推广到其他谷。

Abstract: Topological flat bands in two-dimensional (2D) moir\'e materials have emerged
as promising platforms for exploring the interplay between topology and
correlation effects. However, realistic calculations of moir\'e band topology
using density functional theory (DFT) are computationally inefficient due to
the large number of atoms in a single moir\'e unit cell. In this work, we
propose a systematic scheme to predict the topology of moir\'e bands from
atomic symmetry data and moir\'e symmetry group, both of which can be
efficiently extracted from DFT. Specifically, for $\Gamma$-valley electron
gases, we find that certain combinations of atomic symmetry data and moir\'e
symmetry groups can enforce nontrivial band topology in the low-energy moir\'e
bands, as long as the moir\'e band gap is smaller than the atomic band
splitting at the moir\'e Brillouin zone boundary. This symmetry-enforced
nontrivial moir\'e topology, including both topological insulators and
topological semimetals, is robust against various material-specific details
such as the precise form and strength of the moir\'e potential or the exact
twist angle. By exhaustively scanning all 2D atomic symmetry data and moir\'e
symmetry groups, we identify 197 combinations that can yield symmetry-enforced
nontrivial moir\'e topology, and we verify one such combination using a moir\'e
model with cubic Rashba spin-orbit coupling. Our approach is generalizable to
other valleys and provides a useful guideline for experimental efforts to
discover and design new topologically nontrivial moir\'e materials.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [597] [Compositional Inductive Invariant Inference via Assume-Guarantee Reasoning](https://arxiv.org/abs/2509.06250)
*Ian Dardik,Eunsuk Kang*

Main category: cs.LO

TL;DR: 通过将系统分解为组件并为每个组件分配假设-保证契约，然后推断局部归纳不变量来推断归纳不变量。


<details>
  <summary>Details</summary>
Motivation: 现有的归纳不变量推断方法由于需要处理整个系统的转移关系而面临复杂性挑战。

Method: 提出一种组合方法，将系统分解为组件，为每个组件分配假设-保证契约，并推断局部归纳不变量，这些不变量仅在组件的转移关系下是封闭的。

Result: 该框架在两个案例研究中得到应用，证明了其比全局技术更有效地推断不变量，并提供了比全局不变量更具模块化的规范见解。

Conclusion: 组合式归纳不变量推断技术通过分解系统和推断局部不变量，可以更有效地推断不变量，并提供更具模块化的见解。

Abstract: A common technique for verifying the safety of complex systems is the
inductive invariant method. Inductive invariants are inductive formulas that
overapproximate the reachable states of a system and imply a desired safety
property. However, inductive invariants are notoriously complex, which makes
inductive invariant inference a challenging problem. In this work, we observe
that inductive invariant formulas are complex primarily because they must be
closed over the transition relation of an entire system. Therefore, we propose
a new approach in which we decompose a system into components, assign an
assume-guarantee contract to each component, and prove that each component
fulfills its contract by inferring a local inductive invariant. The key
advantage of local inductive invariant inference is that the local invariant
need only be closed under the transition relation for the component, which is
simpler than the transition relation for the entire system. Once local
invariant inference is complete, system-wide safety follows by construction
because the conjunction of all local invariants becomes an inductive invariant
for the entire system. We apply our compositional inductive invariant inference
technique to two case studies, in which we provide evidence that our framework
can infer invariants more efficiently than the global technique. Our case
studies also show that local inductive invariants provide modular insights
about a specification that are not offered by global invariants.

</details>


### [598] [Verifying Sampling Algorithms via Distributional Invariants](https://arxiv.org/abs/2509.06410)
*Kevin Batz,Joost-Pieter Katoen,Tobias Winkler,Daniel Zilken*

Main category: cs.LO

TL;DR: 本篇论文提出了一种用于验证离散采样算法正确性的框架，将概率程序视为分布变换器，并引入了（归纳）分布循环不变式的概念，最终成功验证了快筛骰子和快加权骰子两个算法的正确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决离散采样算法的正确性验证问题。

Method: 提出了一种将概率程序视为分布变换器的验证框架，并引入了（归纳）分布循环不变式的概念，将其嵌入到类似Hoare的验证框架中，包含总正确性和部分正确性的证明规则。

Result: 成功验证了快筛骰子和快加权骰子两个离散采样算法的正确性。

Conclusion: 所提出的基于（归纳）分布循环不变式的验证框架能够有效地验证离散采样算法的正确性。

Abstract: This paper develops a verification framework aimed at establishing the
correctness of discrete sampling algorithms. We do so by considering
probabilistic programs as distribution transformers. Inspired by recent work on
distributional verification of Markov models, we introduce the notion of
(inductive) distributional loop invariants for discrete probabilistic programs.
These invariants are embedded in a Hoare-like verification framework that
includes proof rules for total and partial correctness. To illustrate the
applicability of our framework, we prove the correctness of two discrete
sampling algorithms: the Fast Dice Roller and the Fast Loaded Dice Roller.

</details>


### [599] [Tabular intermediate logics comparison](https://arxiv.org/abs/2509.06841)
*Paweł Rzążewski,Michał Stronkowski*

Main category: cs.LO

TL;DR: 研究有限偏序集表示的逻辑包含和上确界保持映射问题的复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究逻辑包含问题和上确界保持映射问题的复杂度，特别是当它们由有限偏序集表示时。

Method: 提出了一种图论到偏序集的构造方法，用于将图的同态问题与偏序集的上确界保持映射问题联系起来，并推导NP-完备性结果。此外，还为树形偏序集的情况设计了一个多项式时间算法。

Result: 证明了几种受限版本的逻辑包含和上确界保持映射问题是NP-完备的，并给出了一个18个元素的偏序集例子。为树形偏序集的情况提供了一个多项式时间算法。

Conclusion: 该研究为理解和解决与表格中间逻辑相关的逻辑包含和上确界保持映射问题的计算复杂度提供了新的见解和工具。

Abstract: Tabular intermediate logics are intermediate logics characterized by finite
posets treated as Kripke frames. For a poset $\mathbb{P}$, let $L(\mathbb{P})$
denote the corresponding tabular intermediate logic. We investigate the
complexity of the following decision problem $\mathsf{LogContain}$: given two
finite posets $\mathbb P$ and $\mathbb Q$, decide whether $L(\mathbb P)
\subseteq L(\mathbb Q)$.
  By Jankov's and de Jongh's theorem, the problem $\mathsf{LogContain}$ is
related to the problem $\mathsf{SPMorph}$: given two finite posets $\mathbb P$
and $\mathbb Q$, decide whether there exists a surjective $p$-morphism from
$\mathbb P$ onto $\mathbb Q$. Both problems belong to the complexity class NP.
  We present two contributions. First, we describe a construction which,
starting with a graph $\mathbb{G}$, gives a poset $\mathsf{Pos}(\mathbb{G})$
such that there is a surjective locally surjective homomorphism (the
graph-theoretic analog of a $p$-morphism) from $\mathbb{G}$ onto $\mathbb{H}$
if and only if there is a surjective $p$-morphism from
$\mathsf{Pos}(\mathbb{G})$ onto $\mathsf{Pos}(\mathbb{H})$. This allows us to
translate some hardness results from graph theory and obtain that several
restricted versions of the problems $\mathsf{LogContain}$ and
$\mathsf{SPMorph}$ are NP-complete. Among other results, we present a
18-element poset $\mathbb{Q}$ such that the problem to decide, for a given
poset $\mathbb{P}$, whether $L(\mathbb{P})\subseteq L(\mathbb{Q})$ is
NP-complete.
  Second, we describe a polynomial-time algorithm that decides
$\mathsf{LogContain}$ and $\mathsf{SPMorph}$ for posets $\mathbb{T}$ and
$\mathbb{Q}$, when $\mathbb{T}$ is a tree.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [600] [PaMO: Parallel Mesh Optimization for Intersection-Free Low-Poly Modeling on the GPU](https://arxiv.org/abs/2509.05595)
*Seonghun Oh,Xiaodi Yuan,Xinyue Wei,Ruoxi Shi,Fanbo Xiang,Minghua Liu,Hao Su*

Main category: cs.GR

TL;DR: 该研究提出了一种新颖的GPU加速网格优化方法，用于解决复杂3D模型简化中的自相交、表面偏移和特征丢失问题，并实现了高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有的网格简化方法在处理复杂3D模型时存在自相交、需要预处理（如重新网格化）导致表面偏移和特征丢失，以及处理大型网格速度慢等问题，限制了其在3D打印、软体模拟和交互式编辑等应用中的实际效果。

Method: 提出了一种包含三个关键组件的GPU加速网格优化方法：1. 并行重新网格化算法，用于处理“野外”网格，生成无自相交、流形的、无缝隙的网格，并减少不规则三角形的出现；2. 具有无自相交保证的鲁棒并行简化算法；3. 基于优化的安全投影算法，用于将简化后的网格与输入网格对齐，消除重新网格化带来的表面偏移，并恢复原始的尖锐特征。

Result: 该方法在RTX4090上仅用3秒钟就将一个包含200万个面片的网格简化为2万个三角形。在Thingi10K数据集上的评估结果表明，该方法在几何保真度和处理速度方面表现出色。

Conclusion: 所提出的GPU加速网格优化方法能够高效地解决现有网格简化技术的痛点，在保持几何细节的同时实现快速处理，适用于多种图形学应用。

Abstract: Reducing the triangle count in complex 3D models is a basic geometry
preprocessing step in graphics pipelines such as efficient rendering and
interactive editing. However, most existing mesh simplification methods exhibit
a few issues. Firstly, they often lead to self-intersections during decimation,
a major issue for applications such as 3D printing and soft-body simulation.
Second, to perform simplification on a mesh in the wild, one would first need
to perform re-meshing, which often suffers from surface shifts and losses of
sharp features. Finally, existing re-meshing and simplification methods can
take minutes when processing large-scale meshes, limiting their applications in
practice. To address the challenges, we introduce a novel GPU-based mesh
optimization approach containing three key components: (1) a parallel
re-meshing algorithm to turn meshes in the wild into watertight, manifold, and
intersection-free ones, and reduce the prevalence of poorly shaped triangles;
(2) a robust parallel simplification algorithm with intersection-free
guarantees; (3) an optimization-based safe projection algorithm to realign the
simplified mesh with the input, eliminating the surface shift introduced by
re-meshing and recovering the original sharp features. The algorithm
demonstrates remarkable efficiency, simplifying a 2-million-face mesh to 20k
triangles in 3 seconds on RTX4090. We evaluated the approach on the Thingi10K
dataset and showcased its exceptional performance in geometry preservation and
speed.

</details>


### [601] [Programming tension in 3D printed networks inspired by spiderwebs](https://arxiv.org/abs/2509.05855)
*Thijs Masmeijer,Caleb Swain,Jeff Hill,Ed Habtour*

Main category: cs.GR

TL;DR: 该研究提出了一种直接3D打印具有程序化张力梯度的结构网络的算法，解决了制造中的挑战。


<details>
  <summary>Details</summary>
Motivation: 需要为张力结构网络（如张拉整体、建筑织物或医疗支架/网格）中的每个元素设置特定的张力水平，以实现所需的形状、稳定性和依从性。然而，在制造、3D打印或组装这些结构时，将网络压平成平面会导致最终张力梯度出现累积误差。

Method: 该算法包括：(i) 使用力密度法定义所需网络并规定其张力梯度；(ii) 通过数值优化顶点位置以达到目标单元长度，并将直线单元转换为圆弧以解决任何剩余误差，从而将网络转换为未拉伸的对应物；(iii) 将网络分解为可打印的工具路径；可选的附加步骤包括：(iv) 压平面或3D网络以确保3D打印兼容性；(v) 自动解决压平过程引入的任何不希望出现的交叉。

Result: 通过使用2D粘弹性丝网单元进行实验验证，表明该方法能够实现精确的张力梯度，平均单元应变误差小于1.0%。该方法对于单元最小长度为5.8毫米和最大应力为7.3兆帕的网络仍然有效。该方法还成功用于演示制造三个复杂案例：平面蜘蛛网、曲面网格和张拉整体系统。

Conclusion: 该程序化张力梯度算法可用于制造紧凑、集成化的电缆网络，从而实现新的应用，例如在医疗支架和夹板中实现施加力矩的结构。

Abstract: Each element in tensioned structural networks -- such as tensegrity,
architectural fabrics, or medical braces/meshes -- requires a specific tension
level to achieve and maintain the desired shape, stability, and compliance.
These structures are challenging to manufacture, 3D print, or assemble because
flattening the network during fabrication introduces multiplicative
inaccuracies in the network's final tension gradients. This study overcomes
this challenge by offering a fabrication algorithm for direct 3D printing of
such networks with programmed tension gradients, an approach analogous to the
spinning of spiderwebs. The algorithm: (i) defines the desired network and
prescribes its tension gradients using the force density method; (ii) converts
the network into an unstretched counterpart by numerically optimizing vertex
locations toward target element lengths and converting straight elements into
arcs to resolve any remaining error; and (iii) decomposes the network into
printable toolpaths; Optional additional steps are: (iv) flattening curved 2D
networks or 3D networks to ensure 3D printing compatibility; and (v)
automatically resolving any unwanted crossings introduced by the flattening
process. The proposed method is experimentally validated using 2D unit cells of
viscoelastic filaments, where accurate tension gradients are achieved with an
average element strain error of less than 1.0\%. The method remains effective
for networks with element minimum length and maximum stress of 5.8 mm and 7.3
MPa, respectively. The method is used to demonstrate the fabrication of three
complex cases: a flat spiderweb, a curved mesh, and a tensegrity system. The
programmable tension gradient algorithm can be utilized to produce compact,
integrated cable networks, enabling novel applications such as moment-exerting
structures in medical braces and splints.

</details>


### [602] [From Rigging to Waving: 3D-Guided Diffusion for Natural Animation of Hand-Drawn Characters](https://arxiv.org/abs/2509.06573)
*Jie Zhou,Linzi Qu,Miu-Ling Lam,Hongbo Fu*

Main category: cs.GR

TL;DR: 本研究提出了一种结合骨骼动画和视频扩散模型的方法，用于生成几何一致且动态自然的中国风手绘动画。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统骨骼动画在处理非刚性元素（如头发、裙子）时变形不自然，以及视频扩散模型在手绘风格动画中存在几何失真和领域差距的问题，本研究提出了一种混合动画系统。

Method: 该系统首先利用骨骼动画对角色进行重定向，生成具有几何引导的粗糙图像。然后，将视频扩散模型作为图像修复任务，利用其纹理和二级动态先验来增强这些图像。通过领域自适应扩散模型来优化用户掩蔽的区域，特别关注二级动态。为了提升运动的真实感，研究中引入了一种在去噪过程中注入二级动态（SDI）的策略，该策略整合了一个预训练的、具有人类运动先验的扩散模型的特征。此外，为了解决低多边形单网格角色建模导致的变形不自然问题，提出了一种头发分层建模（HLM）技术，利用分割图将头发与身体分离，从而实现更自然的头发动画。

Result: 通过大量实验表明，本研究提出的系统在定量和定性评估方面均优于现有最先进的方法。

Conclusion: 本研究提出的混合动画系统成功地结合了骨骼动画的几何一致性和视频扩散模型的动态表现力，并通过SDI和HLM等创新技术解决了现有方法的局限性，为生成高质量的手绘动画提供了新的解决方案。

Abstract: Hand-drawn character animation is a vibrant field in computer graphics,
presenting challenges in achieving geometric consistency while conveying
expressive motion. Traditional skeletal animation methods maintain geometric
consistency but struggle with complex non-rigid elements like flowing hair and
skirts, leading to unnatural deformation. Conversely, video diffusion models
synthesize realistic dynamics but often create geometric distortions in
stylized drawings due to domain gaps. This work proposes a hybrid animation
system that combines skeletal animation and video diffusion. Initially, coarse
images are generated from characters retargeted with skeletal animations for
geometric guidance. These images are then enhanced in texture and secondary
dynamics using video diffusion priors, framing this enhancement as an
inpainting task. A domain-adapted diffusion model refines user-masked regions
needing improvement, especially for secondary dynamics. To enhance motion
realism further, we introduce a Secondary Dynamics Injection (SDI) strategy in
the denoising process, incorporating features from a pre-trained diffusion
model enriched with human motion priors. Additionally, to tackle unnatural
deformations from low-poly single-mesh character modeling, we present a Hair
Layering Modeling (HLM) technique that uses segmentation maps to separate hair
from the body, allowing for more natural animation of long-haired characters.
Extensive experiments show that our system outperforms state-of-the-art methods
in both quantitative and qualitative evaluations.

</details>


### [603] [From Skin to Skeleton: Towards Biomechanically Accurate 3D Digital Humans](https://arxiv.org/abs/2509.06607)
*Marilyn Keller,Keenon Werling,Soyong Shin,Scott Delp,Sergi Pujades,C. Karen Liu,Michael J. Black*

Main category: cs.GR

TL;DR: 开发了一个名为SKEL的新模型，通过重新绑定SMPL模型并使用生物力学准确的骨骼结构，实现了更逼真的人体姿态和形状估计，解决了现有模型在生物力学应用中的局限性，并能将现有数据集升级以包含生物力学参数。


<details>
  <summary>Details</summary>
Motivation: 现有的参数化人体模型（如SMPL）的运动学结构过于简化，与真实的人体骨骼系统不符，限制了其在生物力学中的应用。而现有的生物力学运动估计方法依赖于复杂和昂贵的动作捕捉系统。因此，需要一个具有生物力学准确骨骼结构且易于摆放姿势的参数化人体模型。

Method: 1. 通过优化AMASS序列中的SMPL网格体内的生物力学准确骨骼，构建了一个包含多样化姿势的骨骼数据集。 2. 学习了一个从SMPL网格顶点到优化后的关节位置和骨骼旋转的回归器。 3. 使用新的运动学参数重新参数化SMPL网格。

Result: SKEL模型像SMPL一样易于驱动，但具有更少且符合生物力学现实的自由度。SKEL的关节位置比SMPL更符合生物力学，骨骼在身体表面内的贴合度也优于以往方法。通过将SKEL拟合到SMPL网格，可以升级现有的人体姿态和形状数据集，使其包含生物力学参数。

Conclusion: SKEL模型为“野外”生物力学研究提供了一个新工具，同时也为计算机视觉和图形学研究者提供了一个约束更佳、更真实的人体关节模型。该模型、代码和数据均可用于研究。

Abstract: Great progress has been made in estimating 3D human pose and shape from
images and video by training neural networks to directly regress the parameters
of parametric human models like SMPL. However, existing body models have
simplified kinematic structures that do not correspond to the true joint
locations and articulations in the human skeletal system, limiting their
potential use in biomechanics. On the other hand, methods for estimating
biomechanically accurate skeletal motion typically rely on complex motion
capture systems and expensive optimization methods. What is needed is a
parametric 3D human model with a biomechanically accurate skeletal structure
that can be easily posed. To that end, we develop SKEL, which re-rigs the SMPL
body model with a biomechanics skeleton. To enable this, we need training data
of skeletons inside SMPL meshes in diverse poses.
  We build such a dataset by optimizing biomechanically accurate skeletons
inside SMPL meshes from AMASS sequences. We then learn a regressor from SMPL
mesh vertices to the optimized joint locations and bone rotations. Finally, we
re-parametrize the SMPL mesh with the new kinematic parameters. The resulting
SKEL model is animatable like SMPL but with fewer, and
biomechanically-realistic, degrees of freedom. We show that SKEL has more
biomechanically accurate joint locations than SMPL, and the bones fit inside
the body surface better than previous methods. By fitting SKEL to SMPL meshes
we are able to "upgrade" existing human pose and shape datasets to include
biomechanical parameters. SKEL provides a new tool to enable biomechanics in
the wild, while also providing vision and graphics researchers with a better
constrained and more realistic model of human articulation. The model, code,
and data are available for research at https://skel.is.tue.mpg.de..

</details>


### [604] [Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data](https://arxiv.org/abs/2509.06950)
*Nithin Gopalakrishnan Nair,Srinivas Kaza,Xuan Luo,Vishal M. Patel,Stephen Lombardi,Jungyeon Park*

Main category: cs.GR

TL;DR: 通过引入扩散模型生成的合成数据并结合token解耦技术，改进了新视角合成（NVS）模型的泛化能力和重建质量，实现了最先进的性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大型transformer模型在通用新视角合成（NVS）方面取得了进展，但受限于公开数据集的多样性，导致在真实世界场景中表现不佳。同时，合成数据的生成也可能引入伪影，影响重建质量。

Method: 提出了一种新的方法，结合了扩散模型生成的合成数据和Transformer架构中的token解耦过程。token解耦旨在改善特征分离，从而更有效地学习。

Result: 所提出的方法在数据集内和跨数据集评估中均优于现有模型，在多个基准测试中取得了最先进的结果，并显著降低了计算成本。

Conclusion: 通过结合合成数据和token解耦技术，所提出的方法提高了NVS模型的泛化能力和重建质量，克服了现有方法的局限性，并实现了最先进的性能。

Abstract: Large transformer-based models have made significant progress in
generalizable novel view synthesis (NVS) from sparse input views, generating
novel viewpoints without the need for test-time optimization. However, these
models are constrained by the limited diversity of publicly available scene
datasets, making most real-world (in-the-wild) scenes out-of-distribution. To
overcome this, we incorporate synthetic training data generated from diffusion
models, which improves generalization across unseen domains. While synthetic
data offers scalability, we identify artifacts introduced during data
generation as a key bottleneck affecting reconstruction quality. To address
this, we propose a token disentanglement process within the transformer
architecture, enhancing feature separation and ensuring more effective
learning. This refinement not only improves reconstruction quality over
standard transformers but also enables scalable training with synthetic data.
As a result, our method outperforms existing models on both in-dataset and
cross-dataset evaluations, achieving state-of-the-art results across multiple
benchmarks while significantly reducing computational costs. Project page:
https://scaling3dnvs.github.io/

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [605] [SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips](https://arxiv.org/abs/2509.05532)
*Changxu Song,Arda Caliskan,Beyza Zeynep Ucpinar,Yasemin Kopur,Mustafa Altay Karamuftuoglu,Sasan Razmkhah,Shahin Nazarian,Massoud Pedram*

Main category: cs.ET

TL;DR: 设计了一个名为SuperSNN的框架，用于在制造限制下实现超导神经网络（SNN），在MNIST数据集上达到了96.47%的准确率，并在实际芯片上实现了80.07%的准确率，同时保持了3.02 GHz的时钟频率和极低的功耗。


<details>
  <summary>Details</summary>
Motivation: 尽管已提出多种SNN设计，但大多忽略了实际制造限制，导致实现规模受限。当前超导技术（如MIT LL SFQ5ee）对芯片面积、布线和I/O引脚数量有严格限制，严重制约了网络规模和复杂性。因此，需要一个全面的框架来在满足物理实现能力的前提下，最大限度地减少准确率损失。

Method: 提出SuperSNN框架，包含：1. 硬件感知训练方法，通过片外剪枝和权重量化实现节能超导SNN。2. 推理SNN芯片设计和布局，采用新型高扇入神经元和定制超导单元。3. 优化的LAGS（局部同步，全局同步）时钟分发方案，以实现鲁棒的电路实现和SFQ SNN中的数据传输延迟管理。

Result: 1. 完整网络在量化和剪枝后，于MNIST数据集上达到96.47%的准确率。2. 制造的SuperSNN芯片成功分类了简化数字集（2、3、4），准确率为80.07%，对数字（0、1、2）准确率最高达到86.2%。3. 芯片运行频率高达3.02 GHz。4. 芯片尺寸为3.4 x 3.9 mm^2，包含5822个约瑟夫森结，静态功耗为2.15 mW，每次推理的能耗极低，为6.55 fJ。

Conclusion: SuperSNN框架成功地在实际制造限制下实现了全SNN芯片，在保持极高时钟频率和极低能耗的同时，实现了有竞争力的准确率。

Abstract: Despite numerous proposed designs for superconducting neural networks (SNNs),
most have overlooked practical fabrication constraints, leading to
implementations limited to only a few neurons or synapses. Current
superconducting technologies, such as MIT LL SFQ5ee, impose severe limitations
on chip area, routing, and input/output pin counts (e.g., 5x5 mm^2 chip with 40
pins), drastically restricting network size and complexity. These hardware
constraints necessitate a comprehensive framework to tailor network designs for
physical realizability while minimizing accuracy loss. This paper introduces
SuperSNN, a comprehensive framework for the implementation of full
superconducting SNNs on a chip within these constraints. The key technical
contributions include: (1) A hardware-aware training methodology for SNNs,
utilizing off-chip pruning and weight quantization for energy-efficient
superconducting implementations. (2) Design and layout of an inference SNN chip
that incorporates novel high fan-in neurons and custom superconducting cells.
(3) An optimized locally synchronous, globally synchronous (LAGS) clock
distribution scheme for robust circuit implementation and management of data
transfer delays in SFQ SNNs. The main results and findings demonstrate the
effectiveness of the framework: (1) The complete network achieved 96.47%
accuracy on the full MNIST dataset after quantization and pruning. (2) The
fabricated SuperSNN chip successfully classified a reduced set of digits (2, 3,
and 4) with 80.07% accuracy, reaching a maximum of 86.2% accuracy for digits 0,
1, and 2. (3) The chip operates at an ultra-high 3.02 GHz clock frequency. (4)
It occupies a compact area of 3.4 x 3.9 mm^2, incorporates 5,822 Josephson
Junctions, consumes 2.15 mW static power, and has an exceptionally low energy
cost of 6.55 fJ (or 1.31e-6 nJ) per inference.

</details>
