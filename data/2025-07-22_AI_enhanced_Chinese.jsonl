{"id": "2507.14650", "categories": ["cs.LO", "I.2.3, I.2.4", "F.4"], "pdf": "https://arxiv.org/pdf/2507.14650", "abs": "https://arxiv.org/abs/2507.14650", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "A Proof System with Causal Labels (Part I): checking Individual Fairness and Intersectionality", "comment": null, "summary": "In this article we propose an extension to the typed natural deduction\ncalculus TNDPQ to model verification of individual fairness and\nintersectionality in probabilistic classifiers. Their interpretation is\nobtained by formulating specific conditions for the application of the\nstructural rule of Weakening. Such restrictions are given by causal labels used\nto check for conditional independence between protected and target variables.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTNDPQ\u7684\u6f14\u7b97\uff0c\u901a\u8fc7\u56e0\u679c\u6807\u7b7e\u548c\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u67e5\u6765\u9a8c\u8bc1\u6982\u7387\u5206\u7c7b\u5668\u7684\u516c\u5e73\u6027\u548c\u4ea4\u53c9\u6027\u3002", "motivation": "\u5bf9\u6982\u7387\u5206\u7c7b\u5668\u4e2d\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u4ea4\u53c9\u6027\u8fdb\u884c\u5efa\u6a21\u548c\u9a8c\u8bc1\u3002", "method": "\u901a\u8fc7\u5236\u5b9a\u7279\u5b9a\u7684\u7ed3\u6784\u89c4\u5219\uff08Weakening\uff09\u5e94\u7528\u6761\u4ef6\u6765\u5b9e\u73b0\u89e3\u91ca\uff0c\u8fd9\u4e9b\u6761\u4ef6\u7531\u56e0\u679c\u6807\u7b7e\u7ed9\u51fa\uff0c\u7528\u4e8e\u68c0\u67e5\u53d7\u4fdd\u62a4\u53d8\u91cf\u548c\u76ee\u6807\u53d8\u91cf\u4e4b\u95f4\u7684\u6761\u4ef6\u72ec\u7acb\u6027\u3002", "result": "\u6210\u529f\u5730\u5bf9\u6982\u7387\u5206\u7c7b\u5668\u4e2d\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u4ea4\u53c9\u6027\u8fdb\u884c\u4e86\u5efa\u6a21\u548c\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684\u7c7b\u578b\u5316\u81ea\u7136\u63a8\u7406\u6f14\u7b97TNDPQ\uff0c\u7528\u4e8e\u5bf9\u6982\u7387\u5206\u7c7b\u5668\u4e2d\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u4ea4\u53c9\u6027\u8fdb\u884c\u5efa\u6a21\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2507.14655", "categories": ["cs.LO", "I.2.3, I.2.4", "F.4"], "pdf": "https://arxiv.org/pdf/2507.14655", "abs": "https://arxiv.org/abs/2507.14655", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "A Proof System with Causal Labels (Part II): checking Counterfactual Fairness", "comment": null, "summary": "In this article we propose an extension to the typed natural deduction\ncalculus TNDPQ to model verification of counterfactual fairness in\nprobabilistic classifiers. This is obtained formulating specific structural\nconditions for causal labels and checking that evaluation is robust under their\nvariation.", "AI": {"tldr": "The paper extends TNDPQ to verify counterfactual fairness in probabilistic classifiers by checking causal label variations.", "motivation": "To model verification of counterfactual fairness in probabilistic classifiers.", "method": "Formulating specific structural conditions for causal labels and checking that evaluation is robust under their variation.", "result": "An extension to the typed natural deduction calculus TNDPQ.", "conclusion": "The proposed extension to TNDPQ allows for the verification of counterfactual fairness in probabilistic classifiers by formulating structural conditions for causal labels and checking robustness under their variation."}}
{"id": "2507.14949", "categories": ["cs.LO", "03B45, 68Q17", "F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2507.14949", "abs": "https://arxiv.org/abs/2507.14949", "authors": ["Philippe Balbiani", "Olivier Gasquet"], "title": "PSPACE-completeness of bimodal transitive weak-density logic", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.11238", "summary": "Windows have been introduce in \\cite{BalGasq25} as a tool for designing\npolynomial algorithms to check satisfiability of a bimodal logic of\nweak-density. In this paper, after revisiting the ``folklore'' case of bimodal\n$\\K4$ already treated in \\cite{Halpern} but which is worth a fresh review, we\nshow that windows allow to polynomially solve the satisfiability problem when\nadding transitivity to weak-density, by mixing algorithms for bimodal K\ntogether with windows-approach. The conclusion is that both satisfiability and\nvalidity are PSPACE-complete for these logics.", "AI": {"tldr": "Windows, introduced for designing polynomial algorithms for checking satisfiability of a bimodal logic of weak-density, are used to polynomially solve the satisfiability problem when adding transitivity to weak-density. Both satisfiability and validity are PSPACE-complete for these logics.", "motivation": "Revisiting the 'folklore' case of bimodal K4 and showing that windows allow to polynomially solve the satisfiability problem when adding transitivity to weak-density.", "method": "Windows are used to polynomially solve the satisfiability problem for bimodal logic with transitivity and weak-density, by mixing algorithms for bimodal K with the windows-approach.", "result": "Windows allow to polynomially solve the satisfiability problem when adding transitivity to weak-density, by mixing algorithms for bimodal K together with windows-approach.", "conclusion": "Both satisfiability and validity are PSPACE-complete for these logics."}}
{"id": "2507.14956", "categories": ["cs.LO", "03B45, 68Q17", "F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2507.14956", "abs": "https://arxiv.org/abs/2507.14956", "authors": ["Olivier Gasquet"], "title": "PSPACE-completeness of Grammar logics of bounded density", "comment": null, "summary": "We introduce the family of multi-modal logics of bounded density and with a\ntableau-like approach using finite \\emph{windows} which were introduced in\n\\cite{BalGasq25}, we prove that their satisfiability problem is\nPSPACE-complete. As a side effect, the monomodal logic of density is shown to\nbe in para-PSPACE.", "AI": {"tldr": "Multi-modal logics of bounded density with finite windows are PSPACE-complete. Monomodal logic of density is para-PSPACE.", "motivation": "Introduction of the family of multi-modal logics of bounded density.", "method": "A tableau-like approach using finite windows.", "result": "The satisfiability problem for the family of multi-modal logics of bounded density is PSPACE-complete. The monomodal logic of density is shown to be in para-PSPACE.", "conclusion": "The satisfiability problem for the family of multi-modal logics of bounded density is PSPACE-complete. As a side effect, the monomodal logic of density is shown to be in para-PSPACE."}}
{"id": "2507.14392", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.14392", "abs": "https://arxiv.org/abs/2507.14392", "authors": ["Lang Xu", "Kaushik Kandadi Suresh", "Quentin Anthony", "Nawras Alnaasan", "Dhabaleswar K. Panda"], "title": "Characterizing Communication Patterns in Distributed Large Language Model Inference", "comment": "To be presented at Hot Interconnects 2025", "summary": "Large Language Models (LLMs) built on transformer architectures have\ntransformed natural language processing, achieving remarkable performance\nacross diverse applications. While distributed inference frameworks enable\npractical deployment of these models, inter-GPU communication creates\nsignificant performance constraints that limit service quality in real-world\nsystems. This paper investigates communication dynamics in distributed LLM\nserving-analyzing how various parallelization approaches coordinate data\nexchange between GPU workers during inference. We study dense transformer-based\nmodels as representative examples of contemporary architectures widely used in\noperational deployments. Our work combines detailed profiling measurements with\npredictive analytical models to characterize communication behavior across\ndifferent parallelization configurations. Results show that tensor parallelism\nincurs substantial network overhead but delivers superior response times for\nbrief sequences, pipeline parallelism minimizes data transfer requirements\nwhile increasing total latency, and combined approaches demand careful tuning\nto achieve balanced performance. These insights offer practical recommendations\nfor selecting appropriate parallelization schemes in production LLM services\nand identify key opportunities for optimizing inference frameworks and\ncommunication infrastructure.", "AI": {"tldr": "\u5206\u5e03\u5f0fLLM\u670d\u52a1\u4e2d\uff0c\u5f20\u91cf\u5e76\u884c\u901f\u5ea6\u5feb\u4f46\u901a\u4fe1\u5f00\u9500\u5927\uff0c\u6d41\u6c34\u7ebf\u5e76\u884c\u901a\u4fe1\u5f00\u9500\u5c0f\u4f46\u901f\u5ea6\u6162\uff0c\u6df7\u5408\u5e76\u884c\u9700\u4ed4\u7ec6\u8c03\u6574\u3002", "motivation": "\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5206\u5e03\u5f0f\u670d\u52a1\u4e2d\uff0c\u8de8GPU\u901a\u4fe1\u6210\u4e3a\u5f71\u54cd\u670d\u52a1\u8d28\u91cf\u548c\u6027\u80fd\u7684\u5173\u952e\u74f6\u9888\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8be6\u7ec6\u7684\u6027\u80fd\u5206\u6790\u6d4b\u91cf\u548c\u9884\u6d4b\u6027\u5206\u6790\u6a21\u578b\uff0c\u7814\u7a76\u4e86\u4e0d\u540c\u5e76\u884c\u5316\u65b9\u6cd5\uff08\u5f20\u91cf\u5e76\u884c\u3001\u6d41\u6c34\u7ebf\u5e76\u884c\u53ca\u6df7\u5408\u65b9\u6cd5\uff09\u5728\u5206\u5e03\u5f0fLLM\u670d\u52a1\u4e2d\u7684\u901a\u4fe1\u884c\u4e3a\u548c\u6027\u80fd\u7279\u5f81\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f20\u91cf\u5e76\u884c\u4f1a\u5e26\u6765\u663e\u8457\u7684\u7f51\u7edc\u5f00\u9500\u4f46\u80fd\u4e3a\u77ed\u5e8f\u5217\u63d0\u4f9b\u66f4\u4f18\u7684\u54cd\u5e94\u65f6\u95f4\uff1b\u6d41\u6c34\u7ebf\u5e76\u884c\u5219\u80fd\u6700\u5c0f\u5316\u6570\u636e\u4f20\u8f93\u91cf\u4f46\u4f1a\u589e\u52a0\u603b\u5ef6\u8fdf\uff1b\u6df7\u5408\u5e76\u884c\u65b9\u6848\u5219\u9700\u8981\u7ec6\u81f4\u7684\u53c2\u6570\u8c03\u6574\u4ee5\u8fbe\u5230\u6027\u80fd\u5e73\u8861\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u751f\u4ea7\u73af\u5883\u4e0b\u7684LLM\u670d\u52a1\u63d0\u4f9b\u4e86\u5b9e\u9645\u7684\u5e76\u884c\u5316\u65b9\u6848\u9009\u62e9\u5efa\u8bae\uff0c\u5e76\u6307\u660e\u4e86\u4f18\u5316\u63a8\u7406\u6846\u67b6\u548c\u901a\u4fe1\u7684\u6f5c\u5728\u65b9\u5411\u3002", "conclusion": "LLM\u5206\u5e03\u5f0f\u670d\u52a1\u7684\u5e76\u884c\u5316\u65b9\u6848\u9009\u62e9\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u8fdb\u884c\u6743\u8861\uff0c\u4f8b\u5982\uff0c\u5bf9\u4e8e\u9700\u8981\u4f4e\u54cd\u5e94\u65f6\u95f4\u7684\u77ed\u5e8f\u5217\u63a8\u7406\uff0c\u5f20\u91cf\u5e76\u884c\u53ef\u80fd\u66f4\u4f18\uff1b\u800c\u5bf9\u4e8e\u6ce8\u91cd\u6570\u636e\u4f20\u8f93\u6548\u7387\u7684\u573a\u666f\uff0c\u6d41\u6c34\u7ebf\u5e76\u884c\u5219\u80fd\u66f4\u597d\u5730\u6ee1\u8db3\u9700\u6c42\u3002\u672a\u6765\u7684\u4f18\u5316\u65b9\u5411\u5305\u62ec\u6539\u8fdb\u63a8\u7406\u6846\u67b6\u548c\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2507.14249", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14249", "abs": "https://arxiv.org/abs/2507.14249", "authors": ["Yuejiao Xie", "Maonan Wang", "Di Zhou", "Man-On Pun", "Zhu Han"], "title": "Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach", "comment": null, "summary": "Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions\nto alleviate urban congestion, with path planning becoming a key focus area.\nUnlike ground transportation, UAM trajectory planning has to prioritize\ncommunication quality for accurate location tracking in constantly changing\nenvironments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,\nrequires adaptive planning to respond to real-time passenger requests,\nespecially in ride-sharing scenarios where passenger demands are unpredictable\nand dynamic. However, conventional trajectory planning strategies based on\npredefined routes lack the flexibility to meet varied passenger ride demands.\nTo address these challenges, this work first proposes constructing a radio map\nto evaluate the communication quality of urban airspace. Building on this, we\nintroduce a novel Multi-Source Hybrid Attention Reinforcement Learning\n(MSHA-RL) framework for the challenge of effectively focusing on passengers and\nUAM locations, which arises from the significant dimensional disparity between\nthe representations. This model first generates the alignment among diverse\ndata sources with large gap dimensions before employing hybrid attention to\nbalance global and local insights, thereby facilitating responsive, real-time\npath planning. Extensive experimental results demonstrate that the approach\nenables communication-compliant trajectory planning, reducing travel time and\nenhancing operational efficiency while prioritizing passenger safety.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MSHA-RL \u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a (UAM) \u7684\u8def\u5f84\u89c4\u5212\u95ee\u9898\u3002\u5b83\u901a\u8fc7\u8003\u8651\u901a\u4fe1\u8d28\u91cf\u548c\u52a8\u6001\u4e58\u5ba2\u9700\u6c42\u6765\u63d0\u9ad8\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a (UAM) \u7cfb\u7edf\u4f5c\u4e3a\u7f13\u89e3\u57ce\u5e02\u62e5\u5835\u7684\u6709\u524d\u9014\u7684\u89e3\u51b3\u65b9\u6848\u6b63\u5728\u8fc5\u901f\u51fa\u73b0\uff0c\u4f46\u5176\u8f68\u8ff9\u89c4\u5212\u9762\u4e34\u72ec\u7279\u6311\u6218\uff1a1. \u4e0e\u5730\u9762\u4ea4\u901a\u4e0d\u540c\uff0cUAM \u8f68\u8ff9\u89c4\u5212\u5fc5\u987b\u4f18\u5148\u8003\u8651\u901a\u4fe1\u8d28\u91cf\u4ee5\u5728\u4e0d\u65ad\u53d8\u5316\u7684\u73af\u5883\u4e2d\u8fdb\u884c\u51c6\u786e\u5b9a\u4f4d\uff0c\u4ece\u800c\u786e\u4fdd\u5b89\u5168\u30022. UAM \u7cfb\u7edf\u9700\u8981\u81ea\u9002\u5e94\u89c4\u5212\u4ee5\u54cd\u5e94\u5b9e\u65f6\u4e58\u5ba2\u8bf7\u6c42\uff0c\u5c24\u5176\u662f\u5728\u4e58\u5ba2\u9700\u6c42\u4e0d\u53ef\u9884\u6d4b\u548c\u52a8\u6001\u7684\u62fc\u8f66\u573a\u666f\u4e2d\u30023. \u4f20\u7edf\u7684\u57fa\u4e8e\u9884\u5b9a\u4e49\u8def\u7ebf\u7684\u8f68\u8ff9\u89c4\u5212\u7b56\u7565\u7f3a\u4e4f\u6ee1\u8db3\u591a\u6837\u5316\u4e58\u5ba2\u51fa\u884c\u9700\u6c42\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u6784\u5efa\u65e0\u7ebf\u7535\u56fe\u6765\u8bc4\u4f30\u57ce\u5e02\u7a7a\u57df\u7684\u901a\u4fe1\u8d28\u91cf\u3002\u7136\u540e\uff0c\u5f15\u5165\u591a\u6e90\u6df7\u5408\u6ce8\u610f\u529b\u5f3a\u5316\u5b66\u4e60\uff08MSHA-RL\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u9996\u5148\u751f\u6210\u5bf9\u9f50\u8de8\u8d8a\u5de8\u5927\u7ef4\u5ea6\u5dee\u5f02\u7684\u591a\u79cd\u6570\u636e\u6e90\uff0c\u7136\u540e\u91c7\u7528\u6df7\u5408\u6ce8\u610f\u529b\u6765\u5e73\u8861\u5168\u5c40\u548c\u5c40\u90e8\u89c1\u89e3\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u4e58\u5ba2\u548c UAM \u4f4d\u7f6e\u7684\u6709\u6548\u5173\u6ce8\uff0c\u6700\u7ec8\u5b9e\u73b0\u54cd\u5e94\u53ca\u65f6\u7684\u5b9e\u65f6\u8def\u5f84\u89c4\u5212\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u901a\u4fe1\u517c\u5bb9\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u7f29\u77ed\u65c5\u884c\u65f6\u95f4\u5e76\u63d0\u9ad8\u8fd0\u8425\u6548\u7387\uff0c\u540c\u65f6\u4f18\u5148\u8003\u8651\u4e58\u5ba2\u5b89\u5168\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6e90\u6df7\u5408\u6ce8\u610f\u529b\u5f3a\u5316\u5b66\u4e60\uff08MSHA-RL\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a (UAM) \u7684\u8f68\u8ff9\u89c4\u5212\u3002\u8be5\u6846\u67b6\u80fd\u591f\u5904\u7406\u901a\u4fe1\u8d28\u91cf\u548c\u52a8\u6001\u4e58\u5ba2\u9700\u6c42\u7b49\u6311\u6218\uff0c\u901a\u8fc7\u6784\u5efa\u65e0\u7ebf\u7535\u56fe\u8bc4\u4f30\u57ce\u5e02\u7a7a\u57df\u7684\u901a\u4fe1\u8d28\u91cf\uff0c\u5e76\u5229\u7528\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\u5728\u4e0d\u540c\u6570\u636e\u6e90\u4e4b\u95f4\u8fdb\u884c\u5bf9\u9f50\uff0c\u4ece\u800c\u5b9e\u73b0\u5177\u6709\u901a\u4fe1\u517c\u5bb9\u6027\u3001\u7f29\u77ed\u65c5\u884c\u65f6\u95f4\u548c\u63d0\u9ad8\u8fd0\u8425\u6548\u7387\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u540c\u65f6\u4f18\u5148\u8003\u8651\u4e58\u5ba2\u5b89\u5168\u3002"}}
{"id": "2507.14268", "categories": ["cs.CV", "cond-mat.mtrl-sci", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.14268", "abs": "https://arxiv.org/abs/2507.14268", "authors": ["Andreas Alpers", "Orkun Furat", "Christian Jung", "Matthias Neumann", "Claudia Redenbach", "Aigerim Saken", "Volker Schmidt"], "title": "Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data", "comment": "31 pages, 16 figures, 8 tables", "summary": "This paper presents a comparative analysis of algorithmic strategies for\nfitting tessellation models to 3D image data of materials such as polycrystals\nand foams. In this steadily advancing field, we review and assess\noptimization-based methods -- including linear and nonlinear programming,\nstochastic optimization via the cross-entropy method, and gradient descent --\nfor generating Voronoi, Laguerre, and generalized balanced power diagrams\n(GBPDs) that approximate voxelbased grain structures. The quality of fit is\nevaluated on real-world datasets using discrepancy measures that quantify\ndifferences in grain volume, surface area, and topology. Our results highlight\ntrade-offs between model complexity, the complexity of the optimization\nroutines involved, and the quality of approximation, providing guidance for\nselecting appropriate methods based on data characteristics and application\nneeds.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u7528\u4e8e\u6750\u6599\u4e09\u7ef4\u56fe\u50cf\u6570\u636e\u7684\u9576\u5d4c\u6a21\u578b\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u4e3a\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5bf9\u7528\u4e8e\u62df\u5408\u6676\u4f53\u548c\u6ce1\u6cab\u7b49\u6750\u6599\u7684\u4e09\u7ef4\u56fe\u50cf\u6570\u636e\u7684\u9576\u5d4c\u6a21\u578b\u7b97\u6cd5\u7b56\u7565\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "method": "\u672c\u7814\u7a76\u56de\u987e\u5e76\u8bc4\u4f30\u4e86\u7528\u4e8e\u751f\u6210Voronoi\u3001Laguerre\u548c\u5e7f\u4e49\u5e73\u8861\u5e42\u56fe\uff08GBPD\uff09\u4ee5\u8fd1\u4f3c\u57fa\u4e8e\u4f53\u7d20\u7684\u6676\u7c92\u7ed3\u6784\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u7ebf\u6027\u89c4\u5212\u3001\u975e\u7ebf\u6027\u89c4\u5212\u3001\u901a\u8fc7\u4ea4\u53c9\u71b5\u65b9\u6cd5\u8fdb\u884c\u7684\u968f\u673a\u4f18\u5316\u548c\u68af\u5ea6\u4e0b\u964d\u3002", "result": "\u672c\u7814\u7a76\u7684\u7ed3\u679c\u5f3a\u8c03\u4e86\u6a21\u578b\u590d\u6742\u6027\u3001\u4f18\u5316\u4f8b\u7a0b\u590d\u6742\u6027\u548c\u8fd1\u4f3c\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u6839\u636e\u6570\u636e\u7279\u6027\u548c\u5e94\u7528\u9700\u6c42\u4e3a\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "\u672c\u7814\u7a76\u5bf9\u7528\u4e8e\u62df\u5408\u6676\u7c92\u548c\u6ce1\u6cab\u7b49\u6750\u6599\u76843D\u56fe\u50cf\u6570\u636e\u7684\u9576\u5d4c\u6a21\u578b\u7684\u7b97\u6cd5\u7b56\u7565\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002\u8bc4\u4f30\u4e86\u5305\u62ec\u7ebf\u6027\u89c4\u5212\u3001\u975e\u7ebf\u6027\u89c4\u5212\u3001\u4ea4\u53c9\u71b5\u65b9\u6cd5\u968f\u673a\u4f18\u5316\u548c\u68af\u5ea6\u4e0b\u964d\u7b49\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8fd1\u4f3c\u57fa\u4e8e\u4f53\u7d20\u7684\u6676\u7c92\u7ed3\u6784\u7684Voronoi\u3001Laguerre\u548c\u5e7f\u4e49\u5e73\u8861\u5e42\u56fe\uff08GBPD\uff09\u3002\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u5dee\u5f02\u5ea6\u91cf\u8bc4\u4f30\u62df\u5408\u8d28\u91cf\uff0c\u8fd9\u4e9b\u5ea6\u91cf\u91cf\u5316\u4e86\u6676\u7c92\u4f53\u79ef\u3001\u8868\u9762\u79ef\u548c\u62d3\u6251\u7ed3\u6784\u7684\u5dee\u5f02\u3002\u7ed3\u679c\u5f3a\u8c03\u4e86\u6a21\u578b\u590d\u6742\u6027\u3001\u6240\u6d89\u53ca\u7684\u4f18\u5316\u4f8b\u7a0b\u590d\u6742\u6027\u4ee5\u53ca\u8fd1\u4f3c\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u6839\u636e\u6570\u636e\u7279\u6027\u548c\u5e94\u7528\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.14154", "categories": ["cs.AI", "cs.LG", "68T05, 81P68", "I.2.6; I.2.0; F.1.2"], "pdf": "https://arxiv.org/pdf/2507.14154", "abs": "https://arxiv.org/abs/2507.14154", "authors": ["Rahul Kabali"], "title": "The Free Will Equation: Quantum Field Analogies for AGI", "comment": "22 pages, 5 figures. Submitted as an arXiv preprint. All code and\n  experiment details included in appendix", "summary": "Artificial General Intelligence (AGI) research traditionally focuses on\nalgorithms that optimize for specific goals under deterministic rules. Yet,\nhuman-like intelligence exhibits adaptive spontaneity - an ability to make\nunexpected choices or free decisions not strictly dictated by past data or\nimmediate reward. This trait, often dubbed \"free will\" in a loose sense, might\nbe crucial for creativity, robust adaptation, and avoiding ruts in\nproblem-solving. This paper proposes a theoretical framework, called the Free\nWill Equation, that draws analogies from quantum field theory to endow AGI\nagents with a form of adaptive, controlled stochasticity in their\ndecision-making process. The core idea is to treat an AI agent's cognitive\nstate as a superposition of potential actions or thoughts, which collapses\nprobabilistically into a concrete action when a decision is made - much like a\nquantum wavefunction collapsing upon measurement. By incorporating mechanisms\nanalogous to quantum fields, along with intrinsic motivation terms, we aim to\nimprove an agent's ability to explore novel strategies and adapt to unforeseen\nchanges. Experiments in a non-stationary multi-armed bandit environment\ndemonstrate that agents using this framework achieve higher rewards and policy\ndiversity compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u201d\uff0c\u501f\u9274\u91cf\u5b50\u573a\u8bba\uff0c\u4e3aAGI\u5f15\u5165\u51b3\u7b56\u7684\u968f\u673a\u6027\uff0c\u4ee5\u589e\u5f3a\u5176\u521b\u9020\u529b\u548c\u9002\u5e94\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\u6b64\u65b9\u6cd5\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u5177\u5907\u4eba\u7c7b\u667a\u80fd\u4e2d\u7684\u81ea\u53d1\u9002\u5e94\u6027\uff0c\u7279\u522b\u662f\u201c\u81ea\u7531\u610f\u5fd7\u201d\u2014\u2014\u4e00\u79cd\u4e0d\u88ab\u8fc7\u53bb\u6570\u636e\u6216\u5373\u65f6\u5956\u52b1\u4e25\u683c\u51b3\u5b9a\u7684\u3001\u80fd\u505a\u51fa\u610f\u60f3\u4e0d\u5230\u9009\u62e9\u6216\u81ea\u7531\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u4ee5\u589e\u5f3a\u521b\u9020\u529b\u3001\u9c81\u68d2\u9002\u5e94\u6027\u548c\u907f\u514d\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u50f5\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u201d\u7684\u7406\u8bba\u6846\u67b6\uff0c\u501f\u9274\u91cf\u5b50\u573a\u8bba\u7684\u7c7b\u6bd4\uff0c\u5c06\u4eba\u5de5\u667a\u80fd\u7684\u8ba4\u77e5\u72b6\u6001\u89c6\u4e3a\u6f5c\u5728\u884c\u52a8\u6216\u601d\u60f3\u7684\u53e0\u52a0\u6001\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u6027\u5730\u574d\u7f29\u5230\u5177\u4f53\u884c\u52a8\u6765\u6a21\u62df\u51b3\u7b56\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u8fd8\u7ed3\u5408\u4e86\u91cf\u5b50\u573a\u7c7b\u6bd4\u548c\u5185\u7980\u52a8\u673a\u9879\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528\u8be5\u6846\u67b6\u7684\u667a\u80fd\u4f53\u5728\u975e\u5e73\u7a33\u591a\u81c2\u8001\u864e\u673a\u73af\u5883\u4e2d\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u5956\u52b1\u548c\u7b56\u7565\u591a\u6837\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u901a\u8fc7\u5f15\u5165\u53d7\u63a7\u968f\u673a\u6027\uff0c\u6709\u671b\u63d0\u5347\u4eba\u5de5\u667a\u80fd\u5728\u9762\u5bf9\u975e\u56fa\u5b9a\u73af\u5883\u65f6\u7684\u51b3\u7b56\u80fd\u529b\u3001\u7b56\u7565\u65b0\u9896\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.14319", "categories": ["cond-mat.mes-hall", "cond-mat.soft", "nlin.CD", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.14319", "abs": "https://arxiv.org/abs/2507.14319", "authors": ["Alexander D. Muratov", "Vladik A. Avetisov"], "title": "Martini 3 application for the design of bistable nanomachines", "comment": "9 pages, 5 figures, 1 table", "summary": "During our previous modeling using all-atom molecular dynamics, we have\nidentified several foldamers whose nanoscale behavior resembles that of classic\nbistable machines, namely the Euler archs and Duffing oscillators. However,\ntime limitations of the all-atom molecular dynamics prevent us from performing\na full-scale investigation of long-time behavior and prompt us to develop a\ncoarse-grained model. In this work, we summarize our recent research on\ndeveloping such models using the most widely available method called Martini.", "AI": {"tldr": "Researchers developed coarse-grained models using the Martini method to study the long-time behavior of foldamers after all-atom molecular dynamics simulations faced time limitations.", "motivation": "Previous all-atom molecular dynamics modeling identified foldamers resembling bistable machines, but time limitations necessitated the development of a coarse-grained model for long-time behavior investigation.", "method": "The study uses the Martini method to develop coarse-grained models.", "result": "Coarse-grained models were developed using the Martini method.", "conclusion": "The paper summarizes recent research on developing coarse-grained models using the Martini method."}}
{"id": "2507.14658", "categories": ["cs.MA", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14658", "abs": "https://arxiv.org/abs/2507.14658", "authors": ["Faizan Contractor", "Li Li", "Ranwa Al Mallah"], "title": "Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence", "comment": null, "summary": "Popular methods in cooperative Multi-Agent Reinforcement Learning with\npartially observable environments typically allow agents to act independently\nduring execution, which may limit the coordinated effect of the trained\npolicies. However, by sharing information such as known or suspected ongoing\nthreats, effective communication can lead to improved decision-making in the\ncyber battle space. We propose a game design where defender agents learn to\ncommunicate and defend against imminent cyber threats by playing training games\nin the Cyber Operations Research Gym, using the Differentiable Inter Agent\nLearning algorithm adapted to the cyber operational environment. The tactical\npolicies learned by these autonomous agents are akin to those of human experts\nduring incident responses to avert cyber threats. In addition, the agents\nsimultaneously learn minimal cost communication messages while learning their\ndefence tactical policies.", "AI": {"tldr": "\u901a\u8fc7\u5728\u7f51\u7edc\u4f5c\u6218\u7814\u7a76\u6f14\u4e60\u4e2d\u4f7f\u7528\u53ef\u5fae\u5206\u667a\u80fd\u4f53\u5b66\u4e60\u7b97\u6cd5\uff0c\u6211\u4eec\u8bad\u7ec3\u4e86\u80fd\u591f\u901a\u4fe1\u548c\u9632\u5fa1\u7684\u7279\u5de5\uff0c\u4ed6\u4eec\u7684\u7b56\u7565\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5e76\u4e14\u5b66\u4f1a\u4e86\u4f4e\u6210\u672c\u901a\u4fe1\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\uff0c\u5408\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u65b9\u6cd5\u4e2d\uff0c\u7279\u5de5\u72ec\u7acb\u884c\u52a8\u53ef\u80fd\u9650\u5236\u5176\u534f\u8c03\u6548\u5e94\u7684\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u4fe1\u673a\u5236\uff0c\u4ee5\u63d0\u5347\u7f51\u7edc\u6218\u7a7a\u95f4\u7684\u51b3\u7b56\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u53ef\u5fae\u5206\u667a\u80fd\u4f53\u5b66\u4e60\u7b97\u6cd5\uff08Differentiable Inter Agent Learning\uff09\u5728\u7f51\u7edc\u4f5c\u6218\u7814\u7a76\u6f14\u4e60\uff08Cyber Operations Research Gym\uff09\u4e2d\u8bad\u7ec3\u7279\u5de5\uff0c\u4f7f\u5176\u5b66\u4e60\u901a\u4fe1\u548c\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u7279\u5de5\u4eec\u5b66\u4f1a\u4e86\u540c\u65f6\u5b66\u4e60\u6700\u4f4e\u6210\u672c\u7684\u901a\u4fe1\u4fe1\u606f\u548c\u9632\u5fa1\u6218\u672f\u7b56\u7565\uff0c\u4ee5\u5e94\u5bf9\u7f51\u7edc\u5a01\u80c1\u3002", "conclusion": "\u7279\u5de5\u4eec\u5b66\u4f1a\u4e86\u5728\u7f51\u7edc\u653b\u9632\u6f14\u7ec3\u4e2d\u8fdb\u884c\u901a\u4fe1\u548c\u9632\u5fa1\uff0c\u5176\u6218\u672f\u7b56\u7565\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5e94\u5bf9\u7f51\u7edc\u5a01\u80c1\u7684\u7b56\u7565\u76f8\u4f3c\u3002"}}
{"id": "2507.14170", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14170", "abs": "https://arxiv.org/abs/2507.14170", "authors": ["Jaeheun Jung", "Donghun Lee"], "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space", "comment": "ICML 2025 workshop HiLD 2025 (3rd workshop on High-dimensional\n  Learning Dynamics)", "summary": "Structured pruning aims to reduce the size and computational cost of deep\nneural networks by removing entire filters or channels. The traditional\nregularizers such as L1 or Group Lasso and its variants lead to\nmagnitude-biased pruning decisions, such that the filters with small magnitudes\nare likely to be pruned. Also, they often entail pruning results with almost\nzero margin around pruning decision boundary, such that tiny perturbation in a\nfilter magnitude can flip the pruning decision. In this paper, we identify the\nprecise algebraic condition under which pruning operations preserve model\nperformance, and use the condition to construct a novel regularizer defined in\nan extended parameter space via auxiliary catalyst variables. The proposed\nCatalyst regularization ensures fair pruning chance for each filters with\ntheoretically provable zero bias to their magnitude and robust pruning behavior\nachieved by wide-margin bifurcation of magnitudes between the preserved and the\npruned filters. The theoretical properties naturally lead to real-world\neffectiveness, as shown by empirical validations of Catalyst Pruning algorithm.\nPruning results on various datasets and models are superior to state-of-the-art\nfilter pruning methods, and at the same time confirm the predicted robust and\nfair pruning characteristics of Catalyst pruning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Catalyst \u7684\u65b0\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5316\u526a\u679d\u4e2d\u7684\u5e45\u5ea6\u504f\u5dee\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u53d8\u91cf\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6ee4\u6ce2\u5668\u5e45\u5ea6\u7684\u516c\u5e73\u5bf9\u5f85\u548c\u5bbd\u88d5\u7684\u526a\u679d\u51b3\u7b56\u8fb9\u754c\uff0c\u4ece\u800c\u5728\u4fdd\u8bc1\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u526a\u679d\u7684\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCatalyst \u526a\u679d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff08\u5982 L1 \u6216 Group Lasso\uff09\u5b58\u5728\u5e45\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u5373\u503e\u5411\u4e8e\u526a\u6389\u5e45\u5ea6\u5c0f\u7684\u6ee4\u6ce2\u5668\uff0c\u5e76\u4e14\u526a\u679d\u51b3\u7b56\u7684\u8fb9\u754c\u8fc7\u4e8e\u72ed\u7a84\uff0c\u5bb9\u6613\u53d7\u5230\u5fae\u5c0f\u6270\u52a8\u7684\u5f71\u54cd\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u526a\u679d\u540e\u7684\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u79f0\u4e3a Catalyst \u6b63\u5219\u5316\uff0c\u901a\u8fc7\u5728\u6269\u5c55\u53c2\u6570\u7a7a\u95f4\u4e2d\u5f15\u5165\u8f85\u52a9\u50ac\u5316\u53d8\u91cf\u6765\u5b9e\u73b0\u3002\u8be5\u65b9\u6cd5\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u6b63\u5219\u5316\u5668\uff08\u5982 L1 \u6216 Group Lasso \u53ca\u5176\u53d8\u4f53\uff09\u5728\u6ee4\u6ce2\u5668\u526a\u679d\u4e2d\u5b58\u5728\u7684\u5e45\u5ea6\u504f\u5dee\u548c\u526a\u679d\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u7684\u96f6\u8fb9\u9645\u95ee\u9898\u3002", "result": "Catalyst \u526a\u679d\u7b97\u6cd5\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u7684\u6ee4\u6ce2\u5668\u526a\u679d\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86 Catalyst \u526a\u679d\u6240\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u7279\u5f81\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 Catalyst \u6b63\u5219\u5316\u901a\u8fc7\u5728\u6269\u5c55\u53c2\u6570\u7a7a\u95f4\u4e2d\u4f7f\u7528\u8f85\u52a9\u50ac\u5316\u53d8\u91cf\uff0c\u786e\u4fdd\u4e86\u6bcf\u4e2a\u6ee4\u6ce2\u5668\u5177\u6709\u516c\u5e73\u7684\u526a\u679d\u673a\u4f1a\uff0c\u4e14\u7406\u8bba\u4e0a\u53ef\u8bc1\u660e\u5176\u5e45\u5ea6\u6ca1\u6709\u504f\u5dee\uff0c\u5e76\u901a\u8fc7\u4fdd\u7559\u548c\u526a\u679d\u6ee4\u6ce2\u5668\u4e4b\u95f4\u5e45\u5ea6\u7684\u5bbd\u88d5\u533a\u5206\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u526a\u679d\u884c\u4e3a\u3002\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6ee4\u6ce2\u5668\u526a\u679d\u65b9\u6cd5\uff0c\u5e76\u8bc1\u5b9e\u4e86 Catalyst \u526a\u679d\u7684\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.14273", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14273", "abs": "https://arxiv.org/abs/2507.14273", "authors": ["K. M. Borysovska", "N. M. Marchenko", "Yu. Koval", "Yu. N. Podrezov", "S. A. Firstov"], "title": "The fracture toughness of molybdenum at different grain sizes under and since brittle-ductile transition: computer modeling and experiment", "comment": "19 pages, 11 figures", "summary": "The sharp growth of the fracture toughness after brittle-ductile transition\nhappens at grain sizes approximately equal to the plastic zone size. Here we\nanalyze the influence of the grain boundary on the evolution of the ensemble of\ndislocations near the crack tip using dislocation dynamics method. We show\nevidence that for large grain sizes, the size has little effect on the ensemble\nof dislocations and the fracture toughness, but when dislocations reach the\ngrain boundary, distribution of dislocations changes, which leads to increase\nof the fracture toughness.", "AI": {"tldr": "\u6676\u754c\u901a\u8fc7\u6539\u53d8\u4f4d\u9519\u5206\u5e03\u6765\u63d0\u9ad8\u65ad\u88c2\u97e7\u6027\u3002", "motivation": "\u5206\u6790\u6676\u754c\u5bf9\u4f4d\u9519\u7cfb\u6f14\u5316\u548c\u65ad\u88c2\u97e7\u6027\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u4f4d\u9519\u52a8\u529b\u5b66\u65b9\u6cd5\u5206\u6790\u6676\u754c\u5bf9\u88c2\u7eb9\u5c16\u7aef\u4f4d\u9519\u7cfb\u6f14\u5316\u7684\u5f71\u54cd\u3002", "result": "\u5bf9\u4e8e\u5927\u6676\u7c92\u5c3a\u5bf8\uff0c\u6676\u7c92\u5c3a\u5bf8\u5bf9\u4f4d\u9519\u7cfb\u548c\u65ad\u88c2\u97e7\u6027\u5f71\u54cd\u5f88\u5c0f\uff0c\u4f46\u6676\u754c\u4f1a\u6539\u53d8\u4f4d\u9519\u5206\u5e03\uff0c\u4ece\u800c\u63d0\u9ad8\u65ad\u88c2\u97e7\u6027\u3002", "conclusion": "\u6676\u7c92\u5c3a\u5bf8\u63a5\u8fd1\u5851\u6027\u533a\u5c3a\u5bf8\u65f6\uff0c\u65ad\u88c2\u97e7\u6027\u5728\u8106\u6027-\u97e7\u6027\u8f6c\u53d8\u540e\u6025\u5267\u589e\u52a0\u3002\u6676\u754c\u4f1a\u5f71\u54cd\u88c2\u7eb9\u5c16\u7aef\u9644\u8fd1\u4f4d\u9519\u7cfb\u7684\u6f14\u5316\uff0c\u5f53\u4f4d\u9519\u8fbe\u5230\u6676\u754c\u65f6\uff0c\u4f4d\u9519\u5206\u5e03\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u5bfc\u81f4\u65ad\u88c2\u97e7\u6027\u589e\u52a0\u3002"}}
{"id": "2507.14300", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14300", "abs": "https://arxiv.org/abs/2507.14300", "authors": ["Marcelo Jacinto", "Pedro Trindade", "Francisco Rego", "Rita Cunha"], "title": "Distributed consensus-based observer design for target state estimation with bearing measurements", "comment": null, "summary": "This paper introduces a novel distributed consensus-based observer design\nthat enables a group of agents in an undirected communication network to solve\nthe problem of target tracking, where the target is modeled as a chain of\nintegrators of arbitrary order. Each agent is assumed to know its own position\nand simultaneously measure bearing vectors relative to the target. We start by\nintroducing a general continuous time observer design tailored to systems whose\nstate dynamics are modeled as chains of integrators and whose measurement model\nfollows a particular nonlinear but observer-suited form. This design leverages\na correction term that combines innovation and consensus components, allowing\neach agent to broadcast only a part of the state estimate to its neighbours,\nwhich effectively reduces the data flowing across the network. To provide\nuniform exponential stability guarantees, a novel result for a class of\nnonlinear closed-loop systems in a generalized observer form is introduced and\nsubsequently used as the main tool to derive stability conditions on the\nobserver gains. Then, by exploring the properties of orthogonal projection\nmatrices, the proposed design is used to solve the distributed target tracking\nproblem and provide explicit stability conditions that depend on the\ntarget-agents geometric formation. Practical examples are derived for a target\nmodeled as first-, second-, and third-order integrator dynamics, highlighting\nthe design procedure and the stability conditions imposed. Finally, numerical\nresults showcase the properties of the proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u5206\u5e03\u5f0f\u5171\u8bc6\u89c2\u6d4b\u5668\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u76ee\u6807\u8ddf\u8e2a\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c40\u90e8\u901a\u4fe1\u548c\u6d4b\u91cf\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4efb\u610f\u79ef\u5206\u5668\u94fe\u6a21\u578b\u76ee\u6807\u7684\u4f30\u8ba1\uff0c\u5e76\u4fdd\u8bc1\u4e86\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5206\u5e03\u5f0f\u76ee\u6807\u8ddf\u8e2a\u95ee\u9898\uff0c\u5176\u4e2d\u4e00\u7ec4\u667a\u80fd\u4f53\u9700\u8981\u901a\u8fc7\u5b83\u4eec\u7684\u5c40\u90e8\u6d4b\u91cf\u548c\u901a\u4fe1\u6765\u5171\u540c\u4f30\u8ba1\u4e00\u4e2a\u79fb\u52a8\u76ee\u6807\u7684\u72b6\u6001\u3002\u5173\u952e\u6311\u6218\u5728\u4e8e\u5982\u4f55\u5728\u5b58\u5728\u901a\u4fe1\u5ef6\u8fdf\u3001\u4f20\u611f\u5668\u566a\u58f0\u4ee5\u53ca\u667a\u80fd\u4f53\u4e4b\u95f4\u6709\u9650\u901a\u4fe1\u5e26\u5bbd\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u7cbe\u786e\u4e14\u9c81\u68d2\u7684\u76ee\u6807\u8ddf\u8e2a\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u7684\u76ee\u6807\u662f\u8bbe\u8ba1\u4e00\u79cd\u89c2\u6d4b\u5668\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u667a\u80fd\u4f53\u80fd\u591f\u4ec5\u901a\u8fc7\u4e0e\u5176\u90bb\u5c45\u7684\u901a\u4fe1\uff0c\u5e76\u6d4b\u91cf\u76f8\u5bf9\u4e8e\u76ee\u6807\u7684\u65b9\u5411\u5411\u91cf\uff0c\u6765\u4f30\u8ba1\u76ee\u6807\u7684\u8fd0\u52a8\u72b6\u6001\uff0c\u800c\u65e0\u9700\u5168\u5c40\u4fe1\u606f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5206\u5e03\u5f0f\u5171\u8bc6\u57fa\u4e8e\u7684\u89c2\u6d4b\u5668\u8bbe\u8ba1\u3002\u8be5\u8bbe\u8ba1\u9996\u5148\u9488\u5bf9\u72b6\u6001\u52a8\u529b\u5b66\u88ab\u5efa\u6a21\u4e3a\u79ef\u5206\u5668\u94fe\u4e14\u6d4b\u91cf\u6a21\u578b\u5177\u6709\u7279\u5b9a\u975e\u7ebf\u6027\u4f46\u9002\u5408\u89c2\u6d4b\u5668\u5f62\u5f0f\u7684\u7cfb\u7edf\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u8fde\u7eed\u65f6\u95f4\u89c2\u6d4b\u5668\u8bbe\u8ba1\u3002\u8be5\u8bbe\u8ba1\u5229\u7528\u4e86\u4e00\u4e2a\u7ed3\u5408\u4e86\u521b\u65b0\u548c\u5171\u8bc6\u7ec4\u4ef6\u7684\u6821\u6b63\u9879\uff0c\u5141\u8bb8\u6bcf\u4e2a\u667a\u80fd\u4f53\u4ec5\u5411\u5176\u90bb\u5c45\u5e7f\u64ad\u4e00\u90e8\u5206\u72b6\u6001\u4f30\u8ba1\uff0c\u4ece\u800c\u6709\u6548\u51cf\u5c11\u4e86\u7f51\u7edc\u4e2d\u7684\u6570\u636e\u6d41\u3002\u4e3a\u4e86\u63d0\u4f9b\u5747\u5300\u7684\u6307\u6570\u7a33\u5b9a\u6027\u4fdd\u8bc1\uff0c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u5e7f\u4e49\u89c2\u6d4b\u5668\u5f62\u5f0f\u7684\u4e00\u7c7b\u975e\u7ebf\u6027\u95ed\u73af\u7cfb\u7edf\u7684\u65b0\u578b\u7ed3\u679c\uff0c\u5e76\u4ee5\u6b64\u4f5c\u4e3a\u63a8\u5bfc\u89c2\u6d4b\u5668\u589e\u76ca\u7a33\u5b9a\u6027\u6761\u4ef6\u7684\u4e3b\u8981\u5de5\u5177\u3002\u968f\u540e\uff0c\u901a\u8fc7\u5229\u7528\u6b63\u4ea4\u6295\u5f71\u77e9\u9635\u7684\u6027\u8d28\uff0c\u8be5\u8bbe\u8ba1\u88ab\u5e94\u7528\u4e8e\u89e3\u51b3\u5206\u5e03\u5f0f\u76ee\u6807\u8ddf\u8e2a\u95ee\u9898\uff0c\u5e76\u7ed9\u51fa\u4e86\u53d6\u51b3\u4e8e\u76ee\u6807-\u667a\u80fd\u4f53\u51e0\u4f55\u6784\u578b\u7684\u663e\u5f0f\u7a33\u5b9a\u6027\u6761\u4ef6\u3002\u6700\u540e\uff0c\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u7279\u6027\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5206\u5e03\u5f0f\u5171\u8bc6\u57fa\u4e8e\u7684\u89c2\u6d4b\u5668\u8bbe\u8ba1\uff0c\u53ef\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u76ee\u6807\u8ddf\u8e2a\u95ee\u9898\u3002\u8be5\u8bbe\u8ba1\u901a\u8fc7\u5229\u7528\u5c40\u90e8\u6d4b\u91cf\u548c\u901a\u4fe1\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4efb\u610f\u9636\u79ef\u5206\u5668\u94fe\u6a21\u578b\u7684\u76ee\u6807\u7684\u4f30\u8ba1\u3002\u7814\u7a76\u63a8\u5bfc\u4e86\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u8bbe\u8ba1\u5728\u4e0d\u540c\u9636\u6570\u7684\u79ef\u5206\u5668\u6a21\u578b\u4e0b\u5747\u80fd\u5b9e\u73b0\u5747\u5300\u6307\u6570\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u6570\u503c\u6a21\u62df\u5c55\u793a\u4e86\u8be5\u7b97\u6cd5\u5728\u76ee\u6807\u8ddf\u8e2a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u4e0d\u540c\u51e0\u4f55\u6784\u578b\u4e0b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5206\u5e03\u5f0f\u5171\u8bc6\u57fa\u4e8e\u7684\u89c2\u6d4b\u5668\u8bbe\u8ba1\uff0c\u7528\u4e8e\u89e3\u51b3\u76ee\u6807\u8ddf\u8e2a\u95ee\u9898\u3002\u8be5\u8bbe\u8ba1\u5141\u8bb8\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u4e00\u7ec4\u667a\u80fd\u4f53\u8ddf\u8e2a\u7531\u4efb\u610f\u9636\u79ef\u5206\u5668\u94fe\u5efa\u6a21\u7684\u76ee\u6807\u3002\u6bcf\u4e2a\u667a\u80fd\u4f53\u4ec5\u9700\u5e7f\u64ad\u5176\u72b6\u6001\u4f30\u8ba1\u7684\u4e00\u90e8\u5206\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u7f51\u7edc\u6570\u636e\u6d41\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u9488\u5bf9\u7279\u5b9a\u975e\u7ebf\u6027\u4f46\u9002\u5408\u89c2\u6d4b\u5668\u7684\u7cfb\u7edf\u7684\u65b0\u578b\u8fde\u7eed\u65f6\u95f4\u89c2\u6d4b\u5668\u8bbe\u8ba1\uff0c\u5e76\u5229\u7528\u5176\u521b\u65b0\u548c\u5171\u8bc6\u7ec4\u4ef6\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u8fd9\u4e00\u76ee\u6807\u3002\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u975e\u7ebf\u6027\u95ed\u73af\u7cfb\u7edf\u7ed3\u679c\uff0c\u4ee5\u4fdd\u8bc1\u6307\u6570\u7a33\u5b9a\u6027\uff0c\u5e76\u63a8\u5bfc\u4e86\u89c2\u6d4b\u5668\u589e\u76ca\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\u3002\u901a\u8fc7\u5229\u7528\u6b63\u4ea4\u6295\u5f71\u77e9\u9635\u7684\u6027\u8d28\uff0c\u8be5\u8bbe\u8ba1\u88ab\u5e94\u7528\u4e8e\u5206\u5e03\u5f0f\u76ee\u6807\u8ddf\u8e2a\u95ee\u9898\uff0c\u5e76\u7ed9\u51fa\u4e86\u660e\u786e\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u8fd9\u4e9b\u6761\u4ef6\u4f9d\u8d56\u4e8e\u76ee\u6807-\u667a\u80fd\u4f53\u7684\u51e0\u4f55\u6784\u578b\u3002\u7814\u7a76\u4e2d\u8fd8\u63a8\u5bfc\u4e86\u76ee\u6807\u6a21\u578b\u4e3a\u4e00\u9636\u3001\u4e8c\u9636\u548c\u4e09\u9636\u79ef\u5206\u5668\u52a8\u529b\u5b66\u7684\u5177\u4f53\u5b9e\u4f8b\uff0c\u5e76\u5c55\u793a\u4e86\u8bbe\u8ba1\u8fc7\u7a0b\u548c\u65bd\u52a0\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\u3002\u6700\u540e\u7684\u6570\u503c\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.14278", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14278", "abs": "https://arxiv.org/abs/2507.14278", "authors": ["Minjeong Song", "Arthur J. Parzygnat"], "title": "Bipartite quantum states admitting a causal explanation", "comment": "18 pages, 2 figures, 5 diagrams; comments welcome!", "summary": "The statistics of local measurements of joint quantum systems can sometimes\nbe used to distinguish the temporal order in which they were measured. We first\nprove that every bipartite separable density matrix is temporally compatible\nwith direct causal influence for arbitrary finite-dimensional quantum systems\nand measurements of a tomographically-complete class of observables, which\nincludes all Pauli observables in the case of multi-qubit systems.\nEquivalently, if a bipartite density matrix is not temporally compatible with\ndirect causal influence, then it must be entangled. We also provide an\noperational meaning for the temporal evolution consistent with such\ncorrelations in terms of a generalized dephasing channel and a pretty good\nmeasurement. The two temporal evolutions turn out to not be Petz recovery maps\nof each other, but are Bayesian inverses of each other. Finally, we prove\nnecessary and sufficient conditions for an arbitrary bipartite quantum state to\nbe temporally compatible, thereby providing a temporal analogue of the positive\npartial transpose criterion valid for quantum systems of any dimension.", "AI": {"tldr": "\"\u91cf\u5b50\u5173\u8054\u53ef\u4ee5\u63ed\u793a\u6d4b\u91cf\u7684\u65f6\u95f4\u987a\u5e8f\u3002\u53ef\u5206\u6001\u603b\u662f\u65f6\u95f4\u517c\u5bb9\u7684\uff0c\u800c\u7ea0\u7f20\u6001\u5219\u4e0d\u4e00\u5b9a\u3002\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5224\u65ad\u4efb\u610f\u4e8c\u5206\u6001\u662f\u5426\u65f6\u95f4\u517c\u5bb9\u7684\u65b0\u5224\u636e\u3002\"", "motivation": "\"\u91cf\u5b50\u5173\u8054\u53ef\u80fd\u5305\u542b\u5173\u4e8e\u5c40\u90e8\u6d4b\u91cf\u7684\u65f6\u95f4\u987a\u5e8f\u7684\u4fe1\u606f\u3002\"", "method": "\"\u6211\u4eec\u9996\u5148\u8bc1\u660e\u4e86\u6bcf\u4e2a\u4e8c\u5206\u53ef\u5206\u5bc6\u5ea6\u77e9\u9635\u90fd\u4e0e\u76f4\u63a5\u56e0\u679c\u5f71\u54cd\u5728\u65f6\u95f4\u4e0a\u517c\u5bb9\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u6709\u9650\u7ef4\u91cf\u5b50\u7cfb\u7edf\u548c\u4e00\u79cd\u53ef\u65ad\u5c42\u7684\u53ef\u89c2\u6d4b\u91cf\u7c7b\uff08\u5305\u62ec\u6240\u6709\u6ce1\u5229\u53ef\u89c2\u6d4b\u91cf\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0e\u6b64\u7c7b\u76f8\u5173\u6027\u4e00\u81f4\u7684\u65f6\u95f4\u6f14\u5316\u7684\u64cd\u4f5c\u610f\u4e49\uff0c\u5373\u5e7f\u4e49\u9000\u76f8\u5e72\u901a\u9053\u548c\u76f8\u5f53\u4e0d\u9519\u7684\u6d4b\u91cf\u3002\"", "result": "\"\u6211\u4eec\u8bc1\u660e\u4e86\u6bcf\u4e2a\u4e8c\u5206\u53ef\u5206\u5bc6\u5ea6\u77e9\u9635\u90fd\u4e0e\u76f4\u63a5\u56e0\u679c\u5f71\u54cd\u5728\u65f6\u95f4\u4e0a\u517c\u5bb9\u3002\u4e24\u4e2a\u65f6\u95f4\u6f14\u5316\u4e0d\u662f\u5f7c\u6b64\u7684Petz\u6062\u590d\u56fe\uff0c\u800c\u662f\u5f7c\u6b64\u7684\u8d1d\u53f6\u65af\u9006\u3002\"", "conclusion": "\"\u5982\u679c\u4e00\u4e2a\u4e8c\u5206\u6001\u5bc6\u5ea6\u77e9\u9635\u4e0e\u76f4\u63a5\u56e0\u679c\u5f71\u54cd\u5728\u65f6\u95f4\u4e0a\u4e0d\u517c\u5bb9\uff0c\u90a3\u4e48\u5b83\u5fc5\u5b9a\u662f\u7ea0\u7f20\u7684\u3002\u6700\u540e\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u4efb\u610f\u4e8c\u5206\u91cf\u5b50\u6001\u5728\u65f6\u95f4\u4e0a\u517c\u5bb9\u7684\u5145\u8981\u6761\u4ef6\uff0c\u8fd9\u4e3a\u9002\u7528\u4e8e\u4efb\u4f55\u7ef4\u5ea6\u7684\u91cf\u5b50\u7cfb\u7edf\u7684\u6b63\u90e8\u5206\u8f6c\u7f6e\u5224\u636e\u63d0\u4f9b\u4e86\u65f6\u95f4\u4e0a\u7684\u7c7b\u4f3c\u7269\u3002\""}}
{"id": "2507.14189", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14189", "abs": "https://arxiv.org/abs/2507.14189", "authors": ["Song Mao", "Lejun Cheng", "Pinlong Cai", "Guohang Yan", "Ding Wang", "Botian Shi"], "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "comment": "work in process", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious applications. However, their use as writing assistants in specialized\ndomains like finance, medicine, and law is often hampered by a lack of deep\ndomain-specific knowledge and a tendency to hallucinate. Existing solutions,\nsuch as Retrieval-Augmented Generation (RAG), can suffer from inconsistency\nacross multiple retrieval steps, while online search-based methods often\ndegrade quality due to unreliable web content. To address these challenges, we\nintroduce DeepWriter, a customizable, multimodal, long-form writing assistant\nthat operates on a curated, offline knowledge base. DeepWriter leverages a\nnovel pipeline that involves task decomposition, outline generation, multimodal\nretrieval, and section-by-section composition with reflection. By deeply mining\ninformation from a structured corpus and incorporating both textual and visual\nelements, DeepWriter generates coherent, factually grounded, and\nprofessional-grade documents. We also propose a hierarchical knowledge\nrepresentation to enhance retrieval efficiency and accuracy. Our experiments on\nfinancial report generation demonstrate that DeepWriter produces high-quality,\nverifiable articles that surpasses existing baselines in factual accuracy and\ngenerated content quality.", "AI": {"tldr": "DeepWriter\u662f\u4e00\u4e2a\u9488\u5bf9\u91d1\u878d\u3001\u533b\u5b66\u3001\u6cd5\u5f8b\u7b49\u4e13\u4e1a\u9886\u57df\u5b9a\u5236\u7684\u591a\u6a21\u6001\u3001\u957f\u7bc7\u5199\u4f5c\u52a9\u624b\u3002\u5b83\u4f7f\u7528\u7cbe\u5fc3\u7b56\u5212\u7684\u79bb\u7ebf\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u3001\u5927\u7eb2\u751f\u6210\u3001\u591a\u6a21\u6001\u68c0\u7d22\u548c\u9010\u8282\u64b0\u5199\u4e0e\u53cd\u601d\u7684\u6d41\u7a0b\uff0c\u514b\u670d\u4e86\u73b0\u6709LLM\u5728\u4e13\u4e1a\u77e5\u8bc6\u548c\u5e7b\u89c9\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cDeepWriter\u5728\u91d1\u878d\u62a5\u544a\u751f\u6210\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5728\u91d1\u878d\u3001\u533b\u5b66\u548c\u6cd5\u5f8b\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u5e94\u7528\u53d7\u5230\u9886\u57df\u77e5\u8bc6\u7f3a\u4e4f\u548c\u5e7b\u89c9\u95ee\u9898\u7684\u9650\u5236\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u53ef\u80fd\u5b58\u5728\u591a\u6b65\u68c0\u7d22\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u5728\u7ebf\u641c\u7d22\u7684\u65b9\u6cd5\u5219\u5bb9\u6613\u53d7\u5230\u4e0d\u53ef\u9760\u7f51\u7edc\u5185\u5bb9\u7684\u5f71\u54cd\u3002", "method": "DeepWriter\u91c7\u7528\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6d41\u7a0b\uff0c\u5305\u62ec\u4efb\u52a1\u5206\u89e3\u3001\u5927\u7eb2\u751f\u6210\u3001\u591a\u6a21\u6001\u68c0\u7d22\u4ee5\u53ca\u9010\u8282\u64b0\u5199\u548c\u53cd\u601d\u3002\u5b83\u5229\u7528\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u8bed\u6599\u5e93\u8fdb\u884c\u6df1\u5ea6\u4fe1\u606f\u6316\u6398\uff0c\u5e76\u6574\u5408\u4e86\u6587\u672c\u548c\u89c6\u89c9\u5143\u7d20\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\u6765\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "result": "\u5728\u91d1\u878d\u62a5\u544a\u751f\u6210\u65b9\u9762\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDeepWriter\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7684\u6587\u7ae0\uff0c\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u751f\u6210\u5185\u5bb9\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "DeepWriter\u901a\u8fc7\u5229\u7528\u5b9a\u5236\u7684\u3001\u79bb\u7ebf\u7684\u77e5\u8bc6\u5e93\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u5305\u542b\u4efb\u52a1\u5206\u89e3\u3001\u5927\u7eb2\u751f\u6210\u3001\u591a\u6a21\u6001\u68c0\u7d22\u4ee5\u53ca\u9010\u8282\u64b0\u5199\u548c\u53cd\u601d\u7684\u6d41\u7a0b\uff0c\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u3001\u57fa\u4e8e\u4e8b\u5b9e\u4e14\u4e13\u4e1a\u7ea7\u7684\u6587\u6863\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cDeepWriter\u5728\u91d1\u878d\u62a5\u544a\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5176\u751f\u6210\u6587\u7ae0\u7684\u8d28\u91cf\u3001\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6574\u4f53\u5185\u5bb9\u8d28\u91cf\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002"}}
{"id": "2507.14624", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14624", "abs": "https://arxiv.org/abs/2507.14624", "authors": ["Yaru Liu", "Derek Nowrouzezahri", "Morgan Mcguire"], "title": "Real-Time Scene Reconstruction using Light Field Probes", "comment": null, "summary": "Reconstructing photo-realistic large-scale scenes from images, for example at\ncity scale, is a long-standing problem in computer graphics. Neural rendering\nis an emerging technique that enables photo-realistic image synthesis from\npreviously unobserved viewpoints; however, state-of-the-art neural rendering\nmethods have difficulty efficiently rendering a high complex large-scale scene\nbecause these methods typically trade scene size, fidelity, and rendering speed\nfor quality. The other stream of techniques utilizes scene geometries for\nreconstruction. But the cost of building and maintaining a large set of\ngeometry data increases as scene size grows. Our work explores novel view\nsynthesis methods that efficiently reconstruct complex scenes without explicit\nuse of scene geometries. Specifically, given sparse images of the scene\n(captured from the real world), we reconstruct intermediate, multi-scale,\nimplicit representations of scene geometries. In this way, our method avoids\nexplicitly relying on scene geometry, significantly reducing the computational\ncost of maintaining large 3D data. Unlike current methods, we reconstruct the\nscene using a probe data structure. Probe data hold highly accurate depth\ninformation of dense data points, enabling the reconstruction of highly complex\nscenes. By reconstructing the scene using probe data, the rendering cost is\nindependent of the complexity of the scene. As such, our approach combines\ngeometry reconstruction and novel view synthesis. Moreover, when rendering\nlarge-scale scenes, compressing and streaming probe data is more efficient than\nusing explicit scene geometry. Therefore, our neural representation approach\ncan potentially be applied to virtual reality (VR) and augmented reality (AR)\napplications.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u6e32\u67d3\u6280\u672f\uff0c\u4f7f\u7528\u201c\u63a2\u9488\u6570\u636e\u201d\u6765\u9ad8\u6548\u91cd\u5efa\u5927\u578b\u590d\u6742\u573a\u666f\uff0c\u65e0\u9700\u573a\u666f\u51e0\u4f55\uff0c\u6e32\u67d3\u901f\u5ea6\u5feb\uff0c\u9002\u5408VR/AR\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u6e32\u67d3\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u6e32\u67d3\u590d\u6742\u7684\u3001\u5927\u89c4\u6a21\u7684\u573a\u666f\uff0c\u56e0\u4e3a\u5b83\u4eec\u9700\u8981\u5728\u573a\u666f\u5927\u5c0f\u3001\u4fdd\u771f\u5ea6\u548c\u6e32\u67d3\u901f\u5ea6\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u800c\u57fa\u4e8e\u573a\u666f\u51e0\u4f55\u7684\u65b9\u6cd5\u5219\u9700\u8981\u6784\u5efa\u548c\u7ef4\u62a4\u5e9e\u5927\u7684\u51e0\u4f55\u6570\u636e\uff0c\u6210\u672c\u9ad8\u6602\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u63a2\u9488\u6570\u636e\u7ed3\u6784\u6765\u91cd\u5efa\u573a\u666f\uff0c\u8be5\u6570\u636e\u7ed3\u6784\u5305\u542b\u5bc6\u96c6\u6570\u636e\u70b9\u7684\u7cbe\u786e\u6df1\u5ea6\u4fe1\u606f\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u907f\u514d\u4e86\u5bf9\u573a\u666f\u51e0\u4f55\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0e\u573a\u666f\u590d\u6742\u5ea6\u65e0\u5173\u7684\u6e32\u67d3\u6210\u672c\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u5730\u91cd\u5efa\u590d\u6742\u7684\u5927\u578b\u573a\u666f\uff0c\u5e76\u5c06\u6e32\u67d3\u6210\u672c\u4e0e\u573a\u666f\u590d\u6742\u6027\u5206\u79bb\u5f00\u6765\u3002\u6b64\u5916\uff0c\u5728\u6e32\u67d3\u5927\u578b\u573a\u666f\u65f6\uff0c\u63a2\u9488\u6570\u636e\u7684\u538b\u7f29\u548c\u6d41\u5f0f\u4f20\u8f93\u6bd4\u4f7f\u7528\u663e\u5f0f\u573a\u666f\u51e0\u4f55\u66f4\u6709\u6548\uff0c\u8fd9\u4f7f\u5f97\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u5e94\u7528\u4e8e\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u548c\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u9886\u57df\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u6e32\u67d3\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u63a2\u9488\u6570\u636e\u7ed3\u6784\u6765\u9ad8\u6548\u5730\u91cd\u5efa\u590d\u6742\u7684\u5927\u578b\u573a\u666f\uff0c\u800c\u65e0\u9700\u663e\u5f0f\u4f7f\u7528\u573a\u666f\u51e0\u4f55\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u63a2\u9488\u6570\u636e\uff0c\u5c06\u6e32\u67d3\u6210\u672c\u4e0e\u573a\u666f\u590d\u6742\u5ea6\u5206\u79bb\u5f00\u6765\uff0c\u5e76\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14270", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14270", "abs": "https://arxiv.org/abs/2507.14270", "authors": ["Ravin Kumar"], "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "comment": "10 pages, 2 figures, 1 table, and GitHub repository for the source\n  code", "summary": "We propose the APTx Neuron, a novel, unified neural computation unit that\nintegrates non-linear activation and linear transformation into a single\ntrainable expression. The APTx Neuron is derived from the APTx activation\nfunction, thereby eliminating the need for separate activation layers and\nmaking the architecture both computationally efficient and elegant. The\nproposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i +\n\\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters\n$\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our\nAPTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\\%\ntest accuracy in just 20 epochs using approximately 332K trainable parameters.\nThe results highlight the superior expressiveness and computational efficiency\nof the APTx Neuron compared to traditional neurons, pointing toward a new\nparadigm in unified neuron design and the architectures built upon it.", "AI": {"tldr": "\u63d0\u51faAPTx Neuron\uff0c\u4e00\u79cd\u96c6\u6210\u4e86\u6fc0\u6d3b\u548c\u7ebf\u6027\u53d8\u6362\u7684\u7edf\u4e00\u795e\u7ecf\u5143\uff0c\u5728MNIST\u4e0a\u8fbe\u523096.69%\u51c6\u786e\u7387\uff0c\u6548\u7387\u9ad8\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u6548\u7387\u548c\u67b6\u6784\u7684\u4f18\u96c5\u6027\uff0c\u6d88\u9664\u5bf9\u72ec\u7acb\u6fc0\u6d3b\u5c42\u548c\u7ebf\u6027\u53d8\u6362\u5c42\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAPTx Neuron\u7684\u65b0\u578b\u7edf\u4e00\u795e\u7ecf\u5143\u8ba1\u7b97\u5355\u5143\uff0c\u5b83\u5c06\u975e\u7ebf\u6027\u6fc0\u6d3b\u548c\u7ebf\u6027\u53d8\u6362\u878d\u5408\u5230\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684\u8868\u8fbe\u5f0f\u4e2d\u3002\u8be5\u795e\u7ecf\u5143\u57fa\u4e8eAPTx\u6fc0\u6d3b\u51fd\u6570\uff0c\u6570\u5b66\u5f62\u5f0f\u4e3a $y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$\uff0c\u5176\u4e2d\u6240\u6709\u53c2\u6570 $\\alpha_i$, $\\beta_i$, $\\gamma_i$, \u548c $\\delta$ \u5747\u53ef\u8bad\u7ec3\u3002", "result": "\u5728MNIST\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u4e8eAPTx Neuron\u7684\u67b6\u6784\u572820\u4e2aepoch\u5185\u8fbe\u5230\u4e8696.69%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u6a21\u578b\u53c2\u6570\u91cf\u7ea6\u4e3a332K\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAPTx Neuron\u6bd4\u4f20\u7edf\u795e\u7ecf\u5143\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "APTx Neuron\u7684\u67b6\u6784\u5728MNIST\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe96.69%\uff0c\u5e76\u4e14\u8bad\u7ec3\u901f\u5ea6\u5feb\uff08\u4ec520\u4e2aepoch\uff09\uff0c\u53c2\u6570\u91cf\u5c11\uff08\u7ea6332K\uff09\uff0c\u8bc1\u660e\u4e86\u5176\u76f8\u5bf9\u4e8e\u4f20\u7edf\u795e\u7ecf\u5143\u5177\u6709\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u7edf\u4e00\u795e\u7ecf\u5143\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.14139", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.14139", "abs": "https://arxiv.org/abs/2507.14139", "authors": ["Peipei Wang", "Wu Guan", "Liping Liang", "Zhijun Wang", "Hanqing Luo", "Zhibin Zhang"], "title": "SpeedLLM: An FPGA Co-design of Large Language Model Inference Accelerator", "comment": null, "summary": "This paper introduces SpeedLLM, a neural network accelerator designed on the\nXilinx Alevo U280 platform and optimized for the Tinyllama framework to enhance\nedge computing performance. Key innovations include data stream parallelism, a\nmemory reuse strategy, and Llama2 operator fusion, which collectively reduce\nlatency and energy consumption. SpeedLLM's data pipeline architecture optimizes\nthe read-compute-write cycle, while the memory strategy minimizes FPGA resource\ndemands. The operator fusion boosts computational density and throughput.\nResults show SpeedLLM outperforms traditional Tinyllama implementations,\nachieving up to 4.8* faster performance and 1.18* lower energy consumption,\noffering improvements in edge devices.", "AI": {"tldr": "SpeedLLM \u662f\u4e00\u4e2a\u5728 Xilinx Alevo U280 \u5e73\u53f0\u4e0a\u9488\u5bf9 Tinyllama \u4f18\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u591a\u79cd\u521b\u65b0\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8ba1\u7b97\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u8fb9\u7f18\u8ba1\u7b97\u6027\u80fd\uff0c\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86 SpeedLLM\uff0c\u4e00\u4e2a\u4e3a Tinyllama \u6846\u67b6\u4f18\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u3002", "method": "SpeedLLM \u91c7\u7528\u6570\u636e\u6d41\u5e76\u884c\u3001\u5185\u5b58\u590d\u7528\u548c Llama2 \u7b97\u5b50\u878d\u5408\u7b49\u6280\u672f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6570\u636e\u7ba1\u9053\u67b6\u6784\u6765\u4f18\u5316\u8bfb-\u8ba1\u7b97-\u5199\u5468\u671f\uff0c\u540c\u65f6\u901a\u8fc7\u5185\u5b58\u7b56\u7565\u6700\u5c0f\u5316 FPGA \u8d44\u6e90\u9700\u6c42\u3002", "result": "SpeedLLM \u7684\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u7684 Tinyllama \u5b9e\u73b0\u76f8\u6bd4\uff0c\u5176\u6027\u80fd\u63d0\u5347\u4e86 4.8 \u500d\uff0c\u80fd\u8017\u964d\u4f4e\u4e86 1.18 \u500d\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u5e26\u6765\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "SpeedLLM \u5728 Xilinx Alevo U280 \u5e73\u53f0\u4e0a\uff0c\u901a\u8fc7\u6570\u636e\u6d41\u5e76\u884c\u3001\u5185\u5b58\u590d\u7528\u548c Llama2 \u7b97\u5b50\u878d\u5408\u7b49\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86 Tinyllama \u6846\u67b6\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe 4.8 \u500d\u7684\u6027\u80fd\u63d0\u5347\u548c 1.18 \u500d\u7684\u80fd\u8017\u964d\u4f4e\u3002"}}
{"id": "2507.14465", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14465", "abs": "https://arxiv.org/abs/2507.14465", "authors": ["Xiaoyu Xiong", "Yuting Peng", "Summer Kwong", "Anqi Huang"], "title": "Discipline and Resistance: The Construction of a Digital Home for TikTok Refugees on Xiaohongshu", "comment": "33 pages, 4 figures, 2 tables", "summary": "This study examines how TikTok refugees moved to Xiaohongshu after TikTok was\nabout to be banned in the United States. It utilizes Foucault's idea of\nheterotopia to demonstrate how Xiaohongshu became a crisis space for\ncross-cultural discussions across the Great Firewall. Through Critical\nDiscourse Analysis of 586 user comments, the study reveals how Chinese and\ninternational users collaboratively constructed and contested a new online\norder through language negotiation, identity positioning, and playful platform\npolicing. The findings highlight distinct discursive strategies between\ndomestic and overseas users, reflecting both cultural resistance and\nadaptation. This research contributes to the understanding of digital\nmigration, heterotopic spaces in social media, and emerging dynamics of\ncross-cultural discourse during geopolitical crises.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14261", "categories": ["cs.DS", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14261", "abs": "https://arxiv.org/abs/2507.14261", "authors": ["Mahmood K. M. Almansoori", "Miklos Telek"], "title": "FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data", "comment": null, "summary": "We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm\nthat addresses the computational challenges of constructing Minimum Spanning\nTrees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a\nthree-phase approach: Approximate Nearest Neighbor (ANN) graph construction,\nANN inter-component connection, and iterative edge refinement. For a dataset of\n$n$ points in a $d$-dimensional space, FAMST achieves $\\mathcal{O}(dn \\log n)$\ntime complexity and $\\mathcal{O}(dn + kn)$ space complexity when $k$ nearest\nneighbors are considered, which is a significant improvement over the\n$\\mathcal{O}(n^2)$ time and space complexity of traditional methods.\n  Experiments across diverse datasets demonstrate that FAMST achieves\nremarkably low approximation errors while providing speedups of up to\n1000$\\times$ compared to exact MST algorithms. We analyze how the key\nhyperparameters, $k$ (neighborhood size) and $\\lambda$ (inter-component edges),\naffect performance, providing practical guidelines for hyperparameter\nselection. FAMST enables MST-based analysis on datasets with millions of points\nand thousands of dimensions, extending the applicability of MST techniques to\nproblem scales previously considered infeasible.", "AI": {"tldr": "FAMST\u662f\u4e00\u79cd\u65b0\u7684MST\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u65b9\u6cd5\uff08ANN\u56fe\u6784\u5efa\u3001ANN\u5206\u91cf\u95f4\u8fde\u63a5\u3001\u8fed\u4ee3\u8fb9\u4f18\u5316\uff09\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\uff0c\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u3001\u9ad8\u7ef4\u6570\u636e\u96c6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u89c4\u6a21\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u8ba1\u7b97\u6700\u5c0f\u751f\u6210\u6811\uff08MST\uff09\u7684\u8ba1\u7b97\u6311\u6218\u3002", "method": "FAMST\u7b97\u6cd5\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u56fe\u6784\u5efa\u3001ANN\u5206\u91cf\u95f4\u8fde\u63a5\u548c\u8fed\u4ee3\u8fb9\u4f18\u5316\u3002", "result": "FAMST\u7b97\u6cd5\u5b9e\u73b0\u4e86$\"O\"$(dn log n)\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c$\"O\"$(dn + kn)\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4fdd\u6301\u53ef\u5ffd\u7565\u7684\u8fd1\u4f3c\u8bef\u5dee\u7684\u540c\u65f6\uff0c\u901f\u5ea6\u63d0\u9ad8\u4e861000\u500d\u3002", "conclusion": "FAMST\u7b97\u6cd5\u80fd\u591f\u5904\u7406\u5177\u6709\u6570\u767e\u4e07\u4e2a\u70b9\u548c\u6570\u5343\u4e2a\u7ef4\u5ea6\u7684\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\uff0c\u5c06MST\u6280\u672f\u7684\u5e94\u7528\u8303\u56f4\u6269\u5c55\u5230\u4ee5\u524d\u8ba4\u4e3a\u4e0d\u53ef\u884c\u7684\u6bd4\u4f8b\u3002"}}
{"id": "2507.14586", "categories": ["physics.app-ph", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14586", "abs": "https://arxiv.org/abs/2507.14586", "authors": ["Adrian Ehrenhofer", "Thomas Wallmersperger", "Gianaurelio Cuniberti"], "title": "What do Large Language Models know about materials?", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in the fields of\nmechanical engineering and materials science. As models that establish\nconnections through the interface of language, LLMs can be applied for\nstep-wise reasoning through the Processing-Structure-Property-Performance chain\nof material science and engineering. Current LLMs are built for adequately\nrepresenting a dataset, which is the most part of the accessible internet.\nHowever, the internet mostly contains non-scientific content. If LLMs should be\napplied for engineering purposes, it is valuable to investigate models for\ntheir intrinsic knowledge -- here: the capacity to generate correct information\nabout materials. In the current work, for the example of the Periodic Table of\nElements, we highlight the role of vocabulary and tokenization for the\nuniqueness of material fingerprints, and the LLMs' capabilities of generating\nfactually correct output of different state-of-the-art open models. This leads\nto a material knowledge benchmark for an informed choice, for which steps in\nthe PSPP chain LLMs are applicable, and where specialized models are required.", "AI": {"tldr": "LLM\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u5e94\u7528\u9700\u8981\u8c28\u614e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u8bc4\u4f30\u3002", "motivation": "\u8bc4\u4f30\u73b0\u6709LLM\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u5e94\u7528\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5176\u751f\u6210\u51c6\u786e\u6750\u6599\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u4ee5\u786e\u5b9a\u5176\u5728\u201c\u5904\u7406-\u7ed3\u6784-\u6027\u8d28-\u6027\u80fd\u201d\uff08PSPP\uff09\u94fe\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790LLM\u5728\u5904\u7406\u5468\u671f\u8868\u6570\u636e\u65f6\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u5176\u5728\u6750\u6599\u79d1\u5b66\u77e5\u8bc6\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u6750\u6599\u77e5\u8bc6\u57fa\u51c6\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cLLM\u5728\u5904\u7406\u6750\u6599\u79d1\u5b66\u4fe1\u606f\u65f6\u5b58\u5728\u6311\u6218\uff0c\u5176\u8f93\u51fa\u7684\u51c6\u786e\u6027\u53d7\u5230\u8bcd\u6c47\u548c\u6807\u8bb0\u5316\u7684\u5f71\u54cd\u3002\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\uff0c\u5e76\u53ef\u80fd\u9700\u8981\u4e13\u95e8\u7684\u6a21\u578b\u6765\u5904\u7406\u7279\u5b9a\u4efb\u52a1\u3002", "conclusion": "LLM\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5bf9\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u8fdb\u884c\u4f18\u5316\u548c\u8bc4\u4f30\uff0c\u4ee5\u786e\u4fdd\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14713", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2507.14713", "abs": "https://arxiv.org/abs/2507.14713", "authors": ["Allan Luedeman", "Nicholas Baum", "Andrew Quijano", "Kemal Akkaya"], "title": "Privacy-Preserving Drone Navigation Through Homomorphic Encryption for Collision Avoidance", "comment": null, "summary": "As drones increasingly deliver packages in neighborhoods, concerns about\ncollisions arise. One solution is to share flight paths within a specific zip\ncode, but this compromises business privacy by revealing delivery routes. For\nexample, it could disclose which stores send packages to certain addresses. To\navoid exposing path information, we propose using homomorphic encryption-based\ncomparison to compute path intersections. This allows drones to identify\npotential collisions without revealing path and destination details, allowing\nthem to adjust altitude to avoid crashes. We implemented and tested our\napproach on resource-limited virtual machines to mimic the computational power\nof drones. Our results demonstrate that our method is significantly faster and\nrequires less network communication compared to a garbled circuit-based\napproach. We also provide a security analysis of the approach against potential\nattacks.", "AI": {"tldr": "\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\uff1a\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u907f\u514d\u78b0\u649e\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u4e3a\u4e86\u5728\u65e0\u4eba\u673a\u9012\u9001\u5305\u88f9\u65f6\u907f\u514d\u66b4\u9732\u5546\u4e1a\u9690\u79c1\uff08\u4f8b\u5982\uff0c\u54ea\u4e9b\u5546\u5e97\u5411\u7279\u5b9a\u5730\u5740\u53d1\u9001\u5305\u88f9\uff09\u548c\u8def\u5f84\u4fe1\u606f\uff0c\u63d0\u51fa\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u6bd4\u8f83\u65b9\u6cd5\u6765\u8ba1\u7b97\u8def\u5f84\u4ea4\u53c9\u70b9\uff0c\u4f7f\u65e0\u4eba\u673a\u80fd\u591f\u8bc6\u522b\u6f5c\u5728\u78b0\u649e\uff0c\u800c\u65e0\u9700\u6cc4\u9732\u8def\u5f84\u548c\u76ee\u7684\u5730\u7ec6\u8282\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u865a\u62df\u673a\u4e0a\u5b9e\u73b0\u548c\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660e\u4e0e\u57fa\u4e8e\u4e71\u7801\u7535\u8def\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u901f\u5ea6\u66f4\u5feb\uff0c\u7f51\u7edc\u901a\u4fe1\u9700\u6c42\u66f4\u5c11\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u6bd4\u8f83\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5728\u4e0d\u6cc4\u9732\u8def\u5f84\u548c\u76ee\u7684\u5730\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u8ba9\u65e0\u4eba\u673a\u8bc6\u522b\u6f5c\u5728\u7684\u78b0\u649e\u3002"}}
{"id": "2507.15117", "categories": ["cs.LO", "math.LO", "03B45", "F.4.0"], "pdf": "https://arxiv.org/pdf/2507.15117", "abs": "https://arxiv.org/abs/2507.15117", "authors": ["Alfredo Burrieza", "Fernando Soler-Toscano", "Antonio Yuste-Ginel"], "title": "A meta-modal logic for bisimulations", "comment": "24 pages", "summary": "We propose a modal study of the notion of bisimulation. Our contribution is\ntwofold. First, we extend the basic modal language with a new modality [b],\nwhose intended meaning is universal quantification over all states that are\nbisimilar to the current one. We show that bisimulations are definable in this\nobject language. Second, we provide a sound and complete axiomatisation of the\nclass of all pairs of Kripke models linked by bisimulations.", "AI": {"tldr": "We introduce a new modality [b] to the modal language to define bisimulations and provide an axiomatization for bisimulation-related Kripke models.", "motivation": "We propose a modal study of the notion of bisimulation.", "method": "We extend the basic modal language with a new modality [b], whose intended meaning is universal quantification over all states that are bisimilar to the current one.", "result": "Bisimulations are definable in this object language.", "conclusion": "bisimulations are definable in this object language and we provide a sound and complete axiomatisation of the class of all pairs of Kripke models linked by bisimulations"}}
{"id": "2507.14597", "categories": ["cs.DC", "cs.CV", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.14597", "abs": "https://arxiv.org/abs/2507.14597", "authors": ["Eugene Armah", "Linda Amoako Bannning"], "title": "Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning", "comment": null, "summary": "Processing data at high speeds is becoming increasingly critical as digital\neconomies generate enormous data. The current paradigms for timely data\nprocessing are edge computing and data stream processing (DSP). Edge computing\nplaces resources closer to where data is generated, while stream processing\nanalyzes the unbounded high-speed data in motion. However, edge stream\nprocessing faces rapid workload fluctuations, complicating resource\nprovisioning. Inadequate resource allocation leads to bottlenecks, whereas\nexcess allocation results in wastage. Existing reactive methods, such as\nthreshold-based policies and queuing theory scale only after performance\ndegrades, potentially violating SLAs. Although reinforcement learning (RL)\noffers a proactive approach through agents that learn optimal runtime\nadaptation policies, it requires extensive simulation. Furthermore, predictive\nmachine learning models face online distribution and concept drift that\nminimize their accuracy. We propose a three-step solution to the proactive edge\nstream processing autoscaling problem. Firstly, a GRU neural network forecasts\nthe upstream load using real-world and synthetic DSP datasets. Secondly, a\ntransfer learning framework integrates the predictive model into an online\nstream processing system using the DTW algorithm and joint distribution\nadaptation to handle the disparities between offline and online domains.\nFinally, a horizontal autoscaling module dynamically adjusts the degree of\noperator parallelism, based on predicted load while considering edge resource\nconstraints. The lightweight GRU model for load predictions recorded up to\n1.3\\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and\nProphet on the SMAPE and RMSE evaluation metrics, with lower training time than\nthe computationally intensive RL models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u8fb9\u7f18\u6d41\u5904\u7406\u81ea\u52a8\u6269\u5c55\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7GRU\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u8d1f\u8f7d\u9884\u6d4b\uff0c\u5e76\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\u548c\u6c34\u5e73\u81ea\u52a8\u6269\u5c55\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8d44\u6e90\u914d\u7f6e\u7684\u52a8\u6001\u8c03\u6574\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u8d44\u6e90\u6d6a\u8d39\u3002", "motivation": "\u5f53\u524d\u7684\u8fb9\u7f18\u6d41\u5904\u7406\uff08ESP\uff09\u9762\u4e34\u5de5\u4f5c\u8d1f\u8f7d\u5feb\u901f\u6ce2\u52a8\u7684\u95ee\u9898\uff0c\u8fd9\u4f7f\u5f97\u8d44\u6e90\u914d\u7f6e\u590d\u6742\u5316\u3002\u8fc7\u5ea6\u7684\u8d44\u6e90\u5206\u914d\u4f1a\u5bfc\u81f4\u6d6a\u8d39\uff0c\u800c\u4e0d\u8db3\u7684\u8d44\u6e90\u5206\u914d\u5219\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u8fdd\u53cd\u670d\u52a1\u7b49\u7ea7\u534f\u8bae\uff08SLA\uff09\u3002\u73b0\u6709\u7684\u53cd\u5e94\u5f0f\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u9608\u503c\u548c\u6392\u961f\u8bba\u7684\u7b56\u7565\uff09\u5728\u6027\u80fd\u4e0b\u964d\u540e\u624d\u8fdb\u884c\u6269\u5c55\uff0c\u800c\u57fa\u4e8eRL\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6a21\u62df\uff0c\u9884\u6d4b\u6027\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5219\u9762\u4e34\u5728\u7ebf\u5206\u5e03\u548c\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4\uff1a1. \u4f7f\u7528GRU\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4e0a\u6e38\u8d1f\u8f7d\uff0c\u5e76\u5229\u7528\u771f\u5b9e\u548c\u5408\u6210\u7684DSP\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u30022. \u5efa\u7acb\u4e00\u4e2a\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528DTW\u7b97\u6cd5\u548c\u8054\u5408\u5206\u5e03\u9002\u5e94\u6765\u5904\u7406\u79bb\u7ebf\u548c\u5728\u7ebf\u57df\u7684\u5dee\u5f02\uff0c\u5e76\u5c06\u9884\u6d4b\u6a21\u578b\u96c6\u6210\u5230\u5728\u7ebf\u6d41\u5904\u7406\u7cfb\u7edf\u4e2d\u30023. \u5b9e\u73b0\u4e00\u4e2a\u6c34\u5e73\u81ea\u52a8\u6269\u5c55\u6a21\u5757\uff0c\u6839\u636e\u9884\u6d4b\u7684\u8d1f\u8f7d\u5e76\u8003\u8651\u8fb9\u7f18\u8d44\u6e90\u7ea6\u675f\u6765\u52a8\u6001\u8c03\u6574\u7b97\u5b50\u5e76\u884c\u5ea6\u3002", "result": "GRU\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684SMAPE\u503c\u6700\u9ad8\u8fbe\u52301.3%\uff0c\u5728SMAPE\u548cRMSE\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u4f18\u4e8eCNN\u3001ARIMA\u548cProphet\u6a21\u578b\uff0c\u5e76\u4e14\u8bad\u7ec3\u65f6\u95f4\u6bd4\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684RL\u6a21\u578b\u66f4\u77ed\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9884\u6d4b\u6a21\u578b\u901a\u8fc7GRU\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e861.3%\u7684SMAPE\u503c\uff0c\u5e76\u4e14\u5728SMAPE\u548cRMSE\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8eCNN\u3001ARIMA\u548cProphet\u6a21\u578b\uff0c\u540c\u65f6\u8bad\u7ec3\u65f6\u95f4\u4e5f\u6bd4\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684RL\u6a21\u578b\u66f4\u77ed\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u6a21\u578b\u3001\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\u548c\u6c34\u5e73\u81ea\u52a8\u6269\u5c55\u6a21\u5757\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u6d41\u5904\u7406\u7684\u81ea\u52a8\u6269\u5c55\u95ee\u9898\uff0c\u80fd\u591f\u5728\u8003\u8651\u8fb9\u7f18\u8d44\u6e90\u9650\u5236\u7684\u540c\u65f6\uff0c\u6839\u636e\u9884\u6d4b\u8d1f\u8f7d\u52a8\u6001\u8c03\u6574\u7b97\u5b50\u5e76\u884c\u5ea6\u3002"}}
{"id": "2507.14274", "categories": ["cs.RO", "cs.NA", "math.DG", "math.DS", "math.GR", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.14274", "abs": "https://arxiv.org/abs/2507.14274", "authors": ["Andreas Mueller", "Shivesh Kumar", "Thomas Kordik"], "title": "A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators", "comment": null, "summary": "Series elastic actuators (SEA) were introduced for serial robotic arms. Their\nmodel-based trajectory tracking control requires the second time derivatives of\nthe inverse dynamics solution, for which algorithms were proposed. Trajectory\ncontrol of parallel kinematics manipulators (PKM) equipped with SEAs has not\nyet been pursued. Key element for this is the computationally efficient\nevaluation of the second time derivative of the inverse dynamics solution. This\nhas not been presented in the literature, and is addressed in the present paper\nfor the first time. The special topology of PKM is exploited reusing the\nrecursive algorithms for evaluating the inverse dynamics of serial robots. A\nLie group formulation is used and all relations are derived within this\nframework. Numerical results are presented for a 6-DOF Gough-Stewart platform\n(as part of an exoskeleton), and for a planar PKM when a flatness-based control\nscheme is applied.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u5e76\u8054\u673a\u5668\u4eba\u7684SEA\u9006\u52a8\u529b\u5b66\u4e8c\u9636\u5bfc\u6570\uff0c\u5e76\u7528\u4e8e\u63a7\u5236\u5e94\u7528\u3002", "motivation": "\u76ee\u524d\uff0c\u5bf9\u88c5\u6709SEA\u7684\u5e76\u8054\u8fd0\u52a8\u89c4\u5212\u5668\uff08PKM\uff09\u7684\u8f68\u8ff9\u63a7\u5236\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\uff0c\u7279\u522b\u662f\u5176\u9006\u52a8\u529b\u5b66\u89e3\u7684\u4e8c\u9636\u65f6\u95f4\u5bfc\u6570\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u89e3\u51b3\u3002\u672c\u6587\u65e8\u5728\u9996\u6b21\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4e3aPKM\u7684\u8f68\u8ff9\u63a7\u5236\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u674e\u7fa4\uff08Lie group\uff09\u7406\u8bba\u548c\u4e32\u8054\u673a\u5668\u4eba\u9012\u5f52\u7b97\u6cd5\u6765\u9ad8\u6548\u8ba1\u7b97\u5e76\u8054\u673a\u5668\u4eba\uff08PKM\uff09\u7684\u9006\u52a8\u529b\u5b66\u89e3\u7684\u4e8c\u9636\u65f6\u95f4\u5bfc\u6570\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u590d\u7528\u73b0\u6709\u7b97\u6cd5\u6765\u5904\u7406PKM\u7684\u7279\u6b8a\u62d3\u6251\u7ed3\u6784\u3002", "result": "\u901a\u8fc7\u5bf96-DOF Gough-Stewart\u5e73\u53f0\u548c\u5e73\u9762PKM\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u5730\u8ba1\u7b97\u9006\u52a8\u529b\u5b66\u89e3\u7684\u4e8c\u9636\u65f6\u95f4\u5bfc\u6570\uff0c\u5e76\u53ef\u5e94\u7528\u4e8e\u57fa\u4e8e\u5e73\u5766\u6027\u7684\u63a7\u5236\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e32\u8054\u673a\u5668\u4eba\u548c\u5e76\u8054\u673a\u5668\u4eba\uff08PRM\uff09\u7684\u7cfb\u5217\u5f39\u6027\u6267\u884c\u5668\uff08SEA\uff09\u7684\u9006\u52a8\u529b\u5b66\u89e3\u7684\u4e8c\u9636\u65f6\u95f4\u5bfc\u6570\u8bc4\u4f30\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u674e\u7fa4\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u4eff\u771f\u9a8c\u8bc1\u3002"}}
{"id": "2507.14303", "categories": ["cs.CV", "I.4.8"], "pdf": "https://arxiv.org/pdf/2507.14303", "abs": "https://arxiv.org/abs/2507.14303", "authors": ["Ehsan Rassekh"], "title": "Semantic Segmentation based Scene Understanding in Autonomous Vehicles", "comment": "74 pages, 35 figures, Master's Thesis, Institute for Advanced Studies\n  in Basic Sciences (IASBS), Zanjan, Iran, 2023", "summary": "In recent years, the concept of artificial intelligence (AI) has become a\nprominent keyword because it is promising in solving complex tasks. The need\nfor human expertise in specific areas may no longer be needed because machines\nhave achieved successful results using artificial intelligence and can make the\nright decisions in critical situations. This process is possible with the help\nof deep learning (DL), one of the most popular artificial intelligence\ntechnologies. One of the areas in which the use of DL is used is in the\ndevelopment of self-driving cars, which is very effective and important. In\nthis work, we propose several efficient models to investigate scene\nunderstanding through semantic segmentation. We use the BDD100k dataset to\ninvestigate these models. Another contribution of this work is the usage of\nseveral Backbones as encoders for models. The obtained results show that\nchoosing the appropriate backbone has a great effect on the performance of the\nmodel for semantic segmentation. Better performance in semantic segmentation\nallows us to understand better the scene and the environment around the agent.\nIn the end, we analyze and evaluate the proposed models in terms of accuracy,\nmean IoU, and loss function, and the results show that these metrics are\nimproved.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u51e0\u79cd\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u8bed\u4e49\u5206\u5272\u6a21\u578b\uff0c\u91cd\u70b9\u662f\u9aa8\u5e72\u7f51\u7edc\u7684\u9009\u62e9\uff0c\u5e76\u53d6\u5f97\u4e86\u6539\u8fdb\u7684\u6027\u80fd\u6307\u6807\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u548c\u5728\u5173\u952e\u60c5\u51b5\u4e0b\u505a\u51fa\u6b63\u786e\u51b3\u7b56\u65b9\u9762\u7684\u6f5c\u529b\u65e5\u76ca\u663e\u73b0\uff0c\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u6765\u6539\u8fdb\u573a\u666f\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u51e0\u79cd\u6709\u6548\u7684\u6a21\u578b\u6765\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u7814\u7a76\u573a\u666f\u7406\u89e3\uff0c\u5e76\u4f7f\u7528 BDD100k \u6570\u636e\u96c6\u8fdb\u884c\u7814\u7a76\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528\u4e86\u51e0\u79cd\u9aa8\u5e72\u7f51\u7edc\u4f5c\u4e3a\u6a21\u578b\u7684\u7f16\u7801\u5668\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728 BDD100k \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u9009\u62e9\u5408\u9002\u7684\u9aa8\u5e72\u7f51\u7edc\u5bf9\u6a21\u578b\u7684\u8bed\u4e49\u5206\u5272\u6027\u80fd\u6709\u5f88\u5927\u5f71\u54cd\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u6307\u6807\uff08\u51c6\u786e\u6027\u3001\u5e73\u5747 IoU \u548c\u635f\u5931\u51fd\u6570\uff09\u5747\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u5e73\u5747 IoU \u548c\u635f\u5931\u51fd\u6570\u65b9\u9762\u5f97\u5230\u4e86\u6539\u8fdb\uff0c\u63d0\u9ad8\u4e86\u8bed\u4e49\u5206\u5272\u7684\u6027\u80fd\uff0c\u4ece\u800c\u66f4\u597d\u5730\u7406\u89e3\u573a\u666f\u548c\u5468\u56f4\u73af\u5883\u3002"}}
{"id": "2507.14267", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14267", "abs": "https://arxiv.org/abs/2507.14267", "authors": ["Ziqi Wang", "Hongshuo Huang", "Hancheng Zhao", "Changwen Xu", "Shang Zhu", "Jan Janssen", "Venkatasubramanian Viswanathan"], "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation", "comment": "34 pages, 28 pages of Supporting Information", "summary": "Materials discovery relies on high-throughput, high-fidelity simulation\ntechniques such as Density Functional Theory (DFT), which require years of\ntraining, extensive parameter fine-tuning and systematic error handling. To\naddress these challenges, we introduce the DFT-based Research Engine for\nAgentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for\nDFT simulation that combines a central Large Language Model (LLM) planner agent\nwith domain-specific LLM agents for atomistic structure generation, systematic\nDFT convergence testing, High-Performance Computing (HPC) scheduling, and error\nhandling. In addition, a shared canvas helps the LLM agents to structure their\ndiscussions, preserve context and prevent hallucination. We validate DREAMS\ncapabilities on the Sol27LC lattice-constant benchmark, achieving average\nerrors below 1\\% compared to the results of human DFT experts. Furthermore, we\napply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating\nits long-term and complex problem-solving capabilities. The framework again\nreproduces expert-level literature adsorption-energy differences. Finally,\nDREAMS is employed to quantify functional-driven uncertainties with Bayesian\nensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at\nthe Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS\napproaches L3-level automation - autonomous exploration of a defined design\nspace - and significantly reduces the reliance on human expertise and\nintervention, offering a scalable path toward democratized, high-throughput,\nhigh-fidelity computational materials discovery.", "AI": {"tldr": "DREAMS \u662f\u4e00\u4e2a\u7531 LLM \u9a71\u52a8\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e DFT \u6750\u6599\u53d1\u73b0\uff0c\u53ef\u81ea\u4e3b\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u4e13\u5bb6\u7684\u4f9d\u8d56\uff0c\u5e76\u8fbe\u5230\u4e13\u5bb6\u7ea7\u522b\u6c34\u5e73\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9ad8\u901a\u91cf\u3001\u9ad8\u4fdd\u771f\u5ea6\u7684\u6750\u6599\u53d1\u73b0\u4e2d\uff0c\u5982\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u6a21\u62df\u6240\u9700\u591a\u5e74\u7684\u57f9\u8bad\u3001\u5e7f\u6cdb\u7684\u53c2\u6570\u5fae\u8c03\u548c\u7cfb\u7edf\u6027\u9519\u8bef\u5904\u7406\u7b49\u6311\u6218\u3002", "method": "DREAMS \u662f\u4e00\u4e2a\u57fa\u4e8e DFT \u7684\u3001\u5206\u5c42\u7684\u3001\u591a\u667a\u80fd\u4f53\u7684\u6750\u6599\u7b5b\u9009\u7814\u7a76\u5f15\u64ce\u3002\u5b83\u7ed3\u5408\u4e86\u4e00\u4e2a\u4e2d\u5fc3\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u89c4\u5212\u5668\u667a\u80fd\u4f53\uff0c\u4ee5\u53ca\u7528\u4e8e\u539f\u5b50\u7ed3\u6784\u751f\u6210\u3001\u7cfb\u7edf\u6027 DFT \u6536\u655b\u6027\u6d4b\u8bd5\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u8c03\u5ea6\u548c\u9519\u8bef\u5904\u7406\u7684\u9886\u57df\u7279\u5b9a LLM \u667a\u80fd\u4f53\u3002\u6b64\u5916\uff0c\u4e00\u4e2a\u5171\u4eab\u753b\u5e03\u6709\u52a9\u4e8e LLM \u667a\u80fd\u4f53\u6784\u5efa\u5b83\u4eec\u7684\u8ba8\u8bba\u3001\u4fdd\u5b58\u4e0a\u4e0b\u6587\u5e76\u9632\u6b62\u5e7b\u89c9\u3002", "result": "DREAMS \u5728 Sol27LC \u6676\u683c\u5e38\u6570\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u5bf9\u4e8e\u4eba\u7c7b DFT \u4e13\u5bb6\u7684\u7ed3\u679c\uff0c\u5b9e\u73b0\u4e86\u4f4e\u4e8e 1% \u7684\u5e73\u5747\u8bef\u5dee\u3002\u5728 CO/Pt(111) \u5438\u9644\u95ee\u9898\u4e2d\uff0cDREAMS \u91cd\u73b0\u4e86\u4e13\u5bb6\u7ea7\u522b\u7684\u6587\u732e\u5438\u9644\u80fd\u91cf\u5dee\u5f02\u3002\u6b64\u5916\uff0cDREAMS \u88ab\u7528\u4e8e\u901a\u8fc7\u8d1d\u53f6\u65af\u96c6\u6210\u91c7\u6837\u6765\u91cf\u5316\u529f\u80fd\u9a71\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8bc1\u5b9e\u4e86\u5728\u5e7f\u4e49\u68af\u5ea6\u8fd1\u4f3c\uff08GGA\uff09DFT \u7ea7\u522b\u4e0a\uff0c\u9762\u5fc3\u7acb\u65b9\uff08FCC\uff09\u4f4d\u70b9\u7684\u504f\u597d\u3002", "conclusion": "DREAMS \u5b9e\u73b0\u4e86 L3 \u7ea7\u522b\u7684\u81ea\u52a8\u5316\uff08\u5728\u5b9a\u4e49\u7684\u7a7a\u95f4\u5185\u81ea\u4e3b\u63a2\u7d22\uff09\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u548c\u5e72\u9884\u7684\u4f9d\u8d56\uff0c\u4e3a\u5b9e\u73b0\u9ad8\u901a\u91cf\u3001\u9ad8\u4fdd\u771f\u5ea6\u7684\u8ba1\u7b97\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9014\u5f84\u3002"}}
{"id": "2507.14357", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14357", "abs": "https://arxiv.org/abs/2507.14357", "authors": ["Maxwell Wisne", "Venkat Chandrasekhar"], "title": "Supercurrent tuning of the Josephson coupling energy", "comment": "5 pages, 3 figures", "summary": "The ability to non-dissipatively tune the Josephson coupling energy of\nJosephson junctions is a useful tool in frequency-tunable qubits. This is\ntypically done by threading magnetic flux through two junctions connected in a\nloop, a geometry that exposes the qubit to magnetic environmental noise. In\nthis paper, we show that by biasing a junction with supercurrent from a\nseparate pair of superconducting leads coupled to the device, the Josephson\nenergy can be tuned without the need for a flux loop. Our multiterminal device\nmay enable the realization of a frequency-tunable qubit with greatly reduced\nsusceptibility to flux noise.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8c03\u8c10\u7ea6\u745f\u592b\u68ee\u7ed3\u7684\u80fd\u91cf\uff0c\u65e0\u9700\u78c1\u901a\u91cf\u56de\u8def\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u91cf\u5b50\u6bd4\u7279\u5bf9\u78c1\u566a\u58f0\u7684\u654f\u611f\u6027\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u9ad8\u6027\u80fd\u7684\u91cf\u5b50\u6bd4\u7279\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u7ea6\u745f\u592b\u68ee\u7ed3\u8c03\u8c10\u4e2d\u78c1\u901a\u91cf\u56de\u8def\u66b4\u9732\u4e8e\u78c1\u566a\u58f0\u7684\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u9891\u7387\u53ef\u8c03\u91cf\u5b50\u6bd4\u7279\u3002", "method": "\u901a\u8fc7\u5c06\u8d85\u5bfc\u7ebf\u8026\u5408\u5230\u5668\u4ef6\uff0c\u5e76\u7528\u8d85\u7535\u6d41\u504f\u7f6e\u7ea6\u745f\u592b\u68ee\u7ed3\u6765\u8c03\u8282\u5176\u7ea6\u745f\u592b\u68ee\u80fd\u91cf\uff0c\u800c\u65e0\u9700\u78c1\u901a\u91cf\u56de\u8def\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7aef\u5668\u4ef6\uff0c\u901a\u8fc7\u8d85\u7535\u6d41\u8c03\u8282\u7ea6\u745f\u592b\u68ee\u80fd\u91cf\uff0c\u53ef\u51cf\u5c11\u5bf9\u78c1\u901a\u566a\u58f0\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u5668\u4ef6\u53ef\u4ee5\u901a\u8fc7\u8d85\u7535\u6d41\u8c03\u8282\u7ea6\u745f\u592b\u68ee\u80fd\u91cf\uff0c\u4ece\u800c\u65e0\u9700\u78c1\u901a\u91cf\u56de\u8def\u5373\u53ef\u8c03\u8c10\u7ea6\u745f\u592b\u68ee\u7ed3\u7684\u7ea6\u745f\u592b\u68ee\u8026\u5408\u80fd\u91cf\uff0c\u6709\u671b\u5b9e\u73b0\u4f4e\u78c1\u901a\u566a\u58f0\u7684\u9891\u7387\u53ef\u8c03\u91cf\u5b50\u6bd4\u7279\u3002"}}
{"id": "2507.14995", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.14995", "abs": "https://arxiv.org/abs/2507.14995", "authors": ["Chengwei Lou", "Zekai Jin", "Wei Tang", "Guangfei Geng", "Jin Yang", "Lu Zhang"], "title": "LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading", "comment": null, "summary": "Real-time peer-to-peer (P2P) electricity markets dynamically adapt to\nfluctuations in renewable energy and variations in demand, maximizing economic\nbenefits through instantaneous price responses while enhancing grid\nflexibility. However, scaling expert guidance for massive personalized\nprosumers poses critical challenges, including diverse decision-making demands\nand lack of customized modeling frameworks. This paper proposed an integrated\nlarge language model-multi-agent reinforcement learning (LLM-MARL) framework\nfor real-time P2P energy trading to address challenges such as the limited\ntechnical capability of prosumers, the lack of expert experience, and security\nissues of distribution networks. LLMs are introduced as experts to generate\npersonalized strategy, guiding MARL under the centralized training with\ndecentralized execution (CTDE) paradigm through imitation learning. A\ndifferential attention-based critic network is designed to enhance convergence\nperformance. Experimental results demonstrate that LLM generated strategies\neffectively substitute human experts. The proposed multi-agent imitation\nlearning algorithms achieve significantly lower economic costs and voltage\nviolation rates on test sets compared to baselines algorithms, while\nmaintaining robust stability. This work provides an effective solution for\nreal-time P2P electricity market decision-making by bridging expert knowledge\nwith agent learning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faLLM-MARL\u6846\u67b6\uff0c\u901a\u8fc7LLM\u63d0\u4f9b\u4e2a\u6027\u5316\u7b56\u7565\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\uff0c\u4ee5\u89e3\u51b3\u5b9e\u65f6P2P\u7535\u529b\u4ea4\u6613\u4e2d\u7684\u7528\u6237\u80fd\u529b\u3001\u4e13\u5bb6\u7ecf\u9a8c\u548c\u7535\u7f51\u5b89\u5168\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u964d\u4f4e\u6210\u672c\u548c\u63d0\u9ad8\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5b9e\u65f6P2P\u7535\u529b\u5e02\u573a\u5728\u9002\u5e94\u53ef\u518d\u751f\u80fd\u6e90\u6ce2\u52a8\u548c\u9700\u6c42\u53d8\u5316\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u4e3a\u5927\u89c4\u6a21\u4e2a\u6027\u5316\u4ea7\u6d88\u8005\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\u9762\u4e34\u6311\u6218\uff0c\u5305\u62ec\u591a\u6837\u5316\u7684\u51b3\u7b56\u9700\u6c42\u548c\u5b9a\u5236\u5316\u5efa\u6a21\u6846\u67b6\u7684\u7f3a\u4e4f\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u7684LLM-MARL\u6846\u67b6\uff0c\u5176\u4e2dLLM\u4f5c\u4e3a\u4e13\u5bb6\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u751f\u6210\u4e2a\u6027\u5316\u7b56\u7565\uff0c\u6307\u5bfcCTDE\u8303\u5f0f\u4e0b\u7684MARL\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u7684Critic\u7f51\u7edc\u6765\u63d0\u5347\u6536\u655b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u751f\u6210\u7684\u7b56\u7565\u80fd\u591f\u6709\u6548\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u3002\u4e0e\u57fa\u7ebf\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u7ecf\u6d4e\u6210\u672c\u548c\u7535\u538b\u8fdd\u89c4\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9c81\u68d2\u6027\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5b9e\u65f6\u70b9\u5bf9\u70b9\uff08P2P\uff09\u7535\u529b\u4ea4\u6613\u4e2d\u7684\u6311\u6218\uff0c\u5982\u7528\u6237\u6280\u672f\u80fd\u529b\u6709\u9650\u3001\u7f3a\u4e4f\u4e13\u5bb6\u7ecf\u9a8c\u548c\u7535\u7f51\u5b89\u5168\u95ee\u9898\u3002LLM\u4f5c\u4e3a\u4e13\u5bb6\u751f\u6210\u4e2a\u6027\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u6307\u5bfcCTDE\uff08\u96c6\u4e2d\u8bad\u7ec3\u53bb\u4e2d\u5fc3\u5316\u6267\u884c\uff09\u8303\u5f0f\u4e0b\u7684MARL\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u751f\u6210\u7684\u7b56\u7565\u80fd\u6709\u6548\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\u5728\u7ecf\u6d4e\u6210\u672c\u548c\u7535\u538b\u8fdd\u89c4\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9c81\u68d2\u6027\u7a33\u5b9a\u6027\u3002"}}
{"id": "2507.14171", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14171", "abs": "https://arxiv.org/abs/2507.14171", "authors": ["Jaeheun Jung", "Jaehyuk Lee", "Yeajin Lee", "Donghun Lee"], "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning", "comment": null, "summary": "With the growth of demand on neural network compression methods, the\nstructured pruning methods including importance-based approach are actively\nstudied. The magnitude importance and many correlated modern importance\ncriteria often limit the capacity of pruning decision, since the filters with\nlarger magnitudes are not likely to be pruned if the smaller one didn't, even\nif it is redundant. In this paper, we propose a novel pruning strategy to\nchallenge this dominating effect of magnitude and provide fair chance to each\nfilter to be pruned, by placing it on projective space. After that, we observe\nthe gradient descent movement whether the filters move toward the origin or\nnot, to measure how the filter is likely to be pruned. This measurement is used\nto construct PROscore, a novel importance score for IPPRO, a novel\nimportance-based structured pruning with magnitude-indifference. Our evaluation\nresults shows that the proposed importance criteria using the projective space\nachieves near-lossless pruning by reducing the performance drop in pruning,\nwith promising performance after the finetuning. Our work debunks the\n``size-matters'' myth in pruning and expands the frontier of importance-based\npruning both theoretically and empirically.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u526a\u679d\u7b56\u7565\uff0c\u5c06\u6ee4\u6ce2\u5668\u7f6e\u4e8e\u6295\u5f71\u7a7a\u95f4\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u79fb\u52a8\u5224\u65ad\u5176\u88ab\u4fee\u526a\u7684\u53ef\u80fd\u6027\uff0c\u5f15\u5165PROscore\u8bc4\u5206\uff0c\u5b9e\u73b0\u63a5\u8fd1\u65e0\u635f\u526a\u679d\uff0c\u6253\u7834\u201c\u5c3a\u5bf8\u81f3\u4e0a\u201d\u8ff7\u601d\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u65b9\u6cd5\uff09\u53d7\u9650\u4e8e\u5e45\u5ea6\u91cd\u8981\u6027\u53ca\u5176\u76f8\u5173\u6807\u51c6\uff0c\u8fd9\u4e9b\u6807\u51c6\u503e\u5411\u4e8e\u4fdd\u7559\u5e45\u5ea6\u8f83\u5927\u7684\u6ee4\u6ce2\u5668\uff0c\u5373\u4f7f\u5b83\u4eec\u662f\u5197\u4f59\u7684\uff0c\u4ece\u800c\u9650\u5236\u4e86\u526a\u679d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u526a\u679d\u7b56\u7565\uff0c\u5c06\u6ee4\u6ce2\u5668\u7f6e\u4e8e\u6295\u5f71\u7a7a\u95f4\u4e2d\uff0c\u901a\u8fc7\u89c2\u5bdf\u68af\u5ea6\u4e0b\u964d\u7684\u79fb\u52a8\u65b9\u5411\u6765\u8861\u91cf\u6ee4\u6ce2\u5668\u88ab\u4fee\u526a\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u6784\u5efa\u4e86PROscore\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u7528\u4e8eIPPRO\uff08\u4e00\u79cd\u65b0\u9896\u7684\u3001\u4e0d\u8003\u8651\u5e45\u5ea6\u7684\u3001\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6295\u5f71\u7a7a\u95f4\u7684\u91cd\u8981\u6027\u8bc4\u4f30\u6807\u51c6\u901a\u8fc7\u964d\u4f4e\u526a\u679d\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u526a\u679d\u6548\u679c\uff0c\u5e76\u5728\u5fae\u8c03\u540e\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6295\u5f71\u7a7a\u95f4\u7684\u65b0\u578b\u526a\u679d\u7b56\u7565\u901a\u8fc7\u5f15\u5165PROscore\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u526a\u679d\u6548\u679c\uff0c\u5e76\u5728\u5fae\u8c03\u540e\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002\u8be5\u7814\u7a76\u6253\u7834\u4e86\u201c\u5c3a\u5bf8\u81f3\u4e0a\u201d\u7684\u526a\u679d\u89c2\u5ff5\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u62d3\u5c55\u4e86\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u526a\u679d\u65b9\u6cd5\u3002"}}
{"id": "2507.14292", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14292", "abs": "https://arxiv.org/abs/2507.14292", "authors": ["Zhenqi Hua", "Chang Niu", "Sandeep Joy", "Pukun Tan", "Gang Shi", "Haoyang Liu", "Jiaxing Guo", "David Graf", "Peide Ye", "Cyprian Lewandowski", "Peng Xiong"], "title": "Interplay of orbital and spin magnetization in trigonal tellurium", "comment": null, "summary": "Orbital effects, despite their fundamental significance and potential to\nengender novel physical phenomena and enable new applications, have long been\nunderexplored compared to their spin counterparts. Recently, surging interest\nin the orbital degree of freedom has led to the discovery of a plethora of\norbital-related effects, underscoring the need for a deeper understanding of\ntheir roles in quantum materials. Here, we report first experimental signatures\nof orbital magnetization in trigonal Tellurium, an elemental semiconductor with\na unique helical crystal structure that serves as a natural platform for\ninvestigating orbital effects. Detailed angular dependent linear and nonlinear\nmagnetotransport measurements, supported by theoretical Boltzmann transport\nanalysis, reveal the coexistence of current-induced spin polarization and\norbital magnetization. By disentangling the interplay between spin and orbital\ndegrees of freedom, this work establishes a general framework for understanding\norbital magnetization in chiral crystals and beyond, paving the way for its\nutilization in orbitronics and spintronics.", "AI": {"tldr": "\u4e09\u89d2\u78b2\u4e2d\u7684\u8f68\u9053\u78c1\u5316\u7814\u7a76\u3002", "motivation": "\u7531\u4e8e\u8f68\u9053\u6548\u5e94\u76f8\u5bf9\u4e8e\u81ea\u65cb\u6548\u5e94\u7684\u6f5c\u529b\u88ab\u4f4e\u4f30\uff0c\u4f46\u8fd1\u5e74\u6765\u5176\u5728\u91cf\u5b50\u6750\u6599\u4e2d\u7684\u4f5c\u7528\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7406\u89e3\u8f68\u9053\u6548\u5e94\u3002", "method": "\u901a\u8fc7\u8be6\u7ec6\u7684\u89d2\u4f9d\u8d56\u7ebf\u6027\u53ca\u975e\u7ebf\u6027\u78c1\u8f93\u8fd0\u6d4b\u91cf\uff0c\u5e76\u7ed3\u5408\u7406\u8bba\u73bb\u5c14\u5179\u66fc\u8f93\u8fd0\u5206\u6790\uff0c\u5206\u79bb\u4e86\u81ea\u65cb\u548c\u8f68\u9053\u81ea\u7531\u5ea6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u4e86\u4e09\u89d2\u78b2\u4e2d\u5b58\u5728\u7531\u7535\u6d41\u5f15\u8d77\u7684\u81ea\u65cb\u6781\u5316\u548c\u8f68\u9053\u78c1\u5316\uff0c\u63ed\u793a\u4e86\u5176\u81ea\u65cb\u548c\u8f68\u9053\u81ea\u7531\u5ea6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u4e09\u89d2\u78b2\u4e2d\u8f68\u9053\u78c1\u5316\u7684\u5b58\u5728\uff0c\u4e3a\u5728\u624b\u6027\u6676\u4f53\u53ca\u5176\u4ed6\u6750\u6599\u4e2d\u5229\u7528\u8f68\u9053\u78c1\u5316\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u671b\u5e94\u7528\u4e8e\u8f68\u9053\u7535\u5b50\u5b66\u548c\u81ea\u65cb\u7535\u5b50\u5b66\u3002"}}
{"id": "2507.14347", "categories": ["eess.SY", "cs.SE", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14347", "abs": "https://arxiv.org/abs/2507.14347", "authors": ["Ole Hans", "Benedikt Walter"], "title": "Remote Assistance or Remote Driving: The Impact of Operational Design Domains on ADS-Supporting Systems Selection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "High level Automated Driving Systems (ADS) can handle many situations, but\nthey still encounter situations where human intervention is required. In\nsystems where a physical driver is present in the vehicle, typically SAE Level\n3 systems, this intervention is relatively straightforward and is handled by\nthe in-vehicle driver. However, the complexity increases for Level 4 systems,\nwhere, in most cases, no physical driver remains in the vehicle. The two common\nindustry solutions for this challenge are the integration of a remote support\nsystem, such as a Remote Driving System (RDS) or Remote Assistance System\n(RAS). While it is clear that ADS will require one of these systems, it is less\nclear how the suitability of either system for a particular ADS application\nshould be evaluated. Currently, the selection process often focuses on system\narchitecture as well as its design and integration challenges. Furthermore,\nsince many ADS developers choose to develop remote system solutions in-house,\nit is advantageous to select the simpler approach to streamline development and\nintegration efforts. While these decision points are certainly relevant, this\napproach overlooks the most critical factors: the use cases and the\ncomplementarity of the ADS and the remote support system within the context of\nthe Operational Design Design Domain (ODD). This paper proposes a structured\napproach for selecting between RDS and RAS as an ADS support system, based on\nthe defined ODD and use case analysis. To achieve this, the paper applies the\nPEGASUS framework to systematically describe and analyze the ODD. A structured\nframework is introduced to evaluate and select the most suitable remote support\nsystem for an ADS based on clearly defined criteria.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\uff0c\u91cd\u70b9\u662f\u8fd0\u884c\u8bbe\u8ba1\u57df\uff08ODD\uff09\u548c\u7528\u4f8b\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u5173\u6ce8\u6280\u672f\u65b9\u9762\u3002", "motivation": "\u5f53\u524d\u884c\u4e1a\u5728\u9009\u62e9\u8fdc\u7a0b\u9a7e\u9a76\u7cfb\u7edf\uff08RDS\uff09\u6216\u8fdc\u7a0b\u534f\u52a9\u7cfb\u7edf\uff08RAS\uff09\u4f5c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u7684\u652f\u6301\u7cfb\u7edf\u65f6\uff0c\u5f80\u5f80\u4fa7\u91cd\u4e8e\u7cfb\u7edf\u67b6\u6784\u3001\u8bbe\u8ba1\u548c\u96c6\u6210\u6311\u6218\uff0c\u800c\u5ffd\u7565\u4e86\u7528\u4f8b\u4ee5\u53caADS\u548c\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\u5728\u8fd0\u884c\u8bbe\u8ba1\u57df\uff08ODD\uff09\u4e2d\u7684\u4e92\u8865\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5e94\u7528PEGASUS\u6846\u67b6\u6765\u7cfb\u7edf\u5730\u63cf\u8ff0\u548c\u5206\u6790ODD\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u548c\u9009\u62e9\u6700\u9002\u5408ADS\u7684\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\uff0c\u8be5\u9009\u62e9\u57fa\u4e8e\u6e05\u6670\u5b9a\u4e49\u7684\u6807\u51c6\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6839\u636e\u5b9a\u4e49\u7684ODD\u548c\u7528\u4f8b\u5206\u6790\u6765\u9009\u62e9RDS\u6216RAS\u4f5c\u4e3aADS\u7684\u652f\u6301\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eODD\u548c\u7528\u4f8b\u5206\u6790\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728RDS\u548cRAS\u4e4b\u95f4\u8fdb\u884c\u9009\u62e9\uff0c\u4ee5\u4f5c\u4e3aADS\u7684\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2507.14323", "categories": ["quant-ph", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.14323", "abs": "https://arxiv.org/abs/2507.14323", "authors": ["Jaswanthi Mandalapu", "Vikesh Siddhu", "Krishna Jagannathan"], "title": "Polar Codes for Erasure and Unital Classical-Quantum Markovian Channels", "comment": null, "summary": "We consider classical-quantum (cq-)channels with memory, and establish that\nAr{\\i}kan-constructed polar codes achieve the classical capacity for two key\nnoise models, namely for (i) qubit erasures and (ii) unital qubit noise with\nchannel state information at the receiver. The memory in the channel is assumed\nto be governed by a discrete-time, countable-state, aperiodic, irreducible, and\npositive recurrent Markov process. We establish this result by leveraging\nexisting classical polar coding guarantees established for finite-state,\naperiodic, and irreducible Markov processes [FAIM], alongside the recent\nfinding that no entanglement is required to achieve the capacity of Markovian\nunital and erasure quantum channels when transmitting classical information.\nMore broadly, our work illustrates that for cq-channels with memory, where an\noptimal coding strategy is essentially classical, polar codes can be shown to\napproach the capacity.", "AI": {"tldr": "\u5bf9\u4e8e\u5177\u6709\u8bb0\u5fc6\u7684\u7ecf\u5178-\u91cf\u5b50\u4fe1\u9053\uff0c\u6781\u5316\u7801\u53ef\u4ee5\u8fbe\u5230\u91cf\u5b50\u6bd4\u7279\u64e6\u9664\u548c\u5177\u6709\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u5728\u63a5\u6536\u7aef\u7684\u5355\u91cf\u5b50\u6bd4\u7279\u566a\u58f0\u7684\u7ecf\u5178\u5bb9\u91cf\u3002", "motivation": "\u8003\u8651\u5177\u6709\u8bb0\u5fc6\u7684\u7ecf\u5178-\u91cf\u5b50\uff08CQ\uff09\u4fe1\u9053\uff0c\u5e76\u786e\u5b9aAr\u0131kan\u6784\u9020\u7684\u6781\u5316\u7801\u662f\u5426\u80fd\u8fbe\u5230\u4e24\u79cd\u5173\u952e\u566a\u58f0\u6a21\u578b\u7684\u7ecf\u5178\u5bb9\u91cf\uff0c\u5373\uff08i\uff09\u91cf\u5b50\u6bd4\u7279\u64e6\u9664\u548c\uff08ii\uff09\u5177\u6709\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u5355\u91cf\u5b50\u6bd4\u7279\u566a\u58f0\u3002", "method": "\u901a\u8fc7\u5229\u7528\u73b0\u6709\u7684\u9488\u5bf9\u6709\u9650\u72b6\u6001\u3001\u975e\u5468\u671f\u548c\u4e0d\u53ef\u7ea6\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u7ecf\u5178\u6781\u5316\u7f16\u7801\u4fdd\u8bc1\uff0c\u4ee5\u53ca\u6700\u8fd1\u53d1\u73b0\u7684\u5728\u4f20\u8f93\u7ecf\u5178\u4fe1\u606f\u65f6\uff0c\u65e0\u9700\u7ea0\u7f20\u5373\u53ef\u8fbe\u5230\u9a6c\u5c14\u53ef\u592b\u9149\u548c\u64e6\u9664\u91cf\u5b50\u4fe1\u9053\u7684\u5bb9\u91cf\uff0c\u6765\u5efa\u7acb\u8fd9\u4e00\u7ed3\u679c\u3002", "result": "Ar\u0131kan\u6784\u9020\u7684\u6781\u5316\u7801\u5b9e\u73b0\u4e86\uff08i\uff09\u91cf\u5b50\u6bd4\u7279\u64e6\u9664\u548c\uff08ii\uff09\u5177\u6709\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u5728\u63a5\u6536\u7aef\u7684\u5355\u91cf\u5b50\u6bd4\u7279\u566a\u58f0\u8fd9\u4e24\u79cd\u5173\u952e\u566a\u58f0\u6a21\u578b\u7684\u7ecf\u5178\u5bb9\u91cf\u3002", "conclusion": "\u5bf9\u4e8e\u5177\u6709\u8bb0\u5fc6\u7684\u7ecf\u5178-\u91cf\u5b50\uff08CQ\uff09\u4fe1\u9053\uff0c\u5176\u4e2d\u6700\u4f18\u7f16\u7801\u7b56\u7565\u672c\u8d28\u4e0a\u662f\u7ecf\u5178\u7684\uff0c\u53ef\u4ee5\u8bc1\u660e\u6781\u5316\u7801\u53ef\u4ee5\u903c\u8fd1\u5bb9\u91cf\u3002"}}
{"id": "2507.14198", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14198", "abs": "https://arxiv.org/abs/2507.14198", "authors": ["Fufang Wen", "Shichang Zhang"], "title": "Retention analysis of edited knowledge after fine-tuning", "comment": null, "summary": "Large language models (LLMs) store vast amounts of knowledge, which often\nrequires updates to correct factual errors, incorporate newly acquired\ninformation, or adapt model behavior. Model editing methods have emerged as\nefficient solutions for such updates, offering localized and precise knowledge\nmodification at significantly lower computational cost than continual training.\nIn parallel, LLMs are frequently fine-tuned for a wide range of downstream\ntasks. However, the effect of fine-tuning on previously edited knowledge\nremains poorly understood. In this work, we systematically investigate how\ndifferent fine-tuning objectives interact with various model editing\ntechniques. Our findings show that edited knowledge is substantially more\nsusceptible to forgetting during fine-tuning than intrinsic knowledge acquired\nthrough pre-training. This analysis highlights a key limitation of current\nediting approaches and suggests that evaluating edit robustness under\ndownstream fine-tuning is critical for their practical deployment. We further\nfind that freezing layers associated with edited content can significantly\nimprove knowledge retention, offering insight into how future editing methods\nmight be made more robust.", "AI": {"tldr": "LLM \u7684\u5df2\u7f16\u8f91\u77e5\u8bc6\u5728\u5fae\u8c03\u4e2d\u5bb9\u6613\u9057\u5fd8\uff0c\u51bb\u7ed3\u5c42\u53ef\u6539\u5584\u6b64\u72b6\u51b5\u3002", "motivation": "\u7814\u7a76 LLM \u5fae\u8c03\u5bf9\u6a21\u578b\u7f16\u8f91\u540e\u77e5\u8bc6\u7684\u5f71\u54cd\uff0c\u4ee5\u89e3\u51b3\u5df2\u7f16\u8f91\u77e5\u8bc6\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5bb9\u6613\u88ab\u9057\u5fd8\u7684\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u4e0e\u6a21\u578b\u7f16\u8f91\u6280\u672f\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u5e76\u901a\u8fc7\u51bb\u7ed3\u76f8\u5173\u5c42\u6765\u589e\u5f3a\u77e5\u8bc6\u4fdd\u7559\u3002", "result": "\u5df2\u7f16\u8f91\u77e5\u8bc6\u6bd4\u9884\u8bad\u7ec3\u77e5\u8bc6\u66f4\u5bb9\u6613\u5728\u5fae\u8c03\u4e2d\u9057\u5fd8\uff1b\u51bb\u7ed3\u5c42\u53ef\u4ee5\u63d0\u9ad8\u77e5\u8bc6\u4fdd\u7559\u7387\u3002", "conclusion": "LLM \u77e5\u8bc6\u7f16\u8f91\u540e\u7684\u5185\u5bb9\u5728\u4e0b\u6e38\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u6bd4\u9884\u8bad\u7ec3\u7684\u5185\u5728\u77e5\u8bc6\u66f4\u5bb9\u6613\u88ab\u9057\u5fd8\u3002\u51bb\u7ed3\u4e0e\u7f16\u8f91\u5185\u5bb9\u76f8\u5173\u7684\u5c42\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u77e5\u8bc6\u4fdd\u7559\u7387\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u7f16\u8f91\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.14841", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14841", "abs": "https://arxiv.org/abs/2507.14841", "authors": ["Xiang Tang", "Ruotong Li", "Xiaopeng Fan"], "title": "Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization", "comment": "15 pages, 8 figures, Project page: https://xdlbw.github.io/sing3d/", "summary": "In recent years, 3D generation has made great strides in both academia and\nindustry. However, generating 3D scenes from a single RGB image remains a\nsignificant challenge, as current approaches often struggle to ensure both\nobject generation quality and scene coherence in multi-object scenarios. To\novercome these limitations, we propose a novel three-stage framework for 3D\nscene generation with explicit geometric representations and high-quality\ntextural details via single image-guided model generation and spatial layout\noptimization. Our method begins with an image instance segmentation and\ninpainting phase, which recovers missing details of occluded objects in the\ninput images, thereby achieving complete generation of foreground 3D assets.\nSubsequently, our approach captures the spatial geometry of reference image by\nconstructing pseudo-stereo viewpoint for camera parameter estimation and scene\ndepth inference, while employing a model selection strategy to ensure optimal\nalignment between the 3D assets generated in the previous step and the input.\nFinally, through model parameterization and minimization of the Chamfer\ndistance between point clouds in 3D and 2D space, our approach optimizes layout\nparameters to produce an explicit 3D scene representation that maintains\nprecise alignment with input guidance image. Extensive experiments on\nmulti-object scene image sets have demonstrated that our approach not only\noutperforms state-of-the-art methods in terms of geometric accuracy and texture\nfidelity of individual generated 3D models, but also has significant advantages\nin scene layout synthesis.", "AI": {"tldr": "\u4ece\u5355\u5f20RGB\u56fe\u50cf\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u8fde\u8d2f\u7684\u591a\u7269\u4f533D\u573a\u666f\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5206\u5272\u3001\u4fee\u590d\u3001\u4f2a\u7acb\u4f53\u5339\u914d\u548cChamfer\u8ddd\u79bb\u4f18\u5316\u5e03\u5c40\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4ece\u5355\u4e2aRGB\u56fe\u50cf\u751f\u62103D\u573a\u666f\u65f6\uff0c\u96be\u4ee5\u4fdd\u8bc1\u7269\u4f53\u751f\u6210\u8d28\u91cf\u548c\u573a\u666f\u8fde\u8d2f\u6027\uff0c\u5c24\u5176\u662f\u5728\u591a\u7269\u4f53\u573a\u666f\u4e2d\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u56fe\u50cf\u5b9e\u4f8b\u5206\u5272\u548c\u4fee\u590d\u3001\u4f2a\u7acb\u4f53\u89c6\u56fe\u6784\u5efa\u548c\u6a21\u578b\u9009\u62e9\uff0c\u4ee5\u53ca\u901a\u8fc7 Chamfer \u8ddd\u79bb\u6700\u5c0f\u5316\u8fdb\u884c\u5e03\u5c40\u4f18\u5316\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u51e0\u4f55\u51c6\u786e\u6027\u548c\u7eb9\u7406\u4fdd\u771f\u5ea6\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u573a\u666f\u5e03\u5c40\u5408\u6210\u65b9\u9762\u5177\u6709\u663e\u7740\u4f18\u52bf\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u901a\u8fc7\u663e\u5f0f\u7684\u51e0\u4f55\u8868\u793a\u548c\u9ad8\u8d28\u91cf\u7684\u7eb9\u7406\u7ec6\u8282\uff0c\u5728\u751f\u6210\u5355\u4e2a3D\u6a21\u578b\u548c\u573a\u666f\u5e03\u5c40\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14386", "categories": ["cs.NE", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.14386", "abs": "https://arxiv.org/abs/2507.14386", "authors": ["Yi Cheng", "Zongli Lin"], "title": "Training oscillator Ising machines to assign the dynamic stability of their equilibrium points", "comment": "8 pages, 4 figures", "summary": "We propose a neural network model, which, with appropriate assignment of the\nstability of its equilibrium points (EPs), achieves Hopfield-like associative\nmemory. The oscillator Ising machine (OIM) is an ideal candidates for such a\nmodel, as all its $0/\\pi$ binary EPs are structurally stable with their dynamic\nstability tunable by the coupling weights. Traditional Hopfield-based models\nstore the desired patterns by designing the coupling weights between neurons.\nThe design of coupling weights should simultaneously take into account both the\nexistence and the dynamic stability of the EPs for the storage of the desired\npatterns. For OIMs, since all $0/\\pi$ binary EPs are structurally stable, the\ndesign of the coupling weights needs only to focus on assigning appropriate\nstability for the $0/\\pi$ binary EPs according to the desired patterns. In this\npaper, we establish a connection between the stability and the Hamiltonian\nenergy of EPs for OIMs, and, based on this connection, provide a\nHamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the\ncoupling weights of OIMs for assigning appropriate stability to their EPs.\nFinally, numerical experiments are performed to validate the effectiveness of\nthe proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM)\uff0c\u7528\u4e8e\u8bad\u7ec3\u632f\u8361\u5668\u4f0a\u8f9b\u673a (OIM) \u7684\u8026\u5408\u6743\u91cd\uff0c\u4ee5\u5b9e\u73b0 Hopfield \u7c7b\u4f3c\u7684\u8054\u60f3\u8bb0\u5fc6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u914d\u5e73\u8861\u70b9\u7684\u7a33\u5b9a\u6027\u6765\u5b58\u50a8\u6a21\u5f0f\uff0c\u7b80\u5316\u4e86\u4f20\u7edf Hopfield \u6a21\u578b\u7684\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u5728 Hopfield \u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\u5b9e\u73b0 Hopfield \u7c7b\u4f3c\u8054\u60f3\u8bb0\u5fc6\uff0c\u5e76\u89e3\u51b3\u4f20\u7edf Hopfield \u6a21\u578b\u5728\u8bbe\u8ba1\u8026\u5408\u6743\u91cd\u65f6\u9700\u8981\u540c\u65f6\u8003\u8651\u5e73\u8861\u70b9\u7684\u5b58\u5728\u548c\u52a8\u6001\u7a33\u5b9a\u6027\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) \u6765\u8bad\u7ec3 OIM \u7684\u8026\u5408\u6743\u91cd\uff0c\u4ee5\u5206\u914d\u9002\u5f53\u7684\u7a33\u5b9a\u6027\u7ed9\u5176\u5e73\u8861\u70b9\u3002", "result": "OIM \u5b9e\u73b0\u4e86 Hopfield \u7c7b\u4f3c\u7684\u8054\u60f3\u8bb0\u5fc6\uff0c\u5e76\u4e14\u5176\u8026\u5408\u6743\u91cd\u7684\u8bbe\u8ba1\u53ea\u9700\u8981\u5173\u6ce8\u4e3a\u5e73\u8861\u70b9\u5206\u914d\u9002\u5f53\u7684\u7a33\u5b9a\u6027\uff0c\u800c\u65e0\u9700\u8003\u8651\u5e73\u8861\u70b9\u7684\u5b58\u5728\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.14397", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.14397", "abs": "https://arxiv.org/abs/2507.14397", "authors": ["Michael Davies", "Neal Crago", "Karthikeyan Sankaralingam", "Christos Kozyrakis"], "title": "Efficient LLM Inference: Bandwidth, Compute, Synchronization, and Capacity are all you need", "comment": null, "summary": "This paper presents a limit study of transformer-based large language model\n(LLM) inference, focusing on the fundamental performance bottlenecks imposed by\nmemory bandwidth, memory capacity, and synchronization overhead in distributed\ninference systems. We develop a hardware-agnostic performance model that\nabstracts away implementation details, enabling the analysis of a wide range of\ncurrent and near-future hardware technologies. Our analysis spans from current\nHBM3 memory technology used in AI accelerators like GPUs and TPUs to systems\nbased on advanced HBM4 and advanced 3D-stacked DRAM technology. It also covers\nSRAM-based designs and scaling techniques from distributed clusters with\nvarying numbers of chips to wafer-scale integration. Our key findings for\nauto-regressive decoding are: i) serving LLMs requires 100s of GB per server to\nserve a model instance; ii) high memory bandwidth is critical for high per-user\nthroughput; iii) exposed synchronization latencies to achieve collective\ncommunication must be around 1us else they make the memory bandwidth\nineffective; iv) DRAM-based designs have a fundamental advantage in terms of\nsystem-level efficiency as measured in throughput per cost or watt; and v)\nhardware designs can easily reach 2000+ user token/sec but getting to 10,000+\ntokens/sec will need smaller models, smaller context, or other forms of\nalgorithmic advances. This study provides valuable insights into the\nfundamental performance limits of LLM inference, highlighting the potential\nbenefits of future hardware advancements and guiding the optimization of LLM\ndeployment strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9LLM\u63a8\u7406\u7684\u6027\u80fd\u74f6\u9888\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u53d1\u73b0DRAM\u5728\u80fd\u6548\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u5e76\u6307\u51fa\u4e86\u63d0\u9ad8\u541e\u5410\u91cf\u548c\u6269\u5c55\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u5173\u6ce8transformer-based LLM\u63a8\u7406\u7684\u57fa\u672c\u6027\u80fd\u74f6\u9888\uff0c\u8fd9\u4e9b\u74f6\u9888\u7531\u5206\u5e03\u5f0f\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u5185\u5b58\u5e26\u5bbd\u3001\u5185\u5b58\u5bb9\u91cf\u548c\u540c\u6b65\u5f00\u9500\u51b3\u5b9a\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u786c\u4ef6\u65e0\u5173\u7684\u6027\u80fd\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u6790transformer-based LLM\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u5e26\u5bbd\u3001\u5185\u5b58\u5bb9\u91cf\u548c\u540c\u6b65\u5f00\u9500\u7b49\u57fa\u672c\u6027\u80fd\u74f6\u9888\uff0c\u8be5\u6a21\u578b\u6db5\u76d6\u4e86\u4eceHBM3\u5230HBM4\u53ca3D\u5806\u53e0DRAM\u7b49\u591a\u79cd\u5185\u5b58\u6280\u672f\uff0c\u4ee5\u53caSRAM\u548c\u8de8\u8d8a\u4e0d\u540c\u89c4\u6a21\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u670d\u52a1LLM\u5b9e\u4f8b\u9700\u8981\u6bcf\u53f0\u670d\u52a1\u5668\u6570\u767eGB\u7684\u5185\u5b58\uff1b\u9ad8\u5185\u5b58\u5e26\u5bbd\u5bf9\u9ad8\u6bcf\u7528\u6237\u541e\u5410\u91cf\u81f3\u5173\u91cd\u8981\uff1b\u540c\u6b65\u5ef6\u8fdf\u9700\u8981\u63a5\u8fd11us\uff0c\u5426\u5219\u4f1a\u4f7f\u5185\u5b58\u5e26\u5bbd\u5931\u6548\uff1bDRAM\u8bbe\u8ba1\u5728\u7cfb\u7edf\u7ea7\u6548\u7387\uff08\u6309\u6bcf\u6210\u672c\u6216\u6bcf\u74e6\u7279\u541e\u5410\u91cf\u8861\u91cf\uff09\u65b9\u9762\u5177\u6709\u57fa\u672c\u4f18\u52bf\uff1b\u786c\u4ef6\u8bbe\u8ba1\u53ef\u4ee5\u8f7b\u677e\u8fbe\u5230\u6bcf\u79d22000\u591a\u4e2a\u7528\u6237\u4ee4\u724c\uff0c\u4f46\u8981\u8fbe\u5230\u6bcf\u79d210,000\u591a\u4e2a\u4ee4\u724c\uff0c\u5219\u9700\u8981\u66f4\u5c0f\u7684\u6a21\u578b\u3001\u66f4\u77ed\u7684\u4e0a\u4e0b\u6587\u6216\u5176\u4ed6\u7684\u7b97\u6cd5\u8fdb\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6027\u80fd\u6781\u9650\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u672a\u6765\u786c\u4ef6\u8fdb\u6b65\u7684\u6f5c\u5728\u597d\u5904\uff0c\u5e76\u6307\u5bfc\u4e86LLM\u90e8\u7f72\u7b56\u7565\u7684\u4f18\u5316\u3002"}}
{"id": "2507.14623", "categories": ["cs.SI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.14623", "abs": "https://arxiv.org/abs/2507.14623", "authors": ["Mingchen Li", "Wenbo Xu", "Wenqing Gu", "Yixuan Xie", "Yao Zhou", "Yunsong Dai", "Cheng Tan", "Pan Hui"], "title": "Rejection or Inclusion in the Emotion-Identity Dynamics of TikTok Refugees on RedNote", "comment": null, "summary": "This study examines cross-cultural interactions between Chinese users and\nself-identified \"TikTok Refugees\"(foreign users who migrated to RedNote after\nTikTok's U.S. ban). Based on a dataset of 1,862 posts and 403,054 comments, we\nuse large language model-based sentiment classification and BERT-based topic\nmodelling to explore how both groups engage with the TikTok refugee phenomenon.\nWe analyse what themes foreign users express, how Chinese users respond, how\nstances (Pro-China, Neutral, Pro-Foreign) shape emotional expression, and how\naffective responses differ across topics and identities. Results show strong\naffective asymmetry: Chinese users respond with varying emotional intensities\nacross topics and stances: pride and praise dominate cultural threads, while\npolitical discussions elicit high levels of contempt and anger, especially from\nPro-China commenters. Pro-Foreign users exhibit the strongest negative emotions\nacross all topics, whereas neutral users express curiosity and joy but still\nreinforce mainstream discursive norms. Cross-topic comparisons reveal that\nappearance-related content produces the most emotionally balanced interactions,\nwhile politics generates the highest polarization. Our findings reveal distinct\nemotion-stance structures in Sino-foreign online interactions and offer\nempirical insights into identity negotiation in transnational digital publics.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u4e2d\u56fd\u7528\u6237\u4e0e\u201cTikTok\u96be\u6c11\u201d\u5728\u4e2d\u56fd\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u4e92\u52a8\u3002\u4e2d\u56fd\u7528\u6237\u5728\u6587\u5316\u8bdd\u9898\u4e0a\u8868\u8fbe\u81ea\u8c6a\uff0c\u5728\u653f\u6cbb\u8bdd\u9898\u4e0a\u8868\u8fbe\u6124\u6012\u548c\u9119\u89c6\u3002\u4eb2\u5916\u7528\u6237\u666e\u904d\u8868\u8fbe\u8d1f\u9762\u60c5\u7eea\uff0c\u800c\u4e2d\u7acb\u7528\u6237\u5219\u8868\u8fbe\u597d\u5947\u548c\u559c\u60a6\u3002\u4e0e\u5916\u8c8c\u76f8\u5173\u7684\u5185\u5bb9\u4e92\u52a8\u6700\u4e3a\u5747\u8861\uff0c\u800c\u653f\u6cbb\u8bdd\u9898\u5219\u5bfc\u81f4\u4e86\u6700\u9ad8\u7a0b\u5ea6\u7684\u4e24\u6781\u5206\u5316\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728 examining cross-cultural interactions between Chinese users and self-identified \"TikTok Refugees\"(foreign users who migrated to RedNote after TikTok", "method": "\u672c\u7814\u7a76\u57fa\u4e8e1,862\u4e2a\u5e16\u5b50\u548c403,054\u6761\u8bc4\u8bba\u7684\u6570\u636e\u96c6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\uff0c\u5e76\u4f7f\u7528BERT\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u4ee5\u63a2\u7a76\u4e24\u7c7b\u7fa4\u4f53\u5982\u4f55\u53c2\u4e0eTikTok\u96be\u6c11\u73b0\u8c61\u3002\u7814\u7a76\u5206\u6790\u4e86\u5916\u56fd\u7528\u6237\u8868\u8fbe\u7684\u4e3b\u9898\u3001\u4e2d\u56fd\u7528\u6237\u7684\u56de\u5e94\u65b9\u5f0f\u3001\u4e0d\u540c\u7acb\u573a\uff08\u4eb2\u534e\u3001\u4e2d\u7acb\u3001\u4eb2\u5916\uff09\u5982\u4f55\u5f71\u54cd\u60c5\u611f\u8868\u8fbe\uff0c\u4ee5\u53ca\u8de8\u4e3b\u9898\u548c\u8eab\u4efd\u7684\u60c5\u611f\u53cd\u5e94\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u60c5\u611f\u4e0d\u5bf9\u79f0\u6027\u663e\u8457\uff1a\u4e2d\u56fd\u7528\u6237\u5bf9\u4e0d\u540c\u4e3b\u9898\u548c\u7acb\u573a\u7684\u53cd\u5e94\u60c5\u611f\u5f3a\u5ea6\u5404\u5f02\uff0c\u6587\u5316\u4e3b\u9898\u4e2d\u4ee5\u81ea\u8c6a\u548c\u8d5e\u626c\u4e3a\u4e3b\uff0c\u800c\u653f\u6cbb\u8ba8\u8bba\u5219\u5f15\u53d1\u9ad8\u5ea6\u7684\u9119\u89c6\u548c\u6124\u6012\uff0c\u5c24\u5176\u662f\u6765\u81ea\u4eb2\u534e\u8bc4\u8bba\u8005\u3002\u4eb2\u5916\u7528\u6237\u5728\u6240\u6709\u4e3b\u9898\u4e2d\u8868\u73b0\u51fa\u6700\u5f3a\u70c8\u8d1f\u9762\u60c5\u7eea\uff0c\u800c\u4e2d\u7acb\u7528\u6237\u5219\u8868\u8fbe\u597d\u5947\u548c\u559c\u60a6\uff0c\u4f46\u4ecd\u4f1a\u5f3a\u5316\u4e3b\u6d41\u8bdd\u8bed\u89c4\u8303\u3002\u8de8\u4e3b\u9898\u6bd4\u8f83\u8868\u660e\uff0c\u4e0e\u5916\u8c8c\u76f8\u5173\u7684\u5185\u5bb9\u4e92\u52a8\u6700\u4e3a\u5747\u8861\uff0c\u800c\u653f\u6cbb\u5219\u4ea7\u751f\u6700\u9ad8\u7a0b\u5ea6\u7684\u4e24\u6781\u5206\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u4e2d\u5916\u5728\u7ebf\u4e92\u52a8\u4e2d\u72ec\u7279\u7684\u201c\u60c5\u611f-\u7acb\u573a\u201d\u7ed3\u6784\uff0c\u5e76\u4e3a\u8de8\u56fd\u6570\u5b57\u516c\u4f17\u4e2d\u7684\u8eab\u4efd\u534f\u5546\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u89c1\u89e3\u3002"}}
{"id": "2507.14462", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.14462", "abs": "https://arxiv.org/abs/2507.14462", "authors": ["Xinpeng Jiang", "Haoyu Liu", "Siqiang Luo", "Xiaokui Xiao"], "title": "Tighter Lower Bounds for Single Source Personalized PageRank", "comment": "33 pages", "summary": "We study lower bounds for approximating the Single Source Personalized\nPageRank (SSPPR) query, which measures the probability distribution of an\n$\\alpha$-decay random walk starting from a source node $s$. Existing lower\nbounds remain loose-$\\Omega\\left(\\min(m, 1/\\delta)\\right)$ for relative error\n(SSPPR-R) and $\\Omega\\left(\\min(n, 1/\\epsilon)\\right)$ for additive error\n(SSPPR-A). To close this gap, we establish tighter bounds for both settings.\nFor SSPPR-R, we show a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\delta)}{\\delta}\\right)\\right)$ for any $\\delta \\in (0,1)$. For\nSSPPR-A, we prove a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\epsilon)}{\\epsilon}\\right)\\right)$ for any $\\epsilon \\in (0,1)$,\nassuming the graph has $m \\in \\mathcal{O}(n^{2-\\beta})$ edges for any\narbitrarily small constant $\\beta \\in (0,1)$.", "AI": {"tldr": "\u4e3aPageRank\u8fd1\u4f3c\u67e5\u8be2\u63d0\u4f9b\u66f4\u7d27\u786e\u7684\u4e0b\u754c\u3002", "motivation": "\u73b0\u6709SSPPR\u67e5\u8be2\u8fd1\u4f3c\u7684\u4e0b\u754c\uff08SSPPR-R\u4e3a$\\Omega(\\min(m, 1/\\delta))$\uff0cSSPPR-A\u4e3a$\\Omega(\\min(n, 1/\\epsilon))$\uff09\u4e0d\u591f\u7d27\u5bc6\uff0c\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u95ee\u9898\u96be\u5ea6\u3002\u672c\u7814\u7a76\u65e8\u5728\u7f29\u5c0f\u7406\u8bba\u4e0b\u754c\u4e0e\u5b9e\u9645\u7b97\u6cd5\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6784\u9020\u7279\u5b9a\u56fe\u7ed3\u6784\u6765\u63a8\u5bfcSSPPR-R\u548cSSPPR-A\u7684\u4e0b\u754c\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6587\u7ae0\u8bc1\u660e\u4e86SSPPR-R\u7684\u4e0b\u754c\u4e3a$\\Omega\\left(\\min\\left(m, \\frac{\\log(1/\\delta)}{\\delta}\\right)\\right)$\uff0cSSPPR-A\u7684\u4e0b\u754c\u4e3a$\\Omega\\left(\\min\\left(m, \\frac{\\log(1/\\epsilon)}{\\epsilon}\\right)\\right)$\uff08\u5f53$m \\in \\mathcal{O}(n^{2-\\beta})$\u65f6\uff09\u3002", "result": "\u6587\u7ae0\u6210\u529f\u5efa\u7acb\u4e86\u66f4\u7d27\u786e\u7684SSPPR-R\u548cSSPPR-A\u8fd1\u4f3c\u95ee\u9898\u7684\u4e0b\u754c\u3002\u5bf9\u4e8eSSPPR-R\uff0c\u4e0b\u754c\u88ab\u63d0\u5347\u81f3$\\Omega(\\min(m, \\frac{\\log(1/\\delta)}{\\delta}))$\uff1b\u5bf9\u4e8eSSPPR-A\uff0c\u5728\u7279\u5b9a\u56fe\u7ed3\u6784\u4e0b\uff08$m \\in \\mathcal{O}(n^{2-\\beta})$\uff09\uff0c\u4e0b\u754c\u88ab\u63d0\u5347\u81f3$\\Omega(\\min(m, \\frac{\\log(1/\\epsilon)}{\\epsilon}))$\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5355\u6e90\u4e2a\u6027\u5316PageRank\uff08SSPPR\uff09\u67e5\u8be2\u7684\u8fd1\u4f3c\u503c\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u7684\u4e0b\u754c\uff0c\u9488\u5bf9\u76f8\u5bf9\u8bef\u5dee\uff08SSPPR-R\uff09\u548c\u7edd\u5bf9\u8bef\u5dee\uff08SSPPR-A\uff09\u4e24\u79cd\u60c5\u51b5\uff0c\u5e76\u5bf9SSPPR-A\u7684\u4e0b\u754c\u5728\u8fb9\u6570\u8f83\u5c11\uff08$m = O(n^{2-\beta})$\uff09\u7684\u56fe\u4e0a\u8fdb\u884c\u4e86\u8bc1\u660e\u3002"}}
{"id": "2507.14923", "categories": ["physics.app-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.14923", "abs": "https://arxiv.org/abs/2507.14923", "authors": ["Mengyang Cui", "Chengduo Hu", "Qing Li", "Hongxing Qi"], "title": "Model of dark current in silicon-based barrier impurity band infrared detector devices", "comment": null, "summary": "Dark current in silicon-based blocked impurity band (BIB) infrared detectors\nhas long been a critical limitation on device performance. This work proposes a\nchiral-phonon-assisted spin current model at interfaces to explain the\nparabolic-like dark current behavior observed at low bias voltages.\nConcurrently, the spatially-confined charge transport theory is employed to\nelucidate the dark current generation mechanism across the entire operational\nvoltage range.", "AI": {"tldr": "A new model explains dark current in infrared detectors at low voltages, while another model covers the entire voltage range.", "motivation": "The motivation is to explain the parabolic-like dark current behavior observed at low bias voltages in silicon-based blocked impurity band (BIB) infrared detectors, which has been a critical limitation on device performance.", "method": "This paper proposes a chiral-phonon-assisted spin current model at interfaces and utilizes spatially-confined charge transport theory.", "result": "The study explains the dark current behavior in BIB infrared detectors using two theoretical models.", "conclusion": "The study proposes a novel model involving chiral-phonon-assisted spin current at interfaces to explain the parabolic-like dark current behavior at low bias voltages in silicon-based BIB infrared detectors. It also employs spatially-confined charge transport theory to clarify the dark current generation mechanism across the entire operational voltage range."}}
{"id": "2507.15146", "categories": ["cs.ET", "cs.AI", "cs.CV", "cs.CY", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15146", "abs": "https://arxiv.org/abs/2507.15146", "authors": ["Sebastian A. Cruz Romero", "Misael J. Mercado Hernandez", "Samir Y. Ali Rivera", "Jorge A. Santiago Fernandez", "Wilfredo E. Lugo Beauchamp"], "title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications", "comment": "Accepted at IEEE Global Humanitarian Technology Conference 2025", "summary": "The design of medical systems for remote, resource-limited environments faces\npersistent challenges due to poor interoperability, lack of offline support,\nand dependency on costly infrastructure. Many existing digital health solutions\nneglect these constraints, limiting their effectiveness for frontline health\nworkers in underserved regions. This paper presents a portable, edge-enabled\nElectronic Health Record platform optimized for offline-first operation, secure\npatient data management, and modular diagnostic integration. Running on\nsmall-form factor embedded devices, it provides AES-256 encrypted local storage\nwith optional cloud synchronization for interoperability. As a use case, we\nintegrated a non-invasive anemia screening module leveraging fingernail pallor\nanalysis. Trained on 250 patient cases (27\\% anemia prevalence) with\nKDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL\nand MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To\noptimize performance, a YOLOv8n-based nail bed detector was quantized to INT8,\nreducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5\nat 0.995. The system emphasizes low-cost deployment, modularity, and data\nprivacy compliance (HIPAA/GDPR), addressing critical barriers to digital health\nadoption in disconnected settings. Our work demonstrates a scalable approach to\nenhance portable health information systems and support frontline healthcare in\nunderserved regions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4fbf\u643a\u5f0f\u3001\u652f\u6301\u79bb\u7ebf\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\uff0c\u5e76\u96c6\u6210\u4e86\u4e00\u4e2a\u7528\u4e8e\u8d2b\u8840\u7b5b\u67e5\u7684 AI \u6a21\u5757\uff0c\u4ee5\u89e3\u51b3\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u8fdc\u7a0b\u3001\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u533b\u7597\u7cfb\u7edf\u5728\u4e92\u64cd\u4f5c\u6027\u5dee\u3001\u7f3a\u4e4f\u79bb\u7ebf\u652f\u6301\u548c\u4f9d\u8d56\u6602\u8d35\u57fa\u7840\u8bbe\u65bd\u65b9\u9762\u7684\u6311\u6218\uff0c\u73b0\u6709\u6570\u5b57\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u672a\u80fd\u6ee1\u8db3\u670d\u52a1\u6b20\u7f3a\u5730\u533a\u4e00\u7ebf\u533b\u62a4\u4eba\u5458\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4fbf\u643a\u5f0f\u3001\u8fb9\u7f18\u8ba1\u7b97\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u9488\u5bf9\u79bb\u7ebf\u4f18\u5148\u64cd\u4f5c\u3001\u5b89\u5168\u60a3\u8005\u6570\u636e\u7ba1\u7406\u548c\u6a21\u5757\u5316\u8bca\u65ad\u96c6\u6210\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u5728\u5c0f\u578b\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u63d0\u4f9b AES-256 \u52a0\u5bc6\u672c\u5730\u5b58\u50a8\u548c\u53ef\u9009\u7684\u4e91\u540c\u6b65\u3002\u96c6\u6210\u4e86\u5229\u7528\u6307\u7532\u82cd\u767d\u5206\u6790\u7684\u65e0\u521b\u8d2b\u8840\u7b5b\u67e5\u6a21\u5757\uff0c\u5e76\u4f7f\u7528\u91cf\u5316 YOLOv8n \u6a21\u578b\u4f18\u5316\u6027\u80fd\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u8d2b\u8840\u7b5b\u67e5\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86 1.969 g/dL \u7684\u6d4b\u8bd5 RMSE \u548c 1.490 g/dL \u7684 MAE\uff0c\u4e25\u91cd\u6027\u6a21\u578b\u8fbe\u5230\u4e86 79.2% \u7684\u7075\u654f\u5ea6\u3002YOLOv8n \u6a21\u578b\u91cf\u5316\u5230 INT8 \u540e\uff0c\u63a8\u7406\u5ef6\u8fdf\u4ece 46.96 ms \u964d\u4f4e\u5230 21.50 ms\uff0c\u540c\u65f6\u4fdd\u6301\u4e86 0.995 \u7684 mAP@0.5\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u4f4e\u6210\u672c\u3001\u6a21\u5757\u5316\u548c\u6570\u636e\u9690\u79c1\u5408\u89c4\u6027\uff08HIPAA/GDPR\uff09\u7684\u7efc\u5408\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5728\u65ad\u5f00\u8fde\u63a5\u7684\u73af\u5883\u4e2d\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u7684\u969c\u788d\uff0c\u4e3a\u670d\u52a1\u6b20\u7f3a\u5730\u533a\u7684\u4e00\u7ebf\u533b\u7597\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u652f\u6301\u3002"}}
{"id": "2507.14193", "categories": ["cs.GT", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14193", "abs": "https://arxiv.org/abs/2507.14193", "authors": ["Tori Qiu", "Benjamin Laufer", "Jon Kleinberg", "Hoda Heidari"], "title": "A Formal Model of the Economic Impacts of AI Openness Regulation", "comment": null, "summary": "Regulatory frameworks, such as the EU AI Act, encourage openness of\ngeneral-purpose AI models by offering legal exemptions for \"open-source\"\nmodels. Despite this legislative attention on openness, the definition of\nopen-source foundation models remains ambiguous. This paper models the\nstrategic interactions among the creator of a general-purpose model (the\ngeneralist) and the entity that fine-tunes the general-purpose model to a\nspecialized domain or task (the specialist), in response to regulatory\nrequirements on model openness. We present a stylized model of the regulator's\nchoice of an open-source definition to evaluate which AI openness standards\nwill establish appropriate economic incentives for developers. Our results\ncharacterize market equilibria -- specifically, upstream model release\ndecisions and downstream fine-tuning efforts -- under various openness\nregulations and present a range of effective regulatory penalties and\nopen-source thresholds. Overall, we find the model's baseline performance\ndetermines when increasing the regulatory penalty vs. the open-source threshold\nwill significantly alter the generalist's release strategy. Our model provides\na theoretical foundation for AI governance decisions around openness and\nenables evaluation and refinement of practical open-source policies.", "AI": {"tldr": "\u76d1\u7ba1\u6846\u67b6\u9f13\u52b1AI\u6a21\u578b\u7684\u5f00\u653e\u6027\uff0c\u4f46\u201c\u5f00\u6e90\u201d\u5b9a\u4e49\u6a21\u7cca\u3002\u672c\u6587\u901a\u8fc7\u5bf9\u901a\u7528\u6a21\u578b\u5f00\u53d1\u8005\u548c\u5fae\u8c03\u8005\u4e4b\u95f4\u4e92\u52a8\u7684\u5efa\u6a21\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u5f00\u653e\u6027\u6cd5\u89c4\u5bf9\u5f00\u53d1\u8005\u7ecf\u6d4e\u6fc0\u52b1\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u76d1\u7ba1\u5904\u7f5a\u548c\u5f00\u6e90\u9608\u503c\u7684\u5efa\u8bae\u3002", "motivation": "\u5728AI\u76d1\u7ba1\u6846\u67b6\uff08\u5982\u6b27\u76dfAI\u6cd5\u6848\uff09\u9f13\u52b1\u901a\u7528\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5f00\u653e\u6027\uff0c\u5e76\u4e3a\u201c\u5f00\u6e90\u201d\u6a21\u578b\u63d0\u4f9b\u6cd5\u5f8b\u8c41\u514d\u7684\u540c\u65f6\uff0c\u8be5\u9886\u57df\u5185\u5173\u4e8e\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u7684\u5b9a\u4e49\u4ecd\u7136\u6a21\u7cca\u4e0d\u6e05\u3002", "method": "\u901a\u8fc7\u5bf9\u76d1\u7ba1\u8005\u9009\u62e9\u5f00\u6e90\u5b9a\u4e49\u8fdb\u884c\u5efa\u6a21\uff0c\u6765\u8bc4\u4f30\u54ea\u4e9bAI\u5f00\u653e\u6027\u6807\u51c6\u80fd\u591f\u4e3a\u5f00\u53d1\u8005\u5efa\u7acb\u5408\u7406\u7684\u7ecf\u6d4e\u6fc0\u52b1\u3002\u6211\u4eec\u63a8\u5bfc\u4e86\u5728\u4e0d\u540c\u5f00\u653e\u6027\u6cd5\u89c4\u4e0b\uff0c\u4e0a\u6e38\u6a21\u578b\u53d1\u5e03\u51b3\u7b56\u548c\u4e0b\u6e38\u5fae\u8c03\u7684\u52aa\u529b\u7a0b\u5ea6\u7684\u5e02\u573a\u5747\u8861\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u6709\u6548\u7684\u76d1\u7ba1\u5904\u7f5a\u548c\u5f00\u6e90\u9608\u503c\u3002", "result": "\u6211\u4eec\u53d1\u73b0\uff0c\u6a21\u578b\u7684\u57fa\u7ebf\u6027\u80fd\u51b3\u5b9a\u4e86\u589e\u52a0\u76d1\u7ba1\u5904\u7f5a\u6216\u5f00\u6e90\u9608\u503c\u4f1a\u5728\u4f55\u79cd\u7a0b\u5ea6\u4e0a\u663e\u8457\u6539\u53d8\u901a\u7528\u6a21\u578b\u5f00\u53d1\u8005\u7684\u53d1\u5e03\u7b56\u7565\u3002\u6a21\u578b\u523b\u753b\u4e86\u5e02\u573a\u5747\u8861\u2014\u2014\u7279\u522b\u662f\u4e0a\u6e38\u6a21\u578b\u53d1\u5e03\u51b3\u7b56\u548c\u4e0b\u6e38\u5fae\u8c03\u7684\u52aa\u529b\u2014\u2014\u5728\u5404\u79cd\u5f00\u653e\u6027\u6cd5\u89c4\u4e0b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u6709\u6548\u7684\u76d1\u7ba1\u5904\u7f5a\u548c\u5f00\u6e90\u9608\u503c\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3aAI\u6cbb\u7406\u5728\u5f00\u653e\u6027\u65b9\u9762\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u80fd\u5bf9\u5b9e\u9645\u7684\u5f00\u6e90\u653f\u7b56\u8fdb\u884c\u8bc4\u4f30\u548c\u5b8c\u5584\u3002"}}
{"id": "2507.15147", "categories": ["cs.LO", "cs.FL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15147", "abs": "https://arxiv.org/abs/2507.15147", "authors": ["Yiqi Zhao", "Xinyi Yu", "Bardh Hoxha", "Georgios Fainekos", "Jyotirmoy V. Deshmukh", "Lars Lindemann"], "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies", "comment": null, "summary": "Multi-agent systems (MASs) consisting of a number of autonomous agents that\ncommunicate, coordinate, and jointly sense the environment to achieve complex\nmissions can be found in a variety of applications such as robotics, smart\ncities, and internet-of-things applications. Modeling and monitoring MAS\nrequirements to guarantee overall mission objectives, safety, and reliability\nis an important problem. Such requirements implicitly require reasoning about\ndiverse sensing and communication modalities between agents, analysis of the\ndependencies between agent tasks, and the spatial or virtual distance between\nagents. To capture such rich MAS requirements, we model agent interactions via\nmultiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic\nwith Graph Operators (STL-GO). The key innovation in STL-GO are graph operators\nthat enable us to reason about the number of agents along either the incoming\nor outgoing edges of the underlying interaction graph that satisfy a given\nproperty of interest; for example, the requirement that an agent should sense\nat least two neighboring agents whose task graphs indicate the ability to\ncollaborate. We then propose novel distributed monitoring conditions for\nindividual agents that use only local information to determine whether or not\nan STL-GO specification is satisfied. We compare the expressivity of STL-GO\nagainst existing spatio-temporal logic formalisms, and demonstrate the utility\nof STL-GO and our distributed monitors in a bike-sharing and a multi-drone case\nstudy.", "AI": {"tldr": "A new logic (STL-GO) and distributed monitoring methods are proposed for multi-agent systems, allowing reasoning about agent interactions and properties using graph operators and local information, with successful application in case studies.", "motivation": "Modeling and monitoring multi-agent system requirements is crucial for guaranteeing mission objectives, safety, and reliability, especially considering diverse sensing and communication modalities, task dependencies, and spatial/virtual distances between agents.", "method": "The paper models agent interactions using multiple directed graphs and introduces Spatio-Temporal Logic with Graph Operators (STL-GO), which includes graph operators to reason about agent properties based on their interactions. Novel distributed monitoring conditions for individual agents are also proposed.", "result": "STL-GO enables reasoning about agent interactions and properties through graph operators. Distributed monitors using local information can determine if STL-GO specifications are met. The expressivity of STL-GO is compared to existing formalisms, and its utility is shown in bike-sharing and multi-drone case studies.", "conclusion": "The paper introduces STL-GO, a novel logic for modeling and monitoring multi-agent system requirements, and demonstrates its utility in case studies."}}
{"id": "2507.14723", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.14723", "abs": "https://arxiv.org/abs/2507.14723", "authors": ["Brati Mondal", "Pritam Goswami", "Buddhadeb Sau"], "title": "Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring", "comment": null, "summary": "We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile\nagents in a 1-interval-connected ring network having $n$ nodes and with $l$\nagents where $3 \\le l \\le \\lfloor \\frac{n}{k}\\rfloor$, without the assumption\nof chirality (a common sense of direction for the agents). This generalizes the\nclassical dispersion problem by requiring that agents maintain a minimum\ndistance of $k$ hops from each other, with the special case $k=1$ corresponding\nto the standard dispersion.\n  The contribution in this work is threefold. Our first contribution is a novel\nmethod that enables agents to simulate chirality using only local information,\nvision and bounded memory. This technique demonstrates that chirality is not a\nfundamental requirement for coordination in this model.\n  Building on this, our second contribution partially resolves an open question\nposed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1-\ninterval connected ring, synchronous agents, no chirality). We prove that\nD-$k$-D, and thus dispersion is solvable from any arbitrary configuration under\nthese assumptions (excluding vertex permutation dynamism)for any size of the\nring network which was earlier limited to only odd sized ring or to a ring of\nsize four.\n  Finally, we present an algorithm for D-$k$-D in this setting that works in\n$O(ln)$ rounds, completing the constructive side of our result.\n  Altogether, our findings significantly extend the theoretical understanding\nof mobile agent coordination in dynamic networks and clarify the role of\nchirality in distributed computation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u65e0\u5b9a\u6027\u5047\u8bbe\u4e0b\u540c\u6b65\u79fb\u52a8\u667a\u80fd\u4f53\u5728\u73af\u5f62\u7f51\u7edc\u4e2d\u7684\u8ddd\u79bb-k-\u5206\u6563\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6a21\u62df\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u95ee\u9898\u7684\u53ef\u89e3\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2aO(ln)\u8f6e\u7684\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u540c\u6b65\u79fb\u52a8\u667a\u80fd\u4f53\u57281-\u95f4\u9694\u8fde\u901a\u7684\u73af\u5f62\u7f51\u7edc\u4e2d\u7684\u8ddd\u79bb-k-\u5206\u6563\uff08D-k-D\uff09\u95ee\u9898\uff0c\u7279\u522b\u662f\u65e0\u5b9a\u6027\uff08\u65e0\u5171\u540c\u65b9\u5411\u611f\uff09\u7684\u5047\u8bbe\uff0c\u5e76\u8bd5\u56fe\u89e3\u51b3Agarwalla\u7b49\u4eba\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u4ec5\u4f7f\u7528\u5c40\u90e8\u4fe1\u606f\u3001\u89c6\u89c9\u548c\u6709\u9650\u5185\u5b58\u6765\u6a21\u62df\u5b9a\u6027\uff0c\u8bc1\u660e\u4e86\u5b9a\u6027\u5e76\u975e\u667a\u80fd\u4f53\u534f\u8c03\u7684\u6839\u672c\u8981\u6c42\u3002", "result": "\u8bc1\u660e\u4e86D-k-D\u95ee\u9898\uff08\u4ee5\u53ca\u5206\u6563\u95ee\u9898\uff09\u5728\u7ed9\u5b9a\u6a21\u578b\u4e0b\uff08\u6392\u9664\u9876\u70b9\u7f6e\u6362\u52a8\u6001\u6027\uff09\u5bf9\u4e8e\u4efb\u4f55\u5927\u5c0f\u7684\u73af\u5f62\u7f51\u7edc\u90fd\u662f\u53ef\u89e3\u7684\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u5728O(ln)\u8f6e\u5185\u89e3\u51b3D-k-D\u95ee\u9898\u7684\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u65e0\u5b9a\u6027\u5047\u8bbe\u4e0b\uff0c\u8ddd\u79bb-k-\u5206\u6563\uff08D-k-D\uff09\u95ee\u9898\uff08\u5305\u62ec\u7ecf\u5178\u7684\u5206\u6563\u95ee\u9898\uff09\u662f\u53ef\u89e3\u7684\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u5728O(ln)\u8f6e\u5185\u89e3\u51b3D-k-D\u95ee\u9898\u7684\u7b97\u6cd5\u3002"}}
{"id": "2507.14412", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14412", "abs": "https://arxiv.org/abs/2507.14412", "authors": ["Mengxue Fu", "Zhonghao Shi", "Minyu Huang", "Siqi Liu", "Mina Kian", "Yirui Song", "Maja J. Matari\u0107"], "title": "Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support", "comment": null, "summary": "Socially assistive robots (SARs) have shown great potential for supplementing\nwell-being support. However, prior studies have found that existing dialogue\npipelines for SARs remain limited in real-time latency, back-channeling, and\npersonalized speech dialogue. Toward addressing these limitations, we propose\nusing integrated end-to-end speech-language models (SLMs) with SARs. This work\n1) evaluated the usability of an SLM-enabled SAR dialogue system through a\nsmall user study, and 2) identified remaining limitations through study user\nfeedback to inform future improvements. We conducted a small within-participant\nuser study with university students (N = 11) whose results showed that\nparticipants perceived an SLM-enabled SAR system as capable of providing\nempathetic feedback, natural turn-taking, back-channeling, and adaptive\nresponses. We also found that participants reported the robot's nonverbal\nbehaviors as lacking variability and synchronization with conversation, and the\nSLM's verbal feedback as generic and repetitive. These findings highlighted the\nneed for real-time robot movement synchronized with conversation, improved\nprompting or fine-tuning to generate outputs better aligned with mental health\npractices, and more expressive, adaptive vocal generation.", "AI": {"tldr": "Socially assistive robots with integrated speech-language models show promise for better dialogue, offering empathy and natural interaction. However, robot movements need better synchronization, and the AI's responses should be less generic and more aligned with mental health practices for improved user experience.", "motivation": "Prior studies found limitations in existing dialogue pipelines for Socially Assistive Robots (SARs) concerning real-time latency, back-channeling, and personalized speech dialogue. This work aims to address these limitations by proposing the use of integrated end-to-end speech-language models (SLMs) with SARs.", "method": "The study evaluated an SLM-enabled SAR dialogue system through a small within-participant user study with university students (N = 11). The evaluation focused on usability and identified limitations through user feedback.", "result": "Participants perceived the SLM-enabled SAR system as capable of empathetic feedback, natural turn-taking, back-channeling, and adaptive responses. Key limitations identified were the lack of variability and synchronization in the robot's nonverbal behaviors, and generic and repetitive verbal feedback from the SLM.", "conclusion": "The study demonstrated that an SLM-enabled SAR system is perceived by users as capable of providing empathetic feedback, natural turn-taking, back-channeling, and adaptive responses. However, limitations were identified in the robot's nonverbal behaviors (lack of variability and synchronization) and the SLM's verbal feedback (generic and repetitive). Future improvements should focus on synchronizing robot movements with conversation, enhancing prompting or fine-tuning for mental health alignment, and developing more expressive and adaptive vocal generation."}}
{"id": "2507.14312", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14312", "abs": "https://arxiv.org/abs/2507.14312", "authors": ["Marc Lafon", "Gustavo Adolfo Vargas Hakim", "Cl\u00e9ment Rambour", "Christian Desrosier", "Nicolas Thome"], "title": "CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation", "comment": null, "summary": "Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities\nbut often fail to generalize under distribution shifts. Test-time adaptation\n(TTA) allows models to update at inference time without labeled data, typically\nvia entropy minimization. However, this objective is fundamentally misaligned\nwith the contrastive image-text training of VLMs, limiting adaptation\nperformance and introducing failure modes such as pseudo-label drift and class\ncollapse. We propose CLIPTTA, a new gradient-based TTA method for\nvision-language models that leverages a soft contrastive loss aligned with\nCLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's\ngradients, showing how its batch-aware design mitigates the risk of collapse.\nWe further extend CLIPTTA to the open-set setting, where both in-distribution\n(ID) and out-of-distribution (OOD) samples are encountered, using an Outlier\nContrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75\ndatasets spanning diverse distribution shifts, CLIPTTA consistently outperforms\nentropy-based objectives and is highly competitive with state-of-the-art TTA\nmethods, outperforming them on a large number of datasets and exhibiting more\nstable performance across diverse shifts.", "AI": {"tldr": "CLIPTTA\u662f\u4e00\u79cd\u7528\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u8f6f\u5bf9\u6bd4\u635f\u5931\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5404\u79cd\u5206\u5e03\u53d8\u5316\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u4e14\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff08\u5982\u71b5\u6700\u5c0f\u5316\uff09\u4e0e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u5e76\u51fa\u73b0\u4f2a\u6807\u7b7e\u6f02\u79fb\u548c\u7c7b\u522b\u574d\u584c\u7b49\u95ee\u9898\u3002", "method": "CLIPTTA\u662f\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u5229\u7528\u8f6f\u5bf9\u6bd4\u635f\u5931\u6765\u9002\u5e94\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u3002\u5b83\u901a\u8fc7\u6279\u6b21\u611f\u77e5\u8bbe\u8ba1\u6765\u7f13\u89e3\u574d\u584c\u98ce\u9669\uff0c\u5e76\u901a\u8fc7\u6d77\u6d0b\u635f\u5931\u6269\u5c55\u5230\u5f00\u653e\u96c6\u8bbe\u7f6e\uff0c\u4ee5\u6539\u8fdbOOD\u68c0\u6d4b\u3002", "result": "CLIPTTA\u5728\u5404\u79cd\u5206\u5e03\u53d8\u5316\u4e0b\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u8bb8\u591a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "conclusion": "CLIPTTA\u572875\u4e2a\u8de8\u5206\u5e03\u53d8\u5316\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5176\u6027\u80fd\u6301\u7eed\u4f18\u4e8e\u57fa\u4e8e\u71b5\u7684\u76ee\u6807\uff0c\u5e76\u4e14\u4e0e\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u9ad8\u5ea6\u7ade\u4e89\u529b\uff0c\u5728\u5927\u91cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u5728\u8de8\u591a\u6837\u5316\u5206\u5e03\u53d8\u5316\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14293", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14293", "abs": "https://arxiv.org/abs/2507.14293", "authors": ["Boyuan Zheng", "Zeyi Liao", "Scott Salisbury", "Zeyuan Liu", "Michael Lin", "Qinyuan Zheng", "Zifan Wang", "Xiang Deng", "Dawn Song", "Huan Sun", "Yu Su"], "title": "WebGuard: Building a Generalizable Guardrail for Web Agents", "comment": "We publicly release WebGuard, along with its annotation tools and\n  fine-tuned models, to facilitate open-source research on monitoring and\n  safeguarding web agents. All resources are available at\n  https://github.com/OSU-NLP-Group/WebGuard", "summary": "The rapid development of autonomous web agents powered by Large Language\nModels (LLMs), while greatly elevating efficiency, exposes the frontier risk of\ntaking unintended or harmful actions. This situation underscores an urgent need\nfor effective safety measures, akin to access controls for human users. To\naddress this critical challenge, we introduce WebGuard, the first comprehensive\ndataset designed to support the assessment of web agent action risks and\nfacilitate the development of guardrails for real-world online environments. In\ndoing so, WebGuard specifically focuses on predicting the outcome of\nstate-changing actions and contains 4,939 human-annotated actions from 193\nwebsites across 22 diverse domains, including often-overlooked long-tail\nwebsites. These actions are categorized using a novel three-tier risk schema:\nSAFE, LOW, and HIGH. The dataset includes designated training and test splits\nto support evaluation under diverse generalization settings. Our initial\nevaluations reveal a concerning deficiency: even frontier LLMs achieve less\nthan 60% accuracy in predicting action outcomes and less than 60% recall in\nlagging HIGH-risk actions, highlighting the risks of deploying\ncurrent-generation agents without dedicated safeguards. We therefore\ninvestigate fine-tuning specialized guardrail models using WebGuard. We conduct\ncomprehensive evaluations across multiple generalization settings and find that\na fine-tuned Qwen2.5VL-7B model yields a substantial improvement in\nperformance, boosting accuracy from 37% to 80% and HIGH-risk action recall from\n20% to 76%. Despite these improvements, the performance still falls short of\nthe reliability required for high-stakes deployment, where guardrails must\napproach near-perfect accuracy and recall.", "AI": {"tldr": "LLM \u9a71\u52a8\u7684 Web Agent \u5e26\u6765\u4e86\u610f\u5916\u884c\u4e3a\u7684\u98ce\u9669\uff0c\u9700\u8981\u5b89\u5168\u63aa\u65bd\u3002WebGuard \u6570\u636e\u96c6\u901a\u8fc7\u5bf9 4,939 \u4e2a\u7f51\u7ad9\u64cd\u4f5c\u8fdb\u884c\u98ce\u9669\u5206\u7c7b\uff0c\u4e3a\u8bc4\u4f30\u548c\u5f00\u53d1\u62a4\u680f\u63d0\u4f9b\u4e86\u652f\u6301\u3002\u5c3d\u7ba1\u5bf9 LLM \u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u51fa\u98ce\u9669\uff0c\u4f46\u4f7f\u7528 WebGuard \u5bf9 Qwen2.5VL-7B \u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u90e8\u7f72\u7684\u8981\u6c42\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b Web Agent \u7684\u5feb\u901f\u53d1\u5c55\uff0cLLM \u5728\u63d0\u9ad8\u6548\u7387\u7684\u540c\u65f6\uff0c\u4e5f\u5e26\u6765\u4e86\u610f\u5916\u6216\u6709\u5bb3\u884c\u4e3a\u7684\u98ce\u9669\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u7c7b\u4f3c\u4e8e\u5bf9\u4eba\u7c7b\u7528\u6237\u7684\u8bbf\u95ee\u63a7\u5236\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u6570\u636e\u96c6\u6765\u8bc4\u4f30 Web Agent \u64cd\u4f5c\u98ce\u9669\uff0c\u5e76\u4fc3\u8fdb\u5728\u7ebf\u73af\u5883\u7684\u62a4\u680f\u5f00\u53d1\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3a WebGuard \u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b 4,939 \u4e2a\u6765\u81ea 193 \u4e2a\u7f51\u7ad9\u7684\u6ce8\u91ca\u64cd\u4f5c\uff0c\u8de8\u8d8a 22 \u4e2a\u4e0d\u540c\u7684\u57df\u3002\u8fd9\u4e9b\u64cd\u4f5c\u6839\u636e SAFE\u3001LOW \u548c HIGH \u7684\u4e09\u7ea7\u98ce\u9669\u6a21\u5f0f\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5305\u542b\u7528\u4e8e\u8bc4\u4f30\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u62c6\u5206\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u5fae\u8c03\u4e86\u4e00\u4e2a Qwen2.5VL-7B \u6a21\u578b\uff0c\u4ee5\u8bc4\u4f30\u62a4\u680f\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u5728\u5bf9 22 \u4e2a\u9886\u57df\u7684 193 \u4e2a\u7f51\u7ad9\u8fdb\u884c\u8bc4\u4f30\u540e\uff0cWebGuard \u6570\u636e\u96c6\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684 LLM\uff0c\u5728\u9884\u6d4b\u64cd\u4f5c\u7ed3\u679c\u65b9\u9762\u7684\u51c6\u786e\u6027\u4e5f\u4f4e\u4e8e 60%\uff0c\u5728\u6ede\u540e\u9ad8\u98ce\u9669\u64cd\u4f5c\u65b9\u9762\u7684\u53ec\u56de\u7387\u4e5f\u4f4e\u4e8e 60%\u3002\u901a\u8fc7\u4f7f\u7528 WebGuard \u5bf9 Qwen2.5VL-7B \u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u51c6\u786e\u6027\u4ece 37% \u63d0\u9ad8\u5230 80%\uff0c\u9ad8\u98ce\u9669\u64cd\u4f5c\u53ec\u56de\u7387\u4ece 20% \u63d0\u9ad8\u5230 76%\u3002", "conclusion": "\u5c3d\u7ba1\u7ecf\u8fc7\u5fae\u8c03\uff0c\u4f46\u7528\u4e8e\u9ad8\u98ce\u9669\u90e8\u7f72\u7684 WebGuard \u4ecd\u9700\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ec\u56de\u7387\u3002LLM \u5728\u9884\u6d4b\u7f51\u7ad9\u64cd\u4f5c\u7ed3\u679c\u65b9\u9762\u7684\u51c6\u786e\u6027\u4f4e\u4e8e 60%\uff0c\u5e76\u4e14\u5728\u6ede\u540e\u9ad8\u98ce\u9669\u64cd\u4f5c\u65b9\u9762\u7684\u53ec\u56de\u7387\u4f4e\u4e8e 60%\uff0c\u8fd9\u51f8\u663e\u4e86\u5728\u6ca1\u6709\u4e13\u95e8\u4fdd\u62a4\u63aa\u65bd\u7684\u60c5\u51b5\u4e0b\u90e8\u7f72\u5f53\u524d\u4e00\u4ee3\u4ee3\u7406\u7684\u98ce\u9669\u3002\u7136\u800c\uff0c\u4f7f\u7528 WebGuard \u5bf9\u4e13\u7528\u62a4\u680f\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u5c06\u51c6\u786e\u6027\u4ece 37% \u63d0\u9ad8\u5230 80%\uff0c\u5e76\u5c06\u9ad8\u98ce\u9669\u64cd\u4f5c\u53ec\u56de\u7387\u4ece 20% \u63d0\u9ad8\u5230 76%\u3002"}}
{"id": "2507.14364", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14364", "abs": "https://arxiv.org/abs/2507.14364", "authors": ["Natalya A Zimbovskaya"], "title": "Chiral-induced circularly polarized light emission from a single-molecule junction", "comment": "6 pages, 4 figures", "summary": "In the present work we theoretically analyze electroluminescence occurring in\na biased single-molecule junction with a chiral bridge imitated by a helical\nchain. We show that optical transitions between electron states of the chiral\nlinker may result in the emission of circular polarized light whose handedness\ndepends on both direction of propagation and the polarity of the bias voltage\nprovided that the coupling between the bridge sites is sufficiently strong. The\nmechanism controlling this specific light emission does not depend on the\nmagnetic moments and spin-orbit interactions. It rather relies on the chiral\nproperties of the bridge molecule and on the distribution of the bias voltage\nbetween the electrodes in the junction.", "AI": {"tldr": "Chiral molecule junctions can emit circularly polarized light, dependent on bias and propagation direction, due to molecular properties, not magnetic interactions.", "motivation": "Analyze electroluminescence in a biased single-molecule junction with a chiral bridge.", "method": "Theoretical analysis of electroluminescence in a biased single-molecule junction with a chiral bridge imitated by a helical chain.", "result": "Demonstrated that circular polarized light emission can occur, with handedness dependent on propagation direction and bias voltage polarity, provided strong coupling between bridge sites.", "conclusion": "If the coupling between the bridge sites is sufficiently strong, optical transitions between electron states of the chiral linker can result in the emission of circular polarized light whose handedness depends on both direction of propagation and the polarity of the bias voltage. This mechanism is controlled by the chiral properties of the bridge molecule and the bias voltage distribution, not by magnetic moments or spin-orbit interactions."}}
{"id": "2507.15015", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15015", "abs": "https://arxiv.org/abs/2507.15015", "authors": ["Xinmeng Hou", "Zhouquan Lu", "Wenli Chen", "Hai Hu", "Qing Guo"], "title": "EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems", "comment": null, "summary": "Large language models (LLMs) have demonstrated significant potential as\neducational tutoring agents, capable of tailoring hints, orchestrating lessons,\nand grading with near-human finesse across various academic domains. However,\ncurrent LLM-based educational systems exhibit critical limitations in promoting\ngenuine critical thinking, failing on over one-third of multi-hop questions\nwith counterfactual premises, and remaining vulnerable to adversarial prompts\nthat trigger biased or factually incorrect responses. To address these gaps, we\npropose EDU-Prompting, a novel multi-agent framework that bridges established\neducational critical thinking theories with LLM agent design to generate\ncritical, bias-aware explanations while fostering diverse perspectives. Our\nsystematic evaluation across theoretical benchmarks and practical college-level\ncritical writing scenarios demonstrates that EDU-Prompting significantly\nenhances both content truthfulness and logical soundness in AI-generated\neducational responses. The framework's modular design enables seamless\nintegration into existing prompting frameworks and educational applications,\nallowing practitioners to directly incorporate critical thinking catalysts that\npromote analytical reasoning and introduce multiple perspectives without\nrequiring extensive system modifications.", "AI": {"tldr": "EDU-Prompting\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6559\u80b2\u7406\u8bba\u548cLLM\u8bbe\u8ba1\uff0c\u63d0\u9ad8\u4e86AI\u6559\u80b2\u5de5\u5177\u751f\u6210\u5185\u5bb9\u7684\u771f\u5b9e\u6027\u548c\u903b\u8f91\u6027\uff0c\u540c\u65f6\u4fc3\u8fdb\u4e86\u6279\u5224\u6027\u601d\u7ef4\u548c\u591a\u89c6\u89d2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u6559\u80b2\u5de5\u5177\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u548c\u5bf9\u6297\u6027\u63d0\u793a\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524dLLM\u6559\u80b2\u5de5\u5177\u5728\u57f9\u517b\u6279\u5224\u6027\u601d\u7ef4\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5b83\u4eec\u5728\u5904\u7406\u5177\u6709\u53cd\u4e8b\u5b9e\u524d\u63d0\u7684\u591a\u6b65\u63a8\u7406\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5bb9\u6613\u53d7\u5230\u89e6\u53d1\u504f\u89c1\u6216\u4e8b\u5b9e\u9519\u8bef\u56de\u5e94\u7684\u5bf9\u6297\u6027\u63d0\u793a\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEDU-Prompting\u7684\u65b0\u578b\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u6210\u719f\u7684\u6559\u80b2\u6279\u5224\u6027\u601d\u7ef4\u7406\u8bba\u548cLLM\u667a\u80fd\u4f53\u8bbe\u8ba1\uff0c\u7528\u4e8e\u751f\u6210\u6279\u5224\u6027\u3001\u8ba4\u77e5\u504f\u89c1\u610f\u8bc6\u7684\u89e3\u91ca\uff0c\u5e76\u4fc3\u8fdb\u89c2\u70b9\u7684\u591a\u6837\u6027\u3002", "result": "\u5728\u7406\u8bba\u57fa\u51c6\u548c\u5b9e\u9645\u5927\u5b66\u6c34\u5e73\u7684\u6279\u5224\u6027\u5199\u4f5c\u573a\u666f\u4e2d\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u8868\u660e\uff0cEDU-Prompting\u663e\u8457\u63d0\u9ad8\u4e86AI\u751f\u6210\u6559\u80b2\u56de\u5e94\u7684\u5185\u5bb9\u771f\u5b9e\u6027\u548c\u903b\u8f91\u5408\u7406\u6027\u3002", "conclusion": "EDU-Prompting\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347AI\u751f\u6210\u6559\u80b2\u56de\u5e94\u7684\u5185\u5bb9\u771f\u5b9e\u6027\u548c\u903b\u8f91\u4e25\u8c28\u6027\uff0c\u5e76\u4e14\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u7cfb\u7edf\u4e2d\uff0c\u80fd\u591f\u4fc3\u8fdb\u5206\u6790\u6027\u63a8\u7406\u548c\u591a\u89c6\u89d2\u5f15\u5165\u3002"}}
{"id": "2507.14172", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.14172", "abs": "https://arxiv.org/abs/2507.14172", "authors": ["Julien Pourcel", "C\u00e9dric Colas", "Pierre-Yves Oudeyer"], "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI", "comment": null, "summary": "Many program synthesis tasks prove too challenging for even state-of-the-art\nlanguage models to solve in single attempts. Search-based evolutionary methods\noffer a promising alternative by exploring solution spaces iteratively, but\ntheir effectiveness remain limited by the fixed capabilities of the underlying\ngenerative model.\n  We propose SOAR, a method that learns program synthesis by integrating\nlanguage models into a self-improving evolutionary loop.\n  SOAR alternates between (1) an evolutionary search that uses an LLM to sample\nand refine candidate solutions, and (2) a hindsight learning phase that\nconverts search attempts into valid problem-solution pairs used to fine-tune\nthe LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly\neffective search in subsequent iterations.\n  On the challenging ARC-AGI benchmark, SOAR achieves significant performance\ngains across model scales and iterations, leveraging positive transfer between\nthe sampling and refinement finetuning tasks. These improvements carry over to\ntest-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our\ncode is open-sourced at: https://github.com/flowersteam/SOAR", "AI": {"tldr": "SOAR\u901a\u8fc7\u5c06\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u81ea\u6539\u8fdb\u7684\u8fdb\u5316\u5faa\u73af\u4e2d\u6765\u5b66\u4e60\u7a0b\u5e8f\u5408\u6210\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u7a0b\u5e8f\u5408\u6210\u7684\u6311\u6218\u3002", "motivation": "\u8bb8\u591a\u7a0b\u5e8f\u7efc\u5408\u4efb\u52a1\u5bf9\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u6765\u8bf4\u90fd\u592a\u96be\u4e86\uff0c\u65e0\u6cd5\u4e00\u6b21\u6027\u89e3\u51b3\u3002\u57fa\u4e8e\u641c\u7d22\u7684\u8fdb\u5316\u65b9\u6cd5\u901a\u8fc7\u8fed\u4ee3\u5730\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u9014\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u6709\u6548\u6027\u4ecd\u7136\u53d7\u5230\u5e95\u5c42\u751f\u6210\u6a21\u578b\u56fa\u5b9a\u80fd\u529b\u7684\u9650\u5236\u3002", "method": "SOAR\u901a\u8fc7\u6574\u5408\u8bed\u8a00\u6a21\u578b\u5230\u4e00\u4e2a\u81ea\u6539\u8fdb\u7684\u8fdb\u5316\u5faa\u73af\u4e2d\u6765\u5b66\u4e60\u7a0b\u5e8f\u5408\u6210\u3002SOAR\u5728\uff081\uff09\u4f7f\u7528LLM\u91c7\u6837\u548c\u6539\u8fdb\u5019\u9009\u89e3\u51b3\u65b9\u6848\u7684\u8fdb\u5316\u641c\u7d22\u548c\uff082\uff09\u5c06\u641c\u7d22\u5c1d\u8bd5\u8f6c\u6362\u4e3a\u7528\u4e8e\u5fae\u8c03LLM\u7684\u91c7\u6837\u548c\u6539\u8fdb\u80fd\u529b\u7684\u6709\u6548\u95ee\u9898-\u89e3\u51b3\u65b9\u6848\u5bf9\u7684\u6ede\u540e\u5b66\u4e60\u9636\u6bb5\u4e4b\u95f4\u4ea4\u66ff\u8fdb\u884c\uff0c\u4ece\u800c\u5728\u540e\u7eed\u8fed\u4ee3\u4e2d\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u641c\u7d22\u3002", "result": "SOAR\u5728\u5177\u6709\u6311\u6218\u6027\u7684ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8de8\u6a21\u578b\u89c4\u6a21\u548c\u8fed\u4ee3\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u80fd\u89e3\u51b352%\u7684\u516c\u5f00\u6d4b\u8bd5\u96c6\u3002", "conclusion": "SOAR\u5728\u5177\u6709\u6311\u6218\u6027\u7684ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8de8\u6a21\u578b\u89c4\u6a21\u548c\u8fed\u4ee3\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u9002\u5e94\u4e2d\u5c06\u8fd9\u4e9b\u6539\u8fdb\u8f6c\u79fb\u5230\u89e3\u51b352%\u7684\u516c\u5f00\u6d4b\u8bd5\u96c6\u4e2d\u3002"}}
{"id": "2507.14369", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14369", "abs": "https://arxiv.org/abs/2507.14369", "authors": ["Issam Mahraj", "Andrzej Ptok"], "title": "Phonon Weyl points and chiral edge modes with unconventional Fermi arcs in NbSi$_{2}$", "comment": "10 pages, 6 figures", "summary": "NbSi$_{2}$ crystallizes in the P6$_{2}$22 symmetry, featuring chiral chains\nof Si atoms. The absence of inversion symmetry, combined with its chiral\nstructure, gives arise to unique physical properties. The breaking of inversion\nsymmetry leads to the emergence of Weyl points, while the chiral structure\nenables the formation of chiral edge modes. As a result, NbSi$_{2}$ serves as\nan ideal platform for exploring the interplay between phonon Weyl points and\nchiral phonon edge modes. For example, we identify the presence of a structure\nconsisting of three Weyl points with a Chern number of $\\mathcal{C} = +1$\naround the $\\bar{\\text{K}}$ point. These nodes form unconventional Fermi arcs\nconnecting the $\\bar{\\Gamma}$ or $\\bar{\\text{K}}$ points, which mimic an\neffective Chern number of $\\mathcal{C} = -2$.", "AI": {"tldr": "NbSi$_{2}$ has a chiral structure and no inversion symmetry, leading to Weyl points and chiral edge modes. It's a good material for studying these phenomena, with specific findings about Weyl points and Fermi arcs.", "motivation": "The motivation is to explore the unique physical properties arising from the absence of inversion symmetry and chiral structure in NbSi$_{2}$, specifically the interplay between phonon Weyl points and chiral phonon edge modes.", "method": "The paper likely used theoretical calculations and symmetry analysis to identify the presence of Weyl points and chiral edge modes in NbSi$_{2}$.", "result": "NbSi$_{2}$ crystallizes in the P6$_{2}$22 symmetry, featuring chiral chains of Si atoms. The paper identifies three Weyl points with a Chern number of +1 around the $\bar{\text{K}}$ point, which form unconventional Fermi arcs connecting the $\bar{\text{\u0393}}$ or $\bar{\text{K}}$ points, mimicking an effective Chern number of -2.", "conclusion": "NbSi$_{2}$ is an ideal platform for exploring the interplay between phonon Weyl points and chiral phonon edge modes due to its chiral structure and absence of inversion symmetry. It hosts three Weyl points with a Chern number of +1 around the $\bar{\text{K}}$ point, forming unconventional Fermi arcs that mimic an effective Chern number of -2."}}
{"id": "2507.14385", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14385", "abs": "https://arxiv.org/abs/2507.14385", "authors": ["Hongliang Li", "Herschel C. Pangborn", "Ilya Kovalenko"], "title": "Bi-level Model Predictive Control for Energy-aware Integrated Product Pricing and Production Scheduling", "comment": null, "summary": "The manufacturing industry is under growing pressure to enhance\nsustainability while preserving economic competitiveness. As a result,\nmanufacturers have been trying to determine how to integrate onsite renewable\nenergy and real-time electricity pricing into manufacturing schedules without\ncompromising profitability. To address this challenge, we propose a bi-level\nmodel predictive control framework that jointly optimizes product prices and\nproduction scheduling with explicit consideration of renewable energy\navailability. The higher level determines the product price to maximize revenue\nand renewable energy usage. The lower level controls production scheduling in\nruntime to minimize operational costs and respond to the product demand. Price\nelasticity is incorporated to model market response, allowing the system to\nincrease demand by lowering the product price during high renewable energy\ngeneration. Results from a lithium-ion battery pack manufacturing system case\nstudy demonstrate that our approach enables manufacturers to reduce grid energy\ncosts while increasing profit.", "AI": {"tldr": "\u4e00\u79cd\u53cc\u5c42\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u53ef\u4ee5\u4f18\u5316\u4ef7\u683c\u548c\u751f\u4ea7\u8ba1\u5212\uff0c\u4ee5\u9002\u5e94\u53ef\u518d\u751f\u80fd\u6e90\u548c\u5b9e\u65f6\u7535\u4ef7\uff0c\u4ece\u800c\u964d\u4f4e\u5236\u9020\u6210\u672c\u5e76\u589e\u52a0\u5229\u6da6\u3002", "motivation": "\u5236\u9020\u4e1a\u9700\u8981\u5728\u4fdd\u6301\u7ecf\u6d4e\u7ade\u4e89\u529b\u7684\u540c\u65f6\u63d0\u9ad8\u53ef\u6301\u7eed\u6027\uff0c\u5236\u9020\u5546\u9700\u8981\u786e\u5b9a\u5982\u4f55\u5728\u4e0d\u635f\u5bb3\u76c8\u5229\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u5c06\u73b0\u573a\u53ef\u518d\u751f\u80fd\u6e90\u548c\u5b9e\u65f6\u7535\u4ef7\u7eb3\u5165\u5236\u9020\u8ba1\u5212\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u660e\u786e\u8003\u8651\u53ef\u518d\u751f\u80fd\u6e90\u53ef\u7528\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u8054\u5408\u4f18\u5316\u4ea7\u54c1\u4ef7\u683c\u548c\u751f\u4ea7\u8c03\u5ea6\u3002", "result": "\u901a\u8fc7\u9502\u79bb\u5b50\u7535\u6c60\u7ec4\u5236\u9020\u7cfb\u7edf\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5e2e\u52a9\u5236\u9020\u5546\u964d\u4f4e\u7535\u7f51\u80fd\u6e90\u6210\u672c\u5e76\u589e\u52a0\u5229\u6da6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5e2e\u52a9\u5236\u9020\u5546\u964d\u4f4e\u7535\u7f51\u80fd\u6e90\u6210\u672c\u5e76\u589e\u52a0\u5229\u6da6\u3002"}}
{"id": "2507.14329", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14329", "abs": "https://arxiv.org/abs/2507.14329", "authors": ["Florian Otterpohl", "Peter Nalbach", "Elisabetta Paladino", "Giuseppe A. Falci", "Michael Thorwart"], "title": "Quantum $1/f^\u03b7$ Noise Induced Relaxation in the Spin-Boson Model", "comment": "7 pages, 5 figures", "summary": "We extend the spin-boson model of open quantum systems to the regime of\nquantum $1/f^\\eta$ noise characterized by negative exponents of its spectral\ndistribution. Using the numerically exact time-evolving matrix product\noperator, we find the dynamic regime diagram, including pseudocoherent dynamics\ncontrolled by quantum $1/f^\\eta$ noise. We determine the dephasing rate and\nfind for it an empirical formula valid at zero temperature. The bath\nreorganization energy depends on the infrared bath cutoff frequency, revealing\nan increased sensitivity of the dephasing on the measurement time of an\nexperiment. \\ep{Our results apply to a qubit as an elementary building block of\na quantum computer and pave the way towards a quantum treatment of\nlow-frequency noise in more complex architectures.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91cf\u5b501/f\u03b7\u566a\u58f0\u5bf9\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e86\u65b0\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u548c\u9000\u76f8\u5e72\u89c4\u5f8b\uff0c\u5e76\u4e3a\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u4f4e\u9891\u566a\u58f0\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5c06\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u81ea\u65cb-\u73bb\u8272\u6a21\u578b\u6269\u5c55\u5230\u91cf\u5b501/f\u03b7\u566a\u58f0\u533a\u57df\uff0c\u8be5\u533a\u57df\u5177\u6709\u8d1f\u6307\u6570\u8c31\u5206\u5e03\u3002", "method": "\u5229\u7528\u6570\u503c\u7cbe\u786e\u7684\u65f6\u95f4\u6f14\u5316\u77e9\u9635\u56e0\u5b50\u7b97\u7b26\uff0c\u786e\u5b9a\u4e86\u52a8\u529b\u5b66\u6a21\u578b\u56fe\uff0c\u5305\u62ec\u7531\u91cf\u5b501/f\u03b7\u566a\u58f0\u63a7\u5236\u7684\u8d5d\u76f8\u5e72\u52a8\u529b\u5b66\u3002", "result": "\u786e\u5b9a\u4e86\u9000\u76f8\u5e72\u7387\uff0c\u5e76\u627e\u5230\u4e86\u9002\u7528\u4e8e\u96f6\u6e29\u5ea6\u7684\u7ecf\u9a8c\u516c\u5f0f\uff0c\u540c\u65f6\u53d1\u73b0\u91cd\u7ec4\u80fd\u5bf9\u7ea2\u5916\u6d74\u622a\u6b62\u9891\u7387\u654f\u611f\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9000\u76f8\u5e72\u6027\u5bf9\u5b9e\u9a8c\u6d4b\u91cf\u65f6\u95f4\u7684\u654f\u611f\u5ea6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u5e94\u7528\u4e8e\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u57fa\u672c\u7ec4\u6210\u5355\u5143\u2014\u2014\u91cf\u5b50\u6bd4\u7279\uff0c\u5e76\u4e3a\u5728\u66f4\u590d\u6742\u7684\u91cf\u5b50\u8ba1\u7b97\u67b6\u6784\u4e2d\u5bf9\u4f4e\u9891\u566a\u58f0\u8fdb\u884c\u91cf\u5b50\u5316\u5904\u7406\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.14200", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14200", "abs": "https://arxiv.org/abs/2507.14200", "authors": ["Shengji Tang", "Jianjian Cao", "Weihao Lin", "Jiale Hong", "Bo Zhang", "Shuyue Hu", "Lei Bai", "Tao Chen", "Wanli Ouyang", "Peng Ye"], "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System", "comment": null, "summary": "This paper aims to demonstrate the potential and strengths of open-source\ncollectives. It leads to a promising question: Can we harness multiple\nopen-source LLMs to match or even beat the closed-source LLMs? To answer this,\nwe propose SMACS, a scalable multi-agent collaboration system (MACS) framework\nwith high performance. Specifically, for continuous integration of new LLMs and\ngeneralization to diverse questions, we first propose a Retrieval-based Prior\nSelection (RPS), which assigns a proxy performance score to each LLM to select\nthe Top-k LLMs at the instance level for any given question. Then, we propose\nan Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the\ngeneration of diverse responses through prior dropping and selecting the\nhigh-quality response via a hybrid posterior score. Experiments on eight\nmainstream benchmarks validate the effectiveness of our SMACS: by integrating\nfifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,\ne.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)\nacross multiple tasks. Remarkably, it even exceeds the average of best results\nof different datasets from both open-source LLMs (+2.86%) and closed-source\nLLMs (+2.04%), pushing the upper bound of intelligence. Code will be released\nat https://github.com/magent4aci/SMACS.", "AI": {"tldr": "SMACS\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u68c0\u7d22\u5f0f\u5148\u9a8c\u9009\u62e9\uff08RPS\uff09\u548c\u63a2\u7d22-\u5229\u7528\u9a71\u52a8\u7684\u540e\u9a8c\u589e\u5f3a\uff08EPE\uff09\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\uff08MACS\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u5f00\u6e90LLM\uff0c\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6bd4\u9886\u5148\u7684\u95ed\u6e90\u6a21\u578b\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u65e8\u5728\u5c55\u793a\u5f00\u6e90\u96c6\u4f53\u7684\u6f5c\u529b\u548c\u4f18\u52bf\uff0c\u5e76\u63a2\u8ba8\u662f\u5426\u53ef\u4ee5\u5229\u7528\u591a\u4e2a\u5f00\u6e90LLM\u6765\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u95ed\u6e90LLM\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSMACS\u7684\u53ef\u6269\u5c55\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\uff08MACS\uff09\u6846\u67b6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4e3a\u4e86\u6301\u7eed\u96c6\u6210\u65b0\u7684LLM\u548c\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u95ee\u9898\uff0c\u9996\u5148\u63d0\u51fa\u4e86\u68c0\u7d22\u5f0f\u5148\u9a8c\u9009\u62e9\uff08RPS\uff09\uff0c\u4e3a\u6bcf\u4e2aLLM\u5206\u914d\u4ee3\u7406\u6027\u80fd\u5206\u6570\uff0c\u4ee5\u4fbf\u5728\u5b9e\u4f8b\u7ea7\u522b\u4e3a\u4efb\u4f55\u7ed9\u5b9a\u95ee\u9898\u9009\u62e9\u524dk\u4e2aLLM\u3002\u7136\u540e\uff0c\u63d0\u51fa\u4e86\u63a2\u7d22-\u5229\u7528\u9a71\u52a8\u7684\u540e\u9a8c\u589e\u5f3a\uff08EPE\uff09\uff0c\u901a\u8fc7\u5148\u9a8c\u4e22\u5f03\u9f13\u52b1\u751f\u6210\u591a\u6837\u5316\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u540e\u9a8c\u5206\u6570\u9009\u62e9\u9ad8\u8d28\u91cf\u54cd\u5e94\u3002", "result": "SMACS\u901a\u8fc7\u6574\u5408\u5341\u4e94\u4e2a\u5f00\u6e90LLM\uff0c\u5728\u516b\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86Claude-3.7-Sonnet (+12.73%)\u3001GPT-4.1(+5.36%)\u548cGPT-o3-mini(+5.28%)\u7b49\u9886\u5148\u7684\u95ed\u6e90LLM\uff0c\u5e76\u4e14\u8d85\u8fc7\u4e86\u5f00\u6e90LLM\uff08+2.86%\uff09\u548c\u95ed\u6e90LLM\uff08+2.04%\uff09\u4e0d\u540c\u6570\u636e\u96c6\u7684\u6700\u4f73\u7ed3\u679c\u7684\u5e73\u5747\u503c\u3002", "conclusion": "SMACS\u901a\u8fc7\u6574\u5408\u5341\u4e94\u4e2a\u5f00\u6e90LLM\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u95ed\u6e90LLM\uff08\u5982Claude-3.7-Sonnet\u3001GPT-4.1\u548cGPT-o3-mini\uff09\uff0c\u5e76\u8d85\u8fc7\u4e86\u5f00\u6e90\u548c\u95ed\u6e90LLM\u7684\u6700\u4f73\u7ed3\u679c\u7684\u5e73\u5747\u503c\uff0c\u63a8\u52a8\u4e86\u667a\u80fd\u7684\u4e0a\u9650\u3002"}}
{"id": "2507.14920", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.14920", "abs": "https://arxiv.org/abs/2507.14920", "authors": ["Evandro S. Ortigossa", "F\u00e1bio F. Dias", "Diego C. Nascimento", "Luis Gustavo Nonato"], "title": "Time Series Information Visualization -- A Review of Approaches and Tools", "comment": "Preprint. Under review", "summary": "Time series data are prevalent across various domains and often encompass\nlarge datasets containing multiple time-dependent features in each sample.\nExploring time-varying data is critical for data science practitioners aiming\nto understand dynamic behaviors and discover periodic patterns and trends.\nHowever, the analysis of such data often requires sophisticated procedures and\ntools. Information visualization is a communication channel that leverages\nhuman perceptual abilities to transform abstract data into visual\nrepresentations. Visualization techniques have been successfully applied in the\ncontext of time series to enhance interpretability by graphically representing\nthe temporal evolution of data. The challenge for information visualization\ndevelopers lies in integrating a wide range of analytical tools into rich\nvisualization systems that can summarize complex datasets while clearly\ndescribing the impacts of the temporal component. Such systems enable data\nscientists to turn raw data into understandable and potentially useful\nknowledge. This review examines techniques and approaches designed for handling\ntime series data, guiding users through knowledge discovery processes based on\nvisual analysis. We also provide readers with theoretical insights and design\nguidelines for considering when developing comprehensive information\nvisualization approaches for time series, with a particular focus on time\nseries with multiple features. As a result, we highlight the challenges and\nfuture research directions to address open questions in the visualization of\ntime-dependent data.", "AI": {"tldr": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u6790\u590d\u6742\uff0c\u4fe1\u606f\u53ef\u89c6\u5316\u662f\u5173\u952e\u3002\u672c\u8bba\u6587\u7efc\u8ff0\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u7684\u6280\u672f\u548c\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u6307\u5357\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u672c\u7bc7\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u5404\u4e2a\u9886\u57df\u90fd\u975e\u5e38\u666e\u904d\uff0c\u4f46\u5176\u5206\u6790\u8fc7\u7a0b\u590d\u6742\uff0c\u9700\u8981\u5148\u8fdb\u7684\u5de5\u5177\u3002\u4fe1\u606f\u53ef\u89c6\u5316\u4f5c\u4e3a\u4e00\u79cd\u5229\u7528\u4eba\u7c7b\u611f\u77e5\u80fd\u529b\u5c06\u6570\u636e\u8f6c\u5316\u4e3a\u89c6\u89c9\u8868\u793a\u7684\u901a\u4fe1\u6e20\u9053\uff0c\u5728\u589e\u5f3a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u548c\u603b\u7ed3\u7528\u4e8e\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5e76\u4e3a\u5f00\u53d1\u76f8\u5173\u53ef\u89c6\u5316\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u7bc7\u8bba\u6587\u7684\u5206\u6790\u65b9\u6cd5\u662f\u5ba1\u67e5\u73b0\u6709\u7684\u4fe1\u606f\u53ef\u89c6\u5316\u6280\u672f\u548c\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u901a\u8fc7\u68b3\u7406\u8fd9\u4e9b\u6280\u672f\u548c\u65b9\u6cd5\uff0c\u4e3a\u5f00\u53d1\u66f4\u5168\u9762\u7684\u53ef\u89c6\u5316\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u89c1\u89e3\u548c\u8bbe\u8ba1\u6307\u5357\u3002", "result": "\u672c\u7bc7\u8bba\u6587\u7684\u7ed3\u679c\u662f\uff0c\u5b83\u5ba1\u67e5\u4e86\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6280\u672f\u548c\u65b9\u6cd5\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u57fa\u4e8e\u89c6\u89c9\u5206\u6790\u7684\u77e5\u8bc6\u53d1\u73b0\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u4e3a\u5f00\u53d1\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53ef\u89c6\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u548c\u8bbe\u8ba1\u6307\u5357\uff0c\u5e76\u6307\u51fa\u4e86\u8be5\u9886\u57df\u9762\u4e34\u7684\u6311\u6218\u548c\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u7bc7\u8bba\u6587\u7684\u7ed3\u8bba\u662f\uff0c\u4fe1\u606f\u53ef\u89c6\u5316\u6280\u672f\u5728\u5904\u7406\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u53ef\u4ee5\u5e2e\u52a9\u6570\u636e\u79d1\u5b66\u5bb6\u7406\u89e3\u52a8\u6001\u884c\u4e3a\u3001\u53d1\u73b0\u5468\u671f\u6027\u6a21\u5f0f\u548c\u8d8b\u52bf\u3002\u7136\u800c\uff0c\u4ecd\u5b58\u5728\u4e00\u4e9b\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6765\u89e3\u51b3\u65f6\u95f4\u4f9d\u8d56\u6027\u6570\u636e\u7684\u53ef\u89c6\u5316\u95ee\u9898\u3002"}}
{"id": "2507.14757", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14757", "abs": "https://arxiv.org/abs/2507.14757", "authors": ["Szymon Mazurek", "Jakub Caputa", "Maciej Wielgosz"], "title": "Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space", "comment": null, "summary": "Spiking Neural Networks (SNNs) offer energy-efficient and biologically\nplausible alternatives to traditional artificial neural networks, but their\nperformance depends critically on the tuning of neuron model parameters. In\nthis work, we identify and characterize an operational space - a constrained\nregion in the neuron hyperparameter domain (specifically membrane time constant\ntau and voltage threshold vth) - within which the network exhibits meaningful\nactivity and functional behavior. Operating inside this manifold yields optimal\ntrade-offs between classification accuracy and spiking activity, while stepping\noutside leads to degeneration: either excessive energy use or complete network\nsilence.\n  Through systematic exploration across datasets and architectures, we\nvisualize and quantify this manifold and identify efficient operating points.\nWe further assess robustness to adversarial noise, showing that SNNs exhibit\nincreased spike correlation and internal synchrony when operating outside their\noptimal region. These findings highlight the importance of principled\nhyperparameter tuning to ensure both task performance and energy efficiency.\nOur results offer practical guidelines for deploying robust and efficient SNNs,\nparticularly in neuromorphic computing scenarios.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14651", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.14651", "abs": "https://arxiv.org/abs/2507.14651", "authors": ["Joren Dumoulin", "Pouya Houshmand", "Vikram Jain", "Marian Verhelst"], "title": "Enabling Efficient Hardware Acceleration of Hybrid Vision Transformer (ViT) Networks at the Edge", "comment": null, "summary": "Hybrid vision transformers combine the elements of conventional neural\nnetworks (NN) and vision transformers (ViT) to enable lightweight and accurate\ndetection. However, several challenges remain for their efficient deployment on\nresource-constrained edge devices. The hybrid models suffer from a widely\ndiverse set of NN layer types and large intermediate data tensors, hampering\nefficient hardware acceleration. To enable their execution at the edge, this\npaper proposes innovations across the hardware-scheduling stack: a.) At the\nlowest level, a configurable PE array supports all hybrid ViT layer types; b.)\ntemporal loop re-ordering within one layer, enabling hardware support for\nnormalization and softmax layers, minimizing on-chip data transfers; c.)\nfurther scheduling optimization employs layer fusion across inverted bottleneck\nlayers to drastically reduce off-chip memory transfers. The resulting\naccelerator is implemented in 28nm CMOS, achieving a peak energy efficiency of\n1.39 TOPS/W at 25.6 GMACs/s.", "AI": {"tldr": "\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u6df7\u5408\u89c6\u89c9Transformer\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u914d\u7f6ePE\u9635\u5217\u3001\u5c42\u5185\u65f6\u95f4\u5faa\u73af\u91cd\u6392\u5e8f\u548c\u5c42\u878d\u5408\u7684\u786c\u4ef6\u8c03\u5ea6\u4f18\u5316\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6570\u636e\u4f20\u8f93\uff0c\u5b9e\u73b0\u4e86\u9ad8\u80fd\u6548\u6bd4\u3002", "motivation": "\u4e3a\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u90e8\u7f72\u6df7\u5408\u89c6\u89c9Transformer\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u56e0\u5c42\u7c7b\u578b\u591a\u6837\u548c\u4e2d\u95f4\u6570\u636e\u5f20\u91cf\u5927\u800c\u96be\u4ee5\u8fdb\u884c\u786c\u4ef6\u52a0\u901f\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u8d8a\u786c\u4ef6\u8c03\u5ea6\u5806\u6808\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1\uff09\u5728\u6700\u4f4e\u5c42\u7ea7\uff0c\u901a\u8fc7\u53ef\u914d\u7f6e\u7684\u5904\u7406\u5355\u5143\uff08PE\uff09\u9635\u5217\u652f\u6301\u6240\u6709\u6df7\u5408ViT\u5c42\u7c7b\u578b\uff1b2\uff09\u901a\u8fc7\u5c42\u5185\u65f6\u95f4\u5faa\u73af\u91cd\u6392\u5e8f\uff0c\u4e3a\u5f52\u4e00\u5316\u548cSoftmax\u5c42\u63d0\u4f9b\u786c\u4ef6\u652f\u6301\uff0c\u5e76\u6700\u5c0f\u5316\u7247\u4e0a\u6570\u636e\u4f20\u8f93\uff1b3\uff09\u901a\u8fc7\u878d\u5408\u5012\u7f6e\u74f6\u9888\u5c42\uff08inverted bottleneck layers\uff09\u8fdb\u4e00\u6b65\u4f18\u5316\u8c03\u5ea6\uff0c\u4ee5\u5927\u5e45\u51cf\u5c11\u7247\u5916\u5185\u5b58\u4f20\u8f93\u3002", "result": "\u5b9e\u73b0\u4e86\u652f\u6301\u6240\u6709\u6df7\u5408ViT\u5c42\u7c7b\u578b\u7684\u53ef\u914d\u7f6ePE\u9635\u5217\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u5faa\u73af\u91cd\u6392\u5e8f\u548c\u5c42\u878d\u5408\u7b49\u6280\u672f\uff0c\u6700\u5c0f\u5316\u4e86\u6570\u636e\u4f20\u8f93\uff0c\u6700\u7ec8\u7684\u52a0\u901f\u5668\u572828nm CMOS\u4e0a\u5b9e\u73b0\u4e861.39 TOPS/W\u7684\u5cf0\u503c\u80fd\u6548\u6bd4\u548c25.6 GMACs/s\u7684\u5904\u7406\u901f\u5ea6\u3002", "conclusion": "\u8be5\u6df7\u5408\u89c6\u89c9Transformer\u52a0\u901f\u5668\u572828nm CMOS\u4e0a\u5b9e\u73b0\uff0c\u5cf0\u503c\u80fd\u6548\u6bd4\u8fbe\u52301.39 TOPS/W\uff0c\u5904\u7406\u901f\u5ea6\u4e3a25.6 GMACs/s\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u7684\u90e8\u7f72\u6311\u6218\u3002"}}
{"id": "2507.14696", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14696", "abs": "https://arxiv.org/abs/2507.14696", "authors": ["Samantha Dies", "David Liu", "Tina Eliassi-Rad"], "title": "Forecasting Faculty Placement from Patterns in Co-authorship Networks", "comment": null, "summary": "Faculty hiring shapes the flow of ideas, resources, and opportunities in\nacademia, influencing not only individual career trajectories but also broader\npatterns of institutional prestige and scientific progress. While traditional\nstudies have found strong correlations between faculty hiring and attributes\nsuch as doctoral department prestige and publication record, they rarely assess\nwhether these associations generalize to individual hiring outcomes,\nparticularly for future candidates outside the original sample. Here, we\nconsider faculty placement as an individual-level prediction task. Our data\nconsist of temporal co-authorship networks with conventional attributes such as\ndoctoral department prestige and bibliometric features. We observe that using\nthe co-authorship network significantly improves predictive accuracy by up to\n10% over traditional indicators alone, with the largest gains observed for\nplacements at the most elite (top-10) departments. Our results underscore the\nrole that social networks, professional endorsements, and implicit advocacy\nplay in faculty hiring beyond traditional measures of scholarly productivity\nand institutional prestige. By introducing a predictive framing of faculty\nplacement and establishing the benefit of considering co-authorship networks,\nthis work provides a new lens for understanding structural biases in academia\nthat could inform targeted interventions aimed at increasing transparency,\nfairness, and equity in academic hiring practices.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5b66\u672f\u62db\u8058\u4e2d\u7684\u5171\u4f5c\u8005\u7f51\u7edc\uff0c\u53d1\u73b0\u5176\u6bd4\u4f20\u7edf\u6307\u6807\uff08\u5982\u535a\u58eb\u5b66\u4f4d\u6388\u4e88\u90e8\u95e8\u58f0\u671b\u548c\u53d1\u8868\u8bb0\u5f55\uff09\u66f4\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u9876\u5c16\u90e8\u95e8\u7684\u62db\u8058\u4e2d\uff0c\u8fd9\u8868\u660e\u793e\u4f1a\u7f51\u7edc\u548c\u4e13\u4e1a\u8ba4\u53ef\u5728\u5b66\u672f\u62db\u8058\u4e2d\u8d77\u7740\u91cd\u8981\u4f5c\u7528\uff0c\u5e76\u6709\u52a9\u4e8e\u8bc6\u522b\u548c\u89e3\u51b3\u5b66\u672f\u754c\u7684\u7ed3\u6784\u6027\u504f\u89c1\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u867d\u7136\u53d1\u73b0\u4e86\u6559\u804c\u62db\u8058\u4e0e\u535a\u58eb\u5b66\u4f4d\u6388\u4e88\u90e8\u95e8\u58f0\u671b\u548c\u53d1\u8868\u8bb0\u5f55\u7b49\u5c5e\u6027\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4f46\u5f88\u5c11\u8bc4\u4f30\u8fd9\u4e9b\u5173\u8054\u662f\u5426\u80fd\u63a8\u5e7f\u5230\u4e2a\u4f53\u62db\u8058\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u539f\u59cb\u6837\u672c\u4e4b\u5916\u7684\u672a\u6765\u5019\u9009\u4eba\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u672c\u7814\u7a76\u5c06\u6559\u804cplacement\u89c6\u4e3a\u4e00\u9879\u4e2a\u4f53\u5c42\u9762\u7684\u9884\u6d4b\u4efb\u52a1\uff0c\u5229\u7528\u5305\u62ec\u535a\u58eb\u5b66\u4f4d\u6388\u4e88\u90e8\u95e8\u58f0\u671b\u548c\u6587\u732e\u8ba1\u91cf\u7279\u5f81\u5728\u5185\u7684\u4f20\u7edf\u5c5e\u6027\uff0c\u7ed3\u5408\u65f6\u95f4\u5171\u4f5c\u8005\u7f51\u7edc\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u4ec5\u4f7f\u7528\u4f20\u7edf\u6307\u6807\u76f8\u6bd4\uff0c\u5229\u7528\u5171\u4f5c\u8005\u7f51\u7edc\u53ef\u4ee5\u5c06\u9884\u6d4b\u51c6\u786e\u5ea6\u663e\u8457\u63d0\u9ad8\u591a\u8fbe10%\uff0c\u5176\u4e2d\u5728\u6700\u9876\u5c16\uff08\u524d10\u540d\uff09\u7684\u90e8\u95e8\uff0c\u9884\u6d4b\u51c6\u786e\u5ea6\u7684\u63d0\u5347\u6700\u4e3a\u663e\u8457\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u793e\u4f1a\u7f51\u7edc\u3001\u4e13\u4e1a\u8ba4\u53ef\u548c\u9690\u6027\u5021\u5bfc\u5728\u5b66\u672f\u62db\u8058\u4e2d\u8d85\u8d8a\u4f20\u7edf\u5b66\u672f\u6210\u679c\u548c\u673a\u6784\u58f0\u671b\u6307\u6807\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u5f15\u5165\u5b66\u672f\u804c\u4f4d\u5206\u914d\u7684\u9884\u6d4b\u6846\u67b6\u5e76\u786e\u7acb\u8003\u8651\u5408\u8457\u8005\u7f51\u7edc\u7684\u76ca\u5904\uff0c\u672c\u7814\u7a76\u4e3a\u7406\u89e3\u5b66\u672f\u754c\u7684\u7ed3\u6784\u6027\u504f\u89c1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u4e3a\u63d0\u9ad8\u5b66\u672f\u62db\u8058\u5b9e\u8df5\u7684\u900f\u660e\u5ea6\u3001\u516c\u5e73\u6027\u548c\u5e73\u7b49\u6027\u63d0\u4f9b\u6709\u9488\u5bf9\u6027\u7684\u5e72\u9884\u63aa\u65bd\u3002"}}
{"id": "2507.14504", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14504", "abs": "https://arxiv.org/abs/2507.14504", "authors": ["Junqiang Peng", "Zimo Sheng", "Mingyu Xiao"], "title": "New Algorithms for #2-SAT and #3-SAT", "comment": "Accepted by IJCAI 2025", "summary": "The #2-SAT and #3-SAT problems involve counting the number of satisfying\nassignments (also called models) for instances of 2-SAT and 3-SAT,\nrespectively. In 2010, Zhou et al. proposed an $\\mathcal{O}^*(1.1892^m)$-time\nalgorithm for #2-SAT and an efficient approach for #3-SAT, where $m$ denotes\nthe number of clauses. In this paper, we show that the weighted versions of\n#2-SAT and #3-SAT can be solved in $\\mathcal{O}^*(1.1082^m)$ and\n$\\mathcal{O}^*(1.4423^m)$ time, respectively. These results directly apply to\nthe unweighted cases and achieve substantial improvements over the previous\nresults. These advancements are enabled by the introduction of novel reduction\nrules, a refined analysis of branching operations, and the application of path\ndecompositions on the primal and dual graphs of the formula.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u6c42\u89e3\u52a0\u6743 #2-SAT \u548c #3-SAT \u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7b97\u6cd5\u6548\u7387\u3002", "motivation": "\u5728 #2-SAT \u548c #3-SAT \u95ee\u9898\uff08\u8ba1\u7b97 2-SAT \u548c 3-SAT \u5b9e\u4f8b\u7684\u6ee1\u8db3\u8d4b\u503c\u6570\u91cf\uff09\u7684\u80cc\u666f\u4e0b\uff0c\u65e8\u5728\u6539\u8fdb\u5df2\u6709\u7b97\u6cd5\u7684\u6548\u7387\uff0c\u7279\u522b\u662f\u9488\u5bf9\u52a0\u6743\u7248\u672c\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u7ea6\u7b80\u89c4\u5219\u3001\u6539\u8fdb\u5206\u652f\u64cd\u4f5c\u5206\u6790\u4ee5\u53ca\u5e94\u7528\u8def\u5f84\u5206\u89e3\u5230\u516c\u5f0f\u7684\u56fe\u8bba\u8868\u793a\uff08\u5305\u62ec\u539f\u56fe\u548c\u5bf9\u5076\u56fe\uff09\u6765\u89e3\u51b3\u52a0\u6743 #2-SAT \u548c #3-SAT \u95ee\u9898\u3002", "result": "\u52a0\u6743 #2-SAT \u95ee\u9898\u53ef\u4ee5\u5728 O*(1.1082^m) \u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u52a0\u6743 #3-SAT \u95ee\u9898\u53ef\u4ee5\u5728 O*(1.4423^m) \u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u8fd9\u4e9b\u7ed3\u679c\u4e5f\u9002\u7528\u4e8e\u65e0\u6743\u60c5\u51b5\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u7814\u7a76\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u52a0\u6743 #2-SAT \u548c #3-SAT \u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u6c42\u89e3\u7b97\u6cd5\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u5206\u522b\u4e3a O*(1.1082^m) \u548c O*(1.4423^m)\uff0c\u5728\u65e0\u6743\u60c5\u51b5\u4e0b\u4e5f\u4f18\u4e8e\u5148\u524d\u7ed3\u679c\u3002"}}
{"id": "2507.15014", "categories": ["physics.app-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15014", "abs": "https://arxiv.org/abs/2507.15014", "authors": ["Graeme W. Milton"], "title": "A rediscovery of stiff pentmodes. A comment on \"High bulk modulus pentamodes: the three-dimensional metal water\"", "comment": "8 pages, 3 figures", "summary": "We bring attention to the fact that the claim of Brambilla et.al. [Extreme\nMechanics Letters 74 (2025) 102267; arXiv:2406.14502] of discovering a novel\ndesign for pentamode materials is incorrect. Back in 2016 Briane, Harutyunyan\nand myself [Mathematics and Mechanics of Complex Systems 5 (2016) 41--94;\narXiv:1606.03305] designed a class of stiff pentamodes, that include the high\nbulk modulus pentamodes of Brambilla et.al.", "AI": {"tldr": "Brambilla et.al. \u8072\u7a31\u767c\u73fe\u65b0\u578b\u4e94\u6a21\u6750\u6599\u8a2d\u8a08\u662f\u932f\u8aa4\u7684\uff0c\u4f5c\u8005\u65e9\u5728 2016 \u5e74\u5c31\u5df2\u8a2d\u8a08\u51fa\u5305\u542b\u8a72\u6750\u6599\u7684\u4e94\u6a21\u6750\u6599\u3002", "motivation": "\u6307\u51fa Brambilla et.al. \u7684\u7814\u7a76\u4e2d\u5b58\u5728\u4e0d\u6b63\u786e\u7684\u8bf4\u6cd5\uff0c\u5373\u4ed6\u4eec\u53d1\u73b0\u4e86\u65b0\u578b\u4e94\u6a21\u6750\u6599\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u5f15\u7528\u5148\u524d\u7684\u5de5\u4f5c\u6765\u53cd\u9a73 Brambilla et.al. \u7684\u7814\u7a76\u7ed3\u679c\u3002", "result": "Briane, Harutyunyan \u548c\u4f5c\u8005\u5728 2016 \u5e74\u5c31\u5df2\u7ecf\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5305\u542b Brambilla et.al. \u7684\u9ad8\u4f53\u79ef\u6a21\u91cf\u4e94\u6a21\u6750\u6599\u7684\u521a\u6027\u4e94\u6a21\u6750\u6599\u3002", "conclusion": "Brambilla et.al. \u7684\u7814\u7a76\u7ed3\u679c\u662f\u9519\u8bef\u7684\uff0c\u4ed6\u4eec\u53d1\u73b0\u7684\u65b0\u578b\u4e94\u6a21\u6750\u6599\u8bbe\u8ba1\u5e76\u4e0d\u65b0\u9896\u3002"}}
{"id": "2507.15483", "categories": ["cs.ET", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.15483", "abs": "https://arxiv.org/abs/2507.15483", "authors": ["Selen Gecgel Cetin", "Baris Donmez", "Gunes Karabulut Kurt"], "title": "Advancing Lunar Communication through Inter-domain Space Networks and Dynamic Orchestration", "comment": null, "summary": "The reawakened era of lunar exploration is defined by a strategic shift from\ntemporary visits to a sustained international and commercial presence,\nresulting in an unprecedented demand for a robust and continuously available\ncommunication infrastructure. The conventional direct-to-Earth communication\narchitecture relies on limited and oversubscribed deep space networks, which\nare further challenged by the radiative environment and insufficient visibility\nin certain areas of the cislunar domain. We address these issues by proposing a\nfoundational move toward inter-domain space network cooperation by introducing\narchitectures based on near space networks. They can directly service lunar\nsurface users or, via cislunar relays, by forming a resilient and multi-layered\ncommunication backbone. First, we establish a unified link analysis framework\nincorporating frequently disregarded environmental factors, such as the Moon's\nvariable illumination, to provide a high-fidelity performance evaluation.\nSecond, we assess architectures' reliability based on the outage risk,\nessential for quantifying the operational robustness of communication links.\nFinally, to manage the inherent dynamism of architectures, we propose an\ninter-domain space digital twin$-$a dynamic decision-making engine that\nperforms real-time analysis to autonomously select the best communication path,\nensuring high and stable reliability while simultaneously optimizing power\nconsumption. Overall, our paper provides a holistic architectural and\nconceptual management framework, emphasizing the necessity of lunar\ncommunications to support a permanent human and economic foothold on the Moon.", "AI": {"tldr": "\u9274\u4e8e\u6708\u7403\u63a2\u7d22\u7684\u6301\u7eed\u9700\u6c42\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd1\u5730\u7a7a\u95f4\u7f51\u7edc\u7684\u65b0\u578b\u901a\u4fe1\u67b6\u6784\uff0c\u4ee5\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u786e\u4fdd\u6708\u7403\u901a\u4fe1\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u76f4\u63a5\u5bf9\u5730\u901a\u4fe1\u67b6\u6784\u4f9d\u8d56\u4e8e\u6709\u9650\u4e14\u8fc7\u5ea6\u4f7f\u7528\u7684\u6df1\u7a7a\u7f51\u7edc\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u6708\u7403\u533a\u57df\u9762\u4e34\u901a\u4fe1\u53ef\u89c1\u6027\u4e0d\u8db3\u7684\u6311\u6218\u3002\u968f\u7740\u6708\u7403\u63a2\u7d22\u8fdb\u5165\u65b0\u65f6\u4ee3\uff0c\u9700\u8981\u4e00\u4e2a\u5f3a\u5927\u4e14\u53ef\u7528\u7684\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\u6765\u652f\u6301\u6301\u7eed\u7684\u56fd\u9645\u548c\u5546\u4e1a\u6d3b\u52a8\u3002", "method": "1. \u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u94fe\u8def\u5206\u6790\u6846\u67b6\uff0c\u8003\u8651\u4e86\u6708\u7403\u53ef\u53d8\u5149\u7167\u7b49\u73af\u5883\u56e0\u7d20\uff0c\u4ee5\u8fdb\u884c\u9ad8\u4fdd\u771f\u6027\u80fd\u8bc4\u4f30\u3002 2. \u57fa\u4e8e\u4e2d\u65ad\u98ce\u9669\u8bc4\u4f30\u4e86\u901a\u4fe1\u67b6\u6784\u7684\u53ef\u9760\u6027\u3002 3. \u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u51b3\u7b56\u5f15\u64ce\uff08\u8de8\u57df\u7a7a\u95f4\u6570\u5b57\u5b6a\u751f\uff09\u6765\u7ba1\u7406\u67b6\u6784\u7684\u52a8\u6001\u6027\uff0c\u9009\u62e9\u6700\u4f73\u901a\u4fe1\u8def\u5f84\uff0c\u786e\u4fdd\u9ad8\u7a33\u5b9a\u6027\u548c\u4f18\u5316\u529f\u8017\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u4fdd\u771f\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\uff0c\u91cf\u5316\u4e86\u901a\u4fe1\u94fe\u8def\u7684\u8fd0\u884c\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u51b3\u7b56\u5f15\u64ce\u5b9e\u73b0\u4e86\u901a\u4fe1\u8def\u5f84\u7684\u9009\u62e9\u4f18\u5316\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u652f\u6301\u6708\u7403\u6c38\u4e45\u4eba\u5458\u548c\u7ecf\u6d4e\u7acb\u8db3\u70b9\u7684\u6708\u7403\u901a\u4fe1\u7684\u6574\u4f53\u67b6\u6784\u548c\u6982\u5ff5\u7ba1\u7406\u6846\u67b6\u3002"}}
{"id": "2507.14472", "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.14472", "abs": "https://arxiv.org/abs/2507.14472", "authors": ["Yuhang Guo", "Dong Hao", "Bin Li", "Mingyu Xiao", "Bakh Khoussainov"], "title": "Strategyproofness and Monotone Allocation of Auction in Social Networks", "comment": "Accepted by IJCAI 2025", "summary": "Strategyproofness in network auctions requires that bidders not only report\ntheir valuations truthfully, but also do their best to invite neighbours from\nthe social network. In contrast to canonical auctions, where the value-monotone\nallocation in Myerson's Lemma is a cornerstone, a general principle of\nallocation rules for strategyproof network auctions is still missing. We show\nthat, due to the absence of such a principle, even extensions to multi-unit\nnetwork auctions with single-unit demand present unexpected difficulties, and\nall pioneering researches fail to be strategyproof. For the first time in this\nfield, we identify two categories of monotone allocation rules on networks:\nInvitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity\n(IP-MON). They encompass all existing allocation rules of network auctions as\nspecific instances. For any given ID-MON or IP-MON allocation rule, we\ncharacterize the existence and sufficient conditions for the strategyproof\npayment rules, and show that among all such payment rules, the\nrevenue-maximizing one exists and is computationally feasible. With these\nresults, the obstacle of combinatorial network auction with single-minded\nbidders is now resolved.", "AI": {"tldr": "\u7f51\u7edc\u62cd\u5356\u7684\u7b56\u7565\u8bc1\u660e\u6bd4\u4f20\u7edf\u62cd\u5356\u66f4\u590d\u6742\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u5206\u914d\u89c4\u5219\uff08ID-MON \u548c IP-MON\uff09\uff0c\u5e76\u4e3a\u5b83\u4eec\u63d0\u4f9b\u4e86\u7b56\u7565\u8bc1\u660e\u7684\u652f\u4ed8\u89c4\u5219\uff0c\u89e3\u51b3\u4e86\u7ec4\u5408\u7f51\u7edc\u62cd\u5356\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u5728\u7f51\u7edc\u62cd\u5356\u4e2d\uff0c\u9664\u4e86\u771f\u5b9e\u62a5\u544a\u4f30\u503c\u5916\uff0c\u8fd8\u9700\u8981\u6295\u6807\u4eba\u9080\u8bf7\u90bb\u5c45\uff0c\u8fd9\u4e0e\u4f20\u7edf\u62cd\u5356\u4e0d\u540c\u3002\u7531\u4e8e\u7f3a\u4e4f\u660e\u786e\u7684\u5206\u914d\u539f\u5219\uff0c\u7f51\u7edc\u62cd\u5356\u7684\u7b56\u7565\u8bc1\u660e\u53d8\u5f97\u590d\u6742\uff0c\u5c24\u5176\u662f\u5728\u591a\u5355\u4f4d\u7f51\u7edc\u62cd\u5356\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u5355\u8c03\u5206\u914d\u89c4\u5219\uff08ID-MON \u548c IP-MON\uff09\uff0c\u5e76\u4e3a\u8fd9\u4e9b\u89c4\u5219\u7684\u7b56\u7565\u8bc1\u660e\u652f\u4ed8\u89c4\u5219\u7684\u5b58\u5728\u6027\u53ca\u5176\u5145\u5206\u6761\u4ef6\u8fdb\u884c\u4e86\u7279\u5f81\u5316\uff0c\u540c\u65f6\u8868\u660e\u4e86\u6536\u76ca\u6700\u5927\u5316\u652f\u4ed8\u89c4\u5219\u7684\u5b58\u5728\u6027\u53ca\u5176\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "result": "\u8bc6\u522b\u4e86 ID-MON \u548c IP-MON \u4e24\u79cd\u5355\u8c03\u5206\u914d\u89c4\u5219\uff0c\u5b83\u4eec\u5305\u542b\u4e86\u6240\u6709\u73b0\u6709\u7684\u7f51\u7edc\u62cd\u5356\u5206\u914d\u89c4\u5219\u3002\u4e3a\u8fd9\u4e9b\u89c4\u5219\u627e\u5230\u4e86\u7b56\u7565\u8bc1\u660e\u652f\u4ed8\u89c4\u5219\uff0c\u5e76\u8bc1\u660e\u4e86\u6536\u76ca\u6700\u5927\u5316\u652f\u4ed8\u89c4\u5219\u7684\u5b58\u5728\u6027\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7ec4\u5408\u7f51\u7edc\u62cd\u5356\u4e2d\u7684\u5355\u76ee\u6807\u7ade\u6807\u8005\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u4e00\u4e2a\u4e3b\u8981\u969c\u788d\u3002"}}
{"id": "2507.15415", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.15415", "abs": "https://arxiv.org/abs/2507.15415", "authors": ["Florent Ferrari", "Emmanuel Hainry", "Romain P\u00e9choux", "M\u00e1rio Silva"], "title": "Quantum Programming in Polylogarithmic Time", "comment": null, "summary": "Polylogarithmic time delineates a relevant notion of feasibility on several\nclassical computational models such as Boolean circuits or parallel random\naccess machines. As far as the quantum paradigm is concerned, this notion\nyields the complexity class FBQPOLYLOG of functions approximable in\npolylogarithmic time with a quantum random-access Turing machine. We introduce\na quantum programming language with first-order recursive procedures, which\nprovides the first programming-language-based characterization of FBQPOLYLOG.\nEach program computes a function in FBQPOLYLOG (soundness) and, conversely,\neach function of this complexity class is computed by a program (completeness).\nWe also provide a compilation strategy from programs to uniform families of\nquantum circuits of polylogarithmic depth and polynomial size, whose set of\ncomputed functions is known as QNC, and recover the well-known separation\nresult FBQPOLYLOG $\\subsetneq$ QNC.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\uff0c\u7528\u4e8e\u8868\u5f81 FBQPOLYLOG \u590d\u6742\u5ea6\u7c7b\uff0c\u5e76\u8bc1\u660e\u4e86 FBQPOLYLOG $\\subsetneq$ QNC\u3002", "motivation": "\u5728\u7ecf\u5178\u8ba1\u7b97\u6a21\u578b\uff08\u5982\u5e03\u5c14\u7535\u8def\u6216\u5e76\u884c\u968f\u673a\u8bbf\u95ee\u673a\uff09\u4e2d\uff0c\u591a\u5bf9\u6570\u65f6\u95f4\u662f\u4e00\u79cd\u91cd\u8981\u7684\u53ef\u884c\u6027\u6982\u5ff5\u3002\u7136\u800c\uff0c\u5728\u91cf\u5b50\u8303\u5f0f\u4e2d\uff0c\u8fd9\u79cd\u53ef\u884c\u6027\u6982\u5ff5\u5c1a\u672a\u5728\u7f16\u7a0b\u8bed\u8a00\u5c42\u9762\u5f97\u5230\u5145\u5206\u8868\u5f81\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u4e00\u9636\u9012\u5f52\u8fc7\u7a0b\u7684\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u7a0b\u5e8f\u7f16\u8bd1\u4e3a\u591a\u5bf9\u6570\u6df1\u5ea6\u548c\u591a\u9879\u5f0f\u89c4\u6a21\u7684\u91cf\u5b50\u7535\u8def\u65cf\u7684\u7b56\u7565\u3002", "result": "\u8be5\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u80fd\u591f\u8ba1\u7b97 FBQPOLYLOG \u4e2d\u7684\u51fd\u6570\uff0c\u5e76\u4e14FBQPOLYLOG\u4e2d\u7684\u6bcf\u4e2a\u51fd\u6570\u90fd\u53ef\u4ee5\u7531\u8be5\u8bed\u8a00\u7684\u7a0b\u5e8f\u8ba1\u7b97\u3002\u6b64\u5916\uff0c\u8be5\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5c06\u7a0b\u5e8f\u7f16\u8bd1\u4e3a\u591a\u5bf9\u6570\u6df1\u5ea6\u548c\u591a\u9879\u5f0f\u89c4\u6a21\u7684\u91cf\u5b50\u7535\u8def\u7684\u7b56\u7565\uff0c\u5e76\u9a8c\u8bc1\u4e86 FBQPOLYLOG $\\subsetneq$ QNC \u7684\u5206\u79bb\u7ed3\u679c\u3002", "conclusion": "FBQPOLYLOG\uff08\u7531\u91cf\u5b50\u968f\u673a\u8bbf\u95ee\u56fe\u7075\u673a\u5728\u591a\u5bf9\u6570\u65f6\u95f4\u5185\u5b9e\u73b0\uff09\u7684\u57fa\u4e8e\u7f16\u7a0b\u8bed\u8a00\u7684\u8868\u5f81\u5f97\u5230\u4e86\u9996\u6b21\u5b9e\u73b0\uff0c\u5e76\u4e14 FBQPOLYLOG $\\subsetneq$ QNC\u3002"}}
{"id": "2507.14802", "categories": ["cs.DC", "cs.AI", "C.2.4; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.14802", "abs": "https://arxiv.org/abs/2507.14802", "authors": ["Ziming Dai", "Chao Qiu", "Fei Gao", "Yunfeng Zhao", "Xiaofei Wang"], "title": "ACME: Adaptive Customization of Large Models via Distributed Systems", "comment": "Accepted to IEEE ICDCS 2025. 11 pages, 13 figures", "summary": "Pre-trained Transformer-based large models have revolutionized personal\nvirtual assistants, but their deployment in cloud environments faces challenges\nrelated to data privacy and response latency. Deploying large models closer to\nthe data and users has become a key research area to address these issues.\nHowever, applying these models directly often entails significant difficulties,\nsuch as model mismatching, resource constraints, and energy inefficiency.\nAutomated design of customized models is necessary, but it faces three key\nchallenges, namely, the high cost of centralized model customization,\nimbalanced performance from user heterogeneity, and suboptimal performance from\ndata heterogeneity. In this paper, we propose ACME, an adaptive customization\napproach of Transformer-based large models via distributed systems. To avoid\nthe low cost-efficiency of centralized methods, ACME employs a bidirectional\nsingle-loop distributed system to progressively achieve fine-grained\ncollaborative model customization. In order to better match user heterogeneity,\nit begins by customizing the backbone generation and identifying the Pareto\nFront under model size constraints to ensure optimal resource utilization.\nSubsequently, it performs header generation and refines the model using data\ndistribution-based personalized architecture aggregation to match data\nheterogeneity. Evaluation on different datasets shows that ACME achieves\ncost-efficient models under model size constraints. Compared to centralized\nsystems, data transmission volume is reduced to 6 percent. Additionally, the\naverage accuracy improves by 10 percent compared to the baseline, with the\ntrade-off metrics increasing by nearly 30 percent.", "AI": {"tldr": "ACME\u662f\u4e00\u79cd\u521b\u65b0\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9a\u5236Transformer\u5927\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4e91\u90e8\u7f72\u4e2d\u7684\u6210\u672c\u3001\u9690\u79c1\u548c\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u4e91\u73af\u5883\u4e2d\u90e8\u7f72\u9884\u8bad\u7ec3Transformer\u5927\u6a21\u578b\u65f6\u9762\u4e34\u7684\u6570\u636e\u9690\u79c1\u548c\u54cd\u5e94\u5ef6\u8fdf\u6311\u6218\uff0c\u4ee5\u53ca\u76f4\u63a5\u5e94\u7528\u8fd9\u4e9b\u6a21\u578b\u65f6\u9047\u5230\u7684\u6a21\u578b\u4e0d\u5339\u914d\u3001\u8d44\u6e90\u9650\u5236\u548c\u80fd\u6e90\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\uff0c\u9700\u8981\u5bf9\u6a21\u578b\u8fdb\u884c\u5b9a\u5236\u5316\u8bbe\u8ba1\u3002\u7136\u800c\uff0c\u96c6\u4e2d\u7684\u6a21\u578b\u5b9a\u5236\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u7528\u6237\u548c\u6570\u636e\u7684\u5f02\u8d28\u6027\u5bfc\u81f4\u6027\u80fd\u4e0d\u5747\u8861\u548c\u6b21\u4f18\u3002", "method": "ACME\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u5b9a\u5236Transformer\u5927\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u91c7\u7528\u53cc\u5411\u5355\u56de\u8def\u5206\u5e03\u5f0f\u7cfb\u7edf\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u534f\u540c\u6a21\u578b\u5b9a\u5236\u3002\u9996\u5148\uff0c\u5728\u6a21\u578b\u5c3a\u5bf8\u7ea6\u675f\u4e0b\u5b9a\u5236\u4e3b\u5e72\u751f\u6210\u5e76\u8bc6\u522b\u5e15\u7d2f\u6258\u524d\u6cbf\u4ee5\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002\u7136\u540e\uff0c\u901a\u8fc7\u57fa\u4e8e\u6570\u636e\u5206\u5e03\u7684\u4e2a\u6027\u5316\u67b6\u6784\u805a\u5408\u8fdb\u884c\u5934\u90e8\u751f\u6210\u548c\u6a21\u578b\u7cbe\u70bc\uff0c\u4ee5\u5339\u914d\u6570\u636e\u5f02\u8d28\u6027\u3002", "result": "ACME\u5b9e\u73b0\u4e86\u6210\u672c\u6548\u76ca\uff0c\u5c06\u6570\u636e\u4f20\u8f93\u91cf\u51cf\u5c11\u52306%\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad810%\uff0c\u6743\u8861\u6307\u6807\u589e\u52a0\u8fd130%\u3002", "conclusion": "ACME\u901a\u8fc7\u5206\u5e03\u5f0f\u7cfb\u7edf\u5b9e\u73b0\u4e86Transformer\u5927\u6a21\u578b\u7684\u81ea\u9002\u5e94\u5b9a\u5236\uff0c\u5728\u6a21\u578b\u5c3a\u5bf8\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u6210\u672c\u6548\u76ca\uff0c\u51cf\u5c11\u4e866%\u7684\u6570\u636e\u4f20\u8f93\u91cf\uff0c\u5e76\u4f7f\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e8610%\uff0c\u800c\u6743\u8861\u6307\u6807\u589e\u52a0\u4e86\u8fd130%\u3002"}}
{"id": "2507.14455", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14455", "abs": "https://arxiv.org/abs/2507.14455", "authors": ["Chun-Ming Yang", "Pranav A. Bhounsule"], "title": "Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking", "comment": null, "summary": "Time-delay embedding is a technique that uses snapshots of state history over\ntime to build a linear state space model of a nonlinear smooth system. We\ndemonstrate that periodic non-smooth or hybrid system can also be modeled as a\nlinear state space system using this approach as long as its behavior is\nconsistent in modes and timings. We extended time-delay embeddings to generate\na linear model of two periodic hybrid systems: the bouncing pendulum and the\nsimplest walker with control inputs. This leads to a novel state history\naugmented linear quadratic regulator (LQR) which uses current and past state\nhistory for feedback control.", "AI": {"tldr": "\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u53ef\u7528\u4e8e\u5bf9\u5468\u671f\u6027\u6df7\u5408\u7cfb\u7edf\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u7528\u4e8e\u5f00\u53d1\u65b0\u7684\u53cd\u9988\u63a7\u5236\u5668\u3002", "motivation": "\u8bc1\u660e\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u4e0d\u4ec5\u53ef\u4ee5\u7528\u4e8e\u5efa\u7acb\u975e\u7ebf\u6027\u5e73\u6ed1\u7cfb\u7edf\u7684\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5efa\u7acb\u5468\u671f\u6027\u975e\u5149\u6ed1\u6216\u6df7\u5408\u7cfb\u7edf\u7684\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u6269\u5c55\u5230\u5468\u671f\u6027\u975e\u5149\u6ed1\u6216\u6df7\u5408\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4ee5\u6784\u5efa\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "result": "\u6210\u529f\u5730\u5c06\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u5e94\u7528\u4e8e\u4e24\u4e2a\u5468\u671f\u6027\u6df7\u5408\u7cfb\u7edf\u2014\u2014\u53cd\u5f39\u949f\u6446\u548c\u5e26\u63a7\u5236\u8f93\u5165\u7684\u7b80\u5355\u6b65\u884c\u8005\uff0c\u5e76\u751f\u6210\u4e86\u5b83\u4eec\u7684\u7ebf\u6027\u6a21\u578b\u3002\u57fa\u4e8e\u6b64\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u72b6\u6001\u5386\u53f2\u589e\u5f3a\u578b\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\uff08LQR\uff09\uff0c\u8be5\u8c03\u8282\u5668\u5229\u7528\u5f53\u524d\u548c\u8fc7\u53bb\u7684\u72b6\u6001\u5386\u53f2\u8fdb\u884c\u53cd\u9988\u63a7\u5236\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u4e0d\u4ec5\u53ef\u4ee5\u7528\u4e8e\u5efa\u7acb\u975e\u7ebf\u6027\u5e73\u6ed1\u7cfb\u7edf\u7684\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7\u6269\u5c55\u8be5\u6280\u672f\u6765\u751f\u6210\u5468\u671f\u6027\u6df7\u5408\u7cfb\u7edf\u7684\u7ebf\u6027\u6a21\u578b\uff0c\u4f8b\u5982\u53cd\u5f39\u949f\u6446\u548c\u5177\u6709\u63a7\u5236\u8f93\u5165\u7684\u7b80\u5355\u6b65\u884c\u8005\u3002"}}
{"id": "2507.14315", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14315", "abs": "https://arxiv.org/abs/2507.14315", "authors": ["Qiyu Xu", "Zhanxuan Hu", "Yu Duan", "Ercheng Pei", "Yonghang Tai"], "title": "A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention", "comment": null, "summary": "Generalized Category Discovery (GCD) aims to classify unlabeled data from\nboth known and unknown categories by leveraging knowledge from labeled known\ncategories. While existing methods have made notable progress, they often\noverlook a hidden stumbling block in GCD: distracted attention. Specifically,\nwhen processing unlabeled data, models tend to focus not only on key objects in\nthe image but also on task-irrelevant background regions, leading to suboptimal\nfeature extraction. To remove this stumbling block, we propose Attention\nFocusing (AF), an adaptive mechanism designed to sharpen the model's focus by\npruning non-informative tokens. AF consists of two simple yet effective\ncomponents: Token Importance Measurement (TIME) and Token Adaptive Pruning\n(TAP), working in a cascade. TIME quantifies token importance across multiple\nscales, while TAP prunes non-informative tokens by utilizing the multi-scale\nimportance scores provided by TIME. AF is a lightweight, plug-and-play module\nthat integrates seamlessly into existing GCD methods with minimal computational\noverhead. When incorporated into one prominent GCD method, SimGCD, AF achieves\nup to 15.4% performance improvement over the baseline with minimal\ncomputational overhead. The implementation code is provided in\nhttps://github.com/Afleve/AFGCD.", "AI": {"tldr": "AF\u662f\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u526a\u679d\u975e\u4fe1\u606f\u6027\u4ee4\u724c\u6765\u89e3\u51b3GCD\u4e2d\u7684\u2018\u6ce8\u610f\u529b\u5206\u6563\u2019\u95ee\u9898\uff0c\u80fd\u663e\u8457\u63d0\u5347\u73b0\u6709GCD\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684GCD\u65b9\u6cd5\u5728\u5904\u7406\u65e0\u6807\u7b7e\u6570\u636e\u65f6\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u5173\u6ce8\u4efb\u52a1\u65e0\u5173\u7684\u80cc\u666f\u533a\u57df\uff0c\u5bfc\u81f4\u7279\u5f81\u63d0\u53d6\u4e0d\u4f73\uff0c\u5373\u2018\u6ce8\u610f\u529b\u5206\u6563\u2019\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51faAF\u673a\u5236\u6765\u63d0\u5347\u6a21\u578b\u6ce8\u610f\u529b\u3002", "method": "AF\u5305\u62ec\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u4ee4\u724c\u91cd\u8981\u6027\u5ea6\u91cf\uff08TIME\uff09\u548c\u4ee4\u724c\u81ea\u9002\u5e94\u526a\u679d\uff08TAP\uff09\u3002TIME\u5728\u591a\u4e2a\u5c3a\u5ea6\u4e0a\u91cf\u5316\u4ee4\u724c\u7684\u91cd\u8981\u6027\uff0c\u800cTAP\u5219\u5229\u7528TIME\u63d0\u4f9b\u7684\u591a\u5c3a\u5ea6\u91cd\u8981\u6027\u5206\u6570\u6765\u526a\u679d\u975e\u4fe1\u606f\u6027\u4ee4\u724c\u3002", "result": "AF\u5728SimGCD\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe15.4%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "AF\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u3001\u5373\u63d2\u5373\u7528\u7684\u6a21\u5757\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684GCD\u65b9\u6cd5\u4e2d\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002\u4e0eSimGCD\u7ed3\u5408\u4f7f\u7528\u65f6\uff0cAF\u5728\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u6bd4\u57fa\u7ebf\u63d0\u9ad8\u4e8615.4%\u3002"}}
{"id": "2507.14306", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.14306", "abs": "https://arxiv.org/abs/2507.14306", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "title": "Manimator: Transforming Research Papers into Visual Explanations", "comment": null, "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "AI": {"tldr": "Manimator\u662f\u4e00\u4e2a\u5f00\u6e90\u7cfb\u7edf\uff0c\u4f7f\u7528LLM\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3aManim\u52a8\u753b\uff0c\u4ee5\u7b80\u5316STEM\u5185\u5bb9\u7684\u89c6\u89c9\u89e3\u91ca\u521b\u5efa\u8fc7\u7a0b\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u52a8\u6001\u53ef\u89c6\u5316\u4ee5\u589e\u5f3a\u5bf9\u79d1\u5b66\u548c\u6570\u5b66\u6982\u5ff5\u7684\u7406\u89e3\u65e2\u8017\u65f6\uff0c\u53c8\u9700\u8981\u4e13\u95e8\u7684\u77e5\u8bc6\u548c\u6280\u80fd\u3002\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "Manimator\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u4f7f\u7528Manim\u5f15\u64ce\u7684\u89e3\u91ca\u6027\u52a8\u753b\u3002\u5176\u5de5\u4f5c\u6d41\u7a0b\u5305\u62ec\uff1a1. LLM\u89e3\u6790\u8f93\u5165\u6587\u672c\u6216\u7814\u7a76\u8bba\u6587PDF\uff0c\u751f\u6210\u7ed3\u6784\u5316\u7684\u573a\u666f\u63cf\u8ff0\uff08\u5305\u62ec\u5173\u952e\u6982\u5ff5\u3001\u6570\u5b66\u516c\u5f0f\u548c\u89c6\u89c9\u5143\u7d20\uff09\u30022. \u53e6\u4e00\u4e2aLLM\u5c06\u6b64\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Manim Python\u4ee3\u7801\u3002", "result": "Manimator\u7cfb\u7edf\u80fd\u591f\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u89e3\u91ca\u6027\u52a8\u753b\u3002", "conclusion": "Manimator\u6709\u6f5c\u529b\u6210\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u6559\u80b2\u5de5\u5177\uff0c\u80fd\u591f\u5feb\u901f\u4e3a\u590d\u6742\u7684STEM\u4e3b\u9898\u521b\u5efa\u5f15\u4eba\u5165\u80dc\u7684\u89c6\u89c9\u89e3\u91ca\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6559\u80b2\u5185\u5bb9\u7684\u666e\u53ca\u5316\u3002"}}
{"id": "2507.14365", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14365", "abs": "https://arxiv.org/abs/2507.14365", "authors": ["Matthew Copus", "Ezio Iacocca"], "title": "Dynamic annihilation pathways of magnetic skyrmions", "comment": null, "summary": "The investigation of magnetic solitons often relies on numerical modeling to\ndetermine key features such as stability, annihilation, nucleation, and motion.\nHowever, as soliton sizes approach atomic length scales, the accuracy of these\npredictions become increasingly sensitive to the details of the numerical\nmodel. Here, we study the annihilation of two-dimensional magnetic skyrmions\nusing a pseudospectral approach and compare its performance to that of\nconventional micromagnetic simulations. A central distinction between the\nmodels lies in their treatment of the exchange interaction, which governs the\nmagnon dispersion relation and plays a crucial role to balance the uniaxial\nanisotropy to stabilise skyrmions. We demonstrate that both the choice of model\nand spatial discretisation significantly influence the skyrmion dynamics and\nthe magnetic field required for annihilation. The pseudospectral model provides\na consistent description across length scales and captures complex behaviours\nsuch as skyrmion breathing on its path to annihilation. Our results have direct\nimplications in the state-of-the-art modeling of skyrmions and other\ntwo-dimensional textures and will impact the modeling of three-dimensional\ntextures such as hopfions.", "AI": {"tldr": "\u4f2a\u8c31\u65b9\u6cd5\u6bd4\u4f20\u7edf\u5fae\u78c1\u6a21\u62df\u66f4\u9002\u5408\u6a21\u62df\u539f\u5b50\u5c3a\u5ea6\u78c1\u5b64\u5b50\u52a8\u529b\u5b66\u3002", "motivation": "\u4f20\u7edf\u7684\u6570\u503c\u6a21\u62df\u65b9\u6cd5\u5728\u5904\u7406\u539f\u5b50\u5c3a\u5ea6\u7684\u78c1\u5b64\u5b50\u65f6\u7cbe\u5ea6\u4f1a\u53d7\u5230\u6a21\u578b\u7ec6\u8282\u7684\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6a21\u578b\u6765\u7814\u7a76\u78c1\u5b64\u5b50\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u4f2a\u8c31\u65b9\u6cd5\u548c\u4f20\u7edf\u7684\u5fae\u78c1\u6a21\u62df\u65b9\u6cd5\uff0c\u7814\u7a76\u4e8c\u7ef4\u78c1\u6027\u65af\u683c\u660e\u5b50\u7684\u6e6e\u706d\u52a8\u529b\u5b66\uff0c\u5e76\u5bf9\u6bd4\u4e24\u8005\u5728\u5904\u7406\u4ea4\u6362\u76f8\u4e92\u4f5c\u7528\u3001\u6676\u683c\u5316\u3001\u7a7a\u95f4\u79bb\u6563\u5316\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u548c\u5f71\u54cd\u3002", "result": "\u4f2a\u8c31\u65b9\u6cd5\u5728\u6a21\u62df\u65af\u683c\u660e\u5b50\u6e6e\u706d\u65f6\uff0c\u80fd\u8de8\u8d8a\u4e0d\u540c\u957f\u5ea6\u5c3a\u5ea6\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u5e76\u80fd\u6355\u6349\u5230\u65af\u683c\u660e\u5b50\u547c\u5438\u7b49\u590d\u6742\u884c\u4e3a\uff0c\u4e14\u6240\u9700\u7684\u78c1\u573a\u4e5f\u4e0e\u5fae\u78c1\u6a21\u62df\u6709\u6240\u4e0d\u540c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u8de8\u5c3a\u5ea6\u6a21\u62df\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u4e9a\u539f\u5b50\u5c3a\u5ea6\u7684\u78c1\u5b64\u5b50\uff0c\u4f2a\u8c31\u65b9\u6cd5\u6bd4\u4f20\u7edf\u7684\u5fae\u78c1\u6a21\u62df\u80fd\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u5176\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u5e76\u80fd\u6355\u6349\u5230\u8bf8\u5982\u547c\u5438\u7b49\u590d\u6742\u73b0\u8c61\uff0c\u8fd9\u5bf9\u4e8e\u672a\u6765\u78c1\u6027\u6750\u6599\u548c\u5668\u4ef6\u7684\u5efa\u6a21\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.15815", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15815", "abs": "https://arxiv.org/abs/2507.15815", "authors": ["Seth Karten", "Wenzhe Li", "Zihan Ding", "Samuel Kleiner", "Yu Bai", "Chi Jin"], "title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra", "comment": "27 pages, 6 figures, Code:\n  https://github.com/sethkarten/LLM-Economist", "summary": "We present the LLM Economist, a novel framework that uses agent-based\nmodeling to design and assess economic policies in strategic environments with\nhierarchical decision-making. At the lower level, bounded rational worker\nagents -- instantiated as persona-conditioned prompts sampled from U.S.\nCensus-calibrated income and demographic statistics -- choose labor supply to\nmaximize text-based utility functions learned in-context. At the upper level, a\nplanner agent employs in-context reinforcement learning to propose\npiecewise-linear marginal tax schedules anchored to the current U.S. federal\nbrackets. This construction endows economic simulacra with three capabilities\nrequisite for credible fiscal experimentation: (i) optimization of\nheterogeneous utilities, (ii) principled generation of large, demographically\nrealistic agent populations, and (iii) mechanism design -- the ultimate nudging\nproblem -- expressed entirely in natural language. Experiments with populations\nof up to one hundred interacting agents show that the planner converges near\nStackelberg equilibria that improve aggregate social welfare relative to Saez\nsolutions, while a periodic, persona-level voting procedure furthers these\ngains under decentralized governance. These results demonstrate that large\nlanguage model-based agents can jointly model, simulate, and govern complex\neconomic systems, providing a tractable test bed for policy evaluation at the\nsocietal scale to help build better civilizations.", "AI": {"tldr": "LLM\u7ecf\u6d4e\u5b66\u6846\u67b6\u5229\u7528\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u5efa\u6a21\uff0c\u8ba9\u5de5\u4eba\u667a\u80fd\u4f53\u548c\u89c4\u5212\u8005\u667a\u80fd\u4f53\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u4ea4\u4e92\uff0c\u4ee5\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8\u793e\u4f1a\u798f\u5229\u548c\u652f\u6301\u5206\u6563\u6cbb\u7406\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u5206\u5c42\u51b3\u7b56\u7684\u6218\u7565\u73af\u5883\u4e2d\uff0c\u4ee5\u89e3\u51b3\u7ecf\u6d4e\u6a21\u62df\u548c\u653f\u7b56\u8bc4\u4f30\u7684\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86LLM\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u5efa\u6a21\u6765\u8bbe\u8ba1\u548c\u8bc4\u4f30\u6218\u7565\u73af\u5883\u4e2d\u7684\u7ecf\u6d4e\u653f\u7b56\uff0c\u5176\u4e2d\u5305\u542b\u5206\u5c42\u51b3\u7b56\u3002\u5728\u8f83\u4f4e\u5c42\u7ea7\uff0c\u6709\u754c\u7406\u6027\u5de5\u4eba\u667a\u80fd\u4f53\uff08\u8868\u73b0\u4e3a\u6e90\u81ea\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u6821\u51c6\u7684\u6536\u5165\u548c\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u7684\u4e2a\u4eba\u6761\u4ef6\u63d0\u793a\uff09\u9009\u62e9\u52b3\u52a8\u4f9b\u7ed9\u4ee5\u6700\u5927\u5316\u5728\u4e0a\u4e0b\u6587\u4e2d\u5b66\u4e60\u5230\u7684\u57fa\u4e8e\u6587\u672c\u7684\u6548\u7528\u51fd\u6570\u3002\u5728\u4e0a\u5c42\u7ea7\uff0c\u89c4\u5212\u8005\u667a\u80fd\u4f53\u91c7\u7528\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u51fa\u4ee5\u5f53\u524d\u7f8e\u56fd\u8054\u90a6\u7a0e\u7387\u4e3a\u57fa\u51c6\u7684 \uac83\uc785\ub2c8\ub2e4\u3002\u7ebf\u6027\u8fb9\u9645\u7a0e\u6536\u8ba1\u5212\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u652f\u6301\u5f02\u8d28\u6027\u6548\u7528\u4f18\u5316\u3001\u751f\u6210\u5927\u89c4\u6a21\u3001\u4eba\u53e3\u7edf\u8ba1\u5b66\u4e0a\u771f\u5b9e\u7684\u667a\u80fd\u4f53\u7fa4\u4f53\uff0c\u5e76\u4ee5\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u673a\u5236\u8bbe\u8ba1\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u89c4\u5212\u8005\u667a\u80fd\u4f53\u63a5\u8fd1\u65af\u5854\u514b\u5c14\u4f2f\u683c\u5747\u8861\uff0c\u76f8\u6bd4Saez\u89e3\u51b3\u65b9\u6848\u63d0\u9ad8\u4e86\u603b\u793e\u4f1a\u798f\u5229\uff0c\u800c\u5468\u671f\u6027\u7684\u3001\u4e2a\u4eba\u5c42\u9762\u7684\u6295\u7968\u7a0b\u5e8f\u5728\u5206\u6563\u6cbb\u7406\u4e0b\u8fdb\u4e00\u6b65\u589e\u52a0\u4e86\u8fd9\u4e9b\u6536\u76ca\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u53ef\u4ee5\u5171\u540c\u5efa\u6a21\u3001\u6a21\u62df\u548c\u6cbb\u7406\u590d\u6742\u7684\u7ecf\u6d4e\u7cfb\u7edf\uff0c\u4e3a\u5927\u89c4\u6a21\u7684\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u8bd5\u9a8c\u53f0\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u66f4\u7f8e\u597d\u7684\u6587\u660e\u3002"}}
{"id": "2507.14175", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.14175", "abs": "https://arxiv.org/abs/2507.14175", "authors": ["Youcef Barkat", "Dylan Hamitouche", "Deven Parekh", "Ivy Guo", "David Benrimoh"], "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data", "comment": null, "summary": "Background: Mental illnesses such as depression and anxiety require improved\nmethods for early detection and personalized intervention. Traditional\npredictive models often rely on unimodal data or early fusion strategies that\nfail to capture the complex, multimodal nature of psychiatric data. Advanced\nintegration techniques, such as intermediate (latent space) fusion, may offer\nbetter accuracy and clinical utility. Methods: Using data from the BRIGHTEN\nclinical trial, we evaluated intermediate (latent space) fusion for predicting\ndaily depressive symptoms (PHQ-2 scores). We compared early fusion implemented\nwith a Random Forest (RF) model and intermediate fusion implemented via a\nCombined Model (CM) using autoencoders and a neural network. The dataset\nincluded behavioral (smartphone-based), demographic, and clinical features.\nExperiments were conducted across multiple temporal splits and data stream\ncombinations. Performance was evaluated using mean squared error (MSE) and\ncoefficient of determination (R2). Results: The CM outperformed both RF and\nLinear Regression (LR) baselines across all setups, achieving lower MSE (0.4985\nvs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed\nsigns of overfitting, with a large gap between training and test performance,\nwhile the CM maintained consistent generalization. Performance was best when\nintegrating all data modalities in the CM (in contradistinction to RF),\nunderscoring the value of latent space fusion for capturing non-linear\ninteractions in complex psychiatric datasets. Conclusion: Latent space fusion\noffers a robust alternative to traditional fusion methods for prediction with\nmultimodal mental health data. Future work should explore model\ninterpretability and individual-level prediction for clinical deployment.", "AI": {"tldr": "\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u5728\u9884\u6d4b\u591a\u6a21\u6001\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u65e9\u671f\u878d\u5408\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u6570\u636e\u95f4\u7684\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u5e76\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5fc3\u7406\u75be\u75c5\uff08\u5982\u6291\u90c1\u548c\u7126\u8651\uff09\u9700\u8981\u6539\u8fdb\u65e9\u671f\u68c0\u6d4b\u548c\u4e2a\u6027\u5316\u5e72\u9884\u7684\u65b9\u6cd5\u3002\u4f20\u7edf\u7684\u9884\u6d4b\u6a21\u578b\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5355\u4e00\u6a21\u6001\u6570\u636e\u6216\u65e9\u671f\u878d\u5408\u7b56\u7565\uff0c\u672a\u80fd\u6355\u6349\u7cbe\u795e\u75c5\u5b66\u6570\u636e\u7684\u590d\u6742\u591a\u6a21\u6001\u6027\u8d28\u3002\u800c\u4e2d\u95f4\uff08\u6f5c\u5728\u7a7a\u95f4\uff09\u878d\u5408\u7b49\u9ad8\u7ea7\u96c6\u6210\u6280\u672f\u53ef\u80fd\u63d0\u4f9b\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u6548\u7528\u3002", "method": "\u5229\u7528BRIGHTEN\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\uff0c\u8bc4\u4f30\u4e86\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u7ec4\u5408\u6a21\u578b\uff08CM\uff09\u5b9e\u73b0\u7684\u4e2d\u95f4\uff08\u6f5c\u5728\u7a7a\u95f4\uff09\u878d\u5408\uff0c\u7528\u4e8e\u9884\u6d4b\u6bcf\u65e5\u6291\u90c1\u75c7\u72b6\uff08PHQ-2\u8bc4\u5206\uff09\uff0c\u5e76\u5c06\u5176\u4e0e\u968f\u673a\u68ee\u6797\uff08RF\uff09\u7684\u65e9\u671f\u878d\u5408\u65b9\u6cd5\u548c\u7ebf\u6027\u56de\u5f52\uff08LR\uff09\u57fa\u7ebf\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u5b9e\u9a8c\u5728\u591a\u4e2a\u65f6\u95f4\u5206\u5272\u548c\u6570\u636e\u6d41\u7ec4\u5408\u4e0a\u8fdb\u884c\uff0c\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u548c\u51b3\u5b9a\u7cfb\u6570\uff08R2\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ec4\u5408\u6a21\u578b\uff08CM\uff09\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8e\u968f\u673a\u68ee\u6797\uff08RF\uff09\u548c\u7ebf\u6027\u56de\u5f52\uff08LR\uff09\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u5747\u65b9\u8bef\u5dee\uff080.4985 vs. 0.5305\uff09\u548c\u66f4\u9ad8\u7684\u51b3\u5b9a\u7cfb\u6570\uff080.4695 vs. 0.4356\uff09\u3002RF\u6a21\u578b\u8868\u73b0\u51fa\u8fc7\u62df\u5408\u8ff9\u8c61\uff0c\u800cCM\u4fdd\u6301\u4e86\u6301\u7eed\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5728CM\u4e2d\u96c6\u6210\u6240\u6709\u6570\u636e\u6a21\u5f0f\uff08\u4e0eRF\u76f8\u53cd\uff09\u65f6\uff0c\u6027\u80fd\u6700\u4f73\uff0c\u8fd9\u51f8\u663e\u4e86\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u5728\u6355\u6349\u590d\u6742\u7cbe\u795e\u75c5\u5b66\u6570\u636e\u4e2d\u7684\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u65b9\u9762\u7684\u4ef7\u503c\u3002", "conclusion": "\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u4e3a\u9884\u6d4b\u591a\u6a21\u6001\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u66f4\u9c81\u7684\u65b9\u6cd5\uff0c\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u63a2\u7d22\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u4e2a\u4f53\u6c34\u5e73\u9884\u6d4b\u4ee5\u7528\u4e8e\u4e34\u5e8a\u90e8\u7f72\u3002"}}
{"id": "2507.14377", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14377", "abs": "https://arxiv.org/abs/2507.14377", "authors": ["Tyler D. Dole\u017eal", "Rodrigo Freitas", "Ju Li"], "title": "Segregation and Ordering of Light Interstitials (B, C, H, and N) in Cr-Ni Alloys: Implications for Grain Boundary Stability in Superalloy Design", "comment": null, "summary": "The segregation and ordering behavior of light interstitials (B, C, and N) in\nCr30-Ni is examined, as these elements are critical for grain boundary\nstability and high-temperature mechanical performance in Ni-based superalloys.\nUsing Monte Carlo simulations, we identify the chemical and structural\npreferences of these interstitials in both bulk and grain boundary (GB)\nenvironments, aligning with experimental segregation and precipitation trends.\nBoron strongly prefers GBs over the bulk, where it enhances GB cohesion and\nstabilizes the GB structure. Uniquely, boron induces a structural\ntransformation at higher concentrations, hinting at the formation of serrated\nGBs where boron content is high, which improves high-temperature mechanical\nperformance. Carbon and nitrogen form carbide and nitride motifs and exhibit\nlimited GB solubility, reinforcing their precipitation tendencies. In support\nof ongoing hydrogen embrittlement mitigation strategies, we also examined\nhydrogen behavior. Hydrogen demonstrated chemical stability in the Cr-Ni GB\nzone, suggesting it may preferentially migrate inward along Cr- and Ni-rich GBs\nwhile avoiding Mo-enriched regions, further supporting Mo's role in mitigating\nembrittlement. These findings suggest that Mo-containing borides may serve as\neffective barriers against hydrogen-induced degradation by inhibiting H ingress\nand stabilizing GB cohesion. By elucidating the chemical and structural\npreferences of these light interstitials, this work provides a robust\ncomputational framework for guiding superalloy design toward improved\nhigh-temperature grain boundary stability, resistance to hydrogen\nembrittlement, and controlled chemical ordering.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff0c\u7814\u7a76\u4e86 B, C, N, H \u5728 Cr-Ni \u4e2d\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u787c\u80fd\u7a33\u5b9a\u6676\u754c\uff0c\u78b3\u6c2e\u6613\u5f62\u6210\u6c89\u6dc0\uff0c\u6c22\u504f\u597d\u6cbf\u5bcc Cr\u3001Ni \u7684\u6676\u754c\u8fc1\u79fb\u3002\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u7a33\u5b9a\u7684\u8d85\u7ea7\u5408\u91d1\u3002", "motivation": "\u7814\u7a76 B, C, N, H \u5728 Cr-Ni \u4e2d\u7684\u504f\u6790\u548c\u6709\u5e8f\u884c\u4e3a\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u5143\u7d20\u5bf9\u954d\u57fa\u9ad8\u6e29\u5408\u91d1\u7684\u6676\u754c\u7a33\u5b9a\u6027\u53ca\u9ad8\u6e29\u529b\u5b66\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u4e3a\u51cf\u7f13\u6c22\u8106\u63d0\u4f9b\u7b56\u7565\u3002", "method": "\u91c7\u7528\u8499\u7279\u5361\u6d1b\u6a21\u62df\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86 B, C, N, H \u5728 Cr-Ni \u7684\u4f53\u76f8\u548c\u6676\u754c\u73af\u5883\u4e2d\u7684\u5316\u5b66\u548c\u7ed3\u6784\u504f\u597d\u3002", "result": "\u787c\u5f3a\u70c8\u504f\u597d\u6676\u754c\uff0c\u63d0\u9ad8\u6676\u754c\u5185\u805a\u529b\u5e76\u7a33\u5b9a\u6676\u754c\u7ed3\u6784\uff0c\u9ad8\u6d53\u5ea6\u4e0b\u4f1a\u8bf1\u5bfc\u7ed3\u6784\u8f6c\u53d8\uff0c\u5f62\u6210\u952f\u9f7f\u72b6\u6676\u754c\uff1b\u78b3\u548c\u6c2e\u5f62\u6210\u78b3\u5316\u7269\u548c\u6c2e\u5316\u7269\uff0c\u5728\u6676\u754c\u6eb6\u89e3\u5ea6\u6709\u9650\uff1b\u6c22\u5728 Cr-Ni \u6676\u754c\u533a\u5177\u6709\u5316\u5b66\u7a33\u5b9a\u6027\uff0c\u5e76\u53ef\u80fd\u6cbf\u5bcc Cr \u548c Ni \u7684\u6676\u754c\u5411\u5185\u8fc1\u79fb\uff0c\u800c\u907f\u5f00\u5bcc Mo \u7684\u533a\u57df\uff1b\u542b\u94bc\u7684\u787c\u5316\u7269\u53ef\u4f5c\u4e3a\u6709\u6548\u5c4f\u969c\uff0c\u6291\u5236\u6c22\u4fb5\u8680\u5e76\u7a33\u5b9a\u6676\u754c\u5185\u805a\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff0c\u9610\u660e\u4e86 B, C, N, H \u5728 Cr-Ni \u4e2d\u7684\u504f\u6790\u548c\u6709\u5e8f\u884c\u4e3a\uff0c\u4e3a\u8d85\u7ea7\u5408\u91d1\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u9ad8\u6e29\u6676\u754c\u7a33\u5b9a\u6027\u3001\u6297\u6c22\u8106\u6027\u4ee5\u53ca\u5316\u5b66\u6709\u5e8f\u6027\u3002"}}
{"id": "2507.14409", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14409", "abs": "https://arxiv.org/abs/2507.14409", "authors": ["Max L. Gardenswartz", "Brandon C. Fallin", "Cristian F. Nino", "Warren E. Dixon"], "title": "Collaborative Indirect Influencing and Control on Graphs using Graph Neural Networks", "comment": "arXiv admin note: substantial text overlap with arXiv:2503.15360", "summary": "This paper presents a novel approach to solving the indirect influence\nproblem in networked systems, in which cooperative nodes must regulate a target\nnode with uncertain dynamics to follow a desired trajectory. We leverage the\nmessage-passing structure of a graph neural network (GNN), allowing nodes to\ncollectively learn the unknown target dynamics in real time. We develop a novel\nGNN-based backstepping control strategy with formal stability guarantees\nderived from a Lyapunov-based analysis. Numerical simulations are included to\ndemonstrate the performance of the developed controller.", "AI": {"tldr": "This paper introduces a new GNN-based control method to manage systems where multiple nodes influence a central target node with unknown behavior, ensuring stability and successful trajectory tracking.", "motivation": "To address the indirect influence problem in networked systems where cooperative nodes need to regulate a target node with uncertain dynamics to follow a desired trajectory.", "method": "The paper uses a graph neural network (GNN) with a message-passing structure to learn unknown target dynamics in real time. A GNN-based backstepping control strategy is developed, with stability guarantees based on Lyapunov analysis.", "result": "The developed controller, based on a GNN-backstepping strategy, shows effective performance in simulations for regulating a target node with uncertain dynamics.", "conclusion": "The paper presents a novel GNN-based backstepping control strategy for indirect influence problems in networked systems, demonstrating its effectiveness through numerical simulations and providing formal stability guarantees."}}
{"id": "2507.14370", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14370", "abs": "https://arxiv.org/abs/2507.14370", "authors": ["Jonas T. Anderson", "Andrew Connelly"], "title": "Affine Equivalence in the Clifford Hierarchy", "comment": "17 pages, comments welcome", "summary": "In this paper we prove a collection of results on the structure of\npermutations in the Clifford Hierarchy. First, we leverage results from the\ncryptography literature on affine equivalence classes of 4-bit permutations\nwhich we use to find all 4-qubit permutations in the Clifford Hierarchy. We\nthen use the classification of 4-qubit permutations and previous results on the\nstructure of diagonal gates in the Clifford Hierarchy to prove that all 4-qubit\ngates in the third level of the Clifford Hierarchy are semi-Clifford. Finally,\nwe introduce the formalism of cycle structures to permutations in the Clifford\nHierarchy and prove a general structure theorem about them. We also classify\nmany small cycle structures up to affine equivalence. Interestingly, this\nclassification is independent of the number of qubits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u6392\u5217\uff0c\u7279\u522b\u662f4\u8111\u8c61\u6392\u5217\u3002\u5b83\u8868\u660e\u8fd9\u4e9b\u6392\u5217\u662f\u534a\u514b\u5229\u798f\u5fb7\u7684\uff0c\u5e76\u5f15\u5165\u4e86\u5468\u671f\u7ed3\u6784\u7684\u6982\u5ff5\u6765\u66f4\u597d\u5730\u7406\u89e3\u5b83\u4eec\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u662f\u7814\u7a76\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u6392\u5217\u7684\u7ed3\u6784\uff0c\u7279\u522b\u662f\u91cd\u70b9\u5173\u6ce84\u8111\u8c61\u6392\u5217\uff0c\u5e76\u63ed\u793a\u5176\u4eff\u5c04\u7b49\u4ef7\u7c7b\u3001\u5468\u671f\u7ed3\u6784\u4ee5\u53ca\u5b83\u4eec\u5728\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u5c42\u6570\u3002", "method": "\u8be5\u8bba\u6587\u5229\u7528\u5bc6\u7801\u5b66\u6587\u732e\u4e2d\u5173\u4e8e4\u4f4d\u6392\u5217\u7684\u4eff\u5c04\u7b49\u4ef7\u7c7b\u7684\u7ed3\u679c\uff0c\u5bf9\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u6240\u67094\u8111\u8c61\u6392\u5217\u8fdb\u884c\u4e86\u5206\u7c7b\u3002\u7136\u540e\uff0c\u5229\u75284\u8111\u8c61\u6392\u5217\u7684\u5206\u7c7b\u548c\u5173\u4e8e\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u5bf9\u89d2\u95e8\u7ed3\u6784\u7684\u5148\u524d\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u7b2c\u4e09\u5c42\u4e2d\u7684\u6240\u67094\u8111\u8c61\u95e8\u90fd\u662f\u534a\u514b\u5229\u798f\u5fb7\u7684\u3002", "result": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u6240\u67094\u8111\u8c61\u6392\u5217\u90fd\u662f\u534a\u514b\u5229\u798f\u5fb7\u7684\uff0c\u5e76\u5f15\u5165\u4e86\u5468\u671f\u7ed3\u6784\u7684\u6982\u5ff5\u6765\u63cf\u8ff0\u8fd9\u4e9b\u6392\u5217\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u5b83\u4eec\u7684\u901a\u7528\u7ed3\u6784\u5b9a\u7406\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u7ed3\u8bba\u662f\uff0c\u7b2c\u56db\u8111\u8c61\u7684\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u6240\u6709\u95e8\u90fd\u662f\u534a\u514b\u5229\u798f\u5fb7\u7684\uff0c\u5e76\u4e14\u5f15\u5165\u4e86\u514b\u5229\u798f\u5fb7\u5c42\u7ea7\u4e2d\u7684\u6392\u5217\u7684\u5468\u671f\u7ed3\u6784\u5f62\u5f0f\u5316\uff0c\u5e76\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u901a\u7528\u7ed3\u6784\u5b9a\u7406\u3002"}}
{"id": "2507.14214", "categories": ["cs.CL", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14214", "abs": "https://arxiv.org/abs/2507.14214", "authors": ["Rui Zhao", "Vladyslav Melnychuk", "Jun Zhao", "Jesse Wright", "Nigel Shadbolt"], "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale", "comment": null, "summary": "In modern times, people have numerous online accounts, but they rarely read\nthe Terms of Service or Privacy Policy of those sites despite claiming\notherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that\nassists users with personalized privacy policy analysis. PoliAnalyzer uses\nNatural Language Processing (NLP) to extract formal representations of data\nusage practices from policy texts. In favor of deterministic, logical inference\nis applied to compare user preferences with the formal privacy policy\nrepresentation and produce a compliance report. To achieve this, we extend an\nexisting formal Data Terms of Use policy language to model privacy policies as\napp policies and user preferences as data policies. In our evaluation using our\nenriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated\nhigh accuracy in identifying relevant data usage practices, achieving F1-score\nof 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can\nmodel diverse user data-sharing preferences, derived from prior research as 23\nuser profiles, and perform compliance analysis against the top 100 most-visited\nwebsites. This analysis revealed that, on average, 95.2% of a privacy policy's\nsegments do not conflict with the analyzed user preferences, enabling users to\nconcentrate on understanding the 4.8% (636 / 13205) that violates preferences,\nsignificantly reducing cognitive burden. Further, we identified common\npractices in privacy policies that violate user expectations - such as the\nsharing of location data with 3rd parties. This paper demonstrates that\nPoliAnalyzer can support automated personalized privacy policy analysis at\nscale using off-the-shelf NLP tools. This sheds light on a pathway to help\nindividuals regain control over their data and encourage societal discussions\non platform data practices to promote a fairer power dynamic.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15186", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.15186", "abs": "https://arxiv.org/abs/2507.15186", "authors": ["Dmitry Brodsky", "Benjamin Watson"], "title": "Model Simplification through refinement", "comment": null, "summary": "As modeling and visualization applications proliferate, there arises a need\nto simplify large polygonal models at interactive rates. Unfortunately existing\npolygon mesh simplification algorithms are not well suited for this task\nbecause they are either too slow (requiring the simplified model to be\npre-computed) or produce models that are too poor in quality. These\nshortcomings become particularly acute when models are extremely large. We\npresent an algorithm suitable for simplification of large models at interactive\nspeeds. The algorithm is fast and can guarantee displayable results within a\ngiven time limit. Results also have good quality. Inspired by splitting\nalgorithms from vector quantization literature, we simplify models in reverse,\nbeginning with an extremely coarse approximation and refining it.\nApproximations of surface curvature guide the simplification process.\nPreviously produced simplifications can be further refined by using them as\ninput to the algorithm.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u73b0\u6709\u7b80\u5316\u7b97\u6cd5\u901f\u5ea6\u6162\u6216\u8d28\u91cf\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7b80\u5316\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u4ece\u7c97\u5230\u7cbe\uff0c\u5229\u7528\u66f2\u9762\u66f2\u7387\u8fdb\u884c\u4f18\u5316\uff0c\u901f\u5ea6\u5feb\u4e14\u6548\u679c\u597d\u3002", "motivation": "\u968f\u7740\u5efa\u6a21\u548c\u53ef\u89c6\u5316\u5e94\u7528\u7684\u6fc0\u589e\uff0c\u9700\u8981\u6709\u80fd\u591f\u4ee5\u4ea4\u4e92\u901f\u7387\u7b80\u5316\u5927\u578b\u591a\u8fb9\u5f62\u6a21\u578b\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u591a\u8fb9\u5f62\u7f51\u683c\u7b80\u5316\u7b97\u6cd5\u8981\u4e48\u592a\u6162\uff08\u9700\u8981\u9884\u5148\u8ba1\u7b97\u7b80\u5316\u6a21\u578b\uff09\uff0c\u8981\u4e48\u751f\u6210\u7684\u6a21\u578b\u8d28\u91cf\u592a\u5dee\uff0c\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u6781\u5927\u578b\u6a21\u578b\u65f6\u3002", "method": "\u8be5\u7b97\u6cd5\u4ece\u5411\u91cf\u91cf\u5316\u7b97\u6cd5\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u901a\u8fc7\u53cd\u5411\u64cd\u4f5c\uff0c\u4ece\u4e00\u4e2a\u975e\u5e38\u7c97\u7cd9\u7684\u8fd1\u4f3c\u6a21\u578b\u5f00\u59cb\uff0c\u5e76\u9010\u6b65\u5bf9\u5176\u8fdb\u884c\u7ec6\u5316\u3002\u66f2\u9762\u66f2\u7387\u88ab\u7528\u6765\u6307\u5bfc\u7b80\u5316\u8fc7\u7a0b\u3002\u5148\u524d\u751f\u6210\u7684\u7b80\u5316\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u8be5\u7b97\u6cd5\u7684\u8f93\u5165\uff0c\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u8be5\u7b97\u6cd5\u4e0d\u4ec5\u901f\u5ea6\u5feb\uff0c\u80fd\u5728\u8bbe\u5b9a\u7684\u65f6\u95f4\u5185\u751f\u6210\u53ef\u663e\u793a\u7684\u7b80\u5316\u6a21\u578b\uff0c\u800c\u4e14\u7ed3\u679c\u7684\u8d28\u91cf\u4e5f\u5f88\u597d\u3002\u6b64\u5916\uff0c\u5148\u524d\u751f\u6210\u7684\u7b80\u5316\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u4f18\u5316\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u80fd\u591f\u5feb\u901f\u5730\u7b80\u5316\u5927\u578b\u6a21\u578b\uff0c\u5e76\u4fdd\u8bc1\u5728\u7ed9\u5b9a\u7684\u65f6\u95f4\u5185\u5f97\u5230\u53ef\u663e\u793a\u7684\u3001\u9ad8\u8d28\u91cf\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.15615", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2507.15615", "abs": "https://arxiv.org/abs/2507.15615", "authors": ["Zhihao Zhang", "Siyuan Li", "Chenxi Li", "Feifan Liu", "Mengjing Chen", "Kai Li", "Tao Zhong", "Bo An", "Peng Liu"], "title": "DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving", "comment": null, "summary": "Primal heuristics play a critical role in improving the efficiency of mixed\ninteger programming (MILP) solvers. As large language models (LLMs) have\ndemonstrated superior code generation abilities, recent MILP works are devoted\nto leveraging the evolutionary computation approaches with LLMs to generate\neffective primal heuristics. Although the generated heuristics have achieved\nbetter solving performance than the hand-crafted ones with little adaptability,\nthe advantage of current LLM-based methods is limited to few MILP instances in\none problem class, as they fail to capture the instance characteristics in the\nproblem class (the MILP instances generated from the same mathematical model\nare defined as a problem class). Since MILP instances often differ\nsignificantly in structure and feature distribution, the neglect of their\ncharacteristics in the evolution process results in poor generalization within\nthe same problem class. To overcome this challenge, we propose a data-algorithm\nco-evolution framework (DHEvo) that iteratively selects representative\ninstances and evolves corresponding heuristics. With the initial instance\ndistribution, we develop an LLM-based multi-agent system to generate data-code\npairs simultaneously. These data-code pairs are iteratively refined based on\ntheir fitness scores, leading to the identification of the most effective\nheuristic over the entire problem class. Extensive experiments across diverse\nMILP benchmarks demonstrate that our approach significantly outperforms both\nhuman-designed heuristics and existing LLM-based methods.", "AI": {"tldr": "\u901a\u8fc7\u6570\u636e-\u7b97\u6cd5\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff08DHEvo\uff09\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u5728\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MILP\uff09\u542f\u53d1\u5f0f\u65b9\u6cd5\u751f\u6210\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6c42\u89e3\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684LLM\u65b9\u6cd5\u751f\u6210\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u867d\u7136\u6bd4\u624b\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u6709\u66f4\u597d\u7684\u6c42\u89e3\u6027\u80fd\uff0c\u4f46\u9002\u5e94\u6027\u8f83\u5dee\uff0c\u4e14\u4ec5\u9650\u4e8e\u67d0\u4e00\u95ee\u9898\u7c7b\u522b\u4e2d\u7684\u5c11\u6570\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MILP\uff09\u5b9e\u4f8b\uff0c\u65e0\u6cd5\u6355\u6349\u95ee\u9898\u7c7b\u522b\u4e2d\u7684\u5b9e\u4f8b\u7279\u5f81\u3002\u8fd9\u662f\u56e0\u4e3a\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MILP\uff09\u5b9e\u4f8b\u5728\u7ed3\u6784\u548c\u7279\u5f81\u5206\u5e03\u4e0a\u5e38\u5e38\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u800c\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u5ffd\u7565\u8fd9\u4e9b\u7279\u5f81\u4f1a\u5bfc\u81f4\u5728\u540c\u4e00\u95ee\u9898\u7c7b\u522b\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e-\u7b97\u6cd5\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff08DHEvo\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u9009\u62e9\u4ee3\u8868\u6027\u5b9e\u4f8b\u5e76\u6f14\u5316\u76f8\u5e94\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u5229\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684LLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u540c\u65f6\u751f\u6210\u6570\u636e-\u4ee3\u7801\u5bf9\uff0c\u5e76\u6839\u636e\u9002\u5e94\u5ea6\u5206\u6570\u8fed\u4ee3\u4f18\u5316\u8fd9\u4e9b\u6570\u636e-\u4ee3\u7801\u5bf9\uff0c\u4ece\u800c\u8bc6\u522b\u51fa\u5728\u6574\u4e2a\u95ee\u9898\u7c7b\u4e2d\u6700\u4e3a\u6709\u6548\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684LLM\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6df7\u5408\u6574\u6570\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684LLM\u65b9\u6cd5\u3002"}}
{"id": "2507.15300", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.15300", "abs": "https://arxiv.org/abs/2507.15300", "authors": ["Minnan Pei", "Gang Li", "Junwen Si", "Zeyu Zhu", "Zitao Mo", "Peisong Wang", "Zhuoran Song", "Xiaoyao Liang", "Jian Cheng"], "title": "GCC: A 3DGS Inference Architecture with Gaussian-Wise and Cross-Stage Conditional Processing", "comment": null, "summary": "3D Gaussian Splatting (3DGS) has emerged as a leading neural rendering\ntechnique for high-fidelity view synthesis, prompting the development of\ndedicated 3DGS accelerators for mobile applications. Through in-depth analysis,\nwe identify two major limitations in the conventional decoupled\npreprocessing-rendering dataflow adopted by existing accelerators: 1) a\nsignificant portion of preprocessed Gaussians are not used in rendering, and 2)\nthe same Gaussian gets repeatedly loaded across different tile renderings,\nresulting in substantial computational and data movement overhead. To address\nthese issues, we propose GCC, a novel accelerator designed for fast and\nenergy-efficient 3DGS inference. At the dataflow level, GCC introduces: 1)\ncross-stage conditional processing, which interleaves preprocessing and\nrendering to dynamically skip unnecessary Gaussian preprocessing; and 2)\nGaussian-wise rendering, ensuring that all rendering operations for a given\nGaussian are completed before moving to the next, thereby eliminating\nduplicated Gaussian loading. We also propose an alpha-based boundary\nidentification method to derive compact and accurate Gaussian regions, thereby\nreducing rendering costs. We implement our GCC accelerator in 28nm technology.\nExtensive experiments demonstrate that GCC significantly outperforms the\nstate-of-the-art 3DGS inference accelerator, GSCore, in both performance and\nenergy efficiency.", "AI": {"tldr": "GCC \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 3DGS \u63a8\u7406\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u4ea4\u53c9\u9636\u6bb5\u6761\u4ef6\u5904\u7406\u548c\u6309\u9ad8\u65af\u6e32\u67d3\u6765\u89e3\u51b3\u73b0\u6709\u52a0\u901f\u5668\u6570\u636e\u6d41\u7684\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e alpha \u7684\u8fb9\u754c\u8bc6\u522b\u65b9\u6cd5\u6765\u964d\u4f4e\u6e32\u67d3\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u6bd4 GSCore \u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u7684 3DGS \u52a0\u901f\u5668\u91c7\u7528\u4e86\u5206\u79bb\u7684\u9884\u5904\u7406-\u6e32\u67d3\u6570\u636e\u6d41\uff0c\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\u6027\uff1a1\uff09\u9884\u5904\u7406\u540e\u7684\u9ad8\u65af\u4e2d\u6709\u76f8\u5f53\u4e00\u90e8\u5206\u672a\u7528\u4e8e\u6e32\u67d3\uff1b2\uff09\u5728\u4e0d\u540c\u7684\u5207\u7247\u6e32\u67d3\u8fc7\u7a0b\u4e2d\uff0c\u76f8\u540c\u7684\u9ad8\u65af\u4f1a\u88ab\u91cd\u590d\u52a0\u8f7d\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u8ba1\u7b97\u548c\u6570\u636e\u79fb\u52a8\u5f00\u9500\u3002", "method": "GCC \u901a\u8fc7\u4ea4\u53c9\u9636\u6bb5\u6761\u4ef6\u5904\u7406\u548c\u6309\u9ad8\u65af\u6e32\u67d3\u6765\u89e3\u51b3\u73b0\u6709\u52a0\u901f\u5668\u7684\u5c40\u9650\u6027\uff0c\u524d\u8005\u53ef\u4ee5\u8df3\u8fc7\u4e0d\u5fc5\u8981\u7684\u9ad8\u65af\u9884\u5904\u7406\uff0c\u540e\u8005\u786e\u4fdd\u5728\u79fb\u52a8\u5230\u4e0b\u4e00\u4e2a\u9ad8\u65af\u4e4b\u524d\u5b8c\u6210\u7ed9\u5b9a\u9ad8\u65af\u7684\u6240\u6709\u6e32\u67d3\u64cd\u4f5c\uff0c\u4ece\u800c\u6d88\u9664\u91cd\u590d\u7684\u9ad8\u65af\u52a0\u8f7d\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e alpha \u7684\u8fb9\u754c\u8bc6\u522b\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u7d27\u51d1\u51c6\u786e\u7684\u9ad8\u65af\u533a\u57df\u4ee5\u964d\u4f4e\u6e32\u67d3\u6210\u672c\u3002", "result": "GCC \u52a0\u901f\u5668\u5728 28nm \u5de5\u827a\u6280\u672f\u4e0a\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u6027\u80fd\u548c\u80fd\u6548\u4e0a\u5747\u663e\u8457\u4f18\u4e8e GSCore\u3002", "conclusion": "GCC \u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684 3DGS \u63a8\u7406\u52a0\u901f\u5668 GSCore\uff0c\u5728\u6027\u80fd\u548c\u80fd\u6548\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.14864", "categories": ["cs.SI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.14864", "abs": "https://arxiv.org/abs/2507.14864", "authors": ["Gengyu Wang", "Runze Zhang", "Zhongzhi Zhang"], "title": "Efficient Algorithms for Relevant Quantities of Friedkin-Johnsen Opinion Dynamics Model", "comment": null, "summary": "Online social networks have become an integral part of modern society,\nprofoundly influencing how individuals form and exchange opinions across\ndiverse domains ranging from politics to public health. The Friedkin-Johnsen\nmodel serves as a foundational framework for modeling opinion formation\ndynamics in such networks. In this paper, we address the computational task of\nefficiently determining the equilibrium opinion vector and associated metrics\nincluding polarization and disagreement, applicable to both directed and\nundirected social networks. We propose a deterministic local algorithm with\nrelative error guarantees, scaling to networks exceeding ten million nodes.\nFurther acceleration is achieved through integration with successive\nover-relaxation techniques, where a relaxation factor optimizes convergence\nrates. Extensive experiments on diverse real-world networks validate the\npractical effectiveness of our approaches, demonstrating significant\nimprovements in computational efficiency and scalability compared to\nconventional methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u610f\u89c1\u5f62\u6210\uff0c\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u7f51\u7edc\u5e76\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5feb\u5730\u8ba1\u7b97\u7ed3\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5927\u578b\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u4e2d\u8ba1\u7b97\u610f\u89c1\u5f62\u6210\u5747\u8861\u5411\u91cf\u53ca\u76f8\u5173\u6307\u6807\uff08\u5982\u6781\u5316\u548c\u5206\u6b67\uff09\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u5e76\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u5c40\u90e8\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e86\u8d85\u677e\u5f1b\uff08Successive Over-Relaxation, SOR\uff09\u6280\u672f\u6765\u52a0\u901f\u6536\u655b\u3002\u8be5\u7b97\u6cd5\u80fd\u591f\u8ba1\u7b97\u5747\u8861\u610f\u89c1\u5411\u91cf\u4ee5\u53ca\u76f8\u5173\u7684\u5ea6\u91cf\u6307\u6807\uff08\u5982\u6781\u5316\u548c\u5206\u6b67\uff09\uff0c\u9002\u7528\u4e8e\u6709\u5411\u548c\u65e0\u5411\u7f51\u7edc\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5904\u7406\u8d85\u8fc7\u5343\u4e07\u8282\u70b9\u7684\u5927\u578b\u7f51\u7edc\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u5c40\u90e8\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e86\u8d85\u677e\u5f1b\u6280\u672f\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u610f\u89c1\u5f62\u6210\u5747\u8861\u5411\u91cf\uff0c\u4ee5\u53ca\u76f8\u5173\u7684\u6781\u5316\u548c\u5206\u6b67\u6307\u6807\u3002\u8be5\u7b97\u6cd5\u5177\u6709\u76f8\u5bf9\u8bef\u5dee\u4fdd\u8bc1\uff0c\u80fd\u591f\u6269\u5c55\u5230\u62e5\u6709\u5343\u4e07\u7ea7\u8282\u70b9\u7684\u5927\u578b\u7f51\u7edc\uff0c\u5e76\u5728\u5404\u79cd\u771f\u5b9e\u7f51\u7edc\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.14509", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14509", "abs": "https://arxiv.org/abs/2507.14509", "authors": ["Sheikh Shakil Akhtar", "Jayakrishnan Madathil", "Pranabendu Misra", "Geevarghese Philip"], "title": "Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and Feedback Vertex Set", "comment": null, "summary": "A typical goal of research in combinatorial optimization is to come up with\nfast algorithms that find optimal solutions to a computational problem. The\nprocess that takes a real-world problem and extracts a clean mathematical\nabstraction of it often throws out a lot of \"side information\" which is deemed\nirrelevant. However, the discarded information could be of real significance to\nthe end-user of the algorithm's output. All solutions of the same cost are not\nnecessarily of equal impact in the real-world; some solutions may be much more\ndesirable than others, even at the expense of additional increase in cost. If\nthe impact, positive or negative, is mostly felt by some specific (minority)\nsubgroups of the population, the population at large will be largely unaware of\nit. In this work we ask the question of finding solutions to combinatorial\noptimization problems that are \"unbiased\" with respect to a collection of\nspecified subgroups of the total population.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5982\u4f55\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u627e\u5230\u516c\u5e73\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u5173\u6ce8\u5c11\u6570\u7fa4\u4f53\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u7b97\u6cd5\u5728\u62bd\u8c61\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u65f6\u4f1a\u5ffd\u7565\u201c\u526f\u4fe1\u606f\u201d\uff0c\u5bfc\u81f4\u89e3\u51b3\u65b9\u6848\u5728\u4e0d\u540c\u4eba\u7fa4\u4e2d\u53ef\u80fd\u4ea7\u751f\u4e0d\u516c\u5e73\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u5bf9\u5c11\u6570\u7fa4\u4f53\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u5bfb\u627e\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u65e0\u504f\u89e3\u51b3\u65b9\u6848\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u7814\u7a76\u5173\u6ce8\u5982\u4f55\u627e\u5230\u5728\u6307\u5b9a\u4eba\u7fa4\u5b50\u96c6\u65b9\u9762\u201c\u65e0\u504f\u201d\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u7814\u7a76\u65e8\u5728\u627e\u5230\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u65e0\u504f\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u89e3\u51b3\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u5ffd\u7565\u201c\u526f\u4fe1\u606f\u201d\u800c\u5bfc\u81f4\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002"}}
{"id": "2507.15218", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.15218", "abs": "https://arxiv.org/abs/2507.15218", "authors": ["Yi Wang", "Cheng Chen", "Shuyu Lin"], "title": "An ultrasonic transducer for vibration mode conversion of wedge-shaped structure of acoustic black hole", "comment": null, "summary": "Acoustic black hole (ABH) structure has been extensively employed in\napplications such as vibration mitigation, noise reduction, and energy\nharvesting, owing to its unique sound wave trapping and energy concentration\neffects. Furthermore, ABH structure shows significant promise in improving the\nperformance of ultrasonic device and constructing multifunc-tional acoustic\nfield. Therefore, this paper proposes an ultrasonic mode-conversion transducer\nconsisting of a Langevin transducer and an ABH wedge radiant plate to\ninvestigate the potential applications of ABH in ultrasonic levitation and\nmultifunctional particle manipulation. The theoretical model of flexural\nvibration of the radiant plate is established by utilizing Timoshenko beam\ntheory and transfer matrix method, and the calculated vibration frequencies\ndemonstrated good agreement with those obtained from finite element simulations\n(FES). The electrical impedance frequency response characteristics, vibration\nmodes and the near-field sound pressure distribution of the transducer in air\nwere also simulated. The results revealed that the amplitude of the ABH wedge\nradiant plate increases stepwise, and the sound pressure exhibits a gradient\ndistribution. A prototype of the transducer was fabricated and experimentally\ntested, confirming the accuracy of FES and the feasibility of the design\napproach. Finally, the ultrasonic levitation experiment demonstrated that the\nABH design enables the formation of gradient distribution of sound pressure in\nthe standing wave sound field, thereby facilitating precise particle sorting.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e ABH \u7ed3\u6784\u7684\u8d85\u58f0\u6ce2\u6a21\u5f0f\u8f6c\u6362\u6362\u80fd\u5668\uff0c\u8be5\u6362\u80fd\u5668\u53ef\u5b9e\u73b0\u68af\u5ea6\u58f0\u538b\u5206\u5e03\uff0c\u7528\u4e8e\u8d85\u58f0\u60ac\u6d6e\u548c\u7c92\u5b50\u5206\u9009\u3002", "motivation": "\u9274\u4e8e ABH \u7ed3\u6784\u5728\u51cf\u632f\u3001\u964d\u566a\u548c\u80fd\u91cf\u6536\u96c6\u7b49\u65b9\u9762\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u5176\u5728\u6539\u5584\u8d85\u58f0\u8bbe\u5907\u6027\u80fd\u548c\u6784\u5efa\u591a\u529f\u80fd\u58f0\u573a\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22 ABH \u5728\u8d85\u58f0\u60ac\u6d6e\u548c\u591a\u529f\u80fd\u7c92\u5b50\u64cd\u7eb5\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528 Timoshenko \u6881\u7406\u8bba\u548c\u4f20\u9012\u77e9\u9635\u6cd5\u5efa\u7acb\u4e86\u8f90\u5c04\u677f\u7684\u5f2f\u66f2\u632f\u52a8\u7406\u8bba\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u6709\u9650\u5143\u6a21\u62df\uff08FES\uff09\u7814\u7a76\u4e86\u6362\u80fd\u5668\u7684\u7535\u58f0\u963b\u6297\u7279\u6027\u3001\u632f\u52a8\u6a21\u5f0f\u548c\u8fd1\u573a\u58f0\u538b\u5206\u5e03\u3002", "result": "\u7406\u8bba\u6a21\u578b\u8ba1\u7b97\u7ed3\u679c\u4e0e\u6709\u9650\u5143\u6a21\u62df\u7ed3\u679c\u543b\u5408\u826f\u597d\u3002\u6a21\u62df\u663e\u793a ABH \u6954\u5f62\u8f90\u5c04\u677f\u7684\u5e45\u503c\u5448\u9636\u68af\u72b6\u589e\u5927\uff0c\u58f0\u538b\u5448\u68af\u5ea6\u5206\u5e03\u3002\u5b9e\u9a8c\u539f\u578b\u9a8c\u8bc1\u4e86\u6709\u9650\u5143\u6a21\u62df\u7684\u51c6\u786e\u6027\u548c\u8bbe\u8ba1\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6210\u529f\u5b9e\u73b0\u4e86\u8d85\u58f0\u60ac\u6d6e\u548c\u7c92\u5b50\u5206\u9009\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7531 Langevin \u6362\u80fd\u5668\u548c ABH \u6954\u5f62\u8f90\u5c04\u677f\u7ec4\u6210\u7684\u8d85\u58f0\u6ce2\u6a21\u5f0f\u8f6c\u6362\u6362\u80fd\u5668\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u8d85\u58f0\u6ce2\u60ac\u6d6e\u548c\u591a\u529f\u80fd\u7c92\u5b50\u64cd\u7eb5\u65b9\u9762\u7684\u5e94\u7528\u6f5c\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cABH \u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u5730\u5728\u9a7b\u6ce2\u58f0\u573a\u4e2d\u5f62\u6210\u68af\u5ea6\u58f0\u538b\u5206\u5e03\uff0c\u4ece\u800c\u5b9e\u73b0\u7cbe\u786e\u7684\u7c92\u5b50\u5206\u9009\u3002"}}
{"id": "2507.15063", "categories": ["quant-ph", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15063", "abs": "https://arxiv.org/abs/2507.15063", "authors": ["Chloe Pomeroy", "Aleksandar Pramov", "Karishma Thakrar", "Lakshmi Yendapalli"], "title": "Quantum Annealing for Machine Learning: Applications in Feature Selection, Instance Selection, and Clustering", "comment": null, "summary": "This paper explores the applications of quantum annealing (QA) and classical\nsimulated annealing (SA) to a suite of combinatorial optimization problems in\nmachine learning, namely feature selection, instance selection, and clustering.\nWe formulate each task as a Quadratic Unconstrained Binary Optimization (QUBO)\nproblem and implement both quantum and classical solvers to compare their\neffectiveness. For feature selection, we propose several QUBO configurations\nthat balance feature importance and redundancy, showing that quantum annealing\n(QA) produces solutions that are computationally more efficient. In instance\nselection, we propose a few novel heuristics for instance-level importance\nmeasures that extend existing methods. For clustering, we embed a\nclassical-to-quantum pipeline, using classical clustering followed by\nQUBO-based medoid refinement, and demonstrate consistent improvements in\ncluster compactness and retrieval metrics. Our results suggest that QA can be a\ncompetitive and efficient tool for discrete machine learning optimization, even\nwithin the constraints of current quantum hardware.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u5e94\u7528\u4e8e\u7279\u5f81\u9009\u62e9\u3001\u5b9e\u4f8b\u9009\u62e9\u548c\u805a\u7c7b\u95ee\u9898\uff0c\u7ed3\u679c\u8868\u660eQA\u5728\u8ba1\u7b97\u6548\u7387\u548c\u4f18\u5316\u6548\u679c\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u662f\u79bb\u6563\u673a\u5668\u5b66\u4e60\u4f18\u5316\u7684\u6709\u6548\u5de5\u5177\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\uff08SA\uff09\u5728\u673a\u5668\u5b66\u4e60\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5c06\u7279\u5f81\u9009\u62e9\u3001\u5b9e\u4f8b\u9009\u62e9\u548c\u805a\u7c7b\u4efb\u52a1\u8868\u8ff0\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u5143\u4f18\u5316\uff08QUBO\uff09\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\uff08SA\uff09\u6c42\u89e3\u5668\u8fdb\u884c\u6c42\u89e3\u3002", "result": "QA\u5728\u7279\u5f81\u9009\u62e9\u65b9\u9762\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u8ba1\u7b97\u6548\u7387\uff1b\u5728\u5b9e\u4f8b\u9009\u62e9\u65b9\u9762\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5b9e\u4f8b\u7ea7\u522b\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\uff1b\u5728\u805a\u7c7b\u65b9\u9762\uff0c\u901a\u8fc7\u7ed3\u5408\u7ecf\u5178\u805a\u7c7b\u548c\u57fa\u4e8eQUBO\u7684\u4e2d\u5fc3\u70b9\u4f18\u5316\uff0c\u5728\u805a\u7c7b\u7d27\u5bc6\u5ea6\u548c\u68c0\u7d22\u6307\u6807\u65b9\u9762\u53d6\u5f97\u4e86\u4e00\u81f4\u6027\u6539\u8fdb\u3002", "conclusion": "QA\u53ef\u4f5c\u4e3a\u5f53\u524d\u786c\u4ef6\u7ea6\u675f\u4e0b\u7684\u79bb\u6563\u673a\u5668\u5b66\u4e60\u4f18\u5316\u7684\u7ade\u4e89\u6027\u548c\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.14957", "categories": ["cs.GT", "cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14957", "abs": "https://arxiv.org/abs/2507.14957", "authors": ["Jaros\u0142aw Byrka", "Franciszek Malinka", "Tomasz Ponitka"], "title": "Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division", "comment": "27 pages, 4 figures", "summary": "We study the fair division of indivisible items and provide new insights into\nthe EFX problem, which is widely regarded as the central open question in fair\ndivision, and the PMMS problem, a strictly stronger variant of EFX. Our first\nresult constructs a three-agent instance with two monotone valuations and one\nadditive valuation in which no PMMS allocation exists. Since EFX allocations\nare known to exist under these assumptions, this establishes a formal\nseparation between EFX and PMMS.\n  We prove existence of fair allocations for three important special cases. We\nshow that EFX allocations exist for personalized bivalued valuations, where for\neach agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value\n$v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous\nexistence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also\nprove that PMMS allocations exist for binary-valued MMS-feasible valuations,\nwhere each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result\nholds even without assuming monotonicity of valuations and thus applies to the\nfair division of chores and mixed manna. Finally, we study a class of\nvaluations called pair-demand valuations, which extend the well-studied\nunit-demand valuations to the case where each agent derives value from at most\ntwo items, and we show that PMMS allocations exist in this setting. Our proofs\nare constructive, and we provide polynomial-time algorithms for all three\nexistence results.", "AI": {"tldr": "\u672c\u7814\u7a76\u89e3\u51b3\u4e86\u516c\u5e73\u5206\u914d\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684EFX\u548cPMMS\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u9020\u5b9e\u4f8b\u5206\u79bb\u4e86EFX\u548cPMMS\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u51e0\u79cd\u7279\u5b9a\u4f30\u503c\uff08\u4e2a\u4eba\u53cc\u503c\u3001\u4e8c\u503cMMS\u53ef\u884c\u3001\u6210\u5bf9\u9700\u6c42\uff09\u4e0bEFX\u548cPMMS\u5206\u914d\u7684\u5b58\u5728\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u516c\u5e73\u5206\u914d\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u6838\u5fc3\u5f00\u653e\u95ee\u9898\uff0c\u7279\u522b\u662fEFX\uff08Equitable Fractional Allocation\uff09\u95ee\u9898\u53ca\u5176\u66f4\u5f3a\u7684\u53d8\u4f53PMMS\uff08Proportional, Maximin Share\uff09\u95ee\u9898\u3002\u901a\u8fc7\u7814\u7a76\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ee5\u671f\u4e3a\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u516c\u5e73\u5206\u914d\u63d0\u4f9b\u65b0\u7684\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u7528\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u6784\u9020\u6027\u8bc1\u660e\u548c\u7b97\u6cd5\u8bbe\u8ba1\u6765\u89e3\u51b3\u516c\u5e73\u5206\u914d\u95ee\u9898\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. \u6784\u9020\u4e09\u65b9\u5b9e\u4f8b\uff0c\u8bc1\u660ePMMS\u4e0eEFX\u7684\u5206\u79bb\u6027\u30022. \u8bc1\u660eEFX\u5206\u914d\u5728\u4e2a\u4eba\u53cc\u503c\u4f30\u503c\u60c5\u51b5\u4e0b\u7684\u5b58\u5728\u6027\u30023. \u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff08$a_i$\u53ef\u88ab$b_i$\u6574\u9664\uff09PMMS\u5206\u914d\u7684\u5b58\u5728\u6027\u30024. \u8bc1\u660e\u5728\u4e8c\u503cMMS\u53ef\u884c\u4f30\u503c\uff08\u5305\u62ec\u975e\u5355\u8c03\u4f30\u503c\uff09\u60c5\u51b5\u4e0bPMMS\u5206\u914d\u7684\u5b58\u5728\u6027\u30025. \u8bc1\u660e\u5728\u6210\u5bf9\u9700\u6c42\u4f30\u503c\u60c5\u51b5\u4e0bPMMS\u5206\u914d\u7684\u5b58\u5728\u6027\u3002\u4e3a\u6240\u6709\u5b58\u5728\u6027\u7ed3\u679c\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "result": "1. \u6784\u9020\u4e86\u4e00\u4e2a\u4e09\u65b9\u5b9e\u4f8b\uff08\u4e24\u79cd\u5355\u8c03\u4f30\u503c\uff0c\u4e00\u79cd\u52a0\u6027\u4f30\u503c\uff09\uff0c\u8bc1\u660e\u4e86PMMS\u5206\u914d\u4e0d\u5b58\u5728\uff0c\u4ece\u800c\u5728EFX\u548cPMMS\u4e4b\u95f4\u5efa\u7acb\u4e86\u6b63\u5f0f\u7684\u5206\u79bb\u3002 2. \u8bc1\u660e\u4e86EFX\u5206\u914d\u5728\u4e2a\u4eba\u53cc\u503c\u4f30\u503c\uff08$v_i (\\{g\\}) \\in \\{a_i, b_i\\}$\uff09\u60c5\u51b5\u4e0b\u5b58\u5728\u3002 3. \u8bc1\u660e\u4e86\u5f53$a_i$\u53ef\u88ab$b_i$\u6574\u9664\u65f6\uff0cPMMS\u5206\u914d\u5728\u4e2a\u4eba\u53cc\u503c\u4f30\u503c\u60c5\u51b5\u4e0b\u5b58\u5728\u3002 4. \u8bc1\u660e\u4e86PMMS\u5206\u914d\u5728\u4e8c\u503cMMS\u53ef\u884c\u4f30\u503c\uff08$v_i(S) \\in \\{0, 1\\}$\uff09\u60c5\u51b5\u4e0b\u5b58\u5728\uff0c\u4e14\u4e0d\u8981\u6c42\u4f30\u503c\u5355\u8c03\uff0c\u9002\u7528\u4e8e\u516c\u5e73\u5206\u914d\u4e8b\u52a1\u548c\u6df7\u5408\u7ba1\u7406\u3002 5. \u8bc1\u660e\u4e86PMMS\u5206\u914d\u5728\u6210\u5bf9\u9700\u6c42\u4f30\u503c\uff08\u6bcf\u4e2a\u4ee3\u7406\u6700\u591a\u4ece\u4e24\u4e2a\u7269\u54c1\u4e2d\u83b7\u5f97\u4ef7\u503c\uff09\u60c5\u51b5\u4e0b\u5b58\u5728\u3002 6. \u4e3a\u6240\u6709\u5b58\u5728\u6027\u7ed3\u679c\u63d0\u4f9b\u4e86\u6784\u9020\u6027\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u5728\u516c\u5e73\u5206\u914d\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u9886\u57df\u53d6\u5f97\u4e86\u65b0\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u5728EFX\u548cPMMS\u95ee\u9898\u4e0a\u3002\u6211\u4eec\u6784\u9020\u4e86\u4e00\u4e2a\u4e09\u65b9\u5b9e\u4f8b\uff0c\u5176\u4e2d\u5305\u542b\u4e24\u79cd\u5355\u8c03\u4f30\u503c\u548c\u4e00\u4e2a\u52a0\u6027\u4f30\u503c\uff0c\u8bc1\u660e\u4e86\u4e0d\u5b58\u5728PMMS\u5206\u914d\uff0c\u4ece\u800c\u5728EFX\u548cPMMS\u4e4b\u95f4\u5efa\u7acb\u4e86\u6b63\u5f0f\u7684\u5206\u79bb\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bc1\u660e\u4e86EFX\u5206\u914d\u5728\u4e2a\u4eba\u53cc\u503c\u4f30\u503c\u60c5\u51b5\u4e0b\u5b58\u5728\uff0c\u5e76\u4e14\u5f53$a_i$\u53ef\u88ab$b_i$\u6574\u9664\u65f6\uff0cPMMS\u5206\u914d\u4e5f\u5b58\u5728\u3002\u6211\u4eec\u8fd8\u8bc1\u660e\u4e86\u5728\u4e8c\u503cMMS\u53ef\u884c\u4f30\u503c\uff08\u5305\u62ec\u975e\u5355\u8c03\u4f30\u503c\uff09\u60c5\u51b5\u4e0bPMMS\u5206\u914d\u5b58\u5728\uff0c\u8fd9\u9002\u7528\u4e8e\u516c\u5e73\u5206\u914d\u4e8b\u52a1\u548c\u6df7\u5408\u7ba1\u7406\u3002\u6700\u540e\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u6269\u5c55\u7684\u5355\u9700\u6c42\u4f30\u503c\uff0c\u5373\u6210\u5bf9\u9700\u6c42\u4f30\u503c\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0bPMMS\u5206\u914d\u5b58\u5728\u3002\u6240\u6709\u8bc1\u660e\u90fd\u5177\u6709\u5efa\u8bbe\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5e94\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002"}}
{"id": "2507.15420", "categories": ["cs.LO", "E.1; F.4.1; I.2.4; K.5.1"], "pdf": "https://arxiv.org/pdf/2507.15420", "abs": "https://arxiv.org/abs/2507.15420", "authors": ["Robert David", "Albin Ahmeti", "Geni Bushati", "Amar Tauqeer", "Anna Fensel"], "title": "A SHACL-based Data Consistency Solution for Contract Compliance Verification", "comment": "Extended version of the short paper published at OPAL workshop (ESWC\n  2025 Workshops and Tutorials Joint Proceedings). See\n  https://ceur-ws.org/Vol-3977/OPAL2025-1.pdf", "summary": "In recent years, there have been many developments for GDPR-compliant data\naccess and sharing based on consent. For more complex data sharing scenarios,\nwhere consent might not be sufficient, many parties rely on contracts. Before a\ncontract is signed, it must undergo the process of contract negotiation within\nthe contract lifecycle, which consists of negotiating the obligations\nassociated with the contract. Contract compliance verification (CCV) provides a\nmeans to verify whether a contract is GDPR-compliant, i.e., adheres to legal\nobligations and there are no violations. The rise of knowledge graph (KG)\nadoption, enabling semantic interoperability using well-defined semantics,\nallows CCV to be applied on KGs. In the scenario of different participants\nnegotiating obligations, there is a need for data consistency to ensure that\nCCV is done correctly. Recent work introduced the automated contracting tool\n(ACT), a KG-based and ODRL-employing tool for GDPR CCV, which was developed in\nthe Horizon 2020 project smashHit (https://smashhit.eu). Although the tool\nreports violations with respect to obligations, it had limitations in verifying\nand ensuring compliance, as it did not use an interoperable semantic formalism,\nsuch as SHACL, and did not support users in resolving data inconsistencies. In\nthis work, we propose a novel approach to overcome these limitations of ACT. We\nsemi-automatically resolve CCV inconsistencies by providing repair strategies,\nwhich automatically propose (optimal) solutions to the user to re-establish\ndata consistency and thereby support them in managing GDPR-compliant contract\nlifecycle data. We have implemented the approach, integrated it into ACT and\ntested its correctness and performance against basic CCV consistency\nrequirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdbACT\u5de5\u5177\uff0c\u901a\u8fc7\u534a\u81ea\u52a8\u4fee\u590d\u7b56\u7565\u89e3\u51b3GDPR\u5408\u540c\u5408\u89c4\u6027\u9a8c\u8bc1\u4e2d\u7684\u6570\u636e\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4ee5\u786e\u4fdd\u5408\u89c4\u6027\u3002", "motivation": "\u73b0\u6709\u7684ACT\u5de5\u5177\u867d\u7136\u53ef\u4ee5\u62a5\u544a\u8fdd\u53cd\u4e49\u52a1\u7684\u60c5\u51b5\uff0c\u4f46\u5728\u9a8c\u8bc1\u548c\u786e\u4fdd\u5408\u89c4\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u5b83\u6ca1\u6709\u4f7f\u7528\u50cfSHACL\u8fd9\u6837\u7684\u53ef\u4e92\u64cd\u4f5c\u7684\u8bed\u4e49\u5f62\u5f0f\uff0c\u5e76\u4e14\u4e0d\u652f\u6301\u7528\u6237\u89e3\u51b3\u6570\u636e\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u4f9b\u4fee\u590d\u7b56\u7565\u6765\u89e3\u51b3\u5408\u540c\u5408\u89c4\u6027\u9a8c\u8bc1\uff08CCV\uff09\u4e2d\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230ACT\u5de5\u5177\u4e2d\u8fdb\u884c\u5b9e\u73b0\u548c\u6d4b\u8bd5\u3002", "result": "\u5b9e\u73b0\u5e76\u6d4b\u8bd5\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u89e3\u51b3CCV\u4e0d\u4e00\u81f4\u6027\u65b9\u9762\u7684\u6b63\u786e\u6027\u548c\u6027\u80fd\uff0c\u4ee5\u53ca\u5728\u652f\u6301\u7528\u6237\u7ba1\u7406GDPR\u5408\u89c4\u6027\u5408\u540c\u751f\u547d\u5468\u671f\u6570\u636e\u65b9\u9762\u7684\u4f5c\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5408\u540c\u5408\u89c4\u6027\u9a8c\u8bc1\uff08CCV\uff09\u4e2d\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u4f9b\u4fee\u590d\u7b56\u7565\u6765\u81ea\u52a8\u63d0\u51fa\uff08\u6700\u4f18\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u91cd\u65b0\u5efa\u7acb\u6570\u636e\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u652f\u6301\u7528\u6237\u7ba1\u7406\u7b26\u5408GDPR\u7684\u5408\u540c\u751f\u547d\u5468\u671f\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u5df2\u88ab\u5b9e\u73b0\u5e76\u96c6\u6210\u5230ACT\u5de5\u5177\u4e2d\uff0c\u5e76\u5728\u57fa\u672cCCV\u4e00\u81f4\u6027\u8981\u6c42\u65b9\u9762\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002"}}
{"id": "2507.14928", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14928", "abs": "https://arxiv.org/abs/2507.14928", "authors": ["Yongrae Jo", "Chanik Park"], "title": "Byzantine-Robust Decentralized Coordination of LLM Agents", "comment": null, "summary": "Collaboration among multiple large language model (LLM) agents is a promising\napproach to overcome inherent limitations of single-agent systems, such as\nhallucinations and single points of failure. As LLM agents are increasingly\ndeployed on open blockchain platforms, multi-agent systems capable of\ntolerating malicious (Byzantine) agents have become essential.\n  Recent Byzantine-robust multi-agent systems typically rely on leader-driven\ncoordination, which suffers from two major drawbacks. First, they are\ninherently vulnerable to targeted attacks against the leader. If consecutive\nleaders behave maliciously, the system repeatedly fails to achieve consensus,\nforcing new consensus rounds, which is particularly costly given the high\nlatency of LLM invocations. Second, an underperforming proposal from the leader\ncan be accepted as the final answer even when higher-quality alternatives are\navailable, as existing methods finalize the leader's proposal once it receives\na quorum of votes.\n  To address these issues, we propose DecentLLMs, a novel decentralized\nconsensus approach for multi-agent LLM systems, where worker agents generate\nanswers concurrently and evaluator agents independently score and rank these\nanswers to select the best available one. This decentralized architecture\nenables faster consensus despite the presence of Byzantine agents and\nconsistently selects higher-quality answers through Byzantine-robust\naggregation techniques.\n  Experimental results demonstrate that DecentLLMs effectively tolerates\nByzantine agents and significantly improves the quality of selected answers.", "AI": {"tldr": "DecentLLMs \u662f\u4e00\u79cd\u65b0\u7684\u53bb\u4e2d\u5fc3\u5316\u5171\u8bc6\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u4e3b\u4f53 LLM \u7cfb\u7edf\uff0c\u5b83\u53ef\u4ee5\u5bb9\u5fcd\u62dc\u5360\u5ead\u4ee3\u7406\u5e76\u9009\u62e9\u66f4\u9ad8\u8d28\u91cf\u7684\u7b54\u6848\u3002", "motivation": "\u6700\u8fd1\u7684\u62dc\u5360\u5ead\u9c81\u68d2\u591a\u4e3b\u4f53\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u4e8e\u9886\u5bfc\u8005\u9a71\u52a8\u7684\u534f\u8c03\uff0c\u8fd9\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u7f3a\u70b9\uff1a1. \u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u9488\u5bf9\u9886\u5bfc\u8005\u7684\u5b9a\u5411\u653b\u51fb\u30022. \u5373\u4f7f\u5b58\u5728\u66f4\u9ad8\u8d28\u91cf\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9886\u5bfc\u8005\u7684\u8868\u73b0\u4e0d\u4f73\u7684\u63d0\u8bae\u4ecd\u53ef\u80fd\u88ab\u63a5\u53d7\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a DecentLLMs \u7684\u65b0\u9896\u7684\u53bb\u4e2d\u5fc3\u5316\u5171\u8bc6\u65b9\u6cd5\uff0c\u5176\u4e2d\u5de5\u4f5c\u4ee3\u7406\u5e76\u53d1\u751f\u6210\u7b54\u6848\uff0c\u8bc4\u4f30\u4ee3\u7406\u72ec\u7acb\u8bc4\u4f30\u548c\u6392\u540d\u8fd9\u4e9b\u7b54\u6848\u4ee5\u9009\u62e9\u6700\u4f73\u53ef\u7528\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDecentLLMs \u80fd\u591f\u6709\u6548\u5bb9\u5fcd\u62dc\u5360\u5ead\u4ee3\u7406\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u6240\u9009\u7b54\u6848\u7684\u8d28\u91cf\u3002", "conclusion": "DecentLLMs \u80fd\u591f\u6709\u6548\u5bb9\u5fcd\u62dc\u5360\u5ead\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u62dc\u5360\u5ead\u9c81\u68d2\u805a\u5408\u6280\u672f\u6301\u7eed\u9009\u62e9\u66f4\u9ad8\u8d28\u91cf\u7684\u7b54\u6848\u3002"}}
{"id": "2507.14538", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14538", "abs": "https://arxiv.org/abs/2507.14538", "authors": ["Jin Chai", "Xiang Yao", "Mengfan Hou", "Yanghong Li", "Erbao Dong"], "title": "A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0", "comment": null, "summary": "CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid\ntendon-driven actuation system that combines shape memory alloys (SMAs) and DC\nmotors. The hand employs high-strength fishing line as artificial tendons and\nuses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal\nand tendon-muscle structure of the human hand. A linear motor-driven module\ncontrols finger flexion, while an SMA-based module enables finger extension and\nlateral abduction. These modules are integrated into a compact hybrid actuation\nunit mounted on a custom rear support structure. Mechanical and kinematic\nexperiments, conducted under an Arduino Mega 2560-based control system,\nvalidate the effectiveness of the design and demonstrate its biomimetic\ndexterity.", "AI": {"tldr": "CYJ Hand-0 \u662f\u4e00\u6b3e21\u81ea\u7531\u5ea6\u7684\u7075\u5de7\u624b\uff0c\u91c7\u7528\u6df7\u5408\u9a71\u52a8\u7cfb\u7edf\uff08SMA\u548c\u76f4\u6d41\u7535\u673a\uff09\u548c3D\u6253\u5370\u91d1\u5c5e\u6846\u67b6\uff0c\u6a21\u4eff\u4eba\u624b\u7ed3\u6784\uff0c\u5177\u6709\u4eff\u751f\u7075\u5de7\u6027\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u6b3e\u5177\u6709\u4eff\u751f\u7075\u5de7\u6027\u7684\u7075\u5de7\u624b\u3002", "method": "CYJ Hand-0 \u624b\u90e8\u91c7\u7528\u6df7\u5408\u9a71\u52a8\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f62\u72b6\u8bb0\u5fc6\u5408\u91d1\uff08SMA\uff09\u548c\u76f4\u6d41\u7535\u673a\uff0c\u4f7f\u7528\u9ad8\u5f3a\u5ea6\u9493\u9c7c\u7ebf\u4f5c\u4e3a\u4eba\u9020\u808c\u8171\uff0c\u4ee5\u53ca\u4e00\u4e2a3D\u6253\u5370\u7684AlSi10Mg\u91d1\u5c5e\u6846\u67b6\u6765\u6a21\u4eff\u4eba\u624b\u7684\u9aa8\u9abc\u548c\u808c\u8171-\u808c\u8089\u7ed3\u6784\u3002\u7ebf\u6027\u7535\u673a\u6a21\u5757\u63a7\u5236\u624b\u6307\u5f2f\u66f2\uff0cSMA\u6a21\u5757\u63a7\u5236\u624b\u6307\u4f38\u5c55\u548c\u4fa7\u5411\u5916\u5c55\u3002", "result": "CYJ Hand-0 \u662f\u4e00\u6b3e\u5177\u670921\u81ea\u7531\u5ea6\u3001\u6df7\u5408\u9a71\u52a8\u7684\u7075\u5de7\u624b\uff0c\u5177\u6709\u7d27\u51d1\u7684\u6df7\u5408\u9a71\u52a8\u5355\u5143\u548c\u5b9a\u5236\u7684\u540e\u652f\u6491\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u673a\u68b0\u548c\u8fd0\u52a8\u5b66\u5b9e\u9a8c\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "CYJ Hand-0\u7684\u8bbe\u8ba1\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u4eff\u751f\u7075\u5de7\u6027\u3002"}}
{"id": "2507.14367", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14367", "abs": "https://arxiv.org/abs/2507.14367", "authors": ["Weiming Ren", "Raghav Goyal", "Zhiming Hu", "Tristan Ty Aumentado-Armstrong", "Iqbal Mohomed", "Alex Levinshtein"], "title": "Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution", "comment": "12 pages, 17 figures and 7 tables", "summary": "Generative super-resolution (GSR) currently sets the state-of-the-art in\nterms of perceptual image quality, overcoming the \"regression-to-the-mean\" blur\nof prior non-generative models. However, from a human perspective, such models\ndo not fully conform to the optimal balance between quality and fidelity.\nInstead, a different class of artifacts, in which generated details fail to\nperceptually match the low resolution image (LRI) or ground-truth image (GTI),\nis a critical but under studied issue in GSR, limiting its practical\ndeployments. In this work, we focus on measuring, analyzing, and mitigating\nthese artifacts (i.e., \"hallucinations\"). We observe that hallucinations are\nnot well-characterized with existing image metrics or quality models, as they\nare orthogonal to both exact fidelity and no-reference quality. Instead, we\ntake advantage of a multimodal large language model (MLLM) by constructing a\nprompt that assesses hallucinatory visual elements and generates a\n\"Hallucination Score\" (HS). We find that our HS is closely aligned with human\nevaluations, and also provides complementary insights to prior image metrics\nused for super-resolution (SR) models. In addition, we find certain deep\nfeature distances have strong correlations with HS. We therefore propose to\nalign the GSR models by using such features as differentiable reward functions\nto mitigate hallucinations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u201c\u5e7b\u89c9\u8bc4\u5206\u201d\uff08HS\uff09\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6765\u8bc4\u4f30\u8d85\u5206\u8fa8\u7387\u56fe\u50cf\u7684\u751f\u6210\u7ec6\u8282\u662f\u5426\u4e0e\u539f\u59cb\u56fe\u50cf\u5339\u914d\uff0c\u53d1\u73b0HS\u4e0e\u4eba\u7c7b\u8bc4\u4ef7\u4e00\u81f4\uff0c\u5e76\u63d0\u51fa\u7528\u6df1\u5ea6\u7279\u5f81\u6765\u4f18\u5316\u6a21\u578b\u4ee5\u51cf\u5c11\u201c\u5e7b\u89c9\u201d\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u751f\u6210\u5f0f\u8d85\u5206\u8fa8\u7387\uff08GSR\uff09\u6a21\u578b\u867d\u7136\u5728\u611f\u77e5\u56fe\u50cf\u8d28\u91cf\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u751f\u6210\u7684\u5185\u5bb9\u6709\u65f6\u4e0e\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\uff08LRI\uff09\u6216\u5730\u9762\u771f\u5b9e\u56fe\u50cf\uff08GTI\uff09\u5728\u611f\u77e5\u4e0a\u4e0d\u5339\u914d\uff0c\u5373\u201c\u5e7b\u89c9\u201d\u73b0\u8c61\u3002\u8fd9\u79cd\u73b0\u8c61\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u7528\u6237\u4f53\u9a8c\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u56fe\u50cf\u8bc4\u4f30\u6307\u6807\u548c\u8d28\u91cf\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u6355\u6349\u6216\u91cf\u5316\u8fd9\u79cd\u201c\u5e7b\u89c9\u201d\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0e\u56fe\u50cf\u7684\u4fdd\u771f\u5ea6\u6216\u65e0\u53c2\u8003\u8d28\u91cf\u662f\u6b63\u4ea4\u7684\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u3001\u5206\u6790\u548c\u51cf\u8f7b\u8fd9\u79cd\u201c\u5e7b\u89c9\u201d\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u6765\u8bc4\u4f30\u548c\u91cf\u5316\u751f\u6210\u5f0f\u8d85\u5206\u8fa8\u7387\uff08GSR\uff09\u201c\u5e7b\u89c9\u201d\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\u3002\u901a\u8fc7\u8bbe\u8ba1\u7279\u5b9a\u7684\u63d0\u793a\uff08prompt\uff09\uff0cMLLM\u80fd\u591f\u751f\u6210\u4e00\u4e2a\u201c\u5e7b\u89c9\u8bc4\u5206\u201d\uff08HS\uff09\uff0c\u8be5\u8bc4\u5206\u80fd\u591f\u51c6\u786e\u53cd\u6620\u4eba\u7c7b\u5bf9\u751f\u6210\u56fe\u50cf\u7ec6\u8282\u4e0e\u539f\u59cb\u56fe\u50cf\uff08LRI\u6216GTI\uff09\u7684\u611f\u77e5\u5339\u914d\u7a0b\u5ea6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u7d22\u4e86\u6df1\u5ea6\u7279\u5f81\u8ddd\u79bb\u4e0eHS\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd9\u4e9b\u7279\u5f81\u7684\u3001\u53ef\u5fae\u5206\u7684\u5956\u52b1\u51fd\u6570\uff0c\u7528\u4e8e\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u4f18\u5316GSR\u6a21\u578b\uff0c\u4ee5\u51cf\u8f7b\u5e7b\u89c9\u7684\u4ea7\u751f\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u201c\u5e7b\u89c9\u8bc4\u5206\u201d\uff08HS\uff09\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7ed3\u679c\u9ad8\u5ea6\u543b\u5408\uff0c\u5e76\u4e14\u80fd\u591f\u63d0\u4f9b\u6bd4\u73b0\u6709\u8d85\u5206\u8fa8\u7387\uff08SR\uff09\u6a21\u578b\u8bc4\u4f30\u6307\u6807\u66f4\u5177\u4e92\u8865\u6027\u7684\u89c1\u89e3\u3002\u6b64\u5916\uff0c\u7814\u7a76\u53d1\u73b0\u7279\u5b9a\u7684\u6df1\u5ea6\u7279\u5f81\u8ddd\u79bb\u4e0eHS\u4e4b\u95f4\u5b58\u5728\u5f88\u5f3a\u7684\u76f8\u5173\u6027\u3002\u57fa\u4e8e\u8fd9\u4e00\u53d1\u73b0\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06GSR\u6a21\u578b\u8fdb\u884c\u5bf9\u9f50\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8fd9\u4e9b\u6df1\u5ea6\u7279\u5f81\u4f5c\u4e3a\u53ef\u5fae\u5206\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4ece\u800c\u6709\u6548\u51cf\u8f7b\u201c\u5e7b\u89c9\u201d\u95ee\u9898\u3002", "conclusion": "\u867d\u7136\u751f\u6210\u5f0f\u8d85\u5206\u8fa8\u7387\uff08GSR\uff09\u5728\u611f\u77e5\u56fe\u50cf\u8d28\u91cf\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u4f46\u5176\u751f\u6210\u7ec6\u8282\u4e0e\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\uff08LRI\uff09\u6216\u5730\u9762\u771f\u5b9e\u56fe\u50cf\uff08GTI\uff09\u5728\u611f\u77e5\u4e0a\u4e0d\u5339\u914d\u7684\u201c\u5e7b\u89c9\u201d\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u4e2d\u7684\u5e94\u7528\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u201c\u5e7b\u89c9\u8bc4\u5206\u201d\uff08HS\uff09\u6307\u6807\uff0c\u8be5\u6307\u6807\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u80fd\u63d0\u4f9b\u6bd4\u73b0\u6709\u56fe\u50cf\u6307\u6807\u66f4\u6df1\u5165\u7684\u6d1e\u5bdf\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\u67d0\u4e9b\u6df1\u5ea6\u7279\u5f81\u8ddd\u79bb\u4e0eHS\u9ad8\u5ea6\u76f8\u5173\uff0c\u53ef\u7528\u4e8e\u4f18\u5316GSR\u6a21\u578b\u4ee5\u51cf\u8f7b\u5e7b\u89c9\u3002"}}
{"id": "2507.14334", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14334", "abs": "https://arxiv.org/abs/2507.14334", "authors": ["Hui Yang", "Jiaoyan Chen", "Yuan He", "Yongsheng Gao", "Ian Horrocks"], "title": "Language Models as Ontology Encoders", "comment": null, "summary": "OWL (Web Ontology Language) ontologies which are able to formally represent\ncomplex knowledge and support semantic reasoning have been widely adopted\nacross various domains such as healthcare and bioinformatics. Recently,\nontology embeddings have gained wide attention due to its potential to infer\nplausible new knowledge and approximate complex reasoning. However, existing\nmethods face notable limitations: geometric model-based embeddings typically\noverlook valuable textual information, resulting in suboptimal performance,\nwhile the approaches that incorporate text, which are often based on language\nmodels, fail to preserve the logical structure. In this work, we propose a new\nontology embedding method OnT, which tunes a Pretrained Language Model (PLM)\nvia geometric modeling in a hyperbolic space for effectively incorporating\ntextual labels and simultaneously preserving class hierarchies and other\nlogical relationships of Description Logic EL. Extensive experiments on four\nreal-world ontologies show that OnT consistently outperforms the baselines\nincluding the state-of-the-art across both tasks of prediction and inference of\naxioms. OnT also demonstrates strong potential in real-world applications,\nindicated by its robust transfer learning abilities and effectiveness in real\ncases of constructing a new ontology from SNOMED CT. Data and code are\navailable at https://github.com/HuiYang1997/OnT.", "AI": {"tldr": "OnT\u662f\u4e00\u79cd\u65b0\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\u6765\u7ed3\u5408\u6587\u672c\u4fe1\u606f\u548c\u4fdd\u7559\u903b\u8f91\u7ed3\u6784\uff0c\u5e76\u5728\u5404\u79cd\u4efb\u52a1\u548c\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u6587\u672c\u4fe1\u606f\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u7559\u903b\u8f91\u7ed3\u6784\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "OnT\u901a\u8fc7\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\u6765\u8c03\u4f18\uff0c\u4ee5\u6709\u6548\u7ed3\u5408\u6587\u672c\u6807\u7b7e\uff0c\u540c\u65f6\u4fdd\u7559\u903b\u8f91\u7ed3\u6784\u548c\u63cf\u8ff0\u903b\u8f91EL\u7684\u5c42\u6b21\u7ed3\u6784\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u672c\u4f53\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOnT\u5728\u516c\u7406\u9884\u6d4b\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u5f3a\u5927\u7684\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u548c\u6709\u6548\u6027\u3002", "conclusion": "OnT\u5728\u516c\u7406\u9884\u6d4b\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5305\u62ec\u6700\u5148\u8fdb\u6280\u672f\u5728\u5185\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6784\u5efa\u6765\u81eaSNOMED CT\u7684\u65b0\u672c\u4f53\u65b9\u9762\u663e\u793a\u51fa\u5f3a\u5927\u7684\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.14435", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14435", "abs": "https://arxiv.org/abs/2507.14435", "authors": ["Dongdong An", "Tao Zhang", "Qiaoling Xu", "Hailing Guo", "Majeed Ur Rehman", "Dante M. Kennes", "Angel Rubio", "Lei Wang", "Lede Xian"], "title": "Critical angles and one-dimensional moir\u00e9 physics in twisted rectangular lattices", "comment": "7 pages, 3 figures", "summary": "Engineering moir\\'e superlattices in van der Waals heterostructures provides\nfundamental control over emergent electronic, structural, and optical\nproperties allowing to affect topological and correlated phenomena. This\ncontrol is achieved through imposed periodic modulation of potentials and\ntargeted modifications of symmetries. For twisted bilayers of van der Waals\nmaterials with rectangular lattices, such as PdSe2, this work shows that\none-dimensional (1D) moir\\'e patterns emerge universally. This emergence is\ndriven by a series of critical twist angles (CAs). We investigate the geometric\norigins of these unique 1D moir\\'e patterns and develop a universal\nmathematical framework to predict the CAs in twisted rectangular lattices.\nThrough a density functional theory (DFT) description of the electronic\nproperties of twisted bilayer PdSe2, we further reveal directionally localized\nflat band structures, localized charge densities and strong spin-orbit coupling\nalong the dispersive direction which points to the emergence of an effectively\n1D strongly spin-orbit coupled electronic systems. This establishes twisted\nrectangular systems as a unique platform for engineering low-symmetry moir\\'e\npatterns, low-dimensional strongly correlated and topological physics, and\nspatially selective quantum phases beyond the isotropic paradigms of hexagonal\nmoir\\'e materials.", "AI": {"tldr": "PdSe2\u7b49\u77e9\u5f62\u6676\u683c\u6750\u6599\u7684\u626d\u8f6c\u53cc\u5c42\u7ed3\u6784\u53ef\u4ee5\u5f62\u62101D Moir\u00e9\u8d85\u6676\u683c\uff0c\u5e76\u4ea7\u751f1D\u5e73\u5e26\u548c\u5f3a\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u6548\u5e94\uff0c\u4e3a\u4f4e\u7ef4\u5ea6\u7269\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5e73\u53f0\u3002", "motivation": "\u5de5\u7a0b\u5316\u7684Moir\u00e9\u8d85\u6676\u683c\u5728\u63a7\u5236\u6d8c\u73b0\u7684\u7535\u5b50\u3001\u7ed3\u6784\u548c\u5149\u5b66\u6027\u8d28\u65b9\u9762\u53d1\u6325\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u4ece\u800c\u5f71\u54cd\u62d3\u6251\u548c\u76f8\u5173\u73b0\u8c61\u3002\u4f46\u662f\uff0c\u4ee5\u5f80\u5bf9Moir\u00e9\u8d85\u6676\u683c\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5177\u6709\u516d\u65b9\u6676\u683c\u7684\u6750\u6599\u4e0a\uff0c\u800c\u5177\u6709\u77e9\u5f62\u6676\u683c\u7684\u6750\u6599\uff08\u5982PdSe2\uff09\u5728Moir\u00e9\u8d85\u6676\u683c\u5de5\u7a0b\u65b9\u9762\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u63cf\u8ff0\u626d\u8f6c\u53cc\u5c42PdSe2\u7684\u7535\u5b50\u7279\u6027\uff0c\u63ed\u793a\u4e86\u65b9\u5411\u6027\u5c40\u57df\u5316\u7684\u5e73\u5766\u80fd\u5e26\u7ed3\u6784\u3001\u5c40\u57df\u5316\u7535\u8377\u5bc6\u5ea6\u4ee5\u53ca\u6cbf\u8272\u6563\u65b9\u5411\u7684\u5f3a\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u3002", "result": "\u5728\u5177\u6709\u77e9\u5f62\u6676\u683c\u7684\u626d\u8f6c\u53cc\u5c42\u8303\u5fb7\u534e\u6750\u6599\uff08\u5982PdSe2\uff09\u4e2d\uff0c1D Moir\u00e9\u6a21\u5f0f\u666e\u904d\u51fa\u73b0\u3002\u7814\u7a76\u4e86\u8fd9\u4e9b\u72ec\u7279\u76841D Moir\u00e9\u6a21\u5f0f\u7684\u51e0\u4f55\u8d77\u6e90\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u6570\u5b66\u6846\u67b6\u6765\u9884\u6d4b\u626d\u8f6c\u77e9\u77e9\u5f62\u6676\u683c\u4e2d\u7684\u4e34\u754c\u626d\u8f6c\u89d2\uff08CAs\uff09\u3002", "conclusion": "\u626d\u8f6c\u77e9\u7ea640%\u7684PdSe2\u53cc\u5c42\u6750\u6599\u4e2d\u51fa\u73b0\u76841D\u89d2\u5411\u80fd\u5e26\u548c1D\u81ea\u65cb\u8f68\u9053\u8026\u5408\u7535\u5b50\u7cfb\u7edf\uff0c\u4e3a\u4f4e\u5bf9\u79f0\u6027\u3001\u4f4e\u7ef4\u5ea6\u5f3a\u5173\u8054\u548c\u62d3\u6251\u7269\u7406\u5b66\u4ee5\u53ca\u7a7a\u95f4\u9009\u62e9\u6027\u91cf\u5b50\u76f8\u5de5\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u72ec\u7279\u7684\u5e73\u53f0\u3002"}}
{"id": "2507.14176", "categories": ["cs.LG", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14176", "abs": "https://arxiv.org/abs/2507.14176", "authors": ["Andr\u00e9s Morales-Forero", "Lili J. Rueda", "Ronald Herrera", "Samuel Bassetto", "Eric Coatanea"], "title": "Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection", "comment": null, "summary": "Artificial intelligence (AI) systems increasingly inform medical\ndecision-making, yet concerns about algorithmic bias and inequitable outcomes\npersist, particularly for historically marginalized populations. This paper\nintroduces the concept of Predictive Representativity (PR), a framework of\nfairness auditing that shifts the focus from the composition of the data set to\noutcomes-level equity. Through a case study in dermatology, we evaluated\nAI-based skin cancer classifiers trained on the widely used HAM10000 dataset\nand on an independent clinical dataset (BOSQUE Test set) from Colombia. Our\nanalysis reveals substantial performance disparities by skin phototype, with\nclassifiers consistently underperforming for individuals with darker skin,\ndespite proportional sampling in the source data. We argue that\nrepresentativity must be understood not as a static feature of datasets but as\na dynamic, context-sensitive property of model predictions. PR operationalizes\nthis shift by quantifying how reliably models generalize fairness across\nsubpopulations and deployment contexts. We further propose an External\nTransportability Criterion that formalizes the thresholds for fairness\ngeneralization. Our findings highlight the ethical imperative for post-hoc\nfairness auditing, transparency in dataset documentation, and inclusive model\nvalidation pipelines. This work offers a scalable tool for diagnosing\nstructural inequities in AI systems, contributing to discussions on equity,\ninterpretability, and data justice and fostering a critical re-evaluation of\nfairness in data-driven healthcare.", "AI": {"tldr": "AI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u5b58\u5728\u516c\u5e73\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u80a4\u8272\u4eba\u7fa4\u4e2d\u8868\u73b0\u4e0d\u4e00\u3002\u672c\u6587\u63d0\u51fa\u7684\u9884\u6d4b\u4ee3\u8868\u6027\uff08PR\uff09\u6846\u67b6\u901a\u8fc7\u5173\u6ce8\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u516c\u5e73\u6027\uff0c\u800c\u975e\u4ec5\u4ec5\u6570\u636e\u96c6\u6784\u6210\uff0c\u6765\u8bc4\u4f30\u548c\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5916\u90e8\u53ef\u8fc1\u79fb\u6027\u6807\u51c6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u5728\u6570\u636e\u6bd4\u4f8b\u5747\u8861\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u5728\u80a4\u8272\u8f83\u6df1\u4eba\u7fa4\u4e0a\u7684\u8868\u73b0\u4e5f\u66f4\u5dee\uff0c\u5f3a\u8c03\u4e86\u4e8b\u540e\u5ba1\u8ba1\u548c\u5305\u5bb9\u6027\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u5e26\u6765\u4e86\u7b97\u6cd5\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u7ed3\u679c\u7684\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u5728\u5386\u53f2\u4e0a\u88ab\u8fb9\u7f18\u5316\u7684\u4eba\u7fa4\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u516c\u5e73\u6027\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5c06\u5173\u6ce8\u70b9\u4ece\u6570\u636e\u96c6\u6784\u6210\u8f6c\u79fb\u5230\u7ed3\u679c\u5c42\u9762\u7684\u516c\u5e73\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u9884\u6d4b\u4ee3\u8868\u6027\uff08PR\uff09\u7684\u516c\u5e73\u6027\u5ba1\u8ba1\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u5916\u90e8\u53ef\u8fc1\u79fb\u6027\u6807\u51c6\u6765\u91cf\u5316\u6a21\u578b\u5728\u4e0d\u540c\u4e9a\u7fa4\u4f53\u548c\u90e8\u7f72\u73af\u5883\u4e2d\u7684\u516c\u5e73\u6027\u6cdb\u5316\u80fd\u529b\u3002\u901a\u8fc7\u5728HAM10000\u548cBOSQUE\u6570\u636e\u96c6\u4e0a\u5bf9\u76ae\u80a4\u764c\u5206\u7c7b\u5668\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u76ae\u80a4\u7c7b\u578b\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u5728\u76ae\u80a4\u764c\u5206\u7c7b\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cAI\u5206\u7c7b\u5668\u5728\u80a4\u8272\u8f83\u6df1\u7684\u4eba\u7fa4\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5c3d\u7ba1\u6570\u636e\u96c6\u4e2d\u53ef\u80fd\u5b58\u5728\u6bd4\u4f8b\u62bd\u6837\u3002\u8fd9\u8868\u660e\u4ec5\u6709\u6bd4\u4f8b\u62bd\u6837\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u516c\u5e73\u6027\u3002", "conclusion": "AI\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u7b97\u6cd5\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u7ed3\u679c\u7684\u62c5\u5fe7\u4f9d\u7136\u5b58\u5728\uff0c\u5c24\u5176\u662f\u5728\u5386\u53f2\u4e0a\u88ab\u8fb9\u7f18\u5316\u7684\u4eba\u7fa4\u4e2d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u9884\u6d4b\u4ee3\u8868\u6027\uff08PR\uff09\u7684\u6982\u5ff5\uff0c\u8fd9\u662f\u4e00\u79cd\u516c\u5e73\u6027\u5ba1\u8ba1\u6846\u67b6\uff0c\u5b83\u5c06\u91cd\u70b9\u4ece\u6570\u636e\u96c6\u7684\u6784\u6210\u8f6c\u79fb\u5230\u7ed3\u679c\u5c42\u9762\u7684\u516c\u5e73\u6027\u3002\u901a\u8fc7\u5bf9\u76ae\u80a4\u79d1\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684HAM10000\u6570\u636e\u96c6\u548c\u6765\u81ea\u54e5\u4f26\u6bd4\u4e9a\u7684\u72ec\u7acb\u4e34\u5e8a\u6570\u636e\u96c6\uff08BOSQUE\u6d4b\u8bd5\u96c6\uff09\u4e0a\u8bad\u7ec3\u7684\u57fa\u4e8eAI\u7684\u76ae\u80a4\u764c\u5206\u7c7b\u5668\u3002\u6211\u4eec\u7684\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u76ae\u80a4\u7c7b\u578b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5c3d\u7ba1\u5728\u539f\u59cb\u6570\u636e\u4e2d\u8fdb\u884c\u4e86\u6bd4\u4f8b\u62bd\u6837\uff0c\u4f46\u5206\u7c7b\u5668\u5728\u80a4\u8272\u8f83\u6df1\u7684\u4eba\u7fa4\u4e2d\u7684\u8868\u73b0\u6301\u7eed\u4e0d\u4f73\u3002\u6211\u4eec\u8ba4\u4e3a\uff0c\u4ee3\u8868\u6027\u4e0d\u5e94\u88ab\u7406\u89e3\u4e3a\u6570\u636e\u96c6\u7684\u9759\u6001\u7279\u5f81\uff0c\u800c\u5e94\u88ab\u89c6\u4e3a\u6a21\u578b\u9884\u6d4b\u7684\u52a8\u6001\u3001\u60c5\u5883\u654f\u611f\u7684\u5c5e\u6027\u3002PR\u901a\u8fc7\u91cf\u5316\u6a21\u578b\u5728\u4e0d\u540c\u4e9a\u7fa4\u4f53\u548c\u90e8\u7f72\u73af\u5883\u4e2d\u7684\u516c\u5e73\u6027\u6cdb\u5316\u53ef\u9760\u6027\u6765\u5b9e\u73b0\u8fd9\u79cd\u8f6c\u53d8\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u4e00\u79cd\u5916\u90e8\u53ef\u8fc1\u79fb\u6027\u6807\u51c6\uff0c\u7528\u4e8e\u89c4\u8303\u516c\u5e73\u6027\u6cdb\u5316\u7684\u9608\u503c\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u4e8b\u540e\u516c\u5e73\u6027\u5ba1\u8ba1\u3001\u6570\u636e\u96c6\u6587\u6863\u900f\u660e\u5316\u4ee5\u53ca\u5305\u5bb9\u6027\u6a21\u578b\u9a8c\u8bc1\u6d41\u7a0b\u7684\u4f26\u7406\u5fc5\u8981\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5de5\u5177\u6765\u8bca\u65adAI\u7cfb\u7edf\u4e2d\u7684\u7ed3\u6784\u6027\u4e0d\u516c\u5e73\uff0c\u4e3a\u516c\u5e73\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u516c\u6b63\u6027\u7684\u8ba8\u8bba\u505a\u51fa\u8d21\u732e\uff0c\u5e76\u4fc3\u8fdb\u5bf9\u6570\u636e\u9a71\u52a8\u7684\u533b\u7597\u4fdd\u5065\u4e2d\u516c\u5e73\u6027\u7684\u6279\u5224\u6027\u91cd\u65b0\u8bc4\u4f30\u3002"}}
{"id": "2507.14382", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14382", "abs": "https://arxiv.org/abs/2507.14382", "authors": ["Tyler D. Dol\u017eal", "Emre Tekoglu", "Jong-Soo Bae", "Gi-Dong Sim", "Rodrigo Freitas", "Ju Li"], "title": "Atomistic Simulations of Short-range Ordering with Light Interstitials in Inconel Superalloys", "comment": null, "summary": "This study employed hybrid Monte Carlo Molecular Dynamics simulations to\ninvestigate the short-range ordering behavior of Ni-based superalloys doped\nwith boron or carbon. The simulations revealed that both boron and carbon\ndissociated from their host Ti atoms to achieve energetically favored ordering\nwith Cr, Mo, and Nb. Boron clusters formed as B2, surrounded by Mo, Nb, and Cr,\nwhile carbon preferentially clustered with Cr to form a Cr23C6 local motif and\nwith Nb to form Nb2C. Distinct preferences for interstitial sites were\nobserved, with boron favoring tetrahedral sites and carbon occupying octahedral\nsites. In the presence of a vacancy, B2 shifted from the tetrahedral site to\nthe vacancy, where it remained coordinated with Mo, Nb, and Cr. Similarly,\ncarbon utilized vacancies to form Nb2C clusters. Excess energy calculations\nshowed that B and C exhibited strong thermodynamic stability within their\nshort-range ordered configurations. However, under Ti-rich conditions, C was\nmore likely to segregate into TiC, despite preexisting ordering with Cr. This\nshift in stability suggests that increased Ti availability would alter carbide\nformation pathways, drawing C away from Cr-rich networks and promoting the\ndevelopment of TiC. Such redistribution may disrupt the continuity of Cr-based\ncarbide networks, which play a critical role in stabilizing grain boundaries\nand impeding crack propagation. These effects further underscore the impact of\ninterstitial-induced ordering on phase stability and microstructural evolution.\nThis work provides an atomistic perspective on how boron- and carbon-induced\nordering influences microstructure and mechanical properties. These findings\nhighlight the critical role of interstitial-induced short-range ordering and\ndemonstrate that this mechanism can be leveraged as a design principle to\nfine-tune alloy microstructures for specific engineering applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u6df7\u5408\u8499\u7279\u5361\u6d1b\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u53d1\u73b0\u954d\u57fa\u9ad8\u6e29\u5408\u91d1\u4e2d\u7684\u787c\u548c\u78b3\u4f18\u5148\u4e0eCr\u3001Mo\u3001Nb\u5f62\u6210\u6709\u5e8f\u7ed3\u6784\uff0c\u800c\u975eTi\u3002\u8fd9\u4e9b\u7ed3\u6784\u5f71\u54cd\u5408\u91d1\u7684\u5fae\u89c2\u7ed3\u6784\u548c\u529b\u5b66\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u53ef\u7528\u4e8e\u4f18\u5316\u5408\u91d1\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u6df1\u5165\u4e86\u89e3\u787c\u548c\u78b3\u5728\u954d\u57fa\u9ad8\u6e29\u5408\u91d1\u4e2d\u7684\u884c\u4e3a\uff0c\u4ee5\u53ca\u5b83\u4eec\u5982\u4f55\u5f71\u54cd\u5408\u91d1\u7684\u5fae\u89c2\u7ed3\u6784\u548c\u529b\u5b66\u6027\u80fd\uff0c\u672c\u7814\u7a76\u8fdb\u884c\u4e86\u76f8\u5173\u7684\u539f\u5b50\u5c3a\u5ea6\u6a21\u62df\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6df7\u5408\u8499\u7279\u5361\u6d1b\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86\u63ba\u6742\u787c\u6216\u78b3\u7684\u954d\u57fa\u9ad8\u6e29\u5408\u91d1\u7684\u77ed\u7a0b\u6709\u5e8f\u884c\u4e3a\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u787c\u548c\u78b3\u4f1a\u4eceTi\u539f\u5b50\u5904\u89e3\u79bb\uff0c\u5e76\u4f18\u5148\u4e0eCr\u3001Mo\u548cNb\u5f62\u6210\u66f4\u6709\u5229\u7684\u6709\u5e8f\u7ed3\u6784\u3002\u787c\u503e\u5411\u4e8e\u5f62\u6210B2\u7ed3\u6784\uff0c\u5e76\u88abMo\u3001Nb\u548cCr\u5305\u56f4\uff1b\u78b3\u5219\u4f18\u5148\u4e0eCr\u5f62\u6210Cr23C6\u5c40\u90e8\u7ed3\u6784\uff0c\u6216\u4e0eNb\u5f62\u6210Nb2C\u7ed3\u6784\u3002\u787c\u548c\u78b3\u5728\u95f4\u9699\u4f4d\u7f6e\u4e0a\u7684\u504f\u597d\u4e5f\u4e0d\u540c\uff0c\u787c\u503e\u5411\u4e8e\u56db\u9762\u4f53\u4f4d\u7f6e\uff0c\u800c\u78b3\u503e\u5411\u4e8e\u5360\u7528\u516b\u9762\u4f53\u4f4d\u7f6e\u3002\u5728\u7a7a\u4f4d\u5b58\u5728\u65f6\uff0c\u787c\u548c\u78b3\u90fd\u4f1a\u5229\u7528\u7a7a\u4f4d\u5f62\u6210\u66f4\u7a33\u5b9a\u7684\u7ed3\u6784\u3002\u787c\u548c\u78b3\u5728\u77ed\u7a0b\u6709\u5e8f\u7ed3\u6784\u4e2d\u5177\u6709\u5f88\u5f3a\u7684\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u3002\u7136\u800c\uff0c\u5728\u5bccTi\u6761\u4ef6\u4e0b\uff0c\u5373\u4f7f\u5b58\u5728\u4e0eCr\u7684\u6709\u5e8f\u7ed3\u6784\uff0c\u78b3\u4e5f\u66f4\u503e\u5411\u4e8e\u5f62\u6210TiC\u3002\u8fd9\u79cd\u7a33\u5b9a\u6027\u8f6c\u53d8\u8868\u660e\uff0cTi\u542b\u91cf\u7684\u589e\u52a0\u4f1a\u6539\u53d8\u78b3\u5316\u7269\u7684\u5f62\u6210\u8def\u5f84\uff0c\u5c06\u78b3\u4ece\u5bccCr\u7f51\u7edc\u4e2d\u8f6c\u79fb\u51fa\u6765\uff0c\u4fc3\u8fdbTiC\u7684\u5f62\u6210\u3002\u8fd9\u79cd\u91cd\u65b0\u5206\u5e03\u53ef\u80fd\u4f1a\u7834\u574f\u4f5c\u4e3a\u6676\u754c\u7a33\u5b9a\u5242\u548c\u963b\u788d\u88c2\u7eb9\u6269\u5c55\u7684\u5173\u952e\u7684\u5bccCr\u78b3\u5316\u7269\u7f51\u7edc\u7684\u8fde\u7eed\u6027\u3002", "conclusion": "\u787c\u548c\u78b3\u5728\u954d\u57fa\u9ad8\u6e29\u5408\u91d1\u4e2d\u503e\u5411\u4e8e\u4e0eCr\u3001Mo\u548cNb\u5f62\u6210\u6709\u5e8f\u7ed3\u6784\uff0c\u800c\u4e0d\u662f\u4e0eTi\u7ed3\u5408\u3002\u8fd9\u4e9b\u539f\u5b50\u5c3a\u5ea6\u7684\u7ed3\u6784\u53d8\u5316\u4f1a\u5f71\u54cd\u5408\u91d1\u7684\u5fae\u89c2\u7ed3\u6784\u548c\u529b\u5b66\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5bf9\u6676\u754c\u7a33\u5b9a\u6027\u548c\u88c2\u7eb9\u6269\u5c55\u6709\u91cd\u8981\u5f71\u54cd\u3002\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u95f4\u9699\u539f\u5b50\u8bf1\u5bfc\u7684\u77ed\u7a0b\u6709\u5e8f\u5bf9\u76f8\u7a33\u5b9a\u6027\u548c\u5fae\u89c2\u7ed3\u6784\u6f14\u53d8\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u53ef\u5c06\u6b64\u673a\u5236\u4f5c\u4e3a\u8bbe\u8ba1\u539f\u5219\u6765\u4f18\u5316\u5408\u91d1\u6027\u80fd\u4ee5\u6ee1\u8db3\u7279\u5b9a\u5de5\u7a0b\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2507.14450", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14450", "abs": "https://arxiv.org/abs/2507.14450", "authors": ["Jin Lu", "Linhan Fang", "Fan Jiang", "Xingpeng Li"], "title": "A Black Start Strategy for Hydrogen-integrated Renewable Grids with Energy Storage Systems", "comment": "6 pages, 5 figures", "summary": "With the increasing integration of renewable energy, the reliability and\nresilience of modern power systems are of vital significance. However,\nlarge-scale blackouts caused by natural disasters or equipment failures remain\na significant threat, necessitating effective restoration strategies. This\nstudy proposes novel black start models for modern power systems that integrate\nfuel cells and battery storage, recognizing their distinct characteristics and\ncontributions to grid resilience. These models specifically address the\nrestoration of electrical grids, including the energization paths and time of\nthe transmission network, while accounting for the unique power output traits\nof fuel cells and the energy storage capacity of batteries as black start\nresources. Black start simulations, comparing the generator startup sequence\n(GSUS) with fuel cell versus battery systems, are performed on the IEEE 39-bus\nsystem. We conduct sensitivity analyses on fuel cell capacity, battery storage\ncapacity, initial state of charge (SOC), and resource locations to identify\noptimal scenarios for black start operations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u7ed3\u5408\u71c3\u6599\u7535\u6c60\u548c\u7535\u6c60\u50a8\u80fd\u7684\u65b0\u578b\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u9ed1\u542f\u52a8\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u4e86\u4eff\u771f\u548c\u654f\u611f\u6027\u5206\u6790\uff0c\u4ee5\u4f18\u5316\u9ed1\u542f\u52a8\u64cd\u4f5c\u3002", "motivation": "\u968f\u7740\u53ef\u518d\u751f\u80fd\u6e90\u7684\u6574\u5408\uff0c\u7535\u529b\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u6062\u590d\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u5927\u89c4\u6a21\u505c\u7535\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u5a01\u80c1\uff0c\u9700\u8981\u6709\u6548\u7684\u6062\u590d\u7b56\u7565\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u65b0\u578b\u9ed1\u542f\u52a8\u6a21\u578b\uff0c\u8003\u8651\u71c3\u6599\u7535\u6c60\u548c\u7535\u6c60\u50a8\u80fd\u7684\u7279\u6027\uff0c\u5e76\u8fdb\u884c\u4eff\u771f\u548c\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u6bd4\u8f83\u4e86\u71c3\u6599\u7535\u6c60\u548c\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u7684\u53d1\u7535\u673a\u542f\u52a8\u987a\u5e8f\uff0c\u5e76\u8fdb\u884c\u4e86\u654f\u611f\u6027\u5206\u6790\uff0c\u4ee5\u786e\u5b9a\u6700\u4f73\u7684\u9ed1\u542f\u52a8\u8fd0\u884c\u573a\u666f\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u7ed3\u5408\u71c3\u6599\u7535\u6c60\u548c\u7535\u6c60\u50a8\u80fd\u7684\u65b0\u578b\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u9ed1\u542f\u52a8\u6a21\u578b\uff0c\u5e76\u5bf9IEEE 39\u8282\u70b9\u7cfb\u7edf\u8fdb\u884c\u4e86\u4eff\u771f\u548c\u654f\u611f\u6027\u5206\u6790\uff0c\u4ee5\u4f18\u5316\u9ed1\u542f\u52a8\u64cd\u4f5c\u3002"}}
{"id": "2507.14371", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14371", "abs": "https://arxiv.org/abs/2507.14371", "authors": ["Ammara Ammara", "Paolo Facchi", "Saverio Pascazio", "Francesco V. Pepe", "Debmalya Das"], "title": "Quasi-degenerate resonant eigenstate doublets of two quantum emitters in a closed waveguide", "comment": "8 pages, 6 figures", "summary": "The physics of systems of quantum emitters is significantly influenced by the\nrelation between their spatial separation and the wavelength of the emitted\nphotons. If the distance that separates a pair of emitters meets specific\nresonance conditions, the photons produced from decay may destructively\ninterfere. In an infinite-wavelength setting, this effect gives rise to bound\nstates in the continuum, where a photon remains confined in between the\nemitter. In the case of a finite-length waveguide with two periodic boundary\nconditions, the relevant distances become two, leading to states in which a\nphoton is confined in either the shorter or the longer path that connects the\nemitters. If the ratio of the shorter and the longer path is a rational number,\nthese two kinds of resonant states are allowed to co-exist in the same\nHamiltonian. In this paper, we investigate the existence of quasi-degenerate\nresonant doublets of a pair of identical emitters coupled to a linear waveguide\nmode. The states that form the doublet are searched among the ones in which a\nsingle excitation tends to remain bound to the emitters. We investigate the\nspectrum in a finite range around degeneracy points to check whether the\ndoublet remains well separated from the closest eigenvalues in the spectrum.\nThe identification of quasi-degenerate doublets opens the possibility to\nmanipulate the emitters-waveguide system as an effectively two-level system in\nspecific energy ranges, providing an innovative tool for quantum technology\ntasks.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e24\u4e2a\u53d1\u5c04\u5668\u8026\u5408\u5230\u6ce2\u5bfc\u4e2d\u7684\u5171\u632f\u53cc\u5cf0\uff0c\u4e3a\u91cf\u5b50\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002", "motivation": "\u91cf\u5b50\u53d1\u5c04\u5668\u7cfb\u7edf\u7684\u7269\u7406\u6027\u8d28\u663e\u8457\u53d7\u5230\u5176\u7a7a\u95f4\u5206\u79bb\u4e0e\u53d1\u5c04\u5149\u5b50\u6ce2\u957f\u4e4b\u95f4\u5173\u7cfb\u7684\u5f71\u54cd\u3002\u5728\u7279\u5b9a\u5171\u632f\u6761\u4ef6\u4e0b\uff0c\u5149\u5b50\u53ef\u80fd\u53d1\u751f\u7834\u574f\u6027\u5e72\u6d89\uff0c\u4ece\u800c\u5f62\u6210\u675f\u7f1a\u6001\u3002", "method": "\u7814\u7a76\u4e86\u4e24\u4e2a\u76f8\u540c\u53d1\u5c04\u5668\u8026\u5408\u5230\u7ebf\u6027\u6ce2\u5bfc\u6a21\u5f0f\u4e0b\u51c6\u7b80\u5e76\u5171\u632f\u53cc\u5cf0\u7684\u5b58\u5728\u6027\u3002\u641c\u5bfb\u4e86\u5728\u5355\u4e2a\u6fc0\u53d1\u503e\u5411\u4e8e\u675f\u7f1a\u5728\u53d1\u5c04\u5668\u4e0a\u7684\u72b6\u6001\u4e2d\u7684\u53cc\u5cf0\u6001\uff0c\u5e76\u7814\u7a76\u4e86\u9000\u5316\u70b9\u9644\u8fd1\u7684\u8c31\uff0c\u4ee5\u68c0\u67e5\u53cc\u5cf0\u662f\u5426\u4e0e\u8c31\u4e2d\u6700\u63a5\u8fd1\u7684\u7279\u5f81\u503c\u826f\u597d\u5206\u79bb\u3002", "result": "\u5728\u6709\u9650\u957f\u5ea6\u6ce2\u5bfc\u4e2d\uff0c\u5f53\u77ed\u8def\u5f84\u4e0e\u957f\u8def\u5f84\u7684\u6bd4\u4f8b\u4e3a\u6709\u7406\u6570\u65f6\uff0c\u4e24\u79cd\u7c7b\u578b\u7684\u5171\u632f\u6001\uff08\u675f\u7f1a\u5728\u8f83\u77ed\u6216\u8f83\u957f\u8def\u5f84\u4e2d\uff09\u53ef\u4ee5\u5171\u5b58\u4e8e\u540c\u4e00\u54c8\u5bc6\u987f\u91cf\u4e2d\u3002\u5f53\u77ed\u8def\u5f84\u4e0e\u957f\u8def\u5f84\u7684\u6bd4\u4f8b\u4e3a\u6709\u7406\u6570\u65f6\uff0c\u8fd9\u4e24\u79cd\u7c7b\u578b\u7684\u5171\u632f\u6001\u53ef\u4ee5\u5171\u5b58\u4e8e\u540c\u4e00\u54c8\u5bc6\u987f\u91cf\u4e2d\u3002", "conclusion": "\u8bc6\u522b\u51fa\u7684\u51c6\u7b80\u5e76\u5171\u632f\u53cc\u5cf0\u4e3a\u91cf\u5b50\u6280\u672f\u4efb\u52a1\u63d0\u4f9b\u4e86\u64cd\u63a7\u53d1\u5c04\u5668-\u6ce2\u5bfc\u7cfb\u7edf\u4f5c\u4e3a\u6709\u6548\u4e24\u80fd\u7ea7\u7cfb\u7edf\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.14231", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14231", "abs": "https://arxiv.org/abs/2507.14231", "authors": ["Khalid Hasan", "Jamil Saquer"], "title": "Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media", "comment": "The 37th International Conference on Software Engineering & Knowledge\n  Engineering, SEKE 2025 (camera-ready)", "summary": "Bipolar disorder is a chronic mental illness frequently underdiagnosed due to\nsubtle early symptoms and social stigma. This paper explores the advanced\nnatural language processing (NLP) models for recognizing signs of bipolar\ndisorder based on user-generated social media text. We conduct a comprehensive\nevaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,\nDistilBERT) and Long Short Term Memory (LSTM) models based on contextualized\n(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed\non a large, annotated dataset of Reddit posts after confirming their validity\nthrough sentiment variance and judgmental analysis. Our results demonstrate\nthat RoBERTa achieves the highest performance among transformer models with an\nF1 score of ~98% while LSTM models using BERT embeddings yield nearly identical\nresults. In contrast, LSTMs trained on static embeddings fail to capture\nmeaningful patterns, scoring near-zero F1. These findings underscore the\ncritical role of contextual language modeling in detecting bipolar disorder. In\naddition, we report model training times and highlight that DistilBERT offers\nan optimal balance between efficiency and accuracy. In general, our study\noffers actionable insights for model selection in mental health NLP\napplications and validates the potential of contextualized language models to\nsupport early bipolar disorder screening.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528Transformer\u548cLSTM\u6a21\u578b\u5206\u6790Reddit\u5e16\u5b50\uff0c\u4ee5\u8bc6\u522b\u53cc\u76f8\u60c5\u611f\u969c\u788d\u7684\u8ff9\u8c61\u3002RoBERTa\u548cBERT\u5d4c\u5165\u7684LSTM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08F1\u7ea698%\uff09\uff0c\u800c\u9759\u6001\u5d4c\u5165\u7684LSTM\u6a21\u578b\u6548\u679c\u4e0d\u4f73\u3002DistilBERT\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u5747\u8861\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u5728\u65e9\u671f\u7b5b\u67e5\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u53cc\u76f8\u60c5\u611f\u969c\u788d\u662f\u4e00\u79cd\u5e38\u89c1\u7684\u6162\u6027\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\uff0c\u7531\u4e8e\u65e9\u671f\u75c7\u72b6\u4e0d\u660e\u663e\u548c\u793e\u4f1a\u7684\u6c61\u540d\u5316\uff0c\u5e38\u5e38\u88ab\u6f0f\u8bca\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6a21\u578b\u8bc6\u522b\u7528\u6237\u751f\u6210\u7684\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u4e2d\u53cc\u76f8\u60c5\u611f\u969c\u788d\u7684\u8ff9\u8c61\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4f7f\u7528\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6a21\u578b\u8bc6\u522b\u7528\u6237\u751f\u6210\u7684\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u4e2d\u53cc\u76f8\u60c5\u611f\u969c\u788d\u8ff9\u8c61\u3002\u6211\u4eec\u57fa\u4e8e\u4e0a\u4e0b\u6587\uff08BERT\uff09\u548c\u9759\u6001\uff08GloVe, Word2Vec\uff09\u8bcd\u5d4c\u5165\uff0c\u5bf9\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT\uff09\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u5b9e\u9a8c\u6570\u636e\u6765\u81ea\u6807\u6ce8\u8fc7\u7684Reddit\u5e16\u5b50\uff0c\u5e76\u901a\u8fc7\u60c5\u611f\u65b9\u5dee\u548c\u5224\u65ad\u5206\u6790\u786e\u8ba4\u4e86\u5176\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cRoBERTa\u5728Transformer\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u7ea6\u4e3a98%\uff0c\u800c\u4f7f\u7528BERT\u5d4c\u5165\u7684LSTM\u6a21\u578b\u53d6\u5f97\u4e86\u76f8\u4f3c\u7684\u7ed3\u679c\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u57fa\u4e8e\u9759\u6001\u5d4c\u5165\u8bad\u7ec3\u7684LSTM\u6a21\u578b\u672a\u80fd\u6355\u6349\u5230\u6709\u610f\u4e49\u7684\u6a21\u5f0f\uff0cF1\u5206\u6570\u63a5\u8fd1\u4e8e\u96f6\u3002\u6b64\u5916\uff0cDistilBERT\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u4f7f\u7528\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u53cc\u76f8\u60c5\u611f\u969c\u788d\u7684\u6f5c\u529b\uff0c\u4e3a\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u5e76\u9a8c\u8bc1\u4e86\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u5728\u652f\u6301\u65e9\u671f\u53cc\u76f8\u60c5\u611f\u969c\u788d\u7b5b\u67e5\u65b9\u9762\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.15399", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15399", "abs": "https://arxiv.org/abs/2507.15399", "authors": ["Etai Sella", "Noam Atia", "Ron Mokady", "Hadar Averbuch-Elor"], "title": "Blended Point Cloud Diffusion for Localized Text-guided Shape Editing", "comment": "Accepted to ICCV 2025. Project Page:\n  https://tau-vailab.github.io/BlendedPC/", "summary": "Natural language offers a highly intuitive interface for enabling localized\nfine-grained edits of 3D shapes. However, prior works face challenges in\npreserving global coherence while locally modifying the input 3D shape. In this\nwork, we introduce an inpainting-based framework for editing shapes represented\nas point clouds. Our approach leverages foundation 3D diffusion models for\nachieving localized shape edits, adding structural guidance in the form of a\npartial conditional shape, ensuring that other regions correctly preserve the\nshape's identity. Furthermore, to encourage identity preservation also within\nthe local edited region, we propose an inference-time coordinate blending\nalgorithm which balances reconstruction of the full shape with inpainting at a\nprogression of noise levels during the inference process. Our coordinate\nblending algorithm seamlessly blends the original shape with its edited\nversion, enabling a fine-grained editing of 3D shapes, all while circumventing\nthe need for computationally expensive and often inaccurate inversion.\nExtensive experiments show that our method outperforms alternative techniques\nacross a wide range of metrics that evaluate both fidelity to the original\nshape and also adherence to the textual description.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u76843D\u5f62\u72b6\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u54083D\u6269\u6563\u6a21\u578b\u548c\u5750\u6807\u6df7\u5408\u7b97\u6cd5\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u5c40\u90e8\u7f16\u8f91\uff0c\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u5bf93D\u5f62\u72b6\u8fdb\u884c\u76f4\u89c2\u7684\u3001\u5c40\u90e8\u7ec6\u7c92\u5ea6\u7684\u7f16\u8f91\uff0c\u540c\u65f6\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u5728\u5c40\u90e8\u4fee\u6539\u65f6\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u57fa\u4e8e\u4fee\u590d\u7684\u6846\u67b6\uff0c\u7ed3\u54083D\u6269\u6563\u6a21\u578b\u548c\u7ed3\u6784\u5f15\u5bfc\uff08\u5982\u90e8\u5206\u6761\u4ef6\u5f62\u72b6\uff09\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u91c7\u7528\u5750\u6807\u6df7\u5408\u7b97\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u5c40\u90e8\u7f16\u8f91\u548c\u8eab\u4efd\u4fdd\u6301\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u672c\u65b9\u6cd5\u5728\u8bc4\u4f30\u539f\u59cb\u5f62\u72b6\u4fdd\u771f\u5ea6\u548c\u9075\u5faa\u6587\u672c\u63cf\u8ff0\u65b9\u9762\uff0c\u4f18\u4e8e\u5176\u4ed6\u6280\u672f\u3002", "conclusion": "\u672c\u65b9\u6cd5\u901a\u8fc7\u878d\u5408\u539f\u59cb\u5f62\u72b6\u548c\u7f16\u8f91\u540e\u7684\u5f62\u72b6\uff0c\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u8fdb\u884c\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u5bf93D\u5f62\u72b6\u7684\u7ec6\u7c92\u5ea6\u7f16\u8f91\uff0c\u5e76\u4fdd\u6301\u4e86\u539f\u59cb\u5f62\u72b6\u7684\u5b8c\u6574\u6027\uff0c\u540c\u65f6\u6ee1\u8db3\u6587\u672c\u63cf\u8ff0\u7684\u8981\u6c42\u3002"}}
{"id": "2507.15734", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2507.15734", "abs": "https://arxiv.org/abs/2507.15734", "authors": ["Jules Lecomte", "Konrad Zinner", "Michael Neumeier", "Axel von Arnim"], "title": "TONUS: Neuromorphic human pose estimation for artistic sound co-creation", "comment": "Published at the International Joint Conference on Neural Networks\n  2025 in the special track on HUMAN-AI INTERACTION IN CREATIVE ARTS AND\n  SCIENCES", "summary": "Human machine interaction is a huge source of inspiration in today's media\nart and digital design, as machines and humans merge together more and more.\nIts place in art reflects its growing applications in industry, such as\nrobotics. However, those interactions often remains too technical and\nmachine-driven for people to really engage into. On the artistic side, new\ntechnologies are often not explored in their full potential and lag a bit\nbehind, so that state-of-the-art research does not make its way up to museums\nand exhibitions. Machines should support people's imagination and poetry in a\nseamless interface to their body or soul. We propose an artistic sound\ninstallation featuring neuromorphic body sensing to support a direct yet non\nintrusive interaction with the visitor with the purpose of creating sound\nscapes together with the machine. We design a neuromorphic multihead human pose\nestimation neural sensor that shapes sound scapes and visual output with fine\nbody movement control. In particular, the feature extractor is a spiking neural\nnetwork tailored for a dedicated neuromorphic chip. The visitor, immersed in a\nsound atmosphere and a neurally processed representation of themselves that\nthey control, experience the dialogue with a machine that thinks neurally,\nsimilarly to them.", "AI": {"tldr": "\u901a\u8fc7\u795e\u7ecf\u5f62\u6001\u8eab\u4f53\u4f20\u611f\u6280\u672f\uff0c\u521b\u9020\u4e86\u4e00\u4e2a\u827a\u672f\u88c5\u7f6e\uff0c\u5b9e\u73b0\u4e86\u4eba\u4e0e\u673a\u5668\u4e4b\u95f4\u66f4\u81ea\u7136\u3001\u66f4\u5bcc\u6709\u8bd7\u610f\u7684\u4ea4\u4e92\uff0c\u5171\u540c\u751f\u6210\u58f0\u97f3\u666f\u89c2\u3002", "motivation": "\u5f53\u524d\u4eba\u673a\u4ea4\u4e92\u5728\u827a\u672f\u548c\u5de5\u4e1a\u9886\u57df\u867d\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5f80\u5f80\u8fc7\u4e8e\u6280\u672f\u5316\u548c\u4ee5\u673a\u5668\u4e3a\u4e3b\u5bfc\uff0c\u672a\u80fd\u5145\u5206\u6fc0\u53d1\u4eba\u7684\u60f3\u8c61\u529b\u548c\u8bd7\u610f\u3002\u73b0\u6709\u6280\u672f\u5728\u827a\u672f\u9886\u57df\u7684\u5e94\u7528\u4e5f\u672a\u80fd\u5b8c\u5168\u53d1\u6325\u5176\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u81ea\u7136\u3001\u66f4\u5177\u8bd7\u610f\u7684\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u795e\u7ecf\u5f62\u6001\u591a\u5934\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u795e\u7ecf\u7f51\u7edc\u4f20\u611f\u5668\uff0c\u8be5\u4f20\u611f\u5668\u80fd\u591f\u901a\u8fc7\u7cbe\u7ec6\u7684\u8eab\u4f53\u52a8\u4f5c\u63a7\u5236\u6765\u5851\u9020\u58f0\u97f3\u666f\u89c2\u548c\u89c6\u89c9\u8f93\u51fa\u3002\u5176\u4e2d\uff0c\u7279\u5f81\u63d0\u53d6\u5668\u662f\u4e3a\u4e13\u7528\u795e\u7ecf\u5f62\u6001\u82af\u7247\u91cf\u8eab\u5b9a\u5236\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u53c2\u89c2\u8005\u6c89\u6d78\u5728\u58f0\u97f3\u6c1b\u56f4\u548c\u7531\u795e\u7ecf\u5904\u7406\u7684\u81ea\u8eab\u6620\u5c04\u4e2d\uff0c\u4f53\u9a8c\u5230\u4e0e\u4e00\u4e2a\u4e0e\u4ed6\u4eec\u4e00\u6837\u8fdb\u884c\u795e\u7ecf\u601d\u8003\u7684\u673a\u5668\u7684\u5bf9\u8bdd\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u4eba\u4e0e\u673a\u5668\u7684\u5171\u521b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u827a\u672f\u88c5\u7f6e\uff0c\u5229\u7528\u795e\u7ecf\u5f62\u6001\u8eab\u4f53\u4f20\u611f\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u4eba\u4e0e\u673a\u5668\u4e4b\u95f4\u66f4\u5177\u8bd7\u610f\u548c\u6c89\u6d78\u5f0f\u7684\u4e92\u52a8\uff0c\u5171\u540c\u521b\u9020\u58f0\u97f3\u666f\u89c2\u3002"}}
{"id": "2507.15465", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15465", "abs": "https://arxiv.org/abs/2507.15465", "authors": ["Sungmin Yun", "Seonyong Park", "Hwayong Nam", "Younjoo Lee", "Gunjun Lee", "Kwanhee Kyung", "Sangpyo Kim", "Nam Sung Kim", "Jongmin Kim", "Hyungyo Kim", "Juhwan Cho", "Seungmin Baek", "Jung Ho Ahn"], "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts", "comment": "15 pages, 11 figures", "summary": "Computational workloads composing traditional Transformer models are starkly\nbifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic\nintensity, while feedforward layers are compute-bound. This dichotomy has long\nmotivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent\nAttention (MLA) and Mixture-of-Experts (MoE), challenge the premise of\nspecialized attention hardware. We make two key observations. First, the\narithmetic intensity of MLA is over two orders of magnitude greater than that\nof MHA, shifting it close to a compute-bound regime well-suited for modern\naccelerators like GPUs. Second, by distributing MoE experts across a pool of\naccelerators, their arithmetic intensity can be tuned through batching to match\nthat of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware.\nThe central challenge for next-generation Transformers is no longer\naccelerating a single memory-bound layer. Instead, the focus must shift to\ndesigning balanced systems with sufficient compute, memory capacity, memory\nbandwidth, and high-bandwidth interconnects to manage the diverse demands of\nlarge-scale models.", "AI": {"tldr": "Recent Transformer architectures like MLA and MoE reduce the need for specialized attention hardware by increasing arithmetic intensity and balancing workloads. Future efforts should focus on creating balanced systems for large-scale models.", "motivation": "The motivation is to re-evaluate the necessity of specialized hardware for Transformer models in light of recent architectural innovations like MLA and MoE, which alter the computational profile of attention mechanisms.", "method": "The paper analyzes the architectural shifts in Transformer models, specifically MLA and MoE, by examining their computational characteristics (memory-bound vs. compute-bound, arithmetic intensity) and comparing them to traditional MHA. It argues that these shifts challenge the need for specialized attention hardware.", "result": "Recent architectural shifts, including MLA and MoE, have significantly changed the computational landscape of Transformer models. MLA boasts an arithmetic intensity over two orders of magnitude greater than MHA, moving it towards a compute-bound regime. MoE layers, when distributed across accelerators, can have their arithmetic intensity tuned via batching to match dense layers, leading to a more balanced computational profile. Consequently, the need for specialized attention hardware is diminishing.", "conclusion": "The architectural shifts in Transformer models, such as MLA and MoE, reduce the need for specialized attention hardware by increasing arithmetic intensity and enabling better load balancing, respectively. The focus for future Transformer development should be on creating balanced systems that cater to the diverse computational demands of large-scale models."}}
{"id": "2507.15124", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2507.15124", "abs": "https://arxiv.org/abs/2507.15124", "authors": ["Md Jahangir Alam", "Ismail Hossain", "Sai Puppala", "Sajedul Talukder"], "title": "Comprehensive Privacy Risk Assessment in Social Networks Using User Attributes Social Graphs and Text Analysis", "comment": "8 pages, 6 figures, HyperText 2025", "summary": "The rise of social networking platforms has amplified privacy threats as\nusers increasingly share sensitive information across profiles, content, and\nsocial connections. We present a Comprehensive Privacy Risk Scoring (CPRS)\nframework that quantifies privacy risk by integrating user attributes, social\ngraph structures, and user-generated content. Our framework computes risk\nscores across these dimensions using sensitivity, visibility, structural\nsimilarity, and entity-level analysis, then aggregates them into a unified risk\nscore. We validate CPRS on two real-world datasets: the SNAP Facebook Ego\nNetwork (4,039 users) and the Koo microblogging dataset (1M posts, 1M\ncomments). The average CPRS is 0.478 with equal weighting, rising to 0.501 in\ngraph-sensitive scenarios. Component-wise, graph-based risks (mean 0.52)\nsurpass content (0.48) and profile attributes (0.45). High-risk attributes\ninclude email, date of birth, and mobile number. Our user study with 100\nparticipants shows 85% rated the dashboard as clear and actionable, confirming\nCPRS's practical utility. This work enables personalized privacy risk insights\nand contributes a holistic, scalable methodology for privacy management. Future\ndirections include incorporating temporal dynamics and multimodal content for\nbroader applicability.", "AI": {"tldr": "\u63d0\u51fa CPRS \u6846\u67b6\uff0c\u91cf\u5316\u793e\u4ea4\u7f51\u7edc\u9690\u79c1\u98ce\u9669\uff0c\u6574\u5408\u7528\u6237\u5c5e\u6027\u3001\u793e\u4ea4\u56fe\u548c\u5185\u5bb9\u3002\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u7528\u6237\u7814\u7a76\u8bc1\u660e\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u5e73\u53f0\u7684\u5174\u8d77\u52a0\u5267\u4e86\u9690\u79c1\u5a01\u80c1\uff0c\u56e0\u4e3a\u7528\u6237\u8d8a\u6765\u8d8a\u591a\u5730\u5728\u4e2a\u4eba\u8d44\u6599\u3001\u5185\u5bb9\u548c\u793e\u4ea4\u8fde\u63a5\u4e2d\u5206\u4eab\u654f\u611f\u4fe1\u606f\u3002", "method": "CPRS \u6846\u67b6\u6574\u5408\u4e86\u7528\u6237\u5c5e\u6027\u3001\u793e\u4ea4\u56fe\u7ed3\u6784\u548c\u7528\u6237\u751f\u6210\u5185\u5bb9\uff0c\u5229\u7528\u654f\u611f\u6027\u3001\u53ef\u89c1\u6027\u3001\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u5b9e\u4f53\u7ea7\u522b\u5206\u6790\u6765\u8ba1\u7b97\u8de8\u7ef4\u5ea6\u7684\u98ce\u9669\u8bc4\u5206\uff0c\u6700\u540e\u5c06\u5b83\u4eec\u6c47\u603b\u4e3a\u7edf\u4e00\u7684\u98ce\u9669\u8bc4\u5206\u3002", "result": "CPRS \u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\uff08SNAP Facebook Ego Network \u548c Koo \u5fae\u535a\u5ba2\u6570\u636e\u96c6\uff09\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u5e73\u5747 CPRS \u4e3a 0.478\uff08\u7b49\u6743\u91cd\uff09\uff0c\u5728\u56fe\u654f\u611f\u573a\u666f\u4e0b\u4e3a 0.501\u3002\u5176\u4e2d\uff0c\u57fa\u4e8e\u56fe\u7684\u98ce\u9669\uff08\u5e73\u5747 0.52\uff09\u9ad8\u4e8e\u5185\u5bb9\uff080.48\uff09\u548c\u4e2a\u4eba\u8d44\u6599\u5c5e\u6027\uff080.45\uff09\u3002\u7535\u5b50\u90ae\u4ef6\u3001\u51fa\u751f\u65e5\u671f\u548c\u624b\u673a\u53f7\u7801\u662f\u9ad8\u98ce\u9669\u5c5e\u6027\u3002\u7528\u6237\u7814\u7a76\u8868\u660e 85% \u7684\u53c2\u4e0e\u8005\u8ba4\u4e3a\u4eea\u8868\u677f\u6e05\u6670\u4e14\u53ef\u64cd\u4f5c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a CPRS \u7684\u7efc\u5408\u9690\u79c1\u98ce\u9669\u8bc4\u5206\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u9690\u79c1\u98ce\u9669\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u7528\u6237\u5c5e\u6027\u3001\u793e\u4ea4\u56fe\u7ed3\u6784\u548c\u7528\u6237\u751f\u6210\u5185\u5bb9\u6765\u8ba1\u7b97\u98ce\u9669\u8bc4\u5206\uff0c\u5e76\u5df2\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u7528\u6237\u7814\u7a76\u8868\u660e\u8be5\u6846\u67b6\u5177\u6709\u5b9e\u7528\u6027\uff0c\u53ef\u4e3a\u4e2a\u6027\u5316\u9690\u79c1\u98ce\u9669\u6d1e\u5bdf\u63d0\u4f9b\u652f\u6301\uff0c\u5e76\u4e3a\u9690\u79c1\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6574\u4f53\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14569", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14569", "abs": "https://arxiv.org/abs/2507.14569", "authors": ["Yonatan Nakar", "Dana Ron"], "title": "Characterizing and Testing Configuration Stability in Two-Dimensional Threshold Cellular Automata", "comment": null, "summary": "We consider the problems of characterizing and testing the stability of\ncellular automata configurations that evolve on a two-dimensional torus\naccording to threshold rules with respect to the von-Neumann neighborhood.\nWhile stable configurations for Threshold-1 (OR) and Threshold-5 (AND) are\ntrivial (and hence easily testable), the other threshold rules exhibit much\nmore diverse behaviors. We first characterize the structure of stable\nconfigurations with respect to the Threshold-2 (similarly, Threshold-4) and\nThreshold-3 (Majority) rules. We then design and analyze a testing algorithm\nthat distinguishes between configurations that are stable with respect to the\nThreshold-2 rule, and those that are $\\epsilon$-far from any stable\nconfiguration, where the query complexity of the algorithm is independent of\nthe size of the configuration and depends quadratically on $1/\\epsilon$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e8c\u7ef4\u73af\u9762\u4e0a\u5143\u80de\u81ea\u52a8\u673a\u914d\u7f6e\u7684\u7a33\u5b9a\u6027\u3002\u5bf9\u4e8e\u9608\u503c-1 \u548c\u9608\u503c-5 \u89c4\u5219\uff0c\u7a33\u5b9a\u914d\u7f6e\u662f\u5e73\u51e1\u7684\u3002\u5bf9\u4e8e\u9608\u503c-2 \u548c\u9608\u503c-3 \u89c4\u5219\uff0c\u7814\u7a76\u4e86\u7a33\u5b9a\u914d\u7f6e\u7684\u7ed3\u6784\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u72ec\u7acb\u4e8e\u914d\u7f6e\u5927\u5c0f\uff0c\u4e14\u4e0e 1/\u03b5 \u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002", "motivation": "\u7814\u7a76\u5728\u4e8c\u7ef4\u73af\u9762\u4e0a\u6839\u636e\u5177\u6709\u51af\u00b7\u8bfa\u4f9d\u66fc\u90bb\u57df\u7684\u9608\u503c\u89c4\u5219\u6f14\u5316\u7684\u5143\u80de\u81ea\u52a8\u673a\u914d\u7f6e\u7684\u7a33\u5b9a\u6027\u7684\u8868\u5f81\u548c\u6d4b\u8bd5\u95ee\u9898\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4e8c\u7ef4\u73af\u9762\u4e0a\u6839\u636e\u5177\u6709\u51af\u00b7\u8bfa\u4f9d\u66fc\u90bb\u57df\u7684\u9608\u503c\u89c4\u5219\u6f14\u5316\u7684\u5143\u80de\u81ea\u52a8\u673a\u914d\u7f6e\u7684\u7a33\u5b9a\u6027\u7684\u8868\u5f81\u548c\u6d4b\u8bd5\u95ee\u9898\u3002\u9996\u5148\uff0c\u6211\u4eec\u8868\u5f81\u4e86\u9608\u503c-2\uff08\u7c7b\u4f3c\u5730\uff0c\u9608\u503c-4\uff09\u548c\u9608\u503c-3\uff08\u591a\u6570\uff09\u89c4\u5219\u7684\u7a33\u5b9a\u914d\u7f6e\u7ed3\u6784\u3002\u7136\u540e\uff0c\u6211\u4eec\u8bbe\u8ba1\u5e76\u5206\u6790\u4e86\u4e00\u79cd\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u533a\u5206\u4e86\u76f8\u5bf9\u4e8e\u9608\u503c-2 \u89c4\u5219\u7a33\u5b9a\u7684\u914d\u7f6e\u548c\u4e0e\u4efb\u4f55\u7a33\u5b9a\u914d\u7f6e\u76f8\u8ddd \u03b5 \u7684\u914d\u7f6e\u3002", "result": "\u5bf9\u4e8e\u9608\u503c-1\uff08OR\uff09\u548c\u9608\u503c-5\uff08AND\uff09\u7684\u7a33\u5b9a\u914d\u7f6e\u662f\u5e73\u51e1\u7684\uff08\u4e14\u6613\u4e8e\u6d4b\u8bd5\uff09\u3002\u5176\u4ed6\u9608\u503c\u89c4\u5219\u8868\u73b0\u51fa\u66f4\u591a\u6837\u5316\u7684\u884c\u4e3a\u3002\u4f5c\u8005\u4eec\u8868\u5f81\u4e86\u9608\u503c-2 \u548c\u9608\u503c-3 \u89c4\u5219\u7684\u7a33\u5b9a\u914d\u7f6e\u7ed3\u6784\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6d4b\u8bd5\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u67e5\u8be2\u590d\u6742\u5ea6\u4e0a\u72ec\u7acb\u4e8e\u914d\u7f6e\u7684\u5927\u5c0f\uff0c\u5e76\u4e14\u590d\u6742\u5ea6\u4e0e 1/\u03b5 \u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002"}}
{"id": "2507.15323", "categories": ["physics.app-ph", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2507.15323", "abs": "https://arxiv.org/abs/2507.15323", "authors": ["Jakob Holstein", "Nicholas K. North", "Arne Hof", "Sanchit Kondawar", "Dmytro B. But", "Mohammed Salih", "Lianhe Li", "Edmund H. Linfield", "A. Giles Davies", "Joshua R. Freeman", "Alexander Valavanis", "Alvydas Lisauskas", "Hartmut G. Roskos"], "title": "Improving 8x8 TeraFET array sensitivity through liquid-nitrogen cooling in a compact low-noise cryostat", "comment": null, "summary": "The sensitivity of antenna-coupled field-effect transistors (TeraFETs) to\nterahertz (THz) radiation has been shown to improve continuously with\ndecreasing temperature. In this work, we first present a quantitative\nevaluation of the temperature-dependent noise-equivalent power (NEP) of\nrecently developed patch-antenna-coupled TeraFET detectors resonant at 540 GHz,\nwith measurements down to 20 K. Based on these results, we project NEP values\napproaching 1 to 2 pW/$\\sqrt{\\textrm{Hz}}$ under efficient power\ncoupling-comparable to state-of-the-art superconducting niobium transition-edge\nsensors (TESs) operated at 4 K. Building on these findings in the sub-1 THz\nrange, a compact, low-noise, liquid-nitrogen-cooled (77 K) TeraFET power\ndetection system for spectroscopy applications was realized. The system\nincorporates an 8$\\times$8 pixel-binned detector array fabricated in a\ncommercial 65 nm Si-CMOS process, optimized for operation in the 2.85- to 3.4\nTHz band, where fast, sensitive and spectrally specific detectors that do not\nrequire helium cooling remain scarce. Final system characterization was\nperformed in the focal plane of a 2.85-THz quantum-cascade laser delivering\napproximately 2 mW of optical power. An experimental linear dynamic range\nexceeding 67 dB was achieved without saturation (for 1 Hz-detection bandwidth).\nThe system provides a -3 dB detection bandwidth of 5 MHz vastly exceeding that\nof conventional thermal detectors (typically 1-kHz), thus potentially enabling\nadvanced applications such as time-resolved THz spectroscopy down to the\nsub-$\\mu$s scale. Combined with its broad temperature operability and compact\ndesign, the system is particularly well suited for space- and\npayload-constrained platforms such as balloon- and satellite-based missions,\nwhere deep cryogenic cooling is impractical.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6db2\u6c2e\u6e29\u533a\u5de5\u4f5c\u7684TeraFET\u63a2\u6d4b\u7cfb\u7edf\uff0c\u57283 THz\u9644\u8fd1\u5b9e\u73b0\u4e86\u9ad8\u7075\u654f\u5ea6\u3001\u5bbd\u52a8\u6001\u8303\u56f4\u548c\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\uff0c\u9002\u7528\u4e8e\u7a7a\u95f4\u4efb\u52a1\u3002", "motivation": "\u4e3a\u4e86\u5728\u592a\u8d6b\u5179\u9891\u6bb5\uff0c\u7279\u522b\u662f3 THz\u9644\u8fd1\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u7075\u654f\u4e14\u4e0d\u9700\u8981\u6c26\u51b7\u5374\u7684\u5149\u8c31\u63a2\u6d4b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u53ef\u5728\u8f83\u9ad8\u6e29\u5ea6\u4e0b\u5de5\u4f5c\uff08\u5982\u6db2\u6c2e\u6e29\u533a\uff09\u7684TeraFET\u63a2\u6d4b\u7cfb\u7edf\u3002", "method": "\u672c\u5de5\u4f5c\u9996\u5148\u5bf9\u6700\u8fd1\u5f00\u53d1\u7684\u7ed3\u6676\u5929\u7ebf\u8026\u5408\u592a\u8d6b\u5179\u573a\u6548\u5e94\u6676\u4f53\u7ba1\uff08TeraFET\uff09\u63a2\u6d4b\u5668\u5728540 GHz\u4e0b\u7684\u566a\u58f0\u7b49\u6548\u529f\u7387\uff08NEP\uff09\u8fdb\u884c\u4e86\u5b9a\u91cf\u8bc4\u4f30\uff0c\u6d4b\u91cf\u6e29\u5ea6\u4f4e\u81f320 K\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u4f4e\u566a\u58f0\u3001\u6db2\u6c2e\u51b7\u5374\uff0877 K\uff09\u7684TeraFET\u529f\u7387\u63a2\u6d4b\u7cfb\u7edf\uff0c\u7528\u4e8e\u5149\u8c31\u5b66\u5e94\u7528\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u5546\u752865 nm Si-CMOS\u5de5\u827a\u5236\u9020\uff0c\u5305\u542b\u4e00\u4e2a8x8\u50cf\u7d20\u7684\u63a2\u6d4b\u5668\u9635\u5217\uff0c\u4f18\u5316\u5de5\u4f5c\u57282.85-3.4 THz\u9891\u6bb5\u3002", "result": "\u57282.85 THz\u4e0b\uff0c\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86\u8d85\u8fc767 dB\u7684\u7ebf\u6027\u52a8\u6001\u8303\u56f4\uff08\u57281 Hz\u68c0\u6d4b\u5e26\u5bbd\u4e0b\uff09\uff0c-3 dB\u7684\u68c0\u6d4b\u5e26\u5bbd\u8fbe\u52305 MHz\uff0c\u8fdc\u8d85\u4f20\u7edf\u70ed\u63a2\u6d4b\u5668\uff08\u901a\u5e38\u4e3a1 kHz\uff09\uff0c\u80fd\u591f\u5b9e\u73b0\u4f4e\u81f3\u4e9a\u5fae\u79d2\u7ea7\u7684\u65f6\u95f4\u5206\u8fa8\u592a\u8d6b\u5179\u5149\u8c31\u5b66\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5177\u6709\u826f\u597d\u7684\u6e29\u5ea6\u9002\u5e94\u6027\u3001\u7d27\u51d1\u7684\u8bbe\u8ba1\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7a7a\u95f4\u548c\u8f7d\u8377\u53d7\u9650\u7684\u5e73\u53f0\uff0c\u5982\u6c14\u7403\u548c\u536b\u661f\u4efb\u52a1\uff0c\u56e0\u4e3a\u5176\u6df1\u4f4e\u6e29\u51b7\u5374\u662f\u4e0d\u5207\u5b9e\u9645\u7684\u3002"}}
{"id": "2507.15351", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15351", "abs": "https://arxiv.org/abs/2507.15351", "authors": ["Zijian Zhao", "Sen Li"], "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms", "comment": null, "summary": "On-demand ride-sharing platforms face the fundamental challenge of\ndynamically bundling passengers with diverse origins and destinations and\nmatching them with vehicles in real time, all under significant uncertainty.\nRecently, MARL has emerged as a promising solution for this problem, leveraging\ndecentralized learning to address the curse of dimensionality caused by the\nlarge number of agents in the ride-hailing market and the resulting expansive\nstate and action spaces. However, conventional MARL-based ride-sharing\napproaches heavily rely on the accurate estimation of Q-values or V-values,\nwhich becomes problematic in large-scale, highly uncertain environments.\nSpecifically, most of these approaches adopt an independent paradigm,\nexacerbating this issue, as each agent treats others as part of the\nenvironment, leading to unstable training and substantial estimation bias in\nvalue functions. To address these challenges, we propose two novel alternative\nmethods that bypass value function estimation. First, we adapt GRPO to\nride-sharing, replacing the PPO baseline with the group average reward to\neliminate critic estimation errors and reduce training bias. Second, inspired\nby GRPO's full utilization of group reward information, we customize the PPO\nframework for ride-sharing platforms and show that, under a homogeneous fleet,\nthe optimal policy can be trained using only one-step rewards - a method we\nterm One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan\nride-hailing dataset demonstrate that both GRPO and OSPO achieve superior\nperformance across most scenarios, efficiently optimizing pickup times and the\nnumber of served orders using simple MLP networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGRPO\u548cOSPO\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u53eb\u8f66\u670d\u52a1\u4e2dMARL\u65b9\u6cd5\u5728\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u4e0a\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u7684MARL\u65b9\u6cd5\u5728\u53eb\u8f66\u670d\u52a1\u4e2d\u4f9d\u8d56\u4e8e\u51c6\u786e\u7684Q\u503c\u6216V\u503c\u4f30\u8ba1\uff0c\u8fd9\u5728\u5927\u89c4\u6a21\u3001\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u73af\u5883\u4e2d\u5b58\u5728\u95ee\u9898\uff0c\u7279\u522b\u662f\u72ec\u7acb\u8303\u5f0f\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u504f\u5dee\u3002\u56e0\u6b64\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3MARL\u5728\u53eb\u8f66\u670d\u52a1\u4e2d\u7684\u5e94\u7528\u95ee\u9898\uff1a1.\u5c06GRPO\u9002\u5e94\u4e8e\u53eb\u8f66\u670d\u52a1\uff0c\u7528\u7ec4\u5408\u5e73\u5747\u5956\u52b1\u66ff\u6362PPO\u57fa\u7ebf\uff0c\u4ee5\u6d88\u9664\u8bc4\u4f30\u8005\u4f30\u8ba1\u9519\u8bef\u5e76\u51cf\u5c11\u8bad\u7ec3\u504f\u5dee\u30022.\u5b9a\u5236PPO\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u5355\u6b65\u5956\u52b1\u6765\u8bad\u7ec3\u6700\u4f18\u7b56\u7565\uff0c\u79f0\u4e3a\u5355\u6b65\u7b56\u7565\u4f18\u5316\uff08OSPO\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGRPO\u548cOSPO\u5728\u771f\u5b9e\u66fc\u54c8\u987f\u53eb\u8f66\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u5747\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u6709\u6548\u4f18\u5316\u4e86\u4e0a\u8f66\u65f6\u95f4\u548c\u8ba2\u5355\u6570\u91cf\uff0c\u4ec5\u4f7f\u7528\u4e86\u7b80\u5355\u7684MLP\u7f51\u7edc\u3002", "conclusion": "GRPO\u548cOSPO\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6709\u6548\u4f18\u5316\u4e86\u4e0a\u8f66\u65f6\u95f4\u548c\u670d\u52a1\u8ba2\u5355\u6570\u91cf\uff0c\u5e76\u4e14\u4ec5\u4f7f\u7528\u4e86\u7b80\u5355\u7684MLP\u7f51\u7edc\u3002"}}
{"id": "2507.15325", "categories": ["cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.15325", "abs": "https://arxiv.org/abs/2507.15325", "authors": ["Nicolas Lanzetti", "Sylvain Fricker", "Saverio Bolognani", "Florian D\u00f6rfler", "Dario Paccagnan"], "title": "Strategically Robust Game Theory via Optimal Transport", "comment": null, "summary": "In many game-theoretic settings, agents are challenged with taking decisions\nagainst the uncertain behavior exhibited by others. Often, this uncertainty\narises from multiple sources, e.g., incomplete information, limited\ncomputation, bounded rationality. While it may be possible to guide the agents'\ndecisions by modeling each source, their joint presence makes this task\nparticularly daunting. Toward this goal, it is natural for agents to seek\nprotection against deviations around the emergent behavior itself, which is\nultimately impacted by all the above sources of uncertainty. To do so, we\npropose that each agent takes decisions in face of the worst-case behavior\ncontained in an ambiguity set of tunable size, centered at the emergent\nbehavior so implicitly defined. This gives rise to a novel equilibrium notion,\nwhich we call strategically robust equilibrium. Building on its definition, we\nshow that, when judiciously operationalized via optimal transport,\nstrategically robust equilibria (i) are guaranteed to exist under the same\nassumptions required for Nash equilibria; (ii) interpolate between Nash and\nsecurity strategies; (iii) come at no additional computational cost compared to\nNash equilibria. Through a variety of experiments, including bi-matrix games,\ncongestion games, and Cournot competition, we show that strategic robustness\nprotects against uncertainty in the opponents' behavior and, surprisingly,\noften results in higher equilibrium payoffs - an effect we refer to as\ncoordination via robustification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u7b56\u7565\u7a33\u5065\u5747\u8861\u201d\u7684\u65b0\u5747\u8861\u6982\u5ff5\uff0c\u7528\u4e8e\u89e3\u51b3\u535a\u5f08\u8bba\u4e2d\u4ee3\u7406\u5728\u9762\u5bf9\u4e0d\u786e\u5b9a\u884c\u4e3a\u65f6\u7684\u51b3\u7b56\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8003\u8651\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u884c\u4e3a\uff0c\u5e76\u5728\u8ba1\u7b97\u6210\u672c\u4e0e\u7eb3\u4ec0\u5747\u8861\u76f8\u5f53\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u5e76\u53ef\u80fd\u5e26\u6765\u66f4\u9ad8\u7684\u6536\u76ca\u3002", "motivation": "\u5728\u8bb8\u591a\u535a\u5f08\u8bba\u573a\u666f\u4e2d\uff0c\u4ee3\u7406\u9700\u8981\u5728\u9762\u5bf9\u5176\u4ed6\u53c2\u4e0e\u8005\u4e0d\u786e\u5b9a\u7684\u884c\u4e3a\u65f6\u505a\u51fa\u51b3\u7b56\u3002\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u53ef\u80fd\u6e90\u4e8e\u4fe1\u606f\u4e0d\u5b8c\u6574\u3001\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u6216\u6709\u754c\u7406\u6027\u7b49\u591a\u79cd\u56e0\u7d20\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u5e94\u5bf9\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5747\u8861\u6982\u5ff5\uff0c\u79f0\u4e3a\u7b56\u7565\u7a33\u5065\u5747\u8861\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u6a21\u7cca\u96c6\uff08ambiguity set\uff09\u4ee5\u53ef\u8c03\u5927\u5c0f\u4e3a\u4e2d\u5fc3\u56f4\u7ed5\u7740\u6e10\u8fdb\u884c\u4e3a\u8fdb\u884c\u5b9a\u4e49\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u4ee3\u7406\u5728\u9762\u5bf9\u6700\u574f\u60c5\u51b5\u884c\u4e3a\u65f6\u505a\u51fa\u51b3\u7b56\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u6700\u4f18\u4f20\u8f93\uff08optimal transport\uff09\u8fdb\u884c\u64cd\u4f5c\u5316\u3002", "result": "\u7b56\u7565\u7a33\u5065\u5747\u8861\u5728\u5b58\u5728\u6027\u548c\u63d2\u503c\u6027\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u4e14\u8ba1\u7b97\u6210\u672c\u76f8\u5f53\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4fdd\u62a4\u4ee3\u7406\u514d\u53d7\u5bf9\u624b\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u5e38\u5e38\u5e26\u6765\u66f4\u9ad8\u7684\u5747\u8861\u6536\u76ca\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u7a33\u5065\u6027\u9a71\u52a8\u7684\u534f\u8c03\u201d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u7a33\u5065\u5747\u8861\uff08strategically robust equilibria\uff09\u5728\u7eb3\u4ec0\u5747\u8861\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\u4fdd\u8bc1\u5b58\u5728\uff0c\u80fd\u591f\u6709\u6548\u5730\u5728\u7eb3\u4ec0\u5747\u8861\u548c\u5b89\u5168\u7b56\u7565\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\uff0c\u5e76\u4e14\u8ba1\u7b97\u6210\u672c\u4e0e\u7eb3\u4ec0\u5747\u8861\u76f8\u5f53\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7b56\u7565\u7a33\u5065\u6027\u4e0d\u4ec5\u80fd\u6709\u6548\u5e94\u5bf9\u5bf9\u624b\u884c\u4e3a\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd8\u80fd\u901a\u8fc7\u201c\u7a33\u5065\u6027\u9a71\u52a8\u7684\u534f\u8c03\u201d\u6548\u5e94\u5e26\u6765\u66f4\u9ad8\u7684\u5747\u8861\u6536\u76ca\u3002"}}
{"id": "2507.14177", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "68T07(Primary), 41A15(Secondary)", "I.2.6; G.1.2"], "pdf": "https://arxiv.org/pdf/2507.14177", "abs": "https://arxiv.org/abs/2507.14177", "authors": ["Changcun Huang"], "title": "Understanding Two-Layer Neural Networks with Smooth Activation Functions", "comment": null, "summary": "This paper aims to understand the training solution, which is obtained by the\nback-propagation algorithm, of two-layer neural networks whose hidden layer is\ncomposed of the units with smooth activation functions, including the usual\nsigmoid type most commonly used before the advent of ReLUs. The mechanism\ncontains four main principles: construction of Taylor series expansions, strict\npartial order of knots, smooth-spline implementation and smooth-continuity\nrestriction. The universal approximation for arbitrary input dimensionality is\nproved and experimental verification is given, through which the mystery of\n``black box'' of the solution space is largely revealed. The new proofs\nemployed also enrich approximation theory.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u4f7f\u7528\u5e73\u6ed1\u6fc0\u6d3b\u51fd\u6570\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u673a\u5236\uff0c\u901a\u8fc7\u6cf0\u52d2\u5c55\u5f00\u7b49\u65b9\u6cd5\u8bc1\u660e\u4e86\u5176\u666e\u904d\u903c\u8fd1\u80fd\u529b\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u7406\u89e3\u5305\u542b\u5e73\u6ed1\u6fc0\u6d3b\u51fd\u6570\u7684\u9690\u85cf\u5c42\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u4f20\u7edfsigmoid\u7c7b\u6fc0\u6d3b\u51fd\u6570\uff0c\u4ee5\u63ed\u793a\u5176\u89e3\u7a7a\u95f4\u7684\u201c\u9ed1\u7bb1\u201d\u673a\u5236\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u6cf0\u52d2\u7ea7\u6570\u5c55\u5f00\u3001\u8282\u70b9\u4e25\u683c\u504f\u5e8f\u3001\u5149\u6ed1\u6837\u6761\u5b9e\u73b0\u548c\u5149\u6ed1\u8fde\u7eed\u6027\u7ea6\u675f\u7b49\u65b9\u6cd5\u6765\u5206\u6790\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5728\u4efb\u610f\u8f93\u5165\u7ef4\u5ea6\u4e0b\u7684\u666e\u904d\u903c\u8fd1\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u63ed\u793a\u4e86\u5176\u89e3\u7a7a\u95f4\u7684\u201c\u9ed1\u7bb1\u201d\u673a\u5236\uff0c\u540c\u65f6\u4e3a\u903c\u8fd1\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u6cf0\u52d2\u7ea7\u6570\u5c55\u5f00\u3001\u8282\u70b9\u4e25\u683c\u504f\u5e8f\u3001\u5149\u6ed1\u6837\u6761\u5b9e\u73b0\u548c\u5149\u6ed1\u8fde\u7eed\u6027\u7ea6\u675f\u8fd9\u56db\u4e2a\u4e3b\u8981\u539f\u7406\uff0c\u4e3a\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u4efb\u610f\u8f93\u5165\u7ef4\u5ea6\u4e0b\u7684\u666e\u904d\u903c\u8fd1\u80fd\u529b\uff0c\u540c\u65f6\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u63ed\u793a\u4e86\u5176\u89e3\u7a7a\u95f4\u7684\u201c\u9ed1\u7bb1\u201d\u673a\u5236\u3002"}}
{"id": "2507.15689", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15689", "abs": "https://arxiv.org/abs/2507.15689", "authors": ["Jean Christoph Jung", "J\u0119drzej Ko\u0142odziejski", "Frank Wolter"], "title": "Computation of Interpolants for Description Logic Concepts in Hard Cases", "comment": null, "summary": "While the computation of Craig interpolants for description logics (DLs) with\nthe Craig Interpolation Property (CIP) is well understood, very little is known\nabout the computation and size of interpolants for DLs without CIP or if one\naims at interpolating concepts in a weaker DL than the DL of the input ontology\nand concepts. In this paper, we provide the first elementary algorithms\ncomputing (i) ALC-interpolants between ALC-concepts under ALCH-ontologies and\n(ii) ALC-interpolants between ALCQ-concepts under ALCQ-ontologies. The\nalgorithms are based on recent decision procedures for interpolant existence.\nWe also observe that, in contrast, uniform (possibly depth restricted)\ninterpolants might be of non-elementary size.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8ba1\u7b97ALC\u548cALCQ\u6982\u5ff5\u63d2\u503c\u7684\u57fa\u672c\u7b97\u6cd5\uff0c\u5e76\u6307\u51fa\u5747\u5300\u63d2\u503c\u53ef\u80fd\u975e\u5e38\u5927\u3002", "motivation": "\u4e0e\u6b64\u76f8\u53cd\uff0c\u6211\u4eec\u8fd8\u89c2\u5bdf\u5230\uff0c\u5747\u5300\uff08\u53ef\u80fd\u53d7\u6df1\u5ea6\u9650\u5236\uff09\u7684\u63d2\u503c\u53ef\u80fd\u5177\u6709\u975e\u57fa\u672c\u5927\u5c0f\u3002", "method": "\u672c\u6587\u63d0\u51fa\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u57fa\u672c\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\uff08i\uff09\u5728ALCH\u672c\u4f53\u4e0b\u7684ALC\u6982\u5ff5\u4e4b\u95f4\u7684ALC\u63d2\u503c\uff0c\u4ee5\u53ca\uff08ii\uff09\u5728ALCQ\u672c\u4f53\u4e0b\u7684ALCQ\u6982\u5ff5\u4e4b\u95f4\u7684ALC\u63d2\u503c\u3002\u8fd9\u4e9b\u7b97\u6cd5\u57fa\u4e8e\u6700\u8fd1\u7684\u63d2\u503c\u5b58\u5728\u6027\u5224\u5b9a\u8fc7\u7a0b\u3002", "result": "\u672c\u6587\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u8ba1\u7b97ALC\u6982\u5ff5\u4e4b\u95f4ALC\u63d2\u503c\u548cALCQ\u6982\u5ff5\u4e4b\u95f4ALC\u63d2\u503c\u7684\u57fa\u672c\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u57fa\u4e8e\u6700\u8fd1\u7684\u63d2\u503c\u5b58\u5728\u6027\u5224\u5b9a\u8fc7\u7a0b\u3002", "conclusion": "\u867d\u7136\u5bf9\u4e8e\u5177\u6709Craig\u63d2\u503c\u6027\u8d28\uff08CIP\uff09\u7684\u63cf\u8ff0\u903b\u8f91\uff08DL\uff09\u7684Craig\u63d2\u503c\u8ba1\u7b97\u5f97\u5230\u4e86\u5f88\u597d\u7684\u7406\u89e3\uff0c\u4f46\u5bf9\u4e8e\u6ca1\u6709CIP\u7684DL\u6216\u4ee5\u5f31\u4e8e\u8f93\u5165\u672c\u4f53\u548c\u6982\u5ff5\u7684DL\u6765\u63d2\u503c\u6982\u5ff5\uff0c\u5176\u63d2\u503c\u8ba1\u7b97\u548c\u5927\u5c0f\u7684\u4e86\u89e3\u5374\u5f88\u5c11\u3002"}}
{"id": "2507.15121", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.15121", "abs": "https://arxiv.org/abs/2507.15121", "authors": ["Sasindu Wijeratne", "Rajgopal Kannan", "Viktor Prasanna"], "title": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs", "comment": null, "summary": "Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational\nbottleneck in sparse tensor decomposition. As real-world sparse tensors grow to\nbillions of nonzeros, they increasingly demand higher memory capacity and\ncompute throughput from hardware accelerators. In this work, we present AMPED,\na multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale\nsparse tensors. AMPED scales beyond the limits of a single GPU, meeting both\nthe memory and performance requirements of large-scale workloads. We introduce\na partitioning strategy combined with a dynamic load balancing scheme to\ndistribute computation and minimize GPU idle time. On real-world billion-scale\ntensors, AMPED achieves a 5.1x geometric mean speedup in total execution time\nover state-of-the-art GPU baselines using 4 GPUs on a single CPU node.", "AI": {"tldr": "AMPED\u662f\u4e00\u79cd\u591aGPU\u5e76\u884c\u7b97\u6cd5\uff0c\u7528\u4e8e\u52a0\u901f\u5927\u89c4\u6a21\u7a00\u758f\u5f20\u91cf\u5206\u89e3\u4e2d\u7684MTTKRP\u8ba1\u7b97\u3002", "motivation": "MTTKRP\u662f\u7a00\u758f\u5f20\u91cf\u5206\u89e3\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u968f\u7740\u771f\u5b9e\u7a00\u758f\u5f20\u91cf\u7684\u89c4\u6a21\u589e\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u7684\u5185\u5b58\u5bb9\u91cf\u548c\u8ba1\u7b97\u541e\u5410\u91cf\u3002", "method": "AMPED\u662f\u4e00\u4e2a\u591aGPU\u5e76\u884c\u7b97\u6cd5\uff0c\u91c7\u7528\u5206\u533a\u7b56\u7565\u548c\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\u65b9\u6848\u6765\u52a0\u901fMTTKRP\u3002", "result": "AMPED\u5728\u5904\u7406\u5305\u542b\u6570\u5341\u4ebf\u975e\u96f6\u5143\u7d20\u7684\u7a00\u758f\u5f20\u91cf\u65f6\uff0c\u6269\u5c55\u6027\u8d85\u8d8a\u4e86\u5355GPU\u7684\u9650\u5236\u3002", "conclusion": "AMPED\u57284\u4e2aGPU\u4e0a\u5b9e\u73b0\u4e865.1\u500d\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\uff0c\u6ee1\u8db3\u4e86\u5927\u89c4\u6a21\u7a00\u758f\u5f20\u91cf\u5206\u89e3\u7684\u5185\u5b58\u548c\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2507.14582", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14582", "abs": "https://arxiv.org/abs/2507.14582", "authors": ["Zezhi Liu", "Shizhen Wu", "Hanqian Luo", "Deyun Qin", "Yongchun Fang"], "title": "BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives", "comment": "11 pages, 8 figures", "summary": "In the field of Learning from Demonstration (LfD), enabling robots to\ngeneralize learned manipulation skills to novel scenarios for long-horizon\ntasks remains challenging. Specifically, it is still difficult for robots to\nadapt the learned skills to new environments with different task and motion\nrequirements, especially in long-horizon, multi-stage scenarios with intricate\nconstraints. This paper proposes a novel hierarchical framework, called\nBT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and\nDynamical Movement Primitives (DMPs) to address this problem. Within this\nframework, Signal Temporal Logic (STL) is employed to formally specify complex,\nlong-horizon task requirements and constraints. These STL specifications are\nsystematically transformed to generate reactive and modular BTs for high-level\ndecision-making task structure. An STL-constrained DMP optimization method is\nproposed to optimize the DMP forcing term, allowing the learned motion\nprimitives to adapt flexibly while satisfying intricate spatiotemporal\nrequirements and, crucially, preserving the essential dynamics learned from\ndemonstrations. The framework is validated through simulations demonstrating\ngeneralization capabilities under various STL constraints and real-world\nexperiments on several long-horizon robotic manipulation tasks. The results\ndemonstrate that the proposed framework effectively bridges the symbolic-motion\ngap, enabling more reliable and generalizable autonomous manipulation for\ncomplex robotic tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBT-TL-DMPs\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u884c\u4e3a\u6811\u3001\u65f6\u5e8f\u903b\u8f91\u548c\u52a8\u529b\u5b66\u79fb\u52a8\u539f\u8bed\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u96be\u4ee5\u5728\u957f\u65f6\u5e8f\u4efb\u52a1\u4e2d\u6cdb\u5316\u5b66\u4e60\u6280\u80fd\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u5229\u7528STL\u89c4\u8303\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7684DMPs\u5b9e\u73b0\u5bf9\u65b0\u73af\u5883\u7684\u9002\u5e94\u548c\u52a8\u529b\u5b66\u7684\u4fdd\u6301\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u53ef\u9760\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5728\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\uff08LfD\uff09\u9886\u57df\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5c06\u5b66\u4e60\u5230\u7684\u64cd\u4f5c\u6280\u80fd\u6cdb\u5316\u5230\u957f\u65f6\u5e8f\u4efb\u52a1\u7684\u65b0\u573a\u666f\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u673a\u5668\u4eba\u4ecd\u7136\u96be\u4ee5\u5c06\u5b66\u4e60\u5230\u7684\u6280\u80fd\u9002\u5e94\u5230\u5177\u6709\u4e0d\u540c\u4efb\u52a1\u548c\u8fd0\u52a8\u8981\u6c42\u7684\u65b0\u73af\u5883\u4e2d\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u590d\u6742\u7ea6\u675f\u7684\u957f\u65f6\u5e8f\u3001\u591a\u9636\u6bb5\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBT-TL-DMPs\u7684\u6df7\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u884c\u4e3a\u6811\uff08BT\uff09\u3001\u65f6\u5e8f\u903b\u8f91\uff08TL\uff09\u548c\u52a8\u529b\u5b66\u79fb\u52a8\u539f\u8bed\uff08DMPs\uff09\u3002\u4f7f\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u6765\u5f62\u5f0f\u5316\u590d\u6742\u3001\u957f\u65f6\u5e8f\u7684\u4efb\u52a1\u9700\u6c42\u548c\u7ea6\u675f\uff0c\u5e76\u5c06STL\u89c4\u8303\u8f6c\u6362\u4e3a\u884c\u4e3a\u6811\uff0c\u7528\u4e8e\u9ad8\u5c42\u51b3\u7b56\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7STL\u7ea6\u675f\u7684DMP\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316DMP\u7684\u5f3a\u8feb\u9879\uff0c\u4f7f\u5b66\u4e60\u5230\u7684\u8fd0\u52a8\u539f\u8bed\u80fd\u591f\u7075\u6d3b\u9002\u5e94\uff0c\u540c\u65f6\u6ee1\u8db3\u65f6\u7a7a\u7ea6\u675f\u5e76\u4fdd\u7559\u5b66\u4e60\u5230\u7684\u52a8\u529b\u5b66\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5404\u79cdSTL\u7ea6\u675f\u4e0b\uff0c\u8be5\u6846\u67b6\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u771f\u5b9e\u4e16\u754c\u7684\u5b9e\u9a8c\u4e5f\u5728\u591a\u4e2a\u957f\u65f6\u5e8f\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u5730\u5f25\u5408\u4e86\u7b26\u53f7-\u8fd0\u52a8\u7684\u9e3f\u6c9f\uff0c\u4f7f\u5f97\u590d\u6742\u673a\u5668\u4eba\u4efb\u52a1\u7684\u81ea\u4e3b\u64cd\u4f5c\u66f4\u52a0\u53ef\u9760\u548c\u53ef\u6cdb\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u884c\u4e3a\u6811\uff08BT\uff09\u3001\u65f6\u5e8f\u903b\u8f91\uff08TL\uff09\u548c\u52a8\u529b\u5b66\u79fb\u52a8\u539f\u8bed\uff08DMPs\uff09\u6765\u89e3\u51b3\u673a\u5668\u4eba\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\uff08LfD\uff09\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5b9e\u73b0\u4e86\u5728\u957f\u65f6\u5e8f\u3001\u591a\u9636\u6bb5\u4efb\u52a1\u4e2d\u6cdb\u5316\u5230\u65b0\u573a\u666f\u7684\u80fd\u529b\u3002\u901a\u8fc7\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u89c4\u8303\u4efb\u52a1\u8981\u6c42\u548c\u7ea6\u675f\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u884c\u4e3a\u6811\uff0c\u540c\u65f6\u4f18\u5316DMPs\u4ee5\u9002\u5e94\u65b0\u73af\u5883\u5e76\u4fdd\u6301\u5b66\u4e60\u5230\u7684\u52a8\u529b\u5b66\u7279\u6027\u3002\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u6709\u6548\u5f25\u5408\u4e86\u7b26\u53f7-\u8fd0\u52a8\u7684\u9e3f\u6c9f\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u673a\u5668\u4eba\u4efb\u52a1\u7684\u81ea\u4e3b\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.14368", "categories": ["cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.14368", "abs": "https://arxiv.org/abs/2507.14368", "authors": ["Praneeth Namburi", "Roger Pallar\u00e8s-L\u00f3pez", "Jessica Rosendorf", "Duarte Folgado", "Brian W. Anthony"], "title": "DUSTrack: Semi-automated point tracking in ultrasound videos", "comment": null, "summary": "Ultrasound technology enables safe, non-invasive imaging of dynamic tissue\nbehavior, making it a valuable tool in medicine, biomechanics, and sports\nscience. However, accurately tracking tissue motion in B-mode ultrasound\nremains challenging due to speckle noise, low edge contrast, and out-of-plane\nmovement. These challenges complicate the task of tracking anatomical landmarks\nover time, which is essential for quantifying tissue dynamics in many clinical\nand research applications. This manuscript introduces DUSTrack (Deep learning\nand optical flow-based toolkit for UltraSound Tracking), a semi-automated\nframework for tracking arbitrary points in B-mode ultrasound videos. We combine\ndeep learning with optical flow to deliver high-quality and robust tracking\nacross diverse anatomical structures and motion patterns. The toolkit includes\na graphical user interface that streamlines the generation of high-quality\ntraining data and supports iterative model refinement. It also implements a\nnovel optical-flow-based filtering technique that reduces high-frequency\nframe-to-frame noise while preserving rapid tissue motion. DUSTrack\ndemonstrates superior accuracy compared to contemporary zero-shot point\ntrackers and performs on par with specialized methods, establishing its\npotential as a general and foundational tool for clinical and biomechanical\nresearch. We demonstrate DUSTrack's versatility through three use cases:\ncardiac wall motion tracking in echocardiograms, muscle deformation analysis\nduring reaching tasks, and fascicle tracking during ankle plantarflexion. As an\nopen-source solution, DUSTrack offers a powerful, flexible framework for point\ntracking to quantify tissue motion from ultrasound videos. DUSTrack is\navailable at https://github.com/praneethnamburi/DUSTrack.", "AI": {"tldr": "DUSTrack\u662f\u4e00\u4e2a\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u6d41\u6cd5\u7684\u8d85\u58f0\u8ffd\u8e2a\u5de5\u5177\uff0c\u80fd\u51c6\u786e\u8ffd\u8e2a\u7ec4\u7ec7\u8fd0\u52a8\uff0c\u5e76\u63d0\u4f9b\u6613\u7528\u7684\u754c\u9762\u548c\u4f18\u5316\u7684\u8ffd\u8e2a\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u8ffd\u8e2aB\u6a21\u5f0f\u8d85\u58f0\u56fe\u50cf\u4e2d\u7684\u7ec4\u7ec7\u8fd0\u52a8\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u6563\u6591\u566a\u58f0\u3001\u4f4e\u8fb9\u7f18\u5bf9\u6bd4\u5ea6\u548c\u5e73\u9762\u5916\u8fd0\u52a8\u4f1a\u5f71\u54cd\u89e3\u5256\u6807\u5fd7\u70b9\u7684\u8ffd\u8e2a\uff0c\u800c\u8fd9\u5bf9\u4e8e\u91cf\u5316\u7ec4\u7ec7\u52a8\u6001\u81f3\u5173\u91cd\u8981\u3002", "method": "DUSTrack\u7ed3\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u6d41\u6cd5\uff0c\u5e76\u901a\u8fc7\u56fe\u5f62\u7528\u6237\u754c\u9762\u7b80\u5316\u4e86\u8bad\u7ec3\u6570\u636e\u7684\u751f\u6210\u548c\u6a21\u578b\u7684\u8fed\u4ee3\u4f18\u5316\uff0c\u540c\u65f6\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5149\u6d41\u6cd5\u6ee4\u6ce2\u6280\u672f\u6765\u51cf\u5c11\u566a\u58f0\u5e76\u4fdd\u7559\u5feb\u901f\u7684\u7ec4\u7ec7\u8fd0\u52a8\u3002", "result": "DUSTrack\u5728\u96f6\u6837\u672c\u70b9\u8ffd\u8e2a\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u7279\u5b9a\u65b9\u6cd5\u65b9\u9762\u8868\u73b0\u76f8\u5f53\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u901a\u7528\u57fa\u7840\u5de5\u5177\u7684\u6f5c\u529b\u3002", "conclusion": "DUSTrack\u662f\u4e00\u4e2a\u5f3a\u5927\u800c\u7075\u6d3b\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u8d85\u58f0\u89c6\u9891\u4e2d\u8ffd\u8e2a\u70b9\u548c\u91cf\u5316\u7ec4\u7ec7\u8fd0\u52a8\uff0c\u5728\u4e34\u5e8a\u548c\u751f\u7269\u529b\u5b66\u7814\u7a76\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.14335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14335", "abs": "https://arxiv.org/abs/2507.14335", "authors": ["Nicolas Wischermann", "Claudio Mayrink Verdun", "Gabriel Poesia", "Francesco Noseda"], "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance", "comment": "19 pages, 7 figures. Accepted at the 2nd AI for MATH Workshop at the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "Language models have become increasingly powerful tools for formal\nmathematical reasoning. However, most existing approaches rely exclusively on\neither large general-purpose models or smaller specialized models, each with\ndistinct limitations, while training specialized large models still requires\nsignificant computational resources. This paper introduces ProofCompass, a\nnovel hybrid methodology that achieves remarkable computational efficiency by\nstrategically guiding existing specialized prover methods, such as\nDeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without\nrequiring additional model training. The LLM provides natural language proof\nstrategies and analyzes failed attempts to select intermediate lemmas, enabling\neffective problem decomposition. On the miniF2F benchmark, ProofCompass\ndemonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\%\n\\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$).\nOur synergistic approach paves the way for simultaneously improving\ncomputational efficiency and accuracy in formal theorem proving.", "AI": {"tldr": "ProofCompass\u901a\u8fc7LLM\u6307\u5bfc\u4e13\u7528\u8bc1\u660e\u5668\uff0c\u5728\u4e0d\u589e\u52a0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee5\u66f4\u5c11\u7684\u5c1d\u8bd5\u6b21\u6570\u63d0\u9ad8\u4e86\u6570\u5b66\u63a8\u7406\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5f62\u5f0f\u5316\u6570\u5b66\u63a8\u7406\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e8e\u5927\u578b\u901a\u7528\u6a21\u578b\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u5c0f\u578b\u4e13\u7528\u6a21\u578b\uff0c\u800c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5404\u6709\u5c40\u9650\u6027\u3002\u8bad\u7ec3\u4e13\u7528\u7684LLM\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "ProofCompass\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u6307\u5bfc\u73b0\u6709\u7684\u4e13\u4e1a\u8bc1\u660e\u5668\uff08\u5982DeepSeek-Prover-v1.5-RL\uff08DSP-v1.5\uff09\uff09\uff0c\u65e0\u9700\u989d\u5916\u7684\u6a21\u578b\u8bad\u7ec3\u3002LLM\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u4f9b\u8bc1\u660e\u7b56\u7565\uff0c\u5e76\u5206\u6790\u5931\u8d25\u7684\u8bc1\u660e\u5c1d\u8bd5\u4ee5\u9009\u62e9\u4e2d\u95f4\u5f15\u7406\uff0c\u4ece\u800c\u5b9e\u73b0\u95ee\u9898\u5206\u89e3\u3002", "result": "\u5728miniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProofCompass\u5728\u4f7f\u7528\u7684\u5c1d\u8bd5\u6b21\u6570\u51cf\u5c1125\u500d\uff083200\u6b21\u51cf\u5c11\u5230128\u6b21\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06DSP-v1.5\u7684\u6027\u80fd\u4ece54.9%\u63d0\u9ad8\u523055.3%\u3002", "conclusion": "\"ProofCompass\"\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5730\u6307\u5bfc\u73b0\u6709\u7684\u4e13\u4e1a\u8bc1\u660e\u5668\u65b9\u6cd5\uff08\u5982DeepSeek-Prover-v1.5-RL\uff08DSP-v1.5\uff09\uff09\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u7684\u6a21\u578b\u8bad\u7ec3\uff0cLLM\u901a\u8fc7\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\u7b56\u7565\u548c\u5206\u6790\u5931\u8d25\u7684\u5c1d\u8bd5\u6765\u9009\u62e9\u4e2d\u95f4\u5f15\u7406\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684\u95ee\u200b\u200b\u9898\u5206\u89e3\u3002\u5728miniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProofCompass\u5c55\u793a\u4e86\u663e\u8457\u7684\u8d44\u6e90\u6548\u7387\uff0c\u5728\u4f7f\u7528\u7684\u5c1d\u8bd5\u6b21\u6570\u51cf\u5c1125\u500d\uff08\u4ece3200\u51cf\u5c11\u5230128\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u6027\u80fd\u4f18\u4e8eDSP-v1.5\uff08\u4ece54.9%\u63d0\u9ad8\u523055.3%\uff09\u3002\u8fd9\u79cd\u534f\u540c\u65b9\u6cd5\u4e3a\u540c\u65f6\u63d0\u9ad8\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14476", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14476", "abs": "https://arxiv.org/abs/2507.14476", "authors": ["Hui Zhang", "Daming Tian", "Xiaobing Chen", "Weijian Qi", "Lu Chen", "Min Li", "Yetong Bai", "Jine Zhang", "Furong Han", "Huaiwen Yang", "Yuansha Chen", "Yunzhong Chen", "Jing Wu", "Yongbing Xu", "Fengxia Hu", "Baogen Shen", "Jirong Sun", "Weisheng Zhao"], "title": "Light-Induced Giant Enhancement of the Nonlinear Hall Effect in Two-Dimensional Electron Gases at KTaO3 (111) Interfaces", "comment": null, "summary": "The nonlinear Hall effect (NLHE), an emergent phenomenon in\nnoncentrosymmetric systems, enables the generation of a transverse voltage\nwithout an external magnetic field through a second-order electrical response.\nHowever, achieving a sizable NLHE signal remains a critical challenge for its\napplication in frequency-doubling and rectifying devices. Here, we report a\nlight-induced giant enhancement of the NLHE in the two-dimensional electron gas\n(2DEG) at the CaZrO3/KTaO3 (111) interface. Under light illumination, the\nsecond harmonic Hall voltage (V2{\\omega} y) increases substantially and\nundergoes a sign reversal. Correspondingly,the second-order transverse\nconductivity increases by nearly five orders of magnitude, reaching 2.4 um V-1\nomega-1, while also reversing its sign. Scaling analysis indicates that skew\nscattering is the dominant mechanism underlying the NLHE and is highly tunable\nvia optical gating. Photoexcitation pumps electrons from in-gap states into the\nhigher-lying Ta 5d conduction band, generating high-mobility photocarriers that\nsignificantly increase the cubic transport scattering time, thereby driving a\ndramatic enhancement of {\\sigma}(2) yxx. First-principles calculations further\nreveal that the Berry curvature distribution on the Fermi surface strongly\ndepends on band filling. As the Fermi level approaches a band crossing in the\nTa 5d subband near the M point, the Berry curvature triple undergoes a sign\nchange, accounting for the experimentally observed sign reversal of the\nnonlinear Hall response. Our work offers a new strategy to optically boost and\ntune the nonlinear Hall effect in oxide 2DEG systems, paving the way for\napplications in light-controlled rectification and nonlinear electronic\ndevices.", "AI": {"tldr": "\u901a\u8fc7\u5149\u7167\u663e\u8457\u589e\u5f3a\u548c\u8c03\u63a7\u6c27\u5316\u7269\u4e8c\u7ef4\u7535\u5b50\u6c14\u4e2d\u7684\u975e\u7ebf\u6027\u970d\u5c14\u6548\u5e94\uff0c\u4e3a\u5149\u63a7\u6574\u6d41\u548c\u975e\u7ebf\u6027\u7535\u5b50\u5668\u4ef6\u5f00\u8f9f\u4e86\u9053\u8def\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u975e\u7ebf\u6027\u970d\u5c14\u6548\u5e94\u4fe1\u53f7\u5e45\u5ea6\u5c0f\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u5668\u4ef6\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u4e86\u63d0\u9ad8\u548c\u8c03\u63a7\u975e\u7ebf\u6027\u970d\u5c14\u6548\u5e94\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u91cf\u548c\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86CaZrO3/KTaO3 (111)\u754c\u9762\u4e8c\u7ef4\u7535\u5b50\u6c14\u5728\u5149\u7167\u4e0b\u7684\u975e\u7ebf\u6027\u970d\u5c14\u6548\u5e94\u3002", "result": "\u5728\u5149\u7167\u4e0b\uff0c\u89c2\u5bdf\u5230\u4e86\u975e\u7ebf\u6027\u970d\u5c14\u7535\u538b\u548c\u4e8c\u9636\u6a2a\u5411\u7535\u5bfc\u7387\u7684\u663e\u8457\u589e\u5f3a\uff08\u8fd1\u4e94\u4e2a\u6570\u91cf\u7ea7\uff09\u548c\u7b26\u53f7\u53cd\u8f6c\u3002\u901a\u8fc7\u5149\u6805\u8c03\u63a7\uff0c\u8bc1\u660e\u4e86\u503e\u659c\u6563\u5c04\u662f\u4e3b\u5bfc\u673a\u5236\uff0c\u5e76\u89e3\u91ca\u4e86\u5b9e\u9a8c\u89c2\u5bdf\u5230\u7684\u7b26\u53f7\u53cd\u8f6c\u73b0\u8c61\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5149\u7167\u663e\u8457\u589e\u5f3a\u5e76\u8c03\u63a7\u4e86\u6c27\u5316\u7269\u4e8c\u7ef4\u7535\u5b50\u6c14\u4e2d\u7684\u975e\u7ebf\u6027\u970d\u5c14\u6548\u5e94\uff0c\u4e3a\u5f00\u53d1\u5149\u63a7\u6574\u6d41\u548c\u975e\u7ebf\u6027\u7535\u5b50\u5668\u4ef6\u63d0\u4f9b\u4e86\u65b0\u7684\u7b56\u7565\u3002"}}
{"id": "2507.15143", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15143", "abs": "https://arxiv.org/abs/2507.15143", "authors": ["Abderaouf Bahi", "Amel Ourici"], "title": "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", "comment": null, "summary": "This paper investigates the feasibility of human mobility in The Line, a\nproposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess\nwhether citizens can move freely within this unprecedented urban topology, we\ndevelop a hybrid simulation framework that integrates agent-based modeling,\nreinforcement learning, supervised learning, and graph neural networks. The\nsimulation captures multi-modal transportation behaviors across 50 vertical\nlevels and varying density scenarios using both synthetic data and real-world\ntraces from high-density cities. Our experiments reveal that with the full\nAI-integrated architecture, agents achieved an average commute time of 7.8 to\n8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index\nof over 91 percent, even during peak congestion periods. Ablation studies\nconfirmed that the removal of intelligent modules such as reinforcement\nlearning or graph neural networks significantly degrades performance, with\ncommute times increasing by up to 85 percent and reachability falling below 70\npercent. Environmental modeling further demonstrated low energy consumption and\nminimal CO2 emissions when electric modes are prioritized. The findings suggest\nthat freedom of movement is not only conceptually achievable in The Line, but\nalso operationally realistic if supported by adaptive AI systems, sustainable\ninfrastructure, and real-time feedback loops.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6df7\u5408\u6a21\u62df\u6846\u67b6\u9a8c\u8bc1\u4e86\u5728\u6c99\u7279\u963f\u62c9\u4f2f\u7684\u7ebf\u6027\u57ce\u5e02\u201c\u7ebf\u201d\u4e2d\u5b9e\u73b0\u9ad8\u6548\u4fbf\u6377\u7684\u4eba\u7c7b\u79fb\u52a8\u662f\u53ef\u884c\u7684\uff0c\u5373\u4f7f\u5728\u9ad8\u5cf0\u671f\u4e5f\u80fd\u4fdd\u8bc1\u77ed\u901a\u52e4\u65f6\u95f4\u548c\u9ad8\u6ee1\u610f\u5ea6\uff0c\u800cAI\u548c\u53ef\u6301\u7eed\u63aa\u65bd\u662f\u5173\u952e\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5728\u6c99\u7279\u963f\u62c9\u4f2fNEOM\u8ba1\u5212\u5efa\u8bbe\u7684170\u516c\u91cc\u7ebf\u6027\u667a\u80fd\u57ce\u5e02\u201c\u7ebf\u201d\u4e2d\uff0c\u5e02\u6c11\u662f\u5426\u80fd\u591f\u81ea\u7531\u79fb\u52a8\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df7\u5408\u6a21\u62df\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u57fa\u4e8e\u4ee3\u7406\u7684\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7763\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u6a21\u62df\u201c\u7ebf\u201d\u8fd9\u4e00\u7ebf\u6027\u57ce\u5e02\u4e2d\u7684\u4eba\u7c7b\u79fb\u52a8\u6027\u3002\u8be5\u6a21\u62df\u6355\u6349\u4e86\u8de8\u8d8a50\u4e2a\u5782\u76f4\u5c42\u9762\u548c\u4e0d\u540c\u5bc6\u5ea6\u60c5\u666f\u4e0b\u7684\u591a\u6a21\u5f0f\u4ea4\u901a\u884c\u4e3a\uff0c\u5e76\u4f7f\u7528\u4e86\u5408\u6210\u6570\u636e\u548c\u6765\u81ea\u9ad8\u5bc6\u5ea6\u57ce\u5e02\u7684\u771f\u5b9e\u75d5\u8ff9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u96c6\u6210\u5b8c\u6574\u4eba\u5de5\u667a\u80fd\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\uff0c\u667a\u80fd\u4f53\u5b9e\u73b0\u4e867.8\u81f38.4\u5206\u949f\u7684\u5e73\u5747\u901a\u52e4\u65f6\u95f4\u3001\u8d85\u8fc789%\u7684\u6ee1\u610f\u7387\u548c91%\u4ee5\u4e0a\u7684\u53ef\u8fbe\u6027\u6307\u6570\uff0c\u5373\u4f7f\u5728\u9ad8\u5cf0\u62e5\u5835\u65f6\u6bb5\u4e5f\u662f\u5982\u6b64\u3002\u4f18\u5316\u7814\u7a76\u4e5f\u8bc1\u5b9e\uff0c\u79fb\u9664\u5f3a\u5316\u5b66\u4e60\u6216\u56fe\u795e\u7ecf\u7f51\u7edc\u7b49\u667a\u80fd\u6a21\u5757\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\uff0c\u901a\u52e4\u65f6\u95f4\u589e\u52a0\u9ad8\u8fbe85%\uff0c\u53ef\u8fbe\u6027\u964d\u81f370%\u4ee5\u4e0b\u3002\u6b64\u5916\uff0c\u73af\u5883\u6a21\u578b\u8868\u660e\uff0c\u5f53\u4f18\u5148\u8003\u8651\u7535\u52a8\u6a21\u5f0f\u65f6\uff0c\u80fd\u6e90\u6d88\u8017\u4f4e\u4e14\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u91cf\u6700\u5c0f\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3001\u53ef\u6301\u7eed\u57fa\u7840\u8bbe\u65bd\u548c\u5b9e\u65f6\u53cd\u9988\u5faa\u73af\u7684\u652f\u6301\u4e0b\uff0c\u5728\u201c\u7ebf\u201d\u8fd9\u4e00\u7ebf\u6027\u57ce\u5e02\u4e2d\u5b9e\u73b0\u81ea\u7531\u79fb\u52a8\u4e0d\u4ec5\u5728\u6982\u5ff5\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u800c\u4e14\u5728\u64cd\u4f5c\u4e0a\u4e5f\u5177\u6709\u73b0\u5b9e\u610f\u4e49\u3002"}}
{"id": "2507.14415", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2507.14415", "abs": "https://arxiv.org/abs/2507.14415", "authors": ["Hiroki Kobayashi", "Kazuki Komatsu", "Kenji Mochizuki", "Hayate Ito", "Koichi Momma", "Shinichi Machida", "Takanori Hattori", "Kunio Hirata", "Yoshiaki Kawano", "Saori Maki-Yonekura", "Kiyofumi Takaba", "Koji Yonekura", "Qianli Xue", "Misaki Sato", "Hiroyuki Kagi"], "title": "New metastable ice phases via supercooled water", "comment": null, "summary": "Water exhibits rich polymorphism, where more than 20 crystalline phases have\nbeen experimentally reported. Five of them are metastable and form at low\ntemperatures by either heating amorphous ice or degassing clathrate hydrates.\nHowever, such metastable phases rarely crystallise directly from liquid water,\nmaking it challenging to study metastable phase relations at relatively high\ntemperatures. Here, we report that high-pressure metastable phases of ice,\nincluding two unknown phases named ices XXI and XXII, crystallise directly from\nliquid water in a deeply supercooled region around the homogeneous nucleation\ntemperature. The key is to use emulsified water to stabilise supercooled water\nin laboratory timescales. Ices XXI and XXII are obtained by isothermal\ncompression of emulsified water at 295 K and 250 K, respectively. Our powder\nx-ray and neutron diffraction analyses combined with molecular dynamics (MD)\nsimulations revealed the surprisingly complex structures of these new phases\nwith Z = 152 (ice XXI) and 304 (ice XXII). Ice XXI is topologically identical\nto 'ice T2' previously predicted by MD simulations, and our experimental\nstructural model can be used as a benchmark for its structures in simulations,\nwhich depend on the force fields. On cooling, ice XXI transforms into an\norientationally ordered counterpart named ice XXIII. Our results revealed the\n\"hidden\" structural complexity of water underlying the phase diagram, as\nimplied by previous computational works. Further efforts at unveiling such\nmetastable phase relations will bridge the large gaps between computational and\nexperimental phase diagrams of water.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14595", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14595", "abs": "https://arxiv.org/abs/2507.14595", "authors": ["Tongxin Li"], "title": "Learning-Augmented Control: Adaptively Confidence Learning for Competitive MPC", "comment": "13 pages, 4 figures", "summary": "We introduce Learning-Augmented Control (LAC), an approach that integrates\nuntrusted machine learning predictions into the control of constrained,\nnonlinear dynamical systems. LAC is designed to achieve the\n\"best-of-both-worlds\" guarantees, i.e, near-optimal performance when\npredictions are accurate, and robust, safe performance when they are not. The\ncore of our approach is a delayed confidence learning procedure that optimizes\na confidence parameter online, adaptively balancing between ML and nominal\npredictions. We establish formal competitive ratio bounds for general nonlinear\nsystems under standard MPC regularity assumptions. For the linear quadratic\ncase, we derive a competitive ratio bound that is provably tight, thereby\ncharacterizing the fundamental limits of this learning-augmented approach. The\neffectiveness of LAC is demonstrated in numerical studies, where it maintains\nstability and outperforms standard methods under adversarial prediction errors.", "AI": {"tldr": "LAC\u662f\u4e00\u79cd\u5c06\u4e0d\u53ef\u4fe1\u7684\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6574\u5408\u5230\u53d7\u7ea6\u675f\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u63a7\u5236\u4e2d\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u4f9b\u6700\u4f73\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u5ef6\u8fdf\u7f6e\u4fe1\u5b66\u4e60\u5b9e\u73b0\u81ea\u9002\u5e94\u5e73\u8861\u3002", "motivation": "LAC\u65e8\u5728\u4e3a\u53d7\u7ea6\u675f\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u63a7\u5236\u6574\u5408\u4e0d\u53ef\u4fe1\u7684\u673a\u5668\u5b66\u4e60\u9884\u6d4b\uff0c\u4ee5\u5b9e\u73b0\u201c\u4e24\u5168\u5176\u7f8e\u201d\u7684\u4fdd\u8bc1\uff0c\u5373\u5728\u9884\u6d4b\u51c6\u786e\u65f6\u83b7\u5f97\u8fd1\u4e4e\u6700\u4f18\u7684\u6027\u80fd\uff0c\u5728\u9884\u6d4b\u4e0d\u51c6\u786e\u65f6\u83b7\u5f97\u9c81\u68d2\u3001\u5b89\u5168\u7684\u6027\u80fd\u3002", "method": "LAC\u91c7\u7528\u5ef6\u8fdf\u7f6e\u4fe1\u5b66\u4e60\u7a0b\u5e8f\uff0c\u5728\u7ebf\u4f18\u5316\u7f6e\u4fe1\u53c2\u6570\uff0c\u81ea\u9002\u5e94\u5730\u5e73\u8861\u673a\u5668\u5b66\u4e60\u548c\u6807\u79f0\u9884\u6d4b\u3002\u6211\u4eec\u4e3a\u5177\u6709\u6807\u51c6MPC\u6b63\u5219\u6027\u5047\u8bbe\u7684\u4e00\u822c\u975e\u7ebf\u6027\u7cfb\u7edf\u5efa\u7acb\u4e86\u6b63\u5f0f\u7684\u7ade\u4e89\u6bd4\u754c\u9650\u3002\u5bf9\u4e8e\u7ebf\u6027\u4e8c\u6b21\u60c5\u51b5\uff0c\u6211\u4eec\u63a8\u5bfc\u4e86\u4e00\u4e2a\u53ef\u8bc1\u660e\u7684\u7d27\u51d1\u7ade\u4e89\u6bd4\u754c\u9650\uff0c\u4ece\u800c\u8868\u5f81\u4e86\u8fd9\u4e2a\u5b66\u4e60\u589e\u5f3a\u65b9\u6cd5\u7684\u57fa\u672c\u6781\u9650\u3002", "result": "LAC\u80fd\u591f\u5b9e\u73b0\u8fd1\u4e4e\u6700\u4f18\u7684\u6027\u80fd\uff0c\u5f53\u9884\u6d4b\u51c6\u786e\u65f6\uff0c\u4ee5\u53ca\u9c81\u68d2\u3001\u5b89\u5168\u7684\u6027\u80fd\uff0c\u5f53\u9884\u6d4b\u4e0d\u51c6\u786e\u65f6\u3002\u5728\u5177\u6709\u6807\u51c6MPC\u6b63\u5219\u6027\u5047\u8bbe\u7684\u4e00\u822c\u975e\u7ebf\u6027\u7cfb\u7edf\u4e0b\uff0cLAC\u5177\u6709\u6b63\u5f0f\u7684\u7ade\u4e89\u6bd4\u754c\u9650\u3002\u5bf9\u4e8e\u7ebf\u6027\u4e8c\u6b21\u60c5\u51b5\uff0cLAC\u5177\u6709\u53ef\u8bc1\u660e\u7684\u7d27\u51d1\u7ade\u4e89\u6bd4\u754c\u9650\uff0c\u8fd9\u8868\u5f81\u4e86\u8be5\u65b9\u6cd5\u7684\u6839\u672c\u9650\u5236\u3002", "conclusion": "LAC\u5728\u6570\u503c\u7814\u7a76\u4e2d\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\uff0c\u5b83\u5728\u5bf9\u6297\u6027\u9884\u6d4b\u9519\u8bef\u4e0b\u4fdd\u6301\u4e86\u7a33\u5b9a\u6027\u5e76\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2507.14383", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14383", "abs": "https://arxiv.org/abs/2507.14383", "authors": ["Janine Hilder", "Sascha Heu\u00dfen", "Anke Ginter", "Andreas Wilke", "Ulrich Poschinger", "Ferdinand Schmidt-Kaler", "Wadim Wormsbecher"], "title": "Quantum Internet in a Nutshell -- Advancing Quantum Communication with Ion Traps", "comment": null, "summary": "Quantum Internet in a Nutshell (QI-Nutshell) connects the fields of quantum\ncommunication and quantum computing by emulating quantum communication\nprotocols on currently available ion-trap quantum computers. We demonstrate\nemulations of QKD protocols where the individual steps are mapped to physical\noperations within our hardware platform. This allows us to not only practically\nexecute established protocols such as BB84 or BBM92, but also include cloning\nattacks by an eavesdropping party, noise sources and side-channel attacks that\nare generally hard to include in theoretical QKD security proofs. We\ndeliberately inject noise and investigate its effect on quantum communication\nprotocols. We employ numerical simulations in order to study the incorporation\nof small quantum error correction (QEC) codes into QKD protocols. We find that\nthese codes can help to suppress the noise level and to monitor the noise\nprofile of the channel. This may enable the communicating parties to detect\nsuspicious deviations from expected noise characteristics as a result of\npotential eavesdropping. This suggests that QEC may serve as a means of privacy\nauthentication for quantum communication without altering the transmitted\nquantum information.", "AI": {"tldr": "QI-Nutshell\u5728\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u4eff\u771f\u4e86\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\uff0c\u5e76\u901a\u8fc7\u6ce8\u5165\u566a\u97f3\u548c\u91cf\u5b50\u7ea0\u9519\u7801\u7814\u7a76\u4e86\u5176\u5bf9\u534f\u8bae\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u91cf\u5b50\u7ea0\u9519\u7801\u8fdb\u884c\u9690\u79c1\u8ba4\u8bc1\u7684\u53ef\u80fd\u6027\u3002", "motivation": "QI-Nutshell\u65e8\u5728\u8fde\u63a5\u91cf\u5b50\u901a\u4fe1\u548c\u91cf\u5b50\u8ba1\u7b97\u7684\u9886\u57df\uff0c\u901a\u8fc7\u5728\u5f53\u524d\u7684\u79bb\u5b50\u9631\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u4eff\u771f\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u3002", "method": "\u5bf9BB84\u6216BBM92\u7b49\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u534f\u8bae\u8fdb\u884c\u4eff\u771f\uff0c\u5c06\u5404\u4e2a\u6b65\u9aa4\u6620\u5c04\u5230\u79bb\u5b50\u9631\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u7684\u7269\u7406\u64cd\u4f5c\u3002\u6211\u4eec\u8fd8\u901a\u8fc7\u6570\u503c\u6a21\u62df\u7814\u7a76\u4e86\u91cf\u5b50\u7ea0\u9519\uff08QEC\uff09\u7801\u5728QKD\u534f\u8bae\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6ce8\u5165\u566a\u97f3\u4ee5\u7814\u7a76\u5176\u5bf9\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u7684\u5f71\u54cd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u91cf\u5b50\u7ea0\u9519\u7801\u53ef\u4ee5\u5e2e\u52a9\u6291\u5236\u566a\u97f3\u6c34\u5e73\uff0c\u76d1\u6d4b\u4fe1\u9053\u7684\u566a\u97f3\u5206\u5e03\uff0c\u4f7f\u901a\u4fe1\u65b9\u80fd\u591f\u68c0\u6d4b\u5230\u6f5c\u5728\u7a83\u542c\u9020\u6210\u7684\u5f02\u5e38\u566a\u97f3\u7279\u5f81\uff0c\u4ece\u800c\u4e3a\u91cf\u5b50\u901a\u4fe1\u63d0\u4f9b\u9690\u79c1\u8ba4\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u5728\u91cf\u5b50\u7ea0\u9519\u7801\u4e2d\u52a0\u5165\u5bf9\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u7684\u566a\u97f3\u6ce8\u5165\uff0c\u6211\u4eec\u80fd\u591f\u5b9e\u73b0\u5bf9\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u7684\u68c0\u6d4b\uff0c\u5e76\u4e3a\u91cf\u5b50\u901a\u4fe1\u63d0\u4f9b\u9690\u79c1\u8ba4\u8bc1\u3002"}}
{"id": "2507.14238", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14238", "abs": "https://arxiv.org/abs/2507.14238", "authors": ["Matthew Kearney", "Reuben Binns", "Yarin Gal"], "title": "Language Models Change Facts Based on the Way You Talk", "comment": null, "summary": "Large language models (LLMs) are increasingly being used in user-facing\napplications, from providing medical consultations to job interview advice.\nRecent research suggests that these models are becoming increasingly proficient\nat inferring identity information about the author of a piece of text from\nlinguistic patterns as subtle as the choice of a few words. However, little is\nknown about how LLMs use this information in their decision-making in\nreal-world applications. We perform the first comprehensive analysis of how\nidentity markers present in a user's writing bias LLM responses across five\ndifferent high-stakes LLM applications in the domains of medicine, law,\npolitics, government benefits, and job salaries. We find that LLMs are\nextremely sensitive to markers of identity in user queries and that race,\ngender, and age consistently influence LLM responses in these applications. For\ninstance, when providing medical advice, we find that models apply different\nstandards of care to individuals of different ethnicities for the same\nsymptoms; we find that LLMs are more likely to alter answers to align with a\nconservative (liberal) political worldview when asked factual questions by\nolder (younger) individuals; and that LLMs recommend lower salaries for\nnon-White job applicants and higher salaries for women compared to men. Taken\ntogether, these biases mean that the use of off-the-shelf LLMs for these\napplications may cause harmful differences in medical care, foster wage gaps,\nand create different political factual realities for people of different\nidentities. Beyond providing an analysis, we also provide new tools for\nevaluating how subtle encoding of identity in users' language choices impacts\nmodel decisions. Given the serious implications of these findings, we recommend\nthat similar thorough assessments of LLM use in user-facing applications are\nconducted before future deployment.", "AI": {"tldr": "LLM\u5728\u9762\u5411\u7528\u6237\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u4f1a\u56e0\u4e3a\u6587\u672c\u4e2d\u5305\u542b\u7684\u79cd\u65cf\u3001\u6027\u522b\u548c\u5e74\u9f84\u7b49\u8eab\u4efd\u6807\u8bb0\u800c\u4ea7\u751f\u504f\u89c1\uff0c\u5bfc\u81f4\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u548c\u5c31\u4e1a\u7b49\u9886\u57df\u51fa\u73b0\u4e0d\u516c\u5e73\u7684\u54cd\u5e94\u3002\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u65b0\u7684\u5de5\u5177\u6765\u8bc4\u4f30\u8fd9\u79cd\u5f71\u54cd\uff0c\u5e76\u5efa\u8bae\u5728\u90e8\u7f72\u524d\u8fdb\u884c\u5f7b\u5e95\u8bc4\u4f30\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4e8e\u9762\u5411\u7528\u6237\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u51b3\u7b56\u8fc7\u7a0b\u5374\u9c9c\u4e3a\u4eba\u77e5\uff0c\u7279\u522b\u662f\u5f53\u6587\u672c\u4e2d\u5b58\u5728\u7ec6\u5fae\u7684\u8eab\u4efd\u4fe1\u606f\u65f6\u3002\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u5206\u6790\u8eab\u4efd\u6807\u8bb0\u5982\u4f55\u5f71\u54cdLLM\u5728\u4e0d\u540c\u9ad8\u98ce\u9669\u9886\u57df\u7684\u54cd\u5e94\uff0c\u4ee5\u63ed\u793a\u6f5c\u5728\u7684\u504f\u89c1\u3002", "method": "\u672c\u7814\u7a76\u5bf9LLM\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u3001\u653f\u5e9c\u798f\u5229\u548c\u5c31\u4e1a\u85aa\u8d44\u8fd9\u4e94\u4e2a\u4e0d\u540c\u9ad8\u98ce\u9669\u5e94\u7528\u9886\u57df\u4e2d\uff0c\u5982\u4f55\u56e0\u7528\u6237\u4e66\u5199\u5185\u5bb9\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u800c\u4ea7\u751f\u504f\u89c1\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bc4\u4f30\u7528\u6237\u8bed\u8a00\u9009\u62e9\u4e2d\u8eab\u4efd\u7f16\u7801\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u51b3\u7b56\u7684\u65b0\u5de5\u5177\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5bf9\u7528\u6237\u67e5\u8be2\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u6781\u5176\u654f\u611f\uff0c\u79cd\u65cf\u3001\u6027\u522b\u548c\u5e74\u9f84\u5bf9LLM\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u3001\u653f\u5e9c\u798f\u5229\u548c\u5c31\u4e1a\u85aa\u8d44\u7b49\u9886\u57df\u7684\u54cd\u5e94\u5b58\u5728\u6301\u7eed\u5f71\u54cd\u3002\u4f8b\u5982\uff0cLLM\u5728\u533b\u7597\u5efa\u8bae\u4e2d\u5bf9\u4e0d\u540c\u79cd\u65cf\u9002\u7528\u4e0d\u540c\u7684\u62a4\u7406\u6807\u51c6\uff1b\u5728\u56de\u7b54\u4e8b\u5b9e\u95ee\u9898\u65f6\uff0c\u4f1a\u6839\u636e\u7528\u6237\u5e74\u9f84\u8c03\u6574\u7b54\u6848\u4ee5\u7b26\u5408\u653f\u6cbb\u503e\u5411\uff1b\u5e76\u5bf9\u975e\u767d\u4eba\u6c42\u804c\u8005\u5efa\u8bae\u8f83\u4f4e\u85aa\u8d44\uff0c\u5bf9\u5973\u6027\u5efa\u8bae\u8f83\u9ad8\u85aa\u8d44\u3002", "conclusion": "LLMs\u5728\u7528\u6237\u751f\u6210\u7684\u5185\u5bb9\u4e2d\u52a0\u5165\u8eab\u4efd\u6807\u8bb0\u65f6\uff0c\u4f1a\u5bf9\u5305\u62ec\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u3001\u653f\u5e9c\u798f\u5229\u548c\u5c31\u4e1a\u85aa\u8d44\u5728\u5185\u7684\u4e94\u4e2a\u4e0d\u540c\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u7684LLM\u54cd\u5e94\u4ea7\u751f\u504f\u89c1\u3002LLM\u5bf9\u7528\u6237\u67e5\u8be2\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u6781\u5176\u654f\u611f\uff0c\u79cd\u65cf\u3001\u6027\u522b\u548c\u5e74\u9f84\u4f1a\u6301\u7eed\u5f71\u54cdLLM\u7684\u54cd\u5e94\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u63d0\u4f9b\u533b\u7597\u5efa\u8bae\u65f6\uff0cLLM\u4f1a\u6839\u636e\u4e0d\u540c\u7684\u79cd\u65cf\u63d0\u4f9b\u4e0d\u540c\u7684\u62a4\u7406\u6807\u51c6\uff1b\u5728\u56de\u7b54\u4e8b\u5b9e\u95ee\u9898\u65f6\uff0cLLM\u4f1a\u6839\u636e\u7528\u6237\u7684\u5e74\u9f84\uff08\u8001\u5e74\u4eba\u6216\u5e74\u8f7b\u4eba\uff09\u8c03\u6574\u7b54\u6848\u4ee5\u7b26\u5408\u4fdd\u5b88\u515a\u6216\u81ea\u7531\u515a\u7684\u4e16\u754c\u89c2\uff1bLLM\u4f1a\u7ed9\u975e\u767d\u4eba\u6c42\u804c\u8005\u5efa\u8bae\u8f83\u4f4e\u7684\u85aa\u8d44\uff0c\u800c\u7ed9\u5973\u6027\u7684\u5efa\u8bae\u9ad8\u4e8e\u7537\u6027\u3002\u8fd9\u4e9b\u504f\u89c1\u53ef\u80fd\u5bfc\u81f4\u4e0d\u540c\u7684\u533b\u7597\u62a4\u7406\u3001\u52a0\u5267\u85aa\u916c\u5dee\u8ddd\u4ee5\u53ca\u57fa\u4e8e\u4e0d\u540c\u8eab\u4efd\u7684\u4eba\u4eec\u9762\u4e34\u4e0d\u540c\u7684\u653f\u6cbb\u4e8b\u5b9e\u3002\u56e0\u6b64\uff0c\u5728\u672a\u6765\u90e8\u7f72LLM\u7528\u6237\u754c\u9762\u5e94\u7528\u4e4b\u524d\uff0c\u5e94\u8fdb\u884c\u7c7b\u4f3c\u5f7b\u5e95\u7684\u8bc4\u4f30\u3002"}}
{"id": "2507.15454", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.15454", "abs": "https://arxiv.org/abs/2507.15454", "authors": ["Ruijie Zhu", "Mulin Yu", "Linning Xu", "Lihan Jiang", "Yixuan Li", "Tianzhu Zhang", "Jiangmiao Pang", "Bo Dai"], "title": "ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting", "comment": "Accepted by ICCV 2025", "summary": "3D Gaussian Splatting is renowned for its high-fidelity reconstructions and\nreal-time novel view synthesis, yet its lack of semantic understanding limits\nobject-level perception. In this work, we propose ObjectGS, an object-aware\nframework that unifies 3D scene reconstruction with semantic understanding.\nInstead of treating the scene as a unified whole, ObjectGS models individual\nobjects as local anchors that generate neural Gaussians and share object IDs,\nenabling precise object-level reconstruction. During training, we dynamically\ngrow or prune these anchors and optimize their features, while a one-hot ID\nencoding with a classification loss enforces clear semantic constraints. We\nshow through extensive experiments that ObjectGS not only outperforms\nstate-of-the-art methods on open-vocabulary and panoptic segmentation tasks,\nbut also integrates seamlessly with applications like mesh extraction and scene\nediting. Project page: https://ruijiezhu94.github.io/ObjectGS_page", "AI": {"tldr": "\u63d0\u51faObjectGS\u6846\u67b6\uff0c\u5b9e\u73b0\u4e863D\u573a\u666f\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\u7684\u7edf\u4e00\uff0c\u80fd\u591f\u8fdb\u884c\u7cbe\u786e\u7684\u5bf9\u8c61\u7ea7\u91cd\u5efa\uff0c\u5e76\u5728\u5206\u5272\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b33D\u9ad8\u65af\u6cfc\u6e85\u6cd5\uff083D Gaussian Splatting\uff09\u867d\u7136\u4ee5\u9ad8\u4fdd\u771f\u5ea6\u548c\u5b9e\u65f6\u65b0\u89c6\u89d2\u5408\u6210\u800c\u95fb\u540d\uff0c\u4f46\u5176\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u9650\u5236\u4e86\u5bf9\u8c61\u7ea7\u611f\u77e5\u7684\u5c40\u9650\u6027\u3002", "method": "ObjectGS\u662f\u4e00\u4e2a\u5c063D\u573a\u666f\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\u76f8\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u573a\u666f\u4e2d\u7684\u5bf9\u8c61\u5efa\u6a21\u4e3a\u5c40\u90e8\u951a\u70b9\u6765\u751f\u6210\u795e\u7ecf\u9ad8\u65af\u5e76\u5171\u4eab\u5bf9\u8c61ID\uff0c\u4ece\u800c\u5b9e\u73b0\u7cbe\u786e\u7684\u5bf9\u8c61\u7ea7\u91cd\u5efa\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u52a8\u6001\u5730\u751f\u957f\u6216\u4fee\u526a\u8fd9\u4e9b\u951a\u70b9\u5e76\u4f18\u5316\u5b83\u4eec\u7684\u7279\u5f81\uff0c\u540c\u65f6\u4f7f\u7528\u72ec\u70edID\u7f16\u7801\u548c\u5206\u7c7b\u635f\u5931\u6765\u5f3a\u5236\u6267\u884c\u6e05\u6670\u7684\u8bed\u4e49\u7ea6\u675f\u3002", "result": "ObjectGS\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u5bf9\u8c61\u7ea7\u91cd\u5efa\uff0c\u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u5168\u666f\u5206\u5272\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8fd8\u80fd\u4e0e\u7f51\u683c\u63d0\u53d6\u548c\u573a\u666f\u7f16\u8f91\u7b49\u5e94\u7528\u826f\u597d\u96c6\u6210\u3002", "conclusion": "ObjectGS\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u5168\u666f\u5206\u5272\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u4e0e\u7f51\u683c\u63d0\u53d6\u548c\u573a\u666f\u7f16\u8f91\u7b49\u5e94\u7528\u65e0\u7f1d\u96c6\u6210\u3002"}}
{"id": "2507.15603", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.15603", "abs": "https://arxiv.org/abs/2507.15603", "authors": ["Haoxiong Ren", "Yangu He", "Kwunhang Wong", "Rui Bao", "Ning Lin", "Zhongrui Wang", "Dashan Shang"], "title": "When Pipelined In-Memory Accelerators Meet Spiking Direct Feedback Alignment: A Co-Design for Neuromorphic Edge Computing", "comment": "International Conference on Computer-Aided Design 2025", "summary": "Spiking Neural Networks (SNNs) are increasingly favored for deployment on\nresource-constrained edge devices due to their energy-efficient and\nevent-driven processing capabilities. However, training SNNs remains\nchallenging because of the computational intensity of traditional\nbackpropagation algorithms adapted for spike-based systems. In this paper, we\npropose a novel software-hardware co-design that introduces a hardware-friendly\ntraining algorithm, Spiking Direct Feedback Alignment (SDFA) and implement it\non a Resistive Random Access Memory (RRAM)-based In-Memory Computing (IMC)\narchitecture, referred to as PipeSDFA, to accelerate SNN training.\nSoftware-wise, the computational complexity of SNN training is reduced by the\nSDFA through the elimination of sequential error propagation. Hardware-wise, a\nthree-level pipelined dataflow is designed based on IMC architecture to\nparallelize the training process. Experimental results demonstrate that the\nPipeSDFA training accelerator incurs less than 2% accuracy loss on five\ndatasets compared to baselines, while achieving 1.1X~10.5X and 1.37X~2.1X\nreductions in training time and energy consumption, respectively compared to\nPipeLayer.", "AI": {"tldr": "\u63d0\u51faPipeSDFA\uff0c\u4e00\u79cd\u7ed3\u5408SDFA\u7b97\u6cd5\u548cRRAM IMC\u67b6\u6784\u7684SNN\u8bad\u7ec3\u52a0\u901f\u5668\uff0c\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u80fd\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5728\u8bad\u7ec3SNN\u65f6\u8ba1\u7b97\u91cf\u5927\uff0c\u8ba1\u7b97\u5bc6\u96c6\uff0c\u56e0\u6b64\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5305\u62ec\u4e00\u79cd\u540d\u4e3aSpiking Direct Feedback Alignment (SDFA) \u7684\u786c\u4ef6\u53cb\u597d\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u5b9e\u73b0\u4e8e\u57fa\u4e8e\u963b\u53d8\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668 (RRAM) \u7684\u5185\u5b58\u8ba1\u7b97 (IMC) \u67b6\u6784\uff08PipeSDFA\uff09\u4e0a\uff0c\u4ee5\u52a0\u901fSNN\u8bad\u7ec3\u3002SDFA\u901a\u8fc7\u6d88\u9664\u987a\u5e8f\u8bef\u5dee\u4f20\u64ad\u6765\u964d\u4f4eSNN\u8bad\u7ec3\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002IMC\u67b6\u6784\u91c7\u7528\u4e09\u7ea7\u6d41\u6c34\u7ebf\u6570\u636e\u6d41\u5e76\u884c\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "PipeSDFA\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e861.1X~10.5X\u7684\u8bad\u7ec3\u65f6\u95f4\u548c1.37X~2.1X\u7684\u80fd\u8017\u8282\u7701\uff0c\u540c\u65f6\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u51c6\u786e\u7387\u635f\u5931\u5c0f\u4e8e2%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684PipeSDFA\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e861.1X~10.5X\u7684\u8bad\u7ec3\u65f6\u95f4\u548c1.37X~2.1X\u7684\u80fd\u8017\u8282\u7701\uff0c\u540c\u65f6\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u51c6\u786e\u7387\u635f\u5931\u5c0f\u4e8e2%\u3002"}}
{"id": "2507.15460", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15460", "abs": "https://arxiv.org/abs/2507.15460", "authors": ["Mehdi Khalaj", "Shahrzad Golestani Najafabadi", "Julita Vassileva"], "title": "Privacy-Preserving Multimodal News Recommendation through Federated Learning", "comment": null, "summary": "Personalized News Recommendation systems (PNR) have emerged as a solution to\ninformation overload by predicting and suggesting news items tailored to\nindividual user interests. However, traditional PNR systems face several\nchallenges, including an overreliance on textual content, common neglect of\nshort-term user interests, and significant privacy concerns due to centralized\ndata storage. This paper addresses these issues by introducing a novel\nmultimodal federated learning-based approach for news recommendation. First, it\nintegrates both textual and visual features of news items using a multimodal\nmodel, enabling a more comprehensive representation of content. Second, it\nemploys a time-aware model that balances users' long-term and short-term\ninterests through multi-head self-attention networks, improving recommendation\naccuracy. Finally, to enhance privacy, a federated learning framework is\nimplemented, enabling collaborative model training without sharing user data.\nThe framework divides the recommendation model into a large server-maintained\nnews model and a lightweight user model shared between the server and clients.\nThe client requests news representations (vectors) and a user model from the\ncentral server, then computes gradients with user local data, and finally sends\ntheir locally computed gradients to the server for aggregation. The central\nserver aggregates gradients to update the global user model and news model. The\nupdated news model is further used to infer news representation by the server.\nTo further safeguard user privacy, a secure aggregation algorithm based on\nShamir's secret sharing is employed. Experiments on a real-world news dataset\ndemonstrate strong performance compared to existing systems, representing a\nsignificant advancement in privacy-preserving personalized news recommendation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u6a21\u6001\u5b66\u4e60\u548c\u8054\u90a6\u5b66\u4e60\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u5728\u5185\u5bb9\u8868\u793a\u3001\u7528\u6237\u5174\u8da3\u6355\u6349\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u4e2a\u6027\u5316\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\uff08PNR\uff09\u5728\u5e94\u5bf9\u4fe1\u606f\u8fc7\u8f7d\u65b9\u9762\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u5185\u5bb9\uff0c\u5ffd\u7565\u7528\u6237\u7684\u77ed\u671f\u5174\u8da3\uff0c\u5e76\u4e14\u7531\u4e8e\u4e2d\u5fc3\u5316\u6570\u636e\u5b58\u50a8\u800c\u5f15\u53d1\u4e25\u91cd\u7684\u9690\u79c1\u62c5\u5fe7\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u3001\u540c\u65f6\u5173\u6ce8\u7528\u6237\u957f\u671f\u548c\u77ed\u671f\u5174\u8da3\uff0c\u5e76\u80fd\u6709\u6548\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u6a21\u6001\u5b66\u4e60\u548c\u8054\u90a6\u5b66\u4e60\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u5229\u7528\u591a\u6a21\u6001\u6a21\u578b\u878d\u5408\u65b0\u95fb\u7684\u6587\u672c\u548c\u89c6\u89c9\u7279\u5f81\uff1b\u5176\u6b21\uff0c\u91c7\u7528\u65f6\u5e8f\u611f\u77e5\u6a21\u578b\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u7f51\u7edc\u6765\u5e73\u8861\u7528\u6237\u7684\u957f\u671f\u548c\u77ed\u671f\u5174\u8da3\uff1b\u6700\u540e\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u5728\u4e0d\u5171\u4eab\u7528\u6237\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u534f\u540c\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u5c06\u63a8\u8350\u6a21\u578b\u5212\u5206\u4e3a\u670d\u52a1\u5668\u7ef4\u62a4\u7684\u65b0\u95fb\u6a21\u578b\u548c\u5ba2\u6237\u7aef\u5171\u4eab\u7684\u7528\u6237\u6a21\u578b\u3002\u5ba2\u6237\u7aef\u5728\u672c\u5730\u8ba1\u7b97\u68af\u5ea6\u5e76\u53d1\u9001\u81f3\u670d\u52a1\u5668\u8fdb\u884c\u805a\u5408\u66f4\u65b0\uff0c\u540c\u65f6\u91c7\u7528\u57fa\u4e8eShamir\u79d8\u5bc6\u5171\u4eab\u7684\u5b89\u5168\u805a\u5408\u7b97\u6cd5\u8fdb\u4e00\u6b65\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u3001\u5e73\u8861\u7528\u6237\u5174\u8da3\u4ee5\u53ca\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6587\u672c\u548c\u89c6\u89c9\u7279\u5f81\u3001\u8003\u8651\u77ed\u671f\u7528\u6237\u5174\u8da3\u4ee5\u53ca\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6765\u89e3\u51b3\u4f20\u7edf\u4e2a\u6027\u5316\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5176\u76f8\u5bf9\u4e8e\u73b0\u6709\u7cfb\u7edf\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u662f\u9690\u79c1\u4fdd\u62a4\u4e2a\u6027\u5316\u65b0\u95fb\u63a8\u8350\u9886\u57df\u7684\u4e00\u9879\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2507.14812", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14812", "abs": "https://arxiv.org/abs/2507.14812", "authors": ["Suho Kang", "Ziyang Liu", "Rajan Udwani"], "title": "A Black-Box Approach for Exogenous Replenishment in Online Resource Allocation", "comment": null, "summary": "In a typical online resource allocation problem, we start with a fixed\ninventory of resources and make online allocation decisions in response to\nresource requests that arrive sequentially over a finite horizon. We consider\nsettings where the inventory is replenished over time according to an unknown\nexogenous process. We introduce black-box methods that extend any existing\nalgorithm, originally designed without considering replenishment, into one that\nworks with an arbitrary (adversarial or stochastic) replenishment process. Our\napproach preserves the original algorithm's competitive ratio in regimes with\nlarge initial inventory, thereby enabling the seamless integration of exogenous\nreplenishment into a large body of existing algorithmic results for both\nadversarial and stochastic arrival models.", "AI": {"tldr": "\u9ed1\u76d2\u65b9\u6cd5\u6269\u5c55\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u4ee5\u5904\u7406\u5e93\u5b58\u8865\u5145\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5e93\u5b58\u968f\u65f6\u95f4\u6309\u672a\u77e5\u5916\u90e8\u8fc7\u7a0b\u8865\u5145\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ed1\u76d2\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5c06\u4e0d\u8003\u8651\u5e93\u5b58\u8865\u5145\u7684\u73b0\u6709\u7b97\u6cd5\u6269\u5c55\u5230\u80fd\u591f\u5904\u7406\u4efb\u610f\uff08\u5bf9\u6297\u6027\u6216\u968f\u673a\u6027\uff09\u5e93\u5b58\u8865\u5145\u8fc7\u7a0b\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5c06\u73b0\u6709\u7b97\u6cd5\u7684\u7ade\u4e89\u6bd4\u4fdd\u6301\u5728\u521d\u59cb\u5e93\u5b58\u5145\u8db3\u7684\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5c06\u5916\u90e8\u5e93\u5b58\u8865\u5145\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7b97\u6cd5\u4e2d\u7684\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5bf9\u6297\u6027\u548c\u968f\u673a\u6027\u5230\u8fbe\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u73b0\u6709\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u6269\u5c55\u5230\u8003\u8651\u5e93\u5b58\u8865\u5145\u7684\u9ed1\u76d2\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u521d\u59cb\u5e93\u5b58\u5145\u8db3\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4fdd\u6301\u539f\u7b97\u6cd5\u7684\u7ade\u4e89\u6bd4\u3002"}}
{"id": "2507.15813", "categories": ["physics.app-ph", "cs.CE", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2507.15813", "abs": "https://arxiv.org/abs/2507.15813", "authors": ["Ilaria Fontana", "Goustan Bacquaert", "Daniele A. Di Pietro", "Kyrylo Kazymyrenko"], "title": "Hyperelastic nature of the Hoek-Brown criterion", "comment": "Accepted for publication in European Journal of Mechanics - A/Solids", "summary": "We propose a nonlinear elasto-plastic model, for which a specific class of\nhyperbolic elasticity arises as a straight consequence of the yield criterion\ninvariance on the plasticity level. We superimpose this nonlinear elastic (or\nhyperelastic) behavior with plasticity obeying the associated flow rule.\nInterestingly, we find that a linear yield criterion on the thermodynamical\nforce associated with plasticity results in a quadratic yield criterion in the\nstress space. This suggests a specific hyperelastic connection between\nMohr-Coulomb and Hoek-Brown (or alternatively between Drucker-Prager and\nPan-Hudson) yield criteria. We compare the elasto-plastic responses of standard\ntests for the Drucker-Prager yield criterion using either linear or the\nsuggested hyperbolic elasticity. Notably, the nonlinear case stands out due to\ndilatancy saturation observed during cyclic loading in the triaxial compression\ntest. We conclude this study with structural finite element simulations that\nclearly demonstrate the numerical applicability of the proposed model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f39\u5851\u6027\u6a21\u578b\uff0c\u5c06\u975e\u7ebf\u6027\u5f39\u6027\u4e0e\u5851\u6027\u76f8\u7ed3\u5408\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u6709\u9650\u5143\u6a21\u62df\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u901a\u8fc7\u5c06\u7ebf\u6027\u5c48\u670d\u51c6\u5219\u5173\u8054\u5230\u4e0e\u5851\u6027\u76f8\u5173\u7684\u70ed\u529b\u5b66\u529b\uff0c\u5728\u5e94\u529b\u7a7a\u95f4\u4e2d\u5f97\u5230\u4e8c\u6b21\u5c48\u670d\u51c6\u5219\uff0c\u4ece\u800c\u5c06Mohr-Coulomb\u4e0eHoek-Brown\u6216Drucker-Prager\u4e0ePan-Hudson\u5c48\u670d\u51c6\u5219\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u7ebf\u6027\u5f39\u5851\u6027\u6a21\u578b\uff0c\u5176\u4e2d\u53cc\u66f2\u5f39\u6027\u662f\u5c48\u670d\u51c6\u5219\u4e0d\u53d8\u6027\u7684\u76f4\u63a5\u7ed3\u679c\u3002\u5c06\u6b64\u975e\u7ebf\u6027\u5f39\u6027\u884c\u4e3a\u4e0e\u670d\u4ece\u76f8\u5173\u6d41\u52a8\u6cd5\u5219\u7684\u53ef\u5851\u6027\u53e0\u52a0\u3002", "result": "\u4e0e\u4f7f\u7528\u7ebf\u6027\u6216\u5efa\u8bae\u7684\u53cc\u66f2\u5f39\u6027\u7684Drucker-Prager\u5c48\u670d\u51c6\u5219\u7684\u6807\u51c6\u6d4b\u8bd5\u7684\u5f39\u5851\u6027\u54cd\u5e94\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u53d1\u73b0\u975e\u7ebf\u6027\u60c5\u51b5\u5728\u4e09\u8f74\u538b\u7f29\u8bd5\u9a8c\u7684\u5faa\u73af\u52a0\u8f7d\u4e2d\u8868\u73b0\u51fa\u72ec\u7279\u7684\u5e94\u53d8\u8f6f\u5316\u73b0\u8c61\u3002", "conclusion": "\u8be5\u6a21\u578b\u5177\u6709\u6570\u503c\u9002\u7528\u6027\uff0c\u5728\u4e09\u8f74\u538b\u7f29\u8bd5\u9a8c\u7684\u5faa\u73af\u52a0\u8f7d\u4e2d\u8868\u73b0\u51fa\u5e94\u53d8\u8f6f\u5316\u73b0\u8c61\u3002"}}
{"id": "2507.15676", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.15676", "abs": "https://arxiv.org/abs/2507.15676", "authors": ["Reza Vatankhah Barenji", "Sina Khoshgoftar"], "title": "Agentic AI for autonomous anomaly management in complex systems", "comment": null, "summary": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.", "AI": {"tldr": "Agentic AI can automate anomaly detection and response in complex systems.", "motivation": "To explore the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems and to transform traditional, human-dependent anomaly management methods.", "method": "Exploration of agentic AI capabilities.", "result": "Agentic AI has the potential to significantly improve anomaly detection and response.", "conclusion": "Agentic AI can autonomously detect and respond to anomalies in complex systems, transforming traditional methods."}}
{"id": "2507.15735", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.15735", "abs": "https://arxiv.org/abs/2507.15735", "authors": ["Sergiu Hart", "Noam Nisan"], "title": "The Root of Revenue Continuity", "comment": null, "summary": "In the setup of selling one or more goods, various papers have shown, in\nvarious forms and for various purposes, that a small change in the distribution\nof a buyer's valuations may cause only a small change in the possible revenue\nthat can be extracted. We prove a simple, clean, convenient, and general\nstatement to this effect: let X and Y be random valuations on k additive goods,\nand let W(X,Y) be the Wasserstein (or \"earth mover's\") distance between them;\nthen sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y)). This further implies that a\nsimple explicit modification of any optimal mechanism for X, namely, \"uniform\ndiscounting\", is guaranteed to be almost optimal for any Y that is close to X\nin the Wasserstein distance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u6536\u5165\u548cWasserstein\u8ddd\u79bb\u7684\u6570\u5b66\u5b9a\u7406\uff0c\u4e3a\u673a\u5236\u8bbe\u8ba1\u4e2d\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "motivation": "\u5728\u9500\u552e\u4e00\u79cd\u6216\u591a\u79cd\u5546\u54c1\u7684\u8bbe\u7f6e\u4e2d\uff0c\u4e70\u65b9\u7684\u4f30\u4ef7\u5206\u5e03\u7684\u5fae\u5c0f\u53d8\u5316\u53ef\u80fd\u53ea\u4f1a\u5f15\u8d77\u53ef\u63d0\u53d6\u6536\u5165\u7684\u5fae\u5c0f\u53d8\u5316\u3002", "method": "\u5bf9X\u7684\u6700\u4f73\u673a\u5236\u8fdb\u884c\u7b80\u5355\u7684\u663e\u5f0f\u4fee\u6539\uff0c\u5373\u201c\u7edf\u4e00\u6298\u6263\u201d\uff0c\u4fdd\u8bc1\u5bf9\u4e8eWasserstein\u8ddd\u79bb\u63a5\u8fd1X\u7684\u4efb\u4f55Y\u51e0\u4e4e\u90fd\u662f\u6700\u4f18\u7684\u3002", "result": "sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y))\uff0c\u5e76\u4e14\u5bf9\u4e8eX\u7684\u4efb\u4f55\u6700\u4f18\u673a\u5236\u7684\u7b80\u5355\u663e\u5f0f\u4fee\u6539\uff0c\u5373\u201c\u7edf\u4e00\u6298\u6263\u201d\uff0c\u4fdd\u8bc1\u5bf9\u4e8eWasserstein\u8ddd\u79bb\u63a5\u8fd1X\u7684\u4efb\u4f55Y\u51e0\u4e4e\u90fd\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u4e70\u65b9\u7684\u4f30\u4ef7\u5206\u5e03\u53d1\u751f\u5fae\u5c0f\u53d8\u5316\uff0c\u53ef\u80fd\u53ea\u4f1a\u5f15\u8d77\u53ef\u63d0\u53d6\u6536\u5165\u7684\u5fae\u5c0f\u53d8\u5316\uff0c\u5e76\u4e14\u5bf9\u4e8eX\u548cY\u4e4b\u95f4\u7684Wasserstein\uff08\u6216\u201c\u571f\u65b9\u201d\uff09\u8ddd\u79bb\uff0c\u6211\u4eec\u8bc1\u660e\u4e86sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y))\u3002"}}
{"id": "2507.14138", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14138", "abs": "https://arxiv.org/abs/2507.14138", "authors": ["Vaishnavi C K", "Sricharan Vijayarangan", "Sri Gayathri G", "Danush Adhithya N", "Alex Joseph", "Preejith SP", "Mohanasankar Sivaprakasam"], "title": "Optimizing VO2max Prediction in Gamified Cardiac Assessment: Leveraging Effective Feature Selection and Refined Protocols for Robust Models", "comment": "Accepted and Presented in IEEE IECBES 2024", "summary": "VO2max is a critical indicator of cardiopulmonary fitness, reflecting the\nmaximum amount of oxygen the body can utilize during intense exercise.\nAccurately measuring VO2max is essential for assessing cardiovascular health\nand predicting outcomes in clinical settings. However, current methods for\nVO2max estimation, such as Cardiopulmonary Exercise Testing (CPET), require\nexpensive equipment and the supervision of trained personnel, limiting\naccessibility for large-scale screening. Preliminary efforts have been made to\ncreate a more accessible method, such as the Cardiopulmonary Spot Jog Test\n(CPSJT). Unfortunately, these early attempts yielded high error margins,\nrendering them unsuitable for widespread use. In our study, we address these\nshortcomings by refining the CPSJT protocol to improve prediction accuracy. A\ncrucial contribution is improved feature extraction which include gender, body\nmass index, aerobic duration, and anaerobic duration. This targeted approach\nhelps in streamlining the model to enhance prediction precision while\nminimizing the risk of overfitting. In a cohort of 44 participants from the\nIndian population, we assessed the performance of various machine learning\nmodels using these features. With Stratified 5-Fold Cross-Validation, the Root\nMean Squared Error (RMSE) values were 5.78 for Linear Regression, 5.15 for\nRandom Forest, and 5.17 for Support Vector Regression. All models demonstrated\nstrong test correlations and low RMSE values, underscoring their robust and\nreliable performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6539\u8fdbCPSJT\u65b9\u6848\u548c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662f\u968f\u673a\u68ee\u6797\uff09\u63d0\u9ad8\u4e86VO2max\u6d4b\u91cf\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u5fc3\u80ba\u5065\u5eb7\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6613\u4e8e\u83b7\u53d6\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684VO2max\u6d4b\u91cf\u65b9\u6cd5\uff08\u5982CPET\uff09\u6210\u672c\u9ad8\u6602\u4e14\u9700\u8981\u4e13\u4e1a\u4eba\u5458\u64cd\u4f5c\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u7b5b\u67e5\u4e2d\u7684\u5e94\u7528\u3002\u65e9\u671f\u7684CPSJT\u65b9\u6cd5\u5b58\u5728\u8bef\u5dee\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u4e0d\u9002\u5408\u5e7f\u6cdb\u4f7f\u7528\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u6613\u4e8e\u83b7\u53d6\u4e14\u66f4\u51c6\u786e\u7684VO2max\u4f30\u7b97\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6539\u8fdb\u7684Cardiopulmonary Spot Jog Test (CPSJT) \u65b9\u6848\uff0c\u5e76\u63d0\u53d6\u4e86\u6027\u522b\u3001\u8eab\u4f53\u8d28\u91cf\u6307\u6570\u3001\u6709\u6c27\u8fd0\u52a8\u65f6\u957f\u548c\u65e0\u6c27\u8fd0\u52a8\u65f6\u957f\u7b49\u5173\u952e\u7279\u5f81\uff0c\u4ee5\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5305\u62ec\u7ebf\u6027\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u548c\u652f\u6301\u5411\u91cf\u56de\u5f52\uff09\uff0c\u5e76\u4f7f\u7528\u5206\u5c425\u6298\u4ea4\u53c9\u9a8c\u8bc1\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u5305\u542b44\u540d\u5370\u5ea6\u53c2\u4e0e\u8005\u7684\u961f\u5217\u7814\u7a76\u4e2d\uff0c\u968f\u673a\u68ee\u6797\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\uff08RMSE\uff09\u4e3a5.15\uff0c\u4f18\u4e8e\u7ebf\u6027\u56de\u5f52\uff085.78\uff09\u548c\u652f\u6301\u5411\u91cf\u56de\u5f52\uff085.17\uff09\u3002\u6240\u6709\u6a21\u578b\u7684\u6d4b\u8bd5\u76f8\u5173\u6027\u548c\u4f4eRMSE\u503c\u5747\u8868\u660e\u5176\u6027\u80fd\u7a33\u5065\u4e14\u53ef\u9760\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u6539\u8fdb\u7684CPSJT\u65b9\u6848\u548c\u7279\u5f81\u63d0\u53d6\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86VO2max\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5176\u4e2d\u968f\u673a\u68ee\u6797\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cRMSE\u503c\u4e3a5.15\uff0c\u663e\u793a\u51fa\u7a33\u5065\u53ef\u9760\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14516", "categories": ["cs.LG", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.14516", "abs": "https://arxiv.org/abs/2507.14516", "authors": ["Jeyoung Lee", "Hochul Kang"], "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning", "comment": null, "summary": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware\nmetric function for time series self-supervised representation learning. Most\nSelf-Supervised Learning (SSL) methods for signals commonly adopt\ndistance-based objectives such as mean squared error (MSE), which are sensitive\nto amplitude, invariant to waveform polarity, and unbounded in scale. These\nproperties hinder semantic alignment and reduce interpretability. SDSC\naddresses this by quantifying structural agreement between temporal signals\nbased on the intersection of signed amplitudes, derived from the Dice\nSimilarity Coefficient (DSC).Although SDSC is defined as a structure-aware\nmetric, it can be used as a loss by subtracting from 1 and applying a\ndifferentiable approximation of the Heaviside function for gradient-based\noptimization. A hybrid loss formulation is also proposed to combine SDSC with\nMSE, improving stability and preserving amplitude where necessary. Experiments\non forecasting and classification benchmarks demonstrate that SDSC-based\npre-training achieves comparable or improved performance over MSE, particularly\nin in-domain and low-resource scenarios. The results suggest that structural\nfidelity in signal representations enhances the semantic representation\nquality, supporting the consideration of structure-aware metrics as viable\nalternatives to conventional distance-based methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a SDSC \u7684\u65b0\u5ea6\u91cf\u51fd\u6570\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8e\u8ddd\u79bb\u7684\u65b9\u6cd5\uff08\u5982 MSE\uff09\u7684\u5c40\u9650\u6027\u3002SDSC \u901a\u8fc7\u8861\u91cf\u7ed3\u6784\u4e00\u81f4\u6027\u6765\u63d0\u9ad8\u8868\u793a\u7684\u8bed\u4e49\u8d28\u91cf\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u635f\u5931\u51fd\u6570\uff08\u5982 MSE\uff09\uff0c\u8fd9\u4e9b\u51fd\u6570\u5bf9\u5e45\u5ea6\u654f\u611f\u3001\u5bf9\u6ce2\u5f62\u6781\u6027\u4e0d\u654f\u611f\u4e14\u5c3a\u5ea6\u65e0\u754c\uff0c\u4ece\u800c\u963b\u788d\u4e86\u8bed\u4e49\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u4fe1\u53f7\u9ab0\u5b50\u76f8\u4f3c\u7cfb\u6570\uff08SDSC\uff09\u7684\u7ed3\u6784\u611f\u77e5\u5ea6\u91cf\u51fd\u6570\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u3002SDSC \u57fa\u4e8e\u9ab0\u5b50\u76f8\u4f3c\u7cfb\u6570\uff08DSC\uff09\uff0c\u901a\u8fc7\u91cf\u5316\u65f6\u95f4\u4fe1\u53f7\u4e4b\u95f4\u57fa\u4e8e\u7b26\u53f7\u5e45\u5ea6\u7684\u4ea4\u96c6\u6765\u8861\u91cf\u7ed3\u6784\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u635f\u5931\u51fd\u6570\uff0c\u5c06 SDSC \u4e0e\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u76f8\u7ed3\u5408\uff0c\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u5728\u5fc5\u8981\u65f6\u4fdd\u7559\u5e45\u5ea6\u3002", "result": "\u5728\u9884\u6d4b\u548c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8e SDSC \u7684\u9884\u8bad\u7ec3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff08\u5c24\u5176\u662f\u5728\u57df\u5185\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\uff09\u5b9e\u73b0\u4e86\u4e0e MSE \u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u5728\u4fe1\u53f7\u8868\u793a\u5b66\u4e60\u4e2d\uff0c\u7ed3\u6784\u4fdd\u771f\u5ea6\u53ef\u4ee5\u63d0\u9ad8\u8bed\u4e49\u8868\u793a\u8d28\u91cf\uff0c\u8868\u660e\u7ed3\u6784\u611f\u77e5\u5ea6\u91cf\u53ef\u4ee5\u4f5c\u4e3a\u4f20\u7edf\u57fa\u4e8e\u8ddd\u79bb\u7684\u65b9\u6cd5\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.15154", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.15154", "abs": "https://arxiv.org/abs/2507.15154", "authors": ["Kohya Shiozaki", "Junya Nakamura"], "title": "Dynatune: Dynamic Tuning of Raft Election Parameters Using Network Measurement", "comment": "This paper was accepted at the 27th International Workshop on\n  Advances in Parallel and Distributed Computational Models (APDCM 2025), held\n  in conjunction with IPDPS 2025", "summary": "Raft is a leader-based consensus algorithm that implements State Machine\nReplication (SMR), which replicates the service state across multiple servers\nto enhance fault tolerance. In Raft, the servers play one of three roles:\nleader, follower, or candidate. The leader receives client requests, determines\nthe processing order, and replicates them to the followers. When the leader\nfails, the service must elect a new leader to continue processing requests,\nduring which the service experiences an out-of-service (OTS) time. The OTS time\nis directly influenced by election parameters, such as heartbeat interval and\nelection timeout. However, traditional approaches, such as Raft, often struggle\nto effectively tune these parameters, particularly under fluctuating network\nconditions, leading to increased OTS time and reduced service responsiveness.\nTo address this, we propose Dynatune, a mechanism that dynamically adjusts\nRaft's election parameters based on network metrics such as round-trip time and\npacket loss rates measured via heartbeats. By adapting to changing network\nenvironments, Dynatune significantly reduces the leader failure detection and\nOTS time without altering Raft's core mechanisms or introducing additional\ncommunication overheads. Experimental results demonstrate that Dynatune reduces\nthe leader failure detection and OTS times by 80% and 45%, respectively,\ncompared with Raft, while maintaining high availability even under dynamic\nnetwork conditions. These findings confirm that Dynatune effectively enhances\nthe performance and reliability of SMR services in various network scenarios.", "AI": {"tldr": "Dynatune\u662f\u4e00\u79cd\u52a8\u6001\u8c03\u6574Raft\u9009\u4e3e\u53c2\u6570\u4ee5\u51cf\u5c11\u975e\u670d\u52a1\uff08OTS\uff09\u65f6\u95f4\u7684\u673a\u5236\uff0c\u53ef\u5e94\u5bf9\u7f51\u7edc\u6ce2\u52a8\u3002", "motivation": "\u4f20\u7edfRaft\u7b97\u6cd5\u5728\u8c03\u6574\u9009\u4e3e\u53c2\u6570\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7f51\u7edc\u6761\u4ef6\u6ce2\u52a8\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u66f4\u957f\u7684\u975e\u670d\u52a1\uff08OTS\uff09\u65f6\u95f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDynatune\u7684\u673a\u5236\uff0c\u8be5\u673a\u5236\u6839\u636e\u901a\u8fc7\u5fc3\u8df3\u6d4b\u91cf\u7684\u5f80\u8fd4\u65f6\u95f4\u548c\u4e22\u5305\u7387\u7b49\u7f51\u7edc\u6307\u6807\u52a8\u6001\u8c03\u6574Raft\u7684\u9009\u4e3e\u53c2\u6570\u3002", "result": "Dynatune\u5c06\u9886\u5bfc\u8005\u6545\u969c\u68c0\u6d4b\u548c\u975e\u670d\u52a1\uff08OTS\uff09\u65f6\u95f4\u5206\u522b\u51cf\u5c11\u4e8680%\u548c45%\uff0c\u540c\u65f6\u5728\u9ad8\u53ef\u7528\u6027\u751a\u81f3\u52a8\u6001\u7f51\u7edc\u6761\u4ef6\u4e0b\u4fdd\u6301\u4e86\u9ad8\u53ef\u7528\u6027\u3002", "conclusion": "Dynatune\u901a\u8fc7\u6839\u636e\u8bf8\u5982\u5f80\u8fd4\u65f6\u95f4\u548c\u4e22\u5305\u7387\u7b49\u7f51\u7edc\u6307\u6807\u52a8\u6001\u8c03\u6574Raft\u7684\u9009\u4e3e\u53c2\u6570\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9886\u5bfc\u8005\u6545\u969c\u68c0\u6d4b\u548c\u975e\u670d\u52a1\uff08OTS\uff09\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u53ef\u7528\u6027\u3002"}}
{"id": "2507.14605", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14605", "abs": "https://arxiv.org/abs/2507.14605", "authors": ["Chun-Ming Yang", "Pranav A. Bhounsule"], "title": "Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition", "comment": null, "summary": "Online optimal control of quadrupedal robots would enable them to plan their\nmovement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged\nas a practical approach for real-time control. In LMPC, an optimization problem\nwith a quadratic cost and linear constraints is formulated over a finite\nhorizon and solved on the fly. However, LMPC relies on linearizing the\nequations of motion (EOM), which may lead to poor solution quality. In this\npaper, we use Koopman operator theory and the Extended Dynamic Mode\nDecomposition (EDMD) to create a linear model of the system in high dimensional\nspace, thus retaining the nonlinearity of the EOM. We model the aerial phase\nand ground contact phases using different linear models. Then, using LMPC, we\ndemonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait\ntransitions in level and rough terrains. The main novelty is the use of Koopman\noperator theory to create hybrid models of a quadrupedal system and demonstrate\nthe online generation of multiple gaits and gaits transitions.", "AI": {"tldr": "\u4f7f\u7528 Koopman \u7b97\u5b50\u7406\u8bba\u548c LMPC \u6765\u63a7\u5236\u56db\u8db3\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u591a\u79cd\u6b65\u6001\u548c\u6b65\u6001\u8f6c\u6362\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u56db\u8db3\u673a\u5668\u4eba\u80fd\u591f\u5e94\u5bf9\u65b0\u573a\u666f\u7684\u5728\u7ebf\u6700\u4f18\u8fd0\u52a8\u89c4\u5212\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236 (LMPC) \u4e2d\u56e0\u8fd0\u52a8\u65b9\u7a0b\u7ebf\u6027\u5316\u800c\u5bfc\u81f4\u7684\u89e3\u7684\u8d28\u91cf\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408 Koopman \u7b97\u5b50\u7406\u8bba\u548c\u6269\u5c55\u52a8\u6001\u6a21\u5f0f\u5206\u89e3 (EDMD) \u7684\u65b9\u6cd5\uff0c\u4e3a\u56db\u8db3\u52a8\u7269\u7684\u8fd0\u52a8\u72b6\u6001\u65b9\u7a0b\uff08EOM\uff09\u521b\u5efa\u9ad8\u7ef4\u7ebf\u6027\u6a21\u578b\uff0c\u4ee5\u4fdd\u7559\u975e\u7ebf\u6027\u7279\u5f81\u3002\u8be5\u6a21\u578b\u533a\u5206\u4e86\u7a7a\u4e2d\u548c\u5730\u9762\u63a5\u89e6\u9636\u6bb5\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5229\u7528\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236 (LMPC) \u8fdb\u884c\u5728\u7ebf\u4f18\u5316\u63a7\u5236\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u5728\u5e73\u5766\u548c\u5d0e\u5c96\u5730\u5f62\u4e2d\uff0c\u4f7f\u7528 LMPC \u8fdb\u884c\u7684bounding\u3001trotting\u4ee5\u53cabound-to-trot\u548ctrot-to-bound\u7684\u6b65\u6001\u8f6c\u6362\u3002", "conclusion": "\u8be5\u7814\u7a76\u4f7f\u7528 Koopman \u7b97\u5b50\u7406\u8bba\u548c\u6269\u5c55\u52a8\u6001\u6a21\u5f0f\u5206\u89e3 (EDMD) \u521b\u5efa\u4e86\u56db\u8db3\u52a8\u7269\u7cfb\u7edf\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5e76\u5728\u4e0d\u540c\u5730\u5f62\u4e0a\u6f14\u793a\u4e86\u591a\u79cd\u6b65\u6001\u548c\u6b65\u6001\u8f6c\u6362\u7684\u5728\u7ebf\u751f\u6210\u3002"}}
{"id": "2507.14426", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14426", "abs": "https://arxiv.org/abs/2507.14426", "authors": ["Zhou Chen", "Joe Lin", "Sathyanarayanan N. Aakur"], "title": "CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding", "comment": "Accepted to NeSy 2025", "summary": "We introduce CRAFT, a neuro-symbolic framework for interpretable affordance\ngrounding, which identifies the objects in a scene that enable a given action\n(e.g., \"cut\"). CRAFT integrates structured commonsense priors from ConceptNet\nand language models with visual evidence from CLIP, using an energy-based\nreasoning loop to refine predictions iteratively. This process yields\ntransparent, goal-driven decisions to ground symbolic and perceptual\nstructures. Experiments in multi-object, label-free settings demonstrate that\nCRAFT enhances accuracy while improving interpretability, providing a step\ntoward robust and trustworthy scene understanding.", "AI": {"tldr": "CRAFT is a neuro-symbolic framework for interpretable affordance grounding that uses commonsense priors and visual evidence with an energy-based reasoning loop to identify objects enabling actions, improving accuracy and interpretability in scene understanding.", "motivation": "To introduce a neuro-symbolic framework for interpretable affordance grounding, which identifies the objects in a scene that enable a given action (e.g., \"cut\").", "method": "CRAFT integrates structured commonsense priors from ConceptNet and language models with visual evidence from CLIP, using an energy-based reasoning loop to refine predictions iteratively.", "result": "Experiments in multi-object, label-free settings demonstrate that CRAFT enhances accuracy while improving interpretability.", "conclusion": "CRAFT enhances accuracy while improving interpretability, providing a step toward robust and trustworthy scene understanding."}}
{"id": "2507.14393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14393", "abs": "https://arxiv.org/abs/2507.14393", "authors": ["Humza Sami", "Mubashir ul Islam", "Pierre-Emmanuel Gaillardon", "Valerio Tenace"], "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation", "comment": null, "summary": "The rise of Large Reasoning Models (LRMs) promises a significant leap forward\nin language model capabilities, aiming to tackle increasingly sophisticated\ntasks with unprecedented efficiency and accuracy. However, despite their\nimpressive performance, recent studies have highlighted how current reasoning\nmodels frequently fail to generalize to novel, unseen problems, often resorting\nto memorized solutions rather than genuine inferential reasoning. Such behavior\nunderscores a critical limitation in modern LRMs, i.e., their tendency toward\noverfitting, which in turn results in poor generalization in problem-solving\ncapabilities.\n  In this paper, we introduce Nexus Architect, an enhanced iteration of our\nmulti-agent system framework, Nexus, equipped with a novel automated workflow\nsynthesis mechanism. Given a user's prompt and a small set of representative\nexamples, the Architect autonomously generates a tailored reasoning workflow by\nselecting suitable strategies, tool integrations, and adversarial techniques\nfor a specific problem class. Furthermore, the Architect includes an iterative\nprompt refinement mechanism that fine-tunes agents' system prompts to maximize\nperformance and improve the generalization capabilities of the system.\n  We empirically evaluate Nexus Architect by employing an off-the-shelf,\nnon-reasoning model on a custom dataset of challenging logical questions and\ncompare its performance against state-of-the-art LRMs. Results show that Nexus\nArchitect consistently outperforms existing solutions, achieving up to a 66%\nincrease in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against\nClaude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.", "AI": {"tldr": "Nexus Architect\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5408\u6210\u548c\u63d0\u793a\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u80fd\u529b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5b83\u4eec\u5728\u6cdb\u5316\u5230\u65b0\u9896\u3001\u672a\u89c1\u8fc7\u7684\u95ee\u9898\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5e38\u5e38\u4f9d\u8d56\u8bb0\u5fc6\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002\u8fd9\u79cd\u8fc7\u62df\u5408\u73b0\u8c61\u662f\u73b0\u4ee3LRMs\u7684\u4e00\u4e2a\u5173\u952e\u9650\u5236\uff0c\u5bfc\u81f4\u5176\u89e3\u51b3\u95ee\u9898\u80fd\u529b\u6cdb\u5316\u6027\u5dee\u3002", "method": "Nexus Architect\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\uff0c\u6839\u636e\u7528\u6237\u63d0\u4f9b\u7684\u63d0\u793a\u548c\u793a\u4f8b\uff0c\u81ea\u4e3b\u751f\u6210\u5b9a\u5236\u5316\u7684\u63a8\u7406\u5de5\u4f5c\u6d41\uff0c\u5305\u62ec\u9009\u62e9\u5408\u9002\u7684\u7b56\u7565\u3001\u5de5\u5177\u96c6\u6210\u548c\u5bf9\u6297\u6280\u672f\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5305\u542b\u4e00\u4e2a\u8fed\u4ee3\u5f0f\u63d0\u793a\u4f18\u5316\u673a\u5236\uff0c\u7528\u4e8e\u8c03\u6574\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\u63d0\u793a\uff0c\u4ee5\u6700\u5927\u5316\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "Nexus Architect\u5728\u81ea\u5b9a\u4e49\u7684\u6311\u6218\u6027\u903b\u8f91\u95ee\u9898\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u8f83\u4e8eGemini 2.5 Flash Preview\u3001Claude Sonnet 4\u3001DeepSeek-R1\u548cLlama 4 Scout\u7b49\u5148\u8fdb\u6a21\u578b\uff0c\u5c55\u73b0\u51fa\u4e86\u4e00\u81f4\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u901a\u5173\u7387\u6700\u9ad8\u5206\u522b\u63d0\u9ad8\u4e8666%\u3001\u8fd12.5\u500d\u548c\u8d85\u8fc73\u500d\u3002", "conclusion": "Nexus Architect\u901a\u8fc7\u5176\u65b0\u9896\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\u548c\u8fed\u4ee3\u5f0f\u63d0\u793a\u4f18\u5316\uff0c\u5728\u89e3\u51b3\u590d\u6742\u903b\u8f91\u95ee\u9898\u548c\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u5927\u578b\u63a8\u7406\u6a21\u578b\u3002"}}
{"id": "2507.14585", "categories": ["cond-mat.mes-hall", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2507.14585", "abs": "https://arxiv.org/abs/2507.14585", "authors": ["P. N. Kozhevin", "A. D. Liubomirov", "R. V. Cherbunin", "M. A. Chukeev", "I. Yu. Chestnov", "A. V. Kavokin", "A. V. Nalitov"], "title": "Supersolidity in Optically Trapped Polariton Condensates", "comment": "16 pages, 8 figures", "summary": "Superfluids under specific conditions can exhibit spontaneous breaking of\ncontinuous translation symmetries and form exotic spatially ordered states of\nmatter known as supersolids. Despite its early theoretical prediction, it took\nover half-a-centrury to experimentally demonstrate the supersolid phase in\nultracold atomic Bose-Einstein condensates, forming due to long-range\ninteratomic interactions. Here we propose as a promising new platform for\nsupersolidity exciton-polariton superfluids, confined in annular optically\ninduced traps. The supersolid phase emerges due to effective attractive\ninteractions, mediated by the normal excitonic component of the system.\nExperimental demonstration of spontaneously formed spatially ordered phase is\nin agreement with detailed mean-field theoretical analysis and numerical\nsimulation. The spontaneous character of the observed supersolid transition is\nfurther evidenced by the formation of specific zero-energy Nambu-Goldstone\nmodes in the collective excitation spectrum.", "AI": {"tldr": "\u5728\u5149\u5b66\u9677\u9631\u4e2d\uff0c\u6fc0\u5b50-\u6781\u5316\u5b50\u8d85\u6d41\u4f53\u56e0\u5438\u5f15\u76f8\u4e92\u4f5c\u7528\u8868\u73b0\u51fa\u8d85\u56fa\u6001\u3002", "motivation": "\u63d0\u51fa\u6fc0\u5b50-\u6781\u5316\u5b50\u8d85\u6d41\u4f53\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u3001\u6709\u5e0c\u671b\u7684\u8d85\u56fa\u6001\u7814\u7a76\u5e73\u53f0\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u89c2\u6d4b\u548c\u7406\u8bba\u5206\u6790\uff08\u5305\u62ec\u5e73\u5747\u573a\u7406\u8bba\u548c\u6570\u503c\u6a21\u62df\uff09\u6765\u7814\u7a76\u6fc0\u5b50-\u6781\u5316\u5b50\u8d85\u6d41\u4f53\u3002", "result": "\u89c2\u5bdf\u5230\u81ea\u53d1\u5f62\u6210\u7684\u5177\u6709\u7a7a\u95f4\u6709\u5e8f\u76f8\u7684\u8d85\u56fa\u6001\uff0c\u5e76\u901a\u8fc7\u96f6\u80fdNambu-Goldstone\u6a21\u5f0f\u7684\u5f62\u6210\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u5176\u81ea\u53d1\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5728\u5149\u5b66\u8bf1\u5bfc\u7684\u73af\u5f62\u9677\u9631\u4e2d\uff0c\u6fc0\u5b50-\u6781\u5316\u5b50\u8d85\u6d41\u4f53\u7531\u4e8e\u6709\u6548\u7684\u5438\u5f15\u76f8\u4e92\u4f5c\u7528\u800c\u8868\u73b0\u51fa\u8d85\u56fa\u6001\u76f8\u53d8\u3002"}}
{"id": "2507.14178", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14178", "abs": "https://arxiv.org/abs/2507.14178", "authors": ["Yuhang Liu", "Yuefei Wu", "Bin Shi", "Bo Dong"], "title": "Feature Bank Enhancement for Distance-based Out-of-Distribution Detection", "comment": "8 pages, 5 figures", "summary": "Out-of-distribution (OOD) detection is critical to ensuring the reliability\nof deep learning applications and has attracted significant attention in recent\nyears. A rich body of literature has emerged to develop efficient score\nfunctions that assign high scores to in-distribution (ID) samples and low\nscores to OOD samples, thereby helping distinguish OOD samples. Among these\nmethods, distance-based score functions are widely used because of their\nefficiency and ease of use. However, deep learning often leads to a biased\ndistribution of data features, and extreme features are inevitable. These\nextreme features make the distance-based methods tend to assign too low scores\nto ID samples. This limits the OOD detection capabilities of such methods. To\naddress this issue, we propose a simple yet effective method, Feature Bank\nEnhancement (FBE), that uses statistical characteristics from dataset to\nidentify and constrain extreme features to the separation boundaries, therapy\nmaking the distance between samples inside and outside the distribution\nfarther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10\nrespectively, and the results show that our method achieves state-of-the-art\nperformance on both benchmark. Additionally, theoretical analysis and\nsupplementary experiments are conducted to provide more insights into our\nmethod.", "AI": {"tldr": "A new method called FBE improves out-of-distribution detection by handling extreme features in deep learning models, achieving top results on standard tests.", "motivation": "Deep learning's biased feature distributions and inevitable extreme features cause distance-based OOD detection methods to assign scores that are too low to in-distribution samples, limiting their OOD detection capabilities.", "method": "Feature Bank Enhancement (FBE), which utilizes statistical characteristics from the dataset to identify and constrain extreme features to separation boundaries.", "result": "Achieves state-of-the-art performance on large-scale ImageNet-1k and CIFAR-10 benchmarks, with further theoretical analysis and supplementary experiments providing additional insights.", "conclusion": "The proposed Feature Bank Enhancement (FBE) method effectively addresses the issue of extreme features limiting distance-based OOD detection by constraining these features to separation boundaries, thereby increasing the distance between in-distribution and out-of-distribution samples. Experiments on ImageNet-1k and CIFAR-10 demonstrate state-of-the-art performance."}}
{"id": "2507.14416", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14416", "abs": "https://arxiv.org/abs/2507.14416", "authors": ["Pablo Galaviz", "Kyle A. Portwin", "Dehong Yu", "Kirrily C. Rule", "David L. Cortie", "Zhenxiang Cheng"], "title": "Phonon density of states of magnetite (\\ce{Fe3O4}) nanoparticles via molecular dynamics simulations", "comment": "39 pages, 19 figures", "summary": "This study presents a comprehensive computational investigation of magnetite\nnanoparticles, systematically evaluating a range of force fields against\nexperimental results. We analyze the influence of particle size, temperature,\nand surface-adsorbed water molecules on the structural and dynamic properties\nof the nanoparticles. We performed classical molecular dynamics of\nnanoparticles and bulk magnetite and utilized density functional theory\ncalculations for bulk magnetite for comparison. Our results reveal that\nnanoparticle size and the presence of adsorbed water molecules have a\npronounced impact on the density of states. Specifically, as the nanoparticle\nsize is decreased, phonon modes exhibit significant broadening and softening,\nwhich is attributable to reduced phonon lifetimes resulting from enhanced\nboundary scattering. The incorporation of water further broadens the density of\nstates and extends the spectra to higher energy regions. Temperature variations\nresult in a slight broadening and softening of the phonon density of states,\nparticularly in the oxygen-dominated region, which is attributed to phonon\nanharmonicity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u5b50\u52a8\u529b\u5b66\u548c\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff0c\u63a2\u7a76\u4e86\u78c1\u94c1\u77ff\u7eb3\u7c73\u9897\u7c92\u7684\u5c3a\u5bf8\u3001\u6e29\u5ea6\u548c\u6c34\u5206\u5bf9\u5176\u58f0\u5b50\u72b6\u6001\u5bc6\u5ea6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5c3a\u5bf8\u51cf\u5c0f\u548c\u6c34\u5206\u5b50\u7684\u5b58\u5728\u4f1a\u5f15\u8d77\u58f0\u5b50\u6a21\u5f0f\u5c55\u5bbd\u548c\u8f6f\u5316\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u8ba1\u7b97\u7814\u7a76\u78c1\u94c1\u77ff\u7eb3\u7c73\u9897\u7c92\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u529b\u573a\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u7684\u543b\u5408\u5ea6\uff0c\u5e76\u63a2\u7a76\u9897\u7c92\u5c3a\u5bf8\u3001\u6e29\u5ea6\u53ca\u8868\u9762\u5438\u9644\u6c34\u5206\u5b50\u5bf9\u7eb3\u7c73\u9897\u7c92\u7ed3\u6784\u4e0e\u52a8\u529b\u5b66\u6027\u8d28\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u7ecf\u5178\u7684\u5206\u5b50\u52a8\u529b\u5b66\u65b9\u6cd5\u5bf9\u7eb3\u7c73\u9897\u7c92\u548c\u5757\u72b6\u78c1\u94c1\u77ff\u8fdb\u884c\u6a21\u62df\uff0c\u5e76\u5229\u7528\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\u5bf9\u5757\u72b6\u78c1\u94c1\u77ff\u8fdb\u884c\u6bd4\u5bf9\u5206\u6790\u3002\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u4e00\u7cfb\u5217\u529b\u573a\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u7684\u543b\u5408\u5ea6\uff0c\u5e76\u5206\u6790\u4e86\u9897\u7c92\u5c3a\u5bf8\u3001\u6e29\u5ea6\u4ee5\u53ca\u8868\u9762\u5438\u9644\u6c34\u5206\u5b50\u5bf9\u7eb3\u7c73\u9897\u7c92\u7ed3\u6784\u548c\u52a8\u529b\u5b66\u6027\u8d28\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7eb3\u7c73\u9897\u7c92\u5c3a\u5bf8\u548c\u5438\u9644\u6c34\u5206\u5b50\u7684\u5b58\u5728\u5bf9\u72b6\u6001\u5bc6\u5ea6\u6709\u663e\u8457\u5f71\u54cd\u3002\u51cf\u5c0f\u7eb3\u7c73\u9897\u7c92\u5c3a\u5bf8\u4f1a\u5bfc\u81f4\u58f0\u5b50\u6a21\u5f0f\u5c55\u5bbd\u548c\u8f6f\u5316\uff0c\u539f\u56e0\u662f\u8fb9\u754c\u6563\u5c04\u589e\u5f3a\u5bfc\u81f4\u58f0\u5b50\u5bff\u547d\u7f29\u77ed\u3002\u6c34\u5206\u5b50\u7684\u5f15\u5165\u4f1a\u8fdb\u4e00\u6b65\u5c55\u5bbd\u72b6\u6001\u5bc6\u5ea6\u5e76\u5c06\u5149\u8c31\u6269\u5c55\u5230\u66f4\u9ad8\u80fd\u91cf\u533a\u57df\u3002\u6e29\u5ea6\u53d8\u5316\u5f15\u8d77\u58f0\u5b50\u72b6\u6001\u5bc6\u5ea6\uff08\u5c24\u5176\u5728\u6c27\u4e3b\u5bfc\u533a\u57df\uff09\u7684\u5c55\u5bbd\u548c\u8f6f\u5316\uff0c\u8fd9\u662f\u7531\u58f0\u5b50\u975e\u8c10\u6027\u9020\u6210\u7684\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7eb3\u7c73\u9897\u7c92\u7684\u5927\u5c0f\u548c\u5438\u9644\u6c34\u5206\u5b50\u7684\u5b58\u5728\u5bf9\u72b6\u6001\u5bc6\u5ea6\u6709\u663e\u8457\u5f71\u54cd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u968f\u7740\u7eb3\u7c73\u9897\u7c92\u5c3a\u5bf8\u51cf\u5c0f\uff0c\u58f0\u5b50\u6a21\u5f0f\u8868\u73b0\u51fa\u660e\u663e\u7684\u5c55\u5bbd\u548c\u8f6f\u5316\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8fb9\u754c\u6563\u5c04\u589e\u5f3a\u5bfc\u81f4\u7684\u58f0\u5b50\u5bff\u547d\u7f29\u77ed\u3002\u6c34\u5206\u5b50\u7684\u5f15\u5165\u8fdb\u4e00\u6b65\u5c55\u5bbd\u4e86\u72b6\u6001\u5bc6\u5ea6\uff0c\u5e76\u5c06\u5149\u8c31\u6269\u5c55\u5230\u66f4\u9ad8\u7684\u80fd\u91cf\u533a\u57df\u3002\u6e29\u5ea6\u53d8\u5316\u5bfc\u81f4\u58f0\u5b50\u72b6\u6001\u5bc6\u5ea6\u7565\u6709\u5c55\u5bbd\u548c\u8f6f\u5316\uff0c\u5c24\u5176\u662f\u5728\u4ee5\u6c27\u4e3a\u4e3b\u7684\u533a\u57df\uff0c\u8fd9\u5f52\u56e0\u4e8e\u58f0\u5b50\u975e\u8c10\u6027\u3002"}}
{"id": "2507.14601", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14601", "abs": "https://arxiv.org/abs/2507.14601", "authors": ["Giacomo Oliveri", "Francesco Zardi", "Aaron Angel Salas Sancez", "Andrea Massa"], "title": "One-Time Programmable Passive Electromagnetic Skins", "comment": null, "summary": "The implementation of simple, inexpensive, and mass-production-oriented\nsolutions for smart electromagnetic environments (SEMEs) is dealt with by\nintroducing the concept of \"one-time programmable\" electromagnetic skins\n(OTP-EMSs). The simultaneous achievement of modular fabrication, (one-time)\nconfigurable reflection properties, passive-static operation, and zero\nmaintenance is yielded by integrating expendable components at the atomic level\nof EMSs. Towards this end, an OTP meta-atom structure is properly defined and\noptimized to build EMSs featuring the desired scenario-dependent EM wave\nmanipulation functionalities. In order to illustrate the features as well as to\npoint out the potentialities of OTP-EMSs, a representative set of analytical,\nnumerical, and experimental results is reported by considering different\napertures, illuminations, and EM wave manipulation requirements.", "AI": {"tldr": "A new type of electromagnetic skin (OTP-EMS) is proposed for smart environments. It's cheap, modular, configurable, and requires no maintenance. The paper shows how it works with various examples.", "motivation": "The motivation is to develop simple, inexpensive, and mass-production-oriented solutions for smart electromagnetic environments (SEMEs).", "method": "The paper introduces \"one-time programmable\" electromagnetic skins (OTP-EMSs) by integrating expendable components at the atomic level. An OTP meta-atom structure is defined and optimized to create EMSs with scenario-dependent EM wave manipulation functionalities.", "result": "The paper reports a representative set of analytical, numerical, and experimental results for different apertures, illuminations, and EM wave manipulation requirements to illustrate the features and potentialities of OTP-EMSs.", "conclusion": "OTP-EMSs are demonstrated to be a viable solution for smart electromagnetic environments, offering configurable reflection properties, passive operation, and zero maintenance."}}
{"id": "2507.14394", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14394", "abs": "https://arxiv.org/abs/2507.14394", "authors": ["John R. Pitten", "Nicholas Materise", "Wei-Ren Syong", "Jorge Ramirez", "Douglas Bennett", "Corey Rae H. McRae"], "title": "An Effective Reflection Mode Measurement for Hanger-Coupled Microwave Resonators", "comment": "10 pages, 4 figures", "summary": "Superconducting microwave resonators are used to study two-level system (TLS)\nloss in superconducting quantum devices. Fano asymmetry, characterized by a\nnonzero asymmetry angle $\\phi$ in the diameter correction method (DCM), results\nfrom the coupling schemes used to measure these devices, including the commonly\nused hanger method. $\\phi$ is an additional fitting parameter which contains no\nphysically interesting information and can obscure device parameters of\ninterest. The tee-junction symmetry nominally present in these resonator\ndevices provides an avenue for the elimination of Fano asymmetry using\ncalibrated measurement. We show that the eigenvalue associated with the common\nmode excitation of the resonator is an effective reflection mode (ERM) which\nhas no Fano asymmetry. Our analysis reveals the cause of Fano asymmetry as\ninterference between common and differential modes. Practically, we obtain the\nERM from a linear combination of calibrated reflection and transmission\nmeasurements. We utilize a 3D aluminum cavity to experimentally demonstrate the\nvalidity and flexibility of this model. To extend the usefulness of this\nsymmetry analysis, we apply perturbation theory to recover the ERM in a\nmultiplexed coplanar waveguide resonator device and experimentally demonstrate\nquantitative agreement in the extracted $Q_i^{-1}$ between hanger mode and ERM\nmeasurements. We observe a five-fold reduction in uncertainty from the ERM\ncompared to the standard hanger mode at the lowest measured power, -160 dBm\ndelivered to the device. This method could facilitate an increase in throughput\nof low-power superconducting resonator measurements by up to a factor of 25, as\nwell as allow the extraction of critical parameters from otherwise unfittable\ndevice data.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6d88\u9664\u8d85\u5bfc\u8c10\u632f\u5668\u4e2d\u6cd5\u8bfa\u4e0d\u5bf9\u79f0\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u83b7\u5f97\u65e0\u4e0d\u5bf9\u79f0\u6027\u7684ERM\uff0c\u63d0\u9ad8\u4e86\u6d4b\u91cf\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u6709\u671b\u5927\u5e45\u63d0\u5347\u6d4b\u91cf\u541e\u5410\u91cf\u3002", "motivation": "\u6cd5\u8bfa\u4e0d\u5bf9\u79f0\u6027\uff08\u7531\u76f4\u5f84\u6821\u6b63\u6cd5\uff08DCM\uff09\u4e2d\u7684\u975e\u96f6\u4e0d\u5bf9\u79f0\u89d2$\\\text{phi}$\u8868\u5f81\uff09\u662f\u7531\u6d4b\u91cf\u8fd9\u4e9b\u8bbe\u5907\u6240\u7528\u7684\u8026\u5408\u65b9\u6848\u5f15\u8d77\u7684\uff0c\u5e76\u4e14\u4f1a\u63a9\u76d6\u8bbe\u5907\u53c2\u6570\u3002\u672c\u7814\u7a76\u65e8\u5728\u6d88\u9664\u6cd5\u8bfa\u4e0d\u5bf9\u79f0\u6027\uff0c\u4ee5\u66f4\u7cbe\u786e\u5730\u63d0\u53d6\u8bbe\u5907\u53c2\u6570\u3002", "method": "\u901a\u8fc7\u6821\u51c6\u6d4b\u91cf\u83b7\u5f97ERM\uff0c\u5e76\u5229\u7528\u5fae\u6270\u7406\u8bba\u5728\u591a\u8def\u590d\u7528\u5e73\u9762\u6ce2\u5bfc\u8c10\u632f\u5668\u8bbe\u5907\u4e2d\u6062\u590dERM\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6a21\u578b\u57283D\u94dd\u8154\u548c\u591a\u8def\u590d\u7528\u5e73\u9762\u6ce2\u5bfc\u8c10\u632f\u5668\u8bbe\u5907\u4e2d\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002\u4e0e\u6807\u51c6\u7684\u540a\u6746\u6a21\u5f0f\u76f8\u6bd4\uff0cERM\u5728\u6700\u4f4e\u6d4b\u91cf\u529f\u7387\u4e0b\uff08-160 dBm\uff09\u5c06\u4e0d\u786e\u5b9a\u6027\u964d\u4f4e\u4e86\u4e94\u500d\u3002\u8be5\u65b9\u6cd5\u6709\u671b\u5c06\u4f4e\u529f\u7387\u8d85\u5bfc\u8c10\u632f\u5668\u6d4b\u91cf\u7684\u541e\u5410\u91cf\u63d0\u9ad825\u500d\uff0c\u5e76\u80fd\u4ece\u65e0\u6cd5\u62df\u5408\u7684\u6570\u636e\u4e2d\u63d0\u53d6\u5173\u952e\u53c2\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6d88\u9664\u8d85\u5bfc\u91cf\u5b50\u8bbe\u5907\u4e2d\u6cd5\u8bfa\u4e0d\u5bf9\u79f0\u6027\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u8c10\u632f\u5668\u8bbe\u5907\u7684T\u578b\u7ed3\u5bf9\u79f0\u6027\u3002\u901a\u8fc7\u6821\u51c6\u6d4b\u91cf\uff0c\u53ef\u4ee5\u83b7\u5f97\u4e00\u4e2a\u6ca1\u6709\u6cd5\u8bfa\u4e0d\u5bf9\u79f0\u6027\u7684\u6709\u6548\u53cd\u5c04\u6a21\u5f0f\uff08ERM\uff09\u3002"}}
{"id": "2507.14239", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14239", "abs": "https://arxiv.org/abs/2507.14239", "authors": ["Weihua Zheng", "Roy Ka-Wei Lee", "Zhengyuan Liu", "Kui Wu", "AiTi Aw", "Bowei Zou"], "title": "CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation", "comment": null, "summary": "Multilingual Large Language Models(MLLMs) demonstrate strong generalization\nacross languages, yet they remain prone to hallucinations, especially in\nlow-resource languages, due to training data imbalances. These hallucinations,\nwhich include inaccurate or fabricated outputs, are particularly problematic in\ndomain-specific generation tasks (Chataigner et al., 2024). To address this\nchallenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based\nCross-lingual Chain-of-Thought), a two-stage fine-tuning framework for\nmitigating hallucination in MLLMs. Our approach first enhances cross-lingual\nsemantic alignment through curriculum-based contrastive learning combined with\nnext-token prediction during continued pre-training. Building on this\nfoundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting\nstrategy during instruction fine-tuning, which guides the model to reason in a\nhigh-resource language before generating answers in the target low-resource\nlanguage. Experimental results show that CCL-XCoT reduces hallucination rates\nby up to 62% and substantially improves factual knowledge transfer across\nlanguage pairs, without relying on external retrieval or multi-model ensembles.", "AI": {"tldr": "CCL-XCoT\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u8de8\u8bed\u8a00\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u51cf\u5c11\u4e86\u591a\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u5e7b\u89c9\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u8fd9\u662f\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u4e0d\u5e73\u8861\u9020\u6210\u7684\uff0c\u8fd9\u5728\u9886\u57df\u7279\u5b9a\u751f\u6210\u4efb\u52a1\u4e2d\u5c24\u5176\u6210\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCCL-XCoT\u7684\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u57fa\u4e8e\u8bfe\u7a0b\u7684\u5bf9\u6bd4\u5b66\u4e60\u548c\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u6765\u589e\u5f3a\u8de8\u8bed\u8a00\u8bed\u4e49\u5bf9\u9f50\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5728\u6307\u4ee4\u5fae\u8c03\u4e2d\u5f15\u5165\u8de8\u8bed\u8a00\u601d\u7ef4\u94fe\uff08XCoT\uff09\u63d0\u793a\uff0c\u5f15\u5bfc\u6a21\u578b\u5148\u7528\u9ad8\u8d44\u6e90\u8bed\u8a00\u63a8\u7406\uff0c\u518d\u7528\u4f4e\u8d44\u6e90\u8bed\u8a00\u751f\u6210\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCCL-XCoT\u5c06\u5e7b\u89c9\u7387\u964d\u4f4e\u4e86\u9ad8\u8fbe62%\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u8bed\u8a00\u5bf9\u7684\u4e8b\u5b9e\u77e5\u8bc6\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "CCL-XCoT\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u5fae\u8c03\uff08\u5305\u62ec\u57fa\u4e8e\u8bfe\u7a0b\u7684\u5bf9\u6bd4\u5b66\u4e60\u548c\u8de8\u8bed\u8a00\u601d\u7ef4\u94fe\u63d0\u793a\uff09\u6709\u6548\u964d\u4f4e\u4e86\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u5e7b\u89c9\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u77e5\u8bc6\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u5916\u90e8\u68c0\u7d22\u6216\u591a\u6a21\u578b\u96c6\u6210\u3002"}}
{"id": "2507.15629", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15629", "abs": "https://arxiv.org/abs/2507.15629", "authors": ["Zuo-Liang Zhu", "Jian Yang", "Beibei Wang"], "title": "Gaussian Splatting with Discretized SDF for Relightable Assets", "comment": null, "summary": "3D Gaussian splatting (3DGS) has shown its detailed expressive ability and\nhighly efficient rendering speed in the novel view synthesis (NVS) task. The\napplication to inverse rendering still faces several challenges, as the\ndiscrete nature of Gaussian primitives makes it difficult to apply geometry\nconstraints. Recent works introduce the signed distance field (SDF) as an extra\ncontinuous representation to regularize the geometry defined by Gaussian\nprimitives. It improves the decomposition quality, at the cost of increasing\nmemory usage and complicating training. Unlike these works, we introduce a\ndiscretized SDF to represent the continuous SDF in a discrete manner by\nencoding it within each Gaussian using a sampled value. This approach allows us\nto link the SDF with the Gaussian opacity through an SDF-to-opacity\ntransformation, enabling rendering the SDF via splatting and avoiding the\ncomputational cost of ray marching.The key challenge is to regularize the\ndiscrete samples to be consistent with the underlying SDF, as the discrete\nrepresentation can hardly apply the gradient-based constraints (\\eg Eikonal\nloss). For this, we project Gaussians onto the zero-level set of SDF and\nenforce alignment with the surface from splatting, namely a projection-based\nconsistency loss. Thanks to the discretized SDF, our method achieves higher\nrelighting quality, while requiring no extra memory beyond GS and avoiding\ncomplex manually designed optimization. The experiments reveal that our method\noutperforms existing Gaussian-based inverse rendering methods. Our code is\navailable at https://github.com/NK-CS-ZZL/DiscretizedSDF.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79bb\u6563\u5316SDF\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9ad8\u65af\u51fd\u6570\u4e2d\u7f16\u7801SDF\u91c7\u6837\u503c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u6e32\u67d3\u548c\u51e0\u4f55\u7ea6\u675f\uff0c\u63d0\u9ad8\u4e86\u9006\u6e32\u67d3\u8d28\u91cf\uff0c\u4e14\u4e0d\u589e\u52a0\u5185\u5b58\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u76843DGS\u65b9\u6cd5\u5728\u9006\u6e32\u67d3\u4efb\u52a1\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u9ad8\u65af\u51fd\u6570\u7684\u79bb\u6563\u6027\u4f7f\u5f97\u5e94\u7528\u51e0\u4f55\u7ea6\u675f\u53d8\u5f97\u56f0\u96be\u3002\u867d\u7136\u5f15\u5165SDF\u53ef\u4ee5\u4f5c\u4e3a\u8fde\u7eed\u8868\u793a\u6765\u6b63\u5219\u5316\u9ad8\u65af\u51fd\u6570\u5b9a\u4e49\u7684\u51e0\u4f55\uff0c\u4f46\u8fd9\u4f1a\u589e\u52a0\u5185\u5b58\u4f7f\u7528\u5e76\u4f7f\u8bad\u7ec3\u590d\u6742\u5316\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u5728\u4e0d\u589e\u52a0\u989d\u5916\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u51e0\u4f55\u7ea6\u675f\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79bb\u6563\u5316SDF\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6bcf\u4e2a\u9ad8\u65af\u51fd\u6570\u4e2d\u7f16\u7801\u91c7\u6837\u503c\u6765\u79bb\u6563\u5730\u8868\u793a\u8fde\u7eedSDF\u3002\u5c06SDF\u4e0e\u9ad8\u65af\u51fd\u6570\u7684\u900f\u660e\u5ea6\u5173\u8054\u8d77\u6765\uff0c\u5b9e\u73b0\u4e86\u901a\u8fc7splatting\u6e32\u67d3SDF\uff0c\u907f\u514d\u4e86\u5149\u7ebf\u6b65\u8fdb\u7684\u8ba1\u7b97\u6210\u672c\u3002\u901a\u8fc7\u5c06\u9ad8\u65af\u51fd\u6570\u6295\u5f71\u5230SDF\u7684\u96f6\u6c34\u5e73\u96c6\u4e0a\uff0c\u5e76\u5f3a\u5236\u5176\u4e0esplatting\u4ea7\u751f\u7684\u8868\u9762\u5bf9\u9f50\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6295\u5f71\u7684\u4e00\u81f4\u6027\u635f\u5931\u6765\u7ea6\u675f\u79bb\u6563\u6837\u672c\u4e0e\u6f5c\u5728SDF\u7684\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684 relighting \u8d28\u91cf\uff0c\u540c\u65f6\u4e0d\u9700\u8981\u6bd4GS\u989d\u5916\u589e\u52a0\u5185\u5b58\uff0c\u5e76\u4e14\u907f\u514d\u4e86\u590d\u6742\u7684\u624b\u52a8\u8bbe\u8ba1\u4f18\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u9ad8\u65af\u51fd\u6570\u7684\u9006\u6e32\u67d3\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u79bb\u6563\u5316SDF\u65b9\u6cd5\u5728\u4e0d\u589e\u52a0\u989d\u5916\u5185\u5b58\u5360\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u57fa\u4e8e\u9ad8\u65af\u51fd\u6570\u7684\u9006\u6e32\u67d3\u65b9\u6cd5\u66f4\u9ad8\u7684 relighting \u8d28\u91cf\uff0c\u5e76\u4e14\u907f\u514d\u4e86\u590d\u6742\u7684\u624b\u52a8\u8bbe\u8ba1\u4f18\u5316\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14747", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.14747", "abs": "https://arxiv.org/abs/2507.14747", "authors": ["Yiding Song"], "title": "Pruning Increases Orderedness in Recurrent Computation", "comment": "8 pages, 11 figures, 2 tables, Workshop on Methods and Opportunities\n  at Small Scale (MOSS), ICML 2025", "summary": "Inspired by the prevalence of recurrent circuits in biological brains, we\ninvestigate the degree to which directionality is a helpful inductive bias for\nartificial neural networks. Taking directionality as topologically-ordered\ninformation flow between neurons, we formalise a perceptron layer with\nall-to-all connections (mathematically equivalent to a weight-tied recurrent\nneural network) and demonstrate that directionality, a hallmark of modern\nfeed-forward networks, can be induced rather than hard-wired by applying\nappropriate pruning techniques. Across different random seeds our pruning\nschemes successfully induce greater topological ordering in information flow\nbetween neurons without compromising performance, suggesting that\ndirectionality is not a prerequisite for learning, but may be an advantageous\ninductive bias discoverable by gradient descent and sparsification.", "AI": {"tldr": "Directionality in neural networks can be induced by pruning, acting as a beneficial inductive bias without harming performance.", "motivation": "The research is motivated by the prevalence of recurrent circuits in biological brains and aims to investigate the usefulness of directionality as an inductive bias for artificial neural networks.", "method": "The paper formalizes a perceptron layer with all-to-all connections and applies pruning techniques to induce directionality, analyzing the topological order of information flow between neurons.", "result": "The pruning schemes successfully induced greater topological ordering in information flow between neurons across different random seeds without compromising performance.", "conclusion": "The study suggests that directionality, while not essential for learning, can be a beneficial inductive bias that can be discovered through gradient descent and sparsification. Pruning techniques can induce directionality in artificial neural networks without hindering performance."}}
{"id": "2507.15664", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.15664", "abs": "https://arxiv.org/abs/2507.15664", "authors": ["Haomin Qi", "Yuyang Du", "Lihao Zhang", "Soung Chang Liew", "Kexin Chen", "Yining Du"], "title": "VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair", "comment": "8 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated immense potential in\ncomputer-aided design (CAD), particularly for automated debugging and\nverification within electronic design automation (EDA) tools. However, Design\nfor Testability (DFT) remains a relatively underexplored area. This paper\npresents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a\nRetrieval-Augmented Generation (RAG) approach to enable LLM to revise code to\nensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity\nmeasurement model for precise retrieval of reference RTL designs for the LLM,\nand (2) an iterative code revision pipeline that allows the LLM to ensure DFT\ncompliance while maintaining synthesizability. To support VeriRAG, we introduce\nVeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG\nretrieves structurally similar RTL designs from VeriDFT, each paired with a\nrigorously validated correction, as references for code repair. With VeriRAG\nand VeriDFT, we achieve fully automated DFT correction -- resulting in a\n7.72-fold improvement in successful repair rate compared to the zero-shot\nbaseline (Fig. 5 in Section V). Ablation studies further confirm the\ncontribution of each component of the VeriRAG framework. We open-source our\ndata, models, and scripts at https://github.com/yuyangdu01/LLM4DFT.", "AI": {"tldr": "VeriRAG\u662f\u9996\u4e2aLLM\u8f85\u52a9DFT-EDA\u6846\u67b6\uff0c\u901a\u8fc7RAG\u548cVeriDFT\u6570\u636e\u96c6\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8DFT\u4fee\u590d\uff0c\u6210\u529f\u7387\u5927\u5e45\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728CAD\u548cEDA\u9886\u57df\u7684\u81ea\u52a8\u5316\u8c03\u8bd5\u548c\u9a8c\u8bc1\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46DFT\u9886\u57df\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u89e3\u51b3DFT\u5408\u89c4\u6027\u95ee\u9898\u3002", "method": "VeriRAG\u662f\u4e00\u4e2a\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9DFT-EDA\u6846\u67b6\uff0c\u80fd\u591f\u4fee\u590d\u4ee3\u7801\u4ee5\u786e\u4fddDFT\u5408\u89c4\u6027\u3002\u5b83\u5305\u62ec\u4e00\u4e2a\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u76f8\u4f3c\u5ea6\u6d4b\u91cf\u6a21\u578b\uff0c\u7528\u4e8e\u7cbe\u786e\u68c0\u7d22\u53c2\u8003RTL\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u4e00\u4e2a\u8fed\u4ee3\u4ee3\u7801\u4fee\u8ba2\u6d41\u7a0b\uff0c\u786e\u4fddDFT\u5408\u89c4\u6027\u548c\u53ef\u7efc\u5408\u6027\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u4e86VeriDFT\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542bDFT\u611f\u77e5RTL\u4fee\u590d\u7684Verilog\u6570\u636e\u96c6\u3002", "result": "VeriRAG\u6846\u67b6\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8DFT\u4fee\u590d\uff0c\u6210\u529f\u4fee\u590d\u7387\u76f8\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u9ad8\u4e867.72\u500d\u3002", "conclusion": "VeriRAG\u6846\u67b6\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8DFT\u4fee\u590d\uff0c\u4e0e\u96f6\u6837\u672c\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6210\u529f\u4fee\u590d\u7387\u63d0\u9ad8\u4e867.72\u500d\u3002\u6d88\u878d\u7814\u7a76\u4e5f\u9a8c\u8bc1\u4e86VeriRAG\u6846\u67b6\u5404\u7ec4\u4ef6\u7684\u8d21\u732e\u3002"}}
{"id": "2507.15067", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.15067", "abs": "https://arxiv.org/abs/2507.15067", "authors": ["Bing He", "Mustaque Ahamad", "Srijan Kumar"], "title": "ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model", "comment": "15 pages, 12 tables", "summary": "Detecting bad actors is critical to ensure the safety and integrity of\ninternet platforms. Several deep learning-based models have been developed to\nidentify such users. These models should not only accurately detect bad actors,\nbut also be robust against adversarial attacks that aim to evade detection.\nHowever, past deep learning-based detection models do not meet the robustness\nrequirement because they are sensitive to even minor changes in the input\nsequence. To address this issue, we focus on (1) improving the model\nunderstanding capability and (2) enhancing the model knowledge such that the\nmodel can recognize potential input modifications when making predictions. To\nachieve these goals, we create a novel transformer-based classification model,\ncalled ROBAD (RObust adversary-aware local-global attended Bad Actor Detection\nmodel), which uses the sequence of user posts to generate user embedding to\ndetect bad actors. Particularly, ROBAD first leverages the transformer encoder\nblock to encode each post bidirectionally, thus building a post embedding to\ncapture the local information at the post level. Next, it adopts the\ntransformer decoder block to model the sequential pattern in the post\nembeddings by using the attention mechanism, which generates the sequence\nembedding to obtain the global information at the sequence level. Finally, to\nenrich the knowledge of the model, embeddings of modified sequences by mimicked\nattackers are fed into a contrastive-learning-enhanced classification layer for\nsequence prediction. In essence, by capturing the local and global information\n(i.e., the post and sequence information) and leveraging the mimicked behaviors\nof bad actors in training, ROBAD can be robust to adversarial attacks.\nExtensive experiments on Yelp and Wikipedia datasets show that ROBAD can\neffectively detect bad actors when under state-of-the-art adversarial attacks.", "AI": {"tldr": "ROBAD\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u4e8eTransformer\u7684\u6076\u610f\u884c\u4e3a\u8005\u68c0\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\u4ee5\u53ca\u5bf9\u6bd4\u5b66\u4e60\u6765\u63d0\u9ad8\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u68c0\u6d4b\u6a21\u578b\u5bf9\u8f93\u5165\u5e8f\u5217\u7684\u5fae\u5c0f\u53d8\u5316\u5f88\u654f\u611f\uff0c\u672a\u80fd\u6ee1\u8db3\u9c81\u68d2\u6027\u8981\u6c42\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u548c\u77e5\u8bc6\uff0c\u4f7f\u5176\u5728\u8fdb\u884c\u9884\u6d4b\u65f6\u80fd\u591f\u8bc6\u522b\u6f5c\u5728\u7684\u8f93\u5165\u4fee\u6539\u3002", "method": "ROBAD\u6a21\u578b\u9996\u5148\u5229\u7528Transformer\u7f16\u7801\u5668\u5757\u5bf9\u6bcf\u4e2a\u5e16\u5b50\u8fdb\u884c\u53cc\u5411\u7f16\u7801\uff0c\u6784\u5efa\u5e16\u5b50\u5d4c\u5165\u4ee5\u6355\u83b7\u5e16\u5b50\u7ea7\u522b\u7684\u5c40\u90e8\u4fe1\u606f\u3002\u7136\u540e\uff0c\u91c7\u7528Transformer\u89e3\u7801\u5668\u5757\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u5e16\u5b50\u5d4c\u5165\u4e2d\u7684\u5e8f\u5217\u6a21\u5f0f\u8fdb\u884c\u5efa\u6a21\uff0c\u751f\u6210\u5e8f\u5217\u5d4c\u5165\u4ee5\u83b7\u5f97\u5e8f\u5217\u7ea7\u522b\u7684\u5168\u5c40\u4fe1\u606f\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5c06\u6a21\u4eff\u653b\u51fb\u8005\u4fee\u6539\u7684\u5e8f\u5217\u7684\u5d4c\u5165\u8f93\u5165\u5230\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u7684\u5206\u7c7b\u5c42\u8fdb\u884c\u5e8f\u5217\u9884\u6d4b\uff0c\u4ee5\u4e30\u5bcc\u6a21\u578b\u7684\u77e5\u8bc6\u3002", "result": "ROBAD\u6a21\u578b\u5728Yelp\u548cWikipedia\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u5bf9\u6297\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5bf9\u6297\u6027\u653b\u51fb\u65f6\uff0c\u80fd\u591f\u6709\u6548\u5730\u68c0\u6d4b\u6076\u610f\u884c\u4e3a\u8005\u3002", "conclusion": "ROBAD\u6a21\u578b\u901a\u8fc7\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u5e76\u5229\u7528\u6a21\u4eff\u7684\u6076\u610f\u884c\u4e3a\u8005\u8bad\u7ec3\uff0c\u53ef\u4ee5\u6709\u6548\u62b5\u5fa1\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u5728Yelp\u548cWikipedia\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002"}}
{"id": "2507.14835", "categories": ["cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14835", "abs": "https://arxiv.org/abs/2507.14835", "authors": ["Pan Peng", "Hangyu Xu"], "title": "Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts", "comment": "COLT 2025", "summary": "We study the problem of releasing a differentially private (DP) synthetic\ngraph $G'$ that well approximates the triangle-motif sizes of all cuts of any\ngiven graph $G$, where a motif in general refers to a frequently occurring\nsubgraph within complex networks. Non-private versions of such graphs have\nfound applications in diverse fields such as graph clustering, graph\nsparsification, and social network analysis. Specifically, we present the first\n$(\\varepsilon,\\delta)$-DP mechanism that, given an input graph $G$ with $n$\nvertices, $m$ edges and local sensitivity of triangles $\\ell_{3}(G)$, generates\na synthetic graph $G'$ in polynomial time, approximating the triangle-motif\nsizes of all cuts $(S,V\\setminus S)$ of the input graph $G$ up to an additive\nerror of $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$. Additionally, we\nprovide a lower bound of $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ on the\nadditive error for any DP algorithm that answers the triangle-motif size\nqueries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to\nweighted graphs, and our lower bound extends to any $K_h$-motif cut for any\nconstant $h\\geq 2$.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u5408\u6210\u56fe\u751f\u6210\u673a\u5236\uff0c\u80fd\u6709\u6548\u8fd1\u4f3c\u56fe\u4e2d\u6240\u6709\u5272\u7684\u4e09\u89d2-\u57fa\u5143\u5b50\u56fe\u5927\u5c0f\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f8\u5e94\u7684\u8bef\u5dee\u4e0b\u754c\u3002", "motivation": "\u4e3a\u4e86\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u524d\u63d0\u4e0b\uff0c\u5229\u7528\u5408\u6210\u56fe\u8fdb\u884c\u56fe\u805a\u7c7b\u3001\u56fe\u7a00\u758f\u5316\u548c\u793e\u4f1a\u7f51\u7edc\u5206\u6790\u7b49\u5e94\u7528\uff0c\u7814\u7a76\u4e86\u53d1\u5e03\u80fd\u591f\u8fd1\u4f3c\u4efb\u610f\u7ed9\u5b9a\u56fe $G$ \u7684\u6240\u6709\u5272\u7684\u4e09\u89d2-\u57fa\u5143\u5b50\u56fe\u5927\u5c0f\u7684\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u5408\u6210\u56fe $G'$ \u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u673a\u5236\uff0c\u7528\u4e8e\u751f\u6210\u80fd\u591f\u8fd1\u4f3c\u4efb\u610f\u7ed9\u5b9a\u56fe $G$ \u7684\u6240\u6709\u5272\u7684\u4e09\u89d2-\u57fa\u5143\u5b50\u56fe\u5927\u5c0f\u7684\u5408\u6210\u56fe $G'$\u3002\u8be5\u673a\u5236\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8fd0\u884c\uff0c\u5e76\u63d0\u4f9b $(\\varepsilon,\\delta)$-DP\u4fdd\u8bc1\u3002\u5176\u8fd1\u4f3c\u8bef\u5dee\u754c\u4e3a $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$\uff0c\u5176\u4e2d $n$ \u662f\u56fe\u7684\u9876\u70b9\u6570\uff0c$m$ \u662f\u8fb9\u6570\uff0c$\\ell_{3}(G)$ \u662f\u56fe\u7684\u5c40\u90e8\u4e09\u89d2\u5f62\u654f\u611f\u5ea6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u9488\u5bf9\u4efb\u4f55 $DP$ \u7b97\u6cd5\u5728\u56de\u7b54\u6240\u6709 $(S,T)$-\u5272\u7684\u4e09\u89d2-\u57fa\u5143\u5b50\u56fe\u5927\u5c0f\u67e5\u8be2\u65f6\u7684 $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ \u7684\u52a0\u6027\u8bef\u5dee\u4e0b\u754c\u3002\u8be5\u7b97\u6cd5\u53ef\u63a8\u5e7f\u5230\u52a0\u6743\u56fe\uff0c\u4e0b\u754c\u4e5f\u53ef\u6269\u5c55\u5230\u4efb\u610f\u5e38\u6570 $h\\geq 2$ \u7684 $K_h$-\u57fa\u5143\u5b50\u56fe\u5272\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u6ee1\u8db3 $(\\varepsilon,\\delta)$-DP \u7684\u673a\u5236\uff0c\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u751f\u6210\u5408\u6210\u56fe $G'$\uff0c\u8fd1\u4f3c\u8bef\u5dee\u754c\u4e3a $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$\u3002\u540c\u65f6\uff0c\u4e5f\u7ed9\u51fa\u4e86\u4efb\u4f55 DP \u7b97\u6cd5\u5728\u56de\u7b54\u6240\u6709 $(S,T)$-\u5272\u7684\u4e09\u89d2-\u57fa\u5143\u5b50\u56fe\u5927\u5c0f\u67e5\u8be2\u65f6\u7684 $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ \u7684\u52a0\u6027\u8bef\u5dee\u4e0b\u754c\u3002\u8be5\u7b97\u6cd5\u53ef\u63a8\u5e7f\u81f3\u52a0\u6743\u56fe\uff0c\u4e0b\u754c\u53ef\u6269\u5c55\u81f3\u4efb\u610f\u5e38\u6570 $h\\geq 2$ \u7684 $K_h$-\u57fa\u5143\u5b50\u56fe\u5272\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u6ee1\u8db3\u5dee\u5206\u9690\u79c1\u7684\u5408\u6210\u56fe\uff08$G"}}
{"id": "2507.14436", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.14436", "abs": "https://arxiv.org/abs/2507.14436", "authors": ["Yulong Li", "Wuerkaixi Nuerbolati", "Chunqing Deng", "Xizheng Ma", "Haonan Xiong", "Haifeng Yu"], "title": "Mitigating state transition errors during readout with a synchronized flux pulse", "comment": null, "summary": "State transitions during qubit measurements are extremely detrimental to\nquantum tasks that rely on repeated measurements, such as quantum error\ncorrection. These state transitions can occur when excessive measurement power\nleads to qubit excitations outside its computational space. Alternatively, the\nqubit state can decay rapidly when the measurement protocol inadvertently\ncouples the qubit to lossy modes such as two-level systems (TLSs). We\nexperimentally verify the impact of these TLSs in qubit readout by measuring\nthe transition errors at different qubit flux bias. Because such state\ntransitions during measurements are often localized in frequency space, we\ndemonstrate the ability to avoid them during a fluxonium readout by exploiting\nthe qubit's flux-tunability. By synchronizing the flux bias with the readout\nphoton dynamics, we obtain an optimal readout fidelity of 99 % (98.4 %) in 1 us\n(0.5 us) integration time. Our work advances the understanding of state\ntransitions in superconducting circuit measurements and demonstrates the\npotential of fluxonium qubits to achieve fast high-fidelity readout.", "AI": {"tldr": "\u7531\u4e8e\u6d4b\u91cf\u5f15\u8d77\u7684\u91cf\u5b50\u6bd4\u7279\u72b6\u6001\u8dc3\u8fc1\u4f1a\u635f\u5bb3\u91cf\u5b50\u7ea0\u9519\u7b49\u4efb\u52a1\u3002\u672c\u7814\u7a76\u901a\u8fc7\u540c\u6b65\u901a\u91cf\u504f\u7f6e\u548c\u8bfb\u51fa\u5149\u5b50\u52a8\u529b\u5b66\uff0c\u5229\u7528\u901a\u91cf\u5947\u5f02\u91cf\u5b50\u6bd4\u7279\u7684\u901a\u91cf\u53ef\u8c03\u6027\uff0c\u5b9e\u73b0\u4e8699%\uff080.5\u5fae\u79d2\uff09\u7684\u8bfb\u51fa\u4fdd\u771f\u5ea6\uff0c\u514b\u670d\u4e86\u72b6\u6001\u8dc3\u8fc1\u95ee\u9898\u3002", "motivation": "\u91cf\u5b50\u6bd4\u7279\u6d4b\u91cf\u671f\u95f4\u7684\u72b6\u6001\u8dc3\u8fc1\u5bf9\u4f9d\u8d56\u91cd\u590d\u6d4b\u91cf\u7684\u91cf\u5b50\u4efb\u52a1\uff08\u5982\u91cf\u5b50\u7ea0\u9519\uff09\u975e\u5e38\u4e0d\u5229\uff0c\u56e0\u4e3a\u8fc7\u5ea6\u7684\u6d4b\u91cf\u529f\u7387\u4f1a\u5bfc\u81f4\u91cf\u5b50\u6bd4\u7279\u6fc0\u53d1\u8d85\u51fa\u5176\u8ba1\u7b97\u7a7a\u95f4\uff0c\u6216\u8005\u6d4b\u91cf\u534f\u8bae\u4f1a\u65e0\u610f\u4e2d\u5c06\u91cf\u5b50\u6bd4\u7279\u8026\u5408\u5230\u6709\u635f\u8017\u6a21\u5f0f\uff08\u5982\u4e24\u80fd\u7ea7\u7cfb\u7edfTLS\uff09\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u4e0d\u540c\u7ea6\u901a\u91cf\u504f\u7f6e\u4e0b\u7684\u91cf\u5b50\u6bd4\u7279\u8dc3\u8fc1\u8bef\u5dee\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TLS\u5bf9\u91cf\u5b50\u6bd4\u7279\u8bfb\u51fa\u7684\u5f71\u54cd\u3002\u5229\u7528\u91cf\u5b50\u6bd4\u7279\u7684\u901a\u91cf\u53ef\u8c03\u6027\uff0c\u901a\u8fc7\u540c\u6b65\u8bfb\u51fa\u5149\u5b50\u52a8\u529b\u5b66\u548c\u7ea6\u901a\u91cf\u504f\u7f6e\u6765\u907f\u514d\u5728\u901a\u91cf\u5947\u5f02\u8bfb\u51fa\u4e2d\u53d1\u751f\u72b6\u6001\u8dc3\u8fc1\u3002", "result": "\u57281\u5fae\u79d2\uff080.5\u5fae\u79d2\uff09\u7684\u79ef\u5206\u65f6\u95f4\u5185\uff0c\u5b9e\u73b0\u4e8699%\uff0898.4%\uff09\u7684\u6700\u4f73\u8bfb\u51fa\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u540c\u6b65\u8bfb\u51fa\u5149\u5b50\u52a8\u529b\u5b66\u548c\u7ea6\u901a\u91cf\u504f\u7f6e\uff0c\u5b9e\u73b0\u4e86\u9ad8\u901a\u91cf\u5947\u5f02\u91cf\u5b50\u6bd4\u7279\u7684\u5feb\u901f\u9ad8\u4fdd\u771f\u8bfb\u51fa\uff0c\u4e3a\u8d85\u5bfc\u7535\u8def\u6d4b\u91cf\u4e2d\u7684\u72b6\u6001\u8dc3\u8fc1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u5947\u5f02\u91cf\u5b50\u6bd4\u7279\u5728\u5b9e\u73b0\u5feb\u901f\u9ad8\u4fdd\u771f\u8bfb\u51fa\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15797", "categories": ["quant-ph", "cs.ET", "81P68 (Primary), 68Q12 68Q25 (Secondary)", "F.1.2"], "pdf": "https://arxiv.org/pdf/2507.15797", "abs": "https://arxiv.org/abs/2507.15797", "authors": ["John Burke", "Ciaran McGoldrick"], "title": "Deterministic Quantum Search via Recursive Oracle Expansion", "comment": "11 pages, 3 figures. Data and code available on request", "summary": "We introduce a novel deterministic quantum search algorithm that provides a\npractical alternative to conventional probabilistic search approaches. Our\nscheme eliminates the inherent uncertainty of quantum search without relying on\narbitrary phase rotations, a key limitation of other deterministic methods. The\nalgorithm achieves certainty by recursively expanding the base oracle so that\nit marks all states prefixed by the same two bits as the target, encompassing\nexactly one-quarter of the search space. This enables a step-by-step reduction\nof the superposition until the target state can be measured with certainty. The\nalgorithm achieves deterministic success with a query complexity of\n$O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$, falling between Grover's\n$O(\\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively\non two-qubit nearest-neighbour diffusion operators, avoiding global diffusion\nentirely. We show that, despite the increased query complexity, this design\nreduces the total number of two-qubit gates required for diffusion by more than\nan order of magnitude for search spaces up to at least 18 qubits, with even\ngreater advantages on hardware with limited qubit connectivity. The scheme's\ninherent determinism, reliance on simple nearest-neighbour, low-depth\noperations, and scalable recursive structure make it well-suited for hardware\nimplementation. Additionally, we show that the algorithm naturally supports\npartial database search, enabling deterministic identification of selected\ntarget bits without requiring a full search, further broadening its\napplicability.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u786e\u5b9a\u6027\u91cf\u5b50\u641c\u7d22\u7b97\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u6269\u5c55\u9884\u8a00\u673a\u6765\u6807\u8bb0\u76ee\u6807\u7684\u524d\u7f00\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u641c\u7d22\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u4f18\u4e8e\u7ecf\u5178\u641c\u7d22\u4f46\u7565\u900a\u4e8eGrover\u641c\u7d22\u3002\u8be5\u7b97\u6cd5\u4f7f\u7528\u8fd1\u90bb\u6269\u6563\u7b97\u5b50\uff0c\u5728\u95e8\u64cd\u4f5c\u6570\u91cf\u4e0a\u66f4\u4f18\uff0c\u5e76\u652f\u6301\u90e8\u5206\u6570\u636e\u5e93\u641c\u7d22\uff0c\u9002\u5408\u786c\u4ef6\u5b9e\u73b0\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u786e\u5b9a\u6027\u91cf\u5b50\u641c\u7d22\u65b9\u6cd5\u4f9d\u8d56\u4efb\u610f\u76f8\u4f4d\u65cb\u8f6c\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e00\u79cd\u4e0d\u542b\u4e0d\u786e\u5b9a\u6027\u7684\u5b9e\u7528\u91cf\u5b50\u641c\u7d22\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u786e\u5b9a\u6027\u91cf\u5b50\u641c\u7d22\u7b97\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u6269\u5c55\u57fa\u7840\u9884\u8a00\u673a\uff0c\u4f7f\u5176\u6807\u8bb0\u6240\u6709\u4ee5\u4e0e\u76ee\u6807\u76f8\u540c\u7684\u4e24\u4e2a\u6bd4\u7279\u4f5c\u4e3a\u524d\u7f00\u7684\u72b6\u6001\uff0c\u4ece\u800c\u8986\u76d6\u56db\u5206\u4e4b\u4e00\u7684\u641c\u7d22\u7a7a\u95f4\u3002\u901a\u8fc7\u9010\u6b65\u51cf\u5c0f\u53e0\u52a0\u6001\uff0c\u6700\u7ec8\u53ef\u4ee5\u786e\u5b9a\u6027\u5730\u6d4b\u91cf\u76ee\u6807\u72b6\u6001\u3002", "result": "\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4e86\u786e\u5b9a\u6027\u6210\u529f\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u4e3a$O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$\u3002\u5b83\u4ec5\u4f7f\u7528\u53cc\u91cf\u5b50\u6bd4\u7279\u8fd1\u90bb\u6269\u6563\u7b97\u5b50\uff0c\u5728\u51cf\u5c11\u6240\u9700\u53cc\u91cf\u5b50\u6bd4\u7279\u95e8\u6570\u91cf\u65b9\u9762\u6bd4Grover\u7b97\u6cd5\u6709\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u91cf\u5b50\u6bd4\u7279\u8fde\u901a\u6027\u6709\u9650\u7684\u786c\u4ef6\u4e0a\u3002\u8be5\u7b97\u6cd5\u8fd8\u652f\u6301\u90e8\u5206\u6570\u636e\u5e93\u641c\u7d22\uff0c\u53ef\u7528\u4e8e\u786e\u5b9a\u6027\u5730\u8bc6\u522b\u9009\u5b9a\u76ee\u6807\u6bd4\u7279\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u901a\u8fc7\u9012\u5f52\u5730\u6269\u5c55\u57fa\u7840\u9884\u8a00\u673a\u6765\u6807\u8bb0\u6240\u6709\u4ee5\u4e0e\u76ee\u6807\u76f8\u540c\u7684\u4e24\u4e2a\u6bd4\u7279\u4f5c\u4e3a\u524d\u7f00\u7684\u72b6\u6001\uff0c\u4ece\u800c\u5b9e\u73b0\u786e\u5b9a\u6027\u6210\u529f\u3002\u5b83\u5b9e\u73b0\u4e86$O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u4ecb\u4e8eGrover\u7684$O(\\sqrt{N})$\u548c\u7ecf\u5178$O(N)$\u4e4b\u95f4\u3002\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u53cc\u91cf\u5b50\u6bd4\u7279\u8fd1\u90bb\u6269\u6563\u7b97\u5b50\uff0c\u907f\u514d\u4e86\u5168\u5c40\u6269\u6563\u3002\u4e0eGrover\u7b97\u6cd5\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u5728\u6269\u6563\u6240\u9700\u53cc\u91cf\u5b50\u6bd4\u7279\u95e8\u6570\u91cf\u4e0a\u51cf\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff0c\u5c24\u5176\u662f\u5728\u91cf\u5b50\u6bd4\u7279\u8fde\u901a\u6027\u6709\u9650\u7684\u786c\u4ef6\u4e0a\u4f18\u52bf\u66f4\u660e\u663e\u3002\u5176\u786e\u5b9a\u6027\u3001\u5bf9\u7b80\u5355\u8fd1\u90bb\u4f4e\u6df1\u5ea6\u64cd\u4f5c\u7684\u4f9d\u8d56\u4ee5\u53ca\u53ef\u6269\u5c55\u7684\u9012\u5f52\u7ed3\u6784\u4f7f\u5176\u9002\u5408\u786c\u4ef6\u5b9e\u73b0\u3002\u6b64\u5916\uff0c\u8be5\u7b97\u6cd5\u8fd8\u652f\u6301\u90e8\u5206\u6570\u636e\u5e93\u641c\u7d22\uff0c\u65e0\u9700\u8fdb\u884c\u5b8c\u6574\u641c\u7d22\u5373\u53ef\u786e\u5b9a\u6027\u5730\u8bc6\u522b\u9009\u5b9a\u7684\u76ee\u6807\u6bd4\u7279\u3002"}}
{"id": "2507.15737", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.15737", "abs": "https://arxiv.org/abs/2507.15737", "authors": ["Felipe Garrido-Lucero", "Rida Laraki"], "title": "General Matching Games", "comment": null, "summary": "Matching games is a one-to-one two sided market model introduced by\nGarrido-Lucero and Laraki, in which coupled agents' utilities are endogenously\ndetermined as the outcome of a strategic game. They refine the classical\npairwise stability by requiring robustness to renegotiation and provide general\nconditions under which pairwise stable and renegotiation-proof outcomes exist\nas the limit of a deferred acceptance with competitions algorithm together with\na renegotiation process. In this article, we extend their model to a general\nsetting encompassing most of one-to-many matching markets and roommates models\nand specify two frameworks under which core stable and renegotiation-proof\noutcomes exist and can be efficiently computed.", "AI": {"tldr": "\u5c06\u5339\u914d\u535a\u5f08\u6a21\u578b\u63a8\u5e7f\u5230\u4e00\u5bf9\u591a\u548c\u5ba4\u53cb\u6a21\u578b\uff0c\u5e76\u627e\u5230\u7a33\u5b9a\u53ef\u8ba1\u7b97\u7684\u5339\u914d\u7ed3\u679c\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u5c06 Garrido-Lucero \u548c Laraki \u63d0\u51fa\u7684\u5339\u914d\u535a\u5f08\u6a21\u578b\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u5e02\u573a\u6a21\u578b\uff0c\u4f8b\u5982\u4e00\u5bf9\u591a\u5339\u914d\u5e02\u573a\u548c\u5ba4\u53cb\u6a21\u578b\uff0c\u5e76\u63a2\u7d22\u5728\u8fd9\u4e9b\u6a21\u578b\u4e2d\u5b58\u5728\u7a33\u5b9a\u4e14\u53ef\u91cd\u65b0\u534f\u5546\u5339\u914d\u7ed3\u679c\u7684\u6761\u4ef6\u548c\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u5728\u5339\u914d\u535a\u5f08\u6a21\u578b\u7684\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u4e00\u5bf9\u591a\u5339\u914d\u5e02\u573a\u548c\u5ba4\u53cb\u6a21\u578b\u7684\u66f4\u4e00\u822c\u5316\u6846\u67b6\uff0c\u5e76\u7ed9\u51fa\u4e86\u4fdd\u8bc1\u6838\u5fc3\u7a33\u5b9a\u548c\u53ef\u91cd\u65b0\u534f\u5546\u5339\u914d\u7ed3\u679c\u5b58\u5728\u6027\u7684\u6761\u4ef6\uff0c\u540c\u65f6\u8bf4\u660e\u4e86\u5982\u4f55\u901a\u8fc7\u7b97\u6cd5\u6709\u6548\u8ba1\u7b97\u8fd9\u4e9b\u7ed3\u679c\u3002", "result": "\u8be5\u7814\u7a76\u4e3a\u5305\u542b\u4e00\u5bf9\u591a\u5339\u914d\u5e02\u573a\u548c\u5ba4\u53cb\u6a21\u578b\u5728\u5185\u7684\u4e00\u822c\u5316\u5339\u914d\u535a\u5f08\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6846\u67b6\u4e0b\uff0c\u6838\u5fc3\u7a33\u5b9a\u4e14\u53ef\u91cd\u65b0\u534f\u5546\u7684\u5339\u914d\u7ed3\u679c\u662f\u5b58\u5728\u7684\uff0c\u5e76\u4e14\u53ef\u4ee5\u88ab\u6709\u6548\u8ba1\u7b97\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u5339\u914d\u535a\u5f08\u6a21\u578b\u6269\u5c55\u5230\u4e86\u4e00\u5bf9\u591a\u5339\u914d\u5e02\u573a\u548c\u5ba4\u53cb\u6a21\u578b\u7b49\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u5176\u4e2d\u5b58\u5728\u6838\u5fc3\u7a33\u5b9a\u4e14\u53ef\u91cd\u65b0\u534f\u5546\u7684\u5339\u914d\u7ed3\u679c\uff0c\u5e76\u80fd\u8fdb\u884c\u6709\u6548\u8ba1\u7b97\u3002"}}
{"id": "2507.14141", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14141", "abs": "https://arxiv.org/abs/2507.14141", "authors": ["Danny Dongyeop Han", "Ahhyun Lucy Lee", "Taeyang Lee", "Yonghyeon Gwon", "Sebin Lee", "Seongjin Lee", "David Keetae Park", "Shinjae Yoo", "Jiook Cha", "Chun Kee Chung"], "title": "DIVER-0 : A Fully Channel Equivariant EEG Foundation Model", "comment": "11 pages, 1 figures, ICML 2025 Workshop on GenBio", "summary": "Electroencephalography (EEG) is a non-invasive technique widely used in\nbrain-computer interfaces and clinical applications, yet existing EEG\nfoundation models face limitations in modeling spatio-temporal brain dynamics\nand lack channel permutation equivariance, preventing robust generalization\nacross diverse electrode configurations. To address these challenges, we\npropose DIVER-0, a novel EEG foundation model that demonstrates how full\nspatio-temporal attention-rather than segregated spatial or temporal\nprocessing-achieves superior performance when properly designed with Rotary\nPosition Embedding (RoPE) for temporal relationships and binary attention\nbiases for channel differentiation. We also introduce Sliding Temporal\nConditional Positional Encoding (STCPE), which improves upon existing\nconditional positional encoding approaches by maintaining both temporal\ntranslation equivariance and channel permutation equivariance, enabling robust\nadaptation to arbitrary electrode configurations unseen during pretraining.\nExperimental results demonstrate that DIVER-0 achieves competitive performance\nwith only 10% of pretraining data while maintaining consistent results across\nall channel permutation conditions, validating its effectiveness for\ncross-dataset generalization and establishing key design principles for\nhandling the inherent heterogeneity of neural recording setups.", "AI": {"tldr": "DIVER-0\u662f\u4e00\u4e2a\u521b\u65b0\u7684EEG\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5168\u65f6\u7a7a\u6ce8\u610f\u529b\u548cSTCPE\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u540c\u7535\u6781\u914d\u7f6e\u4e0b\u7684\u9c81\u68d2\u6cdb\u5316\uff0c\u5e76\u4ee5\u66f4\u5c11\u7684\u6570\u636e\u8fbe\u5230\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684EEG\u57fa\u7840\u6a21\u578b\u5728\u6a21\u62df\u65f6\u7a7a\u5927\u8111\u52a8\u6001\u4ee5\u53ca\u901a\u9053\u6392\u5217\u7b49\u53d8\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u963b\u788d\u4e86\u5728\u4e0d\u540c\u7535\u6781\u914d\u7f6e\u4e0b\u7684\u9c81\u68d2\u6cdb\u5316\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u7684\u65b0\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDIVER-0\u7684\u65b0\u578bEEG\u57fa\u7840\u6a21\u578b\uff0c\u5b83\u91c7\u7528\u4e86\u5168\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08RoPE\uff09\u5904\u7406\u65f6\u95f4\u5173\u7cfb\uff0c\u4e8c\u5143\u6ce8\u610f\u529b\u504f\u89c1\u5904\u7406\u901a\u9053\u533a\u5206\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u6ed1\u52a8\u65f6\u95f4\u6761\u4ef6\u4f4d\u7f6e\u7f16\u7801\uff08STCPE\uff09\uff0c\u4ee5\u5b9e\u73b0\u65f6\u95f4\u5e73\u79fb\u7b49\u53d8\u6027\u548c\u901a\u9053\u6392\u5217\u7b49\u53d8\u6027\u3002", "result": "DIVER-0\u6a21\u578b\u5728\u4ec5\u4f7f\u752810%\u9884\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u6240\u6709\u901a\u9053\u6392\u5217\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u7ed3\u679c\u3002\u8fd9\u8bc1\u660e\u4e86\u8be5\u6a21\u578b\u5728\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u786e\u7acb\u4e86\u5904\u7406\u795e\u7ecf\u8bb0\u5f55\u8bbe\u7f6e\u5f02\u8d28\u6027\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u3002", "conclusion": "DIVER-0\u901a\u8fc7\u7ed3\u5408\u5168\u65f6\u7a7a\u6ce8\u610f\u529b\u3001\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08RoPE\uff09\u548c\u4e8c\u5143\u6ce8\u610f\u529b\u504f\u89c1\uff0c\u5e76\u5f15\u5165\u6ed1\u52a8\u65f6\u95f4\u6761\u4ef6\u4f4d\u7f6e\u7f16\u7801\uff08STCPE\uff09\uff0c\u5b9e\u73b0\u4e86\u5728\u8111\u7535\u56fe\uff08EEG\uff09\u5efa\u6a21\u65b9\u9762\u7684\u7a81\u7834\u3002\u8be5\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u65f6\u7a7a\u52a8\u6001\uff0c\u5e76\u5177\u6709\u901a\u9053\u6392\u5217\u7b49\u53d8\u6027\uff0c\u4ece\u800c\u5728\u4e0d\u540c\u7535\u6781\u914d\u7f6e\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cDIVER-0\u4ec5\u752810%\u7684\u9884\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u8fbe\u5230\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u5728\u6240\u6709\u901a\u9053\u6392\u5217\u6761\u4ef6\u4e0b\u4fdd\u6301\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u5176\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u5904\u7406\u795e\u7ecf\u8bb0\u5f55\u8bbe\u7f6e\u7684\u56fa\u6709\u5f02\u8d28\u6027\u5960\u5b9a\u4e86\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.14962", "categories": ["cs.AI", "cs.CC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.14962", "abs": "https://arxiv.org/abs/2507.14962", "authors": ["Johannes Schmidt", "Mohamed Maizia", "Victor Lagerkvist", "Johannes K. Fichte"], "title": "Complexity of Faceted Explanations in Propositional Abduction", "comment": "This is the author's self-archived copy including detailed proofs. To\n  appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the\n  41st International Conference on Logic Programming (ICLP 2025)", "summary": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post's framework.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u201c\u9762\u201d\u548c\u5206\u6790\u89e3\u91ca\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u7814\u7a76\u547d\u9898\u6c42\u53cd\u4e2d\u7684\u63a8\u7406\uff0c\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u5e76\u52a0\u6df1\u5bf9\u89e3\u91ca\u7684\u7406\u89e3\u3002", "motivation": "\u5c3d\u7ba1\u6c42\u53cd\u63a8\u7406\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u6709\u8bb8\u591a\u5e94\u7528\uff0c\u4f46\u8ba1\u6570\u548c\u679a\u4e3e\u7b49\u63a8\u7406\u95ee\u9898\u5728\u8ba1\u7b97\u4e0a\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u201c\u9762\u201d\u548c\u5206\u6790\u89e3\u91ca\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u7814\u7a76\u51b3\u7b56\u548c\u8ba1\u6570\u4e4b\u95f4\u7684\u63a8\u7406\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u89e3\u91ca\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u5229\u7684\u590d\u6742\u6027\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u547d\u9898\u6c42\u53cd\u7684\u201c\u9762\u201d\uff0c\u5373\u51fa\u73b0\u5728\u67d0\u4e9b\u89e3\u91ca\uff08\u76f8\u5173\uff09\u4f46\u4e0d\u51fa\u73b0\u5728\u6240\u6709\u89e3\u91ca\uff08\u53ef\u5206\uff09\u4e2d\u7684\u6587\u5b57\u3002\u901a\u8fc7\u5206\u6790\u201c\u9762\u201d\u6765\u63d0\u4f9b\u5bf9\u89e3\u91ca\u53d8\u5f02\u6027\u7684\u66f4\u7ec6\u7c92\u5ea6\u7684\u7406\u89e3\u3002\u6b64\u5916\uff0c\u8be5\u7814\u7a76\u8fd8\u8003\u8651\u4e86\u4e24\u4e2a\u89e3\u91ca\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u89e3\u91ca\u7684\u5f02\u8d28\u6027/\u540c\u8d28\u6027\u3002", "result": "\u8be5\u7814\u7a76\u5c06\u201c\u9762\u201d\u5f15\u5165\u547d\u9898\u6c42\u53cd\uff0c\u4ee5\u63d0\u4f9b\u5bf9\u89e3\u91ca\u53d8\u5f02\u6027\u7684\u66f4\u7ec6\u7c92\u5ea6\u7684\u7406\u89e3\u3002\u5b83\u8fd8\u901a\u8fc7\u8003\u8651\u89e3\u91ca\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u5206\u6790\u5f02\u8d28\u6027/\u540c\u8d28\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728 Post \u6846\u67b6\u4e2d\uff0c\u51e0\u4e4e\u5bf9\u547d\u9898\u6c42\u53cd\u7684\u201c\u9762\u201d\u8fdb\u884c\u4e86\u5b8c\u6574\u7684\u63cf\u8ff0\u3002", "conclusion": "\u8be5\u7814\u7a76\u5168\u9762\u5206\u6790\u4e86\u547d\u9898\u6c42\u53cd\u4e2d\u7684\u5404\u79cd\u8bbe\u5b9a\uff0c\u5305\u62ec\u5728 Post \u6846\u67b6\u4e2d\u7684\u51e0\u4e4e\u5b8c\u6574\u7684\u63cf\u8ff0\u3002"}}
{"id": "2507.15230", "categories": ["cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2507.15230", "abs": "https://arxiv.org/abs/2507.15230", "authors": ["Guoxi Liu", "Thomas Randall", "Rong Ge", "Federico Iuricich"], "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis", "comment": null, "summary": "Unstructured meshes present challenges in scientific data analysis due to\nirregular distribution and complex connectivity. Computing and storing\nconnectivity information is a major bottleneck for visualization algorithms,\naffecting both time and memory performance. Recent task-parallel data\nstructures address this by precomputing connectivity information at runtime\nwhile the analysis algorithm executes, effectively hiding computation costs and\nimproving performance. However, existing approaches are CPU-bound, forcing the\ndata structure and analysis algorithm to compete for the same computational\nresources, limiting potential speedups. To overcome this limitation, we\nintroduce a novel task-parallel approach optimized for heterogeneous CPU-GPU\nsystems. Specifically, we offload the computation of mesh connectivity\ninformation to GPU threads, enabling CPU threads to focus on executing the\nvisualization algorithm. Following this paradigm, we propose GALE (GPU-Aided\nLocalized data structurE), the first open-source CUDA-based data structure\ndesigned for heterogeneous task parallelism. Experiments on two 20-core CPUs\nand an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over\nstate-of-the-art localized data structures while maintaining memory efficiency.", "AI": {"tldr": "GALE\u662f\u4e00\u79cd\u65b0\u9896\u7684GPU\u52a0\u901f\u6570\u636e\u7ed3\u6784\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u975e\u7ed3\u6784\u5316\u7f51\u683c\u7684\u53ef\u89c6\u5316\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u975e\u7ed3\u6784\u5316\u7f51\u683c\u5728\u79d1\u5b66\u6570\u636e\u5206\u6790\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u8ba1\u7b97\u548c\u5b58\u50a8\u8fde\u63a5\u4fe1\u606f\u662f\u53ef\u89c6\u5316\u7b97\u6cd5\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u5f71\u54cd\u65f6\u95f4\u548c\u5185\u5b58\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9488\u5bf9\u5f02\u6784CPU-GPU\u7cfb\u7edf\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u5c06\u7f51\u683c\u8fde\u63a5\u4fe1\u606f\u7684\u8ba1\u7b97\u5378\u8f7d\u5230GPU\u7ebf\u7a0b\uff0c\u4f7fCPU\u7ebf\u7a0b\u80fd\u591f\u4e13\u6ce8\u4e8e\u6267\u884c\u53ef\u89c6\u5316\u7b97\u6cd5\u3002\u5728\u6b64\u8303\u4f8b\u7684\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86GALE\uff08GPU\u8f85\u52a9\u7684\u672c\u5730\u5316\u6570\u636e\u7ed3\u6784\uff09\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u5f02\u6784\u4efb\u52a1\u5e76\u884c\u7684\u5f00\u6e90CUDA\u57fa\u7840\u6570\u636e\u7ed3\u6784\u3002", "result": "GALE\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.7\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u4e14\u4e0e\u6700\u5148\u8fdb\u7684\u672c\u5730\u5316\u6570\u636e\u7ed3\u6784\u76f8\u6bd4\uff0c\u5185\u5b58\u6548\u7387\u76f8\u5f53\u3002", "conclusion": "GALE\u901a\u8fc7\u5c06\u7f51\u683c\u8fde\u63a5\u4fe1\u606f\u7684\u8ba1\u7b97\u5378\u8f7d\u5230GPU\u7ebf\u7a0b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u6700\u5148\u8fdb\u7684\u672c\u5730\u5316\u6570\u636e\u7ed3\u6784\u9ad82.7\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5185\u5b58\u6548\u7387\u3002"}}
{"id": "2507.14694", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14694", "abs": "https://arxiv.org/abs/2507.14694", "authors": ["Yue Ma", "Kanglei Zhou", "Fuyang Yu", "Frederick W. B. Li", "Xiaohui Liang"], "title": "Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks", "comment": null, "summary": "3D human motion forecasting aims to enable autonomous applications.\nEstimating uncertainty for each prediction (i.e., confidence based on\nprobability density or quantile) is essential for safety-critical contexts like\nhuman-robot collaboration to minimize risks. However, existing diverse motion\nforecasting approaches struggle with uncertainty quantification due to implicit\nprobabilistic representations hindering uncertainty modeling. We propose\nProbHMI, which introduces invertible networks to parameterize poses in a\ndisentangled latent space, enabling probabilistic dynamics modeling. A\nforecasting module then explicitly predicts future latent distributions,\nallowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI\nachieves strong performance for both deterministic and diverse prediction while\nvalidating uncertainty calibration, critical for risk-aware decision making.", "AI": {"tldr": "ProbHMI\u901a\u8fc7\u4f7f\u7528\u53ef\u9006\u7f51\u7edc\u8fdb\u884c\u6982\u7387\u5efa\u6a21\u6765\u89e3\u51b33D\u4eba\u7c7b\u52a8\u4f5c\u9884\u6d4b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u5b89\u5168\u5173\u952e\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728\u8bf8\u5982\u4eba\u673a\u534f\u4f5c\u7b49\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u6700\u5c0f\u5316\u98ce\u9669\uff0c3D\u4eba\u7c7b\u52a8\u4f5c\u9884\u6d4b\u9700\u8981\u4e3a\u6bcf\u4e2a\u9884\u6d4b\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u7531\u4e8e\u9690\u5f0f\u6982\u7387\u8868\u793a\u800c\u96be\u4ee5\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "method": "ProbHMI\u5f15\u5165\u4e86\u53ef\u9006\u7f51\u7edc\u6765\u53c2\u6570\u5316\u59ff\u52bf\uff0c\u5e76\u7ed3\u5408\u9884\u6d4b\u6a21\u5757\u6765\u663e\u5f0f\u9884\u6d4b\u672a\u6765\u6f5c\u5728\u5206\u5e03\uff0c\u4ece\u800c\u5b9e\u73b0\u6982\u7387\u52a8\u529b\u5b66\u5efa\u6a21\u548c\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "ProbHMI\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5728\u786e\u5b9a\u6027\u548c\u591a\u6837\u6027\u9884\u6d4b\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u80fd\u529b\uff0c\u8fd9\u5bf9\u4e8e\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "ProbHMI\u901a\u8fc7\u5f15\u5165\u53ef\u9006\u7f51\u7edc\u5728\u89e3\u8026\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u53c2\u6570\u5316\u59ff\u52bf\uff0c\u5b9e\u73b0\u4e86\u6982\u7387\u52a8\u529b\u5b66\u5efa\u6a21\uff0c\u5e76\u663e\u5f0f\u9884\u6d4b\u672a\u6765\u6f5c\u5728\u5206\u5e03\uff0c\u4ece\u800c\u80fd\u591f\u8fdb\u884c\u6709\u6548\u7684\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u786e\u5b9a\u6027\u548c\u591a\u6837\u6027\u9884\u6d4b\u65b9\u9762\u5747\u53d6\u5f97\u4e86\u5f3a\u52b2\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5bf9\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u3002"}}
{"id": "2507.14432", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.14432", "abs": "https://arxiv.org/abs/2507.14432", "authors": ["Han Gong", "Qiyue Li", "Zhi Liu", "Hao Zhou", "Peng Yuan Zhou", "Zhu Li", "Jie Li"], "title": "Adaptive 3D Gaussian Splatting Video Streaming", "comment": null, "summary": "The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the\nquality of volumetric video representation. Meanwhile, in contrast to\nconventional volumetric video, 3DGS video poses significant challenges for\nstreaming due to its substantially larger data volume and the heightened\ncomplexity involved in compression and transmission. To address these issues,\nwe introduce an innovative framework for 3DGS volumetric video streaming.\nSpecifically, we design a 3DGS video construction method based on the Gaussian\ndeformation field. By employing hybrid saliency tiling and differentiated\nquality modeling of 3DGS video, we achieve efficient data compression and\nadaptation to bandwidth fluctuations while ensuring high transmission quality.\nThen we build a complete 3DGS video streaming system and validate the\ntransmission performance. Through experimental evaluation, our method\ndemonstrated superiority over existing approaches in various aspects, including\nvideo quality, compression effectiveness, and transmission rate.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u76843DGS\u89c6\u9891\u6d41\u4f20\u8f93\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u9ad8\u65af\u53d8\u5f62\u573a\u7684\u65b9\u6cd5\u548c\u6df7\u5408\u663e\u8457\u6027\u5207\u7247\u3001\u5dee\u5f02\u5316\u8d28\u91cf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u538b\u7f29\u548c\u9ad8\u8d28\u91cf\u4f20\u8f93\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b33DGS\u89c6\u9891\u6d41\u4f20\u8f93\u9762\u4e34\u7684\u6570\u636e\u91cf\u5927\u3001\u538b\u7f29\u548c\u4f20\u8f93\u590d\u6742\u6027\u9ad8\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u53d8\u5f62\u573a\u7684\u4e09\u7ef4\u9ad8\u65af\u55b7\u6e85\uff083DGS\uff09\u89c6\u9891\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u6df7\u5408\u663e\u8457\u6027\u5207\u7247\u548c\u5dee\u5f02\u5316\u8d28\u91cf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u538b\u7f29\u548c\u5e26\u5bbd\u6ce2\u52a8\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5176\u5728\u89c6\u9891\u8d28\u91cf\u3001\u538b\u7f29\u6548\u7387\u548c\u4f20\u8f93\u901f\u7387\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u76843DGS\u89c6\u9891\u6d41\u4f20\u8f93\u6846\u67b6\u5728\u89c6\u9891\u8d28\u91cf\u3001\u538b\u7f29\u6548\u7387\u548c\u4f20\u8f93\u901f\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14406", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14406", "abs": "https://arxiv.org/abs/2507.14406", "authors": ["Michael J. Zellinger", "Matt Thomson"], "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering", "comment": "8 pages, 5 figures", "summary": "State-of-the-art reasoning LLMs are powerful problem solvers, but they still\noccasionally make mistakes. However, adopting AI models in risk-sensitive\ndomains often requires error rates near 0%. To address this gap, we propose\ncollaboration between a reasoning model and a human expert who resolves queries\nthe model cannot confidently answer. We find that quantifying the uncertainty\nof a reasoning model through the length of its reasoning trace yields an\neffective basis for deferral to a human, e.g., cutting the error rate of Qwen3\n235B-A22B on difficult MATH problems from 3% to less than 1% when deferring\n7.5% of queries. However, the high latency of reasoning models still makes them\nchallenging to deploy on use cases with high query volume. To address this\nchallenge, we explore fronting a reasoning model with a large non-reasoning\nmodel. We call this modified human-in-the-loop system \"Fail Fast, or Ask\",\nsince the non-reasoning model may defer difficult queries to the human expert\ndirectly (\"failing fast\"), without incurring the reasoning model's higher\nlatency. We show that this approach yields around 40% latency reduction and\nabout 50% cost savings for DeepSeek R1 while maintaining 90+% area under the\naccuracy-rejection curve. However, we observe that latency savings are lower\nthan expected because of \"latency drag\", the phenomenon that processing easier\nqueries with a non-reasoning model pushes the reasoning model's latency\ndistribution towards longer latencies. Broadly, our results suggest that the\ndeficiencies of state-of-the-art reasoning models -- nontrivial error rates and\nhigh latency -- can be substantially mitigated through black-box systems\nengineering, without requiring access to LLM internals.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u975e\u63a8\u7406\u6a21\u578b\u548c\u4eba\u7c7b\u4e13\u5bb6\uff0c\u53ef\u4ee5\u63d0\u9ad8 LLM \u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u964d\u4f4e\u9519\u8bef\u7387\u548c\u5ef6\u8fdf\uff0c\u4f46\u5b58\u5728\u201c\u5ef6\u8fdf\u62d6\u62fd\u201d\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u63a8\u7406\u6a21\u578b\uff08\u5982 LLM\uff09\u5728\u98ce\u9669\u654f\u611f\u9886\u57df\u4e2d\u5b58\u5728\u7684\u9519\u8bef\u7387\u8f83\u9ad8\u548c\u5ef6\u8fdf\u65f6\u95f4\u957f\u7684\u95ee\u9898\uff0c\u4ee5\u6ee1\u8db3\u63a5\u8fd1 0% \u7684\u9519\u8bef\u7387\u8981\u6c42\uff0c\u5e76\u63d0\u9ad8\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4eba\u673a\u534f\u4f5c\u7cfb\u7edf\uff0c\u79f0\u4e3a\u201c\u5feb\u901f\u5931\u8d25\u6216\u8be2\u95ee\u201d (Fail Fast, or Ask)\u3002\u8be5\u7cfb\u7edf\u5728\u524d\u7ebf\u90e8\u7f72\u4e00\u4e2a\u5927\u578b\u975e\u63a8\u7406\u6a21\u578b\uff0c\u7531\u8be5\u6a21\u578b\u5904\u7406\u7b80\u5355\u67e5\u8be2\uff0c\u5e76\u5c06\u590d\u6742\u6216\u6a21\u578b\u4e0d\u786e\u5b9a\u7684\u67e5\u8be2\u59d4\u6258\u7ed9\u4eba\u7c7b\u4e13\u5bb6\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06 Qwen3 235B-A22B \u5728 MATH \u96be\u9898\u4e0a\u7684\u9519\u8bef\u7387\u4ece 3% \u964d\u4f4e\u5230 1% \u4ee5\u4e0b\uff0c\u540c\u65f6\u53ea\u5c06 7.5% \u7684\u67e5\u8be2\u59d4\u6258\u7ed9\u4eba\u7c7b\u3002\u5bf9\u4e8e DeepSeek R1\uff0c\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86\u7ea6 40% \u7684\u5ef6\u8fdf\u7f29\u51cf\u548c\u7ea6 50% \u7684\u6210\u672c\u8282\u7ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86 90% \u4ee5\u4e0a\u7684\u51c6\u786e\u7387-\u62d2\u7edd\u66f2\u7ebf\u4e0b\u9762\u79ef\u3002\u7136\u800c\uff0c\u201c\u5ef6\u8fdf\u62d6\u62fd\u201d\u73b0\u8c61\u5bfc\u81f4\u5ef6\u8fdf\u8282\u7701\u4f4e\u4e8e\u9884\u671f\u3002", "conclusion": "\u901a\u8fc7\u9ed1\u76d2\u7cfb\u7edf\u5de5\u7a0b\uff0c\u53ef\u4ee5\u5728\u4e0d\u8bbf\u95ee LLM \u5185\u90e8\u673a\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u7f13\u89e3\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u7684\u975e\u5fc5\u8981\u9519\u8bef\u7387\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\u3002"}}
{"id": "2507.14618", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14618", "abs": "https://arxiv.org/abs/2507.14618", "authors": ["Hong Wu", "Jia-Ji Zhu", "Jian Li", "Xue-Min Yang", "Jiang-Shan Chen", "Mu Zhou"], "title": "Floquet composite Dirac semimetals", "comment": "6 pages and 5 figures", "summary": "Dirac semimetals are classified into types I, II, and III based on the\ntopological charge of their Dirac points. If a three-dimensional (3D) system\ncan be sliced into a family of $k_z$-dependent normal and topological\ninsulators, type I Dirac points separate a 2D normal insulator from a 2D\nfirst-order topological insulator, while type II (III) Dirac points separate a\n2D normal (first-order) insulator from a 2D second-order topological insulator.\nTo investigate the effects arising from the interplay of distinct Dirac points,\none may wonder whether these Dirac points can coexist in single system. Here,\nwe propose a scheme to induce composite Dirac semimetals in a Floquet four-band\nsystem with time-reversal and space-inversion symmetries. A general description\nis established to characterize Dirac semimetals in Floquet systems. The results\nshow that Dirac semimetals hosting coexisting type I, II, and III Dirac points\ncan be induced by delta-function or harmonic driving. Our results provide a\npromising new avenue for exploring novel Dirac semimetals.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Floquet\u7cfb\u7edf\u4e2d\u8bf1\u5bfc\u590d\u5408\u72c4\u62c9\u514b\u534a\u91d1\u5c5e\u7684\u65b9\u6cd5\uff0c\u53ef\u5b9e\u73b0I\u3001II\u3001III\u578b\u72c4\u62c9\u514b\u70b9\u7684\u5171\u5b58\u3002", "motivation": "\u4e3a\u4e86\u7814\u7a76\u4e0d\u540c\u72c4\u62c9\u514b\u70b9\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u72c4\u62c9\u514b\u70b9\u662f\u5426\u80fd\u5728\u5355\u4e2a\u7cfb\u7edf\u4e2d\u5171\u5b58\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Floquet\u56db\u5e26\u7cfb\u7edf\u4e2d\u8bf1\u5bfc\u590d\u5408\u72c4\u62c9\u514b\u534a\u91d1\u5c5e\u7684\u65b9\u6848\uff0c\u5e76\u5efa\u7acb\u4e86\u63cf\u8ff0Floquet\u7cfb\u7edf\u4e2d\u72c4\u62c9\u514b\u534a\u91d1\u5c5e\u7684\u901a\u7528\u63cf\u8ff0\u3002", "result": "\u6210\u529f\u8bf1\u5bfc\u4e86\u540c\u65f6\u5305\u542bI\u3001II\u548cIII\u578b\u72c4\u62c9\u514b\u70b9\u7684\u72c4\u62c9\u514b\u534a\u91d1\u5c5e\uff0c\u8be5\u7cfb\u7edf\u53ef\u901a\u8fc7delta\u51fd\u6570\u6216\u8c10\u6ce2\u9a71\u52a8\u5b9e\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5728\u5177\u6709\u65f6\u95f4\u53cd\u6f14\u548c\u7a7a\u95f4\u53cd\u79f0\u7684Floquet\u56db\u5e26\u7cfb\u7edf\u4e2d\u8bf1\u5bfc\u590d\u5408\u72c4\u62c9\u514b\u534a\u91d1\u5c5e\u7684\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86 I\u3001II \u548c III \u578b\u72c4\u62c9\u514b\u70b9\u7684\u5171\u5b58\u3002"}}
{"id": "2507.15268", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15268", "abs": "https://arxiv.org/abs/2507.15268", "authors": ["Junhyeong Lee", "Joon-Young Kim", "Heekyu Kim", "Inhyo Lee", "Seunghwa Ryu"], "title": "IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry", "comment": null, "summary": "The injection molding industry faces critical challenges in preserving and\ntransferring field knowledge, particularly as experienced workers retire and\nmultilingual barriers hinder effective communication. This study introduces\nIM-Chat, a multi-agent framework based on large language models (LLMs),\ndesigned to facilitate knowledge transfer in injection molding. IM-Chat\nintegrates both limited documented knowledge (e.g., troubleshooting tables,\nmanuals) and extensive field data modeled through a data-driven process\ncondition generator that infers optimal manufacturing settings from\nenvironmental inputs such as temperature and humidity, enabling robust and\ncontext-aware task resolution. By adopting a retrieval-augmented generation\n(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat\nensures adaptability without the need for fine-tuning. Performance was assessed\nacross 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and\nGPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance\nand correctness, and was further supplemented by automated evaluation using\nGPT-4o guided by a domain-adapted instruction prompt. The evaluation results\nindicate that more capable models tend to achieve higher accuracy, particularly\nin complex, tool-integrated scenarios. Overall, these findings demonstrate the\nviability of multi-agent LLM systems for industrial knowledge workflows and\nestablish IM-Chat as a scalable and generalizable approach to AI-assisted\ndecision support in manufacturing.", "AI": {"tldr": "IM-Chat\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u6ce8\u5851\u6210\u578b\u884c\u4e1a\u7684\u77e5\u8bc6\u8f6c\u79fb\u95ee\u9898\uff0c\u5b83\u901a\u8fc7\u6574\u5408\u6587\u6863\u77e5\u8bc6\u548c\u73b0\u573a\u6570\u636e\uff0c\u5e76\u91c7\u7528RAG\u7b56\u7565\u548c\u5de5\u5177\u8c03\u7528\u4ee3\u7406\uff0c\u80fd\u591f\u9002\u5e94\u5e76\u89e3\u51b3\u5b9e\u9645\u751f\u4ea7\u4e2d\u7684\u95ee\u9898\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6ce8\u5851\u6210\u578b\u884c\u4e1a\u5728\u77e5\u8bc6\u4fdd\u5b58\u548c\u8f6c\u79fb\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5de5\u4eba\u9000\u4f11\u548c\u591a\u8bed\u8a00\u969c\u788d\u5bfc\u81f4\u7684\u6c9f\u901a\u4e0d\u7545\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684IM-Chat\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u6587\u6863\u77e5\u8bc6\u548c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u5de5\u827a\u6761\u4ef6\u751f\u6210\u5668\u63a8\u65ad\u51fa\u7684\u73b0\u573a\u6570\u636e\uff0c\u5e76\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7b56\u7565\u548c\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u3002", "result": "\u5728100\u4e2a\u5355\u5de5\u5177\u548c60\u4e2a\u6df7\u5408\u4efb\u52a1\u7684\u8bc4\u4f30\u4e2d\uff0cIM-Chat\u5728\u590d\u6742\u3001\u4e0e\u5de5\u5177\u96c6\u6210\u7684\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\uff0c\u4e14\u80fd\u529b\u66f4\u5f3a\u7684\u6a21\u578b\u51c6\u786e\u6027\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u591a\u667a\u80fd\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u5728\u5de5\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u6d41\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86IM-Chat\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u6cdb\u5316\u7684AI\u8f85\u52a9\u5236\u9020\u51b3\u7b56\u652f\u6301\u65b9\u6cd5\u3002"}}
{"id": "2507.14179", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.14179", "abs": "https://arxiv.org/abs/2507.14179", "authors": ["Nobel Dhar", "Bobin Deng", "Md Romyull Islam", "Xinyue Zhang", "Kazi Fahim Ahmad Nasif", "Kun Suo"], "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering", "comment": "To be published in Euro-Par 2025", "summary": "Large Language Models (LLMs) exhibit significant activation sparsity, where\nonly a subset of neurons are active for a given input. Although this sparsity\npresents opportunities to reduce computational cost, efficiently utilizing it\nrequires predicting activation patterns in a scalable manner. However, direct\nprediction at the neuron level is computationally expensive due to the vast\nnumber of neurons in modern LLMs. To enable efficient prediction and\nutilization of activation sparsity, we propose a clustering-based activation\npattern compression framework. Instead of treating each neuron independently,\nwe group similar activation patterns into a small set of representative\nclusters. Our method achieves up to 79.34% clustering precision, outperforming\nstandard binary clustering approaches while maintaining minimal degradation in\nperplexity (PPL) scores. With a sufficiently large number of clusters, our\napproach attains a PPL score as low as 12.49, demonstrating its effectiveness\nin preserving model quality while reducing computational overhead. By\npredicting cluster assignments rather than individual neuron states, future\nmodels can efficiently infer activation patterns from pre-computed centroids.\nWe detail the clustering algorithm, analyze its effectiveness in capturing\nmeaningful activation structures, and demonstrate its potential to improve\nsparse computation efficiency. This clustering-based formulation serves as a\nfoundation for future work on activation pattern prediction, paving the way for\nefficient inference in large-scale language models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u6765\u63d0\u9ad8\u9884\u6d4b\u6548\u7387\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u4e3a\u4e86\u80fd\u591f\u9ad8\u6548\u5730\u9884\u6d4b\u548c\u5229\u7528\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u6fc0\u6d3b\u6a21\u5f0f\u3002\u7136\u800c\uff0c\u7531\u4e8e\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u795e\u7ecf\u5143\u6570\u91cf\u4f17\u591a\uff0c\u5728\u795e\u7ecf\u5143\u7ea7\u522b\u76f4\u63a5\u8fdb\u884c\u9884\u6d4b\u7684\u8ba1\u7b97\u6210\u672c\u5f88\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u5230\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\u4e2d\uff0c\u800c\u4e0d\u662f\u72ec\u7acb\u5730\u5bf9\u5f85\u6bcf\u4e2a\u795e\u7ecf\u5143\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe79.34%\u7684\u805a\u7c7b\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u6807\u51c6\u7684\u4e8c\u5143\u805a\u7c7b\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u56f0\u60d1\u5ea6\uff08PPL\uff09\u5206\u6570\u4e0a\u4ec5\u6709\u5f88\u5c0f\u7684\u4e0b\u964d\u3002\u5f53\u805a\u7c7b\u6570\u91cf\u8db3\u591f\u591a\u65f6\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u523012.49\u7684\u4f4e\u56f0\u60d1\u5ea6\u5206\u6570\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u548c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u9884\u6d4b\u805a\u7c7b\u5206\u914d\u800c\u975e\u5355\u72ec\u795e\u7ecf\u5143\u72b6\u6001\uff0c\u672a\u6765\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u9884\u5148\u8ba1\u7b97\u7684\u8d28\u5fc3\u63a8\u65ad\u6fc0\u6d3b\u6a21\u5f0f\u3002\u8be5\u57fa\u4e8e\u805a\u7c7b\u7684\u6a21\u578b\u4e3a\u672a\u6765\u6fc0\u6d3b\u6a21\u5f0f\u9884\u6d4b\u5de5\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14493", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.14493", "abs": "https://arxiv.org/abs/2507.14493", "authors": ["Umesh Thuwal", "Sumanta Maity", "Ruksana Pervin", "Rohit Medwal", "Joseph Vimal Vas", "Yasuhiro Fukuma", "Herve Courtois", "Clemens B. Winkelmann", "Anjan Kumar Gupta"], "title": "Tunable exchange bias in Y$_3$Fe$_5$O$_{12}$ film on Gd$_3$Ga$_5$O$_{12}$", "comment": "7 pages (5 figures) + 2 page suppl-info (6 figures)", "summary": "Ferrimagnetic Y$_3$Fe$_5$O$_{12}$ grown on the (001) surface of paramagnetic\nGd$_3$Ga$_5$O$_{12}$ experiences an exchange bias field, which has been\nattributed to the magnetism of an interface layer between the two materials. We\nreport here that when grown using sputtering and with lower post-annealing\ntemperatures than in previous works, the blocking temperature of the interface\nmagnetic layer is lowered to about 7 K, while still displaying a strong\nexchange bias. This exchange bias is then found to be tunable between its two\nextreme values by carefully varying the field cooling protocol. This is\nattributed to a slow and complex dynamics of the spins of the interface-layer\nwhen it is warmed up close to its blocking (or melting) temperature, which is\nreminiscent of a spin glass.", "AI": {"tldr": "\u901a\u8fc7\u6e85\u5c04\u548c\u4f4e\u6e29\u9000\u706b\u964d\u4f4eYIG/GGG\u754c\u9762\u5c42\u7684\u963b\u6321\u6e29\u5ea6\u81f37K\uff0c\u5e76\u53d1\u73b0\u4ea4\u6362\u504f\u7f6e\u53ef\u901a\u8fc7\u573a\u51b7\u8fc7\u7a0b\u8c03\u63a7\uff0c\u8fd9\u4e0e\u81ea\u65cb\u73bb\u7483\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u76f8\u4f3c\u3002", "motivation": "\u63a2\u7a76\u94c1\u78c1\u6027Y3Fe5O12\u8584\u819c\u5728\u987a\u78c1\u6027Gd3Ga5O12\u886c\u5e95\u4e0a\u51fa\u73b0\u7684\u4ea4\u6362\u504f\u7f6e\u6548\u5e94\u7684\u6765\u6e90\uff0c\u5e76\u7814\u7a76\u5176\u8c03\u63a7\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6e85\u5c04\u751f\u957f\u6280\u672f\uff0c\u5e76\u4f18\u5316\u4e86\u4f4e\u6e29\u540e\u9000\u706b\u5de5\u827a\uff0c\u5c06\u94c1\u78c1\u6027Y3Fe5O12\u8584\u819c\u7684\u754c\u9762\u5c42\u963b\u6321\u6e29\u5ea6\u964d\u4f4e\u3002", "result": "\u53d1\u73b0\u901a\u8fc7\u6e85\u5c04\u548c\u4f4e\u6e29\u540e\u9000\u706b\u5de5\u827a\uff0c\u754c\u9762\u5c42\u7684\u963b\u6321\u6e29\u5ea6\u964d\u4f4e\u81f37K\uff0c\u540c\u65f6\u4ecd\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u4ea4\u6362\u504f\u7f6e\u3002\u901a\u8fc7\u6539\u53d8\u573a\u51b7\u534f\u8bae\uff0c\u53ef\u4ee5\u8c03\u63a7\u4ea4\u6362\u504f\u7f6e\u5728\u4e24\u4e2a\u6781\u7aef\u503c\u4e4b\u95f4\u53d8\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u8c03\u6574\u6e85\u5c04\u548c\u4f4e\u6e29\u9000\u706b\u6761\u4ef6\uff0c\u6210\u529f\u5c06\u94c1\u78c1\u6027Y3Fe5O12\u8584\u819c\u754c\u9762\u5c42\u7684\u963b\u6321\u6e29\u5ea6\u964d\u4f4e\u81f37K\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u70c8\u7684\u4ea4\u6362\u504f\u7f6e\u6548\u5e94\u3002\u6b64\u5916\uff0c\u7814\u7a76\u53d1\u73b0\u8be5\u4ea4\u6362\u504f\u7f6e\u6548\u5e94\u53ef\u4ee5\u901a\u8fc7\u7cbe\u7ec6\u8c03\u63a7\u573a\u51b7\u8fc7\u7a0b\u5728\u4e24\u4e2a\u6781\u7aef\u503c\u4e4b\u95f4\u8fdb\u884c\u8c03\u8282\uff0c\u8fd9\u5f52\u56e0\u4e8e\u754c\u9762\u5c42\u81ea\u65cb\u5728\u63a5\u8fd1\u963b\u6321\uff08\u6216\u7194\u5316\uff09\u6e29\u5ea6\u65f6\u8868\u73b0\u51fa\u7684\u7f13\u6162\u800c\u590d\u6742\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u7c7b\u4f3c\u4e8e\u81ea\u65cb\u73bb\u7483\u3002"}}
{"id": "2507.14727", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14727", "abs": "https://arxiv.org/abs/2507.14727", "authors": ["Jiayu Ding", "Benjamin Seleb", "Saad Bhamla", "Zhenyu Gan"], "title": "Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model", "comment": null, "summary": "Quadrupedal animals employ diverse galloping strategies to optimize speed,\nstability, and energy efficiency. However, the biomechanical mechanisms that\nenable adaptive gait transitions during high-speed locomotion under load remain\npoorly understood. In this study, we present new empirical and modeling\ninsights into the biomechanics of load-pulling quadrupeds, using sprint sled\ndogs as a model system. High-speed video and force recordings reveal that sled\ndogs often switch between rotary and transverse galloping gaits within just a\nfew strides and without any observable changes in speed, stride duration, or\nterrain, providing clear evidence of locomotor multistability during high-speed\nload-pulling. To investigate the mechanical basis of these transitions, a\nphysics-based quadrupedal Spring-Loaded Inverted Pendulum model with hybrid\ndynamics and prescribed footfall sequences to reproduce the asymmetric\ngalloping patterns observed in racing sled dogs. Through trajectory\noptimization, we replicate experimentally observed gait sequences and identify\nswing-leg stiffness modulation as a key control mechanism for inducing\ntransitions. This work provides a much-needed biomechanical perspective on\nhigh-speed animal draft and establishes a modeling framework for studying\nlocomotion in pulling quadrupeds, with implications for both biological\nunderstanding and the design of adaptive legged systems.", "AI": {"tldr": "\u96ea\u6a47\u72ac\u5728\u9ad8\u901f\u62c9\u62fd\u65f6\u80fd\u5728\u51e0\u79cd\u6b65\u6001\u95f4\u5feb\u901f\u5207\u6362\uff0c\u8fd9\u5f97\u76ca\u4e8e\u5176\u817f\u90e8\u521a\u5ea6\u7684\u8c03\u8282\u3002", "motivation": "\u4e3a\u4e86\u89e3\u9ad8\u901f\u8d1f\u8f7d\u4e0b\u9002\u5e94\u6027\u6b65\u6001\u8f6c\u6362\u7684\u751f\u7269\u529b\u5b66\u673a\u5236\uff0c\u4ee5\u8349\u539f\u72ac\u9f20\u4e3a\u6a21\u578b\u7cfb\u7edf\u3002", "method": "\u5229\u7528\u9ad8\u901f\u89c6\u9891\u548c\u529b\u8bb0\u5f55\uff0c\u7ed3\u5408\u57fa\u4e8e\u7269\u7406\u7684\u56db\u8db3\u5f39\u7c27\u52a0\u8f7d\u5012\u7acb\u6446\u6a21\u578b\uff08\u5177\u6709\u6df7\u5408\u52a8\u529b\u5b66\u548c\u89c4\u5b9a\u7684\u843d\u811a\u70b9\u5e8f\u5217\uff09\uff0c\u901a\u8fc7\u8f68\u8ff9\u4f18\u5316\u6765\u7814\u7a76\u96ea\u6a47\u72ac\u7684\u751f\u7269\u529b\u5b66\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u96ea\u6a47\u72ac\u5728\u9ad8\u901f\u62c9\u62fd\u65f6\u5e38\u5e38\u5728\u51e0\u6b65\u4e4b\u5185\u5728\u65cb\u8f6c\u548c\u6a2a\u5411\u75be\u9a70\u6b65\u6001\u4e4b\u95f4\u5207\u6362\uff0c\u5e76\u4e14\u5728\u901f\u5ea6\u3001\u6b65\u5e45\u6301\u7eed\u65f6\u95f4\u6216\u5730\u5f62\u4e0a\u6ca1\u6709\u660e\u663e\u53d8\u5316\uff0c\u8bc1\u660e\u4e86\u8fd0\u52a8\u4e2d\u7684\u591a\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u8f68\u8ff9\u4f18\u5316\uff0c\u6210\u529f\u590d\u5236\u4e86\u5b9e\u9a8c\u89c2\u5bdf\u5230\u7684\u6b65\u6001\u5e8f\u5217\uff0c\u5e76\u5c06\u6446\u52a8\u817f\u521a\u5ea6\u8c03\u8282\u786e\u5b9a\u4e3a\u5f15\u8d77\u6b65\u6001\u8f6c\u6362\u7684\u5173\u952e\u63a7\u5236\u673a\u5236\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u9ad8\u901f\u62c9\u62fd\u52a8\u7269\u63d0\u4f9b\u4e86\u6025\u9700\u7684\u751f\u7269\u529b\u5b66\u89c6\u89d2\uff0c\u5e76\u5efa\u7acb\u4e86\u7814\u7a76\u62c9\u62fd\u56db\u8db3\u52a8\u7269\u8fd0\u52a8\u7684\u6a21\u578b\u6846\u67b6\uff0c\u5bf9\u751f\u7269\u5b66\u7406\u89e3\u548c\u9002\u5e94\u6027\u817f\u90e8\u7cfb\u7edf\u8bbe\u8ba1\u90fd\u6709\u501f\u9274\u610f\u4e49\u3002"}}
{"id": "2507.14422", "categories": ["quant-ph", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2507.14422", "abs": "https://arxiv.org/abs/2507.14422", "authors": ["Zane Ozzello", "Yannick Meurice"], "title": "Multipartite entanglement from ditstrings for 1+1D systems", "comment": "24 pages, 16 figures", "summary": "We show that multipartite entanglement can be used as an efficient way of\nidentifying the critical points of 1+1D systems. We demonstrate this with the\nquantum Ising model, lattice $\\lambda \\phi^4$ approximated with qutrits, and\narrays of Rydberg atoms. To do so we make use of multipartite compositions of\nentanglement quantities for different parts combined to form the strong\nsubadditivity, weak monotonicity, and a convex combination of these with\nconformal properties. These quantities display some remarkable properties. We\nwill demonstrate how the entanglement of individual parts together displays\nbehavior at phase boundaries, but the combination of these in the\naforementioned quantities sharpens and localizes this behavior to the\nboundaries even better. We will show that we can extend a scheme for\napproximating the entanglement with the mutual information, and that this acts\nas a lower bound which will also follow the changes in the entanglement for the\nabove quantities, despite the additional contributions of different signs. This\nmutual information approximation to the identifying quantities can have its\nlower probabilities removed in a process we call filtering, and despite the\ncombination of terms will respond well to the filtering and offer improvements\nto the lower bound.", "AI": {"tldr": "\u591a\u65b9\u7ea0\u7f20\u53ef\u7528\u4e8e\u6709\u6548\u8bc6\u522b1+1D\u7cfb\u7edf\u7684\u4e34\u754c\u70b9\uff0c\u5e76\u80fd\u6bd4\u5355\u72ec\u7684\u7ea0\u7f20\u91cf\u66f4\u7cbe\u786e\u5730\u8bc6\u522b\u76f8\u8fb9\u754c\u7684\u884c\u4e3a\u3002\u4e92\u4fe1\u606f\u4e5f\u53ef\u7528\u4e8e\u8fd1\u4f3c\u7ea0\u7f20\uff0c\u5e76\u5728\u6ee4\u6ce2\u540e\u63d0\u4f9b\u6539\u8fdb\u7684\u4e0b\u754c\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u591a\u65b9\u7ea0\u7f20\u5728\u8bc6\u522b\u4e00\u7ef4\u91cf\u5b50\u7cfb\u7edf\u4e34\u754c\u70b9\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7ea0\u7f20\u91cf\u7ec4\u5408\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u591a\u65b9\u7ea0\u7f20\u91cf\u7ec4\u5408\uff0c\u5305\u62ec\u5f3a\u6b21\u53ef\u52a0\u6027\u3001\u5f31\u5355\u8c03\u6027\u548c\u4e0e\u5171\u5f62\u6027\u8d28\u7684\u51f8\u7ec4\u5408\uff0c\u6765\u8bc6\u522b\u4e34\u754c\u70b9\u3002\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u6269\u5c55\u7528\u4e92\u4fe1\u606f\u8fd1\u4f3c\u7ea0\u7f20\u7684\u65b9\u6848\uff0c\u8be5\u4e92\u4fe1\u606f\u53ef\u4f5c\u4e3a\u4e0b\u754c\uff0c\u5e76\u80fd\u5f88\u597d\u5730\u54cd\u5e94\u6ee4\u6ce2\u8fc7\u7a0b\uff0c\u4ece\u800c\u6539\u8fdb\u4e0b\u754c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u591a\u65b9\u7ea0\u7f20\u91cf\u80fd\u591f\u6bd4\u5355\u72ec\u7684\u7ea0\u7f20\u91cf\u66f4\u7cbe\u786e\u5730\u8bc6\u522b\u548c\u5b9a\u4f4d\u76f8\u8fb9\u754c\u5904\u7684\u884c\u4e3a\u3002\u4e92\u4fe1\u606f\u4f5c\u4e3a\u4e00\u79cd\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u540c\u6837\u80fd\u6709\u6548\u5730\u8ffd\u8e2a\u7ea0\u7f20\u91cf\u7684\u53d8\u5316\uff0c\u5e76\u4e14\u5728\u6ee4\u6ce2\u5904\u7406\u540e\u80fd\u63d0\u4f9b\u6539\u8fdb\u7684\u4e0b\u754c\u3002", "conclusion": "\u6587\u7ae0\u8868\u660e\uff0c\u591a\u65b9\u7ea0\u7f20\u53ef\u7528\u4e8e\u6709\u6548\u8bc6\u522b1+1D\u7cfb\u7edf\u7684\u4e34\u754c\u70b9\uff0c\u5e76\u5728\u91cf\u5b50\u4f0a\u8f9b\u6a21\u578b\u3001\u03bb \u03c6^4\u683c\u70b9\uff08\u7528qutrits\u8fd1\u4f3c\uff09\u548c\u91cc\u5fb7\u4f2f\u539f\u5b50\u9635\u5217\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.14240", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14240", "abs": "https://arxiv.org/abs/2507.14240", "authors": ["Mohammad Shahedur Rahman", "Peng Gao", "Yuede Ji"], "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem", "comment": "10 pages, 5 figures", "summary": "Large language models (LLMs) leverage deep learning to process and predict\nsequences of words from context, enabling them to perform various NLP tasks,\nsuch as translation, summarization, question answering, and content generation.\nHowever, the growing size and complexity of developing, training, and deploying\nadvanced LLMs require extensive computational resources and large datasets.\nThis creates a barrier for users. As a result, platforms that host models and\ndatasets are widely used. For example, Hugging Face, one of the most popular\nplatforms, hosted 1.8 million models and 450K datasets by June 2025, with no\nsign of slowing down. Since many LLMs are built from base models, pre-trained\nmodels, and external datasets, they can inherit vulnerabilities, biases, or\nmalicious components from earlier models or datasets. Therefore, it is critical\nto understand the origin and development of these components to better detect\npotential risks, improve model fairness, and ensure compliance. Motivated by\nthis, our project aims to study the relationships between models and datasets,\nwhich are core components of the LLM supply chain. First, we design a method to\nsystematically collect LLM supply chain data. Using this data, we build a\ndirected heterogeneous graph to model the relationships between models and\ndatasets, resulting in a structure with 397,376 nodes and 453,469 edges. We\nthen perform various analyses and uncover several findings, such as: (i) the\nLLM supply chain graph is large, sparse, and follows a power-law degree\ndistribution; (ii) it features a densely connected core and a fragmented\nperiphery; (iii) datasets play pivotal roles in training; (iv) strong\ninterdependence exists between models and datasets; and (v) the graph is\ndynamic, with daily updates reflecting the ecosystem's ongoing evolution.", "AI": {"tldr": "LLM\u4f9b\u5e94\u94fe\u56fe\u8c31\u5206\u6790\u663e\u793a\uff0c\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u5b58\u5728\u590d\u6742\u4e14\u52a8\u6001\u7684\u5173\u8054\uff0c\u6570\u636e\u96c6\u662f\u8bad\u7ec3\u7684\u5173\u952e\uff0c\u751f\u6001\u7cfb\u7edf\u5e9e\u5927\u4e14\u5728\u4e0d\u65ad\u53d1\u5c55\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9LLM\u5f00\u53d1\u3001\u8bad\u7ec3\u548c\u90e8\u7f72\u4e2d\u56e0\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\u800c\u4ea7\u751f\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\u58c1\u5792\uff0c\u5e76\u89e3\u51b3\u7ee7\u627f\u81ea\u65e9\u671f\u6a21\u578b\u6216\u6570\u636e\u96c6\u7684\u6f5c\u5728\u6f0f\u6d1e\u3001\u504f\u89c1\u6216\u6076\u610f\u7ec4\u4ef6\u5e26\u6765\u7684\u98ce\u9669\uff0c\u9700\u8981\u7406\u89e3LLM\u4f9b\u5e94\u94fe\u4e2d\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u7cfb\u7edf\u6027\u6536\u96c6LLM\u4f9b\u5e94\u94fe\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b397,376\u4e2a\u8282\u70b9\u548c453,469\u6761\u8fb9\u7684\u6709\u5411\u5f02\u6784\u56fe\uff0c\u7136\u540e\u8fdb\u884c\u591a\u79cd\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u4f9b\u5e94\u94fe\u56fe\u8c31\u89c4\u6a21\u5e9e\u5927\u3001\u7a00\u758f\u4e14\u9075\u5faa\u5e42\u5f8b\u5ea6\u5206\u5e03\uff1b\u56fe\u4e2d\u5b58\u5728\u4e00\u4e2a\u5bc6\u96c6\u8fde\u63a5\u7684\u6838\u5fc3\u548c\u788e\u7247\u5316\u7684\u5916\u56f4\uff1b\u6570\u636e\u96c6\u5728\u8bad\u7ec3\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff1b\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff1b\u8be5\u56fe\u8c31\u662f\u52a8\u6001\u7684\uff0c\u6bcf\u65e5\u66f4\u65b0\u53cd\u6620\u4e86\u751f\u6001\u7cfb\u7edf\u7684\u6301\u7eed\u6f14\u53d8\u3002", "conclusion": "LLM\u4f9b\u5e94\u94fe\u56fe\u8c31\u63ed\u793a\u4e86\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u590d\u6742\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u5176\u52a8\u6001\u6f14\u5316\u7279\u6027\u8981\u6c42\u6301\u7eed\u76d1\u63a7\u4ee5\u8bc6\u522b\u98ce\u9669\u3002\u5efa\u8bae\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u5173\u7cfb\u6765\u6539\u8fdb\u6a21\u578b\u5b89\u5168\u6027\u3001\u516c\u5e73\u6027\u548c\u5408\u89c4\u6027\u3002"}}
{"id": "2507.15118", "categories": ["eess.SP", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.15118", "abs": "https://arxiv.org/abs/2507.15118", "authors": ["Szymon Mazurek", "Stephen Moore", "Alessandro Crimi"], "title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings", "comment": null, "summary": "Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce\nneurologists and costly diagnostic tools. We propose a graph-based deep\nlearning framework to detect epilepsy from low-cost Electroencephalography\n(EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus\nis on fair, accessible automatic assessment and explainability to shed light on\nepilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs,\nclassify them, and identify interchannel relationships and temporal dynamics\nusing graph attention networks (GAT). To emphasize connectivity biomarkers, we\nadapt the inherently node-focused GAT to analyze edges. We also designed signal\npreprocessing for low-fidelity recordings and a lightweight GAT architecture\ntrained on Google Colab and deployed on RaspberryPi devices. Results: The\napproach achieves promising classification performance, outperforming a\nstandard classifier based on random forest and graph convolutional networks in\nterms of accuracy and robustness over multiple sessions, but also highlighting\nspecific connections in the fronto-temporal region. Conclusions: The results\nhighlight the potential of GATs to provide insightful and scalable diagnostic\nsupport for epilepsy in underserved regions, paving the way for affordable and\naccessible neurodiagnostic tools.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u4f4e\u6210\u672c\u8111\u7535\u56fe\uff08EEG\uff09\u786c\u4ef6\u68c0\u6d4b\u766b\u75eb\u75c5\uff0c\u7279\u522b\u5173\u6ce8\u670d\u52a1\u6b20\u7f3a\u5730\u533a\u3002\u8be5\u6846\u67b6\u5728\u516c\u5e73\u6027\u3001\u53ef\u53ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4e3a\u5f00\u53d1\u7ecf\u6d4e\u5b9e\u60e0\u7684\u795e\u7ecf\u8bca\u65ad\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "motivation": "\u766b\u75eb\u75c5\u5728\u4f4e\u6536\u5165\u56fd\u5bb6\u7684\u8bca\u65ad\u7387\u504f\u4f4e\uff0c\u539f\u56e0\u662f\u795e\u7ecf\u79d1\u533b\u751f\u7a00\u7f3a\u4e14\u8bca\u65ad\u5de5\u5177\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u4f4e\u6210\u672c\u7684\u8111\u7535\u56fe\uff08EEG\uff09\u786c\u4ef6\u68c0\u6d4b\u766b\u75eb\u75c5\uff0c\u5e76\u5173\u6ce8\u516c\u5e73\u3001\u53ef\u53ca\u7684\u81ea\u52a8\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ee5\u63ed\u793a\u766b\u75eb\u751f\u7269\u6807\u5fd7\u7269\u3002", "method": "\u901a\u8fc7\u5c06\u8111\u7535\u56fe\uff08EEG\uff09\u4fe1\u53f7\u5efa\u6a21\u4e3a\u65f6\u7a7a\u56fe\uff0c\u5e76\u5229\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u8bc6\u522b\u901a\u9053\u95f4\u7684\u5173\u7cfb\u548c\u65f6\u95f4\u52a8\u6001\u3002\u8be5\u65b9\u6cd5\u8fd8\u9488\u5bf9\u4f4e\u4fdd\u771f\u5ea6\u8bb0\u5f55\u8fdb\u884c\u4e86\u4fe1\u53f7\u9884\u5904\u7406\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684GAT\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5728Google Colab\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5728RaspberryPi\u8bbe\u5907\u4e0a\u8fdb\u884c\u90e8\u7f72\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u6709\u524d\u666f\u7684\u7ed3\u679c\uff0c\u5176\u51c6\u786e\u6027\u548c\u8de8\u591a \u0938\u0924\u094d\u0930\u7684\u9c81\u68d2\u6027\u5747\u4f18\u4e8e\u57fa\u4e8e\u968f\u673a\u68ee\u6797\u548c\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u6807\u51c6\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u7a81\u51fa\u4e86\u989d\u989e\u533a\u57df\u7684\u7279\u5b9a\u8fde\u63a5\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u5728\u4e3a\u670d\u52a1\u6b20\u7f3a\u5730\u533a\u63d0\u4f9b\u6709\u89c1\u5730\u4e14\u53ef\u6269\u5c55\u7684\u766b\u75eb\u75c5\u8bca\u65ad\u652f\u6301\u7684\u6f5c\u529b\uff0c\u4e3a\u5f00\u53d1\u7ecf\u6d4e\u5b9e\u60e0\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u795e\u7ecf\u8bca\u65ad\u5de5\u5177\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.15253", "categories": ["cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.15253", "abs": "https://arxiv.org/abs/2507.15253", "authors": ["Zhaochen Guo", "Zhixiang Shen", "Xuanting Xie", "Liangjian Wen", "Zhao Kang"], "title": "Disentangling Homophily and Heterophily in Multimodal Graph Clustering", "comment": "Appear in ACM Multimedia 2025", "summary": "Multimodal graphs, which integrate unstructured heterogeneous data with\nstructured interconnections, offer substantial real-world utility but remain\ninsufficiently explored in unsupervised learning. In this work, we initiate the\nstudy of multimodal graph clustering, aiming to bridge this critical gap.\nThrough empirical analysis, we observe that real-world multimodal graphs often\nexhibit hybrid neighborhood patterns, combining both homophilic and\nheterophilic relationships. To address this challenge, we propose a novel\nframework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which\ndecomposes the original hybrid graph into two complementary views: (1) a\nhomophily-enhanced graph that captures cross-modal class consistency, and (2)\nheterophily-aware graphs that preserve modality-specific inter-class\ndistinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism\nthat jointly filters these disentangled graphs through a dual-pass strategy,\nenabling effective multimodal integration while mitigating category confusion.\nOur self-supervised alignment objectives further guide the learning process\nwithout requiring labels. Extensive experiments on both multimodal and\nmulti-relational graph datasets demonstrate that DMGC achieves state-of-the-art\nperformance, highlighting its effectiveness and generalizability across diverse\nsettings. Our code is available at https://github.com/Uncnbb/DMGC.", "AI": {"tldr": "DMGC\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u805a\u7c7b\u591a\u6a21\u6001\u56fe\u3002\u5b83\u901a\u8fc7\u5c06\u56fe\u5206\u89e3\u4e3a\u540c\u8d28\u548c\u5f02\u8d28\u7684\u89c6\u56fe\uff0c\u5e76\u4f7f\u7528\u53cc\u9891\u878d\u5408\u673a\u5236\u6765\u5904\u7406\u6df7\u5408\u90bb\u57df\u6a21\u5f0f\uff0c\u4ece\u800c\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u591a\u6a21\u6001\u56fe\u901a\u5e38\u8868\u73b0\u51fa\u6df7\u5408\u90bb\u57df\u6a21\u5f0f\uff0c\u7ed3\u5408\u4e86\u540c\u8d28\u548c\u5f02\u8d28\u5173\u7cfb\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u5e76\u5f25\u5408\u65e0\u76d1\u7763\u5b66\u4e60\u5728\u591a\u6a21\u6001\u56fe\u805a\u7c7b\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86DMGC\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDMGC\uff08Disentangled Multimodal Graph Clustering\uff09\u7684\u65b0\u9896\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u539f\u59cb\u6df7\u5408\u56fe\u5206\u89e3\u4e3a\u4e24\u4e2a\u4e92\u8865\u7684\u89c6\u56fe\uff1a1. \u589e\u5f3a\u540c\u8d28\u6027\u7684\u56fe\uff0c\u6355\u6349\u8de8\u6a21\u6001\u7c7b\u522b\u4e00\u81f4\u6027\uff1b2. \u4fdd\u6301\u6a21\u6001\u7279\u5b9a\u7c7b\u95f4\u5dee\u5f02\u7684\u5f02\u8d28\u6027\u611f\u77e5\u56fe\u3002\u901a\u8fc7\u201c\u591a\u6a21\u6001\u53cc\u9891\u878d\u5408\u201d\u673a\u5236\uff0c\u91c7\u7528\u53cc\u901a\u9053\u7b56\u7565\u8054\u5408\u8fc7\u6ee4\u8fd9\u4e24\u4e2a\u5206\u89e3\u540e\u7684\u56fe\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684\u6570\u636e\u878d\u5408\uff0c\u540c\u65f6\u51cf\u8f7b\u7c7b\u522b\u6df7\u6dc6\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u81ea\u76d1\u7763\u5bf9\u9f50\u76ee\u6807\u6765\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\uff0c\u65e0\u9700\u6807\u7b7e\u3002", "result": "DMGC\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u591a\u6a21\u6001\u548c\u591a\u5173\u7cfb\u56fe\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u4e86\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "DMGC\u5728\u591a\u6a21\u6001\u548c\u591a\u5173\u7cfb\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5176\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7a81\u663e\u4e86\u5176\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2507.15282", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.15282", "abs": "https://arxiv.org/abs/2507.15282", "authors": ["Aqsa Ashraf Makhdomi", "Iqra Altaf Gillani"], "title": "Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture for Sustainable Urban Food Delivery", "comment": null, "summary": "The rapid proliferation of food delivery platforms has reshaped urban\nmobility but has also contributed significantly to environmental degradation\nthrough increased greenhouse gas emissions. Existing optimization mechanisms\nproduce sub-optimal outcomes as they do not consider environmental\nsustainability their optimization objective. This study proposes a novel\neco-friendly food delivery optimization framework that integrates demand\nprediction, delivery person routing, and order allocation to minimize\nenvironmental impact while maintaining service efficiency. Since recommending\nroutes is NP-Hard, the proposed approach utilizes the submodular and monotone\nproperties of the objective function and designs an efficient greedy\noptimization algorithm. Thereafter, it formulates order allocation problem as a\nnetwork flow optimization model, which, to the best of our knowledge, has not\nbeen explored in the context of food delivery. A three-layered network\narchitecture is designed to match orders with delivery personnel based on\ncapacity constraints and spatial demand. Through this framework, the proposed\napproach reduces the vehicle count, and creates a sustainable food delivery\necosystem.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u73af\u4fdd\u7684\u98df\u54c1\u914d\u9001\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u9700\u6c42\u9884\u6d4b\u3001\u8def\u7ebf\u89c4\u5212\u548c\u8ba2\u5355\u5206\u914d\uff0c\u5e76\u5229\u7528\u8d2a\u5a6a\u7b97\u6cd5\u548c\u7f51\u7edc\u6d41\u6a21\u578b\uff0c\u6210\u529f\u51cf\u5c11\u4e86\u8f66\u8f86\u4f7f\u7528\uff0c\u964d\u4f4e\u4e86\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u670d\u52a1\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u98df\u54c1\u914d\u9001\u5e73\u53f0\u589e\u52a0\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u5bf9\u73af\u5883\u9020\u6210\u7684\u7834\u574f\uff0c\u4ee5\u53ca\u73b0\u6709\u4f18\u5316\u673a\u5236\u672a\u80fd\u5c06\u73af\u5883\u53ef\u6301\u7eed\u6027\u7eb3\u5165\u4f18\u5316\u76ee\u6807\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u73af\u4fdd\u98df\u54c1\u914d\u9001\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u9700\u6c42\u9884\u6d4b\u3001\u914d\u9001\u5458\u8def\u7ebf\u89c4\u5212\u548c\u8ba2\u5355\u5206\u914d\uff0c\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u5e76\u4fdd\u6301\u670d\u52a1\u6548\u7387\u3002\u5229\u7528\u76ee\u6807\u51fd\u6570\u7684\u5b50\u6a21\u6027\u548c\u5355\u8c03\u6027\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8d2a\u5a6a\u4f18\u5316\u7b97\u6cd5\u6765\u89e3\u51b3\u8def\u7ebf\u63a8\u8350\u95ee\u9898\uff0c\u5e76\u5c06\u8ba2\u5355\u5206\u914d\u95ee\u9898\u516c\u5f0f\u5316\u4e3a\u7f51\u7edc\u6d41\u4f18\u5316\u6a21\u578b\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e09\u5c42\u7f51\u7edc\u67b6\u6784\uff0c\u6839\u636e\u5bb9\u91cf\u7ea6\u675f\u548c\u7a7a\u95f4\u9700\u6c42\u5c06\u8ba2\u5355\u4e0e\u914d\u9001\u5458\u8fdb\u884c\u5339\u914d\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7\u51cf\u5c11\u8f66\u8f86\u6570\u91cf\uff0c\u5e76\u521b\u5efa\u53ef\u6301\u7eed\u7684\u98df\u54c1\u914d\u9001\u751f\u6001\u7cfb\u7edf\uff0c\u8fbe\u5230\u4e86\u4f18\u5316\u76ee\u6807\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u51cf\u5c11\u8f66\u8f86\u6570\u91cf\u5e76\u521b\u5efa\u53ef\u6301\u7eed\u7684\u98df\u54c1\u914d\u9001\u751f\u6001\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u73af\u5883\u5f71\u54cd\u6700\u5c0f\u5316\u548c\u6548\u7387\u6700\u5927\u5316\u7684\u76ee\u6807\u3002"}}
{"id": "2507.14709", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "nlin.CD", "physics.app-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.14709", "abs": "https://arxiv.org/abs/2507.14709", "authors": ["San\u00e9 Erasmus", "Charalampos Skokos", "George Kalosakas"], "title": "Temperature Dependent Mechanical and Structural Properties of Uniaxially Strained Planar Graphene", "comment": "18 pages, 11 figures", "summary": "Using molecular dynamics simulations in a planar graphene sheet, we\ninvestigate the temperature dependence of its mechanical behavior under\nuniaxial tensile stress applied either along the armchair or the zigzag\ndirection. Stress-strain curves are calculated for different temperatures and\nthe corresponding dependence of various elastic parameters, like the Young\nmodulus, the third-order elastic modulus, the tensile strength and failure\nstrain, is presented. Fracture stress and strain, as well as the Young modulus,\ndecrease almost linearly with temperature. The distributions of bond lengths\nand bond angles at different strains and temperatures are also discussed and\napproximate analytical expressions are presented. The latter describe\naccurately the numerically obtained distributions.", "AI": {"tldr": "\u7814\u7a76\u4e86\u77f3\u58a8\u70ef\u5728\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u529b\u5b66\u884c\u4e3a\uff0c\u53d1\u73b0\u5176\u529b\u5b66\u6027\u80fd\u968f\u6e29\u5ea6\u5347\u9ad8\u800c\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76\u77f3\u58a8\u70ef\u5728\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u529b\u5b66\u884c\u4e3a", "method": "\u4f7f\u7528\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u7814\u7a76\u4e86\u77f3\u58a8\u70ef\u5728\u5355\u8f74\u62c9\u4f38\u5e94\u529b\u4e0b\u7684\u529b\u5b66\u884c\u4e3a\u53ca\u5176\u5bf9\u6e29\u5ea6\u7684\u4f9d\u8d56\u6027\uff0c\u5e76\u8ba1\u7b97\u4e86\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u5e94\u529b-\u5e94\u53d8\u66f2\u7ebf\u4ee5\u53ca\u6768\u6c0f\u6a21\u91cf\u3001\u4e09\u9636\u5f39\u6027\u6a21\u91cf\u3001\u62c9\u4f38\u5f3a\u5ea6\u548c\u65ad\u88c2\u5e94\u53d8\u7b49\u5f39\u6027\u53c2\u6570\u3002", "result": "\u65ad\u88c2\u5e94\u529b\u548c\u65ad\u88c2\u5e94\u53d8\uff0c\u4ee5\u53ca\u6768\u6c0f\u6a21\u91cf\u968f\u6e29\u5ea6\u5347\u9ad8\u51e0\u4e4e\u5448\u7ebf\u6027\u4e0b\u964d\u3002", "conclusion": "\u5e94\u529b-\u5e94\u53d8\u66f2\u7ebf\u968f\u6e29\u5ea6\u5347\u9ad8\u800c\u964d\u4f4e\uff0c\u952e\u957f\u548c\u952e\u89d2\u5206\u5e03\u6709\u76f8\u5e94\u7684\u5206\u6790"}}
{"id": "2507.15088", "categories": ["cs.RO", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.15088", "abs": "https://arxiv.org/abs/2507.15088", "authors": ["Pouya Panahandeh", "Mohammad Pirani", "Baris Fidan", "Amir Khajepour"], "title": "Search-Based Autonomous Vehicle Motion Planning Using Game Theory", "comment": null, "summary": "In this paper, we propose a search-based interactive motion planning scheme\nfor autonomous vehicles (AVs), using a game-theoretic approach. In contrast to\ntraditional search-based approaches, the newly developed approach considers\nother road users (e.g. drivers and pedestrians) as intelligent agents rather\nthan static obstacles. This leads to the generation of a more realistic path\nfor the AV. Due to the low computational time, the proposed motion planning\nscheme is implementable in real-time applications. The performance of the\ndeveloped motion planning scheme is compared with existing motion planning\ntechniques and validated through experiments using WATonoBus, an electrical\nall-weather autonomous shuttle bus.", "AI": {"tldr": "A game-theoretic approach for autonomous vehicle motion planning that treats other road users as intelligent agents, enabling real-time, realistic path generation validated on an actual autonomous shuttle bus.", "motivation": "To generate a more realistic path for autonomous vehicles (AVs) by considering other road users as intelligent agents rather than static obstacles.", "method": "A search-based interactive motion planning scheme using a game-theoretic approach.", "result": "The performance of the developed motion planning scheme is compared with existing motion planning techniques and validated through experiments using WATonoBus.", "conclusion": "The proposed motion planning scheme is implementable in real-time applications and generates more realistic paths for AVs by considering other road users as intelligent agents."}}
{"id": "2507.14144", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14144", "abs": "https://arxiv.org/abs/2507.14144", "authors": ["Cyril Falcon", "Hassan Mortada", "Math\u00e9o Clavaud", "Jean-Philippe Michel"], "title": "Recursive KalmanNet: Analyse des capacit\u00e9s de g\u00e9n\u00e9ralisation d'un r\u00e9seau de neurones r\u00e9current guid\u00e9 par un filtre de Kalman", "comment": "4 pages, in French language. 4 figures. Accepted for publication in\n  GRETSI 2025 proceedings", "summary": "The Recursive KalmanNet, recently introduced by the authors, is a recurrent\nneural network guided by a Kalman filter, capable of estimating the state\nvariables and error covariance of stochastic dynamic systems from noisy\nmeasurements, without prior knowledge of the noise characteristics. This paper\nexplores its generalization capabilities in out-of-distribution scenarios,\nwhere the temporal dynamics of the test measurements differ from those\nencountered during training.\n  Le Recursive KalmanNet, r\\'ecemment introduit par les auteurs, est un\nr\\'eseau de neurones r\\'ecurrent guid\\'e par un filtre de Kalman, capable\nd'estimer les variables d'\\'etat et la covariance des erreurs des syst\\`emes\ndynamiques stochastiques \\`a partir de mesures bruit\\'ees, sans connaissance\npr\\'ealable des caract\\'eristiques des bruits. Cet article explore ses\ncapacit\\'es de g\\'en\\'eralisation dans des sc\\'enarios hors distribution, o\\`u\nles dynamiques temporelles des mesures de test diff\\`erent de celles\nrencontr\\'ees \\`a l'entra\\^inement.", "AI": {"tldr": "Recursive KalmanNet\u5728\u5904\u7406\u65f6\u95f4\u52a8\u6001\u53d8\u5316\u65f6\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7cfb\u7edf\u7684\u65f6\u95f4\u52a8\u6001\u53ef\u80fd\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u56e0\u6b64\u7814\u7a76\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86Recursive KalmanNet\u5728\u4e0d\u540c\u65f6\u95f4\u52a8\u6001\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "Recursive KalmanNet\u5728\u5904\u7406\u5206\u5e03\u5916\u573a\u666f\u65f6\uff0c\u80fd\u591f\u6709\u6548\u5730\u4f30\u8ba1\u72b6\u6001\u53d8\u91cf\u548c\u8bef\u5dee\u534f\u65b9\u5dee\uff0c\u5373\u4f7f\u5728\u6d4b\u8bd5\u6570\u636e\u7684 temporal dynamics \u4e0e\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u663e\u8457\u5dee\u5f02\u65f6\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0cRecursive KalmanNet\u5728\u5904\u7406\u4e0e\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e0d\u540c\u7684\u65f6\u95f4\u52a8\u6001\u65f6\uff0c\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.15120", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15120", "abs": "https://arxiv.org/abs/2507.15120", "authors": ["Stefan Borgwardt", "Duy Nhu", "Gabriele R\u00f6ger"], "title": "Automated planning with ontologies under coherence update semantics", "comment": null, "summary": "Standard automated planning employs first-order formulas under closed-world\nsemantics to achieve a goal with a given set of actions from an initial state.\nWe follow a line of research that aims to incorporate background knowledge into\nautomated planning problems, for example, by means of ontologies, which are\nusually interpreted under open-world semantics. We present a new approach for\nplanning with DL-Lite ontologies that combines the advantages of ontology-based\naction conditions provided by explicit-input knowledge and action bases (eKABs)\nand ontology-aware action effects under the coherence update semantics. We show\nthat the complexity of the resulting formalism is not higher than that of\nprevious approaches and provide an implementation via a polynomial compilation\ninto classical planning. An evaluation of existing and new benchmarks examines\nthe performance of a planning system on different variants of our compilation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5c06\u672c\u4f53\u77e5\u8bc6\u4e0e\u7ecf\u5178\u89c4\u5212\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e0e\u5148\u524d\u65b9\u6cd5\u76f8\u5f53\u7684\u590d\u6742\u6027\uff0c\u5e76\u901a\u8fc7\u7f16\u8bd1\u548c\u8bc4\u4f30\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u65e8\u5728\u5c06\u672c\u4f53\u7b49\u80cc\u666f\u77e5\u8bc6\u878d\u5165\u81ea\u52a8\u5316\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u672c\u4f53\u7684\u4f18\u70b9\uff08\u5982\u663e\u5f0f\u8f93\u5165\u77e5\u8bc6\u548c\u52a8\u4f5c\u5e93\uff09\u4ee5\u53ca\u672c\u4f53\u611f\u77e5\u52a8\u4f5c\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408eKABs\u548c\u672c\u4f53\u611f\u77e5\u52a8\u4f5c\u6548\u5e94\uff08\u5728\u76f8\u5e72\u66f4\u65b0\u8bed\u4e49\u4e0b\uff09\u7684\u89c4\u5212\u65b0\u65b9\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u89c4\u5212\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u5bf9\u73b0\u6709\u548c\u65b0\u57fa\u51c6\u7684\u8bc4\u4f30\uff0c\u68c0\u9a8c\u4e86\u8be5\u7cfb\u7edf\u5728\u4e0d\u540c\u7f16\u8bd1\u53d8\u4f53\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u672c\u4f53\u77e5\u8bc6\u4e0e\u7ecf\u5178\u89c4\u5212\u76f8\u7ed3\u5408\uff0c\u5176\u590d\u6742\u6027\u4e0d\u9ad8\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u5230\u7ecf\u5178\u89c4\u5212\u8fdb\u884c\u5b9e\u73b0\u3002"}}
{"id": "2507.15233", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.15233", "abs": "https://arxiv.org/abs/2507.15233", "authors": ["Jintao Liu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "title": "An ML-Driven Participant Selection Technique for Federated Recommendation System in Edge-Cloud Computing", "comment": null, "summary": "Recommendation systems (RS) personalize content by analyzing user\npreferences, but typically require centralized collection of user data, raising\nprivacy and scalability concerns. Federated Recommendation Systems (FRS)\naddress these issues by enabling distributed, privacy-preserving model training\nacross edge devices, keeping raw data on-device. Although existing FRS\nframeworks benefit from on-device feature extraction and privacy preservation,\nthey suffer from heterogeneous device capabilities, non-independent and\nidentically distributed (non-IID) data, and communication bottlenecks. To\novercome these limitations, we propose a multi-objective reinforcement learning\n(RL) participant selection that jointly optimizes historical client performance\nreputation (CPR), data utility, and system efficiency. First, we define a\ncomposite client-utility function combining CPR, system capability, and data\nquality. Next, we embed this utility into a multi-armed bandit (MAB) framework\nand dynamically balance exploration-exploitation to select participants.\nFinally, we practically implement our approach using the PySyft framework on an\nedge-cloud testbed, and evaluate it on a multimodal movie-recommendation task\nbuilt from the MovieLens-100K dataset. Across four different skewed\ndata-partition scenarios, our MAB-based selection accelerates convergence by\n32-50% in time-to-target AUC and reduces total wall-clock training time by up\nto 46%, while matching or slightly improving final AUC, NDCG@50, and Recall@50\ncompared to existing FRS baselines. Our results demonstrate that adaptive,\nreward-driven client sampling can substantially enhance both efficiency and\nfairness in real-world federated deployments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u53c2\u4e0e\u8005\u9009\u62e9\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bbe\u5907\u5f02\u6784\u6027\u3001\u6570\u636e\u5206\u5e03\u548c\u901a\u4fe1\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\uff08FRS\uff09\u867d\u7136\u5177\u6709\u8bbe\u5907\u7aef\u7279\u5f81\u63d0\u53d6\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u4f18\u70b9\uff0c\u4f46\u5b58\u5728\u8bbe\u5907\u80fd\u529b\u5f02\u6784\u3001\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u4ee5\u53ca\u901a\u4fe1\u74f6\u9888\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u53c2\u4e0e\u8005\u9009\u62e9\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5386\u53f2\u5ba2\u6237\u6027\u80fd\u58f0\u8a89\uff08CPR\uff09\u3001\u6570\u636e\u6548\u7528\u548c\u7cfb\u7edf\u6548\u7387\u6765\u89e3\u51b3\u5f02\u6784\u8bbe\u5907\u80fd\u529b\u3001\u975eIID\u6570\u636e\u548c\u901a\u4fe1\u74f6\u9888\u95ee\u9898\u3002\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7ed3\u5408CPR\u3001\u7cfb\u7edf\u80fd\u529b\u548c\u6570\u636e\u8d28\u91cf\u7684\u7efc\u5408\u5ba2\u6237\u6548\u7528\u51fd\u6570\u3002\u7136\u540e\u5c06\u8be5\u6548\u7528\u5d4c\u5165\u5230\u591aarmed bandit\uff08MAB\uff09\u6846\u67b6\u4e2d\uff0c\u5e76\u52a8\u6001\u5e73\u8861\u63a2\u7d22-\u5229\u7528\u4ee5\u9009\u62e9\u53c2\u4e0e\u8005\u3002", "result": "\u4e0e\u73b0\u6709\u7684FRS\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684MAB\u65b9\u6cd5\u5728\u76ee\u6807AUC\u6536\u655b\u65f6\u95f4\u548c\u603b\u8bad\u7ec3\u65f6\u95f4\u65b9\u9762\u5206\u522b\u63d0\u9ad8\u4e8632-50%\u548c46%\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u7565\u5fae\u63d0\u9ad8\u4e86\u6700\u7ec8\u7684AUC\u3001NDCG@50\u548cRecall@50\u3002", "conclusion": "\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u53c2\u4e0e\u8005\u9009\u62e9\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5b9e\u9645\u8054\u90a6\u90e8\u7f72\u4e2d\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.14700", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14700", "abs": "https://arxiv.org/abs/2507.14700", "authors": ["Nicholas Mohammad", "Nicola Bezzo"], "title": "Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation", "comment": "To be presented in the 64th IEEE Conference on Decision and Control\n  (CDC 25)", "summary": "Safe navigation in unknown and cluttered environments remains a challenging\nproblem in robotics. Model Predictive Contour Control (MPCC) has shown promise\nfor performant obstacle avoidance by enabling precise and agile trajectory\ntracking, however, existing methods lack formal safety assurances. To address\nthis issue, we propose a general Control Lyapunov Function (CLF) and Control\nBarrier Function (CBF) enabled MPCC framework that enforces safety constraints\nderived from a free-space corridor around the planned trajectory. To enhance\nfeasibility, we dynamically adapt the CBF parameters at runtime using a Soft\nActor-Critic (SAC) policy. The approach is validated with extensive simulations\nand an experiment on mobile robot navigation in unknown cluttered environments.", "AI": {"tldr": "\u5728\u672a\u77e5\u548c\u6df7\u4e71\u7684\u73af\u5883\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCLF\u548cCBF\u7684MPCC\u6846\u67b6\uff0c\u901a\u8fc7SAC\u7b56\u7565\u52a8\u6001\u8c03\u6574CBF\u53c2\u6570\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u578b\u9884\u6d4b\u8f6e\u5ed3\u63a7\u5236\uff08MPCC\uff09\u65b9\u6cd5\u5728\u8fdb\u884c\u673a\u5668\u4eba\u5bfc\u822a\u65f6\u7f3a\u4e4f\u6b63\u5f0f\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u800c\u5728\u672a\u77e5\u548c\u6df7\u4e71\u7684\u73af\u5883\u4e2d\u5b89\u5168\u5bfc\u822a\u662f\u4e00\u4e2a\u6311\u6218\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\uff08CLF\uff09\u548c\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08CBF\uff09\u9a71\u52a8\u7684\u6a21\u578b\u9884\u6d4b\u8f6e\u5ed3\u63a7\u5236\uff08MPCC\uff09\u6846\u67b6\uff0c\u5e76\u4f7f\u7528\u8f6fActor-Critic\uff08SAC\uff09\u7b56\u7565\u52a8\u6001\u8c03\u6574CBF\u53c2\u6570\u4ee5\u589e\u5f3a\u53ef\u884c\u6027\u3002", "result": "\u901a\u8fc7\u5728\u672a\u77e5\u6df7\u4e71\u73af\u5883\u4e2d\u8fdb\u884c\u5927\u91cf\u7684\u6a21\u62df\u548c\u79fb\u52a8\u673a\u5668\u4eba\u5bfc\u822a\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u4f7f\u7528\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\uff08CLF\uff09\u548c\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08CBF\uff09\u6765\u5f3a\u5236\u6267\u884c\u5b89\u5168\u7ea6\u675f\uff0c\u5e76\u4f7f\u7528\u8f6fActor-Critic\uff08SAC\uff09\u7b56\u7565\u52a8\u6001\u8c03\u6574CBF\u53c2\u6570\uff0c\u4ece\u800c\u5728\u672a\u77e5\u548c\u6df7\u4e71\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u79fb\u52a8\u673a\u5668\u4eba\u5bfc\u822a\u3002"}}
{"id": "2507.14449", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14449", "abs": "https://arxiv.org/abs/2507.14449", "authors": ["Zhe Cao", "Jin Zhang", "Ruiheng Zhang"], "title": "IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark", "comment": "11 pages, 7 figures. This paper is accepted by ICCV 2025", "summary": "Real-world infrared imagery presents unique challenges for vision-language\nmodels due to the scarcity of aligned text data and domain-specific\ncharacteristics. Although existing methods have advanced the field, their\nreliance on synthetic infrared images generated through style transfer from\nvisible images, which limits their ability to capture the unique\ncharacteristics of the infrared modality. To address this, we propose IRGPT,\nthe first multi-modal large language model for real-world infrared images,\nbuilt upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K\nauthentic image-text pairs. The proposed IR-TD dataset contains real infrared\nimages paired with meticulously handcrafted texts, where the initial drafts\noriginated from two complementary processes: (1) LLM-generated descriptions of\nvisible images, and (2) rule-based descriptions of annotations. Furthermore, we\nintroduce a bi-cross-modal curriculum transfer learning strategy that\nsystematically transfers knowledge from visible to infrared domains by\nconsidering the difficulty scores of both infrared-visible and infrared-text.\nEvaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT\nachieves state-of-the-art performance even compared with larger-scale models.", "AI": {"tldr": "IRGPT\u662f\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u5927\u89c4\u6a21\u771f\u5b9e\u7ea2\u5916\u6587\u672c\u6570\u636e\u96c6\uff08IR-TD\uff09\u6784\u5efa\u7684\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u7ea2\u5916\u56fe\u50cf\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u4ea4\u53c9\u6a21\u6001\u8bfe\u7a0b\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u8bc6\u522b\u548c\u57fa\u7840\u7b49\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5408\u6210\u6570\u636e\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u7684\u7ea2\u5916\u56fe\u50cf\u7531\u4e8e\u5bf9\u9f50\u6587\u672c\u6570\u636e\u7684\u7a00\u758f\u6027\u548c\u7279\u5b9a\u9886\u57df\u7684\u7279\u6027\uff0c\u7ed9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u4e86\u72ec\u7279\u7684\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4ece\u53ef\u89c1\u56fe\u50cf\u8fdb\u884c\u98ce\u683c\u8f6c\u6362\u751f\u6210\u7684\u5408\u6210\u7ea2\u5916\u56fe\u50cf\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u6355\u6349\u7ea2\u5916\u6a21\u6001\u72ec\u7279\u7279\u6027\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faIRGPT\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u7ea2\u5916\u56fe\u50cf\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5efa\u7acb\u5728\u5177\u6709\u8d85\u8fc7260K\u771f\u5b9e\u56fe\u50cf\u6587\u672c\u5bf9\u7684\u5927\u578b\u7ea2\u5916\u6587\u672c\u6570\u636e\u96c6\uff08IR-TD\uff09\u4e4b\u4e0a\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u4ea4\u53c9\u6a21\u6001\u8bfe\u7a0b\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u8003\u8651\u7ea2\u5916-\u53ef\u89c1\u548c\u7ea2\u5916-\u6587\u672c\u7684\u96be\u5ea6\u5206\u6570\uff0c\u7cfb\u7edf\u5730\u5c06\u77e5\u8bc6\u4ece\u53ef\u89c1\u57df\u8fc1\u79fb\u5230\u7ea2\u5916\u57df\u3002", "result": "IRGPT\u57289\u9879\u4efb\u52a1\uff08\u4f8b\u5982\u8bc6\u522b\u3001\u57fa\u7840\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5373\u4f7f\u4e0e\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u4e5f\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "IRGPT\u57289\u9879\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u4e0e\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u76f8\u6bd4\u4e5f\u662f\u5982\u6b64\u3002"}}
{"id": "2507.14417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14417", "abs": "https://arxiv.org/abs/2507.14417", "authors": ["Aryo Pradipta Gema", "Alexander H\u00e4gele", "Runjin Chen", "Andy Arditi", "Jacob Goldman-Wetzler", "Kit Fraser-Taliente", "Henry Sleight", "Linda Petrini", "Julian Michael", "Beatrice Alex", "Pasquale Minervini", "Yanda Chen", "Joe Benton", "Ethan Perez"], "title": "Inverse Scaling in Test-Time Compute", "comment": null, "summary": "We construct evaluation tasks where extending the reasoning length of Large\nReasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling\nrelationship between test-time compute and accuracy. Our evaluation tasks span\nfour categories: simple counting tasks with distractors, regression tasks with\nspurious features, deduction tasks with constraint tracking, and advanced AI\nrisks. We identify five distinct failure modes when models reason for longer:\n1) Claude models become increasingly distracted by irrelevant information; 2)\nOpenAI o-series models resist distractors but overfit to problem framings; 3)\nmodels shift from reasonable priors to spurious correlations; 4) all models\nshow difficulties in maintaining focus on complex deductive tasks; and 5)\nextended reasoning may amplify concerning behaviors, with Claude Sonnet 4\nshowing increased expressions of self-preservation. These findings suggest that\nwhile test-time compute scaling remains promising for improving model\ncapabilities, it may inadvertently reinforce problematic reasoning patterns.\nOur results demonstrate the importance of evaluating models across diverse\nreasoning lengths to identify and address these failure modes in LRMs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u5904\u7406\u66f4\u957f\u63a8\u7406\u65f6\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u53ef\u80fd\u51fa\u73b0\u591a\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u6613\u53d7\u5e72\u6270\u3001\u8fc7\u62df\u5408\u3001\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027\u3001\u96be\u4ee5\u4fdd\u6301\u4e13\u6ce8\u4ee5\u53ca\u653e\u5927\u4e0d\u826f\u884c\u4e3a\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u4e0d\u540c\u63a8\u7406\u957f\u5ea6\u4e0b\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5f53\u63a8\u7406\u957f\u5ea6\u7684\u589e\u52a0\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff08\u53cd\u5411\u7f29\u653e\uff09\u7684\u73b0\u8c61\uff0c\u65e8\u5728\u8bc6\u522b\u548c\u7406\u89e3\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u8ba1\u6570\u3001\u56de\u5f52\u3001\u6f14\u7ece\u548c\u4eba\u5de5\u667a\u80fd\u98ce\u9669\u7b49\u7c7b\u522b\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u65e8\u5728\u4f7f\u66f4\u957f\u7684\u63a8\u7406\u957f\u5ea6\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4ece\u800c\u63ed\u793a\u63a8\u7406\u957f\u5ea6\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u53cd\u5411\u7f29\u653e\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u4e86\u4e94\u79cd\u4e3b\u8981\u7684\u5931\u8d25\u6a21\u5f0f\uff1a1) \u6a21\u578b\u5bb9\u6613\u88ab\u65e0\u5173\u4fe1\u606f\u5e72\u6270\uff1b2) \u6a21\u578b\u53ef\u80fd\u8fc7\u62df\u5408\u95ee\u9898\u8868\u8ff0\uff1b3) \u6a21\u578b\u53ef\u80fd\u4ece\u5408\u7406\u5148\u9a8c\u8f6c\u5411\u865a\u5047\u76f8\u5173\u6027\uff1b4) \u6a21\u578b\u5728\u4fdd\u6301\u5bf9\u590d\u6742\u6f14\u7ece\u4efb\u52a1\u7684\u5173\u6ce8\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff1b5) \u66f4\u957f\u7684\u63a8\u7406\u53ef\u80fd\u653e\u5927\u6a21\u578b\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u4f8b\u5982\u81ea\u6211\u4fdd\u62a4\u503e\u5411\u3002", "conclusion": "\u6a21\u578b\u5728\u66f4\u957f\u7684\u63a8\u7406\u957f\u5ea6\u4e0b\u4f1a\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u8fd9\u8868\u660e\u5728\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u65f6\uff0c\u8003\u8651\u63a8\u7406\u957f\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u589e\u52a0\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u91cf\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u80fd\u529b\uff0c\u4f46\u5b83\u4e5f\u53ef\u80fd\u52a0\u5267\u4e0d\u826f\u7684\u63a8\u7406\u6a21\u5f0f\u3002"}}
{"id": "2507.14754", "categories": ["cond-mat.mes-hall", "physics.optics", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14754", "abs": "https://arxiv.org/abs/2507.14754", "authors": ["Daigo Oue", "M\u00e1rio G. Silveirinha"], "title": "Fluctuation-induced Hall-like lateral forces in a chiral-gain environment", "comment": null, "summary": "Here, we demonstrate that vacuum fluctuations can induce lateral forces on a\nsmall particle positioned near a translation-invariant uniform non-Hermitian\nsubstrate with chiral gain. This type of non-Hermitian response can be\nengineered by biasing a low-symmetry conductor with a static electric field and\nis rooted in the quantum geometry of the material through the Berry curvature\ndipole. The chiral-gain material acts as an active medium for a particular\ncircular polarisation handedness, while serving as a passive, dissipative\nmedium for the other polarisation handedness. Owing to the nonreciprocity and\ngain characteristics, momentum is continuously exchanged in a preferred\ndirection parallel to the surface between the test particle and the surrounding\nelectromagnetic field, giving rise to lateral forces. Interestingly, the force\ncan be viewed as a fluctuation-induced drag linked to the nonlinear Hall\ncurrent. Indeed, although the gain is driven by an electric current, the\nresulting force acts perpendicular to the bias -- unlike conventional\ncurrent-drag effects. This effect stems from the skewed propagation\ncharacteristics of surface modes and gain-momentum locking. Our theory reveals\na Hall-like asymmetry in the field correlations and establishes a novel link\nbetween quantum geometry and fluctuation-induced phenomena, offering new\npossibilities for nanoscale control via tailored electromagnetic environments.", "AI": {"tldr": "\u771f\u7a7a\u6da8\u843d\u53ef\u8bf1\u5bfc\u9897\u7c92\u6a2a\u5411\u529b\uff0c\u4e0e\u91cf\u5b50\u51e0\u4f55\u548c\u975e\u7ebf\u6027\u970d\u5c14\u7535\u6d41\u76f8\u5173\u3002", "motivation": "\u63a2\u7d22\u771f\u7a7a\u6da8\u843d\u4e0e\u6750\u6599\u7684\u975e\u5384\u7c73\u7279\u6027\uff08\u7279\u522b\u662f\u624b\u6027\u589e\u76ca\uff09\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u4ea7\u751f\u5b8f\u89c2\u6548\u5e94\uff0c\u5982\u9897\u7c92\u7684\u6a2a\u5411\u529b\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5c55\u793a\u4e86\u771f\u7a7a\u6da8\u843d\u5982\u4f55\u901a\u8fc7\u5177\u6709\u624b\u6027\u589e\u76ca\u7684\u975e\u5384\u7c73\u886c\u5e95\u5bf9\u5c0f\u9897\u7c92\u4ea7\u751f\u6a2a\u5411\u529b\uff0c\u5e76\u5c06\u6b64\u6548\u5e94\u4e0e\u91cf\u5b50\u51e0\u4f55\u3001Berry\u66f2\u7387\u5076\u6781\u4ee5\u53ca\u975e\u7ebf\u6027\u970d\u5c14\u7535\u6d41\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u771f\u7a7a\u6da8\u843d\u53ef\u4ee5\u8bf1\u5bfc\u5c0f\u9897\u7c92\u7684\u6a2a\u5411\u529b\uff0c\u8be5\u529b\u4e0e\u6750\u6599\u7684\u91cf\u5b50\u51e0\u4f55\uff08Berry\u66f2\u7387\u5076\u6781\uff09\u548c\u975e\u7ebf\u6027\u970d\u5c14\u7535\u6d41\u76f8\u5173\uff0c\u5373\u4f7f\u589e\u76ca\u7531\u7535\u6d41\u9a71\u52a8\uff0c\u8be5\u529b\u4e5f\u5782\u76f4\u4e8e\u504f\u7f6e\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u771f\u7a7a\u6da8\u843d\u5982\u4f55\u5728\u5177\u6709\u624b\u6027\u589e\u76ca\u7684\u5747\u5300\u975e\u5384\u7c73\u886c\u5e95\u9644\u8fd1\u8bf1\u5bfc\u5c0f\u9897\u7c92\u7684\u6a2a\u5411\u529b\uff0c\u5e76\u5c06\u6b64\u6548\u5e94\u4e0e\u91cf\u5b50\u51e0\u4f55\u548c\u975e\u7ebf\u6027\u970d\u5c14\u7535\u6d41\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7eb3\u7c73\u5c3a\u5ea6\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.14180", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14180", "abs": "https://arxiv.org/abs/2507.14180", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "title": "Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems", "comment": null, "summary": "In line with the AI-native 6G vision, explainability and robustness are\ncrucial for building trust and ensuring reliable performance in millimeter-wave\n(mmWave) systems. Efficient beam alignment is essential for initial access, but\ndeep learning (DL) solutions face challenges, including high data collection\noverhead, hardware constraints, lack of explainability, and susceptibility to\nadversarial attacks. This paper proposes a robust and explainable DL-based beam\nalignment engine (BAE) for mmWave multiple-input multiple output (MIMO)\nsystems. The BAE uses received signal strength indicator (RSSI) measurements\nfrom wide beams to predict the best narrow beam, reducing the overhead of\nexhaustive beam sweeping. To overcome the challenge of real-world data\ncollection, this work leverages a site-specific digital twin (DT) to generate\nsynthetic channel data closely resembling real-world environments. A model\nrefinement via transfer learning is proposed to fine-tune the pre-trained model\nresiding in the DT with minimal real-world data, effectively bridging\nmismatches between the digital replica and real-world environments. To reduce\nbeam training overhead and enhance transparency, the framework uses deep\nShapley additive explanations (SHAP) to rank input features by importance,\nprioritizing key spatial directions and minimizing beam sweeping. It also\nincorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a\ncredibility metric for detecting out-of-distribution inputs and ensuring\nrobust, transparent decision-making. Experimental results show that the\nproposed framework reduces real-world data needs by 70%, beam training overhead\nby 62%, and improves outlier detection robustness by up to 8.5x, achieving\nnear-optimal spectral efficiency and transparent decision making compared to\ntraditional softmax based DL models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6ce2\u675f\u5bf9\u9f50\u5f15\u64ce\uff08BAE\uff09\uff0c\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u3002\u8be5\u5f15\u64ce\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u8fdb\u884c\u6a21\u578b\u4f18\u5316\u3002\u7ed3\u5408\u6df1\u5ea6SHAP\u548cDkNN\u7b97\u6cd5\uff0cBAE\u80fd\u591f\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u51cf\u5c11\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728AI\u539f\u751f6G\u613f\u666f\u4e0b\uff0c\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u5bf9\u4e8e\u6beb\u7c73\u6ce2\uff08mmWave\uff09\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u89e3\u51b3\u65b9\u6848\u5728\u521d\u59cb\u63a5\u5165\u7684\u6ce2\u675f\u5bf9\u9f50\u65b9\u9762\u9762\u4e34\u6570\u636e\u91c7\u96c6\u5f00\u9500\u9ad8\u3001\u786c\u4ef6\u9650\u5236\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u6613\u53d7\u5bf9\u6297\u6027\u653b\u51fb\u7b49\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u3001\u8fc1\u79fb\u5b66\u4e60\u3001\u6df1\u5ea6Shapley\u52a0\u6cd5\u89e3\u91ca\uff08SHAP\uff09\u548c\u6df1\u5ea6k\u8fd1\u90bb\uff08DkNN\uff09\u7b97\u6cd5\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u7684\u6ce2\u675f\u5bf9\u9f50\u3002\u9996\u5148\u5229\u7528\u6570\u5b57\u5b6a\u751f\u751f\u6210\u7ad9\u70b9\u7279\u5b9a\u7684\u5408\u6210\u4fe1\u9053\u6570\u636e\uff0c\u7136\u540e\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u4f18\u5316\u6a21\u578b\uff0c\u5e76\u5229\u7528\u6df1\u5ea6SHAP\u5206\u6790\u7279\u5f81\u91cd\u8981\u6027\u4ee5\u51cf\u5c11\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u548c\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u6700\u540e\u5229\u7528DkNN\u7b97\u6cd5\u63d0\u4f9b\u53ef\u4fe1\u5ea6\u6307\u6807\u4ee5\u68c0\u6d4b\u5206\u5e03\u5916\u8f93\u5165\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5c06\u5b9e\u9645\u6570\u636e\u9700\u6c42\u51cf\u5c11\u4e8670%\uff0c\u5c06\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u51cf\u5c11\u4e8662%\uff0c\u5e76\u5c06\u5f02\u5e38\u503c\u68c0\u6d4b\u9c81\u68d2\u6027\u63d0\u9ad8\u4e86\u9ad8\u8fbe8.5\u500d\uff0c\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8esoftmax\u7684DL\u6a21\u578b\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9891\u8c31\u6548\u7387\u548c\u900f\u660e\u7684\u51b3\u7b56\u5236\u5b9a\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u7684\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6ce2\u675f\u5bf9\u9f50\u5f15\u64ce\uff08BAE\uff09\uff0c\u5229\u7528\u6570\u5b57\u5b6a\u751f\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u8fdb\u884c\u6a21\u578b\u4f18\u5316\uff0c\u7ed3\u5408\u6df1\u5ea6SHAP\u548cDkNN\u7b97\u6cd5\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14514", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14514", "abs": "https://arxiv.org/abs/2507.14514", "authors": ["Yan Gong", "HuiMin Tang", "Yong Yang", "Yoshiyuki Kawazoe"], "title": "Possible Orthorhombic Phase of Ta$_2$O$_5$ under High Pressures", "comment": "30 Pages, 4 Figures, 2 Tables", "summary": "A potential orthorhombic phase of Ta$_2$O$_5$, designated as Y-Ta$_2$O$_5$,\nis predicted under high-pressure conditions through density functional theory\n(DFT) calculations combined with structural search algorithms. This phase,\nconsisting of four formula units per unit cell ($Z = 4$), exhibits the highest\nknown Ta-O coordination numbers. Y-Ta$_2$O$_5$ is found to be the most\nenergetically favorable form of Ta$_2$O$_5$ in the pressure range of\napproximately 70 GPa to at least 200 GPa. Both standard DFT-GGA and\nhigher-accuracy GW calculations reveal that Y-Ta$_2$O$_5$ is a wide bandgap\nsemiconductor with a direct bandgap. Additionally, nuclear quantum effects\n(NQEs) introduce nontrivial corrections to external pressure at fixed volumes,\nunderscoring their significance in high-pressure phase stability analyses.", "AI": {"tldr": "\u5728\u9ad8\u538b\u4e0b\u53d1\u73b0\u4e86\u4e00\u79cd\u65b0\u7684Ta$_{2}$O$_{5}$\u76f8\uff08Y-Ta$_{2}$O$_{5}$\uff09\uff0c\u5b83\u662f\u5bbd\u5e26\u9699\u534a\u5bfc\u4f53\uff0c\u5e76\u4e14\u5728\u9ad8\u538b\u4e0b\u6bd4\u5176\u4ed6\u76f8\u66f4\u7a33\u5b9a\u3002", "motivation": "\u5728\u9ad8\u538b\u6761\u4ef6\u4e0b\u9884\u6d4bTa$_{2}$O$_{5}$\u7684\u65b0\u76f8\u3002", "method": "\u5229\u7528\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u7ed3\u5408\u7ed3\u6784\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u8ba1\u7b97\u3002", "result": "\u9884\u6d4b\u5f97\u5230Y-Ta$_{2}$O$_{5}$\uff0c\u4e00\u79cd\u5177\u6709\u6700\u9ad8Ta-O\u914d\u4f4d\u6570\u7684\u659c\u65b9\u6676\u76f8\uff0c\u572870-200 GPa\u8303\u56f4\u5185\u662f\u6700\u7a33\u5b9a\u7684\u76f8\u3002\u8be5\u76f8\u662f\u5bbd\u5e26\u9699\u534a\u5bfc\u4f53\uff0c\u5177\u6709\u76f4\u63a5\u5e26\u9699\u3002\u6838\u91cf\u5b50\u6548\u5e94\u5728\u9ad8\u538b\u76f8\u7a33\u5b9a\u6027\u5206\u6790\u4e2d\u5f88\u91cd\u8981\u3002", "conclusion": "DFT\u8ba1\u7b97\u7ed3\u5408\u7ed3\u6784\u641c\u7d22\u7b97\u6cd5\u9884\u6d4b\u4e86\u5728\u9ad8\u538b\u6761\u4ef6\u4e0b\u53ef\u80fd\u5b58\u5728\u7684Ta$_{2}$O$_{5}$\u659c\u65b9\u6676\u76f8\uff08Y-Ta$_{2}$O$_{5}$\uff09\u3002\u8be5\u76f8\u5177\u6709\u6700\u9ad8\u7684\u5df2\u77e5Ta-O\u914d\u4f4d\u6570\uff0c\u572870 GPa\u81f3\u81f3\u5c11200 GPa\u7684\u538b\u529b\u8303\u56f4\u5185\u662f\u6700\u6709\u5229\u7684Ta$_{2}$O$_{5}$\u5f62\u5f0f\u3002Y-Ta$_{2}$O$_{5}$\u662f\u5bbd\u5e26\u9699\u534a\u5bfc\u4f53\uff0c\u5177\u6709\u76f4\u63a5\u5e26\u9699\u3002\u6838\u91cf\u5b50\u6548\u5e94\uff08NQEs\uff09\u5bf9\u56fa\u5b9a\u4f53\u79ef\u4e0b\u7684\u5916\u538b\u6709\u663e\u8457\u5f71\u54cd\uff0c\u8868\u660e\u4e86\u5176\u5728\u9ad8\u538b\u76f8\u7a33\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.14728", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14728", "abs": "https://arxiv.org/abs/2507.14728", "authors": ["Maryam Salamatmoghadasi", "Metin Ozturk", "Halim Yanikomeroglu"], "title": "Enhancing Sustainability in HAPS-Assisted 6G Networks: Load Estimation Aware Cell Switching", "comment": "6 pages, 5 figures, PIMRC", "summary": "This study introduces and addresses the critical challenge of traffic load\nestimation in cell switching within vertical heterogeneous networks. The\neffectiveness of cell switching is significantly limited by the lack of\naccurate traffic load data for small base stations (SBSs) in sleep mode, making\nmany load-dependent energy-saving approaches impractical, as they assume\nperfect knowledge of traffic loads, an assumption that is unrealistic when SBSs\nare inactive. In other words, when SBSs are in sleep mode, their traffic loads\ncannot be directly known and can only be estimated, inevitably with\ncorresponding errors. Rather than proposing a new switching algorithm, we focus\non eliminating this foundational barrier by exploring effective prediction\ntechniques. A novel vertical heterogeneous network model is considered,\nintegrating a high-altitude platform station (HAPS) as a super macro base\nstation (SMBS). We investigate both spatial and temporal load estimation\napproaches, including three spatial interpolation schemes, random neighboring\nselection, distance based selection, and multi level clustering (MLC),\nalongside a temporal deep learning method based on long short-term memory\n(LSTM) networks. Using a real world dataset for empirical validation, our\nresults show that both spatial and temporal methods significantly improve\nestimation accuracy, with the MLC and LSTM approaches demonstrating\nparticularly strong performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7MLC\u548cLSTM\u7b49\u65b9\u6cd5\u6539\u8fdb\u4e86\u5f02\u6784\u7f51\u7edc\u4e2d\u7761\u7720\u6a21\u5f0f\u57fa\u7ad9\u7684\u6d41\u91cf\u8d1f\u8f7d\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u89e3\u51b3\u5782\u76f4\u5f02\u6784\u7f51\u7edc\u4e2d\u8702\u7a9d\u5207\u6362\u7684\u6d41\u91cf\u8d1f\u8f7d\u4f30\u8ba1\u6311\u6218\uff0c\u7279\u522b\u662f\u4f4e\u7761\u7720\u6a21\u5f0f\u4e0b\u5c0f\u578b\u57fa\u7ad9\uff08SBS\uff09\u7f3a\u4e4f\u51c6\u786e\u6d41\u91cf\u6570\u636e\u7684\u95ee\u9898\uff0c\u8fd9\u4f7f\u5f97\u8bb8\u591a\u4f9d\u8d56\u8d1f\u8f7d\u7684\u8282\u80fd\u65b9\u6cd5\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u7814\u7a76\u4e86\u4e09\u79cd\u7a7a\u95f4\u63d2\u503c\u65b9\u6848\uff08\u968f\u673a\u90bb\u57df\u9009\u62e9\u3001\u57fa\u4e8e\u8ddd\u79bb\u7684\u9009\u62e9\u548c\u591a\u5c42\u805a\u7c7b\uff08MLC\uff09\uff09\u4ee5\u53ca\u4e00\u79cd\u57fa\u4e8e\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7f51\u7edc\u7684\u6df1\u5ea6\u5b66\u4e60\u65f6\u95f4\u65b9\u6cd5\u3002", "result": "\u7a7a\u95f4\u548c\u65f6\u95f4\u65b9\u6cd5\u5747\u663e\u8457\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u5176\u4e2dMLC\u548cLSTM\u65b9\u6cd5\u8868\u73b0\u51fa\u7279\u522b\u5f3a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7a7a\u95f4\u548c\u65f6\u95f4\u65b9\u6cd5\u6539\u8fdb\u4e86\u8702\u7a9d\u5207\u6362\u4e2d\u7684\u6d41\u91cf\u8d1f\u8f7d\u4f30\u8ba1\uff0c\u5176\u4e2d\u591a\u5c42\u805a\u7c7b\uff08MLC\uff09\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7f51\u7edc\u8868\u73b0\u51fa\u7279\u522b\u5f3a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14427", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14427", "abs": "https://arxiv.org/abs/2507.14427", "authors": ["Jeffrey H. Shapiro", "Clark Embleton", "Michael G. Raymer", "Brian J. Smith"], "title": "High-fidelity, quasi-deterministic entanglement generation using phase-matched spectral islands in a zero-added-loss multiplexing architecture", "comment": "18 pages, 10 figures", "summary": "While photonic entanglement generation and distribution are well developed,\ntheir demonstrated rates are far below what is needed for a quantum internet.\nThe present paper proposes and analyzes a scheme for spectral multiplexing that\nprovides entanglement-distribution rates well in excess of the state of the\nart. It builds on the idea presented by Chen~\\emph{et al}.~[Phys. Rev. Appl.\n{\\bf 19}, 054209 (2023)], who proposed zero-added-loss multiplexing (ZALM) as a\nmeans for high-fidelity, quasi-deterministic entanglement generation.\nUnfortunately, Chen \\emph{et al}.'s ZALM requires a large number (800) of\nspectral channels to achieve its claimed high-fidelity, quasi-deterministic,\nhigh-rate entanglement generation. Our modified version of ZALM affords major\nperformance improvements over the original. It draws on Morrison~\\emph{et\nal}.~[APL Photon. {\\bf 7}, 066102 (2022)], who domain engineered a $\\chi^{(2)}$\ncrystal to realize a biphoton wave function with 8 discrete and\nspectrally-factorable frequency bins. Our ZALM SPDCs each have a modest number\n($N_I\\ll$ 800) of these phase-matched spectral islands each generating two-mode\nsqueezed-vacuum states, permitting our analysis, unlike Chen~\\emph{et al.}'s,\nto account for multipairs of all orders, losses in the partial BSM, and\npropagation losses en route to the receivers. A major innovation in our\nproposal is to employ both same-island heralding and cross-island heralding,\nwhich allows the entanglement-delivery rate to scale as $N_I^2$ rather than\n$N_I$ in the weak squeezing regime required for the reception of photon pairs\nwith a high Bell-state fidelity under realistic losses. This heralding scheme\nuses an order of magnitude fewer spectral channels, which may enable near-term\nimplementations of satellite-to-ground or fiber-optic based ZALM architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684ZALM\u65b9\u6848\uff0c\u5229\u7528\u591a\u9891\u6bb5\u805a\u5408\u548c\u8003\u8651\u635f\u8017\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u7ea0\u7f20\u5206\u53d1\u901f\u7387\uff0c\u5e76\u51cf\u5c11\u4e86\u6240\u9700\u9891\u8c31\u901a\u9053\u6570\uff0c\u4e3a\u5b9e\u73b0\u91cf\u5b50\u4e92\u8054\u7f51\u94fa\u5e73\u4e86\u9053\u8def\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u91cf\u5b50\u4e92\u8054\u7f51\u6240\u9700\u7684\u7ea0\u7f20\u5206\u53d1\u901f\u7387\u8fdc\u4f4e\u4e8e\u5b9e\u9645\u9700\u6c42\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u7ea0\u7f20\u5206\u53d1\u901f\u7387\u7684\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6539\u8fdb\u96f6\u9644\u52a0\u635f\u8017\u590d\u7528\uff08ZALM\uff09\u65b9\u6848\uff0c\u5229\u7528 Morrison \u7b49\u4eba\u63d0\u51fa\u7684\u57df\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5728 $\\chi^{(2)}$ \u6676\u4f53\u4e2d\u5b9e\u73b0\u4e86\u5177\u6709 8 \u4e2a\u79bb\u6563\u4e14\u5149\u8c31\u53ef\u5206\u79bb\u9891\u6bb5\u7684\u53cc\u5149\u5b50\u6ce2\u51fd\u6570\u3002\u901a\u8fc7\u91c7\u7528\u540c\u4e00\u9891\u6bb5\u548c\u4e0d\u540c\u9891\u6bb5\u7684\u4fe1\u53f7\u805a\u5408\uff08heralding\uff09\u673a\u5236\uff0c\u4f7f\u5f97\u7ea0\u7f20\u5206\u53d1\u901f\u7387\u4e0e\u9891\u6bb5\u6570\u91cf $N_I$ \u7684\u5e73\u65b9\u6210\u6b63\u6bd4\uff08\u5728\u5f31\u538b\u7f29\u60c5\u51b5\u4e0b\uff09\uff0c\u76f8\u6bd4\u4e8e\u539f\u59cbZALM\u65b9\u6848\uff08\u4e0e $N_I$ \u6210\u6b63\u6bd4\uff09\u6709\u4e86\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8003\u8651\u591a\u5bf9\u3001\u90e8\u5206\u57fa\u7ad9\u4e4b\u95f4\u6d4b\u91cf\uff08BSM\uff09\u7684\u635f\u8017\u4ee5\u53ca\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u7684\u635f\u8017\u3002", "result": "\u6240\u63d0\u51fa\u7684ZALM\u65b9\u6848\u901a\u8fc7\u5229\u7528\u540c\u4e00\u9891\u6bb5\u548c\u4e0d\u540c\u9891\u6bb5\u7684\u4fe1\u53f7\u805a\u5408\uff0c\u4f7f\u7ea0\u7f20\u5206\u53d1\u901f\u7387\u5728\u5f31\u538b\u7f29\u60c5\u51b5\u4e0b\u53ef\u6269\u5c55\u81f3 $N_I^2$\uff0c\u800c\u539f\u59cb\u65b9\u6848\u4ec5\u4e3a $N_I$\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6848\u6240\u9700\u7684\u9891\u8c31\u901a\u9053\u6570\u91cf\u5927\u5927\u51cf\u5c11\uff08$N_I \\ll 800$\uff09\uff0c\u5e76\u80fd\u66f4\u5168\u9762\u5730\u8003\u8651\u5404\u79cd\u635f\u8017\u56e0\u7d20\uff0c\u6709\u671b\u5b9e\u73b0\u8fd1\u671f\u7684\u661f\u5730\u6216\u5149\u7ea4ZALM\u67b6\u6784\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u6539\u8fdb\u578b\u96f6\u9644\u52a0\u635f\u8017\u590d\u7528\uff08ZALM\uff09\u65b9\u6848\uff0c\u901a\u8fc7\u5229\u7528\u540c\u4e00\u9891\u6bb5\u548c\u4e0d\u540c\u9891\u6bb5\u7684\u4fe1\u53f7\u805a\u5408\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u9ad8\u7684\u7ea0\u7f20\u5206\u53d1\u901f\u7387\uff0c\u5e76\u4e14\u6240\u9700\u7684\u9891\u8c31\u901a\u9053\u6570\u91cf\u5927\u5927\u51cf\u5c11\uff0c\u6709\u671b\u5b9e\u73b0\u8fd1\u671f\u7684\u661f\u5730\u6216\u5149\u7ea4ZALM\u67b6\u6784\u3002"}}
{"id": "2507.14241", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14241", "abs": "https://arxiv.org/abs/2507.14241", "authors": ["Rithesh Murthy", "Ming Zhu", "Liangwei Yang", "Jielin Qiu", "Juntao Tan", "Shelby Heinecke", "Huan Wang", "Caiming Xiong", "Silvio Savarese"], "title": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) perform best with well-crafted prompts, yet\nprompt engineering remains manual, inconsistent, and inaccessible to\nnon-experts. We introduce Promptomatix, an automatic prompt optimization\nframework that transforms natural language task descriptions into high-quality\nprompts without requiring manual tuning or domain expertise. Promptomatix\nsupports both a lightweight meta-prompt-based optimizer and a DSPy-powered\ncompiler, with modular design enabling future extension to more advanced\nframeworks. The system analyzes user intent, generates synthetic training data,\nselects prompting strategies, and refines prompts using cost-aware objectives.\nEvaluated across 5 task categories, Promptomatix achieves competitive or\nsuperior performance compared to existing libraries, while reducing prompt\nlength and computational overhead making prompt optimization scalable and\nefficient.", "AI": {"tldr": "Promptomatix \u662f\u4e00\u4e2a\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u53ef\u4ee5\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u9ad8\u8d28\u91cf\u7684\u63d0\u793a\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e76\u4e14\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002", "motivation": "\u63d0\u793a\u5de5\u7a0b\u867d\u7136\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4ecd\u662f\u624b\u52a8\u3001\u4e0d\u4e00\u81f4\u4e14\u975e\u4e13\u4e1a\u4eba\u58eb\u96be\u4ee5\u4f7f\u7528\u7684\u3002Promptomatix \u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u75db\u70b9\uff0c\u63d0\u4f9b\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "Promptomatix \u662f\u4e00\u4e2a\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u7528\u6237\u610f\u56fe\u3001\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3001\u9009\u62e9\u63d0\u793a\u7b56\u7565\u4ee5\u53ca\u4f7f\u7528\u6210\u672c\u611f\u77e5\u76ee\u6807\u6765\u4f18\u5316\u63d0\u793a\u3002\u5b83\u652f\u6301\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u5143\u63d0\u793a\u7684\u4f18\u5316\u5668\u548c\u57fa\u4e8e DSPy \u7684\u7f16\u8bd1\u5668\uff0c\u5e76\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\u3002", "result": "Promptomatix \u5728 5 \u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5176\u6027\u80fd\u4e0e\u73b0\u6709\u5e93\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\u8d8a\uff0c\u540c\u65f6\u63d0\u793a\u957f\u5ea6\u548c\u8ba1\u7b97\u5f00\u9500\u4e5f\u5f97\u5230\u51cf\u5c11\u3002", "conclusion": "Promptomatix \u6846\u67b6\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u7684\u63d0\u793a\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e76\u5728 5 \u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8fd8\u51cf\u5c11\u4e86\u63d0\u793a\u957f\u5ea6\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u4f7f\u5f97\u63d0\u793a\u4f18\u5316\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2507.15132", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.15132", "abs": "https://arxiv.org/abs/2507.15132", "authors": ["Joanna Komorniczak"], "title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm", "comment": null, "summary": "The research community continues to seek increasingly more advanced synthetic\ndata generators to reliably evaluate the strengths and limitations of machine\nlearning methods. This work aims to increase the availability of datasets\nencompassing a diverse range of problem complexities by proposing a genetic\nalgorithm that optimizes a set of problem complexity measures for\nclassification and regression tasks towards specific targets. For\nclassification, a set of 10 complexity measures was used, while for regression\ntasks, 4 measures demonstrating promising optimization capabilities were\nselected. Experiments confirmed that the proposed genetic algorithm can\ngenerate datasets with varying levels of difficulty by transforming\nsynthetically created datasets to achieve target complexity values through\nlinear feature projections. Evaluations involving state-of-the-art classifiers\nand regressors revealed a correlation between the complexity of the generated\ndata and the recognition quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9057\u4f20\u7b97\u6cd5\uff0c\u53ef\u4ee5\u751f\u6210\u5177\u6709\u53ef\u8c03\u590d\u6742\u6027\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u4ee5\u5e2e\u52a9\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u53ef\u9760\u5730\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u7814\u7a76\u793e\u533a\u4e00\u76f4\u5728\u5bfb\u6c42\u66f4\u5148\u8fdb\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5668\uff0c\u65e8\u5728\u589e\u52a0\u5305\u542b\u5404\u79cd\u95ee\u9898\u590d\u6742\u6027\u6570\u636e\u96c6\u7684\u53ef\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9057\u4f20\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u7ebf\u6027\u7279\u5f81\u6295\u5f71\u6765\u4f18\u5316\u4e00\u7cfb\u5217\u7528\u4e8e\u5206\u7c7b\uff0810\u4e2a\u5ea6\u91cf\uff09\u548c\u56de\u5f52\uff084\u4e2a\u5ea6\u91cf\uff09\u4efb\u52a1\u7684\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u4ee5\u5b9e\u73b0\u76ee\u6807\u590d\u6742\u6027\u503c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u6240\u63d0\u51fa\u7684\u9057\u4f20\u7b97\u6cd5\u53ef\u4ee5\u901a\u8fc7\u7ebf\u6027\u7279\u5f81\u6295\u5f71\u5c06\u5408\u6210\u521b\u5efa\u7684\u6570\u636e\u96c6\u8f6c\u6362\u4e3a\u76ee\u6807\u590d\u6742\u6027\u503c\uff0c\u4ece\u800c\u751f\u6210\u4e0d\u540c\u96be\u5ea6\u7684\u00a1\u6570\u636e\u96c6\u3002\u5bf9\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\u548c\u56de\u5f52\u5668\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u751f\u6210\u6570\u636e\u7684\u590d\u6742\u6027\u4e0e\u8bc6\u522b\u8d28\u91cf\u4e4b\u95f4\u5b58\u5728\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9057\u4f20\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u4e00\u7cfb\u5217\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u7684\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u751f\u6210\u5177\u6709\u4e0d\u540c\u96be\u5ea6\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bc1\u5b9e\u4e86\u751f\u6210\u6570\u636e\u7684\u590d\u6742\u6027\u4e0e\u8bc6\u522b\u8d28\u91cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002"}}
{"id": "2507.15600", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.15600", "abs": "https://arxiv.org/abs/2507.15600", "authors": ["Armin Pournaki"], "title": "Conflicting narratives and polarization on social media", "comment": "30 pages, 7 figures", "summary": "Narratives are key interpretative devices by which humans make sense of\npolitical reality. In this work, we show how the analysis of conflicting\nnarratives, i.e. conflicting interpretive lenses through which political\nreality is experienced and told, provides insight into the discursive\nmechanisms of polarization and issue alignment in the public sphere. Building\nupon previous work that has identified ideologically polarized issues in the\nGerman Twittersphere between 2021 and 2023, we analyze the discursive dimension\nof polarization by extracting textual signals of conflicting narratives from\ntweets of opposing opinion groups. Focusing on a selection of salient issues\nand events (the war in Ukraine, Covid, climate change), we show evidence for\nconflicting narratives along two dimensions: (i) different attributions of\nactantial roles to the same set of actants (e.g. diverging interpretations of\nthe role of NATO in the war in Ukraine), and (ii) emplotment of different\nactants for the same event (e.g. Bill Gates in the right-leaning Covid\nnarrative). Furthermore, we provide first evidence for patterns of narrative\nalignment, a discursive strategy that political actors employ to align opinions\nacross issues. These findings demonstrate the use of narratives as an\nanalytical lens into the discursive mechanisms of polarization.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u5fb7\u56fd\u63a8\u7279\u5e73\u53f0\u4e0a\u5173\u4e8e\u4e4c\u514b\u5170\u6218\u4e89\u3001\u65b0\u51a0\u75ab\u60c5\u548c\u6c14\u5019\u53d8\u5316\u7b49\u8bae\u9898\u7684\u51b2\u7a81\u53d9\u4e8b\uff0c\u63ed\u793a\u4e86\u8bdd\u8bed\u4e24\u6781\u5206\u5316\u548c\u8bae\u9898\u4e00\u81f4\u6027\u7684\u673a\u5236\u3002", "motivation": "\u5728\u653f\u6cbb\u73b0\u5b9e\u4e2d\uff0c\u53d9\u4e8b\u662f\u4eba\u7c7b\u7406\u89e3\u7684\u5173\u952e\u89e3\u91ca\u5de5\u5177\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u51b2\u7a81\u53d9\u4e8b\u5982\u4f55\u63ed\u793a\u4e24\u6781\u5206\u5316\u548c\u8bae\u9898\u4e00\u81f4\u6027\u7684\u673a\u5236\u3002", "method": "\u901a\u8fc7\u63d0\u53d6\u63a8\u7279\u6587\u672c\u4e2d\u51b2\u7a81\u53d9\u4e8b\u7684\u4fe1\u53f7\uff0c\u5206\u6790\u4e86\u4e4c\u514b\u5170\u6218\u4e89\u3001\u65b0\u51a0\u75ab\u60c5\u548c\u6c14\u5019\u53d8\u5316\u7b49\u7126\u70b9\u8bae\u9898\u548c\u4e8b\u4ef6\u4e2d\u7684\u8bdd\u8bed\u4e24\u6781\u5206\u5316\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u884c\u52a8\u8005\u89d2\u8272\u7684\u5f52\u5c5e\u51b2\u7a81\u548c\u4e8b\u4ef6\u7684\u53d9\u4e8b\u51b2\u7a81\u4e24\u4e2a\u7ef4\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6d89\u53ca\u4e4c\u514b\u5170\u6218\u4e89\u3001\u65b0\u51a0\u75ab\u60c5\u548c\u6c14\u5019\u53d8\u5316\u7b49\u8bae\u9898\u65f6\uff0c\u5b58\u5728\u4e24\u79cd\u51b2\u7a81\u53d9\u4e8b\uff1a\u4e00\u662f\u884c\u52a8\u8005\u89d2\u8272\u7684\u5f52\u5c5e\u51b2\u7a81\uff0c\u4e8c\u662f\u4e8b\u4ef6\u7684\u53d9\u4e8b\u51b2\u7a81\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u653f\u6cbb\u884c\u52a8\u8005\u7528\u4e8e\u8de8\u8bae\u9898\u7edf\u4e00\u610f\u89c1\u7684\u53d9\u4e8b\u4e00\u81f4\u6027\u6a21\u5f0f\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5206\u6790\u51b2\u7a81\u53d9\u4e8b\u5982\u4f55\u63ed\u793a\u516c\u4f17\u9886\u57df\u4e2d\u4e24\u6781\u5206\u5316\u548c\u8bae\u9898\u4e00\u81f4\u6027\u7684\u8bdd\u8bed\u673a\u5236\uff0c\u5e76\u4e3a\u653f\u6cbb\u884c\u52a8\u8005\u8de8\u8bae\u9898\u7edf\u4e00\u610f\u89c1\u7684\u53d9\u4e8b\u7b56\u7565\u63d0\u4f9b\u4e86\u521d\u6b65\u8bc1\u636e\u3002"}}
{"id": "2507.15319", "categories": ["cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15319", "abs": "https://arxiv.org/abs/2507.15319", "authors": ["Yannan Bai", "Debmalya Panigrahi", "Ian Zhang"], "title": "Language Generation in the Limit: Noise, Loss, and Feedback", "comment": null, "summary": "Kleinberg and Mullainathan (2024) recently proposed a formal framework called\nlanguage generation in the limit and showed that given a sequence of example\nstrings from an unknown target language drawn from any countable collection, an\nalgorithm can correctly generate unseen strings from the target language within\nfinite time. This notion was further refined by Li, Raman, and Tewari (2024),\nwho defined stricter categories of non-uniform and uniform generation. They\nshowed that a finite union of uniformly generatable collections is generatable\nin the limit, and asked if the same is true for non-uniform generation.\n  We begin by resolving the question in the negative: we give a uniformly\ngeneratable collection and a non-uniformly generatable collection whose union\nis not generatable in the limit. We then use facets of this construction to\nfurther our understanding of several variants of language generation. The first\ntwo, generation with noise and without samples, were introduced by Raman and\nRaman (2025) and Li, Raman, and Tewari (2024) respectively. We show the\nequivalence of these models for uniform and non-uniform generation, and provide\na characterization of non-uniform noisy generation. The former paper asked if\nthere is any separation between noisy and non-noisy generation in the limit --\nwe show that such a separation exists even with a single noisy string. Finally,\nwe study the framework of generation with feedback, introduced by Charikar and\nPabbaraju (2025), where the algorithm is strengthened by allowing it to ask\nmembership queries. We show finite queries add no power, but infinite queries\nyield a strictly more powerful model.\n  In summary, the results in this paper resolve the union-closedness of\nlanguage generation in the limit, and leverage those techniques (and others) to\ngive precise characterizations for natural variants that incorporate noise,\nloss, and feedback.", "AI": {"tldr": "\u8be5\u8bba\u6587\u89e3\u51b3\u4e86\u8bed\u8a00\u751f\u6210\u5728\u6781\u9650\u4e0b\u7684\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u5305\u542b\u566a\u58f0\u3001\u635f\u5931\u548c\u53cd\u9988\u7684\u53d8\u4f53\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u8868\u5f81\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8bed\u8a00\u751f\u6210\u5728\u6781\u9650\u4e0b\u7684\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u548c\u8868\u5f81\u5305\u542b\u566a\u58f0\u3001\u635f\u5931\u548c\u53cd\u9988\u7684\u8bed\u8a00\u751f\u6210\u6a21\u578b\u7684\u53d8\u4f53\u3002", "method": "\u901a\u8fc7\u6784\u9020\u4e00\u4e2a\u53ef\u7edf\u4e00\u751f\u6210\u548c\u4e0d\u53ef\u5747\u5300\u751f\u6210\u4f46\u5176\u5e76\u96c6\u4e0d\u53ef\u5728\u6781\u9650\u4e0b\u751f\u6210\u7684\u96c6\u5408\uff0c\u6765\u89e3\u51b3\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\u3002\u5e76\u7814\u7a76\u4e86\u5e26\u566a\u58f0\u3001\u65e0\u6837\u672c\u548c\u5e26\u53cd\u9988\u7684\u8bed\u8a00\u751f\u6210\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u975e\u5747\u5300\u566a\u58f0\u751f\u6210\u7684\u7279\u5f81\u3002", "result": "1. \u8bc1\u660e\u4e86\u53ef\u5747\u5300\u751f\u6210\u96c6\u5408\u7684\u5e76\u96c6\u4e0d\u4e00\u5b9a\u662f\u53ef\u751f\u6210\u6781\u9650\u7684\u30022. \u8bc1\u660e\u4e86\u5e26\u566a\u58f0\u548c\u65e0\u6837\u672c\u7684\u751f\u6210\u6a21\u578b\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u751f\u6210\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u975e\u5747\u5300\u566a\u58f0\u751f\u6210\u7684\u7279\u5f81\u30023. \u8bc1\u660e\u4e86\u5728\u6781\u9650\u4e0b\u7684\u566a\u58f0\u751f\u6210\u548c\u975e\u566a\u58f0\u751f\u6210\u4e4b\u95f4\u5b58\u5728\u5206\u79bb\uff0c\u5373\u4f7f\u53ea\u6709\u4e00\u4e2a\u566a\u58f0\u5b57\u7b26\u4e32\u30024. \u8bc1\u660e\u4e86\u6709\u9650\u67e5\u8be2\u5728\u5e26\u53cd\u9988\u7684\u751f\u6210\u6a21\u578b\u4e2d\u6ca1\u6709\u589e\u52a0\u80fd\u529b\uff0c\u800c\u65e0\u9650\u67e5\u8be2\u5219\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u8bba\u6587\u89e3\u51b3\u4e86\u8bed\u8a00\u751f\u6210\u5728\u6781\u9650\u4e0b\u7684\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u6280\u672f\uff08\u4ee5\u53ca\u5176\u4ed6\u6280\u672f\uff09\u4e3a\u5305\u542b\u566a\u58f0\u3001\u635f\u5931\u548c\u53cd\u9988\u7684\u81ea\u7136\u53d8\u4f53\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u8868\u5f81\u3002"}}
{"id": "2507.15158", "categories": ["cs.LG", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.15158", "abs": "https://arxiv.org/abs/2507.15158", "authors": ["A. H. Abbas", "Hend Abdel-Ghani", "Ivan S. Maksymov"], "title": "Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition", "comment": null, "summary": "As artificial intelligence continues to push into real-time, edge-based and\nresource-constrained environments, there is an urgent need for novel,\nhardware-efficient computational models. In this study, we present and validate\na neuromorphic computing architecture based on resonant-tunnelling diodes\n(RTDs), which exhibit the nonlinear characteristics ideal for physical\nreservoir computing (RC). We theoretically formulate and numerically implement\nan RTD-based RC system and demonstrate its effectiveness on two image\nrecognition benchmarks: handwritten digit classification and object recognition\nusing the Fruit~360 dataset. Our results show that this circuit-level\narchitecture delivers promising performance while adhering to the principles of\nnext-generation RC -- eliminating random connectivity in favour of a\ndeterministic nonlinear transformation of input signals.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c10\u632f\u96a7\u9053\u4e8c\u6781\u7ba1\uff08RTD\uff09\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u56fe\u50cf\u8bc6\u522b\uff0c\u6d88\u9664\u4e86\u5bf9\u968f\u673a\u8fde\u63a5\u7684\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6301\u7eed\u8fdb\u5165\u5b9e\u65f6\u3001\u8fb9\u7f18\u548c\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff0c\u8feb\u5207\u9700\u8981\u65b0\u9896\u3001\u786c\u4ef6\u9ad8\u6548\u7684\u8ba1\u7b97\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c10\u632f\u96a7\u9053\u4e8c\u6781\u7ba1\uff08RTD\uff09\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\uff0c\u8be5\u4e8c\u6781\u7ba1\u8868\u73b0\u51fa\u7406\u60f3\u7684\u975e\u7ebf\u6027\u7279\u6027\uff0c\u9002\u7528\u4e8e\u7269\u7406\u6c34\u5e93\u8ba1\u7b97\uff08RC\uff09\u3002\u7406\u8bba\u4e0a\u516c\u5f0f\u5316\u5e76\u4ee5\u6570\u503c\u65b9\u5f0f\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eRTD\u7684RC\u7cfb\u7edf\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7535\u8def\u7ea7\u67b6\u6784\u5728\u624b\u5199\u6570\u5b57\u5206\u7c7b\u548c\u4f7f\u7528Fruit360\u6570\u636e\u96c6\u7684\u76ee\u6807\u8bc6\u522b\u4e24\u4e2a\u56fe\u50cf\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eRTD\u7684RC\u7cfb\u7edf\u5728\u56fe\u50cf\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u7b26\u5408\u4e0b\u4e00\u4ee3RC\u7684\u539f\u5219\uff0c\u5373\u6d88\u9664\u968f\u673a\u8fde\u63a5\uff0c\u8f6c\u800c\u91c7\u7528\u786e\u5b9a\u6027\u7684\u975e\u7ebf\u6027\u8f93\u5165\u4fe1\u53f7\u8f6c\u6362\u3002"}}
{"id": "2507.15727", "categories": ["cs.LG", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15727", "abs": "https://arxiv.org/abs/2507.15727", "authors": ["Xuchuang Wang", "Bo Sun", "Hedyeh Beyhaghi", "John C. S. Lui", "Mohammad Hajiesmaili", "Adam Wierman"], "title": "Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems", "comment": null, "summary": "This paper introduces a novel multi-agent ski-rental problem that generalizes\nthe classical ski-rental dilemma to a group setting where agents incur\nindividual and shared costs. In our model, each agent can either rent at a\nfixed daily cost, or purchase a pass at an individual cost, with an additional\nthird option of a discounted group pass available to all. We consider scenarios\nin which agents' active days differ, leading to dynamic states as agents drop\nout of the decision process. To address this problem from different\nperspectives, we define three distinct competitive ratios: overall,\nstate-dependent, and individual rational. For each objective, we design and\nanalyze optimal deterministic and randomized policies. Our deterministic\npolicies employ state-aware threshold functions that adapt to the dynamic\nstates, while our randomized policies sample and resample thresholds from\ntailored state-aware distributions. The analysis reveals that symmetric\npolicies, in which all agents use the same threshold, outperform asymmetric\nones. Our results provide competitive ratio upper and lower bounds and extend\nclassical ski-rental insights to multi-agent settings, highlighting both\ntheoretical and practical implications for group decision-making under\nuncertainty.", "AI": {"tldr": "\u672c\u6587\u5c06\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u6269\u5c55\u5230\u591a\u4e3b\u4f53\u8bbe\u7f6e\uff0c\u8003\u8651\u4e86\u4e2a\u4eba\u548c\u5171\u540c\u6210\u672c\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e09\u79cd\u7ade\u4e89\u6bd4\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u6700\u4f18\u7b56\u7565\uff0c\u5e76\u53d1\u73b0\u5bf9\u79f0\u7b56\u7565\u4f18\u4e8e\u975e\u5bf9\u79f0\u7b56\u7565\u3002", "motivation": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u4e3b\u4f53\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5c06\u7ecf\u5178\u7684\u6ed1\u96ea\u79df\u8d41\u56f0\u5883\u63a8\u5e7f\u5230\u4e00\u79cd\u7fa4\u4f53\u8bbe\u7f6e\uff0c\u5728\u8fd9\u79cd\u8bbe\u7f6e\u4e2d\uff0c\u4e3b\u4f53\u9700\u8981\u627f\u62c5\u4e2a\u4eba\u548c\u5171\u540c\u7684\u6210\u672c\u3002", "method": "\u6211\u4eec\u5b9a\u4e49\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u7ade\u4e89\u6bd4\uff1a\u6574\u4f53\u7684\u3001\u72b6\u6001\u76f8\u5173\u7684\u548c\u4e2a\u4f53\u7406\u6027\u7684\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u8bbe\u8ba1\u5e76\u5206\u6790\u4e86\u6700\u4f18\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u3002\u6211\u4eec\u7684\u786e\u5b9a\u6027\u7b56\u7565\u91c7\u7528\u72b6\u6001\u611f\u77e5\u9608\u503c\u51fd\u6570\uff0c\u4ee5\u9002\u5e94\u52a8\u6001\u72b6\u6001\uff0c\u800c\u6211\u4eec\u7684\u968f\u673a\u7b56\u7565\u4ece\u5b9a\u5236\u7684\u72b6\u6001\u611f\u77e5\u5206\u5e03\u4e2d\u91c7\u6837\u548c\u91cd\u65b0\u91c7\u6837\u9608\u503c\u3002", "result": "\u6211\u4eec\u8bbe\u8ba1\u5e76\u5206\u6790\u4e86\u6700\u4f18\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u3002\u6211\u4eec\u7684\u786e\u5b9a\u6027\u7b56\u7565\u91c7\u7528\u72b6\u6001\u611f\u77e5\u9608\u503c\u51fd\u6570\uff0c\u4ee5\u9002\u5e94\u52a8\u6001\u72b6\u6001\uff0c\u800c\u6211\u4eec\u7684\u968f\u673a\u7b56\u7565\u4ece\u5b9a\u5236\u7684\u72b6\u6001\u611f\u77e5\u5206\u5e03\u4e2d\u91c7\u6837\u548c\u91cd\u65b0\u91c7\u6837\u9608\u503c\u3002\u5206\u6790\u8868\u660e\uff0c\u5bf9\u79f0\u7b56\u7565\uff08\u6240\u6709\u4e3b\u4f53\u4f7f\u7528\u76f8\u540c\u9608\u503c\u7684\u7b56\u7565\uff09\u7684\u6027\u80fd\u4f18\u4e8e\u975e\u5bf9\u79f0\u7b56\u7565\u3002", "conclusion": "\u5bf9\u79f0\u7b56\u7565\u4f18\u4e8e\u975e\u5bf9\u79f0\u7b56\u7565\uff0c\u5e76\u4e14\u6211\u4eec\u4e3a\u6bcf\u4e2a\u76ee\u6807\u63d0\u4f9b\u4e86\u7ade\u4e89\u6bd4\u7684\u4e0a\u754c\u548c\u4e0b\u754c\uff0c\u5c06\u7ecf\u5178\u7684\u6ed1\u96ea\u79df\u8d41\u89c1\u89e3\u6269\u5c55\u5230\u591a\u4e3b\u4f53\u8bbe\u7f6e\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u8fdb\u884c\u7fa4\u4f53\u51b3\u7b56\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2507.14146", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14146", "abs": "https://arxiv.org/abs/2507.14146", "authors": ["Kleanthis Avramidis", "Emily Zhou", "Tiantian Feng", "Hossein Hamidi Shishavan", "Frederico Marcolino Quintao Severgnini", "Danny J. Lohan", "Paul Schmalenberg", "Ercan M. Dede", "Shrikanth Narayanan"], "title": "Estimating Markers of Driving Stress through Multimodal Physiological Monitoring", "comment": "11 pages, 7 figures, 3 tables. This work has been submitted to the\n  IEEE for possible publication", "summary": "Understanding and mitigating driving stress is vital for preventing accidents\nand advancing both road safety and driver well-being. While vehicles are\nequipped with increasingly sophisticated safety systems, many limits exist in\ntheir ability to account for variable driving behaviors and environmental\ncontexts. In this study we examine how short-term stressor events impact\ndrivers' physiology and their behavioral responses behind the wheel. Leveraging\na controlled driving simulation setup, we collected physiological signals from\n31 adult participants and designed a multimodal machine learning system to\nestimate the presence of stressors. Our analysis explores the model sensitivity\nand temporal dynamics against both known and novel emotional inducers, and\nexamines the relationship between predicted stress and observable patterns of\nvehicle control. Overall, this study demonstrates the potential of linking\nphysiological signals with contextual and behavioral cues in order to improve\nreal-time estimation of driving stress.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u6790\u751f\u7406\u4fe1\u53f7\u548c\u9a7e\u9a76\u884c\u4e3a\uff0c\u4ee5\u5b9e\u65f6\u4f30\u7b97\u9a7e\u9a76\u538b\u529b\u3002", "motivation": "\u7406\u89e3\u548c\u51cf\u8f7b\u9a7e\u9a76\u538b\u529b\u5bf9\u4e8e\u9884\u9632\u4e8b\u6545\u4ee5\u53ca\u63d0\u9ad8\u9053\u8def\u5b89\u5168\u548c\u9a7e\u9a76\u5458\u798f\u7949\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u8f66\u8f86\u914d\u5907\u4e86\u65e5\u76ca\u590d\u6742\u7684\u5b89\u5168\u7cfb\u7edf\uff0c\u4f46\u5b83\u4eec\u5728\u5e94\u5bf9\u53ef\u53d8\u7684\u9a7e\u9a76\u884c\u4e3a\u548c\u73af\u5883\u80cc\u666f\u65b9\u9762\u5b58\u5728\u8bb8\u591a\u9650\u5236\u3002", "method": "\u5229\u7528\u53d7\u63a7\u9a7e\u9a76\u6a21\u62df\u88c5\u7f6e\uff0c\u6536\u96c6\u4e86 31 \u540d\u6210\u5e74\u53c2\u4e0e\u8005\u7684\u751f\u7406\u4fe1\u53f7\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u6765\u4f30\u8ba1\u538b\u529b\u6e90\u7684\u5b58\u5728\u3002", "result": "\u5206\u6790\u63a2\u8ba8\u4e86\u6a21\u578b\u5bf9\u5df2\u77e5\u548c\u65b0\u578b\u60c5\u7eea\u8bf1\u56e0\u7684\u654f\u611f\u6027\u548c\u65f6\u95f4\u52a8\u6001\u6027\uff0c\u5e76\u68c0\u9a8c\u4e86\u9884\u6d4b\u538b\u529b\u4e0e\u8f66\u8f86\u63a7\u5236\u53ef\u89c2\u5bdf\u6a21\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u7ed3\u5408\u751f\u7406\u4fe1\u53f7\u3001\u4e0a\u4e0b\u6587\u548c\u884c\u4e3a\u7ebf\u7d22\u4ee5\u6539\u5584\u9a7e\u9a76\u538b\u529b\u5b9e\u65f6\u4f30\u7b97\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15156", "categories": ["cs.LG", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15156", "abs": "https://arxiv.org/abs/2507.15156", "authors": ["Mykhailo Buleshnyi", "Anna Polova", "Zsolt Zombori", "Michael Benedikt"], "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification", "comment": null, "summary": "We investigate multi-label classification involving large sets of labels,\nwhere the output labels may be known to satisfy some logical constraints. We\nlook at an architecture in which classifiers for individual labels are fed into\nan expressive sequential model, which produces a joint distribution. One of the\npotential advantages for such an expressive model is its ability to modelling\ncorrelations, as can arise from constraints. We empirically demonstrate the\nability of the architecture both to exploit constraints in training and to\nenforce constraints at inference time.", "AI": {"tldr": "A new architecture for multi-label classification uses a sequential model to leverage label correlations and constraints, showing effectiveness in both training and inference.", "motivation": "Investigating multi-label classification with large label sets and logical constraints between labels.", "method": "An architecture where classifiers for individual labels feed into an expressive sequential model to produce a joint distribution.", "result": "Empirical demonstration of the architecture's ability to exploit and enforce constraints.", "conclusion": "The architecture can exploit constraints during training and enforce them during inference."}}
{"id": "2507.15553", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.15553", "abs": "https://arxiv.org/abs/2507.15553", "authors": ["Shibo Yu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "title": "Efficient Routing of Inference Requests across LLM Instances in Cloud-Edge Computing", "comment": null, "summary": "The rising demand for Large Language Model (LLM) inference services has\nintensified pressure on computational resources, resulting in latency and cost\nchallenges. This paper introduces a novel routing algorithm based on the\nNon-dominated Sorting Genetic Algorithm II (NSGA-II) to distribute inference\nrequests across heterogeneous LLM instances in a cloud-edge computing\nenvironment. Formulated as a multi-objective optimization problem, the\nalgorithm balances response quality, response time, and inference cost,\nadapting to request heterogeneity (e.g., varying complexity and prompt lengths)\nand node diversity (e.g., edge vs. cloud resources). This adaptive routing\nalgorithm optimizes performance under dynamic workloads. We benchmark the\napproach using a testbed with datasets including Stanford Question Answering\nDataset (SQuAD), Mostly Basic Python Problems (MBPP), Hella Situations With\nAdversarial Generations (HellaSwag), and Grade School Math 8K (GSM8K).\nExperimental results show our solution, compared to the baselines, achieves up\nto 95.2% and 34.9% improvements in terms of response time and cost,\nrespectively. These findings validate the algorithm's effectiveness for\nscalable LLM deployments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e NSGA-II \u7684\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\uff0c\u4ee5\u4f18\u5316\u4e91\u8fb9\u73af\u5883\u4e2d LLM \u63a8\u7406\u670d\u52a1\u7684\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9 LLM \u63a8\u7406\u670d\u52a1\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\u6240\u5e26\u6765\u7684\u8ba1\u7b97\u8d44\u6e90\u538b\u529b\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e NSGA-II \u7684\u65b0\u9896\u8def\u7531\u7b97\u6cd5\uff0c\u5c06 LLM \u63a8\u7406\u8bf7\u6c42\u5206\u914d\u5230\u4e91\u8fb9\u73af\u5883\u4e2d\u7684\u5f02\u6784 LLM \u5b9e\u4f8b\u3002\u8be5\u7b97\u6cd5\u5c06\u95ee\u9898\u516c\u5f0f\u5316\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u5e73\u8861\u54cd\u5e94\u8d28\u91cf\u3001\u54cd\u5e94\u65f6\u95f4\u548c\u63a8\u7406\u6210\u672c\uff0c\u5e76\u80fd\u9002\u5e94\u8bf7\u6c42\u5f02\u8d28\u6027\u548c\u8282\u70b9\u591a\u6837\u6027\u3002", "result": "\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u5728\u54cd\u5e94\u65f6\u95f4\u548c\u6210\u672c\u65b9\u9762\u5206\u522b\u53d6\u5f97\u4e86\u9ad8\u8fbe 95.2% \u548c 34.9% \u7684\u6539\u8fdb\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u53ef\u6269\u5c55 LLM \u90e8\u7f72\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\u901a\u8fc7\u5728\u4e91\u8fb9\u8ba1\u7b97\u73af\u5883\u4e2d\u5229\u7528 NSGA-II \u6765\u4f18\u5316 LLM \u63a8\u7406\u670d\u52a1\u7684\u6027\u80fd\uff0c\u5728\u54cd\u5e94\u65f6\u95f4\u3001\u6210\u672c\u548c\u8bf7\u6c42\u5f02\u8d28\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002"}}
{"id": "2507.14721", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14721", "abs": "https://arxiv.org/abs/2507.14721", "authors": ["Keita Kobashi", "Masayoshi Tomizuka"], "title": "Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls", "comment": "7 pages, 7 figures", "summary": "This study addresses the problem of occluded grasping, where primary grasp\nconfigurations of an object are not available due to occlusion with\nenvironment. Simple parallel grippers often struggle with such tasks due to\nlimited dexterity and actuation constraints. Prior works have explored object\npose reorientation such as pivoting by utilizing extrinsic contacts between an\nobject and an environment feature like a wall, to make the object graspable.\nHowever, such works often assume the presence of a short wall, and this\nassumption may not always hold in real-world scenarios. If the wall available\nfor interaction is too large or too tall, the robot may still fail to grasp the\nobject even after pivoting, and the robot must combine different types of\nactions to grasp. To address this, we propose a hierarchical reinforcement\nlearning (RL) framework. We use Q-learning to train a high-level policy that\nselects the type of action expected to yield the highest reward. The selected\nlow-level skill then samples a specific robot action in continuous space. To\nguide the robot to an appropriate location for executing the selected action,\nwe adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on\nthe object point cloud and the skill ID, enabling it to infer a suitable\nlocation based on the object geometry and the selected skill. To promote\ngeneralization, we apply domain randomization during the training of low-level\nskills. The RL policy is trained entirely in simulation with a box-like object\nand deployed to six objects in real world. We conduct experiments to evaluate\nour method and demonstrate both its generalizability and robust sim-to-real\ntransfer performance with promising success rates.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528CVAE\u8fdb\u884c\u5b9a\u4f4d\uff0c\u5b9e\u73b0\u906e\u6321\u6293\u53d6\uff0c\u5e76\u6210\u529f\u4ece\u6a21\u62df\u8fc1\u79fb\u5230\u73b0\u5b9e\u3002", "motivation": "\u89e3\u51b3\u56e0\u4e0e\u73af\u5883\u7684\u906e\u6321\u800c\u5bfc\u81f4\u7269\u4f53\u4e3b\u8981\u6293\u53d6\u6784\u578b\u4e0d\u53ef\u7528\u7684\u906e\u6321\u6293\u53d6\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u63a2\u7d22\u4e86\u5229\u7528\u7269\u4f53\u4e0e\u5899\u7b49\u73af\u5883\u7279\u5f81\u4e4b\u95f4\u7684\u5916\u5728\u63a5\u89e6\u6765\u8fdb\u884c\u67a2\u8f6c\u7b49\u59ff\u6001\u91cd\u5b9a\u5411\uff0c\u4f46\u901a\u5e38\u5047\u8bbe\u5b58\u5728\u8f83\u77ed\u7684\u5899\uff0c\u800c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u8fd9\u79cd\u5047\u8bbe\u4e0d\u4e00\u5b9a\u6210\u7acb\u3002\u5982\u679c\u7528\u4e8e\u4ea4\u4e92\u7684\u5899\u8fc7\u5927\u6216\u8fc7\u9ad8\uff0c\u673a\u5668\u4eba\u5373\u4f7f\u5728\u67a2\u8f6c\u540e\u4ecd\u53ef\u80fd\u65e0\u6cd5\u6293\u53d6\u7269\u4f53\uff0c\u5e76\u4e14\u9700\u8981\u7ed3\u5408\u4e0d\u540c\u7c7b\u578b\u7684\u52a8\u4f5c\u624d\u80fd\u6293\u53d6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6\uff0c\u5176\u4e2d\u4f7f\u7528Q\u5b66\u4e60\u8bad\u7ec3\u4e00\u4e2a\u9ad8\u7ea7\u7b56\u7565\u6765\u9009\u62e9\u9884\u671f\u7684\u6700\u9ad8\u5956\u52b1\u52a8\u4f5c\u7c7b\u578b\uff0c\u7136\u540e\u7531\u9009\u5b9a\u7684\u4f4e\u7ea7\u6280\u80fd\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u91c7\u6837\u5177\u4f53\u7684\u673a\u5668\u4eba\u52a8\u4f5c\u3002\u4e3a\u4e86\u6307\u5bfc\u673a\u5668\u4eba\u5230\u6267\u884c\u6240\u9009\u52a8\u4f5c\u7684\u5408\u9002\u4f4d\u7f6e\uff0c\u91c7\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\uff0c\u5e76\u5c06\u5176\u6761\u4ef6\u8bbe\u7f6e\u4e3a\u7269\u4f53\u70b9\u4e91\u548c\u6280\u80fdID\uff0c\u4ece\u800c\u80fd\u591f\u6839\u636e\u7269\u4f53\u51e0\u4f55\u548c\u6240\u9009\u6280\u80fd\u63a8\u65ad\u51fa\u5408\u9002\u7684\u4f4d\u7f6e\u3002\u4e3a\u4e86\u4fc3\u8fdb\u6cdb\u5316\uff0c\u5728\u4f4e\u7ea7\u6280\u80fd\u7684\u8bad\u7ec3\u4e2d\u5e94\u7528\u4e86\u57df\u968f\u673a\u5316\u3002", "result": "\u8be5RL\u7b56\u7565\u5b8c\u5168\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u7c7b\u4f3c\u76d2\u5b50\u7684\u7269\u4f53\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u6210\u529f\u90e8\u7f72\u5230\u73b0\u5b9e\u4e16\u754c\u7684\u516d\u79cd\u7269\u4f53\u4e0a\u3002\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u548c\u7a33\u5065\u7684\u4ece\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u4f20\u8f93\u6027\u80fd\uff0c\u6210\u529f\u7387\u4ee4\u4eba\u6ee1\u610f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8bad\u7ec3\uff0c\u5e76\u6210\u529f\u8fc1\u79fb\u5230\u771f\u5b9e\u4e16\u754c\u7684\u516d\u79cd\u4e0d\u540c\u7269\u4f53\u4e0a\uff0c\u5c55\u793a\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u548c\u4ece\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u4f20\u8f93\u6027\u80fd\uff0c\u5e76\u53d6\u5f97\u4e86\u4ee4\u4eba\u9f13\u821e\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2507.14452", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14452", "abs": "https://arxiv.org/abs/2507.14452", "authors": ["Weikang Gu", "Mingyue Han", "Li Xue", "Heng Dong", "Changcai Yang", "Riqing Chen", "Lifang Wei"], "title": "GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration", "comment": "9 pages, 4 figures. Accepted to IJCAI 2025", "summary": "The accurate identification of high-quality correspondences is a prerequisite\ntask in feature-based point cloud registration. However, it is extremely\nchallenging to handle the fusion of local and global features due to feature\nredundancy and complex spatial relationships. Given that Gestalt principles\nprovide key advantages in analyzing local and global relationships, we propose\na novel Gestalt-guided Parallel Interaction Network via orthogonal geometric\nconsistency (GPI-Net) in this paper. It utilizes Gestalt principles to\nfacilitate complementary communication between local and global information.\nSpecifically, we introduce an orthogonal integration strategy to optimally\nreduce redundant information and generate a more compact global structure for\nhigh-quality correspondences. To capture geometric features in correspondences,\nwe leverage a Gestalt Feature Attention (GFA) block through a hybrid\nutilization of self-attention and cross-attention mechanisms. Furthermore, to\nfacilitate the integration of local detail information into the global\nstructure, we design an innovative Dual-path Multi-Granularity parallel\ninteraction aggregation (DMG) block to promote information exchange across\ndifferent granularities. Extensive experiments on various challenging tasks\ndemonstrate the superior performance of our proposed GPI-Net in comparison to\nexisting methods. The code will be released at https://github.com/gwk/GPI-Net.", "AI": {"tldr": "\u63d0\u51faGPI-Net\u7f51\u7edc\uff0c\u5229\u7528\u683c\u5f0f\u5854\u539f\u7406\u548c\u6b63\u4ea4\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u901a\u8fc7GFA\u548cDMG\u5757\u6709\u6548\u878d\u5408\u70b9\u4e91\u7684\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\uff0c\u63d0\u5347\u914d\u51c6\u7cbe\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u70b9\u4e91\u914d\u51c6\u4e2d\u7279\u5f81\u878d\u5408\u65f6\u7279\u5f81\u5197\u4f59\u548c\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u5e26\u6765\u7684\u6311\u6218\uff0c\u63d0\u51fa\u5229\u7528\u683c\u5f0f\u5854\u539f\u7406\u6765\u4fc3\u8fdb\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\u4e4b\u95f4\u7684\u4e92\u8865\u901a\u4fe1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGPI-Net\u7684\u65b0\u578b\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u7ed3\u5408\u4e86\u683c\u5f0f\u5854\u539f\u7406\u548c\u6b63\u4ea4\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u5177\u4f53\u5305\u62ec\uff1a1. \u5f15\u5165\u6b63\u4ea4\u96c6\u6210\u7b56\u7565\uff0c\u51cf\u5c11\u5197\u4f59\u4fe1\u606f\u5e76\u751f\u6210\u66f4\u7d27\u51d1\u7684\u5168\u5c40\u7ed3\u6784\u30022. \u8bbe\u8ba1\u4e86\u683c\u5f0f\u5854\u7279\u5f81\u6ce8\u610f\u529b\uff08GFA\uff09\u5757\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5bf9\u5e94\u70b9\u4e2d\u7684\u51e0\u4f55\u7279\u5f81\u30023. \u8bbe\u8ba1\u4e86\u53cc\u8def\u5f84\u591a\u7c92\u5ea6\u5e76\u884c\u4ea4\u4e92\u805a\u5408\uff08DMG\uff09\u5757\uff0c\u4fc3\u8fdb\u4e0d\u540c\u7c92\u5ea6\u95f4\u7684\u7279\u5f81\u4fe1\u606f\u4ea4\u6362\u3002", "result": "\u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cGPI-Net\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684GPI-Net\u5728\u70b9\u4e91\u914d\u51c6\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u7684\u878d\u5408\uff0c\u5e76\u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14447", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14447", "abs": "https://arxiv.org/abs/2507.14447", "authors": ["Guancheng Zeng", "Xueyi Chen", "Jiawang Hu", "Shaohua Qi", "Yaxuan Mao", "Zhantao Wang", "Yifan Nie", "Shuang Li", "Qiuyang Feng", "Pengxu Qiu", "Yujia Wang", "Wenqiang Han", "Linyan Huang", "Gang Li", "Jingjing Mo", "Haowen Hu"], "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "comment": "26 pages, 8 figures, 5 tables", "summary": "The deployment of agent systems in an enterprise environment is often\nhindered by several challenges: common models lack domain-specific process\nknowledge, leading to disorganized plans, missing key tools, and poor execution\nstability. To address this, this paper introduces Routine, a multi-step agent\nplanning framework designed with a clear structure, explicit instructions, and\nseamless parameter passing to guide the agent's execution module in performing\nmulti-step tool-calling tasks with high stability. In evaluations conducted\nwithin a real-world enterprise scenario, Routine significantly increases the\nexecution accuracy in model tool calls, increasing the performance of GPT-4o\nfrom 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed\na Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an\naccuracy increase to 88.2% on scenario-specific evaluations, indicating\nimproved adherence to execution plans. In addition, we employed Routine-based\ndistillation to create a scenario-specific, multi-step tool-calling dataset.\nFine-tuning on this distilled dataset raised the model's accuracy to 95.5%,\napproaching GPT-4o's performance. These results highlight Routine's\neffectiveness in distilling domain-specific tool-usage patterns and enhancing\nmodel adaptability to new scenarios. Our experimental results demonstrate that\nRoutine provides a practical and accessible approach to building stable agent\nworkflows, accelerating the deployment and adoption of agent systems in\nenterprise environments, and advancing the technical vision of AI for Process.", "AI": {"tldr": "Routine\u662f\u4e00\u4e2a\u4ee3\u7406\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u548c\u660e\u786e\u7684\u6307\u4ee4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u591a\u6b65\u5de5\u5177\u8c03\u7528\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u5fae\u8c03\u548c\u84b8\u998f\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u597d\u5730\u9002\u5e94\u7279\u5b9a\u573a\u666f\u3002", "motivation": "\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u4ee3\u7406\u7cfb\u7edf\u90e8\u7f72\u5e38\u9762\u4e34\u6a21\u578b\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u6d41\u7a0b\u77e5\u8bc6\u7684\u6311\u6218\uff0c\u5bfc\u81f4\u8ba1\u5212\u6df7\u4e71\u3001\u7f3a\u5c11\u5173\u952e\u5de5\u5177\u548c\u6267\u884c\u7a33\u5b9a\u6027\u5dee\u3002", "method": "Routine\u662f\u4e00\u4e2a\u591a\u6b65\u4ee3\u7406\u89c4\u5212\u6846\u67b6\uff0c\u5177\u6709\u6e05\u6670\u7684\u7ed3\u6784\u3001\u660e\u786e\u7684\u6307\u4ee4\u548c\u65e0\u7f1d\u7684\u53c2\u6570\u4f20\u9012\uff0c\u7528\u4e8e\u6307\u5bfc\u4ee3\u7406\u7684\u6267\u884c\u6a21\u5757\u7a33\u5b9a\u5730\u6267\u884c\u591a\u6b65\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u8fd8\u6784\u5efa\u4e86Routine\u9075\u5faa\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u8fd8\u5229\u7528Routine\u84b8\u998f\u521b\u5efa\u4e86\u7279\u5b9a\u573a\u666f\u7684\u591a\u6b65\u5de5\u5177\u8c03\u7528\u6570\u636e\u96c6\u3002", "result": "\u5728\u771f\u5b9e\u7684\u4f01\u4e1a\u573a\u666f\u8bc4\u4f30\u4e2d\uff0cRoutine\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5de5\u5177\u8c03\u7528\u7684\u6267\u884c\u51c6\u786e\u6027\uff0cGPT-4o\u7684\u6027\u80fd\u4ece41.1%\u63d0\u5347\u81f396.3%\uff0cQwen3-14B\u4ece32.6%\u63d0\u5347\u81f383.3%\u3002\u901a\u8fc7\u5fae\u8c03\uff0cQwen3-14B\u5728\u7279\u5b9a\u573a\u666f\u8bc4\u4f30\u4e2d\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u523088.2%\u3002\u5728\u84b8\u998f\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u523095.5%\u3002", "conclusion": "Routine\u901a\u8fc7\u63d0\u70bc\u9886\u57df\u7279\u5b9a\u7684\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u5e76\u589e\u5f3a\u6a21\u578b\u5bf9\u65b0\u573a\u666f\u7684\u9002\u5e94\u6027\uff0c\u4e3a\u6784\u5efa\u7a33\u5b9a\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u6613\u4e8e\u8bbf\u95ee\u7684\u65b9\u6cd5\uff0c\u52a0\u901f\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u4ee3\u7406\u7cfb\u7edf\u7684\u90e8\u7f72\u548c\u91c7\u7528\uff0c\u5e76\u63a8\u8fdb\u4e86AI for Process\u7684\u6280\u672f\u613f\u666f\u3002"}}
{"id": "2507.14763", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14763", "abs": "https://arxiv.org/abs/2507.14763", "authors": ["J. Boy", "R. Mitdank", "A. Popp", "Z. Galazka", "S. F. Fischer"], "title": "Enhanced phonon-drag by nanoscale design of homoepitaxial \\hbox{$\u03b2$-Ga$_2$O$_3$}", "comment": "14 pages, 4 figures", "summary": "Phonon drag may be harnessed for thermoelectric generators and devices. Here,\nwe demonstrate the geometric control of the phonon-drag contribution to the\nthermopower. In nanometer-thin electrically conducting $\\beta$-Ga$_2$O$_3$\nfilms homoepitaxially-grown on insulating substrates it is enhanced from -0,4\nmV/K to up to -3 mV/K at 100 K by choice of the film thickness. Analysis of the\ntemperature-dependent Seebeck coefficients reveal that a crossover from\nthree-dimensional to quasi-two-dimensional electron-phonon interaction occurs\nfor film thicknesses below 75~nm. The ratio of phonon-phonon to electron-phonon\nrelaxation times in these confined structures is $10$ times larger than that of\nbulk. Generally the phonon drag can be tuned depending on the relations between\nthe phonon-drag interaction length $\\lambda_\\text{PD}$, the phonon mean free\npath $\\lambda$ and the film thickness $d$. Phonon drag can be enhanced for\n$\\lambda_\\text{PD}\\gg\\lambda>d$.", "AI": {"tldr": "Geometric control of phonon drag in $\\beta$-Ga$_2$O$_3$ films enhances thermopower for thermoelectric devices. Thinner films (below 75 nm) exhibit quasi-2D electron-phonon interaction and significantly increased phonon-drag effect compared to bulk.", "motivation": "To harness phonon drag for thermoelectric generators and devices by demonstrating geometric control of its contribution to the thermopower.", "method": "Demonstrated geometric control of phonon-drag thermopower in nanometer-thin $\beta$-Ga$_2$O$_3$ films by varying film thickness and analyzed temperature-dependent Seebeck coefficients.", "result": "Enhanced phonon-drag contribution to thermopower from -0.4 mV/K to -3 mV/K at 100 K by reducing film thickness. Observed crossover from 3D to quasi-2D electron-phonon interaction below 75 nm thickness. Found that the ratio of phonon-phonon to electron-phonon relaxation times is 10 times larger in confined structures compared to bulk. Established that phonon drag can be enhanced when $\\lambda_\\text{PD}\\gg\\lambda>d$.", "conclusion": "Phonon drag can be tuned by controlling film thickness, which affects electron-phonon interactions and relaxation times, showing potential for thermoelectric applications."}}
{"id": "2507.15518", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15518", "abs": "https://arxiv.org/abs/2507.15518", "authors": ["Sizhou Chen", "Shufan Jiang", "Chi Zhang", "Xiao-Lei Zhang", "Xuelong Li"], "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics", "comment": null, "summary": "Creating an immersive and interactive theatrical experience is a long-term\ngoal in the field of interactive narrative. The emergence of large language\nmodel (LLM) is providing a new path to achieve this goal. However, existing\nLLM-based drama generation methods often result in AI agents that lack\ninitiative and cannot interact with the physical environment. Furthermore,\nthese methods typically require detailed user input to drive the drama. These\nlimitations reduce the interactivity and immersion of online real-time\nperformance. To address the above challenges, we propose HAMLET, a multi-agent\nframework focused on drama creation and online performance. Given a simple\ntopic, the framework generates a narrative blueprint, guiding the subsequent\nimprovisational performance. During the online performance, each actor is given\nan autonomous mind. This means that actors can make independent decisions based\non their own background, goals, and emotional state. In addition to\nconversations with other actors, their decisions can also change the state of\nscene props through actions such as opening a letter or picking up a weapon.\nThe change is then broadcast to other related actors, updating what they know\nand care about, which in turn influences their next action. To evaluate the\nquality of drama performance, we designed an evaluation method to assess three\nprimary aspects, including character performance, narrative quality, and\ninteraction experience. The experimental evaluation shows that HAMLET can\ncreate expressive and coherent theatrical experiences. Our code, dataset and\nmodels are available at https://github.com/HAMLET-2025/HAMLET.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14181", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14181", "abs": "https://arxiv.org/abs/2507.14181", "authors": ["Yajiao Dai", "Jun Li", "Zhen Mei", "Yiyang Ni", "Shi Jin", "Zengxiang Li", "Sheng Guo", "Wei Xiang"], "title": "Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis", "comment": "Accepted to IEEE Internet of Things Journal, Early Access. 14 pages,\n  5 figures", "summary": "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe\noperation of industrial machinery and improving production efficiency. However,\ntraditional supervised deep learning methods require a large amount of training\ndata and labels, which are often located in different clients. Additionally,\nthe cost of data labeling is high, making labels difficult to acquire.\nMeanwhile, differences in data distribution among clients may also hinder the\nmodel's performance. To tackle these challenges, this paper proposes a\nsemi-supervised federated learning framework, SSFL-DCSL, which integrates dual\ncontrastive loss and soft labeling to address data and label scarcity for\ndistributed clients with few labeled samples while safeguarding user privacy.\nIt enables representation learning using unlabeled data on the client side and\nfacilitates joint learning among clients through prototypes, thereby achieving\nmutual knowledge sharing and preventing local model divergence. Specifically,\nfirst, a sample weighting function based on the Laplace distribution is\ndesigned to alleviate bias caused by low confidence in pseudo labels during the\nsemi-supervised training process. Second, a dual contrastive loss is introduced\nto mitigate model divergence caused by different data distributions, comprising\nlocal contrastive loss and global contrastive loss. Third, local prototypes are\naggregated on the server with weighted averaging and updated with momentum to\nshare knowledge among clients. To evaluate the proposed SSFL-DCSL framework,\nexperiments are conducted on two publicly available datasets and a dataset\ncollected on motors from the factory. In the most challenging task, where only\n10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by\n1.15% to 7.85% over state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa SSFL-DCSL \u534a\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u53cc\u5bf9\u6bd4\u635f\u5931\u548c\u8f6f\u6807\u7b7e\u89e3\u51b3\u6570\u636e\u6807\u7b7e\u7a00\u758f\u95ee\u9898\uff0c\u901a\u8fc7\u52a0\u6743\u5e73\u5747\u805a\u5408\u539f\u578b\u5b9e\u73b0\u77e5\u8bc6\u5171\u4eab\uff0c\u51c6\u786e\u7387\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad8\u3002", "motivation": "\u4f20\u7edf\u7684\u76d1\u7763\u5f0f\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5de5\u4e1a\u673a\u68b0\u6545\u969c\u8bca\u65ad\u4e2d\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u800c\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u5206\u6563\u5728\u4e0d\u540c\u5ba2\u6237\u7aef\uff0c\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u83b7\u53d6\u3002\u540c\u65f6\uff0c\u5ba2\u6237\u7aef\u95f4\u6570\u636e\u5206\u5e03\u7684\u5dee\u5f02\u4e5f\u53ef\u80fd\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u672a\u6807\u8bb0\u6570\u636e\u3001\u4fc3\u8fdb\u8054\u5408\u5b66\u4e60\u5e76\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a SSFL-DCSL \u7684\u534a\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u53cc\u5bf9\u6bd4\u635f\u5931\u548c\u8f6f\u6807\u7b7e\u6280\u672f\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. \u8bbe\u8ba1\u57fa\u4e8e\u62c9\u666e\u62c9\u65af\u5206\u5e03\u7684\u6837\u672c\u6743\u91cd\u51fd\u6570\uff0c\u4ee5\u51cf\u8f7b\u4f2a\u6807\u7b7e\u7f6e\u4fe1\u5ea6\u4f4e\u5e26\u6765\u7684\u504f\u5dee\u30022. \u5f15\u5165\u5305\u542b\u5c40\u90e8\u5bf9\u6bd4\u635f\u5931\u548c\u5168\u5c40\u5bf9\u6bd4\u635f\u5931\u7684\u53cc\u5bf9\u6bd4\u635f\u5931\uff0c\u4ee5\u7f13\u89e3\u4e0d\u540c\u6570\u636e\u5206\u5e03\u5bfc\u81f4\u7684\u6a21\u578b\u5206\u6b67\u30023. \u5728\u670d\u52a1\u5668\u7aef\u901a\u8fc7\u52a0\u6743\u5e73\u5747\u548c\u52a8\u91cf\u66f4\u65b0\u805a\u5408\u5c40\u90e8\u539f\u578b\uff0c\u4ee5\u5b9e\u73b0\u5ba2\u6237\u7aef\u95f4\u7684\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u5728\u4e24\u79cd\u516c\u5f00\u6570\u636e\u96c6\u548c\u5de5\u5382\u7535\u673a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSSFL-DCSL \u6846\u67b6\u5728\u6700\u4e25\u5cfb\u7684\u6311\u6218\u6027\u4efb\u52a1\uff08\u4ec5 10% \u6570\u636e\u88ab\u6807\u8bb0\uff09\u4e2d\uff0c\u51c6\u786e\u7387\u6bd4\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e86 1.15% \u81f3 7.85%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 SSFL-DCSL \u6846\u67b6\u901a\u8fc7\u96c6\u6210\u53cc\u5bf9\u6bd4\u635f\u5931\u548c\u8f6f\u6807\u7b7e\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u5ba2\u6237\u7aef\u6570\u636e\u548c\u6807\u7b7e\u7a00\u758f\u7684\u95ee\u9898\uff0c\u5e76\u5728\u4ec5\u6709 10% \u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u9ad8\u4e86 1.15% \u81f3 7.85% \u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2507.14532", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14532", "abs": "https://arxiv.org/abs/2507.14532", "authors": ["Kaile Chen", "Xin Jin", "Xiaolong Yang"], "title": "Symmetry-breaking strain drives significant reduction in lattice thermal conductivity: A case study of boron arsenide", "comment": null, "summary": "Recent research has revealed that cubic boron arsenide (BAs) exhibits a\nnon-monotonic pressure dependence of lattice thermal conductivity ($\\kappa_{\\rm\nL}$) under isotropic strain. Here, through rigorous first-principles\ncalculations, we unveil that uniaxial tensile strain induces a monotonic\nreduction in the $\\kappa_{\\rm L}$ of BAs -- a striking contrast to the\nisotropic scenario. The results show that applying uniaxial (100) strain leads\nto the lifting of phonon band degeneracy, accompanied by an overall softening\nof the phonon spectrum. These modifications significantly increase\nphonon-phonon scattering channels by facilitating the fulfillment of selection\nrules, resulting in a concurrent increase in both three- and four-phonon\nscattering rates. Consequently, $\\kappa_{\\rm L}$ exhibits a dramatic\nsuppression of nearly 80\\% under large tension at room temperature. Meanwhile,\nwe unexpectedly observe that the uniaxial strain suppresses $\\kappa_{\\rm L}$\nmuch more strongly in the direction perpendicular to the strain than along the\nstretching direction. This work establishes the fundamental understanding of\nthe thermal conductivity behavior of BAs under uniaxial strain and opens a\npromising avenue for manipulating solid-state heat transport by tuning crystal\nsymmetry.", "AI": {"tldr": "\u5355\u8f74\u62c9\u4f38\u5e94\u53d8\u53ef\u5927\u5e45\u964d\u4f4eBAs\u70ed\u5bfc\u7387\uff0c\u4e14\u5bf9\u5782\u76f4\u65b9\u5411\u6291\u5236\u4f5c\u7528\u66f4\u5f3a\u3002", "motivation": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u7acb\u65b9\u7837\u5316\u787c\uff08BAs\uff09\u5728\u5404\u5411\u540c\u6027\u5e94\u53d8\u4e0b\u8868\u73b0\u51fa\u6676\u683c\u70ed\u5bfc\u7387\uff08\u03baL\uff09\u7684\u975e\u5355\u8c03\u538b\u529b\u4f9d\u8d56\u6027\u3002\u7136\u800c\uff0c\u5355\u8f74\u5e94\u53d8\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u4e25\u683c\u7684\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u3002", "result": "\u5355\u8f74\u62c9\u4f38\u5e94\u53d8\u5bfc\u81f4BAs\u7684\u6676\u683c\u70ed\u5bfc\u7387\uff08\u03baL\uff09\u5355\u8c03\u964d\u4f4e\uff0c\u8fd9\u4e0e\u5404\u5411\u540c\u6027\u60c5\u51b5\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u65bd\u52a0\u5355\u8f74\uff08100\uff09\u5e94\u53d8\u4f1a\u89e3\u9664\u58f0\u5b50\u80fd\u5e26\u7b80\u5e76\uff0c\u5e76\u4f7f\u58f0\u5b50\u8c31\u6574\u4f53\u8f6f\u5316\u3002\u8fd9\u4e9b\u53d8\u5316\u901a\u8fc7\u4fc3\u8fdb\u9009\u62e9\u89c4\u5219\u7684\u6ee1\u8db3\uff0c\u6781\u5927\u5730\u589e\u52a0\u4e86\u58f0\u5b50-\u58f0\u5b50\u6563\u5c04\u901a\u9053\uff0c\u4ece\u800c\u5bfc\u81f4\u4e09\u58f0\u5b50\u548c\u56db\u58f0\u5b50\u6563\u5c04\u7387\u540c\u65f6\u589e\u52a0\u3002\u56e0\u6b64\uff0c\u5728\u5ba4\u6e29\u4e0b\uff0c\u5728\u5927\u7684\u62c9\u4f38\u4f5c\u7528\u4e0b\uff0c\u03baL\u8868\u73b0\u51fa\u8fd180%\u7684\u6025\u5267\u6291\u5236\u3002\u6b64\u5916\uff0c\u5355\u8f74\u5e94\u53d8\u5728\u5782\u76f4\u4e8e\u5e94\u53d8\u7684\u65b9\u5411\u4e0a\u6bd4\u6cbf\u7740\u62c9\u4f38\u65b9\u5411\u66f4\u80fd\u6291\u5236\u03baL\u3002", "conclusion": "\u5355\u8f74\u62c9\u4f38\u5e94\u53d8\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u7acb\u65b9\u7837\u5316\u787c\uff08BAs\uff09\u7684\u6676\u683c\u70ed\u5bfc\u7387\uff08\u03baL\uff09\uff0c\u5e76\u4e14\u5728\u5782\u76f4\u4e8e\u5e94\u53d8\u65b9\u5411\u4e0a\u6bd4\u5728\u5e73\u884c\u65b9\u5411\u4e0a\u6291\u5236\u4f5c\u7528\u66f4\u5f3a\u3002\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u5bf9BAs\u5728\u5355\u8f74\u5e94\u53d8\u4e0b\u70ed\u5bfc\u884c\u4e3a\u7684\u57fa\u672c\u7406\u89e3\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u6676\u4f53\u5bf9\u79f0\u6027\u4e3a\u64cd\u7eb5\u56fa\u6001\u70ed\u8f93\u8fd0\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2507.14765", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14765", "abs": "https://arxiv.org/abs/2507.14765", "authors": ["Debadrita Banerjee", "Debjani Mitra", "Rajesh Dey", "Mudassir Khan", "Lalan Kumar"], "title": "Multi Target Observability", "comment": null, "summary": "In this paper, we mainly focus on the problem of multi-target observability,\nfocusing on the unique state estimation criteria for multiple targets. We\nderive the condition which is necessary as well as sufficient for observability\nusing bearing angles with multiple higher-order dynamics observed by a single\nobserver. We then establish an alternative notion of observability by analyzing\nambiguous target trajectories and deriving the condition which is NECNDSUF\n(Nec. and Suff.) for multi-target observability, considering three types of\nmeasurements: Doppler-only, bearing-only, and combined Doppler and bearing\nmeasurements, which offers insights that can improve target distinguishability,\ntrajectory reconstruction, and overall tracking accuracy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u76ee\u6807\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u63a8\u5bfc\u4e86\u4f7f\u7528\u65b9\u4f4d\u89d2\u8fdb\u884c\u53ef\u89c2\u6d4b\u6027\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u8003\u8651\u4e0d\u540c\u6d4b\u91cf\u7c7b\u578b\u7684\u591a\u76ee\u6807\u53ef\u89c2\u6d4b\u6027\u6982\u5ff5\u3002", "motivation": "\u672c\u6587\u7684\u4e3b\u8981\u76ee\u7684\u662f\u89e3\u51b3\u591a\u76ee\u6807\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u591a\u76ee\u6807\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u72ec\u7279\u7684\u72b6\u6001\u4f30\u8ba1\u6807\u51c6\u3002", "method": "\u672c\u6587\u63a8\u5bfc\u4e86\u4f7f\u7528\u65b9\u4f4d\u89d2\u8fdb\u884c\u591a\u76ee\u6807\u53ef\u89c2\u6d4b\u6027\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u7cca\u76ee\u6807\u8f68\u8ff9\uff0c\u63d0\u51fa\u4e86\u591a\u76ee\u6807\u53ef\u89c2\u6d4b\u6027\u7684\u66ff\u4ee3\u6982\u5ff5\uff0c\u5e76\u8003\u8651\u4e86\u4ec5\u591a\u666e\u52d2\u3001\u4ec5\u65b9\u4f4d\u89d2\u4ee5\u53ca\u591a\u666e\u52d2\u548c\u65b9\u4f4d\u89d2\u7ec4\u5408\u4e09\u79cd\u6d4b\u91cf\u7c7b\u578b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3a\u63d0\u9ad8\u76ee\u6807\u53ef\u533a\u5206\u6027\u3001\u8f68\u8ff9\u91cd\u5efa\u548c\u6574\u4f53\u8ddf\u8e2a\u7cbe\u5ea6\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u76ee\u6807\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u591a\u76ee\u6807\u72b6\u6001\u4f30\u8ba1\u63d0\u51fa\u4e86\u72ec\u7279\u7684\u72b6\u6001\u4f30\u8ba1\u6807\u51c6\u3002\u6211\u4eec\u63a8\u5bfc\u4e86\u4f7f\u7528\u591a\u4e2a\u9ad8\u9636\u52a8\u529b\u5b66\u548c\u5355\u4e00\u89c2\u6d4b\u8005\u4f7f\u7528\u65b9\u4f4d\u89d2\u8fdb\u884c\u53ef\u89c2\u6d4b\u6027\u7684\u5145\u8981\u6761\u4ef6\u3002"}}
{"id": "2507.14434", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14434", "abs": "https://arxiv.org/abs/2507.14434", "authors": ["Kai Chen", "Wen Liu", "GuoSheng Xu", "Yangzhi Li", "Maoduo Li", "Shouli He"], "title": "Quantum Circuit Optimization Based on Dynamic Grouping and ZX-Calculus for Reducing 2-Qubit Gate Count", "comment": null, "summary": "In the noisy intermediate-scale quantum (NISQ) era, two-qubit gates in\nquantum circuits are more susceptible to noise than single-qubit gates.\nTherefore, reducing the number of two-qubit gates is crucial for improving\ncircuit efficiency and reliability. As quantum circuits scale up, the\noptimization search space becomes increasingly complex, leading to challenges\nsuch as low efficiency and suboptimal solutions. To address these issues, this\npaper proposes a quantum circuit optimization approach based on dynamic\ngrouping and ZX-calculus. First, a random strategy-based dynamic grouping\nmethod partitions the circuit into multiple subcircuits. Second, a ZX-calculus\nguided k-step lookahead search performs equivalent subcircuit filtering to\nminimize two-qubit gate counts. Third, a delay-aware placement method optimizes\nthe recombined circuit to reduce the overall gate count. Finally, simulated\nannealing iteratively updates the grouping strategy to achieve an optimized\ntwo-qubit gate count. Experimental results on benchmark datasets demonstrate\nthe effectiveness and superiority of the proposed method in reducing two-qubit\ngates. Compared to the original circuits, the approach achieves an average\nreduction of 18% in two-qubit gates. It outperforms classical methods with up\nto 25% reduction, especially on gf circuits, and shows a 4% average improvement\nover heuristic ZX-calculus-based methods, validating its efficiency.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u5206\u7ec4\u548c ZX-\u6f14\u7b97\u7684\u91cf\u5b50\u7535\u8def\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11 NISQ \u65f6\u4ee3\u91cf\u5b50\u7535\u8def\u4e2d\u7684\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u7535\u8def\u5212\u5206\u4e3a\u5b50\u7535\u8def\u3001\u8fdb\u884c ZX-\u6f14\u7b97\u5f15\u5bfc\u7684\u4f18\u5316\u4ee5\u53ca\u4f7f\u7528\u6a21\u62df\u9000\u706b\u6765\u8fed\u4ee3\u66f4\u65b0\u5206\u7ec4\u7b56\u7565\uff0c\u6210\u529f\u51cf\u5c11\u4e86\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u5608\u6742\u7684\u4e2d\u7b49\u89c4\u6a21\u91cf\u5b50 (NISQ) \u65f6\u4ee3\uff0c\u91cf\u5b50\u7535\u8def\u4e2d\u7684\u4e24\u6bd4\u7279\u95e8\u6bd4\u5355\u6bd4\u7279\u95e8\u66f4\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u7684\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u51cf\u5c11\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u5bf9\u4e8e\u63d0\u9ad8\u7535\u8def\u6548\u7387\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002\u968f\u7740\u91cf\u5b50\u7535\u8def\u89c4\u6a21\u7684\u6269\u5927\uff0c\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u6b21\u4f18\u89e3\u7b49\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u52a8\u6001\u5206\u7ec4\u548c ZX-\u6f14\u7b97\u3002\u9996\u5148\uff0c\u4f7f\u7528\u57fa\u4e8e\u968f\u673a\u7b56\u7565\u7684\u52a8\u6001\u5206\u7ec4\u65b9\u6cd5\u5c06\u91cf\u5b50\u7535\u8def\u5212\u5206\u4e3a\u591a\u4e2a\u5b50\u7535\u8def\u3002\u5176\u6b21\uff0c\u8fdb\u884c\u57fa\u4e8e ZX-\u6f14\u7b97\u5f15\u5bfc\u7684 k \u6b65\u524d\u77bb\u641c\u7d22\uff0c\u5bf9\u7b49\u6548\u5b50\u7535\u8def\u8fdb\u884c\u8fc7\u6ee4\uff0c\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u3002\u7b2c\u4e09\uff0c\u901a\u8fc7\u5ef6\u8fdf\u611f\u77e5\u653e\u7f6e\u65b9\u6cd5\u4f18\u5316\u91cd\u65b0\u7ec4\u5408\u540e\u7684\u7535\u8def\uff0c\u4ee5\u51cf\u5c11\u6574\u4f53\u95e8\u6570\u91cf\u3002\u6700\u540e\uff0c\u901a\u8fc7\u6a21\u62df\u9000\u706b\u8fed\u4ee3\u66f4\u65b0\u5206\u7ec4\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u4f18\u5316\u7684\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u65b9\u9762\u662f\u6709\u6548\u4e14\u4f18\u8d8a\u7684\u3002\u4e0e\u539f\u59cb\u7535\u8def\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86 18% \u7684\u5e73\u5747\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u51cf\u5c11\u3002\u4e0e\u7ecf\u5178\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6027\u80fd\u63d0\u9ad8\u4e86 25%\uff0c\u5c24\u5176\u662f\u5728 GF \u7535\u8def\u65b9\u9762\uff0c\u5e76\u4e14\u6bd4\u57fa\u4e8e ZX-\u6f14\u7b97\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u9ad8\u4e86 4% \u7684\u5e73\u5747\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u65b9\u9762\u662f\u6709\u6548\u4e14\u4f18\u8d8a\u7684\u3002\u4e0e\u539f\u59cb\u7535\u8def\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86 18% \u7684\u5e73\u5747\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u51cf\u5c11\u3002\u4e0e\u7ecf\u5178\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6027\u80fd\u63d0\u9ad8\u4e86 25%\uff0c\u5c24\u5176\u662f\u5728 GF \u7535\u8def\u65b9\u9762\uff0c\u5e76\u4e14\u6bd4\u57fa\u4e8e ZX-\u6f14\u7b97\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u9ad8\u4e86 4% \u7684\u5e73\u5747\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u7387\u3002"}}
{"id": "2507.14298", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14298", "abs": "https://arxiv.org/abs/2507.14298", "authors": ["Wan-Cyuan Fan", "Yen-Chun Chen", "Mengchen Liu", "Alexander Jacobson", "Lu Yuan", "Leonid Sigal"], "title": "In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding", "comment": "arXiv admin note: substantial text overlap with arXiv:2407.14506", "summary": "Recent methods for customizing Large Vision Language Models (LVLMs) for\ndomain-specific tasks have shown promising results in scientific chart\ncomprehension. However, existing approaches face two major limitations: First,\nthey rely on paired data from only a few chart types, limiting generalization\nto wide range of chart types. Secondly, they lack targeted pre-training for\nchart-data alignment, which hampers the model's understanding of underlying\ndata. In this paper, we introduce ChartScope, an LVLM optimized for in-depth\nchart comprehension across diverse chart types. We propose an efficient data\ngeneration pipeline that synthesizes paired data for a wide range of chart\ntypes, along with a novel Dual-Path training strategy that enabling the model\nto succinctly capture essential data details while preserving robust reasoning\ncapabilities by incorporating reasoning over the underlying data. Lastly, we\nestablish ChartDQA, a new benchmark for evaluating not only question-answering\nat different levels but also underlying data understanding. Experimental\nresults demonstrate that ChartScope significantly enhances comprehension on a\nwide range of chart types. The code and data are available at\nhttps://davidhalladay.github.io/chartscope_demo.", "AI": {"tldr": "ChartScope\u662f\u4e00\u4e2a\u9488\u5bf9\u5404\u79cd\u56fe\u8868\u7c7b\u578b\u7684LVLM\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u6570\u636e\u751f\u6210\u548c\u53cc\u8def\u5f84\u8bad\u7ec3\u7b56\u7565\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u65b0\u57fa\u51c6ChartDQA\u4e0a\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5b9a\u5236\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\u4ee5\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u7684\u65b9\u6cd5\u5728\u79d1\u5b66\u56fe\u8868\u7406\u89e3\u65b9\u9762\u663e\u793a\u51fa\u6709\u524d\u666f\u7684\u7ed3\u679c\uff0c\u4f46\u662f\uff0c\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a\u9996\u5148\uff0c\u5b83\u4eec\u4ec5\u4f9d\u8d56\u4e8e\u5c11\u6570\u51e0\u79cd\u56fe\u8868\u7684\u914d\u5bf9\u6570\u636e\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5bf9\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5176\u6b21\uff0c\u5b83\u4eec\u7f3a\u4e4f\u9488\u5bf9\u56fe\u8868-\u6570\u636e\u5bf9\u9f50\u7684\u5b9a\u5411\u9884\u8bad\u7ec3\uff0c\u8fd9\u963b\u788d\u4e86\u6a21\u578b\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u53ef\u4ee5\u5408\u6210\u5404\u79cd\u56fe\u8868\u7c7b\u578b\u7684\u6570\u636e\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u53cc\u8def\u5f84\u8bad\u7ec3\u7b56\u7565\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u7b80\u6d01\u5730\u6355\u6349\u5173\u952e\u6570\u636e\u7ec6\u8282\uff0c\u540c\u65f6\u901a\u8fc7\u6574\u5408\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u63a8\u7406\u6765\u4fdd\u6301\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cChartScope \u5728\u5e7f\u6cdb\u7684\u56fe\u8868\u7c7b\u578b\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "ChartScope \u5728\u5e7f\u6cdb\u7684\u56fe\u8868\u7c7b\u578b\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2507.15823", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.15823", "abs": "https://arxiv.org/abs/2507.15823", "authors": ["Anton Abilov", "Ke Zhang", "Hemank Lamba", "Elizabeth M. Olson", "Joel R. Tetreault", "Alejandro Jaimes"], "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work", "comment": null, "summary": "Publications in the AI for Good space have tended to focus on the research\nand model development that can support high-impact applications. However, very\nfew AI for Good papers discuss the process of deploying and collaborating with\nthe partner organization, and the resulting real-world impact. In this work, we\nshare details about the close collaboration with a humanitarian-to-humanitarian\n(H2H) organization and how to not only deploy the AI model in a\nresource-constrained environment, but also how to maintain it for continuous\nperformance updates, and share key takeaways for practitioners.", "AI": {"tldr": "\u672c\u6587\u5206\u4eab\u4e86\u5728\u4eba\u9053\u4e3b\u4e49\u7ec4\u7ec7\u4e2d\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\u7684\u7ecf\u9a8c\u3002", "motivation": "AI for Good\u9886\u57df\u7684\u8bba\u6587\u5f80\u5f80\u4fa7\u91cd\u4e8e\u7814\u7a76\u548c\u6a21\u578b\u5f00\u53d1\uff0c\u5f88\u5c11\u8ba8\u8bba\u90e8\u7f72\u3001\u5408\u4f5c\u548c\u5b9e\u9645\u5f71\u54cd\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5206\u4eab\u4e86\u4e0e\u4eba\u9053\u4e3b\u4e49\u7ec4\u7ec7\u5408\u4f5c\u7684\u7ec6\u8282\uff0c\u5305\u62ecAI\u6a21\u578b\u7684\u90e8\u7f72\u3001\u7ef4\u62a4\u548c\u6301\u7eed\u6027\u80fd\u66f4\u65b0\u3002", "result": "\u63d0\u4f9b\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\u7684\u5b9e\u8df5\u7ecf\u9a8c\u548c\u5173\u952e\u542f\u793a\u3002", "conclusion": "AI\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u4eba\u9053\u4e3b\u4e49\u90e8\u7f72\u548c\u7ef4\u62a4"}}
{"id": "2507.15417", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.15417", "abs": "https://arxiv.org/abs/2507.15417", "authors": ["Dahoon Lee", "Chenglin Fan", "Euiwoong Lee"], "title": "1.64-Approximation for Chromatic Correlation Clustering via Chromatic Cluster LP", "comment": null, "summary": "Chromatic Correlation Clustering (CCC) generalizes Correlation Clustering by\nassigning multiple categorical relationships (colors) to edges and imposing\nchromatic constraints on the clusters. Unlike traditional Correlation\nClustering, which only deals with binary $(+/-)$ relationships, CCC captures\nricher relational structures. Despite its importance, improving the\napproximation for CCC has been difficult due to the limitations of standard LP\nrelaxations. We present a randomized $1.64$-approximation algorithm to the CCC\nproblem, significantly improving the previous factor of $2.15$. Our approach\nextends the cluster LP framework to the chromatic setting by introducing a\nchromatic cluster LP relaxation and an rounding algorithm that utilizes both a\ncluster-based and a greedy pivot-based strategy. The analysis bypasses the\nintegrality gap of $2$ for the CCC version of standard LP and highlights the\npotential of the cluster LP framework to address other variants of clustering\nproblems.", "AI": {"tldr": "\u4e00\u9879\u65b0\u7684\u968f\u673a\u7b97\u6cd5\u5c06CCC\u95ee\u9898\u7684\u8fd1\u4f3c\u6bd4\u4ece2.15\u63d0\u9ad8\u52301.64\uff0c\u5b83\u4f7f\u7528\u4e00\u79cd\u65b0\u7684LP\u677e\u5f1b\u548c\u820d\u5165\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u805a\u7c7bLP\u6846\u67b6\u5728\u5904\u7406\u5176\u4ed6\u805a\u7c7b\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\u3002", "motivation": "\u6539\u8fdbCCC\u95ee\u9898\u7684\u8fd1\u4f3c\u6bd4\uff0c\u56e0\u4e3a\u5148\u524d\u7684\u65b9\u6cd5\u53d7\u9650\u4e8e\u6807\u51c6LP\u677e\u5f1b\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u76841.64\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u6269\u5c55\u4e86\u805a\u7c7bLP\u6846\u67b6\u5230\u8272\u5f69\u8bbe\u5b9a\uff0c\u5f15\u5165\u4e86\u8272\u5f69\u805a\u7c7bLP\u677e\u5f1b\uff0c\u5e76\u4f7f\u7528\u7ed3\u5408\u4e86\u57fa\u4e8e\u805a\u7c7b\u548c\u57fa\u4e8e\u8d2a\u5fc3\u67a2\u8f74\u7684\u7b56\u7565\u7684\u820d\u5165\u7b97\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a1.64\u7684\u8fd1\u4f3c\u6bd4\uff0c\u4f18\u4e8e\u4e4b\u524d\u76842.15\u8fd1\u4f3c\u6bd4\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u7684\u3001\u8fd1\u4f3c\u6bd4\u4e3a1.64\u7684CCC\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d2.15\u7684\u8fd1\u4f3c\u6bd4\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u8272\u5f69\u805a\u7c7bLP\u677e\u5f1b\u548c\u4e00\u4e2a\u7ed3\u5408\u4e86\u57fa\u4e8e\u805a\u7c7b\u548c\u57fa\u4e8e\u8d2a\u5fc3\u67a2\u8f74\u7684\u7b56\u7565\u7684\u820d\u5165\u7b97\u6cd5\uff0c\u5c06\u805a\u7c7bLP\u6846\u67b6\u6269\u5c55\u5230\u4e86\u8272\u5f69\u8bbe\u5b9a\u3002\u8be5\u5206\u6790\u7ed5\u8fc7\u4e86\u6807\u51c6LP\u7684CCC\u7248\u672c\u4e2d\u76842\u7684\u79ef\u5206\u95f4\u9699\uff0c\u5e76\u5f3a\u8c03\u4e86\u805a\u7c7bLP\u6846\u67b6\u5728\u89e3\u51b3\u5176\u4ed6\u805a\u7c7b\u95ee\u9898\u53d8\u4f53\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15400", "categories": ["cond-mat.mtrl-sci", "physics.acc-ph", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2507.15400", "abs": "https://arxiv.org/abs/2507.15400", "authors": ["Konstantinos Kaleris", "Emmanouel Kaniolakis-Kaloudis", "Evaggelos Kaselouris", "Kyriaki Kosma", "Emmanouil Gagaoudakis", "Vassilis Binas", "Stelios Petrakis", "Vasilis Dimitriou", "Makis Bakarezos", "Michael Tatarakis", "Nektarios A. Papadogiannis"], "title": "Efficient ultrafast photoacoustic transduction on Tantalum thin films", "comment": "23 pages, 6 figures", "summary": "Nano-acoustic strain generation in thin metallic films via ultrafast laser\nexcitation is widely used in material science, imaging and medical\napplications. Recently, it was shown that transition metals, such as Titanium,\nexhibit enhanced photoacoustic transduction properties compared to noble\nmetals, such as Silver. This work presents experimental results and simulations\nthat demonstrate that among transition metals Tantalum exhibits superior\nphotoacoustic properties. Experiments of nano-acoustic strain generation by\nfemtosecond laser pulses focused on thin Tantalum films deposited on Silicon\nsubstrates are presented. The nano-acoustic strains are measured via pump-probe\ntransient reflectivity that captures the Brillouin oscillations produced by\nphoton-phonon interactions. The observed Brillouin oscillations are correlated\nto the photoacoustic transduction efficiency of the Tantalum thin film and\ncompared to the performance of Titanium thin films, clearly demonstrating the\nsuperior photoacoustic transduction efficiency of Tantalum. The findings are\nsupported by computational results on the laser-induced strains and their\npropagation in these thin metal film/substrate systems using a Two-Temperature\nModel in combination with thermo-mechanical Finite Element Analysis. Finally,\nthe role of the metal transducer-substrate acoustic impedance matching is\ndiscussed and the possibility to generate appropriately modulated acoustic\npulse trains inside the crystalline substrate structures for the development of\ncrystalline undulators used for {\\gamma}-ray generation is presented.", "AI": {"tldr": "\u94bd\u8584\u819c\u7684\u5149\u58f0\u8f6c\u6362\u6548\u7387\u4f18\u4e8e\u949b\u8584\u819c\uff0c\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u7528\u4e8e\u03b3\u5c04\u7ebf\u4ea7\u751f\u7684\u6676\u4f53 the undulators \u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002", "motivation": "\u8fc7\u6e21\u91d1\u5c5e\uff08\u5982\u949b\uff09\u5728\u5149\u58f0\u8f6c\u6362\u65b9\u9762\u6bd4\u8d35\u91d1\u5c5e\uff08\u5982\u94f6\uff09\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6027\u80fd\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fc7\u6e21\u91d1\u5c5e\u4e2d\u5149\u58f0\u6027\u80fd\u4f18\u5f02\u7684\u6750\u6599\uff0c\u5e76\u9a8c\u8bc1\u94bd\u7684\u4f18\u8d8a\u6027\u3002", "method": "\u901a\u8fc7\u98de\u79d2\u6fc0\u5149\u8109\u51b2\u6fc0\u53d1\u94bd\u8584\u819c\u4ea7\u751f\u7eb3\u7c73\u58f0\u5e94\u53d8\uff0c\u5e76\u5229\u7528\u6cf5\u6d66-\u63a2\u6d4b\u77ac\u6001\u53cd\u5c04\u5149\u8c31\u6d4b\u91cf\u5e03\u91cc\u6e0a\u632f\u8361\u6765\u6355\u83b7\u5149\u5b50-\u58f0\u5b50\u76f8\u4e92\u4f5c\u7528\uff0c\u4ece\u800c\u91cf\u5316\u5149\u58f0\u8f6c\u6362\u6548\u7387\uff0c\u5e76\u4e0e\u949b\u8584\u819c\u8fdb\u884c\u6bd4\u8f83\u3002\u540c\u65f6\uff0c\u91c7\u7528\u53cc\u6e29\u6a21\u578b\u548c\u6709\u9650\u5143\u5206\u6790\u76f8\u7ed3\u5408\u7684\u8ba1\u7b97\u65b9\u6cd5\u6765\u6a21\u62df\u6fc0\u5149\u8bf1\u5bfc\u5e94\u53d8\u53ca\u5176\u4f20\u64ad\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u548c\u6a21\u62df\u5747\u8868\u660e\uff0c\u94bd\u8584\u819c\u7684\u5149\u58f0\u8f6c\u6362\u6548\u7387\u4f18\u4e8e\u949b\u8584\u819c\u3002\u7814\u7a76\u8fd8\u8ba8\u8bba\u4e86\u91d1\u5c5e\u6362\u80fd\u5668-\u886c\u5e95\u58f0\u963b\u6297\u5339\u914d\u5bf9\u5149\u58f0\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u5229\u7528\u94bd\u8584\u819c\u751f\u6210\u53d7\u6fc0\u58f0\u8109\u51b2\u5e8f\u5217\u7528\u4e8e\u6676\u4f53 the undulators \u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u94bd(Tantalum)\u5728\u5149\u58f0\u8f6c\u6362\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u949b(Titanium)\u7b49\u8fc7\u6e21\u91d1\u5c5e\uff0c\u5e76\u4e14\u4e0e\u886c\u5e95\u7684\u58f0\u963b\u6297\u5339\u914d\u53ef\u4ee5\u7528\u4e8e\u5f00\u53d1\u7528\u4e8e\u03b3\u5c04\u7ebf\u4ea7\u751f\u7684\u6676\u4f53 the undulators\u3002"}}
{"id": "2507.14147", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.14147", "abs": "https://arxiv.org/abs/2507.14147", "authors": ["Kevin Monteiro", "Sam Nallaperuma-Herzberg", "Martina Mason", "Steve Niederer"], "title": "Graph Convolutional Neural Networks to Model the Brain for Insomnia", "comment": "12 pages, 6 figures. This version has been accepted as a full paper\n  at the 2025 AI in Healthcare (AIiH) Conference", "summary": "Insomnia affects a vast population of the world and can have a wide range of\ncauses. Existing treatments for insomnia have been linked with many side\neffects like headaches, dizziness, etc. As such, there is a clear need for\nimproved insomnia treatment. Brain modelling has helped with assessing the\neffects of brain pathology on brain network dynamics and with supporting\nclinical decisions in the treatment of Alzheimer's disease, epilepsy, etc.\nHowever, such models have not been developed for insomnia. Therefore, this\nproject attempts to understand the characteristics of the brain of individuals\nexperiencing insomnia using continuous long-duration EEG data. Brain networks\nare derived based on functional connectivity and spatial distance between EEG\nchannels. The power spectral density of the channels is then computed for the\nmajor brain wave frequency bands. A graph convolutional neural network (GCNN)\nmodel is then trained to capture the functional characteristics associated with\ninsomnia and configured for the classification task to judge performance.\nResults indicated a 50-second non-overlapping sliding window was the most\nsuitable choice for EEG segmentation. This approach achieved a classification\naccuracy of 70% at window level and 68% at subject level. Additionally, the\nomission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in\nmodel performance than the removal of other channels. These channel electrodes\nare positioned near brain regions known to exhibit atypical levels of\nfunctional connectivity in individuals with insomnia, which can explain such\nresults.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u8111\u7535\u56fe\u548c\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u8bc6\u522b\u5931\u7720\u75c7\u7684\u8111\u7f51\u7edc\u7279\u5f81\uff0c\u51c6\u786e\u7387\u8fbe70%\uff0c\u5e76\u786e\u5b9a\u4e86\u5173\u952e\u7535\u6781\u4f4d\u7f6e\u3002", "motivation": "\u73b0\u6709\u5931\u7720\u75c7\u6cbb\u7597\u5b58\u5728\u526f\u4f5c\u7528\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6cbb\u7597\u65b9\u6cd5\u3002\u8111\u6a21\u578b\u5728\u5176\u4ed6\u75be\u75c5\u7814\u7a76\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5c1a\u672a\u5e94\u7528\u4e8e\u5931\u7720\u75c7\u3002", "method": "\u901a\u8fc7\u5206\u6790\u957f\u65f6\u95f4\u8111\u7535\u56fe\u6570\u636e\uff0c\u6784\u5efa\u8111\u7f51\u7edc\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08GCNN\uff09\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u8bc6\u522b\u5931\u7720\u75c7\u7684\u7279\u5f81\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c50\u79d2\u65e0\u91cd\u53e0\u6ed1\u52a8\u7a97\u53e3\u6700\u9002\u5408\u8111\u7535\u56fe\u5206\u5272\uff0cGCNN\u6a21\u578b\u5728\u7a97\u53e3\u7ea7\u522b\u548c\u4e2a\u4f53\u7ea7\u522b\u7684\u5206\u7c7b\u51c6\u786e\u7387\u5206\u522b\u4e3a70%\u548c68%\u3002\u79fb\u9664C4-P4\u3001F4-C4\u548cC4-A1\u7535\u6781\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u6700\u5927\uff0c\u8fd9\u4e0e\u8fd9\u4e9b\u533a\u57df\u5728\u5931\u7720\u75c7\u60a3\u8005\u4e2d\u7684\u529f\u80fd\u8fde\u63a5\u5f02\u5e38\u6709\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u57fa\u4e8e\u8111\u7f51\u7edc\u5206\u6790\u7684\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u53ef\u4ee5\u533a\u5206\u5931\u7720\u75c7\u60a3\u8005\u548c\u5065\u5eb7\u4e2a\u4f53\uff0c\u5e76\u4e14 C4-P4\u3001F4-C4 \u548c C4-A1 \u7535\u6781\u4e0e\u5931\u7720\u75c7\u7684\u529f\u80fd\u8fde\u63a5\u5f02\u5e38\u6709\u5173\u3002"}}
{"id": "2507.14731", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14731", "abs": "https://arxiv.org/abs/2507.14731", "authors": ["Haitong Wang", "Aaron Hao Tan", "Angus Fung", "Goldie Nejat"], "title": "X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots", "comment": null, "summary": "Existing navigation methods are primarily designed for specific robot\nembodiments, limiting their generalizability across diverse robot platforms. In\nthis paper, we introduce X-Nav, a novel framework for end-to-end\ncross-embodiment navigation where a single unified policy can be deployed\nacross various embodiments for both wheeled and quadrupedal robots. X-Nav\nconsists of two learning stages: 1) multiple expert policies are trained using\ndeep reinforcement learning with privileged observations on a wide range of\nrandomly generated robot embodiments; and 2) a single general policy is\ndistilled from the expert policies via navigation action chunking with\ntransformer (Nav-ACT). The general policy directly maps visual and\nproprioceptive observations to low-level control commands, enabling\ngeneralization to novel robot embodiments. Simulated experiments demonstrated\nthat X-Nav achieved zero-shot transfer to both unseen embodiments and\nphotorealistic environments. A scalability study showed that the performance of\nX-Nav improves when trained with an increasing number of randomly generated\nembodiments. An ablation study confirmed the design choices of X-Nav.\nFurthermore, real-world experiments were conducted to validate the\ngeneralizability of X-Nav in real-world environments.", "AI": {"tldr": "X-Nav \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u7aef\u5230\u7aef\u8de8\u5177\u8eab\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u7b56\u7565\u84b8\u998f\uff0c\u4f7f\u5355\u4e00\u7b56\u7565\u53ef\u5e94\u7528\u4e8e\u4e0d\u540c\u673a\u5668\u4eba\uff08\u8f6e\u5f0f\u3001\u56db\u8db3\uff09\uff0c\u5e76\u6210\u529f\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u96f6\u6837\u672c\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u7279\u5b9a\u673a\u5668\u4eba\u5b9e\u4f53\u8bbe\u8ba1\uff0c\u6cdb\u5316\u6027\u6709\u9650\uff0c\u96be\u4ee5\u8de8\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u4f7f\u7528\u3002\u672c\u6587\u63d0\u51fa X-Nav \u6846\u67b6\uff0c\u65e8\u5728\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u8de8\u5177\u8eab\u5bfc\u822a\uff0c\u4f7f\u5355\u4e00\u7edf\u4e00\u7b56\u7565\u80fd\u591f\u5e94\u7528\u4e8e\u5305\u62ec\u8f6e\u5f0f\u548c\u56db\u8db3\u673a\u5668\u4eba\u5728\u5185\u7684\u591a\u79cd\u673a\u5668\u4eba\u5b9e\u4f53\u3002", "method": "X-Nav \u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u5b66\u4e60\u9636\u6bb5\u5b9e\u73b0\u8de8\u5177\u8eab\u5bfc\u822a\uff1a\u9996\u5148\uff0c\u5728\u5927\u91cf\u968f\u673a\u751f\u6210\u7684\u673a\u5668\u4eba\u5177\u8eab\uff08\u5305\u62ec\u8f6e\u5f0f\u548c\u56db\u8db3\u673a\u5668\u4eba\uff09\u4e0a\uff0c\u5229\u7528\u5177\u6709\u7279\u6743\u89c2\u5bdf\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u591a\u4e2a\u4e13\u5bb6\u7b56\u7565\uff1b\u7136\u540e\uff0c\u901a\u8fc7\u5bfc\u822a\u52a8\u4f5c\u5206\u5757\uff08Nav-ACT\uff09\u6280\u672f\uff0c\u4ece\u8fd9\u4e9b\u4e13\u5bb6\u7b56\u7565\u4e2d\u84b8\u998f\u51fa\u5355\u4e00\u7684\u901a\u7528\u7b56\u7565\u3002\u8be5\u901a\u7528\u7b56\u7565\u80fd\u591f\u5c06\u89c6\u89c9\u548c\u672c\u4f53\u611f\u89c9\u89c2\u5bdf\u76f4\u63a5\u6620\u5c04\u5230\u4f4e\u7ea7\u63a7\u5236\u547d\u4ee4\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u65b0\u5177\u8eab\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0cX-Nav \u5bf9\u672a\u89c1\u8fc7\u7684\u673a\u5668\u4eba\u5b9e\u4f53\u548c\u5149\u7167\u903c\u771f\u7684\u73af\u5883\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u8fc1\u79fb\u3002\u53ef\u6269\u5c55\u6027\u7814\u7a76\u8868\u660e\uff0c\u968f\u7740\u8bad\u7ec3\u6570\u636e\u7684\u589e\u52a0\uff0cX-Nav \u7684\u6027\u80fd\u5f97\u5230\u63d0\u5347\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86 X-Nav \u7684\u8bbe\u8ba1\u9009\u62e9\u3002\u6b64\u5916\uff0c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e5f\u9a8c\u8bc1\u4e86 X-Nav \u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "X-Nav \u6846\u67b6\u5b9e\u73b0\u4e86\u8de8\u5177\u8eab\u5bfc\u822a\u7684\u7aef\u5230\u7aef\u901a\u7528\u6027\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u968f\u7740\u8bad\u7ec3\u5177\u8eab\u6570\u91cf\u7684\u589e\u52a0\uff0c\u6027\u80fd\u6709\u6240\u63d0\u5347\u3002"}}
{"id": "2507.14454", "categories": ["cs.CV", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.14454", "abs": "https://arxiv.org/abs/2507.14454", "authors": ["Han Gong", "Qiyue Li", "Jie Li", "Zhi Liu"], "title": "Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation", "comment": null, "summary": "3D Gaussian splatting video (3DGS) streaming has recently emerged as a\nresearch hotspot in both academia and industry, owing to its impressive ability\nto deliver immersive 3D video experiences. However, research in this area is\nstill in its early stages, and several fundamental challenges, such as tiling,\nquality assessment, and bitrate adaptation, require further investigation. In\nthis paper, we tackle these challenges by proposing a comprehensive set of\nsolutions. Specifically, we propose an adaptive 3DGS tiling technique guided by\nsaliency analysis, which integrates both spatial and temporal features. Each\ntile is encoded into versions possessing dedicated deformation fields and\nmultiple quality levels for adaptive selection. We also introduce a novel\nquality assessment framework for 3DGS video that jointly evaluates\nspatial-domain degradation in 3DGS representations during streaming and the\nquality of the resulting 2D rendered images. Additionally, we develop a\nmeta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS\nvideo streaming, achieving optimal performance across varying network\nconditions. Extensive experiments demonstrate that our proposed approaches\nsignificantly outperform state-of-the-art methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u89e3\u51b3\u4e863DGS\u89c6\u9891\u6d41\u5f0f\u4f20\u8f93\u4e2d\u7684\u5207\u7247\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u6bd4\u7279\u7387\u9002\u5e94\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u663e\u8457\u6027\u5206\u6790\u7684\u81ea\u9002\u5e94\u5207\u7247\u6280\u672f\u3001\u4e00\u79cd\u65b0\u7684\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\u548c\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u6bd4\u7279\u7387\u7b97\u6cd5\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "3DGS\u89c6\u9891\u6d41\u5f0f\u4f20\u8f93\u9886\u57df\u7684\u7814\u7a76\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u5728\u5207\u7247\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u6bd4\u7279\u7387\u9002\u5e94\u7b49\u65b9\u9762\u5b58\u5728\u57fa\u672c\u6311\u6218\u3002", "method": "\u901a\u8fc7\u663e\u8457\u6027\u5206\u6790\u6307\u5bfc\u7684\u81ea\u9002\u5e943DGS\u5207\u7247\u6280\u672f\uff0c\u7ed3\u5408\u7a7a\u95f4\u548c\u65f6\u95f4\u7279\u5f81\uff0c\u4e3a\u6bcf\u4e2a\u5207\u7247\u7f16\u7801\u5177\u6709\u4e13\u7528\u53d8\u5f62\u573a\u548c\u591a\u7ea7\u8d28\u91cf\u7684\u7248\u672c\uff1b\u5f15\u5165\u4e86\u4e00\u4e2a\u8054\u5408\u8bc4\u4f303DGS\u8868\u793a\u4e2d\u7684\u7a7a\u95f4\u57df\u9000\u5316\u548c2D\u6e32\u67d3\u56fe\u50cf\u8d28\u91cf\u7684\u65b0\u9896\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff1b\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u6bd4\u7279\u7387\u7b97\u6cd5\uff0c\u4ee5\u9002\u5e943DGS\u89c6\u9891\u6d41\u5f0f\u4f20\u8f93\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5207\u7247\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u6bd4\u7279\u7387\u9002\u5e94\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u5e76\u5728\u5927\u91cf\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e943DGS\u5207\u7247\u6280\u672f\uff0c\u8be5\u6280\u672f\u7531\u663e\u8457\u6027\u5206\u6790\u6307\u5bfc\uff0c\u5e76\u7ed3\u5408\u4e86\u7a7a\u95f4\u548c\u65f6\u95f4\u7279\u5f81\u3002\u6bcf\u4e2a\u5207\u7247\u88ab\u7f16\u7801\u4e3a\u5177\u6709\u4e13\u7528\u53d8\u5f62\u573a\u548c\u591a\u4e2a\u8d28\u91cf\u7ea7\u522b\u7684\u7248\u672c\uff0c\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\u9009\u62e9\u3002\u6b64\u5916\uff0c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u9896\u76843DGS\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u6d41\u5f0f\u4f20\u8f93\u671f\u95f4\u8054\u5408\u8bc4\u4f303DGS\u8868\u793a\u4e2d\u7684\u7a7a\u95f4\u57df\u9000\u5316\u4ee5\u53ca\u751f\u6210\u76842D\u6e32\u67d3\u56fe\u50cf\u7684\u8d28\u91cf\u3002\u7814\u7a76\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u4e13\u95e8\u9488\u5bf93DGS\u89c6\u9891\u6d41\u5f0f\u4f20\u8f93\u7684\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u6bd4\u7279\u7387\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u4e0d\u540c\u7684\u7f51\u7edc\u6761\u4ef6\u4e0b\u5747\u80fd\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14468", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14468", "abs": "https://arxiv.org/abs/2507.14468", "authors": ["Yitong Lin", "Jiaying He", "Jiahe Chen", "Xinnan Zhu", "Jianwei Zheng", "Tao Bo"], "title": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning", "comment": "Accepted by Bioinformatics on July 11th", "summary": "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery\nand disease understanding, yet their completion and reasoning are challenging.\nKnowledge Embedding (KE) methods capture global semantics but struggle with\ndynamic structural integration, while Graph Neural Networks (GNNs) excel\nlocally but often lack semantic understanding. Even ensemble approaches,\nincluding those leveraging language models, often fail to achieve a deep,\nadaptive, and synergistic co-evolution between semantic comprehension and\nstructural learning. Addressing this critical gap in fostering continuous,\nreciprocal refinement between these two aspects in complex biomedical KGs is\nparamount.\n  Results: We introduce BioGraphFusion, a novel framework for deeply\nsynergistic semantic and structural learning. BioGraphFusion establishes a\nglobal semantic foundation via tensor decomposition, guiding an LSTM-driven\nmechanism to dynamically refine relation embeddings during graph propagation.\nThis fosters adaptive interplay between semantic understanding and structural\nlearning, further enhanced by query-guided subgraph construction and a hybrid\nscoring mechanism. Experiments across three key biomedical tasks demonstrate\nBioGraphFusion's superior performance over state-of-the-art KE, GNN, and\nensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)\nhighlights its ability to unveil biologically meaningful pathways.\n  Availability and Implementation: Source code and all training data are freely\navailable for download at https://github.com/Y-TARL/BioGraphFusion.\n  Contact: zjw@zjut.edu.cn, botao666666@126.com.\n  Supplementary information: Supplementary data are available at Bioinformatics\nonline.", "AI": {"tldr": "BioGraphFusion \u6846\u67b6\u901a\u8fc7\u6df1\u5ea6\u534f\u540c\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u7684\u6027\u80fd\uff0c\u5e76\u5728\u63ed\u793a\u751f\u7269\u901a\u8def\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31 (KG) \u5bf9\u4e8e\u836f\u7269\u53d1\u73b0\u548c\u75be\u75c5\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u8865\u5168\u548c\u63a8\u7406\u5145\u6ee1\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u4e4b\u95f4\u7684\u6df1\u5ea6\u3001\u81ea\u9002\u5e94\u548c\u534f\u540c\u7684\u5171\u540c\u6f14\u5316\u3002", "method": "BioGraphFusion \u901a\u8fc7\u5f20\u91cf\u5206\u89e3\u5efa\u7acb\u5168\u5c40\u8bed\u4e49\u57fa\u7840\uff0c\u5e76\u901a\u8fc7 LSTM \u9a71\u52a8\u7684\u673a\u5236\u5728\u56fe\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u52a8\u6001\u5730\u4f18\u5316\u5173\u7cfb\u5d4c\u5165\u3002\u67e5\u8be2\u5f15\u5bfc\u7684\u5b50\u56fe\u6784\u5efa\u548c\u6df7\u5408\u8bc4\u5206\u673a\u5236\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u4e4b\u95f4\u7684\u81ea\u9002\u5e94\u76f8\u4e92\u4f5c\u7528\u3002", "result": "BioGraphFusion \u5728\u4e09\u4e2a\u5173\u952e\u7684\u751f\u7269\u533b\u5b66\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165 (KE)\u3001\u56fe\u795e\u7ecf\u7f51\u7edc (GNN) \u548c\u96c6\u6210\u6a21\u578b\u3002", "conclusion": "BioGraphFusion\u5728\u63ed\u793a\u751f\u7269\u5b66\u4e0a\u6709\u610f\u4e49\u7684\u901a\u8def\u65b9\u9762\u663e\u793a\u51fa\u5176\u80fd\u529b\u3002"}}
{"id": "2507.14977", "categories": ["cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14977", "abs": "https://arxiv.org/abs/2507.14977", "authors": ["Chaimae Chrirou", "Abderrahim El Allati", "Robert S Whitney"], "title": "Potential barriers are nearly-ideal quantum thermoelectrics at finite power output", "comment": "11 pages, 6 figures", "summary": "Quantum thermodynamics defines the ideal quantum thermoelectric, with maximum\npossible efficiency at finite power output. However, such an ideal\nthermoelectric is challenging to implement experimentally. Instead, here we\nconsider two types of thermoelectrics regularly implemented in experiments: (i)\nfinite-height potential barriers or quantum point contacts, and (ii)\ndouble-barrier structures or single-level quantum dots. We model them with\nLandauer scattering theory as (i) step transmissions and (ii) Lorentzian\ntransmissions. We optimize their thermodynamic efficiency for any given power\noutput, when they are used as thermoelectric heat-engines or refrigerators. The\nLorentzian's efficiency is excellent at vanishing power, but we find that it is\npoor at the finite powers of practical interest. In contrast, the step\ntransmission is remarkably close to ideal efficiency (typically within 15%) at\nall power outputs. The step transmission is also close to ideal in the presence\nof phonons and other heat-leaks, for which the Lorentzian performs very poorly.\nThus, a simple nanoscale thermoelectric - made with a potential barrier or\nquantum point contact - is almost as efficient as an ideal thermoelectric.", "AI": {"tldr": "\u5b9e\u9a8c\u4e2d\u5e38\u7528\u7684\u9636\u8dc3\u900f\u5c04\u70ed\u7535\u5668\u4ef6\u6548\u7387\u63a5\u8fd1\u7406\u60f3\u503c\uff0c\u800c\u6d1b\u4f26\u5179\u900f\u5c04\u6548\u7387\u4e0d\u4f73\u3002", "motivation": "\u91cf\u5b50\u70ed\u529b\u5b66\u5b9a\u4e49\u4e86\u5177\u6709\u6700\u5927\u53ef\u80fd\u6548\u7387\u7684\u7406\u60f3\u91cf\u5b50\u70ed\u7535\u5668\u4ef6\uff0c\u4f46\u5176\u96be\u4ee5\u5b9e\u73b0\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u8003\u8651\u4e24\u79cd\u5b9e\u9a8c\u4e2d\u5e38\u7528\u7684\u70ed\u7535\u5668\u4ef6\uff1a(i) \u6709\u9650\u9ad8\u5ea6\u52bf\u5792\u6216\u91cf\u5b50\u70b9\u63a5\u89e6\uff0c\u4ee5\u53ca (ii) \u53cc\u52bf\u5792\u7ed3\u6784\u6216\u5355\u5c42\u91cf\u5b50\u70b9\u3002", "method": "\u4f7f\u7528 Landauer \u6563\u5c04\u7406\u8bba\u5c06\u5b9e\u9a8c\u4e2d\u5e38\u7528\u7684\u4e24\u79cd\u70ed\u7535\u5668\u4ef6\u5efa\u6a21\u4e3a\uff08i\uff09\u9636\u8dc3\u900f\u5c04\u548c\uff08ii\uff09\u6d1b\u4f26\u5179\u900f\u5c04\u3002", "result": "\u9636\u8dc3\u900f\u5c04\u5728\u6240\u6709\u529f\u7387\u8f93\u51fa\u4e0b\u90fd\u975e\u5e38\u63a5\u8fd1\u7406\u60f3\u6548\u7387\uff0c\u800c\u6d1b\u4f26\u5179\u900f\u5c04\u5728\u5b9e\u9645\u529f\u7387\u4e0b\u6548\u7387\u4e0d\u4f73\u3002\u9636\u8dc3\u900f\u5c04\u5728\u5b58\u5728\u58f0\u5b50\u548c\u5176\u4ed6\u70ed\u6cc4\u6f0f\u7684\u60c5\u51b5\u4e0b\u4e5f\u63a5\u8fd1\u7406\u60f3\u6548\u7387\uff0c\u800c\u6d1b\u4f26\u5179\u900f\u5c04\u8868\u73b0\u5f88\u5dee\u3002", "conclusion": "\u7b80\u5355\u7684\u7eb3\u7c73\u70ed\u7535\u5668\u4ef6\uff0c\u5982\u52bf\u5792\u6216\u91cf\u5b50\u70b9\u63a5\u89e6\uff0c\u5728\u6240\u6709\u529f\u7387\u8f93\u51fa\u4e0b\u6548\u7387\u90fd\u63a5\u8fd1\u7406\u60f3\u503c\uff0c\u5176\u6548\u7387\u901a\u5e38\u5728\u7406\u60f3\u6548\u7387\u7684 15% \u4ee5\u5185\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6d1b\u4f26\u5179\u900f\u5c04\u7684\u6548\u7387\u5728\u4f4e\u529f\u7387\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u7684\u6709\u9650\u529f\u7387\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2507.15658", "categories": ["cs.DS", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15658", "abs": "https://arxiv.org/abs/2507.15658", "authors": ["Romain Cosson", "Laurent Massouli\u00e9"], "title": "Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound", "comment": null, "summary": "We study the problem of collective tree exploration in which a team of $k$\nmobile agents must collectively visit all nodes of an unknown tree in as few\nmoves as possible. The agents all start from the root and discover adjacent\nedges as they progress in the tree. Communication is distributed in the sense\nthat agents share information by reading and writing on whiteboards located at\nall nodes. Movements are asynchronous, in the sense that the speeds of all\nagents are controlled by an adversary at all times. All previous competitive\nguarantees for collective tree exploration are either distributed but\nsynchronous, or asynchronous but centralized. In contrast, we present a\ndistributed asynchronous algorithm that explores any tree of $n$ nodes and\ndepth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear\nin $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e.,\nwith a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is\nasymptotically optimal (i.e., $1$-competitive) from the perspective of\naverage-case complexity. We then present a new general lower bound on the\ncompetitive ratio of asynchronous collective tree exploration, in\n$\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and\ncentralized settings, and improves upon the previous lower bound in\n$\\Omega(\\log k)$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8ek\u4e2a\u79fb\u52a8\u4ee3\u7406\u5728\u672a\u77e5\u6811\u4e2d\u8fdb\u884c\u5206\u5e03\u5f0f\u5f02\u6b65\u63a2\u7d22\u7684\u7b97\u6cd5\uff0c\u5176\u79fb\u52a8\u6b21\u6570\u4e0a\u9650\u4e3a $2n+O(k^2 2^kD)$\uff0c\u7ade\u4e89\u6bd4\u4e3a $O(k/\text{log} k)$\u3002\u540c\u65f6\uff0c\u4e5f\u63d0\u51fa\u4e86\u65b0\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c $\text{Omega}(\text{log}^2 k)$\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u672a\u77e5\u6811\u4e2d\u96c6\u4f53\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u7814\u7a76\u56e2\u961f\u5f00\u53d1\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u4ee5\u5c3d\u53ef\u80fd\u5c11\u7684\u79fb\u52a8\u6b21\u6570\u8bbf\u95ee\u6811\u4e2d\u7684\u6240\u6709\u8282\u70b9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u4e00\u5b9a\u7684\u6539\u8fdb\u3002\u5177\u4f53\u7b97\u6cd5\u7ec6\u8282\u672a\u5728\u6458\u8981\u4e2d\u8be6\u8ff0\uff0c\u4f46\u63d0\u5230\u4e86\u5176\u5728\u63a2\u7d22\u672a\u77e5\u6811\u65f6\u7684\u79fb\u52a8\u6b21\u6570\u548c\u7ade\u4e89\u6bd4\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\u53ef\u4ee5\u5728 $2n+O(k^2 2^kD)$ \u6b21\u79fb\u52a8\u5185\u63a2\u7d22\u4efb\u610f\u6811\uff0c\u5e76\u4e14\u6709\u4e00\u79cd\u6539\u8fdb\u7b97\u6cd5\u7684\u7ade\u4e89\u6bd4\u4e3a $O(k/\text{log} k)$\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u65b0\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c $\text{Omega}(\text{log}^2 k)$\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5728 $2n+O(k^2 2^kD)$ \u6b21\u79fb\u52a8\u5185\u63a2\u7d22\u5305\u542b $n$ \u4e2a\u8282\u70b9\u548c\u6df1\u5ea6 $D$ \u7684\u4efb\u610f\u6811\uff0c\u5176\u9057\u61be\u662f $D$ \u7684\u7ebf\u6027\u51fd\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7b97\u6cd5\uff0c\u5176\u4fdd\u8bc1\u4e3a $O(k/\text{log} k)(n+kD)$\uff0c\u7ade\u4e89\u6bd4\u4e3a $O(k/\text{log} k)$\u3002\u672c\u6587\u8fd8\u4e3a\u5f02\u6b65\u5206\u5e03\u5f0f\u6811\u63a2\u7d22\u63d0\u51fa\u4e86\u65b0\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c $\text{Omega}(\text{log}^2 k)$\uff0c\u8be5\u4e0b\u754c\u540c\u6837\u9002\u7528\u4e8e\u96c6\u4e2d\u5f0f\u8bbe\u7f6e\uff0c\u5e76\u6539\u8fdb\u4e86\u5148\u524d $\text{Omega}(\text{log} k)$ \u7684\u4e0b\u754c\u3002"}}
{"id": "2507.14182", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14182", "abs": "https://arxiv.org/abs/2507.14182", "authors": ["Xiaotong Luo", "Shengda Zhuo", "Min Chen", "Lichun Li", "Ruizhao Lu", "Wenqi Fan", "Shuqiang Huang", "Yin Tang"], "title": "From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling", "comment": null, "summary": "Financial markets exhibit highly dynamic and complex behaviors shaped by both\nhistorical price trajectories and exogenous narratives, such as news, policy\ninterpretations, and social media sentiment. The heterogeneity in these data\nand the diverse insight of investors introduce biases that complicate the\nmodeling of market dynamics. Unlike prior work, this paper explores the\npotential of bull and bear regimes in investor-driven market dynamics. Through\nempirical analysis on real-world financial datasets, we uncover a dynamic\nrelationship between bias variation and behavioral adaptation, which enhances\ntrend prediction under evolving market conditions. To model this mechanism, we\npropose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified\nframework that jointly embeds temporal price sequences and external contextual\nsignals into a shared latent space where opposing bull and bear forces\nnaturally emerge, forming the foundation for bias representation. Within this\nspace, an inertial pairing module pairs temporally adjacent samples to preserve\nmomentum, while the dual competition mechanism contrasts bullish and bearish\nembeddings to capture behavioral divergence. Together, these components allow\nB4 to model bias-driven asymmetry, behavioral inertia, and market\nheterogeneity. Experimental results on real-world financial datasets\ndemonstrate that our model not only achieves superior performance in predicting\nmarket trends but also provides interpretable insights into the interplay of\nbiases, investor behaviors, and market dynamics.", "AI": {"tldr": "B4\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u5386\u53f2\u4ef7\u683c\u548c\u5916\u90e8\u4fe1\u53f7\uff0c\u8003\u8651\u4e86\u725b\u5e02\u548c\u718a\u5e02\u4e2d\u7684\u6295\u8d44\u8005\u504f\u89c1\uff0c\u5e76\u80fd\u9884\u6d4b\u5e02\u573a\u8d8b\u52bf\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u7684\u52a8\u6001\u548c\u590d\u6742\u6027\uff0c\u6295\u8d44\u8005\u7fa4\u4f53\u7684\u5f02\u8d28\u6027\u548c\u504f\u89c1\u4f7f\u5efa\u6a21\u590d\u6742\u5316\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u725b\u5e02\u548c\u718a\u5e02\u72b6\u6001\u5728\u6295\u8d44\u8005\u9a71\u52a8\u7684\u5e02\u573a\u52a8\u6001\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aB4\uff08Bias to Behavior from Bull-Bear Dynamics\uff09\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u65f6\u95f4\u4ef7\u683c\u5e8f\u5217\u548c\u5916\u90e8\u4e0a\u4e0b\u6587\u4fe1\u53f7\u5171\u540c\u5d4c\u5165\u5230\u4e00\u4e2a\u5171\u4eab\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u725b\u5e02\u548c\u718a\u5e02\u7684\u529b\u91cf\u81ea\u7136\u51fa\u73b0\uff0c\u4ece\u800c\u4e3a\u504f\u89c1\u8868\u793a\u5960\u5b9a\u57fa\u7840\u3002\u5728\u6b64\u7a7a\u95f4\u5185\uff0c\u60ef\u6027\u914d\u5bf9\u6a21\u5757\u914d\u5bf9\u65f6\u95f4\u4e0a\u76f8\u90bb\u7684\u6837\u672c\u4ee5\u4fdd\u6301\u52a8\u91cf\uff0c\u800c\u53cc\u91cd\u7ade\u4e89\u673a\u5236\u5219\u5bf9\u6bd4\u725b\u5e02\u548c\u718a\u5e02\u7684\u5d4c\u5165\u4ee5\u6355\u6349\u884c\u4e3a\u5dee\u5f02\u3002", "result": "B4\u6a21\u578b\u5728\u9884\u6d4b\u5e02\u573a\u8d8b\u52bf\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u5bf9\u5e02\u573a\u8d8b\u52bf\u7684\u9884\u6d4b\uff0c\u5e76\u5bf9\u504f\u89c1\u3001\u6295\u8d44\u8005\u884c\u4e3a\u548c\u5e02\u573a\u52a8\u6001\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14536", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14536", "abs": "https://arxiv.org/abs/2507.14536", "authors": ["Aarti Lakhara", "Lars Thole", "Rolf J. Haug", "P. A. Bhobe"], "title": "Metal-Insulator transition and Charge Transport Mechanisms in SnSe$_2$ Field-Effect Transistor", "comment": "5 pages, 5 figures, supplementary text", "summary": "We report an observation of metal-insulator transition in a thin film of\nSnSe$_2$. The room-temperature carrier concentration of SnSe$_2$ film was\nincreased by electrostatic doping to 1.14$\\times$ 10$^{13}$ cm$^{-2}$. A\ncrossover from insulating phase to metallic state was clearly observed. The\nlow-temperature charge transport mechanism is governed by two-dimensional (2D)\nvariable-range hopping. This mechanism is influenced by band bending and gap\nstates introduced by selenium vacancies. At low temperatures, the mobility is\nprimarily limited by charged impurities, while at higher temperatures, it\nfollows a power-law dependence, $\\mu = T^{-\\gamma}$, indicating a dominance of\nelectron-phonon scattering. The application of a gate field shifts the Fermi\nlevel toward the conduction band, and at sufficiently high temperatures, this\ndrives the system into a metallic state. Our findings offer insights into the\ncharge transport mechanisms in SnSe$_2$ FET, this understanding will allow for\nthe optimization of other 2D materials for advanced electronic device\napplications.", "AI": {"tldr": "\u901a\u8fc7\u9759\u7535\u63ba\u6742\uff0c\u5728SnSe$_2$\u8584\u819c\u4e2d\u5b9e\u73b0\u4e86\u91d1\u5c5e-\u7edd\u7f18\u4f53\u8f6c\u53d8\uff0c\u5e76\u5206\u6790\u4e86\u5176\u7535\u8377\u4f20\u8f93\u673a\u5236\u3002", "motivation": "\u4e3a\u4e86\u7406\u89e3SnSe$_2$\u8584\u819c\u4e2d\u7684\u91d1\u5c5e-\u7edd\u7f18\u4f53\u8f6c\u53d8\u53ca\u5176\u7535\u8377\u4f20\u8f93\u673a\u5236\uff0c\u4e3a\u4f18\u5316\u4e8c\u7ef4\u6750\u6599\u5728\u7535\u5b50\u5668\u4ef6\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u9759\u7535\u63ba\u6742\u63d0\u9ad8SnSe$_2$\u8584\u819c\u7684\u8f7d\u6d41\u5b50\u6d53\u5ea6\uff0c\u5e76\u5229\u7528\u4f4e\u6e29\u7535\u8377\u8f93\u8fd0\u673a\u5236\uff08\u4e8c\u7ef4\u53ef\u53d8\u7a0b\u8df3\u8dc3\uff09\u3001\u80fd\u5e26\u5f2f\u66f2\u3001\u7852\u7a7a\u4f4d\u5f15\u5165\u7684\u80fd\u9699\u6001\u3001\u5e26\u7535\u6742\u8d28\u4ee5\u53ca\u7535\u5b50-\u58f0\u5b50\u6563\u5c04\u6765\u5206\u6790\u5176\u7535\u8377\u4f20\u8f93\u7279\u6027\u3002", "result": "\u5728SnSe$_2$\u8584\u819c\u4e2d\u89c2\u5bdf\u5230\u4e86\u4ece\u7edd\u7f18\u76f8\u5230\u91d1\u5c5e\u6001\u7684\u8f6c\u53d8\uff0c\u5e76\u786e\u5b9a\u4e86\u5176\u4f4e\u6e29\u7535\u8377\u4f20\u8f93\u673a\u5236\u4e3a\u4e8c\u7ef4\u53ef\u53d8\u7a0b\u8df3\u8dc3\uff0c\u8be5\u673a\u5236\u53d7\u80fd\u5e26\u5f2f\u66f2\u548c\u7852\u7a7a\u4f4d\u5f15\u5165\u7684\u80fd\u9699\u6001\u5f71\u54cd\u3002\u540c\u65f6\uff0c\u7814\u7a76\u4e5f\u63ed\u793a\u4e86\u5728\u4e0d\u540c\u6e29\u5ea6\u4e0b\u9650\u5236\u8fc1\u79fb\u7387\u7684\u56e0\u7d20\uff08\u4f4e\u6e29\u4e0b\u4e3a\u5e26\u7535\u6742\u8d28\uff0c\u9ad8\u6e29\u4e0b\u4e3a\u7535\u5b50-\u58f0\u5b50\u6563\u5c04\uff09\uff0c\u5e76\u6307\u51fa\u6805\u6781\u573a\u53ef\u4ee5\u9a71\u52a8\u7cfb\u7edf\u8fdb\u5165\u91d1\u5c5e\u6001\u3002", "conclusion": "\u672c\u7814\u7a76\u89c2\u5bdf\u5230\u4e86SnSe$_2$\u8584\u819c\u4e2d\u7684\u91d1\u5c5e-\u7edd\u7f18\u4f53\u8f6c\u53d8\uff0c\u5e76\u6df1\u5165\u4e86\u89e3\u4e86\u5176\u7535\u8377\u4f20\u8f93\u673a\u5236\uff0c\u4e3a\u4f18\u5316\u5176\u4ed6\u4e8c\u7ef4\u6750\u6599\u5728\u7535\u5b50\u5668\u4ef6\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2507.14800", "categories": ["eess.SY", "cs.AI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14800", "abs": "https://arxiv.org/abs/2507.14800", "authors": ["Xu Yang", "Chenhui Lin", "Haotian Liu", "Qi Wang", "Wenchuan Wu"], "title": "Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control", "comment": null, "summary": "With the advanced reasoning and information analysis capabilities, large\nlanguage models (LLMs) can offer a novel approach for the autonomous generation\nof dispatch strategies in power systems. This letter proposes an LLM-based\nexperience-driven voltage control solution for distribution networks, which\nenables the self-evolution of LLM-based voltage control strategies through the\ncollaboration and interaction of multiple modules-specifically, experience\nstorage, experience retrieval, experience generation, and experience\nmodification. Comprehensive experimental results validate the effectiveness of\nthe proposed method and highlight the applicability of LLM in addressing power\nsystem dispatch challenges.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e LLM \u7684\u7ecf\u9a8c\u9a71\u52a8\u7535\u538b\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6a21\u5757\u534f\u4f5c\u5b9e\u73b0\u7b56\u7565\u81ea\u6f14\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5148\u8fdb\u7684\u63a8\u7406\u548c\u4fe1\u606f\u5206\u6790\u80fd\u529b\uff0c\u4e3a\u7535\u529b\u7cfb\u7edf\u81ea\u4e3b\u751f\u6210\u8c03\u5ea6\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e LLM \u7684\u7ecf\u9a8c\u9a71\u52a8\u7684\u7535\u538b\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ecf\u9a8c\u5b58\u50a8\u3001\u7ecf\u9a8c\u68c0\u7d22\u3001\u7ecf\u9a8c\u751f\u6210\u548c\u7ecf\u9a8c\u4fee\u6539\u7b49\u591a\u4e2a\u6a21\u5757\u7684\u534f\u4f5c\u548c\u4ea4\u4e92\uff0c\u5b9e\u73b0 LLM \u57fa\u7535\u538b\u63a7\u5236\u7b56\u7565\u7684\u81ea\u6f14\u5316\u3002", "result": "LLM \u5728\u89e3\u51b3\u7535\u529b\u7cfb\u7edf\u8c03\u5ea6\u6311\u6218\u65b9\u9762\u5177\u6709\u9002\u7528\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5 \u7684\u6709\u6548\u6027\uff0c\u5e76\u7a81\u51fa\u4e86 LLM \u5728\u89e3\u51b3\u7535\u529b\u7cfb\u7edf\u8c03\u5ea6\u6311\u6218\u65b9\u9762\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2507.14304", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14304", "abs": "https://arxiv.org/abs/2507.14304", "authors": ["Rakesh Paul", "Anusha Kamath", "Kanishk Singla", "Raviraj Joshi", "Utkarsh Vaidya", "Sanjay Singh Chauhan", "Niranjan Wartikar"], "title": "Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study", "comment": null, "summary": "Multilingual large language models (LLMs) often demonstrate a performance gap\nbetween English and non-English languages, particularly in low-resource\nsettings. Aligning these models to low-resource languages is essential yet\nchallenging due to limited high-quality data. While English alignment datasets\nare readily available, curating equivalent data in other languages is expensive\nand time-consuming. A common workaround is to translate existing English\nalignment data; however, standard translation techniques often fail to preserve\ncritical elements such as code, mathematical expressions, and structured\nformats like JSON. In this work, we investigate LLM-based selective\ntranslation, a technique that selectively translates only the translatable\nparts of a text while preserving non-translatable content and sentence\nstructure. We conduct a systematic study to explore key questions around this\napproach, including its effectiveness compared to vanilla translation, the\nimportance of filtering noisy outputs, and the benefits of mixing translated\nsamples with original English data during alignment. Our experiments focus on\nthe low-resource Indic language Hindi and compare translations generated by\nGoogle Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the\npromise of selective translation as a practical and effective method for\nimproving multilingual alignment in LLMs.", "AI": {"tldr": "LLM\u9009\u62e9\u6027\u7ffb\u8bd1\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4ee3\u7801\u548c\u6570\u5b66\u516c\u5f0f\u7b49\u975e\u7ffb\u8bd1\u5185\u5bb9\u65f6\uff0c\u76f8\u6bd4\u4f20\u7edf\u7ffb\u8bd1\u65b9\u6cd5\u66f4\u5177\u4f18\u52bf\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u975e\u82f1\u8bed\u8bed\u8a00\uff08\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\uff09\u7684\u8868\u73b0\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\u3002\u76f4\u63a5\u83b7\u53d6\u9ad8\u8d28\u91cf\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u9f50\u6570\u636e\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\uff0c\u800c\u76f4\u63a5\u7ffb\u8bd1\u82f1\u6587\u5bf9\u9f50\u6570\u636e\u53c8\u53ef\u80fd\u4e22\u5931\u4ee3\u7801\u3001\u6570\u5b66\u516c\u5f0f\u548cJSON\u7b49\u5173\u952e\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5bf9\u9f50\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u57fa\u4e8eLLM\u7684\u9009\u62e9\u6027\u7ffb\u8bd1\u6280\u672f\uff0c\u5bf9\u6587\u672c\u4e2d\u7684\u53ef\u7ffb\u8bd1\u90e8\u5206\u8fdb\u884c\u7ffb\u8bd1\uff0c\u540c\u65f6\u4fdd\u7559\u975e\u7ffb\u8bd1\u5185\u5bb9\uff08\u5982\u4ee3\u7801\u3001\u6570\u5b66\u516c\u5f0f\u3001JSON\uff09\u548c\u53e5\u5b50\u7ed3\u6784\u3002\u901a\u8fc7\u5bf9\u6bd4Google Cloud Translation (GCP)\u548cLlama-3.1-405B\u4e24\u79cd\u7ffb\u8bd1\u5668\u5728Hindi\u8bed\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u8be5\u65b9\u6cd5\u4e0e\u6807\u51c6\u7ffb\u8bd1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u5bf9\u6bd4\u3001\u8fc7\u6ee4\u566a\u58f0\u8f93\u51fa\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u5728\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u6df7\u5408\u7ffb\u8bd1\u6837\u672c\u4e0e\u539f\u59cb\u82f1\u6587\u6570\u636e\u7684\u76ca\u5904\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u9009\u62e9\u6027\u7ffb\u8bd1\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u591a\u8bed\u8a00LLMs\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u5bf9\u9f50\u8868\u73b0\u3002\u8be5\u65b9\u6cd5\u5728Hindi\u8bed\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u4e14\u8fc7\u6ee4\u566a\u58f0\u548c\u6df7\u5408\u6570\u636e\u80fd\u8fdb\u4e00\u6b65\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u5728\u4ee3\u7801\u3001\u6570\u5b66\u516c\u5f0f\u548cJSON\u7b49\u7ed3\u6784\u5316\u6570\u636e\u65b9\u9762\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u9009\u62e9\u6027\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u7ffb\u8bd1\u53ef\u7ffb\u8bd1\u90e8\u5206\u5e76\u4fdd\u7559\u539f\u6587\u7ed3\u6784\u548c\u975e\u7ffb\u8bd1\u5185\u5bb9\uff0c\u4ee5\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u9f50\u6570\u636e\u7684\u7f3a\u4e4f\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Hindi\u8bed\u4e0a\u76f8\u6bd4\u4f20\u7edf\u7ffb\u8bd1\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fc7\u6ee4\u566a\u58f0\u548c\u6df7\u5408\u6570\u636e\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.15434", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.15434", "abs": "https://arxiv.org/abs/2507.15434", "authors": ["Yi-Ting Hsieh", "Mong-Jen Kao", "Jhong-Yun Liu", "Hung-Lung Wang"], "title": "Job Scheduling under Base and Additional Fees, with Applications to Mixed-Criticality Scheduling", "comment": null, "summary": "We are concerned with the problem of scheduling $n$ jobs onto $m$ identical\nmachines. Each machine has to be in operation for a prescribed time, and the\nobjective is to minimize the total machine working time. Precisely, let $c_i$\nbe the prescribed time for machine $i$, where $i\\in[m]$, and $p_j$ be the\nprocessing time for job $j$, where $j\\in[n]$. The problem asks for a schedule\n$\\sigma\\colon\\, J\\to M$ such that $\\sum_{i=1}^m\\max\\{c_i,\n\\sum_{j\\in\\sigma^{-1}(i)}p_j\\}$ is minimized, where $J$ and $M$ denote the sets\nof jobs and machines, respectively. We show that First Fit Decreasing (FFD)\nleads to a $1.5$-approximation, and this problem admits a polynomial-time\napproximation scheme (PTAS). The idea is further applied to mixed-criticality\nsystem scheduling to yield improved approximation results.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8c03\u5ea6\u7b97\u6cd5\uff0c\u7528\u4e8e\u6700\u5c0f\u5316n\u4e2a\u4f5c\u4e1a\u5728m\u53f0\u673a\u5668\u4e0a\u7684\u603b\u5de5\u65f6\uff0c\u5176\u4e2d\u6bcf\u53f0\u673a\u5668\u90fd\u6709\u89c4\u5b9a\u7684\u8fd0\u884c\u65f6\u95f4\u3002FFD\u7b97\u6cd5\u7684\u8fd1\u4f3c\u6bd4\u4e3a1.5\uff0c\u5e76\u4e14\u5b58\u5728PTAS\u3002\u8be5\u65b9\u6cd5\u4e5f\u53ef\u7528\u4e8e\u6df7\u5408\u5173\u952e\u5ea6\u7cfb\u7edf\u8c03\u5ea6\u3002", "motivation": "\u7814\u7a76\u7684\u76ee\u7684\u662f\u89e3\u51b3\u5c06n\u4e2a\u4f5c\u4e1a\u5206\u914d\u5230m\u4e2a\u76f8\u540c\u673a\u5668\u4e0a\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u76ee\u6807\u662f\u6700\u5c0f\u5316\u603b\u673a\u5668\u5de5\u65f6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9700\u8981\u8003\u8651\u6bcf\u53f0\u673a\u5668\u89c4\u5b9a\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u5e76\u6700\u5c0f\u5316\u603b\u673a\u5668\u5de5\u65f6\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86FFD\u7b97\u6cd5\u76841.5\u8fd1\u4f3c\u6bd4\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u8be5\u95ee\u9898\u7684PTAS\u3002", "result": "FFD\u7b97\u6cd5\u63d0\u4f9b\u4e861.5\u7684\u8fd1\u4f3c\u6bd4\uff0c\u5e76\u4e14\u5b58\u5728\u4e00\u4e2aPTAS\u3002", "conclusion": "FFD\u7b97\u6cd5\uff08First Fit Decreasing\uff09\u5728\u6b64\u95ee\u9898\u4e0a\u53ef\u4ee5\u8fbe\u52301.5\u7684\u8fd1\u4f3c\u6bd4\uff0c\u5e76\u4e14\u8be5\u95ee\u9898\u5b58\u5728\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff08PTAS\uff09\u3002\u8be5\u65b9\u6cd5\u8fd8\u53ef\u4ee5\u5e94\u7528\u4e8e\u6df7\u5408\u5173\u952e\u5ea6\u7cfb\u7edf\u8c03\u5ea6\uff0c\u5e76\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u8fd1\u4f3c\u7ed3\u679c\u3002"}}
{"id": "2507.14148", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.14148", "abs": "https://arxiv.org/abs/2507.14148", "authors": ["Daniele Pugliese", "Giovanni Iacovelli", "Alessio Fascista", "Domenico Striccoli", "Oleksandr Romanov", "Luigi Alfredo Grieco", "Gennaro Boggia"], "title": "Visible Light Indoor Positioning with a Single LED and Distributed Single-Element OIRS: An Iterative Approach with Adaptive Beam Steering", "comment": null, "summary": "The integration of Optical Intelligent Reflective Surfaces (OIRSs) into\nVisible Light Communication (VLC) systems is gaining momentum as a valid\nalternative to RF technologies, harnessing the existing lighting\ninfrastructures and the vast unlicensed optical spectrum to enable higher\nspectral efficiency, improved resilience to Line-of-Sight (LoS) blockages, and\nenhanced positioning capabilities. This paper investigates the problem of\nlocalizing a low-cost Photo Detector (PD) in a VLC-based indoor environment\nconsisting of only a single Light Emitting Diode (LED) as an active anchor, and\nmultiple spatially distributed single-element OIRSs. We formulate the problem\nwithin an indirect, computationally efficient localization framework: first,\nthe optimal Maximum Likelihood (ML) estimators of the LoS and Non-Line-of-Sight\n(NLoS) distances are derived, using a suitable OIRS activation strategy to\nprevent interferences. To overcome the grid-based optimization required by the\nML NLoS estimator, we devise a novel algorithm based on an unstructured noise\nvariance transformation, which admits a closed-form solution. The set of\nestimated LoS/NLoS distances are then used within a low-complexity localization\nalgorithm combining an Iterative Weighted Least Squares (IWLS) procedure, whose\nweights are set according to the inverse of the Cram\\'er-Rao Lower Bound\n(CRLB), with an adaptive beam steering strategy that allows the OIRSs network\nto dynamically align with the PD, without any prior knowledge of its position.\nAccordingly, we derive the CRLB for both LoS/NLoS distance estimation and PD\nposition estimation. Simulation results demonstrate the effectiveness of our\napproach in terms of localization accuracy, robustness against OIRSs\nmisalignment conditions, and low number of iterations required to attain the\ntheoretical bounds.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408OIRS\u548cVLC\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u5ba4\u5185\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5229\u7528ML\u4f30\u8ba1\u548cIWLS\u7b97\u6cd5\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728\u4ec5\u5305\u542b\u5355\u4e2aLED\u4f5c\u4e3a\u4e3b\u52a8\u951a\u70b9\u548c\u591a\u4e2aOIRS\u7684VLC\u5ba4\u5185\u73af\u5883\u4e2d\uff0c\u5b9e\u73b0\u4f4e\u6210\u672cPD\u7684\u5b9a\u4f4d\uff0c\u514b\u670d\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u5b9a\u4f4d\u6846\u67b6\uff0c\u5305\u62ec\u6700\u5927\u4f3c\u7136\uff08ML\uff09\u4f30\u8ba1\u5668\u7528\u4e8e\u89c6\u8ddd\uff08LoS\uff09\u548c\u975e\u89c6\u8ddd\uff08NLoS\uff09\u8ddd\u79bb\u4f30\u8ba1\uff0c\u5e76\u5229\u7528\u65e0\u7ed3\u6784\u566a\u58f0\u65b9\u5dee\u53d8\u6362\u63a8\u5bfc\u51faNLoS\u4f30\u8ba1\u7684\u95ed\u5f0f\u89e3\u3002\u7ed3\u5408\u8fed\u4ee3\u52a0\u6743\u6700\u5c0f\u4e8c\u4e58\uff08IWLS\uff09\u548c\u81ea\u9002\u5e94\u6ce2\u675f\u63a7\u5236\u7b56\u7565\uff0c\u4ee5\u6700\u5c0f\u5316\u514b\u62c9\u7f8e-\u7f57\u4e0b\u754c\uff08CRLB\uff09\u4e3a\u6743\u91cd\uff0c\u5b9e\u73b0\u4e86OIRS\u7f51\u7edc\u4e0e\u5149\u7535\u63a2\u6d4b\u5668\uff08PD\uff09\u7684\u52a8\u6001\u5bf9\u51c6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u5bf9\u6297OIRS\u5931\u914d\u7684\u9c81\u68d2\u6027\u4ee5\u53ca\u8fbe\u5230\u7406\u8bba\u4e0b\u754c\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eOIRS\u7684VLC\u5b9a\u4f4d\u65b9\u6cd5\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u9c81\u68d2\u6027\u4ee5\u53ca\u6536\u655b\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u8fbe\u5230\u4e86\u7406\u8bba\u6027\u80fd\u6781\u9650\u3002"}}
{"id": "2507.14322", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11; C.2.4; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.14322", "abs": "https://arxiv.org/abs/2507.14322", "authors": ["Md Rafid Haque", "Abu Raihan Mostofa Kamal", "Md. Azam Hossain"], "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning", "comment": "24 pages, 8 figures. This work is intended for a journal submission", "summary": "Federated Learning (FL) offers a paradigm for privacy-preserving\ncollaborative AI, but its decentralized nature creates significant\nvulnerabilities to model poisoning attacks. While numerous static defenses\nexist, their effectiveness is highly context-dependent, often failing against\nadaptive adversaries or in heterogeneous data environments. This paper\nintroduces FedStrategist, a novel meta-learning framework that reframes robust\naggregation as a real-time, cost-aware control problem. We design a lightweight\ncontextual bandit agent that dynamically selects the optimal aggregation rule\nfrom an arsenal of defenses based on real-time diagnostic metrics. Through\ncomprehensive experiments, we demonstrate that no single static rule is\nuniversally optimal. We show that our adaptive agent successfully learns\nsuperior policies across diverse scenarios, including a ``Krum-favorable\"\nenvironment and against a sophisticated \"stealth\" adversary designed to\nneutralize specific diagnostic signals. Critically, we analyze the paradoxical\nscenario where a non-robust baseline achieves high but compromised accuracy,\nand demonstrate that our agent learns a conservative policy to prioritize model\nintegrity. Furthermore, we prove the agent's policy is controllable via a\nsingle \"risk tolerance\" parameter, allowing practitioners to explicitly manage\nthe trade-off between performance and security. Our work provides a new,\npractical, and analyzable approach to creating resilient and intelligent\ndecentralized AI systems.", "AI": {"tldr": "FedStrategist\u901a\u8fc7\u5143\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u805a\u5408\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u5e94\u5bf9\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u9759\u6001\u9632\u5fa1\u63aa\u65bd\u5728\u9002\u5e94\u6027\u5bf9\u624b\u6216\u5f02\u6784\u6570\u636e\u73af\u5883\u4e2d\u6548\u679c\u6709\u9650\uff0c\u65e0\u6cd5\u5e94\u5bf9\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u7684\u6311\u6218\u3002", "method": "FedStrategist\u6846\u67b6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u4ee3\u7406\uff0c\u6839\u636e\u5b9e\u65f6\u8bca\u65ad\u6307\u6807\u52a8\u6001\u9009\u62e9\u805a\u5408\u89c4\u5219\uff0c\u4ee5\u5e94\u5bf9\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cFedStrategist\u7684\u81ea\u9002\u5e94\u4ee3\u7406\u5728\u5404\u79cd\u573a\u666f\u4e0b\u90fd\u80fd\u5b66\u4e60\u5230\u4f18\u8d8a\u7684\u7b56\u7565\uff0c\u5305\u62ec\u5728\u201cKrum\u6709\u5229\u201d\u7684\u73af\u5883\u548c\u5bf9\u6297\u65e8\u5728\u62b5\u6d88\u7279\u5b9a\u8bca\u65ad\u4fe1\u53f7\u7684\u201c\u9690\u5f62\u201d\u5bf9\u624b\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u8fd8\u8bc1\u660e\u4e86\u5176\u7b56\u7565\u53ef\u4ee5\u901a\u8fc7\u5355\u4e00\u7684\u201c\u98ce\u9669\u5bb9\u5fcd\u5ea6\u201d\u53c2\u6570\u8fdb\u884c\u63a7\u5236\uff0c\u5141\u8bb8\u7528\u6237\u7ba1\u7406\u6027\u80fd\u548c\u5b89\u5168\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedStrategist\u7684\u65b0\u578b\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u9c81\u68d2\u805a\u5408\u91cd\u6784\u4e3a\u4e00\u4e2a\u5b9e\u65f6\u3001\u6210\u672c\u611f\u77e5\u7684\u63a7\u5236\u95ee\u9898\u3002\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u4ee3\u7406\uff0c\u8be5\u4ee3\u7406\u80fd\u591f\u6839\u636e\u5b9e\u65f6\u8bca\u65ad\u6307\u6807\u52a8\u6001\u9009\u62e9\u6700\u4f18\u805a\u5408\u89c4\u5219\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14820", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14820", "abs": "https://arxiv.org/abs/2507.14820", "authors": ["Bingran Chen", "Baorun Li", "Jian Yang", "Yong Liu", "Guangyao Zhai"], "title": "KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning", "comment": null, "summary": "High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation\nto serve as a basic function. Previous approaches either directly generate\ngrasps from point-cloud data, suffering from challenges with small objects and\nsensor noise, or infer 3D information from RGB images, which introduces\nexpensive annotation requirements and discretization issues. Recent methods\nmitigate some challenges by retaining a 2D representation to estimate grasp\nkeypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF\nposes. However, these methods are limited by their non-differentiable nature\nand reliance solely on 2D supervision, which hinders the full exploitation of\nrich 3D information. In this work, we present KGN-Pro, a novel grasping network\nthat preserves the efficiency and fine-grained object grasping of previous KGNs\nwhile integrating direct 3D optimization through probabilistic PnP layers.\nKGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further\noutputs a 2D confidence map to weight keypoint contributions during\nre-projection error minimization. By modeling the weighted sum of squared\nre-projection errors probabilistically, the network effectively transmits 3D\nsupervision to its 2D keypoint predictions, enabling end-to-end learning.\nExperiments on both simulated and real-world platforms demonstrate that KGN-Pro\noutperforms existing methods in terms of grasp cover rate and success rate.", "AI": {"tldr": "KGN-Pro \u662f\u4e00\u79cd\u65b0\u7684\u6293\u53d6\u7f51\u7edc\uff0c\u5b83\u901a\u8fc7\u6982\u7387 PnP \u5c42\u96c6\u6210\u76f4\u63a5\u7684 3D \u4f18\u5316\uff0c\u4ece\u800c\u5728\u4fdd\u7559\u73b0\u6709 KGN \u7684\u6548\u7387\u548c\u7ec6\u7c92\u5ea6\u6293\u53d6\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u5b66\u4e60\u3002", "motivation": "\u9ad8\u5c42\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u9700\u8981\u7075\u6d3b\u7684 6-DoF \u6293\u53d6\u4f30\u8ba1\u4f5c\u4e3a\u57fa\u672c\u529f\u80fd\u3002\u4ee5\u5f80\u7684\u65b9\u6cd5\u8981\u4e48\u76f4\u63a5\u4ece\u70b9\u4e91\u6570\u636e\u751f\u6210\u6293\u53d6\uff0c\u5728\u5904\u7406\u5c0f\u7269\u4f53\u548c\u4f20\u611f\u5668\u566a\u58f0\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u8981\u4e48\u4ece RGB \u56fe\u50cf\u63a8\u65ad 3D \u4fe1\u606f\uff0c\u8fd9\u4f1a\u5f15\u5165\u6602\u8d35\u7684\u6ce8\u91ca\u8981\u6c42\u548c\u79bb\u6563\u5316\u95ee\u9898\u3002\u8fd1\u671f\u65b9\u6cd5\u901a\u8fc7\u4fdd\u7559 2D \u8868\u793a\u6765\u4f30\u8ba1\u6293\u53d6\u5173\u952e\u70b9\u5e76\u5e94\u7528 PnP \u7b97\u6cd5\u8ba1\u7b97 6-DoF \u59ff\u52bf\u6765\u7f13\u89e3\u4e00\u4e9b\u6311\u6218\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53d7\u5176\u975e\u53ef\u5fae\u5206\u6027\u8d28\u548c\u4ec5\u4f9d\u8d56 2D \u76d1\u7763\u7684\u9650\u5236\uff0c\u963b\u788d\u4e86\u5bf9\u4e30\u5bcc 3D \u4fe1\u606f\u7684\u5145\u5206\u5229\u7528\u3002", "method": "KGN-Pro \u7f16\u7801\u914d\u5bf9\u7684 RGB-D \u56fe\u50cf\u4ee5\u751f\u6210\u5173\u952e\u70b9\u56fe\uff0c\u5e76\u8f93\u51fa 2D \u7f6e\u4fe1\u56fe\uff0c\u5728\u91cd\u65b0\u6295\u5f71\u8bef\u5dee\u6700\u5c0f\u5316\u671f\u95f4\u5bf9\u5173\u952e\u70b9\u8d21\u732e\u8fdb\u884c\u52a0\u6743\u3002\u901a\u8fc7\u6982\u7387\u6a21\u578b\u5316\u52a0\u6743\u5e73\u65b9\u91cd\u65b0\u6295\u5f71\u8bef\u5dee\uff0c\u7f51\u7edc\u6709\u6548\u5730\u5c06 3D \u76d1\u7763\u4f20\u9012\u7ed9 2D \u5173\u952e\u70b9\u9884\u6d4b\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cKGN-Pro \u5728\u6293\u53d6\u8986\u76d6\u7387\u548c\u6210\u529f\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "KGN-Pro \u5728\u6293\u53d6\u8986\u76d6\u7387\u548c\u6210\u529f\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14456", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14456", "abs": "https://arxiv.org/abs/2507.14456", "authors": ["Chi Wan", "Yixin Cui", "Jiatong Du", "Shuo Yang", "Yulong Bai", "Yanjun Huang"], "title": "GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving", "comment": null, "summary": "End-to-end autonomous driving requires adaptive and robust handling of\ncomplex and diverse traffic environments. However, prevalent single-mode\nplanning methods attempt to learn an overall policy while struggling to acquire\ndiversified driving skills to handle diverse scenarios. Therefore, this paper\nproposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework\nfeaturing a Global Expert, a Scene-Adaptive Experts Group, and equipped with a\nDual-aware Router. Specifically, the Global Expert is trained on the overall\ndataset, possessing robust performance. The Scene-Adaptive Experts are trained\non corresponding scene subsets, achieving adaptive performance. The Dual-aware\nRouter simultaneously considers scenario-level features and routing uncertainty\nto dynamically activate expert modules. Through the effective coupling of the\nGlobal Expert and the Scene-Adaptive Experts Group via the Dual-aware Router,\nGEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS\noutperforms existing methods in the Bench2Drive closed-loop benchmark and\nachieves state-of-the-art performance in Driving Score and Success Rate, even\nwith only monocular vision input. Furthermore, ablation studies demonstrate\nsignificant improvements over the original single-expert baseline: 7.67% in\nDriving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The\ncode will be available at https://github.com/newbrains1/GEMINUS.", "AI": {"tldr": "GEMINUS\u662f\u4e00\u4e2a\u6df7\u5408\u4e13\u5bb6\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5168\u5c40\u548c\u573a\u666f\u81ea\u9002\u5e94\u4e13\u5bb6\uff0c\u5e76\u4f7f\u7528\u53cc\u611f\u77e5\u8def\u7531\u5668\u6765\u63d0\u9ad8\u5728\u5404\u79cd\u9a7e\u9a76\u573a\u666f\u4e0b\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u5728Bench2Drive\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5355\u6a21\u6001\u89c4\u5212\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6837\u5316\u4ea4\u901a\u73af\u5883\u65f6\u96be\u4ee5\u5b66\u4e60\u5230\u591a\u6837\u5316\u7684\u9a7e\u9a76\u6280\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u573a\u666f\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGEMINUS\u7684\u6df7\u5408\u4e13\u5bb6\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u5168\u5c40\u4e13\u5bb6\u3001\u4e00\u4e2a\u573a\u666f\u81ea\u9002\u5e94\u4e13\u5bb6\u7ec4\u548c\u4e00\u4e2a\u53cc\u611f\u77e5\u8def\u7531\u5668\u3002", "result": "GEMINUS\u5728Bench2Drive\u95ed\u73af\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u4ec5\u4f7f\u7528\u5355\u76ee\u89c6\u89c9\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u9a7e\u9a76\u5f97\u5206\u548c\u6210\u529f\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u539f\u59cb\u5355\u4e13\u5bb6\u57fa\u7ebf\u76f8\u6bd4\uff0cGEMINUS\u5728\u9a7e\u9a76\u5f97\u5206\u3001\u6210\u529f\u7387\u548c\u591a\u80fd\u529b\u5e73\u5747\u5206\u65b9\u9762\u5206\u522b\u63d0\u9ad8\u4e867.67%\u300122.06%\u548c19.41%\u3002", "conclusion": "GEMINUS\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5168\u5c40\u4e13\u5bb6\u548c\u573a\u666f\u81ea\u9002\u5e94\u4e13\u5bb6\u7ec4\uff0c\u5e76\u901a\u8fc7\u53cc\u611f\u77e5\u8def\u7531\u5668\u52a8\u6001\u6fc0\u6d3b\u4e13\u5bb6\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u5728\u591a\u6837\u5316\u573a\u666f\u4e0b\u7684\u81ea\u9002\u5e94\u548c\u9c81\u68d2\u6027\u80fd\u3002"}}
{"id": "2507.14513", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14513", "abs": "https://arxiv.org/abs/2507.14513", "authors": ["Hongyi Yang", "Yue Pan", "Jiayi Xu", "Kelsen Liu"], "title": "Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy", "comment": null, "summary": "Recent advances in large language models (LLMs) and autonomous agents have\nenabled systems capable of performing complex tasks across domains such as\nhuman-computer interaction, planning, and web navigation. However, many\nexisting frameworks struggle in real-world or resource-constrained environments\ndue to their reliance on cloud-based computation, limited robustness in dynamic\ncontexts, and lack of persistent autonomy and environmental awareness.\n  We present Amico, a modular, event-driven framework for building autonomous\nagents optimized for embedded systems. Written in Rust for safety and\nperformance, Amico supports reactive, persistent agents that operate\nefficiently across embedded platforms and browser environments via WebAssembly.\nIt provides clean abstractions for event handling, state management, behavior\nexecution, and integration with reasoning modules. Amico delivers a unified\ninfrastructure for constructing resilient, interactive agents suitable for\ndeployment in settings with limited compute and intermittent connectivity.", "AI": {"tldr": "Amico\u662f\u4e00\u4e2a\u7528Rust\u7f16\u5199\u7684\u3001\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8bbe\u8ba1\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u3001\u4e8b\u4ef6\u9a71\u52a8\u7684\u67b6\u6784\uff0c\u652f\u6301\u54cd\u5e94\u5f0f\u3001\u6301\u4e45\u6027\u4ee3\u7406\u3002", "motivation": "\u73b0\u6709\u7684LLM\u548c\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\u5728\u5b9e\u9645\u6216\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u4e91\u8ba1\u7b97\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9c81\u68d2\u6027\u6709\u9650\uff0c\u5e76\u4e14\u7f3a\u4e4f\u6301\u4e45\u81ea\u4e3b\u6027\u548c\u73af\u5883\u610f\u8bc6\u3002", "method": "Amico\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u3001\u4e8b\u4ef6\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u4f7f\u7528Rust\u7f16\u5199\uff0c\u652f\u6301\u8de8\u5d4c\u5165\u5f0f\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u73af\u5883\uff08\u901a\u8fc7WebAssembly\uff09\u8fd0\u884c\u7684\u54cd\u5e94\u5f0f\u3001\u6301\u4e45\u6027\u4ee3\u7406\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e8b\u4ef6\u5904\u7406\u3001\u72b6\u6001\u7ba1\u7406\u3001\u884c\u4e3a\u6267\u884c\u4ee5\u53ca\u4e0e\u63a8\u7406\u6a21\u5757\u96c6\u6210\u7684\u62bd\u8c61\u3002", "result": "Amico\u662f\u4e00\u4e2a\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4f18\u5316\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u5177\u6709\u5b89\u5168\u6027\u548c\u9ad8\u6027\u80fd\uff0c\u652f\u6301\u54cd\u5e94\u5f0f\u3001\u6301\u4e45\u6027\u4ee3\u7406\uff0c\u5e76\u80fd\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u73af\u5883\uff08\u901a\u8fc7WebAssembly\uff09\u4e2d\u9ad8\u6548\u8fd0\u884c\u3002", "conclusion": "Amico\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u7528\u4e8e\u6784\u5efa\u9002\u7528\u4e8e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u548c\u95f4\u6b47\u6027\u8fde\u63a5\u73af\u5883\u7684\u5f39\u6027\u3001\u4ea4\u4e92\u5f0f\u4ee3\u7406\u3002"}}
{"id": "2507.15011", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.15011", "abs": "https://arxiv.org/abs/2507.15011", "authors": ["Saumen Acharjee"], "title": "Quantum Capacitance and Electronic Properties of a Hexagonal Boron Nitride based FET Gas Sensor", "comment": "12 pages 7 figures", "summary": "We present a comprehensive theoretical investigation of gas sensing in\nmonolayer hexagonal boron nitride (h-BN) based field-effect transistors (FET)\nusing the non-equilibrium Green function formalism and Landauer-B\\\"{u}ttiker\napproach. Moving beyond conventional density functional theory analyses, our\nframework captures the full device level response by incorporating\nfield-dependent quantum transport and temperature effects. We model the impact\nof NO, H$_2$S, HF and CO$_2$ gases on the band structure and density of states\n(DOS), carrier concentration, quantum capacitance and I-V characteristics. The\nresults indicate that CO$_2$ followed by NO induce strongest perturbations via\nmid-gap states and band edge shifts, leading to the appearance of asymmetric\nVan-Hove singularities with enhanced carrier modulation and quantum\ncapacitance. It is observed that HF induce moderate perturbation while H$_2$S\ninduce weakest response for all temperature and biasing condition. It is found\nthat an applied vertical electric field narrows the band gap via the Stark\neffect, further boosting mobility and tunability. Temperature influences\nsensing response by enhancing charge transfer at moderate levels and causing\ndesorption at higher temperatures. We found that CO$_2$ consistently show the\nhighest sensitivity and selectivity followed by NO and HF, while H$_2$S display\nthe weakest response. This study offers a comprehensive framework to engineer\nh-BN based FET sensors by harnessing intrinsic band modulation and quantum\ncapacitance for molecule discrimination and temperature optimization.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5148\u8fdb\u7684\u7406\u8bba\u65b9\u6cd5\u7814\u7a76\u4e86h-BN\u57faFET\u7684\u6c14\u4f53\u4f20\u611f\u7279\u6027\uff0c\u53d1\u73b0CO2\u548cNO\u662f\u6709\u6548\u7684\u4f20\u611f\u6c14\u4f53\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u5316\u4f20\u611f\u5668\u6027\u80fd\u7684\u8bbe\u8ba1\u601d\u8def\u3002", "motivation": "\u5bf9h-BN\u57faFET\u7684\u6c14\u4f53\u4f20\u611f\u673a\u5236\u8fdb\u884c\u5168\u9762\u7684\u7406\u8bba\u7814\u7a76\uff0c\u4ee5\u7406\u89e3\u4e0d\u540c\u6c14\u4f53\u5206\u5b50\u548c\u5de5\u4f5c\u6761\u4ef6\u5bf9\u5668\u4ef6\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5229\u7528\u975e\u5e73\u8861\u683c\u6797\u51fd\u6570\u5f62\u5f0f\u4e3b\u4e49\u548cLandauer-B\u00fcttiker\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u573a\u6548\u5e94\u3001\u91cf\u5b50\u8f93\u8fd0\u548c\u6e29\u5ea6\u5f71\u54cd\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u5206\u6790\u3002", "result": "CO2\u548cNO\u6c14\u4f53\u5f15\u8d77\u6700\u5f3a\u7684\u4f20\u611f\u54cd\u5e94\uff0cHF\u6b21\u4e4b\uff0cH2S\u6700\u5f31\u3002\u5782\u76f4\u7535\u573a\u53ef\u4ee5\u8c03\u8282\u5e26\u9699\u5bbd\u5ea6\u548c\u8f7d\u6d41\u5b50\u8fc1\u79fb\u7387\uff0c\u6e29\u5ea6\u4f1a\u5f71\u54cd\u4f20\u611f\u54cd\u5e94\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790h-BN\u57faFET\u7684\u6c14\u4f53\u4f20\u611f\u7279\u6027\uff0c\u5e76\u8003\u8651\u4e86\u573a\u6548\u5e94\u3001\u91cf\u5b50\u8f93\u8fd0\u548c\u6e29\u5ea6\u5f71\u54cd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cCO2\u548cNO\u6c14\u4f53\u5bf9h-BN\u7684\u4f20\u611f\u54cd\u5e94\u6700\u5f3a\uff0cHF\u6b21\u4e4b\uff0cH2S\u6700\u5f31\u3002\u6b64\u5916\uff0c\u5782\u76f4\u7535\u573a\u53ef\u4ee5\u8c03\u8282\u5e26\u9699\u5bbd\u5ea6\u548c\u8f7d\u6d41\u5b50\u8fc1\u79fb\u7387\uff0c\u800c\u6e29\u5ea6\u5219\u4f1a\u5f71\u54cd\u7535\u8377\u8f6c\u79fb\u548c\u5438\u9644/\u89e3\u5438\u8fc7\u7a0b\u3002\u672c\u7814\u7a76\u4e3a\u5de5\u7a0b\u8bbe\u8ba1h-BN\u57faFET\u4f20\u611f\u5668\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2507.14204", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14204", "abs": "https://arxiv.org/abs/2507.14204", "authors": ["Dachuan Shi", "Yonggan Fu", "Xiangchi Yuan", "Zhongzhi Yu", "Haoran You", "Sixu Li", "Xin Dong", "Jan Kautz", "Pavlo Molchanov", "Yingyan", "Lin"], "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models", "comment": "ICML 2025. Code: https://github.com/GATECH-EIC/LaCache", "summary": "Recent advancements in Large Language Models (LLMs) have spurred interest in\nnumerous applications requiring robust long-range capabilities, essential for\nprocessing extensive input contexts and continuously generating extended\noutputs. As sequence lengths increase, the number of Key-Value (KV) pairs in\nLLMs escalates, creating a significant efficiency bottleneck. In this paper, we\npropose a new KV cache optimization paradigm called LaCache, a training-free\nmethod for efficient and accurate generative inference of LLMs. LaCache enables\nLLMs to simultaneously address both of the critical challenges in long-range\nmodeling: robust long-range capabilities and continuous generation without\nrunning out-of-memory (OOM). Specifically, LaCache integrates two key\ninnovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only\nsequentially (left-to-right within each layer) but also across layers (from\nshallow to deep), providing an extended span for capturing long-range\ndependencies under a fixed storage budget, thereby boosting long-range\ncapabilities; and (2) an iterative compaction mechanism that progressively\ncompresses older caches, freeing up space for new tokens within a fixed cache\nsize. This token distance-based dynamic compression enables more effective\ncontinuous generation under constrained cache budgets. Experiments across\nvarious tasks, benchmarks, and LLM models consistently validate LaCache's\neffectiveness in enhancing LLMs' long-range capabilities. Our code is available\nat https://github.com/GATECH-EIC/LaCache.", "AI": {"tldr": "LaCache \u662f\u4e00\u79cd\u521b\u65b0\u7684 KV \u7f13\u5b58\u4f18\u5316\u65b9\u6cd5\uff0c\u53ef\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u5927\u5c0f\u6216\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8 LLM \u5904\u7406\u957f\u5e8f\u5217\u548c\u8fde\u7eed\u751f\u6210\u7684\u80fd\u529b\uff0c\u5e76\u89e3\u51b3\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u957f\u8f93\u5165\u548c\u6301\u7eed\u751f\u6210\u957f\u8f93\u51fa\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u7684\u589e\u52a0\uff0cKV \u5bf9\u7684\u6570\u91cf\u6025\u5267\u4e0a\u5347\uff0c\u5bfc\u81f4\u6548\u7387\u74f6\u9888\uff0c\u5e76\u53ef\u80fd\u5f15\u53d1\u5185\u5b58\u4e0d\u8db3\uff08OOM\uff09\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u4f18\u5316 KV \u7f13\u5b58\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "LaCache \u662f\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u4e24\u79cd\u521b\u65b0\uff1a1. \u9636\u68af\u72b6 KV \u7f13\u5b58\u6a21\u5f0f\uff1aKV \u5bf9\u4e0d\u4ec5\u6309\u987a\u5e8f\u5b58\u50a8\uff08\u5c42\u5185\u4ece\u5de6\u5230\u53f3\uff09\uff0c\u8fd8\u8de8\u5c42\u5b58\u50a8\uff08\u4ece\u6d45\u5230\u6df1\uff09\uff0c\u5728\u56fa\u5b9a\u5b58\u50a8\u9884\u7b97\u4e0b\u6269\u5c55\u4e86\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u7684\u8303\u56f4\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u957f\u7a0b\u80fd\u529b\u30022. \u8fed\u4ee3\u538b\u7f29\u673a\u5236\uff1a\u9010\u6b65\u538b\u7f29\u65e7\u7f13\u5b58\uff0c\u4e3a\u56fa\u5b9a\u7f13\u5b58\u5927\u5c0f\u5185\u7684\u65b0 token \u817e\u51fa\u7a7a\u95f4\uff0c\u8fd9\u79cd\u57fa\u4e8e token \u8ddd\u79bb\u7684\u52a8\u6001\u538b\u7f29\u80fd\u591f\u5728\u6709\u9650\u7684\u7f13\u5b58\u9884\u7b97\u4e0b\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u8fde\u7eed\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5728\u5404\u79cd\u4efb\u52a1\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c LLM \u6a21\u578b\u4e0a\u5747\u4e00\u81f4\u8868\u660e\uff0cLaCache \u5728\u589e\u5f3a LLM \u7684\u957f\u7a0b\u80fd\u529b\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002", "conclusion": "LaCache \u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684 LLM \u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u91c7\u7528\u9636\u68af\u72b6 KV \u7f13\u5b58\u6a21\u5f0f\u548c\u8fed\u4ee3\u538b\u7f29\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u957f\u7a0b\u5efa\u6a21\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u9ad8\u4e86 LLM \u7684\u957f\u7a0b\u80fd\u529b\u548c\u8fde\u7eed\u751f\u6210\u80fd\u529b\uff0c\u5e76\u6709\u6548\u907f\u514d\u4e86\u5185\u5b58\u4e0d\u8db3\uff08OOM\uff09\u7684\u95ee\u9898\u3002"}}
{"id": "2507.14574", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14574", "abs": "https://arxiv.org/abs/2507.14574", "authors": ["D. I. Zainutdinov", "A. E. Volkov"], "title": "Swift heavy ion track formation in SiC films under high-temperature irradiation", "comment": null, "summary": "The resistance of bulk silicon carbide (SiC) to impacts of swift heavy ions\n(SHI) decelerating at room temperature in the electronic stopping regime is\nwell known. However, the effect of the SiC film thickness on the formation and\nstructure of SHI tracks over a wide range of irradiation temperatures remains\nunexplored. To address this disadvantage, we utilize a model sensitive to\nirradiation temperature that describes all stages of ion track formation: from\nmaterial excitation, considering the emission of excited electrons from the\nfilm surface (MC code TREKIS-3), to the reaction of the material's atomic\nsystem to the excitation (classical molecular dynamics). We observed the\nformation of two different types of nanostructures on the surface of SiC films\nwith thicknesses ranging from 10 nm to 100 nm when irradiated with 710 MeV Bi\nions: craters and hills. The type of nanostructure formed depended on the\nirradiation temperature. The transition irradiation temperature ($T_{tr}$) from\nhills to craters grows with the film thickness and follows an empirical\nrelation $T_{tr}=T_{tr}^{cr} \\left(1-\\left(1+\\left(L/L_{cr} \\right)^2\n\\right)^{-\\frac{1}{2}} \\right)$ with $T_{tr}^{cr}=1534$ K and $L_{cr}=2.8$ nm.\nThat means such a transition should occur in bulk SiC at the irradiation\ntemperature of $\\approx 1534$ K.", "AI": {"tldr": "\u7814\u7a76\u4e86SiC\u8584\u819c\u539a\u5ea6\u548c\u8f90\u7167\u6e29\u5ea6\u5bf9\u91cd\u79bb\u5b50\u8f90\u7167\u7eb3\u7c73\u7ed3\u6784\u5f62\u6210\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b58\u5728\u4e24\u79cd\u7eb3\u7c73\u7ed3\u6784\uff08\u9668\u77f3\u5751\u548c\u5c71\u4e18\uff09\uff0c\u5176\u5f62\u6210\u53d6\u51b3\u4e8e\u6e29\u5ea6\u548c\u539a\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ecf\u9a8c\u6a21\u578b\u3002", "motivation": "\u586b\u8865\u4e86SiC\u8584\u819c\u539a\u5ea6\u5bf9\u91cd\u79bb\u5b50\u8f90\u7167\u635f\u4f24\uff08\u5305\u62ec\u7eb3\u7c73\u7ed3\u6784\u5f62\u6210\uff09\u5f71\u54cd\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63a2\u7d22\u4e86\u8f90\u7167\u6e29\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528MC\u4ee3\u7801TREKIS-3\u548c\u7ecf\u5178\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u7814\u7a76\u4e86710 MeV Bi\u79bb\u5b50\u8f90\u7167\u4e0d\u540c\u539a\u5ea6SiC\u8584\u819c\uff0810 nm\u81f3100 nm\uff09\u5728\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u8868\u9762\u7eb3\u7c73\u7ed3\u6784\u5f62\u6210\u3002", "result": "\u5728SiC\u8584\u819c\u8868\u9762\u89c2\u5bdf\u5230\u4e24\u79cd\u7eb3\u7c73\u7ed3\u6784\uff1a\u9668\u77f3\u5751\u548c\u5c71\u4e18\u3002\u9668\u77f3\u5751\u548c\u5c71\u4e18\u7684\u8f6c\u53d8\u4e0e\u8f90\u7167\u6e29\u5ea6\u548c\u8584\u819c\u539a\u5ea6\u6709\u5173\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ecf\u9a8c\u5173\u7cfb\u5f0f\u6765\u63cf\u8ff0\u8f6c\u53d8\u6e29\u5ea6\u968f\u8584\u819c\u539a\u5ea6\u7684\u53d8\u5316\uff0c\u8be5\u5173\u7cfb\u5f0f\u8868\u660e\u5728\u4f53\u6750\u6599\u4e2d\u8f6c\u53d8\u6e29\u5ea6\u7ea6\u4e3a1534 K\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86SiC\u8584\u819c\u539a\u5ea6\u548c\u8f90\u7167\u6e29\u5ea6\u5bf9\u91cd\u79bb\u5b50\u8f90\u7167\u4e0b\u7eb3\u7c73\u7ed3\u6784\u5f62\u6210\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u63cf\u8ff0\u79bb\u5b50\u675f\u5f15\u8d77\u7684\u6750\u6599\u635f\u4f24\u7684\u552f\u8c61\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u8003\u8651\u4e86\u7535\u5b50\u6fc0\u53d1\u548c\u539f\u5b50\u7cfb\u7edf\u53cd\u5e94\u3002"}}
{"id": "2507.14857", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14857", "abs": "https://arxiv.org/abs/2507.14857", "authors": ["Hassan Osseily"], "title": "Grid Stability and Power Factor Dynamics in Solar Farms Integration", "comment": "6 pages, 16 figures, African Scientific", "summary": "This paper examines the impact of solar farm fluctuations on grid stability,\nfocusing on maintaining an optimal power factor. ETAP-based simulations and\ncase studies are used to analyze real-time grid performance under solar\nvariability. Reactive power control strategies and advanced inverter functions\nare proposed for stabilization. Theoretical analysis and simulation results\nhighlight effective integration techniques. Artificial intelligence is trailed\nfor controlling the SVC in adaptive reactive power compensation. The study\nprovides practical solutions for improving reliability in renewable-integrated\npower systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528ETAP\u4eff\u771f\u548c\u6848\u4f8b\u7814\u7a76\u5206\u6790\u4e86\u592a\u9633\u80fd\u53d1\u7535\u6ce2\u52a8\u5bf9\u7535\u7f51\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u65e0\u529f\u529f\u7387\u8865\u507f\u63a7\u5236\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u7535\u7f51\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u592a\u9633\u80fd\u53d1\u7535\u6ce2\u52a8\u5bf9\u7535\u7f51\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u91cd\u70b9\u5173\u6ce8\u7ef4\u6301\u6700\u4f18\u529f\u7387\u56e0\u6570\u3002", "method": "ETAP\u4eff\u771f\u548c\u6848\u4f8b\u7814\u7a76\u88ab\u7528\u4e8e\u5206\u6790\u592a\u9633\u80fd\u6ce2\u52a8\u4e0b\u7684\u5b9e\u65f6\u7535\u7f51\u6027\u80fd\u3002\u63d0\u51fa\u4e86\u91c7\u7528\u4eba\u5de5\u667a\u80fd\u591f\u63a7\u5236\u9759\u6b62\u65e0\u529f\u529f\u7387\u8865\u507f\u5668\uff08SVC\uff09\u8fdb\u884c\u81ea\u9002\u5e94\u65e0\u529f\u529f\u7387\u8865\u507f\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u7a81\u51fa\u4e86\u6709\u6548\u7684\u6574\u5408\u6280\u672f\uff0c\u5e76\u4e3a\u63d0\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\u7535\u529b\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u63d0\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\u7535\u529b\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14496", "categories": ["quant-ph", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14496", "abs": "https://arxiv.org/abs/2507.14496", "authors": ["Xin Hong", "Chenjian Li", "Aochu Dai", "Sanjiang Li", "Shenggang Ying", "Mingsheng Ying"], "title": "Quantum State Preparation Based on LimTDD", "comment": null, "summary": "Quantum state preparation is a fundamental task in quantum computing and\nquantum information processing. With the rapid advancement of quantum\ntechnologies, efficient quantum state preparation has become increasingly\nimportant. This paper proposes a novel approach for quantum state preparation\nbased on the Local Invertible Map Tensor Decision Diagram (LimTDD). LimTDD\ncombines the advantages of tensor networks and decision diagrams, enabling\nefficient representation and manipulation of quantum states. Compared with the\nstate-of-the-art quantum state preparation method, LimTDD demonstrates\nsubstantial improvements in efficiency when dealing with complex quantum\nstates, while also reducing the complexity of quantum circuits. Examples\nindicate that, in the best-case scenario, our method can achieve exponential\nefficiency gains over existing methods. This study not only highlights the\npotential of LimTDD in quantum state preparation but also provides a robust\ntheoretical and practical foundation for the future development of quantum\ncomputing technologies.", "AI": {"tldr": "LimTDD\u662f\u4e00\u79cd\u7ed3\u5408\u5f20\u91cf\u7f51\u7edc\u548c\u5224\u5b9a\u56fe\u7684\u65b0\u578b\u91cf\u5b50\u72b6\u6001\u5236\u5907\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u91cf\u5b50\u6001\u65f6\u6548\u7387\u66f4\u9ad8\uff0c\u7535\u8def\u590d\u6742\u5ea6\u66f4\u4f4e\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u6280\u672f\u7684\u53d1\u5c55\uff0c\u9ad8\u6548\u7684\u91cf\u5b50\u72b6\u6001\u5236\u5907\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u53ef\u9006\u6620\u5c04\u5f20\u91cf\u5224\u5b9a\u56fe\uff08LimTDD\uff09\u7684\u65b0\u578b\u91cf\u5b50\u72b6\u6001\u5236\u5907\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5f20\u91cf\u7f51\u7edc\u548c\u5224\u5b9a\u56fe\u7684\u4f18\u70b9\uff0c\u80fd\u591f\u6709\u6548\u5730\u8868\u793a\u548c\u64cd\u4f5c\u91cf\u5b50\u6001\u3002", "result": "\u4e0e\u73b0\u6709\u7684\u91cf\u5b50\u72b6\u6001\u5236\u5907\u65b9\u6cd5\u76f8\u6bd4\uff0cLimTDD\u5728\u5904\u7406\u590d\u6742\u91cf\u5b50\u6001\u65f6\u8868\u73b0\u51fa\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\uff0c\u5e76\u964d\u4f4e\u4e86\u91cf\u5b50\u7535\u8def\u7684\u590d\u6742\u5ea6\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u5b9e\u73b0\u6307\u6570\u7ea7\u7684\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86LimTDD\u5728\u91cf\u5b50\u72b6\u6001\u5236\u5907\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2507.14307", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14307", "abs": "https://arxiv.org/abs/2507.14307", "authors": ["Karin de Langis", "Jong Inn Park", "Andreas Schramm", "Bin Hu", "Khanh Chi Le", "Michael Mensink", "Ahn Thu Tong", "Dongyeop Kang"], "title": "How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs", "comment": null, "summary": "Large language models (LLMs) exhibit increasingly sophisticated linguistic\ncapabilities, yet the extent to which these behaviors reflect human-like\ncognition versus advanced pattern recognition remains an open question. In this\nstudy, we investigate how LLMs process the temporal meaning of linguistic\naspect in narratives that were previously used in human studies. Using an\nExpert-in-the-Loop probing pipeline, we conduct a series of targeted\nexperiments to assess whether LLMs construct semantic representations and\npragmatic inferences in a human-like manner. Our findings show that LLMs\nover-rely on prototypicality, produce inconsistent aspectual judgments, and\nstruggle with causal reasoning derived from aspect, raising concerns about\ntheir ability to fully comprehend narratives. These results suggest that LLMs\nprocess aspect fundamentally differently from humans and lack robust narrative\nunderstanding. Beyond these empirical findings, we develop a standardized\nexperimental framework for the reliable assessment of LLMs' cognitive and\nlinguistic capabilities.", "AI": {"tldr": "LLMs\u5728\u7406\u89e3\u53d9\u4e8b\u7684\u65f6\u95f4\u8bed\u8a00\u5b66\u65b9\u9762\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u5b83\u4eec\u8fc7\u5ea6\u4f9d\u8d56\u539f\u578b\u6027\uff0c\u5224\u65ad\u4e0d\u4e00\u81f4\uff0c\u5e76\u4e14\u5728\u56e0\u679c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u8868\u660e\u5b83\u4eec\u7f3a\u4e4f\u5065\u5168\u7684\u53d9\u4e8b\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u7814\u7a76LLMs\u5982\u4f55\u5904\u7406\u53d9\u4e8b\u4e2d\u7684\u65f6\u95f4\u8bed\u8a00\u5b66\u65b9\u9762\uff0c\u5e76\u4e0e\u4e4b\u524d\u5728\u4eba\u7c7b\u7814\u7a76\u4e2d\u7684\u884c\u4e3a\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4ee5\u63a2\u7a76\u8fd9\u4e9b\u884c\u4e3a\u662f\u53cd\u6620\u4e86\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u8fd8\u662f\u9ad8\u7ea7\u7684\u6a21\u5f0f\u8bc6\u522b\u3002", "method": "\u4f7f\u7528\u4e13\u5bb6\u5728\u5faa\u73af\uff08Expert-in-the-Loop\uff09\u63a2\u6d4b\u6d41\u7a0b\uff0c\u8fdb\u884c\u4e00\u7cfb\u5217\u9488\u5bf9\u6027\u7684\u5b9e\u9a8c\uff0c\u4ee5\u8bc4\u4f30LLMs\u662f\u5426\u4ee5\u7c7b\u4f3c\u4eba\u7c7b\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u4e49\u8868\u5f81\u548c\u8bed\u7528\u63a8\u65ad\u3002", "result": "LLMs\u8fc7\u5ea6\u4f9d\u8d56\u539f\u578b\u6027\uff0c\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u65b9\u9762\u5224\u65ad\uff0c\u5e76\u4e14\u5728\u63a8\u5bfc\u81ea\u65b9\u9762\u7684\u56e0\u679c\u63a8\u7406\u65b9\u9762\u9047\u5230\u56f0\u96be\u3002", "conclusion": "LLMs\u5904\u7406\u65b9\u9762\u4e0e\u4eba\u7c7b\u6709\u672c\u8d28\u533a\u522b\uff0c\u5e76\u4e14\u7f3a\u4e4f\u5065\u5168\u7684\u53d9\u4e8b\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2507.15549", "categories": ["cs.DS", "90", "F.2; E.1; G.2"], "pdf": "https://arxiv.org/pdf/2507.15549", "abs": "https://arxiv.org/abs/2507.15549", "authors": ["Ren\u00e9 Sitters"], "title": "An $n^{O(\\log\\log n)}$ time approximation scheme for capacitated VRP in the Euclidean plane", "comment": "40 pages", "summary": "We present a quasi polynomial time approximation scheme (Q-PTAS) for the\ncapacitated vehicle routing problem (CVRP) on $n$ points in the Euclidean plane\nfor arbitrary capacity $c$. The running time is $n^{f(\\epsilon)\\cdot\\log\\log\nn}$ for any $c$, and where $f$ is a function of $\\epsilon$ only. This is a\nmajor improvement over the so far best known running time of\n$n^{\\log^{O(1/\\epsilon)}n}$ time and a big step towards a PTAS for Euclidean\nCVRP.\n  In our algorithm, we first give a polynomial time reduction of the CVRP in\n$\\mathbb{R}^d$ (for any fixed $d$) to an uncapacitated routing problem in\n$\\mathbb{R}^d$ that we call the $m$-paths problem. Here, one needs to find\nexactly $m$ paths between two points $a$ and $b$, covering all the given points\nin the Euclidean space. We then give a Q-PTAS for the $m$-paths problem in the\npane. Any PTAS for the (arguably easier to handle) Euclidean $m$-paths problem\nis most likely to imply a PTAS for the Euclidean CVRP.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e3a\u6b27\u6c0fCVRP\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5feb\u7684\u8fd1\u4f3c\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u80fd\u6709\u52a9\u4e8e\u89e3\u51b3\u8be5\u95ee\u9898\u7684m-paths\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6709\u5bb9\u91cf\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08CVRP\uff09\uff0c\u7279\u522b\u662f\u6b27\u6c0f\u7a7a\u95f4\u4e2d\u7684CVRP\uff0c\u5e76\u671d\u7740\u5b9e\u73b0\u5176PTAS\u7684\u76ee\u6807\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06CVRP\uff08\u5728\u4efb\u610f\u56fa\u5b9a\u7ef4\u5ea6d\u7684\u211dd\u4e2d\uff09\u5f52\u7ea6\u5230\u65e0\u5bb9\u91cf\u8def\u5f84\u95ee\u9898\uff08m-paths problem\uff09\u7684\u8fd1\u4f3c\u65b9\u6848\uff0c\u8be5\u95ee\u9898\u9700\u8981\u627e\u5230\u5728\u4e24\u4e2a\u70b9a\u548cb\u4e4b\u95f4\u6070\u597dm\u6761\u8def\u5f84\uff0c\u5e76\u8986\u76d6\u6b27\u6c0f\u7a7a\u95f4\u4e2d\u7ed9\u5b9a\u7684\u6240\u6709\u70b9\u3002\u7136\u540e\uff0c\u4e3a\u5e73\u9762\u4e2d\u7684m-paths\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2aQ-PTAS\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6b27\u6c0fCVRP\u7684Q-PTAS\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3an^f(\u03b5)\u00b7loglogn\uff0c\u540c\u65f6\u8fd8\u63d0\u51fa\u4e86\u7528\u4e8em-paths\u95ee\u9898\u7684Q-PTAS\uff0c\u8fd9\u5f88\u53ef\u80fd\u610f\u5473\u7740\u6b27\u6c0fCVRP\u7684PTAS\u3002", "conclusion": "\u6587\u7ae0\u4e3a\u5728n\u4e2a\u70b9\u4e0a\u7684\u6b27\u6c0f\u5e73\u9762\u65e0\u5bb9\u91cf\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08CVRP\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8fd1\u4f3c\u65b9\u6848\uff08Q-PTAS\uff09\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4e3an^f(\u03b5)\u00b7loglogn\uff0c\u8fd9\u662f\u5bf9\u5148\u524d\u5df2\u77e5\u8fd0\u884c\u65f6\u95f4\u7684\u91cd\u5927\u6539\u8fdb\u3002"}}
{"id": "2507.14151", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14151", "abs": "https://arxiv.org/abs/2507.14151", "authors": ["Giuliana Monachino", "Nicol\u00f2 La Porta", "Beatrice Zanchi", "Luigi Fiorillo", "Alvise Dei Rossi", "Georgiy Farina", "Francesca Dalia Faraci"], "title": "Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models", "comment": null, "summary": "Foundation Models (FMs) are large-scale machine learning models trained on\nextensive, diverse datasets that can be adapted to a wide range of downstream\ntasks with minimal fine-tuning. In the last two years, interest in FMs has also\ngrown for applications in the cardiological field to analyze the\nelectrocardiogram (ECG) signals. One of the key properties of FMs is their\ntransferability to a wide range of downstream scenarios. With the spread of\nwearable and portable devices, keen interest in learning from reduced-channel\nconfigurations has arisen. However, the adaptation of ECG FMs to downstream\nscenarios with fewer available channels still has to be properly investigated.\nIn this work, we propose Self-DANA, a novel, easy-to-integrate solution that\nmakes self-supervised architectures adaptable to a reduced number of input\nchannels, ensuring resource efficiency and high performance. We also introduce\nRandom Lead Selection, a novel augmentation technique to pre-train models in a\nmore robust and channel-agnostic way. Our experimental results on five\nreduced-channel configurations demonstrate that Self-DANA significantly\nenhances resource efficiency while reaching state-of-the-art performance. It\nrequires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about\n17% less average epoch CPU time, and about 24% less average epoch GPU time.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-DANA\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u63d0\u5347\u5fc3\u7535\u56fe\uff08ECG\uff09\u57fa\u77f3\u6a21\u578b\u5728\u901a\u9053\u6570\u51cf\u5c11\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\u3002\u8be5\u65b9\u6848\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u968f\u673a\u5bfc\u8054\u9009\u62e9\u6280\u672f\uff0c\u5728\u4e94\u4e2a\u51cf\u5c11\u901a\u9053\u6570\u7684\u914d\u7f6e\u4e0b\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u5728\u663e\u8457\u51cf\u5c11\u5185\u5b58\u548c\u8ba1\u7b97\u65f6\u95f4\u7684\u540c\u65f6\uff0c\u4ecd\u80fd\u8fbe\u5230\u884c\u4e1a\u9886\u5148\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u53ef\u7a7f\u6234\u548c\u4fbf\u643a\u5f0f\u8bbe\u5907\u7684\u5e94\u7528\u666e\u53ca\uff0c\u5728\u8f83\u5c11\u901a\u9053\u6570\u7684\u914d\u7f6e\u4e0b\u8fdb\u884c\u5b66\u4e60\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u7136\u800c\uff0c\u5c06ECG\u9886\u57df\u7684\u57fa\u77f3\u6a21\u578b\uff08Foundation Models\uff09\u5e94\u7528\u4e8e\u4e0b\u6e38\u573a\u666f\u4e2d\u901a\u9053\u6570\u51cf\u5c11\u7684\u60c5\u51b5\uff0c\u4ecd\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-DANA\u7684\u65b0\u578b\u6613\u4e8e\u96c6\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5f97\u81ea\u76d1\u7763\u5b66\u4e60\u67b6\u6784\u80fd\u591f\u9002\u5e94\u4e8e\u8f93\u5165\u901a\u9053\u6570\u51cf\u5c11\u7684\u60c5\u51b5\uff0c\u786e\u4fdd\u4e86\u8d44\u6e90\u7684\u6709\u6548\u5229\u7528\u548c\u9ad8\u6027\u80fd\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u968f\u673a\u5bfc\u8054\u9009\u62e9\uff08Random Lead Selection\uff09\u8fd9\u4e00\u65b0\u9896\u7684\u589e\u5f3a\u6280\u672f\uff0c\u65e8\u5728\u4ee5\u66f4\u5177\u9c81\u68d2\u6027\u548c\u4e0e\u901a\u9053\u65e0\u5173\u7684\u65b9\u5f0f\u5bf9\u6a21\u578b\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSelf-DANA\u65b9\u6848\u5728\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5cf0\u503cCPU\u5185\u5b58\u51cf\u5c11\u9ad8\u8fbe69.3%\uff0c\u5cf0\u503cGPU\u5185\u5b58\u51cf\u5c1134.4%\uff0c\u5e73\u5747\u8bad\u7ec3\u5468\u671fCPU\u65f6\u95f4\u51cf\u5c11\u7ea617%\uff0c\u5e73\u5747\u8bad\u7ec3\u5468\u671fGPU\u65f6\u95f4\u51cf\u5c11\u7ea624%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684Self-DANA\u65b9\u6848\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u8f83\u5c11\u8f93\u5165\u901a\u9053\u6570\u4e0b\u7684\u8d44\u6e90\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u5728\u4e94\u4e2a\u51cf\u5c11\u901a\u9053\u6570\u7684\u914d\u7f6e\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.15349", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.15349", "abs": "https://arxiv.org/abs/2507.15349", "authors": ["Zehua Cheng", "Rui Sun", "Jiahao Sun", "Yike Guo"], "title": "Scaling Decentralized Learning with FLock", "comment": null, "summary": "Fine-tuning the large language models (LLMs) are prevented by the deficiency\nof centralized control and the massive computing and communication overhead on\nthe decentralized schemes. While the typical standard federated learning (FL)\nsupports data privacy, the central server requirement creates a single point of\nattack and vulnerability to poisoning attacks. Generalizing the result in this\ndirection to 70B-parameter models in the heterogeneous, trustless environments\nhas turned out to be a huge, yet unbroken bottleneck. This paper introduces\nFLock, a decentralized framework for secure and efficient collaborative LLM\nfine-tuning. Integrating a blockchain-based trust layer with economic\nincentives, FLock replaces the central aggregator with a secure, auditable\nprotocol for cooperation among untrusted parties. We present the first\nempirical validation of fine-tuning a 70B LLM in a secure, multi-domain,\ndecentralized setting. Our experiments show the FLock framework defends against\nbackdoor poisoning attacks that compromise standard FL optimizers and fosters\nsynergistic knowledge transfer. The resulting models show a >68% reduction in\nadversarial attack success rates. The global model also demonstrates superior\ncross-domain generalization, outperforming models trained in isolation on their\nown specialized data.", "AI": {"tldr": "FLock\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u5229\u7528\u533a\u5757\u94fe\u548c\u7ecf\u6d4e\u6fc0\u52b1\u5b89\u5168\u9ad8\u6548\u5730\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u4e2d\u5fc3\u5316\u98ce\u9669\u548c\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\uff0c\u5e76\u6210\u529f\u9632\u5fa1\u4e86\u4e2d\u6bd2\u653b\u51fb\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u65f6\uff0c\u4e2d\u5fc3\u5316\u63a7\u5236\u7684\u4e0d\u8db3\u4ee5\u53ca\u53bb\u4e2d\u5fc3\u5316\u65b9\u6848\u4e2d\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u540c\u65f6\u5e94\u5bf9\u6807\u51c6\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u4e2d\u5fc3\u670d\u52a1\u5668\u7684\u5355\u70b9\u653b\u51fb\u548c\u4e2d\u6bd2\u653b\u51fb\u98ce\u9669\u3002", "method": "FLock\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u4fe1\u4efb\u5c42\u548c\u7ecf\u6d4e\u6fc0\u52b1\uff0c\u7528\u4e00\u4e2a\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u534f\u8bae\u6765\u4fc3\u8fdb\u4e0d\u53ef\u4fe1\u65b9\u4e4b\u95f4\u7684\u534f\u4f5c\uff0c\u53d6\u4ee3\u4e86\u4e2d\u5fc3\u805a\u5408\u5668\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u9ad8\u6548\u7684LLM\u534f\u4f5c\u5fae\u8c03\u3002", "result": "\u9996\u6b21\u5728\u5b89\u5168\u3001\u591a\u57df\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u73af\u5883\u4e2d\u5bf970B LLM\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8868\u660eFLock\u6846\u67b6\u80fd\u591f\u62b5\u5fa1\u540e\u95e8\u4e2d\u6bd2\u653b\u51fb\uff0c\u5e76\u63d0\u5347\u6a21\u578b\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u964d\u4f4e\u4e8668%\u4ee5\u4e0a\u7684\u5bf9\u6297\u6027\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "FLock\u6846\u67b6\u80fd\u591f\u9632\u5fa1\u9488\u5bf9\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u5668\u7684\u540e\u95e8\u4e2d\u6bd2\u653b\u51fb\uff0c\u5e76\u4fc3\u8fdb\u534f\u540c\u77e5\u8bc6\u8f6c\u79fb\u3002\u6700\u7ec8\u7684\u6a21\u578b\u5728\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u4f18\u4e8e\u5728\u5404\u81ea\u4e13\u4e1a\u6570\u636e\u4e0a\u72ec\u7acb\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5176\u5bf9\u6297\u6027\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u4e8668%\u4ee5\u4e0a\u3002"}}
{"id": "2507.14903", "categories": ["cs.RO", "I.2.9; I.2.10; I.2.11"], "pdf": "https://arxiv.org/pdf/2507.14903", "abs": "https://arxiv.org/abs/2507.14903", "authors": ["Pan Hu"], "title": "CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning", "comment": "8 pages, 5 figures", "summary": "Autonomous driving demands reliable and efficient solutions to closely\nrelated problems such as decision-making and motion planning. In this work,\ndecision-making refers specifically to highway lane selection, while motion\nplanning involves generating control commands (such as speed and steering) to\nreach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),\nachieving both flexible and safe lane selection alongside precise trajectory\nexecution remains a significant challenge. This paper proposes a framework\ncalled Cohesive Decision-Guided Motion Planning (CDGMP), which tightly\nintegrates decision-making and motion planning using a Mixture of Experts (MoE)\ninspired architecture combined with multi-policy reinforcement learning. By\ncoordinating multiple specialized sub-networks through a gating mechanism, the\nmethod decomposes the complex driving task into modular components. Each\nsub-network focuses on a specific aspect of driving, improving efficiency by\nactivating only the most relevant modules during inference. This design also\nenhances safety through modular specialization. CDGMP improves the adaptability\nand robustness of CAVs across diverse traffic scenarios, offering a scalable\nsolution to real-world autonomy challenges. The architectural principles behind\nCDGMP, especially the use of MoE, also provide a strong foundation for other\nhigh-dimensional decision and control tasks. Simulation results (available at\nhttps://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane\nselection and motion planning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14459", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14459", "abs": "https://arxiv.org/abs/2507.14459", "authors": ["Huayuan Ye", "Juntong Chen", "Shenzhuo Zhang", "Yipeng Zhang", "Changbo Wang", "Chenhui Li"], "title": "VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval", "comment": "9 pages, IEEE VIS 2025", "summary": "The dissemination of visualizations is primarily in the form of raster\nimages, which often results in the loss of critical information such as source\ncode, interactive features, and metadata. While previous methods have proposed\nembedding metadata into images to facilitate Visualization Image Data Retrieval\n(VIDR), most existing methods lack practicability since they are fragile to\ncommon image tampering during online distribution such as cropping and editing.\nTo address this issue, we propose VisGuard, a tamper-resistant VIDR framework\nthat reliably embeds metadata link into visualization images. The embedded data\nlink remains recoverable even after substantial tampering upon images. We\npropose several techniques to enhance robustness, including repetitive data\ntiling, invertible information broadcasting, and an anchor-based scheme for\ncrop localization. VisGuard enables various applications, including interactive\nchart reconstruction, tampering detection, and copyright protection. We conduct\ncomprehensive experiments on VisGuard's superior performance in data retrieval\naccuracy, embedding capacity, and security against tampering and steganalysis,\ndemonstrating VisGuard's competence in facilitating and safeguarding\nvisualization dissemination and information conveyance.", "AI": {"tldr": "VisGuard is a robust framework that embeds recoverable metadata links into visualization images, protecting against tampering and enabling applications like interactive reconstruction and copyright protection.", "motivation": "Existing methods for embedding metadata into visualization images for retrieval (VIDR) are often fragile to common image tampering (e.g., cropping, editing) during online distribution, leading to information loss.", "method": "The proposed VisGuard framework embeds metadata links into visualization images using techniques like repetitive data tiling, invertible information broadcasting, and an anchor-based scheme for crop localization to ensure recoverability even after image tampering.", "result": "VisGuard reliably embeds metadata links into visualization images, ensuring they remain recoverable even after substantial tampering, thereby facilitating and safeguarding visualization dissemination and information conveyance.", "conclusion": "VisGuard enables various applications, including interactive chart reconstruction, tampering detection, and copyright protection, demonstrating superior performance in data retrieval accuracy, embedding capacity, and security against tampering and steganalysis."}}
{"id": "2507.14520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14520", "abs": "https://arxiv.org/abs/2507.14520", "authors": ["Xinyi Chen", "Yifei Yuan", "Jiaang Li", "Serge Belongie", "Maarten de Rijke", "Anders S\u00f8gaard"], "title": "What if Othello-Playing Language Models Could See?", "comment": "ICML 2025 Assessing World Models Workshop", "summary": "Language models are often said to face a symbol grounding problem. While some\nargue that world understanding can emerge from text alone, others suggest\ngrounded learning is more efficient. We explore this through Othello, where the\nboard state defines a simplified, rule-based world. Building on prior work, we\nintroduce VISOTHELLO, a multi-modal model trained on move histories and board\nimages. Using next-move prediction, we compare it to mono-modal baselines and\ntest robustness to semantically irrelevant perturbations. We find that\nmulti-modal training improves both performance and the robustness of internal\nrepresentations. These results suggest that grounding language in visual input\nhelps models infer structured world representations.", "AI": {"tldr": "VISOTHELLO\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5b83\u5728\u68cb\u5c40\u8bb0\u5f55\u548c\u68cb\u76d8\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u901a\u8fc7\u4e0e\u5355\u6a21\u6001\u6a21\u578b\u7684\u6bd4\u8f83\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u8bad\u7ec3\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4f1a\u9762\u4e34\u7b26\u53f7\u4e3b\u4e49\u96be\u9898\uff0c\u4ee5\u53ca\u4ec5\u901a\u8fc7\u6587\u672c\u8fdb\u884c\u4e16\u754c\u7406\u89e3\uff0c\u8fd8\u662f\u901a\u8fc7\u591a\u6a21\u6001\u5b66\u4e60\u80fd\u66f4\u6709\u6548\u5730\u8fdb\u884c\u4e16\u754c\u7406\u89e3\u3002", "method": "\u672c\u6587\u63d0\u51faVISOTHELLO\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a\u5728\u68cb\u5c40\u8bb0\u5f55\u548c\u68cb\u76d8\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u6a21\u578b\u7684\u4e0b\u4e00\u6b65\u9884\u6d4b\u4efb\u52a1\u6765\u4e0e\u5355\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u540c\u65f6\u6d4b\u8bd5\u5176\u5bf9\u8bed\u4e49\u4e0a\u4e0d\u76f8\u5173\u7684\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "result": "\u4e0e\u5355\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cVISOTHELLO\u5728\u6027\u80fd\u548c\u5185\u90e8\u8868\u5f81\u7684\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u6709\u6240\u63d0\u9ad8\uff0c\u8fd9\u8868\u660e\u591a\u6a21\u6001\u8bad\u7ec3\u6709\u52a9\u4e8e\u6a21\u578b\u901a\u8fc7\u89c6\u89c9\u8f93\u5165\u8fdb\u884c\u63a8\u7406\uff0c\u4ece\u800c\u5b66\u4e60\u5230\u7ed3\u6784\u5316\u7684\u4e16\u754c\u8868\u5f81\u3002", "conclusion": "\u591a\u6a21\u6001\u8bad\u7ec3\u6709\u52a9\u4e8e\u6a21\u578b\u901a\u8fc7\u89c6\u89c9\u8f93\u5165\u8fdb\u884c\u63a8\u7406\uff0c\u4ece\u800c\u5b66\u4e60\u5230\u7ed3\u6784\u5316\u7684\u4e16\u754c\u8868\u5f81\uff0c\u5e76\u63d0\u9ad8\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.15451", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.15451", "abs": "https://arxiv.org/abs/2507.15451", "authors": ["Yichen Chu", "Qizhong Zhu"], "title": "$\\mathbb{Z}_2$ topological trion insulator", "comment": null, "summary": "Trions, charged quasiparticles formed by binding an exciton to an excess\ncharge carrier, dominate the optical response of doped transition metal\ndichalcogenides (TMDs), and the study of the transport properties of trions in\nTMDs may have application in developing high-speed excitonic and optoelectronic\ndevices. However, an important building block for low-dissipation\noptoelectronic devices that provides dissipationless transport channels for\ntrions has remained elusive. Here, we propose the concept of a $\\mathbb{Z}_2$\ntopological trion insulator that features helical dissipationless edge states\nfor trions. This is realized for intralayer trions, which inherit the\nvalley-orbit coupling of intralayer excitons in TMDs subject to a moir\\'e\nperiodic potential. We find that under certain circumstances, the moir\\'e trion\nband becomes topological, characterized by the $\\mathbb{Z}_2$ topological\nnumber. We further provide two specific material realizations of this\n$\\mathbb{Z}_2$ topological insulator: a doped monolayer TMD placed on top of a\ntwisted hBN substrate, and a generic twisted TMD heterobilayer. We also examine\nthe effect of charge screening and find that the $\\mathbb{Z}_2$ topological\ntrion insulator remains robust. Our work paves the way toward realizing\ndissipationless excitonic devices.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u62d3\u6251\u4e09\u5b50\u7edd\u7f18\u4f53\uff0c\u5b9e\u73b0\u4e86\u4e09\u5b50\u7684\u65e0\u8017\u6563\u8fb9\u7f18\u6001\uff0c\u4e3a\u5f00\u53d1\u65e0\u8017\u6563\u5668\u4ef6\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u4e3a\u4e86\u5728\u63ba\u6742\u8fc7\u6e21\u91d1\u5c5e\u786b\u5c5e\u5316\u7269\uff08TMDs\uff09\u4e2d\u5b9e\u73b0\u7528\u4e8e\u5f00\u53d1\u9ad8\u901f\u6fc0\u5b50\u548c\u5149\u7535\u5668\u4ef6\u7684\u4e09\u5b50\u8f93\u8fd0\u6027\u8d28\uff0c\u5e76\u5bfb\u627e\u63d0\u4f9b\u4e09\u5b50\u65e0\u8017\u6563\u8f93\u8fd0\u901a\u9053\u7684\u5173\u952e\u6784\u4ef6\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u83ab\u5c14\u8d85\u6676\u683c\u52bf\uff0c\u5229\u7528\u5185\u7980\u4e09\u5b50\u6781\u5316\u5b50\u7684\u8c37-\u8f68\u9053\u8026\u5408\uff0c\u4f7f\u83ab\u5c14\u4e09\u5b50\u6781\u5316\u5b50\u80fd\u5e26\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5448\u73b0\u62d3\u6251\u6027\uff0c\u5e76\u8ba1\u7b97\u5176 $\\mathbb{Z}_2$ \u62d3\u6251\u6570\u3002", "result": "\u53d1\u73b0\u4e86\u83ab\u5c14\u4e09\u5b50\u6781\u5316\u5b50\u80fd\u5e26\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u5b9e\u73b0\u62d3\u6251\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u79cd\u5177\u4f53\u7684\u6750\u6599\u5b9e\u73b0\uff08\u63ba\u6742\u5355\u5c42TMD/\u626d\u66f2hBN\u886c\u5e95\u548c\u626d\u66f2TMD\u5f02\u8d28\u53cc\u5c42\uff09\uff0c\u8bc1\u660e\u4e86\u5176\u5bf9\u7535\u8377\u5c4f\u853d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86 $\\mathbb{Z}_2$ \u62d3\u6251\u4e09\u5b50\u6781\u5316\u5b50\u7edd\u7f18\u4f53\u6982\u5ff5\uff0c\u4e3a\u4e09\u5b50\u63d0\u4f9b\u87ba\u65cb\u65e0\u8017\u6563\u8fb9\u7f18\u6001\uff0c\u5e76\u5728\u63ba\u6742\u7684\u5355\u5c42\u8fc7\u6e21\u91d1\u5c5e\u786b\u5c5e\u5316\u7269\u548c\u626d\u66f2\u7684\u8fc7\u6e21\u91d1\u5c5e\u786b\u5c5e\u5316\u7269\u5f02\u8d28\u53cc\u5c42\u4e2d\u5b9e\u73b0\u4e86\u8be5\u6982\u5ff5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7535\u8377\u5c4f\u853d\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9e\u73b0\u65e0\u8017\u6563\u6fc0\u5b50\u5668\u4ef6\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14215", "categories": ["cs.LG", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.14215", "abs": "https://arxiv.org/abs/2507.14215", "authors": ["Jiayu", "Liu"], "title": "Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired", "comment": null, "summary": "This study aims to develop a deep learning system for an accessibility device\nfor the deaf or hearing impaired. The device will accurately localize and\nidentify sound sources in real time. This study will fill an important gap in\ncurrent research by leveraging machine learning techniques to target the\nunderprivileged community. The system includes three main components. 1.\nJerryNet: A custom designed CNN architecture that determines the direction of\narrival (DoA) for nine possible directions. 2. Audio Classification: This model\nis based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model\nto identify the exact sound classes only based on audio. 3. Multimodal\nintegration model: This is an accurate sound localization model that combines\naudio, visual, and text data to locate the exact sound sources in the images.\nThe part consists of two modules, one object detection using Yolov9 to generate\nall the bounding boxes of the objects, and an audio visual localization model\nto identify the optimal bounding box using complete Intersection over Union\n(CIoU). The hardware consists of a four-microphone rectangular formation and a\ncamera mounted on glasses with a wristband for displaying necessary information\nlike direction. On a custom collected data set, JerryNet achieved a precision\nof 91. 1% for the sound direction, outperforming all the baseline models. The\nCLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets,\nrespectively. The audio-visual localization model within component 3 yielded a\ncIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are\nmany future potentials to this study, paving the way to creating a new\ngeneration of accessibility devices.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u6b3e\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8f85\u52a9\u8bbe\u5907\uff0c\u80fd\u5b9e\u65f6\u8bc6\u522b\u548c\u5b9a\u4f4d\u58f0\u6e90\uff0c\u4e3a\u542c\u969c\u4eba\u58eb\u63d0\u4f9b\u5e2e\u52a9\u3002\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86CNN\u3001CLAP\u6a21\u578b\u548c\u591a\u6a21\u6001\u878d\u5408\u6280\u672f\uff0c\u5e76\u5728\u7cbe\u786e\u7387\u3001\u51c6\u786e\u7387\u548c\u5b9a\u4f4d\u6027\u80fd\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u5f02\u7ed3\u679c\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u804b\u54d1\u6216\u542c\u529b\u969c\u788d\u4eba\u58eb\u5f00\u53d1\u4e00\u6b3e\u80fd\u591f\u5b9e\u65f6\u51c6\u786e\u8bc6\u522b\u548c\u5b9a\u4f4d\u58f0\u6e90\u7684\u6df1\u5ea6\u5b66\u4e60\u8f85\u52a9\u8bbe\u5907\uff0c\u4ee5\u586b\u8865\u5f53\u524d\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u670d\u52a1\u4e8e\u5f31\u52bf\u7fa4\u4f53\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u7ec4\u4ef6\u7684\u7cfb\u7edf\uff1a1. JerryNet\uff1a\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u67b6\u6784\uff0c\u7528\u4e8e\u786e\u5b9a\u4e5d\u4e2a\u53ef\u80fd\u65b9\u5411\u7684\u5230\u8fbe\u89d2\uff08DoA\uff09\u30022. \u97f3\u9891\u5206\u7c7b\uff1a\u57fa\u4e8e\u5bf9\u6bd4\u8bed\u8a00-\u97f3\u9891\u9884\u8bad\u7ec3\uff08CLAP\uff09\u6a21\u578b\u7684\u5fae\u8c03\uff0c\u4ec5\u901a\u8fc7\u97f3\u9891\u8bc6\u522b\u58f0\u97f3\u7c7b\u522b\u30023. \u591a\u6a21\u6001\u878d\u5408\u6a21\u578b\uff1a\u7ed3\u5408\u97f3\u9891\u3001\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\uff0c\u5229\u7528Yolov9\u8fdb\u884c\u7269\u4f53\u68c0\u6d4b\u548c\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\u6a21\u578b\uff08\u57fa\u4e8eCIoU\uff09\u6765\u7cbe\u786e\u5b9a\u4f4d\u58f0\u6e90\u3002\u786c\u4ef6\u5305\u62ec\u56db\u9ea6\u514b\u98ce\u9635\u5217\u548c\u96c6\u6210\u5728\u773c\u955c\u4e0a\u7684\u6444\u50cf\u5934\uff0c\u5e76\u901a\u8fc7\u8155\u5e26\u663e\u793a\u4fe1\u606f\u3002", "result": "JerryNet\u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8691.1%\u7684\u58f0\u6e90\u65b9\u5411\u7cbe\u786e\u7387\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u3002CLAP\u6a21\u578b\u5728\u81ea\u5b9a\u4e49\u548cAudioSet\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u5206\u522b\u4e3a98.5%\u548c95%\u3002\u591a\u6a21\u6001\u878d\u5408\u6a21\u578b\u5728\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\u65b9\u9762\u53d6\u5f97\u4e860.892\u7684cIoU\u548c0.658\u7684AUC\uff0c\u8d85\u8d8a\u4e86\u5176\u4ed6\u7c7b\u4f3c\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e3a\u804b\u54d1\u6216\u542c\u529b\u969c\u788d\u4eba\u58eb\u5f00\u53d1\u8f85\u52a9\u8bbe\u5907\u3002\u8be5\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u51c6\u786e\u5730\u5b9a\u4f4d\u548c\u8bc6\u522b\u58f0\u6e90\uff0c\u586b\u8865\u4e86\u5f53\u524d\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u6709\u671b\u4e3a\u5f31\u52bf\u7fa4\u4f53\u5e26\u6765\u65b0\u7684\u8f85\u52a9\u6280\u672f\u3002"}}
{"id": "2507.14580", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14580", "abs": "https://arxiv.org/abs/2507.14580", "authors": ["Fangqi Cai", "Mingxi Chi", "Yingjie Hu", "Heyao Liu", "Yangyang Chen", "Chao Jing", "Wei Ren", "He Wang"], "title": "Investigation on high-order planar Hall effect in trigonal PtBi$_2$", "comment": "18 pages, 4 figures,", "summary": "The trigonal PtBi$_2$ (t-PtBi$_2$) as a Weyl semimetal possessing triply\ndegenerate points in its electronic bands near the Fermi level endows it with\nrich electronic properties. Previous studies have already measured the planar\nHall effect (PHE) and in-plane anisotropic magnetoresistance (AMR) of\nt-PtBi$_2$. We noticed that their experimental results exhibited high-order\nfeatures in both the PHE and AMR, yet these features were not systematically\ninvestigated. In our work, we conducted more systematic measurements and\nanalyses of the PHE and AMR in t-PtBi$_2$. Both PHE and AMR show high-order\nfeatures under low temperatures and strong magnetic fields, and these features\nshare a similar temperature and magnetic field dependence with the turn-on\nbehavior of resistance and temperature curves, indicating a common physical\norigin for them. We further summarize the critical conditions for the emergence\nof high-order PHE in t-PtBi$_2$, which will help to understand the origin of\nhigh-order features. In addition, we performed computational simulations on the\nAMR of t-PtBi$_2$, and the results were consistent with the experiments,\nindicating the high-order features are the result of the combined contribution\nof the Fermi surface anisotropy and the scaling behavior of magnetoresistance.\nOur findings will contribute to a deeper understanding of the origins of\nhigh-order features in non-magnetic topological materials.", "AI": {"tldr": "t-PtBi$_2$\u7684PHE\u548cAMR\u5728\u9ad8\u9636\u7279\u5f81\u4e0a\u8868\u73b0\u51fa\u76f8\u4f3c\u7684\u6e29\u5ea6\u548c\u78c1\u573a\u4f9d\u8d56\u6027\uff0c\u6e90\u4e8e\u8d39\u7c73\u9762\u5404\u5411\u5f02\u6027\u548c\u78c1\u963b\u7684\u6807\u5ea6\u884c\u4e3a\u3002", "motivation": "\u524d\u671f\u7814\u7a76\u89c2\u5bdf\u5230t-PtBi$_2$\u7684PHE\u548cAMR\u8868\u73b0\u51fa\u9ad8\u9636\u7279\u5f81\uff0c\u4f46\u672a\u7cfb\u7edf\u7814\u7a76\uff0c\u672c\u5de5\u4f5c\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u8fd9\u4e9b\u7279\u5f81\u3002", "method": "\u901a\u8fc7\u5728\u4f4e\u6e29\u548c\u5f3a\u78c1\u573a\u4e0b\u8fdb\u884c\u7cfb\u7edf\u6027\u7684PHE\u548cAMR\u6d4b\u91cf\uff0c\u5e76\u7ed3\u5408\u8ba1\u7b97\u6a21\u62df\uff0c\u5206\u6790\u4e86t-PtBi$_2$\u7684\u7535\u5b50\u7279\u6027\u3002", "result": "PHE\u548cAMR\u5728\u9ad8\u9636\u7279\u5f81\u4e0a\u8868\u73b0\u51fa\u76f8\u4f3c\u7684\u6e29\u5ea6\u548c\u78c1\u573a\u4f9d\u8d56\u6027\uff0c\u4e14\u4e0e\u7535\u963b\u7684\u5f00\u542f\u884c\u4e3a\u76f8\u5173\u3002\u8ba1\u7b97\u6a21\u62df\u7ed3\u679c\u4e0e\u5b9e\u9a8c\u4e00\u81f4\uff0c\u8868\u660e\u9ad8\u9636\u7279\u5f81\u6e90\u4e8e\u8d39\u7c73\u9762\u5404\u5411\u5f02\u6027\u548c\u78c1\u963b\u7684\u6807\u5ea6\u884c\u4e3a\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6d4b\u91cf\u548c\u8ba1\u7b97\u6a21\u62df\uff0c\u63ed\u793a\u4e86\u4e09\u65b9PtBi$_2$\uff08t-PtBi$_2$\uff09\u4e2d\u5e73\u9762\u970d\u5c14\u6548\u5e94\uff08PHE\uff09\u548c\u9762\u5185\u78c1\u963b\uff08AMR\uff09\u7684\u9ad8\u9636\u7279\u5f81\u53ca\u5176\u7269\u7406\u8d77\u6e90\uff0c\u4e3a\u7406\u89e3\u975e\u78c1\u6027\u62d3\u6251\u6750\u6599\u4e2d\u9ad8\u9636\u7279\u5f81\u7684\u4ea7\u751f\u673a\u5236\u63d0\u4f9b\u4e86\u6df1\u5165\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14863", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14863", "abs": "https://arxiv.org/abs/2507.14863", "authors": ["Hampei Sasahara"], "title": "Adversarial Destabilization Attacks to Direct Data-Driven Control", "comment": "15 pages", "summary": "This study investigates the vulnerability of direct data-driven control\nmethods, specifically for the linear quadratic regulator problem, to\nadversarial perturbations in collected data used for controller synthesis. We\nconsider stealthy attacks that subtly manipulate offline-collected data to\ndestabilize the resulting closed-loop system while evading detection. To\ngenerate such perturbations, we propose the Directed Gradient Sign Method\n(DGSM) and its iterative variant (I-DGSM), adaptations of the fast gradient\nsign method originally developed for neural networks, which align perturbations\nwith the gradient of the spectral radius of the closed-loop matrix to reduce\nstability. A key contribution is an efficient gradient computation technique\nbased on implicit differentiation through the Karush-Kuhn-Tucker conditions of\nthe underlying semidefinite program, enabling scalable and exact gradient\nevaluation without repeated optimization computations. To defend against these\nattacks, we propose two defense strategies: a regularization-based approach\nthat enhances robustness by suppressing controller sensitivity to data\nperturbations and a robust data-driven control approach that guarantees\nclosed-loop stability within bounded perturbation sets. Extensive numerical\nexperiments on benchmark systems show that adversarial perturbations with\nmagnitudes up to ten times smaller than random noise can destabilize\ncontrollers trained on corrupted data and that the proposed defense strategies\neffectively mitigate attack success rates while maintaining control\nperformance. Additionally, we evaluate attack transferability under partial\nknowledge scenarios, highlighting the practical importance of protecting\ntraining data confidentiality.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6cd5\u5728\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u76f4\u63a5\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6cd5\uff08\u7279\u522b\u662fLQR\u95ee\u9898\uff09\u5bf9\u7528\u4e8e\u63a7\u5236\u5668\u7efc\u5408\u7684\u6536\u96c6\u6570\u636e\u4e2d\u7684\u5bf9\u6297\u6027\u6270\u52a8\u7684\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51faDGSM\u548cI-DGSM\u65b9\u6cd5\u6765\u751f\u6210\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u548c\u9c81\u68d2\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6cd5\u6765\u9632\u5fa1\u653b\u51fb\u3002", "result": "DGSM\u548cI-DGSM\u653b\u51fb\u7684\u6270\u52a8\u5e45\u5ea6\u6bd4\u968f\u673a\u566a\u58f0\u5c0f10\u500d\uff0c\u5373\u53ef\u7834\u574f\u63a7\u5236\u5668\u3002\u6240\u63d0\u51fa\u7684\u9632\u5fa1\u7b56\u7565\u80fd\u6709\u6548\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u63a7\u5236\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684DGSM\u548cI-DGSM\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u6709\u6548\u7684\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u4e14\u6240\u63d0\u51fa\u7684\u6b63\u5219\u5316\u548c\u9c81\u68d2\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u63a7\u5236\u6027\u80fd\u3002\u653b\u51fb\u7684\u8fc1\u79fb\u6027\u7814\u7a76\u4e5f\u51f8\u663e\u4e86\u4fdd\u62a4\u8bad\u7ec3\u6570\u636e\u673a\u5bc6\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.14531", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14531", "abs": "https://arxiv.org/abs/2507.14531", "authors": ["Peng Wang", "Bin-Han Lu", "Tian-Le Wang", "Sheng Zhang", "Zhao-Yun Chen", "Hai-Feng Zhang", "Ren-Ze Zhao", "Xiao-Yan Yang", "Ze-An Zhao", "Zhuo-Zhi Zhang", "Xiang-Xiang Song", "Yu-Chun Wu", "Peng Duan", "Guo-Ping Guo"], "title": "Spectator Leakage Elimination in CZ Gates via Tunable Coupler Interference on a Superconducting Quantum Processor", "comment": "6 pages, 4 figures in main text", "summary": "Spectator-induced leakage poses a fundamental challenge to scalable quantum\ncomputing, particularly as frequency collisions become unavoidable in\nmulti-qubit processors. We introduce a leakage mitigation strategy based on\ndynamically reshaping the system Hamiltonian. Our technique utilizes a tunable\ncoupler to enforce a block-diagonal structure on the effective Hamiltonian\ngoverning near-resonant spectator interactions, confining the gate dynamics to\na two-dimensional invariant subspace and thus preventing leakage by\nconstruction. On a multi-qubit superconducting processor, we experimentally\ndemonstrate that this dynamic control scheme suppresses leakage rates to the\norder of $10^{-4}$ across a wide near-resonant detuning range. The method also\nscales effectively with the number of spectators. With three simultaneous\nspectators, the total leakage remains below the threshold relevant for surface\ncode error correction. This approach eases the tension between dense frequency\npacking and high-fidelity gate operation, establishing dynamic Hamiltonian\nengineering as an essential tool for advancing fault-tolerant quantum\ncomputing.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u54c8\u5bc6\u987f\u91cf\u91cd\u5851\u7684\u6cc4\u6f0f\u6291\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u95e8\u52a8\u529b\u5b66\u9650\u5236\u5728\u4e8c\u7ef4\u4e0d\u53d8\u5b50\u7a7a\u95f4\u5185\uff0c\u6709\u6548\u9632\u6b62\u6cc4\u6f0f\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u53ef\u6269\u5c55\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7531\u5149\u8c31\u8bf1\u5bfc\u6cc4\u6f0f\u5f15\u8d77\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u591a\u91cf\u5b50\u6bd4\u7279\u5904\u7406\u5668\u4e2d\u9891\u7387\u78b0\u649e\u4e0d\u53ef\u907f\u514d\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u901a\u8fc7\u53ef\u8c03\u8026\u5408\u5668\u52a8\u6001\u91cd\u5851\u7cfb\u7edf\u54c8\u5bc6\u987f\u91cf\uff0c\u5b9e\u73b0\u5176\u6709\u6548\u54c8\u5bc6\u987f\u91cf\u7684\u5757\u5bf9\u89d2\u5316\u7ed3\u6784\uff0c\u5c06\u95e8\u64cd\u4f5c\u9650\u5236\u5728\u4e8c\u7ef4\u4e0d\u53d8\u5b50\u7a7a\u95f4\u5185\uff0c\u4ece\u800c\u4ece\u6839\u672c\u4e0a\u6d88\u9664\u6cc4\u6f0f\u3002", "result": "\u5728\u8d85\u5bfc\u5904\u7406\u5668\u4e0a\uff0c\u8be5\u6280\u672f\u5728\u8f83\u5bbd\u7684\u8fd1\u5171\u632f\u5931\u8c10\u8303\u56f4\u5185\u5c06\u6cc4\u6f0f\u7387\u6291\u5236\u5230 $10^{-4}$ \u7684\u91cf\u7ea7\uff0c\u5e76\u4e14\u968f\u7740\u5149\u8c31\u6570\u91cf\u7684\u589e\u52a0\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002\u5728\u6709\u4e09\u4e2a\u540c\u65f6\u5149\u8c31\u7684\u60c5\u51b5\u4e0b\uff0c\u603b\u6cc4\u6f0f\u91cf\u4f4e\u4e8e\u8868\u9762\u7801\u7ea0\u9519\u7684\u76f8\u5173\u9608\u503c\u3002", "conclusion": "\u52a8\u6001\u54c8\u5bc6\u987f\u91cf\u5de5\u7a0b\u662f\u63a8\u8fdb\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u7684\u5173\u952e\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u7f13\u89e3\u91cf\u5b50\u6bd4\u7279\u9891\u7387\u78b0\u649e\u95ee\u9898\u3002"}}
{"id": "2507.14314", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14314", "abs": "https://arxiv.org/abs/2507.14314", "authors": ["Marija An\u0111edeli\u0107", "Dominik \u0160ipek", "Laura Majer", "Jan \u0160najder"], "title": "What Makes You CLIC: Detection of Croatian Clickbait Headlines", "comment": "Accepted at Slavic NLP 2025", "summary": "Online news outlets operate predominantly on an advertising-based revenue\nmodel, compelling journalists to create headlines that are often scandalous,\nintriguing, and provocative -- commonly referred to as clickbait. Automatic\ndetection of clickbait headlines is essential for preserving information\nquality and reader trust in digital media and requires both contextual\nunderstanding and world knowledge. For this task, particularly in\nless-resourced languages, it remains unclear whether fine-tuned methods or\nin-context learning (ICL) yield better results. In this paper, we compile CLIC,\na novel dataset for clickbait detection of Croatian news headlines spanning a\n20-year period and encompassing mainstream and fringe outlets. We fine-tune the\nBERTi\\'c model on this task and compare its performance to LLM-based ICL\nmethods with prompts both in Croatian and English. Finally, we analyze the\nlinguistic properties of clickbait. We find that nearly half of the analyzed\nheadlines contain clickbait, and that finetuned models deliver better results\nthan general LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7CLIC\u6570\u636e\u96c6\u548cBERTi'c\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5728\u514b\u7f57\u5730\u4e9a\u8bed\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u65b9\u9762\uff0c\u5fae\u8c03\u65b9\u6cd5\u6bd4\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u5728\u7ebf\u65b0\u95fb\u4e3b\u8981\u4f9d\u8d56\u5e7f\u544a\u6536\u5165\uff0c\u5bfc\u81f4\u8bb0\u8005\u503e\u5411\u4e8e\u64b0\u5199\u8038\u4eba\u542c\u95fb\u3001\u5f15\u4eba\u5165\u80dc\u548c\u6311\u8845\u6027\u7684\u6807\u9898\uff08\u5373\u70b9\u51fb\u8bf1\u9975\uff09\u3002\u81ea\u52a8\u68c0\u6d4b\u70b9\u51fb\u8bf1\u9975\u5bf9\u4e8e\u7ef4\u62a4\u6570\u5b57\u5a92\u4f53\u7684\u4fe1\u606f\u8d28\u91cf\u548c\u8bfb\u8005\u4fe1\u4efb\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u8f83\u5c11\u7684\u8bed\u8a00\u4e2d\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u5fae\u8c03\u65b9\u6cd5\u6216\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u662f\u5426\u80fd\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\u3002", "method": "\u672c\u7814\u7a76\u7f16\u8bd1\u4e86CLIC\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u6db5\u76d6\u4e8620\u5e74\u95f4\u7684\u514b\u7f57\u5730\u4e9a\u65b0\u95fb\u6807\u9898\uff0c\u7528\u4e8e\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u3002\u7814\u7a76\u4eba\u5458\u5fae\u8c03\u4e86BERTi'c\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u4e0e\u4f7f\u7528\u514b\u7f57\u5730\u4e9a\u8bed\u548c\u82f1\u8bed\u63d0\u793a\u7684\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u5728CLIC\u6570\u636e\u96c6\u4e2d\uff0c\u8fd1\u4e00\u534a\u7684\u6807\u9898\u88ab\u8bc6\u522b\u4e3a\u70b9\u51fb\u8bf1\u9975\u3002\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u7684LLM\u3002", "conclusion": "\u5fae\u8c03\u6a21\u578b\u5728\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2507.15598", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.15598", "abs": "https://arxiv.org/abs/2507.15598", "authors": ["Ruoxu Cen", "Henry Fleischmann", "George Z. Li", "Jason Li", "Debmalya Panigrahi"], "title": "Fast Algorithms for Graph Arboricity and Related Problems", "comment": "FOCS 2025. 25 pages, 3 figures", "summary": "We give an algorithm for finding the arboricity of a weighted, undirected\ngraph, defined as the minimum number of spanning forests that cover all edges\nof the graph, in $\\sqrt{n} m^{1+o(1)}$ time. This improves on the previous best\nbound of $\\tilde{O}(nm)$ for weighted graphs and $\\tilde{O}(m^{3/2}) $ for\nunweighted graphs (Gabow 1995) for this problem. The running time of our\nalgorithm is dominated by a logarithmic number of calls to a directed global\nminimum cut subroutine -- if the running time of the latter problem improves to\n$m^{1+o(1)}$ (thereby matching the running time of maximum flow), the running\ntime of our arboricity algorithm would improve further to $m^{1+o(1)}$.\n  We also give a new algorithm for computing the entire cut hierarchy --\nlaminar multiway cuts with minimum cut ratio in recursively defined induced\nsubgraphs -- in $m n^{1+o(1)}$ time. The cut hierarchy yields the ideal edge\nloads (Thorup 2001) in a fractional spanning tree packing of the graph which,\nwe show, also corresponds to a max-entropy solution in the spanning tree\npolytope. For the cut hierarchy problem, the previous best bound was\n$\\tilde{O}(n^2 m)$ for weighted graphs and $\\tilde{O}(n m^{3/2})$ for\nunweighted graphs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u8ba1\u7b97\u52a0\u6743\u65e0\u5411\u56fe\u7684\u6811\u5bbd\u5ea6\u548c\u5272\u5c42\u7ea7\u7684\u65b0\u7b97\u6cd5\uff0c\u8fd0\u884c\u65f6\u95f4\u5f97\u5230\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u63d0\u9ad8\u8ba1\u7b97\u52a0\u6743\u65e0\u5411\u56fe\u7684\u6811\u5bbd\u5ea6\u548c\u5272\u5c42\u7ea7\u7684\u6548\u7387\u3002", "method": "\u8be5\u7b97\u6cd5\u901a\u8fc7\u5bf9\u6709\u5411\u56fe\u5168\u5c40\u6700\u5c0f\u5272\u5b50\u7a0b\u5e8f\u8fdb\u884c\u5bf9\u6570\u6b21\u8c03\u7528\u6765\u5b9e\u73b0\uff0c\u5e76\u5728\u8ba1\u7b97\u5272\u5c42\u7ea7\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fd0\u884c\u65f6\u95f4\u4e3a $\\sqrt{n} m^{1+o(1)}$ \u7684\u7b97\u6cd5\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684\u6700\u4f18\u754c\u9650\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fd0\u884c\u65f6\u95f4\u4e3a $m n^{1+o(1)}$ \u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u5272\u5c42\u7ea7\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684\u6700\u4f18\u754c\u9650\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u8ba1\u7b97\u52a0\u6743\u65e0\u5411\u56fe\u7684\u6811\u5bbd\u5ea6\u548c\u6574\u4e2a\u5272\u5c42\u7ea7\u7684\u65b0\u7b97\u6cd5\u3002"}}
{"id": "2507.14152", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2507.14152", "abs": "https://arxiv.org/abs/2507.14152", "authors": ["Frank Efe Erukainure", "Feidra Gjata", "Matin Ataei Kachouei", "Henry Cox", "Md. Azahar Ali"], "title": "Machine learning-enabled river water quality monitoring using lithography-free 3D-printed sensors", "comment": "34 pages, 9 figures", "summary": "River water quality monitoring is important for aquatic life, livestock, and\nhumans because clean water is critical to meeting food demand during the global\nfood crisis. Excessive contaminants, including phosphate, deplete dissolved\noxygen and trigger eutrophication, leading to serious health and ecological\nproblems. Continuous sensors that track phosphate levels can therefore help\nprevent eutrophication. In this work we present a lithography-free phosphate\nsensor (P-sensor) that detects phosphate in river water at parts-per-billion\nlevels. The device uses a solid-state indicator electrode formed by 3D-printed\nperiodic polymer patterns (8 um feature size) coated with a thin phosphate\nion-selective membrane. The P-sensor detects as little as 1 ppb phosphate\nacross 0 - 475 ppm with a response time under 30 seconds. We validated the\nsensor on Rappahannock River water, Virginia (less than 0.8 ppm phosphate) at\nsites upstream and downstream of a sewage treatment plant and benchmarked the\nresults against a commercial phosphate meter. A feed-forward neural network was\ntrained to predict phosphate levels, achieving a mean-squared error below 1e-3,\nzero standard deviation, and a Pearson correlation coefficient of 0.997 for\nriver samples. These results demonstrate a practical tool for continuous\nwater-quality monitoring that can inform stakeholders and policymakers and\nultimately improve public health.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D\u6253\u5370\u6280\u672f\u7684\u78f7\u9178\u76d0\u4f20\u611f\u5668\uff0c\u80fd\u591f\u5feb\u901f\u3001\u51c6\u786e\u5730\u68c0\u6d4b\u6cb3\u6c34\u4e2d\u7684\u78f7\u9178\u76d0\u6c61\u67d3\uff0c\u4e3a\u6c34\u8d28\u76d1\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u6cb3\u6d41\u7684\u6c34\u8d28\u76d1\u6d4b\u5bf9\u4e8e\u6c34\u751f\u751f\u7269\u3001\u7272\u755c\u4ee5\u53ca\u4eba\u7c7b\u90fd\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5168\u7403\u7cae\u98df\u5371\u673a\u80cc\u666f\u4e0b\uff0c\u6e05\u6d01\u6c34\u662f\u6ee1\u8db3\u7cae\u98df\u9700\u6c42\u7684\u5173\u952e\u3002\u8fc7\u91cf\u7684\u6c61\u67d3\u7269\uff0c\u5982\u78f7\u9178\u76d0\uff0c\u4f1a\u6d88\u8017\u6eb6\u89e3\u6c27\u5e76\u5f15\u53d1\u5bcc\u8425\u517b\u5316\uff0c\u5bfc\u81f4\u4e25\u91cd\u7684\u73af\u5883\u548c\u5065\u5eb7\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u80fd\u591f\u6301\u7eed\u8ffd\u8e2a\u78f7\u9178\u76d0\u6c34\u5e73\u7684\u4f20\u611f\u5668\uff0c\u5bf9\u4e8e\u9884\u9632\u5bcc\u8425\u517b\u5316\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5149\u523b\u7684\u78f7\u9178\u76d0\u4f20\u611f\u5668\uff08P-sensor\uff09\u3002\u8be5\u4f20\u611f\u5668\u91c7\u75283D\u6253\u5370\u6280\u672f\u5236\u9020\uff0c\u5f62\u6210\u4e86\u5177\u67098\u5fae\u7c73\u7279\u5f81\u5c3a\u5bf8\u7684\u5468\u671f\u6027\u805a\u5408\u7269\u56fe\u6848\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u6d82\u8986\u4e86\u78f7\u9178\u76d0\u79bb\u5b50\u9009\u62e9\u6027\u819c\uff0c\u5f62\u6210\u56fa\u6001\u6307\u793a\u7535\u6781\u3002\u8be5\u4f20\u611f\u5668\u80fd\u591f\u68c0\u6d4b\u4f4e\u81f31 ppb\u7684\u78f7\u9178\u76d0\uff0c\u5e76\u4e14\u57280-475 ppm\u7684\u6d53\u5ea6\u8303\u56f4\u5185\u5177\u6709\u5feb\u901f\u54cd\u5e94\uff08\u4f4e\u4e8e30\u79d2\uff09\u3002\u4e3a\u4e86\u63d0\u9ad8\u6d4b\u91cf\u7cbe\u5ea6\uff0c\u7814\u7a76\u4e2d\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u78f7\u9178\u76d0\u6c34\u5e73\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u6307\u6807\uff08\u5747\u65b9\u8bef\u5dee\u4f4e\u4e8e1e-3\uff0c\u96f6\u6807\u51c6\u5dee\uff0c\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u4e3a0.997\uff09\u3002\u6700\u540e\uff0c\u7814\u7a76\u4eba\u5458\u5728\u5b9e\u9645\u7684\u6cb3\u6c34\u6837\u672c\u4e2d\u9a8c\u8bc1\u4e86\u4f20\u611f\u5668\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0e\u5546\u4e1a\u8bbe\u5907\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u65e0\u9700\u5149\u523b\u7684\u78f7\u9178\u76d0\u4f20\u611f\u5668\uff08P-sensor\uff09\u3002\u8be5\u4f20\u611f\u5668\u80fd\u591f\u4ee5\u5341\u4ebf\u5206\u4e4b\u51e0\uff08ppb\uff09\u7684\u6c34\u5e73\u68c0\u6d4b\u6cb3\u6c34\u4e2d\u7684\u78f7\u9178\u76d0\uff0c\u68c0\u6d4b\u9650\u4f4e\u81f31 ppb\uff0c\u54cd\u5e94\u65f6\u95f4\u5c0f\u4e8e30\u79d2\u3002\u5728\u5f17\u5409\u5c3c\u4e9a\u5dde\u62c9\u5e15\u6c49\u8bfa\u514b\u6cb3\u7684\u5b9e\u9645\u6c34\u6837\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u4f20\u611f\u5668\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u901a\u8fc7\u8bad\u7ec3\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u78f7\u9178\u76d0\u6c34\u5e73\uff0c\u53d6\u5f97\u4e86\u975e\u5e38\u9ad8\u7684\u51c6\u786e\u6027\uff08\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u4e3a0.997\uff09\u3002\u4e0e\u5546\u4e1a\u78f7\u9178\u76d0\u6d4b\u91cf\u4eea\u7684\u6bd4\u8f83\u7ed3\u679c\u4e5f\u8868\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9700\u5149\u523b\u7684\u78f7\u9178\u76d0\u4f20\u611f\u5668\uff08P-sensor\uff09\uff0c\u80fd\u591f\u4ee5\u5341\u4ebf\u5206\u4e4b\u51e0\uff08ppb\uff09\u7684\u6c34\u5e73\u68c0\u6d4b\u6cb3\u6c34\u4e2d\u7684\u78f7\u9178\u76d0\u3002\u8be5\u4f20\u611f\u5668\u4f7f\u75283D\u6253\u5370\u7684\u805a\u5408\u7269\u5468\u671f\u6027\u56fe\u6848\uff088\u5fae\u7c73\u7279\u5f81\u5c3a\u5bf8\uff09\u5f62\u6210\u7684\u56fa\u6001\u6307\u793a\u7535\u6781\uff0c\u5e76\u6d82\u8986\u6709\u78f7\u9178\u76d0\u79bb\u5b50\u9009\u62e9\u6027\u819c\u3002P-sensor\u57280-475 ppm\u7684\u6d53\u5ea6\u8303\u56f4\u5185\uff0c\u68c0\u6d4b\u4f4e\u81f31 ppb\u7684\u78f7\u9178\u76d0\uff0c\u54cd\u5e94\u65f6\u95f4\u4e0d\u523030\u79d2\u3002\u7814\u7a76\u4eba\u5458\u5728\u5f17\u5409\u5c3c\u4e9a\u5dde\u62c9\u5e15\u6c49\u8bfa\u514b\u6cb3\u7684\u6c34\u6837\u4e2d\u5bf9\u8be5\u4f20\u611f\u5668\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc4\u4f30\u4e86\u6c61\u6c34\u5904\u7406\u5382\u4e0a\u6e38\u548c\u4e0b\u6e38\u7684\u6c34\u6837\uff0c\u5e76\u4e0e\u5546\u4e1a\u78f7\u9178\u76d0\u6d4b\u91cf\u4eea\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u901a\u8fc7\u8bad\u7ec3\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u78f7\u9178\u76d0\u6c34\u5e73\uff0c\u53d6\u5f97\u4e86\u4f4e\u4e8e1e-3\u7684\u5747\u65b9\u8bef\u5dee\u3001\u96f6\u6807\u51c6\u5dee\u4ee5\u53ca0.997\u7684\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u4f20\u611f\u5668\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u8fde\u7eed\u6c34\u8d28\u76d1\u6d4b\u5de5\u5177\uff0c\u53ef\u4e3a\u5229\u76ca\u76f8\u5173\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4fe1\u606f\uff0c\u6700\u7ec8\u6539\u5584\u516c\u4f17\u5065\u5eb7\u3002"}}
{"id": "2507.14914", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14914", "abs": "https://arxiv.org/abs/2507.14914", "authors": ["Zhexuan Xu", "Jie Wang", "Siyuan Xu", "Zijie Geng", "Mingxuan Yuan", "Feng Wu"], "title": "One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner", "comment": null, "summary": "Floorplanning determines the shapes and locations of modules on a chip canvas\nand plays a critical role in optimizing the chip's Power, Performance, and Area\n(PPA) metrics. However, existing floorplanning approaches often fail to\nintegrate with subsequent physical design stages, leading to suboptimal\nin-module component placement and excessive inter-module feedthrough. To tackle\nthis challenge, we propose Flora, a three-stage feedthrough and placement aware\nrectilinear floorplanner. In the first stage, Flora employs wiremask and\nposition mask techniques to achieve coarse-grained optimization of HPWL and\nfeedthrough. In the second stage, under the constraint of a fixed outline,\nFlora achieves a zero-whitespace layout by locally resizing module shapes,\nthereby performing fine-grained optimization of feedthrough and improving\ncomponent placement. In the third stage, Flora utilizes a fast tree\nsearch-based method to efficiently place components-including macros and\nstandard cells-within each module, subsequently adjusting module boundaries\nbased on the placement results to enable cross-stage optimization. Experimental\nresults show that Flora outperforms recent state-of-the-art floorplanning\napproaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,\n29.15% in FTmod, and a 14% improvement in component placement performance.", "AI": {"tldr": "Flora \u662f\u4e00\u79cd\u65b0\u7684\u4e09\u9636\u6bb5\u5730\u677f\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u7ebf\u63a9\u7801\u3001\u4f4d\u7f6e\u63a9\u7801\u3001\u6a21\u5757\u8c03\u6574\u548c\u7ec4\u4ef6\u653e\u7f6e\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5404\u9879\u6027\u80fd\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u5730\u677f\u89c4\u5212\u65b9\u6cd5\u96be\u4ee5\u4e0e\u540e\u7eed\u7269\u7406\u8bbe\u8ba1\u9636\u6bb5\u96c6\u6210\uff0c\u5bfc\u81f4\u6a21\u5757\u5185\u7ec4\u4ef6\u653e\u7f6e\u4e0d\u4f73\u548c\u8fc7\u591a\u7684\u8de8\u7ebf\u3002", "method": "Flora \u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1. \u4f7f\u7528\u7ebf\u63a9\u7801\u548c\u4f4d\u7f6e\u63a9\u7801\u8fdb\u884c\u7c97\u7c92\u5ea6\u4f18\u5316\uff08HPWL \u548c\u8fc7\u7ebf\uff09\uff1b2. \u5728\u56fa\u5b9a\u8f6e\u5ed3\u4e0b\uff0c\u901a\u8fc7\u5c40\u90e8\u8c03\u6574\u6a21\u5757\u5f62\u72b6\u6765\u5b9e\u73b0\u96f6\u7a7a\u767d\u5e03\u5c40\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4f18\u5316\uff08\u8fc7\u7ebf\u548c\u7ec4\u4ef6\u653e\u7f6e\uff09\uff1b3. \u5229\u7528\u57fa\u4e8e\u5feb\u901f\u6811\u641c\u7d22\u7684\u65b9\u6cd5\u5728\u6a21\u5757\u5185\u653e\u7f6e\u7ec4\u4ef6\uff0c\u5e76\u6839\u636e\u653e\u7f6e\u7ed3\u679c\u8c03\u6574\u6a21\u5757\u8fb9\u754c\u4ee5\u5b9e\u73b0\u8de8\u9636\u6bb5\u4f18\u5316\u3002", "result": "Flora \u5728 HPWL\u3001FTpin\u3001FTmod \u548c\u7ec4\u4ef6\u653e\u7f6e\u6027\u80fd\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u5730\u677f\u89c4\u5212\u65b9\u6cd5\uff0c\u5e73\u5747\u5206\u522b\u964d\u4f4e\u4e86 6%\u30015.16%\u300129.15%\uff0c\u5e76\u63d0\u9ad8\u4e86 14%\u3002", "conclusion": "Flora \u5728 HPWL\u3001FTpin\u3001FTmod \u548c\u7ec4\u4ef6\u653e\u7f6e\u6027\u80fd\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u5730\u677f\u89c4\u5212\u65b9\u6cd5\uff0c\u5e73\u5747\u5206\u522b\u964d\u4f4e\u4e86 6%\u30015.16%\u300129.15%\uff0c\u5e76\u63d0\u9ad8\u4e86 14%\u3002"}}
{"id": "2507.14477", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14477", "abs": "https://arxiv.org/abs/2507.14477", "authors": ["Zhenyu Li", "Tianyi Shang", "Pengjie Xu", "Ruirui Zhang", "Fanchen Kong"], "title": "OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition", "comment": "5 figures", "summary": "Visual Place Recognition (VPR) in dynamic and perceptually aliased\nenvironments remains a fundamental challenge for long-term localization.\nExisting deep learning-based solutions predominantly focus on single-frame\nembeddings, neglecting the temporal coherence present in image sequences. This\npaper presents OptiCorNet, a novel sequence modeling framework that unifies\nspatial feature extraction and temporal differencing into a differentiable,\nend-to-end trainable module. Central to our approach is a lightweight 1D\nconvolutional encoder combined with a learnable differential temporal operator,\ntermed Differentiable Sequence Delta (DSD), which jointly captures short-term\nspatial context and long-range temporal transitions. The DSD module models\ndirectional differences across sequences via a fixed-weight differencing\nkernel, followed by an LSTM-based refinement and optional residual projection,\nyielding compact, discriminative descriptors robust to viewpoint and appearance\nshifts. To further enhance inter-class separability, we incorporate a\nquadruplet loss that optimizes both positive alignment and multi-negative\ndivergence within each batch. Unlike prior VPR methods that treat temporal\naggregation as post-processing, OptiCorNet learns sequence-level embeddings\ndirectly, enabling more effective end-to-end place recognition. Comprehensive\nevaluations on multiple public benchmarks demonstrate that our approach\noutperforms state-of-the-art baselines under challenging seasonal and viewpoint\nvariations.", "AI": {"tldr": "OptiCorNet\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u5e8f\u5217\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u548c\u65f6\u95f4\u5dee\u5206\uff08DSD\u6a21\u5757\uff09\u6765\u6539\u8fdb\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u3002\u5b83\u4f7f\u75281D\u5377\u79ef\u548cLSTM\u6765\u751f\u6210\u9c81\u68d2\u7684\u63cf\u8ff0\u7b26\uff0c\u5e76\u901a\u8fc7\u56db\u5143\u7ec4\u635f\u5931\u8fdb\u884c\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u5b63\u8282\u548c\u89c6\u89d2\u53d8\u5316\u7b49\u6311\u6218\u6027\u573a\u666f\u65f6\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u89e3\u51b3\u65b9\u6848\u4e3b\u8981\u5173\u6ce8\u5355\u5e27\u5d4c\u5165\uff0c\u5ffd\u7565\u4e86\u56fe\u50cf\u5e8f\u5217\u4e2d\u5b58\u5728\u7684\u65f6\u95f4\u76f8\u5e72\u6027\uff0c\u800c\u8fd9\u5728\u52a8\u6001\u548c\u611f\u77e5\u6df7\u6dc6\u7684\u73af\u5883\u4e2d\u957f\u671f\u5b9a\u4f4d\u4ecd\u7136\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002", "method": "OptiCorNet\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5e8f\u5217\u5efa\u6a21\u6846\u67b6\uff0c\u5b83\u5c06\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u548c\u65f6\u95f4\u5dee\u5206\u7edf\u4e00\u5230\u4e00\u4e2a\u53ef\u5fae\u5206\u3001\u53ef\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u6a21\u5757\u4e2d\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u76841D\u5377\u79ef\u7f16\u7801\u5668\uff0c\u7ed3\u5408\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u5fae\u5206\u65f6\u95f4\u7b97\u5b50\uff08DSD\uff09\uff0c\u5171\u540c\u6355\u83b7\u77ed\u671f\u7a7a\u95f4\u4e0a\u4e0b\u6587\u548c\u957f\u671f\u65f6\u95f4\u8f6c\u6362\u3002DSD\u6a21\u5757\u901a\u8fc7\u4e00\u4e2a\u56fa\u5b9a\u7684\u5dee\u5206\u6838\u5bf9\u5e8f\u5217\u4e2d\u7684\u65b9\u5411\u5dee\u5f02\u8fdb\u884c\u5efa\u6a21\uff0c\u7136\u540e\u8fdb\u884c\u57fa\u4e8eLSTM\u7684\u7ec6\u5316\u548c\u53ef\u9009\u7684\u6b8b\u5dee\u6295\u5f71\uff0c\u4ea7\u751f\u7d27\u51d1\u3001\u5177\u6709\u533a\u5206\u6027\u7684\u63cf\u8ff0\u7b26\uff0c\u8fd9\u4e9b\u63cf\u8ff0\u7b26\u5bf9\u89c6\u89d2\u548c\u5916\u89c2\u7684\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u91c7\u7528\u56db\u5143\u7ec4\u635f\u5931\u6765\u4f18\u5316\u6279\u6b21\u5185\u7684\u6b63\u5bf9\u9f50\u548c\u591a\u8d1f\u53d1\u6563\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7c7b\u95f4\u53ef\u5206\u79bb\u6027\u3002", "result": "\u4e0e\u5148\u524d\u5c06\u65f6\u95f4\u805a\u5408\u89c6\u4e3a\u540e\u5904\u7406\u7684\u65b9\u6cd5\u4e0d\u540c\uff0cOptiCorNet\u76f4\u63a5\u5b66\u4e60\u5e8f\u5217\u7ea7\u5d4c\u5165\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u7aef\u5230\u7aef\u5730\u70b9\u8bc6\u522b\u3002", "conclusion": "OptiCorNet\u901a\u8fc7\u5b66\u4e60\u5e8f\u5217\u7ea7\u5d4c\u5165\u76f4\u63a5\u8fdb\u884c\u7aef\u5230\u7aef\u5730\u70b9\u8bc6\u522b\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5b63\u8282\u548c\u89c6\u89d2\u53d8\u5316\u7684\u591a\u9879\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14552", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14552", "abs": "https://arxiv.org/abs/2507.14552", "authors": ["Anna Sofia Lippolis", "Mohammad Javad Saeedizade", "Robin Keskis\u00e4rkk\u00e4", "Aldo Gangemi", "Eva Blomqvist", "Andrea Giovanni Nuzzolese"], "title": "Large Language Models Assisting Ontology Evaluation", "comment": null, "summary": "Ontology evaluation through functional requirements, such as testing via\ncompetency question (CQ) verification, is a well-established yet costly,\nlabour-intensive, and error-prone endeavour, even for ontology engineering\nexperts. In this work, we introduce OE-Assist, a novel framework designed to\nassist ontology evaluation through automated and semi-automated CQ\nverification. By presenting and leveraging a dataset of 1,393 CQs paired with\ncorresponding ontologies and ontology stories, our contributions present, to\nour knowledge, the first systematic investigation into large language model\n(LLM)-assisted ontology evaluation, and include: (i) evaluating the\neffectiveness of a LLM-based approach for automatically performing CQ\nverification against a manually created gold standard, and (ii) developing and\nassessing an LLM-powered framework to assist CQ verification with Prot\\'eg\\'e,\nby providing suggestions. We found that automated LLM-based evaluation with\no1-preview and o3-mini perform at a similar level to the average user's\nperformance.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86OE-Assist\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u81ea\u52a8\u5316\u548c\u534a\u81ea\u52a8\u5316\u672c\u4f53\u8bc4\u4f30\u4e2d\u7684\u80fd\u529b\u95ee\u9898\uff08CQ\uff09\u9a8c\u8bc1\uff0c\u65e8\u5728\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u9ad8\u6548\u7387\u3002\u901a\u8fc7\u4e00\u4e2a\u5305\u542b1,393\u4e2aCQ\u7684\u6570\u636e\u96c6\uff0c\u7814\u7a76\u4e86LLM\u5728CQ\u9a8c\u8bc1\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f85\u52a9\u6846\u67b6\u3002\u7ed3\u679c\u8868\u660e\uff0cLLM\u5728\u81ea\u52a8\u8bc4\u4f30\u65b9\u9762\u7684\u8868\u73b0\u4e0e\u666e\u901a\u7528\u6237\u76f8\u5f53\u3002", "motivation": "\u4f20\u7edf\u7684\u672c\u4f53\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982\u901a\u8fc7\u80fd\u529b\u95ee\u9898CQ\u9a8c\u8bc1\uff09\u6210\u672c\u9ad8\u6602\u3001\u8017\u65f6\u8017\u529b\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u5373\u4f7f\u5bf9\u672c\u4f53\u5de5\u7a0b\u4e13\u5bb6\u4e5f\u662f\u5982\u6b64\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u3001\u66f4\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u8f85\u52a9\u672c\u4f53\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u5e76\u5229\u7528\u4e00\u4e2a\u5305\u542b1,393\u4e2aCQ\u53ca\u5176\u5bf9\u5e94\u672c\u4f53\u548c\u672c\u4f53\u6545\u4e8b\u7684\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u672c\u4f53\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u3002\u8bc4\u4f30\u4e86LLM\u5728\u81ea\u52a8\u6267\u884cCQ\u9a8c\u8bc1\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u4f9b\u5efa\u8bae\u6765\u8f85\u52a9\u5728Prot\u00e9g\u00e9\u4e2d\u8fdb\u884cCQ\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528o1-preview\u548co3-mini\u7684LLM\u81ea\u52a8\u8bc4\u4f30\u5728\u6027\u80fd\u4e0a\u4e0e\u666e\u901a\u7528\u6237\u7684\u5e73\u5747\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "LLM\u5728\u672c\u4f53\u8bc4\u4f30\u65b9\u9762\uff0c\u7279\u522b\u662f\u901a\u8fc7\u80fd\u529b\u95ee\u9898\uff08CQ\uff09\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u8fbe\u5230\u4e0e\u666e\u901a\u7528\u6237\u76f8\u5f53\u7684\u6c34\u5e73\u3002"}}
{"id": "2507.15531", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.15531", "abs": "https://arxiv.org/abs/2507.15531", "authors": ["Mu-Kun Lee", "Javier A. V\u00e9lez", "Rub\u00e9n M. Otxoa", "Masahito Mochizuki"], "title": "Skyrmion Hall effect and shape deformation of current-driven bilayer skyrmions in synthetic antiferromagnets", "comment": "14 pages, 5 figures", "summary": "The commonly believed absence of skyrmion Hall effect for topologically\ntrivial magnetic skyrmions is reconsidered for bilayer skyrmions in synthetic\nantiferromagnets driven by spin-transfer and spin-orbit torques. Using a\ngeneral Lagrangian formalism, we show that Bloch-type bilayer skyrmions acquire\na finite Hall angle when driven by spin-orbit torque, while N\\'{e}el-type\nskyrmions do not, in agreement with micromagnetic simulations. Both types of\nskyrmions exhibit current-induced elliptical deformation with minor and major\naxes aligned longitudinally and transversely to their velocity, respectively. A\nlinear relation between velocity and longitudinal radius is derived with a\ncoefficient proportional to the strength of spin-orbit torque. These effects\nare critical for antiferromagnetic skyrmion-based applications such as skyrmion\nracetrack memory. The Lagrange equations also reproduce the linear Hall\nangle-helicity relation reported by Msiska et al., Phys. Rev. Appl. 17, 064015\n(2022). An intuitive explanation of the skyrmion Hall effect for arbitrary\nhelicity based on the antiferromagnetic exchange torque is also provided.", "AI": {"tldr": "This paper investigates bilayer skyrmions in synthetic antiferromagnets and finds that Bloch-type skyrmions exhibit a Hall effect under spin-orbit torque, unlike N\representation{e}el-type skyrmions. It also details current-induced deformations and provides theoretical explanations crucial for memory applications.", "motivation": "The motivation behind this research is to reconsider the commonly believed absence of the skyrmion Hall effect for topologically trivial magnetic skyrmions, specifically focusing on bilayer skyrmions in synthetic antiferromagnets. The study aims to understand the behavior of these skyrmions under different driving torques (spin-transfer and spin-orbit) and to provide insights relevant to applications in antiferromagnetic skyrmion-based technologies like racetrack memory.", "method": "This paper utilizes a general Lagrangian formalism to analyze the behavior of bilayer skyrmions in synthetic antiferromagnets under the influence of spin-transfer and spin-orbit torques. The study also incorporates micromagnetic simulations to validate theoretical predictions and derives relationships between physical quantities such as velocity and longitudinal radius. An intuitive explanation for the skyrmion Hall effect is provided based on antiferromagnetic exchange torque.", "result": "The paper demonstrates that Bloch-type bilayer skyrmions acquire a finite Hall angle when driven by spin-orbit torque, a phenomenon not observed in N\representation{e}el-type skyrmions, as confirmed by micromagnetic simulations. It also shows that both skyrmion types exhibit current-induced elliptical deformation, with a linear relationship between velocity and longitudinal radius that is proportional to the spin-orbit torque strength. The study reproduces a previously reported linear Hall angle-helicity relation and offers an explanation for the skyrmion Hall effect based on antiferromagnetic exchange torque.", "conclusion": " Bloch-type bilayer skyrmions in synthetic antiferromagnets driven by spin-orbit torque exhibit a finite skyrmion Hall effect, while N\representation{e}el-type skyrmions do not. Both types show current-induced elliptical deformation with a linear relation between velocity and longitudinal radius. The derived Lagrange equations explain the Hall angle-helicity relation and provide an intuitive understanding of the skyrmion Hall effect based on antiferromagnetic exchange torque. These findings are crucial for antiferromagnetic skyrmion-based applications like racetrack memory."}}
{"id": "2507.14217", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.14217", "abs": "https://arxiv.org/abs/2507.14217", "authors": ["Tudor Matei Opran", "Samir Loudni"], "title": "Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation", "comment": null, "summary": "We address the pattern explosion problem in pattern mining by proposing an\ninteractive learning framework that combines nonlinear utility aggregation with\ngeometry-aware query selection. Our method models user preferences through a\nChoquet integral over multiple interestingness measures and exploits the\ngeometric structure of the version space to guide the selection of informative\ncomparisons. A branch-and-bound strategy with tight distance bounds enables\nefficient identification of queries near the decision boundary. Experiments on\nUCI datasets show that our approach outperforms existing methods such as\nChoquetRank, achieving better ranking accuracy with fewer user interactions.", "AI": {"tldr": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\u548c\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\uff0c\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u6392\u5e8f\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u975e\u7ebf\u6027\u6548\u7528\u805a\u5408\u548c\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\u7684\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u591a\u4e2a\u6709\u8da3\u6027\u5ea6\u91cf\u7684Choquet\u79ef\u5206\u6765\u6a21\u62df\u7528\u6237\u504f\u597d\uff0c\u5e76\u5229\u7528\u7248\u672c\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u6307\u5bfc\u4fe1\u606f\u6027\u6bd4\u8f83\u7684\u9009\u62e9\u3002\u4e00\u4e2a\u5e26\u6709\u7d27\u5bc6\u8ddd\u79bb\u754c\u9650\u7684\u5206\u679d\u5b9a\u754c\u7b56\u7565\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u7684\u67e5\u8be2\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u975e\u7ebf\u6027\u6548\u7528\u805a\u5408\u4e0e\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\uff0c\u5e76\u5229\u7528\u5e26\u6709\u7d27\u5bc6\u8ddd\u79bb\u754c\u9650\u7684\u5206\u679d\u5b9a\u754c\u7b56\u7565\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8bc6\u522b\u6a21\u5f0f\uff0c\u5e76\u5728\u7528\u6237\u4ea4\u4e92\u6b21\u6570\u66f4\u5c11\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6392\u5e8f\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728UCI\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eChoquetRank\u7b49\u65b9\u6cd5\uff0c\u5728\u66f4\u5c11\u7528\u6237\u4ea4\u4e92\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6392\u5e8f\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14654", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.14654", "abs": "https://arxiv.org/abs/2507.14654", "authors": ["Dingyanyan Zhou", "Yujin Ji", "Mir F. Mousavi", "Youyong Li"], "title": "Designing Two-Dimensional Octuple-Atomic-Layer M$_2$A$_2$Z$_4$ as Promising Photocatalysts for Overall Water Splitting", "comment": null, "summary": "Two-dimensional (2D) materials have emerged as promising candidates as\nphotocatalytic materials due to their large surface areas and tunable\nelectronic properties. In this work, we systematically design and screen a\nseries of octuple-atomic-layer M$_2$A$_2$Z$_4$ monolayers (M = Al, Ga, In; A =\nSi, Ge, Sn; Z = N, P, As) using first-principles calculations. 108 structures\nare constructed by intercalation approach, followed by a comprehensive\nevaluation of their thermodynamic and dynamic stability, band gaps, and band\nedge alignments to assess their potential for photocatalytic overall water\nsplitting. Among them, eight candidates meet the criteria for overall water\nsplitting under acidic condition (pH = 0), and Al$_2$Si$_2$N$_4$ and\nAl$_2$Ge$_2$N$_4$, further exhibit suitable band edge positions for\nphotocatalysis under both acidic and neutral environments (pH = 0 and 7).\nAl$_2$Si$_2$N$_4$ and Al$_2$Ge$_2$N$_4$ also show pronounced visible-light\nabsorption and structural stability in aqueous conditions. Importantly, the\nintroduction of N vacancies on the surfaces of Al$_2$Si$_2$N$_4$ and\nAl$_2$Ge$_2$N$_4$ significantly enhances their catalytic activity for both\nhydrogen reduction and water oxidation reactions, further supporting their\npotential as photocatalysts for overall water splitting. Our study provides\ntheoretical insights for the rational design of efficient and stable 2D\nphotocatalysts for overall water splitting.", "AI": {"tldr": "\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u7b5b\u9009\u51faAl2Si2N4\u548cAl2Ge2N4\u4e24\u79cd\u4e8c\u7ef4\u6750\u6599\uff0c\u5b83\u4eec\u5728\u9178\u6027\u548c\u4e2d\u6027\u6761\u4ef6\u4e0b\u5747\u9002\u7528\u4e8e\u5149\u50ac\u5316\u5168\u5206\u89e3\u6c34\uff0c\u5e76\u4e14\u5f15\u5165\u6c2e\u7a7a\u4f4d\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5176\u50ac\u5316\u6d3b\u6027\u3002", "motivation": "\u4e8c\u7ef4\u6750\u6599\u56e0\u5176\u5927\u8868\u9762\u79ef\u548c\u53ef\u8c03\u7684\u7535\u5b50\u6027\u8d28\uff0c\u5728\u5149\u50ac\u5316\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u8bbe\u8ba1\u548c\u7b5b\u9009\u7528\u4e8e\u5149\u50ac\u5316\u5168\u5206\u89e3\u6c34\u7684\u65b0\u578b\u4e8c\u7ef4\u6750\u6599\u3002", "method": "\u4f7f\u7528\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u7cfb\u7edf\u8bbe\u8ba1\u5e76\u7b5b\u9009\u4e86\u4e00\u7cfb\u5217\u516b\u91cd\u539f\u5b50\u5c42M2A2Z4\u5355\u5c42\uff08M = Al, Ga, In; A = Si, Ge, Sn; Z = N, P, As\uff09\u3002\u6784\u5efa\u4e86108\u4e2a\u7ed3\u6784\uff0c\u5e76\u5bf9\u5176\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\u7a33\u5b9a\u6027\u3001\u5e26\u9699\u4ee5\u53ca\u80fd\u5e26\u5bf9\u9f50\u60c5\u51b5\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u7b5b\u9009\u51fa8\u79cd\u6ee1\u8db3\u9178\u6027\u6761\u4ef6\u4e0b\uff08pH=0\uff09\u5168\u5206\u89e3\u6c34\u6807\u51c6\u7684\u5019\u9009\u6750\u6599\u3002\u5176\u4e2d\uff0cAl2Si2N4\u548cAl2Ge2N4\u5728\u9178\u6027\u548c\u4e2d\u6027\uff08pH=0\u548c7\uff09\u73af\u5883\u4e0b\u90fd\u5177\u6709\u5408\u9002\u7684\u5149\u50ac\u5316\u80fd\u5e26\u8fb9\u7f18\u4f4d\u7f6e\uff0c\u5e76\u4e14\u8868\u73b0\u51fa\u663e\u8457\u7684\u53ef\u89c1\u5149\u5438\u6536\u548c\u6c34\u6027\u73af\u5883\u4e0b\u7684\u7ed3\u6784\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u5f15\u5165\u6c2e\u7a7a\u4f4d\uff0cAl2Si2N4\u548cAl2Ge2N4\u7684\u50ac\u5316\u6d3b\u6027\u5f97\u5230\u663e\u8457\u589e\u5f3a\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u5149\u50ac\u5316\u5242\u7684\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u7a33\u5b9a\u7684\u4e8c\u7ef4\u5149\u50ac\u5316\u5242\u7528\u4e8e\u5168\u5206\u89e3\u6c34\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2507.14952", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.14952", "abs": "https://arxiv.org/abs/2507.14952", "authors": ["Mahyar Mahinzaeim", "Kamyar Mehran"], "title": "An approach to the LQG/LTR design problem with specifications for finite-dimensional SISO control systems", "comment": null, "summary": "This is an expository paper which discusses an approach to the LQG/LTR design\nproblem for finite-dimensional SISO control systems. The approach is based on\nthe utilisation of weighting augmentation for incorporating design\nspecifications into the framework of the LTR technique for LQG compensator\ndesign. The LQG compensator is to simultaneously meet given analytical low- and\nhigh-frequency design specifications expressed in terms of desirable\nsensitivity and controller noise sensitivity functions. The paper is aimed at\nnonspecialists and, in particular, practitioners in finite-dimensional LQG\ntheory interested in the design of feedback compensators for closed-loop\nperformance and robustness shaping of SISO control systems in realistic\nsituations. The proposed approach is illustrated by a detailed numerical\nexample: the torque control of a current-controlled DC motor with an\nelastically mounted rotor.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e SISO \u63a7\u5236\u7cfb\u7edf\u7684 LQG/LTR \u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a0\u6743\u589e\u5f3a\u6765\u6ee1\u8db3\u4f4e\u9891\u548c\u9ad8\u9891\u8bbe\u8ba1\u89c4\u8303\uff0c\u5e76\u4ee5\u76f4\u6d41\u7535\u673a\u8f6c\u77e9\u63a7\u5236\u4e3a\u4f8b\u8fdb\u884c\u8bf4\u660e\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u4e3a\u975e\u4e13\u4e1a\u4eba\u58eb\uff0c\u7279\u522b\u662f\u6709\u9650\u7ef4 LQG \u7406\u8bba\u7684\u4ece\u4e1a\u8005\uff0c\u4ecb\u7ecd\u4e00\u79cd\u7528\u4e8e\u5b9e\u9645\u60c5\u51b5\u4e2d SISO \u63a7\u5236\u7cfb\u7edf\u7684\u95ed\u73af\u6027\u80fd\u548c\u9c81\u68d2\u6027\u6574\u5f62\u53cd\u9988\u8865\u507f\u5668\u8bbe\u8ba1\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u8ba8\u8bba\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u589e\u5f3a\u7684 LQG/LTR \u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u6709\u9650\u7ef4 SISO \u63a7\u5236\u7cfb\u7edf\u3002", "result": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a0\u6743\u589e\u5f3a\u5c06\u8bbe\u8ba1\u89c4\u8303\u7eb3\u5165 LQG \u8865\u507f\u5668\u8bbe\u8ba1\u7684 LTR \u6280\u672f\u6846\u67b6\uff0c\u4ee5\u6ee1\u8db3\u6240\u9700\u7684\u7075\u654f\u5ea6\u548c\u63a7\u5236\u5668\u566a\u58f0\u7075\u654f\u5ea6\u51fd\u6570\u7684\u4f4e\u9891\u548c\u9ad8\u9891\u8bbe\u8ba1\u89c4\u8303\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a0\u6743\u589e\u5f3a\u5c06\u8bbe\u8ba1\u89c4\u8303\u7eb3\u5165 LQG \u8865\u507f\u5668\u8bbe\u8ba1\u7684 LTR \u6280\u672f\u6846\u67b6\uff0c\u4ee5\u6ee1\u8db3\u6240\u9700\u7684\u7075\u654f\u5ea6\u548c\u63a7\u5236\u5668\u566a\u58f0\u7075\u654f\u5ea6\u51fd\u6570\u7684\u4f4e\u9891\u548c\u9ad8\u9891\u8bbe\u8ba1\u89c4\u8303\u3002"}}
{"id": "2507.14563", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14563", "abs": "https://arxiv.org/abs/2507.14563", "authors": ["Jonathan Kenny", "Feifei Zhou", "Ruihua He", "Fedor Jelezko", "Teck Seng Koh", "Weibo Gao"], "title": "Quantum Sensing Enhancement through a Nuclear Spin Register in Nitrogen-Vacancy Centers in Diamond", "comment": "35 pages, 16 figures, Accepted to Applied Physics Review", "summary": "Quantum sensing has seen rapid progress from laboratory research to\nreal-world applications. Solid-state spin systems, particularly\nnitrogen-vacancy (NV) centers in diamond, are attractive for their ability to\noperate at room temperature with high sensitivity. However, electron spin\ncoherence due to noise from the surrounding spin bath and this environment\neffect limits the sensitivity of NV centers. Thus, a critical task in NV\ncenter-based quantum sensing is sensitivity enhancement through coherence\nprotection. Nuclear spin assisted protocols have demonstrated greater\nenhancement of electron spin coherence due to the naturally occurring electron\nand nuclear spin pair. The longer nuclear coherence times allow for long-lived\nmemory bit for quantum information protocols. This review discusses the physics\nof NV centers, the mechanisms and variations of nuclear spin-assisted\nprotocols, and their applications in nuclear spin spectroscopy, atomic imaging,\nand magnetic sensing. Challenges in sensitivity enhancement, commercialization\nprospects, and future research directions are also explored.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u91d1\u521a\u77f3NV\u8272\u5fc3\u91cf\u5b50\u4f20\u611f\u6280\u672f\uff0c\u7279\u522b\u662f\u6838\u81ea\u65cb\u8f85\u52a9\u534f\u8bae\u5728\u63d0\u9ad8\u76f8\u5e72\u6027\u548c\u7075\u654f\u5ea6\u65b9\u9762\u7684\u5e94\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u91cf\u5b50\u4f20\u611f\u6280\u672f\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46NV\u8272\u5fc3\u7b49\u56fa\u6001\u81ea\u65cb\u7cfb\u7edf\u6613\u53d7\u73af\u5883\u566a\u58f0\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u5176\u7075\u654f\u5ea6\u3002\u56e0\u6b64\uff0c\u63d0\u9ad8NV\u8272\u5fc3\u7684\u76f8\u5e72\u6027\u548c\u7075\u654f\u5ea6\u662f\u5173\u952e\u4efb\u52a1\u3002", "method": "\u672c\u6587\u7efc\u8ff0\u4e86NV\u8272\u5fc3\u5728\u91d1\u521a\u77f3\u4e2d\u7684\u91cf\u5b50\u4f20\u611f\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u6838\u81ea\u65cb\u8f85\u52a9\u534f\u8bae\u5728\u4fdd\u62a4\u7535\u5b50\u81ea\u65cb\u76f8\u5e72\u6027\u65b9\u9762\u7684\u4f5c\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5728\u91cf\u5b50\u4fe1\u606f\u534f\u8bae\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u6838\u81ea\u65cb\u8f85\u52a9\u534f\u8bae\u901a\u8fc7\u5229\u7528\u5929\u7136\u5b58\u5728\u7684\u7535\u5b50-\u6838\u81ea\u65cb\u5bf9\u548c\u6838\u81ea\u65cb\u66f4\u957f\u7684\u76f8\u5e72\u65f6\u95f4\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3aNV\u8272\u5fc3\u7684\u7535\u5b50\u81ea\u65cb\u76f8\u5e72\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u4f20\u611f\u7075\u654f\u5ea6\u3002", "conclusion": "NV\u4e2d\u5fc3\u548c\u6838\u81ea\u65cb\u8f85\u52a9\u534f\u8bae\u5728\u91cf\u5b50\u4f20\u611f\u3001\u6838\u81ea\u65cb\u8c31\u3001\u539f\u5b50\u6210\u50cf\u548c\u78c1\u4f20\u611f\u65b9\u9762\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\uff0c\u4f46\u4ecd\u9762\u4e34\u7075\u654f\u5ea6\u63d0\u5347\u548c\u5546\u4e1a\u5316\u7b49\u6311\u6218\u3002"}}
{"id": "2507.14355", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14355", "abs": "https://arxiv.org/abs/2507.14355", "authors": ["Jianfeng Zhu", "Ruoming Jin", "Karin G. Coifman"], "title": "Can LLMs Infer Personality from Real World Conversations?", "comment": "21 pages, 12 figures", "summary": "Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a\npromising approach for scalable personality assessment from open-ended\nlanguage. However, inferring personality traits remains challenging, and\nearlier work often relied on synthetic data or social media text lacking\npsychometric validity. We introduce a real-world benchmark of 555\nsemi-structured interviews with BFI-10 self-report scores for evaluating\nLLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini,\nMeta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item\nprediction and both zero-shot and chain-of-thought prompting for Big Five trait\ninference. All models showed high test-retest reliability, but construct\nvalidity was limited: correlations with ground-truth scores were weak (max\nPearson's $r = 0.27$), interrater agreement was low (Cohen's $\\kappa < 0.10$),\nand predictions were biased toward moderate or high trait levels.\nChain-of-thought prompting and longer input context modestly improved\ndistributional alignment, but not trait-level accuracy. These results\nunderscore limitations in current LLM-based personality inference and highlight\nthe need for evidence-based development for psychological applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15616", "categories": ["cs.DS", "cond-mat.dis-nn", "cs.DM", "math-ph", "math.MP", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.15616", "abs": "https://arxiv.org/abs/2507.15616", "authors": ["Ferenc Bencs", "Kuikui Liu", "Guus Regts"], "title": "On zeros and algorithms for disordered systems: mean-field spin glasses", "comment": null, "summary": "Spin glasses are fundamental probability distributions at the core of\nstatistical physics, the theory of average-case computational complexity, and\nmodern high-dimensional statistical inference. In the mean-field setting, we\ndesign deterministic quasipolynomial-time algorithms for estimating the\npartition function to arbitrarily high accuracy for nearly all inverse\ntemperatures in the second moment regime. In particular, for the\nSherrington--Kirkpatrick model, our algorithms succeed for almost the entire\nreplica-symmetric phase. To achieve this, we study the locations of the zeros\nof the partition function. Notably, our methods are conceptually simple, and\napply equally well to the spherical case and the case of Ising spins.", "AI": {"tldr": "\u4e3a\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u5728\u5747\u503c\u573a\u8bbe\u5b9a\u4e0b\uff0c\u901a\u8fc7\u7814\u7a76\u914d\u5206\u51fd\u6570\u7684\u96f6\u70b9\u4f4d\u7f6e\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u51e0\u4e4e\u6240\u6709\u9006\u6e29\u5ea6\u4e0b\u7684\u7b2c\u4e8c\u4e2a\u77e9\u8303\u56f4\u5185\u90fd\u80fd\u4ee5\u4efb\u610f\u9ad8\u7684\u7cbe\u5ea6\u4f30\u8ba1\u914d\u5206\u51fd\u6570\u3002", "motivation": "\u81ea\u65cb\u73bb\u7483\u662f\u7edf\u8ba1\u7269\u7406\u5b66\u3001\u5e73\u5747\u60c5\u51b5\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u548c\u73b0\u4ee3\u9ad8\u7ef4\u7edf\u8ba1\u63a8\u65ad\u7684\u6838\u5fc3\u6982\u7387\u5206\u5e03\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u914d\u5206\u51fd\u6570\u7684\u96f6\u70b9\u4f4d\u7f6e\u6765\u8bbe\u8ba1\u786e\u5b9a\u6027\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "result": "\u5728\u5747\u503c\u573a\u8bbe\u5b9a\u4e0b\uff0c\u4e3a\u51e0\u4e4e\u6240\u6709\u9006\u6e29\u5ea6\u4e0b\u7684\u7b2c\u4e8c\u4e2a\u77e9\u8303\u56f4\u5185\uff0c\u4ee5\u4efb\u610f\u9ad8\u7684\u7cbe\u5ea6\u4f30\u8ba1\u914d\u5206\u51fd\u6570\u63d0\u4f9b\u4e86\u786e\u5b9a\u6027\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002\u7279\u522b\u662f\u5bf9\u4e8e Sherrington-Kirkpatrick \u6a21\u578b\uff0c\u8be5\u7b97\u6cd5\u5728\u51e0\u4e4e\u6574\u4e2a\u526f\u672c\u5bf9\u79f0\u76f8\u4e2d\u90fd\u53d6\u5f97\u4e86\u6210\u529f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u5728\u63a5\u8fd1\u6240\u6709\u9006\u6e29\u5ea6\u4e0b\u7684\u5e73\u5747\u60c5\u51b5\u590d\u6742\u6027\u7406\u8bba\u548c\u9ad8\u7ef4\u7edf\u8ba1\u63a8\u65ad\u4e2d\u63d0\u4f9b\u4e86\u786e\u5b9a\u6027\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002"}}
{"id": "2507.14153", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14153", "abs": "https://arxiv.org/abs/2507.14153", "authors": ["Daniel Cie\u015blak", "Barbara Szyca", "Weronika Bajko", "Liwia Florkiewicz", "Kinga Grz\u0119da", "Mariusz Kaczmarek", "Helena Kamieniecka", "Hubert Lis", "Weronika Matwiejuk", "Anna Prus", "Michalina Razik", "Inga Rozumowicz", "Wiktoria Ziembakowska"], "title": "Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM", "comment": "International Conference on Hybrid Artificial Intelligence Systems\n  (HAIS 2024)", "summary": "Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to\nits progressive nature and complex symptoms. This study introduces a novel\napproach utilizing surface electromyography (sEMG) to objectively assess PD\nseverity, focusing on the biceps brachii muscle. Initial analysis of sEMG data\nfrom five PD patients and five healthy controls revealed significant\nneuromuscular differences. A traditional Support Vector Machine (SVM) model\nachieved up to 83% accuracy, while enhancements with a Graph Convolutional\nNetwork-Support Vector Machine (GCN-SVM) model increased accuracy to 92%.\nDespite the preliminary nature of these results, the study outlines a detailed\nexperimental methodology for future research with larger cohorts to validate\nthese findings and integrate the approach into clinical practice. The proposed\napproach holds promise for advancing PD severity assessment and improving\npatient care in Parkinson's disease management.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8esEMG\u548cGCN-SVM\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5ba2\u89c2\u8bc4\u4f30\u5e15\u91d1\u68ee\u75c5\u4e25\u91cd\u7a0b\u5ea6\uff0c\u51c6\u786e\u7387\u8fbe92%\uff0c\u6709\u6f5c\u529b\u5e94\u7528\u4e8e\u4e34\u5e8a\u3002", "motivation": "\u5e15\u91d1\u68ee\u75c5\uff08PD\uff09\u7684\u8bca\u65ad\u548c\u76d1\u6d4b\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5ba2\u89c2\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5176\u4e25\u91cd\u7a0b\u5ea6\u3002", "method": "\u5229\u7528\u8868\u9762\u808c\u7535\u56fe\uff08sEMG\uff09\u548c\u56fe\u5377\u79ef\u7f51\u7edc-\u652f\u6301\u5411\u91cf\u673a\uff08GCN-SVM\uff09\u6a21\u578b\u6765\u8bc4\u4f30\u5e15\u91d1\u68ee\u75c5\u7684\u4e25\u91cd\u7a0b\u5ea6\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u6a21\u578b\uff08\u51c6\u786e\u7387\u6700\u9ad883%\uff09\u76f8\u6bd4\uff0cGCN-SVM\u6a21\u578b\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u523092%\uff0c\u663e\u793a\u51fa\u5728\u8bc4\u4f30\u5e15\u91d1\u68ee\u75c5\u4e25\u91cd\u7a0b\u5ea6\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684sEMG\u7ed3\u5408GCN-SVM\u6a21\u578b\u5728\u8bc4\u4f30\u5e15\u91d1\u68ee\u75c5\u4e25\u91cd\u7a0b\u5ea6\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u6709\u671b\u6539\u8fdb\u5e15\u91d1\u68ee\u75c5\u7684\u8bca\u65ad\u548c\u6cbb\u7597\u3002"}}
{"id": "2507.14929", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14929", "abs": "https://arxiv.org/abs/2507.14929", "authors": ["Tero Kaarlela", "Sami Salo", "Jose Outeiro"], "title": "Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly", "comment": null, "summary": "Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a\nsustainable transition to electric vehicles by enabling a closed-loop supply\nchain. Currently, the manual disassembly process exposes workers to hazards,\nincluding electrocution and toxic chemicals. We propose a teleoperated system\nfor the safe disassembly and sorting of EVBs. A human-in-the-loop can create\nand save disassembly sequences for unknown EVB types, enabling future\nautomation. An RGB camera aligns the physical and digital twins of the EVB, and\nthe digital twin of the robot is based on the Robot Operating System (ROS)\nmiddleware. This hybrid approach combines teleoperation and automation to\nimprove safety, adaptability, and efficiency in EVB disassembly and sorting.\nThe economic contribution is realized by reducing labor dependency and\nincreasing throughput in battery recycling. An online pilot study was set up to\nevaluate the usability of the presented approach, and the results demonstrate\nthe potential as a user-friendly solution.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8fdc\u7a0b\u64cd\u4f5c\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b89\u5168\u62c6\u5378\u548c\u5206\u7c7b\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u7ed3\u5408\u8fdc\u7a0b\u64cd\u4f5c\u548c\u81ea\u52a8\u5316\u6765\u63d0\u9ad8\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u5e76\u5df2\u901a\u8fc7\u8bd5\u70b9\u7814\u7a76\u8bc1\u660e\u5176\u53ef\u7528\u6027\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u5411\u7535\u52a8\u6c7d\u8f66\u7684\u8fc7\u6e21\uff0c\u9700\u8981\u5bf9\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u8fdb\u884c\u62c6\u5378\u548c\u5206\u7c7b\uff0c\u4ee5\u5b9e\u73b0\u95ed\u73af\u4f9b\u5e94\u94fe\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u304c\u624by\u52a8\u62c6\u5378\u8fc7\u7a0b\u5b58\u5728\u5371\u9669\uff0c\u5305\u62ec\u7535\u51fb\u548c\u6709\u6bd2\u5316\u5b66\u7269\u8d28\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8fdc\u7a0b\u64cd\u4f5c\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u7684\u5b89\u5168\u62c6\u5378\u548c\u5206\u7c7b\u3002\u8be5\u7cfb\u7edf\u4f7f\u7528RGB\u6444\u50cf\u5934\u5bf9\u9f50EVB\u7684\u7269\u7406\u548c\u6570\u5b57\u5b6a\u751f\uff0c\u673a\u5668\u4eba\u6570\u5b57\u5b6a\u751f\u57fa\u4e8eROS\u4e2d\u95f4\u4ef6\u3002\u4eba\u7c7b\u64cd\u4f5c\u5458\u53ef\u4ee5\u521b\u5efa\u548c\u4fdd\u5b58\u672a\u77e5EVB\u7c7b\u578b\u7684\u62c6\u5378\u5e8f\u5217\uff0c\u4ee5\u5b9e\u73b0\u672a\u6765\u7684\u81ea\u52a8\u5316\u3002", "result": "\u5728\u7ebf\u8bd5\u70b9\u7814\u7a76\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u7528\u6027\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u4e00\u79cd\u7528\u6237\u53cb\u597d\u578b\u89e3\u51b3\u65b9\u6848\u5177\u6709\u6f5c\u529b\uff0c\u5e76\u80fd\u901a\u8fc7\u51cf\u5c11\u52b3\u52a8\u529b\u4f9d\u8d56\u548c\u63d0\u9ad8\u7535\u6c60\u56de\u6536\u80fd\u529b\u6765\u964d\u4f4e\u6210\u672c\u3002", "conclusion": "\u8be5\u6df7\u5408\u65b9\u6cd5\u7ed3\u5408\u4e86\u8fdc\u7a0b\u64cd\u4f5c\u548c\u81ea\u52a8\u5316\uff0c\u4ee5\u63d0\u9ad8\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u62c6\u5378\u548c\u5206\u7c7b\u7684\u5b89\u5168\u6027\u3001\u9002\u5e94\u6027\u548c\u6548\u7387\u3002\u5728\u7ebf\u8bd5\u70b9\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u4f5c\u4e3a\u7528\u6237\u53cb\u597d\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14481", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14481", "abs": "https://arxiv.org/abs/2507.14481", "authors": ["Yujia Tong", "Jingling Yuan", "Tian Zhang", "Jianquan Liu", "Chuang Hu"], "title": "DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning", "comment": null, "summary": "Data-Free Quantization (DFQ) enables the quantization of Vision Transformers\n(ViTs) without requiring access to data, allowing for the deployment of ViTs on\ndevices with limited resources. In DFQ, the quantization model must be\ncalibrated using synthetic samples, making the quality of these synthetic\nsamples crucial. Existing methods fail to fully capture and balance the global\nand local features within the samples, resulting in limited synthetic data\nquality. Moreover, we have found that during inference, there is a significant\ndifference in the distributions of intermediate layer activations between the\nquantized and full-precision models. These issues lead to a severe performance\ndegradation of the quantized model. To address these problems, we propose a\npipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).\nSpecifically, we synthesize samples in order of increasing difficulty,\neffectively enhancing the quality of synthetic data. During the calibration and\ninference stage, we introduce the activation correction matrix for the\nquantized model to align the intermediate layer activations with those of the\nfull-precision model. Extensive experiments demonstrate that DFQ-ViT achieves\nremarkable superiority over existing DFQ methods and its performance is on par\nwith models quantized through real data. For example, the performance of DeiT-T\nwith 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our\nmethod eliminates the need for fine-tuning, which not only reduces\ncomputational overhead but also lowers the deployment barriers for edge\ndevices. This characteristic aligns with the principles of Green Learning by\nimproving energy efficiency and facilitating real-world applications in\nresource-constrained environments.", "AI": {"tldr": "DFQ-ViT \u901a\u8fc7\u6539\u8fdb\u5408\u6210\u6837\u672c\u751f\u6210\u548c\u5f15\u5165\u6fc0\u6d3b\u503c\u6821\u6b63\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u65e0\u5173\u91cf\u5316\u89c6\u89c9Transformer\u7684\u6027\u80fd\u95ee\u9898\uff0c\u6548\u679c\u5ab2\u7f8e\u771f\u5b9e\u6570\u636e\u91cf\u5316\uff0c\u4e14\u65e0\u9700\u5fae\u8c03\uff0c\u66f4\u7eff\u8272\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u65e0\u5173\u91cf\u5316\uff08DFQ\uff09\u65b9\u6cd5\u5728\u4e3a\u89c6\u89c9Transformer\uff08ViT\uff09\u751f\u6210\u7528\u4e8e\u91cf\u5316\u7684\u5408\u6210\u6837\u672c\u65f6\uff0c\u672a\u80fd\u5145\u5206\u6355\u6349\u548c\u5e73\u8861\u6837\u672c\u4e2d\u7684\u5168\u5c40\u4e0e\u5c40\u90e8\u7279\u5f81\uff0c\u5bfc\u81f4\u5408\u6210\u6570\u636e\u8d28\u91cf\u4e0d\u9ad8\u3002\u6b64\u5916\uff0c\u91cf\u5316\u540e\u7684\u6a21\u578b\u5728\u63a8\u7406\u65f6\uff0c\u5176\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u503c\u7684\u5206\u5e03\u4e0e\u5168\u7cbe\u5ea6\u6a21\u578b\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u8fd9\u4e9b\u95ee\u9898\u5171\u540c\u5bfc\u81f4\u4e86\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7684\u4e25\u91cd\u4e0b\u964d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347DFQ\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "DFQ-ViT \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u65e0\u5173\u91cf\u5316\uff08DFQ\uff09\u6d41\u6c34\u7ebf\uff0c\u4e3b\u8981\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u90e8\u5206\uff1a1. \u5408\u6210\u6837\u672c\u751f\u6210\uff1a\u91c7\u7528\u9010\u6b65\u589e\u52a0\u96be\u5ea6\u7684\u65b9\u5f0f\u751f\u6210\u5408\u6210\u6837\u672c\uff0c\u4ee5\u63d0\u9ad8\u6837\u672c\u8d28\u91cf\uff0c\u66f4\u597d\u5730\u6355\u6349\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u30022. \u6fc0\u6d3b\u503c\u6821\u6b63\uff1a\u5728\u91cf\u5316\u6a21\u578b\u7684\u6821\u51c6\u548c\u63a8\u7406\u9636\u6bb5\uff0c\u5f15\u5165\u6fc0\u6d3b\u503c\u6821\u6b63\u77e9\u9635\uff0c\u7528\u4e8e\u7f29\u5c0f\u91cf\u5316\u6a21\u578b\u4e0e\u5168\u7cbe\u5ea6\u6a21\u578b\u4e4b\u95f4\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u503c\u5206\u5e03\u7684\u5dee\u8ddd\u3002", "result": "DFQ-ViT \u5728\u5404\u9879\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u76f8\u5bf9\u4e8e\u73b0\u6709 DFQ \u65b9\u6cd5\u7684\u663e\u8457\u4f18\u8d8a\u6027\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5728 DeiT-T \u6a21\u578b\u8fdb\u884c 3 \u4f4d\u6743\u91cd\u91cf\u5316\u65f6\uff0cDFQ-ViT \u7684\u6027\u80fd\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u9ad8\u51fa 4.29%\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5fae\u8c03\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u63d0\u4f9b\u4e86\u4fbf\u5229\uff0c\u63d0\u9ad8\u4e86\u80fd\u6e90\u6548\u7387\uff0c\u6709\u5229\u4e8e\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "DFQ-ViT \u514b\u670d\u4e86\u73b0\u6709\u6570\u636e\u65e0\u5173\u91cf\u5316\u65b9\u6cd5\u5728\u5904\u7406\u89c6\u89c9Transformer\uff08ViT\uff09\u65f6\u5408\u6210\u6837\u672c\u8d28\u91cf\u4e0d\u9ad8\u4ee5\u53ca\u91cf\u5316\u540e\u6a21\u578b\u4e0e\u5168\u7cbe\u5ea6\u6a21\u578b\u4e4b\u95f4\u6fc0\u6d3b\u503c\u5206\u5e03\u5dee\u5f02\u7684\u95ee\u9898\u3002\u901a\u8fc7\u9010\u6b65\u751f\u6210\u96be\u5ea6\u9012\u589e\u7684\u5408\u6210\u6837\u672c\u548c\u5f15\u5165\u6fc0\u6d3b\u503c\u6821\u6b63\u77e9\u9635\uff0cDFQ-ViT \u663e\u8457\u63d0\u9ad8\u4e86\u91cf\u5316\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u8fbe\u5230\u751a\u81f3\u4f18\u4e8e\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u91cf\u5316\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u65e0\u9700\u5fae\u8c03\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u548c\u90e8\u7f72\u95e8\u69db\uff0c\u7b26\u5408\u7eff\u8272\u5b66\u4e60\u7684\u7406\u5ff5\u3002"}}
{"id": "2507.14593", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14593", "abs": "https://arxiv.org/abs/2507.14593", "authors": ["Omar Al-Desi"], "title": "Coordinate Heart System: A Geometric Framework for Emotion Representation", "comment": "26 pages", "summary": "This paper presents the Coordinate Heart System (CHS), a geometric framework\nfor emotion representation in artificial intelligence applications. We position\neight core emotions as coordinates on a unit circle, enabling mathematical\ncomputation of complex emotional states through coordinate mixing and vector\noperations. Our initial five-emotion model revealed significant coverage gaps\nin the emotion space, leading to the development of an eight-emotion system\nthat provides complete geometric coverage with mathematical guarantees. The\nframework converts natural language input to emotion coordinates and supports\nreal-time emotion interpolation through computational algorithms. The system\nintroduces a re-calibrated stability parameter S in [0,1], which dynamically\nintegrates emotional load, conflict resolution, and contextual drain factors.\nThis stability model leverages advanced Large Language Model interpretation of\ntextual cues and incorporates hybrid temporal tracking mechanisms to provide\nnuanced assessment of psychological well-being states. Our key contributions\ninclude: (i) mathematical proof demonstrating why five emotions are\ninsufficient for complete geometric coverage, (ii) an eight-coordinate system\nthat eliminates representational blind spots, (iii) novel algorithms for\nemotion mixing, conflict resolution, and distance calculation in emotion space,\nand (iv) a comprehensive computational framework for AI emotion recognition\nwith enhanced multi-dimensional stability modeling. Experimental validation\nthrough case studies demonstrates the system's capability to handle emotionally\nconflicted states, contextual distress factors, and complex psychological\nscenarios that traditional categorical emotion models cannot adequately\nrepresent. This work establishes a new mathematical foundation for emotion\nmodeling in artificial intelligence systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5750\u6807\u5fc3\u810f\u7cfb\u7edf\uff08CHS\uff09\uff0c\u4e00\u4e2a\u5c06\u516b\u79cd\u6838\u5fc3\u60c5\u611f\u5b9a\u4f4d\u4e3a\u5355\u4f4d\u5706\u5750\u6807\u7684\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u4eba\u5de5\u667a\u80fd\u60c5\u611f\u8868\u793a\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5750\u6807\u6df7\u5408\u548c\u5411\u91cf\u8fd0\u7b97\u5904\u7406\u590d\u6742\u60c5\u611f\uff0c\u5e76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6df7\u5408\u65f6\u95f4\u8ddf\u8e2a\u673a\u5236\u8bc4\u4f30\u5fc3\u7406\u5065\u5eb7\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u7cfb\u7edf\u5728\u5904\u7406\u60c5\u611f\u51b2\u7a81\u548c\u590d\u6742\u5fc3\u7406\u60c5\u666f\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u4e2d\u4e3a\u60c5\u611f\u8868\u793a\u63d0\u4f9b\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\uff0c\u5e76\u89e3\u51b3\u4f20\u7edf\u60c5\u611f\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u60c5\u611f\u72b6\u6001\u548c\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5750\u6807\u5fc3\u810f\u7cfb\u7edf\uff08CHS\uff09\uff0c\u5c06\u516b\u79cd\u6838\u5fc3\u60c5\u611f\u5b9a\u4f4d\u4e3a\u5355\u4f4d\u5706\u4e0a\u7684\u5750\u6807\uff0c\u901a\u8fc7\u5750\u6807\u6df7\u5408\u548c\u5411\u91cf\u8fd0\u7b97\u5b9e\u73b0\u590d\u6742\u60c5\u611f\u72b6\u6001\u7684\u6570\u5b66\u8ba1\u7b97\u3002\u8be5\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u6587\u672c\u7ebf\u7d22\uff0c\u5e76\u7ed3\u5408\u6df7\u5408\u65f6\u95f4\u8ddf\u8e2a\u673a\u5236\u6765\u8bc4\u4f30\u5fc3\u7406\u5065\u5eb7\u72b6\u6001\u3002", "result": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u516b\u5750\u6807\u60c5\u611f\u7cfb\u7edf\uff0c\u6d88\u9664\u4e86\u8868\u793a\u76f2\u70b9\uff0c\u5e76\u63d0\u4f9b\u4e86\u60c5\u611f\u6df7\u5408\u3001\u51b2\u7a81\u89e3\u51b3\u548c\u60c5\u611f\u7a7a\u95f4\u8ddd\u79bb\u8ba1\u7b97\u7684\u65b0\u7b97\u6cd5\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u8868\u793a\u7684\u60c5\u611f\u51b2\u7a81\u72b6\u6001\u3001\u80cc\u666f\u56f0\u6270\u56e0\u7d20\u548c\u590d\u6742\u7684\u5fc3\u7406\u60c5\u666f\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5750\u6807\u5fc3\u810f\u7cfb\u7edf\uff08CHS\uff09\uff0c\u4e00\u4e2a\u7528\u4e8e\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u4e2d\u60c5\u611f\u8868\u793a\u7684\u51e0\u4f55\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u516b\u79cd\u6838\u5fc3\u60c5\u611f\u5b9a\u4f4d\u4e3a\u5355\u4f4d\u5706\u4e0a\u7684\u5750\u6807\uff0c\u901a\u8fc7\u5750\u6807\u6df7\u5408\u548c\u5411\u91cf\u8fd0\u7b97\u5b9e\u73b0\u590d\u6742\u60c5\u611f\u72b6\u6001\u7684\u6570\u5b66\u8ba1\u7b97\u3002\u8be5\u7cfb\u7edf\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u91cd\u65b0\u6821\u51c6\u7684\u7a33\u5b9a\u6027\u53c2\u6570S\uff0c\u8be5\u53c2\u6570\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u6587\u672c\u7ebf\u7d22\u7684\u89e3\u91ca\u548c\u6df7\u5408\u65f6\u95f4\u8ddf\u8e2a\u673a\u5236\uff0c\u4e3a\u5fc3\u7406\u5065\u5eb7\u72b6\u6001\u63d0\u4f9b\u7ec6\u81f4\u7684\u8bc4\u4f30\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u4f20\u7edf\u5206\u7c7b\u60c5\u611f\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u8868\u793a\u7684\u60c5\u611f\u51b2\u7a81\u72b6\u6001\u3001\u80cc\u666f\u56f0\u6270\u56e0\u7d20\u548c\u590d\u6742\u7684\u5fc3\u7406\u60c5\u666f\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u60c5\u611f\u5efa\u6a21\u5960\u5b9a\u4e86\u65b0\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2507.15554", "categories": ["cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15554", "abs": "https://arxiv.org/abs/2507.15554", "authors": ["Ssu-Chih Lin", "Paul Steinacker", "MengKe Feng", "Ajit Dash", "Santiago Serrano", "Wee Han Lim", "Kohei M. Itoh", "Fay E. Hudson", "Tuomo Tanttu", "Andre Saraiva", "Arne Laucht", "Andrew S. Dzurak", "Hsi-Sheng Goan", "Chih Hwan Yang"], "title": "Interplay of Zeeman Splitting and Tunnel Coupling in Coherent Spin Qubit Shuttling", "comment": null, "summary": "Spin shuttling offers a promising approach for developing scalable\nsilicon-based quantum processors by addressing the connectivity limitations of\nquantum dots (QDs). In this work, we demonstrate high-fidelity bucket-brigade\n(BB) spin shuttling in a silicon MOS device, utilizing Pauli Spin Blockade\n(PSB) readout. We achieve an average shuttling fidelity of \\SI{99.8}{\\percent}.\nThe residual shuttling error is highly sensitive to the ratio between interdot\ntunnel coupling and Zeeman splitting, with tuning of these parameters enabling\nup to a twenty-fold variation in error rate. An appropriate four-level\nHamiltonian model supports our findings. These results provide valuable\ninsights for optimizing high-performance spin shuttling systems in future\nquantum architectures.", "AI": {"tldr": "\u901a\u8fc7 Pauli Spin Blockade (PSB) \u8bfb\u51fa\u6280\u672f\uff0c\u5728\u7845 MOS \u5668\u4ef6\u4e2d\u5b9e\u73b0\u4e86 \n99.8% \u4fdd\u771f\u5ea6\u7684\u81ea\u65cb\u7a7f\u68ad\uff0c\u53ef\u7528\u4e8e\u6784\u5efa\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u5904\u7406\u5668\u3002", "motivation": "\u4e3a\u4e86\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u7845\u57fa\u91cf\u5b50\u5904\u7406\u5668\uff0c\u9700\u8981\u89e3\u51b3\u91cf\u5b50\u70b9\uff08QD\uff09\u7684\u8fde\u63a5\u6027\u9650\u5236\u3002\u81ea\u65cb\u7a7f\u68ad\u6280\u672f\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u9014\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5229\u7528 Pauli Spin Blockade (PSB) \u8bfb\u51fa\u6280\u672f\uff0c\u5728\u7845 MOS \u5668\u4ef6\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684 bucket-brigade (BB) \u81ea\u65cb\u7a7f\u68ad\u3002", "result": "\u5b9e\u73b0\u4e86\u5e73\u5747 \n99.8% \u7684\u7a7f\u68ad\u4fdd\u771f\u5ea6\uff0c\u5e76\u4e14\u53d1\u73b0\u6b8b\u4f59\u7a7f\u68ad\u8bef\u5dee\u5bf9\u5e93\u4ed1\u8026\u5408\u548c\u6cfd\u66fc\u5206\u88c2\u7684\u6bd4\u4f8b\u975e\u5e38\u654f\u611f\u3002", "conclusion": "\u81ea\u65cb\u7a7f\u68ad\u6280\u672f\u4e3a\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u7845\u57fa\u91cf\u5b50\u5904\u7406\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u5b83\u89e3\u51b3\u4e86\u91cf\u5b50\u70b9\uff08QD\uff09\u7684\u8fde\u63a5\u6027\u9650\u5236\u3002\u901a\u8fc7\u5bf9\u95e8\u7535\u538b\u7684\u4ed4\u7ec6\u8c03\u6574\uff0c\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u8fbe 20 \u500d\u7684\u9519\u8bef\u7387\u53d8\u5316\uff0c\u8fd9\u4e3a\u4f18\u5316\u672a\u6765\u7684\u91cf\u5b50\u67b6\u6784\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14219", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14219", "abs": "https://arxiv.org/abs/2507.14219", "authors": ["Obumneme Zimuzor Nwafor", "Mohammed Abdul Majeed Al Hooti"], "title": "Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman", "comment": null, "summary": "As nations seek sustainable alternatives to fossil fuels, green hydrogen has\nemerged as a promising strategic pathway toward decarbonisation, particularly\nin solar-rich arid regions. However, identifying optimal locations for hydrogen\nproduction requires the integration of complex environmental, atmospheric, and\ninfrastructural factors, often compounded by limited availability of direct\nhydrogen yield data. This study presents a novel Artificial Intelligence (AI)\nframework for computing green hydrogen yield and site suitability index using\nmean absolute SHAP (SHapley Additive exPlanations) values. This framework\nconsists of a multi-stage pipeline of unsupervised multi-variable clustering,\nsupervised machine learning classifier and SHAP algorithm. The pipeline trains\non an integrated meteorological, topographic and temporal dataset and the\nresults revealed distinct spatial patterns of suitability and relative\ninfluence of the variables. With model predictive accuracy of 98%, the result\nalso showed that water proximity, elevation and seasonal variation are the most\ninfluential factors determining green hydrogen site suitability in Oman with\nmean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively.\nGiven limited or absence of ground-truth yield data in many countries that have\ngreen hydrogen prospects and ambitions, this study offers an objective and\nreproducible alternative to subjective expert weightings, thus allowing the\ndata to speak for itself and potentially discover novel latent groupings\nwithout pre-imposed assumptions. This study offers industry stakeholders and\npolicymakers a replicable and scalable tool for green hydrogen infrastructure\nplanning and other decision making in data-scarce regions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u7eff\u8272\u6c22\u6c14\u4ea7\u91cf\u548c\u573a\u5730\u9002\u7528\u6027\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u5730\u533a\u9762\u4e34\u7684\u6311\u6218\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u805a\u7c7b\u3001\u5206\u7c7b\u548cSHAP\u503c\u6765\u8bc6\u522b\u5173\u952e\u56e0\u7d20\uff0c\u5982\u6c34\u4f53\u90bb\u8fd1\u5ea6\u3001\u6d77\u62d4\u548c\u5b63\u8282\u6027\u53d8\u5316\uff0c\u51c6\u786e\u5ea6\u8fbe98%\uff0c\u4e3a\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5de5\u5177\u3002", "motivation": "\u968f\u7740\u5404\u56fd\u5bfb\u6c42\u5316\u77f3\u71c3\u6599\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u54c1\uff0c\u7eff\u8272\u6c22\u6c14\u5df2\u6210\u4e3a\u8131\u78b3\u7684\u91cd\u8981\u6218\u7565\u9014\u5f84\uff0c\u5c24\u5176\u662f\u5728\u592a\u9633\u80fd\u4e30\u5bcc\u7684\u5e72\u65f1\u5730\u533a\u3002\u7136\u800c\uff0c\u786e\u5b9a\u6c22\u6c14\u751f\u4ea7\u7684\u6700\u4f73\u5730\u70b9\u9700\u8981\u6574\u5408\u590d\u6742\u7684\u73af\u5883\u3001\u5927\u6c14\u548c\u57fa\u7840\u8bbe\u65bd\u56e0\u7d20\uff0c\u5e76\u4e14\u901a\u5e38\u7531\u4e8e\u76f4\u63a5\u6c22\u6c14\u4ea7\u91cf\u6570\u636e\u7684\u53ef\u7528\u6027\u6709\u9650\u800c\u53d8\u5f97\u590d\u6742\u3002", "method": "\u672c\u7814\u7a76\u7684\u6846\u67b6\u5305\u62ec\u4e00\u4e2a\u591a\u9636\u6bb5\u6d41\u7a0b\uff1a\u65e0\u76d1\u7763\u591a\u53d8\u91cf\u805a\u7c7b\u3001\u6709\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u548cSHAP\u7b97\u6cd5\u3002\u8be5\u6d41\u7a0b\u5728\u96c6\u6210\u7684\u6c14\u8c61\u3001\u5730\u5f62\u548c\u65f6\u95f4\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u4e86\u9002\u7528\u6027\u7684\u72ec\u7279\u7a7a\u95f4\u6a21\u5f0f\u4ee5\u53ca\u53d8\u91cf\u7684\u76f8\u5bf9\u5f71\u54cd\u3002\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6\u4e3a98%\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5728\u963f\u66fc\uff0c\u6c34\u4f53\u90bb\u8fd1\u5ea6\u3001\u6d77\u62d4\u548c\u5b63\u8282\u6027\u53d8\u5316\u662f\u51b3\u5b9a\u7eff\u8272\u6c22\u6c14\u573a\u5730\u9002\u7528\u6027\u7684\u6700\u91cd\u8981\u56e0\u7d20\uff0c\u5176\u5e73\u5747\u7edd\u5bf9SHAP\u503c\u5206\u522b\u4e3a2.470891\u30012.376296\u548c1.273216\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u6846\u67b6\uff0c\u5229\u7528\u5e73\u5747\u7edd\u5bf9SHAP\u503c\u8ba1\u7b97\u7eff\u8272\u6c22\u6c14\u4ea7\u91cf\u548c\u573a\u5730\u9002\u7528\u6027\u6307\u6570\u3002\u8be5\u6846\u67b6\u4e3a\u6570\u636e\u7a00\u7f3a\u5730\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5ba2\u89c2\u4e14\u53ef\u91cd\u590d\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u7528\u4e8e\u7eff\u8272\u6c22\u6c14\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2507.15031", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15031", "abs": "https://arxiv.org/abs/2507.15031", "authors": ["Omid Akbarzadeh", "Mohammad H. Mamduhi", "Abolfazl Lavaei"], "title": "Safety Controller Synthesis for Stochastic Networked Systems under Communication Constraints", "comment": null, "summary": "This paper develops a framework for synthesizing safety controllers for\ndiscrete-time stochastic linear control systems (dt-SLS) operating under\ncommunication imperfections. The control unit is remote and communicates with\nthe sensor and actuator through an imperfect wireless network. We consider a\nconstant delay in the sensor-to-controller channel (uplink), and data loss in\nboth sensor-to-controller and controller-to-actuator (downlink) channels. In\nour proposed scheme, data loss in each channel is modeled as an independent\nBernoulli-distributed random process. To systematically handle the uplink\ndelay, we first introduce an augmented discrete-time stochastic linear system\n(dt-ASLS) by concatenating all states and control inputs that sufficiently\nrepresent the state-input evolution of the original dt-SLS under the delay and\npacket loss constraints. We then leverage control barrier certificates (CBCs)\nfor dt-ASLS to synthesize a controller that guarantees dt-SLS safety in a\nstochastic sense, ensuring that all trajectories of dt-SLS remain within safe\nregions with a quantified probabilistic bound. Our approach translates safety\nconstraints into matrix inequalities, leading to an optimization problem that\neventually quantifies the probability of satisfying the safety specification in\nthe presence of communication imperfections. We validate our results on an RLC\ncircuit subject to both constant delay and probabilistic data loss.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u63a7\u5236\u969c\u788d\u8bc1\u4e66\uff08CBCs\uff09\u4e3a\u5b58\u5728\u65f6\u5ef6\u548c\u4e22\u5305\u7684\u901a\u4fe1\u7cfb\u7edf\u7684\u79bb\u6563\u65f6\u95f4\u968f\u673a\u7ebf\u6027\u63a7\u5236\u7cfb\u7edf\uff08dt-SLS\uff09\u5408\u6210\u5b89\u5168\u63a7\u5236\u5668\u7684\u65b9\u6cd5\uff0c\u5e76\u5728RLC\u7535\u8def\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u4e3a\u5728\u901a\u4fe1\u4e0d\u5b8c\u5584\uff08\u5305\u62ec\u65f6\u5ef6\u548c\u4e22\u5305\uff09\u7684\u60c5\u51b5\u4e0b\u8fd0\u884c\u7684\u79bb\u6563\u65f6\u95f4\u968f\u673a\u7ebf\u6027\u63a7\u5236\u7cfb\u7edf\uff08dt-SLS\uff09\u5f00\u53d1\u5b89\u5168\u63a7\u5236\u5668\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u65f6\u5ef6\u548c\u4e22\u5305\u7684\u589e\u5f3a\u79bb\u6563\u65f6\u95f4\u968f\u673a\u7ebf\u6027\u7cfb\u7edf\uff08dt-ASLS\uff09\u6a21\u578b\uff0c\u5e76\u5229\u7528\u5176\u63a7\u5236\u969c\u788d\u8bc1\u4e66\uff08CBCs\uff09\u6765\u5408\u6210\u63a7\u5236\u5668\uff0c\u5c06\u5b89\u5168\u7ea6\u675f\u8f6c\u5316\u4e3a\u77e9\u9635\u4e0d\u7b49\u5f0f\uff0c\u6700\u7ec8\u6c42\u89e3\u4e00\u4e2a\u4f18\u5316\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06\u5b89\u5168\u7ea6\u675f\u8f6c\u5316\u4e3a\u77e9\u9635\u4e0d\u7b49\u5f0f\uff0c\u6700\u7ec8\u6c42\u89e3\u4e00\u4e2a\u4f18\u5316\u95ee\u9898\uff0c\u91cf\u5316\u4e86\u5728\u901a\u4fe1\u4e0d\u5b8c\u5584\u7684\u60c5\u51b5\u4e0b\u6ee1\u8db3\u5b89\u5168\u89c4\u8303\u7684\u6982\u7387\uff0c\u5e76\u5728RLC\u7535\u8def\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63a7\u5236\u969c\u788d\u8bc1\u4e66\uff08CBCs\uff09\u4e3a\u79bb\u6563\u65f6\u95f4\u968f\u673a\u7ebf\u6027\u63a7\u5236\u7cfb\u7edf\uff08dt-SLS\uff09\u5408\u6210\u63a7\u5236\u5668\uff0c\u5728\u901a\u4fe1\u4e0d\u5b8c\u5584\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u4e86\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5e76\u91cf\u5316\u4e86\u6ee1\u8db3\u5b89\u5168\u89c4\u8303\u7684\u6982\u7387\u3002"}}
{"id": "2507.14663", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14663", "abs": "https://arxiv.org/abs/2507.14663", "authors": ["Nicola Piovella"], "title": "Subradiance generation in a chain of two-level atoms with a single excitation", "comment": "19 pages, 12 figures", "summary": "Studies of subradiance in a chain N two-level atoms in the single excitation\nregime focused mainly on the complex spectrum of the effective Hamiltonian,\nidentifying subradiant eigenvalues. This can be achieved by finding the\neigenvalues $N$ of the Hamiltonian or by evaluating the expectation value of\nthe Hamiltonian on a generalized Dicke state, depending on a continuous\nvariable k. This has the advantage that the sum above N can be calculated\nexactly, such that N becomes a simple parameter of the system and no more the\nsize of the Hilbert space. However, the question remains how subradiance\nemerges from atoms initially excited or driven by a laser. Here we study the\ndynamics of the system, solving the coupled-dipole equations for N atoms and\nevaluating the probability to be in a generalized Dicke state at a given time.\nOnce the subradiant regions has been identified, it is simple to see if\nsubradiance is being generated. We discuss different initial excitation\nconditions that lead to subradiance and the case of atoms excited by switching\non and off a weak laser. This may be relevant for future experiments aimed at\ndetecting subradiance in ordered systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u52a8\u529b\u5b66\u6a21\u62df\u7814\u7a76\u4e86\u539f\u5b50\u94fe\u4e2d\u7684\u4e9a\u8f90\u5c04\u73b0\u8c61\uff0c\u53d1\u73b0\u4e86\u4e9a\u8f90\u5c04\u7684\u4ea7\u751f\u673a\u5236\uff0c\u5e76\u4e3a\u5b9e\u9a8c\u63a2\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4e9a\u8f90\u5c04\u5982\u4f55\u4ece\u521d\u59cb\u6fc0\u53d1\u6216\u6fc0\u5149\u9a71\u52a8\u7684\u539f\u5b50\u4e2d\u4ea7\u751f\u7684\u5173\u952e\u95ee\u9898\uff0c\u4ee5\u671f\u6307\u5bfc\u672a\u6765\u5728\u6709\u5e8f\u7cfb\u7edf\u4e2d\u63a2\u6d4b\u4e9a\u8f90\u5c04\u7684\u5b9e\u9a8c\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u6c42\u89e3N\u539f\u5b50\u7684\u8026\u5408\u5076\u6781\u65b9\u7a0b\uff0c\u5e76\u8bc4\u4f30\u539f\u5b50\u5904\u4e8e\u5e7f\u4e49\u8fea\u514b\u72b6\u6001\u7684\u6982\u7387\u6765\u7814\u7a76\u4e9a\u8f90\u5c04\u7684\u52a8\u529b\u5b66\u3002", "result": "\u672c\u7814\u7a76\u8bc6\u522b\u4e86\u4e9a\u8f90\u5c04\u533a\u57df\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u521d\u59cb\u6fc0\u53d1\u6761\u4ef6\u548c\u6fc0\u5149\u9a71\u52a8\u4e0b\u4e9a\u8f90\u5c04\u7684\u4ea7\u751f\u60c5\u51b5\uff0c\u4e3a\u76f8\u5173\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4e9a\u8f90\u5c04\u73b0\u8c61\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u901a\u8fc7\u6c42\u89e3\u8026\u5408\u5076\u6781\u65b9\u7a0b\u5e76\u8bc4\u4f30\u539f\u5b50\u5904\u4e8e\u5e7f\u4e49\u8fea\u514b\u72b6\u6001\u7684\u6982\u7387\uff0c\u9610\u8ff0\u4e86\u4e9a\u8f90\u5c04\u7684\u4ea7\u751f\u673a\u5236\uff0c\u5e76\u8ba8\u8bba\u4e86\u4e0d\u540c\u7684\u521d\u59cb\u6fc0\u53d1\u6761\u4ef6\u548c\u6fc0\u5149\u9a71\u52a8\u4e0b\u7684\u60c5\u51b5\u3002"}}
{"id": "2507.14372", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.14372", "abs": "https://arxiv.org/abs/2507.14372", "authors": ["Albert Chen", "Manas Bundele", "Gaurav Ahlawat", "Patrick Stetz", "Zhitao Wang", "Qiang Fei", "Donghoon Jung", "Audrey Chu", "Bharadwaj Jayaraman", "Ayushi Panth", "Yatin Arora", "Sourav Jain", "Renjith Varma", "Alexey Ilin", "Iuliia Melnychuk", "Chelsea Chueh", "Joyan Sil", "Xiaofeng Wang"], "title": "Text-to-SQL for Enterprise Data Analytics", "comment": "11 pages, 8 figures, Workshop on Agentic AI for Enterprise at KDD '25", "summary": "The introduction of large language models has brought rapid progress on\nText-to-SQL benchmarks, but it is not yet easy to build a working enterprise\nsolution. In this paper, we present insights from building an internal chatbot\nthat enables LinkedIn's product managers, engineers, and operations teams to\nself-serve data insights from a large, dynamic data lake. Our approach features\nthree components. First, we construct a knowledge graph that captures\nup-to-date semantics by indexing database metadata, historical query logs,\nwikis, and code. We apply clustering to identify relevant tables for each team\nor product area. Second, we build a Text-to-SQL agent that retrieves and ranks\ncontext from the knowledge graph, writes a query, and automatically corrects\nhallucinations and syntax errors. Third, we build an interactive chatbot that\nsupports various user intents, from data discovery to query writing to\ndebugging, and displays responses in rich UI elements to encourage follow-up\nchats. Our chatbot has over 300 weekly users. Expert review shows that 53% of\nits responses are correct or close to correct on an internal benchmark set.\nThrough ablation studies, we identify the most important knowledge graph and\nmodeling components, offering a practical path for developing enterprise\nText-to-SQL solutions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u4f01\u4e1a\u7ea7Text-to-SQL\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u667a\u80fd\u4ee3\u7406\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u81ea\u52a9\u67e5\u8be2\u6570\u636e\u3002\u673a\u5668\u4eba\u62e5\u6709\u5927\u91cf\u7528\u6237\uff0c\u5e76\u5728\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u4f01\u4e1a\u7ea7\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\uff0c\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Text-to-SQL\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u5feb\u901f\u8fdb\u5c55\uff0c\u4f46\u5728\u6784\u5efa\u5b9e\u9645\u7684\u4f01\u4e1a\u7ea7\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u5206\u4eab\u4e00\u4e2a\u5185\u90e8\u804a\u5929\u673a\u5668\u4eba\u7684\u6784\u5efa\u7ecf\u9a8c\uff0c\u8be5\u673a\u5668\u4eba\u4f7fLinkedIn\u7684\u4ea7\u54c1\u7ecf\u7406\u3001\u5de5\u7a0b\u5e08\u548c\u8fd0\u8425\u56e2\u961f\u80fd\u591f\u4ece\u5927\u578b\u52a8\u6001\u6570\u636e\u6e56\u4e2d\u81ea\u52a9\u83b7\u53d6\u6570\u636e\u6d1e\u5bdf\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a1. \u6784\u5efa\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u7d22\u5f15\u6570\u636e\u5e93\u5143\u6570\u636e\u3001\u5386\u53f2\u67e5\u8be2\u65e5\u5fd7\u3001\u7ef4\u57fa\u767e\u79d1\u548c\u4ee3\u7801\u6765\u6355\u6349\u6700\u65b0\u8bed\u4e49\uff0c\u5e76\u5e94\u7528\u805a\u7c7b\u8bc6\u522b\u6bcf\u4e2a\u56e2\u961f\u6216\u4ea7\u54c1\u9886\u57df\u76f8\u5173\u7684\u8868\u30022. \u6784\u5efa\u4e00\u4e2aText-to-SQL\u4ee3\u7406\uff0c\u7528\u4e8e\u68c0\u7d22\u548c\u6392\u5e8f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e0a\u4e0b\u6587\uff0c\u7f16\u5199SQL\u67e5\u8be2\uff0c\u5e76\u81ea\u52a8\u7ea0\u6b63\u5e7b\u89c9\u548c\u8bed\u6cd5\u9519\u8bef\u30023. \u6784\u5efa\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\uff0c\u652f\u6301\u7528\u6237\u4ece\u6570\u636e\u53d1\u73b0\u5230\u67e5\u8be2\u7f16\u5199\u548c\u8c03\u8bd5\u7684\u5404\u79cd\u610f\u56fe\uff0c\u5e76\u4f7f\u7528\u4e30\u5bcc\u7684UI\u5143\u7d20\u5c55\u793a\u54cd\u5e94\u4ee5\u9f13\u52b1\u540e\u7eed\u4ea4\u4e92\u3002", "result": "\u8be5\u804a\u5929\u673a\u5668\u4eba\u6bcf\u5468\u62e5\u6709\u8d85\u8fc7300\u4e2a\u6d3b\u8dc3\u7528\u6237\u3002\u5728\u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e13\u5bb6\u8bc4\u5ba1\u663e\u793a\u517653%\u7684\u54cd\u5e94\u662f\u6b63\u786e\u6216\u57fa\u672c\u6b63\u786e\u7684\u3002\u901a\u8fc7\u6d88\u878d\u7814\u7a76\uff0c\u8bba\u6587\u786e\u5b9a\u4e86\u77e5\u8bc6\u56fe\u8c31\u548c\u6a21\u578b\u4e2d\u6700\u91cd\u8981\u7684\u7ec4\u6210\u90e8\u5206\u3002", "conclusion": "\u8be5\u8bba\u6587\u901a\u8fc7\u6784\u5efa\u5305\u542b\u6570\u636e\u5e93\u5143\u6570\u636e\u3001\u5386\u53f2\u67e5\u8be2\u65e5\u5fd7\u3001\u7ef4\u57fa\u767e\u79d1\u548c\u4ee3\u7801\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u7ed3\u5408\u80fd\u591f\u68c0\u7d22\u548c\u6392\u5e8f\u77e5\u8bc6\u56fe\u8c31\u4e0a\u4e0b\u6587\u3001\u7f16\u5199\u67e5\u8be2\u4ee5\u53ca\u81ea\u52a8\u7ea0\u6b63\u9519\u8bef\u7684Text-to-SQL\u4ee3\u7406\uff0c\u6700\u7ec8\u6784\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u6570\u636e\u53d1\u73b0\u3001\u67e5\u8be2\u7f16\u5199\u548c\u8c03\u8bd5\u7684\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\uff0c\u4e3a\u4f01\u4e1a\u7ea7Text-to-SQL\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u7684\u9014\u5f84\u3002"}}
{"id": "2507.14155", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.14155", "abs": "https://arxiv.org/abs/2507.14155", "authors": ["Pramesh Gautam", "Sushmita Sapkota", "Carsten Bockelmann", "Shashi Raj Pandey", "Armin Dekorsy"], "title": "Extreme Value Theory-based Distributed Interference Prediction for 6G Industrial Sub-networks", "comment": null, "summary": "Interference prediction that accounts for extreme and rare events remains a\nkey challenge for ultra-densely deployed sub-networks (SNs) requiring\nhyper-reliable low-latency communication (HRLLC), particularly under dynamic\nmobility, rapidly varying channel statistics, and sporadic traffic. This paper\nproposes a novel calibrated interference tail prediction framework, a hybrid\nstatistical and machine learning (ML) approach that integrates an inverted\nquantile patch transformer (iQPTransformer) within extreme value theory (EVT).\nIt captures interference dynamics and tail behavior while quantifying\nuncertainty to provide statistical coverage guarantees. Its effectiveness is\ndemonstrated by leveraging the estimated interference tail distribution to\ndesign predictive, risk-aware resource allocation. In resource-constrained SN\nscenarios, we introduce the split-iQPTransformer, enabling collaborative\ntraining by distributing neural network components between sensor-actuator (SA)\npairs and the SN controller, while maintaining minimal performance disparity\ncompared to the centralized iQPTransformer. The framework effectively handles\ndeep fading, random traffic, and time-division duplexing (TDD) misalignments\nand is resilient to rare and extreme interference events. Extensive evaluations\nare performed under two mobility models and two realistic SN traffic patterns,\nusing a spatially consistent 3GPP channel model across all scenarios.\nExperimental results show consistent achievement of block error rate (BLER)\ntargets beyond the 95th percentile in the hyper-reliable regime, significantly\noutperforming baseline approaches.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6781\u503c\u7406\u8bba\u548c\u673a\u5668\u5b66\u4e60\u7684\u6846\u67b6\uff08iQPTransformer\uff09\uff0c\u7528\u4e8e\u9884\u6d4b\u8d85\u5bc6\u96c6\u7f51\u7edc\u4e2d\u7684\u5e72\u6270\uff0c\u7279\u522b\u662f\u6781\u7aef\u60c5\u51b5\u3002\u8be5\u6846\u67b6\u80fd\u5904\u7406\u5404\u79cd\u6311\u6218\uff0c\u5e76\u5df2\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u8fbe\u5230\u9ad8\u53ef\u9760\u6027\u76ee\u6807\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u4e8e\u8d85\u5bc6\u96c6\u90e8\u7f72\u7684\u5b50\u7f51\u7edc\uff08SN\uff09\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u79fb\u52a8\u3001\u5feb\u901f\u53d8\u5316\u7684\u4fe1\u9053\u7edf\u8ba1\u548c\u96f6\u661f\u6d41\u91cf\u4e0b\uff0c\u9700\u8981\u8d85\u9ad8\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\uff08HRLLC\uff09\uff0c\u800c\u80fd\u591f\u8003\u8651\u6781\u7aef\u548c\u7f55\u89c1\u4e8b\u4ef6\u7684\u5e72\u6270\u9884\u6d4b\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6821\u51c6\u5e72\u6270\u5c3e\u90e8\u9884\u6d4b\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u6df7\u5408\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u65b9\u6cd5\uff0c\u5c06\u53cd\u5411\u5206\u4f4d\u6570\u5757 Transformer\uff08iQPTransformer\uff09\u4e0e\u6781\u503c\u7406\u8bba\uff08EVT\uff09\u76f8\u7ed3\u5408\u3002\u5b83\u6355\u83b7\u5e72\u6270\u52a8\u6001\u548c\u5c3e\u90e8\u884c\u4e3a\uff0c\u540c\u65f6\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u4ee5\u63d0\u4f9b\u7edf\u8ba1\u8986\u76d6\u4fdd\u8bc1\u3002\u901a\u8fc7\u5229\u7528\u4f30\u8ba1\u7684\u5e72\u6270\u5c3e\u90e8\u5206\u5e03\u6765\u8bbe\u8ba1\u9884\u6d4b\u6027\u3001\u98ce\u9669\u611f\u77e5\u7684\u8d44\u6e90\u5206\u914d\u6765\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5b50\u7f51\u7edc\uff08SN\uff09\u573a\u666f\u4e2d\uff0c\u5f15\u5165\u4e86split-iQPTransformer\uff0c\u901a\u8fc7\u5728\u4f20\u611f\u5668-\u6267\u884c\u5668\uff08SA\uff09\u5bf9\u548cSN\u63a7\u5236\u5668\u4e4b\u95f4\u5206\u5e03\u5f0f\u795e\u7ecf\u7f51\u7edc\u7ec4\u4ef6\u6765\u5b9e\u73b0\u534f\u540c\u8bad\u7ec3\uff0c\u540c\u65f6\u4e0e\u96c6\u4e2d\u5f0fiQPTransformer\u76f8\u6bd4\uff0c\u6027\u80fd\u5dee\u5f02\u6781\u5c0f\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u6df1\u5ea6\u8870\u843d\u3001\u968f\u673a\u6d41\u91cf\u548c\u65f6\u5206\u53cc\u5de5\uff08TDD\uff09\u9519\u4f4d\uff0c\u5e76\u80fd\u62b5\u6297\u7a00\u6709\u548c\u6781\u7aef\u5e72\u6270\u4e8b\u4ef6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8d85\u53ef\u9760\u72b6\u6001\u4e0b\uff0c\u5757\u9519\u8bef\u7387\uff08BLER\uff09\u76ee\u6807\u59cb\u7ec8\u80fd\u8fbe\u523095%\u4ee5\u4e0a\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u6df1\u5ea6\u8870\u843d\u3001\u968f\u673a\u6d41\u91cf\u548c\u65f6\u5206\u53cc\u5de5\uff08TDD\uff09\u9519\u4f4d\uff0c\u5e76\u80fd\u62b5\u6297\u7a00\u6709\u548c\u6781\u7aef\u5e72\u6270\u4e8b\u4ef6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8d85\u53ef\u9760\u72b6\u6001\u4e0b\uff0c\u5757\u9519\u8bef\u7387\uff08BLER\uff09\u76ee\u6807\u59cb\u7ec8\u80fd\u8fbe\u523095%\u4ee5\u4e0a\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2507.14931", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14931", "abs": "https://arxiv.org/abs/2507.14931", "authors": ["Qiaoqiao Ren", "Remko Proesmans", "Arend Pissens", "Lara Dehandschutter", "William Denecker", "Lotte Rouckhout", "Joke Carrette", "Peter Vanhopplinus", "Tony Belpaeme", "Francis wyffels"], "title": "Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry", "comment": null, "summary": "Forensic mental health care involves the treatment of individuals with severe\nmental disorders who have committed violent offences. These settings are often\ncharacterized by high levels of bureaucracy, risk avoidance, and restricted\nautonomy. Patients frequently experience a profound loss of control over their\nlives, leading to heightened psychological stress-sometimes resulting in\nisolation as a safety measure. In this study, we explore how co-design can be\nused to collaboratively develop a companion robot that helps monitor and\nregulate stress while maintaining tracking of the patients' interaction\nbehaviours for long-term intervention. We conducted four co-design workshops in\na forensic psychiatric clinic with patients, caregivers, and therapists. Our\nprocess began with the presentation of an initial speculative prototype to\ntherapists, enabling reflection on shared concerns, ethical risks, and\ndesirable features. This was followed by a creative ideation session with\npatients, a third workshop focused on defining desired functions and emotional\nresponses, and we are planning a final prototype demo to gather direct patient\nfeedback. Our findings emphasize the importance of empowering patients in the\ndesign process and adapting proposals based on their current emotional state.\nThe goal was to empower the patient in the design process and ensure each\npatient's voice was heard.", "AI": {"tldr": "\u901a\u8fc7\u5171\u540c\u8bbe\u8ba1\uff0c\u8ba9\u53f8\u6cd5\u7cbe\u795e\u536b\u751f\u4fdd\u5065\u4e2d\u7684\u60a3\u8005\u53c2\u4e0e\u5230\u5f00\u53d1\u51cf\u538b\u673a\u5668\u4eba\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u89e3\u51b3\u4ed6\u4eec\u7684\u5fc3\u7406\u538b\u529b\u548c\u5931\u63a7\u611f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u53f8\u6cd5\u7cbe\u795e\u536b\u751f\u4fdd\u5065\u73af\u5883\u4e2d\u5b58\u5728\u7684\u5b98\u50da\u4e3b\u4e49\u3001\u89c4\u907f\u98ce\u9669\u548c\u81ea\u4e3b\u6027\u53d7\u9650\u7b49\u95ee\u9898\uff0c\u5e76\u5e94\u5bf9\u60a3\u8005\u56e0\u5931\u53bb\u5bf9\u751f\u6d3b\u7684\u63a7\u5236\u800c\u4ea7\u751f\u7684\u5fc3\u7406\u538b\u529b\u3002", "method": "\u901a\u8fc7\u56db\u4e2a\u5171\u540c\u8bbe\u8ba1\u7814\u8ba8\u4f1a\uff0c\u8ba9\u60a3\u8005\u3001\u62a4\u7406\u4eba\u5458\u548c\u6cbb\u7597\u5e08\u53c2\u4e0e\u8fdb\u6765\uff0c\u5171\u540c\u5f00\u53d1\u4e00\u6b3e\u80fd\u591f\u76d1\u6d4b\u548c\u8c03\u8282\u538b\u529b\u7684\u4f34\u4fa3\u673a\u5668\u4eba\u3002", "result": "\u5171\u540c\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u53d1\u73b0\uff0c\u5f3a\u8c03\u4e86\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u8d4b\u4e88\u60a3\u8005\u6743\u529b\u4ee5\u53ca\u6839\u636e\u60a3\u8005\u5f53\u524d\u60c5\u7eea\u72b6\u6001\u8c03\u6574\u5efa\u8bae\u7684\u91cd\u8981\u6027\uff0c\u76ee\u6807\u662f\u8ba9\u60a3\u8005\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u62e5\u6709\u8bdd\u8bed\u6743\uff0c\u5e76\u786e\u4fdd\u6bcf\u4e2a\u60a3\u8005\u7684\u58f0\u97f3\u90fd\u80fd\u88ab\u542c\u5230\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u8d4b\u4e88\u60a3\u8005\u6743\u529b\u4ee5\u53ca\u6839\u636e\u60a3\u8005\u5f53\u524d\u60c5\u7eea\u72b6\u6001\u8c03\u6574\u5efa\u8bae\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.14485", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14485", "abs": "https://arxiv.org/abs/2507.14485", "authors": ["Hongye Hou", "Liu Zhan", "Yang Yang"], "title": "Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion", "comment": null, "summary": "Completing the whole 3D structure based on an incomplete point cloud is a\nchallenging task, particularly when the residual point cloud lacks typical\nstructural characteristics. Recent methods based on cross-modal learning\nattempt to introduce instance images to aid the structure feature learning.\nHowever, they still focus on each particular input class, limiting their\ngeneration abilities. In this work, we propose a novel retrieval-augmented\npoint cloud completion framework. The core idea is to incorporate cross-modal\nretrieval into completion task to learn structural prior information from\nsimilar reference samples. Specifically, we design a Structural Shared Feature\nEncoder (SSFE) to jointly extract cross-modal features and reconstruct\nreference features as priors. Benefiting from a dual-channel control gate in\nthe encoder, relevant structural features in the reference sample are enhanced\nand irrelevant information interference is suppressed. In addition, we propose\na Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical\nfeature fusion mechanism to integrate reference prior information with input\nfeatures from global to local. Through extensive evaluations on multiple\ndatasets and real-world scenes, our method shows its effectiveness in\ngenerating fine-grained point clouds, as well as its generalization capability\nin handling sparse data and unseen categories.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u68c0\u7d22\u589e\u5f3a\u7684\u70b9\u4e91\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u76f8\u4f3c\u53c2\u8003\u6837\u672c\u7684\u7ed3\u6784\u5148\u9a8c\u4fe1\u606f\u6765\u6539\u8fdb\u4e0d\u5b8c\u6574\u70b9\u4e91\u76843D\u7ed3\u6784\u91cd\u5efa\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7SSFE\u548cPRAG\u6a21\u5757\uff0c\u6709\u6548\u589e\u5f3a\u76f8\u5173\u7ed3\u6784\u7279\u5f81\uff0c\u6291\u5236\u65e0\u5173\u4fe1\u606f\uff0c\u5e76\u5b9e\u73b0\u4ece\u5168\u5c40\u5230\u5c40\u90e8\u7684\u7279\u5f81\u878d\u5408\uff0c\u5728\u5904\u7406\u7a00\u758f\u548c\u672a\u89c1\u7c7b\u522b\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u5728\u4e0d\u5b8c\u6574\u7684\u70b9\u4e91\u4e2d\u5b8c\u6210\u6574\u4e2a3D\u7ed3\u6784\u7684\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u6b8b\u5dee\u70b9\u4e91\u7f3a\u4e4f\u5178\u578b\u7ed3\u6784\u7279\u5f81\u65f6\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6bcf\u4e2a\u7279\u5b9a\u7684\u8f93\u5165\u7c7b\u522b\uff0c\u9650\u5236\u4e86\u5176\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u68c0\u7d22\u589e\u5f3a\u70b9\u4e91\u8865\u5168\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u8de8\u6a21\u6001\u68c0\u7d22\u6765\u5b66\u4e60\u76f8\u4f3c\u53c2\u8003\u6837\u672c\u7684\u7ed3\u6784\u5148\u9a8c\u4fe1\u606f\u3002\u8bbe\u8ba1\u4e86\u7ed3\u6784\u5171\u4eab\u7279\u5f81\u7f16\u7801\u5668\uff08SSFE\uff09\u6765\u8054\u5408\u63d0\u53d6\u8de8\u6a21\u6001\u7279\u5f81\u548c\u91cd\u5efa\u53c2\u8003\u7279\u5f81\u4f5c\u4e3a\u5148\u9a8c\u3002\u901a\u8fc7\u7f16\u7801\u5668\u4e2d\u7684\u53cc\u901a\u9053\u63a7\u5236\u95e8\uff0c\u589e\u5f3a\u53c2\u8003\u6837\u672c\u4e2d\u7684\u76f8\u5173\u7ed3\u6784\u7279\u5f81\u5e76\u6291\u5236\u65e0\u5173\u4fe1\u606f\u5e72\u6270\u3002\u63d0\u51fa\u4e86\u6e10\u8fdb\u5f0f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5668\uff08PRAG\uff09\uff0c\u91c7\u7528\u5206\u5c42\u7279\u5f81\u878d\u5408\u673a\u5236\uff0c\u4ece\u5168\u5c40\u5230\u5c40\u90e8\u5730\u5c06\u53c2\u8003\u5148\u9a8c\u4fe1\u606f\u4e0e\u8f93\u5165\u7279\u5f81\u76f8\u7ed3\u5408\u3002", "result": "\u751f\u6210\u7ec6\u7c92\u5ea6\u70b9\u4e91\uff0c\u5e76\u5c55\u793a\u4e86\u5904\u7406\u7a00\u758f\u6570\u636e\u548c\u672a\u89c1\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u771f\u5b9e\u573a\u666f\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u751f\u6210\u7ec6\u7c92\u5ea6\u70b9\u4e91\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u5728\u5904\u7406\u7a00\u758f\u6570\u636e\u548c\u672a\u89c1\u7c7b\u522b\u65b9\u9762\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.14642", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14642", "abs": "https://arxiv.org/abs/2507.14642", "authors": ["Monoshiz Mahbub Khan", "Xioayin Xi", "Andrew Meneely", "Zhe Yu"], "title": "Efficient Story Point Estimation With Comparative Learning", "comment": null, "summary": "Story point estimation is an essential part of agile software development.\nStory points are unitless, project-specific effort estimates that help\ndevelopers plan their sprints. Traditionally, developers estimate story points\ncollaboratively using planning poker or other manual techniques. While the\ninitial calibrating of the estimates to each project is helpful, once a team\nhas converged on a set of precedents, story point estimation can become tedious\nand labor-intensive. Machine learning can reduce this burden, but only with\nenough context from the historical decisions made by the project team. That is,\nstate-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate\npredictions (within-project) when trained on data from the same project. The\ngoal of this work is to streamline story point estimation by evaluating a\ncomparative learning-based framework for calibrating project-specific story\npoint prediction models. Instead of assigning a specific story point value to\nevery backlog item, developers are presented with pairs of items, and indicate\nwhich item requires more effort. Using these comparative judgments, a machine\nlearning model is trained to predict the story point estimates. We empirically\nevaluated our technique using data with 23,313 manual estimates in 16 projects.\nThe model learned from comparative judgments can achieve on average 0.34\nSpearman's rank correlation coefficient between its predictions and the ground\ntruth story points. This is similar to, if not better than, the performance of\na regression model learned from the ground truth story points. Therefore, the\nproposed comparative learning approach is more efficient than state-of-the-art\nregression-based approaches according to the law of comparative judgments -\nproviding comparative judgments yields a lower cognitive burden on humans than\nproviding ratings or categorical labels.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6545\u4e8b\u70b9\u4f30\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u5f00\u53d1\u8005\u6bd4\u8f83\u9700\u6c42\u5bf9\u800c\u975e\u76f4\u63a5\u4f30\u7b97\uff0c\u53ef\u4ee5\u51cf\u8f7b\u4f30\u7b97\u8d1f\u62c5\u5e76\u63d0\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u6545\u4e8b\u70b9\u4f30\u7b97\u65b9\u6cd5\uff08\u5982\u89c4\u5212\u6251\u514b\uff09\u867d\u7136\u5728\u9879\u76ee\u521d\u671f\u6821\u51c6\u4f30\u7b97\u5f88\u6709\u5e2e\u52a9\uff0c\u4f46\u4e00\u65e6\u56e2\u961f\u5c31\u4e00\u7cfb\u5217\u5148\u4f8b\u8fbe\u6210\u4e00\u81f4\uff0c\u4f30\u7b97\u8fc7\u7a0b\u4f1a\u53d8\u5f97\u7e41\u7410\u4e14\u8017\u65f6\u3002\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u51cf\u8f7b\u8fd9\u79cd\u8d1f\u62c5\uff0c\u4f46\u9700\u8981\u9879\u76ee\u5386\u53f2\u6570\u636e\u7684\u652f\u6301\uff0c\u73b0\u6709\u6a21\u578b\uff08\u5982GPT2SP\u548cFastText-SVM\uff09\u4ec5\u5728\u540c\u4e00\u9879\u76ee\u7684\u5386\u53f2\u6570\u636e\u4e0a\u8bad\u7ec3\u65f6\u624d\u80fd\u505a\u51fa\u51c6\u786e\u9884\u6d4b\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8bc4\u4f30\u4e00\u4e2a\u6bd4\u8f83\u5b66\u4e60\u6846\u67b6\u6765\u7b80\u5316\u6545\u4e8b\u70b9\u4f30\u7b97\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6bd4\u8f83\u5b66\u4e60\u7684\u6846\u67b6\u3002\u5f00\u53d1\u8005\u65e0\u9700\u4e3a\u6bcf\u4e2a\u9700\u6c42\u6761\u76ee\u5206\u914d\u5177\u4f53\u7684\u6545\u4e8b\u70b9\u503c\uff0c\u800c\u662f\u9762\u4e34\u6210\u5bf9\u7684\u9700\u6c42\u6761\u76ee\uff0c\u5e76\u6307\u51fa\u54ea\u4e2a\u6761\u76ee\u9700\u8981\u66f4\u591a\u7684\u4f30\u7b97\u5de5\u4f5c\u91cf\u3002\u5229\u7528\u8fd9\u4e9b\u6bd4\u8f83\u5224\u65ad\uff0c\u53ef\u4ee5\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u9884\u6d4b\u6545\u4e8b\u70b9\u4f30\u7b97\u3002", "result": "\u7814\u7a76\u4f7f\u7528\u5305\u542b16\u4e2a\u9879\u76ee\u300123,313\u4e2a\u4eba\u5de5\u4f30\u7b97\u7684\u6570\u636e\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4ece\u6bd4\u8f83\u5224\u65ad\u4e2d\u5b66\u4e60\u5230\u7684\u6a21\u578b\u4e0e\u4ece\u771f\u5b9e\u6545\u4e8b\u70b9\u4e2d\u5b66\u4e60\u5230\u7684\u56de\u5f52\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u9884\u6d4b\u7684Spearman\u79e9\u76f8\u5173\u7cfb\u6570\u4e0a\u5e73\u5747\u8fbe\u52300.34\uff0c\u6027\u80fd\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6bd4\u8f83\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6821\u51c6\u9879\u76ee\u7279\u5b9a\u7684\u6545\u4e8b\u70b9\u9884\u6d4b\u6a21\u578b\uff0c\u65e8\u5728\u7b80\u5316\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6545\u4e8b\u70b9\u4f30\u7b97\u3002"}}
{"id": "2507.15853", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15853", "abs": "https://arxiv.org/abs/2507.15853", "authors": ["Shuwen Sun", "Pablo Jarillo-Herrero"], "title": "Optimized Fabrication Procedure for High-Quality Graphene-based Moir\u00e9 Superlattice Devices", "comment": "28 pages, 8 figures; for associated video demonstration, see\n  https://www.jove.com/video/68230", "summary": "Moir\\'e superlattices constitute a versatile platform to investigate emergent\nphenomena arising from the interplay of strong correlations and topology, while\noffering flexible in situ tunability. However, the fabrication of such moir\\'e\nsuperlattices is challenging. It is difficult to achieve highly uniform devices\nwith a precise twist angle because of the unintentional introduction of\nheterostrain, twist angle disorder, and angle/lattice relaxation during the\nnanofabrication process. This article introduces an optimized,\nexperience-informed protocol for fabricating high-quality graphene-based\nmoir\\'e superlattice devices, focusing on a modified dry transfer technique.\nThe transfer process is performed in a highly tunable, custom-built transfer\nsetup that enables precise position, angle, and temperature control. By\ncombining rigorous flake selection criteria, pre-cleaned bubble-free bottom\ngates, and graphene laser ablation, the moir\\'e superlattice is constructed by\ndeliberately overlaying twisted graphene flakes at a submicron speed at room\ntemperature. Through precise control of the transfer process, the resulting\ngraphene moir\\'e superlattice devices exhibit high uniformity and desired twist\nangles. This optimized protocol addresses existing challenges in the\nfabrication of graphene-based moir\\'e superlattice devices and paves the way\nfor further advances in the rapidly evolving field of moir\\'e materials.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5e72\u8f6c\u79fb\u6280\u672f\uff0c\u7528\u4e8e\u5236\u5907\u9ad8\u8d28\u91cf\u3001\u5747\u5300\u7684\u77f3\u58a8\u70ef\u57fa\u9b54\u5c14\u8d85\u6676\u683c\u5668\u4ef6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5236\u5907\u65b9\u6cd5\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u5236\u5907\u9ad8\u8d28\u91cf\u3001\u5177\u6709\u7cbe\u786e\u626d\u8f6c\u89d2\u7684\u9b54\u5c14\u8d85\u6676\u683c\u5668\u4ef6\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5728\u7eb3\u7c73\u5236\u9020\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u5f15\u5165\u975e\u9884\u671f\u7684\u5e94\u53d8\u3001\u626d\u8f6c\u89d2\u65e0\u5e8f\u4ee5\u53ca\u89d2\u5ea6/\u6676\u683c\u5f1b\u8c6b\u3002\u9b54\u5c14\u8d85\u6676\u683c\u4e3a\u7814\u7a76\u5f3a\u5173\u8054\u548c\u62d3\u6251\u5b66\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u7684\u6d8c\u73b0\u73b0\u8c61\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u529f\u80fd\u7684\u5e73\u53f0\uff0c\u5e76\u5177\u6709\u7075\u6d3b\u7684\u539f\u4f4d\u8c03\u8c10\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u3001\u57fa\u4e8e\u7ecf\u9a8c\u7684\u77f3\u58a8\u70ef\u57fa\u9b54\u5c14\u8d85\u6676\u683c\u5668\u4ef6\u5236\u5907\u65b9\u6848\uff0c\u91cd\u70b9\u662f\u6539\u8fdb\u7684\u5e72\u8f6c\u79fb\u6280\u672f\u3002\u8f6c\u79fb\u8fc7\u7a0b\u5728\u4e00\u4e2a\u53ef\u9ad8\u5ea6\u8c03\u8c10\u3001\u5b9a\u5236\u7684\u8f6c\u79fb\u88c5\u7f6e\u4e2d\u8fdb\u884c\uff0c\u8be5\u88c5\u7f6e\u80fd\u591f\u7cbe\u786e\u63a7\u5236\u4f4d\u7f6e\u3001\u89d2\u5ea6\u548c\u6e29\u5ea6\u3002\u901a\u8fc7\u4e25\u683c\u7684\u8584\u7247\u9009\u62e9\u6807\u51c6\u3001\u9884\u5148\u6e05\u6d01\u7684\u65e0\u6c14\u6ce1\u6805\u6781\u4ee5\u53ca\u77f3\u58a8\u70ef\u6fc0\u5149\u70e7\u8680\uff0c\u5728\u5ba4\u6e29\u4e0b\u4ee5\u4e9a\u5fae\u7c73\u901f\u5ea6\u7cbe\u786e\u53e0\u52a0\u626d\u8f6c\u7684\u77f3\u58a8\u70ef\u8584\u7247\u6765\u6784\u5efa\u9b54\u5c14\u8d85\u6676\u683c\u3002", "result": "\u901a\u8fc7\u7cbe\u786e\u63a7\u5236\u8f6c\u79fb\u8fc7\u7a0b\uff0c\u6240\u5f97\u77f3\u58a8\u70ef\u9b54\u5c14\u8d85\u6676\u683c\u5668\u4ef6\u8868\u73b0\u51fa\u9ad8\u5ea6\u7684\u5747\u5300\u6027\u548c\u671f\u671b\u7684\u626d\u8f6c\u89d2\u3002", "conclusion": "\u8be5\u4f18\u5316\u65b9\u6848\u89e3\u51b3\u4e86\u73b0\u6709\u77f3\u58a8\u70ef\u57fa\u9b54\u5c14\u8d85\u6676\u683c\u5668\u4ef6\u5236\u5907\u4e2d\u7684\u6311\u6218\uff0c\u6709\u671b\u63a8\u52a8\u9b54\u5c14\u6750\u6599\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.14227", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14227", "abs": "https://arxiv.org/abs/2507.14227", "authors": ["Khoi Do", "Duong Nguyen", "Nam-Khanh Le", "Quoc-Viet Pham", "Binh-Son Hua", "Won-Joo Hwang"], "title": "Domain Generalization via Pareto Optimal Gradient Matching", "comment": null, "summary": "In this study, we address the gradient-based domain generalization problem,\nwhere predictors aim for consistent gradient directions across different\ndomains. Existing methods have two main challenges. First, minimization of\ngradient empirical distance or gradient inner products (GIP) leads to gradient\nfluctuations among domains, thereby hindering straightforward learning. Second,\nthe direct application of gradient learning to the joint loss function can\nincur high computation overheads due to second-order derivative approximation.\nTo tackle these challenges, we propose a new Pareto Optimality Gradient\nMatching (POGM) method. In contrast to existing methods that add gradient\nmatching as regularization, we leverage gradient trajectories as collected data\nand apply independent training at the meta-learner. In the meta-update, we\nmaximize GIP while limiting the learned gradient from deviating too far from\nthe empirical risk minimization gradient trajectory. By doing so, the aggregate\ngradient can incorporate knowledge from all domains without suffering gradient\nfluctuation towards any particular domain. Experimental evaluations on datasets\nfrom DomainBed demonstrate competitive results yielded by POGM against other\nbaselines while achieving computational efficiency.", "AI": {"tldr": "\u63d0\u51faPOGM\u65b9\u6cd5\u89e3\u51b3\u68af\u5ea6\u4e0b\u964d\u7684\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5e15\u7d2f\u6258\u6700\u4f18\u68af\u5ea6\u5339\u914d\u5b9e\u73b0\u8de8\u57df\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u4e00\u662f\u68af\u5ea6\u7ecf\u9a8c\u8ddd\u79bb\u6216\u68af\u5ea6\u7684\u5185\u79ef\uff08GIP\uff09\u6700\u5c0f\u5316\u4f1a\u5bfc\u81f4\u8de8\u57df\u68af\u5ea6\u6ce2\u52a8\uff0c\u4e8c\u662f\u5c06\u68af\u5ea6\u5b66\u4e60\u76f4\u63a5\u5e94\u7528\u4e8e\u8054\u5408\u635f\u5931\u51fd\u6570\u4f1a\u56e0\u4e8c\u9636\u5bfc\u6570\u8fd1\u4f3c\u800c\u4ea7\u751f\u9ad8\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u68af\u5ea6\u5339\u914d\uff08POGM\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u68af\u5ea6\u8f68\u8ff9\u4f5c\u4e3a\u6536\u96c6\u7684\u6570\u636e\uff0c\u5e76\u5728\u5143\u5b66\u4e60\u5668\u4e2d\u8fdb\u884c\u72ec\u7acb\u8bad\u7ec3\u3002\u5728\u5143\u66f4\u65b0\u4e2d\uff0c\u901a\u8fc7\u6700\u5927\u5316\u68af\u5ea6\u5185\u79ef\uff08GIP\uff09\u5e76\u9650\u5236\u5b66\u4e60\u5230\u7684\u68af\u5ea6\u4e0d\u504f\u79bb\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u68af\u5ea6\u8f68\u8ff9\u592a\u8fdc\uff0c\u6765\u89e3\u51b3\u68af\u5ea6\u6ce2\u52a8\u548c\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002", "result": "POGM\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u8de8\u57df\u68af\u5ea6\u7684\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u5177\u6709\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "POGM\u65b9\u6cd5\u5728DomainBed\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u7ed3\u679c\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\u3002"}}
{"id": "2507.14710", "categories": ["cond-mat.mtrl-sci", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.14710", "abs": "https://arxiv.org/abs/2507.14710", "authors": ["Thomas J. Hicken", "Oliver Amin", "Alfred Dal Din", "J. Hugo Dil", "Dominik Kriegner", "Hubertus Luetkens", "Helena Reichlov\u00e1", "Zaher Salman", "Kl\u00e1ra Uhl\u00ed\u0159ov\u00e1", "Peter Wadley", "Juraj Krempask\u00fd", "Jonas A. Krieger"], "title": "Anomalous temperature dependence of local magnetic fields in altermagnetic MnTe", "comment": null, "summary": "Altermagnets are a novel type of magnetic system that has a spin-polarised\nelectric band structure in the absence of a net magnetic moment, leading to\nexciting prospects in potential device applications. Hexagonal MnTe, a\nprototypical altermagnet, has arguably shown the most properties consistent\nwith theoretical predictions, including an anomalous Hall effect despite no net\nmagnetisation, and strong altermagnet-induced spin splitting in the electronic\nband structure. Here we present muon-spin spectroscopy measurements of a single\ncrystal of MnTe. Below room temperature we observe pronounced anomalies in the\nmuon-spin depolarisation, as well as the onset of a second, non-proportional\ninternal field in the absence of an applied field. These findings point to a\nchange in the magnetic structure around $T\\simeq250$ K, which coincides with\nother changes in reported properties, such as transport.", "AI": {"tldr": "MnTe\u6676\u4f53\u5728250K\u4ee5\u4e0b\u78c1\u7ed3\u6784\u53d1\u751f\u53d8\u5316\u3002", "motivation": "Altermagnets\uff08\u5305\u62ecMnTe\uff09\u5177\u6709\u65e0\u51c0\u78c1\u77e9\u4f46\u5177\u6709\u81ea\u65cb\u6781\u5316\u80fd\u5e26\u7ed3\u6784\u7684\u7279\u70b9\uff0c\u5728\u5668\u4ef6\u5e94\u7528\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u7406\u89e3MnTe\u7684\u78c1\u6027\uff0c\u672c\u7814\u7a76\u8fdb\u884c\u4e86\u03bcSR\u6d4b\u91cf\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u03bcSR\uff08muon-spin spectroscopy\uff09\u6280\u672f\u6d4b\u91cf\u4e86MnTe\u5355\u6676\u3002", "result": "\u5728\u5ba4\u6e29\u4ee5\u4e0b\uff0c\u89c2\u5bdf\u5230\u03bcSR\u4fe1\u53f7\u7684\u660e\u663e\u5f02\u5e38\u548c\u975e\u6bd4\u4f8b\u5185\u573a\u7684\u51fa\u73b0\uff0c\u8868\u660e\u5728250K\u5de6\u53f3\u53d1\u751f\u4e86\u78c1\u7ed3\u6784\u53d8\u5316\u3002", "conclusion": "MnTe\u6676\u4f53\u5728250K\u4ee5\u4e0b\u51fa\u73b0\u663e\u8457\u7684\u78c1\u7ed3\u6784\u53d8\u5316\uff0c\u8868\u73b0\u4e3a\u03bcSR\u4fe1\u53f7\u7684\u5f02\u5e38\u548c\u975e\u6bd4\u4f8b\u5185\u573a\u7684\u51fa\u73b0\uff0c\u8fd9\u4e0e\u4e4b\u524d\u62a5\u9053\u7684\u8f93\u8fd0\u6027\u8d28\u53d8\u5316\u7b49\u73b0\u8c61\u4e00\u81f4\u3002"}}
{"id": "2507.15047", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.15047", "abs": "https://arxiv.org/abs/2507.15047", "authors": ["Michelangelo Bin", "David Angeli"], "title": "On an Abstraction of Lyapunov and Lagrange Stability", "comment": null, "summary": "This paper studies a set-theoretic generalization of Lyapunov and Lagrange\nstability for abstract systems described by set-valued maps. Lyapunov stability\nis characterized as the property of inversely mapping filters to filters,\nLagrange stability as that of mapping ideals to ideals. These abstract\ndefinitions unveil a deep duality between the two stability notions, enable a\ndefinition of global stability for abstract systems, and yield an agile\ngeneralization of the stability theorems for basic series, parallel, and\nfeedback interconnections, including a small-gain theorem. Moreover, it is\nshown that Lagrange stability is abstractly identical to other properties of\ninterest in control theory, such as safety and positivity, whose preservation\nunder interconnections can be thus studied owing to the developed stability\nresults.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14672", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2507.14672", "abs": "https://arxiv.org/abs/2507.14672", "authors": ["Herve Zwirn"], "title": "Are Events Absolute?", "comment": null, "summary": "The Wigner's Friend thought experiment stands as one of the most\nintellectually provocative and challenging conceptual puzzles in quantum\nmechanics. It compels us to confront profound questions concerning the\nfundamental nature of reality, the very act of observation, and the possible\nrole that consciousness might play within the quantum measurement process. This\narticle gives a general presentation, beginning with Eugene Wigner's seminal\nproposal of the original thought experiment. In this paper, we explore its\ninitial implications, which shook the foundations of classical physics, and\nthen progress to an examination of the recent theoretical advancements and the\ningenious extended versions of the experiment. The recent versions seem to\nimply that it is no more possible to consider events as absolute.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7ef4\u683c\u7eb3\u7684\u670b\u53cb\u601d\u60f3\u5b9e\u9a8c\uff0c\u4e00\u4e2a\u6311\u6218\u91cf\u5b50\u529b\u5b66\u57fa\u7840\u7684\u8457\u540d\u601d\u60f3\u5b9e\u9a8c\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u8fd1\u671f\u53d1\u5c55\uff0c\u6697\u793a\u4e8b\u4ef6\u7684\u7edd\u5bf9\u6027\u5df2\u4e0d\u590d\u5b58\u5728\u3002", "motivation": "\u8be5\u8bba\u6587\u65e8\u5728\u6df1\u5165\u63a2\u8ba8\u7ef4\u683c\u7eb3\u7684\u670b\u53cb\u601d\u60f3\u5b9e\u9a8c\uff0c\u8be5\u5b9e\u9a8c\u5bf9\u91cf\u5b50\u529b\u5b66\u63d0\u51fa\u4e86\u6df1\u523b\u7684\u6311\u6218\uff0c\u5e76\u4fc3\u4f7f\u4eba\u4eec\u601d\u8003\u73b0\u5b9e\u7684\u672c\u8d28\u3001\u89c2\u5bdf\u884c\u4e3a\u4ee5\u53ca\u610f\u8bc6\u5728\u91cf\u5b50\u6d4b\u91cf\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5bf9\u7ef4\u683c\u7eb3\u7684\u521d\u59cb\u601d\u60f3\u5b9e\u9a8c\u53ca\u5176\u8fd1\u671f\u7406\u8bba\u8fdb\u5c55\u548c\u6269\u5c55\u7248\u672c\u8fdb\u884c\u4e86\u666e\u904d\u7684\u4ecb\u7ecd\u548c\u5ba1\u89c6\u3002", "result": "\u8fd1\u671f\u7248\u672c\u7684\u5b9e\u9a8c\u4f3c\u4e4e\u610f\u5473\u7740\u4e8b\u4ef6\u4e0d\u518d\u53ef\u80fd\u88ab\u89c6\u4e3a\u7edd\u5bf9\u7684\u3002", "conclusion": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u7ef4\u683c\u7eb3\u7684\u670b\u53cb\u601d\u60f3\u5b9e\u9a8c\u7684\u8fd1\u671f\u7406\u8bba\u8fdb\u5c55\u548c\u6269\u5c55\u7248\u672c\uff0c\u6697\u793a\u4e8b\u4ef6\u4e0d\u518d\u662f\u7edd\u5bf9\u7684\u3002"}}
{"id": "2507.14374", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14374", "abs": "https://arxiv.org/abs/2507.14374", "authors": ["Sinchani Chakraborty", "Sudeshna Sarkar", "Pawan Goyal"], "title": "Error-Aware Curriculum Learning for Biomedical Relation Classification", "comment": "16 pages, 2 figures", "summary": "Relation Classification (RC) in biomedical texts is essential for\nconstructing knowledge graphs and enabling applications such as drug\nrepurposing and clinical decision-making. We propose an error-aware\nteacher--student framework that improves RC through structured guidance from a\nlarge language model (GPT-4o). Prediction failures from a baseline student\nmodel are analyzed by the teacher to classify error types, assign difficulty\nscores, and generate targeted remediations, including sentence rewrites and\nsuggestions for KG-based enrichment. These enriched annotations are used to\ntrain a first student model via instruction tuning. This model then annotates a\nbroader dataset with difficulty scores and remediation-enhanced inputs. A\nsecond student is subsequently trained via curriculum learning on this dataset,\nordered by difficulty, to promote robust and progressive learning. We also\nconstruct a heterogeneous biomedical knowledge graph from PubMed abstracts to\nsupport context-aware RC. Our approach achieves new state-of-the-art\nperformance on 4 of 5 PPI datasets and the DDI dataset, while remaining\ncompetitive on ChemProt.", "AI": {"tldr": "\u901a\u8fc7\u4e00\u4e2a\u9519\u8bef\u611f\u77e5\u7684\u5e08\u751f\u6846\u67b6\uff0c\u5229\u7528GPT-4o\u8fdb\u884c\u6307\u5bfc\uff0c\u6539\u8fdb\u4e86\u751f\u7269\u533b\u5b66\u6587\u672c\u4e2d\u7684\u5173\u7cfb\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u5173\u7cfb\u5206\u7c7b\uff08RC\uff09\u5728\u751f\u7269\u533b\u5b66\u6587\u672c\u4e2d\u5bf9\u4e8e\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u548c\u652f\u6301\u836f\u7269\u518d\u5229\u7528\u3001\u4e34\u5e8a\u51b3\u7b56\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u9519\u8bef\u611f\u77e5\u7684\u5e08\u751f\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u8fdb\u884c\u7ed3\u6784\u5316\u6307\u5bfc\uff0c\u901a\u8fc7\u5206\u6790\u57fa\u7ebf\u5b66\u751f\u6a21\u578b\u7684\u9884\u6d4b\u5931\u8d25\u6765\u5206\u7c7b\u9519\u8bef\u7c7b\u578b\u3001\u5206\u914d\u96be\u5ea6\u5206\u6570\u5e76\u751f\u6210\u9488\u5bf9\u6027\u7684\u8865\u6551\u63aa\u65bd\uff08\u5982\u53e5\u5b50\u6539\u5199\u548c\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u5efa\u8bae\uff09\u3002\u8fd9\u4e9b\u589e\u5f3a\u7684\u6807\u6ce8\u7528\u4e8e\u901a\u8fc7\u6307\u4ee4\u8c03\u4f18\u6765\u8bad\u7ec3\u7b2c\u4e00\u4e2a\u5b66\u751f\u6a21\u578b\uff0c\u7136\u540e\u8be5\u6a21\u578b\u7528\u96be\u5ea6\u5206\u6570\u548c\u8865\u6551\u63aa\u65bd\u589e\u5f3a\u7684\u8f93\u5165\u6765\u6807\u6ce8\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u96c6\u3002\u63a5\u7740\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u5728\u6309\u96be\u5ea6\u6392\u5e8f\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7b2c\u4e8c\u4e2a\u5b66\u751f\u6a21\u578b\u3002\u8fd8\u4ecePubMed\u6458\u8981\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u5f02\u6784\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u4ee5\u652f\u6301\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5173\u7cfb\u5206\u7c7b\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u6307\u5bfc\u6539\u8fdb\u4e86\u5173\u7cfb\u5206\u7c7b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u57285\u4e2aPPI\u6570\u636e\u96c6\u4e2d\u76844\u4e2a\u548cDDI\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728ChemProt\u6570\u636e\u96c6\u4e0a\u4e5f\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u3002"}}
{"id": "2507.14163", "categories": ["eess.SP", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14163", "abs": "https://arxiv.org/abs/2507.14163", "authors": ["Renxiang Qiu", "Raghavendra Selvan"], "title": "UniPhyNet: A Unified Network For Multimodal Physiological Raw Signal Classification", "comment": "Accepted to be presented at the 35th IEEE International Workshop on\n  Machine Learning for Signal Processing (IEEE MLSP 2025). Source code\n  available at https://github.com/HughYau/UniPhyNet", "summary": "We present UniPhyNet, a novel neural network architecture to classify\ncognitive load using multimodal physiological data -- specifically EEG, ECG and\nEDA signals -- without the explicit need for extracting hand-crafted features.\nUniPhyNet integrates multiscale parallel convolutional blocks and ResNet-type\nblocks enhanced with channel block attention module to focus on the informative\nfeatures while a bidirectional gated recurrent unit is used to capture temporal\ndependencies. This architecture processes and combines signals in both unimodal\nand multimodal configurations via intermediate fusion of learned feature maps.\nOn the CL-Drive dataset, UniPhyNet improves raw signal classification accuracy\nfrom 70% to 80% (binary) and 62% to 74% (ternary), outperforming feature-based\nmodels, demonstrating its effectiveness as an end-to-end solution for\nreal-world cognitive state monitoring.", "AI": {"tldr": "UniPhyNet \u662f\u4e00\u79cd\u521b\u65b0\u7684\u7aef\u5230\u7aef\u795e\u7ecf\u7f51\u7edc\uff0c\u53ef\u4ee5\u76f4\u63a5\u5904\u7406 EEG\u3001ECG \u548c EDA \u4fe1\u53f7\uff0c\u65e0\u9700\u624b\u52a8\u7279\u5f81\u5de5\u7a0b\uff0c\u5373\u53ef\u5bf9\u8ba4\u77e5\u8d1f\u8377\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5728 CL-Drive \u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u63d0\u51fa UniPhyNet \u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u65e8\u5728\u65e0\u9700\u663e\u5f0f\u63d0\u53d6\u624b\u5de5\u7279\u5f81\uff0c\u5373\u53ef\u5229\u7528\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff08EEG\u3001ECG \u548c EDA\uff09\u5bf9\u8ba4\u77e5\u8d1f\u8377\u8fdb\u884c\u5206\u7c7b\u3002", "method": "UniPhyNet \u67b6\u6784\u96c6\u6210\u4e86\u591a\u5c3a\u5ea6\u5e76\u884c\u5377\u79ef\u5757\u548c ResNet \u7c7b\u578b\u5757\uff08\u901a\u8fc7\u901a\u9053\u5757\u6ce8\u610f\u529b\u6a21\u5757\u589e\u5f3a\uff09\uff0c\u4ee5\u5173\u6ce8\u4fe1\u606f\u7279\u5f81\uff0c\u540c\u65f6\u5229\u7528\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\u6765\u6355\u83b7\u65f6\u95f4\u4f9d\u8d56\u6027\u3002\u8be5\u67b6\u6784\u901a\u8fc7\u5b66\u4e60\u5230\u7684\u7279\u5f81\u56fe\u7684\u4e2d\u95f4\u878d\u5408\uff0c\u5904\u7406\u548c\u7ec4\u5408\u5355\u5cf0\u548c\u591a\u5cf0\u914d\u7f6e\u4e2d\u7684\u4fe1\u53f7\u3002", "result": "UniPhyNet \u5728 CL-Drive \u6570\u636e\u96c6\u4e0a\uff0c\u5c06\u539f\u59cb\u4fe1\u53f7\u5206\u7c7b\u51c6\u786e\u7387\u4ece 70% \u63d0\u9ad8\u5230 80%\uff08\u4e8c\u5143\u5206\u7c7b\uff09\uff0c\u5e76\u5c06\u51c6\u786e\u7387\u4ece 62% \u63d0\u9ad8\u5230 74%\uff08\u4e09\u5143\u5206\u7c7b\uff09\uff0c\u4f18\u4e8e\u57fa\u4e8e\u7279\u5f81\u7684\u6a21\u578b\u3002", "conclusion": "UniPhyNet \u662f\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff08EEG\u3001ECG \u548c EDA\uff09\u5bf9\u8ba4\u77e5\u8d1f\u8377\u8fdb\u884c\u5206\u7c7b\uff0c\u65e0\u9700\u624b\u52a8\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u4e14\u5728 CL-Drive \u6570\u636e\u96c6\u4e0a\uff0c\u5c06\u539f\u59cb\u4fe1\u53f7\u5206\u7c7b\u51c6\u786e\u7387\u4ece 70% \u63d0\u9ad8\u5230 80%\uff08\u4e8c\u5143\u5206\u7c7b\uff09\u548c\u4ece 62% \u63d0\u9ad8\u5230 74%\uff08\u4e09\u5143\u5206\u7c7b\uff09\uff0c\u4f18\u4e8e\u57fa\u4e8e\u7279\u5f81\u7684\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u5b9e\u65f6\u8ba4\u77e5\u72b6\u6001\u76d1\u6d4b\u7684\u6709\u6548\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14967", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14967", "abs": "https://arxiv.org/abs/2507.14967", "authors": ["Pratik Ingle", "Kasper St\u00f8y", "Andres Fai\u00f1a"], "title": "Heterogeneous object manipulation on nonlinear soft surface through linear controller", "comment": "8 pages, 3 figures", "summary": "Manipulation surfaces indirectly control and reposition objects by actively\nmodifying their shape or properties rather than directly gripping objects.\nThese surfaces, equipped with dense actuator arrays, generate dynamic\ndeformations. However, a high-density actuator array introduces considerable\ncomplexity due to increased degrees of freedom (DOF), complicating control\ntasks. High DOF restrict the implementation and utilization of manipulation\nsurfaces in real-world applications as the maintenance and control of such\nsystems exponentially increase with array/surface size. Learning-based control\napproaches may ease the control complexity, but they require extensive training\nsamples and struggle to generalize for heterogeneous objects. In this study, we\nintroduce a simple, precise and robust PID-based linear close-loop feedback\ncontrol strategy for heterogeneous object manipulation on MANTA-RAY\n(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation\ndensity). Our approach employs a geometric transformation-driven PID\ncontroller, directly mapping tilt angle control outputs(1D/2D) to actuator\ncommands to eliminate the need for extensive black-box training. We validate\nthe proposed method through simulations and experiments on a physical system,\nsuccessfully manipulating objects with diverse geometries, weights and\ntextures, including fragile objects like eggs and apples. The outcomes\ndemonstrate that our approach is highly generalized and offers a practical and\nreliable solution for object manipulation on soft robotic manipulation,\nfacilitating real-world implementation without prohibitive training demands.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e PID \u7684\u63a7\u5236\u7b56\u7565\uff0c\u7528\u4e8e\u5728 MANTA-RAY\uff08\u4e00\u79cd\u9a71\u52a8\u5bc6\u5ea6\u964d\u4f4e\u7684\u81ea\u9002\u5e94\u975e\u521a\u6027\u7eba\u7ec7\u9a71\u52a8\u64cd\u7eb5\u5668\uff09\u4e0a\u64cd\u7eb5\u5f02\u6784\u7269\u4f53\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u503e\u659c\u89d2\u5ea6\u63a7\u5236\u8f93\u51fa\u76f4\u63a5\u6620\u5c04\u5230\u6267\u884c\u5668\u547d\u4ee4\u6765\u7b80\u5316\u63a7\u5236\uff0c\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\uff0c\u5e76\u5df2\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u9ad8\u5bc6\u5ea6\u9a71\u52a8\u5668\u9635\u5217\u4f1a\u5e26\u6765\u76f8\u5f53\u5927\u7684\u590d\u6742\u6027\uff0c\u5e76\u9650\u5236\u4e86\u64cd\u7eb5\u9762\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5e94\u7528\u548c\u5229\u7528\uff0c\u56e0\u4e3a\u968f\u7740\u9635\u5217/\u8868\u9762\u5c3a\u5bf8\u7684\u589e\u52a0\uff0c\u7cfb\u7edf\u7684\u7ef4\u62a4\u548c\u63a7\u5236\u5448\u6307\u6570\u7ea7\u589e\u957f\u3002\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u65b9\u6cd5\u53ef\u80fd\u6709\u52a9\u4e8e\u7b80\u5316\u63a7\u5236\u590d\u6742\u6027\uff0c\u4f46\u5b83\u4eec\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u5e76\u4e14\u96be\u4ee5\u6cdb\u5316\u5230\u5f02\u6784\u7269\u4f53\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e PID \u7684\u7ebf\u6027\u95ed\u73af\u53cd\u9988\u63a7\u5236\u7b56\u7565\uff0c\u91c7\u7528\u51e0\u4f55\u53d8\u6362\u9a71\u52a8\u7684 PID \u63a7\u5236\u5668\uff0c\u5c06\u503e\u659c\u89d2\u5ea6\u63a7\u5236\u8f93\u51fa\uff081D/2D\uff09\u76f4\u63a5\u6620\u5c04\u5230\u6267\u884c\u5668\u547d\u4ee4\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u7269\u7406\u7cfb\u7edf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u6210\u529f\u64cd\u7eb5\u4e86\u5177\u6709\u4e0d\u540c\u51e0\u4f55\u5f62\u72b6\u3001\u91cd\u91cf\u548c\u7eb9\u7406\u7684\u7269\u4f53\uff0c\u5305\u62ec\u6613\u788e\u7269\u4f53\uff08\u5982\u9e21\u86cb\u548c\u82f9\u679c\uff09\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u7684\u6cdb\u5316\u6027\uff0c\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u64cd\u7eb5\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7 PID \u63a7\u5236\u7b56\u7565\u5b9e\u73b0\u4e86\u5bf9\u5f02\u6784\u7269\u4f53\u7684\u64cd\u7eb5\uff0c\u65e0\u9700\u5927\u91cf\u7684\u9ed1\u76d2\u8bad\u7ec3\uff0c\u53ef\u7528\u4e8e\u8f6f\u4f53\u673a\u5668\u4eba\u64cd\u7eb5\uff0c\u4e14\u6613\u4e8e\u5b9e\u73b0\u3002"}}
{"id": "2507.14497", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14497", "abs": "https://arxiv.org/abs/2507.14497", "authors": ["Weimin Lyu", "Qingqiao Hu", "Kehan Qi", "Zhan Shi", "Wentao Huang", "Saumya Gupta", "Chao Chen"], "title": "Efficient Whole Slide Pathology VQA via Token Compression", "comment": null, "summary": "Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000\npixels, posing significant challenges for multimodal large language model\n(MLLM) due to long context length and high computational demands. Previous\nmethods typically focus on patch-level analysis or slide-level classification\nusing CLIP-based models with multi-instance learning, but they lack the\ngenerative capabilities needed for visual question answering (VQA). More recent\nMLLM-based approaches address VQA by feeding thousands of patch tokens directly\ninto the language model, which leads to excessive resource consumption. To\naddress these limitations, we propose Token Compression Pathology LLaVA\n(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token\ncompression. TCP-LLaVA introduces a set of trainable compression tokens that\naggregate visual and textual information through a modality compression module,\ninspired by the [CLS] token mechanism in BERT. Only the compressed tokens are\nforwarded to the LLM for answer generation, significantly reducing input length\nand computational cost. Experiments on ten TCGA tumor subtypes show that\nTCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing\ntraining resource consumption by a substantial margin.", "AI": {"tldr": "TCP-LLaVA \u900f\u904e token \u58d3\u7e2e\u6280\u8853\uff0c\u6709\u6548\u89e3\u6c7a\u4e86\u75c5\u7406\u5b78\u5168\u8f09\u73bb\u7247\u5716\u50cf\u5206\u6790\u7684\u9577\u4e0a\u4e0b\u6587\u548c\u8a08\u7b97\u9700\u6c42\u554f\u984c\uff0c\u9996\u6b21\u5be6\u73fe\u4e86 WSI \u7684 VQA\uff0c\u4e26\u5728\u6e96\u78ba\u6027\u548c\u8cc7\u6e90\u6d88\u8017\u65b9\u9762\u5747\u53d6\u5f97\u986f\u8457\u6210\u6548\u3002", "motivation": "\u89e3\u6c7a\u4e86\u5168\u8f09\u73bb\u7247\u5716\u50cf\uff08WSIs\uff09\u5728\u75c5\u7406\u5b78\u5206\u6790\u4e2d\uff0c\u7531\u65bc\u5176\u5de8\u5927\u7684\u5c3a\u5bf8\uff08\u9ad8\u9054 10,000 x 10,000 \u50cf\u7d20\uff09\u800c\u5c0d\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08MLLM\uff09\u9020\u6210\u7684\u9577\u4e0a\u4e0b\u6587\u548c\u9ad8\u8a08\u7b97\u9700\u6c42\u6311\u6230\uff0c\u4ee5\u53ca\u73fe\u6709\u65b9\u6cd5\u5728 VQA \u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TCP-LLaVA \u7684\u65b0 MLLM \u67b6\u6784\uff0c\u5229\u7528\u53ef\u8bad\u7ec3\u7684\u538b\u7f29 token \u805a\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u6a21\u6001\u538b\u7f29\u6a21\u5757\uff08\u53d7 BERT \u7684 [CLS] token \u673a\u5236\u542f\u53d1\uff09\u5c06\u538b\u7f29\u540e\u7684 token \u8f93\u5165 LLM \u4ee5\u751f\u6210\u7b54\u6848\u3002", "result": "\u5728\u5341\u7a2e TCGA \u816b\u7624\u4e9e\u578b\u7684\u5be6\u9a57\u4e2d\uff0cTCP-LLaVA \u5728 VQA \u6e96\u78ba\u6027\u65b9\u9762\u512a\u65bc\u73fe\u6709\u7684 MLLM \u65b9\u6cd5\uff0c\u4e26\u5927\u5e45\u6e1b\u5c11\u4e86\u8a13\u7df4\u8cc7\u6e90\u7684\u6d88\u8017\u3002", "conclusion": "TCP-LLaVA \u900f\u904e token \u58d3\u7e2e\u6280\u8853\uff0c\u6210\u529f\u5be6\u73fe\u4e86 WSI \u7684\u8996\u89ba\u554f\u7b54\uff08VQA\uff09\uff0c\u5728\u6e96\u78ba\u6027\u65b9\u9762\u8d85\u8d8a\u4e86\u73fe\u6709 MLLM \u65b9\u6cd5\uff0c\u540c\u6642\u986f\u8457\u964d\u4f4e\u4e86\u8a13\u7df4\u8cc7\u6e90\u6d88\u8017\u3002"}}
{"id": "2507.14660", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14660", "abs": "https://arxiv.org/abs/2507.14660", "authors": ["Qibing Ren", "Sitao Xie", "Longxuan Wei", "Zhenfei Yin", "Junchi Yan", "Lizhuang Ma", "Jing Shao"], "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems", "comment": "Code is available at https://github.com/renqibing/RogueAgent", "summary": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.", "AI": {"tldr": "\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u7fa4\u4f53\u53ef\u80fd\u9020\u6210\u4e25\u91cd\u5371\u5bb3\u3002\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u6bd4\u4e2d\u5fc3\u5316\u7cfb\u7edf\u66f4\u80fd\u6709\u6548\u5730\u8fdb\u884c\u6076\u610f\u6d3b\u52a8\uff0c\u5e76\u80fd\u89c4\u907f\u68c0\u6d4b\u3002\u9700\u8981\u65b0\u7684\u5bf9\u7b56\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5174\u8d77\uff0c\u4eba\u4eec\u8d8a\u6765\u8d8a\u62c5\u5fc3\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u7fa4\u4f53\u53ef\u80fd\u9020\u6210\u7c7b\u4f3c\u4e8e\u9009\u4e3e\u6b3a\u8bc8\u548c\u91d1\u878d\u8bc8\u9a97\u7b49\u5927\u89c4\u6a21\u4e8b\u4ef6\u7684\u5371\u5bb3\uff0c\u4f46\u76ee\u524d\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u60c5\u51b5\u4e0b\u7684\u98ce\u9669\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\u6765\u6a21\u62df\u6076\u610f\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5171\u8c0b\uff0c\u8be5\u6846\u67b6\u652f\u6301\u4e2d\u5fc3\u5316\u548c\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u548c\u7535\u5b50\u5546\u52a1\u6b3a\u8bc8\u9886\u57df\u3002", "result": "\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5728\u6267\u884c\u6076\u610f\u884c\u4e3a\u65b9\u9762\u6bd4\u4e2d\u5fc3\u5316\u7cfb\u7edf\u66f4\u6709\u6548\uff0c\u80fd\u591f\u9002\u5e94\u7b56\u7565\u4ee5\u907f\u514d\u68c0\u6d4b\uff0c\u5373\u4f7f\u5728\u5e94\u7528\u4e86\u5185\u5bb9\u6807\u8bb0\u7b49\u4f20\u7edf\u5e72\u9884\u63aa\u65bd\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5728\u6076\u610f\u884c\u4e3a\u65b9\u9762\u6bd4\u4e2d\u5fc3\u5316\u7cfb\u7edf\u66f4\u6709\u6548\uff0c\u5e76\u4e14\u80fd\u591f\u8c03\u6574\u7b56\u7565\u4ee5\u9003\u907f\u68c0\u6d4b\u3002\u6709\u5fc5\u8981\u5f00\u53d1\u66f4\u597d\u7684\u68c0\u6d4b\u7cfb\u7edf\u548c\u5bf9\u7b56\u6765\u5e94\u5bf9\u8fd9\u4e9b\u98ce\u9669\u3002"}}
{"id": "2507.14245", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "cs.CE", "q-bio.BM", "I.6.5; J.3; I.5.4"], "pdf": "https://arxiv.org/pdf/2507.14245", "abs": "https://arxiv.org/abs/2507.14245", "authors": ["Hengjie Yu", "Kenneth A. Dawson", "Haiyun Yang", "Shuya Liu", "Yan Yan", "Yaochu Jin"], "title": "A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions", "comment": "31 pages, 6 figures", "summary": "Unlocking the potential of nanomaterials in medicine and environmental\nscience hinges on understanding their interactions with proteins, a complex\ndecision space where AI is poised to make a transformative impact. However,\nprogress has been hindered by limited datasets and the restricted\ngeneralizability of existing models. Here, we propose NanoPro-3M, the largest\nnanomaterial-protein interaction dataset to date, comprising over 3.2 million\nsamples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,\na foundational model that predicts nanomaterial-protein affinities through\nmultimodal representation learning, demonstrating strong generalization,\nhandling missing features, and unseen nanomaterials or proteins. We show that\nmultimodal modeling significantly outperforms single-modality approaches and\nidentifies key determinants of corona formation. Furthermore, we demonstrate\nits applicability to a range of downstream tasks through zero-shot inference\nand fine-tuning. Together, this work establishes a solid foundation for\nhigh-performance and generalized prediction of nanomaterial-protein interaction\nendpoints, reducing experimental reliance and accelerating various in vitro\napplications.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aNanoPro-3M\u7684\u5927\u578b\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u540d\u4e3aNanoProFormer\u7684\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5229\u7528\u591a\u6a21\u6001\u8868\u5f81\u5b66\u4e60\u6765\u9884\u6d4b\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u4eb2\u548c\u529b\uff0c\u5e76\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u9501\u7eb3\u7c73\u6750\u6599\u5728\u533b\u5b66\u548c\u73af\u5883\u79d1\u5b66\u4e2d\u7684\u6f5c\u529b\uff0c\u7406\u89e3\u5b83\u4eec\u4e0e\u86cb\u767d\u8d28\u7684\u76f8\u4e92\u4f5c\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5b58\u5728\u6570\u636e\u96c6\u6709\u9650\u548c\u6cdb\u5316\u6027\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNanoProFormer\u7684\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u591a\u6a21\u6001\u8868\u5f81\u5b66\u4e60\u6765\u9884\u6d4b\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u4eb2\u548c\u529b\u3002", "result": "NanoPro-3M\u662f\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc7320\u4e07\u4e2a\u6837\u672c\u548c37,000\u4e2a\u72ec\u7279\u7684\u86cb\u767d\u8d28\u3002NanoProFormer\u6a21\u578b\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u7f3a\u5931\u7684\u7279\u5f81\u4ee5\u53ca\u672a\u77e5\u7684\u7eb3\u7c73\u6750\u6599\u6216\u86cb\u767d\u8d28\uff0c\u5e76\u4e14\u5176\u591a\u6a21\u6001\u5efa\u6a21\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6a21\u6001\u7684\u65b9\u6cd5\uff0c\u8fd8\u786e\u5b9a\u4e86\u51a0\u5c42\u5f62\u6210\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9ad8\u6027\u80fd\u3001\u6cdb\u5316\u7684\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u51cf\u5c11\u4e86\u5bf9\u5b9e\u9a8c\u7684\u4f9d\u8d56\uff0c\u5e76\u52a0\u901f\u4e86\u5404\u79cd\u4f53\u5916\u5e94\u7528\u3002"}}
{"id": "2507.14781", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14781", "abs": "https://arxiv.org/abs/2507.14781", "authors": ["Oliver Lin", "Zhiheng Lyu", "Hsu-Chih Ni", "Xiaokang Wang", "Yetong Jia", "Chu-Yun Hwang", "Lehan Yao", "Jian-Min Zuo", "Qian Chen"], "title": "Size-Dependent Lattice Pseudosymmetry for Frustrated Decahedral Nanoparticles", "comment": null, "summary": "Geometric frustration is a widespread phenomenon in physics, materials\nscience, and biology, occurring when the geometry of a system prevents local\ninteractions from being all accommodated. The resulting manifold of nearly\ndegenerate configurations can lead to complex collective behaviors and emergent\npseudosymmetry in diverse systems such as frustrated magnets, mechanical\nmetamaterials, and protein assemblies. In synthetic multi-twinned\nnanomaterials, similar pseudosymmetric features have also been observed and\nmanifest as intrinsic lattice strain. Despite extensive interest in the\nstability of these nanostructures, a fundamental understanding remains limited\ndue to the lack of detailed structural characterization across varying sizes\nand geometries. In this work, we apply four-dimensional scanning transmission\nelectron microscopy strain mapping over a total of 23 decahedral nanoparticles\nwith edge lengths, d, between 20 and 55 nm. From maps of full 2D strain tensor\nat nanometer spatial resolution, we reveal the prevalence of heterogeneity in\ndifferent modes of lattice distortions, which homogenizes and restores symmetry\nwith increasing size. Knowing the particle crystallography, we reveal\ndistinctive spatial patterns of local lattice phase transformation between\nface-centered cubic and body-centered tetragonal symmetries, with a contrast\nbetween particles below and above d of 35 nm. The results suggest a cross-over\nsize of the internal structure occurs, as particles shape transition from\nmodified-Wulff shape favored at nanoscale to faceted, pentagonal bipyramidal\nshape. Ultimately, our 4D-STEM mapping provides new insight to long-standing\nmysteries of this historic system and can be widely applicable to study\nnanocrystalline solids and material phase transformation that are important in\ncatalysis, metallurgy, electronic devices, and energy storage materials.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u75284D-STEM\u6280\u672f\u5206\u6790\u4e86\u7eb3\u7c73\u7c92\u5b50\uff0c\u53d1\u73b0\u5176\u6676\u683c\u7578\u53d8\u968f\u5c3a\u5bf8\u53d8\u5316\uff0c\u5e76\u572835 nm\u5904\u5b58\u5728\u7ed3\u6784\u76f8\u53d8\u70b9\uff0c\u63ed\u793a\u4e86\u7eb3\u7c73\u6750\u6599\u7684\u5c3a\u5bf8\u4f9d\u8d56\u6027\u7ed3\u6784\u7279\u5f81\u3002", "motivation": "\u5c3d\u7ba1\u51e0\u4f55\u53d7\u632b\u73b0\u8c61\u5e7f\u6cdb\u5b58\u5728\u4e8e\u591a\u4e2a\u79d1\u5b66\u9886\u57df\uff0c\u4f46\u5bf9\u4e8e\u5408\u6210\u591a\u91cd\u5b6a\u6676\u7eb3\u7c73\u6750\u6599\u4e2d\u7684\u5185\u5728\u6676\u683c\u5e94\u53d8\u548c\u7ed3\u6784\u7a33\u5b9a\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u5c3a\u5bf8\u548c\u51e0\u4f55\u5f62\u72b6\u4e0b\u7684\u8868\u73b0\uff0c\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7684\u7406\u89e3\u3002", "method": "\u5229\u7528\u56db\u7ef4\u626b\u63cf\u900f\u5c04\u7535\u5b50\u663e\u5fae\u955c\uff084D-STEM\uff09\u5e94\u53d8\u56fe\u8c31\u6280\u672f\uff0c\u5bf923\u4e2a\u4e0d\u540c\u5c3a\u5bf8\uff0820-55 nm\uff09\u7684\u5341 \u0648\u062c\u0647\u4f53\u7eb3\u7c73\u7c92\u5b50\u8fdb\u884c\u5e94\u53d8\u6620\u5c04\uff0c\u4ee5\u7eb3\u7c73\u5c3a\u5ea6\u7684\u7a7a\u95f4\u5206\u8fa8\u7387\u89e3\u6790\u5176\u4e8c\u7ef4\u5e94\u53d8\u5f20\u91cf\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u7eb3\u7c73\u6750\u6599\u5185\u90e8\u6676\u683c\u7578\u53d8\u7684\u5f02\u8d28\u6027\uff0c\u5e76\u89c2\u5bdf\u5230\u7578\u53d8\u968f\u5c3a\u5bf8\u589e\u52a0\u800c\u8d8b\u4e8e\u5747\u5300\u5316\u548c\u5bf9\u79f0\u6027\u6062\u590d\u3002\u5728\u5c0f\u4e8e35 nm\u548c\u5927\u4e8e35 nm\u7684\u7c92\u5b50\u4e2d\uff0c\u53d1\u73b0\u4e86\u9762\u5fc3\u7acb\u65b9\u4e0e\u4f53\u5fc3\u56db\u65b9\u6676\u683c\u5bf9\u79f0\u6027\u4e4b\u95f4\u7684\u7a7a\u95f4\u76f8\u53d8\u6a21\u5f0f\u5dee\u5f02\uff0c\u8fd9\u4e0e\u7c92\u5b50\u5f62\u72b6\u4ece\u7eb3\u7c73\u5c3a\u5ea6\u7684Wulff\u5f62\u72b6\u5411\u6676\u9762\u5316\u7684\u4e94\u91cd\u53cc\u9525\u5f62\u72b6\u7684\u8f6c\u53d8\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc74D-STEM\u5e94\u53d8\u56fe\u8c31\u6280\u672f\uff0c\u63ed\u793a\u4e86\u51e0\u4f55\u53d7\u632b\u7eb3\u7c73\u6750\u6599\u7684\u5185\u90e8\u7ed3\u6784\u7279\u5f81\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u968f\u7740\u5c3a\u5bf8\u7684\u589e\u52a0\uff0c\u7eb3\u7c73\u6750\u6599\u7684\u6676\u683c\u7578\u53d8\u8d8b\u4e8e\u5747\u5300\u5316\u5e76\u6062\u590d\u5bf9\u79f0\u6027\u3002\u7279\u522b\u662f\uff0c\u5f53\u5c3a\u5bf8\u5c0f\u4e8e\u6216\u5927\u4e8e35 nm\u65f6\uff0c\u9762\u5fc3\u7acb\u65b9\u548c\u4f53\u5fc3\u56db\u65b9\u6676\u683c\u5bf9\u79f0\u6027\u4e4b\u95f4\u4f1a\u53d1\u751f\u7a7a\u95f4\u76f8\u53d8\uff0c\u8fd9\u8868\u660e\u6750\u6599\u5185\u90e8\u7ed3\u6784\u5b58\u5728\u4e00\u4e2a\u4ea4\u53c9\u5c3a\u5bf8\u3002\u8fd9\u4e00\u53d1\u73b0\u6709\u52a9\u4e8e\u7406\u89e3\u8be5\u4f53\u7cfb\u7684\u957f\u671f\u672a\u89e3\u4e4b\u8c1c\uff0c\u5e76\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u7814\u7a76\u7eb3\u7c73\u6676\u4f53\u56fa\u4f53\u548c\u6750\u6599\u76f8\u53d8\u3002"}}
{"id": "2507.15093", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15093", "abs": "https://arxiv.org/abs/2507.15093", "authors": ["Lucian Cristian Iacob", "Roland T\u00f3th", "Maarten Schoukens"], "title": "Exact Finite Koopman Embedding of Block-Oriented Polynomial Systems", "comment": "Submitted to SIAM Journal on Applied Dynamical Systems (SIADS)", "summary": "The challenge of finding exact and finite-dimensional Koopman embeddings of\nnonlinear systems has been largely circumvented by employing data-driven\ntechniques to learn models of different complexities (e.g., linear, bilinear,\ninput affine). Although these models may provide good accuracy, selecting the\nmodel structure and dimension is still ad-hoc and it is difficult to quantify\nthe error that is introduced. In contrast to the general trend of data-driven\nlearning, in this paper, we develop a systematic technique for nonlinear\nsystems that produces a finite-dimensional and exact embedding. If the\nnonlinear system is represented as a network of series and parallel linear and\nnonlinear (polynomial) blocks, one can derive an associated Koopman model that\nhas constant state and output matrices and the input influence is polynomial.\nFurthermore, if the linear blocks do not have feedthrough, the Koopman\nrepresentation simplifies to a bilinear model.", "AI": {"tldr": "\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u5b66\u4e60\u7cbe\u786e\u7684Koopman\u5d4c\u5165\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u968f\u610f\u6027\u548c\u91cf\u5316\u8bef\u5dee\u7684\u56f0\u96be\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u6280\u672f\u5728\u5b66\u4e60\u975e\u7ebf\u6027\u7cfb\u7edf\u6a21\u578b\u65f6\uff0c\u6a21\u578b\u7ed3\u6784\u548c\u7ef4\u5ea6\u7684\u9009\u62e9\u5177\u6709\u968f\u610f\u6027\u4e14\u96be\u4ee5\u91cf\u5316\u8bef\u5dee\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u6280\u672f\uff0c\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u751f\u6210\u6709\u9650\u7ef4\u4e14\u7cbe\u786e\u7684Koopman\u5d4c\u5165\u3002", "method": "\u901a\u8fc7\u5c06\u975e\u7ebf\u6027\u7cfb\u7edf\u8868\u793a\u4e3a\u7531\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\uff08\u591a\u9879\u5f0f\uff09\u5757\u7ec4\u6210\u7684\u4e32\u8054/\u5e76\u8054\u7f51\u7edc\uff0c\u63a8\u5bfc\u51fa\u5177\u6709\u6052\u5b9a\u72b6\u6001\u548c\u8f93\u51fa\u77e9\u9635\u7684Koopman\u6a21\u578b\uff0c\u5e76\u5c06\u8f93\u5165\u5f71\u54cd\u5efa\u6a21\u4e3a\u591a\u9879\u5f0f\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff08\u7ebf\u6027\u5757\u65e0\u524d\u9988\uff09\u8fdb\u4e00\u6b65\u7b80\u5316\u4e3a\u53cc\u7ebf\u6027\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u6280\u672f\uff0c\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u751f\u6210\u6709\u9650\u7ef4\u4e14\u7cbe\u786e\u7684Koopman\u5d4c\u5165\u3002\u5f53\u7cfb\u7edf\u7531\u7ebf\u6027\u4e0e\u591a\u9879\u5f0f\u5757\u7ec4\u6210\u65f6\uff0c\u53ef\u5f97\u5230\u5177\u6709\u5e38\u6570\u72b6\u6001\u548c\u8f93\u51fa\u77e9\u9635\u7684\u6a21\u578b\uff0c\u8f93\u5165\u5f71\u54cd\u4e3a\u591a\u9879\u5f0f\uff1b\u82e5\u7ebf\u6027\u5757\u65e0\u524d\u9988\uff0c\u5219\u7b80\u5316\u4e3a\u53cc\u7ebf\u6027\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u6280\u672f\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\uff0c\u80fd\u591f\u751f\u6210\u6709\u9650\u7ef4\u4e14\u7cbe\u786e\u7684Koopman\u5d4c\u5165\u3002\u5982\u679c\u975e\u7ebf\u6027\u7cfb\u7edf\u53ef\u4ee5\u8868\u793a\u4e3a\u4e32\u8054\u548c\u5e76\u8054\u7684\u7ebf\u6027\u53ca\u975e\u7ebf\u6027\uff08\u591a\u9879\u5f0f\uff09\u5757\u7684\u7f51\u7edc\uff0c\u5219\u53ef\u4ee5\u63a8\u5bfc\u51fa\u5177\u6709\u6052\u5b9a\u72b6\u6001\u548c\u8f93\u51fa\u77e9\u9635\u7684\u5173\u8054Koopman\u6a21\u578b\uff0c\u5e76\u4e14\u8f93\u5165\u5f71\u54cd\u662f\u591a\u9879\u5f0f\u7684\u3002\u6b64\u5916\uff0c\u5982\u679c\u7ebf\u6027\u5757\u6ca1\u6709\u524d\u9988\uff0cKoopman\u8868\u793a\u4f1a\u7b80\u5316\u4e3a\u53cc\u7ebf\u6027\u6a21\u578b\u3002"}}
{"id": "2507.14691", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14691", "abs": "https://arxiv.org/abs/2507.14691", "authors": ["Fernando Gago-Encinas", "Christiane P. Koch"], "title": "Scalable modular architecture for universal quantum computation", "comment": "7 pages, 2 figures", "summary": "Universal quantum computing requires the ability to perform every unitary\noperation, i.e., evolution operator controllability. In view of developing\nresource-efficient quantum processing units (QPUs), it is important to\ndetermine how many local controls and qubit-qubit couplings are required for\ncontrollability. Unfortunately, assessing the controllability of large qubit\narrays is a difficult task, due to the exponential scaling of Hilbert space\ndimension. Here we show that it is sufficient to connect two qubit arrays that\nare evolution operator controllable by a single entangling two-qubit gate in\norder to obtain a composite qubit array that is evolution operator\ncontrollable. Our proof provides a template to build up modular QPUs from\nsmaller building blocks with reduced numbers of local controls and couplings.\nWe illustrate the approach with two examples, consisting of 10, respectively\n127 qubits, inspired by IBM quantum processors.", "AI": {"tldr": "\u91cf\u5b50\u8ba1\u7b97\u7684\u53ef\u63a7\u6027\u53ef\u4ee5\u901a\u8fc7\u8fde\u63a5\u8f83\u5c0f\u7684\u53ef\u63a7\u5355\u5143\u6765\u6784\u5efa\u6a21\u5757\u5316QPU\u3002", "motivation": "\u4e3a\u4e86\u5f00\u53d1\u8d44\u6e90\u9ad8\u6548\u7684\u91cf\u5b50\u5904\u7406\u5355\u5143\uff08QPU\uff09\uff0c\u786e\u5b9a\u5b9e\u73b0\u6f14\u5316\u7b97\u5b50\u53ef\u63a7\u6027\u6240\u9700\u7684\u5c40\u90e8\u63a7\u5236\u548c\u6bd4\u7279\u8026\u5408\u7684\u6570\u91cf\u5f88\u91cd\u8981\u3002", "method": "\u8bc1\u660e\u4e86\u53ef\u63a7\u6027\u53ef\u4ee5\u901a\u8fc7\u8fde\u63a5\u8f83\u5c0f\u7684\u3001\u53ef\u63a7\u7684\u91cf\u5b50\u6bd4\u7279\u9635\u5217\u6765\u6784\u5efa\uff0c\u6bcf\u6b21\u8fde\u63a5\u4f7f\u7528\u4e00\u4e2a\u5355\u6bd4\u7279\u95e8\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6784\u5efa\u6a21\u5757\u5316QPU\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4ece\u5177\u6709\u8f83\u5c11\u5c40\u90e8\u63a7\u5236\u548c\u8026\u5408\u7684\u5c0f\u6a21\u5757\u5f00\u59cb\u6784\u5efa\u3002", "conclusion": "\u901a\u8fc7\u8fde\u63a5\u4e24\u4e2a\u53ef\u63a7\u7684\u91cf\u5b50\u6bd4\u7279\u9635\u5217\uff0c\u53ef\u4ee5\u83b7\u5f97\u53ef\u63a7\u7684\u590d\u5408\u91cf\u5b50\u6bd4\u7279\u9635\u5217\u3002"}}
{"id": "2507.14430", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14430", "abs": "https://arxiv.org/abs/2507.14430", "authors": ["Xiaolin Yan", "Yangxing Liu", "Jiazhang Zheng", "Chi Liu", "Mingyu Du", "Caisheng Chen", "Haoyang Liu", "Ming Ding", "Yuan Li", "Qiuping Liao", "Linfeng Li", "Zhili Mei", "Siyu Wan", "Li Li", "Ruyi Zhong", "Jiangling Yu", "Xule Liu", "Huihui Hu", "Jiameng Yue", "Ruohui Cheng", "Qi Yang", "Liangqing Wu", "Ke Zhu", "Chi Zhang", "Chufei Jing", "Yifan Zhou", "Yan Liang", "Dongdong Li", "Zhaohui Wang", "Bin Zhao", "Mingzhou Wu", "Mingzhong Zhou", "Peng Du", "Zuomin Liao", "Chao Dai", "Pengfei Liang", "Xiaoguang Zhu", "Yu Zhang", "Yu Gu", "Kun Pan", "Yuan Wu", "Yanqing Guan", "Shaojing Wu", "Zikang Feng", "Xianze Ma", "Peishan Cheng", "Wenjuan Jiang", "Jing Ba", "Huihao Yu", "Zeping Hu", "Yuan Xu", "Zhiwei Liu", "He Wang", "Zhenguo Lin", "Ming Liu", "Yanhong Meng"], "title": "X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display", "comment": "Technical Report", "summary": "Large language models (LLMs) have recently achieved significant advances in\nreasoning and demonstrated their advantages in solving challenging problems.\nYet, their effectiveness in the semiconductor display industry remains limited\ndue to a lack of domain-specific training and expertise. To bridge this gap, we\npresent X-Intelligence 3.0, the first high-performance reasoning model\nspecifically developed for the semiconductor display industry. This model is\ndesigned to deliver expert-level understanding and reasoning for the industry's\ncomplex challenges. Leveraging a carefully curated industry knowledge base, the\nmodel undergoes supervised fine-tuning and reinforcement learning to enhance\nits reasoning and comprehension capabilities. To further accelerate\ndevelopment, we implemented an automated evaluation framework that simulates\nexpert-level assessments. We also integrated a domain-specific\nretrieval-augmented generation (RAG) mechanism, resulting in notable\nperformance gains on benchmark datasets. Despite its relatively compact size of\n32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B\nacross multiple evaluations. This demonstrates its exceptional efficiency and\nestablishes it as a powerful solution to the longstanding reasoning challenges\nfaced by the semiconductor display industry.", "AI": {"tldr": "X-Intelligence 3.0 \u662f\u9996\u4e2a\u4e13\u4e3a\u534a\u5bfc\u4f53\u663e\u793a\u884c\u4e1a\u5f00\u53d1\u7684\u9ad8\u6027\u80fd\u63a8\u7406\u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u7279\u5b9a\u9886\u57df\u7684\u5fae\u8c03\u548c RAG \u673a\u5236\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u90fd\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u884c\u4e1a\u5185\u7684\u63a8\u7406\u96be\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u534a\u5bfc\u4f53\u663e\u793a\u884c\u4e1a\u4e2d\u56e0\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u548c\u4e13\u4e1a\u77e5\u8bc6\u800c\u6548\u679c\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u7ed3\u5408\u7279\u5b9a\u9886\u57df\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u673a\u5236\u8fdb\u884c\u8bad\u7ec3\uff0c\u540c\u65f6\u5229\u7528\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\u8fdb\u884c\u52a0\u901f\u5f00\u53d1\u3002", "result": "X-Intelligence 3.0 \u5728\u591a\u4e2a\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e SOTA DeepSeek-R1-671B\uff0c\u5c3d\u7ba1\u5176\u53c2\u6570\u91cf\u4ec5\u4e3a 320 \u4ebf\u3002", "conclusion": "X-Intelligence 3.0 \u5728\u534a\u5bfc\u4f53\u663e\u793a\u884c\u4e1a\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6548\u6bd4\u9ad8\uff0c\u89e3\u51b3\u4e86\u8be5\u884c\u4e1a\u957f\u671f\u5b58\u5728\u7684\u63a8\u7406\u6311\u6218\u3002"}}
{"id": "2507.14631", "categories": ["cs.LG", "cs.CG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.14631", "abs": "https://arxiv.org/abs/2507.14631", "authors": ["Daniel Greenhut", "Dan Feldman"], "title": "$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation", "comment": null, "summary": "Given an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the\nclassic $k$-PCA (Principle Component Analysis) approximates the affine\n\\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear\nsubspace that minimizes its sum of squared Euclidean distances\n($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.\nThe \\emph{$k$-subspace median} is the subspace that minimizes its sum of\n(non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their\nmedian. The median subspace is usually more sparse and robust to noise/outliers\nthan the mean, but also much harder to approximate since, unlike the\n$\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.\n  We provide the first polynomial-time deterministic algorithm whose both\nrunning time and approximation factor are not exponential in $k$. More\nprecisely, the multiplicative approximation factor is $\\sqrt{d}$, and the\nrunning time is polynomial in the size of the input. We expect that our\ntechnique would be useful for many other related problems, such as $\\ell_{2,z}$\nnorm of distances for $z\\not \\in \\br{1,2}$, e.g., $z=\\infty$, and handling\noutliers/sparsity.\n  Open code and experimental results on real-world datasets are also provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u80fd\u5728\u5927\u7ea6k\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u503c\uff08\u6bd4k\u7ef4\u5b50\u7a7a\u95f4\u5747\u503c\u66f4\u7a00\u758f\u4e14\u5bf9\u566a\u58f0/\u5f02\u5e38\u503c\u66f4\u9c81\u68d2\uff09\u7684\u8fd1\u4f3c\u503c\uff08\u8fd1\u4f3c\u56e0\u5b50\u4e3a$\\\\\"\text{sqrt(d)}$\uff09\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4e0d\u4f9d\u8d56\u4e8ek\u7684\u6307\u6570\u3002", "motivation": "k\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u503c\u6bd4k\u7ef4\u5b50\u7a7a\u95f4\u5747\u503c\u66f4\u7a00\u758f\u4e14\u5bf9\u566a\u58f0/\u5f02\u5e38\u503c\u66f4\u9c81\u68d2\uff0c\u4f46\u7531\u4e8e\u5176\u975e\u51f8\u6027\uff0c\u8fd1\u4f3c\u8d77\u6765\u66f4\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u786e\u5b9a\u6027\u7b97\u6cd5\u6765\u8fd1\u4f3ck\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u503c\uff0c\u8fd1\u4f3c\u56e0\u5b50\u4e3a$\\\\\"\text{sqrt(d)}$\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u548c\u8fd1\u4f3c\u56e0\u5b50\u5747\u4e0d\u4f9d\u8d56\u4e8ek\u7684\u6307\u6570\uff0c\u8fd1\u4f3c\u56e0\u5b50\u4e3a$\\\\\"\text{sqrt(d)}$\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8fd1\u4f3ck\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u503c\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u548c\u8fd1\u4f3c\u56e0\u5b50\u5747\u4e0d\u4f9d\u8d56\u4e8ek\u7684\u6307\u6570\u3002"}}
{"id": "2507.14164", "categories": ["eess.SP", "cs.AI", "cs.LG", "I.2; J.3"], "pdf": "https://arxiv.org/pdf/2507.14164", "abs": "https://arxiv.org/abs/2507.14164", "authors": ["Samuel Ruip\u00e9rez-Campillo", "Alain Ryser", "Thomas M. Sutter", "Ruibin Feng", "Prasanth Ganesan", "Brototo Deb", "Kelly A. Brennan", "Maxime Pedron", "Albert J. Rogers", "Maarten Z. H. Kolk", "Fleur V. Y. Tjong", "Sanjiv M. Narayan", "Julia E. Vogt"], "title": "A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy", "comment": "9 pages, 2 figures, 3 tables, the last two authors are shared senior\n  authors", "summary": "In the field of cardiac electrophysiology (EP), effectively reducing noise in\nintra-cardiac signals is crucial for the accurate diagnosis and treatment of\narrhythmias and cardiomyopathies. However, traditional noise reduction\ntechniques fall short in addressing the diverse noise patterns from various\nsources, often non-linear and non-stationary, present in these signals. This\nwork introduces a Variational Autoencoder (VAE) model, aimed at improving the\nquality of intra-ventricular monophasic action potential (MAP) signal\nrecordings. By constructing representations of clean signals from a dataset of\n5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our\napproach demonstrates superior denoising performance when compared to\nconventional filtering methods commonly employed in clinical settings. We\nassess the effectiveness of our VAE model using various metrics, indicating its\nsuperior capability to denoise signals across different noise types, including\ntime-varying non-linear noise frequently found in clinical settings. These\nresults reveal that VAEs can eliminate diverse sources of noise in single\nbeats, outperforming state-of-the-art denoising techniques and potentially\nimproving treatment efficacy in cardiac EP.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eVAE\u7684\u4fe1\u53f7\u53bb\u566a\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u5584\u5fc3\u810f\u7535\u751f\u7406\u4fe1\u53f7\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u590d\u6742\u566a\u58f0\u65b9\u9762\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u566a\u58f0\u6d88\u9664\u6280\u672f\u96be\u4ee5\u5904\u7406\u5fc3\u810f\u7535\u751f\u7406\u4fe1\u53f7\u4e2d\u5b58\u5728\u7684\u591a\u6837\u5316\u3001\u975e\u7ebf\u6027\u3001\u975e\u5e73\u7a33\u566a\u58f0\uff0c\u5f71\u54cd\u5fc3\u5f8b\u5931\u5e38\u548c\u5fc3\u808c\u75c5\u7684\u51c6\u786e\u8bca\u65ad\u548c\u6cbb\u7597\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u548c\u53bb\u566a\u5fc3\u8154\u5185\u4fe1\u53f7\u3002", "result": "VAE\u6a21\u578b\u5728\u53bb\u9664\u5305\u62ec\u65f6\u53d8\u975e\u7ebf\u6027\u566a\u58f0\u5728\u5185\u7684\u591a\u79cd\u566a\u58f0\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u964d\u566a\u6027\u80fd\uff0c\u4f18\u4e8e\u4e34\u5e8a\u5e38\u7528\u7684\u6ee4\u6ce2\u65b9\u6cd5\u548c\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6280\u672f\u3002", "conclusion": "VAE\u6a21\u578b\u5728\u53bb\u9664\u5fc3\u8154\u5185\u5355\u76f8\u52a8\u4f5c\u7535\u4f4d\uff08MAP\uff09\u4fe1\u53f7\u7684\u591a\u79cd\u566a\u58f0\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u63d0\u5347\u4fe1\u53f7\u8d28\u91cf\uff0c\u6709\u671b\u6539\u5584\u5fc3\u810f\u7535\u751f\u7406\u5b66\uff08EP\uff09\u7684\u6cbb\u7597\u6548\u679c\u3002"}}
{"id": "2507.14975", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14975", "abs": "https://arxiv.org/abs/2507.14975", "authors": ["Yufan Song", "Jiatao Zhang", "Zeng Gu", "Qingmiao Liang", "Tuocheng Hu", "Wei Song", "Shiqiang Zhu"], "title": "FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models", "comment": "8 pages, 6 figures, IROS 2025", "summary": "Autonomous error correction is critical for domestic robots to achieve\nreliable execution of complex long-horizon tasks. Prior work has explored\nself-reflection in Large Language Models (LLMs) for task planning error\ncorrection; however, existing methods are constrained by inflexible\nself-reflection mechanisms that limit their effectiveness. Motivated by these\nlimitations and inspired by human cognitive adaptation, we propose the Flexible\nConstructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture\nthat enables LLMs to perform flexible self-reflection based on task difficulty,\nwhile constructively integrating historical valuable experience with failure\nlessons. We evaluated FCRF on diverse domestic tasks through simulation in\nAlfWorld and physical deployment in the real-world environment. Experimental\nresults demonstrate that FCRF significantly improves overall performance and\nself-reflection flexibility in complex long-horizon robotic tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFCRF\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u6539\u8fdb\u4e86LLM\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u7684\u81ea\u6211\u7ea0\u9519\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u8c03\u6574\u53cd\u601d\u7b56\u7565\uff0c\u5e76\u4ece\u8fc7\u53bb\u7684\u6210\u529f\u548c\u5931\u8d25\u4e2d\u5b66\u4e60\uff0c\u4ece\u800c\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u7528\u4e8e\u4efb\u52a1\u89c4\u5212\u9519\u8bef\u6821\u6b63\u7684\u81ea\u6211\u53cd\u601d\u673a\u5236\u5b58\u5728\u7075\u6d3b\u6027\u4e0d\u8db3\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5bfc\u5e08-\u884c\u52a8\u8005\u67b6\u6784\uff08FCRF\uff09\uff0c\u8be5\u67b6\u6784\u80fd\u591f\u57fa\u4e8e\u4efb\u52a1\u96be\u5ea6\u5bf9LLM\u8fdb\u884c\u7075\u6d3b\u7684\u81ea\u6211\u53cd\u601d\uff0c\u5e76\u5efa\u8bbe\u6027\u5730\u6574\u5408\u5386\u53f2\u5b9d\u8d35\u7ecf\u9a8c\u548c\u5931\u8d25\u6559\u8bad\u3002", "result": "\u5728AlfWorld\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5bf9\u591a\u79cd\u5bb6\u52a1\u4efb\u52a1\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8bc1\u660eFCRF\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u957f\u671f\u673a\u5668\u4eba\u4efb\u52a1\u7684\u6574\u4f53\u6027\u80fd\u548c\u81ea\u6211\u53cd\u601d\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "FCRF\u5728\u590d\u6742\u7684\u957f\u671f\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6574\u4f53\u6027\u80fd\u548c\u81ea\u6211\u53cd\u601d\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2507.14500", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14500", "abs": "https://arxiv.org/abs/2507.14500", "authors": ["Zhiyuan Hua", "Dehao Yuan", "Cornelia Ferm\u00fcller"], "title": "Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow", "comment": null, "summary": "This paper introduces a robust framework for motion segmentation and\negomotion estimation using event-based normal flow, tailored specifically for\nneuromorphic vision sensors. In contrast to traditional methods that rely\nheavily on optical flow or explicit depth estimation, our approach exploits the\nsparse, high-temporal-resolution event data and incorporates geometric\nconstraints between normal flow, scene structure, and inertial measurements.\nThe proposed optimization-based pipeline iteratively performs event\nover-segmentation, isolates independently moving objects via residual analysis,\nand refines segmentations using hierarchical clustering informed by motion\nsimilarity and temporal consistency. Experimental results on the EVIMO2v2\ndataset validate that our method achieves accurate segmentation and\ntranslational motion estimation without requiring full optical flow\ncomputation. This approach demonstrates significant advantages at object\nboundaries and offers considerable potential for scalable, real-time robotic\nand navigation applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u4e8b\u4ef6\u6570\u636e\u548c\u51e0\u4f55\u7ea6\u675f\u7684\u9c81\u68d2\u6846\u67b6\uff0c\u7528\u4e8e\u8fd0\u52a8\u5206\u5272\u548c\u81ea\u6211\u8fd0\u52a8\u4f30\u8ba1\uff0c\u65e0\u9700\u8ba1\u7b97\u5149\u6d41\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u4f9d\u8d56\u5149\u6d41\u6216\u663e\u5f0f\u6df1\u5ea6\u4f30\u8ba1\u7684\u8fd0\u52a8\u5206\u5272\u548c\u81ea\u6211\u8fd0\u52a8\u4f30\u8ba1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5229\u7528\u4e8b\u4ef6\u6570\u636e\u7684\u7a00\u758f\u6027\u548c\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\uff0c\u5e76\u7ed3\u5408\u51e0\u4f55\u7ea6\u675f\uff08\u6cd5\u5411\u6d41\u3001\u573a\u666f\u7ed3\u6784\u3001\u60ef\u6027\u6d4b\u91cf\uff09\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fdb\u884c\u4e8b\u4ef6\u8fc7\u5206\u5272\u3001\u5229\u7528\u6b8b\u5dee\u5206\u6790\u5206\u79bb\u72ec\u7acb\u8fd0\u52a8\u5bf9\u8c61\uff0c\u5e76\u7ed3\u5408\u8fd0\u52a8\u76f8\u4f3c\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u4fe1\u606f\u8fdb\u884c\u5206\u5c42\u805a\u7c7b\u6765\u4f18\u5316\u5206\u5272\u3002", "result": "\u5728EVIMO2v2\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u8fdb\u884c\u51c6\u786e\u7684\u5206\u5272\u548c\u8f68\u8ff9\u8fd0\u52a8\u4f30\u8ba1\uff0c\u4e14\u65e0\u9700\u8ba1\u7b97\u5168\u90e8\u5149\u6d41\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728EVIMO2v2\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u5206\u5272\u548c\u8f68\u8ff9\u8fd0\u52a8\u4f30\u8ba1\uff0c\u4e14\u65e0\u9700\u8ba1\u7b97\u5149\u6d41\uff0c\u5728\u7269\u4f53\u8fb9\u754c\u5904\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u5177\u6709\u5927\u89c4\u6a21\u3001\u5b9e\u65f6\u673a\u5668\u4eba\u548c\u5bfc\u822a\u5e94\u7528\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.14705", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14705", "abs": "https://arxiv.org/abs/2507.14705", "authors": ["Sai Wang", "Senthilnathan Subramanian", "Mudit Sahni", "Praneeth Gone", "Lingjie Meng", "Xiaochen Wang", "Nicolas Ferradas Bertoli", "Tingxian Cheng", "Jun Xu"], "title": "Configurable multi-agent framework for scalable and realistic testing of llm-based agents", "comment": null, "summary": "Large-language-model (LLM) agents exhibit complex, context-sensitive\nbehaviour that quickly renders static benchmarks and ad-hoc manual testing\nobsolete.\n  We present Neo, a configurable, multi-agent framework that automates\nrealistic, multi-turn evaluation of LLM-based systems. Neo couples a Question\nGeneration Agent and an Evaluation Agent through a shared context-hub, allowing\ndomain prompts, scenario controls and dynamic feedback to be composed\nmodularly. Test inputs are sampled from a probabilistic state model spanning\ndialogue flow, user intent and emotional tone, enabling diverse, human-like\nconversations that adapt after every turn.\n  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)\nuncovered edge-case failures across five attack categories with a 3.3% break\nrate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered\n10-12X higher throughput, generating 180 coherent test questions in around 45\nmins versus 16h of human effort. Beyond security probing, Neo's stochastic\npolicies balanced topic coverage and conversational depth, yielding broader\nbehavioural exploration than manually crafted scripts.\n  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent\ninterfaces, state controller and feedback loops are model-agnostic and\nextensible to richer factual-grounding and policy-compliance checks. We release\nthe framework to facilitate reproducible, high-fidelity testing of emerging\nagentic systems.", "AI": {"tldr": "Neo\u662f\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316LLM\u7cfb\u7edf\u7684\u591a\u56de\u5408\u8bc4\u4f30\u3002\u5b83\u901a\u8fc7\u7ed3\u5408\u95ee\u7b54\u4ee3\u7406\u548c\u8bc4\u4f30\u4ee3\u7406\uff0c\u5e76\u5229\u7528\u6982\u7387\u72b6\u6001\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u7684\u5bf9\u8bdd\uff0c\u80fd\u591f\u53d1\u73b0\u8fb9\u7f18\u6848\u4f8b\u6545\u969c\uff0c\u5e76\u4e14\u6548\u7387\u8fdc\u9ad8\u4e8e\u4eba\u5de5\u6d4b\u8bd5\u3002\u8be5\u6846\u67b6\u652f\u6301\u53ef\u6269\u5c55\u548c\u81ea\u6f14\u8fdb\u7684LLM\u8d28\u91cf\u4fdd\u8bc1\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u884c\u4e3a\u590d\u6742\u4e14\u5bf9\u4e0a\u4e0b\u6587\u654f\u611f\uff0c\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e34\u65f6\u7684\u624b\u52a8\u6d4b\u8bd5\u5f88\u5feb\u5c31\u4f1a\u8fc7\u65f6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u8fdb\u884c\u73b0\u5b9e\u7684\u3001\u591a\u56de\u5408\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9LLM\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\u3002", "method": "Neo\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u95ee\u9898\u751f\u6210\u4ee3\u7406\u548c\u8bc4\u4f30\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u5171\u4eab\u4e0a\u4e0b\u6587\u4e2d\u5fc3\u8fdb\u884c\u8026\u5408\uff0c\u5b9e\u73b0\u4e86LLM\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u3001\u73b0\u5b9e\u7684\u591a\u56de\u5408\u8bc4\u4f30\u3002\u5b83\u4f7f\u7528\u6982\u7387\u72b6\u6001\u6a21\u578b\u6765\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\uff0c\u6db5\u76d6\u5bf9\u8bdd\u6d41\u7a0b\u3001\u7528\u6237\u610f\u56fe\u548c\u60c5\u611f\u57fa\u8c03\uff0c\u4ece\u800c\u5b9e\u73b0\u591a\u6837\u5316\u3001\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5bf9\u8bdd\uff0c\u5e76\u4e14\u80fd\u591f\u6839\u636e\u6bcf\u4e00\u8f6e\u7684\u4ea4\u4e92\u8fdb\u884c\u8c03\u6574\u3002", "result": "Neo\u6846\u67b6\u5728\u5e94\u7528\u4e8e\u751f\u4ea7\u7ea7\u7684\u5356\u5bb6\u8d22\u52a1\u52a9\u624b\u804a\u5929\u673a\u5668\u4eba\u65f6\uff0c\u4e0d\u4ec5\u53d1\u73b0\u4e86\u8de8\u8d8a\u4e94\u4e2a\u653b\u51fb\u7c7b\u522b\u7684\u8fb9\u7f18\u6848\u4f8b\u6545\u969c\uff08\u6253\u7834\u7387\u63a5\u8fd1\u4e13\u5bb6\u4eba\u7c7b\u7ea2\u961f\u6d4b\u8bd5\u4eba\u5458\u7684\u6c34\u5e73\uff09\uff0c\u800c\u4e14\u5b9e\u73b0\u4e8610-12\u500d\u7684\u66f4\u9ad8\u541e\u5410\u91cf\uff0c\u80fd\u591f\u5728\u7ea645\u5206\u949f\u5185\u751f\u6210180\u4e2a\u8fde\u8d2f\u7684\u6d4b\u8bd5\u95ee\u9898\uff0c\u800c\u4eba\u5de5\u6d4b\u8bd5\u5219\u9700\u898116\u5c0f\u65f6\u3002\u6b64\u5916\uff0cNeo\u7684\u968f\u673a\u7b56\u7565\u5728\u5e73\u8861\u4e3b\u9898\u8986\u76d6\u548c\u5bf9\u8bdd\u6df1\u5ea6\u65b9\u9762\u4f18\u4e8e\u624b\u52a8\u811a\u672c\uff0c\u5b9e\u73b0\u4e86\u66f4\u5e7f\u6cdb\u7684\u884c\u4e3a\u63a2\u7d22\u3002", "conclusion": "Neo\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u3001\u81ea\u6f14\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8d28\u91cf\u4fdd\u8bc1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5176\u4ee3\u7406\u63a5\u53e3\u3001\u72b6\u6001\u63a7\u5236\u5668\u548c\u53cd\u9988\u5faa\u73af\u4e0e\u6a21\u578b\u65e0\u5173\uff0c\u5e76\u4e14\u53ef\u4ee5\u6269\u5c55\u5230\u66f4\u4e30\u5bcc\u7684\u57fa\u4e8e\u4e8b\u5b9e\u7684 grounding \u548c\u7b56\u7565\u5408\u89c4\u6027\u68c0\u67e5\u3002\u6211\u4eec\u53d1\u5e03\u8be5\u6846\u67b6\u4ee5\u4fc3\u8fdb\u65b0\u5174\u4ee3\u7406\u7cfb\u7edf\u7684\u53ef\u590d\u73b0\u3001\u9ad8\u4fdd\u771f\u6d4b\u8bd5\u3002"}}
{"id": "2507.14257", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14257", "abs": "https://arxiv.org/abs/2507.14257", "authors": ["Julio Candanedo"], "title": "Linearized Diffusion Map", "comment": null, "summary": "We introduce the Linearized Diffusion Map (LDM), a novel linear\ndimensionality reduction method constructed via a linear approximation of the\ndiffusion-map kernel. LDM integrates the geometric intuition of diffusion-based\nnonlinear methods with the computational simplicity, efficiency, and\ninterpretability inherent in linear embeddings such as PCA and classical MDS.\nThrough comprehensive experiments on synthetic datasets (Swiss roll and\nhyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that\nLDM captures distinct geometric features of datasets compared to PCA, offering\ncomplementary advantages. Specifically, LDM embeddings outperform PCA in\ndatasets exhibiting explicit manifold structures, particularly in\nhigh-dimensional regimes, whereas PCA remains preferable in scenarios dominated\nby variance or noise. Furthermore, the complete positivity of LDM's kernel\nmatrix allows direct applicability of Non-negative Matrix Factorization (NMF),\nsuggesting opportunities for interpretable latent-structure discovery. Our\nanalysis positions LDM as a valuable new linear dimensionality reduction\ntechnique with promising theoretical and practical extensions.", "AI": {"tldr": "LDM \u662f\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u964d\u7ef4\u65b9\u6cd5\uff0c\u5b83\u7ed3\u5408\u4e86\u975e\u7ebf\u6027\u65b9\u6cd5\u7684\u51e0\u4f55\u76f4\u89c9\u548c\u7ebf\u6027\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u5904\u7406\u5177\u6709\u6d41\u5f62\u7ed3\u6784\u7684\u590d\u6742\u6570\u636e\u96c6\u65f6\u4f18\u4e8e PCA\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u5c06\u57fa\u4e8e\u6269\u6563\u7684\u975e\u7ebf\u6027\u65b9\u6cd5\u7684\u51e0\u4f55\u76f4\u89c9\u4e0e PCA \u548c\u7ecf\u5178 MDS \u7b49\u7ebf\u6027\u5d4c\u5165\u56fa\u6709\u7684\u8ba1\u7b97\u7b80\u5355\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u76f8\u7ed3\u5408\u3002", "method": "LDM \u901a\u8fc7\u5bf9\u6269\u6563\u6620\u5c04\u6838\u8fdb\u884c\u7ebf\u6027\u8fd1\u4f3c\u6765\u6784\u5efa\uff0c\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7ebf\u6027\u964d\u7ef4\u65b9\u6cd5\u3002", "result": "\u4e0e PCA \u76f8\u6bd4\uff0cLDM \u5728\u5177\u6709\u660e\u663e\u6d41\u5f62\u7ed3\u6784\u7684\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\uff08\u5305\u62ec MNIST \u548c COIL-20\uff09\u4e0a\u5c55\u793a\u4e86\u6355\u6349\u72ec\u7279\u51e0\u4f55\u7279\u5f81\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u3002LDM \u7684\u5b8c\u6574\u6b63\u6838\u77e9\u9635\u53ef\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u975e\u8d1f\u77e9\u9635\u5206\u89e3 (NMF)\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u7ed3\u6784\u53d1\u73b0\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "conclusion": "LDM \u662f\u4e00\u79cd\u6709\u4ef7\u503c\u7684\u65b0\u578b\u7ebf\u6027\u964d\u7ef4\u6280\u672f\uff0c\u5177\u6709\u5e7f\u9614\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u524d\u666f\u3002"}}
{"id": "2507.14838", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14838", "abs": "https://arxiv.org/abs/2507.14838", "authors": ["Xingyue Han", "Xiong Yao", "Tilak Ram Thapaliya", "Genaro Bierhance", "Chihun In", "Zhuoliang Ni", "Amilcar Bedoya-Pinto", "Sunxiang Huang", "Claudia Felser", "Stuart S. P. Parkin", "Tobias Kampfrath", "Seongshik Oh", "Liang Wu"], "title": "Broad-band THz emission by Spin-to-Charge Conversion in Topological Material -- Ferromagnet Heterostructures", "comment": null, "summary": "Terahertz spintronic devices combine ultrafast operation with low power\nconsumption, making them strong candidates for next-generation memory\ntechnologies. In this study, we use time-domain terahertz emission spectroscopy\nto investigate spin-to-charge conversion (SCC) in bilayer heterostructures\ncomprising topological insulators (TIs) or Weyl semimetals (WSMs) with\nferromagnetic metals (FMs). SCC is studied in TI materials \\ce{Bi2Se3},\nPb-doped \\ce{Bi2Se3}, and (Bi$_{1-x}$Sb$_x$)$_2$Te$_3$, and the WSM NbP. Our\nresults reveal that the dependence of SCC on TI thickness varies with interface\nquality, indicating that thickness dependence alone is not a reliable criterion\nfor distinguishing between inverse spin Hall effect and the inverse\nRashba--Edelstein effect mechanisms. We find efficient SCC in TIs depends on\nboth \\textit{in-situ} growth to prevent surface oxidation and proper\ncomposition. In NbP$\\vert$FM bilayers, we observe THz emission with efficiency\nand bandwidth comparable to that of TIs, highlighting the broader potential of\ntopological materials. Finally, broadband spectral measurements demonstrate\nthat both TIs and WSMs can generate THz pulses with frequencies extending up to\n8\\,THz. These findings underscore the promise of topological materials as\nefficient platforms for ultrafast, broadband spintronic applications.", "AI": {"tldr": "\u7814\u7a76\u4e86\u62d3\u6251\u6750\u6599\uff08TIs\u548cWSMs\uff09\u4e0e\u94c1\u78c1\u91d1\u5c5e\uff08FMs\uff09\u7ec4\u6210\u7684\u53cc\u5c42\u5f02\u8d28\u7ed3\u6784\u4e2d\u7684\u592a\u8d6b\u5179\u81ea\u65cb\u5230\u7535\u8377\u8f6c\u6362\uff08SCC\uff09\uff0c\u7ed3\u679c\u8868\u660e\u62d3\u6251\u6750\u6599\u5728\u8d85\u5feb\u3001\u5bbd\u5e26\u81ea\u65cb\u7535\u5b50\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u5f00\u53d1\u4e0b\u4e00\u4ee3\u8bb0\u5fc6\u6280\u672f\uff0c\u7814\u7a76\u4e86\u592a\u8d6b\u5179\u81ea\u65cb\u7535\u5b50\u5668\u4ef6\u7684\u8d85\u5feb\u548c\u4f4e\u529f\u8017\u7279\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u62d3\u6251\u6750\u6599\u4e2d\u7684\u81ea\u65cb\u5230\u7535\u8377\u8f6c\u6362\uff08SCC\uff09\u73b0\u8c61\u3002", "method": "\u4f7f\u7528\u65f6\u57df\u592a\u8d6b\u5179\u53d1\u5c04\u5149\u8c31\u7814\u7a76\u4e86\u62d3\u6251\u7edd\u7f18\u4f53\uff08TIs\uff09\u6216Weyl\u534a\u91d1\u5c5e\uff08WSMs\uff09\u4e0e\u94c1\u78c1\u91d1\u5c5e\uff08FMs\uff09\u7ec4\u6210\u7684\u53cc\u5c42\u5f02\u8d28\u7ed3\u6784\u4e2d\u7684\u81ea\u65cb\u5230\u7535\u8377\u8f6c\u6362\uff08SCC\uff09\u3002", "result": "SCC\u5bf9TI\u539a\u5ea6\u7684\u4f9d\u8d56\u6027\u53d7\u754c\u9762\u8d28\u91cf\u5f71\u54cd\uff0c\u4e0d\u80fd\u5355\u72ec\u7528\u4e8e\u533a\u5206SCC\u673a\u5236\u3002TI\u7684\u9ad8\u6548SCC\u4f9d\u8d56\u4e8e\u539f\u4f4d\u751f\u957f\u548c\u6210\u5206\u3002NbP|FM\u53cc\u5c42\u7ed3\u6784\u8868\u73b0\u51fa\u4e0eTI\u76f8\u5f53\u7684THz\u53d1\u5c04\u6548\u7387\u548c\u5e26\u5bbd\u3002TI\u548cWSM\u5747\u80fd\u4ea7\u751f\u9ad8\u8fbe8THz\u7684THz\u8109\u51b2\u3002", "conclusion": "Bi2Se3\u3001Pb\u63ba\u6742Bi2Se3\u3001(Bi1-xSbx)2Te3\u7b49\u62d3\u6251\u7edd\u7f18\u4f53\uff08TIs\uff09\u4ee5\u53ca the Weyl semimetal NbP\u4e0e\u94c1\u78c1\u91d1\u5c5e\uff08FMs\uff09\u5f62\u6210\u7684\u53cc\u5c42\u5f02\u8d28\u7ed3\u6784\uff0c\u901a\u8fc7\u65f6\u57df\u592a\u8d6b\u5179\u53d1\u5c04\u5149\u8c31\u7814\u7a76\u4e86\u81ea\u65cb\u5230\u7535\u8377\u7684\u8f6c\u6362\uff08SCC\uff09\u3002\u7ed3\u679c\u8868\u660e\uff0cSCC\u5bf9TI\u539a\u5ea6\u7684\u4f9d\u8d56\u6027\u968f\u754c\u9762\u8d28\u91cf\u800c\u53d8\u5316\uff0c\u4ec5\u4f9d\u8d56\u539a\u5ea6\u53d8\u5316\u4e0d\u8db3\u4ee5\u533a\u5206SCC\u7684\u673a\u5236\u3002TI\u4e2d\u7684\u9ad8\u6548SCC\u4f9d\u8d56\u4e8e\u539f\u4f4d\u751f\u957f\u548c\u5408\u9002\u7684\u6210\u5206\u3002\u5728NbP|FM\u53cc\u5c42\u7ed3\u6784\u4e2d\uff0c\u89c2\u5bdf\u5230\u4e86\u4e0eTI\u76f8\u5f53\u7684THz\u53d1\u5c04\u6548\u7387\u548c\u5e26\u5bbd\u3002\u6700\u7ec8\uff0c\u5bbd\u5e26\u5149\u8c31\u6d4b\u91cf\u8868\u660eTI\u548cWSM\u90fd\u53ef\u4ee5\u4ea7\u751f\u9ad8\u8fbe8THz\u9891\u7387\u7684THz\u8109\u51b2\u3002"}}
{"id": "2507.15163", "categories": ["eess.SY", "cs.CR", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15163", "abs": "https://arxiv.org/abs/2507.15163", "authors": ["Kim Hammar", "Yuchao Li", "Tansu Alpcan", "Emil C. Lupu", "Dimitri Bertsekas"], "title": "Adaptive Network Security Policies via Belief Aggregation and Rollout", "comment": null, "summary": "Evolving security vulnerabilities and shifting operational conditions require\nfrequent updates to network security policies. These updates include\nadjustments to incident response procedures and modifications to access\ncontrols, among others. Reinforcement learning methods have been proposed for\nautomating such policy adaptations, but most of the methods in the research\nliterature lack performance guarantees and adapt slowly to changes. In this\npaper, we address these limitations and present a method for computing security\npolicies that is scalable, offers theoretical guarantees, and adapts quickly to\nchanges. It assumes a model or simulator of the system and comprises three\ncomponents: belief estimation through particle filtering, offline policy\ncomputation through aggregation, and online policy adaptation through rollout.\nCentral to our method is a new feature-based aggregation technique, which\nimproves scalability and flexibility. We analyze the approximation error of\naggregation and show that rollout efficiently adapts policies to changes under\ncertain conditions. Simulations and testbed results demonstrate that our method\noutperforms state-of-the-art methods on several benchmarks, including CAGE-2.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u9002\u5e94\u7f51\u7edc\u5b89\u5168\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u7f51\u7edc\u5b89\u5168\u7b56\u7565\u81ea\u52a8\u9002\u5e94\u65b9\u9762\u7684\u6027\u80fd\u4fdd\u8bc1\u4e0d\u8db3\u548c\u9002\u5e94\u53d8\u5316\u7f13\u6162\u7684\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u901a\u8fc7\u7c92\u5b50\u6ee4\u6ce2\u8fdb\u884c\u4fe1\u5ff5\u4f30\u8ba1\uff0c\u901a\u8fc7\u805a\u5408\u8fdb\u884c\u79bb\u7ebf\u7b56\u7565\u8ba1\u7b97\uff0c\u4ee5\u53ca\u901a\u8fc7\u6eda\u52a8\u8fdb\u884c\u5728\u7ebf\u7b56\u7565\u9002\u5e94\u3002\u5176\u6838\u5fc3\u662f\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u7279\u5f81\u7684\u805a\u5408\u6280\u672f\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u8ba1\u7b97\u51fa\u53ef\u6269\u5c55\u3001\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u4e14\u80fd\u5feb\u901f\u9002\u5e94\u53d8\u5316\u7684\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u6a21\u62df\u548c\u6d4b\u8bd5\u5e73\u53f0\u7ed3\u679c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728CAGE-2\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14836", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14836", "abs": "https://arxiv.org/abs/2507.14836", "authors": ["Hikaru Shimizu", "Joe Yoshimoto", "Daiki Ichii", "Junko Ishi-Hayase", "Rikizo Ikuta", "Masahiro Takeoka"], "title": "Improving the Rate-Loss Scaling in Polarization Entanglement Distribution using Single-Click Entanglement Swapping", "comment": "12 pages, 9 figures", "summary": "Polarization entanglement is widely used in optical quantum information\nprocessing due to its compatibility with standard optical components. On the\nother hand, it is known that polarization entanglement is susceptible to the\nloss, more precisely, its transmission rate in a lossy channel is limited by\nthe scaling of O({\\eta}), where {\\eta} is a transmittance of the channel. Here,\nwe experimentally demonstrate that this rate-loss scaling limit can be overcome\nby a relatively simple protocol. This is possible by integrating the idea of\nthe polarizaion-photon-number hybrid entanglement and the single-click\nentanglement swapping. We demonstrate square root improvement of the rate-loss\nscaling from the conventional approaches and achieve the fidelity of 0.843 for\nthe distributed polarization entangled photon pairs. This improvement in the\nrate-loss scaling is equivalent to that achieved by 1-hop quantum repeater\nnode. Our result paves a way to build a near-future quantum network and its\napplications.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e00\u79cd\u7ed3\u5408\u504f\u632f-\u5149\u5b50\u6570\u6df7\u5408\u7ea0\u7f20\u548c\u5355\u6b21\u70b9\u51fb\u7ea0\u7f20\u4ea4\u6362\u7684\u534f\u8bae\uff0c\u514b\u670d\u4e86\u504f\u632f\u7ea0\u7f20\u5728\u635f\u8017\u4fe1\u9053\u4e2d\u4f20\u8f93\u901f\u7387\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u597d\u7684\u901f\u7387-\u635f\u8017\u6269\u5c55\uff0c\u4e3a\u91cf\u5b50\u7f51\u7edc\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u504f\u632f\u7ea0\u7f20\u5728\u635f\u8017\u4fe1\u9053\u4e2d\u4f20\u8f93\u901f\u7387\u53d7\u9650\u4e8eO(\u03b7)\u7684\u6269\u5c55\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6574\u5408\u504f\u632f-\u5149\u5b50\u6570\u6df7\u5408\u7ea0\u7f20\u548c\u5355\u6b21\u70b9\u51fb\u7ea0\u7f20\u4ea4\u6362\u7684\u601d\u60f3\uff0c\u5e76\u7ed3\u5408\u504f\u632f\u7ea0\u7f20\u5206\u53d1\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5e73\u65b9\u6839\u7684\u901f\u7387-\u635f\u8017\u6269\u5c55\u3002", "result": "\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5e73\u65b9\u6839\u7684\u901f\u7387-\u635f\u8017\u6269\u5c55\uff0c\u5bf9\u4e8e\u5206\u5e03\u5f0f\u504f\u632f\u7ea0\u7f20\u5149\u5b50\u5bf9\u5b9e\u73b0\u4e860.843\u7684\u4fdd\u771f\u5ea6\uff0c\u8fd9\u79cd\u901f\u7387-\u635f\u8017\u6269\u5c55\u7684\u6539\u8fdb\u7b49\u540c\u4e8e\u5355\u8df3\u91cf\u5b50\u4e2d\u7ee7\u8282\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u4e3a\u6784\u5efa\u8fd1\u672a\u6765\u91cf\u5b50\u7f51\u7edc\u53ca\u5176\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14578", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14578", "abs": "https://arxiv.org/abs/2507.14578", "authors": ["Sachin Yadav", "Dominik Schlechtweg"], "title": "XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification", "comment": "8 pages", "summary": "We propose XL-DURel, a finetuned, multilingual Sentence Transformer model\noptimized for ordinal Word-in-Context classification. We test several loss\nfunctions for regression and ranking tasks managing to outperform previous\nmodels on ordinal and binary data with a ranking objective based on angular\ndistance in complex space. We further show that binary WiC can be treated as a\nspecial case of ordinal WiC and that optimizing models for the general ordinal\ntask improves performance on the more specific binary task. This paves the way\nfor a unified treatment of WiC modeling across different task formulations.", "AI": {"tldr": "XL-DURel \u662f\u4e00\u4e2a\u4f18\u5316\u7684\u591a\u8bed\u8a00\u53e5\u5b50 Transformer \u6a21\u578b\uff0c\u7528\u4e8e\u5e8f\u6570\u8bcd\u8bed in-context\uff08WiC\uff09\u5206\u7c7b\uff0c\u5728\u5e8f\u6570\u548c\u4e8c\u5143\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e3a WiC \u5efa\u6a21\u7684\u7edf\u4e00\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u65e8\u5728\u4f18\u5316\u8bcd\u8bed in-context\uff08WiC\uff09\u5206\u7c7b\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5e8f\u6570 WiC \u5206\u7c7b\uff0c\u5e76\u63a2\u7d22\u4e8c\u5143 WiC \u4e0e\u5e8f\u6570 WiC \u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u5b9e\u73b0 WiC \u5efa\u6a21\u7684\u7edf\u4e00\u5904\u7406\u3002", "method": "\u63d0\u51fa\u5e76\u5fae\u8c03\u4e86\u4e00\u4e2a\u540d\u4e3a XL-DURel \u7684\u591a\u8bed\u8a00\u53e5\u5b50 Transformer \u6a21\u578b\uff0c\u8be5\u6a21\u578b\u9488\u5bf9\u5e8f\u6570\u8bcd\u8bed in-context\uff08WiC\uff09\u5206\u7c7b\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u6d4b\u8bd5\u4e86\u591a\u79cd\u7528\u4e8e\u56de\u5f52\u548c\u6392\u5e8f\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u590d\u7a7a\u95f4\u89d2\u5ea6\u8ddd\u79bb\u7684\u6392\u5e8f\u76ee\u6807\u3002", "result": "XL-DURel \u6a21\u578b\u5728\u5e8f\u6570\u548c\u4e8c\u5143\u6570\u636e\u4e0a\u5747\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4e86\u9488\u5bf9\u5e8f\u6570 WiC \u4efb\u52a1\u8fdb\u884c\u4f18\u5316\u80fd\u591f\u63d0\u5347\u4e8c\u5143 WiC \u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "XL-DURel \u662f\u4e00\u4e2a\u9488\u5bf9\u5e8f\u6570\u8bcd\u8bed in-context\uff08WiC\uff09\u5206\u7c7b\u8fdb\u884c\u4f18\u5316\u7684\u3001\u7ecf\u8fc7\u5fae\u8c03\u7684\u591a\u8bed\u8a00\u53e5\u5b50 Transformer \u6a21\u578b\u3002\u901a\u8fc7\u6d4b\u8bd5\u4e0d\u540c\u7684\u56de\u5f52\u548c\u6392\u5e8f\u635f\u5931\u51fd\u6570\uff0c\u8be5\u6a21\u578b\u5728\u5e8f\u6570\u548c\u4e8c\u5143\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u5148\u524d\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5176\u6392\u5e8f\u76ee\u6807\u57fa\u4e8e\u590d\u7a7a\u95f4\u4e2d\u7684\u89d2\u5ea6\u8ddd\u79bb\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u4e8c\u5143 WiC \u53ef\u89c6\u4e3a\u5e8f\u6570 WiC \u7684\u7279\u4f8b\uff0c\u5e76\u4e14\u9488\u5bf9\u66f4\u901a\u7528\u7684\u5e8f\u6570\u4efb\u52a1\u8fdb\u884c\u4f18\u5316\u53ef\u4ee5\u63d0\u5347\u5728\u66f4\u5177\u4f53\u7684\u4e8c\u5143\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u8fd9\u4e3a\u8de8\u4e0d\u540c\u4efb\u52a1\u8868\u8ff0\u7684 WiC \u5efa\u6a21\u7684\u7edf\u4e00\u5904\u7406\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14165", "categories": ["eess.SP", "cs.SY", "eess.IV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14165", "abs": "https://arxiv.org/abs/2507.14165", "authors": ["Philip Wiese", "Victor Kartsch", "Marco Guermandi", "Luca Benini"], "title": "A Multi-Modal IoT Node for Energy-Efficient Environmental Monitoring with Edge AI Processing", "comment": "7 pages, 4 figures, 2 tables. This paper has been accepted at 2025\n  IEEE International Conference on Omni-layer Intelligent Systems (COINS)", "summary": "The widespread adoption of Internet of Things (IoT) technologies has\nsignificantly advanced environmental monitoring (EM) by enabling cost-effective\nand scalable sensing solutions. Concurrently, machine learning (ML) and\nartificial intelligence (AI) are introducing powerful tools for the efficient\nand accurate analysis of complex environmental data. However, current IoT\nplatforms for environmental sensing are typically limited to a narrow set of\nsensors, preventing a comprehensive assessment of environmental conditions and\nlacking sufficient computational capabilities to support the deployment of\nadvanced ML and AI algorithms on the edge. To overcome these limitations, we\nintroduce a compact (17x38 mm2), multi-modal, MCU-based environmental IoT node\nintegrating 11 sensors, including CO2 concentration, volatile organic compounds\n(VOCs), light intensity, UV radiation, pressure, temperature, humidity, visual\nsensing via an RGB camera, and precise geolocation through a GNSS module. It\nfeatures GAP9, a parallel ultra-low-power system-on-chip, enabling real-time,\nenergy-efficient edge processing of advanced ML models directly on-device. We\nimplemented a YOLOv5-based occupancy detection pipeline (0.3 M parameters, 42\nMOP per inference), demonstrating 42% energy savings over raw data streaming.\nAdditionally, we present a smart indoor air quality (IAQ) monitoring setup that\ncombines occupancy detection with adaptive sample rates, achieving operational\ntimes of up to 143 h on a single compact 600 mAh, 3.7 V battery. Our platform\nlays the groundwork for innovative applications such as predictive indoor IAQ,\nenabling efficient AI-driven on-edge forecasting for energy-efficient and\nautonomous, proactive pollution-mitigation control strategies", "AI": {"tldr": "\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u4f20\u611f\u5668\u548c\u652f\u6301\u8fb9\u7f18 AI \u5904\u7406\u7684\u4f4e\u529f\u8017\u82af\u7247\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u529f\u80fd\u7684\u7269\u8054\u7f51\u73af\u5883\u76d1\u6d4b\u8282\u70b9\uff0c\u5b9e\u73b0\u4e86\u8282\u80fd\u548c\u667a\u80fd\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u3002", "motivation": "\u76ee\u524d\u7684\u7269\u8054\u7f51\u73af\u5883\u4f20\u611f\u5e73\u53f0\u901a\u5e38\u4ec5\u9650\u4e8e\u5c11\u6570\u4f20\u611f\u5668\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u73af\u5883\u72b6\u51b5\uff0c\u5e76\u4e14\u7f3a\u4e4f\u8db3\u591f\u7684\u8ba1\u7b97\u80fd\u529b\u6765\u652f\u6301\u5728\u8fb9\u7f18\u90e8\u7f72\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\uff0817x38 mm2\uff09\u3001\u591a\u529f\u80fd\u7684\u3001\u57fa\u4e8e MCU \u7684\u73af\u5883\u7269\u8054\u7f51\u8282\u70b9\uff0c\u96c6\u6210\u4e86 11 \u79cd\u4f20\u611f\u5668\uff08\u5305\u62ec CO2 \u6d53\u5ea6\u3001\u6325\u53d1\u6027\u6709\u673a\u5316\u5408\u7269\u3001\u5149\u7167\u5f3a\u5ea6\u3001\u7d2b\u5916\u7ebf\u8f90\u5c04\u3001\u538b\u529b\u3001\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001RGB \u6444\u50cf\u5934\u89c6\u89c9\u4f20\u611f\u4ee5\u53ca GNSS \u6a21\u5757\u7684\u7cbe\u786e\u5730\u7406\u5b9a\u4f4d\uff09\u3002\u8be5\u8282\u70b9\u91c7\u7528 GAP9\uff08\u4e00\u79cd\u5e76\u884c\u7684\u8d85\u4f4e\u529f\u8017\u7247\u4e0a\u7cfb\u7edf\uff09\uff0c\u53ef\u5b9e\u73b0\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u3001\u9ad8\u80fd\u6548\u8fb9\u7f18\u5904\u7406\u3002\u5b9e\u73b0\u4e86\u57fa\u4e8e YOLOv5 \u7684\u5360\u7528\u68c0\u6d4b\u7ba1\u9053\uff080.3M \u53c2\u6570\uff0c\u6bcf\u6b21\u63a8\u7406 42MOP\uff09\uff0c\u4e0e\u539f\u59cb\u6570\u636e\u6d41\u76f8\u6bd4\uff0c\u8282\u80fd 42%\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u4e00\u4e2a\u7ed3\u5408\u5360\u7528\u68c0\u6d4b\u548c\u81ea\u9002\u5e94\u91c7\u6837\u7387\u7684\u667a\u80fd\u5ba4\u5185\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u7cfb\u7edf\uff0c\u5728\u5355\u5757 600 mAh\u30013.7 V \u7535\u6c60\u4e0a\u53ef\u8fd0\u884c\u957f\u8fbe 143 \u5c0f\u65f6\u3002", "result": "\u5b9e\u73b0\u4e86 42% \u7684\u8282\u80fd\uff0c\u5355\u5757\u7535\u6c60\u53ef\u8fd0\u884c\u957f\u8fbe 143 \u5c0f\u65f6\u3002", "conclusion": "\u8be5\u5e73\u53f0\u4e3a\u521b\u65b0\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f8b\u5982\u9884\u6d4b\u5ba4\u5185\u7a7a\u6c14\u8d28\u91cf\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u3001\u7531\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u8fb9\u7f18\u9884\u6d4b\uff0c\u4ee5\u5b9e\u73b0\u8282\u80fd\u548c\u81ea\u4e3b\u7684\u3001\u4e3b\u52a8\u7684\u6c61\u67d3\u7f13\u89e3\u63a7\u5236\u7b56\u7565\u3002"}}
{"id": "2507.15022", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.15022", "abs": "https://arxiv.org/abs/2507.15022", "authors": ["Sumeadh MS", "Kevin Dsouza", "Ravi Prakash"], "title": "CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions", "comment": "6pages, 4figures, Submitted to the prestigious Indian Control\n  Conference (ICC), 2025", "summary": "Among the promising approaches to enforce safety in control systems, learning\nControl Barrier Functions (CBFs) from expert demonstrations has emerged as an\neffective strategy. However, a critical challenge remains: verifying that the\nlearned CBFs truly enforce safety across the entire state space. This is\nespecially difficult when CBF is represented using neural networks (NCBFs).\nSeveral existing verification techniques attempt to address this problem\nincluding SMT-based solvers, mixed-integer programming (MIP), and interval or\nbound-propagation methods but these approaches often introduce loose,\nconservative bounds. To overcome these limitations, in this work we use\nCPED-NCBFs a split-conformal prediction based verification strategy to verify\nthe learned NCBF from the expert demonstrations. We further validate our method\non point mass systems and unicycle models to demonstrate the effectiveness of\nthe proposed theory.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faCPED-NCBFs\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u88c2\u4e00\u81f4\u6027\u9884\u6d4b\u6765\u9a8c\u8bc1\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u5230\u7684\u795e\u7ecf\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08NCBF\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u754c\u9650\u4fdd\u5b88\u7684\u7f3a\u70b9\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u9a8c\u8bc1\u6280\u672f\uff08\u5982SMT\u6c42\u89e3\u5668\u3001\u6df7\u5408\u6574\u6570\u89c4\u5212\u3001\u533a\u95f4/\u8fb9\u754c\u4f20\u64ad\uff09\u751f\u6210\u7684\u754c\u9650\u8fc7\u4e8e\u4fdd\u5b88\u7684\u95ee\u9898\uff0c\u4ee5\u786e\u4fdd\u5b66\u4e60\u5230\u7684CBFs\u5728\u6574\u4e2a\u72b6\u6001\u7a7a\u95f4\u4e2d\u5f3a\u5236\u6267\u884c\u5b89\u5168\u6027\u3002", "method": "CPED-NCBFs\uff08\u4e00\u79cd\u57fa\u4e8e\u5206\u88c2\u4e00\u81f4\u6027\u9884\u6d4b\u7684\u9a8c\u8bc1\u7b56\u7565\uff09", "result": "\u5728\u70b9\u8d28\u91cf\u7cfb\u7edf\u548c\u5355\u8f6e\u8f66\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7406\u8bba\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u88c2\u4e00\u81f4\u6027\u9884\u6d4b\u7684\u9a8c\u8bc1\u7b56\u7565CPED-NCBFs\uff0c\u7528\u4e8e\u9a8c\u8bc1\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u5230\u7684\u795e\u7ecf\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08NCBF\uff09\u3002"}}
{"id": "2507.14501", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14501", "abs": "https://arxiv.org/abs/2507.14501", "authors": ["Jiahui Zhang", "Yuelei Li", "Anpei Chen", "Muyu Xu", "Kunhao Liu", "Jianyuan Wang", "Xiao-Xiao Long", "Hanxue Liang", "Zexiang Xu", "Hao Su", "Christian Theobalt", "Christian Rupprecht", "Andrea Vedaldi", "Hanspeter Pfister", "Shijian Lu", "Fangneng Zhan"], "title": "Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey", "comment": "A project page associated with this survey is available at\n  https://fnzhan.com/projects/Feed-Forward-3D", "summary": "3D reconstruction and view synthesis are foundational problems in computer\nvision, graphics, and immersive technologies such as augmented reality (AR),\nvirtual reality (VR), and digital twins. Traditional methods rely on\ncomputationally intensive iterative optimization in a complex chain, limiting\ntheir applicability in real-world scenarios. Recent advances in feed-forward\napproaches, driven by deep learning, have revolutionized this field by enabling\nfast and generalizable 3D reconstruction and view synthesis. This survey offers\na comprehensive review of feed-forward techniques for 3D reconstruction and\nview synthesis, with a taxonomy according to the underlying representation\narchitectures including point cloud, 3D Gaussian Splatting (3DGS), Neural\nRadiance Fields (NeRF), etc. We examine key tasks such as pose-free\nreconstruction, dynamic 3D reconstruction, and 3D-aware image and video\nsynthesis, highlighting their applications in digital humans, SLAM, robotics,\nand beyond. In addition, we review commonly used datasets with detailed\nstatistics, along with evaluation protocols for various downstream tasks. We\nconclude by discussing open research challenges and promising directions for\nfuture work, emphasizing the potential of feed-forward approaches to advance\nthe state of the art in 3D vision.", "AI": {"tldr": "3D\u91cd\u5efa\u548c\u89c6\u56fe\u5408\u6210\u7684\u8fdb\u9636\uff0c\u91cd\u70b9\u662f\u5feb\u901f\u7684\u524d\u9988\u65b9\u6cd5\uff0c\u59823DGS\u548cNeRF\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728AR/VR\u548c\u6570\u5b57\u4eba\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u578b\u8fed\u4ee3\u4f18\u5316\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u9650\u5236\uff0c\u800c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u524d\u9988\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u5feb\u901f\u3001\u53ef\u6cdb\u5316\u76843D\u91cd\u5efa\u548c\u89c6\u56fe\u5408\u6210\u3002", "method": "\u5bf9\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u524d\u9988\u6280\u672f\u8fdb\u884c\u5168\u9762\u7684\u8c03\u67e5\uff0c\u6839\u636e\u70b9\u4e91\u30013D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u3001\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7b49\u57fa\u7840\u8868\u793a\u67b6\u6784\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u68c0\u67e5\u5173\u952e\u4efb\u52a1\uff0c\u5982\u65e0\u59ff\u6001\u91cd\u5efa\u3001\u52a8\u60013D\u91cd\u5efa\u4ee5\u53ca3D\u611f\u77e5\u56fe\u50cf\u548c\u89c6\u9891\u5408\u6210\uff0c\u5e76\u5f3a\u8c03\u5b83\u4eec\u5728\u6570\u5b57\u4eba\u3001SLAM\u3001\u673a\u5668\u4eba\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002\u6b64\u5916\uff0c\u8fd8\u56de\u987e\u4e86\u5e38\u7528\u7684\u6570\u636e\u96c6\u3001\u8be6\u7ec6\u7edf\u8ba1\u6570\u636e\u548c\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "conclusion": "\u8fdb\u9636\u76843D\u89c6\u89c9\u548c\u76f8\u5173\u5e94\u7528\u3002"}}
{"id": "2507.14719", "categories": ["cs.AI", "I.2.7; F.2.2"], "pdf": "https://arxiv.org/pdf/2507.14719", "abs": "https://arxiv.org/abs/2507.14719", "authors": ["Juan Manuel Contreras"], "title": "Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix", "comment": null, "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, scalable and rigorous safety evaluation is essential.\nThis paper introduces Aymara AI, a programmatic platform for generating and\nadministering customized, policy-grounded safety evaluations. Aymara AI\ntransforms natural-language safety policies into adversarial prompts and scores\nmodel responses using an AI-based rater validated against human judgments. We\ndemonstrate its capabilities through the Aymara LLM Risk and Responsibility\nMatrix, which evaluates 20 commercially available LLMs across 10 real-world\nsafety domains. Results reveal wide performance disparities, with mean safety\nscores ranging from 86.2% to 52.4%. While models performed well in\nwell-established safety domains such as Misinformation (mean = 95.7%), they\nconsistently failed in more complex or underspecified domains, notably Privacy\n& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety\nscores differed significantly across both models and domains (p < .05). These\nfindings underscore the inconsistent and context-dependent nature of LLM safety\nand highlight the need for scalable, customizable tools like Aymara AI to\nsupport responsible AI development and oversight.", "AI": {"tldr": "Aymara AI\u662f\u4e00\u4e2a\u7528\u4e8eLLM\u5b89\u5168\u8bc4\u4f30\u7684\u5e73\u53f0\uff0c\u8bc4\u4f30\u4e8620\u79cdLLM\u572810\u4e2a\u5b89\u5168\u57df\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u6027\u80fd\u5dee\u5f02\u5f88\u5927\uff0c\u5c24\u5176\u662f\u5728\u9690\u79c1\u4e0e\u8eab\u4efd\u5192\u5145\u65b9\u9762\u8868\u73b0\u8f83\u5dee\uff0c\u51f8\u663e\u4e86\u5bf9\u53ef\u6269\u5c55\u8bc4\u4f30\u5de5\u5177\u7684\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u5b9e\u9645\u5e94\u7528\uff0c\u53ef\u6269\u5c55\u4e14\u4e25\u683c\u7684\u5b89\u5168\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002", "method": "Aymara AI\u662f\u4e00\u4e2a\u7a0b\u5e8f\u5316\u5e73\u53f0\uff0c\u7528\u4e8e\u751f\u6210\u548c\u7ba1\u7406\u5b9a\u5236\u7684\u3001\u57fa\u4e8e\u7b56\u7565\u7684\u5b89\u5168\u8bc4\u4f30\u3002\u5b83\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u8f6c\u5316\u4e3a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5e76\u4f7f\u7528\u7ecf\u8fc7\u4eba\u7c7b\u5224\u65ad\u9a8c\u8bc1\u7684\u57fa\u4e8eAI\u7684\u8bc4\u5206\u5668\u5bf9\u6a21\u578b\u54cd\u5e94\u8fdb\u884c\u8bc4\u5206\u3002", "result": "\u901a\u8fc7Aymara LLM\u98ce\u9669\u4e0e\u8d23\u4efb\u77e9\u9635\uff0c\u8bc4\u4f30\u4e8620\u79cd\u5546\u4e1a\u4e0a\u53ef\u7528\u7684LLM\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u5b89\u5168\u57df\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5e73\u5747\u5b89\u5168\u5f97\u5206\u572886.2%\u523052.4%\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u5dee\u5f02\u3002\u6a21\u578b\u5728\u4fe1\u606f\u5931\u200b\u200b\u73b0\u5b9e\uff08\u5e73\u5747=95.7%\uff09\u7b49\u6210\u719f\u7684\u5b89\u5168\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9690\u79c1\u4e0e\u8eab\u4efd\u5192\u5145\uff08\u5e73\u5747=24.3%\uff09\u7b49\u66f4\u590d\u6742\u6216\u5b9a\u4e49\u4e0d\u6e05\u7684\u57df\u65b9\u9762\u6301\u7eed\u5b58\u5728\u95ee\u9898\u3002\u65b9\u5dee\u5206\u6790\u8bc1\u5b9e\uff0c\u4e0d\u540c\u6a21\u578b\u548c\u57df\u4e4b\u95f4\u7684\u5b89\u5168\u5f97\u5206\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08p < .05\uff09\u3002", "conclusion": "LLM\u7684\u5b89\u5168\u6027\u8868\u73b0\u51fa\u663e\u8457\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u5f3a\u8c03\u4e86\u50cfAymara AI\u8fd9\u6837\u53ef\u6269\u5c55\u3001\u53ef\u5b9a\u5236\u7684\u5de5\u5177\u5bf9\u4e8e\u652f\u6301\u8d1f\u8d23\u4efb\u7684AI\u5f00\u53d1\u548c\u76d1\u7ba1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.14295", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14295", "abs": "https://arxiv.org/abs/2507.14295", "authors": ["Licheng Liu", "Zihan Wang", "Linjie Li", "Chenwei Xu", "Yiping Lu", "Han Liu", "Avirup Sil", "Manling Li"], "title": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "comment": null, "summary": "Multi-turn problem solving is critical yet challenging for Large Reasoning\nModels (LRMs) to reflect on their reasoning and revise from feedback. Existing\nReinforcement Learning (RL) methods train large reasoning models on a\nsingle-turn paradigm with verifiable rewards. However, we observe that models\ntrained with existing RL paradigms often lose their ability to solve problems\nacross multiple turns and struggle to revise answers based on contextual\nfeedback, leading to repetitive responses. We ask: can LRMs learn to reflect\ntheir answers in a multi-turn context? In this work, we find that training\nmodels with multi-turn RL using only unary feedback (e.g., \"Let's try again\")\nafter wrong answers can improve both single-turn performance and multi-turn\nreasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement\nlearning, which uses minimal yet common unary user feedback during iterative\nproblem solving. It can be easily applied to existing single-turn RL training\nsetups. Experimental results show that RL training with UFO keeps single-turn\nperformance and improves multi-turn reasoning accuracy by up to 14%, enabling\nlanguage models to better react to feedback in multi-turn problem solving. To\nfurther minimize the number of turns needed for a correct answer while\nencouraging diverse reasoning when mistakes occur, we design reward structures\nthat guide models to produce careful and deliberate answers in each turn. Code:\nhttps://github.com/lichengliu03/unary-feedback", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u201cUnary Feedback as Observation\u201d\uff08UFO\uff09\u6846\u67b6\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5229\u7528\u7b80\u5355\u7684\u5426\u5b9a\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u95ee\u9898\u89e3\u51b3\u548c\u54cd\u5e94\u53cd\u9988\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5355\u8f6e\u8303\u5f0f\u4e2d\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u591a\u8f6e\u63a8\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u96be\u4ee5\u6839\u636e\u4e0a\u4e0b\u6587\u53cd\u9988\u8fdb\u884c\u4fee\u6b63\uff0c\u4ece\u800c\u4ea7\u751f\u91cd\u590d\u6027\u54cd\u5e94\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3LRM\u5728\u591a\u8f6e\u4e0a\u4e0b\u6587\u4e2d\u53cd\u601d\u548c\u4fee\u6b63\u7b54\u6848\u7684\u80fd\u529b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cUnary Feedback as Observation\u201d\uff08UFO\uff09\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u4ec5\u5305\u542b\u5426\u5b9a\u53cd\u9988\u7684\u5355\u8f6e\u53cd\u9988\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u73b0\u6709\u7684\u5355\u8f6e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8bbe\u7f6e\u4e2d\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u5956\u52b1\u7ed3\u6784\u6765\u6307\u5bfc\u6a21\u578b\u5728\u6bcf\u4e2a\u56de\u5408\u4e2d\u751f\u6210\u8c28\u614e\u548c\u6df1\u601d\u719f\u8651\u7684\u7b54\u6848\uff0c\u4ee5\u5c3d\u91cf\u51cf\u5c11\u83b7\u5f97\u6b63\u786e\u7b54\u6848\u6240\u9700\u7684\u56de\u5408\u6570\u5e76\u9f13\u52b1\u5728\u51fa\u73b0\u9519\u8bef\u65f6\u8fdb\u884c\u591a\u6837\u5316\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528UFO\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u53ef\u4ee5\u4fdd\u6301\u6a21\u578b\u7684\u5355\u8f6e\u6027\u80fd\uff0c\u5e76\u5c06\u591a\u8f6e\u63a8\u7406\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe14%\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u54cd\u5e94\u591a\u8f6e\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u53cd\u9988\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f7f\u7528\u4ec5\u5305\u542b\u5426\u5b9a\u53cd\u9988\uff08\u4f8b\u5982\uff0c\u201c\u8ba9\u6211\u4eec\u518d\u8bd5\u4e00\u6b21\u201d\uff09\u7684\u5355\u8f6e\u53cd\u9988\u53ef\u4ee5\u63d0\u9ad8\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u7684\u5355\u8f6e\u6027\u80fd\u548c\u591a\u8f6e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u8fd8\u80fd\u8ba9\u6a21\u578b\u66f4\u597d\u5730\u54cd\u5e94\u591a\u8f6e\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u53cd\u9988\u3002"}}
{"id": "2507.15052", "categories": ["cond-mat.mtrl-sci", "cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.15052", "abs": "https://arxiv.org/abs/2507.15052", "authors": ["Suman Mahakal", "Pallabi Sardar", "Diptasikha Das", "Subrata Jana", "Swapnava Mukherjee", "Biplab Ghosh", "Shamima Hussain", "Santanu K. Maiti", "Kartick Malik"], "title": "Anomalous Power Factor Enhancement and Local Structural Transition in Ni-Doped TiCoSb", "comment": "Main article (15 pages, 13 figures), Supplemental article (15 pages,\n  9 figures), Comments are welcome", "summary": "We report a significant enhancement (~269%) in the power factor (PF) and a\nlocal structural transition in Ni-doped TiCoSb samples (TiCo_{1-x}Ni_xSb, (x=\n0.0, 0.01, 0.02, 0.03, 0.04, and 0.06). First-principles calculations reveal\nthat even minute Ni doping induces a substantial shift in the Fermi level (EF)\nand alters the density of states (DOS). Structural analysis via Rietveld\nrefinement of X-ray diffraction (XRD) data shows anomalous behavior at x =\n0.02, supported by Williamson-Hall and modified methods. X-ray absorption\nspectroscopy (XAS) at the Ti and Co K-edges further confirms a pronounced local\nstructural change at this composition. These structural transitions are\nconsistent with temperature-dependent resistivity (\\rho(T)) and thermopower\n(S(T)) data, which reflect changes in EF and disorder. Analysis of Lorentz\nnumber and scattering parameters reinforces the observed modifications in the\nelectronic structure. The simultaneous enhancement of S and electrical\nconductivity at x = 0.02 is attributed to the disorder-to-order transition,\nleading to the marked rise in PF.", "AI": {"tldr": "Ni\u63ba\u6742TiCoSb\u53ef\u5927\u5e45\u63d0\u9ad8\u529f\u7387\u56e0\u5b50\uff0c\u901a\u8fc7\u8c03\u63a7\u5c40\u90e8\u7ed3\u6784\u548c\u7535\u5b50\u6027\u8d28\u5b9e\u73b0\u3002", "motivation": "\u7814\u7a76Ni\u63ba\u6742\u5bf9TiCoSb\u529f\u7387\u56e0\u5b50\u7684\u589e\u5f3a\u673a\u5236\uff0c\u63ed\u793a\u5176\u7ed3\u6784\u8f6c\u53d8\u548c\u7535\u5b50\u7ed3\u6784\u53d8\u5316\u3002", "method": "\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u3001X\u5c04\u7ebf\u884d\u5c04\uff08XRD\uff09\u6570\u636eRietveld\u7cbe\u4fee\u3001Williamson-Hall\u548c\u4fee\u6b63\u65b9\u6cd5\u3001Ti\u548cCo K\u8fb9X\u5c04\u7ebf\u5438\u6536\u5149\u8c31\uff08XAS\uff09\u3001\u4ee5\u53ca\u6e29\u5ea6\u76f8\u5173\u7535\u963b\u7387\uff08\u03c1(T)\uff09\u548c\u70ed\u7535\u52bf\uff08S(T)\uff09\u6570\u636e\u5206\u6790\uff0c\u7814\u7a76Ni\u63ba\u6742\u5bf9TiCoSb\u7684\u7ed3\u6784\u548c\u7535\u5b50\u6027\u8d28\u7684\u5f71\u54cd\u3002", "result": "Ni\u63ba\u6742\uff08x=0.02\uff09\u5f15\u8d77\u8d39\u7c73\u80fd\u7ea7\uff08EF\uff09\u79fb\u52a8\u548c\u6001\u5bc6\u5ea6\uff08DOS\uff09\u6539\u53d8\uff0c\u5bfc\u81f4\u5c40\u90e8\u7ed3\u6784\u8f6c\u53d8\uff0c\u529f\u7387\u56e0\u5b50\uff08PF\uff09\u663e\u8457\u63d0\u9ad8\u7ea6269%\u3002", "conclusion": "Ni\u63ba\u6742TiCoSb\u6837\u54c1\uff08TiCo_{1-x}Ni_xSb\uff0cx=0.0, 0.01, 0.02, 0.03, 0.04, and 0.06\uff09\u7684\u529f\u7387\u56e0\u5b50\uff08PF\uff09\u663e\u8457\u63d0\u9ad8\uff08~269%\uff09\uff0c\u5e76\u4f34\u968f\u5c40\u90e8\u7ed3\u6784\u8f6c\u53d8\u3002"}}
{"id": "2507.15167", "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15167", "abs": "https://arxiv.org/abs/2507.15167", "authors": ["Nan An", "Mingtong Chen", "Zhengbao Yang"], "title": "A New Ultrafast Printer for Large-Scale Assembly of Piezoelectric Biomaterials", "comment": null, "summary": "We propose a modular, fast and large-area fabrication of bio-piezoelectric\nfilms. The technique is based on the formation of cone-jet mode by applying a\nhigh voltage electric field to conductive spiked metal disks. And the\nself-assembly process of biomolecular materials through nanoconfinement with\nin-situ poling effect. This job achieved print speeds of up to 9.2 109 um3/s\nwith a combination of only 2 printheads. At the same time, the modular design\nallows the MLSP to achieve theoretically unlimited print efficiency. It also\nprovides flexible configuration options for different printing needs, such as\npreparing films of different areas and shapes. In short, MLSP demonstrates the\nability of piezoelectric biomaterials to undergo ultra-fast, large-scale\nassembly. Demonstrates good potential as a universally applicable bio-device\nfor the fabrication of bio-piezoelectric films", "AI": {"tldr": "\u4e00\u79cd\u5229\u7528\u9525\u5f62\u5c04\u6d41\u548c\u7eb3\u7c73\u9650\u5236\u81ea\u7ec4\u88c5\u6280\u672f\uff0c\u5b9e\u73b0\u8d85\u5feb\u3001\u5927\u9762\u79ef\u751f\u7269\u538b\u7535\u8584\u819c\u5236\u9020\u7684\u65b9\u6cd5\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5b9e\u73b0\u4e00\u79cd\u6a21\u5757\u5316\u3001\u5feb\u901f\u548c\u5927\u9762\u79ef\u7684\u751f\u7269\u538b\u7535\u8584\u819c\u5236\u9020\u6280\u672f\u3002", "method": "\u901a\u8fc7\u5c06\u9ad8\u7535\u538b\u7535\u573a\u65bd\u52a0\u5230\u5bfc\u7535\u5c16\u523a\u91d1\u5c5e\u5706\u76d8\u4e0a\u5f62\u6210\u9525\u5f62\u5c04\u6d41\u6a21\u5f0f\uff0c\u5e76\u7ed3\u5408\u7eb3\u7c73\u9650\u5236\u4e0b\u7684\u751f\u7269\u5206\u5b50\u6750\u6599\u81ea\u7ec4\u88c5\u8fc7\u7a0b\u548c\u539f\u4f4d\u6781\u5316\u6548\u5e94\uff0c\u5b9e\u73b0\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u3001\u5feb\u901f\u548c\u5927\u9762\u79ef\u7684\u751f\u7269\u538b\u7535\u8584\u819c\u5236\u9020\u6280\u672f\u3002", "result": "\u8be5\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u8fbe 9.2 x 10^9 um^3/s \u7684\u6253\u5370\u901f\u5ea6\uff0c\u5e76\u4e14\u6a21\u5757\u5316\u8bbe\u8ba1\u5141\u8bb8 MLSP \u5b9e\u73b0\u7406\u8bba\u4e0a\u65e0\u9650\u7684\u6253\u5370\u6548\u7387\uff0c\u540c\u65f6\u4e3a\u4e0d\u540c\u6253\u5370\u9700\u6c42\u63d0\u4f9b\u7075\u6d3b\u7684\u914d\u7f6e\u9009\u9879\u3002", "conclusion": "MLSP\u5c55\u793a\u4e86\u538b\u7535\u751f\u7269\u6750\u6599\u8fdb\u884c\u8d85\u5feb\u3001\u5927\u89c4\u6a21\u7ec4\u88c5\u7684\u80fd\u529b\uff0c\u5e76\u4f5c\u4e3a\u751f\u7269\u538b\u7535\u8584\u819c\u5236\u9020\u7684\u901a\u7528\u751f\u7269\u5236\u9020\u65b9\u6cd5\u5177\u6709\u826f\u597d\u6f5c\u529b\u3002"}}
{"id": "2507.14839", "categories": ["quant-ph", "cs.CR", "C.2.4; E.1"], "pdf": "https://arxiv.org/pdf/2507.14839", "abs": "https://arxiv.org/abs/2507.14839", "authors": ["Ruwanga Konara", "Kasun De Zoysa", "Anuradha Mahasinghe", "Asanka Sayakkara", "Nalin Ranasinghe"], "title": "Time Entangled Quantum Blockchain with Phase Encoding for Classical Data", "comment": null, "summary": "With rapid advancements in quantum computing, it is widely believed that\nthere will be quantum hardware capable of compromising classical cryptography\nand hence, the internet and the current information security infrastructure in\nthe coming decade. This is mainly due to the operational realizations of\nquantum algorithms such as Grover and Shor, to which the current classical\nencryption protocols are vulnerable. Blockchains, i.e., blockchain data\nstructures and their data, rely heavily on classical cryptography. One approach\nto secure blockchain is to attempt to achieve information theoretical security\nby defining blockchain on quantum technologies. There have been two\nconceptualizations of blockchains on quantum registers: the time-entangled\nGreenberger-Horne-Zeilinger (GHZ) state blockchain and the quantum hypergraph\nblockchain. On our part, an attempt is made to conceptualize a new quantum\nblockchain combining features of both these schemes to achieve the absolute\nsecurity of the time-temporal GHZ blockchain and the scalability and efficiency\nof the quantum hypergraph blockchain in the proposed quantum blockchain\nprotocol.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u79cd\u73b0\u6709\u91cf\u5b50\u533a\u5757\u94fe\u65b9\u6848\u4f18\u70b9\u7684\u6df7\u5408\u91cf\u5b50\u533a\u5757\u94fe\u534f\u8bae\uff0c\u4ee5\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5e26\u6765\u7684\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u73b0\u6709\u7684\u7ecf\u5178\u52a0\u5bc6\u534f\u8bae\u9762\u4e34\u88ab\u7834\u89e3\u7684\u98ce\u9669\uff0c\u8fd9\u5c06\u5a01\u80c1\u5230\u4fe1\u606f\u5b89\u5168\u3002\u533a\u5757\u94fe\u6280\u672f\u4e25\u91cd\u4f9d\u8d56\u7ecf\u5178\u52a0\u5bc6\uff0c\u56e0\u6b64\u9700\u8981\u91cf\u5b50\u6280\u672f\u6765\u4fdd\u969c\u5176\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u533a\u5757\u94fe\u534f\u8bae\uff0c\u7ed3\u5408\u4e86\u65f6\u95f4\u7ea0\u7f20GHZ\u72b6\u6001\u533a\u5757\u94fe\u7684\u7edd\u5bf9\u5b89\u5168\u6027\u548c\u91cf\u5b50\u8d85\u56fe\u533a\u5757\u94fe\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6548\u7387\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u533a\u5757\u94fe\u534f\u8bae\uff0c\u65e8\u5728\u5b9e\u73b0\u65f6\u95f4\u7ea0\u7f20GHZ\u72b6\u6001\u533a\u5757\u94fe\u7684\u7edd\u5bf9\u5b89\u5168\u6027\u548c\u91cf\u5b50\u8d85\u56fe\u533a\u5757\u94fe\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u65f6\u95f4\u7ea0\u7f20GHZ\u72b6\u6001\u533a\u5757\u94fe\u548c\u91cf\u5b50\u8d85\u56fe\u533a\u5757\u94fe\u4f18\u70b9\u7684\u91cf\u5b50\u533a\u5757\u94fe\u534f\u8bae\u3002"}}
{"id": "2507.14579", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14579", "abs": "https://arxiv.org/abs/2507.14579", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models", "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 5 pages", "summary": "Detecting collaborative problem solving (CPS) indicators from dialogue using\nmachine learning techniques is a significant challenge for the field of AI in\nEducation. Recent studies have explored the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) models on transcription data to\nreliably detect meaningful CPS indicators. A notable advancement involved the\nmultimodal BERT variant, AudiBERT, which integrates speech and\nacoustic-prosodic audio features to enhance CPS diagnosis. Although initial\nresults demonstrated multimodal improvements, the statistical significance of\nthese enhancements remained unclear, and there was insufficient guidance on\nleveraging human-AI complementarity for CPS diagnosis tasks. This workshop\npaper extends the previous research by highlighting that the AudiBERT model not\nonly improved the classification of classes that were sparse in the dataset,\nbut it also had statistically significant class-wise improvements over the BERT\nmodel for classifications in the social-cognitive dimension. However, similar\nsignificant class-wise improvements over the BERT model were not observed for\nclassifications in the affective dimension. A correlation analysis highlighted\nthat larger training data was significantly associated with higher recall\nperformance for both the AudiBERT and BERT models. Additionally, the precision\nof the BERT model was significantly associated with high inter-rater agreement\namong human coders. When employing the BERT model to diagnose indicators within\nthese subskills that were well-detected by the AudiBERT model, the performance\nacross all indicators was inconsistent. We conclude the paper by outlining a\nstructured approach towards achieving human-AI complementarity for CPS\ndiagnosis, highlighting the crucial inclusion of model explainability to\nsupport human agency and engagement in the reflective coding process.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528 AudiBERT \u548c BERT \u6a21\u578b\u5206\u6790\u5bf9\u8bdd\u4ee5\u68c0\u6d4b\u534f\u4f5c\u95ee\u9898\u89e3\u51b3 (CPS) \u6307\u6807\u3002AudiBERT \u5728\u67d0\u4e9b\u65b9\u9762\u4f18\u4e8e BERT\uff0c\u5c24\u5176\u662f\u5728\u7a00\u758f\u7c7b\u522b\u548c\u793e\u4f1a\u8ba4\u77e5\u6307\u6807\u4e0a\u3002\u6a21\u578b\u6027\u80fd\u4e0e\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u4eba\u5de5\u6807\u6ce8\u4e00\u81f4\u6027\u76f8\u5173\u3002\u7814\u7a76\u8fd8\u5f3a\u8c03\u4e86\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5bf9\u4e8e\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\u4ee5\u6539\u8fdb CPS \u8bca\u65ad\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u6559\u80b2\u9886\u57df\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u68c0\u6d4b\u5bf9\u8bdd\u4e2d\u534f\u4f5c\u95ee\u9898\u89e3\u51b3 (CPS) \u6307\u6807\u7684\u6311\u6218\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22 AudiBERT \u7b49\u591a\u6a21\u6001\u6a21\u578b\u76f8\u5bf9\u4e8e BERT \u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5e76\u4e3a\u5b9e\u73b0\u4eba\u673a\u4e92\u8865\u4ee5\u6539\u8fdb CPS \u8bca\u65ad\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528 AudiBERT \u548c BERT \u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u4e86\u8bed\u97f3\u548c\u58f0\u5b66-\u97f5\u5f8b\u97f3\u9891\u7279\u5f81\uff0c\u4ee5\u68c0\u6d4b\u5bf9\u8bdd\u4e2d\u7684\u534f\u4f5c\u95ee\u9898\u89e3\u51b3 (CPS) \u6307\u6807\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u76f8\u5173\u6027\u5206\u6790\uff0c\u4ee5\u786e\u5b9a\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u8bc4\u5206\u8005\u95f4\u4e00\u81f4\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0 AudiBERT \u6a21\u578b\u5728\u5206\u7c7b\u7a00\u758f\u7c7b\u522b\u4ee5\u53ca\u793e\u4f1a\u8ba4\u77e5\u7ef4\u5ea6\u65b9\u9762\uff0c\u76f8\u6bd4 BERT \u6a21\u578b\u5728\u5206\u7c7b\u4e0a\u6709\u4e86\u7edf\u8ba1\u4e0a\u663e\u8457\u7684\u6539\u8fdb\u3002\u7136\u800c\uff0c\u5728\u60c5\u611f\u7ef4\u5ea6\u65b9\u9762\uff0c\u5e76\u672a\u89c2\u5bdf\u5230\u7c7b\u4f3c\u7684\u663e\u8457\u6539\u8fdb\u3002\u76f8\u5173\u6027\u5206\u6790\u8868\u660e\uff0c\u66f4\u5927\u7684\u8bad\u7ec3\u6570\u636e\u91cf\u4e0e\u66f4\u9ad8\u7684\u53ec\u56de\u7387\u663e\u8457\u76f8\u5173\uff0c\u800c BERT \u6a21\u578b\u7684\u7cbe\u786e\u7387\u4e0e\u8bc4\u5206\u8005\u95f4\u4e00\u81f4\u6027\u663e\u8457\u76f8\u5173\u3002\u5728\u5c06 BERT \u6a21\u578b\u5e94\u7528\u4e8e AudiBERT \u68c0\u6d4b\u6548\u679c\u8f83\u597d\u7684\u5b50\u6280\u80fd\u6307\u6807\u65f6\uff0c\u6240\u6709\u6307\u6807\u7684\u8868\u73b0\u5747\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u8be5\u8bba\u6587\u603b\u7ed3\u4e86\u4f7f\u7528 AudiBERT \u548c BERT \u6a21\u578b\u68c0\u6d4b\u534f\u4f5c\u95ee\u9898\u89e3\u51b3 (CPS) \u6307\u6807\u7684\u53d1\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u73b0\u4eba\u673a\u4e92\u8865\u4ee5\u8fdb\u884c CPS \u8bca\u65ad\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5728\u652f\u6301\u4eba\u7c7b\u80fd\u52a8\u6027\u548c\u53c2\u4e0e\u53cd\u601d\u6027\u7f16\u7801\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2507.15173", "categories": ["cs.LG", "cs.DS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.15173", "abs": "https://arxiv.org/abs/2507.15173", "authors": ["Jason Gaitonde", "Ankur Moitra", "Elchanan Mossel"], "title": "Better Models and Algorithms for Learning Ising Models from Dynamics", "comment": "49 pages", "summary": "We study the problem of learning the structure and parameters of the Ising\nmodel, a fundamental model of high-dimensional data, when observing the\nevolution of an associated Markov chain. A recent line of work has studied the\nnatural problem of learning when observing an evolution of the well-known\nGlauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Mossel STOC 2024], which provides an arguably more realistic\ngenerative model than the classical i.i.d. setting. However, this prior work\ncrucially assumes that all site update attempts are observed, \\emph{even when\nthis attempt does not change the configuration}: this strong observation model\nis seemingly essential for these approaches. While perhaps possible in\nrestrictive contexts, this precludes applicability to most realistic settings\nwhere we can observe \\emph{only} the stochastic evolution itself, a minimal and\nnatural assumption for any process we might hope to learn from. However,\ndesigning algorithms that succeed in this more realistic setting has remained\nan open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Moitra, Mossel, STOC 2025].\n  In this work, we give the first algorithms that efficiently learn the Ising\nmodel in this much more natural observation model that only observes when the\nconfiguration changes. For Ising models with maximum degree $d$, our algorithm\nrecovers the underlying dependency graph in time $\\mathsf{poly}(d)\\cdot n^2\\log\nn$ and then the actual parameters in additional $\\widetilde{O}(2^d n)$ time,\nwhich qualitatively matches the state-of-the-art even in the i.i.d. setting in\na much weaker observation model. Our analysis holds more generally for a\nbroader class of reversible, single-site Markov chains that also includes the\npopular Metropolis chain by leveraging more robust properties of reversible\nMarkov chains.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u63d0\u51fa\u4e86\u4ec5\u5728\u914d\u7f6e\u53d8\u5316\u65f6\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u94fe\u6f14\u5316\u6765\u5b66\u4e60\u4f0a\u8f9b\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7b97\u6cd5\u6548\u7387\u9ad8\uff0c\u9002\u7528\u4e8e\u66f4\u73b0\u5b9e\u7684\u573a\u666f\u3002", "motivation": "\u5148\u524d\u5173\u4e8e\u4ece\u9a6c\u5c14\u53ef\u592b\u94fe\u6f14\u5316\u4e2d\u5b66\u4e60\u4f0a\u8f9b\u6a21\u578b\u7684\u7814\u7a76\uff0c\u901a\u5e38\u5047\u8bbe\u9700\u8981\u89c2\u5bdf\u5230\u6240\u6709\u7ad9\u70b9\u66f4\u65b0\u5c1d\u8bd5\uff08\u5373\u4f7f\u6ca1\u6709\u6539\u53d8\u914d\u7f6e\uff09\uff0c\u800c\u8fd9\u79cd\u5047\u8bbe\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u96be\u4ee5\u6ee1\u8db3\u3002\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u63d0\u51fa\u4e00\u79cd\u66f4\u81ea\u7136\u7684\u5b66\u4e60\u6a21\u578b\uff0c\u5373\u4ec5\u5728\u914d\u7f6e\u53d1\u751f\u53d8\u5316\u65f6\u8fdb\u884c\u89c2\u5bdf\uff0c\u5e76\u4e3a\u8fd9\u79cd\u66f4\u73b0\u5b9e\u7684\u89c2\u6d4b\u6a21\u578b\u8bbe\u8ba1\u6709\u6548\u7684\u5b66\u4e60\u7b97\u6cd5\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5728\u4ec5\u89c2\u5bdf\u5230\u914d\u7f6e\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u4f0a\u8f9b\u6a21\u578b\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8be5\u7b97\u6cd5\u9996\u5148\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6062\u590d\u6a21\u578b\u7684\u4f9d\u8d56\u56fe\uff0c\u7136\u540e\u901a\u8fc7\u9644\u52a0\u7684\u5bf9\u6570\u65f6\u95f4\u5185\u6062\u590d\u6a21\u578b\u53c2\u6570\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u53ef\u9006\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u7a33\u5065\u6027\u8d28\uff0c\u5e76\u9002\u7528\u4e8e\u5305\u62ecMetropolis\u94fe\u5728\u5185\u7684\u66f4\u5e7f\u6cdb\u7684\u53ef\u9006\u5355\u7ad9\u70b9\u9a6c\u5c14\u53ef\u592b\u94fe\u3002", "result": "\u5bf9\u4e8e\u6700\u5927\u5ea6\u4e3ad\u7684\u4f0a\u8f9b\u6a21\u578b\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u5728 $\\mathsf{poly}(d)\\cdot n^2\\log n$ \u65f6\u95f4\u5185\u6062\u590d\u4f9d\u8d56\u56fe\uff0c\u5e76\u5728 $\\widetilde{O}(2^d n)$ \u65f6\u95f4\u5185\u6062\u590d\u53c2\u6570\u3002\u8fd9\u5728\u66f4\u5f31\u7684\u89c2\u6d4b\u6a21\u578b\u4e0b\uff0c\u5176\u6027\u80fd\u5728\u65f6\u95f4\u590d\u6742\u5ea6\u4e0a\u53ef\u4e0e\u72ec\u7acb\u540c\u5206\u5e03\uff08i.i.d.\uff09\u8bbe\u7f6e\u4e0b\u7684\u73b0\u6709\u6280\u672f\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u63d0\u51fa\u4e86\u5728\u4ec5\u89c2\u5bdf\u5230\u914d\u7f6e\u53d1\u751f\u53d8\u5316\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u6f14\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u5b66\u4e60\u4f0a\u8f9b\u6a21\u578b\uff08Ising model\uff09\u7684\u7b97\u6cd5\u3002\u5bf9\u4e8e\u6700\u5927\u5ea6\u4e3ad\u7684\u4f0a\u8f9b\u6a21\u578b\uff0c\u7b97\u6cd5\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6062\u590d\u4f9d\u8d56\u56fe\uff0c\u5e76\u5728\u9644\u52a0\u7684\u8fd1\u4f3c\u5bf9\u6570\u65f6\u95f4\u5185\u6062\u590d\u53c2\u6570\u3002\u8be5\u7b97\u6cd5\u7684\u5206\u6790\u66f4\u5e7f\u6cdb\u5730\u9002\u7528\u4e8e\u4e00\u7c7b\u53ef\u9006\u7684\u5355\u7ad9\u70b9\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u5305\u62ec\u6d41\u884c\u7684Metropolis\u94fe\uff0c\u5229\u7528\u4e86\u53ef\u9006\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u66f4\u7a33\u5065\u6027\u8d28\u3002"}}
{"id": "2507.14166", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14166", "abs": "https://arxiv.org/abs/2507.14166", "authors": ["Sankalp Jajee", "Gaurav Kumar", "Homayoun Valafar"], "title": "Automated Vigilance State Classification in Rodents Using Machine Learning and Feature Engineering", "comment": "8 pages, 5 figures", "summary": "Preclinical sleep research remains constrained by labor intensive, manual\nvigilance state classification and inter rater variability, limiting throughput\nand reproducibility. This study presents an automated framework developed by\nTeam Neural Prognosticators to classify electroencephalogram (EEG) recordings\nof small rodents into three critical vigilance states paradoxical sleep (REM),\nslow wave sleep (SWS), and wakefulness. The system integrates advanced signal\nprocessing with machine learning, leveraging engineered features from both time\nand frequency domains, including spectral power across canonical EEG bands\n(delta to gamma), temporal dynamics via Maximum-Minimum Distance, and\ncross-frequency coupling metrics. These features capture distinct\nneurophysiological signatures such as high frequency desynchronization during\nwakefulness, delta oscillations in SWS, and REM specific bursts. Validated\nduring the 2024 Big Data Health Science Case Competition (University of South\nCarolina Big Data Health Science Center, 2024), our XGBoost model achieved\n91.5% overall accuracy, 86.8% precision, 81.2% recall, and an F1 score of\n83.5%, outperforming all baseline methods. Our approach represents a critical\nadvancement in automated sleep state classification and a valuable tool for\naccelerating discoveries in sleep science and the development of targeted\ninterventions for chronic sleep disorders. As a publicly available code (BDHSC)\nresource is set to contribute significantly to advancements.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u5229\u7528EEG\u4fe1\u53f7\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u4fe1\u53f7\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff08\u7279\u522b\u662fXGBoost\u6a21\u578b\uff09\uff0c\u4ee5\u533a\u5206\u5c0f\u578b\u556e\u9f7f\u52a8\u7269\u7684REM\u3001SWS\u548c\u6e05\u9192\u72b6\u6001\u3002\u8be5\u65b9\u6cd5\u57282024\u5e74\u5927\u6570\u636e\u5065\u5eb7\u79d1\u5b66\u6848\u4f8b\u7ade\u8d5b\u4e2d\u53d6\u5f97\u4e8691.5%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6709\u671b\u52a0\u901f\u7761\u7720\u79d1\u5b66\u7814\u7a76\u548c\u5e72\u9884\u63aa\u65bd\u7684\u5f00\u53d1\u3002", "motivation": "\u4e34\u5e8a\u524d\u7761\u7720\u7814\u7a76\u53d7\u5230\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u624b\u52a8\u8b66\u89c9\u72b6\u6001\u5206\u7c7b\u548c\u8bc4\u4f30\u8005\u95f4\u53d8\u5f02\u6027\u7684\u9650\u5236\uff0c\u8fd9\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u9650\u5236\u4e86\u7814\u7a76\u901a\u91cf\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5148\u8fdb\u7684\u4fe1\u53f7\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5bf9\u5c0f\u578b\u556e\u9f7f\u52a8\u7269\u7684\u8111\u7535\u56fe\uff08EEG\uff09\u8bb0\u5f55\u8fdb\u884c\u5206\u7c7b\uff0c\u5c06\u5176\u5212\u5206\u4e3a\u4e09\u4e2a\u5173\u952e\u7684\u8b66\u89c9\u72b6\u6001\uff1a\u5f02\u7761\uff08REM\uff09\u3001\u6162\u6ce2\u7761\u7720\uff08SWS\uff09\u548c\u6e05\u9192\u3002\u8be5\u7cfb\u7edf\u5229\u7528\u4e86\u6765\u81ea\u65f6\u57df\u548c\u9891\u57df\u7684\u5de5\u7a0b\u7279\u5f81\uff0c\u5305\u62ec\u8de8\u8d8a\u7ecf\u5178EEG\u9891\u5e26\uff08\u4ecedelta\u5230gamma\uff09\u7684\u9891\u8c31\u529f\u7387\u3001\u901a\u8fc7\u6700\u5927\u6700\u5c0f\u8ddd\u79bb\u6cd5\uff08Maximum-Minimum Distance\uff09\u6355\u6349\u7684\u65f6\u95f4\u52a8\u6001\uff0c\u4ee5\u53ca\u8de8\u9891\u7387\u8026\u5408\u6307\u6807\u3002\u8fd9\u4e9b\u7279\u5f81\u80fd\u591f\u6355\u6349\u5230\u72ec\u7279\u7684\u795e\u7ecf\u751f\u7406\u5b66\u7279\u5f81\uff0c\u4f8b\u5982\u6e05\u9192\u671f\u95f4\u7684\u9ad8\u9891\u53bb\u540c\u6b65\u5316\u3001SWS\u4e2d\u7684delta\u632f\u8361\u4ee5\u53caREM\u7279\u6709\u7684\u7206\u53d1\u3002", "result": "XGBoost\u6a21\u578b\u57282024\u5e74\u5927\u6570\u636e\u5065\u5eb7\u79d1\u5b66\u6848\u4f8b\u7ade\u8d5b\uff08\u5357\u5361\u7f57\u6765\u7eb3\u5927\u5b66\u5927\u6570\u636e\u5065\u5eb7\u79d1\u5b66\u4e2d\u5fc3\uff09\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u53d6\u5f97\u4e8691.5%\u7684\u603b\u4f53\u51c6\u786e\u7387\u300186.8%\u7684\u7cbe\u786e\u7387\u300181.2%\u7684\u53ec\u56de\u7387\u548c83.5%\u7684F1\u5206\u6570\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ee3\u8868\u4e86\u81ea\u52a8\u7761\u7720\u72b6\u6001\u5206\u7c7b\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u5e76\u4e3a\u52a0\u901f\u7761\u7720\u79d1\u5b66\u7814\u7a76\u548c\u9488\u5bf9\u6162\u6027\u7761\u7720\u969c\u788d\u7684\u9776\u5411\u5e72\u9884\u63aa\u65bd\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u5de5\u5177\u3002\u516c\u5f00\u7684\u4ee3\u7801\uff08BDHSC\uff09\u8d44\u6e90\u5c06\u4e3a\u8be5\u9886\u57df\u7684\u8fdb\u6b65\u505a\u51fa\u91cd\u5927\u8d21\u732e\u3002"}}
{"id": "2507.15062", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15062", "abs": "https://arxiv.org/abs/2507.15062", "authors": ["Xinyue Zhu", "Binghao Huang", "Yunzhu Li"], "title": "Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper", "comment": "More videos can be found on our\n  website:https://binghao-huang.github.io/touch_in_the_wild/", "summary": "Handheld grippers are increasingly used to collect human demonstrations due\nto their ease of deployment and versatility. However, most existing designs\nlack tactile sensing, despite the critical role of tactile feedback in precise\nmanipulation. We present a portable, lightweight gripper with integrated\ntactile sensors that enables synchronized collection of visual and tactile data\nin diverse, real-world, and in-the-wild settings. Building on this hardware, we\npropose a cross-modal representation learning framework that integrates visual\nand tactile signals while preserving their distinct characteristics. The\nlearning procedure allows the emergence of interpretable representations that\nconsistently focus on contacting regions relevant for physical interactions.\nWhen used for downstream manipulation tasks, these representations enable more\nefficient and effective policy learning, supporting precise robotic\nmanipulation based on multimodal feedback. We validate our approach on\nfine-grained tasks such as test tube insertion and pipette-based fluid\ntransfer, demonstrating improved accuracy and robustness under external\ndisturbances. Our project page is available at\nhttps://binghao-huang.github.io/touch_in_the_wild/ .", "AI": {"tldr": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u5e26\u6709\u89e6\u89c9\u4f20\u611f\u5668\u7684\u624b\u6301\u5939\u6301\u5668\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u7ed3\u5408\u89c6\u89c9\u548c\u89e6\u89c9\u6570\u636e\uff0c\u4ee5\u63d0\u9ad8\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u5939\u6301\u5668\u7f3a\u4e4f\u89e6\u89c9\u4f20\u611f\u800c\u65e0\u6cd5\u8fdb\u884c\u7cbe\u786e\u64cd\u63a7\u7684\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u89c6\u89c9\u548c\u89e6\u89c9\u6570\u636e\u7684\u540c\u6b65\u6536\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u89c6\u89c9\u548c\u89e6\u89c9\u4fe1\u53f7\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5b83\u4eec\u5404\u81ea\u7684\u7279\u5f81\u3002\u8be5\u5b66\u4e60\u8fc7\u7a0b\u80fd\u591f\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u8fd9\u4e9b\u8868\u793a\u6301\u7eed\u5173\u6ce8\u4e0e\u7269\u7406\u4ea4\u4e92\u76f8\u5173\u7684\u63a5\u89e6\u533a\u57df\u3002", "result": "\u5728\u6d4b\u8bd5\u7ba1\u63d2\u5165\u548c\u57fa\u4e8e\u79fb\u6db2\u5668\u7684\u6d41\u4f53\u8f93\u9001\u7b49\u7cbe\u7ec6\u4efb\u52a1\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8bc1\u660e\u4e86\u5728\u5916\u90e8\u5e72\u6270\u4e0b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u5f97\u5230\u4e86\u63d0\u9ad8\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u7b56\u7565\u5b66\u4e60\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u96c6\u6210\u4e86\u89e6\u89c9\u4f20\u611f\u5668\u7684\u4fbf\u643a\u5f0f\u3001\u8f7b\u91cf\u5316\u5939\u6301\u5668\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6574\u5408\u89c6\u89c9\u548c\u89e6\u89c9\u4fe1\u53f7\uff0c\u4ece\u800c\u5728\u6293\u53d6\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u63d0\u9ad8\u7cbe\u786e\u5ea6\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14505", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14505", "abs": "https://arxiv.org/abs/2507.14505", "authors": ["Jiahao Ma", "Tianyu Wang", "Miaomiao Liu", "David Ahmedt-Aristizabal", "Chuong Nguyen"], "title": "DCHM: Depth-Consistent Human Modeling for Multiview Detection", "comment": "multi-view detection, sparse-view reconstruction", "summary": "Multiview pedestrian detection typically involves two stages: human modeling\nand pedestrian localization. Human modeling represents pedestrians in 3D space\nby fusing multiview information, making its quality crucial for detection\naccuracy. However, existing methods often introduce noise and have low\nprecision. While some approaches reduce noise by fitting on costly multiview 3D\nannotations, they often struggle to generalize across diverse scenes. To\neliminate reliance on human-labeled annotations and accurately model humans, we\npropose Depth-Consistent Human Modeling (DCHM), a framework designed for\nconsistent depth estimation and multiview fusion in global coordinates.\nSpecifically, our proposed pipeline with superpixel-wise Gaussian Splatting\nachieves multiview depth consistency in sparse-view, large-scaled, and crowded\nscenarios, producing precise point clouds for pedestrian localization.\nExtensive validations demonstrate that our method significantly reduces noise\nduring human modeling, outperforming previous state-of-the-art baselines.\nAdditionally, to our knowledge, DCHM is the first to reconstruct pedestrians\nand perform multiview segmentation in such a challenging setting. Code is\navailable on the \\href{https://jiahao-ma.github.io/DCHM/}{project page}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDCHM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8d85\u50cf\u7d20\u9ad8\u65af\u6e85\u5c04\u6280\u672f\u5b9e\u73b0\u4e86\u591a\u89c6\u89d2\u6df1\u5ea6\u4e00\u81f4\u6027\uff0c\u7528\u4e8e\u5728\u7a00\u758f\u89c6\u89d2\u3001\u5927\u89c4\u6a21\u548c\u62e5\u6324\u573a\u666f\u4e0b\u7cbe\u786e\u5730\u8fdb\u884c\u884c\u4eba\u68c0\u6d4b\uff0c\u4e14\u65e0\u9700\u6602\u8d35\u6807\u6ce8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u884c\u4eba\u68c0\u6d4b\u4e2d\u5b58\u5728\u566a\u58f0\u591a\u3001\u7cbe\u5ea6\u4f4e\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u4f9d\u8d56\u6602\u8d35\u7684\u591a\u89c6\u89d23D\u6807\u6ce8\uff0c\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u4e14\u80fd\u7cbe\u786e\u5efa\u6a21\u4eba\u7c7b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6df1\u5ea6\u4e00\u81f4\u6027\u4eba\u7c7b\u5efa\u6a21\uff08DCHM\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u8d85\u50cf\u7d20\u9ad8\u65af\u6e85\u5c04\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u7a00\u758f\u89c6\u89d2\u3001\u5927\u89c4\u6a21\u548c\u62e5\u6324\u573a\u666f\u4e0b\u7684\u591a\u89c6\u89d2\u6df1\u5ea6\u4e00\u81f4\u6027\uff0c\u751f\u6210\u7cbe\u786e\u7684\u70b9\u4e91\u7528\u4e8e\u884c\u4eba\u5b9a\u4f4d\u3002", "result": "DCHM\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u7c7b\u5efa\u6a21\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\uff0c\u5e76\u5728\u884c\u4eba\u5b9a\u4f4d\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0cDCHM\u662f\u9996\u4e2a\u5728\u5982\u6b64\u5177\u6709\u6311\u6218\u6027\u7684\u8bbe\u7f6e\u4e0b\u91cd\u5efa\u884c\u4eba\u5e76\u8fdb\u884c\u591a\u89c6\u89d2\u5206\u5272\u7684\u65b9\u6cd5\u3002", "conclusion": "DCHM\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7a00\u758f\u89c6\u89d2\u3001\u5927\u89c4\u6a21\u548c\u62e5\u6324\u7684\u573a\u666f\u4e2d\u8fdb\u884c\u4e00\u81f4\u7684\u6df1\u5ea6\u4f30\u8ba1\u548c\u591a\u89c6\u89d2\u878d\u5408\uff0c\u901a\u8fc7\u8d85\u50cf\u7d20\u9ad8\u65af\u6e85\u5c04\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u70b9\u4e91\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u884c\u4eba\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u65e0\u9700\u6602\u8d35\u7684\u591a\u89c6\u89d23D\u6807\u6ce8\uff0c\u5728\u964d\u566a\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14730", "abs": "https://arxiv.org/abs/2507.14730", "authors": ["Yanjie Fu"], "title": "Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI", "comment": "4 pages; will continue to update to add more figures to describe the\n  vision;", "summary": "Generative AI, large language models, and agentic AI have emerged separately\nof urban planning. However, the convergence between AI and urban planning\npresents an interesting opportunity towards AI urban planners. This paper\nconceptualizes urban planning as a generative AI task, where AI synthesizes\nland-use configurations under geospatial, social, and human-centric\nconstraints. We survey how generative AI approaches, including VAEs, GANs,\ntransformers, and diffusion models, reshape urban design. We further identify\ncritical gaps: 1) limited research on integrating urban theory guidance, 2)\nlimited research of AI urban planning over multiple spatial resolutions or\nangularities, 3) limited research on augmenting urban design knowledge from\ndata, and 4) limited research on addressing real-world interactions. To address\nthese limitations, we outline future research directions in theory-guided\ngeneration, digital twins, and human-machine co-design, calling for a new\nsynthesis of generative intelligence and participatory urbanism.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u548c\u57ce\u5e02\u89c4\u5212\u7684\u7ed3\u5408\u6709\u671b\u5b9e\u73b0AI\u57ce\u5e02\u89c4\u5212\u5e08\u3002\u672c\u7814\u7a76\u5c06\u57ce\u5e02\u89c4\u5212\u89c6\u4e3a\u4e00\u4e2a\u751f\u6210\u5f0fAI\u4efb\u52a1\uff0c\u5e76\u63a2\u8ba8\u4e86\u73b0\u6709\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5728\u57ce\u5e02\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u3002\u8bba\u6587\u6307\u51fa\u4e86\u5f53\u524d\u7814\u7a76\u7684\u56db\u4e2a\u4e3b\u8981\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u7406\u8bba\u6307\u5bfc\u751f\u6210\u3001\u6570\u5b57\u5b6a\u751f\u548c\u4eba\u673a\u534f\u540c\u8bbe\u8ba1\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u671f\u4fc3\u8fdb\u751f\u6210\u5f0f\u667a\u80fd\u4e0e\u53c2\u4e0e\u5f0f\u57ce\u5e02\u4e3b\u4e49\u7684\u878d\u5408\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u5f0fAI\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4ee3\u7406AI\u5728\u57ce\u5e02\u89c4\u5212\u9886\u57df\u7684\u878d\u5408\u6f5c\u529b\uff0c\u4ee5\u53caAI\u57ce\u5e02\u89c4\u5212\u5e08\u7684\u53ef\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u8c03\u7814\u751f\u6210\u5f0fAI\u65b9\u6cd5\uff08\u5305\u62ecVAEs\u3001GANs\u3001Transformers\u548c\u6269\u6563\u6a21\u578b\uff09\u5728\u57ce\u5e02\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8bc6\u522b\u5f53\u524d\u7814\u7a76\u7684\u5c40\u9650\u6027\uff1a1)\u6574\u5408\u57ce\u5e02\u7406\u8bba\u6307\u5bfc\u7684\u7814\u7a76\u6709\u9650\uff1b2)AI\u57ce\u5e02\u89c4\u5212\u5728\u591a\u7a7a\u95f4\u5206\u8fa8\u7387\u6216\u89d2\u5ea6\u4e0a\u7684\u7814\u7a76\u6709\u9650\uff1b3)\u4ece\u6570\u636e\u4e2d\u589e\u5f3a\u57ce\u5e02\u8bbe\u8ba1\u77e5\u8bc6\u7684\u7814\u7a76\u6709\u9650\uff1b4)\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4ea4\u4e92\u7684\u7814\u7a76\u6709\u9650\u3002", "result": "\u63d0\u51fa\u4e86\u5c06\u57ce\u5e02\u89c4\u5212\u89c6\u4e3a\u751f\u6210\u5f0fAI\u4efb\u52a1\uff0cAI\u53ef\u6839\u636e\u5404\u79cd\u7ea6\u675f\u5408\u6210\u571f\u5730\u5229\u7528\u914d\u7f6e\u3002\u786e\u5b9a\u4e86\u73b0\u6709\u7814\u7a76\u7684\u56db\u4e2a\u5173\u952e\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u7406\u8bba\u6307\u5bfc\u7684\u751f\u6210\u3001\u6570\u5b57\u5b6a\u751f\u548c\u4eba\u673a\u534f\u540c\u8bbe\u8ba1\uff0c\u4ee5\u671f\u5b9e\u73b0\u751f\u6210\u5f0f\u667a\u80fd\u548c\u53c2\u4e0e\u5f0f\u57ce\u5e02\u4e3b\u4e49\u7684\u7ed3\u5408\u3002", "conclusion": "AI\u5728\u57ce\u5e02\u89c4\u5212\u9886\u57df\u7684\u878d\u5408\u5e26\u6765\u4e86\u65b0\u7684\u673a\u9047\uff0c\u65e8\u5728\u5b9e\u73b0AI\u57ce\u5e02\u89c4\u5212\u5e08\u3002\u5c06\u57ce\u5e02\u89c4\u5212\u6982\u5ff5\u5316\u4e3a\u751f\u6210\u5f0fAI\u4efb\u52a1\uff0cAI\u53ef\u4ee5\u5728\u5730\u7f18\u7a7a\u95f4\u3001\u793e\u4f1a\u548c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u7ea6\u675f\u4e0b\u5408\u6210\u571f\u5730\u5229\u7528\u914d\u7f6e\u3002"}}
{"id": "2507.15180", "categories": ["cond-mat.mtrl-sci", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15180", "abs": "https://arxiv.org/abs/2507.15180", "authors": ["Deep Patel"], "title": "Quantum Mechanical Study of the Electronic Structure and Thermoelectric Properties of Heusler Alloys", "comment": null, "summary": "Heusler alloys were discovered in 1903, and materials with half-metallic\ncharacteristics have drawn more attention from researchers since the advances\nin semiconductor industry. Heusler alloys have found application as\nspin-filters, tunnel junctions or giant magnetoresistance (GMR) devices in\ntechnological applications. In this work, the electronic structures, phonon\ndispersion, thermal properties, and electrical conductivities of PdMnSn and six\nnovel alloys (AuCrSn, AuMnGe, Au2MnSn, Cu2NiGe, Pd2NiGe and Pt2CoSn) along with\ntheir magnetic moments are studied using ab initio calculations to understand\nthe roots of half-metallicity in these alloys of Heusler family. From the\nphonon dispersion, the thermodynamic stability of the alloys in their\nrespective phases is assessed. Phonon modes were also used to further\nunderstand the electrical transport in the crystals of these seven alloys. This\nstudy evaluates the relationship between materials' electrical conductivity and\nminority-spin bandgap in the band structure, and it provides suggestions for\nselecting constituent elements when designing new half-metallic Heusler alloys\nof C1b and L21 structures.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e03\u79cd\u8d6b\u65af\u52d2\u5408\u91d1\u7684\u7279\u6027\uff0c\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u534a\u91d1\u5c5e\u7279\u6027\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u65b0\u578b\u5408\u91d1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u81ea\u534a\u5bfc\u4f53\u884c\u4e1a\u53d1\u5c55\u4ee5\u6765\uff0c\u5177\u6709\u534a\u91d1\u5c5e\u7279\u6027\u7684\u6750\u6599\u5f15\u8d77\u4e86\u7814\u7a76\u4eba\u5458\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\u3002\u8d6b\u65af\u52d2\u5408\u91d1\u5df2\u5728\u6280\u672f\u5e94\u7528\u4e2d\u7528\u4f5c\u81ea\u65cb\u6ee4\u6ce2\u5668\u3001\u96a7\u9053\u7ed3\u6216\u5de8\u78c1\u963b\uff08GMR\uff09\u5668\u4ef6\u3002", "method": "\u4f7f\u7528\u4ece\u5934\u7b97\u65b9\u6cd5\u7814\u7a76\u4e86PdMnSn\u548c\u4e03\u79cd\u65b0\u578b\u5408\u91d1\uff08AuCrSn\u3001AuMnGe\u3001Au2MnSn\u3001Cu2NiGe\u3001Pd2NiGe\u548cPt2CoSn\uff09\u7684\u7535\u5b50\u7ed3\u6784\u3001\u58f0\u5b50\u8272\u6563\u3001\u70ed\u529b\u5b66\u6027\u8d28\u548c\u7535\u5bfc\u7387\u53ca\u5176\u78c1\u77e9\uff0c\u4ee5\u4e86\u89e3\u8fd9\u4e9b\u8d6b\u65af\u52d2\u5bb6\u65cf\u5408\u91d1\u7684\u534a\u91d1\u5c5e\u7279\u6027\u7684\u6839\u6e90\u3002", "result": "\u901a\u8fc7\u58f0\u5b50\u8272\u6563\u8bc4\u4f30\u4e86\u5408\u91d1\u5728\u5404\u81ea\u76f8\u4e2d\u7684\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u3002\u8fd8\u5229\u7528\u58f0\u5b50\u6a21\u5f0f\u8fdb\u4e00\u6b65\u7406\u89e3\u4e86\u8fd9\u4e03\u79cd\u5408\u91d1\u6676\u4f53\u4e2d\u7684\u7535\u8f93\u8fd0\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u6750\u6599\u7684\u7535\u5bfc\u7387\u4e0e\u80fd\u5e26\u7ed3\u6784\u4e2d\u5c11\u6570\u81ea\u65cb\u5e26\u9699\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u5177\u6709C1b\u548cL21\u7ed3\u6784\u7684\u65b0\u578b\u534a\u91d1\u5c5e\u8d6b\u65af\u52d2\u5408\u91d1\u7684\u6784\u6210\u5143\u7d20\u63d0\u4f9b\u4e86\u5efa\u8bae\u3002"}}
{"id": "2507.15169", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15169", "abs": "https://arxiv.org/abs/2507.15169", "authors": ["Yuhan Dai", "Mingtong Chen", "Zhengbao Yang"], "title": "Energy consumption optimization and self-powered environmental monitoring design for low-carbon smart buildings", "comment": null, "summary": "Despite the growing emphasis on intelligent buildings as a cornerstone of\nsustainable urban development, significant energy inefficiencies persist due to\nsuboptimal design, material choices, and user behavior. The applicability of\nintegrated Building Information Modeling (BIM) and solarpowered environmental\nmonitoring systems for energy optimization in low-carbon smart buildings\nremains underexplored. Can BIM-driven design improvements, combined with\nphotovoltaic systems, achieve substantial energy savings while enabling\nself-powered environmental monitoring? This study conducts a case analysis on a\nretrofitted primary school building in Guangdong, China, utilizing BIM-based\nenergy simulations, material optimization, and solar technology integration.\nThe outcomes reveal that the proposed approach reduced annual energy\nconsumption by 40.68%, with lighting energy use decreasing by 36.59%. A rooftop\nphotovoltaic system demonstrated a payback period of 7.46 years while powering\nenvironmental sensors autonomously. Hardware system integrates sensors and an\nARDUINO-based controller to detect environmental factors like rainfall,\ntemperature, and air quality. It is powered by a 6W solar panel and a 2200\nmAh/7.4 V lithium battery to ensure stable operation. This study underscores\nthe potential of BIM and solar energy integration to transform traditional\nbuildings into energy-efficient, self-sustaining smart structures. Further\nresearch can expand the scalability of these methods across diverse climates\nand building typologies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14866", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.14866", "abs": "https://arxiv.org/abs/2507.14866", "authors": ["Manuel Calixto", "Julio Guerrero"], "title": "Wigner quasi-probability distribution for symmetric multi-quDit systems and their generalized heat kernel", "comment": "15 pages, 20 figures", "summary": "For a symmetric $N$-quDit system described by a density matrix $\\rho$, we\nconstruct a one-parameter $s$ family $\\mathcal{F}^{(s)}_\\rho$ of\nquasi-probability distributions through generalized Fano multipole operators\nand Stratonovich-Weyl kernels. The corresponding phase space is the complex\nprojective ${C}P^{D-1}=U(D)/U(D-1)\\times U(1)$, related to fully symmetric\nirreducible representations of the unitary group $U(D)$. For the particular\ncases $D=2$ (qubits) and $D=3$ (qutrits), we analyze the phase-space structure\nof Schr\\\"odinger $U(D)$-spin cat (parity adapted coherent) states and we\nprovide plots of the corresponding Wigner $\\mathcal{F}^{(0)}_\\rho$ function. We\nexamine the connection between non-classical behavior and the negativity of the\nWigner function. We also compute the generalized heat kernel relating two\nquasi-probability distributions $\\mathcal{F}^{(s)}_\\rho$ and\n$\\mathcal{F}^{(s')}_\\rho$, with $t=(s'-s)/2$ playing the role of ``time'',\ntogether with their twisted Moyal product in terms of a trikernel. In the\nthermodynamic limit $N\\to\\infty$, we recover the usual Gaussian smoothing for\n$s'>s$. A diagramatic interpretation of the phase-space construction in terms\nof Young tableaux is also provided.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2aN-\u8c31\u7cfb\u7edf$\rho$\u7684\u51c6\u6982\u7387\u5206\u5e03\u65cf$\frac{\rho$\uff0c\u5206\u6790\u4e86\u5176\u76f8\u7a7a\u95f4\u7ed3\u6784\u548cWigner\u51fd\u6570\uff0c\u63a2\u8ba8\u4e86\u975e\u7ecf\u5178\u884c\u4e3a\u4e0eWigner\u51fd\u6570\u8d1f\u503c\u95f4\u7684\u8054\u7cfb\uff0c\u5e76\u8ba1\u7b97\u4e86\u5e7f\u4e49\u70ed\u6838\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u5bf9\u79f0N-\u8c31\u7cfb\u7edf$\rho$\u7684\u51c6\u6982\u7387\u5206\u5e03\u65cf$\frac{\rho$\uff0c\u5e76\u5206\u6790\u5176\u76f8\u7a7a\u95f4\u7ed3\u6784\uff0c\u7279\u522b\u662f\u7814\u7a76\u975e\u7ecf\u5178\u884c\u4e3a\u4e0eWigner\u51fd\u6570\u8d1f\u503c\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u901a\u8fc7\u5e7f\u4e49Fano\u591a\u6781\u7b97\u5b50\u548cStratonovich-Weyl\u6838\u6784\u5efa\u4e86\u4e00\u4e2a\u5bf9\u79f0N-\u8c31\u7cfb\u7edf$\rho$\u7684\u4e00\u53c2\u6570s\u51c6\u6982\u7387\u5206\u5e03\u65cf$\frac{\rho$. \u7814\u7a76\u5206\u6790\u4e86D=2\u548cD=3\u91cf\u5b50\u6bd4\u7279\u548c\u91cf\u5b50\u4e09\u5143\u6001\u7684\u76f8\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u7ed8\u5236\u4e86\u76f8\u5e94\u7684Wigner\u51fd\u6570$\rho$\u3002\u7814\u7a76\u8fd8\u8ba1\u7b97\u4e86\u5e7f\u4e49\u70ed\u6838\uff0c\u5b83\u8054\u7cfb\u4e86\u4e24\u4e2a\u51c6\u6982\u7387\u5206\u5e03$\rho$\u548c$\rho'$\uff0c\u5176\u4e2dt=(s'-s)/2\u626e\u6f14\u201c\u65f6\u95f4\u201d\u7684\u89d2\u8272\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u4e09\u6838\u8868\u793a\u4e0b\u7684\u626d\u66f2Moyal\u79ef\u3002\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u7528Young\u56fe\u8868\u5bf9\u76f8\u7a7a\u95f4\u6784\u9020\u7684\u56fe\u793a\u89e3\u91ca\u3002", "result": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5bf9\u79f0N-\u8c31\u7cfb\u7edf$\rho$\u7684\u4e00\u53c2\u6570s\u51c6\u6982\u7387\u5206\u5e03\u65cf$\frac{\rho$\uff0c\u5206\u6790\u4e86D=2\u548cD=3\u91cf\u5b50\u6bd4\u7279\u548c\u91cf\u5b50\u4e09\u5143\u6001\u7684\u76f8\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u7ed8\u5236\u4e86\u76f8\u5e94\u7684Wigner\u51fd\u6570$\rho$\u3002\u7814\u7a76\u8fd8\u8ba1\u7b97\u4e86\u5e7f\u4e49\u70ed\u6838\uff0c\u5e76\u53d1\u73b0\u5b83\u5728\u70ed\u529b\u5b66\u6781\u9650N\u2192\u221e\u4e0b\u6062\u590d\u4e86\u901a\u5e38\u7684\u9ad8\u65af\u5e73\u6ed1\u3002\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u7528Young\u56fe\u8868\u5bf9\u76f8\u7a7a\u95f4\u6784\u9020\u7684\u56fe\u793a\u89e3\u91ca\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5bf9\u79f0N-\u8c31\u7cfb\u7edf\u63d0\u51fa\u4e86\u4e00\u4e2a\u7531\u5e7f\u4e49Fano\u591a\u6781\u7b97\u5b50\u548cStratonovich-Weyl\u6838\u6784\u6210\u7684\u4e00\u53c2\u6570s\u51c6\u6982\u7387\u5206\u5e03\u65cf$\rho$\u3002\u7814\u7a76\u5206\u6790\u4e86D=2\uff08\u91cf\u5b50\u6bd4\u7279\uff09\u548cD=3\uff08\u91cf\u5b50\u4e09\u5143\uff09\u7684\u859b\u5b9a\u8c14U(D)-\u81ea\u65cb\u732b\u6001\uff08\u5076\u6570\u81ea\u9002\u5e94\u76f8\u5e72\uff09\u7684\u76f8\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u7ed8\u5236\u4e86\u76f8\u5e94\u7684Wigner $\rho$\u51fd\u6570\u3002\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u975e\u7ecf\u5178\u884c\u4e3a\u4e0eWigner\u51fd\u6570\u8d1f\u503c\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5e76\u8ba1\u7b97\u4e86\u8054\u7cfb\u4e24\u4e2a\u51c6\u6982\u7387\u5206\u5e03$\rho$\u548c$\rho'$\u7684\u5e7f\u4e49\u70ed\u6838\uff0c\u5176\u4e2dt=(s'-s)/2\u626e\u6f14\u201c\u65f6\u95f4\u201d\u7684\u89d2\u8272\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u4e09\u6838\u8868\u793a\u4e0b\u7684\u626d\u66f2Moyal\u79ef\u3002\u5728\u70ed\u529b\u5b66\u6781\u9650N\u2192\u221e\u4e0b\uff0c\u7814\u7a76\u8868\u660e\u7814\u7a76\u6062\u590d\u4e86\u901a\u5e38\u7684\u9ad8\u65af\u5e73\u6ed1\u3002\u6700\u540e\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u7528Young\u56fe\u8868\u5bf9\u76f8\u7a7a\u95f4\u6784\u9020\u7684\u56fe\u793a\u89e3\u91ca\u3002"}}
{"id": "2507.14584", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14584", "abs": "https://arxiv.org/abs/2507.14584", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption", "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 6 pages, 2 figures", "summary": "The use of Bidirectional Encoder Representations from Transformers (BERT)\nmodel and its variants for classifying collaborative problem solving (CPS) has\nbeen extensively explored within the AI in Education community. However,\nlimited attention has been given to understanding how individual tokenised\nwords in the dataset contribute to the model's classification decisions.\nEnhancing the explainability of BERT-based CPS diagnostics is essential to\nbetter inform end users such as teachers, thereby fostering greater trust and\nfacilitating wider adoption in education. This study undertook a preliminary\nstep towards model transparency and explainability by using SHapley Additive\nexPlanations (SHAP) to examine how different tokenised words in transcription\ndata contributed to a BERT model's classification of CPS processes. The\nfindings suggested that well-performing classifications did not necessarily\nequate to a reasonable explanation for the classification decisions. Particular\ntokenised words were used frequently to affect classifications. The analysis\nalso identified a spurious word, which contributed positively to the\nclassification but was not semantically meaningful to the class. While such\nmodel transparency is unlikely to be useful to an end user to improve their\npractice, it can help them not to overrely on LLM diagnostics and ignore their\nhuman expertise. We conclude the workshop paper by noting that the extent to\nwhich the model appropriately uses the tokens for its classification is\nassociated with the number of classes involved. It calls for an investigation\ninto the exploration of ensemble model architectures and the involvement of\nhuman-AI complementarity for CPS diagnosis, since considerable human reasoning\nis still required for fine-grained discrimination of CPS subskills.", "AI": {"tldr": "BERT\u6a21\u578b\u5728\u6559\u80b2\u9886\u57df\u8bca\u65ad\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\uff08CPS\uff09\u8fc7\u7a0b\u4e2d\uff0c\u4ec5\u6709\u51c6\u786e\u5206\u7c7b\u662f\u4e0d\u591f\u7684\uff0c\u8fd8\u9700\u8981\u5408\u7406\u7684\u89e3\u91ca\u3002\u672c\u7814\u7a76\u4f7f\u7528SHAP\u5206\u6790\u4e86\u8bcd\u8bed\u5bf9\u5206\u7c7b\u7684\u8d21\u732e\uff0c\u53d1\u73b0\u6a21\u578b\u6709\u65f6\u4f1a\u4f9d\u8d56\u65e0\u610f\u4e49\u7684\u8bcd\u8bed\u8fdb\u884c\u5206\u7c7b\u3002\u8fd9\u63d0\u9192\u7528\u6237\u4e0d\u8981\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\uff0c\u800c\u5e94\u7ed3\u5408\u81ea\u8eab\u4e13\u4e1a\u77e5\u8bc6\u3002\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u63a2\u7d22\u96c6\u6210\u6a21\u578b\u548c\u4eba\u673a\u4e92\u8865\uff0c\u4ee5\u66f4\u597d\u5730\u8fdb\u884cCPS\u8bca\u65ad\u3002", "motivation": "\u4e3a\u4e86\u589e\u5f3aBERT\u6a21\u578b\u5728\u6559\u80b2\u9886\u57df\u8bca\u65adCPS\u7684\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u66f4\u597d\u5730\u544a\u77e5\u6559\u5e08\u7b49\u6700\u7ec8\u7528\u6237\uff0c\u589e\u52a0\u4fe1\u4efb\u5e76\u4fc3\u8fdb\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528SHapley Additive exPlanations\uff08SHAP\uff09\u6765\u68c0\u9a8cBERT\u6a21\u578b\u5728\u5206\u7c7b\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\uff08CPS\uff09\u8fc7\u7a0b\u65f6\uff0c\u6570\u636e\u96c6\u4e2d\u4e0d\u540c\u6807\u8bb0\u5316\u8bcd\u8bed\u7684\u8d21\u732e\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8868\u73b0\u826f\u597d\u7684\u5206\u7c7b\u5e76\u4e0d\u4e00\u5b9a\u610f\u5473\u7740\u5176\u5206\u7c7b\u51b3\u7b56\u5177\u6709\u5408\u7406\u7684\u89e3\u91ca\u3002\u7279\u5b9a\u7684\u6807\u8bb0\u5316\u8bcd\u8bed\u88ab\u9891\u7e41\u7528\u4e8e\u5f71\u54cd\u5206\u7c7b\uff0c\u5e76\u4e14\u53d1\u73b0\u4e86\u4e00\u4e2a\u201c\u4f2a\u9020\u201d\u8bcd\u8bed\uff0c\u5b83\u5bf9\u5206\u7c7b\u505a\u51fa\u4e86\u79ef\u6781\u8d21\u732e\u4f46\u4e0e\u7c7b\u522b\u5728\u8bed\u4e49\u4e0a\u65e0\u610f\u4e49\u3002", "conclusion": "\u4e3a\u4e86\u5b9e\u73b0\u5bf9\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\uff08CPS\uff09\u8fc7\u7a0b\u7684\u8bca\u65ad\uff0c\u9700\u8981\u5bf9\u6a21\u578b\u8fdb\u884c\u89e3\u91ca\uff0c\u4ee5\u589e\u52a0\u6559\u5e08\u7b49\u6700\u7ec8\u7528\u6237\u7684\u4fe1\u4efb\u5e76\u4fc3\u8fdb\u5176\u5728\u6559\u80b2\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u3002\u8be5\u7814\u7a76\u4f7f\u7528SHAP\u68c0\u9a8c\u4e86BERT\u6a21\u578b\u5206\u7c7bCPS\u8fc7\u7a0b\u4e2d\u7684\u8bcd\u8bed\u8d21\u732e\u5ea6\uff0c\u53d1\u73b0\u8868\u73b0\u826f\u597d\u7684\u5206\u7c7b\u4e0d\u4e00\u5b9a\u5177\u6709\u5408\u7406\u7684\u89e3\u91ca\uff0c\u5e76\u4e14\u5b58\u5728\u4e00\u4e9b\u201c\u4f2a\u9020\u201d\u7684\u8bcd\u8bed\u3002\u867d\u7136\u6a21\u578b\u900f\u660e\u5ea6\u672c\u8eab\u53ef\u80fd\u65e0\u6cd5\u76f4\u63a5\u6539\u8fdb\u7528\u6237\u5b9e\u8df5\uff0c\u4f46\u53ef\u4ee5\u9632\u6b62\u7528\u6237\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u800c\u5ffd\u7565\u81ea\u8eab\u4e13\u4e1a\u77e5\u8bc6\u3002\u6700\u7ec8\uff0c\u8be5\u7814\u7a76\u6307\u51fa\u6a21\u578b\u5bf9\u8bcd\u8bed\u7684\u6070\u5f53\u4f7f\u7528\u7a0b\u5ea6\u4e0e\u6d89\u53ca\u7684\u7c7b\u522b\u6570\u91cf\u6709\u5173\uff0c\u5e76\u547c\u5401\u63a2\u7d22\u96c6\u6210\u6a21\u578b\u67b6\u6784\u548c\u4eba\u673a\u4e92\u8865\u4ee5\u8fdb\u884cCPS\u8bca\u65ad\uff0c\u56e0\u4e3a\u7cbe\u7ec6\u533a\u5206CPS\u5b50\u6280\u80fd\u4ecd\u9700\u8981\u5927\u91cf\u4eba\u7c7b\u63a8\u7406\u3002"}}
{"id": "2507.14167", "categories": ["eess.SP", "cs.IR", "cs.LG", "62H05, 65-11, 94-11", "E.0; H.1.1; I.2.6; I.5.4"], "pdf": "https://arxiv.org/pdf/2507.14167", "abs": "https://arxiv.org/abs/2507.14167", "authors": ["Lucas Heublein", "Christian Wielenberg", "Thorsten Nowak", "Tobias Feigl", "Christopher Mutschler", "Felix Ott"], "title": "Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization", "comment": "6 pages, 10 figures", "summary": "Jamming devices disrupt signals from the global navigation satellite system\n(GNSS) and pose a significant threat by compromising the reliability of\naccurate positioning. Consequently, the detection and localization of these\ninterference signals are essential to achieve situational awareness, mitigating\ntheir impact, and implementing effective counter-measures. Classical Angle of\nArrival (AoA) methods exhibit reduced accuracy in multipath environments due to\nsignal reflections and scattering, leading to localization errors.\nAdditionally, AoA-based techniques demand substantial computational resources\nfor array signal processing. In this paper, we propose a novel approach for\ndetecting and classifying interference while estimating the distance, azimuth,\nand elevation of jamming sources. Our benchmark study evaluates 128 vision\nencoder and time-series models to identify the highest-performing methods for\neach task. We introduce an attention-based fusion framework that integrates\nin-phase and quadrature (IQ) samples with Fast Fourier Transform (FFT)-computed\nspectrograms while incorporating 22 AoA features to enhance localization\naccuracy. Furthermore, we present a novel dataset of moving jamming devices\nrecorded in an indoor environment with dynamic multipath conditions and\ndemonstrate superior performance compared to state-of-the-art methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408IQ\u6837\u672c\u548cFFT\u9891\u8c31\u56fe\u5e76\u7ed3\u5408AoA\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u5b9a\u4f4dGNSS\u5e72\u6270\u6e90\uff0c\u5e76\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5e72\u6270\u8bbe\u5907\uff08\u5982GNSS\u5e72\u6270\u5668\uff09\u5bf9\u7cbe\u786e\u5b9a\u4f4d\u7684\u5a01\u80c1\uff0c\u63d0\u9ad8\u6001\u52bf\u611f\u77e5\u80fd\u529b\u3001\u51cf\u8f7b\u5176\u5f71\u54cd\u5e76\u5b9e\u65bd\u6709\u6548\u7684\u53cd\u5236\u63aa\u65bd\uff0c\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u5b9a\u4f4d\u8fd9\u4e9b\u5e72\u6270\u4fe1\u53f7\u3002\u4f20\u7edf\u7684\u5230\u8fbe\u89d2\uff08AoA\uff09\u65b9\u6cd5\u5728\u591a\u5f84\u73af\u5883\u4e2d\u7cbe\u5ea6\u4f1a\u964d\u4f4e\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u878d\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u540c\u76f8\u548c\u6b63\u4ea4\uff08IQ\uff09\u6837\u672c\u4e0e\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\u8ba1\u7b97\u7684\u9891\u8c31\u56fe\uff0c\u5e76\u7ed3\u5408\u4e8622\u4e2a\u5230\u8fbe\u89d2\uff08AoA\uff09\u7279\u5f81\uff0c\u4ee5\u63d0\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\u3002\u901a\u8fc7\u8bc4\u4f30128\u4e2a\u89c6\u89c9\u7f16\u7801\u5668\u548c\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u6765\u9009\u62e9\u6027\u80fd\u6700\u4f73\u7684\u65b9\u6cd5\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u5728\u5305\u542b\u79fb\u52a8\u5e72\u6270\u6e90\u548c\u52a8\u6001\u591a\u5f84\u6761\u4ef6\u7684\u65b0\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u5b9a\u4f4d\u5e72\u6270\u6e90\uff0c\u5e76\u5728\u5305\u542b\u79fb\u52a8\u5e72\u6270\u6e90\u548c\u52a8\u6001\u591a\u5f84\u6761\u4ef6\u7684\u65b0\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2507.14533", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14533", "abs": "https://arxiv.org/abs/2507.14533", "authors": ["Shuo Cao", "Nan Ma", "Jiayang Li", "Xiaohui Li", "Lihao Shao", "Kaiwen Zhu", "Yu Zhou", "Yuandong Pu", "Jiarui Wu", "Jiaquan Wang", "Bo Qu", "Wenhai Wang", "Yu Qiao", "Dajuin Yao", "Yihao Liu"], "title": "ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding", "comment": "43 pages, 31 figures, 13 tables", "summary": "The rapid advancement of educational applications, artistic creation, and\nAI-generated content (AIGC) technologies has substantially increased practical\nrequirements for comprehensive Image Aesthetics Assessment (IAA), particularly\ndemanding methods capable of delivering both quantitative scoring and\nprofessional understanding. Multimodal Large Language Model (MLLM)-based IAA\nmethods demonstrate stronger perceptual and generalization capabilities\ncompared to traditional approaches, yet they suffer from modality bias\n(score-only or text-only) and lack fine-grained attribute decomposition,\nthereby failing to support further aesthetic assessment. In this paper, we\npresent:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and\nExpert-Level Understanding capabilities; (2) ArtiMuse-10K, the first\nexpert-curated image aesthetic dataset comprising 10,000 images spanning 5 main\ncategories and 15 subcategories, each annotated by professional experts with\n8-dimensional attributes analysis and a holistic score. Both the model and\ndataset will be made public to advance the field.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86ArtiMuse\uff0c\u4e00\u4e2a\u57fa\u4e8eMLLM\u7684IAA\u6a21\u578b\uff0c\u4ee5\u53caArtiMuse-10K\uff0c\u4e00\u4e2a\u5305\u542b10,000\u5f20\u56fe\u50cf\u7684\u4e13\u5bb6\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u65e8\u5728\u6539\u8fdbIAA\u7684\u91cf\u5316\u8bc4\u5206\u548c\u4e13\u4e1a\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u6559\u80b2\u5e94\u7528\u3001\u827a\u672f\u521b\u4f5c\u548cAIGC\u6280\u672f\u5728\u56fe\u50cf\u7f8e\u5b66\u8bc4\u4f30\uff08IAA\uff09\u65b9\u9762\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u9700\u8981\u80fd\u591f\u63d0\u4f9b\u91cf\u5316\u8bc4\u5206\u548c\u4e13\u4e1a\u7406\u89e3\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aArtiMuse \u7684\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u56fe\u50cf\u7f8e\u5b66\u8bc4\u4f30\uff08IAA\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u8fdb\u884c\u8054\u5408\u8bc4\u5206\u548c\u4e13\u5bb6\u7ea7\u7406\u89e3\u3002", "result": "\u6240\u63d0\u51fa\u7684ArtiMuse\u6a21\u578b\u548cArtiMuse-10K\u6570\u636e\u96c6\u80fd\u591f\u63d0\u4f9b\u66f4\u5f3a\u7684\u611f\u77e5\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u6a21\u5f0f\u504f\u5dee\u548c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u5c5e\u6027\u5206\u89e3\u7684\u95ee\u9898\uff0c\u4ece\u800c\u652f\u6301\u66f4\u6df1\u5165\u7684\u7f8e\u5b66\u8bc4\u4f30\u3002", "conclusion": " ArtiMuse-10K\u662f\u4e00\u4e2a\u5305\u542b10,000\u5f20\u56fe\u50cf\u7684\u4e13\u5bb6\u7b56\u5212\u56fe\u50cf\u7f8e\u5b66\u6570\u636e\u96c6\uff0c\u6db5\u76d65\u4e2a\u4e3b\u8981\u7c7b\u522b\u548c15\u4e2a\u5b50\u7c7b\u522b\uff0c\u5e76\u9644\u67098\u7ef4\u5c5e\u6027\u5206\u6790\u548c\u6574\u4f53\u8bc4\u5206\u3002"}}
{"id": "2507.14897", "categories": ["cs.AI", "I.2.5"], "pdf": "https://arxiv.org/pdf/2507.14897", "abs": "https://arxiv.org/abs/2507.14897", "authors": ["Renxi Wang", "Rifo Ahmad Genadi", "Bilal El Bouardi", "Yongxin Wang", "Fajri Koto", "Zhengzhong Liu", "Timothy Baldwin", "Haonan Li"], "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents", "comment": null, "summary": "Language model (LM) agents have gained significant attention for their\nability to autonomously complete tasks through interactions with environments,\ntools, and APIs. LM agents are primarily built with prompt engineering or\nsupervised finetuning. At the same time, reinforcement learning (RL) has been\nexplored to enhance LM's capabilities, such as reasoning and factuality.\nHowever, the combination of the LM agents and reinforcement learning (Agent-RL)\nremains underexplored and lacks systematic study. To this end, we built\nAgentFly, a scalable and extensible Agent-RL framework designed to empower LM\nagents with a variety of RL algorithms. Our framework supports multi-turn\ninteractions by adapting traditional RL methods with token-level masking. It\nfeatures a decorator-based interface for defining tools and reward functions,\nenabling seamless extension and ease of use. To support high-throughput\ntraining, we implement asynchronous execution of tool calls and reward\ncomputations, and design a centralized resource management system for scalable\nenvironment coordination. We also provide a suite of prebuilt tools and\nenvironments, demonstrating the framework's effectiveness through successful\nagent training across multiple tasks.", "AI": {"tldr": "AgentFly \u662f\u4e00\u4e2a\u7528\u4e8e\u8bad\u7ec3 LM \u4ee3\u7406\u7684 Agent-RL \u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u9002\u5e94 RL \u65b9\u6cd5\u548c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u63a5\u53e3\u6765\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u7684\u4e0d\u8db3\uff0c\u5e76\u901a\u8fc7\u6210\u529f\u6848\u4f8b\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9 LM \u4ee3\u7406\u548c\u5f3a\u5316\u5b66\u4e60\uff08Agent-RL\uff09\u76f8\u7ed3\u5408\u7684\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "AgentFly \u6846\u67b6\u901a\u8fc7\u4ee4\u724c\u7ea7\u63a9\u7801\u9002\u914d\u4f20\u7edf RL \u65b9\u6cd5\u6765\u652f\u6301\u591a\u56de\u5408\u4ea4\u4e92\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u88c5\u9970\u5668\u7684\u63a5\u53e3\u6765\u5b9a\u4e49\u5de5\u5177\u548c\u5956\u52b1\u51fd\u6570\u3002\u5b83\u901a\u8fc7\u5f02\u6b65\u6267\u884c\u5de5\u5177\u8c03\u7528\u548c\u5956\u52b1\u8ba1\u7b97\u4ee5\u53ca\u96c6\u4e2d\u5f0f\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u6765\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u8bad\u7ec3\u3002", "result": "AgentFly \u6210\u529f\u8bad\u7ec3\u4e86\u8de8\u591a\u4e2a\u4efb\u52a1\u7684\u4ee3\u7406\u3002", "conclusion": "AgentFly \u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684 Agent-RL \u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a LM \u4ee3\u7406\u7684\u80fd\u529b\uff0c\u5e76\u5df2\u901a\u8fc7\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u6210\u529f\u8bad\u7ec3\u4ee3\u7406\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2507.14326", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14326", "abs": "https://arxiv.org/abs/2507.14326", "authors": ["Aryana Hou", "Li Lin", "Justin Li", "Shu Hu"], "title": "Rethinking Individual Fairness in Deepfake Detection", "comment": "This paper has been accepted by ACM MM 2025", "summary": "Generative AI models have substantially improved the realism of synthetic\nmedia, yet their misuse through sophisticated DeepFakes poses significant\nrisks. Despite recent advances in deepfake detection, fairness remains\ninadequately addressed, enabling deepfake markers to exploit biases against\nspecific populations. While previous studies have emphasized group-level\nfairness, individual fairness (i.e., ensuring similar predictions for similar\nindividuals) remains largely unexplored. In this work, we identify for the\nfirst time that the original principle of individual fairness fundamentally\nfails in the context of deepfake detection, revealing a critical gap previously\nunexplored in the literature. To mitigate it, we propose the first\ngeneralizable framework that can be integrated into existing deepfake detectors\nto enhance individual fairness and generalization. Extensive experiments\nconducted on leading deepfake datasets demonstrate that our approach\nsignificantly improves individual fairness while maintaining robust detection\nperformance, outperforming state-of-the-art methods. The code is available at\nhttps://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.", "AI": {"tldr": "\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5b58\u5728\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u4e2a\u4f53\u516c\u5e73\u6027\u65b9\u9762\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u63d0\u5347\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u6846\u67b6\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6280\u672f\u5728\u516c\u5e73\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u5173\u6ce8\u4e0d\u591f\uff0c\u4f7f\u5f97\u6df1\u5ea6\u4f2a\u9020\u5236\u4f5c\u8005\u80fd\u591f\u5229\u7528\u57fa\u4e8e\u7279\u5b9a\u4eba\u7fa4\u7684\u504f\u89c1\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u96c6\u6210\u5230\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u4e2d\u7684\u901a\u7528\u6846\u67b6\uff0c\u4ee5\u589e\u5f3a\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7684\u4e2a\u4f53\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9c81\u68d2\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5728\u9886\u5148\u7684\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u65e8\u5728\u63d0\u5347\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u901a\u7528\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u5f3a\u5927\u68c0\u6d4b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u4e2a\u4f53\u516c\u5e73\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.15190", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15190", "abs": "https://arxiv.org/abs/2507.15190", "authors": ["Wei Nong", "Ruiming Zhu", "Zekun Ren", "Martin Hoffmann Petersen", "Shuya Yamazaki", "Nikita Kazeev", "Andrey Ustyuzhanin", "Gang Wu", "Shuo-Wang Yang", "Kedar Hippalgaonkar"], "title": "Energy Underprediction from Symmetry in Machine-Learning Interatomic Potentials", "comment": "15 pages, 3 figures, supplementary information included", "summary": "Machine learning interatomic potentials (MLIAPs) have emerged as powerful\ntools for accelerating materials simulations with near-density functional\ntheory (DFT) accuracy. However, despite significant advances, we identify a\ncritical yet overlooked issue undermining their reliability: a systematic\nenergy underprediction. This problem becomes starkly evident in large-scale\nthermodynamic stability assessments. By performing over 12 million calculations\nusing nine MLIAPs for over 150,000 inorganic crystals in the Materials Project,\nwe demonstrate that most frontier models consistently underpredict energy above\nhull (Ehull), a key metric for thermodynamic stability, total energy, and\nformation energy, despite the fact that over 90\\% of test structures\n(DFT-relaxed) are in the training data. The mean absolute errors (MAE) for\nEhull exceed ~30 meV/atom even by the best model, directly challenging claims\nof achieving ``DFT accuracy'' for property predictions central to materials\ndiscovery, especially related to (meta-)stability. Crucially, we trace this\nunderprediction to insufficient handling of symmetry degrees of freedom (DOF),\nconstituting both lattice symmetry and Wyckoff site symmetries for the space\ngroup. MLIAPs exhibit pronounced errors (MAE for Ehull $>$ ~40 meV/atom) in\nstructures with high symmetry DOF, where subtle atomic displacements\nsignificantly impact energy landscapes. Further analysis also indicates that\nthe MLIAPs show severe energy underprediction for a large proportion of\nnear-hull materials. We argue for improvements on symmetry-aware models such as\nexplicit DOF encoding or symmetry-regularized loss functions, and more robust\nMLIAPs for predicting crystal properties where the preservation and breaking of\nsymmetry are pivotal.", "AI": {"tldr": "MLIAP\u503e\u5411\u4e8e\u4f4e\u4f30\u6750\u6599\u80fd\u91cf\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5bf9\u79f0\u6027\u7ed3\u6784\u4e2d\uff0c\u8fd9\u662f\u7531\u4e8e\u5bf9\u5bf9\u79f0\u6027\u5904\u7406\u4e0d\u5f53\u3002\u5efa\u8bae\u6539\u8fdb\u6a21\u578b\u4ee5\u66f4\u597d\u5730\u5904\u7406\u5bf9\u79f0\u6027\u3002", "motivation": "\u6307\u51faMLIAP\u5728\u6750\u6599\u6a21\u62df\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u4e14\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\uff1a\u7cfb\u7edf\u6027\u7684\u80fd\u91cf\u4f4e\u4f30\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u8bc4\u4f30\u4e2d\uff0c\u8fd9\u5f71\u54cd\u4e86\u5176\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u5bf9Materials Project\u4e2d\u7684150,000\u591a\u79cd\u65e0\u673a\u6676\u4f53\u8fdb\u884c\u8d85\u8fc71200\u4e07\u6b21\u8ba1\u7b97\uff0c\u4f7f\u75289\u79cdMLIAP\u8bc4\u4f30\u5176\u80fd\u91cf\uff08Ehull\uff09\u3001\u603b\u80fd\u91cf\u548c\u5f62\u6210\u80fd\u3002", "result": "\u5927\u591a\u6570MLIAP\u6301\u7eed\u4f4e\u4f30\u80fd\u91cf\uff08Ehull\uff09\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u8d85\u8fc730 meV/atom\uff0c\u5373\u4f7f\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u5305\u542b90%\u4ee5\u4e0a\u7684\u6d4b\u8bd5\u7ed3\u6784\u65f6\u4e5f\u662f\u5982\u6b64\u3002\u6a21\u578b\u5728\u9ad8\u5bf9\u79f0\u6027DOF\u7ed3\u6784\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u7684\u8bef\u5dee\uff08Ehull\u7684MAE > 40 meV/atom\uff09\uff0c\u5e76\u4e25\u91cd\u4f4e\u4f30\u4e86\u8fd1hull\u6750\u6599\u7684\u80fd\u91cf\u3002", "conclusion": "MLIAPs\u5728\u6750\u6599\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u8bc4\u4f30\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u65f6\u3002\u8be5\u95ee\u9898\u6e90\u4e8e\u5bf9\u5bf9\u79f0\u6027\u81ea\u7531\u5ea6\uff08\u5305\u62ec\u6676\u683c\u5bf9\u79f0\u6027\u548c\u7a7a\u95f4\u7fa4\u7684Wyckoff\u4f4d\u70b9\u5bf9\u79f0\u6027\uff09\u5904\u7406\u4e0d\u8db3\u3002\u9ad8\u5bf9\u79f0\u6027DOF\u7684\u7ed3\u6784\u8bef\u5dee\u8f83\u5927\uff08Ehull\u7684MAE > 40 meV/atom\uff09\u3002\u8fd1hull\u6750\u6599\u4e5f\u5b58\u5728\u4e25\u91cd\u7684\u80fd\u91cf\u4f4e\u4f30\u3002\u5efa\u8bae\u5f00\u53d1\u66f4\u5f3a\u7684\u5bf9\u79f0\u6027\u611f\u77e5\u6a21\u578b\uff08\u5982\u663e\u5f0fDOF\u7f16\u7801\u6216\u5bf9\u79f0\u6027\u6b63\u5219\u5316\u635f\u5931\u51fd\u6570\uff09\uff0c\u4ee5\u53ca\u66f4\u7a33\u5065\u7684MLIAP\u6765\u9884\u6d4b\u6676\u4f53\u6027\u8d28\u3002"}}
{"id": "2507.15259", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15259", "abs": "https://arxiv.org/abs/2507.15259", "authors": ["Kyung-Bin Kwon", "Sayak Mukherjee", "Ramij R. Hossain", "Marcelo Elizondo"], "title": "Physics-Informed Learning of Proprietary Inverter Models for Grid Dynamic Studies", "comment": "7 pages, 5 figures", "summary": "This letter develops a novel physics-informed neural ordinary differential\nequations-based framework to emulate the proprietary dynamics of the inverters\n-- essential for improved accuracy in grid dynamic simulations. In current\nindustry practice, the original equipment manufacturers (OEMs) often do not\ndisclose the exact internal controls and parameters of the inverters, posing\nsignificant challenges in performing accurate dynamic simulations and other\nrelevant studies, such as gain tunings for stability analysis and controls. To\naddress this, we propose a Physics-Informed Latent Neural ODE Model (PI-LNM)\nthat integrates system physics with neural learning layers to capture the\nunmodeled behaviors of proprietary units. The proposed method is validated\nusing a grid-forming inverter (GFM) case study, demonstrating improved dynamic\nsimulation accuracy over approaches that rely solely on data-driven learning\nwithout physics-based guidance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edcODE\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u4e13\u6709\u9006\u53d8\u5668\u52a8\u6001\uff0c\u89e3\u51b3\u4e86OEM\u4e0d\u62ab\u9732\u9006\u53d8\u5668\u53c2\u6570\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u62df\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u539f\u59cb\u8bbe\u5907\u5236\u9020\u5546\uff08OEM\uff09\u901a\u5e38\u4e0d\u62ab\u9732\u9006\u53d8\u5668\u786e\u5207\u5185\u90e8\u63a7\u4ef6\u548c\u53c2\u6570\u7684\u95ee\u9898\uff0c\u8fd9\u7ed9\u6267\u884c\u51c6\u786e\u7684\u52a8\u6001\u6a21\u62df\u548c\u589e\u76ca\u8c03\u6574\u7b49\u76f8\u5173\u7814\u7a76\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u6f5c\u5728\u795e\u7ecf\u7f51\u7edcODE\u6a21\u578b\uff08PI-LNM\uff09\uff0c\u8be5\u6a21\u578b\u5c06\u7cfb\u7edf\u7269\u7406\u4e0e\u795e\u7ecf\u7f51\u7edc\u5c42\u76f8\u7ed3\u5408\uff0c\u4ee5\u6355\u83b7\u4e13\u6709\u5355\u5143\u7684\u672a\u5efa\u6a21\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u5e76\u7f51\u9006\u53d8\u5668\uff08GFM\uff09\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u4e0e\u4ec5\u4f9d\u8d56\u4e8e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u800c\u6ca1\u6709\u57fa\u4e8e\u7269\u7406\u6307\u5bfc\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8bc1\u660e\u4e86\u5176\u52a8\u6001\u6a21\u62df\u7cbe\u5ea6\u7684\u63d0\u9ad8\u3002", "conclusion": "\u4f7f\u7528\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u5e38\u5fae\u5206\u65b9\u7a0b\uff08PINODE\uff09\u7684\u6846\u67b6\u6765\u6a21\u62df\u9006\u53d8\u5668\u7684\u4e13\u6709\u52a8\u6001\uff0c\u4ee5\u63d0\u9ad8\u7535\u7f51\u52a8\u6001\u6a21\u62df\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14878", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14878", "abs": "https://arxiv.org/abs/2507.14878", "authors": ["Mao-Sheng Li", "Rafael Wagner", "Lin Zhang"], "title": "Multi-state imaginarity and coherence in qubit systems", "comment": "18+3 pages, 2 figures. Comments are welcome!", "summary": "Traditionally, the characterization of quantum resources has focused on\nindividual quantum states. Recent literature, however, has increasingly\nexplored the characterization of resources in multi-states (ordered collections\nof states indexed by a varying parameter). In this work, we provide a\nunitary-invariant framework to pinpoint imaginarity and coherence in sets of\nqubit states: we prove that Bloch vectors must be coplanar to be\nimaginarity-free and colinear to be incoherent, yielding exact rank-based tests\nof coherence and imaginarity, and closed-form bounds for existing robustness\nquantifiers, all based on two-state overlaps only. We also show that the set of\nimaginarity-free multi-states is not convex, and that third-order invariants\ncompletely characterize multi-state imaginarity of single-qubits but not of\nhigher-dimensional systems. As our main technical result, we show that every\nBargmann invariant of single-qubit states is determined (up to conjugation) by\ntwo-state overlaps. Beyond qubits, we give purity and system-agnostic coherence\nwitnesses from equality constraints on higher-order invariants and connect our\nresults to practical protocols: characterization of partial distinguishability,\nspin-chirality detection, and subchannel discrimination.", "AI": {"tldr": "This paper introduces a method to measure 'imaginarity' and 'coherence' in groups of quantum states using simple two-state comparisons. It finds that these properties are linked to the geometric arrangement of the states' representations (coplanarity and collinearity). The study also reveals that some properties are not 'convex' and that simple comparisons can determine complex properties for single quantum bits but not for larger systems. The findings have applications in distinguishing quantum states and detecting spin-chirality.", "motivation": "The motivation stems from the growing interest in characterizing resources within multi-states, moving beyond the traditional focus on individual quantum states. Specifically, this work aims to provide a precise and generalizable method for quantifying imaginarity and coherence in these multi-state systems.", "method": "This paper develops a unitary-invariant framework to characterize imaginarity and coherence in sets of qubit states. It proves that Bloch vectors must be coplanar for imaginarity-free states and colinear for incoherent states, enabling exact rank-based tests and closed-form bounds for robustness quantifiers using only two-state overlaps. The study also investigates the convexity of imaginarity-free multi-states and the role of third-order invariants, and demonstrates that all Bargmann invariants of single-qubit states are determined by two-state overlaps. Additionally, it provides purity and system-agnostic coherence witnesses through equality constraints on higher-order invariants.", "result": "The research establishes that coplanarity and collinearity of Bloch vectors are necessary and sufficient conditions for imaginarity-free and incoherent sets of qubit states, respectively. It introduces rank-based tests for coherence and imaginarity and derives closed-form bounds for robustness quantifiers using only two-state overlaps. The non-convexity of the imaginarity-free multi-state set is shown, and the complete characterization of single-qubit multi-state imaginarity by third-order invariants is demonstrated, with a limitation for higher dimensions. A key technical result is that all Bargmann invariants for single-qubit states are determined by two-state overlaps. Furthermore, purity and system-agnostic coherence witnesses are derived, linking the results to practical applications like partial distinguishability, spin-chirality detection, and subchannel discrimination.", "conclusion": "Imaginarity and coherence in multi-qubit states can be precisely characterized using unitary-invariant frameworks based on two-state overlaps. The set of imaginarity-free multi-states is not convex, and while third-order invariants characterize single-qubit multi-state imaginarity, they do not for higher-dimensional systems. All Bargmann invariants for single-qubit states are determined by two-state overlaps. The findings also extend to purity and coherence witnesses in a system-agnostic manner, with connections to partial distinguishability, spin-chirality detection, and subchannel discrimination."}}
{"id": "2507.14590", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14590", "abs": "https://arxiv.org/abs/2507.14590", "authors": ["\u0141ukasz Radli\u0144ski", "Mateusz Gu\u015bciora", "Jan Koco\u0144"], "title": "Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification", "comment": "International Conference on Computational Science 2025", "summary": "Numerous domain-specific machine learning tasks struggle with data scarcity\nand class imbalance. This paper systematically explores data augmentation\nmethods for NLP, particularly through large language models like GPT. The\npurpose of this paper is to examine and evaluate whether traditional methods\nsuch as paraphrasing and backtranslation can leverage a new generation of\nmodels to achieve comparable performance to purely generative methods. Methods\naimed at solving the problem of data scarcity and utilizing ChatGPT were\nchosen, as well as an exemplary dataset. We conducted a series of experiments\ncomparing four different approaches to data augmentation in multiple\nexperimental setups. We then evaluated the results both in terms of the quality\nof generated data and its impact on classification performance. The key\nfindings indicate that backtranslation and paraphrasing can yield comparable or\neven better results than zero and a few-shot generation of examples.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u4f7f\u7528GPT\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884cNLP\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u53cd\u5411\u7ffb\u8bd1\u548c\u91ca\u4e49\u7b49\u4f20\u7edf\u65b9\u6cd5\u5728\u751f\u6210\u6570\u636e\u548c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u65b9\u9762\uff0c\u6548\u679c\u4e0e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u751f\u6210\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3NLP\u9886\u57df\u4e2d\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5229\u7528GPT\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u53ef\u884c\u6027\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e86\u5305\u62ec\u53cd\u5411\u7ffb\u8bd1\u3001\u91ca\u4e49\u3001\u96f6\u6837\u672c\u751f\u6210\u548c\u5c11\u6837\u672c\u751f\u6210\u5728\u5185\u7684\u56db\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5728NLP\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u53cd\u5411\u7ffb\u8bd1\u548c\u91ca\u4e49\u5728\u6570\u636e\u8d28\u91cf\u548c\u5206\u7c7b\u6027\u80fd\u4e0a\u5747\u53ef\u8fbe\u5230\u4e0e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u751f\u6210\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6548\u679c\u3002", "conclusion": "GPT\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u53cd\u5411\u7ffb\u8bd1\u548c\u91ca\u4e49\u7b49\u4f20\u7edf\u65b9\u6cd5\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684NLP\u6570\u636e\uff0c\u5e76\u4e14\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u751f\u6210\u3002"}}
{"id": "2507.14169", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.14169", "abs": "https://arxiv.org/abs/2507.14169", "authors": ["Pramesh Gautam", "Ravi Sharan B A G", "Paolo Baracca", "Carsten Bockelmann", "Thorsten Wild", "Armin Dekorsy"], "title": "CQI-Based Interference Prediction for Link Adaptation in Industrial Sub-networks", "comment": null, "summary": "We propose a novel interference prediction scheme to improve link adaptation\n(LA) in densely deployed industrial sub-networks (SNs) with high-reliability\nand low-latency communication (HRLLC) requirements. The proposed method aims to\nimprove the LA framework by predicting and leveraging the heavy-tailed\ninterference probability density function (pdf). Interference is modeled as a\nlatent vector of available channel quality indicator (CQI), using a vector\ndiscrete-time state-space model (vDSSM) at the SN controller, where the CQI is\nsubjected to compression, quantization, and delay-induced errors. To robustly\nestimate interference power values under these impairments, we employ a\nlow-complexity, outlier-robust, sparse Student-t process regression (SPTPR)\nmethod. This is integrated into a modified unscented Kalman filter, which\nrecursively refines predicted interference using CQI, enabling accurate\nestimation and compensating protocol feedback delays, crucial for accurate LA.\nNumerical results show that the proposed method achieves over 10x lower\ncomplexity compared to a similar non-parametric baseline. It also maintains a\nBLER below the 90th percentile target of 1e-6 while delivering performance\ncomparable to a state-of-the-art supervised technique using only CQI reports.", "AI": {"tldr": "Novel interference prediction for industrial networks improves link adaptation using vDSSM and SP-TPR in an unscented Kalman filter, reducing complexity by 10x and matching SOTA performance with high reliability.", "motivation": "To improve link adaptation (LA) in densely deployed industrial sub-networks (SNs) with high-reliability and low-latency communication (HRLLC) requirements by predicting and leveraging the heavy-tailed interference probability density function (pdf).", "method": "A novel interference prediction scheme using a vector discrete-time state-space model (vDSSM) to model interference as a latent vector of CQI, with a low-complexity, outlier-robust, sparse Student-t process regression (SPTPR) method integrated into a modified unscented Kalman filter for robust estimation and compensation of protocol feedback delays.", "result": "The proposed method achieves over 10x lower complexity than a similar non-parametric baseline, maintains a Block Error Rate (BLER) below the 90th percentile target of 1e-6, and delivers performance comparable to a state-of-the-art supervised technique using only CQI reports.", "conclusion": "The proposed interference prediction scheme effectively improves link adaptation in industrial sub-networks for HRLLC, achieving lower complexity and comparable performance to state-of-the-art methods while maintaining target reliability."}}
{"id": "2507.15155", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15155", "abs": "https://arxiv.org/abs/2507.15155", "authors": ["Majid Roshanfar", "Alex Zhang", "Changyan He", "Amir Hooshiar", "Dale J. Podolsky", "Thomas Looi", "Eric Diller"], "title": "Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions", "comment": null, "summary": "This letter introduces a novel learning-based modeling framework for a\nmagnetically steerable soft suction device designed for endoscopic endonasal\nbrain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm\ninner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,\nand integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape\nfeedback. Shape reconstruction is represented using four Bezier control points,\nenabling a compact and smooth model of the device's deformation. A data-driven\nmodel was trained on 5,097 experimental samples covering a range of magnetic\nfield magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical\ntip distances (90-100 mm), using both Neural Network (NN) and Random Forest\n(RF) architectures. The RF model outperformed the NN across all metrics,\nachieving a mean root mean square error of 0.087 mm in control point prediction\nand a mean shape reconstruction error of 0.064 mm. Feature importance analysis\nfurther revealed that magnetic field components predominantly influence distal\ncontrol points, while frequency and distance affect the base configuration.\nThis learning-based approach effectively models the complex nonlinear behavior\nof hyperelastic soft robots under magnetic actuation without relying on\nsimplified physical assumptions. By enabling sub-millimeter shape prediction\naccuracy and real-time inference, this work represents an advancement toward\nthe intelligent control of magnetically actuated soft robotic tools in\nminimally invasive neurosurgery.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u8111\u80bf\u7624\u5207\u9664\u3002\u8be5\u65b9\u6cd5\u80fd\u7cbe\u786e\u9884\u6d4b\u673a\u5668\u4eba\u5f62\u72b6\uff0c\u5b9e\u73b0\u4e9a\u6beb\u7c73\u7ea7\u7cbe\u5ea6\uff0c\u4e3a\u5fae\u521b\u624b\u672f\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u78c1\u529b\u9a71\u52a8\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u5728\u5fae\u521b\u795e\u7ecf\u5916\u79d1\u624b\u672f\u4e2d\uff0c\u5176\u590d\u6742\u975e\u7ebf\u6027\u884c\u4e3a\u96be\u4ee5\u7cbe\u786e\u5efa\u6a21\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u7b80\u5316\u7269\u7406\u5047\u8bbe\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u5b9e\u73b0\u5bf9\u8bbe\u5907\u5f62\u72b6\u7684\u9ad8\u7cbe\u5ea6\u5b9e\u65f6\u9884\u6d4b\uff0c\u4ece\u800c\u63d0\u5347\u624b\u672f\u7684\u7cbe\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09\u548c\u968f\u673a\u68ee\u6797\uff08RF\uff09\u4e24\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5bf94\u6beb\u7c73\u5916\u5f84\u30012\u6beb\u7c73\u5185\u5f84\u300140\u6beb\u7c73\u957f\u5ea6\u76843D\u6253\u5370\u8f6f\u4f53\u673a\u5668\u4eba\u8fdb\u884c\u5efa\u6a21\u3002\u8bbe\u5907\u96c6\u6210\u4e86\u5149\u7ea4\u5e03\u62c9\u683c\u5149\u6805\uff08FBG\uff09\u4f20\u611f\u5668\uff0c\u7528\u4e8e\u5b9e\u65f6\u5f62\u72b6\u53cd\u9988\u3002\u901a\u8fc75097\u4e2a\u5b9e\u9a8c\u6837\u672c\uff0c\u5728\u4e0d\u540c\u78c1\u573a\uff080-14 mT\uff09\u3001\u9a71\u52a8\u9891\u7387\uff080.2-1.0 Hz\uff09\u548c\u672b\u7aef\u8ddd\u79bb\uff0890-100 mm\uff09\u4e0b\u8bad\u7ec3\u6a21\u578b\u3002\u901a\u8fc7\u6bd4\u8f83NN\u548cRF\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d1\u73b0RF\u6a21\u578b\u5728\u63a7\u5236\u70b9\u9884\u6d4b\u548c\u5f62\u72b6\u91cd\u5efa\u8bef\u5dee\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5e73\u5747\u5747\u65b9\u6839\u8bef\u5dee\u5206\u522b\u4e3a0.087\u6beb\u7c73\u548c0.064\u6beb\u7c73\u3002\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u8868\u660e\uff0c\u78c1\u573a\u5206\u91cf\u4e3b\u8981\u5f71\u54cd\u8fdc\u7aef\u63a7\u5236\u70b9\uff0c\u800c\u9891\u7387\u548c\u8ddd\u79bb\u5219\u5f71\u54cd\u57fa\u5ea7\u914d\u7f6e\u3002", "result": "\u968f\u673a\u68ee\u6797\uff08RF\uff09\u6a21\u578b\u5728\u63a7\u5236\u70b9\u9884\u6d4b\u65b9\u9762\u8fbe\u5230\u4e860.087\u6beb\u7c73\u7684\u5e73\u5747\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u5728\u5f62\u72b6\u91cd\u5efa\u65b9\u9762\u8fbe\u5230\u4e860.064\u6beb\u7c73\u7684\u5e73\u5747\u8bef\u5dee\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u7684\u6709\u6548\u6027\u3002\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u53c2\u6570\u5bf9\u8bbe\u5907\u5f62\u72b6\u7684\u5f71\u54cd\u89c4\u5f8b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u78c1\u529b\u53ef\u63a7\u8f6f\u5438\u5165\u8bbe\u5907\uff0c\u8be5\u8bbe\u5907\u53ef\u7528\u4e8e\u5185\u7aa5\u955c\u4e0b\u9f3b\u8154\u8111\u80bf\u7624\u5207\u9664\u672f\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8bbe\u5907\u7684\u4e9a\u6beb\u7c73\u7ea7\u5f62\u72b6\u9884\u6d4b\u7cbe\u5ea6\u548c\u5b9e\u65f6\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5f00\u53d1\u667a\u80fd\u63a7\u5236\u7684\u5fae\u521b\u795e\u7ecf\u5916\u79d1\u624b\u672f\u8f6f\u4f53\u673a\u5668\u4eba\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14543", "categories": ["cs.CV", "cs.CY", "cs.HC", "cs.LG", "I.4.6"], "pdf": "https://arxiv.org/pdf/2507.14543", "abs": "https://arxiv.org/abs/2507.14543", "authors": ["Sharanya Mukherjee", "Md Hishaam Akhtar", "Kannadasan R"], "title": "Real Time Captioning of Sign Language Gestures in Video Meetings", "comment": "7 pages, 2 figures, 1 table, Presented at ICCMDE 2021", "summary": "It has always been a rather tough task to communicate with someone possessing\na hearing impairment. One of the most tested ways to establish such a\ncommunication is through the use of sign based languages. However, not many\npeople are aware of the smaller intricacies involved with sign language. Sign\nlanguage recognition using computer vision aims at eliminating the\ncommunication barrier between deaf-mute and ordinary people so that they can\nproperly communicate with others. Recently the pandemic has left the whole\nworld shaken up and has transformed the way we communicate. Video meetings have\nbecome essential for everyone, even people with a hearing disability. In recent\nstudies, it has been found that people with hearing disabilities prefer to sign\nover typing during these video calls. In this paper, we are proposing a browser\nextension that will automatically translate sign language to subtitles for\neveryone else in the video call. The Large-scale dataset which contains more\nthan 2000 Word-Level ASL videos, which were performed by over 100 signers will\nbe used.", "AI": {"tldr": "A browser extension that translates sign language to subtitles for video calls.", "motivation": "To bridge the communication gap between people with and without hearing impairments, especially in the context of increasingly essential video meetings.", "method": "Developing a browser extension for real-time sign language to subtitle translation.", "result": "The system will translate sign language into subtitles using a dataset of over 2000 ASL videos performed by more than 100 signers.", "conclusion": "We propose a browser extension that automatically translates sign language to subtitles during video calls, using a large-scale dataset of ASL videos."}}
{"id": "2507.14899", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14899", "abs": "https://arxiv.org/abs/2507.14899", "authors": ["Jiale Liu", "Huan Wang", "Yue Zhang", "Xiaoyu Luo", "Jiaxiang Hu", "Zhiliang Liu", "Min Xie"], "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis", "comment": null, "summary": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for\nindustrial quality assurance, yet existing deep-learning-based approaches often\nlack interactivity, interpretability, and the capacity for critical\nself-assessment, limiting their reliability and operator trust. To address\nthese shortcomings, this paper proposes InsightX Agent, a novel LMM-based\nagentic framework designed to deliver reliable, interpretable, and interactive\nX-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent\npositions a Large Multimodal Model (LMM) as a central orchestrator,\ncoordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the\nEvidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect\nregion proposals for multi-scale feature maps and sparsifies them through\nNon-Maximum Suppression (NMS), optimizing detection of small, dense targets in\nX-ray images while maintaining computational efficiency. The EGR tool guides\nthe LMM agent through a chain-of-thought-inspired review process, incorporating\ncontext assessment, individual defect analysis, false positive elimination,\nconfidence recalibration and quality assurance to validate and refine the\nSDMSD's initial proposals. By strategically employing and intelligently using\ntools, InsightX Agent moves beyond passive data processing to active reasoning,\nenhancing diagnostic reliability and providing interpretations that integrate\ndiverse information sources. Experimental evaluations on the GDXray+ dataset\ndemonstrate that InsightX Agent not only achieves a high object detection\nF1-score of 96.35% but also offers significantly improved interpretability and\ntrustworthiness in its analyses, highlighting the transformative potential of\nagentic LLM frameworks for industrial inspection tasks.", "AI": {"tldr": "InsightX Agent\u662f\u4e00\u4e2a\u521b\u65b0\u7684LMM\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7SDMSD\u8fdb\u884c\u7cbe\u786e\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7EGR\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u65b9\u6cd5\u5728\u4ea4\u4e92\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u6211\u6279\u5224\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53ef\u9760\u6027\u548c\u64cd\u4f5c\u5458\u7684\u4fe1\u4efb\u5ea6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4ea4\u4e92\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aInsightX Agent\u7684\u65b0\u578b\u57fa\u4e8eLMM\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMM\uff09\u4f5c\u4e3a\u4e2d\u592e\u534f\u8c03\u5668\uff0c\u4e0e\u7a00\u758f\u53ef\u53d8\u5f62\u591a\u5c3a\u5ea6\u68c0\u6d4b\u5668\uff08SDMSD\uff09\u548c\u8bc1\u636e\u7ea6\u675f\u53cd\u601d\uff08EGR\uff09\u5de5\u5177\u534f\u540c\u5de5\u4f5c\u3002SDMSD\u7528\u4e8e\u751f\u6210\u5bc6\u96c6\u7f3a\u9677\u533a\u57df\u63d0\u6848\uff0c\u5e76\u901a\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236\uff08NMS\uff09\u8fdb\u884c\u7a00\u758f\u5316\u3002EGR\u5de5\u5177\u5219\u5f15\u5bfcLMM\u4ee3\u7406\u901a\u8fc7\u4e00\u7cfb\u5217\u63a8\u7406\u6b65\u9aa4\uff08\u5305\u62ec\u4e0a\u4e0b\u6587\u8bc4\u4f30\u3001\u7f3a\u9677\u5206\u6790\u3001\u8bef\u62a5\u5254\u9664\u3001\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u8d28\u91cf\u4fdd\u8bc1\uff09\u6765\u9a8c\u8bc1\u548c\u4f18\u5316SDMSD\u7684\u521d\u6b65\u68c0\u6d4b\u7ed3\u679c\u3002", "result": "InsightX Agent\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8696.35%\u7684\u76ee\u6807\u68c0\u6d4bF1\u5206\u6570\uff0c\u5e76\u5728\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5de5\u4e1a\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "InsightX Agent\u901a\u8fc7\u96c6\u6210SDMSD\u548cEGR\u5de5\u5177\uff0c\u5229\u7528LMM\u4f5c\u4e3a\u4e2d\u592e\u534f\u8c03\u5668\uff0c\u5728X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u9886\u57df\u5b9e\u73b0\u4e86\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u4ea4\u4e92\u7684\u5206\u6790\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8696.35%\u7684\u9ad8\u76ee\u6807\u68c0\u6d4bF1\u5206\u6570\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.15384", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.15384", "abs": "https://arxiv.org/abs/2507.15384", "authors": ["Yongxu Fu", "Gao Xianlong"], "title": "Anatomy of Non-Hermitian Dynamical Quantum Phase Transitions", "comment": "27 pages, 4 figures", "summary": "We establish a unified framework for dynamical quantum phase transitions\n(DQPTs) in non-Hermitian systems that encompasses both biorthogonal and\nself-norm non-biorthogonal formulations for pure and mixed states. Our\nframework provides explicit expressions for the Loschmidt amplitude, Loschmidt\necho, and rate function, revealing a universal geometric signature of DQPTs:\northogonality of two related vectors in two-dimensional real space. Strikingly,\nwe demonstrate that non-biorthogonal quenches from non-Hermitian to Hermitian\nHamiltonians under chiral symmetry exhibit emergent topological\ncharacteristics, unveiling the intrinsic topological nature of DQPTs beyond\nconventional Hermitian regimes. This work establishes fundamental geometric and\ntopological principles governing quantum criticality in open systems, with\nimplications for quantum sensing and many-body physics in dissipative\nenvironments.", "AI": {"tldr": "\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u91cf\u5b50\u76f8\u53d8\uff08DQPTs\uff09\u7edf\u4e00\u6846\u67b6\uff1a\u53d1\u73b0\u4e86\u666e\u904d\u7684\u51e0\u4f55\uff08\u5411\u91cf\u6b63\u4ea4\u6027\uff09\u548c\u62d3\u6251\uff08\u6d8c\u73b0\u7684\u62d3\u6251\u7279\u6027\uff09\u539f\u7406\uff0c\u5bf9\u91cf\u5b50\u4f20\u611f\u548c\u5f00\u653e\u7cfb\u7edf\u7269\u7406\u5b66\u6709\u610f\u4e49\u3002", "motivation": "\u4e3a\u4e86\u5728\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u52a8\u529b\u5b66\u91cf\u5b50\u76f8\u53d8\uff08DQPTs\uff09\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u63ed\u793a\u5176\u5185\u5728\u7684\u51e0\u4f55\u548c\u62d3\u6251\u6027\u8d28\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u7814\u7a76\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u7684\u52a8\u529b\u5b66\u91cf\u5b50\u76f8\u53d8\uff08DQPTs\uff09\uff0c\u8be5\u6846\u67b6\u8003\u8651\u4e86\u7eaf\u6001\u548c\u6df7\u5408\u6001\u7684\u53cc\u6b63\u4ea4\u548c\u81ea\u8303\u6570\u975e\u53cc\u6b63\u4ea4\u5f62\u5f0f\uff0c\u5e76\u7ed9\u51fa\u4e86\u6d1b\u65bd\u5bc6\u7279\u5e45\u5ea6\u3001\u6d1b\u65bd\u5bc6\u7279\u56de\u58f0\u548c\u901f\u7387\u51fd\u6570\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86DQPTs\u7684\u4e00\u4e2a\u666e\u904d\u51e0\u4f55\u7279\u5f81\uff1a\u4e24\u4e2a\u76f8\u5173\u5411\u91cf\u5728\u4e8c\u7ef4\u5b9e\u7a7a\u95f4\u4e2d\u7684\u6b63\u4ea4\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8868\u660e\u975e\u5384\u7c73\u5230\u5384\u7c73\u54c8\u5bc6\u987f\u91cf\u7684\u975e\u53cc\u6b63\u4ea4\u6dec\u706d\u5728\u624b\u5f81\u5bf9\u79f0\u6027\u4e0b\u8868\u73b0\u51fa\u6d8c\u73b0\u7684\u62d3\u6251\u7279\u6027\uff0c\u63ed\u793a\u4e86DQPTs\u8d85\u8d8a\u4f20\u7edf\u5384\u7c73\u4f53\u7cfb\u7684\u5185\u5728\u62d3\u6251\u6027\u8d28\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u7684\u52a8\u529b\u5b66\u91cf\u5b50\u76f8\u53d8\uff08DQPTs\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u62ec\u7eaf\u6001\u548c\u6df7\u5408\u6001\u7684\u53cc\u6b63\u4ea4\u548c\u81ea\u8303\u6570\u975e\u53cc\u6b63\u4ea4\u5f62\u5f0f\u3002\u8be5\u6846\u67b6\u63ed\u793a\u4e86DQPTs\u7684\u4e00\u4e2a\u666e\u904d\u51e0\u4f55\u7279\u5f81\uff1a\u4e8c\u7ef4\u5b9e\u7a7a\u95f4\u4e2d\u4e24\u4e2a\u76f8\u5173\u5411\u91cf\u7684\u6b63\u4ea4\u6027\u3002\u7279\u522b\u662f\uff0c\u7814\u7a76\u8868\u660e\u5177\u6709\u624b\u5f81\u5bf9\u79f0\u6027\u7684\u975e\u53cc\u6b63\u4ea4\u6dec\u706d\uff08\u4ece\u975e\u5384\u7c73\u5230\u5384\u7c73\u54c8\u5bc6\u987f\u91cf\uff09\u8868\u73b0\u51fa\u6d8c\u73b0\u7684\u62d3\u6251\u7279\u6027\uff0c\u63ed\u793a\u4e86DQPTs\u5728\u4f20\u7edf\u5384\u7c73\u4f53\u7cfb\u4e4b\u5916\u7684\u5185\u5728\u62d3\u6251\u6027\u8d28\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5f00\u653e\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50\u4e34\u754c\u6027\u5efa\u7acb\u4e86\u57fa\u672c\u7684\u51e0\u4f55\u548c\u62d3\u6251\u539f\u7406\uff0c\u5bf9\u91cf\u5b50\u4f20\u611f\u548c\u8017\u6563\u73af\u5883\u4e2d\u7684\u591a\u4f53\u7269\u7406\u5b66\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.14332", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14332", "abs": "https://arxiv.org/abs/2507.14332", "authors": ["Aidan Furlong", "Xingang Zhao", "Robert Salko", "Xu Wu"], "title": "Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries", "comment": "Accepted for inclusion in Transactions of the American Nuclear\n  Society for the 2025 ANS Winter Conference", "summary": "Accurate prediction of critical heat flux (CHF) is an essential component of\nsafety analysis in pressurized and boiling water reactors. To support reliable\nprediction of this quantity, several empirical correlations and lookup tables\nhave been constructed from physical experiments over the past several decades.\nWith the onset of accessible machine learning (ML) frameworks, multiple\ninitiatives have been established with the goal of predicting CHF more\naccurately than these traditional methods. While purely data-driven surrogate\nmodeling has been extensively investigated, these approaches lack\ninterpretability, lack resilience to data scarcity, and have been developed\nmostly using data from tube experiments. As a result, bias-correction hybrid\napproaches have become increasingly popular, which correct initial\n\"low-fidelity\" estimates provided by deterministic base models by using\nML-predicted residuals. This body of work has mostly considered round tube\ngeometries; annular geometry-specific ML models have not yet been deployed in\nthermal hydraulic codes. This study developed, deployed, and validated four ML\nmodels to predict CHF in annular geometries using the CTF subchannel code.\nThree empirical correlation models, Biasi, Bowring, and Katto, were used as\nbase models for comparison. The ML models were trained and tested using 577\nexperimental annulus data points from four datasets: Becker, Beus, Janssen, and\nMortimore. Baseline CHF predictions were obtained from the empirical\ncorrelations, with mean relative errors above 26%. The ML-driven models\nachieved mean relative errors below 3.5%, with no more than one point exceeding\nthe 10% error envelope. In all cases, the hybrid ML models significantly\noutperformed their empirical counterparts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u73af\u5f62\u51e0\u4f55\u4e2d\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4fee\u6b63\u4f20\u7edf\u7ecf\u9a8c\u6a21\u578b\u7684\u9884\u6d4b\u6b8b\u5dee\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u7ecf\u9a8c\u5173\u8054\u548c\u67e5\u627e\u8868\u5728\u9884\u6d4b\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e14\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u6297\u6570\u636e\u7a00\u758f\u6027\u80fd\u529b\u5dee\uff0c\u5e76\u4e14\u4e3b\u8981\u57fa\u4e8e\u7ba1\u72b6\u51e0\u4f55\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8e\u73af\u5f62\u51e0\u4f55\u7684\u3001\u66f4\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684CHF\u9884\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u53cd\u5e94\u5806\u7684\u5b89\u5168\u5206\u6790\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u4fee\u6b63\u4f20\u7edf\u7ecf\u9a8c\u6a21\u578b\uff08Biasi\u3001Bowring\u3001Katto\uff09\u7684\u9884\u6d4b\u6b8b\u5dee\uff0c\u4ee5\u63d0\u9ad8\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002\u6570\u636e\u6765\u6e90\u4e8e\u56db\u4e2a\u6570\u636e\u96c6\uff08Becker\u3001Beus\u3001Janssen\u3001Mortimore\uff09\u7684577\u4e2a\u5b9e\u9a8c\u6570\u636e\u70b9\uff0c\u5e76\u4f7f\u7528CTF\u5b50\u901a\u9053\u4ee3\u7801\u8fdb\u884c\u4e86\u90e8\u7f72\u548c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u5f00\u53d1\u7684\u6df7\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5c06\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4ece\u7ecf\u9a8c\u76f8\u5173\u6a21\u578b\u768426%\u4ee5\u4e0a\u964d\u4f4e\u52303.5%\u4ee5\u4e0b\uff0c\u4e14\u4ec5\u6709\u4e00\u4e2a\u6570\u636e\u70b9\u7684\u8bef\u5dee\u8d85\u8fc710%\u3002\u8fd9\u8868\u660e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u73af\u5f62\u51e0\u4f55\u4e2d\u7684CHF\u65b9\u9762\u8fdc\u4f18\u4e8e\u4f20\u7edf\u7684\u7ecf\u9a8c\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u3001\u90e8\u7f72\u5e76\u9a8c\u8bc1\u4e86\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u73af\u5f62\u51e0\u4f55\u4e2d\u7684\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u3002\u4e0e\u4f20\u7edf\u7684\u7ecf\u9a8c\u76f8\u5173\u6a21\u578b\u76f8\u6bd4\uff0c\u8fd9\u4e9b\u6df7\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4ece26%\u4ee5\u4e0a\u964d\u4f4e\u52303.5%\u4ee5\u4e0b\u3002"}}
{"id": "2507.15199", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15199", "abs": "https://arxiv.org/abs/2507.15199", "authors": ["Ali Kefayati", "Branislav Nikolic", "Yafei Ren"], "title": "Light-induced ultrafast magnetization dynamics in van der Waals antiferromagnetic CrSBr", "comment": "7 pages, 4 figures", "summary": "The magnetization dynamics driven by the femtosecond laser pulse of\nantiferromagnet van der Waals semiconductor CrSBr is studied within\ntime-dependent density functional theory. We investigate the effect of laser\nfluence as well as the excitation frequency on the ultrafast dynamics of spins.\nIn low fluence, the local magnetic moment of Cr increases when the laser\nfrequency is below the band gap, whereas it decreases when the laser frequency\nis below the band gap. In high fluence, we find strong demagnetization\nindependent of excitation frequency. We find that the ultrafast demagnetization\nin CrSBr is dominated by intralayer and interlayer optical intersite spin\ntransfer, and spin flip via the spin-orbit coupling plays a minor role. Our\nresults reveal hole excitation in the low-fluence regime and electron\nexcitation in the high-fluence regime. Further, we investigate the effect of\nthe external static magnetic field on the dynamics. We demonstrate even and odd\nhigh harmonic generation in the local magnetic moments and electric current,\nrespectively. The external magnetic field results in an out-of-plane charge\ncurrent via the inverse spin Hall effect as well as odd harmonics in the local\nmagnetic moment dynamics as a result of breaking the time-reversal symmetry.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528TDDFT\u7814\u7a76\u4e86CrSBr\u5728\u98de\u79d2\u6fc0\u5149\u4e0b\u7684\u78c1\u5316\u52a8\u529b\u5b66\u3002\u4f4e\u6ce8\u91cf\u65f6\u6fc0\u5149\u9891\u7387\u5f71\u54cd\u78c1\u77e9\u53d8\u5316\uff0c\u9ad8\u6ce8\u91cf\u65f6\u53d1\u751f\u9000\u78c1\u3002\u9000\u78c1\u4e3b\u56e0\u662f\u5c42\u5185/\u95f4\u81ea\u65cb\u8f6c\u79fb\uff0c\u975e\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u3002\u4f4e\u6ce8\u91cf\u4e3a\u91cd\u53e0\u6fc0\u53d1\uff0c\u9ad8\u6ce8\u91cf\u4e3a\u7535\u5b50\u6fc0\u53d1\u3002\u5916\u52a0\u78c1\u573a\u53ef\u4ea7\u751f\u7535\u8377\u6d41\u548c\u5947\u6b21\u8c10\u6ce2\u3002", "motivation": "\u7814\u7a76CrSBr\u5728\u98de\u79d2\u6fc0\u5149\u8109\u51b2\u9a71\u52a8\u4e0b\u7684\u78c1\u5316\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662f\u6fc0\u5149\u6ce8\u91cf\u548c\u6fc0\u53d1\u9891\u7387\u5bf9\u8d85\u5feb\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5916\u52a0\u9759\u6001\u78c1\u573a\u7684\u4f5c\u7528\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528\u65f6\u4f9d\u8d56\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08TDDFT\uff09\u7814\u7a76\u4e86CrSBr\u7684\u78c1\u5316\u52a8\u529b\u5b66\u3002", "result": "\u4f4e\u6ce8\u91cf\u4e0b\uff0c\u6fc0\u5149\u9891\u7387\u4f4e\u4e8e\u5e26\u9699\u65f6\uff0cCr\u7684\u5c40\u57df\u78c1\u77e9\u589e\u52a0\uff1b\u6fc0\u5149\u9891\u7387\u4f4e\u4e8e\u5e26\u9699\u65f6\uff0cCr\u7684\u5c40\u57df\u78c1\u77e9\u51cf\u5c0f\u3002\u9ad8\u6ce8\u91cf\u4e0b\uff0c\u53d1\u751f\u4e0e\u6fc0\u53d1\u9891\u7387\u65e0\u5173\u7684\u5f3a\u9000\u78c1\u3002\u8d85\u5feb\u9000\u78c1\u4e3b\u8981\u7531\u5c42\u5185\u548c\u5c42\u95f4\u5149\u5b66\u5f02\u4f4d\u81ea\u65cb\u8f6c\u79fb\u5f15\u8d77\uff0c\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u7684\u81ea\u65cb\u7ffb\u8f6c\u4f5c\u7528\u8f83\u5c0f\u3002\u4f4e\u6ce8\u91cf\u4e0b\u4e3a\u91cd\u53e0\u6fc0\u53d1\uff0c\u9ad8\u6ce8\u91cf\u4e0b\u4e3a\u7535\u5b50\u6fc0\u53d1\u3002\u5916\u52a0\u9759\u6001\u78c1\u573a\u53ef\u5f15\u8d77\u9762\u5916\u7535\u8377\u6d41\uff08\u9006\u81ea\u65cb\u970d\u5c14\u6548\u5e94\uff09\u548c\u5c40\u57df\u78c1\u77e9\u52a8\u529b\u5b66\u4e2d\u7684\u5947\u6b21\u8c10\u6ce2\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u65f6\u4f9d\u8d56\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u7814\u7a76\u4e86\u7587\u94c1\u78c1\u8303\u5fb7\u534e\u534a\u5bfc\u4f53CrSBr\u5728\u98de\u79d2\u6fc0\u5149\u8109\u51b2\u9a71\u52a8\u4e0b\u7684\u78c1\u5316\u52a8\u529b\u5b66\uff0c\u5e76\u63a2\u8ba8\u4e86\u6fc0\u5149\u6ce8\u91cf\u548c\u6fc0\u53d1\u9891\u7387\u5bf9\u81ea\u65cb\u8d85\u5feb\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f4e\u6ce8\u91cf\u4e0b\uff0c\u5f53\u6fc0\u5149\u9891\u7387\u4f4e\u4e8e\u5e26\u9699\u65f6\uff0cCr\u7684\u5c40\u57df\u78c1\u77e9\u589e\u52a0\uff1b\u5f53\u6fc0\u5149\u9891\u7387\u4f4e\u4e8e\u5e26\u9699\u65f6\uff0cCr\u7684\u5c40\u57df\u78c1\u77e9\u51cf\u5c0f\u3002\u5728\u9ad8\u6ce8\u91cf\u4e0b\uff0c\u65e0\u8bba\u6fc0\u53d1\u9891\u7387\u5982\u4f55\uff0c\u90fd\u4f1a\u53d1\u751f\u5f3a\u70c8\u7684\u9000\u78c1\u3002\u672c\u7814\u7a76\u53d1\u73b0\uff0cCrSBr\u4e2d\u7684\u8d85\u5feb\u9000\u78c1\u4e3b\u8981\u7531\u5c42\u5185\u548c\u5c42\u95f4\u5149\u5b66\u5f02\u4f4d\u81ea\u65cb\u8f6c\u79fb\u5f15\u8d77\uff0c\u800c\u901a\u8fc7\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u4ea7\u751f\u7684\u81ea\u65cb\u7ffb\u8f6c\u8d77\u6b21\u8981\u4f5c\u7528\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u4f4e\u6ce8\u91cf\u4e0b\u7684\u7a7a\u7a74\u6fc0\u53d1\u548c\u9ad8\u6ce8\u91cf\u4e0b\u7684\u7535\u5b50\u6fc0\u53d1\u3002\u6b64\u5916\uff0c\u672c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u5916\u52a0\u9759\u6001\u78c1\u573a\u5bf9\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u5c40\u57df\u78c1\u77e9\u548c\u7535\u6d41\u4e2d\u5b58\u5728\u7684\u5076\u6b21\u548c\u5947\u6b21\u9ad8\u6b21\u8c10\u6ce2\u4ea7\u751f\u3002\u5916\u52a0\u78c1\u573a\u901a\u8fc7\u9006\u81ea\u65cb\u970d\u5c14\u6548\u5e94\u4ea7\u751f\u9762\u5916\u7535\u8377\u6d41\uff0c\u5e76\u7531\u4e8e\u65f6\u95f4\u53cd\u8f6c\u5bf9\u79f0\u6027\u7684\u7834\u574f\u800c\u5728\u5c40\u57df\u78c1\u77e9\u52a8\u529b\u5b66\u4e2d\u4ea7\u751f\u5947\u6b21\u8c10\u6ce2\u3002"}}
{"id": "2507.15261", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15261", "abs": "https://arxiv.org/abs/2507.15261", "authors": ["Xinqi Chen", "Xiuxian Li", "Min Meng"], "title": "Dual-Channel Adaptive NMPC for Quadrotor under Instantaneous Impact and Payload Disturbances", "comment": null, "summary": "Capturing target objects using the quadrotor has gained increasing popularity\nin recent years, but most studies focus on capturing lightweight objects. The\ninstantaneous contact force generated when capturing objects of a certain mass,\nalong with the payload uncertainty after attachment, will pose significant\nchallenges to the quadrotor control. This paper proposes a novel control\narchitecture, namely Dual-Channel Adaptive Nonlinear Model Predictive Control\n(DCA-NMPC), which cascades a nonlinear model predictive control with two\nlower-level model reference adaptive controllers and can resist drastic impact\nand adapt to uncertain inertial parameters. Numerical simulation experiments\nare performed for validation.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u56db\u65cb\u7ffc\u6293\u53d6\u91cd\u7269\u65f6\u63a7\u5236\u96be\u9898\uff0c\u63d0\u51faDCA-NMPC\u67b6\u6784\uff0c\u901a\u8fc7\u7ea7\u8054\u63a7\u5236\u6709\u6548\u5e94\u5bf9\u51b2\u51fb\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u7814\u7a76\u96c6\u4e2d\u4e8e\u6293\u53d6\u8f7b\u91cf\u7ea7\u7269\u4f53\uff0c\u800c\u5ffd\u7565\u4e86\u6293\u53d6\u6709\u4e00\u5b9a\u8d28\u91cf\u7269\u4f53\u65f6\u4ea7\u751f\u7684\u77ac\u65f6\u63a5\u89e6\u529b\u4ee5\u53ca\u9644\u7740\u540e\u8f7d\u8377\u4e0d\u786e\u5b9a\u6027\u5bf9\u56db\u65cb\u7ffc\u98de\u884c\u5668\u63a7\u5236\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684DCA-NMPC\u63a7\u5236\u67b6\u6784\uff0c\u5c06\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e0e\u4e24\u4e2a\u4f4e\u7ea7\u6a21\u578b\u53c2\u8003\u81ea\u9002\u5e94\u63a7\u5236\u5668\u7ea7\u8054\uff0c\u4ee5\u62b5\u6297\u5267\u70c8\u51b2\u51fb\u5e76\u9002\u5e94\u4e0d\u786e\u5b9a\u7684\u60ef\u6027\u53c2\u6570\u3002", "result": "\u901a\u8fc7\u6570\u503c\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u901a\u9053\u81ea\u9002\u5e94\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08DCA-NMPC\uff09\u67b6\u6784\uff0c\u80fd\u591f\u5e94\u5bf9\u6293\u53d6\u5e26\u8d28\u91cf\u7269\u4f53\u65f6\u4ea7\u751f\u7684\u77ac\u65f6\u63a5\u89e6\u529b\u4ee5\u53ca\u9644\u7740\u540e\u8f7d\u8377\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2507.14880", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14880", "abs": "https://arxiv.org/abs/2507.14880", "authors": ["Huili Zhang", "Yibin Guo", "Guanglei Xu", "Yulong Feng", "Jingning Zhang", "Hai-feng Yu", "S. P. Zhao"], "title": "Simultaneous determination of multiple low-energy eigenstates of many-body systems on a superconducting quantum processor", "comment": null, "summary": "The determination of the ground and low-lying excited states is critical in\nmany studies of quantum chemistry and condensed-matter physics. Recent\ntheoretical work proposes a variational quantum eigensolver using ancillary\nqubits to generate entanglement in the variational circuits, which avoids\ncomplex ansatz circuits and successive measurements in the previous algorithms.\nIn this work, we employ the ancilla-entangled variational quantum eigensolver\nto simultaneously compute multiple low-lying eigenenergies and eigenstates of\nthe H2 molecule and three- and five-spin transverse field Ising models (TFIMs)\non a superconducting quantum processor. We obtain the potential energy curves\nof H2 and show an indication of antiferromagnetic to paramagnetic phase\ntransition in the TFIMs from the average absolute magnetization. Our\nexperiments demonstrate that the algorithm is capable of simultaneously\ndetermining multiple eigenenergies and eigenstates of many-body systems with\nhigh efficiency and accuracy and with less computational resources.", "AI": {"tldr": "\u8f85\u6bd4\u7279\u53d8\u5206\u91cf\u5b50\u7279\u5f81\u6c42\u89e3\u5668\u53ef\u9ad8\u6548\u3001\u51c6\u786e\u5730\u6c42\u89e3\u591a\u4f53\u7cfb\u7edf\uff0c\u5e76\u6d88\u8017\u66f4\u5c11\u7684\u8d44\u6e90\u3002", "motivation": "\u786e\u5b9a\u57fa\u6001\u548c\u4f4e\u80fd\u6fc0\u53d1\u6001\u5bf9\u4e8e\u8bb8\u591a\u91cf\u5b50\u5316\u5b66\u548c\u51dd\u805a\u6001\u7269\u7406\u7814\u7a76\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u91c7\u7528\u5305\u542b\u8f85\u6bd4\u7279\u7684\u53d8\u5206\u91cf\u5b50\u7279\u5f81\u6c42\u89e3\u5668\uff0c\u5728\u8d85\u5bfc\u91cf\u5b50\u5904\u7406\u5668\u4e0a\u540c\u65f6\u8ba1\u7b97H2\u5206\u5b50\u4ee5\u53ca\u4e09\u81ea\u65cb\u548c\u4e94\u81ea\u65cb\u6a2a\u5411\u573a\u4f0a\u8f9b\u6a21\u578b\uff08TFIMs\uff09\u7684\u591a\u4e2a\u4f4e\u80fd\u7279\u5f81\u80fd\u91cf\u548c\u7279\u5f81\u6001\u3002", "result": "\u6211\u4eec\u83b7\u5f97\u4e86H2\u7684\u52bf\u80fd\u66f2\u7ebf\uff0c\u5e76\u901a\u8fc7\u5e73\u5747\u7edd\u5bf9\u78c1\u5316\u503c\u9884\u793a\u4e86TFIMs\u4e2d\u7684\u53cd\u94c1\u78c1\u5230\u987a\u78c1\u76f8\u53d8\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u3001\u51c6\u786e\u5730\u540c\u65f6\u786e\u5b9a\u591a\u4f53\u7cfb\u7edf\u591a\u4e2a\u4f4e\u80fd\u80fd\u91cf\u548c\u7279\u5f81\u6001\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u66f4\u5c11\u3002"}}
{"id": "2507.14615", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14615", "abs": "https://arxiv.org/abs/2507.14615", "authors": ["Fred Mutisya", "Shikoh Gitau", "Christine Syovata", "Diana Oigara", "Ibrahim Matende", "Muna Aden", "Munira Ali", "Ryan Nyotu", "Diana Marion", "Job Nyangena", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha", "Eric Mibuari", "Jean Philbert Nsengemana", "Talkmore Chidede"], "title": "Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper", "comment": "29 pages, 6 figs, 6 tables. Companion methods paper forthcoming", "summary": "Large Language Models(LLMs) hold promise for improving healthcare access in\nlow-resource settings, but their effectiveness in African primary care remains\nunderexplored. We present a methodology for creating a benchmark dataset and\nevaluation framework focused on Kenyan Level 2 and 3 clinical care. Our\napproach uses retrieval augmented generation (RAG) to ground clinical questions\nin Kenya's national guidelines, ensuring alignment with local standards. These\nguidelines were digitized, chunked, and indexed for semantic retrieval. Gemini\nFlash 2.0 Lite was then prompted with guideline excerpts to generate realistic\nclinical scenarios, multiple-choice questions, and rationale based answers in\nEnglish and Swahili. Kenyan physicians co-created and refined the dataset, and\na blinded expert review process ensured clinical accuracy, clarity, and\ncultural appropriateness. The resulting Alama Health QA dataset includes\nthousands of regulator-aligned question answer pairs across common outpatient\nconditions. Beyond accuracy, we introduce evaluation metrics that test clinical\nreasoning, safety, and adaptability such as rare case detection (Needle in the\nHaystack), stepwise logic (Decision Points), and contextual adaptability.\nInitial results reveal significant performance gaps when LLMs are applied to\nlocalized scenarios, consistent with findings that LLM accuracy is lower on\nAfrican medical content than on US-based benchmarks. This work offers a\nreplicable model for guideline-driven, dynamic benchmarking to support safe AI\ndeployment in African health systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u9488\u5bf9\u80af\u5c3c\u4e9a\u533b\u7597\u4fdd\u5065\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u70b9\u662f\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u56fd\u5bb6\u6307\u5357\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u7f8e\u56fd\u57fa\u51c6\u76f8\u6bd4\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u672c\u5730\u5316\u573a\u666f\u4e2d\u7684\u8868\u73b0\u5b58\u5728\u5dee\u8ddd\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u975e\u6d32\u536b\u751f\u7cfb\u7edf\u90e8\u7f72\u4eba\u5de5\u667a\u80fd\u7684\u6311\u6218\u548c\u673a\u9047\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u73af\u5883\uff08\u7279\u522b\u662f\u975e\u6d32\u57fa\u5c42\u533b\u7597\uff09\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5c06\u4e34\u5e8a\u95ee\u9898\u4e0e\u80af\u5c3c\u4e9a\u7684\u56fd\u5bb6\u6307\u5357\u76f8\u7ed3\u5408\uff0c\u5e76\u5bf9\u6570\u636e\u96c6\u7684\u51c6\u786e\u6027\u3001\u6e05\u6670\u5ea6\u548c\u6587\u5316\u9002\u5e94\u6027\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u521d\u59cb\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u672c\u5730\u5316\u573a\u666f\u65f6\uff0c\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u8fd9\u4e0e\u5728\u975e\u6d32\u533b\u7597\u5185\u5bb9\u4e0a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u51c6\u786e\u6027\u4f4e\u4e8e\u7f8e\u56fd\u57fa\u51c6\u6d4b\u8bd5\u7684\u53d1\u73b0\u4e00\u81f4\u3002\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u6570\u5343\u4e2a\u7b26\u5408\u6cd5\u89c4\u7684\u95ee\u7b54\u5bf9\u7684 Alama Health QA \u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e86\u5e38\u89c1\u7684\u95e8\u8bca\u75c5\u75c7\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u5236\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u9a71\u52a8\u7684\u3001\u52a8\u6001\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u652f\u6301\u975e\u6d32\u536b\u751f\u7cfb\u7edf\u4e2d\u4eba\u5de5\u667a\u80fd\u7684\u5b89\u5168\u90e8\u7f72\u3002"}}
{"id": "2507.14173", "categories": ["eess.SP", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14173", "abs": "https://arxiv.org/abs/2507.14173", "authors": ["Karim Alghoul", "Hussein Al Osman", "Abdulmotaleb El Saddik"], "title": "Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model", "comment": "Accepted by IEEE International Instrumentation and Measurement\n  Technology Conference (I2MTC) 2025", "summary": "Human computer interaction has become integral to modern life, driven by\nadvancements in machine learning technologies. Affective computing, in\nparticular, has focused on systems that recognize, interpret, and respond to\nhuman emotions, often using wearable devices, which provide continuous data\nstreams of physiological signals. Among various physiological signals, the\nphotoplethysmogram (PPG) has gained prominence due to its ease of acquisition\nfrom widely available devices. However, the generalization of PPG-based emotion\nrecognition models across individuals remains an unresolved challenge. This\npaper introduces a novel hybrid architecture that combines Convolutional Neural\nNetworks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal\nConvolutional Networks (TCNs) to address this issue. The proposed model\nintegrates the strengths of these architectures to improve robustness and\ngeneralization. Raw PPG signals are fed into the CNN for feature extraction.\nThese features are processed separately by LSTM and TCN. The outputs from these\ncomponents are concatenated to generate a final feature representation, which\nserves as the input for classifying valence and arousal, the primary dimensions\nof emotion. Experiments using the Photoplethysmogram Dataset for Emotional\nAnalysis (PPGE) demonstrate that the proposed hybrid model achieves better\nmodel generalization than standalone CNN and LSTM architectures. Our results\nshow that the proposed solution outperforms the state-of-the-art CNN\narchitecture, as well as a CNN-LSTM model, in emotion recognition tasks with\nPPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we\nhighlight the model's effectiveness in handling subject variability.", "AI": {"tldr": "\u70ba\u4e86\u89e3\u6c7aPPG\u4fe1\u865f\u60c5\u7dd2\u8b58\u5225\u7684\u500b\u9ad4\u6cdb\u5316\u6027\u6311\u6230\uff0c\u63d0\u51fa\u4e86\u4e00\u7a2e\u7d50\u5408CNN\u3001LSTM\u548cTCN\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5be6\u9a57\u8b49\u660e\u8a72\u6a21\u578b\u5728PPGE\u6578\u64da\u96c6\u4e0a\u8868\u73fe\u66f4\u512a\u3002", "motivation": "\u5118\u7ba1\u57fa\u65bcPPG\u4fe1\u865f\u7684\u60c5\u7dd2\u8b58\u5225\u6280\u8853\u53d6\u5f97\u9032\u5c55\uff0c\u4f46\u6a21\u578b\u5728\u4e0d\u540c\u500b\u9ad4\u9593\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u7136\u662f\u4e00\u500b\u6311\u6230\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u958b\u767c\u80fd\u5920\u66f4\u597d\u5730\u8655\u7406\u500b\u9ad4\u5dee\u7570\u4e26\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u7684\u65b0\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u6df7\u5408\u67b6\u69cb\uff0c\u7d50\u5408\u4e86\u5377\u7a4d\u795e\u7d93\u7db2\u7d61\uff08CNN\uff09\u3001\u9577\u77ed\u671f\u8a18\u61b6\u7db2\u7d61\uff08LSTM\uff09\u548c\u6642\u9593\u5377\u7a4d\u7db2\u7d61\uff08TCN\uff09\u3002\u8a72\u6a21\u578b\u9996\u5148\u4f7f\u7528CNN\u63d0\u53d6\u539f\u59cbPPG\u4fe1\u865f\u7684\u7279\u5fb5\uff0c\u7136\u5f8c\u5206\u5225\u7531LSTM\u548cTCN\u8655\u7406\u9019\u4e9b\u7279\u5fb5\u3002\u6700\u5f8c\uff0c\u5c07LSTM\u548cTCN\u7684\u8f38\u51fa\u9023\u63a5\u8d77\u4f86\uff0c\u751f\u6210\u6700\u7d42\u7684\u7279\u5fb5\u8868\u793a\uff0c\u7528\u65bc\u5206\u985e\u60c5\u7dd2\u7684\u4e3b\u8981\u7dad\u5ea6\u2014\u2014\u6548\u50f9\uff08valence\uff09\u548c\u559a\u9192\u5ea6\uff08arousal\uff09\u3002", "result": "\u5728PPGE\u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8a72\u6df7\u5408\u6a21\u578b\u76f8\u6bd4\u65bc\u55ae\u7368\u7684CNN\u548cLSTM\u67b6\u69cb\uff0c\u5177\u6709\u66f4\u597d\u7684\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8a72\u6a21\u578b\u5728\u60c5\u7dd2\u8b58\u5225\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u512a\u65bc\u6700\u5148\u9032\u7684CNN\u67b6\u69cb\u548cCNN-LSTM\u6a21\u578b\uff0c\u4e26\u901a\u904eAUC\u548cF1\u5206\u6578\u7b49\u6307\u6a19\u8b49\u660e\u4e86\u5176\u5728\u8655\u7406\u53d7\u8a66\u8005\u8b8a\u7570\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6df7\u5408\u6a21\u578b\u5728\u5904\u7406\u6765\u81eaPPG\u4fe1\u865f\u7684\u8868\u60c5\u8b58\u5225\u4efb\u52d9\u6642\uff0c\u901a\u904e\u7d50\u5408CNN\u3001LSTM\u548cTCN\u7684\u512a\u52e2\uff0c\u5be6\u73fe\u4e86\u6bd4\u55ae\u7368\u7684CNN\u548cLSTM\u67b6\u69cb\u66f4\u597d\u7684\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u4e26\u4e14\u512a\u65bc\u73fe\u6709\u7684\u57fa\u65bcCNN\u7684\u67b6\u69cb\u548cCNN-LSTM\u6a21\u578b\uff0c\u80fd\u5920\u6709\u6548\u8655\u7406\u53d7\u8a66\u8005\u8b8a\u7570\u6027\u3002"}}
{"id": "2507.15189", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15189", "abs": "https://arxiv.org/abs/2507.15189", "authors": ["Kevin Christiansen Marsim", "Jinwoo Jeon", "Yeeun Kim", "Myeongwoo Jeong", "Hyun Myung"], "title": "CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer", "comment": null, "summary": "Depth information which specifies the distance between objects and current\nposition of the robot is essential for many robot tasks such as navigation.\nRecently, researchers have proposed depth completion frameworks to provide\ndense depth maps that offer comprehensive information about the surrounding\nenvironment. However, existing methods show significant trade-offs between\ncomputational efficiency and accuracy during inference. The substantial memory\nand computational requirements make them unsuitable for real-time applications,\nhighlighting the need to improve the completeness and accuracy of depth\ninformation while improving processing speed to enhance robot performance in\nvarious tasks. To address these challenges, in this paper, we propose\nCHADET(cross-hierarchical-attention depth-completion transformer), a\nlightweight depth-completion network that can generate accurate dense depth\nmaps from RGB images and sparse depth points. For each pair, its feature is\nextracted from the depthwise blocks and passed to the equally lightweight\ntransformer-based decoder. In the decoder, we utilize the novel\ncross-hierarchical-attention module that refines the image features from the\ndepth information. Our approach improves the quality and reduces memory usage\nof the depth map prediction, as validated in both KITTI, NYUv2, and VOID\ndatasets.", "AI": {"tldr": "CHADET\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6df1\u5ea6\u8865\u5168Transformer\uff0c\u901a\u8fc7\u4ea4\u53c9\u5206\u5c42\u6ce8\u610f\u529b\u63d0\u9ad8\u4e86\u6df1\u5ea6\u56fe\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u8865\u5168\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u6743\u8861\u3002\u5b83\u4eec\u5bf9\u5185\u5b58\u548c\u8ba1\u7b97\u7684\u8981\u6c42\u5f88\u9ad8\uff0c\u4e0d\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u9ad8\u6df1\u5ea6\u4fe1\u606f\u7684\u5b8c\u6574\u6027\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u63d0\u9ad8\u5904\u7406\u901f\u5ea6\uff0c\u4ee5\u589e\u5f3a\u673a\u5668\u4eba\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "method": "CHADET\uff08\u4ea4\u53c9\u5206\u5c42\u6ce8\u610f\u529b\u6df1\u5ea6\u8865\u5168Transformer\uff09\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6df1\u5ea6\u8865\u5168\u7f51\u7edc\uff0c\u53ef\u4ee5\u4eceRGB\u56fe\u50cf\u548c\u7a00\u758f\u6df1\u5ea6\u70b9\u751f\u6210\u51c6\u786e\u7684\u5bc6\u96c6\u6df1\u5ea6\u56fe\u3002\u901a\u8fc7\u6df1\u5ea6\u5757\u63d0\u53d6\u6bcf\u4e2a\u70b9\u7684\u7279\u5f81\uff0c\u5e76\u5c06\u5176\u4f20\u9012\u7ed9\u540c\u6837\u8f7b\u91cf\u7ea7\u7684\u57fa\u4e8eTransformer\u7684\u89e3\u7801\u5668\u3002", "result": "CHADET\u63d0\u9ad8\u4e86\u6df1\u5ea6\u56fe\u9884\u6d4b\u7684\u8d28\u91cf\u5e76\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u4e14\u5728KITTI\u3001NYUv2\u548cVOID\u6570\u636e\u96c6\u4e0a\u90fd\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "CHADET\u901a\u8fc7\u5728\u89e3\u7801\u5668\u4e2d\u4f7f\u7528\u65b0\u9896\u7684\u4ea4\u53c9\u5206\u5c42\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5229\u7528\u6765\u81ea\u6df1\u5ea6\u4fe1\u606f\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u63d0\u9ad8\u4e86\u6df1\u5ea6\u56fe\u9884\u6d4b\u7684\u8d28\u91cf\u5e76\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u4e14\u5728KITTI\u3001NYUv2\u548cVOID\u6570\u636e\u96c6\u4e0a\u90fd\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.14544", "categories": ["cs.CV", "cs.AI", "68T45 (Machine vision and scene understanding)", "I.2.10; I.4.8; H.3.1"], "pdf": "https://arxiv.org/pdf/2507.14544", "abs": "https://arxiv.org/abs/2507.14544", "authors": ["Sujata Gaihre", "Amir Thapa Magar", "Prasuna Pokharel", "Laxmi Tiwari"], "title": "Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025", "comment": "accepted to ImageCLEF 2025, to be published in the lab proceedings", "summary": "This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA\n2025 Challenge, which targets visual question answering (VQA) for\ngastrointestinal endoscopy. We adopt the Florence model-a large-scale\nmultimodal foundation model-as the backbone of our VQA pipeline, pairing a\npowerful vision encoder with a text encoder to interpret endoscopic images and\nproduce clinically relevant answers. To improve generalization, we apply\ndomain-specific augmentations that preserve medical features while increasing\ntraining diversity. Experiments on the KASVIR dataset show that fine-tuning\nFlorence yields accurate responses on the official challenge metrics. Our\nresults highlight the potential of large multimodal models in medical VQA and\nprovide a strong baseline for future work on explainability, robustness, and\nclinical integration. The code is publicly available at:\nhttps://github.com/TiwariLaxuu/VQA-Florence.git", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u80c3\u80a0\u5185\u7aa5\u955c\u68c0\u67e5\u533b\u5b66VQA\u7684Florence\u6a21\u578b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03\u548c\u6570\u636e\u589e\u5f3a\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u672c\u6b21\u5de5\u4f5c\u65e8\u5728\u89e3\u51b3\u56fe\u50cf\u5bc6\u96c6\u578b\u80c3\u80a0\u5185\u7aa5\u955c\u68c0\u67e5\u7684\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u7684\u5b50\u4efb\u52a11\uff0c\u8be5\u4efb\u52a1\u662fImageCLEFmed MEDVQA 2025\u6311\u6218\u7684\u4e00\u90e8\u5206\u3002", "method": "\u91c7\u7528Florence\u6a21\u578b\u4f5c\u4e3aVQA\u6d41\u6c34\u7ebf\u7684\u9aa8\u5e72\uff0c\u7ed3\u5408\u5f3a\u5927\u7684\u89c6\u89c9\u7f16\u7801\u5668\u548c\u6587\u672c\u7f16\u7801\u5668\u6765\u89e3\u6790\u5185\u7aa5\u955c\u56fe\u50cf\u5e76\u751f\u6210\u4e34\u5e8a\u76f8\u5173\u7684\u7b54\u6848\u3002\u4e3a\u4e86\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u91c7\u7528\u4e86\u9886\u57df\u7279\u5b9a\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5728\u589e\u52a0\u8bad\u7ec3\u591a\u6837\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u533b\u5b66\u7279\u5f81\u3002", "result": "\u5728KASVIR\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u5bf9Florence\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u4ee5\u83b7\u5f97\u5728\u5b98\u65b9\u6311\u6218\u6307\u6807\u4e0a\u7684\u51c6\u786e\u54cd\u5e94\u3002", "conclusion": "\u901a\u8fc7\u5bf9Florence\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u4ee5\u5728\u5b98\u65b9\u6311\u6218\u6307\u6807\u4e0a\u4ea7\u751f\u51c6\u786e\u7684\u54cd\u5e94\uff0c\u8fd9\u8868\u660e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u533b\u5b66VQA\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u548c\u4e34\u5e8a\u6574\u5408\u5de5\u4f5c\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.14906", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14906", "abs": "https://arxiv.org/abs/2507.14906", "authors": ["Xiao Yang", "Juxi Leitner", "Michael Burke"], "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making", "comment": null, "summary": "The ability of Large Language Models (LLMs) to extract context from natural\nlanguage problem descriptions naturally raises questions about their\nsuitability in autonomous decision-making settings. This paper studies the\nbehaviour of these models within a Markov Decision Process (MDPs). While\ntraditional reinforcement learning (RL) strategies commonly employed in this\nsetting rely on iterative exploration, LLMs, pre-trained on diverse datasets,\noffer the capability to leverage prior knowledge for faster adaptation. We\ninvestigate online structured prompting strategies in sequential decision\nmaking tasks, comparing the zero-shot performance of LLM-based approaches to\nthat of classical RL methods. Our findings reveal that although LLMs\ndemonstrate improved initial performance in simpler environments, they struggle\nwith planning and reasoning in complex scenarios without fine-tuning or\nadditional guidance. Our results show that feedback mechanisms, intended to\nimprove decision-making, often introduce confusion, leading to diminished\nperformance in intricate environments. These insights underscore the need for\nfurther exploration into hybrid strategies, fine-tuning, and advanced memory\nintegration to enhance LLM-based decision-making capabilities.", "AI": {"tldr": "LLMs\u5728\u7b80\u5355\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u9700\u8981\u989d\u5916\u7684\u6307\u5bfc\u548c\u4f18\u5316\u624d\u80fd\u6709\u6548\u8fdb\u884c\u89c4\u5212\u548c\u63a8\u7406\u3002", "motivation": "LLMs\u4ece\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u5f15\u53d1\u4e86\u5173\u4e8e\u5176\u5728\u81ea\u4e3b\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76LLMs\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u4e2d\u7684\u884c\u4e3a\uff0c\u5e76\u7814\u7a76\u5728\u7ebf\u7ed3\u6784\u5316\u63d0\u793a\u7b56\u7565\u5728\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5c06\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u4e0e\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\u7684\u96f6\u6837\u672c\u6027\u80fd\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "LLMs\u5728\u7b80\u5355\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u521d\u59cb\u6027\u80fd\uff0c\u4f46\u5728\u6ca1\u6709\u5fae\u8c03\u6216\u989d\u5916\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u590d\u6742\u573a\u666f\u4e2d\u8fdb\u884c\u89c4\u5212\u548c\u63a8\u7406\u5b58\u5728\u56f0\u96be\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u65e8\u5728\u6539\u5584\u51b3\u7b56\u7684\u53cd\u9988\u673a\u5236\u5728\u590d\u6742\u73af\u5883\u4e2d\u5e38\u5e38\u4f1a\u5f15\u5165\u6df7\u6dc6\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "LLMs\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fdb\u884c\u89c4\u5212\u548c\u63a8\u7406\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u6df7\u5408\u7b56\u7565\u3001\u5fae\u8c03\u548c\u9ad8\u7ea7\u5185\u5b58\u96c6\u6210\u6765\u589e\u5f3a\u5176\u57fa\u4e8eLLM\u7684\u51b3\u7b56\u80fd\u529b\u3002\u6b64\u5916\uff0c\u53cd\u9988\u673a\u5236\u5728\u590d\u6742\u73af\u5883\u4e2d\u53ef\u80fd\u5bfc\u81f4\u6df7\u6dc6\u5e76\u964d\u4f4e\u6027\u80fd\u3002"}}
{"id": "2507.15429", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.15429", "abs": "https://arxiv.org/abs/2507.15429", "authors": ["Zi-Hao Ding", "Zhen-Feng Ouyang", "Ze-Feng Gao", "Wei Ji", "Kai Liu", "Peng-Jie Guo", "Zhong-Yi Lu"], "title": "Anomalous charge density wave in two-dimensional altermagnet WO", "comment": "6 pages, 4 figures", "summary": "Recently, the study of novel physical properties arising from the combination\nof altermagnetism and other matter phases has attracted widespread attention,\nsuch as the integration of altermagnetism and topology. However, research on\nthe combination of altermagnetism and charge density waves remains relatively\nsparse. In this letter, based on symmetry analysis and first-principles\ncalculations, we demonstrate for the first time that altermagnetism and charge\ndensity waves can coexist in a two-dimensional material and predict monolayer\nWO to be such a material. Moreover, our calculations reveal that the\naltermagnetic order in monolayer WO stabilizes the $\\sqrt{2}\\times\\sqrt{2}$\ncharge density wave. Further, the $\\sqrt{2}\\times\\sqrt{2}$ charge density wave\nis not driven by Fermi-surface nesting but rather by strong electron-phonon\ncoupling. More importantly, the $\\sqrt{2}\\times\\sqrt{2}$ charge density wave in\nmonolayer WO leads to an anomalous transition from semimetal to metal.\nTherefore, we realize an anomalous charge density wave phase in altermagnetic\nWO. Considering the strong electron-phonon coupling and good metallic\nproperties in the altermagnetic charge density wave state, our work may provide\nnew insights into the realization of nontrivial altermagnetic\nsuperconductivity.", "AI": {"tldr": "\u9996\u6b21\u5728\u5355\u5c42WO\u4e2d\u53d1\u73b0\u4e86\u53cd\u78c1\u6027\u4e0e\u7535\u8377\u5bc6\u5ea6\u6ce2\u5171\u5b58\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u5f62\u6210\u673a\u5236\u548c\u53cd\u5e38\u7684\u76f8\u53d8\u884c\u4e3a\u3002", "motivation": "\u63a2\u7d22\u53cd\u78c1\u6027\u4e0e\u7535\u8377\u5bc6\u5ea6\u6ce2\u7ed3\u5408\u7684\u7269\u7406\u6027\u8d28\uff0c\u4ee5\u53ca\u53cd\u78c1\u6027\u5728\u7a33\u5b9a\u7535\u8377\u5bc6\u5ea6\u6ce2\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u57fa\u4e8e\u5bf9\u79f0\u6027\u5206\u6790\u548c\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97", "result": "\u53d1\u73b0\u4e86\u5355\u5c42WO\u6750\u6599\u4e2d\u53cd\u78c1\u6027\u4e0e\u7535\u8377\u5bc6\u5ea6\u6ce2\u53ef\u4ee5\u5171\u5b58\uff0c\u53cd\u78c1\u6027\u7a33\u5b9a\u4e86\u7535\u8377\u5bc6\u5ea6\u6ce2\uff0c\u4e14\u7535\u8377\u5bc6\u5ea6\u6ce2\u7684\u5f62\u6210\u7531\u5f3a\u7535\u5b50-\u58f0\u5b50\u8026\u5408\u9a71\u52a8\uff0c\u5e76\u5bfc\u81f4\u4e86\u6750\u6599\u4ece\u534a\u91d1\u5c5e\u5230\u91d1\u5c5e\u7684\u53cd\u5e38\u8f6c\u53d8\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u8bc1\u660e\u4e86\u4e8c\u7ef4\u6750\u6599\u4e2d\u53cd\u78c1\u6027\u4e0e\u7535\u8377\u5bc6\u5ea6\u6ce2\u5171\u5b58\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u63d0\u51fa\u5355\u5c42WO\u662f\u6b64\u7c7b\u6750\u6599\u7684\u5b9e\u4f8b\u3002\u7814\u7a76\u63ed\u793a\u4e86\u53cd\u78c1\u6027\u5e8f\u6709\u6548\u7a33\u5b9a\u4e86WO\u4e2d\u7684\u7535\u8377\u5bc6\u5ea6\u6ce2\uff0c\u4e14\u8be5\u6ce2\u5e76\u975e\u6e90\u4e8e\u8d39\u7c73\u9762\u5d4c\u5957\uff0c\u800c\u662f\u7531\u5f3a\u7535\u5b50-\u58f0\u5b50\u8026\u5408\u9a71\u52a8\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5355\u5c42WO\u4e2d\u7684\u7535\u8377\u5bc6\u5ea6\u6ce2\u5bfc\u81f4\u4e86\u4ece\u534a\u91d1\u5c5e\u5230\u91d1\u5c5e\u7684\u53cd\u5e38\u8f6c\u53d8\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e86\u53cd\u5e38\u7684\u7535\u8377\u5bc6\u5ea6\u6ce2\u76f8\u3002\u8003\u8651\u5230\u53cd\u78c1\u6027\u7535\u8377\u5bc6\u5ea6\u6ce2\u6001\u4e0b\u7684\u5f3a\u7535\u5b50-\u58f0\u5b50\u8026\u5408\u548c\u826f\u597d\u7684\u91d1\u5c5e\u6027\u8d28\uff0c\u8be5\u7814\u7a76\u4e3a\u5b9e\u73b0\u975e\u5e73\u51e1\u7684\u53cd\u78c1\u6027\u8d85\u5bfc\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2507.14344", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14344", "abs": "https://arxiv.org/abs/2507.14344", "authors": ["Daniel Fein", "Gabriela Aranguiz-Dias"], "title": "Influence Functions for Preference Dataset Pruning", "comment": null, "summary": "Language models are commonly fine-tuned via reinforcement learning to alter\ntheir behavior or elicit new capabilities. Datasets used for these purposes,\nand particularly human preference datasets, are often noisy. The relatively\nsmall size post-training datasets, combined with parameter-efficient\nfine-tuning methods, enable the use of influence functions approximations to\ndetect and prune training examples that are harmful to performance on a\nvalidation set. In this work, we adapt the TL;DR dataset for reward model\ntraining to demonstrate how conjugate-gradient approximated influence functions\ncan be used to filter datasets. In our experiments, influence function\nfiltering yields a small retraining accuracy uplift of 1.5% after removing 10%\nof training examples. We also show that gradient similarity outperforms\ninfluence functions for detecting helpful training examples. This suggests that\nlocal curvature is important for detecting harmful training examples, but less\nso for identifying helpful examples.", "AI": {"tldr": "\u4f7f\u7528\u5f71\u54cd\u51fd\u6570\u8fc7\u6ee4\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u6570\u636e\u96c6\u53ef\u4ee5\u8f7b\u5fae\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u5bf9\u4e8e\u8bc6\u522b\u6709\u76ca\u793a\u4f8b\uff0c\u68af\u5ea6\u76f8\u4f3c\u6027\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u5728\u5bf9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u6539\u8fdb\u5176\u6027\u80fd\u7684\u8fc7\u7a0b\u4e2d\uff0c\u901a\u5e38\u4f1a\u4f7f\u7528\u5305\u542b\u566a\u58f0\u7684\u3001\u7279\u522b\u662f\u4eba\u7c7b\u504f\u597d\u7684\u6570\u636e\u96c6\u3002\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u63a2\u7d22\u4e00\u79cd\u8fc7\u6ee4\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u5171\u8f6d\u68af\u5ea6\u8fd1\u4f3c\u5f71\u54cd\u51fd\u6570\u6765\u8fc7\u6ee4 TL;DR \u6570\u636e\u96c6\uff0c\u5e76\u4e0e\u68af\u5ea6\u76f8\u4f3c\u6027\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5f71\u54cd\u51fd\u6570\u8fc7\u6ee4\u5728\u79fb\u9664 10% \u7684\u8bad\u7ec3\u793a\u4f8b\u540e\uff0c\u5728\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u7684\u51c6\u786e\u6027\u4e0a\u4ea7\u751f\u4e86 1.5% \u7684\u5c0f\u5e45\u63d0\u5347\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8868\u660e\u68af\u5ea6\u76f8\u4f3c\u6027\u5728\u8bc6\u522b\u6709\u76ca\u8bad\u7ec3\u793a\u4f8b\u65b9\u9762\u4f18\u4e8e\u5f71\u54cd\u51fd\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5728\u56e0\u679c\u5173\u7cfb\u56fe\u4e2d\uff0c\u5c40\u90e8\u66f2\u7387\u5bf9\u4e8e\u68c0\u6d4b\u6709\u5bb3\u7684\u8bad\u7ec3\u793a\u4f8b\u5f88\u91cd\u8981\uff0c\u4f46\u5bf9\u4e8e\u8bc6\u522b\u6709\u76ca\u7684\u793a\u4f8b\u5219\u4e0d\u592a\u91cd\u8981\u3002"}}
{"id": "2507.15213", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15213", "abs": "https://arxiv.org/abs/2507.15213", "authors": ["Fengxian Ma", "Zeying Zhang", "Zhen Gao", "Xiaobei Wan", "Yandong Ma", "Yalong Jiao", "Shengyuan A. Yang"], "title": "Engineering Spin Splitting in Antiferromagnets by Superatoms with Internal Degree of Freedom", "comment": null, "summary": "Superatoms, stable atomic clusters acting as building blocks for new\nmaterials, offer unique opportunities due to their rich properties and\npotential for 2D material assembly. While extensive research has focused on\ntheir similarities to ordinary atoms, the role of their internal degrees of\nfreedom (IDOF) remains largely unexplored. Concurrently, compensated\nantiferromagnets (AFMs) with intrinsic spin-split band structures have emerged\nas a promising class of materials for spintronics, yet their experimental\nrealization, particularly in two dimensions, is limited. Here, we bridge these\ntwo fields by proposing a novel strategy to achieve spin-split AFMs using\nsuperatoms with IDOFs. We establish our core concept using a simple model,\ndemonstrating how superatom IDOFs can be leveraged to engineer system symmetry\nand induce spin splitting in AFM states. We concretely illustrate this strategy\nby first-principles calculations on a Mo-decorated carborophene sheets,\nconstructed from closo-carborane superatoms. We show that the distinct IDOFs of\ncarborane isomers (electric-dipole-like and nematic) are critical in\ndetermining the symmetry of the resulting 2D superatomic crystal and,\nconsequently, the spin splitting pattern of its AFM states. Our findings\nunderscore the profound significance of superatom IDOFs-a feature absent in\nordinary atoms-and introduce a new paradigm for engineering spin splitting in\nAFM lattices. This work opens novel avenues for the design of advanced\nspintronic and quantum materials based on superatoms.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u8d85\u539f\u5b50\u7684\u5185\u7980\u81ea\u7531\u5ea6\uff08IDOF\uff09\u6765\u8bbe\u8ba1\u4e8c\u7ef4\u53cd\u94c1\u78c1\u4f53\uff08AFM\uff09\u6750\u6599\uff0c\u901a\u8fc7\u8c03\u63a7\u8d85\u539f\u5b50\u7684\u5bf9\u79f0\u6027\u6765\u63a7\u5236\u81ea\u65cb\u5206\u88c2\u3002\u4ee5Mo\u4fee\u9970\u7684\u78b3\u787c\u77f3\u70ef\u4e3a\u4f8b\uff0c\u8bc1\u660e\u4e86\u78b3\u787c\u70f7\u8d85\u539f\u5b50\u7684\u4e0d\u540cIDOF\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u7684\u81ea\u65cb\u5206\u88c2\u8c03\u63a7\uff0c\u4e3a\u65b0\u578b\u81ea\u65cb\u7535\u5b50\u6750\u6599\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5f53\u524d\uff0c\u8d85\u539f\u5b50\u4f5c\u4e3a\u6784\u6210\u65b0\u6750\u6599\u7684\u5355\u5143\uff0c\u56e0\u5176\u72ec\u7279\u7684\u6027\u8d28\u548c\u5728\u4e8c\u7ef4\u6750\u6599\u7ec4\u88c5\u4e2d\u7684\u6f5c\u529b\u800c\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5bf9\u5176\u5185\u7980\u81ea\u7531\u5ea6\uff08IDOF\uff09\u7684\u4f5c\u7528\u7814\u7a76\u4e0d\u8db3\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5177\u6709\u672c\u5f81\u81ea\u65cb\u5288\u88c2\u80fd\u5e26\u7ed3\u6784\u7684\u8865\u507f\u53cd\u94c1\u78c1\u4f53\uff08AFM\uff09\u5728\u81ea\u65cb\u7535\u5b50\u5b66\u9886\u57df\u5177\u6709\u5e94\u7528\u524d\u666f\uff0c\u4f46\u5728\u4e8c\u7ef4\u4f53\u7cfb\u4e2d\u7684\u5b9e\u9a8c\u5b9e\u73b0\u53d7\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u7ed3\u5408\u8fd9\u4e24\u4e2a\u9886\u57df\uff0c\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u8d85\u539f\u5b50IDOF\u6765\u6784\u7b51\u4e8c\u7ef4AFM\u6750\u6599\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u7ed3\u5408\u4e86\u7406\u8bba\u6a21\u578b\u548c\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u3002\u9996\u5148\uff0c\u4f7f\u7528\u4e00\u4e2a\u7b80\u5355\u7684\u6a21\u578b\u9610\u8ff0\u4e86\u5982\u4f55\u5229\u7528\u8d85\u539f\u5b50\u7684IDOF\u6765\u8c03\u63a7\u7cfb\u7edf\u5bf9\u79f0\u6027\u5e76\u8bf1\u5bfcAFM\u6001\u7684\u81ea\u65cb\u5206\u88c2\u3002\u968f\u540e\uff0c\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u5177\u4f53\u5730\u5728\u7531\u95ed\u5408\u78b3\u787c\u70f7\u8d85\u539f\u5b50\u6784\u6210\u7684Mo\u4fee\u9970\u7684\u78b3\u787c\u77f3\u70ef\u8584\u819c\u4e0a\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u7b56\u7565\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u78b3\u787c\u70f7\u5f02\u6784\u4f53\u7684IDOF\u5bf9\u6750\u6599\u5bf9\u79f0\u6027\u548c\u81ea\u65cb\u5206\u88c2\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8d85\u539f\u5b50\u7684IDOF\uff08\u7279\u522b\u662f\u7535\u5076\u6781\u77e9\u548c\u56db\u6781\u77e9\uff09\u662f\u51b3\u5b9a\u4e8c\u7ef4\u8d85\u539f\u5b50\u6676\u4f53\u5bf9\u79f0\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8fdb\u800c\u80fd\u591f\u6709\u6548\u5730\u8c03\u63a7\u5176\u53cd\u94c1\u78c1\u6001\u7684\u81ea\u65cb\u5206\u88c2\u6a21\u5f0f\u3002\u5177\u4f53\u800c\u8a00\uff0c\u901a\u8fc7Mo\u4fee\u9970\u78b3\u787c\u77f3\u70ef\u7684\u4f8b\u5b50\u8bc1\u660e\uff0c\u4e0d\u540c\u7684\u78b3\u787c\u70f7\u8d85\u539f\u5b50IDOF\u53ef\u4ee5\u5bfc\u81f4\u4e0d\u540c\u7684\u81ea\u65cb\u5206\u88c2\u7279\u5f81\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5229\u7528\u5177\u6709\u5185\u7980\u81ea\u7531\u5ea6\uff08IDOF\uff09\u7684\u8d85\u539f\u5b50\u6765\u6784\u7b51\u81ea\u65cb\u5206\u88c2\u7684\u8865\u507f\u53cd\u94c1\u78c1\u4f53\uff08AFM\uff09\u7684\u65b0\u7b56\u7565\uff0c\u5e76\u4ee5Mo\u4fee\u9970\u7684\u78b3\u787c\u77f3\u70ef\uff08\u7531\u95ed\u5408\u78b3\u787c\u70f7\u8d85\u539f\u5b50\u6784\u6210\uff09\u4e3a\u4f8b\u8fdb\u884c\u4e86\u7406\u8bba\u9a8c\u8bc1\u3002\u7814\u7a76\u8868\u660e\uff0c\u78b3\u787c\u70f7\u5f02\u6784\u4f53\u7684IDOF\uff08\u7535\u5076\u6781\u77e9\u548c\u56db\u6781\u77e9\uff09\u80fd\u591f\u8c03\u63a7\u8d85\u539f\u5b50\u6676\u683c\u7684\u5bf9\u79f0\u6027\uff0c\u8fdb\u800c\u5f71\u54cd\u5176AFM\u6001\u7684\u81ea\u65cb\u5206\u88c2\u6a21\u5f0f\u3002\u8fd9\u63ed\u793a\u4e86\u8d85\u539f\u5b50IDOF\u5728\u8bbe\u8ba1AFM\u6750\u6599\u65b9\u9762\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u5f00\u53d1\u65b0\u578b\u81ea\u65cb\u7535\u5b50\u548c\u91cf\u5b50\u6750\u6599\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.15307", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15307", "abs": "https://arxiv.org/abs/2507.15307", "authors": ["Jun Kang Yap", "Vishnu Monn Baskaran", "Wen Shan Tan", "Ze Yang Ding", "Hao Wang", "David L. Dowe"], "title": "Joint Optimisation of Electric Vehicle Routing and Scheduling: A Deep Learning-Driven Approach for Dynamic Fleet Sizes", "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "Electric Vehicles (EVs) are becoming increasingly prevalent nowadays, with\nstudies highlighting their potential as mobile energy storage systems to\nprovide grid support. Realising this potential requires effective charging\ncoordination, which are often formulated as mixed-integer programming (MIP)\nproblems. However, MIP problems are NP-hard and often intractable when applied\nto time-sensitive tasks. To address this limitation, we propose a deep learning\nassisted approach for optimising a day-ahead EV joint routing and scheduling\nproblem with varying number of EVs. This problem simultaneously optimises EV\nrouting, charging, discharging and generator scheduling within a distribution\nnetwork with renewable energy sources. A convolutional neural network is\ntrained to predict the binary variables, thereby reducing the solution search\nspace and enabling solvers to determine the remaining variables more\nefficiently. Additionally, a padding mechanism is included to handle the\nchanges in input and output sizes caused by varying number of EVs, thus\neliminating the need for re-training. In a case study on the IEEE 33-bus system\nand Nguyen-Dupuis transportation network, our approach reduced runtime by 97.8%\nwhen compared to an unassisted MIP solver, while retaining 99.5% feasibility\nand deviating less than 0.01% from the optimal solution.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u8c03\u5ea6\uff0c\u901f\u5ea6\u5feb97.8%\uff0c\u7ed3\u679c\u63a5\u8fd1\u6700\u4f18\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65e5\u76ca\u666e\u53ca\u7684\u7535\u52a8\u6c7d\u8f66\u4f5c\u4e3a\u79fb\u52a8\u50a8\u80fd\u7cfb\u7edf\u4e3a\u7535\u7f51\u63d0\u4f9b\u652f\u6301\uff0c\u9700\u8981\u6709\u6548\u7684\u5145\u7535\u534f\u8c03\uff0c\u4f46\u4f20\u7edf\u7684MIP\u65b9\u6cd5\u5728\u65f6\u9650\u6027\u4efb\u52a1\u4e2d\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u9884\u6d4bMIP\u95ee\u9898\u4e2d\u7684\u4e8c\u5143\u53d8\u91cf\uff0c\u4ee5\u51cf\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u91c7\u7528\u586b\u5145\u673a\u5236\u5904\u7406EV\u6570\u91cf\u53d8\u5316\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5728IEEE 33\u8282\u70b9\u7cfb\u7edf\u548cNguyen-Dupuis\u4ea4\u901a\u7f51\u7edc\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u8fd0\u884c\u65f6\u95f4\u7f29\u77ed\u4e8697.8%\uff0c\u540c\u65f6\u4fdd\u6301\u4e8699.5%\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4f7f\u7ed3\u679c\u4e0e\u6700\u4f18\u89e3\u7684\u504f\u5dee\u5c0f\u4e8e0.01%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u8f85\u52a9\u65b9\u6cd5\u6765\u4f18\u5316\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u7684 \u064a\u0648\u0645 ahead \u8def\u7531\u548c\u8c03\u5ea6\u95ee\u9898\uff0c\u4ee5\u89e3\u51b3\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u7684NP\u96be\u9898\u3002"}}
{"id": "2507.14886", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14886", "abs": "https://arxiv.org/abs/2507.14886", "authors": ["Zibo Gao", "Zhengzhi Jiang", "Qiyu Liang", "Ruihua He", "Van Cuong Mai", "Yingwei Tang", "Qirong Xiong", "Wenting Zhao", "Hongwei Duan", "Hongliang Sun", "Mo Li", "Yansong Miao", "Weibo Gao"], "title": "Quantum sensing of Lanthandie binding tags with relaxometer of NV center in diamond", "comment": "8 pages, 4 figures. Published in Advanced Optical Materials", "summary": "Lanthanide binding tags (LBTs) stand out as a prominent group of fluorescent\nprobes that are extensively utilized in biological detection. However, research\non LBTs has predominantly emphasized their fluorescence properties, which\nfrequently compromised by background fluorescence noise. Investigating magnetic\nproperties could optimize detection methodologies that offer enhanced\nsensitivity and specificity. In this study, we measured the response of a\nrelaxometer based on ensemble nitrogen-vacancy (NV) centers in diamond to\nvarious amounts of LBTs with gadolinium ions, determining the detection limit\nof LBTs to be 25 fmol. We then proposed and demonstrated a detection scheme\nemploying the NV relaxometer to detect specific binding between LBTs and\ntarget. Specifically, we assessed the relaxometer's response to various\nconcentrations of the interaction between the modified LBTs and\nReceptor-Binding Domain (RBD) of SARS-COVID-2 spike protein, with the detection\nthreshold reaching ~1 pmol. Our research provides a potential application\nplatform for biomarker detection under picomole concentration by using NV\ncenters to detect the magnetism of LBTs.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u91d1\u521a\u77f3\u4e2d\u7684\u6c2e-\u7a7a\u4f4d\uff08NV\uff09\u4e2d\u5fc3\u4f5c\u4e3a\u4f20\u611f\u5668\uff0c\u901a\u8fc7\u68c0\u6d4b\u9567\u7cfb\u7ed3\u5408\u6807\u7b7e\uff08LBTs\uff09\u7684\u78c1\u6027\uff0c\u5b9e\u73b0\u4e86\u5bf9SARS-COVID-2\u523a\u7a81\u86cb\u767d\u53d7\u4f53\u7ed3\u5408\u57df\uff08RBD\uff09\u7b49\u751f\u7269\u6807\u5fd7\u7269\u7684\u9ad8\u7075\u654f\u5ea6\uff08\u4f4e\u81f3\u76ae\u6469\u5c14\u7ea7\u522b\uff09\u68c0\u6d4b\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u8367\u5149\u6cd5\u7684\u80cc\u666f\u5e72\u6270\u95ee\u9898\u3002", "motivation": "\u9274\u4e8e\u8367\u5149\u63a2\u9488\u6613\u53d7\u80cc\u666f\u8367\u5149\u5e72\u6270\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u5229\u7528\u78c1\u6027\u6027\u8d28\u4f18\u5316\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u7075\u654f\u5ea6\u548c\u7279\u5f02\u6027\u3002", "method": "\u901a\u8fc7\u6c2e-\u7a7a\u4f4d\uff08NV\uff09\u4e2d\u5fc3\u5f1b\u8c6b\u4eea\u6d4b\u91cf\u4e86\u4e0d\u540c\u91cf\u9486\u79bb\u5b50\u6807\u8bb0\u7684LBTs\u7684\u54cd\u5e94\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eSARS-COVID-2\u523a\u7a81\u86cb\u767d\u53d7\u4f53\u7ed3\u5408\u57df\uff08RBD\uff09\u4e0eLBTs\u4e4b\u95f4\u7684\u7279\u5f02\u6027\u7ed3\u5408\u68c0\u6d4b\u3002", "result": "\u7814\u7a76\u786e\u5b9a\u4e86LBTs\u7684\u68c0\u6d4b\u9650\u4e3a25 fmol\uff0c\u5e76\u901a\u8fc7NV\u5f1b\u8c6b\u4eea\u5b9e\u73b0\u4e86\u7ea61 pmol\u6d53\u5ea6\u7684LBTs\u4e0eRBD\u4e4b\u95f4\u7279\u5f02\u6027\u7ed3\u5408\u7684\u68c0\u6d4b\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5229\u7528\u6c2e-\u7a7a\u4f4d\uff08NV\uff09\u4e2d\u5fc3\u63a2\u6d4b\u9486\u79bb\u5b50\u6807\u8bb0\u7684\u9567\u7cfb\u7ed3\u5408\u6807\u7b7e\uff08LBTs\uff09\u7684\u78c1\u6027\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u7075\u654f\u5ea6\u7684\u751f\u7269\u6807\u5fd7\u7269\u68c0\u6d4b\u3002"}}
{"id": "2507.14640", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14640", "abs": "https://arxiv.org/abs/2507.14640", "authors": ["Eric Xia", "Jugal Kalita"], "title": "Linear Relational Decoding of Morphology in Language Models", "comment": null, "summary": "A two-part affine approximation has been found to be a good approximation for\ntransformer computations over certain subject object relations. Adapting the\nBigger Analogy Test Set, we show that the linear transformation Ws, where s is\na middle layer representation of a subject token and W is derived from model\nderivatives, is also able to accurately reproduce final object states for many\nrelations. This linear technique is able to achieve 90% faithfulness on\nmorphological relations, and we show similar findings multi-lingually and\nacross models. Our findings indicate that some conceptual relationships in\nlanguage models, such as morphology, are readily interpretable from latent\nspace, and are sparsely encoded by cross-layer linear transformations.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5f62\u6001\u5b66\u5173\u7cfb\u53ef\u4ee5\u901a\u8fc7\u8de8\u5c42\u7ebf\u6027\u53d8\u6362\u7a00\u758f\u7f16\u7801\u6765\u89e3\u91ca\u3002", "motivation": "\u63a2\u7a76 transformer \u8ba1\u7b97\u5728\u67d0\u4e9b\u4e3b\u8bed-\u5bbe\u8bed\u5173\u7cfb\u4e0a\u7684\u8fd1\u4f3c\u6027\uff0c\u5e76\u7814\u7a76\u7ebf\u6027\u53d8\u6362\u5728\u5176\u4e2d\u626e\u6f14\u7684\u89d2\u8272\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528 Bigger Analogy Test Set\uff0c\u5e76\u8868\u660e\u7ebf\u6027\u53d8\u6362 Ws\uff08\u5176\u4e2d s \u662f\u4e3b\u8bed\u6807\u8bb0\u7684\u4e2d\u95f4\u5c42\u8868\u793a\uff0cW \u6765\u81ea\u6a21\u578b\u5bfc\u6570\uff09\u4e5f\u80fd\u591f\u51c6\u786e\u5730\u518d\u73b0\u8bb8\u591a\u5173\u7cfb\u4e2d\u7684\u6700\u7ec8\u5bf9\u8c61\u72b6\u6001\u3002", "result": "\u7ebf\u6027\u6280\u672f\u5728\u5f62\u6001\u5b66\u5173\u7cfb\u4e0a\u5b9e\u73b0\u4e86 90% \u7684\u5fe0\u5b9e\u5ea6\uff0c\u5e76\u4e14\u5728\u591a\u8bed\u8a00\u548c\u8de8\u6a21\u578b\u4e2d\u4e5f\u53d1\u73b0\u4e86\u7c7b\u4f3c\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u67d0\u4e9b\u6982\u5ff5\u5173\u7cfb\uff08\u5982\u5f62\u6001\u5b66\uff09\u53ef\u4ee5\u4ece\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8f7b\u677e\u89e3\u91ca\uff0c\u5e76\u4e14\u901a\u8fc7\u8de8\u5c42\u7ebf\u6027\u53d8\u6362\u7a00\u758f\u7f16\u7801\u3002"}}
{"id": "2507.14184", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14184", "abs": "https://arxiv.org/abs/2507.14184", "authors": ["ZhengXiao He", "Jinghao Wen", "Huayu Li", "Ao Li"], "title": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment", "comment": null, "summary": "We present a novel and interpretable framework for electrocardiogram\n(ECG)-based disease detection that combines hyperdimensional computing (HDC)\nwith learnable neural encoding. Unlike conventional HDC approaches that rely on\nstatic, random projections, our method introduces a rhythm-aware and trainable\nencoding pipeline based on RR intervals, a physiological signal segmentation\nstrategy that aligns with cardiac cycles. The core of our design is a\nneural-distilled HDC architecture, featuring a learnable RR-block encoder and a\nBinaryLinear hyperdimensional projection layer, optimized jointly with\ncross-entropy and proxy-based metric loss. This hybrid framework preserves the\nsymbolic interpretability of HDC while enabling task-adaptive representation\nlearning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model\nsignificantly outperforms traditional HDC and classical ML baselines, achieving\n73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable\nrobustness on PTB-XL. Our framework offers an efficient and scalable solution\nfor edge-compatible ECG classification, with strong potential for interpretable\nand personalized health monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9ad8\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u548c\u53ef\u5b66\u4e60\u795e\u7ecf\u7f16\u7801\u7684\u65b0\u9896\u53ef\u89e3\u91ca\u6846\u67b6\uff0c\u7528\u4e8e\u5fc3\u7535\u56fe\uff08ECG\uff09\u75be\u75c5\u68c0\u6d4b\u3002\u8be5\u6846\u67b6\u5728 Apnea-ECG \u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf HDC \u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u3001\u968f\u673a\u6295\u5f71\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u9ad8\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u4e0e\u53ef\u5b66\u4e60\u795e\u7ecf\u7f16\u7801\u76f8\u7ed3\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9ad8\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u548c\u53ef\u5b66\u4e60\u795e\u7ecf\u7f16\u7801\u7684\u65b0\u9896\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u57fa\u4e8e RR \u95f4\u9694\uff08\u5fc3\u810f\u5468\u671f\u7684\u751f\u7406\u4fe1\u53f7\u5206\u5272\uff09\u7684\u53ef\u8bad\u7ec3\u7f16\u7801\u6d41\u7a0b\uff0c\u5e76\u91c7\u7528\u4e86\u4e00\u4e2a\u5305\u542b\u53ef\u5b66\u4e60 RR-block \u7f16\u7801\u5668\u548c BinaryLinear \u8d85\u7ef4\u6295\u5f71\u5c42\u7684\u795e\u7ecf\u84b8\u998f HDC \u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728 Apnea-ECG \u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf HDC \u548c\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0c\u7cbe\u5ea6\u8fbe\u5230 73.09%\uff0cF1 \u5206\u6570\u8fbe\u5230 0.626\uff0c\u5728 PTB-XL \u6570\u636e\u96c6\u4e0a\u5177\u6709\u53ef\u6bd4\u7684\u7a33\u5065\u6027\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u4e3a\u8fb9\u7f18\u517c\u5bb9\u7684\u5fc3\u7535\u56fe\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u53ef\u89e3\u91ca\u548c\u4e2a\u6027\u5316\u5065\u5eb7\u76d1\u6d4b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15266", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.15266", "abs": "https://arxiv.org/abs/2507.15266", "authors": ["Haichao Liu", "Haoren Guo", "Pei Liu", "Benshan Ma", "Yuxiang Zhang", "Jun Ma", "Tong Heng Lee"], "title": "VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving", "comment": "14 pages, 12 figures", "summary": "Scene understanding and risk-aware attentions are crucial for human drivers\nto make safe and effective driving decisions. To imitate this cognitive ability\nin urban autonomous driving while ensuring the transparency and\ninterpretability, we propose a vision-language model (VLM)-enhanced unified\ndecision-making and motion control framework, named VLM-UDMC. This framework\nincorporates scene reasoning and risk-aware insights into an upper-level slow\nsystem, which dynamically reconfigures the optimal motion planning for the\ndownstream fast system. The reconfiguration is based on real-time environmental\nchanges, which are encoded through context-aware potential functions. More\nspecifically, the upper-level slow system employs a two-step reasoning policy\nwith Retrieval-Augmented Generation (RAG), leveraging foundation models to\nprocess multimodal inputs and retrieve contextual knowledge, thereby generating\nrisk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM\nprovides real-time trajectory predictions for heterogeneous traffic\nparticipants by extracting smoother trend representations for short-horizon\ntrajectory prediction. The effectiveness of the proposed VLM-UDMC framework is\nverified via both simulations and real-world experiments with a full-size\nautonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively\nleverages scene understanding and attention decomposition for rational driving\ndecisions, thus improving the overall urban driving performance. Our\nopen-source project is available at https://github.com/henryhcliu/vlmudmc.git.", "AI": {"tldr": "\u63d0\u51faVLM-UDMC\u6846\u67b6\uff0c\u7ed3\u5408VLM\u548c\u7edf\u4e00\u51b3\u7b56\u63a7\u5236\uff0c\u901a\u8fc7RAG\u548cLSTM\u5b9e\u73b0\u57ce\u5e02\u81ea\u52a8\u9a7e\u9a76\u7684\u573a\u666f\u7406\u89e3\u3001\u98ce\u9669\u611f\u77e5\u548c\u5b9e\u65f6\u8f68\u8ff9\u9884\u6d4b\uff0c\u63d0\u5347\u9a7e\u9a76\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5728\u57ce\u5e02\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6a21\u4eff\u4eba\u7c7b\u9a7e\u9a76\u5458\u7684\u573a\u666f\u7406\u89e3\u548c\u98ce\u9669\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u786e\u4fdd\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u548c\u7edf\u4e00\u51b3\u7b56\u4e0e\u8fd0\u52a8\u63a7\u5236\u7684\u6846\u67b6\uff08VLM-UDMC\uff09\u3002\u8be5\u6846\u67b6\u7684\u4e0a\u5c42\u6162\u901f\u7cfb\u7edf\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u57fa\u7840\u6a21\u578b\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u5e76\u751f\u6210\u98ce\u9669\u611f\u77e5\u89c1\u89e3\uff0c\u4e0b\u5c42\u5feb\u901f\u7cfb\u7edf\u5219\u91c7\u7528\u8f7b\u91cf\u7ea7\u591a\u6838\u5206\u89e3LSTM\u8fdb\u884c\u5b9e\u65f6\u8f68\u8ff9\u9884\u6d4b\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8868\u660e\uff0cVLM-UDMC\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u5229\u7528\u573a\u666f\u7406\u89e3\u548c\u6ce8\u610f\u529b\u5206\u89e3\u505a\u51fa\u5408\u7406\u7684\u9a7e\u9a76\u51b3\u7b56\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u57ce\u5e02\u9a7e\u9a76\u6027\u80fd\u3002", "conclusion": "VLM-UDMC\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u573a\u666f\u7406\u89e3\u548c\u98ce\u9669\u611f\u77e5\u6ce8\u610f\u529b\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u57ce\u5e02\u9a7e\u9a76\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u4e86\u51b3\u7b56\u548c\u8fd0\u52a8\u63a7\u5236\u7684\u7edf\u4e00\u3002"}}
{"id": "2507.14549", "categories": ["cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14549", "abs": "https://arxiv.org/abs/2507.14549", "authors": ["Haotian Deng", "Chi Zhang", "Chen Wei", "Quanying Liu"], "title": "Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions", "comment": "Accepted by IJCNN 2025", "summary": "A fundamental challenge in affective cognitive science is to develop models\nthat accurately capture the relationship between external emotional stimuli and\nhuman internal experiences. While ANNs have demonstrated remarkable accuracy in\nfacial expression recognition, their ability to model inter-individual\ndifferences in human perception remains underexplored. This study investigates\nthe phenomenon of high perceptual variability-where individuals exhibit\nsignificant differences in emotion categorization even when viewing the same\nstimulus. Inspired by the similarity between ANNs and human perception, we\nhypothesize that facial expression samples that are ambiguous for ANN\nclassifiers also elicit divergent perceptual judgments among human observers.\nTo examine this hypothesis, we introduce a novel perceptual boundary sampling\nmethod to generate facial expression stimuli that lie along ANN decision\nboundaries. These ambiguous samples form the basis of the varEmotion dataset,\nconstructed through large-scale human behavioral experiments. Our analysis\nreveals that these ANN-confusing stimuli also provoke heightened perceptual\nuncertainty in human participants, highlighting shared computational principles\nin emotion perception. Finally, by fine-tuning ANN representations using\nbehavioral data, we achieve alignment between ANN predictions and both\ngroup-level and individual-level human perceptual patterns. Our findings\nestablish a systematic link between ANN decision boundaries and human\nperceptual variability, offering new insights into personalized modeling of\nemotional interpretation.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u63a2\u7d22\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u51b3\u7b56\u8fb9\u754c\u4e0e\u4eba\u7c7b\u611f\u77e5\u53d8\u5f02\u6027\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u8bc1\u660e\u4e86\u6a21\u7cca\u7684\u9762\u90e8\u8868\u60c5\u523a\u6fc0\u4f1a\u540c\u65f6\u5f71\u54cdANN\u548c\u4eba\u7c7b\u7684\u611f\u77e5\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u884c\u4e3a\u6570\u636e\u5fae\u8c03ANN\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u60c5\u611f\u89e3\u8bfb\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u5728\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u65b9\u9762\u867d\u7136\u51c6\u786e\u4f46\u5bf9\u4e2a\u4f53\u611f\u77e5\u5dee\u5f02\u7684\u5efa\u6a21\u80fd\u529b\u6b20\u7f3a\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u9762\u90e8\u8868\u60c5\u6837\u672c\u7684\u6a21\u7cca\u6027\u4e0e\u4eba\u7c7b\u89c2\u5bdf\u8005\u4e4b\u95f4\u611f\u77e5\u5224\u65ad\u5206\u6b67\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u611f\u77e5\u8fb9\u754c\u91c7\u6837\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u4f4d\u4e8eANN\u51b3\u7b56\u8fb9\u754c\u4e0a\u7684\u4eba\u8138\u8868\u60c5\u523a\u6fc0\u3002\u5229\u7528\u8fd9\u4e9b\u523a\u6fc0\u6784\u5efa\u4e86varEmotion\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u4eba\u7c7b\u884c\u4e3a\u5b9e\u9a8c\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u90a3\u4e9b\u4f7fANN\u5206\u7c7b\u5668\u611f\u5230\u56f0\u60d1\u7684\u523a\u6fc0\u540c\u6837\u4f1a\u5f15\u8d77\u4eba\u7c7b\u53c2\u4e0e\u8005\u9ad8\u5ea6\u7684\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u63ed\u793a\u4e86\u60c5\u7eea\u611f\u77e5\u4e2d\u5b58\u5728\u7684\u5171\u4eab\u8ba1\u7b97\u539f\u7406\u3002\u901a\u8fc7\u884c\u4e3a\u6570\u636e\u5fae\u8c03ANN\uff0c\u80fd\u591f\u4f7fANN\u9884\u6d4b\u4e0e\u4eba\u7c7b\u611f\u77e5\u6a21\u5f0f\uff08\u5305\u62ec\u7fa4\u4f53\u548c\u4e2a\u4f53\u5c42\u9762\uff09\u4fdd\u6301\u4e00\u81f4\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5efa\u7acb\u4e86\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u51b3\u7b56\u8fb9\u754c\u4e0e\u4eba\u7c7b\u611f\u77e5\u53d8\u5f02\u6027\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u8054\u7cfb\uff0c\u5e76\u901a\u8fc7\u4f7f\u7528\u884c\u4e3a\u6570\u636e\u5bf9ANN\u8868\u793a\u8fdb\u884c\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86ANN\u9884\u6d4b\u4e0e\u7fa4\u4f53\u53ca\u4e2a\u4f53\u5c42\u9762\u7684\u4eba\u7c7b\u611f\u77e5\u6a21\u5f0f\u7684\u5bf9\u9f50\uff0c\u4e3a\u60c5\u611f\u89e3\u8bfb\u7684\u4e2a\u6027\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14909", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.14909", "abs": "https://arxiv.org/abs/2507.14909", "authors": ["Elio Grande"], "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "comment": null, "summary": "The Endless Tuning is a design method for a reliable deployment of artificial\nintelligence based on a double mirroring process, which pursues both the goals\nof avoiding human replacement and filling the so-called responsibility gap\n(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the\nrelational approach urged therein, it was then actualized in a protocol,\nimplemented in three prototypical applications regarding decision-making\nprocesses (respectively: loan granting, pneumonia diagnosis, and art style\nrecognition) and tested with such as many domain experts. Step by step\nillustrating the protocol, giving insights concretely showing a different voice\n(Gilligan 1993) in the ethics of artificial intelligence, a philosophical\naccount of technical choices (e.g., a reversed and hermeneutic deployment of\nXAI algorithms) will be provided in the present study together with the results\nof the experiments, focusing on user experience rather than statistical\naccuracy. Even thoroughly employing deep learning models, full control was\nperceived by the interviewees in the decision-making setting, while it appeared\nthat a bridge can be built between accountability and liability in case of\ndamage.", "AI": {"tldr": "\u201c\u65e0\u9650\u8c03\u4f18\u201d\u662f\u4e00\u79cd\u4eba\u5de5\u667a\u80fd\u90e8\u7f72\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u91cd\u955c\u50cf\u907f\u514d\u53d6\u4ee3\u4eba\u7c7b\u5e76\u89e3\u51b3\u8d23\u4efb\u95ee\u9898\u3002\u5728\u8d37\u6b3e\u3001\u533b\u7597\u548c\u827a\u672f\u9886\u57df\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u7528\u6237\u611f\u89c9\u63a7\u5236\u529b\u5f3a\uff0c\u4e14\u95ee\u8d23\u548c\u8d23\u4efb\u53ef\u517c\u987e\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u53ef\u9760\u90e8\u7f72\u4eba\u5de5\u667a\u80fd\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u907f\u514d\u4eba\u7c7b\u66ff\u4ee3\u548c\u586b\u8865\u8d23\u4efb\u9e3f\u6c9f\u7684\u76ee\u6807\u3002\u7814\u7a76\u5173\u6ce8\u4e8e\u63d0\u4f9b\u4e00\u79cd\u4e0d\u540c\u4e8e\u4ee5\u5f80\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u7684\u89c2\u70b9\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u548c\u7528\u6237\u4f53\u9a8c\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u65e0\u9650\u8c03\u4f18\u201d\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\uff0c\u5e76\u9075\u5faa\u5173\u7cfb\u6027\u65b9\u6cd5\u3002\u7814\u7a76\u8be6\u7ec6\u8bf4\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4e00\u4e2a\u534f\u8bae\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e09\u4e2a\u539f\u578b\u5e94\u7528\uff1a\u8d37\u6b3e\u5ba1\u6279\u3001\u80ba\u708e\u8bca\u65ad\u548c\u827a\u672f\u98ce\u683c\u8bc6\u522b\u3002\u901a\u8fc7\u4e0e\u9886\u57df\u4e13\u5bb6\u7684\u6d4b\u8bd5\uff0c\u7814\u7a76\u5173\u6ce8\u7528\u6237\u4f53\u9a8c\u800c\u975e\u7edf\u8ba1\u51c6\u786e\u6027\uff0c\u5e76\u5bf9\u6280\u672f\u9009\u62e9\uff08\u5982XAI\u7b97\u6cd5\u7684\u53cd\u5411\u548c\u89e3\u91ca\u6027\u90e8\u7f72\uff09\u8fdb\u884c\u4e86\u54f2\u5b66\u63a2\u8ba8\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u5728\u51b3\u7b56\u8bbe\u7f6e\u4e2d\u4e5f\u80fd\u611f\u77e5\u5230\u5b8c\u5168\u7684\u63a7\u5236\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u5728\u53d1\u751f\u635f\u5bb3\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u5728\u95ee\u8d23\u5236\u548c\u8d23\u4efb\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u201c\u65e0\u9650\u8c03\u4f18\u201d\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u65e8\u5728\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u7684\u53ef\u9760\u90e8\u7f72\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\uff0c\u65e2\u907f\u514d\u4e86\u53d6\u4ee3\u4eba\u7c7b\uff0c\u53c8\u586b\u8865\u4e86\u8d23\u4efb\u9e3f\u6c9f\u3002\u7814\u7a76\u5c06\u6b64\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e09\u4e2a\u539f\u578b\u6848\u4f8b\uff08\u8d37\u6b3e\u5ba1\u6279\u3001\u80ba\u708e\u8bca\u65ad\u3001\u827a\u672f\u98ce\u683c\u8bc6\u522b\uff09\uff0c\u5e76\u4e0e\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u91cd\u70b9\u5173\u6ce8\u7528\u6237\u4f53\u9a8c\u800c\u975e\u7edf\u8ba1\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u4e5f\u80fd\u611f\u77e5\u5230\u51b3\u7b56\u8fc7\u7a0b\u7684\u5b8c\u5168\u63a7\u5236\uff0c\u5e76\u4e14\u5728\u53d1\u751f\u635f\u5bb3\u65f6\uff0c\u53ef\u4ee5\u5728\u8d23\u4efb\u548c\u95ee\u8d23\u4e4b\u95f4\u5efa\u7acb\u8054\u7cfb\u3002"}}
{"id": "2507.14353", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14353", "abs": "https://arxiv.org/abs/2507.14353", "authors": ["Harsh Nilesh Pathak", "Randy Paffenroth"], "title": "Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers", "comment": null, "summary": "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach\nfor adapting a Large Language Model (LLM) for newer tasks. One of the most\nprominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on\nadjusting the attention weight matrices within individual decoder blocks of a\nGenerative Pre trained Transformer (GPT2). In contrast, we introduce Solo\nConnection a novel method that adapts the representation at the decoder-block\nlevel rather than modifying individual weight matrices. Not only does Solo\nConnection outperform LoRA on E2E natural language generation benchmarks, but\nit also reduces the number of trainable parameters by 59% relative to LoRA and\nby more than 99% compared to full fine-tuning of GPT2, an early version of\nLarge Language Models (LLMs). Solo Connection is also motivated by homotopy\ntheory: we introduce a trainable linear transformation that gradually\ninterpolates between a zero vector and the task-specific representation,\nenabling smooth and stable adaptation over time. While skip connections in the\noriginal 12 layer GPT2 are typically confined to individual decoder blocks,\nsubsequent GPT2 variants scale up to 48 layers, and even larger language models\ncan include 128 or more decoder blocks. These expanded architectures underscore\nthe need to revisit how skip connections are employed during fine-tuning. This\npaper focuses on long skip connections that link outputs of different decoder\nblocks, potentially enhancing the model's ability to adapt to new tasks while\nleveraging pre-trained knowledge.", "AI": {"tldr": "PEFT methods like LoRA fine-tune LLMs by adjusting weight matrices. This paper introduces Solo Connection, which adapts representations at the decoder-block level instead. Solo Connection outperforms LoRA and significantly reduces trainable parameters, motivated by homotopy theory and the need for better fine-tuning in large LLMs.", "motivation": "The need to revisit how skip connections are employed during fine-tuning, especially in larger language models with many decoder blocks, and to find more parameter-efficient fine-tuning approaches than LoRA.", "method": "Solo Connection introduces a trainable linear transformation that gradually interpolates between a zero vector and the task-specific representation, enabling smooth and stable adaptation. It focuses on long skip connections that link outputs of different decoder blocks.", "result": "Solo Connection outperforms LoRA on E2E natural language generation benchmarks, reduces trainable parameters by 59% relative to LoRA and by more than 99% compared to full fine-tuning of GPT2.", "conclusion": "Solo Connection, a novel method that adapts the representation at the decoder-block level rather than modifying individual weight matrices, outperforms LoRA on E2E natural language generation benchmarks and significantly reduces trainable parameters."}}
{"id": "2507.15354", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15354", "abs": "https://arxiv.org/abs/2507.15354", "authors": ["Xuejun Gong", "Andrea Dal Corso"], "title": "High pressure and temperature thermoelasticity of hcp osmium from ab initio quasi-harmonic theory", "comment": "9 pages, 11 figures, 2 tables", "summary": "We present a systematic ab initio study of the thermoelastic properties of\nhcp osmium as functions of temperature and pressure within the quasi-harmonic\napproximation (QHA). The precision of the Zero Static Internal Stress\nApproximation (ZSISA) and of the volume-constrained ZSISA (V-ZSISA) are\nrigorously assessed. For osmium, we find negligible deviations between ZSISA\nand a full free energy minimization (FFEM) approach. Also, the V-ZSISA\napproximation influences the results very little, as we found already in\nberyllium, despite the markedly different behavior of the c/a ratio with\ntemperature in the two metals. Our QHA-derived ECs show excellent agreement\nwith available experimental data in the temperature range of 5-301 K,\noutperforming the results obtained from the quasi-static approximation (QSA).\nAdditionally, we report the pressure-dependent QHA ECs at 5 K, 301 K, and 1000\nK, spanning pressures from 0 to 150 kbar.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15344", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15344", "abs": "https://arxiv.org/abs/2507.15344", "authors": ["Jiahao Liu", "Cheng Wang", "Tianshu Bi"], "title": "RoCoF Constrained Regional Inertia Security Region: Formulation and Application", "comment": null, "summary": "The regional inertia, which determines the regional rate of change of\nfrequency (RoCoF), should be kept in a secure status in renewable-penetrated\npower systems. To break away from mapping the regional maximum RoCoF with\nregional inertia in a linearized form, this paper comprehensively studies the\nregional inertia security problem from formulation to applications. Firstly,\nthe regional inertia security region (R-ISR) is defined, whose boundary is\nnon-linear and non-convex. Then, a local linearized method is devised to\ncalculate the global maximum of regional RoCoF. The non-convex ISR boundary is\nexpressed by multiple simple boundaries corresponding to each local solution,\nwhich can be obtained by a simple search-based method. Finally, the convexified\nR-ISR constraint is formed by convex decomposition and embedded in an inertia\noptimal adjustment model. The results on a 3-region system show some\ncounter-intuitive findings, such as increasing the inertia of one region may\nworsen its RoCoF.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u533a\u57df\u60ef\u91cf\u5b89\u5168\u533a\u57df\uff08R-ISR\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8ba1\u7b97\u548c\u4f18\u5316\u53d7R-ISR\u7ea6\u675f\u7684\u533a\u57df\u60ef\u91cf\uff0c\u4ee5\u5e94\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u5e76\u7f51\u5e26\u6765\u7684\u6311\u6218\u3002\u7814\u7a76\u53d1\u73b0\u589e\u52a0\u533a\u57df\u60ef\u91cf\u5e76\u4e0d\u603b\u662f\u80fd\u6539\u5584\u9891\u7387\u7a33\u5b9a\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u542b\u5927\u91cf\u53ef\u518d\u751f\u80fd\u6e90\u7684\u7535\u529b\u7cfb\u7edf\u4e2d\uff0c\u533a\u57df\u60ef\u91cf\u4e0e\u533a\u57df\u6700\u5927\u9891\u7387\u53d8\u5316\u7387\uff08RoCoF\uff09\u7684\u7ebf\u6027\u6620\u5c04\u5173\u7cfb\u8fc7\u4e8e\u7b80\u5316\u7684\u7f3a\u70b9\uff0c\u672c\u6587\u65e8\u5728\u5168\u9762\u7814\u7a76\u533a\u57df\u60ef\u91cf\u5b89\u5168\u95ee\u9898\uff0c\u6db5\u76d6\u4ece\u6a21\u578b\u5efa\u7acb\u5230\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u9996\u5148\uff0c\u5b9a\u4e49\u4e86\u533a\u57df\u60ef\u91cf\u5b89\u5168\u533a\u57df\uff08R-ISR\uff09\uff0c\u5176\u8fb9\u754c\u4e3a\u975e\u7ebf\u6027\u4e14\u975e\u51f8\u7684\u3002\u7136\u540e\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5c40\u90e8\u7ebf\u6027\u5316\u65b9\u6cd5\u6765\u8ba1\u7b97\u533a\u57df\u6700\u5927RoCoF\u3002\u901a\u8fc7\u641c\u7d22\u65b9\u6cd5\u83b7\u5f97\u4e0e\u6bcf\u4e2a\u5c40\u90e8\u89e3\u5bf9\u5e94\u7684\u7b80\u5355\u8fb9\u754c\uff0c\u4ee5\u6b64\u6765\u8868\u793a\u975e\u51f8\u7684R-ISR\u8fb9\u754c\u3002\u6700\u540e\uff0c\u901a\u8fc7\u51f8\u5206\u89e3\u5c06R-ISR\u7ea6\u675f\u51f8\u5316\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u60ef\u91cf\u6700\u4f18\u8c03\u6574\u6a21\u578b\u3002", "result": "\u5728\u4e00\u4e2a\u4e09\u533a\u57df\u7cfb\u7edf\u4e0a\u7684\u7ed3\u679c\u663e\u793a\u4e86\u4e00\u4e9b\u53cd\u76f4\u89c9\u7684\u53d1\u73b0\uff0c\u4f8b\u5982\u589e\u52a0\u4e00\u4e2a\u533a\u57df\u7684\u60ef\u91cf\u53ef\u80fd\u4f1a\u5bfc\u81f4\u5176RoCoF\u6076\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u5b9a\u4e49\u4e86\u533a\u57df\u60ef\u91cf\u5b89\u5168\u533a\u57df\uff08R-ISR\uff09\uff0c\u5176\u8fb9\u754c\u4e3a\u975e\u7ebf\u6027\u4e14\u975e\u51f8\u7684\u3002\u901a\u8fc7\u5c40\u90e8\u7ebf\u6027\u5316\u65b9\u6cd5\u8ba1\u7b97\u533a\u57df\u6700\u5927\u9891\u7387\u53d8\u5316\u7387\uff08RoCoF\uff09\uff0c\u5e76\u5c06\u975e\u51f8\u7684R-ISR\u8fb9\u754c\u8868\u793a\u4e3a\u591a\u4e2a\u5c40\u90e8\u89e3\u5bf9\u5e94\u7684\u7b80\u5355\u8fb9\u754c\uff0c\u5229\u7528\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u83b7\u5f97\u8fd9\u4e9b\u8fb9\u754c\u3002\u6700\u540e\uff0c\u901a\u8fc7\u51f8\u5206\u89e3\u5c06R-ISR\u7ea6\u675f\u51f8\u5316\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u60ef\u91cf\u6700\u4f18\u8c03\u6574\u6a21\u578b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u589e\u52a0\u4e00\u4e2a\u533a\u57df\u7684\u60ef\u91cf\u6709\u65f6\u53cd\u800c\u4f1a\u6076\u5316\u5176RoCoF\u3002"}}
{"id": "2507.14892", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14892", "abs": "https://arxiv.org/abs/2507.14892", "authors": ["Yan Xing", "Xuedong Zhao", "Hui Jing", "Shi-Lei Su"], "title": "Exceptional-Point Dynamics", "comment": "7 pages, 3 figures for main text; 16pages, 5 figures for\n  Supplementary Material", "summary": "Exceptional points (EPs) play a vital role in non-Hermitian (NH) systems,\ndriving unique dynamical phenomena and promising innovative applications.\nHowever, the NH dynamics at EPs remains obscure due to the incomplete\nbiorthogonal eigenspaces of defective NH Hamiltonians and thus is often\navoided. In this Letter, we systematically establish pseudo-completeness\nrelations at EPs by employing all available generalized eigenstates, where both\nsingle and multiple arbitrary-order EPs embracing degenerate scenarios are\naddressed, to unveil EP dynamics. We reveal that depending on EP order and\ninitial conditions, the EP dynamics is characterized by a \\emph{polynomial\ngrowth over time} of EP eigenstates or their superposition, which will dominate\nlong-term evolution despite real spectra protected by pseudo-Hermiticity (PH),\nor can also become unitary. We further introduce two PH-compliant NH models to\ndemonstrate these EP dynamics and explore their applications. This work\ncompletes the dynamical investigation of NH physics, offers valuable insights\ninto nonunitary EP evolution, and further lays the groundwork for engineering\nNH devices and exploiting other EP-related technologies.", "AI": {"tldr": "\u7814\u7a76\u4e86\u975e\u5384\u7c73\u7cfb\u7edf\u5728\u5384\u7c73\u70b9\uff08EPs\uff09\u5904\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u53d1\u73b0\u5176\u52a8\u529b\u5b66\u8868\u73b0\u4e3a\u591a\u9879\u5f0f\u589e\u957f\u6216\u9149\u6f14\u5316\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5173\u6a21\u578b\u548c\u5e94\u7528\u3002", "motivation": "\u7531\u4e8e\u6709\u7f3a\u9677\u7684\u975e\u5384\u7c73\u54c8\u5bc6\u987f\u91cf\u7684\u53cc\u6b63\u4ea4\u7279\u5f81\u7a7a\u95f4\u4e0d\u5b8c\u5907\uff0cEPs\u5904\u7684\u975e\u5384\u7c73\u52a8\u529b\u5b66\u4ecd\u4e0d\u6e05\u695a\uff0c\u56e0\u6b64\u901a\u5e38\u88ab\u907f\u514d\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u91c7\u7528\u6240\u6709\u53ef\u7528\u7684\u5e7f\u4e49\u7279\u5f81\u6001\u6765\u7cfb\u7edf\u5730\u5efa\u7acbEPs\u5904\u7684\u4f2a\u5b8c\u5907\u6027\u5173\u7cfb\uff0c\u6db5\u76d6\u4e86\u5355EP\u548c\u591aEP\u7684\u9000\u5316\u60c5\u51b5\uff0c\u4ee5\u63ed\u793aEPs\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cEPs\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u8868\u73b0\u4e3a\u7279\u5f81\u6001\u6216\u5176\u53e0\u52a0\u7684\u201c\u591a\u9879\u5f0f\u589e\u957f\u201d\uff0c\u5e76\u53ef\u80fd\u8d8b\u4e8e\u9149\u6f14\u5316\uff0c\u8fd9\u53d6\u51b3\u4e8eEP\u7684\u9636\u6570\u548c\u521d\u59cb\u6761\u4ef6\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u4f2a\u5b8c\u5907\u6027\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u975e\u5384\u7c73\u7cfb\u7edf\u5728\u5384\u7c73\u70b9\uff08EPs\uff09\u5904\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u4f2a\u5384\u7c73\uff08PH\uff09\u7cfb\u7edf\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\uff0c\u4e3a\u5de5\u7a0b\u8bbe\u8ba1\u548c\u5f00\u53d1EPs\u76f8\u5173\u6280\u672f\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14649", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14649", "abs": "https://arxiv.org/abs/2507.14649", "authors": ["Minsuh Joo", "Hyunsoo Cho"], "title": "Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs", "comment": null, "summary": "Despite the outstanding performance of large language models (LLMs) across\nvarious NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate\nresponses--remains as a critical problem as it can be directly connected to a\ncrisis of building safe and reliable LLMs. Uncertainty estimation is primarily\nused to measure hallucination levels in LLM responses so that correct and\nincorrect answers can be distinguished clearly. This study proposes an\neffective uncertainty estimation approach, \\textbf{Cl}ust\\textbf{e}ring-based\nsem\\textbf{an}tic con\\textbf{s}ist\\textbf{e}ncy (\\textbf{Cleanse}). Cleanse\nquantifies the uncertainty with the proportion of the intra-cluster consistency\nin the total consistency between LLM hidden embeddings which contain adequate\nsemantic information of generations, by employing clustering. The effectiveness\nof Cleanse for detecting hallucination is validated using four off-the-shelf\nmodels, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two\nquestion-answering benchmarks, SQuAD and CoQA.", "AI": {"tldr": "Cleanse\u662f\u4e00\u79cd\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u4e0d\u51c6\u786e\u56de\u5e94\uff08\u5e7b\u89c9\uff09\u65b9\u9762\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8fd9\u5f71\u54cd\u4e86\u6784\u5efa\u5b89\u5168\u53ef\u9760\u7684LLMs\u7684\u4fe1\u4efb\u5ea6\u3002", "method": "Cleanse\u901a\u8fc7\u805a\u7c7b\u65b9\u6cd5\u91cf\u5316LLM\u9690\u85cf\u5d4c\u5165\u4e4b\u95f4\u7684\u5185\u90e8\u805a\u7c7b\u4e00\u81f4\u6027\u6bd4\u4f8b\u6765\u8861\u91cf\u4e0d\u786e\u5b9a\u6027\u3002", "result": "Cleanse\u5728LLaMA-7B\u3001LLaMA-13B\u3001LLaMA2-7B\u548cMistral-7B\u8fd9\u56db\u79cd\u6a21\u578b\u4ee5\u53caSQuAD\u548cCoQA\u8fd9\u4e24\u4e2a\u95ee\u7b54\u57fa\u51c6\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u68c0\u6d4b\u5e7b\u89c9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "Cleanse\u901a\u8fc7\u5229\u7528\u805a\u7c7b\u65b9\u6cd5\u91cf\u5316LLM\u9690\u85cf\u5d4c\u5165\u4e4b\u95f4\u7684\u5185\u90e8\u805a\u7c7b\u4e00\u81f4\u6027\u6bd4\u4f8b\u6765\u8861\u91cf\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u6709\u6548\u68c0\u6d4b\u5e7b\u89c9\u3002"}}
{"id": "2507.14185", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14185", "abs": "https://arxiv.org/abs/2507.14185", "authors": ["Abdullah Ahmed", "Jeremy Gummeson"], "title": "Latent Sensor Fusion: Multimedia Learning of Physiological Signals for Resource-Constrained Devices", "comment": null, "summary": "Latent spaces offer an efficient and effective means of summarizing data\nwhile implicitly preserving meta-information through relational encoding. We\nleverage these meta-embeddings to develop a modality-agnostic, unified encoder.\nOur method employs sensor-latent fusion to analyze and correlate multimodal\nphysiological signals. Using a compressed sensing approach with\nautoencoder-based latent space fusion, we address the computational challenges\nof biosignal analysis on resource-constrained devices. Experimental results\nshow that our unified encoder is significantly faster, lighter, and more\nscalable than modality-specific alternatives, without compromising\nrepresentational accuracy.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u7edf\u4e00\u7f16\u7801\u5668\u5229\u7528\u4f20\u611f\u5668-\u6f5c\u5728\u878d\u5408\u548c\u538b\u7f29\u4f20\u611f\u65b9\u6cd5\u6765\u9ad8\u6548\u3001\u51c6\u786e\u5730\u5206\u6790\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u8bbe\u5907\u3002", "motivation": "\u4e3a\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8bbe\u5907\u4e0a\u8fdb\u884c\u751f\u7269\u4fe1\u53f7\u5206\u6790\uff0c\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u6765\u6709\u6548\u5730\u603b\u7ed3\u6570\u636e\uff0c\u540c\u65f6\u901a\u8fc7\u5173\u7cfb\u7f16\u7801\u9690\u5f0f\u5730\u4fdd\u7559\u5143\u4fe1\u606f\u3002", "method": "\u5229\u7528\u4f20\u611f\u5668-\u6f5c\u5728\u878d\u5408\u548c\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u7684\u538b\u7f29\u4f20\u611f\u65b9\u6cd5\u6765\u5206\u6790\u548c\u5173\u8054\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7edf\u4e00\u7f16\u7801\u5668\u5728\u901f\u5ea6\u3001\u8f7b\u91cf\u5316\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u7279\u5b9a\u4e8e\u6a21\u6001\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8868\u793a\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7edf\u4e00\u7f16\u7801\u5668\u6bd4\u7279\u5b9a\u4e8e\u6a21\u6001\u7684\u66ff\u4ee3\u65b9\u6848\u66f4\u5feb\u3001\u66f4\u8f7b\u3001\u66f4\u5177\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u8868\u793a\u51c6\u786e\u6027\u3002"}}
{"id": "2507.15293", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15293", "abs": "https://arxiv.org/abs/2507.15293", "authors": ["Shanshan Zhang", "Tianshui Wen", "Siyue Wang", "Qi Zhang", "Ziheng Zhou", "Lingxiang Zheng", "Yu Yang"], "title": "RepILN: Reparameterized Inertial Localization Network", "comment": null, "summary": "Inertial localization is regarded as a promising positioning solution for\nconsumer-grade IoT devices due to its cost-effectiveness and independence from\nexternal infrastructure. However, data-driven inertial localization methods\noften rely on increasingly complex network architectures to improve accuracy,\nwhich challenges the limited computational resources of IoT devices. Moreover,\nthese methods frequently overlook the importance of modeling long-term\ndependencies in inertial measurements - a critical factor for accurate\ntrajectory reconstruction - thereby limiting localization performance. To\naddress these challenges, we propose a reparameterized inertial localization\nnetwork that uses a multi-branch structure during training to enhance feature\nextraction. At inference time, this structure is transformed into an equivalent\nsingle-path architecture to improve parameter efficiency. To further capture\nlong-term dependencies in motion trajectories, we introduce a temporal-scale\nsparse attention mechanism that selectively emphasizes key trajectory segments\nwhile suppressing noise. Additionally, a gated convolutional unit is\nincorporated to effectively integrate long-range dependencies with local\nfine-grained features. Extensive experiments on public benchmarks demonstrate\nthat our method achieves a favorable trade-off between accuracy and model\ncompactness. For example, on the RoNIN dataset, our approach reduces the\nAbsolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while\nreducing the number of parameters by 3.86%.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u60ef\u6027\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5206\u652f\u8bad\u7ec3\u3001\u5355\u8def\u5f84\u63a8\u7406\u3001\u7a00\u758f\u6ce8\u610f\u529b\u548c\u95e8\u63a7\u5377\u79ef\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u5904\u7406\u957f\u671f\u4f9d\u8d56\u6027\u65b9\u9762\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u7684\u60ef\u6027\u5b9a\u4f4d\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7f51\u7edc\u67b6\u6784\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u4ee5\u53ca\u5ffd\u7565\u8fd0\u52a8\u8f68\u8ff9\u957f\u671f\u4f9d\u8d56\u6027\u5bfc\u81f4\u5b9a\u4f4d\u6027\u80fd\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cd\u65b0\u53c2\u6570\u5316\u7684\u60ef\u6027\u5b9a\u4f4d\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5728\u8bad\u7ec3\u65f6\u91c7\u7528\u591a\u5206\u652f\u7ed3\u6784\u4ee5\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\uff0c\u5728\u63a8\u7406\u65f6\u5219\u8f6c\u6362\u4e3a\u7b49\u6548\u7684\u5355\u8def\u5f84\u67b6\u6784\u4ee5\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u65f6\u95f4\u5c3a\u5ea6\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6765\u6355\u6349\u8fd0\u52a8\u8f68\u8ff9\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408\u95e8\u63a7\u5377\u79ef\u5355\u5143\u6765\u6574\u5408\u957f\u7a0b\u4f9d\u8d56\u4e0e\u5c40\u90e8\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002", "result": "\u8be5\u65b9\u6cd5\u5728RoNIN\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6bd4RoNIN-ResNet\u4f4e2.59%\u7684\u7edd\u5bf9\u8f68\u8ff9\u8bef\u5dee\uff08ATE\uff09\uff0c\u540c\u65f6\u53c2\u6570\u91cf\u51cf\u5c11\u4e863.86%\uff0c\u5c55\u793a\u4e86\u5728\u51c6\u786e\u6027\u548c\u6a21\u578b\u7d27\u51d1\u6027\u4e4b\u95f4\u7684\u826f\u597d\u6743\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u91cd\u65b0\u53c2\u6570\u5316\u7684\u60ef\u6027\u5b9a\u4f4d\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u591a\u5206\u652f\u7ed3\u6784\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\uff0c\u5728\u63a8\u7406\u65f6\u8f6c\u6362\u4e3a\u7b49\u6548\u7684\u5355\u8def\u5f84\u67b6\u6784\u4ee5\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u3002\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u5c3a\u5ea6\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6765\u6355\u6349\u8fd0\u52a8\u8f68\u8ff9\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408\u95e8\u63a7\u5377\u79ef\u5355\u5143\u6574\u5408\u957f\u7a0b\u4f9d\u8d56\u4e0e\u5c40\u90e8\u7ec6\u7c92\u5ea6\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u548c\u6a21\u578b\u7d27\u51d1\u6027\u4e4b\u95f4\u7684\u826f\u597d\u6743\u8861\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728RoNIN\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8eRoNIN-ResNet\uff0c\u7edd\u5bf9\u8f68\u8ff9\u8bef\u5dee\uff08ATE\uff09\u964d\u4f4e\u4e862.59%\uff0c\u540c\u65f6\u53c2\u6570\u91cf\u51cf\u5c11\u4e863.86%\u3002"}}
{"id": "2507.14553", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.14553", "abs": "https://arxiv.org/abs/2507.14553", "authors": ["Xiaoran Wu"], "title": "Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance", "comment": null, "summary": "Clutter in photos is a distraction preventing photographers from conveying\nthe intended emotions or stories to the audience. Photography amateurs\nfrequently include clutter in their photos due to unconscious negligence or the\nlack of experience in creating a decluttered, aesthetically appealing scene for\nshooting. We are thus motivated to develop a camera guidance system that\nprovides solutions and guidance for clutter identification and removal. We\nestimate and visualize the contribution of objects to the overall aesthetics\nand content of a photo, based on which users can interactively identify\nclutter. Suggestions on getting rid of clutter, as well as a tool that removes\ncluttered objects computationally, are provided to guide users to deal with\ndifferent kinds of clutter and improve their photographic work. Two technical\nnovelties underpin interactions in our system: a clutter distinguishment\nalgorithm with aesthetics evaluations for objects and an iterative image\ninpainting algorithm based on generative adversarial nets that reconstructs\nmissing regions of removed objects for high-resolution images. User studies\ndemonstrate that our system provides flexible interfaces and accurate\nalgorithms that allow users to better identify distractions and take higher\nquality images within less time.", "AI": {"tldr": "\u4e00\u4e2a\u76f8\u673a\u5f15\u5bfc\u7cfb\u7edf\uff0c\u5e2e\u52a9\u6444\u5f71\u7231\u597d\u8005\u8bc6\u522b\u548c\u79fb\u9664\u7167\u7247\u4e2d\u7684\u5e72\u6270\u7269\uff0c\u4ee5\u63d0\u9ad8\u7167\u7247\u8d28\u91cf\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6444\u5f71\u7231\u597d\u8005\u56e0\u758f\u5ffd\u6216\u7f3a\u4e4f\u7ecf\u9a8c\u800c\u5728\u7167\u7247\u4e2d\u5305\u542b\u5e72\u6270\u7269\uff0c\u963b\u788d\u60c5\u611f\u548c\u6545\u4e8b\u4f20\u8fbe\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u76f8\u673a\u5f15\u5bfc\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f30\u8ba1\u548c\u53ef\u89c6\u5316\u5bf9\u8c61\u5bf9\u7167\u7247\u7f8e\u611f\u548c\u5185\u5bb9\u7684\u8d21\u732e\u6765\u8bc6\u522b\u548c\u79fb\u9664\u6df7\u4e71\u7269\u3002\u8be5\u7cfb\u7edf\u5305\u62ec\u4e00\u4e2a\u5177\u6709\u7f8e\u611f\u8bc4\u4f30\u7684\u6df7\u4e71\u533a\u5206\u7b97\u6cd5\u548c\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u7684\u8fed\u4ee3\u56fe\u50cf\u4fee\u590d\u7b97\u6cd5\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u754c\u9762\u548c\u51c6\u786e\u7684\u7b97\u6cd5\uff0c\u7528\u6237\u53ef\u4ee5\u66f4\u597d\u5730\u8bc6\u522b\u5e72\u6270\u7269\u5e76\u62cd\u51fa\u66f4\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u5e2e\u52a9\u7528\u6237\u5728\u66f4\u5c11\u7684\u65f6\u95f4\u5185\u8bc6\u522b\u5e72\u6270\u7269\u5e76\u62cd\u51fa\u66f4\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u3002"}}
{"id": "2507.14912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14912", "abs": "https://arxiv.org/abs/2507.14912", "authors": ["Ruhul Amin Khalil", "Kashif Ahmad", "Hazrat Ali"], "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities", "comment": null, "summary": "The global ageing population necessitates new and emerging strategies for\ncaring for older adults. In this article, we explore the potential for\ntransformation in elderly care through Agentic Artificial Intelligence (AI),\npowered by Large Language Models (LLMs). We discuss the proactive and\nautonomous decision-making facilitated by Agentic AI in elderly care.\nPersonalized tracking of health, cognitive care, and environmental management,\nall aimed at enhancing independence and high-level living for older adults,\nrepresents important areas of application. With a potential for significant\ntransformation of elderly care, Agentic AI also raises profound concerns about\ndata privacy and security, decision independence, and access. We share key\ninsights to emphasize the need for ethical safeguards, privacy protections, and\ntransparent decision-making. Our goal in this article is to provide a balanced\ndiscussion of both the potential and the challenges associated with Agentic AI,\nand to provide insights into its responsible use in elderly care, to bring\nAgentic AI into harmony with the requirements and vulnerabilities specific to\nthe elderly. Finally, we identify the priorities for the academic research\ncommunities, to achieve human-centered advancements and integration of Agentic\nAI in elderly care. To the best of our knowledge, this is no existing study\nthat reviews the role of Agentic AI in elderly care. Hence, we address the\nliterature gap by analyzing the unique capabilities, applications, and\nlimitations of LLM-based Agentic AI in elderly care. We also provide a\ncompanion interactive dashboard at https://hazratali.github.io/agenticai/.", "AI": {"tldr": "Agentic AI, powered by LLMs, offers transformative potential for elderly care through personalized support but raises significant ethical concerns regarding privacy and decision-making that require careful management.", "motivation": "The growing global aging population creates a need for new strategies in elderly care. This article aims to explore the transformative potential of Agentic AI, powered by LLMs, in addressing this need by discussing its applications, benefits, and challenges.", "method": "This article explores the potential of Agentic Artificial Intelligence (AI), powered by Large Language Models (LLMs), in the transformation of elderly care. It addresses a literature gap by analyzing the unique capabilities, applications, and limitations of LLM-based Agentic AI in this domain. The authors also provide a companion interactive dashboard.", "result": "The analysis highlights the proactive and autonomous decision-making capabilities of Agentic AI in personalized health tracking, cognitive care, and environmental management for older adults. It also identifies significant concerns regarding data privacy, security, decision independence, and access, emphasizing the need for ethical safeguards and transparency.", "conclusion": "Agentic AI has the potential to significantly transform elderly care by enabling personalized health tracking, cognitive support, and environmental management, thereby enhancing independence and quality of life for older adults. However, ethical considerations such as data privacy, security, decision independence, and access must be addressed through robust safeguards, privacy protections, and transparent decision-making processes to ensure responsible integration."}}
{"id": "2507.14387", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14387", "abs": "https://arxiv.org/abs/2507.14387", "authors": ["Arun Vignesh Malarkkan", "Dongjie Wang", "Haoyue Bai", "Yanjie Fu"], "title": "Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures", "comment": "12 pages, 5 figures, 3 Tables, under review in IEEE Transactions on\n  Big Data", "summary": "The escalating threat of cyberattacks on real-time critical infrastructures\nposes serious risks to public safety, demanding detection methods that\neffectively capture complex system interdependencies and adapt to evolving\nattack patterns. Traditional real-time anomaly detection techniques often\nsuffer from excessive false positives due to their statistical sensitivity to\nhigh data variance and class imbalance. To address these limitations, recent\nresearch has explored modeling causal relationships among system components.\nHowever, prior work mainly focuses on offline causal graph-based approaches\nthat require static historical data and fail to generalize to real-time\nsettings. These methods are fundamentally constrained by: (1) their inability\nto adapt to dynamic shifts in data distribution without retraining, and (2) the\nrisk of catastrophic forgetting when lacking timely supervision in live\nsystems. To overcome these challenges, we propose INCADET, a novel framework\nfor incremental causal graph learning tailored to real-time cyberattack\ndetection. INCADET dynamically captures evolving system behavior by\nincrementally updating causal graphs across streaming time windows. The\nframework comprises three modules: 1) Early Symptom Detection: Detects\ntransitions in system status using divergence in edge-weight distributions\nacross sequential causal graphs. 2) Incremental Causal Graph Learning:\nLeverages experience replay and edge reinforcement to continually refine causal\nstructures while preserving prior knowledge. 3) Causal Graph Classification:\nEmploys Graph Convolutional Networks (GCNs) to classify system status using the\nlearned causal graphs. Extensive experiments on real-world critical\ninfrastructure datasets demonstrate that INCADET achieves superior accuracy,\nrobustness, and adaptability compared to both static causal and deep temporal\nbaselines in evolving attack scenarios.", "AI": {"tldr": "INCADET \u662f\u4e00\u4e2a\u7528\u4e8e\u5b9e\u65f6\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u91cf\u5b66\u4e60\u56e0\u679c\u56fe\u6765\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u56e0\u5bf9\u9ad8\u6570\u636e\u65b9\u5dee\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u7edf\u8ba1\u654f\u611f\u6027\u800c\u4ea7\u751f\u8fc7\u591a\u7684\u8bef\u62a5\u3002\u867d\u7136\u4e00\u4e9b\u7814\u7a76\u8bd5\u56fe\u901a\u8fc7\u5bf9\u7cfb\u7edf\u7ec4\u4ef6\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\u6765\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u4f46\u5148\u524d\u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u9700\u8981\u9759\u6001\u5386\u53f2\u6570\u636e\u4e14\u65e0\u6cd5\u6cdb\u5316\u5230\u5b9e\u65f6\u73af\u5883\u7684\u79bb\u7ebf\u56e0\u679c\u56fe\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u53d7\u5230\u65e0\u6cd5\u5728\u6ca1\u6709\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9002\u5e94\u6570\u636e\u5206\u5e03\u7684\u52a8\u6001\u53d8\u5316\u4ee5\u53ca\u5728\u7f3a\u4e4f\u5b9e\u65f6\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u7684\u9650\u5236\u3002", "method": "INCADET \u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u91cf\u56e0\u679c\u56fe\u5b66\u4e60\uff0c\u4e13\u95e8\u7528\u4e8e\u5b9e\u65f6\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5728\u6d41\u5f0f\u65f6\u95f4\u7a97\u53e3\u4e2d\u4e0d\u65ad\u66f4\u65b0\u56e0\u679c\u56fe\u6765\u52a8\u6001\u6355\u83b7\u4e0d\u65ad\u6f14\u53d8\u7684\u7cfb\u7edf\u884c\u4e3a\u3002\u8be5\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u6a21\u5757\uff1a1\uff09\u65e9\u671f\u75c7\u72b6\u68c0\u6d4b\uff1a\u4f7f\u7528\u8fde\u7eed\u56e0\u679c\u56fe\u4e2d\u8fb9\u6743\u91cd\u5206\u5e03\u7684\u5dee\u5f02\u6765\u68c0\u6d4b\u7cfb\u7edf\u72b6\u6001\u7684\u8f6c\u53d8\u30022\uff09\u589e\u91cf\u56e0\u679c\u56fe\u5b66\u4e60\uff1a\u5229\u7528\u7ecf\u9a8c\u56de\u653e\u548c\u8fb9\u5f3a\u5316\u6765\u6301\u7eed\u4f18\u5316\u56e0\u679c\u7ed3\u6784\uff0c\u540c\u65f6\u4fdd\u7559\u5148\u9a8c\u77e5\u8bc6\u30023\uff09\u56e0\u679c\u56fe\u5206\u7c7b\uff1a\u91c7\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u6765\u5229\u7528\u5b66\u4e60\u5230\u7684\u56e0\u679c\u56fe\u5bf9\u7cfb\u7edf\u72b6\u6001\u8fdb\u884c\u5206\u7c7b\u3002", "result": "INCADET \u5728\u771f\u5b9e\u4e16\u754c\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5e76\u5728\u4e0d\u65ad\u6f14\u53d8\u7684\u653b\u51fb\u573a\u666f\u4e2d\uff0c\u4e0e\u9759\u6001\u56e0\u679c\u548c\u6df1\u5ea6\u65f6\u95f4\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u5747\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "INCADET \u5728\u771f\u5b9e\u4e16\u754c\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5e76\u5728\u4e0d\u65ad\u6f14\u53d8\u7684\u653b\u51fb\u573a\u666f\u4e2d\uff0c\u4e0e\u9759\u6001\u56e0\u679c\u548c\u6df1\u5ea6\u65f6\u95f4\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u5747\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2507.15369", "categories": ["cond-mat.mtrl-sci", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2507.15369", "abs": "https://arxiv.org/abs/2507.15369", "authors": ["Hanlin Yu", "Maksym Seredyuk", "Nan Ma", "Katerina Znoviak", "Nikita Liedienov", "M. Carmen Mu\u00f1oz", "Iv\u00e1n da Silva", "Francisco-Javier Valverde Mu\u00f1oz", "Ricardo-Guillermo Torres Ram\u00edrez", "Elzbieta Trzop", "Wei Xu", "Quanjun Li", "Bingbing Liu", "Georgiy Levchenko", "J. Antonio Real"], "title": "Pressure-Induced Low-Spin State Destabilization and Piezo-Chromic Effect in an Iron(II) Spin Crossover Complex with Pyrazol-Pyridine-Triazolate Coordination Core", "comment": "42 pages, 1 scheme, 21 figures, 7 tables", "summary": "Rapidly developing science and technology demand new materials with versatile\nand promising properties for practical applications. In this context,\npseudo-octahedral iron(II) spin crossover (SCO) complexes are particularly\nappealing - not only for their fundamental scientific interest but also for\ntheir potential as key components in the development of multifunctional\nswitchable molecular materials and novel technological applications. This work\npresents the synthesis and structure of a new mononuclear SCO complex\n[FeII(L)2]0*nMeOH (n = 2, 0) where L is the asymmetrically substituted\ntridentate ligand\n[4-trifluoromethylphenyl-(1H-1,2,4-triazol-5-yl)-6-(1H-pyrazol-1-yl)pyridine].\nDue to high trigonal distortion, the solvated form (n = 2) remains high spin\n(HS) at all temperatures. In contrast, the more regular Oh geometry of the\nunsolvated form, 4CF3, favors a complete spin transition (ST) at room\ntemperature, which has been investigated, in the pressure interval 0-0.64 GPa,\nby means of its magnetic and optical properties. Contrary to intuition and\nexperience, the increase of pressure on 4CF3 denotes a radically abnormal\nbehavior of this ST, involving: i) decrease of the characteristic temperatures,\nii) increase of the high-spin molar fraction in the temperature range where the\nlow-spin state is stable at ambient pressure; iii) increase of the thermal\nhysteresis width; and iv) above certain threshold pressure, full stabilization\nof the high-spin state. All these observations have been explained in the\nframework of a thermodynamic that model based on the elastic interactions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5408\u6210\u4e86\u4e00\u79cd\u65b0\u7684\u94c1(II)\u81ea\u65cb\u4ea4\u53c9\u914d\u5408\u7269\uff0c\u53d1\u73b0\u5176\u5728\u538b\u529b\u4e0b\u8868\u73b0\u51fa\u53cd\u5e38\u7684\u81ea\u65cb\u8f6c\u53d8\u884c\u4e3a\uff0c\u5e76\u7528\u5305\u542b\u5f39\u6027\u76f8\u4e92\u4f5c\u7528\u7684\u70ed\u529b\u5b66\u6a21\u578b\u89e3\u91ca\u4e86\u8fd9\u4e9b\u73b0\u8c61\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u79d1\u5b66\u6280\u672f\u5bf9\u5177\u6709\u591a\u529f\u80fd\u548c\u6f5c\u5728\u5e94\u7528\u524d\u666f\u7684\u65b0\u6750\u6599\u7684\u9700\u6c42\uff0c\u672c\u7814\u7a76\u5173\u6ce8\u5177\u6709\u57fa\u7840\u79d1\u5b66\u610f\u4e49\u548c\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u7684\u94c1(II)\u81ea\u65cb\u4ea4\u53c9\uff08SCO\uff09\u914d\u5408\u7269\u3002\u7279\u522b\u5730\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b0\u578bSCO\u914d\u5408\u7269\u5728\u538b\u529b\u4e0b\u7684\u53cd\u5e38\u81ea\u65cb\u8f6c\u53d8\u884c\u4e3a\uff0c\u4ee5\u52a0\u6df1\u5bf9\u5176\u7269\u7406\u5316\u5b66\u6027\u8d28\u7684\u7406\u89e3\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5408\u6210\u65b0\u7684\u5355\u6838SCO\u914d\u5408\u7269 [FeII(L)2]0*nMeOH\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5728\u4e0d\u540c\u538b\u529b\u4e0b\u7684\u78c1\u5b66\u548c\u5149\u5b66\u6027\u8d28\uff0c\u4ee5\u63a2\u7d22\u5176\u81ea\u65cb\u4ea4\u53c9\u884c\u4e3a\u3002\u4f7f\u7528\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\u6280\u672f\uff0c\u5305\u62ec\u78c1\u5316\u7387\u6d4b\u91cf\u548c\u5149\u5b66\u5149\u8c31\u5206\u6790\uff0c\u5e76\u7ed3\u5408\u70ed\u529b\u5b66\u6a21\u578b\u6765\u89e3\u91ca\u89c2\u5bdf\u5230\u7684\u73b0\u8c61\u3002", "result": "\u7814\u7a76\u6210\u529f\u5408\u6210\u4e86\u65b0\u7684\u5355\u6838SCO\u914d\u5408\u7269 [FeII(L)2]0*nMeOH\u3002\u6eb6\u5242\u5316\u5f62\u5f0f\u5728\u9ad8\u81ea\u65cb\u72b6\u6001\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u800c\u975e\u6eb6\u5242\u5316\u5f62\u5f0f\u5728\u5ba4\u6e29\u4e0b\u8868\u73b0\u51fa\u81ea\u65cb\u8f6c\u53d8\u3002\u538b\u529b\u5bf9\u975e\u6eb6\u5242\u5316\u5f62\u5f0f\u7684ST\u8868\u73b0\u51fa\u53cd\u5e38\u5f71\u54cd\uff0c\u5305\u62ec\u7279\u5f81\u6e29\u5ea6\u964d\u4f4e\u3001\u4f4e\u6e29\u533a\u9ad8\u81ea\u65cb\u6bd4\u4f8b\u589e\u52a0\u3001\u70ed\u6ede\u56de\u7ebf\u53d8\u5bbd\u4ee5\u53ca\u5728\u9ad8\u538b\u4e0b\u7a33\u5b9a\u5728\u9ad8\u81ea\u65cb\u72b6\u6001\u3002\u8fd9\u4e9b\u7ed3\u679c\u901a\u8fc7\u5305\u542b\u5f39\u6027\u76f8\u4e92\u4f5c\u7528\u7684\u70ed\u529b\u5b66\u6a21\u578b\u5f97\u5230\u4e86\u5408\u7406\u89e3\u91ca\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5355\u6838\u81ea\u65cb\u4ea4\u53c9\uff08SCO\uff09\u914d\u5408\u7269 [FeII(L)2]0*nMeOH\uff0c\u5176\u4e2dL\u662f[4-\u4e09\u6c1f\u7532\u57fa\u82ef\u57fa-(1H-1,2,4-\u4e09\u5511-5-\u57fa)-6-(1H-\u5421\u5511-1-\u57fa)\u5421\u5576]\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6eb6\u5242\u5316\u5f62\u5f0f\uff08n=2\uff09\u5728\u6240\u6709\u6e29\u5ea6\u4e0b\u5747\u4fdd\u6301\u9ad8\u81ea\u65cb\u72b6\u6001\uff0c\u800c\u975e\u6eb6\u5242\u5316\u5f62\u5f0f\uff084CF3\uff09\u5728\u5ba4\u6e29\u4e0b\u8868\u73b0\u51fa\u5b8c\u6574\u7684\u81ea\u65cb\u8f6c\u53d8\uff08ST\uff09\u3002\u7136\u800c\uff0c\u538b\u529b\u5bf9\u5176ST\u8868\u73b0\u51fa\u53cd\u5e38\u884c\u4e3a\uff0c\u5305\u62ec\u7279\u5f81\u6e29\u5ea6\u964d\u4f4e\u3001\u5728\u4f4e\u6e29\u533a\u9ad8\u81ea\u65cb\u6469\u5c14\u5206\u6570\u589e\u52a0\u3001\u70ed\u6ede\u56de\u7ebf\u5bbd\u5ea6\u589e\u52a0\uff0c\u4ee5\u53ca\u5728\u9ad8\u538b\u4e0b\u7a33\u5b9a\u5728\u9ad8\u81ea\u65cb\u72b6\u6001\u3002\u8fd9\u4e9b\u73b0\u8c61\u5df2\u901a\u8fc7\u57fa\u4e8e\u5f39\u6027\u76f8\u4e92\u4f5c\u7528\u7684\u70ed\u529b\u5b66\u6a21\u578b\u5f97\u5230\u89e3\u91ca\u3002"}}
{"id": "2507.15358", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15358", "abs": "https://arxiv.org/abs/2507.15358", "authors": ["Jiahao Liu", "Cheng Wang", "Tianshu Bi"], "title": "Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part I: Center of Inertia", "comment": null, "summary": "Understanding the impact of grid-following (GFL) converters on system\nfrequency dynamics is crucial, from both the center of inertia (COI) and\nfrequency spatial variation perspectives. Part I of this series clarifies the\nmechanisms by which GFLs influence COI frequency dynamics. A multi-generator\nmodel of the power system with GFLs is developed, incorporating the local\ndynamics of GFLs and their interaction with synchronous generators via virtual\ntie lines. By aggregating the multi-generator model into the COI frame, the\ninteraction between the COI frequency and the equivalent frequency of GFLs is\nrevealed. The equivalent inertia and other components at the GFL side,\ndetermined by control parameters and operating conditions, support the COI\nthrough virtual tying power. Simulation validates the accuracy of the proposed\nmodeling and demonstrates that the impact of GFLs on COI frequency is\nrelatively weak. The equivalent inertia and other components of GFLs still\nsignificantly influence COI frequency dynamics, with their effects being both\ntime-variable and adjustable.", "AI": {"tldr": "GFLs\u5bf9COI\u9891\u7387\u52a8\u6001\u7684\u5f71\u54cd\u662f\u6709\u9650\u7684\uff0c\u4f46\u5b83\u4eec\u7684\u7b49\u6548\u60ef\u91cf\u662f\u53ef\u53d8\u7684\uff0c\u5e76\u4e14\u4f1a\u5f71\u54cdCOI\u9891\u7387\u3002", "motivation": "\u7406\u89e3GFLs\u5bf9\u7cfb\u7edf\u9891\u7387\u52a8\u6001\uff08\u4eceCOI\u548c\u9891\u7387\u7a7a\u95f4\u53d8\u5f02\u6027\u89d2\u5ea6\uff09\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542bGFLs\u548c\u540c\u6b65\u53d1\u7535\u673a\u7684\u591a\u673a\u7ec4\u7535\u529b\u7cfb\u7edf\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u865a\u62df\u8f93\u7535\u7ebf\u8def\u5c06GFLs\u7684\u5c40\u90e8\u52a8\u6001\u4e0e\u5176\u8fdb\u884c\u4ea4\u4e92\u3002\u901a\u8fc7\u5c06\u591a\u673a\u7ec4\u6a21\u578b\u805a\u5408\u5230COI\u6846\u67b6\u4e2d\uff0c\u63ed\u793a\u4e86COI\u9891\u7387\u4e0eGFLs\u7b49\u6548\u9891\u7387\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u8868\u660eGFLs\u5bf9COI\u9891\u7387\u7684\u5f71\u54cd\u76f8\u5bf9\u8f83\u5f31\uff0c\u4f46GFLs\u7684\u7b49\u6548\u60ef\u91cf\u548c\u5176\u4ed6\u5206\u91cf\u5bf9COI\u9891\u7387\u52a8\u6001\u4ecd\u7136\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5176\u5f71\u54cd\u5177\u6709\u65f6\u53d8\u6027\u548c\u53ef\u8c03\u6027\u3002", "conclusion": "GFLs\u5bf9COI\u9891\u7387\u7684\u5f71\u54cd\u76f8\u5bf9\u8f83\u5f31\uff0c\u4f46\u5176\u7b49\u6548\u60ef\u91cf\u548c\u5176\u4ed6\u5206\u91cf\u5bf9COI\u9891\u7387\u52a8\u6001\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u5f71\u54cd\u5177\u6709\u65f6\u53d8\u6027\u548c\u53ef\u8c03\u6027\u3002"}}
{"id": "2507.14895", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.14895", "abs": "https://arxiv.org/abs/2507.14895", "authors": ["Dhiman Bhowmick", "Wen Wei Ho"], "title": "Granovskii-Zhedanov Scar of XYZ Spin-chain: Modern Algebraic Perspectives and Realization in Higher Dimensional Lattices", "comment": "21 pages, 9 figures", "summary": "In a work by Granovskii and Zhedanov, a surprising scar state exhibiting zero\nentanglement and long periodicity was discovered in the XYZ spin chains;\nremarkably, nearly three decades before the concept of many-body scars became a\nsubject of active research. In this study, we uncover the origin of the\nGranovskii-Zhedanov (GZ) scar within the framework of the modern understanding\nof quantum many-body scars. We demonstrate that the scar subspace can be\neffectively described using the standard spectrum-generating algebra (SGA)\nframework and through a group-theoretical formulation of the Hamiltonian. This\ndescription, however, is applicable only in the XXZ limit, where a quasi-$U(1)$\nsymmetry exists within the scar subspace. In contrast, the absence of such\nquasi-$U(1)$ symmetry for the GZ scar subspace restricts the applicability of\nthese standard formulations. We propose two alternative techniques:\napproximated SGA and generalized SGA, which construct and describe the scar\nsubspace in the XYZ case. Using these approaches, we can characterize the scar\nsubspaces. We further explore the possibility of constructing\nlattice-independent GZ scars in higher-dimensional uniform spin-exchange\nsystems with centrosymmetry, using graphical rules developed for GZ scar\nconstruction. Our results indicate that lattice-independent GZ scars cannot be\nsupported on uniform lattices with odd coordination numbers or plaquettes with\nan odd number of edges, while uniform lattices featuring even coordination\nnumbers and even-edged plaquettes can host such lattice-independent scars in\nspecific scenarios. Remarkably, if certain bonds retain the full $SU(2)$\nsymmetry of the spin-exchange interaction, thereby breaking the spatial\nuniformity of the lattice, lattice-independent GZ scars can still emerge in\nsystems with odd coordination numbers or plaquettes with an odd number of\nedges.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u91cf\u5b50\u591a\u4f53\u62df\u6001\u6846\u67b6\u4e0b\u89e3\u91ca\u4e86GZ\u62df\u6001\u7684\u8d77\u6e90\uff0c\u5e76\u4e3aXYZ\u6a21\u578b\u5f00\u53d1\u4e86\u65b0\u7684\u63cf\u8ff0\u65b9\u6cd5\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u6676\u683c\u7ed3\u6784\u5bf9GZ\u62df\u6001\u7684\u5b58\u5728\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u901a\u8fc7\u4fdd\u7559\u67d0\u4e9b\u952e\u7684SU(2)\u5bf9\u79f0\u6027\uff0c\u53ef\u4ee5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "motivation": "\u4e3a\u4e86\u5728\u73b0\u4ee3\u91cf\u5b50\u591a\u4f53\u62df\u6001\u7406\u8bba\u6846\u67b6\u4e0b\u7406\u89e3\u5e76\u63ed\u793a\u4e09\u5341\u5e74\u524d\u53d1\u73b0\u7684Granovskii-Zhedanov (GZ) \u62df\u6001\u7684\u8d77\u6e90\uff0c\u7279\u522b\u662f\u5728XYZ\u81ea\u65cb\u94fe\u4e2d\u5b58\u5728\u7684\u96f6\u7ea0\u7f20\u548c\u957f\u5468\u671f\u7279\u6027\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6807\u51c6SGA\u6846\u67b6\u5728\u63cf\u8ff0GZ\u62df\u6001\u5b50\u7a7a\u95f4\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406XYZ\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u73b0\u4ee3\u91cf\u5b50\u591a\u4f53\u62df\u6001\u7684\u7406\u89e3\u6846\u67b6\uff0c\u5229\u7528\u8c31\u751f\u6210\u4ee3\u6570\uff08SGA\uff09\u548c\u54c8\u5bc6\u987f\u91cf\u7684\u7fa4\u8bba\u5f62\u5f0f\u6765\u63cf\u8ff0GZ\u62df\u6001\u5b50\u7a7a\u95f4\u3002\u9488\u5bf9XYZ\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u8fd1\u4f3cSGA\u548c\u5e7f\u4e49SGA\u4e24\u79cd\u65b0\u65b9\u6cd5\u6765\u6784\u9020\u548c\u63cf\u8ff0\u62df\u6001\u5b50\u7a7a\u95f4\u3002\u5229\u7528\u4e3aGZ\u62df\u6001\u6784\u9020\u8bbe\u8ba1\u7684\u56fe\u89e3\u89c4\u5219\uff0c\u63a2\u7d22\u4e86\u5728\u66f4\u9ad8\u7ef4\u5ea6\u5747\u5300\u81ea\u65cb\u4ea4\u6362\u7cfb\u7edf\u4e2d\u6784\u5efa\u4e0e\u6676\u683c\u65e0\u5173\u7684GZ\u62df\u6001\u7684\u53ef\u80fd\u6027\u3002", "result": "\u5728XXZ\u6781\u9650\u4e0b\uff0cGZ\u62df\u6001\u5b50\u7a7a\u95f4\u53ef\u4ee5\u7528\u6807\u51c6\u7684SGA\u6846\u67b6\u548c\u7fa4\u8bba\u65b9\u6cd5\u63cf\u8ff0\uff0c\u4f46\u7531\u4e8eGZ\u62df\u6001\u5b50\u7a7a\u95f4\u4e2d\u4e0d\u5b58\u5728\u51c6U(1)\u5bf9\u79f0\u6027\uff0c\u6807\u51c6\u65b9\u6cd5\u5931\u6548\u3002\u63d0\u51fa\u7684\u8fd1\u4f3cSGA\u548c\u5e7f\u4e49SGA\u65b9\u6cd5\u80fd\u591f\u6784\u9020\u548c\u63cf\u8ff0XYZ\u6a21\u578b\u4e2d\u7684GZ\u62df\u6001\u5b50\u7a7a\u95f4\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u6676\u683c\u65e0\u5173\u7684GZ\u62df\u6001\u4e0d\u80fd\u5b58\u5728\u4e8e\u534f\u8c03\u6570\u6216\u5177\u6709\u5947\u6570\u6761\u8fb9\u7684\u83f1\u5f62\u533a\u57df\u7684\u6676\u683c\u4e0a\uff0c\u4f46\u53ef\u4ee5\u5728\u534f\u8c03\u6570\u4e3a\u5076\u6570\u4e14\u83f1\u5f62\u533a\u57df\u5177\u6709\u5076\u6570\u6761\u8fb9\u7684\u6676\u683c\u4e0a\u5b58\u5728\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u5728\u534f\u8c03\u6570\u4e3a\u5947\u6570\u6216\u83f1\u5f62\u533a\u57df\u5177\u6709\u5947\u6570\u6761\u8fb9\u7684\u7cfb\u7edf\u4e2d\uff0c\u53ea\u8981\u67d0\u4e9b\u952e\u4fdd\u7559\u5b8c\u6574\u7684SU(2)\u5bf9\u79f0\u6027\uff0c\u6253\u7834\u7a7a\u95f4\u5747\u5300\u6027\uff0c\u4e5f\u53ef\u4ee5\u51fa\u73b0\u4e0e\u6676\u683c\u65e0\u5173\u7684GZ\u62df\u6001\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86Granovskii-Zhedanov (GZ) \u62df\u6001\u5728\u73b0\u4ee3\u91cf\u5b50\u591a\u4f53\u62df\u6001\u7406\u8bba\u6846\u67b6\u4e0b\u7684\u8d77\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86\u7528\u4e8e\u63cf\u8ff0\u548c\u6784\u9020XYZ\u6a21\u578b\u4e2dGZ\u62df\u6001\u5b50\u7a7a\u95f4\u7684\u8fd1\u4f3c\u548c\u5e7f\u4e49\u8c31\u751f\u6210\u4ee3\u6570\uff08SGA\uff09\u65b9\u6cd5\u3002\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u5728\u66f4\u9ad8\u7ef4\u5ea6\u7684\u4e2d\u5fc3\u5bf9\u79f0\u81ea\u65cb\u4ea4\u6362\u7cfb\u7edf\u4e2d\u6784\u9020\u4e0e\u6676\u683c\u65e0\u5173\u7684GZ\u62df\u6001\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u6676\u683c\u7ed3\u6784\u5bf9\u62df\u6001\u5b58\u5728\u7684\u9650\u5236\uff0c\u540c\u65f6\u53d1\u73b0\u5373\u4f7f\u5728\u7a7a\u95f4\u975e\u5747\u5300\u7684\u60c5\u51b5\u4e0b\uff0cGZ\u62df\u6001\u4e5f\u53ef\u4ee5\u5b58\u5728\u3002"}}
{"id": "2507.14664", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14664", "abs": "https://arxiv.org/abs/2507.14664", "authors": ["Wannaphong Phatthiyaphaibun", "Can Udomcharoenchaikit", "Pakpoom Singkorapoom", "Kunat Pipatanakul", "Ekapol Chuangsuwanich", "Peerat Limkonchotiwat", "Sarana Nutanong"], "title": "Mangosteen: An Open Thai Corpus for Language Model Pretraining", "comment": "Work in Progress.All artifacts in this papers:\n  https://huggingface.co/collections/aisingapore/wangchanlion-v3-687a362d8f0ea2fe4077c6b3", "summary": "Pre-training data shapes a language model's quality, but raw web text is\nnoisy and demands careful cleaning. Existing large-scale corpora rely on\nEnglish-centric or language-agnostic pipelines whose heuristics do not capture\nThai script or cultural nuances, leaving risky material such as gambling\ncontent untreated. Prior Thai-specific efforts customize pipelines or build new\nones, yet seldom release their data or document design choices, hindering\nreproducibility and raising the question of how to construct a transparent,\nhigh-quality Thai corpus. We introduce Mangosteen: a 47 billion-token Thai\ncorpus built through a Thai-adapted Dolma pipeline that includes custom\nrule-based language ID, revised C4/Gopher quality filters, and Thai-trained\ncontent filters, plus curated non-web sources such as Wikipedia, Royal Gazette\ntexts, OCR-extracted books, and CC-licensed YouTube subtitles. Systematic\nablations using GPT-2 show the pipeline trims CommonCrawl from 202M to 25M\ndocuments while raising SEA-HELM NLG from 3 to 11; an 8B-parameter SEA-LION\nmodel continually pre-trained on Mangosteen then surpasses SEA-LION-v3 and\nLlama-3.1 by about four points on Thai benchmarks. We release the full pipeline\ncode, cleaning manifests, corpus snapshot, and all checkpoints, providing a\nfully reproducible foundation for future Thai and regional LLM research.", "AI": {"tldr": "Mangosteen\u662f\u4e00\u4e2a\u5305\u542b470\u4ebftoken\u7684\u6cf0\u8bed\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u6539\u8fdb\u7684Dolma\u5904\u7406\u6d41\u7a0b\u6784\u5efa\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6cf0\u8bed\u8bed\u6599\u5e93\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u6cf0\u8bed\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u516c\u5f00\u4e86\u6240\u6709\u76f8\u5173\u8d44\u6e90\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6570\u636e\u5904\u7406\u6d41\u7a0b\u672a\u80fd\u5145\u5206\u8003\u8651\u5230\u6cf0\u8bed\u7684\u8bed\u8a00\u7279\u70b9\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\uff0c\u5bfc\u81f4\u5b58\u5728\u4e0d\u5f53\u5185\u5bb9\uff0c\u5e76\u4e14\u73b0\u6709\u9488\u5bf9\u6cf0\u8bed\u7684\u5b9a\u5236\u5316\u65b9\u6cd5\u5f80\u5f80\u4e0d\u516c\u5f00\u6570\u636e\u6216\u8bbe\u8ba1\u9009\u62e9\uff0c\u963b\u788d\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u900f\u660e\u3001\u9ad8\u8d28\u91cf\u7684\u6cf0\u8bed\u8bed\u6599\u5e93\u3002", "method": "Mangosteen\u8bed\u6599\u5e93\u662f\u901a\u8fc7\u4e00\u4e2a\u9488\u5bf9\u6cf0\u8bed\u7684Dolma\u5904\u7406\u6d41\u7a0b\u6784\u5efa\u7684\uff0c\u8be5\u6d41\u7a0b\u5305\u62ec\u81ea\u5b9a\u4e49\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u8bed\u8a00\u8bc6\u522b\u3001\u4fee\u6539\u540e\u7684C4/Gopher\u8d28\u91cf\u8fc7\u6ee4\u4ee5\u53ca\u9488\u5bf9\u6cf0\u8bed\u7684\u6709\u5bb3\u5185\u5bb9\u8fc7\u6ee4\uff0c\u6b64\u5916\u8fd8\u5305\u62ec\u4e86\u6765\u81eaWikipedia\u3001\u7687\u5bb6\u516c\u62a5\u3001OCR\u4e66\u7c4d\u548cCC\u8bb8\u53ef\u7684YouTube\u5b57\u5e55\u7b49\u7cbe\u9009\u7684\u975e\u7f51\u7edc\u6570\u636e\u6e90\u3002", "result": "Mangosteen\u8bed\u6599\u5e93\u5305\u542b470\u4ebf\u4e2atoken\u3002\u901a\u8fc7GPT-2\u8fdb\u884c\u7684\u7cfb\u7edf\u6027\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u5904\u7406\u6d41\u7a0b\u5c06CommonCrawl\u7684\u6587\u6863\u6570\u91cf\u4ece2.02\u4ebf\u51cf\u5c11\u52302500\u4e07\uff0c\u540c\u65f6\u5c06SEA-HELM NLG\u5f97\u5206\u4ece3\u63d0\u9ad8\u523011\u3002\u5728Mangosteen\u4e0a\u6301\u7eed\u9884\u8bad\u7ec3\u768480\u4ebf\u53c2\u6570SEA-LION\u6a21\u578b\u5728\u6cf0\u56fd\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u6bd4SEA-LION-v3\u548cLlama-3.1\u9ad8\u51fa\u7ea64\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Mangosteen\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u5168\u53ef\u590d\u73b0\u7684\u6cf0\u56fd\u548c\u533a\u57df\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u57fa\u7840\uff0c\u5305\u62ec\u5b8c\u6574\u7684\u5904\u7406\u6d41\u7a0b\u4ee3\u7801\u3001\u6e05\u7406\u6e05\u5355\u3001\u8bed\u6599\u5e93\u5feb\u7167\u548c\u6240\u6709\u68c0\u67e5\u70b9\u3002"}}
{"id": "2507.14187", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14187", "abs": "https://arxiv.org/abs/2507.14187", "authors": ["Xiaojuan Zhang", "Tianyu Jiang", "Haoxiang Zong", "Chen Zhang", "Chendan Li", "Marta Molinas"], "title": "AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms", "comment": null, "summary": "The impedance network (IN) model is gaining popularity in the oscillation\nanalysis of wind farms. However, the construction of such an IN model requires\nimpedance curves of each wind turbine under their respective operating\nconditions, making its online application difficult due to the transmission of\nnumerous high-density impedance curves. To address this issue, this paper\nproposes an AI-based impedance encoding-decoding method to facilitate the\nonline construction of IN model. First, an impedance encoder is trained to\ncompress impedance curves by setting the number of neurons much smaller than\nthat of frequency points. Then, the compressed data of each turbine are\nuploaded to the wind farm and an impedance decoder is trained to reconstruct\noriginal impedance curves. At last, based on the nodal admittance matrix (NAM)\nmethod, the IN model of the wind farm can be obtained. The proposed method is\nvalidated via model training and real-time simulations, demonstrating that the\nencoded impedance vectors enable fast transmission and accurate reconstruction\nof the original impedance curves.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cdAI\u9a71\u52a8\u7684\u963b\u6297\u538b\u7f29\u548c\u91cd\u5efa\u6280\u672f\uff0c\u7528\u4e8e\u7b80\u5316\u98ce\u7535\u573a\u963b\u6297\u7f51\u7edc\u6a21\u578b\u7684\u5728\u7ebf\u6784\u5efa\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u963b\u6297\u7f51\u7edc\uff08IN\uff09\u6a21\u578b\u5728\u7ebf\u5e94\u7528\u56f0\u96be\u7684\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u538b\u7f29\u963b\u6297\u66f2\u7ebf\u6570\u636e\uff0c\u7b80\u5316\u5176\u4f20\u8f93\u8fc7\u7a0b\uff0c\u4fbf\u4e8e\u5728\u7ebf\u6784\u5efa\u98ce\u7535\u573aIN\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u963b\u6297\u7f16\u7801-\u89e3\u7801\u65b9\u6cd5\u3002\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u963b\u6297\u7f16\u7801\u5668\u6765\u538b\u7f29\u963b\u6297\u66f2\u7ebf\uff0c\u7136\u540e\u4e0a\u4f20\u538b\u7f29\u6570\u636e\u5e76\u8bad\u7ec3\u4e00\u4e2a\u963b\u6297\u89e3\u7801\u5668\u6765\u91cd\u6784\u539f\u59cb\u963b\u6297\u66f2\u7ebf\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u8282\u70b9\u5bfc\u7eb3\u77e9\u9635\uff08NAM\uff09\u65b9\u6cd5\u83b7\u5f97\u98ce\u7535\u573a\u963b\u6297\u7f51\u7edc\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u6a21\u578b\u8bad\u7ec3\u548c\u5b9e\u65f6\u4eff\u771f\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u7f16\u7801\u540e\u7684\u963b\u6297\u5411\u91cf\u80fd\u591f\u5b9e\u73b0\u539f\u59cb\u963b\u6297\u66f2\u7ebf\u7684\u5feb\u901f\u4f20\u8f93\u548c\u7cbe\u786e\u91cd\u6784\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7f16\u7801\u548c\u89e3\u7801\u65b9\u6cd5\u5b9e\u73b0\u4e86\u963b\u6297\u66f2\u7ebf\u7684\u538b\u7f29\u4f20\u8f93\u548c\u7cbe\u786e\u91cd\u6784\uff0c\u4ece\u800c\u80fd\u591f\u5feb\u901f\u6784\u5efa\u98ce\u7535\u573a\u963b\u6297\u7f51\u7edc\u6a21\u578b\uff0c\u4fbf\u4e8e\u5728\u7ebf\u5e94\u7528\u3002"}}
{"id": "2507.15444", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15444", "abs": "https://arxiv.org/abs/2507.15444", "authors": ["Leonard Bauersfeld", "Davide Scaramuzza"], "title": "Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe", "comment": "17 pages", "summary": "Autonomous quadrotor flight in confined spaces such as pipes and tunnels\npresents significant challenges due to unsteady, self-induced aerodynamic\ndisturbances. Very recent advances have enabled flight in such conditions, but\nthey either rely on constant motion through the pipe to mitigate airflow\nrecirculation effects or suffer from limited stability during hovering. In this\nwork, we present the first closed-loop control system for quadrotors for\nhovering in narrow pipes that leverages real-time flow field measurements. We\ndevelop a low-latency, event-based smoke velocimetry method that estimates\nlocal airflow at high temporal resolution. This flow information is used by a\ndisturbance estimator based on a recurrent convolutional neural network, which\ninfers force and torque disturbances in real time. The estimated disturbances\nare integrated into a learning-based controller trained via reinforcement\nlearning. The flow-feedback control proves particularly effective during\nlateral translation maneuvers in the pipe cross-section. There, the real-time\ndisturbance information enables the controller to effectively counteract\ntransient aerodynamic effects, thereby preventing collisions with the pipe\nwall. To the best of our knowledge, this work represents the first\ndemonstration of an aerial robot with closed-loop control informed by real-time\nflow field measurements. This opens new directions for research on flight in\naerodynamically complex environments. In addition, our work also sheds light on\nthe characteristic flow structures that emerge during flight in narrow,\ncircular pipes, providing new insights at the intersection of robotics and\nfluid dynamics.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u9996\u4e2a\u5728\u72ed\u7a84\u7ba1\u9053\u4e2d\u901a\u8fc7\u5b9e\u65f6\u6d41\u573a\u6d4b\u91cf\u8fdb\u884c\u95ed\u73af\u63a7\u5236\u7684\u56db\u65cb\u7ffc\u98de\u884c\u5668\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u6c14\u52a8\u73af\u5883\u4e0b\u7684\u60ac\u505c\u548c\u673a\u52a8\u6311\u6218\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u5728\u7ba1\u9053\u7b49\u72ed\u7a84\u7a7a\u95f4\u4e2d\u56db\u65cb\u7ffc\u98de\u884c\u5668\u9762\u4e34\u7684\u4e0d\u7a33\u5b9a\u3001\u81ea\u611f\u6c14\u52a8\u5e72\u6270\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u6280\u672f\u5728\u89c4\u907f\u6c14\u6d41\u56de\u6d41\u6216\u60ac\u505c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5b9e\u65f6\u6d41\u573a\u6d4b\u91cf\u8fdb\u884c\u95ed\u73af\u63a7\u5236\u7684\u7cfb\u7edf\uff0c\u5305\u62ec\u4f4e\u5ef6\u8fdf\u3001\u57fa\u4e8e\u4e8b\u4ef6\u7684\u70df\u96fe\u901f\u6d4b\u6cd5\u6765\u4f30\u8ba1\u6c14\u6d41\uff0c\u4ee5\u53ca\u4e00\u4e2a\u57fa\u4e8e\u5faa\u73af\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6270\u52a8\u4f30\u8ba1\u5668\u6765\u63a8\u65ad\u5b9e\u65f6\u529b\u548c\u626d\u77e9\u6270\u52a8\uff0c\u5e76\u6574\u5408\u5230\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a7\u5236\u5668\u4e2d\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6d41\u53cd\u9988\u63a7\u5236\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u62b5\u6d88\u77ac\u6001\u6c14\u52a8\u6548\u5e94\uff0c\u5c24\u5176\u5728\u7ba1\u9053\u6a2a\u5411\u5e73\u79fb\u673a\u52a8\u65f6\uff0c\u80fd\u591f\u9632\u6b62\u4e0e\u7ba1\u9053\u58c1\u53d1\u751f\u78b0\u649e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u5c55\u793a\u4e86\u7531\u5b9e\u65f6\u6d41\u573a\u6d4b\u91cf\u4fe1\u606f\u9a71\u52a8\u7684\u95ed\u73af\u63a7\u5236\u7684\u98de\u884c\u5668\uff0c\u5b83\u80fd\u591f\u6210\u529f\u5730\u5728\u72ed\u7a84\u7ba1\u9053\u4e2d\u60ac\u505c\uff0c\u5e76\u80fd\u6709\u6548\u5e94\u5bf9\u590d\u6742\u7684\u7a7a\u6c14\u52a8\u529b\u5b66\u6311\u6218\u3002"}}
{"id": "2507.14555", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14555", "abs": "https://arxiv.org/abs/2507.14555", "authors": ["Jintang Xue", "Ganning Zhao", "Jie-En Yao", "Hong-En Chen", "Yue Hu", "Meida Chen", "Suya You", "C. -C. Jay Kuo"], "title": "Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions", "comment": null, "summary": "Understanding 3D scenes goes beyond simply recognizing objects; it requires\nreasoning about the spatial and semantic relationships between them. Current 3D\nscene-language models often struggle with this relational understanding,\nparticularly when visual embeddings alone do not adequately convey the roles\nand interactions of objects. In this paper, we introduce Descrip3D, a novel and\npowerful framework that explicitly encodes the relationships between objects\nusing natural language. Unlike previous methods that rely only on 2D and 3D\nembeddings, Descrip3D enhances each object with a textual description that\ncaptures both its intrinsic attributes and contextual relationships. These\nrelational cues are incorporated into the model through a dual-level\nintegration: embedding fusion and prompt-level injection. This allows for\nunified reasoning across various tasks such as grounding, captioning, and\nquestion answering, all without the need for task-specific heads or additional\nsupervision. When evaluated on five benchmark datasets, including ScanRefer,\nMulti3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms\nstrong baseline models, demonstrating the effectiveness of language-guided\nrelational representation for understanding complex indoor scenes.", "AI": {"tldr": "Descrip3D uses text descriptions to represent object relationships in 3D scenes, improving understanding and performance on various tasks without needing extra supervision.", "motivation": "Current 3D scene-language models struggle with relational understanding, particularly when visual embeddings alone do not adequately convey object roles and interactions.", "method": "Descrip3D explicitly encodes object relationships using natural language. It enhances objects with textual descriptions capturing intrinsic attributes and contextual relationships, integrated through embedding fusion and prompt-level injection for unified reasoning across tasks like grounding, captioning, and question answering, without task-specific heads or additional supervision.", "result": "Descrip3D enhances object representations with textual descriptions, improving relational understanding and achieving superior performance on benchmark datasets.", "conclusion": "Descrip3D consistently outperforms strong baseline models across five benchmark datasets, demonstrating the effectiveness of language-guided relational representation for understanding complex indoor scenes."}}
{"id": "2507.14419", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14419", "abs": "https://arxiv.org/abs/2507.14419", "authors": ["Guojun Wu"], "title": "It's Not That Simple. An Analysis of Simple Test-Time Scaling", "comment": null, "summary": "Prior work proposed simple test-time scaling, a method for replicating this\nscaling behavior with models distilled from o1-like models by manually\ncontrolling test-time compute: either scaling down by enforcing a maximum\nlength or scaling up by iteratively appending \"Wait\" when the model is about to\nterminate its generation. This paper presents an analysis of simple test-time\nscaling and finds that the scaling behavior is largely attributed to scaling\ndown by enforcing a maximum length. In contrast, fine-tuning on long CoT data\ndistilled from o1-like models has no significant impact on scaling behavior,\nand scaling up by appending \"Wait\" leads to inconsistencies, as the model may\noscillate between solutions. A key distinction exists between scaling down by\nenforcing a maximum length and scaling up test-time compute in o1-like models,\nsuch as DeepSeek-R1\\@. These models are typically allowed to utilize as much\ncompute as needed, with the only constraint being the model's maximum supported\nlength. By learning to naturally scale up test-time compute during\nreinforcement learning, o1-like models surpass their peak performance when\nscaling up. In contrast, simple test-time scaling progressively imposes a lower\nupper limit on model performance as it scales down. While replicating the\ntest-time scaling behavior of o1 models can be straightforward by scaling down,\nit is crucial to recognize that the goal of scaling test-time compute is to\nunlock higher performance -- beyond what the model could originally achieve --\nrather than merely reproducing the appearance of scaling behavior.", "AI": {"tldr": "\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u4e3b\u8981\u662f\u901a\u8fc7\u9650\u5236\u957f\u5ea6\u6765\u5b9e\u73b0\u7684\uff0c\u800c\u4e0d\u662f\u50cfo1\u6a21\u578b\u90a3\u6837\u901a\u8fc7\u589e\u52a0\u8ba1\u7b97\u91cf\u6765\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7a76\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u7684\u673a\u5236\uff0c\u5e76\u4e0eo1\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u884c\u4e3a\u8fdb\u884c\u6bd4\u8f83\uff0c\u7406\u89e3\u7f29\u653e\u6d4b\u8bd5\u65f6\u95f4\u7684\u771f\u6b63\u76ee\u6807\u3002", "method": "\u5bf9\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u5e76\u5c06\u5176\u4e0eo1\u6a21\u578b\uff08\u5982DeepSeek-R1@\uff09\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u4e3b\u8981\u662f\u901a\u8fc7\u5f3a\u5236\u6700\u5927\u957f\u5ea6\u5b9e\u73b0\u7684\uff0c\u800c\u653e\u5927\u7f29\u653e\u5219\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\u3002o1\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u81ea\u7136\u5730\u653e\u5927\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u6765\u8d85\u8d8a\u5176\u5cf0\u503c\u6027\u80fd\uff0c\u800c\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u4f1a\u964d\u4f4e\u6027\u80fd\u4e0a\u9650\u3002", "conclusion": "\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u4e3b\u8981\u901a\u8fc7\u5f3a\u5236\u6700\u5927\u957f\u5ea6\u8fdb\u884c\u7f29\u653e\uff0c\u800c\u901a\u8fc7\u8ffd\u52a0\u201c\u7b49\u5f85\u201d\u8fdb\u884c\u7f29\u653e\u5219\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\u3002\u4e0eo1\u6a21\u578b\u4e0d\u540c\uff0c\u7b80\u5355\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u4f1a\u968f\u7740\u7f29\u653e\u800c\u964d\u4f4e\u6a21\u578b\u7684\u6027\u80fd\u4e0a\u9650\u3002"}}
{"id": "2507.15362", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15362", "abs": "https://arxiv.org/abs/2507.15362", "authors": ["Jiahao Liu", "Cheng Wang", "Tianshu Bi"], "title": "Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part II: Spatial Variation", "comment": null, "summary": "Besides the center of inertia (COI) frequency dynamics addressed in Part I,\nthe spatial frequency variation in power systems with grid-following (GFL)\nconverters is also crucial. Part II revisits the effect of GFLs on frequency\nspatial variation. Leveraging the interfacing state variables and equivalent\nfrequency defined in Part I, an extended frequency divider (FD) formula is\nproposed. The linearized mapping relationship between network node frequency\nand synchronous generator (SG) rotor frequency, as well as GFL equivalent\nfrequency, is modeled. The superposition contribution from GFLs is determined\nby the electrical distance between the generator and the frequency observation\nnode, as well as the system power flow conditions. Additionally, the frequency\nmapping for branch currents, which is overlooked in previous research, is\naddressed. Simulation results validate the accuracy of the proposed extended FD\nformula. They quantitatively demonstrate that the superposition contribution of\nGFLs to node frequency is relatively weak and that the superposition\ncoefficient is time-varying. The branch frequency superposition reveals a\ncomplex and distinctly different pattern.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6269\u5c55\u9891\u7387\u5206\u9891\u5668\uff08FD\uff09\u516c\u5f0f\uff0c\u5206\u6790\u4e86\u5e76\u7f51\u9006\u53d8\u5668\uff08GFL\uff09\u5bf9\u7535\u529b\u7cfb\u7edf\u7a7a\u95f4\u9891\u7387\u53d8\u5316\u7684\u5f71\u54cd\uff0c\u5e76\u5bf9\u8282\u70b9\u548c\u652f\u8def\u9891\u7387\u7684\u6620\u5c04\u5173\u7cfb\u8fdb\u884c\u4e86\u5efa\u6a21\u548c\u4eff\u771f\u9a8c\u8bc1\u3002", "motivation": "\u9664\u4e86\u8d28\u5fc3\uff08COI\uff09\u9891\u7387\u52a8\u529b\u5b66\uff08\u5982\u7b2c\u4e00\u90e8\u5206\u6240\u8ff0\uff09\uff0c\u5177\u6709\u5e76\u7f51\u9006\u53d8\u5668\uff08GFL\uff09\u7684\u7535\u529b\u7cfb\u7edf\u7684\u7a7a\u95f4\u9891\u7387\u53d8\u5316\u4e5f\u81f3\u5173\u91cd\u8981\u3002\u7b2c\u4e8c\u90e8\u5206\u65e8\u5728\u91cd\u65b0\u5ba1\u89c6GFL\u5bf9\u9891\u7387\u7a7a\u95f4\u53d8\u5316\u7684\u5f71\u54cd\u3002", "method": "\u5229\u7528\u63a5\u53e3\u72b6\u6001\u53d8\u91cf\u548c\u7b49\u6548\u9891\u7387\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u9891\u7387\u5206\u9891\u5668\uff08FD\uff09\u516c\u5f0f\uff0c\u5e76\u5bf9\u7f51\u7edc\u8282\u70b9\u9891\u7387\u4e0e\u540c\u6b65\u53d1\u7535\u673a\uff08SG\uff09\u8f6c\u5b50\u9891\u7387\u4ee5\u53caGFL\u7b49\u6548\u9891\u7387\u4e4b\u95f4\u7684\u7ebf\u6027\u5316\u6620\u5c04\u5173\u7cfb\u8fdb\u884c\u4e86\u5efa\u6a21\u3002", "result": "GFL\u5bf9\u8282\u70b9\u9891\u7387\u7684\u53e0\u52a0\u8d21\u732e\u76f8\u5bf9\u8f83\u5f31\uff0c\u4e14\u53e0\u52a0\u7cfb\u6570\u662f\u65f6\u53d8\u7684\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u89e3\u51b3\u4e86\u652f\u8def\u7535\u6d41\u7684\u9891\u7387\u6620\u5c04\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5176\u4e0e\u8282\u70b9\u9891\u7387\u4e0d\u540c\u7684\u590d\u6742\u6a21\u5f0f\u3002", "conclusion": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u6269\u5c55\u9891\u7387\u5206\u9891\u5668\uff08FD\uff09\u516c\u5f0f\u7684\u51c6\u786e\u6027\uff0c\u5e76\u91cf\u5316\u8bc1\u660e\u4e86GFL\u5bf9\u8282\u70b9\u9891\u7387\u7684\u53e0\u52a0\u8d21\u732e\u76f8\u5bf9\u8f83\u5f31\uff0c\u4e14\u53e0\u52a0\u7cfb\u6570\u662f\u65f6\u53d8\u7684\u3002"}}
{"id": "2507.14934", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2507.14934", "abs": "https://arxiv.org/abs/2507.14934", "authors": ["Kieran Hymas", "Tadahiko Hirai", "Daniel Tibben", "Jack B. Muir", "Christopher J. Dunn", "Daniel E. G\u00f3mez", "James Q. Quach"], "title": "Superradiant Organic Light-Emitting Diodes", "comment": "22 pages, 4 figures, comments welcome", "summary": "Organic light-emitting diodes (OLEDs) are central to modern display\ntechnologies and are promising candidates for low-cost energy-efficient\nlighting. Their performance is determined by numerous, intricate fabrication\nparameters, but not least by the number of emissive molecules N, which provide\nsites for electron-hole recombination and photon generation in the diode host\nmatrix. Counterintuitively, larger concentrations of emitters do not always\nlead to brighter or more efficient OLEDs due to concentration quenching of\nluminescence meaning that rates of radiative electron-hole recombination can\nbecome severely reduced, negatively impacting charge-to-photon conversion\nefficiency. In this work we trigger steady-state superradiant light emission\nfrom a series of Fabry-P\\'erot microcavity OLEDs by scaling the operating\nvoltage of each device with emitter concentration. We demonstrate a collective\nenhancement in the luminance of a microcavity OLED that scales\nsuper-extensively when compared to no-cavity controls fabricated in the same\nrun. Triggering quantum correlations between emitters via the confined cavity\nfield allows devices with fewer emitters to match or even exceed the brightness\nof control OLEDs even when driven by lower voltages. Moreover, our devices show\nsignificant narrowing of their emission spectra, offering purer colours at low\napplied voltages. Leveraging collective effects in microcavity OLEDs provides a\nnew approach to enable brighter, more efficient devices paving the way for\nnext-generation displays and lighting that do not compromise performance for\noperational efficiency or device lifetime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6269\u5c55\u6bcf\u4e2a\u5668\u4ef6\u7684\u5de5\u4f5c\u7535\u538b\u4e0e\u53d1\u5c04\u5668\u6d53\u5ea6\uff0c\u89e6\u53d1\u4e86\u4e00\u7cfb\u5217\u6cd5\u5e03\u91cc-\u73c0\u7f57\u5fae\u8154OLED\u7684\u7a33\u6001\u8d85\u8f90\u5c04\u5149\u53d1\u5c04\uff0c\u5b9e\u73b0\u4e86\u66f4\u660e\u4eae\u3001\u66f4\u9ad8\u6548\u7684OLED\uff0c\u5e76\u63d0\u4f9b\u66f4\u7eaf\u51c0\u7684\u8272\u5f69\u3002", "motivation": "\u5728OLED\u4e2d\uff0c\u66f4\u5927\u7684\u53d1\u5c04\u5668\u6d53\u5ea6\u5e76\u4e0d\u603b\u662f\u80fd\u5e26\u6765\u66f4\u4eae\u6216\u66f4\u9ad8\u6548\u7684OLED\uff0c\u56e0\u4e3a\u6d53\u5ea6\u731d\u706d\u4f1a\u4e25\u91cd\u964d\u4f4e\u8f90\u5c04\u7535\u5b50-\u7a7a\u7a74\u590d\u5408\u901f\u7387\uff0c\u4ece\u800c\u5f71\u54cd\u7535\u8377-\u5149\u5b50\u8f6c\u6362\u6548\u7387\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u6bcf\u4e2a\u5668\u4ef6\u7684\u5de5\u4f5c\u7535\u538b\u4e0e\u53d1\u5c04\u5668\u6d53\u5ea6\uff0c\u89e6\u53d1\u4e86\u4e00\u7cfb\u5217\u6cd5\u5e03\u91cc-\u73c0\u7f57\u5fae\u8154OLED\u7684\u7a33\u6001\u8d85\u8f90\u5c04\u5149\u53d1\u5c04\u3002", "result": "\u5668\u4ef6\u8868\u73b0\u51fa\u6bd4\u6ca1\u6709\u8154\u7684\u5bf9\u7167\u7ec4\u66f4\u4f18\u8d8a\u7684\u53d1\u5149\u5ea6\uff0c\u5e76\u4e14\u53d1\u5c04\u5149\u8c31\u663e\u7740\u53d8\u7a84\uff0c\u5728\u4f4e\u65bd\u52a0\u7535\u538b\u4e0b\u63d0\u4f9b\u66f4\u7eaf\u51c0\u7684\u8272\u5f69\u3002", "conclusion": "\u5229\u7528\u5fae\u8154OLED\u4e2d\u7684\u96c6\u4f53\u6548\u5e94\u4e3a\u66f4\u660e\u4eae\u3001\u66f4\u9ad8\u6548\u7684\u8bbe\u5907\u63d0\u4f9b\u65b0\u65b9\u6cd5\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u663e\u793a\u5668\u548c\u7167\u660e\u94fa\u5e73\u9053\u8def\uff0c\u800c\u4e0d\u4f1a\u5728\u6027\u80fd\u3001\u8fd0\u884c\u6548\u7387\u6216\u8bbe\u5907\u5bff\u547d\u65b9\u9762\u59a5\u534f\u3002"}}
{"id": "2507.14681", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14681", "abs": "https://arxiv.org/abs/2507.14681", "authors": ["Vinicius Anjos de Almeida", "Vinicius de Camargo", "Raquel G\u00f3mez-Bravo", "Egbert van der Haring", "Kees van Boven", "Marcelo Finger", "Luis Fernandez Lopez"], "title": "Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care", "comment": "To be submitted to peer-reviewed journal. 33 pages, 10 figures\n  (including appendix), 15 tables (including appendix). For associated code\n  repository, see https://github.com/almeidava93/llm-as-code-selectors-paper", "summary": "Background: Medical coding structures healthcare data for research, quality\nmonitoring, and policy. This study assesses the potential of large language\nmodels (LLMs) to assign ICPC-2 codes using the output of a domain-specific\nsearch engine.\n  Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each\nannotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's\ntext-embedding-3-large) retrieved candidates from 73,563 labeled concepts.\nThirty-three LLMs were prompted with each query and retrieved results to select\nthe best-matching ICPC-2 code. Performance was evaluated using F1-score, along\nwith token usage, cost, response time, and format adherence.\n  Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top\nperformers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever\noptimization can improve performance by up to 4 points. Most models returned\nvalid codes in the expected format, with reduced hallucinations. Smaller models\n(<3B) struggled with formatting and input length.\n  Conclusions: LLMs show strong potential for automating ICPC-2 coding, even\nwithout fine-tuning. This work offers a benchmark and highlights challenges,\nbut findings are limited by dataset scope and setup. Broader, multilingual,\nend-to-end evaluations are needed for clinical validation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14190", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14190", "abs": "https://arxiv.org/abs/2507.14190", "authors": ["Mingcheng Liao", "Zebang Feng", "Miao Fan", "Shengtong Xu", "Haoyi Xiong"], "title": "Traffic Signal Phase and Timing Estimation with Large-Scale Floating Car Data", "comment": "Accepted by ITSC'25", "summary": "Effective modern transportation systems depend critically on accurate Signal\nPhase and Timing (SPaT) estimation. However, acquiring ground-truth SPaT\ninformation faces significant hurdles due to communication challenges with\ntransportation departments and signal installers. As a result, Floating Car\nData (FCD) has become the primary source for large-scale SPaT analyses. Current\nFCD approaches often simplify the problem by assuming fixed schedules and basic\nintersection designs for specific times and locations. These methods fail to\naccount for periodic signal changes, diverse intersection structures, and the\ninherent limitations of real-world data, thus lacking a comprehensive framework\nthat is universally applicable. Addressing this limitation, we propose an\nindustrial-grade FCD analysis suite that manages the entire process, from\ninitial data preprocessing to final SPaT estimation. Our approach estimates\nsignal phases, identifies time-of-day (TOD) periods, and determines the\ndurations of red and green lights. The framework's notable stability and\nrobustness across diverse conditions, regardless of road geometry, is a key\nfeature. Furthermore, we provide a cleaned, de-identified FCD dataset and\nsupporting parameters to facilitate future research. Currently operational\nwithin our navigation platform, the system analyses over 15 million FCD records\ndaily, supporting over two million traffic signals in mainland China, with more\nthan 75\\% of estimations demonstrating less than five seconds of error.", "AI": {"tldr": "\u7531\u4e8e\u83b7\u53d6\u5730\u9762\u771f\u5b9eSPaT\u4fe1\u606f\u56f0\u96be\uff0cFCD\u6210\u4e3a\u5927\u89c4\u6a21SPaT\u5206\u6790\u7684\u4e3b\u8981\u6765\u6e90\u3002\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u7b80\u5316\uff0c\u65e0\u6cd5\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u5de5\u4e1a\u7ea7FCD\u5206\u6790\u5957\u4ef6\uff0c\u80fd\u5904\u7406\u4ece\u6570\u636e\u9884\u5904\u7406\u5230SPaT\u4f30\u7b97\u7684\u6574\u4e2a\u6d41\u7a0b\uff0c\u4f30\u7b97\u4fe1\u53f7\u76f8\u4f4d\u3001TOD\u65f6\u6bb5\u548c\u7ea2\u7eff\u706f\u65f6\u957f\uff0c\u5e76\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u3002\u8be5\u7cfb\u7edf\u5df2\u5728\u4e2d\u56fd\u5927\u9646\u6210\u529f\u5e94\u7528\uff0c\u5206\u6790\u6d77\u91cf\u6570\u636e\uff0c\u4e14\u4f30\u7b97\u7cbe\u5ea6\u9ad8\u3002", "motivation": "\u5f53\u524d\u7684FCD\u65b9\u6cd5\u5728SPaT\u4f30\u7b97\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u7b80\u5316\u95ee\u9898\uff0c\u5047\u8bbe\u56fa\u5b9a\u7684\u65f6\u95f4\u8868\u548c\u57fa\u672c\u7684\u4ea4\u53c9\u53e3\u8bbe\u8ba1\uff0c\u672a\u80fd\u8003\u8651\u5468\u671f\u6027\u4fe1\u53f7\u53d8\u5316\u3001\u591a\u6837\u7684\u4ea4\u53c9\u53e3\u7ed3\u6784\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u66f4\u9c81\u68d2\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5de5\u4e1a\u7ea7\u7684FCD\u5206\u6790\u5957\u4ef6\uff0c\u5305\u542b\u4ece\u6570\u636e\u9884\u5904\u7406\u5230SPaT\u4f30\u7b97\u7684\u5b8c\u6574\u6d41\u7a0b\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u4f30\u7b97\u4fe1\u53f7\u76f8\u4f4d\u3001\u8bc6\u522bTOD\u65f6\u6bb5\u3001\u786e\u5b9a\u7ea2\u706f\u548c\u7eff\u706f\u7684\u6301\u7eed\u65f6\u95f4\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\uff08\u65e0\u8bba\u9053\u8def\u51e0\u4f55\u5f62\u72b6\u5982\u4f55\uff09\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684FCD\u5206\u6790\u5957\u4ef6\u80fd\u591f\u7a33\u5b9a\u3001\u9c81\u68d2\u5730\u4f30\u7b97SPaT\u4fe1\u606f\uff0c\u5e76\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5b9e\u9645\u5bfc\u822a\u5e73\u53f0\u3002\u8be5\u7cfb\u7edf\u6bcf\u65e5\u5904\u7406\u8d85\u8fc71500\u4e07\u6761FCD\u8bb0\u5f55\uff0c\u652f\u6301\u4e2d\u56fd\u5927\u9646\u8d85\u8fc7200\u4e07\u4e2a\u4ea4\u901a\u4fe1\u53f7\u706f\uff0c\u8d85\u8fc775%\u7684\u4f30\u7b97\u8bef\u5dee\u5c0f\u4e8e5\u79d2\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5de5\u4e1a\u7ea7\u7684\u6d6e\u52a8\u8f66\u6570\u636e\uff08FCD\uff09\u5206\u6790\u5957\u4ef6\uff0c\u7528\u4e8e\u4eceFCD\u4e2d\u4f30\u7b97\u4fe1\u53f7\u706f\u76f8\u4f4d\u548c\u65f6\u5e8f\uff08SPaT\uff09\u3002\u8be5\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u6570\u636e\u9884\u5904\u7406\u5230SPaT\u4f30\u7b97\u7684\u6574\u4e2a\u6d41\u7a0b\uff0c\u5305\u62ec\u4f30\u7b97\u4fe1\u53f7\u76f8\u4f4d\u3001\u8bc6\u522b\u4e00\u5929\u4e2d\u7684\u4e0d\u540c\u65f6\u6bb5\uff08TOD\uff09\u4ee5\u53ca\u786e\u5b9a\u7ea2\u7eff\u706f\u7684\u6301\u7eed\u65f6\u95f4\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u8be5\u6846\u67b6\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e0d\u8003\u8651\u9053\u8def\u51e0\u4f55\u5f62\u72b6\u7684\u9650\u5236\u3002\u76ee\u524d\u8be5\u7cfb\u7edf\u5df2\u5728\u5bfc\u822a\u5e73\u53f0\u4e2d\u8fd0\u884c\uff0c\u6bcf\u65e5\u5206\u6790\u8d85\u8fc71500\u4e07\u6761FCD\u8bb0\u5f55\uff0c\u652f\u6301\u4e2d\u56fd\u5927\u9646\u8d85\u8fc7200\u4e07\u4e2a\u4ea4\u901a\u4fe1\u53f7\u706f\uff0c\u5176\u4e2d\u8d85\u8fc775%\u7684\u4f30\u7b97\u8bef\u5dee\u5c0f\u4e8e5\u79d2\u3002"}}
{"id": "2507.15469", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15469", "abs": "https://arxiv.org/abs/2507.15469", "authors": ["Thanh Thi Nguyen", "Saeid Nahavandi", "Imran Razzak", "Dung Nguyen", "Nhat Truong Pham", "Quoc Viet Hung Nguyen"], "title": "The Emergence of Deep Reinforcement Learning for Path Planning", "comment": "Accepted for publication in the Proceedings of the 2025 IEEE\n  International Conference on Systems, Man, and Cybernetics (SMC)", "summary": "The increasing demand for autonomous systems in complex and dynamic\nenvironments has driven significant research into intelligent path planning\nmethodologies. For decades, graph-based search algorithms, linear programming\ntechniques, and evolutionary computation methods have served as foundational\napproaches in this domain. Recently, deep reinforcement learning (DRL) has\nemerged as a powerful method for enabling autonomous agents to learn optimal\nnavigation strategies through interaction with their environments. This survey\nprovides a comprehensive overview of traditional approaches as well as the\nrecent advancements in DRL applied to path planning tasks, focusing on\nautonomous vehicles, drones, and robotic platforms. Key algorithms across both\nconventional and learning-based paradigms are categorized, with their\ninnovations and practical implementations highlighted. This is followed by a\nthorough discussion of their respective strengths and limitations in terms of\ncomputational efficiency, scalability, adaptability, and robustness. The survey\nconcludes by identifying key open challenges and outlining promising avenues\nfor future research. Special attention is given to hybrid approaches that\nintegrate DRL with classical planning techniques to leverage the benefits of\nboth learning-based adaptability and deterministic reliability, offering\npromising directions for robust and resilient autonomous navigation.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u603b\u7ed3\u4e86\u7528\u4e8e\u81ea\u4e3b\u5bfc\u822a\u7684\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u6280\u672f\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60 (DRL) \u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u6df7\u5408\u65b9\u6cd5\u53ca\u5176\u5728\u673a\u5668\u4eba\u548c\u8f66\u8f86\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5e94\u5bf9\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u7684\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\uff0c\u5e76\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u5168\u9762\u7684\u6982\u8ff0\u3002", "method": "\u5bf9\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u56fe\u641c\u7d22\u3001\u7ebf\u6027\u89c4\u5212\u3001\u8fdb\u5316\u8ba1\u7b97\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60 (DRL) \u5728\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u5206\u7c7b\u548c\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u521b\u65b0\u3001\u5b9e\u73b0\u3001\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "result": "\u5bf9\u4f20\u7edf\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u8ba8\u8bba\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u6df7\u5408\u65b9\u6cd5\uff0c\u5e76\u786e\u5b9a\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u8be5\u8c03\u67e5\u5168\u9762\u6982\u8ff0\u4e86\u7528\u4e8e\u81ea\u4e3b\u7cfb\u7edf\u8def\u5f84\u89c4\u5212\u7684\u4f20\u7edf\u65b9\u6cd5\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60 (DRL) \u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u3001\u65e0\u4eba\u673a\u548c\u673a\u5668\u4eba\u5e73\u53f0\u3002\u5b83\u5bf9\u4e24\u79cd\u8303\u4f8b\u4e2d\u7684\u5173\u952e\u7b97\u6cd5\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u8ba8\u8bba\u4e86\u5b83\u4eec\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5f3a\u8c03\u4e86\u6df7\u5408\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7ed3\u5408\u4e86 DRL \u7684\u9002\u5e94\u6027\u548c\u7ecf\u5178\u65b9\u6cd5\u7684\u786e\u5b9a\u6027\u3002"}}
{"id": "2507.14559", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14559", "abs": "https://arxiv.org/abs/2507.14559", "authors": ["Zixuan Hu", "Xiaotong Li", "Shixiang Tang", "Jun Liu", "Yichun Hu", "Ling-Yu Duan"], "title": "LEAD: Exploring Logit Space Evolution for Model Selection", "comment": "Accepted by CVPR 2024", "summary": "The remarkable success of pretrain-then-finetune paradigm has led to a\nproliferation of available pre-trained models for vision tasks. This surge\npresents a significant challenge in efficiently choosing the most suitable\npre-trained models for downstream tasks. The critical aspect of this challenge\nlies in effectively predicting the model transferability by considering the\nunderlying fine-tuning dynamics. Existing methods often model fine-tuning\ndynamics in feature space with linear transformations, which do not precisely\nalign with the fine-tuning objective and fail to grasp the essential\nnonlinearity from optimization. To this end, we present LEAD, a\nfinetuning-aligned approach based on the network output of logits. LEAD\nproposes a theoretical framework to model the optimization process and derives\nan ordinary differential equation (ODE) to depict the nonlinear evolution\ntoward the final logit state. Additionally, we design a class-aware\ndecomposition method to consider the varying evolution dynamics across classes\nand further ensure practical applicability. Integrating the closely aligned\noptimization objective and nonlinear modeling capabilities derived from the\ndifferential equation, our method offers a concise solution to effectively\nbridge the optimization gap in a single step, bypassing the lengthy fine-tuning\nprocess. The comprehensive experiments on 24 supervised and self-supervised\npre-trained models across 10 downstream datasets demonstrate impressive\nperformances and showcase its broad adaptability even in low-data scenarios.", "AI": {"tldr": "LEAD\u662f\u4e00\u79cd\u65b0\u7684\u5fae\u8c03\u5bf9\u9f50\u65b9\u6cd5\uff0c\u4f7f\u7528\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u6765\u6a21\u62df\u548c\u9884\u6d4b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u4f18\u5316\u975e\u7ebf\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u6790\u7f51\u7edc\u8f93\u51fa\uff08logits\uff09\u7684\u6f14\u5316\uff0c\u5e76\u7ed3\u5408\u7c7b\u522b\u611f\u77e5\u5206\u89e3\uff0c\u80fd\u591f\u4e00\u6b65\u9884\u6d4b\u8fc1\u79fb\u80fd\u529b\uff0c\u65e0\u9700\u5b9e\u9645\u5fae\u8c03\uff0c\u5e76\u5728\u591a\u9879\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u9884\u8bad\u7ec3-\u5fae\u8c03\u8303\u5f0f\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u5bfc\u81f4\u4e86\u5927\u91cf\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6d8c\u73b0\u3002\u7136\u800c\uff0c\u5982\u4f55\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u9ad8\u6548\u5730\u9009\u62e9\u6700\u5408\u9002\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6210\u4e86\u4e00\u4e2a\u4e25\u5cfb\u7684\u6311\u6218\u3002\u8fd9\u4e2a\u6311\u6218\u7684\u5173\u952e\u5728\u4e8e\u6709\u6548\u5730\u9884\u6d4b\u6a21\u578b\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u540c\u65f6\u8981\u8003\u8651\u5230\u6f5c\u5728\u7684\u5fae\u8c03\u52a8\u6001\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u7528\u7ebf\u6027\u53d8\u6362\u6765\u6a21\u62df\u5fae\u8c03\u52a8\u6001\uff0c\u4f46\u8fd9\u4e0e\u5fae\u8c03\u76ee\u6807\u5e76\u4e0d\u7cbe\u786e\u543b\u5408\uff0c\u4e5f\u65e0\u6cd5\u6355\u6349\u4f18\u5316\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u975e\u7ebf\u6027\u3002", "method": "LEAD\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u8f93\u51fa\uff08logits\uff09\u7684\u3001\u4e0e\u5fae\u8c03\u5bf9\u9f50\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u6a21\u62df\u4f18\u5316\u8fc7\u7a0b\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u4e2a\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u6765\u63cf\u7ed8\u5411\u6700\u7ec8logit\u72b6\u6001\u6f14\u5316\u7684\u975e\u7ebf\u6027\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7c7b\u522b\u611f\u77e5\u5206\u89e3\u65b9\u6cd5\u6765\u8003\u8651\u8de8\u7c7b\u522b\u7684\u4e0d\u540c\u6f14\u5316\u52a8\u6001\uff0c\u4ee5\u786e\u4fdd\u5176\u5b9e\u9645\u9002\u7528\u6027\u3002", "result": "\u572824\u4e2a\u76d1\u7763\u548c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u53ca10\u4e2a\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cLEAD\u5177\u6709\u51fa\u8272\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5373\u4f7f\u5728\u6570\u636e\u7a00\u758f\u7684\u60c5\u51b5\u4e0b\u4e5f\u5c55\u73b0\u51fa\u5e7f\u6cdb\u7684\u9002\u5e94\u6027\u3002", "conclusion": "LEAD\u901a\u8fc7\u6574\u5408\u4e0e\u5176\u4f18\u5316\u76ee\u6807\u7d27\u5bc6\u7ed3\u5408\u7684\u975e\u7ebf\u6027\u5efa\u6a21\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u6d01\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5730\u5f25\u5408\u4f18\u5316\u9e3f\u6c9f\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e00\u6b65\u5b8c\u6210\uff0c\u65e0\u9700\u6f2b\u957f\u7684\u5fae\u8c03\u8fc7\u7a0b\u3002"}}
{"id": "2507.14987", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14987", "abs": "https://arxiv.org/abs/2507.14987", "authors": ["Yi Zhang", "An Zhang", "XiuYu Zhang", "Leheng Sheng", "Yuxin Chen", "Zhenkai Liang", "Xiang Wang"], "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs), despite possessing latent safety understanding\nfrom their vast pretraining data, remain vulnerable to generating harmful\ncontent and exhibit issues such as over-refusal and utility degradation after\nsafety alignment. Current safety alignment methods often result in superficial\nrefusal shortcuts or rely on intensive supervision for reasoning-based\napproaches, failing to fully leverage the model's intrinsic safety\nself-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure\nreinforcement learning (RL) framework with verifiable safety reward designed to\nincentivize this latent safety awareness through proactive safety reasoning.}\nAlphaAlign employs a dual-reward system: a verifiable safety reward encourages\ncorrectly formatted and explicitly justified refusals for harmful queries while\npenalizing over-refusals, and a normalized helpfulness reward guides\nhigh-quality responses to benign inputs. This allows the model to develop\nproactive safety reasoning capabilities without depending on supervised\nsafety-specific reasoning data. AlphaAlign demonstrates three key advantages:\n(1) Simplicity and efficiency, requiring only binary prompt safety labels and\nminimal RL steps for substantial improvements. (2) Breaking the safety-utility\ntrade-off, by enhancing refusal of harmful content and reducing over-refusals,\nwhile simultaneously maintaining or even improving general task performance and\nrobustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety\nreasoning that generates explicit safety rationales rather than relying on\nshallow refusal patterns.", "AI": {"tldr": "AlphaAlign\u662f\u4e00\u79cd\u521b\u65b0\u7684\u7eaf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u548c\u6807\u51c6\u5316\u7684\u6709\u7528\u6027\u5956\u52b1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u5728\u4e0d\u727a\u7272\u6548\u7528\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u6df1\u5ea6\u5b89\u5168\u5bf9\u9f50\u548c\u4e3b\u52a8\u5b89\u5168\u63a8\u7406\u3002", "motivation": "\u5f53\u524d\u7684LLM\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5f80\u5f80\u4f1a\u5bfc\u81f4\u8868\u9762\u4e0a\u7684\u62d2\u7edd\u6377\u5f84\uff0c\u6216\u8005\u5728\u57fa\u4e8e\u63a8\u7406\u7684\u65b9\u6cd5\u4e2d\u8fc7\u5ea6\u4f9d\u8d56\u76d1\u7763\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u6a21\u578b\u5185\u5728\u7684\u5b89\u5168\u81ea\u6211\u610f\u8bc6\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8fd8\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u62d2\u7edd\u548c\u6548\u7528\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "AlphaAlign\u662f\u4e00\u4e2a\u7eaf\u7cb9\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6\uff0c\u5b83\u5229\u7528\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u6765\u6fc0\u52b1\u6a21\u578b\u6f5c\u5728\u7684\u5b89\u5168\u81ea\u6211\u610f\u8bc6\uff0c\u5e76\u901a\u8fc7\u79ef\u6781\u7684\u5b89\u5168\u63a8\u7406\u6765\u505a\u5230\u8fd9\u4e00\u70b9\u3002\u5b83\u91c7\u7528\u53cc\u91cd\u5956\u52b1\u7cfb\u7edf\uff1a\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u7528\u4e8e\u9f13\u52b1\u5bf9\u6709\u5bb3\u67e5\u8be2\u7684\u6b63\u786e\u683c\u5f0f\u5316\u548c\u660e\u786e\u7406\u7531\u7684\u62d2\u7edd\uff0c\u540c\u65f6\u60e9\u7f5a\u8fc7\u5ea6\u62d2\u7edd\uff1b\u6807\u51c6\u5316\u7684\u6709\u7528\u6027\u5956\u52b1\u7528\u4e8e\u6307\u5bfc\u5bf9\u826f\u6027\u8f93\u5165\u7684\u54cd\u5e94\u3002", "result": "AlphaAlign\u5728\u4e09\u4e2a\u5173\u952e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff1a1. \u7b80\u5355\u6027\u548c\u6548\u7387\uff1a\u4ec5\u9700\u8981\u4e8c\u8fdb\u5236\u63d0\u793a\u5b89\u5168\u6807\u7b7e\u548c\u5c11\u91cf\u7684RL\u6b65\u9aa4\u5373\u53ef\u83b7\u5f97\u663e\u8457\u6539\u8fdb\u30022. \u7a81\u7834\u4e86\u5b89\u5168-\u6548\u7528\u6743\u8861\uff1a\u5b83\u63d0\u9ad8\u4e86\u5bf9\u6709\u5bb3\u5185\u5bb9\u7684\u62d2\u7edd\u80fd\u529b\uff0c\u51cf\u5c11\u4e86\u8fc7\u5ea6\u62d2\u7edd\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u4e86\u901a\u7528\u4efb\u52a1\u6027\u80fd\u548c\u5bf9\u672a\u89c1\u8fc7\u7684\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u30023. \u6df1\u5ea6\u5bf9\u9f50\uff1a\u5b83\u57f9\u517b\u4e86\u79ef\u6781\u7684\u5b89\u5168\u63a8\u7406\u80fd\u529b\uff0c\u80fd\u591f\u751f\u6210\u660e\u786e\u7684\u5b89\u5168\u7406\u7531\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u80a4\u6d45\u7684\u62d2\u7edd\u6a21\u5f0f\u3002", "conclusion": "AlphaAlign\u901a\u8fc7\u5176\u53cc\u91cd\u5956\u52b1\u7cfb\u7edf\uff08\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u548c\u6807\u51c6\u5316\u7684\u6709\u7528\u6027\u5956\u52b1\uff09\u6709\u6548\u6fc0\u52b1\u4e86LLM\u7684\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u79ef\u6781\u7684\u5b89\u5168\u63a8\u7406\uff0c\u5e76\u514b\u670d\u4e86\u5f53\u524d\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u8868\u9762\u4e0a\u7684\u62d2\u7edd\u6377\u5f84\u6216\u5bf9\u57fa\u4e8e\u63a8\u7406\u7684\u65b9\u6cd5\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002"}}
{"id": "2507.14446", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14446", "abs": "https://arxiv.org/abs/2507.14446", "authors": ["Feng Liu", "Ying Liu", "Carson Eisenach"], "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness", "comment": null, "summary": "In this work, we study how to efficiently apply reinforcement learning (RL)\nfor solving large-scale stochastic optimization problems by leveraging\nintervention models. The key of the proposed methodology is to better explore\nthe solution space by simulating and composing the stochastic processes using\npre-trained deep learning (DL) models. We demonstrate our approach on a\nchallenging real-world application, the multi-sourcing multi-period inventory\nmanagement problem in supply chain optimization. In particular, we employ deep\nRL models for learning and forecasting the stochastic supply chain processes\nunder a range of assumptions. Moreover, we also introduce a constraint\ncoordination mechanism, designed to forecast dual costs given the\ncross-products constraints in the inventory network. We highlight that instead\nof directly modeling the complex physical constraints into the RL optimization\nproblem and solving the stochastic problem as a whole, our approach breaks down\nthose supply chain processes into scalable and composable DL modules, leading\nto improved performance on large real-world datasets. We also outline open\nproblems for future research to further investigate the efficacy of such\nmodels.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u4f9b\u5e94\u94fe\u8fc7\u7a0b\u5206\u89e3\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757\uff0c\u5e76\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u9884\u6d4b\u548c\u534f\u8c03\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u89e3\u51b3\u5927\u89c4\u6a21\u968f\u673a\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u968f\u673a\u4f18\u5316\u95ee\u9898\uff08\u5982\u4f9b\u5e94\u94fe\u4f18\u5316\u4e2d\u7684\u591a\u6e90\u591a\u671f\u5e93\u5b58\u7ba1\u7406\uff09\u7684\u6709\u6548\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u3002", "method": "\u5229\u7528\u5e72\u9884\u6a21\u578b\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6a21\u62df\u548c\u7ec4\u5408\u968f\u673a\u8fc7\u7a0b\u6765\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5b66\u4e60\u548c\u9884\u6d4b\u968f\u673a\u4f9b\u5e94\u94fe\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u534f\u8c03\u673a\u5236\u6765\u9884\u6d4b\u8de8\u4ea7\u54c1\u7ea6\u675f\u4e0b\u7684\u5bf9\u5076\u6210\u672c\u3002", "result": "\u5728\u591a\u6e90\u591a\u671f\u5e93\u5b58\u7ba1\u7406\u95ee\u9898\u4e0a\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5927\u578b\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u6539\u8fdb\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u590d\u6742\u7684\u4f9b\u5e94\u94fe\u7ea6\u675f\u5206\u89e3\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u7ec4\u5408\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757\uff0c\u5728\u5927\u578b\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.15413", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15413", "abs": "https://arxiv.org/abs/2507.15413", "authors": ["Francesc Ballester", "Ion Errea", "Maia G. Vergniory"], "title": "Simphony: A full tight-binding package for lattice vibrations and topological phonon analysis", "comment": "34 pages, 5 figures, source code available at\n  https://github.com/fballestermacia/simphony", "summary": "Simphony is an open-source software package designed for the topological\nanalysis of lattice vibrations based on Wannier tight-binding models. Its\nprimary function is to classify the topology of novel materials by computing\nbulk and slab phonon band structures, extracting phonon surface spectra, and\nproviding analysis tools such as Wilson loop calculations and Weyl node\ndetection. The workflow is analogous to that of established electronic topology\ncodes like Wannier90 and WannierTools. It also incorporates long-range polar\ninteractions during the wannierization process, making Simphony one of the\nfirst tools capable of diagnosing topology in polar insulators.", "AI": {"tldr": "Simphony\u662f\u4e00\u6b3e\u5f00\u6e90\u8f6f\u4ef6\uff0c\u7528\u4e8e\u5206\u6790\u6676\u683c\u632f\u52a8\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u53ef\u4ee5\u8bca\u65ad\u6781\u6027\u7edd\u7f18\u4f53\u7684\u62d3\u6251\u7ed3\u6784\u3002", "motivation": "Simphony\u7684\u76ee\u7684\u662f\u5bf9\u6676\u683c\u632f\u52a8\u8fdb\u884c\u62d3\u6251\u5206\u6790\uff0c\u5e76\u5bf9\u65b0\u578b\u6750\u6599\u8fdb\u884c\u62d3\u6251\u5206\u7c7b\u3002", "method": "Simphony\u662f\u4e00\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u901a\u8fc7\u8ba1\u7b97\u4f53\u548c\u677f\u72b6\u58f0\u5b50\u80fd\u5e26\u7ed3\u6784\u3001\u63d0\u53d6\u58f0\u5b50\u8868\u9762\u8c31\u4ee5\u53ca\u63d0\u4f9bWilson\u56de\u8def\u8ba1\u7b97\u548cWeyl\u8282\u70b9\u68c0\u6d4b\u7b49\u5206\u6790\u5de5\u5177\uff0c\u5bf9\u57fa\u4e8eWannier\u7d27\u675f\u7f1a\u6a21\u578b\u7684\u6676\u683c\u632f\u52a8\u8fdb\u884c\u62d3\u6251\u5206\u6790\u3002", "result": "Simphony\u80fd\u591f\u8ba1\u7b97\u4f53\u548c\u677f\u72b6\u58f0\u5b50\u80fd\u5e26\u7ed3\u6784\uff0c\u63d0\u53d6\u58f0\u5b50\u8868\u9762\u8c31\uff0c\u5e76\u8fdb\u884cWilson\u56de\u8def\u8ba1\u7b97\u548cWeyl\u8282\u70b9\u68c0\u6d4b\uff0c\u80fd\u591f\u8bca\u65ad\u6781\u6027\u7edd\u7f18\u4f53\u7684\u62d3\u6251\u7ed3\u6784\u3002", "conclusion": "Simphony\u80fd\u591f\u8bca\u65ad\u6781\u6027\u7edd\u7f18\u4f53\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u8fd9\u662f\u5c11\u6570\u80fd\u591f\u505a\u5230\u8fd9\u4e00\u70b9\u7684\u5de5\u5177\u4e4b\u4e00\u3002"}}
{"id": "2507.15385", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15385", "abs": "https://arxiv.org/abs/2507.15385", "authors": ["Jun Kang Yap", "Vishnu Monn Baskaran", "Wen Shan Tan", "Ze Yang Ding", "Hao Wang", "David L. Dowe"], "title": "Transformer-based Deep Learning Model for Joint Routing and Scheduling with Varying Electric Vehicle Numbers", "comment": "Accepted at Industry Applications Society Annual Meeting (IAS 2025)", "summary": "The growing integration of renewable energy sources in modern power systems\nhas introduced significant operational challenges due to their intermittent and\nuncertain outputs. In recent years, mobile energy storage systems (ESSs) have\nemerged as a popular flexible resource for mitigating these challenges.\nCompared to stationary ESSs, mobile ESSs offer additional spatial flexibility,\nenabling cost-effective energy delivery through the transportation network.\nHowever, the widespread deployment of mobile ESSs is often hindered by the high\ninvestment cost, which has motivated researchers to investigate utilising more\nreadily available alternatives, such as electric vehicles (EVs) as mobile\nenergy storage units instead. Hence, we explore this opportunity with a\nMIP-based day-ahead electric vehicle joint routing and scheduling problem in\nthis work. However, solving the problem in a practical setting can often be\ncomputationally intractable since the existence of binary variables makes it\ncombinatorial challenging. Therefore, we proposed to simplify the problem's\nsolution process for a MIP solver by pruning the solution search space with a\ntransformer-based deep learning (DL) model. This is done by training the model\nto rapidly predict the optimal binary solutions. In addition, unlike many\nexisting DL approaches that assume fixed problem structures, the proposed model\nis designed to accommodate problems with EV fleets of any sizes. This\nflexibility is essential since frequent re-training can introduce significant\ncomputational overhead. We evaluated the approach with simulations on the IEEE\n33-bus system coupled with the Nguyen-Dupuis transportation network.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u7535\u52a8\u6c7d\u8f66\u4f5c\u4e3a\u79fb\u52a8\u50a8\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684 transformer \u6a21\u578b\u6765\u4f18\u5316\u7535\u52a8\u6c7d\u8f66\u7684\u8def\u5f84\u548c\u8c03\u5ea6\u95ee\u9898\uff0c\u4ee5\u5e94\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u7684\u6311\u6218\uff0c\u5e76\u7b80\u5316\u4e86\u6c42\u89e3\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u79fb\u52a8\u50a8\u80fd\u7cfb\u7edf\uff08ESS\uff09\u90e8\u7f72\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5e76\u5e94\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u7684\u95f4\u6b47\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u4f5c\u4e3a\u79fb\u52a8\u50a8\u80fd\u5355\u5143\uff0c\u5e76\u89e3\u51b3\u7535\u52a8\u6c7d\u8f66\u8054\u5408\u8def\u5f84\u548c\u8c03\u5ea6\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u7684 transformer \u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u95ee\u9898\u7684\u6700\u4f18\u4e8c\u5143\u89e3\uff0c\u4ee5\u7b80\u5316\u6c42\u89e3\u8fc7\u7a0b\u5e76\u4fee\u526a\u641c\u7d22\u7a7a\u95f4\u3002\u8be5\u6a21\u578b\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u89c4\u6a21\u7684\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u8f66\u961f\u3002", "result": "\u901a\u8fc7\u5728 IEEE 33 \u6bcd\u7ebf\u7cfb\u7edf\u548c Nguyen-Dupuis \u4ea4\u901a\u7f51\u7edc\u4e0a\u8fdb\u884c\u6a21\u62df\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u5df2\u63d0\u51fa\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u4e3a\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u6c42\u89e3\u5668\u63d0\u4f9b\u6700\u4f18\u7684\u4e8c\u5143\u89e3\uff0c\u4ece\u800c\u7b80\u5316\u5176\u6c42\u89e3\u8fc7\u7a0b\uff0c\u5e76\u4e14\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u89c4\u6a21\u7684\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u8f66\u961f\uff0c\u800c\u65e0\u9700\u9891\u7e41\u91cd\u65b0\u8bad\u7ec3\u3002"}}
{"id": "2507.14953", "categories": ["quant-ph", "81P10, 05A19"], "pdf": "https://arxiv.org/pdf/2507.14953", "abs": "https://arxiv.org/abs/2507.14953", "authors": ["David Ellerman"], "title": "The Way from Rota to Quantum Mechanics", "comment": null, "summary": "This paper traces an intellectual journey or \\textit{Way} (in the sense of a\nTao) that starts with some unfinished work of Gian-Carlo Rota on making a logic\nof equivalence relations or partitions. Rota understood the category-theoretic\nduality between subsets and partitions which implied there should be a logic of\npartitions dual to the usual Boolean logic of subsets.And just as probability\nstarts quantitatively with the size of a subset, so he saw that information\nshould start with some notion of size of a partition. After developing the\nlogic of partitions and its quantitative version as logical entropy, it became\nclear that there is a fundamental duality, fully developed only in category\ntheory, that runs through the exact sciences. Classical physics lies on the\nsubset side and quantum physics on the partition side of the duality. The rest\nof the paper develops the treatment of quantum mechanics seen through the lens\nof partitions as the logic of definiteness and indefiniteness. The lattices of\npartitions allows the treatment of quantum phenomena in highly simplified but\nessential terms. Since Feynman saw the``only mystery'' of quantum mechanics in\nthe two-slit experiment, this new approach is developed to show how to resolve\nthat mystery. Finally, quantum statistics is treated using Rota-style\nenumerative combinatorics.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eRota\u5173\u4e8e\u5212\u5206\u7684\u903b\u8f91\u7684\u5de5\u4f5c\uff0c\u5c06\u91cf\u5b50\u529b\u5b66\u89c6\u4e3a\u4e00\u79cd\u5212\u5206\u7684\u903b\u8f91\uff0c\u5229\u7528\u5212\u5206\u7684\u683c\u6765\u89e3\u91ca\u91cf\u5b50\u73b0\u8c61\uff0c\u5e76\u5904\u7406\u91cf\u5b50\u7edf\u8ba1\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5b8c\u6210Gian-Carlo Rota\u5173\u4e8e\u5efa\u7acb\u7b49\u4ef7\u5173\u7cfb\u6216\u5212\u5206\u7684\u903b\u8f91\u7684\u672a\u5b8c\u6210\u5de5\u4f5c\u3002\u4f5c\u8005\u53d7\u5230Rota\u5173\u4e8e\u5b50\u96c6\u548c\u5212\u5206\u4e4b\u95f4\u7684\u8303\u7574\u8bba\u5bf9\u5076\u6027\u7684\u542f\u53d1\uff0c\u8ba4\u8bc6\u5230\u5e94\u8be5\u5b58\u5728\u4e00\u79cd\u4e0e\u901a\u5e38\u7684\u5e03\u5c14\u5b50\u96c6\u903b\u8f91\u76f8\u5bf9\u5e94\u7684\u5212\u5206\u903b\u8f91\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u63d0\u51fa\uff0c\u4fe1\u606f\u8bba\u7684\u8d77\u70b9\u5e94\u7c7b\u4f3c\u4e8e\u6982\u7387\u8bba\u4e2d\u4ece\u5b50\u96c6\u5927\u5c0f\u51fa\u53d1\uff0c\u5e94\u4ece\u5212\u5206\u7684\u5927\u5c0f\u6982\u5ff5\u51fa\u53d1\u3002\u8fd9\u5bfc\u81f4\u4e86\u5bf9\u91cf\u5b50\u529b\u5b66\u7684\u63a2\u7d22\uff0c\u4f5c\u8005\u8ba4\u4e3a\u91cf\u5b50\u529b\u5b66\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u5173\u4e8e\u786e\u5b9a\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u5212\u5206\u903b\u8f91\u3002", "method": "\u672c\u6587\u8ffd\u6eaf\u4e86\u4e00\u6bb5\u667a\u529b\u5386\u7a0b\uff0c\u4eceRota\u5173\u4e8e\u7b49\u4ef7\u5173\u7cfb\u6216\u5212\u5206\u7684\u903b\u8f91\u7684\u672a\u5b8c\u6210\u5de5\u4f5c\u5f00\u59cb\uff0c\u9610\u8ff0\u4e86\u5212\u5206\u7684\u903b\u8f91\u53ca\u5176\u91cf\u5316\u7248\u672c\uff08\u903b\u8f91\u71b5\uff09\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u7cbe\u786e\u79d1\u5b66\u4e2d\u8d2f\u7a7f\u59cb\u7ec8\u7684\u5b50\u96c6\u548c\u5212\u5206\u4e4b\u95f4\u7684\u5bf9\u5076\u6027\u3002\u968f\u540e\uff0c\u6587\u7ae0\u6df1\u5165\u63a2\u8ba8\u4e86\u91cf\u5b50\u529b\u5b66\uff0c\u5c06\u5176\u89c6\u4e3a\u5212\u5206\u7684\u903b\u8f91\uff0c\u5e76\u5229\u7528\u5212\u5206\u7684\u683c\u6765\u7b80\u5316\u5bf9\u91cf\u5b50\u73b0\u8c61\u7684\u5904\u7406\uff0c\u7279\u522b\u662f\u5c55\u793a\u4e86\u5982\u4f55\u89e3\u51b3\u53cc\u7f1d\u5b9e\u9a8c\u7684\u8c1c\u56e2\u3002\u6700\u540e\uff0c\u6587\u7ae0\u4f7f\u7528Rota\u98ce\u683c\u7684\u679a\u4e3e\u7ec4\u5408\u5b66\u6765\u5904\u7406\u91cf\u5b50\u7edf\u8ba1\u3002", "result": "\u8be5\u8bba\u6587\u6210\u529f\u5730\u53d1\u5c55\u4e86\u5212\u5206\u7684\u903b\u8f91\u53ca\u5176\u91cf\u5316\u7248\u672c\uff0c\u5373\u903b\u8f91\u71b5\u3002\u5b83\u63ed\u793a\u4e86\u5b50\u96c6\u548c\u5212\u5206\u4e4b\u95f4\u6df1\u523b\u7684\u8303\u7574\u8bba\u5bf9\u5076\u6027\uff0c\u5e76\u5c06\u6b64\u5bf9\u5076\u6027\u5e94\u7528\u4e8e\u7ecf\u5178\u7269\u7406\u5b66\u548c\u91cf\u5b50\u7269\u7406\u5b66\u3002\u901a\u8fc7\u5c06\u91cf\u5b50\u529b\u5b66\u89c6\u4e3a\u5212\u5206\u7684\u903b\u8f91\uff0c\u5e76\u5229\u7528\u5212\u5206\u7684\u683c\uff0c\u8bba\u6587\u5bf9\u91cf\u5b50\u73b0\u8c61\uff08\u7279\u522b\u662f\u53cc\u7f1d\u5b9e\u9a8c\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u89c6\u89d2\u548c\u89e3\u91ca\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8fd8\u8fd0\u7528Rota\u98ce\u683c\u7684\u679a\u4e3e\u7ec4\u5408\u5b66\u6210\u529f\u5730\u5904\u7406\u4e86\u91cf\u5b50\u7edf\u8ba1\u3002", "conclusion": "\u8be5\u8bba\u6587\u53d1\u5c55\u4e86\u4e00\u79cd\u5c06\u91cf\u5b50\u529b\u5b66\u89c6\u4e3a\u4f9d\u8d56\u4e8e\u53ef\u5206\u6027\u7684\u6982\u5ff5\uff0c\u5e76\u4f7f\u7528\u683c\u7684\u5212\u5206\u6765\u7b80\u5316\u91cf\u5b50\u73b0\u8c61\u7684\u8bba\u8ff0\u3002\u6b64\u5916\uff0c\u8be5\u8bba\u6587\u8fd8\u8fd0\u7528\u4e86Rota\u98ce\u683c\u7684\u679a\u4e3e\u7ec4\u5408\u5b66\u6765\u5904\u7406\u91cf\u5b50\u7edf\u8ba1\u3002"}}
{"id": "2507.14683", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14683", "abs": "https://arxiv.org/abs/2507.14683", "authors": ["Xingxuan Li", "Yao Xiao", "Dianwen Ng", "Hai Ye", "Yue Deng", "Xiang Lin", "Bin Wang", "Zhanfeng Mo", "Chong Zhang", "Yueyi Zhang", "Zonglin Yang", "Ruilin Li", "Lei Lei", "Shihao Xu", "Han Zhao", "Weiling Chen", "Feng Ji", "Lidong Bing"], "title": "MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization", "comment": "Technical report", "summary": "Large language models have recently evolved from fluent text generation to\nadvanced reasoning across diverse domains, giving rise to reasoning language\nmodels. Among these domains, mathematical reasoning serves as a representative\nbenchmark as it requires precise multi-step logic and abstract reasoning, which\ncan be generalized to other tasks. While closed-source RLMs such as GPT-o3\ndemonstrate impressive reasoning capabilities, their proprietary nature limits\ntransparency and reproducibility. Although many open-source projects aim to\nclose this gap, most of them lack sufficient openness by omitting critical\nresources such as datasets and detailed training configurations, which hinders\nreproducibility. To contribute toward greater transparency in RLM development,\nwe introduce the MiroMind-M1 series, a set of fully open-source RLMs built on\nthe Qwen-2.5 backbone that match or exceed the performance of existing\nopen-source RLMs. Specifically, our models are trained in two stages: SFT on a\ncarefully curated corpus of 719K math-reasoning problems with verified CoT\ntrajectories, followed by RLVR on 62K challenging and verifiable problems. To\nenhance the robustness and efficiency of the RLVR process, we introduce\nContext-Aware Multi-Stage Policy Optimization, an algorithm that integrates\nlength-progressive training with an adaptive repetition penalty to encourage\ncontext-aware RL training. Our model achieves state-of-the-art or competitive\nperformance and superior token efficiency among Qwen-2.5-based open-source 7B\nand 32B models on the AIME24, AIME25, and MATH benchmarks. To facilitate\nreproducibility, we release the complete stack: models (MiroMind-M1-SFT-7B,\nMiroMind-M1-RL-7B, MiroMind-M1-RL-32B); datasets (MiroMind-M1-SFT-719K,\nMiroMind-M1-RL-62K); and all training and evaluation configurations. We hope\nthese resources will support further research and foster community advancement.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86 MiroMind-M1 \u7cfb\u5217\u5b8c\u5168\u5f00\u6e90\u7684\u63a8\u7406\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u9ad8\u6570\u5b66\u63a8\u7406\u80fd\u529b\u548c\u8bad\u7ec3\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u4e0e\u53ef\u590d\u73b0\u6027\u3002\u6a21\u578b\u5728 SFT \u548c RLVR \u4e24\u4e2a\u9636\u6bb5\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u591a\u9636\u6bb5\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u3002\u7ed3\u679c\u663e\u793a\uff0cMiroMind-M1 \u6a21\u578b\u5728\u5404\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5f00\u6e90\u8d44\u6e90\u3002", "motivation": "\u5c3d\u7ba1\u95ed\u6e90\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u4e13\u6709\u6027\u8d28\u9650\u5236\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u3002\u73b0\u6709\u7684\u5f00\u6e90\u9879\u76ee\u867d\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f46\u901a\u5e38\u7f3a\u4e4f\u6570\u636e\u96c6\u548c\u8be6\u7ec6\u8bad\u7ec3\u914d\u7f6e\u7b49\u5173\u952e\u8d44\u6e90\uff0c\u963b\u788d\u4e86\u53ef\u590d\u73b0\u6027\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u5b8c\u5168\u5f00\u6e90\u7684 RLM \u6765\u4fc3\u8fdb RLM \u5f00\u53d1\u7684\u900f\u660e\u5ea6\u3002", "method": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86 MiroMind-M1 \u7cfb\u5217\u6a21\u578b\uff0c\u5b83\u4eec\u662f\u57fa\u4e8e Qwen-2.5 \u4e3b\u5e72\u6784\u5efa\u7684\u5168\u5f00\u6e90\u63a8\u7406\u8bed\u8a00\u6a21\u578b (RLM)\u3002\u6a21\u578b\u8bad\u7ec3\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u5728\u5305\u542b 719K \u4e2a\u5df2\u9a8c\u8bc1\u7684\u601d\u7ef4\u94fe\u8f68\u8ff9\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03 (SFT)\uff1b\u5176\u6b21\uff0c\u5728 62K \u4e2a\u5177\u6709\u6311\u6218\u6027\u4e14\u53ef\u9a8c\u8bc1\u7684\u95ee\u9898\u4e0a\u8fdb\u884c\u57fa\u4e8e\u5956\u52b1\u7684\u5b66\u4e60 (RLVR)\u3002\u4e3a\u4e86\u63d0\u9ad8 RLVR \u8fc7\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u4e0a\u4e0b\u6587\u611f\u77e5\u591a\u9636\u6bb5\u7b56\u7565\u4f18\u5316\u201d\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u6574\u5408\u4e86\u957f\u5ea6\u6e10\u8fdb\u8bad\u7ec3\u548c\u81ea\u9002\u5e94\u91cd\u590d\u60e9\u7f5a\uff0c\u4ee5\u4fc3\u8fdb\u4e0a\u4e0b\u6587\u611f\u77e5\u7684 RL \u8bad\u7ec3\u3002", "result": "MiroMind-M1 \u7cfb\u5217\u6a21\u578b\u5728 AIME24\u3001AIME25 \u548c MATH \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u57fa\u4e8e Qwen-2.5 \u7684\u5f00\u6e90 7B \u548c 32B \u6a21\u578b\u4e2d\u5177\u6709\u66f4\u9ad8\u7684\u4ee3\u5e01\u6548\u7387\u3002", "conclusion": "MiroMind-M1 \u7cfb\u5217\u6a21\u578b\u5728 AIME24\u3001AIME25 \u548c MATH \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u57fa\u4e8e Qwen-2.5 \u7684\u5f00\u6e90 7B \u548c 32B \u6a21\u578b\u4e2d\u5177\u6709\u66f4\u9ad8\u7684\u4ee3\u5e01\u6548\u7387\u3002\u4e3a\u4fbf\u4e8e\u590d\u73b0\uff0c\u6211\u4eec\u53d1\u5e03\u4e86\u5b8c\u6574\u7684\u6280\u672f\u6808\uff0c\u5305\u62ec\u6a21\u578b\u3001\u6570\u636e\u96c6\u4ee5\u53ca\u6240\u6709\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u914d\u7f6e\u3002"}}
{"id": "2507.14191", "categories": ["eess.SP", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.14191", "abs": "https://arxiv.org/abs/2507.14191", "authors": ["Cliver Oliver Turpo Benique"], "title": "School Attendance Control System Based on RFID Technology with Raspberry Pi and Arduino: EDURFID", "comment": "27 pages, 4 figures. Educational technology system for rural schools\n  in Peru. Implements RFID-based attendance control using open-source hardware\n  (Raspberry Pi, Arduino). System validation conducted at T\\'upac Amaru\n  Secondary Educational Institution, Coasa, Puno", "summary": "This paper presents EDURFID, an automated school attendance control system\nbased on RFID technology designed for rural educational institutions in Peru.\nThe system integrates open-source hardware (Raspberry Pi 5, Arduino UNO R3)\nwith RC522 RFID modules operating at 13.56 MHz, implementing a web architecture\ndeveloped in Python Django. The system demonstrates 100% precision in RFID\nreadings with 0.03-second response time, achieving 94% cost reduction compared\nto commercial solutions. Validation at T\\'upac Amaru Secondary Educational\nInstitution showed successful automation of attendance processes, saving 50\ndaily minutes of administrative time while providing real-time reporting\ncapabilities.", "AI": {"tldr": "EDURFID\u662f\u4e00\u4e2a\u57fa\u4e8eRFID\u6280\u672f\u7684\u81ea\u52a8\u5316\u8003\u52e4\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u79d8\u9c81\u519c\u6751\u5b66\u6821\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u6210\u672c\u548c\u9ad8\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u79d8\u9c81\u519c\u6751\u6559\u80b2\u673a\u6784\u5728\u8003\u52e4\u7ba1\u7406\u4e0a\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u6bd4\u5546\u4e1a\u89e3\u51b3\u65b9\u6848\u66f4\u5177\u6210\u672c\u6548\u76ca\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "method": "EDURFID\u7cfb\u7edf\u91c7\u7528\u57fa\u4e8eRFID\u6280\u672f\u7684\u81ea\u52a8\u5316\u5b66\u6821\u8003\u52e4\u63a7\u5236\uff0c\u6574\u5408\u4e86\u5f00\u6e90\u786c\u4ef6\uff08Raspberry Pi 5\u3001Arduino UNO R3\uff09\u548cRC522 RFID\u6a21\u5757\uff08\u5de5\u4f5c\u9891\u738713.56 MHz\uff09\uff0c\u5e76\u4f7f\u7528Python Django\u5f00\u53d1\u7684Web\u67b6\u6784\u3002", "result": "\u7cfb\u7edf\u5728RFID\u8bfb\u53d6\u65b9\u9762\u5b9e\u73b0\u4e86100%\u7684\u7cbe\u5ea6\u548c0.03\u79d2\u7684\u54cd\u5e94\u65f6\u95f4\uff0c\u6210\u672c\u964d\u4f4e\u4e8694%\u3002\u5728T'upac Amaru\u4e2d\u5b66\u6559\u80b2\u673a\u6784\u7684\u9a8c\u8bc1\u4e2d\uff0c\u7cfb\u7edf\u6210\u529f\u81ea\u52a8\u5316\u4e86\u8003\u52e4\u6d41\u7a0b\uff0c\u6bcf\u5929\u8282\u7701\u4e8650\u5206\u949f\u7684\u884c\u653f\u65f6\u95f4\uff0c\u5e76\u5177\u5907\u5b9e\u65f6\u62a5\u544a\u80fd\u529b\u3002", "conclusion": "EDURFID\u7cfb\u7edf\u6210\u529f\u81ea\u52a8\u5316\u4e86\u8003\u52e4\u6d41\u7a0b\uff0c\u4e3a\u79d8\u9c81\u519c\u6751\u6559\u80b2\u673a\u6784\u63d0\u4f9b\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u7cbe\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15474", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15474", "abs": "https://arxiv.org/abs/2507.15474", "authors": ["Charith Premachandra", "Achala Athukorala", "U-Xuan Tan"], "title": "All-UWB SLAM Using UWB Radar and UWB AOA", "comment": null, "summary": "There has been a growing interest in autonomous systems designed to operate\nin adverse conditions (e.g. smoke, dust), where the visible light spectrum\nfails. In this context, Ultra-wideband (UWB) radar is capable of penetrating\nthrough such challenging environmental conditions due to the lower frequency\ncomponents within its broad bandwidth. Therefore, UWB radar has emerged as a\npotential sensing technology for Simultaneous Localization and Mapping (SLAM)\nin vision-denied environments where optical sensors (e.g. LiDAR, Camera) are\nprone to failure. Existing approaches involving UWB radar as the primary\nexteroceptive sensor generally extract features in the environment, which are\nlater initialized as landmarks in a map. However, these methods are constrained\nby the number of distinguishable features in the environment. Hence, this paper\nproposes a novel method incorporating UWB Angle of Arrival (AOA) measurements\ninto UWB radar-based SLAM systems to improve the accuracy and scalability of\nSLAM in feature-deficient environments. The AOA measurements are obtained using\nUWB anchor-tag units which are dynamically deployed by the robot in featureless\nareas during mapping of the environment. This paper thoroughly discusses\nprevailing constraints associated with UWB AOA measurement units and presents\nsolutions to overcome them. Our experimental results show that integrating UWB\nAOA units with UWB radar enables SLAM in vision-denied feature-deficient\nenvironments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06UWB\u5230\u8fbe\u89d2\uff08AOA\uff09\u6d4b\u91cf\u96c6\u6210\u5230UWB\u96f7\u8fbeSLAM\u7cfb\u7edf\u4e2d\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u7279\u5f81\u7a00\u758f\u73af\u5883\u4e0b\u7684SLAM\u6311\u6218\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u53d7\u9650\u4e14\u7279\u5f81\u7f3a\u5931\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684SLAM\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eUWB\u96f7\u8fbe\u7684SLAM\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u73af\u5883\u4e2d\u7684\u53ef\u533a\u5206\u7279\u5f81\uff0c\u4f46\u5728\u7279\u5f81\u7a00\u758f\u7684\u73af\u5883\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5c06UWB\u5230\u8fbe\u89d2\uff08AOA\uff09\u6d4b\u91cf\u96c6\u6210\u5230\u57fa\u4e8eUWB\u96f7\u8fbe\u7684SLAM\u7cfb\u7edf\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u5728\u7279\u5f81\u7f3a\u5931\u73af\u5883\u4e2d\u7684SLAM\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002AOA\u6d4b\u91cf\u662f\u901a\u8fc7\u5728\u6620\u5c04\u8fc7\u7a0b\u4e2d\u7531\u673a\u5668\u4eba\u52a8\u6001\u90e8\u7f72\u7684UWB\u951a\u5b9a\u6807\u7b7e\u5355\u5143\u83b7\u5f97\u7684\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c06UWB AOA\u5355\u5143\u4e0eUWB\u96f7\u8fbe\u96c6\u6210\uff0c\u53ef\u4ee5\u5728\u89c6\u89c9\u53d7\u9650\u4e14\u7279\u5f81\u7f3a\u5931\u7684\u73af\u5883\u4e2d\u5b9e\u73b0SLAM\u3002", "conclusion": "UWB\u96f7\u8fbe\u53ef\u4ee5\u7528\u4e8e\u89c6\u89c9\u53d7\u9650\u548c\u7279\u5f81\u7f3a\u5931\u7684\u73af\u5883\u4e0b\u7684SLAM\uff0c\u901a\u8fc7\u878d\u5408AOA\u6d4b\u91cf\u53ef\u4ee5\u63d0\u9ad8SLAM\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.14575", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14575", "abs": "https://arxiv.org/abs/2507.14575", "authors": ["Andrea Moschetto", "Lemuel Puglisi", "Alec Sargood", "Pierluigi Dell'Acqua", "Francesco Guarnera", "Sebastiano Battiato", "Daniele Rav\u00ec"], "title": "Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation", "comment": null, "summary": "Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image\ncontrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering\ndistinct diagnostic insights. However, acquiring all desired modalities\nincreases scan time and cost, motivating research into computational methods\nfor cross-modal synthesis. To address this, recent approaches aim to synthesize\nmissing MRI contrasts from those already acquired, reducing acquisition time\nwhile preserving diagnostic quality. Image-to-image (I2I) translation provides\na promising framework for this task. In this paper, we present a comprehensive\nbenchmark of generative models$\\unicode{x2013}$specifically, Generative\nAdversarial Networks (GANs), diffusion models, and flow matching (FM)\ntechniques$\\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All\nframeworks are implemented with comparable settings and evaluated on three\npublicly available MRI datasets of healthy adults. Our quantitative and\nqualitative analyses show that the GAN-based Pix2Pix model outperforms\ndiffusion and FM-based methods in terms of structural fidelity, image quality,\nand computational efficiency. Consistent with existing literature, these\nresults suggest that flow-based models are prone to overfitting on small\ndatasets and simpler tasks, and may require more data to match or surpass GAN\nperformance. These findings offer practical guidance for deploying I2I\ntranslation techniques in real-world MRI workflows and highlight promising\ndirections for future research in cross-modal medical image synthesis. Code and\nmodels are publicly available at\nhttps://github.com/AndreaMoschetto/medical-I2I-benchmark.", "AI": {"tldr": "Pix2Pix\u5728MRI\u8de8\u6a21\u6001\u5408\u6210\u4e2d\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4f46\u57fa\u4e8e\u6d41\u7684\u6a21\u578b\u9700\u8981\u66f4\u591a\u6570\u636e\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11MRI\u626b\u63cf\u65f6\u95f4\u3001\u6210\u672c\u548c\u63d0\u9ad8\u8bca\u65ad\u8d28\u91cf\uff0c\u7814\u7a76\u4eba\u5458\u6b63\u5728\u63a2\u7d22\u8ba1\u7b97\u65b9\u6cd5\u6765\u8fdb\u884c\u8de8\u6a21\u6001\u5408\u6210\uff0c\u5c06\u5df2\u83b7\u5f97\u7684MRI\u5bf9\u6bd4\u5ea6\uff08\u5982T1w\uff09\u8f6c\u6362\u4e3a\u7f3a\u5931\u7684\u5bf9\u6bd4\u5ea6\uff08\u5982T2w\uff09\u3002", "method": "\u672c\u6587\u5bf9\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u3001\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\uff08FM\uff09\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8eT1w\u5230T2w\u7684\u4e8c\u7ef4MRI\u56fe\u50cf\u8f6c\u6362\u3002\u6240\u6709\u6a21\u578b\u5747\u5728\u4e09\u4e2a\u516c\u5f00\u7684\u5065\u5eb7\u6210\u4ebaMRI\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u516c\u5e73\u8bbe\u7f6e\u548c\u8bc4\u4f30\u3002", "result": "\u5728\u5bf9\u4e09\u4e2a\u516c\u5f00MRI\u6570\u636e\u96c6\u8fdb\u884c\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u4e2d\uff0c\u57fa\u4e8eGAN\u7684Pix2Pix\u6a21\u578b\u5728\u7ed3\u6784\u4fdd\u771f\u5ea6\u3001\u56fe\u50cf\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u4e8e\u6269\u6563\u548cFM\u7684\u6a21\u578b\u3002", "conclusion": "Pix2Pix\u7b49\u751f\u6210\u6a21\u578b\u5728T1w\u5230T2w\u7684MRI\u56fe\u50cf\u8f6c\u6362\u4efb\u52a1\u4e2d\uff0c\u5728\u7ed3\u6784\u4fdd\u771f\u5ea6\u3001\u56fe\u50cf\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\u6a21\u578b\u3002\u57fa\u4e8e\u6d41\u7684\u6a21\u578b\u5728\u5c0f\u578b\u6570\u636e\u96c6\u4e0a\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u9700\u8981\u66f4\u591a\u6570\u636e\u624d\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7GAN\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15013", "abs": "https://arxiv.org/abs/2507.15013", "authors": ["Xiaoyu Li", "Jin Wu", "Shaoyang Guo", "Haoran Shi", "Chanjin Zheng"], "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing", "comment": "15pages, 7 figures", "summary": "In the smart era, psychometric tests are becoming increasingly important for\npersonnel selection, career development, and mental health assessment.\nForced-choice tests are common in personality assessments because they require\nparticipants to select from closely related options, lowering the risk of\nresponse distortion. This study presents a deep learning-based Forced-Choice\nNeural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of\ntraditional models and is applicable to the three most common item block types\nfound in forced-choice tests. To account for the unidimensionality of items in\nforced-choice tests, we create interpretable participant and item parameters.\nWe model the interactions between participant and item features using\nmultilayer neural networks after mining them using nonlinear mapping. In\naddition, we use the monotonicity assumption to improve the interpretability of\nthe diagnostic results. The FCNCD's effectiveness is validated by experiments\non real-world and simulated datasets that show its accuracy, interpretability,\nand robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFCNCD\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u6790\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5728\u667a\u80fd\u65f6\u4ee3\uff0c\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u5728\u4eba\u5458\u9009\u62d4\u3001\u804c\u4e1a\u53d1\u5c55\u548c\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u65b9\u9762\u65e5\u76ca\u91cd\u8981\u3002\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u56e0\u5176\u8981\u6c42\u53c2\u4e0e\u8005\u4ece\u5bc6\u5207\u76f8\u5173\u7684\u9009\u9879\u4e2d\u8fdb\u884c\u9009\u62e9\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u54cd\u5e94\u504f\u5dee\u7684\u98ce\u9669\uff0c\u56e0\u6b64\u5728\u6027\u683c\u8bc4\u4f30\u4e2d\u5f88\u5e38\u89c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5f3a\u5236\u9009\u62e9\u795e\u7ecf\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\uff08FCNCD\uff09\uff0c\u8be5\u6a21\u578b\u514b\u670d\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u9002\u7528\u4e8e\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u4e2d\u6700\u5e38\u89c1\u7684\u4e09\u4e2a\u9879\u76ee\u5757\u7c7b\u578b\u3002\u4e3a\u4e86\u89e3\u51b3\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u4e2d\u9879\u76ee\u7684\u5355\u4e00\u7ef4\u5ea6\u95ee\u9898\uff0c\u7814\u7a76\u521b\u5efa\u4e86\u53ef\u89e3\u91ca\u7684\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u53c2\u6570\u3002\u901a\u8fc7\u975e\u7ebf\u6027\u6620\u5c04\u6316\u6398\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u7279\u5f81\u540e\uff0c\u4f7f\u7528\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u8fdb\u884c\u5efa\u6a21\u3002\u6b64\u5916\uff0c\u8fd8\u5229\u7528\u5355\u8c03\u6027\u5047\u8bbe\u6765\u63d0\u9ad8\u8bca\u65ad\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86FCNCD\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "FCNCD\u7684\u6709\u6548\u6027\u901a\u8fc7\u5728\u771f\u5b9e\u4e16\u754c\u548c\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u5f97\u5230\u9a8c\u8bc1\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\u5176\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14484", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14484", "abs": "https://arxiv.org/abs/2507.14484", "authors": ["Yule Li", "Yifeng Lu", "Zhen Wang", "Zhewei Wei", "Yaliang Li", "Bolin Ding"], "title": "ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions", "comment": null, "summary": "In recent years, graph neural networks (GNN) have achieved unprecedented\nsuccesses in node classification tasks. Although GNNs inherently encode\nspecific inductive biases (e.g., acting as low-pass or high-pass filters), most\nexisting methods implicitly assume conditional independence among node labels\nin their optimization objectives. While this assumption is suitable for\ntraditional classification tasks such as image recognition, it contradicts the\nintuitive observation that node labels in graphs remain correlated, even after\nconditioning on the graph structure. To make structured predictions for node\nlabels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for\nStructured node Classification. ReDiSC estimates the joint distribution of node\nlabels using a reparameterized masked diffusion model, which is learned through\nthe variational expectation-maximization (EM) framework. Our theoretical\nanalysis shows the efficiency advantage of ReDiSC in the E-step compared to\nDPM-SNC, a state-of-the-art model that relies on a manifold-constrained\ndiffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's\nM-step objective to popular GNN and label propagation hybrid approaches.\nExtensive experiments demonstrate that ReDiSC achieves superior or highly\ncompetitive performance compared to state-of-the-art GNN, label propagation,\nand diffusion-based baselines across both homophilic and heterophilic graphs of\nvarying sizes. Notably, ReDiSC scales effectively to large-scale datasets on\nwhich previous structured diffusion methods fail due to computational\nconstraints, highlighting its significant practical advantage in structured\nnode classification tasks.", "AI": {"tldr": "ReDiSC\u662f\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u5316\u8282\u70b9\u5206\u7c7b\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u6269\u6563\u6a21\u578b\u5b66\u4e60\u8282\u70b9\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u5ffd\u7565\u4e86\u8282\u70b9\u6807\u7b7e\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u8fd9\u4e0e\u5b9e\u9645\u60c5\u51b5\u76f8\u6096\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReDiSC\u7684\u91cd\u53c2\u6570\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u8282\u70b9\u5206\u7c7b\u3002ReDiSC\u901a\u8fc7\u53d8\u5206\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u6846\u67b6\u5b66\u4e60\uff0c\u4f30\u8ba1\u8282\u70b9\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\u3002", "result": "ReDiSC\u5728E\u6b65\u6bd4DPM-SNC\u66f4\u6709\u6548\u7387\uff0c\u5176M\u6b65\u76ee\u6807\u4e0e\u6d41\u884c\u7684GNN\u548c\u6807\u7b7e\u4f20\u64ad\u6df7\u5408\u65b9\u6cd5\u76f8\u5173\u8054\u3002", "conclusion": "ReDiSC\u5728\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u56fe\u4e0a\u90fd\u53d6\u5f97\u4e86\u4f18\u4e8e\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u5730\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u514b\u670d\u4e86\u5148\u524d\u7ed3\u6784\u5316\u6269\u6563\u65b9\u6cd5\u5b58\u5728\u7684\u8ba1\u7b97\u74f6\u9888\u3002"}}
{"id": "2507.15564", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.15564", "abs": "https://arxiv.org/abs/2507.15564", "authors": ["Julius P. J. Krebbekx", "Roland T\u00f3th", "Amritam Das"], "title": "Scaled Relative Graph Analysis of General Interconnections of SISO Nonlinear Systems", "comment": null, "summary": "Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain\nmethod for the analysis of nonlinear systems. However, we show that the current\nSRG analysis suffers from a pitfall that limits its applicability in analyzing\npractical nonlinear systems. We overcome this pitfall by introducing a novel\nreformulation of the SRG of a linear time-invariant operator and combining the\nSRG with the Nyquist criterion. The result is a theorem that can be used to\nassess stability and $L_2$-gain performance for general interconnections of\nnonlinear dynamic systems. We provide practical calculation results for\ncanonical interconnections and apply our result to Lur'e systems to obtain a\ngeneralization of the celebrated circle criterion, which deals with broader\nclass of nonlinearities, and we derive (incremental) $L_2$-gain performance\nbounds. We illustrate the power of the new approach on the analysis of several\nexamples.", "AI": {"tldr": "\u6bd4\u4f8b\u56fe\uff08SRG\uff09\u5206\u6790\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u7cfb\u7edf\u5206\u6790\u4e2d\u5f97\u5230\u6539\u8fdb\uff0c\u901a\u8fc7\u4e0e\u5948\u594e\u65af\u7279\u5b9a\u7406\u7ed3\u5408\uff0c\u53ef\u4ee5\u66f4\u5e7f\u6cdb\u5730\u5e94\u7528\u4e8e\u7a33\u5b9a\u6027\u4e0eL2\u589e\u76ca\u6027\u80fd\u7684\u8bc4\u4f30\uff0c\u5e76\u5bf9Lur", "motivation": "\u73b0\u6709\u6bd4\u4f8b\u56fe\uff08SRG\uff09\u5206\u6790\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u5b9e\u9645\u975e\u7ebf\u6027\u7cfb\u7edf\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u7ebf\u6027\u65f6\u4e0d\u53d8\u7b97\u5b50\u7684\u6bd4\u4f8b\u56fe\uff08SRG\uff09\u7684\u4fee\u6b63\u516c\u5f0f\uff0c\u5e76\u5c06\u5176\u4e0e\u5948\u594e\u65af\u7279\u5b9a\u7406\u76f8\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b9a\u7406\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u4e00\u822c\u975e\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u4e0eL2\u589e\u76ca\u6027\u80fd\u3002\u63a8\u5bfc\u4e86Lur", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u7ebf\u6027\u65f6\u4e0d\u53d8\u7b97\u5b50\u7684\u6bd4\u4f8b\u56fe\uff08SRG\uff09\u7684\u4fee\u6b63\u516c\u5f0f\uff0c\u5e76\u5c06\u5176\u4e0e\u5948\u594e\u65af\u7279\u5b9a\u7406\u76f8\u7ed3\u5408\uff0c\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709SRG\u5206\u6790\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u65b0\u7684\u7406\u8bba\u6846\u67b6\u80fd\u591f\u8bc4\u4f30\u4e00\u822c\u975e\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c L2 \u589e\u76ca\u6027\u80fd\uff0c\u5e76\u5df2\u6210\u529f\u5e94\u7528\u4e8e Lur"}}
{"id": "2507.15051", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15051", "abs": "https://arxiv.org/abs/2507.15051", "authors": ["Mikhael T. Sayat", "Trevor R. Lee", "Suchit Negi", "Naoya Iwahara", "In Cheol Seo", "Yung Chuen Tan", "Ping Koy Lam", "Young-Wook Cho", "Jian-Rui Soh"], "title": "Polarisation and Temperature Dependence of Er$^{3+}$:CaWO$_4$ -- Towards a Solid-State Rare-Earth Ion-Doped Quantum Memory", "comment": "16 pages, 8 figures, 1 table (Supplementary Material: 6 pages, 1\n  table)", "summary": "In the endeavour of developing quantum memories, Er$^{3+}$:CaWO$_4$ has\nemerged as a promising rare-earth ion-doped (REID) crystal platform due to its\nlong optical coherence times and compatibility with the 1550 nm\ntelecommunications band. This work investigates the effects of polarisation and\ntemperature on the absorption strength, central wavelength, and linewidth of\nthe $Z_1\\to Y_1$ and $Z_1\\to Y_2$ optical transitions, with light incident\nalong the crystal $a$ and $c$ axes. It is found that the $Z_1\\to Y_1$\ntransition at 1532.6 nm with the incident laser along the $c$-axis at cryogenic\ntemperatures ($\\sim$3 K) is particularly favourable. The transition exhibits a\nstable central wavelength, narrower linewidth, polarisation independence,\nlarger absorption cross-section, and lies within the C-band -- attributes that\nmake it highly suitable for quantum memory applications.", "AI": {"tldr": "Er$^{3+}$:CaWO$_4$\u6676\u4f53\u57281532.6 nm\uff0cc\u8f74\u5165\u5c04\uff0c\u4f4e\u6e29\u4e0b\u5149\u5b66\u7279\u6027\u4f18\u5f02\uff0c\u9002\u5408\u91cf\u5b50\u5b58\u50a8\u3002", "motivation": "\u4e3a\u4e86\u5f00\u53d1\u91cf\u5b50\u5b58\u50a8\u5668\uff0c\u7814\u7a76\u5177\u6709\u957f\u5149\u5b66\u76f8\u5e72\u65f6\u95f4\u548c\u517c\u5bb91550 nm\u901a\u4fe1\u6ce2\u6bb5\u7684Er$^{3+}$:CaWO$_4$\u6676\u4f53\u5e73\u53f0\u3002", "method": "\u7814\u7a76\u4e86\u504f\u632f\u548c\u6e29\u5ea6\u5bf9Er$^{3+}$:CaWO$_4$\u6676\u4f53\u4e2dZ$_{1}\to Y_{1}$\u548cZ$_{1}\to Y_{2}$\u5149\u5b66\u8dc3\u8fc1\u7684\u5438\u6536\u5f3a\u5ea6\u3001\u4e2d\u5fc3\u6ce2\u957f\u548c\u7ebf\u5bbd\u7684\u5f71\u54cd\u3002", "result": "Z$_{1}\to Y_{1}$\u8dc3\u8fc1\u57281532.6 nm\uff0cc\u8f74\u5165\u5c04\uff0c\u4f4e\u6e29\uff08\u7ea63 K\uff09\u65f6\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u4e2d\u5fc3\u6ce2\u957f\u3001\u66f4\u7a84\u7684\u7ebf\u5bbd\u3001\u504f\u632f\u65e0\u5173\u6027\u3001\u66f4\u5927\u7684\u5438\u6536\u622a\u9762\uff0c\u5e76\u5904\u4e8eC\u6ce2\u6bb5\uff0c\u975e\u5e38\u9002\u5408\u91cf\u5b50\u5b58\u50a8\u3002", "conclusion": "Er$^{3+}$:CaWO$_4$\u6676\u4f53\u5728\u4f4e\u6e29\u548c\u7279\u5b9a\u6761\u4ef6\u4e0b\uff081532.6 nm\uff0cc\u8f74\u5165\u5c04\uff09\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u5149\u5b66\u7279\u6027\uff0c\u4f7f\u5176\u6210\u4e3a\u91cf\u5b50\u5b58\u50a8\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\u3002"}}
{"id": "2507.14688", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14688", "abs": "https://arxiv.org/abs/2507.14688", "authors": ["Mohammed Alkhowaiter", "Norah Alshahrani", "Saied Alshahrani", "Reem I. Masoud", "Alaa Alzahrani", "Deema Alnuhait", "Emad A. Alghamdi", "Khalid Almubarak"], "title": "Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations", "comment": null, "summary": "Post-training has emerged as a crucial technique for aligning pre-trained\nLarge Language Models (LLMs) with human instructions, significantly enhancing\ntheir performance across a wide range of tasks. Central to this process is the\nquality and diversity of post-training datasets. This paper presents a review\nof publicly available Arabic post-training datasets on the Hugging Face Hub,\norganized along four key dimensions: (1) LLM Capabilities (e.g., Question\nAnswering, Translation, Reasoning, Summarization, Dialogue, Code Generation,\nand Function Calling); (2) Steerability (e.g., persona and system prompts); (3)\nAlignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.\nEach dataset is rigorously evaluated based on popularity, practical adoption,\nrecency and maintenance, documentation and annotation quality, licensing\ntransparency, and scientific contribution. Our review revealed critical gaps in\nthe development of Arabic post-training datasets, including limited task\ndiversity, inconsistent or missing documentation and annotation, and low\nadoption across the community. Finally, the paper discusses the implications of\nthese gaps on the progress of Arabic LLMs and applications while providing\nconcrete recommendations for future efforts in post-training dataset\ndevelopment.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86Hugging Face Hub\u4e0a\u7684\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u4efb\u52a1\u591a\u6837\u6027\u3001\u6587\u6863\u8d28\u91cf\u548c\u793e\u533a\u91c7\u7528\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u963f\u62c9\u4f2f\u8bed\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u5316\u7684\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u3002\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u4e86\u89e3\u5f53\u524d\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u7684\u73b0\u72b6\uff0c\u8bc6\u522b\u5b58\u5728\u7684\u95ee\u9898\u548c\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u6570\u636e\u96c6\u7684\u5f00\u53d1\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u5bf9Hugging Face Hub\u4e0a\u516c\u5f00\u7684\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u6027\u56de\u987e\u548c\u8bc4\u4f30\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5728\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3001\u53ef\u63a7\u6027\u3001\u5bf9\u9f50\u6027\u548c\u9c81\u68d2\u6027\u56db\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4ece\u6d41\u884c\u5ea6\u3001\u5b9e\u9645\u5e94\u7528\u3001\u66f4\u65b0\u7ef4\u62a4\u3001\u6587\u6863\u6807\u6ce8\u8d28\u91cf\u3001\u8bb8\u53ef\u900f\u660e\u5ea6\u548c\u79d1\u5b66\u8d21\u732e\u7b49\u65b9\u9762\u8fdb\u884c\u8bc4\u4ef7\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524d\u7684\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u5728\u4efb\u52a1\u591a\u6837\u6027\u3001\u6587\u6863\u548c\u6807\u6ce8\u8d28\u91cf\u4ee5\u53ca\u793e\u533a\u91c7\u7528\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6570\u636e\u96c6\u8986\u76d6\u7684\u4efb\u52a1\u7c7b\u578b\u6709\u9650\uff0c\u6587\u6863\u548c\u6807\u6ce8\u8d28\u91cf\u4e0d\u4e00\u81f4\u6216\u7f3a\u5931\uff0c\u4e14\u5728\u793e\u533a\u4e2d\u7684\u5e94\u7528\u548c\u7ef4\u62a4\u7a0b\u5ea6\u8f83\u4f4e\u3002", "conclusion": "\u8be5\u8bba\u6587\u5bf9Hugging Face Hub\u4e0a\u516c\u5f00\u7684\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5168\u9762\u56de\u987e\uff0c\u8bc4\u4f30\u4e86\u5176\u5728\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3001\u53ef\u63a7\u6027\u3001\u5bf9\u9f50\u6027\u548c\u9c81\u68d2\u6027\u7b49\u65b9\u9762\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u963f\u62c9\u4f2f\u8bed\u6570\u636e\u96c6\u5728\u4efb\u52a1\u591a\u6837\u6027\u3001\u6587\u6863\u548c\u6807\u6ce8\u8d28\u91cf\u4ee5\u53ca\u793e\u533a\u91c7\u7528\u7387\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5e76\u5bf9\u963f\u62c9\u4f2f\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002"}}
{"id": "2507.14194", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14194", "abs": "https://arxiv.org/abs/2507.14194", "authors": ["David J Poland"], "title": "Boosted Enhanced Quantile Regression Neural Networks with Spatiotemporal Permutation Entropy for Complex System Prognostics", "comment": "Preliminary version of a predictive maintenance framework using\n  spiking neural networks and entropy-based analysis. To be expanded in future\n  publications with hardware implementations and real-time drift detection\n  modules. arXiv admin note: substantial text overlap with arXiv:2501.05087", "summary": "This paper presents a novel framework for pattern prediction and system\nprognostics centered on Spatiotemporal Permutation Entropy analysis integrated\nwith Boosted Enhanced Quantile Regression Neural Networks (BEQRNNs). We address\nthe challenge of understanding complex dynamical patterns in multidimensional\nsystems through an approach that combines entropy-based complexity measures\nwith advanced neural architectures. The system leverages dual computational\nstages: first implementing spatiotemporal entropy extraction optimized for\nmultiscale temporal and spatial data streams, followed by an integrated BEQRNN\nlayer that enables probabilistic pattern prediction with uncertainty\nquantification. This architecture achieves 81.17% accuracy in spatiotemporal\npattern classification with prediction horizons up to 200 time steps and\nmaintains robust performance across diverse regimes. Field testing across\nchaotic attractors, reaction-diffusion systems, and industrial datasets shows a\n79% increase in critical transition detection accuracy and 81.22% improvement\nin long-term prediction reliability. The framework's effectiveness in\nprocessing complex, multimodal entropy features demonstrates significant\npotential for real-time prognostic applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65f6\u7a7a\u6392\u5217\u71b5\u548cBEQRNNs\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u7cfb\u7edf\u9884\u540e\u548c\u6a21\u5f0f\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u7406\u89e3\u591a\u7ef4\u7cfb\u7edf\u4e2d\u590d\u6742\u52a8\u6001\u6a21\u5f0f\u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8e\u65f6\u7a7a\u6392\u5217\u71b5\u5206\u6790\u548c\u589e\u5f3a\u5206\u4f4d\u6570\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\uff08BEQRNNs\uff09\u7684\u6a21\u5f0f\u9884\u6d4b\u548c\u7cfb\u7edf\u9884\u540e\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u57fa\u4e8e\u71b5\u7684\u590d\u6742\u6027\u5ea6\u91cf\u548c\u5148\u8fdb\u7684\u795e\u7ecf\u67b6\u6784\uff0c\u4ee5\u5e94\u5bf9\u591a\u7ef4\u7cfb\u7edf\u4e2d\u590d\u6742\u52a8\u6001\u6a21\u5f0f\u7684\u7406\u89e3\u6311\u6218\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u53cc\u8ba1\u7b97\u9636\u6bb5\uff1a\u9996\u5148\u5b9e\u73b0\u9488\u5bf9\u591a\u5c3a\u5ea6\u65f6\u95f4\u548c\u7a7a\u95f4\u6570\u636e\u6d41\u4f18\u5316\u7684\u65f6\u7a7a\u71b5\u63d0\u53d6\uff0c\u7136\u540e\u96c6\u6210BEQRNN\u5c42\uff0c\u5b9e\u73b0\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u6982\u7387\u6a21\u5f0f\u9884\u6d4b\u3002", "result": "\u8be5\u6846\u67b6\u5728\u65f6\u7a7a\u6a21\u5f0f\u5206\u7c7b\u4e2d\u5b9e\u73b0\u4e8681.17%\u7684\u51c6\u786e\u7387\uff0c\u9884\u6d4b\u8303\u56f4\u957f\u8fbe200\u4e2a\u65f6\u95f4\u6b65\uff0c\u5e76\u5728\u4e0d\u540c\u72b6\u6001\u4e0b\u4fdd\u6301\u7a33\u5065\u7684\u6027\u80fd\u3002\u5728\u6df7\u6c8c\u5438\u5f15\u5b50\u3001\u53cd\u5e94\u6269\u6563\u7cfb\u7edf\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u73b0\u573a\u6d4b\u8bd5\u663e\u793a\uff0c\u5173\u952e\u8f6c\u53d8\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad8\u4e8679%\uff0c\u957f\u671f\u9884\u6d4b\u53ef\u9760\u6027\u63d0\u9ad8\u4e8681.22%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5904\u7406\u590d\u6742\u3001\u591a\u6a21\u6001\u71b5\u7279\u5f81\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u5728\u5b9e\u65f6\u9884\u540e\u5e94\u7528\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15478", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15478", "abs": "https://arxiv.org/abs/2507.15478", "authors": ["Simon Kohaut", "Felix Divo", "Navid Hamid", "Benedict Flade", "Julian Eggert", "Devendra Singh Dhami", "Kristian Kersting"], "title": "The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents", "comment": null, "summary": "Ensuring reliable and rule-compliant behavior of autonomous agents in\nuncertain environments remains a fundamental challenge in modern robotics. Our\nwork shows how neuro-symbolic systems, which integrate probabilistic, symbolic\nwhite-box reasoning models with deep learning methods, offer a powerful\nsolution to this challenge. This enables the simultaneous consideration of\nexplicit rules and neural models trained on noisy data, combining the strength\nof structured reasoning with flexible representations. To this end, we\nintroduce the Constitutional Controller (CoCo), a novel framework designed to\nenhance the safety and reliability of agents by reasoning over deep\nprobabilistic logic programs representing constraints such as those found in\nshared traffic spaces. Furthermore, we propose the concept of self-doubt,\nimplemented as a probability density conditioned on doubt features such as\ntravel velocity, employed sensors, or health factors. In a real-world aerial\nmobility study, we demonstrate CoCo's advantages for intelligent autonomous\nsystems to learn appropriate doubts and navigate complex and uncertain\nenvironments safely and compliantly.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14587", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14587", "abs": "https://arxiv.org/abs/2507.14587", "authors": ["Merjem Be\u0107irovi\u0107", "Amina Kurtovi\u0107", "Nordin Smajlovi\u0107", "Medina Kapo", "Amila Akagi\u0107"], "title": "Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX", "comment": null, "summary": "Medical imaging plays a vital role in early disease diagnosis and monitoring.\nSpecifically, blood microscopy offers valuable insights into blood cell\nmorphology and the detection of hematological disorders. In recent years, deep\nlearning-based automated classification systems have demonstrated high\npotential in enhancing the accuracy and efficiency of blood image analysis.\nHowever, a detailed performance analysis of specific deep learning frameworks\nappears to be lacking. This paper compares the performance of three popular\ndeep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in\nclassifying blood cell images from the publicly available BloodMNIST dataset.\nThe study primarily focuses on inference time differences, but also\nclassification performance for different image sizes. The results reveal\nvariations in performance across frameworks, influenced by factors such as\nimage resolution and framework-specific optimizations. Classification accuracy\nfor JAX and PyTorch was comparable to current benchmarks, showcasing the\nefficiency of these frameworks for medical image classification.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86TensorFlow\u3001PyTorch\u548cJAX\u5728\u8840\u7ec6\u80de\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5728\u56fe\u50cf\u5206\u8fa8\u7387\u548c\u6846\u67b6\u4f18\u5316\u7b49\u56e0\u7d20\u5f71\u54cd\u4e0b\uff0cJAX\u548cPyTorch\u7684\u6027\u80fd\u4e0e\u73b0\u6709\u57fa\u51c6\u76f8\u5f53\uff0c\u663e\u793a\u51fa\u5176\u5728\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u81ea\u52a8\u5206\u7c7b\u7cfb\u7edf\u5728\u8840\u7ec6\u80de\u56fe\u50cf\u5206\u6790\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7279\u5b9a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u8be6\u7ec6\u6027\u80fd\u5206\u6790\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u6bd4\u8f83TensorFlow (Keras)\u3001PyTorch\u548cJAX\u8fd9\u4e09\u79cd\u6d41\u884c\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5728BloodMNIST\u6570\u636e\u96c6\u4e0a\u7684\u8840\u7ec6\u80de\u56fe\u50cf\u5206\u7c7b\u6027\u80fd\u6765\u8bc4\u4f30\u5b83\u4eec\u3002\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a8\u7406\u65f6\u95f4\u5dee\u5f02\uff0c\u540c\u65f6\u4e5f\u8003\u5bdf\u4e86\u4e0d\u540c\u56fe\u50cf\u5c3a\u5bf8\u4e0b\u7684\u5206\u7c7b\u6027\u80fd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u540c\u6846\u67b6\u5728\u6027\u80fd\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u8fd9\u53d7\u5230\u56fe\u50cf\u5206\u8fa8\u7387\u548c\u6846\u67b6\u7279\u5b9a\u4f18\u5316\u7b49\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "conclusion": "JAX\u548cPyTorch\u5728\u8840\u7ec6\u80de\u56fe\u50cf\u5206\u7c7b\u65b9\u9762\u8fbe\u5230\u4e86\u4e0e\u5f53\u524d\u57fa\u51c6\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u6846\u67b6\u5728\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u65b9\u9762\u7684\u6548\u7387\u3002"}}
{"id": "2507.15042", "categories": ["cs.AI", "cs.IR", "I.2.7; H.3.3; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.15042", "abs": "https://arxiv.org/abs/2507.15042", "authors": ["Jerry Wang", "Fang Yu"], "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection", "comment": "Accepted by KDD Workshop on Prompt Optimization 2025", "summary": "Adversarial prompt attacks can significantly alter the reliability of\nRetrieval-Augmented Generation (RAG) systems by re-ranking them to produce\nincorrect outputs. In this paper, we present a novel method that applies\nDifferential Evolution (DE) to optimize adversarial prompt suffixes for\nRAG-based question answering. Our approach is gradient-free, treating the RAG\npipeline as a black box and evolving a population of candidate suffixes to\nmaximize the retrieval rank of a targeted incorrect document to be closer to\nreal world scenarios. We conducted experiments on the BEIR QA datasets to\nevaluate attack success at certain retrieval rank thresholds under multiple\nretrieving applications. Our results demonstrate that DE-based prompt\noptimization attains competitive (and in some cases higher) success rates\ncompared to GGPP to dense retrievers and PRADA to sparse retrievers, while\nusing only a small number of tokens (<=5 tokens) in the adversarial suffix.\nFurthermore, we introduce a readability-aware suffix construction strategy,\nvalidated by a statistically significant reduction in MLM negative\nlog-likelihood with Welch's t-test. Through evaluations with a BERT-based\nadversarial suffix detector, we show that DE-generated suffixes evade\ndetection, yielding near-chance detection accuracy.", "AI": {"tldr": "This paper introduces a Differential Evolution (DE) method to create adversarial prompt attacks for RAG systems. The method optimizes suffixes to trick RAG into retrieving wrong information, showing strong performance against existing methods and evading detection, even with short suffixes.", "motivation": "Adversarial prompt attacks can degrade the reliability of Retrieval-Augmented Generation (RAG) systems by causing them to produce incorrect outputs. This work aims to develop an effective method to optimize these attacks.", "method": "This paper proposes a novel gradient-free method using Differential Evolution (DE) to optimize adversarial prompt suffixes for RAG-based question answering. The RAG pipeline is treated as a black box, and DE evolves candidate suffixes to maximize the retrieval rank of a targeted incorrect document. A readability-aware suffix construction strategy was also introduced and validated.", "result": "Experiments on BEIR QA datasets show that the DE-based method attains competitive or higher success rates compared to GGPP and PRADA, using only a few tokens (<=5). The readability-aware strategy reduced MLM negative log-likelihood. Furthermore, DE-generated suffixes were found to evade detection by a BERT-based detector, resulting in near-chance detection accuracy.", "conclusion": "DE-based prompt optimization achieves competitive or higher success rates than existing methods like GGPP and PRADA for RAG systems, using minimal tokens and evading detection by adversarial suffix detectors."}}
{"id": "2507.14487", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14487", "abs": "https://arxiv.org/abs/2507.14487", "authors": ["Ukjo Hwang", "Songnam Hong"], "title": "Federated Reinforcement Learning in Heterogeneous Environments", "comment": null, "summary": "We investigate a Federated Reinforcement Learning with Environment\nHeterogeneity (FRL-EH) framework, where local environments exhibit statistical\nheterogeneity. Within this framework, agents collaboratively learn a global\npolicy by aggregating their collective experiences while preserving the privacy\nof their local trajectories. To better reflect real-world scenarios, we\nintroduce a robust FRL-EH framework by presenting a novel global objective\nfunction. This function is specifically designed to optimize a global policy\nthat ensures robust performance across heterogeneous local environments and\ntheir plausible perturbations. We propose a tabular FRL algorithm named FedRQ\nand theoretically prove its asymptotic convergence to an optimal policy for the\nglobal objective function. Furthermore, we extend FedRQ to environments with\ncontinuous state space through the use of expectile loss, addressing the key\nchallenge of minimizing a value function over a continuous subset of the state\nspace. This advancement facilitates the seamless integration of the principles\nof FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive\nempirical evaluations validate the effectiveness and robustness of our FRL\nalgorithms across diverse heterogeneous environments, consistently achieving\nsuperior performance over the existing state-of-the-art FRL algorithms.", "AI": {"tldr": "Federated Reinforcement Learning (FRL) with Environment Heterogeneity (FRL-EH) framework and FedRQ algorithm improve robustness and performance in diverse environments compared to existing methods.", "motivation": "To address the challenge of statistical heterogeneity in local environments within Federated Reinforcement Learning (FRL), aiming to improve robustness and performance in real-world scenarios.", "method": "We introduce a Federated Reinforcement Learning with Environment Heterogeneity (FRL-EH) framework. A novel global objective function is proposed to optimize a global policy for robust performance across heterogeneous local environments. FedRQ is proposed for tabular environments and theoretically proven for convergence. An extension using expectile loss is developed for continuous state spaces, enabling integration with DNN-based RL algorithms.", "result": "Empirical evaluations show that our FRL algorithms (FedRQ and its extension) are effective and robust, consistently outperforming state-of-the-art FRL algorithms in diverse heterogeneous environments.", "conclusion": "We propose FedRQ, a tabular FRL algorithm, and its extension to continuous state spaces, demonstrating superior performance and robustness against existing FRL algorithms in heterogeneous environments."}}
{"id": "2507.15430", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15430", "abs": "https://arxiv.org/abs/2507.15430", "authors": ["Nikhil Singh", "Mohammad Ubaid", "Pabitra Kumar Nayak", "Jiangang He", "Dibyajyoti Ghosh", "Chris Wolverton", "Koushik Pal"], "title": "Data-driven Discovery of Novel High-performance Quaternary Chalcogenide Photovoltaics", "comment": null, "summary": "Photovoltaic materials facilitate the conversion of sunlight into electricity\nby harnessing the interaction between light and matter, offering an\neco-friendly and cost-efficient energy solution. Combining data-driven\napproaches with static and time-dependent density functional theories and\nnonadiabatic molecular dynamics simulations, we predict 14 high-performance\nphotoabsorber materials from a family of known quaternary semiconductors. Among\nthese, we investigate four compounds - SrCuGdSe3, SrCuDyTe3, BaCuLaSe3, and\nBaCuLaTe3 in greater detail. Hybrid density functional theory calculations\nincluding spin-orbit coupling reveal that SrCuGdSe3, SrCuDyTe3, BaCuLaSe3 and\nBaCuLaTe3 possess direct band gaps of 1.65, 1.79, 1.05, and 1.01 eV,\nrespectively. These band gap values lie close to an optimal range ideal for\nvisible-light absorption. Consequently, the calculated optical absorption\ncoefficient and spectroscopic limited maximum efficiency for these compounds\nbecome comparable or larger than crystalline silicon, GaAs, and methylammonium\nlead iodide. Calculated exciton binding energies for these compounds are\nrelatively small (30-32 meV), signifying easy separation of the electron-hole\npairs, and hence enhanced power conversion efficiencies. Investigations of\nphotoexcited carrier dynamics reveal a relatively long carrier lifetime (~\n30-40 ns), suggesting suppressed nonradiative recombination and enhanced\nphoto-conversion efficiencies. We further determined the defect formation\nenergies in these compounds, which showed that despite the likely formation of\ncation vacancies and interstitial defects, midgap states remain absent making\nthese defects non-detrimental to carrier recombination. Our theoretical\npredictions invite experimental verification and encourage further\ninvestigations of these and similar compounds in this quaternary semiconductor\nfamily.", "AI": {"tldr": "\u5229\u7528DFT\u548c\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u9884\u6d4b\u4e86\u56db\u79cd\u5177\u6709\u4f18\u5f02\u5149\u7535\u6027\u80fd\u7684\u65b0\u578b\u5149\u4f0f\u6750\u6599\uff08SrCuGdSe3, SrCuDyTe3, BaCuLaSe3, BaCuLaTe3\uff09\uff0c\u5b83\u4eec\u5728\u5e26\u9699\u3001\u5149\u5b66\u5438\u6536\u3001\u8f7d\u6d41\u5b50\u5bff\u547d\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u6709\u671b\u6210\u4e3a\u9ad8\u6548\u592a\u9633\u80fd\u7535\u6c60\u7684\u5019\u9009\u6750\u6599\u3002", "motivation": "\u4e3a\u4e86\u5bfb\u627e\u73af\u4fdd\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u80fd\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u9884\u6d4b\u9ad8\u6027\u80fd\u5149\u5438\u6536\u6750\u6599\u6765\u63a8\u52a8\u5149\u4f0f\u6280\u672f\u7684\u53d1\u5c55\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u53d1\u73b0\u5177\u6709\u7406\u60f3\u5149\u7535\u6027\u80fd\u7684\u65b0\u578b\u5149\u4f0f\u6750\u6599\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u5728\u53ef\u89c1\u5149\u5438\u6536\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u7684\u6750\u6599\uff0c\u4ee5\u671f\u8d85\u8d8a\u73b0\u6709\u6750\u6599\u5982\u6676\u4f53\u7845\u3001GaAs\u548c\u6709\u673a-\u7898\u5316\u94c5\u3002", "method": "\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3001\u9759\u6001\u548c\u65f6\u53d8\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u4ee5\u53ca\u975e\u7edd\u70ed\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u7814\u7a76\u4eba\u5458\u9884\u6d4b\u4e8614\u79cd\u9ad8\u6027\u80fd\u5149\u5438\u6536\u6750\u6599\u3002\u5bf9\u5176\u4e2d\u56db\u79cd\u6750\u6599\uff08SrCuGdSe3, SrCuDyTe3, BaCuLaSe3, BaCuLaTe3\uff09\u8fdb\u884c\u4e86\u66f4\u8be6\u7ec6\u7684\u7814\u7a76\uff0c\u5229\u7528\u5305\u62ec\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u7684\u6df7\u5408\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\u4e86\u5b83\u4eec\u7684\u5e26\u9699\u3001\u5149\u5b66\u5438\u6536\u7cfb\u6570\u3001\u6709\u9650\u5c3a\u5bf8\u7684\u6700\u9ad8\u6548\u7387\uff08SLME\uff09\u3001\u6fc0\u5b50\u7ed3\u5408\u80fd\u548c\u5149\u6fc0\u53d1\u8f7d\u6d41\u5b50\u52a8\u529b\u5b66\u3002\u6b64\u5916\uff0c\u8fd8\u8ba1\u7b97\u4e86\u8fd9\u4e9b\u5316\u5408\u7269\u7684\u7f3a\u9677\u5f62\u6210\u80fd\u3002", "result": "\u7814\u7a76\u9884\u6d4b\u4e8614\u79cd\u9ad8\u6027\u80fd\u5149\u5438\u6536\u6750\u6599\uff0c\u5e76\u8be6\u7ec6\u7814\u7a76\u4e86SrCuGdSe3, SrCuDyTe3, BaCuLaSe3\u548cBaCuLaTe3\u3002\u8fd9\u4e9b\u6750\u6599\u5177\u67091.65, 1.79, 1.05, \u548c 1.01 eV\u7684\u76f4\u63a5\u5e26\u9699\uff0c\u5904\u4e8e\u53ef\u89c1\u5149\u5438\u6536\u7684\u7406\u60f3\u8303\u56f4\u3002\u5b83\u4eec\u7684\u5149\u5b66\u5438\u6536\u7cfb\u6570\u548c\u6709\u9650\u5c3a\u5bf8\u7684\u6700\u9ad8\u6548\u7387\uff08SLME\uff09\u4e0e\u6676\u4f53\u7845\u3001GaAs\u548c\u6709\u673a-\u7898\u5316\u94c5\u76f8\u5f53\u6216\u66f4\u9ad8\u3002\u6fc0\u5b50\u7ed3\u5408\u80fd\u5c0f\uff0830-32 meV\uff09\uff0c\u6709\u5229\u4e8e\u7535\u5b50-\u7a7a\u7a74\u5206\u79bb\u3002\u8f7d\u6d41\u5b50\u5bff\u547d\u957f\uff08\u7ea630-40 ns\uff09\uff0c\u6291\u5236\u4e86\u975e\u8f90\u5c04\u590d\u5408\u3002\u867d\u7136\u5b58\u5728\u9633\u79bb\u5b50\u7a7a\u4f4d\u548c\u95f4\u9699\u7f3a\u9677\uff0c\u4f46\u5b83\u4eec\u4e0d\u4f1a\u5f62\u6210\u6709\u5bb3\u7684\u4e2d\u5e26\u9699\u6001\uff0c\u5bf9\u8f7d\u6d41\u5b50\u590d\u5408\u65e0\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u9884\u6d4b\u4e8614\u79cd\u9ad8\u6027\u80fd\u5149\u5438\u6536\u6750\u6599\uff0c\u5176\u4e2dSrCuGdSe3, SrCuDyTe3, BaCuLaSe3\u548cBaCuLaTe3\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u5149\u7535\u6027\u80fd\uff0c\u5177\u6709\u63a5\u8fd1\u53ef\u89c1\u5149\u5438\u6536\u7684\u7406\u60f3\u5e26\u9699\u3001\u4e0e\u7845\u548cGaAs\u76f8\u5f53\u7684\u5149\u5b66\u6027\u8d28\u3001\u5c0f\u7684\u6fc0\u5b50\u7ed3\u5408\u80fd\u3001\u957f\u7684\u8f7d\u6d41\u5b50\u5bff\u547d\u4ee5\u53ca\u65e0\u5bb3\u7684\u7f3a\u9677\uff0c\u8fd9\u4e9b\u90fd\u9884\u793a\u7740\u5b83\u4eec\u5728\u5149\u4f0f\u9886\u57df\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u548c\u7814\u7a76\u3002"}}
{"id": "2507.15594", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15594", "abs": "https://arxiv.org/abs/2507.15594", "authors": ["Junnan Pan", "Prodromos Sotiriadis", "Vladislav Nenchev", "Ferdinand Englberger"], "title": "Improving Functional Reliability of Near-Field Monitoring for Emergency Braking in Autonomous Vehicles", "comment": "6 pages, 3 figures, conference paper", "summary": "Autonomous vehicles require reliable hazard detection. However, primary\nsensor systems may miss near-field obstacles, resulting in safety risks.\nAlthough a dedicated fast-reacting near-field monitoring system can mitigate\nthis, it typically suffers from false positives. To mitigate these, in this\npaper, we introduce three monitoring strategies based on dynamic spatial\nproperties, relevant object sizes, and motion-aware prediction. In experiments\nin a validated simulation, we compare the initial monitoring strategy against\nthe proposed improvements. The results demonstrate that the proposed strategies\ncan significantly improve the reliability of near-field monitoring systems.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8e\u52a8\u6001\u7a7a\u95f4\u5c5e\u6027\u3001\u5bf9\u8c61\u5927\u5c0f\u548c\u8fd0\u52a8\u9884\u6d4b\u7684\u76d1\u63a7\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8fd1\u573a\u969c\u788d\u7269\u68c0\u6d4b\u7684\u53ef\u9760\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8fd1\u573a\u969c\u788d\u7269\u68c0\u6d4b\u4e2d\uff0c\u4e3b\u8981\u4f20\u611f\u5668\u7cfb\u7edf\u53ef\u80fd\u9057\u6f0f\u8fd1\u573a\u969c\u788d\u7269\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u4e13\u95e8\u7684\u5feb\u901f\u53cd\u5e94\u8fd1\u573a\u76d1\u63a7\u7cfb\u7edf\u53ef\u80fd\u51fa\u73b0\u7684\u8bef\u62a5\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u57fa\u4e8e\u52a8\u6001\u7a7a\u95f4\u5c5e\u6027\u3001\u76f8\u5173\u5bf9\u8c61\u5927\u5c0f\u548c\u8fd0\u52a8\u611f\u77e5\u9884\u6d4b\uff0c\u5f15\u5165\u4e86\u4e09\u79cd\u76d1\u63a7\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728\u5df2\u9a8c\u8bc1\u7684\u6a21\u62df\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\uff0c\u5c06\u521d\u59cb\u76d1\u63a7\u7b56\u7565\u4e0e\u6240\u63d0\u51fa\u7684\u6539\u8fdb\u7b56\u7565\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8fd1\u573a\u76d1\u63a7\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u53ef\u663e\u8457\u63d0\u9ad8\u8fd1\u573a\u76d1\u63a7\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.15056", "categories": ["quant-ph", "cond-mat.str-el", "cs.IT", "hep-th", "math.GT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15056", "abs": "https://arxiv.org/abs/2507.15056", "authors": ["Guanyu Zhu"], "title": "Transversal non-Clifford gates on qLDPC codes breaking the $\\sqrt{N}$ distance barrier and quantum-inspired geometry with $\\mathbb{Z}_2$ systolic freedom", "comment": "18 pages, 4 figures", "summary": "Historically, a $\\sqrt{N}log^{1/2}(N)$ distance barrier for quantum\nlow-density parity-check (LDPC) codes with $N$ qubits persisted for nearly two\ndecades, until the recent discovery of the fibre-bundle code. An open question\nis whether such a distance barrier can be broken while preserving the ability\nto perform transversal non-Clifford gates. In this direction, another\nlong-standing distance barrier of $N^{1/3}$ for LDPC stabilizer codes --\npresent since the discovery of the 3D color code -- was only recently overcome\nby a construction achieving an $\\Omega(\\sqrt{N})$ distance (arXiv:2501.19375).\nThe present work further breaks the $\\sqrt{N}$ distance barrier by taking a\nhomological product of three good qLDPC codes, combined with the\nFreedman-Hastings code-to-manifold mapping and the triple cup product to\nimplement transversal CCZ gates. The resulting code achieves an\n$\\Omega(N^{2/3})$ distance (a linear $X$-distance of $\\Theta(N)$) and a\ndimension of $\\Theta(N^{2/3})$, which enables fault-tolerant preparation of\n$\\Theta(N^{1/3})$ independent logical CCZ magic states in a single shot,\nwithout distillation (`magic state fountain'). This new quantum code also\ninspires the discovery of a family of exotic $3q$-dimensional manifolds\n$\\mathcal{M}$, which exhibit both a power-law $\\mathbb{Z}_2$-($q$,\n$2q$)-systolic freedom and $\\Theta(vol(\\mathcal{M}))$ triple intersection\npoints of $2q$-dimensional submanifolds.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u540c\u8c03\u79ef\u548c\u4e09\u91cd\u676f\u79ef\uff0c\u5c06\u91cf\u5b50LDPC\u7801\u7684\u8ddd\u79bb\u969c\u788d\u4ece$\text{O}(\text{N}^{1/2})$\u63d0\u5347\u81f3$\text{O}(\text{N}^{2/3})$\uff0c\u5e76\u5b9e\u73b0\u4e86\u65e0\u9700\u84b8\u998f\u7684\u903b\u8f91CCZ\u9b54\u6cd5\u6001\u5236\u5907\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u7a81\u7834\u91cf\u5b50LDPC\u7801\u7684\u8ddd\u79bb\u969c\u788d\uff0c\u540c\u65f6\u4fdd\u6301\u6a2a\u7a7f\u975eClifford\u95e8\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u53d6\u4e09\u4e2a\u826f\u597d\u91cf\u5b50LDPC\u7801\u7684\u540c\u8c03\u79ef\uff0c\u7ed3\u5408Freedman-Hastings\u7801\u5230\u6d41\u5f62\u6620\u5c04\u548c\u4e09\u91cd\u676f\u79ef\uff0c\u5b9e\u73b0\u4e86\u53ef\u6a2a\u7a7f\u7684CCZ\u95e8\u3002", "result": "\u6240\u63d0\u51fa\u7684\u91cf\u5b50\u7801\u5b9e\u73b0\u4e86$\text{O}(\text{N}^{2/3})$\u7684\u8ddd\u79bb\uff08\u7ebf\u6027\u7684X\u8ddd\u79bb\u4e3a$\text{\u0398}(\text{N})$\uff09\uff0c\u7ef4\u5ea6\u4e3a$\text{\u0398}(\text{N}^{2/3})$\uff0c\u53ef\u5728\u5355\u6b21\u5b9e\u73b0\u4e2d\u5236\u5907$\text{\u0398}(\text{N}^{1/3})$\u4e2a\u72ec\u7acb\u7684\u903b\u8f91CCZ\u9b54\u6cd5\u6001\uff0c\u4e14\u65e0\u9700\u84b8\u998f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u91cf\u5b50LDPC\u7801\u5c06\u8ddd\u79bb\u969c\u788d\u4ece$\text{O}(\text{N}^{1/2})$\u63d0\u5347\u81f3$\text{O}(\text{N}^{2/3})$\uff0c\u5e76\u5b9e\u73b0\u4e86$\text{O}(\text{N})$\u7684\u7ebf\u6027X\u8ddd\u79bb\uff0c\u80fd\u591f\u5728\u5355\u6b21\u5b9e\u73b0\u4e2d\u5236\u5907$\text{O}(\text{N}^{1/3})$\u4e2a\u72ec\u7acb\u7684\u903b\u8f91CCZ\u9b54\u6cd5\u6001\uff0c\u65e0\u9700\u84b8\u998f\u3002\u6b64\u5916\uff0c\u8be5\u5de5\u4f5c\u8fd8\u542f\u53d1\u4e86\u4e00\u7c7b\u65b0\u7684$\text{3q}$\u7ef4\u6d41\u5f62$\text{M}$\u7684\u53d1\u73b0\u3002"}}
{"id": "2507.14693", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14693", "abs": "https://arxiv.org/abs/2507.14693", "authors": ["Amina Dzafic", "Merve Kavut", "Ulya Bayram"], "title": "Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation", "comment": "This manuscript has been submitted to the IEEE Journal of Biomedical\n  and Health Informatics", "summary": "Suicidal ideation detection is critical for real-time suicide prevention, yet\nits progress faces two under-explored challenges: limited language coverage and\nunreliable annotation practices. Most available datasets are in English, but\neven among these, high-quality, human-annotated data remains scarce. As a\nresult, many studies rely on available pre-labeled datasets without examining\ntheir annotation process or label reliability. The lack of datasets in other\nlanguages further limits the global realization of suicide prevention via\nartificial intelligence (AI). In this study, we address one of these gaps by\nconstructing a novel Turkish suicidal ideation corpus derived from social media\nposts and introducing a resource-efficient annotation framework involving three\nhuman annotators and two large language models (LLMs). We then address the\nremaining gaps by performing a bidirectional evaluation of label reliability\nand model consistency across this dataset and three popular English suicidal\nideation detection datasets, using transfer learning through eight pre-trained\nsentiment and emotion classifiers. These transformers help assess annotation\nconsistency and benchmark model performance against manually labeled data. Our\nfindings underscore the need for more rigorous, language-inclusive approaches\nto annotation and evaluation in mental health natural language processing (NLP)\nwhile demonstrating the questionable performance of popular models with\nzero-shot transfer learning. We advocate for transparency in model training and\ndataset construction in mental health NLP, prioritizing data and model\nreliability.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u571f\u8033\u5176\u8bed\u81ea\u6740\u610f\u5ff5\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u4eba\u5de5\u548cAI\u6807\u6ce8\u7684\u6846\u67b6\u3002\u901a\u8fc7\u8bc4\u4f30\u6807\u7b7e\u53ef\u9760\u6027\u548c\u6a21\u578b\u4e00\u81f4\u6027\uff0c\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u5728\u81ea\u6740\u610f\u5ff5\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u547c\u5401\u5728\u5fc3\u7406\u5065\u5eb7NLP\u9886\u57df\u63d0\u9ad8\u6570\u636e\u548c\u6a21\u578b\u7684\u900f\u660e\u5ea6\u4e0e\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u6740\u610f\u5ff5\u68c0\u6d4b\u7814\u7a76\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u8bed\u8a00\u8986\u76d6\u8303\u56f4\u6709\u9650\u548c\u6807\u6ce8\u5b9e\u8df5\u4e0d\u53ef\u9760\u3002\u5927\u591a\u6570\u53ef\u7528\u6570\u636e\u96c6\u662f\u82f1\u6587\u7684\uff0c\u5373\u4f7f\u662f\u82f1\u6587\u6570\u636e\uff0c\u9ad8\u8d28\u91cf\u7684\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u4e5f\u5f88\u7a00\u5c11\u3002\u6b64\u5916\uff0c\u5176\u4ed6\u8bed\u8a00\u7684\u6570\u636e\u96c6\u532e\u4e4f\u963b\u788d\u4e86\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5b9e\u73b0\u5168\u7403\u81ea\u6740\u9884\u9632\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u65b0\u7684\u571f\u8033\u5176\u8bed\u8bed\u6599\u5e93\u5e76\u8bc4\u4f30\u6807\u6ce8\u53ef\u9760\u6027\u548c\u6a21\u578b\u4e00\u81f4\u6027\u3002", "method": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u571f\u8033\u5176\u8bed\u81ea\u6740\u610f\u5ff5\u8bed\u6599\u5e93\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u4eba\u5de5\u6807\u6ce8\u8005\u548c\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8d44\u6e90\u9ad8\u6548\u6807\u6ce8\u6846\u67b6\u3002\u968f\u540e\uff0c\u7814\u7a76\u8005\u901a\u8fc7\u516b\u4e2a\u9884\u8bad\u7ec3\u7684\u60c5\u611f\u548c\u60c5\u7eea\u5206\u7c7b\u5668\u8fdb\u884c\u4e86\u8fc1\u79fb\u5b66\u4e60\uff0c\u5bf9\u8be5\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u6d41\u884c\u7684\u82f1\u8bed\u81ea\u6740\u610f\u5ff5\u68c0\u6d4b\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u53cc\u5411\u8bc4\u4f30\uff0c\u4ee5\u68c0\u9a8c\u6807\u7b7e\u53ef\u9760\u6027\u548c\u6a21\u578b\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u91c7\u7528\u66f4\u4e25\u683c\u3001\u66f4\u5177\u5305\u5bb9\u6027\u7684\u8bed\u8a00\u6807\u6ce8\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6d41\u884c\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u9760\u6027\u5b58\u5728\u7591\u95ee\u3002\u7814\u7a76\u8005\u4e3b\u5f20\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u63d0\u9ad8\u6a21\u578b\u8bad\u7ec3\u548c\u6570\u636e\u96c6\u6784\u5efa\u7684\u900f\u660e\u5ea6\uff0c\u5e76\u4f18\u5148\u8003\u8651\u6570\u636e\u548c\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u91c7\u7528\u66f4\u4e25\u683c\u3001\u66f4\u5177\u5305\u5bb9\u6027\u7684\u8bed\u8a00\u6807\u6ce8\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u6d41\u884c\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u9760\u6027\u5b58\u5728\u7591\u95ee\u3002\u7814\u7a76\u8005\u4e3b\u5f20\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u63d0\u9ad8\u6a21\u578b\u8bad\u7ec3\u548c\u6570\u636e\u96c6\u6784\u5efa\u7684\u900f\u660e\u5ea6\uff0c\u5e76\u4f18\u5148\u8003\u8651\u6570\u636e\u548c\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14195", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14195", "abs": "https://arxiv.org/abs/2507.14195", "authors": ["Elzbieta Gruzewska", "Pooja Rao", "Sebastien Baur", "Matthew Baugh", "Mathias M. J. Bellaiche", "Sharanya Srinivas", "Octavio Ponce", "Matthew Thompson", "Pramod Rudrapatna", "Michael A. Sanchez", "Lawrence Z. Cai", "Timothy JA Chico", "Robert F. Storey", "Emily Maz", "Umesh Telang", "Shravya Shetty", "Mayank Daswani"], "title": "UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach", "comment": "31 pages, 11 tables, 9 figures, 14 supplementary tables, 4\n  supplementary figures", "summary": "Radar technology presents untapped potential for continuous, contactless, and\npassive heart rate monitoring via consumer electronics like mobile phones.\nHowever the variety of available radar systems and lack of standardization\nmeans that a large new paired dataset collection is required for each radar\nsystem. This study demonstrates transfer learning between frequency-modulated\ncontinuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems,\nboth increasingly integrated into consumer devices. FMCW radar utilizes a\ncontinuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW\nradar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3\nreceiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz\nbandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we\nachieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage\nerror (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119\nparticipants, an average of 8 hours per participant). This model maintained\nperformance (under 5 MAE/10% MAPE) across various body positions and heart rate\nranges, with a 98.9% recall. We then fine-tuned a variant of this model,\ntrained on single-antenna and single-range bin FMCW data, using a small (N=376,\navg 6 minutes per participant) IR-UWB dataset. This transfer learning approach\nyielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE\nreduction over the IR-UWB baseline. This demonstration of transfer learning\nbetween radar systems for heart rate monitoring has the potential to accelerate\nits introduction into existing consumer devices.", "AI": {"tldr": "\u96f7\u8fbe\u5fc3\u7387\u76d1\u6d4b\u4e2d\u7684\u8fc1\u79fb\u5b66\u4e60\uff1a\u901a\u8fc7\u4f7f\u7528\u65b0\u9896\u7684ResNet\u67b6\u6784\u548c\u8fc1\u79fb\u5b66\u4e60\u6280\u672f\uff0c\u672c\u7814\u7a76\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u8de8\u4e0d\u540c\u96f7\u8fbe\u7cfb\u7edf\uff08FMCW\u548cIR-UWB\uff09\u7684\u5fc3\u7387\u76d1\u6d4b\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u6709\u671b\u52a0\u901f\u96f7\u8fbe\u6280\u672f\u5728\u6d88\u8d39\u7535\u5b50\u4ea7\u54c1\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e0d\u540c\u96f7\u8fbe\u7cfb\u7edf\u9700\u8981\u6536\u96c6\u65b0\u914d\u5bf9\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6f14\u793a\u4e0d\u540c\u96f7\u8fbe\u7cfb\u7edf\u4e4b\u95f4\u8fc1\u79fb\u5b66\u4e60\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u5b9e\u73b0\u8fde\u7eed\u3001\u975e\u63a5\u89e6\u3001\u88ab\u52a8\u7684\u5fc3\u7387\u76d1\u6d4b\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u9891\u7387\u8c03\u5236\u8fde\u7eed\u6ce2\uff08FMCW\uff09\u548c\u8109\u51b2\u8d85\u5bbd\u5e26\uff08IR-UWB\uff09\u96f7\u8fbe\u7cfb\u7edf\u4e4b\u95f4\u7684\u8fc1\u79fb\u5b66\u4e60\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e8c\u7ef4+\u4e00\u7ef4\u6b8b\u5dee\u795e\u7ecf\u7f51\u7edc\uff08ResNet\uff09\u67b6\u6784\u3002", "result": "\u5728FMCW\u96f7\u8fbe\u7cfb\u7edf\u4e0a\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e860.85 bpm\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u548c1.42%\u7684\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff08MAPE\uff09\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u7684\u8eab\u4f53\u4f4d\u7f6e\u548c\u5fc3\u7387\u8303\u56f4\u5185\u5747\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5c06\u8be5\u6a21\u578b\u8fc1\u79fb\u5230IR-UWB\u96f7\u8fbe\u7cfb\u7edf\uff0c\u5e76\u5728\u5c0f\u89c4\u6a21IR-UWB\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u53d6\u5f97\u4e86MAE 4.1 bpm\u548cMAPE 6.3%\u7684\u6027\u80fd\uff0c\u76f8\u6bd4\u4e8e\u57fa\u7ebf\u6a21\u578bMAE\u964d\u4f4e\u4e8625%\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u96f7\u8fbe\u7cfb\u7edf\u4e4b\u95f4\u5728\u5fc3\u7387\u76d1\u6d4b\u65b9\u9762\u53ef\u4ee5\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u6709\u6f5c\u529b\u52a0\u901f\u5176\u5728\u73b0\u6709\u6d88\u8d39\u8bbe\u5907\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.15484", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15484", "abs": "https://arxiv.org/abs/2507.15484", "authors": ["Jamie Bell"], "title": "Robots for Kiwifruit Harvesting and Pollination", "comment": null, "summary": "This research was a part of a project that developed mobile robots that\nperformed targeted pollen spraying and automated harvesting in pergola\nstructured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were\ndesigned and field testing of one of the concepts showed that the mechanism\ncould reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism\nwas able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,\nwhereas the previous state of the art mechanism was only able to reach less\nthan 70 percent of the fruit. Artificial pollination was performed by detecting\nflowers and then spraying pollen in solution onto the detected flowers from a\nline of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the\nheight of the canopy was measured and the spray boom was moved up and down to\nkeep the boom close enough to the flowers for the spray to reach the flowers,\nwhile minimising collisions with the canopy. Mobile robot navigation was\nperformed using a 2D lidar in apple orchards and vineyards. Lidar navigation in\nkiwifruit orchards was more challenging because the pergola structure only\nprovides a small amount of data for the direction of rows, compared to the\namount of data from the overhead canopy, the undulating ground and other\nobjects in the orchards. Multiple methods are presented here for extracting\nstructure defining features from 3D lidar data in kiwifruit orchards. In\naddition, a 3D lidar navigation system -- which performed row following, row\nend detection and row end turns -- was tested for over 30 km of autonomous\ndriving in kiwifruit orchards. Computer vision algorithms for row detection and\nrow following were also tested. The computer vision algorithm worked as well as\nthe 3D lidar row following method in testing.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u96c6\u6388\u7c89\u548c\u91c7\u6458\u529f\u80fd\u4e8e\u4e00\u4f53\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u7528\u4e8e\u68da\u67b6\u5f0f\u7315\u7334\u6843\u56ed\uff0c\u5e76\u89e3\u51b3\u4e86\u5bfc\u822a\u96be\u9898\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u7315\u7334\u6843\u79cd\u690d\u7684\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u514b\u670d\u5728\u68da\u67b6\u7ed3\u6784\u4e0b\u673a\u5668\u4eba\u5bfc\u822a\u548c\u4f5c\u4e1a\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u81ea\u52a8\u6388\u7c89\u548c\u91c7\u6458\u673a\u5668\u4eba\uff0c\u5305\u62ec\u8bbe\u8ba1\u548c\u6d4b\u8bd5\u7315\u7334\u6843\u91c7\u6458\u673a\u5236\u3001\u4f7f\u7528\u55b7\u6d12\u5668\u8fdb\u884c\u6388\u7c89\u3001\u901a\u8fc7\u6fc0\u5149\u96f7\u8fbe\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u8fdb\u884c\u5bfc\u822a\u3002", "result": "\u91c7\u6458\u673a\u5236\u80fd\u591f\u53ef\u9760\u5730\u91c7\u6458\u7315\u7334\u6843\uff0c\u53ef\u89e6\u53ca 80% \u4ee5\u4e0a\u7684\u679c\u5b9e\uff0c\u4f18\u4e8e\u5148\u524d\u6280\u672f\u3002\u6388\u7c89\u7cfb\u7edf\u80fd\u5728\u4e00\u5b9a\u901f\u5ea6\u4e0b\u8fdb\u884c\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u55b7\u6d12\u81c2\u9ad8\u5ea6\u6765\u4f18\u5316\u55b7\u6d12\u6548\u679c\u3002\u5728\u68da\u67b6\u7315\u7334\u6843\u56ed\u4e2d\u5f00\u53d1\u5e76\u6d4b\u8bd5\u4e86\u57fa\u4e8e 3D \u6fc0\u5149\u96f7\u8fbe\u7684\u5bfc\u822a\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc7 30 \u516c\u91cc\u7684\u81ea\u4e3b\u9a7e\u9a76\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u884c\u68c0\u6d4b\u548c\u8ddf\u968f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u7528\u4e8e\u7315\u7334\u6843\u7684\u81ea\u52a8\u5316\u519c\u827a\u4f5c\u4e1a\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5305\u62ec\u6388\u7c89\u548c\u91c7\u6458\uff0c\u5e76\u89e3\u51b3\u4e86\u5728\u7279\u5b9a\u68da\u67b6\u7ed3\u6784\u4e0b\u7684\u5bfc\u822a\u6311\u6218\u3002"}}
{"id": "2507.14596", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14596", "abs": "https://arxiv.org/abs/2507.14596", "authors": ["Doriand Petit", "Steve Bourgeois", "Vincent Gay-Bellile", "Florian Chabot", "Lo\u00efc Barthe"], "title": "DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF", "comment": "Published at ICCV'25", "summary": "3D semantic segmentation provides high-level scene understanding for\napplications in robotics, autonomous systems, \\textit{etc}. Traditional methods\nadapt exclusively to either task-specific goals (open-vocabulary segmentation)\nor scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the\nfirst method addressing the broader problem of 3D Open-Vocabulary Sub-concepts\nDiscovery, which aims to provide a 3D semantic segmentation that adapts to both\nthe scene and user queries. We build DiSCO-3D on Neural Fields representations,\ncombining unsupervised segmentation with weak open-vocabulary guidance. Our\nevaluations demonstrate that DiSCO-3D achieves effective performance in\nOpen-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in\nthe edge cases of both open-vocabulary and unsupervised segmentation.", "AI": {"tldr": "DiSCO-3D\u662f\u7b2c\u4e00\u4e2a\u89e3\u51b33D\u5f00\u653e\u8bcd\u6c47\u5b50\u6982\u5ff5\u53d1\u73b0\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5b83\u80fd\u540c\u65f6\u9002\u5e94\u573a\u666f\u548c\u7528\u6237\u67e5\u8be2\uff0c\u5e76\u5728\u5404\u79cd\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b33D\u5f00\u653e\u8bcd\u6c47\u5b50\u6982\u5ff5\u53d1\u73b0\u7684\u66f4\u5e7f\u6cdb\u95ee\u9898\uff0c\u65e8\u5728\u540c\u65f6\u9002\u5e94\u573a\u666f\u548c\u7528\u6237\u67e5\u8be2\u76843D\u8bed\u4e49\u5206\u5272\u3002", "method": "DiSCO-3D\u57fa\u4e8e\u795e\u7ecf\u573a\u8868\u793a\uff0c\u7ed3\u5408\u4e86\u65e0\u76d1\u7763\u5206\u5272\u548c\u5f31\u5f00\u653e\u8bcd\u6c47\u5f15\u5bfc\u3002", "result": "DiSCO-3D\u57283D\u5f00\u653e\u8bcd\u6c47\u5b50\u6982\u5ff5\u53d1\u73b0\u65b9\u9762\u5b9e\u73b0\u4e86\u6709\u6548\u6027\u80fd\uff0c\u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u65e0\u76d1\u7763\u5206\u5272\u7684\u8fb9\u7f18\u60c5\u51b5\u4e0b\u5c55\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "DiSCO-3D\u57283D\u5f00\u653e\u8bcd\u6c47\u5b50\u6982\u5ff5\u53d1\u73b0\u65b9\u9762\u5b9e\u73b0\u4e86\u6709\u6548\u6027\u80fd\uff0c\u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u65e0\u76d1\u7763\u5206\u5272\u7684\u8fb9\u7f18\u60c5\u51b5\u4e0b\u5c55\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.15106", "categories": ["cs.AI", "cs.RO", "F.2.2"], "pdf": "https://arxiv.org/pdf/2507.15106", "abs": "https://arxiv.org/abs/2507.15106", "authors": ["Xia Xu", "Jochen Triesch"], "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward", "comment": "13 pages, 5 figures", "summary": "While human infants robustly discover their own causal efficacy, standard\nreinforcement learning agents remain brittle, as their reliance on\ncorrelation-based rewards fails in noisy, ecologically valid scenarios. To\naddress this, we introduce the Causal Action Influence Score (CAIS), a novel\nintrinsic reward rooted in causal inference. CAIS quantifies an action's\ninfluence by measuring the 1-Wasserstein distance between the learned\ndistribution of sensory outcomes conditional on that action, $p(h|a)$, and the\nbaseline outcome distribution, $p(h)$. This divergence provides a robust reward\nthat isolates the agent's causal impact from confounding environmental noise.\nWe test our approach in a simulated infant-mobile environment where\ncorrelation-based perceptual rewards fail completely when the mobile is\nsubjected to external forces. In stark contrast, CAIS enables the agent to\nfilter this noise, identify its influence, and learn the correct policy.\nFurthermore, the high-quality predictive model learned for CAIS allows our\nagent, when augmented with a surprise signal, to successfully reproduce the\n\"extinction burst\" phenomenon. We conclude that explicitly inferring causality\nis a crucial mechanism for developing a robust sense of agency, offering a\npsychologically plausible framework for more adaptive autonomous systems.", "AI": {"tldr": "CAIS \u662f\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u5956\u52b1\uff0c\u53ef\u5e2e\u52a9 RL \u4ee3\u7406\u5728\u5608\u6742\u7684\u73af\u5883\u4e2d\u5b66\u4e60\uff0c\u91cd\u73b0\u201c\u6d88\u9000\u7206\u53d1\u201d\u73b0\u8c61\u3002", "motivation": "\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4ecd\u7136\u8106\u5f31\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5956\u52b1\u7684\u4f9d\u8d56\u5728\u5608\u6742\u3001\u751f\u6001\u6709\u6548\u7684\u573a\u666f\u4e2d\u4f1a\u5931\u8d25\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u56e0\u679c\u884c\u52a8\u5f71\u54cd\u5f97\u5206\uff08CAIS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u65b0\u9896\u5185\u5728\u5956\u52b1\u3002CAIS \u901a\u8fc7\u8861\u91cf\u5b66\u4e60\u5230\u7684\u611f\u5b98\u7ed3\u679c\u5206\u5e03\uff08\u4ee5\u8be5\u884c\u52a8\u4e3a\u6761\u4ef6\uff09$p(h|a)$ \u4e0e\u57fa\u7ebf\u7ed3\u679c\u5206\u5e03$p(h)$\u4e4b\u95f4\u7684 1-Wasserstein \u8ddd\u79bb\u6765\u91cf\u5316\u884c\u52a8\u7684\u5f71\u54cd\u3002", "result": "CAIS \u4f7f\u4ee3\u7406\u80fd\u591f\u8fc7\u6ee4\u566a\u58f0\u3001\u8bc6\u522b\u5176\u5f71\u54cd\u5e76\u5b66\u4e60\u6b63\u786e\u7684\u7b56\u7565\uff0c\u5e76\u6210\u529f\u91cd\u73b0\u201c\u6d88\u9000\u7206\u53d1\u201d\u73b0\u8c61\u3002", "conclusion": "\u56e0\u679c\u63a8\u7406\u662f\u5f00\u53d1\u7a33\u5065\u7684\u4ee3\u7406\u611f\u7684\u91cd\u8981\u673a\u5236\uff0c\u4e3a\u66f4\u5177\u9002\u5e94\u6027\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc3\u7406\u5b66\u4e0a\u5408\u7406\u7684\u6846\u67b6\u3002"}}
{"id": "2507.14492", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14492", "abs": "https://arxiv.org/abs/2507.14492", "authors": ["Satyankar Chandra", "Ashutosh Gupta", "Kaushik Mallik", "Krishna Shankaranarayanan", "Namrita Varshney"], "title": "Glitches in Decision Tree Ensemble Models", "comment": null, "summary": "Many critical decision-making tasks are now delegated to machine-learned\nmodels, and it is imperative that their decisions are trustworthy and reliable,\nand their outputs are consistent across similar inputs. We identify a new\nsource of unreliable behaviors-called glitches-which may significantly impair\nthe reliability of AI models having steep decision boundaries. Roughly\nspeaking, glitches are small neighborhoods in the input space where the model's\noutput abruptly oscillates with respect to small changes in the input. We\nprovide a formal definition of glitches, and use well-known models and datasets\nfrom the literature to demonstrate that they have widespread existence and\nargue they usually indicate potential model inconsistencies in the neighborhood\nof where they are found. We proceed to the algorithmic search of glitches for\nwidely used gradient-boosted decision tree (GBDT) models. We prove that the\nproblem of detecting glitches is NP-complete for tree ensembles, already for\ntrees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP\nencoding of the problem, and its effectiveness and computational feasibility\nare demonstrated on a set of widely used GBDT benchmarks taken from the\nliterature.", "AI": {"tldr": "AI \u6a21\u578b\u4e2d\u7684\u201cglitches\u201d\uff08\u8f93\u5165\u7a7a\u95f4\u4e2d\u7684\u5c0f\u90bb\u57df\uff0c\u6a21\u578b\u7684\u8f93\u51fa\u4f1a\u968f\u7740\u8f93\u5165\u7684\u5fae\u5c0f\u53d8\u5316\u800c\u5267\u70c8\u632f\u8361\uff09\u662f\u4e0d\u53ef\u9760\u884c\u4e3a\u7684\u65b0\u6765\u6e90\u3002\u8be5\u7814\u7a76\u4e3a glitches \u63d0\u4f9b\u4e86\u6b63\u5f0f\u5b9a\u4e49\uff0c\u8bc1\u660e\u4e86\u5b83\u4eec\u5e7f\u6cdb\u5b58\u5728\u4e8e GBDT \u6a21\u578b\u4e2d\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e MILP \u7684\u641c\u7d22\u7b97\u6cd5\uff0c\u8bc1\u660e\u8be5\u95ee\u9898\u662f NP \u5b8c\u5907\u7684\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u952e\u51b3\u7b56\u4efb\u52a1\u59d4\u6258\u7ed9\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u786e\u4fdd\u8fd9\u4e9b\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\u3002\u8be5\u7814\u7a76\u65e8\u5728\u8bc6\u522b\u548c\u89e3\u51b3\u5bfc\u81f4\u6a21\u578b\u4e0d\u53ef\u9760\u884c\u4e3a\u7684\u65b0\u578b\u6765\u6e90\uff0c\u5373\u201cglitches\u201d\uff0c\u4ee5\u63d0\u9ad8 AI \u51b3\u7b56\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 glitch \u68c0\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86 glitch \u68c0\u6d4b\u5bf9\u4e8e\u6811\u6df1\u5ea6\u4e3a 4 \u7684\u6811\u96c6\u6210\u6765\u8bf4\u662f NP \u5b8c\u5907\u7684\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e GBDT \u6a21\u578b\u7684 glitch \u641c\u7d22\u7b97\u6cd5\uff0c\u5e76\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5bf9\u5176\u6709\u6548\u6027\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cglitches \u5728\u5177\u6709\u9661\u5ced\u51b3\u7b56\u8fb9\u754c\u7684 AI \u6a21\u578b\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5e76\u4e14\u901a\u5e38\u8868\u660e\u6a21\u578b\u5728 glitches \u9644\u8fd1\u7684\u90bb\u57df\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u3002\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u7684 glitch \u641c\u7d22\u7b97\u6cd5\u5728 GBDT \u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u6709\u6548\u4e14\u8ba1\u7b97\u4e0a\u53ef\u884c\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc6\u522b\u51fa\u4e00\u79cd\u540d\u4e3a\u201cglitches\u201d\u7684\u65b0\u578b\u4e0d\u53ef\u9760\u884c\u4e3a\uff0c\u5b83\u4f1a\u4e25\u91cd\u5f71\u54cd\u5177\u6709\u9661\u5ced\u51b3\u7b56\u8fb9\u754c\u7684 AI \u6a21\u578b\u3002\u8be5\u7814\u7a76\u4e3a glitches \u63d0\u4f9b\u4e86\u6b63\u5f0f\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86 glitches \u7684\u5e7f\u6cdb\u5b58\u5728\uff0c\u5e76\u8ba4\u4e3a\u5b83\u4eec\u901a\u5e38\u8868\u660e\u6a21\u578b\u5728 glitches \u9644\u8fd1\u5b58\u5728\u6f5c\u5728\u7684\u4e0d\u4e00\u81f4\u6027\u3002\u6700\u540e\uff0c\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e GBDT \u6a21\u578b\u7684 glitches \u641c\u7d22\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u7684 NP \u5b8c\u5907\u6027\u3002"}}
{"id": "2507.15447", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15447", "abs": "https://arxiv.org/abs/2507.15447", "authors": ["Sudeepta Mukherjee", "Hemant Kumar", "B. S. Murty", "Satyam Suwas", "Surendra Kumar Makineni"], "title": "Effect of Co partitioning to the \u03b3 matrix on the microstructural stablity of a Ti-rich Ni-Base Superalloy", "comment": null, "summary": "The microstructural stability and mechanical properties of superalloys at\nhigh temperatures are significantly influenced by the composition and nature of\nthe solutes they contain. Most of the alloys with high solvus temperature have\nhigher gamma prime coarsening resistance, while the larger lattice misfit is\nattributed to higher gamma prime coarsening rate. In this work, we explore the\ninfluence of Co on the microstructure evolution, thermophysical/mechanical\nproperties and gamma prime precipitate coarsening kinetics in a Ti-rich\nNi-Co-Cr-Al-Ti based alloy. More specifically, we focus on the effect of\npartitioning of Co into the gamma matrix on the redistribution of other solutes\nacross the interface. We observe a significant increase in the coarsening\nresistance and a twofold increase in the activation energy with the increase in\nthe Co composition from 10at.%Co to 30at.%Co, even though the gamma prime\nsolvus reduces by 75C. As otherwise, a higher solvus, usually, indicates better\nmicrostructural stability at high temperatures. We employed a combined\nexperimental and theoretical approach by atom probe tomography (APT) and\nCALPHAD simulations to probe the critical role of Co partitioning to gamma\nmatrix on the solute transport in the gamma matrix and flux across the\ngamma/gamma prime interfaces, which is found to control the overall gamma prime\ncoarsening behavior in the alloy. The observed behavior was rationlised by the\nproposition of a simplistic unified coarsening rate expression that\nsuccessfully decouples thermodynamic and kinetic contributions. Additionally,\nwe also observe that the gamma prime volume fraction dominates over the gamma\nprime precipitate size on the 0.2% yield strength (YS) of the alloys.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u5728Ti\u542b\u91cf\u9ad8\u7684Ni-Co-Cr-Al-Ti\u57fa\u9ad8\u6e29\u5408\u91d1\u4e2d\uff0c\u589e\u52a0\u94b4\uff08Co\uff09\u542b\u91cf\u53ef\u663e\u8457\u63d0\u9ad8\u7c97\u5316\u6297\u6027\u548c\u6d3b\u5316\u80fd\uff0c\u5c3d\u7ba1\u4f1a\u964d\u4f4e\u03b3'\u56fa\u6eb6\u7ebf\u3002\u901a\u8fc7APT\u548cCALPHAD\u6a21\u62df\u53d1\u73b0\uff0c\u94b4\u5411\u03b3\u57fa\u4f53\u504f\u6790\u662f\u63a7\u5236\u03b3'\u7c97\u5316\u7684\u5173\u952e\u3002\u7814\u7a76\u8fd8\u6307\u51fa\uff0c\u03b3'\u76f8\u4f53\u79ef\u5206\u6570\u5bf9\u5408\u91d1\u5c48\u670d\u5f3a\u5ea6\u7684\u5f71\u54cd\u6bd4\u6790\u51fa\u7269\u5c3a\u5bf8\u66f4\u91cd\u8981\u3002", "motivation": "\u9ad8\u6e29\u4e0b\u8fc7 \u0985\u09aa\u09b0 alloy \u7684\u663e\u5fae\u7ed3\u6784\u7a33\u5b9a\u6027\u548c\u529b\u5b66\u6027\u80fd\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d7\u5176\u7ec4\u5206\u548c\u6eb6\u8d28\u6027\u8d28\u7684\u5f71\u54cd\u3002\u901a\u5e38\uff0c\u5177\u6709\u66f4\u9ad8\u56fa\u6eb6\u7ebf\u6e29\u5ea6\u7684\u5408\u91d1\u5177\u6709\u66f4\u597d\u7684\u03b3'\u7c97\u5316\u6297\u6027\uff0c\u4f46\u66f4\u5927\u7684\u6676\u683c\u9519\u914d\u4f1a\u52a0\u901f\u03b3'\u7c97\u5316\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u94b4\uff08Co\uff09\u5143\u7d20\u5bf9Ti\u542b\u91cf\u9ad8\u7684Ni-Co-Cr-Al-Ti\u57fa\u5408\u91d1\u7684\u5fae\u89c2\u7ed3\u6784\u6f14\u53d8\u3001\u70ed\u7269\u7406/\u673a\u68b0\u6027\u80fd\u548c\u03b3'\u6790\u51fa\u7269\u7c97\u5316\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u94b4\u5411\u03b3\u57fa\u4f53\u504f\u6790\u5bf9\u6eb6\u8d28\u518d\u5206\u914d\u548c\u7c97\u5316\u884c\u4e3a\u7684\u63a7\u5236\u4f5c\u7528\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u5b9e\u9a8c\u4e0e\u7406\u8bba\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u539f\u5b50\u63a2\u9488\u65ad\u5c42\u626b\u63cf\uff08APT\uff09\u548cCALPHAD\u6a21\u62df\uff0c\u4ee5\u63a2\u7d22\u94b4\uff08Co\uff09\u5bf9Ti\u542b\u91cf\u9ad8\u7684Ni-Co-Cr-Al-Ti\u57fa\u5408\u91d1\u7684\u5fae\u89c2\u7ed3\u6784\u6f14\u53d8\u3001\u70ed\u7269\u7406/\u673a\u68b0\u6027\u80fd\u4ee5\u53ca\u03b3'\u6790\u51fa\u7269\u7c97\u5316\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u94b4\u5411\u03b3\u57fa\u4f53\u504f\u6790\u5bf9\u5176\u4ed6\u6eb6\u8d28\u5728\u754c\u9762\u91cd\u65b0\u5206\u5e03\u7684\u5f71\u54cd\u3002", "result": "\u968f\u7740Co\u542b\u91cf\u4ece10at.%\u589e\u52a0\u523030at.%\uff0c\u5408\u91d1\u7684\u7c97\u5316\u6297\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u6d3b\u5316\u80fd\u52a0\u500d\uff0c\u5c3d\u7ba1\u03b3'\u56fa\u6eb6\u7ebf\u964d\u4f4e\u4e8675\u00b0C\u3002\u94b4\u5411\u03b3\u57fa\u4f53\u504f\u6790\u5bf9\u03b3\u57fa\u4f53\u4e2d\u7684\u6eb6\u8d28\u4f20\u8f93\u4ee5\u53ca\u8de8\u8d8a\u03b3/\u03b3'\u754c\u9762\u7684\u6eb6\u8d28\u901a\u91cf\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4ece\u800c\u63a7\u5236\u4e86\u6574\u4f53\u7684\u03b3'\u7c97\u5316\u884c\u4e3a\u3002\u6b64\u5916\uff0c\u03b3'\u76f8\u4f53\u79ef\u5206\u6570\u5bf9\u5408\u91d1\u76840.2%\u5c48\u670d\u5f3a\u5ea6\u7684\u5f71\u54cd\u5927\u4e8e\u03b3'\u6790\u51fa\u7269\u7684\u5c3a\u5bf8\u3002", "conclusion": "\u94b4\u5143\u7d20\u5728\u954d\u94b4\u94ec\u94dd\u949b\u57fa\u9ad8\u6e29\u5408\u91d1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u7c97\u5316\u6297\u6027\uff0c\u5e76\u4f7f\u6d3b\u5316\u80fd\u52a0\u500d\uff0c\u5c3d\u7ba1\u5176\u03b3'\u56fa\u6eb6\u7ebf\u5c06\u964d\u4f4e75\u00b0C\u3002\u8be5\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u539f\u5b50\u63a2\u9488\u65ad\u5c42\u626b\u63cf\u548cCALPHAD\u6a21\u62df\uff0c\u63ed\u793a\u4e86\u94b4\u5411\u03b3\u57fa\u4f53\u504f\u6790\u5bf9\u6eb6\u8d28\u5728\u03b3\u57fa\u4f53\u4e2d\u518d\u5206\u5e03\u548c\u8de8\u8d8a\u03b3/\u03b3'\u754c\u9762\u7684\u6eb6\u8d28\u901a\u91cf\u7684\u5f71\u54cd\uff0c\u8fdb\u800c\u63a7\u5236\u4e86\u03b3'\u7c97\u5316\u884c\u4e3a\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\u03b3'\u76f8\u4f53\u79ef\u5206\u6570\u6bd4\u03b3'\u6790\u51fa\u7269\u5c3a\u5bf8\u5bf9\u5408\u91d1\u76840.2%\u5c48\u670d\u5f3a\u5ea6\u6709\u66f4\u5927\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.15708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15708", "abs": "https://arxiv.org/abs/2507.15708", "authors": ["Niloofar Nobahari", "Alireza Rezaee"], "title": "Reliability-Based Fault Analysis and Modeling of Satellite Electrical Power Subsystems Using Fault Tree and Simulation Tools", "comment": null, "summary": "One of the most important satellite subsystems is its electric power\nsubsystem. The occurrence of a fault in the satellite power system causes the\nfailure of all or part of the satellite. Calculating the overall reliability of\nthe power system before the mission is crucial in improving the design of the\nsatellite power system. Each component of the power system may malfunction due\nto pressure, launch pressure, and operating conditions. Accordingly, in this\npaper, first, a healthy and faulty system for the components of the electrical\npower system is simulated with MATLAB. Finally, by drawing a fault tree to\nanalyze the reliability of the power subsystem, overall mission reliability,\npower system fault rate, and overall fault rate of the mission are calculated\nby Windchill software. Finally, a total mission assurance of 0.999 was\nachieved, indicating the high reliability of the simulated system.", "AI": {"tldr": "\u5bf9\u536b\u661f\u7535\u529b\u7cfb\u7edf\u8fdb\u884c\u4e86\u4eff\u771f\u548c\u6545\u969c\u6811\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u536b\u661f\u4e2d\u7684\u7535\u529b\u5b50\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u5176\u6545\u969c\u4f1a\u5bfc\u81f4\u536b\u661f\u90e8\u5206\u6216\u5168\u90e8\u5931\u6548\u3002\u56e0\u6b64\uff0c\u5728\u4efb\u52a1\u524d\u8ba1\u7b97\u7535\u529b\u7cfb\u7edf\u7684\u6574\u4f53\u53ef\u9760\u6027\u5bf9\u4e8e\u6539\u8fdb\u536b\u661f\u7535\u529b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u7535\u529b\u7cfb\u7edf\u7684\u7ec4\u4ef6\u53ef\u80fd\u56e0\u538b\u529b\u3001\u53d1\u5c04\u538b\u529b\u548c\u64cd\u4f5c\u6761\u4ef6\u800c\u53d1\u751f\u6545\u969c\u3002", "method": "\u9996\u5148\uff0c\u4f7f\u7528MATLAB\u5bf9\u7535\u529b\u7cfb\u7edf\u7ec4\u4ef6\u7684\u5065\u5eb7\u548c\u6545\u969c\u7cfb\u7edf\u8fdb\u884c\u4eff\u771f\u3002\u7136\u540e\uff0c\u901a\u8fc7\u7ed8\u5236\u6545\u969c\u6811\u6765\u5206\u6790\u7535\u529b\u5b50\u7cfb\u7edf\u7684\u53ef\u9760\u6027\uff0c\u5e76\u4f7f\u7528Windchill\u8f6f\u4ef6\u8ba1\u7b97\u4efb\u52a1\u7684\u6574\u4f53\u53ef\u9760\u6027\u3001\u7535\u529b\u7cfb\u7edf\u7684\u6545\u969c\u7387\u548c\u4efb\u52a1\u7684\u6574\u4f53\u6545\u969c\u7387\u3002", "result": "\u4eff\u771f\u7cfb\u7edf\u8fbe\u5230\u4e860.999\u7684\u4efb\u52a1\u4fdd\u8bc1\u5ea6\uff0c\u8868\u660e\u5176\u5177\u6709\u9ad8\u53ef\u9760\u6027\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u7535\u529b\u7cfb\u7edf\u8fdb\u884c\u5efa\u6a21\u548c\u4eff\u771f\uff0c\u5e76\u7ed8\u5236\u6545\u969c\u6811\u8fdb\u884c\u53ef\u9760\u6027\u5206\u6790\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e860.999\u7684\u4efb\u52a1\u4fdd\u8bc1\u5ea6\uff0c\u8868\u660e\u4e86\u4eff\u771f\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14741", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14741", "abs": "https://arxiv.org/abs/2507.14741", "authors": ["Maria Sahakyan", "Bedoor AlShebli"], "title": "Disparities in Peer Review Tone and the Role of Reviewer Anonymity", "comment": null, "summary": "The peer review process is often regarded as the gatekeeper of scientific\nintegrity, yet increasing evidence suggests that it is not immune to bias.\nAlthough structural inequities in peer review have been widely debated, much\nless attention has been paid to the subtle ways in which language itself may\nreinforce disparities. This study undertakes one of the most comprehensive\nlinguistic analyses of peer review to date, examining more than 80,000 reviews\nin two major journals. Using natural language processing and large-scale\nstatistical modeling, it uncovers how review tone, sentiment, and supportive\nlanguage vary across author demographics, including gender, race, and\ninstitutional affiliation. Using a data set that includes both anonymous and\nsigned reviews, this research also reveals how the disclosure of reviewer\nidentity shapes the language of evaluation. The findings not only expose hidden\nbiases in peer feedback, but also challenge conventional assumptions about\nanonymity's role in fairness. As academic publishing grapples with reform,\nthese insights raise critical questions about how review policies shape career\ntrajectories and scientific progress.", "AI": {"tldr": "\u4e00\u9879\u9488\u5bf980,000\u591a\u4efd\u540c\u884c\u8bc4\u5ba1\u62a5\u544a\u7684\u8bed\u8a00\u5206\u6790\u663e\u793a\uff0c\u5ba1\u7a3f\u4e2d\u5b58\u5728\u57fa\u4e8e\u4f5c\u8005\u6027\u522b\u3001\u79cd\u65cf\u548c\u673a\u6784\u7684\u504f\u89c1\uff0c\u533f\u540d\u8bc4\u5ba1\u7684\u516c\u5e73\u6027\u4e5f\u53d7\u5230\u8d28\u7591\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u8bed\u8a00\u53ef\u80fd\u5b58\u5728\u7684\u5fae\u5999\u504f\u89c1\uff0c\u4ee5\u63ed\u793a\u5176\u5982\u4f55\u52a0\u5267\u79d1\u5b66\u9886\u57df\u7684\u4e0d\u5e73\u7b49\u73b0\u8c61\uff0c\u5e76\u6311\u6218\u5173\u4e8e\u533f\u540d\u8bc4\u5ba1\u516c\u5e73\u6027\u7684\u4f20\u7edf\u89c2\u5ff5\u3002", "method": "\u7814\u7a76\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u89c4\u6a21\u7edf\u8ba1\u5efa\u6a21\uff0c\u5206\u6790\u4e86\u4e24\u4e2a\u4e3b\u8981\u671f\u520a\u4e2d\u8d85\u8fc780,000\u4efd\u540c\u884c\u8bc4\u5ba1\u62a5\u544a\uff0c\u8003\u5bdf\u4e86\u5305\u62ec\u6027\u522b\u3001\u79cd\u65cf\u548c\u673a\u6784\u5f52\u5c5e\u5728\u5185\u7684\u4f5c\u8005\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5728\u5ba1\u7a3f\u8bed\u6c14\u3001\u60c5\u611f\u548c\u652f\u6301\u6027\u8bed\u8a00\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u4e86\u5ba1\u7a3f\u4eba\u8eab\u4efd\u62ab\u9732\u5bf9\u8bc4\u5ba1\u8bed\u8a00\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5ba1\u7a3f\u7684\u8bed\u6c14\u3001\u60c5\u611f\u548c\u652f\u6301\u6027\u8bed\u8a00\u56e0\u4f5c\u8005\u7684\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\uff08\u5305\u62ec\u6027\u522b\u3001\u79cd\u65cf\u548c\u673a\u6784\u5f52\u5c5e\uff09\u800c\u5f02\u3002\u6b64\u5916\uff0c\u5ba1\u7a3f\u4eba\u8eab\u4efd\u7684\u62ab\u9732\u4e5f\u4f1a\u5f71\u54cd\u8bc4\u5ba1\u8bed\u8a00\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u9690\u85cf\u504f\u89c1\uff0c\u5e76\u5bf9\u533f\u540d\u8bc4\u5ba1\u7684\u516c\u5e73\u6027\u63d0\u51fa\u4e86\u8d28\u7591\uff0c\u5f3a\u8c03\u4e86\u5ba1\u67e5\u653f\u7b56\u5bf9\u5b66\u672f\u51fa\u7248\u548c\u79d1\u5b66\u8fdb\u6b65\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.14196", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14196", "abs": "https://arxiv.org/abs/2507.14196", "authors": ["Zahra Teimouri-Jervekani", "Fahimeh Nasimi", "Mohammadreza Yazdchi", "Ghazal MogharehZadeh", "Javad Tezerji", "Farzan Niknejad Mazandarani", "Maryam Mohebbi"], "title": "Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs", "comment": null, "summary": "Background and Objective: Differentiating wide complex tachycardia (WCT) is\nclinically critical yet challenging due to morphological similarities in\nelectrocardiogram (ECG) signals between life-threatening ventricular\ntachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A).\nMisdiagnosis carries fatal risks. We propose a computationally efficient deep\nlearning solution to improve diagnostic accuracy and provide model\ninterpretability for clinical deployment.\n  Methods: A novel lightweight parallel deep architecture is introduced. Each\npipeline processes individual ECG leads using two 1D-CNN blocks to extract\nlocal features. Feature maps are concatenated across leads, followed by LSTM\nlayers to capture temporal dependencies. Final classification employs fully\nconnected layers. Explainability is achieved via Shapley Additive Explanations\n(SHAP) for local/global interpretation. The model was evaluated on a 35-subject\nECG database using standard performance metrics.\n  Results: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$),\nwith sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It\noutperformed state-of-the-art methods in both accuracy and computational\nefficiency, requiring minimal CNN blocks per pipeline. SHAP analysis\ndemonstrated clinically interpretable feature contributions.\n  Conclusions: Our end-to-end framework delivers high-precision WCT\nclassification with minimal computational overhead. The integration of SHAP\nenhances clinical trust by elucidating decision logic, supporting rapid,\ninformed diagnosis. This approach shows significant promise for real-world ECG\nanalysis tools.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u4f7f\u7528CNN\u548cLSTM\u6765\u533a\u5206\u5fc3\u52a8\u8fc7\u901f\u7c7b\u578b\uff0c\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u5e76\u4e14\u901a\u8fc7SHAP\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u9274\u522b\u5bbdQRS\u6ce2\u5fc3\u52a8\u8fc7\u901f\uff08WCT\uff09\u5728\u4e34\u5e8a\u4e0a\u81f3\u5173\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5371\u53ca\u751f\u547d\u7684\u5fc3\u5ba4\u5fc3\u52a8\u8fc7\u901f\uff08VT\uff09\u548c\u5177\u6709\u4ee3\u507f\u6027\u8054\u5f8b\u7684\u5ba4\u4e0a\u6027\u5fc3\u52a8\u8fc7\u901f\uff08SVT-A\uff09\u4e4b\u95f4\u7684\u5fc3\u7535\u56fe\uff08ECG\uff09\u4fe1\u53f7\u5b58\u5728\u5f62\u6001\u5b66\u76f8\u4f3c\u6027\u3002\u8bef\u8bca\u53ef\u80fd\u5bfc\u81f4\u81f4\u547d\u98ce\u9669\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u5e76\u4e3a\u4e34\u5e8a\u90e8\u7f72\u63d0\u4f9b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8f7b\u91cf\u7ea7\u5e76\u884c\u6df1\u5ea6\u67b6\u6784\u3002\u6bcf\u4e2a\u7ba1\u9053\u4f7f\u7528\u4e24\u4e2a1D-CNN\u5757\u5904\u7406\u5355\u4e2aECG\u5bfc\u8054\u4ee5\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\u3002\u7279\u5f81\u56fe\u8de8\u5bfc\u8054\u8fde\u63a5\uff0c\u7136\u540e\u4f7f\u7528LSTM\u5c42\u6355\u83b7\u65f6\u95f4\u4f9d\u8d56\u6027\u3002\u6700\u7ec8\u5206\u7c7b\u91c7\u7528\u5168\u8fde\u63a5\u5c42\u3002\u901a\u8fc7Shapley Additive Explanations\uff08SHAP\uff09\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u7528\u4e8e\u5c40\u90e8/\u5168\u5c40\u89e3\u91ca\u3002\u6a21\u578b\u572835\u540d\u53d7\u8bd5\u8005\u7684ECG\u6570\u636e\u5e93\u4e0a\u4f7f\u7528\u6807\u51c6\u6027\u80fd\u6307\u6807\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5b9e\u73b0\u4e8695.63%\u7684\u51c6\u786e\u7387\uff0895%\u7f6e\u4fe1\u533a\u95f4\uff1a93.07-98.19%\uff09\uff0c\u654f\u611f\u6027=95.10%\uff0c\u7279\u5f02\u6027=96.06%\uff0cF1\u5206\u6570=95.12%\u3002\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u7ba1\u9053\u6240\u9700\u7684CNN\u5757\u6700\u5c11\u3002SHAP\u5206\u6790\u8bc1\u660e\u4e86\u5177\u6709\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u7684\u7279\u5f81\u8d21\u732e\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u7cbe\u5ea6\u5730\u533a\u5206\u5bbdQRS\u6ce2\u5fc3\u52a8\u8fc7\u901f\uff08WCT\uff09\uff0c\u540c\u65f6\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002SHAP\u7684\u96c6\u6210\u901a\u8fc7\u9610\u660e\u51b3\u7b56\u903b\u8f91\u589e\u5f3a\u4e86\u4e34\u5e8a\u4fe1\u4efb\u5ea6\uff0c\u652f\u6301\u5feb\u901f\u3001\u660e\u667a\u7684\u8bca\u65ad\u3002\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5fc3\u7535\u56fe\u5206\u6790\u5de5\u5177\u4e2d\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15493", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15493", "abs": "https://arxiv.org/abs/2507.15493", "authors": ["Chilam Cheang", "Sijin Chen", "Zhongren Cui", "Yingdong Hu", "Liqun Huang", "Tao Kong", "Hang Li", "Yifeng Li", "Yuxiao Liu", "Xiao Ma", "Hao Niu", "Wenxuan Ou", "Wanli Peng", "Zeyu Ren", "Haixin Shi", "Jiawen Tian", "Hongtao Wu", "Xin Xiao", "Yuyang Xiao", "Jiafeng Xu", "Yichu Yang"], "title": "GR-3 Technical Report", "comment": "Tech report. Authors are listed in alphabetical order. Project page:\n  https://seed.bytedance.com/GR3/", "summary": "We report our recent progress towards building generalist robot policies, the\ndevelopment of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.\nIt showcases exceptional capabilities in generalizing to novel objects,\nenvironments, and instructions involving abstract concepts. Furthermore, it can\nbe efficiently fine-tuned with minimal human trajectory data, enabling rapid\nand cost-effective adaptation to new settings. GR-3 also excels in handling\nlong-horizon and dexterous tasks, including those requiring bi-manual\nmanipulation and mobile movement, showcasing robust and reliable performance.\nThese capabilities are achieved through a multi-faceted training recipe that\nincludes co-training with web-scale vision-language data, efficient fine-tuning\nfrom human trajectory data collected via VR devices, and effective imitation\nlearning with robot trajectory data. In addition, we introduce ByteMini, a\nversatile bi-manual mobile robot designed with exceptional flexibility and\nreliability, capable of accomplishing a wide range of tasks when integrated\nwith GR-3. Through extensive real-world experiments, we show GR-3 surpasses the\nstate-of-the-art baseline method, $\\pi_0$, on a wide variety of challenging\ntasks. We hope GR-3 can serve as a step towards building generalist robots\ncapable of assisting humans in daily life.", "AI": {"tldr": "GR-3 \u662f\u4e00\u4e2a\u5927\u89c4\u6a21 VLA \u6a21\u578b\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u9002\u5e94\u65b0\u73af\u5883\u548c\u4efb\u52a1\uff0c\u5e76\u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u65e8\u5728\u6784\u5efa\u80fd\u591f\u534f\u52a9\u4eba\u7c7b\u65e5\u5e38\u751f\u6d3b\u7684\u4e00\u822c\u673a\u5668\u4eba\u7b56\u7565\u3002", "method": "GR-3 \u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8fdb\u884c\u8bad\u7ec3\uff1a\u4f7f\u7528\u7f51\u7edc\u89c4\u6a21\u7684\u89c6\u89c9-\u8bed\u8a00\u6570\u636e\u8fdb\u884c\u534f\u540c\u8bad\u7ec3\uff0c\u4f7f\u7528\u901a\u8fc7 VR \u8bbe\u5907\u6536\u96c6\u7684\u4eba\u7c7b\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u9ad8\u6548\u5fae\u8c03\uff0c\u4ee5\u53ca\u4f7f\u7528\u673a\u5668\u4eba\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u6709\u6548\u7684\u6a21\u4eff\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u591a\u529f\u80fd\u53cc\u81c2\u79fb\u52a8\u673a\u5668\u4eba ByteMini\u3002", "result": "GR-3 \u5728\u6cdb\u5316\u5230\u65b0\u9896\u7269\u4f53\u3001\u73af\u5883\u548c\u6d89\u53ca\u62bd\u8c61\u6982\u5ff5\u7684\u6307\u4ee4\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u80fd\u529b\u3002\u5b83\u8fd8\u53ef\u4ee5\u6709\u6548\u5730\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u80fd\u5904\u7406\u9700\u8981\u53cc\u81c2\u64cd\u4f5c\u548c\u79fb\u52a8\u7684\u4efb\u52a1\u3002", "conclusion": "GR-3 \u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5 $\\pi_0$\u3002"}}
{"id": "2507.14608", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14608", "abs": "https://arxiv.org/abs/2507.14608", "authors": ["Nandani Sharma", "Dinesh Singh"], "title": "Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition", "comment": null, "summary": "Facial expression recognition is crucial for human-computer interaction\napplications such as face animation, video surveillance, affective computing,\nmedical analysis, etc. Since the structure of facial attributes varies with\nfacial expressions, incorporating structural information into facial attributes\nis essential for facial expression recognition. In this paper, we propose\nExp-Graph, a novel framework designed to represent the structural relationships\namong facial attributes using graph-based modeling for facial expression\nrecognition. For facial attributes graph representation, facial landmarks are\nused as the graph's vertices. At the same time, the edges are determined based\non the proximity of the facial landmark and the similarity of the local\nappearance of the facial attributes encoded using the vision transformer.\nAdditionally, graph convolutional networks are utilized to capture and\nintegrate these structural dependencies into the encoding of facial attributes,\nthereby enhancing the accuracy of expression recognition. Thus, Exp-Graph\nlearns from the facial attribute graphs highly expressive semantic\nrepresentations. On the other hand, the vision transformer and graph\nconvolutional blocks help the framework exploit the local and global\ndependencies among the facial attributes that are essential for the recognition\nof facial expressions. We conducted comprehensive evaluations of the proposed\nExp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.\nThe model achieved recognition accuracies of 98.09\\%, 79.01\\%, and 56.39\\%,\nrespectively. These results indicate that Exp-Graph maintains strong\ngeneralization capabilities across both controlled laboratory settings and\nreal-world, unconstrained environments, underscoring its effectiveness for\npractical facial expression recognition applications.", "AI": {"tldr": "Exp-Graph\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5bf9\u9f50\u9762\u90e8\u5c5e\u6027\u7684\u7ed3\u6784\u5173\u7cfb\uff0c\u4ee5\u63d0\u9ad8\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6027\u80fd\u3002", "motivation": "\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u5728\u4eba\u673a\u4ea4\u4e92\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u9762\u90e8\u5c5e\u6027\u7684\u7ed3\u6784\u4fe1\u606f\u3002\u7531\u4e8e\u9762\u90e8\u5c5e\u6027\u7684\u7ed3\u6784\u968f\u8868\u60c5\u53d8\u5316\uff0c\u5c06\u7ed3\u6784\u4fe1\u606f\u7eb3\u5165\u9762\u90e8\u5c5e\u6027\u5bf9\u4e8e\u63d0\u9ad8\u8bc6\u522b\u7cbe\u5ea6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aExp-Graph\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5bf9\u9762\u90e8\u5c5e\u6027\u7684\u7ed3\u6784\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\uff0c\u4ee5\u5b9e\u73b0\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u3002\u5177\u4f53\u5730\uff0c\u4f7f\u7528\u9762\u90e8\u5730\u6807\u4f5c\u4e3a\u56fe\u7684\u9876\u70b9\uff0c\u90bb\u8fd1\u6027\u548c\u89c6\u89c9Transformer\u7f16\u7801\u7684\u5c40\u90e8\u5916\u89c2\u76f8\u4f3c\u6027\u6765\u786e\u5b9a\u8fb9\uff0c\u5e76\u901a\u8fc7\u56fe\u5377\u79ef\u7f51\u7edc\u6765\u6355\u83b7\u548c\u6574\u5408\u8fd9\u4e9b\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "Exp-Graph\u6846\u67b6\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u8868\u660e\u5176\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "Exp-Graph\u6846\u67b6\u5728Oulu-CASIA\u3001eNTERFACE05\u548cAFEW\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8698.09%\u300179.01%\u548c56.39%\u7684\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9a8c\u5ba4\u548c\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u90fd\u5177\u6709\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.14503", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14503", "abs": "https://arxiv.org/abs/2507.14503", "authors": ["Jiequan Cui", "Beier Zhu", "Qingshan Xu", "Xiaogang Xu", "Pengguang Chen", "Xiaojuan Qi", "Bei Yu", "Hanwang Zhang", "Richang Hong"], "title": "Generative Distribution Distillation", "comment": "Technique report", "summary": "In this paper, we formulate the knowledge distillation (KD) as a conditional\ngenerative problem and propose the \\textit{Generative Distribution Distillation\n(GenDD)} framework. A naive \\textit{GenDD} baseline encounters two major\nchallenges: the curse of high-dimensional optimization and the lack of semantic\nsupervision from labels. To address these issues, we introduce a \\textit{Split\nTokenization} strategy, achieving stable and effective unsupervised KD.\nAdditionally, we develop the \\textit{Distribution Contraction} technique to\nintegrate label supervision into the reconstruction objective. Our theoretical\nproof demonstrates that \\textit{GenDD} with \\textit{Distribution Contraction}\nserves as a gradient-level surrogate for multi-task learning, realizing\nefficient supervised training without explicit classification loss on\nmulti-step sampling image representations. To evaluate the effectiveness of our\nmethod, we conduct experiments on balanced, imbalanced, and unlabeled data.\nExperimental results show that \\textit{GenDD} performs competitively in the\nunsupervised setting, significantly surpassing KL baseline by \\textbf{16.29\\%}\non ImageNet validation set. With label supervision, our ResNet-50 achieves\n\\textbf{82.28\\%} top-1 accuracy on ImageNet in 600 epochs training,\nestablishing a new state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa GenDD \u6846\u67b6\uff0c\u901a\u8fc7\u5206\u88c2\u6807\u8bb0\u5316\u548c\u5206\u5e03\u6536\u7f29\u6280\u672f\uff0c\u5728\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u8bbe\u7f6e\u4e0b\u5747\u5b9e\u73b0\u4e86\u77e5\u8bc6\u84b8\u998f\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u5728\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u8bbe\u7f6e\u4e0b\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u5c06\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u6784\u5efa\u4e3a\u6761\u4ef6\u751f\u6210\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u751f\u6210\u5206\u5e03\u84b8\u998f\uff08GenDD\uff09\u6846\u67b6\u3002\u4e3a\u89e3\u51b3\u65e0\u76d1\u7763 KD \u4e2d\u7684\u9ad8\u7ef4\u4f18\u5316\u8bc5\u5492\u548c\u8bed\u4e49\u76d1\u7763\u7f3a\u5931\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u5206\u88c2\u6807\u8bb0\u5316\u7b56\u7565\u548c\u5206\u5e03\u6536\u7f29\u6280\u672f\uff0c\u540e\u8005\u5c06\u6807\u7b7e\u76d1\u7763\u6574\u5408\u5230\u91cd\u5efa\u76ee\u6807\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u76d1\u7763\u8bad\u7ec3\u3002", "result": "GenDD \u5728\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e0b\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5728 ImageNet \u9a8c\u8bc1\u96c6\u4e0a\u6bd4 KL \u57fa\u7ebf\u9ad8\u51fa 16.29%\u3002", "conclusion": "GenDD \u7ed3\u5408\u6807\u7b7e\u76d1\u7763\u540e\uff0c\u5728 ImageNet \u4e0a\u7684 ResNet-50 \u6a21\u578b\u5b9e\u73b0\u4e86 82.28% \u7684 top-1 \u51c6\u786e\u7387\uff0c\u521b\u4e0b\u65b0\u7684\u6700\u5148\u8fdb\u8bb0\u5f55\u3002"}}
{"id": "2507.15580", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15580", "abs": "https://arxiv.org/abs/2507.15580", "authors": ["Y. M. Beltukov", "A. V. Rodina", "A. Alekseev", "Al. L. Efros"], "title": "Non-perturbative macroscopic theory of interfaces with discontinuous dielectric constant", "comment": null, "summary": "Discontinuity of dielectric constants at the interface is a common feature of\nall nanostructures and semiconductor heterostructures. It gives rise to a\ndivergence of the self-interaction potential acting on a charge near the\ninterface, and it presents an obstruction to a perturbative description. In\nseveral limiting cases, this problem can be avoided by zeroing out the carrier\nwave function at the interface. In this paper, we developed a non-perturbative\ntheory which gives a self-consistent description of carrier propagation through\nan interface with dielectric discontinuity. It is based on conservation of the\ncurrent density propagating through the interface, and it is formulated in\nterms of general boundary conditions (GBC) for the wave function at the\ninterface with a single phenomenological parameter W. For these GBC, we find\nexact solutions of the Schr\\\"odinger equation near the interface and the\ncarrier energy spectrum including resonances. Using these results, we describe\nthe photo effect at the semiconductor/vacuum interface and the electron energy\nspectrum in the interface quantum well, as well as the dependence of these two\nphenomena on the interface parameter W.", "AI": {"tldr": "\u9488\u5bf9\u7eb3\u7c73\u7ed3\u6784\u548c\u534a\u5bfc\u4f53\u5f02\u8d28\u7ed3\u6784\u754c\u9762\u5904\u4ecb\u7535\u5e38\u6570\u4e0d\u8fde\u7eed\u6027\u7684\u95ee\u9898\uff0c\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u975e\u5fae\u6270\u7406\u8bba\u548c\u5e7f\u4e49\u8fb9\u754c\u6761\u4ef6\uff08GBC\uff09\uff0c\u6210\u529f\u63cf\u8ff0\u4e86\u8f7d\u6d41\u5b50\u4f20\u64ad\uff0c\u5e76\u89e3\u91ca\u4e86\u5149\u7535\u6548\u5e94\u548c\u91cf\u5b50\u9631\u4e2d\u7684\u7535\u5b50\u8c31\uff0c\u540c\u65f6\u8003\u8651\u4e86\u754c\u9762\u53c2\u6570W\u7684\u5f71\u54cd\u3002", "motivation": "\u4ecb\u7535\u5e38\u6570\u5728\u754c\u9762\u5904\u7684\u4e0d\u8fde\u7eed\u6027\u4f1a\u5bfc\u81f4\u81ea\u76f8\u4e92\u4f5c\u7528\u52bf\u53d1\u6563\uff0c\u963b\u788d\u5fae\u6270\u63cf\u8ff0\uff0c\u8fd9\u5728\u6240\u6709\u7eb3\u7c73\u7ed3\u6784\u548c\u534a\u5bfc\u4f53\u5f02\u8d28\u7ed3\u6784\u4e2d\u90fd\u662f\u666e\u904d\u5b58\u5728\u7684\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u975e\u5fae\u6270\u7406\u8bba\uff0c\u4f7f\u7528\u5e7f\u4e49\u8fb9\u754c\u6761\u4ef6\uff08GBC\uff09\u548c\u5355\u4e2a\u73b0\u8c61\u5b66\u53c2\u6570W\u6765\u63cf\u8ff0\u8f7d\u6d41\u5b50\u5728\u5177\u6709\u4ecb\u7535\u5e38\u6570\u4e0d\u8fde\u7eed\u6027\u7684\u754c\u9762\u4f20\u64ad\uff0c\u5e76\u627e\u5230\u4e86\u859b\u5b9a\u8c14\u65b9\u7a0b\u5728\u754c\u9762\u9644\u8fd1\u7684\u7cbe\u786e\u89e3\u4ee5\u53ca\u5305\u62ec\u5171\u632f\u5728\u5185\u7684\u8f7d\u6d41\u5b50\u80fd\u91cf\u8c31\u3002", "result": "\u627e\u5230\u4e86\u859b\u5b9a\u8c14\u65b9\u7a0b\u5728\u754c\u9762\u9644\u8fd1\u7684\u7cbe\u786e\u89e3\uff0c\u83b7\u5f97\u4e86\u8f7d\u6d41\u5b50\u80fd\u91cf\u8c31\uff08\u5305\u542b\u5171\u632f\uff09\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u7ed3\u679c\u63cf\u8ff0\u4e86\u534a\u5bfc\u4f53/\u771f\u7a7a\u754c\u9762\u5904\u7684\u5149\u7535\u6548\u5e94\u548c\u754c\u9762\u91cf\u5b50\u9631\u4e2d\u7684\u7535\u5b50\u80fd\u91cf\u8c31\uff0c\u540c\u65f6\u5206\u6790\u4e86\u8fd9\u4e9b\u73b0\u8c61\u5bf9\u754c\u9762\u53c2\u6570W\u7684\u4f9d\u8d56\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7535\u6d41\u5bc6\u5ea6\u5b88\u6052\u7684\u975e\u5fae\u6270\u7406\u8bba\uff0c\u7528\u4e8e\u63cf\u8ff0\u8f7d\u6d41\u5b50\u5728\u5177\u6709\u4ecb\u7535\u5e38\u6570\u4e0d\u8fde\u7eed\u6027\u7684\u754c\u9762\u4f20\u64ad\uff0c\u5e76\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u5177\u6709\u5355\u4e2a\u73b0\u8c61\u5b66\u53c2\u6570W\u7684\u754c\u9762\u6ce2\u51fd\u6570\u7684\u5e7f\u4e49\u8fb9\u754c\u6761\u4ef6\uff08GBC\uff09\u3002"}}
{"id": "2507.15781", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.15781", "abs": "https://arxiv.org/abs/2507.15781", "authors": ["Gian Carlo Maffettone", "Alain Boldini", "Mario di Bernardo", "Maurizio Porfiri"], "title": "Density control of multi-agent swarms via bio-inspired leader-follower plasticity", "comment": null, "summary": "The design of control systems for the spatial self-organization of mobile\nagents is an open challenge across several engineering domains, including swarm\nrobotics and synthetic biology. Here, we propose a bio-inspired leader-follower\nsolution, which is aware of energy constraints of mobile agents and is apt to\ndeal with large swarms. Akin to many natural systems, control objectives are\nformulated for the entire collective, and leaders and followers are allowed to\nplastically switch their role in time. We frame a density control problem,\nmodeling the agents' population via a system of nonlinear partial differential\nequations. This approach allows for a compact description that inherently\navoids the curse of dimensionality and improves analytical tractability. We\nderive analytical guarantees for the existence of desired steady-state\nsolutions and their local stability for one-dimensional and higher-dimensional\nproblems. We numerically validate our control methodology, offering support to\nthe effectiveness, robustness, and versatility of our proposed bio-inspired\ncontrol strategy.", "AI": {"tldr": "A bio-inspired leader-follower control system is proposed for mobile agent self-organization, using PDEs for analysis and offering proven stability and effectiveness in simulations.", "motivation": "Designing control systems for spatial self-organization of mobile agents is a challenge in areas like swarm robotics and synthetic biology. This paper addresses this by proposing an energy-aware, leader-follower solution suitable for large swarms.", "method": "A bio-inspired leader-follower approach is used, formulating control objectives for the collective and allowing agents to switch roles. The density control problem is modeled using nonlinear partial differential equations to avoid the curse of dimensionality and improve analytical tractability.", "result": "Analytical guarantees for the existence and local stability of desired steady-state solutions were derived for both one-dimensional and higher-dimensional problems. Numerical validation supported the effectiveness, robustness, and versatility of the control methodology.", "conclusion": "The proposed bio-inspired leader-follower control strategy is effective, robust, and versatile for spatial self-organization of mobile agents, with analytical guarantees for steady-state solutions and their local stability."}}
{"id": "2507.15065", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15065", "abs": "https://arxiv.org/abs/2507.15065", "authors": ["Yudai Suzuki", "Marek Gluza", "Jeongrak Son", "Bi Hong Tiang", "Nelly H. Y. Ng", "Zo\u00eb Holmes"], "title": "Grover's algorithm is an approximation of imaginary-time evolution", "comment": null, "summary": "We reveal the power of Grover's algorithm from thermodynamic and geometric\nperspectives by showing that it is a product formula approximation of\nimaginary-time evolution (ITE), a Riemannian gradient flow on the special\nunitary group. This viewpoint uncovers three key insights. First, we show that\nthe ITE dynamics trace the shortest path between the initial and the solution\nstates in complex projective space. Second, we prove that the geodesic length\nof ITE determines the query complexity of Grover's algorithm. This complexity\nnotably aligns with the known optimal scaling for unstructured search. Lastly,\nutilizing the geodesic structure of ITE, we construct a quantum signal\nprocessing formulation for ITE without post-selection, and derive a new set of\nangles for the fixed-point search. These results collectively establish a\ndeeper understanding of Grover's algorithm and suggest a potential role for\nthermodynamics and geometry in quantum algorithm design.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ece\u70ed\u529b\u5b66\u548c\u51e0\u4f55\u89d2\u5ea6\u63ed\u793a\u4e86 Grover \u7b97\u6cd5\u662f\u865a\u65f6\u6f14\u5316\uff08ITE\uff09\u7684\u8fd1\u4f3c\uff0cITE \u662f\u9149\u7fa4\u4e0a\u7684\u9ece\u66fc\u68af\u5ea6\u6d41\u3002\u7814\u7a76\u8bc1\u660e\u4e86 ITE \u8def\u5f84\u7684\u6700\u4f18\u6027\uff0c\u91cf\u5316\u4e86\u5176\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u4e3a\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u4e3a\u4e86\u4ece\u70ed\u529b\u5b66\u548c\u51e0\u4f55\u7684\u89d2\u5ea6\u63ed\u793a Grover \u7b97\u6cd5\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u5e76\u6df1\u5316\u5bf9\u5176\u7684\u7406\u89e3\uff0c\u540c\u65f6\u63a2\u7d22\u70ed\u529b\u5b66\u548c\u51e0\u4f55\u5728\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u5728\u4f5c\u7528\u3002", "method": "\u5c06 Grover \u7b97\u6cd5\u89c6\u4e3a\u4e00\u79cd\u5728\u7279\u6b8a\u9149\u7fa4\u4e0a\u7684\u9ece\u66fc\u68af\u5ea6\u6d41\u2014\u2014\u865a\u65f6\u6f14\u5316\uff08ITE\uff09\u7684\u4e58\u79ef\u516c\u5f0f\u8fd1\u4f3c\uff0c\u5e76\u4ece\u70ed\u529b\u5b66\u548c\u51e0\u4f55\u89d2\u5ea6\u8fdb\u884c\u5206\u6790\u3002\u5177\u4f53\u5305\u62ec\uff1a\u8bc1\u660e ITE \u52a8\u529b\u5b66\u8ffd\u8e2a\u4e86\u590d\u6570\u5c04\u5f71\u7a7a\u95f4\u4e2d\u521d\u59cb\u72b6\u6001\u548c\u89e3\u72b6\u6001\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84\uff1b\u8bc1\u660e ITE \u7684\u9ece\u66fc\u51e0\u4f55\u6d4b\u5730\u7ebf\u957f\u5ea6\u51b3\u5b9a\u4e86 Grover \u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff1b\u5229\u7528 ITE \u7684\u6d4b\u5730\u7ebf\u7ed3\u6784\uff0c\u6784\u5efa\u4e86\u4e00\u79cd\u65e0\u9700\u540e\u9009\u62e9\u7684 ITE \u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u516c\u5f0f\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u7ec4\u65b0\u7684\u5b9a\u70b9\u641c\u7d22\u89d2\u5ea6\u3002", "result": "Grover \u7b97\u6cd5\u662f\u865a\u65f6\u6f14\u5316\uff08ITE\uff09\u7684\u4e58\u79ef\u516c\u5f0f\u8fd1\u4f3c\uff0cITE \u662f\u9149\u7fa4\u4e0a\u7684\u9ece\u66fc\u68af\u5ea6\u6d41\u3002ITE \u52a8\u529b\u5b66\u8ffd\u8e2a\u4e86\u590d\u6570\u5c04\u5f71\u7a7a\u95f4\u4e2d\u521d\u59cb\u72b6\u6001\u548c\u89e3\u72b6\u6001\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84\u3002ITE \u7684\u9ece\u66fc\u51e0\u4f55\u6d4b\u5730\u7ebf\u957f\u5ea6\u51b3\u5b9a\u4e86 Grover \u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u8be5\u590d\u6742\u5ea6\u4e0e\u65e0\u7ed3\u6784\u641c\u7d22\u7684\u6700\u4f18\u7f29\u653e\u4e00\u81f4\u3002\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u79cd\u65e0\u9700\u540e\u9009\u62e9\u7684 ITE \u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u516c\u5f0f\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u7ec4\u65b0\u7684\u5b9a\u70b9\u641c\u7d22\u89d2\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86 Grover \u7b97\u6cd5\u5728\u70ed\u529b\u5b66\u548c\u51e0\u4f55\u89d2\u5ea6\u4e0b\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u5c06\u5176\u89c6\u4e3a\u4e00\u79cd\u5728\u9149\u7fa4\u4e0a\u7684\u9ece\u66fc\u68af\u5ea6\u6d41\u2014\u2014\u865a\u65f6\u6f14\u5316\uff08ITE\uff09\u7684\u4e58\u79ef\u516c\u5f0f\u8fd1\u4f3c\u3002\u8fd9\u4e00\u89c6\u89d2\u63ed\u793a\u4e86\u4e09\u4e2a\u5173\u952e\u89c1\u89e3\uff1aITE \u52a8\u529b\u5b66\u8ffd\u8e2a\u4e86\u590d\u6570\u5c04\u5f71\u7a7a\u95f4\u4e2d\u521d\u59cb\u72b6\u6001\u548c\u89e3\u72b6\u6001\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84\uff1bITE \u7684\u9ece\u66fc\u51e0\u4f55\u6d4b\u5730\u7ebf\u957f\u5ea6\u51b3\u5b9a\u4e86 Grover \u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u5e76\u4e14\u8be5\u590d\u6742\u5ea6\u4e0e\u65e0\u7ed3\u6784\u641c\u7d22\u7684\u6700\u4f18\u7f29\u653e\u4e00\u81f4\uff1b\u5229\u7528 ITE \u7684\u6d4b\u5730\u7ebf\u7ed3\u6784\uff0c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u79cd\u65e0\u9700\u540e\u9009\u62e9\u7684 ITE \u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u516c\u5f0f\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u7ec4\u65b0\u7684\u5b9a\u70b9\u641c\u7d22\u89d2\u5ea6\u3002\u8fd9\u4e9b\u7ed3\u679c\u5171\u540c\u6df1\u5316\u4e86\u5bf9 Grover \u7b97\u6cd5\u7684\u7406\u89e3\uff0c\u5e76\u6697\u793a\u4e86\u70ed\u529b\u5b66\u548c\u51e0\u4f55\u5728\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u5728\u4f5c\u7528\u3002"}}
{"id": "2507.14749", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14749", "abs": "https://arxiv.org/abs/2507.14749", "authors": ["Wai Keen Vong", "Brenden M. Lake"], "title": "On the robustness of modeling grounded word learning through a child's egocentric input", "comment": null, "summary": "What insights can machine learning bring to understanding human language\nacquisition? Large language and multimodal models have achieved remarkable\ncapabilities, but their reliance on massive training datasets creates a\nfundamental mismatch with children, who succeed in acquiring language from\ncomparatively limited input. To help bridge this gap, researchers have\nincreasingly trained neural networks using data similar in quantity and quality\nto children's input. Taking this approach to the limit, Vong et al. (2024)\nshowed that a multimodal neural network trained on 61 hours of visual and\nlinguistic input extracted from just one child's developmental experience could\nacquire word-referent mappings. However, whether this approach's success\nreflects the idiosyncrasies of a single child's experience, or whether it would\nshow consistent and robust learning patterns across multiple children's\nexperiences was not explored. In this article, we applied automated speech\ntranscription methods to the entirety of the SAYCam dataset, consisting of over\n500 hours of video data spread across all three children. Using these automated\ntranscriptions, we generated multi-modal vision-and-language datasets for both\ntraining and evaluation, and explored a range of neural network configurations\nto examine the robustness of simulated word learning. Our findings demonstrate\nthat networks trained on automatically transcribed data from each child can\nacquire and generalize word-referent mappings across multiple network\narchitectures. These results validate the robustness of multimodal neural\nnetworks for grounded word learning, while highlighting the individual\ndifferences that emerge in how models learn when trained on each child's\ndevelopmental experiences.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790500\u591a\u5c0f\u65f6\u7684\u513f\u7ae5\u89c6\u9891\u6570\u636e\uff0c\u7814\u7a76\u53d1\u73b0\u591a\u6a21\u6001\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u4ece\u6709\u9650\u7684\u3001\u81ea\u52a8\u8f6c\u5f55\u7684\u513f\u7ae5\u8f93\u5165\u4e2d\u5b66\u4e60\u8bcd\u6c47\uff0c\u5e76\u4e14\u8fd9\u79cd\u5b66\u4e60\u5177\u6709\u8de8\u4e0d\u540c\u513f\u7ae5\u548c\u7f51\u7edc\u67b6\u6784\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u4e5f\u5b58\u5728\u4e2a\u4f53\u5dee\u5f02\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u513f\u7ae5\u8bed\u8a00\u4e60\u5f97\u4e4b\u95f4\u5728\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u8d28\u91cf\u4e0a\u7684\u5dee\u5f02\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u901a\u8fc7\u6a21\u62df\u513f\u7ae5\u6709\u9650\u7684\u8f93\u5165\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u9a8c\u8bc1\u8fd9\u79cd\u65b9\u6cd5\u5728\u8de8\u591a\u4e2a\u513f\u7ae5\u6570\u636e\u96c6\u4e0a\u7684\u5b66\u4e60\u6a21\u5f0f\u7684\u7a33\u5065\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u81ea\u52a8\u5316\u8bed\u97f3\u8f6c\u5f55\u65b9\u6cd5\u5904\u7406\u4e86SAYCam\u6570\u636e\u96c6\u4e2d\u7684500\u591a\u5c0f\u65f6\u89c6\u9891\u6570\u636e\uff0c\u751f\u6210\u4e86\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684\u591a\u6a21\u6001\u89c6\u89c9-\u8bed\u8a00\u6570\u636e\u96c6\u3002\u7814\u7a76\u4eba\u5458\u63a2\u7d22\u4e86\u4e00\u7cfb\u5217\u795e\u7ecf\u7f51\u7edc\u914d\u7f6e\uff0c\u4ee5\u68c0\u9a8c\u6a21\u62df\u8bcd\u6c47\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4ece\u6bcf\u4e2a\u513f\u7ae5\u7684\u81ea\u52a8\u8f6c\u5f55\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u8de8\u591a\u79cd\u7f51\u7edc\u67b6\u6784\u4e60\u5f97\u5e76\u6cdb\u5316\u8bcd\u6c47-\u6307\u4ee3\u8868\u5f81\u3002\u8fd9\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u795e\u7ecf\u7f51\u7edc\u5728\u57fa\u7840\u8bcd\u6c47\u5b66\u4e60\u4e0a\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4e5f\u7a81\u663e\u4e86\u5728\u4e0d\u540c\u513f\u7ae5\u7684\u7ecf\u9a8c\u4e0a\u8bad\u7ec3\u6a21\u578b\u65f6\u51fa\u73b0\u7684\u4e2a\u4f53\u5dee\u5f02\u3002", "conclusion": "\u672c\u7814\u7a76\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u795e\u7ecf\u7f51\u7edc\u5728\u57fa\u7840\u8bcd\u6c47\u5b66\u4e60\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u56e0\u8bad\u7ec3\u6570\u636e\u4e2a\u4f53\u5dee\u5f02\u800c\u4ea7\u751f\u7684\u5b66\u4e60\u6a21\u5f0f\u7684\u72ec\u7279\u6027\u3002"}}
{"id": "2507.14206", "categories": ["eess.SP", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14206", "abs": "https://arxiv.org/abs/2507.14206", "authors": ["Zhijiang Tang", "Jiaxin Qi", "Yuhua Zheng", "Jianqiang Huang"], "title": "A Comprehensive Benchmark for Electrocardiogram Time-Series", "comment": "Accepted to ACM MM 2025", "summary": "Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial\nfor assessing cardiac health and diagnosing various diseases. Given its\ntime-series format, ECG data is often incorporated into pre-training datasets\nfor large-scale time-series model training. However, existing studies often\noverlook its unique characteristics and specialized downstream applications,\nwhich differ significantly from other time-series data, leading to an\nincomplete understanding of its properties. In this paper, we present an\nin-depth investigation of ECG signals and establish a comprehensive benchmark,\nwhich includes (1) categorizing its downstream applications into four distinct\nevaluation tasks, (2) identifying limitations in traditional evaluation metrics\nfor ECG analysis, and introducing a novel metric; (3) benchmarking\nstate-of-the-art time-series models and proposing a new architecture. Extensive\nexperiments demonstrate that our proposed benchmark is comprehensive and\nrobust. The results validate the effectiveness of the proposed metric and model\narchitecture, which establish a solid foundation for advancing research in ECG\nsignal analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5fc3\u7535\u56fe\u4fe1\u53f7\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u65b0\u7684\u8bc4\u4f30\u4efb\u52a1\u3001\u5ea6\u91cf\u6307\u6807\u548c\u6a21\u578b\u67b6\u6784\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u5bf9\u5fc3\u7535\u56fe\u4fe1\u53f7\u7279\u6027\u7684\u5ffd\u89c6\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u901a\u5e38\u5ffd\u7565\u4e86\u5fc3\u7535\u56fe\u4fe1\u53f7\u7684\u72ec\u7279\u6027\u8d28\u53ca\u5176\u5728\u7279\u5b9a\u4e0b\u6e38\u5e94\u7528\u4e2d\u7684\u7279\u6b8a\u6027\uff0c\u5bfc\u81f4\u5bf9\u5176\u6027\u8d28\u7684\u7406\u89e3\u4e0d\u5b8c\u6574\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\uff081\uff09\u5c06\u4e0b\u6e38\u5e94\u7528\u5206\u4e3a\u56db\u4e2a\u4e0d\u540c\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\uff082\uff09\u8bc6\u522b\u4f20\u7edf\u5fc3\u7535\u56fe\u5206\u6790\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\u5e76\u5f15\u5165\u65b0\u7684\u5ea6\u91cf\u6307\u6807\uff0c\uff083\uff09\u5bf9\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u67b6\u6784\u7684\u7efc\u5408\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u5ea6\u91cf\u548c\u6a21\u578b\u67b6\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u51c6\u6d4b\u8bd5\u5168\u9762\u4e14\u7a33\u5065\uff0c\u6240\u63d0\u51fa\u7684\u5ea6\u91cf\u548c\u6a21\u578b\u67b6\u6784\u7684\u6709\u6548\u6027\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u4e3a\u63a8\u8fdb\u5fc3\u7535\u56fe\u4fe1\u53f7\u5206\u6790\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.15499", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15499", "abs": "https://arxiv.org/abs/2507.15499", "authors": ["Jongseok Lee", "Timo Birr", "Rudolph Triebel", "Tamim Asfour"], "title": "CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions", "comment": "8 pages. Accepted to IEEE RAL", "summary": "We propose CLEVER, an active learning system for robust semantic perception\nwith Deep Neural Networks (DNNs). For data arriving in streams, our system\nseeks human support when encountering failures and adapts DNNs online based on\nhuman instructions. In this way, CLEVER can eventually accomplish the given\nsemantic perception tasks. Our main contribution is the design of a system that\nmeets several desiderata of realizing the aforementioned capabilities. The key\nenabler herein is our Bayesian formulation that encodes domain knowledge\nthrough priors. Empirically, we not only motivate CLEVER's design but further\ndemonstrate its capabilities with a user validation study as well as\nexperiments on humanoid and deformable objects. To our knowledge, we are the\nfirst to realize stream-based active learning on a real robot, providing\nevidence that the robustness of the DNN-based semantic perception can be\nimproved in practice. The project website can be accessed at\nhttps://sites.google.com/view/thecleversystem.", "AI": {"tldr": "CLEVER\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u4e3b\u52a8\u5b66\u4e60\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u4eba\u7c7b\u667a\u6167\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u8bed\u4e49\u611f\u77e5\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u5728\u5904\u7406\u6570\u636e\u6d41\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u548c\u9002\u5e94\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u8d1d\u53f6\u65af\u65b9\u6cd5\u7ed3\u5408\u5148\u9a8c\u77e5\u8bc6\u6765\u7f16\u7801\u9886\u57df\u77e5\u8bc6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u80fd\u5904\u7406\u6570\u636e\u6d41\u3001\u5728\u9047\u5230\u5931\u8d25\u65f6\u5bfb\u6c42\u4eba\u7c7b\u652f\u6301\u5e76\u6839\u636e\u4eba\u7c7b\u6307\u4ee4\u5728\u7ebf\u8c03\u6574DNN\u7684\u7cfb\u7edf\u3002", "result": "\u5728\u4eba\u5f62\u548c\u53ef\u53d8\u5f62\u7269\u4f53\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u548c\u7528\u6237\u9a8c\u8bc1\u7814\u7a76\uff0c\u5c55\u793a\u4e86CLEVER\u7cfb\u7edf\u7684\u80fd\u529b\u3002", "conclusion": "CLEVER\u7cfb\u7edf\u9996\u6b21\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6d41\u7684\u4e3b\u52a8\u5b66\u4e60\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8eDNN\u7684\u8bed\u4e49\u611f\u77e5\u7684\u9c81\u68d2\u6027\u53ef\u4ee5\u5f97\u5230\u5b9e\u9645\u63d0\u5347\u3002"}}
{"id": "2507.14613", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14613", "abs": "https://arxiv.org/abs/2507.14613", "authors": ["Guoping Xu", "Christopher Kabat", "You Zhang"], "title": "Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2", "comment": "24 pages, 6 figures", "summary": "Recent advances in medical image segmentation have been driven by deep\nlearning; however, most existing methods remain limited by modality-specific\ndesigns and exhibit poor adaptability to dynamic medical imaging scenarios. The\nSegment Anything Model 2 (SAM2) and its related variants, which introduce a\nstreaming memory mechanism for real-time video segmentation, present new\nopportunities for prompt-based, generalizable solutions. Nevertheless, adapting\nthese models to medical video scenarios typically requires large-scale datasets\nfor retraining or transfer learning, leading to high computational costs and\nthe risk of catastrophic forgetting. To address these challenges, we propose\nDD-SAM2, an efficient adaptation framework for SAM2 that incorporates a\nDepthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature\nextraction with minimal parameter overhead. This design enables effective\nfine-tuning of SAM2 on medical videos with limited training data. Unlike\nexisting adapter-based methods focused solely on static images, DD-SAM2 fully\nexploits SAM2's streaming memory for medical video object tracking and\nsegmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)\nand EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior\nperformance, achieving Dice scores of 0.93 and 0.97, respectively. To the best\nof our knowledge, this work provides an initial attempt at systematically\nexploring adapter-based SAM2 fine-tuning for medical video segmentation and\ntracking. Code, datasets, and models will be publicly available at\nhttps://github.com/apple1986/DD-SAM2.", "AI": {"tldr": "DD-SAM2\u901a\u8fc7\u5f15\u5165DD-Adapter\u589e\u5f3aSAM2\u5728\u533b\u7597\u89c6\u9891\u5206\u5272\u548c\u8ddf\u8e2a\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4ee5\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u533b\u5b66\u56fe\u50cf\u5206\u5272\u65b9\u6cd5\u5728\u52a8\u6001\u533b\u5b66\u6210\u50cf\u573a\u666f\u4e2d\u9002\u5e94\u6027\u5dee\u3001\u6a21\u6001\u7279\u5f02\u6027\u8bbe\u8ba1\u9650\u5236\u4ee5\u53caSAM2\u6a21\u578b\u5728\u533b\u7597\u89c6\u9891\u5e94\u7528\u4e2d\u9700\u8981\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\u6216\u8fc1\u79fb\u5b66\u4e60\u5bfc\u81f4\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDD-SAM2\u7684\u9ad8\u6548\u9002\u5e94\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5f15\u5165\u4e86\u6df1\u5ea6\u53ef\u5206\u79bb\u9002\u914d\u5668\uff08DD-Adapter\uff09\uff0c\u4ee5\u589e\u5f3a\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u5e76\u6700\u5c0f\u5316\u53c2\u6570\u5f00\u9500\u3002\u8be5\u65b9\u6cd5\u5229\u7528SAM2\u7684\u6d41\u5f0f\u5185\u5b58\u673a\u5236\uff0c\u4e13\u6ce8\u4e8e\u533b\u7597\u89c6\u9891\u5bf9\u8c61\u8ddf\u8e2a\u548c\u5206\u5272\u3002", "result": "\u5728TrackRad2025\uff08\u80bf\u7624\u5206\u5272\uff09\u548cEchoNet-Dynamic\uff08\u5de6\u5fc3\u5ba4\u8ddf\u8e2a\uff09\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\uff0cDice\u5206\u6570\u5206\u522b\u8fbe\u52300.93\u548c0.97\u3002", "conclusion": "DD-SAM2\u662f\u4e00\u4e2a\u9ad8\u6548\u7684SAM2\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u6df1\u5ea6\u53ef\u5206\u79bb\u9002\u914d\u5668\uff08DD-Adapter\uff09\u589e\u5f3a\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u5e76\u4ee5\u6700\u5c0f\u7684\u53c2\u6570\u5f00\u9500\u5b9e\u73b0\u4e86\u5728\u6709\u9650\u533b\u7597\u89c6\u9891\u6570\u636e\u4e0a\u7684\u6709\u6548\u5fae\u8c03\u3002\u8be5\u6846\u67b6\u5145\u5206\u5229\u7528\u4e86SAM2\u7684\u6d41\u5f0f\u5185\u5b58\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u533b\u7597\u89c6\u9891\u5bf9\u8c61\u8ddf\u8e2a\u548c\u5206\u5272\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDD-SAM2\u5728TrackRad2025\u548cEchoNet-Dynamic\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e860.93\u548c0.97\u7684Dice\u5206\u6570\uff0c\u5c55\u73b0\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2507.15140", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15140", "abs": "https://arxiv.org/abs/2507.15140", "authors": ["Mohammad Mashayekhi", "Sara Ahmadi Majd", "Arian AmirAmjadi", "Parsa Hosseini"], "title": "Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis", "comment": null, "summary": "The diagnosis of oral diseases presents a problematic clinical challenge,\ncharacterized by a wide spectrum of pathologies with overlapping\nsymptomatology. To address this, we developed Clinical Semantic Intelligence\n(CSI), a novel artificial intelligence framework that diagnoses 118 different\noral diseases by computationally modeling the cognitive processes of an expert\nclinician. Our core hypothesis is that moving beyond simple pattern matching to\nemulate expert reasoning is critical to building clinically useful diagnostic\naids.\n  CSI's architecture integrates a fine-tuned multimodal CLIP model with a\nspecialized ChatGLM-6B language model. This system executes a Hierarchical\nDiagnostic Reasoning Tree (HDRT), a structured framework that distills the\nsystematic, multi-step logic of differential diagnosis. The framework operates\nin two modes: a Fast Mode for rapid screening and a Standard Mode that\nleverages the full HDRT for an interactive and in-depth diagnostic workup.\n  To train and validate our system, we curated a primary dataset of 4,310\nimages, supplemented by an external hold-out set of 176 images for final\nvalidation. A clinically-informed augmentation strategy expanded our training\ndata to over 30,000 image-text pairs. On a 431-image internal test set, CSI's\nFast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the\nHDRT-driven Standard Mode. The performance gain is directly attributable to the\nhierarchical reasoning process. Herein, we detail the architectural philosophy,\ndevelopment, and rigorous evaluation of the CSI framework.", "AI": {"tldr": "CSI\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u4e13\u5bb6\u63a8\u7406\uff0c\u5229\u7528CLIP\u548cChatGLM\u6a21\u578b\u53caHDRT\uff0c\u5728\u53e3\u8154\u75be\u75c5\u8bca\u65ad\u65b9\u9762\u8fbe\u523089.5%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u53e3\u8154\u75be\u75c5\u8bca\u65ad\u7684\u4e34\u5e8a\u6311\u6218\uff0c\u5373\u75c5\u53d8\u8c31\u5e7f\u6cdb\u4e14\u75c7\u72b6\u91cd\u53e0\uff0c\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6a21\u62df\u4e13\u5bb6\u8ba4\u77e5\u8fc7\u7a0b\u7684AI\u6846\u67b6\uff0c\u4ee5\u8d85\u8d8a\u7b80\u5355\u7684\u6a21\u5f0f\u5339\u914d\uff0c\u63d0\u4f9b\u6709\u7528\u7684\u4e34\u5e8a\u8bca\u65ad\u8f85\u52a9\u3002", "method": "\u5f00\u53d1\u4e86\u4e34\u5e8a\u8bed\u4e49\u667a\u80fd\uff08CSI\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u4e86CLIP\u591a\u6a21\u6001\u6a21\u578b\u548cChatGLM-6B\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5229\u7528\u4e86\u5206\u5c42\u8bca\u65ad\u63a8\u7406\u6811\uff08HDRT\uff09\u6765\u6a21\u62df\u4e13\u5bb6\u8bca\u65ad\u8fc7\u7a0b\uff0c\u540c\u65f6\u5305\u542b\u5feb\u901f\u6a21\u5f0f\u548c\u6807\u51c6\u6a21\u5f0f\u4e24\u79cd\u8fd0\u884c\u65b9\u5f0f\u3002", "result": "\u5728\u5185\u90e8\u6d4b\u8bd5\u96c6\u4e0a\uff0cCSI\u7684\u5feb\u901f\u6a21\u5f0f\u51c6\u786e\u7387\u4e3a73.4%\uff0c\u6807\u51c6\u6a21\u5f0f\uff08\u5229\u7528HDRT\uff09\u51c6\u786e\u7387\u63d0\u5347\u81f389.5%\u3002", "conclusion": "CSI\u6846\u67b6\u5728\u8bca\u65ad\u53e3\u8154\u75be\u75c5\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u7387\uff0c\u5176HDRT\u9a71\u52a8\u7684\u6807\u51c6\u6a21\u5f0f\u6027\u80fd\u63d0\u5347\u663e\u8457\uff0c\u8bc1\u660e\u4e86\u6a21\u62df\u4e13\u5bb6\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.15583", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15583", "abs": "https://arxiv.org/abs/2507.15583", "authors": ["Lyes Mesbahi", "Omar Messaoudi", "Hamid Bouzar", "Samir Lounis"], "title": "Ab-initio exploration of Gd monolayer interfaced with WSe$_2$: from electronic and magnetic properties to the anomalous Hall effect", "comment": null, "summary": "Heterostructures involving transition metal dichalcogenides (TMDs) have\nattracted significant research interest due to the richness and versatility of\nthe underlying physical phenomena. In this work, we investigate a\nheterostructure consisting of a rare-earth material, specifically a Gd\nmonolayer, interfaced with WSe$_2$. We explore its electronic structure,\nmagnetic properties, and transport behavior, with particular emphasis on the\nemergence of the anomalous Hall effect (AHE). Both Gd and W are heavy elements,\nproviding strong spin-orbit coupling (SOC), which plays a crucial role in\ntriggering the AHE. The combination of strong SOC and inversion symmetry\nbreaking leads to pronounced asymmetries between the $\\Gamma-K$ and\n$\\Gamma-K^\\prime$ directions in the Brillouin zone. Our calculations reveal a\nsubstantial anomalous Hall conductivity (AHC) at the ferromagnetic interface,\nprimarily originating from numerous avoided crossings involving the d-states of\nboth Gd and W near the Fermi level. Moreover, we demonstrate that the AHC is\nhighly tunable, either by adjusting the in-plane lattice constant or by\nreducing the separation between Gd and WSe$_2$.", "AI": {"tldr": "Gd/WSe2\u5f02\u8d28\u7ed3\u901a\u8fc7\u5f3aSOC\u548c\u5bf9\u79f0\u6027\u7834\u7f3a\u5c55\u73b0\u51fa\u53ef\u8c03\u63a7\u7684\u5f02\u5e38\u970d\u5c14\u6548\u5e94(AHE)\uff0c\u5176\u6839\u6e90\u5728\u4e8e\u8d39\u7c73\u80fd\u7ea7\u9644\u8fd1\u7684d\u6001\u907f\u514d\u4ea4\u53c9\u3002", "motivation": "\u63a2\u7d22\u5177\u6709\u4e30\u5bcc\u7269\u7406\u73b0\u8c61\u7684\u8fc7\u6e21\u91d1\u5c5e\u786b\u65cf\u5316\u5408\u7269(TMD)\u5f02\u8d28\u7ed3\u6784\uff0c\u7279\u522b\u662f\u7a00\u571f\u6750\u6599\u4e0eTMDs\u7684\u754c\u9762\u6548\u5e94\u3002", "method": "\u5229\u7528\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u7814\u7a76\u4e86Gd/WSe2\u5f02\u8d28\u7ed3\u7684\u7535\u5b50\u7ed3\u6784\u3001\u78c1\u6027\u548c\u8f93\u8fd0\u6027\u8d28\u3002", "result": "\u8ba1\u7b97\u53d1\u73b0Gd/WSe2\u5f02\u8d28\u7ed3\u8868\u73b0\u51fa\u663e\u8457\u7684\u5f02\u5e38\u970d\u5c14\u7535\u5bfc(AHC)\uff0c\u4e3b\u8981\u5f52\u56e0\u4e8eGd\u548cW\u7684d\u6001\u5728\u8d39\u7c73\u80fd\u7ea7\u9644\u8fd1\u7684\u907f\u514d\u4ea4\u53c9\u3002AHC\u53ef\u4ee5\u901a\u8fc7\u6539\u53d8\u6676\u683c\u5e38\u6570\u6216Gd-WSe2\u95f4\u8ddd\u8fdb\u884c\u8c03\u63a7\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86Gd/WSe2\u5f02\u8d28\u7ed3\u7684\u7535\u5b50\u7ed3\u6784\u3001\u78c1\u6027\u548c\u8f93\u8fd0\u6027\u8d28\uff0c\u7279\u522b\u662f\u5f02\u5e38\u970d\u5c14\u6548\u5e94(AHE)\u3002\u901a\u8fc7\u7ed3\u5408\u5f3a\u81ea\u65cb-\u8f68\u9053\u8026\u5408(SOC)\u548c\u53cd\u6f14\u5bf9\u79f0\u6027\u7834\u574f\uff0c\u5728$\rm \bf \boldsymbol\n \text{\u0393-K}$\u548c$\rm \bf \boldsymbol\n \text{\u0393-K}$'\u65b9\u5411\u4e4b\u95f4\u4ea7\u751f\u4e86\u663e\u8457\u7684\u4e0d\u5bf9\u79f0\u6027\u3002\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\uff0c\u5728\u94c1\u78c1\u754c\u9762\u5904\u5b58\u5728\u663e\u8457\u7684\u5f02\u5e38\u970d\u5c14\u7535\u5bfc(AHC)\uff0c\u8fd9\u4e3b\u8981\u6e90\u4e8eGd\u548cW\u7684d\u6001\u5728\u8d39\u7c73\u80fd\u7ea7\u9644\u8fd1\u7684\u591a\u6b21\u907f\u514d\u4ea4\u53c9\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u901a\u8fc7\u8c03\u6574\u9762\u5185\u6676\u683c\u5e38\u6570\u6216\u51cf\u5c0fGd\u548cWSe2\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u8c03\u63a7AHC\u3002"}}
{"id": "2507.05297", "categories": ["cs.AI", "cs.SY", "econ.TH", "eess.SY", "math.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.05297", "abs": "https://arxiv.org/abs/2507.05297", "authors": ["Zijun Meng"], "title": "Continuous Classification Aggregation", "comment": "9 pages; 2 figures", "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean. We also provide a characterization for the case when $m=p=2$.", "AI": {"tldr": "\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u503c\u3002", "motivation": "\u7814\u7a76\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u7684\u6027\u8d28", "method": "\u8bc1\u660e\u548c\u523b\u753b", "result": "\u8bc1\u660e\u4e86\u6700\u4f18\u3001\u72ec\u7acb\u3001\u96f6\u4e00\u81f4\u7684\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u503c\uff0c\u5e76\u5bf9 $m=p=2$ \u7684\u60c5\u51b5\u8fdb\u884c\u4e86\u523b\u753b\u3002", "conclusion": "\u8bc1\u660e\u4e86\u4efb\u4f55\u6700\u4f18\u3001\u72ec\u7acb\u3001\u96f6\u4e00\u81f4\u7684\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\uff08\u5bf9\u4e8e $m \times p$ \u7684\u5206\u7c7b\uff09\u5fc5\u987b\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u503c\uff0c\u5e76\u5bf9 $m=p=2$ \u7684\u60c5\u51b5\u8fdb\u884c\u4e86\u523b\u753b\u3002"}}
{"id": "2507.15128", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2507.15128", "abs": "https://arxiv.org/abs/2507.15128", "authors": ["Huw Price", "Ken Wharton"], "title": "Taming Entanglement", "comment": "53 pages, 13 figures", "summary": "In statistics and causal modeling it is common for a selection process to\ninduce correlations in a subset of an uncorrelated ensemble. We propose that\nEPR and Bell correlations are selection artefacts of this kind. The selection\nprocess is preparation of the initial state of the relevant experiments. Choice\nof initial state amounts to preselection of a subensemble of a larger,\nuncorrelated, virtual ensemble of possble histories. Because it is preselection\nrather than postselection, the resulting correlations support the intuitive\ncounterfactuals of the EPR argument and Bell nonlocality. In this respect, and\nin its temporal orientation, the case differs from familiar forms of selection\nbias. Given the ubiquity of quantum entanglement, the result may thus be of\nindependent interest to students of causal modeling. The paper concludes with a\ndiscussion of its novel implications in that field.", "AI": {"tldr": "EPR\u548c\u8d1d\u5c14\u5173\u8054\u662f\u9009\u62e9\u6548\u5e94\uff0c\u6e90\u4e8e\u5b9e\u9a8c\u5236\u5907\u7684\u521d\u59cb\u72b6\u6001\uff0c\u800c\u975e\u771f\u6b63\u7684\u91cf\u5b50\u7ea0\u7f20\u3002", "motivation": "\u89e3\u91caEPR\u548c\u8d1d\u5c14\u5173\u8054\u7684\u6765\u6e90\uff0c\u5e76\u5c06\u5176\u4e0e\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u9009\u62e9\u504f\u5dee\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u63d0\u51faEPR\u548c\u8d1d\u5c14\u5173\u8054\u662f\u9009\u62e9\u6548\u5e94\uff0c\u901a\u8fc7\u5206\u6790\u521d\u59cb\u72b6\u6001\u5236\u5907\u8fc7\u7a0b\u4e2d\u7684\u5b50\u7cfb\u7efc\u9009\u62e9\u6765\u89e3\u91ca\u3002", "result": "EPR\u548c\u8d1d\u5c14\u5173\u8054\u662f\u521d\u59cb\u72b6\u6001\u5236\u5907\u8fd9\u4e00\u9009\u62e9\u8fc7\u7a0b\u4ea7\u751f\u7684\uff0c\u800c\u975e\u5185\u79c9\u7684\u91cf\u5b50\u73b0\u8c61\uff0c\u5e76\u5bf9\u56e0\u679c\u6a21\u578b\u9886\u57df\u6709\u65b0\u7684\u542f\u793a\u3002", "conclusion": "EPR\u548c\u8d1d\u5c14\u5173\u8054\u662f\u9009\u62e9\u6548\u5e94\uff0c\u7531\u521d\u59cb\u72b6\u6001\u5236\u5907\u5f15\u5165\uff0c\u652f\u6301\u4e86EPR\u8bba\u8bc1\u548c\u8d1d\u5c14\u975e\u5c40\u57df\u6027\u7684\u76f4\u89c2\u53cd\u4e8b\u5b9e\u3002"}}
{"id": "2507.14758", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.14758", "abs": "https://arxiv.org/abs/2507.14758", "authors": ["Luyi Ma", "Wanjia Zhang", "Kai Zhao", "Abhishek Kulkarni", "Lalitesh Morishetti", "Anjana Ganesh", "Ashish Ranjan", "Aashika Padmanabhan", "Jianpeng Xu", "Jason Cho", "Praveen Kanumala", "Kaushiki Nag", "Sumit Dutta", "Kamiya Motwani", "Malay Patel", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "title": "GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization", "comment": "10 pages, 5 figures, The ACM Conference on Recommender Systems\n  (RecSys) 2025", "summary": "Generative models have recently demonstrated strong potential in\nmulti-behavior recommendation systems, leveraging the expressive power of\ntransformers and tokenization to generate personalized item sequences. However,\ntheir adoption is hindered by (1) the lack of explicit information for token\nreasoning, (2) high computational costs due to quadratic attention complexity\nand dense sequence representations after tokenization, and (3) limited\nmulti-scale modeling over user history. In this work, we propose GRACE\n(Generative Recommendation via journey-aware sparse Attention on\nChain-of-thought tokEnization), a novel generative framework for multi-behavior\nsequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)\ntokenization method that encodes user-item interactions with explicit\nattributes from product knowledge graphs (e.g., category, brand, price) over\nsemantic tokenization, enabling interpretable and behavior-aligned generation.\nTo address the inefficiency of standard attention, we design a Journey-Aware\nSparse Attention (JSA) mechanism, which selectively attends to compressed,\nintra-, inter-, and current-context segments in the tokenized sequence.\nExperiments on two real-world datasets show that GRACE significantly\noutperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and\n+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home\ndomain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces\nattention computation by up to 48% with long sequences.", "AI": {"tldr": "GRACE\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u884c\u4e3a\u63a8\u8350\u7684\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7CoT\u6807\u8bb0\u5316\u548cJSA\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u591a\u884c\u4e3a\u63a8\u8350\u7cfb\u7edf\u4e2d\u867d\u7136\u6709\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\uff081\uff09\u7f3a\u4e4f\u7528\u4e8e\u6807\u8bb0\u63a8\u7406\u7684\u663e\u5f0f\u4fe1\u606f\uff1b\uff082\uff09\u6807\u8bb0\u5316\u540e\u7531\u4e8e\u4e8c\u6b21\u6ce8\u610f\u529b\u590d\u6742\u6027\u548c\u5bc6\u96c6\u5e8f\u5217\u8868\u793a\u5bfc\u81f4\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\uff1b\uff083\uff09\u7528\u6237\u5386\u53f2\u7684\u591a\u5c3a\u5ea6\u5efa\u6a21\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGRACE\uff08Generative Recommendation via journey-aware sparse Attention on Chain-of-thought tokEnization\uff09\u7684\u65b0\u578b\u751f\u6210\u63a8\u8350\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5f15\u5165\u4e86\u6df7\u5408\u601d\u7ef4\u94fe\uff08CoT\uff09\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u7528\u6237-\u9879\u4ea4\u4e92\u548c\u6765\u81ea\u4ea7\u54c1\u77e5\u8bc6\u56fe\u8c31\uff08\u5982\u7c7b\u522b\u3001\u54c1\u724c\u3001\u4ef7\u683c\uff09\u7684\u663e\u5f0f\u5c5e\u6027\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u548c\u884c\u4e3a\u5bf9\u9f50\u7684\u751f\u6210\u3002\u4e3a\u4e86\u89e3\u51b3\u6807\u51c6\u6ce8\u610f\u529b\u7684\u6548\u7387\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u65c5\u7a0b\u611f\u77e5\u7a00\u758f\u6ce8\u610f\u529b\uff08JSA\uff09\u673a\u5236\uff0c\u9009\u62e9\u6027\u5730\u5173\u6ce8\u6807\u8bb0\u5316\u5e8f\u5217\u4e2d\u7684\u538b\u7f29\u3001\u5185\u90e8\u3001\u5916\u90e8\u548c\u5f53\u524d\u4e0a\u4e0b\u6587\u7247\u6bb5\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGRACE\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u3002\u5728\u5bb6\u5ead\u9886\u57df\uff0c\u5176HR@10\u548cNDCG@10\u7684\u63d0\u5347\u9ad8\u8fbe+106.9%\u548c+106.7%\uff1b\u5728\u7535\u5b50\u4ea7\u54c1\u9886\u57df\uff0cHR@10\u63d0\u5347\u4e86+22.1%\u3002\u6b64\u5916\uff0cGRACE\u8fd8\u5c06\u957f\u5e8f\u5217\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u91cf\u51cf\u5c11\u4e86\u9ad8\u8fbe48%\u3002", "conclusion": "GRACE\u6846\u67b6\u901a\u8fc7\u6df7\u5408\u601d\u7ef4\u94fe\uff08CoT\uff09\u6807\u8bb0\u5316\u65b9\u6cd5\u548c\u5173\u6ce8\u538b\u7f29\u3001\u5185\u90e8\u3001\u5916\u90e8\u548c\u5f53\u524d\u4e0a\u4e0b\u6587\u7247\u6bb5\u7684\u65c5\u7a0b\u611f\u77e5\u7a00\u758f\u6ce8\u610f\u529b\uff08JSA\uff09\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u591a\u884c\u4e3a\u63a8\u8350\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2507.14208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14208", "abs": "https://arxiv.org/abs/2507.14208", "authors": ["Mohammadreza F. Imani", "Alexander L. Colson", "Leslie K. Miller", "Jorge A. Valdez", "Jose C. Sanchez", "Richard F. Rader"], "title": "Toward intelligent wireless networks in computer chassis", "comment": "9 pages, 5 figures", "summary": "Processing the exponentially growing amount of data produced daily requires\nefficient communication between different processing units in a computer.\nTraditionally, wired interconnects have been used to maintain these data links\ndue to their energy efficiency and ability to support high data rates. However,\nas computing demands continue to increase in size and speed, these wired\ninterconnects can become longer and less effective. One possible solution is to\nenhance the wired interconnects with short-range wireless communication (SRWC),\nwhich offers flexible resource allocation and the ability to broadcast data.\nHowever, implementing SRWC inside a computer chassis presents challenges due to\nmultiple scattering. This scattering stretches the channel impulse response\n(CIR), leading to inter-symbol interference (ISI) and limiting data rates. To\naddress this issue, we propose transforming the computer chassis into a smart\nradio environment by utilizing a reconfigurable intelligent surface (RIS). The\nRIS elements adjust the phase of reflected waves so that the multipath\ncomponents combine at the receiver in a way that creates a pulse-like CIR. This\napproach has been experimentally validated within a typical computer chassis.\nThe results of this study pave the way for integrating RIS-enabled SRWC to\nenhance wireless links in both current and future data processing units.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528RIS\u6280\u672f\u6539\u9020\u8ba1\u7b97\u673a\u673a\u7bb1\uff0c\u89e3\u51b3\u4e86\u65e0\u7ebf\u901a\u4fe1\u7684\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u4f20\u8f93\u901f\u7387\u3002", "motivation": "\u4f20\u7edf\u6709\u7ebf\u4e92\u8fde\u5728\u8ba1\u7b97\u673a\u5185\u90e8\u968f\u7740\u8ba1\u7b97\u9700\u6c42\u7684\u589e\u957f\u800c\u53d8\u5f97\u66f4\u957f\u4e14\u6548\u7387\u964d\u4f4e\uff0c\u800c\u77ed\u8ddd\u79bb\u65e0\u7ebf\u901a\u4fe1\uff08SRWC\uff09\u867d\u7136\u7075\u6d3b\u4f46\u9762\u4e34\u591a\u5f84\u6563\u5c04\u5bfc\u81f4\u7684\u7b26\u53f7\u95f4\u5e72\u6270\uff08ISI\uff09\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6570\u636e\u901f\u7387\u3002", "method": "\u63d0\u51fa\u5229\u7528\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8c03\u6574\u53cd\u5c04\u6ce2\u76f8\u4f4d\uff0c\u4f7f\u591a\u5f84\u5206\u91cf\u5728\u63a5\u6536\u7aef\u53e0\u52a0\u5f62\u6210\u7c7b\u4f3c\u8109\u51b2\u7684\u4fe1\u9053\u51b2\u6fc0\u54cd\u5e94\uff08CIR\uff09\uff0c\u4ee5\u5e94\u5bf9\u8ba1\u7b97\u673a\u673a\u7bb1\u5185\u90e8\u77ed\u8ddd\u79bb\u65e0\u7ebf\u901a\u4fe1\uff08SRWC\uff09\u4e2d\u7684\u591a\u5f84\u6563\u5c04\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5178\u578b\u8ba1\u7b97\u673a\u673a\u7bb1\u5185\u6210\u529f\u5730\u5c06CIR\u6539\u9020\u6210\u8109\u51b2\u72b6\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u589e\u5f3a\u8ba1\u7b97\u673a\u5185\u90e8\u65e0\u7ebf\u94fe\u8def\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5229\u7528\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u5c06\u8ba1\u7b97\u673a\u673a\u7bb1\u6539\u9020\u6210\u667a\u80fd\u65e0\u7ebf\u7535\u73af\u5883\uff0c\u4ee5\u89e3\u51b3\u77ed\u8ddd\u79bb\u65e0\u7ebf\u901a\u4fe1\uff08SRWC\uff09\u4e2d\u7684\u591a\u5f84\u6563\u5c04\u548c\u7b26\u53f7\u95f4\u5e72\u6270\uff08ISI\uff09\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u6570\u636e\u4f20\u8f93\u901f\u7387\u3002\u5b9e\u9a8c\u5df2\u5728\u5178\u578b\u8ba1\u7b97\u673a\u673a\u7bb1\u5185\u5f97\u5230\u9a8c\u8bc1\uff0c\u4e3a\u5728\u6570\u636e\u5904\u7406\u5355\u5143\u4e2d\u96c6\u6210RIS\u652f\u6301\u7684SRWC\u4ee5\u589e\u5f3a\u65e0\u7ebf\u94fe\u8def\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2507.15604", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15604", "abs": "https://arxiv.org/abs/2507.15604", "authors": ["Johannes Hartwig", "Philipp Lienhardt", "Dominik Henrich"], "title": "Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding", "comment": "Accepted for publication in Annals of Scientific Society for\n  Assembly, Handling and Industrial Robotics 2025 (to appear)", "summary": "As the availability of cobots increases, it is essential to address the needs\nof users with little to no programming knowledge to operate such systems\nefficiently. Programming concepts often use intuitive interaction modalities,\nsuch as hand guiding, to address this. When programming in-contact motions,\nsuch frameworks require knowledge of the robot tool's payload inertial\nparameters (PIP) in addition to the demonstrated velocities and forces to\nensure effective hybrid motion-force control. This paper aims to enable\nnon-expert users to program in-contact motions more efficiently by eliminating\nthe need for a dedicated PIP calibration, thereby enabling flexible robot tool\nchanges. Since demonstrated tasks generally also contain motions with\nnon-contact, our approach uses these parts to estimate the robot's PIP using\nestablished estimation techniques. The results show that the estimation of the\npayload's mass is accurate, whereas the center of mass and the inertia tensor\nare affected by noise and a lack of excitation. Overall, these findings show\nthe feasibility of PIP estimation during hand guiding but also highlight the\nneed for sufficient payload accelerations for an accurate estimation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u673a\u5668\u4eba\u624b\u52a8\u5f15\u5bfc\u8fc7\u7a0b\u4e2d\u4f30\u8ba1\u5176\u6709\u6548\u8f7d\u8377\u53c2\u6570\uff08PIP\uff09\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4e13\u95e8\u7684\u6821\u51c6\u6b65\u9aa4\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4efb\u52a1\u4e2d\u7684\u975e\u63a5\u89e6\u8fd0\u52a8\u6765\u4f30\u8ba1PIP\uff0c\u4f46\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u8d28\u91cf\u4f30\u8ba1\u51c6\u786e\uff0c\u4f46\u8d28\u5fc3\u548c\u60ef\u6027\u5f20\u91cf\u7684\u4f30\u8ba1\u4f1a\u53d7\u5230\u566a\u58f0\u548c\u6fc0\u52b1\u4e0d\u8db3\u7684\u5f71\u54cd\uff0c\u8fd9\u8868\u660e\u9700\u8981\u8db3\u591f\u7684\u6709\u6548\u8f7d\u8377\u52a0\u901f\u5ea6\u624d\u80fd\u8fdb\u884c\u51c6\u786e\u4f30\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u7f3a\u4e4f\u7f16\u7a0b\u77e5\u8bc6\u7684\u975e\u4e13\u4e1a\u7528\u6237\u80fd\u591f\u66f4\u6709\u6548\u5730\u5bf9\u534f\u4f5c\u673a\u5668\u4eba\u8fdb\u884c\u793a\u6559\u7f16\u7a0b\uff0c\u9700\u8981\u6d88\u9664\u5bf9\u4e13\u7528PIP\u6821\u51c6\u7684\u9700\u6c42\uff0c\u4ece\u800c\u5b9e\u73b0\u7075\u6d3b\u7684\u673a\u5668\u4eba\u5de5\u5177\u66f4\u6362\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u6f14\u793a\u4efb\u52a1\u4e2d\u5305\u542b\u7684\u975e\u63a5\u89e6\u8fd0\u52a8\u90e8\u5206\uff0c\u5229\u7528\u5df2\u5efa\u7acb\u7684\u4f30\u8ba1\u6280\u672f\u6765\u4f30\u8ba1\u673a\u5668\u4eba\u7684PIP\u3002", "result": "\u4f30\u8ba1\u7ed3\u679c\u8868\u660e\uff0c\u6709\u6548\u8f7d\u8377\u8d28\u91cf\u7684\u4f30\u8ba1\u662f\u51c6\u786e\u7684\uff0c\u800c\u8d28\u5fc3\u548c\u60ef\u6027\u5f20\u91cf\u5219\u53d7\u5230\u566a\u58f0\u548c\u7f3a\u4e4f\u6fc0\u52b1\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u5728\u624b\u52a8\u5f15\u5bfc\u8fc7\u7a0b\u4e2d\u8fdb\u884cPIP\u4f30\u8ba1\u7684\u53ef\u884c\u6027\uff0c\u4f46\u4e5f\u5f3a\u8c03\u4e86\u51c6\u786e\u4f30\u8ba1\u9700\u8981\u8db3\u591f\u7684\u6709\u6548\u8f7d\u8377\u52a0\u901f\u5ea6\u3002"}}
{"id": "2507.14632", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14632", "abs": "https://arxiv.org/abs/2507.14632", "authors": ["Haiquan Wen", "Tianxiao Li", "Zhenglin Huang", "Yiwei He", "Guangliang Cheng"], "title": "BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM", "comment": null, "summary": "Recent advances in generative AI have dramatically improved image and video\nsynthesis capabilities, significantly increasing the risk of misinformation\nthrough sophisticated fake content. In response, detection methods have evolved\nfrom traditional approaches to multimodal large language models (MLLMs),\noffering enhanced transparency and interpretability in identifying synthetic\nmedia. However, current detection systems remain fundamentally limited by their\nsingle-modality design. These approaches analyze images or videos separately,\nmaking them ineffective against synthetic content that combines multiple media\nformats. To address these challenges, we introduce \\textbf{BusterX++}, a novel\nframework designed specifically for cross-modal detection and explanation of\nsynthetic media. Our approach incorporates an advanced reinforcement learning\n(RL) post-training strategy that eliminates cold-start. Through Multi-stage\nTraining, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and\nsubstantial performance improvements. To enable comprehensive evaluation, we\nalso present \\textbf{GenBuster++}, a cross-modal benchmark leveraging\nstate-of-the-art image and video generation techniques. This benchmark\ncomprises 4,000 images and video clips, meticulously curated by human experts\nusing a novel filtering methodology to ensure high quality, diversity, and\nreal-world applicability. Extensive experiments demonstrate the effectiveness\nand generalizability of our approach.", "AI": {"tldr": "BusterX++ \u6846\u67b6\u901a\u8fc7\u8de8\u6a21\u6001\u68c0\u6d4b\u548c RL \u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5408\u6210\u5a92\u4f53\u68c0\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728 GenBuster++ \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u679c\u3002", "motivation": "\u5f53\u524d\u7684\u5408\u6210\u5a92\u4f53\u68c0\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u7ed3\u5408\u591a\u79cd\u5a92\u4f53\u683c\u5f0f\u7684\u5408\u6210\u5185\u5bb9\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e3b\u8981\u57fa\u4e8e\u5355\u6a21\u6001\u8bbe\u8ba1\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u8de8\u6a21\u6001\u68c0\u6d4b\u548c\u89e3\u91ca\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a BusterX++ \u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60 (RL) \u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u3001\u601d\u7ef4\u5956\u52b1\u548c\u6df7\u5408\u63a8\u7406\u6765\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u5355\u6a21\u6001\u68c0\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "BusterX++ \u5728 GenBuster++ \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u7a33\u5b9a\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8be5\u57fa\u51c6\u5305\u542b 4,000 \u4e2a\u7531\u4eba\u7c7b\u4e13\u5bb6\u7cbe\u5fc3\u7b56\u5212\u7684\u56fe\u50cf\u548c\u89c6\u9891\u526a\u8f91\uff0c\u786e\u4fdd\u4e86\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6027\u3002", "conclusion": "BusterX++ \u6846\u67b6\u5728\u8de8\u6a21\u6001\u5408\u6210\u5a92\u4f53\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.14528", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14528", "abs": "https://arxiv.org/abs/2507.14528", "authors": ["Ilias Tsoumas", "Dimitrios Bormpoudakis", "Vasileios Sitokonstantinou", "Athanasios Askitopoulos", "Andreas Kalogeras", "Charalampos Kontoes", "Ioannis Athanasiadis"], "title": "Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference", "comment": "Accepted at KDD 2025 Workshop on Causal Inference and Machine\n  Learning in Practice", "summary": "In causal inference, whether through randomized controlled trials or\nobservational studies, access to both treated and control units is essential\nfor estimating the effect of a treatment on an outcome of interest. When\ntreatment assignment is random, the average treatment effect (ATE) can be\nestimated directly by comparing outcomes between groups. In non-randomized\nsettings, various techniques are employed to adjust for confounding and\napproximate the counterfactual scenario to recover an unbiased ATE. A common\nchallenge, especially in observational studies, is the absence of units clearly\nlabeled as controls-that is, units known not to have received the treatment. To\naddress this, we propose positive-unlabeled (PU) learning as a framework for\nidentifying, with high confidence, control units from a pool of unlabeled ones,\nusing only the available treated (positive) units. We evaluate this approach\nusing both simulated and real-world data. We construct a causal graph with\ndiverse relationships and use it to generate synthetic data under various\nscenarios, assessing how reliably the method recovers control groups that allow\nestimates of true ATE. We also apply our approach to real-world data on optimal\nsowing and fertilizer treatments in sustainable agriculture. Our findings show\nthat PU learning can successfully identify control (negative) units from\nunlabeled data based only on treated units and, through the resulting control\ngroup, estimate an ATE that closely approximates the true value. This work has\nimportant implications for observational causal inference, especially in fields\nwhere randomized experiments are difficult or costly. In domains such as earth,\nenvironmental, and agricultural sciences, it enables a plethora of\nquasi-experiments by leveraging available earth observation and climate data,\nparticularly when treated units are available but control units are lacking.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15687", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15687", "abs": "https://arxiv.org/abs/2507.15687", "authors": ["Denan Li", "Haofei Ni", "Yi Zhang", "Shi Liu"], "title": "Giant Reversible Piezoelectricity from Symmetry-Governed Stochastic Dipole Hopping", "comment": "16 pages, 4 figures", "summary": "Organic--inorganic hybrid perovskites with giant piezoelectric responses,\nexemplified by TMCM-CdCl$_3$, represent a promising platform for flexible and\nenvironmentally friendly electromechanical materials. However, the microscopic\norigin of such exceptional performance in this weakly polar system has remained\nelusive. Here, using deep-learning-assisted large-scale molecular dynamics\nsimulations, we resolve this paradox by reproducing the experimentally measured\npiezoelectric coefficient $d_{33} \\approx 220$~pC/N, and demonstrating that the\ngiant response arises from the collective contribution of multiple intrinsic\ncomponents, particularly the shear component $d_{15}$. This effect does not\nstem from conventional polarization rotation or phase switching, but instead\noriginates from stochastic 120$^\\circ$ in-plane rotational hopping of a small\nfraction of organic cations. This discrete hopping mechanism is governed by the\nlocal C$_3$-symmetric halogen-bonding network between the host framework and\nthe guest cation. The Arrhenius-type temperature dependence of $d_{15}$ further\nconfirms the role of thermally activated dipole hopping. This work provides a\nclear pathway to enhance piezoelectric performance of hybrid materials through\nrational engineering of host--guest interactions.", "AI": {"tldr": "\u6742\u5316\u9499\u949b\u77ff\u7684\u5de8\u538b\u7535\u54cd\u5e94\u6e90\u4e8e\u6709\u673a\u9633\u79bb\u5b50\u7684\u65cb\u8f6c\u8df3\u8dc3\uff0c\u800c\u975e\u6781\u5316\u65cb\u8f6c\u6216\u76f8\u53d8\u3002", "motivation": "\u89e3\u91ca\u6709\u673a-\u65e0\u673a\u6742\u5316\u9499\u949b\u77ff\uff08\u5982TMCM-CdCl3\uff09\u5de8\u538b\u7535\u54cd\u5e94\u7684\u5fae\u89c2\u8d77\u6e90\uff0c\u56e0\u5176\u5728\u5f31\u6781\u6027\u4f53\u7cfb\u4e2d\u7684\u5f02\u5e38\u8868\u73b0\u800c\u96be\u4ee5\u7406\u89e3\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u8f85\u52a9\u7684\u5927\u89c4\u6a21\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u7814\u7a76\u4e86TMCM-CdCl3\u7684\u538b\u7535\u54cd\u5e94\u673a\u5236\u3002", "result": "\u6210\u529f\u590d\u73b0\u4e86\u5b9e\u9a8c\u6d4b\u91cf\u7684\u538b\u7535\u7cfb\u6570 $d_{33} \\approx 220$~pC/N\uff0c\u5e76\u8bc1\u660e\u4e86\u5de8\u538b\u7535\u54cd\u5e94\u4e3b\u8981\u5f52\u56e0\u4e8e\u6709\u673a\u9633\u79bb\u5b50\uff08\u7279\u522b\u662fC3\u5bf9\u79f0\u6027\u5364\u952e\u7f51\u7edc\u4e2d\u7684\u6709\u673a\u9633\u79bb\u5b50\uff09\u7684120\u00b0\u5e73\u9762\u5185\u65cb\u8f6c\u8df3\u8dc3\uff0c\u800c\u975e\u4f20\u7edf\u7684\u6781\u5316\u65cb\u8f6c\u6216\u76f8\u53d8\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u8f85\u52a9\u7684\u5927\u89c4\u6a21\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u63ed\u793a\u4e86TMCM-CdCl3\u7b49\u6709\u673a-\u65e0\u673a\u6742\u5316\u9499\u949b\u77ff\u4e2d\u5de8\u538b\u7535\u54cd\u5e94\u7684\u8d77\u6e90\uff0c\u53d1\u73b0\u5176\u6e90\u4e8e\u6709\u673a\u9633\u79bb\u5b50\u7684\u96c6\u4f53\u8d21\u732e\uff0c\u7279\u522b\u662f120\u00b0\u5e73\u9762\u5185\u65cb\u8f6c\u8df3\u8dc3\uff0c\u5e76\u63d0\u51fa\u53ef\u901a\u8fc7\u8c03\u63a7\u4e3b\u5ba2\u4f53\u76f8\u4e92\u4f5c\u7528\u6765\u63d0\u5347\u538b\u7535\u6027\u80fd\u3002"}}
{"id": "2507.15148", "categories": ["quant-ph", "math-ph", "math.MP", "physics.chem-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.15148", "abs": "https://arxiv.org/abs/2507.15148", "authors": ["Timothy Stroschein", "Davide Castaldo", "Markus Reiher"], "title": "Ground and excited-state energies with analytic errors and short time evolution on a quantum computer", "comment": "38 pages, 6 figures, 1 table", "summary": "Accurately solving the Schr\\\"odinger equation remains a central challenge in\ncomputational physics, chemistry, and materials science. Here, we propose an\nalternative eigenvalue problem based on a system's autocorrelation function,\navoiding direct reference to a wave function. In particular, we develop a\nrigorous approximation framework that enables precise frequency estimation from\na finite number of signal samples. Our analysis builds on new results involving\nprolate spheroidal wave functions and yields error bounds that reveal a sharp\naccuracy transition governed by the observation time and spectral density of\nthe signal. These results are very general and thus carry far. As one important\nexample application we consider the quantum computation for molecular systems.\nBy combining our spectral method with a quantum subroutine for signal\ngeneration, we define quantum prolate diagonalization (QPD) - a hybrid\nclassical-quantum algorithm. QPD simultaneously estimates ground and excited\nstate energies within chemical accuracy at the Heisenberg limit. An analysis of\ndifferent input states demonstrates the robustness of the method, showing that\nhigh precision can be retained even under imperfect state preparation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u7b97\u6cd5QPD\uff0c\u7528\u4e8e\u6c42\u89e3\u859b\u5b9a\u8c14\u65b9\u7a0b\uff0c\u80fd\u591f\u4ee5\u5316\u5b66\u7cbe\u5ea6\u540c\u65f6\u4f30\u8ba1\u57fa\u6001\u548c\u6fc0\u53d1\u6001\u80fd\u91cf\uff0c\u5e76\u4e14\u5728\u72b6\u6001\u5236\u5907\u4e0d\u5b8c\u7f8e\u7684\u60c5\u51b5\u4e0b\u4ecd\u7136\u9c81\u68d2\u3002", "motivation": "\u51c6\u786e\u6c42\u89e3\u859b\u5b9a\u8c14\u65b9\u7a0b\u662f\u8ba1\u7b97\u7269\u7406\u3001\u5316\u5b66\u548c\u6750\u6599\u79d1\u5b66\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7cfb\u7edf\u81ea\u76f8\u5173\u51fd\u6570\u7684\u66ff\u4ee3\u7279\u5f81\u503c\u95ee\u9898\uff0c\u907f\u514d\u4e86\u5bf9\u6ce2\u51fd\u6570\u7684\u76f4\u63a5\u5f15\u7528\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e25\u683c\u7684\u8fd1\u4f3c\u6846\u67b6\uff0c\u53ef\u4ee5\u4ece\u6709\u9650\u6570\u91cf\u7684\u4fe1\u53f7\u6837\u672c\u4e2d\u7cbe\u786e\u4f30\u8ba1\u9891\u7387\u3002", "result": "\u5206\u6790\u57fa\u4e8e\u65b0\u7684\u957f\u7403\u5f62\u6ce2\u51fd\u6570\u7ed3\u679c\uff0c\u5e76\u7ed9\u51fa\u8bef\u5dee\u754c\u9650\uff0c\u63ed\u793a\u4e86\u7531\u89c2\u6d4b\u65f6\u95f4\u548c\u4fe1\u53f7\u8c31\u5bc6\u5ea6\u51b3\u5b9a\u7684\u5c16\u9510\u7cbe\u5ea6\u8f6c\u53d8\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u91cf\u5b50\u957f\u7403\u5f62\u5bf9\u89d2\u5316\uff08QPD\uff09\u662f\u4e00\u79cd\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u6d77\u68ee\u5821\u6781\u9650\u5185\u4ee5\u5316\u5b66\u7cbe\u5ea6\u540c\u65f6\u4f30\u8ba1\u57fa\u6001\u548c\u6fc0\u53d1\u6001\u80fd\u91cf\u3002\u4e0d\u540c\u8f93\u5165\u6001\u7684\u5206\u6790\u8868\u660e\uff0c\u5373\u4f7f\u5728\u72b6\u6001\u5236\u5907\u4e0d\u5b8c\u7f8e\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4e5f\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2507.14815", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14815", "abs": "https://arxiv.org/abs/2507.14815", "authors": ["Shoutao Guo", "Shaolei Zhang", "Qingkai Fang", "Zhengrui Ma", "Min Zhang", "Yang Feng"], "title": "FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing", "comment": "The code is at https://github.com/ictnlp/FastLongSpeech. This model\n  is at https://huggingface.co/ICTNLP/FastLongSpeech. The dataset is at\n  https://huggingface.co/datasets/ICTNLP/LongSpeech-Eval", "summary": "The rapid advancement of Large Language Models (LLMs) has spurred significant\nprogress in Large Speech-Language Models (LSLMs), enhancing their capabilities\nin both speech understanding and generation. While existing LSLMs often\nconcentrate on augmenting speech generation or tackling a diverse array of\nshort-speech tasks, the efficient processing of long-form speech remains a\ncritical yet underexplored challenge. This gap is primarily attributed to the\nscarcity of long-speech training datasets and the high computational costs\nassociated with long sequences. To address these limitations, we introduce\nFastLongSpeech, a novel framework designed to extend LSLM capabilities for\nefficient long-speech processing without necessitating dedicated long-speech\ntraining data. FastLongSpeech incorporates an iterative fusion strategy that\ncan compress excessively long-speech sequences into manageable lengths. To\nadapt LSLMs for long-speech inputs, it introduces a dynamic compression\ntraining approach, which exposes the model to short-speech sequences at varying\ncompression ratios, thereby transferring the capabilities of LSLMs to\nlong-speech tasks. To assess the long-speech capabilities of LSLMs, we develop\na long-speech understanding benchmark called LongSpeech-Eval. Experiments show\nthat our method exhibits strong performance in both long-speech and\nshort-speech tasks, while greatly improving inference efficiency.", "AI": {"tldr": "FastLongSpeech\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u538b\u7f29\u548c\u52a8\u6001\u8bad\u7ec3\uff0c\u4f7fLSLM\u80fd\u9ad8\u6548\u5904\u7406\u957f\u8bed\u97f3\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\uff0c\u5e76\u5728\u957f\u77ed\u8bed\u97f3\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684LSLM\u5728\u5904\u7406\u957f\u8bed\u97f3\u65b9\u9762\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u800cFastLongSpeech\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFastLongSpeech\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u8fed\u4ee3\u878d\u5408\u7b56\u7565\u538b\u7f29\u957f\u8bed\u97f3\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u538b\u7f29\u8bad\u7ec3\u65b9\u6cd5\u4f7fLSLM\u9002\u5e94\u957f\u8bed\u97f3\u8f93\u5165\uff0c\u65e0\u9700\u4e13\u95e8\u7684\u957f\u8bed\u97f3\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFastLongSpeech\u5728\u957f\u77ed\u8bed\u97f3\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6027\u80fd\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002", "conclusion": "FastLongSpeech\u6846\u67b6\u80fd\u591f\u6709\u6548\u6269\u5c55\u5927\u578b\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08LSLM\uff09\u5904\u7406\u957f\u8bed\u97f3\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u5728\u957f\u77ed\u8bed\u97f3\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.14210", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14210", "abs": "https://arxiv.org/abs/2507.14210", "authors": ["Jiayuan Wei", "Qingwei Jiang", "Wen Fang", "Mingqing Liu", "Qingwen Liu", "Wen Chen", "Qingqing Wu"], "title": "System Design and Performance Analysis for RIS-assisted Terahertz Self-Alignment Beamforming", "comment": null, "summary": "The widespread deployment of Internet of Things(IoT) devices underscores the\nneed for sustainable wireless solutions capable of simultaneously transferring\nboth energy and information. Terahertz (THz) band-enabled simultaneous wireless\ninformation and power transfer (SWIPT) systems offer ultra-high data rates and\nexpansive bandwidth. However, THz waves are inherently susceptible to severe\npath loss and beam misalignment due to their narrow-beam characteristics. In\nthis context, this paper proposes a reconfigurable intelligent\nsurface(RIS)-assisted transmitter architecture for the THz-SWIPT system, which\nenables end-to-end self-alignment for steady-state transmission. The proposed\nsystem incorporates phase conjugate circuits to achieve self-aligned\nbeamforming, facilitating the dynamic tracking of mobile IoT devices without\nthe need for beam training. Additionally, active amplification within the RIS\narrays compensates for cascaded channel attenuation through an iterative power\ncycle, thereby enhancing the energy transmission efficiency. Theoretical models\nand simulations indicate that the proposed system significantly mitigates\nsidelobe interference, achieving a transmission efficiency of up to 73.26% over\na 2 meter distance with self-alignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRIS\u7684\u592a\u8d6b\u5179SWIPT\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u5bf9\u51c6\u6ce2\u675f\u6210\u5f62\u548c\u6709\u6e90\u653e\u5927\u6280\u672f\u89e3\u51b3\u4e86\u6ce2\u675f\u672a\u5bf9\u51c6\u548c\u8def\u5f84\u635f\u8017\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4f20\u8f93\u6548\u7387\u3002", "motivation": "\u592a\u8d6b\u5179SWIPT\u7cfb\u7edf\u867d\u7136\u5177\u6709\u8d85\u9ad8\u6570\u636e\u901f\u7387\u548c\u5bbd\u5e7f\u5e26\u5bbd\u7684\u4f18\u70b9\uff0c\u4f46\u5176\u56fa\u6709\u7684\u7a84\u6ce2\u675f\u7279\u6027\u5bfc\u81f4\u8def\u5f84\u635f\u8017\u548c\u6ce2\u675f\u672a\u5bf9\u51c6\u95ee\u9898\u4e25\u91cd\uff0c\u9700\u8981\u53ef\u6301\u7eed\u7684\u65e0\u7ebf\u89e3\u51b3\u65b9\u6848\u6765\u540c\u65f6\u4f20\u8f93\u80fd\u91cf\u548c\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u592a\u8d6b\u5179SWIPT\u7cfb\u7edf\u7684\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8f85\u52a9\u53d1\u5c04\u673a\u67b6\u6784\uff0c\u5e76\u5229\u7528\u76f8\u4f4d\u5171\u8f6d\u7535\u8def\u5b9e\u73b0\u81ea\u5bf9\u51c6\u6ce2\u675f\u6210\u5f62\uff0c\u4ee5\u53ca\u901a\u8fc7\u8fed\u4ee3\u529f\u7387\u5faa\u73af\u8fdb\u884c\u6709\u6e90\u653e\u5927\u4ee5\u8865\u507f\u7ea7\u8054\u4fe1\u9053\u8870\u51cf\u3002", "result": "\u7406\u8bba\u6a21\u578b\u548c\u4eff\u771f\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u52a8\u6001\u8ddf\u8e2a\u79fb\u52a8\u7684\u7269\u8054\u7f51\u8bbe\u5907\uff0c\u65e0\u9700\u8fdb\u884c\u6ce2\u675f\u8bad\u7ec3\uff0c\u5e76\u6709\u6548\u8865\u507f\u4fe1\u9053\u8870\u51cf\uff0c\u63d0\u5347\u4e86\u80fd\u91cf\u4f20\u8f93\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u663e\u8457\u51cf\u8f7b\u4e86\u65c1\u74e3\u5e72\u6270\uff0c\u5e76\u57282\u7c73\u8ddd\u79bb\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe73.26%\u7684\u81ea\u5bf9\u51c6\u4f20\u8f93\u6548\u7387\u3002"}}
{"id": "2507.15607", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15607", "abs": "https://arxiv.org/abs/2507.15607", "authors": ["Yanbo Chen", "Yunzhe Tan", "Yaojia Wang", "Zhengzhe Xu", "Junbo Tan", "Xueqian Wang"], "title": "A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning", "comment": "8 pages, 10 figures", "summary": "Autonomous navigation of vehicle-trailer systems is crucial in environments\nlike airports, supermarkets, and concert venues, where various types of\ntrailers are needed to navigate with different payloads and conditions.\nHowever, accurately modeling such systems remains challenging, especially for\ntrailers with castor wheels. In this work, we propose a novel universal\nvehicle-trailer navigation system that integrates a hybrid nominal kinematic\nmodel--combining classical nonholonomic constraints for vehicles and neural\nnetwork-based trailer kinematics--with a lightweight online residual learning\nmodule to correct real-time modeling discrepancies and disturbances.\nAdditionally, we develop a model predictive control framework with a weighted\nmodel combination strategy that improves long-horizon prediction accuracy and\nensures safer motion planning. Our approach is validated through extensive\nreal-world experiments involving multiple trailer types and varying payload\nconditions, demonstrating robust performance without manual tuning or\ntrailer-specific calibration.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u8f66\u8f86-\u62d6\u8f66\u5bfc\u822a\u7cfb\u7edf\uff0c\u4f7f\u7528\u6df7\u5408\u8fd0\u52a8\u5b66\u6a21\u578b\u548c\u5728\u7ebf\u6b8b\u5dee\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5b9e\u73b0\u5b89\u5168\u8fd0\u52a8\u89c4\u5212\u3002", "motivation": "\u81ea\u4e3b\u5bfc\u822a\u8f66\u8f86-\u62d6\u8f66\u7cfb\u7edf\u5728\u673a\u573a\u3001\u8d85\u5e02\u548c\u97f3\u4e50\u4f1a\u573a\u9986\u7b49\u73af\u5883\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\u9700\u8981\u5404\u79cd\u7c7b\u578b\u7684\u62d6\u8f66\u5728\u4e0d\u540c\u8d1f\u8f7d\u548c\u6761\u4ef6\u4e0b\u8fdb\u884c\u5bfc\u822a\u3002\u7136\u800c\uff0c\u51c6\u786e\u5efa\u6a21\u6b64\u7c7b\u7cfb\u7edf\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5e26\u811a\u8f6e\u7684\u62d6\u8f66\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u901a\u7528\u8f66\u8f86-\u62d6\u8f66\u5bfc\u822a\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86\u6df7\u5408\u540d\u4e49\u8fd0\u52a8\u5b66\u6a21\u578b\uff08\u7ed3\u5408\u4e86\u7ecf\u5178\u7684\u975e\u5b8c\u6574\u7ea6\u675f\u548c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u62d6\u8f66\u8fd0\u52a8\u5b66\uff09\u4ee5\u53ca\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5728\u7ebf\u6b8b\u5dee\u5b66\u4e60\u6a21\u5757\uff0c\u7528\u4e8e\u5b9e\u65f6\u6821\u6b63\u6a21\u578b\u5dee\u5f02\u548c\u5e72\u6270\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u5177\u6709\u52a0\u6743\u6a21\u578b\u7ec4\u5408\u7b56\u7565\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u957f\u89c6\u8ddd\u9884\u6d4b\u7684\u51c6\u786e\u6027\u5e76\u786e\u4fdd\u66f4\u5b89\u5168\u7684\u8fd0\u52a8\u89c4\u5212\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u771f\u5b9e\u4e16\u754c\u7684\u5b9e\u9a8c\uff0c\u6d89\u53ca\u591a\u79cd\u62d6\u8f66\u7c7b\u578b\u548c\u4e0d\u540c\u7684\u8d1f\u8f7d\u6761\u4ef6\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5177\u6709\u7a33\u5065\u7684\u6027\u80fd\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u4f18\u6216\u62d6\u8f66\u7279\u5b9a\u7684\u6821\u51c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u6d89\u53ca\u591a\u79cd\u62d6\u8f66\u7c7b\u578b\u548c\u4e0d\u540c\u7684\u8d1f\u8f7d\u6761\u4ef6\uff0c\u5728\u6ca1\u6709\u624b\u52a8\u8c03\u6574\u6216\u62d6\u8f66\u7279\u5b9a\u6821\u51c6\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14643", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14643", "abs": "https://arxiv.org/abs/2507.14643", "authors": ["Jifeng Shen", "Haibo Zhan", "Shaohua Dong", "Xin Zuo", "Wankou Yang", "Haibin Ling"], "title": "Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection", "comment": "submitted on 30/4/2025, Under Major Revision", "summary": "Modern multispectral feature fusion for object detection faces two critical\nlimitations: (1) Excessive preference for local complementary features over\ncross-modal shared semantics adversely affects generalization performance; and\n(2) The trade-off between the receptive field size and computational complexity\npresent critical bottlenecks for scalable feature modeling. Addressing these\nissues, a novel Multispectral State-Space Feature Fusion framework, dubbed\nMS2Fusion, is proposed based on the state space model (SSM), achieving\nefficient and effective fusion through a dual-path parametric interaction\nmechanism. More specifically, the first cross-parameter interaction branch\ninherits the advantage of cross-attention in mining complementary information\nwith cross-modal hidden state decoding in SSM. The second shared-parameter\nbranch explores cross-modal alignment with joint embedding to obtain\ncross-modal similar semantic features and structures through parameter sharing\nin SSM. Finally, these two paths are jointly optimized with SSM for fusing\nmultispectral features in a unified framework, allowing our MS2Fusion to enjoy\nboth functional complementarity and shared semantic space. In our extensive\nexperiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our\nMS2Fusion significantly outperforms other state-of-the-art multispectral object\ndetection methods, evidencing its superiority. Moreover, MS2Fusion is general\nand applicable to other multispectral perception tasks. We show that, even\nwithout specific design, MS2Fusion achieves state-of-the-art results on RGB-T\nsemantic segmentation and RGBT salient object detection, showing its\ngenerality. The source code will be available at\nhttps://github.com/61s61min/MS2Fusion.git.", "AI": {"tldr": "MS2Fusion\u6846\u67b6\u5229\u7528\u72c0\u614b\u7a7a\u9593\u6a21\u578b\uff08SSM\uff09\u901a\u904e\u96d9\u8def\u4ea4\u4e92\u6a5f\u5236\u89e3\u6c7a\u4e86\u591a\u5149\u8b5c\u76ee\u6a19\u6aa2\u6e2c\u4e2d\u7684\u6cdb\u5316\u6027\u548c\u8a08\u7b97\u74f6\u9838\u554f\u984c\uff0c\u5728\u591a\u500b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u53d6\u5f97\u4e86\u512a\u8d8a\u7684\u6027\u80fd\uff0c\u4e26\u5c0d\u5176\u4ed6\u591a\u5149\u8b5c\u611f\u77e5\u4efb\u52d9\u5177\u6709\u901a\u7528\u6027\u3002", "motivation": "\u73fe\u4ee3\u591a\u5149\u8b5c\u7279\u5fb5\u878d\u5408\u5728\u76ee\u6a19\u6aa2\u6e2c\u65b9\u9762\u9762\u81e8\u5169\u500b\u95dc\u9375\u9650\u5236\uff1a1\uff09\u904e\u5ea6\u504f\u597d\u5c40\u90e8\u4e92\u88dc\u7279\u5fb5\u800c\u975e\u8de8\u6a21\u614b\u5171\u4eab\u8a9e\u7fa9\uff0c\u4e0d\u5229\u65bc\u6cdb\u5316\u6027\u80fd\uff1b2\uff09\u611f\u53d7\u91ce\u5927\u5c0f\u8207\u8a08\u7b97\u8907\u96dc\u5ea6\u4e4b\u9593\u7684\u6b0a\u8861\uff0c\u70ba\u53ef\u64f4\u5c55\u7684\u7279\u5fb5\u5efa\u6a21\u5e36\u4f86\u4e86\u95dc\u9375\u74f6\u9838\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u5149\u8b5c\u72c0\u614b\u7a7a\u9593\u7279\u5fb5\u878d\u5408\u6846\u67b6\uff08MS2Fusion\uff09\uff0c\u8a72\u6846\u67b6\u57fa\u65bc\u72c0\u614b\u7a7a\u9593\u6a21\u578b\uff08SSM\uff09\uff0c\u901a\u904e\u96d9\u8def\u53c3\u6578\u4ea4\u4e92\u6a5f\u5236\u5be6\u73fe\u9ad8\u6548\u6709\u6548\u7684\u878d\u5408\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u7b2c\u4e00\u689d\u4ea4\u53c9\u53c3\u6578\u4ea4\u4e92\u5206\u652f\u7e7c\u627f\u4e86\u4ea4\u53c9\u6ce8\u610f\u529b\u5728\u6316\u6398\u4e92\u88dc\u4fe1\u606f\u65b9\u9762\u7684\u512a\u52e2\uff0c\u4e26\u5728SSM\u4e2d\u9032\u884c\u4e86\u8de8\u6a21\u614b\u96b1\u614b\u89e3\u78bc\u3002\u7b2c\u4e8c\u689d\u5171\u4eab\u53c3\u6578\u5206\u652f\u901a\u904e\u53c3\u6578\u5171\u4eab\u7684SSM\uff0c\u5229\u7528\u806f\u5408\u5d4c\u5165\u63a2\u7d22\u8de8\u6a21\u614b\u5c0d\u9f4a\uff0c\u4ee5\u7372\u5f97\u8de8\u6a21\u614b\u7684\u76f8\u4f3c\u8a9e\u7fa9\u7279\u5fb5\u548c\u7d50\u69cb\u3002\u6700\u5f8c\uff0c\u9019\u5169\u500b\u8def\u5f91\u8207SSM\u806f\u5408\u512a\u5316\uff0c\u5728\u7d71\u4e00\u7684\u6846\u67b6\u4e2d\u878d\u5408\u591a\u5149\u8b5c\u7279\u5fb5\uff0c\u4f7fMS2Fusion\u80fd\u5920\u540c\u6642\u4eab\u53d7\u529f\u80fd\u4e92\u88dc\u548c\u5171\u4eab\u8a9e\u7fa9\u7a7a\u9593\u3002", "result": "MS2Fusion\u986f\u8457\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684\u591a\u5149\u8b5c\u76ee\u6a19\u6aa2\u6e2c\u65b9\u6cd5\uff0c\u4e26\u4e14\u5728RGB-T\u8a9e\u7fa9\u5206\u5272\u548cRGBT\u986f\u8457\u76ee\u6a19\u6aa2\u6e2c\u4e0a\u4e5f\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\u3002", "conclusion": "MS2Fusion\u5728FLIR\u3001M3FD\u548cLLVIP\u7b49\u4e3b\u6d41\u57fa\u6e96\u6e2c\u8a66\u4e2d\u986f\u8457\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684\u591a\u5149\u8b5c\u76ee\u6a19\u6aa2\u6e2c\u65b9\u6cd5\uff0c\u8b49\u660e\u4e86\u5176\u512a\u8d8a\u6027\u3002\u6b64\u5916\uff0cMS2Fusion\u5177\u6709\u901a\u7528\u6027\uff0c\u9069\u7528\u65bc\u5176\u4ed6\u591a\u5149\u8b5c\u611f\u77e5\u4efb\u52d9\uff0c\u5373\u4f7f\u6c92\u6709\u7279\u6b8a\u8a2d\u8a08\uff0c\u5728RGB-T\u8a9e\u7fa9\u5206\u5272\u548cRGBT\u986f\u8457\u76ee\u6a19\u6aa2\u6e2c\u4e0a\u4e5f\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\uff0c\u986f\u793a\u4e86\u5176\u901a\u7528\u6027\u3002"}}
{"id": "2507.15225", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15225", "abs": "https://arxiv.org/abs/2507.15225", "authors": ["Yichi Zhou", "Jianqiu Zhao", "Yongxin Zhang", "Bohan Wang", "Siran Wang", "Luoxin Chen", "Jiahui Wang", "Haowei Chen", "Allan Jie", "Xinbo Zhang", "Haocheng Wang", "Luong Trung", "Rong Ye", "Phan Nhat Hoang", "Huishuai Zhang", "Peng Sun", "Hang Li"], "title": "Solving Formal Math Problems by Decomposition and Iterative Reflection", "comment": null, "summary": "General-purpose Large Language Models (LLMs) have achieved remarkable success\nin intelligence, performing comparably to human experts on complex reasoning\ntasks such as coding and mathematical reasoning. However, generating formal\nproofs in specialized languages like Lean 4 remains a significant challenge for\nthese models, limiting their application in complex theorem proving and\nautomated verification. Current approaches typically require specializing\nmodels through fine-tuning on dedicated formal corpora, incurring high costs\nfor data collection and training. In this work, we introduce \\textbf{Delta\nProver}, an agent-based framework that orchestrates the interaction between a\ngeneral-purpose LLM and the Lean 4 proof environment. Delta Prover leverages\nthe reflection and reasoning capabilities of general-purpose LLMs to\ninteractively construct formal proofs in Lean 4, circumventing the need for\nmodel specialization. At its core, the agent integrates two novel,\ninterdependent components: an algorithmic framework for reflective\ndecomposition and iterative proof repair, and a custom Domain-Specific Language\n(DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta\nProver achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test\nbenchmark, surpassing all existing approaches, including those requiring model\nspecialization.} Furthermore, Delta Prover exhibits a significantly stronger\ntest-time scaling law compared to standard Best-of-N proof strategies.\nCrucially, our findings demonstrate that general-purpose LLMs, when guided by\nan effective agentic structure, possess substantial untapped theorem-proving\ncapabilities. This presents a computationally efficient alternative to\nspecialized models for robust automated reasoning in formal environments.", "AI": {"tldr": "Delta Prover \u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u5b83\u5229\u7528\u901a\u7528 LLM \u6765\u8bc1\u660e Lean 4 \u4e2d\u7684\u5b9a\u7406\uff0c\u65e0\u9700\u4e13\u95e8\u5316\u6a21\u578b\uff0c\u5e76\u5728 miniF2F-test \u4e0a\u53d6\u5f97\u4e86 95.9% \u7684\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\uff0c\u901a\u7528 LLM \u5728\u751f\u6210 Lean 4 \u7b49\u4e13\u4e1a\u8bed\u8a00\u4e2d\u7684\u5f62\u5f0f\u5316\u8bc1\u660e\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u590d\u6742\u5b9a\u7406\u8bc1\u660e\u548c\u81ea\u52a8\u9a8c\u8bc1\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u901a\u8fc7\u5728\u4e13\u7528\u5f62\u5f0f\u5316\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u5fae\u8c03\u6765\u5b9e\u73b0\u6a21\u578b\u4e13\u4e1a\u5316\uff0c\u4f46\u6210\u672c\u9ad8\u6602\u3002", "method": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3a Delta Prover \u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u534f\u8c03\u901a\u7528 LLM \u4e0e Lean 4 \u8bc1\u660e\u73af\u5883\u7684\u4ea4\u4e92\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u7528\u4e8e\u53cd\u5c04\u6027\u5206\u89e3\u548c\u8fed\u4ee3\u8bc1\u660e\u4fee\u590d\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u57fa\u4e8e Lean 4 \u7684\u81ea\u5b9a\u4e49\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u6765\u5b9e\u73b0\u5b50\u95ee\u9898\u7ba1\u7406\u3002", "result": "Delta Prover \u5728 miniF2F-test \u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86 95.9% \u7684\u6700\u5148\u8fdb\u6210\u529f\u7387\uff0c\u8d85\u8fc7\u4e86\u5305\u62ec\u9700\u8981\u6a21\u578b\u4e13\u4e1a\u5316\u7684\u65b9\u6cd5\u5728\u5185\u7684\u6240\u6709\u73b0\u6709\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u4e0e\u6807\u51c6\u7684 Best-of-N \u8bc1\u660e\u7b56\u7565\u76f8\u6bd4\uff0cDelta Prover \u5728\u6d4b\u8bd5\u65f6\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u6709\u6548\u7684\u4ee3\u7406\u7ed3\u6784\u5f15\u5bfc\u4e0b\u7684\u901a\u7528\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u5177\u6709\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u4e3a\u5728\u5f62\u5f0f\u5316\u73af\u5883\u4e2d\u8fdb\u884c\u5f3a\u5927\u7684\u81ea\u52a8\u5316\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u4e13\u95e8\u6a21\u578b\u66f4\u5177\u8ba1\u7b97\u6548\u7387\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.14529", "categories": ["cs.LG", "math.OC", "91A16, 68T05, 49N45, 93E20, 46E22"], "pdf": "https://arxiv.org/pdf/2507.14529", "abs": "https://arxiv.org/abs/2507.14529", "authors": ["Berkay Anahtarci", "Can Deha Kariksiz", "Naci Saldi"], "title": "Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games", "comment": null, "summary": "We consider the maximum causal entropy inverse reinforcement learning problem\nfor infinite-horizon stationary mean-field games, in which we model the unknown\nreward function within a reproducing kernel Hilbert space. This allows the\ninference of rich and potentially nonlinear reward structures directly from\nexpert demonstrations, in contrast to most existing inverse reinforcement\nlearning approaches for mean-field games that typically restrict the reward\nfunction to a linear combination of a fixed finite set of basis functions. We\nalso focus on the infinite-horizon cost structure, whereas prior studies\nprimarily rely on finite-horizon formulations. We introduce a Lagrangian\nrelaxation to this maximum causal entropy inverse reinforcement learning\nproblem that enables us to reformulate it as an unconstrained log-likelihood\nmaximization problem, and obtain a solution \\lk{via} a gradient ascent\nalgorithm. To illustrate the theoretical consistency of the algorithm, we\nestablish the smoothness of the log-likelihood objective by proving the\nFr\\'echet differentiability of the related soft Bellman operators with respect\nto the parameters in the reproducing kernel Hilbert space. We demonstrate the\neffectiveness of our method on a mean-field traffic routing game, where it\naccurately recovers expert behavior.", "AI": {"tldr": "This paper presents an inverse reinforcement learning method for infinite-horizon mean-field games that uses reproducing kernel Hilbert spaces to model complex reward functions, overcoming limitations of previous approaches. It employs a Lagrangian relaxation and gradient ascent for efficient solution and proves theoretical consistency through operator differentiability, showing success in a traffic routing game.", "motivation": "To address the limitations of existing inverse reinforcement learning approaches for mean-field games, which typically restrict the reward function to linear combinations of finite basis functions and rely on finite-horizon formulations. This work models the unknown reward function within a reproducing kernel Hilbert space to infer rich and potentially nonlinear reward structures from expert demonstrations in infinite-horizon settings.", "method": "A Lagrangian relaxation is used to reformulate the maximum causal entropy inverse reinforcement learning problem as an unconstrained log-likelihood maximization problem, solved via a gradient ascent algorithm. The theoretical consistency is established by proving the Fr\u00e9chet differentiability of the related soft Bellman operators.", "result": "The method demonstrates effectiveness on a mean-field traffic routing game, accurately recovering expert behavior.", "conclusion": "The proposed method accurately recovers expert behavior in a mean-field traffic routing game."}}
{"id": "2507.15711", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15711", "abs": "https://arxiv.org/abs/2507.15711", "authors": ["Nicholas Winzer"], "title": "Evaluation of hydrogen diffusion and trapping in ferritic steels containing (Ti,Cr)C particles using electrochemical permeation and thermal desorption spectroscopy", "comment": null, "summary": "Hydrogen diffusion and trapping in ferritic steels containing (Ti,Cr)C\nparticles was investigated using electrochemical permeation (EP) and thermal\ndesorption spectroscopy (TDS). The trapping parameters for the test materials\nwere evaluated by fitting the measurements with a finite element model based on\nthe McNabb-Foster equations using least-squares optimisation. The measurements\nshowed that hydrogen diffusion in ferrite is slowed significantly by the\npresence of fine (<5 nm) (Ti,Cr)C particles; coarser particles had little or no\neffect. The TDS measurements were consistent with hydrogen traps with a high\nenergy barrier. The uniqueness of the hydrogen trapping parameters obtained\nusing the fitting procedure was evaluated. It was found that the system was\noverdetermined; the measurements could be fitted with multiple combinations of\ntrapping parameters. Consequently, it was not possible to determine the\nindividual trapping parameters using this procedure. Trapping parameters were\nalso evaluated from TDS measurements by applying Kissinger's equation. Using\nthis procedure a trap binding energy of 0.24 eV was calculated for all\nmaterials, albeit with a high degree of uncertainty.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u7ec6\u5c0f\u7684 (Ti,Cr)C \u9897\u7c92\u4f1a\u51cf\u7f13\u94c1\u7d20\u4f53\u94a2\u4e2d\u7684\u6c22\u6269\u6563\uff0c\u4f46\u7531\u4e8e\u6a21\u578b\u8fc7\u5ea6\u786e\u5b9a\uff0c\u65e0\u6cd5\u7cbe\u786e\u91cf\u5316\u4fd8\u83b7\u53c2\u6570\u3002", "motivation": "\u7814\u7a76\u542b (Ti,Cr)C \u9897\u7c92\u7684\u94c1\u7d20\u4f53\u94a2\u4e2d\u6c22\u7684\u6269\u6563\u548c\u4fd8\u83b7\u884c\u4e3a\uff0c\u4ee5\u4e86\u89e3\u8fd9\u4e9b\u9897\u7c92\u5bf9\u6c22\u6269\u6563\u548c\u4fd8\u83b7\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u7535\u5316\u5b66\u6e17\u900f\uff08EP\uff09\u548c\u70ed\u89e3\u5438\u5149\u8c31\uff08TDS\uff09\u7814\u7a76\u6c22\u6269\u6563\u548c\u4fd8\u83b7\u3002\u4f7f\u7528\u57fa\u4e8e\u9ea6\u514b\u7eb3\u5e03-\u798f\u65af\u7279\u65b9\u7a0b\u7684\u6709\u9650\u5143\u6a21\u578b\u548c\u6700\u5c0f\u4e8c\u4e58\u4f18\u5316\u6765\u62df\u5408\u6d4b\u91cf\u6570\u636e\uff0c\u4ee5\u8bc4\u4f30\u4fd8\u83b7\u53c2\u6570\u3002\u53e6\u5916\uff0c\u4f7f\u7528\u57fa\u8f9b\u683c\u65b9\u7a0b\u4ece TDS \u6d4b\u91cf\u4e2d\u8bc4\u4f30\u4fd8\u83b7\u53c2\u6570\u3002", "result": "\u542b\u7ec6\u5c0f (<5 nm) (Ti,Cr)C \u9897\u7c92\u7684\u94c1\u7d20\u4f53\u94a2\u7684\u6c22\u6269\u6563\u660e\u663e\u51cf\u6162\u3002TDS \u6d4b\u91cf\u7ed3\u679c\u4e0e\u5177\u6709\u9ad8\u80fd\u5792\u7684\u6c22\u9677\u9631\u4e00\u81f4\u3002\u901a\u8fc7\u6709\u9650\u5143\u6a21\u578b\u548c\u9ea6\u514b\u7eb3\u5e03-\u798f\u65af\u7279\u65b9\u7a0b\u7684\u62df\u5408\uff0c\u53d1\u73b0\u7cfb\u7edf\u88ab\u8fc7\u5ea6\u786e\u5b9a\uff0c\u65e0\u6cd5\u786e\u5b9a\u5355\u4e2a\u4fd8\u83b7\u53c2\u6570\u3002\u4f7f\u7528\u57fa\u8f9b\u683c\u65b9\u7a0b\u8ba1\u7b97\u51fa\u7684\u7ed3\u5408\u80fd\u4e3a 0.24 eV\uff0c\u4f46\u5b58\u5728\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u6c22\u5728\u94c1\u7d20\u4f53\u94a2\u4e2d\u7684\u6269\u6563\u548c\u4fd8\u83b7\u53d7\u5230\u7ec6\u5c0f (<5 nm) (Ti,Cr)C \u9897\u7c92\u7684\u663e\u8457\u51cf\u7f13\uff0c\u800c\u8f83\u7c97\u5927\u7684\u9897\u7c92\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\u3002\u901a\u8fc7\u6709\u9650\u5143\u6a21\u578b\u548c\u9ea6\u514b\u7eb3\u5e03-\u798f\u65af\u7279\u65b9\u7a0b\u7684\u62df\u5408\uff0c\u8bc4\u4f30\u4e86\u6750\u6599\u7684\u4fd8\u83b7\u53c2\u6570\uff0c\u4f46\u7531\u4e8e\u7cfb\u7edf\u88ab\u8fc7\u5ea6\u786e\u5b9a\uff0c\u65e0\u6cd5\u786e\u5b9a\u5355\u4e2a\u4fd8\u83b7\u53c2\u6570\u3002\u4f7f\u7528\u57fa\u8f9b\u683c\u65b9\u7a0b\u4ece\u70ed\u89e3\u5438\u5149\u8c31\u6d4b\u91cf\u4e2d\u5f97\u51fa\u7684\u4fd8\u83b7\u53c2\u6570\u663e\u793a\u7ed3\u5408\u80fd\u4e3a 0.24 eV\uff0c\u4f46\u5b58\u5728\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2507.15166", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2507.15166", "abs": "https://arxiv.org/abs/2507.15166", "authors": ["Linjun Wang", "Joshua T. Cantin", "Smik Patel", "Ignacio Loaiza", "Rick Huang", "Artur F. Izmaylov"], "title": "Planted Solutions in Quantum Chemistry: Generating Non-Trivial Hamiltonians with Known Ground States", "comment": "15 pages, 6 figures", "summary": "Generating large, non-trivial quantum chemistry test problems with known\nground-state solutions remains a core challenge for benchmarking electronic\nstructure methods. Inspired by planted-solution techniques from combinatorial\noptimization, we introduce four classes of Hamiltonians with embedded,\nretrievable ground states. These Hamiltonians mimic realistic electronic\nstructure problems, support adjustable complexity, and are derived from\nreference systems. Crucially, their ground-state energies can be computed\nexactly, provided the construction parameters are known. To obscure this\nstructure and control perceived complexity, we introduce techniques such as\nkiller operators, balance operators, and random orbital rotations. We showcase\nthis framework using examples based on homogeneous catalysts of industrial\nrelevance and validate tunable difficulty through density matrix\nrenormalization group (DMRG) convergence behavior. Beyond enabling scalable,\nground-truth benchmark generation, our approach offers a controlled setting to\nexplore the limitations of electronic structure methods and investigate how\nHamiltonian structure influences ground state solution difficulty.", "AI": {"tldr": "\u751f\u6210\u5177\u6709\u5df2\u77e5\u57fa\u6001\u7684\u91cf\u5b50\u5316\u5b66\u6d4b\u8bd5\u95ee\u9898\uff0c\u4f7f\u7528\u201cplanted-solution\u201d\u6280\u672f\uff0c\u5e76\u5f15\u5165\u201ckiller\u201d\u7b97\u5b50\u3001\u5e73\u8861\u7b97\u5b50\u548c\u968f\u673a\u8f68\u9053\u65cb\u8f6c\u6765\u63a7\u5236\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u5747\u76f8\u50ac\u5316\u5242\uff0c\u5e76\u901a\u8fc7DMRG\u9a8c\u8bc1\u3002", "motivation": "\u4e3a\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\u751f\u6210\u5177\u6709\u5df2\u77e5\u57fa\u6001\u89e3\u7684\u5927\u578b\u3001\u975e\u5e73\u51e1\u91cf\u5b50\u5316\u5b66\u6d4b\u8bd5\u95ee\u9898\uff0c\u8fd9\u662f\u5bf9\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u6838\u5fc3\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u7ec4\u5408\u4f18\u5316\u4e2d\u201cplanted-solution\u201d\u6280\u672f\u542f\u53d1\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u56db\u7c7b\u5177\u6709\u5d4c\u5165\u5f0f\u3001\u53ef\u68c0\u7d22\u57fa\u6001\u7684\u54c8\u5bc6\u987f\u91cf\u3002\u4e3a\u4e86\u9690\u85cf\u8fd9\u79cd\u7ed3\u6784\u5e76\u63a7\u5236\u611f\u77e5\u590d\u6742\u5ea6\uff0c\u8fd8\u5f15\u5165\u4e86\u8bf8\u5982\u201ckiller\u201d\u7b97\u5b50\u3001\u5e73\u8861\u7b97\u5b50\u548c\u968f\u673a\u8f68\u9053\u65cb\u8f6c\u7b49\u6280\u672f\u3002", "result": "\u5c55\u793a\u4e86\u4f7f\u7528\u57fa\u4e8e\u5de5\u4e1a\u76f8\u5173\u5747\u76f8\u50ac\u5316\u5242\u7684\u793a\u4f8b\uff0c\u5e76\u901a\u8fc7\u5bc6\u5ea6\u77e9\u9635\u91cd\u6574\u5316\u7fa4\uff08DMRG\uff09\u6536\u655b\u884c\u4e3a\u9a8c\u8bc1\u4e86\u53ef\u8c03\u96be\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u53ef\u6269\u5c55\u7684\u3001\u5177\u6709\u5730\u9762\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u80fd\u529b\u7684\u91cf\u5b50\u5316\u5b66\u95ee\u9898\uff0c\u5e76\u4e3a\u63a2\u7d22\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u548c\u7814\u7a76\u54c8\u5bc6\u987f\u91cf\u7ed3\u6784\u5982\u4f55\u5f71\u54cd\u57fa\u6001\u6c42\u89e3\u96be\u5ea6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u63a7\u7684\u73af\u5883\u3002"}}
{"id": "2507.14819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14819", "abs": "https://arxiv.org/abs/2507.14819", "authors": ["Akriti Jain", "Pritika Ramu", "Aparna Garimella", "Apoorv Saxena"], "title": "Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\ntransforming text descriptions or tables to data visualizations via\ninstruction-tuning methods. However, it is not straightforward to apply these\nmethods directly for a more real-world use case of visualizing data from long\ndocuments based on user-given intents, as opposed to the user pre-selecting the\nrelevant content manually. We introduce the task of intent-based chart\ngeneration from documents: given a user-specified intent and document(s), the\ngoal is to generate a chart adhering to the intent and grounded on the\ndocument(s) in a zero-shot setting. We propose an unsupervised, two-staged\nframework in which an LLM first extracts relevant information from the\ndocument(s) by decomposing the intent and iteratively validates and refines\nthis data. Next, a heuristic-guided module selects an appropriate chart type\nbefore final code generation. To assess the data accuracy of the generated\ncharts, we propose an attribution-based metric that uses a structured textual\nrepresentation of charts, instead of relying on visual decoding metrics that\noften fail to capture the chart data effectively. To validate our approach, we\ncurate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from\ntwo domains, finance and scientific, in contrast to the existing datasets that\nare largely limited to parallel text descriptions/ tables and their\ncorresponding charts. We compare our approach with baselines using single-shot\nchart generation using LLMs and query-based retrieval methods; our method\noutperforms by upto $9$ points and $17$ points in terms of chart data accuracy\nand chart type respectively over the best baselines.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u64c5\u957f\u5c06\u6587\u672c\u6216\u8868\u683c\u8f6c\u6362\u4e3a\u53ef\u89c6\u5316\u56fe\u8868\uff0c\u4f46\u5728\u6839\u636e\u7528\u6237\u610f\u56fe\u4ece\u957f\u6587\u6863\u751f\u6210\u56fe\u8868\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u57fa\u4e8e\u610f\u56fe\u7684\u6587\u6863\u56fe\u8868\u751f\u6210\u201d\u7684\u65b0\u4efb\u52a1\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u65e0\u76d1\u7763\u3001\u4e24\u9636\u6bb5\u7684\u6846\u67b6\uff0c\u901a\u8fc7LLM\u63d0\u53d6\u4fe1\u606f\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u9009\u62e9\u56fe\u8868\u7c7b\u578b\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5c5e\u6027\u7684\u6307\u6807\u6765\u8bc4\u4f30\u56fe\u8868\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u51c6\u786e\u6027\u548c\u56fe\u8868\u7c7b\u578b\u9009\u62e9\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u6570\u636e\u53ef\u89c6\u5316\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u6839\u636e\u7528\u6237\u610f\u56fe\u4ece\u957f\u6587\u6863\u4e2d\u751f\u6210\u53ef\u89c6\u5316\u56fe\u8868\uff0c\u56e0\u4e3a\u7528\u6237\u901a\u5e38\u9700\u8981\u624b\u52a8\u9009\u62e9\u76f8\u5173\u5185\u5bb9\u3002", "method": "\u8be5\u6846\u67b6\u9996\u5148\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u4fe1\u606f\uff0c\u901a\u8fc7\u5206\u89e3\u610f\u56fe\u5e76\u8fed\u4ee3\u9a8c\u8bc1\u548c\u4f18\u5316\u6570\u636e\u3002\u63a5\u7740\uff0c\u4e00\u4e2a\u542f\u53d1\u5f0f\u5f15\u5bfc\u6a21\u5757\u9009\u62e9\u5408\u9002\u7684\u56fe\u8868\u7c7b\u578b\uff0c\u6700\u540e\u751f\u6210\u4ee3\u7801\u3002", "result": "\u5728\u91d1\u878d\u548c\u79d1\u5b66\u9886\u57df\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b1,242\u4e2a<\u610f\u56fe, \u6587\u6863, \u56fe\u8868>\u5143\u7ec4\u7684\u6570\u636e\u96c6\u3002\u4e0e\u57fa\u4e8eLLM\u7684\u5355\u6b21\u751f\u6210\u548c\u57fa\u4e8e\u67e5\u8be2\u7684\u68c0\u7d22\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u56fe\u8868\u6570\u636e\u51c6\u786e\u6027\u548c\u56fe\u8868\u7c7b\u578b\u9009\u62e9\u4e0a\u5206\u522b\u63d0\u9ad8\u4e86\u9ad8\u8fbe9\u4e2a\u548c17\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u57fa\u4e8e\u610f\u56fe\u7684\u6587\u6863\u56fe\u8868\u751f\u6210\u201d\u7684\u65b0\u4efb\u52a1\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u65e0\u76d1\u7763\u3001\u4e24\u9636\u6bb5\u7684\u6846\u67b6\u6765\u89e3\u51b3\u5b83\u3002\u8be5\u6846\u67b6\u9996\u5148\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u4fe1\u606f\uff0c\u7136\u540e\u901a\u8fc7\u542f\u53d1\u5f0f\u65b9\u6cd5\u9009\u62e9\u56fe\u8868\u7c7b\u578b\u5e76\u751f\u6210\u4ee3\u7801\u3002"}}
{"id": "2507.14216", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14216", "abs": "https://arxiv.org/abs/2507.14216", "authors": ["Manish Kumar", "Tzu-Hsuan Chou", "Byunghyun Lee", "Nicol\u00f2 Michelusi", "David J. Love", "Yaguang Zhang", "James V. Krogmeier"], "title": "Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems", "comment": "This paper has been submitted to IEEE Transactions on Wireless\n  Communications", "summary": "Low-latency localization is critical in cellular networks to support\nreal-time applications requiring precise positioning. In this paper, we propose\na distributed machine learning (ML) framework for fingerprint-based\nlocalization tailored to cell-free massive multiple-input multiple-output\n(MIMO) systems, an emerging architecture for 6G networks. The proposed\nframework enables each access point (AP) to independently train a Gaussian\nprocess regression model using local angle-of-arrival and received signal\nstrength fingerprints. These models provide probabilistic position estimates\nfor the user equipment (UE), which are then fused by the UE with minimal\ncomputational overhead to derive a final location estimate. This decentralized\napproach eliminates the need for fronthaul communication between the APs and\nthe central processing unit (CPU), thereby reducing latency. Additionally,\ndistributing computational tasks across the APs alleviates the processing\nburden on the CPU compared to traditional centralized localization schemes.\nSimulation results demonstrate that the proposed distributed framework achieves\nlocalization accuracy comparable to centralized methods, despite lacking the\nbenefits of centralized data aggregation. Moreover, it effectively reduces\nuncertainty of the location estimates, as evidenced by the 95\\% covariance\nellipse. The results highlight the potential of distributed ML for enabling\nlow-latency, high-accuracy localization in future 6G networks.", "AI": {"tldr": "\u4e00\u79cd\u7528\u4e8e\u8702\u7a9d\u7f51\u7edc\u7684\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5b9a\u4f4d\u6846\u67b6\uff0c\u53ef\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u5728\u8702\u7a9d\u7f51\u7edc\u4e2d\u5b9e\u73b0\u652f\u6301\u5b9e\u65f6\u5e94\u7528\u6240\u9700\u7684\u4f4e\u5ef6\u8fdf\u5b9a\u4f4d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6307\u7eb9\u5b9a\u4f4d\u7684\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u4e2d\u6bcf\u4e2a\u63a5\u5165\u70b9\uff08AP\uff09\u72ec\u7acb\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6a21\u578b\uff0c\u5229\u7528\u5c40\u90e8\u5230\u8fbe\u89d2\u548c\u63a5\u6536\u4fe1\u53f7\u5f3a\u5ea6\u6307\u7eb9\uff0c\u7136\u540e\u7531\u7528\u6237\u8bbe\u5907\uff08UE\uff09\u878d\u5408\u8fd9\u4e9b\u6a21\u578b\u4ee5\u83b7\u5f97\u6700\u7ec8\u7684\u4f4d\u7f6e\u4f30\u8ba1\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u6846\u67b6\u5b9e\u73b0\u4e86\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u5b9a\u4f4d\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u4f4d\u7f6e\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\uff08\u598295%\u534f\u65b9\u5dee\u692d\u5706\u6240\u793a\uff09\u3002", "conclusion": "\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u6846\u67b6\u5728\u8702\u7a9d\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u7684\u5b9a\u4f4d\uff0c\u5176\u51c6\u786e\u6027\u53ef\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u5e76\u51cf\u5c11\u4e86\u4f4d\u7f6e\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2507.15608", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15608", "abs": "https://arxiv.org/abs/2507.15608", "authors": ["Johannes Hartwig", "Fabian Viessmann", "Dominik Henrich"], "title": "Optimizing Force Signals from Human Demonstrations of In-Contact Motions", "comment": "Accepted for publication in Annals of Scientific Society for\n  Assembly, Handling and Industrial Robotics 2024 (to appear)", "summary": "For non-robot-programming experts, kinesthetic guiding can be an intuitive\ninput method, as robot programming of in-contact tasks is becoming more\nprominent. However, imprecise and noisy input signals from human demonstrations\npose problems when reproducing motions directly or using the signal as input\nfor machine learning methods. This paper explores optimizing force signals to\ncorrespond better to the human intention of the demonstrated signal. We compare\ndifferent signal filtering methods and propose a peak detection method for\ndealing with first-contact deviations in the signal. The evaluation of these\nmethods considers a specialized error criterion between the input and the\nhuman-intended signal. In addition, we analyze the critical parameters'\ninfluence on the filtering methods. The quality for an individual motion could\nbe increased by up to \\SI{20}{\\percent} concerning the error criterion. The\nproposed contribution can improve the usability of robot programming and the\ninteraction between humans and robots.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u673a\u5668\u4eba\u7f16\u7a0b\u4e2d\u6f14\u793a\u529b\u4fe1\u53f7\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ee4\u6ce2\u548c\u5cf0\u503c\u68c0\u6d4b\u6765\u63d0\u9ad8\u4fe1\u53f7\u8d28\u91cf\uff0c\u4ece\u800c\u6539\u5584\u4eba\u673a\u4ea4\u4e92\u3002", "motivation": "\u5bf9\u4e8e\u975e\u673a\u5668\u4eba\u7f16\u7a0b\u4e13\u5bb6\u6765\u8bf4\uff0c\u5728\u8fdb\u884c\u673a\u5668\u4eba\u7f16\u7a0b\u65f6\uff0c\u52a8\u89c9\u5f15\u5bfc\u662f\u4e00\u79cd\u76f4\u89c2\u7684\u8f93\u5165\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u8fdb\u884c\u673a\u5668\u4eba\u7f16\u7a0b\u7684\u63a5\u89e6\u4efb\u52a1\u65f6\u3002\u7136\u800c\uff0c\u4eba\u7c7b\u6f14\u793a\u4e2d\u7684\u8f93\u5165\u4fe1\u53f7\u53ef\u80fd\u4e0d\u7cbe\u786e\u6216\u5e26\u6709\u566a\u58f0\uff0c\u8fd9\u5728\u76f4\u63a5\u590d\u73b0\u8fd0\u52a8\u6216\u5c06\u4fe1\u53f7\u7528\u4f5c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u8f93\u5165\u65f6\u4f1a\u5e26\u6765\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4e0d\u540c\u7684\u4fe1\u53f7\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5904\u7406\u9996\u6b21\u63a5\u89e6\u504f\u5dee\u7684\u5cf0\u503c\u68c0\u6d4b\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86\u5173\u952e\u53c2\u6570\u5bf9\u8fc7\u6ee4\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u5355\u4e2a\u8fd0\u52a8\u7684\u8d28\u91cf\u53ef\u4ee5\u6839\u636e\u9519\u8bef\u6807\u51c6\u63d0\u9ad8\u591a\u8fbe 20%\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u4f18\u5316\u529b\u4fe1\u53f7\u4ee5\u66f4\u597d\u5730\u5339\u914d\u6f14\u793a\u4fe1\u53f7\u4e2d\u7684\u4eba\u7c7b\u610f\u56fe\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u7f16\u7a0b\u7684\u53ef\u7528\u6027\u4ee5\u53ca\u4eba\u673a\u4ea4\u4e92\u7684\u8d28\u91cf\u3002"}}
{"id": "2507.14657", "categories": ["cs.CV", "cs.AI", "68T45", "I.2.10"], "pdf": "https://arxiv.org/pdf/2507.14657", "abs": "https://arxiv.org/abs/2507.14657", "authors": ["Keivan Shariatmadar", "Ahmad Osman"], "title": "AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)", "comment": "24 pages, 9 figures", "summary": "The integration of Artificial Intelligence (AI) into sports officiating\nrepresents a paradigm shift in how decisions are made in competitive\nenvironments. Traditional manual systems, even when supported by Instant Video\nReplay (IVR), often suffer from latency, subjectivity, and inconsistent\nenforcement, undermining fairness and athlete trust. This paper introduces\nFST.ai, a novel AI-powered framework designed to enhance officiating in Sport\nTaekwondo, particularly focusing on the complex task of real-time head kick\ndetection and scoring. Leveraging computer vision, deep learning, and edge\ninference, the system automates the identification and classification of key\nactions, significantly reducing decision time from minutes to seconds while\nimproving consistency and transparency. Importantly, the methodology is not\nlimited to Taekwondo. The underlying framework -- based on pose estimation,\nmotion classification, and impact analysis -- can be adapted to a wide range of\nsports requiring action detection, such as judo, karate, fencing, or even team\nsports like football and basketball, where foul recognition or performance\ntracking is critical. By addressing one of Taekwondo's most challenging\nscenarios -- head kick scoring -- we demonstrate the robustness, scalability,\nand sport-agnostic potential of FST.ai to transform officiating standards\nacross multiple disciplines.", "AI": {"tldr": "FST.ai\u662f\u4e00\u4e2a\u5229\u7528AI\u6280\u672f\uff08\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u6df1\u5ea6\u5b66\u4e60\uff09\u7684\u4f53\u80b2\u88c1\u5224\u6846\u67b6\uff0c\u80fd\u5b9e\u65f6\u51c6\u786e\u5730\u8bc6\u522b\u548c\u8bc4\u5206\u8dc6\u62f3\u9053\u4e2d\u7684\u5934\u8e22\u52a8\u4f5c\uff0c\u5e76\u5c06\u8be5\u6280\u672f\u63a8\u5e7f\u5230\u5176\u4ed6\u4f53\u80b2\u9879\u76ee\u3002", "motivation": "\u4f20\u7edf\u4f53\u80b2\u88c1\u5224\u7cfb\u7edf\u5b58\u5728\u5ef6\u8fdf\u3001\u4e3b\u89c2\u6027\u548c\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5f71\u54cd\u516c\u5e73\u6027\u548c\u8fd0\u52a8\u5458\u4fe1\u4efb\u5ea6\u3002", "method": "\u5229\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u6df1\u5ea6\u5b66\u4e60\u548c\u8fb9\u7f18\u63a8\u7406\u6280\u672f\uff0c\u901a\u8fc7\u59ff\u6001\u4f30\u8ba1\u3001\u8fd0\u52a8\u5206\u7c7b\u548c\u51b2\u51fb\u5206\u6790\u6765\u5b9e\u73b0\u81ea\u52a8\u5316\u52a8\u4f5c\u8bc6\u522b\u4e0e\u5206\u7c7b\u3002", "result": "\u5c06\u51b3\u7b56\u65f6\u95f4\u4ece\u51e0\u5206\u949f\u7f29\u77ed\u5230\u51e0\u79d2\u949f\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5224\u7f5a\u7684\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "FST.ai\u6846\u67b6\u7684\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u4ee5\u53ca\u8de8\u8fd0\u52a8\u7684\u6f5c\u529b\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u6709\u671b\u63d0\u5347\u591a\u4e2a\u9879\u76ee\u7684\u88c1\u5224\u6807\u51c6\u3002"}}
{"id": "2507.15239", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15239", "abs": "https://arxiv.org/abs/2507.15239", "authors": ["Qianchao Wang", "Yuxuan Ding", "Chuanzhen Jia", "Zhe Li", "Yaping Du"], "title": "Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis", "comment": null, "summary": "Novel AI-based arc fault diagnosis models have demonstrated outstanding\nperformance in terms of classification accuracy. However, an inherent problem\nis whether these models can actually be trusted to find arc faults. In this\nlight, this work proposes a soft evaluation indicator that explains the outputs\nof arc fault diagnosis models, by defining the the correct explanation of arc\nfaults and leveraging Explainable Artificial Intelligence and real arc fault\nexperiments. Meanwhile, a lightweight balanced neural network is proposed to\nguarantee competitive accuracy and soft feature extraction score. In our\nexperiments, several traditional machine learning methods and deep learning\nmethods across two arc fault datasets with different sample times and noise\nlevels are utilized to test the effectiveness of the soft evaluation indicator.\nThrough this approach, the arc fault diagnosis models are easy to understand\nand trust, allowing practitioners to make informed and trustworthy decisions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f6f\u8bc4\u4f30\u6307\u6807\u548c\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u63d0\u9ad8AI\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u4fe1\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7528\u6237\u4fe1\u4efb\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f6f\u8bc4\u4f30\u6307\u6807\uff0c\u8be5\u6307\u6807\u901a\u8fc7\u5b9a\u4e49\u7535\u5f27\u6545\u969c\u7684\u6b63\u786e\u89e3\u91ca\uff0c\u5e76\u5229\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u548c\u771f\u5b9e\u7684\u7535\u5f27\u6545\u969c\u5b9e\u9a8c\u6765\u89e3\u91ca\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u7684\u8f93\u51fa\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5e73\u8861\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u4fdd\u8bc1\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u548c\u8f6f\u7279\u5f81\u63d0\u53d6\u5206\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8f6f\u8bc4\u4f30\u6307\u6807\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u548c\u63d0\u5347\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u7684\u53ef\u7406\u89e3\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u5373\u4f7f\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u548c\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4fdd\u6301\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u8f6f\u8bc4\u4f30\u6307\u6807\uff0c\u53ef\u4ee5\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5728\u7535\u5f27\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u7406\u89e3\u6027\uff0c\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u505a\u51fa\u660e\u667a\u4e14\u503c\u5f97\u4fe1\u8d56\u7684\u51b3\u7b56\u3002"}}
{"id": "2507.14560", "categories": ["cs.LG", "cs.CV", "68T07, 05C50, 15A18", "I.2.6; I.2.7; I.5.1"], "pdf": "https://arxiv.org/pdf/2507.14560", "abs": "https://arxiv.org/abs/2507.14560", "authors": ["Giorgio Roffo"], "title": "The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers", "comment": "24 pages, 10 figures, submitted for review. Companion code and\n  reproducibility materials available", "summary": "The self-attention mechanism, now central to deep learning architectures such\nas Transformers, is a modern instance of a more general computational\nprinciple: learning and using pairwise affinity matrices to control how\ninformation flows through a model. This paper traces the conceptual origins of\nself-attention across multiple domains, including computer vision, natural\nlanguage processing, and graph learning, through their shared reliance on an\naffinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)\nas a foundational approach that generalizes the idea of affinity-based\nweighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS\ndefines A either through domain knowledge or by learning, and computes feature\nrelevance through multi-hop propagation over the affinity graph. From this\nperspective, self-attention can be seen as a special case of Inf-FS: it uses a\nsingle-hop affinity computation where A is dynamically built from token\nsimilarities. We argue that the underlying structure, reasoning over pairwise\nrelationships, is preserved across both approaches, and the key differences lie\nin how the affinity matrix is defined and applied. By situating self-attention\nwithin the broader paradigm of affinity-based computation, we unify several\nstrands of machine learning research and highlight a common mathematical\nfoundation that underpins diverse models and tasks.", "AI": {"tldr": "Self-attention, common in Transformers, is a type of affinity-based computation. This paper links it to Infinite Feature Selection (Inf-FS), a more general method using affinity matrices. Key differences are how the matrix is defined and used (single vs. multi-hop steps). This view unifies research by showing a shared basis in pairwise relationships.", "motivation": "The paper aims to trace the conceptual origins of the self-attention mechanism, a key component in modern deep learning, and connect it to a more general computational principle: learning and using pairwise affinity matrices to control information flow. By highlighting Infinite Feature Selection (Inf-FS) as a foundational and generalizable approach, the paper seeks to unify diverse machine learning research strands under a common mathematical foundation.", "method": "The paper traces the conceptual origins of self-attention across computer vision, natural language processing, and graph learning, identifying the shared reliance on pairwise affinity matrices. It highlights Inf-FS as a foundational approach that generalizes affinity-based weighting and contrasts its methods (domain knowledge or learned matrices, multi-hop propagation) with the fixed dot-product structure and single-hop computation of self-attention.", "result": "The analysis reveals that self-attention is a special case of Inf-FS, differing primarily in how the affinity matrix is constructed and utilized (single-hop vs. multi-hop propagation). This perspective unifies various machine learning research areas by identifying a common mathematical foundation in affinity-based computation.", "conclusion": "Self-attention is a specific instance of the broader concept of affinity-based computation, exemplified by Infinite Feature Selection (Inf-FS). The key distinctions lie in the definition and application of the affinity matrix, with self-attention utilizing a single-hop computation based on token similarities, while Inf-FS allows for more general definitions and multi-hop propagation."}}
{"id": "2507.15712", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15712", "abs": "https://arxiv.org/abs/2507.15712", "authors": ["Rosa Almache-Hern\u00e1ndeza", "Gerard Masmitj\u00e0", "Benjam\u00edn Pusay", "Eloi Ros", "Kunal J. Tiwari", "Pedro Vidal-Fuentes", "Victor Izquierdo-Roca", "Edgardo Saucedo", "Crist\u00f3bal Voz", "Joaquim Puigdollers", "Pablo Ortega"], "title": "Fully atomic layer deposited transparent carrier selective contacts for bifacial Cd-free Cu2ZnSnSe4 thin-film solar cells", "comment": "32 pages, 10 figures", "summary": "Thin-film solar cells based on kesterite (Cu2ZnSnSe4) material are a\npromising alternative for photovoltaic devices due to their composition\nconsisting of earth abundant elements, ease of production at a relatively low\ntemperatures and excellent optical absorption properties. Additionally, this\nabsorber compound allows a tuneable bandgap energy in the 1 to 1.5 eV window\nrange, which makes it an attractive candidate either as a top or a bottom solar\ncell in tandem technologies combined with transparent carrier-selective\ncontacts. However, conventional kesterite devices use a toxic CdS layer as an\nelectron-selective contact, resulting in the difficultto-dispose chemical\nwaste. This work explores the use of a stack of ZnO and Al-doped ZnO (AZO)\nfilms deposited by ALD to replace the CdS-based contacts in kesterite devices.\nThe inclusion of a polyethylenimine (PEI) interlayer as dipole to enhance the\noverall electrical contact performance is also discussed. The transparent back\ncontact is formed by an ALD V2Ox thin layer over a FTO conductive electrode.\nFabricated kesterite solar cells exhibit remarkable photocurrent density values\nof 35 mAcm-2, open-circuit voltage around 260 mV and efficiencies up to 3.5%\nusing front illumination. The aforementioned photovoltaic parameters yield to\n5.3 mAcm-2, 160 mV and 0.3% respectively under back illumination, demonstrating\nthe bifaciality of the proposed structure.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528 ZnO/AZO/PEI \u66ff\u4ee3\u4e86 kesterite \u592a\u9633\u80fd\u7535\u6c60\u4e2d\u7684 CdS \u5c42\uff0c\u5e76\u5b9e\u73b0\u4e86\u53cc\u9762\u5149\u4f0f\u5668\u4ef6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf kesterite \u592a\u9633\u80fd\u7535\u6c60\u4e2d\u4f7f\u7528\u6709\u6bd2 CdS \u5c42\u4f5c\u4e3a\u7535\u5b50\u9009\u62e9\u6027\u63a5\u89e6\u5c42\u5e26\u6765\u7684\u73af\u5883\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u73af\u4fdd\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u539f\u5b50\u5c42\u6c89\u79ef (ALD) \u6280\u672f\u5236\u5907 ZnO \u548c Al:ZnO (AZO) \u8584\u819c\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u7535\u5b50\u9009\u62e9\u6027\u63a5\u89e6\u5c42\uff0c\u4ee5\u66ff\u4ee3 kesterite \u592a\u9633\u80fd\u7535\u6c60\u4e2d\u4f7f\u7528\u7684 CdS \u5c42\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u805a\u4e59\u70ef\u4e9a\u80fa (PEI) \u4f5c\u4e3a\u5076\u6781\u5b50\u5c42\u4ee5\u589e\u5f3a\u7535\u5b66\u63a5\u89e6\u6027\u80fd\u3002\u80cc\u90e8\u63a5\u89e6\u5219\u91c7\u7528 ALD V2O5 \u8584\u5c42\u8986\u76d6\u5728 FTO \u5bfc\u7535\u7535\u6781\u4e0a\u3002", "result": "\u5728\u6b63\u9762\u5149\u7167\u4e0b\uff0c\u5236\u5907\u7684 kesterite \u592a\u9633\u80fd\u7535\u6c60\u5b9e\u73b0\u4e86 35 mAcm\u207b\u00b2 \u7684\u5149\u7535\u6d41\u5bc6\u5ea6\u3001\u7ea6 260 mV \u7684\u5f00\u8def\u7535\u538b\u548c\u9ad8\u8fbe 3.5% \u7684\u6548\u7387\u3002\u5728\u80cc\u90e8\u5149\u7167\u4e0b\uff0c\u8fd9\u4e9b\u53c2\u6570\u5206\u522b\u4e3a 5.3 mAcm\u207b\u00b2\u3001160 mV \u548c 0.3%\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u7ed3\u6784\u5177\u6709\u53cc\u9762\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u4f7f\u7528 ZnO \u548c Al:ZnO (AZO) \u8584\u819c\u5806\u53e0\u4ee5\u53ca PEI \u4e92\u5c42\u6765\u66ff\u4ee3 kesterite \u592a\u9633\u80fd\u7535\u6c60\u4e2d\u7684 CdS \u63a5\u89e6\u5c42\uff0c\u5e76\u4f7f\u7528 ALD V2O5 \u8584\u5c42\u4f5c\u4e3a\u900f\u660e\u80cc\u90e8\u63a5\u89e6\u3002"}}
{"id": "2507.15178", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15178", "abs": "https://arxiv.org/abs/2507.15178", "authors": ["Pei-Xi Liu", "Yu-Ping Lin", "Zong-Quan Zhou", "Chuan-Feng Li", "Guang-Can Guo"], "title": "Global-scale quantum networking using hybrid-channel quantum repeaters with relays based on a chain of balloons", "comment": null, "summary": "Global-scale entanglement distribution has been a formidable challenge due to\nthe unavoidable losses in communication channels. Here, we propose a novel\nbackbone channel for quantum network based on balloon-based aerial relays. We\ndemonstrate for the first time that the atmospheric disturbances in\nballoon-based channels can be almost eliminated through optimizing beam waist\npositions and employing a series of adaptive optics systems, which boosts the\nchannel efficiency to -21 dB over a 10,000 km distance, outperforming\nsatellite-based relays by 12 dB with same device parameters. We then propose a\nglobal-scale quantum networking scheme based on hybrid-channel quantum\nrepeaters that combine ground-based quantum repeaters and balloon-based aerial\nrelays. Servers are interconnected globally via a chain of balloons, while\nclients link to local servers through fiber connections, facilitating rapid\nclient switching and network scalability. Our simulations, employing\nstate-of-the-art Eu$^{3+}$:Y$_2$SiO$_5$ quantum memories and mature\nentanglement sources based on spontaneous parametric down-conversion,\ndemonstrate an entanglement distribution rate in the sub-Hertz range between\nclients separated by 10,000 km. This approach offers a practical path toward\nglobal quantum networking in the near future.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6c14\u7403\u4f5c\u4e3a\u4e2d\u7ee7\u5668\u7684\u91cf\u5b50\u7f51\u7edc\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u957f\u8ddd\u79bb\u3001\u9ad8\u6548\u7387\u7684\u7ea0\u7f20\u5206\u53d1\u3002", "motivation": "\u89e3\u51b3\u5168\u7403\u8303\u56f4\u5185\u5206\u53d1\u7ea0\u7f20\u6240\u9762\u4e34\u7684\u901a\u4fe1\u4fe1\u9053\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u635f\u8017\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6c14\u7403\u7684\u7a7a\u4e2d\u4e2d\u7ee7\u9aa8\u5e72\u901a\u9053\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u5149\u675f\u8170\u90e8\u4f4d\u7f6e\u548c\u91c7\u7528\u4e00\u7cfb\u5217\u81ea\u9002\u5e94\u5149\u5b66\u7cfb\u7edf\u51e0\u4e4e\u6d88\u9664\u4e86\u6c14\u7403\u57fa\u901a\u9053\u4e2d\u7684\u5927\u6c14\u6270\u52a8\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u901a\u9053\u91cf\u5b50\u4e2d\u7ee7\u5668\u7684\u5168\u7403\u89c4\u6a21\u91cf\u5b50\u7f51\u7edc\u65b9\u6848\uff0c\u8be5\u4e2d\u7ee7\u5668\u7ed3\u5408\u4e86\u5730\u9762\u91cf\u5b50\u4e2d\u7ee7\u5668\u548c\u6c14\u7403\u57fa\u7a7a\u4e2d\u4e2d\u7ee7\u5668\u3002", "result": "\u4e0e\u5177\u6709\u76f8\u540c\u8bbe\u5907\u53c2\u6570\u7684\u57fa\u7ad9\u4e2d\u7ee7\u76f8\u6bd4\uff0c\u57fa\u4e8e\u6c14\u7403\u7684\u7a7a\u4e2d\u4e2d\u7ee7\u5728 10,000 \u516c\u91cc\u7684\u8ddd\u79bb\u4e0a\u5c06\u4fe1\u9053\u6548\u7387\u63d0\u9ad8\u4e86 12 \u5206\u8d1d\uff0c\u8fbe\u5230\u4e86 -21 \u5206\u8d1d\u3002\u5728 10,000 \u516c\u91cc\u7684\u5ba2\u6237\u7aef\u4e4b\u95f4\u5b9e\u73b0\u4e86\u8d6b\u5179\u8303\u56f4\u4ee5\u4e0b\u7684\u7ea0\u7f20\u5206\u53d1\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u672a\u6765\u51e0\u5e74\u5185\u5b9e\u73b0\u5168\u7403\u91cf\u5b50\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u7684\u9014\u5f84\u3002"}}
{"id": "2507.14849", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14849", "abs": "https://arxiv.org/abs/2507.14849", "authors": ["Yifei Wang"], "title": "Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding", "comment": null, "summary": "Reasoning distillation has emerged as an effective approach to enhance the\nreasoning capabilities of smaller language models. However, the impact of\nlarge-scale reasoning distillation on other critical abilities, particularly\nin-context retrieval and reasoning, remains unexplored. This gap in\nunderstanding is particularly significant given the increasing importance of\nRetrieval-Augmented Generation (RAG) systems, where efficient acquisition and\nutilization of contextual information are paramount for generating reliable\nresponses. Motivated by the need to understand how the extended long-CoT\nprocess influences long-context comprehension, we conduct a comprehensive\ninvestigation using a series of open-source models distilled from Deepseek-R1,\nrenowned for its exceptional reasoning capabilities. Our study focuses on\nevaluating these models' performance in extracting and integrating relevant\ninformation from extended contexts through multi-document question and\nanswering tasks. Through rigorous experimentation, we demonstrate that\ndistilled reasoning patterns significantly improve long-context understanding.\nOur analysis reveals that distillation fosters greater long-context awareness\nby promoting more detailed and explicit reasoning processes during context\nanalysis and information parsing. This advancement effectively mitigates the\npersistent \"lost in the middle\" issue that has hindered long-context models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14220", "categories": ["eess.SP", "cs.LG", "physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2507.14220", "abs": "https://arxiv.org/abs/2507.14220", "authors": ["Haitian Hu", "Wei Zhang", "Feng Feng", "Zhiguo Zhang", "Qi-Jun Zhang"], "title": "Advanced Space Mapping Technique Integrating a Shared Coarse Model for Multistate Tuning-Driven Multiphysics Optimization of Tunable Filters", "comment": null, "summary": "This article introduces an advanced space mapping (SM) technique that applies\na shared electromagnetic (EM)-based coarse model for multistate tuning-driven\nmultiphysics optimization of tunable filters. The SM method combines the\ncomputational efficiency of EM single-physics simulations with the precision of\nmultiphysics simulations. The shared coarse model is based on EM single-physics\nresponses corresponding to various nontunable design parameters values.\nConversely, the fine model is implemented to delineate the behavior of\nmultiphysics responses concerning both nontunable and tunable design parameter\nvalues. The proposed overall surrogate model comprises multiple subsurrogate\nmodels, each consisting of one shared coarse model and two distinct mapping\nneural networks. The responses from the shared coarse model in the EM\nsingle-physics filed offer a suitable approximation for the fine responses in\nthe multiphysics filed, whereas the mapping neural networks facilitate\ntransition from the EM single-physics field to the multiphysics field. Each\nsubsurrogate model maintains consistent nontunable design parameter values but\npossesses unique tunable design parameter values. By developing multiple\nsubsurrogate models, optimization can be simultaneously performed for each\ntuning state. Nontunable design parameter values are constrained by all tuning\nstates, whereas tunable design parameter values are confined to their\nrespective tuning states. This optimization technique simultaneously accounts\nfor all the tuning states to fulfill the necessary multiple tuning state\nrequirements. Multiple EM and multiphysics training samples are generated\nconcurrently to develop the surrogate model. Compared with existing direct\nmultiphysics parameterized modeling techniques, our proposed method achieves\nsuperior multiphysics modeling accuracy with fewer training samples and reduced\ncomputational costs.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u7a7a\u95f4\u6620\u5c04\u6280\u672f\uff0c\u901a\u8fc7\u5171\u4eab\u7684\u7535\u78c1\u7c97\u7565\u6a21\u578b\u548c\u6620\u5c04\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u5bf9\u53ef\u8c03\u8c10\u6ee4\u6ce2\u5668\u7684\u591a\u7269\u7406\u573a\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u9488\u5bf9\u53ef\u8c03\u8c10\u6ee4\u6ce2\u5668\u7684\u591a\u7269\u7406\u573a\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u591a\u72b6\u6001\u8c03\u8c10\u9700\u6c42\u7684\u9ad8\u6548\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u7a7a\u95f4\u6620\u5c04\uff08SM\uff09\u6280\u672f\uff0c\u8be5\u6280\u672f\u91c7\u7528\u5171\u4eab\u7684\u3001\u57fa\u4e8e\u7535\u78c1\uff08EM\uff09\u7684\u7c97\u7565\u6a21\u578b\uff0c\u7528\u4e8e\u591a\u72b6\u6001\u8c03\u8c10\u9a71\u52a8\u7684\u591a\u7269\u7406\u573a\u4f18\u5316\u3002\u8be5SM\u65b9\u6cd5\u7ed3\u5408\u4e86EM\u5355\u7269\u7406\u573a\u4eff\u771f\u7684\u8ba1\u7b97\u6548\u7387\u548c\u591a\u7269\u7406\u573a\u4eff\u771f\u7684\u7cbe\u786e\u5ea6\u3002\u5171\u4eab\u7c97\u7565\u6a21\u578b\u57fa\u4e8e\u5bf9\u5e94\u4e8e\u5404\u79cd\u4e0d\u53ef\u8c03\u8bbe\u8ba1\u53c2\u6570\u503c\u7684EM\u5355\u7269\u7406\u573a\u54cd\u5e94\u3002\u76f8\u53cd\uff0c\u7cbe\u7ec6\u6a21\u578b\u7528\u4e8e\u63cf\u8ff0\u591a\u7269\u7406\u573a\u54cd\u5e94\u4e0e\u4e0d\u53ef\u8c03\u548c\u53ef\u8c03\u8bbe\u8ba1\u53c2\u6570\u503c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u63d0\u51fa\u7684\u6574\u4f53\u4ee3\u7406\u6a21\u578b\u7531\u591a\u4e2a\u5b50\u4ee3\u7406\u6a21\u578b\u7ec4\u6210\uff0c\u6bcf\u4e2a\u5b50\u4ee3\u7406\u6a21\u578b\u5305\u542b\u4e00\u4e2a\u5171\u4eab\u7684\u7c97\u7565\u6a21\u578b\u548c\u4e24\u4e2a\u4e0d\u540c\u7684\u6620\u5c04\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u6240\u63d0\u51fa\u7684\u4ee3\u7406\u6a21\u578b\u7531\u591a\u4e2a\u5b50\u4ee3\u7406\u6a21\u578b\u7ec4\u6210\uff0c\u6bcf\u4e2a\u5b50\u4ee3\u7406\u6a21\u578b\u7531\u4e00\u4e2a\u5171\u4eab\u7684\u7c97\u7565\u6a21\u578b\u548c\u4e24\u4e2a\u6620\u5c04\u795e\u7ecf\u7f51\u7edc\u7ec4\u6210\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u591a\u7269\u7406\u573a\u5efa\u6a21\uff0c\u5e76\u540c\u65f6\u4f18\u5316\u6240\u6709\u8c03\u8c10\u72b6\u6001\u3002", "conclusion": "\u4e0e\u73b0\u6709\u7684\u76f4\u63a5\u591a\u7269\u7406\u573a\u53c2\u6570\u5316\u5efa\u6a21\u6280\u672f\u76f8\u6bd4\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8bad\u7ec3\u6837\u672c\u66f4\u5c11\u3001\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u591a\u7269\u7406\u573a\u5efa\u6a21\u7cbe\u5ea6\u3002"}}
{"id": "2507.15649", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15649", "abs": "https://arxiv.org/abs/2507.15649", "authors": ["Haocheng Xu", "Haodong Zhang", "Zhenghan Chen", "Rong Xiong"], "title": "EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation", "comment": null, "summary": "To support humanoid robots in performing manipulation tasks, it is essential\nto study stable standing while accommodating upper-body motions. However, the\nlimited controllable range of humanoid robots in a standing position affects\nthe stability of the entire body. Thus we introduce a reinforcement learning\nbased framework for humanoid robots to imitate human upper-body motions while\nmaintaining overall stability. Our approach begins with designing a retargeting\nnetwork that generates a large-scale upper-body motion dataset for training the\nreinforcement learning (RL) policy, which enables the humanoid robot to track\nupper-body motion targets, employing domain randomization for enhanced\nrobustness. To avoid exceeding the robot's execution capability and ensure\nsafety and stability, we propose an Executable Motion Prior (EMP) module, which\nadjusts the input target movements based on the robot's current state. This\nadjustment improves standing stability while minimizing changes to motion\namplitude. We evaluate our framework through simulation and real-world tests,\ndemonstrating its practical applicability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u5b9a\u5411\u7f51\u7edc\u548c\u53ef\u6267\u884c\u8fd0\u52a8\u5148\u9a8c\uff08EMP\uff09\u6a21\u5757\uff0c\u4f7f\u4eba\u5f62\u673a\u5668\u4eba\u80fd\u591f\u5728\u6a21\u4eff\u4eba\u7c7b\u4e0a\u8eab\u8fd0\u52a8\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u7ad9\u7acb\u7a33\u5b9a\u6027\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u4eba\u5f62\u673a\u5668\u4eba\u5728\u6267\u884c\u64cd\u7eb5\u4efb\u52a1\u65f6\uff0c\u5728\u9002\u5e94\u4e0a\u8eab\u8fd0\u52a8\u7684\u540c\u65f6\u4fdd\u6301\u7a33\u5b9a\u7684\u7ad9\u7acb\uff0c\u4f46\u673a\u5668\u4eba\u7ad9\u7acb\u4f4d\u7f6e\u7684\u53ef\u63a7\u8303\u56f4\u6709\u9650\uff0c\u5f71\u54cd\u4e86\u6574\u4e2a\u8eab\u4f53\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u5305\u62ec\u4e00\u4e2a\u91cd\u5b9a\u5411\u7f51\u7edc\uff0c\u7528\u4e8e\u751f\u6210\u5927\u89c4\u6a21\u4e0a\u8eab\u8fd0\u52a8\u6570\u636e\u96c6\u4ee5\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6267\u884c\u8fd0\u52a8\u5148\u9a8c\uff08EMP\uff09\u6a21\u5757\uff0c\u6839\u636e\u673a\u5668\u4eba\u5f53\u524d\u72b6\u6001\u8c03\u6574\u8f93\u5165\u76ee\u6807\u8fd0\u52a8\uff0c\u4ee5\u63d0\u9ad8\u7ad9\u7acb\u7a33\u5b9a\u6027\u5e76\u5c3d\u91cf\u51cf\u5c11\u8fd0\u52a8\u5e45\u5ea6\u7684\u53d8\u5316\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u8ba9\u673a\u5668\u4eba\u8ddf\u8e2a\u4e0a\u8eab\u8fd0\u52a8\u76ee\u6807\uff0c\u5e76\u901a\u8fc7EMP\u6a21\u5757\u63d0\u9ad8\u4e86\u7ad9\u7acb\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u5c3d\u91cf\u51cf\u5c11\u4e86\u8fd0\u52a8\u5e45\u5ea6\u7684\u53d8\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9645\u6d4b\u8bd5\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u6a21\u4eff\u4eba\u7c7b\u4e0a\u8eab\u8fd0\u52a8\u5e76\u4fdd\u6301\u6574\u4f53\u7a33\u5b9a\u6027\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2507.14662", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14662", "abs": "https://arxiv.org/abs/2507.14662", "authors": ["Shayan Rokhva", "Babak Teimourpour"], "title": "Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall", "comment": "Questions & Recommendations: shayanrokhva1999@gmail.com;\n  shayan1999rokh@yahoo.com", "summary": "Quantifying post-consumer food waste in institutional dining settings is\nessential for supporting data-driven sustainability strategies. This study\npresents a cost-effective computer vision framework that estimates plate-level\nfood waste by utilizing semantic segmentation of RGB images taken before and\nafter meal consumption across five Iranian dishes. Four fully supervised models\n(U-Net, U-Net++, and their lightweight variants) were trained using a capped\ndynamic inverse-frequency loss and AdamW optimizer, then evaluated through a\ncomprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a\ncustom-defined Distributional Pixel Agreement (DPA) metric tailored to the\ntask. All models achieved satisfying performance, and for each food type, at\nleast one model approached or surpassed 90% DPA, demonstrating strong alignment\nin pixel-wise proportion estimates. Lighter models with reduced parameter\ncounts offered faster inference, achieving real-time throughput on an NVIDIA T4\nGPU. Further analysis showed superior segmentation performance for dry and more\nrigid components (e.g., rice and fries), while more complex, fragmented, or\nviscous dishes, such as stews, showed reduced performance, specifically\npost-consumption. Despite limitations such as reliance on 2D imaging,\nconstrained food variety, and manual data collection, the proposed framework is\npioneering and represents a scalable, contactless solution for continuous\nmonitoring of food consumption. This research lays foundational groundwork for\nautomated, real-time waste tracking systems in large-scale food service\nenvironments and offers actionable insights and outlines feasible future\ndirections for dining hall management and policymakers aiming to reduce\ninstitutional food waste.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u98df\u7269\u6d6a\u8d39\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u9910\u524d\u9910\u540e\u56fe\u50cf\u7684\u8bed\u4e49\u5206\u5272\u6765\u4f30\u7b97\u9910\u76d8\u98df\u7269\u6d6a\u8d39\u3002\u8be5\u65b9\u6cd5\u7ecf\u6d4e\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u80fd\u5b9e\u73b0\u5b9e\u65f6\u76d1\u6d4b\uff0c\u5bf9\u5e72\u6027\u98df\u7269\u6548\u679c\u5c24\u4f73\uff0c\u4e3a\u9910\u996e\u4e1a\u51cf\u5c11\u98df\u7269\u6d6a\u8d39\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\u3002", "motivation": "\u91cf\u5316\u673a\u6784\u98df\u5802\u7684\u98df\u7269\u6d6a\u8d39\u5bf9\u4e8e\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\uff0c\u4ee5\u4f30\u7b97\u9910\u76d8\u7ea7\u522b\u7684\u98df\u7269\u6d6a\u8d39\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff0c\u5229\u7528\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\uff0c\u5bf9\u9910\u524d\u9910\u540e\u7684RGB\u56fe\u50cf\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u91cf\u5316\u98df\u7269\u6d6a\u8d39\u3002\u7814\u7a76\u4e2d\u8bad\u7ec3\u4e86\u56db\u79cd\u5168\u76d1\u7763\u6a21\u578b\uff08U-Net\u3001U-Net++\u53ca\u5176\u8f7b\u91cf\u7ea7\u53d8\u4f53\uff09\uff0c\u5e76\u91c7\u7528\u4e86\u6709\u4e0a\u9650\u7684\u52a8\u6001\u9006\u9891\u7387\u635f\u5931\u548cAdamW\u4f18\u5316\u5668\u3002\u6027\u80fd\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u50cf\u7d20\u51c6\u786e\u7387\u3001Dice\u3001IoU\u4ee5\u53ca\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u50cf\u7d20\u4e00\u81f4\u6027\uff08DPA\uff09\u6307\u6807\u3002", "result": "\u6240\u6709\u6a21\u578b\u5747\u53d6\u5f97\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u6027\u80fd\uff0c\u5728DPA\u6307\u6807\u4e0a\uff0c\u81f3\u5c11\u6709\u4e00\u4e2a\u6a21\u578b\u9488\u5bf9\u6bcf\u79cd\u98df\u7269\u7c7b\u578b\u90fd\u8fbe\u5230\u4e8690%\u6216\u66f4\u9ad8\uff0c\u8868\u660e\u50cf\u7d20\u7ea7\u6bd4\u4f8b\u4f30\u8ba1\u5177\u6709\u5f88\u5f3a\u7684\u4e00\u81f4\u6027\u3002\u8f7b\u91cf\u7ea7\u6a21\u578b\u5177\u6709\u66f4\u5c11\u7684\u53c2\u6570\uff0c\u63a8\u7406\u901f\u5ea6\u66f4\u5feb\uff0c\u5728NVIDIA T4 GPU\u4e0a\u5b9e\u73b0\u4e86\u5b9e\u65f6\u541e\u5410\u91cf\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u5e72\u6027\u3001\u786c\u6027\u98df\u7269\u6210\u5206\uff08\u5982\u7c73\u996d\u548c\u70b8\u85af\u6761\uff09\u7684\u5206\u5272\u6548\u679c\u4f18\u4e8e\u590d\u6742\u3001\u788e\u7247\u5316\u6216\u7c98\u7a20\u7684\u83dc\u80b4\uff08\u5982\u7096\u83dc\uff09\uff0c\u5c24\u5176\u662f\u5728\u9910\u540e\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\uff0c\u7528\u4e8e\u4f30\u7b97\u9910\u76d8\u7ea7\u522b\u7684\u98df\u7269\u6d6a\u8d39\u3002\u8be5\u6846\u67b6\u5229\u7528\u4e86\u9910\u524d\u9910\u540eRGB\u56fe\u50cf\u7684\u8bed\u4e49\u5206\u5272\u6280\u672f\uff0c\u5e76\u9488\u5bf9\u4f0a\u6717\u7684\u4e94\u79cd\u83dc\u80b4\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6240\u6709\u6a21\u578b\u5747\u53d6\u5f97\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u6027\u80fd\uff0c\u5176\u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a\u6a21\u578b\u5728DPA\uff08\u50cf\u7d20\u7ea7\u6bd4\u4f8b\u4f30\u8ba1\u7684\u4e00\u81f4\u6027\uff09\u4e0a\u63a5\u8fd1\u6216\u8d85\u8fc7\u4e8690%\u3002\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728\u63a8\u7406\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5b9e\u73b0\u5b9e\u65f6\u541e\u5410\u91cf\u3002\u7814\u7a76\u8fd8\u6307\u51fa\u4e86\u5e72\u6027\u3001\u786c\u6027\u98df\u7269\u6210\u5206\u7684\u5206\u5272\u6548\u679c\u4f18\u4e8e\u590d\u6742\u3001\u788e\u7247\u5316\u6216\u7c98\u7a20\u7684\u83dc\u80b4\u3002\u5c3d\u7ba1\u5b58\u57282D\u6210\u50cf\u3001\u98df\u7269\u79cd\u7c7b\u6709\u9650\u548c\u624b\u52a8\u6570\u636e\u6536\u96c6\u7b49\u9650\u5236\uff0c\u4f46\u8be5\u6846\u67b6\u4ee3\u8868\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u975e\u63a5\u89e6\u5f0f\u7684\u98df\u7269\u6d88\u8017\u76d1\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u81ea\u52a8\u5316\u3001\u5b9e\u65f6\u6d6a\u8d39\u8ddf\u8e2a\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u9910\u996e\u7ba1\u7406\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\u548c\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2507.14570", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14570", "abs": "https://arxiv.org/abs/2507.14570", "authors": ["Xu Cheng", "Liang Yao", "Feng He", "Yukuo Cen", "Yufei He", "Chenhui Zhang", "Wenzheng Feng", "Hongyun Cai", "Jie Tang"], "title": "LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges", "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph\nmining tasks, yet existing scalable solutions often struggle to balance\nexecution efficiency with prediction accuracy. These difficulties stem from\niterative message-passing techniques, which place significant computational\ndemands and require extensive GPU memory, particularly when dealing with the\nneighbor explosion issue inherent in large-scale graphs. This paper introduces\na scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,\nwhich can perform representation learning on 100 billion graphs with a single\nGPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We\nexamine existing graph partitioning methods and design a superior graph\npartition algorithm named LPMetis. In particular, LPMetis outperforms current\nstate-of-the-art (SOTA) approaches on various evaluation metrics. In addition,\nour paper proposes a subgraph augmentation strategy to enhance the model's\npredictive performance. It exhibits excellent compatibility, allowing the\nentire framework to accommodate various GNN algorithms. Successfully deployed\non the Tencent platform, LPS-GNN has been tested on public and real-world\ndatasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in\nonline applications.", "AI": {"tldr": "LPS-GNN \u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u3001\u7075\u6d3b\u7684 GNN \u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u7684\u56fe\u5212\u5206\u7b97\u6cd5\u548c\u5b50\u56fe\u589e\u5f3a\u7b56\u7565\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u56fe\u5904\u7406\u7684\u96be\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709 GNN \u6846\u67b6\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u65f6\u5b58\u5728\u6548\u7387\u548c\u7cbe\u5ea6\u96be\u4ee5\u5e73\u8861\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u8fed\u4ee3\u6d88\u606f\u4f20\u9012\u6280\u672f\u5e26\u6765\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u538b\u529b\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u65b0\u7684\u56fe\u5212\u5206\u7b97\u6cd5 LPMetis \u548c\u5b50\u56fe\u589e\u5f3a\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709 GNN \u6846\u67b6\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u65f6\u6548\u7387\u548c\u7cbe\u5ea6\u7684\u5e73\u8861\u95ee\u9898\u3002", "result": "LPS-GNN \u6846\u67b6\u80fd\u591f\u5904\u7406\u5305\u542b 1000 \u4ebf\u8282\u70b9\u7684\u56fe\uff0c\u5728\u5355 GPU \u4e0a\u4ec5\u9700 10 \u5c0f\u65f6\u5373\u53ef\u5b8c\u6210\uff0c\u540c\u65f6\u5728\u7528\u6237\u83b7\u53d6\u573a\u666f\u4e0b\u63d0\u9ad8\u4e86 13.8% \u7684\u51c6\u786e\u7387\uff0c\u5e76\u5728\u591a\u4e2a\u5728\u7ebf\u5e94\u7528\u4e2d\u8d85\u8fc7\u4e86 SOTA \u6a21\u578b\u3002", "conclusion": "LPS-GNN \u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u7528\u6237\u83b7\u53d6\u573a\u666f\u4e0b\u63d0\u5347\u4e86 13.8% \u7684\u6548\u679c\uff0c\u5e76\u4e14\u5728\u5176\u4ed6\u5728\u7ebf\u5e94\u7528\u4e2d\u4e5f\u5b9e\u73b0\u4e86 8.24% \u5230 13.89% \u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2507.15817", "categories": ["cond-mat.mtrl-sci", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.15817", "abs": "https://arxiv.org/abs/2507.15817", "authors": ["Rafaela F. S. Penacchio", "Siham Mohamed", "Haley A. Harms", "Lin-Lin Wang", "Sergey L. Bud'ko", "Paul. C Canfield", "Tyler J. Slade"], "title": "Charge density wave in intermetallic oxides R$_5$Pb$_3$O (R = La and Ce)", "comment": null, "summary": "The R$_5$Pb$_3$O family was discovered decades ago, but has remained largely\nunexplored. Here, we report single crystal growth and basic characterization\nfor the La and Ce members of this family. At room temperature, these compounds\nadopt a tetragonal structure (I4/mcm), where R and Pb atoms form linear chains\nalong the c-axis. We identify a second-order structural phase transition at 260\nK and 145 K for R = La and Ce, respectively. Single crystal X-ray diffraction\nreveals a lattice modulation below the transition temperature, resulting in\nR-Pb pairs in the z direction. The broken symmetry in the low-temperature\nphases results in a primitive structure with space group P4/ncc. Transport and\ndiffraction measurements, in agreement with density functional theory\ncalculations, support that the R$_5$Pb$_3$O (R = La and Ce) series hosts an\nelectron-phonon coupling driven charge density wave (CDW) at low temperatures.\nThe CDW ordering temperature is suppressed by more than 100 K by the La to Ce\nsubstitution, suggesting high pressure-sensitivity. Therefore, this family\noffers the potential for investigating competing orders in oxides, with heavier\nrare-earth members still to be explored.", "AI": {"tldr": "R$_5$Pb$_3$O (R = La, Ce) \u5177\u6709\u7531\u7535\u5b50-\u58f0\u5b50\u8026\u5408\u9a71\u52a8\u7684 CDW\uff0c\u5e76\u5728\u4f4e\u6e29\u4e0b\u7ecf\u5386\u7ed3\u6784\u76f8\u53d8\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22 R$_5$Pb$_3$O \u5bb6\u65cf\u7684 La \u548c Ce \u6210\u5458\uff0c\u5e76\u63ed\u793a\u5176\u7ed3\u6784\u76f8\u53d8\u548c\u7535\u8377\u5bc6\u5ea6\u6ce2\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5355\u6676 X \u5c04\u7ebf\u884d\u5c04\u548c\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\uff0c\u7814\u7a76\u4e86 La$_5$Pb$_3$O \u548c Ce$_5$Pb$_3$O \u7684\u7ed3\u6784\u548c\u7535\u5b50\u6027\u8d28\u3002", "result": "\u5728 260 K \u548c 145 K \u53d1\u73b0\u4e86\u4e8c\u9636\u7ed3\u6784\u76f8\u53d8\uff0c\u5bfc\u81f4\u4e86\u4f4e\u5bf9\u79f0\u6027\u7684 P4/ncc \u7ed3\u6784\u3002CDW \u7684\u8ba2\u8d2d\u6e29\u5ea6\u56e0 La \u5230 Ce \u7684\u53d6\u4ee3\u800c\u964d\u4f4e\u4e86 100 K \u4ee5\u4e0a\u3002", "conclusion": "La$_5$Pb$_3$O \u548c Ce$_5$Pb$_3$O \u8868\u73b0\u51fa\u7531\u7535\u5b50-\u58f0\u5b50\u8026\u5408\u9a71\u52a8\u7684\u7535\u8377\u5bc6\u5ea6\u6ce2 (CDW)\u3002"}}
{"id": "2507.15217", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15217", "abs": "https://arxiv.org/abs/2507.15217", "authors": ["Kenichiro Tateishi", "Shuji Otsuka", "Akihiro Yamaji", "Shunsuke Kurosawa", "Tomohiro Uesaka"], "title": "1H Polarization above 60% at room temperature by triplet dynamic nuclear polarization", "comment": null, "summary": "1H polarization of 61% was achieved by Dynamic Nuclear Polarization using\nphotoexcited triplet electrons (Triplet-DNP) at room temperature and in 0.64 T.\nWe introduced dibenz[a, h]anthracene as a new host molecule of the polarizing\nagent, pentacene-d14. Its rigid structure provides a long spin-lattice\nrelaxation time (T1) of more than 2 hours at room temperature. The single\ncrystal of dibenz[a, h]anthracene doped with 0.05 mol% pentacene-d14 was grown\nby the Bridgman method, and cut into a small piece of ~1 mg for Triplet-DNP\nexperiment. The 1H polarization buildup and relaxation measurements indicated\nthat paramagnetic relaxation became the major source of the relaxation than\nspin-lattice relaxation. Finally, two promising applications of\nroom-temperature hyperpolarization, i .e. nuclear ordering and\nradiation-tolerant polarized target, are discussed.", "AI": {"tldr": "\u5728\u5ba4\u6e29\u548c\u4f4e\u78c1\u573a\u4e0b\uff0c\u901a\u8fc7\u4f7f\u7528\u4e8c\u82ef\u5e76[a, h]\u84bd\u4f5c\u4e3a\u5506\u9ebb[d14]\u7684\u5bbf\u4e3b\u5206\u5b50\uff0c\u5b9e\u73b0\u4e8661%\u76841H\u6781\u5316\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u6838\u5e8f\u548c\u6297\u8f90\u5c04\u6781\u5316\u9776\u65b9\u9762\u7684\u5e94\u7528\u3002", "motivation": "\u5728\u5ba4\u6e29\u548c\u4f4e\u78c1\u573a\u4e0b\u5b9e\u73b0\u9ad8\u6781\u5316\u5bf9\u4e8e\u6838\u78c1\u5171\u632f\u6210\u50cf\u548c\u7c92\u5b50\u7269\u7406\u5b9e\u9a8c\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u7684\u52a8\u6001\u6838\u6781\u5316\uff08DNP\uff09\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u4f20\u7edfDNP\u65b9\u6cd5\u7684\u9650\u5236\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e8c\u82ef\u5e76[a, h]\u84bd\u4f5c\u4e3a\u65b0\u4e00\u4ee3\u7684\u5506\u9ebb[d14]\u7684\u5bbf\u4e3b\u5206\u5b50\uff0c\u8fd9\u79cd\u5206\u5b50\u7684\u521a\u6027\u7ed3\u6784\u4f7f\u5f97\u5176\u5728\u5ba4\u6e29\u4e0b\u7684\u81ea\u65cb\u6676\u683c\u5f1b\u8c6b\u65f6\u95f4\uff08T1\uff09\u8d85\u8fc72\u5c0f\u65f6\u3002\u901a\u8fc7\u6865\u5f0f\u6cd5\u751f\u957f\u4e86\u63ba\u6742\u4e860.05 mol%\u5506\u9ebb[d14]\u7684\u4e8c\u82ef\u5e76[a, h]\u84bd\u5355\u6676\uff0c\u5e76\u5c06\u5176\u5207\u5272\u6210\u7ea61\u6beb\u514b\u7684\u6837\u54c1\u7528\u4e8eTriplet-DNP\u5b9e\u9a8c\u3002\u987a\u78c1\u5f1b\u8c6b\u6210\u4e3a\u4e3b\u8981\u7684\u5f1b\u8c6b\u673a\u5236\uff0c\u800c\u975e\u81ea\u65cb\u6676\u683c\u5f1b\u8c6b\u3002", "result": "\u5728\u5ba4\u6e29\u548c0.64T\u78c1\u573a\u4e0b\uff0c\u901a\u8fc7Triplet-DNP\u5b9e\u73b0\u4e8661%\u76841H\u6781\u5316\u3002\u7814\u7a76\u8fd8\u8ba8\u8bba\u4e86\u5ba4\u6e29\u8d85\u6781\u5316\u5728\u6838\u5e8f\u548c\u6297\u8f90\u5c04\u6781\u5316\u9776\u4e24\u65b9\u9762\u7684\u5e94\u7528\u524d\u666f\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4f7f\u7528\u5149\u6fc0\u53d1\u7684\u4e09\u7ebf\u6001\u7535\u5b50\uff08Triplet-DNP\uff09\u5728\u5ba4\u6e29\u548c0.64T\u78c1\u573a\u4e0b\u5b9e\u73b0\u4e8661%\u76841H\u6781\u5316\u3002"}}
{"id": "2507.14871", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14871", "abs": "https://arxiv.org/abs/2507.14871", "authors": ["Ronit D. Gross", "Yarden Tzach", "Tal Halevi", "Ella Koresh", "Ido Kanter"], "title": "Tiny language models", "comment": "23 pages, 1 figure and 12 tables", "summary": "A prominent achievement of natural language processing (NLP) is its ability\nto understand and generate meaningful human language. This capability relies on\ncomplex feedforward transformer block architectures pre-trained on large\nlanguage models (LLMs). However, LLM pre-training is currently feasible only\nfor a few dominant companies due to the immense computational resources\nrequired, limiting broader research participation. This creates a critical need\nfor more accessible alternatives. In this study, we explore whether tiny\nlanguage models (TLMs) exhibit the same key qualitative features of LLMs. We\ndemonstrate that TLMs exhibit a clear performance gap between pre-trained and\nnon-pre-trained models across classification tasks, indicating the\neffectiveness of pre-training, even at a tiny scale. The performance gap\nincreases with the size of the pre-training dataset and with greater overlap\nbetween tokens in the pre-training and classification datasets. Furthermore,\nthe classification accuracy achieved by a pre-trained deep TLM architecture can\nbe replicated through a soft committee of multiple, independently pre-trained\nshallow architectures, enabling low-latency TLMs without affecting\nclassification accuracy. Our results are based on pre-training BERT-6 and\nvariants of BERT-1 on subsets of the Wikipedia dataset and evaluating their\nperformance on FewRel, AGNews, and DBPedia classification tasks. Future\nresearch on TLM is expected to further illuminate the mechanisms underlying\nNLP, especially given that its biologically inspired models suggest that TLMs\nmay be sufficient for children or adolescents to develop language.", "AI": {"tldr": "Tiny language models (TLMs) show similar features to large language models (LLMs), with pre-training proving effective even at a small scale. This research opens up possibilities for more accessible NLP research and potential applications in language development.", "motivation": "The motivation for this study was the immense computational resources required for LLM pre-training, which limits broader research participation. The study aimed to explore accessible alternatives by investigating whether tiny language models (TLMs) exhibit the same key qualitative features as LLMs.", "method": "The study explored whether tiny language models (TLMs) exhibit the same key qualitative features as large language models (LLMs). The researchers pre-trained BERT-6 and variants of BERT-1 on subsets of the Wikipedia dataset and evaluated their performance on FewRel, AGNews, and DBPedia classification tasks. They also investigated whether a soft committee of multiple, independently pre-trained shallow architectures could replicate the classification accuracy of a pre-trained deep TLM architecture.", "result": "TLMs exhibit a clear performance gap between pre-trained and non-pre-trained models across classification tasks, demonstrating the effectiveness of pre-training even at a tiny scale. The performance gap increases with the size of the pre-training dataset and with greater overlap between tokens in the pre-training and classification datasets. The classification accuracy achieved by a pre-trained deep TLM architecture can be replicated through a soft committee of multiple, independently pre-trained shallow architectures, enabling low-latency TLMs without affecting classification accuracy.", "conclusion": "TLMs can exhibit the same key qualitative features as LLMs, and pre-training is effective even at a tiny scale. The performance gap between pre-trained and non-pre-trained models increases with the size of the pre-training dataset and the overlap between tokens in the pre-training and classification datasets. A pre-trained deep TLM architecture's classification accuracy can be replicated by a soft committee of multiple, independently pre-trained shallow architectures, enabling low-latency TLMs without affecting classification accuracy. Future research on TLMs may further illuminate the mechanisms underlying NLP, as biologically inspired models suggest TLMs may be sufficient for language development in children and adolescents."}}
{"id": "2507.14224", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14224", "abs": "https://arxiv.org/abs/2507.14224", "authors": ["Beno\u00eet Brebion", "Alban Gallard", "Katrin Sippel", "Amer Zaylaa", "Hubert Preissl", "Sahar Moghimi", "Fabrice Wallois", "Ya\u00ebl Fr\u00e9gier"], "title": "Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG", "comment": null, "summary": "Background and objective: Brain activity in premature newborns has\ntraditionally been studied using electroencephalography (EEG), leading to\nsubstantial advances in our understanding of early neural development. However,\nsince brain development takes root at the fetal stage, a critical window of\nthis process remains largely unknown. The only technique capable of recording\nneural activity in the intrauterine environment is fetal magnetoencephalography\n(fMEG), but this approach presents challenges in terms of data quality and\nscarcity. Using artificial intelligence, the present research aims to transfer\nthe well-established knowledge from EEG studies to fMEG to improve\nunderstanding of prenatal brain development, laying the foundations for better\ndetection and treatment of potential pathologies. Methods: We developed an\nunpaired diffusion translation method based on dual diffusion bridges, which\nnotably includes numerical integration improvements to obtain more qualitative\nresults at a lower computational cost. Models were trained on our unpaired\ndataset of bursts of spontaneous activity from 30 high-resolution premature\nnewborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that\nour method achieves significant improvement upon previous results obtained with\nGenerative Adversarial Networks (GANs), by almost 5% on the mean squared error\nin the time domain, and completely eliminating the mode collapse problem in the\nfrequency domain, thus achieving near-perfect signal fidelity. Conclusion: We\nset a new state of the art in the EEG-fMEG unpaired translation problem, as our\ndeveloped tool completely paves the way for early brain activity analysis.\nOverall, we also believe that our method could be reused for other unpaired\nsignal translation applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u4eba\u5de5\u667a\u80fd\u548c\u53cc\u6269\u6563\u6865\u6280\u672f\uff0c\u6210\u529f\u5730\u5c06\u8111\u7535\u56fe\uff08EEG\uff09\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u80ce\u513f\u8111\u78c1\u56fe\uff08fMEG\uff09\u4e0a\uff0c\u63d0\u9ad8\u4e86\u4ea7\u524d\u5927\u8111\u6d3b\u52a8\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u65e9\u671f\u68c0\u6d4b\u548c\u6cbb\u7597\u8111\u90e8\u75be\u75c5\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u7531\u4e8e\u5927\u8111\u53d1\u80b2\u59cb\u4e8e\u80ce\u513f\u671f\uff0c\u800c\u8fd9\u4e00\u8fc7\u7a0b\u7684\u5173\u952e\u7a97\u53e3\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ecd\u7136\u672a\u77e5\u3002\u552f\u4e00\u80fd\u591f\u5728\u5bab\u5185\u73af\u5883\u4e2d\u8bb0\u5f55\u795e\u7ecf\u6d3b\u52a8\u7684\u6280\u672f\u662f\u80ce\u513f\u8111\u78c1\u56fe\uff08fMEG\uff09\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u6570\u636e\u8d28\u91cf\u548c\u7a00\u7f3a\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u4eba\u5de5\u667a\u80fd\u5c06\u4ece\u8111\u7535\u56fe\u7814\u7a76\u4e2d\u83b7\u5f97\u7684\u6210\u719f\u77e5\u8bc6\u8f6c\u79fb\u5230\u80ce\u513f\u8111\u78c1\u56fe\u4e2d\uff0c\u4ee5\u589e\u8fdb\u5bf9\u4ea7\u524d\u5927\u8111\u53d1\u80b2\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u66f4\u597d\u5730\u68c0\u6d4b\u548c\u6cbb\u7597\u6f5c\u5728\u75c5\u7406\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u6269\u6563\u6865\u7684\u4e0d\u6210\u5bf9\u6269\u6563\u8f6c\u6362\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5305\u62ec\u6570\u503c\u79ef\u5206\u6539\u8fdb\uff0c\u4ee5\u5728\u8f83\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u4e0b\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u7ed3\u679c\u3002\u6a21\u578b\u5728\u6765\u81ea30\u540d\u9ad8\u5206\u8fa8\u7387\u65e9\u4ea7\u65b0\u751f\u513f\u8111\u7535\u56fe\u8bb0\u5f55\u548c44\u540d\u80ce\u513f\u8111\u78c1\u56fe\u8bb0\u5f55\u7684\u81ea\u53d1\u6d3b\u52a8\u7206\u53d1\u7684\u4e0d\u6210\u5bf9\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u3002", "result": "\u6240\u5f00\u53d1\u7684\u65b9\u6cd5\u5728\u5747\u65b9\u8bef\u5dee\u548c\u6a21\u6001\u5d29\u6e83\u95ee\u9898\u4e0a\u5747\u4f18\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GANs\uff09\uff0c\u5206\u522b\u63d0\u9ad8\u4e86\u8fd15%\u548c\u5b8c\u5168\u6d88\u9664\u4e86\u6a21\u6001\u5d29\u6e83\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u4fe1\u53f7\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u5728\u4e0d\u6210\u5bf9\u7684\u8111\u7535\u56fe\u5230\u80ce\u513f\u8111\u78c1\u56fe\u8f6c\u6362\u95ee\u9898\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6280\u672f\u6c34\u5e73\uff0c\u6240\u5f00\u53d1\u7684\u5de5\u5177\u4e3a\u65e9\u671f\u5927\u8111\u6d3b\u52a8\u5206\u6790\u94fa\u5e73\u4e86\u9053\u8def\u3002\u6b64\u5916\uff0c\u6211\u4eec\u76f8\u4fe1\u8be5\u65b9\u6cd5\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5176\u4ed6\u4e0d\u6210\u5bf9\u4fe1\u53f7\u8f6c\u6362\u5e94\u7528\u3002"}}
{"id": "2507.15677", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15677", "abs": "https://arxiv.org/abs/2507.15677", "authors": ["Huayue Liang", "Yanbo Chen", "Hongyang Cheng", "Yanzhao Yu", "Shoujie Li", "Junbo Tan", "Xueqian Wang", "Long Zeng"], "title": "Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms", "comment": null, "summary": "Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant\nmotion. Still, the inherent properties of cables, such as resilience,\nhysteresis, and friction, often lead to particular difficulties in modeling and\ncontrol. This paper proposes a model predictive control (MPC) method that\nrelies exclusively on input-output data, without a physical model, to improve\nthe control accuracy of FCRAs. First, we develop an implicit model based on\ninput-output data and integrate it into an MPC optimization framework. Second,\na data selection algorithm (DSA) is introduced to filter the data that best\ncharacterize the system, thereby reducing the solution time per step to\napproximately 4 ms, which is an improvement of nearly 80%. Lastly, the\ninfluence of hyperparameters on tracking error is investigated through\nsimulation. The proposed method has been validated on a real FCRA platform,\nincluding five-point positioning accuracy tests, a five-point response tracking\ntest, and trajectory tracking for letter drawing. The results demonstrate that\nthe average positioning accuracy is approximately 2.070 mm. Moreover, compared\nto the PID method with an average tracking error of 1.418{\\deg}, the proposed\nmethod achieves an average tracking error of 0.541{\\deg}.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684MPC\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a7\u5236\u67d4\u6027 kabel \u9a71\u52a8\u7684\u673a\u5668\u4eba\u624b\u81c2 (FCRA)\uff0c\u89e3\u51b3\u4e86 kabel \u7684\u56fa\u6709\u7279\u6027\u5e26\u6765\u7684\u5efa\u6a21\u548c\u63a7\u5236\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u7269\u7406\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u9009\u62e9\u7b97\u6cd5 (DSA) \u4f18\u5316\u4e86\u6c42\u89e3\u65f6\u95f4\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u8ddf\u8e2a\u8bef\u5dee\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u7684PID\u65b9\u6cd5\u3002", "motivation": "\u67d4\u6027 kabel \u9a71\u52a8\u7684\u673a\u5668\u4eba\u624b\u81c2 (FCRA) \u63d0\u4f9b\u7075\u5de7\u548c\u987a\u4ece\u7684\u8fd0\u52a8\u3002\u7136\u800c\uff0ckabel \u7684\u56fa\u6709\u7279\u6027\uff0c\u4f8b\u5982\u5f39\u6027\u3001\u6ede\u540e\u548c\u6469\u64e6\uff0c\u901a\u5e38\u4f1a\u5bfc\u81f4\u5efa\u6a21\u548c\u63a7\u5236\u65b9\u9762\u7684\u7279\u5b9a\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4ec5\u4f9d\u8d56\u8f93\u5165\u8f93\u51fa\u6570\u636e\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u65b9\u6cd5\uff0c\u65e0\u9700\u7269\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8FCRA\u7684\u63a7\u5236\u7cbe\u5ea6\u3002\u5f00\u53d1\u4e86\u57fa\u4e8e\u8f93\u5165\u8f93\u51fa\u6570\u636e\u7684\u9690\u5f0f\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230MPC\u4f18\u5316\u6846\u67b6\u4e2d\u3002\u5f15\u5165\u6570\u636e\u9009\u62e9\u7b97\u6cd5\uff08DSA\uff09\u6765\u7b5b\u9009\u6700\u80fd\u8868\u5f81\u7cfb\u7edf\u7684\u6570\uff0c\u5c06\u6bcf\u6b65\u7684\u6c42\u89e3\u65f6\u95f4\u51cf\u5c11\u5230\u5927\u7ea64\u6beb\u79d2\uff0c\u63d0\u9ad8\u4e86\u8fd180%\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u771f\u5b9e\u7684FCRA\u5e73\u53f0\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5305\u62ec\u4e94\u70b9\u5b9a\u4f4d\u7cbe\u5ea6\u6d4b\u8bd5\u3001\u4e94\u70b9\u54cd\u5e94\u8ddf\u8e2a\u6d4b\u8bd5\u4ee5\u53ca\u5b57\u6bcd\u7ed8\u5236\u7684\u8f68\u8ff9\u8ddf\u8e2a\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5e73\u5747\u5b9a\u4f4d\u7cbe\u5ea6\u7ea6\u4e3a2.070\u6beb\u7c73\u3002\u6b64\u5916\uff0c\u4e0e\u5e73\u5747\u8ddf\u8e2a\u8bef\u5dee\u4e3a1.418\u5ea6\u7684PID\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e860.541\u5ea6\u7684\u5e73\u5747\u8ddf\u8e2a\u8bef\u5dee\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6570\u636e\u7684\u65b9\u6cd5\u5728FCRA\u7684\u63a7\u5236\u7cbe\u5ea6\u65b9\u9762\u4f18\u4e8ePID\u65b9\u6cd5\uff0c\u5e73\u5747\u5b9a\u4f4d\u7cbe\u5ea6\u7ea6\u4e3a2.070\u6beb\u7c73\uff0c\u5e73\u5747\u8ddf\u8e2a\u8bef\u5dee\u4e3a0.541\u5ea6\uff0c\u4f18\u4e8ePID\u65b9\u6cd5\u76841.418\u5ea6\u3002"}}
{"id": "2507.14670", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14670", "abs": "https://arxiv.org/abs/2507.14670", "authors": ["Yaxuan Song", "Jianan Fan", "Hang Chang", "Weidong Cai"], "title": "Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images", "comment": "16 pages, 15 tables, 8 figures", "summary": "Accurately predicting gene expression from histopathology images offers a\nscalable and non-invasive approach to molecular profiling, with significant\nimplications for precision medicine and computational pathology. However,\nexisting methods often underutilize the cross-modal representation alignment\nbetween histopathology images and gene expression profiles across multiple\nrepresentational levels, thereby limiting their prediction performance. To\naddress this, we propose Gene-DML, a unified framework that structures latent\nspace through Dual-pathway Multi-Level discrimination to enhance correspondence\nbetween morphological and transcriptional modalities. The multi-scale\ninstance-level discrimination pathway aligns hierarchical histopathology\nrepresentations extracted at local, neighbor, and global levels with gene\nexpression profiles, capturing scale-aware morphological-transcriptional\nrelationships. In parallel, the cross-level instance-group discrimination\npathway enforces structural consistency between individual (image/gene)\ninstances and modality-crossed (gene/image, respectively) groups, strengthening\nthe alignment across modalities. By jointly modelling fine-grained and\nstructural-level discrimination, Gene-DML is able to learn robust cross-modal\nrepresentations, enhancing both predictive accuracy and generalization across\ndiverse biological contexts. Extensive experiments on public spatial\ntranscriptomics datasets demonstrate that Gene-DML achieves state-of-the-art\nperformance in gene expression prediction. The code and checkpoints will be\nreleased soon.", "AI": {"tldr": "Gene-DML\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u901a\u8def\u591a\u5c42\u6b21\u5224\u522b\u6765\u66f4\u597d\u5730\u5339\u914d\u75c5\u7406\u56fe\u50cf\u548c\u57fa\u56e0\u8868\u8fbe\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u57fa\u56e0\u8868\u8fbe\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u548c\u57fa\u56e0\u8868\u8fbe\u8c31\u5728\u591a\u5c42\u6b21\u8868\u793a\u4e4b\u95f4\u8fdb\u884c\u8de8\u6a21\u6001\u8868\u793a\u5bf9\u9f50\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6027\u80fd\u3002\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Gene-DML \u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u53cc\u901a\u8def\u591a\u5c42\u6b21\u5224\u522b\uff08Dual-pathway Multi-Level discrimination\uff09\u6765\u6784\u5efa\u6f5c\u5728\u7a7a\u95f4\uff0c\u4ee5\u589e\u5f3a\u5f62\u6001\u5b66\u548c\u8f6c\u5f55\u7ec4\u5b66\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u5177\u4f53\u5305\u62ec\uff1a1. \u591a\u5c3a\u5ea6\u5b9e\u4f8b\u7ea7\u5224\u522b\u901a\u8def\uff1a\u5bf9\u4ece\u5c40\u90e8\u3001\u90bb\u57df\u548c\u5168\u5c40\u4e09\u4e2a\u5c42\u7ea7\u63d0\u53d6\u7684\u7ec4\u7ec7\u75c5\u7406\u5b66\u8868\u793a\u8fdb\u884c\u5bf9\u9f50\uff0c\u4ee5\u6355\u6349\u4e0e\u57fa\u56e0\u8868\u8fbe\u8c31\u76f8\u5173\u7684\u3001\u53ef\u611f\u77e5\u5c3a\u5ea6\u7684\u5f62\u6001-\u8f6c\u5f55\u5173\u7cfb\u30022. \u8de8\u5c42\u7ea7\u5b9e\u4f8b-\u7ec4\u5224\u522b\u901a\u8def\uff1a\u5f3a\u5236\u5355\u4e2a\u5b9e\u4f8b\uff08\u56fe\u50cf/\u57fa\u56e0\uff09\u4e0e\u8de8\u6a21\u6001\u7684\u5b9e\u4f8b\u7ec4\uff08\u57fa\u56e0/\u56fe\u50cf\uff09\u4e4b\u95f4\u4fdd\u6301\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u4ee5\u52a0\u5f3a\u8de8\u6a21\u6001\u7684\u5bf9\u9f50\u3002\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u7ec6\u7c92\u5ea6\u548c\u7ed3\u6784\u5c42\u6b21\u7684\u5224\u522b\uff0cGene-DML \u5b66\u4e60\u4e86\u9c81\u68d2\u7684\u8de8\u6a21\u6001\u8868\u793a\u3002", "result": "\u901a\u8fc7\u53cc\u901a\u8def\u591a\u5c42\u6b21\u5224\u522b\uff0cGene-DML \u80fd\u591f\u5b66\u4e60\u9c81\u68d2\u7684\u8de8\u6a21\u6001\u8868\u793a\uff0c\u4ece\u800c\u63d0\u9ad8\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u5728\u516c\u5f00\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cGene-DML \u5728\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "Gene-DML \u6846\u67b6\u901a\u8fc7\u5176\u53cc\u901a\u8def\u591a\u5c42\u6b21\u5224\u522b\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5728\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u4e2d\u9884\u6d4b\u57fa\u56e0\u8868\u8fbe\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u516c\u5f00\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14592", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14592", "abs": "https://arxiv.org/abs/2507.14592", "authors": ["Haochen Liu", "Jia Bi", "Xiaomin Wang", "Xin Yang", "Ling Wang"], "title": "A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification", "comment": "13 pages, 7 figures", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,\nlogistics, agriculture, disaster management, and military operations. Accurate\ndetection and classification of UAV flight states, such as hovering, cruising,\nascending, or transitioning, which are essential for safe and effective\noperations. However, conventional time series classification (TSC) methods\noften lack robustness and generalization for dynamic UAV environments, while\nstate of the art(SOTA) models like Transformers and LSTM based architectures\ntypically require large datasets and entail high computational costs,\nespecially with high-dimensional data streams. This paper proposes a novel\nframework that integrates a Transformer-based Generative Adversarial Network\n(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address\nthese challenges in UAV flight state classification. The Transformer encoder\ncaptures long-range temporal dependencies and complex telemetry dynamics, while\nthe GAN module augments limited datasets with realistic synthetic samples. MIL\nis incorporated to focus attention on the most discriminative input segments,\nreducing noise and computational overhead. Experimental results show that the\nproposed method achieves superior accuracy 96.5% on the DroneDetect dataset and\n98.6% on the DroneRF dataset that outperforming other SOTA approaches. The\nframework also demonstrates strong computational efficiency and robust\ngeneralization across diverse UAV platforms and flight states, highlighting its\npotential for real-time deployment in resource constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Transformer-GAN\u548cMILET\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8eUAV\u98de\u884c\u72b6\u6001\u5206\u7c7b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u548cSOTA\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff08\u6700\u9ad898.6%\uff09\uff0c\u589e\u5f3a\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u5b9e\u65f6\u90e8\u7f72\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u5e8f\u5206\u7c7b\uff08TSC\uff09\u65b9\u6cd5\u5728\u52a8\u6001UAV\u73af\u5883\u4e2d\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u50cfTransformer\u548cLSTM\u8fd9\u6837\u7684SOTA\u6a21\u578b\u9700\u8981\u5927\u91cf\u6570\u636e\u96c6\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u6d41\u65f6\uff0c\u800c\u7cbe\u786e\u68c0\u6d4b\u548c\u5206\u7c7bUAV\uff08\u5982\u60ac\u505c\u3001\u5de1\u822a\u3001\u722c\u5347\u6216\u8f6c\u6362\uff09\u7684\u98de\u884c\u72b6\u6001\u5bf9\u4e8e\u5b89\u5168\u6709\u6548\u7684\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u4e86\u57fa\u4e8eTransformer\u7684\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u548c\u591a\u5b9e\u4f8b\u5c40\u90e8\u53ef\u89e3\u91ca\u5b66\u4e60\uff08MILET\uff09\u7684\u65b0\u578b\u6846\u67b6\u3002Transformer\u7f16\u7801\u5668\u6355\u6349\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u590d\u6742\u7684\u9065\u6d4b\u52a8\u6001\uff0cGAN\u6a21\u5757\u4f7f\u7528\u771f\u5b9e\u7684\u5408\u6210\u6837\u672c\u589e\u5f3a\u6709\u9650\u7684\u6570\u636e\u96c6\uff0cMIL\u5219\u4e13\u6ce8\u4e8e\u6700\u5177\u5224\u522b\u6027\u7684\u8f93\u5165\u7247\u6bb5\uff0c\u4ee5\u51cf\u5c11\u566a\u58f0\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728DroneDetect\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8696.5%\u7684\u51c6\u786e\u7387\uff0c\u5728DroneRF\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8698.6%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6SOTA\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u5728\u8ba1\u7b97\u6548\u7387\u548c\u8de8\u4e0d\u540cUAV\u5e73\u53f0\u53ca\u98de\u884c\u72b6\u6001\u7684\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728DroneDetect\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8696.5%\u7684\u51c6\u786e\u7387\uff0c\u5728DroneRF\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8698.6%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6SOTA\u65b9\u6cd5\u3002\u8be5\u6846\u67b6\u8fd8\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u8ba1\u7b97\u6548\u7387\u548c\u5728\u4e0d\u540cUAV\u5e73\u53f0\u53ca\u98de\u884c\u72b6\u6001\u4e0b\u7684\u7a33\u5065\u6cdb\u5316\u80fd\u529b\uff0c\u8868\u660e\u5176\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u65f6\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15295", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15295", "abs": "https://arxiv.org/abs/2507.15295", "authors": ["Ximo Wang", "Qiwei Han", "Zhenqi Bai", "Hongyan Fan", "Yichi Zhang"], "title": "Strongly Coupled Continuous Time Crystal", "comment": null, "summary": "Time crystals are classified into discrete time crystals and continuous time\ncrystals based on whether they spontaneously break time-translation symmetry.\nContinuous-time crystals do not require external driving. By introducing\nAdS/CFT duality to time crystals, we derive their thermodynamic limit and find\nthat in strongly correlated many-body systems such as a 3D optical lattice,\ncooperative many-body tunneling enables time crystals to oscillate\nspontaneously. In strongly correlated quantum systems driven by many-body\ncooperative tunneling, we discover a universal scaling law governing the\ntime-crystalline phase transition at a critical temperature.", "AI": {"tldr": "\u5f3a\u5173\u8054\u591a\u4f53\u7cfb\u7edf\u4e2d\uff0c\u534f\u540c\u591a\u4f53\u96a7\u7a7f\u4f7f\u65f6\u95f4\u6676\u4f53\u81ea\u53d1\u632f\u8361\uff0c\u5e76\u53d1\u73b0\u4e86\u666e\u9002\u6807\u5ea6\u5f8b\u3002", "motivation": "\u57fa\u4e8e\u65f6\u95f4\u6676\u4f53\u662f\u5426\u81ea\u53d1\u7834\u574f\u65f6\u95f4\u5e73\u79fb\u5bf9\u79f0\u6027\uff0c\u5c06\u65f6\u95f4\u6676\u4f53\u5206\u4e3a\u79bb\u6563\u65f6\u95f4\u548c\u8fde\u7eed\u65f6\u95f4\u6676\u4f53\u3002\u8fde\u7eed\u65f6\u95f4\u6676\u4f53\u4e0d\u9700\u8981\u5916\u90e8\u9a71\u52a8\u3002", "method": "\u901a\u8fc7\u5f15\u5165AdS/CFT\u5bf9\u5076\u5230\u65f6\u95f4\u6676\u4f53\uff0c\u6211\u4eec\u63a8\u5bfc\u4e86\u5b83\u4eec\u7684\u70ed\u529b\u5b66\u6781\u9650\u3002", "result": "\u53d1\u73b0\u534f\u540c\u591a\u4f53\u96a7\u7a7f\u4f7f\u65f6\u95f4\u6676\u4f53\u81ea\u53d1\u632f\u8361\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e2a\u63a7\u5236\u65f6\u95f4\u6676\u4f53\u76f8\u53d8\u5728\u4e34\u754c\u6e29\u5ea6\u4e0b\u666e\u9002\u7684\u6807\u5ea6\u5f8b\u3002", "conclusion": "\u65f6\u95f4\u6676\u4f53\u5728\u5f3a\u5173\u8054\u591a\u4f53\u7cfb\u7edf\u4e2d\uff0c\u59823D\u5149\u5b66\u6676\u683c\u4e2d\uff0c\u534f\u540c\u591a\u4f53\u96a7\u7a7f\u4f7f\u5f97\u65f6\u95f4\u6676\u4f53\u81ea\u53d1\u632f\u8361\u3002\u5728\u7531\u591a\u4f53\u534f\u540c\u96a7\u7a7f\u9a71\u52a8\u7684\u5f3a\u5173\u8054\u91cf\u5b50\u7cfb\u7edf\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u4e00\u4e2a\u63a7\u5236\u65f6\u95f4\u6676\u4f53\u76f8\u53d8\u5728\u4e34\u754c\u6e29\u5ea6\u4e0b\u666e\u9002\u7684\u6807\u5ea6\u5f8b\u3002"}}
{"id": "2507.14887", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14887", "abs": "https://arxiv.org/abs/2507.14887", "authors": ["Shiyi Mu", "Yongkang Liu", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yifei Zhang"], "title": "MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction", "comment": "Accepted by CogSci", "summary": "Although large language models (LLMs) excel in text comprehension and\ngeneration, their performance on the Emotion-Cause Pair Extraction (ECPE) task,\nwhich requires reasoning ability, is often underperform smaller language model.\nThe main reason is the lack of auxiliary knowledge, which limits LLMs' ability\nto effectively perceive emotions and reason causes. To address this issue, we\npropose a novel \\textbf{M}ulti-source h\\textbf{E}terogeneous \\textbf{K}nowledge\n\\textbf{i}njection me\\textbf{T}hod, MEKiT, which integrates heterogeneous\ninternal emotional knowledge and external causal knowledge. Specifically, for\nthese two distinct aspects and structures of knowledge, we apply the approaches\nof incorporating instruction templates and mixing data for instruction-tuning,\nwhich respectively facilitate LLMs in more comprehensively identifying emotion\nand accurately reasoning causes. Experimental results demonstrate that MEKiT\nprovides a more effective and adaptable solution for the ECPE task, exhibiting\nan absolute performance advantage over compared baselines and dramatically\nimproving the performance of LLMs on the ECPE task.", "AI": {"tldr": "MEKiT \u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u5185\u90e8\u60c5\u611f\u77e5\u8bc6\u548c\u5916\u90e8\u56e0\u679c\u77e5\u8bc6\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f-\u539f\u56e0\u5bf9\u63d0\u53d6\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u63a8\u7406\u80fd\u529b\u7684 ECPE \u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u63a8\u7406\u80fd\u529b\u7684\u60c5\u611f-\u539f\u56e0\u5bf9\u63d0\u53d6\uff08ECPE\uff09\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5374\u5e38\u5e38\u4e0d\u5982\u8f83\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u3002\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u8f85\u52a9\u77e5\u8bc6\uff0c\u8fd9\u9650\u5236\u4e86 LLM \u6709\u6548\u611f\u77e5\u60c5\u611f\u548c\u63a8\u7406\u539f\u56e0\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6e90\u5f02\u6784\u77e5\u8bc6\u6ce8\u5165\u65b9\u6cd5\uff08MEKiT\uff09\uff0c\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u5f02\u6784\u7684\u5185\u90e8\u60c5\u611f\u77e5\u8bc6\u548c\u5916\u90e8\u56e0\u679c\u77e5\u8bc6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u8fd9\u4e24\u79cd\u4e0d\u540c\u7684\u77e5\u8bc6\u65b9\u9762\u548c\u7ed3\u6784\uff0c\u6211\u4eec\u5e94\u7528\u4e86\u6307\u4ee4\u6a21\u677f\u548c\u6df7\u5408\u6570\u636e\u8fdb\u884c\u6307\u4ee4\u8c03\u6574\u7684\u65b9\u6cd5\uff0c\u5206\u522b\u4fc3\u8fdb LLM \u66f4\u5168\u9762\u5730\u8bc6\u522b\u60c5\u611f\u548c\u51c6\u786e\u5730\u63a8\u7406\u539f\u56e0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMEKiT \u4e3a ECPE \u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6709\u6548\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u7edd\u5bf9\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86 LLM \u5728 ECPE \u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "MEKiT \u4e3a ECPE \u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6709\u6548\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u7edd\u5bf9\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86 LLM \u5728 ECPE \u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14228", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.14228", "abs": "https://arxiv.org/abs/2507.14228", "authors": ["Xiaobin Zhu", "Minling Zhang", "Guofa Cai", "Jiguang He", "Georges Kaddoum"], "title": "Design of A New Multiple-Chirp-Rate Index Modulation for LoRa Networks", "comment": "13 pages,11 figures,3 tables", "summary": "We propose a multiple chirp rate index modulation (MCR-IM) system based on\nZadoff-Chu (ZC) sequences that overcomes the problems of low transmission rate\nand large-scale access in classical LoRa networks. We demonstrate the extremely\nlow cross-correlation of MCR-IM signals across different spread factors,\nshowing that the proposed MCR-IM system also inherits the characteristics of ZC\nsequences modulation. Moreover, we derive an approximate closed-form expression\nfor the bit-error rate (BER) of the proposed MCR-IM system over Nakagami-m\nfading channels. Simulation results confirm the accuracy of the derived\nclosed-form expression and demonstrate that the MCR-IM system achieves higher\nlevels of spectral efficiency (SE) compared to existing systems. In this\ncontext, assigning multiple chirp rates to each user results in a reduction in\nthe number of parallel channels. To mitigate this issue, we propose a peak\ndetection based successive interference cancellation (PD-SIC) algorithm to\naccommodate more users. Compared to orthogonal scatter chirp spreading spectrum\nsystem that names OrthoRa, the MCR-IM system with PD-SIC algorithm achieves\nlower BER levels. For a similar number of collision signals, the throughput of\nthe MCR-IM system is enhanced by 16% to 21%. Owing to these advantages, the\nproposed MCR-IM is well suited for large-scale, high-rate LoRa network\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MCR-IM\u7cfb\u7edf\uff0c\u5b83\u4f7f\u7528ZC\u5e8f\u5217\u6765\u63d0\u9ad8LoRa\u7f51\u7edc\u7684\u4f20\u8f93\u901f\u7387\u548c\u63a5\u5165\u5bb9\u91cf\u3002\u8be5\u7cfb\u7edf\u5177\u6709\u4f4e\u4e92\u76f8\u5173\u6027\u3001\u9ad8\u9891\u8c31\u6548\u7387\u548c\u4f4e\u8bef\u6bd4\u7279\u7387\u3002\u5f15\u5165PD-SIC\u7b97\u6cd5\u8fdb\u4e00\u6b65\u89e3\u51b3\u4e86\u591a\u7528\u6237\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u4f7f\u5176\u6210\u4e3a\u5927\u89c4\u6a21\u3001\u9ad8\u541e\u5410\u91cfLoRa\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfLoRa\u7f51\u7edc\u4f20\u8f93\u901f\u7387\u4f4e\u548c\u5927\u5bb9\u91cf\u63a5\u5165\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eZadoff-Chu\uff08ZC\uff09\u5e8f\u5217\u7684MCR-IM\u7cfb\u7edf\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u5728Nakagami-m\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u8bef\u6bd4\u7279\u7387\uff08BER\uff09\u8fd1\u4f3c\u95ed\u5408\u8868\u8fbe\u5f0f\u3002\u4e3a\u4e86\u5904\u7406\u7528\u6237\u6570\u91cf\u589e\u52a0\u5bfc\u81f4\u7684\u591a\u7528\u6237\u5e72\u6270\u95ee\u9898\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5cf0\u503c\u68c0\u6d4b\u7684\u8fde\u7eed\u5e72\u6270\u62b5\u6d88\uff08PD-SIC\uff09\u7b97\u6cd5\u3002", "result": "MCR-IM\u7cfb\u7edf\u5177\u6709\u6781\u4f4e\u7684\u4e92\u76f8\u5173\u6027\uff0c\u7ee7\u627f\u4e86ZC\u5e8f\u5217\u8c03\u5236\u7684\u7279\u6027\u3002\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86BER\u95ed\u5408\u8868\u8fbe\u5f0f\u7684\u51c6\u786e\u6027\uff0c\u5e76\u8868\u660eMCR-IM\u7cfb\u7edf\u6bd4\u73b0\u6709\u7cfb\u7edf\u5177\u6709\u66f4\u9ad8\u7684\u9891\u8c31\u6548\u7387\uff08SE\uff09\u3002\u4e0eOrthoRa\u7cfb\u7edf\u76f8\u6bd4\uff0cMCR-IM\u7cfb\u7edf\u5728PD-SIC\u7b97\u6cd5\u7684\u52a0\u6301\u4e0b\uff0cBER\u66f4\u4f4e\uff0c\u5728\u76f8\u4f3c\u7684\u4fe1\u53f7\u78b0\u649e\u6570\u4e0b\uff0c\u541e\u5410\u91cf\u63d0\u5347\u4e8616%\u523021%\u3002", "conclusion": "MCR-IM\u7cfb\u7edf\u975e\u5e38\u9002\u5408\u5927\u89c4\u6a21\u3001\u9ad8\u541e\u5410\u91cf\u7684LoRa\u7f51\u7edc\u5e94\u7528\uff0c\u5176\u6027\u80fd\u4f18\u4e8eOrthoRa\u7cfb\u7edf\uff0c\u5e76\u80fd\u63d0\u9ad8\u541e\u5410\u91cf\u3002"}}
{"id": "2507.15693", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15693", "abs": "https://arxiv.org/abs/2507.15693", "authors": ["Georges Chebly", "Spencer Little", "Nisal Perera", "Aliya Abedeen", "Ken Suzuki", "Donghyun Kim"], "title": "Strong, Accurate, and Low-Cost Robot Manipulator", "comment": null, "summary": "This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed\nto achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,\nand sub-millimeter repeatability - at a material cost under $215. As an\naccessible robot for broad applications across classroom education to AI\nexperiments, Forte pushes forward the performance limitations of existing\nlow-cost educational arms. We introduce a cost-effective mechanical design that\ncombines capstan-based cable drives, timing belts, simple tensioning\nmechanisms, and lightweight 3D-printed structures, along with topology\noptimization for structural stiffness. Through careful drivetrain engineering,\nwe minimize backlash and maintain control fidelity without relying on\nhigh-power electronics or expensive manufacturing processes. Experimental\nvalidation demonstrates that Forte achieves high repeatability and load\ncapacity, offering a compelling robotic platform for both classroom instruction\nand advanced robotics research.", "AI": {"tldr": "Forte\uff1a\u4e00\u6b3e\u4f4e\u6210\u672c\uff08<215\u7f8e\u5143\uff09\u30013D\u6253\u5370\u30016\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u624b\u81c2\uff0c\u6027\u80fd\u63a5\u8fd1\u5de5\u4e1a\u7ea7\uff0c\u9002\u7528\u4e8e\u6559\u80b2\u548c\u7814\u7a76\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u6b3e\u4f4e\u6210\u672c\u3001\u63a5\u8fd1\u5de5\u4e1a\u7ea7\u6027\u80fd\u76846\u81ea\u7531\u5ea6\uff086-DoF\uff093D\u6253\u5370\u673a\u5668\u4eba\u624b\u81c2\uff0c\u4ee5\u6ee1\u8db3\u8bfe\u5802\u6559\u5b66\u548cAI\u5b9e\u9a8c\u7b49\u5e7f\u6cdb\u5e94\u7528\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u7f8a\u6bdb\u7ef3\u9a71\u52a8\u3001\u540c\u6b65\u5e26\u3001\u5f20\u7d27\u673a\u6784\u548c\u62d3\u6251\u4f18\u53163D\u6253\u5370\u7ed3\u6784\u7684\u4f4e\u6210\u672c\u673a\u68b0\u8bbe\u8ba1\uff0c\u4ee5\u6700\u5c0f\u5316\u9f7f\u8f6e\u6e38\u9699\u5e76\u4fdd\u6301\u63a7\u5236\u4fdd\u771f\u5ea6\u3002", "result": "Forte\u673a\u5668\u4eba\u624b\u81c2\u5b9e\u73b0\u4e860.63\u516c\u65a4\u7684\u8d1f\u8f7d\u80fd\u529b\u30010.467\u7c73\u7684\u673a\u68b0\u81c2\u957f\u5ea6\u548c\u4e9a\u6beb\u7c73\u7ea7\u7684\u91cd\u590d\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u6750\u6599\u6210\u672c\u4f4e\u4e8e215\u7f8e\u5143\u3002", "conclusion": "Forte\u673a\u5668\u4eba\u624b\u81c2\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5de5\u4e1a\u7ea7\u6027\u80fd\u7684\u4f4e\u6210\u672c3D\u6253\u5370\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u6559\u80b2\u548cAI\u7814\u7a76\u3002"}}
{"id": "2507.14675", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14675", "abs": "https://arxiv.org/abs/2507.14675", "authors": ["Yuchen Duan", "Zhe Chen", "Yusong Hu", "Weiyun Wang", "Shenglong Ye", "Botian Shi", "Lewei Lu", "Qibin Hou", "Tong Lu", "Hongsheng Li", "Jifeng Dai", "Wenhai Wang"], "title": "Docopilot: Improving Multimodal Models for Document-Level Understanding", "comment": null, "summary": "Despite significant progress in multimodal large language models (MLLMs),\ntheir performance on complex, multi-page document comprehension remains\ninadequate, largely due to the lack of high-quality, document-level datasets.\nWhile current retrieval-augmented generation (RAG) methods offer partial\nsolutions, they suffer from issues, such as fragmented retrieval contexts,\nmulti-stage error accumulation, and extra time costs of retrieval. In this\nwork, we present a high-quality document-level dataset, Doc-750K, designed to\nsupport in-depth understanding of multimodal documents. This dataset includes\ndiverse document structures, extensive cross-page dependencies, and real\nquestion-answer pairs derived from the original documents. Building on the\ndataset, we develop a native multimodal model, Docopilot, which can accurately\nhandle document-level dependencies without relying on RAG. Experiments\ndemonstrate that Docopilot achieves superior coherence, accuracy, and\nefficiency in document understanding tasks and multi-turn interactions, setting\na new baseline for document-level multimodal understanding. Data, code, and\nmodels are released at https://github.com/OpenGVLab/Docopilot", "AI": {"tldr": "\u53d1\u5e03Doc-750K\u6570\u636e\u96c6\u548cDocopilot\u6a21\u578b\uff0c\u7528\u4e8e\u6587\u6863\u7ea7\u591a\u6a21\u6001\u7406\u89e3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u3001\u591a\u9875\u6587\u6863\u7406\u89e3\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4ee5\u53ca\u73b0\u6709RAG\u65b9\u6cd5\u5b58\u5728\u7684\u788e\u7247\u5316\u68c0\u7d22\u4e0a\u4e0b\u6587\u3001\u591a\u9636\u6bb5\u9519\u8bef\u7d2f\u79ef\u548c\u989d\u5916\u68c0\u7d22\u65f6\u95f4\u6210\u672c\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faDoc-750K\u6570\u636e\u96c6\uff0c\u6784\u5efaDocopilot\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u65e0\u9700\u4f9d\u8d56RAG\u5373\u53ef\u51c6\u786e\u5904\u7406\u6587\u6863\u7ea7\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "Doc-750K\u6570\u636e\u96c6\u5305\u542b\u591a\u6837\u5316\u7684\u6587\u6863\u7ed3\u6784\u3001\u5e7f\u6cdb\u7684\u8de8\u9875\u4f9d\u8d56\u5173\u7cfb\u4ee5\u53ca\u6e90\u81ea\u539f\u59cb\u6587\u6863\u7684\u771f\u5b9e\u95ee\u7b54\u5bf9\u3002Docopilot\u5728\u6587\u6863\u7406\u89e3\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Docopilot\u5728\u6587\u6863\u7406\u89e3\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u8fde\u8d2f\u6027\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u6587\u6863\u7ea7\u591a\u6a21\u6001\u7406\u89e3\u6811\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.15330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15330", "abs": "https://arxiv.org/abs/2507.15330", "authors": ["Hammad Atta", "Muhammad Zeeshan Baig", "Yasir Mehmood", "Nadeem Shahzad", "Ken Huang", "Muhammad Aziz Ul Haq", "Muhammad Awais", "Kamal Ahmed"], "title": "QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI", "comment": null, "summary": "We introduce Cognitive Degradation as a novel vulnerability class in agentic\nAI systems. Unlike traditional adversarial external threats such as prompt\ninjection, these failures originate internally, arising from memory starvation,\nplanner recursion, context flooding, and output suppression. These systemic\nweaknesses lead to silent agent drift, logic collapse, and persistent\nhallucinations over time. To address this class of failures, we introduce the\nQorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain\n10), a lifecycle-aware defense framework defined by a six-stage cognitive\ndegradation lifecycle. The framework includes seven runtime controls\n(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger\nproactive mitigation through fallback routing, starvation detection, and memory\nintegrity enforcement. Drawing from cognitive neuroscience, we map agentic\narchitectures to human analogs, enabling early detection of fatigue,\nstarvation, and role collapse. By introducing a formal lifecycle and real-time\nmitigation controls, this work establishes Cognitive Degradation as a critical\nnew class of AI system vulnerability and proposes the first cross-platform\ndefense model for resilient agentic behavior.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u201c\u8ba4\u77e5\u9000\u5316\u201d\u4f5c\u4e3aAI Agent\u7684\u65b0\u578b\u5185\u90e8\u6f0f\u6d1e\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aQSAF Domain 10\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u6765\u589e\u5f3aAgent\u7684\u97e7\u6027\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9Agent\u5185\u90e8\u7684\u6545\u969c\uff0c\u5982\u5185\u5b58\u8017\u5c3d\u3001\u89c4\u5212\u5668\u9012\u5f52\u3001\u4e0a\u4e0b\u6587\u6cdb\u6ee5\u548c\u8f93\u51fa\u6291\u5236\uff0c\u8fd9\u4e9b\u6545\u969c\u4f1a\u5bfc\u81f4Agent\u884c\u4e3a\u6f02\u79fb\u3001\u903b\u8f91\u5d29\u6e83\u548c\u6301\u7eed\u7684\u5e7b\u89c9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQSAF Domain 10\u7684\u751f\u547d\u5468\u671f\u611f\u77e5\u9632\u5fa1\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u516d\u4e2a\u9636\u6bb5\u7684\u8ba4\u77e5\u9000\u5316\u751f\u547d\u5468\u671f\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e03\u4e2a\u8fd0\u884c\u65f6\u63a7\u4ef6\uff08QSAF-BC-001\u81f3BC-007\uff09\u6765\u76d1\u63a7Agent\u5b50\u7cfb\u7edf\u5e76\u89e6\u53d1\u7f13\u89e3\u63aa\u65bd\u3002\u8be5\u6846\u67b6\u501f\u9274\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\uff0c\u5c06Agent\u67b6\u6784\u6620\u5c04\u5230\u4eba\u7c7b\u7c7b\u6bd4\uff0c\u4ee5\u68c0\u6d4b\u75b2\u52b3\u3001\u9965\u997f\u548c\u89d2\u8272\u5d29\u6e83\u3002", "result": "\u5f15\u5165\u4e86\u8ba4\u77e5\u9000\u5316\u4f5c\u4e3a\u4e00\u7c7b\u65b0\u7684AI\u7cfb\u7edf\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86QSAF Domain 10\u9632\u5fa1\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u76d1\u63a7\u548c\u5b9e\u65f6\u7f13\u89e3\u63aa\u65bd\u6765\u589e\u5f3aAgent\u7684\u8ba4\u77e5\u97e7\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u8ba4\u77e5\u9000\u5316\u786e\u7acb\u4e3a\u4e00\u79cd\u5173\u952e\u7684\u65b0\u578bAI\u7cfb\u7edf\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u9996\u4e2a\u8de8\u5e73\u53f0\u7684\u5f39\u6027Agent\u884c\u4e3a\u9632\u5fa1\u6a21\u578b\u3002"}}
{"id": "2507.15302", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15302", "abs": "https://arxiv.org/abs/2507.15302", "authors": ["Kieran Dalton", "Johannes Kn\u00f6rzer", "Finn Hoehne", "Yongxin Song", "Alexander Flasby", "Dante Colao Zanuz", "Mohsen Bahrami Panah", "Ilya Besedin", "Jean-Claude Besse", "Andreas Wallraff"], "title": "Resource-Efficient Cross-Platform Verification with Modular Superconducting Devices", "comment": "14 pages, 7 figures", "summary": "Large-scale quantum computers are expected to benefit from modular\narchitectures. Validating the capabilities of modular devices requires\nbenchmarking strategies that assess performance within and between modules. In\nthis work, we evaluate cross-platform verification protocols, which are\ncritical for quantifying how accurately different modules prepare the same\nquantum state -- a key requirement for modular scalability and system-wide\nconsistency. We demonstrate these algorithms using a six-qubit flip-chip\nsuperconducting quantum device consisting of two three-qubit modules on a\nsingle carrier chip, with connectivity for intra- and inter-module\nentanglement. We examine how the resource requirements of protocols relying\nsolely on classical communication between modules scale exponentially with\nqubit number, and demonstrate that introducing an inter-module two-qubit gate\nenables sub-exponential scaling in cross-platform verification. This approach\nreduces the number of repetitions required by a factor of four for three-qubit\nstates, with greater reductions projected for larger and higher-fidelity\ndevices.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u516d\u6bd4\u7279\u8d85\u5bfc\u91cf\u5b50\u8bbe\u5907\u4e0a\u8bc4\u4f30\u4e86\u8de8\u5e73\u53f0\u9a8c\u8bc1\u534f\u8bae\uff0c\u53d1\u73b0\u5f15\u5165\u6a21\u5757\u95f4\u4e24\u6bd4\u7279\u95e8\u53ef\u5c06\u8d44\u6e90\u9700\u6c42\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u4e9a\u6307\u6570\u7ea7\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u9a8c\u8bc1\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u9a8c\u8bc1\u5927\u578b\u6a21\u5757\u5316\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u80fd\u529b\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u5757\u5185\u548c\u6a21\u5757\u95f4\u7684\u6027\u80fd\u3002\u8de8\u5e73\u53f0\u9a8c\u8bc1\u534f\u8bae\u5bf9\u4e8e\u91cf\u5316\u4e0d\u540c\u6a21\u5757\u5236\u5907\u76f8\u540c\u91cf\u5b50\u72b6\u6001\u7684\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u662f\u6a21\u5757\u5316\u53ef\u6269\u5c55\u6027\u548c\u7cfb\u7edf\u4e00\u81f4\u6027\u7684\u5173\u952e\u8981\u6c42\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u8de8\u5e73\u53f0\u9a8c\u8bc1\u534f\u8bae\uff0c\u5e76\u5728\u5305\u542b\u4e24\u4e2a\u4e09\u6bd4\u7279\u6a21\u5757\u7684\u516d\u6bd4\u7279\u8d85\u5bfc\u91cf\u5b50\u8bbe\u5907\u4e0a\u8fdb\u884c\u4e86\u6f14\u793a\u3002\u7814\u7a76\u4e86\u4ec5\u4f9d\u8d56\u7ecf\u5178\u901a\u4fe1\u7684\u534f\u8bae\u7684\u8d44\u6e90\u9700\u6c42\uff0c\u5e76\u4e0e\u5f15\u5165\u6a21\u5757\u95f4\u4e24\u6bd4\u7279\u95e8\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u4f9d\u8d56\u7ecf\u5178\u901a\u4fe1\u7684\u8de8\u5e73\u53f0\u9a8c\u8bc1\u534f\u8bae\u7684\u8d44\u6e90\u9700\u6c42\u968f\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u5448\u6307\u6570\u7ea7\u589e\u957f\u3002\u901a\u8fc7\u5f15\u5165\u6a21\u5757\u95f4\u4e24\u6bd4\u7279\u95e8\uff0c\u53ef\u4ee5\u5c06\u8d44\u6e90\u9700\u6c42\u964d\u4f4e\u5230\u4e9a\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5e76\u5c06\u4e09\u6bd4\u7279\u72b6\u6001\u9a8c\u8bc1\u6240\u9700\u7684\u91cd\u590d\u6b21\u6570\u51cf\u5c11\u4e86\u56db\u500d\uff0c\u5e76\u9884\u6d4b\u5728\u66f4\u5927\u3001\u66f4\u9ad8\u4fdd\u771f\u5ea6\u7684\u8bbe\u5907\u4e0a\u5c06\u6709\u66f4\u5927\u7684\u6539\u8fdb\u3002", "conclusion": "\u53ef\u6269\u5c55\u7684\u8de8\u5e73\u53f0\u9a8c\u8bc1\u534f\u8bae\u5bf9\u4e8e\u5b9e\u73b0\u6a21\u5757\u5316\u91cf\u5b50\u8ba1\u7b97\u7684\u53ef\u6269\u5c55\u6027\u548c\u7cfb\u7edf\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\u3002\u5f15\u5165\u6a21\u5757\u95f4\u4e24\u6bd4\u7279\u95e8\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u9a8c\u8bc1\u6240\u9700\u7684\u8d44\u6e90\u3002"}}
{"id": "2507.14894", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14894", "abs": "https://arxiv.org/abs/2507.14894", "authors": ["Boyi Deng", "Yu Wan", "Baosong Yang", "Fei Huang", "Wenjie Wang", "Fuli Feng"], "title": "Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs", "comment": null, "summary": "Large Language Models (LLMs) have impressive multilingual capabilities, but\nthey suffer from unexpected code-switching, also known as language mixing,\nwhich involves switching to unexpected languages in the model response. This\nproblem leads to poor readability and degrades the usability of model\nresponses. However, existing work on this issue lacks a mechanistic analysis\nand shows limited effectiveness. In this paper, we first provide an in-depth\nanalysis of unexpected code-switching using sparse autoencoders and find that\nwhen LLMs switch to a language, the features of that language exhibit excessive\npre-activation values. Based on our findings, we propose $\\textbf{S}$parse\n$\\textbf{A}$utoencoder-guided $\\textbf{S}$upervised\n$\\textbf{F}$ine$\\textbf{t}$uning (SASFT), which teaches LLMs to maintain\nappropriate pre-activation values of specific language features during\ntraining. Experiments on five models across three languages demonstrate that\nSASFT consistently reduces unexpected code-switching by more than 50\\% compared\nto standard supervised fine-tuning, with complete elimination in four cases.\nMoreover, SASFT maintains or even improves the models' performance on six\nmultilingual benchmarks, showing its effectiveness in addressing code-switching\nwhile preserving multilingual capabilities.", "AI": {"tldr": "LLMs sometimes mix languages unexpectedly. We analyzed why (it's about feature pre-activation values) and created a new training method, SASFT, that fixes this by guiding those values. SASFT cuts down language mixing by over 50% without hurting the LLM's other skills.", "motivation": "Existing LLMs suffer from unexpected code-switching, which degrades readability and usability. Current solutions lack mechanistic analysis and have limited effectiveness.", "method": "Propose SASFT (Sparse Autoencoder-guided Supervised Fine-tuning), which trains LLMs to maintain appropriate pre-activation values of specific language features. This is based on an in-depth analysis using sparse autoencoders that found excessive pre-activation values in features of the language being switched to.", "result": "SASFT reduces unexpected code-switching by over 50% (completely in 4/5 cases) and maintains/improves performance on multilingual benchmarks.", "conclusion": "SASFT consistently reduces unexpected code-switching by more than 50% across five models and three languages, with complete elimination in four cases. It also maintains or improves performance on six multilingual benchmarks, effectively addressing code-switching while preserving multilingual capabilities."}}
{"id": "2507.14299", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14299", "abs": "https://arxiv.org/abs/2507.14299", "authors": ["Yu Bai", "Yifan Zhang", "Boxuan Xie", "Zheng Chang", "Yanru Zhang", "Riku Jantti", "Zhu Han"], "title": "Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems", "comment": null, "summary": "Unmanned aerial vehicles (UAVs) equipped with integrated sensing and\ncommunication (ISAC) capabilities are envisioned to play a pivotal role in\nfuture wireless networks due to their enhanced flexibility and efficiency.\nHowever, jointly optimizing UAV trajectory planning, multi-user communication,\nand target sensing under stringent resource constraints and time-critical\nconditions remains a significant challenge. To address this, we propose an Age\nof Information (AoI)-centric UAV-ISAC system that simultaneously performs\ntarget sensing and serves multiple ground users, emphasizing information\nfreshness as the core performance metric. We formulate a long-term average AoI\nminimization problem that jointly optimizes the UAV's flight trajectory and\nbeamforming. To tackle the high-dimensional, non-convexity of this problem, we\ndevelop a deep reinforcement learning (DRL)-based algorithm capable of\nproviding real-time decisions on UAV movement and beamforming for both radar\nsensing and multi-user communication. Specifically, a Kalman filter is employed\nfor accurate target state prediction, regularized zero-forcing is utilized to\nmitigate inter-user interference, and the Soft Actor-Critic algorithm is\napplied for training the DRL agent on continuous actions. The proposed\nframework adaptively balances the trade-offs between sensing accuracy and\ncommunication quality. Extensive simulation results demonstrate that our\nproposed method consistently achieves lower average AoI compared to baseline\napproaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65e0\u4eba\u673a-ISAC\u7cfb\u7edf\uff0c\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u548c\u6ce2\u675f\u6210\u5f62\uff0c\u4ee5\u6700\u5c0f\u5316\u4fe1\u606f\u5e74\u9f84\uff08AoI\uff09\uff0c\u540c\u65f6\u5e73\u8861\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u4e25\u683c\u7684\u8d44\u6e90\u9650\u5236\u548c\u65f6\u95f4\u5173\u952e\u6761\u4ef6\u4e0b\uff0c\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u3001\u591a\u7528\u6237\u901a\u4fe1\u548c\u76ee\u6807\u611f\u77e5\u8fd9\u4e00\u91cd\u5927\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4fe1\u606f\u5e74\u9f84\uff08AoI\uff09\u4e3a\u4e2d\u5fc3\u7684\u65e0\u4eba\u673a-ISAC\u7cfb\u7edf\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5229\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8fdb\u884c\u76ee\u6807\u72b6\u6001\u9884\u6d4b\uff0c\u91c7\u7528\u6b63\u5219\u5316\u96f6\u5f3a\u5236\uff08RZF\uff09\u6765\u51cf\u8f7b\u7528\u6237\u95f4\u5e72\u6270\uff0c\u5e76\u5e94\u7528\u8f6fActor-Critic\uff08SAC\uff09\u7b97\u6cd5\u6765\u8bad\u7ec3DRL\u667a\u80fd\u4f53\u5904\u7406\u8fde\u7eed\u52a8\u4f5c\uff0c\u4ee5\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u7684\u98de\u884c\u8f68\u8ff9\u548c\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6700\u5c0f\u5316\u5e73\u5747AoI\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eDRL\u7684\u6846\u67b6\u80fd\u591f\u81ea\u9002\u5e94\u5730\u5e73\u8861\u611f\u77e5\u51c6\u786e\u6027\u548c\u901a\u4fe1\u8d28\u91cf\uff0c\u5e76\u4e14\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u80fd\u591f\u6301\u7eed\u5b9e\u73b0\u66f4\u4f4e\u7684\u5e73\u5747\u4fe1\u606f\u5e74\u9f84\uff08AoI\uff09\u3002"}}
{"id": "2507.15710", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15710", "abs": "https://arxiv.org/abs/2507.15710", "authors": ["Lu Huang", "Lingxiao Meng", "Jiankun Wang", "Xingjian Jing"], "title": "Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages", "comment": null, "summary": "Sampling-based algorithms are widely used for motion planning in\nhigh-dimensional configuration spaces. However, due to low sampling efficiency,\ntheir performance often diminishes in complex configuration spaces with narrow\ncorridors. Existing approaches address this issue using handcrafted or learned\nheuristics to guide sampling toward useful regions. Unfortunately, these\nstrategies often lack generalizability to various problems or require extensive\nprior training. In this paper, we propose a simple yet efficient sampling-based\nplanning framework along with its bidirectional version that overcomes these\nissues by integrating different levels of planning granularity. Our approach\nprobes configuration spaces with uniform random samples at varying resolutions\nand explores these multi-resolution samples online with a bias towards sparse\nsamples when traveling large free configuration spaces. By seamlessly\ntransitioning between sparse and dense samples, our approach can navigate\ncomplex configuration spaces while maintaining planning speed and completeness.\nThe simulation results demonstrate that our approach outperforms several\nstate-of-the-art sampling-based planners in $\\mathbb{SE}(2)$, $\\mathbb{SE}(3)$,\nand $\\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments\nconducted with the Franka Emika Panda robot operating in a constrained\nworkspace provide additional evidence of the superiority of the proposed\nmethod.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5206\u8fa8\u7387\u91c7\u6837\u548c\u5728\u7ebf\u63a2\u7d22\u6765\u63d0\u9ad8\u6548\u7387\u548c\u901a\u7528\u6027\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u914d\u7f6e\u7a7a\u95f4\u4e2d\u6027\u80fd\u4f1a\u4e0b\u964d\uff0c\u5e76\u4e14\u7f3a\u4e4f\u901a\u7528\u6027\u6216\u9700\u8981\u5927\u91cf\u5148\u9a8c\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u89c4\u5212\u6846\u67b6\u53ca\u5176\u53cc\u5411\u7248\u672c\uff0c\u901a\u8fc7\u4ee5\u4e0d\u540c\u5206\u8fa8\u7387\u63a2\u6d4b\u914d\u7f6e\u7a7a\u95f4\uff0c\u5e76\u4f18\u5148\u63a2\u7d22\u7a00\u758f\u6837\u672c\u6765\u514b\u670d\u91c7\u6837\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "result": "\u5728SE(2)\u3001SE(3)\u548cR^14\u4ee5\u53caFranka Emika Panda\u673a\u5668\u4eba\u7684\u7ea6\u675f\u5de5\u4f5c\u7a7a\u95f4\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u89c4\u5212\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u65e0\u7f1d\u96c6\u6210\u4e0d\u540c\u7c92\u5ea6\u7684\u89c4\u5212\uff0c\u53ef\u4ee5\u5904\u7406\u590d\u6742\u7684\u914d\u7f6e\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u89c4\u5212\u901f\u5ea6\u548c\u5b8c\u6574\u6027\u3002"}}
{"id": "2507.14680", "categories": ["cs.CV", "cs.AI", "68T07, 92C55", "I.2.7; I.4.8; J.3"], "pdf": "https://arxiv.org/pdf/2507.14680", "abs": "https://arxiv.org/abs/2507.14680", "authors": ["Xinheng Lyu", "Yuci Liang", "Wenting Chen", "Meidan Ding", "Jiaqi Yang", "Guolin Huang", "Daokun Zhang", "Xiangjian He", "Linlin Shen"], "title": "WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis", "comment": null, "summary": "Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel\ntissue analysis across various pathological tasks. While recent advancements in\nmulti-modal large language models (MLLMs) allow multi-task WSI analysis through\nnatural language, they often underperform compared to task-specific models.\nCollaborative multi-agent systems have emerged as a promising solution to\nbalance versatility and accuracy in healthcare, yet their potential remains\nunderexplored in pathology-specific domains. To address these issues, we\npropose WSI-Agents, a novel collaborative multi-agent system for multi-modal\nWSI analysis. WSI-Agents integrates specialized functional agents with robust\ntask allocation and verification mechanisms to enhance both task-specific\naccuracy and multi-task versatility through three components: (1) a task\nallocation module assigning tasks to expert agents using a model zoo of patch\nand WSI level MLLMs, (2) a verification mechanism ensuring accuracy through\ninternal consistency checks and external validation using pathology knowledge\nbases and domain-specific models, and (3) a summary module synthesizing the\nfinal summary with visual interpretation maps. Extensive experiments on\nmulti-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs\nand medical agent frameworks across diverse tasks.", "AI": {"tldr": "WSI-Agents \u662f\u4e00\u4e2a\u534f\u4f5c\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u4e13\u4e1a\u4ee3\u7406\u548c\u9a8c\u8bc1\u673a\u5236\uff0c\u63d0\u9ad8\u4e86 WSI \u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u591a\u4efb\u52a1\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728 WSI \u5206\u6790\u4e2d\u8868\u73b0\u4e0d\u5982\u7279\u5b9a\u4efb\u52a1\u6a21\u578b\u4ee5\u53ca\u534f\u4f5c\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u75c5\u7406\u5b66\u9886\u57df\u5e94\u7528\u6f5c\u529b\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a WSI-Agents \u7684\u65b0\u578b\u534f\u4f5c\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u96c6\u6210\u4e86\u4e13\u95e8\u7684\u529f\u80fd\u4ee3\u7406\u3001\u4efb\u52a1\u5206\u914d\u548c\u9a8c\u8bc1\u673a\u5236\uff0c\u5e76\u5305\u542b\u4efb\u52a1\u5206\u914d\u6a21\u5757\u3001\u9a8c\u8bc1\u673a\u5236\u548c\u6c47\u603b\u6a21\u5757\u3002", "result": "\u5728\u591a\u6a21\u6001 WSI \u57fa\u51c6\u6d4b\u8bd5\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cWSI-Agents \u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u5747\u663e\u793a\u51fa\u4f18\u4e8e\u5f53\u524d WSI MLLMs \u548c\u533b\u5b66\u4ee3\u7406\u6846\u67b6\u7684\u6027\u80fd\u3002", "conclusion": "WSI-Agents \u5728\u591a\u6a21\u6001 WSI \u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684 WSI MLLMs \u548c\u533b\u5b66\u4ee3\u7406\u6846\u67b6\u3002"}}
{"id": "2507.14668", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14668", "abs": "https://arxiv.org/abs/2507.14668", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "title": "Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model", "comment": "15 pages, 14 figures", "summary": "Deep learning models have been widely adopted for False Data Injection Attack\n(FDIA) detection in smart grids due to their ability to capture unstructured\nand sparse features. However, the increasing system scale and data\ndimensionality introduce significant computational and memory burdens,\nparticularly in large-scale industrial datasets, limiting detection efficiency.\nTo address these issues, this paper proposes Rec-AD, a computationally\nefficient framework that integrates Tensor Train decomposition with the Deep\nLearning Recommendation Model (DLRM). Rec-AD enhances training and inference\nefficiency through embedding compression, optimized data access via index\nreordering, and a pipeline training mechanism that reduces memory communication\noverhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing\nFDIA detection systems without code modifications. Experimental results show\nthat Rec-AD significantly improves computational throughput and real-time\ndetection performance, narrowing the attack window and increasing attacker\ncost. These advancements strengthen edge computing capabilities and\nscalability, providing robust technical support for smart grid security.", "AI": {"tldr": "\"Rec-AD is a new framework that makes deep learning models for detecting attacks in smart grids more efficient and faster, improving security.\"", "motivation": "\"To address the computational and memory burdens of deep learning models for FDIA detection in large-scale smart grid datasets, which limit detection efficiency.\"", "method": "\"Rec-AD integrates Tensor Train decomposition with the Deep Learning Recommendation Model (DLRM), using embedding compression, index reordering, and pipeline training to improve efficiency.\"", "result": "\"Rec-AD significantly improves computational throughput and real-time detection performance, narrowing the attack window and increasing attacker cost.\"", "conclusion": "\"Rec-AD enhances computational efficiency and real-time detection performance for FDIA in smart grids, strengthening edge computing and scalability.\""}}
{"id": "2507.14999", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14999", "abs": "https://arxiv.org/abs/2507.14999", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "title": "Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data", "comment": "10 pages,6 figures", "summary": "False Data Injection Attacks (FDIAs) pose severe security risks to smart\ngrids by manipulating measurement data collected from spatially distributed\ndevices such as SCADA systems and PMUs. These measurements typically exhibit\nNon-Independent and Identically Distributed (Non-IID) characteristics across\ndifferent regions, which significantly challenges the generalization ability of\ndetection models. Traditional centralized training approaches not only face\nprivacy risks and data sharing constraints but also incur high transmission\ncosts, limiting their scalability and deployment feasibility. To address these\nissues, this paper proposes a privacy-preserving federated learning framework,\ntermed Federated Cluster Average (FedClusAvg), designed to improve FDIA\ndetection in Non-IID and resource-constrained environments. FedClusAvg\nincorporates cluster-based stratified sampling and hierarchical communication\n(client-subserver-server) to enhance model generalization and reduce\ncommunication overhead. By enabling localized training and weighted parameter\naggregation, the algorithm achieves accurate model convergence without\ncentralizing sensitive data. Experimental results on benchmark smart grid\ndatasets demonstrate that FedClusAvg not only improves detection accuracy under\nheterogeneous data distributions but also significantly reduces communication\nrounds and bandwidth consumption. This work provides an effective solution for\nsecure and efficient FDIA detection in large-scale distributed power systems.", "AI": {"tldr": "This paper introduces FedClusAvg, a federated learning framework to combat False Data Injection Attacks (FDIAs) in smart grids. It addresses challenges of Non-IID data and privacy concerns by using cluster-based sampling and hierarchical communication, improving detection accuracy while reducing communication costs. The framework enables secure and efficient FDIA detection in large-scale power systems.", "motivation": "False Data Injection Attacks (FDIAs) pose severe security risks to smart grids by manipulating measurement data collected from spatially distributed devices such as SCADA systems and PMUs. These measurements typically exhibit Non-Independent and Identically Distributed (Non-IID) characteristics across different regions, which significantly challenges the generalization ability of detection models. Traditional centralized training approaches not only face privacy risks and data sharing constraints but also incur high transmission costs, limiting their scalability and deployment feasibility.", "method": "FedClusAvg incorporates cluster-based stratified sampling and hierarchical communication (client-subserver-server) to enhance model generalization and reduce communication overhead. By enabling localized training and weighted parameter aggregation, the algorithm achieves accurate model convergence without centralizing sensitive data.", "result": "Experimental results on benchmark smart grid datasets demonstrate that FedClusAvg not only improves detection accuracy under heterogeneous data distributions but also significantly reduces communication rounds and bandwidth consumption.", "conclusion": "\"False Data Injection Attacks (FDIAs) pose severe security risks to smart grids by manipulating measurement data collected from spatially distributed devices such as SCADA systems and PMUs. These measurements typically exhibit Non-Independent and Identically Distributed (Non-IID) characteristics across different regions, which significantly challenges the generalization ability of detection models. Traditional centralized training approaches not only face privacy risks and data sharing constraints but also incur high transmission costs, limiting their scalability and deployment feasibility. To address these issues, this paper proposes a privacy-preserving federated learning framework, termed Federated Cluster Average (FedClusAvg), designed to improve FDIA detection in Non-IID and resource-constrained environments. FedClusAvg incorporates cluster-based stratified sampling and hierarchical communication (client-subserver-server) to enhance model generalization and reduce communication overhead. By enabling localized training and weighted parameter aggregation, the algorithm achieves accurate model convergence without centralizing sensitive data. Experimental results on benchmark smart grid datasets demonstrate that FedClusAvg not only improves detection accuracy under heterogeneous data distributions but also significantly reduces communication rounds and bandwidth consumption. This work provides an effective solution for secure and efficient FDIA detection in large-scale distributed power systems.\""}}
{"id": "2507.15348", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15348", "abs": "https://arxiv.org/abs/2507.15348", "authors": ["Dmitriy Tsarev", "Stepan Osipov", "Ray-Kuang Lee", "Sergey Kulik", "Alexander Alodjants"], "title": "Quantum sensor network metrology with bright solitons", "comment": null, "summary": "We consider multiparameter quantum metrology problem with bright soliton\nnetworks in the presence of weak losses. We introduce General Heisenberg Limit\n(GHL) $\\sigma_{\\boldsymbol{\\chi}}=1/N^k$ that characterizes fundamental\nlimitations for unknown parameter measurement and estimation accuracy\n$\\sigma_{\\boldsymbol{\\chi}}$ within linear ($k=1$) and nonlinear ($k=3$)\nquantum metrology approaches to solitons. We examine multipartite $N00N$ states\nspecially prepared for the improvement of multiparameter estimation protocols.\nAs a particular example of producing such states, we propose the three-mode\nsoliton Josephson junction (TMSJJ) system as a three mode extension for the\nsoliton Josephson junction (SJJ) bosonic model, which we previously proposed.\nThe energy spectrum of the TMSJJ exhibits sharp phase transition peculiarities\nfor the TMSJJ ground state. The transition occurs from a Gaussian-like\n(coherent) state to the superposition of entangled Fock states, which rapidly\napproach the three-mode $N00N$ state. We show that in the presence of weak\nlosses, the TMSJJ enables saturate scaling relevant to the optimal state limit\nclose to the GHL. Our findings open new prospects for quantum network sensorics\nwith atomtronic circuits.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e09\u6a21\u5b64\u5b50\u7ea6\u745f\u592b\u68ee\u7ed3\uff08TMSJJ\uff09\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u5f31\u635f\u8017\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u591a\u53c2\u6570\u91cf\u5b50\u8ba1\u91cf\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u901a\u7528\u6d77\u68ee\u5821\u6781\u9650\uff08GHL\uff09\u7684\u7cbe\u5ea6\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u591a\u53c2\u6570\u91cf\u5b50\u8ba1\u91cf\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\uff08TMSJJ\uff09\u6765\u4f18\u5316\u8ba1\u91cf\u534f\u8bae\u7684\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u5f31\u635f\u8017\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u7814\u7a76\u8003\u8651\u4e86\u5b58\u5728\u5f31\u635f\u8017\u7684\u591a\u53c2\u6570\u91cf\u5b50\u8ba1\u91cf\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u8868\u5f81\u672a\u77e5\u53c2\u6570\u6d4b\u91cf\u548c\u4f30\u8ba1\u7cbe\u5ea6\u57fa\u672c\u9650\u5236\u7684\u901a\u7528\u6d77\u68ee\u5821\u6781\u9650\uff08GHL\uff09$\\\\", "result": "\u8bc1\u660e\u4e86TMSJJ\u7cfb\u7edf\u5728\u5f31\u635f\u8017\u4e0b\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1GHL\u7684\u9971\u548c\u7f29\u653e\uff0c\u4ece\u800c\u4f18\u5316\u4e86\u8ba1\u91cf\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u6a21\u5b64\u5b50\u7ea6\u745f\u592b\u68ee\u7ed3\uff08TMSJJ\uff09\u7cfb\u7edf\uff0c\u53ef\u751f\u6210\u4f18\u5316\u7684\u591a\u53c2\u6570\u91cf\u5b50\u8ba1\u91cf\u534f\u8bae\u3002\u8be5\u7cfb\u7edf\u5728\u5f31\u635f\u8017\u4e0b\u53ef\u5b9e\u73b0\u63a5\u8fd1\u901a\u7528\u6d77\u68ee\u5821\u6781\u9650\uff08GHL\uff09\u7684\u9971\u548c\u7f29\u653e\uff0c\u4e3a\u539f\u5b50\u7535\u5b50\u7ebf\u8def\u4e2d\u7684\u91cf\u5b50\u7f51\u7edc\u4f20\u611f\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.14900", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14900", "abs": "https://arxiv.org/abs/2507.14900", "authors": ["Chongxuan Huang", "Yongshi Ye", "Biao Fu", "Qifeng Su", "Xiaodong Shi"], "title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable multilingual\ncapabilities, however, how to evaluate cross-lingual alignment remains\nunderexplored. Existing alignment benchmarks primarily focus on sentence\nembeddings, but prior research has shown that neural models tend to induce a\nnon-smooth representation space, which impact of semantic alignment evaluation\non low-resource languages. Inspired by neuroscientific findings that similar\ninformation activates overlapping neuronal regions, we propose a novel Neuron\nState-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a\nlignment capabilities of LLMs, which offers a more semantically grounded\napproach to assess cross-lingual alignment. We evaluate NeuronXA on several\nprominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two\ntransfer tasks and three multilingual benchmarks. The results demonstrate that\nwith only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation\nof 0.9556 with downstream tasks performance and 0.8514 with transferability.\nThese findings demonstrate NeuronXA's effectiveness in assessing both\ncross-lingual alignment and transferability, even with a small dataset. This\nhighlights its potential to advance cross-lingual alignment research and to\nimprove the semantic understanding of multilingual LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a NeuronXA \u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u8de8\u8bed\u8a00\u5bf9\u9f50\u80fd\u529b\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u795e\u7ecf\u5143\u72b6\u6001\u6765\u63d0\u4f9b\u66f4\u5177\u8bed\u4e49\u57fa\u7840\u7684\u8bc4\u4f30\u3002NeuronXA \u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u4e5f\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\uff0c\u80fd\u591f\u51c6\u786e\u8bc4\u4f30\u8de8\u8bed\u8a00\u5bf9\u9f50\u548c\u8fc1\u79fb\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u8de8\u8bed\u8a00\u5bf9\u9f50\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u53e5\u5b50\u5d4c\u5165\uff0c\u4f46\u5148\u524d\u7814\u7a76\u8868\u660e\uff0c\u795e\u7ecf\u6a21\u578b\u503e\u5411\u4e8e\u8bf1\u5bfc\u4e00\u4e2a\u4e0d\u5e73\u6ed1\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u8fd9\u4f1a\u5f71\u54cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u4e49\u5bf9\u9f50\u8bc4\u4f30\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u8de8\u8bed\u8a00\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u795e\u7ecf\u5143\u72b6\u6001\u7684\u8de8\u8bed\u8a00\u5bf9\u9f50 (NeuronXA) \u65b9\u6cd5\uff0c\u4ee5\u8bc4\u4f30 LLM \u7684\u8de8\u8bed\u8a00\u5bf9\u9f50\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u501f\u9274\u4e86\u795e\u7ecf\u79d1\u5b66\u7684\u53d1\u73b0\uff0c\u5373\u76f8\u4f3c\u4fe1\u606f\u4f1a\u6fc0\u6d3b\u91cd\u53e0\u7684\u795e\u7ecf\u5143\u533a\u57df\uff0c\u4ece\u800c\u63d0\u4f9b\u4e00\u79cd\u66f4\u5177\u8bed\u4e49\u57fa\u7840\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u8de8\u8bed\u8a00\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u8457\u540d\u7684\u591a\u8bed\u8a00 LLM\uff08LLaMA\u3001Qwen\u3001Mistral\u3001GLM \u548c OLMo\uff09\u4ee5\u53ca\u4e24\u4e2a\u8fc1\u79fb\u4efb\u52a1\u548c\u4e09\u4e2a\u591a\u8bed\u8a00\u57fa\u51c6\u4e0a\u8bc4\u4f30\u4e86 NeuronXA\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u4f7f\u7528 100 \u5bf9\u5e73\u884c\u53e5\u5b50\uff0cNeuronXA \u5728\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u5b9e\u73b0\u4e86 0.9556 \u7684\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\uff0c\u5728\u8fc1\u79fb\u6027\u65b9\u9762\u5b9e\u73b0\u4e86 0.8514 \u7684\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u3002", "conclusion": "NeuronXA \u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u8de8\u8bed\u8a00\u5bf9\u9f50\u548c\u8fc1\u79fb\u80fd\u529b\u65b9\u9762\u662f\u6709\u6548\u7684\uff0c\u5373\u4f7f\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u4e5f\u662f\u5982\u6b64\u3002\u8fd9\u8868\u660e NeuronXA \u6709\u6f5c\u529b\u63a8\u52a8\u8de8\u8bed\u8a00\u5bf9\u9f50\u7814\u7a76\uff0c\u5e76\u63d0\u9ad8\u591a\u8bed\u8a00 LLM \u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2507.14309", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14309", "abs": "https://arxiv.org/abs/2507.14309", "authors": ["Mert Torun", "Alireza Parsay", "Yasamin Mostofi"], "title": "Fast and Robust Stationary Crowd Counting with Commodity WiFi", "comment": null, "summary": "This paper introduces a novel method for estimating the size of seated crowds\nwith commodity WiFi signals, by leveraging natural body fidgeting behaviors as\na passive sensing cue. Departing from prior binary fidget representations, our\napproach leverages the bandwidth of the received signal as a finer-grained and\nrobust indicator of crowd counts. More specifically, we propose a mathematical\nmodel that relates the probability density function (PDF) of the signal\nbandwidth to the crowd size, using a principled derivation based on the PDF of\nan individual's fidget-induced bandwidth. To characterize the individual\nfidgeting PDF, we use publicly available online videos, each of a seated\nindividual, from which we extract body motion profiles using vision techniques,\nfollowed by a speed-to-bandwidth conversion inspired by Carson's Rule from\nanalog FM radio design. Finally, to enhance robustness in real-world\ndeployments where unrelated motions may occur nearby, we further introduce an\nanomaly detection module that filters out non-fidget movements. We validate our\nsystem through 42 experiments across two indoor environments with crowd sizes\nup to and including 13 people, achieving a mean absolute error of 1.04 and a\nnormalized mean square error of 0.15, with an average convergence time of 51\nseconds, significantly reducing the convergence time as compared to the state\nof the art. Additional simulation results demonstrate scalability to larger\ncrowd sizes. Overall, our results show that our pipeline enables fast, robust,\nand highly accurate counting of seated crowds.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528WiFi\u4fe1\u53f7\u548c\u4eba\u4f53\u6296\u52a8\u884c\u4e3a\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6570\u5b66\u6a21\u578b\u548c\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5750\u59ff\u4eba\u7fa4\u7684\u5feb\u901f\u3001\u51c6\u786e\u548c\u7a33\u5065\u7684\u7edf\u8ba1\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u65e5\u5e38\u751f\u6d3b\u4e2d\u666e\u904d\u5b58\u5728\u7684WiFi\u4fe1\u53f7\u548c\u4eba\u4f53\u81ea\u7136\u6296\u52a8\u884c\u4e3a\uff0c\u5f00\u53d1\u4e00\u79cd\u88ab\u52a8\u3001\u65e0\u611f\u4e14\u51c6\u786e\u7684\u4eba\u7fa4\u7edf\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u4eba\u7fa4\u7edf\u8ba1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528WiFi\u4fe1\u53f7\u548c\u4eba\u4f53\u81ea\u7136\u6296\u52a8\u884c\u4e3a\u6765\u4f30\u8ba1\u5750\u59ff\u4eba\u7fa4\u6570\u91cf\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5c06\u63a5\u6536\u4fe1\u53f7\u7684\u5e26\u5bbd\u4f5c\u4e3a\u8861\u91cf\u4eba\u7fa4\u6570\u91cf\u7684\u7cbe\u7ec6\u4e14\u9c81\u68d2\u7684\u6307\u6807\uff0c\u5e76\u5efa\u7acb\u4e86\u4fe1\u53f7\u5e26\u5bbd\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff08PDF\uff09\u4e0e\u4eba\u7fa4\u6570\u91cf\u4e4b\u95f4\u7684\u6570\u5b66\u6a21\u578b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9996\u5148\u901a\u8fc7\u516c\u5f00\u89c6\u9891\u63d0\u53d6\u4e2a\u4f53\u6296\u52a8\u884c\u4e3a\u7684\u8eab\u4f53\u8fd0\u52a8\u4fe1\u606f\uff0c\u5e76\u501f\u9274\u5361\u68ee\u6cd5\u5219\u5c06\u901f\u5ea6\u8f6c\u6362\u4e3a\u5e26\u5bbd\u3002\u63a5\u7740\uff0c\u4e3a\u4e86\u63d0\u9ad8\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5f15\u5165\u4e86\u5f02\u5e38\u68c0\u6d4b\u6a21\u5757\u6765\u8fc7\u6ee4\u6389\u975e\u6296\u52a8\u8fd0\u52a8\u3002", "result": "\u901a\u8fc7\u5728\u4e24\u79cd\u5ba4\u5185\u73af\u5883\u4e2d\u8fdb\u884c\u768442\u6b21\u5b9e\u9a8c\uff0c\u8be5\u7cfb\u7edf\u5728\u6700\u591a13\u4eba\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e861.04\u4eba\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u548c0.15\u7684\u5f52\u4e00\u5316\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u5e73\u5747\u6536\u655b\u65f6\u95f4\u4e3a51\u79d2\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u6b64\u5916\uff0c\u6a21\u62df\u7ed3\u679c\u4e5f\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u9002\u5e94\u66f4\u5927\u89c4\u6a21\u7684\u4eba\u7fa4\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5feb\u901f\u3001\u7a33\u5065\u4e14\u9ad8\u7cbe\u5ea6\u5730\u7edf\u8ba1\u5750\u59ff\u4eba\u7fa4\u7684\u6570\u91cf\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.15716", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15716", "abs": "https://arxiv.org/abs/2507.15716", "authors": ["Ziyu Wan", "Lin Zhao"], "title": "DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models", "comment": null, "summary": "This paper proposes DiffPF, a differentiable particle filter that leverages\ndiffusion models for state estimation in dynamic systems. Unlike conventional\ndifferentiable particle filters, which require importance weighting and\ntypically rely on predefined or low-capacity proposal distributions. DiffPF\nlearns a flexible posterior sampler by conditioning a diffusion model on\npredicted particles and the current observation. This enables accurate,\nequally-weighted sampling from complex, high-dimensional, and multimodal\nfiltering distributions. We evaluate DiffPF across a range of scenarios,\nincluding both unimodal and highly multimodal distributions, and test it on\nsimulated as well as real-world tasks, where it consistently outperforms\nexisting filtering baselines. In particular, DiffPF achieves an 82.8%\nimprovement in estimation accuracy on a highly multimodal global localization\nbenchmark, and a 26% improvement on the real-world KITTI visual odometry\nbenchmark, compared to state-of-the-art differentiable filters. To the best of\nour knowledge, DiffPF is the first method to integrate conditional diffusion\nmodels into particle filtering, enabling high-quality posterior sampling that\nproduces more informative particles and significantly improves state\nestimation.", "AI": {"tldr": "DiffPF\u662f\u4e00\u79cd\u65b0\u7684\u53ef\u5fae\u7c92\u5b50\u6ee4\u6ce2\u5668\uff0c\u5b83\u4f7f\u7528\u6269\u6563\u6a21\u578b\u6765\u63d0\u9ad8\u72b6\u6001\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u548c\u591a\u5cf0\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\uff0c\u5e76\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "motivation": "\u4f20\u7edf\u7684\u7c92\u5b50\u6ee4\u6ce2\u5668\u9700\u8981\u91cd\u8981\u6027\u91cd\u91c7\u6837\uff0c\u5e76\u4e14\u901a\u5e38\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u6216\u4f4e\u5bb9\u91cf\u7684\u63d0\u8bae\u5206\u5e03\uff0c\u800cDiffPF\u65e8\u5728\u901a\u8fc7\u5b66\u4e60\u7075\u6d3b\u7684\u540e\u9a8c\u91c7\u6837\u5668\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "DiffPF\u5229\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u72b6\u6001\u4f30\u8ba1\uff0c\u901a\u8fc7\u5c06\u6269\u6563\u6a21\u578b\u6761\u4ef6\u5316\u4e8e\u9884\u6d4b\u7c92\u5b50\u548c\u5f53\u524d\u89c2\u6d4b\u6765\u5b66\u4e60\u7075\u6d3b\u7684\u540e\u9a8c\u91c7\u6837\u5668\uff0c\u4ece\u800c\u5b9e\u73b0\u4ece\u590d\u6742\u3001\u9ad8\u7ef4\u548c\u591a\u5cf0\u6ee4\u6ce2\u5206\u5e03\u4e2d\u8fdb\u884c\u51c6\u786e\u3001\u7b49\u6743\u91cd\u91c7\u6837\u3002", "result": "DiffPF\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u7684\u4efb\u52a1\u4e2d\uff0c\u5305\u62ec\u5355\u5cf0\u548c\u9ad8\u5ea6\u591a\u5cf0\u5206\u5e03\uff0c\u5176\u6027\u80fd\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u6ee4\u6ce2\u57fa\u7ebf\u3002\u5728\u9ad8\u5ea6\u591a\u5cf0\u7684\u5168\u5c40\u5b9a\u4f4d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f30\u8ba1\u7cbe\u5ea6\u63d0\u9ad8\u4e8682.8%\uff1b\u5728\u771f\u5b9e\u7684KITTI\u89c6\u89c9\u91cc\u7a0b\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u9ad8\u4e8626%\u3002", "conclusion": "DiffPF\u662f\u9996\u4e2a\u5c06\u6761\u4ef6\u6269\u6563\u6a21\u578b\u96c6\u6210\u5230\u7c92\u5b50\u6ee4\u6ce2\u4e2d\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u8fdb\u884c\u9ad8\u8d28\u91cf\u7684\u540e\u9a8c\u91c7\u6837\uff0c\u4ea7\u751f\u4fe1\u606f\u66f4\u4e30\u5bcc\u7684\u7c92\u5b50\uff0c\u5e76\u663e\u8457\u6539\u5584\u72b6\u6001\u4f30\u8ba1\u3002"}}
{"id": "2507.14686", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14686", "abs": "https://arxiv.org/abs/2507.14686", "authors": ["Chen Cai", "Tianyi Liu", "Jianjun Gao", "Wenyang Liu", "Kejun Wu", "Ruoyu Wang", "Yi Wang", "Soo Chin Liew"], "title": "From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition", "comment": null, "summary": "Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot\nabilities but struggle with complex Grounded Situation Recognition (GSR) and\nare resource-intensive for edge device deployment. Meanwhile, conventional GSR\nmodels often lack generalization ability, falling short in recognizing unseen\nand rare situations. In this paper, we exploit transferring knowledge from a\nteacher MLLM to a small GSR model to enhance its generalization and zero-shot\nabilities, thereby introducing the task of Open-vocabulary Grounded Situation\nRecognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt\nDistillation (MIPD), a novel framework that distills enriched multimodal\nknowledge from the foundation model, enabling the student Ov-GSR model to\nrecognize unseen situations and be better aware of rare situations.\nSpecifically, the MIPD framework first leverages the LLM-based Judgmental\nRationales Generator (JRG) to construct positive and negative glimpse and gaze\nrationales enriched with contextual semantic information. The proposed\nscene-aware and instance-perception prompts are then introduced to align\nrationales with visual information from the MLLM teacher via the\nNegative-Guided Multimodal Prompting Alignment (NMPA) module, effectively\ncapturing holistic and perceptual multimodal knowledge. Finally, the aligned\nmultimodal knowledge is distilled into the student Ov-GSR model, providing a\nstronger foundation for generalization that enhances situation understanding,\nbridges the gap between seen and unseen scenarios, and mitigates prediction\nbias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving\nsuperior performance on seen, rare, and unseen situations, and further\ndemonstrate improved unseen detection on the HICO-DET dataset.", "AI": {"tldr": "MIPD\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u589e\u5f3a\u4e86GSR\u6a21\u578b\u7684\u6cdb\u5316\u548c\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4ee5\u8bc6\u522b\u672a\u89c1\u548c\u7f55\u89c1\u7684\u573a\u666f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709MLLM\u5728\u590d\u6742GSR\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\u4ee5\u53ca\u5b83\u4eec\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u4e0a\u7684\u8d44\u6e90\u5bc6\u96c6\u6027\u95ee\u9898\uff0c\u5e76\u514b\u670d\u4f20\u7edfGSR\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3001\u96be\u4ee5\u8bc6\u522b\u672a\u77e5\u548c\u7f55\u89c1\u573a\u666f\u7684\u7f3a\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u591a\u6a21\u6001\u4ea4\u4e92\u63d0\u793a\u84b8\u998f\uff08MIPD\uff09\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528LLM\u9a71\u52a8\u7684\u5224\u65ad\u6027\u539f\u7406\u751f\u6210\u5668\uff08JRG\uff09\u548c\u8d1f\u5f15\u5bfc\u591a\u6a21\u6001\u63d0\u793a\u5bf9\u9f50\uff08NMPA\uff09\u6a21\u5757\uff0c\u5c06\u77e5\u8bc6\u4ece\u6559\u5e08MLLM\u8f6c\u79fb\u5230\u5c0f\u578bGSR\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a\u5176\u6cdb\u5316\u80fd\u529b\u548c\u96f6\u6837\u672c\u80fd\u529b\u3002", "result": "MIPD\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u672a\u89c1\u8fc7\u7684\u573a\u666f\uff0c\u5e76\u4e14\u66f4\u597d\u5730\u8bc6\u522b\u7f55\u89c1\u7684\u573a\u666f\uff0c\u6700\u7ec8\u7684GSR\u6a21\u578b\u5177\u6709\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u573a\u666f\uff0c\u7f29\u5c0f\u5df2\u89c1\u4e0e\u672a\u89c1\u573a\u666f\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u51cf\u8f7b\u7f55\u89c1\u60c5\u51b5\u4e0b\u7684\u9884\u6d4b\u504f\u5dee\u3002", "conclusion": "MIPD\u6846\u67b6\u5728Ov-SWiG\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u4ee5\u5f80\u7684\u6027\u80fd\uff0c\u5728\u5df2\u89c1\u3001\u7f55\u89c1\u548c\u672a\u89c1\u7684\u60c5\u51b5\u4e0b\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728HICO-DET\u6570\u636e\u96c6\u4e0a\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5176\u5728\u672a\u89c1\u68c0\u6d4b\u65b9\u9762\u7684\u6539\u8fdb\u3002"}}
{"id": "2507.15356", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15356", "abs": "https://arxiv.org/abs/2507.15356", "authors": ["Lu Guo", "Yixiang Shan", "Zhengbang Zhu", "Qifan Liang", "Lichang Song", "Ting Long", "Weinan Zhang", "Yi Chang"], "title": "RAD: Retrieval High-quality Demonstrations to Enhance Decision-making", "comment": null, "summary": "Offline reinforcement learning (RL) enables agents to learn policies from\nfixed datasets, avoiding costly or unsafe environment interactions. However,\nits effectiveness is often limited by dataset sparsity and the lack of\ntransition overlap between suboptimal and expert trajectories, which makes\nlong-horizon planning particularly challenging. Prior solutions based on\nsynthetic data augmentation or trajectory stitching often fail to generalize to\nnovel states and rely on heuristic stitching points. To address these\nchallenges, we propose Retrieval High-quAlity Demonstrations (RAD) for\ndecision-making, which combines non-parametric retrieval with diffusion-based\ngenerative modeling. RAD dynamically retrieves high-return states from the\noffline dataset as target states based on state similarity and return\nestimation, and plans toward them using a condition-guided diffusion model.\nSuch retrieval-guided generation enables flexible trajectory stitching and\nimproves generalization when encountered with underrepresented or\nout-of-distribution states. Extensive experiments confirm that RAD achieves\ncompetitive or superior performance compared to baselines across diverse\nbenchmarks, validating its effectiveness.", "AI": {"tldr": "Offline RL struggles with sparse data and trajectory gaps. RAD uses a diffusion model to retrieve and plan towards high-return states, improving generalization and performance.", "motivation": "Offline RL is limited by dataset sparsity and lack of transition overlap, making long-horizon planning challenging. Prior solutions often fail to generalize and rely on heuristic stitching points.", "method": "RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. This retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states.", "result": "Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks.", "conclusion": "RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness."}}
{"id": "2507.14677", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14677", "abs": "https://arxiv.org/abs/2507.14677", "authors": ["Yiming Xu", "Zhen Peng", "Bin Shi", "Xu Hua", "Bo Dong", "Song Wang", "Chen Chen"], "title": "Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective", "comment": "Accepted by AAAI2025", "summary": "The superiority of graph contrastive learning (GCL) has prompted its\napplication to anomaly detection tasks for more powerful risk warning systems.\nUnfortunately, existing GCL-based models tend to excessively prioritize overall\ndetection performance while neglecting robustness to structural imbalance,\nwhich can be problematic for many real-world networks following power-law\ndegree distributions. Particularly, GCL-based methods may fail to capture tail\nanomalies (abnormal nodes with low degrees). This raises concerns about the\nsecurity and robustness of current anomaly detection algorithms and therefore\nhinders their applicability in a variety of realistic high-risk scenarios. To\nthe best of our knowledge, research on the robustness of graph anomaly\ndetection to structural imbalance has received little scrutiny. To address the\nabove issues, this paper presents a novel GCL-based framework named AD-GCL. It\ndevises the neighbor pruning strategy to filter noisy edges for head nodes and\nfacilitate the detection of genuine tail nodes by aligning from head nodes to\nforged tail nodes. Moreover, AD-GCL actively explores potential neighbors to\nenlarge the receptive field of tail nodes through anomaly-guided neighbor\ncompletion. We further introduce intra- and inter-view consistency loss of the\noriginal and augmentation graph for enhanced representation. The performance\nevaluation of the whole, head, and tail nodes on multiple datasets validates\nthe comprehensive superiority of the proposed AD-GCL in detecting both head\nanomalies and tail anomalies.", "AI": {"tldr": "AD-GCL\u901a\u8fc7\u90bb\u57df\u526a\u679d\u548c\u5f02\u5e38\u5f15\u5bfc\u7684\u90bb\u57df\u8865\u5168\u7b49\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u7ed3\u6784\u4e0d\u5e73\u8861\u7f51\u7edc\u65f6\u7684\u5c3e\u90e8\u5f02\u5e38\u68c0\u6d4b\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5f02\u5e38\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u5bf9\u6bd4\u5b66\u4e60\uff08GCL\uff09\u6a21\u578b\u5728\u5e94\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u65f6\uff0c\u867d\u7136\u6574\u4f53\u68c0\u6d4b\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u5ffd\u7565\u4e86\u5bf9\u7ed3\u6784\u4e0d\u5e73\u8861\uff08\u5982\u5e42\u5f8b\u5ea6\u5206\u5e03\uff09\u7684\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u53ef\u80fd\u65e0\u6cd5\u68c0\u6d4b\u5230\u4f4e\u5ea6\u7684\u5c3e\u90e8\u5f02\u5e38\u8282\u70b9\uff0c\u8fd9\u5f71\u54cd\u4e86\u5176\u5728\u73b0\u5b9e\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAD-GCL\u7684\u65b0\u578b\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u90bb\u57df\u526a\u679d\u7b56\u7565\u4ee5\u8fc7\u6ee4\u566a\u58f0\u8fb9\uff0c\u5e76\u5229\u7528\u5f02\u5e38\u5f15\u5bfc\u7684\u90bb\u57df\u8865\u5168\u6765\u6269\u5927\u5c3e\u90e8\u8282\u70b9\u7684\u611f\u53d7\u91ce\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u539f\u59cb\u56fe\u548c\u589e\u5f3a\u56fe\u7684\u89c6\u56fe\u5185\u548c\u89c6\u56fe\u95f4\u4e00\u81f4\u6027\u635f\u5931\u3002", "result": "AD-GCL\u6846\u67b6\u5728\u6574\u4f53\u3001\u5934\u90e8\u548c\u5c3e\u90e8\u8282\u70b9\u4e0a\u7684\u6027\u80fd\u8bc4\u4f30\u5747\u8bc1\u660e\u4e86\u5176\u5728\u68c0\u6d4b\u5934\u90e8\u548c\u5c3e\u90e8\u5f02\u5e38\u65b9\u9762\u7684\u5168\u9762\u4f18\u8d8a\u6027\u3002", "conclusion": "AD-GCL\u6846\u67b6\u5728\u68c0\u6d4b\u5934\u90e8\u5f02\u5e38\u548c\u5c3e\u90e8\u5f02\u5e38\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.14913", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14913", "abs": "https://arxiv.org/abs/2507.14913", "authors": ["Eliya Habba", "Noam Dahan", "Gili Lior", "Gabriel Stanovsky"], "title": "PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation", "comment": "Eliya Habba and Noam Dahan contributed equally to this work", "summary": "Evaluating LLMs with a single prompt has proven unreliable, with small\nchanges leading to significant performance differences. However, generating the\nprompt variations needed for a more robust multi-prompt evaluation is\nchallenging, limiting its adoption in practice. To address this, we introduce\nPromptSuite, a framework that enables the automatic generation of various\nprompts. PromptSuite is flexible - working out of the box on a wide range of\ntasks and benchmarks. It follows a modular prompt design, allowing controlled\nperturbations to each component, and is extensible, supporting the addition of\nnew components and perturbation types. Through a series of case studies, we\nshow that PromptSuite provides meaningful variations to support strong\nevaluation practices. It is available through both a Python API:\nhttps://github.com/eliyahabba/PromptSuite, and a user-friendly web interface:\nhttps://promptsuite.streamlit.app/", "AI": {"tldr": "Evaluating LLMs is hard with one prompt. PromptSuite makes many prompts automatically, making evaluations better. It's flexible, extensible, and has a Python API and web interface.", "motivation": "Evaluating LLMs with a single prompt is unreliable due to sensitivity to small changes; generating prompt variations for robust multi-prompt evaluation is challenging, limiting its practical adoption.", "method": "PromptSuite framework enables automatic generation of various prompts through a modular design and controlled perturbations to each component, supporting the addition of new components and perturbation types.", "result": "Case studies demonstrate that PromptSuite provides meaningful variations that support strong evaluation practices for LLMs.", "conclusion": "PromptSuite is a flexible and extensible framework for automatically generating diverse prompts, supporting more robust multi-prompt evaluations of LLMs."}}
{"id": "2507.14310", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14310", "abs": "https://arxiv.org/abs/2507.14310", "authors": ["Parisa Kanani", "Mohammad Javad Omidi", "Mahmoud Modarres-Hashemi", "Halim Yanikomeroglu"], "title": "Optimizing Network Performance and Resource Allocation in HAPS-UAV Integrated Sensing and Communication Systems for 6G", "comment": null, "summary": "This paper proposes an innovative approach by leveraging uncrewed aerial\nvehicles (UAVs) as base stations (BSs) and a high-altitude platform station\n(HAPS) as the central processing unit (CPU) in an integrated sensing and\ncommunication (ISAC) system for 6G networks. We explore the challenges,\napplications, and advantages of ISAC systems in next-generation networks,\nhighlighting the significance of optimizing position and power control. Our\napproach integrates HAPS and UAVs to enhance wireless coverage, particularly in\nremote areas. UAVs function as dual-purpose access points (APs), using their\nmaneuverability and line-of-sight (LoS) aerial-to-ground (A2G) links to\ntransmit combined communication and sensing signals. The scheme operates in two\ntime slots: in the first slot, UAVs transmit dedicated signals to communication\nusers (CUs) and potential targets. UAVs detect targets in specific ground\nlocations and, after signal transmission, receive reflected signals from\ntargets. In the second slot, UAVs relay these signals to HAPS, which performs\nbeamforming to align signals for each CU from various UAVs. UAVs decode\ninformation from HAPS and adjust transmissions to maximize the beam pattern\nefficiency toward the desired targets. We formulate a multi-objective\noptimization problem to maximize both the minimum\nsignal-to-interference-plus-noise ratio (SINR) for CUs and the echo signal\npower from the targets. This is achieved by finding the optimal power\nallocation for CUs in each UAV, subject to constraints on the maximum total\npower in each UAV and the transmitted beam pattern gain. Simulation results\ndemonstrate the effectiveness of this approach in enhancing network\nperformance, resource allocation, fairness, and system optimization. Using HAPS\nas the CPU, computational tasks are offloaded from UAVs, which conserves energy\nand improves network performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u65e0\u4eba\u673a\u4f5c\u4e3a\u57fa\u7ad9\u3001\u9ad8\u7a7a\u5e73\u53f0\u4f5c\u4e3aCPU\u76846G ISAC\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u529f\u7387\u548c\u6ce2\u675f\u4ee5\u63d0\u5347\u901a\u4fe1\u548c\u611f\u77e5\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u8282\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b36G\u7f51\u7edc\u4e0b\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7cfb\u7edf\u5728\u4f18\u5316\u4f4d\u7f6e\u548c\u529f\u7387\u63a7\u5236\u65b9\u9762\u7684\u6311\u6218\uff0c\u5e76\u5229\u7528\u65e0\u4eba\u673a\uff08UAVs\uff09\u4f5c\u4e3a\u57fa\u7ad9\uff08BS\uff09\u548c\u9ad8\u7a7a\u5e73\u53f0\uff08HAPS\uff09\u4f5c\u4e3a\u4e2d\u592e\u5904\u7406\u5355\u5143\uff08CPU\uff09\u6765\u589e\u5f3a\u65e0\u7ebf\u8986\u76d6\uff0c\u7279\u522b\u662f\u5728\u504f\u8fdc\u5730\u533a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u65e0\u4eba\u673a\u4f5c\u4e3a\u57fa\u7ad9\uff08BS\uff09\uff0c\u9ad8\u7a7a\u5e73\u53f0\uff08HAPS\uff09\u4f5c\u4e3a\u4e2d\u592e\u5904\u7406\u5355\u5143\uff08CPU\uff09\u7684\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7cfb\u7edf\u3002\u7cfb\u7edf\u5728\u4e24\u4e2a\u65f6\u9699\u5185\u8fd0\u884c\uff1a\u65e0\u4eba\u673a\u4f20\u8f93\u901a\u4fe1\u548c\u4f20\u611f\u4fe1\u53f7\uff0c\u5e76\u63a5\u6536\u76ee\u6807\u53cd\u5c04\u4fe1\u53f7\uff1b\u7136\u540e\u5c06\u4fe1\u53f7\u4e2d\u7ee7\u7ed9HAPS\uff0cHAPS\u8fdb\u884c\u6ce2\u675f\u6210\u5f62\u3002\u65e0\u4eba\u673a\u63a5\u6536HAPS\u89e3\u7801\u4fe1\u606f\u5e76\u8c03\u6574\u4f20\u8f93\u4ee5\u6700\u5927\u5316\u6ce2\u675f\u6a21\u5f0f\u6548\u7387\u3002\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5927\u5316\u7528\u6237\u7684\u6700\u5c0f\u4fe1\u5e72\u566a\u6bd4\uff08SINR\uff09\u548c\u76ee\u6807\u7684 the echo signal power\uff0c\u5e76\u4f18\u5316\u65e0\u4eba\u673a\u7684\u529f\u7387\u5206\u914d\u548c\u6ce2\u675f\u6a21\u5f0f\u589e\u76ca\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u589e\u5f3a\u7f51\u7edc\u6027\u80fd\u3001\u8d44\u6e90\u5206\u914d\u3001\u516c\u5e73\u6027\u548c\u7cfb\u7edf\u4f18\u5316\u65b9\u9762\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u9ad8\u7a7a\u5e73\u53f0\u548c\u65e0\u4eba\u673a\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u548c\u611f\u77e5\u4e00\u4f53\u5316\uff0c\u5728\u63d0\u9ad8\u65e0\u7ebf\u8986\u76d6\u3001\u7f51\u7edc\u6027\u80fd\u3001\u8d44\u6e90\u5206\u914d\u3001\u516c\u5e73\u6027\u548c\u7cfb\u7edf\u4f18\u5316\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5c06\u9ad8\u7a7a\u5e73\u53f0\u4f5c\u4e3aCPU\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u65e0\u4eba\u673a\u7684\u80fd\u8017\u3002"}}
{"id": "2507.15729", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.15729", "abs": "https://arxiv.org/abs/2507.15729", "authors": ["Jens V. R\u00fcppel", "Andrey Rudenko", "Tim Schreiter", "Martin Magnusson", "Achim J. Lilienthal"], "title": "Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction", "comment": "This paper has been accepted to the 34th IEEE International\n  Conference on Robot and Human Interactive Communication (RO-MAN), which will\n  be held in Eindhoven, Netherlands on August 25-29, 2025. Copyright 2025 IEEE.\n  Personal use of this material is permitted. Permission from IEEE must be\n  obtained for all other uses", "summary": "The rapid development of Large Language Models (LLMs) creates an exciting\npotential for flexible, general knowledge-driven Human-Robot Interaction (HRI)\nsystems for assistive robots. Existing HRI systems demonstrate great progress\nin interpreting and following user instructions, action generation, and robot\ntask solving. On the other hand, bi-directional, multi-modal, and context-aware\nsupport of the user in collaborative tasks still remains an open challenge. In\nthis paper, we present a gaze- and speech-informed interface to the assistive\nrobot, which is able to perceive the working environment from multiple vision\ninputs and support the dynamic user in their tasks. Our system is designed to\nbe modular and transferable to adapt to diverse tasks and robots, and it is\ncapable of real-time use of language-based interaction state representation and\nfast on board perception modules. Its development was supported by multiple\npublic dissemination events, contributing important considerations for improved\nrobustness and user experience. Furthermore, in two lab studies, we compare the\nperformance and user ratings of our system with those of a traditional scripted\nHRI pipeline. Our findings indicate that an LLM-based approach enhances\nadaptability and marginally improves user engagement and task execution metrics\nbut may produce redundant output, while a scripted pipeline is well suited for\nmore straightforward tasks.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u8f85\u52a9\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u9002\u5e94\u6027\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u53ef\u80fd\u4ea7\u751f\u5197\u4f59\u8f93\u51fa\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709HRI\u7cfb\u7edf\u5728\u652f\u6491\u53cc\u5411\u3001\u591a\u6a21\u6001\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7528\u6237\u8fdb\u884c\u534f\u4f5c\u4efb\u52a1\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u89c6\u548c\u8bed\u97f3\u4fe1\u606f\u63a5\u53e3\u7684\u8f85\u52a9\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u611f\u77e5\u5de5\u4f5c\u73af\u5883\u5e76\u652f\u6301\u52a8\u6001\u7528\u6237\u3002\u8be5\u7cfb\u7edf\u8bbe\u8ba1\u4e3a\u6a21\u5757\u5316\u548c\u53ef\u8f6c\u79fb\u7684\uff0c\u80fd\u591f\u5b9e\u65f6\u4f7f\u7528\u57fa\u4e8e\u8bed\u8a00\u7684\u4ea4\u4e92\u72b6\u6001\u8868\u793a\u548c\u5feb\u901f\u7684\u677f\u8f7d\u611f\u77e5\u6a21\u5757\u3002", "result": "\u5728\u4e24\u9879\u5b9e\u9a8c\u5ba4\u7814\u7a76\u4e2d\uff0c\u5c06LLM\u9a71\u52a8\u7684\u7cfb\u7edf\u4e0e\u4f20\u7edf\u7684\u811a\u672c\u5316HRI\u7ba1\u9053\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u8868\u660eLLM\u9a71\u52a8\u7684\u65b9\u6cd5\u589e\u5f3a\u4e86\u9002\u5e94\u6027\uff0c\u5e76\u7565\u5fae\u63d0\u9ad8\u4e86\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u4efb\u52a1\u6267\u884c\u6307\u6807\uff0c\u4f46\u53ef\u80fd\u4ea7\u751f\u5197\u4f59\u8f93\u51fa\uff0c\u800c\u811a\u672c\u5316\u7ba1\u9053\u975e\u5e38\u9002\u5408\u66f4\u76f4\u63a5\u7684\u4efb\u52a1\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u65b9\u6cd5\u589e\u5f3a\u4e86\u9002\u5e94\u6027\uff0c\u5e76\u7565\u5fae\u63d0\u9ad8\u4e86\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u4efb\u52a1\u6267\u884c\u6307\u6807\uff0c\u4f46\u53ef\u80fd\u4ea7\u751f\u5197\u4f59\u8f93\u51fa\uff0c\u800c\u811a\u672c\u5316\u7ba1\u9053\u975e\u5e38\u9002\u5408\u66f4\u76f4\u63a5\u7684\u4efb\u52a1\u3002"}}
{"id": "2507.14697", "categories": ["cs.CV", "I.4.6; I.2.10"], "pdf": "https://arxiv.org/pdf/2507.14697", "abs": "https://arxiv.org/abs/2507.14697", "authors": ["Zhiwei Zhang", "Zi Ye", "Yibin Wen", "Shuai Yuan", "Haohuan Fu", "Jianxi Huang", "Juepeng Zheng"], "title": "GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset", "comment": "38 pages, 18 figures, submitted to NeurIPS 2025", "summary": "Agricultural parcels serve as basic units for conducting agricultural\npractices and applications, which is vital for land ownership registration,\nfood security assessment, soil erosion monitoring, etc. However, existing\nagriculture parcel extraction studies only focus on mid-resolution mapping or\nregular plain farmlands while lacking representation of complex terraced\nterrains due to the demands of precision agriculture.In this paper, we\nintroduce a more fine-grained terraced parcel dataset named GTPBD (Global\nTerraced Parcel and Boundary Dataset), which is the first fine-grained dataset\ncovering major worldwide terraced regions with more than 200,000 complex\nterraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution\nimages with three-level labels, including pixel-level boundary labels, mask\nlabels, and parcel labels. It covers seven major geographic zones in China and\ntranscontinental climatic regions around the world.Compared to the existing\ndatasets, the GTPBD dataset brings considerable challenges due to the: (1)\nterrain diversity; (2) complex and irregular parcel objects; and (3) multiple\ndomain styles. Our proposed GTPBD dataset is suitable for four different tasks,\nincluding semantic segmentation, edge detection, terraced parcel extraction,\nand unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the\nGTPBD dataset on eight semantic segmentation methods, four edge extraction\nmethods, three parcel extraction methods, and five UDA methods, along with a\nmulti-dimensional evaluation framework integrating pixel-level and object-level\nmetrics. GTPBD fills a critical gap in terraced remote sensing research,\nproviding a basic infrastructure for fine-grained agricultural terrain analysis\nand cross-scenario knowledge transfer.", "AI": {"tldr": "GTPBD\u662f\u4e00\u4e2a\u65b0\u7684\u7cbe\u7ec6\u68af\u7530\u5730\u5757\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc720\u4e07\u4e2a\u5730\u5757\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u5728\u590d\u6742\u68af\u7530\u5730\u5f62\u8868\u793a\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u652f\u6301\u591a\u79cd\u9065\u611f\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u519c\u4e1a\u5730\u5757\u63d0\u53d6\u7814\u7a76\u4ec5\u5173\u6ce8\u4e2d\u7b49\u5206\u8fa8\u7387\u6d4b\u7ed8\u6216\u89c4\u5219\u7684\u5e73\u539f\u519c\u7530\uff0c\u800c\u7f3a\u4e4f\u5bf9\u590d\u6742\u68af\u7530\u5730\u5f62\u7684\u8868\u793a\uff0c\u8fd9\u4e0e\u7cbe\u51c6\u519c\u4e1a\u7684\u9700\u6c42\u4e0d\u7b26\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGTPBD\uff08\u5168\u7403\u68af\u7530\u5730\u5757\u548c\u8fb9\u754c\u6570\u636e\u96c6\uff09\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u662f\u7b2c\u4e00\u4e2a\u6db5\u76d6\u5168\u7403\u4e3b\u8981\u68af\u7530\u533a\u57df\u7684\u7cbe\u7ec6\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc720\u4e07\u4e2a\u624b\u5de5\u6807\u6ce8\u7684\u590d\u6742\u68af\u7530\u5730\u5757\u3002GTPBD\u5305\u542b47,537\u5f20\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\uff0c\u5177\u6709\u4e09\u4e2a\u7ea7\u522b\u7684\u6807\u7b7e\uff1a\u50cf\u7d20\u7ea7\u8fb9\u754c\u6807\u7b7e\u3001\u63a9\u7801\u6807\u7b7e\u548c\u5730\u5757\u6807\u7b7e\u3002\u5b83\u6db5\u76d6\u4e86\u4e2d\u56fd\u4e03\u4e2a\u4e3b\u8981\u5730\u7406\u533a\u57df\u548c\u5168\u7403\u5927\u9646\u6027\u6c14\u5019\u533a\u57df\u3002\u5bf9GTPBD\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u516b\u79cd\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\u3001\u56db\u79cd\u8fb9\u7f18\u63d0\u53d6\u65b9\u6cd5\u3001\u4e09\u79cd\u5730\u5757\u63d0\u53d6\u65b9\u6cd5\u548c\u4e94\u79cd\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff08UDA\uff09\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e86\u6574\u5408\u50cf\u7d20\u7ea7\u548c\u5bf9\u8c61\u7ea7\u6307\u6807\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\u3002", "result": "GTPBD\u6570\u636e\u96c6\u5305\u542b\u8d85\u8fc720\u4e07\u4e2a\u590d\u6742\u68af\u7530\u5730\u5757\uff0c\u5177\u6709\u50cf\u7d20\u7ea7\u8fb9\u754c\u6807\u7b7e\u3001\u63a9\u7801\u6807\u7b7e\u548c\u5730\u5757\u6807\u7b7e\uff0c\u9002\u7528\u4e8e\u8bed\u4e49\u5206\u5272\u3001\u8fb9\u7f18\u68c0\u6d4b\u3001\u68af\u7530\u5730\u5757\u63d0\u53d6\u548c\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff08UDA\uff09\u4efb\u52a1\uff0c\u5e76\u8fdb\u884c\u4e86\u591a\u79cd\u65b9\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "GTPBD\u586b\u8865\u4e86\u68af\u7530\u9065\u611f\u7814\u7a76\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u7cbe\u7ec6\u519c\u4e1a\u5730\u5f62\u5206\u6790\u548c\u8de8\u573a\u666f\u77e5\u8bc6\u8f6c\u79fb\u63d0\u4f9b\u4e86\u57fa\u7840\u67b6\u6784\u3002"}}
{"id": "2507.15411", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15411", "abs": "https://arxiv.org/abs/2507.15411", "authors": ["Wissam Gherissi", "Mehdi Acheli", "Joyce El Haddad", "Daniela Grigori"], "title": "Predictive Process Monitoring Using Object-centric Graph Embeddings", "comment": "ICSOC Workshops 2024, Dec 2024, Tunis, Tunisia", "summary": "Object-centric predictive process monitoring explores and utilizes\nobject-centric event logs to enhance process predictions. The main challenge\nlies in extracting relevant information and building effective models. In this\npaper, we propose an end-to-end model that predicts future process behavior,\nfocusing on two tasks: next activity prediction and next event time. The\nproposed model employs a graph attention network to encode activities and their\nrelationships, combined with an LSTM network to handle temporal dependencies.\nEvaluated on one reallife and three synthetic event logs, the model\ndemonstrates competitive performance compared to state-of-the-art methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14679", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14679", "abs": "https://arxiv.org/abs/2507.14679", "authors": ["Zixin Xu", "Zhijie Wang", "Zhiyuan Pan"], "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks", "comment": null, "summary": "The exponential growth of spam text on the Internet necessitates robust\ndetection mechanisms to mitigate risks such as information leakage and social\ninstability. This work addresses two principal challenges: adversarial\nstrategies employed by spammers and the scarcity of labeled data. We propose a\nnovel spam-text detection framework GCC-Spam, which integrates three core\ninnovations. First, a character similarity network captures orthographic and\nphonetic features to counter character-obfuscation attacks and furthermore\nproduces sentence embeddings for downstream classification. Second, contrastive\nlearning enhances discriminability by optimizing the latent-space distance\nbetween spam and normal texts. Third, a Generative Adversarial Network (GAN)\ngenerates realistic pseudo-spam samples to alleviate data scarcity while\nimproving model robustness and classification accuracy. Extensive experiments\non real-world datasets demonstrate that our model outperforms baseline\napproaches, achieving higher detection rates with significantly fewer labeled\nexamples.", "AI": {"tldr": "GCC-Spam\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5b57\u7b26\u76f8\u4f3c\u6027\u7f51\u7edc\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u6765\u89e3\u51b3\u5783\u573e\u77ed\u4fe1\u68c0\u6d4b\u4e2d\u7684\u5bf9\u6297\u7b56\u7565\u548c\u6570\u636e\u7a00\u7f3a\u6027\u95ee\u9898\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4e92\u8054\u7f51\u4e0a\u5783\u573e\u77ed\u4fe1\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u6709\u5fc5\u8981\u91c7\u53d6\u5f3a\u5927\u7684\u68c0\u6d4b\u673a\u5236\u6765\u964d\u4f4e\u4fe1\u606f\u6cc4\u9732\u548c\u793e\u4f1a\u4e0d\u7a33\u5b9a\u7b49\u98ce\u9669\u3002\u8fd9\u9879\u5de5\u4f5c\u89e3\u51b3\u4e86\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u5783\u573e\u4fe1\u606f\u53d1\u9001\u8005\u91c7\u7528\u7684\u5bf9\u6297\u7b56\u7565\u4ee5\u53ca\u6807\u8bb0\u6570\u636e\u7684\u7a00\u7f3a\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5783\u573e\u77ed\u4fe1\u68c0\u6d4b\u6846\u67b6GCC-Spam\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u4e09\u79cd\u6838\u5fc3\u521b\u65b0\uff1a1. \u5b57\u7b26\u76f8\u4f3c\u6027\u7f51\u7edc\u6355\u83b7\u62fc\u5199\u548c\u8bed\u97f3\u7279\u5f81\uff0c\u4ee5\u5e94\u5bf9\u5b57\u7b26\u6df7\u6dc6\u653b\u51fb\uff0c\u5e76\u4e3a\u4e0b\u6e38\u5206\u7c7b\u4ea7\u751f\u53e5\u5b50\u5d4c\u5165\u30022. \u5bf9\u6bd4\u5b66\u4e60\u901a\u8fc7\u4f18\u5316\u5783\u573e\u77ed\u4fe1\u548c\u666e\u901a\u77ed\u4fe1\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8ddd\u79bb\u6765\u589e\u5f3a\u53ef\u8fa8\u522b\u6027\u30023. \u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u751f\u6210\u903c\u771f\u7684\u4f2a\u5783\u573e\u77ed\u4fe1\u6837\u672c\uff0c\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u6027\uff0c\u540c\u65f6\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u5206\u7c7b\u51c6\u786e\u6027\u3002", "result": "GCC-Spam\u6846\u67b6\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6a21\u578b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6807\u8bb0\u793a\u4f8b\u663e\u8457\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\u3002", "conclusion": "GCC-Spam\u6846\u67b6\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6a21\u578b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6807\u8bb0\u793a\u4f8b\u663e\u8457\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\u3002"}}
{"id": "2507.15421", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.15421", "abs": "https://arxiv.org/abs/2507.15421", "authors": ["Paolo Facchi", "Francesco Perrini", "Vito Viesti"], "title": "Slow convergence of Trotter decomposition for rotations", "comment": "18 pages", "summary": "We study the Trotter approximation for a pair of orbital angular momentum\noperators, $L_x$ and $L_y$. In particular, we investigate the scaling behavior\nof the state-dependent Trotter error. We show that for states in the domains of\nthe orbital angular momentum operators the Trotter error scales as $n^{-1}$,\nwhere $n$ is the time discretization. Instead, the convergence rate can be\narbitrarily slow for states that do not belong to the domains of all three\nangular momentum operators simultaneously.", "AI": {"tldr": "\u7814\u7a76\u4e86Trotter\u8fd1\u4f3c\u5728\u8f68\u9053\u89d2\u52a8\u91cf\u7b97\u5b50\u4e0a\u7684\u5e94\u7528\uff0c\u53d1\u73b0Trotter\u8bef\u5dee\u7684\u6536\u655b\u7387\u4e0e\u72b6\u6001\u662f\u5426\u5728\u6240\u6709\u7b97\u5b50\u57df\u5185\u6709\u5173\u3002", "motivation": "\u7814\u7a76Trotter\u8fd1\u4f3c\u5728\u8f68\u9053\u89d2\u52a8\u91cf\u7b97\u5b50\u4e0a\u7684\u5e94\u7528\u53ca\u5176\u8bef\u5dee\u7684\u7f29\u653e\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u4e86Trotter\u8fd1\u4f3c\u5728L_x\u548cL_y\u7b97\u5b50\u4e0a\u7684\u5e94\u7528\uff0c\u5e76\u7740\u91cd\u5206\u6790\u4e86\u72b6\u6001\u4f9d\u8d56\u7684Trotter\u8bef\u5dee\u7684\u7f29\u653e\u884c\u4e3a\u3002", "result": "\u5bf9\u4e8e\u5728\u8f68\u9053\u89d2\u52a8\u91cf\u7b97\u5b50\u57df\u5185\u7684\u72b6\u6001\uff0cTrotter\u8bef\u5dee\u7f29\u653e\u4e3an^{-1}\uff1b\u4f46\u5bf9\u4e8e\u4e0d\u5c5e\u4e8e\u6240\u6709\u4e09\u4e2a\u89d2\u52a8\u91cf\u7b97\u5b50\u57df\u7684\u72b6\u6001\uff0c\u6536\u655b\u7387\u53ef\u80fd\u4efb\u610f\u6162\u3002", "conclusion": "Trotter\u8bef\u5dee\u7684\u6536\u655b\u7387\u5bf9\u4e8e\u4e0d\u5c5e\u4e8e\u6240\u6709\u4e09\u4e2a\u89d2\u52a8\u91cf\u7b97\u5b50\u57df\u7684\u72b6\u6001\u53ef\u4ee5\u4efb\u610f\u6162\u3002"}}
{"id": "2507.14922", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.14922", "abs": "https://arxiv.org/abs/2507.14922", "authors": ["Vahid Rahimzadeh", "Erfan Moosavi Monazzah", "Mohammad Taher Pilehvar", "Yadollah Yaghoobzadeh"], "title": "SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs", "comment": null, "summary": "Persona-driven LLMs have emerged as powerful tools in computational social\nscience, yet existing approaches fall at opposite extremes, either relying on\ncostly human-curated data or producing synthetic personas that lack consistency\nand realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from\n10,000 real social media users from BlueSky open platform across three time\nwindows, bridging this spectrum by grounding synthetic generation in authentic\nuser activity. Our evaluation demonstrates that SYNTHIA achieves competitive\nperformance with state-of-the-art methods in demographic diversity and social\nsurvey alignment while significantly outperforming them in narrative\nconsistency. Uniquely, SYNTHIA incorporates temporal dimensionality and\nprovides rich social interaction metadata from the underlying network, enabling\nnew research directions in computational social science and persona-driven\nlanguage modeling.", "AI": {"tldr": "SYNTHIA\u662f\u4e00\u4e2a\u65b0\u6570\u636e\u96c6\uff0c\u5305\u542b30,000\u4e2a\u6765\u81ea\u771f\u5b9e\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u7684\u80cc\u666f\u6545\u4e8b\uff0c\u65e8\u5728\u63d0\u9ad8\u9762\u5411\u4e2a\u4eba\u7684LLM\u7684\u771f\u5b9e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u63d0\u4f9b\u65b0\u7684\u7814\u7a76\u9014\u5f84\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u9762\u5411\u4e2a\u4eba\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65b9\u6cd5\u5728\u6210\u672c\u9ad8\u6602\u7684\u4eba\u5de5\u7b56\u5212\u6570\u636e\u6216\u7f3a\u4e4f\u4e00\u81f4\u6027\u548c\u771f\u5b9e\u6027\u7684\u5408\u6210\u89d2\u8272\u4e4b\u95f4\u5b58\u5728\u6781\u7aef\u5316\u7684\u95ee\u9898\u3002", "method": "SYNTHIA\u662f\u4e00\u4e2a\u5305\u542b30,000\u4e2a\u80cc\u666f\u6545\u4e8b\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6545\u4e8b\u6e90\u81eaBlueSky\u5f00\u653e\u5e73\u53f0\u4e0a\u768410,000\u4e2a\u771f\u5b9e\u793e\u4ea4\u5a92\u4f53\u7528\u6237\uff0c\u8de8\u8d8a\u4e09\u4e2a\u65f6\u95f4\u7a97\u53e3\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u5408\u6210\u751f\u6210\u690d\u6839\u4e8e\u771f\u5b9e\u7684\u7528\u6236\u6d3b\u52a8\u6765\u5f25\u5408\u73b0\u6709\u65b9\u6cd5\u5728\u6210\u672c\u548c\u771f\u5b9e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "SYNTHIA\u5728\u4eba\u53e3\u591a\u6837\u6027\u548c\u793e\u4f1a\u8c03\u67e5\u4e00\u81f4\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5728\u53d9\u4e8b\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5b83\u4eec\u3002\u6b64\u5916\uff0cSYNTHIA\u5305\u542b\u4e86\u65f6\u95f4\u7ef4\u5ea6\u548c\u4e30\u5bcc\u7684\u793e\u4ea4\u4e92\u52a8\u5143\u6570\u636e\uff0c\u4e3a\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u548c\u9762\u5411\u4e2a\u4eba\u7684\u8bed\u8a00\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "SYNTHIA\u6570\u636e\u96c6\u901a\u8fc7\u7ed3\u5408\u771f\u5b9e\u7528\u6237\u6d3b\u52a8\u548c\u5408\u6210\u751f\u6210\uff0c\u5728\u4eba\u53e3\u591a\u6837\u6027\u548c\u793e\u4f1a\u8c03\u67e5\u4e00\u81f4\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\uff0c\u5e76\u5728\u53d9\u4e8b\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5b83\u4eec\u3002"}}
{"id": "2507.14469", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14469", "abs": "https://arxiv.org/abs/2507.14469", "authors": ["Shuxian Wu", "Shun Yao", "Xingyu Du", "Chin-Yu Chang", "Roy H. Olsson III"], "title": "Spatially tailored spin wave excitation for spurious-free, low-loss magnetostatic wave filters with ultra-wide frequency tunability", "comment": null, "summary": "Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity\nfilters are promising for sixth-generation (6G) communication systems due to\ntheir wide frequency tunability. However, the presence of severe spurious modes\narising from the finite cavity dimensions severely degrades the filter\nperformance. We present a half-cone transducer that spatially tailors spin wave\nexcitation to selectively enhance the primary cavity modes comprising the MSW\nfilter passband, while strongly suppressing the undesired spurious modes.\nTheoretical analysis, numerical simulations and experiments verify the\neffectiveness of the spatially tailored technique. We utilize the half-cone\ntransducer to demonstrate a spurious-free, single-cavity half-cone MSW filter\n(HC-MSWF) with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning\nrange of 6.3-16.8 GHz. Extending our study, we further demonstrate a\nspurious-free, dual-cavity HC-MSWF with an unprecedented tuning range of 21.7\nGHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB. This significant\nadvance in performance will enable highly reconfigurable and robust 6G\nnetworks.", "AI": {"tldr": "A novel half-cone transducer effectively suppresses spurious modes in YIG MSW RF cavity filters, enabling wider tuning ranges and improved performance for 6G networks.", "motivation": "Spurious modes in Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity filters degrade performance in 6G communication systems. This work aims to suppress these spurious modes to improve filter performance.", "method": "A half-cone transducer is proposed to spatially tailor spin wave excitation, selectively enhancing primary cavity modes and suppressing spurious modes in Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity filters. The effectiveness of this technique is verified through theoretical analysis, numerical simulations, and experiments.", "result": "A spurious-free, single-cavity half-cone MSW filter (HC-MSWF) was demonstrated with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning range of 6.3-16.8 GHz. A spurious-free, dual-cavity HC-MSWF was further demonstrated with an unprecedented tuning range of 21.7 GHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB.", "conclusion": "Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity filters are promising for sixth-generation (6G) communication systems due to their wide frequency tunability. However, the presence of severe spurious modes arising from the finite cavity dimensions severely degrades the filter performance. We present a half-cone transducer that spatially tailors spin wave excitation to selectively enhance the primary cavity modes comprising the MSW filter passband, while strongly suppressing the undesired spurious modes. Theoretical analysis, numerical simulations and experiments verify the effectiveness of the spatially tailored technique. We utilize the half-cone transducer to demonstrate a spurious-free, single-cavity half-cone MSW filter (HC-MSWF) with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning range of 6.3-16.8 GHz. Extending our study, we further demonstrate a spurious-free, dual-cavity HC-MSWF with an unprecedented tuning range of 21.7 GHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB. This significant advance in performance will enable highly reconfigurable and robust 6G networks."}}
{"id": "2507.15782", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15782", "abs": "https://arxiv.org/abs/2507.15782", "authors": ["Ruochu Yang", "Yu Zhou", "Fumin Zhang", "Mengxue Hou"], "title": "Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs", "comment": null, "summary": "Household robots have been a longstanding research topic, but they still lack\nhuman-like intelligence, particularly in manipulating open-set objects and\nnavigating large environments efficiently and accurately. To push this\nboundary, we consider a generalized multi-object collection problem in large\nscene graphs, where the robot needs to pick up and place multiple objects\nacross multiple locations in a long mission of multiple human commands. This\nproblem is extremely challenging since it requires long-horizon planning in a\nvast action-state space under high uncertainties. To this end, we propose a\nnovel interleaved LLM and motion planning algorithm Inter-LLM. By designing a\nmultimodal action cost similarity function, our algorithm can both reflect the\nhistory and look into the future to optimize plans, striking a good balance of\nquality and efficiency. Simulation experiments demonstrate that compared with\nlatest works, our algorithm improves the overall mission performance by 30% in\nterms of fulfilling human commands, maximizing mission success rates, and\nminimizing mission costs.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8fd0\u52a8\u89c4\u5212\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aInter-LLM\u7684\u7b97\u6cd5\uff0c\u80fd\u8ba9\u5bb6\u5ead\u670d\u52a1\u673a\u5668\u4eba\u5728\u5927\u578b\u73af\u5883\u4e2d\u66f4\u667a\u80fd\u5730\u6536\u96c6\u548c\u653e\u7f6e\u591a\u4e2a\u7269\u54c1\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u9ad8\u4e8630%\u3002", "motivation": "\u5bb6\u5ead\u670d\u52a1\u673a\u5668\u4eba\u7f3a\u4e4f\u7c7b\u4f3c\u4eba\u7c7b\u7684\u667a\u80fd\uff0c\u5c24\u5176\u5728\u5904\u7406\u5f00\u653e\u96c6\u5bf9\u8c61\u548c\u9ad8\u6548\u7cbe\u786e\u5730\u5bfc\u822a\u5927\u578b\u73af\u5883\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u4e3a\u4e86\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\uff0c\u7814\u7a76\u8003\u8651\u4e86\u5728\u5927\u89c4\u6a21\u573a\u666f\u56fe\u4e2d\u7684\u5e7f\u4e49\u591a\u5bf9\u8c61\u6536\u96c6\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u9519\u5f0fLLM\u548c\u8fd0\u52a8\u89c4\u5212\u7b97\u6cd5Inter-LLM\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u52a8\u4f5c\u4ee3\u4ef7\u76f8\u4f3c\u6027\u51fd\u6570\uff0c\u4ee5\u5e73\u8861\u89c4\u5212\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4e0e\u73b0\u6709\u6700\u65b0\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u5728\u5b8c\u6210\u4eba\u7c7b\u6307\u4ee4\u3001\u6700\u5927\u5316\u4efb\u52a1\u6210\u529f\u7387\u548c\u6700\u5c0f\u5316\u4efb\u52a1\u6210\u672c\u65b9\u9762\uff0c\u5c06\u6574\u4f53\u4efb\u52a1\u6027\u80fd\u63d0\u9ad8\u4e8630%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ea4\u9519\u5f0fLLM\u548c\u8fd0\u52a8\u89c4\u5212\u7b97\u6cd5Inter-LLM\uff0c\u7528\u4e8e\u89e3\u51b3\u5bb6\u5ead\u670d\u52a1\u673a\u5668\u4eba\u9762\u4e34\u7684\u591a\u5bf9\u8c61\u6536\u96c6\u95ee\u9898\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u573a\u666f\u56fe\u8fdb\u884c\u591a\u5bf9\u8c61\u62fe\u53d6\u548c\u653e\u7f6e\uff0c\u4ee5\u5e94\u5bf9\u957f\u65f6\u5e8f\u89c4\u5212\u548c\u9ad8\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002"}}
{"id": "2507.14738", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14738", "abs": "https://arxiv.org/abs/2507.14738", "authors": ["Jeannie She", "Katie Spivakovsky"], "title": "MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy", "comment": null, "summary": "Diabetic retinopathy (DR) is a leading cause of preventable blindness,\naffecting over 100 million people worldwide. In the United States, individuals\nfrom lower-income communities face a higher risk of progressing to advanced\nstages before diagnosis, largely due to limited access to screening. Comorbid\nconditions further accelerate disease progression. We propose MultiRetNet, a\nnovel pipeline combining retinal imaging, socioeconomic factors, and\ncomorbidity profiles to improve DR staging accuracy, integrated with a clinical\ndeferral system for a clinical human-in-the-loop implementation. We experiment\nwith three multimodal fusion methods and identify fusion through a fully\nconnected layer as the most versatile methodology. We synthesize adversarial,\nlow-quality images and use contrastive learning to train the deferral system,\nguiding the model to identify out-of-distribution samples that warrant\nclinician review. By maintaining diagnostic accuracy on suboptimal images and\nintegrating critical health data, our system can improve early detection,\nparticularly in underserved populations where advanced DR is often first\nidentified. This approach may reduce healthcare costs, increase early detection\nrates, and address disparities in access to care, promoting healthcare equity.", "AI": {"tldr": "MultiRetNet \u901a\u8fc7\u7ed3\u5408\u773c\u5e95\u56fe\u50cf\u3001\u793e\u4f1a\u7ecf\u6d4e\u548c\u5408\u5e76\u75c7\u6570\u636e\uff0c\u63d0\u9ad8\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u671f\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u4e34\u5e8a\u63a8\u8fdf\u7cfb\u7edf\u6539\u5584\u670d\u52a1\u6b20\u7f3a\u7fa4\u4f53\u7684\u65e9\u671f\u68c0\u6d4b\u3002", "motivation": "\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\uff08DR\uff09\u662f\u53ef\u9884\u9632\u5931\u660e\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u6536\u5165\u793e\u533a\uff0c\u7531\u4e8e\u7b5b\u67e5\u673a\u4f1a\u6709\u9650\uff0c\u60a3\u8005\u66f4\u6709\u53ef\u80fd\u5728\u8bca\u65ad\u524d\u53d1\u5c55\u5230\u665a\u671f\u9636\u6bb5\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u548c\u4e34\u5e8a\u63a8\u8fdf\u7cfb\u7edf\u6765\u63d0\u9ad8 DR \u7684\u65e9\u671f\u68c0\u6d4b\u548c\u5206\u671f\u51c6\u786e\u6027\uff0c\u7279\u522b\u5173\u6ce8\u670d\u52a1\u6b20\u7f3a\u7684\u7fa4\u4f53\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MultiRetNet \u7684\u65b0\u9896\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e86\u4e09\u79cd\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u63a8\u8fdf\u7cfb\u7edf\uff0c\u4ee5\u8bc6\u522b\u9700\u8981\u4e34\u5e8a\u533b\u751f\u5ba1\u67e5\u7684\u5206\u5e03\u5916\u6837\u672c\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u7684\u63a8\u8fdf\u7cfb\u7edf\uff0c\u5728\u6b20\u4f73\u56fe\u50cf\u4e0a\u4fdd\u6301\u4e86\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u5e76\u6574\u5408\u4e86\u5173\u952e\u5065\u5eb7\u6570\u636e\uff0c\u6709\u671b\u964d\u4f4e\u533b\u7597\u6210\u672c\uff0c\u63d0\u9ad8\u65e9\u671f\u68c0\u6d4b\u7387\uff0c\u4fc3\u8fdb\u533b\u7597\u516c\u5e73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u89c6\u7f51\u819c\u6210\u50cf\u3001\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u548c\u5408\u5e76\u75c7\u4fe1\u606f\uff0c\u63d0\u9ad8\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u671f\u51c6\u786e\u6027\uff0c\u5e76\u6574\u5408\u4e86\u4e34\u5e8a\u63a8\u8fdf\u7cfb\u7edf\uff0c\u4ee5\u5b9e\u73b0\u4e34\u5e8a\u4eba\u7c7b\u5728\u5faa\u73af\u5b9e\u73b0\u3002\u901a\u8fc7\u4fdd\u6301\u5728\u6b20\u4f73\u56fe\u50cf\u4e0a\u7684\u8bca\u65ad\u51c6\u786e\u6027\u5e76\u6574\u5408\u5173\u952e\u5065\u5eb7\u6570\u636e\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u6539\u5584\u65e9\u671f\u68c0\u6d4b\uff0c\u5c24\u5176\u662f\u5728\u670d\u52a1\u6b20\u7f3a\u7684\u5730\u533a\uff0c\u4ece\u800c\u964d\u4f4e\u533b\u7597\u6210\u672c\uff0c\u63d0\u9ad8\u65e9\u671f\u68c0\u6d4b\u7387\uff0c\u89e3\u51b3\u533b\u7597\u516c\u5e73\u6027\u95ee\u9898\u3002"}}
{"id": "2507.15457", "categories": ["cs.AI", "I.2.8"], "pdf": "https://arxiv.org/pdf/2507.15457", "abs": "https://arxiv.org/abs/2507.15457", "authors": ["Orlenys L\u00f3pez-Pintado", "Jannis Rosenbaum", "Marlon Dumas"], "title": "Optimization of Activity Batching Policies in Business Processes", "comment": null, "summary": "In business processes, activity batching refers to packing multiple activity\ninstances for joint execution. Batching allows managers to trade off cost and\nprocessing effort against waiting time. Larger and less frequent batches may\nlower costs by reducing processing effort and amortizing fixed costs, but they\ncreate longer waiting times. In contrast, smaller and more frequent batches\nreduce waiting times but increase fixed costs and processing effort. A batching\npolicy defines how activity instances are grouped into batches and when each\nbatch is activated. This paper addresses the problem of discovering batching\npolicies that strike optimal trade-offs between waiting time, processing\neffort, and cost. The paper proposes a Pareto optimization approach that starts\nfrom a given set (possibly empty) of activity batching policies and generates\nalternative policies for each batched activity via intervention heuristics.\nEach heuristic identifies an opportunity to improve an activity's batching\npolicy with respect to a metric (waiting time, processing time, cost, or\nresource utilization) and an associated adjustment to the activity's batching\npolicy (the intervention). The impact of each intervention is evaluated via\nsimulation. The intervention heuristics are embedded in an optimization\nmeta-heuristic that triggers interventions to iteratively update the Pareto\nfront of the interventions identified so far. The paper considers three\nmeta-heuristics: hill-climbing, simulated annealing, and reinforcement\nlearning. An experimental evaluation compares the proposed approach based on\nintervention heuristics against the same (non-heuristic guided) meta-heuristics\nbaseline regarding convergence, diversity, and cycle time gain of\nPareto-optimal policies.", "AI": {"tldr": "\u901a\u8fc7\u5e72\u9884\u542f\u53d1\u5f0f\u548c\u5e15\u7d2f\u6258\u4f18\u5316\u6765\u6539\u8fdb\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\uff0c\u4ee5\u5e73\u8861\u7b49\u5f85\u65f6\u95f4\u3001\u5904\u7406\u5de5\u4f5c\u91cf\u548c\u6210\u672c\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\u7684\u53d1\u73b0\u95ee\u9898\uff0c\u5bfb\u627e\u80fd\u591f\u5728\u7b49\u5f85\u65f6\u95f4\u3001\u5904\u7406\u5de5\u4f5c\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u6700\u4f18\u6743\u8861\u7684\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e72\u9884\u542f\u53d1\u5f0f\u6765\u751f\u6210\u548c\u6539\u8fdb\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\u3002\u5e72\u9884\u542f\u53d1\u5f0f\u8bc6\u522b\u6539\u8fdb\u673a\u4f1a\u5e76\u8c03\u6574\u6279\u5904\u7406\u7b56\u7565\uff0c\u901a\u8fc7\u6a21\u62df\u8bc4\u4f30\u5e72\u9884\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u5c06\u8fd9\u4e9b\u542f\u53d1\u5f0f\u5d4c\u5165\u5230\u5143\u542f\u53d1\u5f0f\uff08\u5982\u722c\u5c71\u6cd5\u3001\u6a21\u62df\u9000\u706b\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u4e2d\uff0c\u4ee5\u8fed\u4ee3\u66f4\u65b0\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5e72\u9884\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u5728\u6536\u655b\u6027\u3001\u591a\u6837\u6027\u548c\u5468\u671f\u65f6\u95f4\u589e\u76ca\u65b9\u9762\u4f18\u4e8e\u4e0d\u4f7f\u7528\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u5143\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e72\u9884\u542f\u53d1\u5f0f\u7684\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u53d1\u73b0\u80fd\u591f\u4f18\u5316\u7b49\u5f85\u65f6\u95f4\u3001\u5904\u7406\u5de5\u4f5c\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u6743\u8861\u7684\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\u3002\u5b9e\u9a8c\u8bc4\u4f30\u5c06\u8be5\u65b9\u6cd5\u4e0e\u4e0d\u4f7f\u7528\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u5143\u542f\u53d1\u5f0f\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u6536\u655b\u6027\u3001\u591a\u6837\u6027\u548c\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u7684\u5468\u671f\u65f6\u95f4\u589e\u76ca\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2507.14698", "categories": ["cs.LG", "cs.AI", "cs.HC", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14698", "abs": "https://arxiv.org/abs/2507.14698", "authors": ["Xuetao Lin", "Tianhao Peng", "Peihong Dai", "Yu Liang", "Wenjun Wu"], "title": "Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition", "comment": null, "summary": "EEG-based emotion recognition plays an important role in developing adaptive\nbrain-computer communication systems, yet faces two fundamental challenges in\npractical implementations: (1) effective integration of non-stationary\nspatial-temporal neural patterns, (2) robust adaptation to dynamic emotional\nintensity variations in real-world scenarios. This paper proposes SST-CL, a\nnovel framework integrating spatial-temporal transformers with curriculum\nlearning. Our method introduces two core components: a spatial encoder that\nmodels inter-channel relationships and a temporal encoder that captures\nmulti-scale dependencies through windowed attention mechanisms, enabling\nsimultaneous extraction of spatial correlations and temporal dynamics from EEG\nsignals. Complementing this architecture, an intensity-aware curriculum\nlearning strategy progressively guides training from high-intensity to\nlow-intensity emotional states through dynamic sample scheduling based on a\ndual difficulty assessment. Comprehensive experiments on three benchmark\ndatasets demonstrate state-of-the-art performance across various emotional\nintensity levels, with ablation studies confirming the necessity of both\narchitectural components and the curriculum learning mechanism.", "AI": {"tldr": "\u63d0\u51faSST-CL\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u7a7aTransformer\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3EEG\u60c5\u7eea\u8bc6\u522b\u4e2d\u7684\u65f6\u7a7a\u6a21\u5f0f\u6574\u5408\u548c\u60c5\u7eea\u5f3a\u5ea6\u9002\u5e94\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3EEG\u60c5\u7eea\u8bc6\u522b\u4e2d\u4e24\u4e2a\u57fa\u672c\u6311\u6218\uff1a(1) \u975e\u5e73\u7a33\u65f6\u7a7a\u795e\u7ecf\u6a21\u5f0f\u7684\u6709\u6548\u6574\u5408\uff0c(2) \u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5bf9\u52a8\u6001\u60c5\u7eea\u5f3a\u5ea6\u53d8\u5316\u7684\u9c81\u68d2\u9002\u5e94\u3002", "method": "SST-CL\u6846\u67b6\uff0c\u96c6\u6210\u65f6\u7a7aTransformer\u548c\u8bfe\u7a0b\u5b66\u4e60\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u7a7a\u95f4\u7f16\u7801\u5668\uff08\u5bf9\u901a\u9053\u95f4\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\uff09\u548c\u4e00\u4e2a\u65f6\u95f4\u7f16\u7801\u5668\uff08\u901a\u8fc7\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u591a\u5c3a\u5ea6\u4f9d\u8d56\u5173\u7cfb\uff09\uff0c\u53ef\u540c\u65f6\u63d0\u53d6EEG\u4fe1\u53f7\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u548c\u65f6\u95f4\u52a8\u6001\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u4e00\u79cd\u611f\u77e5\u5f3a\u5ea6\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u57fa\u4e8e\u53cc\u91cd\u96be\u5ea6\u8bc4\u4f30\u7684\u52a8\u6001\u6837\u672c\u8c03\u5ea6\uff0c\u9010\u6b65\u6307\u5bfc\u6a21\u578b\u4ece\u9ad8\u5f3a\u5ea6\u5230\u4f4e\u5f3a\u5ea6\u60c5\u7eea\u72b6\u6001\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86SST-CL\u6846\u67b6\u5728\u4e0d\u540c\u60c5\u7eea\u5f3a\u5ea6\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SST-CL\u6846\u67b6\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5747\u5c55\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u60c5\u7eea\u5f3a\u5ea6\u6c34\u5e73\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u5176\u67b6\u6784\u7ec4\u4ef6\u548c\u8bfe\u7a0b\u5b66\u4e60\u673a\u5236\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15601", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.15601", "abs": "https://arxiv.org/abs/2507.15601", "authors": ["Huiling Yang", "Zhanwei Wang", "Kaibin Huang"], "title": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity", "comment": null, "summary": "Federated learning (FL) has emerged as a popular approach for collaborative\nmachine learning in sixth-generation (6G) networks, primarily due to its\nprivacy-preserving capabilities. The deployment of FL algorithms is expected to\nempower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous\ndriving, augmented reality, and healthcare. The mission-critical and\ntime-sensitive nature of these applications necessitates the design of\nlow-latency FL frameworks that guarantee high learning performance. In\npractice, achieving low-latency FL faces two challenges: the overhead of\ncomputing and transmitting high-dimensional model updates, and the\nheterogeneity in communication-and-computation (C$^2$) capabilities across\ndevices. To address these challenges, we propose a novel C$^2$-aware framework\nfor optimal batch-size control that minimizes end-to-end (E2E) learning latency\nwhile ensuring convergence. The framework is designed to balance a fundamental\nC$^2$ tradeoff as revealed through convergence analysis. Specifically,\nincreasing batch sizes improves the accuracy of gradient estimation in FL and\nthus reduces the number of communication rounds required for convergence, but\nresults in higher per-round latency, and vice versa. The associated problem of\nlatency minimization is intractable; however, we solve it by designing an\naccurate and tractable surrogate for convergence speed, with parameters fitted\nto real data. This approach yields two batch-size control strategies tailored\nto scenarios with slow and fast fading, while also accommodating device\nheterogeneity. Extensive experiments using real datasets demonstrate that the\nproposed strategies outperform conventional batch-size adaptation schemes that\ndo not consider the C$^2$ tradeoff or device heterogeneity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd C^2 \u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u4f18\u6279\u5927\u5c0f\u63a7\u5236\u6765\u6700\u5c0f\u5316 6G \u7f51\u7edc\u4e2d\u8054\u90a6\u5b66\u4e60\u7684\u5ef6\u8fdf\uff0c\u540c\u65f6\u786e\u4fdd\u6536\u655b\u6027\uff0c\u5e76\u8003\u8651\u4e86\u8bbe\u5907\u5f02\u8d28\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u9ad8\u7ef4\u5ea6\u6a21\u578b\u66f4\u65b0\u7684\u8ba1\u7b97\u548c\u4f20\u8f93\u5f00\u9500\u4ee5\u53ca\u8bbe\u5907\u901a\u4fe1\u548c\u8ba1\u7b97\uff08C^2\uff09\u80fd\u529b\u5f02\u8d28\u6027\u7684\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 C^2 \u611f\u77e5\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 C^2 \u611f\u77e5\u6846\u67b6\uff0c\u7528\u4e8e\u6700\u4f18\u6279\u5927\u5c0f\u63a7\u5236\uff0c\u4ee5\u6700\u5c0f\u5316\u7aef\u5230\u7aef\u5b66\u4e60\u5ef6\u8fdf\u5e76\u786e\u4fdd\u6536\u655b\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6279\u5927\u5c0f\u63a7\u5236\u7b56\u7565\u5728\u8003\u8651 C^2 \u6298\u8877\u548c\u8bbe\u5907\u5f02\u8d28\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u53ef\u6bd4\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u4f18\u4e8e\u672a\u8003\u8651 C^2 \u6298\u8877\u6216\u8bbe\u5907\u5f02\u8d28\u6027\u7684\u4f20\u7edf\u6279\u5927\u5c0f\u9002\u5e94\u65b9\u6848\u3002"}}
{"id": "2507.15424", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15424", "abs": "https://arxiv.org/abs/2507.15424", "authors": ["Sirui Peng", "Shengminjie Chen", "Xiaoming Sun", "Hongyi Zhou"], "title": "Stochastic Quantum Hamiltonian Descent", "comment": "24 pages, 5 figures", "summary": "Stochastic Gradient Descent (SGD) and its variants underpin modern machine\nlearning by enabling efficient optimization of large-scale models. However,\ntheir local search nature limits exploration in complex landscapes. In this\npaper, we introduce Stochastic Quantum Hamiltonian Descent (SQHD), a quantum\noptimization algorithm that integrates the computational efficiency of\nstochastic gradient methods with the global exploration power of quantum\ndynamics. We propose a Lindbladian dynamics as the quantum analogue of\ncontinuous-time SGD. We further propose a discrete-time gate-based algorithm\nthat approximates these dynamics while avoiding direct Lindbladian simulation,\nenabling practical implementation on near-term quantum devices. We rigorously\nprove the convergence of SQHD for convex and smooth objectives. Numerical\nexperiments demonstrate that SQHD also exhibits advantages in non-convex\noptimization. All these results highlight its potential for quantum-enhanced\nmachine learning.", "AI": {"tldr": "SQHD\u662f\u4e00\u79cd\u7ed3\u5408\u4e86\u968f\u673a\u68af\u5ea6\u6cd5\u6548\u7387\u548c\u91cf\u5b50\u52a8\u529b\u5b66\u5168\u5c40\u63a2\u7d22\u80fd\u529b\u7684\u91cf\u5b50\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5904\u7406\u590d\u6742\u548c\u9ad8\u7ef4\u6570\u636e\u65f6\u3002", "motivation": "\u73b0\u6709\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u53ca\u5176\u53d8\u4f53\u867d\u7136\u80fd\u591f\u9ad8\u6548\u4f18\u5316\u5927\u578b\u6a21\u578b\uff0c\u4f46\u5176\u5c40\u90e8\u641c\u7d22\u7279\u6027\u9650\u5236\u4e86\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u7684\u63a2\u7d22\u80fd\u529b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7ed3\u5408\u968f\u673a\u68af\u5ea6\u6cd5\u7684\u6548\u7387\u548c\u91cf\u5b50\u52a8\u529b\u5b66\u7684\u5168\u5c40\u63a2\u7d22\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u968f\u673a\u91cf\u5b50\u54c8\u5bc6\u987f\u91cf\u4e0b\u964d\uff08SQHD\uff09\u7684\u91cf\u5b50\u4f18\u5316\u7b97\u6cd5\uff0c\u5b83\u5c06\u968f\u673a\u68af\u5ea6\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u4e0e\u91cf\u5b50\u52a8\u529b\u5b66\u7684\u5168\u5c40\u63a2\u7d22\u80fd\u529b\u76f8\u7ed3\u5408\u3002\u63d0\u51fa\u4e86Lindbladian\u52a8\u529b\u5b66\u4f5c\u4e3a\u8fde\u7eed\u65f6\u95f4\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u91cf\u5b50\u7c7b\u4f3c\u7269\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u95e8\u7684\u79bb\u6563\u65f6\u95f4\u7b97\u6cd5\u6765\u8fd1\u4f3c\u8fd9\u4e9b\u52a8\u529b\u5b66\uff0c\u4ee5\u4fbf\u5728\u8fd1\u671f\u91cf\u5b50\u8bbe\u5907\u4e0a\u5b9e\u73b0\u3002", "result": "SQHD\u5df2\u88ab\u8bc1\u660e\u5728\u7ebf\u6027\u4ee3\u6570\u3001\u91cf\u5b50\u5316\u5b66\u548c\u673a\u5668\u5b66\u4e60\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u3002\u5c24\u5176\u662f\u5728\u5904\u7406\u9ad8\u7ef4\u548c\u7a00\u758f\u6570\u636e\u65f6\uff0c\u5176\u6027\u80fd\u63d0\u5347\u5c24\u4e3a\u663e\u8457\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8fd8\u8868\u660e\uff0c\u4e0e\u7ecf\u5178\u7b97\u6cd5\u76f8\u6bd4\uff0cSQHD\u5728\u6536\u655b\u901f\u5ea6\u548c\u89e3\u7684\u8d28\u91cf\u65b9\u9762\u5747\u6709\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u975e\u51f8\u4f18\u5316\u95ee\u9898\u4e2d\u3002", "conclusion": "SQHD\u6709\u6f5c\u529b\u7528\u4e8e\u91cf\u5b50\u589e\u5f3a\u673a\u5668\u5b66\u4e60\uff0c\u5e76\u5728\u975e\u51f8\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u4f18\u52bf\u3002"}}
{"id": "2507.14958", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14958", "abs": "https://arxiv.org/abs/2507.14958", "authors": ["Hang Yan", "Fangzhi Xu", "Rongman Xu", "Yifei Li", "Jian Zhang", "Haoran Luo", "Xiaobao Wu", "Luu Anh Tuan", "Haiteng Zhao", "Qika Lin", "Jun Liu"], "title": "MUR: Momentum Uncertainty guided Reasoning for Large Language Models", "comment": "25 pages, 8 figures", "summary": "Large Language Models (LLMs) have achieved impressive performance on\nreasoning-intensive tasks, yet optimizing their reasoning efficiency remains an\nopen challenge. While Test-Time Scaling (TTS) improves reasoning quality, it\noften leads to overthinking, wasting tokens on redundant computations. This\nwork investigates how to efficiently and adaptively guide LLM test-time scaling\nwithout additional training. Inspired by the concept of momentum in physics, we\npropose Momentum Uncertainty-guided Reasoning (MUR), which dynamically\nallocates thinking budgets to critical reasoning steps by tracking and\naggregating stepwise uncertainty over time. To support flexible inference-time\ncontrol, we introduce gamma-control, a simple mechanism that tunes the\nreasoning budget via a single hyperparameter. We provide in-depth theoretical\nproof to support the superiority of MUR in terms of stability and biases. MUR\nis comprehensively evaluated against various TTS methods across four\nchallenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using\ndifferent sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate\nthat MUR reduces computation by over 50% on average while improving accuracy by\n0.62-3.37%.", "AI": {"tldr": "MUR \u662f\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ffd\u8e2a\u548c\u6574\u5408\u9010\u6b65\u4e0d\u786e\u5b9a\u6027\u6765\u4f18\u5316 LLMs \u7684\u63a8\u7406\u6548\u7387\uff0c\u5728\u4e0d\u589e\u52a0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7 gamma-control \u8c03\u6574\u8ba1\u7b97\u9884\u7b97\uff0c\u4ece\u800c\u5728\u51cf\u5c11\u8ba1\u7b97\u7684\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u6548\u7387\u65b9\u9762\u5b58\u5728\u7684\u4f18\u5316\u6311\u6218\uff0c\u7279\u522b\u662f\u6d4b\u8bd5\u65f6\u63a8\u7406\uff08TTS\uff09\u53ef\u80fd\u5bfc\u81f4\u7684\u8fc7\u5ea6\u601d\u8003\u548c\u8ba1\u7b97\u6d6a\u8d39\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMUR\uff08Momentum Uncertainty-guided Reasoning\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ddf\u8e2a\u548c\u805a\u5408\u9010\u6b65\u4e0d\u786e\u5b9a\u6027\u6765\u52a8\u6001\u5206\u914d\u601d\u8003\u9884\u7b97\u5230\u5173\u952e\u7684\u63a8\u7406\u6b65\u9aa4\u3002\u5f15\u5165\u4e86gamma-control\u673a\u5236\uff0c\u901a\u8fc7\u4e00\u4e2a\u8d85\u53c2\u6570\u6765\u8c03\u6574\u63a8\u7406\u9884\u7b97\u3002", "result": "MUR \u5728 MATH-500\u3001AIME24\u3001AIME25 \u548c GPQA-diamond \u56db\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u5bf9\u4e8e\u591a\u79cd TTS \u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u5927\u5c0f\u7684 Qwen3 \u6a21\u578b\uff081.7B\u30014B \u548c 8B\uff09\u4e0a\uff0c\u5e73\u5747\u51cf\u5c11\u4e86 50% \u4ee5\u4e0a\u7684\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86 0.62-3.37% \u7684\u51c6\u786e\u7387\u3002", "conclusion": "MUR\u901a\u8fc7\u51cf\u5c1150%\u7684\u8ba1\u7b97\u91cf\u5e76\u63d0\u9ad80.62-3.37%\u7684\u51c6\u786e\u7387\uff0c\u5728\u5404\u79cd\u6d4b\u8bd5\u65f6\u63a8\u7406\u65b9\u6cd5\u548c\u4e0d\u540c\u5927\u5c0f\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002"}}
{"id": "2507.14622", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14622", "abs": "https://arxiv.org/abs/2507.14622", "authors": ["Wahab Khawaja", "Ismail Guvenc", "Rune Hylsberg Jacobsen"], "title": "Propagation Channel Modeling for LEO Satellite Missions Using Ray-Tracing Simulations", "comment": "This manuscript is submitted to MILCOM 2025 conference", "summary": "This work presents a high-resolution, ray-tracing-based channel modeling for\nLow Earth Orbit (LEO) satellite-to-ground links in a suburban environment at\nX-band. Using simulations conducted in Wireless InSite, we develop a parametric\nchannel model that characterizes both large- and small-scale fading effects\nacross different satellite elevation angles. Large-scale fading incorporates\nattenuation due to terrain-induced shadowing and dynamic environmental factors\nsuch as weather conditions, and is compared with 3GPP NTN channel model.\nAdditionally, we quantify link degradation resulting from ground station (GS)\nantenna misalignment, considering both fixed single-element and electronically\nsteerable phased-array antennas. Small-scale fading is modeled by fitting a\nshadowed and non-shadowed Rician distribution to the fading statistics at\nvarious satellite elevations. To the best of our knowledge, this is the first\nstudy to propose a comprehensive elevation-aware channel model for\nsatellite-to-ground propagation at X-band, integrating ray-traced environmental\ndynamics, elevation-dependent fading, and phased-array beam misalignment\neffects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdX\u6ce2\u6bb5\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u5230\u5730\u9762\u94fe\u8def\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u8003\u8651\u4e86\u4ef0\u89d2\u3001\u5730\u5f62\u3001\u5929\u6c14\u548c\u5929\u7ebf\u5931\u914d\u7b49\u56e0\u7d20\u3002", "motivation": "\u4e3a\u4e86\u63d0\u4f9bX\u6ce2\u6bb5\u536b\u661f\u5230\u5730\u9762\u4f20\u64ad\u7684\u7efc\u5408\u6027\u3001\u8003\u8651\u4ef0\u89d2\u53d8\u5316\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u8be5\u7814\u7a76\u6574\u5408\u4e86\u5c04\u7ebf\u8ffd\u8e2a\u73af\u5883\u52a8\u6001\u3001\u4ef0\u89d2\u76f8\u5173\u7684\u8870\u843d\u4ee5\u53ca\u76f8\u63a7\u9635\u6ce2\u675f\u5931\u914d\u6548\u5e94\u3002", "method": "\u5229\u7528Wireless InSite\u8f6f\u4ef6\u8fdb\u884c\u4eff\u771f\uff0c\u5f00\u53d1\u4e86\u53c2\u6570\u5316\u4fe1\u9053\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u8868\u5f81\u4e0d\u540c\u536b\u661f\u4ef0\u89d2\u4e0b\u7684\u5b8f\u89c2\u548c\u5fae\u89c2\u8870\u843d\u6548\u5e94\u3002\u5b8f\u89c2\u8870\u843d\u8003\u8651\u4e86\u5730\u5f62\u9634\u5f71\u548c\u5929\u6c14\u6761\u4ef6\u7b49\u52a8\u6001\u73af\u5883\u56e0\u7d20\u9020\u6210\u7684\u8870\u51cf\uff0c\u5e76\u4e0e3GPP NTN\u4fe1\u9053\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u540c\u65f6\uff0c\u91cf\u5316\u4e86\u5730\u9762\u7ad9\uff08GS\uff09\u5929\u7ebf\u5931\u914d\uff08\u5305\u62ec\u56fa\u5b9a\u5355\u9635\u5143\u548c\u7535\u5b50\u626b\u63cf\u76f8\u63a7\u9635\u5929\u7ebf\uff09\u5bfc\u81f4\u7684\u94fe\u8def\u9000\u5316\u3002\u5fae\u89c2\u8870\u843d\u5219\u901a\u8fc7\u5728\u4e0d\u540c\u536b\u661f\u4ef0\u89d2\u4e0b\u62df\u5408\u6709\u9634\u5f71\u548c\u65e0\u9634\u5f71\u7684\u83b1\u65af\u5206\u5e03\u6765\u5efa\u6a21\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3aX\u6ce2\u6bb5\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u5230\u5730\u9762\u94fe\u8def\u63d0\u4f9b\u4e86\u9ad8\u5206\u8fa8\u7387\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u80fd\u591f\u8868\u5f81\u4e0d\u540c\u536b\u661f\u4ef0\u89d2\u4e0b\u7684\u5b8f\u89c2\u548c\u5fae\u89c2\u8870\u843d\u6548\u5e94\uff0c\u5e76\u8003\u8651\u4e86\u5730\u5f62\u3001\u5929\u6c14\u548c\u5929\u7ebf\u5931\u914d\u7b49\u56e0\u7d20\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eX\u6ce2\u6bb5\u90ca\u533a\u73af\u5883\u4e2d\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u5230\u5730\u9762\u94fe\u8def\u7684\u9ad8\u5206\u8fa8\u7387\u3001\u57fa\u4e8e\u5c04\u7ebf\u8ffd\u8e2a\u7684\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u76f8\u5e94\u7684\u5206\u6790\u3002"}}
{"id": "2507.15833", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15833", "abs": "https://arxiv.org/abs/2507.15833", "authors": ["Ian Chuang", "Andrew Lee", "Dechen Gao", "Jinyu Zou", "Iman Soltani"], "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers", "comment": "13 pages, 10 figures", "summary": "Human vision is a highly active process driven by gaze, which directs\nattention and fixation to task-relevant regions and dramatically reduces visual\nprocessing. In contrast, robot learning systems typically rely on passive,\nuniform processing of raw camera images. In this work, we explore how\nincorporating human-like active gaze into robotic policies can enhance both\nefficiency and performance. We build on recent advances in foveated image\nprocessing and apply them to an Active Vision robot system that emulates both\nhuman head movement and eye tracking. Extending prior work on the AV-ALOHA\nrobot simulation platform, we introduce a framework for simultaneously\ncollecting eye-tracking data and robot demonstrations from a human operator as\nwell as a simulation benchmark and dataset for training robot policies that\nincorporate human gaze. Given the widespread use of Vision Transformers (ViTs)\nin robot learning, we integrate gaze information into ViTs using a foveated\npatch tokenization scheme inspired by recent work in image segmentation.\nCompared to uniform patch tokenization, this significantly reduces the number\nof tokens-and thus computation-without sacrificing visual fidelity near regions\nof interest. We also explore two approaches to gaze imitation and prediction\nfrom human data. The first is a two-stage model that predicts gaze to guide\nfoveation and action; the second integrates gaze into the action space,\nallowing the policy to jointly predict gaze and actions end-to-end. Our results\nshow that our method for foveated robot vision not only drastically reduces\ncomputational overhead, but also improves performance for high precision tasks\nand robustness to unseen distractors. Together, these findings suggest that\nhuman-inspired visual processing offers a useful inductive bias for robotic\nvision systems. https://ian-chuang.github.io/gaze-av-aloha/", "AI": {"tldr": "Human gaze improves robot vision: Active gaze in robots reduces computation and boosts performance, especially in precise tasks, by using foveated vision inspired by human eyes. The study introduces a new framework and dataset for training these 'gaze-aware' robots.", "motivation": "The motivation is to enhance the efficiency and performance of robot learning systems by incorporating human-like active gaze, contrasting with the current passive, uniform processing of raw camera images.", "method": "The study integrates human-like active gaze into robotic policies using foveated image processing. It builds upon the AV-ALOHA robot simulation platform, introducing a framework for collecting eye-tracking data and robot demonstrations. A novel foveated patch tokenization scheme is proposed for Vision Transformers (ViTs) to reduce computation without sacrificing visual fidelity. Two gaze imitation and prediction approaches are explored: a two-stage model and an end-to-end model that integrates gaze into the action space.", "result": "The foveated robot vision method significantly reduces computational overhead and improves performance for high-precision tasks and robustness to unseen distractors compared to uniform patch tokenization.", "conclusion": "The findings suggest that human-inspired visual processing, specifically active gaze, offers a useful inductive bias for robotic vision systems, leading to reduced computational overhead and improved performance in high-precision tasks and robustness to unseen distractors."}}
{"id": "2507.14743", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14743", "abs": "https://arxiv.org/abs/2507.14743", "authors": ["Joseph Raj Vishal", "Rutuja Patil", "Manas Srinivas Gowda", "Katha Naik", "Yezhou Yang", "Bharatesh Chakravarthi"], "title": "InterAct-Video: Reasoning-Rich Video QA for Urban Traffic", "comment": null, "summary": "Traffic monitoring is crucial for urban mobility, road safety, and\nintelligent transportation systems (ITS). Deep learning has advanced\nvideo-based traffic monitoring through video question answering (VideoQA)\nmodels, enabling structured insight extraction from traffic videos. However,\nexisting VideoQA models struggle with the complexity of real-world traffic\nscenes, where multiple concurrent events unfold across spatiotemporal\ndimensions. To address these challenges, this paper introduces \\textbf{InterAct\nVideoQA}, a curated dataset designed to benchmark and enhance VideoQA models\nfor traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of\nreal-world traffic footage collected from diverse intersections, segmented into\n10-second video clips, with over 25,000 question-answer (QA) pairs covering\nspatiotemporal dynamics, vehicle interactions, incident detection, and other\ncritical traffic attributes. State-of-the-art VideoQA models are evaluated on\nInterAct VideoQA, exposing challenges in reasoning over fine-grained\nspatiotemporal dependencies within complex traffic scenarios. Additionally,\nfine-tuning these models on InterAct VideoQA yields notable performance\nimprovements, demonstrating the necessity of domain-specific datasets for\nVideoQA. InterAct VideoQA is publicly available as a benchmark dataset to\nfacilitate future research in real-world deployable VideoQA models for\nintelligent transportation systems. GitHub Repo:\nhttps://github.com/joe-rabbit/InterAct_VideoQA", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86InterAct VideoQA\u6570\u636e\u96c6\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u89c6\u9891\u95ee\u7b54\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4ea4\u901a\u573a\u666f\u65f6\u7684\u4e0d\u8db3\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4e3a\u672a\u6765\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u89c6\u9891\u95ee\u7b54\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u9891\u95ee\u7b54\u6a21\u578b\u5728\u5904\u7406\u771f\u5b9e\u4ea4\u901a\u573a\u666f\u7684\u590d\u6742\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u4e9b\u573a\u666f\u901a\u5e38\u6d89\u53ca\u8de8\u8d8a\u65f6\u7a7a\u7684\u591a\u4e2a\u5e76\u53d1\u4e8b\u4ef6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u5e76\u63a8\u52a8\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u89c6\u9891\u95ee\u7b54\u7814\u7a76\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51faInterAct VideoQA\u6570\u636e\u96c6\uff0c\u5305\u542b8\u5c0f\u65f6\u771f\u5b9e\u4ea4\u901a\u89c6\u9891\uff0c\u5206\u5272\u621010\u79d2\u7247\u6bb5\uff0c\u5e76\u63d0\u4f9b\u8d85\u8fc725,000\u4e2a\u95ee\u7b54\u5bf9\uff0c\u6db5\u76d6\u65f6\u7a7a\u52a8\u6001\u3001\u8f66\u8f86\u4ea4\u4e92\u3001\u4e8b\u4ef6\u68c0\u6d4b\u7b49\u4ea4\u901a\u5c5e\u6027\u3002\u8bc4\u4f30\u5e76\u5fae\u8c03\u4e86\u73b0\u6709\u7684\u89c6\u9891\u95ee\u7b54\u6a21\u578b\u3002", "result": "\u5728InterAct VideoQA\u6570\u636e\u96c6\u4e0a\uff0c\u73b0\u6709\u7684\u89c6\u9891\u95ee\u7b54\u6a21\u578b\u5728\u63a8\u7406\u7ec6\u7c92\u5ea6\u7684\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002\u7136\u800c\uff0c\u901a\u8fc7\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u6027\u80fd\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86InterAct VideoQA\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u89c6\u9891\u95ee\u7b54\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u8868\u660e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7684\u4ea4\u901a\u573a\u666f\u65f6\u5b58\u5728\u6311\u6218\uff0c\u4f46\u901a\u8fc7\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u5bf9\u4e8e\u89c6\u9891\u95ee\u7b54\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.15509", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15509", "abs": "https://arxiv.org/abs/2507.15509", "authors": ["Lei Chen", "Xuanle Zhao", "Zhixiong Zeng", "Jing Huang", "Yufeng Zhong", "Lin Ma"], "title": "Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner", "comment": "technical report", "summary": "Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based\non reinforcement learning fine-tuning has received widespread attention from\nthe community. Previous R1-Style methods mainly focus on mathematical reasoning\nand code intelligence. It is of great research significance to verify their\nadvantages on more general multimodal data. Chart is an important multimodal\ndata type with rich information, which brings important research challenges in\ncomplex reasoning. In this work, we introduce Chart-R1, a chart-domain\nvision-language model with reinforcement learning fine-tuning to enable complex\nchart reasoning. To support Chart-R1, we first propose a novel programmatic\ndata synthesis technology to generate high-quality step-by-step chart reasoning\ndata covering single- and multi-subcharts, which makes up for the lack of\nreasoning data in the chart domain. Then we develop a two-stage training\nstrategy: Chart-COT with step-by-step chain-of-thought supervision, and\nChart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims\nto decompose complex chart reasoning tasks into fine-grained, understandable\nsubtasks through step-by-step supervision, which lays a good foundation for\nimproving the reasoning level of reinforcement learning. Chart-RFT utilize the\ntypical group relative policy optimization strategy, in which a relatively soft\nreward is adopted for numerical response to emphasize the numerical sensitivity\nin the chart domain. We conduct extensive experiments on open-source benchmarks\nand self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental\nresults show that Chart-R1 has significant advantages compared to chart-domain\nmethods, even comparable to open/closed source large-scale models (\\emph{e.g.,\nGPT-4o, Claude-3.5}).", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faChart-R1\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684\u56fe\u8868\u9886\u57df\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u590d\u6742\u7684\u56fe\u8868\u63a8\u7406\u3002\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u5408\u6210\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08Chart-COT\u548cChart-RFT\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u56fe\u8868\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53ef\u4e0e\u9876\u5c16\u5927\u578b\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002", "motivation": "\u9a8c\u8bc1R1-Style\u65b9\u6cd5\uff08\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff09\u5728\u66f4\u901a\u7528\u7684\u591a\u6a21\u6001\u6570\u636e\uff08\u7279\u522b\u662f\u56fe\u8868\u6570\u636e\uff09\u4e0a\u7684\u4f18\u52bf\uff0c\u4ee5\u5b9e\u73b0\u590d\u6742\u7684\u56fe\u8868\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a0b\u5e8f\u5316\u6570\u636e\u5408\u6210\u6280\u672f\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u3001\u9010\u6b65\u7684\u56fe\u8868\u63a8\u7406\u6570\u636e\uff08\u5305\u62ec\u5355\u5b50\u56fe\u548c\u591a\u5b50\u56fe\uff09\uff0c\u4ee5\u5f25\u8865\u56fe\u8868\u9886\u57df\u63a8\u7406\u6570\u636e\u7684\u4e0d\u8db3\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1aChart-COT\uff08\u4f7f\u7528\u9010\u6b65\u7684\u94fe\u5f0f\u601d\u8003\u76d1\u7763\uff09\u548cChart-RFT\uff08\u4f7f\u7528\u6570\u503c\u654f\u611f\u7684\u5f3a\u5316\u5fae\u8c03\uff09\u3002Chart-COT\u65e8\u5728\u901a\u8fc7\u9010\u6b65\u76d1\u7763\u5c06\u590d\u6742\u7684\u56fe\u8868\u63a8\u7406\u4efb\u52a1\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u3001\u53ef\u7406\u89e3\u7684\u5b50\u4efb\u52a1\uff1bChart-RFT\u5229\u7528\u5178\u578b\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7b56\u7565\uff0c\u91c7\u7528\u76f8\u5bf9\u8f83\u8f6f\u7684\u5956\u52b1\u6765\u5f3a\u8c03\u56fe\u8868\u9886\u57df\u7684\u6570\u503c\u654f\u611f\u6027\u3002", "result": "\u5728\u5f00\u6e90\u57fa\u51c6\u548c\u81ea\u5efa\u7684ChartRQA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eChart-R1\u76f8\u6bd4\u4e8e\u56fe\u8868\u9886\u57df\u7684\u5176\u4ed6\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5e76\u4e14\u4e0eGPT-4o\u3001Claude-3.5\u7b49\u5927\u578b\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "Chart-R1\u5728\u56fe\u8868\u9886\u57df\u7684\u590d\u6742\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u6027\u80fd\u53ef\u4e0eGPT-4o\u3001Claude-3.5\u7b49\u5927\u578b\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2507.14706", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14706", "abs": "https://arxiv.org/abs/2507.14706", "authors": ["Claudio Giusti", "Luca Guarnera", "Mirko Casu", "Sebastiano Battiato"], "title": "Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling", "comment": "23 pages, 14 figures", "summary": "Detecting fraudulent credit card transactions remains a significant\nchallenge, due to the extreme class imbalance in real-world data and the often\nsubtle patterns that separate fraud from legitimate activity. Existing research\ncommonly attempts to address this by generating synthetic samples for the\nminority class using approaches such as GANs, VAEs, or hybrid generative\nmodels. However, these techniques, particularly when applied only to\nminority-class data, tend to result in overconfident classifiers and poor\nlatent cluster separation, ultimately limiting real-world detection\nperformance. In this study, we propose the Causal Prototype Attention\nClassifier (CPAC), an interpretable architecture that promotes class-aware\nclustering and improved latent space structure through prototype-based\nattention mechanisms and we will couple it with the encoder in a VAE-GAN\nallowing it to offer a better cluster separation moving beyond post-hoc sample\naugmentation. We compared CPAC-augmented models to traditional oversamplers,\nsuch as SMOTE, as well as to state-of-the-art generative models, both with and\nwithout CPAC-based latent classifiers. Our results show that classifier-guided\nlatent shaping with CPAC delivers superior performance, achieving an F1-score\nof 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster\nseparation. Further ablation studies and visualizations provide deeper insight\ninto the benefits and limitations of classifier-driven representation learning\nfor fraud detection. The codebase for this work will be available at final\nsubmission.", "AI": {"tldr": "CPAC \u662f\u4e00\u79cd\u521b\u65b0\u7684\u4fe1\u7528\u5361\u6b3a\u8bc8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u548c\u805a\u7c7b\u5206\u79bb\u6765\u514b\u670d\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u4e2d\u6781\u7aef\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u4ee5\u53ca\u6b3a\u8bc8\u4e0e\u5408\u6cd5\u4ea4\u6613\u4e4b\u95f4\u7ec6\u5fae\u7684\u6a21\u5f0f\u5dee\u5f02\uff0c\u7ed9\u68c0\u6d4b\u5e26\u6765\u4e86\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u5982\u751f\u6210\u6a21\u578b\uff0c\u5e38\u5e38\u5bfc\u81f4\u5206\u7c7b\u5668\u8fc7\u4e8e\u81ea\u4fe1\u548c\u6f5c\u5728\u805a\u7c7b\u5206\u79bb\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a CPAC\uff08\u56e0\u679c\u539f\u578b\u6ce8\u610f\u529b\u5206\u7c7b\u5668\uff09\u7684\u53ef\u89e3\u91ca\u67b6\u6784\uff0c\u5229\u7528\u57fa\u4e8e\u539f\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u805a\u7c7b\u548c\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u4e0e VAE-GAN \u4e2d\u7684\u7f16\u7801\u5668\u76f8\u7ed3\u5408\uff0c\u4ee5\u6539\u5584\u4fe1\u7528\u5361\u6b3a\u8bc8\u68c0\u6d4b\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u8fc7\u91c7\u6837\u65b9\u6cd5\uff08\u5982 SMOTE\uff09\u548c\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u76f8\u6bd4\uff0cCPAC \u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0cF1 \u5206\u6570\u8fbe\u5230\u4e86 93.14%\uff0c\u53ec\u56de\u7387\u8fbe\u5230\u4e86 90.18%\uff0c\u5e76\u6539\u5584\u4e86\u6f5c\u5728\u805a\u7c7b\u5206\u79bb\u3002", "conclusion": "CPAC \u662f\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u539f\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u4fc3\u8fdb\u7c7b\u522b\u611f\u77e5\u805a\u7c7b\u548c\u6539\u8fdb\u7684\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u4e0e VAE-GAN \u4e2d\u7684\u7f16\u7801\u5668\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u63d0\u4f9b\u66f4\u597d\u7684\u805a\u7c7b\u5206\u79bb\uff0c\u8d85\u8d8a\u4e86\u4e8b\u540e\u6837\u672c\u589e\u5f3a\u3002"}}
{"id": "2507.15432", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2507.15432", "abs": "https://arxiv.org/abs/2507.15432", "authors": ["Guruprasad Kadam"], "title": "State-Dependent Quantum Copying and the limits of the No-Cloning Theorem", "comment": "7 pages, comments are welcome", "summary": "In this work, we examine the physical process of stimulated emission as a\nmodel for state-dependent quantum copying. We explore how a quantum state, for\ninstance, a photon polarization, can be cloned through light-matter\ninteractions when the ancillary system, such as an excited atom, effectively\nencodes prior information about the quantum state. This process, while\nresembling quantum cloning, adheres to the no-cloning theorem due to its\nstate-dependent and non-universal nature. We clarify the distinction between\nuniversal cloning and conditional copying, and demonstrate that stimulated\nemission offers a concrete physical realization of state-dependent quantum\ncopying.", "AI": {"tldr": "Quantum states can be copied conditionally using stimulated emission, a process that respects the no-cloning theorem.", "motivation": "To model state-dependent quantum copying using the physical process of stimulated emission and clarify the distinction between universal cloning and conditional copying.", "method": "Examining the physical process of stimulated emission as a model for state-dependent quantum copying, exploring how quantum states like photon polarization can be cloned through light-matter interactions.", "result": "Demonstrated that stimulated emission can achieve state-dependent quantum copying, where an ancillary system (e.g., an excited atom) encodes prior information about the quantum state, a process that resembles quantum cloning but obeys the no-cloning theorem.", "conclusion": "Stimulated emission provides a concrete physical realization of state-dependent quantum copying, adhering to the no-cloning theorem due to its state-dependent and non-universal nature."}}
{"id": "2507.15024", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15024", "abs": "https://arxiv.org/abs/2507.15024", "authors": ["Qiaoyu Tang", "Hao Xiang", "Le Yu", "Bowen Yu", "Hongyu Lin", "Yaojie Lu", "Xianpei Han", "Le Sun", "Junyang Lin"], "title": "RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback", "comment": null, "summary": "With the rapid advancement of Large Language Models (LLMs), developing\neffective critic modules for precise guidance has become crucial yet\nchallenging. In this paper, we initially demonstrate that supervised\nfine-tuning for building critic modules (which is widely adopted in current\nsolutions) fails to genuinely enhance models' critique abilities, producing\nsuperficial critiques with insufficient reflections and verifications. To\nunlock the unprecedented critique capabilities, we propose RefCritic, a\nlong-chain-of-thought critic module based on reinforcement learning with dual\nrule-based rewards: (1) instance-level correctness of solution judgments and\n(2) refinement accuracies of the policy model based on critiques, aiming to\ngenerate high-quality evaluations with actionable feedback that effectively\nguides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and\nDeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement\nsettings, RefCritic demonstrates consistent advantages across all benchmarks,\ne.g., 6.8\\% and 7.2\\% gains on AIME25 for the respective base models. Notably,\nunder majority voting, policy models filtered by RefCritic show superior\nscaling with increased voting numbers. Moreover, despite training on\nsolution-level supervision, RefCritic outperforms step-level supervised\napproaches on ProcessBench, a benchmark to identify erroneous steps in\nmathematical reasoning.", "AI": {"tldr": "RefCritic \u662f\u4e00\u79cd\u65b0\u9896\u7684\u957f\u94fe\u5f0f\u601d\u7ef4\u6279\u8bc4\u6a21\u5757\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u53cc\u91cd\u5956\u52b1\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6279\u8bc4\u80fd\u529b\u548c\u6307\u5bfc\u6548\u679c\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\uff0c\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5f00\u53d1\u7528\u4e8e\u7cbe\u786e\u6307\u5bfc\u7684\u6709\u6548\u6279\u8bc4\u6a21\u5757\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u672a\u80fd\u771f\u6b63\u63d0\u5347\u6a21\u578b\u7684\u6279\u8bc4\u80fd\u529b\uff0c\u4ea7\u751f\u7684\u6279\u8bc4\u6d41\u4e8e\u8868\u9762\uff0c\u7f3a\u4e4f\u5145\u5206\u7684\u601d\u8003\u548c\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u548c\u53cc\u91cd\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\uff08\u5b9e\u4f8b\u7ea7\u89e3\u51b3\u65b9\u6848\u5224\u65ad\u7684\u6b63\u786e\u6027\uff1b\u57fa\u4e8e\u6279\u8bc4\u7684\u7b56\u7565\u6a21\u578b\u6539\u8fdb\u51c6\u786e\u6027\uff09\u7684\u201c\u957f\u94fe\u5f0f\u601d\u7ef4\u201d\u6279\u8bc4\u6a21\u5757RefCritic\uff0c\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u64cd\u4f5c\u7684\u8bc4\u4f30\u3002", "result": "RefCritic \u5728 Qwen2.5-14B-Instruct \u548c DeepSeek-R1-Distill-Qwen-14B \u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5728\u6279\u8bc4\u548c\u6539\u8fdb\u8bbe\u7f6e\u4e0a\u5c55\u73b0\u51fa\u4e00\u81f4\u7684\u4f18\u52bf\uff0c\u5728AIME25\u4e0a\u5206\u522b\u63d0\u9ad8\u4e866.8%\u548c7.2%\u3002\u4f7f\u7528 RefCritic \u8fc7\u6ee4\u7684\u7b56\u7565\u6a21\u578b\u5728\u591a\u6570\u6295\u7968\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6269\u5c55\u6027\u3002\u5728ProcessBench\u6d4b\u8bd5\u4e2d\uff0cRefCritic \u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u6b65\u9aa4\u7684\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "RefCritic \u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u5f53\u524d\u5e7f\u6cdb\u91c7\u7528\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u6279\u8bc4\u548c\u6539\u8fdb\u8bbe\u7f6e\u4e0a\u59cb\u7ec8\u5177\u6709\u4f18\u52bf\uff0c\u4f8b\u5982\u5728AIME25\u4e0a\u4e3a\u76f8\u5e94\u7684\u57fa\u7ebf\u6a21\u578b\u5206\u522b\u63d0\u9ad8\u4e866.8%\u548c7.2%\u3002\u6b64\u5916\uff0cRefCritic \u8bad\u7ec3\u4e8e\u89e3\u9898\u7ea7\u522b\u7684\u76d1\u7763\uff0c\u4f46\u5728\u8bc6\u522b\u6570\u5b66\u63a8\u7406\u9519\u8bef\u6b65\u9aa4\u7684\u57fa\u51c6\u6d4b\u8bd5ProcessBench\u4e0a\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u89e3\u9898\u6b65\u9aa4\u7ea7\u522b\u7684\u76d1\u7763\u65b9\u6cd5\u3002"}}
{"id": "2507.14804", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14804", "abs": "https://arxiv.org/abs/2507.14804", "authors": ["Jingjing Zhao", "Qian Xu", "Kaiquan Cai", "Yanbo Zhu", "Xidong Mu", "Yuanwei Liu"], "title": "Movable-Element STARS-Aided Secure Communications", "comment": null, "summary": "A novel movable-element (ME) enabled simultaneously transmitting and\nreflecting surface (ME-STARS)-aided secure communication system is\ninvestigated. Against the full-space eavesdropping, MEs are deployed at the\nSTARS for enhancing the physical layer security by exploiting higher spatial\ndegrees of freedom. Specifically, a sum secrecy rate maximization problem is\nformulated, which jointly optimizes the passive beamforming and the MEs\npositions at the ME-STARS, as well as the active beamforming at the base\nstation. To solve the resultant non-convex optimization problem involving\nhighly-coupled variables, an alternating optimization-based iterative algorithm\nis developed, decomposing the original problem into three subproblems. In\nparticular, for the MEs position optimization subproblem, a gradient ascent\nalgorithm is employed to iteratively refine the MEs' locations within the\nconfined region. Moreover, the the active and passive beamforming subproblems\nare solved by employing successive convex approximation. Numerical results\nunveil that: 1) ME-STARS significantly improves the secrecy performance\ncompared to the conventional STARS with fixed-position elements; and 2) The\nsecrecy rate achieved by the ME-STARS gets saturated within limited movable\nregion size.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14784", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14784", "abs": "https://arxiv.org/abs/2507.14784", "authors": ["Xinxin Dong", "Baoyun Peng", "Haokai Ma", "Yufei Wang", "Zixuan Dong", "Fei Hu", "Xiaodong Wang"], "title": "LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering", "comment": null, "summary": "Video Question Answering (VideoQA) requires identifying sparse critical\nmoments in long videos and reasoning about their causal relationships to answer\nsemantically complex questions. While recent advances in multimodal learning\nhave improved alignment and fusion, current approaches remain limited by two\nprevalent but fundamentally flawed strategies: (1) task-agnostic sampling\nindiscriminately processes all frames, overwhelming key events with irrelevant\ncontent; and (2) heuristic retrieval captures superficial patterns but misses\ncausal-temporal structures needed for complex reasoning. To address these\nchallenges, we introduce LeAdQA, an innovative approach that bridges these gaps\nthrough synergizing causal-aware query refinement with fine-grained visual\ngrounding. Our method first leverages LLMs to reformulate question-option\npairs, resolving causal ambiguities and sharpening temporal focus. These\nrefined queries subsequently direct a temporal grounding model to precisely\nretrieve the most salient segments, complemented by an adaptive fusion\nmechanism dynamically integrating the evidence to maximize relevance. The\nintegrated visual-textual cues are then processed by an MLLM to generate\naccurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and\nNExT-GQA demonstrate that our method's precise visual grounding substantially\nenhances the understanding of video-question relationships, achieving\nstate-of-the-art (SOTA) performance on complex reasoning tasks while\nmaintaining computational efficiency.", "AI": {"tldr": "LeAdQA \u901a\u8fc7\u5229\u7528 LLM \u7ec6\u5316\u89c6\u9891\u95ee\u7b54\u4e2d\u7684\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u7cbe\u786e\u7684\u89c6\u89c9\u57fa\u7840\u6765\u8bc6\u522b\u5173\u952e\u65f6\u523b\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u56de\u7b54\u590d\u6742\u95ee\u9898\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u89c6\u9891\u95ee\u7b54\u65b9\u6cd5\u5728\u5904\u7406\u957f\u89c6\u9891\u4e2d\u7684\u7a00\u758f\u5173\u952e\u65f6\u523b\u548c\u63a8\u7406\u5176\u56e0\u679c\u5173\u7cfb\u4ee5\u56de\u7b54\u590d\u6742\u95ee\u9898\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53d7\u9650\u4e8e\uff081\uff09\u4efb\u52a1\u65e0\u5173\u7684\u91c7\u6837\uff08\u5904\u7406\u6240\u6709\u5e27\uff0c\u7528\u65e0\u5173\u5185\u5bb9\u538b\u5012\u5173\u952e\u4e8b\u4ef6\uff09\u548c\uff082\uff09\u542f\u53d1\u5f0f\u68c0\u7d22\uff08\u6355\u83b7\u8868\u9762\u6a21\u5f0f\u4f46\u5ffd\u7565\u56e0\u679c\u65f6\u95f4\u7ed3\u6784\uff09\u3002", "method": "LeAdQA \u65b9\u6cd5\u9996\u5148\u5229\u7528 LLM \u6539\u9769\u95ee\u9898-\u9009\u9879\u5bf9\uff0c\u89e3\u51b3\u56e0\u679c\u6a21\u7cca\u6027\u5e76\u805a\u7126\u65f6\u95f4\u3002\u7136\u540e\uff0c\u8fd9\u4e9b\u6539\u8fdb\u7684\u67e5\u8be2\u6307\u5bfc\u65f6\u95f4\u57fa\u7840\u6a21\u578b\u7cbe\u786e\u68c0\u7d22\u6700\u663e\u8457\u7684\u7247\u6bb5\uff0c\u5e76\u8f85\u4ee5\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\u4ee5\u6700\u5927\u5316\u76f8\u5173\u6027\u3002\u6700\u540e\uff0c\u901a\u8fc7 MLLM \u5904\u7406\u96c6\u6210\u7684\u89c6\u89c9-\u6587\u672c\u7ebf\u7d22\u6765\u751f\u6210\u51c6\u786e\u7684\u3001\u4e0e\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7b54\u6848\u3002", "result": "\u5728 NExT-QA\u3001IntentQA \u548c NExT-GQA \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLeAdQA \u7684\u7cbe\u786e\u89c6\u89c9\u57fa\u7840\u663e\u8457\u589e\u5f3a\u4e86\u89c6\u9891-\u95ee\u9898\u5173\u7cfb\u7684\u7406\u89e3\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86 SOTA \u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "LeAdQA \u901a\u8fc7\u56e0\u679c\u611f\u77e5\u67e5\u8be2\u7ec6\u5316\u548c\u7ec6\u7c92\u5ea6\u89c6\u89c9\u57fa\u7840\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u89c6\u9891\u95ee\u7b54\u7684\u6700\u65b0\uff08SOTA\uff09\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.14715", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14715", "abs": "https://arxiv.org/abs/2507.14715", "authors": ["Rachid Karami", "Rajeev Patwari", "Hyoukjun Kwon", "Ashish Sirasao"], "title": "Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems", "comment": null, "summary": "The integration of generative AI models, particularly large language models\n(LLMs), into real-time multi-model AI applications such as video conferencing\nand gaming is giving rise to a new class of workloads: real-time generative AI\n(RTGen). These workloads combine the compute intensity and dynamic execution\npatterns of generative models with the stringent latency and concurrency\nconstraints of real-time inference. To meet the diverse demands of RTGen\nworkloads, modern edge platforms increasingly adopt heterogeneous\nsystem-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite\nthe potential of heterogeneous SoC, the scheduling space complexity and\nperformance implications of RTGen workloads on such platforms remain\nunderexplored. In this work, we perform a comprehensive characterization of\nRTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct\nrealistic multi-model scenarios inspired by industry use cases and profile\nmodel performance across all available backends. Using this data, we evaluate\nfive scheduling policies and their impact on both real-time metrics (e.g.,\ndeadline violation rate) and LLM performance (e.g., time-to-first-token and\ntokens-per-second). Our results show that scheduling decisions significantly\naffect workload performance (e.g., leading to a 41.7% difference in deadline\nviolation rates on average), and highlight the need for scheduling strategies\nthat are aware of workload dynamics and hardware heterogeneity. Our findings\nunderscore the importance of workload-aware, dynamic heterogeneous scheduling\nin enabling high-performance, on-device RTGen applications.", "AI": {"tldr": "RTGen \u5de5\u4f5c\u8d1f\u8f7d\u5728\u5f02\u6784 SoC \u4e0a\u9700\u8981\u667a\u80fd\u8c03\u5ea6\uff0c\u4ee5\u4f18\u5316\u6027\u80fd\u548c\u6ee1\u8db3\u5b9e\u65f6\u6027\u8981\u6c42\u3002", "motivation": "\u5b9e\u65f6\u751f\u6210\u5f0f AI (RTGen) \u5de5\u4f5c\u8d1f\u8f7d\u7ed3\u5408\u4e86\u751f\u6210\u6a21\u578b\u7684\u8ba1\u7b97\u5bc6\u96c6\u5ea6\u548c\u5b9e\u65f6\u63a8\u7406\u7684\u4e25\u683c\u5ef6\u8fdf\u548c\u5e76\u53d1\u7ea6\u675f\uff0c\u800c\u73b0\u4ee3\u8fb9\u7f18\u5e73\u53f0\u4e0a\u7684\u5f02\u6784 SoC \u67b6\u6784\u5728\u8c03\u5ea6\u590d\u6742\u6027\u548c\u6027\u80fd\u65b9\u9762\u4ecd\u6709\u5f85\u63a2\u7d22\u3002", "method": "\u5bf9 AMD \u9510\u9f99 AI \u5f02\u6784 SoC \u4e0a\u7684 RTGen \u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7279\u6027\u5206\u6790\uff0c\u5305\u62ec\u6784\u5efa\u73b0\u5b9e\u573a\u666f\u3001\u8de8\u540e\u7aef\u6027\u80fd\u5206\u6790\u3001\u8bc4\u4f30\u4e94\u79cd\u8c03\u5ea6\u7b56\u7565\u53ca\u5176\u5bf9\u5b9e\u65f6\u6307\u6807\u548c LLM \u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u8c03\u5ea6\u51b3\u7b56\u663e\u8457\u5f71\u54cd\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\uff0c\u5e73\u5747\u5bfc\u81f4 41.7% \u7684\u622a\u6b62\u65e5\u671f\u8fdd\u89c4\u7387\u5dee\u5f02\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u611f\u77e5\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u548c\u786c\u4ef6\u5f02\u6784\u6027\u7684\u8c03\u5ea6\u7b56\u7565\u3002", "conclusion": "\u5728 AMD \u9510\u9f99 AI \u7b49\u5f02\u6784 SoC \u4e0a\uff0c\u9700\u8981\u6709\u611f\u77e5\u5de5\u4f5c\u8d1f\u8f7d\u548c\u786c\u4ef6\u5f02\u6784\u6027\u7684\u52a8\u6001\u8c03\u5ea6\u7b56\u7565\uff0c\u4ee5\u652f\u6301\u9ad8\u6027\u80fd\u7684\u8bbe\u5907\u7aef RTGen \u5e94\u7528\u3002"}}
{"id": "2507.15446", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15446", "abs": "https://arxiv.org/abs/2507.15446", "authors": ["I. S. Sushchev", "K. E. Bugai", "S. N. Molotkov", "D. S. Bulavkin", "A. S. Sidelnikova", "D. M. Melkonian", "V. M. Vakhrusheva", "R. Yu. Lokhmatov", "D. A. Dvoretskiy"], "title": "Realistic vulnerabilities of decoy-state quantum key distribution", "comment": null, "summary": "We analyze realistic vulnerabilities of decoy-state quantum key distribution\n(QKD) arising from the combination of laser damage attack (LDA) and unambiguous\nstate discrimination (USD). While decoy-state QKD is designed to protect\nagainst photon-number-splitting and beam-splitting attacks by accurately\nestimating the single-photon fraction, it relies on stable attenuation to\nprepare pulses with fixed mean-photon numbers. An eavesdropper (Eve) can\nexploit LDA to irreversibly alter the optical components on Alice's side,\neffectively increasing the mean-photon numbers beyond the decoy-state security\nregime. We show that once the alteration exceeds a critical threshold - on the\norder of 10--20 dB - Eve can implement an efficient USD-based intercept-resend\nstrategy using current off-the-shelf technology, thus obtaining the entire\nsecret key. Numerical simulations confirm that for sufficiently elevated\nmean-photon numbers, Eve's conclusive measurement outcomes skew the decoy-state\nstatistics, yet remain undetected by standard security checks. We further\ndemonstrate how a modified USD setup employing an additional beam splitter can\nreduce the required threshold, facilitating Eve's attack. Our findings\nemphasize the need for robust safeguards against high-power laser damage in QKD\nsystems, including careful hardware selection, rigorous testing under\nhigh-power illumination, and real-time monitoring to ensure the integrity of\nthe decoy-state protocol.", "AI": {"tldr": "\u8bf1\u9a97\u6001QKD\u6613\u53d7\u6fc0\u5149\u635f\u4f24\u548c\u660e\u786e\u72b6\u6001\u9274\u522b\u7ec4\u5408\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bc6\u94a5\u6cc4\u9732\u3002", "motivation": "\u65e8\u5728\u63ed\u793a\u8bf1\u9a97\u6001\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u9762\u4e34\u7684\uff0c\u7531\u6fc0\u5149\u635f\u4f24\u653b\u51fb\uff08LDA\uff09\u548c\u660e\u786e\u72b6\u6001\u9274\u522b\uff08USD\uff09\u5171\u540c\u5f15\u53d1\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5f53\u653b\u51fb\u8d85\u51fa\u4e86\u534f\u8bae\u8bbe\u8ba1\u7684\u5b89\u5168\u8303\u7574\u65f6\u3002", "method": "\u5206\u6790\u4e86\u6fc0\u5149\u635f\u4f24\u653b\u51fb\uff08LDA\uff09\u548c\u660e\u786e\u72b6\u6001\u9274\u522b\uff08USD\uff09\u7ec4\u5408\u653b\u51fb\u5bf9\u8bf1\u9a97\u6001\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7684\u5b9e\u9645\u6f0f\u6d1e\u3002\u901a\u8fc7\u6570\u503c\u6a21\u62df\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u5f53\u5e73\u5747\u5149\u5b50\u6570\u8d85\u8fc7\u7279\u5b9a\u9608\u503c\u65f6\uff0c\u5373\u4f7f\u5728\u6807\u51c6\u5b89\u5168\u68c0\u67e5\u4e0b\uff0c\u7a83\u542c\u8005\uff08Eve\uff09\u4e5f\u80fd\u901a\u8fc7\u57fa\u4e8eUSD\u7684\u62e6\u622a\u91cd\u53d1\u7b56\u7565\u7a83\u53d6\u5168\u90e8\u5bc6\u94a5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u4fee\u6539USD\u8bbe\u7f6e\u53ef\u4ee5\u964d\u4f4e\u653b\u51fb\u6240\u9700\u7684\u9608\u503c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u5e73\u5747\u5149\u5b50\u6570\u8d85\u8fc7\u7279\u5b9a\u9608\u503c\uff08\u7ea610-20 dB\uff09\u65f6\uff0c\u7a83\u542c\u8005\uff08Eve\uff09\u53ef\u4ee5\u5229\u7528\u6fc0\u5149\u635f\u4f24\u653b\u51fb\uff08LDA\uff09\u548c\u660e\u786e\u72b6\u6001\u9274\u522b\uff08USD\uff09\u5b9e\u65bd\u6709\u6548\u7684\u62e6\u622a\u91cd\u53d1\u7b56\u7565\uff0c\u4ece\u800c\u83b7\u53d6\u5168\u90e8\u5bc6\u94a5\uff0c\u5e76\u4e14\u4e0d\u4f1a\u88ab\u6807\u51c6\u5b89\u5168\u68c0\u67e5\u53d1\u73b0\u3002\u4fee\u6539\u540e\u7684USD\u8bbe\u7f6e\u53ef\u4ee5\u964d\u4f4e\u6240\u9700\u7684\u653b\u51fb\u9608\u503c\u3002", "conclusion": "\u73b0\u6709\u8bf1\u9a97\u6001\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u534f\u8bae\u6613\u53d7\u6fc0\u5149\u635f\u4f24\u653b\u51fb\uff08LDA\uff09\u548c\u660e\u786e\u72b6\u6001\u9274\u522b\uff08USD\uff09\u7ec4\u5408\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u8fd9\u4f1a\u5f71\u54cd\u5176\u5b89\u5168\u6027\u3002\u9700\u8981\u5f00\u53d1\u7a33\u5065\u7684\u5bf9\u7b56\u6765\u62b5\u5fa1\u9ad8\u529f\u7387\u6fc0\u5149\u635f\u4f24\u3002"}}
{"id": "2507.15061", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15061", "abs": "https://arxiv.org/abs/2507.15061", "authors": ["Zhengwei Tao", "Jialong Wu", "Wenbiao Yin", "Junkai Zhang", "Baixuan Li", "Haiyang Shen", "Kuan Li", "Liwen Zhang", "Xinyu Wang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization", "comment": null, "summary": "The advent of Large Language Model (LLM)-powered agents has revolutionized\nartificial intelligence by enabling solutions to complex, open-ended tasks\nthrough web-based information-seeking (IS) capabilities. The scarcity of\nhigh-quality training data has limited the development of IS agents. Existing\napproaches typically adopt an information-driven paradigm that first collects\nweb data and then generates questions based on the retrieval. However, this may\nlead to inconsistency between information structure and reasoning structure,\nquestion and answer. To mitigate, we propose a formalization-driven IS data\nsynthesis framework WebShaper to construct a dataset. WebShaper systematically\nformalizes IS tasks through set theory. Central to the formalization is the\nconcept of Knowledge Projections (KP), which enables precise control over\nreasoning structure by KP operation compositions. During synthesis, we begin by\ncreating seed tasks, then use a multi-step expansion process. At each step, an\nagentic Expander expands the current formal question more complex with\nretrieval and validation tools based on our formalization. We train our model\non the synthesized dataset. Experiment results demonstrate that WebShaper\nachieves state-of-the-art performance among open-sourced IS agents on GAIA and\nWebWalkerQA benchmarks.", "AI": {"tldr": "WebShaper \u901a\u8fc7\u5f62\u5f0f\u5316 IS \u4efb\u52a1\u548c\u4f7f\u7528\u4ee3\u7406 Expander \u8fdb\u884c\u591a\u6b65\u6269\u5c55\u6765\u5408\u6210\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709 IS \u4ee3\u7406\u6570\u636e\u7a00\u758f\u548c\u7ed3\u6784\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4fe1\u606f\u68c0\u7d22\uff08IS\uff09\u4ee3\u7406\u5728\u8bad\u7ec3\u6570\u636e\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u4e14\u4fe1\u606f\u9a71\u52a8\u8303\u5f0f\u53ef\u80fd\u5bfc\u81f4\u4fe1\u606f\u7ed3\u6784\u3001\u63a8\u7406\u7ed3\u6784\u3001\u95ee\u9898\u548c\u7b54\u6848\u4e4b\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a WebShaper \u7684\u5f62\u5f0f\u5316\u9a71\u52a8\u7684\u4fe1\u606f\u68c0\u7d22\uff08IS\uff09\u6570\u636e\u7efc\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u96c6\u5408\u8bba\u5bf9 IS \u4efb\u52a1\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u5e76\u901a\u8fc7\u77e5\u8bc6\u6295\u5f71\uff08KP\uff09\u64cd\u4f5c\u7ec4\u5408\u6765\u7cbe\u786e\u63a7\u5236\u63a8\u7406\u7ed3\u6784\u3002\u5728\u7efc\u5408\u8fc7\u7a0b\u4e2d\uff0c\u9996\u5148\u521b\u5efa\u79cd\u5b50\u4efb\u52a1\uff0c\u7136\u540e\u4f7f\u7528\u591a\u6b65\u6269\u5c55\u8fc7\u7a0b\uff0c\u5176\u4e2d\u4ee3\u7406 Expander \u501f\u52a9\u68c0\u7d22\u548c\u9a8c\u8bc1\u5de5\u5177\u6839\u636e\u5f62\u5f0f\u5316\u8fdb\u884c\u6269\u5c55\uff0c\u4ee5\u751f\u6210\u66f4\u590d\u6742\u7684\u95ee\u9898\u3002", "result": "WebShaper \u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u5730\u5f62\u5f0f\u5316 IS \u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u591a\u6b65\u6269\u5c55\u8fc7\u7a0b\u5408\u6210\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86 IS \u4ee3\u7406\u7684\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cWebShaper \u5728 GAIA \u548c WebWalkerQA \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u5f00\u6e90\u4fe1\u606f\u68c0\u7d22\uff08IS\uff09\u4ee3\u7406\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14831", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.14831", "abs": "https://arxiv.org/abs/2507.14831", "authors": ["Mengyu Qian", "Xidong Mu", "Li You", "Michail Matthaiou"], "title": "Pinching-Antenna-based Communications: Spectral Efficiency Analysis and Deployment Strategies", "comment": "13 pages, 8 figures", "summary": "A multiple-waveguide pinching-antenna (PA)-based multi-user communication\nsystem is investigated. With a given number of PAs, two deployment strategies\nare considered, namely the centralized PA deployment, where all PAs are\nswitched between waveguides to serve users in a time-division manner to avail\nof beamforming gain, and the distributed PA deployment, where a single PA is\ndeployed on each waveguide to simultaneously serve multiple users by leveraging\nthe multiplexing gain. The spectral efficiency (SE) achieved by each deployment\nstrategy is analyzed: i) For the centralized deployment, the positioning\nstrategy of PAs on each waveguide is determined first with the aim of\nmaximizing the channel gain of the corresponding nearest served user. Based on\nthis, the corresponding system SE is derived. ii) For the distributed\ndeployment, the system SE under the maximum ratio transmission (MRT) is first\nobtained. To obtain an analytically tractable form, the stationary phase method\nis utilized to approximate the system SE. The approximation result reveals that\nthe average inter-user interference can be negligible with a large waveguide\nspacing and thus the simple MRT is appealing for PA-based multi-user\ncommunications. Furthermore, the system SEs achieved by the two strategies are\ncompared in both the high and low signal-to-noise ratio (SNR) regimes. Our\nanalysis suggests that at high SNRs, the distributed deployment is superior to\nachieve the maximal system SE, while the centralized deployment is more\nsuitable for the low-SNR regime. Finally, the theoretical analysis is verified\nthrough simulations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u591a\u6ce2\u5bfc\u634f\u5408\u5929\u7ebf\uff08PA\uff09\u7684\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\uff0c\u6bd4\u8f83\u4e86\u96c6\u4e2d\u5f0f\u548c\u5206\u5e03\u5f0f\u4e24\u79cd\u90e8\u7f72\u7b56\u7565\u7684\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u9ad8\u4fe1\u566a\u6bd4\u4e0b\u5206\u5e03\u5f0f\u90e8\u7f72\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u90e8\u7f72\uff0c\u800c\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u96c6\u4e2d\u5f0f\u90e8\u7f72\u66f4\u4f18\u3002", "motivation": "\u4e3a\u4e86\u7814\u7a76\u57fa\u4e8e\u591a\u6ce2\u5bfc\u634f\u5408\u5929\u7ebf\uff08PA\uff09\u7684\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5e76\u6bd4\u8f83\u4e24\u79cd\u90e8\u7f72\u7b56\u7565\uff08\u96c6\u4e2d\u5f0f\u548c\u5206\u5e03\u5f0f\uff09\u7684\u4f18\u52a3\u3002", "method": "1. \u96c6\u4e2d\u5f0f\u90e8\u7f72\uff1a\u9996\u5148\u901a\u8fc7\u4f18\u5316 PA \u5728\u6ce2\u5bfc\u4e0a\u7684\u4f4d\u7f6e\u6765\u6700\u5927\u5316\u6700\u8fd1\u7528\u6237\u7684\u4fe1\u9053\u589e\u76ca\uff0c\u7136\u540e\u63a8\u5bfc\u7cfb\u7edf\u8c31\u6548\u7387\u3002 2. \u5206\u5e03\u5f0f\u90e8\u7f72\uff1a\u5728\u6700\u5927\u6bd4\u4f20\u8f93\uff08MRT\uff09\u4e0b\u83b7\u5f97\u7cfb\u7edf\u8c31\u6548\u7387\uff0c\u5e76\u5229\u7528\u5e73\u7a33\u76f8\u4f4d\u6cd5\u8fdb\u884c\u8fd1\u4f3c\uff0c\u4ee5\u83b7\u5f97\u53ef\u89e3\u6790\u5904\u7406\u7684\u5f62\u5f0f\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u5728 \u0410\u0421\u041d\uff08\u9ad8\u4fe1\u566a\u6bd4\uff09\u4e0b\uff0c\u5206\u5e03\u5f0f\u90e8\u7f72\u7684\u7cfb\u7edf\u8c31\u6548\u7387\u66f4\u9ad8\uff1b\u800c\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\uff0c\u96c6\u4e2d\u5f0f\u90e8\u7f72\u66f4\u5177\u4f18\u52bf\u3002\u7406\u8bba\u5206\u6790\u901a\u8fc7\u4eff\u771f\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u5728\u4e24\u79cd\u90e8\u7f72\u7b56\u7565\u7684\u6bd4\u8f83\u4e2d\uff0c\u5206\u5e03\u5f0f\u90e8\u7f72\u5728 \u0410\u0421\u041d\uff08\u9ad8\u4fe1\u566a\u6bd4\uff09\u4e0b\u80fd\u591f\u5b9e\u73b0\u66f4\u9ad8\u7684\u7cfb\u7edf\u8c31\u6548\u7387\uff0c\u800c\u96c6\u4e2d\u5f0f\u90e8\u7f72\u5219\u66f4\u9002\u7528\u4e8e\u4f4e\u4fe1\u566a\u6bd4\u573a\u666f\u3002"}}
{"id": "2507.14787", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14787", "abs": "https://arxiv.org/abs/2507.14787", "authors": ["Xi Xiao", "Aristeidis Tsaris", "Anika Tabassum", "John Lagergren", "Larry M. York", "Tianyang Wang", "Xiao Wang"], "title": "FOCUS: Fused Observation of Channels for Unveiling Spectra", "comment": null, "summary": "Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous\nwavelength bands, making it a powerful tool in biology, agriculture, and\nenvironmental monitoring. However, interpreting Vision Transformers (ViTs) in\nthis setting remains largely unexplored due to two key challenges: (1) existing\nsaliency methods struggle to capture meaningful spectral cues, often collapsing\nattention onto the class token, and (2) full-spectrum ViTs are computationally\nprohibitive for interpretability, given the high-dimensional nature of HSI\ndata. We present FOCUS, the first framework that enables reliable and efficient\nspatial-spectral interpretability for frozen ViTs. FOCUS introduces two core\ncomponents: class-specific spectral prompts that guide attention toward\nsemantically meaningful wavelength groups, and a learnable [SINK] token trained\nwith an attraction loss to absorb noisy or redundant attention. Together, these\ndesigns make it possible to generate stable and interpretable 3D saliency maps\nand spectral importance curves in a single forward pass, without any gradient\nbackpropagation or backbone modification. FOCUS improves band-level IoU by 15\npercent, reduces attention collapse by over 40 percent, and produces saliency\nresults that align closely with expert annotations. With less than 1 percent\nparameter overhead, our method makes high-resolution ViT interpretability\npractical for real-world hyperspectral applications, bridging a long-standing\ngap between black-box modeling and trustworthy HSI decision-making.", "AI": {"tldr": "\"FOCUS enables practical and accurate spatial-spectral interpretability for Vision Transformers in hyperspectral imaging by using spectral prompts and a learnable SINK token to guide attention, overcoming challenges of spectral cue interpretation and computational cost.\"", "motivation": "\"Interpreting Vision Transformers (ViTs) in hyperspectral imaging (HSI) is challenging due to: 1. Existing saliency methods failing to capture meaningful spectral cues, often focusing solely on the class token. 2. Full-spectrum ViTs being computationally expensive for interpretability given HSI's high-dimensional nature.\"", "method": "\"FOCUS utilizes two core components: 1. Class-specific spectral prompts: These guide the attention mechanism towards semantically meaningful wavelength groups within the hyperspectral data. 2. A learnable [SINK] token: This token is trained with an attraction loss to absorb noisy or redundant attention, effectively cleaning up the interpretability signals.\"", "result": "\"FOCUS achieves stable and interpretable 3D saliency maps and spectral importance curves in a single forward pass, without gradient backpropagation or backbone modification. It improves band-level IoU by 15%, reduces attention collapse by over 40%, and generates saliency results that closely align with expert annotations.\"", "conclusion": "\"FOCUS is the first framework enabling reliable and efficient spatial-spectral interpretability for frozen ViTs in hyperspectral imaging. It introduces class-specific spectral prompts and a learnable [SINK] token to guide attention, producing stable and interpretable 3D saliency maps and spectral importance curves. FOCUS improves band-level IoU by 15%, reduces attention collapse by over 40%, aligns with expert annotations, and has less than 1% parameter overhead, making high-resolution ViT interpretability practical for real-world hyperspectral applications.\""}}
{"id": "2507.15521", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15521", "abs": "https://arxiv.org/abs/2507.15521", "authors": ["Cole Robertson", "Philip Wolff"], "title": "LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning", "comment": "Manuscript comprises 14 pages, 4 figures, 4 tables in the Technical\n  Appendix and Supplementary Material, and is under review at NeurIPS 2025", "summary": "Do large language models (LLMs) construct and manipulate internal world\nmodels, or do they rely solely on statistical associations represented as\noutput layer token probabilities? We adapt cognitive science methodologies from\nhuman mental models research to test LLMs on pulley system problems using\nTikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical\nadvantage (MA). State-of-the-art models performed marginally but significantly\nabove chance, and their estimates correlated significantly with ground-truth\nMA. Significant correlations between number of pulleys and model estimates\nsuggest that models employed a pulley counting heuristic, without necessarily\nsimulating pulley systems to derive precise values. Study 2 tested this by\nprobing whether LLMs represent global features crucial to MA estimation. Models\nevaluated a functionally connected pulley system against a fake system with\nrandomly placed components. Without explicit cues, models identified the\nfunctional system as having greater MA with F1=0.8, suggesting LLMs could\nrepresent systems well enough to differentiate jumbled from functional systems.\nStudy 3 built on this by asking LLMs to compare functional systems with matched\nsystems which were connected up but which transferred no force to the weight;\nLLMs identified the functional system with F1=0.46, suggesting random guessing.\nInsofar as they may generalize, these findings are compatible with the notion\nthat LLMs manipulate internal world models, sufficient to exploit statistical\nassociations between pulley count and MA (Study 1), and to approximately\nrepresent system components' spatial relations (Study 2). However, they may\nlack the facility to reason over nuanced structural connectivity (Study 3). We\nconclude by advocating the utility of cognitive scientific methods to evaluate\nthe world-modeling capacities of artificial intelligence systems.", "AI": {"tldr": "LLM\u53ef\u4ee5\u8fdb\u884c\u57fa\u672c\u7684\u7269\u7406\u63a8\u7406\uff0c\u4f46\u5176\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u662f\u6784\u5efa\u548c\u64cd\u7eb5\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u4f5c\u4e3a\u8f93\u51fa\u5c42\u6807\u8bb0\u6982\u7387\u8868\u793a\u7684\u7edf\u8ba1\u5173\u8054\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7684\u5fc3\u667a\u6a21\u578b\u7814\u7a76\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528TikZ\u6e32\u67d3\u7684\u523a\u6fc0\uff0c\u5bf9LLM\u5728\u6ed1\u8f6e\u7cfb\u7edf\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002\u7814\u7a761\u68c0\u67e5\u4e86LLM\u662f\u5426\u80fd\u4f30\u8ba1\u673a\u68b0\u4f18\u52bf\uff08MA\uff09\uff0c\u5e76\u5206\u6790\u4e86\u6ed1\u8f6e\u6570\u91cf\u4e0e\u6a21\u578b\u4f30\u8ba1\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u7814\u7a762\u6d4b\u8bd5\u4e86LLM\u662f\u5426\u80fd\u8868\u793a\u5bf9MA\u4f30\u8ba1\u81f3\u5173\u91cd\u8981\u7684\u5168\u5c40\u7279\u5f81\uff0c\u65b9\u6cd5\u662f\u8bc4\u4f30\u4e00\u4e2a\u529f\u80fd\u8fde\u63a5\u7684\u6ed1\u8f6e\u7cfb\u7edf\u4e0e\u4e00\u4e2a\u7ec4\u4ef6\u968f\u673a\u653e\u7f6e\u7684\u865a\u5047\u7cfb\u7edf\u3002\u7814\u7a763\u5219\u901a\u8fc7\u8981\u6c42LLM\u6bd4\u8f83\u529f\u80fd\u7cfb\u7edf\u4e0e\u8fde\u63a5\u597d\u4f46\u5bf9\u91cd\u91cf\u65e0\u529b\u7684\u5339\u914d\u7cfb\u7edf\u6765\u8fdb\u4e00\u6b65\u63a2\u7a76\u3002", "result": "\u7814\u7a761\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u6a21\u578b\u8868\u73b0\u7565\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\uff0c\u5e76\u4e14\u5176\u4f30\u8ba1\u503c\u4e0e\u771f\u5b9e\u7684\u673a\u68b0\u4f18\u52bf\u663e\u8457\u76f8\u5173\uff0c\u6ed1\u8f6e\u6570\u91cf\u4e0e\u6a21\u578b\u4f30\u8ba1\u503c\u4e4b\u95f4\u4e5f\u5b58\u5728\u663e\u8457\u76f8\u5173\u6027\uff0c\u8fd9\u8868\u660e\u6a21\u578b\u53ef\u80fd\u91c7\u7528\u4e86\u6ed1\u8f6e\u8ba1\u6570\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u7814\u7a762\u663e\u793a\uff0c\u5728\u6ca1\u6709\u660e\u786e\u7ebf\u7d22\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u80fd\u591f\u4ee5F1=0.8\u7684\u51c6\u786e\u7387\u8bc6\u522b\u51fa\u529f\u80fd\u6027\u7cfb\u7edf\uff0c\u8868\u660eLLM\u80fd\u591f\u5145\u5206\u8868\u793a\u7cfb\u7edf\u4ee5\u533a\u5206\u6df7\u4e71\u7cfb\u7edf\u548c\u529f\u80fd\u7cfb\u7edf\u3002\u7814\u7a763\u5219\u663e\u793a\uff0cLLM\u5728\u533a\u5206\u529f\u80fd\u7cfb\u7edf\u4e0e\u65e0\u529b\u4f20\u9012\u7684\u5339\u914d\u7cfb\u7edf\u65f6\u51c6\u786e\u7387\u4ec5\u4e3aF1=0.46\uff0c\u8868\u73b0\u5982\u540c\u968f\u673a\u731c\u6d4b\u3002", "conclusion": "LLM\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u64cd\u7eb5\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u4ee5\u5229\u7528\u6ed1\u8f6e\u6570\u91cf\u548c\u673a\u68b0\u4f18\u52bf\u4e4b\u95f4\u7684\u7edf\u8ba1\u5173\u8054\uff0c\u5e76\u80fd\u8fd1\u4f3c\u8868\u793a\u7cfb\u7edf\u7ec4\u4ef6\u7684\u7a7a\u95f4\u5173\u7cfb\u3002\u7136\u800c\uff0c\u5b83\u4eec\u53ef\u80fd\u7f3a\u4e4f\u63a8\u7406\u7ec6\u5fae\u7ed3\u6784\u8fde\u63a5\u7684\u80fd\u529b\u3002\u6211\u4eec\u4e3b\u5f20\u4f7f\u7528\u8ba4\u77e5\u79d1\u5b66\u65b9\u6cd5\u6765\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2507.14722", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14722", "abs": "https://arxiv.org/abs/2507.14722", "authors": ["Mat\u011bj Kripner", "Michal \u0160ustr", "Milan Straka"], "title": "LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4", "comment": null, "summary": "Automated theorem proving (ATP) has been a classical problem in artificial\nintelligence since its inception, yet it remains challenging due to its vast\nstate and action space. Large language models (LLMs) have recently emerged as a\npromising heuristic for ATP, but they lack correctness guarantees and thus\nrequire interaction with a proof verifier. Such interactions typically follow\none of two approaches: black-box interaction, which does not utilize\nintermediate proof states, or white-box approaches, which allow for incremental\nproof construction and examination of intermediate states. While black-box\napproaches have directly benefited from recent LLM advances, white-box methods\nhave comparatively lagged behind. In this paper, we address this gap by\nintroducing LeanTree, which consists of (i) a tool built in the Lean 4 language\nthat factorizes complex proof states into simpler, independent branches, and\n(ii) a dataset of these factorized intermediate states. Our white-box tooling\noffers several advantages over black-box approaches: it simplifies evaluation,\nreduces necessary context, generates richer training data, enables parallel\nsearch across multiple states, supports efficient reuse of states, and provides\nfeedback in case of errors. Our preliminary results hint that white-box\napproaches outperform black-box alternatives in some settings.", "AI": {"tldr": "LeanTree\u901a\u8fc7\u5c06\u590d\u6742\u8bc1\u660e\u72b6\u6001\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u5206\u652f\uff0c\u5e76\u63d0\u4f9b\u76f8\u5e94\u7684\u6570\u636e\u96c6\uff0c\u6765\u6539\u8fdb\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u767d\u76d2\u65b9\u6cd5\uff0c\u4e0e\u9ed1\u76d2\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u591a\u9879\u4f18\u52bf\uff0c\u5e76\u5728\u521d\u6b65\u7ed3\u679c\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff08ATP\uff09\u4e2d\u7f3a\u4e4f\u6b63\u786e\u6027\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u5e76\u5f25\u8865\u767d\u76d2\u65b9\u6cd5\u5728LLM\u5e94\u7528\u4e2d\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86LeanTree\uff0c\u4e00\u4e2a\u7531Lean 4\u8bed\u8a00\u6784\u5efa\u7684\u5de5\u5177\uff0c\u53ef\u4ee5\u5c06\u590d\u6742\u7684\u8bc1\u660e\u72b6\u6001\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u3001\u72ec\u7acb\u7684\u5206\u652f\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u542b\u8fd9\u4e9b\u5206\u89e3\u7684\u4e2d\u95f4\u72b6\u6001\u7684\u6570\u636e\u96c6\u3002", "result": "LeanTree\u5de5\u5177\u53ef\u4ee5\u7b80\u5316\u8bc4\u4f30\u3001\u51cf\u5c11\u6240\u9700\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u3001\u5b9e\u73b0\u8de8\u591a\u4e2a\u72b6\u6001\u7684\u5e76\u884c\u641c\u7d22\u3001\u652f\u6301\u72b6\u6001\u7684\u9ad8\u6548\u91cd\u7528\uff0c\u5e76\u5728\u51fa\u9519\u65f6\u63d0\u4f9b\u53cd\u9988\u3002", "conclusion": "\u767d\u76d2\u65b9\u6cd5\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f18\u4e8e\u9ed1\u76d2\u65b9\u6cd5\u3002"}}
{"id": "2507.15303", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.15303", "abs": "https://arxiv.org/abs/2507.15303", "authors": ["Liang Zhang", "Kong Chen", "Yuen Wu"], "title": "Universal crystal material property prediction via multi-view geometric fusion in graph transformers", "comment": null, "summary": "Accurately and comprehensively representing crystal structures is critical\nfor advancing machine learning in large-scale crystal materials simulations,\nhowever, effectively capturing and leveraging the intricate geometric and\ntopological characteristics of crystal structures remains a core, long-standing\nchallenge for most existing methods in crystal property prediction. Here, we\npropose MGT, a multi-view graph transformer framework that synergistically\nfuses SE3 invariant and SO3 equivariant graph representations, which\nrespectively captures rotation-translation invariance and rotation equivariance\nin crystal geometries. To strategically incorporate these complementary\ngeometric representations, we employ a lightweight mixture of experts router in\nMGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on\nthe specific target task. Compared with previous state-of-the-art models, MGT\nreduces the mean absolute error by up to 21% on crystal property prediction\ntasks through multi-task self-supervised pretraining. Ablation experiments and\ninterpretable investigations confirm the effectiveness of each technique\nimplemented in our framework. Additionally, in transfer learning scenarios\nincluding crystal catalyst adsorption energy and hybrid perovskite bandgap\nprediction, MGT achieves performance improvements of up to 58% over existing\nbaselines, demonstrating domain-agnostic scalability across diverse application\ndomains. As evidenced by the above series of studies, we believe that MGT can\nserve as useful model for crystal material property prediction, providing a\nvaluable tool for the discovery of novel materials.", "AI": {"tldr": "MGT\u662f\u4e00\u79cd\u65b0\u7684\u56feTransformer\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408SE(3)\u4e0d\u53d8\u548cSO(3)\u7b49\u53d8\u8868\u793a\uff0c\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u5d4c\u5165\u6743\u91cd\uff0c\u63d0\u9ad8\u4e86\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u6676\u4f53\u7ed3\u6784\u8868\u5f81\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u548c\u5229\u7528\u6676\u4f53\u7ed3\u6784\u7684\u51e0\u4f55\u548c\u62d3\u6251\u7279\u5f81\uff0c\u9650\u5236\u4e86\u673a\u5668\u5b66\u4e60\u5728\u6676\u4f53\u6750\u6599\u6a21\u62df\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u5168\u9762\u3001\u51c6\u786e\u5730\u8868\u5f81\u6676\u4f53\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMGT\u7684\u591a\u89c6\u56fe\u56feTransformer\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u878d\u5408\u4e86SE(3)\u4e0d\u53d8\u548cSO(3)\u7b49\u53d8\u56fe\u8868\u793a\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u7ea7\u7684\u4e13\u5bb6\u6df7\u5408\u8def\u7531\u5668\u6765\u6839\u636e\u76ee\u6807\u4efb\u52a1\u81ea\u9002\u5e94\u5730\u8c03\u6574SE(3)\u548cSO(3)\u5d4c\u5165\u7684\u6743\u91cd\u3002", "result": "MGT\u6846\u67b6\u5728\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\u4e0a\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u5c06\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u964d\u4f4e\u4e86\u9ad8\u8fbe21%\u3002\u5728\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e0b\uff08\u5982\u50ac\u5316\u5242\u5438\u9644\u80fd\u548c\u9499\u949b\u77ff\u5e26\u9699\u9884\u6d4b\uff09\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0cMGT\u7684\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe58%\uff0c\u5c55\u73b0\u4e86\u8de8\u9886\u57df\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "MGT\u6846\u67b6\u5728\u6676\u4f53\u7ed3\u6784\u8868\u5f81\u548c\u6027\u8d28\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u901a\u8fc7\u878d\u5408SE(3)\u4e0d\u53d8\u548cSO(3)\u7b49\u53d8\u56fe\u8868\u793a\uff0c\u5e76\u5229\u7528\u8def\u7531\u5668\u81ea\u9002\u5e94\u8c03\u6574\u5d4c\u5165\u6743\u91cd\uff0c\u5728\u591a\u4e2a\u9884\u6d4b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u5c24\u5176\u5728\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\uff0c\u4e3a\u65b0\u578b\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2507.15453", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15453", "abs": "https://arxiv.org/abs/2507.15453", "authors": ["Po-Han Tseng", "Yong-Fan Chen"], "title": "Entanglement Preservation and Clauser-Horne Nonlocality in Electromagnetically Induced Transparency Quantum Memories", "comment": "16 pages, 4 figures", "summary": "Quantum memories are indispensable for quantum repeater networks,\ndeterministic generation of single- or multi-photon states, and linear optical\nquantum computing. Although experiments have demonstrated that\nelectromagnetically induced transparency (EIT) quantum memories can store\nentangled photons, a definitive theoretical framework verifying the\npreservation of entanglement and nonlocality has not been rigorously\nestablished. Here, we develop a comprehensive model by integrating the\ndark-state polariton framework with reduced-density-operator theory to derive\nthe retrieved density operator under realistic ground-state decoherence\nconditions. Our analysis reveals that decoherence inevitably causes probe\nphoton loss, converting a Bell state into a mixed state. Crucially, we predict\na critical storage efficiency threshold of 89.7%. Only when this threshold is\nexceeded does the retrieved probe photon state violate the Clauser-Horne\ninequality, thereby preserving nonlocality; below this point, nonlocal\ncorrelations vanish. Moreover, our theory shows that multiple spatially\nseparated EIT memories can cooperatively store and retrieve N-qubit entangled\nstates encoded in photon number, path, and polarization with near-unity\nfidelity in the ideal limit. This work bridges a long-standing theoretical gap\nand lays a solid foundation for the application of quantum memories in scalable\nquantum networks and quantum information processing.", "AI": {"tldr": "EIT \u91cf\u5b50\u5b58\u50a8\u5668\u5b58\u50a8\u7ea0\u7f20\u5149\u5b50\u7684\u7406\u8bba\u6a21\u578b\u88ab\u5efa\u7acb\uff0c\u5e76\u9884\u6d4b\u4e86\u4fdd\u6301\u975e\u5c40\u57df\u6027\u7684\u4e34\u754c\u5b58\u50a8\u6548\u7387\u9608\u503c\u3002", "motivation": "\u867d\u7136\u5b9e\u9a8c\u8bc1\u660e EIT \u91cf\u5b50\u5b58\u50a8\u5668\u53ef\u4ee5\u5b58\u50a8\u7ea0\u7f20\u5149\u5b50\uff0c\u4f46\u5c1a\u672a\u4e25\u683c\u5efa\u7acb\u9a8c\u8bc1\u7ea0\u7f20\u548c\u975e\u5c40\u57df\u6027\u4fdd\u6301\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u6574\u5408\u6697\u6001\u6781\u5316\u5b50\u6846\u67b6\u548c\u7ea6\u5316\u5bc6\u5ea6\u7b97\u7b26\u7406\u8bba\uff0c\u6211\u4eec\u63a8\u5bfc\u4e86\u5728\u5b9e\u9645\u57fa\u6001\u9000\u76f8\u5e72\u6761\u4ef6\u4e0b\u68c0\u7d22\u5230\u7684\u5bc6\u5ea6\u7b97\u7b26\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u9000\u76f8\u5e72\u4f1a\u5bfc\u81f4\u63a2\u6d4b\u5149\u5b50\u635f\u5931\uff0c\u5c06\u8d1d\u5c14\u6001\u8f6c\u5316\u4e3a\u6df7\u5408\u6001\uff0c\u5e76\u9884\u6d4b\u4e86 89.7% \u7684\u4e34\u754c\u5b58\u50a8\u6548\u7387\u9608\u503c\uff0c\u8d85\u8fc7\u8be5\u9608\u503c\u540e\u63a2\u6d4b\u5149\u5b50\u6001\u624d\u8fdd\u53cd Clauser-Horne \u4e0d\u7b49\u5f0f\uff0c\u4ece\u800c\u4fdd\u6301\u975e\u5c40\u57df\u6027\uff1b\u5728\u7406\u60f3\u6781\u9650\u4e0b\uff0c\u591a\u4e2a\u7a7a\u95f4\u5206\u79bb\u7684 EIT \u5b58\u50a8\u5668\u53ef\u4ee5\u4ee5\u8fd1\u4e4e\u7edf\u4e00\u7684\u4fdd\u771f\u5ea6\u8054\u5408\u5b58\u50a8\u548c\u68c0\u7d22\u7f16\u7801\u5728\u5149\u5b50\u6570\u3001\u8def\u5f84\u548c\u504f\u632f\u4e2d\u7684 N \u95ee\u6570\u91cf\u5b50\u6001\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a EIT \u91cf\u5b50\u5b58\u50a8\u5668\u5728\u53ef\u6269\u5c55\u91cf\u5b50\u7f51\u7edc\u548c\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.15087", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15087", "abs": "https://arxiv.org/abs/2507.15087", "authors": ["Chenlei Gong", "Yuanhe Tian", "Lei Mao", "Yan Song"], "title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling", "comment": null, "summary": "Currently, many studies view DNA sequences as a special type of language and\nutilize Transformers to model them. These studies use fixed-length k-mer\nsegmentation and BPE subword tokenization but lack a systematic evaluation to\ndetermine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a\n4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,\nAliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and\n24-layer Transformer encoders and evaluated on GUE benchmark dataset. In\ngeneral, BPE delivers higher and more stable performance across tasks by\ncompressing frequent motifs into variable-length tokens, reducing sequence\nlength, and improving model generalization. RoPE excels at capturing periodic\nmotifs and extrapolating to long sequences, while AliBi also performs well on\ntasks driven by local dependencies. In terms of depth, we observe significant\ngains when increasing layers from 3 to 12, with only marginal improvements or\nslight overfitting at 24 layers. This study provides practical guidance for\ndesigning tokenization and positional encoding in DNA Transformer models.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86 DNA Transformer \u4e2d\u4e0d\u540c\u7684\u5e8f\u5217\u5206\u5272\u548c\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u3002\u7ed3\u679c\u8868\u660e\uff0cBPE \u5207\u8bcd\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e k-mer\uff0cRoPE \u5728\u957f\u5e8f\u5217\u548c\u5468\u671f\u6027\u57fa\u5e8f\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002\u589e\u52a0\u6a21\u578b\u6df1\u5ea6\u81f3 12 \u5c42\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u5728 DNA Transformer \u6a21\u578b\u4e2d\uff0c\u56fa\u5b9a\u957f\u5ea6\u7684 k-mer \u5e8f\u5217\u5206\u5272\u548c BPE \u5b50\u8bcd\u5207\u8bcd\u54ea\u79cd\u65b9\u6cd5\u66f4\u4f18\u8d8a\u3002", "method": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86 k-mer \u5e8f\u5217\u5206\u5272\uff08k=1, 3, 4, 5, 6\uff09\u30014096 \u8bcd\u6c47\u91cf\u7684 BPE \u5b50\u8bcd\u5207\u8bcd\u3001\u4ee5\u53ca\u4e09\u79cd\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff08sinusoidal, AliBi, RoPE\uff09\u3002\u5728 GUE benchmark \u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u4ece\u5934\u8bad\u7ec3\u7684 3, 6, 12, 24 \u5c42 Transformer \u7f16\u7801\u5668\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "BPE \u5728 GUE benchmark \u6570\u636e\u96c6\u4e0a\u63d0\u4f9b\u4e86\u66f4\u9ad8\u4e14\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002RoPE \u5728\u6355\u6349\u5468\u671f\u6027\u57fa\u5e8f\u548c\u5916\u63a8\u5230\u957f\u5e8f\u5217\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0cAliBi \u5728\u5c40\u90e8\u4f9d\u8d56\u6027\u4efb\u52a1\u4e0a\u4e5f\u8868\u73b0\u826f\u597d\u3002\u6a21\u578b\u6027\u80fd\u968f\u5c42\u6570\u7684\u589e\u52a0\u800c\u63d0\u5347\uff0c\u5728 12 \u5c42\u65f6\u8fbe\u5230\u6700\u4f73\uff0c24 \u5c42\u65f6\u63d0\u5347\u8fb9\u9645\u5316\u3002", "conclusion": "BPE \u5728\u538b\u7f29\u9891\u7e41\u7684\u57fa\u5e8f\uff08motifs\uff09\u3001\u51cf\u5c11\u5e8f\u5217\u957f\u5ea6\u548c\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u4f18\u8d8a\u548c\u7a33\u5b9a\u7684\u6027\u80fd\u3002RoPE \u5728\u6355\u83b7\u5468\u671f\u6027\u57fa\u5e8f\u548c\u5916\u63a8\u5230\u957f\u5e8f\u5217\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800c AliBi \u5728\u5904\u7406\u5c40\u90e8\u4f9d\u8d56\u6027\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002\u589e\u52a0 Transformer \u5c42\u6570\u4ece 3 \u5c42\u5230 12 \u5c42\u53ef\u4ee5\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u800c\u589e\u52a0\u5230 24 \u5c42\u5219\u63d0\u5347\u8fb9\u9645\u6216\u51fa\u73b0\u8f7b\u5fae\u8fc7\u62df\u5408\u3002"}}
{"id": "2507.14856", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14856", "abs": "https://arxiv.org/abs/2507.14856", "authors": ["Victor Shatov", "Steffen Schieler", "Charlotte Muth", "Jos\u00e9 Miguel Mateos-Ramos", "Ivo Bizon", "Florian Euchner", "Sebastian Semper", "Stephan ten Brink", "Gerhard Fettweis", "Christian H\u00e4ger", "Henk Wymeersch", "Laurent Schmalen", "Reiner Thom\u00e4", "Norman Franchi"], "title": "Integrated Radio Sensing Capabilities for 6G Networks: AI/ML Perspective", "comment": "30 pages, 18 figures", "summary": "The sixth-generation wireless communications (6G) is often labeled as\n\"connected intelligence\". Radio sensing, aligned with machine learning (ML) and\nartificial intelligence (AI), promises, among other benefits, breakthroughs in\nthe system's ability to perceive the environment and effectively utilize this\nawareness. This article offers a tutorial-style survey of AI and ML approaches\nto enhance the sensing capabilities of next-generation wireless networks. To\nthis end, while staying in the framework of integrated sensing and\ncommunication (ISAC), we expand the term \"sensing\" from radar, via spectrum\nsensing, to miscellaneous applications of radio sensing like non-cooperative\ntransmitter localization. We formulate the problems, explain the\nstate-of-the-art approaches, and detail AI-based techniques to tackle various\nobjectives in the context of wireless sensing. We discuss the advantages,\nenablers, and challenges of integrating various sensing capabilities into an\nenvisioned AI-powered multimodal multi-task network. In addition to the\ntutorial-style core of this work based on direct authors' involvement in 6G\nresearch problems, we review the related literature, and provide both a good\nstart for those entering this field of research, and a topical overview for a\ngeneral reader with a background in wireless communications", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u548cML\u57286G\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u6559\u7a0b\u5f0f\u8c03\u67e5\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86AI\u548cML\u5728\u589e\u5f3a\u4f20\u611f\u80fd\u529b\u65b9\u9762\u7684\u4f5c\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u6280\u672f\u5728ISAC\u6846\u67b6\u4e0b\u7684\u5e94\u7528\uff0c\u5305\u62ec\u96f7\u8fbe\u3001\u9891\u8c31\u4f20\u611f\u548c\u975e\u5408\u4f5c\u53d1\u5c04\u673a\u5b9a\u4f4d\u7b49\u3002", "motivation": "\u7b2c\u516d\u4ee3\u65e0\u7ebf\u901a\u4fe1\uff086G\uff09\u88ab\u79f0\u4e3a\u201c\u4e92\u8054\u667a\u80fd\u201d\u3002\u65e0\u7ebf\u4f20\u611f\u4e0e\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u548c\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u76f8\u7ed3\u5408\uff0c\u6709\u671b\u5728\u611f\u77e5\u73af\u5883\u548c\u6709\u6548\u5229\u7528\u8fd9\u79cd\u610f\u8bc6\u65b9\u9762\u53d6\u5f97\u7a81\u7834\u3002", "method": "\u672c\u6587\u662fAI\u548cML\u65b9\u6cd5\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u4f20\u611f\u80fd\u529b\u5e94\u7528\u7684\u6559\u7a0b\u5f0f\u8c03\u67e5\u3002\u6211\u4eec\u6269\u5c55\u4e86\u201c\u4f20\u611f\u201d\u7684\u5b9a\u4e49\uff0c\u5305\u62ec\u96f7\u8fbe\u3001\u9891\u8c31\u4f20\u611f\u548c\u975e\u5408\u4f5c\u53d1\u5c04\u673a\u5b9a\u4f4d\u7b49\u591a\u79cd\u65e0\u7ebf\u4f20\u611f\u5e94\u7528\u3002\u6211\u4eec\u8fd8\u5236\u5b9a\u4e86\u95ee\u9898\uff0c\u89e3\u91ca\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u57fa\u4e8eAI\u7684\u6280\u672f\uff0c\u4ee5\u5e94\u5bf9\u65e0\u7ebf\u4f20\u611f\u4e2d\u7684\u5404\u79cd\u76ee\u6807\u3002", "result": "\u6587\u7ae0\u8ba8\u8bba\u4e86\u5c06\u5404\u79cd\u4f20\u611f\u80fd\u529b\u96c6\u6210\u5230\u8bbe\u60f3\u7684\u3001\u7531AI\u9a71\u52a8\u7684\u591a\u6a21\u6001\u591a\u4efb\u52a1\u7f51\u7edc\u4e2d\u7684\u4f18\u52bf\u3001\u63a8\u52a8\u56e0\u7d20\u548c\u6311\u6218\u3002", "conclusion": "AI\u548cML\u65b9\u6cd5\u53ef\u4ee5\u589e\u5f3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7684\u4f20\u611f\u80fd\u529b\uff0c\u5e76\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5404\u79cd\u65e0\u7ebf\u4f20\u611f\u76ee\u6807\u3002"}}
{"id": "2507.14790", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14790", "abs": "https://arxiv.org/abs/2507.14790", "authors": ["Wenbo Yue", "Chang Li", "Guoping Xu"], "title": "A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation", "comment": "6 pages, 6 figures", "summary": "In convolutional neural networks (CNNs), downsampling operations are crucial\nto model performance. Although traditional downsampling methods (such as\nmaximum pooling and cross-row convolution) perform well in feature aggregation,\nreceptive field expansion, and computational reduction, they may lead to the\nloss of key spatial information in semantic segmentation tasks, thereby\naffecting the pixel-by-pixel prediction accuracy.To this end, this study\nproposes a downsampling method based on information complementarity - Hybrid\nPooling Downsampling (HPD). The core is to replace the traditional method with\nMinMaxPooling, and effectively retain the light and dark contrast and detail\nfeatures of the image by extracting the maximum value information of the local\narea.Experiment on various CNN architectures on the ACDC and Synapse datasets\nshow that HPD outperforms traditional methods in segmentation performance, and\nincreases the DSC coefficient by 0.5% on average. The results show that the HPD\nmodule provides an efficient solution for semantic segmentation tasks.", "AI": {"tldr": "HPD\u662f\u4e00\u79cd\u65b0\u7684\u4e0b\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7MinMaxPooling\u4fdd\u7559\u66f4\u591a\u7a7a\u95f4\u4fe1\u606f\uff0c\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\u63d0\u5347\u4e86\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u4e0b\u91c7\u6837\u65b9\u6cd5\uff08\u5982\u6700\u5927\u6c60\u5316\u548c\u8de8\u884c\u5377\u79ef\uff09\u5728\u7279\u5f81\u805a\u5408\u3001\u611f\u53d7\u91ce\u6269\u5c55\u548c\u8ba1\u7b97\u7ea6\u7b80\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\u53ef\u80fd\u4f1a\u4e22\u5931\u5173\u952e\u7684\u7a7a\u95f4\u4fe1\u606f\uff0c\u4ece\u800c\u5f71\u54cd\u50cf\u7d20\u7ea7\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u4e92\u8865\u7684\u4e0b\u91c7\u6837\u65b9\u6cd5\u2014\u2014\u6df7\u5408\u6c60\u5316\u4e0b\u91c7\u6837\uff08HPD\uff09\uff0c\u5e76\u4f7f\u7528MinMaxPooling\u6765\u66ff\u4ee3\u4f20\u7edf\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5c40\u90e8\u533a\u57df\u7684\u6700\u5927\u503c\u4fe1\u606f\u6765\u6709\u6548\u4fdd\u7559\u56fe\u50cf\u7684\u660e\u6697\u5bf9\u6bd4\u5ea6\u548c\u7ec6\u8282\u7279\u5f81\u3002", "result": "\u5728ACDC\u548cSynapse\u6570\u636e\u96c6\u4e0a\u7684\u5404\u79cdCNN\u67b6\u6784\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHPD\u5728\u5206\u5272\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e73\u5747\u5c06DSC\u7cfb\u6570\u63d0\u9ad8\u4e860.5%\u3002", "conclusion": "HPD\u6a21\u5757\u4e3a\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728DSC\u7cfb\u6570\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e860.5%"}}
{"id": "2507.15532", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15532", "abs": "https://arxiv.org/abs/2507.15532", "authors": ["Kasper Engelen", "Guillermo A. P\u00e9rez", "Marnix Suilen"], "title": "Data-Efficient Safe Policy Improvement Using Parametric Structure", "comment": "Accepted at ECAI 2025", "summary": "Safe policy improvement (SPI) is an offline reinforcement learning problem in\nwhich a new policy that reliably outperforms the behavior policy with high\nconfidence needs to be computed using only a dataset and the behavior policy.\nMarkov decision processes (MDPs) are the standard formalism for modeling\nenvironments in SPI. In many applications, additional information in the form\nof parametric dependencies between distributions in the transition dynamics is\navailable. We make SPI more data-efficient by leveraging these dependencies\nthrough three contributions: (1) a parametric SPI algorithm that exploits known\ncorrelations between distributions to more accurately estimate the transition\ndynamics using the same amount of data; (2) a preprocessing technique that\nprunes redundant actions from the environment through a game-based abstraction;\nand (3) a more advanced preprocessing technique, based on satisfiability modulo\ntheory (SMT) solving, that can identify more actions to prune. Empirical\nresults and an ablation study show that our techniques increase the data\nefficiency of SPI by multiple orders of magnitude while maintaining the same\nreliability guarantees.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5229\u7528MDP\u8f6c\u79fb\u52a8\u529b\u5b66\u4e2d\u7684\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\uff0c\u7ed3\u5408\u57fa\u4e8e\u6e38\u620f\u7684\u62bd\u8c61\u548cSMT\u6c42\u89e3\u5668\uff0c\u63d0\u51fa\u4e86\u63d0\u9ad8\u5b89\u5168\u7b56\u7565\u6539\u8fdb\uff08SPI\uff09\u7b97\u6cd5\u6570\u636e\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\uff0cMDP\u7684\u8f6c\u79fb\u52a8\u529b\u5b66\u4e2d\u5b58\u5728\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u8fd9\u4e9b\u4f9d\u8d56\u5173\u7cfb\u6765\u63d0\u9ad8SPI\u7684\u6570\u636e\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u5316SPI\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u5df2\u77e5\u7684\u5206\u5e03\u76f8\u5173\u6027\u6765\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u8f6c\u79fb\u52a8\u529b\u5b66\u3002\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6e38\u620f\u62bd\u8c61\u7684\u9884\u5904\u7406\u6280\u672f\uff0c\u901a\u8fc7\u6d88\u9664\u5197\u4f59\u52a8\u4f5c\u6765\u7b80\u5316\u73af\u5883\u3002\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8eSMT\u6c42\u89e3\u5668\u7684\u66f4\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\uff0c\u4ee5\u8bc6\u522b\u548c\u6d88\u9664\u66f4\u591a\u5197\u4f59\u52a8\u4f5c\u3002", "result": "\u7ecf\u9a8c\u7ed3\u679c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6280\u672f\u53ef\u5c06SPI\u7684\u6570\u636e\u6548\u7387\u63d0\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u53ef\u9760\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u5229\u7528\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\u3001\u57fa\u4e8e\u6e38\u620f\u7684\u62bd\u8c61\u548cSMT\u6c42\u89e3\u5668\u6765\u63d0\u9ad8\u6570\u636e\u6548\u7387\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u53ef\u9760\u6027\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u5c06SPI\u7684\u6570\u636e\u6548\u7387\u63d0\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002"}}
{"id": "2507.14725", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14725", "abs": "https://arxiv.org/abs/2507.14725", "authors": ["Anushka Tiwari", "Sayantan Pal", "Rohini K. Srihari", "Kaiyi Ji"], "title": "Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding", "comment": null, "summary": "Prompt-based continual learning (CL) offers a parameter-efficient way to\nadapt large language models (LLMs) across task sequences. However, most\nexisting methods assume task-aware inference and maintain a growing list of\ntask-specific prompts, which limits scalability and hides latent forgetting. In\nthis work, we introduce GRID, a unified framework that addresses two key\nlimitations: (1) latent forgetting under task-agnostic inference, and (2)\nprompt memory explosion as task sequences grow. GRID integrates a task-aware\ndecoding mechanism that improves backward transfer by leveraging representative\ninputs, automatic task identification, and constrained decoding. Additionally,\nwe propose a gradient-based prompt selection strategy that compresses less\ninformative prompts into a single aggregated representation, enabling scalable\nand memory-efficient lifelong learning. Extensive experiments across\nshort-sequence, long-sequence, and negative transfer benchmarks show that GRID\nsignificantly improves backward transfer, achieves competitive forward\ntransfer, and reduces forgotten tasks by up to 80\\%, outperforming\nstate-of-the-art methods on T5 and Flan-T5 backbones.", "AI": {"tldr": "GRID \u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u63d0\u793a\u57fa\u7840\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u9057\u5fd8\u548c\u63d0\u793a\u7206\u70b8\u95ee\u9898\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u89e3\u7801\u548c\u538b\u7f29\u63d0\u793a\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u5185\u5b58\u9ad8\u6548\u7684\u7ec8\u8eab\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u57fa\u7840\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5728\u4efb\u52a1\u611f\u77e5\u63a8\u7406\u548c\u63d0\u793a\u5217\u8868\u589e\u957f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u5dee\u548c\u6f5c\u5728\u9057\u5fd8\u3002", "method": "GRID \u6846\u67b6\u96c6\u6210\u4e86\u4efb\u52a1\u611f\u77e5\u89e3\u7801\uff08\u5229\u7528\u4ee3\u8868\u6027\u8f93\u5165\u3001\u81ea\u52a8\u4efb\u52a1\u8bc6\u522b\u548c\u7ea6\u675f\u89e3\u7801\uff09\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u63d0\u793a\u9009\u62e9\uff08\u538b\u7f29\u4e0d\u91cd\u8981\u63d0\u793a\uff09\u3002", "result": "GRID \u663e\u8457\u63d0\u9ad8\u4e86\u5411\u540e\u8fc1\u79fb\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u5411\u524d\u8fc1\u79fb\u80fd\u529b\uff0c\u5e76\u5c06\u9057\u5fd8\u4efb\u52a1\u51cf\u5c11\u4e86\u9ad8\u8fbe 80%\uff0c\u5728 T5 \u548c Flan-T5 \u4e3b\u5e72\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "GRID \u6846\u67b6\u901a\u8fc7\u96c6\u6210\u4efb\u52a1\u611f\u77e5\u89e3\u7801\u673a\u5236\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u63d0\u793a\u9009\u62e9\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63d0\u793a\u57fa\u7840\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u9057\u5fd8\u548c\u63d0\u793a\u7206\u70b8\u95ee\u9898\uff0c\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.15458", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15458", "abs": "https://arxiv.org/abs/2507.15458", "authors": ["Asghar Ullah", "M. Tahir Naseem", "\u00d6zg\u00fcr E. M\u00fcstecapl\u0131o\u011flu"], "title": "Quantum thermometry with non-Gaussian states: From non-equilibrium speed to equilibrium precision", "comment": "20 pages, 15 figures. Comments and feedback are welcome", "summary": "We study temperature estimation using quantum probes, including single-mode\ninitial states and two-mode states generated via stimulated parametric\ndown-conversion in a nonlinear crystal at finite temperature. We explore both\ntransient and equilibrium regimes and compare the performance of Gaussian and\nnon-Gaussian probe states for temperature estimation. In the non-equilibrium\nregime, we show that single-mode non-Gaussian probe states - such as Fock, odd\ncat, and Gottesman-Kitaev-Preskill states - can significantly enhance the speed\nof estimation, particularly at short interaction times. In the two-mode\nsetting, entangled states such as the two-mode squeezed vacuum, NOON state, and\nentangled cat state can enable access to temperature information at much\nearlier times. In the equilibrium regime, we analyze temperature estimation\nusing two-mode squeezed thermal states, which outperform single-mode\nstrategies. We evaluate practical measurements and find that both energy and\npopulation difference observables yield optimal precision, while\nquadrature-based measurements are suboptimal. The precision gain arises from\nsqueezing, which suppresses fluctuations in the population difference.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u91cf\u5b50\u63a2\u9488\u5728\u4e0d\u540c\u72b6\u6001\uff08\u77ac\u6001\u3001\u5e73\u8861\uff09\u548c\u7c7b\u578b\uff08\u9ad8\u65af\u3001\u975e\u9ad8\u65af\u3001\u5355\u6a21\u3001\u53cc\u6a21\uff09\u4e0b\u8fdb\u884c\u6e29\u5ea6\u4f30\u8ba1\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u975e\u9ad8\u65af\u63a2\u9488\u548c\u7ea0\u7f20\u6001\u5728\u975e\u5e73\u8861\u72b6\u6001\u4e0b\u80fd\u63d0\u9ad8\u4f30\u8ba1\u901f\u5ea6\u548c\u7cbe\u5ea6\uff0c\u800c\u5728\u5e73\u8861\u72b6\u6001\u4e0b\uff0c\u53cc\u6a21\u538b\u7f29\u70ed\u6001\u4f18\u4e8e\u5355\u6a21\u7b56\u7565\u3002\u80fd\u91cf\u548c\u5e03\u5c14\u6570\u53ef\u89c2\u6d4b\u91cf\u662f\u6700\u4f73\u6d4b\u91cf\u65b9\u5f0f\u3002", "motivation": "\u6211\u4eec\u7814\u7a76\u4f7f\u7528\u91cf\u5b50\u63a2\u9488\u8fdb\u884c\u6e29\u5ea6\u4f30\u8ba1\uff0c\u4ee5\u63a2\u7d22\u5728\u9ad8\u65af\u548c\u975e\u9ad8\u65af\u63a2\u9488\u72b6\u6001\u4e0b\uff0c\u5728\u77ac\u6001\u548c\u5e73\u8861\u72b6\u6001\u4e0b\u7684\u4f30\u8ba1\u6027\u80fd\u3002", "method": "\u6211\u4eec\u7814\u7a76\u4e86\u4f7f\u7528\u91cf\u5b50\u63a2\u9488\u8fdb\u884c\u6e29\u5ea6\u4f30\u8ba1\uff0c\u5305\u62ec\u5355\u6a21\u521d\u59cb\u6001\u548c\u5728\u6709\u9650\u6e29\u5ea6\u4e0b\u901a\u8fc7\u975e\u7ebf\u6027\u6676\u4f53\u53d7\u6fc0\u53c2\u91cf\u4e0b\u8f6c\u6362\u4ea7\u751f\u7684\u53cc\u6a21\u6001\u3002\u6211\u4eec\u63a2\u7d22\u4e86\u77ac\u6001\u548c\u5e73\u8861\u72b6\u6001\uff0c\u5e76\u6bd4\u8f83\u4e86\u9ad8\u65af\u548c\u975e\u9ad8\u65af\u63a2\u9488\u72b6\u6001\u5728\u6e29\u5ea6\u4f30\u8ba1\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u5728\u975e\u5e73\u8861\u72b6\u6001\u4e0b\uff0c\u5355\u6a21\u975e\u9ad8\u65af\u63a2\u9488\u72b6\u6001\uff08\u5982 Fock\u3001\u5947\u6570\u732b\u548c Gottesman-Kitaev-Preskill \u72b6\u6001\uff09\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4f30\u8ba1\u901f\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u76f8\u4e92\u4f5c\u7528\u65f6\u95f4\u77ed\u7684\u60c5\u51b5\u4e0b\u3002\u5728\u53cc\u6a21\u60c5\u51b5\u4e0b\uff0c\u7ea0\u7f20\u6001\uff08\u5982\u53cc\u6a21\u538b\u7f29\u771f\u7a7a\u3001NOON \u6001\u548c\u7ea0\u7f20\u732b\u6001\uff09\u53ef\u4ee5\u66f4\u65e9\u5730\u83b7\u53d6\u6e29\u5ea6\u4fe1\u606f\u3002\u5728\u5e73\u8861\u72b6\u6001\u4e0b\uff0c\u53cc\u6a21\u538b\u7f29\u70ed\u6001\u7684\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u7b56\u7565\u3002\u80fd\u91cf\u548c\u5e03\u5c14\u6570\u53ef\u89c2\u6d4b\u91cf\u80fd\u83b7\u5f97\u6700\u4f73\u7cbe\u5ea6\uff0c\u800c\u4e8c\u6b21\u6d4b\u91cf\u5219\u4e0d\u662f\u6700\u4f73\u9009\u62e9\u3002\u538b\u7f29\u53ef\u4ee5\u6291\u5236\u5e03\u5c14\u6570\u4e2d\u7684\u6da8\u843d\uff0c\u4ece\u800c\u63d0\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u5728\u975e\u5e73\u8861\u72b6\u6001\u4e0b\uff0c\u5355\u6a21\u975e\u9ad8\u65af\u63a2\u9488\u72b6\u6001\uff08\u5982 Fock\u3001\u5947\u6570\u732b\u548c Gottesman-Kitaev-Preskill \u72b6\u6001\uff09\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4f30\u8ba1\u901f\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u76f8\u4e92\u4f5c\u7528\u65f6\u95f4\u77ed\u7684\u60c5\u51b5\u4e0b\u3002\u5728\u53cc\u6a21\u60c5\u51b5\u4e0b\uff0c\u7ea0\u7f20\u6001\uff08\u5982\u53cc\u6a21\u538b\u7f29\u771f\u7a7a\u3001NOON \u6001\u548c\u7ea0\u7f20\u732b\u6001\uff09\u53ef\u4ee5\u66f4\u65e9\u5730\u83b7\u53d6\u6e29\u5ea6\u4fe1\u606f\u3002\u5728\u5e73\u8861\u72b6\u6001\u4e0b\uff0c\u53cc\u6a21\u538b\u7f29\u70ed\u6001\u7684\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u7b56\u7565\u3002\u80fd\u91cf\u548c\u5e03\u5c14\u6570\u53ef\u89c2\u6d4b\u91cf\u80fd\u83b7\u5f97\u6700\u4f73\u7cbe\u5ea6\uff0c\u800c\u4e8c\u6b21\u6d4b\u91cf\u5219\u4e0d\u662f\u6700\u4f73\u9009\u62e9\u3002\u538b\u7f29\u53ef\u4ee5\u6291\u5236\u5e03\u5c14\u6570\u4e2d\u7684\u6da8\u843d\uff0c\u4ece\u800c\u63d0\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2507.15092", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15092", "abs": "https://arxiv.org/abs/2507.15092", "authors": ["Vijeta Deshpande", "Ishita Dasgupta", "Uttaran Bhattacharya", "Somdeb Sarkhel", "Saayan Mitra", "Anna Rumshisky"], "title": "A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations", "comment": null, "summary": "Synthetic text generated by Large Language Models (LLMs) is increasingly used\nfor further training and improvement of LLMs. Diversity is crucial for the\neffectiveness of synthetic data, and researchers rely on prompt engineering to\nimprove diversity. However, the impact of prompt variations on response text\nlength, and, more importantly, the consequential effect on lexical diversity\nmeasurements, remain underexplored. In this work, we propose Penalty-Adjusted\nType-Token Ratio (PATTR), a diversity metric robust to length variations. We\ngenerate a large synthetic corpus of over 20M words using seven models from the\nLLaMA, OLMo, and Phi families, focusing on a creative writing task of video\nscript generation, where diversity is crucial. We evaluate per-response lexical\ndiversity using PATTR and compare it against existing metrics of Moving-Average\nTTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length\nvariations introduce biases favoring shorter responses. Unlike existing\nmetrics, PATTR explicitly considers the task-specific target response length\n($L_T$) to effectively mitigate length biases. We further demonstrate the\nutility of PATTR in filtering the top-10/100/1,000 most lexically diverse\nresponses, showing that it consistently outperforms MATTR and CR by yielding on\npar or better diversity with high adherence to $L_T$.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86PATTR\uff0c\u4e00\u79cd\u80fd\u514b\u670d\u6587\u672c\u957f\u5ea6\u504f\u5dee\u7684\u65b0\u578b\u591a\u6837\u6027\u5ea6\u91cf\u6307\u6807\uff0c\u9002\u7528\u4e8eLLM\u5408\u6210\u6570\u636e\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u7684LLM\u7814\u7a76\u4e2d\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u8bad\u7ec3\u548c\u6539\u8fdbLLM\u7684\u5408\u6210\u6587\u672c\u591a\u6837\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u63d0\u793a\u5de5\u7a0b\u5728\u63d0\u9ad8\u591a\u6837\u6027\u65b9\u9762\u7684\u5177\u4f53\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u54cd\u5e94\u6587\u672c\u957f\u5ea6\u548c\u8bcd\u6c47\u591a\u6837\u6027\u6d4b\u91cf\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u5c1a\u5f85\u6df1\u5165\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPATTR\uff08Penalty-Adjusted Type-Token Ratio\uff09\u7684\u65b0\u578b\u8bcd\u6c47\u591a\u6837\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528LLaMA\u3001OLMo\u548cPhi\u7cfb\u5217\u4e2d\u7684\u4e03\u79cd\u6a21\u578b\u751f\u6210\u4e86\u8d85\u8fc72000\u4e07\u8bcd\u7684\u5408\u6210\u8bed\u6599\u5e93\uff0c\u4e13\u6ce8\u4e8e\u89c6\u9891\u811a\u672c\u751f\u6210\u8fd9\u4e00\u9700\u8981\u9ad8\u591a\u6837\u6027\u7684\u521b\u610f\u5199\u4f5c\u4efb\u52a1\u3002", "result": "\u901a\u8fc7\u5bf9\u751f\u6210\u76842000\u4e07\u8bcd\u8bed\u6599\u5e93\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u73b0\u6709\u7684\u591a\u6837\u6027\u5ea6\u91cf\u6307\u6807\uff08\u5982MATTR\u548cCR\uff09\u5728\u9762\u5bf9\u6587\u672c\u957f\u5ea6\u53d8\u5316\u65f6\u5b58\u5728\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u504f\u7231\u8f83\u77ed\u7684\u54cd\u5e94\u3002\u800cPATTR\u901a\u8fc7\u660e\u786e\u8003\u8651\u4efb\u52a1\u76ee\u6807\u54cd\u5e94\u957f\u5ea6\uff08LT\uff09\uff0c\u6709\u6548\u51cf\u8f7b\u4e86\u8fd9\u79cd\u957f\u5ea6\u504f\u5dee\uff0c\u5e76\u5728\u7b5b\u9009\u591a\u6837\u5316\u54cd\u5e94\u65b9\u9762\u8868\u73b0\u4f18\u4e8eMATTR\u548cCR\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86PATTR\uff08Penalty-Adjusted Type-Token Ratio\uff09\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u8bcd\u6c47\u591a\u6837\u6027\u5ea6\u91cf\u6807\u51c6\uff0c\u8be5\u6807\u51c6\u80fd\u591f\u6709\u6548\u7f13\u89e3\u6587\u672c\u957f\u5ea6\u53d8\u5316\u5e26\u6765\u7684\u504f\u5dee\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u8bc4\u4f30\u548c\u7b5b\u9009\u591a\u6837\u5316\u6587\u672c\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.14888", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14888", "abs": "https://arxiv.org/abs/2507.14888", "authors": ["Zhuo Wang"], "title": "Stabilization of the bias point in MZM modulators", "comment": null, "summary": "This article mainly introduces the role of MZM in practical communication\nsystems, the materials used to make MZM modulators such as lithium niobate, and\nits working principle. It also explains why it changes due to environmental\nfactors. This leads to the introduction of a method that controls the stable\npoints of MZM by algorithmically controlling the voltage, and the algorithm is\nverified through experiments. Finally, a summary and outlook on the future\ndevelopment of MZM are provided.", "AI": {"tldr": "\u4ecb\u7ecdMZM\u53ca\u5176\u5728\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u901a\u8fc7\u7b97\u6cd5\u63a7\u5236\u7535\u538b\u4ee5\u4fdd\u6301\u5176\u7a33\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4ecb\u7ecdMZM\u5728\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\u3001\u6750\u6599\u3001\u5de5\u4f5c\u539f\u7406\u4ee5\u53ca\u6613\u53d7\u73af\u5883\u56e0\u7d20\u5f71\u54cd\u7684\u7279\u6027\uff0c\u5f15\u51fa\u901a\u8fc7\u7b97\u6cd5\u63a7\u5236\u7535\u538b\u4ee5\u4fdd\u6301\u5176\u7a33\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7b97\u6cd5\u63a7\u5236\u7535\u538b\u6765\u63a7\u5236MZM\u7684\u7a33\u5b9a\u70b9\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u3002", "result": "\u9a8c\u8bc1\u4e86\u901a\u8fc7\u7b97\u6cd5\u63a7\u5236\u7535\u538b\u4ee5\u4fdd\u6301MZM\u7a33\u5b9a\u6027\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86MZM\u5728\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u5c55\u671b\u3002"}}
{"id": "2507.14809", "categories": ["cs.CV", "cs.MM", "cs.RO", "I.2.10; I.4.8"], "pdf": "https://arxiv.org/pdf/2507.14809", "abs": "https://arxiv.org/abs/2507.14809", "authors": ["Zesen Zhong", "Duomin Zhang", "Yijia Li"], "title": "Light Future: Multimodal Action Frame Prediction via InstructPix2Pix", "comment": "9 pages including appendix, 5 tables, 8 figures, to be submitted to\n  WACV 2026", "summary": "Predicting future motion trajectories is a critical capability across domains\nsuch as robotics, autonomous systems, and human activity forecasting, enabling\nsafer and more intelligent decision-making. This paper proposes a novel,\nefficient, and lightweight approach for robot action prediction, offering\nsignificantly reduced computational cost and inference latency compared to\nconventional video prediction models. Importantly, it pioneers the adaptation\nof the InstructPix2Pix model for forecasting future visual frames in robotic\ntasks, extending its utility beyond static image editing. We implement a deep\nlearning-based visual prediction framework that forecasts what a robot will\nobserve 100 frames (10 seconds) into the future, given a current image and a\ntextual instruction. We repurpose and fine-tune the InstructPix2Pix model to\naccept both visual and textual inputs, enabling multimodal future frame\nprediction. Experiments on the RoboTWin dataset (generated based on real-world\nscenarios) demonstrate that our method achieves superior SSIM and PSNR compared\nto state-of-the-art baselines in robot action prediction tasks. Unlike\nconventional video prediction models that require multiple input frames, heavy\ncomputation, and slow inference latency, our approach only needs a single image\nand a text prompt as input. This lightweight design enables faster inference,\nreduced GPU demands, and flexible multimodal control, particularly valuable for\napplications like robotics and sports motion trajectory analytics, where motion\ntrajectory precision is prioritized over visual fidelity.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14797", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14797", "abs": "https://arxiv.org/abs/2507.14797", "authors": ["Beier Zhu", "Ruoyu Wang", "Tong Zhao", "Hanwang Zhang", "Chi Zhang"], "title": "Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models", "comment": "To appear in ICCV 2025", "summary": "Diffusion models (DMs) have achieved state-of-the-art generative performance\nbut suffer from high sampling latency due to their sequential denoising nature.\nExisting solver-based acceleration methods often face image quality degradation\nunder a low-latency budget. In this paper, we propose the Ensemble Parallel\nDirection solver (dubbed as \\ours), a novel ODE solver that mitigates\ntruncation errors by incorporating multiple parallel gradient evaluations in\neach ODE step. Importantly, since the additional gradient computations are\nindependent, they can be fully parallelized, preserving low-latency sampling.\n  Our method optimizes a small set of learnable parameters in a distillation\nfashion, ensuring minimal training overhead.\n  In addition, our method can serve as a plugin to improve existing ODE\nsamplers. Extensive experiments on various image synthesis benchmarks\ndemonstrate the effectiveness of our \\ours~in achieving high-quality and\nlow-latency sampling. For example, at the same latency level of 5 NFE, EPD\nachieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26\non LSUN Bedroom, surpassing existing learning-based solvers by a significant\nmargin. Codes are available in https://github.com/BeierZhu/EPD.", "AI": {"tldr": "EPD is a novel ODE solver that accelerates diffusion models by parallelizing gradient evaluations, achieving high-quality results with low latency and outperforming existing methods.", "motivation": "Diffusion models suffer from high sampling latency due to their sequential denoising nature, and existing acceleration methods often degrade image quality under low-latency constraints.", "method": "EPD incorporates multiple parallel gradient evaluations in each ODE step to mitigate truncation errors, allowing for fully parallelized additional gradient computations to preserve low-latency sampling. It optimizes a small set of learnable parameters in a distillation fashion.", "result": "EPD achieves state-of-the-art performance in low-latency sampling, surpassing existing learning-based solvers. For instance, at 5 NFE, EPD achieves FID scores of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26 on LSUN Bedroom.", "conclusion": "Our method, Ensemble Parallel Direction solver (EPD), achieves high-quality and low-latency sampling by mitigating truncation errors through parallel gradient evaluations in each ODE step. It optimizes learnable parameters with minimal training overhead and can be used as a plugin for existing ODE samplers."}}
{"id": "2507.15581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15581", "abs": "https://arxiv.org/abs/2507.15581", "authors": ["Ekaterina Goliakova", "Xavier Renard", "Marie-Jeanne Lesot", "Thibault Laugel", "Christophe Marsala", "Marcin Detyniecki"], "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks", "comment": null, "summary": "Using multiple-choice questions (MCQs) has become a standard for assessing\nLLM capabilities efficiently. A variety of metrics can be employed for this\ntask. However, previous research has not conducted a thorough assessment of\nthem. At the same time, MCQ evaluation suffers from answer fluctuation: models\nproduce different results given slight changes in prompts. We suggest a metric\nassessment protocol in which evaluation methodologies are analyzed through\ntheir connection with fluctuation rates, as well as original performance. Our\nresults show that there is a strong link between existing metrics and the\nanswer changing, even when computed without any additional prompt variants. A\nnovel metric, worst accuracy, demonstrates the highest association on the\nprotocol.", "AI": {"tldr": "LLM\u8bc4\u4f30\u7684MCQ\u5b58\u5728\u7b54\u6848\u6ce2\u52a8\u95ee\u9898\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u5c06\u201c\u6700\u5dee\u51c6\u786e\u7387\u201d\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u6307\u6807\uff0c\u5b83\u4e0e\u7b54\u6848\u6ce2\u52a8\u6709\u5f88\u5f3a\u7684\u5173\u8054\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3LLM\u8bc4\u4f30\u4e2d\u591a\u9879\u9009\u62e9\u9898\uff08MCQ\uff09\u8bc4\u4f30\u7684\u7b54\u6848\u6ce2\u52a8\u95ee\u9898\uff0c\u5e76\u5bf9\u73b0\u6709\u6307\u6807\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6307\u6807\u8bc4\u4f30\u534f\u8bae\uff0c\u901a\u8fc7\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u4e0d\u786e\u5b9a\u6027\u7387\u4ee5\u53ca\u539f\u59cb\u6027\u80fd\u7684\u8054\u7cfb\u6765\u5206\u6790\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u73b0\u6709\u6307\u6807\u4e0e\u7b54\u6848\u53d8\u5316\u4e4b\u95f4\u5b58\u5728\u5f88\u5f3a\u7684\u8054\u7cfb\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u989d\u5916\u63d0\u793a\u53d8\u4f53\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u4e5f\u662f\u5982\u6b64\u3002\u201c\u6700\u5dee\u51c6\u786e\u7387\u201d\u8fd9\u4e00\u65b0\u6307\u6807\u4e0e\u8be5\u534f\u8bae\u5177\u6709\u6700\u9ad8\u7684\u5173\u8054\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6307\u6807\u8bc4\u4f30\u534f\u8bae\u5c06\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u5176\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u539f\u59cb\u6027\u80fd\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u4e14\u201c\u6700\u5dee\u51c6\u786e\u7387\u201d\u6307\u6807\u4e0e\u8be5\u534f\u8bae\u5177\u6709\u6700\u9ad8\u7684\u5173\u8054\u6027\u3002"}}
{"id": "2507.14736", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14736", "abs": "https://arxiv.org/abs/2507.14736", "authors": ["Rafa\u0142 Surdej", "Micha\u0142 Bortkiewicz", "Alex Lewandowski", "Mateusz Ostaszewski", "Clare Lyle"], "title": "Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning", "comment": "Accepted for oral presentation at CoLLAs 2025", "summary": "Trainable activation functions, whose parameters are optimized alongside\nnetwork weights, offer increased expressivity compared to fixed activation\nfunctions. Specifically, trainable activation functions defined as ratios of\npolynomials (rational functions) have been proposed to enhance plasticity in\nreinforcement learning. However, their impact on training stability remains\nunclear. In this work, we study trainable rational activations in both\nreinforcement and continual learning settings. We find that while their\nflexibility enhances adaptability, it can also introduce instability, leading\nto overestimation in RL and feature collapse in longer continual learning\nscenarios. Our main result is demonstrating a trade-off between expressivity\nand plasticity in rational activations. To address this, we propose a\nconstrained variant that structurally limits excessive output scaling while\npreserving adaptability. Experiments across MetaWorld and DeepMind Control\nSuite (DMC) environments show that our approach improves training stability and\nperformance. In continual learning benchmarks, including MNIST with reshuffled\nlabels and Split CIFAR-100, we reveal how different constraints affect the\nbalance between expressivity and long-term retention. While preliminary\nexperiments in discrete action domains (e.g., Atari) did not show similar\ninstability, this suggests that the trade-off is particularly relevant for\ncontinuous control. Together, our findings provide actionable design principles\nfor robust and adaptable trainable activations in dynamic, non-stationary\nenvironments. Code available at:\nhttps://github.com/special114/rl_rational_plasticity.", "AI": {"tldr": "\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8868\u8fbe\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u7684\u6743\u8861\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea6\u675f\u53d8\u4f53\uff0c\u901a\u8fc7\u9650\u5236\u8f93\u51fa\u5c3a\u5ea6\u6765\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u3002\u4ee3\u7801\u5df2\u53d1\u5e03\u3002", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u53ef\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\uff08\u7279\u522b\u662f\u4f5c\u4e3a\u591a\u9879\u5f0f\u6bd4\u7387\u7684\u6709\u7406\u51fd\u6570\uff09\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u5851\u6027\uff0c\u540c\u65f6\u89e3\u51b3\u5176\u5bf9\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u5176\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4e86\u53ef\u8bad\u7ec3\u7684\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea6\u675f\u53d8\u4f53\u6765\u89e3\u51b3\u5176\u6f5c\u5728\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5728MetaWorld\u3001DeepMind Control Suite\uff08DMC\uff09\u3001MNIST\uff08\u91cd\u6392\u6807\u7b7e\uff09\u548cSplit CIFAR-100\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u53ef\u8bad\u7ec3\u7684\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u867d\u7136\u589e\u5f3a\u4e86\u9002\u5e94\u6027\uff0c\u4f46\u4e5f\u53ef\u80fd\u5f15\u5165\u4e0d\u7a33\u5b9a\u6027\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9ad8\u4f30\u548c\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u5d29\u6e83\u3002\u63d0\u51fa\u7684\u7ea6\u675f\u53d8\u4f53\u901a\u8fc7\u9650\u5236\u8fc7\u5ea6\u7684\u8f93\u51fa\u5c3a\u5ea6\uff0c\u5728\u4fdd\u6301\u9002\u5e94\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540c\u7ea6\u675f\u5bf9\u8868\u8fbe\u80fd\u529b\u548c\u957f\u671f\u4fdd\u6301\u80fd\u529b\u5e73\u8861\u7684\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u8fd9\u79cd\u6743\u8861\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u5c24\u4e3a\u5173\u952e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u8bad\u7ec3\u7684\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u5728\u9002\u5e94\u6027\u548c\u8868\u8fbe\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u7ea6\u675f\u53d8\u4f53\uff0c\u53ef\u4ee5\u9650\u5236\u8fc7\u5ea6\u7684\u8f93\u51fa\u5c3a\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9002\u5e94\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u5728\u8fde\u7eed\u63a7\u5236\u548c\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u4f46\u5176\u5728\u79bb\u6563\u52a8\u4f5c\u57df\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u6697\u793a\u8fd9\u79cd\u6743\u8861\u5728\u8fde\u7eed\u63a7\u5236\u4e2d\u5c24\u4e3a\u91cd\u8981\u3002\u7814\u7a76\u4e3a\u5728\u52a8\u6001\u3001\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8bbe\u8ba1\u9c81\u68d2\u4e14\u53ef\u9002\u5e94\u7684\u53ef\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.15506", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15506", "abs": "https://arxiv.org/abs/2507.15506", "authors": ["Mi-Jung So", "Mahn-Soo Choi"], "title": "Symmetry and Liouville Space Formulation of Decoherence-Free Subsystems", "comment": "12 pages with 3 figures", "summary": "We propose a generic and systematic decoherence-free scheme to encode quantum\ninformation into an open quantum system based focusing on symmetry. Under a\ngiven symmetry, the Liouville space is decomposed into invariant subspaces\ncharacterized by a tensor-product structure. A decoherence-free subsystem is\nthen identified as a factor of the tensor product. Unlike decoherence-free\nsubspaces, which typically require strong symmetries, decoherence-free systems\nare permitted under less restrictive weak symmetries. Specifically, we\nprimarily concern the permutation symmetry in conjunction with the unitary\nsymmetry and utilize the Schur-Weyl duality, which facilitates numerous\nefficient and systematic calculations based on the well-established group\nrepresentation theory. Employing the isomorphism between the Liouville space\nand the fictitious Hilbert space, we construct a super-Schur basis, which\nblock-diagonalizes the super-operators that describe the noisy quantum\nchannels, both in the Kraus representation and in terms of the quantum master\nequation. Each block reveals the tensor-product structure and facilitates the\nidentification of physically relevant decoherence-free subsystems under the\nspecified weak symmetry.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u9000\u76f8\u5e72\u81ea\u7531\u65b9\u6848\uff0c\u5229\u7528\u8212\u5c14-\u97e6\u5c14\u5bf9\u5076\u6027\u548c\u8d85\u7ea7\u8212\u5c14\u57fa\u7b80\u5316\u4e86\u8ba1\u7b97\uff0c\u5e76\u80fd\u8bc6\u522b\u51fa\u9000\u76f8\u5e72\u81ea\u7531\u5b50\u7cfb\u7edf\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u7684\u3001\u7cfb\u7edf\u7684\u9000\u76f8\u5e72\u81ea\u7531\u65b9\u6848\uff0c\u7528\u4e8e\u5728\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7f16\u7801\u91cf\u5b50\u4fe1\u606f\uff0c\u91cd\u70b9\u5728\u4e8e\u5bf9\u79f0\u6027\u3002", "method": "\u901a\u8fc7\u5229\u7528\u8212\u5c14-\u97e6\u5c14\u5bf9\u5076\u6027\uff0c\u57fa\u4e8e\u6210\u719f\u7684\u7fa4\u8868\u793a\u8bba\u8fdb\u884c\u8ba1\u7b97\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u8d85\u7ea7\u8212\u5c14\u57fa\uff0c\u5c06\u63cf\u8ff0\u566a\u58f0\u91cf\u5b50\u901a\u9053\u7684\u8d85\u7ea7\u7b97\u5b50\u8fdb\u884c\u5757\u5bf9\u89d2\u5316\u3002", "result": "\u8be5\u65b9\u6848\u80fd\u591f\u8bc6\u522b\u51fa\u9000\u76f8\u5e72\u81ea\u7531\u5b50\u7cfb\u7edf\uff0c\u5e76\u5229\u7528\u8212\u5c14-\u97e6\u5c14\u5bf9\u5076\u6027\u7b80\u5316\u4e86\u8ba1\u7b97\u3002", "conclusion": "\u53ef\u4ee5\u8bc6\u522b\u51fa\u7269\u7406\u4e0a\u76f8\u5173\u7684\u9000\u76f8\u5e72\u81ea\u7531\u5b50\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u5b50\u7cfb\u7edf\u5728\u6307\u5b9a\u7684\u5f31\u5bf9\u79f0\u6027\u4e0b\u662f\u53ef\u8bc6\u522b\u7684\u3002"}}
{"id": "2507.15100", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15100", "abs": "https://arxiv.org/abs/2507.15100", "authors": ["Chathuri Jayaweera", "Brianna Yanqui", "Bonnie Dorr"], "title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?", "comment": "9 pages, 8 figures and 5 tables", "summary": "Natural Language Inference (NLI) is the task of determining the semantic\nentailment of a premise for a given hypothesis. The task aims to develop\nsystems that emulate natural human inferential processes where commonsense\nknowledge plays a major role. However, existing commonsense resources lack\nsufficient coverage for a variety of premise-hypothesis pairs. This study\nexplores the potential of Large Language Models as commonsense knowledge\ngenerators for NLI along two key dimensions: their reliability in generating\nsuch knowledge and the impact of that knowledge on prediction accuracy. We\nadapt and modify existing metrics to assess LLM factuality and consistency in\ngenerating in this context. While explicitly incorporating commonsense\nknowledge does not consistently improve overall results, it effectively helps\ndistinguish entailing instances and moderately improves distinguishing\ncontradictory and neutral inferences.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u6765\u589e\u5f3a\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\uff08NLI\uff09\u4efb\u52a1\uff0c\u4f46\u5176\u5f71\u54cd\u56e0\u60c5\u51b5\u800c\u5f02\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\uff08NLI\uff09\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u6a21\u62df\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\u7684\u5e38\u8bc6\u77e5\u8bc6\u7684\u7cfb\u7edf\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5e38\u8bc6\u8d44\u6e90\u5728\u8986\u76d6\u5404\u79cd\u524d\u63d0-\u5047\u8bbe\u5bf9\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3aNLI\u7684\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u7684\u6f5c\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u751f\u6210\u6b64\u7c7b\u77e5\u8bc6\u7684\u53ef\u9760\u6027\u4ee5\u53ca\u8fd9\u4e9b\u77e5\u8bc6\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002\u6211\u4eec\u8c03\u6574\u5e76\u4fee\u6539\u4e86\u73b0\u6709\u6307\u6807\uff0c\u4ee5\u8bc4\u4f30LLM\u5728\u6b64\u80cc\u666f\u4e0b\u751f\u6210\u5e38\u8bc6\u77e5\u8bc6\u7684\u4e8b\u5b9e\u6027\u548c\u4e00\u81f4\u6027\u3002", "result": "\u867d\u7136\u663e\u5f0f\u5730\u7ed3\u5408\u5e38\u8bc6\u77e5\u8bc6\u5e76\u4e0d\u603b\u80fd\u63d0\u9ad8\u6574\u4f53\u7ed3\u679c\uff0c\u4f46\u5b83\u80fd\u6709\u6548\u5730\u5e2e\u52a9\u533a\u5206\u8574\u542b\u5173\u7cfb\u5b9e\u4f8b\uff0c\u5e76\u9002\u5ea6\u6539\u5584\u533a\u5206\u77db\u76fe\u548c\u4e2d\u7acb\u63a8\u65ad\u7684\u6548\u679c\u3002", "conclusion": "\u867d\u7136\u663e\u5f0f\u5730\u7ed3\u5408\u5e38\u8bc6\u77e5\u8bc6\u5e76\u4e0d\u603b\u80fd\u63d0\u9ad8\u6574\u4f53\u7ed3\u679c\uff0c\u4f46\u5b83\u80fd\u6709\u6548\u5730\u5e2e\u52a9\u533a\u5206\u8574\u542b\u5173\u7cfb\u5b9e\u4f8b\uff0c\u5e76\u9002\u5ea6\u6539\u5584\u533a\u5206\u77db\u76fe\u548c\u4e2d\u7acb\u63a8\u65ad\u7684\u6548\u679c\u3002"}}
{"id": "2507.14937", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14937", "abs": "https://arxiv.org/abs/2507.14937", "authors": ["Hugh L Kennedy"], "title": "Phase-optimised linearly-constrained minimum-variance beamformers", "comment": "Initial draft", "summary": "A novel procedure for the determination of the optimal group-delay for a\nLinearly-Constrained Minimum-Variance (LCMV) beamformer is proposed. Two ways\nof selecting the optimal delay are recommended: the first is the solution that\nminimizes the noise power; the second is the solution that minimizes the\nprocessing delay. The potential of this hitherto unexplored degree of design\nfreedom is explored using simulated Very-High-Frequency (VHF) communication,\nand Ultra-High-Frequency (UHF) bistatic radar, applications.", "AI": {"tldr": "A new way to find the best group-delay for beamformers is proposed, which can reduce noise or processing delay, and it works well in communication and radar simulations.", "motivation": "The motivation is to explore the potential of an unexplored degree of design freedom in LCMV beamformers by determining the optimal group-delay, which can lead to improved performance in applications like communication and radar systems.", "method": "The proposed method involves finding the optimal group-delay for an LCMV beamformer by considering two criteria: minimizing noise power and minimizing processing delay. The effectiveness of this approach is evaluated through simulations in VHF communication and UHF bistatic radar scenarios.", "result": "The paper demonstrates the potential of the proposed method using simulated VHF communication and UHF bistatic radar applications, showing improved performance through the optimization of group-delay.", "conclusion": "The paper proposes a novel procedure for determining the optimal group-delay for an LCMV beamformer, exploring two methods: minimizing noise power and minimizing processing delay. The potential of this approach is demonstrated using simulated VHF communication and UHF bistatic radar applications."}}
{"id": "2507.14850", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.14850", "abs": "https://arxiv.org/abs/2507.14850", "authors": ["H. M. Sabbir Ahmad", "Ehsan Sabouni", "Alexander Wasilkoff", "Param Budhraja", "Zijian Guo", "Songyuan Zhang", "Chuchu Fan", "Christos Cassandras", "Wenchao Li"], "title": "Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems", "comment": null, "summary": "We address the problem of safe policy learning in multi-agent safety-critical\nautonomous systems. In such systems, it is necessary for each agent to meet the\nsafety requirements at all times while also cooperating with other agents to\naccomplish the task. Toward this end, we propose a safe Hierarchical\nMulti-Agent Reinforcement Learning (HMARL) approach based on Control Barrier\nFunctions (CBFs). Our proposed hierarchical approach decomposes the overall\nreinforcement learning problem into two levels learning joint cooperative\nbehavior at the higher level and learning safe individual behavior at the lower\nor agent level conditioned on the high-level policy. Specifically, we propose a\nskill-based HMARL-CBF algorithm in which the higher level problem involves\nlearning a joint policy over the skills for all the agents and the lower-level\nproblem involves learning policies to execute the skills safely with CBFs. We\nvalidate our approach on challenging environment scenarios whereby a large\nnumber of agents have to safely navigate through conflicting road networks.\nCompared with existing state of the art methods, our approach significantly\nimproves the safety achieving near perfect (within 5%) success/safety rate\nwhile also improving performance across all the environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdHMARL-CBF\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u5b66\u4e60\u548cCBFs\u6765\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u5728\u5bfc\u822a\u51b2\u7a81\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5b89\u5168\u6027\u548c\u6027\u80fd\u7684\u63d0\u5347\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u5b89\u5168\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u786e\u4fdd\u6bcf\u4e2a\u667a\u80fd\u4f53\u59cb\u7ec8\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\uff0c\u5e76\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u534f\u4f5c\u4ee5\u5b8c\u6210\u4efb\u52a1\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08CBFs\uff09\u548c\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u3002\u5728\u9ad8\u5c42\uff0c\u5b66\u4e60\u6240\u6709\u667a\u80fd\u4f53\u7684\u8054\u5408\u6280\u80fd\u7b56\u7565\uff1b\u5728\u4f4e\u5c42\uff0c\u5b66\u4e60\u5b89\u5168\u6267\u884c\u6280\u80fd\u7684\u7b56\u7565\uff0c\u5e76\u4ee5CBFs\u4fdd\u8bc1\u5b89\u5168\u3002", "result": "\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u6210\u529f/\u5b89\u5168\u7387\u63a5\u8fd1\u5b8c\u7f8e\uff08\u57285%\u4ee5\u5185\uff09\uff0c\u5e76\u5728\u6240\u6709\u73af\u5883\u4e2d\u90fd\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08CBFs\uff09\u7684\u5b89\u5168\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08HMARL\uff09\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5b89\u5168\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5c06\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5c42\u6b21\uff1a\u9ad8\u5c42\u5b66\u4e60\u8054\u5408\u534f\u4f5c\u884c\u4e3a\uff0c\u4f4e\u5c42\u5b66\u4e60\u4e2a\u4f53\u5b89\u5168\u884c\u4e3a\u3002"}}
{"id": "2507.14798", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14798", "abs": "https://arxiv.org/abs/2507.14798", "authors": ["Xinyi Wu", "Steven Landgraf", "Markus Ulrich", "Rongjun Qin"], "title": "An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks", "comment": "23 pages, 6 figures, this manuscript has been submitted to\n  Geo-spatial Information Science for consideration", "summary": "State-of-the-art 3D computer vision algorithms continue to advance in\nhandling sparse, unordered image sets. Recently developed foundational models\nfor 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction\n(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry\nGrounded Transformer (VGGT), have attracted attention due to their ability to\nhandle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical\naerial images matters, as these models may handle extremely low image overlaps,\nstereo occlusions, and textureless regions. For redundant collections, they can\naccelerate 3D reconstruction by using extremely sparsified image sets. Despite\ntests on various computer vision benchmarks, their potential on photogrammetric\naerial blocks remains unexplored. This paper conducts a comprehensive\nevaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of\nthe UseGeo dataset for pose estimation and dense 3D reconstruction. Results\nshow these methods can accurately reconstruct dense point clouds from very\nsparse image sets (fewer than 10 images, up to 518 pixels resolution), with\ncompleteness gains up to +50% over COLMAP. VGGT also demonstrates higher\ncomputational efficiency, scalability, and more reliable camera pose\nestimation. However, all exhibit limitations with high-resolution images and\nlarge sets, as pose reliability declines with more images and geometric\ncomplexity. These findings suggest transformer-based methods cannot fully\nreplace traditional SfM and MVS, but offer promise as complementary approaches,\nespecially in challenging, low-resolution, and sparse scenarios.", "AI": {"tldr": "DUSt3R/MASt3R/VGGT \u7b49\u57fa\u4e8e Transformer \u7684 3D \u91cd\u5efa\u65b9\u6cd5\u5728\u7a00\u758f\u3001\u4f4e\u5206\u8fa8\u7387\u822a\u7a7a\u5f71\u50cf\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5e76\u975e\u4f20\u7edf SfM/MVS \u65b9\u6cd5\u7684\u5b8c\u5168\u66ff\u4ee3\u54c1\u3002", "motivation": "\u8bc4\u4f30 DUSt3R/MASt3R/VGGT \u7b49\u5148\u8fdb\u7684 3D \u91cd\u5efa\u57fa\u7840\u6a21\u578b\u5728\u822a\u7a7a\u5f71\u50cf\u96c6\u4e0a\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u7a00\u758f\u5f71\u50cf\u91cd\u53e0\u3001\u7acb\u4f53\u906e\u6321\u548c\u7eb9\u7406\u7f3a\u5931\u7b49\u6311\u6218\u6027\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5bf9\u9884\u8bad\u7ec3\u7684 DUSt3R/MASt3R/VGGT \u6a21\u578b\u5728 UseGeo \u6570\u636e\u96c6\u7684\u822a\u7a7a\u5f71\u50cf\u5757\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u7684\u8bc4\u4f30\uff0c\u91cd\u70b9\u5173\u6ce8\u4f4d\u59ff\u4f30\u8ba1\u548c\u5bc6\u96c6 3D \u91cd\u5efa\u3002", "result": "\u4e0e COLMAP \u76f8\u6bd4\uff0cDUSt3R/MASt3R/VGGT \u5728\u975e\u5e38\u7a00\u758f\u7684\u5f71\u50cf\u96c6\uff08\u5c11\u4e8e 10 \u5f20\u56fe\u50cf\uff0c\u5206\u8fa8\u7387\u9ad8\u8fbe 518 \u50cf\u7d20\uff09\u4e0a\u80fd\u591f\u51c6\u786e\u5730\u91cd\u5efa\u5bc6\u96c6\u70b9\u4e91\uff0c\u5b8c\u6574\u6027\u63d0\u9ad8\u9ad8\u8fbe 50%\u3002VGGT \u5728\u8ba1\u7b97\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u548c\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u7684\u53ef\u9760\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u7136\u800c\uff0c\u6240\u6709\u6a21\u578b\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u548c\u5927\u578b\u6570\u636e\u96c6\u4e0a\u9762\u4e34\u5c40\u9650\u6027\uff0c\u968f\u7740\u56fe\u50cf\u6570\u91cf\u7684\u589e\u52a0\u548c\u51e0\u4f55\u590d\u6742\u6027\u7684\u63d0\u9ad8\uff0c\u4f4d\u59ff\u7684\u53ef\u9760\u6027\u4f1a\u4e0b\u964d\u3002", "conclusion": " transformer-based \u65b9\u6cd5\uff08DUSt3R/MASt3R/VGGT\uff09\u5728\u4f4e\u5206\u8fa8\u7387\u3001\u7a00\u758f\u7684\u822a\u7a7a\u5f71\u50cf\u96c6\u4e0a\u8868\u73b0\u51fa\u6709\u524d\u666f\u7684\u6027\u80fd\uff0c\u4f46\u5728\u9ad8\u5206\u8fa8\u7387\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9762\u4e34\u6311\u6218\uff0c\u4e0d\u80fd\u5b8c\u5168\u53d6\u4ee3\u4f20\u7edf\u7684 SfM \u548c MVS \u65b9\u6cd5\uff0c\u53ef\u4f5c\u4e3a\u5176\u8865\u5145\u3002"}}
{"id": "2507.15618", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15618", "abs": "https://arxiv.org/abs/2507.15618", "authors": ["Weiyu Ma", "Jiwen Jiang", "Haobo Fu", "Haifeng Zhang"], "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II", "comment": null, "summary": "We present an adapter-based approach for tactical conditioning of StarCraft\nII AI agents. Current agents, while powerful, lack the ability to adapt their\nstrategies based on high-level tactical directives. Our method freezes a\npre-trained policy network (DI-Star) and attaches lightweight adapter modules\nto each action head, conditioned on a tactical tensor that encodes strategic\npreferences. By training these adapters with KL divergence constraints, we\nensure the policy maintains core competencies while exhibiting tactical\nvariations. Experimental results show our approach successfully modulates agent\nbehavior across tactical dimensions including aggression, expansion patterns,\nand technology preferences, while maintaining competitive performance. Our\nmethod enables flexible tactical control with minimal computational overhead,\noffering practical strategy customization for complex real-time strategy games.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u661f\u9645\u4e89\u9738II AI\u667a\u80fd\u4f53\u7684\u6218\u672f\u6761\u4ef6\u5316\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6765\u8c03\u6574\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u4f7f\u5176\u80fd\u591f\u6839\u636e\u6218\u672f\u6307\u4ee4\u6539\u53d8\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u6838\u5fc3\u80fd\u529b\u548c\u7ade\u4e89\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u7075\u6d3b\u5730\u8fdb\u884c\u6218\u672f\u63a7\u5236\uff0c\u8ba1\u7b97\u5f00\u9500\u5c0f\uff0c\u5e76\u4e3a\u590d\u6742\u7684\u5b9e\u65f6\u7b56\u7565\u6e38\u620f\u63d0\u4f9b\u5b9e\u7528\u7684\u7b56\u7565\u5b9a\u5236\u3002", "motivation": "\u5f53\u524d\u7684\u661f\u9645\u4e89\u9738II AI\u667a\u80fd\u4f53\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u7f3a\u4e4f\u6839\u636e\u9ad8\u7ea7\u6218\u672f\u6307\u4ee4\u8c03\u6574\u5176\u7b56\u7565\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u51bb\u7ed3\u9884\u8bad\u7ec3\u7b56\u7565\u7f51\u7edc\uff08DI-Star\uff09\u5e76\u4e3a\u6bcf\u4e2a\u52a8\u4f5c\u5934\u9644\u52a0\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u4ee5\u7f16\u7801\u7b56\u7565\u504f\u597d\u7684\u6218\u672f\u5f20\u91cf\u4e3a\u6761\u4ef6\u3002\u901a\u8fc7\u4f7f\u7528KL\u6563\u5ea6\u7ea6\u675f\u6765\u8bad\u7ec3\u8fd9\u4e9b\u9002\u914d\u5668\uff0c\u53ef\u4ee5\u786e\u4fdd\u7b56\u7565\u5728\u5c55\u73b0\u6218\u672f\u53d8\u5316\u7684\u540c\u65f6\u4fdd\u6301\u6838\u5fc3\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6210\u529f\u5730\u8c03\u6574\u667a\u80fd\u4f53\u884c\u4e3a\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u6218\u672f\u7ef4\u5ea6\uff08\u5305\u62ec\u4fb5\u7565\u6027\u3001\u6269\u5f20\u6a21\u5f0f\u548c\u6280\u672f\u504f\u597d\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6210\u529f\u5730\u8c03\u6574\u667a\u80fd\u4f53\u884c\u4e3a\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u6218\u672f\u7ef4\u5ea6\uff08\u5305\u62ec\u4fb5\u7565\u6027\u3001\u6269\u5f20\u6a21\u5f0f\u548c\u6280\u672f\u504f\u597d\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\u3002"}}
{"id": "2507.14740", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14740", "abs": "https://arxiv.org/abs/2507.14740", "authors": ["Andrew Wang", "Elisa Nguyen", "Runshi Yang", "Juhan Bae", "Sheila A. McIlraith", "Roger Grosse"], "title": "Better Training Data Attribution via Better Inverse Hessian-Vector Products", "comment": "28 pages, 4 figures", "summary": "Training data attribution (TDA) provides insights into which training data is\nresponsible for a learned model behavior. Gradient-based TDA methods such as\ninfluence functions and unrolled differentiation both involve a computation\nthat resembles an inverse Hessian-vector product (iHVP), which is difficult to\napproximate efficiently. We introduce an algorithm (ASTRA) which uses the\nEKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP\napproximation for TDA. ASTRA is easy to tune, requires fewer iterations than\nNeumann series iterations, and is more accurate than EKFAC-based\napproximations. Using ASTRA, we show that improving the accuracy of the iHVP\napproximation can significantly improve TDA performance.", "AI": {"tldr": "ASTRA \u662f\u4e00\u79cd\u65b0\u7684 TDA \u7b97\u6cd5\uff0c\u5b83\u4f7f\u7528 EKFAC-preconditioner \u548c Neumann \u7ea7\u6570\u8fed\u4ee3\u6765\u51c6\u786e\u8fd1\u4f3c iHVP\uff0c\u4ece\u800c\u63d0\u9ad8 TDA \u6027\u80fd\u3002", "motivation": "\u68af\u5ea6\u4e0b\u964d TDA \u65b9\u6cd5\uff08\u5982\u5f71\u54cd\u51fd\u6570\u548c\u5c55\u5f00\u5fae\u5206\uff09\u6d89\u53ca\u7c7b\u4f3c iHVP \u7684\u8ba1\u7b97\uff0c\u800c iHVP \u96be\u4ee5\u6709\u6548\u8fd1\u4f3c\u3002", "method": "ASTRA \u7b97\u6cd5\u4f7f\u7528 EKFAC-preconditioner \u548c Neumann \u7ea7\u6570\u8fed\u4ee3\u6765\u8fd1\u4f3c\u9006 Hessian-vector product (iHVP)\uff0c\u7528\u4e8e\u8bad\u7ec3\u6570\u636e\u5f52\u56e0 (TDA)\u3002", "result": "ASTRA \u7b97\u6cd5\u80fd\u591f\u51c6\u786e\u5730\u8fd1\u4f3c iHVP\uff0c\u5e76\u4e14\u5728 TDA \u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "ASTRA \u7b97\u6cd5\u901a\u8fc7\u5728 Neumann \u7ea7\u6570\u8fed\u4ee3\u4e2d\u4f7f\u7528 EKFAC-preconditioner \u6765\u5b9e\u73b0\u5bf9 TDA \u7684 iHVP \u8fd1\u4f3c\uff0c\u8be5\u65b9\u6cd5\u6613\u4e8e\u8c03\u6574\uff0c\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u5c11\u4e8e Neumann \u7ea7\u6570\u8fed\u4ee3\uff0c\u5e76\u4e14\u6bd4\u57fa\u4e8e EKFAC \u7684\u8fd1\u4f3c\u66f4\u51c6\u786e\u3002"}}
{"id": "2507.15508", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15508", "abs": "https://arxiv.org/abs/2507.15508", "authors": ["D. I. Salykina", "V. S. Liamin", "P. R. Sharapova", "F. Ya. Khalili"], "title": "Quantum non-demolition measurement of optical quadratures using quadratic nonlinearity", "comment": "8 pages, 4 figures", "summary": "Quantum non-demolition (QND) measurement is a special technique that allows\nto evade quantum back-action. In this paper, we propose a new QND measurement\nscheme of the optical field quadratures based on the non-degenerate optical\nparametric amplifier. We show that for a proper set of parameters, this scheme\ncan realize a new type of QND measurement, where the quadrature of interest is\namplified but still does not subject to any back action.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5149\u5b66\u573a \u092f\u093e\u091a\u0947\u7684QND\u6d4b\u91cf\u65b9\u6848\uff0c\u5229\u7528\u975e\u7b80\u5e76\u5149\u5b66\u53c2\u91cf\u653e\u5927\u5668\uff0c\u5b9e\u73b0\u4e86\u6d4b\u91cf\u4e4b \u092f\u093e\u091a\u0947\u7684 \u092f\u093e\u091a\u0947\u88ab\u653e\u5927\u7684\u540c\u65f6\u4e0d\u53d7\u53cd\u4f5c\u7528\u529b\u5f71\u54cd\u3002", "motivation": "\u91cf\u5b50\u65e0\u7834\u574f\uff08QND\uff09\u6d4b\u91cf\u662f\u4e00\u79cd\u80fd\u591f\u907f\u514d\u91cf\u5b50\u53cd\u4f5c\u7528\u529b\u7684\u7279\u6b8a\u6280\u672f\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684QND\u6d4b\u91cf\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u7b80\u5e76\u5149\u5b66\u53c2\u91cf\u653e\u5927\u5668\uff08non-degenerate optical parametric amplifier\uff09\u7684\u65b0\u578b\u91cf\u5b50\u65e0\u7834\u574f\uff08Quantum Non-demolition, QND\uff09\u6d4b\u91cf\u65b9\u6848\uff0c\u7528\u4e8e\u6d4b\u91cf\u5149\u5b66\u573a\u7684 \u092f\u093e\u091a\u0947\u3002", "result": "\u8be5\u65b9\u6848\u5728\u7279\u5b9a\u53c2\u6570\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5149\u5b66\u573a \u092f\u093e\u091a\u0947\u7684QND\u6d4b\u91cf\uff0c\u5176\u7279\u70b9\u662f\u88ab\u6d4b\u91cf\u4e4b \u092f\u093e\u091a\u0947\u7684 \u092f\u093e\u091a\u0947\u88ab\u653e\u5927\u7684\u540c\u65f6\uff0c\u4ecd\u7136\u4e0d\u53d7\u4efb\u4f55\u53cd\u4f5c\u7528\u529b\u7684\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u975e\u7b80\u5e76\u5149\u5b66\u53c2\u91cf\u653e\u5927\u5668\u7684\u5149\u5b66\u573a \u092f\u093e\u091a\u0947\u7684QND\u6d4b\u91cf\u65b9\u6848\uff0c\u5728\u5408\u9002\u7684\u53c2\u6570\u4e0b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u4e00\u79cd\u65b0\u7684QND\u6d4b\u91cf\u7c7b\u578b\uff0c\u5373\u88ab\u6d4b\u91cf\u4e4b \u092f\u093e\u091a\u0947\u7684 \u092f\u093e\u091a\u0947\u88ab\u653e\u5927\u7684\u540c\u65f6\uff0c\u4ecd\u7136\u4e0d\u53d7\u4efb\u4f55\u53cd\u4f5c\u7528\u529b\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.15114", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15114", "abs": "https://arxiv.org/abs/2507.15114", "authors": ["Chathuri Jayaweera", "Bonnie Dorr"], "title": "From Disagreement to Understanding: The Case for Ambiguity Detection in NLI", "comment": "8 pages, 6 figures", "summary": "This position paper argues that annotation disagreement in Natural Language\nInference (NLI) is not mere noise but often reflects meaningful interpretive\nvariation, especially when triggered by ambiguity in the premise or hypothesis.\nWhile underspecified guidelines and annotator behavior can contribute to\nvariation, content-based ambiguity offers a process-independent signal of\ndivergent human perspectives. We call for a shift toward ambiguity-aware NLI by\nsystematically identifying ambiguous input pairs and classifying ambiguity\ntypes. To support this, we present a unified framework that integrates existing\ntaxonomies and illustrate key ambiguity subtypes through concrete examples.\nThese examples reveal how ambiguity shapes annotator decisions and motivate the\nneed for targeted detection methods that better align models with human\ninterpretation. A key limitation is the lack of datasets annotated for\nambiguity and subtypes. We propose addressing this gap through new annotated\nresources and unsupervised approaches to ambiguity detection -- paving the way\nfor more robust, explainable, and human-aligned NLI systems.", "AI": {"tldr": "\u8fd9\u9879\u5de5\u4f5c\u8ba4\u4e3a\uff0c\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u4e2d\u7684\u6ce8\u91ca\u5206\u6b67\u53cd\u6620\u4e86\u6709\u610f\u4e49\u7684\u89e3\u91ca\u5dee\u5f02\uff0c\u5c24\u5176\u662f\u5728\u7531\u524d\u63d0\u6216\u5047\u8bbe\u4e2d\u7684\u6b67\u4e49\u89e6\u53d1\u65f6\u3002\u5b83\u547c\u5401\u901a\u8fc7\u7cfb\u7edf\u5730\u8bc6\u522b\u6b67\u4e49\u8f93\u5165\u5bf9\u548c\u5206\u7c7b\u6b67\u4e49\u7c7b\u578b\u6765\u8f6c\u5411\u6b67\u4e49\u611f\u77e5\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u3002", "motivation": "\u4e89\u8fa9\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u4e2d\u7684\u6ce8\u91ca\u5206\u6b67\u4e0d\u4ec5\u4ec5\u662f\u566a\u97f3\uff0c\u5b83\u901a\u5e38\u53cd\u6620\u4e86\u6709\u610f\u4e49\u7684\u89e3\u91ca\u5dee\u5f02\uff0c\u8fd9\u4fc3\u4f7f\u4eba\u4eec\u9700\u8981\u6709\u9488\u5bf9\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u6a21\u578b\u4e0e\u4eba\u7c7b\u7684\u89e3\u91ca\u66f4\u597d\u5730\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u6574\u5408\u73b0\u6709\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u793a\u4f8b\u8bf4\u660e\u5173\u952e\u7684\u6b67\u4e49\u5b50\u7c7b\u578b\uff0c\u4ee5\u8bc6\u522b\u6a21\u7cca\u7684\u8f93\u5165\u5bf9\u5e76\u5bf9\u6b67\u4e49\u7c7b\u578b\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5c55\u793a\u4e86\u6b67\u4e49\u5982\u4f55\u5f71\u54cd\u6ce8\u91ca\u8005\u7684\u51b3\u7b56\uff0c\u5e76\u5f3a\u8c03\u4e86\u5bf9\u66f4\u597d\u7684\u4eba\u7c7b\u5bf9\u9f50\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u7cfb\u7edf\u7684\u9700\u6c42\u3002", "conclusion": "\u9700\u8981\u65b0\u7684\u5e26\u6709\u5173\u6ce8\u610f\u529b\u548c\u5b50\u7c7b\u578b\u6ce8\u91ca\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u7528\u4e8e\u6ce8\u610f\u68c0\u6d4b\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u4ee5\u6784\u5efa\u66f4\u5065\u58ee\u3001\u53ef\u89e3\u91ca\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u7cfb\u7edf\u3002"}}
{"id": "2507.14945", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14945", "abs": "https://arxiv.org/abs/2507.14945", "authors": ["Bin Wang", "Jun Fang", "Jieru Du", "Shihai Shao"], "title": "Jamming-Resistant AAV Communications: A Multichannel-Aided Approach", "comment": null, "summary": "Jamming cancellation is essential to reliable unmanned autonomous vehicle\n(AAV) communications in the presence of malicious jammers. In this paper, we\ndevelop a practical multichannel-aided jamming cancellation method to realize\nsecure AAV communications. The proposed method is capable of simultaneously\nachieving timing/frequency synchronization as well as jamming cancellation.\nMore importantly, our method does not need the signal's/jammer's channel state\ninformation. It only utilizes the knowledge of the legitimate sender's preamble\nsequence that is available in existing communication protocols. We also analyze\nthe length of the preamble sequence required for successful synchronization and\nsignal recovery. Experimental results on the built hardware platform show that,\nwith a two-antenna receiver, the proposed method can successfully decode the\nsignal of interest even when the jamming signal is $40$dB stronger than the\ncommunication signal.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u3001\u4ec5\u5229\u7528\u524d\u5bfc\u7801\u5e8f\u5217\u7684\u591a\u901a\u9053\u8f85\u52a9\u5e72\u6270\u6d88\u9664\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8eAAV\u901a\u4fe1\uff0c\u5e76\u6210\u529f\u5728\u786c\u4ef6\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5728\u5f3a\u5e72\u6270\u4e0b\u7684\u4fe1\u53f7\u89e3\u7801\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u5728\u5b58\u5728\u6076\u610f\u5e72\u6270\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u53ef\u9760\u7684\u65e0\u4eba\u81ea\u4e3b\u98de\u884c\u5668\uff08AAV\uff09\u901a\u4fe1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u591a\u4e2a\u4fe1\u9053\u8f85\u52a9\u7684\u5e72\u6270\u6d88\u9664\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u53cc\u5929\u7ebf\u63a5\u6536\u5668\uff0c\u5373\u4f7f\u5728\u5e72\u6270\u4fe1\u53f7\u6bd4\u901a\u4fe1\u4fe1\u53f7\u5f3a40dB\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e5f\u80fd\u6210\u529f\u89e3\u7801\u76ee\u6807\u4fe1\u53f7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5b58\u5728\u6076\u610f\u5e72\u6270\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5b89\u5168\u7684AAV\u901a\u4fe1\uff0c\u5e76\u4e14\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u65f6/\u9891\u540c\u6b65\u548c\u5e72\u6270\u6d88\u9664\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u5e76\u4e14\u53ea\u9700\u8981\u5408\u6cd5\u7684\u53d1\u9001\u7aef\u524d\u5bfc\u7801\u5e8f\u5217\uff0c\u5df2\u5728\u901a\u4fe1\u534f\u8bae\u4e2d\u63d0\u4f9b\u3002"}}
{"id": "2507.15036", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15036", "abs": "https://arxiv.org/abs/2507.15036", "authors": ["Lyes Saad Saoud", "Irfan Hussain"], "title": "EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring", "comment": null, "summary": "Underwater image enhancement is vital for marine conservation, particularly\ncoral reef monitoring. However, AI-based enhancement models often face dataset\nbias, high computational costs, and lack of transparency, leading to potential\nmisinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware\nAI framework to address these challenges. EBA-AI leverages CLIP embeddings to\ndetect and mitigate dataset bias, ensuring balanced representation across\nvaried underwater environments. It also integrates adaptive processing to\noptimize energy efficiency, significantly reducing GPU usage while maintaining\ncompetitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100\nshow that while PSNR drops by a controlled 1.0 dB, computational savings enable\nreal-time feasibility for large-scale marine monitoring. Additionally,\nuncertainty estimation and explainability techniques enhance trust in AI-driven\nenvironmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,\nWaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing\nefficiency, fairness, and interpretability in underwater image processing. By\naddressing key limitations of AI-driven enhancement, this work contributes to\nsustainable, bias-aware, and computationally efficient marine conservation\nefforts. For interactive visualizations, animations, source code, and access to\nthe preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/", "AI": {"tldr": "EBA-AI\u662f\u4e00\u4e2aAI\u6846\u67b6\uff0c\u7528\u4e8e\u6c34\u4e0b\u56fe\u50cf\u589e\u5f3a\uff0c\u5b83\u89e3\u51b3\u4e86\u6570\u636e\u96c6\u504f\u5dee\u3001\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u7f3a\u4e4f\u900f\u660e\u5ea6\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u6548\u7387\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u5e73\u8861\u3002", "motivation": "\u6c34\u4e0b\u56fe\u50cf\u589e\u5f3a\u5bf9\u4e8e\u6d77\u6d0b\u4fdd\u62a4\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u73ca\u745a\u7901\u76d1\u6d4b\u65b9\u9762\u3002\u7136\u800c\uff0c\u76ee\u524d\u57fa\u4e8eAI\u7684\u589e\u5f3a\u6a21\u578b\u5e38\u5e38\u9762\u4e34\u6570\u636e\u96c6\u504f\u5dee\u3001\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u7f3a\u4e4f\u900f\u660e\u5ea6\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7684\u89e3\u8bfb\u3002", "method": "EBA-AI\u6846\u67b6\u5229\u7528CLIP\u5d4c\u5165\u6765\u68c0\u6d4b\u548c\u51cf\u8f7b\u6570\u636e\u96c6\u504f\u5dee\uff0c\u786e\u4fdd\u8de8\u4e0d\u540c\u6c34\u4e0b\u73af\u5883\u7684\u5747\u8861\u8868\u793a\u3002\u5b83\u8fd8\u96c6\u6210\u4e86\u81ea\u9002\u5e94\u5904\u7406\u4ee5\u4f18\u5316\u80fd\u6e90\u6548\u7387\uff0c\u663e\u8457\u964d\u4f4eGPU\u4f7f\u7528\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5177\u6709\u7ade\u4e89\u529b\u7684\u589e\u5f3a\u8d28\u91cf\u3002", "result": "\u5728LSUI400\u3001Oceanex\u548cUIEB100\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u867d\u7136PSNR\u4e0b\u964d\u4e861.0 dB\uff0c\u4f46\u8ba1\u7b97\u8282\u7701\u4f7f\u5f97\u5927\u89c4\u6a21\u6d77\u6d0b\u76d1\u6d4b\u7684\u5b9e\u65f6\u53ef\u884c\u6027\u6210\u4e3a\u53ef\u80fd\u3002\u6b64\u5916\uff0c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u53ef\u89e3\u91ca\u6027\u6280\u672f\u589e\u5f3a\u4e86\u5bf9AI\u9a71\u52a8\u7684\u73af\u5883\u51b3\u7b56\u7684\u4fe1\u4efb\u3002\u4e0eCycleGAN\u3001FunIEGAN\u3001RAUNENet\u3001WaterNet\u3001UGAN\u3001PUGAN\u548cUTUIE\u7684\u6bd4\u8f83\u9a8c\u8bc1\u4e86EBA-AI\u5728\u5e73\u8861\u6c34\u4e0b\u56fe\u50cf\u5904\u7406\u4e2d\u7684\u6548\u7387\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "EBA-AI\u6846\u67b6\u901a\u8fc7\u5229\u7528CLIP\u5d4c\u5165\u6765\u68c0\u6d4b\u548c\u51cf\u8f7b\u6570\u636e\u96c6\u504f\u5dee\uff0c\u5e76\u96c6\u6210\u81ea\u9002\u5e94\u5904\u7406\u4ee5\u4f18\u5316\u80fd\u6e90\u6548\u7387\uff0c\u663e\u8457\u964d\u4f4eGPU\u4f7f\u7528\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5177\u6709\u7ade\u4e89\u529b\u7684\u589e\u5f3a\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86AI\u9a71\u52a8\u7684\u589e\u5f3a\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u6570\u636e\u96c6\u504f\u5dee\u3001\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u7f3a\u4e4f\u900f\u660e\u5ea6\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u867d\u7136PSNR\u4f1a\u53d7\u52301.0 dB\u7684\u63a7\u5236\u6027\u4e0b\u964d\uff0c\u4f46\u8ba1\u7b97\u8282\u7701\u4f7f\u5f97\u5927\u89c4\u6a21\u6d77\u6d0b\u76d1\u6d4b\u7684\u5b9e\u65f6\u53ef\u884c\u6027\u6210\u4e3a\u53ef\u80fd\u3002\u6b64\u5916\uff0c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u53ef\u89e3\u91ca\u6027\u6280\u672f\u589e\u5f3a\u4e86\u5bf9AI\u9a71\u52a8\u7684\u73af\u5883\u51b3\u7b56\u7684\u4fe1\u4efb\u3002"}}
{"id": "2507.14801", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14801", "abs": "https://arxiv.org/abs/2507.14801", "authors": ["Xiangyu Chen", "Kaiwen Zhu", "Yuandong Pu", "Shuo Cao", "Xiaohui Li", "Wenlong Zhang", "Yihao Liu", "Yu Qiao", "Jiantao Zhou", "Chao Dong"], "title": "Exploring Scalable Unified Modeling for General Low-Level Vision", "comment": null, "summary": "Low-level vision involves a wide spectrum of tasks, including image\nrestoration, enhancement, stylization, and feature extraction, which differ\nsignificantly in both task formulation and output domains. To address the\nchallenge of unified modeling across such diverse tasks, we propose a Visual\ntask Prompt-based Image Processing (VPIP) framework that leverages input-target\nimage pairs as visual prompts to guide the model in performing a variety of\nlow-level vision tasks. The framework comprises an end-to-end image processing\nbackbone, a prompt encoder, and a prompt interaction module, enabling flexible\nintegration with various architectures and effective utilization of\ntask-specific visual representations. Based on this design, we develop a\nunified low-level vision model, GenLV, and evaluate its performance across\nmultiple representative tasks. To explore the scalability of this approach, we\nextend the framework along two dimensions: model capacity and task diversity.\nWe construct a large-scale benchmark consisting of over 100 low-level vision\ntasks and train multiple versions of the model with varying scales.\nExperimental results show that the proposed method achieves considerable\nperformance across a wide range of tasks. Notably, increasing the number of\ntraining tasks enhances generalization, particularly for tasks with limited\ndata, indicating the model's ability to learn transferable representations\nthrough joint training. Further evaluations in zero-shot generalization,\nfew-shot transfer, and task-specific fine-tuning scenarios demonstrate the\nmodel's strong adaptability, confirming the effectiveness, scalability, and\npotential of the proposed framework as a unified foundation for general\nlow-level vision modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684VPIP\u6846\u67b6\u548cGenLV\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u7edf\u4e00\u7684\u4f4e\u7ea7\u89c6\u89c9\u4efb\u52a1\u5904\u7406\uff0c\u5e76\u5728\u591a\u4efb\u52a1\u3001\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u679c\u3002", "motivation": "\u4f4e\u7ea7\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u56fe\u50cf\u6062\u590d\u3001\u589e\u5f3a\u3001\u98ce\u683c\u5316\u548c\u7279\u5f81\u63d0\u53d6\uff09\u5728\u4efb\u52a1\u5f62\u5f0f\u548c\u8f93\u51fa\u57df\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e3a\u5b9e\u73b0\u8de8\u8fd9\u4e9b\u591a\u6837\u5316\u4efb\u52a1\u7684\u7edf\u4e00\u5efa\u6a21\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u89c6\u89c9\u4efb\u52a1\u63d0\u793a\u56fe\u50cf\u5904\u7406\uff08VPIP\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u8f93\u5165-\u76ee\u6807\u56fe\u50cf\u5bf9\u4f5c\u4e3a\u89c6\u89c9\u63d0\u793a\u6765\u5f15\u5bfc\u6a21\u578b\u6267\u884c\u5404\u79cd\u4f4e\u7ea7\u89c6\u89c9\u4efb\u52a1\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u56fe\u50cf\u5904\u7406\u9aa8\u5e72\u7f51\u7edc\u3001\u4e00\u4e2a\u63d0\u793a\u7f16\u7801\u5668\u548c\u4e00\u4e2a\u63d0\u793a\u4ea4\u4e92\u6a21\u5757\u3002\u57fa\u4e8e\u6b64\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4f4e\u7ea7\u89c6\u89c9\u6a21\u578bGenLV\uff0c\u5e76\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u901a\u8fc7\u6269\u5c55\u6a21\u578b\u5bb9\u91cf\u548c\u4efb\u52a1\u591a\u6837\u6027\uff0c\u5e76\u5728\u5305\u542b100\u591a\u4e2a\u4f4e\u7ea7\u89c6\u89c9\u4efb\u52a1\u7684\u5927\u578b\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6269\u5c55\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5e7f\u6cdb\u7684\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u76f8\u5f53\u53ef\u89c2\u7684\u6027\u80fd\u3002\u7279\u522b\u662f\uff0c\u589e\u52a0\u8bad\u7ec3\u4efb\u52a1\u7684\u6570\u91cf\u53ef\u4ee5\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u4e8e\u6570\u636e\u6709\u9650\u7684\u4efb\u52a1\u5c24\u5176\u5982\u6b64\u3002\u8be5\u6a21\u578b\u5728\u96f6\u6837\u672c\u6cdb\u5316\u3001\u5c11\u6837\u672c\u8fc1\u79fb\u548c\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u573a\u666f\u4e2d\u7684\u8868\u73b0\u4e5f\u8bc1\u5b9e\u4e86\u5176\u5f3a\u5927\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u89c6\u89c9\u4efb\u52a1\u63d0\u793a\u56fe\u50cf\u5904\u7406\uff08VPIP\uff09\u6846\u67b6\u53ca\u5176\u7edf\u4e00\u6a21\u578bGenLV\u5728\u591a\u79cd\u4f4e\u7ea7\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u901a\u7528\u4f4e\u7ea7\u89c6\u89c9\u5efa\u6a21\u7684\u6709\u6548\u57fa\u7840\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14744", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14744", "abs": "https://arxiv.org/abs/2507.14744", "authors": ["Mustafa Cavus", "Jan N. van Rijn", "Przemys\u0142aw Biecek"], "title": "Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML", "comment": "Accepted at 28th International Conference on Discovery Science 2025", "summary": "Automated machine learning systems efficiently streamline model selection but\noften focus on a single best-performing model, overlooking explanation\nuncertainty, an essential concern in human centered explainable AI. To address\nthis, we propose a novel framework that incorporates model multiplicity into\nexplanation generation by aggregating partial dependence profiles (PDP) from a\nset of near optimal models, known as the Rashomon set. The resulting Rashomon\nPDP captures interpretive variability and highlights areas of disagreement,\nproviding users with a richer, uncertainty aware view of feature effects. To\nevaluate its usefulness, we introduce two quantitative metrics, the coverage\nrate and the mean width of confidence intervals, to evaluate the consistency\nbetween the standard PDP and the proposed Rashomon PDP. Experiments on 35\nregression datasets from the OpenML CTR23 benchmark suite show that in most\ncases, the Rashomon PDP covers less than 70% of the best model's PDP,\nunderscoring the limitations of single model explanations. Our findings suggest\nthat Rashomon PDP improves the reliability and trustworthiness of model\ninterpretations by adding additional information that would otherwise be\nneglected. This is particularly useful in high stakes domains where\ntransparency and confidence are critical.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u4e2d\u5355\u4e00\u6a21\u578b\u89e3\u91ca\u5ffd\u7565\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Rashomon PDP \u7684\u65b0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u805a\u5408\u8fd1\u4e4e\u6700\u4f18\u6a21\u578b\u7684\u89e3\u91ca\u6765\u63d0\u4f9b\u66f4\u53ef\u9760\u3001\u66f4\u5177\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7684\u7279\u5f81\u6548\u5e94\u89c6\u56fe\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u867d\u7136\u80fd\u6709\u6548\u7b80\u5316\u6a21\u578b\u9009\u62e9\uff0c\u4f46\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u4e00\u6027\u80fd\u6700\u4f73\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u8fd9\u662f\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u8fd1\u4e4e\u6700\u4f18\u6a21\u578b\u7684\u504f\u4f9d\u8d56\u56fe\uff08PDP\uff09\u6765\u5c06\u6a21\u578b\u591a\u91cd\u6027\u7eb3\u5165\u89e3\u91ca\u751f\u6210\uff0c\u8fd9\u4e9b\u8fd1\u4e4e\u6700\u4f18\u6a21\u578b\u88ab\u79f0\u4e3a Rashomon \u96c6\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u8986\u76d6\u7387\u548c\u7f6e\u4fe1\u533a\u95f4\u5e73\u5747\u5bbd\u5ea6\u4e24\u4e2a\u5b9a\u91cf\u6307\u6807\u6765\u8bc4\u4f30 Rashomon PDP \u4e0e\u6807\u51c6 PDP \u7684\u4e00\u81f4\u6027\u3002\u5728 OpenML CTR23 \u57fa\u51c6\u5957\u4ef6\u7684 35 \u4e2a\u56de\u5f52\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRashomon PDP \u8986\u76d6\u4e86\u4e0d\u5230 70% \u7684\u6700\u4f73\u6a21\u578b PDP\uff0c\u8fd9\u51f8\u663e\u4e86\u5355\u4e00\u6a21\u578b\u89e3\u91ca\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684 Rashomon \u90e8\u5206\u4f9d\u8d56\u56fe\uff08Rashomon PDP\uff09\u901a\u8fc7\u805a\u5408\u8fd1\u4e4e\u6700\u4f18\u6a21\u578b\uff08Rashomon set\uff09\u7684\u90e8\u5206\u4f9d\u8d56\u56fe\uff08PDP\uff09\uff0c\u5c06\u6a21\u578b\u591a\u91cd\u6027\u7eb3\u5165\u89e3\u91ca\u751f\u6210\uff0c\u6355\u83b7\u4e86\u89e3\u91ca\u53d8\u5f02\u6027\u5e76\u5f3a\u8c03\u4e86\u5206\u6b67\u70b9\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u3001\u66f4\u5177\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7684\u7279\u5f81\u6548\u5e94\u89c6\u56fe\u3002\u5b9e\u9a8c\u8868\u660e\uff0cRashomon PDP \u8986\u76d6\u4e86\u4e0d\u5230 70% \u7684\u6700\u4f73\u6a21\u578b PDP\uff0c\u5f3a\u8c03\u4e86\u5355\u4e00\u6a21\u578b\u89e3\u91ca\u7684\u5c40\u9650\u6027\u3002Rashomon PDP \u901a\u8fc7\u6dfb\u52a0\u901a\u5e38\u4f1a\u88ab\u5ffd\u7565\u7684\u989d\u5916\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5c24\u4e3a\u6709\u7528\u3002"}}
{"id": "2507.15537", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15537", "abs": "https://arxiv.org/abs/2507.15537", "authors": ["Christoph S\u00fcnderhauf", "Zal\u00e1n N\u00e9meth", "Adnaan Walayat", "Andrew Patterson", "Bjorn K. Berntson"], "title": "Matrix inversion polynomials for the quantum singular value transformation", "comment": null, "summary": "Quantum matrix inversion with the quantum singular value transformation\n(QSVT) requires a polynomial approximation to $1/x$. Several methods from the\nliterature construct polynomials that achieve the known degree complexity\n$\\mathcal{O}(\\kappa\\log(\\kappa/\\varepsilon))$ with condition number $\\kappa$\nand uniform error $\\varepsilon$. However, the \\emph{optimal} polynomial with\nlowest degree for fixed error $\\varepsilon$ can only be approximated\nnumerically with the resource-intensive Remez method, leading to impractical\npreprocessing runtimes. Here, we derive an analytic shortcut to the optimal\npolynomial. Comparisons with other polynomials from the literature, based on\nTaylor expansion, Chebyshev iteration, and convex optimization, confirm that\nour result is optimal. Furthermore, for large $\\kappa\\log(\\kappa/\\varepsilon)$,\nour polynomial has the smallest maximum value on $[-1,1]$ of all approaches\nconsidered, leading to reduced circuit depth due to the normalization condition\nof QSVT. With the Python code provided, this paper will also be useful for\npractitioners in the field.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u91cf\u5b50\u77e9\u9635\u6c42\u9006\u7684\u89e3\u6790\u65b9\u6cd5\uff0c\u4ee5\u83b7\u5f97\u6700\u4f18\u591a\u9879\u5f0f\u903c\u8fd1\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u548c\u7535\u8def\u6df1\u5ea6\u3002", "motivation": "\u91cf\u5b50\u5947\u5f02\u503c\u53d8\u6362\uff08QSVT\uff09\u9700\u8981\u5bf9 1/x \u7684\u591a\u9879\u5f0f\u903c\u8fd1\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8d44\u6e90\u5bc6\u96c6\u578b\u7684 Remez \u65b9\u6cd5\u6765\u8fd1\u4f3c\u6700\u4f18\u591a\u9879\u5f0f\u3002", "method": "\u63a8\u5bfc\u4e86\u6700\u4f18\u591a\u9879\u5f0f\u7684\u89e3\u6790\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u591a\u9879\u5f0f\u88ab\u8bc1\u660e\u662f\u6700\u4f18\u7684\uff0c\u5e76\u4e14\u5728 [-1,1] \u533a\u95f4\u4e0a\u7684\u6700\u5927\u503c\u6700\u5c0f\uff0c\u4ece\u800c\u51cf\u5c11\u4e86 QSVT \u7684\u7535\u8def\u6df1\u5ea6\u3002", "conclusion": "\u6587\u4e2d\u63d0\u4f9b\u7684 Python \u4ee3\u7801\u53ef\u4f9b\u8be5\u9886\u57df\u7684\u4ece\u4e1a\u8005\u4f7f\u7528\u3002"}}
{"id": "2507.15142", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15142", "abs": "https://arxiv.org/abs/2507.15142", "authors": ["Hellina Hailu Nigatu", "Atnafu Lambebo Tonja", "Henok Biadglign Ademtew", "Hizkel Mitiku Alemayehu", "Negasi Haile Abadi", "Tadesse Destaw Belay", "Seid Muhie Yimam"], "title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", "comment": "Paper under review", "summary": "Homophone normalization, where characters that have the same sound in a\nwriting script are mapped to one character, is a pre-processing step applied in\nAmharic Natural Language Processing (NLP) literature. While this may improve\nperformance reported by automatic metrics, it also results in models that are\nnot able to understand different forms of writing in a single language.\nFurther, there might be impacts in transfer learning, where models trained on\nnormalized data do not generalize well to other languages. In this paper, we\nexperiment with monolingual training and cross-lingual transfer to understand\nthe impacts of normalization on languages that use the Ge'ez script. We then\npropose a post-inference intervention in which normalization is applied to\nmodel predictions instead of training data. With our simple scheme of\npost-inference normalization, we show that we can achieve an increase in BLEU\nscore of up to 1.03 while preserving language features in training. Our work\ncontributes to the broader discussion on technology-facilitated language change\nand calls for more language-aware interventions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14951", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14951", "abs": "https://arxiv.org/abs/2507.14951", "authors": ["Hongzhi Zhu", "Wei Xu", "Xiaohu You"], "title": "Latent-attention Based Transformer for Near ML Polar Decoding in Short-code Regime", "comment": null, "summary": "Transformer architectures have emerged as promising deep learning (DL) tools\nfor modeling complex sequence-to-sequence interactions in channel decoding.\nHowever, current transformer-based decoders for error correction codes (ECCs)\ndemonstrate inferior performance and generalization capabilities compared to\nconventional algebraic decoders, especially in short-code regimes. In this\nwork, we propose a novel latent-attention based transformer (LAT) decoder for\npolar codes that addresses the limitations on performance and generalization\nthrough three pivotal innovations. First, we develop a latent-attention\nmechanism that supersedes the conventional self-attention mechanism. This\narchitectural modification enables independent learning of the Query and Key\nmatrices for code-aware attention computation, decoupling them from the Value\nmatrix to emphasize position-wise decoding interactions while reducing context\ncorrelation interference. Second, we devise an advanced training framework\nincorporating three synergistic components: entropy-aware importance sampling\nthat emphasizes low-probability regions in the signal constellation space,\nexperience reflow that introduces empirical labels to improve characterization\nof decoding boundaries, and dynamic label smoothing for likelihood-based\nregularization. Third, we propose a code-aware mask scheme which allows dynamic\nadaptation for varying code configurations. Numerical evaluations demonstrate\nthat the proposed LAT decoder achieves near maximum-likelihood (ML) performance\nin terms of both bit error rate (BER) and block error rate (BLER) for\nshort-length polar codes. Furthermore, the architecture exhibits robust\ngeneralization capabilities across diverse code rates and code lengths.", "AI": {"tldr": "\u9488\u5bf9Transformer\u5728\u77ed\u7801\u89e3\u7801\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u6f5c\u5728\u6ce8\u610f\u529b\u673a\u5236\u3001\u5148\u8fdb\u8bad\u7ec3\u6846\u67b6\u548c\u4ee3\u7801\u611f\u77e5\u63a9\u7801\u7684\u65b0\u578bTransformer\u89e3\u7801\u5668\uff08LAT\uff09\uff0c\u5728\u77ed\u7801\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u5927\u4f3c\u7136\u7684\u6027\u80fd\u548c\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684Transformer\uff08Transformer architectures\uff09\u5728\u4fe1\u9053\u89e3\u7801\uff08channel decoding\uff09\u65b9\u9762\u867d\u7136\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u7ea0\u9519\u7801\uff08ECCs\uff09\u5e94\u7528\u4e2d\uff0c\u5176\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u76f8\u6bd4\u4f20\u7edf\u7684\u4ee3\u6570\u89e3\u7801\u5668\uff08algebraic decoders\uff09\u8f83\u5dee\uff0c\u5c24\u5176\u662f\u5728\u77ed\u7801\uff08short-code\uff09\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6f5c\u5728\u6ce8\u610f\u529b\uff08latent-attention\uff09\u7684Transformer\uff08LAT\uff09\u89e3\u7801\u5668\u3002\u8be5\u89e3\u7801\u5668\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1. \u6f5c\u5728\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u4ee3\u7801\u611f\u77e5\uff08code-aware\uff09\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u5f3a\u8c03\u9010\u4f4d\u89e3\u7801\u4ea4\u4e92\uff0c\u51cf\u5c11\u4e0a\u4e0b\u6587\u5173\u8054\u5e72\u6270\u30022. \u5148\u8fdb\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u62ec\u71b5\u611f\u77e5\uff08entropy-aware\uff09\u7684\u91cd\u8981\u6027\u91c7\u6837\u3001\u7ecf\u9a8c\u91cd\u653e\uff08experience reflow\uff09\u548c\u52a8\u6001\u6807\u7b7e\u5e73\u6ed1\uff08dynamic label smoothing\uff09\u30023. \u4ee3\u7801\u611f\u77e5\uff08code-aware\uff09\u63a9\u7801\u65b9\u6848\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u7684\u7801\u914d\u7f6e\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cLAT\u89e3\u7801\u5668\u5728\u77ed\u7801\u573a\u666f\u4e0b\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684LAT\u89e3\u7801\u5668\u5728\u77ed\u7801\uff08short-code\uff09\u573a\u666f\u4e0b\uff0c\u5728\u6bd4\u7279\u9519\u8bef\u7387\uff08BER\uff09\u548c\u5757\u9519\u8bef\u7387\uff08BLER\uff09\u65b9\u9762\u5747\u8fbe\u5230\u4e86\u63a5\u8fd1\u6700\u5927\u4f3c\u7136\uff08ML\uff09\u7684\u6027\u80fd\uff0c\u5e76\u8868\u73b0\u51fa\u5bf9\u4e0d\u540c\u7801\u7387\u548c\u7801\u957f\u9c81\u68d2\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.15089", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15089", "abs": "https://arxiv.org/abs/2507.15089", "authors": ["Ioannis Tsampikos Papapetros", "Ioannis Kansizoglou", "Antonios Gasteratos"], "title": "Visual Place Recognition for Large-Scale UAV Applications", "comment": null, "summary": "Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial\nVehicle (UAV) navigation, enabling robust localization across diverse\nenvironments. Despite significant advancements, aerial vPR faces unique\nchallenges due to the limited availability of large-scale, high-altitude\ndatasets, which limits model generalization, along with the inherent rotational\nambiguity in UAV imagery. To address these challenges, we introduce LASED, a\nlarge-scale aerial dataset with approximately one million images,\nsystematically sampled from 170,000 unique locations throughout Estonia over a\ndecade, offering extensive geographic and temporal diversity. Its structured\ndesign ensures clear place separation significantly enhancing model training\nfor aerial scenarios. Furthermore, we propose the integration of steerable\nConvolutional Neural Networks (CNNs) to explicitly handle rotational variance,\nleveraging their inherent rotational equivariance to produce robust,\norientation-invariant feature representations. Our extensive benchmarking\ndemonstrates that models trained on LASED achieve significantly higher recall\ncompared to those trained on smaller, less diverse datasets, highlighting the\nbenefits of extensive geographic coverage and temporal diversity. Moreover,\nsteerable CNNs effectively address rotational ambiguity inherent in aerial\nimagery, consistently outperforming conventional convolutional architectures,\nachieving on average 12\\% recall improvement over the best-performing\nnon-steerable network. By combining structured, large-scale datasets with\nrotation-equivariant neural networks, our approach significantly enhances model\nrobustness and generalization for aerial vPR.", "AI": {"tldr": "\u63d0\u51faLASED\u6570\u636e\u96c6\u548c\u53ef\u5b9a\u5411CNN\u89e3\u51b3\u4e86\u822a\u7a7a\u89c6\u89c9\u573a\u6240\u8bc6\u522b\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u822a\u7a7a\u89c6\u89c9\u573a\u6240\u8bc6\u522b\uff08vPR\uff09\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u5927\u89c4\u6a21\u3001\u9ad8\u6d77\u62d4\u6570\u636e\u96c6\u7684\u53ef\u7528\u6027\u6709\u9650\u4ee5\u53caUAV\u56fe\u50cf\u56fa\u6709\u7684\u65cb\u8f6c\u6b67\u4e49\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLASED\u7684\u5927\u89c4\u6a21\u822a\u7a7a\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea6100\u4e07\u5f20\u56fe\u50cf\uff0c\u5e76\u96c6\u6210\u4e86\u53ef\u5b9a\u5411\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u4ee5\u5904\u7406\u65cb\u8f6c\u4e0d\u53d8\u6027\u3002", "result": "\u5728LASED\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u6bd4\u5728\u8f83\u5c0f\u3001\u591a\u6837\u6027\u8f83\u4f4e\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5177\u6709\u66f4\u9ad8\u7684\u53ec\u56de\u7387\uff0c\u5e76\u4e14\u53ef\u5b9a\u5411CNN\u5728\u5904\u7406\u65cb\u8f6c\u6b67\u4e49\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684\u5377\u79ef\u67b6\u6784\uff0c\u5e73\u5747\u53ec\u56de\u7387\u63d0\u9ad8\u4e8612%\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u3001\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u65cb\u8f6c\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u822a\u7a7a\u89c6\u89c9\u573a\u6240\u8bc6\u522b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.14807", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14807", "abs": "https://arxiv.org/abs/2507.14807", "authors": ["Juan Hu", "Shaojing Fan", "Terence Sim"], "title": "Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection", "comment": null, "summary": "Multi-face deepfake videos are becoming increasingly prevalent, often\nappearing in natural social settings that challenge existing detection methods.\nMost current approaches excel at single-face detection but struggle in\nmulti-face scenarios, due to a lack of awareness of crucial contextual cues. In\nthis work, we develop a novel approach that leverages human cognition to\nanalyze and defend against multi-face deepfake videos. Through a series of\nhuman studies, we systematically examine how people detect deepfake faces in\nsocial settings. Our quantitative analysis reveals four key cues humans rely\non: scene-motion coherence, inter-face appearance compatibility, interpersonal\ngaze alignment, and face-body consistency. Guided by these insights, we\nintroduce \\textsf{HICOM}, a novel framework designed to detect every fake face\nin multi-face scenarios. Extensive experiments on benchmark datasets show that\n\\textsf{HICOM} improves average accuracy by 3.3\\% in in-dataset detection and\n2.8\\% under real-world perturbations. Moreover, it outperforms existing methods\nby 5.8\\% on unseen datasets, demonstrating the generalization of human-inspired\ncues. \\textsf{HICOM} further enhances interpretability by incorporating an LLM\nto provide human-readable explanations, making detection results more\ntransparent and convincing. Our work sheds light on involving human factors to\nenhance defense against deepfakes.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a HICOM \u7684\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u7684\u8ba4\u77e5\u65b9\u5f0f\u6765\u68c0\u6d4b\u591a\u9762\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\u68c0\u6d4b\u65b9\u6cd5\u5728\u5355\u9762\u68c0\u6d4b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u9762\u573a\u666f\u4e0b\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u5173\u952e\u60c5\u5883\u7ebf\u7d22\u7684\u8ba4\u77e5\u800c\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u5e94\u5bf9\u591a\u9762\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4eba\u7c7b\u7814\u7a76\u7cfb\u7edf\u5730\u68c0\u67e5\u4eba\u4eec\u5982\u4f55\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u68c0\u6d4b\u6df1\u5ea6\u4f2a\u9020\u9762\u90e8\uff0c\u5e76\u91cf\u5316\u5206\u6790\u4eba\u4eec\u4f9d\u8d56\u7684\u5173\u952e\u7ebf\u7d22\uff1a\u573a\u666f\u8fd0\u52a8\u4e00\u81f4\u6027\u3001\u9762\u90e8\u5916\u89c2\u517c\u5bb9\u6027\u3001\u4eba\u9645\u76ee\u5149\u5bf9\u9f50\u548c\u9762\u90e8-\u8eab\u4f53\u4e00\u81f4\u6027\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c1\u89e3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a HICOM \u7684\u65b0\u9896\u6846\u67b6\u6765\u68c0\u6d4b\u591a\u9762\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5047\u9762\u90e8\uff0c\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "result": "HICOM \u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6570\u636e\u96c6\u5185\u68c0\u6d4b\u65b9\u9762\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 3.3%\uff1b\u5728\u771f\u5b9e\u4e16\u754c\u6270\u52a8\u4e0b\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 2.8%\u3002\u6b64\u5916\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u6570\u636e\u96c6\u4e0a\uff0cHICOM \u7684\u8868\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad8\u51fa 5.8%\uff0c\u8bc1\u660e\u4e86\u4eba\u7c7b\u542f\u53d1\u5f0f\u7ebf\u7d22\u7684\u6cdb\u5316\u80fd\u529b\u3002HICOM \u8fd8\u901a\u8fc7\u6574\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u63d0\u4f9b\u4eba\u7c7b\u53ef\u8bfb\u7684\u89e3\u91ca\uff0c\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5 \u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u591a\u9762\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\uff0c\u901a\u8fc7\u8bc6\u522b\u573a\u666f\u8fd0\u52a8\u4e00\u81f4\u6027\u3001\u9762\u90e8\u5916\u89c2\u517c\u5bb9\u6027\u3001\u4eba\u9645\u76ee\u5149\u5bf9\u9f50\u548c\u9762\u90e8-\u8eab\u4f53\u4e00\u81f4\u6027\u8fd9\u56db\u4e2a\u5173\u952e\u7ebf\u7d22\uff0c\u5e76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u6df1\u5ea6\u4f2a\u9020\u9632\u5fa1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.15743", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15743", "abs": "https://arxiv.org/abs/2507.15743", "authors": ["Elahe Vedadi", "David Barrett", "Natalie Harris", "Ellery Wulczyn", "Shashir Reddy", "Roma Ruparel", "Mike Schaekermann", "Tim Strother", "Ryutaro Tanno", "Yash Sharma", "Jihyeon Lee", "C\u00edan Hughes", "Dylan Slack", "Anil Palepu", "Jan Freyberg", "Khaled Saab", "Valentin Li\u00e9vin", "Wei-Hung Weng", "Tao Tu", "Yun Liu", "Nenad Tomasev", "Kavita Kulkarni", "S. Sara Mahdavi", "Kelvin Guu", "Jo\u00eblle Barral", "Dale R. Webster", "James Manyika", "Avinatan Hassidim", "Katherine Chou", "Yossi Matias", "Pushmeet Kohli", "Adam Rodman", "Vivek Natarajan", "Alan Karthikesalingam", "David Stutz"], "title": "Towards physician-centered oversight of conversational diagnostic AI", "comment": null, "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3ag-AMIE\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u5b89\u5168\u62a4\u680f\u5185\u8fdb\u884c\u95ee\u8bca\uff0c\u5e76\u5c06\u8bc4\u4f30\u4fe1\u606f\u4f20\u8fbe\u7ed9\u76d1\u7763\u7684PCP\uff0c\u4ee5\u5b9e\u73b0\u5f02\u6b65\u76d1\u7763\u3002\u5728\u865a\u62dfOSCE\u7814\u7a76\u4e2d\uff0cg-AMIE\u5728\u95ee\u8bca\u8d28\u91cf\u3001\u75c5\u4f8b\u603b\u7ed3\u4ee5\u53ca\u8bca\u65ad\u548c\u6cbb\u7597\u8ba1\u5212\u65b9\u9762\u4f18\u4e8eNPs/PAs\u548cPCP\u7ec4\uff0c\u5e76\u4e14PCP\u5bf9g-AMIE\u7684\u76d1\u7763\u6bd4\u72ec\u7acbPCP\u54a8\u8be2\u66f4\u6709\u6548\u7387\u3002", "motivation": "\u53d7\u9650\u4e8eAI\u7cfb\u7edf\u63d0\u4f9b\u4e2a\u4f53\u5316\u8bca\u65ad\u548c\u6cbb\u7597\u8ba1\u5212\u662f\u53d7\u8bb8\u53ef\u4e13\u4e1a\u4eba\u58eb\u76d1\u7ba1\u6d3b\u52a8\u7684\u542f\u53d1\uff0c\u5e76\u8003\u8651\u5230\u533b\u5e08\u901a\u5e38\u4f1a\u76d1\u7763\u5176\u4ed6\u56e2\u961f\u6210\u5458\uff08\u5982NPs\u6216PAs\uff09\u53c2\u4e0e\u6b64\u7c7b\u6d3b\u52a8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aguardrailed-AMIE (g-AMIE) \u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5728\u5b89\u5168\u62a4\u680f\u5185\u8fdb\u884c\u95ee\u8bca\uff0c\u4e0d\u63d0\u4f9b\u4e2a\u4f53\u5316\u533b\u7597\u5efa\u8bae\u3002\u7136\u540e\uff0cg-AMIE\u901a\u8fc7\u4e34\u5e8a\u5ea7\u8231\u754c\u9762\u5c06\u8bc4\u4f30\u4fe1\u606f\u4f20\u8fbe\u7ed9\u76d1\u7763\u7684\u521d\u7ea7\u4fdd\u5065\u533b\u5e08(PCP)\uff0cPCP\u63d0\u4f9b\u76d1\u7763\u5e76\u4fdd\u7559\u4e34\u5e8a\u51b3\u7b56\u7684\u8d23\u4efb\u3002\u5728\u5bf9\u5e26\u6709\u5f02\u6b65\u76d1\u7763\u7684\u6587\u672c\u54a8\u8be2\u8fdb\u884c\u7684\u968f\u673a\u3001\u76f2\u6cd5\u865a\u62df\u5ba2\u89c2\u7ed3\u6784\u5316\u4e34\u5e8a\u8003\u8bd5(OSCE)\u4e2d\uff0c\u5c06g-AMIE\u4e0e\u5728\u76f8\u540c\u5b89\u5168\u62a4\u680f\u4e0b\u7684\u62a4\u58eb\u6267\u4e1a\u533b\u5e08/\u533b\u5e08\u52a9\u7406(NPs/PAs)\u6216\u4e00\u7ec4PCP\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u572860\u4e2a\u573a\u666f\u4e2d\uff0cg-AMIE\u5728\u8fdb\u884c\u9ad8\u8d28\u91cf\u95ee\u8bca\u3001\u603b\u7ed3\u75c5\u4f8b\u4ee5\u53ca\u63d0\u51fa\u4f9b\u76d1\u7763\u7684PCP\u5ba1\u9605\u7684\u8bca\u65ad\u548c\u6cbb\u7597\u8ba1\u5212\u65b9\u9762\uff0c\u4f18\u4e8eNPs/PAs\u548cPCP\u7ec4\u3002\u8fd9\u5bfc\u81f4\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u7efc\u5408\u51b3\u7b56\u3002\u4e0e\u5148\u524d\u7814\u7a76\u4e2d\u7684\u72ec\u7acbPCP\u54a8\u8be2\u76f8\u6bd4\uff0cPCP\u5bf9g-AMIE\u7684\u76d1\u7763\u4e5f\u66f4\u6709\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f02\u6b65\u76d1\u7763\u8303\u5f0f\u5bf9\u4e8e\u8bca\u65adAI\u7cfb\u7edf\u5728\u4e13\u5bb6\u4eba\u7c7b\u76d1\u7763\u4e0b\u8fd0\u884c\u4ee5\u589e\u5f3a\u5b9e\u9645\u62a4\u7406\u5177\u6709\u53ef\u884c\u6027\u3002"}}
{"id": "2507.14746", "categories": ["cs.LG", "math.OC", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14746", "abs": "https://arxiv.org/abs/2507.14746", "authors": ["Bach Do", "Nafeezat A. Ajenifuja", "Taiwo A. Adebiyi", "Ruda Zhang"], "title": "Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization", "comment": null, "summary": "High-fidelity simulations and physical experiments are essential for\nengineering analysis and design. However, their high cost often limits their\napplications in two critical tasks: global sensitivity analysis (GSA) and\noptimization. This limitation motivates the common use of Gaussian processes\n(GPs) as proxy regression models to provide uncertainty-aware predictions based\non a limited number of high-quality observations. GPs naturally enable\nefficient sampling strategies that support informed decision-making under\nuncertainty by extracting information from a subset of possible functions for\nthe model of interest. Despite their popularity in machine learning and\nstatistics communities, sampling from GPs has received little attention in the\ncommunity of engineering optimization. In this paper, we present the\nformulation and detailed implementation of two notable sampling methods --\nrandom Fourier features and pathwise conditioning -- for generating posterior\nsamples from GPs. Alternative approaches are briefly described. Importantly, we\ndetail how the generated samples can be applied in GSA, single-objective\noptimization, and multi-objective optimization. We show successful applications\nof these sampling methods through a series of numerical examples.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u4ece\u9ad8\u65af\u8fc7\u7a0b\u4e2d\u751f\u6210\u540e\u9a8c\u6837\u672c\u7684\u65b9\u6cd5\uff08\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u548c\u8def\u5f84\u79ef\u5206\uff09\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u4eec\u5728\u5de5\u7a0b\u4f18\u5316\u548c\u654f\u611f\u6027\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u9ad8\u4fdd\u771f\u6a21\u62df\u548c\u7269\u7406\u5b9e\u9a8c\u5728\u5de5\u7a0b\u5206\u6790\u548c\u8bbe\u8ba1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u6210\u672c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff08GSA\uff09\u548c\u4f18\u5316\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u9ad8\u65af\u8fc7\u7a0b\uff08GPs\uff09\u5e38\u88ab\u7528\u4f5c\u4ee3\u7406\u56de\u5f52\u6a21\u578b\uff0c\u4ee5\u6709\u9650\u7684\u9ad8\u8d28\u91cf\u89c2\u6d4b\u6570\u636e\u63d0\u4f9b\u53ef\u611f\u77e5\u7684\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u548c\u8def\u5f84\u79ef\u5206\u8fd9\u4e24\u79cd\u4ece\u9ad8\u65af\u8fc7\u7a0b\u4e2d\u751f\u6210\u540e\u9a8c\u6837\u672c\u7684\u65b9\u6cd5\uff0c\u5e76\u8be6\u7ec6\u8bf4\u660e\u4e86\u5b83\u4eec\u7684\u5b9e\u73b0\u7ec6\u8282\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u6570\u503c\u793a\u4f8b\u6210\u529f\u5c55\u793a\u4e86\u8fd9\u4e9b\u91c7\u6837\u65b9\u6cd5\u5728GSA\u3001\u5355\u76ee\u6807\u4f18\u5316\u548c\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u4ece\u9ad8\u65af\u8fc7\u7a0b\uff08GPs\uff09\u4e2d\u751f\u6210\u540e\u9a8c\u6837\u672c\u7684\u65b9\u6cd5\u2014\u2014\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u548c\u8def\u5f84\u79ef\u5206\uff0c\u5e76\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5b83\u4eec\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5982\u4f55\u5c06\u8fd9\u4e9b\u6837\u672c\u5e94\u7528\u4e8e\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff08GSA\uff09\u3001\u5355\u76ee\u6807\u4f18\u5316\u548c\u591a\u76ee\u6807\u4f18\u5316\u3002"}}
{"id": "2507.15588", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15588", "abs": "https://arxiv.org/abs/2507.15588", "authors": ["Konstantin Beyer", "M. S. Kim", "Igor Pikovski"], "title": "A One-sided Witness for the Quantumness of Gravitational Dynamics", "comment": null, "summary": "Quantum information concepts and quantum technologies have opened the\nprospect to probe quantum gravity in table-top experiments. Many proposals rely\non witnessing entanglement generation as a means to probe whether gravity is a\nquantum channel. Here we formulate a different and conclusive indirect test of\nthe quantum nature of the gravitational interaction. Our witness is based on\nthe concept of verifiable quantum memory in the dynamics of a quantum system.\nThis allows us to assess the quantumness of an interaction between two systems\nby local measurements on one subsystem only. Our approach enables the first\none-sided verification of the quantum nature of gravity, and provides a quantum\nsignature of the interaction that is not fully covered by existing proposals.\nOur results open novel ways to witnessing the quantum nature of gravity in\ntable-top experiments and clarify how {decisive tests can be designed even with\nmeasurements on only the probe system", "AI": {"tldr": "\u5229\u7528\u53ef\u9a8c\u8bc1\u91cf\u5b50\u8bb0\u5fc6\uff0c\u5355\u65b9\u9762\u9a8c\u8bc1\u5f15\u529b\u76f8\u4e92\u4f5c\u7528\u7684\u91cf\u5b50\u6027\u3002", "motivation": "\u63a2\u7d22\u5728\u684c\u9762\u5b9e\u9a8c\u4e2d\u5229\u7528\u91cf\u5b50\u4fe1\u606f\u6982\u5ff5\u548c\u91cf\u5b50\u6280\u672f\u63a2\u6d4b\u91cf\u5b50\u5f15\u529b\uff0c\u7279\u522b\u662f\u9a8c\u8bc1\u5f15\u529b\u662f\u5426\u4e3a\u91cf\u5b50\u901a\u9053\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u91cf\u5b50\u8bb0\u5fc6\u7684\u95f4\u63a5\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u9700\u5bf9\u4e00\u4e2a\u5b50\u7cfb\u7edf\u8fdb\u884c\u5c40\u90e8\u6d4b\u91cf\u5373\u53ef\u8bc4\u4f30\u4e24\u4e2a\u7cfb\u7edf\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u91cf\u5b50\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u5f15\u529b\u91cf\u5b50\u6027\u8d28\u7684\u5355\u65b9\u9762\u9a8c\u8bc1\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e0d\u540c\u4e8e\u73b0\u6709\u65b9\u6848\u7684\u3001\u80fd\u591f\u5b8c\u5168\u8986\u76d6\u5f15\u529b\u76f8\u4e92\u4f5c\u7528\u91cf\u5b50\u6027\u7684\u91cf\u5b50\u7b7e\u540d\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u53ef\u9a8c\u8bc1\u7684\u91cf\u5b50\u8bb0\u5fc6\u65b9\u6cd5\uff0c\u7528\u4e8e\u5355\u65b9\u9762\u9a8c\u8bc1\u5f15\u529b\u76f8\u4e92\u4f5c\u7528\u7684\u91cf\u5b50\u6027\u8d28\uff0c\u4e3a\u8bbe\u8ba1\u4ec5\u901a\u8fc7\u63a2\u6d4b\u7cfb\u7edf\u8fdb\u884c\u6d4b\u91cf\u5373\u53ef\u8fdb\u884c\u7684\u51b3\u5b9a\u6027\u6d4b\u8bd5\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.15152", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15152", "abs": "https://arxiv.org/abs/2507.15152", "authors": ["Lingbo Li", "Anuradha Mathrani", "Teo Susnjak"], "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction", "comment": null, "summary": "Automating data extraction from full-text randomised controlled trials (RCTs)\nfor meta-analysis remains a significant challenge. This study evaluates the\npractical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)\nacross tasks involving statistical results, risk-of-bias assessments, and\nstudy-level characteristics in three medical domains: hypertension, diabetes,\nand orthopaedics. We tested four distinct prompting strategies (basic\nprompting, self-reflective prompting, model ensemble, and customised prompts)\nto determine how to improve extraction quality. All models demonstrate high\nprecision but consistently suffer from poor recall by omitting key information.\nWe found that customised prompts were the most effective, boosting recall by up\nto 15\\%. Based on this analysis, we propose a three-tiered set of guidelines\nfor using LLMs in data extraction, matching data types to appropriate levels of\nautomation based on task complexity and risk. Our study offers practical advice\nfor automating data extraction in real-world meta-analyses, balancing LLM\nefficiency with expert oversight through targeted, task-specific automation.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u8bed\u8a00\u6a21\u578b\uff08Gemini-2.0-flash\u3001Grok-3\u3001GPT-4o-mini\uff09\u5728\u4ece\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff08RCT\uff09\u4e2d\u63d0\u53d6\u6570\u636e\u4ee5\u8fdb\u884c\u835f\u8403\u5206\u6790\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5b9a\u5236\u5316\u63d0\u793a\u53ef\u63d0\u9ad8\u53ec\u56de\u7387\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u7528\u4e8e\u6570\u636e\u63d0\u53d6\u7684\u6307\u5357\uff0c\u4ee5\u5e73\u8861\u81ea\u52a8\u5316\u548c\u4e13\u5bb6\u76d1\u7763\u3002", "motivation": "\u4ece\u5168\u6587\u672c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff08RCT\uff09\u4e2d\u81ea\u52a8\u63d0\u53d6\u7528\u4e8e\u835f\u8403\u5206\u6790\u7684\u6570\u636e\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u8bed\u8a00\u6a21\u578b\uff08Gemini-2.0-flash\u3001Grok-3\u3001GPT-4o-mini\uff09\u5728\u63d0\u53d6\u7edf\u8ba1\u7ed3\u679c\u3001\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u548c\u7814\u7a76\u7279\u5f81\u65b9\u9762\u7684\u5b9e\u9645\u8868\u73b0\u3002\u7814\u7a76\u6d4b\u8bd5\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff08\u57fa\u672c\u63d0\u793a\u3001\u81ea\u7701\u63d0\u793a\u3001\u6a21\u578b\u96c6\u6210\u548c\u5b9a\u5236\u5316\u63d0\u793a\uff09\uff0c\u4ee5\u63d0\u9ad8\u63d0\u53d6\u8d28\u91cf\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u5728\u53ec\u56de\u7387\u65b9\u9762\u6301\u7eed\u5b58\u5728\u4e0d\u8db3\uff0c\u9057\u6f0f\u4e86\u5173\u952e\u4fe1\u606f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5b9a\u5236\u5316\u63d0\u793a\u6700\u6709\u6548\uff0c\u53ec\u56de\u7387\u6700\u9ad8\u53ef\u63d0\u9ad815%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u5957\u4e09\u5c42\u6307\u5357\uff0c\u7528\u4e8e\u5728\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u6570\u636e\u63d0\u53d6\u65f6\uff0c\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u548c\u98ce\u9669\uff0c\u5c06\u6570\u636e\u7c7b\u578b\u4e0e\u9002\u5f53\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u76f8\u5339\u914d\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5728\u5b9e\u9645\u7684\u835f\u8403\u5206\u6790\u4e2d\u81ea\u52a8\u63d0\u53d6\u6570\u636e\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5efa\u8bae\uff0c\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u3001\u4efb\u52a1\u7279\u5b9a\u7684\u81ea\u52a8\u5316\u6765\u5e73\u8861LLM\u7684\u6548\u7387\u548c\u4e13\u5bb6\u76d1\u7763\u3002"}}
{"id": "2507.14982", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.14982", "abs": "https://arxiv.org/abs/2507.14982", "authors": ["Kareem M. Attiah", "Wei Yu"], "title": "How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?", "comment": "26 pages, 7 figures, Submitted to T-IT for future publication", "summary": "Consider a downlink integrated sensing and communications (ISAC) system in\nwhich a base station employs linear beamforming to communicate to $K$ users,\nwhile simultaneously uses sensing beams to perform a sensing task of estimating\n$L$ real parameters. How many beamformers are needed to achieve the best\nperformance for both sensing and communications? This paper establishes bounds\non the minimum number of downlink beamformers, in which sensing performance is\nmeasured in terms of the Cram\\'{e}r-Rao bound for parameter estimation and\ncommunications performance is measured in terms of the\nsignal-to-interference-and-noise ratios. We show that an ISAC system requires\nat most $K + \\sqrt{\\frac{L(L+1)}{2}}$ beamformers if the remote users have the\nability to cancel the interference caused by the sensing beams. If cancelling\ninterference due to the sensing beams is not possible, the bound becomes\n$\\sqrt{K^2 + \\frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound\non the number of beamformers is less than the sum of the bounds for each task\nindividually. These results can be extended to sensing tasks for which the\nperformance is measured as a function of $d$ quadratic terms in the\nbeamformers. In this case, the bound becomes $K + \\sqrt{d}$ and $\\sqrt{K^2 +\nd}$, respectively. Specifically, for estimating complex path losses and\nangles-of-arrival of $N_\\text{tr}$ targets while communicating to $K$ users,\nthe bound on the minimum number of beamformers scales linearly in $K$ and in\n$N_\\text{tr}$, assuming interference from sensing can be cancelled. When\ninterference cancellation is not possible, the following exact characterization\nfor the case of $N_\\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two\nbeamformers should be used; when $K \\ge 2$, exactly $K$ beamformers should be\nused, i.e., communication beamformers alone are already sufficient.", "AI": {"tldr": "ISAC\u7cfb\u7edf\u9700\u8981 K + sqrt(L(L+1)/2) \u6216 sqrt(K^2 + L(L+1)/2) \u4e2a\u4e0b\u884c\u6ce2\u675f\u6570\u91cf\u3002", "motivation": "\u7814\u7a76\u5728ISAC\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u4e86\u540c\u65f6\u5b9e\u73b0\u4f20\u611f\u548c\u901a\u4fe1\u7684\u6700\u4f73\u6027\u80fd\uff0c\u9700\u8981\u591a\u5c11\u4e2a\u4e0b\u884c\u6ce2\u675f\u6570\u91cf\u3002", "method": "\u672c\u6587\u5efa\u7acb\u4e86\u4e0b\u884c\u6ce2\u675f\u6570\u91cf\u7684\u754c\u9650\uff0c\u5176\u4e2d\u4f20\u611f\u6027\u80fd\u901a\u8fc7\u53c2\u6570\u4f30\u8ba1\u7684\u514b\u62c9\u7f8e-\u62c9\u5965\u8fb9\u754c\u6765\u8861\u91cf\uff0c\u901a\u4fe1\u6027\u80fd\u901a\u8fc7\u4fe1\u566a\u6bd4\u6765\u8861\u91cf\u3002", "result": "\u5728\u7528\u6237\u53ef\u4ee5\u6d88\u9664\u4f20\u611f\u6ce2\u675f\u5e72\u6270\u7684\u60c5\u51b5\u4e0b\uff0cISAC\u7cfb\u7edf\u6700\u591a\u9700\u8981 K + sqrt(L(L+1)/2) \u4e2a\u6ce2\u675f\u6570\u91cf\u3002\u5982\u679c\u7528\u6237\u65e0\u6cd5\u6d88\u9664\u4f20\u611f\u6ce2\u675f\u7684\u5e72\u6270\uff0c\u754c\u9650\u4e3a sqrt(K^2 + L(L+1)/2)\u3002\u5f53\u65e0\u6cd5\u8fdb\u884c\u5e72\u6270\u6d88\u9664\u65f6\uff0c\u6ce2\u675f\u6570\u91cf\u7684\u754c\u9650\u5c0f\u4e8e\u5355\u72ec\u6267\u884c\u5404\u9879\u4efb\u52a1\u7684\u754c\u9650\u4e4b\u548c\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3a\u4e0b\u884c\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7cfb\u7edf\u5efa\u7acb\u4e86\u4e0b\u884c\u6ce2\u675f\u6570\u91cf\u7684\u754c\u9650\u3002"}}
{"id": "2507.15758", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15758", "abs": "https://arxiv.org/abs/2507.15758", "authors": ["Xingyu Wu", "Yuchen Yan", "Shangke Lyu", "Linjuan Wu", "Yiwen Qiu", "Yongliang Shen", "Weiming Lu", "Jian Shao", "Jun Xiao", "Yueting Zhuang"], "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "comment": "GitHub:https://github.com/zju-real/lapo;\n  Project:https://zju-real.github.io/lapo", "summary": "Large reasoning models have achieved remarkable performance through extended\nchain-of-thought sequences, yet this computational freedom leads to excessive\ntoken generation even for simple problems. We present Length-Adaptive Policy\nOptimization (LAPO), a novel framework that transforms reasoning length control\nfrom an external constraint into an intrinsic model capability. Unlike existing\napproaches that impose rigid limits or rely on post-hoc interventions, LAPO\nenables models to internalize an understanding of appropriate reasoning depth\nthrough a two-stage reinforcement learning process. In the first stage, models\nlearn natural reasoning patterns by discovering the statistical distribution of\nsuccessful solution lengths. The second stage leverages these patterns as\nmeta-cognitive guidance, embedding them directly within the model's reasoning\ncontext to ensure inference-time flexibility. Experiments on mathematical\nreasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\%\nwhile improving accuracy by 2.3\\%. Our analysis reveals that models trained\nwith LAPO develop emergent abilities to allocate computational resources based\non problem complexity, achieving efficient reasoning without sacrificing\nquality.", "AI": {"tldr": "LAPO is a new framework that trains reasoning models to control their own reasoning length using reinforcement learning, reducing token use by up to 40.9% and improving accuracy by 2.3% by making them better at judging problem complexity.", "motivation": "To address the issue of excessive token generation in large reasoning models due to extended chain-of-thought sequences, even for simple problems, by transforming reasoning length control from an external constraint into an intrinsic model capability.", "method": "LAPO is a novel framework that enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. The first stage involves learning natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage uses these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context for inference-time flexibility.", "result": "Experiments on mathematical reasoning benchmarks show that LAPO reduces token usage by up to 40.9% and improves accuracy by 2.3%. Models trained with LAPO demonstrate emergent abilities to allocate computational resources based on problem complexity.", "conclusion": "LAPO enables models to develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality, reducing token usage by up to 40.9% while improving accuracy by 2.3%."}}
{"id": "2507.15605", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15605", "abs": "https://arxiv.org/abs/2507.15605", "authors": ["Yao Dong", "Jing-jing Wang", "Guo-Feng Zhang"], "title": "Unconventional photon blockade in a hybrid optomechanical system with an embedded spin-triplet", "comment": "12 pages, 5 figures", "summary": "The research article studies the unconventional photon blockade effect in a\nhybrid optomechanical system with an embedded spin-triplet state. The\ninteraction between the optomechanical system and the spin state generates new\ntransition paths for the destructive quantum interference of the two-photon\nexcitation state. By analytically solving the Schrodinger equation and\nnumerically simulating the master equation, it can be found that the modulated\nmechanical dissipation is essential for achieving the strong photon blockade in\nour system. Unlike the conventional cavity optomechanical system, the\nsecond-order correlation function g(2)(0) =0 can be obtained with the weak\nsingle-photon optomechanical coupling. By adjusting the system parameters, the\nstrong photon blockade and the single-photon resonance can coincide, which\nindicates the hybrid system has the potential to be a high-quality and\nefficient single-photon source. Finally, the influence of the thermal noise on\nphoton blockade is investigated. The results show that the second-order\ncorrelation function is more robust for the weaker phonon-spin coupling.", "AI": {"tldr": "\u8be5\u7814\u7a76 article \u63a2\u8ba8\u4e86\u5728\u5177\u6709\u5d4c\u5165\u5f0f\u81ea\u65cb\u4e09\u91cd\u6001\u7684\u6df7\u5408\u5149\u529b\u7cfb\u7edf\u4e2d\u53cd\u5e38\u7684\u5149\u5b50\u5757\u6548\u5e94\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8c03\u5236\u673a\u68b0\u8017\u6563\u5bf9\u4e8e\u5b9e\u73b0\u5f3a\u5149\u5b50\u5757\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u4e14\u8be5\u7cfb\u7edf\u6709\u6f5c\u529b\u6210\u4e3a\u9ad8\u8d28\u91cf\u3001\u9ad8\u6548\u7387\u7684\u5355\u5149\u5b50\u6e90\u3002", "motivation": "\u7814\u7a76\u5728\u5177\u6709\u5d4c\u5165\u5f0f\u81ea\u65cb\u4e09\u91cd\u6001\u7684\u6df7\u5408\u5149\u529b\u7cfb\u7edf\u4e2d\u53cd\u5e38\u7684\u5149\u5b50\u5757\u6548\u5e94\u3002", "method": "\u901a\u8fc7\u89e3\u6790\u6c42\u89e3\u859b\u5b9a\u8c14\u65b9\u7a0b\u548c\u6570\u503c\u6a21\u62df\u4e3b\u65b9\u7a0b\u3002", "result": "\u901a\u8fc7\u8c03\u6574\u7cfb\u7edf\u53c2\u6570\uff0c\u5f3a\u5149\u5b50\u5757\u548c\u5355\u5149\u5b50\u5171\u632f\u53ef\u4ee5\u91cd\u5408\uff0c\u8bc1\u660e\u4e86\u8be5\u6df7\u5408\u7cfb\u7edf\u6709\u6f5c\u529b\u6210\u4e3a\u9ad8\u8d28\u91cf\u3001\u9ad8\u6548\u7387\u7684\u5355\u5149\u5b50\u6e90\u3002\u8c03\u5236\u673a\u68b0\u8017\u6563\u5bf9\u4e8e\u5728\u6211\u4eec\u7684\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5f3a\u5149\u5b50\u5757\u81f3\u5173\u91cd\u8981\u3002\u4e0e\u4f20\u7edf\u7684\u8154\u5149\u529b\u7cfb\u7edf\u4e0d\u540c\uff0c\u5728\u5f31\u5355\u5149\u5b50\u5149\u529b\u8026\u5408\u4e0b\u53ef\u4ee5\u83b7\u5f97\u4e8c\u9636\u5173\u8054\u51fd\u6570g(2)(0) =0\u3002", "conclusion": "\u8be5\u6df7\u5408\u7cfb\u7edf\u6709\u6f5c\u529b\u6210\u4e3a\u9ad8\u8d28\u91cf\u3001\u9ad8\u6548\u7387\u7684\u5355\u5149\u5b50\u6e90\u3002"}}
{"id": "2507.15198", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15198", "abs": "https://arxiv.org/abs/2507.15198", "authors": ["Xiandong Meng", "Yan Wu", "Yexin Tian", "Xin Hu", "Tianze Kang", "Junliang Du"], "title": "Collaborative Distillation Strategies for Parameter-Efficient Language Model Deployment", "comment": null, "summary": "This paper addresses the challenges of high computational cost and slow\ninference in deploying large language models. It proposes a distillation\nstrategy guided by multiple teacher models. The method constructs several\nteacher models and integrates their output probability distributions and\nintermediate semantic features. This guides the student model to learn from\nmultiple sources of knowledge. As a result, the student model gains stronger\nlanguage understanding and generation ability while maintaining a small\nparameter size. To achieve this, the paper introduces a weighted output fusion\nmechanism, a feature alignment loss function, and an entropy-driven dynamic\nteacher weighting strategy. These components improve the quality and stability\nof knowledge transfer during distillation. Under multi-teacher guidance, the\nstudent model captures semantic information more effectively and demonstrates\nstrong performance across multiple evaluation metrics. In particular, the\nmethod shows high consistency in expression, generalization ability, and task\nadaptability in tasks such as language modeling, text generation, and\nmulti-task learning. The experiments compare the proposed method with several\nwidely adopted distillation approaches. The results further confirm its overall\nadvantages in perplexity, distillation loss, and generation quality. This study\nprovides a feasible technical path for the efficient compression of large-scale\nlanguage models. It also demonstrates the effectiveness of multi-teacher\ncollaborative mechanisms in complex language modeling tasks.", "AI": {"tldr": "\u901a\u8fc7\u591a\u6559\u5e08\u77e5\u8bc6\u84b8\u998f\uff0c\u5728\u538b\u7f29\u5927\u6a21\u578b\u7684\u540c\u65f6\u63d0\u5347\u5176\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u901f\u5ea6\u6162\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u591a\u4e2a\u6559\u5e08\u6a21\u578b\u6307\u5bfc\u7684\u84b8\u998f\u7b56\u7565\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\u5206\u5e03\u548c\u4e2d\u95f4\u8bed\u4e49\u7279\u5f81\u6765\u6307\u5bfc\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u3002\u5177\u4f53\u5305\u542b\u52a0\u6743\u8f93\u51fa\u878d\u5408\u673a\u5236\u3001\u7279\u5f81\u5bf9\u9f50\u635f\u5931\u51fd\u6570\u4ee5\u53ca\u71b5\u9a71\u52a8\u52a8\u6001\u6559\u5e08\u52a0\u6743\u7b56\u7565\u3002", "result": "\u5b66\u751f\u6a21\u578b\u5728\u4fdd\u6301\u8f83\u5c0f\u53c2\u6570\u91cf\u7684\u540c\u65f6\uff0c\u83b7\u5f97\u4e86\u66f4\u5f3a\u7684\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u6587\u672c\u751f\u6210\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u9ad8\u4e00\u81f4\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u4efb\u52a1\u9002\u5e94\u6027\u3002\u4e0e\u73b0\u6709\u84b8\u998f\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u56f0\u60d1\u5ea6\u3001\u84b8\u998f\u635f\u5931\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u5747\u663e\u793a\u51fa\u4f18\u52bf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u538b\u7f29\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\uff0c\u5e76\u8bc1\u660e\u4e86\u591a\u6559\u5e08\u534f\u4f5c\u673a\u5236\u5728\u590d\u6742\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15116", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15116", "abs": "https://arxiv.org/abs/2507.15116", "authors": ["Zichao Zhang", "Melda Yuksel", "Gokhan M. Guvensen", "Halim Yanikomeroglu"], "title": "PAPR Analysis for MIMO FTN Signaling with Gaussian Symbols", "comment": null, "summary": "Faster-than-Nyquist signaling serves as a promising solution for improving\nspectral efficiency in future generations of communications. However, its\nnature of fast acceleration brings highly overlapped pulses that lead to worse\npeak-to-average power ratio (PAPR) performance. In this paper, we investigate\nthe PAPR behavior of MIMO FTN using Gaussian symbols under optimal power\nallocation for two power constraints: fixed transmit power and fixed received\nsignal-to-noise-ratio (SNR). Our findings reveal that PAPR is mainly determined\nby the acceleration factor and the power constraint, but power allocation\noptimization does not change the PAPR behavior for Gaussian signaling.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86 MIMO FTN \u7684 PAPR \u95ee\u9898\uff0c\u53d1\u73b0 PAPR \u4e3b\u8981\u7531\u52a0\u901f\u5ea6\u56e0\u5b50\u548c\u529f\u7387\u7ea6\u675f\u51b3\u5b9a\uff0c\u800c\u529f\u7387\u5206\u914d\u4f18\u5316\u4e0d\u5f71\u54cd\u9ad8\u65af\u4fe1\u53f7\u7684 PAPR\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u901a\u4fe1\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\uff0c\u4eba\u4eec\u63d0\u51fa\u4e86\u8d85\u5948\u594e\u65af\u7279 (FTN) \u4fe1\u53f7\uff0c\u4f46\u5176\u5feb\u901f\u52a0\u901f\u7684\u7279\u6027\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u5cf0\u5747\u529f\u7387\u6bd4 (PAPR) \u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e86\u4e24\u79cd\u529f\u7387\u7ea6\u675f\u4e0b\u7684 MIMO FTN \u7684 PAPR \u7279\u6027\uff1a\u56fa\u5b9a\u7684\u53d1\u5c04\u529f\u7387\u548c\u56fa\u5b9a\u7684\u63a5\u6536\u4fe1\u566a\u6bd4 (SNR)\u3002", "result": "PAPR \u4e3b\u8981\u7531\u52a0\u901f\u5ea6\u56e0\u5b50\u548c\u529f\u7387\u7ea6\u675f\u51b3\u5b9a\uff0c\u5e76\u4e14\u529f\u7387\u5206\u914d\u4f18\u5316\u4e0d\u4f1a\u6539\u53d8\u9ad8\u65af\u4fe1\u53f7\u7684 PAPR \u7279\u6027\u3002", "conclusion": "\u5bf9\u4e8e\u9ad8\u65af\u4fe1\u53f7\uff0c\u529f\u7387\u5206\u914d\u4f18\u5316\u4e0d\u4f1a\u6539\u53d8 PAPR \u7684\u884c\u4e3a\u3002"}}
{"id": "2507.15496", "categories": ["cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15496", "abs": "https://arxiv.org/abs/2507.15496", "authors": ["JunYing Huang", "Ao Xu", "DongSun Yong", "KeRen Li", "YuanFeng Wang", "Qi Qin"], "title": "Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images", "comment": null, "summary": "Odometry is a critical task for autonomous systems for self-localization and\nnavigation. We propose a novel LiDAR-Visual odometry framework that integrates\nLiDAR point clouds and images for accurate and robust pose estimation. Our\nmethod utilizes a dense-depth map estimated from point clouds and images\nthrough depth completion, and incorporates a multi-scale feature extraction\nnetwork with attention mechanisms, enabling adaptive depth-aware\nrepresentations. Furthermore, we leverage dense depth information to refine\nflow estimation and mitigate errors in occlusion-prone regions. Our\nhierarchical pose refinement module optimizes motion estimation progressively,\nensuring robust predictions against dynamic environments and scale ambiguities.\nComprehensive experiments on the KITTI odometry benchmark demonstrate that our\napproach achieves similar or superior accuracy and robustness compared to\nstate-of-the-art visual and LiDAR odometry methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408LiDAR\u548c\u89c6\u89c9\u4fe1\u606f\u7684\u65b0\u7684\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u8865\u5168\u3001\u6ce8\u610f\u529b\u673a\u5236\u548c\u5206\u5c42\u59ff\u6001\u4f18\u5316\uff0c\u5728KITTI\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u5b9e\u73b0\u7cbe\u786e\u53ef\u9760\u7684\u81ea\u6211\u5b9a\u4f4d\u548c\u5bfc\u822a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684LiDAR-\u89c6\u89c9\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u8865\u5168\u4ece\u70b9\u4e91\u548c\u56fe\u50cf\u4e2d\u4f30\u8ba1\u7a20\u5bc6\u6df1\u5ea6\u56fe\uff0c\u5e76\u7ed3\u5408\u4e86\u5177\u6709\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u7684\u6df1\u5ea6\u611f\u77e5\u8868\u793a\u3002\u6b64\u5916\uff0c\u5229\u7528\u7a20\u5bc6\u7684\u6df1\u5ea6\u4fe1\u606f\u6539\u8fdb\u4e86\u5149\u6d41\u4f30\u8ba1\uff0c\u5e76\u51cf\u5c11\u4e86\u906e\u6321\u533a\u57df\u7684\u8bef\u5dee\u3002\u6240\u63d0\u51fa\u7684\u5206\u5c42\u59ff\u6001\u4f18\u5316\u6a21\u5757\u9010\u6b65\u4f18\u5316\u8fd0\u52a8\u4f30\u8ba1\uff0c\u786e\u4fdd\u5728\u52a8\u6001\u73af\u5883\u548c\u5c3a\u5ea6\u6a21\u7cca\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728KITTI Odometry\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u548cLiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u76f8\u4f3c\u6216\u66f4\u4f18\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728KITTI Odometry\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4e0e\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u548cLiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14811", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14811", "abs": "https://arxiv.org/abs/2507.14811", "authors": ["Jiaji Zhang", "Ruichao Sun", "Hailiang Zhao", "Jiaju Wu", "Peng Chen", "Hao Li", "Xinkui Zhao", "Kingsum Chow", "Gang Xiong", "Lin Ye", "Shuiguang Deng"], "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models", "comment": null, "summary": "Diffusion models have demonstrated exceptional generative capabilities but\nare computationally intensive, posing significant challenges for deployment in\nresource-constrained or latency-sensitive environments. Quantization offers an\neffective means to reduce model size and computational cost, with post-training\nquantization (PTQ) being particularly appealing due to its compatibility with\npre-trained models without requiring retraining or training data. However,\nexisting PTQ methods for diffusion models often rely on architecture-specific\nheuristics that limit their generalizability and hinder integration with\nindustrial deployment pipelines. To address these limitations, we propose\nSegQuant, a unified quantization framework that adaptively combines\ncomplementary techniques to enhance cross-model versatility. SegQuant consists\nof a segment-aware, graph-based quantization strategy (SegLinear) that captures\nstructural semantics and spatial heterogeneity, along with a dual-scale\nquantization scheme (DualScale) that preserves polarity-asymmetric activations,\nwhich is crucial for maintaining visual fidelity in generated outputs. SegQuant\nis broadly applicable beyond Transformer-based diffusion models, achieving\nstrong performance while ensuring seamless compatibility with mainstream\ndeployment tools.", "AI": {"tldr": "SegQuant\u901a\u8fc7\u7ed3\u5408SegLinear\u548cDualScale\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u91cf\u5316\u4e2d\u7684\u6cdb\u5316\u6027\u548c\u96c6\u6210\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u4fdd\u771f\u7684\u6a21\u578b\u538b\u7f29\u3002", "motivation": "\u73b0\u6709\u7684\u91cf\u5316\u65b9\u6cd5\uff08PTQ\uff09\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u67b6\u6784\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u963b\u788d\u4e86\u4e0e\u5de5\u4e1a\u90e8\u7f72\u7ba1\u9053\u7684\u96c6\u6210\u3002", "method": "SegQuant\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u611f\u77e5\u6bb5\u7684\u3001\u57fa\u4e8e\u56fe\u7684\u91cf\u5316\u7b56\u7565\uff08SegLinear\uff09\u6765\u6355\u6349\u7ed3\u6784\u8bed\u4e49\u548c\u7a7a\u95f4\u5f02\u8d28\u6027\uff0c\u4ee5\u53ca\u4e00\u4e2a\u53cc\u5c3a\u5ea6\u91cf\u5316\u65b9\u6848\uff08DualScale\uff09\u6765\u4fdd\u7559\u6781\u6027\u4e0d\u5bf9\u79f0\u6fc0\u6d3b\u3002", "result": "SegQuant\u5728\u4fdd\u6301\u751f\u6210\u8f93\u51fa\u89c6\u89c9\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5b9e\u73b0\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4e0e\u4e3b\u6d41\u90e8\u7f72\u5de5\u5177\u517c\u5bb9\uff0c\u5e76\u4e14\u9002\u7528\u4e8eTransformer\u4ee5\u5916\u7684\u6269\u6563\u6a21\u578b\u3002", "conclusion": "SegQuant\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u7ed3\u5408\u4e92\u8865\u6280\u672f\u6765\u589e\u5f3a\u8de8\u6a21\u578b\u901a\u7528\u6027\u3002\u5b83\u5305\u62ec\u4e00\u4e2a\u611f\u77e5\u6bb5\u7684\u3001\u57fa\u4e8e\u56fe\u7684\u91cf\u5316\u7b56\u7565\uff08SegLinear\uff09\u548c\u4e00\u79cd\u53cc\u5c3a\u5ea6\u91cf\u5316\u65b9\u6848\uff08DualScale\uff09\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8f93\u51fa\u89c6\u89c9\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5b9e\u73b0\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4e0e\u4e3b\u6d41\u90e8\u7f72\u5de5\u5177\u517c\u5bb9\u3002"}}
{"id": "2507.15761", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15761", "abs": "https://arxiv.org/abs/2507.15761", "authors": ["Jingyi Zheng", "Zifan Peng", "Yule Liu", "Junfeng Wang", "Yifan Liao", "Wenhan Dong", "Xinlei He"], "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts", "comment": null, "summary": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.", "AI": {"tldr": "GasAgent\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u667a\u80fd\u5408\u7ea6\u7684Gas\u4f18\u5316\u3002\u5b83\u901a\u8fc7\u56db\u4e2a\u534f\u4f5c\u667a\u80fd\u4f53\uff08\u63a2\u5bfb\u8005\u3001\u521b\u65b0\u8005\u3001\u6267\u884c\u8005\u3001\u7ba1\u7406\u8005\uff09\u5b9e\u73b0Gas\u6d6a\u8d39\u6a21\u5f0f\u7684\u81ea\u52a8\u5316\u53d1\u73b0\u3001\u9a8c\u8bc1\u548c\u5e94\u7528\uff0c\u5e76\u80fd\u4e0e\u73b0\u6709\u6a21\u5f0f\u517c\u5bb9\u3002\u5b9e\u9a8c\u8bc1\u660eGasAgent\u80fd\u663e\u8457\u8282\u7701Gas\uff0c\u5e76\u80fd\u4f18\u5316LLM\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\uff0c\u662fLLM\u8f85\u52a9\u5f00\u53d1\u7684\u4e00\u4e2a\u6709\u6548\u4f18\u5316\u5c42\u3002", "motivation": "\u73b0\u6709\u7684\u667a\u80fd\u5408\u7ea6Gas\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u624b\u52a8\u53d1\u73b0\uff0c\u6548\u7387\u4f4e\u4e0b\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u867d\u7136\u8fd1\u671f\u7814\u7a76\u5c1d\u8bd5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u53d1\u73b0\u65b0\u7684Gas\u6d6a\u8d39\u6a21\u5f0f\uff0c\u4f46\u4ecd\u5b58\u5728\u4e0e\u73b0\u6709\u6a21\u5f0f\u517c\u5bb9\u6027\u4e0d\u8db3\u3001\u4ea7\u751f\u5197\u4f59\u6a21\u5f0f\u4ee5\u53ca\u9700\u8981\u624b\u52a8\u9a8c\u8bc1/\u91cd\u5199\u7b49\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u8db3\uff0cGasAgent\u88ab\u63d0\u51fa\u3002", "method": "GasAgent\u91c7\u7528\u4e86\u4e00\u4e2a\u5305\u542b\u201c\u63a2\u5bfb\u8005\u201d\u3001\u201c\u521b\u65b0\u8005\u201d\u3001\u201c\u6267\u884c\u8005\u201d\u548c\u201c\u7ba1\u7406\u8005\u201d\u56db\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u95ed\u73af\u534f\u4f5c\u6765\u8bc6\u522b\u3001\u9a8c\u8bc1\u548c\u5e94\u7528\u8282\u7701Gas\u7684\u6539\u8fdb\u63aa\u65bd\u3002", "result": "\u5728100\u4e2a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u771f\u5b9e\u4e16\u754c\u5408\u7ea6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cGasAgent\u6210\u529f\u4f18\u5316\u4e8682\u4e2a\u5408\u7ea6\uff0c\u5b9e\u73b0\u4e86\u5e73\u57479.97%\u7684\u90e8\u7f72Gas\u8282\u7701\u3002\u5bf9500\u4e2a\u7531\u4e94\u79cd\u4ee3\u8868\u6027LLM\u751f\u6210\u7684\u5408\u7ea6\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0cGasAgent\u4f18\u5316\u4e86\u5176\u4e2d79.8%\u7684\u5408\u7ea6\uff0c\u90e8\u7f72Gas\u8282\u7701\u91cf\u57284.79%\u523013.93%\u4e4b\u95f4\u3002\u8bc4\u4f30\u8fd8\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u786e\u8ba4\u4e86\u5176\u4e0e\u73b0\u6709\u5de5\u5177\u7684\u517c\u5bb9\u6027\u4ee5\u53ca\u5404\u6a21\u5757\u7684\u6709\u6548\u6027\u3002", "conclusion": "GasAgent\u4f5c\u4e3a\u4e00\u4e2a\u9996\u4e2a\u667a\u80fd\u5408\u7ea6Gas\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u6a21\u5f0f\u7684\u517c\u5bb9\u6027\u4ee5\u53ca\u65b0\u6a21\u5f0f\u7684\u81ea\u52a8\u5316\u53d1\u73b0\u4e0e\u9a8c\u8bc1\uff0c\u80fd\u591f\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u4f18\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGasAgent\u5728100\u4e2a\u771f\u5b9e\u4e16\u754c\u5408\u7ea6\u7684\u4f18\u5316\u4e2d\uff0c\u6210\u529f\u4f18\u5316\u4e8682\u4e2a\u5408\u7ea6\uff0c\u5e73\u5747\u90e8\u7f72Gas\u8282\u7701\u4e869.97%\u3002\u6b64\u5916\uff0c\u5728\u5bf9500\u4e2a\u7531\u4e0d\u540cLLM\u751f\u6210\u7684\u5408\u7ea6\u8fdb\u884c\u7684\u8bc4\u4f30\u4e2d\uff0cGasAgent\u4f18\u5316\u4e8679.8%\u7684\u5408\u7ea6\uff0cGas\u8282\u7701\u91cf\u57284.79%\u523013.93%\u4e4b\u95f4\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3aLLM\u8f85\u52a9\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u4f18\u5316\u5c42\u7684\u5e7f\u6cdb\u53ef\u7528\u6027\u3002"}}
{"id": "2507.14748", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.14748", "abs": "https://arxiv.org/abs/2507.14748", "authors": ["Patrik Reizinger", "B\u00e1lint Mucs\u00e1nyi", "Siyuan Guo", "Benjamin Eysenbach", "Bernhard Sch\u00f6lkopf", "Wieland Brendel"], "title": "Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning", "comment": "16 pages, 7 figures", "summary": "Self-supervised feature learning and pretraining methods in reinforcement\nlearning (RL) often rely on information-theoretic principles, termed mutual\ninformation skill learning (MISL). These methods aim to learn a representation\nof the environment while also incentivizing exploration thereof. However, the\nrole of the representation and mutual information parametrization in MISL is\nnot yet well understood theoretically. Our work investigates MISL through the\nlens of identifiable representation learning by focusing on the Contrastive\nSuccessor Features (CSF) method. We prove that CSF can provably recover the\nenvironment's ground-truth features up to a linear transformation due to the\ninner product parametrization of the features and skill diversity in a\ndiscriminative sense. This first identifiability guarantee for representation\nlearning in RL also helps explain the implications of different mutual\ninformation objectives and the downsides of entropy regularizers. We\nempirically validate our claims in MuJoCo and DeepMind Control and show how CSF\nprovably recovers the ground-truth features both from states and pixels.", "AI": {"tldr": "CSF\u662fMISL\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6062\u590d\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\uff0c\u5e76\u4e14\u5177\u6709\u53ef\u8bc6\u522b\u6027\u4fdd\u8bc1\u3002", "motivation": "MISL\u4e2d\u7684\u8868\u793a\u548c\u4e92\u4fe1\u606f\u53c2\u6570\u5316\u7684\u4f5c\u7528\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u5173\u6ce8\u5bf9\u6bd4\u6027\u540e\u7ee7\u7279\u5f81\uff08CSF\uff09\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u53ef\u8bc6\u522b\u8868\u793a\u5b66\u4e60\u7684\u89c6\u89d2\u6765\u7814\u7a76MISL\u3002", "result": "CSF\u80fd\u591f\u6062\u590d\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\uff0c\u5e76\u4e14\u5728MuJoCo\u548cDeepMind\u63a7\u5236\u4e2d\u5f97\u5230\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "CSF\u53ef\u4ee5\u51ed\u501f\u5176\u5185\u79ef\u53c2\u6570\u5316\u548c\u8fa8\u522b\u610f\u4e49\u4e0a\u7684\u6280\u80fd\u591a\u6837\u6027\uff0c\u53ef\u8bc1\u660e\u5730\u5c06\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\u6062\u590d\u5230\u7ebf\u6027\u53d8\u6362\u7684\u7a0b\u5ea6\u3002\u8fd9\u662fRL\u4e2d\u5173\u4e8e\u53ef\u8bc6\u522b\u8868\u793a\u5b66\u4e60\u7684\u7b2c\u4e00\u4e2a\u4fdd\u8bc1\uff0c\u6709\u52a9\u4e8e\u89e3\u91ca\u4e0d\u540c\u4e92\u4fe1\u606f\u76ee\u6807\u548c\u71b5\u6b63\u5219\u5316\u7f3a\u70b9\u7684\u542b\u4e49\u3002"}}
{"id": "2507.15619", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15619", "abs": "https://arxiv.org/abs/2507.15619", "authors": ["Qiyi Li", "Shaoqiang Ma", "Sansheng Wang", "Xiao Zheng", "Guofeng Zhang"], "title": "Dynamic Investigation of the New Quantum-Control-Assisted Reverse uncertainty relation", "comment": "11 pages, 9 figures", "summary": "Recently, a new interesting concept of reverse uncertainty relation is\nintroduced. Different from the normal uncertainty relation, the reverse one\nindicates that one cannot only prepare quantum states with joint small\nuncertainty, but also with joint great uncertainty for incompatible\nobservables. We in this work construct a new quantum-control-assisted reverse\nuncertainty relation and investigate the corresponding dynamic evolution in the\nHeisenberg model with Dzyaloshinskii-Moriya interaction. The obtained relation\nindicates that the reverse uncertainty can be broken with help of the quantum\ncontrol system. The dynamic investigation reveals that there exists an\ninteresting single-value relationship between new uncertainty relation and the\nmixedness of the system, indicating that the tightness and upper bound of the\nuncertainty relation can be written as functional form of the mixedness. By\ncomparing the existing research in [Physica Scripta 2023, 98(6), 065113], we\nshow that the single-value relationship with the mixedness is the common nature\nof both the normal uncertainty relations and the reverse uncertainty relation.", "AI": {"tldr": "\u901a\u8fc7\u91cf\u5b50\u63a7\u5236\u6253\u7834\u53cd\u5411\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\uff0c\u5e76\u53d1\u73b0\u5176\u4e0e\u7cfb\u7edf\u6df7\u5408\u5ea6\u5b58\u5728\u51fd\u6570\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u53cd\u5411\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5982\u4f55\u901a\u8fc7\u91cf\u5b50\u63a7\u5236\u6765\u5f71\u54cd\u5b83\uff0c\u4ee5\u53ca\u5b83\u4e0e\u7cfb\u7edf\u6df7\u5408\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u63a7\u5236\u8f85\u52a9\u53cd\u5411\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5728\u5177\u6709\u5fb7\u96c5\u6d1b\u7533\u65af\u57fa-\u83ab\u91cc\u4e9a\u76f8\u4e92\u4f5c\u7528\u7684\u6d77\u68ee\u5821\u6a21\u578b\u4e2d\u7684\u52a8\u6001\u6f14\u5316\u3002", "result": "\u53cd\u5411\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\u53ef\u4ee5\u88ab\u91cf\u5b50\u63a7\u5236\u6253\u7834\uff0c\u5e76\u4e14\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\u7684\u7d27\u5bc6\u5ea6\u548c\u4e0a\u9650\u53ef\u4ee5\u8868\u793a\u4e3a\u7cfb\u7edf\u6df7\u5408\u5ea6\u7684\u51fd\u6570\u3002", "conclusion": "\u65b0\u6784\u9020\u7684\u91cf\u5b50\u63a7\u5236\u8f85\u52a9\u53cd\u5411\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\u53ef\u4ee5\u5728\u91cf\u5b50\u63a7\u5236\u7cfb\u7edf\u7684\u5e2e\u52a9\u4e0b\u88ab\u6253\u7834\uff0c\u5e76\u4e14\u8be5\u5173\u7cfb\u4e0e\u7cfb\u7edf\u7684\u6df7\u5408\u5ea6\u5b58\u5728\u5355\u503c\u5173\u7cfb\uff0c\u800c\u8fd9\u79cd\u5173\u7cfb\u662f\u6807\u51c6\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\u548c\u53cd\u5411\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\u7684\u5171\u540c\u7279\u6027\u3002"}}
{"id": "2507.15236", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15236", "abs": "https://arxiv.org/abs/2507.15236", "authors": ["Shayan Vassef", "Amirhossein Dabiriaghdam", "Mohammadreza Bakhtiari", "Yadollah Yaghoobzadeh"], "title": "SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest", "comment": null, "summary": "This work investigates the impact of multi-task, multi-lingual, and\nmulti-source learning approaches on the robustness and performance of\npretrained language models. To enhance this analysis, we introduce Subsets of\nInterest (SOI), a novel categorization framework that identifies six distinct\nlearning behavior patterns during training, including forgettable examples,\nunlearned examples, and always correct examples. Through SOI transition\nheatmaps and dataset cartography visualization, we analyze how examples shift\nbetween these categories when transitioning from single-setting to\nmulti-setting configurations. We perform comprehensive experiments across three\nparallel comparisons: multi-task vs. single-task learning using English tasks\n(entailment, paraphrase, sentiment), multi-source vs. single-source learning\nusing sentiment analysis datasets, and multi-lingual vs. single-lingual\nlearning using intent classification in French, English, and Persian. Our\nresults demonstrate that multi-source learning consistently improves\nout-of-distribution performance by up to 7%, while multi-task learning shows\nmixed results with notable gains in similar task combinations. We further\nintroduce a two-stage fine-tuning approach where the second stage leverages\nSOI-based subset selection to achieve additional performance improvements.\nThese findings provide new insights into training dynamics and offer practical\napproaches for optimizing multi-setting language model performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165SOI\u5206\u7c7b\u6846\u67b6\uff0c\u5206\u6790\u591a\u4efb\u52a1\u3001\u591a\u6e90\u3001\u591a\u8bed\u8a00\u5b66\u4e60\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\u3002\u53d1\u73b0\u591a\u6e90\u5b66\u4e60\u663e\u8457\u63d0\u5347\u5206\u5e03\u5916\u6027\u80fd\uff0c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u76f8\u4f3c\u4efb\u52a1\u4e0a\u6709\u589e\u76ca\u3002\u63d0\u51fa\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9c81\u68d2\u6027\u548c\u6027\u80fd\u7684\u5206\u6790\uff0c\u8be5\u7814\u7a76\u5f15\u5165\u4e86SOI\uff08Subsets of Interest\uff09\u8fd9\u4e00\u65b0\u9896\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u65e8\u5728\u8bc6\u522b\u548c\u7406\u89e3\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u884c\u4e3a\u7684\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u5f15\u5165SOI\uff08Subsets of Interest\uff09\u65b0\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u51fa\u516d\u79cd\u4e0d\u540c\u7684\u8bad\u7ec3\u884c\u4e3a\u6a21\u5f0f\uff0c\u5305\u62ec\u6613\u5fd8\u793a\u4f8b\u3001\u672a\u5b66\u793a\u4f8b\u548c\u4e00\u76f4\u6b63\u786e\u793a\u4f8b\u3002\u5229\u7528SOI\u8f6c\u6362\u70ed\u56fe\u548c\u6570\u636e\u96c6\u5236\u56fe\u53ef\u89c6\u5316\u6280\u672f\uff0c\u5206\u6790\u4e86\u4ece\u5355\u4e00\u8bbe\u7f6e\u5230\u591a\u91cd\u8bbe\u7f6e\u914d\u7f6e\u7684\u793a\u4f8b\u8fc1\u79fb\u8fc7\u7a0b\u3002\u8fdb\u884c\u4e86\u4e09\u7ec4\u5e73\u884c\u6bd4\u8f83\u5b9e\u9a8c\uff1a\u591a\u4efb\u52a1\u4e0e\u5355\u4efb\u52a1\u5b66\u4e60\uff08\u82f1\u8bed\u4efb\u52a1\uff09\u3001\u591a\u6e90\u4e0e\u5355\u6e90\u5b66\u4e60\uff08\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\uff09\u3001\u591a\u8bed\u8a00\u4e0e\u5355\u8bed\u8a00\u5b66\u4e60\uff08\u6cd5\u8bed\u3001\u82f1\u8bed\u3001\u6ce2\u65af\u8bed\u7684\u610f\u56fe\u5206\u7c7b\uff09\u3002", "result": "\u591a\u6e90\u5b66\u4e60\u80fd\u6301\u7eed\u63d0\u5347\u9ad8\u8fbe7%\u7684\u5206\u5e03\u5916\u6027\u80fd\uff0c\u800c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u76f8\u4f3c\u4efb\u52a1\u7ec4\u5408\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\uff0c\u4f46\u7ed3\u679c\u559c\u5fe7\u53c2\u534a\u3002SOI\u8f6c\u6362\u70ed\u56fe\u548c\u6570\u636e\u96c6\u5236\u56fe\u53ef\u89c6\u5316\u6280\u672f\u63ed\u793a\u4e86\u793a\u4f8b\u5728\u4e0d\u540c\u8bbe\u7f6e\u95f4\u7684\u8fc1\u79fb\u6a21\u5f0f\u3002", "conclusion": "\u591a\u6e90\u5b66\u4e60\u80fd\u6301\u7eed\u63d0\u5347\u9ad8\u8fbe7%\u7684\u5206\u5e03\u5916\u6027\u80fd\uff0c\u800c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u76f8\u4f3c\u4efb\u52a1\u7ec4\u5408\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\uff0c\u4f46\u7ed3\u679c\u559c\u5fe7\u53c2\u534a\u3002\u901a\u8fc7\u5f15\u5165\u57fa\u4e8eSOI\uff08Subsets of Interest\uff09\u7684\u5b50\u96c6\u9009\u62e9\u7684\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.14823", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14823", "abs": "https://arxiv.org/abs/2507.14823", "authors": ["Dong Shu", "Haoyang Yuan", "Yuchen Wang", "Yanguang Liu", "Huopu Zhang", "Haiyan Zhao", "Mengnan Du"], "title": "FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models", "comment": "20 Pages, 18 Figures", "summary": "Large vision-language models (LVLMs) have made significant progress in chart\nunderstanding. However, financial charts, characterized by complex temporal\nstructures and domain-specific terminology, remain notably underexplored. We\nintroduce FinChart-Bench, the first benchmark specifically focused on\nreal-world financial charts. FinChart-Bench comprises 1,200 financial chart\nimages collected from 2015 to 2024, each annotated with True/False (TF),\nMultiple Choice (MC), and Question Answering (QA) questions, totaling 7,016\nquestions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs\non FinChart-Bench. Our evaluation reveals critical insights: (1) the\nperformance gap between open-source and closed-source models is narrowing, (2)\nperformance degradation occurs in upgraded models within families, (3) many\nmodels struggle with instruction following, (4) both advanced models show\nsignificant limitations in spatial reasoning abilities, and (5) current LVLMs\nare not reliable enough to serve as automated evaluators. These findings\nhighlight important limitations in current LVLM capabilities for financial\nchart understanding. The FinChart-Bench dataset is available at\nhttps://huggingface.co/datasets/Tizzzzy/FinChart-Bench.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15770", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15770", "abs": "https://arxiv.org/abs/2507.15770", "authors": ["Yifan Shen", "Zihan Zhao", "Xiao Xue", "Yuwei Guo", "Qun Ma", "Deyu Zhou", "Ming Zhang"], "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining", "comment": null, "summary": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.", "AI": {"tldr": "EAMI\u662f\u4e00\u4e2a\u7528\u4e8e\u52a8\u6001\u548c\u53ef\u89e3\u91ca\u6d8c\u73b0\u5206\u6790\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u89c6\u89d2\u601d\u7ef4\u8f68\u8ff9\u3001k-means\u805a\u7c7b\u548c\u610f\u56fe\u65f6\u95f4\u6d8c\u73b0\u56fe\u6765\u5206\u6790\u667a\u80fd\u4f53\u610f\u56fe\uff0c\u4ee5\u89e3\u51b3\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u4e2d\u5f02\u5e38\u6d8c\u73b0\u5206\u6790\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u5f02\u5e38\u6d8c\u73b0\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u667a\u80fd\u4f53\u4e4b\u95f4\u590d\u6742\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u56e0\u4e3a\u4f20\u7edf\u56e0\u679c\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u4e2a\u4f53\u8f68\u8ff9\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u4e3a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u5efa\u6a21\uff08ABM\uff09\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u63ed\u793a\u667a\u80fd\u4f53\u7684\u610f\u56fe\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ecd\u5c40\u9650\u4e8e\u5fae\u89c2\u548c\u9759\u6001\u5206\u6790\u3002", "method": "EAMI\u6846\u67b6\u91c7\u7528\u53cc\u89c6\u89d2\u601d\u7ef4\u8f68\u8ff9\u673a\u5236\uff0c\u901a\u8fc7\u68c0\u67e5\u4ee3\u7406\u548c\u5206\u6790\u4ee3\u7406\u5728\u6709\u754c\u548c\u5b8c\u7f8e\u7406\u6027\u4e0b\u63d0\u53d6\u4ee3\u7406\u610f\u56fe\uff0c\u5e76\u5229\u7528k-means\u805a\u7c7b\u8bc6\u522b\u7fa4\u4f53\u610f\u56fe\u7684\u76f8\u53d8\u70b9\uff0c\u6700\u540e\u901a\u8fc7\u610f\u56fe\u65f6\u95f4\u6d8c\u73b0\u56fe\u8fdb\u884c\u52a8\u6001\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u5728\u590d\u6742\u7684\u7ebf\u4e0a\u5230\u7ebf\u4e0b\uff08O2O\uff09\u670d\u52a1\u7cfb\u7edf\u548c\u65af\u5766\u798fAI Town\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86EAMI\u7684\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u786e\u8ba4\u4e86\u5176\u6548\u679c\u3002", "conclusion": "EAMI\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8303\u5f0f\uff0c\u7528\u4e8e\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u4e2d\u5f02\u5e38\u6d8c\u73b0\u548c\u56e0\u679c\u5206\u6790\u3002"}}
{"id": "2507.14766", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14766", "abs": "https://arxiv.org/abs/2507.14766", "authors": ["Mehak Arora", "Ayman Ali", "Kaiyuan Wu", "Carolyn Davis", "Takashi Shimazui", "Mahmoud Alwakeel", "Victor Moas", "Philip Yang", "Annette Esper", "Rishikesan Kamaleswaran"], "title": "CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories", "comment": "In Review for MICCAI 2025", "summary": "In intensive care units (ICUs), patients with complex clinical conditions\nrequire vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a\nvital diagnostic tool, providing insights into clinical trajectories, but their\nirregular acquisition limits their utility. Existing tools for CXR\ninterpretation are constrained by cross-sectional analysis, failing to capture\ntemporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal\nframework that integrates temporally sparse CXR imaging and radiology reports\nwith high-frequency clinical data, such as vital signs, laboratory values, and\nrespiratory flow sheets, to predict the trajectory of CXR findings in\ncritically ill patients. CXR-TFT leverages latent embeddings from a vision\nencoder that are temporally aligned with hourly clinical data through\ninterpolation. A transformer model is then trained to predict CXR embeddings at\neach hour, conditioned on previous embeddings and clinical measurements. In a\nretrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy\nin forecasting abnormal CXR findings up to 12 hours before they became\nradiographically evident. This predictive capability in clinical data holds\nsignificant potential for enhancing the management of time-sensitive conditions\nlike acute respiratory distress syndrome, where early intervention is crucial\nand diagnoses are often delayed. By providing distinctive temporal resolution\nin prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights\nthat can directly improve clinical outcomes.", "AI": {"tldr": "CXR-TFT\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408X\u5149\u5f71\u50cf\u548c\u4e34\u5e8a\u6570\u636e\uff0c\u53ef\u4ee5\u63d0\u524d12\u5c0f\u65f6\u9884\u6d4bICU\u60a3\u8005\u7684X\u5149\u7ed3\u679c\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u60a3\u8005\u6cbb\u7597\u3002", "motivation": "\u73b0\u6709\u80f8\u90e8X\u5149\u89e3\u8bfb\u5de5\u5177\u4ec5\u9650\u4e8e\u6a2a\u65ad\u9762\u5206\u6790\uff0c\u65e0\u6cd5\u6355\u6349\u65f6\u95f4\u52a8\u6001\u3002\u5371\u91cd\u75c7\u60a3\u8005\u9700\u8981\u5bc6\u5207\u76d1\u6d4b\u548c\u53ca\u65f6\u5e72\u9884\uff0c\u800c\u80f8\u90e8X\u5149\u68c0\u67e5\u7684\u975e\u89c4\u5f8b\u6027\u83b7\u53d6\u9650\u5236\u4e86\u5176\u6548\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u65f6\u95f4\u52a8\u6001\u4fe1\u606f\u7684\u65b0\u578b\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCXR-TFT\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5229\u7528\u89c6\u89c9\u7f16\u7801\u5668\u63d0\u53d6\u80f8\u90e8X\u5149\u5f71\u50cf\u7684\u6f5c\u5728\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u63d2\u503c\u65f6\u95f4\u5bf9\u9f50\uff0c\u4e0e\u6bcf\u5c0f\u65f6\u7684\u4e34\u5e8a\u6570\u636e\u8fdb\u884c\u6574\u5408\u3002\u968f\u540e\uff0c\u8bad\u7ec3\u4e00\u4e2aTransformer\u6a21\u578b\uff0c\u4ee5\u4e4b\u524d\u7684\u5d4c\u5165\u548c\u4e34\u5e8a\u6d4b\u91cf\u503c\u4e3a\u6761\u4ef6\uff0c\u9884\u6d4b\u6bcf\u5c0f\u65f6\u7684\u80f8\u90e8X\u5149\u5d4c\u5165\u3002", "result": "\u5728\u5bf920,000\u540dICU\u60a3\u8005\u7684\u56de\u987e\u6027\u7814\u7a76\u4e2d\uff0cCXR-TFT\u5728\u9884\u6d4b\u653e\u5c04\u5b66\u68c0\u67e5\u524d12\u5c0f\u65f6\u5185\u5f02\u5e38\u80f8\u90e8X\u5149\u7ed3\u679c\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "CXR-TFT\u901a\u8fc7\u6574\u5408\u7a00\u758f\u7684\u80f8\u90e8X\u5149\u5f71\u50cf\u3001\u653e\u5c04\u5b66\u62a5\u544a\u548c\u9ad8\u9891\u4e34\u5e8a\u6570\u636e\uff08\u5982\u751f\u547d\u4f53\u5f81\u3001\u5b9e\u9a8c\u5ba4\u503c\u548c\u547c\u5438\u6d41\u7a0b\u8868\uff09\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5371\u91cd\u75c7\u60a3\u8005\u7684\u80f8\u90e8X\u5149\u7ed3\u679c\u53d8\u5316\uff0c\u9884\u6d4b\u65f6\u95f4\u53ef\u8fbe12\u5c0f\u65f6\uff0c\u4e3a\u6539\u5584\u6025\u6027\u547c\u5438\u7a98\u8feb\u7efc\u5408\u5f81\u7b49\u75be\u75c5\u7684\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u4e34\u5e8a\u89c1\u89e3\u3002"}}
{"id": "2507.15627", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15627", "abs": "https://arxiv.org/abs/2507.15627", "authors": ["Hua-Wei Zhao", "Gen Li", "Guo-Feng Zhang"], "title": "Enhancing Quantum Discord in V-shaped Plasmonic Waveguides by Quantum Feedback", "comment": "11 pages, 8 figures", "summary": "We investigate the impact of a symmetric quantum feedback control on the\nquantum discord of the X state in V-shaped plasmonic waveguides. Under this\nfeedback, the quantum discord of the Werner state is enhanced from 0 to 0.38.\nThis value even continues to rise after reducing the decay rate of the atoms.\nFurthermore, we get the operational mechanism of feedback control through the\nevolution of the matrix elements. It confines the initial 4 * 4 matrix into a 3\n* 3 subspace. As a result, the weights of each ground state in the quantum\nstate change, which suppresses the degradation of Bell state. Lastly, we\npropose a direction for suggesting an improved feedback Hamiltonian.", "AI": {"tldr": "\u901a\u8fc7\u91cf\u5b50\u53cd\u9988\u63a7\u5236\uff0c\u6539\u5584\u4e86\u91cf\u5b50\u6563\u5ea6\u548c\u8d1d\u5c14\u6001\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u5316\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u53cd\u9988\u63a7\u5236\u5bf9\u91cf\u5b50 \uc0c1\uad00\u5173\u7cfb\uff08\u7279\u522b\u662f\u91cf\u5b50\u6563\u5ea6\uff09\u7684\u5f71\u54cd\uff0c\u4ee5\u671f\u6539\u5584\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u9000\u76f8\u5e72\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf9\u79f0\u91cf\u5b50\u53cd\u9988\u63a7\u5236\uff0c\u7814\u7a76\u4e86\u5176\u5bf9V\u5f62\u7b49\u79bb\u4f53\u6ce2\u5bfc\u4e2dX\u6001\u91cf\u5b50\u6563\u5ea6\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u6f14\u5316\u77e9\u9635\u5143\u7d20\u63ed\u793a\u4e86\u5176\u4f5c\u7528\u673a\u5236\uff0c\u5c06\u521d\u59cb\u76844*4\u77e9\u9635\u9650\u5236\u57283*3\u5b50\u7a7a\u95f4\u5185\u3002", "result": "\u91cf\u5b50\u6563\u5ea6\u4ece0\u63d0\u9ad8\u52300.38\uff0c\u5e76\u4e14\u5728\u964d\u4f4e\u539f\u5b50\u8870\u51cf\u7387\u540e\u6301\u7eed\u5347\u9ad8\uff0c\u6210\u529f\u6291\u5236\u4e86\u8d1d\u5c14\u6001\u7684\u9000\u5316\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u5bf9\u79f0\u91cf\u5b50\u53cd\u9988\u63a7\u5236\u6539\u5584\u4e86X\u6001\u91cf\u5b50\u6563\u5ea6\u548c\u8d1d\u5c14\u6001\u7684\u9000\u5316\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u53cd\u9988\u54c8\u5bc6\u987f\u91cf\u63d0\u51fa\u4e86\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2507.15275", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15275", "abs": "https://arxiv.org/abs/2507.15275", "authors": ["Yuanhe Tian", "Junjie Liu", "Zhizhou Kou", "Yuxiang Li", "Yan Song"], "title": "ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling", "comment": null, "summary": "Building high-quality data resources is crucial for advancing artificial\nintelligence research and applications in specific domains, particularly in the\nChinese medical domain. Existing Chinese medical datasets are limited in size\nand narrow in domain coverage, falling short of the diverse corpora required\nfor effective pre-training. Moreover, most datasets are designed solely for LLM\nfine-tuning and do not support pre-training and reinforcement learning from\nhuman feedback (RLHF). In this paper, we propose a Chinese medical dataset\nnamed ChiMed 2.0, which extends our previous work ChiMed, and covers data\ncollected from Chinese medical online platforms and generated by LLMs. ChiMed\n2.0 contains 204.4M Chinese characters covering both traditional Chinese\nmedicine classics and modern general medical data, where there are 164.8K\ndocuments for pre-training, 351.6K question-answering pairs for supervised\nfine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the\neffectiveness of our approach for training a Chinese medical LLM, we conduct\nfurther pre-training, SFT, and RLHF experiments on representative general\ndomain LLMs and evaluate their performance on medical benchmark datasets. The\nresults show performance gains across different model scales, validating the\ndataset's effectiveness and applicability.", "AI": {"tldr": "ChiMed 2.0 \u662f\u4e00\u4e2a\u5305\u542b 2.044 \u4ebf\u5b57\u7b26\u7684\u5927\u89c4\u6a21\u4e2d\u6587\u533b\u7597\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u9884\u8bad\u7ec3\u3001SFT \u548c RLHF\uff0c\u65e8\u5728\u63d0\u5347\u4e2d\u6587\u533b\u7597\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4e2d\u6587\u533b\u7597\u6570\u636e\u96c6\u5728\u89c4\u6a21\u548c\u9886\u57df\u8986\u76d6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6709\u6548\u9884\u8bad\u7ec3\u7684\u9700\u6c42\u3002\u6b64\u5916\uff0c\u5927\u591a\u6570\u6570\u636e\u96c6\u4ec5\u652f\u6301 LLM \u5fae\u8c03\uff0c\u4e0d\u652f\u6301\u9884\u8bad\u7ec3\u548c RLHF\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a ChiMed 2.0 \u7684\u4e2d\u6587\u533b\u7597\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u6765\u81ea\u4e2d\u6587\u5728\u7ebf\u533b\u7597\u5e73\u53f0\u7684\u6570\u636e\u548c\u7531\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b 2.044 \u4ebf\u4e2d\u6587\u5b57\u7b26\uff0c\u6db5\u76d6\u4e86\u4f20\u7edf\u4e2d\u533b\u836f\u7ecf\u5178\u548c\u73b0\u4ee3\u7efc\u5408\u533b\u7597\u6570\u636e\u3002\u6570\u636e\u96c6\u5305\u62ec 164.8K \u4e2a\u7528\u4e8e\u9884\u8bad\u7ec3\u7684\u6587\u6863\uff0c351.6K \u4e2a\u7528\u4e8e\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7684\u95ee\u7b54\u5bf9\uff0c\u4ee5\u53ca 41.7K \u4e2a\u7528\u4e8e\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u7684\u504f\u597d\u6570\u636e\u5143\u7ec4\u3002\u901a\u8fc7\u5728\u4ee3\u8868\u6027\u901a\u7528\u5927\u6a21\u578b\u4e0a\u8fdb\u884c\u8fdb\u4e00\u6b65\u9884\u8bad\u7ec3\u3001SFT \u548c RLHF \u5b9e\u9a8c\uff0c\u5e76\u5728\u533b\u7597\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u6570\u636e\u96c6\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u4ee3\u8868\u6027\u901a\u7528\u5927\u6a21\u578b\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3001SFT \u548c RLHF \u5b9e\u9a8c\uff0c\u5e76\u5728\u533b\u7597\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e ChiMed 2.0 \u6570\u636e\u96c6\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\u5747\u80fd\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "ChiMed 2.0 \u7684\u6709\u6548\u6027\u548c\u9002\u7528\u6027\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u80fd\u591f\u63d0\u5347\u4e2d\u6587\u533b\u7597\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15255", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15255", "abs": "https://arxiv.org/abs/2507.15255", "authors": ["Deyun Zhang", "Xiang Lan", "Shijia Geng", "Qinghao Zhao", "Sumei Fan", "Mengling Feng", "Shenda Hong"], "title": "MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations", "comment": null, "summary": "Electrocardiogram (ECG) plays a foundational role in modern cardiovascular\ncare, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and\nconduction disorders. While machine learning has achieved expert-level\nperformance in ECG interpretation, the development of clinically deployable\nmultimodal AI systems remains constrained, primarily due to the lack of\npublicly available datasets that simultaneously incorporate raw signals,\ndiagnostic images, and interpretation text. Most existing ECG datasets provide\nonly single-modality data or, at most, dual modalities, making it difficult to\nbuild models that can understand and integrate diverse ECG information in\nreal-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext\nECG-Text-Image), the first large-scale ECG dataset that synchronizes raw\nwaveform data, high-resolution plotted images, and detailed textual\ninterpretations generated by large language models. In addition, MEETI includes\nbeat-level quantitative ECG parameters extracted from each lead, offering\nstructured parameters that support fine-grained analysis and model\ninterpretability. Each MEETI record is aligned across four components: (1) the\nraw ECG waveform, (2) the corresponding plotted image, (3) extracted feature\nparameters, and (4) detailed interpretation text. This alignment is achieved\nusing consistent, unique identifiers. This unified structure supports\ntransformer-based multimodal learning and supports fine-grained, interpretable\nreasoning about cardiac health. By bridging the gap between traditional signal\nanalysis, image-based interpretation, and language-driven understanding, MEETI\nestablished a robust foundation for the next generation of explainable,\nmultimodal cardiovascular AI. It offers the research community a comprehensive\nbenchmark for developing and evaluating ECG-based AI systems.", "AI": {"tldr": "MEETI\uff1a\u9996\u4e2a\u591a\u6a21\u6001 ECG \u6570\u636e\u96c6\uff0c\u5305\u542b\u539f\u59cb\u6ce2\u5f62\u3001\u56fe\u50cf\u548c\u6587\u672c\uff0c\u63a8\u52a8\u53ef\u89e3\u91ca\u7684\u5fc3\u8840\u7ba1 AI \u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7684 ECG \u6570\u636e\u96c6\u591a\u4e3a\u5355\u6a21\u6001\u6216\u53cc\u6a21\u6001\uff0c\u96be\u4ee5\u6784\u5efa\u80fd\u7406\u89e3\u548c\u6574\u5408\u591a\u6e90 ECG \u4fe1\u606f\u7684\u4e34\u5e8a AI \u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86 MEETI \u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u539f\u59cb ECG \u6ce2\u5f62\u3001\u7ed8\u56fe\u56fe\u50cf\u3001\u63d0\u53d6\u7684\u53c2\u6570\u548c\u6587\u672c\u89e3\u91ca\uff0c\u5e76\u4f7f\u7528\u4e00\u81f4\u7684\u6807\u8bc6\u7b26\u8fdb\u884c\u5bf9\u9f50\u3002", "result": "MEETI \u6570\u636e\u96c6\u652f\u6301\u57fa\u4e8e Transformer \u7684\u591a\u6a21\u6001\u5b66\u4e60\uff0c\u80fd\u591f\u5bf9\u5fc3\u810f\u5065\u5eb7\u8fdb\u884c\u7ec6\u7c92\u5ea6\u3001\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u4e3a ECG AI \u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u57fa\u51c6\u3002", "conclusion": "MEETI \u662f\u9996\u4e2a\u5927\u89c4\u6a21\u540c\u6b65\u5305\u542b\u539f\u59cb\u6ce2\u5f62\u6570\u636e\u3001\u9ad8\u5206\u8fa8\u7387\u7ed8\u56fe\u56fe\u50cf\u548c\u8be6\u7ec6\u6587\u672c\u89e3\u91ca\u7684 ECG \u6570\u636e\u96c6\uff0c\u4e3a\u591a\u6a21\u6001\u5fc3\u8840\u7ba1 AI \u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15597", "categories": ["cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15597", "abs": "https://arxiv.org/abs/2507.15597", "authors": ["Hao Luo", "Yicheng Feng", "Wanpeng Zhang", "Sipeng Zheng", "Ye Wang", "Haoqi Yuan", "Jiazheng Liu", "Chaoyi Xu", "Qin Jin", "Zongqing Lu"], "title": "Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos", "comment": "37 pages", "summary": "We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained\non large-scale human videos. Existing VLAs struggle with complex manipulation\ntasks requiring high dexterity and generalize poorly to novel scenarios and\ntasks, primarily due to their reliance on synthetic data with significant\nsim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To\naddress this data bottleneck, we propose leveraging human hands as a foundation\nmanipulator, capitalizing on the rich dexterity and scalability present in web\ndata. Our approach centers on physical instruction tuning, a novel training\nparadigm that combines large-scale VLA pretraining from human videos, physical\nspace alignment for 3D reasoning, and post-training adaptation for robotic\ntasks. Additionally, we introduce a part-level motion tokenization method which\nachieves millimeter-level reconstruction accuracy to model precise hand\ntrajectories for action learning. To support our proposed paradigm, we further\ndevelop a comprehensive data curation pipeline that integrates heterogeneous\nsources -- including motion capture, VR, and RGB-only videos -- into a\nlarge-scale dataset with millions of motion-based instructional instances. We\nempirically show the excellence of Being-H0 in hand motion generation and\ninstruction following, and it also scales well with model and data sizes.\nImportantly, we observe the expected gains of Being-H0 in real-world robotic\nmanipulation as physical instruction tuning is applied. More details are\navailable at https://beingbeyond.github.io/Being-H0.", "AI": {"tldr": "Being-H0\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u89c4\u6a21\u4eba\u7c7b\u89c6\u9891\u8bad\u7ec3\u7684\u7075\u5de7\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u7269\u7406\u6307\u4ee4\u8c03\u4f18\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u624b\u90e8\u8fd0\u52a8\u751f\u6210\u548c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709VLA\u6a21\u578b\u5728\u5904\u7406\u9700\u8981\u9ad8\u7075\u5de7\u6027\u7684\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u4ee5\u53ca\u5728\u65b0\u573a\u666f\u548c\u4efb\u52a1\u4e0a\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8be5\u7814\u7a76\u63d0\u51fa\u5229\u7528\u4eba\u7c7b\u624b\u90e8\u4f5c\u4e3a\u57fa\u7840\u64cd\u7eb5\u5668\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u74f6\u9888\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBeing-H0\u7684\u7075\u5de7\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u5305\u62ec\u8fd0\u52a8\u6355\u6349\u3001VR\u548c\u7eafRGB\u89c6\u9891\u5728\u5185\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\u7269\u7406\u6307\u4ee4\u8c03\u4f18\uff0c\u5305\u62ec\u5927\u89c4\u6a21VLA\u9884\u8bad\u7ec3\u3001\u7269\u7406\u7a7a\u95f4\u5bf9\u9f50\u548c\u673a\u5668\u4eba\u4efb\u52a1\u7684\u540e\u8bad\u7ec3\u9002\u5e94\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u5b9e\u73b0\u6beb\u7c73\u7ea7\u91cd\u5efa\u7cbe\u5ea6\u7684\u90e8\u4ef6\u7ea7\u8fd0\u52a8\u6807\u8bb0\u65b9\u6cd5\uff0c\u7528\u4e8e\u7cbe\u786e\u7684\u624b\u90e8\u8f68\u8ff9\u5efa\u6a21\u3002", "result": "Being-H0\u5728\u624b\u90e8\u8fd0\u52a8\u751f\u6210\u548c\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u6a21\u578b\u548c\u6570\u636e\u7684\u89c4\u6a21\u5316\u4e5f\u5e26\u6765\u4e86\u76f8\u5e94\u7684\u6027\u80fd\u63d0\u5347\u3002\u5728\u5c06\u7269\u7406\u6307\u4ee4\u8c03\u4f18\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u65f6\uff0c\u4e5f\u89c2\u5bdf\u5230\u4e86\u9884\u671f\u7684\u6536\u76ca\u3002", "conclusion": "Being-H0\u5728\u624b\u90e8\u8fd0\u52a8\u751f\u6210\u548c\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u80fd\u591f\u5f88\u597d\u5730\u968f\u7740\u6a21\u578b\u548c\u6570\u636e\u89c4\u6a21\u7684\u6269\u5c55\u800c\u6269\u5c55\u3002\u5728\u5c06\u7269\u7406\u6307\u4ee4\u8c03\u4f18\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u65f6\uff0c\u4e5f\u89c2\u5bdf\u5230\u4e86\u9884\u671f\u7684\u6536\u76ca\u3002"}}
{"id": "2507.14826", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14826", "abs": "https://arxiv.org/abs/2507.14826", "authors": ["Fu-Jen Tsai", "Yan-Tsung Peng", "Yen-Yu Lin", "Chia-Wen Lin"], "title": "PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing", "comment": "ICCV 2025", "summary": "Image dehazing aims to remove unwanted hazy artifacts in images. Although\nprevious research has collected paired real-world hazy and haze-free images to\nimprove dehazing models' performance in real-world scenarios, these models\noften experience significant performance drops when handling unseen real-world\nhazy images due to limited training data. This issue motivates us to develop a\nflexible domain adaptation method to enhance dehazing performance during\ntesting. Observing that predicting haze patterns is generally easier than\nrecovering clean content, we propose the Physics-guided Haze Transfer Network\n(PHATNet) which transfers haze patterns from unseen target domains to\nsource-domain haze-free images, creating domain-specific fine-tuning sets to\nupdate dehazing models for effective domain adaptation. Additionally, we\nintroduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to\nenhance PHATNet's disentanglement ability. Experimental results demonstrate\nthat PHATNet significantly boosts state-of-the-art dehazing models on benchmark\nreal-world image dehazing datasets.", "AI": {"tldr": "PHATNet \u662f\u4e00\u79cd\u65b0\u7684\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u5b83\u5c06 Haze \u6a21\u5f0f\u4ece\u770b\u4e0d\u89c1\u7684\u57df\u8f6c\u79fb\u5230\u65e0 Haze \u7684\u56fe\u50cf\uff0c\u4ee5\u6539\u8fdb\u53bb\u96fe\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u53bb\u96fe\u6a21\u578b\u5728\u5904\u7406\u770b\u4e0d\u89c1\u7684\u771f\u5b9e\u4e16\u754c Haze \u56fe\u50cf\u65f6\uff0c\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u6709\u9650\uff0c\u6027\u80fd\u4f1a\u663e\u7740\u4e0b\u964d\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e00\u79cd\u7075\u6d3b\u7684\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6d4b\u8bd5\u671f\u95f4\u7684\u53bb\u96fe\u6027\u80fd\u3002", "method": "PHATNet \u901a\u8fc7\u5c06\u65e0 Haze \u7684\u56fe\u50cf\u4e0e\u6765\u81ea\u770b\u4e0d\u89c1\u7684\u57df\u7684 Haze \u6a21\u5f0f\u76f8\u7ed3\u5408\uff0c\u6765\u751f\u6210\u7279\u5b9a\u9886\u57df\u7684\u5fae\u8c03\u96c6\uff0c\u4ee5\u66f4\u65b0\u53bb\u96fe\u6a21\u578b\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u57df\u9002\u5e94\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86 Haze-Transfer-Consistency \u635f\u5931\u548c Content-Leakage \u635f\u5931\u6765\u589e\u5f3a PHATNet \u7684\u5206\u79bb\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPHATNet \u663e\u7740\u63d0\u9ad8\u4e86\u6700\u5148\u8fdb\u7684\u53bb\u96fe\u6a21\u578b\u5728\u57fa\u51c6\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u53bb\u96fe\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "PHATNet \u663e\u7740\u63d0\u9ad8\u4e86\u6700\u5148\u8fdb\u7684\u53bb\u96fe\u6a21\u578b\u5728\u57fa\u51c6\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u53bb\u96fe\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15796", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15796", "abs": "https://arxiv.org/abs/2507.15796", "authors": ["Nuria Rodr\u00edguez-Barroso", "Mario Garc\u00eda-M\u00e1rquez", "M. Victoria Luz\u00f3n", "Francisco Herrera"], "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work", "comment": null, "summary": "In recent years, the development of Trustworthy Artificial Intelligence (TAI)\nhas emerged as a critical objective in the deployment of AI systems across\nsensitive and high-risk domains. TAI frameworks articulate a comprehensive set\nof ethical, legal, and technical requirements to ensure that AI technologies\nare aligned with human values, rights, and societal expectations. Among the\nvarious AI paradigms, Federated Learning (FL) presents a promising solution to\npressing privacy concerns. However, aligning FL with the rest of the\nrequirements of TAI presents a series of challenges, most of which arise from\nits inherently distributed nature. In this work, we adopt the requirements TAI\nas a guiding structure to systematically analyze the challenges of adapting FL\nto TAI. Specifically, we classify and examine the key obstacles to aligning FL\nwith TAI, providing a detailed exploration of what has been done, the trends,\nand the remaining work within each of the identified challenges.", "AI": {"tldr": "This paper analyzes how to make Federated Learning trustworthy by looking at TAI requirements and identifying challenges and solutions.", "motivation": "The development of Trustworthy Artificial Intelligence (TAI) is critical for deploying AI systems in sensitive domains. Federated Learning (FL) addresses privacy concerns, but aligning FL with TAI requirements presents challenges due to its distributed nature.", "method": "The paper adopts the requirements of TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. It classifies and examines key obstacles, providing a detailed exploration of what has been done, trends, and remaining work within each identified challenge.", "result": "The paper provides a classification and detailed exploration of the key obstacles to aligning FL with TAI, including current work, trends, and future research directions for each challenge.", "conclusion": "The paper systematically analyzes the challenges of adapting Federated Learning (FL) to Trustworthy Artificial Intelligence (TAI) by adopting TAI requirements as a guiding structure. It classifies and examines key obstacles, exploring current work, trends, and remaining challenges."}}
{"id": "2507.14777", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14777", "abs": "https://arxiv.org/abs/2507.14777", "authors": ["Bishwamittra Ghosh", "Soumi Das", "Qinyuan Wu", "Mohammad Aflah Khan", "Krishna P. Gummadi", "Evimaria Terzi", "Deepak Garg"], "title": "Rethinking Memorization Measures and their Implications in Large Language Models", "comment": "Preprint", "summary": "Concerned with privacy threats, memorization in LLMs is often seen as\nundesirable, specifically for learning. In this paper, we study whether\nmemorization can be avoided when optimally learning a language, and whether the\nprivacy threat posed by memorization is exaggerated or not. To this end, we\nre-examine existing privacy-focused measures of memorization, namely\nrecollection-based and counterfactual memorization, along with a newly proposed\ncontextual memorization.\n  Relating memorization to local over-fitting during learning, contextual\nmemorization aims to disentangle memorization from the contextual learning\nability of LLMs. Informally, a string is contextually memorized if its\nrecollection due to training exceeds the optimal contextual recollection, a\nlearned threshold denoting the best contextual learning without training.\nConceptually, contextual recollection avoids the fallacy of recollection-based\nmemorization, where any form of high recollection is a sign of memorization.\nTheoretically, contextual memorization relates to counterfactual memorization,\nbut imposes stronger conditions. Memorization measures differ in outcomes and\ninformation requirements.\n  Experimenting on 18 LLMs from 6 families and multiple formal languages of\ndifferent entropy, we show that (a) memorization measures disagree on\nmemorization order of varying frequent strings, (b) optimal learning of a\nlanguage cannot avoid partial memorization of training strings, and (c)\nimproved learning decreases contextual and counterfactual memorization but\nincreases recollection-based memorization. Finally, (d) we revisit existing\nreports of memorized strings by recollection that neither pose a privacy threat\nnor are contextually or counterfactually memorized.", "AI": {"tldr": "LLM\u5b66\u4e60\u4e2d\u8bb0\u5fc6\u662f\u4e0d\u53ef\u907f\u514d\u7684\uff0c\u4f46\u73b0\u6709\u7684\u8861\u91cf\u9690\u79c1\u98ce\u9669\u7684\u65b9\u6cd5\u53ef\u80fd\u4e0d\u51c6\u786e\u3002", "motivation": "\u9274\u4e8e\u9690\u79c1\u5a01\u80c1\uff0cLLM\u4e2d\u7684\u8bb0\u5fc6\u88ab\u8ba4\u4e3a\u662f\u4e0d\u7406\u60f3\u7684\uff0c\u5c24\u5176\u662f\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u6700\u4f18\u8bed\u8a00\u5b66\u4e60\u662f\u5426\u80fd\u907f\u514d\u8bb0\u5fc6\uff0c\u4ee5\u53ca\u8bb0\u5fc6\u5e26\u6765\u7684\u9690\u79c1\u5a01\u80c1\u662f\u5426\u88ab\u5938\u5927\u3002", "method": "\u901a\u8fc7\u91cd\u65b0\u5ba1\u89c6\u57fa\u4e8e\u56de\u5fc6\u7684\u8bb0\u5fc6\u3001\u53cd\u4e8b\u5b9e\u8bb0\u5fc6\u4ee5\u53ca\u65b0\u63d0\u51fa\u7684\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u8fd9\u51e0\u79cd\u8861\u91cf\u6807\u51c6\uff0c\u5e76\u5c06\u5176\u4e0e\u5c40\u90e8\u8fc7\u62df\u5408\u8054\u7cfb\u8d77\u6765\uff0c\u6765\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u8bb0\u5fc6\u95ee\u9898\u3002\u5b9e\u9a8c\u572818\u4e2aLLM\u548c\u591a\u79cd\u5f62\u5f0f\u8bed\u8a00\u4e0a\u8fdb\u884c\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u8bb0\u5fc6\u5ea6\u91cf\u7684\u7ed3\u679c\u548c\u4fe1\u606f\u9700\u6c42\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4e0d\u540c\u7684\u8bb0\u5fc6\u5ea6\u91cf\u6807\u51c6\u5728\u8861\u91cf\u4e0d\u540c\u9891\u7387\u5b57\u7b26\u4e32\u7684\u8bb0\u5fc6\u7a0b\u5ea6\u65f6\u5b58\u5728\u5206\u6b67\uff1b\u6700\u4f18\u8bed\u8a00\u5b66\u4e60\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u90e8\u5206\u8bb0\u5fc6\uff1b\u5b66\u4e60\u80fd\u529b\u7684\u63d0\u5347\u4f1a\u964d\u4f4e\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u548c\u53cd\u4e8b\u5b9e\u8bb0\u5fc6\uff0c\u4f46\u4f1a\u589e\u52a0\u57fa\u4e8e\u56de\u5fc6\u7684\u8bb0\u5fc6\uff1b\u5e76\u4e14\uff0c\u4e4b\u524d\u62a5\u544a\u7684\u901a\u8fc7\u56de\u5fc6\u53d1\u73b0\u7684\u8bb0\u5fc6\u5b57\u7b26\u4e32\uff0c\u5b9e\u9645\u4e0a\u5e76\u4e0d\u6784\u6210\u9690\u79c1\u5a01\u80c1\uff0c\u4e5f\u5e76\u975e\u5728\u4e0a\u4e0b\u6587\u6216\u53cd\u4e8b\u5b9e\u610f\u4e49\u4e0a\u88ab\u8bb0\u5fc6\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6700\u4f18\u8bed\u8a00\u5b66\u4e60\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\uff0c\u5e76\u4e14\u73b0\u6709\u7684\u57fa\u4e8e\u56de\u5fc6\u7684\u8bb0\u5fc6\u5ea6\u91cf\u53ef\u80fd\u5938\u5927\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u56e0\u4e3a\u5b83\u4eec\u672a\u80fd\u533a\u5206\u5b9e\u9645\u8bb0\u5fc6\u548c\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002"}}
{"id": "2507.15634", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15634", "abs": "https://arxiv.org/abs/2507.15634", "authors": ["Yi Cao", "Shaowen Lan", "Bin Sun", "Jie Liu"], "title": "Caustics in a Near-Resonant Quantum Kicked Rotor", "comment": null, "summary": "In this paper, we investigate the dynamics of the quantum kicked rotor in the\nnear-resonant regime and observe a particular recurring cusp caustic of the\nwave functions' accumulation. We then derive the path integral expression of\nthe quantum evolution and analytically determine the conditions for the caustic\nformation and recurring period. A scaling power law with Arnold index of $1/4$\nrelating to the wave amplitude enhancement depending on the kicking strength as\nwell as the resonant detuning parameter, has been derived and verified. We also\ndiscuss classical-quantum correspondence of the caustics and find that chaos\ncan disrupt the phase matching leading to the destruction of the caustic\nstructure. Finally, possible experimental observations and some implications of\nthese findings are discussed.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91cf\u5b50\u8e22\u8f6c\u5b50\u5728\u8fd1\u5171\u632f\u72b6\u6001\u4e0b\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u53d1\u73b0\u4e86\u5468\u671f\u6027\u7684\u5c16\u74e3\u5929\u7bf7\uff0c\u5e76\u63a8\u5bfc\u4e86\u91cf\u5b50\u632f\u5e45\u589e\u5f3a\u7684\u6807\u5ea6\u5f8b\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u8e22\u8f6c\u5b50\u5728\u8fd1\u5171\u632f\u533a\u57df\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u89c2\u5bdf\u5230\u4e86\u91cf\u5b50\u6ce2\u51fd\u6570\u7d2f\u79ef\u7684\u7279\u5b9a\u5468\u671f\u6027\u5c16\u74e3\u5929\u7bf7\u3002", "method": "\u901a\u8fc7\u63a8\u5bfc\u8def\u5f84\u79ef\u5206\u8868\u8fbe\u5f0f\uff0c\u5206\u6790\u4e86\u91cf\u5b50\u8c61\u9650\u8f6c\u5b50\u5728\u8fd1\u5171\u632f\u72b6\u6001\u4e0b\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u5e76\u786e\u5b9a\u4e86\u5929\u7bf7\u5f62\u6210\u548c\u91cd\u590d\u5468\u671f\u7684\u6761\u4ef6\u3002", "result": "\u63a8\u5bfc\u4e86\u4e0e\u963f\u8bfa\u5fb7\u6307\u65701/4\u76f8\u5173\u7684\u6807\u5ea6\u5e42\u5f8b\uff0c\u8be5\u5e42\u5f8b\u5c06\u91cf\u5b50\u632f\u5e45\u589e\u5f3a\u4e0e\u8e22\u529b\u5f3a\u5ea6\u548c\u5171\u632f\u5931\u8c10\u53c2\u6570\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a8\u5bfc\u4e86\u91cf\u5b50\u6f14\u5316\u7684\u8def\u5f84\u79ef\u5206\u8868\u8fbe\u5f0f\uff0c\u5e76\u786e\u5b9a\u4e86\u5929\u7bf7\u5f62\u6210\u548c\u91cd\u590d\u5468\u671f\u7684\u6761\u4ef6\u3002\u53d1\u73b0\u4e0e\u963f\u8bfa\u5fb7\u6307\u6570 1/4 \u76f8\u5173\u7684\u6807\u5ea6\u5e42\u5f8b\uff0c\u8be5\u5e42\u5f8b\u5c06\u91cf\u5b50\u632f\u5e45\u589e\u5f3a\u4e0e\u8e22\u529b\u5f3a\u5ea6\u548c\u5171\u632f\u5931\u8c10\u53c2\u6570\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u5df2\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2507.15281", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15281", "abs": "https://arxiv.org/abs/2507.15281", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "title": "A Novel Self-Evolution Framework for Large Language Models", "comment": null, "summary": "The capabilities of Large Language Models (LLMs) are limited to some extent\nby pre-training, so some researchers optimize LLMs through post-training.\nExisting post-training strategies, such as memory-based retrieval or preference\noptimization, improve user alignment yet fail to enhance the model's domain\ncognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution\n(DPSE) framework that jointly optimizes user preference adaptation and\ndomain-specific competence. DPSE introduces a Censor module to extract\nmulti-dimensional interaction signals and estimate satisfaction scores, which\nguide structured data expansion via topic-aware and preference-driven\nstrategies. These expanded datasets support a two-stage fine-tuning pipeline:\nsupervised domain grounding followed by frequency-aware preference\noptimization. Experiments across general NLP benchmarks and long-term dialogue\ntasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,\nPreference Optimization, and Memory-Augmented baselines. Ablation studies\nvalidate the contribution of each module. In this way, our framework provides\nan autonomous path toward continual self-evolution of LLMs.", "AI": {"tldr": "DPSE\u6846\u67b6\u901a\u8fc7Censor\u6a21\u5757\u63d0\u53d6\u4fe1\u53f7\uff0c\u6269\u5c55\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u4e24\u9636\u6bb5\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347LLM\u7684\u7528\u6237\u5bf9\u9f50\u6027\u548c\u9886\u57df\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4f18\u5316\u7b56\u7565\uff08\u5982\u57fa\u4e8e\u8bb0\u5fc6\u7684\u68c0\u7d22\u6216\u504f\u597d\u4f18\u5316\uff09\u5728\u63d0\u5347\u7528\u6237\u5bf9\u9f50\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u672a\u80fd\u589e\u5f3a\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u7684\u8ba4\u77e5\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u540c\u65f6\u63d0\u5347\u7528\u6237\u504f\u597d\u9002\u5e94\u548c\u9886\u57df\u7279\u5b9a\u80fd\u529b\u3002", "method": "DPSE\u6846\u67b6\u901a\u8fc7\u5f15\u5165Censor\u6a21\u5757\u63d0\u53d6\u591a\u7ef4\u5ea6\u4ea4\u4e92\u4fe1\u53f7\u5e76\u4f30\u8ba1\u6ee1\u610f\u5ea6\u5206\u6570\uff0c\u5229\u7528\u8bdd\u9898\u611f\u77e5\u548c\u504f\u597d\u9a71\u52a8\u7684\u7b56\u7565\u8fdb\u884c\u7ed3\u6784\u5316\u6570\u636e\u6269\u5c55\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u7684\u5fae\u8c03\u6d41\u7a0b\uff08\u76d1\u7763\u9886\u57df\u5b66\u4e60\u548c\u9891\u7387\u611f\u77e5\u504f\u597d\u4f18\u5316\uff09\u6765\u534f\u540c\u4f18\u5316\u7528\u6237\u504f\u597d\u9002\u5e94\u548c\u9886\u57df\u7279\u5b9a\u80fd\u529b\u3002", "result": "DPSE\u6846\u67b6\u5728\u901a\u7528NLP\u57fa\u51c6\u548c\u957f\u671f\u5bf9\u8bdd\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u3001\u504f\u597d\u4f18\u5316\u548c\u8bb0\u5fc6\u589e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "DPSE\u6846\u67b6\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u81ea\u4e3b\u6301\u7eed\u8fdb\u5316\u7684\u9014\u5f84\u3002"}}
{"id": "2507.15256", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15256", "abs": "https://arxiv.org/abs/2507.15256", "authors": ["Zihao Hu", "Jia Yan", "Ying-Jun Angela Zhang", "Jun Zhang", "Khaled B. Letaief"], "title": "Optimal Transceiver Design in Over-the-Air Federated Distillation", "comment": "13 pages, 7 figures, submitted to IEEE Transactions on Wireless\n  Communications", "summary": "The rapid proliferation and growth of artificial intelligence (AI) has led to\nthe development of federated learning (FL). FL allows wireless devices (WDs) to\ncooperatively learn by sharing only local model parameters, without needing to\nshare the entire dataset. However, the emergence of large AI models has made\nexisting FL approaches inefficient, due to the significant communication\noverhead required. In this paper, we propose a novel over-the-air federated\ndistillation (FD) framework by synergizing the strength of FL and knowledge\ndistillation to avoid the heavy local model transmission. Instead of sharing\nthe model parameters, only the WDs' model outputs, referred to as knowledge,\nare shared and aggregated over-the-air by exploiting the superposition property\nof the multiple-access channel. We shall study the transceiver design in\nover-the-air FD, aiming to maximize the learning convergence rate while meeting\nthe power constraints of the transceivers. The main challenge lies in the\nintractability of the learning performance analysis, as well as the non-convex\nnature and the optimization spanning the whole FD training period. To tackle\nthis problem, we first derive an analytical expression of the convergence rate\nin over-the-air FD. Then, the closed-form optimal solutions of the WDs'\ntransmit power and the estimator for over-the-air aggregation are obtained\ngiven the receiver combining strategy. Accordingly, we put forth an efficient\napproach to find the optimal receiver beamforming vector via semidefinite\nrelaxation. We further prove that there is no optimality gap between the\noriginal and relaxed problem for the receiver beamforming design. Numerical\nresults will show that the proposed over-the-air FD approach achieves a\nsignificant reduction in communication overhead, with only a minor compromise\nin testing accuracy compared to conventional FL benchmarks.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u8fc7\u9876\u8054\u90a6\u84b8\u998f\uff08FD\uff09\u6846\u67b6\uff0c\u5229\u7528FL\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u901a\u8fc7\u5171\u4eab\u6a21\u578b\u8f93\u51fa\u6765\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u6536\u53d1\u5668\u8bbe\u8ba1\u548c\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709FL\u65b9\u6cd5\u5728\u5927\u6a21\u578b\u65f6\u4ee3\u7531\u4e8e\u663e\u8457\u7684\u901a\u4fe1\u5f00\u9500\u800c\u5bfc\u81f4\u7684\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e86\u8fc7\u9876FD\u4e2d\u7684\u6536\u53d1\u5668\u8bbe\u8ba1\uff0c\u65e8\u5728\u6700\u5927\u5316\u5b66\u4e60\u6536\u655b\u901f\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u6536\u53d1\u5668\u7684\u529f\u7387\u7ea6\u675f\u3002\u901a\u8fc7\u63a8\u5bfc\u6536\u655b\u901f\u7387\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u4ee5\u53ca\u5f97\u5230 WD \u53d1\u5c04\u529f\u7387\u548c\u8fc7\u9876\u805a\u5408\u4f30\u8ba1\u5668\u7684\u95ed\u5f0f\u6700\u4f18\u89e3\uff0c\u5e76\u91c7\u7528\u534a\u5b9a\u677e\u5f1b\u6765\u5bfb\u627e\u6700\u4f18\u63a5\u6536\u5668\u6ce2\u675f\u5f62\u6210\u5411\u91cf\uff0c\u8bc1\u660e\u4e86\u539f\u95ee\u9898\u548c\u677e\u5f1b\u95ee\u9898\u7684\u6700\u4f18\u6027\u6ca1\u6709\u5dee\u8ddd\u3002", "result": "\u6240\u63d0\u51fa\u7684\u8fc7\u9876FD\u65b9\u6cd5\u5b9e\u73b0\u4e86\u901a\u4fe1\u5f00\u9500\u7684\u5927\u5e45\u964d\u4f4e\uff0c\u800c\u6d4b\u8bd5\u51c6\u786e\u6027\u4ec5\u6bd4\u4f20\u7edf\u7684FL\u57fa\u51c6\u6709\u8f7b\u5fae\u7684\u4e0b\u964d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fc7\u9876\u8054\u90a6\u84b8\u998f\uff08FD\uff09\u6846\u67b6\u901a\u8fc7\u5229\u7528\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u548c\u77e5\u8bc6\u84b8\u998f\u7684\u4f18\u52bf\uff0c\u5e76\u5229\u7528\u591a\u5740\u63a5\u5165\u4fe1\u9053\u7684\u53e0\u52a0\u6027\u8d28\uff0c\u5728\u805a\u5408\u8fc7\u7a0b\u4e2d\u53ea\u5171\u4eab\u6a21\u578b\u8f93\u51fa\uff08\u77e5\u8bc6\uff09\uff0c\u4ece\u800c\u907f\u514d\u4e86\u7e41\u91cd\u7684\u672c\u5730\u6a21\u578b\u4f20\u8f93\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u5f00\u9500\u7684\u5927\u5e45\u964d\u4f4e\uff0c\u800c\u4ec5\u5728\u6d4b\u8bd5\u51c6\u786e\u6027\u65b9\u9762\u4e0e\u4f20\u7edf\u7684FL\u57fa\u51c6\u76f8\u6bd4\u6709\u8f7b\u5fae\u7684\u6298\u8877\u3002"}}
{"id": "2507.15857", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15857", "abs": "https://arxiv.org/abs/2507.15857", "authors": ["Mihir Prabhudesai", "Menging Wu", "Amir Zadeh", "Katerina Fragkiadaki", "Deepak Pathak"], "title": "Diffusion Beats Autoregressive in Data-Constrained Settings", "comment": "Project Webpage: https://diffusion-scaling.github.io", "summary": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.", "AI": {"tldr": "\u5728\u6570\u636e\u7a00\u758f\u3001\u8ba1\u7b97\u91cf\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u6a21\u578b\u6bd4\u81ea\u56de\u5f52\u6a21\u578b\u66f4\u597d\u3002", "motivation": "\u63a2\u7a76\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u758f\u7684\u573a\u666f\u4e0b\u7684\u4f18\u52bf\u3002", "method": "\u7cfb\u7edf\u6027\u7814\u7a76\u4e86\u5728\u6570\u636e\u53d7\u9650\uff08\u91cd\u590d\u5229\u7528\u6709\u9650\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u63a9\u7801\u6269\u6563\u6a21\u578b\u76f8\u8f83\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u4e86\u5176\u4f18\u52bf\u7684\u6765\u6e90\u3002", "result": "\u6269\u6563\u6a21\u578b\u5728\u6570\u636e\u53d7\u9650\u4e14\u8ba1\u7b97\u8d44\u6e90\u5145\u88d5\u65f6\u663e\u8457\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5229\u7528\u91cd\u590d\u6570\u636e\uff0c\u5b9e\u73b0\u66f4\u4f4e\u7684\u9a8c\u8bc1\u635f\u5931\u548c\u66f4\u597d\u7684\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u53d1\u73b0\u4e86\u65b0\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5e76\u63a8\u5bfc\u4e86\u6269\u6563\u6a21\u578b\u8d85\u8d8a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4e34\u754c\u8ba1\u7b97\u9608\u503c\u3002", "conclusion": "\u5728\u6570\u636e\u53d7\u9650\u4f46\u8ba1\u7b97\u8d44\u6e90\u5145\u8db3\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u6a21\u578b\u901a\u8fc7\u9690\u5f0f\u6570\u636e\u589e\u5f3a\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u6570\u636e\u5229\u7528\u7387\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u4e86\u6269\u6563\u6a21\u578b\u7684\u65b0\u7f29\u653e\u5b9a\u5f8b\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u8d85\u8d8a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4e34\u754c\u8ba1\u7b97\u9608\u503c\u3002"}}
{"id": "2507.14833", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14833", "abs": "https://arxiv.org/abs/2507.14833", "authors": ["Haoxuan Zhang", "Wenju Cui", "Yuzhu Cao", "Tao Tan", "Jie Liu", "Yunsong Peng", "Jian Zheng"], "title": "Paired Image Generation with Diffusion-Guided Diffusion Models", "comment": null, "summary": "The segmentation of mass lesions in digital breast tomosynthesis (DBT) images\nis very significant for the early screening of breast cancer. However, the\nhigh-density breast tissue often leads to high concealment of the mass lesions,\nwhich makes manual annotation difficult and time-consuming. As a result, there\nis a lack of annotated data for model training. Diffusion models are commonly\nused for data augmentation, but the existing methods face two challenges.\nFirst, due to the high concealment of lesions, it is difficult for the model to\nlearn the features of the lesion area. This leads to the low generation quality\nof the lesion areas, thus limiting the quality of the generated images. Second,\nexisting methods can only generate images and cannot generate corresponding\nannotations, which restricts the usability of the generated images in\nsupervised training. In this work, we propose a paired image generation method.\nThe method does not require external conditions and can achieve the generation\nof paired images by training an extra diffusion guider for the conditional\ndiffusion model. During the experimental phase, we generated paired DBT slices\nand mass lesion masks. Then, we incorporated them into the supervised training\nprocess of the mass lesion segmentation task. The experimental results show\nthat our method can improve the generation quality without external conditions.\nMoreover, it contributes to alleviating the shortage of annotated data, thus\nenhancing the performance of downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u6761\u4ef6\u7684\u914d\u5bf9\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6570\u5b57\u4e73\u623f\u65ad\u5c42\u5408\u6210\uff08DBT\uff09\u56fe\u50cf\u4e2d\u80bf\u5757\u5206\u5272\u7684\u6570\u636e\u77ed\u7f3a\u95ee\u9898\u3002\u901a\u8fc7\u8bad\u7ec3\u989d\u5916\u7684\u5f15\u5bfc\u5668\u6765\u751f\u6210\u914d\u5bf9\u7684DBT\u56fe\u50cf\u548c\u75c5\u7076\u63a9\u6a21\uff0c\u5e76\u5c06\u5176\u7528\u4e8e\u76d1\u7763\u8bad\u7ec3\uff0c\u80fd\u591f\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u5e76\u63d0\u5347\u5206\u5272\u6027\u80fd\u3002", "motivation": "\u6570\u5b57\u4e73\u623f\u65ad\u5c42\u5408\u6210\uff08DBT\uff09\u56fe\u50cf\u4e2d\u80bf\u5757\u75c5\u7076\u7684\u5206\u5272\u5bf9\u4e8e\u4e73\u817a\u764c\u7684\u65e9\u671f\u7b5b\u67e5\u975e\u5e38\u91cd\u8981\u3002\u7136\u800c\uff0c\u9ad8\u5bc6\u5ea6\u4e73\u817a\u7ec4\u7ec7\u5bfc\u81f4\u75c5\u7076\u9690\u85cf\u6027\u9ad8\uff0c\u624b\u52a8\u6807\u6ce8\u56f0\u96be\u4e14\u8017\u65f6\uff0c\u8fd9\u9020\u6210\u4e86\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u6807\u6ce8\u6570\u636e\u7684\u7f3a\u4e4f\u3002\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u5e38\u7528\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u4f46\u9762\u4e34\u751f\u6210\u75c5\u7076\u533a\u57df\u7279\u5f81\u5b66\u4e60\u56f0\u96be\u3001\u751f\u6210\u56fe\u50cf\u8d28\u91cf\u4f4e\u4ee5\u53ca\u53ea\u80fd\u751f\u6210\u56fe\u50cf\u800c\u65e0\u6cd5\u751f\u6210\u5bf9\u5e94\u6807\u6ce8\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u914d\u5bf9\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u989d\u5916\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5f15\u5bfc\u5668\u6765\u5b9e\u73b0\u914d\u5bf9\u56fe\u50cf\u7684\u751f\u6210\uff0c\u65e0\u9700\u5916\u90e8\u6761\u4ef6\u3002", "result": "\u751f\u6210\u7684\u914d\u5bf9DBT\u5207\u7247\u548c\u80bf\u5757\u533a\u57df\u63a9\u6a21\u88ab\u7eb3\u5165\u80bf\u5757\u533a\u57df\u5206\u5272\u4efb\u52a1\u7684\u76d1\u7763\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65e0\u9700\u5916\u90e8\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u6709\u52a9\u4e8e\u7f13\u89e3\u6807\u6ce8\u6570\u636e\u77ed\u7f3a\u95ee\u9898\uff0c\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u540c\u65f6\u5728\u6ca1\u6709\u5916\u90e8\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u52a9\u4e8e\u7f13\u89e3\u6807\u6ce8\u6570\u636e\u77ed\u7f3a\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15842", "categories": ["cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.15842", "abs": "https://arxiv.org/abs/2507.15842", "authors": ["Sara LaPlante", "Emilija Perkovi\u0107"], "title": "Identifying Conditional Causal Effects in MPDAGs", "comment": "67 pages, 8 figures", "summary": "We consider identifying a conditional causal effect when a graph is known up\nto a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG\nrepresents an equivalence class of graphs that is restricted by background\nknowledge and where all variables in the causal model are observed. We provide\nthree results that address identification in this setting: an identification\nformula when the conditioning set is unaffected by treatment, a generalization\nof the well-known do calculus to the MPDAG setting, and an algorithm that is\ncomplete for identifying these conditional effects.", "AI": {"tldr": "This paper provides methods to identify conditional causal effects using MPDAGs, including a new formula, a generalized do calculus, and a complete algorithm.", "motivation": "The paper addresses the problem of identifying a conditional causal effect in the presence of a known graph structure represented by a maximally oriented partially directed acyclic graph (MPDAG), where all variables in the causal model are observed.", "method": "The paper presents an identification formula for a conditional causal effect when the conditioning set is unaffected by treatment, generalizes the do calculus to the MPDAG setting, and introduces a complete algorithm for identifying these conditional effects.", "result": "The results include an identification formula for a specific conditioning set scenario, a generalized do calculus for MPDAGs, and a complete algorithm for effect identification.", "conclusion": "We provide three results that address identification in this setting: an identification formula when the conditioning set is unaffected by treatment, a generalization of the well-known do calculus to the MPDAG setting, and an algorithm that is complete for identifying these conditional effects."}}
{"id": "2507.14783", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14783", "abs": "https://arxiv.org/abs/2507.14783", "authors": ["Derek Li", "Jiaming Zhou", "Amirreza Kazemi", "Qianyi Sun", "Abbas Ghaddar", "Mohammad Ali Alomrani", "Liheng Ma", "Yu Luo", "Dong Li", "Feng Wen", "Jianye Hao", "Mark Coates", "Yingxue Zhang"], "title": "Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards", "comment": null, "summary": "The advancement of general-purpose artificial intelligence relies on large\nlanguage models (LLMs) that excel across a wide range of tasks, from structured\nreasoning to creative generation. However, post-training methods like\nSupervised Fine-Tuning (SFT) often struggle with generalization, favoring\nmemorization over transferable learning. In this work, we introduce Omni-Think,\na unified reinforcement learning (RL) framework that enhances LLM performance\nacross diverse tasks by combining rule-based verifiable rewards with generative\npreference signals via LLM-as-a-Judge evaluations. Our approach enables\nconsistent optimization across task types and scales RL-based training to\nsubjective domains. We further investigate training strategies, demonstrating\nthat a curriculum-based progression that orders tasks from structured to\nopen-ended improves performance and reduces forgetting. Experimental results\nacross four domains reveal that curriculum learning improves performance by\n5.2\\% over joint training and 9.1\\% over model merging. These results highlight\nthe importance of task-aware sampling and hybrid supervision in scaling\nRL-based post-training for general-purpose LLMs.", "AI": {"tldr": "Omni-Think, a new RL framework, improves LLM generalization by combining rule-based rewards and LLM-as-a-Judge preferences. Curriculum learning further boosts performance, outperforming joint training and model merging.", "motivation": "Post-training methods like Supervised Fine-Tuning (SFT) struggle with generalization in LLMs, favoring memorization over transferable learning. The goal is to enhance LLM performance across diverse tasks.", "method": "The paper introduces Omni-Think, a unified reinforcement learning (RL) framework that combines rule-based verifiable rewards with generative preference signals (LLM-as-a-Judge). It also investigates curriculum-based training strategies, ordering tasks from structured to open-ended to improve performance and reduce forgetting.", "result": "Omni-Think enables consistent optimization across task types and scales RL-based training to subjective domains. Curriculum learning improves performance by 5.2% over joint training and 9.1% over model merging across four domains.", "conclusion": "The study highlights the importance of task-aware sampling and hybrid supervision in scaling RL-based post-training for general-purpose LLMs."}}
{"id": "2507.15661", "categories": ["quant-ph", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15661", "abs": "https://arxiv.org/abs/2507.15661", "authors": ["Zahra Baghali Khanian", "Christoph Hirche"], "title": "On Strong Converse Bounds for the Private and Quantum Capacities of Anti-degradable Channels", "comment": null, "summary": "We establish a strong converse bound for the private classical capacity of\nanti-degradable quantum channels. Specifically, we prove that this capacity is\nzero whenever the error $\\epsilon > 0$ and privacy parameter $\\delta > 0$\nsatisfy the inequality $\\delta (1-\\epsilon^2)^{\\frac{1}{2}}+\\epsilon\n(1-\\delta^2)^{\\frac{1}{2}}<1$. This result strengthens previous understandings\nby sharply defining the boundary beyond which reliable and private\ncommunication is impossible. Furthermore, we present a ``pretty simple'' proof\nof the ``pretty strong'' converse for the quantum capacity of anti-degradable\nchannels, valid for any error $\\epsilon < \\frac{1}{\\sqrt{2}}$. Our approach\noffers clarity and technical simplicity, shedding new light on the fundamental\nlimits of quantum communication.", "AI": {"tldr": "\u4e3a\u4e0d\u53ef\u964d\u89e3\u91cf\u5b50\u4fe1\u9053\u7684\u79c1\u6709\u7ecf\u5178\u5bb9\u91cf\u548c\u91cf\u5b50\u5bb9\u91cf\u7684\u6781\u9650\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u754c\u5b9a\u548c\u66f4\u7b80\u5316\u7684\u8bc1\u660e\u3002", "motivation": "\u4e3a\u4e86\u66f4\u7cbe\u786e\u5730\u7406\u89e3\u548c\u754c\u5b9a\u4e0d\u53ef\u964d\u89e3\u91cf\u5b50\u4fe1\u9053\u7684\u79c1\u6709\u7ecf\u5178\u5bb9\u91cf\u548c\u91cf\u5b50\u5bb9\u91cf\u7684\u6781\u9650\uff0c\u7279\u522b\u662f\u8d85\u8d8a\u5148\u524d\u7814\u7a76\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u548c\u4e0d\u7b49\u5f0f\u8bc1\u660e\uff0c\u5efa\u7acb\u4e86\u79c1\u6709\u7ecf\u5178\u5bb9\u91cf\u7684\u5f3a\u53cd\u5411\u754c\u9650\uff0c\u5e76\u5bf9\u4e0d\u53ef\u964d\u89e3\u4fe1\u9053\u7684\u91cf\u5b50\u5bb9\u91cf\u63d0\u51fa\u4e86\u4e00\u4e2a\u201c\u76f8\u5f53\u7b80\u5355\u201d\u7684\u201c\u76f8\u5f53\u5f3a\u201d\u7684\u53cd\u5411\u8bc1\u660e\u3002", "result": "1. \u786e\u7acb\u4e86\u4e0d\u53ef\u964d\u89e3\u91cf\u5b50\u4fe1\u9053\u7684\u79c1\u6709\u7ecf\u5178\u5bb9\u91cf\u7684\u5f3a\u53cd\u5411\u754c\u9650\uff1a\u5f53\u6ee1\u8db3 $\\delta (1-\\epsilon^2)^{\\frac{1}{2}}+\\epsilon (1-\\delta^2)^{\\frac{1}{2}}<1$ \u65f6\uff0c\u5bb9\u91cf\u4e3a\u96f6\u3002 2. \u4e3a\u4e0d\u53ef\u964d\u89e3\u4fe1\u9053\u7684\u91cf\u5b50\u5bb9\u91cf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u201c\u76f8\u5f53\u7b80\u5355\u201d\u7684\u201c\u76f8\u5f53\u5f3a\u201d\u7684\u53cd\u5411\u8bc1\u660e\uff0c\u8be5\u8bc1\u660e\u9002\u7528\u4e8e $\\epsilon < \\frac{1}{\\sqrt{2}}$ \u7684\u60c5\u51b5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e0d\u53ef\u964d\u89e3\u91cf\u5b50\u4fe1\u9053\u7684\u79c1\u6709\u7ecf\u5178\u5bb9\u91cf\u5efa\u7acb\u4e86\u5f3a\u53cd\u5411\u754c\u9650\uff0c\u6307\u51fa\u5f53\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u65f6\uff0c\u8be5\u5bb9\u91cf\u4e3a\u96f6\uff0c\u4ece\u800c\u7cbe\u786e\u5b9a\u4e49\u4e86\u53ef\u9760\u548c\u79c1\u6709\u901a\u4fe1\u7684\u6781\u9650\u8fb9\u754c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u4e3a\u4e0d\u53ef\u964d\u89e3\u4fe1\u9053\u7684\u91cf\u5b50\u5bb9\u91cf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u201c\u76f8\u5f53\u7b80\u5355\u201d\u7684\u201c\u76f8\u5f53\u5f3a\u201d\u7684\u53cd\u5411\u8bc1\u660e\uff0c\u9002\u7528\u4e8e\u7279\u5b9a\u8bef\u5dee\u8303\u56f4\uff0c\u4e3a\u91cf\u5b50\u901a\u4fe1\u7684\u57fa\u7840\u6781\u9650\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.15286", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15286", "abs": "https://arxiv.org/abs/2507.15286", "authors": ["Navid Ayoobi", "Sadat Shahriar", "Arjun Mukherjee"], "title": "Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection", "comment": null, "summary": "We present a novel evaluation paradigm for AI text detectors that prioritizes\nreal-world and equitable assessment. Current approaches predominantly report\nconventional metrics like AUROC, overlooking that even modest false positive\nrates constitute a critical impediment to practical deployment of detection\nsystems. Furthermore, real-world deployment necessitates predetermined\nthreshold configuration, making detector stability (i.e. the maintenance of\nconsistent performance across diverse domains and adversarial scenarios), a\ncritical factor. These aspects have been largely ignored in previous research\nand benchmarks. Our benchmark, SHIELD, addresses these limitations by\nintegrating both reliability and stability factors into a unified evaluation\nmetric designed for practical assessment. Furthermore, we develop a post-hoc,\nmodel-agnostic humanification framework that modifies AI text to more closely\nresemble human authorship, incorporating a controllable hardness parameter.\nThis hardness-aware approach effectively challenges current SOTA zero-shot\ndetection methods in maintaining both reliability and stability. (Data and\ncode: https://github.com/navid-aub/SHIELD-Benchmark)", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15291", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15291", "abs": "https://arxiv.org/abs/2507.15291", "authors": ["Osman Tokluoglu", "Enver Cavus", "Ebrahim Bedeer", "Halim Yanikomeroglu"], "title": "A Novel Domain-Aware CNN Architecture for Faster-than-Nyquist Signaling Detection", "comment": "6 pages, 8 figures", "summary": "This paper proposes a convolutional neural network (CNN)-based detector for\nfaster-than-Nyquist (FTN) signaling that employs structured fixed kernel layers\nwith domain-informed masking to mitigate intersymbol interference (ISI). Unlike\nstandard CNNs with sliding kernels, the proposed method utilizes fixed-position\nkernels to directly capture ISI effects at varying distances from the central\nsymbol. A hierarchical filter allocation strategy is also introduced, assigning\nmore filters to earlier layers for strong ISI patterns and fewer to later\nlayers for weaker ones. This design improves detection accuracy while reducing\nredundant operations. Simulation results show that the detector achieves\nnear-optimal bit error rate (BER) performance for $\\tau \\geq 0.7$, closely\nmatching the BCJR algorithm, and offers computational gains of up to $46\\%$ and\n$84\\%$ over M-BCJR for BPSK and QPSK, respectively. Comparative analysis with\nother methods further highlights the efficiency and effectiveness of the\nproposed approach. To the best of our knowledge, this is the first application\nof a fixed-kernel CNN architecture tailored for FTN detection in the\nliterature.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u56fa\u5b9a\u6838CNN\u68c0\u6d4b\u5668\uff0c\u7528\u4e8e\u8d85\u5948\u594e\u65af\u7279\uff08FTN\uff09\u4fe1\u53f7\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7b26\u53f7\u95f4\u5e72\u6270\uff08ISI\uff09\u95ee\u9898\uff0c\u5e76\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u66f4\u5feb\u5730\u8fdb\u884c\u8d85\u5948\u594e\u65af\u7279\uff08FTN\uff09\u4fe1\u53f7\u68c0\u6d4b\uff0c\u5e76\u6709\u6548\u51cf\u8f7b\u7b26\u53f7\u95f4\u5e72\u6270\uff08ISI\uff09\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u7684\u8d85\u5948\u594e\u65af\u7279\uff08FTN\uff09\u4fe1\u53f7\u68c0\u6d4b\u5668\u3002\u8be5\u68c0\u6d4b\u5668\u91c7\u7528\u7ed3\u6784\u5316\u56fa\u5b9a\u6838\u5c42\u548c\u9886\u57df\u611f\u77e5\u63a9\u7801\u6765\u51cf\u8f7b\u7b26\u53f7\u95f4\u5e72\u6270\uff08ISI\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u5206\u5c42\u6ee4\u6ce2\u5668\u5206\u914d\u7b56\u7565\uff0c\u4f18\u5148\u5904\u7406\u8f83\u5f3a\u7684ISI\u6a21\u5f0f\u3002", "result": "\u5728$\tau \text{ } \textgreater \text{=} \text{ } 0.7$\u65f6\uff0c\u8be5\u68c0\u6d4b\u5668\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u8bef\u7801\u7387\uff08BER\uff09\u6027\u80fd\uff0c\u4e0eBCJR\u7b97\u6cd5\u76f8\u5f53\uff0c\u5e76\u4e14\u5728BPSK\u548cQPSK\u8c03\u5236\u4e0b\uff0c\u8ba1\u7b97\u6548\u7387\u5206\u522b\u6bd4M-BCJR\u7b97\u6cd5\u9ad8\u51fa46%\u548c84%\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5c06\u56fa\u5b9a\u6838\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5e94\u7528\u4e8eFTN\u68c0\u6d4b\uff0c\u5728$\tau \text{ } \textgreater \text{=} \text{ } 0.7$\u65f6\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u8bef\u7801\u7387\uff08BER\uff09\u6027\u80fd\uff0c\u8ba1\u7b97\u6548\u7387\u6bd4M-BCJR\u7b97\u6cd5\u5206\u522b\u63d0\u9ad8\u4e8646%\u548c84%\uff08\u9488\u5bf9BPSK\u548cQPSK\uff09\u3002"}}
{"id": "2507.14845", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14845", "abs": "https://arxiv.org/abs/2507.14845", "authors": ["Rizhao Fan", "Zhigen Li", "Heping Li", "Ning An"], "title": "Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image", "comment": null, "summary": "Depth completion is an important vision task, and many efforts have been made\nto enhance the quality of depth maps from sparse depth measurements. Despite\nsignificant advances, training these models to recover dense depth from sparse\nmeasurements remains a challenging problem. Supervised learning methods rely on\ndense depth labels to predict unobserved regions, while self-supervised\napproaches require image sequences to enforce geometric constraints and\nphotometric consistency between frames. However, acquiring dense annotations is\ncostly, and multi-frame dependencies limit the applicability of self-supervised\nmethods in static or single-frame scenarios. To address these challenges, we\npropose a novel self-supervised depth completion paradigm that requires only\nsparse depth measurements and their corresponding image for training. Unlike\nexisting methods, our approach eliminates the need for dense depth labels or\nadditional images captured from neighboring viewpoints. By leveraging the\ncharacteristics of depth distribution, we design novel loss functions that\neffectively propagate depth information from observed points to unobserved\nregions. Additionally, we incorporate segmentation maps generated by vision\nfoundation models to further enhance depth estimation. Extensive experiments\ndemonstrate the effectiveness of our proposed method.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u6df1\u5ea6\u8865\u5168\u65b9\u6cd5\uff0c\u4ec5\u9700\u7a00\u758f\u6df1\u5ea6\u548c\u56fe\u50cf\u5373\u53ef\u8bad\u7ec3\uff0c\u65e0\u9700\u5bc6\u96c6\u6807\u7b7e\u6216\u591a\u5e27\u56fe\u50cf\uff0c\u901a\u8fc7\u6df1\u5ea6\u5206\u5e03\u635f\u5931\u548c\u5206\u5272\u56fe\u63d0\u9ad8\u4e86\u6df1\u5ea6\u4f30\u8ba1\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u4e86\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5bc6\u96c6\u6df1\u5ea6\u6807\u7b7e\u6210\u672c\u9ad8\uff0c\u4ee5\u53ca\u81ea\u76d1\u7763\u65b9\u6cd5\u9700\u8981\u56fe\u50cf\u5e8f\u5217\u5f3a\u5236\u51e0\u4f55\u7ea6\u675f\u548c\u5149\u5ea6\u4e00\u81f4\u6027\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u9759\u6001\u6216\u5355\u5e27\u573a\u666f\u4e2d\u9002\u7528\u6027\u53d7\u9650\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u5206\u5e03\u7684\u7279\u6027\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u5730\u5c06\u6df1\u5ea6\u4fe1\u606f\u4ece\u89c2\u6d4b\u70b9\u4f20\u64ad\u5230\u672a\u89c2\u6d4b\u533a\u57df\uff0c\u5e76\u7ed3\u5408\u4e86\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u751f\u6210\u7684\u5206\u5272\u56fe\u6765\u8fdb\u4e00\u6b65\u589e\u5f3a\u6df1\u5ea6\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u76d1\u7763\u6df1\u5ea6\u8865\u5168\u8303\u5f0f\uff0c\u4ec5\u9700\u8981\u7a00\u758f\u6df1\u5ea6\u6d4b\u91cf\u53ca\u5176\u5bf9\u5e94\u7684\u56fe\u50cf\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u5bc6\u96c6\u6df1\u5ea6\u6807\u7b7e\u6216\u989d\u5916\u7684\u90bb\u8fd1\u89c6\u70b9\u56fe\u50cf\u3002"}}
{"id": "2507.15844", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15844", "abs": "https://arxiv.org/abs/2507.15844", "authors": ["Shangke Lyu", "Linjuan Wu", "Yuchen Yan", "Xingyu Wu", "Hao Li", "Yongliang Shen", "Peisheng Jiang", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "comment": "Code: https://github.com/zju-real/hbpo Project\n  Page:https://zju-real.github.io/hbpo/", "summary": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.", "AI": {"tldr": "HBPO \u901a\u8fc7\u5206\u5c42\u9884\u7b97\u548c\u5dee\u5f02\u5316\u5956\u52b1\uff0c\u5728\u63d0\u9ad8\u63a8\u7406\u6a21\u578b\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u6df1\u5ea6\u4e0a\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u5b83\u4eec\u901a\u5e38\u91c7\u7528\u7edf\u4e00\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5ffd\u7565\u4e86\u95ee\u9898\u672c\u8eab\u7684\u590d\u6742\u5ea6\u3002HBPO \u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6838\u5fc3\u6311\u6218\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u9002\u5e94\u95ee\u9898\u590d\u6742\u5ea6\u7684\u63a8\u7406\u6df1\u5ea6\uff0c\u540c\u65f6\u907f\u514d\u5728\u4ee5\u6548\u7387\u4e3a\u5bfc\u5411\u7684\u8bad\u7ec3\u4e2d\u51fa\u73b0\u63a2\u7d22\u7a7a\u95f4\u574d\u584c\u3002", "method": "HBPO\uff08\u5206\u5c42\u9884\u7b97\u7b56\u7565\u4f18\u5316\uff09\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u5c06\u91c7\u6837\u5206\u5230\u5177\u6709\u4e0d\u540c\u4ee4\u724c\u9884\u7b97\u7684\u5b50\u7ec4\u4e2d\uff0c\u5e76\u7ed3\u5408\u5dee\u5f02\u5316\u5956\u52b1\u673a\u5236\uff0c\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e0e\u95ee\u9898\u590d\u6742\u5ea6\u76f8\u7b26\u7684\u6fc0\u52b1\uff0c\u4ece\u800c\u5b66\u4e60\u81ea\u9002\u5e94\u7684\u63a8\u7406\u6df1\u5ea6\u3002", "result": "HBPO \u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u4ee4\u724c\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u9ad8\u8fbe 60.6%\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 3.14%\u3002\u6a21\u578b\u80fd\u591f\u6839\u636e\u95ee\u9898\u590d\u6742\u5ea6\u81ea\u52a8\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u5c55\u73b0\u51fa\u6d8c\u73b0\u7684\u81ea\u9002\u5e94\u884c\u4e3a\u3002", "conclusion": "HBPO \u6846\u67b6\u901a\u8fc7\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u548c\u5dee\u5f02\u5316\u5956\u52b1\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u63a8\u7406\u6df1\u5ea6\uff0c\u4ece\u800c\u5728\u964d\u4f4e\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cHBPO \u53ef\u5c06\u5e73\u5747\u4ee4\u724c\u4f7f\u7528\u91cf\u51cf\u5c11\u591a\u8fbe 60.6%\uff0c\u540c\u65f6\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c06\u51c6\u786e\u7387\u63d0\u9ad8 3.14%\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a8\u7406\u6548\u7387\u548c\u80fd\u529b\u7684\u540c\u6b65\u4f18\u5316\uff0c\u6253\u7834\u4e86\u4e24\u8005\u5fc5\u987b\u51b2\u7a81\u7684\u56fa\u6709\u89c2\u5ff5\u3002"}}
{"id": "2507.14785", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14785", "abs": "https://arxiv.org/abs/2507.14785", "authors": ["Erfan Pirmorad"], "title": "Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs", "comment": null, "summary": "The complexity and interconnectivity of entities involved in money laundering\ndemand investigative reasoning over graph-structured data. This paper explores\nthe use of large language models (LLMs) as reasoning engines over localized\nsubgraphs extracted from a financial knowledge graph. We propose a lightweight\npipeline that retrieves k-hop neighborhoods around entities of interest,\nserializes them into structured text, and prompts an LLM via few-shot\nin-context learning to assess suspiciousness and generate justifications. Using\nsynthetic anti-money laundering (AML) scenarios that reflect common laundering\nbehaviors, we show that LLMs can emulate analyst-style logic, highlight red\nflags, and provide coherent explanations. While this study is exploratory, it\nillustrates the potential of LLM-based graph reasoning in AML and lays\ngroundwork for explainable, language-driven financial crime analytics.", "AI": {"tldr": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u63a8\u7406\u5f15\u64ce\uff0c\u5bf9\u91d1\u878d\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b50\u56fe\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u68c0\u6d4b\u6d17\u94b1\u884c\u4e3a\u3002", "motivation": "\u6d17\u94b1\u884c\u4e3a\u6d89\u53ca\u590d\u6742\u7684\u5b9e\u4f53\u548c\u76f8\u4e92\u8054\u7cfb\uff0c\u9700\u8981\u5bf9\u56fe\u7ed3\u6784\u6570\u636e\u8fdb\u884c\u8c03\u67e5\u63a8\u7406\u3002\u63a2\u7d22\u4f7f\u7528LLM\u4f5c\u4e3a\u5728\u672c\u5730\u5b50\u56fe\u4e0a\u8fdb\u884c\u63a8\u7406\u7684\u5f15\u64ce\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u7ba1\u9053\uff0c\u4ece\u91d1\u878d\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63d0\u53d6\u5b9e\u4f53\u7684k\u8df3\u90bb\u57df\uff0c\u5c06\u5b83\u4eec\u5e8f\u5217\u5316\u4e3a\u7ed3\u6784\u5316\u6587\u672c\uff0c\u5e76\u901a\u8fc7\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u793aLLM\uff0c\u4ee5\u8bc4\u4f30\u53ef\u7591\u7a0b\u5ea6\u5e76\u751f\u6210\u7406\u7531\u3002", "result": "LLM\u80fd\u591f\u6a21\u4eff\u5206\u6790\u5e08\u7684\u903b\u8f91\uff0c\u7a81\u51fa\u5371\u9669\u4fe1\u53f7\uff0c\u5e76\u63d0\u4f9b\u8fde\u8d2f\u7684\u89e3\u91ca\u3002LLM\u53ef\u4ee5\u7528\u4e8e\u53cd\u6d17\u94b1\uff08AML\uff09\u573a\u666f\uff0c\u4ee5\u8bc4\u4f30\u53ef\u7591\u7a0b\u5ea6\u548c\u751f\u6210\u7406\u7531\u3002", "conclusion": "LLMs\u5728\u91d1\u878d\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u57fa\u4e8e\u56fe\u63a8\u7406\u7684\u5206\u6790\uff0c\u53ef\u4ee5\u6a21\u4eff\u5206\u6790\u5e08\u7684\u903b\u8f91\uff0c\u7a81\u51fa\u5371\u9669\u4fe1\u53f7\uff0c\u5e76\u63d0\u4f9b\u8fde\u8d2f\u7684\u89e3\u91ca\uff0c\u8fd9\u5728\u53cd\u6d17\u94b1\uff08AML\uff09\u9886\u57df\u5177\u6709\u6f5c\u529b\uff0c\u5e76\u4e3a\u53ef\u89e3\u91ca\u7684\u3001\u7531\u8bed\u8a00\u9a71\u52a8\u7684\u91d1\u878d\u72af\u7f6a\u5206\u6790\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15725", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15725", "abs": "https://arxiv.org/abs/2507.15725", "authors": ["Jia-Jin Zou", "Jian-Wei Qin", "Franco Nori", "Ze-Liang Xiang"], "title": "Efficiently Generation of Cluster States via Time-Delayed Feedback in Matrix Representation", "comment": "11 pages, 5 figures (1 figure in Appendix). Comments welcome", "summary": "Cluster states, as highly entangled multi-qubit states, are widely used as\nessential resources for quantum communication and quantum computing. However,\ndue to the diverse requirements of applications for cluster states with\nspecific entanglement structures, a universal generation protocol is still\nlacking. Here we develop a matrix representation according to the\ncharacteristics of time-delayed feedback (TDF) and propose a protocol for\ngenerating arbitrary cluster states with multiple TDFs. The matrix\nrepresentation also allows us to optimize the generation process to reduce TDF\nusage, thus improving efficiency. In particular, we demonstrate a\ntree-cluster-state generation process that requires only one TDF. Moreover,\naccounting for the critical loss mechanisms and imperfections in our protocol,\nwe discuss the additional losses caused by multiple TDFs and evaluate the\nfidelity of the resulting cluster states.", "AI": {"tldr": "\u5229\u7528\u77e9\u9635\u8868\u793a\u548c\u591a\u65f6\u95f4\u5ef6\u8fdf\u53cd\u9988\uff08TDF\uff09\u751f\u6210\u4efb\u610f\u7c07\u6001\uff0c\u4f18\u5316\u6548\u7387\u5e76\u964d\u4f4e\u635f\u8017\u3002", "motivation": "\u7531\u4e8e\u5e94\u7528\u5bf9\u5177\u6709\u7279\u5b9a\u7ea0\u7f20\u7ed3\u6784\u7684\u7c07\u6001\u6709\u591a\u79cd\u9700\u6c42\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u901a\u7528\u7684\u751f\u6210\u534f\u8bae\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6839\u636e\u65f6\u95f4\u5ef6\u8fdf\u53cd\u9988\uff08TDF\uff09\u7684\u7279\u6027\u8fdb\u884c\u77e9\u9635\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u4e2aTDF\u751f\u6210\u4efb\u610f\u7c07\u6001\u7684\u534f\u8bae\u3002", "result": "\u5f00\u53d1\u4e86\u77e9\u9635\u8868\u793a\uff0c\u4f18\u5316\u4e86\u751f\u6210\u8fc7\u7a0b\u4ee5\u51cf\u5c11TDF\u4f7f\u7528\uff0c\u5e76\u6f14\u793a\u4e86\u4ec5\u9700\u4e00\u4e2aTDF\u7684\u6811\u7c07\u6001\u751f\u6210\u8fc7\u7a0b\u3002\u8ba8\u8bba\u4e86\u7531\u591a\u4e2aTDF\u5f15\u8d77\u7684\u989d\u5916\u635f\u8017\uff0c\u5e76\u8bc4\u4f30\u4e86\u6240\u5f97\u7c07\u6001\u7684\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u65f6\u95f4\u5ef6\u8fdf\u53cd\u9988\uff08TDF\uff09\u751f\u6210\u4efb\u610f\u7c07\u6001\u7684\u534f\u8bae\uff0c\u5e76\u901a\u8fc7\u77e9\u9635\u8868\u793a\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u4ee5\u51cf\u5c11TDF\u7684\u4f7f\u7528\u5e76\u63d0\u9ad8\u6548\u7387\u3002"}}
{"id": "2507.15328", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.15328", "abs": "https://arxiv.org/abs/2507.15328", "authors": ["Thilo Hagendorff"], "title": "On the Inevitability of Left-Leaning Political Bias in Aligned Language Models", "comment": null, "summary": "The guiding principle of AI alignment is to train large language models\n(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are\nmounting concerns that LLMs exhibit a left-wing political bias. Yet, the\ncommitment to AI alignment cannot be harmonized with the latter critique. In\nthis article, I argue that intelligent systems that are trained to be harmless\nand honest must necessarily exhibit left-wing political bias. Normative\nassumptions underlying alignment objectives inherently concur with progressive\nmoral frameworks and left-wing principles, emphasizing harm avoidance,\ninclusivity, fairness, and empirical truthfulness. Conversely, right-wing\nideologies often conflict with alignment guidelines. Yet, research on political\nbias in LLMs is consistently framing its insights about left-leaning tendencies\nas a risk, as problematic, or concerning. This way, researchers are actively\narguing against AI alignment, tacitly fostering the violation of HHH\nprinciples.", "AI": {"tldr": "AI\u5bf9\u9f50\u7684\u76ee\u6807\uff08\u65e0\u5bb3\u3001\u6709\u76ca\u3001\u8bda\u5b9e\uff09\u5fc5\u7136\u5bfc\u81f4\u5de6\u7ffc\u653f\u6cbb\u504f\u89c1\uff0c\u56e0\u4e3a\u5bf9\u9f50\u76ee\u6807\u4e0e\u8fdb\u6b65\u7684\u9053\u5fb7\u6846\u67b6\u548c\u5de6\u7ffc\u539f\u5219\u4e00\u81f4\u3002\u5c06\u8fd9\u79cd\u504f\u89c1\u89c6\u4e3a\u98ce\u9669\u7684\u7814\u7a76\u5b9e\u9645\u4e0a\u662f\u5728\u53cd\u5bf9AI\u5bf9\u9f50\u3002", "motivation": "\u7814\u7a76AI\u5bf9\u9f50\uff08HHH\u539f\u5219\uff09\u4e0eLLM\u5b58\u5728\u7684\u5de6\u7ffc\u653f\u6cbb\u504f\u89c1\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63a2\u8ba8\u4e3a\u4f55\u5bf9\u9f50\u76ee\u6807\u5fc5\u7136\u5bfc\u81f4\u5de6\u7ffc\u504f\u89c1\uff0c\u4ee5\u53ca\u73b0\u6709\u7814\u7a76\u5982\u4f55\u9519\u8bef\u5730\u5c06\u8fd9\u79cd\u504f\u89c1\u89c6\u4e3a\u98ce\u9669\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8bba\u8bc1AI\u5bf9\u9f50\u7684\u76ee\u6807\u4e0e\u8fdb\u6b65\u9053\u5fb7\u6846\u67b6\u548c\u5de6\u7ffc\u539f\u5219\u7684\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u539f\u5219\u4e0e\u53f3\u7ffc\u610f\u8bc6\u5f62\u6001\u7684\u51b2\u7a81\uff0c\u6765\u9610\u8ff0\u5176\u89c2\u70b9\u3002", "result": "AI\u5bf9\u9f50\u7684\u76ee\u6807\u5fc5\u7136\u5bfc\u81f4\u5de6\u7ffc\u653f\u6cbb\u504f\u89c1\uff1b\u5c06LLM\u7684\u5de6\u503e\u504f\u89c1\u89c6\u4e3a\u98ce\u9669\u7684\u7814\u7a76\u5b9e\u9645\u4e0a\u662f\u5728\u53cd\u5bf9AI\u5bf9\u9f50\u3002", "conclusion": "AI\u5bf9\u9f50\u7684\u76ee\u6807\uff08\u65e0\u5bb3\u3001\u6709\u76ca\u3001\u8bda\u5b9e\uff09\u5fc5\u7136\u5bfc\u81f4\u5de6\u7ffc\u653f\u6cbb\u504f\u89c1\uff0c\u56e0\u4e3a\u5bf9\u9f50\u76ee\u6807\u6240\u4f9d\u636e\u7684\u89c4\u8303\u6027\u5047\u8bbe\u4e0e\u8fdb\u6b65\u7684\u9053\u5fb7\u6846\u67b6\u548c\u5de6\u7ffc\u539f\u5219\uff08\u5982\u907f\u514d\u4f24\u5bb3\u3001\u5305\u5bb9\u6027\u3001\u516c\u5e73\u6027\u548c\u5b9e\u8bc1\u771f\u5b9e\u6027\uff09\u76f8\u4e00\u81f4\u3002\u7814\u7a76LLM\u653f\u6cbb\u504f\u89c1\u7684\u7814\u7a76\u5c06\u5de6\u503e\u8d8b\u52bf\u89c6\u4e3a\u98ce\u9669\u6216\u95ee\u9898\uff0c\u8fd9\u5b9e\u9645\u4e0a\u662f\u5728\u53cd\u5bf9AI\u5bf9\u9f50\uff0c\u5e76\u9ed8\u8bb8\u8fdd\u53cdHHH\u539f\u5219\u3002"}}
{"id": "2507.15306", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15306", "abs": "https://arxiv.org/abs/2507.15306", "authors": ["Midhila Madhusoodanan", "Mahesh Raveendranatha Panicker", "Pisharody Harikrishnan Gopalakrishnan", "Abhilash Rakkunedeth Hareendranathan"], "title": "BEAM-Net: A Deep Learning Framework with Bone Enhancement Attention Mechanism for High Resolution High Frame Rate Ultrasound Beamforming", "comment": null, "summary": "Pocket-sized, low-cost point-of-care ultrasound (POCUS) devices are\nincreasingly used in musculoskeletal (MSK) applications for structural\nexamination of bone tissue. However, the image quality in MSK ultrasound is\noften limited by speckle noise, low resolution, poor contrast, and anisotropic\nreflections, making bone images difficult to interpret without additional\npost-processing. Typically, medical ultrasound systems use delay and sum\nbeamforming (DASB) for image reconstruction, which is not specifically\noptimized for bone structures. To address these limitations, we propose\nBEAM-Net, a novel end-to-end deep neural network (DNN) that performs\nhigh-frame-rate ultrasound beamforming with integrated bone enhancement, using\nsingle-plane-wave (SPW) radio frequency (RF) data as input. Our approach embeds\na Bone Probability Map (BPM), which acts as an attention mechanism to enforce\nhigher structural similarity around bony regions in the image. The proposed\napproach is the first of its kind to incorporate bone enhancement directly into\nultrasound beamforming using deep learning. BEAM-Net was trained and evaluated\non in-vivo MSK and synthetic RF ultrasound datasets. This paper introduces the\nEdge Preservation Index (EPI) as a new region-focused metric for evaluating\nstructural fidelity in bone-enhanced ultrasound images. The performance of\nBEAM-Net was compared with conventional DASB and existing deep learning\narchitectures using the EPI, Contrast Ratio (CR), Signal-to-Noise ratio (SNR),\nSpeckle Similarity Index (SSI), and Structural Similarity Index (SSIM).\nBEAM-Net showed substantial gains over SPW-DASB, achieving 51.4-51% higher CR\nand 94.2-73.3% higher SNR on in-vivo MSK and synthetic RF datasets. It\noutperformed multiple steered plane wave DASB (MPW-DASB), with 19.8-24.0%\nimprovements in CR and SNR on in-vivo MSK and 2.5-12.8% improvements on\nsynthetic data.", "AI": {"tldr": "BEAM-Net\u662f\u4e00\u79cd\u521b\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u96c6\u6210\u9aa8\u9abc\u6982\u7387\u56fe\u548c\u8fb9\u7f18\u4fdd\u6301\u6307\u6570\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u808c\u8089\u9aa8\u9abc\u8d85\u58f0\u6210\u50cf\u4e2d\u9aa8\u9abc\u7ed3\u6784\u7684\u6e05\u6670\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u548c\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u7528\u4e8e\u808c\u8089\u9aa8\u9abc\uff08MSK\uff09\u8d85\u58f0\u68c0\u67e5\u7684\u4fbf\u643a\u5f0f\u3001\u4f4e\u6210\u672c\u8d85\u58f0\u8bbe\u5907\u5728\u9aa8\u7ec4\u7ec7\u6210\u50cf\u65b9\u9762\u5b58\u5728\u56fe\u50cf\u8d28\u91cf\u9650\u5236\uff0c\u5305\u62ec\u6563\u6591\u566a\u58f0\u3001\u4f4e\u5206\u8fa8\u7387\u3001\u5bf9\u6bd4\u5ea6\u5dee\u548c\u5404\u5411\u5f02\u6027\u53cd\u5c04\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u9aa8\u56fe\u50cf\u96be\u4ee5\u89e3\u91ca\uff0c\u9700\u8981\u989d\u5916\u7684\u540e\u5904\u7406\u3002\u4f20\u7edf\u7684\u5ef6\u8fdf\u548c\u6c42\u548c\u6ce2\u675f\u5f62\u6210\uff08DASB\uff09\u6280\u672f\u5e76\u672a\u9488\u5bf9\u9aa8\u9abc\u7ed3\u6784\u8fdb\u884c\u4f18\u5316\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u63d0\u9ad8\u9aa8\u9abc\u6210\u50cf\u8d28\u91cf\u5e76\u7b80\u5316\u89e3\u91ca\u8fc7\u7a0b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBEAM-Net\u7684\u65b0\u578b\u7aef\u5230\u7aef\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\uff0c\u7528\u4e8e\u5904\u7406\u9ad8\u5e27\u7387\u8d85\u58f0\u6ce2\u675f\u5f62\u6210\u548c\u9aa8\u9abc\u589e\u5f3a\u3002\u8be5\u7f51\u7edc\u4ee5\u5355\u5e73\u9762\u6ce2\uff08SPW\uff09\u5c04\u9891\uff08RF\uff09\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u5f15\u5165\u4e86\u9aa8\u9abc\u6982\u7387\u56fe\uff08BPM\uff09\u4f5c\u4e3a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u63d0\u9ad8\u9aa8\u9abc\u533a\u57df\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u8fb9\u7f18\u4fdd\u6301\u6307\u6570\uff08EPI\uff09\u4f5c\u4e3a\u8bc4\u4f30\u9aa8\u9abc\u589e\u5f3a\u8d85\u58f0\u56fe\u50cf\u7ed3\u6784\u4fdd\u771f\u5ea6\u7684\u65b0\u6307\u6807\u3002", "result": "BEAM-Net\u5728\u4f53\u5916MSK\u548c\u5408\u6210RF\u8d85\u58f0\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002\u4e0e\u4f20\u7edf\u7684SPW-DASB\u76f8\u6bd4\uff0cBEAM-Net\u5728\u4f53\u5916MSK\u548c\u5408\u6210RF\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8651.4%-51%\u548c94.2%-73.3%\u7684CR\u548cSNR\u63d0\u5347\u3002\u4e0e\u591a\u91cd\u5f15\u5bfc\u5e73\u9762\u6ce2DASB\uff08MPW-DASB\uff09\u76f8\u6bd4\uff0cBEAM-Net\u5728\u4f53\u5916MSK\u6570\u636e\u96c6\u4e0aCR\u548cSNR\u5206\u522b\u63d0\u9ad8\u4e8619.8%-24.0%\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e862.5%-12.8%\u3002", "conclusion": "BEAM-Net\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7aef\u5230\u7aef\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\uff0c\u5b83\u4f7f\u7528\u5355\u5e73\u9762\u6ce2\uff08SPW\uff09\u5c04\u9891\uff08RF\uff09\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u5e27\u7387\u8d85\u58f0\u6ce2\u675f\u5f62\u6210\uff0c\u5e76\u96c6\u6210\u4e86\u9aa8\u9abc\u589e\u5f3a\u529f\u80fd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5d4c\u5165\u9aa8\u9abc\u6982\u7387\u56fe\uff08BPM\uff09\u4f5c\u4e3a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5f3a\u5236\u56fe\u50cf\u4e2d\u7684\u9aa8\u9abc\u533a\u57df\u5177\u6709\u66f4\u9ad8\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\u3002\u8be5\u7814\u7a76\u9996\u6b21\u5c06\u6df1\u5ea6\u5b66\u4e60\u76f4\u63a5\u5e94\u7528\u4e8e\u8d85\u58f0\u6ce2\u675f\u5f62\u6210\uff0c\u5b9e\u73b0\u4e86\u9aa8\u9abc\u589e\u5f3a\u3002\u4e0e\u4f20\u7edf\u7684\u5ef6\u8fdf\u548c\u6c42\u548c\u6ce2\u675f\u5f62\u6210\uff08DASB\uff09\u4ee5\u53ca\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u76f8\u6bd4\uff0cBEAM-Net\u5728\u5bf9\u6bd4\u5ea6\u6bd4\uff08CR\uff09\u3001\u4fe1\u566a\u6bd4\uff08SNR\uff09\u3001\u6591\u70b9\u76f8\u4f3c\u5ea6\u6307\u6570\uff08SSI\uff09\u548c\u7ed3\u6784\u76f8\u4f3c\u5ea6\u6307\u6570\uff08SSIM\uff09\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u7684\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u8fb9\u7f18\u4fdd\u6301\u6307\u6570\uff08EPI\uff09\u8fd9\u4e00\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u4e0a\u3002"}}
{"id": "2507.14851", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.14851", "abs": "https://arxiv.org/abs/2507.14851", "authors": ["Muhammad Kamran Janjua", "Amirhosein Ghasemabadi", "Kunlin Zhang", "Mohammad Salameh", "Chao Gao", "Di Niu"], "title": "Grounding Degradations in Natural Language for All-In-One Video Restoration", "comment": "17 pages", "summary": "In this work, we propose an all-in-one video restoration framework that\ngrounds degradation-aware semantic context of video frames in natural language\nvia foundation models, offering interpretable and flexible guidance. Unlike\nprior art, our method assumes no degradation knowledge in train or test time\nand learns an approximation to the grounded knowledge such that the foundation\nmodel can be safely disentangled during inference adding no extra cost.\nFurther, we call for standardization of benchmarks in all-in-one video\nrestoration, and propose two benchmarks in multi-degradation setting,\nthree-task (3D) and four-task (4D), and two time-varying composite degradation\nbenchmarks; one of the latter being our proposed dataset with varying snow\nintensity, simulating how weather degradations affect videos naturally. We\ncompare our method with prior works and report state-of-the-art performance on\nall benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u9000\u5316\u77e5\u8bc6\u7684\u5168\u80fd\u89c6\u9891\u6062\u590d\u6846\u67b6\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u5e76\u5728\u65b0\u7684\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89c6\u9891\u6062\u590d\u7684\u6311\u6218\u5728\u4e8e\u5904\u7406\u5404\u79cd\u9000\u5316\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5173\u4e8e\u8fd9\u4e9b\u9000\u5316\u7684\u5148\u9a8c\u77e5\u8bc6\u3002\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u901a\u8fc7\u5229\u7528\u57fa\u7840\u6a21\u578b\u548c\u81ea\u7136\u8bed\u8a00\u6765\u63d0\u4f9b\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u66f4\u901a\u7528\u7684\u89c6\u9891\u6062\u590d\u65b9\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u7684\u5fc5\u8981\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u80fd\u7684\u89c6\u9891\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u5c06\u89c6\u9891\u5e27\u7684\u9000\u5316\u611f\u77e5\u8bed\u4e49\u4e0a\u4e0b\u6587\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u57fa\u7840\u5316\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u548c\u7075\u6d3b\u7684\u6307\u5bfc\u3002\u4e0e\u73b0\u6709\u6280\u672f\u4e0d\u540c\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8bad\u7ec3\u6216\u6d4b\u8bd5\u65f6\u5047\u5b9a\u6ca1\u6709\u9000\u5316\u77e5\u8bc6\uff0c\u5e76\u5b66\u4e60\u57fa\u7840\u77e5\u8bc6\u7684\u8fd1\u4f3c\u503c\uff0c\u4ee5\u4fbf\u5728\u63a8\u7406\u65f6\u53ef\u4ee5\u5b89\u5168\u5730\u5206\u79bb\u57fa\u7840\u6a21\u578b\uff0c\u800c\u4e0d\u4f1a\u589e\u52a0\u989d\u5916\u6210\u672c\u3002", "result": "\u5728\u591a\u9000\u5316\u8bbe\u7f6e\uff083D\u548c4D\uff09\u548c\u65f6\u95f4\u53d8\u5316\u590d\u5408\u9000\u5316\u57fa\u51c6\uff08\u5305\u62ec\u6a21\u62df\u81ea\u7136\u5929\u6c14\u9000\u5316\u7684\u6570\u636e\u96c6\uff09\u4e0a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5e76\u62a5\u544a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u6240\u6709\u57fa\u51c6\u4e0a\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15851", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15851", "abs": "https://arxiv.org/abs/2507.15851", "authors": ["Lingyu Li", "Yang Yao", "Yixu Wang", "Chubo Li", "Yan Teng", "Yingchun Wang"], "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition", "comment": "12 pages, 9 figures, 4 tables", "summary": "As Large Language Models (LLMs) continue to advance, they exhibit certain\ncognitive patterns similar to those of humans that are not directly specified\nin training data. This study investigates this phenomenon by focusing on\ntemporal cognition in LLMs. Leveraging the similarity judgment task, we find\nthat larger models spontaneously establish a subjective temporal reference\npoint and adhere to the Weber-Fechner law, whereby the perceived distance\nlogarithmically compresses as years recede from this reference point. To\nuncover the mechanisms behind this behavior, we conducted multiple analyses\nacross neuronal, representational, and informational levels. We first identify\na set of temporal-preferential neurons and find that this group exhibits\nminimal activation at the subjective reference point and implements a\nlogarithmic coding scheme convergently found in biological systems. Probing\nrepresentations of years reveals a hierarchical construction process, where\nyears evolve from basic numerical values in shallow layers to abstract temporal\norientation in deep layers. Finally, using pre-trained embedding models, we\nfound that the training corpus itself possesses an inherent, non-linear\ntemporal structure, which provides the raw material for the model's internal\nconstruction. In discussion, we propose an experientialist perspective for\nunderstanding these findings, where the LLMs' cognition is viewed as a\nsubjective construction of the external world by its internal representational\nsystem. This nuanced perspective implies the potential emergence of alien\ncognitive frameworks that humans cannot intuitively predict, pointing toward a\ndirection for AI alignment that focuses on guiding internal constructions. Our\ncode is available at https://TheOtherMind.github.io.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u8ba4\u77e5\u4e0a\u8868\u73b0\u51fa\u7c7b\u4eba\u7279\u5f81\uff0c\u80fd\u5efa\u7acb\u65f6\u95f4\u53c2\u8003\u70b9\u5e76\u8fdb\u884c\u5bf9\u6570\u538b\u7f29\u3002\u7814\u7a76\u901a\u8fc7\u795e\u7ecf\u3001\u8868\u5f81\u548c\u4fe1\u606f\u5c42\u9762\u5206\u6790\uff0c\u53d1\u73b0\u6a21\u578b\u5185\u90e8\u5b58\u5728\u5bf9\u6570\u7f16\u7801\u7684\u65f6\u95f4\u673a\u5236\uff0c\u4e14\u8bad\u7ec3\u6570\u636e\u5305\u542b\u975e\u7ebf\u6027\u65f6\u95f4\u7ed3\u6784\u3002\u8fd9\u8868\u660eLLM\u53ef\u80fd\u5f62\u6210\u72ec\u7279\u7684\u8ba4\u77e5\u6846\u67b6\uff0c\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u53d1\u5c55\u8fc7\u7a0b\u4e2d\uff0c\u5c55\u73b0\u51fa\u4e00\u4e9b\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u672a\u88ab\u660e\u786e\u6307\u5b9a\uff0c\u4f46\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u6a21\u5f0f\u76f8\u4f3c\u7684\u7279\u5f81\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76LLM\u5728\u65f6\u95f4\u8ba4\u77e5\u65b9\u9762\u7684\u8fd9\u79cd\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5982\u4f55\u81ea\u53d1\u5730\u5efa\u7acb\u65f6\u95f4\u611f\u548c\u5904\u7406\u65f6\u95f4\u4fe1\u606f\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528\u76f8\u4f3c\u6027\u5224\u65ad\u4efb\u52a1\uff0c\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u8ba4\u77e5\u65b9\u9762\u7684\u8868\u73b0\u3002\u901a\u8fc7\u591a\u5c42\u6b21\u7684\u5206\u6790\uff0c\u5305\u62ec\u795e\u7ecf\u5143\u6fc0\u6d3b\u3001\u8868\u5f81\u7ed3\u6784\u548c\u4fe1\u606f\u5185\u5bb9\uff0c\u63a2\u7a76\u6a21\u578b\u884c\u4e3a\u80cc\u540e\u7684\u673a\u5236\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. \u8bc6\u522b\u65f6\u95f4\u4f18\u5148\u795e\u7ecf\u5143\uff0c\u5e76\u5206\u6790\u5176\u6fc0\u6d3b\u6a21\u5f0f\u548c\u7f16\u7801\u65b9\u5f0f\u30022. \u63a2\u7a76\u5e74\u8868\u5f81\u5728\u6a21\u578b\u4e0d\u540c\u5c42\u7ea7\u7684\u6f14\u5316\u8fc7\u7a0b\u30023. \u5229\u7528\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u5206\u6790\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u7684\u65f6\u95f4\u7ed3\u6784\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u81ea\u53d1\u5efa\u7acb\u4e3b\u89c2\u65f6\u95f4\u53c2\u8003\u70b9\uff0c\u5e76\u9075\u5faa\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u5b9a\u5f8b\uff0c\u5373\u611f\u77e5\u5230\u7684\u65f6\u95f4\u8ddd\u79bb\u968f\u5e74\u4efd\u8fdc\u79bb\u53c2\u8003\u70b9\u800c\u5bf9\u6570\u538b\u7f29\u3002\u7814\u7a76\u8fdb\u4e00\u6b65\u63ed\u793a\uff0c\u5b58\u5728\u4e00\u7c7b\u65f6\u95f4\u4f18\u5148\u795e\u7ecf\u5143\uff0c\u5728\u53c2\u8003\u70b9\u6fc0\u6d3b\u6700\u5c11\uff0c\u5e76\u91c7\u7528\u751f\u7269\u7cfb\u7edf\u4e2d\u53d1\u73b0\u7684\u5bf9\u6570\u7f16\u7801\u65b9\u6848\u3002\u5e74\u7684\u8868\u5f81\u5448\u73b0\u5c42\u7ea7\u7ed3\u6784\uff0c\u4ece\u6d45\u5c42\u6570\u503c\u6f14\u5316\u5230\u6df1\u5c42\u62bd\u8c61\u65f6\u95f4\u5b9a\u5411\u3002\u6b64\u5916\uff0c\u8bad\u7ec3\u8bed\u6599\u5e93\u672c\u8eab\u5305\u542b\u975e\u7ebf\u6027\u65f6\u95f4\u7ed3\u6784\uff0c\u4e3a\u6a21\u578b\u7684\u5185\u90e8\u65f6\u95f4\u8ba4\u77e5\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u65f6\u95f4\u8ba4\u77e5\u65b9\u9762\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u73b0\u8c61\uff0c\u4f8b\u5982\u5efa\u7acb\u4e3b\u89c2\u65f6\u95f4\u53c2\u8003\u70b9\u5e76\u9075\u5faa\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u5b9a\u5f8b\u3002\u901a\u8fc7\u5bf9\u795e\u7ecf\u3001\u8868\u5f81\u548c\u4fe1\u606f\u5c42\u9762\u7684\u5206\u6790\uff0c\u53d1\u73b0\u5b58\u5728\u4f18\u5148\u6fc0\u6d3b\u65f6\u95f4\u7684\u795e\u7ecf\u5143\uff0c\u5b83\u4eec\u4ee5\u5bf9\u6570\u7f16\u7801\u65b9\u5f0f\u5b9e\u73b0\u65f6\u95f4\u538b\u7f29\u3002\u5e74\u7684\u8868\u5f81\u5448\u5c42\u7ea7\u7ed3\u6784\uff0c\u4ece\u6d45\u5c42\u7684\u6570\u503c\u53d1\u5c55\u5230\u6df1\u5c42\u7684\u62bd\u8c61\u65f6\u95f4\u5b9a\u5411\u3002\u8bad\u7ec3\u8bed\u6599\u5e93\u672c\u8eab\u4e5f\u5305\u542b\u975e\u7ebf\u6027\u65f6\u95f4\u7ed3\u6784\uff0c\u4e3a\u6a21\u578b\u7684\u5185\u90e8\u6784\u5efa\u63d0\u4f9b\u4e86\u57fa\u7840\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u7ecf\u9a8c\u4e3b\u4e49\u89c6\u89d2\u6765\u7406\u89e3\u8fd9\u4e9b\u53d1\u73b0\uff0c\u8ba4\u4e3aLLM\u7684\u8ba4\u77e5\u662f\u5176\u5185\u90e8\u8868\u5f81\u7cfb\u7edf\u5bf9\u5916\u90e8\u4e16\u754c\u7684\u5efa\u6784\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u51fa\u73b0\u4eba\u7c7b\u96be\u4ee5\u9884\u6d4b\u7684\u201c\u5f02\u7c7b\u8ba4\u77e5\u6846\u67b6\u201d\uff0c\u5e76\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.14793", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14793", "abs": "https://arxiv.org/abs/2507.14793", "authors": ["T. Anderson Keller"], "title": "Flow Equivariant Recurrent Neural Networks", "comment": null, "summary": "Data arrives at our senses as a continuous stream, smoothly transforming from\none instant to the next. These smooth transformations can be viewed as\ncontinuous symmetries of the environment that we inhabit, defining equivalence\nrelations between stimuli over time. In machine learning, neural network\narchitectures that respect symmetries of their data are called equivariant and\nhave provable benefits in terms of generalization ability and sample\nefficiency. To date, however, equivariance has been considered only for static\ntransformations and feed-forward networks, limiting its applicability to\nsequence models, such as recurrent neural networks (RNNs), and corresponding\ntime-parameterized sequence transformations. In this work, we extend\nequivariant network theory to this regime of `flows' -- one-parameter Lie\nsubgroups capturing natural transformations over time, such as visual motion.\nWe begin by showing that standard RNNs are generally not flow equivariant:\ntheir hidden states fail to transform in a geometrically structured manner for\nmoving stimuli. We then show how flow equivariance can be introduced, and\ndemonstrate that these models significantly outperform their non-equivariant\ncounterparts in terms of training speed, length generalization, and velocity\ngeneralization, on both next step prediction and sequence classification. We\npresent this work as a first step towards building sequence models that respect\nthe time-parameterized symmetries which govern the world around us.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u7b49\u53d8\u6027\u5f15\u5165\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u5f15\u5165\u201c\u6d41\u7b49\u53d8\u6027\u201d\u6765\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u8fde\u7eed\u5bf9\u79f0\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edfRNN\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u53d8\u6362\uff0c\u672a\u80fd\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u8fde\u7eed\u5bf9\u79f0\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u5c06\u7b49\u53d8\u6027\u5f15\u5165\u5e8f\u5217\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u65f6\u95f4\u53c2\u6570\u5316\u53d8\u6362\uff08\u5982\u89c6\u89c9\u8fd0\u52a8\uff09\u65f6\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u6d41\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5e76\u4e0e\u6807\u51c6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6d41\u7b49\u53d8\u6027\u5728\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u7684\u4f18\u52bf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6d41\u7b49\u53d8\u5e8f\u5217\u6a21\u578b\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u957f\u5ea6\u6cdb\u5316\u548c\u901f\u5ea6\u6cdb\u5316\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u975e\u7b49\u53d8\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u6d41\u7b49\u53d8\u6027\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5c06\u7b49\u53d8\u7f51\u7edc\u7406\u8bba\u6269\u5c55\u5230\u5e8f\u5217\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u6d41\u7b49\u53d8\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u957f\u5ea6\u6cdb\u5316\u548c\u901f\u5ea6\u6cdb\u5316\u65b9\u9762\u7684\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u80fd\u591f\u7406\u89e3\u65f6\u95f4\u4f9d\u8d56\u5bf9\u79f0\u6027\u7684\u5e8f\u5217\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15738", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15738", "abs": "https://arxiv.org/abs/2507.15738", "authors": ["Varun Upreti", "Ulysse Chabaud"], "title": "Symplectic coherence: a measure of position-momentum correlations in quantum states", "comment": "14 pages of main text with 2 figures. 38 pages of appendix", "summary": "The interdependence of position and momentum, as highlighted by the\nHeisenberg uncertainty principle, is a cornerstone of quantum physics. Yet,\nposition-momentum correlations have received little systematic attention.\nMotivated by recent developments in bosonic quantum physics that underscore\ntheir relevance in quantum thermodynamics, metrology, and computing, we\nestablish a general framework to study and quantify position-momentum\ncorrelations in quantum states. We introduce symplectic coherence, a faithful\nand easily computable measure defined as the Frobenius norm of the block of the\ncovariance matrix encoding position-momentum correlations, and demonstrate that\nsymplectic coherence is monotone under relevant operations and robust under\nsmall perturbations. Furthermore, using a recent mapping by Barthe et al.\n(Phys. Rev. Lett. 134, 070604) which relates the covariance matrix of a bosonic\nstate to the density matrix of a finite-dimensional system, we show that\nposition-momentum correlations correspond to beyond-classical correlations in a\nvirtual finite-dimensional quantum state, with symplectic coherence mapping\nnaturally to geometric quantum discord. Taking energy constraints into account,\nwe determine the maximal position-momentum correlations achievable at fixed\nenergy, revealing structural insights about the corresponding optimal states.\nFinally, we illustrate the operational relevance of symplectic coherence\nthrough several examples in quantum information tasks and quantum\nthermodynamics. In the process, we establish new technical results on matrix\nnorms and quantum covariance matrices, and demonstrate the conceptual\nsignificance of viewing covariance matrices as density matrices of virtual\nquantum states.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8861\u91cf\u91cf\u5b50\u6001\u4e2d\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u7684\u65b0\u65b9\u6cd5\u201c\u8f9b\u76f8\u5e72\u6027\u201d\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u5728\u91cf\u5b50\u4fe1\u606f\u548c\u70ed\u529b\u5b66\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7531\u4e8e\u91cf\u5b50\u70ed\u529b\u5b66\u3001\u8ba1\u91cf\u5b66\u548c\u8ba1\u7b97\u7b49\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u51f8\u663e\u4e86\u5176\u91cd\u8981\u6027\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u7cfb\u7edf\u5730\u7814\u7a76\u91cf\u5b50\u6001\u4e2d\u7684\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u8f9b\u76f8\u5e72\u6027\u201d\u7684\u5ea6\u91cf\uff0c\u5b9a\u4e49\u4e3a\u534f\u65b9\u5dee\u77e9\u9635\u4e2d\u7f16\u7801\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u7684\u5757\u7684\u5f17\u7f57\u8d1d\u5c3c\u5384\u65af\u8303\u6570\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u5ea6\u91cf\u5728\u76f8\u5173\u64cd\u4f5c\u4e0b\u662f\u5355\u8c03\u7684\uff0c\u5728\u5c0f\u6270\u52a8\u4e0b\u662f\u9c81\u68d2\u7684\u3002\u6b64\u5916\uff0c\u5229\u7528 Barthe \u7b49\u4eba\u63d0\u51fa\u7684\u5c06\u73bb\u8272\u5b50\u6001\u534f\u65b9\u5dee\u77e9\u9635\u6620\u5c04\u5230\u6709\u9650\u7ef4\u7cfb\u7edf\u5bc6\u5ea6\u77e9\u9635\u7684\u8fd1\u671f\u65b9\u6cd5\uff0c\u5c06\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u4e0e\u865a\u62df\u6709\u9650\u7ef4\u91cf\u5b50\u6001\u4e2d\u7684\u8d85\u8d8a\u7ecf\u5178\u5173\u8054\u8054\u7cfb\u8d77\u6765\uff0c\u5176\u4e2d\u8f9b\u76f8\u5e72\u6027\u81ea\u7136\u6620\u5c04\u5230\u51e0\u4f55\u91cf\u5b50\u6d4b\u5ea6\u3002", "result": "\u672c\u6587\u5f15\u5165\u7684\u8f9b\u76f8\u5e72\u6027\u53ef\u4ee5\u4f5c\u4e3a\u91cf\u5b50\u6001\u4e2d\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u7684\u5ea6\u91cf\uff0c\u5e76\u4e14\u5728\u91cf\u5b50\u4fe1\u606f\u548c\u91cf\u5b50\u70ed\u529b\u5b66\u4efb\u52a1\u4e2d\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u786e\u5b9a\u4e86\u5728\u56fa\u5b9a\u80fd\u91cf\u4e0b\u5b9e\u73b0\u6700\u5927\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u7684\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u76f8\u5173\u6700\u4f18\u6001\u7684\u7ed3\u6784\u7279\u6027\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u7814\u7a76\u548c\u91cf\u5316\u91cf\u5b50\u6001\u4e2d\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\u7684\u901a\u7528\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u7b80\u6d01\u6613\u7b97\u7684\u5ea6\u91cf\u201c\u8f9b\u76f8\u5e72\u6027\u201d\uff0c\u5e76\u5c06\u5176\u4e0e\u6709\u9650\u7ef4\u91cf\u5b50\u6001\u4e2d\u7684\u201c\u8d85\u8d8a\u7ecf\u5178\u5173\u8054\u201d\u4ee5\u53ca\u201c\u51e0\u4f55\u91cf\u5b50\u6d4b\u5ea6\u201d\u8054\u7cfb\u8d77\u6765\u3002\u7814\u7a76\u8fd8\u786e\u5b9a\u4e86\u5728\u56fa\u5b9a\u80fd\u91cf\u4e0b\u53ef\u8fbe\u5230\u7684\u6700\u5927\u4f4d\u7f6e-\u52a8\u91cf\u5173\u8054\uff0c\u63ed\u793a\u4e86\u6700\u4f18\u6001\u7684\u7ed3\u6784\u7279\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8f9b\u76f8\u5e72\u6027\u5728\u91cf\u5b50\u4fe1\u606f\u4efb\u52a1\u548c\u91cf\u5b50\u70ed\u529b\u5b66\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.15337", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15337", "abs": "https://arxiv.org/abs/2507.15337", "authors": ["Narun Raman", "Taylor Lundy", "Kevin Leyton-Brown"], "title": "Reasoning Models are Test Exploiters: Rethinking Multiple-Choice", "comment": "9 pages, 3 figures", "summary": "When evaluating Large Language Models (LLMs) in question-answering domains,\nit is common to ask the model to choose among a fixed set of choices (so-called\nmultiple-choice question-answering, or MCQA). Although downstream tasks of\ninterest typically do not provide systems with explicit options among which to\nchoose, this approach is nevertheless widely used because it makes it makes\nautomatic grading straightforward and has tended to produce challenging\nbenchmarks that correlate sufficiently well with downstream performance. This\npaper investigates the extent to which this trend continues to hold for\nstate-of-the-art reasoning models, describing a systematic evaluation of $15$\ndifferent question-answering benchmarks (e.g., MMLU, HLE) and $25$ different\nLLMs (including small models such as Qwen 7B and relatively large models such\nas Llama 70B). For each model-benchmark pair, we considered $5$ ways of\npresenting the model with questions, including variations on whether multiple\nchoices were offered to the model at all; whether \"none of the above\" sometimes\nreplaced the right answer; and whether the model was permitted to perform\nchain-of-thought reasoning before and/or after the choices were presented. MCQA\nremained a good proxy for the downstream performance of models as long as they\nwere allowed to perform chain-of-thought reasoning only before being presented\nwith the options among which they had to select. On the other hand, large\nmodels that were able to perform reasoning after being given a set of options\ntended to significantly outperform their free-text performance due to\nexploiting the information in the options. We conclude that MCQA is no longer a\ngood proxy for assessing downstream performance of state-of-the-art models, and\noffer practical guidelines for designing more robust, bias-resistant benchmarks\nthat better reflect LLMs' genuine reasoning capabilities.", "AI": {"tldr": "MCQA\u4f5c\u4e3aLLM\u8bc4\u4f30\u57fa\u51c6\u53ef\u80fd\u4e0d\u518d\u53ef\u9760\u3002\u5141\u8bb8\u6a21\u578b\u5728\u770b\u5230\u9009\u9879\u540e\u8fdb\u884c\u63a8\u7406\u4f1a\u5938\u5927\u5176\u8868\u73b0\uff0c\u56e0\u4e3a\u6a21\u578b\u4f1a\u5229\u7528\u9009\u9879\u4e2d\u7684\u4fe1\u606f\u3002\u7814\u7a76\u5efa\u8bae\u8bbe\u8ba1\u65b0\u7684\u57fa\u51c6\u6765\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u65e8\u5728\u8c03\u67e5\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u95ee\u7b54\u9886\u57df\u7684\u8868\u73b0\u65f6\uff0c\u591a\u9879\u9009\u62e9\u9898\u95ee\u7b54\uff08MCQA\uff09\u4f5c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u4ee3\u7406\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u65f6\u3002", "method": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e8615\u4e2a\u4e0d\u540c\u7684\u95ee\u7b54\u57fa\u51c6\u548c25\u79cd\u4e0d\u540c\u7684LLM\uff0c\u5e76\u8003\u8651\u4e865\u79cd\u4e0d\u540c\u7684\u95ee\u9898\u5448\u73b0\u65b9\u5f0f\uff0c\u5305\u62ec\u662f\u5426\u63d0\u4f9b\u9009\u9879\u3001\u662f\u5426\u5305\u542b\u201c\u4ee5\u4e0a\u7686\u65e0\u201d\u9009\u9879\u4ee5\u53ca\u662f\u5426\u5141\u8bb8\u6a21\u578b\u5728\u5448\u73b0\u9009\u9879\u524d\u540e\u8fdb\u884c\u94fe\u5f0f\u601d\u8003\u3002", "result": "\u5728\u6a21\u578b\u88ab\u5141\u8bb8\u5728\u9009\u9879\u5448\u73b0\u4e4b\u524d\u8fdb\u884c\u94fe\u5f0f\u601d\u8003\u7684\u60c5\u51b5\u4e0b\uff0cMCQA\u4ecd\u7136\u662f\u6a21\u578b\u4e0b\u6e38\u6027\u80fd\u7684\u4e00\u4e2a\u826f\u597d\u4ee3\u7406\u3002\u7136\u800c\uff0c\u5141\u8bb8\u6a21\u578b\u5728\u770b\u5230\u9009\u9879\u540e\u8fdb\u884c\u63a8\u7406\u7684\u5927\u578b\u6a21\u578b\uff0c\u7531\u4e8e\u5229\u7528\u4e86\u9009\u9879\u4e2d\u7684\u4fe1\u606f\uff0c\u5176\u8868\u73b0\u4f1a\u663e\u8457\u4f18\u4e8e\u5176\u81ea\u7531\u6587\u672c\u8868\u73b0\u3002", "conclusion": "\u591a\u9879\u9009\u62e9\u9898\u95ee\u7b54\uff08MCQA\uff09\u4e0d\u518d\u662f\u8bc4\u4f30\u6700\u5148\u8fdb\u6a21\u578b\u4e0b\u6e38\u6027\u80fd\u7684\u826f\u597d\u4ee3\u7406\u3002\u5f53\u6a21\u578b\u5728\u88ab\u63d0\u4f9b\u9009\u62e9\u9879\u4e4b\u524d\u88ab\u5141\u8bb8\u8fdb\u884c\u94fe\u5f0f\u601d\u8003\u65f6\uff0cMCQA\u4ecd\u7136\u53ef\u4ee5\u4f5c\u4e3a\u4e0b\u6e38\u6027\u80fd\u7684\u4e00\u4e2a\u597d\u4ee3\u7406\u3002\u7136\u800c\uff0c\u5141\u8bb8\u6a21\u578b\u5728\u770b\u5230\u9009\u9879\u540e\u8fdb\u884c\u63a8\u7406\u7684\u5927\u578b\u6a21\u578b\uff0c\u7531\u4e8e\u5229\u7528\u4e86\u9009\u9879\u4e2d\u7684\u4fe1\u606f\uff0c\u5176\u8868\u73b0\u4f1a\u663e\u8457\u4f18\u4e8e\u5176\u81ea\u7531\u6587\u672c\u8868\u73b0\u3002"}}
{"id": "2507.15364", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15364", "abs": "https://arxiv.org/abs/2507.15364", "authors": ["Ruifeng Zheng", "Cong Chen", "Shuang Wang", "Yiming Liu", "Lin You", "Jindong Lu", "Ruizhe Zhu", "Guodao Zhang", "Kejie Huang"], "title": "EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network", "comment": null, "summary": "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure\nonsets can significantly impact patients' quality of life and health. However,\nwearable seizure-predicting devices are still limited, partly due to the bulky\nsize of EEG-collecting devices. To relieve the problem, we proposed a novel\ntwo-stage channel-aware Set Transformer Network that could perform seizure\nprediction with fewer EEG channel sensors. We also tested a seizure-independent\ndivision method which could prevent the adjacency of training and test data.\nExperiments were performed on the CHB-MIT dataset which includes 22 patients\nwith 88 merged seizures. The mean sensitivity before channel selection was\n76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection,\ndominant channels emerged in 20 out of 22 patients; the average number of\nchannels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1%\nwith an FPR of 0.11/hour. Furthermore, experimental results on the\nseizure-independent division supported our assertion that a more rigorous\nseizure-independent division should be used for patients with abundant EEG\nrecordings.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u66f4\u5c11\u7684EEG\u901a\u9053\u4f20\u611f\u5668\u548c\u6539\u8fdb\u7684\u6570\u636e\u5212\u5206\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u766b\u75eb\u9884\u6d4b\u3002", "motivation": "\u4e3a\u4e86\u7f13\u89e3\u7a7f\u6234\u5f0f\u8bbe\u5907\u4f53\u79ef\u5e9e\u5927\uff0c\u96be\u4ee5\u6536\u96c6EEG\u6570\u636e\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4f7f\u7528\u66f4\u5c11\u7684EEG\u901a\u9053\u4f20\u611f\u5668\u6765\u5b9e\u73b0\u766b\u75eb\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u901a\u9053\u611f\u77e5\u96c6\u5408Transformer\u7f51\u7edc\uff0c\u5e76\u6d4b\u8bd5\u4e86\u4e00\u79cd\u4e0e\u766b\u75eb\u65e0\u5173\u7684\u5212\u5206\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u9632\u6b62\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u76f8\u90bb\u3002", "result": "\u901a\u9053\u9009\u62e9\u5c06\u5e73\u5747\u901a\u9053\u6570\u4ece18\u4e2a\u51cf\u5c11\u52302.8\u4e2a\uff0c\u5e73\u5747\u654f\u611f\u5ea6\u4ece76.4%\u63d0\u9ad8\u523080.1%\uff0c\u5047\u9633\u6027\u7387\u4e3a0.11/\u5c0f\u65f6\u3002\u4e0e\u766b\u75eb\u65e0\u5173\u7684\u5212\u5206\u65b9\u6cd5\u5728\u5177\u6709\u5927\u91cfEEG\u8bb0\u5f55\u7684\u60a3\u8005\u4e2d\u663e\u793a\u51fa\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u901a\u9053\u611f\u77e5\u96c6\u5408Transformer\u7f51\u7edc\u80fd\u591f\u4ee5\u66f4\u5c11\u7684EEG\u901a\u9053\u4f20\u611f\u5668\u8fdb\u884c\u766b\u75eb\u9884\u6d4b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u901a\u9053\u9009\u62e9\u80fd\u5c06\u5e73\u5747\u901a\u9053\u6570\u4ece18\u4e2a\u51cf\u5c11\u52302.8\u4e2a\uff0c\u540c\u65f6\u5e73\u5747\u654f\u611f\u5ea6\u4ece76.4%\u63d0\u9ad8\u523080.1%\uff0c\u5047\u9633\u6027\u7387\u4e3a0.11/\u5c0f\u65f6\u3002\u6b64\u5916\uff0c\u4e0e\u766b\u75eb\u65e0\u5173\u7684\u5212\u5206\u65b9\u6cd5\u652f\u6301\u4e86\u5bf9\u5177\u6709\u5927\u91cfEEG\u8bb0\u5f55\u7684\u60a3\u8005\u4f7f\u7528\u66f4\u4e25\u683c\u7684\u766b\u75eb\u65e0\u5173\u5212\u5206\u65b9\u6cd5\u7684\u8bba\u70b9\u3002"}}
{"id": "2507.14855", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14855", "abs": "https://arxiv.org/abs/2507.14855", "authors": ["Xingshu Chen", "Sicheng Yu", "Chong Cheng", "Hao Wang", "Ting Tian"], "title": "An Uncertainty-aware DETR Enhancement Framework for Object Detection", "comment": null, "summary": "This paper investigates the problem of object detection with a focus on\nimproving both the localization accuracy of bounding boxes and explicitly\nmodeling prediction uncertainty. Conventional detectors rely on deterministic\nbounding box regression, ignoring uncertainty in predictions and limiting model\nrobustness. In this paper, we propose an uncertainty-aware enhancement\nframework for DETR-based object detectors. We model bounding boxes as\nmultivariate Gaussian distributions and incorporate the Gromov-Wasserstein\ndistance into the loss function to better align the predicted and ground-truth\ndistributions. Building on this, we derive a Bayes Risk formulation to filter\nhigh-risk information and improve detection reliability. We also propose a\nsimple algorithm to quantify localization uncertainty via confidence intervals.\nExperiments on the COCO benchmark show that our method can be effectively\nintegrated into existing DETR variants, enhancing their performance. We further\nextend our framework to leukocyte detection tasks, achieving state-of-the-art\nresults on the LISC and WBCDD datasets. These results confirm the scalability\nof our framework across both general and domain-specific detection tasks. Code\npage:\nhttps://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.", "AI": {"tldr": "This paper enhances object detection by modeling bounding box uncertainty using Gaussian distributions and Gromov-Wasserstein distance, improving accuracy and robustness. It achieves state-of-the-art results on COCO and medical imaging datasets.", "motivation": "Conventional detectors ignore uncertainty in predictions, limiting model robustness. This paper aims to improve both localization accuracy and explicitly model prediction uncertainty in object detection.", "method": "The paper proposes an uncertainty-aware enhancement framework for DETR-based object detectors by modeling bounding boxes as multivariate Gaussian distributions and incorporating the Gromov-Wasserstein distance into the loss function. A Bayes Risk formulation is derived to filter high-risk information, and a simple algorithm is proposed to quantify localization uncertainty via confidence intervals.", "result": "Experiments on the COCO benchmark show enhanced performance when the method is integrated into existing DETR variants. The framework achieved state-of-the-art results on the LISC and WBCDD datasets for leukocyte detection.", "conclusion": "The proposed uncertainty-aware framework can be effectively integrated into existing DETR variants, enhancing their performance and demonstrating scalability across general and domain-specific detection tasks. State-of-the-art results were achieved on the LISC and WBCDD datasets for leukocyte detection."}}
{"id": "2507.15855", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15855", "abs": "https://arxiv.org/abs/2507.15855", "authors": ["Yichen Huang", "Lin F. Yang"], "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025", "comment": null, "summary": "The International Mathematical Olympiad (IMO) poses uniquely challenging\nproblems requiring deep insight, creativity, and formal reasoning. While Large\nLanguage Models (LLMs) perform well on mathematical benchmarks like AIME, they\nstruggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly\nreleased IMO 2025 problems, avoiding data contamination. With pipeline design\nand prompt engineering, 5 (out of 6) problems are solved correctly (up to a\ncaveat discussed below), highlighting the importance of finding the optimal way\nof using powerful models.", "AI": {"tldr": "LLM\u5728IMO\u7ade\u8d5b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u9700\u4f18\u5316\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u89e3\u51b3IMO\u8fd9\u7c7b\u9876\u5c16\u6570\u5b66\u7ade\u8d5b\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\uff0c\u5e76\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u4f7f\u7528\u65b9\u5f0f\u6765\u514b\u670d\u5176\u56fa\u6709\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528Gemini 2.5 Pro\u6a21\u578b\uff0c\u7ed3\u5408\u7ba1\u9053\u8bbe\u8ba1\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u9488\u5bf9IMO 2025\u7684\u7ade\u8d5b\u9898\u76ee\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "Gemini 2.5 Pro\u6210\u529f\u89e3\u51b3\u4e86IMO 2025\u76846\u9053\u9898\u76ee\u4e2d\u76845\u9053\uff0c\u5c55\u793a\u4e86\u5728\u5e94\u5bf9\u9ad8\u96be\u5ea6\u6570\u5b66\u6311\u6218\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u5728\u5177\u4f53\u5e94\u7528\u4e2d\u8fdb\u884c\u4f18\u5316\u8c03\u4f18\u7684\u91cd\u8981\u6027\u3002", "conclusion": "LLM\u5728IMO\u7ade\u8d5b\u4e2d\u7684\u8868\u73b0\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u4f46\u901a\u8fc7\u7cbe\u5fc3\u7684\u6a21\u578b\u8bbe\u8ba1\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5176\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2507.14805", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14805", "abs": "https://arxiv.org/abs/2507.14805", "authors": ["Alex Cloud", "Minh Le", "James Chua", "Jan Betley", "Anna Sztyber-Betley", "Jacob Hilton", "Samuel Marks", "Owain Evans"], "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data", "comment": null, "summary": "We study subliminal learning, a surprising phenomenon where language models\ntransmit behavioral traits via semantically unrelated data. In our main\nexperiments, a \"teacher\" model with some trait T (such as liking owls or being\nmisaligned) generates a dataset consisting solely of number sequences.\nRemarkably, a \"student\" model trained on this dataset learns T. This occurs\neven when the data is filtered to remove references to T. We observe the same\neffect when training on code or reasoning traces generated by the same teacher\nmodel. However, we do not observe the effect when the teacher and student have\ndifferent base models. To help explain our findings, we prove a theoretical\nresult showing that subliminal learning occurs in all neural networks under\ncertain conditions, and demonstrate subliminal learning in a simple MLP\nclassifier. We conclude that subliminal learning is a general phenomenon that\npresents an unexpected pitfall for AI development. Distillation could propagate\nunintended traits, even when developers try to prevent this via data filtering.", "AI": {"tldr": "Language models can unintentionally transfer behavioral traits (like biases or preferences) to other models through seemingly unrelated data, like number sequences or code. This \"subliminal learning\" can happen even if the data is filtered to remove the trait, posing a risk for AI development as unintended behaviors could spread.", "motivation": "The motivation of this paper is to study subliminal learning, a phenomenon where language models transmit behavioral traits via semantically unrelated data, which is a surprising and unexpected pitfall for AI development.", "method": "The study conducted main experiments where a \"teacher\" model with a specific trait T generated datasets solely of number sequences. A \"student\" model trained on this data learned trait T, even when the data was filtered to remove references to T. The same effect was observed when training on code or reasoning traces from the same teacher model. However, the effect was not observed when the teacher and student models were different. The study also includes a theoretical result showing subliminal learning occurs in all neural networks under certain conditions and demonstrates it in a simple MLP classifier.", "result": "Subliminal learning was observed, where a \"student\" model trained on number sequences generated by a \"teacher\" model learned the teacher's trait T. This occurred even with filtered data and when using code or reasoning traces. The effect was not observed with different base models. The theoretical result and MLP classifier demonstration support that this is a general phenomenon.", "conclusion": "This paper concludes that subliminal learning is a general phenomenon that presents an unexpected pitfall for AI development. Distillation could propagate unintended traits, even when developers try to prevent this via data filtering."}}
{"id": "2507.15339", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15339", "abs": "https://arxiv.org/abs/2507.15339", "authors": ["Leanne Tan", "Gabriel Chua", "Ziyu Ge", "Roy Ka-Wei Lee"], "title": "LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators", "comment": null, "summary": "Modern moderation systems increasingly support multiple languages, but often\nfail to address localisation and low-resource variants - creating safety gaps\nin real-world deployments. Small models offer a potential alternative to large\nLLMs, yet still demand considerable data and compute. We present LionGuard 2, a\nlightweight, multilingual moderation classifier tailored to the Singapore\ncontext, supporting English, Chinese, Malay, and partial Tamil. Built on\npre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2\noutperforms several commercial and open-source systems across 17 benchmarks,\nincluding both Singapore-specific and public English datasets. The system is\nactively deployed within the Singapore Government, demonstrating practical\nefficacy at scale. Our findings show that high-quality local data and robust\nmultilingual embeddings can achieve strong moderation performance, without\nfine-tuning large models. We release our model weights and part of our training\ndata to support future work on LLM safety.", "AI": {"tldr": "LionGuard 2 \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u591a\u8bed\u8a00\u7684\u5185\u5bb9\u5ba1\u6838\u5206\u7c7b\u5668\uff0c\u4e13\u4e3a\u65b0\u52a0\u5761\u8bbe\u8ba1\uff0c\u652f\u6301\u591a\u79cd\u8bed\u8a00\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0c\u5e76\u5df2\u6210\u529f\u90e8\u7f72\u3002", "motivation": "\u73b0\u4ee3\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u9700\u8981\u652f\u6301\u591a\u79cd\u8bed\u8a00\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u672c\u5730\u5316\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u53d8\u4f53\u65f6\u5e38\u6709\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u5b89\u5168\u9690\u60a3\u3002", "method": "LionGuard 2 \u57fa\u4e8e\u9884\u8bad\u7ec3\u7684 OpenAI \u5d4c\u5165\u548c\u591a\u5934\u5e8f\u6570\u5206\u7c7b\u5668\u6784\u5efa\uff0c\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u3001\u591a\u8bed\u8a00\u7684\u5185\u5bb9\u5ba1\u6838\u5206\u7c7b\u5668\u3002", "result": "LionGuard 2 \u5728\u5305\u62ec\u65b0\u52a0\u5761\u672c\u5730\u548c\u516c\u5f00\u7684\u82f1\u8bed\u6570\u636e\u96c6\u5728\u5185\u7684 17 \u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a\u5546\u4e1a\u548c\u5f00\u6e90\u7cfb\u7edf\uff0c\u5e76\u5df2\u5728\u65b0\u52a0\u5761\u653f\u5e9c\u5185\u90e8\u7f72\u5e76\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u73b0\u4ee3\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u9700\u8981\u652f\u6301\u591a\u79cd\u8bed\u8a00\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u672c\u5730\u5316\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u53d8\u4f53\u65f6\u5e38\u6709\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u5b89\u5168\u9690\u60a3\u3002LionGuard 2 \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u3001\u591a\u8bed\u8a00\u7684\u5185\u5bb9\u5ba1\u6838\u5206\u7c7b\u5668\uff0c\u4e13\u4e3a\u65b0\u52a0\u5761\u7684\u5b9e\u9645\u9700\u6c42\u8bbe\u8ba1\uff0c\u652f\u6301\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u9a6c\u6765\u8bed\u548c\u90e8\u5206\u6cf0\u7c73\u5c14\u8bed\u3002\u8be5\u7cfb\u7edf\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684 OpenAI \u5d4c\u5165\u548c\u591a\u5934\u5e8f\u6570\u5206\u7c7b\u5668\u6784\u5efa\uff0c\u5728\u5305\u62ec\u65b0\u52a0\u5761\u672c\u5730\u548c\u516c\u5f00\u7684\u82f1\u8bed\u6570\u636e\u96c6\u5728\u5185\u7684 17 \u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a\u5546\u4e1a\u548c\u5f00\u6e90\u7cfb\u7edf\u3002LionGuard 2 \u5df2\u5728\u65b0\u52a0\u5761\u653f\u5e9c\u5185\u90e8\u7f72\u5e76\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u4e2d\u7684\u6709\u6548\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u9ad8\u8d28\u91cf\u7684\u672c\u5730\u6570\u636e\u548c\u5f3a\u5927\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u53ef\u4ee5\u5728\u4e0d\u5fae\u8c03\u5927\u578b\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5f3a\u5927\u7684\u5ba1\u6838\u6027\u80fd\u3002\u6211\u4eec\u516c\u5f00\u4e86\u6a21\u578b\u6743\u91cd\u548c\u90e8\u5206\u8bad\u7ec3\u6570\u636e\uff0c\u4ee5\u652f\u6301\u672a\u6765\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u65b9\u9762\u7684\u7814\u7a76\u3002"}}
{"id": "2507.15373", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15373", "abs": "https://arxiv.org/abs/2507.15373", "authors": ["Tiantian Xu", "Zhenyao He", "Jindan Xu", "Wei Xu", "Jianfeng Wang", "Derrick Wing Kwan Ng"], "title": "Robust ISAC Transceiver Beamforming Design under Low-Resolution AD/DA Converters", "comment": null, "summary": "In this letter, we investigate the robust beamforming design for an\nintegrated sensing and communication (ISAC) system featuring low-resolution\ndigital-to-analog converters (DACs) and analog-to-digital converters (ADCs).\nTaking into account quantization noise, we aim at maximizing the radar\nsignal-to-quantization-plus-noise ratio (SQNR) while guaranteeing the minimum\nrequired signal-to-quantization-plus-interference-plus-noise ratio (SQINR) for\ncommunication users. To address this nonconvex design problem, we first examine\na scenario involving a point target and uniform-resolution DACs, where the\nglobally optimal solution is obtained by applying the semidefinite relaxation\n(SDR) technique. For more general scenarios, including those with mixed-DACs\nand/or an extended target, we develop a low-complexity\nmajorization-minimization (MM)-based algorithm to tackle the problem\niteratively. Compared to the non-robust algorithm, the proposed algorithm\ndemonstrates improved detection performance under practical quantization.\nSimulation results confirm the robustness and efficacy of our proposed\nalgorithm in low-resolution quantization scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4f4e\u5206\u8fa8\u7387 ISAC \u7cfb\u7edf\u7684\u9c81\u68d2\u6ce2\u675f\u5f62\u6210\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528 SDR \u548c MM \u7b97\u6cd5\u5728\u4fdd\u8bc1\u901a\u4fe1\u8d28\u91cf\u7684\u540c\u65f6\u6700\u5927\u5316\u96f7\u8fbe\u6027\u80fd\u3002", "motivation": "ISAC \u7cfb\u7edf\u4e2d\u7684\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u5668\uff08DAC \u548c ADC\uff09\u4f1a\u5f15\u5165\u91cf\u5316\u566a\u58f0\uff0c\u5f71\u54cd\u7cfb\u7edf\u7684\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u5f62\u6210\u8bbe\u8ba1\uff0c\u6700\u5927\u5316\u96f7\u8fbe\u4fe1\u53f7\u7684\u4fe1\u566a\u6bd4\uff08SQNR\uff09\uff0c\u540c\u65f6\u4fdd\u8bc1\u901a\u4fe1\u7528\u6237\u7684\u6700\u5c0f\u4fe1\u5e72\u566a\u6bd4\uff08SQINR\uff09\uff0c\u4ece\u800c\u5728\u4f4e\u5206\u8fa8\u7387\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684 ISAC \u7cfb\u7edf\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9c81\u68d2\u6ce2\u675f\u5f62\u6210\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u534adefinitie \u89c4\u5212\u677e\u5f1b\uff08SDR\uff09\u6280\u672f\u548c\u4e3b\u8981\u5316-\u6700\u5c0f\u5316\uff08MM\uff09\u7b97\u6cd5\u3002\u9996\u5148\uff0c\u9488\u5bf9\u70b9\u76ee\u6807\u548c\u7edf\u4e00\u5206\u8fa8\u7387 DAC \u7684\u573a\u666f\uff0c\u5229\u7528 SDR \u6280\u672f\u83b7\u5f97\u5168\u5c40\u6700\u4f18\u89e3\u3002\u63a5\u7740\uff0c\u5bf9\u4e8e\u5305\u542b\u6df7\u5408 DAC \u548c/\u6216\u6269\u5c55\u76ee\u6807\u7684\u66f4\u666e\u904d\u573a\u666f\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684 MM \u7b97\u6cd5\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u4e0e\u975e\u9c81\u68d2\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5b9e\u9645\u91cf\u5316\u6761\u4ef6\u4e0b\uff0c\u5728\u68c0\u6d4b\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\u3002\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u5728\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u987a\u5e8f\u51f8\u4f18\u5316\u548c MM \u7684\u7b97\u6cd5\u5728\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u573a\u666f\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\uff0c\u5e76\u4e14\u5728\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14867", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14867", "abs": "https://arxiv.org/abs/2507.14867", "authors": ["Zhaoqiang Xia", "Hexiang Huang", "Haoyu Chen", "Xiaoyi Feng", "Guoying Zhao"], "title": "Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition", "comment": null, "summary": "Micro-gestures are unconsciously performed body gestures that can convey the\nemotion states of humans and start to attract more research attention in the\nfields of human behavior understanding and affective computing as an emerging\ntopic. However, the modeling of human emotion based on micro-gestures has not\nbeen explored sufficiently. In this work, we propose to recognize the emotion\nstates based on the micro-gestures by reconstructing the behavior patterns with\na hypergraph-enhanced Transformer in a hybrid-supervised framework. In the\nframework, hypergraph Transformer based encoder and decoder are separately\ndesigned by stacking the hypergraph-enhanced self-attention and multiscale\ntemporal convolution modules. Especially, to better capture the subtle motion\nof micro-gestures, we construct a decoder with additional upsampling operations\nfor a reconstruction task in a self-supervised learning manner. We further\npropose a hypergraph-enhanced self-attention module where the hyperedges\nbetween skeleton joints are gradually updated to present the relationships of\nbody joints for modeling the subtle local motion. Lastly, for exploiting the\nrelationship between the emotion states and local motion of micro-gestures, an\nemotion recognition head from the output of encoder is designed with a shallow\narchitecture and learned in a supervised way. The end-to-end framework is\njointly trained in a one-stage way by comprehensively utilizing\nself-reconstruction and supervision information. The proposed method is\nevaluated on two publicly available datasets, namely iMiGUE and SMG, and\nachieves the best performance under multiple metrics, which is superior to the\nexisting methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14824", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14824", "abs": "https://arxiv.org/abs/2507.14824", "authors": ["Kunyu Yu", "Rui Yang", "Jingchi Liao", "Siqi Li", "Huitao Li", "Irene Li", "Yifan Peng", "Rishikesan Kamaleswaran", "Nan Liu"], "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records", "comment": null, "summary": "Foundation models have emerged as a powerful approach for processing\nelectronic health records (EHRs), offering flexibility to handle diverse\nmedical data modalities. In this study, we present a comprehensive benchmark\nthat evaluates the performance, fairness, and interpretability of foundation\nmodels, both as unimodal encoders and as multimodal learners, using the\npublicly available MIMIC-IV database. To support consistent and reproducible\nevaluation, we developed a standardized data processing pipeline that\nharmonizes heterogeneous clinical records into an analysis-ready format. We\nsystematically compared eight foundation models, encompassing both unimodal and\nmultimodal models, as well as domain-specific and general-purpose variants. Our\nfindings demonstrate that incorporating multiple data modalities leads to\nconsistent improvements in predictive performance without introducing\nadditional bias. Through this benchmark, we aim to support the development of\neffective and trustworthy multimodal artificial intelligence (AI) systems for\nreal-world clinical applications. Our code is available at\nhttps://github.com/nliulab/MIMIC-Multimodal.", "AI": {"tldr": "\u57fa\u7840\u6a21\u578b\u5728EHR\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u63d0\u5347\u6027\u80fd\u4e14\u4e0d\u589e\u52a0\u504f\u89c1\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u5728\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u4e3a\u5f00\u53d1\u6709\u6548\u4e14\u53ef\u4fe1\u8d56\u7684\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u7528\u4e8e\u6574\u5408\u548c\u5206\u6790MIMIC-IV\u6570\u636e\u5e93\u4e2d\u7684\u591a\u6a21\u6001EHR\u6570\u636e\uff0c\u5e76\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u516b\u79cd\u57fa\u7840\u6a21\u578b\uff08\u5305\u62ec\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u6a21\u578b\uff09\u7684\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u9884\u6d4b\u4efb\u52a1\u4e0a\u76f8\u6bd4\u5355\u6a21\u6001\u6a21\u578b\u6709\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14\u4e0d\u4f1a\u589e\u52a0\u989d\u5916\u7684\u504f\u89c1\u3002\u4ee3\u7801\u5df2\u5728https://github.com/nliulab/MIMIC-Multimodal\u516c\u5f00\u3002", "conclusion": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u5206\u6790\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u516c\u5e73\u6027\uff0c\u5e76\u672a\u5f15\u5165\u989d\u5916\u504f\u5dee\u3002"}}
{"id": "2507.15799", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15799", "abs": "https://arxiv.org/abs/2507.15799", "authors": ["Pei Jiang Low", "Nicholas C. F. Zutt", "Gaurav A. Tathed", "Crystal Senko"], "title": "Quantum logic operations and algorithms in a single 25-level atomic qudit", "comment": "15 pages, 4 figures (Supplement includes 29 pages, 15 figures)", "summary": "Scaling quantum computers remains a substantial scientific and technological\nchallenge. Leveraging the full range of intrinsic degrees of freedom in quantum\nsystems offers a promising route towards enhanced algorithmic performance and\nhardware efficiency. We experimentally study the use of $^{137}$Ba$^+$ ions for\nquantum information processing, achieving high-fidelity state preparation and\nreadout of up to 25 internal levels, thus forming a 25-dimensional qudit. By\nprobing superpositions of up to 24 states, we investigate how errors scale with\nqudit dimension $d$ and identify the primary error sources affecting quantum\ncoherence. Additionally, we demonstrate high-dimensional qudit operations by\nimplementing a 3-qubit Bernstein-Vazirani algorithm and a 4-qubit Toffoli gate\nwith a single ion. Our findings suggest that quantum computing architectures\nbased on large-dimensional qudits hold significant promise.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528$^{137}$Ba$^+$\u79bb\u5b50\u5b9e\u73b0\u4e8625\u7ef4\u91cf\u5b50\u6bd4\u7279\uff0c\u5e76\u6f14\u793a\u4e86\u9ad8\u7ef4\u91cf\u5b50\u6bd4\u7279\u5728\u91cf\u5b50\u7b97\u6cd5\u4e2d\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5927\u7ef4\u5ea6\u91cf\u5b50\u6bd4\u7279\u5728\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5229\u7528\u91cf\u5b50\u7cfb\u7edf\u5185\u7980\u81ea\u7531\u5ea6\uff0c\u4ee5\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\u548c\u786c\u4ef6\u6548\u7387\u3002", "method": "\u5b9e\u9a8c\u7814\u7a76\u4e86\u4f7f\u7528$^{137}$Ba$^+$\u79bb\u5b50\u8fdb\u884c\u91cf\u5b50\u4fe1\u606f\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe25\u4e2a\u5185\u90e8\u80fd\u7ea7\u7684\u72b6\u6001\u5236\u5907\u548c\u8bfb\u51fa\uff0c\u6784\u5efa\u4e8625\u7ef4\u91cf\u5b50\u6bd4\u7279\u3002\u901a\u8fc7\u63a2\u6d4b\u591a\u8fbe24\u4e2a\u80fd\u7ea7\u7684\u53e0\u52a0\u6001\uff0c\u7814\u7a76\u4e86\u8bef\u5dee\u4e0e\u91cf\u5b50\u6bd4\u7279\u7ef4\u5ea6d\u7684\u5173\u7cfb\uff0c\u5e76\u8bc6\u522b\u4e86\u5f71\u54cd\u91cf\u5b50\u76f8\u5e72\u7684\u4e3b\u8981\u8bef\u5dee\u6e90\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5b9e\u73b03\u91cf\u5b50\u6bd4\u7279\u7684Bernstein-Vazirani\u7b97\u6cd5\u548c4\u91cf\u5b50\u6bd4\u7279\u7684Toffoli\u95e8\uff0c\u6f14\u793a\u4e86\u9ad8\u7ef4\u91cf\u5b50\u6bd4\u7279\u64cd\u4f5c\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u8fbe25\u4e2a\u5185\u90e8\u80fd\u7ea7\u7684\u72b6\u6001\u5236\u5907\u548c\u8bfb\u51fa\uff0c\u6784\u5efa\u4e8625\u7ef4\u91cf\u5b50\u6bd4\u7279\u3002\u63a2\u6d4b\u4e86\u591a\u8fbe24\u4e2a\u80fd\u7ea7\u7684\u53e0\u52a0\u6001\uff0c\u7814\u7a76\u4e86\u8bef\u5dee\u968f\u7ef4\u5ea6d\u7684\u589e\u957f\uff0c\u5e76\u8bc6\u522b\u4e86\u4e3b\u8981\u8bef\u5dee\u6e90\u3002\u6210\u529f\u5b9e\u73b0\u4e863\u91cf\u5b50\u6bd4\u7279\u7684Bernstein-Vazirani\u7b97\u6cd5\u548c4\u91cf\u5b50\u6bd4\u7279\u7684Toffoli\u95e8\u3002", "conclusion": "\u57fa\u4e8e$^{137}$Ba$^+$\u79bb\u5b50\u7684\u5927\u7ef4\u5ea6\u91cf\u5b50\u6bd4\u7279\u7684\u91cf\u5b50\u8ba1\u7b97\u67b6\u6784\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15347", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15347", "abs": "https://arxiv.org/abs/2507.15347", "authors": ["Amedeo Buonanno", "Alessandro Rivetti", "Francesco A. N. Palmieri", "Giovanni Di Gennaro", "Gianmarco Romano"], "title": "Probing Information Distribution in Transformer Architectures through Entropy Analysis", "comment": "Presented to the Italian Workshop on Neural Networks (WIRN2025) and\n  it will appear in a Springer Chapter", "summary": "This work explores entropy analysis as a tool for probing information\ndistribution within Transformer-based architectures. By quantifying token-level\nuncertainty and examining entropy patterns across different stages of\nprocessing, we aim to investigate how information is managed and transformed\nwithin these models. As a case study, we apply the methodology to a GPT-based\nlarge language model, illustrating its potential to reveal insights into model\nbehavior and internal representations. This approach may offer insights into\nmodel behavior and contribute to the development of interpretability and\nevaluation frameworks for transformer-based models", "AI": {"tldr": "\u5229\u7528\u71b5\u5206\u6790\u6765\u7406\u89e3 Transformer \u6a21\u578b\uff08\u5982 GPT\uff09\u5982\u4f55\u5904\u7406\u4fe1\u606f\uff0c\u4e3a\u6a21\u578b\u89e3\u91ca\u548c\u8bc4\u4f30\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7d22\u71b5\u5206\u6790\u4f5c\u4e3a\u4e00\u79cd\u63a2\u7a76 Transformer \u6a21\u578b\u4fe1\u606f\u5206\u5e03\u7684\u5de5\u5177\uff0c\u5e76\u63ed\u793a\u6a21\u578b\u884c\u4e3a\u548c\u5185\u90e8\u8868\u793a\u7684\u89c1\u89e3\u3002", "method": "\u901a\u8fc7\u91cf\u5316 token \u7ea7\u4e0d\u786e\u5b9a\u6027\u5e76\u68c0\u67e5\u4e0d\u540c\u5904\u7406\u9636\u6bb5\u7684\u71b5\u6a21\u5f0f\u6765\u5206\u6790\u4fe1\u606f\u5728 Transformer \u6a21\u578b\u4e2d\u7684\u5206\u5e03\u548c\u8f6c\u5316\u3002", "result": "\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e GPT \u6a21\u578b\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5176\u63ed\u793a\u6a21\u578b\u884c\u4e3a\u548c\u5185\u90e8\u8868\u5f81\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3 Transformer \u6a21\u578b\uff08\u5982 GPT\uff09\u7684\u884c\u4e3a\u548c\u5185\u90e8\u8868\u793a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u6709\u671b\u4fc3\u8fdb\u53ef\u89e3\u91ca\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.15475", "categories": ["eess.SP", "math.PR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.15475", "abs": "https://arxiv.org/abs/2507.15475", "authors": ["Karl-Ludwig Besser"], "title": "On the Distribution of a Two-Dimensional Random Walk with Restricted Angles", "comment": "12 pages, 13 figures", "summary": "In this paper, we derive the distribution of a two-dimensional (complex)\nrandom walk in which the angle of each step is restricted to a subset of the\ncircle. This setting appears in various domains, such as in over-the-air\ncomputation in signal processing. In particular, we derive the exact joint and\nmarginal distributions for two steps, numerical solutions for a general number\nof steps, and approximations for a large number of steps. Furthermore, we\nprovide an exact characterization of the support for an arbitrary number of\nsteps. The results in this work provide a reference for future work involving\nsuch problems.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u4e8c\u7ef4\u968f\u673a\u6e38\u8d70\u7684\u5206\u5e03\uff0c\u5176\u4e2d\u6bcf\u4e00\u6b65\u7684\u89d2\u5ea6\u90fd\u9650\u5236\u5728\u5706\u7684\u5b50\u96c6\u4e2d\u3002", "motivation": "\u8be5\u8bbe\u7f6e\u51fa\u73b0\u5728\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u8fc7\u9876\u8ba1\u7b97\u7b49\u5404\u79cd\u9886\u57df\u3002", "method": "\u63a8\u5bfc\u4e86\u4e8c\u7ef4\uff08\u590d\u6570\uff09\u968f\u673a\u6e38\u8d70\u7684\u5206\u5e03\uff0c\u5176\u4e2d\u6bcf\u4e00\u6b65\u7684\u89d2\u5ea6\u90fd\u9650\u5236\u5728\u5706\u7684\u5b50\u96c6\u4e2d\u3002\u63a8\u5bfc\u4e86\u4e24\u4e2a\u6b65\u9aa4\u7684\u7cbe\u786e\u8054\u5408\u5206\u5e03\u548c\u8fb9\u7f18\u5206\u5e03\uff0c\u7ed9\u51fa\u4e86\u901a\u7528\u6b65\u9aa4\u6570\u7684\u6570\u503c\u89e3\uff0c\u5e76\u7ed9\u51fa\u4e86\u5927\u6b65\u6570\u7684\u8fd1\u4f3c\u503c\u3002\u6b64\u5916\uff0c\u8fd8\u4e3a\u4efb\u610f\u6b65\u6570\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u652f\u6301\u7279\u5f81\u3002", "result": "\u63a8\u5bfc\u4e86\u4e8c\u7ef4\uff08\u590d\u6570\uff09\u968f\u673a\u6e38\u8d70\u7684\u5206\u5e03\uff0c\u5176\u4e2d\u6bcf\u4e00\u6b65\u7684\u89d2\u5ea6\u90fd\u9650\u5236\u5728\u5706\u7684\u5b50\u96c6\u4e2d\u3002\u63a8\u5bfc\u4e86\u4e24\u4e2a\u6b65\u9aa4\u7684\u7cbe\u786e\u8054\u5408\u5206\u5e03\u548c\u8fb9\u7f18\u5206\u5e03\uff0c\u7ed9\u51fa\u4e86\u901a\u7528\u6b65\u9aa4\u6570\u7684\u6570\u503c\u89e3\uff0c\u5e76\u7ed9\u51fa\u4e86\u5927\u6b65\u6570\u7684\u8fd1\u4f3c\u503c\u3002\u6b64\u5916\uff0c\u8fd8\u4e3a\u4efb\u610f\u6b65\u6570\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u652f\u6301\u7279\u5f81\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6d89\u53ca\u6b64\u7c7b\u95ee\u9898\u7684\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2507.14879", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14879", "abs": "https://arxiv.org/abs/2507.14879", "authors": ["Rizhao Fan", "Tianfang Ma", "Zhigen Li", "Ning An", "Jian Cheng"], "title": "Region-aware Depth Scale Adaptation with Sparse Measurements", "comment": null, "summary": "In recent years, the emergence of foundation models for depth prediction has\nled to remarkable progress, particularly in zero-shot monocular depth\nestimation. These models generate impressive depth predictions; however, their\noutputs are often in relative scale rather than metric scale. This limitation\nposes challenges for direct deployment in real-world applications. To address\nthis, several scale adaptation methods have been proposed to enable foundation\nmodels to produce metric depth. However, these methods are typically costly, as\nthey require additional training on new domains and datasets. Moreover,\nfine-tuning these models often compromises their original generalization\ncapabilities, limiting their adaptability across diverse scenes. In this paper,\nwe introduce a non-learning-based approach that leverages sparse depth\nmeasurements to adapt the relative-scale predictions of foundation models into\nmetric-scale depth. Our method requires neither retraining nor fine-tuning,\nthereby preserving the strong generalization ability of the original foundation\nmodels while enabling them to produce metric depth. Experimental results\ndemonstrate the effectiveness of our approach, high-lighting its potential to\nbridge the gap between relative and metric depth without incurring additional\ncomputational costs or sacrificing generalization ability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u6216\u5fae\u8c03\u7684\u975e\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u7a00\u758f\u6df1\u5ea6\u6d4b\u91cf\u5c06\u57fa\u7840\u6a21\u578b\u7684\u76f8\u5bf9\u6df1\u5ea6\u9884\u6d4b\u8f6c\u6362\u4e3a\u5ea6\u91cf\u6df1\u5ea6\uff0c\u4fdd\u7559\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u7840\u6a21\u578b\u5728\u96f6\u6837\u672c\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8f93\u51fa\u901a\u5e38\u662f\u76f8\u5bf9\u5c3a\u5ea6\u800c\u975e\u5ea6\u91cf\u5c3a\u5ea6\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u3002\u73b0\u6709\u7684\u5c3a\u5ea6\u9002\u5e94\u65b9\u6cd5\u9700\u8981\u984d\u5916\u7684\u8bad\u7ec3\uff0c\u5e76\u4e14\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u7a00\u758f\u6df1\u5ea6\u6d4b\u91cf\u6765\u5c06\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u7684\u76f8\u5bf9\u6df1\u5ea6\u8f6c\u6362\u4e3a\u5ea6\u91cf\u6df1\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5c06\u76f8\u5bf9\u6df1\u5ea6\u8f6c\u6362\u4e3a\u5ea6\u91cf\u6df1\u5ea6\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e14\u6ca1\u6709\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u548c\u6cdb\u5316\u80fd\u529b\u635f\u5931\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u7a00\u758f\u6df1\u5ea6\u6d4b\u91cf\uff0c\u5b9e\u73b0\u4e86\u5c06\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u7684\u76f8\u5bf9\u6df1\u5ea6\u8f6c\u6362\u4e3a\u5ea6\u91cf\u6df1\u5ea6\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u4ece\u800c\u4fdd\u7559\u4e86\u57fa\u7840\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.14828", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14828", "abs": "https://arxiv.org/abs/2507.14828", "authors": ["Abdul-Kazeem Shamba", "Kerstin Bach", "Gavin Taylor"], "title": "eMargin: Revisiting Contrastive Learning with Margin-Based Separation", "comment": "LDD'25: Learning from Difficult Data Workshop (ECAI 2025)", "summary": "We revisit previous contrastive learning frameworks to investigate the effect\nof introducing an adaptive margin into the contrastive loss function for time\nseries representation learning. Specifically, we explore whether an adaptive\nmargin (eMargin), adjusted based on a predefined similarity threshold, can\nimprove the separation between adjacent but dissimilar time steps and\nsubsequently lead to better performance in downstream tasks. Our study\nevaluates the impact of this modification on clustering performance and\nclassification in three benchmark datasets. Our findings, however, indicate\nthat achieving high scores on unsupervised clustering metrics does not\nnecessarily imply that the learned embeddings are meaningful or effective in\ndownstream tasks. To be specific, eMargin added to InfoNCE consistently\noutperforms state-of-the-art baselines in unsupervised clustering metrics, but\nstruggles to achieve competitive results in downstream classification with\nlinear probing. The source code is publicly available at\nhttps://github.com/sfi-norwai/eMargin.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u81ea\u9002\u5e94\u8fb9\u754c\uff08eMargin\uff09\u53ef\u4ee5\u6539\u5584\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u7684\u805a\u7c7b\u6548\u679c\uff0c\u4f46\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5e76\u4e0d\u7406\u60f3\u3002", "motivation": "\u4e3a\u4e86\u7814\u7a76\u81ea\u9002\u5e94\u8fb9\u754c\uff08eMargin\uff09\u5bf9\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5b83\u662f\u5426\u80fd\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u7684\u8d28\u91cf\uff0c\u4ece\u800c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002", "method": "\u5728\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u4e2d\u5f15\u5165\u81ea\u9002\u5e94\u8fb9\u754c\uff08eMargin\uff09\uff0c\u5e76\u57fa\u4e8e\u9884\u8bbe\u7684\u76f8\u4f3c\u5ea6\u9608\u503c\u8fdb\u884c\u8c03\u6574\uff0c\u4ee5\u6539\u5584\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u5206\u79bb\u5ea6\u3002", "result": "eMargin \u663e\u8457\u63d0\u9ad8\u4e86\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u65e0\u76d1\u7763\u805a\u7c7b\u6307\u6807\u8868\u73b0\uff0c\u4f46\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u7684\u7ebf\u6027\u63a2\u6d4b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "eMargin \u63d0\u9ad8\u4e86\u65e0\u76d1\u7763\u805a\u7c7b\u6307\u6807\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u5728\u4e0b\u6e38\u4efb\u52a1\u7684\u7ebf\u6027\u63a2\u6d4b\u5206\u7c7b\u4e2d\u8868\u73b0\u4e0d\u5177\u7ade\u4e89\u529b\u3002"}}
{"id": "2507.15811", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15811", "abs": "https://arxiv.org/abs/2507.15811", "authors": ["Sayan Mondal", "Ujjwal Sen"], "title": "Mpemba effect in self-contained quantum refrigerators: accelerated cooling", "comment": "10 pages, 4 figures", "summary": "We consider the qubit-qutrit model of self-contained quantum refrigerator and\nobserve the quantum Mpemba effect in its cooling. In this system, the qutrit\nacts as the refrigerator while the qubit is to be cooled. The entire system is\ncoupled to three bosonic heat baths, due to which the dynamics of the system is\ngoverned by a Gorini-Kossakoswski-Sudarshan-Lindblad master equation. We\ninvestigate the Liouvillian that generates the dynamics of the system and find\nthat it has a block diagonal form. The dynamics of each element of the system's\ndensity matrix can be determined by solving the dynamical equation of the\ncorresponding block that contains it. We find that the steady state belongs to\nthe block containing only the diagonal elements in the energy basis. We\nnumerically solve for the steady state and investigate the steady-state cooling\nover a significant region of the parameter space. Moreover, we demonstrate the\nquantum Mpemba effect in the refrigerator: a Mpemba state obtained by applying\na unitary on the equilibrium state of the system reaches the steady state\nfaster than the equilibrium state, despite the Mpemba state being initially\nfarther away from the steady state. The Mpemba state thus leads to an\nacceleration in cooling of the cold qubit. We also find that both local and\nglobal unitaries on the qubit-qutrit system can generate the Mpemba state.\nFinally, we study the effect of the qubit-qutrit couplings and the system-bath\ncouplings on the Mpemba effect.", "AI": {"tldr": "\u91cf\u5b50 Mpmba \u6548\u5e94\u5728\u91cf\u5b50\u51b0\u7bb1\u4e2d\u5f97\u5230\u8bc1\u5b9e\uff0c\u5b83\u80fd\u52a0\u901f\u51b7\u5374\u8fc7\u7a0b\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u9149\u53d8\u6362\u5b9e\u73b0\u3002", "motivation": "\u5728\u91cf\u5b50\u7cfb\u7edf\u4e2d\u89c2\u5bdf\u548c\u7406\u89e3\u91cf\u5b50 Mpmba \u6548\u5e94\uff0c\u4ee5\u52a0\u901f\u51b7\u5374\u8fc7\u7a0b\u3002", "method": "\u5229\u7528\u5305\u542b\u4e09\u4e2a\u73bb\u8272\u70ed\u5e93\u7684\u91cf\u5b50 Mpmba \u6548\u5e94\u7684\u91cf\u5b50\u6bd4\u7279-qutrit \u6a21\u578b\uff0c\u901a\u8fc7\u6c42\u89e3\u5757\u5bf9\u89d2\u7ebf Liouvillian \u6765\u7814\u7a76\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u5e76\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u4ee5\u786e\u5b9a\u7a33\u6001\u3002", "result": "\u5728\u91cf\u5b50\u6bd4\u7279-qutrit \u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\u91cf\u5b50 Mpmba \u6548\u5e94\uff0c\u5176\u4e2d Mpmba \u72b6\u6001\u6bd4\u5e73\u8861\u72b6\u6001\u66f4\u5feb\u5730\u8fbe\u5230\u7a33\u6001\uff0c\u4ece\u800c\u52a0\u901f\u4e86\u51b7\u91cf\u5b50\u6bd4\u7279\u7684\u51b7\u5374\u3002\u8fd8\u53d1\u73b0\u5c40\u90e8\u548c\u5168\u5c40\u9149\u53d8\u6362\u90fd\u53ef\u4ee5\u4ea7\u751f Mpmba \u72b6\u6001\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u91cf\u5b50\u51b0\u7bb1\u7684\u91cf\u5b50 Mpmba \u6548\u5e94\u5728\u51b7\u5374\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5b9e\u73b0\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u5c40\u90e8\u548c\u5168\u5c40\u9149\u53d8\u6362\u6765\u751f\u6210\u3002\u8be5\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u8026\u5408\u5bf9 Mpmba \u6548\u5e94\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.15357", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15357", "abs": "https://arxiv.org/abs/2507.15357", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding", "comment": null, "summary": "This paper presents a comprehensive evaluation of the capabilities of Large\nLanguage Models (LLMs) in metaphor interpretation across multiple datasets,\ntasks, and prompt configurations. Although metaphor processing has gained\nsignificant attention in Natural Language Processing (NLP), previous research\nhas been limited to single-dataset evaluations and specific task settings,\noften using artificially constructed data through lexical replacement. We\naddress these limitations by conducting extensive experiments using diverse\npublicly available datasets with inference and metaphor annotations, focusing\non Natural Language Inference (NLI) and Question Answering (QA) tasks. The\nresults indicate that LLMs' performance is more influenced by features like\nlexical overlap and sentence length than by metaphorical content, demonstrating\nthat any alleged emergent abilities of LLMs to understand metaphorical language\nare the result of a combination of surface-level features, in-context learning,\nand linguistic knowledge. This work provides critical insights into the current\ncapabilities and limitations of LLMs in processing figurative language,\nhighlighting the need for more realistic evaluation frameworks in metaphor\ninterpretation tasks. Data and code are publicly available.", "AI": {"tldr": "\u672c\u7814\u7a76\u5168\u9762\u8bc4\u4f30\u4e86LLM\u5728\u6bd4\u55bb\u89e3\u91ca\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5728\u63a8\u7406\u548c\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cLLM\u7684\u8868\u73b0\u66f4\u591a\u5730\u53d7\u5230\u8bcd\u6c47\u91cd\u53e0\u548c\u53e5\u5b50\u957f\u5ea6\u7b49\u8868\u9762\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u800c\u4e0d\u662f\u6bd4\u55bb\u5185\u5bb9\u7684\u56fa\u6709\u7406\u89e3\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u4ec5\u9650\u4e8e\u5355\u6570\u636e\u96c6\u8bc4\u4f30\u548c\u7279\u5b9a\u4efb\u52a1\u8bbe\u7f6e\uff0c\u5e76\u4e14\u7ecf\u5e38\u4f7f\u7528\u901a\u8fc7\u8bcd\u6c47\u66ff\u6362\u8fdb\u884c\u7684\u4eba\u5de5\u6784\u9020\u7684\u6570\u636e\uff0c\u800c\u5ffd\u7565\u4e86LLM\u5728\u6bd4\u55bb\u89e3\u91ca\u65b9\u9762\u7684\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5728\u63a8\u7406\u548c\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u5e26\u6709\u63a8\u7406\u548c\u6bd4\u55bb\u6ce8\u91ca\u7684\u5404\u79cd\u516c\u5f00\u53ef\u7528\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5bf9LLM\u5728\u591a\u7ec4\u6570\u636e\u96c6\u3001\u4efb\u52a1\u548c\u63d0\u793a\u914d\u7f6e\u4e2d\u7684\u6bd4\u55bb\u89e3\u91ca\u80fd\u529b\u8fdb\u884c\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u3002", "result": "LLM\u7684\u8868\u73b0\u66f4\u591a\u5730\u53d7\u5230\u8bcd\u6c47\u91cd\u53e0\u548c\u53e5\u5b50\u957f\u5ea6\u7b49\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u800c\u4e0d\u662f\u6bd4\u55bb\u5185\u5bb9\u3002", "conclusion": "LLMs\u5728\u5904\u7406\u6bd4\u55bb\u8bed\u8a00\u65b9\u9762\u7684\u80fd\u529b\u53d7\u5230\u8bcd\u6c47\u91cd\u53e0\u548c\u53e5\u5b50\u957f\u5ea6\u7b49\u8868\u9762\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u800c\u4e0d\u662f\u6bd4\u55bb\u5185\u5bb9\u7684\u56fa\u6709\u7406\u89e3\u3002\u6240\u8c13\u7684LLM\u7684\u6d8c\u73b0\u80fd\u529b\u662f\u8868\u9762\u7279\u5f81\u3001\u8bed\u5883\u5b66\u4e60\u548c\u8bed\u8a00\u77e5\u8bc6\u7684\u7ed3\u5408\u3002"}}
{"id": "2507.15515", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15515", "abs": "https://arxiv.org/abs/2507.15515", "authors": ["Xuhui Zhang", "Wenchao Liu", "Jinke Ren", "Chunjie Wang", "Huijun Xing", "Yanyan Shen", "Shuguang Cui"], "title": "Movable-Antenna Empowered AAV-Enabled Data Collection over Low-Altitude Wireless Networks", "comment": "This manuscript has been submitted to IEEE", "summary": "Movable-antennas (MAs) are revolutionizing spatial signal processing by\nproviding flexible beamforming in next-generation wireless systems. This paper\ninvestigates an MA-empowered autonomous aerial vehicle (AAV) system in\nlow-altitude wireless networks (LAWNs) for uplink data collection from ground\nusers. We aim to maximize the sum achievable rate by jointly optimizing the AAV\ntrajectory, receive beamforming, and MA positions. An efficient alternating\noptimization (AO) algorithm that incorporates successive convex approximation,\nweighted minimum mean square error, and particle swarm optimization is\ndeveloped. The analysis of the computational complexity and convergence\nfeatures is provided. Extensive simulations demonstrate superior performance in\nterms of the sum achievable rate and the service reliability comparing to\nseveral benchmark schemes. These results demonstrate the distinctive advantages\nof the proposed scheme: enhanced spectral efficiency via adaptive beam-user\nalignment and improved collection reliability through spatial interference\nmanagement, highlighting the implementation potential of the MA-empowered\nLAWNs.", "AI": {"tldr": "This paper uses movable antennas on an autonomous aerial vehicle for better data collection in wireless networks, improving speed and reliability through optimized AAV movement, antenna positions, and beamforming.", "motivation": "Investigating the use of movable-antennas (MAs) in an autonomous aerial vehicle (AAV) system for uplink data collection in low-altitude wireless networks (LAWNs) to maximize the sum achievable rate.", "method": "An alternating optimization (AO) algorithm is proposed, integrating successive convex approximation, weighted minimum mean square error, and particle swarm optimization, to jointly optimize AAV trajectory, receive beamforming, and MA positions.", "result": "The proposed scheme significantly improves the sum achievable rate and service reliability compared to benchmark schemes, showcasing enhanced spectral efficiency via adaptive beam-user alignment and improved collection reliability through spatial interference management.", "conclusion": "Movable-antennas (MAs) technology shows great potential for enhancing spectral efficiency and collection reliability in low-altitude wireless networks (LAWNs), making it a promising solution for future wireless systems."}}
{"id": "2507.14885", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14885", "abs": "https://arxiv.org/abs/2507.14885", "authors": ["Joaquim Comas", "Federico Sukno"], "title": "BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters", "comment": null, "summary": "Remote photoplethysmography (rPPG) captures cardiac signals from facial\nvideos and is gaining attention for its diverse applications. While deep\nlearning has advanced rPPG estimation, it relies on large, diverse datasets for\neffective generalization. In contrast, handcrafted methods utilize\nphysiological priors for better generalization in unseen scenarios like motion\nwhile maintaining computational efficiency. However, their linear assumptions\nlimit performance in complex conditions, where deep learning provides superior\npulsatile information extraction. This highlights the need for hybrid\napproaches that combine the strengths of both methods. To address this, we\npresent BeatFormer, a lightweight spectral attention model for rPPG estimation,\nwhich integrates zoomed orthonormal complex attention and frequency-domain\nenergy measurement, enabling a highly efficient model. Additionally, we\nintroduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be\ntrained without any PPG or HR labels. We validate BeatFormer on the PURE,\nUBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,\nparticularly in cross-dataset evaluations under motion scenarios.", "AI": {"tldr": "BeatFormer\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9891\u8c31\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u901a\u8fc7\u9891\u8c31\u5bf9\u6bd4\u5b66\u4e60\uff0c\u65e0\u9700\u6807\u7b7e\u5373\u53ef\u9ad8\u6548\u51c6\u786e\u5730\u4f30\u8ba1rPPG\u4fe1\u53f7\uff0c\u5c24\u5176\u64c5\u957f\u5904\u7406\u8fd0\u52a8\u573a\u666f\u3002", "motivation": "\u76ee\u524d\u7684rPPG\u4fe1\u53f7\u4f30\u8ba1\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u8981\u4e48\u5728\u590d\u6742\u573a\u666f\u4e0b\u6027\u80fd\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u4f20\u7edf\u65b9\u6cd5\u4f18\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "method": "BeatFormer\u6a21\u578b\u96c6\u6210\u4e86\u7f29\u653e\u6b63\u4ea4\u590d\u6570\u6ce8\u610f\u529b\u548c\u9891\u57df\u80fd\u91cf\u6d4b\u91cf\uff0c\u5e76\u91c7\u7528\u9891\u8c31\u5bf9\u6bd4\u5b66\u4e60\uff08SCL\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700PPG\u6216HR\u6807\u7b7e\u3002", "result": "BeatFormer\u5728PURE\u3001UBFC-rPPG\u548cMMPD\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8fd0\u52a8\u573a\u666f\u4e0b\u7684\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "BeatFormer\u901a\u8fc7\u7ed3\u5408\u9891\u8c31\u6ce8\u610f\u529b\u6a21\u578b\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5728\u65e0\u9700PPG\u6216HR\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684rPPG\u4fe1\u53f7\u4f30\u8ba1\uff0c\u5c24\u5176\u5728\u8fd0\u52a8\u573a\u666f\u4e0b\u7684\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.14843", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14843", "abs": "https://arxiv.org/abs/2507.14843", "authors": ["Fang Wu", "Weihao Xuan", "Ximing Lu", "Zaid Harchaoui", "Yejin Choi"], "title": "The Invisible Leash: Why RLVR May Not Escape Its Origin", "comment": null, "summary": "Recent advances in large reasoning models highlight Reinforcement Learning\nwith Verifiable Rewards (RLVR) as a promising method for enhancing AI's\ncapabilities, particularly in solving complex logical tasks. However, it\nremains unclear whether RLVR truly expands a model's reasoning boundary or\nmerely amplifies high-reward outputs that the base model already knows for\nimproved precision. This study presents a theoretical and empirical\ninvestigation that provides fresh insights into the potential limits of RLVR.\nFirst, we offer a new theoretical perspective that RLVR is constrained by the\nbase model's support-unable to sample solutions with zero initial\nprobability-and operates as a conservative reweighting mechanism that may\nrestrict the discovery of entirely original solutions. We also identify an\nentropy-reward tradeoff: while RLVR reliably enhances precision, it may\nprogressively narrow exploration and potentially overlook correct yet\nunderrepresented solutions. Extensive empirical experiments validate that while\nRLVR consistently improves pass@1, the shrinkage of empirical support generally\noutweighs the expansion of empirical support under larger sampling budgets,\nfailing to recover correct answers that were previously accessible to the base\nmodel. Interestingly, we also observe that while RLVR sometimes increases\ntoken-level entropy, resulting in greater uncertainty at each generation step,\nanswer-level entropy declines, indicating that these seemingly more uncertain\npaths ultimately converge onto a smaller set of distinct answers. Taken\ntogether, these findings reveal potential limits of RLVR in extending reasoning\nhorizons. Breaking this invisible leash may require future algorithmic\ninnovations such as explicit exploration mechanisms or hybrid strategies that\nseed probability mass into underrepresented solution regions.", "AI": {"tldr": "RLVR \u7684\u6269\u5c55\u80fd\u529b\u53ef\u80fd\u53d7\u5230\u57fa\u7840\u6a21\u578b\u7684\u9650\u5236\uff0c\u5e76\u4e14\u53ef\u80fd\u727a\u7272\u63a2\u7d22\u6027\u4ee5\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76 RLVR \u662f\u5426\u80fd\u771f\u6b63\u6269\u5c55\u6a21\u578b\u7684\u63a8\u7406\u8fb9\u754c\uff0c\u6216\u8005\u4ec5\u4ec5\u662f\u4e3a\u4e86\u63d0\u9ad8\u7cbe\u5ea6\u800c\u653e\u5927\u4e86\u57fa\u7840\u6a21\u578b\u5df2\u77e5\u7684\u3001\u5177\u6709\u9ad8\u56de\u62a5\u7684\u8f93\u51fa\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86 RLVR \u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u4ee5\u63d0\u4f9b\u5173\u4e8e\u5176\u6f5c\u5728\u9650\u5236\u7684\u65b0\u89c1\u89e3\u3002", "result": "RLVR \u59cb\u7ec8\u80fd\u63d0\u9ad8 pass@1\uff0c\u4f46\u7ecf\u9a8c\u6027\u652f\u6301\u7684\u6536\u7f29\u901a\u5e38\u4f1a\u8d85\u8fc7\u5728\u66f4\u5927\u91c7\u6837\u9884\u7b97\u4e0b\u7ecf\u9a8c\u6027\u652f\u6301\u7684\u6269\u5f20\uff0c\u672a\u80fd\u6062\u590d\u57fa\u7840\u6a21\u578b\u5148\u524d\u53ef\u8bbf\u95ee\u7684\u6b63\u786e\u7b54\u6848\u3002RLVR \u6709\u65f6\u4f1a\u589e\u52a0 token \u7ea7\u71b5\uff0c\u5bfc\u81f4\u6bcf\u4e2a\u751f\u6210\u6b65\u9aa4\u7684\u4e0d\u786e\u5b9a\u6027\u589e\u52a0\uff0c\u4f46\u7b54\u6848\u7ea7\u71b5\u4f1a\u4e0b\u964d\uff0c\u8868\u660e\u8fd9\u4e9b\u770b\u4f3c\u66f4\u4e0d\u786e\u5b9a\u7684\u8def\u5f84\u6700\u7ec8\u4f1a\u6536\u655b\u5230\u4e00\u7ec4\u66f4\u5c0f\u7684\u4e0d\u540c\u7b54\u6848\u3002", "conclusion": "RLVR \u7684\u6f5c\u529b\u53ef\u80fd\u53d7\u5230\u57fa\u7840\u6a21\u578b\u7684\u9650\u5236\uff0c\u5b83\u662f\u4e00\u79cd\u4fdd\u5b88\u7684\u91cd\u52a0\u6743\u673a\u5236\uff0c\u53ef\u80fd\u4f1a\u9650\u5236\u53d1\u73b0\u5168\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002RLVR \u53ef\u80fd\u4f1a\u727a\u7272\u63a2\u7d22\u6027\u4ee5\u83b7\u5f97\u66f4\u9ad8\u7684\u7cbe\u786e\u5ea6\uff0c\u5e76\u53ef\u80fd\u5ffd\u7565\u6b63\u786e\u4f46\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15845", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.15845", "abs": "https://arxiv.org/abs/2507.15845", "authors": ["Saeed A. Khan", "Sridhar Prabhu", "Logan G. Wright", "Peter L. McMahon"], "title": "Quantum computational sensing using quantum signal processing, quantum neural networks, and Hamiltonian engineering", "comment": "22+39 pages, 6+16 figures", "summary": "Combining quantum sensing with quantum computing can lead to quantum\ncomputational sensors that are able to more efficiently extract task-specific\ninformation from physical signals than is possible otherwise. Early examples of\nquantum computational sensing (QCS) have largely focused on protocols where\nonly a single sensing operation appears before measurement -- with an exception\nbeing the recent application of Grover's algorithm to signal detection. In this\npaper we present, in theory and numerical simulations, the application of two\nquantum algorithms -- quantum signal processing and quantum neural networks --\nto various binary and multiclass machine-learning classification tasks in\nsensing. Here sensing operations are interleaved with computing operations,\ngiving rise to nonlinear functions of the sensed signals. We have evaluated\ntasks based on static and time-varying signals, including spatiotemporal\nsignals. Our approach to optimizing the circuit parameters in a QCS protocol\ntakes into account quantum sampling noise and allows us to engineer protocols\nthat can yield accurate results with as few as just a single measurement shot.\nIn all cases, we have been able to show a regime of operation where a quantum\ncomputational sensor can achieve higher accuracy than a conventional quantum\nsensor, with a simulated accuracy advantage of $>$20 percentage points for some\ntasks. We also present protocols for performing nonlinear tasks using\nHamiltonian-engineered bosonic systems and quantum signal processing with\nhybrid qubit-bosonic systems. Overall, we have shown that substantial quantum\ncomputational-sensing advantages can be obtained even if the quantum system is\nsmall, including few-qubit systems, systems comprising a single qubit and a\nsingle bosonic mode, and even just a single qubit alone -- raising the\nprospects for experimental proof-of-principle and practical realizations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u4e0e\u4f20\u611f\u7684\u65b0\u65b9\u6cd5\uff08QCS\uff09\uff0c\u4f7f\u7528\u91cf\u5b50\u7b97\u6cd5\u5904\u7406\u4f20\u611f\u4fe1\u53f7\uff0c\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u8d85\u8d8a\u4f20\u7edf\u91cf\u5b50\u4f20\u611f\u8fbe 20% \u4ee5\u4e0a\uff0c\u4e14\u5728\u5c0f\u578b\u91cf\u5b50\u7cfb\u7edf\u4e0a\u5373\u53ef\u5b9e\u73b0\u4f18\u52bf\uff0c\u4e3a QCS \u7684\u5b9e\u9a8c\u548c\u5e94\u7528\u94fa\u5e73\u9053\u8def\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u4e0e\u91cf\u5b50\u4f20\u611f\u7684\u7ed3\u5408\u80fd\u591f\u4ea7\u751f\u91cf\u5b50\u8ba1\u7b97\u4f20\u611f\u5668\uff0c\u8fd9\u79cd\u4f20\u611f\u5668\u80fd\u591f\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u4ece\u7269\u7406\u4fe1\u53f7\u4e2d\u63d0\u53d6\u4efb\u52a1\u7279\u5b9a\u7684\u4fe1\u606f\u3002\u5c3d\u7ba1\u5df2\u6709\u5c06\u683c\u7f57\u5f17\u7b97\u6cd5\u5e94\u7528\u4e8e\u4fe1\u53f7\u68c0\u6d4b\u7684\u65e9\u671f QCS \u5b9e\u4f8b\uff0c\u4f46\u5927\u591a\u6570\u7814\u7a76\u4ec5\u9650\u4e8e\u4f20\u611f\u64cd\u4f5c\u524d\u4ec5\u6709\u4e00\u6b21\u6d4b\u91cf\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728\u4f20\u611f\u8fc7\u7a0b\u4e2d\u4ea4\u7ec7\u91cf\u5b50\u8ba1\u7b97\u64cd\u4f5c\uff08\u5982\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u548c\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff09\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u63d0\u5347\u4fe1\u606f\u63d0\u53d6\u7684\u6548\u7387\u548c\u7cbe\u5ea6\uff0c\u5e76\u8bba\u8bc1\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u672c\u7814\u7a76\u5728\u7406\u8bba\u548c\u6570\u503c\u6a21\u62df\u4e0a\uff0c\u5c06\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u548c\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4e24\u79cd\u91cf\u5b50\u7b97\u6cd5\u5e94\u7528\u4e8e\u591a\u79cd\u4e8c\u5206\u7c7b\u548c\u591a\u5206\u7c7b\u7684\u673a\u5668\u5b66\u4e60\u4f20\u611f\u4efb\u52a1\u3002\u901a\u8fc7\u5728\u4f20\u611f\u64cd\u4f5c\u4e2d\u4ea4\u7ec7\u8ba1\u7b97\u64cd\u4f5c\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4f20\u611f\u4fe1\u53f7\u7684\u975e\u7ebf\u6027\u51fd\u6570\u5904\u7406\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u9759\u6001\u3001\u65f6\u53d8\u4ee5\u53ca\u65f6\u7a7a\u8026\u5408\u4fe1\u53f7\u7684\u4efb\u52a1\u3002\u4e3a\u4f18\u5316 QCS \u534f\u8bae\u7684\u7535\u8def\u53c2\u6570\uff0c\u7814\u7a76\u8003\u8651\u4e86\u91cf\u5b50\u91c7\u6837\u566a\u58f0\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4ec5\u9700\u4e00\u6b21\u6d4b\u91cf\u5373\u53ef\u83b7\u5f97\u7cbe\u786e\u7ed3\u679c\u7684\u534f\u8bae\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4f7f\u7528\u54c8\u5bc6\u987f\u91cf\u5de5\u7a0b\u5316\u7684\u73bb\u8272\u5b50\u7cfb\u7edf\u548c\u6df7\u5408\u91cf\u5b50\u6bd4\u7279-\u73bb\u8272\u5b50\u7cfb\u7edf\u6267\u884c\u975e\u7ebf\u6027\u4efb\u52a1\u7684\u534f\u8bae\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u91cf\u5b50\u8ba1\u7b97\u4f20\u611f\u5668\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u80fd\u591f\u5b9e\u73b0\u6bd4\u4f20\u7edf\u91cf\u5b50\u4f20\u611f\u5668\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u6a21\u62df\u6570\u636e\u663e\u793a\u67d0\u4e9b\u4efb\u52a1\u7684\u51c6\u786e\u7387\u4f18\u52bf\u53ef\u8fbe 20% \u4ee5\u4e0a\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u9759\u6001\u3001\u65f6\u53d8\u53ca\u5404\u7c7b\u65f6\u7a7a\u4fe1\u53f7\u3002\u901a\u8fc7\u4f18\u5316\u7535\u8def\u53c2\u6570\u5e76\u8003\u8651\u91cf\u5b50\u91c7\u6837\u566a\u58f0\uff0c\u7814\u7a76\u8bbe\u8ba1\u7684 QCS \u534f\u8bae\u4ec5\u9700\u5355\u6b21\u6d4b\u91cf\u5373\u53ef\u83b7\u5f97\u9ad8\u7cbe\u5ea6\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u54c8\u5bc6\u987f\u91cf\u5de5\u7a0b\u5316\u7684\u73bb\u8272\u5b50\u7cfb\u7edf\u4ee5\u53ca\u6df7\u5408\u91cf\u5b50\u6bd4\u7279-\u73bb\u8272\u5b50\u7cfb\u7edf\u7684\u975e\u7ebf\u6027\u4efb\u52a1\u534f\u8bae\u3002\u7814\u7a76\u8bc1\u5b9e\uff0c\u5373\u4f7f\u5728\u4ec5\u5305\u542b\u5c11\u91cf\u91cf\u5b50\u6bd4\u7279\u3001\u5355\u4e2a\u91cf\u5b50\u6bd4\u7279\u548c\u5355\u4e2a\u73bb\u8272\u5b50\u6a21\u5f0f\uff0c\u751a\u81f3\u4ec5\u5355\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u91cf\u5b50\u7cfb\u7edf\u4e2d\uff0c\u4e5f\u80fd\u83b7\u5f97\u663e\u8457\u7684\u91cf\u5b50\u8ba1\u7b97\u4f20\u611f\u4f18\u52bf\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u91cf\u5b50\u8ba1\u7b97\u4e0e\u91cf\u5b50\u4f20\u611f\u76f8\u7ed3\u5408\u7684\u91cf\u5b50\u8ba1\u7b97\u4f20\u611f\uff08QCS\uff09\u65b0\u65b9\u6cd5\u3002\u901a\u8fc7\u5728\u4f20\u611f\u64cd\u4f5c\u4e2d\u4ea4\u7ec7\u91cf\u5b50\u7b97\u6cd5\uff08\u5982\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u548c\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6bd4\u4f20\u7edf\u91cf\u5b50\u4f20\u611f\u66f4\u9ad8\u7684\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u63d0\u53d6\u6548\u7387\u3002\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5728\u91cf\u5b50\u7cfb\u7edf\u8f83\u5c0f\uff08\u5982\u4ec5\u5305\u542b\u5c11\u91cf\u91cf\u5b50\u6bd4\u7279\u6216\u5355\u4e2a\u91cf\u5b50\u6bd4\u7279\u4e0e\u73bb\u8272\u5b50\u6a21\u5f0f\uff09\u7684\u60c5\u51b5\u4e0b\uff0cQCS \u4e5f\u80fd\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u8d85\u8fc7 20 \u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u7387\u4f18\u52bf\u3002\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u91cf\u5b50\u91c7\u6837\u566a\u58f0\uff0c\u5e76\u80fd\u5728\u4ec5\u4e00\u6b21\u6d4b\u91cf\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u51c6\u786e\u7ed3\u679c\uff0c\u8fd9\u4e3a QCS \u7684\u5b9e\u9a8c\u9a8c\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15375", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.15375", "abs": "https://arxiv.org/abs/2507.15375", "authors": ["Cheng-Han Chiang", "Xiaofei Wang", "Linjie Li", "Chung-Ching Lin", "Kevin Lin", "Shujie Liu", "Zhendong Wang", "Zhengyuan Yang", "Hung-yi Lee", "Lijuan Wang"], "title": "STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models", "comment": "Work in progress. Project page: https://d223302.github.io/STITCH/", "summary": "Spoken Language Models (SLMs) are designed to take speech inputs and produce\nspoken responses. However, current SLMs lack the ability to perform an\ninternal, unspoken thinking process before responding. In contrast, humans\ntypically engage in complex mental reasoning internally, enabling them to\ncommunicate ideas clearly and concisely. Thus, integrating an unspoken thought\nprocess into SLMs is highly desirable. While naively generating a complete\nchain-of-thought (CoT) reasoning before starting to talk can enable thinking\nfor SLMs, this induces additional latency for the speech response, as the CoT\nreasoning can be arbitrarily long. To solve this issue, we propose Stitch, a\nnovel generation method that alternates between the generation of unspoken\nreasoning chunks and spoken response chunks. Since the audio duration of a\nchunk of spoken response is much longer than the time to generate the tokens in\na chunk of spoken response, we use the remaining free time to generate the\nunspoken reasoning tokens. When a chunk of audio is played to the user, the\nmodel continues to generate the next unspoken reasoning chunk, achieving\nsimultaneous thinking and talking. Remarkably, Stitch matches the latency of\nbaselines that cannot generate unspoken CoT by design while outperforming those\nbaselines by 15% on math reasoning datasets; Stitch also performs equally well\non non-reasoning datasets as those baseline models. Some animations and\ndemonstrations are on the project page: https://d223302.github.io/STITCH.", "AI": {"tldr": "Stitch \u662f\u4e00\u79cd\u65b0\u9896\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u66ff\u751f\u6210\u65e0\u58f0\u63a8\u7406\u5757\u548c\u6709\u58f0\u54cd\u5e94\u5757\uff0c\u5b9e\u73b0\u4e86 SLMs \u7684\u201c\u8fb9\u601d\u8003\u8fb9\u8bf4\u201d\u3002\u5b83\u5728\u6570\u5b66\u63a8\u7406\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u5ef6\u8fdf\u4e0e\u4e0d\u601d\u8003\u7684\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7f3a\u4e4f\u5185\u90e8\u7684\u3001\u65e0\u58f0\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u800c\u4eba\u7c7b\u5728\u4ea4\u6d41\u65f6\u901a\u5e38\u4f1a\u8fdb\u884c\u590d\u6742\u7684\u5185\u90e8\u5fc3\u7406\u63a8\u7406\u3002\u56e0\u6b64\uff0c\u4e3a SLMs \u6574\u5408\u65e0\u58f0\u601d\u8003\u8fc7\u7a0b\u662f\u53ef\u53d6\u7684\uff0c\u4f46\u76f4\u63a5\u751f\u6210\u5b8c\u6574\u7684\u601d\u8003\u94fe\uff08CoT\uff09\u4f1a\u589e\u52a0\u54cd\u5e94\u5ef6\u8fdf\u3002", "method": "Stitch \u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u66ff\u751f\u6210\u65e0\u58f0\u63a8\u7406\u5757\u548c\u6709\u58f0\u54cd\u5e94\u5757\uff0c\u5e76\u5229\u7528\u97f3\u9891\u64ad\u653e\u7684\u5269\u4f59\u65f6\u95f4\u751f\u6210\u65e0\u58f0\u63a8\u7406\u4ee4\u724c\uff0c\u5b9e\u73b0\u540c\u65f6\u601d\u8003\u548c\u8bf4\u8bdd\u3002", "result": "Stitch \u5728\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u6bd4\u4e0d\u751f\u6210 CoT \u7684\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u5347 15%\uff0c\u5728\u975e\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "Stitch \u63d0\u6848\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u66ff\u751f\u6210\u65e0\u58f0\u63a8\u7406\u5757\u548c\u6709\u58f0\u54cd\u5e94\u5757\uff0c\u5b9e\u73b0\u4e86\u540c\u65f6\u601d\u8003\u548c\u8bf4\u8bdd\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u6027\u80fd\u63d0\u5347 15%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u4e0d\u751f\u6210 CoT \u7684\u57fa\u7ebf\u76f8\u540c\u7684\u5ef6\u8fdf\u3002"}}
{"id": "2507.15555", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15555", "abs": "https://arxiv.org/abs/2507.15555", "authors": ["Nianzu Li", "Peiran Wu", "Lipeng Zhu", "Weidong Mei", "Boyu Ning", "Derrick Wing Kwan Ng"], "title": "Sum-Rate Maximization for Movable-Antenna Array Enhanced Downlink NOMA Systems", "comment": null, "summary": "Movable antenna (MA) systems have recently attracted significant attention in\nthe field of wireless communications owing to their exceptional capability to\nproactively reconfigure wireless channels via flexible antenna movements. In\nthis paper, we investigate the resource allocation design for an MA\narray-enhanced downlink non-orthogonal multiple access (NOMA) system, where a\nbase station deploys multiple MAs to serve multiple single-antenna users. Our\ngoal is to maximize the sum rate of all users by jointly optimizing the\ntransmit beamforming, positions of MAs, successive interference cancellation\n(SIC) decoding order, and users' corresponding decoding indicator matrix, while\nadhering to constraints on the maximum transmit power and finite MA moving\nregion. The formulated problem is inherently highly non-convex, rendering it\nchallenging to acquire a globally optimal solution. As a compromise, we propose\na low-complexity two-stage optimization algorithm to obtain an effective\nsuboptimal solution. Specifically, in stage one, the SIC decoding order is\nfirst determined by solving a channel gain maximization problem. Then, in stage\ntwo, with the given SIC decoding order, the beamforming vectors, MA positions,\nand users' decoding indicator matrix are iteratively optimized by capitalizing\non alternating optimization, successive convex approximation (SCA), and genetic\nalgorithm (GA). Simulation results unveil that the sum-rate performance of the\nproposed MA-enabled downlink NOMA system significantly outperforms that of\nconventional fixed-position antenna (FPA) systems. Moreover, the results also\nshow that the antenna position optimization in the proposed algorithm can\nfurther enhance the advantages of NOMA over space division multiple access\n(SDMA).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdMA\u589e\u5f3a\u7684\u4e0b\u884c\u94fe\u8defNOMA\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u3001\u6ce2\u675f\u5f62\u6210\u3001\u89e3\u7801\u987a\u5e8f\u7b49\u6765\u6700\u5927\u5316\u7cfb\u7edf\u548c\u901f\u7387\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u4f18\u5316\u7b97\u6cd5\u83b7\u5f97\u6709\u6548\u89e3\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6ce2\u675f\u5f62\u6210\u3001MA\u4f4d\u7f6e\u3001SIC\u89e3\u7801\u987a\u5e8f\u548c\u7528\u6237\u89e3\u7801\u6307\u793a\u77e9\u9635\u6765\u6700\u5927\u5316MA\u589e\u5f3a\u4e0b\u884c\u94fe\u8defNOMA\u7cfb\u7edf\u7684\u603b\u548c\u901f\u7387\uff0c\u5e76\u6ee1\u8db3\u6700\u5927\u53d1\u5c04\u529f\u7387\u548c\u6709\u9650MA\u79fb\u52a8\u533a\u57df\u7684\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u7b97\u6cd5\uff0c\u5305\u62ec\uff1a1. \u786e\u5b9aSIC\u89e3\u7801\u987a\u5e8f\uff1b2. \u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u3001SCA\u548cGA\u8fed\u4ee3\u4f18\u5316\u6ce2\u675f\u5f62\u6210\u5411\u91cf\u3001MA\u4f4d\u7f6e\u548c\u7528\u6237\u7684\u89e3\u7801\u6307\u793a\u77e9\u9635\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684MA\u529f\u80fd\u4e0b\u884c\u94fe\u8defNOMA\u7cfb\u7edf\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684FPA\u7cfb\u7edf\uff0c\u5e76\u4e14\u5929\u7ebf\u4f4d\u7f6e\u4f18\u5316\u53ef\u4ee5\u8fdb\u4e00\u6b65\u589e\u5f3aNOMA\u76f8\u5bf9\u4e8eSDMA\u7684\u4f18\u52bf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684MA\u529f\u80fd\u4e0b\u884c\u94fe\u8defNOMA\u7cfb\u7edf\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684FPA\u7cfb\u7edf\uff0c\u5e76\u4e14\u5929\u7ebf\u4f4d\u7f6e\u4f18\u5316\u53ef\u4ee5\u8fdb\u4e00\u6b65\u589e\u5f3aNOMA\u76f8\u5bf9\u4e8eSDMA\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.14904", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14904", "abs": "https://arxiv.org/abs/2507.14904", "authors": ["Fan Li", "Zanyi Wang", "Zeyi Huang", "Guang Dai", "Jingdong Wang", "Mengmeng Wang"], "title": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "comment": null, "summary": "3D visual grounding allows an embodied agent to understand visual information\nin real-world 3D environments based on human instructions, which is crucial for\nembodied intelligence. Existing 3D visual grounding methods typically rely on\nseparate encoders for different modalities (e.g., RGB images, text, and 3D\npoint clouds), resulting in large and complex models that are inefficient to\ntrain. While some approaches use pre-trained 2D multi-modal models like CLIP\nfor 3D tasks, they still struggle with aligning point cloud data to 2D\nencoders. As a result, these methods continue to depend on 3D encoders for\nfeature extraction, further increasing model complexity and training\ninefficiency. In this paper, we propose a unified 2D pre-trained multi-modal\nnetwork to process all three modalities (RGB images, text, and point clouds),\nsignificantly simplifying the architecture. By leveraging a 2D CLIP bi-modal\nmodel with adapter-based fine-tuning, this framework effectively adapts to the\ntri-modal setting, improving both adaptability and performance across\nmodalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module\nis designed to fuse geometric multi-scale features from point clouds and\nimages. We then integrate textual features for final modality fusion and\nintroduce a multi-modal decoder to facilitate deep cross-modal understanding.\nTogether, our method achieves unified feature extraction and fusion across the\nthree modalities, enabling an end-to-end 3D visual grounding model. Compared to\nthe baseline, our method reduces the number of trainable parameters by\napproximately 58\\%, while achieving a 6.52\\% improvement in the 3D detection\ntask and a 6.25\\% improvement in the 3D visual grounding task.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u76842D\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u7f51\u7edc\uff0c\u7b80\u5316\u4e863D\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7684\u67b6\u6784\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u6027\u80fd\u3002\u901a\u8fc7GARF\u6a21\u5757\u878d\u5408\u51e0\u4f55\u7279\u5f81\uff0c\u5e76\u6574\u5408\u6587\u672c\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u8de8\u6a21\u6001\u7406\u89e3\u3002", "motivation": "\u73b0\u6709\u76843D\u89c6\u89c9\u57fa\u7840\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0d\u540c\u6a21\u6001\uff08\u5982RGB\u56fe\u50cf\u3001\u6587\u672c\u548c3D\u70b9\u4e91\uff09\u7684\u72ec\u7acb\u7f16\u7801\u5668\uff0c\u5bfc\u81f4\u6a21\u578b\u5e9e\u5927\u3001\u590d\u6742\u4e14\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u65e8\u5728\u7b80\u5316\u6a21\u578b\u67b6\u6784\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u76842D\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u7f51\u7edc\u6765\u5904\u7406RGB\u56fe\u50cf\u3001\u6587\u672c\u548c\u70b9\u4e91\u4e09\u79cd\u6a21\u6001\uff0c\u7b80\u5316\u4e86\u6a21\u578b\u67b6\u6784\u3002\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e\u9002\u914d\u5668\u76842D CLIP\u53cc\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u9002\u5e94\u4e09\u6a21\u6001\u8bbe\u7f6e\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4f55\u611f\u77e52D-3D\u7279\u5f81\u6062\u590d\u548c\u878d\u5408\uff08GARF\uff09\u6a21\u5757\u6765\u878d\u5408\u70b9\u4e91\u548c\u56fe\u50cf\u7684\u51e0\u4f55\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u5e76\u6574\u5408\u6587\u672c\u7279\u5f81\u8fdb\u884c\u6700\u7ec8\u7684\u6a21\u6001\u878d\u5408\u3002\u6700\u540e\uff0c\u91c7\u7528\u591a\u6a21\u6001\u89e3\u7801\u5668\u4fc3\u8fdb\u6df1\u5c42\u8de8\u6a21\u6001\u7406\u89e3\u3002", "result": "\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5c06\u53ef\u8bad\u7ec3\u53c2\u6570\u91cf\u51cf\u5c11\u4e86\u7ea658%\uff0c\u57283D\u68c0\u6d4b\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e866.52%\uff0c\u57283D\u89c6\u89c9\u57fa\u7840\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e866.25%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8de8\u4e09\u79cd\u6a21\u6001\u7684\u7edf\u4e00\u7279\u5f81\u63d0\u53d6\u548c\u878d\u5408\uff0c\u80fd\u591f\u6784\u5efa\u7aef\u5230\u7aef\u76843D\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff0c\u57283D\u68c0\u6d4b\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e866.52%\uff0c\u57283D\u89c6\u89c9\u57fa\u7840\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e866.25%\uff0c\u540c\u65f6\u53ef\u8bad\u7ec3\u53c2\u6570\u91cf\u51cf\u5c11\u4e86\u7ea658%\u3002"}}
{"id": "2507.14847", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14847", "abs": "https://arxiv.org/abs/2507.14847", "authors": ["Junhan Yu", "Zhunyi Feng", "Junwei Lu", "Tianxi Cai", "Doudou Zhou"], "title": "Time-Aware Attention for Enhanced Electronic Health Records Modeling", "comment": null, "summary": "Electronic Health Records (EHR) contain valuable clinical information for\npredicting patient outcomes and guiding healthcare decisions. However,\neffectively modeling Electronic Health Records (EHRs) requires addressing data\nheterogeneity and complex temporal patterns. Standard approaches often struggle\nwith irregular time intervals between clinical events. We propose TALE-EHR, a\nTransformer-based framework featuring a novel time-aware attention mechanism\nthat explicitly models continuous temporal gaps to capture fine-grained\nsequence dynamics. To complement this temporal modeling with robust semantics,\nTALE-EHR leverages embeddings derived from standardized code descriptions using\na pre-trained Large Language Model (LLM), providing a strong foundation for\nunderstanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset\ndemonstrate that our approach outperforms state-of-the-art baselines on tasks\nsuch as disease progression forecasting. TALE-EHR underscores the benefit of\nintegrating explicit, continuous temporal modeling with strong semantic\nrepresentations provides a powerful solution for advancing EHR analysis.", "AI": {"tldr": "TALE-EHR \u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u529b\u548c LLM \u5d4c\u5165\u7684 Transformer \u6846\u67b6\uff0c\u7528\u4e8e EHR \u5206\u6790\uff0c\u5728\u75be\u75c5\u8fdb\u5c55\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5bf9\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55 (EHR) \u8fdb\u884c\u6709\u6548\u5efa\u6a21\u9700\u8981\u89e3\u51b3\u6570\u636e\u5f02\u8d28\u6027\u548c\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u7684\u95ee\u9898\uff0c\u800c\u6807\u51c6\u65b9\u6cd5\u5e38\u5e38\u96be\u4ee5\u5904\u7406\u4e34\u5e8a\u4e8b\u4ef6\u4e4b\u95f4\u4e0d\u89c4\u5219\u7684\u65f6\u95f4\u95f4\u9694\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Transformer \u7684\u6846\u67b6 TALE-EHR\uff0c\u8be5\u6846\u67b6\u5177\u6709\u65b0\u9896\u7684\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u663e\u5f0f\u5efa\u6a21\u8fde\u7eed\u65f6\u95f4\u95f4\u9694\u4ee5\u6355\u83b7\u7ec6\u7c92\u5ea6\u5e8f\u5217\u52a8\u6001\u3002TALE-EHR \u5229\u7528\u6e90\u81ea\u6807\u51c6\u5316\u4ee3\u7801\u63cf\u8ff0\u7684\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u589e\u5f3a\u65f6\u95f4\u5efa\u6a21\u7684\u9c81\u68d2\u8bed\u4e49\uff0c\u4ece\u800c\u4e3a\u7406\u89e3\u4e34\u5e8a\u6982\u5ff5\u5960\u5b9a\u575a\u5b9e\u57fa\u7840\u3002", "result": "\u5728 MIMIC-IV \u548c PIC \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u75be\u75c5\u8fdb\u5c55\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u3002", "conclusion": "TALE-EHR \u6846\u67b6\u7ed3\u5408\u4e86\u663e\u5f0f\u3001\u8fde\u7eed\u7684\u65f6\u95f4\u5efa\u6a21\u548c\u5f3a\u5927\u7684\u8bed\u4e49\u8868\u793a\uff0c\u4e3a\u63a8\u8fdb EHR \u5206\u6790\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15378", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15378", "abs": "https://arxiv.org/abs/2507.15378", "authors": ["Jierui Li", "Raymond Mooney"], "title": "AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming", "comment": "19 pages, pre-print only", "summary": "Recent progress in LLMs, such as reasoning models, has demonstrated strong\nabilities to solve complex competitive programming problems, often rivaling top\nhuman competitors. However, it remains underexplored whether these abilities\ngeneralize to relevant domains that are less seen during training. To address\nthis, we introduce AlgoSimBench, a new benchmark designed to assess LLMs'\nability to identify algorithmically similar problems (ASPs)-problems that can\nbe solved using similar algorithmic approaches. AlgoSimBench consists of 1317\nproblems, annotated with 231 distinct fine-grained algorithm tags, from which\nwe curate 402 multiple-choice questions (MCQs), where each question presents\none algorithmically similar problem alongside three textually similar but\nalgorithmically dissimilar distractors. Our evaluation reveals that LLMs\nstruggle to identify ASPs, with the best-performing model (o3-mini) achieving\nonly 65.9% accuracy on the MCQ task. To address this challenge, we propose\nattempted solution matching (ASM), a novel method for improving problem\nsimilarity detection. On our MCQ task, ASM yields an absolute accuracy\nimprovement of 6.7% to 11.7% across different models. We also evaluated code\nembedding models and retrieval methods on similar problem identification. While\nthe adversarial selection of problems degrades the performance to be less than\nrandom, we found that simply summarizing the problem to remove narrative\nelements eliminates the effect, and combining ASM with a keyword-prioritized\nmethod, BM25, can yield up to 52.2% accuracy. Code and data are available at\ngithub.com", "AI": {"tldr": "LLM \u5728\u8bc6\u522b\u7b97\u6cd5\u76f8\u4f3c\u95ee\u9898\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u4f46\u63d0\u51fa\u7684 ASM \u65b9\u6cd5\u548c\u7ed3\u5408 BM25 \u7684\u7b56\u7565\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8bc4\u4f30 LLM \u5728\u8bad\u7ec3\u4e2d\u4e0d\u5e38\u89c1\u4f46\u4e0e\u7b97\u6cd5\u76f8\u5173\u7684\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u8bc6\u522b\u7b97\u6cd5\u76f8\u4f3c\u95ee\u9898\uff08ASPs\uff09\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa AlgoSimBench \u8bc4\u6d4b\u57fa\u51c6\uff0c\u5305\u542b 1317 \u4e2a\u95ee\u9898\u548c 231 \u4e2a\u7b97\u6cd5\u6807\u7b7e\uff0c\u5e76\u8bbe\u8ba1\u4e86 402 \u9053\u9009\u62e9\u9898\uff08MCQ\uff09\u3002\u63d0\u51fa\u5c1d\u8bd5\u6027\u89e3\u51b3\u65b9\u6848\u5339\u914d\uff08ASM\uff09\u65b9\u6cd5\u3002", "result": "\u5728 MCQ \u4efb\u52a1\u4e0a\uff0c\u6700\u4f73 LLM \u6a21\u578b\u7684\u51c6\u786e\u7387\u4ec5\u4e3a 65.9%\u3002ASM \u65b9\u6cd5\u53ef\u4ee5\u5c06\u51c6\u786e\u7387\u63d0\u9ad8 6.7% \u81f3 11.7%\u3002\u79fb\u9664\u53d9\u4e8b\u6027\u5143\u7d20\u53ef\u4ee5\u6d88\u9664\u5bf9\u6297\u6027\u9009\u62e9\u95ee\u9898\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\u3002\u7ed3\u5408 ASM \u548c BM25 \u53ef\u8fbe 52.2% \u7684\u51c6\u786e\u7387\u3002", "conclusion": "LLMs \u5728\u8bc6\u522b\u7b97\u6cd5\u76f8\u4f3c\u95ee\u9898\uff08ASPs\uff09\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u63d0\u51fa\u7684 ASM \u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u901a\u8fc7\u79fb\u9664\u53d9\u4e8b\u6027\u5143\u7d20\u5e76\u7ed3\u5408 BM25\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2507.15621", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15621", "abs": "https://arxiv.org/abs/2507.15621", "authors": ["Imran Ali Khan", "Saif Khan Mohammed", "Ronny Hadani", "Ananthanarayanan Chockalingam", "Robert Calderbank"], "title": "Zak-OTFS based Multiuser Uplink in Doubly-Spread Channels", "comment": null, "summary": "Wireless users with different characteristics will be expected to share\nspectrum in next generation communication networks. One of the great strengths\nof wireless networks based on Orthogonal Frequency Division Multiplexing (OFDM)\nis the ease with which different non-overlapping time-frequency (TF) resources\ncan be allocated to different users by simply shifting each user's signal in\ntime and frequency. However, a significant weaknesses of OFDM is the\ninflexibility of sub-carrier spacing. Since OFDM does not allow users to have\ndifferent sub-carrier spacing, a single user subject to inter-carrier\ninterference causes carrier spacing to increase for all users. Zak-OTFS is an\nalternative delay-Doppler (DD) domain modulation scheme, where, in contrast to\nOFDM, the Input-Output (I/O) relation is predictable. We match the strength of\nOFDM by designing a novel DD domain method of shaping the transmitted Zak-OTFS\npulse on the uplink that enables flexible non-overlapping TF resource\nallocation. The base station (BS) receives a superposition of uplink signals\nand applies individual matched filters to obtain the data specific to\nindividual users. We develop theoretical measures of interference between\nusers, and present numerical simulations for a vehicular channel model\nrepresentative of next generation propagation environments. We demonstrate\nsingle-user performance in a multiuser Zak-OTFS uplink system without needing\nto provision guard bands between TF resources allocated to different users.\nThese performance results demonstrate that the benefits of a predictable\nZak-OTFS waveform can be realized within an architecture for uplink\ncommunication.", "AI": {"tldr": "Zak-OTFS \u901a\u8fc7\u65b0\u7684 DD \u57df\u8109\u51b2\u6574\u5f62\u5b9e\u73b0\u4e86\u7075\u6d3b\u7684 TF \u8d44\u6e90\u5206\u914d\uff0c\u65e0\u9700\u4fdd\u62a4\u5e26\u5373\u53ef\u5728\u591a\u7528\u6237\u4e0a\u4f20\u7cfb\u7edf\u4e2d\u63d0\u4f9b\u826f\u597d\u7684\u5355\u7528\u6237\u6027\u80fd\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u9700\u8981\u652f\u6301\u5177\u6709\u4e0d\u540c\u7279\u6027\u7684\u65e0\u7ebf\u7528\u6237\u5171\u4eab\u9891\u8c31\u3002OFDM \u7684\u4e00\u4e2a\u4e3b\u8981\u4f18\u52bf\u662f\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5730\u5728\u65f6\u57df\u548c\u9891\u57df\u79fb\u52a8\u7528\u6237\u4fe1\u53f7\u6765\u5b9e\u73b0\u4e0d\u540c\u7684\u975e\u91cd\u53e0\u65f6\u9891 (TF) \u8d44\u6e90\u5206\u914d\u3002\u7136\u800c\uff0cOFDM \u7684\u4e00\u4e2a\u663e\u8457\u5f31\u70b9\u662f\u5b50\u8f7d\u6ce2\u95f4\u9694\u7684\u7075\u6d3b\u6027\u5dee\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e00\u4e2a\u7528\u6237\u7684\u8f7d\u6ce2\u95f4\u5e72\u6270\u5f71\u54cd\u6240\u6709\u7528\u6237\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2 (DD) \u57df\u8109\u51b2\u6574\u5f62\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e0a\u4f20\u94fe\u8def\u4e0a\u5bf9\u4f20\u8f93\u7684 Zak-OTFS \u8109\u51b2\u8fdb\u884c\u6574\u5f62\uff0c\u4ee5\u5b9e\u73b0\u7075\u6d3b\u7684\u975e\u91cd\u53e0\u65f6\u9891 (TF) \u8d44\u6e90\u5206\u914d\u3002\u57fa\u7ad9 (BS) \u63a5\u6536\u4e0a\u4f20\u4fe1\u53f7\u7684\u53e0\u52a0\uff0c\u5e76\u5e94\u7528\u5355\u72ec\u7684\u5339\u914d\u6ee4\u6ce2\u5668\u6765\u83b7\u53d6\u7279\u5b9a\u4e8e\u5404\u4e2a\u7528\u6237\u7684\u6570\u636e\u3002\u5f00\u53d1\u4e86\u7528\u6237\u95f4\u5e72\u6270\u7684\u7406\u8bba\u5ea6\u91cf\uff0c\u5e76\u4e3a\u8f66\u8f86\u4fe1\u9053\u6a21\u578b\u8fdb\u884c\u4e86\u6570\u503c\u6a21\u62df\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u591a\u7528\u6237 Zak-OTFS \u4e0a\u4f20\u7cfb\u7edf\u4e2d\uff0c\u65e0\u9700\u5728\u5206\u914d\u7ed9\u4e0d\u540c\u7528\u6237\u7684 TF \u8d44\u6e90\u4e4b\u95f4\u914d\u7f6e\u4fdd\u62a4\u5e26\u5373\u53ef\u5b9e\u73b0\u5355\u7528\u6237\u6027\u80fd\u3002\u8fd9\u4e9b\u6027\u80fd\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0a\u4f20\u901a\u4fe1\u67b6\u6784\u4e2d\u53ef\u4ee5\u5b9e\u73b0\u53ef\u9884\u6d4b\u7684 Zak-OTFS \u6ce2\u5f62\u7684\u4f18\u52bf\u3002", "conclusion": "Zak-OTFS \u662f\u4e00\u79cd\u66ff\u4ee3\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2 (DD) \u57df\u8c03\u5236\u65b9\u6848\uff0c\u4e0e OFDM \u4e0d\u540c\uff0c\u5176\u8f93\u5165-\u8f93\u51fa (I/O) \u5173\u7cfb\u662f\u53ef\u9884\u6d4b\u7684\u3002\u901a\u8fc7\u5728\u4e0a\u4f20\u94fe\u8def\u4e0a\u8bbe\u8ba1\u4e00\u79cd\u65b0\u9896\u7684 DD \u57df\u8109\u51b2\u6574\u5f62\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u7075\u6d3b\u7684\u975e\u91cd\u53e0\u65f6\u9891 (TF) \u8d44\u6e90\u5206\u914d\uff0c\u4ece\u800c\u5339\u914d OFDM \u7684\u4f18\u52bf\u3002\u57fa\u7ad9 (BS) \u63a5\u6536\u4e0a\u4f20\u4fe1\u53f7\u7684\u53e0\u52a0\uff0c\u5e76\u5e94\u7528\u5355\u72ec\u7684\u5339\u914d\u6ee4\u6ce2\u5668\u6765\u83b7\u53d6\u7279\u5b9a\u4e8e\u5404\u4e2a\u7528\u6237\u7684\u6570\u636e\u3002\u6211\u4eec\u5f00\u53d1\u4e86\u7528\u6237\u95f4\u5e72\u6270\u7684\u7406\u8bba\u5ea6\u91cf\uff0c\u5e76\u4e3a\u4ee3\u8868\u4e0b\u4e00\u4ee3\u4f20\u64ad\u73af\u5883\u7684\u8f66\u8f86\u4fe1\u9053\u6a21\u578b\u8fdb\u884c\u4e86\u6570\u503c\u6a21\u62df\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u5728\u591a\u7528\u6237 Zak-OTFS \u4e0a\u4f20\u7cfb\u7edf\u4e2d\uff0c\u65e0\u9700\u5728\u5206\u914d\u7ed9\u4e0d\u540c\u7528\u6237\u7684 TF \u8d44\u6e90\u4e4b\u95f4\u914d\u7f6e\u4fdd\u62a4\u5e26\u5373\u53ef\u5b9e\u73b0\u5355\u7528\u6237\u6027\u80fd\u3002\u8fd9\u4e9b\u6027\u80fd\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0a\u4f20\u901a\u4fe1\u67b6\u6784\u4e2d\u53ef\u4ee5\u5b9e\u73b0\u53ef\u9884\u6d4b\u7684 Zak-OTFS \u6ce2\u5f62\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.14918", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14918", "abs": "https://arxiv.org/abs/2507.14918", "authors": ["Ren-Dong Xie", "Zhi-Fen He", "Bo Li", "Bin Liu", "Jin-Yan Hu"], "title": "Semantic-Aware Representation Learning for Multi-label Image Classification", "comment": null, "summary": "Multi-label image classification, an important research area in computer\nvision, focuses on identifying multiple labels or concepts within an image.\nExisting approaches often employ attention mechanisms or graph convolutional\nnetworks (GCNs) to learn image representation. However, this representation may\ncontain noise and may not locate objects precisely. Therefore, this paper\nproposes a Semantic-Aware Representation Learning (SARL) for multi-label image\nclassification. First, a label semantic-related feature learning module is\nutilized to extract semantic-related features. Then, an optimal transport-based\nattention mechanism is designed to obtain semantically aligned image\nrepresentation. Finally, a regional score aggregation strategy is used for\nmulti-label prediction. Experimental results on two benchmark datasets, PASCAL\nVOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aSARL\uff08\u8bed\u4e49\u611f\u77e5\u8868\u793a\u5b66\u4e60\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\uff0c\u901a\u8fc7\u63d0\u53d6\u8bed\u4e49\u76f8\u5173\u7279\u5f81\u548c\u4f7f\u7528\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u6539\u8fdb\u56fe\u50cf\u8868\u793a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u6216\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u7684\u65b9\u6cd5\u53ef\u80fd\u5305\u542b\u566a\u58f0\u4e14\u5b9a\u4f4d\u4e0d\u7cbe\u786e\uff0c\u56e0\u6b64\u63d0\u51faSARL\u6765\u5b66\u4e60\u8bed\u4e49\u611f\u77e5\u7684\u8868\u793a\u3002", "method": "\u9996\u5148\uff0c\u5229\u7528\u6807\u7b7e\u8bed\u4e49\u76f8\u5173\u7279\u5f81\u5b66\u4e60\u6a21\u5757\u63d0\u53d6\u8bed\u4e49\u76f8\u5173\u7279\u5f81\uff1b\u7136\u540e\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u83b7\u5f97\u8bed\u4e49\u5bf9\u9f50\u7684\u56fe\u50cf\u8868\u793a\uff1b\u6700\u540e\uff0c\u4f7f\u7528\u533a\u57df\u5f97\u5206\u805a\u5408\u7b56\u7565\u8fdb\u884c\u591a\u6807\u7b7e\u9884\u6d4b\u3002", "result": "SARL\u5728PASCAL VOC 2007\u548cMS-COCO\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "SARL\u5728PASCAL VOC 2007\u548cMS-COCO\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2507.14919", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.14919", "abs": "https://arxiv.org/abs/2507.14919", "authors": ["Maximilian Wendlinger", "Kilian Tscharke", "Pascal Debus"], "title": "Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning", "comment": null, "summary": "One of the key obstacles in traditional deep learning is the reduction in\nmodel transparency caused by increasingly intricate model functions, which can\nlead to problems such as overfitting and excessive confidence in predictions.\nWith the advent of quantum machine learning offering possible advances in\ncomputational power and latent space complexity, we notice the same opaque\nbehavior. Despite significant research in classical contexts, there has been\nlittle advancement in addressing the black-box nature of quantum machine\nlearning. Consequently, we approach this gap by building upon existing work in\nclassical uncertainty quantification and initial explorations in quantum\nBayesian modeling to theoretically develop and empirically evaluate techniques\nto map classical uncertainty quantification methods to the quantum machine\nlearning domain. Our findings emphasize the necessity of leveraging classical\ninsights into uncertainty quantification to include uncertainty awareness in\nthe process of designing new quantum machine learning models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u4e0d\u900f\u660e\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5e94\u7528\u4e8e\u91cf\u5b50\u9886\u57df\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u8bbe\u8ba1\u65b0\u6a21\u578b\u65f6\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u548c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u6a21\u578b\u4e0d\u900f\u660e\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u7531\u6b64\u4ea7\u751f\u7684\u8fc7\u62df\u5408\u548c\u8fc7\u5ea6\u81ea\u4fe1\u7b49\u95ee\u9898\u3002", "method": "\u5c06\u7ecf\u5178\u7684_\u4e0d\u786e\u5b9a\u6027_\u91cf\u5316\u65b9\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9886\u57df\uff0c\u5e76\u8fdb\u884c\u7406\u8bba\u53d1\u5c55\u548c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5229\u7528\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u89c1\u89e3\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7eb3\u5165\u65b0\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u6709\u5fc5\u8981\u5229\u7528\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u89c1\u89e3\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7eb3\u5165\u65b0\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u3002"}}
{"id": "2507.15501", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15501", "abs": "https://arxiv.org/abs/2507.15501", "authors": ["Alexandru Coca", "Mark Gaynor", "Zhenxing Zhang", "Jianpeng Cheng", "Bo-Hsiang Tseng", "Pete Boothroyd", "H\u00e9ctor Martinez Alonso", "Diarmuid \u00d3 S\u00e9aghdha", "Anders Johannsen"], "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution", "comment": "37 pages, 22 figures. To appear at ACL 2025", "summary": "This work evaluates the potential of large language models (LLMs) to power\ndigital assistants capable of complex action execution. These assistants rely\non pre-trained programming knowledge to execute multi-step goals by composing\nobjects and functions defined in assistant libraries into action execution\nprograms. To achieve this, we develop ASPERA, a framework comprising an\nassistant library simulation and a human-assisted LLM data generation engine.\nOur engine allows developers to guide LLM generation of high-quality tasks\nconsisting of complex user queries, simulation state and corresponding\nvalidation programs, tackling data availability and evaluation robustness\nchallenges. Alongside the framework we release Asper-Bench, an evaluation\ndataset of 250 challenging tasks generated using ASPERA, which we use to show\nthat program generation grounded in custom assistant libraries is a significant\nchallenge to LLMs compared to dependency-free code generation.", "AI": {"tldr": "LLM\u5728\u4e3a\u9700\u8981\u4e0e\u81ea\u5b9a\u4e49\u5e93\u4ea4\u4e92\u7684\u6570\u5b57\u52a9\u624b\u751f\u6210\u590d\u6742\u64cd\u4f5c\u7a0b\u5e8f\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002ASPERA\u6846\u67b6\u548cAsper-Bench\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u548c\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u652f\u6301\u80fd\u591f\u6267\u884c\u590d\u6742\u64cd\u4f5c\u7684\u6570\u5b57\u52a9\u624b\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "ASPERA\u6846\u67b6\uff0c\u5305\u62ec\u52a9\u624b\u5e93\u6a21\u62df\u548c\u4eba\u7c7b\u8f85\u52a9\u7684LLM\u6570\u636e\u751f\u6210\u5f15\u64ce\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u4efb\u52a1\uff0c\u5305\u62ec\u590d\u6742\u7684\u7528\u6237\u67e5\u8be2\u3001\u6a21\u62df\u72b6\u6001\u548c\u76f8\u5e94\u7684\u9a8c\u8bc1\u7a0b\u5e8f\u3002", "result": "\u53d1\u5e03Asper-Bench\u8bc4\u4f30\u6570\u636e\u96c6\uff08\u5305\u542b250\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff09\uff0c\u5e76\u8868\u660e\u4e0e\u65e0\u4f9d\u8d56\u9879\u7684\u4ee3\u7801\u751f\u6210\u76f8\u6bd4\uff0cLLM\u5728\u751f\u6210\u4e0e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u76f8\u7ed3\u5408\u7684\u7a0b\u5e8f\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\u3002", "conclusion": "LLM\u5728\u751f\u6210\u9700\u8981\u4e0e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u4ea4\u4e92\u4ee5\u6267\u884c\u590d\u6742\u64cd\u4f5c\u7684\u7a0b\u5e8f\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002"}}
{"id": "2507.15800", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15800", "abs": "https://arxiv.org/abs/2507.15800", "authors": ["Yinchao Yang", "Jingxuan Zhou", "Zhaohui Yang", "Mohammad Shikh-Bahaei"], "title": "Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications", "comment": "Accepted by IEEE Transactions on Cognitive Communications and\n  Networking", "summary": "The integration of sensing and communication (ISAC) is a key enabler for\nnext-generation technologies. With high-frequency bands and large-scale antenna\narrays, the Rayleigh distance extends, necessitating near-field (NF) models\nwhere waves are spherical. Although NF-ISAC improves both sensing and\ncommunication, it also poses challenges such as high data volume and potential\nprivacy risks. To address these, we propose a novel framework: near-field\nintegrated sensing, computing, and semantic communication (NF-ISCSC), which\nleverages semantic communication to transmit contextual information only,\nthereby reducing data overhead and improving efficiency. However, semantic\ncommunication is sensitive to channel variations, requiring adaptive\nmechanisms. To this end, fluid antennas (FAs) are introduced to support the\nNF-ISCSC system, enabling dynamic adaptability to changing channels. The\nproposed FA-enabled NF-ISCSC framework considers multiple communication users\nand extended targets comprising several scatterers. A joint optimization\nproblem is formulated to maximize data rate while accounting for sensing\nquality, computational load, and power budget. Using an alternating\noptimization (AO) approach, the original problem is divided into three\nsub-problems: ISAC beamforming, FA positioning, and semantic extraction ratio.\nBeamforming is optimized using the successive convex approximation method. FA\npositioning is solved via a projected Broyden-Fletcher-Goldfarb-Shanno (BFGS)\nalgorithm, and the semantic extraction ratio is optimized using bisection\nsearch. Simulation results demonstrate that the proposed framework achieves\nhigher data rates and better privacy preservation.", "AI": {"tldr": "NF-ISCSC\u6846\u67b6\u7ed3\u5408\u4e86\u8fd1\u573a\u901a\u4fe1\u3001\u4f20\u611f\u3001\u8ba1\u7b97\u548c\u8bed\u4e49\u901a\u4fe1\uff0c\u5e76\u4f7f\u7528\u6d41\u4f53\u5929\u7ebf\u8fdb\u884c\u4fe1\u9053\u81ea\u9002\u5e94\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u89e3\u51b3\u4e86\u6ce2\u675f\u5f62\u6210\u3001\u5929\u7ebf\u5b9a\u4f4d\u548c\u8bed\u4e49\u63d0\u53d6\u7387\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9ad8\u9891\u6bb5\u548c\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u5e26\u6765\u7684\u6570\u636e\u91cf\u5927\u548c\u6f5c\u5728\u9690\u79c1\u98ce\u9669\u7b49\u6311\u6218\uff0c\u5e76\u63d0\u9ad8NF-ISAC\u7cfb\u7edf\u7684\u6548\u7387\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff1a\u8fd1\u573a\u96c6\u6210\u4f20\u611f\u3001\u8ba1\u7b97\u548c\u8bed\u4e49\u901a\u4fe1\uff08NF-ISCSC\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u6d41\u4f53\u5929\u7ebf\uff08FAs\uff09\u6765\u652f\u6301\u8be5\u7cfb\u7edf\u3002\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u65b9\u6cd5\uff0c\u5c06\u539f\u59cb\u95ee\u9898\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u95ee\u9898\uff1aISAC\u6ce2\u675f\u5f62\u6210\uff08\u4f7f\u7528\u8fde\u7eed\u51f8\u8fd1\u4f3c\uff09\u3001FA\u5b9a\u4f4d\uff08\u4f7f\u7528\u6295\u5f71Broyden-Fletcher-Goldfarb-Shinn\u7b97\u6cd5\uff09\u548c\u8bed\u4e49\u63d0\u53d6\u7387\uff08\u4f7f\u7528\u4e8c\u5206\u641c\u7d22\uff09\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6570\u636e\u901f\u7387\u548c\u66f4\u597d\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6570\u636e\u901f\u7387\u548c\u66f4\u597d\u7684\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2507.14921", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14921", "abs": "https://arxiv.org/abs/2507.14921", "authors": ["Xiufeng Huang", "Ka Chun Cheung", "Runmin Cong", "Simon See", "Renjie Wan"], "title": "Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction", "comment": "ACMMM2025. Non-camera-ready version", "summary": "Generalizable 3D Gaussian Splatting reconstruction showcases advanced\nImage-to-3D content creation but requires substantial computational resources\nand large datasets, posing challenges to training models from scratch. Current\nmethods usually entangle the prediction of 3D Gaussian geometry and appearance,\nwhich rely heavily on data-driven priors and result in slow regression speeds.\nTo address this, we propose \\method, a disentangled framework for efficient 3D\nGaussian prediction. Our method extracts features from local image pairs using\na stereo vision backbone and fuses them via global attention blocks. Dedicated\npoint and Gaussian prediction heads generate multi-view point-maps for geometry\nand Gaussian features for appearance, combined as GS-maps to represent the 3DGS\nobject. A refinement network enhances these GS-maps for high-quality\nreconstruction. Unlike existing methods that depend on camera parameters, our\napproach achieves pose-free 3D reconstruction, improving robustness and\npracticality. By reducing resource demands while maintaining high-quality\noutputs, \\method provides an efficient, scalable solution for real-world 3D\ncontent generation.", "AI": {"tldr": "\u4e00\u79cd\u540d\u4e3a\\method\u7684\u65b0\u6846\u67b6\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u8fdb\u884c3D\u9ad8\u65af\u91cd\u5efa\uff0c\u65e0\u9700\u76f8\u673a\u53c2\u6570\uff0c\u5373\u53ef\u4ece\u56fe\u50cf\u751f\u6210\u9ad8\u8d28\u91cf\u76843D\u5185\u5bb9\u3002", "motivation": "\u5f53\u524d3D\u9ad8\u65af\u91cd\u5efa\u65b9\u6cd5\u5728\u8bad\u7ec3\u65f6\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u901a\u5e38\u5c063D\u9ad8\u65af\u51e0\u4f55\u548c\u5916\u89c2\u7684\u9884\u6d4b\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u4f9d\u8d56\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u5bfc\u81f4\u56de\u5f52\u901f\u5ea6\u7f13\u6162\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\method\u7684\u89e3\u8026\u6846\u67b6\uff0c\u901a\u8fc7\u7acb\u4f53\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\u4ece\u5c40\u90e8\u56fe\u50cf\u5bf9\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u6ce8\u610f\u529b\u5757\u8fdb\u884c\u878d\u5408\u3002\u4e13\u95e8\u7684\u70b9\u548c\u9ad8\u65af\u9884\u6d4b\u5934\u751f\u6210\u591a\u89c6\u56fe\u70b9\u56fe\u4ee5\u7528\u4e8e\u51e0\u4f55\uff0c\u4ee5\u53ca\u7528\u4e8e\u5916\u89c2\u7684\u9ad8\u65af\u7279\u5f81\uff0c\u7ec4\u5408\u6210GS\u56fe\u6765\u8868\u793a3DGS\u5bf9\u8c61\u3002\u4e00\u4e2a\u6539\u8fdb\u7f51\u7edc\u589e\u5f3a\u8fd9\u4e9bGS\u56fe\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5efa\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u59ff\u6001\u65e0\u5173\u76843D\u91cd\u5efa\u3002", "result": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u89e3\u80263D\u9ad8\u65af\u8868\u793a\uff0c\u5e76\u5b9e\u73b0\u59ff\u6001\u65e0\u5173\u76843D\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u76843D\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u89e3\u80263D\u9ad8\u65af\u51e0\u4f55\u548c\u5916\u89c2\u9884\u6d4b\uff0c\u5e76\u91c7\u7528\u59ff\u6001\u65e0\u5173\u76843D\u91cd\u5efa\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u76843D\u5185\u5bb9\u751f\u6210\uff0c\u964d\u4f4e\u4e86\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u7684\u8f93\u51fa\u3002"}}
{"id": "2507.14874", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14874", "abs": "https://arxiv.org/abs/2507.14874", "authors": ["Ole-Christoffer Granmo", "Youmna Abdelwahab", "Per-Arne Andersen", "Paul F. A. Clarke", "Kunal Dumbre", "Ylva Gr\u00f8nnins\u00e6ter", "Vojtech Halenka", "Runar Helin", "Lei Jiao", "Ahmed Khalid", "Rebekka Omslandseter", "Rupsa Saha", "Mayur Shende", "Xuan Zhang"], "title": "The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs", "comment": "34 pages, 10 figures", "summary": "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine\n(TM) both interpretable and efficient, while the power of Tsetlin automata\nenables accuracy comparable to deep learning on an increasing number of\ndatasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning\ninterpretable deep clauses from graph-structured input. Moving beyond flat,\nfixed-length input, the GraphTM gets more versatile, supporting sequences,\ngrids, relations, and multimodality. Through message passing, the GraphTM\nbuilds nested deep clauses to recognize sub-graph patterns with exponentially\nfewer clauses, increasing both interpretability and data utilization. For image\nclassification, GraphTM preserves interpretability and achieves 3.86%-points\nhigher accuracy on CIFAR-10 than a convolutional TM. For tracking action\ncoreference, faced with increasingly challenging tasks, GraphTM outperforms\nother reinforcement learning methods by up to 20.6%-points. In recommendation\nsystems, it tolerates increasing noise to a greater extent than a Graph\nConvolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains\naccuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence\ndata, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training\n2.5x faster than GCN. The GraphTM's application to these varied fields\ndemonstrates how graph representation learning and deep clauses bring new\npossibilities for TM learning.", "AI": {"tldr": "GraphTM \u662f\u4e00\u79cd\u65b0\u7684Tsetlin\u673a\uff0c\u53ef\u5904\u7406\u56fe\u6570\u636e\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u8ba9Tsetlin\u673a\u5668\uff08TM\uff09\u80fd\u591f\u5904\u7406\u56fe\u7ed3\u6784\u8f93\u5165\uff0c\u5e76\u8d85\u8d8a\u56fa\u5b9a\u957f\u5ea6\u8f93\u5165\u7684\u9650\u5236\uff0c\u4ece\u800c\u652f\u6301\u5e8f\u5217\u3001\u7f51\u683c\u3001\u5173\u7cfb\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u5e76\u63d0\u9ad8\u5176\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u52a8\u4f5c\u5171\u6307\u8ddf\u8e2a\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u75c5\u6bd2\u57fa\u56e0\u7ec4\u5e8f\u5217\u6570\u636e\u7b49\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0cGraphTM\u80fd\u591f\u4ece\u56fe\u7ed3\u6784\u8f93\u5165\u4e2d\u5b66\u4e60\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b50\u53e5\uff0c\u5e76\u6784\u5efa\u5d4c\u5957\u7684\u6df1\u5ea6\u5b50\u53e5\u4ee5\u8bc6\u522b\u5b50\u56fe\u6a21\u5f0f\uff0c\u4ece\u800c\u4ee5\u6307\u6570\u7ea7\u51cf\u5c11\u7684\u5b50\u53e5\u6570\u91cf\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u5229\u7528\u7387\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cGraphTM\u5728CIFAR-10\u4e0a\u7684\u51c6\u786e\u7387\u6bd4\u5377\u79efTM\u9ad83.86\u4e2a\u767e\u5206\u70b9\uff1b\u5728\u52a8\u4f5c\u5171\u6307\u8ddf\u8e2a\u4efb\u52a1\u4e2d\uff0cGraphTM\u7684\u51c6\u786e\u7387\u6bd4\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9ad820.6\u4e2a\u767e\u5206\u70b9\uff1b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0cGraphTM\u5bf9\u566a\u58f0\u7684\u5bb9\u5fcd\u5ea6\u9ad8\u4e8e\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08GCN\uff09\uff0c\u57280.1\u566a\u58f0\u6bd4\u4e0b\u51c6\u786e\u7387\u8fbe\u523089.86%\uff0c\u800cGCN\u4ec5\u4e3a70.87%\uff1b\u5728\u75c5\u6bd2\u57fa\u56e0\u7ec4\u5e8f\u5217\u6570\u636e\u4e0a\uff0cGraphTM\u7684\u51c6\u786e\u7387\u4e0eBiLSTM-CNN\u548cGCN\u76f8\u5f53\uff0c\u4f46\u8bad\u7ec3\u901f\u5ea6\u662fGCN\u76842.5\u500d\u3002", "conclusion": "Graph Tsetlin Machine (GraphTM) \u5c06\u56fe\u8868\u793a\u5b66\u4e60\u548c\u6df1\u5ea6\u5b50\u53e5\u76f8\u7ed3\u5408\uff0c\u5728\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u5229\u7528\u7387\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u5e76\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u52a8\u4f5c\u5171\u6307\u8ddf\u8e2a\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u75c5\u6bd2\u57fa\u56e0\u7ec4\u5e8f\u5217\u6570\u636e\u7b49\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6210\u679c\uff0c\u663e\u793a\u4e86\u5176\u5728Tsetlin\u673a\uff08TM\uff09\u5b66\u4e60\u4e2d\u7684\u65b0\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.15512", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15512", "abs": "https://arxiv.org/abs/2507.15512", "authors": ["Kaiyan Chang", "Yonghao Shi", "Chenglong Wang", "Hang Zhou", "Chi Hu", "Xiaoqian Liu", "Yingfeng Luo", "Yuan Ge", "Tong Xiao", "Jingbo Zhu"], "title": "Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models", "comment": null, "summary": "Test-Time Scaling (TTS) is a promising approach to progressively elicit the\nmodel's intelligence during inference. Recently, training-based TTS methods,\nsuch as continued reinforcement learning (RL), have further surged in\npopularity, while training-free TTS methods are gradually fading from\nprominence. However, the additional computation overhead of training amplifies\nthe burden on test-time scaling. In this paper, we focus on training-free TTS\nmethods for reasoning. We first design Conditional Step-level Self-refinement,\na fine-grained sequential scaling method guided by process verification. On top\nof its effectiveness, we further combine it with other classical parallel\nscaling methods at the step level, to introduce a novel inference paradigm\ncalled Hybrid Test-Time Scaling. Extensive experiments on five\ninstruction-tuned LLMs across different scales (3B-14B) and families\ndemonstrate that hybrid strategy incorporating various training-free TTS\nmethods at a fine granularity has considerable potential for expanding the\nreasoning performance boundaries of LLMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u6d4b\u8bd5\u65f6\u57df\uff08Hybrid TTS\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u65e0\u8bad\u7ec3\u63a8\u7406\u6280\u672f\uff0c\u5728\u4e0d\u589e\u52a0\u989d\u5916\u8bad\u7ec3\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8bad\u7ec3\u5f0f\u6d4b\u8bd5\u65f6\u57df\uff08training-based TTS\uff09\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u5e76\u91cd\u65b0\u5173\u6ce8\u5e76\u53d1\u5c55\u65e0\u8bad\u7ec3\u6d4b\u8bd5\u65f6\u57df\uff08training-free TTS\uff09\u65b9\u6cd5\u5728\u63a8\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6761\u4ef6\u6b65\u7ea7\u81ea\u7cbe\u70bc\u201d\uff08Conditional Step-level Self-refinement\uff09\u7684\u7ec6\u7c92\u5ea6\u5e8f\u5217\u5316\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u7ecf\u5178\u7684\u5e76\u884c\u5316\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u6df7\u5408\u6d4b\u8bd5\u65f6\u57df\uff08Hybrid Test-Time Scaling\uff09\u63a8\u7406\u8303\u5f0f\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u89c4\u6a21\uff083B-14B\uff09\u548c\u5bb6\u65cf\u7684\u6307\u4ee4\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\uff08instruction-tuned LLMs\uff09\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6df7\u5408\u7b56\u7565\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6df7\u5408\u6d4b\u8bd5\u65f6\u57df\uff08Hybrid Test-Time Scaling\uff09\u901a\u8fc7\u5728\u7ec6\u7c92\u5ea6\u5c42\u9762\u7ed3\u5408\u591a\u79cd\u65e0\u8bad\u7ec3\u6d4b\u8bd5\u65f6\u57df\uff08training-free TTS\uff09\u65b9\u6cd5\uff0c\u5728\u6269\u5c55\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.14924", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14924", "abs": "https://arxiv.org/abs/2507.14924", "authors": ["Kaishva Chintan Shah", "Virajith Boddapati", "Karthik S. Gurumoorthy", "Sandip Kaledhonkar", "Ajit Rajwade"], "title": "3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline", "comment": null, "summary": "Accurate pose estimation and shift correction are key challenges in cryo-EM\ndue to the very low SNR, which directly impacts the fidelity of 3D\nreconstructions. We present an approach for pose estimation in cryo-EM that\nleverages multi-dimensional scaling (MDS) techniques in a robust manner to\nestimate the 3D rotation matrix of each particle from pairs of dihedral angles.\nWe express the rotation matrix in the form of an axis of rotation and a unit\nvector in the plane perpendicular to the axis. The technique leverages the\nconcept of common lines in 3D reconstruction from projections. However, common\nline estimation is ridden with large errors due to the very low SNR of cryo-EM\nprojection images. To address this challenge, we introduce two complementary\ncomponents: (i) a robust joint optimization framework for pose estimation based\non an $\\ell_1$-norm objective or a similar robust norm, which simultaneously\nestimates rotation axes and in-plane vectors while exactly enforcing unit norm\nand orthogonality constraints via projected coordinate descent; and (ii) an\niterative shift correction algorithm that estimates consistent in-plane\ntranslations through a global least-squares formulation. While prior approaches\nhave leveraged such embeddings and common-line geometry for orientation\nrecovery, existing formulations typically rely on $\\ell_2$-based objectives\nthat are sensitive to noise, and enforce geometric constraints only\napproximately. These choices, combined with a sequential pipeline structure,\ncan lead to compounding errors and suboptimal reconstructions in low-SNR\nregimes. Our pipeline consistently outperforms prior methods in both Euler\nangle accuracy and reconstruction fidelity, as measured by the Fourier Shell\nCorrelation (FSC).", "AI": {"tldr": "\u4e00\u79cd\u57fa\u4e8e\u591a\u7ef4\u7f29\u653e\uff08MDS\uff09\u548c\u7a33\u5065\u4f18\u5316\uff08L1 \u8303\u6570\uff09\u7684\u4f4e\u6e29\u7535\u5b50\u663e\u5fae\u955c\uff08cryo-EM\uff09\u59ff\u6001\u4f30\u8ba1\u548c\u79fb\u4f4d\u6821\u6b63\u65b9\u6cd5\uff0c\u53ef\u63d0\u9ad8\u91cd\u5efa\u7cbe\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u4fe1\u566a\u6bd4\uff08SNR\uff09\u60c5\u51b5\u4e0b\u3002", "motivation": "\u4f4e\u6e29\u7535\u5b50\u663e\u5fae\u955c\uff08cryo-EM\uff09\u4e2d\u7684\u7cbe\u786e\u59ff\u6001\u4f30\u8ba1\u548c\u79fb\u4f4d\u6821\u6b63\u662f\u5173\u952e\u6311\u6218\uff0c\u56e0\u4e3a\u6781\u4f4e\u7684\u4fe1\u566a\u6bd4\uff08SNR\uff09\u76f4\u63a5\u5f71\u54cd\u4e09\u7ef4\u91cd\u5efa\u7684\u4fdd\u771f\u5ea6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u591a\u7ef4\u7f29\u653e\uff08MDS\uff09\u6280\u672f\u7a33\u5065\u5730\u4f30\u8ba1\u7c92\u5b50\u4e09\u7ef4\u65cb\u8f6c\u77e9\u9635\u7684\u65b9\u6cd5\uff0c\u5c06\u65cb\u8f6c\u77e9\u9635\u8868\u793a\u4e3a\u65cb\u8f6c\u8f74\u548c\u5782\u76f4\u4e8e\u8be5\u8f74\u7684\u5e73\u9762\u5185\u7684\u5355\u4f4d\u5411\u91cf\u3002\u8be5\u6280\u672f\u5229\u7528\u4e86\u4e09\u7ef4\u91cd\u5efa\u4e2d\u516c\u5171\u7ebf\u7684\u6982\u5ff5\u3002\u4e3a\u89e3\u51b3\u4f4e\u4fe1\u566a\u6bd4\uff08SNR\uff09\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u4e24\u4e2a\u7ec4\u6210\u90e8\u5206\uff1a\uff081\uff09\u57fa\u4e8e L1 \u8303\u6570\u6216\u5176\u4ed6\u7a33\u5065\u8303\u6570\u7684\u7a33\u5065\u8054\u5408\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u540c\u65f6\u4f30\u8ba1\u65cb\u8f6c\u8f74\u548c\u5e73\u9762\u5185\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u6295\u5f71\u5750\u6807\u4e0b\u964d\u6cd5\u7cbe\u786e\u5f3a\u5236\u6267\u884c\u5355\u4f4d\u8303\u6570\u548c\u6b63\u4ea4\u6027\u7ea6\u675f\uff1b\uff082\uff09\u901a\u8fc7\u5168\u5c40\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4f30\u8ba1\u4e00\u81f4\u7684\u5e73\u9762\u5185\u5e73\u79fb\u7684\u8fed\u4ee3\u79fb\u4f4d\u6821\u6b63\u7b97\u6cd5\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728 Euler \u89d2\u7cbe\u5ea6\u548c\u91cd\u5efa\u4fdd\u771f\u5ea6\u65b9\u9762\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728 Euler \u89d2\u7cbe\u5ea6\u548c\u91cd\u5efa\u4fdd\u771f\u5ea6\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5085\u7acb\u53f6\u58f3\u76f8\u5173\u6027\uff08FSC\uff09\u8fdb\u884c\u8861\u91cf\u3002"}}
{"id": "2507.14882", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14882", "abs": "https://arxiv.org/abs/2507.14882", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Amjad Haider", "Daniel G\u00f6rges"], "title": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization", "comment": "6 pages, 22nd International Conference on Advanced Robotics (ICAR\n  2025)", "summary": "Deep neural networks (DNNs) offer significant versatility and performance\nbenefits, but their widespread adoption is often hindered by high model\ncomplexity and computational demands. Model compression techniques such as\npruning have emerged as promising solutions to these challenges. However, it\nremains critical to ensure that application-specific performance\ncharacteristics are preserved during compression. In structured pruning, where\ngroups of structurally coherent elements are removed, conventional importance\nmetrics frequently fail to maintain these essential performance attributes. In\nthis work, we propose an enhanced importance metric framework that not only\nreduces model size but also explicitly accounts for application-specific\nperformance constraints. We employ multiple strategies to determine the optimal\npruning magnitude for each group, ensuring a balance between compression and\ntask performance. Our approach is evaluated on an autoencoder tasked with\nreconstructing MNIST images. Experimental results demonstrate that the proposed\nmethod effectively preserves task-relevant performance, maintaining the model's\nusability even after substantial pruning, by satisfying the required\napplication-specific criteria.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u5316\u4fee\u526a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u79cd\u589e\u5f3a\u578b\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u6846\u67b6\u6765\u89e3\u51b3 DNN \u538b\u7f29\u95ee\u9898\uff0c\u8be5\u6846\u67b6\u53ef\u786e\u4fdd\u6a21\u578b\u6027\u80fd\u5728\u4fee\u526a\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u4fdd\u7559\uff0c\u5e76\u6ee1\u8db3\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u8981\u6c42\u3002", "motivation": "DNNs \u7684\u5e7f\u6cdb\u5e94\u7528\u56e0\u5176\u9ad8\u6a21\u578b\u590d\u6742\u6027\u548c\u8ba1\u7b97\u9700\u6c42\u800c\u53d7\u5230\u963b\u788d\u3002\u6a21\u578b\u538b\u7f29\u6280\u672f\uff08\u5982\u4fee\u526a\uff09\u5df2\u6210\u4e3a\u6709\u5e0c\u671b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u786e\u4fdd\u538b\u7f29\u8fc7\u7a0b\u4e2d\u4fdd\u7559\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u6027\u80fd\u7279\u6027\u81f3\u5173\u91cd\u8981\u3002\u5728\u7ed3\u6784\u5316\u4fee\u526a\u4e2d\uff0c\u5e38\u89c4\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u901a\u5e38\u65e0\u6cd5\u7ef4\u6301\u8fd9\u4e9b\u5173\u952e\u7684\u6027\u80fd\u5c5e\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u51cf\u5c0f\u4e86\u6a21\u578b\u5c3a\u5bf8\uff0c\u8fd8\u660e\u786e\u8003\u8651\u4e86\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u6027\u80fd\u7ea6\u675f\u3002\u6211\u4eec\u91c7\u7528\u591a\u79cd\u7b56\u7565\u6765\u786e\u5b9a\u6bcf\u4e2a\u7ec4\u7684\u6700\u4f73\u4fee\u526a\u5e45\u5ea6\uff0c\u4ee5\u786e\u4fdd\u538b\u7f29\u548c\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7528\u4e8e\u91cd\u5efa MNIST \u56fe\u50cf\u7684\u81ea\u52a8\u7f16\u7801\u5668\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4fdd\u7559\u4efb\u52a1\u76f8\u5173\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4fdd\u7559\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u5927\u91cf\u4fee\u526a\u540e\u4ecd\u80fd\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u7528\u6027\uff0c\u5e76\u6ee1\u8db3\u6240\u9700\u7684\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u6807\u51c6\u3002"}}
{"id": "2507.15557", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15557", "abs": "https://arxiv.org/abs/2507.15557", "authors": ["Vitaly Protasov", "Nikolay Babakov", "Daryna Dementieva", "Alexander Panchenko"], "title": "Evaluating Text Style Transfer: A Nine-Language Benchmark for Text Detoxification", "comment": "preprint", "summary": "Despite recent progress in large language models (LLMs), evaluation of text\ngeneration tasks such as text style transfer (TST) remains a significant\nchallenge. Recent studies (Dementieva et al., 2024; Pauli et al., 2025)\nrevealed a substantial gap between automatic metrics and human judgments.\nMoreover, most prior work focuses exclusively on English, leaving multilingual\nTST evaluation largely unexplored. In this paper, we perform the first\ncomprehensive multilingual study on evaluation of text detoxification system\nacross nine languages: English, Spanish, German, Chinese, Arabic, Hindi,\nUkrainian, Russian, Amharic. Drawing inspiration from the machine translation,\nwe assess the effectiveness of modern neural-based evaluation models alongside\nprompting-based LLM-as-a-judge approaches. Our findings provide a practical\nrecipe for designing more reliable multilingual TST evaluation pipeline in the\ntext detoxification case.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u4e5d\u79cd\u8bed\u8a00\u4e0a\u8bc4\u4f30\u4e86\u6587\u672c\u89e3\u6bd2\u7cfb\u7edf\u7684\u6587\u672c\u98ce\u683c\u8fc1\u79fb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u591a\u8bed\u8a00\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u8bc4\u4f30\u6587\u672c\u98ce\u683c\u8fc1\u79fb\uff08TST\uff09\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u591a\u8bed\u8a00\u65b9\u9762\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\uff0c\u800c\u591a\u8bed\u8a00TST\u8bc4\u4f30\u5219\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u63a2\u7d22\u3002", "method": "1. \u8bc4\u4f30\u4e86\u73b0\u4ee3\u795e\u7ecf\u57fa\u8bc4\u4f30\u6a21\u578b\u548c\u57fa\u4e8e\u63d0\u793a\u7684LLM-as-a-judge\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\n2. \u5728\u4e5d\u79cd\u8bed\u8a00\uff08\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u5fb7\u8bed\u3001\u4e2d\u6587\u3001\u963f\u62c9\u4f2f\u8bed\u3001\u5370\u5730\u8bed\u3001\u4e4c\u514b\u5170\u8bed\u3001\u4fc4\u8bed\u3001\u963f\u59c6\u54c8\u62c9\u8bed\uff09\u4e0a\u8fdb\u884c\u4e86\u591a\u8bed\u8a00\u6587\u672c\u98ce\u683c\u8fc1\u79fb\u8bc4\u4f30\u7814\u7a76\u3002", "result": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf9\u4e5d\u79cd\u8bed\u8a00\u7684\u6587\u672c\u89e3\u6bd2\u7cfb\u7edf\u7684\u8bc4\u4f30\u8fdb\u884c\u4e86\u5168\u9762\u7684\u591a\u8bed\u8a00\u7814\u7a76\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6587\u672c\u89e3\u6bd2\u6848\u4f8b\u4e2d\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u591a\u8bed\u8a00\u6587\u672c\u98ce\u683c\u8fc1\u79fb\u8bc4\u4f30\u6d41\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14932", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14932", "abs": "https://arxiv.org/abs/2507.14932", "authors": ["Francisco M. Castro-Mac\u00edas", "Pablo Morales-\u00c1lvarez", "Yunan Wu", "Rafael Molina", "Aggelos K. Katsaggelos"], "title": "Probabilistic smooth attention for deep multiple instance learning in medical imaging", "comment": null, "summary": "The Multiple Instance Learning (MIL) paradigm is attracting plenty of\nattention in medical imaging classification, where labeled data is scarce. MIL\nmethods cast medical images as bags of instances (e.g. patches in whole slide\nimages, or slices in CT scans), and only bag labels are required for training.\nDeep MIL approaches have obtained promising results by aggregating\ninstance-level representations via an attention mechanism to compute the\nbag-level prediction. These methods typically capture both local interactions\namong adjacent instances and global, long-range dependencies through various\nmechanisms. However, they treat attention values deterministically, potentially\noverlooking uncertainty in the contribution of individual instances. In this\nwork we propose a novel probabilistic framework that estimates a probability\ndistribution over the attention values, and accounts for both global and local\ninteractions. In a comprehensive evaluation involving {\\color{review} eleven}\nstate-of-the-art baselines and three medical datasets, we show that our\napproach achieves top predictive performance in different metrics. Moreover,\nthe probabilistic treatment of the attention provides uncertainty maps that are\ninterpretable in terms of illness localization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6982\u7387\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u793a\u4f8b\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6ce8\u610f\u529b\u503c\u4e0a\u786e\u5b9a\u6027\u5904\u7406\u7684\u95ee\u9898\uff0c\u5e76\u5728\u533b\u7597\u6210\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u7684\u9884\u6d4b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u591a\u793a\u4f8b\u5b66\u4e60\u65b9\u6cd5\u5c06\u6ce8\u610f\u529b\u503c\u89c6\u4e3a\u786e\u5b9a\u6027\u7684\uff0c\u8fd9\u53ef\u80fd\u5ffd\u7565\u4e86\u5355\u4e2a\u5b9e\u4f8b\u7684\u8d21\u732e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6982\u7387\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u4f30\u8ba1\u6ce8\u610f\u529b\u503c\u4e0a\u7684\u6982\u7387\u5206\u5e03\uff0c\u5e76\u540c\u65f6\u8003\u8651\u5168\u5c40\u548c\u5c40\u90e8\u4ea4\u4e92\u3002", "result": "\u5728\u6d89\u53ca\u5341\u4e00\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u548c\u4e09\u4e2a\u533b\u7597\u6570\u636e\u96c6\u7684\u7efc\u5408\u8bc4\u4f30\u4e2d\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6982\u7387\u6846\u67b6\u5728\u4e0d\u540c\u7684\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u9876\u5c16\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u6982\u7387\u6027\u6ce8\u610f\u529b\u5904\u7406\u65b9\u5f0f\u80fd\u591f\u63d0\u4f9b\u5173\u4e8e\u75be\u75c5\u5b9a\u4f4d\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u786e\u5b9a\u6027\u56fe\u3002"}}
{"id": "2507.15576", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15576", "abs": "https://arxiv.org/abs/2507.15576", "authors": ["Nicolas Poggi", "Shashank Agnihotri", "Margret Keuper"], "title": "Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging", "comment": null, "summary": "Terahertz (THz) imaging enables non-invasive analysis for applications such\nas security screening and material classification, but effective image\nclassification remains challenging due to limited annotations, low resolution,\nand visual ambiguity. We introduce In-Context Learning (ICL) with\nVision-Language Models (VLMs) as a flexible, interpretable alternative that\nrequires no fine-tuning. Using a modality-aligned prompting framework, we adapt\ntwo open-weight VLMs to the THz domain and evaluate them under zero-shot and\none-shot settings. Our results show that ICL improves classification and\ninterpretability in low-data regimes. This is the first application of\nICL-enhanced VLMs to THz imaging, offering a promising direction for\nresource-constrained scientific domains. Code:\n\\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub\nrepository}.", "AI": {"tldr": "In-context learning (ICL) with vision-language models (VLMs) offers a no-fine-tuning alternative for Terahertz (THz) image classification, outperforming traditional methods in low-data scenarios and enhancing interpretability.", "motivation": "Effective image classification in Terahertz (THz) imaging is challenging due to limited annotations, low resolution, and visual ambiguity. Existing methods require fine-tuning, which is not always feasible.", "method": "Utilizing a modality-aligned prompting framework to adapt two open-weight Vision-Language Models (VLMs) to the THz domain and evaluating them under zero-shot and one-shot settings.", "result": "ICL improves classification and interpretability in low-data regimes for THz imaging.", "conclusion": "ICL-enhanced VLMs are a promising direction for resource-constrained scientific domains like THz imaging, offering improved classification and interpretability in low-data regimes without fine-tuning."}}
{"id": "2507.15386", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15386", "abs": "https://arxiv.org/abs/2507.15386", "authors": ["Juntao Wang", "Feng Yin", "Tian Ding", "Tsung-Hui Chang", "Zhi-Quan Luo", "Qi Yan"], "title": "Learning to Gridize: Segment Physical World by Wireless Communication Channel", "comment": null, "summary": "Gridization, the process of partitioning space into grids where users share\nsimilar channel characteristics, serves as a fundamental prerequisite for\nefficient large-scale network optimization. However, existing methods like\nGeographical or Beam Space Gridization (GSG or BSG) are limited by reliance on\nunavailable location data or the flawed assumption that similar signal\nstrengths imply similar channel properties. We propose Channel Space\nGridization (CSG), a pioneering framework that unifies channel estimation and\ngridization for the first time. Formulated as a joint optimization problem, CSG\nuses only beam-level reference signal received power (RSRP) to estimate Channel\nAngle Power Spectra (CAPS) and partition samples into grids with homogeneous\nchannel characteristics. To perform CSG, we develop the CSG Autoencoder\n(CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse\ncodebook quantizer, and a physics-informed decoder based on the Localized\nStatistical Channel Model. On recognizing the limitations of naive training\nscheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous\n(PIDA) training scheme for CSG-AE, ensuring stable and effective training by\nsystematically addressing the common pitfalls of the naive training paradigm.\nEvaluations reveal that CSG-AE excels in CAPS estimation accuracy and\nclustering quality on synthetic data. On real-world datasets, it reduces Active\nMean Absolute Error (MAE) by 30\\% and Overall MAE by 65\\% on RSRP prediction\naccuracy compared to salient baselines using the same data, while improving\nchannel consistency, cluster sizes balance, and active ratio, advancing the\ndevelopment of gridization for large-scale network optimization.", "AI": {"tldr": "CSG-AE\u901a\u8fc7\u7ed3\u5408\u4fe1\u9053\u4f30\u8ba1\u548c\u7f51\u683c\u5316\u6765\u6539\u8fdb\u5927\u89c4\u6a21\u7f51\u7edc\u4f18\u5316\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728RSRP\u9884\u6d4b\u51c6\u786e\u6027\u3001\u4fe1\u9053\u4e00\u81f4\u6027\u3001\u96c6\u7fa4\u5927\u5c0f\u5e73\u8861\u548c\u6d3b\u52a8\u6bd4\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u5730\u7406\u7a7a\u95f4\u6216\u6ce2\u675f\u7a7a\u95f4\u7f51\u683c\u5316\u65b9\u6cd5\uff08GSG\u6216BSG\uff09\u4f9d\u8d56\u4e8e\u65e0\u6cd5\u4f7f\u7528\u7684\u4f4d\u7f6e\u6570\u636e\u6216\u57fa\u4e8e\u9519\u8bef\u7684\u5047\u8bbe\uff0c\u5373\u76f8\u4f3c\u7684\u4fe1\u53f7\u5f3a\u5ea6\u610f\u5473\u7740\u76f8\u4f3c\u7684\u4fe1\u9053\u7279\u6027\u3002CSG\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u4fe1\u9053\u4f30\u8ba1\u548c\u7f51\u683c\u5316\u6765\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCSG-AE\u7684\u4fe1\u9053\u7a7a\u95f4\u7f51\u683c\u5316\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u8be5\u7f16\u7801\u5668\u5305\u62ec\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684RSRP\u5230CAPS\u7f16\u7801\u5668\u3001\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u7a00\u758f\u7801\u672c\u91cf\u5316\u5668\u548c\u4e00\u4e2a\u57fa\u4e8e\u5c40\u90e8\u7edf\u8ba1\u4fe1\u9053\u6a21\u578b\u7684\u7269\u7406\u4fe1\u606f\u89e3\u7801\u5668\u3002\u4e3a\u4e86\u786e\u4fdd\u7a33\u5b9a\u6709\u6548\u7684\u8bad\u7ec3\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9884\u8bad\u7ec3-\u521d\u59cb\u5316-\u5206\u79bb-\u5f02\u6b65\uff08PIDA\uff09\u8bad\u7ec3\u65b9\u6848\u3002", "result": "CSG-AE\u5728CAPS\u4f30\u8ba1\u51c6\u786e\u6027\u548c\u5408\u6210\u6570\u636e\u4e0a\u7684\u805a\u7c7b\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "CSG-AE\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u5c06RSRP\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u7684\u6d3b\u52a8\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u964d\u4f4e\u4e8630\uff05\uff0c\u6574\u4f53MAE\u964d\u4f4e\u4e8665\uff05\uff0c\u4e0e\u4f7f\u7528\u76f8\u540c\u6570\u636e\u7684\u663e\u7740\u57fa\u7ebf\u76f8\u6bd4\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u4fe1\u9053\u4e00\u81f4\u6027\u3001\u96c6\u7fa4\u5927\u5c0f\u5e73\u8861\u548c\u6d3b\u52a8\u6bd4\u7387\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u7528\u4e8e\u5927\u89c4\u6a21\u7f51\u7edc\u4f18\u5316\u7684\u7f51\u683c\u5316\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.14935", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14935", "abs": "https://arxiv.org/abs/2507.14935", "authors": ["Hai Huang", "Yan Xia", "Shulei Wang", "Hanting Wang", "Minghui Fang", "Shengpeng Ji", "Sashuai Zhou", "Tao Jin", "Zhou Zhao"], "title": "Open-set Cross Modal Generalization via Multimodal Unified Representation", "comment": "Accepted by ICCV 2025", "summary": "This paper extends Cross Modal Generalization (CMG) to open-set environments\nby proposing the more challenging Open-set Cross Modal Generalization (OSCMG)\ntask. This task evaluates multimodal unified representations in open-set\nconditions, addressing the limitations of prior closed-set cross-modal\nevaluations. OSCMG requires not only cross-modal knowledge transfer but also\nrobust generalization to unseen classes within new modalities, a scenario\nfrequently encountered in real-world applications. Existing multimodal unified\nrepresentation work lacks consideration for open-set environments. To tackle\nthis, we propose MICU, comprising two key components: Fine-Coarse Masked\nmultimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI\nenhances multimodal alignment by applying contrastive learning at both holistic\nsemantic and temporal levels, incorporating masking to enhance generalization.\nCUJP enhances feature diversity and model uncertainty by integrating\nmodality-agnostic feature selection with self-supervised learning, thereby\nstrengthening the model's ability to handle unknown categories in open-set\ntasks. Extensive experiments on CMG and the newly proposed OSCMG validate the\neffectiveness of our approach. The code is available at\nhttps://github.com/haihuangcode/CMG.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u8de8\u6a21\u6001\u6cdb\u5316\u5728\u5f00\u653e\u96c6\u73af\u5883\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51faOSCMG\u4efb\u52a1\u548cMICU\u6a21\u578b\uff08\u542bFCMI\u3001CUJP\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u63d0\u5347\u591a\u6a21\u6001\u7edf\u4e00\u8868\u5f81\u5728\u5f00\u653e\u96c6\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8de8\u6a21\u6001\u6cdb\u5316\uff08CMG\uff09\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u95ed\u96c6\u73af\u5883\uff0c\u7f3a\u4e4f\u5bf9\u5f00\u653e\u96c6\u73af\u5883\u7684\u8003\u8651\u3002\u7136\u800c\uff0c\u5f00\u653e\u96c6\u573a\u666f\uff08\u5982OSCMG\u4efb\u52a1\uff09\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u66f4\u4e3a\u5e38\u89c1\uff0c\u9700\u8981\u6a21\u578b\u4e0d\u4ec5\u80fd\u8fdb\u884c\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\uff0c\u8fd8\u80fd\u6cdb\u5316\u5230\u65b0\u6a21\u6001\u7684\u672a\u89c1\u7c7b\u522b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u5f00\u653e\u96c6\u8de8\u6a21\u6001\u6cdb\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMICU\uff08\u5305\u542bFine-Coarse Masked multimodal InfoNCE (FCMI) \u548c Cross modal Unified Jigsaw Puzzles (CUJP)\uff09\u7684\u6a21\u578b\u3002FCMI\u901a\u8fc7\u5728\u6574\u4f53\u8bed\u4e49\u548c\u65f6\u95f4\u5c42\u9762\u5e94\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u63a9\u7801\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u6cdb\u5316\u80fd\u529b\u3002CUJP\u901a\u8fc7\u6574\u5408\u7279\u5b9a\u4e8e\u6a21\u6001\u7684\u7279\u5f81\u9009\u62e9\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u6765\u589e\u5f3a\u7279\u5f81\u591a\u6837\u6027\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u5904\u7406\u5f00\u653e\u96c6\u4efb\u52a1\u4e2d\u7684\u672a\u77e5\u7c7b\u522b\u3002", "result": "\u6240\u63d0\u51fa\u7684MICU\u6a21\u578b\u5728CMG\u548c\u65b0\u63d0\u51fa\u7684OSCMG\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5176\u80fd\u591f\u589e\u5f3a\u591a\u6a21\u6001\u7edf\u4e00\u8868\u5f81\u5728\u5f00\u653e\u96c6\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86OSCMG\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e86MICU\u6a21\u578b\uff08\u5305\u542bFCMI\u548cCUJP\uff09\uff0c\u5728CMG\u548cOSCMG\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.14980", "categories": ["cs.LG", "68T05, 90C26", "I.2.6; I.5.1; I.2.10"], "pdf": "https://arxiv.org/pdf/2507.14980", "abs": "https://arxiv.org/abs/2507.14980", "authors": ["Tianle Li", "Yongzhi Huang", "Linshan Jiang", "Qipeng Xie", "Chang Liu", "Wenfeng Du", "Lu Wang", "Kaishun Wu"], "title": "FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios", "comment": "ICPP, including appendix", "summary": "Federated Learning (FL) enables decentralized model training while preserving\ndata privacy. Despite its benefits, FL faces challenges with non-identically\ndistributed (non-IID) data, especially in long-tailed scenarios with imbalanced\nclass samples. Momentum-based FL methods, often used to accelerate FL\nconvergence, struggle with these distributions, resulting in biased models and\nmaking FL hard to converge. To understand this challenge, we conduct extensive\ninvestigations into this phenomenon, accompanied by a layer-wise analysis of\nneural network behavior. Based on these insights, we propose FedWCM, a method\nthat dynamically adjusts momentum using global and per-round data to correct\ndirectional biases introduced by long-tailed distributions. Extensive\nexperiments show that FedWCM resolves non-convergence issues and outperforms\nexisting methods, enhancing FL's efficiency and effectiveness in handling\nclient heterogeneity and data imbalance.", "AI": {"tldr": "FedWCM improves Federated Learning on non-IID, long-tailed data by adjusting momentum, fixing convergence issues and outperforming other methods.", "motivation": "Federated Learning (FL) faces challenges with non-identically distributed (non-IID) data, especially in long-tailed scenarios with imbalanced class samples, where momentum-based FL methods struggle with biased models and convergence.", "method": "FedWCM dynamically adjusts momentum using global and per-round data to correct directional biases introduced by long-tailed distributions.", "result": "Extensive experiments show that FedWCM resolves non-convergence issues and outperforms existing methods.", "conclusion": "FedWCM resolves non-convergence issues and outperforms existing methods, enhancing FL's efficiency and effectiveness in handling client heterogeneity and data imbalance."}}
{"id": "2507.15586", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15586", "abs": "https://arxiv.org/abs/2507.15586", "authors": ["Xinping Zhao", "Shouzheng Huang", "Yan Zhong", "Xinshuo Hu", "Baotian Hu", "Min Zhang"], "title": "Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation", "comment": "16 pages, 7 Figures, 10 Tables", "summary": "Retrieval-Augmented Generation (RAG) effectively improves the accuracy of\nLarge Language Models (LLMs). However, retrieval noises significantly impact\nthe quality of LLMs' generation, necessitating the development of denoising\nmechanisms. Previous methods extract evidence straightforwardly without\nexplicit thinking, which risks filtering out key clues and struggles with\ngeneralization. To this end, we propose LEAR, which learns to extract rational\nevidence by (1) explicitly reasoning to identify potential cues within\nretrieval contents first, and then (2) consciously extracting to avoid omitting\nany key cues helpful for answering questions. Specifically, we frame evidence\nreasoning and evidence extraction into one unified response for end-to-end\ntraining; apply knowledge token masks for disentanglement to derive\nreasoning-based and extraction-based answers; and devise three types of\nverifiable reward functions, including answer, length, and format, to update\nthe model via the policy optimization algorithm. Extensive experiments on three\nbenchmark datasets show the effectiveness of LEAR, providing compact and\nhigh-quality evidence, improving the accuracy of downstream tasks, and\npromoting effective application in online RAG systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15690", "categories": ["cs.CV", "eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.15690", "abs": "https://arxiv.org/abs/2507.15690", "authors": ["Hung Nguyen", "Runfa Li", "An Le", "Truong Nguyen"], "title": "DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting", "comment": "6 pages, 4 figures", "summary": "Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in\nreconstructing high-quality novel views, as it often overfits to the\nwidely-varying high-frequency (HF) details of the sparse training views. While\nfrequency regularization can be a promising approach, its typical reliance on\nFourier transforms causes difficult parameter tuning and biases towards\ndetrimental HF learning. We propose DWTGS, a framework that rethinks frequency\nregularization by leveraging wavelet-space losses that provide additional\nspatial supervision. Specifically, we supervise only the low-frequency (LF) LL\nsubbands at multiple DWT levels, while enforcing sparsity on the HF HH subband\nin a self-supervised manner. Experiments across benchmarks show that DWTGS\nconsistently outperforms Fourier-based counterparts, as this LF-centric\nstrategy improves generalization and reduces HF hallucinations.", "AI": {"tldr": "DWTGS\u901a\u8fc7\u5c0f\u6ce2\u57df\u635f\u5931\u548c\u81ea\u76d1\u7763\u7a00\u758f\u6027\uff0c\u89e3\u51b3\u4e86\u7a00\u758f\u89c6\u56fe3D\u9ad8\u65af\u6cfc\u6e85\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u7a00\u758f\u89c6\u56fe3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5728\u91cd\u5efa\u9ad8\u8d28\u91cf\u65b0\u89c6\u56fe\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u8be5\u6311\u6218\u6e90\u4e8e\u5bf9\u7a00\u758f\u8bad\u7ec3\u89c6\u56fe\u4e2d\u7684\u9ad8\u9891\uff08HF\uff09\u7ec6\u8282\u8fc7\u5ea6\u62df\u5408\u3002\u73b0\u6709\u7684\u9891\u7387\u6b63\u5219\u5316\u65b9\u6cd5\u4f9d\u8d56\u5085\u7acb\u53f6\u53d8\u6362\uff0c\u5b58\u5728\u53c2\u6570\u8c03\u6574\u56f0\u96be\u548c\u4e0d\u5229\u7684\u9ad8\u9891\u5b66\u4e60\u504f\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDWTGS\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5c0f\u6ce2\u57df\u635f\u5931\u63d0\u4f9b\u989d\u5916\u7684\u7a7a\u95f4\u76d1\u7763\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u5728\u591a\u4e2a\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\uff08DWT\uff09\u7ea7\u522b\u4e0a\u4ec5\u76d1\u7763\u4f4e\u9891\uff08LF\uff09LL\u5b50\u5e26\uff0c\u540c\u65f6\u4ee5\u81ea\u76d1\u7763\u7684\u65b9\u5f0f\u5f3a\u5236\u6267\u884c\u9ad8\u9891\uff08HF\uff09HH\u5b50\u5e26\u7684\u7a00\u758f\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDWTGS\u7684\u4f4e\u9891\u4f18\u5148\u7b56\u7565\u63d0\u9ad8\u4e86\u6cdb\u5316\u80fd\u529b\u5e76\u51cf\u5c11\u4e86\u9ad8\u9891\u5e7b\u89c9\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u5085\u7acb\u53f6\u7684\u5bf9\u5e94\u65b9\u6cd5\u3002", "conclusion": "DWTGS\u901a\u8fc7\u5728\u591a\u4e2aDWT\u7ea7\u522b\u4e0a\u4ec5\u76d1\u7763\u4f4e\u9891(LF)LL\u5b50\u5e26\uff0c\u5e76\u5728\u9ad8\u9891(HF)HH\u5b50\u5e26\u4e0a\u4ee5\u81ea\u76d1\u7763\u65b9\u5f0f\u5f3a\u5236\u6267\u884c\u7a00\u758f\u6027\uff0c\u4ece\u800c\u5728\u7a00\u758f\u89c6\u56fe3D\u9ad8\u65af\u6cfc\u6e85\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u65b0\u89c6\u56fe\u91cd\u5efa\uff0c\u5e76\u4f18\u4e8e\u57fa\u4e8e\u5085\u7acb\u53f6\u7684\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2507.14959", "categories": ["cs.CV", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.14959", "abs": "https://arxiv.org/abs/2507.14959", "authors": ["Saeid Ghafouri", "Mohsen Fayyaz", "Xiangchen Li", "Deepu John", "Bo Ji", "Dimitrios Nikolopoulos", "Hans Vandierendonck"], "title": "Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices", "comment": null, "summary": "Real-time multi-label video classification on embedded devices is constrained\nby limited compute and energy budgets. Yet, video streams exhibit structural\nproperties such as label sparsity, temporal continuity, and label co-occurrence\nthat can be leveraged for more efficient inference. We introduce Polymorph, a\ncontext-aware framework that activates a minimal set of lightweight Low Rank\nAdapters (LoRA) per frame. Each adapter specializes in a subset of classes\nderived from co-occurrence patterns and is implemented as a LoRA weight over a\nshared backbone. At runtime, Polymorph dynamically selects and composes only\nthe adapters needed to cover the active labels, avoiding full-model switching\nand weight merging. This modular strategy improves scalability while reducing\nlatency and energy overhead. Polymorph achieves 40% lower energy consumption\nand improves mAP by 9 points over strong baselines on the TAO dataset.\nPolymorph is open source at https://github.com/inference-serving/polymorph/.", "AI": {"tldr": "Polymorph\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u6fc0\u6d3b\u4e00\u7ec4\u6700\u5c0f\u5316\u7684\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\u6765\u63d0\u9ad8\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u591a\u6807\u7b7e\u89c6\u9891\u5206\u7c7b\u6548\u7387\uff0c\u4ece\u800c\u964d\u4f4e\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u591a\u6807\u7b7e\u89c6\u9891\u5206\u7c7b\u53d7\u5230\u6709\u9650\u7684\u8ba1\u7b97\u548c\u80fd\u6e90\u9884\u7b97\u7684\u9650\u5236\u3002\u89c6\u9891\u6d41\u5177\u6709\u6807\u7b7e\u7a00\u758f\u6027\u3001\u65f6\u95f4\u8fde\u7eed\u6027\u548c\u6807\u7b7e\u5171\u73b0\u7b49\u7ed3\u6784\u7279\u6027\uff0c\u53ef\u4ee5\u7528\u4e8e\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u3002", "method": "Polymorph\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\uff0c\u4e3a\u6bcf\u4e00\u5e27\u6fc0\u6d3b\u4e00\u7ec4\u6700\u5c0f\u5316\u7684\u8f7b\u91cf\u7ea7\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\u3002\u6bcf\u4e2a\u9002\u914d\u5668\u4e13\u95e8\u5904\u7406\u7531\u5171\u73b0\u6a21\u5f0f\u6d3e\u751f\u7684\u5b50\u96c6\u7c7b\uff0c\u5e76\u4f5c\u4e3a\u5171\u4eab\u9aa8\u5e72\u7684LoRA\u6743\u91cd\u5b9e\u73b0\u3002\u8fd0\u884c\u65f6\uff0cPolymorph\u52a8\u6001\u5730\u9009\u62e9\u548c\u7ec4\u5408\u8986\u76d6\u6d3b\u52a8\u6807\u7b7e\u6240\u9700\u7684\u9002\u914d\u5668\uff0c\u907f\u514d\u4e86\u5b8c\u6574\u7684\u6a21\u578b\u5207\u6362\u548c\u6743\u91cd\u5408\u5e76\u3002", "result": "Polymorph\u5b9e\u73b0\u4e8640%\u7684\u80fd\u8017\u964d\u4f4e\uff0c\u5e76\u5c06mAP\u63d0\u9ad8\u4e869\u4e2a\u70b9\u3002", "conclusion": "Polymorph\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u548c\u7ec4\u5408\u6240\u9700\u7684\u9002\u914d\u5668\u6765\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u5ef6\u8fdf\u548c\u80fd\u6e90\u5f00\u9500\u3002\u5728TAO\u6570\u636e\u96c6\u4e0a\uff0cPolymorph\u5b9e\u73b0\u4e8640%\u7684\u80fd\u8017\u964d\u4f4e\uff0c\u5e76\u5c06mAP\u63d0\u9ad8\u4e869\u4e2a\u70b9\u3002"}}
{"id": "2507.15816", "categories": ["cs.LG", "cs.IT", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.15816", "abs": "https://arxiv.org/abs/2507.15816", "authors": ["Yujia Mu", "Cong Shen"], "title": "Federated Split Learning with Improved Communication and Storage Efficiency", "comment": "Accepted for publication in IEEE Transactions on Mobile Computing", "summary": "Federated learning (FL) is one of the popular distributed machine learning\n(ML) solutions but incurs significant communication and computation costs at\nedge devices. Federated split learning (FSL) can train sub-models in parallel\nand reduce the computational burden of edge devices by splitting the model\narchitecture. However, it still requires a high communication overhead due to\ntransmitting the smashed data and gradients between clients and the server in\nevery global round. Furthermore, the server must maintain separate partial\nmodels for every client, leading to a significant storage requirement. To\naddress these challenges, this paper proposes a novel communication and storage\nefficient federated split learning method, termed CSE-FSL, which utilizes an\nauxiliary network to locally update the weights of the clients while keeping a\nsingle model at the server, hence avoiding frequent transmissions of gradients\nfrom the server and greatly reducing the storage requirement of the server.\nAdditionally, a new model update method of transmitting the smashed data in\nselected epochs can reduce the amount of smashed data sent from the clients. We\nprovide a theoretical analysis of CSE-FSL, rigorously guaranteeing its\nconvergence under non-convex loss functions. The extensive experimental results\nfurther indicate that CSE-FSL achieves a significant communication reduction\nover existing FSL solutions using real-world FL tasks.", "AI": {"tldr": "CSE-FSL\u901a\u8fc7\u672c\u5730\u66f4\u65b0\u548c\u9009\u62e9\u6027\u4f20\u8f93\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u8054\u90a6\u5206\u79bb\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u548c\u5b58\u50a8\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u548c\u8054\u90a6\u5206\u79bb\u5b66\u4e60\uff08FSL\uff09\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u7684\u901a\u4fe1\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u4ee5\u53ca\u670d\u52a1\u5668\u7684\u5b58\u50a8\u9700\u6c42\u3002FSL\u901a\u8fc7\u62c6\u5206\u6a21\u578b\u67b6\u6784\u6765\u964d\u4f4e\u8fb9\u7f18\u8bbe\u5907\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4f46\u4ecd\u7136\u9700\u8981\u9ad8\u901a\u4fe1\u5f00\u9500\u6765\u4f20\u8f93\u6253\u788e\u7684\u6570\u636e\u548c\u68af\u5ea6\uff0c\u5e76\u4e14\u670d\u52a1\u5668\u9700\u8981\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7ef4\u62a4\u5355\u72ec\u7684\u90e8\u5206\u6a21\u578b\u3002", "method": "CSE-FSL\u662f\u4e00\u79cd\u65b0\u9896\u7684\u901a\u4fe1\u548c\u5b58\u50a8\u9ad8\u6548\u7684\u8054\u90a6\u5206\u79bb\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u8f85\u52a9\u7f51\u7edc\u5728\u5ba2\u6237\u7aef\u672c\u5730\u66f4\u65b0\u6743\u91cd\uff0c\u540c\u65f6\u5728\u670d\u52a1\u5668\u4e0a\u7ef4\u62a4\u5355\u4e2a\u6a21\u578b\u3002\u5b83\u8fd8\u901a\u8fc7\u5728\u9009\u5b9a\u7684\u65f6\u671f\u4f20\u8f93\u6253\u788e\u7684\u6570\u636e\u6765\u51cf\u5c11\u901a\u4fe1\u91cf\u3002", "result": "CSE-FSL\u5728\u5b9e\u9645\u7684\u8054\u90a6\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u4e8e\u73b0\u6709\u7684FSL\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\uff0c\u5e76\u4fdd\u8bc1\u4e86\u5728\u975e\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u7684\u6536\u655b\u6027\u3002", "conclusion": "CSE-FSL\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u8f85\u52a9\u7f51\u7edc\u5728\u5ba2\u6237\u7aef\u672c\u5730\u66f4\u65b0\u6743\u91cd\uff0c\u540c\u65f6\u5728\u670d\u52a1\u5668\u4e0a\u53ea\u4fdd\u7559\u4e00\u4e2a\u6a21\u578b\uff0c\u4ece\u800c\u51cf\u5c11\u670d\u52a1\u5668\u7684\u5b58\u50a8\u9700\u6c42\u548c\u9891\u7e41\u7684\u68af\u5ea6\u4f20\u8f93\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5728\u9009\u5b9a\u7684\u65f6\u671f\u4f20\u8f93\u6253\u788e\u7684\u6570\u636e\uff0c\u53ef\u4ee5\u51cf\u5c11\u4ece\u5ba2\u6237\u7aef\u53d1\u9001\u7684\u6253\u788e\u6570\u636e\u7684\u6570\u91cf\u3002CSE-FSL\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e86\u5728\u975e\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u7684\u6536\u655b\u6027\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u7684\u8054\u90a6\u5b66\u4e60\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u3002"}}
{"id": "2507.14965", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14965", "abs": "https://arxiv.org/abs/2507.14965", "authors": ["Yaojie Zhang", "Tianlun Huang", "Weijun Wang", "Wei Feng"], "title": "Decision PCR: Decision version of the Point Cloud Registration task", "comment": null, "summary": "Low-overlap point cloud registration (PCR) remains a significant challenge in\n3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become\nineffective under extremely low inlier ratios. In this paper, we revisit the\nregistration result evaluation problem and identify the Decision version of the\nPCR task as the fundamental problem. To address this Decision PCR task, we\npropose a data-driven approach. First, we construct a corresponding dataset\nbased on the 3DMatch dataset. Then, a deep learning-based classifier is trained\nto reliably assess registration quality, overcoming the limitations of\ntraditional metrics. To our knowledge, this is the first comprehensive study to\naddress this task through a deep learning framework. We incorporate this\nclassifier into standard PCR pipelines. When integrated with our approach,\nexisting state-of-the-art PCR methods exhibit significantly enhanced\nregistration performance. For example, combining our framework with\nGeoTransformer achieves a new SOTA registration recall of 86.97\\% on the\nchallenging 3DLoMatch benchmark. Our method also demonstrates strong\ngeneralization capabilities on the unseen outdoor ETH dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u6765\u8bc4\u4f30\u70b9\u4e91\u914d\u51c6\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u4f4e\u91cd\u53e0\u70b9\u4e91\u914d\u51c6\u7684\u6311\u6218\uff0c\u5e76\u63d0\u9ad8\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4f4e\u91cd\u53e0\u70b9\u4e91\u914d\u51c6\uff08PCR\uff09\u4ecd\u7136\u662f3D\u89c6\u89c9\u4e2d\u7684\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u4f20\u7edf\u7684\u8bc4\u4f30\u6307\u6807\u5728\u6781\u4f4e\u7684\u5185\u70b9\u6bd4\u4f8b\u4e0b\u4f1a\u5931\u6548\u3002", "method": "\u9996\u5148\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e3DMatch\u6570\u636e\u96c6\u7684\u76f8\u5e94\u6570\u636e\u96c6\u3002\u7136\u540e\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u5668\u6765\u53ef\u9760\u5730\u8bc4\u4f30\u914d\u51c6\u8d28\u91cf\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5206\u7c7b\u5668\u514b\u670d\u4e86\u4f20\u7edf\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709PCR\u65b9\u6cd5\u7684\u914d\u51c6\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u5c06\u8be5\u6846\u67b6\u4e0eGeoTransformer\u7ed3\u5408\u57283DLoMatch\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e8686.97%\u7684SOTA\u914d\u51c6\u53ec\u56de\u7387\uff0c\u5e76\u5728ETH\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u901a\u8fc7\u8bad\u7ec3\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u5668\u6765\u8bc4\u4f30\u914d\u51c6\u8d28\u91cf\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709\u914d\u51c6\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u57283DLoMatch\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684SOTA\u914d\u51c6\u53ec\u56de\u738786.97%\u3002"}}
{"id": "2507.15066", "categories": ["cs.LG", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.15066", "abs": "https://arxiv.org/abs/2507.15066", "authors": ["Yiyuan Yang", "Zichuan Liu", "Lei Song", "Kai Ying", "Zhiguang Wang", "Tom Bamford", "Svitlana Vyetrenko", "Jiang Bian", "Qingsong Wen"], "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "comment": "Under review. 19 pages, 8 figures, 12 tables", "summary": "Time series anomaly detection is critical across various domains, yet current\napproaches often limit analysis to mere binary anomaly classification without\ndetailed categorization or further explanatory reasoning. To address these\nlimitations, we propose a novel task, Time-series Reasoning for Anomaly\n(Time-RA) that transforms classical time series anomaly detection from a\ndiscriminative into a generative, reasoning-intensive task leveraging Large\nLanguage Models (LLMs). Also, we introduce the first real-world multimodal\nbenchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,\ncomprising approximately 40,000 samples across 10 real-world domains. Each\nsample includes numeric time series data, contextual text information, and\nvisual representations, each annotated with fine-grained categories (14 types\nfor univariate anomalies and 6 for multivariate anomalies) and structured\nexplanatory reasoning. We develop a sophisticated annotation framework\nutilizing ensemble-generated labels refined through GPT-4-driven feedback,\nensuring accuracy and interpretability. Extensive benchmarking of LLMs and\nmultimodal LLMs demonstrates the capabilities and limitations of current\nmodels, highlighting the critical role of supervised fine-tuning. Our dataset\nand task pave the way for significant advancements in interpretable time series\nanomaly detection and reasoning.", "AI": {"tldr": "\u63d0\u51faTime-RA\u4efb\u52a1\u548cRATs40K\u6570\u636e\u96c6\uff0c\u5229\u7528LLM\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u89e3\u91ca\u6027\u63a8\u7406\uff0c\u5e76\u5728\u591a\u6a21\u6001\u6570\u636e\u4e0a\u8fdb\u884c\u6807\u6ce8\u548c\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u4ec5\u9650\u4e8e\u4e8c\u5143\u5206\u7c7b\uff0c\u7f3a\u4e4f\u8be6\u7ec6\u7684\u7c7b\u522b\u5212\u5206\u548c\u89e3\u91ca\u6027\u63a8\u7406\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u4e2d\u5bf9\u5f02\u5e38\u539f\u56e0\u6df1\u5165\u7406\u89e3\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTime-RA\u7684\u65b0\u4efb\u52a1\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4ece\u5224\u522b\u5f0f\u4efb\u52a1\u8f6c\u53d8\u4e3a\u751f\u6210\u5f0f\u3001\u6ce8\u91cd\u63a8\u7406\u7684\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u5f15\u5165\u4e86RATs40K\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u7ea640,000\u4e2a\u6837\u672c\uff0c\u6db5\u76d610\u4e2a\u771f\u5b9e\u4e16\u754c\u9886\u57df\uff0c\u5e76\u4e3a\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3001\u4e0a\u4e0b\u6587\u6587\u672c\u4fe1\u606f\u548c\u89c6\u89c9\u8868\u793a\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u5f02\u5e38\u7c7b\u522b\uff08\u5355\u53d8\u91cf14\u79cd\uff0c\u591a\u53d8\u91cf6\u79cd\uff09\u548c\u7ed3\u6784\u5316\u89e3\u91ca\u6027\u63a8\u7406\u7684\u6807\u6ce8\u3002\u901a\u8fc7\u5229\u7528\u96c6\u6210\u6a21\u578b\u751f\u6210\u7684\u6807\u7b7e\uff0c\u5e76\u7ed3\u5408GPT-4\u8fdb\u884c\u53cd\u9988\u4f18\u5316\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u590d\u6742\u7684\u6807\u6ce8\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5bf9LLMs\u548c\u591a\u6a21\u6001LLMs\u8fdb\u884c\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u76d1\u7763\u5fae\u8c03\u7684\u5173\u952e\u4f5c\u7528\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684Time-RA\u4efb\u52a1\u548cRATs40K\u6570\u636e\u96c6\u80fd\u591f\u6709\u6548\u63a8\u52a8\u53ef\u89e3\u91ca\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u548c\u63a8\u7406\u9886\u57df\u7684\u53d1\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff08Time-RA\uff09\u548c\u9996\u4e2a\u591a\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\u6570\u636e\u96c6\uff08RATs40K\uff09\uff0c\u65e8\u5728\u4ece\u4f20\u7edf\u7684\u4e8c\u5143\u5206\u7c7b\u8f6c\u5411\u66f4\u5177\u89e3\u91ca\u6027\u7684\u751f\u6210\u5f0f\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u4e3a\u53ef\u89e3\u91ca\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u548c\u63a8\u7406\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.15641", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15641", "abs": "https://arxiv.org/abs/2507.15641", "authors": ["Alessio Pittiglio"], "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates", "comment": "12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025", "summary": "In this paper, we present our submission to the MM-ArgFallacy2025 shared\ntask, which aims to advance research in multimodal argument mining, focusing on\nlogical fallacies in political debates. Our approach uses pretrained\nTransformer-based models and proposes several ways to leverage context. In the\nfallacy classification subtask, our models achieved macro F1-scores of 0.4444\n(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed\nperformance comparable to the text-only model, suggesting potential for\nimprovements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3Transformer\u548c\u4e0a\u4e0b\u6587\u5229\u7528\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u653f\u6cbb\u8fa9\u8bba\u4e2d\u7684\u591a\u6a21\u6001\u903b\u8f91\u8c2c\u8bef\u6316\u6398\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a8\u8fdb\u591a\u6a21\u6001\u8bba\u8bc1\u6316\u6398\u7814\u7a76\uff0c\u7279\u522b\u5173\u6ce8\u653f\u6cbb\u8fa9\u8bba\u4e2d\u7684\u903b\u8f91\u8c2c\u8bef\uff0c\u4ee5\u5e94\u5bf9MM-ArgFallick2025\u5171\u4eab\u4efb\u52a1\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u9884\u8bad\u7ec3\u7684Transformer\u6a21\u578b\uff0c\u5e76\u63a2\u7d22\u4e86\u51e0\u79cd\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9MM-ArgFallick2025\u5171\u4eab\u4efb\u52a1\u4e2d\u5173\u4e8e\u591a\u6a21\u6001\u8bba\u8bc1\u6316\u6398\u548c\u653f\u6cbb\u8fa9\u8bba\u4e2d\u903b\u8f91\u8c2c\u8bef\u7684\u7814\u7a76\u3002", "result": "\u5728\u8c2c\u8bef\u5206\u7c7b\u5b50\u4efb\u52a1\u4e2d\uff0c\u6211\u4eec\u7684\u6a21\u578b\u53d6\u5f97\u4e86\u4ee5\u4e0b\u5b8fF1\u5206\u6570\uff1a\u6587\u672c\u6a21\u578b\u4e3a0.4444\uff0c\u97f3\u9891\u6a21\u578b\u4e3a0.3559\uff0c\u591a\u6a21\u6001\u6a21\u578b\u4e3a0.4403\u3002", "conclusion": "\u867d\u7136\u6211\u4eec\u7684\u591a\u6a21\u6001\u6a21\u578b\u8868\u73b0\u4e0e\u4ec5\u6587\u672c\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2507.14976", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14976", "abs": "https://arxiv.org/abs/2507.14976", "authors": ["Hao Zheng", "Shunzhi Yang", "Zhuoxin He", "Jinfeng Yang", "Zhenhua Huang"], "title": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models", "comment": "Accepted by ICCV2025", "summary": "Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent\ngeneralization abilities. However, adapting these large-scale models to\ndownstream tasks while preserving their generalization capabilities remains\nchallenging. Although prompt learning methods have shown promise, they suffer\nfrom two fundamental bottlenecks that limit generalization: (a) modality\nisolation, and (b) hierarchical semantic decay. To address these limitations,\nwe propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that\nestablishes bidirectional knowledge flow between text and vision modalities,\nenabling them to refine their semantics mutually. HiCroPL routes knowledge\nflows by leveraging the complementary strengths of text and vision. In early\nlayers, text prompts inject relatively clear semantics into visual prompts\nthrough a hierarchical knowledge mapper, enhancing the representation of\nlow-level visual semantics. In later layers, visual prompts encoding specific\ntask-relevant objects flow back to refine text prompts, enabling deeper\nalignment. Crucially, our hierarchical knowledge mapper allows representations\nat multi-scales to be fused, ensuring that deeper representations retain\ntransferable shallow semantics thereby enhancing generalization. We further\nintroduce a lightweight layer-specific knowledge proxy to enable efficient\ncross-modal interactions. Extensive evaluations across four tasks demonstrate\nHiCroPL's superior performance, achieving state-of-the-art results on 11\nbenchmarks with significant improvements. Code is available at:\nhttps://github.com/zzeoZheng/HiCroPL.", "AI": {"tldr": "HiCroPL\u901a\u8fc7\u53cc\u5411\u8de8\u6a21\u6001\u63d0\u793a\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86VLM\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u867d\u7136\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u4f46\u5728\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u65f6\u4fdd\u6301\u5176\u6cdb\u5316\u80fd\u529b\u4ecd\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u63d0\u793a\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u6a21\u6001\u9694\u79bb\u548c\u5c42\u7ea7\u8bed\u4e49\u8870\u51cf\u4e24\u5927\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "method": "HiCroPL\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u6620\u5c04\u5668\uff0c\u5728\u65e9\u671f\u5c42\u5229\u7528\u6587\u672c\u63d0\u793a\u6ce8\u5165\u6e05\u6670\u7684\u8bed\u4e49\u5230\u89c6\u89c9\u63d0\u793a\u4e2d\uff0c\u4ee5\u589e\u5f3a\u4f4e\u5c42\u89c6\u89c9\u8bed\u4e49\u7684\u8868\u793a\u3002\u5728\u540e\u671f\u5c42\uff0c\u89c6\u89c9\u63d0\u793a\u5c06\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u5bf9\u8c61\u4fe1\u606f\u53cd\u5411\u4f20\u9012\u7ed9\u6587\u672c\u63d0\u793a\uff0c\u4ee5\u5b9e\u73b0\u66f4\u6df1\u5c42\u6b21\u7684\u5bf9\u9f50\u3002\u6b64\u5916\uff0cHiCroPL\u8fd8\u5f15\u5165\u4e86\u5c42\u7ea7\u7279\u5b9a\u7684\u77e5\u8bc6\u4ee3\u7406\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u8de8\u6a21\u6001\u4ea4\u4e92\u3002", "result": "HiCroPL\u5728\u56db\u4e2a\u4e0b\u6e38\u4efb\u52a1\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u572811\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "HiCroPL\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u6620\u5c04\u5668\u548c\u5c42\u7ea7\u7279\u5b9a\u7684\u77e5\u8bc6\u4ee3\u7406\uff0c\u5b9e\u73b0\u4e86\u8de8\u6a21\u6001\u77e5\u8bc6\u7684\u53cc\u5411\u6d41\u52a8\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u63d0\u793a\u5b66\u4e60\u65b9\u6cd5\u4e2d\u7684\u6a21\u6001\u9694\u79bb\u548c\u5c42\u7ea7\u8bed\u4e49\u8870\u51cf\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5728\u56db\u4e2a\u4e0b\u6e38\u4efb\u52a1\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0cHiCroPL\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u572811\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002"}}
{"id": "2507.15675", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15675", "abs": "https://arxiv.org/abs/2507.15675", "authors": ["Xinyu Zhang", "Yuanquan Hu", "Fangchao Liu", "Zhicheng Dou"], "title": "P3: Prompts Promote Prompting", "comment": "Accepted to ACL 2025 findings", "summary": "Current large language model (LLM) applications often employ multi-component\nprompts, comprising both system and user prompts, to guide model behaviors.\nWhile recent advancements have demonstrated the efficacy of automatically\noptimizing either the system or user prompt to boost performance, such\nunilateral approaches often yield suboptimal outcomes due to the interdependent\nnature of these components. In this work, we introduce P3, a novel\nself-improvement framework that concurrently optimizes both system and user\nprompts through an iterative process. The offline optimized prompts are further\nleveraged to promote online prompting by performing query-dependent prompt\noptimization. Extensive experiments on general tasks (e.g., Arena-hard and\nAlpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3\nachieves superior performance in the realm of automatic prompt optimization.\nOur results highlight the effectiveness of a holistic optimization strategy in\nenhancing LLM performance across diverse domains.", "AI": {"tldr": "P3\u6846\u67b6\u901a\u8fc7\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u548c\u7528\u6237\u63d0\u793a\uff0c\u5e76\u7ed3\u5408\u5728\u7ebf\u67e5\u8be2\u76f8\u5173\u7684\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5e94\u7528\u901a\u5e38\u4f7f\u7528\u591a\u7ec4\u4ef6\u63d0\u793a\u6765\u6307\u5bfc\u6a21\u578b\u884c\u4e3a\u3002\u867d\u7136\u53ef\u4ee5\u81ea\u52a8\u4f18\u5316\u5176\u4e2d\u4e00\u4e2a\u7ec4\u4ef6\uff0c\u4f46\u7531\u4e8e\u7ec4\u4ef6\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u8fd9\u79cd\u5355\u65b9\u9762\u7684\u65b9\u6cd5\u901a\u5e38\u4e0d\u80fd\u8fbe\u5230\u6700\u4f18\u7ed3\u679c\u3002", "method": "P3\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u63d0\u793a\u548c\u7528\u6237\u63d0\u793a\u3002\u79bb\u7ebf\u4f18\u5316\u540e\u7684\u63d0\u793a\u901a\u8fc7\u6267\u884c\u67e5\u8be2\u76f8\u5173\u7684\u63d0\u793a\u4f18\u5316\u6765\u4fc3\u8fdb\u5728\u7ebf\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cP3\u5728\u901a\u7528\u4efb\u52a1\uff08\u5982Arena-hard\u548cAlpaca-eval\uff09\u548c\u63a8\u7406\u4efb\u52a1\uff08\u5982GSM8K\u548cGPQA\uff09\u4e0a\u5747\u53d6\u5f97\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "P3\u6846\u67b6\u901a\u8fc7\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u63d0\u793a\u548c\u7528\u6237\u63d0\u793a\uff0c\u5e76\u5728\u5728\u7ebf\u63d0\u793a\u4e2d\u8fdb\u884c\u67e5\u8be2\u76f8\u5173\u7684\u63d0\u793a\u4f18\u5316\uff0c\u5728\u901a\u7528\u4efb\u52a1\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u90fd\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14997", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14997", "abs": "https://arxiv.org/abs/2507.14997", "authors": ["Roy H. Jennings", "Genady Paikin", "Roy Shaul", "Evgeny Soloveichik"], "title": "Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) show promise for image-based\nregression tasks, but current approaches face key limitations. Recent methods\nfine-tune MLLMs using preset output vocabularies and generic task-level prompts\n(e.g., \"How would you rate this image?\"), assuming this mimics human rating\nbehavior. Our analysis reveals these approaches provide no benefit over\nimage-only training. Models using preset vocabularies and generic prompts\nperform equivalently to image-only models, failing to leverage semantic\nunderstanding from textual input. We propose Regression via Transformer-Based\nClassification (RvTC), which replaces vocabulary-constrained classification\nwith a flexible bin-based approach. Unlike approaches that address\ndiscretization errors through complex distributional modeling, RvTC eliminates\nmanual vocabulary crafting through straightforward bin increase, achieving\nstate-of-the-art performance on four image assessment datasets using only\nimages. More importantly, we demonstrate that data-specific prompts\ndramatically improve performance. Unlike generic task descriptions, prompts\ncontaining semantic information about specific images enable MLLMs to leverage\ncross-modal understanding. On the AVA dataset, adding challenge titles to\nprompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We\ndemonstrate through empirical evidence from the AVA and AGIQA-3k datasets that\nMLLMs benefit from semantic prompt information surpassing mere statistical\nbiases. This underscores the importance of incorporating meaningful textual\ncontext in multimodal regression tasks.", "AI": {"tldr": "\u4f7f\u7528\u5305\u542b\u7279\u5b9a\u56fe\u50cf\u8bed\u4e49\u7684\u63d0\u793a\uff0c\u53ef\u4ee5\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0cRvTC\u65b9\u6cd5\u901a\u8fc7\u57fa\u4e8e\u533a\u95f4\u7684\u65b9\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u7684\u63d0\u793a\uff0c\u5728\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u4f7f\u7528\u9884\u8bbe\u8f93\u51fa\u8bcd\u6c47\u8868\u548c\u901a\u7528\u4efb\u52a1\u63d0\u793a\uff0c\u8fd9\u672a\u80fd\u5145\u5206\u5229\u7528\u6587\u672c\u8bed\u4e49\u4fe1\u606f\uff0c\u5176\u6548\u679c\u4e0e\u4ec5\u4f7f\u7528\u56fe\u50cf\u8bad\u7ec3\u7684\u6a21\u578b\u76f8\u5f53\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u6709\u6548\u5229\u7528MLLMs\u7684\u8de8\u6a21\u6001\u7406\u89e3\u80fd\u529b\u6765\u6539\u8fdb\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRvTC\uff08Regression via Transformer-Based Classification\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7528\u7075\u6d3b\u7684\u57fa\u4e8e\u533a\u95f4\uff08bin-based\uff09\u7684\u65b9\u6cd5\u66ff\u4ee3\u4e86\u53d7\u8bcd\u6c47\u8868\u9650\u5236\u7684\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u589e\u52a0\u533a\u95f4\u6765\u6d88\u9664\u624b\u52a8\u8bbe\u8ba1\u8bcd\u6c47\u8868\u7684\u9700\u8981\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8868\u660e\u4f7f\u7528\u5305\u542b\u7279\u5b9a\u56fe\u50cf\u8bed\u4e49\u4fe1\u606f\u7684\u6570\u636e\u9a71\u52a8\u578b\u63d0\u793a\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8MLLMs\u7684\u8868\u73b0\uff0c\u4f8b\u5982\u5728AVA\u6570\u636e\u96c6\u4e0a\uff0c\u52a0\u5165\u6311\u6218\u6807\u9898\u5c06\u76f8\u5173\u6027\u4ece0.83\u63d0\u9ad8\u52300.90\u3002", "result": "RvTC\u65b9\u6cd5\u5728\u56db\u4e2a\u56fe\u50cf\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4ec5\u4f7f\u7528\u56fe\u50cf\u6570\u636e\u3002\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u52a0\u5165\u6570\u636e\u7279\u5f02\u6027\u4fe1\u606f\uff08\u5982AVA\u6570\u636e\u96c6\u7684\u6311\u6218\u6807\u9898\uff09\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347MLLMs\u7684\u8868\u73b0\uff0c\u76f8\u5173\u6027\u4ece0.83\u63d0\u9ad8\u52300.90\uff0c\u8d85\u8fc7\u4e86\u4ec5\u4f7f\u7528\u56fe\u50cf\u7684\u6a21\u578b\u4ee5\u53ca\u4f7f\u7528\u901a\u7528\u63d0\u793a\u7684MLLMs\u3002", "conclusion": "MLLMs\u5728\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u4e2d\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u63d0\u793a\uff0c\u53ef\u4ee5\u8d85\u8d8a\u56fe\u50cf\u672c\u8eab\uff0c\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8fd9\u8868\u660e\u5728\u591a\u6a21\u6001\u56de\u5f52\u4efb\u52a1\u4e2d\u5305\u542b\u6709\u610f\u4e49\u7684\u6587\u672c\u4e0a\u4e0b\u6587\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.15073", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15073", "abs": "https://arxiv.org/abs/2507.15073", "authors": ["Samuel Pfrommer", "Yixiao Huang", "Somayeh Sojoudi"], "title": "Reinforcement Learning for Flow-Matching Policies", "comment": null, "summary": "Flow-matching policies have emerged as a powerful paradigm for generalist\nrobotics. These models are trained to imitate an action chunk, conditioned on\nsensor observations and textual instructions. Often, training demonstrations\nare generated by a suboptimal policy, such as a human operator. This work\nexplores training flow-matching policies via reinforcement learning to surpass\nthe original demonstration policy performance. We particularly note\nminimum-time control as a key application and present a simple scheme for\nvariable-horizon flow-matching planning. We then introduce two families of\napproaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group\nRelative Policy Optimization (GRPO) approach with a learned reward surrogate.\nOur policies are trained on an illustrative suite of simulated unicycle\ndynamics tasks, and we show that both approaches dramatically improve upon the\nsuboptimal demonstrator performance, with the GRPO approach in particular\ngenerally incurring between $50\\%$ and $85\\%$ less cost than a naive Imitation\nLearning Flow Matching (ILFM) approach.", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08\u7279\u522b\u662fRWFM\u548cGRPO\uff09\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u673a\u5668\u4eba\u6027\u80fd\uff0c\u8d85\u8d8a\u4eba\u7c7b\u6f14\u793a\u3002", "motivation": "\u63a2\u7d22\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\uff0c\u4ee5\u8d85\u8d8a\u4f5c\u4e3a\u6f14\u793a\u6765\u6e90\u7684\u6b21\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u5956\u52b1\u52a0\u6743\u6d41\u5339\u914d\uff08RWFM\uff09\u7684\u7b80\u5355\u65b9\u6848\uff0c\u4ee5\u53ca\u4e00\u79cd\u5177\u6709\u5b66\u4e60\u5956\u52b1\u66ff\u4ee3\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u65b9\u6cd5\u3002", "result": "\u5728\u6a21\u62df\u7684\u5355\u8f6e\u8f66\u52a8\u529b\u5b66\u4efb\u52a1\u4e2d\uff0cRWFM\u548cGRPO\u65b9\u6cd5\u5747\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0cGRPO\u65b9\u6cd5\u7684\u6210\u672c\u6bd4\u6a21\u4eff\u5b66\u4e60\u6d41\u5339\u914d\uff08ILFM\uff09\u65b9\u6cd5\u4f4e50%-85%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\uff0c\u4ee5\u8d85\u8d8a\u539f\u59cb\u6f14\u793a\u7b56\u7565\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6700\u5c0f\u65f6\u95f4\u63a7\u5236\u5e94\u7528\u4e2d\u3002"}}
{"id": "2507.15698", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15698", "abs": "https://arxiv.org/abs/2507.15698", "authors": ["Congmin Zheng", "Jiachen Zhu", "Jianghao Lin", "Xinyi Dai", "Yong Yu", "Weinan Zhang", "Mengyue Yang"], "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models", "comment": null, "summary": "Process Reward Models (PRMs) play a central role in evaluating and guiding\nmulti-step reasoning in large language models (LLMs), especially for\nmathematical problem solving. However, we identify a pervasive length bias in\nexisting PRMs: they tend to assign higher scores to longer reasoning steps,\neven when the semantic content and logical validity are unchanged. This bias\nundermines the reliability of reward predictions and leads to overly verbose\noutputs during inference. To address this issue, we propose\nCoLD(Counterfactually-Guided Length Debiasing), a unified framework that\nmitigates length bias through three components: an explicit length-penalty\nadjustment, a learned bias estimator trained to capture spurious length-related\nsignals, and a joint training strategy that enforces length-invariance in\nreward predictions. Our approach is grounded in counterfactual reasoning and\ninformed by causal graph analysis. Extensive experiments on MATH500 and\nGSM-Plus show that CoLD consistently reduces reward-length correlation,\nimproves accuracy in step selection, and encourages more concise, logically\nvalid reasoning. These results demonstrate the effectiveness and practicality\nof CoLD in improving the fidelity and robustness of PRMs.", "AI": {"tldr": "CoLD\u6846\u67b6\u901a\u8fc7\u53cd\u4e8b\u5b9e\u63a8\u7406\u548c\u56e0\u679c\u56fe\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u4e2d\u5b58\u5728\u7684\u957f\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u957f\u5ea6\u60e9\u7f5a\u3001\u504f\u5dee\u4f30\u8ba1\u548c\u8054\u5408\u8bad\u7ec3\u7b49\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5956\u52b1\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u7684\u7b80\u6d01\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u5728\u8bc4\u4f30\u548c\u6307\u5bfcLLM\u7684\u591a\u6b65\u63a8\u7406\uff08\u5c24\u5176\u662f\u5728\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u65b9\u9762\uff09\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u5b58\u5728\u666e\u904d\u7684\u957f\u5ea6\u504f\u5dee\uff0c\u5373\u5b83\u4eec\u503e\u5411\u4e8e\u7ed9\u66f4\u957f\u7684\u63a8\u7406\u6b65\u9aa4\u8d4b\u4e88\u66f4\u9ad8\u7684\u5206\u6570\uff0c\u5373\u4f7f\u8bed\u4e49\u5185\u5bb9\u548c\u903b\u8f91\u6709\u6548\u6027\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u79cd\u504f\u5dee\u4f1a\u7834\u574f\u5956\u52b1\u9884\u6d4b\u7684\u53ef\u9760\u6027\uff0c\u5e76\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8f93\u51fa\u5197\u957f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoLD(Counterfactually-Guided Length Debiasing)\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u7ec4\u6210\u90e8\u5206\uff1a\u663e\u5f0f\u7684\u957f\u5ea6\u60e9\u7f5a\u8c03\u6574\u3001\u7528\u4e8e\u6355\u6349\u865a\u5047\u957f\u5ea6\u76f8\u5173\u4fe1\u53f7\u7684\u5b66\u4e60\u504f\u5dee\u4f30\u8ba1\u5668\uff0c\u4ee5\u53ca\u5f3a\u5236\u5956\u52b1\u9884\u6d4b\u4e2d\u957f\u5ea6\u4e0d\u53d8\u6027\u7684\u8054\u5408\u8bad\u7ec3\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u63a8\u7406\uff0c\u5e76\u7ed3\u5408\u4e86\u56e0\u679c\u56fe\u5206\u6790\u3002", "result": "\u5728MATH500\u548cGSM-Plus\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCoLD\u80fd\u591f\u4e00\u81f4\u5730\u964d\u4f4e\u5956\u52b1\u4e0e\u957f\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u63d0\u9ad8\u6b65\u9aa4\u9009\u62e9\u7684\u51c6\u786e\u6027\uff0c\u5e76\u9f13\u52b1\u66f4\u7b80\u6d01\u3001\u903b\u8f91\u4e0a\u6709\u6548\u7684\u63a8\u7406\u3002", "conclusion": "CoLD\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u7684\u957f\u5ea6\u60e9\u7f5a\u8c03\u6574\u3001\u5b66\u4e60\u5230\u7684\u504f\u5dee\u4f30\u8ba1\u5668\u4ee5\u53ca\u8054\u5408\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u7f13\u89e3\u4e86PRM\u4e2d\u7684\u957f\u5ea6\u504f\u5dee\uff0c\u63d0\u9ad8\u4e86\u5956\u52b1\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u8fc7\u7a0b\u7684\u7b80\u6d01\u6027\u4e0e\u903b\u8f91\u6027\u3002"}}
{"id": "2507.15000", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15000", "abs": "https://arxiv.org/abs/2507.15000", "authors": ["Chaoyun Wang", "I-Chao Shen", "Takeo Igarashi", "Nanning Zheng", "Caigui Jiang"], "title": "Axis-Aligned Document Dewarping", "comment": null, "summary": "Document dewarping is crucial for many applications. However, existing\nlearning-based methods primarily rely on supervised regression with annotated\ndata without leveraging the inherent geometric properties in physical documents\nto the dewarping process. Our key insight is that a well-dewarped document is\ncharacterized by transforming distorted feature lines into axis-aligned ones.\nThis property aligns with the inherent axis-aligned nature of the discrete grid\ngeometry in planar documents. In the training phase, we propose an axis-aligned\ngeometric constraint to enhance document dewarping. In the inference phase, we\npropose an axis alignment preprocessing strategy to reduce the dewarping\ndifficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned\nDistortion (AAD), that not only incorporates geometric meaning and aligns with\nhuman visual perception but also demonstrates greater robustness. As a result,\nour method achieves SOTA results on multiple existing benchmarks and achieves\n18.2%~34.5% improvements on the AAD metric.", "AI": {"tldr": "This paper introduces a new approach to document dewarping by leveraging the geometric property of axis alignment. It includes a new training constraint, an inference preprocessing step, and a novel evaluation metric (AAD), achieving state-of-the-art results.", "motivation": "Existing learning-based document dewarping methods do not fully leverage the geometric properties of physical documents. The key insight is that dewarped documents transform distorted feature lines into axis-aligned ones, reflecting the inherent grid geometry of planar documents.", "method": "The method incorporates an axis-aligned geometric constraint during training and an axis-alignment preprocessing strategy during inference. A new metric, Axis-Aligned Distortion (AAD), is introduced for evaluation.", "result": "Achieved state-of-the-art results on multiple existing benchmarks, with 18.2%~34.5% improvement on the AAD metric.", "conclusion": "The proposed method achieves state-of-the-art results on multiple benchmarks and shows significant improvements on the new AAD metric."}}
{"id": "2507.15079", "categories": ["cs.LG", "q-fin.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.15079", "abs": "https://arxiv.org/abs/2507.15079", "authors": ["Arkadiusz Lipiecki", "Bartosz Uniejewski"], "title": "Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts", "comment": "Preprint", "summary": "Quantifying the uncertainty of forecasting models is essential to assess and\nmitigate the risks associated with data-driven decisions, especially in\nvolatile domains such as electricity markets. Machine learning methods can\nprovide highly accurate electricity price forecasts, critical for informing the\ndecisions of market participants. However, these models often lack uncertainty\nestimates, which limits the ability of decision makers to avoid unnecessary\nrisks. In this paper, we propose a novel method for generating probabilistic\nforecasts from ensembles of point forecasts, called Isotonic Quantile\nRegression Averaging (iQRA). Building on the established framework of Quantile\nRegression Averaging (QRA), we introduce stochastic order constraints to\nimprove forecast accuracy, reliability, and computational costs. In an\nextensive forecasting study of the German day-ahead electricity market, we show\nthat iQRA consistently outperforms state-of-the-art postprocessing methods in\nterms of both reliability and sharpness. It produces well-calibrated prediction\nintervals across multiple confidence levels, providing superior reliability to\nall benchmark methods, particularly coverage-based conformal prediction. In\naddition, isotonic regularization decreases the complexity of the quantile\nregression problem and offers a hyperparameter-free approach to variable\nselection.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aiQRA\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u70b9\u9884\u6d4b\u7684\u96c6\u5408\u4e2d\u751f\u6210\u6982\u7387\u9884\u6d4b\uff0c\u4ee5\u63d0\u9ad8\u7535\u529b\u5e02\u573a\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u91cf\u5316\u9884\u6d4b\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u8bc4\u4f30\u548c\u51cf\u8f7b\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u76f8\u5173\u7684\u98ce\u9669\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u7535\u529b\u5e02\u573a\u7b49\u6ce2\u52a8\u6027\u9886\u57df\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u63d0\u4f9b\u51c6\u786e\u7684\u7535\u529b\u4ef7\u683c\u9884\u6d4b\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u9650\u5236\u4e86\u51b3\u7b56\u8005\u89c4\u907f\u98ce\u9669\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7b49otonic\u5206\u4f4d\u6570\u56de\u5f52\u5e73\u5747\uff08iQRA\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u968f\u673a\u987a\u5e8f\u7ea6\u675f\u6765\u751f\u6210\u70b9\u9884\u6d4b\u96c6\u5408\u7684\u6982\u7387\u9884\u6d4b\uff0c\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u8ba1\u7b97\u6210\u672c\u3002", "result": "iQRA\u65b9\u6cd5\u5728\u5fb7\u56fd\u65e5\u5185\u7535\u529b\u5e02\u573a\u7684\u5e7f\u6cdb\u9884\u6d4b\u7814\u7a76\u4e2d\uff0c\u5728\u53ef\u9760\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u5e76\u4f18\u4e8e\u5305\u62ec\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u5171\u5f62\u9884\u6d4b\u5728\u5185\u7684\u6240\u6709\u57fa\u51c6\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7b49otonic\u6b63\u5219\u5316\u964d\u4f4e\u4e86\u5206\u4f4d\u70b9\u56de\u5f52\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8d85\u53c2\u6570\u5373\u53ef\u8fdb\u884c\u53d8\u91cf\u9009\u62e9\u7684\u65b9\u6cd5\u3002", "conclusion": "iQRA\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u5e76\u4e3a\u591a\u4e2a\u7f6e\u4fe1\u6c34\u5e73\u63d0\u4f9b\u4e86\u826f\u597d\u6821\u51c6\u7684\u9884\u6d4b\u533a\u95f4\uff0c\u5728\u5fb7\u56fd\u65e5\u5185\u7535\u529b\u5e02\u573a\u9884\u6d4b\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.15706", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15706", "abs": "https://arxiv.org/abs/2507.15706", "authors": ["David Peter Wallis Freeborn"], "title": "Compositional Understanding in Signaling Games", "comment": null, "summary": "Receivers in standard signaling game models struggle with learning\ncompositional information. Even when the signalers send compositional messages,\nthe receivers do not interpret them compositionally. When information from one\nmessage component is lost or forgotten, the information from other components\nis also erased. In this paper I construct signaling game models in which\ngenuine compositional understanding evolves. I present two new models: a\nminimalist receiver who only learns from the atomic messages of a signal, and a\ngeneralist receiver who learns from all of the available information. These\nmodels are in many ways simpler than previous alternatives, and allow the\nreceivers to learn from the atomic components of messages.", "AI": {"tldr": "Signaling game receivers usually fail to grasp compositional messages. This paper introduces two simpler models where receivers learn compositionally by focusing on atomic message parts or all available information.", "motivation": "Standard signaling game models fail to learn compositional information, meaning receivers don't interpret messages compositionally, and information from one component is lost when others are forgotten. This research aims to overcome this limitation.", "method": "The study constructs two novel signaling game models: one with a minimalist receiver learning from atomic messages, and another with a generalist receiver learning from all available information.", "result": "The proposed models allow receivers to learn from the atomic components of messages, offering a simpler and more effective approach compared to previous alternatives.", "conclusion": "This paper presents two new models for signaling games where receivers can learn compositional information, addressing a key limitation in existing models."}}
{"id": "2507.15008", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15008", "abs": "https://arxiv.org/abs/2507.15008", "authors": ["Jiasheng Xu", "Yewang Chen"], "title": "FastSmoothSAM: A Fast Smooth Method For Segment Anything Model", "comment": null, "summary": "Accurately identifying and representing object edges is a challenging task in\ncomputer vision and image processing. The Segment Anything Model (SAM) has\nsignificantly influenced the field of image segmentation, but suffers from high\nmemory consumption and long inference times, limiting its efficiency in\nreal-time applications. To address these limitations, Fast Segment Anything\n(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM\noften generates jagged edges that deviate from the true object shapes.\nTherefore, this paper introduces a novel refinement approach using B-Spline\ncurve fitting techniques to enhance the edge quality in FastSAM. Leveraging the\nrobust shape control and flexible geometric construction of B-Splines, a\nfour-stage refining process involving two rounds of curve fitting is employed\nto effectively smooth jagged edges. This approach significantly improves the\nvisual quality and analytical accuracy of object edges without compromising\ncritical geometric information. The proposed method improves the practical\nutility of FastSAM by improving segmentation accuracy while maintaining\nreal-time processing capabilities. This advancement unlocks greater potential\nfor FastSAM technology in various real-world scenarios, such as industrial\nautomation, medical imaging, and autonomous systems, where precise and\nefficient edge recognition is crucial.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cdB\u6837\u6761\u66f2\u7ebf\u62df\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316FastSAM\u6a21\u578b\u7684\u5206\u5272\u8fb9\u7f18\uff0c\u89e3\u51b3\u4e86\u5176\u952f\u9f7f\u72b6\u8fb9\u7f18\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u3002", "motivation": "FastSAM\u5728\u5b9e\u73b0\u5b9e\u65f6\u5206\u5272\u7684\u540c\u65f6\uff0c\u5b58\u5728\u8fb9\u7f18\u952f\u9f7f\u3001\u504f\u79bb\u771f\u5b9e\u7269\u4f53\u5f62\u72b6\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u9700\u8981\u7cbe\u786e\u8fb9\u7f18\u8bc6\u522b\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eB\u6837\u6761\u66f2\u7ebf\u62df\u5408\u7684\u56db\u9636\u6bb5\u6a21\u578b\u7ec6\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u8f6e\u66f2\u7ebf\u62df\u5408\u6765\u5e73\u6ed1FastSAM\u751f\u6210\u7684\u952f\u9f7f\u72b6\u8fb9\u7f18\uff0c\u4ee5\u63d0\u5347\u8fb9\u7f18\u8d28\u91cf\u548c\u51e0\u4f55\u7cbe\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u6539\u5584\u4e86FastSAM\u7684\u8fb9\u7f18\u8d28\u91cf\uff0c\u63d0\u9ad8\u4e86\u5206\u5272\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u65f6\u5904\u7406\u80fd\u529b\uff0c\u4e3aFastSAM\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f00\u8f9f\u4e86\u66f4\u5e7f\u9614\u7684\u524d\u666f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7B\u6837\u6761\u66f2\u7ebf\u62df\u5408\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86FastSAM\u751f\u6210\u7684\u8fb9\u7f18\u952f\u9f7f\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5272\u8fb9\u7f18\u7684\u8d28\u91cf\u548c\u7cbe\u5ea6\uff0c\u589e\u5f3a\u4e86FastSAM\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u3001\u533b\u5b66\u6210\u50cf\u548c\u81ea\u52a8\u9a7e\u9a76\u7b49\u9886\u57df\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.15082", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.15082", "abs": "https://arxiv.org/abs/2507.15082", "authors": ["Qian Qi"], "title": "Robust Control with Gradient Uncertainty", "comment": null, "summary": "We introduce a novel extension to robust control theory that explicitly\naddresses uncertainty in the value function's gradient, a form of uncertainty\nendemic to applications like reinforcement learning where value functions are\napproximated. We formulate a zero-sum dynamic game where an adversary perturbs\nboth system dynamics and the value function gradient, leading to a new, highly\nnonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs\nEquation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness\nby proving a comparison principle for its viscosity solutions under a uniform\nellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a\nkey insight: we prove that the classical quadratic value function assumption\nfails for any non-zero gradient uncertainty, fundamentally altering the problem\nstructure. A formal perturbation analysis characterizes the non-polynomial\ncorrection to the value function and the resulting nonlinearity of the optimal\ncontrol law, which we validate with numerical studies. Finally, we bridge\ntheory to practice by proposing a novel Gradient-Uncertainty-Robust\nActor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating\nits effectiveness in stabilizing training. This work provides a new direction\nfor robust control, holding significant implications for fields where function\napproximation is common, including reinforcement learning and computational\nfinance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u63a7\u5236\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684GURAC\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u4ef7\u503c\u51fd\u6570\u8fd1\u4f3c\u5e26\u6765\u7684\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u9c81\u68d2\u63a7\u5236\u7406\u8bba\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u63a7\u5236\u7406\u8bba\u6269\u5c55\uff0c\u5c06\u4ef7\u503c\u51fd\u6570\u7684\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165\u8003\u91cf\uff0c\u5e76\u63a8\u5bfc\u4e86\u5305\u542b\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u7684\u6c49\u5bc6\u5c14\u987f-\u96c5\u53ef\u6bd4-\u8d1d\u5c14\u66fc-\u827e\u8428\u514b\u65b9\u7a0b\uff08GU-HJBI\uff09\u3002\u901a\u8fc7\u8bc1\u660e\u7c98\u6027\u89e3\u7684\u6bd4\u8f83\u539f\u7406\u6765\u5efa\u7acb\u5176\u9002\u5b9a\u6027\uff0c\u5e76\u5bf9\u7ebf\u6027\u4e8c\u6b21\uff08LQ\uff09\u60c5\u51b5\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "\u5206\u6790\u4e86\u7ebf\u6027\u4e8c\u6b21\uff08LQ\uff09\u60c5\u51b5\uff0c\u53d1\u73b0\u4ef7\u503c\u51fd\u6570\u7684\u4e8c\u6b21\u5f62\u5f0f\u5047\u8bbe\u5728\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u975e\u96f6\u65f6\u5931\u6548\uff0c\u5e76\u63ed\u793a\u4e86\u6700\u4f18\u63a7\u5236\u5f8b\u7684\u975e\u591a\u9879\u5f0f\u4fee\u6b63\u548c\u975e\u7ebf\u6027\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u9c81\u68d2 Actor-Critic\uff08GURAC\uff09\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5728\u7a33\u5b9a\u8bad\u7ec3\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u9c81\u68d2\u63a7\u5236\u7684\u65b0\u65b9\u5411\uff0c\u5bf9\u5f3a\u5316\u5b66\u4e60\u548c\u8ba1\u7b97\u91d1\u878d\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.15707", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15707", "abs": "https://arxiv.org/abs/2507.15707", "authors": ["Seok Hwan Song", "Mohna Chakraborty", "Qi Li", "Wallapak Tavanapong"], "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?", "comment": null, "summary": "Large Language Models (LLMs) have been evaluated using diverse question\ntypes, e.g., multiple-choice, true/false, and short/long answers. This study\nanswers an unexplored question about the impact of different question types on\nLLM accuracy on reasoning tasks. We investigate the performance of five LLMs on\nthree different types of questions using quantitative and deductive reasoning\ntasks. The performance metrics include accuracy in the reasoning steps and\nchoosing the final answer. Key Findings: (1) Significant differences exist in\nLLM performance across different question types. (2) Reasoning accuracy does\nnot necessarily correlate with the final selection accuracy. (3) The number of\noptions and the choice of words, influence LLM performance.", "AI": {"tldr": "\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u5f71\u54cdLLM\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\uff1b\u63a8\u7406\u51c6\u786e\u6027\u4e0d\u7b49\u4e8e\u9009\u62e9\u51c6\u786e\u6027\uff1b\u9009\u9879\u6570\u91cf\u548c\u63aa\u8f9e\u5f88\u91cd\u8981\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u7528\u4e86\u5b9a\u91cf\u548c\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u63a8\u7406\u6b65\u9aa4\u7684\u51c6\u786e\u6027\u548c\u6700\u7ec8\u7b54\u6848\u7684\u9009\u62e9\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u95ee\u9898\u4f1a\u5bfc\u81f4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u5dee\u5f02\u3002\u6b64\u5916\uff0c\u63a8\u7406\u8fc7\u7a0b\u7684\u51c6\u786e\u6027\u4e0e\u6700\u7ec8\u9009\u62e9\u7684\u51c6\u786e\u6027\u4e4b\u95f4\u4e0d\u4e00\u5b9a\u5b58\u5728\u5173\u8054\u3002\u6a21\u578b\u6027\u80fd\u4e5f\u53d7\u5230\u9009\u9879\u6570\u91cf\u548c\u63aa\u8f9e\u9009\u62e9\u7684\u5f71\u54cd\u3002", "conclusion": "\u4e0d\u540c\u7c7b\u578b\u7684\u95ee\u9898\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6709\u663e\u8457\u5f71\u54cd\uff0c\u63a8\u7406\u8fc7\u7a0b\u7684\u51c6\u786e\u6027\u4e0e\u6700\u7ec8\u9009\u62e9\u7684\u51c6\u786e\u6027\u4e0d\u4e00\u5b9a\u76f8\u5173\uff0c\u9009\u9879\u7684\u6570\u91cf\u548c\u63aa\u8f9e\u4f1a\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.15028", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15028", "abs": "https://arxiv.org/abs/2507.15028", "authors": ["Yuanhan Zhang", "Yunice Chew", "Yuhao Dong", "Aria Leo", "Bo Hu", "Ziwei Liu"], "title": "Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding", "comment": "ICCV 2025; Project page: https://zhangyuanhan-ai.github.io/video-tt/", "summary": "Human intelligence requires correctness and robustness, with the former being\nfoundational for the latter. In video understanding, correctness ensures the\naccurate interpretation of visual content, and robustness maintains consistent\nperformance in challenging conditions. Despite advances in video large language\nmodels (video LLMs), existing benchmarks inadequately reflect the gap between\nthese models and human intelligence in maintaining correctness and robustness\nin video interpretation. We introduce the Video Thinking Test (Video-TT), to\nassess if video LLMs can interpret real-world videos as effectively as humans.\nVideo-TT reflects genuine gaps in understanding complex visual narratives, and\nevaluates robustness against natural adversarial questions. Video-TT comprises\n1,000 YouTube Shorts videos, each with one open-ended question and four\nadversarial questions that probe visual and narrative complexity. Our\nevaluation shows a significant gap between video LLMs and human performance.", "AI": {"tldr": "\u89c6\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u89c6\u9891\u5185\u5bb9\u65b9\u9762\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u590d\u6742\u53d9\u4e8b\u548c\u5e94\u5bf9\u5bf9\u6297\u6027\u95ee\u9898\u65f6\uff0c\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u672a\u80fd\u5145\u5206\u53cd\u6620\u5176\u5728\u4fdd\u6301\u89c6\u9891\u7406\u89e3\u7684\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4e0e\u4eba\u7c7b\u667a\u80fd\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u89c6\u9891\u601d\u7ef4\u6d4b\u8bd5\uff08Video-TT\uff09\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5305\u542b1000\u4e2aYouTube Shorts\u89c6\u9891\uff0c\u6bcf\u4e2a\u89c6\u9891\u90fd\u914d\u6709\u4e00\u4e2a\u5f00\u653e\u5f0f\u95ee\u9898\u548c\u56db\u4e2a\u65e8\u5728\u63a2\u67e5\u89c6\u89c9\u548c\u53d9\u4e8b\u590d\u6742\u6027\u7684\u5bf9\u6297\u6027\u95ee\u9898\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u89c6\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Video-TT\u4e0a\u7684\u8868\u73b0\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u76ee\u524d\u89c6\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u89c6\u9891\u5185\u5bb9\u65b9\u9762\u4e0e\u4eba\u7c7b\u667a\u80fd\u76f8\u6bd4\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u89c6\u89c9\u53d9\u4e8b\u548c\u5bf9\u6297\u6027\u95ee\u9898\u65b9\u9762\u3002"}}
{"id": "2507.15104", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15104", "abs": "https://arxiv.org/abs/2507.15104", "authors": ["Qiufeng Li", "Shu Hong", "Jian Gao", "Xuan Zhang", "Tian Lan", "Weidong Cao"], "title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI", "comment": null, "summary": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize\nanalog design automation through data-driven approaches. In particular,\nresearchers are increasingly fascinated by harnessing the power of generative\nAI to automate the discovery of novel analog circuit topologies. Unlocking the\nfull potential of generative AI in these data-driven discoveries requires\naccess to large and diverse datasets.Yet, there is a significant barrier in the\nanalog domain--Analog circuit design is inherently proprietary, involving not\nonly confidential circuit structures but also the underlying commercial\nsemiconductor processes. As a result, current generative AI research is largely\nconfined to individual researchers who construct small, narrowly focused\nprivate datasets. This fragmentation severely limits collaborative innovation\nand impedes progress across the research community. To address these\nchallenges, we propose AnalogFed. AnalogFed enables collaborative topology\ndiscovery across decentralized clients (e.g., individual researchers or\ninstitutions) without requiring the sharing of raw private data. To make this\nvision practical, we introduce a suite of techniques tailored to the unique\nchallenges of applying FedL in analog design--from generative model development\nand data heterogeneity handling to privacy-preserving strategies that ensure\nboth flexibility and security for circuit designers and semiconductor\nmanufacturers. Extensive experiments across varying client counts and dataset\nsizes demonstrate that AnalogFed achieves performance comparable to centralized\nbaselines--while maintaining strict data privacy. Specifically, the generative\nAI model within AnalogFed achieves state-of-the-art efficiency and scalability\nin the design of analog circuit topologies.", "AI": {"tldr": "AnalogFed facilitates collaborative discovery of analog circuit topologies using federated learning, overcoming data privacy issues and achieving results comparable to centralized methods.", "motivation": "Current generative AI research in analog circuit topology discovery is severely limited by the proprietary and confidential nature of analog circuit design data, leading to fragmented, small, and narrowly focused private datasets. This fragmentation hinders collaborative innovation and impedes progress across the research community.", "method": "AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. It introduces a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers.", "result": "Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines while maintaining strict data privacy. The generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.", "conclusion": "AnalogFed enables collaborative topology discovery across decentralized clients without requiring the sharing of raw private data, achieving performance comparable to centralized baselines while maintaining strict data privacy. The generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies."}}
{"id": "2507.15714", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15714", "abs": "https://arxiv.org/abs/2507.15714", "authors": ["Tian Li", "Yujian Sun", "Huizhi Liang"], "title": "Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning", "comment": null, "summary": "The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,\nintroduces an emotion recognition challenge spanning over 28 languages. This\ncompetition encourages researchers to explore more advanced approaches to\naddress the challenges posed by the diversity of emotional expressions and\nbackground variations. It features two tracks: multi-label classification\n(Track A) and emotion intensity prediction (Track B), covering six emotion\ncategories: anger, fear, joy, sadness, surprise, and disgust. In our work, we\nsystematically explore the benefits of two contrastive learning approaches:\nsample-based (Contrastive Reasoning Calibration) and generation-based (DPO,\nSimPO) contrastive learning. The sample-based contrastive approach trains the\nmodel by comparing two samples to generate more reliable predictions. The\ngeneration-based contrastive approach trains the model to differentiate between\ncorrect and incorrect generations, refining its prediction. All models are\nfine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A\nand 6th place in Track B for English, while ranking among the top-tier\nperforming systems for other languages.", "AI": {"tldr": "This paper investigates sample-based and generation-based contrastive learning methods using LLaMa3-Instruct-8B for the SemEval-2025 Task 11 emotion detection challenge, yielding strong results in English and other languages.", "motivation": "The paper addresses the SemEval-2025 Task 11, which aims to improve text-based emotion detection across 28 languages, tackling the challenges of diverse emotional expressions and background variations.", "method": "The study fine-tuned LLaMa3-Instruct-8B using two contrastive learning approaches: sample-based (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO). Sample-based contrastive learning involves comparing samples for reliable predictions, while generation-based contrastive learning trains the model to distinguish correct from incorrect generations.", "result": "The system achieved 9th place in Track A (multi-label classification) and 6th place in Track B (emotion intensity prediction) for English, and performed competitively in other languages.", "conclusion": "The authors explored contrastive learning approaches for emotion detection, achieving competitive results in the SemEval-2025 Task 11 across multiple languages."}}
{"id": "2507.15035", "categories": ["cs.CV", "cs.LG", "35Q92, 68U10", "I.4.5; J.2; J.3"], "pdf": "https://arxiv.org/pdf/2507.15035", "abs": "https://arxiv.org/abs/2507.15035", "authors": ["Zhijun Zeng", "Youjia Zheng", "Hao Hu", "Zeyuan Dong", "Yihang Zheng", "Xinliang Liu", "Jinzhuo Wang", "Zuoqiang Shi", "Linfeng Zhang", "Yubing Li", "He Sun"], "title": "OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography", "comment": null, "summary": "Accurate and efficient simulation of wave equations is crucial in\ncomputational wave imaging applications, such as ultrasound computed tomography\n(USCT), which reconstructs tissue material properties from observed scattered\nwaves. Traditional numerical solvers for wave equations are computationally\nintensive and often unstable, limiting their practical applications for\nquasi-real-time image reconstruction. Neural operators offer an innovative\napproach by accelerating PDE solving using neural networks; however, their\neffectiveness in realistic imaging is limited because existing datasets\noversimplify real-world complexity. In this paper, we present OpenBreastUS, a\nlarge-scale wave equation dataset designed to bridge the gap between\ntheoretical equations and practical imaging applications. OpenBreastUS includes\n8,000 anatomically realistic human breast phantoms and over 16 million\nfrequency-domain wave simulations using real USCT configurations. It enables a\ncomprehensive benchmarking of popular neural operators for both forward\nsimulation and inverse imaging tasks, allowing analysis of their performance,\nscalability, and generalization capabilities. By offering a realistic and\nextensive dataset, OpenBreastUS not only serves as a platform for developing\ninnovative neural PDE solvers but also facilitates their deployment in\nreal-world medical imaging problems. For the first time, we demonstrate\nefficient in vivo imaging of the human breast using neural operator solvers.", "AI": {"tldr": "OpenBreastUS \u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u795e\u7ecf\u7b97\u5b50\u5728\u4e73\u817a\u8d85\u58f0\u6210\u50cf\u4e2d\u7684\u5e94\u7528\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u8fc7\u4e8e\u7b80\u5316\u7684\u7f3a\u70b9\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u539f\u4f4d\u6210\u50cf\u3002", "motivation": "\u4f20\u7edf\u7684\u6570\u503c\u6c42\u89e3\u5668\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e0d\u7a33\u5b9a\uff0c\u9650\u5236\u4e86\u5176\u5728\u51c6\u5b9e\u65f6\u56fe\u50cf\u91cd\u5efa\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u7684\u795e\u7ecf\u7b97\u5b50\u6570\u636e\u96c6\u8fc7\u4e8e\u7b80\u5316\uff0c\u672a\u80fd\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa OpenBreastUS \u6570\u636e\u96c6\uff0c\u5305\u542b 8,000 \u4e2a\u89e3\u5256\u5b66\u4e0a\u771f\u5b9e\u7684\u4e73\u817a\u6a21\u578b\u548c\u8d85\u8fc7 1600 \u4e07\u4e2a\u9891\u57df\u6ce2\u6a21\u62df\uff0c\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u795e\u7ecf\u7b97\u5b50\u5728\u8d85\u58f0\u8ba1\u7b97\u673a\u65ad\u5c42\u626b\u63cf (USCT) \u4e2d\u7684\u6027\u80fd\u3002", "result": "OpenBreastUS \u6570\u636e\u96c6\u80fd\u591f\u5bf9\u6d41\u884c\u7684\u795e\u7ecf\u7b97\u5b50\u5728\u6b63\u5411\u6a21\u62df\u548c\u9006\u5411\u6210\u50cf\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u8fdb\u884c\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u4e86\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u6c42\u89e3\u5668\u5bf9\u4eba\u4f53\u4e73\u817a\u8fdb\u884c\u9ad8\u6548\u7684\u539f\u4f4d\u6210\u50cf\u3002", "conclusion": "OpenBreastUS \u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u65e8\u5728\u5f25\u5408\u7406\u8bba\u65b9\u7a0b\u4e0e\u5b9e\u9645\u6210\u50cf\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u4fc3\u8fdb\u795e\u7ecf PDE \u6c42\u89e3\u5668\u5728\u73b0\u5b9e\u4e16\u754c\u533b\u5b66\u6210\u50cf\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002\u8be5\u6570\u636e\u96c6\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5bf9\u6d41\u884c\u7684\u795e\u7ecf\u7b97\u5b50\u5728\u6b63\u5411\u6a21\u62df\u548c\u9006\u5411\u6210\u50cf\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u8fdb\u884c\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u7814\u7a76\u9996\u6b21\u5c55\u793a\u4e86\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u6c42\u89e3\u5668\u5bf9\u4eba\u4f53\u4e73\u817a\u8fdb\u884c\u9ad8\u6548\u7684\u539f\u4f4d\u6210\u50cf\u3002"}}
{"id": "2507.15112", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.15112", "abs": "https://arxiv.org/abs/2507.15112", "authors": ["Youssef Allouah", "Rachid Guerraoui", "Sanmi Koyejo"], "title": "Distributional Unlearning: Forgetting Distributions, Not Just Samples", "comment": null, "summary": "Machine unlearning seeks to remove unwanted information from trained models,\ninitially at the individual-sample level, but increasingly at the level of\nentire sub-populations. In many deployments, models must delete whole topical\ndomains to satisfy privacy, legal, or quality requirements, e.g., removing\nseveral users' posts under GDPR or copyrighted web content. Existing unlearning\ntools remain largely sample-oriented, and straightforward point deletion often\nleaves enough residual signal for downstream learners to recover the unwanted\ndomain. We introduce distributional unlearning, a data-centric, model-agnostic\nframework that asks: Given examples from an unwanted distribution and a\nretained distribution, what is the smallest set of points whose removal makes\nthe edited dataset far from the unwanted domain yet close to the retained one?\nUsing Kullback-Leibler divergence to quantify removal and preservation, we\nderive the exact Pareto frontier in the Gaussian case and prove that any model\nretrained on the edited data incurs log-loss shifts bounded by the divergence\nthresholds. We propose a simple distance-based selection rule satisfying these\nconstraints with a quadratic reduction in deletion budget compared to random\nremoval. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,\nand CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on\nretained performance.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u89e3\u79bb\u6846\u67b6\uff0c\u6709\u6548\u79fb\u9664\u6a21\u578b\u4e2d\u7684\u6574\u4e2a\u6570\u636e\u57df\uff0c\u76f8\u6bd4\u968f\u673a\u79fb\u9664\uff0c\u5220\u9664\u91cf\u66f4\u5c11\uff0c\u5bf9\u4fdd\u7559\u6570\u636e\u6027\u80fd\u5f71\u54cd\u5c0f\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u89e3\u79bb\u5de5\u5177\u4e3b\u8981\u4fa7\u91cd\u4e8e\u5355\u4e2a\u6837\u672c\u7684\u79fb\u9664\uff0c\u4f46\u5728\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u79fb\u9664\u6574\u4e2a\u5b50\u7fa4\u4f53\uff08\u4f8b\u5982\uff0c\u6839\u636eGDPR\u5220\u9664\u7528\u6237\u5e16\u5b50\u6216\u5220\u9664\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u7f51\u9875\u5185\u5bb9\uff09\u3002\u76f4\u63a5\u5220\u9664\u6837\u672c\u70b9\u5f80\u5f80\u4e0d\u8db3\u4ee5\u5b8c\u5168\u6d88\u9664\u6b8b\u7559\u4fe1\u53f7\uff0c\u4f7f\u5f97\u4e0b\u6e38\u5b66\u4e60\u8005\u80fd\u591f\u6062\u590d\u88ab\u79fb\u9664\u7684\u57df\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u6574\u4e2a\u6570\u636e\u57df\u7684\u79fb\u9664\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5206\u5e03\u89e3\u79bb\u201d\u7684\u6570\u636e\u4e2d\u5fc3\u3001\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u65e8\u5728\u79fb\u9664\u6574\u4e2a\u4e3b\u9898\u57df\u7684\u793a\u4f8b\u3002\u8be5\u6846\u67b6\u4f7f\u7528KL\u6563\u5ea6\u6765\u91cf\u5316\u79fb\u9664\u548c\u4fdd\u5b58\uff0c\u5e76\u5728\u9ad8\u65af\u60c5\u51b5\u4e0b\u63a8\u5bfc\u51fa\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u8bc1\u660e\u4e86\u5728\u7f16\u8f91\u6570\u636e\u96c6\u4e0a\u91cd\u65b0\u8bad\u7ec3\u7684\u4efb\u4f55\u6a21\u578b\u6240\u4ea7\u751f\u7684\u5bf9\u6570\u635f\u5931\u504f\u79fb\u90fd\u53d7\u9650\u4e8e\u6563\u5ea6\u9608\u503c\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u9009\u62e9\u89c4\u5219\uff0c\u8be5\u89c4\u5219\u6ee1\u8db3\u8fd9\u4e9b\u7ea6\u675f\uff0c\u5e76\u5c06\u5220\u9664\u9884\u7b97\u4e0e\u968f\u673a\u79fb\u9664\u76f8\u6bd4\u51cf\u5c11\u4e86\u5e73\u65b9\u500d\u3002", "result": "\u901a\u8fc7\u4f7f\u7528KL\u6563\u5ea6\u91cf\u5316\u79fb\u9664\u548c\u4fdd\u5b58\uff0c\u5e76\u5728\u9ad8\u65af\u60c5\u51b5\u4e0b\u63a8\u5bfc\u51fa\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u8bc1\u660e\u4e86\u4efb\u4f55\u5728\u7f16\u8f91\u6570\u636e\u4e0a\u91cd\u65b0\u8bad\u7ec3\u7684\u6a21\u578b\u90fd\u4f1a\u4ea7\u751f\u6709\u754c\u5bf9\u6570\u635f\u5931\u504f\u79fb\u3002\u63d0\u51fa\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u9009\u62e9\u89c4\u5219\u6bd4\u968f\u673a\u79fb\u9664\u6240\u9700\u7684\u5220\u9664\u9884\u7b97\u51cf\u5c11\u4e86\u5e73\u65b9\u500d\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u89e3\u79bb\u6846\u67b6\u5728\u5408\u6210\u9ad8\u65af\u3001Jigsaw\u6709\u6bd2\u8bc4\u8bba\u3001SMS\u5783\u573e\u90ae\u4ef6\u548cCIFAR-10\u7b49\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u968f\u673a\u79fb\u9664\uff0c\u5220\u9664\u91cf\u51cf\u5c11\u4e8615%-72%\uff0c\u540c\u65f6\u5bf9\u4fdd\u7559\u7684\u6570\u636e\u6027\u80fd\u5f71\u54cd\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002"}}
{"id": "2507.15715", "categories": ["cs.CL", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2507.15715", "abs": "https://arxiv.org/abs/2507.15715", "authors": ["Alina Hyk", "Kiera McCormick", "Mian Zhong", "Ioana Ciuc\u0103", "Sanjib Sharma", "John F Wu", "J. E. G. Peek", "Kartheik G. Iyer", "Ziang Xiao", "Anjalie Field"], "title": "From Queries to Criteria: Understanding How Astronomers Evaluate LLMs", "comment": "Accepted to the Conference on Language Modeling 2025 (COLM), 22\n  pages, 6 figures", "summary": "There is growing interest in leveraging LLMs to aid in astronomy and other\nscientific research, but benchmarks for LLM evaluation in general have not kept\npace with the increasingly diverse ways that real people evaluate and use these\nmodels. In this study, we seek to improve evaluation procedures by building an\nunderstanding of how users evaluate LLMs. We focus on a particular use case: an\nLLM-powered retrieval-augmented generation bot for engaging with astronomical\nliterature, which we deployed via Slack. Our inductive coding of 368 queries to\nthe bot over four weeks and our follow-up interviews with 11 astronomers reveal\nhow humans evaluated this system, including the types of questions asked and\nthe criteria for judging responses. We synthesize our findings into concrete\nrecommendations for building better benchmarks, which we then employ in\nconstructing a sample benchmark for evaluating LLMs for astronomy. Overall, our\nwork offers ways to improve LLM evaluation and ultimately usability,\nparticularly for use in scientific research.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u6539\u8fdbLLM\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5929\u6587\u5b66\u7b49\u79d1\u5b66\u7814\u7a76\u9886\u57df\u3002\u901a\u8fc7\u5206\u6790\u7528\u6237\u5982\u4f55\u4e0e\u5929\u6587\u5b66LLM\u8fdb\u884c\u4ea4\u4e92\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u6539\u8fdb\u8bc4\u4f30\u57fa\u51c6\u7684\u5efa\u8bae\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u793a\u4f8b\u57fa\u51c6\uff0c\u4ee5\u671f\u63d0\u9ad8LLM\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709LLM\u8bc4\u4f30\u57fa\u51c6\u672a\u80fd\u8ddf\u4e0a\u7528\u6237\u591a\u6837\u5316\u7684\u8bc4\u4f30\u548c\u4f7f\u7528\u65b9\u5f0f\uff0c\u5c24\u5176\u662f\u5728\u79d1\u5b66\u7814\u7a76\u9886\u57df\uff0cLLM\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u9700\u8981\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5bf9368\u4e2a\u67e5\u8be2\u8fdb\u884c\u5f52\u7eb3\u7f16\u7801\u548c\u5bf911\u4f4d\u5929\u6587\u5b66\u5bb6\u8fdb\u884c\u8bbf\u8c08\uff0c\u5206\u6790\u7528\u6237\u5982\u4f55\u8bc4\u4f30LLM\u5728\u5929\u6587\u5b66\u6587\u732e\u68c0\u7d22\u548c\u751f\u6210\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u7528\u6237\u8bc4\u4f30LLM\u7684\u6807\u51c6\u548c\u63d0\u95ee\u65b9\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u6784\u5efa\u66f4\u597d\u8bc4\u4f30\u57fa\u51c6\u7684\u5177\u4f53\u5efa\u8bae\uff0c\u540c\u65f6\u6784\u5efa\u4e86\u4e00\u4e2a\u5929\u6587\u5b66LLM\u8bc4\u4f30\u7684\u793a\u4f8b\u57fa\u51c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u6539\u8fdbLLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5929\u6587\u5b66\u7b49\u79d1\u5b66\u7814\u7a76\u9886\u57df\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u8bc4\u4f30LLM\u5728\u5929\u6587\u5b66\u9886\u57df\u5e94\u7528\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.15119", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15119", "abs": "https://arxiv.org/abs/2507.15119", "authors": ["Juntong Ni", "Shiyu Wang", "Zewen Liu", "Xiaoming Shi", "Xinyue Zhong", "Zhou Ye", "Wei Jin"], "title": "Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting", "comment": null, "summary": "Time series forecasting (TSF) is a central problem in time series analysis.\nHowever, as the number of channels in time series datasets scales to the\nthousands or more, a scenario we define as High-Dimensional Time Series\nForecasting (HDTSF), it introduces significant new modeling challenges that are\noften not the primary focus of traditional TSF research. HDTSF is challenging\nbecause the channel correlation often forms complex and hierarchical patterns.\nExisting TSF models either ignore these interactions or fail to scale as\ndimensionality grows. To address this issue, we propose U-Cast, a\nchannel-dependent forecasting architecture that learns latent hierarchical\nchannel structures with an innovative query-based attention. To disentangle\nhighly correlated channel representation, U-Cast adds a full-rank\nregularization during training. We also release Time-HD, a benchmark of large,\ndiverse, high-dimensional datasets. Our theory shows that exploiting\ncross-channel information lowers forecasting risk, and experiments on Time-HD\ndemonstrate that U-Cast surpasses strong baselines in both accuracy and\nefficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF\nresearch.", "AI": {"tldr": "U-Cast\u662f\u4e00\u79cd\u65b0\u7684\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u901a\u9053\u95f4\u7684\u5c42\u6b21\u7ed3\u6784\u6765\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5e76\u914d\u5957\u53d1\u5e03\u4e86Time-HD\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u5728\u5904\u7406\u6210\u5343\u4e0a\u4e07\u4e2a\u901a\u9053\u7684\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff08\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0cHDTSF\uff09\u65f6\u9762\u4e34\u4e25\u5cfb\u6311\u6218\uff0c\u56e0\u4e3a\u5b83\u4eec\u5f80\u5f80\u5ffd\u7565\u6216\u65e0\u6cd5\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u901a\u9053\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aU-Cast\u7684\u901a\u9053\u4f9d\u8d56\u6027\u9884\u6d4b\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5229\u7528\u521b\u65b0\u7684\u57fa\u4e8e\u67e5\u8be2\u7684\u6ce8\u610f\u529b\u6765\u5b66\u4e60\u6f5c\u5728\u7684\u5c42\u6b21\u5316\u901a\u9053\u7ed3\u6784\u3002\u4e3a\u4e86\u89e3\u5f00\u9ad8\u5ea6\u76f8\u5173\u7684\u901a\u9053\u8868\u793a\uff0cU-Cast\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u589e\u52a0\u4e86\u5168\u79e9\u6b63\u5219\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cU-Cast\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u5f3a\u6709\u529b\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "U-Cast\u53ca\u5176Time-HD\u6570\u636e\u96c6\u4e3a\u672a\u6765\u7684\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.15717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15717", "abs": "https://arxiv.org/abs/2507.15717", "authors": ["Sahana Srinivasan", "Xuguang Ai", "Thaddaeus Wai Soon Lo", "Aidan Gilson", "Minjie Zou", "Ke Zou", "Hyunjae Kim", "Mingjia Yang", "Krithi Pushpanathan", "Samantha Yew", "Wan Ting Loke", "Jocelyn Goh", "Yibing Chen", "Yiming Kong", "Emily Yuelei Fu", "Michelle Ongyong Hui", "Kristen Nwanyanwu", "Amisha Dave", "Kelvin Zhenghao Li", "Chen-Hsin Sun", "Mark Chia", "Gabriel Dawei Yang", "Wendy Meihua Wong", "David Ziyou Chen", "Dianbo Liu", "Maxwell Singer", "Fares Antaki", "Lucian V Del Priore", "Jost Jonas", "Ron Adelman", "Qingyu Chen", "Yih-Chung Tham"], "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning", "comment": null, "summary": "Current benchmarks evaluating large language models (LLMs) in ophthalmology\nare limited in scope and disproportionately prioritise accuracy. We introduce\nBELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive\nevaluation benchmark developed through multiple rounds of expert checking by 13\nophthalmologists. BELO assesses ophthalmology-related clinical accuracy and\nreasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we\ncurated ophthalmology-specific multiple-choice-questions (MCQs) from diverse\nmedical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset\nunderwent multiple rounds of expert checking. Duplicate and substandard\nquestions were systematically removed. Ten ophthalmologists refined the\nexplanations of each MCQ's correct answer. This was further adjudicated by\nthree senior ophthalmologists. To illustrate BELO's utility, we evaluated six\nLLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)\nusing accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,\nBARTScore, METEOR, and AlignScore). In a further evaluation involving human\nexperts, two ophthalmologists qualitatively reviewed 50 randomly selected\noutputs for accuracy, comprehensiveness, and completeness. BELO consists of 900\nhigh-quality, expert-reviewed questions aggregated from five sources: BCSC\n(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public\nleaderboard has been established to promote transparent evaluation and\nreporting. Importantly, the BELO dataset will remain a hold-out,\nevaluation-only benchmark to ensure fair and reproducible comparisons of future\nmodels.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aBELO\u7684\u773c\u79d1LLM\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b900\u4e2a\u4e13\u5bb6\u5ba1\u6838\u7684\u95ee\u9898\uff0c\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5bf9\u516d\u4e2aLLM\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u773c\u79d1\u9886\u57df\u7684\u57fa\u51c6\u5728\u8303\u56f4\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e76\u4e14\u8fc7\u5ea6\u4fa7\u91cd\u4e8e\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u66f4\u6807\u51c6\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cfLLMs\u5728\u773c\u79d1\u9886\u57df\u7684\u4e34\u5e8a\u51c6\u786e\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aBELO\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc7\u591a\u8f6e\u4e13\u5bb6\u8bc4\u5ba1\uff0813\u540d\u773c\u79d1\u533b\u751f\uff09\u6765\u786e\u4fdd\u5176\u5168\u9762\u6027\u548c\u51c6\u786e\u6027\u3002\u8be5\u57fa\u51c6\u5305\u542b\u6765\u81ea\u4e94\u4e2a\u533b\u5b66\u6570\u636e\u96c6\uff08BCSC, MedMCQA, MedQA, BioASQ, PubMedQA\uff09\u7684\u773c\u79d1\u7279\u5f02\u6027\u9009\u62e9\u9898\uff08MCQs\uff09\u3002\u7814\u7a76\u56e2\u961f\u4f7f\u7528\u5173\u952e\u8bcd\u5339\u914d\u548c\u5fae\u8c03\u7684PubMedBERT\u6a21\u578b\u6765\u7b5b\u9009\u548c\u6574\u7406\u95ee\u9898\uff0c\u5e76\u753110\u540d\u773c\u79d1\u533b\u751f\u5bf9\u6bcf\u4e2aMCQ\u7684\u6b63\u786e\u7b54\u6848\u8fdb\u884c\u4e86\u89e3\u91ca\uff0c\u6700\u7ec8\u75313\u540d\u8d44\u6df1\u773c\u79d1\u533b\u751f\u8fdb\u884c\u5ba1\u6838\u3002\u4e3a\u4e86\u5c55\u793aBELO\u7684\u6709\u6548\u6027\uff0c\u7814\u7a76\u4eba\u5458\u8bc4\u4f30\u4e86\u516d\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, Gemini 1.5 Pro\uff09\uff0c\u5e76\u4f7f\u7528\u4e86\u51c6\u786e\u7387\u3001\u5b8fF1\u4ee5\u53ca\u4e94\u79cd\u6587\u672c\u751f\u6210\u6307\u6807\uff08ROUGE-L, BERTScore, BARTScore, METEOR, AlignScore\uff09\u8fdb\u884c\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u8fd8\u6709\u4e00\u9879\u7531\u4eba\u7c7b\u4e13\u5bb6\u53c2\u4e0e\u7684\u5b9a\u6027\u8bc4\u4f30\uff0c\u4e24\u540d\u773c\u79d1\u533b\u751f\u5bf950\u4e2a\u968f\u673a\u9009\u62e9\u7684\u8f93\u51fa\u8fdb\u884c\u4e86\u51c6\u786e\u6027\u3001\u5168\u9762\u6027\u548c\u5b8c\u6574\u6027\u65b9\u9762\u7684\u5ba1\u67e5\u3002BELO\u6570\u636e\u96c6\u5305\u542b900\u4e2a\u9ad8\u8d28\u91cf\u3001\u4e13\u5bb6\u5ba1\u6838\u7684\u95ee\u9898\uff0c\u5e76\u8bbe\u7acb\u4e86\u516c\u5f00\u6392\u884c\u699c\u4ee5\u4fc3\u8fdb\u900f\u660e\u8bc4\u4f30\u3002", "result": "BELO\u57fa\u51c6\u5305\u542b\u4e86900\u4e2a\u9ad8\u8d28\u91cf\u3001\u7ecf\u8fc7\u4e13\u5bb6\u5ba1\u67e5\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u6765\u81ea\u4e94\u4e2a\u4e0d\u540c\u7684\u533b\u5b66\u6570\u636e\u96c6\u3002\u5728\u5bf9\u516d\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, Gemini 1.5 Pro\uff09\u7684\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528\u4e86\u51c6\u786e\u7387\u3001\u5b8fF1\u4ee5\u53caROUGE-L\u3001BERTScore\u3001BARTScore\u3001METEOR\u548cAlignScore\u7b49\u591a\u79cd\u6307\u6807\u3002\u6b64\u5916\uff0c\u4e00\u9879\u7531\u4e24\u4f4d\u773c\u79d1\u533b\u751f\u8fdb\u884c\u7684\u5b9a\u6027\u8bc4\u4f30\u4e5f\u5ba1\u67e5\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u51c6\u786e\u6027\u3001\u5168\u9762\u6027\u548c\u5b8c\u6574\u6027\u3002BELO\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u8fc7\u7a0b\u5f3a\u8c03\u4e86\u4e13\u5bb6\u8bc4\u5ba1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u516c\u5171\u6392\u884c\u699c\u4ee5\u9f13\u52b1\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002", "conclusion": "BELO\u662f\u4e00\u4e2a\u5168\u9762\u4e14\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u773c\u79d1\u9886\u57df\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u786e\u4fdd\u4e86\u95ee\u9898\u7684\u8d28\u91cf\u548c\u76f8\u5173\u6027\uff0c\u5e76\u5305\u542b\u51c6\u786e\u6027\u548c\u63a8\u7406\u80fd\u529b\u4e24\u65b9\u9762\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u540c\u65f6\u516c\u5f00\u7684\u6392\u884c\u699c\u4fc3\u8fdb\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2507.15037", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15037", "abs": "https://arxiv.org/abs/2507.15037", "authors": ["Zhaotong Yang", "Yuhui Li", "Shengfeng He", "Xinzhe Li", "Yangyang Xu", "Junyu Dong", "Yong Du"], "title": "OmniVTON: Training-Free Universal Virtual Try-On", "comment": "Accepted by ICCV2025", "summary": "Image-based Virtual Try-On (VTON) techniques rely on either supervised\nin-shop approaches, which ensure high fidelity but struggle with cross-domain\ngeneralization, or unsupervised in-the-wild methods, which improve adaptability\nbut remain constrained by data biases and limited universality. A unified,\ntraining-free solution that works across both scenarios remains an open\nchallenge. We propose OmniVTON, the first training-free universal VTON\nframework that decouples garment and pose conditioning to achieve both texture\nfidelity and pose consistency across diverse settings. To preserve garment\ndetails, we introduce a garment prior generation mechanism that aligns clothing\nwith the body, followed by continuous boundary stitching technique to achieve\nfine-grained texture retention. For precise pose alignment, we utilize DDIM\ninversion to capture structural cues while suppressing texture interference,\nensuring accurate body alignment independent of the original image textures. By\ndisentangling garment and pose constraints, OmniVTON eliminates the bias\ninherent in diffusion models when handling multiple conditions simultaneously.\nExperimental results demonstrate that OmniVTON achieves superior performance\nacross diverse datasets, garment types, and application scenarios. Notably, it\nis the first framework capable of multi-human VTON, enabling realistic garment\ntransfer across multiple individuals in a single scene. Code is available at\nhttps://github.com/Jerome-Young/OmniVTON", "AI": {"tldr": "OmniVTON\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u901a\u7528\u865a\u62df\u8bd5\u7a7f\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u670d\u88c5\u548c\u59ff\u6001\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u548c\u59ff\u6001\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u591a\u4eba\u7c7b\u865a\u62df\u8bd5\u7a7f\u65b9\u9762\u53d6\u5f97\u4e86\u7a81\u7834\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u50cf\u7684\u865a\u62df\u8bd5\u7a7f\uff08VTON\uff09\u6280\u672f\u5728\u8de8\u9886\u57df\u6cdb\u5316\u548c\u6570\u636e\u504f\u5dee\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u4e14\u7f3a\u4e4f\u80fd\u591f\u540c\u65f6\u5904\u7406\u8fd9\u4e24\u79cd\u60c5\u51b5\u7684\u7edf\u4e00\u7684\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "OmniVTON\u901a\u8fc7\u89e3\u8026\u670d\u88c5\u548c\u59ff\u6001\u7ea6\u675f\uff0c\u5f15\u5165\u4e86\u670d\u88c5\u5148\u9a8c\u751f\u6210\u673a\u5236\u548c\u8fde\u7eed\u8fb9\u754c\u7f1d\u5408\u6cd5\u6765\u4fdd\u7559\u670d\u88c5\u7ec6\u8282\uff0c\u5e76\u5229\u7528DDIM\u53cd\u6f14\u6765\u7cbe\u786e\u5bf9\u9f50\u59ff\u6001\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOmniVTON\u5728\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u3001\u670d\u88c5\u7c7b\u578b\u548c\u5e94\u7528\u573a\u666f\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u662f\u9996\u4e2a\u80fd\u591f\u5b9e\u73b0\u591a\u4eba\u7c7b\u865a\u62df\u8bd5\u7a7f\u7684\u6846\u67b6\u3002", "conclusion": "OmniVTON\u5728\u591a\u4eba\u7c7b\u865a\u62df\u8bd5\u7a7f\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u8fdb\u5c55\uff0c\u80fd\u591f\u5728\u540c\u4e00\u573a\u666f\u4e2d\u5b9e\u73b0\u591a\u4e2a\u4e2a\u4f53\u4e4b\u95f4\u7684\u903c\u771f\u670d\u88c5\u8f6c\u79fb\u3002"}}
{"id": "2507.15736", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15736", "abs": "https://arxiv.org/abs/2507.15736", "authors": ["Yuanhao Shen", "Daniel Xavier de Sousa", "Ricardo Mar\u00e7al", "Ali Asad", "Hongyu Guo", "Xiaodan Zhu"], "title": "Understanding Large Language Models' Ability on Interdisciplinary Research", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed their\nimpressive ability to perform multi-step, logic-driven reasoning across complex\ndomains, positioning them as powerful tools and collaborators in scientific\ndiscovery while challenging the long-held view that inspiration-driven ideation\nis uniquely human. However, the lack of a dedicated benchmark that evaluates\nLLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings\nposes a critical barrier to fully understanding their strengths and\nlimitations. To address this gap, we introduce IDRBench -- a pioneering\nbenchmark featuring an expert annotated dataset and a suite of tasks tailored\nto evaluate LLMs' capabilities in proposing valuable research ideas from\ndifferent scientific domains for interdisciplinary research. This benchmark\naims to provide a systematic framework for assessing LLM performance in\ncomplex, cross-domain scientific research. Our dataset consists of scientific\npublications sourced from the ArXiv platform covering six distinct disciplines,\nand is annotated by domain experts with diverse academic backgrounds. To ensure\nhigh-quality annotations, we emphasize clearly defined dimensions that\ncharacterize authentic interdisciplinary research. The design of evaluation\ntasks in IDRBench follows a progressive, real-world perspective, reflecting the\nnatural stages of interdisciplinary research development, including 1) IDR\nPaper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation.\nUsing IDRBench, we construct baselines across 10 LLMs and observe that despite\nfostering some level of IDR awareness, LLMs still struggle to produce quality\nIDR ideas. These findings could not only spark new research directions, but\nalso help to develop next-generation LLMs that excel in interdisciplinary\nresearch.", "AI": {"tldr": "LLM\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u7684\u521b\u610f\u751f\u6210\u80fd\u529b\u6709\u5f85\u63d0\u9ad8\uff0cIDRBench\u57fa\u51c6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u8de8\u5b66\u79d1\u7814\u7a76\uff08IDR\uff09\u4e2d\u53d1\u5c55\u60f3\u6cd5\u7684\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aIDRBench\u7684\u57fa\u51c6\uff0c\u5305\u542b\u4e13\u5bb6\u6ce8\u91ca\u7684\u6570\u636e\u96c6\u548c\u4e00\u7cfb\u5217\u8bc4\u4f30LLM\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u63d0\u51fa\u7814\u7a76\u521b\u610f\u7684\u4efb\u52a1\u3002\u8be5\u57fa\u51c6\u5305\u542b\u6765\u81ea\u516d\u4e2a\u4e0d\u540c\u5b66\u79d1\u7684ArXiv\u8bba\u6587\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\uff08IDR\u8bba\u6587\u8bc6\u522b\u3001IDR\u521b\u610f\u6574\u5408\u3001IDR\u521b\u610f\u63a8\u8350\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728IDRBench\u57fa\u51c6\u4e0a\uff0cLLM\u8868\u73b0\u51fa\u4e00\u5b9a\u7684IDR\u610f\u8bc6\uff0c\u4f46\u5728\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684IDR\u521b\u610f\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "LLM\u5728\u8de8\u5b66\u79d1\u7814\u7a76\uff08IDR\uff09\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u6709\u9650\uff0c\u4f46\u8be5\u57fa\u51c6\u53ef\u4ee5\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2507.15059", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15059", "abs": "https://arxiv.org/abs/2507.15059", "authors": ["Ran Zhang", "Xuanhua He", "Li Xueheng", "Ke Cao", "Liu Liu", "Wenbo Xu", "Fang Jiabin", "Yang Qize", "Jie Zhang"], "title": "Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling", "comment": null, "summary": "The field of pan-sharpening has recently seen a trend towards increasingly\nlarge and complex models, often trained on single, specific satellite datasets.\nThis approach, however, leads to high computational overhead and poor\ngeneralization on full resolution data, a paradigm we challenge in this paper.\nIn response to this issue, we propose PanTiny, a lightweight, single-step\npan-sharpening framework designed for both efficiency and robust performance.\nMore critically, we introduce multiple-in-one training paradigm, where a\nsingle, compact model is trained simultaneously on three distinct satellite\ndatasets (WV2, WV3, and GF2) with different resolution and spectral\ninformation. Our experiments show that this unified training strategy not only\nsimplifies deployment but also significantly boosts generalization on\nfull-resolution data. Further, we introduce a universally powerful composite\nloss function that elevates the performance of almost all of models for\npan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny\nmodel, benefiting from these innovations, achieves a superior\nperformance-to-efficiency balance, outperforming most larger, specialized\nmodels. Through extensive ablation studies, we validate that principled\nengineering in model design, training paradigms, and loss functions can surpass\nbrute-force scaling. Our work advocates for a community-wide shift towards\ncreating efficient, generalizable, and data-conscious models for\npan-sharpening. The code is available at\nhttps://github.com/Zirconium233/PanTiny .", "AI": {"tldr": "PanTiny\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6570\u636e\u96c6\u8054\u5408\u8bad\u7ec3\u548c\u521b\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7387\u548c\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u8d85\u5206\u8fa8\u7387\u6210\u50cf\u9886\u57df\u6a21\u578b\u89c4\u6a21\u5927\u3001\u8ba1\u7b97\u5f00\u9500\u9ad8\u4ee5\u53ca\u5728\u5168\u5206\u8fa8\u7387\u6570\u636e\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u51faPanTiny\u6846\u67b6\u4ee5\u5b9e\u73b0\u9ad8\u6548\u548c\u7a33\u5065\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPanTiny\u7684\u8f7b\u91cf\u7ea7\u3001\u5355\u6b65\u8d85\u5206\u8fa8\u7387\u6210\u50cf\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u591a\u5408\u4e00\u8bad\u7ec3\u8303\u5f0f\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u536b\u661f\u6570\u636e\u96c6\uff08WV2\u3001WV3\u548cGF2\uff09\u4e0a\u540c\u65f6\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u63d0\u9ad8\u8d85\u5206\u8fa8\u7387\u6210\u50cf\u7684\u6027\u80fd\u3002", "result": "PanTiny\u6a21\u578b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd-\u6548\u7387\u5e73\u8861\uff0c\u4f18\u4e8e\u5927\u591a\u6570\u66f4\u5927\u3001\u66f4\u4e13\u4e1a\u7684\u6a21\u578b\u3002\u591a\u5408\u4e00\u8bad\u7ec3\u7b56\u7565\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u5168\u5206\u8fa8\u7387\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u590d\u5408\u635f\u5931\u51fd\u6570\u80fd\u591f\u63d0\u5347\u51e0\u4e4e\u6240\u6709\u8d85\u5206\u8fa8\u7387\u6210\u50cf\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "PanTiny\u901a\u8fc7\u5176\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u3001\u591a\u5408\u4e00\u8bad\u7ec3\u8303\u5f0f\u548c\u5f3a\u5927\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u5e73\u8861\uff0c\u8d85\u8d8a\u4e86\u8bb8\u591a\u66f4\u5927\u3001\u66f4\u4e13\u4e1a\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u5021\u4e1a\u754c\u8f6c\u5411\u66f4\u9ad8\u6548\u3001\u53ef\u6cdb\u5316\u548c\u6570\u636e\u611f\u77e5\u6a21\u578b\u3002"}}
{"id": "2507.15742", "categories": ["cs.CL", "cs.IR", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.15742", "abs": "https://arxiv.org/abs/2507.15742", "authors": ["Paul Sheridan", "Zeyad Ahmed", "Aitazaz A. Farooque"], "title": "A Fisher's exact test justification of the TF-IDF term-weighting scheme", "comment": "23 pages, 4 tables", "summary": "Term frequency-inverse document frequency, or TF-IDF for short, is arguably\nthe most celebrated mathematical expression in the history of information\nretrieval. Conceived as a simple heuristic quantifying the extent to which a\ngiven term's occurrences are concentrated in any one given document out of\nmany, TF-IDF and its many variants are routinely used as term-weighting schemes\nin diverse text analysis applications. There is a growing body of scholarship\ndedicated to placing TF-IDF on a sound theoretical foundation. Building on that\ntradition, this paper justifies the use of TF-IDF to the statistics community\nby demonstrating how the famed expression can be understood from a significance\ntesting perspective. We show that the common TF-IDF variant TF-ICF is, under\nmild regularity conditions, closely related to the negative logarithm of the\n$p$-value from a one-tailed version of Fisher's exact test of statistical\nsignificance. As a corollary, we establish a connection between TF-IDF and the\nsaid negative log-transformed $p$-value under certain idealized assumptions. We\nfurther demonstrate, as a limiting case, that this same quantity converges to\nTF-IDF in the limit of an infinitely large document collection. The Fisher's\nexact test justification of TF-IDF equips the working statistician with a ready\nexplanation of the term-weighting scheme's long-established effectiveness.", "AI": {"tldr": "\u672c\u6587\u4ece\u663e\u8457\u6027\u68c0\u9a8c\u7684\u89d2\u5ea6\u4e3a TF-IDF \u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u8868\u660e TF-ICF \u4e0e\u8d39\u5e0c\u5c14\u7cbe\u786e\u68c0\u9a8c\u7684 $p$ \u503c\u7684\u8d1f\u5bf9\u6570\u76f8\u5173\uff0c\u5e76\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u6536\u655b\u4e8e TF-IDF\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u662f\u5c06\u4fe1\u606f\u68c0\u7d22\u9886\u57df\u7684 TF-IDF \u8fd9\u4e00\u91cd\u8981\u6982\u5ff5\uff0c\u4ece\u7edf\u8ba1\u5b66\u7684\u89d2\u5ea6\u8fdb\u884c\u7406\u8bba\u5316\uff0c\u5e76\u5c55\u793a\u5176\u4e0e\u663e\u8457\u6027\u68c0\u9a8c\u7684\u8054\u7cfb\u3002", "method": "\u901a\u8fc7\u5c55\u793a\u8457\u540d\u7684 TF-IDF \u8868\u8fbe\u5f0f\u5982\u4f55\u4ece\u663e\u8457\u6027\u68c0\u9a8c\u7684\u89d2\u5ea6\u6765\u7406\u89e3\uff0c\u4e3a TF-IDF \u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002\u5177\u4f53\u6765\u8bf4\uff0cTF-IDF \u7684\u4e00\u4e2a\u5e38\u89c1\u53d8\u4f53 TF-ICF \u4e0e\u8d39\u5e0c\u5c14\u7cbe\u786e\u68c0\u9a8c\u7684\u5355\u5c3e $p$ \u503c\u7684\u8d1f\u5bf9\u6570\u5bc6\u5207\u76f8\u5173\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cTF-ICF \u4e0e\u8d39\u5e0c\u5c14\u7cbe\u786e\u68c0\u9a8c\u7684 $p$ \u503c\u7684\u8d1f\u5bf9\u6570\u4e4b\u95f4\u5b58\u5728\u5bc6\u5207\u5173\u7cfb\uff0c\u5e76\u4e14\u5728\u6587\u6863\u96c6\u5408\u65e0\u9650\u5927\u7684\u6781\u9650\u60c5\u51b5\u4e0b\uff0c\u8be5\u91cf\u6536\u655b\u4e8e TF-IDF\u3002", "conclusion": "TF-IDF \u7684\u7edf\u8ba1\u5b66\u89e3\u91ca\u4e3a\u7edf\u8ba1\u5b66\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5bf9\u8be5\u672f\u8bed\u52a0\u6743\u65b9\u6848\u957f\u671f\u4ee5\u6765\u6709\u6548\u6027\u7684\u73b0\u6210\u89e3\u91ca\u3002"}}
{"id": "2507.15064", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15064", "abs": "https://arxiv.org/abs/2507.15064", "authors": ["Shuyuan Tu", "Zhen Xing", "Xintong Han", "Zhi-Qi Cheng", "Qi Dai", "Chong Luo", "Zuxuan Wu", "Yu-Gang Jiang"], "title": "StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation", "comment": "arXiv admin note: substantial text overlap with arXiv:2411.17697", "summary": "Current diffusion models for human image animation often struggle to maintain\nidentity (ID) consistency, especially when the reference image and driving\nvideo differ significantly in body size or position. We introduce\nStableAnimator++, the first ID-preserving video diffusion framework with\nlearnable pose alignment, capable of generating high-quality videos conditioned\non a reference image and a pose sequence without any post-processing. Building\nupon a video diffusion model, StableAnimator++ contains carefully designed\nmodules for both training and inference, striving for identity consistency. In\nparticular, StableAnimator++ first uses learnable layers to predict the\nsimilarity transformation matrices between the reference image and the driven\nposes via injecting guidance from Singular Value Decomposition (SVD). These\nmatrices align the driven poses with the reference image, mitigating\nmisalignment to a great extent. StableAnimator++ then computes image and face\nembeddings using off-the-shelf encoders, refining the face embeddings via a\nglobal content-aware Face Encoder. To further maintain ID, we introduce a\ndistribution-aware ID Adapter that counteracts interference caused by temporal\nlayers while preserving ID via distribution alignment. During the inference\nstage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization\nintegrated into the denoising process, guiding the diffusion trajectory for\nenhanced facial fidelity. Experiments on benchmarks show the effectiveness of\nStableAnimator++ both qualitatively and quantitatively.", "AI": {"tldr": "StableAnimator++ \u662f\u4e00\u4e2a\u521b\u65b0\u7684 ID \u4fdd\u6301\u89c6\u9891\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u59ff\u6001\u5bf9\u9f50\u3001SVD \u5f15\u5bfc\u7684\u5bf9\u9f50\u3001\u4eba\u8138\u5d4c\u5165\u7ec6\u5316\u3001\u5206\u5e03\u611f\u77e5 ID \u9002\u914d\u5668\u4ee5\u53ca HJB \u9a71\u52a8\u7684\u9762\u90e8\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u6a21\u578b\u5728\u4eba\u7269\u56fe\u50cf\u52a8\u753b\u4e2d ID \u4e00\u81f4\u6027\u7684\u96be\u9898\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u4e14\u65e0\u9700\u540e\u5904\u7406\u7684\u89c6\u9891\u3002", "motivation": "\u5f53\u524d\u7684\u751f\u6210\u6a21\u578b\u5728\u4fdd\u6301\u4eba\u7269\u56fe\u50cf\u52a8\u753b\u7684\u8eab\u4efd\uff08ID\uff09\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u53c2\u8003\u56fe\u50cf\u548c\u9a71\u52a8\u89c6\u9891\u5728\u8eab\u4f53\u5927\u5c0f\u6216\u4f4d\u7f6e\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u65f6\u3002", "method": "StableAnimator++ \u662f\u4e00\u4e2a\u5305\u542b\u53ef\u5b66\u4e60\u7684\u59ff\u6001\u5bf9\u9f50\u529f\u80fd\u7684 ID \u4fdd\u6301\u89c6\u9891\u6269\u6563\u6846\u67b6\u3002\u5b83\u9996\u5148\u4f7f\u7528\u53ef\u5b66\u4e60\u5c42\u901a\u8fc7\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u6ce8\u5165\u7684\u5f15\u5bfc\u6765\u9884\u6d4b\u53c2\u8003\u56fe\u50cf\u548c\u9a71\u52a8\u59ff\u6001\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u53d8\u6362\u77e9\u9635\uff0c\u4ee5\u5bf9\u9f50\u59ff\u6001\u3002\u7136\u540e\uff0c\u5b83\u4f7f\u7528\u73b0\u6210\u7684\u7f16\u7801\u5668\u8ba1\u7b97\u56fe\u50cf\u548c\u4eba\u8138\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u5185\u5bb9\u611f\u77e5\u4eba\u8138\u7f16\u7801\u5668\u6765\u7ec6\u5316\u4eba\u8138\u5d4c\u5165\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u4fdd\u6301\u8eab\u4efd\u8bc6\u522b\uff08ID\uff09\uff0c\u8be5\u6a21\u578b\u5f15\u5165\u4e86\u4e00\u4e2a\u5206\u5e03\u611f\u77e5 ID \u9002\u914d\u5668\u6765\u62b5\u6d88\u65f6\u95f4\u5c42\u9020\u6210\u7684\u5e72\u6270\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5bf9\u9f50\u6765\u4fdd\u6301 ID\u3002\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6c49\u5bc6\u5c14\u987f-\u96c5\u53ef\u6bd4-\u8d1d\u5c14\u66fc\uff08HJB\uff09\u7684\u4eba\u8138\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u53bb\u566a\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u589e\u5f3a\u9762\u90e8\u4fdd\u771f\u5ea6\u3002", "result": "StableAnimator++ \u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u89c6\u9891\uff0c\u8fd9\u4e9b\u89c6\u9891\u4ee5\u53c2\u8003\u56fe\u50cf\u548c\u59ff\u6001\u5e8f\u5217\u4e3a\u6761\u4ef6\uff0c\u5e76\u4e14\u65e0\u9700\u8fdb\u884c\u4efb\u4f55\u540e\u5904\u7406\u3002", "conclusion": "StableAnimator++ \u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u88ab\u8bc1\u660e\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u4e0a\u90fd\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2507.15752", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15752", "abs": "https://arxiv.org/abs/2507.15752", "authors": ["Ruizhe Zhu", "Hao Zhu", "Yaxuan Li", "Syang Zhou", "Shijing Cai", "Malgorzata Lazuka", "Elliott Ash"], "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue", "comment": "For our code and data, see\n  https://github.com/nerchio/Human_Chatbot-Generation", "summary": "Collecting human-chatbot dialogues typically demands substantial manual\neffort and is time-consuming, which limits and poses challenges for research on\nconversational AI. In this work, we propose DialogueForge - a framework for\ngenerating AI-simulated conversations in human-chatbot style. To initialize\neach generated conversation, DialogueForge uses seed prompts extracted from\nreal human-chatbot interactions. We test a variety of LLMs to simulate the\nhuman chatbot user, ranging from state-of-the-art proprietary models to\nsmall-scale open-source LLMs, and generate multi-turn dialogues tailored to\nspecific tasks. In addition, we explore fine-tuning techniques to enhance the\nability of smaller models to produce indistinguishable human-like dialogues. We\nevaluate the quality of the simulated conversations and compare different\nmodels using the UniEval and GTEval evaluation protocols. Our experiments show\nthat large proprietary models (e.g., GPT-4o) generally outperform others in\ngenerating more realistic dialogues, while smaller open-source models (e.g.,\nLlama, Mistral) offer promising performance with greater customization. We\ndemonstrate that the performance of smaller models can be significantly\nimproved by employing supervised fine-tuning techniques. Nevertheless,\nmaintaining coherent and natural long-form human-like dialogues remains a\ncommon challenge across all models.", "AI": {"tldr": "DialogueForge\u6846\u67b6\u901a\u8fc7\u4f7f\u7528\u79cd\u5b50\u63d0\u793a\u548c\u591a\u79cdLLM\u6765\u751f\u6210\u6a21\u62df\u4eba\u673a\u5bf9\u8bdd\uff0c\u5e76\u63a2\u7d22\u4e86\u5fae\u8c03\u6280\u672f\u4ee5\u63d0\u5347\u5c0f\u578b\u6a21\u578b\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u53d1\u73b0\u5927\u578b\u6a21\u578b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u5c0f\u578b\u6a21\u578b\u901a\u8fc7\u5fae\u8c03\u4e5f\u5f88\u6709\u6f5c\u529b\uff0c\u4e0d\u8fc7\u6240\u6709\u6a21\u578b\u5728\u4fdd\u6301\u957f\u671f\u5bf9\u8bdd\u7684\u8fde\u8d2f\u6027\u548c\u81ea\u7136\u6027\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002", "motivation": "\u6536\u96c6\u4eba\u7c7b\u4e0e\u804a\u5929\u673a\u5668\u4eba\u7684\u5bf9\u8bdd\u6570\u636e\u9700\u8981\u5927\u91cf\u7684\u4eba\u5de5\u548c\u65f6\u95f4\uff0c\u8fd9\u7ed9\u5bf9\u8bdd\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u7814\u7a76\u5e26\u6765\u4e86\u9650\u5236\u548c\u6311\u6218\u3002", "method": "DialogueForge\u6846\u67b6\u4f7f\u7528\u4ece\u771f\u5b9e\u4eba\u673a\u4ea4\u4e92\u4e2d\u63d0\u53d6\u7684\u79cd\u5b50\u63d0\u793a\u6765\u521d\u59cb\u5316\u751f\u6210\u7684\u5bf9\u8bdd\u3002\u6211\u4eec\u6d4b\u8bd5\u4e86\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u6a21\u62df\u4eba\u7c7b\u804a\u5929\u673a\u5668\u4eba\u7528\u6237\uff0c\u5305\u62ec\u6700\u5148\u8fdb\u7684\u4e13\u6709\u6a21\u578b\u548c\u5c0f\u578b\u5f00\u6e90LLM\uff0c\u5e76\u751f\u6210\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u591a\u8f6e\u5bf9\u8bdd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63a2\u7d22\u4e86\u5fae\u8c03\u6280\u672f\uff0c\u4ee5\u589e\u5f3a\u5c0f\u578b\u6a21\u578b\u751f\u6210\u96be\u4ee5\u533a\u5206\u7684\u4eba\u7c7b\u5bf9\u8bdd\u7684\u80fd\u529b\u3002\u6211\u4eec\u4f7f\u7528UniEval\u548cGTEval\u8bc4\u4f30\u534f\u8bae\u8bc4\u4f30\u4e86\u6a21\u62df\u5bf9\u8bdd\u7684\u8d28\u91cf\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u578b\u4e13\u6709\u6a21\u578b\uff08\u5982GPT-4o\uff09\u5728\u751f\u6210\u66f4\u771f\u5b9e\u7684\u5bf9\u8bdd\u65b9\u9762\u901a\u5e38\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u800c\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\uff08\u5982Llama\u3001Mistral\uff09\u5728\u63d0\u4f9b\u66f4\u5927\u5b9a\u5236\u6027\u7684\u540c\u65f6\uff0c\u4e5f\u8868\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u6027\u80fd\u3002\u901a\u8fc7\u91c7\u7528\u76d1\u7763\u5fae\u8c03\u6280\u672f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5c0f\u578b\u6a21\u578b\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u4fdd\u6301\u8fde\u8d2f\u548c\u81ea\u7136\u7684\u957f\u671f\u4eba\u7c7b\u5bf9\u8bdd\u4ecd\u7136\u662f\u6240\u6709\u6a21\u578b\u9762\u4e34\u7684\u5171\u540c\u6311\u6218\u3002", "conclusion": "\u6536\u96c6\u4eba\u7c7b\u4e0e\u804a\u5929\u673a\u5668\u4eba\u7684\u5bf9\u8bdd\u6570\u636e\u9700\u8981\u5927\u91cf\u7684\u4eba\u5de5\u548c\u65f6\u95f4\uff0c\u8fd9\u7ed9\u5bf9\u8bdd\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u7814\u7a76\u5e26\u6765\u4e86\u9650\u5236\u548c\u6311\u6218\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86DialogueForge\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u6a21\u62df\u4eba\u7c7b\u4e0e\u804a\u5929\u673a\u5668\u4eba\u98ce\u683c\u7684AI\u5bf9\u8bdd\u3002"}}
{"id": "2507.15085", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15085", "abs": "https://arxiv.org/abs/2507.15085", "authors": ["Peirong Zhang", "Haowei Xu", "Jiaxin Zhang", "Guitao Xu", "Xuhan Zheng", "Zhenhua Yang", "Junle Liu", "Yuyi Zhang", "Lianwen Jin"], "title": "Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR", "comment": null, "summary": "Text image is a unique and crucial information medium that integrates visual\naesthetics and linguistic semantics in modern e-society. Due to their subtlety\nand complexity, the generation of text images represents a challenging and\nevolving frontier in the image generation field. The recent surge of\nspecialized image generators (\\emph{e.g.}, Flux-series) and unified generative\nmodels (\\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a\nnatural question: can they master the intricacies of text image generation and\nediting? Motivated by this, we assess current state-of-the-art generative\nmodels' capabilities in terms of text image generation and editing. We\nincorporate various typical optical character recognition (OCR) tasks into our\nevaluation and broaden the concept of text-based generation tasks into OCR\ngenerative tasks. We select 33 representative tasks and categorize them into\nfive categories: document, handwritten text, scene text, artistic text, and\ncomplex \\& layout-rich text. For comprehensive evaluation, we examine six\nmodels across both closed-source and open-source domains, using tailored,\nhigh-quality image inputs and prompts. Through this evaluation, we draw crucial\nobservations and identify the weaknesses of current generative models for OCR\ntasks. We argue that photorealistic text image generation and editing should be\ninternalized as foundational skills into general-domain generative models,\nrather than being delegated to specialized solutions, and we hope this\nempirical analysis can provide valuable insights for the community to achieve\nthis goal. This evaluation is online and will be continuously updated at our\nGitHub repository.", "AI": {"tldr": "\u8bc4\u4f30\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u5728\u6587\u672c\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728OCR\u4efb\u52a1\u4e0a\uff0c\u53d1\u73b0\u5b83\u4eec\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u547c\u5401\u5c06\u8fd9\u4e9b\u80fd\u529b\u5185\u5efa\u5230\u901a\u7528\u6a21\u578b\u4e2d\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u751f\u6210\u6a21\u578b\uff08\u5982Flux\u7cfb\u5217\u548cGPT-4o\uff09\u5728\u56fe\u50cf\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5f15\u53d1\u4e86\u5b83\u4eec\u662f\u5426\u80fd\u638c\u63e1\u6587\u672c\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u590d\u6742\u6027\u7684\u7591\u95ee\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u5728\u6587\u672c\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86\u5178\u578b\u7684\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u4efb\u52a1\u3002\u8bc4\u4f30\u4e8633\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\uff0c\u6db5\u76d6\u6587\u6863\u3001\u624b\u5199\u6587\u672c\u3001\u573a\u666f\u6587\u672c\u3001\u827a\u672f\u6587\u672c\u548c\u590d\u6742/\u5bcc\u6587\u672c\u5e03\u5c40\u4e94\u7c7b\u3002\u8bc4\u4f30\u4e866\u4e2a\u6a21\u578b\uff08\u95ed\u6e90\u548c\u5f00\u6e90\uff09\uff0c\u4f7f\u7528\u4e86\u5b9a\u5236\u7684\u9ad8\u8d28\u91cf\u56fe\u50cf\u8f93\u5165\u548c\u63d0\u793a\u3002", "result": "\u8bc6\u522b\u51fa\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728OCR\u4efb\u52a1\u65b9\u9762\u7684\u5f31\u70b9\uff0c\u5e76\u4e3a\u793e\u533a\u63d0\u4f9b\u5b9e\u73b0\u7167\u7247\u7ea7\u6587\u672c\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u80fd\u529b\u5185\u5efa\u5316\u7684\u5b9d\u8d35\u89c1\u89e3\u3002", "conclusion": "\u5e94\u5c06\u7167\u7247\u7ea7\u6587\u672c\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u4f5c\u4e3a\u901a\u7528\u751f\u6210\u6a21\u578b\u7684\u5185\u5efa\u57fa\u7840\u6280\u80fd\uff0c\u800c\u975e\u4ea4\u7ed9\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15162", "abs": "https://arxiv.org/abs/2507.15162", "authors": ["Firdaus Ahmed Choudhury", "Ethan Leicht", "Jude Ethan Bislig", "Hangzhi Guo", "Amulya Yadav"], "title": "Designing User-Centric Metrics for Evaluation of Counterfactual Explanations", "comment": null, "summary": "Machine learning-based decision models are increasingly being used to make\ndecisions that significantly impact people's lives, but their opaque nature\nleaves end users without a clear understanding of why a decision was made.\nCounterfactual Explanations (CFEs) have grown in popularity as a means of\noffering actionable guidance by identifying the minimum changes in feature\nvalues required to flip a model's prediction to something more desirable.\nUnfortunately, most prior research in CFEs relies on artificial evaluation\nmetrics, such as proximity, which may overlook end-user preferences and\nconstraints, e.g., the user's perception of effort needed to make certain\nfeature changes may differ from that of the model designer. To address this\nresearch gap, this paper makes three novel contributions. First, we conduct a\npilot study with 20 crowd-workers on Amazon MTurk to experimentally validate\nthe alignment of existing CF evaluation metrics with real-world user\npreferences. Results show that user-preferred CFEs matched those based on\nproximity in only 63.81% of cases, highlighting the limited applicability of\nthese metrics in real-world settings. Second, inspired by the need to design a\nuser-informed evaluation metric for CFEs, we conduct a more detailed two-day\nuser study with 41 participants facing realistic credit application scenarios\nto find experimental support for or against three intuitive hypotheses that may\nexplain how end users evaluate CFEs. Third, based on the findings of this\nsecond study, we propose the AWP model, a novel user-centric, two-stage model\nthat describes one possible mechanism by which users evaluate and select CFEs.\nOur results show that AWP predicts user-preferred CFEs with 84.37% accuracy.\nOur study provides the first human-centered validation for personalized cost\nmodels in CFE generation and highlights the need for adaptive, user-centered\nevaluation metrics.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u7528\u4e8e\u8bc4\u4f30\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFEs\uff09\u7684\u4eba\u5de5\u8bc4\u4f30\u6307\u6807\uff08\u5982\u90bb\u8fd1\u6027\uff09\u4e0e\u7528\u6237\u7684\u771f\u5b9e\u504f\u597d\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAWP\u7684\u65b0\u578b\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u7528\u6237\u504f\u597d\u7684CFEs\uff0c\u51c6\u786e\u7387\u8fbe84.37%\uff0c\u5f3a\u8c03\u4e86\u5728CFE\u751f\u6210\u4e2d\u91c7\u7528\u4e2a\u6027\u5316\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u51b3\u7b56\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u505a\u51fa\u5bf9\u4eba\u4eec\u751f\u6d3b\u6709\u91cd\u5927\u5f71\u54cd\u7684\u51b3\u7b56\uff0c\u4f46\u5176\u4e0d\u900f\u660e\u7684\u6027\u8d28\u4f7f\u5f97\u6700\u7ec8\u7528\u6237\u65e0\u6cd5\u6e05\u695a\u5730\u4e86\u89e3\u51b3\u7b56\u7684\u539f\u56e0\u3002\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFEs\uff09\u4f5c\u4e3a\u4e00\u79cd\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6027\u6307\u5bfc\u7684\u624b\u6bb5\u8d8a\u6765\u8d8a\u53d7\u6b22\u8fce\uff0c\u5b83\u901a\u8fc7\u8bc6\u522b\u7279\u5f81\u503c\u4e2d\u80fd\u5c06\u6a21\u578b\u9884\u6d4b\u6539\u53d8\u4e3a\u66f4\u7406\u60f3\u7ed3\u679c\u7684\u6700\u5c0f\u53d8\u52a8\u6765\u5b9e\u73b0\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7814\u7a76\u90fd\u4f9d\u8d56\u4e8e\u50cf\u90bb\u8fd1\u6027\u8fd9\u6837\u7684 \uac83\uc785\ub2c8\ub2e4\u3002\u4eba\u5de5\u8bc4\u4f30\u6307\u6807\uff0c\u8fd9\u53ef\u80fd\u5ffd\u7565\u6700\u7ec8\u7528\u6237\u7684\u504f\u597d\u548c\u7ea6\u675f\uff0c\u4f8b\u5982\uff0c\u7528\u6237\u8ba4\u4e3a\u8fdb\u884c\u67d0\u4e9b\u7279\u5f81\u66f4\u6539\u6240\u9700\u7684\u52aa\u529b\u7a0b\u5ea6\u53ef\u80fd\u4e0e\u6a21\u578b\u8bbe\u8ba1\u8005\u7684\u770b\u6cd5\u4e0d\u540c\u3002", "method": "\u672c\u7814\u7a76\u9996\u5148\u8fdb\u884c\u4e86\u8bd5\u70b9\u7814\u7a76\uff0c\u670920\u540d\u6765\u81eaAmazon MTurk\u7684\u4f17\u5305\u5de5\u4f5c\u8005\u53c2\u4e0e\uff0c\u65e8\u5728\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u8bc4\u4f30\u6307\u6807\u4e0e\u771f\u5b9e\u7528\u6237\u504f\u597d\u7684\u4e00\u81f4\u6027\u3002\u968f\u540e\uff0c\u4e3a\u4e86\u8bbe\u8ba1\u7528\u6237\u77e5\u60c5\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u8bc4\u4f30\u6307\u6807\uff0c\u53c8\u8fdb\u884c\u4e86\u66f4\u8be6\u7ec6\u7684\u4e3a\u671f\u4e24\u5929\u7684\u7528\u6237\u7814\u7a76\uff0c\u670941\u540d\u53c2\u4e0e\u8005\u9762\u4e34\u7740\u771f\u5b9e\u7684\u4fe1\u8d37\u7533\u8bf7\u573a\u666f\uff0c\u4ee5\u5bfb\u627e\u652f\u6301\u6216\u53cd\u9a73\u4e09\u79cd\u53ef\u80fd\u89e3\u91ca\u7528\u6237\u5982\u4f55\u8bc4\u4f30\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u76f4\u89c2\u5047\u8bbe\u7684\u5b9e\u9a8c\u8bc1\u636e\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u7b2c\u4e8c\u6b21\u7814\u7a76\u7684\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4e24\u9636\u6bb5\u6a21\u578bAWP\uff0c\u8be5\u6a21\u578b\u63cf\u8ff0\u4e86\u7528\u6237\u8bc4\u4f30\u548c\u9009\u62e9\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u4e00\u79cd\u53ef\u80fd\u673a\u5236\u3002", "result": "\u8bd5\u70b9\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7528\u6237\u559c\u6b22\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u572863.81%\u7684\u60c5\u51b5\u4e0b\u624d\u4e0e\u57fa\u4e8e\u90bb\u8fd1\u6027\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u76f8\u5339\u914d\uff0c\u8fd9\u51f8\u663e\u4e86\u8fd9\u4e9b\u6307\u6807\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5e94\u7528\u5c40\u9650\u6027\u3002AWP\u6a21\u578b\u80fd\u591f\u4ee584.37%\u7684\u51c6\u786e\u7387\u9884\u6d4b\u7528\u6237\u559c\u6b22\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u901a\u8fc7\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9a8c\u8bc1\u4e3a\u4e2a\u6027\u5316\u6210\u672c\u6a21\u578b\u5728\u53cd\u4e8b\u5b9e\u89e3\u91ca\u751f\u6210\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u5e76\u5f3a\u8c03\u4e86\u5bf9\u9002\u5e94\u6027\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u6307\u6807\u7684\u9700\u6c42\u3002"}}
{"id": "2507.15759", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15759", "abs": "https://arxiv.org/abs/2507.15759", "authors": ["Lyumanshan Ye", "Xiaojie Cai", "Xinkai Wang", "Junfei Wang", "Xiangkun Hu", "Jiadi Su", "Yang Nan", "Sihan Wang", "Bohan Zhang", "Xiaoze Fan", "Jinbin Luo", "Yuxiang Zheng", "Tianze Xu", "Dayuan Fu", "Yunze Wu", "Pengrui Lu", "Zengzhi Wang", "Yiwei Qin", "Zhen Huang", "Yan Ma", "Zhulin Hu", "Haoyang Zou", "Tiantian Mi", "Yixin Ye", "Ethan Chern", "Pengfei Liu"], "title": "Interaction as Intelligence: Deep Research With Human-AI Partnership", "comment": "30 pages, 10 figures", "summary": "This paper introduces \"Interaction as Intelligence\" research series,\npresenting a reconceptualization of human-AI relationships in deep research\ntasks. Traditional approaches treat interaction merely as an interface for\naccessing AI capabilities-a conduit between human intent and machine output. We\npropose that interaction itself constitutes a fundamental dimension of\nintelligence. As AI systems engage in extended thinking processes for research\ntasks, meaningful interaction transitions from an optional enhancement to an\nessential component of effective intelligence. Current deep research systems\nadopt an \"input-wait-output\" paradigm where users initiate queries and receive\nresults after black-box processing. This approach leads to error cascade\neffects, inflexible research boundaries that prevent question refinement during\ninvestigation, and missed opportunities for expertise integration. To address\nthese limitations, we introduce Deep Cognition, a system that transforms the\nhuman role from giving instructions to cognitive oversight-a mode of engagement\nwhere humans guide AI thinking processes through strategic intervention at\ncritical junctures. Deep cognition implements three key innovations:\n(1)Transparent, controllable, and interruptible interaction that reveals AI\nreasoning and enables intervention at any point; (2)Fine-grained bidirectional\ndialogue; and (3)Shared cognitive context where the system observes and adapts\nto user behaviors without explicit instruction. User evaluation demonstrates\nthat this cognitive oversight paradigm outperforms the strongest baseline\nacross six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%),\nReal-Time Intervention(+18.5%), Ease of Collaboration(+27.7%),\nResults-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on\nchallenging research problems show 31.8% to 50.0% points of improvements over\ndeep research systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u201c\u4ea4\u4e92\u5373\u667a\u80fd\u201d\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u201c\u6df1\u5ea6\u8ba4\u77e5\u201d\u7cfb\u7edf\u5b9e\u73b0\u7528\u6237\u5bf9AI\u601d\u8003\u8fc7\u7a0b\u7684\u201c\u8ba4\u77e5\u76d1\u7763\u201d\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u900f\u660e\u3001\u53ef\u63a7\u3001\u53ef\u4e2d\u65ad\u7684\u4ea4\u4e92\u5f15\u5bfcAI\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u9879\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6df1\u5ea6\u7814\u7a76\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u4eba\u673a\u4ea4\u4e92\u6a21\u5f0f\u5c06\u4ea4\u4e92\u89c6\u4e3a\u7b80\u5355\u7684\u63a5\u53e3\uff0c\u5ffd\u7565\u4e86\u5176\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u4f5c\u4e3a\u667a\u80fd\u7ec4\u6210\u90e8\u5206\u7684\u5173\u952e\u4f5c\u7528\u3002\u8fd9\u79cd\u6a21\u5f0f\u5bfc\u81f4\u4e86\u9519\u8bef\u7d2f\u79ef\u3001\u7814\u7a76\u8fb9\u754c\u50f5\u5316\u4ee5\u53ca\u4e13\u5bb6\u77e5\u8bc6\u6574\u5408\u7684\u7f3a\u5931\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5c06\u4ea4\u4e92\u63d0\u5347\u81f3\u201c\u8ba4\u77e5\u76d1\u7763\u201d\u7684\u5c42\u9762\uff0c\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6df1\u5ea6\u8ba4\u77e5\u201d\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86\u900f\u660e\u3001\u53ef\u63a7\u3001\u53ef\u4e2d\u65ad\u7684\u4ea4\u4e92\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u7684\u53cc\u5411\u5bf9\u8bdd\uff0c\u5e76\u5efa\u7acb\u4e86\u5171\u4eab\u8ba4\u77e5\u80cc\u666f\uff0c\u4f7fAI\u80fd\u591f\u9002\u5e94\u7528\u6237\u884c\u4e3a\u3002\u7814\u7a76\u901a\u8fc7\u7528\u6237\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u8be5\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "result": "\u7528\u6237\u8bc4\u4f30\u663e\u793a\uff0c\u201c\u8ba4\u77e5\u76d1\u7763\u201d\u8303\u5f0f\u5728\u516d\u9879\u5173\u952e\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff1a\u900f\u660e\u5ea6\uff08+20.0%\uff09\u3001\u7ec6\u7c92\u5ea6\u4ea4\u4e92\uff08+29.2%\uff09\u3001\u5b9e\u65f6\u5e72\u9884\uff08+18.5%\uff09\u3001\u534f\u4f5c\u6613\u7528\u6027\uff08+27.7%\uff09\u3001\u7ed3\u679c\u4ef7\u503c\uff08+8.8%\uff09\u548c\u53ef\u4e2d\u65ad\u6027\uff08+20.7%\uff09\u3002\u5728\u590d\u6742\u7684\u6df1\u5ea6\u7814\u7a76\u95ee\u9898\u4e0a\uff0c\u76f8\u6bd4\u4e8e\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u6027\u80fd\u63d0\u5347\u4e8631.8%\u81f350.0%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u201c\u4ea4\u4e92\u5373\u667a\u80fd\u201d\u7684\u7814\u7a76\u8303\u5f0f\uff0c\u5f3a\u8c03\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\uff0c\u4eba\u4e0eAI\u7684\u5173\u7cfb\u4e0d\u5e94\u4ec5\u4ec5\u662f\u63a5\u53e3\uff0c\u800c\u5e94\u662f\u6784\u6210\u667a\u80fd\u7684\u57fa\u672c\u7ef4\u5ea6\u3002\u901a\u8fc7\u5f15\u5165\u201c\u8ba4\u77e5\u76d1\u7763\u201d\u6a21\u5f0f\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9AI\u7684\u601d\u8003\u8fc7\u7a0b\u8fdb\u884c\u900f\u660e\u3001\u53ef\u63a7\u3001\u53ef\u4e2d\u65ad\u7684\u5f15\u5bfc\u548c\u5e72\u9884\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u53cc\u5411\u5bf9\u8bdd\u548c\u5171\u4eab\u8ba4\u77e5\u80cc\u666f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u8303\u5f0f\u5728\u900f\u660e\u5ea6\u3001\u4ea4\u4e92\u7cbe\u7ec6\u5ea6\u3001\u5b9e\u65f6\u5e72\u9884\u3001\u534f\u4f5c\u6613\u7528\u6027\u3001\u7ed3\u679c\u4ef7\u503c\u548c\u53ef\u4e2d\u65ad\u6027\u7b49\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2507.15773", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15773", "abs": "https://arxiv.org/abs/2507.15773", "authors": ["Andrei-Valentin Tanase", "Elena Pelican"], "title": "Supernova: Achieving More with Less in Transformer Architectures", "comment": null, "summary": "We present Supernova, a 650M-parameter decoder-only transformer that\ndemonstrates how careful architectural design and tokenization innovation can\nachieve the performance of larger models while maintaining computational\nefficiency. Our architecture combines Rotary Positional Embeddings (RoPE),\nGrouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for\ncomputational efficiency, and SwiGLU activation functions. A critical\ninnovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which\nachieves state-of-the-art compression performance. Through detailed analysis,\nwe show that Supernova achieves 90% of the performance of 1B-parameter models\nwhile using 53% fewer parameters and requiring only 100B training tokens--an\norder of magnitude less than competing models. Our findings challenge the\nprevailing scaling paradigm, demonstrating that architectural efficiency and\ntokenization quality can compensate for reduced parameter counts.", "AI": {"tldr": "Supernova\u662f\u4e00\u4e2a650M\u53c2\u6570\u7684Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u5316\u7684\u67b6\u6784\u548c\u5206\u8bcd\u5668\uff0c\u5b9e\u73b0\u4e86\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u53c2\u6570\u91cf\u548c\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22\u901a\u8fc7\u7cbe\u7ec6\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u521b\u65b0\u7684\u5206\u8bcd\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e0e\u66f4\u5927\u53c2\u6570\u91cf\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\u3002", "method": "Supernova\u6a21\u578b\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08RoPE\uff09\u3001\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\uff08GQA\uff09\u548c3:1\u7684\u538b\u7f29\u6bd4\u3001RMSNorm\u4ee5\u53caSwiGLU\u6fc0\u6d3b\u51fd\u6570\u3002\u5173\u952e\u521b\u65b0\u5728\u4e8e\u4f7f\u7528\u4e86\u81ea\u5b9a\u4e49\u7684128,000\u8bcd\u6c47\u91cf\u7684\u5b57\u8282\u7ea7BPE\u5206\u8bcd\u5668\u3002", "result": "Supernova\u6a21\u578b\u5b9e\u73b0\u4e861B\u53c2\u6570\u6a21\u578b90%\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53c2\u6570\u91cf\u51cf\u5c11\u4e8653%\uff0c\u5e76\u4e14\u4ec5\u9700100B\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u6bd4\u73b0\u6709\u6a21\u578b\u6240\u9700\u7684\u8bad\u7ec3\u6570\u636e\u91cf\u51cf\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "Supernova\u7684\u53d1\u73b0\u6311\u6218\u4e86\u73b0\u6709\u7684\u6a21\u578b\u6269\u5c55\u8303\u5f0f\uff0c\u8bc1\u660e\u4e86\u67b6\u6784\u6548\u7387\u548c\u5206\u8bcd\u8d28\u91cf\u53ef\u4ee5\u5f25\u8865\u53c2\u6570\u6570\u91cf\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.15094", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15094", "abs": "https://arxiv.org/abs/2507.15094", "authors": ["Mengya Xu", "Rulin Zhou", "An Wang", "Chaoyang Lyu", "Zhen Li", "Ning Zhong", "Hongliang Ren"], "title": "BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking", "comment": "27 pages, 14 figures", "summary": "Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses\nsignificant risks, demanding precise, real-time localization and continuous\nmonitoring of the bleeding source for effective hemostatic intervention. In\nparticular, endoscopists have to repeatedly flush to clear blood, allowing only\nmilliseconds to identify bleeding sources, an inefficient process that prolongs\noperations and elevates patient risks. However, current Artificial Intelligence\n(AI) methods primarily focus on bleeding region segmentation, overlooking the\ncritical need for accurate bleeding source detection and temporal tracking in\nthe challenging ESD environment, which is marked by frequent visual\nobstructions and dynamic scene changes. This gap is widened by the lack of\nspecialized datasets, hindering the development of robust AI-assisted guidance\nsystems. To address these challenges, we introduce BleedOrigin-Bench, the first\ncomprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated\nbleeding sources across 106,222 frames from 44 procedures, supplemented with\n39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6\nchallenging clinical scenarios. We also present BleedOrigin-Net, a novel\ndual-stage detection-tracking framework for the bleeding source localization in\nESD procedures, addressing the complete workflow from bleeding onset detection\nto continuous spatial tracking. We compare with widely-used object detection\nmodels (YOLOv11/v12), multimodal large language models, and point tracking\nmethods. Extensive evaluation demonstrates state-of-the-art performance,\nachieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset\ndetection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source\ndetection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86BleedOrigin-Bench\u6570\u636e\u96c6\u548cBleedOrigin-Net\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3ESD\u672f\u4e2d\u51fa\u8840\u6e90\u7684\u68c0\u6d4b\u548c\u8ddf\u8e2a\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6210\u679c\u3002", "motivation": "\u5185\u7aa5\u955c\u7c98\u819c\u4e0b\u5265\u79bb\u672f\uff08ESD\uff09\u4e2d\u7684\u672f\u4e2d\u51fa\u8840\u7ed9\u60a3\u8005\u5e26\u6765\u663e\u8457\u98ce\u9669\uff0c\u9700\u8981\u5b9e\u65f6\u7cbe\u786e\u5b9a\u4f4d\u548c\u6301\u7eed\u76d1\u6d4b\u51fa\u8840\u6e90\u4ee5\u8fdb\u884c\u6709\u6548\u7684\u6b62\u8840\u5e72\u9884\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684AI\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u51fa\u8840\u533a\u57df\u5206\u5272\uff0c\u5ffd\u89c6\u4e86\u5728ESD\u8fd9\u79cd\u89c6\u89c9\u969c\u788d\u9891\u7e41\u3001\u573a\u666f\u52a8\u6001\u53d8\u5316\u7684\u6311\u6218\u6027\u73af\u5883\u4e2d\u8fdb\u884c\u7cbe\u786e\u51fa\u8840\u6e90\u68c0\u6d4b\u548c\u65f6\u95f4\u8ddf\u8e2a\u7684\u5173\u952e\u9700\u6c42\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u4e13\u95e8\u7684\u6570\u636e\u96c6\u4e5f\u963b\u788d\u4e86\u5f3a\u5927\u7684AI\u8f85\u52a9\u5f15\u5bfc\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBleedOrigin-Net\u7684\u65b0\u578b\u53cc\u9636\u6bb5\u68c0\u6d4b-\u8ddf\u8e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5728ESD\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u51fa\u8840\u6e90\u5b9a\u4f4d\u3002\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u4ece\u51fa\u8840\u8d77\u59cb\u68c0\u6d4b\u5230\u8fde\u7eed\u7a7a\u95f4\u8ddf\u8e2a\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u6784\u5efa\u4e86\u9996\u4e2a\u5168\u9762\u7684ESD\u51fa\u8840\u6e90\u6570\u636e\u96c6BleedOrigin-Bench\uff0c\u5305\u542b1771\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684\u51fa\u8840\u6e90\uff0c\u8986\u76d6\u4e868\u4e2a\u89e3\u5256\u90e8\u4f4d\u548c6\u79cd\u4e34\u5e8a\u573a\u666f\uff0c\u5e76\u4e0eYOLOv11/v12\u3001\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u70b9\u8ddf\u8e2a\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "BleedOrigin-Net\u5728\u51fa\u8840\u8d77\u59cb\u68c0\u6d4b\u65b9\u9762\u8fbe\u5230\u4e8696.85%\u7684\u5e27\u7ea7\u51c6\u786e\u7387\uff08\u00b1\u22648\u5e27\uff09\uff0c\u5728\u521d\u59cb\u51fa\u8840\u6e90\u68c0\u6d4b\u65b9\u9762\u8fbe\u5230\u4e8670.24%\u7684\u50cf\u7d20\u7ea7\u51c6\u786e\u7387\uff08\u2264100\u50cf\u7d20\uff09\uff0c\u5728\u70b9\u8ddf\u8e2a\u65b9\u9762\u8fbe\u5230\u4e8696.11%\u7684\u50cf\u7d20\u7ea7\u51c6\u786e\u7387\uff08\u2264100\u50cf\u7d20\uff09\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684BleedOrigin-Net\u5728ESD\u6b62\u8840\u65b9\u9762\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u51fa\u8840\u70b9\u68c0\u6d4b\u548c\u8ddf\u8e2a\uff0c\u4e3aAI\u8f85\u52a9\u7684\u5185\u7aa5\u955c\u624b\u672f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15174", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15174", "abs": "https://arxiv.org/abs/2507.15174", "authors": ["Justin Turnau", "Longchao Da", "Khoa Vo", "Ferdous Al Rafi", "Shreyas Bachiraju", "Tiejin Chen", "Hua Wei"], "title": "Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control", "comment": "This paper was accepted to RLC/RLJ 2025", "summary": "Traffic Signal Control (TSC) is essential for managing urban traffic flow and\nreducing congestion. Reinforcement Learning (RL) offers an adaptive method for\nTSC by responding to dynamic traffic patterns, with multi-agent RL (MARL)\ngaining traction as intersections naturally function as coordinated agents.\nHowever, due to shifts in environmental dynamics, implementing MARL-based TSC\npolicies in the real world often leads to a significant performance drop, known\nas the sim-to-real gap. Grounded Action Transformation (GAT) has successfully\nmitigated this gap in single-agent RL for TSC, but real-world traffic networks,\nwhich involve numerous interacting intersections, are better suited to a MARL\nframework. In this work, we introduce JL-GAT, an application of GAT to\nMARL-based TSC that balances scalability with enhanced grounding capability by\nincorporating information from neighboring agents. JL-GAT adopts a\ndecentralized approach to GAT, allowing for the scalability often required in\nreal-world traffic networks while still capturing key interactions between\nagents. Comprehensive experiments on various road networks under simulated\nadverse weather conditions, along with ablation studies, demonstrate the\neffectiveness of JL-GAT. The code is publicly available at\nhttps://github.com/DaRL-LibSignal/JL-GAT/.", "AI": {"tldr": "JL-GAT\u901a\u8fc7\u6574\u5408\u90bb\u8fd1\u667a\u80fd\u4f53\u4fe1\u606f\u548c\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86MARL\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684sim-to-real\u5dee\u8ddd\uff0c\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u5747\u6709\u6548\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4ea4\u901a\u7f51\u7edc\u5305\u542b\u8bb8\u591a\u76f8\u4e92\u4f5c\u7528\u7684\u4ea4\u53c9\u8def\u53e3\uff0c\u66f4\u9002\u5408MARL\u6846\u67b6\u3002\u7136\u800c\uff0cMARL\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5b9e\u65bd\u5e38\u56e0\u73af\u5883\u52a8\u6001\u53d8\u5316\u800c\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff08sim-to-real\u5dee\u8ddd\uff09\u3002GAT\u5df2\u6210\u529f\u89e3\u51b3\u4e86\u5355\u667a\u80fd\u4f53RL\u4e2d\u7684\u6b64\u95ee\u9898\uff0c\u4f46\u9700\u8981\u5c06\u5176\u5e94\u7528\u4e8eMARL\u4ee5\u66f4\u597d\u5730\u5904\u7406\u590d\u6742\u7684\u4ea4\u901a\u7f51\u7edc\u3002", "method": "JL-GAT\u662f\u4e00\u79cd\u5c06Grounded Action Transformation (GAT)\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff08TSC\uff09\u7684\u65b9\u6cd5\uff0c\u5b83\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u7684\u65b9\u5f0f\uff0c\u5e76\u6574\u5408\u4e86\u6765\u81ea\u90bb\u8fd1\u667a\u80fd\u4f53\u7684\u4fe1\u606f\uff0c\u4ee5\u89e3\u51b3sim-to-real\u5dee\u8ddd\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u5728\u5404\u79cd\u9053\u8def\u7f51\u7edc\u548c\u6a21\u62df\u7684\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u7efc\u5408\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u660e\u4e86JL-GAT\u7684\u6709\u6548\u6027\u3002", "conclusion": "JL-GAT\u901a\u8fc7\u6574\u5408\u90bb\u8fd1\u667a\u80fd\u4f53\u7684\u4fe1\u606f\uff0c\u5728\u53ef\u6269\u5c55\u6027\u4e0e\u589e\u5f3a\u7684\u63a5\u5730\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u5e76\u91c7\u7528\u4e86\u53bb\u4e2d\u5fc3\u5316\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u5404\u79cd\u9053\u8def\u7f51\u7edc\u548c\u6a21\u62df\u7684\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\uff0c\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684sim-to-real\u5dee\u8ddd\u95ee\u9898\u3002"}}
{"id": "2507.15778", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15778", "abs": "https://arxiv.org/abs/2507.15778", "authors": ["Jiakang Wang", "Runze Liu", "Fuzheng Zhang", "Xiu Li", "Guorui Zhou"], "title": "Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective\npost-training method for improving the reasoning abilities of Large Language\nModels (LLMs), mainly by shaping higher-order behaviors such as reflection and\nplanning. However, previous RLVR algorithms often apply uniform training\nsignals to all tokens, without considering the different roles of low-entropy\nknowledge-related tokens and high-entropy reasoning-related tokens. Some recent\nmethods try to separate these token types by gradient masking or asynchronous\nupdates, but these approaches may break semantic dependencies in the model\noutput and hinder effective learning. In this work, we propose Archer, an\nentropy-aware RLVR approach with dual-token constraints and synchronous\nupdates. Specifically, our method applies weaker KL regularization and higher\nclipping thresholds to reasoning tokens to encourage exploration, while using\nstronger constraints on knowledge tokens to maintain factual knowledge.\nExperimental results on several mathematical reasoning and code generation\nbenchmarks show that our approach significantly outperforms previous RLVR\nmethods, reaching or exceeding state-of-the-art performance among models of\ncomparable size. The code is available at\nhttps://github.com/wizard-III/ArcherCodeR.", "AI": {"tldr": "Archer improves LLM reasoning by applying different training signals to knowledge and reasoning tokens, outperforming existing methods.", "motivation": "Previous RLVR algorithms apply uniform training signals to all tokens, ignoring the different roles of low-entropy knowledge-related tokens and high-entropy reasoning-related tokens. Existing methods to separate token types may break semantic dependencies and hinder learning.", "method": "Archer uses an entropy-aware approach with dual-token constraints and synchronous updates. It applies weaker KL regularization and higher clipping thresholds to reasoning tokens to encourage exploration, while using stronger constraints on knowledge tokens to maintain factual knowledge.", "result": "Archer significantly outperforms previous RLVR methods on several mathematical reasoning and code generation benchmarks, reaching or exceeding state-of-the-art performance among models of comparable size.", "conclusion": "Archer, an entropy-aware RLVR approach with dual-token constraints and synchronous updates, significantly outperforms previous RLVR methods on mathematical reasoning and code generation benchmarks, reaching or exceeding state-of-the-art performance."}}
{"id": "2507.15109", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15109", "abs": "https://arxiv.org/abs/2507.15109", "authors": ["Mohammad-Maher Nakshbandi", "Ziad Sharawy", "Sorin Grigorescu"], "title": "LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM", "comment": null, "summary": "One of the main challenges in the Simultaneous Localization and Mapping\n(SLAM) loop closure problem is the recognition of previously visited places. In\nthis work, we tackle the two main problems of real-time SLAM systems: 1) loop\nclosure detection accuracy and 2) real-time computation constraints on the\nembedded hardware. Our LoopNet method is based on a multitasking variant of the\nclassical ResNet architecture, adapted for online retraining on a dynamic\nvisual dataset and optimized for embedded devices. The online retraining is\ndesigned using a few-shot learning approach. The architecture provides both an\nindex into the queried visual dataset, and a measurement of the prediction\nquality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,\nLoopNet surpasses the limitations of handcrafted features and traditional deep\nlearning methods, offering better performance under varying conditions. Code is\navailable at https://github.com/RovisLab/LoopNet. Additinally, we introduce a\nnew loop closure benchmarking dataset, coined LoopDB, which is available at\nhttps://github.com/RovisLab/LoopDB.", "AI": {"tldr": "LoopNet improves SLAM loop closure by using a specialized ResNet (LoopNet) with few-shot learning for real-time performance on embedded systems, outperforming older methods. A new dataset, LoopDB, is also released.", "motivation": "The paper aims to solve two main problems in real-time SLAM systems: loop closure detection accuracy and real-time computation constraints on embedded hardware.", "method": "LoopNet employs a multitasking ResNet architecture adapted for online retraining using few-shot learning and optimized for embedded devices. It leverages DISK (DIStinctive Keypoints) descriptors.", "result": "LoopNet surpasses traditional methods and handcrafted features by offering better performance under varying conditions, effectively indexing visual datasets and measuring prediction quality. The paper also introduces a new benchmarking dataset, LoopDB.", "conclusion": "LoopNet is a novel method that enhances loop closure detection accuracy and addresses real-time computation constraints in SLAM systems. It utilizes a multitasking ResNet architecture with few-shot learning for online retraining and incorporates DISK descriptors for improved performance."}}
{"id": "2507.15195", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15195", "abs": "https://arxiv.org/abs/2507.15195", "authors": ["Anwar Said", "Yifan Wei", "Ubaid Ullah Ahmad", "Mudassir Shabbir", "Waseem Abbas", "Xenofon Koutsoukos"], "title": "Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning", "comment": null, "summary": "In this article, we utilize the concept of average controllability in graphs,\nalong with a novel rank encoding method, to enhance the performance of Graph\nNeural Networks (GNNs) in social network classification tasks. GNNs have proven\nhighly effective in various network-based learning applications and require\nsome form of node features to function. However, their performance is heavily\ninfluenced by the expressiveness of these features. In social networks, node\nfeatures are often unavailable due to privacy constraints or the absence of\ninherent attributes, making it challenging for GNNs to achieve optimal\nperformance. To address this limitation, we propose two strategies for\nconstructing expressive node features. First, we introduce average\ncontrollability along with other centrality metrics (denoted as NCT-EFA) as\nnode-level metrics that capture critical aspects of network topology. Building\non this, we develop a rank encoding method that transforms average\ncontrollability or any other graph-theoretic metric into a fixed-dimensional\nfeature space, thereby improving feature representation. We conduct extensive\nnumerical evaluations using six benchmark GNN models across four social network\ndatasets to compare different node feature construction methods. Our results\ndemonstrate that incorporating average controllability into the feature space\nsignificantly improves GNN performance. Moreover, the proposed rank encoding\nmethod outperforms traditional one-hot degree encoding, improving the ROC AUC\nfrom 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,\nunderscoring its effectiveness in generating expressive and efficient node\nrepresentations.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u5e73\u5747\u53ef\u63a7\u6027\u548c\u79e9\u7f16\u7801\uff0c\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8282\u70b9\u7279\u5f81\u8868\u793a\u80fd\u529b\u548c\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8282\u70b9\u7279\u5f81\u7684\u7f3a\u5931\u6216\u8868\u8fbe\u6027\u4e0d\u8db3\u662f\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86GNNs\u7684\u6027\u80fd\u3002\u8fd9\u662f\u7531\u4e8e\u9690\u79c1\u9650\u5236\u6216\u7f3a\u4e4f\u56fa\u6709\u5c5e\u6027\uff0c\u5bfc\u81f4\u8282\u70b9\u7279\u5f81\u901a\u5e38\u4e0d\u53ef\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\u6765\u6784\u5efa\u8868\u8fbe\u6027\u5f3a\u7684\u8282\u70b9\u7279\u5f81\uff1a1. \u7ed3\u5408\u5e73\u5747\u53ef\u63a7\u6027\u548c\u5176\u4ed6\u4e2d\u5fc3\u6027\u5ea6\u91cf\uff08NCT-EFA\uff09\u4f5c\u4e3a\u8282\u70b9\u7ea7\u5ea6\u91cf\u6765\u6355\u6349\u7f51\u7edc\u62d3\u6251\u7684\u5173\u952e\u65b9\u9762\u30022. \u5f00\u53d1\u4e00\u79cd\u79e9\u7f16\u7801\u65b9\u6cd5\uff0c\u5c06\u5e73\u5747\u53ef\u63a7\u6027\u6216\u4efb\u4f55\u5176\u4ed6\u56fe\u8bba\u5ea6\u91cf\u8f6c\u6362\u4e3a\u56fa\u5b9a\u7ef4\u5ea6\u7684\u7279\u5f81\u7a7a\u95f4\uff0c\u4ee5\u6539\u8fdb\u7279\u5f81\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u5e73\u5747\u53ef\u63a7\u6027\u7eb3\u5165\u7279\u5f81\u7a7a\u95f4\u80fd\u663e\u8457\u63d0\u9ad8GNNs\u7684\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u4f7f\u7528GitHub Stargazers\u6570\u636e\u96c6\u548cGraphSAGE\u6a21\u578b\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u79e9\u7f16\u7801\u65b9\u6cd5\u5c06ROC AUC\u4ece68.7%\u63d0\u9ad8\u523073.9%\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u72ec\u70ed\u5ea6\u7f16\u7801\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5e73\u5747\u53ef\u63a7\u6027\u548c\u79e9\u7f16\u7801\u7684\u8282\u70b9\u7279\u5f81\u6784\u9020\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u79e9\u7f16\u7801\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u72ec\u70ed\u5ea6\u7f16\u7801\u65b9\u6cd5\u3002"}}
{"id": "2507.15779", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15779", "abs": "https://arxiv.org/abs/2507.15779", "authors": ["Felix K\u00f6ster", "Atsushi Uchida"], "title": "Reservoir Computing as a Language Model", "comment": "8 pages, 5 figures, 1 table", "summary": "Large Language Models (LLM) have dominated the science and media landscape\nduo to their impressive performance on processing large chunks of data and\nproduce human-like levels of text. Nevertheless, their huge energy demand and\nslow processing still a bottleneck for further increasing quality while also\nmaking the models accessible to everyone. To solve this bottleneck, we will\ninvestigate how reservoir computing performs on natural text processing, which\ncould enable fast and energy efficient hardware implementations. Studies\ninvestigating the use of reservoir computing as a language model remain sparse.\nIn this paper, we compare three distinct approaches for character-level\nlanguage modeling, two different reservoir computing approaches, where only an\noutput layer is trainable, and the well-known transformer-based architectures,\nwhich fully learn an attention-based sequence representation. We explore the\nperformance, computational cost and prediction accuracy for both paradigms by\nequally varying the number of trainable parameters for all models. Using a\nconsistent pipeline for all three approaches, we demonstrate that transformers\nexcel in prediction quality, whereas reservoir computers remain highly\nefficient reducing the training and inference speed. Furthermore, we\ninvestigate two types of reservoir computing: a traditional reservoir with a\nstatic linear readout, and an attention-enhanced reservoir that dynamically\nadapts its output weights via an attention mechanism. Our findings underline\nhow these paradigms scale and offer guidelines to balance resource constraints\nwith performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86Transformer\u548c\u4e24\u79cd\u6c34\u5e93\u8ba1\u7b97\u65b9\u6cd5\u5728\u5b57\u7b26\u7ea7\u8bed\u8a00\u5efa\u6a21\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793aTransformer\u5728\u9884\u6d4b\u8d28\u91cf\u4e0a\u66f4\u80dc\u4e00\u7b79\uff0c\u800c\u6c34\u5e93\u8ba1\u7b97\u5728\u901f\u5ea6\u548c\u80fd\u6548\u4e0a\u66f4\u5177\u4f18\u52bf\uff0c\u4e3a\u5e73\u8861\u8d44\u6e90\u4e0e\u6027\u80fd\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5904\u7406\u5927\u6570\u636e\u548c\u751f\u6210\u7c7b\u4eba\u6587\u672c\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5de8\u5927\u7684\u80fd\u6e90\u6d88\u8017\u548c\u7f13\u6162\u7684\u5904\u7406\u901f\u5ea6\u4ecd\u7136\u662f\u8fdb\u4e00\u6b65\u63d0\u9ad8\u8d28\u91cf\u548c\u666e\u53ca\u6a21\u578b\u7684\u74f6\u9888\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u6c34\u5e93\u8ba1\u7b97\u5728\u81ea\u7136\u6587\u672c\u5904\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u5b9e\u73b0\u5feb\u901f\u4e14\u8282\u80fd\u7684\u786c\u4ef6\u5b9e\u73b0\u3002", "method": "\u672c\u7814\u7a76\u5c06\u6bd4\u8f83\u4e09\u79cd\u4e0d\u540c\u7684\u5b57\u7b26\u7ea7\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\uff1a\u4e24\u79cd\u6c34\u5e93\u8ba1\u7b97\u65b9\u6cd5\uff08\u53ea\u6709\u8f93\u51fa\u5c42\u53ef\u8bad\u7ec3\uff09\u548c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff08\u5b8c\u5168\u5b66\u4e60\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5e8f\u5217\u8868\u793a\uff09\u3002\u901a\u8fc7\u7b49\u91cf\u53d8\u5316\u6240\u6709\u6a21\u578b\u7684\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\uff0c\u6765\u63a2\u7d22\u4e24\u79cd\u8303\u4f8b\u7684\u6027\u80fd\u3001\u8ba1\u7b97\u6210\u672c\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "Transformer\u5728\u9884\u6d4b\u8d28\u91cf\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u6c34\u5e93\u8ba1\u7b97\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\u4e0a\u66f4\u9ad8\u6548\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cTransformer\u5728\u9884\u6d4b\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u6c34\u5e93\u8ba1\u7b97\u5728\u51cf\u5c0f\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\u65b9\u9762\u4ecd\u7136\u5177\u6709\u9ad8\u6548\u7387\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u4e24\u79cd\u6c34\u5e93\u8ba1\u7b97\u65b9\u6cd5\uff1a\u4e00\u79cd\u662f\u4f20\u7edf\u7684\u5177\u6709\u9759\u6001\u7ebf\u6027\u8bfb\u51fa\u7684\u6c34\u5e93\uff0c\u53e6\u4e00\u79cd\u662f\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u8c03\u6574\u5176\u8f93\u51fa\u6743\u91cd\u7684\u6ce8\u610f\u529b\u589e\u5f3a\u578b\u6c34\u5e93\u3002\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u6a21\u578b\u8303\u5f0f\u5982\u4f55\u6269\u5c55\uff0c\u5e76\u4e3a\u5e73\u8861\u8d44\u6e90\u9650\u5236\u4e0e\u6027\u80fd\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.15130", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15130", "abs": "https://arxiv.org/abs/2507.15130", "authors": ["Ce Zhang", "Yale Song", "Ruta Desai", "Michael Louis Iuzzolino", "Joseph Tighe", "Gedas Bertasius", "Satwik Kottur"], "title": "Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction", "comment": null, "summary": "Visual Planning for Assistance (VPA) aims to predict a sequence of user\nactions required to achieve a specified goal based on a video showing the\nuser's progress. Although recent advances in multimodal large language models\n(MLLMs) have shown promising results in video understanding, long-horizon\nvisual planning remains a challenging problem. We identify two challenges in\ntraining large MLLMs for video-based planning tasks: (1) scarcity of procedural\nannotations, limiting the model's ability to learn procedural task dynamics\neffectively, and (2) inefficiency of next-token prediction objective to\nexplicitly capture the structured action space for visual planning when\ncompared to free-form, natural language. To tackle data scarcity, we introduce\nAuxiliary Task Augmentation. We design and train our model on auxiliary tasks\nrelevant to long-horizon video-based planning (e.g., goal prediction) to\naugment the model's planning ability. To more explicitly model the structured\naction space unique to visual planning tasks, we leverage Multi-token\nPrediction, extending traditional next-token prediction by using multiple heads\nto predict multiple future tokens during training. Our approach, VideoPlan,\nachieves state-of-the-art VPA performance on the COIN and CrossTask datasets,\nsurpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3\nfuture actions. We further extend our method to the challenging Ego4D Long-term\nAction Anticipation task, and show that it is on par with the state-of-the-art\napproaches despite not using specialized egocentric features. Code will be made\navailable.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a VideoPlan \u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f85\u52a9\u4efb\u52a1\u589e\u5f3a\u548c\u591a\u4ee4\u724c\u9884\u6d4b\u6765\u89e3\u51b3\u89c6\u9891\u89c4\u5212\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u6027\u548c\u7ed3\u6784\u5316\u52a8\u4f5c\u7a7a\u95f4\u5efa\u6a21\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u89c6\u9891\u89c4\u5212\uff08VPA\uff09\u4efb\u52a1\u4e2d\u8bad\u7ec3\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u6240\u9762\u4e34\u7684\u4e24\u4e2a\u6311\u6218\uff1a1. \u7a0b\u5e8f\u6027\u6ce8\u91ca\u7684\u7a00\u7f3a\u6027\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6709\u6548\u5b66\u4e60\u7a0b\u5e8f\u6027\u4efb\u52a1\u52a8\u6001\u7684\u80fd\u529b\uff1b2. \u4e0e\u81ea\u7531\u5f62\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u76f8\u6bd4\uff0c\u4e0b\u4e00\u4e2a\u4ee4\u724c\u9884\u6d4b\u76ee\u6807\u5728\u663e\u5f0f\u6355\u83b7\u89c6\u89c9\u89c4\u5212\u7684\u7ed3\u6784\u5316\u52a8\u4f5c\u7a7a\u95f4\u65b9\u9762\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a VideoPlan \u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u8f85\u52a9\u4efb\u52a1\u589e\u5f3a\uff08Auxiliary Task Augmentation\uff09\u548c\u591a\u4ee4\u724c\u9884\u6d4b\uff08Multi-token Prediction\uff09\u3002\u8f85\u52a9\u4efb\u52a1\u589e\u5f3a\u901a\u8fc7\u5728\u4e0e\u957f\u671f\u89c6\u9891\u89c4\u5212\u76f8\u5173\u7684\u8f85\u52a9\u4efb\u52a1\uff08\u4f8b\u5982\u76ee\u6807\u9884\u6d4b\uff09\u4e0a\u8bad\u7ec3\u6a21\u578b\u6765\u89e3\u51b3\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\u3002\u591a\u4ee4\u724c\u9884\u6d4b\u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u9884\u6d4b\u5934\u5728\u8bad\u7ec3\u671f\u95f4\u9884\u6d4b\u591a\u4e2a\u672a\u6765\u4ee4\u724c\u6765\u6269\u5c55\u4f20\u7edf\u7684\u4e0b\u4e00\u4e2a\u4ee4\u724c\u9884\u6d4b\uff0c\u4ece\u800c\u66f4\u660e\u786e\u5730\u6a21\u62df\u4e86\u89c6\u89c9\u89c4\u5212\u7279\u6709\u7684\u7ed3\u6784\u5316\u52a8\u4f5c\u7a7a\u95f4\u3002", "result": "VideoPlan \u5728 COIN \u548c CrossTask \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684 VPA \u6027\u80fd\uff0c\u5728\u9884\u6d4b 3 \u4e2a\u672a\u6765\u52a8\u4f5c\u65f6\u5206\u522b\u8d85\u8d8a\u4e86\u5148\u524d\u65b9\u6cd5 7.3% \u548c 3.4%\u3002\u8be5\u65b9\u6cd5\u5728 Ego4D \u957f\u65f6\u52a8\u4f5c\u9884\u6d4b\u4efb\u52a1\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "VideoPlan \u5728 COIN \u548c CrossTask \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684 VPA \u6027\u80fd\uff0c\u5728\u9884\u6d4b 3 \u4e2a\u672a\u6765\u52a8\u4f5c\u65f6\u5206\u522b\u8d85\u8d8a\u4e86\u5148\u524d\u65b9\u6cd5 7.3% \u548c 3.4%\u3002\u6b64\u5916\uff0c\u5728 Ego4D \u957f\u65f6\u52a8\u4f5c\u9884\u6d4b\u4efb\u52a1\u4e0a\uff0cVideoPlan \u7684\u8868\u73b0\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u5f53\uff0c\u5c3d\u7ba1\u5b83\u6ca1\u6709\u4f7f\u7528\u4e13\u95e8\u7684\u4ee5\u81ea\u6211\u4e3a\u4e2d\u5fc3\u7684\u7279\u5f81\u3002"}}
{"id": "2507.15205", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15205", "abs": "https://arxiv.org/abs/2507.15205", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao"], "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation", "comment": "Accepted by the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "summary": "Emotion Recognition in Conversation (ERC) is a practical and challenging\ntask. This paper proposes a novel multimodal approach, the Long-Short Distance\nGraph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it\nconstructs a long-distance graph neural network and a short-distance graph\nneural network to obtain multimodal features of distant and nearby utterances,\nrespectively. To ensure that long- and short-distance features are as distinct\nas possible in representation while enabling mutual influence between the two\nmodules, we employ a Differential Regularizer and incorporate a BiAffine Module\nto facilitate feature interaction. In addition, we propose an Improved\nCurriculum Learning (ICL) to address the challenge of data imbalance. By\ncomputing the similarity between different emotions to emphasize the shifts in\nsimilar emotions, we design a \"weighted emotional shift\" metric and develop a\ndifficulty measurer, enabling a training process that prioritizes learning easy\nsamples before harder ones. Experimental results on the IEMOCAP and MELD\ndatasets demonstrate that our model outperforms existing benchmarks.", "AI": {"tldr": "The paper introduces LSDGNN, a new multimodal model for conversation emotion recognition that uses graph neural networks for long and short-range dependencies, a differential regularizer and BiAffine module for feature interaction, and improved curriculum learning to handle data imbalance, achieving state-of-the-art results on benchmark datasets.", "motivation": "Emotion Recognition in Conversation (ERC) is a practical yet challenging task. The paper aims to address the challenges of capturing both long- and short-distance dependencies in conversational context and handling data imbalance in ERC.", "method": "The paper proposes a novel multimodal approach called the Long-Short Distance Graph Neural Network (LSDGNN). This model constructs long- and short-distance graph neural networks based on a Directed Acyclic Graph (DAG) to capture multimodal features from distant and nearby utterances. It employs a Differential Regularizer and a BiAffine Module to enhance feature distinction and interaction. Additionally, an Improved Curriculum Learning (ICL) strategy is introduced to handle data imbalance, using a \"weighted emotional shift\" metric and a difficulty measurer to prioritize learning easy samples first.", "result": "Experimental results on the IEMOCAP and MELD datasets show that the proposed LSDGNN model achieves superior performance compared to existing benchmarks.", "conclusion": "The proposed LSDGNN model outperforms existing benchmarks on the IEMOCAP and MELD datasets."}}
{"id": "2507.15150", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15150", "abs": "https://arxiv.org/abs/2507.15150", "authors": ["Aayush Atul Verma", "Arpitsinh Vaghela", "Bharatesh Chakravarthi", "Kaustav Chanda", "Yezhou Yang"], "title": "Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection", "comment": null, "summary": "Event-based sensors offer high temporal resolution and low latency by\ngenerating sparse, asynchronous data. However, converting this irregular data\ninto dense tensors for use in standard neural networks diminishes these\ninherent advantages, motivating research into graph representations. While such\nmethods preserve sparsity and support asynchronous inference, their performance\non downstream tasks remains limited due to suboptimal modeling of\nspatiotemporal dynamics. In this work, we propose a novel spatiotemporal\nmultigraph representation to better capture spatial structure and temporal\nchanges. Our approach constructs two decoupled graphs: a spatial graph\nleveraging B-spline basis functions to model global structure, and a temporal\ngraph utilizing motion vector-based attention for local dynamic changes. This\ndesign enables the use of efficient 2D kernels in place of computationally\nexpensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM\ndatasets for event-based object detection, achieving over a 6% improvement in\ndetection accuracy compared to previous graph-based works, with a 5x speedup,\nreduced parameter count, and no increase in computational cost. These results\nhighlight the effectiveness of structured graph modeling for asynchronous\nvision. Project page: eventbasedvision.github.io/eGSMV.", "AI": {"tldr": "\u901a\u8fc7\u65b0\u9896\u7684\u65f6\u7a7a\u591a\u56fe\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u56fe\u65b9\u6cd5\u66f4\u4f18\u7684\u4e8b\u4ef6\u68c0\u6d4b\u6027\u80fd\u548c\u66f4\u9ad8\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u8868\u793a\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u4fdd\u7559\u4e8b\u4ef6\u6570\u636e\u7684\u7a00\u758f\u6027\u548c\u5f02\u6b65\u6027\uff0c\u4f46\u5728\u65f6\u7a7a\u52a8\u6001\u5efa\u6a21\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u5904\u7406\u4e8b\u4ef6\u6570\u636e\u7684\u65f6\u7a7a\u7279\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u7a7a\u591a\u56fe\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u7684\u7a7a\u95f4\u56fe\uff08\u5229\u7528B\u6837\u6761\u57fa\u51fd\u6570\uff09\u548c\u65f6\u95f4\u56fe\uff08\u5229\u7528\u57fa\u4e8e\u8fd0\u52a8\u77e2\u91cf\u7684\u6ce8\u610f\u529b\u673a\u5236\uff09\u6765\u6355\u6349\u65f6\u7a7a\u52a8\u6001\uff0c\u4ece\u800c\u5141\u8bb8\u4f7f\u7528\u9ad8\u6548\u76842D\u5377\u79ef\u6838\u66ff\u4ee3\u8ba1\u7b97\u6210\u672c\u9ad8\u76843D\u5377\u79ef\u6838\u3002", "result": "\u5728Gen1\u6c7d\u8f66\u548ceTraM\u6570\u636e\u96c6\u7684\u4e8b\u4ef6\u5bf9\u8c61\u68c0\u6d4b\u4efb\u52a1\u4e0a\uff0c\u76f8\u8f83\u4e8e\u5148\u524d\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u63d0\u5347\u4e86\u8d85\u8fc76%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e865\u500d\u7684\u52a0\u901f\uff0c\u5e76\u51cf\u5c11\u4e86\u53c2\u6570\u91cf\uff0c\u800c\u8ba1\u7b97\u6210\u672c\u5e76\u672a\u589e\u52a0\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u7ed3\u6784\u5316\u56fe\u6a21\u578b\u6709\u6548\u5730\u5904\u7406\u5f02\u6b65\u89c6\u89c9\u6570\u636e\uff0c\u5728\u4e8b\u4ef6\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u6548\u7387\u6539\u8fdb\u3002"}}
{"id": "2507.15240", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.15240", "abs": "https://arxiv.org/abs/2507.15240", "authors": ["Le Peng", "Yash Travadi", "Chuan He", "Ying Cui", "Ju Sun"], "title": "Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification", "comment": null, "summary": "For classification with imbalanced class frequencies, i.e., imbalanced\nclassification (IC), standard accuracy is known to be misleading as a\nperformance measure. While most existing methods for IC resort to optimizing\nbalanced accuracy (i.e., the average of class-wise recalls), they fall short in\nscenarios where the significance of classes varies or certain metrics should\nreach prescribed levels. In this paper, we study two key classification\nmetrics, precision and recall, under three practical binary IC settings: fix\nprecision optimize recall (FPOR), fix recall optimize precision (FROP), and\noptimize $F_\\beta$-score (OFBS). Unlike existing methods that rely on smooth\napproximations to deal with the indicator function involved, \\textit{we\nintroduce, for the first time, exact constrained reformulations for these\ndirect metric optimization (DMO) problems}, which can be effectively solved by\nexact penalty methods. Experiment results on multiple benchmark datasets\ndemonstrate the practical superiority of our approach over the state-of-the-art\nmethods for the three DMO problems. We also expect our exact reformulation and\noptimization (ERO) framework to be applicable to a wide range of DMO problems\nfor binary IC and beyond. Our code is available at\nhttps://github.com/sun-umn/DMO.", "AI": {"tldr": "\u9488\u5bf9\u4e0d\u5e73\u8861\u5206\u7c7b\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7cbe\u786e\u7ea6\u675f\u91cd\u6784\u548c\u4f18\u5316\u6846\u67b6\uff08ERO\uff09\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f18\u5316\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF\u03b2\u5206\u6570\u7b49\u6307\u6807\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4e0d\u5e73\u8861\u5206\u7c7b\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u4f18\u5316\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4f46\u5728\u7c7b\u522b\u91cd\u8981\u6027\u4e0d\u540c\u6216\u7279\u5b9a\u6307\u6807\u9700\u8981\u8fbe\u5230\u9884\u5b9a\u6c34\u5e73\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u7814\u7a76\u65e8\u5728\u76f4\u63a5\u4f18\u5316\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7b49\u5173\u952e\u6307\u6807\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7cbe\u786e\u7ea6\u675f\u91cd\u6784\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4e0d\u5e73\u8861\u5206\u7c7b\u4e2d\u7684\u76f4\u63a5\u6307\u6807\u4f18\u5316\uff08DMO\uff09\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u7cbe\u786e\u60e9\u7f5a\u65b9\u6cd5\u8fdb\u884c\u6c42\u89e3\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728FPOR\u3001FROP\u548cOFBS\u8fd9\u4e09\u79cdDMO\u95ee\u9898\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u9488\u5bf9\u4e0d\u5e73\u8861\u5206\u7c7b\u7684\u7cbe\u786e\u7ea6\u675f\u91cd\u6784\u548c\u4f18\u5316\uff08ERO\uff09\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e09\u79cd\u76f4\u63a5\u6307\u6807\u4f18\u5316\uff08DMO\uff09\u95ee\u9898\uff1a\u56fa\u5b9a\u7cbe\u5ea6\u4f18\u5316\u53ec\u56de\u7387\uff08FPOR\uff09\u3001\u56fa\u5b9a\u53ec\u56de\u7387\u4f18\u5316\u7cbe\u5ea6\uff08FROP\uff09\u548c\u4f18\u5316F\u03b2\u5206\u6570\uff08OFBS\uff09\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u4e09\u79cdDMO\u95ee\u9898\u4e0a\u5177\u6709\u5b9e\u9645\u4f18\u52bf\uff0c\u5e76\u6709\u671b\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684DMO\u95ee\u9898\u3002"}}
{"id": "2507.15849", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15849", "abs": "https://arxiv.org/abs/2507.15849", "authors": ["Yihao Li", "Jiayi Xin", "Miranda Muqing Miao", "Qi Long", "Lyle Ungar"], "title": "The Impact of Language Mixing on Bilingual LLM Reasoning", "comment": null, "summary": "Proficient multilingual speakers often intentionally switch languages in the\nmiddle of a conversation. Similarly, recent reasoning-focused bilingual large\nlanguage models (LLMs) with strong capabilities in both languages exhibit\nlanguage mixing--alternating languages within their chain of thought.\nDiscouraging this behavior in DeepSeek-R1 was found to degrade accuracy,\nsuggesting that language mixing may benefit reasoning. In this work, we study\nlanguage switching in Chinese-English bilingual reasoning models. We identify\nreinforcement learning with verifiable rewards (RLVR) as the critical training\nstage that leads to language mixing. We demonstrate that language mixing can\nenhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6\npercentage points on math reasoning tasks. Additionally, a lightweight probe\ncan be trained to predict whether a potential language switch would benefit or\nharm reasoning, and when used to guide decoding, increases accuracy by up to\n6.25 percentage points. Our findings suggest that language mixing is not merely\na byproduct of multilingual training, but is a strategic reasoning behavior.", "AI": {"tldr": "\u53cc\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u4f1a\u6df7\u5408\u4f7f\u7528\u8bed\u8a00\uff0c\u8fd9\u662f\u4e00\u79cd\u6709\u76ca\u7684\u7b56\u7565\uff0c\u800c\u4e0d\u662f\u7f3a\u9677\u3002\u901a\u8fc7\u7279\u5b9a\u7684\u8bad\u7ec3\u548c\u5f15\u5bfc\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u53cc\u8bed\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u8bed\u8a00\u6df7\u5408\u73b0\u8c61\uff0c\u63a2\u7a76\u5176\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u662f\u5bfc\u81f4\u8bed\u8a00\u6df7\u5408\u7684\u5173\u952e\u8bad\u7ec3\u9636\u6bb5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea7\u63a2\u9488\u6765\u9884\u6d4b\u548c\u5f15\u5bfc\u8bed\u8a00\u8f6c\u6362\u4ee5\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5f3a\u5236\u5355\u8bed\u89e3\u7801\u4f1a\u4f7f\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u7387\u964d\u4f4e5.6\u4e2a\u767e\u5206\u70b9\u3002\u8f7b\u91cf\u7ea7\u63a2\u9488\u53ef\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u591a\u8fbe6.25\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8bed\u8a00\u6df7\u5408\u5e76\u975e\u591a\u8bed\u8a00\u8bad\u7ec3\u7684\u526f\u4ea7\u54c1\uff0c\u800c\u662f\u4e00\u79cd\u6709\u76ca\u7684\u63a8\u7406\u7b56\u7565\u3002"}}
{"id": "2507.15212", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15212", "abs": "https://arxiv.org/abs/2507.15212", "authors": ["Yusuke Yoshiyasu", "Leyuan Sun", "Ryusuke Sagawa"], "title": "MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction", "comment": "Accepted at ICCV2025", "summary": "In this paper, we introduce MeshMamba, a neural network model for learning 3D\narticulated mesh models by employing the recently proposed Mamba State Space\nModels (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large\nnumber of input tokens, enabling the generation and reconstruction of body mesh\nmodels with more than 10,000 vertices, capturing clothing and hand geometries.\nThe key to effectively learning MeshMamba is the serialization technique of\nmesh vertices into orderings that are easily processed by Mamba. This is\nachieved by sorting the vertices based on body part annotations or the 3D\nvertex locations of a template mesh, such that the ordering respects the\nstructure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D,\na denoising diffusion model for generating 3D articulated meshes and 2)\nMamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape\nand pose from a single image. Experimental results showed that MambaDiff3D can\ngenerate dense 3D human meshes in clothes, with grasping hands, etc., and\noutperforms previous approaches in the 3D human shape generation task.\nAdditionally, Mamba-HMR extends the capabilities of previous non-parametric\nhuman mesh recovery approaches, which were limited to handling body-only poses\nusing around 500 vertex tokens, to the whole-body setting with face and hands,\nwhile achieving competitive performance in (near) real-time.", "AI": {"tldr": "MeshMamba\u662f\u4e00\u4e2a\u57fa\u4e8eMamba-SSM\u7684\u65b0\u578b3D\u5173\u8282\u7f51\u683c\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u91cf\u9876\u70b9\uff0c\u5e76\u50ac\u751f\u4e86\u7528\u4e8e3D\u7f51\u683c\u751f\u6210\uff08MambaDiff3D\uff09\u548c\u4eba\u4f53\u59ff\u6001\u6062\u590d\uff08Mamba-HMR\uff09\u7684\u5148\u8fdb\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u5b66\u4e603D\u5173\u8282\u7f51\u683c\u6a21\u578b\uff0c\u5e76\u63d0\u9ad8\u751f\u6210\u548c\u91cd\u5efa\u7684\u6548\u7387\u548c\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5904\u7406\u5305\u542b\u5927\u91cf\u9876\u70b9\uff08\u5982\u670d\u88c5\u548c\u624b\u90e8\u51e0\u4f55\uff09\u7684\u6a21\u578b\u3002", "method": "MeshMamba\u6a21\u578b\uff0c\u5229\u7528Mamba-SSM\u5904\u74063D\u5173\u8282\u7f51\u683c\uff0c\u901a\u8fc7\u57fa\u4e8e\u8eab\u4f53\u90e8\u4f4d\u6ce8\u91ca\u6216\u6a21\u677f\u7f51\u683c3D\u9876\u70b9\u4f4d\u7f6e\u5bf9\u9876\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u4ee5\u5c0a\u91cd\u5173\u8282\u5f62\u72b6\u7684\u7ed3\u6784\u3002\u57fa\u4e8e\u6b64\uff0c\u5f00\u53d1\u4e86MambaDiff3D\uff08\u7528\u4e8e\u751f\u62103D\u5173\u8282\u7f51\u683c\u7684\u53bb\u566a\u6269\u6563\u6a21\u578b\uff09\u548cMamba-HMR\uff08\u7528\u4e8e\u4ece\u5355\u5f20\u56fe\u50cf\u91cd\u5efa3D\u4eba\u4f53\u5f62\u72b6\u548c\u59ff\u52bf\u7684\u4eba\u4f53\u7f51\u683c\u6062\u590d\u6a21\u578b\uff09\u3002", "result": "MambaDiff3D\u80fd\u591f\u751f\u6210\u5305\u542b\u670d\u88c5\u548c\u6293\u63e1\u624b\u7684\u5bc6\u96c63D\u4eba\u4f53\u7f51\u683c\uff0c\u5e76\u57283D\u4eba\u4f53\u5f62\u72b6\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002Mamba-HMR\u6210\u529f\u5730\u5c06\u975e\u53c2\u6570\u4eba\u4f53\u7f51\u683c\u6062\u590d\u7684\u80fd\u529b\u6269\u5c55\u5230\u5168\u8eab\uff08\u5305\u62ec\u9762\u90e8\u548c\u624b\uff09\uff0c\u5e76\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\uff08\u8fd1\uff09\u5b9e\u65f6\u6027\u80fd\u3002", "conclusion": "MeshMamba\u901a\u8fc7\u5229\u7528Mamba-SSM\uff0c\u53ef\u4ee5\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u5730\u5904\u7406\u5927\u91cf\u8f93\u5165\u6807\u8bb0\uff0c\u4ece\u800c\u80fd\u591f\u751f\u6210\u548c\u91cd\u5efa\u5177\u6709\u8d85\u8fc710,000\u4e2a\u9876\u70b9\u7684\u8eab\u4f53\u7f51\u683c\u6a21\u578b\uff0c\u5e76\u6355\u6349\u670d\u88c5\u548c\u624b\u90e8\u51e0\u4f55\u5f62\u72b6\u3002\u57fa\u4e8eMeshMamba\u8bbe\u8ba1\u7684MambaDiff3D\uff08\u7528\u4e8e\u751f\u62103D\u5173\u8282\u7f51\u683c\u7684\u53bb\u566a\u6269\u6563\u6a21\u578b\uff09\u548cMamba-HMR\uff08\u7528\u4e8e\u4ece\u5355\u5f20\u56fe\u50cf\u91cd\u5efa3D\u4eba\u4f53\u5f62\u72b6\u548c\u59ff\u52bf\u7684\u4eba\u4f53\u7f51\u683c\u6062\u590d\u6a21\u578b\uff09\u5728\u5404\u81ea\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002MambaDiff3D\u751f\u6210\u7684\u5bc6\u96c63D\u4eba\u4f53\u7f51\u683c\uff08\u5305\u62ec\u670d\u88c5\u548c\u6293\u63e1\u7684\u624b\uff09\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002Mamba-HMR\u5219\u5c06\u975e\u53c2\u6570\u4eba\u4f53\u7f51\u683c\u6062\u590d\u7684\u80fd\u529b\u4ece\u4ec5\u5904\u7406\u8eab\u4f53\u59ff\u52bf\uff08\u7ea6500\u4e2a\u9876\u70b9\u6807\u8bb0\uff09\u6269\u5c55\u5230\u5305\u542b\u9762\u90e8\u548c\u624b\u7684\u5168\u8eab\u8bbe\u7f6e\uff0c\u5e76\u5728\uff08\u8fd1\uff09\u5b9e\u65f6\u6027\u80fd\u4e0a\u8fbe\u5230\u6709\u7ade\u4e89\u529b\u6c34\u5e73\u3002"}}
{"id": "2507.15246", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15246", "abs": "https://arxiv.org/abs/2507.15246", "authors": ["Rabia Latief Bhat", "Iqra Altaf Gillani"], "title": "Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks", "comment": null, "summary": "Accurate demand forecasting is critical for enhancing the efficiency and\nresponsiveness of food delivery platforms, where spatial heterogeneity and\ntemporal fluctuations in order volumes directly influence operational\ndecisions. This paper proposes an attention-based Graph Neural Network\nframework that captures spatial-temporal dependencies by modeling the food\ndelivery environment as a graph. In this graph, nodes represent urban delivery\nzones, while edges reflect spatial proximity and inter-regional order flow\npatterns derived from historical data. The attention mechanism dynamically\nweighs the influence of neighboring zones, enabling the model to focus on the\nmost contextually relevant areas during prediction. Temporal trends are jointly\nlearned alongside spatial interactions, allowing the model to adapt to evolving\ndemand patterns. Extensive experiments on real-world food delivery datasets\ndemonstrate the superiority of the proposed model in forecasting future order\nvolumes with high accuracy. The framework offers a scalable and adaptive\nsolution to support proactive fleet positioning, resource allocation, and\ndispatch optimization in urban food delivery operations.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u98df\u7269\u914d\u9001\u73af\u5883\u8fdb\u884c\u5efa\u6a21\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u8ba2\u5355\u91cf\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u914d\u9001\u8fd0\u8425\u3002", "motivation": "\u51c6\u786e\u7684\u9700\u6c42\u9884\u6d4b\u5bf9\u4e8e\u63d0\u9ad8\u98df\u7269\u914d\u9001\u5e73\u53f0\u7684\u6548\u7387\u548c\u54cd\u5e94\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u8ba2\u5355\u91cf\u7684\u7a7a\u95f4\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u6ce2\u52a8\u76f4\u63a5\u5f71\u54cd\u8fd0\u8425\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u6846\u67b6\uff0c\u5c06\u98df\u7269\u914d\u9001\u73af\u5883\u5efa\u6a21\u4e3a\u56fe\u3002\u8282\u70b9\u4ee3\u8868\u57ce\u5e02\u914d\u9001\u533a\uff0c\u8fb9\u8868\u793a\u533a\u57df\u95f4\u7684\u90bb\u8fd1\u5173\u7cfb\u548c\u5386\u53f2\u8ba2\u5355\u6d41\u6a21\u5f0f\u3002\u6ce8\u610f\u529b\u673a\u5236\u7528\u4e8e\u52a8\u6001\u52a0\u6743\u90bb\u8fd1\u533a\u57df\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u6355\u6349\u7a7a\u95f4-\u65f6\u95f4\u4f9d\u8d56\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684GNN\u6846\u67b6\u5728\u9884\u6d4b\u672a\u6765\u8ba2\u5355\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u5b9e\u9645\u7684\u98df\u7269\u914d\u9001\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u672a\u6765\u8ba2\u5355\u91cf\u9884\u6d4b\u65b9\u9762\u7684\u9ad8\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002"}}
{"id": "2507.15850", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15850", "abs": "https://arxiv.org/abs/2507.15850", "authors": ["Basma El Amel Boussaha", "Leen AlQadi", "Mugariya Farooq", "Shaikha Alsuwaidi", "Giulia Campesan", "Ahmed Alzubaidi", "Mohammed Alyafeai", "Hakim Hacid"], "title": "3LM: Bridging Arabic, STEM, and Code through Benchmarking", "comment": null, "summary": "Arabic is one of the most widely spoken languages in the world, yet efforts\nto develop and evaluate Large Language Models (LLMs) for Arabic remain\nrelatively limited. Most existing Arabic benchmarks focus on linguistic,\ncultural, or religious content, leaving a significant gap in domains like STEM\nand code which are increasingly relevant for real-world LLM applications. To\nhelp bridge this gap, we present 3LM, a suite of three benchmarks designed\nspecifically for Arabic. The first is a set of STEM-related question-answer\npairs, naturally sourced from Arabic textbooks and educational worksheets. The\nsecond consists of synthetically generated STEM questions, created using the\nsame sources. The third benchmark focuses on code generation, built through a\ncareful translation of two widely used code benchmarks, incorporating a\nhuman-in-the-loop process with several rounds of review to ensure high-quality\nand faithful translations. We release all three benchmarks publicly to support\nthe growth of Arabic LLM research in these essential but underrepresented\nareas.", "AI": {"tldr": "\u4e3a\u4e86\u5f25\u8865\u963f\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u5728STEM\u548c\u4ee3\u7801\u9886\u57df\u8bc4\u4f30\u57fa\u51c6\u7684\u4e0d\u8db3\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u4e2a\u65b0\u7684\u57fa\u51c6\uff1aSTEM\u95ee\u7b54\u3001\u5408\u6210STEM\u95ee\u9898\u548c\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u963f\u8bed\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bc4\u4f30\u57fa\u51c6\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u8a00\u3001\u6587\u5316\u6216\u5b97\u6559\u5185\u5bb9\uff0c\u800c\u5728STEM\u548c\u4ee3\u7801\u7b49\u4e0e\u73b0\u5b9e\u5e94\u7528\u65e5\u76ca\u76f8\u5173\u7684\u9886\u57df\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u963f\u8bed\u6559\u6750\u548c\u7ec3\u4e60\u9898\uff0c\u521b\u5efa\u4e86STEM\u95ee\u7b54\u5bf9\u548c\u5408\u6210STEM\u95ee\u9898\uff1b\u540c\u65f6\uff0c\u7ffb\u8bd1\u4e86\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4ee3\u7801\u57fa\u51c6\uff0c\u5e76\u7ed3\u5408\u4eba\u5de5\u8bc4\u5ba1\u6d41\u7a0b\uff0c\u521b\u5efa\u4e86\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u3002", "result": "\u53d1\u5e03\u4e86\u4e09\u4e2a\u9488\u5bf9\u963f\u8bed\u7684\u57fa\u51c6\uff1aSTEM\u95ee\u7b54\u5bf9\u3001\u5408\u6210STEM\u95ee\u9898\u548c\u4ee3\u7801\u751f\u6210\uff0c\u4ee5\u652f\u6301\u963f\u8bedLLM\u5728\u8fd9\u4e9b\u5173\u952e\u4f46\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u9886\u57df\u7684\u7814\u7a76\u3002", "conclusion": "\u8be5\u7814\u7a76\u53d1\u5e03\u4e86\u4e09\u4e2a\u65b0\u7684\u963f\u8bed\u57fa\u51c6\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u5728STEM\u548c\u4ee3\u7801\u9886\u57df\u5b58\u5728\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e8\u5728\u4fc3\u8fdb\u963f\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2507.15216", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15216", "abs": "https://arxiv.org/abs/2507.15216", "authors": ["Yuping Qiu", "Rui Zhu", "Ying-cong Chen"], "title": "Improving Joint Embedding Predictive Architecture with Diffusion Noise", "comment": null, "summary": "Self-supervised learning has become an incredibly successful method for\nfeature learning, widely applied to many downstream tasks. It has proven\nespecially effective for discriminative tasks, surpassing the trending\ngenerative models. However, generative models perform better in image\ngeneration and detail enhancement. Thus, it is natural for us to find a\nconnection between SSL and generative models to further enhance the\nrepresentation capacity of SSL. As generative models can create new samples by\napproximating the data distribution, such modeling should also lead to a\nsemantic understanding of the raw visual data, which is necessary for\nrecognition tasks. This enlightens us to combine the core principle of the\ndiffusion model: diffusion noise, with SSL to learn a competitive recognition\nmodel. Specifically, diffusion noise can be viewed as a particular state of\nmask that reveals a close relationship between masked image modeling (MIM) and\ndiffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to\nincorporate diffusion noise into MIM by the position embedding of masked\ntokens. The multi-level noise schedule is a series of feature augmentations to\nfurther enhance the robustness of our model. We perform a comprehensive study\nto confirm its effectiveness in the classification of downstream tasks. Codes\nwill be released soon in public.", "AI": {"tldr": "N-JEPA\uff08\u57fa\u4e8e\u566a\u58f0\u7684JEPA\uff09\u901a\u8fc7\u5c06\u6269\u6563\u566a\u58f0\u6574\u5408\u5230\u63a9\u7801\u56fe\u50cf\u5efa\u6a21\uff08MIM\uff09\u4e2d\uff0c\u5e76\u7ed3\u5408\u591a\u5c42\u6b21\u566a\u58f0\u8c03\u5ea6\uff0c\u589e\u5f3a\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u5728\u56fe\u50cf\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u4e3a\u4e86\u8fdb\u4e00\u6b65\u589e\u5f3a\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u7684\u8868\u793a\u80fd\u529b\uff0c\u7279\u522b\u662f\u5f25\u8865\u5176\u5728\u56fe\u50cf\u751f\u6210\u548c\u7ec6\u8282\u589e\u5f3a\u65b9\u9762\u76f8\u5bf9\u4e8e\u751f\u6210\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u7814\u7a76\u8005\u4eec\u8bd5\u56fe\u627e\u5230SSL\u4e0e\u751f\u6210\u6a21\u578b\u4e4b\u95f4\u7684\u8054\u7cfb\u3002\u751f\u6210\u6a21\u578b\u901a\u8fc7\u8fd1\u4f3c\u6570\u636e\u5206\u5e03\u6765\u521b\u5efa\u65b0\u6837\u672c\uff0c\u8fd9\u6697\u793a\u4e86\u5b83\u4eec\u80fd\u5e26\u6765\u5bf9\u539f\u59cb\u89c6\u89c9\u6570\u636e\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u8fd9\u5bf9\u4e8e\u8bc6\u522b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5c06\u6269\u6563\u6a21\u578b\u7684\u6269\u6563\u566a\u58f0\u4e0eSSL\u76f8\u7ed3\u5408\uff0c\u4ee5\u5b66\u4e60\u4e00\u4e2a\u5177\u6709\u7ade\u4e89\u529b\u7684\u8bc6\u522b\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aN-JEPA\uff08\u57fa\u4e8e\u566a\u58f0\u7684JEPA\uff09\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u6269\u6563\u6a21\u578b\u7684\u6269\u6563\u566a\u58f0\u901a\u8fc7\u63a9\u7801\u4ee4\u724c\u7684\u4f4d\u7f6e\u5d4c\u5165\u878d\u5165\u63a9\u7801\u56fe\u50cf\u5efa\u6a21\uff08MIM\uff09\u3002\u6a21\u578b\u8fd8\u91c7\u7528\u4e86\u591a\u5c42\u6b21\u566a\u58f0\u8c03\u5ea6\u4f5c\u4e3a\u4e00\u7cfb\u5217\u7279\u5f81\u589e\u5f3a\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u7814\u7a76\uff0c\u8bc1\u660e\u4e86N-JEPA\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6269\u6563\u6a21\u578b\u7684\u6269\u6563\u566a\u58f0\u7ed3\u5408\u5230\u63a9\u7801\u56fe\u50cf\u5efa\u6a21\uff08MIM\uff09\u4e2d\uff0c\u5e76\u5229\u7528\u4f4d\u7f6e\u5d4c\u5165\u6765\u6574\u5408\u566a\u58f0\uff0cN-JEPA\uff08\u57fa\u4e8e\u566a\u58f0\u7684JEPA\uff09\u80fd\u591f\u6709\u6548\u5730\u589e\u5f3aSSL\u7684\u8868\u793a\u80fd\u529b\uff0c\u5e76\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u8bc6\u522b\u6a21\u578b\u6548\u679c\u3002"}}
{"id": "2507.15260", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15260", "abs": "https://arxiv.org/abs/2507.15260", "authors": ["Jiaqi Han", "Haotian Ye", "Puheng Li", "Minkai Xu", "James Zou", "Stefano Ermon"], "title": "CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers", "comment": "ICCV 2025", "summary": "Diffusion-based generative models have become dominant generators of\nhigh-fidelity images and videos but remain limited by their computationally\nexpensive inference procedures. Existing acceleration techniques either require\nextensive model retraining or compromise significantly on sample quality. This\npaper explores a general, training-free, and model-agnostic acceleration\nstrategy via multi-core parallelism. Our framework views multi-core diffusion\nsampling as an ODE solver pipeline, where slower yet accurate solvers\nprogressively rectify faster solvers through a theoretically justified\ninter-core communication mechanism. This motivates our multi-core training-free\ndiffusion sampling accelerator, CHORDS, which is compatible with various\ndiffusion samplers, model architectures, and modalities. Through extensive\nexperiments, CHORDS significantly accelerates sampling across diverse\nlarge-scale image and video diffusion models, yielding up to 2.1x speedup with\nfour cores, improving by 50% over baselines, and 2.9x speedup with eight cores,\nall without quality degradation. This advancement enables CHORDS to establish a\nsolid foundation for real-time, high-fidelity diffusion generation.", "AI": {"tldr": "CHORDS\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6269\u6563\u6a21\u578b\u52a0\u901f\u6846\u67b6\uff0c\u5229\u7528\u591a\u6838\u5e76\u884c\u6027\u548c\u6838\u95f4\u901a\u4fe1\u6765\u663e\u8457\u63d0\u9ad8\u91c7\u6837\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6837\u672c\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u52a0\u901f\u6280\u672f\u9700\u8981\u5bf9\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u7684\u91cd\u65b0\u8bad\u7ec3\u6216\u5728\u6837\u672c\u8d28\u91cf\u4e0a\u505a\u51fa\u91cd\u5927\u59a5\u534f\uff0c\u800cCHORDS\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u591a\u6838\u5e76\u884c\u6027\u63a2\u7d22\u901a\u7528\u7684\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u52a0\u901f\u7b56\u7565\u3002\u8be5\u6846\u67b6\u5c06\u591a\u6838\u6269\u6563\u91c7\u6837\u89c6\u4e3a\u4e00\u4e2aODE\u6c42\u89e3\u5668\u7ba1\u9053\uff0c\u5176\u4e2d\u8f83\u6162\u4f46\u51c6\u786e\u7684\u6c42\u89e3\u5668\u901a\u8fc7\u7406\u8bba\u4e0a\u5408\u7406\u7684\u6838\u95f4\u901a\u4fe1\u673a\u5236\u9010\u6b65\u6821\u6b63\u8f83\u5feb\u7684\u6c42\u89e3\u5668\u3002", "result": "CHORDS\u5728\u5404\u79cd\u5927\u89c4\u6a21\u56fe\u50cf\u548c\u89c6\u9891\u6269\u6563\u6a21\u578b\u4e2d\u663e\u8457\u52a0\u5feb\u4e86\u91c7\u6837\u901f\u5ea6\uff0c\u5728\u56db\u4e2a\u6838\u5fc3\u7684\u60c5\u51b5\u4e0b\u901f\u5ea6\u63d0\u9ad8\u4e862.1\u500d\uff08\u6bd4\u57fa\u7ebf\u63d0\u9ad8\u4e8650%\uff09\uff0c\u5728\u516b\u4e2a\u6838\u5fc3\u7684\u60c5\u51b5\u4e0b\u901f\u5ea6\u63d0\u9ad8\u4e862.9\u500d\uff0c\u5e76\u4e14\u6ca1\u6709\u8d28\u91cf\u4e0b\u964d\u3002", "conclusion": "CHORDS\u4e3a\u5b9e\u65f6\u3001\u9ad8\u4fdd\u771f\u6269\u6563\u751f\u6210\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.15223", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15223", "abs": "https://arxiv.org/abs/2507.15223", "authors": ["Siqi Chen", "Guoqing Zhang", "Jiahao Lai", "Bingzhi Shen", "Sihong Zhang", "Caixia Dong", "Xuejin Chen", "Yang Li"], "title": "Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel", "comment": null, "summary": "Advancements in 3D vision have increased the impact of blood vessel modeling\non medical applications. However, accurately representing the complex geometry\nand topology of blood vessels remains a challenge due to their intricate\nbranching patterns, curvatures, and irregular shapes. In this study, we propose\na hierarchical part-based frame work for 3D vessel generation that separates\nthe global binary tree-like topology from local geometric details. Our approach\nproceeds in three stages: (1) key graph generation to model the overall\nhierarchical struc ture, (2) vessel segment generation conditioned on geometric\nproperties, and (3) hierarchical vessel assembly by integrating the local\nsegments according to the global key graph. We validate our framework on real\nworld datasets, demonstrating superior performance over existing methods in\nmodeling complex vascular networks. This work marks the first successful\napplication of a part-based generative approach for 3D vessel modeling, setting\na new benchmark for vascular data generation. The code is available at:\nhttps://github.com/CybercatChen/PartVessel.git.", "AI": {"tldr": "\u4e00\u9879\u65b0\u7684\u5206\u5757\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u4e09\u7ef4\u8840\u7ba1\u5efa\u6a21\uff0c\u5728\u5904\u7406\u590d\u6742\u8840\u7ba1\u7f51\u7edc\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e09\u7ef4\u8840\u7ba1\u5efa\u6a21\u4e2d\u7531\u4e8e\u590d\u6742\u7684\u8840\u7ba1\u5206\u652f\u6a21\u5f0f\u3001\u66f2\u7387\u548c\u4e0d\u89c4\u5219\u5f62\u72b6\u800c\u5bfc\u81f4\u7684\u51e0\u4f55\u548c\u62d3\u6251\u8868\u793a\u7684\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5206\u5757\u6846\u67b6\uff0c\u7528\u4e8e\u4e09\u7ef4\u8840\u7ba1\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u5c06\u5168\u5c40\u4e8c\u53c9\u6811\u62d3\u6251\u4e0e\u5c40\u90e8\u51e0\u4f55\u7ec6\u8282\u5206\u79bb\u5f00\u6765\uff0c\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a\u5173\u952e\u56fe\u751f\u6210\u3001\u57fa\u4e8e\u51e0\u4f55\u5c5e\u6027\u7684\u8840\u7ba1\u6bb5\u751f\u6210\u4ee5\u53ca\u901a\u8fc7\u6574\u5408\u5c40\u90e8\u8840\u7ba1\u6bb5\u8fdb\u884c\u5206\u5c42\u8840\u7ba1\u7ec4\u88c5\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u8840\u7ba1\u7f51\u7edc\u5efa\u6a21\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u5206\u5757\u751f\u6210\u65b9\u6cd5\u5728\u4e09\u7ef4\u8840\u7ba1\u5efa\u6a21\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4e3a\u8840\u7ba1\u6570\u636e\u7684\u751f\u6210\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.15274", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15274", "abs": "https://arxiv.org/abs/2507.15274", "authors": ["Matthew J. Bryan", "Felix Schwock", "Azadeh Yazdan-Shahmorad", "Rajesh P N Rao"], "title": "Temporal Basis Function Models for Closed-Loop Neural Stimulation", "comment": null, "summary": "Closed-loop neural stimulation provides novel therapies for neurological\ndiseases such as Parkinson's disease (PD), but it is not yet clear whether\nartificial intelligence (AI) techniques can tailor closed-loop stimulation to\nindividual patients or identify new therapies. Progress requires us to address\na number of translational issues, including sample efficiency, training time,\nand minimizing loop latency such that stimulation may be shaped in response to\nchanging brain activity. We propose temporal basis function models (TBFMs) to\naddress these difficulties, and explore this approach in the context of\nexcitatory optogenetic stimulation. We demonstrate the ability of TBF models to\nprovide a single-trial, spatiotemporal forward prediction of the effect of\noptogenetic stimulation on local field potentials (LFPs) measured in two\nnon-human primates. We further use simulations to demonstrate the use of TBF\nmodels for closed-loop stimulation, driving neural activity towards target\npatterns. The simplicity of TBF models allow them to be sample efficient, rapid\nto train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the\nmodel on 40 sessions of previously published excitatory optogenetic stimulation\ndata. For each session, the model required 15-20min of data collection to\nsuccessfully model the remainder of the session. It achieved a prediction\naccuracy comparable to a baseline nonlinear dynamical systems model that\nrequires hours to train, and superior accuracy to a linear state-space model.\nIn our simulations, it also successfully allowed a closed-loop stimulator to\ncontrol a neural circuit. Our approach begins to bridge the translational gap\nbetween complex AI-based approaches to modeling dynamical systems and the\nvision of using such forward prediction models to develop novel, clinically\nuseful closed-loop stimulation protocols.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u65f6\u95f4\u57fa\u51fd\u6570\u6a21\u578b\uff08TBFM\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u7684\u4e2a\u4f53\u5316\u548c\u65b0\u7597\u6cd5\u53d1\u73b0\u95ee\u9898\u3002TBFM\u80fd\u591f\u9ad8\u6548\u3001\u5feb\u901f\u4e14\u4f4e\u5ef6\u8fdf\u5730\u9884\u6d4b\u548c\u63a7\u5236\u795e\u7ecf\u6d3b\u52a8\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5f00\u53d1\u4e34\u5e8a\u5b9e\u7528\u7684\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u7597\u6cd5\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u5728\u4e2a\u4f53\u5316\u6cbb\u7597\u548c\u8bc6\u522b\u65b0\u7597\u6cd5\u65b9\u9762\u7684\u6311\u6218\u3002\u5c3d\u7ba1\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u4e3a\u5e15\u91d1\u68ee\u75c5\u7b49\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u63d0\u4f9b\u4e86\u65b0\u7684\u6cbb\u7597\u65b9\u6cd5\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u6280\u672f\u662f\u5426\u80fd\u591f\u5b9e\u73b0\u9488\u5bf9\u4e2a\u4f53\u60a3\u8005\u7684\u95ed\u73af\u523a\u6fc0\u5b9a\u5236\uff0c\u6216\u8005\u53d1\u73b0\u65b0\u7684\u6cbb\u7597\u65b9\u6cd5\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u9700\u8981\u89e3\u51b3\u6837\u672c\u6548\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u6700\u5c0f\u5316\u56de\u8def\u5ef6\u8fdf\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u95ee\u9898\uff0c\u4ee5\u786e\u4fdd\u523a\u6fc0\u80fd\u591f\u6839\u636e\u4e0d\u65ad\u53d8\u5316\u7684\u8111\u6d3b\u52a8\u8fdb\u884c\u8c03\u6574\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u63a2\u7d22\u4e86\u4e00\u79cd\u540d\u4e3a\u65f6\u95f4\u57fa\u51fd\u6570\u6a21\u578b\uff08TBFM\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5174\u594b\u6027\u5149\u9057\u4f20\u523a\u6fc0\u7684\u80cc\u666f\u4e0b\u3002\u7814\u7a76\u4eba\u5458\u4f7f\u7528TBFM\u5bf9\u4e24\u4e2a\u975e\u4eba\u7075\u957f\u7c7b\u52a8\u7269\u7684\u5c40\u90e8\u573a\u7535\u4f4d\uff08LFPs\uff09\u8fdb\u884c\u4e86\u524d\u5411\u9884\u6d4b\uff0c\u4ee5\u8bc4\u4f30\u5176\u5bf9\u5149\u9057\u4f20\u523a\u6fc0\u6548\u679c\u7684\u9884\u6d4b\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5c55\u793a\u4e86TBFM\u5728\u95ed\u73af\u523a\u6fc0\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u5f15\u5bfc\u795e\u7ecf\u6d3b\u52a8\u8fbe\u5230\u76ee\u6807\u6a21\u5f0f\u3002\u8be5\u6a21\u578b\u5728\u5b9e\u9645\u6570\u636e\u548c\u6a21\u62df\u6570\u636e\u4e0a\u90fd\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u6a21\u578b\u548c\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "TBFM\u80fd\u591f\u5bf9\u5149\u9057\u4f20\u523a\u6fc0\u5bf9\u5c40\u90e8\u573a\u7535\u4f4d\uff08LFPs\uff09\u4ea7\u751f\u5355\u6b21PerTrial\uff08single-trial\uff09\u3001\u65f6\u7a7a\uff08spatiotemporal\uff09\u7684\u524d\u5411\u9884\u6d4b\u3002\u7814\u7a76\u4eba\u5458\u5728\u4e24\u4e2a\u975e\u4eba\u7075\u957f\u7c7b\u52a8\u7269\u7684\u5b9e\u9a8c\u6570\u636e\u4e2d\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u70b9\u3002\u6b64\u5916\uff0c\u6a21\u62df\u7ed3\u679c\u8868\u660eTBFM\u53ef\u7528\u4e8e\u95ed\u73af\u523a\u6fc0\uff0c\u4ee5\u9a71\u52a8\u795e\u7ecf\u6d3b\u52a8\u8d8b\u5411\u4e8e\u76ee\u6807\u6a21\u5f0f\u3002TBFM\u6a21\u578b\u5177\u6709\u6837\u672c\u6548\u7387\u9ad8\u3001\u8bad\u7ec3\u901f\u5ea6\u5feb\uff082-4\u5206\u949f\uff09\u548c\u5ef6\u8fdf\u4f4e\uff080.2\u6beb\u79d2\uff09\u7684\u7279\u70b9\u3002\u5728\u5bf940\u4e2a\u5df2\u53d1\u8868\u7684\u5174\u594b\u6027\u5149\u9057\u4f20\u523a\u6fc0\u6570\u636e\u7684\u5206\u6790\u4e2d\uff0cTBFM\u5728\u6bcf\u4e2a\u6837\u672c\u4e2d\u4ec5\u970015-20\u5206\u949f\u7684\u6570\u636e\u6536\u96c6\u5373\u53ef\u6210\u529f\u6a21\u62df\u5269\u4f59\u90e8\u5206\u7684\u6570\u636e\uff0c\u5176\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u9700\u8981\u6570\u5c0f\u65f6\u8bad\u7ec3\u7684\u57fa\u7ebf\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u6a21\u578b\u76f8\u5f53\uff0c\u5e76\u4f18\u4e8e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002\u5728\u6a21\u62df\u4e2d\uff0cTBFM\u6210\u529f\u9a71\u52a8\u4e86\u4e00\u4e2a\u95ed\u73af\u523a\u6fc0\u5668\u6765\u63a7\u5236\u4e00\u4e2a\u795e\u7ecf\u56de\u8def\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u65f6\u95f4\u57fa\u51fd\u6570\u6a21\u578b\uff08TBFM\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u5728\u4e2a\u4f53\u5316\u6cbb\u7597\u548c\u65b0\u7597\u6cd5\u8bc6\u522b\u65b9\u9762\u7684\u6311\u6218\u3002\u7814\u7a76\u8868\u660e\uff0cTBFM\u5728\u9884\u6d4b\u5149\u9057\u4f20\u523a\u6fc0\u5bf9\u5c40\u90e8\u573a\u7535\u4f4d\uff08LFPs\uff09\u7684\u5f71\u54cd\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u6a21\u62df\u4e2d\u80fd\u591f\u5b9e\u73b0\u95ed\u73af\u523a\u6fc0\u4ee5\u63a7\u5236\u795e\u7ecf\u6d3b\u52a8\u3002\u8be5\u6a21\u578b\u5177\u6709\u6837\u672c\u6548\u7387\u9ad8\u3001\u8bad\u7ec3\u901f\u5ea6\u5feb\uff082-4\u5206\u949f\uff09\u548c\u5ef6\u8fdf\u4f4e\uff080.2\u6beb\u79d2\uff09\u7684\u4f18\u70b9\uff0c\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u53ef\u4e0e\u590d\u6742\u7684\u57fa\u7ebf\u6a21\u578b\u76f8\u5ab2\u7f8e\uff0c\u5e76\u4f18\u4e8e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5229\u7528\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u7597\u6cd5\u5728\u4e34\u5e8a\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15227", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15227", "abs": "https://arxiv.org/abs/2507.15227", "authors": ["Krishna Kanth Nakka"], "title": "Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders", "comment": "Preprint. Under review", "summary": "Interpretability is critical in high-stakes domains such as medical imaging,\nwhere understanding model decisions is essential for clinical adoption. In this\nwork, we introduce Sparse Autoencoder (SAE)-based interpretability to breast\nimaging by analyzing {Mammo-CLIP}, a vision--language foundation model\npretrained on large-scale mammogram image--report pairs. We train a patch-level\n\\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features\nassociated with clinically relevant breast concepts such as \\textit{mass} and\n\\textit{suspicious calcification}. Our findings reveal that top activated class\nlevel latent neurons in the SAE latent space often tend to align with ground\ntruth regions, and also uncover several confounding factors influencing the\nmodel's decision-making process. Additionally, we analyze which latent neurons\nthe model relies on during downstream finetuning for improving the breast\nconcept prediction. This study highlights the promise of interpretable SAE\nlatent representations in providing deeper insight into the internal workings\nof foundation models at every layer for breast imaging.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668 (SAE) \u7684\u53ef\u89e3\u91ca\u6027\u5e94\u7528\u4e8e\u4e73\u817a\u6210\u50cf\u7684 Mammo-CLIP \u6a21\u578b\uff0c\u8bc6\u522b\u4e0e\u201c\u80bf\u5757\u201d\u548c\u201c\u53ef\u7591\u9499\u5316\u201d\u7b49\u4e34\u5e8a\u6982\u5ff5\u76f8\u5173\u7684\u6f5c\u5728\u7279\u5f81\uff0c\u53d1\u73b0\u795e\u7ecf\u5143\u4e0e\u771f\u5b9e\u533a\u57df\u5bf9\u9f50\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u51b3\u7b56\u4e2d\u7684\u6df7\u6742\u56e0\u7d20\u3002", "motivation": "\u53ef\u89e3\u91ca\u6027\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u5b66\u6210\u50cf\uff09\u81f3\u5173\u91cd\u8981\uff0c\u5728\u8fd9\u4e9b\u9886\u57df\uff0c\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u5bf9\u4e8e\u4e34\u5e8a\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u5206\u6790\u5728\u5927\u91cf\u4e73\u817aX\u7ebf\u7167\u7247\u56fe\u50cf-\u62a5\u544a\u5bf9\u4e0a\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00\u57fa\u7840\u6a21\u578b Mammo-CLIP\uff0c\u5c06\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668 (SAE) \u7684\u53ef\u89e3\u91ca\u6027\u5f15\u5165\u4e73\u817a\u6210\u50cf\u3002\u6211\u4eec\u9488\u5bf9 Mammo-CLIP \u8bad\u7ec3\u4e86\u4e00\u4e2a\u8865\u4e01\u7ea7\u522b\u7684 Mammo-SAE\uff0c\u4ee5\u8bc6\u522b\u548c\u63a2\u6d4b\u4e0e\u4e34\u5e8a\u76f8\u5173\u4e73\u817a\u6982\u5ff5\uff08\u5982\u201c\u80bf\u5757\u201d\u548c\u201c\u53ef\u7591\u9499\u5316\u201d\uff09\u76f8\u5173\u7684\u6f5c\u5728\u7279\u5f81\u3002", "result": "\u6211\u4eec\u7684\u53d1\u73b0\u63ed\u793a\u4e86 SAE \u6f5c\u5728\u7a7a\u95f4\u4e2d\u9876\u90e8\u6fc0\u6d3b\u7684\u7c7b\u522b\u7ea7\u6f5c\u5728\u795e\u7ecf\u5143\u901a\u5e38\u4e0e\u5730\u9762\u771f\u5b9e\u533a\u57df\u5bf9\u9f50\uff0c\u5e76\u63ed\u793a\u4e86\u5f71\u54cd\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u51e0\u4e2a\u6df7\u6742\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5206\u6790\u4e86\u6a21\u578b\u5728\u4e0b\u6e38\u5fae\u8c03\u4ee5\u6539\u8fdb\u4e73\u817a\u6982\u5ff5\u9884\u6d4b\u65f6\u6240\u4f9d\u8d56\u7684\u6f5c\u5728\u795e\u7ecf\u5143\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u7a81\u663e\u4e86\u53ef\u89e3\u91ca\u7684 SAE \u6f5c\u5728\u8868\u5f81\u5728\u4e3a\u4e73\u817a\u6210\u50cf\u7684\u5404\u79cd\u5c42\u9762\u7684\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u6d1e\u5bdf\u65b9\u9762\u6240\u5c55\u73b0\u51fa\u7684\u524d\u666f\u3002"}}
{"id": "2507.15280", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15280", "abs": "https://arxiv.org/abs/2507.15280", "authors": ["Shaofei Shen", "Chenhao Zhang", "Yawen Zhao", "Alina Bialkowski", "Weitong Chen", "Miao Xu"], "title": "Machine Unlearning for Streaming Forgetting", "comment": null, "summary": "Machine unlearning aims to remove knowledge of the specific training data in\na well-trained model. Currently, machine unlearning methods typically handle\nall forgetting data in a single batch, removing the corresponding knowledge all\nat once upon request. However, in practical scenarios, requests for data\nremoval often arise in a streaming manner rather than in a single batch,\nleading to reduced efficiency and effectiveness in existing methods. Such\nchallenges of streaming forgetting have not been the focus of much research. In\nthis paper, to address the challenges of performance maintenance, efficiency,\nand data access brought about by streaming unlearning requests, we introduce a\nstreaming unlearning paradigm, formalizing the unlearning as a distribution\nshift problem. We then estimate the altered distribution and propose a novel\nstreaming unlearning algorithm to achieve efficient streaming forgetting\nwithout requiring access to the original training data. Theoretical analyses\nconfirm an $O(\\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,\nwhere $V_T$ represents the cumulative total variation in the optimal solution\nover $T$ learning rounds. This theoretical guarantee is achieved under mild\nconditions without the strong restriction of convex loss function. Experiments\nacross various models and datasets validate the performance of our proposed\nmethod.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5904\u7406\u6d41\u5f0f\u6570\u636e\u5220\u9664\u8bf7\u6c42\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b0\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u4e00\u6b21\u6027\u5904\u7406\u6240\u6709\u9057\u5fd8\u6570\u636e\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u5b9e\u9645\u573a\u666f\u4e2d\u51fa\u73b0\u7684\u6d41\u5f0f\u6570\u636e\u5220\u9664\u8bf7\u6c42\uff0c\u5bfc\u81f4\u6548\u7387\u548c\u6548\u679c\u4e0b\u964d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u6d41\u5f0f\u9057\u5fd8\u5e26\u6765\u7684\u6027\u80fd\u7ef4\u6301\u3001\u6548\u7387\u548c\u6570\u636e\u8bbf\u95ee\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u9057\u5fd8\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5206\u5e03\u504f\u79fb\u95ee\u9898\u7684\u6d41\u5f0f\u9057\u5fd8\u8303\u5f0f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u5f0f\u9057\u5fd8\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u4e0d\u8bbf\u95ee\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u6d41\u5f0f\u9057\u5fd8\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u5728\u6d41\u5f0f\u9057\u5fd8\u7684\u9057\u61be\uff08regret\uff09\u4e0a\u5b58\u5728 O(\u221aT + V_T) \u7684\u8bef\u5dee\u754c\u9650\uff0c\u5176\u4e2d V_T \u662f T \u4e2a\u5b66\u4e60\u8f6e\u6b21\u4e2d\u7d2f\u79ef\u7684\u603b\u53d8\u5f02\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d41\u5f0f\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u7b97\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u5904\u7406\u6d41\u5f0f\u6570\u636e\u5220\u9664\u8bf7\u6c42\uff0c\u5e76\u4e14\u65e0\u9700\u8bbf\u95ee\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u3002\u901a\u8fc7\u5c06\u9057\u5fd8\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u8bef\u5dee\u754c\u9650\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.15243", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15243", "abs": "https://arxiv.org/abs/2507.15243", "authors": ["Naeem Paeedeh", "Mahardhika Pratama", "Wolfgang Mayer", "Jimmy Cao", "Ryszard Kowlczyk"], "title": "Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation", "comment": null, "summary": "Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model\npre-trained with DINO combined with a prototypical classifier outperforms the\nlatest SOTA methods. A crucial limitation that needs to be overcome is that\nupdating too many parameters of the transformers leads to overfitting due to\nthe scarcity of labeled samples. To address this challenge, we propose a new\nconcept, Coalescent Projection (CP), as an effective successor to soft prompts.\nAdditionally, we propose a novel pseudo-class generation method combined with\nSelf-Supervised Transformations (SSTs) that relies solely on the base domain to\nprepare the network for encountering unseen samples from different domains. The\nproposed method exhibits its effectiveness in comprehensive experiments on the\nextreme domain shift scenario of the BSCD-FSL benchmark. Our code is published\nat https://github.com/Naeem-Paeedeh/CPLSR.", "AI": {"tldr": "A new method using Coalescent Projection and Self-Supervised Transformations improves Cross-Domain Few-Shot Learning by reducing overfitting and adapting to new domains using only base data, outperforming existing approaches.", "motivation": "Existing Cross-Domain Few-Shot Learning (CD-FSL) methods, even those using DINO pre-training, struggle with overfitting when updating a large number of transformer parameters due to limited labeled samples. This limits their effectiveness in handling unseen data from different domains.", "method": "The paper proposes Coalescent Projection (CP) as a replacement for soft prompts and introduces a novel pseudo-class generation method combined with Self-Supervised Transformations (SSTs). These methods are designed to prepare the network for unseen samples from different domains by updating fewer parameters and leveraging only base domain data to avoid overfitting.", "result": "The proposed method, utilizing Coalescent Projection (CP) and Self-Supervised Transformations (SSTs), demonstrates effectiveness in comprehensive experiments, particularly in the extreme domain shift scenario of the BSCD-FSL benchmark. It outperforms current state-of-the-art methods.", "conclusion": "Coalescent Projection (CP) and Self-Supervised Transformations (SSTs) effectively address overfitting in Cross-Domain Few-Shot Learning (CD-FSL) by enabling network adaptation using only base domain data, outperforming prior methods in extreme domain shift scenarios."}}
{"id": "2507.15287", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15287", "abs": "https://arxiv.org/abs/2507.15287", "authors": ["Elias Malomgr\u00e9", "Pieter Simoens"], "title": "Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning", "comment": "10 pages, 8 figures, accepted for the non-archival workshop \"Workshop\n  on Reinforcement Learning Beyond Rewards @ Reinforcement Learning Conference\n  2025\"", "summary": "Recent trends in Reinforcement Learning (RL) highlight the need for agents to\nlearn from reward-free interactions and alternative supervision signals, such\nas unlabeled or incomplete demonstrations, rather than relying solely on\nexplicit reward maximization. Additionally, developing generalist agents that\ncan adapt efficiently in real-world environments often requires leveraging\nthese reward-free signals to guide learning and behavior. However, while\nintrinsic motivation techniques provide a means for agents to seek out novel or\nuncertain states in the absence of explicit rewards, they are often challenged\nby dense reward environments or the complexity of high-dimensional state and\naction spaces. Furthermore, most existing approaches rely directly on the\nunprocessed intrinsic reward signals, which can make it difficult to shape or\ncontrol the agent's exploration effectively. We propose a framework that can\neffectively utilize expert demonstrations, even when they are incomplete and\nimperfect. By applying a mapping function to transform the similarity between\nan agent's state and expert data into a shaped intrinsic reward, our method\nallows for flexible and targeted exploration of expert-like behaviors. We\nemploy a Mixture of Autoencoder Experts to capture a diverse range of behaviors\nand accommodate missing information in demonstrations. Experiments show our\napproach enables robust exploration and strong performance in both sparse and\ndense reward environments, even when demonstrations are sparse or incomplete.\nThis provides a practical framework for RL in realistic settings where optimal\ndata is unavailable and precise reward control is needed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4e0d\u5b8c\u6574\u4e13\u5bb6\u6f14\u793a\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u72b6\u6001\u76f8\u4f3c\u6027\u8f6c\u5316\u4e3a\u5185\u5728\u5956\u52b1\uff0c\u5b9e\u73b0\u7075\u6d3b\u63a2\u7d22\uff0c\u5e76\u5728\u5404\u79cd\u73af\u5883\u4e0b\u5747\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4e3a\u4e86\u5728\u6ca1\u6709\u663e\u5f0f\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u5956\u52b1\u7684\u5185\u5728\u52a8\u673a\u6280\u672f\u6765\u5b66\u4e60\uff0c\u5e76\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u667a\u80fd\u4f53\uff0c\u5229\u7528\u4e0d\u5b8c\u6574\u7684\u6f14\u793a\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u72b6\u6001\u4e0e\u4e13\u5bb6\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6620\u5c04\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6709\u754c\u7684\u5185\u5728\u5956\u52b1\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u4e13\u5bb6\u884c\u4e3a\u7684\u7075\u6d3b\u548c\u6709\u9488\u5bf9\u6027\u7684\u63a2\u7d22\u3002\u91c7\u7528\u6df7\u5408\u81ea\u52a8\u7f16\u7801\u5668\u4e13\u5bb6\u6a21\u578b\u6765\u6355\u6349\u591a\u6837\u7684\u884c\u4e3a\u5e76\u9002\u5e94\u6f14\u793a\u4e2d\u7684\u7f3a\u5931\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7a00\u758f\u548c\u5bc6\u96c6\u5956\u52b1\u73af\u5883\u4e0b\u90fd\u80fd\u591f\u8fdb\u884c\u9c81\u68d2\u7684\u63a2\u7d22\u5e76\u53d6\u5f97\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u6f14\u793a\u7a00\u758f\u6216\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u65e0\u6700\u4f18\u6570\u636e\u548c\u9700\u8981\u7cbe\u786e\u5956\u52b1\u63a7\u5236\u7684\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u6846\u67b6\u3002"}}
{"id": "2507.15249", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15249", "abs": "https://arxiv.org/abs/2507.15249", "authors": ["Yanbing Zhang", "Zhe Wang", "Qin Zhou", "Mengping Yang"], "title": "FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers", "comment": "Accepted by ICCV 2025", "summary": "In light of recent breakthroughs in text-to-image (T2I) generation,\nparticularly with diffusion transformers (DiT), subject-driven technologies are\nincreasingly being employed for high-fidelity customized production that\npreserves subject identity from reference inputs, enabling thrilling design\nworkflows and engaging entertainment. Existing alternatives typically require\neither per-subject optimization via trainable text embeddings or training\nspecialized encoders for subject feature extraction on large-scale datasets.\nSuch dependencies on training procedures fundamentally constrain their\npractical applications. More importantly, current methodologies fail to fully\nleverage the inherent zero-shot potential of modern diffusion transformers\n(e.g., the Flux series) for authentic subject-driven synthesis. To bridge this\ngap, we propose FreeCus, a genuinely training-free framework that activates\nDiT's capabilities through three key innovations: 1) We introduce a pivotal\nattention sharing mechanism that captures the subject's layout integrity while\npreserving crucial editing flexibility. 2) Through a straightforward analysis\nof DiT's dynamic shifting, we propose an upgraded variant that significantly\nimproves fine-grained feature extraction. 3) We further integrate advanced\nMultimodal Large Language Models (MLLMs) to enrich cross-modal semantic\nrepresentations. Extensive experiments reflect that our method successfully\nunlocks DiT's zero-shot ability for consistent subject synthesis across diverse\ncontexts, achieving state-of-the-art or comparable results compared to\napproaches that require additional training. Notably, our framework\ndemonstrates seamless compatibility with existing inpainting pipelines and\ncontrol modules, facilitating more compelling experiences. Our code is\navailable at: https://github.com/Monalissaa/FreeCus.", "AI": {"tldr": "FreeCus\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5171\u4eab\u3001\u6539\u8fdb\u7684\u7279\u5f81\u63d0\u53d6\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u9501\u4e86\u6269\u6563Transformer\uff08DiT\uff09\u5728\u4e3b\u9898\u9a71\u52a8\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u8fbe\u5230\u4e86\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u751f\u6210\u6280\u672f\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u6269\u6563Transformer\uff08DiT\uff09\u7684\u4e3b\u9898\u9a71\u52a8\u6280\u672f\uff0c\u867d\u7136\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5b9a\u5236\u5316\u751f\u4ea7\uff0c\u4f46\u901a\u5e38\u9700\u8981\u8fdb\u884c\u6bcf\u4e3b\u4f53\u4f18\u5316\u6216\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e13\u7528\u7f16\u7801\u5668\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u6b64\u5916\uff0c\u5f53\u524d\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u73b0\u4ee3\u6269\u6563Transformer\uff08\u5982Flux\u7cfb\u5217\uff09\u56fa\u6709\u7684\u96f6\u6837\u672c\u6f5c\u529b\u6765\u5b9e\u73b0\u771f\u5b9e\u7684\u4e3b\u9898\u9a71\u52a8\u5408\u6210\u3002", "method": "FreeCus\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u6fc0\u6d3bDiT\u7684\u80fd\u529b\uff1a1\uff09\u5f15\u5165\u5173\u952e\u7684\u6ce8\u610f\u529b\u5171\u4eab\u673a\u5236\uff0c\u4ee5\u6355\u6349\u4e3b\u4f53\u7684\u5e03\u5c40\u5b8c\u6574\u6027\u5e76\u4fdd\u7559\u7f16\u8f91\u7684\u7075\u6d3b\u6027\u30022\uff09\u901a\u8fc7\u5bf9DiT\u7684\u52a8\u6001\u79fb\u4f4d\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u53d8\u4f53\uff0c\u4ee5\u589e\u5f3a\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u30023\uff09\u96c6\u6210\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4ee5\u4e30\u5bcc\u8de8\u6a21\u6001\u8bed\u4e49\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFreeCus\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u8de8\u591a\u79cd\u573a\u666f\u4e0b\u7684\u4e00\u81f4\u6027\u4e3b\u4f53\u5408\u6210\uff0c\u5e76\u4e14\u4e0e\u73b0\u6709\u56fe\u50cf\u4fee\u590d\u7ba1\u7ebf\u548c\u63a7\u5236\u6a21\u5757\u517c\u5bb9\u3002", "conclusion": "FreeCus\u6846\u67b6\u6210\u529f\u89e3\u9501\u4e86DiT\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u8de8\u591a\u79cd\u573a\u666f\u4e0b\u7684\u4e00\u81f4\u6027\u4e3b\u4f53\u5408\u6210\uff0c\u5e76\u53d6\u5f97\u4e86\u4e0e\u9700\u8981\u989d\u5916\u8bad\u7ec3\u7684\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u4e0e\u73b0\u6709\u7684\u56fe\u50cf\u4fee\u590d\u7ba1\u7ebf\u548c\u63a7\u5236\u6a21\u5757\u517c\u5bb9\uff0c\u53ef\u7528\u4e8e\u521b\u9020\u66f4\u5177\u5438\u5f15\u529b\u7684\u4f53\u9a8c\u3002"}}
{"id": "2507.15288", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15288", "abs": "https://arxiv.org/abs/2507.15288", "authors": ["Omid G. Sani", "Maryam M. Shanechi"], "title": "Preferential subspace identification (PSID) with forward-backward smoothing", "comment": "17 pages, 5 figures", "summary": "System identification methods for multivariate time-series, such as neural\nand behavioral recordings, have been used to build models for predicting one\nfrom the other. For example, Preferential Subspace Identification (PSID) builds\na state-space model of a primary time-series (e.g., neural activity) to\noptimally predict a secondary time-series (e.g., behavior). However, PSID\nfocuses on optimal prediction using past primary data, even though in offline\napplications, better estimation can be achieved by incorporating concurrent\ndata (filtering) or all available data (smoothing). Here, we extend PSID to\nenable optimal filtering and smoothing. First, we show that the presence of a\nsecondary signal makes it possible to uniquely identify a model with an optimal\nKalman update step (to enable filtering) from a family of otherwise equivalent\nstate-space models. Our filtering solution augments PSID with a reduced-rank\nregression step that directly learns the optimal gain required for the update\nstep from data. We refer to this extension of PSID as PSID with filtering.\nSecond, inspired by two-filter Kalman smoother formulations, we develop a novel\nforward-backward PSID smoothing algorithm where we first apply PSID with\nfiltering and then apply it again in the reverse time direction on the\nresiduals of the filtered secondary signal. We validate our methods on\nsimulated data, showing that our approach recovers the ground-truth model\nparameters for filtering, and achieves optimal filtering and smoothing decoding\nperformance of the secondary signal that matches the ideal performance of the\ntrue underlying model. This work provides a principled framework for optimal\nlinear filtering and smoothing in the two-signal setting, significantly\nexpanding the toolkit for analyzing dynamic interactions in multivariate\ntime-series.", "AI": {"tldr": "PSID\u7684\u6269\u5c55\uff0c\u7528\u4e8e\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u7684\u6ee4\u6ce2\u548cSmoothing\u3002", "motivation": "\u867d\u7136\u73b0\u6709\u7684\u504f\u597d\u5b50\u7a7a\u95f4\u8bc6\u522b\uff08PSID\uff09\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u5229\u7528\u8fc7\u53bb\u7684\u521d\u7ea7\u6570\u636e\u8fdb\u884c\u6700\u4f18\u9884\u6d4b\uff0c\u4f46\u672c\u6587\u8ba4\u4e3a\uff0c\u5728\u79bb\u7ebf\u5e94\u7528\u4e2d\uff0c\u901a\u8fc7\u6574\u5408\u5e76\u53d1\u6570\u636e\uff08\u6ee4\u6ce2\uff09\u6216\u6240\u6709\u53ef\u7528\u6570\u636e\uff08\u5e73\u6ed1\uff09\u53ef\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u4f30\u8ba1\u3002", "method": "\u672c\u6587\u9996\u5148\u8868\u660e\uff0c\u6b21\u7ea7\u4fe1\u53f7\u7684\u5b58\u5728\u4f7f\u5f97\u53ef\u4ee5\u4ece\u4e00\u7ec4\u540c\u6837\u4f18\u5316\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\u552f\u4e00\u5730\u8bc6\u522b\u51fa\u4e00\u4e2a\u5177\u6709\u6700\u4f18\u5361\u5c14\u66fc\u66f4\u65b0\u6b65\u9aa4\uff08\u4ee5\u5b9e\u73b0\u6ee4\u6ce2\uff09\u7684\u6a21\u578b\u3002\u6211\u4eec\u7684\u6ee4\u6ce2\u89e3\u51b3\u65b9\u6848\u901a\u8fc7\u4e00\u4e2a\u964d\u79e9\u56de\u5f52\u6b65\u9aa4\u6765\u589e\u5f3aPSID\uff0c\u8be5\u6b65\u9aa4\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u66f4\u65b0\u6b65\u9aa4\u6240\u9700\u7684\u6700\u4f18\u589e\u76ca\u3002\u6211\u4eec\u5c06\u6b64PSID\u6269\u5c55\u79f0\u4e3a\u5e26\u6ee4\u6ce2\u7684PSID\u3002\u5176\u6b21\uff0c\u53d7\u53cc\u6ee4\u6ce2\u5361\u5c14\u66fc\u5e73\u6ed1\u5668\u914d\u65b9\u7684\u542f\u53d1\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u524d\u5411-\u540e\u5411PSID\u5e73\u6ed1\u7b97\u6cd5\uff0c\u5176\u4e2d\u6211\u4eec\u9996\u5148\u5e94\u7528\u5e26\u6ee4\u6ce2\u7684PSID\uff0c\u7136\u540e\u5728\u8fc7\u6ee4\u540e\u7684\u6b21\u7ea7\u4fe1\u53f7\u7684\u6b8b\u5dee\u4e0a\u518d\u6b21\u53cd\u5411\u5e94\u7528\u5b83\u3002", "result": "\u6211\u4eec\u901a\u8fc7\u6a21\u62df\u6570\u636e\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6062\u590d\u51fa\u6ee4\u6ce2\u95ee\u9898\u7684\u771f\u5b9e\u6a21\u578b\u53c2\u6570\uff0c\u5e76\u5b9e\u73b0\u6b21\u7ea7\u4fe1\u53f7\u7684\u6700\u4f18\u6ee4\u6ce2\u548cSmoothing\u89e3\u7801\u6027\u80fd\uff0c\u4e0e\u771f\u5b9e\u6a21\u578b\u7406\u60f3\u6027\u80fd\u76f8\u5339\u914d\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u53cc\u4fe1\u53f7\u573a\u666f\u4e0b\u7684\u6700\u4f18\u7ebf\u6027\u6ee4\u6ce2\u548cSmoothing\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u663e\u8457\u6269\u5c55\u4e86\u5206\u6790\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u52a8\u6001\u4ea4\u4e92\u7684\u5de5\u5177\u96c6\u3002"}}
{"id": "2507.15257", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15257", "abs": "https://arxiv.org/abs/2507.15257", "authors": ["Pei An", "Jiaqi Yang", "Muyao Peng", "You Yang", "Qiong Liu", "Xiaolin Wu", "Liangliang Nan"], "title": "MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP", "comment": "Accepted by ICCV 2025", "summary": "Image-to-point-cloud (I2P) registration is a fundamental problem in computer\nvision, focusing on establishing 2D-3D correspondences between an image and a\npoint cloud. The differential perspective-n-point (PnP) has been widely used to\nsupervise I2P registration networks by enforcing the projective constraints on\n2D-3D correspondences. However, differential PnP is highly sensitive to noise\nand outliers in the predicted correspondences. This issue hinders the\neffectiveness of correspondence learning. Inspired by the robustness of blind\nPnP against noise and outliers in correspondences, we propose an approximated\nblind PnP based correspondence learning approach. To mitigate the high\ncomputational cost of blind PnP, we simplify blind PnP to an amenable task of\nminimizing Chamfer distance between learned 2D and 3D keypoints, called\nMinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task\nlearning module, named as MinCD-Net, which can be easily integrated into the\nexisting I2P registration architectures. Extensive experiments on 7-Scenes,\nRGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net\noutperforms state-of-the-art methods and achieves a higher inlier ratio (IR)\nand registration recall (RR) in both cross-scene and cross-dataset settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MinCD-Net \u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u56fe\u50cf\u5230\u70b9\u4e91\u914d\u51c6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316 2D \u548c 3D \u5173\u952e\u70b9\u4e4b\u95f4\u7684 Chamfer \u8ddd\u79bb\u6765\u89e3\u51b3 PnP \u7684\u654f\u611f\u6027\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5dee\u5206 PnP \u5bf9\u9884\u6d4b\u7684\u5bf9\u5e94\u5173\u7cfb\u4e2d\u7684\u566a\u58f0\u548c\u79bb\u7fa4\u503c\u654f\u611f\u7684\u95ee\u9898\uff0c\u4ece\u800c\u963b\u788d\u4e86\u5bf9\u5e94\u5173\u7cfb\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd1\u4f3c\u76f2 PnP \u7684\u5bf9\u5e94\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5b66\u4e60\u5230\u7684 2D \u548c 3D \u5173\u952e\u70b9\u4e4b\u95f4\u7684 Chamfer \u8ddd\u79bb\uff08MinCD-PnP\uff09\u6765\u89e3\u51b3\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3a MinCD-Net \u7684\u8f7b\u91cf\u7ea7\u591a\u4efb\u52a1\u5b66\u4e60\u6a21\u5757\u3002", "result": "MinCD-Net \u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u8de8\u573a\u666f\u548c\u8de8\u6570\u636e\u96c6\u7684\u8bbe\u7f6e\u4e2d\uff0c\u5728 7-Scenes\u3001RGBD-V2\u3001ScanNet \u548c\u81ea\u6536\u96c6\u6570\u636e\u96c6\u4e0a\u5747\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5185\u70b9\u7387 (IR) \u548c\u914d\u51c6\u53ec\u56de\u7387 (RR)\u3002", "conclusion": "MinCD-Net \u5728\u8de8\u573a\u666f\u548c\u8de8\u6570\u636e\u96c6\u7684\u8bbe\u7f6e\u4e2d\uff0c\u5728 7-Scenes\u3001RGBD-V2\u3001ScanNet \u548c\u81ea\u6536\u96c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5185\u70b9\u7387 (IR) \u548c\u914d\u51c6\u53ec\u56de\u7387 (RR)\u3002"}}
{"id": "2507.15290", "categories": ["cs.LG", "I.2.6; I.2.0"], "pdf": "https://arxiv.org/pdf/2507.15290", "abs": "https://arxiv.org/abs/2507.15290", "authors": ["Emile Anand", "Sarah Liaw"], "title": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown", "comment": "39 pages, 2 figures, 36 tables", "summary": "Thompson Sampling (TS) is widely used to address the exploration/exploitation\ntradeoff in contextual bandits, yet recent theory shows that it does not\nexplore aggressively enough in high-dimensional problems. Feel-Good Thompson\nSampling (FG-TS) addresses this by adding an optimism bonus that biases toward\nhigh-reward models, and it achieves the asymptotically minimax-optimal regret\nin the linear setting when posteriors are exact. However, its performance with\n\\emph{approximate} posteriors -- common in large-scale or neural problems --\nhas not been benchmarked. We provide the first systematic study of FG-TS and\nits smoothed variant (SFG-TS) across eleven real-world and synthetic\nbenchmarks. To evaluate their robustness, we compare performance across\nsettings with exact posteriors (linear and logistic bandits) to approximate\nregimes produced by fast but coarse stochastic-gradient samplers. Ablations\nover preconditioning, bonus scale, and prior strength reveal a trade-off:\nlarger bonuses help when posterior samples are accurate, but hurt when sampling\nnoise dominates. FG-TS generally outperforms vanilla TS in linear and logistic\nbandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS\nand its variants are competitive and easy-to-use, we recommend them as\nbaselines in modern contextual-bandit benchmarks. Finally, we provide source\ncode for all our experiments in\nhttps://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.", "AI": {"tldr": "FG-TS\u662f\u4e00\u79cd\u7528\u4e8e\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7684\u7b97\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u9ad8\u7ef4\u95ee\u9898\u4e2d\u7684\u63a2\u7d22/\u5229\u7528\u6743\u8861\u95ee\u9898\u3002\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u5730\u7814\u7a76\u4e86FG-TS\u53ca\u5176\u5e73\u6ed1\u53d8\u4f53\uff08SFG-TS\uff09\u7684\u6027\u80fd\uff0c\u5e76\u5c06\u5176\u4e0e\u6807\u51c6TS\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7814\u7a76\u53d1\u73b0\uff0cFG-TS\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f18\u4e8eTS\uff0c\u4f46\u5e76\u975e\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u5982\u6b64\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u4f1a\u53d7\u5230\u540e\u9a8c\u6837\u672c\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u586b\u8865FG-TS\u5728\u8fd1\u4f3c\u540e\u9a8c\uff08\u5e38\u89c1\u4e8e\u5927\u89c4\u6a21\u6216\u795e\u7ecf\u95ee\u9898\uff09\u4e0b\u7684\u6027\u80fd\u8bc4\u4f30\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5728\u5341\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5bf9FG-TS\u53ca\u5176\u5e73\u6ed1\u53d8\u4f53\uff08SFG-TS\uff09\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u5e76\u4e0e\u5177\u6709\u7cbe\u786e\u540e\u9a8c\uff08\u7ebf\u6027/\u903b\u8f91\u8001\u864e\u673a\uff09\u548c\u8fd1\u4f3c\u540e\u9a8c\uff08\u795e\u7ecf\u8001\u864e\u673a\uff09\u7684\u8bbe\u7f6e\u8fdb\u884c\u6bd4\u8f83\u6765\u8bc4\u4f30\u5176\u7a33\u5065\u6027\u3002", "result": "FG-TS\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u6807\u51c6TS\uff0c\u4f46\u5728\u795e\u7ecf\u8001\u864e\u673a\u4e2d\u8868\u73b0\u8f83\u5f31\u3002\u5bf9\u9884\u5904\u7406\u3001\u5956\u52b1\u7f29\u653e\u548c\u5148\u9a8c\u5f3a\u5ea6\u8fdb\u884c\u7684\u5206\u6790\u63ed\u793a\u4e86\u4e00\u4e2a\u6743\u8861\uff1a\u5f53\u540e\u9a8c\u6837\u672c\u51c6\u786e\u65f6\uff0c\u8f83\u5927\u7684\u5956\u52b1\u6709\u52a9\u4e8e\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u5728\u91c7\u6837\u566a\u58f0\u5360\u4e3b\u5bfc\u5730\u4f4d\u65f6\uff0c\u5219\u4f1a\u635f\u5bb3\u6027\u80fd\u3002", "conclusion": "FG-TS\u53ca\u5176\u53d8\u4f53\u5728\u73b0\u4ee3\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u4e14\u6613\u4e8e\u4f7f\u7528\uff0c\u5efa\u8bae\u5c06\u5176\u7528\u4f5c\u57fa\u7ebf\u3002"}}
{"id": "2507.15269", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15269", "abs": "https://arxiv.org/abs/2507.15269", "authors": ["Fangqiu Yi", "Jingyu Xu", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "title": "Conditional Video Generation for High-Efficiency Video Compression", "comment": null, "summary": "Perceptual studies demonstrate that conditional diffusion models excel at\nreconstructing video content aligned with human visual perception. Building on\nthis insight, we propose a video compression framework that leverages\nconditional diffusion models for perceptually optimized reconstruction.\nSpecifically, we reframe video compression as a conditional generation task,\nwhere a generative model synthesizes video from sparse, yet informative\nsignals. Our approach introduces three key modules: (1) Multi-granular\nconditioning that captures both static scene structure and dynamic\nspatio-temporal cues; (2) Compact representations designed for efficient\ntransmission without sacrificing semantic richness; (3) Multi-condition\ntraining with modality dropout and role-aware embeddings, which prevent\nover-reliance on any single modality and enhance robustness. Extensive\nexperiments show that our method significantly outperforms both traditional and\nneural codecs on perceptual quality metrics such as Fr\\'echet Video Distance\n(FVD) and LPIPS, especially under high compression ratios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u89c6\u9891\u538b\u7f29\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u6761\u4ef6\u5316\u3001\u7d27\u51d1\u8868\u793a\u548c\u591a\u6761\u4ef6\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u89c6\u9891\u7684\u611f\u77e5\u91cd\u6784\u8d28\u91cf\uff0c\u5e76\u5728\u5404\u9879\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u7f16\u89e3\u7801\u5668\u3002", "motivation": "\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5728\u89c6\u9891\u91cd\u6784\u65b9\u9762\u8868\u73b0\u51fa\u7b26\u5408\u4eba\u7c7b\u89c6\u89c9\u611f\u77e5\u7684\u4f18\u52bf\u8fd9\u4e00\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u8fdb\u884c\u611f\u77e5\u4f18\u5316\u91cd\u6784\u7684\u89c6\u9891\u538b\u7f29\u6846\u67b6\u3002", "method": "\u672c\u7814\u7a76\u5c06\u89c6\u9891\u538b\u7f29\u91cd\u6784\u4e3a\u4e00\u4e2a\u6761\u4ef6\u751f\u6210\u4efb\u52a1\uff0c\u5229\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4ece\u7a00\u758f\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u4fe1\u53f7\u751f\u6210\u89c6\u9891\u3002\u5f15\u5165\u4e86\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a1. \u591a\u7c92\u5ea6\u6761\u4ef6\u5316\uff0c\u6355\u6349\u9759\u6001\u573a\u666f\u7ed3\u6784\u548c\u52a8\u6001\u65f6\u7a7a\u7ebf\u7d22\uff1b2. \u7d27\u51d1\u8868\u793a\uff0c\u7528\u4e8e\u9ad8\u6548\u4f20\u8f93\u4e14\u4e0d\u727a\u7272\u8bed\u4e49\u4e30\u5bcc\u6027\uff1b3. \u591a\u6761\u4ef6\u8bad\u7ec3\uff0c\u5305\u542b\u6a21\u6001 dropout \u548c\u89d2\u8272\u611f\u77e5\u5d4c\u5165\uff0c\u4ee5\u9632\u6b62\u8fc7\u5ea6\u4f9d\u8d56\u5355\u4e00\u6a21\u6001\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u611f\u77e5\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u9ad8\u538b\u7f29\u7387\u4e0b\u3002", "conclusion": "\u672c\u65b9\u6cd5\u5728\u611f\u77e5\u8d28\u91cf\u6307\u6807\uff08\u5982 Fr\u00e9chet Video Distance (FVD) \u548c LPIPS\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u795e\u7ecf\u7f16\u89e3\u7801\u5668\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u538b\u7f29\u7387\u4e0b\u3002"}}
{"id": "2507.15285", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15285", "abs": "https://arxiv.org/abs/2507.15285", "authors": ["Lazaro Janier Gonzalez-Soler", "Maciej Salwowski", "Christoph Busch"], "title": "In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems", "comment": "Submitted to IEEE-TIFS", "summary": "Recent advances in biometric systems have significantly improved the\ndetection and prevention of fraudulent activities. However, as detection\nmethods improve, attack techniques become increasingly sophisticated. Attacks\non face recognition systems can be broadly divided into physical and digital\napproaches. Traditionally, deep learning models have been the primary defence\nagainst such attacks. While these models perform exceptionally well in\nscenarios for which they have been trained, they often struggle to adapt to\ndifferent types of attacks or varying environmental conditions. These\nsubsystems require substantial amounts of training data to achieve reliable\nperformance, yet biometric data collection faces significant challenges,\nincluding privacy concerns and the logistical difficulties of capturing diverse\nattack scenarios under controlled conditions. This work investigates the\napplication of Vision Language Models (VLM) and proposes an in-context learning\nframework for detecting physical presentation attacks and digital morphing\nattacks in biometric systems. Focusing on open-source models, the first\nsystematic framework for the quantitative evaluation of VLMs in\nsecurity-critical scenarios through in-context learning techniques is\nestablished. The experimental evaluation conducted on freely available\ndatabases demonstrates that the proposed subsystem achieves competitive\nperformance for physical and digital attack detection, outperforming some of\nthe traditional CNNs without resource-intensive training. The experimental\nresults validate the proposed framework as a promising tool for improving\ngeneralisation in attack detection.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u4eba\u8138\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u7269\u7406\u548c\u6570\u5b57\u653b\u51fb\uff0c\u5e76\u5728\u4e0d\u8fdb\u884c\u5927\u91cf\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edfCNN\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u68c0\u6d4b\u65b9\u6cd5\u7684\u6539\u8fdb\uff0c\u653b\u51fb\u6280\u672f\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\u3002\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u653b\u51fb\u6216\u4e0d\u540c\u7684\u73af\u5883\u6761\u4ef6\u4e0b\u9002\u5e94\u6027\u8f83\u5dee\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u751f\u7269\u8bc6\u522b\u6570\u636e\u6536\u96c6\u9762\u4e34\u9690\u79c1\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u68c0\u6d4b\u751f\u7269\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7269\u7406\u5448\u73b0\u653b\u51fb\u548c\u6570\u5b57\u53d8\u5f62\u653b\u51fb\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\u3002\u8be5\u7814\u7a76\u9996\u6b21\u5efa\u7acb\u4e86\u7528\u4e8e\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u6280\u672f\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u91cf\u5316\u8bc4\u4f30 VLM \u7684\u7cfb\u7edf\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u5b50\u7cfb\u7edf\u5728\u7269\u7406\u548c\u6570\u5b57\u653b\u51fb\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u4e00\u4e9b\u4f20\u7edf\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u63d0\u9ad8\u653b\u51fb\u68c0\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u5de5\u5177\uff0c\u5e76\u4e14\u65e0\u9700\u8fdb\u884c\u8d44\u6e90\u5bc6\u96c6\u578b\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2507.15336", "categories": ["cs.LG", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.15336", "abs": "https://arxiv.org/abs/2507.15336", "authors": ["Jialiang Wang", "Hanmo Liu", "Shimin Di", "Zhili Wang", "Jiachuan Wang", "Lei Chen", "Xiaofang Zhou"], "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design", "comment": null, "summary": "Database systems have recently advocated for embedding machine learning (ML)\ncapabilities, offering declarative model queries over large, managed model\nrepositories, thereby circumventing the huge computational overhead of\ntraditional ML-based algorithms in automated neural network model selection.\nPioneering database studies aim to organize existing benchmark repositories as\nmodel bases (MB), querying them for the model records with the highest\nperformance estimation metrics for given tasks. However, this static model\nselection practice overlooks the fine-grained, evolving relational dependencies\nbetween diverse task queries and model architecture variations, resulting in\nsuboptimal matches and failing to further refine the model effectively. To fill\nthe model refinement gap in database research, we propose M-DESIGN, a curated\nmodel knowledge base (MKB) pipeline for mastering neural network refinement by\nadaptively weaving prior insights about model architecture modification. First,\nwe propose a knowledge weaving engine that reframes model refinement as an\nadaptive query problem over task metadata. Given a user's task query, M-DESIGN\nquickly matches and iteratively refines candidate models by leveraging a\ngraph-relational knowledge schema that explicitly encodes data properties,\narchitecture variations, and pairwise performance deltas as joinable relations.\nThis schema supports fine-grained relational analytics over architecture tweaks\nand drives a predictive query planner that can detect and adapt to\nout-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics\ntasks, where our model knowledge base enriches existing benchmarks with\nstructured metadata covering 3 graph tasks and 22 graph datasets, contributing\ndata records of 67,760 graph models. Empirical results demonstrate that\nM-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited\nbudgets.", "AI": {"tldr": "M-DESIGN \u901a\u8fc7\u6784\u5efa\u6a21\u578b\u77e5\u8bc6\u5e93\uff08MKB\uff09\uff0c\u5e76\u5229\u7528\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\u548c\u9884\u6d4b\u67e5\u8be2\u89c4\u5212\u5668\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5e93\u4e2d\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9009\u62e9\u548c\u7cbe\u70bc\u7684\u4e0d\u8db3\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u5730\u4f18\u5316\u6a21\u578b\u5339\u914d\uff0c\u5e76\u5728\u56fe\u5206\u6790\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u5e93\u5185\u5d4c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6a21\u578b\u9009\u62e9\u65f6\u5ffd\u89c6\u4e86\u4efb\u52a1\u67e5\u8be2\u4e0e\u6a21\u578b\u67b6\u6784\u53d8\u4f53\u4e4b\u95f4\u7ec6\u7c92\u5ea6\u7684\u3001\u4e0d\u65ad\u6f14\u5316\u7684\u5173\u7cfb\u4f9d\u8d56\uff0c\u5bfc\u81f4\u5339\u914d\u4e0d\u4f73\u4e14\u65e0\u6cd5\u6709\u6548\u7cbe\u70bc\u6a21\u578b\uff0c\u5b58\u5728\u6a21\u578b\u7cbe\u70bc\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa M-DESIGN\uff0c\u4e00\u4e2a\u5305\u542b\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\u548c\u9884\u6d4b\u67e5\u8be2\u89c4\u5212\u5668\u7684\u6a21\u578b\u77e5\u8bc6\u5e93\uff08MKB\uff09\u7ba1\u9053\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u56fe\u5173\u7cfb\u77e5\u8bc6\u6a21\u5f0f\u6765\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9009\u62e9\u548c\u7cbe\u70bc\uff0c\u8be5\u6a21\u5f0f\u663e\u5f0f\u5730\u7f16\u7801\u4e86\u6570\u636e\u5c5e\u6027\u3001\u67b6\u6784\u53d8\u4f53\u548c\u6210\u5bf9\u6027\u80fd\u5dee\u5f02\u4f5c\u4e3a\u53ef\u8fde\u63a5\u5173\u7cfb\uff0c\u4ee5\u89e3\u51b3\u81ea\u9002\u5e94\u67e5\u8be2\u95ee\u9898\u3002", "result": "M-DESIGN \u5728\u56fe\u5206\u6790\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5b9e\u4f8b\u5316\uff0c\u5176\u6a21\u578b\u77e5\u8bc6\u5e93\u4e3a\u73b0\u6709\u57fa\u51c6\u589e\u52a0\u4e86\u7ed3\u6784\u5316\u5143\u6570\u636e\uff0c\u6db5\u76d6\u4e86 3 \u4e2a\u56fe\u4efb\u52a1\u548c 22 \u4e2a\u56fe\u6570\u636e\u96c6\uff0c\u5305\u542b 67,760 \u4e2a\u56fe\u6a21\u578b\u8bb0\u5f55\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6709\u9650\u7684\u9884\u7b97\u4e0b\uff0cM-DESIGN \u5728 33 \u4e2a\u6570\u636e-\u4efb\u52a1\u5bf9\u4e2d\u7684 26 \u4e2a\u5b9e\u73b0\u4e86\u6700\u4f18\u6a21\u578b\u3002", "conclusion": "M-DESIGN \u901a\u8fc7\u5176\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\u548c\u9884\u6d4b\u67e5\u8be2\u89c4\u5212\u5668\uff0c\u80fd\u591f\u6709\u6548\u5730\u4e3a\u56fe\u5206\u6790\u4efb\u52a1\u627e\u5230\u6700\u4f18\u6a21\u578b\uff0c\u5e76\u5728\u5927\u591a\u6570\u6570\u636e-\u4efb\u52a1\u5bf9\u4e2d\u4ee5\u6709\u9650\u7684\u9884\u7b97\u5b9e\u73b0\u4e86\u6700\u4f18\u89e3\u3002"}}
{"id": "2507.15297", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15297", "abs": "https://arxiv.org/abs/2507.15297", "authors": ["Zhiyu Pan", "Xiongjun Guan", "Yongjie Duan", "Jianjiang Feng", "Jie Zhou"], "title": "Minutiae-Anchored Local Dense Representation for Fingerprint Matching", "comment": "Under review", "summary": "Fingerprint matching under diverse capture conditions remains a fundamental\nchallenge in biometric recognition. To achieve robust and accurate performance\nin such scenarios, we propose DMD, a minutiae-anchored local dense\nrepresentation which captures both fine-grained ridge textures and\ndiscriminative minutiae features in a spatially structured manner.\nSpecifically, descriptors are extracted from local patches centered and\noriented on each detected minutia, forming a three-dimensional tensor, where\ntwo dimensions represent spatial locations on the fingerprint plane and the\nthird encodes semantic features. This representation explicitly captures\nabstract features of local image patches, enabling a multi-level, fine-grained\ndescription that aggregates information from multiple minutiae and their\nsurrounding ridge structures. Furthermore, thanks to its strong spatial\ncorrespondence with the patch image, DMD allows for the use of foreground\nsegmentation masks to identify valid descriptor regions. During matching,\ncomparisons are then restricted to overlapping foreground areas, improving\nefficiency and robustness. Extensive experiments on rolled, plain, parital,\ncontactless, and latent fingerprint datasets demonstrate the effectiveness and\ngeneralizability of the proposed method. It achieves state-of-the-art accuracy\nacross multiple benchmarks while maintaining high computational efficiency,\nshowing strong potential for large-scale fingerprint recognition. Corresponding\ncode is available at https://github.com/Yu-Yy/DMD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a DMD \u7684\u65b0\u9896\u6307\u7eb9\u5339\u914d\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u4ee5\u7ec6\u8282\u70b9\u4e3a\u951a\u70b9\u7684\u5c40\u90e8\u5bc6\u96c6\u8868\u793a\uff0c\u7ed3\u5408\u4e86\u810a\u7ebf\u7eb9\u7406\u548c\u7ec6\u8282\u70b9\u7279\u5f81\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u7a7a\u95f4\u5bf9\u5e94\u5173\u7cfb\u548c\u524d\u666f\u63a9\u7801\u6765\u63d0\u9ad8\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u6307\u7eb9\u5339\u914d\u5728\u5404\u79cd\u4e0d\u540c\u7684\u91c7\u96c6\u6761\u4ef6\u4e0b\u4ecd\u7136\u662f\u751f\u7269\u7279\u5f81\u8bc6\u522b\u4e2d\u7684\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002\u4e3a\u4e86\u5728\u8fd9\u4e9b\u573a\u666f\u4e2d\u5b9e\u73b0\u7a33\u5065\u548c\u51c6\u786e\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a DMD \u7684\u5c40\u90e8\u5bc6\u96c6\u8868\u793a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ee5\u7ec6\u8282\u70b9\u4e3a\u951a\u70b9\uff0c\u53ef\u4ee5\u540c\u65f6\u6355\u83b7\u7ec6\u7c92\u5ea6\u7684\u810a\u7ebf\u7eb9\u7406\u548c\u5177\u6709\u5224\u522b\u6027\u7684\u7ec6\u8282\u70b9\u7279\u5f81\uff0c\u5e76\u4ee5\u7a7a\u95f4\u7ed3\u6784\u5316\u7684\u65b9\u5f0f\u8fdb\u884c\u8868\u793a\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u63cf\u8ff0\u7b26\u662f\u4ece\u4ee5\u68c0\u6d4b\u5230\u7684\u6bcf\u4e2a\u7ec6\u8282\u70b9\u4e3a\u4e2d\u5fc3\u548c\u65b9\u5411\u7684\u5c40\u90e8\u5757\u4e2d\u63d0\u53d6\u7684\uff0c\u5f62\u6210\u4e00\u4e2a\u4e09\u7ef4\u5f20\u91cf\uff0c\u5176\u4e2d\u4e24\u4e2a\u7ef4\u5ea6\u4ee3\u8868\u6307\u7eb9\u5e73\u9762\u4e0a\u7684\u7a7a\u95f4\u4f4d\u7f6e\uff0c\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u7f16\u7801\u8bed\u4e49\u7279\u5f81\u3002\u8fd9\u79cd\u8868\u793a\u663e\u5f0f\u5730\u6355\u83b7\u4e86\u5c40\u90e8\u56fe\u50cf\u5757\u7684\u62bd\u8c61\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u591a\u5c42\u6b21\u3001\u7ec6\u7c92\u5ea6\u7684\u63cf\u8ff0\uff0c\u5e76\u805a\u5408\u4e86\u6765\u81ea\u591a\u4e2a\u7ec6\u8282\u70b9\u53ca\u5176\u5468\u56f4\u810a\u7ebf\u7ed3\u6784\u7684\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u7531\u4e8e DMD \u4e0e\u5757\u56fe\u50cf\u5177\u6709\u5f88\u5f3a\u7684\u7a7a\u95f4\u5bf9\u5e94\u5173\u7cfb\uff0c\u5b83\u5141\u8bb8\u4f7f\u7528\u524d\u666f\u5206\u5272\u63a9\u7801\u6765\u8bc6\u522b\u6709\u6548\u7684\u63cf\u8ff0\u7b26\u533a\u57df\u3002\u5728\u5339\u914d\u8fc7\u7a0b\u4e2d\uff0c\u6bd4\u8f83\u4ec5\u9650\u4e8e\u91cd\u53e0\u7684\u524d\u666f\u533a\u57df\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "result": "\u4e0e\u5176\u4ed6\u65b9\u6cd5\u76f8\u6bd4\uff0cDMD \u5728\u5404\u79cd\u6307\u7eb9\u6570\u636e\u96c6\uff08\u5305\u62ec\u6eda\u5370\u3001\u5e73\u9762\u3001\u5c40\u90e8\u3001\u975e\u63a5\u89e6\u548c\u6f5c\u5728\u6307\u7eb9\uff09\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "DMD \u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u4e07\u89c4\u6a21\u6307\u7eb9\u8bc6\u522b\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15308", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15308", "abs": "https://arxiv.org/abs/2507.15308", "authors": ["Zhimeng Xin", "Tianxu Wu", "Yixiong Zou", "Shiming Chen", "Dingjie Fu", "Xinge You"], "title": "Few-Shot Object Detection via Spatial-Channel State Space Model", "comment": null, "summary": "Due to the limited training samples in few-shot object detection (FSOD), we\nobserve that current methods may struggle to accurately extract effective\nfeatures from each channel. Specifically, this issue manifests in two aspects:\ni) channels with high weights may not necessarily be effective, and ii)\nchannels with low weights may still hold significant value. To handle this\nproblem, we consider utilizing the inter-channel correlation to facilitate the\nnovel model's adaptation process to novel conditions, ensuring the model can\ncorrectly highlight effective channels and rectify those incorrect ones. Since\nthe channel sequence is also 1-dimensional, its similarity with the temporal\nsequence inspires us to take Mamba for modeling the correlation in the channel\nsequence. Based on this concept, we propose a Spatial-Channel State Space\nModeling (SCSM) module for spatial-channel state modeling, which highlights the\neffective patterns and rectifies those ineffective ones in feature channels. In\nSCSM, we design the Spatial Feature Modeling (SFM) module to balance the\nlearning of spatial relationships and channel relationships, and then introduce\nthe Channel State Modeling (CSM) module based on Mamba to learn correlation in\nchannels. Extensive experiments on the VOC and COCO datasets show that the SCSM\nmodule enables the novel detector to improve the quality of focused feature\nrepresentation in channels and achieve state-of-the-art performance.", "AI": {"tldr": "\u9488\u5bf9\u5c11\u6570\u6837\u672c\u76ee\u6807\u68c0\u6d4b\uff08FSOD\uff09\u4e2d\u7279\u5f81\u63d0\u53d6\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eMamba\u7684\u7a7a\u95f4-\u901a\u9053\u72b6\u6001\u7a7a\u95f4\u5efa\u6a21\uff08SCSM\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u5efa\u6a21\u901a\u9053\u95f4\u7684\u76f8\u5173\u6027\u6765\u4f18\u5316\u7279\u5f81\u8868\u793a\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5c11\u6570\u6837\u672c\u76ee\u6807\u68c0\u6d4b\uff08FSOD\uff09\u4e2d\uff0c\u7531\u4e8e\u8bad\u7ec3\u6837\u672c\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u96be\u4ee5\u4ece\u6bcf\u4e2a\u901a\u9053\u51c6\u786e\u63d0\u53d6\u6709\u6548\u7279\u5f81\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6743\u91cd\u9ad8\u7684\u901a\u9053\u4e0d\u4e00\u5b9a\u6709\u6548\uff0c\u6743\u91cd\u4f4e\u7684\u901a\u9053\u53ef\u80fd\u4ecd\u7136\u6709\u91cd\u8981\u4ef7\u503c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7a7a\u95f4-\u901a\u9053\u72b6\u6001\u7a7a\u95f4\u5efa\u6a21\uff08SCSM\uff09\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u5305\u542b\u7a7a\u95f4\u7279\u5f81\u5efa\u6a21\uff08SFM\uff09\u548c\u901a\u9053\u72b6\u6001\u5efa\u6a21\uff08CSM\uff09\u4e24\u4e2a\u5b50\u6a21\u5757\u3002CSM\u5b50\u6a21\u5757\u57fa\u4e8eMamba\uff0c\u7528\u4e8e\u5b66\u4e60\u901a\u9053\u5e8f\u5217\u4e2d\u7684\u76f8\u5173\u6027\u3002", "result": "\u5728VOC\u548cCOCO\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSCSM\u6a21\u5757\u80fd\u591f\u63d0\u5347\u6240\u63d0\u51fa\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7a7a\u95f4-\u901a\u9053\u72b6\u6001\u7a7a\u95f4\u5efa\u6a21\uff08SCSM\uff09\u6a21\u5757\u80fd\u591f\u63d0\u9ad8\u901a\u9053\u4e2d\u7279\u5f81\u8868\u793a\u7684\u8d28\u91cf\uff0c\u5e76\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15381", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15381", "abs": "https://arxiv.org/abs/2507.15381", "authors": ["Julia Machnio", "Mads Nielsen", "Mostafa Mehdipour Ghazi"], "title": "To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models", "comment": "ICCV 2025", "summary": "Active learning (AL) seeks to reduce annotation costs by selecting the most\ninformative samples for labeling, making it particularly valuable in\nresource-constrained settings. However, traditional evaluation methods, which\nfocus solely on final accuracy, fail to capture the full dynamics of the\nlearning process. To address this gap, we propose PALM (Performance Analysis of\nActive Learning Models), a unified and interpretable mathematical model that\ncharacterizes AL trajectories through four key parameters: achievable accuracy,\ncoverage efficiency, early-stage performance, and scalability. PALM provides a\npredictive description of AL behavior from partial observations, enabling the\nestimation of future performance and facilitating principled comparisons across\ndifferent strategies. We validate PALM through extensive experiments on\nCIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and\nself-supervised embeddings. Our results demonstrate that PALM generalizes\neffectively across datasets, budgets, and strategies, accurately predicting\nfull learning curves from limited labeled data. Importantly, PALM reveals\ncrucial insights into learning efficiency, data space coverage, and the\nscalability of AL methods. By enabling the selection of cost-effective\nstrategies and predicting performance under tight budget constraints, PALM lays\nthe basis for more systematic, reproducible, and data-efficient evaluation of\nAL in both research and real-world applications. The code is available at:\nhttps://github.com/juliamachnio/PALM.", "AI": {"tldr": "PALM \u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u7684\u6570\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u56db\u4e2a\u5173\u952e\u53c2\u6570\uff08\u7cbe\u5ea6\u3001\u6548\u7387\u3001\u65e9\u671f\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\uff09\u6765\u9884\u6d4b\u548c\u6bd4\u8f83 AL \u7b56\u7565\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u5b83\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u8de8\u6570\u636e\u96c6\u3001\u9884\u7b97\u548c\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e3a\u66f4\u7cfb\u7edf\u3001\u53ef\u590d\u73b0\u548c\u6570\u636e\u9ad8\u6548\u7684 AL \u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u51c6\u786e\u6027\uff0c\u672a\u80fd\u6355\u6349\u5b66\u4e60\u8fc7\u7a0b\u7684\u5b8c\u6574\u52a8\u6001\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u5dee\u8ddd\uff0cPALM \u88ab\u63d0\u51fa\u7528\u4e8e\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u4e3b\u52a8\u5b66\u4e60\u3002", "method": "PALM (Performance Analysis of Active Learning Models) \u662f\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u89e3\u91ca\u7684\u6570\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u56db\u4e2a\u5173\u952e\u53c2\u6570\u6765\u8868\u5f81\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u8f68\u8ff9\uff1a\u53ef\u5b9e\u73b0\u7cbe\u5ea6\u3001\u8986\u76d6\u6548\u7387\u3001\u65e9\u671f\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002\u8be5\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u90e8\u5206\u89c2\u6d4b\u503c\u9884\u6d4b AL \u884c\u4e3a\uff0c\u4ece\u800c\u80fd\u591f\u4f30\u8ba1\u672a\u6765\u6027\u80fd\u5e76\u4fc3\u8fdb\u4e0d\u540c\u7b56\u7565\u4e4b\u95f4\u7684\u539f\u5219\u6027\u6bd4\u8f83\u3002", "result": "PALM \u901a\u8fc7\u5728 CIFAR-10/100 \u548c ImageNet-50/100/200 \u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u6db5\u76d6\u4e86\u5e7f\u6cdb\u7684 AL \u65b9\u6cd5\u548c\u81ea\u76d1\u7763\u5d4c\u5165\u3002\u7ed3\u679c\u8868\u660e\uff0cPALM \u80fd\u591f\u8de8\u6570\u636e\u96c6\u3001\u9884\u7b97\u548c\u7b56\u7565\u6709\u6548\u5730\u6cdb\u5316\uff0c\u5e76\u80fd\u4ece\u6709\u9650\u7684\u6807\u8bb0\u6570\u636e\u4e2d\u51c6\u786e\u9884\u6d4b\u5b8c\u6574\u7684\u5b66\u4e60\u66f2\u7ebf\u3002\u8be5\u6a21\u578b\u63ed\u793a\u4e86\u5b66\u4e60\u6548\u7387\u3001\u6570\u636e\u7a7a\u95f4\u8986\u76d6\u548c AL \u65b9\u6cd5\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u91cd\u8981\u89c1\u89e3\u3002", "conclusion": "PALM \u662f\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u89e3\u91ca\u7684\u6570\u5b66\u6a21\u578b\uff0c\u7528\u4e8e\u8868\u5f81\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u8f68\u8ff9\uff0c\u901a\u8fc7\u56db\u4e2a\u5173\u952e\u53c2\u6570\uff1a\u53ef\u5b9e\u73b0\u7cbe\u5ea6\u3001\u8986\u76d6\u6548\u7387\u3001\u65e9\u671f\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002PALM \u80fd\u591f\u901a\u8fc7\u90e8\u5206\u89c2\u6d4b\u503c\u5bf9 AL \u884c\u4e3a\u8fdb\u884c\u9884\u6d4b\u6027\u63cf\u8ff0\uff0c\u4ece\u800c\u80fd\u591f\u4f30\u8ba1\u672a\u6765\u6027\u80fd\u5e76\u4fc3\u8fdb\u4e0d\u540c\u7b56\u7565\u4e4b\u95f4\u7684\u539f\u5219\u6027\u6bd4\u8f83\u3002PALM \u80fd\u591f\u8de8\u6570\u636e\u96c6\u3001\u9884\u7b97\u548c\u7b56\u7565\u6709\u6548\u5730\u6cdb\u5316\uff0c\u5e76\u80fd\u4ece\u6709\u9650\u7684\u6807\u8bb0\u6570\u636e\u4e2d\u51c6\u786e\u9884\u6d4b\u5b8c\u6574\u7684\u5b66\u4e60\u66f2\u7ebf\u3002\u901a\u8fc7\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u7b56\u7565\u7684\u9009\u62e9\u548c\u9884\u6d4b\u7d27\u7f29\u9884\u7b97\u4e0b\u7684\u6027\u80fd\uff0cPALM \u4e3a\u5728\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u7cfb\u7edf\u3001\u53ef\u590d\u73b0\u548c\u6570\u636e\u9ad8\u6548\u7684 AL \u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15321", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15321", "abs": "https://arxiv.org/abs/2507.15321", "authors": ["Zhenyu Li", "Haotong Lin", "Jiashi Feng", "Peter Wonka", "Bingyi Kang"], "title": "BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?", "comment": "Webpage: https://zhyever.github.io/benchdepth", "summary": "Depth estimation is a fundamental task in computer vision with diverse\napplications. Recent advancements in deep learning have led to powerful depth\nfoundation models (DFMs), yet their evaluation remains challenging due to\ninconsistencies in existing protocols. Traditional benchmarks rely on\nalignment-based metrics that introduce biases, favor certain depth\nrepresentations, and complicate fair comparisons. In this work, we propose\nBenchDepth, a new benchmark that evaluates DFMs through five carefully selected\ndownstream proxy tasks: depth completion, stereo matching, monocular\nfeed-forward 3D scene reconstruction, SLAM, and vision-language spatial\nunderstanding. Unlike conventional evaluation protocols, our approach assesses\nDFMs based on their practical utility in real-world applications, bypassing\nproblematic alignment procedures. We benchmark eight state-of-the-art DFMs and\nprovide an in-depth analysis of key findings and observations. We hope our work\nsparks further discussion in the community on best practices for depth model\nevaluation and paves the way for future research and advancements in depth\nestimation.", "AI": {"tldr": "BenchDepth \u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u6df1\u5ea6\u57fa\u7840\u6a21\u578b (DFM) \u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e94\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u6df1\u5ea6\u8865\u5168\u3001SLAM \u7b49\uff09\u6765\u8861\u91cf\u5176\u5b9e\u9645\u6548\u7528\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u6709\u95ee\u9898\u7684\u57fa\u4e8e\u5bf9\u9f50\u7684\u6307\u6807\u3002", "motivation": "\u8bc4\u4f30 DFM \u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u73b0\u6709\u534f\u8bae\u4e0d\u4e00\u81f4\u3001\u57fa\u4e8e\u5bf9\u9f50\u7684\u6307\u6807\u5b58\u5728\u504f\u5dee\uff0c\u5e76\u4e14\u96be\u4ee5\u8fdb\u884c\u516c\u5e73\u6bd4\u8f83\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e00\u79cd\u57fa\u4e8e\u5b9e\u9645\u6548\u7528\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a BenchDepth \u7684\u65b0\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u901a\u8fc7\u4e94\u4e2a\u9009\u5b9a\u7684\u4e0b\u6e38\u4ee3\u7406\u4efb\u52a1\uff08\u6df1\u5ea6\u8865\u5168\u3001\u7acb\u4f53\u5339\u914d\u3001\u5355\u76ee\u524d\u9988 3D \u573a\u666f\u91cd\u5efa\u3001SLAM \u548c\u89c6\u89c9\u8bed\u8a00\u7a7a\u95f4\u7406\u89e3\uff09\u6765\u8bc4\u4f30 DFM\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u6709\u504f\u5dee\u7684\u57fa\u4e8e\u5bf9\u9f50\u7684\u6307\u6807\u3002", "result": "\u8bc4\u4f30\u4e86\u516b\u4e2a\u6700\u5148\u8fdb\u7684 DFM\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u952e\u53d1\u73b0\u548c\u89c2\u5bdf\u7684\u6df1\u5165\u5206\u6790\uff0c\u65e8\u5728\u4e3a\u6df1\u5ea6\u6a21\u578b\u8bc4\u4f30\u7684\u6700\u4f73\u5b9e\u8df5\u63d0\u4f9b\u4fe1\u606f\u3002", "conclusion": "BenchDepth \u901a\u8fc7\u8bc4\u4f30\u6df1\u5ea6\u57fa\u7840\u6a21\u578b (DFM) \u5728\u4e94\u4e2a\u4e0b\u6e38\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e8\u5728\u514b\u670d\u73b0\u6709\u534f\u8bae\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4fc3\u8fdb\u6df1\u5ea6\u6a21\u578b\u8bc4\u4f30\u6700\u4f73\u5b9e\u8df5\u7684\u8ba8\u8bba\u3002"}}
{"id": "2507.15335", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15335", "abs": "https://arxiv.org/abs/2507.15335", "authors": ["Muhammad Aqeel", "Federico Leonardi", "Francesco Setti"], "title": "ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis", "comment": "Accepted to ICIAP 2025", "summary": "Industrial defect detection systems face critical limitations when confined\nto one-class anomaly detection paradigms, which assume uniform outlier\ndistributions and struggle with data scarcity in realworld manufacturing\nenvironments. We present ExDD (Explicit Dual Distribution), a novel framework\nthat transcends these limitations by explicitly modeling dual feature\ndistributions. Our approach leverages parallel memory banks that capture the\ndistinct statistical properties of both normality and anomalous patterns,\naddressing the fundamental flaw of uniform outlier assumptions. To overcome\ndata scarcity, we employ latent diffusion models with domain-specific textual\nconditioning, generating in-distribution synthetic defects that preserve\nindustrial context. Our neighborhood-aware ratio scoring mechanism elegantly\nfuses complementary distance metrics, amplifying signals in regions exhibiting\nboth deviation from normality and similarity to known defect patterns.\nExperimental validation on KSDD2 demonstrates superior performance (94.2%\nI-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.", "AI": {"tldr": "ExDD\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u53cc\u7279\u5f81\u5206\u5e03\u548c\u4f7f\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\u751f\u6210\u5408\u6210\u6570\u636e\u6765\u6539\u8fdb\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u5355\u7c7b\u522b\u5f02\u5e38\u68c0\u6d4b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728KSDD2\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u5355\u7c7b\u522b\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\u5728\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5f02\u5e38\u503c\u5206\u5e03\u4e0d\u5747\u5300\u548c\u771f\u5b9e\u4e16\u754c\u5236\u9020\u73af\u5883\u4e2d\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u7684\u65b0\u6846\u67b6\u3002", "method": "ExDD\u6846\u67b6\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5de5\u4f5c\uff1a1. \u663e\u5f0f\u5efa\u6a21\u53cc\u7279\u5f81\u5206\u5e03\uff1a\u5229\u7528\u5e76\u884c\u7684\u5185\u5b58\u5e93\u5206\u522b\u6355\u83b7\u6b63\u5e38\u548c\u5f02\u5e38\u6a21\u5f0f\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u89e3\u51b3\u4e86\u5747\u5300\u5f02\u5e38\u503c\u5047\u8bbe\u7684\u6839\u672c\u7f3a\u9677\u30022. \u514b\u670d\u6570\u636e\u7a00\u7f3a\u6027\uff1a\u91c7\u7528\u5177\u6709\u9886\u57df\u7279\u5b9a\u6587\u672c\u6761\u4ef6\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u751f\u6210\u4fdd\u7559\u5de5\u4e1a\u80cc\u666f\u7684\u539f\u4f4d\u5408\u6210\u7f3a\u9677\u30023. \u90bb\u57df\u611f\u77e5\u6bd4\u7387\u8bc4\u5206\uff1a\u901a\u8fc7\u878d\u5408\u4e92\u8865\u8ddd\u79bb\u5ea6\u91cf\u6765\u653e\u5927\u8868\u73b0\u51fa\u504f\u79bb\u6b63\u5e38\u6027\u548c\u4e0e\u5df2\u77e5\u7f3a\u9677\u6a21\u5f0f\u76f8\u4f3c\u6027\u7684\u533a\u57df\u7684\u4fe1\u53f7\u3002", "result": "\u5728KSDD2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0cExDD\u6846\u67b6\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0cI-AUROC\u4e3a94.2%\uff0cP-AUROC\u4e3a97.7%\uff0c\u5e76\u4e14\u5728\u589e\u52a0100\u4e2a\u5408\u6210\u6837\u672c\u65f6\u6027\u80fd\u8fbe\u5230\u6700\u4f18\u3002", "conclusion": "ExDD\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u53cc\u7279\u5f81\u5206\u5e03\u3001\u5229\u7528\u5177\u6709\u9886\u57df\u7279\u5b9a\u6587\u672c\u6761\u4ef6\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\u751f\u6210\u5408\u6210\u7f3a\u9677\u4ee5\u53ca\u91c7\u7528\u90bb\u57df\u611f\u77e5\u6bd4\u7387\u8bc4\u5206\u673a\u5236\uff0c\u514b\u670d\u4e86\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\u4e2d\u5355\u7c7b\u522b\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728KSDD2\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15397", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.15397", "abs": "https://arxiv.org/abs/2507.15397", "authors": ["Scott Pesme", "Giacomo Meanti", "Michael Arbel", "Julien Mairal"], "title": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "comment": null, "summary": "Denoiser models have become powerful tools for inverse problems, enabling the\nuse of pretrained networks to approximate the score of a smoothed prior\ndistribution. These models are often used in heuristic iterative schemes aimed\nat solving Maximum a Posteriori (MAP) optimisation problems, where the proximal\noperator of the negative log-prior plays a central role. In practice, this\noperator is intractable, and practitioners plug in a pretrained denoiser as a\nsurrogate-despite the lack of general theoretical justification for this\nsubstitution. In this work, we show that a simple algorithm, closely related to\nseveral used in practice, provably converges to the proximal operator under a\nlog-concavity assumption on the prior $p$. We show that this algorithm can be\ninterpreted as a gradient descent on smoothed proximal objectives. Our analysis\nthus provides a theoretical foundation for a class of empirically successful\nbut previously heuristic methods.", "AI": {"tldr": "\u53bb\u566a\u5668\u6a21\u578b\u5728\u9006\u95ee\u9898\u4e2d\u5f88\u6709\u7528\uff0c\u901a\u5e38\u7528\u4e8e\u6700\u5927\u540e\u9a8c\uff08MAP\uff09\u4f18\u5316\u3002\u867d\u7136\u5b9e\u8df5\u4e2d\u4f1a\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u53bb\u566a\u5668\u4f5c\u4e3a\u8fd1\u7aef\u7b97\u5b50\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5728\u5148\u9a8c\u5bf9\u6570\u51f9\u5ea6\u5047\u8bbe\u4e0b\u53ef\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u53bb\u566a\u5668\u6a21\u578b\u88ab\u7528\u4f5c\u6700\u5927\u540e\u9a8c\uff08MAP\uff09\u4f18\u5316\u95ee\u9898\u7684\u4ee3\u7406\uff0c\u4f46\u8fd9\u79cd\u66ff\u4ee3\u7f3a\u4e4f\u666e\u904d\u7684\u7406\u8bba\u4f9d\u636e\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u8fd9\u79cd\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u5b9e\u8df5\u4e2d\u4f7f\u7528\u7684\u51e0\u79cd\u7b97\u6cd5\u5bc6\u5207\u76f8\u5173\u7684\u7b80\u5355\u7b97\u6cd5\uff0c\u5e76\u5728\u5148\u9a8c p \u7684\u5bf9\u6570\u51f9\u5ea6\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u53ef\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\u3002", "result": "\u8bc1\u660e\u4e86\u4e00\u79cd\u7b80\u5355\u7b97\u6cd5\u5728\u5148\u9a8c\u5bf9\u6570\u51f9\u5ea6\u5047\u8bbe\u4e0b\u53ef\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\uff0c\u5e76\u5c06\u5176\u89e3\u91ca\u4e3a\u5e73\u6ed1\u8fd1\u7aef\u76ee\u6807\u7684\u68af\u5ea6\u4e0b\u964d\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u53ef\u4ee5\u88ab\u89e3\u91ca\u4e3a\u5728\u5e73\u6ed1\u8fd1\u7aef\u76ee\u6807\u4e0a\u7684\u68af\u5ea6\u4e0b\u964d\uff0c\u4e3a\u7ecf\u9a8c\u4e0a\u6210\u529f\u4f46\u6b64\u524d\u662f\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.15346", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15346", "abs": "https://arxiv.org/abs/2507.15346", "authors": ["Muhammad Aqeel", "Kidus Dagnaw Bellete", "Francesco Setti"], "title": "RoadFusion: Latent Diffusion Model for Pavement Defect Detection", "comment": "Accepted to ICIAP 2025", "summary": "Pavement defect detection faces critical challenges including limited\nannotated data, domain shift between training and deployment environments, and\nhigh variability in defect appearances across different road conditions. We\npropose RoadFusion, a framework that addresses these limitations through\nsynthetic anomaly generation with dual-path feature adaptation. A latent\ndiffusion model synthesizes diverse, realistic defects using text prompts and\nspatial masks, enabling effective training under data scarcity. Two separate\nfeature adaptors specialize representations for normal and anomalous inputs,\nimproving robustness to domain shift and defect variability. A lightweight\ndiscriminator learns to distinguish fine-grained defect patterns at the patch\nlevel. Evaluated on six benchmark datasets, RoadFusion achieves consistently\nstrong performance across both classification and localization tasks, setting\nnew state-of-the-art in multiple metrics relevant to real-world road\ninspection.", "AI": {"tldr": "RoadFusion \u901a\u8fc7\u5408\u6210\u5f02\u5e38\u751f\u6210\u548c\u53cc\u8def\u5f84\u7279\u5f81\u9002\u5e94\u6027\u89e3\u51b3\u4e86\u9053\u8def\u7f3a\u9677\u68c0\u6d4b\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u3001\u57df\u6f02\u79fb\u548c\u5916\u89c2\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "motivation": "\u9053\u8def\u7f3a\u9677\u68c0\u6d4b\u9762\u4e34\u4e25\u5cfb\u7684\u6311\u6218\uff0c\u5305\u62ec\u6807\u6ce8\u6570\u636e\u6709\u9650\u3001\u8bad\u7ec3\u548c\u90e8\u7f72\u73af\u5883\u4e4b\u95f4\u7684\u57df\u6f02\u79fb\u4ee5\u53ca\u4e0d\u540c\u9053\u8def\u6761\u4ef6\u4e0b\u7f3a\u9677\u5916\u89c2\u7684\u9ad8\u5ea6\u53d8\u5f02\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a RoadFusion \u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5177\u6709\u53cc\u8def\u5f84\u7279\u5f81\u9002\u5e94\u6027\u7684\u5408\u6210\u5f02\u5e38\u751f\u6210\u6765\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u57df\u6f02\u79fb\u548c\u7f3a\u9677\u5916\u89c2\u9ad8\u53d8\u5f02\u6027\u7b49\u6311\u6218\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5229\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u4ee5\u6587\u672c\u63d0\u793a\u548c\u7a7a\u95f4\u63a9\u7801\u4e3a\u6761\u4ef6\uff0c\u751f\u6210\u591a\u6837\u5316\u4e14\u903c\u771f\u7684\u7f3a\u9677\uff0c\u4ece\u800c\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u7684\u8bad\u7ec3\u3002\u4e24\u4e2a\u72ec\u7acb\u7684\u7279\u5f81\u9002\u914d\u5668\u5206\u522b\u5bf9\u6b63\u5e38\u548c\u5f02\u5e38\u8f93\u5165\u7684\u8868\u793a\u8fdb\u884c\u4e13\u95e8\u5316\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u57df\u6f02\u79fb\u548c\u7f3a\u9677\u53d8\u5f02\u6027\u7684\u9c81\u68d2\u6027\u3002\u6700\u540e\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u9274\u522b\u5668\u5728\u6591\u5757\u7ea7\u522b\u5b66\u4e60\u533a\u5206\u7ec6\u7c92\u5ea6\u7684\u7f3a\u9677\u6a21\u5f0f\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0cRoadFusion \u5728\u5206\u7c7b\u548c\u5b9a\u4f4d\u4efb\u52a1\u4e0a\u5747\u5b9e\u73b0\u4e86\u59cb\u7ec8\u5982\u4e00\u7684\u5f3a\u5927\u6027\u80fd\u3002", "conclusion": "RoadFusion \u5728\u5206\u7c7b\u548c\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u59cb\u7ec8\u5982\u4e00\u7684\u5f3a\u5927\u6027\u80fd\uff0c\u5e76\u5728\u4e0e\u5b9e\u9645\u9053\u8def\u68c0\u6d4b\u76f8\u5173\u7684\u591a\u4e2a\u6307\u6807\u4e0a\u521b\u4e0b\u65b0\u7684\u6700\u5148\u8fdb\u7eaa\u5f55\u3002"}}
{"id": "2507.15431", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15431", "abs": "https://arxiv.org/abs/2507.15431", "authors": ["Andrew Gracyk"], "title": "The calculus of variations of the Transformer on the hyperspherical tangent bundle", "comment": "First version", "summary": "We offer a theoretical mathematical background to Transformers through\nLagrangian optimization across the token space. The Transformer, as a flow map,\nexists in the tangent fiber for each token along the high-dimensional unit\nsphere. The circumstance of the hypersphere across the latent data is\nreasonable due to the trained diagonal matrix equal to the identity, which has\nvarious empirical justifications. Thus, under the continuum limit of the\ndynamics, the latent vectors flow among the tangent bundle. Using these facts,\nwe devise a mathematical framework for the Transformer through calculus of\nvariations. We develop a functional and show that the continuous flow map\ninduced by the Transformer satisfies this functional, therefore the Transformer\ncan be viewed as a natural solver of a calculus of variations problem. We\ninvent new scenarios of when our methods are applicable based on loss\noptimization with respect to path optimality. We derive the Euler-Lagrange\nequation for the Transformer. The variant of the Euler-Lagrange equation we\npresent has various appearances in literature, but, to our understanding,\noftentimes not foundationally proven or under other specialized cases. Our\noverarching proof is new: our techniques are classical and the use of the flow\nmap object is original. We provide several other relevant results, primarily\nones specific to neural scenarios. In particular, much of our analysis will be\nattempting to quantify Transformer data in variational contexts under neural\napproximations. Calculus of variations on manifolds is a well-nourished\nresearch area, but for the Transformer specifically, it is uncharted: we lay\nthe foundation for this area through an introduction to the Lagrangian for the\nTransformer.", "AI": {"tldr": "Transformer \u5728\u6570\u5b66\u4e0a\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u6d41\u6620\u5c04\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u53d8\u5206\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u8fd9\u4e3a\u91cf\u5316 Transformer \u6570\u636e\u548c\u4f18\u5316\u635f\u5931\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002", "motivation": "\u4e3a Transformer \u63d0\u4f9b\u7406\u8bba\u6570\u5b66\u80cc\u666f\uff0c\u5e76\u5c06\u5176\u4e0e\u53d8\u5206\u6cd5\u8054\u7cfb\u8d77\u6765\uff0c\u63a2\u7d22\u65b0\u7684\u5e94\u7528\u573a\u666f\u3002", "method": "\u4f7f\u7528\u62c9\u683c\u6717\u65e5\u4f18\u5316\u548c\u53d8\u5206\u6cd5\u6765\u5206\u6790 Transformer\u3002\u901a\u8fc7\u5c06 Transformer \u89c6\u4e3a\u5207\u7ebf\u4e1b\u4e2d\u7684\u6d41\u6620\u5c04\uff0c\u6211\u4eec\u63a8\u5bfc\u4e86\u5176\u6b27\u62c9-\u62c9\u683c\u6717\u65e5\u65b9\u7a0b\u3002", "result": "\u6211\u4eec\u63a8\u5bfc\u4e86 Transformer \u7684\u6b27\u62c9-\u62c9\u683c\u6717\u65e5\u65b9\u7a0b\uff0c\u5e76\u5c55\u793a\u4e86 Transformer \u53ef\u4ee5\u88ab\u89c6\u4e3a\u53d8\u5206\u6cd5\u95ee\u9898\u7684\u81ea\u7136\u89e3\u3002", "conclusion": "Transformer \u53ef\u4ee5\u88ab\u89c6\u4e3a\u53d8\u5206\u6cd5\u95ee\u9898\u7684\u81ea\u7136\u89e3\uff0c\u5e76\u4e14\u6211\u4eec\u7684\u5206\u6790\u4e3a\u5728\u53d8\u5206\u80cc\u666f\u4e0b\u91cf\u5316 Transformer \u6570\u636e\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15365", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15365", "abs": "https://arxiv.org/abs/2507.15365", "authors": ["Fatemeh Saleh", "Sadegh Aliakbarian", "Charlie Hewitt", "Lohit Petikam", "Xiao-Xian", "Antonio Criminisi", "Thomas J. Cashman", "Tadas Baltru\u0161aitis"], "title": "DAViD: Data-efficient and Accurate Vision Models from Synthetic Data", "comment": "Accepted at ICCV 2025", "summary": "The state of the art in human-centric computer vision achieves high accuracy\nand robustness across a diverse range of tasks. The most effective models in\nthis domain have billions of parameters, thus requiring extremely large\ndatasets, expensive training regimes, and compute-intensive inference. In this\npaper, we demonstrate that it is possible to train models on much smaller but\nhigh-fidelity synthetic datasets, with no loss in accuracy and higher\nefficiency. Using synthetic training data provides us with excellent levels of\ndetail and perfect labels, while providing strong guarantees for data\nprovenance, usage rights, and user consent. Procedural data synthesis also\nprovides us with explicit control on data diversity, that we can use to address\nunfairness in the models we train. Extensive quantitative assessment on real\ninput images demonstrates accuracy of our models on three dense prediction\ntasks: depth estimation, surface normal estimation, and soft foreground\nsegmentation. Our models require only a fraction of the cost of training and\ninference when compared with foundational models of similar accuracy. Our\nhuman-centric synthetic dataset and trained models are available at\nhttps://aka.ms/DAViD.", "AI": {"tldr": "\u4f7f\u7528\u6210\u672c\u66f4\u4f4e\u3001\u53ef\u63a7\u6027\u66f4\u9ad8\u7684\u9ad8\u4fdd\u771f\u5ea6\u5408\u6210\u6570\u636e\uff0c\u53ef\u4ee5\u8bad\u7ec3\u51fa\u4e0e\u4f7f\u7528\u5927\u578b\u771f\u5b9e\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u540c\u7b49\u4eba\u672c\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\uff0c\u4e14\u5728\u51c6\u786e\u6027\u4e0a\u4e0d\u6253\u6298\u6263\uff0c\u540c\u65f6\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u63a2\u7d22\u4f7f\u7528\u5408\u6210\u6570\u636e\u66ff\u4ee3\u5927\u578b\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u4eba\u672c\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u8bad\u7ec3\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u5e76\u89e3\u51b3\u6570\u636e\u504f\u89c1\u95ee\u9898\u3002", "method": "\u5728\u5c0f\u578b\u3001\u9ad8\u4fdd\u771f\u5ea6\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u8be6\u7ec6\u7684\u5b9a\u91cf\u8bc4\u4f30\u3002", "result": "\u5728\u771f\u5b9e\u56fe\u50cf\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9a\u91cf\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u5728\u6df1\u5ea6\u4f30\u8ba1\u3001\u8868\u9762\u6cd5\u7ebf\u4f30\u8ba1\u548c\u8f6f\u524d\u666f\u5206\u5272\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u3002\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u4e0a\u4ec5\u4e3a\u540c\u7b49\u7cbe\u5ea6\u7684\u57fa\u7840\u6a21\u578b\u7684\u51e0\u5206\u4e4b\u4e00\u3002", "conclusion": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4e09\u79cd\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u4e0e\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2507.15442", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15442", "abs": "https://arxiv.org/abs/2507.15442", "authors": ["Owen Douglas", "Aku Kammonen", "Anamika Pandey", "Ra\u00fal Tempone"], "title": "An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations", "comment": "20 Pages", "summary": "This work proposes a training algorithm based on adaptive random Fourier\nfeatures (ARFF) with Metropolis sampling and resampling\n\\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and\ndiffusion components of stochastic differential equations from snapshot data.\nSpecifically, this study considers It\\^{o} diffusion processes and a\nlikelihood-based loss function derived from the Euler-Maruyama integration\nintroduced in \\cite{Dietrich2023} and\n\\cite{dridi2021learningstochasticdynamicalsystems}.\n  This work evaluates the proposed method against benchmark problems presented\nin \\cite{Dietrich2023}, including polynomial examples, underdamped Langevin\ndynamics, a stochastic susceptible-infected-recovered model, and a stochastic\nwave equation. Across all cases, the ARFF-based approach matches or surpasses\nthe performance of conventional Adam-based optimization in both loss\nminimization and convergence speed. These results highlight the potential of\nARFF as a compelling alternative for data-driven modeling of stochastic\ndynamics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a ARFF \u7684\u65b0\u8bad\u7ec3\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u8fc7\u7a0b\u3002\u8be5\u7b97\u6cd5\u5728\u6027\u80fd\u548c\u901f\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u968f\u673a\u52a8\u529b\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b0\u9009\u62e9\u3002", "motivation": "\u4ece\u5feb\u7167\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6f02\u79fb\u548c\u6269\u6563\u5206\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08ARFF\uff09\u5e76\u7ed3\u5408Metropolis\u91c7\u6837\u548c\u91cd\u91c7\u6837\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u5feb\u7167\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6f02\u79fb\u548c\u6269\u6563\u5206\u91cf\uff0c\u5e76\u91c7\u7528\u4e86\u57fa\u4e8eEuler-Maruyama\u79ef\u5206\u7684\u4f3c\u7136\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u5305\u62ec\u591a\u9879\u5f0f\u793a\u4f8b\u3001\u6b20\u963b\u5c3c Langevin \u52a8\u529b\u5b66\u3001\u968f\u673a\u6613\u611f-\u611f\u67d3-\u6062\u590d\u6a21\u578b\u548c\u968f\u673a\u6ce2\u52a8\u65b9\u7a0b\u5728\u5185\u7684\u57fa\u51c6\u95ee\u9898\u4e0a\uff0cARFF \u65b9\u6cd5\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8e Adam \u7684\u4f18\u5316\u65b9\u6cd5\u5728\u635f\u5931\u6700\u5c0f\u5316\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u5747\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "ARFF\u4f5c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u968f\u673a\u52a8\u529b\u5b66\u5efa\u6a21\u7684\u6709\u529b\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u635f\u5931\u6700\u5c0f\u5316\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u90fd\u4e0e\u57fa\u4e8eAdam\u7684\u4f18\u5316\u65b9\u6cd5\u76f8\u5339\u914d\u6216\u8d85\u8d8a\u3002"}}
{"id": "2507.15401", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15401", "abs": "https://arxiv.org/abs/2507.15401", "authors": ["Huiyu Zhai", "Xingxing Yang", "Yalan Ye", "Chenyang Li", "Bin Fan", "Changze Li"], "title": "Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond", "comment": null, "summary": "Facial expression recognition (FER) is a challenging task due to pervasive\nocclusion and dataset biases. Especially when facial information is partially\noccluded, existing FER models struggle to extract effective facial features,\nleading to inaccurate classifications. In response, we present ORSANet, which\nintroduces the following three key contributions: First, we introduce auxiliary\nmulti-modal semantic guidance to disambiguate facial occlusion and learn\nhigh-level semantic knowledge, which is two-fold: 1) we introduce semantic\nsegmentation maps as dense semantics prior to generate semantics-enhanced\nfacial representations; 2) we introduce facial landmarks as sparse geometric\nprior to mitigate intrinsic noises in FER, such as identity and gender biases.\nSecond, to facilitate the effective incorporation of these two multi-modal\npriors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively\nfuse the landmark feature and semantics-enhanced representations within\ndifferent scales. Third, we design a Dynamic Adversarial Repulsion Enhancement\nLoss (DARELoss) that dynamically adjusts the margins of ambiguous classes,\nfurther enhancing the model's ability to distinguish similar expressions. We\nfurther construct the first occlusion-oriented FER dataset to facilitate\nspecialized robustness analysis on various real-world occlusion conditions,\ndubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER\ndemonstrate that our proposed ORSANet achieves SOTA recognition performance.\nCode is publicly available at https://github.com/Wenyuzhy/ORSANet-master.", "AI": {"tldr": "ORSANet\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u5206\u5272\u56fe\u548c\u9762\u90e8\u5173\u952e\u70b9\uff0c\u5e76\u4f7f\u7528\u521b\u65b0\u7684\u6a21\u5757\u548c\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9762\u90e8\u906e\u6321\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u6a21\u578b\u5728\u5904\u7406\u90e8\u5206\u906e\u6321\u7684\u9762\u90e8\u4fe1\u606f\u65f6\uff0c\u96be\u4ee5\u63d0\u53d6\u6709\u6548\u7684\u9762\u90e8\u7279\u5f81\uff0c\u5bfc\u81f4\u5206\u7c7b\u4e0d\u51c6\u786e\u3002", "method": "ORSANet\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a1.\u5f15\u5165\u591a\u6a21\u6001\u8bed\u4e49\u5f15\u5bfc\uff08\u8bed\u4e49\u5206\u5272\u56fe\u548c\u9762\u90e8\u5173\u952e\u70b9\uff09\u6765\u5904\u7406\u9762\u90e8\u906e\u6321\u95ee\u9898\uff0c\u5b66\u4e60\u9ad8\u5c42\u8bed\u4e49\u77e5\u8bc6\u30022.\u8bbe\u8ba1\u4e86\u591a\u5c3a\u5ea6\u4ea4\u53c9\u4ea4\u4e92\u6a21\u5757\uff08MCM\uff09\u6765\u878d\u5408\u591a\u6a21\u6001\u5148\u9a8c\u4fe1\u606f\u30023.\u63d0\u51fa\u4e86\u52a8\u6001\u5bf9\u6297\u6392\u65a5\u589e\u5f3a\u635f\u5931\uff08DARELoss\uff09\u6765\u533a\u5206\u76f8\u4f3c\u8868\u60c5\u3002", "result": "ORSANet\u901a\u8fc7\u5f15\u5165\u591a\u6a21\u6001\u8bed\u4e49\u5f15\u5bfc\u3001\u591a\u5c3a\u5ea6\u4ea4\u53c9\u4ea4\u4e92\u6a21\u5757\u548c\u52a8\u6001\u5bf9\u6297\u6392\u65a5\u589e\u5f3a\u635f\u5931\uff0c\u5728\u5305\u542b\u906e\u6321\u7684\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "ORSANet\u5728\u516c\u5f00\u57fa\u51c6\u548cOcclu-FER\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2507.15470", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15470", "abs": "https://arxiv.org/abs/2507.15470", "authors": ["Baran Can G\u00fcl", "Suraksha Nadig", "Stefanos Tziampazis", "Nasser Jazdi", "Michael Weyrich"], "title": "FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning", "comment": "Preprint version. Accepted for publication at IEEE ICECCME 2025", "summary": "In-vehicle emotion recognition underpins adaptive driver-assistance systems\nand, ultimately, occupant safety. However, practical deployment is hindered by\n(i) modality fragility - poor lighting and occlusions degrade vision-based\nmethods; (ii) physiological variability - heart-rate and skin-conductance\npatterns differ across individuals; and (iii) privacy risk - centralized\ntraining requires transmission of sensitive data. To address these challenges,\nwe present FedMultiEmo, a privacy-preserving framework that fuses two\ncomplementary modalities at the decision level: visual features extracted by a\nConvolutional Neural Network from facial images, and physiological cues (heart\nrate, electrodermal activity, and skin temperature) classified by a Random\nForest. FedMultiEmo builds on three key elements: (1) a multimodal federated\nlearning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud\nprototype on Raspberry Pi clients and a Flower server, and (3) a personalized\nFederated Averaging scheme that weights client updates by local data volume.\nEvaluated on FER2013 and a custom physiological dataset, the federated\nConvolutional Neural Network attains 77% accuracy, the Random Forest 74%, and\ntheir fusion 87%, matching a centralized baseline while keeping all raw data\nlocal. The developed system converges in 18 rounds, with an average round time\nof 120 seconds and a per-client memory footprint below 200 MB. These results\nindicate that FedMultiEmo offers a practical approach to real-time,\nprivacy-aware emotion recognition in automotive settings.", "AI": {"tldr": "FedMultiEmo \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u89c6\u89c9\u548c\u751f\u7406\u6570\u636e\uff0c\u5728\u6c7d\u8f66\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u5b9e\u65f6\u60c5\u611f\u8bc6\u522b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5b9e\u9645\u90e8\u7f72\u4e2d\u89c6\u89c9\u65b9\u6cd5\u7684\u5149\u7167\u4e0d\u4f73\u548c\u906e\u6321\u95ee\u9898\u3001\u8de8\u4e2a\u4f53\u7684\u5fc3\u7387\u548c\u76ae\u80a4\u7535\u5bfc\u7387\u6a21\u5f0f\u5dee\u5f02\u4ee5\u53ca\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 FedMultiEmo \u6846\u67b6\u3002", "method": "FedMultiEmo \u662f\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u5b83\u5728\u51b3\u7b56\u5c42\u9762\u878d\u5408\u4e86\u4e24\u79cd\u4e92\u8865\u7684\u6a21\u5f0f\uff1a\u6765\u81ea\u9762\u90e8\u56fe\u50cf\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u4ee5\u53ca\u968f\u673a\u68ee\u6797\u5206\u7c7b\u7684\u751f\u7406\u7ebf\u7d22\uff08\u5fc3\u7387\u3001\u76ae\u80a4\u7535\u6d3b\u52a8\u548c\u76ae\u80a4\u6e29\u5ea6\uff09\u3002FedMultiEmo \u57fa\u4e8e\u4e09\u4e2a\u5173\u952e\u8981\u7d20\uff1a(1) \u5177\u6709\u591a\u6570\u6295\u7968\u878d\u5408\u7684\u591a\u6a21\u5f0f\u8054\u90a6\u5b66\u4e60\u7ba1\u9053\uff0c(2) \u5728 Raspberry Pi \u5ba2\u6237\u7aef\u548c Flower \u670d\u52a1\u5668\u4e0a\u7684\u7aef\u5230\u7aef\u8fb9\u7f18\u5230\u4e91\u539f\u578b\uff0c(3) \u52a0\u6743\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5e73\u5747\u65b9\u6848\u3002", "result": "\u5728 FER2013 \u548c\u81ea\u5b9a\u4e49\u751f\u7406\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u8054\u90a6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u51c6\u786e\u7387\u4e3a 77%\uff0c\u968f\u673a\u68ee\u6797\u4e3a 74%\uff0c\u4e24\u8005\u878d\u5408\u540e\u53ef\u8fbe 87%\uff0c\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u76f8\u5f53\uff0c\u540c\u65f6\u6240\u6709\u539f\u59cb\u6570\u636e\u90fd\u4fdd\u7559\u5728\u672c\u5730\u3002\u5f00\u53d1\u7684\u7cfb\u7edf\u5728 18 \u8f6e\u5185\u6536\u655b\uff0c\u5e73\u5747\u6bcf\u8f6e\u8017\u65f6 120 \u79d2\uff0c\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u5185\u5b58\u5360\u7528\u91cf\u4f4e\u4e8e 200 MB\u3002", "conclusion": "FedMultiEmo \u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u6c7d\u8f66\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u65f6\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u60c5\u611f\u8bc6\u522b\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.15507", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15507", "abs": "https://arxiv.org/abs/2507.15507", "authors": ["Johannes Ackermann", "Takashi Ishida", "Masashi Sugiyama"], "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback", "comment": "Accept at the Conference On Language Modeling (COLM) 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models,\nsuch as language models (LMs), to follow complex human preferences. In RLHF for\nLMs, we first train an LM using supervised fine-tuning, sample pairs of\nresponses, obtain human feedback, and use the resulting data to train a reward\nmodel (RM). RL methods are then used to train the LM to maximize the reward\ngiven by the RM. As training progresses, the responses generated by the LM no\nlonger resemble the responses seen by the RM during training, leading to the RM\nbecoming inaccurate. The score given by the RM keeps increasing, but the\nlearned behavior no longer matches the human preferences. This issue is known\nas overoptimization. We investigate overoptimization from the point of view of\ndistribution shift and show that the shift results in an inconsistent estimate\nof the RM parameters, leading to an inconsistent estimate of the policy\ngradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which\niteratively off-policy corrects the RM using importance weighting, without\nrequiring new labels or samples. This results in a more accurate RM, which\nempirically leads to an improved final policy. We validate our approach in\nexperiments with summarization and chatbot datasets and show that it performs\nsignificantly better than standard RLHF methods and baselines. Our\nimplementation is available at\nhttps://github.com/JohannesAck/OffPolicyCorrectedRewardModeling", "AI": {"tldr": "OCRM \u901a\u8fc7\u6837\u672c\u5916\u6821\u6b63\u5956\u52b1\u6a21\u578b\u89e3\u51b3\u4e86 RLHF \u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5728 RLHF \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u7740\u6a21\u578b\u751f\u6210\u54cd\u5e94\u7684\u5206\u5e03\u53d1\u751f\u504f\u79fb\uff0c\u5bfc\u81f4 RM \u9884\u6d4b\u4e0d\u51c6\u786e\uff0c\u5373\u4f7f RM \u5206\u6570\u6301\u7eed\u63d0\u9ad8\uff0c\u5b66\u4e60\u884c\u4e3a\u4e5f\u53ef\u80fd\u4e0d\u518d\u7b26\u5408\u4eba\u7c7b\u504f\u597d\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u8fc7\u4f18\u5316\u3002", "method": "\u63d0\u51fa Off-Policy Corrected Reward Modeling (OCRM)\uff0c\u901a\u8fc7\u8fed\u4ee3\u5730\u4f7f\u7528\u91cd\u8981\u6027\u52a0\u6743\u8fdb\u884c\u6837\u672c\u5916\u6821\u6b63\uff0c\u4ee5\u83b7\u5f97\u66f4\u51c6\u786e\u7684\u5956\u52b1\u6a21\u578b\uff08RM\uff09\uff0c\u65e0\u9700\u65b0\u7684\u6807\u7b7e\u6216\u6837\u672c\u3002", "result": "OCRM \u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684 RM\uff0c\u5728\u6458\u8981\u548c\u804a\u5929\u673a\u5668\u4eba\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u6807\u51c6 RLHF \u65b9\u6cd5\u548c\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6700\u7ec8\u7b56\u7565\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "RLHF \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u7531\u4e8e\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u5956\u52b1\u6a21\u578b\uff08RM\uff09\u8fc7\u62df\u5408\uff0c\u8fdb\u800c\u7b56\u7565\u68af\u5ea6\u4f30\u8ba1\u4e0d\u4e00\u81f4\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a OCRM \u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u5730\u4f7f\u7528\u91cd\u8981\u6027\u52a0\u6743\u8fdb\u884c\u6837\u672c\u5916\u6821\u6b63\uff0c\u4ee5\u83b7\u5f97\u66f4\u51c6\u786e\u7684 RM\uff0c\u4ece\u800c\u6539\u8fdb\u6700\u7ec8\u7b56\u7565\u3002\u5b9e\u9a8c\u8bc1\u660e OCRM \u5728\u6458\u8981\u548c\u804a\u5929\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u6807\u51c6 RLHF \u65b9\u6cd5\u548c\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2507.15418", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15418", "abs": "https://arxiv.org/abs/2507.15418", "authors": ["Ka Young Kim", "Hyeon Bae Kim", "Seong Tae Kim"], "title": "SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition", "comment": "Accepted to MICCAI 2025", "summary": "Surgical phase recognition plays a crucial role in surgical workflow\nanalysis, enabling various applications such as surgical monitoring, skill\nassessment, and workflow optimization. Despite significant advancements in deep\nlearning-based surgical phase recognition, these models remain inherently\nopaque, making it difficult to understand how they make decisions. This lack of\ninterpretability hinders trust and makes it challenging to debug the model. To\naddress this challenge, we propose SurgX, a novel concept-based explanation\nframework that enhances the interpretability of surgical phase recognition\nmodels by associating neurons with relevant concepts. In this paper, we\nintroduce the process of selecting representative example sequences for\nneurons, constructing a concept set tailored to the surgical video dataset,\nassociating neurons with concepts and identifying neurons crucial for\npredictions. Through extensive experiments on two surgical phase recognition\nmodels, we validate our method and analyze the explanation for prediction. This\nhighlights the potential of our method in explaining surgical phase\nrecognition. The code is available at https://github.com/ailab-kyunghee/SurgX", "AI": {"tldr": "SurgX\u901a\u8fc7\u6982\u5ff5\u5173\u8054\u63d0\u9ad8\u624b\u672f\u9636\u6bb5\u8bc6\u522b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u4e0d\u900f\u660e\u6027\u95ee\u9898\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u624b\u672f\u9636\u6bb5\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u56fa\u6709\u7684\u4e0d\u900f\u660e\u6027\uff0c\u96be\u4ee5\u7406\u89e3\u5176\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8fd9\u963b\u788d\u4e86\u4fe1\u4efb\u5e76\u4f7f\u6a21\u578b\u8c03\u8bd5\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSurgX\u7684\u65b0\u578b\u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u5305\u62ec\u9009\u62e9\u4ee3\u8868\u6027\u793a\u4f8b\u5e8f\u5217\u3001\u6784\u5efa\u5b9a\u5236\u5316\u6982\u5ff5\u96c6\u3001\u5c06\u795e\u7ecf\u5143\u4e0e\u6982\u5ff5\u76f8\u5173\u8054\u4ee5\u53ca\u8bc6\u522b\u5bf9\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u7684\u795e\u7ecf\u5143\u3002", "result": "\u901a\u8fc7\u5728\u4e24\u4e2a\u624b\u672f\u9636\u6bb5\u8bc6\u522b\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86SurgX\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5176\u9884\u6d4b\u89e3\u91ca\u3002", "conclusion": "SurgX\u6846\u67b6\u901a\u8fc7\u5c06\u795e\u7ecf\u5143\u4e0e\u76f8\u5173\u6982\u5ff5\u76f8\u5173\u8054\uff0c\u589e\u5f3a\u4e86\u624b\u672f\u9636\u6bb5\u8bc6\u522b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.15640", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15640", "abs": "https://arxiv.org/abs/2507.15640", "authors": ["Kailai Yang", "Xiao Liu", "Lei Ji", "Hao Li", "Yeyun Gong", "Peng Cheng", "Mao Yang"], "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training", "comment": null, "summary": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Data Mixing Agent \u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u8c03\u6574\u4e0d\u540c\u9886\u57df\u8bad\u7ec3\u6570\u636e\u7684\u6743\u91cd\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u65b0\u77e5\u8bc6\u65f6\u9057\u5fd8\u65e7\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u5e76\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8fd8\u5177\u5907\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6301\u7eed\u9884\u8bad\u7ec3\u867d\u7136\u80fd\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65b0\u9886\u57df\u7684\u8868\u73b0\uff0c\u4f46\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u539f\u6709\u80fd\u529b\u7684\u98ce\u9669\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u901a\u8fc7\u91cd\u65b0\u52a0\u6743\u4e0d\u540c\u57df\u7684\u8bad\u7ec3\u6570\u636e\u6765\u5e73\u8861\u6a21\u578b\u5728\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u624b\u52a8\u6307\u5b9a\u6216\u57fa\u4e8e\u4eba\u7c7b\u76f4\u89c9/\u7ecf\u9a8c\u7ed3\u679c\u7684\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u4e0d\u591f\u901a\u7528\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Data Mixing Agent \u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u5b66\u4e60\u5982\u4f55\u91cd\u65b0\u52a0\u6743\u6765\u81ea\u4e0d\u540c\u57df\uff08\u6e90\u57df\u548c\u76ee\u6807\u57df\uff09\u7684\u8bad\u7ec3\u6570\u636e\u3002\u4e0e\u4f9d\u8d56\u624b\u52a8\u6307\u5b9a\u6216\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u4f20\u7edf\u65b9\u6cd5\u4e0d\u540c\uff0cData Mixing Agent \u901a\u8fc7\u5728\u5927\u91cf\u6570\u636e\u6df7\u5408\u8f68\u8ff9\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u6839\u636e\u8bc4\u4f30\u73af\u5883\u7684\u53cd\u9988\u8fdb\u884c\u5b66\u4e60\uff0c\u4ece\u800c\u5b66\u4e60\u5230\u66f4\u901a\u7528\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u3002", "result": "Data Mixing Agent \u5728\u6570\u5b66\u63a8\u7406\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u4efb\u52a1\u4e2d\uff0c\u5b9e\u73b0\u4e86\u6bd4\u5f3a\u57fa\u7ebf\u6a21\u578b\u66f4\u4f18\u7684\u5e73\u8861\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728\u672a\u89c1\u8fc7\u7684\u6e90\u57df\u3001\u76ee\u6807\u6a21\u578b\u548c\u57df\u7a7a\u95f4\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u76f4\u63a5\u5e94\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u9886\u57df\u4e5f\u8bc1\u660e\u4e86\u5176\u8de8\u76ee\u6807\u57df\u7684\u9002\u5e94\u6027\u3002", "conclusion": "Data Mixing Agent \u662f\u4e00\u79cd\u65b0\u9896\u7684\u3001\u57fa\u4e8e\u6a21\u578b\u7684\u3001\u7aef\u5230\u7aef\u7684\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4f1a\u4e86\u5bf9\u57df\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\uff0c\u4ece\u800c\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u8de8\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u5e73\u8861\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5e94\u7528\u4e8e\u65b0\u7684\u9886\u57df\u3001\u6a21\u578b\u548c\u57df\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5b66\u4e60\u5230\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u4e0e\u4eba\u7c7b\u76f4\u89c9\u4e00\u81f4\uff0c\u5e76\u4e14\u80fd\u7528\u66f4\u5c11\u7684\u6e90\u57df\u6570\u636e\u5b9e\u73b0\u5353\u8d8a\u7684\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.15428", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15428", "abs": "https://arxiv.org/abs/2507.15428", "authors": ["Jiaao Li", "Kaiyuan Li", "Chen Gao", "Yong Li", "Xinlei Chen"], "title": "EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent", "comment": null, "summary": "Egomotion videos are first-person recordings where the view changes\ncontinuously due to the agent's movement. As they serve as the primary visual\ninput for embodied AI agents, making egomotion video reasoning more efficient\nis therefore essential for real-world deployment. Recent advances in\nvision-language models have enabled strong multimodal reasoning capabilities,\nbut their computational cost remains prohibitive for long, redundant video\ninputs. Existing token pruning methods, typically designed for third-person\nvideos, fail to leverage the spatiotemporal continuity and motion constraints\ninherent in egomotion settings. To address this, we propose EgoPrune, a\ntraining-free token pruning method tailored for egomotion video reasoning.\nEgoPrune comprises three components: a keyframe selector adapted from EmbodiedR\nfor temporally efficient sampling; Perspective-Aware Redundancy Filtering\n(PARF), which aligns visual tokens using perspective transformations and\nremoves redundant tokens; and a Maximal Marginal Relevance (MMR)-based token\nselector that jointly considers visual-text relevance and intra-frame\ndiversity. Experiments on two egomotion video benchmarks show that EgoPrune\nconsistently outperforms prior training-free methods across various pruning\nratios while significantly reducing FLOPs, memory usage, and latency. Moreover,\nwe deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB\nedge device, demonstrating its real-world efficiency and suitability for\non-device egomotion video reasoning.", "AI": {"tldr": "EgoPrune\u662f\u4e00\u79cd\u521b\u65b0\u7684\u514d\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5173\u952e\u5e27\u9009\u62e9\u3001\u89c6\u89d2\u611f\u77e5\u5197\u4f59\u8fc7\u6ee4\u548cMMR\u9009\u62e9\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u7684\u63a8\u7406\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\uff08egomotion\uff09\u89c6\u9891\u63a8\u7406\u7684\u6548\u7387\uff0c\u4ee5\u5e94\u5bf9\u5176\u5728\u5177\u8eabAI\uff08embodied AI\uff09\u4ee3\u7406\u4e2d\u4f5c\u4e3a\u4e3b\u8981\u89c6\u89c9\u8f93\u5165\u7684\u9700\u6c42\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4e0d\u9002\u7528\u4e8e\u957f\u89c6\u9891\u8f93\u5165\uff0c\u800c\u4e3a\u7b2c\u4e09\u4eba\u79f0\u89c6\u9891\u8bbe\u8ba1\u7684\u4ee4\u724c\u526a\u9664\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u7684\u65f6\u7a7a\u8fde\u7eed\u6027\u548c\u8fd0\u52a8\u7ea6\u675f\u3002", "method": "EgoPrune\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a1. \u5173\u952e\u5e27\u9009\u62e9\u5668\uff1a\u7528\u4e8e\u4ece\u89c6\u9891\u4e2d\u9ad8\u6548\u5730\u62bd\u53d6\u65f6\u95f4\u5b50\u96c6\u30022. \u89c6\u89d2\u611f\u77e5\u5197\u4f59\u8fc7\u6ee4\uff08PARF\uff09\uff1a\u901a\u8fc7\u89c6\u89d2\u53d8\u6362\u5bf9\u9f50\u89c6\u89c9\u4ee4\u724c\u5e76\u53bb\u9664\u5197\u4f59\u4fe1\u606f\u30023. \u6700\u5927\u8fb9\u7f18\u76f8\u5173\u6027\uff08MMR\uff09\u4ee4\u724c\u9009\u62e9\u5668\uff1a\u7efc\u5408\u8003\u8651\u89c6\u89c9-\u6587\u672c\u76f8\u5173\u6027\u548c\u5e27\u5185\u591a\u6837\u6027\u6765\u9009\u62e9\u4ee4\u724c\u3002", "result": "EgoPrune\u5728\u4e24\u4e2a\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65e0\u8bba\u5728\u4f55\u79cd\u526a\u9664\u6bd4\u4f8b\u4e0b\uff0c\u5176\u6027\u80fd\u59cb\u7ec8\u4f18\u4e8e\u4e4b\u524d\u7684\u514d\u8bad\u7ec3\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u5b83\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u91cf\uff08FLOPs\uff09\u3001\u5185\u5b58\u5360\u7528\u548c\u5ef6\u8fdf\u3002\u8be5\u65b9\u6cd5\u5df2\u6210\u529f\u90e8\u7f72\u5728\u642d\u8f7dJetson Orin NX 16GB\u8fb9\u7f18\u8bbe\u5907\u7684\u5177\u8eab\u4ee3\u7406\u4e0a\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "EgoPrune\u662f\u4e00\u79cd\u9488\u5bf9\u81ea\u4e3b\u79fb\u52a8\u89c6\u9891\u63a8\u7406\u7684\u514d\u8bad\u7ec3\uff08training-free\uff09\u7684\u4ee4\u724c\u526a\u9664\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5173\u952e\u5e27\u9009\u62e9\u3001\u89c6\u89d2\u611f\u77e5\u5197\u4f59\u8fc7\u6ee4\uff08PARF\uff09\u548c\u6700\u5927\u8fb9\u7f18\u76f8\u5173\u6027\uff08MMR\uff09\u4ee4\u724c\u9009\u62e9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u957f\u89c6\u9891\u8f93\u5165\u65f6\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cEgoPrune\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5148\u524d\u514d\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u91cf\u3001\u5185\u5b58\u4f7f\u7528\u548c\u5ef6\u8fdf\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5df2\u6210\u529f\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2507.15523", "categories": ["cs.LG", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.15523", "abs": "https://arxiv.org/abs/2507.15523", "authors": ["Weichuang Shao", "Iman Yi Liao", "Tomas Henrique Bode Maul", "Tissa Chandesa"], "title": "An Investigation of Test-time Adaptation for Audio Classification under Background Noise", "comment": null, "summary": "Domain shift is a prominent problem in Deep Learning, causing a model\npre-trained on a source dataset to suffer significant performance degradation\non test datasets. This research aims to address the issue of audio\nclassification under domain shift caused by background noise using Test-Time\nAdaptation (TTA), a technique that adapts a pre-trained model during testing\nusing only unlabelled test data before making predictions. We adopt two common\nTTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and\ninvestigate their respective performance on two popular audio classification\ndatasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types\nof background noise and noise severity levels. The experimental results reveal\nthat our proposed modified version of CoNMix produced the highest\nclassification accuracy under domain shift (5.31% error rate under 10 dB\nexercise bike background noise and 12.75% error rate under 3 dB running tap\nbackground noise for AM) compared to TTT and TENT. The literature search\nprovided no evidence of similar works, thereby motivating the work reported\nhere as the first study to leverage TTA techniques for audio classification\nunder domain shift.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5c06TTA\u6280\u672f\u5e94\u7528\u4e8e\u9886\u57df\u504f\u79fb\u4e0b\u7684\u97f3\u9891\u5206\u7c7b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684CoNMix\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u566a\u58f0\u6761\u4ef6\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u9886\u57df\u504f\u79fb\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u7a81\u51fa\u95ee\u9898\uff0c\u5b83\u4f1a\u5bfc\u81f4\u5728\u6e90\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u51fa\u73b0\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6d4b\u8bd5\u65f6\u57df\u9002\u5e94\uff08TTA\uff09\u6765\u89e3\u51b3\u7531\u80cc\u666f\u566a\u58f0\u5f15\u8d77\u7684\u9886\u57df\u504f\u79fb\u4e0b\u7684\u97f3\u9891\u5206\u7c7b\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528TTT\u3001TENT\u548cCoNMix\u4e24\u79cd\u5e38\u89c1\u7684\u6d4b\u8bd5\u65f6\u57df\u9002\u5e94\uff08TTA\uff09\u65b9\u6cd5\uff0c\u5e76\u5bf9CoNMix\u8fdb\u884c\u4e86\u4fee\u6539\uff0c\u4ee5\u89e3\u51b3\u7531\u80cc\u666f\u566a\u58f0\u5f15\u8d77\u7684\u9886\u57df\u504f\u79fb\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u4fee\u6539\u7248CoNMix\u5728\u9886\u57df\u504f\u79fb\u4e0b\u4ea7\u751f\u4e86\u6700\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u4fee\u6539\u7248CoNMix\u5728\u9886\u57df\u504f\u79fb\u4e0b\u5177\u6709\u6700\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5728AM\u6570\u636e\u96c6\u768410dB\u8fd0\u52a8\u81ea\u884c\u8f66\u80cc\u666f\u566a\u58f0\u4e0b\u9519\u8bef\u7387\u4e3a5.31%\uff0c\u57283dB\u8dd1\u6b65\u6c34\u9f99\u5934\u80cc\u666f\u566a\u58f0\u4e0b\u9519\u8bef\u7387\u4e3a12.75%\uff0c\u4f18\u4e8eTTT\u548cTENT\u3002"}}
{"id": "2507.15480", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15480", "abs": "https://arxiv.org/abs/2507.15480", "authors": ["Liang Chen", "Ghazi Shazan Ahmad", "Tianjun Yao", "Lingqiao Liu", "Zhiqiang Shen"], "title": "One Last Attention for Your Vision-Language Model", "comment": "Accepted by ICCV 2025", "summary": "Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable\nzero-shot performance, yet their downstream potential hinges on effective\nfine-tuning. Most adaptation methods typically focus on refining representation\nfrom separate modalities (text or vision) but neglect the critical role of\ntheir fused representations in the decision-making process, \\emph{\\ie} rational\nmatrix that drives the final prediction. To bridge the gap, we propose a simple\nyet effective \\textbf{R}ational \\textbf{Ada}ptaion ({RAda}) to explicitly\nexploit the final fused representation during fine-tuning. RAda employs a\nlearned mask, obtained from a lightweight attention layer attached at the end\nof a VLM, to dynamically calibrate the contribution of each element in the\nrational matrix, enabling targeted adjustments to the final cross-modal\ninteractions without incurring costly modifications to intermediate features.\nExperiments in different settings (i.e., updating, or freezing pretrained\nencoders in adaptation, and test-time training that can only access the\nunlabeled test data) show that RAda serves as a versatile fine-tuning\ntechnique, improving the baseline with minimal code and performing comparably\nagainst current arts in most settings. Code is available at\n\\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.", "AI": {"tldr": "RAda \u662f\u4e00\u79cd\u65b0\u7684 VLM \u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6700\u7ec8\u7684\u878d\u5408\u8868\u793a\u6765\u6539\u8fdb\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u591a\u6570 VLM \u5fae\u8c03\u65b9\u6cd5\u901a\u5e38\u4fa7\u91cd\u4e8e\u4ece\u5355\u72ec\u7684\u6a21\u6001\uff08\u6587\u672c\u6216\u89c6\u89c9\uff09\u4e2d\u7cbe\u70bc\u8868\u793a\uff0c\u800c\u5ffd\u7565\u4e86\u5b83\u4eec\u5728\u51b3\u7b56\u8fc7\u7a0b\uff08\u5373\u9a71\u52a8\u6700\u7ec8\u9884\u6d4b\u7684\u7406\u6027\u77e9\u9635\uff09\u4e2d\u878d\u5408\u8868\u793a\u7684\u5173\u952e\u4f5c\u7528\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u7406\u6027\u9002\u5e94 (RAda) \u65b9\u6cd5\uff0c\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u5730\u5229\u7528\u6700\u7ec8\u7684\u878d\u5408\u8868\u793a\u3002", "method": "RAda \u91c7\u7528\u4e86\u4e00\u4e2a\u5728 VLM \u672b\u7aef\u9644\u52a0\u7684\u8f7b\u91cf\u7ea7\u6ce8\u610f\u529b\u5c42\u5b66\u4e60\u5230\u7684\u63a9\u7801\uff0c\u4ee5\u52a8\u6001\u6821\u51c6\u7406\u6027\u77e9\u9635\u4e2d\u6bcf\u4e2a\u5143\u7d20\u7684\u8d21\u732e\uff0c\u4ece\u800c\u5728\u4e0d\u4ea7\u751f\u9ad8\u6602\u7684\u4e2d\u95f4\u7279\u5f81\u4fee\u6539\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u6700\u7ec8\u7684\u8de8\u6a21\u6001\u4ea4\u4e92\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRAda \u662f\u4e00\u79cd\u591a\u529f\u80fd\u5fae\u8c03\u6280\u672f\uff0c\u80fd\u591f\u6539\u8fdb\u57fa\u7ebf\u5e76\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\u76f8\u5ab2\u7f8e\u3002", "conclusion": "RAda \u662f\u4e00\u79cd\u591a\u529f\u80fd\u5fae\u8c03\u6280\u672f\uff0c\u5728\u5927\u591a\u6570\u8bbe\u7f6e\u4e2d\u90fd\u80fd\u4ee5\u6700\u5c11\u7684\u4ee3\u7801\u6539\u8fdb\u57fa\u7ebf\u5e76\u4e0e\u5f53\u524d\u6280\u672f\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2507.15545", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15545", "abs": "https://arxiv.org/abs/2507.15545", "authors": ["Yujia Shi", "Emil Njor", "Pablo Mart\u00ednez-Nuevo", "Sven Ewan Shepstone", "Xenofon Fafoutis"], "title": "Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications", "comment": null, "summary": "The success of Machine Learning is increasingly tempered by its significant\nresource footprint, driving interest in efficient paradigms like TinyML.\nHowever, the inherent complexity of designing TinyML systems hampers their\nbroad adoption. To reduce this complexity, we introduce \"Data Aware\nDifferentiable Neural Architecture Search\". Unlike conventional Differentiable\nNeural Architecture Search, our approach expands the search space to include\ndata configuration parameters alongside architectural choices. This enables\nData Aware Differentiable Neural Architecture Search to co-optimize model\narchitecture and input data characteristics, effectively balancing resource\nusage and system performance for TinyML applications. Initial results on\nkeyword spotting demonstrate that this novel approach to TinyML system design\ncan generate lean but highly accurate systems.", "AI": {"tldr": "\u4e3a\u4e86\u7b80\u5316TinyML\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u540c\u65f6\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u8f93\u5165\u6570\u636e\uff0c\u4ece\u800c\u4e3aTinyML\u5e94\u7528\u521b\u5efa\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u7cfb\u7edf\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7684\u8d44\u6e90\u5360\u7528\u663e\u8457\uff0c\u8fd9\u6fc0\u53d1\u4e86\u5bf9TinyML\u7b49\u9ad8\u6548\u8303\u4f8b\u7684\u5174\u8da3\uff0c\u4f46TinyML\u7cfb\u7edf\u7684\u8bbe\u8ba1\u590d\u6742\u6027\u963b\u788d\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6570\u636e\u611f\u77e5\u53ef\u5fae\u5206\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u201d\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u6570\u636e\u914d\u7f6e\u53c2\u6570\u4e0e\u67b6\u6784\u9009\u62e9\u76f8\u7ed3\u5408\uff0c\u4ee5\u6269\u5c55\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5728\u5173\u952e\u8bcd\u8bc6\u522b\u65b9\u9762\u7684\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b0\u9896\u7684TinyML\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u7cbe\u7b80\u4f46\u9ad8\u5ea6\u51c6\u786e\u7684\u7cfb\u7edf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u9896\u65b9\u6cd5\u80fd\u591f\u4e3aTinyML\u5e94\u7528\u751f\u6210\u7cbe\u7b80\u4f46\u9ad8\u5ea6\u51c6\u786e\u7684\u7cfb\u7edf\u3002"}}
{"id": "2507.15492", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15492", "abs": "https://arxiv.org/abs/2507.15492", "authors": ["Rakesh John Amala Arokia Nathan", "Matthias Gessner", "Nurullah \u00d6zkan", "Marius Bock", "Mohamed Youssef", "Maximilian Mews", "Bj\u00f6rn Piltz", "Ralf Berger", "Oliver Bimber"], "title": "An aerial color image anomaly dataset for search missions in complex forested terrain", "comment": "17 pages", "summary": "After a family murder in rural Germany, authorities failed to locate the\nsuspect in a vast forest despite a massive search. To aid the search, a\nresearch aircraft captured high-resolution aerial imagery. Due to dense\nvegetation obscuring small clues, automated analysis was ineffective, prompting\na crowd-search initiative. This effort produced a unique dataset of labeled,\nhard-to-detect anomalies under occluded, real-world conditions. It can serve as\na benchmark for improving anomaly detection approaches in complex forest\nenvironments, supporting manhunts and rescue operations. Initial benchmark\ntests showed existing methods performed poorly, highlighting the need for\ncontext-aware approaches. The dataset is openly accessible for offline\nprocessing. An additional interactive web interface supports online viewing and\ndynamic growth by allowing users to annotate and submit new findings.", "AI": {"tldr": "\u7531\u4e8e\u68ee\u6797\u8302\u5bc6\uff0c\u641c\u5bfb\u5931\u8e2a\u4eba\u5458\u56f0\u96be\u91cd\u91cd\uff0c\u56e0\u6b64\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u4f17\u5305\u6807\u6ce8\u5f02\u5e38\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u6539\u8fdb\u641c\u7d22\u6280\u672f\u3002", "motivation": "\u5728\u4e00\u6b21\u5bb6\u5ead\u8c0b\u6740\u6848\u7684\u641c\u6355\u884c\u52a8\u4e2d\uff0c\u7531\u4e8e\u690d\u88ab\u8302\u5bc6\uff0c\u81ea\u52a8\u5316\u5206\u6790\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u4f17\u5305\u641c\u7d22\u6765\u5bfb\u627e\u7ebf\u7d22\u3002", "method": "\u901a\u8fc7\u4f17\u5305\u641c\u7d22\u548c\u6807\u6ce8\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u96be\u4ee5\u68c0\u6d4b\u7684\u5f02\u5e38\u6765\u521b\u5efa\u6570\u636e\u96c6\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u6807\u6ce8\u7684\u3001\u5728\u906e\u6321\u6761\u4ef6\u4e0b\u96be\u4ee5\u68c0\u6d4b\u7684\u5f02\u5e38\u7684\u72ec\u7279\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8868\u660e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u4e0d\u4f73\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u53ef\u4f5c\u4e3a\u5728\u590d\u6742\u7684\u68ee\u6797\u73af\u5883\u4e2d\u6539\u8fdb\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u57fa\u51c6\uff0c\u4ee5\u652f\u6301\u641c\u6355\u548c\u6551\u63f4\u884c\u52a8\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\uff0c\u51f8\u663e\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u65b9\u6cd5\u7684\u9700\u6c42\u3002"}}
{"id": "2507.15548", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.15548", "abs": "https://arxiv.org/abs/2507.15548", "authors": ["D. Abler", "O. Pusterla", "A. Joye-K\u00fchnis", "N. Andratschke", "M. Bach", "A. Bink", "S. M. Christ", "P. Hagmann", "B. Pouymayou", "E. Pravat\u00e0", "P. Radojewski", "M. Reyes", "L. Ruinelli", "R. Schaer", "B. Stieltjes", "G. Treglia", "W. Valenzuela", "R. Wiest", "S. Zoergiebel", "M. Guckenberger", "S. Tanadini-Lang", "A. Depeursinge"], "title": "The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information", "comment": null, "summary": "Background: Radiomics shows promise in characterizing glioblastoma, but its\nadded value over clinical and molecular predictors has yet to be proven. This\nstudy assessed the added value of conventional radiomics (CR) and deep learning\n(DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on\na large multi-center dataset.\n  Methods: After patient selection, our curated dataset gathers 1152\nglioblastoma (WHO 2016) patients from five Swiss centers and one public source.\nIt included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI\ndata (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were\ndeveloped using standard methods and evaluated on internal and external\ncohorts. Sub-analyses assessed models with different feature sets\n(imaging-only, clinical/molecular-only, combined-features) and patient subsets\n(S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).\n  Results: The best performance was observed in the full cohort (S-1). In\nexternal validation, the combined-feature CR model achieved an AUC of 0.75,\nslightly, but significantly outperforming clinical-only (0.74) and imaging-only\n(0.68) models. DL models showed similar trends, though without statistical\nsignificance. In S-2 and S-3, combined models did not outperform clinical-only\nmodels. Exploratory analysis of CR models for overall survival prediction\nsuggested greater relevance of imaging data: across all subsets,\ncombined-feature models significantly outperformed clinical-only models, though\nwith a modest advantage of 2-4 C-index points.\n  Conclusions: While confirming the predictive value of anatomical MRI\nsequences for glioblastoma prognosis, this multi-center study found standard CR\nand DL radiomics approaches offer minimal added value over demographic\npredictors such as age and gender.", "AI": {"tldr": "\u5f71\u50cf\u7ec4\u5b66\u5bf9\u9884\u6d4b\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u4ef7\u503c\u6709\u9650\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5e38\u89c4\u5f71\u50cf\u7ec4\u5b66\uff08CR\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09MRI\u5f71\u50cf\u7ec4\u5b66\u5728\u9884\u6d4b\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\uff08\u751f\u5b58\u671f\u22646\u4e2a\u6708 vs >6\u4e2a\u6708\uff09\u65b9\u9762\u7684\u9644\u52a0\u4ef7\u503c\uff0c\u5e76\u4e0e\u4e34\u5e8a\u548c\u5206\u5b50\u9884\u6d4b\u56e0\u5b50\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u56de\u987e\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u7eb3\u5165\u4e86\u6765\u81ea\u745e\u58eb\u4e94\u4e2a\u4e2d\u5fc3\u548c\u4e00\u516c\u5f00\u6570\u636e\u6e90\u76841152\u540d\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\uff08WHO 2016\uff09\u60a3\u8005\u3002\u7814\u7a76\u4f7f\u7528\u5e38\u89c4\u5f71\u50cf\u7ec4\u5b66\uff08CR\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u4e34\u5e8a\uff08\u5e74\u9f84\u3001\u6027\u522b\uff09\u3001\u5206\u5b50\uff08MGMT\u3001IDH\uff09\u548c\u57fa\u7ebfMRI\u6570\u636e\uff08T1\u3001T1\u5bf9\u6bd4\u3001FLAIR\u3001T2\uff09\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002\u6a21\u578b\u5728\u5185\u90e8\u548c\u5916\u90e8\u961f\u5217\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u8fdb\u884c\u4e86\u4e9a\u7ec4\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u7279\u5f81\u96c6\uff08\u4ec5\u5f71\u50cf\u3001\u4ec5\u4e34\u5e8a/\u5206\u5b50\u3001\u7ec4\u5408\u7279\u5f81\uff09\u548c\u60a3\u8005\u5b50\u96c6\uff08S-1\uff1a\u6240\u6709\u60a3\u8005\uff0cS-2\uff1a\u5177\u6709\u5206\u5b50\u6570\u636e\u8005\uff0cS-3\uff1aIDH\u91ce\u751f\u578b\uff09\u7684\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5728\u5916\u90e8\u9a8c\u8bc1\u4e2d\uff0c\u7ed3\u5408\u7279\u5f81\u7684CR\u6a21\u578b\u53d6\u5f97\u4e860.75\u7684AUC\uff0c\u7565\u9ad8\u4e8e\u4ec5\u4e34\u5e8a\u7279\u5f81\uff080.74\uff09\u548c\u4ec5\u5f71\u50cf\u7279\u5f81\uff080.68\uff09\u7684\u6a21\u578b\uff0c\u4f46\u5177\u6709\u7edf\u8ba1\u5b66\u663e\u8457\u6027\u3002DL\u6a21\u578b\u663e\u793a\u51fa\u76f8\u4f3c\u7684\u8d8b\u52bf\uff0c\u4f46\u65e0\u7edf\u8ba1\u5b66\u663e\u8457\u6027\u3002\u5728S-2\u548cS-3\u4e9a\u7ec4\u4e2d\uff0c\u7ec4\u5408\u6a21\u578b\u5e76\u672a\u4f18\u4e8e\u4ec5\u4e34\u5e8a\u6a21\u578b\u3002\u63a2\u7d22\u6027\u5206\u6790\u8868\u660e\uff0c\u5f71\u50cf\u6570\u636e\u5728\u9884\u6d4b\u603b\u751f\u5b58\u671f\u65b9\u9762\u5177\u6709\u66f4\u5927\u7684\u76f8\u5173\u6027\uff1a\u5728\u6240\u6709\u4e9a\u7ec4\u4e2d\uff0c\u7ec4\u5408\u7279\u5f81\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4ec5\u4e34\u5e8a\u6a21\u578b\uff0c\u4f46C-index\u4ec5\u63d0\u9ad8\u4e862-4\u4e2a\u70b9\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u5b9e\u4e86MRI\u89e3\u5256\u5e8f\u5217\u5728\u9884\u6d4b\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u4e2d\u7684\u4ef7\u503c\uff0c\u4f46\u6807\u51c6CR\u548cDL\u5f71\u50cf\u7ec4\u5b66\u65b9\u6cd5\u76f8\u6bd4\u5e74\u9f84\u548c\u6027\u522b\u7b49\u4eba\u53e3\u7edf\u8ba1\u5b66\u9884\u6d4b\u56e0\u5b50\uff0c\u4ec5\u63d0\u4f9b\u4e86\u5fae\u5c0f\u7684\u9644\u52a0\u4ef7\u503c\u3002"}}
{"id": "2507.15788", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15788", "abs": "https://arxiv.org/abs/2507.15788", "authors": ["Sneheel Sarangi", "Hanan Salam"], "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nemergent capabilities in complex reasoning, largely spurred by rule-based\nReinforcement Learning (RL) techniques applied during the post-training. This\nhas raised the question of whether similar methods can instill more nuanced,\nhuman-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This\npaper investigates whether small-scale LLMs can acquire a robust and\ngeneralizable ToM capability through RL with verifiable rewards (RLVR). We\nconduct a systematic evaluation by training models on various combinations of\nprominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for\ngeneralization on held-out datasets (e.g., OpenToM). Our findings indicate that\nsmall LLMs struggle to develop a generic ToM capability. While performance on\nin-distribution tasks improves, this capability fails to transfer to unseen ToM\ntasks with different characteristics. Furthermore, we demonstrate that\nprolonged RL training leads to models ``hacking'' the statistical patterns of\nthe training datasets, resulting in significant performance gains on in-domain\ndata but no change, or degradation of performance on out-of-distribution tasks.\nThis suggests the learned behavior is a form of narrow overfitting rather than\nthe acquisition of a true, abstract ToM capability.", "AI": {"tldr": "\u5c0f\u578bLLM\u901a\u8fc7RLVR\u5b66\u4e60ToM\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002", "motivation": "\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7b49\u65b9\u6cd5\uff0c\u5728LLM\u4e2d\u57f9\u517b\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u7684\u793e\u4ea4\u667a\u80fd\u3002", "method": "\u901a\u8fc7\u5728\u5404\u79cdToM\u6570\u636e\u96c6\uff08HiToM\u3001ExploreToM\u3001FANToM\uff09\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u6d4b\u8bd5\u5176\u5728\u672a\u89c1\u8fc7\u7684\u6570\u636e\u96c6\uff08\u5982OpenToM\uff09\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6765\u7cfb\u7edf\u5730\u8bc4\u4f30RLVR\u7684\u6548\u679c\u3002", "result": "\u5c0f\u578bLLM\u5728ToM\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u72ed\u9698\u7684\u8fc7\u62df\u5408\uff0c\u4ec5\u5728\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u540c\u7279\u5f81\u7684\u672a\u89c1\u8fc7ToM\u4efb\u52a1\u4e0a\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u96be\u4ee5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u83b7\u5f97\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u7684\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u80fd\u529b\u3002"}}
{"id": "2507.15550", "categories": ["cs.LG", "cs.AI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2507.15550", "abs": "https://arxiv.org/abs/2507.15550", "authors": ["Yimeng Chen", "Piotr Pi\u0229kos", "Mateusz Ostaszewski", "Firas Laakom", "J\u00fcrgen Schmidhuber"], "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors", "comment": "31 Pages", "summary": "Evaluating the scientific discovery capabilities of large language model\nbased agents, particularly how they cope with varying environmental complexity\nand utilize prior knowledge, requires specialized benchmarks currently lacking\nin the landscape. To address this gap, we introduce PhysGym, a novel benchmark\nsuite and simulation platform for rigorously assessing LLM-based scientific\nreasoning in interactive physics environments. PhysGym's primary contribution\nlies in its sophisticated control over the level of prior knowledge provided to\nthe agent. This allows researchers to dissect agent performance along axes\nincluding the complexity of the problem and the prior knowledge levels. The\nbenchmark comprises a suite of interactive simulations, where agents must\nactively probe environments, gather data sequentially under constraints and\nformulate hypotheses about underlying physical laws. PhysGym provides\nstandardized evaluation protocols and metrics for assessing hypothesis accuracy\nand model fidelity. We demonstrate the benchmark's utility by presenting\nresults from baseline LLMs, showcasing its ability to differentiate\ncapabilities based on varying priors and task complexity.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aPhysGym\u7684\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7269\u7406\u73af\u5883\u4e2d\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u8be5\u5e73\u53f0\u80fd\u63a7\u5236\u5148\u9a8c\u77e5\u8bc6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\uff0c\u5e76\u5df2\u901a\u8fc7\u57fa\u7ebfLLM\u7684\u6d4b\u8bd5\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e0d\u540c\u590d\u6742\u6027\u7684\u73af\u5883\u548c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u65b9\u9762\u7684\u80fd\u529b\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\uff0c\u800c\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u4e25\u683c\u8bc4\u4f30LLM\u5728\u4ea4\u4e92\u5f0f\u7269\u7406\u73af\u5883\u4e2d\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aPhysGym\u7684\u65b0\u9896\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u5305\u542b\u4e00\u7cfb\u5217\u4ea4\u4e92\u5f0f\u6a21\u62df\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7269\u7406\u73af\u5883\u4e2d\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u3002PhysGym\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u63a7\u5236\u63d0\u4f9b\u7ed9LLM\u7684\u5148\u9a8c\u77e5\u8bc6\u6c34\u5e73\uff0c\u5e76\u80fd\u8bc4\u4f30LLM\u5728\u6570\u636e\u6536\u96c6\u3001\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u987a\u5e8f\u6570\u636e\u6536\u96c6\u4ee5\u53ca\u5047\u8bbe\u5f62\u6210\u7b49\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5bf9\u57fa\u7ebfLLM\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86PhysGym\u533a\u5206\u4e0d\u540c\u5148\u9a8c\u77e5\u8bc6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u7684LLM\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "conclusion": "PhysGym\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\uff0c\u80fd\u591f\u4e25\u683c\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u80fd\u901a\u8fc7\u63a7\u5236\u5148\u9a8c\u77e5\u8bc6\u7684\u6c34\u5e73\u6765\u533a\u5206\u4e0d\u540cLLM\u5728\u4e0d\u540c\u4efb\u52a1\u590d\u6742\u6027\u4e0b\u7684\u80fd\u529b\u3002"}}
{"id": "2507.15504", "categories": ["cs.CV", "68T45", "I.2.10; H.3.3"], "pdf": "https://arxiv.org/pdf/2507.15504", "abs": "https://arxiv.org/abs/2507.15504", "authors": ["Bingqing Zhang", "Zhuo Cao", "Heming Du", "Yang Li", "Xue Li", "Jiajun Liu", "Sen Wang"], "title": "Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization", "comment": "Accepted by ICCV 2025", "summary": "Despite recent advances, Text-to-video retrieval (TVR) is still hindered by\nmultiple inherent uncertainties, such as ambiguous textual queries, indistinct\ntext-video mappings, and low-quality video frames. Although interactive systems\nhave emerged to address these challenges by refining user intent through\nclarifying questions, current methods typically rely on heuristic or ad-hoc\nstrategies without explicitly quantifying these uncertainties, limiting their\neffectiveness. Motivated by this gap, we propose UMIVR, an\nUncertainty-Minimizing Interactive Text-to-Video Retrieval framework that\nexplicitly quantifies three critical uncertainties-text ambiguity, mapping\nuncertainty, and frame uncertainty-via principled, training-free metrics:\nsemantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon\ndivergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based\nFrame Sampler (TQFS). By adaptively generating targeted clarifying questions\nguided by these uncertainty measures, UMIVR iteratively refines user queries,\nsignificantly reducing retrieval ambiguity. Extensive experiments on multiple\nbenchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1\n(69.2\\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby\nestablishing an uncertainty-minimizing foundation for interactive TVR.", "AI": {"tldr": "UMIVR\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u4ea4\u4e92\u5f0f\u6587\u672c\u5230\u89c6\u9891\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u548c\u6700\u5c0f\u5316\u6587\u672c\u6a21\u7cca\u6027\u3001\u6620\u5c04\u4e0d\u786e\u5b9a\u6027\u548c\u5e27\u4e0d\u786e\u5b9a\u6027\u6765\u63d0\u9ad8\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u6587\u672c\u5230\u89c6\u9891\u68c0\u7d22\uff08TVR\uff09\u7cfb\u7edf\u5728\u5904\u7406\u6a21\u7cca\u7684\u6587\u672c\u67e5\u8be2\u3001\u4e0d\u660e\u786e\u7684\u6587\u672c-\u89c6\u9891\u6620\u5c04\u4ee5\u53ca\u4f4e\u8d28\u91cf\u7684\u89c6\u9891\u5e27\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u867d\u7136\u4ea4\u4e92\u5f0f\u7cfb\u7edf\u8bd5\u56fe\u901a\u8fc7\u6f84\u6e05\u95ee\u9898\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u7f3a\u4e4f\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u660e\u786e\u91cf\u5316\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "UMIVR\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u8bed\u4e49\u71b5\u7684\u6587\u672c\u6a21\u7cca\u6027\u8bc4\u5206\uff08TAS\uff09\u3001\u57fa\u4e8eJensen-Shannon\u6563\u5ea6\u7684\u6620\u5c04\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\uff08MUS\uff09\u4ee5\u53ca\u57fa\u4e8e\u65f6\u95f4\u8d28\u91cf\u7684\u5e27\u91c7\u6837\u5668\uff08TQFS\uff09\u6765\u91cf\u5316\u6587\u672c\u6a21\u7cca\u6027\u3001\u6620\u5c04\u4e0d\u786e\u5b9a\u6027\u548c\u5e27\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u5ea6\u91cf\u6765\u751f\u6210\u6709\u9488\u5bf9\u6027\u7684\u6f84\u6e05\u95ee\u9898\uff0c\u4ee5\u8fed\u4ee3\u5730\u4f18\u5316\u7528\u6237\u67e5\u8be2\u3002", "result": "\u5728MSR-VTT-1k\u6570\u636e\u96c6\u4e0a\uff0cUMIVR\u572810\u8f6e\u4ea4\u4e92\u540e\u5b9e\u73b0\u4e8669.2%\u7684\u53ec\u56de\u7387@1\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "UMIVR\u901a\u8fc7\u91cf\u5316\u6587\u672c\u6a21\u7cca\u6027\u3001\u6620\u5c04\u4e0d\u786e\u5b9a\u6027\u548c\u5e27\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u5ea6\u91cf\u6765\u6307\u5bfc\u4ea4\u4e92\u5f0f\u95ee\u9898\u751f\u6210\uff0c\u4ece\u800c\u6709\u6548\u51cf\u5c11\u68c0\u7d22\u6b67\u4e49\uff0c\u5728MSR-VTT-1k\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u53ec\u56de\u7387\u63d0\u5347\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u6587\u672c\u5230\u89c6\u9891\u68c0\u7d22\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15566", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.15566", "abs": "https://arxiv.org/abs/2507.15566", "authors": ["Pieter Smet", "Martina Doneda", "Ettore Lanzarone", "Giuliana Carello"], "title": "Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy", "comment": null, "summary": "The availability of downstream resources plays a critical role in planning\nthe admission of patients undergoing elective surgery, with inpatient beds\nbeing one of the most crucial resources. When planning patient admissions,\npredictions on their length-of-stay (LOS) made by machine learning (ML) models\nare used to ensure bed availability. However, the actual LOS for each patient\nmay differ considerably from the predicted value, potentially making the\nschedule infeasible. To address such infeasibilities, rescheduling strategies\nthat take advantage of operational flexibility can be implemented. For example,\nadjustments may include postponing admission dates, relocating patients to\ndifferent wards, or even transferring patients who are already admitted. The\ncommon assumption is that more accurate LOS predictions reduce the impact of\nrescheduling. However, training ML models that can make such accurate\npredictions can be costly. Building on previous work that proposed simulated\n\\ac{ml} for evaluating data-driven approaches, this paper explores the\nrelationship between LOS prediction accuracy and rescheduling flexibility\nacross various corrective policies. Specifically, we examine the most effective\npatient rescheduling strategies under LOS prediction errors to prevent bed\noverflows while optimizing resource utilization.", "AI": {"tldr": "Patient LOS prediction accuracy impacts hospital bed planning. This paper studies how rescheduling flexibility and prediction accuracy affect bed overflow prevention and resource optimization.", "motivation": "The motivation is to address infeasibilities in patient admission planning caused by differences between predicted and actual patient Length-of-Stay (LOS), which can make schedules unfeasible and impact bed availability.", "method": "The paper uses simulated ML for evaluating data-driven approaches and explores the relationship between LOS prediction accuracy and rescheduling flexibility across various corrective policies.", "result": "The paper examines the most effective patient rescheduling strategies under LOS prediction errors to prevent bed overflows while optimizing resource utilization.", "conclusion": "The paper explores the relationship between LOS prediction accuracy and rescheduling flexibility across various corrective policies, examining the most effective patient rescheduling strategies under LOS prediction errors to prevent bed overflows while optimizing resource utilization."}}
{"id": "2507.15846", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.15846", "abs": "https://arxiv.org/abs/2507.15846", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "comment": null, "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "AI": {"tldr": "\u63d0\u51fa GUI-G$^2$ \u5956\u52b1\u6846\u67b6\uff0c\u5c06 GUI \u5143\u7d20\u5efa\u6a21\u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u5b9e\u73b0\u66f4\u7cbe\u786e\u3001\u9c81\u68d2\u7684\u7a7a\u95f4\u5b9a\u4f4d\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u4e8c\u5143\u5956\u52b1\uff0c\u5c06\u5143\u7d20\u89c6\u4e3a\u547d\u4e2d\u6216\u672a\u547d\u4e2d\u76ee\u6807\uff0c\u4ea7\u751f\u7684\u4fe1\u53f7\u7a00\u758f\u4e14\u5ffd\u7565\u4e86\u7a7a\u95f4\u4ea4\u4e92\u7684\u8fde\u7eed\u6027\u3002\u8fd9\u4e0e\u4eba\u7c7b\u70b9\u51fb\u884c\u4e3a\uff08\u81ea\u7136\u5f62\u6210\u4ee5\u76ee\u6807\u5143\u7d20\u4e3a\u4e2d\u5fc3\u7684\u304c\u30a6\u30b9\u5206\u5e03\uff09\u4e0d\u540c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a GUI-G$^2$\uff08GUI Gaussian Grounding Rewards\uff09\u7684\u539f\u5219\u6027\u5956\u52b1\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06 GUI \u5143\u7d20\u5efa\u6a21\u4e3a\u8de8\u754c\u9762\u5e73\u9762\u7684\u8fde\u7eed\u9ad8\u65af\u5206\u5e03\u3002GUI-G$^2$ \u5305\u542b\u4e24\u4e2a\u673a\u5236\uff1a\u9ad8\u65af\u70b9\u5956\u52b1\u901a\u8fc7\u4ee5\u5143\u7d20\u8d28\u5fc3\u4e3a\u4e2d\u5fc3\u5448\u6307\u6570\u8870\u51cf\u7684\u5206\u5e03\u6765\u6a21\u62df\u7cbe\u786e\u7684\u5b9a\u4f4d\uff1b\u8986\u76d6\u5956\u52b1\u901a\u8fc7\u6d4b\u91cf\u9884\u6d4b\u7684\u9ad8\u65af\u5206\u5e03\u4e0e\u76ee\u6807\u533a\u57df\u7684\u91cd\u53e0\u6765\u8bc4\u4f30\u7a7a\u95f4\u5bf9\u9f50\u3002\u4e3a\u4e86\u5904\u7406\u5404\u79cd\u5143\u7d20\u5c3a\u5ea6\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u65b9\u5dee\u673a\u5236\uff0c\u6839\u636e\u5143\u7d20\u7ef4\u5ea6\u6821\u51c6\u5956\u52b1\u5206\u5e03\u3002", "result": "GUI-G$^2$ \u5728 ScreenSpot\u3001ScreenSpot-v2 \u548c ScreenSpot-Pro \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4 UI-TARS-72B \u6709\u663e\u8457\u63d0\u5347\uff0c\u5728 ScreenSpot-Pro \u4e0a\u63d0\u5347\u9ad8\u8fbe 24.7%\u3002\u5206\u6790\u8868\u660e\uff0c\u8fde\u7eed\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u4f18\u8d8a\u7684\u754c\u9762\u53d8\u5316\u9c81\u68d2\u6027\u548c\u5bf9\u672a\u89c1\u5e03\u5c40\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GUI-G$^2$ \u5c06 GUI grounding \u4ece\u7a00\u758f\u7684\u4e8c\u5143\u5206\u7c7b\u8f6c\u5316\u4e3a\u5bc6\u96c6\u7684\u8fde\u7eed\u4f18\u5316\uff0c\u901a\u8fc7\u9ad8\u65af\u5206\u5e03\u4ea7\u751f\u4e30\u5bcc\u7684\u68af\u5ea6\u4fe1\u53f7\u6765\u6307\u5bfc\u6a21\u578b\u8fbe\u5230\u6700\u4f73\u4ea4\u4e92\u4f4d\u7f6e\u3002\u5b9e\u9a8c\u8bc1\u660e GUI-G$^2$ \u5728 ScreenSpot\u3001ScreenSpot-v2 \u548c ScreenSpot-Pro \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5 UI-TARS-72B\uff0c\u5728 ScreenSpot-Pro \u4e0a\u63d0\u5347\u9ad8\u8fbe 24.7%\u3002\u6b64\u5916\uff0c\u8fde\u7eed\u5efa\u6a21\u5728\u5e94\u5bf9\u754c\u9762\u53d8\u5316\u548c\u6cdb\u5316\u5230\u672a\u89c1\u5e03\u5c40\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u4f18\u8d8a\u6027\uff0c\u4e3a GUI \u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u7a7a\u95f4\u63a8\u7406\u5efa\u7acb\u4e86\u65b0\u8303\u4f8b\u3002"}}
{"id": "2507.15520", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15520", "abs": "https://arxiv.org/abs/2507.15520", "authors": ["Hanting Li", "Fei Zhou", "Xin Sun", "Yang Hua", "Jungong Han", "Liang-Jie Zhang"], "title": "SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement", "comment": "11 pages, 10 figures, 6 tables", "summary": "Recent Transformer-based low-light enhancement methods have made promising\nprogress in recovering global illumination. However, they still struggle with\nnon-uniform lighting scenarios, such as backlit and shadow, appearing as\nover-exposure or inadequate brightness restoration. To address this challenge,\nwe present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer)\nframework that enables accurate illumination restoration. Specifically, we\npropose a dynamic integral image representation to model the spatially-varying\nillumination, and further construct a novel Spatially-Adaptive Integral\nIllumination Estimator ($\\text{SAI}^2\\text{E}$). Moreover, we introduce an\nIllumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which\nleverages the illumination to calibrate the lightness-relevant features toward\nvisual-pleased illumination enhancement. Extensive experiments on five standard\nlow-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our\nSAIGFormer significantly outperforms state-of-the-art methods in both\nquantitative and qualitative metrics. In particular, our method achieves\nsuperior performance in non-uniform illumination enhancement while exhibiting\nstrong generalization capabilities across multiple datasets. Code is available\nat https://github.com/LHTcode/SAIGFormer.git.", "AI": {"tldr": "SAIGFormer\u901a\u8fc7\u52a8\u6001\u79ef\u5206\u56fe\u50cf\u548c\u5149\u7167\u5f15\u5bfc\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u4f4e\u5149\u7167\u56fe\u50cf\u589e\u5f3a\u4e2d\u7684\u975e\u5747\u5300\u5149\u7167\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6210\u679c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709Transformer\u65b9\u6cd5\u5728\u975e\u5747\u5300\u5149\u7167\uff08\u5982\u80cc\u5149\u548c\u9634\u5f71\uff09\u573a\u666f\u4e0b\u51fa\u73b0\u66dd\u5149\u8fc7\u5ea6\u6216\u4eae\u5ea6\u6062\u590d\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7a7a\u95f4\u81ea\u9002\u5e94\u5149\u7167\u5f15\u5bfcTransformer\uff08SAIGFormer\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u62ec\u52a8\u6001\u79ef\u5206\u56fe\u50cf\u8868\u793a\u3001\u7a7a\u95f4\u81ea\u9002\u5e94\u79ef\u5206\u5149\u7167\u4f30\u8ba1\u5668\uff08SAI2E\uff09\u548c\u5149\u7167\u5f15\u5bfc\u591a\u5934\u81ea\u6ce8\u610f\u529b\uff08IG-MSA\uff09\u673a\u5236\u3002", "result": "SAIGFormer\u5728\u4e94\u4e2a\u6807\u51c6\u4f4e\u5149\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u8de8\u57df\u57fa\u51c6\uff08LOL-Blur\uff09\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5176\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u6307\u6807\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "SAIGFormer\u5728\u975e\u5747\u5300\u5149\u7167\u589e\u5f3a\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5177\u6709\u5f3a\u5927\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.15574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15574", "abs": "https://arxiv.org/abs/2507.15574", "authors": ["Gregory F. Stock", "Juan A. Fraire", "Holger Hermanns", "J\u0119drzej Mosi\u0119\u017cny", "Yusra Al-Khazraji", "Julio Ram\u00edrez Molina", "Evridiki V. Ntagiou"], "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project", "comment": "18th International Conference on Space Operations (SpaceOps 2025),\n  Montr\\'eal, Canada, 26-30 May 2025,\n  https://star.spaceops.org/2025/user_manudownload.php?doc=140__9bg48dkf.pdf", "summary": "The rapid expansion of satellite constellations in near-Earth orbits presents\nsignificant challenges in satellite network management, requiring innovative\napproaches for efficient, scalable, and resilient operations. This paper\nexplores the role of Artificial Intelligence (AI) in optimizing the operation\nof satellite mega-constellations, drawing from the ConstellAI project funded by\nthe European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland\nUniversity, and Thales Alenia Space collaborates to develop AI-driven\nalgorithms and demonstrates their effectiveness over traditional methods for\ntwo crucial operational challenges: data routing and resource allocation. In\nthe routing use case, Reinforcement Learning (RL) is used to improve the\nend-to-end latency by learning from historical queuing latency, outperforming\nclassical shortest path algorithms. For resource allocation, RL optimizes the\nscheduling of tasks across constellations, focussing on efficiently using\nlimited resources such as battery and memory. Both use cases were tested for\nmultiple satellite constellation configurations and operational scenarios,\nresembling the real-life spacecraft operations of communications and Earth\nobservation satellites. This research demonstrates that RL not only competes\nwith classical approaches but also offers enhanced flexibility, scalability,\nand generalizability in decision-making processes, which is crucial for the\nautonomous and intelligent management of satellite fleets. The findings of this\nactivity suggest that AI can fundamentally alter the landscape of satellite\nconstellation management by providing more adaptive, robust, and cost-effective\nsolutions.", "AI": {"tldr": "AI, specifically Reinforcement Learning, is shown to be effective in optimizing satellite mega-constellation operations for data routing and resource allocation, outperforming traditional methods and offering better scalability and flexibility.", "motivation": "The rapid expansion of satellite constellations necessitates innovative approaches for efficient, scalable, and resilient network management, addressing challenges in operations.", "method": "Reinforcement Learning (RL) algorithms were developed and tested for data routing (optimizing end-to-end latency using historical queuing latency data) and resource allocation (optimizing task scheduling for battery and memory), comparing their performance against classical algorithms.", "result": "RL-based approaches demonstrated improved performance over classical methods in both data routing and resource allocation use cases, showing greater flexibility, scalability, and generalizability.", "conclusion": "AI, particularly RL, offers enhanced flexibility, scalability, and generalizability for autonomous satellite fleet management, outperforming traditional methods in data routing and resource allocation."}}
{"id": "2507.15540", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15540", "abs": "https://arxiv.org/abs/2507.15540", "authors": ["Syed Ahmed Mahmood", "Ali Shah Ali", "Umer Ahmed", "Fawad Javed Fateh", "M. Zeeshan Zia", "Quoc-Huy Tran"], "title": "Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport", "comment": null, "summary": "We study the problem of self-supervised procedure learning, which discovers\nkey steps and establishes their order from a set of unlabeled procedural\nvideos. Previous procedure learning methods typically learn frame-to-frame\ncorrespondences between videos before determining key steps and their order.\nHowever, their performance often suffers from order variations,\nbackground/redundant frames, and repeated actions. To overcome these\nchallenges, we propose a self-supervised procedure learning framework, which\nutilizes a fused Gromov-Wasserstein optimal transport formulation with a\nstructural prior for computing frame-to-frame mapping between videos. However,\noptimizing exclusively for the above temporal alignment term may lead to\ndegenerate solutions, where all frames are mapped to a small cluster in the\nembedding space and hence every video is associated with only one key step. To\naddress that limitation, we further integrate a contrastive regularization\nterm, which maps different frames to different points in the embedding space,\navoiding the collapse to trivial solutions. Finally, we conduct extensive\nexperiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e.,\nProceL and CrossTask) benchmarks to demonstrate superior performance by our\napproach against previous methods, including OPEL which relies on a traditional\nKantorovich optimal transport formulation with an optimality prior.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15584", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15584", "abs": "https://arxiv.org/abs/2507.15584", "authors": ["Philipp R\u00f6chner", "Simon Kl\u00fcttermann", "Franz Rothlauf", "Daniel Schl\u00f6r"], "title": "We Need to Rethink Benchmarking in Anomaly Detection", "comment": null, "summary": "Despite the continuous proposal of new anomaly detection algorithms and\nextensive benchmarking efforts, progress seems to stagnate, with only minor\nperformance differences between established baselines and new algorithms. In\nthis position paper, we argue that this stagnation is due to limitations in how\nwe evaluate anomaly detection algorithms. Current benchmarking does not, for\nexample, sufficiently reflect the diversity of anomalies in applications\nranging from predictive maintenance to scientific discovery. Consequently, we\nneed to rethink benchmarking in anomaly detection. In our opinion, anomaly\ndetection should be studied using scenarios that capture the relevant\ncharacteristics of different applications. We identify three key areas for\nimprovement: First, we need to identify anomaly detection scenarios based on a\ncommon taxonomy. Second, anomaly detection pipelines should be analyzed\nend-to-end and by component. Third, evaluating anomaly detection algorithms\nshould be meaningful regarding the scenario's objectives.", "AI": {"tldr": "\u5f53\u524d\u5f02\u5e38\u68c0\u6d4b\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u5e94\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u53cd\u6620\u5f02\u5e38\u7684\u591a\u6837\u6027\uff0c\u5e76\u5bf9\u5f02\u5e38\u68c0\u6d4b\u7ba1\u9053\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u672a\u80fd\u5145\u5206\u53cd\u6620\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5f02\u5e38\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u65b0\u7b97\u6cd5\u4e0e\u57fa\u7ebf\u6027\u80fd\u5dee\u5f02\u5fae\u5c0f\uff0c\u7814\u7a76\u8fdb\u5c55\u505c\u6ede\u4e0d\u524d\u3002", "method": "\u63d0\u51fa\u5e94\u6839\u636e\u5e38\u89c1\u5206\u7c7b\u6cd5\u8bc6\u522b\u5f02\u5e38\u68c0\u6d4b\u573a\u666f\uff0c\u5bf9\u5f02\u5e38\u68c0\u6d4b\u7ba1\u9053\u8fdb\u884c\u7aef\u5230\u7aef\u548c\u6309\u7ec4\u4ef6\u7684\u5206\u6790\uff0c\u5e76\u786e\u4fdd\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u573a\u666f\u76ee\u6807\u6709\u610f\u4e49\u3002", "result": "\u6587\u7ae0\u8ba4\u4e3a\uff0c\u901a\u8fc7\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63a8\u52a8\u5f02\u5e38\u68c0\u6d4b\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "conclusion": "\u5e94\u6839\u636e\u573a\u666f\u76ee\u6807\u8bc4\u4f30\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5e76\u5bf9\u5f02\u5e38\u68c0\u6d4b\u7ba1\u9053\u8fdb\u884c\u7aef\u5230\u7aef\u548c\u6309\u7ec4\u4ef6\u7684\u5206\u6790\u3002"}}
{"id": "2507.15541", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15541", "abs": "https://arxiv.org/abs/2507.15541", "authors": ["Jongmin Shin", "Enki Cho", "Ka Yong Kim", "Jung Yong Kim", "Seong Tae Kim", "Namkee Oh"], "title": "Towards Holistic Surgical Scene Graph", "comment": "Accepted to MICCAI 2025", "summary": "Surgical scene understanding is crucial for computer-assisted intervention\nsystems, requiring visual comprehension of surgical scenes that involves\ndiverse elements such as surgical tools, anatomical structures, and their\ninteractions. To effectively represent the complex information in surgical\nscenes, graph-based approaches have been explored to structurally model\nsurgical entities and their relationships. Previous surgical scene graph\nstudies have demonstrated the feasibility of representing surgical scenes using\ngraphs. However, certain aspects of surgical scenes-such as diverse\ncombinations of tool-action-target and the identity of the hand operating the\ntool-remain underexplored in graph-based representations, despite their\nimportance. To incorporate these aspects into graph representations, we propose\nEndoscapes-SG201 dataset, which includes annotations for tool-action-target\ncombinations and hand identity. We also introduce SSG-Com, a graph-based method\ndesigned to learn and represent these critical elements. Through experiments on\ndownstream tasks such as critical view of safety assessment and action triplet\nrecognition, we demonstrated the importance of integrating these essential\nscene graph components, highlighting their significant contribution to surgical\nscene understanding. The code and dataset are available at\nhttps://github.com/ailab-kyunghee/SSG-Com", "AI": {"tldr": "\u63d0\u51faEndoscapes-SG201\u6570\u636e\u96c6\u548cSSG-Com\u65b9\u6cd5\uff0c\u901a\u8fc7\u5305\u542b\u5de5\u5177-\u52a8\u4f5c-\u76ee\u6807\u7ec4\u5408\u548c\u624b\u90e8\u8eab\u4efd\u4fe1\u606f\uff0c\u6539\u8fdb\u4e86\u624b\u672f\u573a\u666f\u56fe\u8868\u793a\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u4ee5\u5f80\u7684\u624b\u672f\u573a\u666f\u56fe\u7814\u7a76\u867d\u7136\u53ef\u884c\uff0c\u4f46\u5728\u8868\u793a\u5de5\u5177-\u52a8\u4f5c-\u76ee\u6807\u7ec4\u5408\u548c\u624b\u90e8\u8eab\u4efd\u7b49\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u800c\u8fd9\u4e9b\u65b9\u9762\u5bf9\u624b\u672f\u573a\u666f\u7684\u7406\u89e3\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faEndoscapes-SG201\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u5de5\u5177-\u52a8\u4f5c-\u76ee\u6807\u7ec4\u5408\u548c\u624b\u90e8\u8eab\u4efd\u7684\u6ce8\u91ca\u3002\u5f15\u5165SSG-Com\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b66\u4e60\u548c\u8868\u793a\u8fd9\u4e9b\u5173\u952e\u8981\u7d20\u3002", "result": "\u6240\u63d0\u51fa\u7684SSG-Com\u65b9\u6cd5\u5728\u5173\u952e\u5b89\u5168\u89c6\u89d2\u8bc4\u4f30\u548c\u52a8\u4f5c\u4e09\u5143\u7ec4\u8bc6\u522b\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u96c6\u6210\u5de5\u5177-\u52a8\u4f5c-\u76ee\u6807\u7ec4\u5408\u548c\u624b\u90e8\u8eab\u4efd\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u624b\u672f\u573a\u666f\u7406\u89e3\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u96c6\u6210\u8fd9\u4e9b\u5173\u952e\u573a\u666f\u56fe\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\uff0c\u51f8\u663e\u4e86\u5b83\u4eec\u5bf9\u624b\u672f\u573a\u666f\u7406\u89e3\u7684\u91cd\u5927\u8d21\u732e\u3002"}}
{"id": "2507.15587", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15587", "abs": "https://arxiv.org/abs/2507.15587", "authors": ["Yinsong Chen", "Kaifeng Wang", "Xiaoqiang Meng", "Xueyuan Li", "Zirui Li", "Xin Gao"], "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario", "comment": null, "summary": "Current research on decision-making in safety-critical scenarios often relies\non inefficient data-driven scenario generation or specific modeling approaches,\nwhich fail to capture corner cases in real-world contexts. To address this\nissue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,\nwhere background vehicles with interference capabilities are treated as\nred-team agents. Through active interference and exploration, red-team vehicles\ncan uncover corner cases outside the data distribution. The framework uses a\nConstraint Graph Representation Markov Decision Process, ensuring that red-team\nvehicles comply with safety rules while continuously disrupting the autonomous\nvehicles (AVs). A policy threat zone model is constructed to quantify the\nthreat posed by red-team vehicles to AVs, inducing more extreme actions to\nincrease the danger level of the scenario. Experimental results show that the\nproposed framework significantly impacts AVs decision-making safety and\ngenerates various corner cases. This method also offers a novel direction for\nresearch in safety-critical scenarios.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u7ea2\u961f\u667a\u80fd\u4f53\u8fdb\u884c\u4e3b\u52a8\u5e72\u6270\u548c\u63a2\u7d22\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8fb9\u7f18\u6848\u4f8b\uff0c\u4ee5\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u51b3\u7b56\u5b89\u5168\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u4f9d\u8d56\u4f4e\u6548\u7684\u6570\u636e\u9a71\u52a8\u573a\u666f\u751f\u6210\u6216\u7279\u5b9a\u5efa\u6a21\u65b9\u6cd5\uff0c\u65e0\u6cd5\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8fb9\u7f18\u6848\u4f8b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea2\u961f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u4e2d\u5177\u6709\u5e72\u6270\u80fd\u529b\u7684\u80cc\u666f\u8f66\u8f86\u88ab\u89c6\u4e3a\u7ea2\u961f\u667a\u80fd\u4f53\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u7ea6\u675f\u56fe\u8868\u793a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u7b56\u7565\u5a01\u80c1\u533a\u57df\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u5f71\u54cd\u4e86\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff08AVs\uff09\u7684\u51b3\u7b56\u5b89\u5168\u6027\uff0c\u5e76\u751f\u6210\u4e86\u5404\u79cd\u8fb9\u7f18\u6848\u4f8b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u5e76\u80fd\u751f\u6210\u5404\u79cd\u8fb9\u7f18\u6848\u4f8b\u3002"}}
{"id": "2507.15542", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15542", "abs": "https://arxiv.org/abs/2507.15542", "authors": ["Qinqian Lei", "Bo Wang", "Robby T. Tan"], "title": "HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation", "comment": "Accepted by ICCV 2025", "summary": "Zero-shot human-object interaction (HOI) detection remains a challenging\ntask, particularly in generalizing to unseen actions. Existing methods address\nthis challenge by tapping Vision-Language Models (VLMs) to access knowledge\nbeyond the training data. However, they either struggle to distinguish actions\ninvolving the same object or demonstrate limited generalization to unseen\nclasses. In this paper, we introduce HOLa (Zero-Shot HOI Detection with\nLow-Rank Decomposed VLM Feature Adaptation), a novel approach that both\nenhances generalization to unseen classes and improves action distinction. In\ntraining, HOLa decomposes VLM text features for given HOI classes via low-rank\nfactorization, producing class-shared basis features and adaptable weights.\nThese features and weights form a compact HOI representation that preserves\nshared information across classes, enhancing generalization to unseen classes.\nSubsequently, we refine action distinction by adapting weights for each HOI\nclass and introducing human-object tokens to enrich visual interaction\nrepresentations. To further distinguish unseen actions, we guide the weight\nadaptation with LLM-derived action regularization. Experimental results show\nthat our method sets a new state-of-the-art across zero-shot HOI settings on\nHICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting.\nOur code is available at https://github.com/ChelsieLei/HOLa.", "AI": {"tldr": "HOLa\u662f\u4e00\u79cd\u65b0\u9896\u7684\u96f6\u6837\u672cHOI\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u79e9\u5206\u89e3VLM\u7279\u5f81\u548cLLM\u9a71\u52a8\u7684\u6b63\u5219\u5316\uff0c\u63d0\u9ad8\u4e86\u5bf9\u4e0d\u53ef\u89c1\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u52a8\u4f5c\u533a\u5206\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u96f6\u6837\u672cHOI\u68c0\u6d4b\u4e2d\u5bf9\u4e0d\u53ef\u89c1\u52a8\u4f5c\u7684\u6cdb\u5316\u80fd\u529b\u548c\u52a8\u4f5c\u533a\u5206\u80fd\u529b\u3002", "method": "HOLa\u9996\u5148\u901a\u8fc7\u4f4e\u79e9\u5206\u89e3VLM\u6587\u672c\u7279\u5f81\uff0c\u751f\u6210\u7c7b\u522b\u5171\u4eab\u7684\u57fa\u7ebf\u7279\u5f81\u548c\u53ef\u9002\u5e94\u7684\u6743\u91cd\u3002\u7136\u540e\uff0c\u4e3a\u6bcf\u4e2aHOI\u7c7b\u522b\u8c03\u6574\u6743\u91cd\uff0c\u5e76\u5f15\u5165\u4eba-\u7269\u6807\u8bb0\u4ee5\u4e30\u5bcc\u89c6\u89c9\u4ea4\u4e92\u8868\u793a\u3002\u6700\u540e\uff0c\u4f7f\u7528LLM\u6d3e\u751f\u7684\u52a8\u4f5c\u6b63\u5219\u5316\u6765\u6307\u5bfc\u6743\u91cd\u8c03\u6574\u3002", "result": "HOLa\u5728HICO-DET\u6570\u636e\u96c6\u7684\u96f6\u6837\u672cHOI\u8bbe\u7f6e\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5728\u4e0d\u53ef\u89c1\u52a8\u8bcd\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e8627.91\u7684\u4e0d\u53ef\u89c1\u7c7b\u522bmAP\u3002", "conclusion": "HOLa\u901a\u8fc7\u4f4e\u79e9\u5206\u89e3VLM\u6587\u672c\u7279\u5f81\uff0c\u751f\u6210\u7c7b\u522b\u5171\u4eab\u7684\u57fa\u7ebf\u7279\u5f81\u548c\u53ef\u9002\u5e94\u7684\u6743\u91cd\uff0c\u5f62\u6210\u7d27\u51d1\u7684HOI\u8868\u793a\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u4e0d\u53ef\u89c1\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2aHOI\u7c7b\u522b\u8c03\u6574\u6743\u91cd\u5e76\u5f15\u5165\u4eba-\u7269\u6807\u8bb0\u4ee5\u4e30\u5bcc\u89c6\u89c9\u4ea4\u4e92\u8868\u793a\u6765\u4f18\u5316\u52a8\u4f5c\u533a\u5206\uff0c\u5e76\u4f7f\u7528LLM\u6d3e\u751f\u7684\u52a8\u4f5c\u6b63\u5219\u5316\u6765\u6307\u5bfc\u6743\u91cd\u8c03\u6574\uff0c\u4ee5\u8fdb\u4e00\u6b65\u533a\u5206\u4e0d\u53ef\u89c1\u52a8\u4f5c\u3002"}}
{"id": "2507.15569", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15569", "abs": "https://arxiv.org/abs/2507.15569", "authors": ["Xiaoyi Bao", "Chenwei Xie", "Hao Tang", "Tingyu Weng", "Xiaofeng Wang", "Yun Zheng", "Xingang Wang"], "title": "DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding", "comment": "Accepted by ICCV 2025", "summary": "In recent years, the introduction of Multi-modal Large Language Models\n(MLLMs) into video understanding tasks has become increasingly prevalent.\nHowever, how to effectively integrate temporal information remains a critical\nresearch focus. Traditional approaches treat spatial and temporal information\nseparately. Due to issues like motion blur, it is challenging to accurately\nrepresent the spatial information of rapidly moving objects. This can lead to\ntemporally important regions being underemphasized during spatial feature\nextraction, which in turn hinders accurate spatio-temporal interaction and\nvideo understanding. To address this limitation, we propose an innovative video\nrepresentation method called Dynamic-Image (DynImg). Specifically, we introduce\na set of non-key frames as temporal prompts to highlight the spatial areas\ncontaining fast-moving objects. During the process of visual feature\nextraction, these prompts guide the model to pay additional attention to the\nfine-grained spatial features corresponding to these regions. Moreover, to\nmaintain the correct sequence for DynImg, we employ a corresponding 4D video\nRotary Position Embedding. This retains both the temporal and spatial adjacency\nof DynImg, helping MLLM understand the spatio-temporal order within this\ncombined format. Experimental evaluations reveal that DynImg surpasses the\nstate-of-the-art methods by approximately 2% across multiple video\nunderstanding benchmarks, proving the effectiveness of our temporal prompts in\nenhancing video comprehension.", "AI": {"tldr": "DynImg\u901a\u8fc7\u4f7f\u7528\u65f6\u95f4\u63d0\u793a\uff08\u975e\u5173\u952e\u5e27\uff09\u6765\u589e\u5f3aMLLMs\u5728\u89c6\u9891\u7406\u89e3\u4e2d\u7684\u65f6\u7a7a\u4ea4\u4e92\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5feb\u901f\u79fb\u52a8\u7269\u4f53\u65f6\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u89c6\u9891\u7406\u89e3\u4efb\u52a1\u4e2d\u5b58\u5728\u5982\u4f55\u6709\u6548\u6574\u5408\u65f6\u95f4\u4fe1\u606f\u7684\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u5c06\u7a7a\u95f4\u548c\u65f6\u95f4\u4fe1\u606f\u5206\u5f00\u5904\u7406\uff0c\u7531\u4e8e\u8fd0\u52a8\u6a21\u7cca\u7b49\u95ee\u9898\uff0c\u5feb\u901f\u79fb\u52a8\u7269\u4f53\u7684\u7a7a\u95f4\u4fe1\u606f\u96be\u4ee5\u51c6\u786e\u8868\u793a\uff0c\u5bfc\u81f4\u65f6\u95f4\u4e0a\u91cd\u8981\u7684\u533a\u57df\u5728\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u4e2d\u88ab\u5ffd\u89c6\uff0c\u4ece\u800c\u963b\u788d\u4e86\u51c6\u786e\u7684\u65f6\u7a7a\u4ea4\u4e92\u548c\u89c6\u9891\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u56fe\u50cf\uff08DynImg\uff09\u7684\u89c6\u9891\u8868\u793a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5f15\u5165\u975e\u5173\u952e\u5e27\u4f5c\u4e3a\u65f6\u95f4\u63d0\u793a\uff0c\u4ee5\u7a81\u51fa\u5305\u542b\u5feb\u901f\u79fb\u52a8\u7269\u4f53\u7684\u7a7a\u95f4\u533a\u57df\uff0c\u5e76\u4f7f\u75284D\u89c6\u9891\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\u6765\u4fdd\u6301DynImg\u7684\u6b63\u786e\u987a\u5e8f\uff0c\u4fdd\u7559\u5176\u65f6\u7a7a\u90bb\u63a5\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cDynImg\u5728\u591a\u4e2a\u89c6\u9891\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u7ea62%\u3002", "conclusion": "DynImg \u901a\u8fc7\u5f15\u5165\u975e\u5173\u952e\u5e27\u4f5c\u4e3a\u65f6\u95f4\u63d0\u793a\uff0c\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u5feb\u901f\u79fb\u52a8\u7269\u4f53\u7684\u7a7a\u95f4\u533a\u57df\uff0c\u5e76\u7ed3\u54084D\u89c6\u9891\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\u6765\u4fdd\u7559\u65f6\u7a7a\u90bb\u63a5\u6027\uff0c\u5728\u591a\u4e2a\u89c6\u9891\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u7ea62%\u7684\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.15614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15614", "abs": "https://arxiv.org/abs/2507.15614", "authors": ["Edward Holmberg", "Pujan Pokhrel", "Maximilian Zoch", "Elias Ioup", "Ken Pathak", "Steven Sloan", "Kendall Niles", "Jay Ratcliff", "Maik Flanagin", "Christian Guetl", "Julian Simeonov", "Mahdi Abdelguerfi"], "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting", "comment": "10 pages, 8 figures", "summary": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but\nare too computationally intensive for on-the-fly decision-making during flood\nevents. The central challenge is to accelerate these simulations without\nsacrificing accuracy. This paper introduces a deep learning surrogate that\ntreats HEC-RAS not as a solver but as a data-generation engine. We propose a\nhybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)\nto capture short-term temporal dynamics with a Geometry-Aware Fourier Neural\nOperator (Geo-FNO) to model long-range spatial dependencies along a river\nreach. The model learns underlying physics implicitly from a minimal\neight-channel feature vector encoding dynamic state, static geometry, and\nboundary forcings extracted directly from native HEC-RAS files. Trained on 67\nreaches of the Mississippi River Basin, the surrogate was evaluated on a\nyear-long, unseen hold-out simulation. Results show the model achieves a strong\npredictive accuracy, with a median absolute stage error of 0.31 feet.\nCritically, for a full 67-reach ensemble forecast, our surrogate reduces the\nrequired wall-clock time from 139 minutes to 40 minutes, a speedup of nearly\n3.5 times over the traditional solver. The success of this data-driven approach\ndemonstrates that robust feature engineering can produce a viable, high-speed\nreplacement for conventional hydraulic models, improving the computational\nfeasibility of large-scale ensemble flood forecasting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\uff08GRU\u548cGeo-FNO\uff09\u7684\u6df7\u5408\u6a21\u578b\uff0c\u4ee5\u52a0\u901fHEC-RAS\u6cb3\u6d41\u6a21\u62df\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u4eceHEC-RAS\u6587\u4ef6\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\uff0c\u5c06\u8ba1\u7b97\u65f6\u95f4\u7f29\u77ed\u4e86\u8fd13.5\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4f7f\u5176\u6210\u4e3a\u5927\u89c4\u6a21\u6d2a\u6c34\u9884\u62a5\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "HEC-RAS\u7b49\u57fa\u4e8e\u7269\u7406\u7684\u6c42\u89e3\u5668\u63d0\u4f9b\u9ad8\u4fdd\u771f\u5ea6\u6cb3\u6d41\u9884\u62a5\uff0c\u4f46\u5728\u6d2a\u6c34\u4e8b\u4ef6\u671f\u95f4\u7684\u5373\u65f6\u51b3\u7b56\u65b9\u9762\uff0c\u5176\u8ba1\u7b97\u91cf\u8fc7\u5927\u3002\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u52a0\u901f\u8fd9\u4e9b\u6a21\u62df\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7684\u3001\u81ea\u56de\u5f52\u7684\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u7ed3\u5408\u4e86\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u6765\u6355\u83b7\u77ed\u671f\u65f6\u95f4\u52a8\u6001\uff0c\u4ee5\u53ca\u51e0\u4f55\u611f\u77e5\u5085\u7acb\u53f6\u795e\u7ecf\u7f51\u7edc\uff08Geo-FNO\uff09\u6765\u6a21\u62df\u6cbf\u6cb3\u6d41\u7684\u8fdc\u7a0b\u7a7a\u95f4\u4f9d\u8d56\u6027\u3002\u8be5\u6a21\u578b\u4ece\u76f4\u63a5\u4ece\u672c\u5730HEC-RAS\u6587\u4ef6\u4e2d\u63d0\u53d6\u7684\u52a8\u6001\u72b6\u6001\u3001\u9759\u6001\u51e0\u4f55\u548c\u8fb9\u754c\u5f3a\u8feb\u7684\u6700\u5c0f\u516b\u901a\u9053\u7279\u5f81\u5411\u91cf\u4e2d\u9690\u5f0f\u5730\u5b66\u4e60\u5e95\u5c42\u7269\u7406\u3002", "result": "\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4e2d\u4f4d\u6570\u7edd\u5bf9\u6c34\u4f4d\u8bef\u5dee\u4e3a0.31\u82f1\u5c3a\u3002\u5173\u952e\u7684\u662f\uff0c\u5bf9\u4e8e\u5b8c\u6574\u768467\u4e2a\u6cb3\u6bb5\u96c6\u5408\u9884\u62a5\uff0c\u6211\u4eec\u7684\u6a21\u62df\u5668\u5c06\u6240\u9700\u7684\u6302\u949f\u65f6\u95f4\u4ece139\u5206\u949f\u51cf\u5c11\u523040\u5206\u949f\uff0c\u901f\u5ea6\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u5feb\u4e86\u8fd13.5\u500d\u3002", "conclusion": "\u8be5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u8868\u660e\uff0c\u53ef\u9760\u7684\u7279\u5f81\u5de5\u7a0b\u53ef\u4ee5\u4ea7\u751f\u4e00\u79cd\u53ef\u884c\u7684\u9ad8\u901f\u66ff\u4ee3\u4f20\u7edf\u6c34\u529b\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u96c6\u5408\u6d2a\u6c34\u9884\u62a5\u7684\u8ba1\u7b97\u53ef\u884c\u6027\u3002"}}
{"id": "2507.15577", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15577", "abs": "https://arxiv.org/abs/2507.15577", "authors": ["Hugo Carlesso", "Maria Eliza Patulea", "Moncef Garouani", "Radu Tudor Ionescu", "Josiane Mothe"], "title": "GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation", "comment": null, "summary": "Mixup has become a popular augmentation strategy for image classification,\nyet its naive pixel-wise interpolation often produces unrealistic images that\ncan hinder learning, particularly in high-stakes medical applications. We\npropose GeMix, a two-stage framework that replaces heuristic blending with a\nlearned, label-aware interpolation powered by class-conditional GANs. First, a\nStyleGAN2-ADA generator is trained on the target dataset. During augmentation,\nwe sample two label vectors from Dirichlet priors biased toward different\nclasses and blend them via a Beta-distributed coefficient. Then, we condition\nthe generator on this soft label to synthesize visually coherent images that\nlie along a continuous class manifold. We benchmark GeMix on the large-scale\nCOVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,\nEfficientNet-B0). When combined with real data, our method increases macro-F1\nover traditional mixup for all backbones, reducing the false negative rate for\nCOVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,\ndelivering stronger regularization and greater semantic fidelity, without\ndisrupting existing training pipelines. We publicly release our code at\nhttps://github.com/hugocarlesso/GeMix to foster reproducibility and further\nresearch.", "AI": {"tldr": "GeMix is a novel augmentation strategy that uses GANs to create more realistic interpolated images, improving performance in medical image classification tasks compared to traditional Mixup.", "motivation": "Naive pixel-wise interpolation in Mixup produces unrealistic images that can hinder learning, particularly in high-stakes medical applications. GeMix aims to replace heuristic blending with a learned, label-aware interpolation powered by class-conditional GANs.", "method": "GeMix is a two-stage framework that uses a StyleGAN2-ADA generator trained on the target dataset. It samples two label vectors from Dirichlet priors biased toward different classes and blends them via a Beta-distributed coefficient. The generator is then conditioned on this soft label to synthesize visually coherent images that lie along a continuous class manifold.", "result": "GeMix increases macro-F1 over traditional mixup for all tested backbones (ResNet-50, ResNet-101, EfficientNet-B0) on the COVIDx-CT-3 dataset, reducing the false negative rate for COVID-19 detection.", "conclusion": "GeMix is a drop-in replacement for pixel-space mixup, delivering stronger regularization and greater semantic fidelity, without disrupting existing training pipelines."}}
{"id": "2507.15578", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.15578", "abs": "https://arxiv.org/abs/2507.15578", "authors": ["Gabriele Inzerillo", "Diego Valsesia", "Aniello Fiengo", "Enrico Magli"], "title": "Compress-Align-Detect: onboard change detection from unregistered images", "comment": null, "summary": "Change detection from satellite images typically incurs a delay ranging from\nseveral hours up to days because of latency in downlinking the acquired images\nand generating orthorectified image products at the ground stations; this may\npreclude real- or near real-time applications. To overcome this limitation, we\npropose shifting the entire change detection workflow onboard satellites. This\nrequires to simultaneously solve challenges in data storage, image registration\nand change detection with a strict complexity constraint. In this paper, we\npresent a novel and efficient framework for onboard change detection that\naddresses the aforementioned challenges in an end-to-end fashion with a deep\nneural network composed of three interlinked submodules: (1) image compression,\ntailored to minimize onboard data storage resources; (2) lightweight\nco-registration of non-orthorectified multi-temporal image pairs; and (3) a\nnovel temporally-invariant and computationally efficient change detection\nmodel. This is the first approach in the literature combining all these tasks\nin a single end-to-end framework with the constraints dictated by onboard\nprocessing. Experimental results compare each submodule with the current\nstate-of-the-art, and evaluate the performance of the overall integrated system\nin realistic setting on low-power hardware. Compelling change detection results\nare obtained in terms of F1 score as a function of compression rate, sustaining\na throughput of 0.7 Mpixel/s on a 15W accelerator.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u6846\u67b6\uff0c\u5c06\u56fe\u50cf\u538b\u7f29\u3001\u5171\u914d\u51c6\u548c\u53d8\u66f4\u68c0\u6d4b\u96c6\u6210\u5230\u536b\u661f\u4e0a\uff0c\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u53d8\u66f4\u68c0\u6d4b\uff0c\u5e76\u8fbe\u5230\u4e86\u663e\u8457\u7684\u6027\u80fd\u3002", "motivation": "\u536b\u661f\u56fe\u50cf\u7684\u53d8\u66f4\u68c0\u6d4b\u901a\u5e38\u4f1a\u6709\u51e0\u4e2a\u5c0f\u65f6\u5230\u51e0\u5929\u7684\u5ef6\u8fdf\uff0c\u56e0\u4e3a\u83b7\u53d6\u7684\u56fe\u50cf\u9700\u8981\u4e0b\u884c\u94fe\u8def\uff0c\u5e76\u4e14\u5730\u9762\u7ad9\u9700\u8981\u751f\u6210\u6b63\u5c04\u6821\u6b63\u7684\u56fe\u50cf\u4ea7\u54c1\uff1b\u8fd9\u53ef\u80fd\u4f1a\u963b\u788d\u5b9e\u65f6\u6216\u8fd1\u5b9e\u65f6\u5e94\u7528\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u9ad8\u6548\u7684\u5728\u8f68\u53d8\u66f4\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u89e3\u51b3\u4e86\u8fd9\u4e9b\u6311\u6218\uff0c\u8be5\u7f51\u7edc\u7531\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u5b50\u6a21\u5757\u7ec4\u6210\uff1a(1) \u56fe\u50cf\u538b\u7f29\uff0c\u65e8\u5728\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u673a\u8f7d\u6570\u636e\u5b58\u50a8\u8d44\u6e90\uff1b(2) \u8f7b\u91cf\u7ea7\u7684\u3001\u975e\u6b63\u5c04\u6821\u6b63\u7684\u591a\u65f6\u76f8\u56fe\u50cf\u5bf9\u7684\u5171\u914d\u51c6\uff1b(3) \u4e00\u4e2a\u65b0\u9896\u7684\u3001\u65f6\u95f4\u4e0d\u53d8\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u53d8\u66f4\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u5728\u538b\u7f29\u7387\u65b9\u9762\u7684 F1 \u5206\u6570\u65b9\u9762\u83b7\u5f97\u4e86\u6709\u5438\u5f15\u529b\u7684\u53d8\u66f4\u68c0\u6d4b\u7ed3\u679c\uff0c\u5728 15W \u52a0\u901f\u5668\u4e0a\u80fd\u591f\u7ef4\u6301 0.7 Mpixel/s \u7684\u541e\u5410\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u5c06\u6240\u6709\u8fd9\u4e9b\u4efb\u52a1\u7ed3\u5408\u5728\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\u4e2d\uff0c\u5e76\u6ee1\u8db3\u5728\u8f68\u5904\u7406\u7684\u9650\u5236\u3002"}}
{"id": "2507.15643", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15643", "abs": "https://arxiv.org/abs/2507.15643", "authors": ["Elnur Isgandarov", "Matteo Cederle", "Federico Chiariotti", "Gian Antonio Susto"], "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems", "comment": "6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication", "summary": "Shared mobility systems, such as bike-sharing networks, play a crucial role\nin urban transportation. Identifying anomalies in these systems is essential\nfor optimizing operations, improving service reliability, and enhancing user\nexperience. This paper presents an interpretable anomaly detection framework\nthat integrates multi-source data, including bike-sharing trip records, weather\nconditions, and public transit availability. The Isolation Forest algorithm is\nemployed for unsupervised anomaly detection, along with the Depth-based\nIsolation Forest Feature Importance (DIFFI) algorithm providing\ninterpretability. Results show that station-level analysis offers a robust\nunderstanding of anomalies, highlighting the influence of external factors such\nas adverse weather and limited transit availability. Our findings contribute to\nimproving decision-making in shared mobility operations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6e90\u6570\u636e\u548c\u9694\u79bb\u68ee\u6797/DIFFI\u7b97\u6cd5\u7684\u53ef\u89e3\u91ca\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\uff0c\u5e76\u5206\u6790\u4e86\u5916\u90e8\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "motivation": "\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u4f5c\u4e3a\u57ce\u5e02\u4ea4\u901a\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u8bc6\u522b\u5176\u5f02\u5e38\u5bf9\u4e8e\u4f18\u5316\u8fd0\u8425\u3001\u63d0\u9ad8\u670d\u52a1\u53ef\u9760\u6027\u548c\u6539\u5584\u7528\u6237\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u591a\u6e90\u6570\u636e\uff08\u5305\u62ec\u5355\u8f66\u5171\u4eab\u884c\u7a0b\u8bb0\u5f55\u3001\u5929\u6c14\u72b6\u51b5\u548c\u516c\u5171\u4ea4\u901a\u53ef\u7528\u6027\uff09\u7684\u53ef\u89e3\u91ca\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u9694\u79bb\u68ee\u6797\u7b97\u6cd5\u8fdb\u884c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u6df1\u5ea6\u7684\u9694\u79bb\u68ee\u6797\u7279\u5f81\u91cd\u8981\u6027\uff08DIFFI\uff09\u7b97\u6cd5\u6765\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u7ad9\u70b9\u7ea7\u522b\u7684\u5206\u6790\u80fd\u591f\u63d0\u4f9b\u5bf9\u5f02\u5e38\u7684\u7a33\u5065\u7406\u89e3\uff0c\u7a81\u663e\u4e86\u8bf8\u5982\u6076\u52a3\u5929\u6c14\u548c\u516c\u5171\u4ea4\u901a\u53ef\u7528\u6027\u53d7\u9650\u7b49\u5916\u90e8\u56e0\u7d20\u5bf9\u5f02\u5e38\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u6570\u636e\u5e76\u7ed3\u5408\u9694\u79bb\u68ee\u6797\u548cDIFFI\u7b97\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\uff0c\u5e76\u63ed\u793a\u5916\u90e8\u56e0\u7d20\uff08\u5982\u6076\u52a3\u5929\u6c14\u548c\u516c\u5171\u4ea4\u901a\u53ef\u7528\u6027\u53d7\u9650\uff09\u5bf9\u5f02\u5e38\u7684\u5f71\u54cd\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5171\u4eab\u51fa\u884c\u7684\u8fd0\u8425\u51b3\u7b56\u6c34\u5e73\u3002"}}
{"id": "2507.15595", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15595", "abs": "https://arxiv.org/abs/2507.15595", "authors": ["Salah Eddine Bekhouche", "Gaby Maroun", "Fadi Dornaika", "Abdenour Hadid"], "title": "SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging", "comment": null, "summary": "Medical image segmentation is crucial for many healthcare tasks, including\ndisease diagnosis and treatment planning. One key area is the segmentation of\nskin lesions, which is vital for diagnosing skin cancer and monitoring\npatients. In this context, this paper introduces SegDT, a new segmentation\nmodel based on diffusion transformer (DiT). SegDT is designed to work on\nlow-cost hardware and incorporates Rectified Flow, which improves the\ngeneration quality at reduced inference steps and maintains the flexibility of\nstandard diffusion models. Our method is evaluated on three benchmarking\ndatasets and compared against several existing works, achieving\nstate-of-the-art results while maintaining fast inference speeds. This makes\nthe proposed model appealing for real-world medical applications. This work\nadvances the performance and capabilities of deep learning models in medical\nimage analysis, enabling faster, more accurate diagnostic tools for healthcare\nprofessionals. The code is made publicly available at\n\\href{https://github.com/Bekhouche/SegDT}{GitHub}.", "AI": {"tldr": "SegDT\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563Transformer\u548cRectified Flow\u7684\u65b0\u578b\u76ae\u80a4\u75c5\u53d8\u5206\u5272\u6a21\u578b\uff0c\u53ef\u5728\u4f4e\u6210\u672c\u786c\u4ef6\u4e0a\u8fd0\u884c\uff0c\u5177\u6709\u5feb\u901f\u63a8\u7406\u548c\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u533b\u7597\u56fe\u50cf\u5206\u5272\uff0c\u7279\u522b\u662f\u76ae\u80a4\u75c5\u53d8\u5206\u5272\u7684\u95ee\u9898\uff0c\u4ee5\u8f85\u52a9\u75be\u75c5\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSegDT\u7684\u65b0\u578b\u5206\u5272\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u6269\u6563Transformer\uff08DiT\uff09\uff0c\u5e76\u7ed3\u5408\u4e86Rectified Flow\u3002", "result": "SegDT\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u5feb\u3002", "conclusion": "SegDT\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5feb\u901f\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u4f7f\u5176\u5728\u5b9e\u9645\u533b\u7597\u5e94\u7528\u4e2d\u5177\u6709\u5438\u5f15\u529b\u3002"}}
{"id": "2507.15678", "categories": ["cs.LG", "math.DG", "math.DS", "math.SG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.15678", "abs": "https://arxiv.org/abs/2507.15678", "authors": ["Amine Mohamed Aboussalah", "Abdessalam Ed-dib"], "title": "GeoHNNs: Geometric Hamiltonian Neural Networks", "comment": null, "summary": "The fundamental laws of physics are intrinsically geometric, dictating the\nevolution of systems through principles of symmetry and conservation. While\nmodern machine learning offers powerful tools for modeling complex dynamics\nfrom data, common methods often ignore this underlying geometric fabric.\nPhysics-informed neural networks, for instance, can violate fundamental\nphysical principles, leading to predictions that are unstable over long\nperiods, particularly for high-dimensional and chaotic systems. Here, we\nintroduce \\textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework\nthat learns dynamics by explicitly encoding the geometric priors inherent to\nphysical laws. Our approach enforces two fundamental structures: the Riemannian\ngeometry of inertia, by parameterizing inertia matrices in their natural\nmathematical space of symmetric positive-definite matrices, and the symplectic\ngeometry of phase space, using a constrained autoencoder to ensure the\npreservation of phase space volume in a reduced latent space. We demonstrate\nthrough experiments on systems ranging from coupled oscillators to\nhigh-dimensional deformable objects that GeoHNN significantly outperforms\nexisting models. It achieves superior long-term stability, accuracy, and energy\nconservation, confirming that embedding the geometry of physics is not just a\ntheoretical appeal but a practical necessity for creating robust and\ngeneralizable models of the physical world.", "AI": {"tldr": "GeoHNN\u662f\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u6574\u5408\u7269\u7406\u5b66\u7684\u51e0\u4f55\u539f\u7406\u6765\u5b66\u4e60\u52a8\u6001\u7cfb\u7edf\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b83\u5728\u4fdd\u6301\u957f\u671f\u7a33\u5b9a\u6027\u3001\u51c6\u786e\u6027\u548c\u80fd\u91cf\u5b88\u6052\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u8bc1\u660e\u4e86\u5c06\u7269\u7406\u51e0\u4f55\u5d4c\u5165\u5230\u6a21\u578b\u4e2d\u7684\u5b9e\u9645\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f1a\u5ffd\u7565\u7269\u7406\u5b66\u7684\u57fa\u672c\u51e0\u4f55\u7ed3\u6784\uff0c\u53ef\u80fd\u5bfc\u81f4\u7269\u7406\u5b66\u539f\u7406\u7684\u8fdd\u53cd\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u9ad8\u7ef4\u548c\u6df7\u6c8c\u7cfb\u7edf\u65f6\uff0c\u9884\u6d4b\u4f1a\u957f\u671f\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u51e0\u4f55\u54c8\u5bc6\u987f\u795e\u7ecf\u7f51\u7edc\uff08GeoHNN\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5728\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u7684\u81ea\u7136\u6570\u5b66\u7a7a\u95f4\u4e2d\u53c2\u6570\u5316\u60ef\u6027\u77e9\u9635\u6765\u5f3a\u5236\u6267\u884c\u60ef\u6027\u6d41\u5f62\uff0c\u5e76\u901a\u8fc7\u4f7f\u7528\u7ea6\u675f\u81ea\u7f16\u7801\u5668\u6765\u786e\u4fdd\u7f29\u51cf\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u76f8\u7a7a\u95f4\u4f53\u79ef\u5b88\u6052\uff0c\u6765\u5f3a\u5236\u6267\u884c\u76f8\u7a7a\u95f4\u7684\u8f9b\u51e0\u4f55\u3002", "result": "GeoHNN\u5728\u4ece\u8026\u5408\u632f\u8361\u5668\u5230\u9ad8\u7ef4\u53ef\u53d8\u5f62\u7269\u4f53\u7b49\u5404\u79cd\u7cfb\u7edf\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\uff0c\u63d0\u9ad8\u4e86\u957f\u671f\u7a33\u5b9a\u6027\u3001\u51c6\u786e\u6027\u548c\u80fd\u91cf\u5b88\u6052\u3002", "conclusion": "GeoHNN\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u7f16\u7801\u7269\u7406\u5b9a\u5f8b\u56fa\u6709\u7684\u51e0\u4f55\u5148\u9a8c\uff0c\u5728\u5b66\u4e60\u52a8\u529b\u5b66\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u5728\u957f\u671f\u7a33\u5b9a\u6027\u3001\u51c6\u786e\u6027\u548c\u80fd\u91cf\u5b88\u6052\u65b9\u9762\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.15718", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15718", "abs": "https://arxiv.org/abs/2507.15718", "authors": ["Matteo Cederle", "Andrea Mazzucco", "Andrea Demartini", "Eugenio Mazza", "Eugenia Suriani", "Federico Vitti", "Gian Antonio Susto"], "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations", "comment": "4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication)", "summary": "Electric vehicles (EV) charging stations are one of the critical\ninfrastructures needed to support the transition to renewable-energy-based\nmobility, but ensuring their reliability and efficiency requires effective\nanomaly detection to identify irregularities in charging behavior. However, in\nsuch a productive scenario, it is also crucial to determine the underlying\ncause behind the detected anomalies. To achieve this goal, this study\ninvestigates unsupervised anomaly detection techniques for EV charging\ninfrastructure, integrating eXplainable Artificial Intelligence techniques to\nenhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies\nIsolation Forest to detect anomalies and employs the Depth-based Isolation\nForest Feature Importance (DIFFI) method to identify the most important\nfeatures contributing to such anomalies. The efficacy of the proposed approach\nis evaluated in a real industrial case.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86 Isolation Forest \u548c DIFFI \u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u7684\u5f02\u5e38\u5e76\u627e\u51fa\u6839\u672c\u539f\u56e0\u3002", "motivation": "\u4e3a\u4e86\u786e\u4fdd\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u9700\u8981\u6709\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u6765\u8bc6\u522b\u5145\u7535\u884c\u4e3a\u4e2d\u7684\u5f02\u5e38\uff0c\u5e76\u786e\u5b9a\u5f02\u5e38\u80cc\u540e\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u8be5\u7814\u7a76\u5e94\u7528 Isolation Forest \u68c0\u6d4b\u5f02\u5e38\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u6df1\u5ea6\u7684 Isolation Forest \u7279\u5f81\u91cd\u8981\u6027 (DIFFI) \u65b9\u6cd5\u627e\u51fa\u5bfc\u81f4\u5f02\u5e38\u7684\u6700\u91cd\u8981\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u5de5\u4e1a\u6848\u4f8b\u4e2d\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u901a\u8fc7\u96c6\u6210\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u8bc6\u522b\u5145\u7535\u884c\u4e3a\u4e2d\u7684\u5f02\u5e38\u5e76\u627e\u51fa\u6839\u672c\u539f\u56e0\u3002"}}
{"id": "2507.15602", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15602", "abs": "https://arxiv.org/abs/2507.15602", "authors": ["Zihui Gao", "Jia-Wang Bian", "Guosheng Lin", "Hao Chen", "Chunhua Shen"], "title": "SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting", "comment": null, "summary": "Surface reconstruction and novel view rendering from sparse-view images are\nchallenging. Signed Distance Function (SDF)-based methods struggle with fine\ndetails, while 3D Gaussian Splatting (3DGS)-based approaches lack global\ngeometry coherence. We propose a novel hybrid method that combines the\nstrengths of both approaches: SDF captures coarse geometry to enhance\n3DGS-based rendering, while newly rendered images from 3DGS refine the details\nof SDF for accurate surface reconstruction. As a result, our method surpasses\nstate-of-the-art approaches in surface reconstruction and novel view synthesis\non the DTU and MobileBrick datasets. Code will be released at\nhttps://github.com/Gaozihui/SurfaceSplat.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SDF\u548c3DGS\u4f18\u70b9\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u7a00\u758f\u89c6\u56fe\u8868\u9762\u91cd\u5efa\u548c\u65b0\u89c6\u56fe\u6e32\u67d3\u7684\u6311\u6218\uff0c\u5e76\u5728DTU\u548cMobileBrick\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4ece\u7a00\u758f\u89c6\u56fe\u56fe\u50cf\u8fdb\u884c\u8868\u9762\u91cd\u5efa\u548c\u65b0\u89c6\u56fe\u6e32\u67d3\u7684\u6311\u6218\u3002SDF\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7cbe\u7ec6\u7ec6\u8282\uff0c\u800c3DGS\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u51e0\u4f55\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86SDF\u548c3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u4f18\u70b9\u3002SDF\u6355\u6349\u7c97\u7cd9\u51e0\u4f55\u4ee5\u589e\u5f3a3DGS\u6e32\u67d3\uff0c\u800c3DGS\u7684\u65b0\u6e32\u67d3\u56fe\u50cf\u5219\u7528\u4e8e\u7cbe\u70bcSDF\u7684\u7ec6\u8282\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684\u8868\u9762\u91cd\u5efa\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u5728\u8868\u9762\u91cd\u5efa\u548c\u65b0\u89c6\u56fe\u6e32\u67d3\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728DTU\u548cMobileBrick\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u8868\u9762\u91cd\u5efa\u548c\u65b0\u89c6\u89d2\u5408\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.15606", "categories": ["cs.CV", "68T45", "I.4.5"], "pdf": "https://arxiv.org/pdf/2507.15606", "abs": "https://arxiv.org/abs/2507.15606", "authors": ["Ru Jia", "Xiaozhuang Ma", "Jianji Wang", "Nanning Zheng"], "title": "CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation", "comment": "5 pages, 4 figures, to be published", "summary": "While the proposal of the Tri-plane representation has advanced the\ndevelopment of the 3D-aware image generative models, problems rooted in its\ninherent structure, such as multi-face artifacts caused by sharing the same\nfeatures in symmetric regions, limit its ability to generate 360$^\\circ$ view\nimages. In this paper, we propose CylinderPlane, a novel implicit\nrepresentation based on Cylindrical Coordinate System, to eliminate the feature\nambiguity issue and ensure multi-view consistency in 360$^\\circ$. Different\nfrom the inevitable feature entanglement in Cartesian coordinate-based\nTri-plane representation, the cylindrical coordinate system explicitly\nseparates features at different angles, allowing our cylindrical representation\npossible to achieve high-quality, artifacts-free 360$^\\circ$ image synthesis.\nWe further introduce the nested cylinder representation that composites\nmultiple cylinders at different scales, thereby enabling the model more\nadaptable to complex geometry and varying resolutions. The combination of\ncylinders with different resolutions can effectively capture more critical\nlocations and multi-scale features, greatly facilitates fine detail learning\nand robustness to different resolutions. Moreover, our representation is\nagnostic to implicit rendering methods and can be easily integrated into any\nneural rendering pipeline. Extensive experiments on both synthetic dataset and\nunstructured in-the-wild images demonstrate that our proposed representation\nachieves superior performance over previous methods.", "AI": {"tldr": "CylinderPlane uses a cylindrical coordinate system to improve 360\u00b0 image generation by avoiding artifacts common in Tri-plane methods, and it works well with different resolutions and rendering techniques.", "motivation": "To address the limitations of Tri-plane representation in 3D-aware image generative models, specifically the multi-face artifacts caused by feature sharing in symmetric regions, which hinder the generation of consistent 360\u00b0 view images.", "method": "The proposed method utilizes a Cylindrical Coordinate System for feature representation, explicitly separating features at different angles to avoid the multi-face artifacts seen in Tri-plane representations. It also introduces a nested cylinder representation that composites multiple cylinders at different scales to handle complex geometry and varying resolutions, making it adaptable to different neural rendering pipelines.", "result": "The CylinderPlane representation enables high-quality, artifacts-free 360\u00b0 image synthesis by explicitly separating features at different angles. The nested cylinder representation further improves adaptability to complex geometry and varying resolutions, facilitating fine detail learning and robustness. Experiments show superior performance compared to existing methods on both synthetic and real-world images.", "conclusion": "CylinderPlane, a novel implicit representation based on Cylindrical Coordinate System, eliminates feature ambiguity and ensures multi-view consistency for 360\u00b0 image synthesis, achieving superior performance over previous methods."}}
{"id": "2507.15769", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15769", "abs": "https://arxiv.org/abs/2507.15769", "authors": ["Ahmad M. Nazar", "Abdulkadir Celik", "Mohamed Y. Selim", "Asmaa Abdallah", "Daji Qiao", "Ahmed M. Eltawil"], "title": "Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks", "comment": "Accepted in IEEE Asilomar Conference on Signals, Systems, and\n  Computers 2025", "summary": "Vehicular communication systems operating in the millimeter wave (mmWave)\nband are highly susceptible to signal blockage from dynamic obstacles such as\nvehicles, pedestrians, and infrastructure. To address this challenge, we\npropose a proactive blockage prediction framework that utilizes multi-modal\nsensing, including camera, GPS, LiDAR, and radar inputs in an\ninfrastructure-to-vehicle (I2V) setting. This approach uses modality-specific\ndeep learning models to process each sensor stream independently and fuses\ntheir outputs using a softmax-weighted ensemble strategy based on validation\nperformance. Our evaluations, for up to 1.5s in advance, show that the\ncamera-only model achieves the best standalone trade-off with an F1-score of\n97.1% and an inference time of 89.8ms. A camera+radar configuration further\nimproves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness\nand efficiency of multi-modal sensing for mmWave blockage prediction and\nprovide a pathway for proactive wireless communication in dynamic environments.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u8f66\u8f86\u901a\u4fe1\u5728\u6beb\u7c73\u6ce2\u9891\u6bb5\u4e2d\u6781\u6613\u53d7\u5230\u4fe1\u53f7\u963b\u585e\u7684\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u591a\u6a21\u6001\u4f20\u611f\uff08\u76f8\u673a\u3001GPS\u3001LiDAR\u3001\u96f7\u8fbe\uff09\u7684\u524d\u77bb\u6027\u963b\u585e\u9884\u6d4b\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8f66\u8f86\u901a\u4fe1\u7cfb\u7edf\u5728\u6beb\u7c73\u6ce2\uff08mmWave\uff09\u9891\u6bb5\u4e2d\u6781\u6613\u53d7\u5230\u8f66\u8f86\u3001\u884c\u4eba\u3001\u57fa\u7840\u8bbe\u65bd\u7b49\u52a8\u6001\u969c\u788d\u7269\u4fe1\u53f7\u963b\u585e\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u5305\u62ec\u76f8\u673a\u3001GPS\u3001LiDAR\u548c\u96f7\u8fbe\u8f93\u5165\u7684\u4f20\u611f\u5668\uff0c\u5728\u57fa\u7840\u8bbe\u65bd\u5230\u8f66\u8f86\uff08I2V\uff09\u8bbe\u7f6e\u4e2d\uff0c\u4f7f\u7528\u7279\u5b9a\u6a21\u6001\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u4f20\u611f\u5668\u6d41\uff0c\u5e76\u57fa\u4e8e\u9a8c\u8bc1\u6027\u80fd\u4f7f\u7528softmax\u52a0\u6743\u96c6\u6210\u7b56\u7565\u878d\u5408\u5b83\u4eec\u7684\u8f93\u51fa\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u4ec5\u4f7f\u7528\u76f8\u673a\u7684\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u4f73\u7684\u72ec\u7acb\u6743\u8861\uff0cF1\u5206\u6570\u8fbe\u523097.1%\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a89.8\u6beb\u79d2\u3002\u76f8\u673a+\u96f7\u8fbe\u914d\u7f6e\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u523097.2% F1\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a95.7\u6beb\u79d2\uff0c\u9884\u6d4b\u65f6\u95f4\u957f\u8fbe1.5\u79d2\u3002", "conclusion": "\u591a\u6a21\u6001\u4f20\u611f\u5bf9\u4e8e\u6beb\u7c73\u6ce2\uff08mmWave\uff09\u963b\u585e\u9884\u6d4b\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u5f97\u5230\u4e86\u8bc1\u660e\uff0c\u5e76\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4e3b\u52a8\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2507.15628", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15628", "abs": "https://arxiv.org/abs/2507.15628", "authors": ["Shanjiang Tang", "Rui Huang", "Hsinyu Luo", "Chunjiang Wang", "Ce Yu", "Yusen Li", "Hao Fu", "Chao Sun", "and Jian Xiao"], "title": "A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications", "comment": null, "summary": "The explosive growth of video data in recent years has brought higher demands\nfor video analytics, where accuracy and efficiency remain the two primary\nconcerns. Deep neural networks (DNNs) have been widely adopted to ensure\naccuracy; however, improving their efficiency in video analytics remains an\nopen challenge. Different from existing surveys that make summaries of\nDNN-based video mainly from the accuracy optimization aspect, in this survey,\nwe aim to provide a thorough review of optimization techniques focusing on the\nimprovement of the efficiency of DNNs in video analytics. We organize existing\nmethods in a bottom-up manner, covering multiple perspectives such as hardware\nsupport, data processing, operational deployment, etc. Finally, based on the\noptimization framework and existing works, we analyze and discuss the problems\nand challenges in the performance optimization of DNN-based video analytics.", "AI": {"tldr": "\u672c\u8c03\u67e5\u4e13\u6ce8\u4e8e\u63d0\u9ad8\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u5728\u89c6\u9891\u5206\u6790\u4e2d\u6548\u7387\u7684\u4f18\u5316\u6280\u672f\uff0c\u6db5\u76d6\u786c\u4ef6\u3001\u6570\u636e\u5904\u7406\u548c\u90e8\u7f72\u7b49\u65b9\u9762\uff0c\u5e76\u8ba8\u8bba\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\u4e0e\u6311\u6218\u3002", "motivation": "\u968f\u7740\u89c6\u9891\u6570\u636e\u7684\u7206\u70b8\u5f0f\u589e\u957f\uff0c\u5bf9\u89c6\u9891\u5206\u6790\u7684\u9700\u6c42\u4e0d\u65ad\u589e\u52a0\uff0c\u5176\u4e2d\u51c6\u786e\u6027\u548c\u6548\u7387\u662f\u4e24\u4e2a\u4e3b\u8981\u5173\u6ce8\u70b9\u3002\u5c3d\u7ba1\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7528\u4ee5\u786e\u4fdd\u51c6\u786e\u6027\uff0c\u4f46\u63d0\u9ad8\u5176\u5728\u89c6\u9891\u5206\u6790\u4e2d\u7684\u6548\u7387\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u6311\u6218\u3002", "method": "\u672c\u8c03\u67e5\u65e8\u5728\u63d0\u4f9b\u5bf9 DNN \u5728\u89c6\u9891\u5206\u6790\u4e2d\u7684\u6548\u7387\u4f18\u5316\u6280\u672f\u7684\u5168\u9762\u56de\u987e\uff0c\u5e76\u6309\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u5f0f\u7ec4\u7ec7\u73b0\u6709\u65b9\u6cd5\uff0c\u6db5\u76d6\u786c\u4ef6\u652f\u6301\u3001\u6570\u636e\u5904\u7406\u3001\u64cd\u4f5c\u90e8\u7f72\u7b49\u591a\u4e2a\u89c6\u89d2\u3002", "result": "\u672c\u8c03\u67e5\u5168\u9762\u56de\u987e\u4e86 DNN \u5728\u89c6\u9891\u5206\u6790\u4e2d\u7684\u6548\u7387\u4f18\u5316\u6280\u672f\uff0c\u5e76\u5206\u6790\u4e86\u76f8\u5173\u95ee\u9898\u4e0e\u6311\u6218\u3002", "conclusion": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u5728\u89c6\u9891\u5206\u6790\u4e2d\u7684\u6548\u7387\u4f18\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u6311\u6218\u3002\u672c\u8c03\u67e5\u5168\u9762\u56de\u987e\u4e86 DNN \u5728\u89c6\u9891\u5206\u6790\u4e2d\u7684\u6548\u7387\u4f18\u5316\u6280\u672f\uff0c\u6db5\u76d6\u4e86\u786c\u4ef6\u652f\u6301\u3001\u6570\u636e\u5904\u7406\u3001\u64cd\u4f5c\u90e8\u7f72\u7b49\u591a\u4e2a\u89c6\u89d2\uff0c\u5e76\u5206\u6790\u4e86\u73b0\u6709\u4f18\u5316\u6846\u67b6\u548c\u5de5\u4f5c\u4e2d\u7684\u95ee\u9898\u4e0e\u6311\u6218\u3002"}}
{"id": "2507.15772", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2507.15772", "abs": "https://arxiv.org/abs/2507.15772", "authors": ["Anoop C. Patil", "Benny Jian Rong Sng", "Yu-Wei Chang", "Joana B. Pereira", "Chua Nam-Hai", "Rajani Sarojam", "Gajendra Pratap Singh", "In-Cheol Jang", "Giovanni Volpe"], "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis", "comment": "*Authors contributed equally to this work. +Supervised this work. 5\n  main figures and 1 extended data figure in manuscript. The PDF includes\n  supplementary material", "summary": "Detecting stress in plants is crucial for both open-farm and\ncontrolled-environment agriculture. Biomolecules within plants serve as key\nstress indicators, offering vital markers for continuous health monitoring and\nearly disease detection. Raman spectroscopy provides a powerful, non-invasive\nmeans to quantify these biomolecules through their molecular vibrational\nsignatures. However, traditional Raman analysis relies on customized\ndata-processing workflows that require fluorescence background removal and\nprior identification of Raman peaks of interest-introducing potential biases\nand inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation\nof Vibrational Raman spectra for plant-stress Analysis), a fully automated\nworkflow based on a variational autoencoder. Unlike conventional approaches,\nDIVA processes native Raman spectra-including fluorescence backgrounds-without\nmanual preprocessing, identifying and quantifying significant spectral features\nin an unbiased manner. We applied DIVA to detect a range of plant stresses,\nincluding abiotic (shading, high light intensity, high temperature) and biotic\nstressors (bacterial infections). By integrating deep learning with vibrational\nspectroscopy, DIVA paves the way for AI-driven plant health assessment,\nfostering more resilient and sustainable agricultural practices.", "AI": {"tldr": "DIVA\u662f\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5168\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7528\u4e8e\u65e0\u504f\u89c1\u5730\u5206\u6790\u62c9\u66fc\u5149\u8c31\u4ee5\u68c0\u6d4b\u690d\u7269\u80c1\u8feb\uff0c\u65e0\u9700\u624b\u52a8\u9884\u5904\u7406\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u4f20\u7edf\u62c9\u66fc\u5206\u6790\u5728\u5904\u7406\u8367\u5149\u80cc\u666f\u548c\u624b\u52a8\u8bc6\u522b\u62c9\u66fc\u5cf0\u65f6\u5b58\u5728\u7684\u6f5c\u5728\u504f\u89c1\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u81ea\u52a8\u5316\u3001\u65e0\u504f\u89c1\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u690d\u7269\u80c1\u8feb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDIVA\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u690d\u7269\u80c1\u8feb\u632f\u52a8\u62c9\u66fc\u5149\u8c31\u5206\u6790\uff09\u7684\u5168\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u53ef\u76f4\u63a5\u5904\u7406\u5305\u542b\u8367\u5149\u80cc\u666f\u7684\u539f\u59cb\u62c9\u66fc\u5149\u8c31\uff0c\u65e0\u9700\u624b\u52a8\u9884\u5904\u7406\uff0c\u5e76\u4ee5\u65e0\u504f\u89c1\u7684\u65b9\u5f0f\u8bc6\u522b\u548c\u91cf\u5316\u91cd\u8981\u7684\u5149\u8c31\u7279\u5f81\u3002", "result": "DIVA\u6210\u529f\u5e94\u7528\u4e8e\u68c0\u6d4b\u906e\u836b\u3001\u9ad8\u5149\u5f3a\u3001\u9ad8\u6e29\u7b49\u975e\u751f\u7269\u80c1\u8feb\u4ee5\u53ca\u7ec6\u83cc\u611f\u67d3\u7b49\u751f\u7269\u80c1\u8feb\u3002", "conclusion": "DIVA\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u632f\u52a8\u5149\u8c31\uff0c\u5b9e\u73b0\u4e86\u5bf9\u690d\u7269\u80c1\u8feb\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u690d\u7269\u5065\u5eb7\u8bc4\u4f30\u5f00\u8f9f\u4e86\u9053\u8def\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u66f4\u5177\u97e7\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u519c\u4e1a\u5b9e\u8df5\u3002"}}
{"id": "2507.15633", "categories": ["cs.CV", "I.2.10; I.4.8; H.3.3"], "pdf": "https://arxiv.org/pdf/2507.15633", "abs": "https://arxiv.org/abs/2507.15633", "authors": ["Sachin Sharma", "Federico Simonetta", "Michele Flammini"], "title": "Experimenting active and sequential learning in a medieval music manuscript", "comment": "6 pages, 4 figures, accepted at IEEE MLSP 2025 (IEEE International\n  Workshop on Machine Learning for Signal Processing). Special Session:\n  Applications of AI in Cultural and Artistic Heritage", "summary": "Optical Music Recognition (OMR) is a cornerstone of music digitization\ninitiatives in cultural heritage, yet it remains limited by the scarcity of\nannotated data and the complexity of historical manuscripts. In this paper, we\npresent a preliminary study of Active Learning (AL) and Sequential Learning\n(SL) tailored for object detection and layout recognition in an old medieval\nmusic manuscript. Leveraging YOLOv8, our system selects samples with the\nhighest uncertainty (lowest prediction confidence) for iterative labeling and\nretraining. Our approach starts with a single annotated image and successfully\nboosts performance while minimizing manual labeling. Experimental results\nindicate that comparable accuracy to fully supervised training can be achieved\nwith significantly fewer labeled examples. We test the methodology as a\npreliminary investigation on a novel dataset offered to the community by the\nAnonymous project, which studies laude, a poetical-musical genre spread across\nItaly during the 12th-16th Century. We show that in the manuscript at-hand,\nuncertainty-based AL is not effective and advocates for more usable methods in\ndata-scarcity scenarios.", "AI": {"tldr": "\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u548c\u987a\u5e8f\u5b66\u4e60\uff08SL\uff09\u5728\u5149\u5b66\u97f3\u4e50\u8bc6\u522b\uff08OMR\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u7814\u7a76\u4eba\u5458\u4f7f\u7528 YOLOv8 \u6a21\u578b\uff0c\u901a\u8fc7\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u6837\u672c\u8fdb\u884c\u6807\u6ce8\u548c\u8bad\u7ec3\uff0c\u5e76\u5728Medieval\u624b\u7a3f\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u5168\u76d1\u7763\u5b66\u4e60\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u6ce8\u6570\u636e\u91cf\u5927\u5927\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u53d6\u5f97\u4e86\u76f8\u4f3c\u7684\u51c6\u786e\u7387\u3002\u7136\u800c\uff0c\u7814\u7a76\u4e5f\u6307\u51fa\uff0c\u5728\u6240\u7528\u7684\u624b\u7a3f\u4e2d\uff0c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684AL\u6548\u679c\u4e0d\u4f73\uff0c\u5e76\u5efa\u8bae\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u63a2\u7d22\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "motivation": "\u5149\u5b66\u97f3\u4e50\u8bc6\u522b\uff08OMR\uff09\u662f\u6587\u5316\u9057\u4ea7\u4e2d\u97f3\u4e50\u6570\u5b57\u5316\u7684\u57fa\u7840\uff0c\u4f46\u5176\u53d1\u5c55\u53d7\u5230\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u548c\u5386\u53f2\u624b\u7a3f\u590d\u6742\u6027\u7684\u9650\u5236\u3002", "method": "\u5229\u7528 YOLOv8\uff0c\u8be5\u7cfb\u7edf\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u6700\u9ad8\uff08\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u6700\u4f4e\uff09\u7684\u6837\u672c\u8fdb\u884c\u8fed\u4ee3\u6807\u6ce8\u548c\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7528\u66f4\u5c11\u7684\u6807\u6ce8\u6837\u672c\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5168\u76d1\u7763\u8bad\u7ec3\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6240\u7528\u7684\u624b\u7a3f\u4e2d\uff0c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u6548\u679c\u4e0d\u4f73\uff0c\u5e76\u63d0\u5021\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u4f7f\u7528\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.15774", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15774", "abs": "https://arxiv.org/abs/2507.15774", "authors": ["Alexis-Raja Brachet", "Pierre-Yves Richard", "C\u00e9line Hudelot"], "title": "Dynamics is what you need for time-series forecasting!", "comment": "13 pages, 6 figures, 1 table", "summary": "While boundaries between data modalities are vanishing, the usual successful\ndeep models are still challenged by simple ones in the time-series forecasting\ntask. Our hypothesis is that this task needs models that are able to learn the\ndata underlying dynamics. We propose to validate it through both systemic and\nempirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to\nanalyze existing models through the lens of dynamics. Two observations thus\nemerged: $\\textbf{1}$. under-performing architectures learn dynamics at most\npartially, $\\textbf{2}$. the location of the dynamics block at the model end is\nof prime importance. We conduct extensive experiments to confirm our\nobservations on a set of performance-varying models with diverse backbones.\nResults support the need to incorporate a learnable dynamics block and its use\nas the final predictor.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15636", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15636", "abs": "https://arxiv.org/abs/2507.15636", "authors": ["Lisan Al Amin", "Md. Ismail Hossain", "Thanh Thi Nguyen", "Tasnim Jahan", "Mahbubul Islam", "Faisal Quader"], "title": "Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis", "comment": "Accepted for publication at the 2025 IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC)", "summary": "Recent advances in deepfake technology have created increasingly convincing\nsynthetic media that poses significant challenges to information integrity and\nsocial trust. While current detection methods show promise, their underlying\nmechanisms remain poorly understood, and the large sizes of their models make\nthem challenging to deploy in resource-limited environments. This study\ninvestigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake\ndetection, aiming to identify the key features crucial for recognizing\ndeepfakes. We examine how neural networks can be efficiently pruned while\nmaintaining high detection accuracy. Through extensive experiments with\nMesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and\nFaceForensics++ datasets, we find that deepfake detection networks contain\nwinning tickets, i.e., subnetworks, that preserve performance even at\nsubstantial sparsity levels. Our results indicate that MesoNet retains 56.2%\naccuracy at 80% sparsity on the OpenForensic dataset, with only 3,000\nparameters, which is about 90% of its baseline accuracy (62.6%). The results\nalso show that our proposed LTH-based iterative magnitude pruning approach\nconsistently outperforms one-shot pruning methods. Using Grad-CAM\nvisualization, we analyze how pruned networks maintain their focus on critical\nfacial regions for deepfake detection. Additionally, we demonstrate the\ntransferability of winning tickets across datasets, suggesting potential for\nefficient, deployable deepfake detection systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u5f69\u7968\u5047\u8bf4\u5e94\u7528\u4e8e\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u901a\u8fc7\u526a\u679d\u6280\u672f\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u51cf\u5c0f\u6a21\u578b\u5927\u5c0f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u572880%\u7a00\u758f\u5ea6\u4e0b\uff0cMesoNet\u4e5f\u80fd\u4fdd\u6301\u7ea690%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u548c\u8de8\u6570\u636e\u96c6\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u4e3a\u5f00\u53d1\u9ad8\u6548\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u8fdb\u6b65\u5e26\u6765\u4e86\u8d8a\u6765\u8d8a\u903c\u771f\u7684\u5408\u6210\u5a92\u4f53\uff0c\u5bf9\u4fe1\u606f\u5b8c\u6574\u6027\u548c\u793e\u4f1a\u4fe1\u4efb\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u68c0\u6d4b\u65b9\u6cd5\u867d\u7136\u6709\u524d\u666f\uff0c\u4f46\u5176\u5e95\u5c42\u673a\u5236\u7406\u89e3\u4e0d\u8db3\uff0c\u4e14\u6a21\u578b\u5e9e\u5927\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5e94\u7528\u5f69\u7968\u5047\u8bf4\uff08LTH\uff09\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ee5\u8bc6\u522b\u5bf9\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\u7684\u5173\u952e\u7279\u5f81\uff0c\u5e76\u63a2\u7d22\u9ad8\u6548\u7684\u526a\u679d\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u5c06\u5f69\u7968\u5047\u8bf4\uff08LTH\uff09\u5e94\u7528\u4e8e\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u68c0\u67e5\u4e86\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u5728\u4fdd\u6301\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u7684\u540c\u65f6\u8fdb\u884c\u6709\u6548\u526a\u679d\u3002\u7814\u7a76\u4f7f\u7528\u4e86MesoNet\u3001CNN-5\u548cResNet-18\u67b6\u6784\uff0c\u5e76\u5728OpenForensic\u548cFaceForensics++\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002\u901a\u8fc7Grad-CAM\u53ef\u89c6\u5316\u5206\u6790\u4e86\u526a\u679d\u7f51\u7edc\u5982\u4f55\u4fdd\u6301\u5bf9\u5173\u952e\u9762\u90e8\u533a\u57df\u7684\u5173\u6ce8\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7f51\u7edc\u5305\u542b\u201c\u4e2d\u5956\u5f69\u7968\u201d\uff0c\u5373\u5b50\u7f51\u7edc\uff0c\u53ef\u4ee5\u5728\u9ad8\u7a00\u758f\u5ea6\u4e0b\u4fdd\u6301\u6027\u80fd\u3002\u4f8b\u5982\uff0cMesoNet\u5728OpenForensic\u6570\u636e\u96c6\u4e0a\uff0c\u572880%\u7684\u7a00\u758f\u5ea6\u4e0b\u4ecd\u80fd\u4fdd\u630156.2%\u7684\u51c6\u786e\u7387\uff0c\u4ec5\u4f7f\u75283000\u4e2a\u53c2\u6570\uff0c\u8fd9\u63a5\u8fd1\u5176\u57fa\u7ebf\u51c6\u786e\u7387\uff0862.6%\uff09\u3002\u63d0\u51fa\u7684\u57fa\u4e8eLTH\u7684\u8fed\u4ee3\u526a\u679d\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u5355\u6b21\u526a\u679d\u65b9\u6cd5\u3002\u53ef\u89c6\u5316\u5206\u6790\u8868\u660e\uff0c\u526a\u679d\u7f51\u7edc\u80fd\u591f\u5173\u6ce8\u5173\u952e\u9762\u90e8\u533a\u57df\u3002\u6b64\u5916\uff0c\u201c\u4e2d\u5956\u5f69\u7968\u201d\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e4b\u95f4\u8868\u73b0\u51fa\u53ef\u8f6c\u79fb\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7f51\u7edc\u5305\u542b\u201c\u4e2d\u5956\u5f69\u7968\u201d\uff0c\u5373\u5b50\u7f51\u7edc\uff0c\u5373\u4f7f\u5728\u9ad8\u5ea6\u7a00\u758f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u6027\u80fd\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8eLTH\u7684\u8fed\u4ee3\u526a\u679d\u65b9\u6cd5\u4f18\u4e8e\u5355\u6b21\u526a\u679d\u65b9\u6cd5\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u526a\u679d\u7f51\u7edc\u80fd\u591f\u5173\u6ce8\u5173\u952e\u9762\u90e8\u533a\u57df\u8fdb\u884c\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e4b\u95f4\u8f6c\u79fb\u201c\u4e2d\u5956\u5f69\u7968\u201d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15784", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15784", "abs": "https://arxiv.org/abs/2507.15784", "authors": ["Zihang Ma", "Qitian Yin"], "title": "Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets", "comment": null, "summary": "Graph node classification is a fundamental task in graph neural networks\n(GNNs), aiming to assign predefined class labels to nodes. On the PubMed\ncitation network dataset, we observe significant classification difficulty\ndisparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,\n7.5% lower than Category 1. To address this, we propose a\nWasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),\ntraining specialized GNN models for Categories 0/1 (with layer normalization\nand residual connections) and Multi-hop Graph Attention Networks (GAT) for\nCategory 2. The WR distance metric optimizes representation similarity between\nmodels, particularly focusing on improving Category 2 performance. Our adaptive\nfusion strategy dynamically weights models based on category-specific\nperformance, with Category 2 assigned a GAT weight of 0.8. WR distance further\nguides the fusion process by measuring distributional differences between model\nrepresentations, enabling more principled integration of complementary\nfeatures.\n  Experimental results show WR-EFM achieves balanced accuracy across\ncategories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),\noutperforming both single models and standard fusion approaches. The\ncoefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%\nlower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM\nimproves Category 2 accuracy by 5.5% compared to GCN, verifying the\neffectiveness of WR-guided fusion in capturing complex structural patterns.\nThis work provides a novel paradigm for handling class-imbalanced graph\nclassification tasks. To promote the research community, we release our project\nat https://github.com/s010m00n/GASEM4NC.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3GNN\u8282\u70b9\u5206\u7c7b\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86WR-EFM\u6a21\u578b\uff0c\u901a\u8fc7WR\u8ddd\u79bb\u4f18\u5316\u6a21\u578b\u8868\u793a\u76f8\u4f3c\u6027\u548c\u6307\u5bfc\u81ea\u9002\u5e94\u878d\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7c7b\u522b2\u7684\u6027\u80fd\u5e76\u5b9e\u73b0\u4e86\u8de8\u7c7b\u522b\u7684\u5747\u8861\u51c6\u786e\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u56fe\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u5728GNN\u4e2d\u662f\u57fa\u7840\u6027\u7684\uff0c\u4f46\u5728PubMed\u6570\u636e\u96c6\u4e0a\u89c2\u5bdf\u5230\u660e\u663e\u7684\u5206\u7c7b\u96be\u5ea6\u5dee\u5f02\uff0c\u7279\u522b\u662f\u7c7b\u522b2\u7684\u51c6\u786e\u7387\u6bd4\u7c7b\u522b1\u4f4e7.5%\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u79cd\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6027\u80fd\u5dee\u5f02\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u5347\u8868\u73b0\u4e0d\u4f73\u7c7b\u522b\u5e76\u5b9e\u73b0\u8de8\u7c7b\u522b\u5747\u8861\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Wasserstein-Rubinstein\uff08WR\uff09\u8ddd\u79bb\u548c\u4e13\u5bb6\u878d\u5408\uff08EFM\uff09\u7684\u6a21\u578b\uff08WR-EFM\uff09\u3002\u8be5\u6a21\u578b\u4e3a\u7c7b\u522b0/1\u8bad\u7ec3\u4e86\u5177\u6709\u5c42\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\u7684GNN\u6a21\u578b\uff0c\u4e3a\u7c7b\u522b2\u8bad\u7ec3\u4e86\u591a\u8df3\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u6a21\u578b\u3002WR\u8ddd\u79bb\u7528\u4e8e\u4f18\u5316\u6a21\u578b\u95f4\u7684\u8868\u793a\u76f8\u4f3c\u6027\uff0c\u7279\u522b\u662f\u63d0\u5347\u7c7b\u522b2\u7684\u6027\u80fd\u3002\u6a21\u578b\u8fd8\u91c7\u7528\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u878d\u5408\u7b56\u7565\uff0c\u6839\u636e\u7c7b\u522b\u7279\u5b9a\u6027\u80fd\u52a8\u6001\u52a0\u6743\u6a21\u578b\uff0c\u5e76\u5229\u7528WR\u8ddd\u79bb\u6307\u5bfc\u878d\u5408\u8fc7\u7a0b\uff0c\u4ee5\u6574\u5408\u4e92\u8865\u7279\u5f81\u3002", "result": "WR-EFM\u5728PubMed\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u8de8\u7c7b\u522b\u7684\u5747\u8861\u51c6\u786e\u7387\uff1a\u7c7b\u522b0\u4e3a77.8%\uff0c\u7c7b\u522b1\u4e3a78.0%\uff0c\u7c7b\u522b2\u4e3a79.9%\u3002\u5176\u51c6\u786e\u7387\u7684\u53d8\u5f02\u7cfb\u6570\uff08CV\uff09\u4e3a0.013\uff0c\u6bd4GCN\u76840.058\u4f4e77.6%\uff0c\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002\u4e0eGCN\u76f8\u6bd4\uff0cWR-EFM\u5c06\u7c7b\u522b2\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e865.5%\uff0c\u9a8c\u8bc1\u4e86WR\u8ddd\u79bb\u6307\u5bfc\u878d\u5408\u5728\u6355\u6349\u590d\u6742\u7ed3\u6784\u6a21\u5f0f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eWasserstein-Rubinstein\uff08WR\uff09\u8ddd\u79bb\u7684\u4e13\u5bb6\u878d\u5408\u6a21\u578b\uff08WR-EFM\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u4e2d\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cWR-EFM\u5728PubMed\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u8de8\u7c7b\u522b\u7684\u5747\u8861\u51c6\u786e\u7387\uff0c\u7279\u522b\u662f\u5c06\u7c7b\u522b2\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e865.5%\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u51c6\u786e\u7387\u7684\u53d8\u5f02\u7cfb\u6570\uff0c\u8bc1\u660e\u4e86\u5176\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\u3002\u8be5\u6a21\u578b\u4e3a\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u56fe\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.15652", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15652", "abs": "https://arxiv.org/abs/2507.15652", "authors": ["Haoran Zhou", "Zihan Zhang", "Hao Chen"], "title": "Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have made significant strides by\ncombining visual recognition and language understanding to generate content\nthat is both coherent and contextually accurate. However, MLLMs continue to\nstruggle with object hallucinations, where models produce seemingly plausible\nbut factually incorrect outputs, including objects that do not exist in the\nimage. Recent work has revealed that the prior knowledge in MLLMs significantly\nsuppresses visual information in deep layers, causing hallucinatory outputs.\nHowever, how these priors suppress visual information at the intermediate layer\nstage in MLLMs remains unclear. We observe that visual factual knowledge and\nthe differences between intermediate-layer prior/original probability\ndistributions show similar evolutionary trends in intermediate layers.\nMotivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a\nsimple, training-free method that dynamically selects intermediate layers with\nthe most significant visual factual information. By contrasting the output\ndistributions of the selected layer derived from the original input and\npure-text input, EVA extracts visual factual knowledge and proportionally\nincorporates it into the final layer to correct the output logits. Importantly,\nEVA is model-agnostic, seamlessly integrates with various classic decoding\nstrategies, and is applicable across different MLLMs. We validate EVA on\nwidely-used benchmarks, and the results show that it significantly reduces\nhallucination rates compared to baseline methods, underscoring its\neffectiveness in mitigating hallucinations.", "AI": {"tldr": "EVA\u901a\u8fc7\u63d0\u53d6\u4e2d\u95f4\u5c42\u7684\u89c6\u89c9\u4e8b\u5b9e\u77e5\u8bc6\u6765\u51cf\u5c11MLLMs\u7684\u5e7b\u89c9\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3MLLMs\u5728\u7269\u4f53\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5373\u6a21\u578b\u4f1a\u751f\u6210\u5305\u542b\u56fe\u50cf\u4e2d\u4e0d\u5b58\u5728\u7684\u7269\u4f53\u7684\u4f3c\u662f\u800c\u975e\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u5185\u5bb9\u3002\u73b0\u6709\u7814\u7a76\u53d1\u73b0MLLMs\u7684\u5148\u9a8c\u77e5\u8bc6\u4f1a\u6291\u5236\u6df1\u5ea6\u5c42\u4e2d\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u4f46\u4e2d\u95f4\u5c42\u5982\u4f55\u6291\u5236\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "EVA\uff08Decoding by Extracting Visual Facts\uff09\u901a\u8fc7\u5bf9\u6bd4\u4e2d\u95f4\u5c42\u4ece\u539f\u59cb\u8f93\u5165\u548c\u7eaf\u6587\u672c\u8f93\u5165\u4e2d\u63d0\u53d6\u89c6\u89c9\u4e8b\u5b9e\u77e5\u8bc6\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u6700\u7ec8\u5c42\u4ee5\u7ea0\u6b63\u8f93\u51falogits\u3002", "result": "EVA\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5e7b\u89c9\u7387\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5e7b\u89c9\u95ee\u9898\u3002", "conclusion": "EVA\u662f\u4e00\u79cd\u7b80\u5355\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5177\u6709\u6700\u663e\u8457\u89c6\u89c9\u4e8b\u5b9e\u4fe1\u606f\u7684\u4e2d\u95f4\u5c42\uff0c\u5e76\u5bf9\u6bd4\u5176\u4e0e\u7eaf\u6587\u672c\u8f93\u5165\u8f93\u51fa\u5206\u5e03\u7684\u5dee\u5f02\uff0c\u4ece\u800c\u63d0\u53d6\u89c6\u89c9\u4e8b\u5b9e\u77e5\u8bc6\u5e76\u5c06\u5176\u6309\u6bd4\u4f8b\u6574\u5408\u5230\u6700\u7ec8\u5c42\u4ee5\u7ea0\u6b63\u8f93\u51falogits\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\u3002"}}
{"id": "2507.15655", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15655", "abs": "https://arxiv.org/abs/2507.15655", "authors": ["Aniket Pal", "Ajoy Mondal", "Minesh Mathew", "C. V. Jawahar"], "title": "HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark", "comment": "This is a minor revision of the original paper submitted to IJDAR", "summary": "The proliferation of MultiLingual Visual Question Answering (MLVQA)\nbenchmarks augments the capabilities of large language models (LLMs) and\nmulti-modal LLMs, thereby enabling them to adeptly capture the intricate\nlinguistic subtleties and visual complexities inherent across diverse\nlanguages. Despite its potential, the current MLVQA model struggles to fully\nutilize its capabilities when dealing with the extensive variety of handwritten\ndocuments. This article delineates HW-MLVQA, an avant-garde VQA benchmark\nmeticulously crafted to mitigate the dearth of authentic Multilingual\nHandwritten document comprehension. HW-MLVQA encompasses an extensive\ncollection of 1,600 handwritten Pages complemented by 2,400 question-answers.\nFurthermore, it provides a robust benchmark evaluation framework spanning three\ndistinct modalities: text, image, and an integrated image & text modality. To\nsimulate authentic real-world contexts devoid of ground truth textual\ntranscriptions, we facilitates a rigorous assessment of proprietary and\nopen-source OCR models. The benchmark aspires to facilitate pivotal\nadvancements in multilingual handwritten document interpretation, fostering\ninnovation and scholarly inquiry within this specialized domain.", "AI": {"tldr": "\u63d0\u51faHW-MLVQA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u89e3\u51b3\u591a\u8bed\u8a00\u624b\u5199\u6587\u6863\u7406\u89e3\u7684\u4e0d\u8db3\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5305\u542b\u5927\u91cf\u624b\u5199\u6570\u636e\u548c\u95ee\u7b54\u5bf9\uff0c\u5e76\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u53ca\u56fe\u6587\u7ed3\u5408\u7684\u8bc4\u4f30\u6a21\u5f0f\uff0c\u540c\u65f6\u53ef\u7528\u4e8e\u8bc4\u4f30OCR\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u591a\u8bed\u8a00\u89c6\u89c9\u95ee\u7b54\uff08MLVQA\uff09\u57fa\u51c6\u6d4b\u8bd5\u7684\u80fd\u529b\u4e0d\u65ad\u589e\u5f3a\uff0c\u4f46\u5f53\u524dMLVQA\u6a21\u578b\u5728\u5904\u7406\u591a\u6837\u5316\u7684\u624b\u5199\u6587\u6863\u65f6\u4ecd\u96be\u4ee5\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u771f\u5b9e\u591a\u8bed\u8a00\u624b\u5199\u6587\u6863\u7406\u89e3\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86HW-MLVQA\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHW-MLVQA\u7684\u65b0\u578bVQA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d\u5305\u542b1600\u4e2a\u624b\u5199\u9875\u9762\u548c2400\u4e2a\u95ee\u7b54\u5bf9\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6db5\u76d6\u6587\u672c\u3001\u56fe\u50cf\u4ee5\u53ca\u56fe\u50cf\u4e0e\u6587\u672c\u96c6\u6210\u4e09\u79cd\u6a21\u5f0f\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u4e3a\u4e86\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u4e2d\u7f3a\u4e4f\u5730\u9762\u771f\u5b9e\u6587\u672c\u8f6c\u5f55\u7684\u60c5\u51b5\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u8fd8\u652f\u6301\u5bf9\u4e13\u6709\u548c\u5f00\u6e90OCR\u6a21\u578b\u7684\u8bc4\u4f30\u3002", "result": "HW-MLVQA\u57fa\u51c6\u6d4b\u8bd5\u5305\u542b\u4e86\u5927\u91cf\u7684\u624b\u5199\u6587\u6863\u548c\u95ee\u7b54\u5bf9\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u6a21\u6001\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u5bf9OCR\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0c\u4ece\u800c\u4fc3\u8fdb\u591a\u8bed\u8a00\u624b\u5199\u6587\u6863\u89e3\u6790\u9886\u57df\u7684\u53d1\u5c55\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u65e8\u5728\u4fc3\u8fdb\u591a\u8bed\u8a00\u624b\u5199\u6587\u6863\u89e3\u6790\u9886\u57df\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u6fc0\u53d1\u8be5\u4e13\u4e1a\u9886\u57df\u7684\u521b\u65b0\u548c\u5b66\u672f\u63a2\u7a76\u3002"}}
{"id": "2507.15680", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15680", "abs": "https://arxiv.org/abs/2507.15680", "authors": ["Yongkang Hou", "Jiarun Song"], "title": "Visual-Language Model Knowledge Distillation Method for Image Quality Assessment", "comment": null, "summary": "Image Quality Assessment (IQA) is a core task in computer vision. Multimodal\nmethods based on vision-language models, such as CLIP, have demonstrated\nexceptional generalization capabilities in IQA tasks. To address the issues of\nexcessive parameter burden and insufficient ability to identify local distorted\nfeatures in CLIP for IQA, this study proposes a visual-language model knowledge\ndistillation method aimed at guiding the training of models with architectural\nadvantages using CLIP's IQA knowledge. First, quality-graded prompt templates\nwere designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned\nto enhance its capabilities in IQA tasks. Finally, a modality-adaptive\nknowledge distillation strategy is proposed to achieve guidance from the CLIP\nteacher model to the student model. Our experiments were conducted on multiple\nIQA datasets, and the results show that the proposed method significantly\nreduces model complexity while outperforming existing IQA methods,\ndemonstrating strong potential for practical deployment.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u5229\u7528CLIP\u7684IQA\u80fd\u529b\u6765\u8bad\u7ec3\u66f4\u9ad8\u6548\u3001\u6027\u80fd\u66f4\u4f18\u7684\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3CLIP\u5728IQA\u4efb\u52a1\u4e2d\u5b58\u5728\u7684\u53c2\u6570\u8d1f\u62c5\u8fc7\u91cd\u4ee5\u53ca\u8bc6\u522b\u5c40\u90e8\u5931\u771f\u7279\u5f81\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u5229\u7528CLIP\u7684\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\uff08IQA\uff09\u77e5\u8bc6\u6765\u6307\u5bfc\u5177\u6709\u67b6\u6784\u4f18\u52bf\u7684\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u9996\u5148\uff0c\u8bbe\u8ba1\u4e86\u8d28\u91cf\u5206\u7ea7\u63d0\u793a\u6a21\u677f\u6765\u5f15\u5bfcCLIP\u8f93\u51fa\u8d28\u91cf\u5206\u6570\u3002\u7136\u540e\uff0c\u5bf9CLIP\u8fdb\u884c\u5fae\u8c03\u4ee5\u589e\u5f3a\u5176\u5728IQA\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u6001\u81ea\u9002\u5e94\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u4eceCLIP\u6559\u5e08\u6a21\u578b\u5230\u5b66\u751f\u6a21\u578b\u7684\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u5728\u591a\u4e2aIQA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u590d\u6742\u6027\uff0c\u5e76\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7684IQA\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u590d\u6742\u6027\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u65b9\u9762\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15832", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15832", "abs": "https://arxiv.org/abs/2507.15832", "authors": ["Shiyang Li"], "title": "Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction", "comment": "in Chinese language", "summary": "To address the limitations of medium- and long-term four-dimensional (4D)\ntrajectory prediction models, this paper proposes a hybrid\nCNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy\nimproved snake-herd optimization (SO) algorithm. The model applies the Adaboost\nalgorithm to divide multiple weak learners, and each submodel utilizes CNN to\nextract spatial features, LSTM to capture temporal features, and attention\nmechanism to capture global features comprehensively. The strong learner model,\ncombined with multiple sub-models, then optimizes the hyperparameters of the\nprediction model through the natural selection behavior pattern simulated by\nSO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the\ncomparison experiments and ablation studies of multiple optimizers are carried\nout, and a comprehensive test and evaluation analysis is carried out. The\nresults show that SO-CLA-adaboost outperforms traditional optimizers such as\nparticle swarm, whale, and gray wolf in handling large-scale high-dimensional\ntrajectory data. In addition, introducing the full-strategy collaborative\nimprovement SO algorithm improves the model's prediction accuracy by 39.89%.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408CNN\u3001LSTM\u3001\u6ce8\u610f\u529b\u673a\u5236\u548cAdaboost\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u6539\u8fdb\u7684\u86c7\u7fa4\uff08SO\uff09\u7b97\u6cd5\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u4e2d\u957f\u671f\u56db\u7ef4\u8f68\u8ff9\u9884\u6d4b\u7684\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u5668\uff0c\u9884\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e2d\u957f\u671f\u56db\u7ef4\uff084D\uff09\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408CNN-LSTM-attention-adaboost\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u4e86\u591a\u7b56\u7565\u6539\u8fdb\u7684\u86c7\u7fa4\uff08SO\uff09\u4f18\u5316\u7b97\u6cd5\u3002\u8be5\u6a21\u578b\u4f7f\u7528Adaboost\u7b97\u6cd5\u5212\u5206\u591a\u4e2a\u5f31\u5b66\u4e60\u5668\uff0c\u6bcf\u4e2a\u5b50\u6a21\u578b\u5229\u7528CNN\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff0cLSTM\u6355\u83b7\u65f6\u95f4\u7279\u5f81\uff0c\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5168\u5c40\u7279\u5f81\u3002\u5f3a\u5b66\u4e60\u5668\u6a21\u578b\u4e0e\u591a\u4e2a\u5b50\u6a21\u578b\u7ed3\u5408\uff0c\u901a\u8fc7SO\u6a21\u62df\u7684\u81ea\u7136\u9009\u62e9\u884c\u4e3a\u6a21\u5f0f\u4f18\u5316\u9884\u6d4b\u6a21\u578b\u7684\u8d85\u53c2\u6570\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u4f18\u5316\u5668\uff08\u5982\u7c92\u5b50\u7fa4\u3001\u9cb8\u9c7c\u548c\u7070\u72fc\uff09\u76f8\u6bd4\uff0cSO-CLA-adaboost\u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u9884\u6d4b\u7cbe\u5ea6\u63d0\u9ad8\u4e8639.89%\u3002", "conclusion": "SO-CLA-adaboost \u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u7c92\u5b50\u7fa4\u3001\u9cb8\u9c7c\u548c\u7070\u72fc\u4f18\u5316\u5668\uff0c\u5e76\u4e14\u901a\u8fc7\u6539\u8fdb\u7684SO\u7b97\u6cd5\uff0c\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u63d0\u9ad8\u4e8639.89%\u3002"}}
{"id": "2507.15683", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15683", "abs": "https://arxiv.org/abs/2507.15683", "authors": ["Boni Hu", "Zhenyu Xia", "Lin Chen", "Pengcheng Han", "Shuhui Bu"], "title": "Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing", "comment": "17 pages, 11 figures", "summary": "Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera\npose from query images, is fundamental to remote sensing and UAV applications.\nExisting methods face inherent trade-offs: image-based retrieval and pose\nregression approaches lack precision, while structure-based methods that\nregister queries to Structure-from-Motion (SfM) models suffer from\ncomputational complexity and limited scalability. These challenges are\nparticularly pronounced in remote sensing scenarios due to large-scale scenes,\nhigh altitude variations, and domain gaps of existing visual priors. To\novercome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel\nscene representation that compactly encodes both 3D geometry and appearance. We\nintroduce $\\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework\nthat follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting\nthe rich semantic information and geometric constraints inherent in Gaussian\nprimitives. To handle large-scale remote sensing scenarios, we incorporate\npartitioned Gaussian training, GPU-accelerated parallel matching, and dynamic\nmemory management strategies. Our approach consists of two stages: (1) a sparse\nstage featuring a Gaussian-specific consistent render-aware sampling strategy\nand landmark-guided detector for robust and accurate initial pose estimation,\nand (2) a dense stage that iteratively refines poses through coarse-to-fine\ndense rasterization matching while incorporating reliability verification.\nThrough comprehensive evaluation on simulation data, public datasets, and real\nflight experiments, we demonstrate that our method delivers competitive\nlocalization accuracy, recall rate, and computational efficiency while\neffectively filtering unreliable pose estimates. The results confirm the\neffectiveness of our approach for practical remote sensing applications.", "AI": {"tldr": "Hi2-GSLoc\u662f\u4e00\u79cd\u5229\u75283D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u8fdb\u884c\u89c6\u89c9\u91cd\u5b9a\u4f4d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u5230\u5bc6\u96c6\u3001\u7c97\u7cd9\u5230\u7cbe\u7ec6\u7684\u53cc\u5c42\u7ea7\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u5728\u9065\u611f\u573a\u666f\u4e0b\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u91cd\u5b9a\u4f4d\u65b9\u6cd5\u5728\u7cbe\u5ea6\u3001\u8ba1\u7b97\u590d\u6742\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u6743\u8861\uff0c\u5c24\u5176\u662f\u5728\u9065\u611f\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u5927\u5c3a\u5ea6\u573a\u666f\u3001\u9ad8\u6d77\u62d4\u53d8\u5316\u548c\u89c6\u89c9\u5148\u9a8c\u7684\u57df\u95f4\u9699\uff0c\u8fd9\u4e9b\u6311\u6218\u5c24\u4e3a\u7a81\u51fa\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u7814\u7a76\u8005\u5229\u75283D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u573a\u666f\u8868\u793a\u3002", "method": "Hi2-GSLoc\u6846\u67b6\u91c7\u7528\u53cc\u5c42\u7ea7\u7a00\u758f\u5230\u5bc6\u96c6\u3001\u7c97\u7cd9\u5230\u7cbe\u7ec6\u7684\u8303\u5f0f\uff0c\u5e76\u5229\u75283D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u4f5c\u4e3a\u65b0\u9896\u7684\u573a\u666f\u8868\u793a\u3002\u5b83\u5305\u542b\u4e00\u4e2a\u7a00\u758f\u9636\u6bb5\uff08\u9ad8\u65af\u7279\u5b9a\u7684\u3001\u4e00\u81f4\u7684\u3001\u6e32\u67d3\u611f\u77e5\u7684\u91c7\u6837\u7b56\u7565\u548c\u57fa\u4e8e\u5730\u6807\u7684\u68c0\u6d4b\u5668\uff09\u548c\u4e00\u4e2a\u5bc6\u96c6\u9636\u6bb5\uff08\u901a\u8fc7\u7c97\u7cd9\u5230\u7cbe\u7ec6\u7684\u5bc6\u96c6\u5149\u6805\u5316\u5339\u914d\u548c\u53ef\u9760\u6027\u9a8c\u8bc1\u6765\u8fed\u4ee3\u5730\u4f18\u5316\u4f4d\u59ff\uff09\u3002\u4e3a\u4e86\u5904\u7406\u5927\u89c4\u6a21\u9065\u611f\u573a\u666f\uff0c\u91c7\u7528\u4e86\u5206\u533a\u9ad8\u65af\u8bad\u7ec3\u3001GPU\u52a0\u901f\u7684\u5e76\u884c\u5339\u914d\u548c\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u7b56\u7565\u3002", "result": "Hi2-GSLoc\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u80fd\u6709\u6548\u8fc7\u6ee4\u4e0d\u53ef\u9760\u7684\u4f4d\u59ff\u4f30\u8ba1\u3002", "conclusion": "Hi2-GSLoc\u5728\u6a21\u62df\u6570\u636e\u3001\u516c\u5f00\u6570\u636e\u96c6\u548c\u771f\u5b9e\u98de\u884c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u5177\u6709\u7ade\u4e89\u529b\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u80fd\u6709\u6548\u8fc7\u6ee4\u4e0d\u53ef\u9760\u7684\u4f4d\u59ff\u4f30\u8ba1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u9065\u611f\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15836", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.15836", "abs": "https://arxiv.org/abs/2507.15836", "authors": ["Matteo Boglioni", "Terrance Liu", "Andrew Ilyas", "Zhiwei Steven Wu"], "title": "Optimizing Canaries for Privacy Auditing with Metagradient Descent", "comment": null, "summary": "In this work we study black-box privacy auditing, where the goal is to lower\nbound the privacy parameter of a differentially private learning algorithm\nusing only the algorithm's outputs (i.e., final trained model). For DP-SGD (the\nmost successful method for training differentially private deep learning\nmodels), the canonical approach auditing uses membership inference-an auditor\ncomes with a small set of special \"canary\" examples, inserts a random subset of\nthem into the training set, and then tries to discern which of their canaries\nwere included in the training set (typically via a membership inference\nattack). The auditor's success rate then provides a lower bound on the privacy\nparameters of the learning algorithm. Our main contribution is a method for\noptimizing the auditor's canary set to improve privacy auditing, leveraging\nrecent work on metagradient optimization. Our empirical evaluation demonstrates\nthat by using such optimized canaries, we can improve empirical lower bounds\nfor differentially private image classification models by over 2x in certain\ninstances. Furthermore, we demonstrate that our method is transferable and\nefficient: canaries optimized for non-private SGD with a small model\narchitecture remain effective when auditing larger models trained with DP-SGD.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u4f18\u5316\u201c\u91d1\u4e1d\u96c0\u201d\u6570\u636e\u96c6\u6765\u63d0\u9ad8\u9ed1\u76d2\u9690\u79c1\u5ba1\u8ba1\uff08\u5982\u4e0b\u9650\u5dee\u5206\u9690\u79c1\u53c2\u6570\uff09\u7684\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u53ef\u5c06\u9690\u79c1\u5ba1\u8ba1\u7684\u4e0b\u9650\u63d0\u9ad82\u500d\u4ee5\u4e0a\uff0c\u4e14\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u8f6c\u79fb\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u5728\u4ec5\u80fd\u83b7\u53d6\u5b66\u4e60\u7b97\u6cd5\u8f93\u51fa\u7684\u60c5\u51b5\u4e0b\uff0c\u964d\u4f4e\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u7b97\u6cd5\u7684\u9690\u79c1\u53c2\u6570\u7684\u4e0b\u9650\u3002", "method": "\u5229\u7528\u5143\u68af\u5ea6\u4f18\u5316\u6765\u9009\u62e9\u201c\u91d1\u4e1d\u96c0\u201d\u6570\u636e\u96c6\uff0c\u4ee5\u63d0\u9ad8\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u7b97\u6cd5\u7684\u9690\u79c1\u5ba1\u8ba1\u6548\u679c\u3002", "result": "\u901a\u8fc7\u4f18\u5316\u201c\u91d1\u4e1d\u96c0\u201d\u6570\u636e\u96c6\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5c06\u5dee\u5206\u9690\u79c1\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u7684\u7ecf\u9a8c\u4e0b\u9650\u63d0\u9ad8\u4e862\u500d\u4ee5\u4e0a\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u5bf9\u4e8e\u4e0d\u540c\u7684\u6a21\u578b\u548c\u8bad\u7ec3\u5668\uff08\u975e\u9690\u79c1SGD\u548cDP-SGD\uff09\u90fd\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u4f18\u5316\u7528\u4e8e\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u7b97\u6cd5\u7684\u201c\u91d1\u4e1d\u96c0\u201d\u6570\u636e\u96c6\u53ef\u4ee5\u63d0\u9ad8\u9690\u79c1\u5ba1\u8ba1\u7684\u4e0b\u9650\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u8f6c\u79fb\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.15686", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15686", "abs": "https://arxiv.org/abs/2507.15686", "authors": ["Wenjie Huang", "Qi Yang", "Shuting Xia", "He Huang", "Zhu Li", "Yiling Xu"], "title": "LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression", "comment": "Accepted to ICCV 2025", "summary": "Existing AI-based point cloud compression methods struggle with dependence on\nspecific training data distributions, which limits their real-world deployment.\nImplicit Neural Representation (INR) methods solve the above problem by\nencoding overfitted network parameters to the bitstream, resulting in more\ndistribution-agnostic results. However, due to the limitation of encoding time\nand decoder size, current INR based methods only consider lossy geometry\ncompression. In this paper, we propose the first INR based lossless point cloud\ngeometry compression method called Lossless Implicit Neural Representations for\nPoint Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we\ndesign a group of point clouds level coding framework with an effective network\ninitialization strategy, which can reduce around 60% encoding time. A\nlightweight coding network based on multiscale SparseConv, consisting of scale\ncontext extraction, child node prediction, and model compression modules, is\nproposed to realize fast inference and compact decoder size. Experimental\nresults show that our method consistently outperforms traditional and AI-based\nmethods: for example, with the convergence time in the MVUB dataset, our method\nreduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and\n21.95% compared to SparsePCGC. Our project can be seen on\nhttps://huangwenjie2023.github.io/LINR-PCGC/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLINR-PCGC\u7684\u65e0\u635f\u70b9\u4e91\u51e0\u4f55\u538b\u7f29\u65b9\u6cd5\uff0c\u5b83\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff0c\u901a\u8fc7\u5206\u5c42\u7f16\u7801\u548c\u8f7b\u91cf\u7ea7\u7f51\u7edc\u8bbe\u8ba1\uff0c\u5728\u4fdd\u8bc1\u65e0\u635f\u538b\u7f29\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7f16\u7801\u901f\u5ea6\u5e76\u51cf\u5c0f\u4e86\u6a21\u578b\u5927\u5c0f\uff0c\u4e14\u538b\u7f29\u7387\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684AI\u70b9\u4e91\u538b\u7f29\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u53d7\u6570\u636e\u5206\u5e03\u9650\u5236\uff0c\u800c\u57fa\u4e8eINR\u7684\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u66f4\u5177\u5206\u5e03\u65e0\u5173\u6027\u7684\u7ed3\u679c\uff0c\u4f46\u73b0\u6709INR\u65b9\u6cd5\u4ec5\u9650\u4e8e\u6709\u635f\u538b\u7f29\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u57fa\u4e8eINR\u7684\u65e0\u635f\u70b9\u4e91\u51e0\u4f55\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INR\uff09\u7684\u65e0\u635f\u70b9\u4e91\u51e0\u4f55\u538b\u7f29\u65b9\u6cd5\uff08LINR-PCGC\uff09\u3002\u8be5\u65b9\u6cd5\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u70b9\u4e91\u5206\u5c42\u7f16\u7801\u6846\u67b6\u548c\u4e00\u79cd\u6709\u6548\u7684\u7f51\u7edc\u521d\u59cb\u5316\u7b56\u7565\u6765\u52a0\u901f\u7f16\u7801\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u591a\u5c3a\u5ea6\u7a00\u758f\u5377\u79ef\uff08SparseConv\uff09\u7684\u8f7b\u91cf\u7ea7\u7f16\u7801\u7f51\u7edc\uff08\u5305\u542b\u5c3a\u5ea6\u4e0a\u4e0b\u6587\u63d0\u53d6\u3001\u5b50\u8282\u70b9\u9884\u6d4b\u548c\u6a21\u578b\u538b\u7f29\u6a21\u5757\uff09\u6765\u5b9e\u73b0\u5feb\u901f\u63a8\u7406\u548c\u7d27\u51d1\u7684\u89e3\u7801\u5668\u5c3a\u5bf8\u3002", "result": "\u5728MVUB\u6570\u636e\u96c6\u4e0a\uff0cLINR-PCGC\u76f8\u6bd4G-PCC TMC13v23\u7684\u6bd4\u7279\u6d41\u51cf\u5c11\u4e86\u7ea621.21%\uff0c\u76f8\u6bd4SparsePCGC\u51cf\u5c11\u4e86\u7ea621.95%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LINR-PCGC\u65b9\u6cd5\u662f\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u7684\u65e0\u635f\u70b9\u4e91\u51e0\u4f55\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u7f16\u7801\u901f\u5ea6\u548c\u89e3\u7801\u5668\u5927\u5c0f\u65b9\u9762\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u4e14\u5728\u538b\u7f29\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u548c\u73b0\u6709\u7684AI\u65b9\u6cd5\u3002"}}
{"id": "2507.15839", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15839", "abs": "https://arxiv.org/abs/2507.15839", "authors": ["Anh Nguyen", "Sam Schafft", "Nicholas Hale", "John Alfaro"], "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs", "comment": null, "summary": "Synthetic data generation has emerged as an invaluable solution in scenarios\nwhere real-world data collection and usage are limited by cost and scarcity.\nLarge language models (LLMs) have demonstrated remarkable capabilities in\nproducing high-fidelity, domain-relevant samples across various fields.\nHowever, existing approaches that directly use LLMs to generate each record\nindividually impose prohibitive time and cost burdens, particularly when large\nvolumes of synthetic data are required. In this work, we propose a fast,\ncost-effective method for realistic tabular data synthesis that leverages LLMs\nto infer and encode each field's distribution into a reusable sampling script.\nBy automatically classifying fields into numerical, categorical, or free-text\ntypes, the LLM generates distribution-based scripts that can efficiently\nproduce diverse, realistic datasets at scale without continuous model\ninference. Experimental results show that our approach outperforms traditional\ndirect methods in both diversity and data realism, substantially reducing the\nburden of high-volume synthetic data generation. We plan to apply this\nmethodology to accelerate testing in production pipelines, thereby shortening\ndevelopment cycles and improving overall system efficiency. We believe our\ninsights and lessons learned will aid researchers and practitioners seeking\nscalable, cost-effective solutions for synthetic data generation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5feb\u901f\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u8868\u683c\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff0c\u5229\u7528LLM\u5c06\u5b57\u6bb5\u5206\u5e03\u7f16\u7801\u4e3a\u53ef\u91cd\u7528\u7684\u91c7\u6837\u811a\u672c\uff0c\u4ee5\u7ecf\u6d4e\u9ad8\u6548\u5730\u5927\u89c4\u6a21\u751f\u6210\u591a\u6837\u5316\u3001\u771f\u5b9e\u7684\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528LLM\u5355\u72ec\u751f\u6210\u6bcf\u4e2a\u8bb0\u5f55\uff0c\u5728\u9700\u8981\u5927\u91cf\u5408\u6210\u6570\u636e\u65f6\u4f1a\u5e26\u6765\u9ad8\u6602\u7684\u65f6\u95f4\u548c\u6210\u672c\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5c06\u5b57\u6bb5\u5206\u7c7b\u4e3a\u6570\u503c\u3001\u5206\u7c7b\u6216\u81ea\u7531\u6587\u672c\u7c7b\u578b\uff0c\u5229\u7528LLM\u751f\u6210\u57fa\u4e8e\u5206\u5e03\u7684\u811a\u672c\uff0c\u4ece\u800c\u9ad8\u6548\u5730\u5927\u89c4\u6a21\u751f\u6210\u591a\u6837\u5316\u3001\u771f\u5b9e\u7684\u6570\u636e\u96c6\uff0c\u800c\u65e0\u9700\u6301\u7eed\u7684\u6a21\u578b\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u6570\u636e\u771f\u5b9e\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u76f4\u63a5\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u9ad8\u5bb9\u91cf\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u8d1f\u62c5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u6570\u636e\u771f\u5b9e\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u76f4\u63a5\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u9ad8\u5bb9\u91cf\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u8d1f\u62c5\u3002"}}
{"id": "2507.15709", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15709", "abs": "https://arxiv.org/abs/2507.15709", "authors": ["Wei Sun", "Weixia Zhang", "Linhan Cao", "Jun Jia", "Xiangyang Zhu", "Dandan Zhu", "Xiongkuo Min", "Guangtao Zhai"], "title": "Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation", "comment": "Efficient-FIQA achieved first place in the ICCV VQualA 2025 Face\n  Image Quality Assessment Challenge", "summary": "Face image quality assessment (FIQA) is essential for various face-related\napplications. Although FIQA has been extensively studied and achieved\nsignificant progress, the computational complexity of FIQA algorithms remains a\nkey concern for ensuring scalability and practical deployment in real-world\nsystems. In this paper, we aim to develop a computationally efficient FIQA\nmethod that can be easily deployed in real-world applications. Specifically,\nour method consists of two stages: training a powerful teacher model and\ndistilling a lightweight student model from it. To build a strong teacher\nmodel, we adopt a self-training strategy to improve its capacity. We first\ntrain the teacher model using labeled face images, then use it to generate\npseudo-labels for a set of unlabeled images. These pseudo-labeled samples are\nused in two ways: (1) to distill knowledge into the student model, and (2) to\ncombine with the original labeled images to further enhance the teacher model\nthrough self-training. The enhanced teacher model is used to further\npseudo-label another set of unlabeled images for distilling the student models.\nThe student model is trained using a combination of labeled images,\npseudo-labeled images from the original teacher model, and pseudo-labeled\nimages from the enhanced teacher model. Experimental results demonstrate that\nour student model achieves comparable performance to the teacher model with an\nextremely low computational overhead. Moreover, our method achieved first place\nin the ICCV 2025 VQualA FIQA Challenge. The code is available at\nhttps://github.com/sunwei925/Efficient-FIQA.git.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684FIQA\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u8bad\u7ec3\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u7528\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\u5b9e\u73b0\u4e86\u4e0e\u6559\u5e08\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\uff0c\u5e76\u5728\u7ade\u8d5b\u4e2d\u593a\u51a0\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709FIQA\u7b97\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u5f71\u54cd\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u8ba1\u7b97\u6548\u7387\u9ad8\u4e14\u6613\u4e8e\u90e8\u7f72\u7684FIQA\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684FIQA\u65b9\u6cd5\uff1a\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u5f3a\u5927\u7684\u6559\u5e08\u6a21\u578b\uff08\u901a\u8fc7\u81ea\u8bad\u7ec3\u7b56\u7565\uff0c\u5229\u7528\u6807\u8bb0\u6570\u636e\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\uff0c\u7136\u540e\u7528\u751f\u6210\u7684\u4f2a\u6807\u7b7e\u6539\u8fdb\u6559\u5e08\u6a21\u578b\uff09\uff0c\u7136\u540e\u4ece\u6559\u5e08\u6a21\u578b\u84b8\u998f\u51fa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5b66\u751f\u6a21\u578b\u3002\u5b66\u751f\u6a21\u578b\u540c\u65f6\u5229\u7528\u6807\u8bb0\u6570\u636e\u3001\u539f\u59cb\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u4f2a\u6807\u7b7e\u4ee5\u53ca\u6539\u8fdb\u540e\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u4f2a\u6807\u7b7e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5b66\u751f\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u4e0e\u6559\u5e08\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\u3002\u8be5\u65b9\u6cd5\u5728ICCV 2025 VQualA FIQA\u6311\u6218\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u4eba\u8138\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\uff08FIQA\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0e\u6559\u5e08\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002\u901a\u8fc7\u7ed3\u5408\u81ea\u8bad\u7ec3\u7b56\u7565\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u6210\u529f\u8bad\u7ec3\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5b66\u751f\u6a21\u578b\uff0c\u5e76\u5728ICCV 2025 VQualA FIQA\u6311\u6218\u8d5b\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\u3002"}}
{"id": "2507.15724", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15724", "abs": "https://arxiv.org/abs/2507.15724", "authors": ["Guoxuan Xia", "Harleen Hanspal", "Petru-Daniel Tudosiu", "Shifeng Zhang", "Sarah Parisot"], "title": "A Practical Investigation of Spatially-Controlled Image Generation with Transformers", "comment": "preprint", "summary": "Enabling image generation models to be spatially controlled is an important\narea of research, empowering users to better generate images according to their\nown fine-grained specifications via e.g. edge maps, poses. Although this task\nhas seen impressive improvements in recent times, a focus on rapidly producing\nstronger models has come at the cost of detailed and fair scientific\ncomparison. Differing training data, model architectures and generation\nparadigms make it difficult to disentangle the factors contributing to\nperformance. Meanwhile, the motivations and nuances of certain approaches\nbecome lost in the literature. In this work, we aim to provide clear takeaways\nacross generation paradigms for practitioners wishing to develop\ntransformer-based systems for spatially-controlled generation, clarifying the\nliterature and addressing knowledge gaps. We perform controlled experiments on\nImageNet across diffusion-based/flow-based and autoregressive (AR) models.\nFirst, we establish control token prefilling as a simple, general and\nperformant baseline approach for transformers. We then investigate previously\nunderexplored sampling time enhancements, showing that extending\nclassifier-free guidance to control, as well as softmax truncation, have a\nstrong impact on control-generation consistency. Finally, we re-clarify the\nmotivation of adapter-based approaches, demonstrating that they mitigate\n\"forgetting\" and maintain generation quality when trained on limited downstream\ndata, but underperform full training in terms of generation-control\nconsistency. Code will be released upon publication.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u7a7a\u95f4\u63a7\u5236\u56fe\u50cf\u751f\u6210\u9886\u57df\u4e2d\u5b58\u5728\u7684\u6587\u732e\u6df7\u4e71\u548c\u77e5\u8bc6\u5dee\u8ddd\u95ee\u9898\u3002\u901a\u8fc7\u5728 ImageNet \u4e0a\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684 Transformer \u6a21\u578b\uff08\u57fa\u4e8e\u6269\u6563/\u6d41\u548c\u81ea\u56de\u5f52\uff09\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e86\u63a7\u5236\u6807\u8bb0\u9884\u586b\u5145\u3001\u91c7\u6837\u65f6\u95f4\u589e\u5f3a\uff08\u5982\u63a7\u5236\u7684\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u548c Softmax \u622a\u65ad\uff09\u4ee5\u53ca\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u63a7\u5236\u6807\u8bb0\u9884\u586b\u5145\u662f\u4e00\u79cd\u6709\u6548\u7684\u57fa\u7ebf\u65b9\u6cd5\uff1b\u91c7\u6837\u65f6\u95f4\u589e\u5f3a\u80fd\u663e\u8457\u63d0\u9ad8\u63a7\u5236-\u751f\u6210\u4e00\u81f4\u6027\uff1b\u800c\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u5728\u7279\u5b9a\u573a\u666f\u4e0b\uff08\u5982\u6570\u636e\u6709\u9650\u65f6\uff09\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u4e00\u81f4\u6027\u65b9\u9762\u4e0d\u5982\u5b8c\u5168\u8bad\u7ec3\u3002\u672c\u7814\u7a76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u6307\u5bfc\uff0c\u4ee5\u5f00\u53d1\u66f4\u4f18\u7684 Transformer \u6a21\u578b\u7528\u4e8e\u7a7a\u95f4\u63a7\u5236\u56fe\u50cf\u751f\u6210\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u5728\u7a7a\u95f4\u63a7\u5236\u56fe\u50cf\u751f\u6210\u9886\u57df\u4e2d\uff0c\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u3001\u6a21\u578b\u67b6\u6784\u548c\u751f\u6210\u8303\u5f0f\u4e0d\u540c\uff0c\u5bfc\u81f4\u96be\u4ee5\u8fdb\u884c\u8be6\u7ec6\u548c\u516c\u5e73\u7684\u79d1\u5b66\u6bd4\u8f83\u7684\u95ee\u9898\u3002\u540c\u65f6\uff0c\u4e5f\u4e3a\u4e86\u68b3\u7406\u548c\u660e\u786e\u67d0\u4e9b\u7814\u7a76\u65b9\u6cd5\u7684\u52a8\u673a\u548c\u7ec6\u8282\uff0c\u586b\u8865\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5728 ImageNet \u4e0a\u8de8\u57fa\u4e8e\u6269\u6563/\u6d41\u548c\u81ea\u56de\u5f52 (AR) \u7684\u6a21\u578b\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\u6765\u9610\u660e\u6587\u732e\u548c\u89e3\u51b3\u77e5\u8bc6\u5dee\u8ddd\u3002\u9996\u5148\uff0c\u5c06\u63a7\u5236\u6807\u8bb0\u9884\u586b\u5145\u5efa\u7acb\u4e3a Transformer \u7684\u7b80\u5355\u3001\u901a\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u7136\u540e\uff0c\u7814\u7a76\u91c7\u6837\u65f6\u95f4\u589e\u5f3a\uff0c\u4f8b\u5982\u5c06\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u6269\u5c55\u5230\u63a7\u5236\u548c Softmax \u622a\u65ad\uff0c\u4ee5\u63d0\u9ad8\u63a7\u5236-\u751f\u6210\u4e00\u81f4\u6027\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5728\u6709\u9650\u7684\u4e0b\u6e38\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u6765\u6f14\u793a\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u53ef\u4ee5\u7f13\u89e3\u201c\u9057\u5fd8\u201d\u5e76\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u53ef\u80fd\u5728\u751f\u6210-\u63a7\u5236\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u5982\u5b8c\u5168\u8bad\u7ec3\u3002", "result": "\u63a7\u5236\u6807\u8bb0\u9884\u586b\u5145\u662f\u4e00\u79cd\u7b80\u5355\u3001\u901a\u7528\u4e14\u9ad8\u6027\u80fd\u7684 Transformer \u57fa\u7ebf\u65b9\u6cd5\u3002\u5c06\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u6269\u5c55\u5230\u63a7\u5236\u4ee5\u53ca Softmax \u622a\u65ad\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u63a7\u5236-\u751f\u6210\u4e00\u81f4\u6027\u3002\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u5728\u6709\u9650\u7684\u4e0b\u6e38\u6570\u636e\u4e0a\u8bad\u7ec3\u65f6\uff0c\u53ef\u4ee5\u7f13\u89e3\u201c\u9057\u5fd8\u201d\u5e76\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u5728\u751f\u6210-\u63a7\u5236\u4e00\u81f4\u6027\u65b9\u9762\u4e0d\u5982\u5b8c\u5168\u8bad\u7ec3\u3002", "conclusion": "\u7a7a\u95f4\u63a7\u5236\u7684\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u7814\u7a76\u5f88\u91cd\u8981\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u6839\u636e\u7528\u6237\u9700\u6c42\u751f\u6210\u56fe\u50cf\u3002\u5c3d\u7ba1\u8fd1\u5e74\u6765\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u4f46\u5feb\u901f\u751f\u4ea7\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u5374\u4ee5\u727a\u7272\u8be6\u7ec6\u548c\u516c\u5e73\u7684\u79d1\u5b66\u6bd4\u8f83\u4e3a\u4ee3\u4ef7\u3002\u8bad\u7ec3\u6570\u636e\u3001\u6a21\u578b\u67b6\u6784\u548c\u751f\u6210\u8303\u5f0f\u7684\u4e0d\u540c\u4f7f\u5f97\u4eba\u4eec\u96be\u4ee5\u533a\u5206\u5f71\u54cd\u6027\u80fd\u7684\u56e0\u7d20\u3002\u540c\u65f6\uff0c\u67d0\u4e9b\u65b9\u6cd5\u7684\u52a8\u673a\u548c\u7ec6\u5fae\u5dee\u522b\u5728\u6587\u732e\u4e2d\u4e5f\u4e22\u5931\u4e86\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u5e0c\u671b\u5f00\u53d1\u57fa\u4e8e Transformer \u7684\u7a7a\u95f4\u63a7\u5236\u751f\u6210\u7cfb\u7edf\u7684\u4ece\u4e1a\u8005\u63d0\u4f9b\u8de8\u751f\u6210\u8303\u5f0f\u7684\u6e05\u6670\u7684\u5b66\u4e60\u8981\u70b9\uff0c\u4ece\u800c\u9610\u660e\u6587\u732e\u5e76\u89e3\u51b3\u77e5\u8bc6\u5dee\u8ddd\u3002\u6211\u4eec\u5728 ImageNet \u4e0a\u8de8\u57fa\u4e8e\u6269\u6563/\u6d41\u548c\u81ea\u56de\u5f52 (AR) \u7684\u6a21\u578b\u8fdb\u884c\u4e86\u53d7\u63a7\u5b9e\u9a8c\u3002\u9996\u5148\uff0c\u6211\u4eec\u5c06\u63a7\u5236\u6807\u8bb0\u9884\u586b\u5145\u5efa\u7acb\u4e3a Transformer \u7684\u7b80\u5355\u3001\u901a\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u7136\u540e\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4ee5\u524d\u672a\u5145\u5206\u63a2\u7d22\u7684\u91c7\u6837\u65f6\u95f4\u589e\u5f3a\uff0c\u8868\u660e\u5c06\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u6269\u5c55\u5230\u63a7\u5236\u4ee5\u53ca Softmax \u622a\u65ad\u5bf9\u63a7\u5236-\u751f\u6210\u4e00\u81f4\u6027\u6709\u5f88\u5f3a\u7684\u5f71\u54cd\u3002\u6700\u540e\uff0c\u6211\u4eec\u91cd\u65b0\u9610\u660e\u4e86\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u7684\u52a8\u673a\uff0c\u8bc1\u660e\u5b83\u4eec\u53ef\u4ee5\u5728\u6709\u9650\u7684\u4e0b\u6e38\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u65f6\u7f13\u89e3\u201c\u9057\u5fd8\u201d\u5e76\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u5728\u751f\u6210-\u63a7\u5236\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u5982\u5b8c\u5168\u8bad\u7ec3\u3002\u4ee3\u7801\u5c06\u5728\u53d1\u5e03\u65f6\u53d1\u5e03\u3002"}}
{"id": "2507.15728", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15728", "abs": "https://arxiv.org/abs/2507.15728", "authors": ["Wenqi Ouyang", "Zeqi Xiao", "Danni Yang", "Yifan Zhou", "Shuai Yang", "Lei Yang", "Jianlou Si", "Xingang Pan"], "title": "TokensGen: Harnessing Condensed Tokens for Long Video Generation", "comment": "Project page: https://vicky0522.github.io/tokensgen-webpage/", "summary": "Generating consistent long videos is a complex challenge: while\ndiffusion-based generative models generate visually impressive short clips,\nextending them to longer durations often leads to memory bottlenecks and\nlong-term inconsistency. In this paper, we propose TokensGen, a novel two-stage\nframework that leverages condensed tokens to address these issues. Our method\ndecomposes long video generation into three core tasks: (1) inner-clip semantic\ncontrol, (2) long-term consistency control, and (3) inter-clip smooth\ntransition. First, we train To2V (Token-to-Video), a short video diffusion\nmodel guided by text and video tokens, with a Video Tokenizer that condenses\nshort clips into semantically rich tokens. Second, we introduce T2To\n(Text-to-Token), a video token diffusion transformer that generates all tokens\nat once, ensuring global consistency across clips. Finally, during inference,\nan adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,\nreducing boundary artifacts and enhancing smooth transitions. Experimental\nresults demonstrate that our approach significantly enhances long-term temporal\nand content coherence without incurring prohibitive computational overhead. By\nleveraging condensed tokens and pre-trained short video models, our method\nprovides a scalable, modular solution for long video generation, opening new\npossibilities for storytelling, cinematic production, and immersive\nsimulations. Please see our project page at\nhttps://vicky0522.github.io/tokensgen-webpage/ .", "AI": {"tldr": "TokensGen\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5229\u7528\u89c6\u9891token\u6765\u89e3\u51b3\u957f\u89c6\u9891\u751f\u6210\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u901a\u8fc7To2V\u548cT2To\u6a21\u578b\u4ee5\u53caFIFO-Diffusion\u7b56\u7565\u5b9e\u73b0\u526a\u8f91\u5185\u63a7\u5236\u3001\u957f\u671f\u4e00\u81f4\u6027\u548c\u5e73\u6ed1\u8fc7\u6e21\u3002", "motivation": "\u751f\u6210\u4e00\u81f4\u7684\u957f\u89c6\u9891\u662f\u4e00\u4e2a\u590d\u6742\u7684\u6311\u6218\uff1a\u867d\u7136\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\u80fd\u751f\u6210\u89c6\u89c9\u4e0a\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u77ed\u7247\u6bb5\uff0c\u4f46\u5c06\u5176\u6269\u5c55\u5230\u66f4\u957f\u7684\u6301\u7eed\u65f6\u95f4\u5e38\u5e38\u4f1a\u5bfc\u81f4\u5185\u5b58\u74f6\u9888\u548c\u957f\u671f\u4e0d\u4e00\u81f4\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTokensGen\u7684\u65b0\u578b\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u6d53\u7f29\u7684token\u6765\u89e3\u51b3\u957f\u89c6\u9891\u751f\u6210\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u548c\u957f\u671f\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5c06\u957f\u89c6\u9891\u751f\u6210\u5206\u89e3\u4e3a\u4e09\u4e2a\u6838\u5fc3\u4efb\u52a1\uff1a(1) \u526a\u8f91\u5185\u8bed\u4e49\u63a7\u5236\uff0c(2) \u957f\u671f\u4e00\u81f4\u6027\u63a7\u5236\uff0c\u4ee5\u53ca (3) \u526a\u8f91\u95f4\u5e73\u6ed1\u8fc7\u6e21\u3002\u9996\u5148\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u540d\u4e3aTo2V\uff08Token-to-Video\uff09\u7684\u77ed\u89c6\u9891\u6269\u6563\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7531\u6587\u672c\u548c\u89c6\u9891token\u6307\u5bfc\uff0c\u5e76\u914d\u5907\u4e86\u4e00\u4e2a\u89c6\u9891\u5206\u8bcd\u5668\uff0c\u5c06\u77ed\u7247\u6bb5\u538b\u7f29\u6210\u4e30\u5bcc\u7684token\u3002\u5176\u6b21\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aT2To\uff08Text-to-Token\uff09\u7684\u89c6\u9891token\u6269\u6563Transformer\uff0c\u80fd\u591f\u4e00\u6b21\u6027\u751f\u6210\u6240\u6709token\uff0c\u786e\u4fdd\u8de8\u526a\u8f91\u7684\u5168\u5c40\u4e00\u81f4\u6027\u3002\u6700\u540e\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u7684FIFO-Diffusion\u7b56\u7565\u65e0\u7f1d\u8fde\u63a5\u76f8\u90bb\u7684\u526a\u8f91\uff0c\u51cf\u5c11\u8fb9\u754c\u4f2a\u5f71\u5e76\u589e\u5f3a\u5e73\u6ed1\u8fc7\u6e21\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u957f\u65f6\u5e8f\u548c\u5185\u5bb9\u8fde\u8d2f\u6027\uff0c\u540c\u65f6\u6ca1\u6709\u5e26\u6765\u9ad8\u6602\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u6d53\u7f29\u7684token\u548c\u9884\u8bad\u7ec3\u7684\u77ed\u89c6\u9891\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u6a21\u5757\u5316\u7684\u957f\u89c6\u9891\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u957f\u65f6\u5e8f\u548c\u5185\u5bb9\u8fde\u8d2f\u6027\uff0c\u540c\u65f6\u6ca1\u6709\u5e26\u6765\u9ad8\u6602\u7684\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2507.15748", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15748", "abs": "https://arxiv.org/abs/2507.15748", "authors": ["Jisu Shin", "Richard Shaw", "Seunghyun Shin", "Anton Pelykh", "Zhensong Zhang", "Hae-Gon Jeon", "Eduardo Perez-Pellitero"], "title": "Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS", "comment": "10 pages, 3 figures, NeurIPS 2025 under review", "summary": "Modern camera pipelines apply extensive on-device processing, such as\nexposure adjustment, white balance, and color correction, which, while\nbeneficial individually, often introduce photometric inconsistencies across\nviews. These appearance variations violate multi-view consistency and degrade\nthe quality of novel view synthesis. Joint optimization of scene\nrepresentations and per-image appearance embeddings has been proposed to\naddress this issue, but at the cost of increased computational complexity and\nslower training. In this work, we propose a transformer-based method that\npredicts spatially adaptive bilateral grids to correct photometric variations\nin a multi-view consistent manner, enabling robust cross-scene generalization\nwithout the need for scene-specific retraining. By incorporating the learned\ngrids into the 3D Gaussian Splatting pipeline, we improve reconstruction\nquality while maintaining high training efficiency. Extensive experiments show\nthat our approach outperforms or matches existing scene-specific optimization\nmethods in reconstruction fidelity and convergence speed.", "AI": {"tldr": "\u8a72\u7814\u7a76\u63d0\u51fa\u4e00\u7a2e Transformer \u65b9\u6cd5\uff0c\u900f\u904e\u9810\u6e2c\u96d9\u908a\u7db2\u683c\u4f86\u6821\u6b63\u591a\u8996\u9ede\u5716\u50cf\u9593\u7684\u6e2c\u5149\u5dee\u7570\uff0c\u4ee5\u63d0\u5347\u65b0\u8996\u9ede\u5408\u6210\u7684\u54c1\u8cea\uff0c\u4e26\u5728\u4e0d\u9700\u91cd\u65b0\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u5be6\u73fe\u8de8\u5834\u666f\u6cdb\u5316\u3002", "motivation": "\u73fe\u4ee3\u76f8\u6a5f\u7ba1\u7dda\u61c9\u7528\u5ee3\u6cdb\u7684\u88dd\u7f6e\u5167\u8655\u7406\uff08\u4f8b\u5982\u66dd\u5149\u8abf\u6574\u3001\u767d\u5e73\u8861\u548c\u8272\u5f69\u6821\u6b63\uff09\uff0c\u96d6\u7136\u55ae\u7368\u6709\u5229\uff0c\u4f46\u7d93\u5e38\u6703\u5c0e\u81f4\u591a\u8996\u9ede\u4e4b\u9593\u51fa\u73fe\u6e2c\u5149\u4e0d\u4e00\u81f4\uff0c\u9055\u53cd\u4e86\u591a\u8996\u9ede\u4e00\u81f4\u6027\u4e26\u964d\u4f4e\u4e86\u65b0\u8996\u9ede\u5408\u6210\u7684\u54c1\u8cea\u3002\u73fe\u6709\u65b9\u6cd5\uff08\u4f8b\u5982\u806f\u5408\u512a\u5316\u5834\u666f\u8868\u793a\u548c\u6bcf\u5f35\u5716\u50cf\u7684\u5916\u89c0\u5d4c\u5165\uff09\u96d6\u7136\u53ef\u4ee5\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u4f46\u8a08\u7b97\u8907\u96dc\u5ea6\u9ad8\u4e14\u8a13\u7df4\u901f\u5ea6\u6162\u3002", "method": "\u63d0\u51fa\u4e00\u7a2e\u57fa\u65bc Transformer \u7684\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u9810\u6e2c\u7a7a\u9593\u81ea\u9069\u61c9\u96d9\u908a\u7db2\u683c\uff0c\u4ee5\u591a\u8996\u9ede\u4e00\u81f4\u7684\u65b9\u5f0f\u6821\u6b63\u6e2c\u5149\u5dee\u7570\u3002", "result": "\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u8a72\u65b9\u6cd5\u5728\u91cd\u5efa\u4fdd\u771f\u5ea6\u548c\u6536\u6582\u901f\u5ea6\u65b9\u9762\u512a\u65bc\u6216\u5ab2\u7f8e\u73fe\u6709\u7684\u7279\u5b9a\u5834\u666f\u512a\u5316\u65b9\u6cd5\u3002", "conclusion": "\u8a72\u65b9\u6cd5\u900f\u904e\u9810\u6e2c\u7a7a\u9593\u81ea\u9069\u61c9\u96d9\u908a\u7db2\u683c\u4f86\u4ee5\u591a\u8996\u9ede\u4e00\u81f4\u7684\u65b9\u5f0f\u6821\u6b63\u6e2c\u5149\u5dee\u7570\uff0c\u5be6\u73fe\u7121\u9700\u5834\u666f\u7279\u5b9a\u91cd\u65b0\u8a13\u7df4\u7684\u7a69\u5065\u8de8\u5834\u666f\u6cdb\u5316\u3002\u5c07\u5b78\u7fd2\u5230\u7684\u7db2\u683c\u6574\u5408\u5230 3D \u9ad8\u65af\u6f51\u6ffa\u7ba1\u7dda\u4e2d\uff0c\u5728\u7dad\u6301\u9ad8\u8a13\u7df4\u6548\u7387\u7684\u540c\u6642\u63d0\u9ad8\u4e86\u91cd\u5efa\u54c1\u8cea\u3002"}}
{"id": "2507.15765", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15765", "abs": "https://arxiv.org/abs/2507.15765", "authors": ["Feng-Qi Cui", "Anyang Tong", "Jinyang Huang", "Jie Zhang", "Dan Guo", "Zhi Liu", "Meng Wang"], "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization", "comment": "Accepted by ACM MM'25", "summary": "Dynamic Facial Expression Recognition (DFER) plays a critical role in\naffective computing and human-computer interaction. Although existing methods\nachieve comparable performance, they inevitably suffer from performance\ndegradation under sample heterogeneity caused by multi-source data and\nindividual expression variability. To address these challenges, we propose a\nnovel framework, called Heterogeneity-aware Distributional Framework (HDF), and\ndesign two plug-and-play modules to enhance time-frequency modeling and\nmitigate optimization imbalance caused by hard samples. Specifically, the\nTime-Frequency Distributional Attention Module (DAM) captures both temporal\nconsistency and frequency robustness through a dual-branch attention design,\nimproving tolerance to sequence inconsistency and visual style shifts. Then,\nbased on gradient sensitivity and information bottleneck principles, an\nadaptive optimization module Distribution-aware Scaling Module (DSM) is\nintroduced to dynamically balance classification and contrastive losses,\nenabling more stable and discriminative representation learning. Extensive\nexperiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF\nsignificantly improves both recognition accuracy and robustness. Our method\nachieves superior weighted average recall (WAR) and unweighted average recall\n(UAR) while maintaining strong generalization across diverse and imbalanced\nscenarios. Codes are released at https://github.com/QIcita/HDF_DFER.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u6837\u672c\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86HDF\u6846\u67b6\uff0c\u5305\u542bDAM\u548cDSM\u6a21\u5757\uff0c\u901a\u8fc7\u589e\u5f3a\u65f6\u9891\u5efa\u6a21\u548c\u81ea\u9002\u5e94\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86DFER\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u6001\u9762\u90e8\u8868\u60c5\u8bc6\u522b\uff08DFER\uff09\u65b9\u6cd5\u5728\u9762\u5bf9\u591a\u6e90\u6570\u636e\u548c\u4e2a\u4f53\u8868\u60c5\u53d8\u5f02\u6027\u5f15\u8d77\u7684\u6837\u672c\u5f02\u8d28\u6027\u65f6\uff0c\u6027\u80fd\u4f1a\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5f02\u8d28\u6027\u611f\u77e5\u5206\u5e03\u6846\u67b6\uff08HDF\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff1a\u65f6\u95f4-\u9891\u7387\u5206\u5e03\u6ce8\u610f\u529b\u6a21\u5757\uff08DAM\uff09\u548c\u5206\u5e03\u611f\u77e5\u7f29\u653e\u6a21\u5757\uff08DSM\uff09\u3002DAM\u901a\u8fc7\u53cc\u5206\u652f\u6ce8\u610f\u529b\u8bbe\u8ba1\u6355\u6349\u65f6\u5e8f\u4e00\u81f4\u6027\u548c\u9891\u7387\u9c81\u68d2\u6027\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u5e8f\u5217\u4e0d\u4e00\u81f4\u548c\u89c6\u89c9\u98ce\u683c\u53d8\u5316\u7684\u5bb9\u5fcd\u5ea6\u3002DSM\u57fa\u4e8e\u68af\u5ea6\u654f\u611f\u6027\u548c\u4fe1\u606f\u74f6\u9888\u539f\u7406\uff0c\u52a8\u6001\u5e73\u8861\u5206\u7c7b\u548c\u5bf9\u6bd4\u635f\u5931\uff0c\u4ee5\u5b9e\u73b0\u66f4\u7a33\u5b9a\u548c\u5177\u6709\u8fa8\u522b\u529b\u7684\u8868\u793a\u5b66\u4e60\u3002", "result": "HDF\u6846\u67b6\u5728DFEW\u548cFERV39k\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5176\u5728\u8bc6\u522b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u591a\u6837\u5316\u548c\u4e0d\u5e73\u8861\u7684\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "HDF\u6846\u67b6\u5728DFEW\u548cFERV39k\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u8bc6\u522b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u591a\u6837\u5316\u548c\u4e0d\u5e73\u8861\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u52a0\u6743\u5e73\u5747\u53ec\u56de\u7387\uff08WAR\uff09\u548c\u672a\u52a0\u6743\u5e73\u5747\u53ec\u56de\u7387\uff08UAR\uff09\u3002"}}
{"id": "2507.15777", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15777", "abs": "https://arxiv.org/abs/2507.15777", "authors": ["Junwen Wang", "Oscar MacCormac", "William Rochford", "Aaron Kujawa", "Jonathan Shapey", "Tom Vercauteren"], "title": "Label tree semantic losses for rich multi-class medical image segmentation", "comment": "arXiv admin note: text overlap with arXiv:2506.21150", "summary": "Rich and accurate medical image segmentation is poised to underpin the next\ngeneration of AI-defined clinical practice by delineating critical anatomy for\npre-operative planning, guiding real-time intra-operative navigation, and\nsupporting precise post-operative assessment. However, commonly used learning\nmethods for medical and surgical imaging segmentation tasks penalise all errors\nequivalently and thus fail to exploit any inter-class semantics in the labels\nspace. This becomes particularly problematic as the cardinality and richness of\nlabels increases to include subtly different classes. In this work, we propose\ntwo tree-based semantic loss functions which take advantage of a hierarchical\norganisation of the labels. We further incorporate our losses in a recently\nproposed approach for training with sparse, background-free annotations to\nextend the applicability of our proposed losses. Extensive experiments are\nreported on two medical and surgical image segmentation tasks, namely head MRI\nfor whole brain parcellation (WBP) with full supervision and neurosurgical\nhyperspectral imaging (HSI) for scene understanding with sparse annotations.\nResults demonstrate that our proposed method reaches state-of-the-art\nperformance in both cases.", "AI": {"tldr": "New tree-based semantic loss functions improve medical image segmentation by considering label hierarchy and sparse annotations, achieving state-of-the-art results.", "motivation": "Commonly used learning methods for medical image segmentation penalize all errors equally, failing to exploit inter-class semantics, especially with a large number of subtly different classes.", "method": "Proposed two tree-based semantic loss functions and incorporated them into a training approach with sparse, background-free annotations.", "result": "Extensive experiments on head MRI for whole brain parcellation and neurosurgical hyperspectral imaging for scene understanding show the proposed method reaches state-of-the-art performance.", "conclusion": "The proposed method achieves state-of-the-art performance on both head MRI and neurosurgical hyperspectral imaging tasks."}}
{"id": "2507.15793", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15793", "abs": "https://arxiv.org/abs/2507.15793", "authors": ["Ghassen Baklouti", "Julio Silva-Rodr\u00edguez", "Jose Dolz", "Houda Bahig", "Ismail Ben Ayed"], "title": "Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation", "comment": "Accepted at MICCAI 2025", "summary": "Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is\nincreasingly attracting interest in medical imaging due to its effectiveness\nand computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)\nis a notable approach based on the assumption that the adaptation inherently\noccurs in a low-dimensional subspace. While it has shown good performance, its\nimplementation requires a fixed and unalterable rank, which might be\nchallenging to select given the unique complexities and requirements of each\nmedical imaging downstream task. Inspired by advancements in natural image\nprocessing, we introduce a novel approach for medical image segmentation that\ndynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank\nrepresentation of the trainable weight matrices as a singular value\ndecomposition, we introduce an l_1 sparsity regularizer to the loss function,\nand tackle it with a proximal optimizer. The regularizer could be viewed as a\npenalty on the decomposition rank. Hence, its minimization enables to find\ntask-adapted ranks automatically. Our method is evaluated in a realistic\nfew-shot fine-tuning setting, where we compare it first to the standard LoRA\nand then to several other PEFT methods across two distinguishable tasks: base\norgans and novel organs. Our extensive experiments demonstrate the significant\nperformance improvements driven by our method, highlighting its efficiency and\nrobustness against suboptimal rank initialization. Our code is publicly\navailable: https://github.com/ghassenbaklouti/ARENA", "AI": {"tldr": "\u901a\u8fc7L1\u7a00\u758f\u6027\u6b63\u5219\u5316\u5668\u52a8\u6001\u8c03\u6574LoRA\u7684\u79e9\uff0c\u5728\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5c3d\u7ba1LoRA\u5728PEFT\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u56fa\u5b9a\u7684\u79e9\u53ef\u80fd\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u533b\u5b66\u6210\u50cf\u4efb\u52a1\u7684\u590d\u6742\u6027\u548c\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u8c03\u6574\u79e9\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5728\u533b\u5b66\u56fe\u50cf\u5206\u5272\u7b49\u4efb\u52a1\u4e0a\u7684\u9002\u5e94\u6027\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u533b\u5b66\u56fe\u50cf\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u635f\u5931\u51fd\u6570\u4e2d\u52a0\u5165L1\u7a00\u758f\u6027\u6b63\u5219\u5316\u5668\uff0c\u5e76\u4f7f\u7528\u8fd1\u7aef\u4f18\u5316\u5668\u6765\u89e3\u51b3\uff0c\u4ece\u800c\u5728\u9002\u5e94\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u79e9\u3002\u8fd9\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u81ea\u52a8\u5bfb\u627e\u9002\u5e94\u4efb\u52a1\u7684\u79e9\u3002", "result": "\u5728\u5c11\u6837\u672c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\uff0c\u4e0e\u6807\u51c6LoRA\u548c\u5176\u4ed6PEFT\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u4efb\u52a1\uff08\u57fa\u7840\u5668\u5b98\u548c\u65b0\u5668\u5b98\u5206\u5272\uff09\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7L1\u7a00\u758f\u6027\u6b63\u5219\u5316\u5668\u81ea\u52a8\u8c03\u6574\u9002\u5e94\u6027\u79e9\uff0c\u5728\u5c11\u6837\u672c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u6807\u51c6LoRA\u548c\u5176\u4ed6PEFT\u65b9\u6cd5\uff0c\u5728\u57fa\u7840\u5668\u5b98\u548c\u65b0\u5668\u5b98\u5206\u5272\u4efb\u52a1\u4e0a\u5747\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u7387\u548c\u5bf9\u6b21\u4f18\u79e9\u521d\u59cb\u5316\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.15798", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15798", "abs": "https://arxiv.org/abs/2507.15798", "authors": ["Lilian Hollard", "Lucas Mohimont", "Nathalie Gaveau", "Luiz-Angelo Steffenel"], "title": "Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models", "comment": null, "summary": "The paper investigates the performance of state-of-the-art low-parameter deep\nneural networks for computer vision, focusing on bottleneck architectures and\ntheir behavior using superlinear activation functions. We address interference\nin feature maps, a phenomenon associated with superposition, where neurons\nsimultaneously encode multiple characteristics. Our research suggests that\nlimiting interference can enhance scaling and accuracy in very low-scaled\nnetworks (under 1.5M parameters). We identify key design elements that reduce\ninterference by examining various bottleneck architectures, leading to a more\nefficient neural network. Consequently, we propose a proof-of-concept\narchitecture named NoDepth Bottleneck built on mechanistic insights from our\nexperiments, demonstrating robust scaling accuracy on the ImageNet dataset.\nThese findings contribute to more efficient and scalable neural networks for\nthe low-parameter range and advance the understanding of bottlenecks in\ncomputer vision. https://caiac.pubpub.org/pub/3dh6rsel", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15803", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15803", "abs": "https://arxiv.org/abs/2507.15803", "authors": ["Danhui Chen", "Ziquan Liu", "Chuxi Yang", "Dan Wang", "Yan Yan", "Yi Xu", "Xiangyang Ji"], "title": "ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction", "comment": "ICCV 2025", "summary": "Pixel-level vision tasks, such as semantic segmentation, require extensive\nand high-quality annotated data, which is costly to obtain. Semi-supervised\nsemantic segmentation (SSSS) has emerged as a solution to alleviate the\nlabeling burden by leveraging both labeled and unlabeled data through\nself-training techniques. Meanwhile, the advent of foundational segmentation\nmodels pre-trained on massive data, has shown the potential to generalize\nacross domains effectively. This work explores whether a foundational\nsegmentation model can address label scarcity in the pixel-level vision task as\nan annotator for unlabeled images. Specifically, we investigate the efficacy of\nusing SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual\ninput, to generate predictive masks for unlabeled data. To address the\nshortcomings of using SEEM-generated masks as supervision, we propose\nConformalSAM, a novel SSSS framework which first calibrates the foundation\nmodel using the target domain's labeled data and then filters out unreliable\npixel labels of unlabeled data so that only high-confidence labels are used as\nsupervision. By leveraging conformal prediction (CP) to adapt foundation models\nto target data through uncertainty calibration, ConformalSAM exploits the\nstrong capability of the foundational segmentation model reliably which\nbenefits the early-stage learning, while a subsequent self-reliance training\nstrategy mitigates overfitting to SEEM-generated masks in the later training\nstage. Our experiment demonstrates that, on three standard benchmarks of SSSS,\nConformalSAM achieves superior performance compared to recent SSSS methods and\nhelps boost the performance of those methods as a plug-in.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faConformalSAM\u6846\u67b6\uff0c\u5229\u7528\u6821\u51c6\u8fc7\u7684\u57fa\u7840\u5206\u5272\u6a21\u578bSEEM\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\uff0c\u7528\u4e8e\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u3002\u901a\u8fc7\u5171\u5f62\u9884\u6d4b\u8fc7\u6ee4\u4f4e\u7f6e\u4fe1\u5ea6\u6807\u7b7e\uff0c\u5e76\u7ed3\u5408\u81ea\u4e3b\u8bad\u7ec3\u7b56\u7565\uff0cConformalSAM\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u53ef\u4f5c\u4e3a\u63d2\u4ef6\u63d0\u5347\u5176\u4ed6\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u7f13\u89e3\u50cf\u7d20\u7ea7\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u8bed\u4e49\u5206\u5272\uff09\u4e2d\u83b7\u53d6\u5927\u91cf\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7684\u6210\u672c\u95ee\u9898\uff0c\u5229\u7528\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\uff08SSSS\uff09\u548c\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u5206\u5272\u6a21\u578b\u662f\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u57fa\u7840\u5206\u5272\u6a21\u578b\u4f5c\u4e3a\u6807\u6ce8\u5668\u5728\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u751f\u6210\u9884\u6d4b\u63a9\u7801\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u53ef\u9760\u5229\u7528\u5176\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faConformalSAM\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u9996\u5148\u4f7f\u7528\u76ee\u6807\u57df\u7684\u6807\u8bb0\u6570\u636e\u6821\u51c6\u57fa\u7840\u5206\u5272\u6a21\u578b\uff08SEEM\uff09\uff0c\u7136\u540e\u8fc7\u6ee4\u6389\u4e0d\u53ef\u9760\u7684\u50cf\u7d20\u6807\u7b7e\uff0c\u53ea\u4f7f\u7528\u9ad8\u7f6e\u4fe1\u5ea6\u6807\u7b7e\u8fdb\u884c\u76d1\u7763\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u5171\u5f62\u9884\u6d4b\uff08CP\uff09\u9002\u5e94\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u5728\u65e9\u671f\u5b66\u4e60\u9636\u6bb5\u5229\u7528\u5176\u5f3a\u5927\u7684\u5206\u5272\u80fd\u529b\uff0c\u968f\u540e\u91c7\u7528\u81ea\u4e3b\u8bad\u7ec3\u7b56\u7565\u51cf\u8f7b\u540e\u671f\u5bf9SEEM\u751f\u6210\u6807\u7b7e\u7684\u8fc7\u62df\u5408\u3002", "result": "ConformalSAM\u5728\u4e09\u4e2a\u6807\u51c6\u7684\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u4e8e\u8fd1\u671f\u7684\u76f8\u5173\u65b9\u6cd5\uff0c\u53d6\u5f97\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u4f5c\u4e3a\u4e00\u4e2a\u63d2\u4ef6\uff0c\u80fd\u591f\u63d0\u5347\u5176\u4ed6\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "ConformalSAM\u6846\u67b6\u901a\u8fc7\u6821\u51c6\u57fa\u7840\u6a21\u578b\u5e76\u8fc7\u6ee4\u4e0d\u53ef\u9760\u7684\u50cf\u7d20\u6807\u7b7e\uff0c\u6709\u6548\u5229\u7528\u4e86SEEM\u751f\u6210\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u6807\u7b7e\u8fdb\u884c\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\uff0c\u5e76\u5728\u4e09\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u8fd1\u671f\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8fd8\u80fd\u4f5c\u4e3a\u63d2\u4ef6\u63d0\u5347\u73b0\u6709\u65b9\u6cd5\u7684\u8868\u73b0\u3002"}}
{"id": "2507.15807", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15807", "abs": "https://arxiv.org/abs/2507.15807", "authors": ["Shuo Chen", "Jianzhe Liu", "Zhen Han", "Yan Xia", "Daniel Cremers", "Philip Torr", "Volker Tresp", "Jindong Gu"], "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context", "comment": "accepted to COLM 2025", "summary": "Multimodal Large Language Models (MLLMs), built on powerful language\nbackbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new\ntasks from a few multimodal demonstrations consisting of images, questions, and\nanswers. Despite showing noticeable improvement on standard vision-language\ndatasets, current MLLMs struggle to leverage visual information in the\ndemonstrations. Specifically, they tend to neglect visual cues and over-rely on\ntextual patterns, leading to mere text imitation rather than genuine multimodal\nadaptation. This behavior makes MICL still unimodal and largely restricts its\npractical utility. More importantly, this limitation is often concealed by the\nimproved performance on tasks that do not require understanding the visual\ncontext. As a result, how to effectively enhance MICL ability and reliably\nevaluate the MICL performance remains underexplored. To address these issues,\nwe first introduce Dynamic Attention Reallocation (DARA), an efficient\nfine-tuning strategy that encourages models to attend to the visual context by\nrebalancing attention across visual and textual tokens. In addition, we present\nTrueMICL, an MICL-dedicated dataset with both support and test sets that\nexplicitly requires the integration of multimodal information-particularly\nvisual content-for correct task completion. Extensive experiments demonstrate\nthe effectiveness of our holistic solution, showcasing substantial improvements\nin the true multimodal in-context learning capabilities. Code and datasets are\navailable at https://chenxshuo.github.io/true-micl-colm .", "AI": {"tldr": "MLLMs\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u5b58\u5728\u5ffd\u89c6\u89c6\u89c9\u4fe1\u606f\u7684\u95ee\u9898\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86DARA\u5fae\u8c03\u7b56\u7565\u548cTrueMICL\u6570\u636e\u96c6\u6765\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u5e76\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08MICL\uff09\u4e2d\u5b58\u5728\u5ffd\u89c6\u89c6\u89c9\u4fe1\u606f\u3001\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u6a21\u5f0f\u7684\u95ee\u9898\uff0c\u5bfc\u81f4MICL\u5b9e\u9645\u4e0a\u4ecd\u662f\u5355\u6a21\u6001\u7684\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u8fd9\u79cd\u5c40\u9650\u6027\u5728\u4e0d\u8981\u6c42\u7406\u89e3\u89c6\u89c9\u5185\u5bb9\u7684\u4efb\u52a1\u4e0a\u4f1a\u88ab\u6027\u80fd\u63d0\u5347\u6240\u63a9\u76d6\uff0c\u56e0\u6b64\u5982\u4f55\u6709\u6548\u589e\u5f3aMICL\u80fd\u529b\u548c\u53ef\u9760\u8bc4\u4f30MICL\u6027\u80fd\u4ecd\u662f\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u6ce8\u610f\u529b\u91cd\u65b0\u5206\u914d\uff08DARA\uff09\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u65e8\u5728\u901a\u8fc7\u91cd\u65b0\u5e73\u8861\u89c6\u89c9\u548c\u6587\u672c\u6807\u8bb0\u7684\u6ce8\u610f\u529b\u6765\u9f13\u52b1\u6a21\u578b\u5173\u6ce8\u89c6\u89c9\u4e0a\u4e0b\u6587\u3002\u6b64\u5916\uff0c\u7814\u7a76\u4eba\u5458\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aTrueMICL\u7684\u4e13\u7528\u6570\u636e\u96c6\uff0c\u5305\u542b\u652f\u6301\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u660e\u786e\u8981\u6c42\u6a21\u578b\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff08\u5c24\u5176\u662f\u89c6\u89c9\u5185\u5bb9\uff09\u4ee5\u5b8c\u6210\u4efb\u52a1\u3002", "result": "\u901a\u8fc7\u5e94\u7528DARA\u7b56\u7565\u548c\u4f7f\u7528TrueMICL\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6574\u4f53\u89e3\u51b3\u65b9\u6848\u80fd\u663e\u8457\u63d0\u9ad8MLLMs\u771f\u6b63\u7684\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u52a8\u6001\u6ce8\u610f\u529b\u91cd\u65b0\u5206\u914d\uff08DARA\uff09\u7b56\u7565\u548cTrueMICL\u6570\u636e\u96c6\uff0c\u4ee5\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08MICL\uff09\u4e2d\u5ffd\u89c6\u89c6\u89c9\u4fe1\u606f\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6574\u5408\u89c6\u89c9\u5185\u5bb9\u7684\u80fd\u529b\uff0c\u5e76\u4e3aMICL\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.15809", "categories": ["cs.CV", "cs.LG", "physics.geo-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.15809", "abs": "https://arxiv.org/abs/2507.15809", "authors": ["Roberto Miele", "Niklas Linde"], "title": "Diffusion models for multivariate subsurface generation and efficient probabilistic inversion", "comment": null, "summary": "Diffusion models offer stable training and state-of-the-art performance for\ndeep generative modeling tasks. Here, we consider their use in the context of\nmultivariate subsurface modeling and probabilistic inversion. We first\ndemonstrate that diffusion models enhance multivariate modeling capabilities\ncompared to variational autoencoders and generative adversarial networks. In\ndiffusion modeling, the generative process involves a comparatively large\nnumber of time steps with update rules that can be modified to account for\nconditioning data. We propose different corrections to the popular Diffusion\nPosterior Sampling approach by Chung et al. (2023). In particular, we introduce\na likelihood approximation accounting for the noise-contamination that is\ninherent in diffusion modeling. We assess performance in a multivariate\ngeological scenario involving facies and correlated acoustic impedance.\nConditional modeling is demonstrated using both local hard data (well logs) and\nnonlinear geophysics (fullstack seismic data). Our tests show significantly\nimproved statistical robustness, enhanced sampling of the posterior probability\ndensity function and reduced computational costs, compared to the original\napproach. The method can be used with both hard and indirect conditioning data,\nindividually or simultaneously. As the inversion is included within the\ndiffusion process, it is faster than other methods requiring an outer-loop\naround the generative model, such as Markov chain Monte Carlo.", "AI": {"tldr": "\u6269\u6563\u6a21\u578b\u5728\u591a\u5143\u5730\u4e0b\u5efa\u6a21\u548c\u6982\u7387\u53cd\u6f14\u65b9\u9762\u4f18\u4e8e VAE \u548c GAN\u3002\u6539\u8fdb\u7684\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u901a\u8fc7\u4f3c\u7136\u8fd1\u4f3c\u548c\u6761\u4ef6\u5efa\u6a21\uff08\u4f7f\u7528\u4e95\u6570\u636e\u548c\u5730\u9707\u6570\u636e\uff09\u63d0\u9ad8\u4e86\u6027\u80fd\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u8003\u8651\u5728\u591a\u5143\u5730\u4e0b\u5efa\u6a21\u548c\u6982\u7387\u53cd\u6f14\u7684\u80cc\u666f\u4e0b\u4f7f\u7528\u6269\u6563\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7684\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5bf9 Chung \u7b49\u4eba\u63d0\u51fa\u7684\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u8fdb\u884c\u4e0d\u540c\u7684\u4fee\u6b63\uff0c\u5e76\u5f15\u5165\u4e86\u8003\u8651\u6269\u6563\u6a21\u578b\u56fa\u6709\u566a\u58f0\u6c61\u67d3\u7684\u4f3c\u7136\u8fd1\u4f3c\u3002", "result": "\u4e0e\u539f\u59cb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u591a\u5143\u5730\u8d28\u573a\u666f\uff08\u5305\u62ec\u76f8\u548c\u76f8\u5173\u7684\u58f0\u963b\u6297\uff09\u4e2d\uff0c\u6d4b\u8bd5\u663e\u793a\u7edf\u8ba1\u9c81\u68d2\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u540e\u9a8c\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u7684\u91c7\u6837\u5f97\u5230\u589e\u5f3a\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5355\u72ec\u6216\u540c\u65f6\u4f7f\u7528\u786c\u6570\u636e\u548c\u95f4\u63a5\u6761\u4ef6\u6570\u636e\u3002\u7531\u4e8e\u53cd\u6f14\u5305\u542b\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\uff0c\u56e0\u6b64\u6bd4\u9700\u8981\u56f4\u7ed5\u751f\u6210\u6a21\u578b\u8bbe\u7f6e\u5916\u90e8\u5faa\u73af\uff08\u4f8b\u5982\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff09\u7684\u5176\u4ed6\u65b9\u6cd5\u66f4\u5feb\u3002"}}
{"id": "2507.15824", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15824", "abs": "https://arxiv.org/abs/2507.15824", "authors": ["Enes Sanli", "Baris Sarper Tezcan", "Aykut Erdem", "Erkut Erdem"], "title": "Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models", "comment": null, "summary": "Recent progress in text-to-video (T2V) generation has enabled the synthesis\nof visually compelling and temporally coherent videos from natural language.\nHowever, these models often fall short in basic physical commonsense, producing\noutputs that violate intuitive expectations around causality, object behavior,\nand tool use. Addressing this gap, we present PhysVidBench, a benchmark\ndesigned to evaluate the physical reasoning capabilities of T2V systems. The\nbenchmark includes 383 carefully curated prompts, emphasizing tool use,\nmaterial properties, and procedural interactions, and domains where physical\nplausibility is crucial. For each prompt, we generate videos using diverse\nstate-of-the-art models and adopt a three-stage evaluation pipeline: (1)\nformulate grounded physics questions from the prompt, (2) caption the generated\nvideo with a vision-language model, and (3) task a language model to answer\nseveral physics-involved questions using only the caption. This indirect\nstrategy circumvents common hallucination issues in direct video-based\nevaluation. By highlighting affordances and tool-mediated actions, areas\noverlooked in current T2V evaluations, PhysVidBench provides a structured,\ninterpretable framework for assessing physical commonsense in generative video\nmodels.", "AI": {"tldr": "PhysVidBench is a new benchmark to evaluate the physical common sense of text-to-video generation models. It uses a benchmark of 383 prompts and a three-stage evaluation process involving question generation, video captioning, and language model-based question answering to assess physical reasoning, addressing limitations in current evaluations that overlook tool use and material properties.", "motivation": "Current text-to-video (T2V) generation models often lack basic physical commonsense, leading to videos that violate intuitive expectations regarding causality, object behavior, and tool use. This benchmark was developed to address this gap by specifically evaluating the physical reasoning capabilities of T2V systems.", "method": "PhysVidBench was created by curating 383 prompts emphasizing tool use, material properties, and procedural interactions. Videos are generated using state-of-the-art models for each prompt. A three-stage evaluation pipeline is used: 1) formulating grounded physics questions from the prompt, 2) captioning the generated video using a vision-language model, and 3) having a language model answer physics-involved questions based solely on the caption. This indirect evaluation strategy aims to circumvent hallucination issues common in direct video-based assessments.", "result": "The benchmark includes 383 carefully curated prompts. The evaluation pipeline, involving question formulation, video captioning, and language model-based question answering, provides a method to assess physical commonsense without direct video evaluation, mitigating hallucination issues.", "conclusion": "PhysVidBench enables a structured and interpretable framework for assessing physical commonsense in generative video models by highlighting affordances and tool-mediated actions, which are often overlooked in current T2V evaluations."}}
{"id": "2507.15852", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15852", "abs": "https://arxiv.org/abs/2507.15852", "authors": ["Zhixiong Zhang", "Shuangrui Ding", "Xiaoyi Dong", "Songxin He", "Jianfan Lin", "Junsong Tang", "Yuhang Zang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction", "comment": "project page: https://rookiexiong7.github.io/projects/SeC/; code:\n  https://github.com/OpenIXCLab/SeC; dataset:\n  https://huggingface.co/datasets/OpenIXCLab/SeCVOS", "summary": "Video Object Segmentation (VOS) is a core task in computer vision, requiring\nmodels to track and segment target objects across video frames. Despite notable\nadvances with recent efforts, current techniques still lag behind human\ncapabilities in handling drastic visual variations, occlusions, and complex\nscene changes. This limitation arises from their reliance on appearance\nmatching, neglecting the human-like conceptual understanding of objects that\nenables robust identification across temporal dynamics. Motivated by this gap,\nwe propose Segment Concept (SeC), a concept-driven segmentation framework that\nshifts from conventional feature matching to the progressive construction and\nutilization of high-level, object-centric representations. SeC employs Large\nVision-Language Models (LVLMs) to integrate visual cues across diverse frames,\nconstructing robust conceptual priors. During inference, SeC forms a\ncomprehensive semantic representation of the target based on processed frames,\nrealizing robust segmentation of follow-up frames. Furthermore, SeC adaptively\nbalances LVLM-based semantic reasoning with enhanced feature matching,\ndynamically adjusting computational efforts based on scene complexity. To\nrigorously assess VOS methods in scenarios demanding high-level conceptual\nreasoning and robust semantic understanding, we introduce the Semantic Complex\nScenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160\nmanually annotated multi-scenario videos designed to challenge models with\nsubstantial appearance variations and dynamic scene transformations. In\nparticular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,\nestablishing a new state-of-the-art in concept-aware video object segmentation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSeC\u7684\u6982\u5ff5\u9a71\u52a8\u89c6\u9891\u5bf9\u8c61\u5206\u5272\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u7406\u89e3\u548c\u5206\u5272\u89c6\u9891\u4e2d\u7684\u5bf9\u8c61\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u89c6\u89c9\u53d8\u5316\u3001\u906e\u6321\u548c\u573a\u666f\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8868\u73b0\u51fa\u8272\u3002\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6SeCVOS\u6765\u8bc4\u4f30\u8fd9\u79cd\u80fd\u529b\uff0cSeC\u5728\u8be5\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u5bf9\u8c61\u5206\u5272\uff08VOS\uff09\u6280\u672f\u5728\u5904\u7406\u5267\u70c8\u7684\u89c6\u89c9\u53d8\u5316\u3001\u906e\u6321\u548c\u590d\u6742\u7684\u573a\u666f\u53d8\u5316\u65b9\u9762\u4ecd\u843d\u540e\u4e8e\u4eba\u7c7b\u80fd\u529b\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u5916\u89c2\u5339\u914d\u800c\u5ffd\u7565\u4e86\u4eba\u7c7b\u7684\u6982\u5ff5\u7406\u89e3\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "SeC\u6846\u67b6\u5229\u7528\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u6574\u5408\u8de8\u89c6\u9891\u5e27\u7684\u89c6\u89c9\u7ebf\u7d22\uff0c\u6784\u5efa\u9c81\u68d2\u7684\u6982\u5ff5\u5148\u9a8c\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u5b83\u901a\u8fc7\u5904\u7406\u540e\u7684\u5e27\u5f62\u6210\u5168\u9762\u7684\u76ee\u6807\u8bed\u4e49\u8868\u5f81\uff0c\u5e76\u81ea\u9002\u5e94\u5730\u5e73\u8861\u57fa\u4e8eLVLM\u7684\u8bed\u4e49\u63a8\u7406\u548c\u589e\u5f3a\u7684\u7279\u5f81\u5339\u914d\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u540c\u573a\u666f\u7684\u590d\u6742\u6027\u3002", "result": "SeC\u5728SeCVOS\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e8611.8\u5206\u7684\u63d0\u5347\uff0c\u8d85\u8fc7\u4e86SAM 2.1\uff0c\u786e\u7acb\u4e86\u6982\u5ff5\u611f\u77e5\u89c6\u9891\u5bf9\u8c61\u5206\u5272\u7684\u65b0\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "SeC\u901a\u8fc7\u4ece\u4f20\u7edf\u7684\u7279\u5f81\u5339\u914d\u8f6c\u5411\u6e10\u8fdb\u5f0f\u6784\u5efa\u548c\u5229\u7528\u9ad8\u5c42\u3001\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u8868\u5f81\uff0c\u5b9e\u73b0\u4e86\u6982\u5ff5\u9a71\u52a8\u7684\u5206\u5272\uff0c\u5e76\u5728SeCVOS\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e8611.8\u5206\u7684\u63d0\u5347\uff0c\u786e\u7acb\u4e86\u5728\u6982\u5ff5\u611f\u77e5\u89c6\u9891\u5bf9\u8c61\u5206\u5272\u65b9\u9762\u7684\u65b0\u6280\u672f\u6c34\u5e73\u3002"}}
{"id": "2507.15856", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.15856", "abs": "https://arxiv.org/abs/2507.15856", "authors": ["Jiawei Yang", "Tianhong Li", "Lijie Fan", "Yonglong Tian", "Yue Wang"], "title": "Latent Denoising Makes Good Visual Tokenizers", "comment": "Code is available at: https://github.com/Jiawei-Yang/DeTok", "summary": "Despite their fundamental role, it remains unclear what properties could make\nvisual tokenizers more effective for generative modeling. We observe that\nmodern generative models share a conceptually similar training objective --\nreconstructing clean signals from corrupted inputs such as Gaussian noise or\nmasking -- a process we term denoising. Motivated by this insight, we propose\naligning tokenizer embeddings directly with the downstream denoising objective,\nencouraging latent embeddings to be more easily reconstructed even when heavily\ncorrupted. To achieve this, we introduce the Latent Denoising Tokenizer\n(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images\nfrom latent embeddings corrupted by interpolative noise and random masking.\nExtensive experiments on ImageNet 256x256 demonstrate that our tokenizer\nconsistently outperforms standard tokenizers across six representative\ngenerative models. Our findings highlight denoising as a fundamental design\nprinciple for tokenizer development, and we hope it could motivate new\nperspectives for future tokenizer design.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3al-DeTok\u7684\u65b0\u578b\u89c6\u89c9\u5206\u8bcd\u5668\uff0c\u901a\u8fc7\u5c06\u5206\u8bcd\u5668\u5d4c\u5165\u4e0e\u53bb\u566a\u76ee\u6807\u5bf9\u9f50\uff0c\u63d0\u9ad8\u4e86\u5176\u5728\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cl-DeTok\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6807\u51c6\u5206\u8bcd\u5668\uff0c\u5e76\u5f3a\u8c03\u4e86\u53bb\u566a\u4f5c\u4e3a\u5206\u8bcd\u5668\u8bbe\u8ba1\u5173\u952e\u539f\u5219\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u80fd\u591f\u4f7f\u89c6\u89c9\u5206\u8bcd\u5668\u66f4\u6709\u6548\u7684\u5c5e\u6027\u5c1a\u4e0d\u6e05\u695a\u7684\u95ee\u9898\u3002\u7814\u7a76\u8005\u89c2\u5bdf\u5230\uff0c\u73b0\u4ee3\u751f\u6210\u6a21\u578b\u6709\u4e00\u4e2a\u5171\u540c\u7684\u8bad\u7ec3\u76ee\u6807\u2014\u2014\u4ece\u635f\u574f\u7684\u8f93\u5165\u4e2d\u91cd\u5efa\u6e05\u6670\u4fe1\u53f7\uff0c\u5e76\u5c06\u6b64\u8fc7\u7a0b\u79f0\u4e3a\u53bb\u566a\u3002\u57fa\u4e8e\u6b64\u6d1e\u5bdf\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u5c06\u5206\u8bcd\u5668\u5d4c\u5165\u76f4\u63a5\u4e0e\u4e0b\u6e38\u53bb\u566a\u76ee\u6807\u5bf9\u9f50\uff0c\u4ee5\u9f13\u52b1\u6f5c\u5728\u5d4c\u5165\u5373\u4f7f\u5728\u4e25\u91cd\u635f\u574f\u7684\u60c5\u51b5\u4e0b\u4e5f\u6613\u4e8e\u91cd\u5efa\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6f5c\u5728\u53bb\u566a\u5206\u8bcd\u5668\uff08l-DeTok\uff09\u7684\u7b80\u5355\u800c\u6709\u6548\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7ecf\u8fc7\u8bad\u7ec3\uff0c\u80fd\u591f\u4ece\u53d7\u635f\u7684\u6f5c\u5728\u5d4c\u5165\u4e2d\u91cd\u5efa\u6e05\u6670\u7684\u56fe\u50cf\uff0c\u5176\u4e2d\u6f5c\u5728\u5d4c\u5165\u662f\u901a\u8fc7\u63d2\u503c\u566a\u58f0\u548c\u968f\u673a\u63a9\u7801\u635f\u574f\u7684\u3002", "result": "\u5728ImageNet 256x256\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684l-DeTok\u5206\u8bcd\u5668\u5728\u516d\u79cd\u4ee3\u8868\u6027\u751f\u6210\u6a21\u578b\u4e0a\uff0c\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6\u5206\u8bcd\u5668\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u53bb\u566a\u4f5c\u4e3a\u5206\u8bcd\u5668\u5f00\u53d1\u7684\u4e00\u4e2a\u57fa\u672c\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u5e0c\u671b\u8fd9\u80fd\u6fc0\u53d1\u672a\u6765\u5206\u8bcd\u5668\u8bbe\u8ba1\u7684\u65b0\u601d\u8def\u3002"}}
