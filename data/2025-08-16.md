<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning](https://arxiv.org/abs/2508.09325)
*Alexandre Brown,Glen Berseth*

Main category: cs.CV

TL;DR: SegDAC, a new method using SAM and YOLO-World for visual RL, enhances generalization and sample efficiency by decomposing tasks based on semantic segments, outperforming prior methods on challenging manipulation tasks.


<details>
  <summary>Details</summary>
Motivation: Visual reinforcement learning (RL) is challenging due to the need to learn both perception and actions from high-dimensional inputs and noisy rewards. Integrating large perception models effectively into RL for visual generalization and improved sample efficiency remains unclear.

Method: SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground segments semantically via text prompts. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels.

Result: SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks on the Maniskill3 benchmark.

Conclusion: SegDAC methods achieve significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks.

Abstract: Visual reinforcement learning (RL) is challenging due to the need to learn
both perception and actions from high-dimensional inputs and noisy rewards.
Although large perception models exist, integrating them effectively into RL
for visual generalization and improved sample efficiency remains unclear. We
propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment
Anything (SAM) for object-centric decomposition and YOLO-World to ground
segments semantically via text prompts. It includes a novel transformer-based
architecture that supports a dynamic number of segments at each time step and
effectively learns which segments to focus on using online RL, without using
human labels. By evaluating SegDAC over a challenging visual generalization
benchmark using Maniskill3, which covers diverse manipulation tasks under
strong visual perturbations, we demonstrate that SegDAC achieves significantly
better visual generalization, doubling prior performance on the hardest setting
and matching or surpassing prior methods in sample efficiency across all
evaluated tasks.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [2] [A Classical Quadratic Speedup for Planted $k$XOR](https://arxiv.org/abs/2508.09422)
*Meghal Gupta,William He,Ryan O'Donnell,Noah G. Singer*

Main category: cs.DS

TL;DR: 新经典算法在大型常数k时，比现有最佳算法快两倍，降低了量子加速比。


<details>
  <summary>Details</summary>
Motivation: 针对Schmidhuber等人提出的针对嘈杂已种植kXOR问题的量子算法，设计一种更快的经典算法。

Method: 结合了子线性时间算法（主要是生日悖论）和多项式反浓缩的工具。

Result: 新设计的经典算法速度是先前最佳算法的两倍，在大型常数k的情况下，将量子加速比从四倍降低到两倍。

Conclusion: 本文设计了一种新的经典算法，在大型常数k的情况下，其速度是先前最佳算法的两倍，从而将Schmidhuber等人的量子算法在这些k上的加速比从四倍降低到两倍，但量子算法仍然具有空间优势。该算法也适用于半随机情况。

Abstract: A recent work of Schmidhuber et al (QIP, SODA, & Phys. Rev. X 2025) exhibited
a quantum algorithm for the noisy planted $k$XOR problem running quartically
faster than all known classical algorithms. In this work, we design a new
classical algorithm that is quadratically faster than the best previous one, in
the case of large constant $k$. Thus for such $k$, the quantum speedup of
Schmidhuber et al. becomes only quadratic (though it retains a space
advantage). Our algorithm, which also works in the semirandom case, combines
tools from sublinear-time algorithms (essentially, the birthday paradox) and
polynomial anticoncentration.

</details>
