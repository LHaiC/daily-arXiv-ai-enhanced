<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 122]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 94]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [eess.SP](#eess.SP) [Total: 12]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 16]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.DS](#cs.DS) [Total: 3]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.DC](#cs.DC) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 11]
- [cs.SI](#cs.SI) [Total: 2]
- [quant-ph](#quant-ph) [Total: 32]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Context-aware Attention and Graph Neural Network-based Multimodal Framework for Misogyny Detection](https://arxiv.org/abs/2508.09175)
*Mohammad Zia Ur Rehman,Sufyaan Zahoor,Areeb Manzoor,Musharaf Maqbool,Nagendra Kumar*

Main category: cs.CV

TL;DR: 研究提出了一种新的多模态方法来检测针对女性的侮辱性内容，通过结合注意力机制、图神经网络和特定内容特征学习，并在两个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上约有2/3的冒犯性内容是针对女性的，而现有的通用冒犯性内容检测方法在检测针对女性的侮辱性内容方面存在挑战，因此需要专门的解决方案。

Method: 提出了一种包含多模态注意力模块（MANM）、基于图的特征重建模块（GFRM）和特定内容特征学习模块（CFLM）的新颖多模态框架。MANM采用自适应门控的多模态上下文感知注意力，GFRM利用图来优化单模态特征，CFLM专注于学习文本和图像的特定特征（如毒性特征和标题特征）。此外，研究还编制了侮辱性词典来计算文本的侮辱性评分，并采用测试时增强技术来提高模型在不同输入上的泛化能力。

Result: 所提出的方法在MAMI和MMHS150K两个多模态数据集上进行了评估，平均宏观F1得分分别比现有方法提高了10.17%和8.88%。

Conclusion: 该研究提出了一个新颖的多模态框架，用于检测针对女性的侮辱性和性别歧视内容，并在两个数据集上取得了显著的性能提升。

Abstract: A substantial portion of offensive content on social media is directed
towards women. Since the approaches for general offensive content detection
face a challenge in detecting misogynistic content, it requires solutions
tailored to address offensive content against women. To this end, we propose a
novel multimodal framework for the detection of misogynistic and sexist
content. The framework comprises three modules: the Multimodal Attention module
(MANM), the Graph-based Feature Reconstruction Module (GFRM), and the
Content-specific Features Learning Module (CFLM). The MANM employs adaptive
gating-based multimodal context-aware attention, enabling the model to focus on
relevant visual and textual information and generating contextually relevant
features. The GFRM module utilizes graphs to refine features within individual
modalities, while the CFLM focuses on learning text and image-specific features
such as toxicity features and caption features. Additionally, we curate a set
of misogynous lexicons to compute the misogyny-specific lexicon score from the
text. We apply test-time augmentation in feature space to better generalize the
predictions on diverse inputs. The performance of the proposed approach has
been evaluated on two multimodal datasets, MAMI and MMHS150K, with 11,000 and
13,494 samples, respectively. The proposed method demonstrates an average
improvement of 10.17% and 8.88% in macro-F1 over existing methods on the MAMI
and MMHS150K datasets, respectively.

</details>


### [2] [Event-driven Robust Fitting on Neuromorphic Hardware](https://arxiv.org/abs/2508.09466)
*Tam Ngoc-Bang Nguyen,Anh-Dzung Doan,Zhipeng Cai,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 通过在新兴的神经形态计算范式下利用脉冲神经网络，为计算机视觉中的鲁棒拟合任务实现了前所未有的能源效率，能耗显著降低。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的普及，AI 的高能耗问题日益严峻，因此需要关注鲁棒拟合任务的能源效率。

Method: 设计了一种新颖的脉冲神经网络（SNN）用于鲁棒拟合，并针对 Intel Loihi 2 神经形态硬件进行了优化，包括事件驱动的公式和算法策略以适应硬件限制。

Result: 与在标准 CPU 上运行的成熟鲁棒拟合算法相比，所提出的神经形态鲁棒拟合方法在达到同等准确性时，能耗仅为后者的 15%。

Conclusion: 所提出的神经形态方法在达到相当的准确性时，能耗仅为传统 CPU 方法的 15%，证明了其在能源效率方面的显著优势。

Abstract: Robust fitting of geometric models is a fundamental task in many computer
vision pipelines. Numerous innovations have been produced on the topic, from
improving the efficiency and accuracy of random sampling heuristics to
generating novel theoretical insights that underpin new approaches with
mathematical guarantees. However, one aspect of robust fitting that has
received little attention is energy efficiency. This performance metric has
become critical as high energy consumption is a growing concern for AI
adoption. In this paper, we explore energy-efficient robust fitting via the
neuromorphic computing paradigm. Specifically, we designed a novel spiking
neural network for robust fitting on real neuromorphic hardware, the Intel
Loihi 2. Enabling this are novel event-driven formulations of model estimation
that allow robust fitting to be implemented in the unique architecture of Loihi
2, and algorithmic strategies to alleviate the current limited precision and
instruction set of the hardware. Results show that our neuromorphic robust
fitting consumes only a fraction (15%) of the energy required to run the
established robust fitting algorithm on a standard CPU to equivalent accuracy.

</details>


### [3] [IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection](https://arxiv.org/abs/2508.09178)
*Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang*

Main category: cs.CV

TL;DR: 提出IAD-R1框架，通过两阶段训练策略（PA-SFT和SC-GRPO），显著提升了视觉语言模型在工业异常检测中的性能，甚至在零样本设置下超越了GPT-4.1和Claude-Sonnet-4。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在工业异常检测方面的性能有限，主要是由于制造业中缺陷样本的稀缺性限制了传统检测方法的应用。为了解决这一挑战，提出IAD-R1框架以提高VLM的通用异常检测能力。

Method: IAD-R1框架采用两阶段训练策略：第一阶段（PA-SFT）利用高质量的思维链数据集（Expert-AD）进行训练，以增强感知能力并建立推理与回答之间的关联；第二阶段（SC-GRPO）通过精心设计的奖励函数，实现从“异常感知”到“异常解释”的能力飞跃。

Result: IAD-R1在7个VLM上实现了显著的平均准确率提升，最高可达43.3%，并在6个工业异常检测基准数据集上表现出色。其训练的0.5B参数模型在零样本设置下超越了GPT-4.1和Claude-Sonnet-4。

Conclusion: IAD-R1是一个通用的视觉语言模型（VLM）的训练后框架，可显著提升其在工业异常检测方面的能力。实验结果表明，IAD-R1在7个不同的VLM上实现了显著的性能提升，在6个工业异常检测基准数据集上的平均准确率提升高达43.3%。特别地，使用IAD-R1训练的0.5B参数模型在零样本设置下超过了GPT-4.1和Claude-Sonnet-4等商业模型。

Abstract: Industrial anomaly detection is a critical component of modern manufacturing,
yet the scarcity of defective samples restricts traditional detection methods
to scenario-specific applications. Although Vision-Language Models (VLMs)
demonstrate significant advantages in generalization capabilities, their
performance in industrial anomaly detection remains limited. To address this
challenge, we propose IAD-R1, a universal post-training framework applicable to
VLMs of different architectures and parameter scales, which substantially
enhances their anomaly detection capabilities. IAD-R1 employs a two-stage
training strategy: the Perception Activation Supervised Fine-Tuning (PA-SFT)
stage utilizes a meticulously constructed high-quality Chain-of-Thought dataset
(Expert-AD) for training, enhancing anomaly perception capabilities and
establishing reasoning-to-answer correlations; the Structured Control Group
Relative Policy Optimization (SC-GRPO) stage employs carefully designed reward
functions to achieve a capability leap from "Anomaly Perception" to "Anomaly
Interpretation". Experimental results demonstrate that IAD-R1 achieves
significant improvements across 7 VLMs, attaining up to 43.3% enhancement in
average accuracy on 6 industrial anomaly detection benchmark datasets. Notably,
the 0.5B parameter model trained with IAD-R1 surpasses commercial models
including GPT-4.1 and Claude-Sonnet-4 in zero-shot settings, demonstrating the
effectiveness and superiority of IAD-R1. The dataset, code, and all model
weights will be publicly available at https://github.com/Yanhui-Lee/IAD-R1.

</details>


### [4] [A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality](https://arxiv.org/abs/2508.09185)
*Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan*

Main category: cs.CV

TL;DR: CADAR是一种新的神经符号方法，利用粒子滤波和多模态VLM来检测AR认知攻击，提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着AR的普及，旨在通过篡改AR内容来操纵用户感知的认知攻击日益受到关注。现有方法在语义推理和可解释性方面存在不足。

Method: CADAR是一种新颖的神经符号方法，通过融合多模态视觉-语言输入获得符号化感知图谱表示，并利用粒子滤波进行统计推理以检测认知攻击。

Result: 实验结果表明，在具有挑战性的AR攻击场景下，CADAR相比现有基线方法在准确性方面提高了10.7%。

Conclusion: CADAR通过结合预训练VLM的适应性和粒子滤波的可解释性与推理严谨性，在AR认知攻击检测方面展现出有效性和可解释性的潜力。

Abstract: Augmented Reality (AR) enriches perception by overlaying virtual elements on
the physical world. Due to its growing popularity, cognitive attacks that alter
AR content to manipulate users' semantic perception have received increasing
attention. Existing detection methods often focus on visual changes, which are
restricted to pixel- or image-level processing and lack semantic reasoning
capabilities, or they rely on pre-trained vision-language models (VLMs), which
function as black-box approaches with limited interpretability. In this paper,
we present CADAR, a novel neurosymbolic approach for cognitive attack detection
in AR. It fuses multimodal vision-language inputs using neural VLMs to obtain a
symbolic perception-graph representation, incorporating prior knowledge,
salience weighting, and temporal correlations. The model then enables
particle-filter based statistical reasoning -- a sequential Monte Carlo method
-- to detect cognitive attacks. Thus, CADAR inherits the adaptability of
pre-trained VLM and the interpretability and reasoning rigor of particle
filtering. Experiments on an extended AR cognitive attack dataset show accuracy
improvements of up to 10.7% over strong baselines on challenging AR attack
scenarios, underscoring the promise of neurosymbolic methods for effective and
interpretable cognitive attack detection.

</details>


### [5] [RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians](https://arxiv.org/abs/2508.09830)
*Shenxing Wei,Jinxi Li,Yafei Yang,Siyuan Zhou,Bo Yang*

Main category: cs.CV

TL;DR: RayletDF：一种通过光线投射距离场直接从查询光线预测表面点的新技术，实现了高效且泛化能力强的3D表面重建。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有基于坐标的方法在渲染显式表面时计算量大的问题，提出了一种直接从查询光线预测表面点的新技术。

Method: 提出了一种名为RayletDF的新技术，该技术通过光线投射距离场直接从查询光线预测表面点。该方法包含三个关键模块：光线投射特征提取器、光线投射距离场预测器和多光线投射融合器。

Result: 在多个公开的真实世界数据集上进行了广泛评估，展示了在点云或3D高斯点云表面重建方面的卓越性能。

Conclusion: 该方法在点云或3D高斯点云上实现了优越的表面重建性能，并在单次前向传播中实现了对未见数据集的卓越泛化能力。

Abstract: In this paper, we present a generalizable method for 3D surface
reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from
RGB images. Unlike existing coordinate-based methods which are often
computationally intensive when rendering explicit surfaces, our proposed
method, named RayletDF, introduces a new technique called raylet distance
field, which aims to directly predict surface points from query rays. Our
pipeline consists of three key modules: a raylet feature extractor, a raylet
distance field predictor, and a multi-raylet blender. These components work
together to extract fine-grained local geometric features, predict raylet
distances, and aggregate multiple predictions to reconstruct precise surface
points. We extensively evaluate our method on multiple public real-world
datasets, demonstrating superior performance in surface reconstruction from
point clouds or 3D Gaussians. Most notably, our method achieves exceptional
generalization ability, successfully recovering 3D surfaces in a single-forward
pass across unseen datasets in testing.

</details>


### [6] [RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System](https://arxiv.org/abs/2508.09186)
*Abdolazim Rezaei,Mehdi Sookhak,Mahboobeh Haghparast*

Main category: cs.CV

TL;DR: RL-MoE 是一种新颖的框架，可将敏感的视觉数据转换为保护隐私的文本描述，从而无需直接传输图像。


<details>
  <summary>Details</summary>
Motivation: AI 摄像头在智能交通系统（ITS）中的激增，在丰富的视觉数据需求与基本隐私权之间产生了严重冲突。现有的隐私保护机制（如模糊或加密）往往不足，导致在隐私受到攻击或数据效用严重下降之间做出不受欢迎的权衡。

Method: RL-MoE 框架结合了专家混合（MoE）架构进行细致的多方面场景分解，以及一个强化学习（RL）代理，该代理优化生成的文本，以实现语义准确性和隐私保护的双重目标。

Result: RL-MoE 在 CFP-FP 数据集上将重放攻击的成功率降低到仅 9.4%，同时生成比基线方法更丰富的文本内容。

Conclusion: RL-MoE 提供了一种实用的、可扩展的解决方案，用于在隐私敏感领域构建值得信赖的 AI 系统，为更安全智慧城市和自动驾驶汽车网络铺平了道路。

Abstract: The proliferation of AI-powered cameras in Intelligent Transportation Systems
(ITS) creates a severe conflict between the need for rich visual data and the
fundamental right to privacy. Existing privacy-preserving mechanisms, such as
blurring or encryption, are often insufficient, creating an undesirable
trade-off where either privacy is compromised against advanced reconstruction
attacks or data utility is critically degraded. To resolve this impasse, we
propose RL-MoE, a novel framework that transforms sensitive visual data into
privacy-preserving textual descriptions, eliminating the need for direct image
transmission. RL-MoE uniquely combines a Mixture-of-Experts (MoE) architecture
for nuanced, multi-aspect scene decomposition with a Reinforcement Learning
(RL) agent that optimizes the generated text for a dual objective of semantic
accuracy and privacy preservation. Extensive experiments demonstrate that
RL-MoE provides superior privacy protection, reducing the success rate of
replay attacks to just 9.4\% on the CFP-FP dataset, while simultaneously
generating richer textual content than baseline methods. Our work provides a
practical and scalable solution for building trustworthy AI systems in
privacy-sensitive domains, paving the way for more secure smart city and
autonomous vehicle networks.

</details>


### [7] [Story2Board: A Training-Free Approach for Expressive Storyboard Generation](https://arxiv.org/abs/2508.09983)
*David Dinkevich,Matan Levy,Omri Avrahami,Dvir Samuel,Dani Lischinski*

Main category: cs.CV

TL;DR: Story2Board is a new framework for generating storyboards from text. It improves consistency and visual storytelling aspects like composition and pacing without needing extra training. It uses methods like Latent Panel Anchoring and Reciprocal Attention Value Mixing, and an LLM for prompt structuring. It also introduces new evaluation metrics and benchmarks. User studies show it creates better storyboards than other methods.


<details>
  <summary>Details</summary>
Motivation: Existing storyboard generation methods focus narrowly on subject identity and overlook visual storytelling aspects like spatial composition, background evolution, and narrative pacing. Story2Board aims to address this by enhancing coherence without architectural changes or fine-tuning.

Method: Story2Board is a training-free framework for expressive storyboard generation from natural language. It uses a lightweight consistency framework with Latent Panel Anchoring (to preserve character reference across panels) and Reciprocal Attention Value Mixing (to blend visual features between token pairs with strong reciprocal attention). It also uses an off-the-shelf language model to convert stories into panel-level prompts.

Result: Story2Board enables state-of-the-art diffusion models to generate visually diverse yet consistent storyboards. The proposed Rich Storyboard Benchmark and Scene Diversity metric were used for evaluation.

Conclusion: Story2Board produces more dynamic, coherent, and narratively engaging storyboards than existing baselines, as demonstrated by qualitative and quantitative results and a user study.

Abstract: We present Story2Board, a training-free framework for expressive storyboard
generation from natural language. Existing methods narrowly focus on subject
identity, overlooking key aspects of visual storytelling such as spatial
composition, background evolution, and narrative pacing. To address this, we
introduce a lightweight consistency framework composed of two components:
Latent Panel Anchoring, which preserves a shared character reference across
panels, and Reciprocal Attention Value Mixing, which softly blends visual
features between token pairs with strong reciprocal attention. Together, these
mechanisms enhance coherence without architectural changes or fine-tuning,
enabling state-of-the-art diffusion models to generate visually diverse yet
consistent storyboards. To structure generation, we use an off-the-shelf
language model to convert free-form stories into grounded panel-level prompts.
To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain
narratives designed to assess layout diversity and background-grounded
storytelling, in addition to consistency. We also introduce a new Scene
Diversity metric that quantifies spatial and pose variation across storyboards.
Our qualitative and quantitative results, as well as a user study, show that
Story2Board produces more dynamic, coherent, and narratively engaging
storyboards than existing baselines.

</details>


### [8] [Synthetic Data Generation for Emotional Depth Faces: Optimizing Conditional DCGANs via Genetic Algorithms in the Latent Space and Stabilizing Training with Knowledge Distillation](https://arxiv.org/abs/2508.09188)
*Seyed Muhammad Hossein Mousavi,S. Younes Mirinezhad*

Main category: cs.CV

TL;DR: 通过结合知识蒸馏和遗传算法的优化GAN，生成了高质量、多样化的合成深度面部数据，显著提高了情感识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前深度面部数据集在识别细微情感表情方面存在的质量不高和多样性不足的问题。

Method: 提出了一种使用优化生成对抗网络（GAN）结合知识蒸馏（EMA teacher models）和遗传算法的框架，以生成用于情感识别的合成深度面部数据。该方法通过知识蒸馏稳定训练、提高数据质量并防止模式崩溃，同时利用遗传算法优化GAN潜在向量以增强数据多样性和视觉质量。

Result: 该框架在生成深度面部数据方面表现优于GAN、VAE、GMM和KDE等方法，在多样性和质量上均有提升。使用提取的LBP、HOG、Sobel边缘和强度直方图特征，结合XGBoost分类器，在情感识别任务中达到了94%和96%的准确率。FID、IS、SSIM和PSNR等评估指标也显示出相对于现有最先进方法的持续改进。

Conclusion: 生成的数据集在准确性和多样性方面优于现有方法，为情感识别提供了高质量的深度面部数据。

Abstract: Affective computing faces a major challenge: the lack of high-quality,
diverse depth facial datasets for recognizing subtle emotional expressions. We
propose a framework for synthetic depth face generation using an optimized GAN
with Knowledge Distillation (EMA teacher models) to stabilize training, improve
quality, and prevent mode collapse. We also apply Genetic Algorithms to evolve
GAN latent vectors based on image statistics, boosting diversity and visual
quality for target emotions. The approach outperforms GAN, VAE, GMM, and KDE in
both diversity and quality. For classification, we extract and concatenate LBP,
HOG, Sobel edge, and intensity histogram features, achieving 94% and 96%
accuracy with XGBoost. Evaluation using FID, IS, SSIM, and PSNR shows
consistent improvement over state-of-the-art methods.

</details>


### [9] [$Δ$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation](https://arxiv.org/abs/2508.09199)
*Jucheng Hu,Suorong Yang,Dongzhan Zhou*

Main category: cs.CV

TL;DR: $\\Delta$-AttnMask 是一种新的数据选择框架，用于视觉指令微调（VIF）。它通过量化样本质量来提高数据效率，仅用 20% 的数据就能达到比全数据集更好的性能，并显著加快训练速度。


<details>
  <summary>Details</summary>
Motivation: 视觉指令微调（VIF）是训练后视觉语言模型（VLMs）的关键，但它需要比单模态指令微调更多的数据，并且对数据选择提出了更严格的挑战，需要同时保证视觉和文本内容的质量及其对齐。然而，VIF 的数据选择仍然是一个研究不足的领域。

Method: 提出了一种名为 $\Delta$-AttnMask 的数据高效框架，该框架通过注意力引导的掩蔽模型隐藏状态来量化样本质量，联合评估图像-文本对，无需领域标签、辅助模型或额外训练。通过计算原始状态与使用高注意力区域掩蔽的状态之间的损失差异（$\Delta$），$\\Delta$-AttnMask 能够内在评估样本质量。

Result: 实验表明，$\Delta$-AttnMask 仅使用 20% 的数据即可达到最先进的性能，训练速度提高 5 倍，并且在整体准确率上比使用全部数据的基线提高了 +10.1%。

Conclusion: $\Delta$-AttnMask 是一种数据高效的框架，通过注意力引导的掩蔽来量化样本质量，能够跨模态和架构广泛应用。

Abstract: Visual Instruction Finetuning (VIF) is pivotal for post-training
Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in
plain-text large language models, which mainly requires instruction datasets to
enable model instruction-following ability, VIF also requires multimodal data
to enable joint visual and textual understanding; therefore, it typically
requires more data. Consequently, VIF imposes stricter data selection
challenges: the method must scale efficiently to handle larger data demands
while ensuring the quality of both visual and textual content, as well as their
alignment. Despite its critical impact on performance, data selection for VIF
remains an understudied area. In this paper, we propose $\Delta$-AttnMask. This
data-efficient framework quantifies sample quality through attention-guided
masking of the model's hidden states, jointly evaluating image-text pairs
without requiring domain labels, auxiliary models, or extra training. By
computing loss differences ($\Delta$) between the original states and states
masked using high-attention regions, $\Delta$-AttnMask intrinsically assesses
sample quality. Experiments across multiple VLMs and datasets show that
$\Delta$-AttnMask achieves state-of-the-art performance with just 20% of data,
accelerating training by 5x while surpassing full-dataset baselines by +10.1%
in overall accuracy. Its model-agnostic and data-agnostic design ensures broad
applicability across modalities and architectures.

</details>


### [10] [Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method](https://arxiv.org/abs/2508.09202)
*Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger*

Main category: cs.CV

TL;DR: 该研究提出了一种名为PFT的新型轻量级源无关领域自适应方法，用于面部表情识别。PFT在潜在空间进行特征翻译，仅使用中性表情的目标数据即可有效提升模型性能，同时避免了复杂的图像生成和高昂的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的源无关领域自适应（SFDA）方法在缺乏源数据且仅有中性表情的目标数据时，难以进行有效适应。这是因为SFDA方法通常不是为仅使用单一类别的目标数据进行自适应而设计的，而使用模型生成非中性表情的图像可能不稳定且计算成本高。因此，需要一种能够有效处理这种具有挑战性场景的新方法。

Method: 提出了一种名为个性化特征翻译（PFT）的方法，该方法在潜在空间中进行特征翻译。首先在源域数据上预训练翻译器，以将特定主体的风格特征从一个源主体转换为另一个。通过优化表达一致性和风格感知目标来保留表情信息。然后在没有源数据或图像合成的情况下，在仅包含中性表情的目标数据上对翻译器进行自适应。

Result: PFT方法通过在潜在空间进行翻译，避免了图像生成带来的复杂性和噪声，生成了可区分的嵌入，从而提高了 FER 模型的性能。与基于图像的翻译方法相比，PFT具有计算开销低、效率高（仅自适应模型的一部分）的优点。

Conclusion: 该研究提出了一种名为个性化特征翻译（PFT）的轻量级方法，用于解决面部表情识别（FER）模型在缺乏源数据且仅有中性表情目标数据时的领域自适应问题。PFT通过在潜在空间中进行特征翻译，保留表情信息，并优化表达一致性和风格感知目标，从而生成可区分的嵌入。该方法避免了图像生成带来的复杂性和计算开销，效率高于基于图像的翻译方法。

Abstract: Facial expression recognition (FER) models are employed in many video-based
affective computing applications, such as human-computer interaction and
healthcare monitoring. However, deep FER models often struggle with subtle
expressions and high inter-subject variability, limiting their performance in
real-world applications. To improve their performance, source-free domain
adaptation (SFDA) methods have been proposed to personalize a pretrained source
model using only unlabeled target domain data, thereby avoiding data privacy,
storage, and transmission constraints. This paper addresses a challenging
scenario where source data is unavailable for adaptation, and only unlabeled
target data consisting solely of neutral expressions is available. SFDA methods
are not typically designed to adapt using target data from only a single class.
Further, using models to generate facial images with non-neutral expressions
can be unstable and computationally intensive. In this paper, personalized
feature translation (PFT) is proposed for SFDA. Unlike current image
translation methods for SFDA, our lightweight method operates in the latent
space. We first pre-train the translator on the source domain data to transform
the subject-specific style features from one source subject into another.
Expression information is preserved by optimizing a combination of expression
consistency and style-aware objectives. Then, the translator is adapted on
neutral target data, without using source data or image synthesis. By
translating in the latent space, PFT avoids the complexity and noise of face
expression generation, producing discriminative embeddings optimized for
classification. Using PFT eliminates the need for image synthesis, reduces
computational overhead (using a lightweight translator), and only adapts part
of the model, making the method efficient compared to image-based translation.

</details>


### [11] [GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning](https://arxiv.org/abs/2508.09207)
*Tai Vu,Robert Yang*

Main category: cs.CV

TL;DR: 本研究评估了在漫画和动画行业中，使用神经风格迁移、C-GAN和CycleGAN将素描转化为全彩色图画的多种模型，发现C-GAN在生成高质量、高分辨率和接近人工效果的图像方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 生成全彩色图画的过程是漫画和动画行业中一个巨大且通常成本高昂的瓶颈。

Method: 本研究使用神经风格迁移、C-GAN和CycleGAN等多个模型对动漫角色及其素描之间的图像到图像翻译进行了研究。

Result: 通过定性和定量评估，发现C-GAN在产生高质量、高分辨率和接近人工效果的图像方面最为有效。

Conclusion: C-GAN是能够产生高质量、高分辨率且接近人工效果的图像的最有效模型。

Abstract: The process of generating fully colorized drawings from sketches is a large,
usually costly bottleneck in the manga and anime industry. In this study, we
examine multiple models for image-to-image translation between anime characters
and their sketches, including Neural Style Transfer, C-GAN, and CycleGAN. By
assessing them qualitatively and quantitatively, we find that C-GAN is the most
effective model that is able to produce high-quality and high-resolution images
close to those created by humans.

</details>


### [12] [MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models](https://arxiv.org/abs/2508.09210)
*Fan Zhang,Zebang Cheng,Chong Deng,Haoxuan Li,Zheng Lian,Qian Chen,Huadai Liu,Wen Wang,Yi-Fan Zhang,Renrui Zhang,Ziyu Guo,Zhihong Zhu,Hao Wu,Haixin Wang,Yefeng Zheng,Xiaojiang Peng,Xian Wu,Kun Wang,Xiangang Li,Jieping Ye,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 本研究提出了 MME-Emotion，一个包含 6000 多个视频片段的 MLLMs 情感基准，以评估其情感理解和推理能力。结果显示，当前 MLLMs 的情感智能尚不成熟，通用模型和专业模型各有优劣。


<details>
  <summary>Details</summary>
Motivation: 当前的情感基准在评估 MLLMs 的泛化能力和识别情绪触发因素的推理能力方面存在局限性。为了弥补这些不足，本研究提出了 MME-Emotion 基准，以系统地评估 MLLMs 的情感理解和推理能力。

Method: 本研究提出了 MME-Emotion 基准，该基准通过包含超过 6000 个视频片段和任务特定 QA 对，跨越广泛场景，制定了八种情感任务，来评估 MLLMs 的情感理解和推理能力。它还包含一个包含混合指标的整体评估套件，用于情感识别和推理，并通过多智能体系统框架进行分析。

Result: 通过对 20 种先进 MLLMs 的严格评估，我们发现当前 MLLMs 的情感智能尚不令人满意，最佳模型的识别得分为 39.3%，链式思考得分为 56.0%。通用模型（如 Gemini-2.5-Pro）通过通用的多模态理解能力获得情感智能，而专业模型（如 R1-Omni）可以通过特定领域的后训练适应获得相当的性能。

Conclusion: MME-Emotion 是一个评估 MLLMs 情感理解和推理能力的系统性基准，包含超过 6000 个视频片段和 QA 对，涵盖八种情感任务。通过对 20 种先进 MLLMs 的严格评估，我们发现它们的情感智能尚不令人满意，最佳模型的识别得分为 39.3%，链式思考得分为 56.0%。通用模型（如 Gemini-2.5-Pro）从通用的多模态理解能力中获得情感智能，而专业模型（如 R1-Omni）可以通过特定领域的后训练适应获得相当的性能。MME-Emotion 有望为未来 MLLMs 情感智能的进步奠定基础。

Abstract: Recent advances in multimodal large language models (MLLMs) have catalyzed
transformative progress in affective computing, enabling models to exhibit
emergent emotional intelligence. Despite substantial methodological progress,
current emotional benchmarks remain limited, as it is still unknown: (a) the
generalization abilities of MLLMs across distinct scenarios, and (b) their
reasoning capabilities to identify the triggering factors behind emotional
states. To bridge these gaps, we present \textbf{MME-Emotion}, a systematic
benchmark that assesses both emotional understanding and reasoning capabilities
of MLLMs, enjoying \textit{scalable capacity}, \textit{diverse settings}, and
\textit{unified protocols}. As the largest emotional intelligence benchmark for
MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific
questioning-answering (QA) pairs, spanning broad scenarios to formulate eight
emotional tasks. It further incorporates a holistic evaluation suite with
hybrid metrics for emotion recognition and reasoning, analyzed through a
multi-agent system framework. Through a rigorous evaluation of 20 advanced
MLLMs, we uncover both their strengths and limitations, yielding several key
insights: \ding{182} Current MLLMs exhibit unsatisfactory emotional
intelligence, with the best-performing model achieving only $39.3\%$
recognition score and $56.0\%$ Chain-of-Thought (CoT) score on our benchmark.
\ding{183} Generalist models (\emph{e.g.}, Gemini-2.5-Pro) derive emotional
intelligence from generalized multimodal understanding capabilities, while
specialist models (\emph{e.g.}, R1-Omni) can achieve comparable performance
through domain-specific post-training adaptation. By introducing MME-Emotion,
we hope that it can serve as a foundation for advancing MLLMs' emotional
intelligence in the future.

</details>


### [13] [Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity](https://arxiv.org/abs/2508.09218)
*Zuoou Li,Weitong Zhang,Jingyuan Wang,Shuyuan Zhang,Wenjia Bai,Bernhard Kainz,Mengyun Qiao*

Main category: cs.CV

TL;DR: 本研究提出了一个更严格的评估框架和一种名为BSD的新型越狱策略，该策略通过平衡提示的相关性和新颖性，成功提高了对多模态大语言模型的攻击效果，揭示了当前多模态安全系统的不足。


<details>
  <summary>Details</summary>
Motivation: 现有针对多模态大语言模型的越狱策略的评估标准可能高估了其有效性，因为许多被标记为成功的响应实际上是良性的、模糊的或与恶意目标无关。本研究旨在提出一个更严格的评估框架，并开发一种更有效的越狱策略。

Method: 提出了一种名为BSD（Balanced Structural Decomposition）的递归重写策略，该策略将恶意提示重构为语义对齐的子任务，同时引入细微的OOD信号和视觉线索以逃避检测。并使用一个包含输入相关性、输入OOD强度、输出有害性和输出拒绝率的四轴评估框架。

Result: BSD策略在13个商业和开源多模态大语言模型上进行了测试，结果显示该策略能持续提高攻击成功率、有害输出比例，并降低拒绝率。与先前的方法相比，BSD策略将成功率提高了67%，有害性提高了21%。

Conclusion: 该研究引入了一个新的四轴评估框架，用于评估针对多模态大语言模型的越狱攻击的有效性，并提出了一种名为BSD（Balanced Structural Decomposition）的递归重写策略，通过平衡提示的相关性和新颖性来提高攻击成功率和有害输出的比例，揭示了当前多模态安全系统的一个弱点。

Abstract: Multimodal large language models (MLLMs) are widely used in vision-language
reasoning tasks. However, their vulnerability to adversarial prompts remains a
serious concern, as safety mechanisms often fail to prevent the generation of
harmful outputs. Although recent jailbreak strategies report high success
rates, many responses classified as "successful" are actually benign, vague, or
unrelated to the intended malicious goal. This mismatch suggests that current
evaluation standards may overestimate the effectiveness of such attacks. To
address this issue, we introduce a four-axis evaluation framework that
considers input on-topicness, input out-of-distribution (OOD) intensity, output
harmfulness, and output refusal rate. This framework identifies truly effective
jailbreaks. In a substantial empirical study, we reveal a structural trade-off:
highly on-topic prompts are frequently blocked by safety filters, whereas those
that are too OOD often evade detection but fail to produce harmful content.
However, prompts that balance relevance and novelty are more likely to evade
filters and trigger dangerous output. Building on this insight, we develop a
recursive rewriting strategy called Balanced Structural Decomposition (BSD).
The approach restructures malicious prompts into semantically aligned
sub-tasks, while introducing subtle OOD signals and visual cues that make the
inputs harder to detect. BSD was tested across 13 commercial and open-source
MLLMs, where it consistently led to higher attack success rates, more harmful
outputs, and fewer refusals. Compared to previous methods, it improves success
rates by $67\%$ and harmfulness by $21\%$, revealing a previously
underappreciated weakness in current multimodal safety systems.

</details>


### [14] [Towards Scalable Training for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.09220)
*Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong*

Main category: cs.CV

TL;DR: 通过开发数据引擎和TexTeller模型，解决了HMER数据稀缺的问题，并取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别（HMER）领域由于手动标注过程艰巨且成本高昂，导致数据稀缺，从而阻碍了其发展。

Method: 通过开发可扩展的数据引擎来整合有限的手写公式和大规模的LaTeX渲染公式，生成复杂且一致的LaTeX序列，并在此基础上训练了TexTeller模型。

Result: TexTeller在近乎所有基准测试中都达到了最先进（SOTA）的性能，我们构建了迄今为止最大的公式数据集Tex80M，其中包含超过8000万个高质量的训练实例。

Conclusion: 我们将公开我们的完整模型、完整数据集和完整的代码库，以支持在此基础上进行进一步研究。

Abstract: Large foundation models have achieved significant performance gains through
scalable training on massive datasets. However, the field of
\textbf{H}andwritten \textbf{M}athematical \textbf{E}xpression
\textbf{R}ecognition (HMER) has been impeded by the scarcity of data, primarily
due to the arduous and costly process of manual annotation. To bridge this gap,
we propose a novel method integrating limited handwritten formulas with
large-scale LaTeX-rendered formulas by developing a scalable data engine to
generate complex and consistent LaTeX sequences. With this engine, we built the
largest formula dataset to date, termed \texttt{Tex80M}, comprising over 80
million high-quality training instances. Then we propose \texttt{TexTeller},
the first HMER model trained at scale, by mix-training \texttt{Tex80M} with a
relatively small HME dataset. The expansive training dataset and our refined
pipeline have equipped \texttt{TexTeller} with state-of-the-art (SOTA)
performance across nearly all benchmarks. To advance the field, we will openly
release our complete model, entire dataset, and full codebase, enabling further
research building upon our contributions.

</details>


### [15] [Gradient-Direction-Aware Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2508.09239)
*Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Jia-Chen Zhang,Hong-Jian Zhan*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced
novel view synthesis through explicit scene representation, enabling real-time
photorealistic rendering. However, existing approaches manifest two critical
limitations in complex scenarios: (1) Over-reconstruction occurs when
persistent large Gaussians cannot meet adaptive splitting thresholds during
density control. This is exacerbated by conflicting gradient directions that
prevent effective splitting of these Gaussians; (2) Over-densification of
Gaussians occurs in regions with aligned gradient aggregation, leading to
redundant component proliferation. This redundancy significantly increases
memory overhead due to unnecessary data retention. We present
Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware
adaptive density control framework to address these challenges. Our key
innovations: the gradient coherence ratio (GCR), computed through normalized
gradient vector norms, which explicitly discriminates Gaussians with concordant
versus conflicting gradient directions; and a nonlinear dynamic weighting
mechanism leverages the GCR to enable gradient-direction-aware density control.
Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting
operations to enhance geometric details while suppressing redundant
concordant-direction Gaussians. Conversely, in cloning processes, GDAGS
promotes concordant-direction Gaussian densification for structural completion
while preventing conflicting-direction Gaussian overpopulation. Comprehensive
evaluations across diverse real-world benchmarks demonstrate that GDAGS
achieves superior rendering quality while effectively mitigating
over-reconstruction, suppressing over-densification, and constructing compact
scene representations with 50\% reduced memory consumption through optimized
Gaussians utilization.

</details>


### [16] [FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents](https://arxiv.org/abs/2508.09241)
*Fengxian Ji,Jingpu Yang,Zirui Song,Yuanxi Wang,Zhexuan Cui,Yuke Li,Qian Jiang,Miao Fang,Xiuying Chen*

Main category: cs.CV

TL;DR: FineState-Bench是首个用于评估GUI代理细粒度控制能力的基准，结果显示现有模型表现不佳，视觉定位是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI代理评估框架过于关注粗粒度的任务完成，而忽略了对现实世界应用至关重要的细粒度控制能力。需要一个能够量化细粒度控制的标准。

Method: 提出FineState-Bench，一个包含2257个任务基准的多平台（桌面、Web、移动）评估和诊断标准，用于量化细粒度控制。引入即插即用的视觉诊断助手（VDA），用于分析感知和定位能力，实现首次定量解耦分析。

Result: 最先进的模型在FineState-Bench上的细粒度交互准确率仅为32.8%。视觉诊断助手（VDA）的实验表明，理想的视觉定位可以将Gemini-2.5-Flash的成功率提高14.9%。

Conclusion: 当前最先进的GUI代理在细粒度交互方面的准确率仅为32.8%，主要的瓶颈在于基础的视觉定位能力。通过使用视觉诊断助手（VDA）进行对照实验，证明了理想的视觉定位可以将Gemini-2.5-Flash的成功率提高14.9%。

Abstract: With the rapid advancement of generative artificial intelligence technology,
Graphical User Interface (GUI) agents have demonstrated tremendous potential
for autonomously managing daily tasks through natural language instructions.
However, current evaluation frameworks for GUI agents suffer from fundamental
flaws: existing benchmarks overly focus on coarse-grained task completion while
neglecting fine-grained control capabilities crucial for real-world
applications. To address this, we introduce FineState-Bench, the first
evaluation and diagnostic standard for fine-grained GUI proxy operations,
designed to quantify fine-grained control. This multi-platform (desktop, Web,
mobile) framework includes 2257 task benchmarks in four components and uses a
four-phase indicator for comprehensive perception-to-control assessment. To
analyze perception and positioning for refined operations, we developed the
plug-and-play Visual Diagnostic Assistant (VDA), enabling the first
quantitative decoupling analysis of these capabilities. Experimental results on
our benchmark show that the most advanced models achieve only 32.8%
fine-grained interaction accuracy. Using our VDA in controlled experiments,
quantifying the impact of visual capabilities, we showed that ideal visual
localization boosts Gemini-2.5-Flash's success rate by 14.9\%. Our diagnostic
framework confirms for the first time that the primary bottleneck for current
GUI proxies is basic visual positioning capability.All resources are fully
open-source. github: https://github.com/AnonymousThewarehouse/FineState-Bench
huggingface: https://huggingface.co/datasets/Willtime2006/Static-FineBench

</details>


### [17] [Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users](https://arxiv.org/abs/2508.09245)
*Jeffri Murrugarra-LLerena,Haoran Niu,K. Suzanne Barber,Hal Daumé III,Yang Trista Cao,Paola Cascante-Bonilla*

Main category: cs.CV

TL;DR: FiGPriv是一种新的隐私保护框架，通过细粒度分割和风险评分，选择性地隐藏敏感信息，提高了图像内容的可用性和视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私保护方法依赖于粗粒度的分割，将整个私人对象统一掩码，牺牲了可用性。本研究旨在解决视觉助手系统中用户隐私问题，特别是对于可能在图像中无意捕获个人隐私信息的盲人和低视力用户。

Method: FiGPriv提出了一种细粒度隐私保护框架，结合了细粒度分割和数据驱动的风险评分机制，选择性地隐藏高风险的私人信息，同时保留低风险信息。

Result: FiGPriv框架在保留图像内容方面表现优于现有方法，同时有效保护了用户隐私。

Conclusion: FiGPriv框架在保证隐私安全的前提下，显著提高了图像内容的保留率（+26%），增强了视觉语言模型（VLMs）提供有用响应（+11%）和识别图像内容（+45%）的能力。

Abstract: As visual assistant systems powered by visual language models (VLMs) become
more prevalent, concerns over user privacy have grown, particularly for blind
and low vision users who may unknowingly capture personal private information
in their images. Existing privacy protection methods rely on coarse-grained
segmentation, which uniformly masks entire private objects, often at the cost
of usability. In this work, we propose FiGPriv, a fine-grained privacy
protection framework that selectively masks only high-risk private information
while preserving low-risk information. Our approach integrates fine-grained
segmentation with a data-driven risk scoring mechanism. We evaluate our
framework using the BIV-Priv-Seg dataset and show that FiG-Priv preserves +26%
of image content, enhancing the ability of VLMs to provide useful responses by
11% and identify the image content by 45%, while ensuring privacy protection.
Project Page: https://artcs1.github.io/VLMPrivacy/

</details>


### [18] [Harnessing Input-Adaptive Inference for Efficient VLN](https://arxiv.org/abs/2508.09262)
*Dongwoo Kang,Akhil Perincherry,Zachary Coalson,Aiden Gabriel,Stefan Lee,Sanghyun Hong*

Main category: cs.CV

TL;DR: 针对VLN模型效率问题，提出一种输入自适应导航方法，通过处理视角、模型内计算和时间效率的优化，在不牺牲性能的情况下将计算量减少一倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有的基于历史的多模态 Transformer 模型在视觉-语言导航（VLN）任务中表现出色，但其巨大的模型规模在计算资源有限的实际应用中可能成为瓶颈。

Method: 提出了一种新颖的输入自适应导航方法，通过在不同层面部署三种自适应算法：1. 空间效率：选择性处理智能体在每次观察时看到的のでパノラマ视图。2. 模型内效率：为早期退出方法提出基于重要性的自适应阈值。3. 时间效率：实现一个缓存机制，防止重复处理先前已经看到的视图。

Result: 在七个VLN基准测试中，实现了超过2倍的计算量减少，并且在标准和连续环境中都适用于三种现成的智能体。

Conclusion: 所提出的输入自适应方法在七个VLN基准测试中，将三种现成智能体的计算量减少了一倍以上，同时保持了性能。

Abstract: An emerging paradigm in vision-and-language navigation (VLN) is the use of
history-aware multi-modal transformer models. Given a language instruction,
these models process observation and navigation history to predict the most
appropriate action for an agent. While they have significantly improved
performance, the scale of these models can be a bottleneck in practical
settings with limited computational resources. In this work, we propose a novel
input-adaptive navigation method to enhance VLN model efficiency. We first show
that existing input-adaptive mechanisms fail to reduce computations without
substantial performance degradation. To address this, we introduce three
adaptive algorithms, each deployed at a different level: (1) To improve spatial
efficiency, we selectively process panoramic views at each observation of an
agent. (2) To improve intra-model efficiency, we propose importance-based
adaptive thresholding for the early-exit methods. (3) To improve temporal
efficiency, we implement a caching mechanism that prevents reprocessing of
views previously seen by the agent. In evaluations on seven VLN benchmarks, we
demonstrate over a 2$\times$ reduction in computation across three
off-the-shelf agents in both standard and continuous environments. Our code is
publicly available at
https://github.com/secure-ai-systems-group/adaptive-vision-and-language-navigation.

</details>


### [19] [Offline Auto Labeling: BAAS](https://arxiv.org/abs/2508.09585)
*Stefan Haag,Bharanidhar Duraisamy,Felix Govaers,Wolfgang Koch,Martin Fritzsche,Juergen Dickmann*

Main category: cs.CV

TL;DR: BAAS是一个用于雷达检测的扩展目标跟踪和标签注释框架，提供准确的目标轨迹和形状估计，并支持不同监督水平和闭环改进。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为自动驾驶汽车中的雷达检测数据提供一种新的扩展目标跟踪（EOT）和基于融合的标签注释框架，以提高目标轨迹和形状估计的准确性，并为检测数据提供标签注释。

Method: 本研究提出了一种名为BAAS的框架，该框架结合了扩展目标跟踪（EOT）和基于融合的标签注释方法，用于处理来自自动驾驶汽车雷达的检测数据。该框架采用了基于贝叶斯的方法进行跟踪和平滑处理，并结合了多种融合技术，以提供准确可靠的目标轨迹和形状估计，从而在不同监督水平下为检测数据提供标签注释。同时，该框架还能对跟踪性能和标签注释进行评估。如果存在手动标记的数据，则可以独立分析或组合各个处理模块，以实现闭环的持续改进。

Result: BAAS框架能够提供精确的目标轨迹和形状估计，从而实现标签注释，并且可以评估跟踪性能和标签注释的准确性。

Conclusion: 该框架在具有挑战性的城市真实场景中进行了评估，证明了其在跟踪性能和标签注释错误方面的有效性，并展示了其针对不同动态对象和类别类型的多功能性。

Abstract: This paper introduces BAAS, a new Extended Object Tracking (EOT) and
fusion-based label annotation framework for radar detections in autonomous
driving. Our framework utilizes Bayesian-based tracking, smoothing and
eventually fusion methods to provide veritable and precise object trajectories
along with shape estimation to provide annotation labels on the detection level
under various supervision levels. Simultaneously, the framework provides
evaluation of tracking performance and label annotation. If manually labeled
data is available, each processing module can be analyzed independently or
combined with other modules to enable closed-loop continuous improvements. The
framework performance is evaluated in a challenging urban real-world scenario
in terms of tracking performance and the label annotation errors. We
demonstrate the functionality of the proposed approach for varying dynamic
objects and class types

</details>


### [20] [SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning](https://arxiv.org/abs/2508.09325)
*Alexandre Brown,Glen Berseth*

Main category: cs.CV

TL;DR: SegDAC 是一种新的视觉强化学习方法，它使用分割和语言提示来提高泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习（RL）由于需要从高维输入和有噪声的奖励中学习感知和动作而具有挑战性。尽管存在大型感知模型，但如何将它们有效地整合到 RL 中以实现视觉泛化和提高样本效率仍不清楚。

Method: SegDAC 是一种基于分割的 Actor-Critic 方法，它利用 Segment Anything (SAM) 进行面向对象的分解，并利用 YOLO-World 通过文本提示进行语义基础。它采用一种新颖的、基于 Transformer 的架构，该架构支持每个时间步长动态数量的分割，并通过在线 RL 有效地学习关注哪些分割，而无需人工标签。

Result: SegDAC 在 Maniskill3 上进行了评估，该基准测试涵盖了在强视觉扰动下的各种操作任务。

Conclusion: SegDAC 在具有挑战性的视觉泛化基准测试中取得了显著的改进，在最困难的情况下性能翻倍，并在所有评估的任务中与先前方法相比在样本效率方面相匹配或超越了先前的方法。

Abstract: Visual reinforcement learning (RL) is challenging due to the need to learn
both perception and actions from high-dimensional inputs and noisy rewards.
Although large perception models exist, integrating them effectively into RL
for visual generalization and improved sample efficiency remains unclear. We
propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment
Anything (SAM) for object-centric decomposition and YOLO-World to ground
segments semantically via text prompts. It includes a novel transformer-based
architecture that supports a dynamic number of segments at each time step and
effectively learns which segments to focus on using online RL, without using
human labels. By evaluating SegDAC over a challenging visual generalization
benchmark using Maniskill3, which covers diverse manipulation tasks under
strong visual perturbations, we demonstrate that SegDAC achieves significantly
better visual generalization, doubling prior performance on the hardest setting
and matching or surpassing prior methods in sample efficiency across all
evaluated tasks.

</details>


### [21] [Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model](https://arxiv.org/abs/2508.09327)
*Yifan Jiang,Ahmad Shariftabrizi,Venkata SK. Manem*

Main category: cs.CV

TL;DR: Lung-DDPM+ 通过结合语义布局和 DPM-solver，显著提高了生成胸部 CT 图像（含肺结节）的效率和质量，计算资源消耗更低，潜力巨大。


<details>
  <summary>Details</summary>
Motivation: 现有的用于肺结节诊断的生成模型存在效率低下和解剖学不精确的问题，限制了其临床应用。为了解决这些问题，需要提出一种更优化的模型。

Method: 提出了一种改进的 DDPM 模型 Lung-DDPM+，通过结合结节语义布局和 DPM-solver 加速，提高了采样效率并优化了计算资源消耗。

Result: Lung-DDPM+ 的 FLOPs、GPU 内存消耗和采样速度均得到显著改善（分别为原来的 1/8、1/6.8 和 1/14），同时在下游分割任务中保持了与 Lung-DDPM 和其他 SOTA 模型相当的样本质量。放射科医生的视觉图灵测试结果也证明了其生成样本的高质量和保真度。

Conclusion: Lung-DDPM+ 在胸部 CT 图像生成方面表现出色，能够生成包含肺结节的高质量图像，并在诊断任务中展现出巨大潜力。

Abstract: Generative artificial intelligence (AI) has been playing an important role in
various domains. Leveraging its high capability to generate high-fidelity and
diverse synthetic data, generative AI is widely applied in diagnostic tasks,
such as lung cancer diagnosis using computed tomography (CT). However, existing
generative models for lung cancer diagnosis suffer from low efficiency and
anatomical imprecision, which limit their clinical applicability. To address
these drawbacks, we propose Lung-DDPM+, an improved version of our previous
model, Lung-DDPM. This novel approach is a denoising diffusion probabilistic
model (DDPM) guided by nodule semantic layouts and accelerated by a pulmonary
DPM-solver, enabling the method to focus on lesion areas while achieving a
better trade-off between sampling efficiency and quality. Evaluation results on
the public LIDC-IDRI dataset suggest that the proposed method achieves
8$\times$ fewer FLOPs (floating point operations per second), 6.8$\times$ lower
GPU memory consumption, and 14$\times$ faster sampling compared to Lung-DDPM.
Moreover, it maintains comparable sample quality to both Lung-DDPM and other
state-of-the-art (SOTA) generative models in two downstream segmentation tasks.
We also conducted a Visual Turing Test by an experienced radiologist, showing
the advanced quality and fidelity of synthetic samples generated by the
proposed method. These experimental results demonstrate that Lung-DDPM+ can
effectively generate high-quality thoracic CT images with lung nodules,
highlighting its potential for broader applications, such as general tumor
synthesis and lesion generation in medical imaging. The code and pretrained
models are available at https://github.com/Manem-Lab/Lung-DDPM-PLUS.

</details>


### [22] [UltraLight Med-Vision Mamba for Classification of Neoplastic Progression in Tubular Adenomas](https://arxiv.org/abs/2508.09339)
*Aqsa Sultana,Nordin Abouzahra,Ahmed Rahu,Brian Shula,Brandon Combs,Derrick Forchetti,Theus Aspiras,Vijayan K. Asari*

Main category: cs.CV

TL;DR: Deep learning models like Ultralight Med-Vision Mamba can improve polyp detection during colonoscopies to prevent colorectal cancer.


<details>
  <summary>Details</summary>
Motivation: The identification and excision of precancerous polyps during colonoscopy are crucial for reducing colorectal cancer risk. Advanced deep learning can improve risk assessment and personalize surveillance.

Method: Deep learning algorithms, specifically Ultralight Med-Vision Mamba (a state-space based model), are used for precise adenoma classification and stratification.

Result: Advanced deep learning algorithms enable precise adenoma classification and stratification, improving risk assessment accuracy and enabling personalized surveillance protocols. Ultralight Med-Vision Mamba excels in modeling dependencies and image generalization, with an efficient architecture beneficial for clinical deployment.

Conclusion: Ultralight Med-Vision Mamba, a state-space based model (SSM), shows promise for real-time clinical deployment in identifying precancerous polyps during colonoscopy due to its efficient architecture and ability to model long- and short-range dependencies and image generalization.

Abstract: Identification of precancerous polyps during routine colonoscopy screenings
is vital for their excision, lowering the risk of developing colorectal cancer.
Advanced deep learning algorithms enable precise adenoma classification and
stratification, improving risk assessment accuracy and enabling personalized
surveillance protocols that optimize patient outcomes. Ultralight Med-Vision
Mamba, a state-space based model (SSM), has excelled in modeling long- and
short-range dependencies and image generalization, critical factors for
analyzing whole slide images. Furthermore, Ultralight Med-Vision Mamba's
efficient architecture offers advantages in both computational speed and
scalability, making it a promising tool for real-time clinical deployment.

</details>


### [23] [Blink-to-code: real-time Morse code communication via eye blink detection and classification](https://arxiv.org/abs/2508.09344)
*Anushka Bhatt*

Main category: cs.CV

TL;DR: Real-time eye blink to Morse code translator using webcam and computer vision achieves 62% accuracy for assistive communication.


<details>
  <summary>Details</summary>
Motivation: To enable communication for individuals with severe motor impairments.

Method: A real-time system using a standard webcam and computer vision to detect and classify voluntary eye blinks as short (dot) or long (dash), then decoding them into alphanumeric characters.

Result: Experiments with five participants showed 62% decoding accuracy and 18-20 seconds response times.

Conclusion: The study demonstrates a viable, low-cost assistive communication method for individuals with severe motor impairments using a real-time eye blink to Morse code translation system.

Abstract: This study proposes a real-time system that translates voluntary eye blinks
into Morse code, enabling communication for individuals with severe motor
impairments. Using a standard webcam and computer vision, the system detects
and classifies blinks as short (dot) or long (dash), then decodes them into
alphanumeric characters. Experiments with five participants show 62% decoding
accuracy and 18-20 seconds response times, demonstrating a viable, low-cost
assistive communication method.

</details>


### [24] [FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition](https://arxiv.org/abs/2508.09362)
*Md. Milon Islam,Md Rezwanul Haque,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: FusionEnsemble-Net is a new method using fused data from video and radar to recognize Italian Sign Language gestures, achieving 99.44% accuracy.


<details>
  <summary>Details</summary>
Motivation: Accurate recognition of sign language in healthcare communication poses a significant challenge, requiring frameworks that can accurately interpret complex multimodal gestures.

Method: FusionEnsemble-Net proposes a novel attention-based ensemble of spatiotemporal networks that dynamically fuses visual and motion data. It processes RGB video and range Doppler map radar modalities synchronously through four different spatiotemporal networks. Features from both modalities are continuously fused using an attention-based fusion module before being fed into an ensemble of classifiers. The outputs of these four different fused channels are combined in an ensemble classification head.

Result: FusionEnsemble-Net outperforms state-of-the-art approaches with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for Italian Sign Language.

Conclusion: FusionEnsemble-Net, an ensemble of diverse spatiotemporal networks unified by attention-based fusion, yields a robust and accurate framework for complex, multimodal isolated gesture recognition tasks.

Abstract: Accurate recognition of sign language in healthcare communication poses a
significant challenge, requiring frameworks that can accurately interpret
complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net,
a novel attention-based ensemble of spatiotemporal networks that dynamically
fuses visual and motion data to enhance recognition accuracy. The proposed
approach processes RGB video and range Doppler map radar modalities
synchronously through four different spatiotemporal networks. For each network,
features from both modalities are continuously fused using an attention-based
fusion module before being fed into an ensemble of classifiers. Finally, the
outputs of these four different fused channels are combined in an ensemble
classification head, thereby enhancing the model's robustness. Experiments
demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches
with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for
Italian Sign Language. Our findings indicate that an ensemble of diverse
spatiotemporal networks, unified by attention-based fusion, yields a robust and
accurate framework for complex, multimodal isolated gesture recognition tasks.
The source code is available at:
https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.

</details>


### [25] [A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition](https://arxiv.org/abs/2508.09372)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出了一种双架构框架，通过使用“无关手语者识别模型”和“多尺度融合Transformer”来解决连续手语识别中的手语者差异和未见过的句子结构问题，并在Isharah-1000数据集和SignEval 2025 CSLR挑战赛中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决连续手语识别中的主要挑战：手语者之间的显著差异和对新句子结构的泛化能力差。

Method: 提出了一种双架构框架：一种是用于解决无关手语者的问题的“无关手语者识别模型”，另一种是用于处理未见过的句子的“多尺度融合Transformer”。

Result: 在Isharah-1000数据集上，无关手语者识别模型在SI挑战上的词错误率为13.07%，比现有技术水平低13.53%；在US任务上的词错误率为47.78%。在SignEval 2025 CSLR挑战赛中，该团队在US任务上获得第二名，在SI任务上获得第四名。

Conclusion: 开发针对手语识别特定挑战的任务特定网络可以带来显著的性能提升，并为进一步研究奠定新基础。

Abstract: Continuous Sign Language Recognition (CSLR) faces multiple challenges,
including significant inter-signer variability and poor generalization to novel
sentence structures. Traditional solutions frequently fail to handle these
issues efficiently. For overcoming these constraints, we propose a
dual-architecture framework. For the Signer-Independent (SI) challenge, we
propose a Signer-Invariant Conformer that combines convolutions with multi-head
self-attention to learn robust, signer-agnostic representations from pose-based
skeletal keypoints. For the Unseen-Sentences (US) task, we designed a
Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that
captures both fine-grained posture dynamics, enabling the model's ability to
comprehend novel grammatical compositions. Experiments on the challenging
Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The
proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on
the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US
task, the transformer model scores a WER of 47.78%, surpassing previous work.
In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th
in the SI task, demonstrating the performance of these models. The findings
validate our key hypothesis: that developing task-specific networks designed
for the particular challenges of CSLR leads to considerable performance
improvements and establishes a new baseline for further research. The source
code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.

</details>


### [26] [What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?](https://arxiv.org/abs/2508.09381)
*Kumar Abhishek,Jeremy Kawahara,Ghassan Hamarneh*

Main category: cs.CV

TL;DR: 由于注释者之间的分歧，医学图像分割任务中存在IAV。本研究在最大的多注释皮肤镜图像分割数据集IMA++上进行了研究，发现IAV与皮肤镜图像的恶性肿瘤之间存在显著关联，并且可以直接从图像预测IAV。将IAV纳入多任务学习目标可提高分割准确性。


<details>
  <summary>Details</summary>
Motivation: 由于注释者之间的分歧，医学图像分割存在IAV，这源于物体边界的模糊性、注释者的偏好、专业知识和工具等因素。边界模糊的病变（例如，浸润性或边界不规则的结节）尤其容易引起分歧，并常常与恶性肿瘤相关。因此，本研究旨在调查IAV，并利用IAV来改进皮肤镜图像分割的准确性。

Method: 研究者们收集了最大的多注释皮肤镜图像分割数据集IMA++，并深入研究了注释者、恶性肿瘤、工具和技能因素造成的IAV。他们使用Dice系数来衡量IAV，并表明IAV与皮肤镜图像的恶性肿瘤存在统计学上的显著关联（p<0.001）。此外，研究者们证明了可以直接从皮肤镜图像预测IAV，平均绝对误差为0.108。

Result: 研究表明，IAV与皮肤镜图像的恶性肿瘤之间存在统计学上的显著关联（p<0.001）。可以直接从皮肤镜图像预测IAV，平均绝对误差为0.108。将IAV作为“软”临床特征纳入多任务学习目标，可使平衡准确率在IMA++和四个公共皮肤镜数据集上平均提高4.2%。

Conclusion: 该研究通过将IAV（即IAV）作为“软”临床特征纳入多任务学习目标，在IMA++和四个公共皮肤镜数据集上，跨越多种模型架构，将平衡准确率平均提高了4.2%。

Abstract: Medical image segmentation exhibits intra- and inter-annotator variability
due to ambiguous object boundaries, annotator preferences, expertise, and
tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated
or infiltrative nodules, or irregular borders per the ABCD rule, are
particularly prone to disagreement and are often associated with malignancy. In
this work, we curate IMA++, the largest multi-annotator skin lesion
segmentation dataset, on which we conduct an in-depth study of variability due
to annotator, malignancy, tool, and skill factors. We find a statistically
significant (p<0.001) association between inter-annotator agreement (IAA),
measured using Dice, and the malignancy of skin lesions. We further show that
IAA can be accurately predicted directly from dermoscopic images, achieving a
mean absolute error of 0.108. Finally, we leverage this association by
utilizing IAA as a "soft" clinical feature within a multi-task learning
objective, yielding a 4.2% improvement in balanced accuracy averaged across
multiple model architectures and across IMA++ and four public dermoscopic
datasets. The code is available at https://github.com/sfu-mial/skin-IAV.

</details>


### [27] [Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://arxiv.org/abs/2508.09423)
*Badi Li,Ren-jie Lu,Yu Zhou,Jingke Meng,Wei-shi Zheng*

Main category: cs.CV

TL;DR: GOAL是一个利用LLM增强的全局语义图来改善对象导航任务的生成式框架，在MP3D、Gibson和HM3D数据集上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 之前的Object ObjectNav任务方法依赖于确定性和判别式模型来完成语义地图，忽略了室内布局的内在不确定性，并限制了它们在未见环境中的泛化能力。

Method: 提出了一种名为GOAL的生成式基于流的框架，该框架通过融合LLM增强的全局语义图和观测区域来模拟室内环境的语义分布。在训练过程中，利用大型语言模型（LLM）推断的空间先验被编码为二维高斯场并注入目标图，将丰富的上下文知识提炼到流模型中，从而实现更具泛化性的地图补全。

Result: GOAL实现了在MP3D和Gibson上的最先进性能，并在HM3D的迁移设置中表现出强大的泛化能力。

Conclusion: GOAL在MP3D和Gibson上实现了最先进的性能，并在HM3D的迁移设置中表现出强大的泛化能力。

Abstract: The Object Goal Navigation (ObjectNav) task challenges agents to locate a
specified object in an unseen environment by imagining unobserved regions of
the scene. Prior approaches rely on deterministic and discriminative models to
complete semantic maps, overlooking the inherent uncertainty in indoor layouts
and limiting their ability to generalize to unseen environments. In this work,
we propose GOAL, a generative flow-based framework that models the semantic
distribution of indoor environments by bridging observed regions with
LLM-enriched full-scene semantic maps. During training, spatial priors inferred
from large language models (LLMs) are encoded as two-dimensional Gaussian
fields and injected into target maps, distilling rich contextual knowledge into
the flow model and enabling more generalizable completions. Extensive
experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D
and Gibson, and shows strong generalization in transfer settings to HM3D. Codes
and pretrained models are available at https://github.com/Badi-Li/GOAL.

</details>


### [28] [X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents](https://arxiv.org/abs/2508.09383)
*Guoxian Song,Hongyi Xu,Xiaochen Zhao,You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Linjie Luo*

Main category: cs.CV

TL;DR: X-UniMotion 是一种新的全身人类运动表示方法，可以直接从单个图像中编码面部表情、身体姿势和手势，并实现高质量的跨身份运动迁移。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有运动迁移方法依赖显式骨骼姿势和启发式跨身份调整的局限性，提出了一种新的方法来直接从单个图像编码多粒度运动。

Method: 提出了一种统一的、富有表现力的隐式潜在表示 X-UniMotion，用于从单个图像编码全身人类运动（面部表情、身体姿势和手势）到四个独立的潜在 token。该方法采用基于 DiT 的视频生成模型，并结合了自监督学习、2D 空间和颜色增强以及合成 3D 渲染来强制执行运动-身份解耦。此外，还使用辅助解码器来指导运动 token 学习，以实现细粒度、语义对齐和深度感知的运动嵌入。

Result: X-UniMotion 能够实现高保真度的跨身份运动迁移，能够处理具有不同身份、姿势和空间配置的主体，并且运动表现力强且具有身份无关性。

Conclusion: X-UniMotion 在运动保真度和身份保持方面优于最先进的方法，能够生成高度表达的动画。

Abstract: We present X-UniMotion, a unified and expressive implicit latent
representation for whole-body human motion, encompassing facial expressions,
body poses, and hand gestures. Unlike prior motion transfer methods that rely
on explicit skeletal poses and heuristic cross-identity adjustments, our
approach encodes multi-granular motion directly from a single image into a
compact set of four disentangled latent tokens -- one for facial expression,
one for body pose, and one for each hand. These motion latents are both highly
expressive and identity-agnostic, enabling high-fidelity, detailed
cross-identity motion transfer across subjects with diverse identities, poses,
and spatial configurations. To achieve this, we introduce a self-supervised,
end-to-end framework that jointly learns the motion encoder and latent
representation alongside a DiT-based video generative model, trained on
large-scale, diverse human motion datasets. Motion-identity disentanglement is
enforced via 2D spatial and color augmentations, as well as synthetic 3D
renderings of cross-identity subject pairs under shared poses. Furthermore, we
guide motion token learning with auxiliary decoders that promote fine-grained,
semantically aligned, and depth-aware motion embeddings. Extensive experiments
show that X-UniMotion outperforms state-of-the-art methods, producing highly
expressive animations with superior motion fidelity and identity preservation.

</details>


### [29] [WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization](https://arxiv.org/abs/2508.09560)
*Jiahao Wen,Hang Yu,Zhedong Zheng*

Main category: cs.CV

TL;DR: WeatherPrompt通过结合图像和文本信息，并利用先进的多模态技术（如无训练天气推理和动态门控机制），显著提高了无人机在恶劣天气下的视觉地理定位能力，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有无人机视觉地理定位方法在面对雨、雾等天气扰动时性能会严重下降，主要受限于两点：1）依赖有限的天气类别，泛化能力不足；2）通过伪天气类别进行的场景-天气特征解耦效果不佳。

Method: WeatherPrompt是一个多模态学习框架，它结合了图像和文本信息。其核心机制包括：1）无训练天气推理：利用现有的多模态大模型生成多天气文本描述，以提高对未知或复杂天气的泛化能力，并能反映天气强度。2）多模态特征解耦：通过动态门控机制，利用文本嵌入自适应地重新加权和融合不同模态的视觉特征。此外，还通过跨模态目标（如图文对比学习和图文匹配）进行优化，使相同场景在不同天气条件下映射到相近的表示空间。

Result: 在各种天气条件下，WeatherPrompt方法取得了与最先进的无人机地理定位方法相比具有竞争力的召回率。具体而言，在夜间条件下，召回率提高了+13.37%，在雾和雪条件下，召回率提高了18.69%。

Conclusion: 该研究提出了一种名为WeatherPrompt的多模态学习范式，通过融合图像嵌入和文本上下文来建立与天气无关的表示，以解决视觉无人机地理定位在天气扰动下的性能下降问题。实验结果表明，该方法在各种天气条件下均优于现有技术，特别是在夜间、雨、雪和雾等条件下性能提升显著。

Abstract: Visual geo-localization for drones faces critical degradation under weather
perturbations, \eg, rain and fog, where existing methods struggle with two
inherent limitations: 1) Heavy reliance on limited weather categories that
constrain generalization, and 2) Suboptimal disentanglement of entangled
scene-weather features through pseudo weather categories. We present
WeatherPrompt, a multi-modality learning paradigm that establishes
weather-invariant representations through fusing the image embedding with the
text context. Our framework introduces two key contributions: First, a
Training-free Weather Reasoning mechanism that employs off-the-shelf large
multi-modality models to synthesize multi-weather textual descriptions through
human-like reasoning. It improves the scalability to unseen or complex weather,
and could reflect different weather strength. Second, to better disentangle the
scene and weather feature, we propose a multi-modality framework with the
dynamic gating mechanism driven by the text embedding to adaptively reweight
and fuse visual features across modalities. The framework is further optimized
by the cross-modal objectives, including image-text contrastive learning and
image-text matching, which maps the same scene with different weather
conditions closer in the respresentation space. Extensive experiments validate
that, under diverse weather conditions, our method achieves competitive recall
rates compared to state-of-the-art drone geo-localization methods. Notably, it
improves Recall@1 by +13.37\% under night conditions and by 18.69\% under fog
and snow conditions.

</details>


### [30] [DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection](https://arxiv.org/abs/2508.09392)
*Kang Ni,Minrui Zou,Yuxuan Li,Xiang Li,Kehua Guo,Ming-Ming Cheng,Yimian Dai*

Main category: cs.CV

TL;DR: DenoDet V2是一种新的SAR目标检测方法，它在变换域处理特征，利用幅度和相位信息，在提高检测性能的同时降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有SAR目标检测方法主要依赖于对象空间域特征的分析或增强来隐式去噪，而本文提出了一种新颖的变换域特征解构和调制方法。

Method: DenoDet V2通过注意力机制在变换域解构和调制特征，并利用幅度与相位信息之间的互补性，通过逐频带互调机制实现了相位和幅度谱的互惠增强。

Result: DenoDet V2在SARDet-100K数据集上相比DenoDet V1性能提升了0.8%，同时模型复杂度降低了一半，并在多个SAR数据集上展现了最先进的性能。

Conclusion: DenoDet V2在SAR图像目标检测任务上取得了显著的性能提升，并在模型复杂度上实现了减半。

Abstract: One of the primary challenges in Synthetic Aperture Radar (SAR) object
detection lies in the pervasive influence of coherent noise. As a common
practice, most existing methods, whether handcrafted approaches or deep
learning-based methods, employ the analysis or enhancement of object
spatial-domain characteristics to achieve implicit denoising. In this paper, we
propose DenoDet V2, which explores a completely novel and different perspective
to deconstruct and modulate the features in the transform domain via a
carefully designed attention architecture. Compared to DenoDet V1, DenoDet V2
is a major advancement that exploits the complementary nature of amplitude and
phase information through a band-wise mutual modulation mechanism, which
enables a reciprocal enhancement between phase and amplitude spectra. Extensive
experiments on various SAR datasets demonstrate the state-of-the-art
performance of DenoDet V2. Notably, DenoDet V2 achieves a significant 0.8\%
improvement on SARDet-100K dataset compared to DenoDet V1, while reducing the
model complexity by half. The code is available at
https://github.com/GrokCV/GrokSAR.

</details>


### [31] [Plane Detection and Ranking via Model Information Optimization](https://arxiv.org/abs/2508.09625)
*Daoxin Zhong,Jun Li,Meng Yee Michael Chuah*

Main category: cs.CV

TL;DR: 一种基于信息优化的平面检测方法，用于解决RANSAC的误报问题，并在真实数据上表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决迭代方法（如RANSAC）在平面检测中因内点阈值模糊性而导致的误报问题，尤其是在真实世界复杂场景中，真实平面数量未知且存在多个平面时。

Method: 提出了一种基于模型信息优化的通用平面检测框架。将深度读数视为离散随机变量，并用地面真实平面约束其概率分布。通过重复的随机子采样生成包含不同候选平面约束的模型来解释观测数据。结合深度传感器的物理和噪声模型，计算每个模型的信息量，并接受信息量最少的模型作为最可能的地面真实。通过对每个平面的内点信息约减进行求和来对检测到的平面质量进行排序。

Result: 该算法估计平面参数比Open3D默认的RANSAC平面分割更准确，并通过神经网络分割加速，提高了在真实世界数据上生成更现实平面参数的能力。

Conclusion: 该方法通过信息优化解决了平面检测中的模糊性和误报问题，并能对检测到的平面质量进行排序。与RANSAC相比，该算法在合成数据上表现出更高的平面参数估计精度，并通过神经分割加速在真实数据上的表现。

Abstract: Plane detection from depth images is a crucial subtask with broad robotic
applications, often accomplished by iterative methods such as Random Sample
Consensus (RANSAC). While RANSAC is a robust strategy with strong probabilistic
guarantees, the ambiguity of its inlier threshold criterion makes it
susceptible to false positive plane detections. This issue is particularly
prevalent in complex real-world scenes, where the true number of planes is
unknown and multiple planes coexist. In this paper, we aim to address this
limitation by proposing a generalised framework for plane detection based on
model information optimization. Building on previous works, we treat the
observed depth readings as discrete random variables, with their probability
distributions constrained by the ground truth planes. Various models containing
different candidate plane constraints are then generated through repeated
random sub-sampling to explain our observations. By incorporating the physics
and noise model of the depth sensor, we can calculate the information for each
model, and the model with the least information is accepted as the most likely
ground truth. This information optimization process serves as an objective
mechanism for determining the true number of planes and preventing false
positive detections. Additionally, the quality of each detected plane can be
ranked by summing the information reduction of inlier points for each plane. We
validate these properties through experiments with synthetic data and find that
our algorithm estimates plane parameters more accurately compared to the
default Open3D RANSAC plane segmentation. Furthermore, we accelerate our
algorithm by partitioning the depth map using neural network segmentation,
which enhances its ability to generate more realistic plane parameters in
real-world data.

</details>


### [32] [Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety](https://arxiv.org/abs/2508.09397)
*Zhengli Zhang,Xinyu Luo,Yuchen Sun,Wenhua Ding,Dongyu Huang,Xinlei Chen*

Main category: cs.CV

TL;DR: SkyShield是一个新的事件驱动框架，可以检测无人机面临的亚毫米级障碍物，如细线。它使用U-Net和Dice-Contour Regularization Loss，在低延迟的情况下实现了高精度。


<details>
  <summary>Details</summary>
Motivation: 无人机在复杂环境中运行，面临着亚毫米级薄障碍物（如钢丝和风筝线）的重大威胁，这些障碍物对RGB摄像头、LiDAR和深度摄像头等传统传感器来说非常难以检测。

Method: 使用轻量级U-Net架构和创新的Dice-Contour Regularization Loss来确保精确检测，利用事件流中细长障碍物的独特特征。

Result: 平均F1分数为0.7088，延迟为21.2毫秒。

Conclusion: SkyShield是一个事件驱动的、端到端的框架，用于感知亚毫米级障碍物。实验结果表明，该方法在低延迟的情况下实现了0.7088的平均F1分数，非常适合在边缘和移动平台上部署。

Abstract: Drones operating in complex environments face a significant threat from thin
obstacles, such as steel wires and kite strings at the submillimeter level,
which are notoriously difficult for conventional sensors like RGB cameras,
LiDAR, and depth cameras to detect. This paper introduces SkyShield, an
event-driven, end-to-end framework designed for the perception of submillimeter
scale obstacles. Drawing upon the unique features that thin obstacles present
in the event stream, our method employs a lightweight U-Net architecture and an
innovative Dice-Contour Regularization Loss to ensure precise detection.
Experimental results demonstrate that our event-based approach achieves mean F1
Score of 0.7088 with a low latency of 21.2 ms, making it ideal for deployment
on edge and mobile platforms.

</details>


### [33] [Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision](https://arxiv.org/abs/2508.09681)
*Gerardo Loza,Junlei Hu,Dominic Jones,Sharib Ali,Pietro Valdastri*

Main category: cs.CV

TL;DR: 提出了一种基于NeRF的测试时优化（TTO）方法，用于长期3D点跟踪，在2D和3D跟踪任务中均取得了优于现有方法的性能，尤其在3D跟踪方面实现了TTO方法的突破。


<details>
  <summary>Details</summary>
Motivation: 当前大多数点跟踪方法在获得一致的运动方面存在困难，或者仅限于2D运动。为了解决这些问题，本研究提出了一种新颖的测试时优化（TTO）方法，该方法基于NeRF架构，能够实现长期的3D点跟踪。

Method: 本研究提出了一种新颖的基于NeRF的测试时优化（TTO）方法，用于长期3D点跟踪。该方法通过一个新颖的可逆神经辐射场（InvNeRF）架构来参数化一个聚合了来自其他专业最先进方法的对应关系的函数，从而实现2D和3D跟踪。该方法利用了基于渲染的方法的优势，通过监督重投影像素对应关系来实现，并借鉴了近期基于渲染的方法的策略，以获得双向可变形-规范映射，有效处理定义的空间，并引导射线密度。此外，研究还提出了用于快速推理的多尺度HexPlanes以及用于高效像素采样和收敛判据的新算法。

Result: 在2D点跟踪任务中，本研究提出的方法在平均精度上比现有的TTO方法提高了近50%，并且在与其它方法的比较中也具有竞争力。在3D点跟踪任务中，本研究首次将TTO方法应用于此，并且其表现超越了前馈方法，同时还结合了可变形NeRF重建的优势。

Conclusion: 所提出的新颖的基于NeRF的测试时优化（TTO）方法在3D点跟踪任务中取得了显著的成果，在2D点跟踪方面，其平均精度nearly 50%的提升，超越了现有的TTO方法，并且与其它方法相比也具有竞争力。在3D点跟踪方面，这是首个TTO方法，不仅超越了前馈方法，还融合了可变形NeRF重建的优点。

Abstract: We proposed a novel test-time optimisation (TTO) approach framed by a
NeRF-based architecture for long-term 3D point tracking. Most current methods
in point tracking struggle to obtain consistent motion or are limited to 2D
motion. TTO approaches frame the solution for long-term tracking as optimising
a function that aggregates correspondences from other specialised
state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose
parametrising such a function with our new invertible Neural Radiance Field
(InvNeRF) architecture to perform both 2D and 3D tracking in surgical
scenarios. Our approach allows us to exploit the advantages of a
rendering-based approach by supervising the reprojection of pixel
correspondences. It adapts strategies from recent rendering-based methods to
obtain a bidirectional deformable-canonical mapping, to efficiently handle a
defined workspace, and to guide the rays' density. It also presents our
multi-scale HexPlanes for fast inference and a new algorithm for efficient
pixel sampling and convergence criteria. We present results in the STIR and
SCARE datasets, for evaluating point tracking and testing the integration of
kinematic data in our pipeline, respectively. In 2D point tracking, our
approach surpasses the precision and accuracy of the TTO state-of-the-art
methods by nearly 50% on average precision, while competing with other
approaches. In 3D point tracking, this is the first TTO approach, surpassing
feed-forward methods while incorporating the benefits of a deformable
NeRF-based reconstruction.

</details>


### [34] [Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring](https://arxiv.org/abs/2508.09398)
*El Mustapha Mansouri*

Main category: cs.CV

TL;DR: 一个低成本、本地化的系统，使用摄像头和AI在后院监测鸟类，准确率高，保护隐私。


<details>
  <summary>Details</summary>
Motivation: 为了实现低成本、本地化的自主后院鸟类监测，以满足公民科学级别在比利时城市花园中的生物多样性记录需求，同时保护隐私并避免云服务费用。

Method: 使用运动触发的IP摄像头上传短视频片段到本地服务器，通过Detectron2进行帧采样和鸟类定位，然后使用在Kaggle数据集的一个包含40种比利时鸟类子集上微调的EfficientNet-B3模型进行分类。所有处理在无独立GPU的普通硬件上运行。物理喂食器使用小的入口（30毫米）来排除鸽子并减少误触发。

Result: 检测器引导的裁剪提高了分类准确性。分类器在经过筛选的子集上达到了很高的验证性能（约99.5%），在未见过物种上实现了实际的现场准确性（top-1约88%）。

Conclusion: 该系统实现了低成本、本地化的自主后院鸟类监测，隐私性好且无云费用，能够满足公民科学级别的家庭生物多样性记录需求。

Abstract: This paper presents a low cost, on premise system for autonomous backyard
bird monitoring in Belgian urban gardens. A motion triggered IP camera uploads
short clips via FTP to a local server, where frames are sampled and birds are
localized with Detectron2; cropped regions are then classified by an
EfficientNet-B3 model fine tuned on a 40-species Belgian subset derived from a
larger Kaggle corpus. All processing runs on commodity hardware without a
discrete GPU, preserving privacy and avoiding cloud fees. The physical feeder
uses small entry ports (30 mm) to exclude pigeons and reduce nuisance triggers.
Detector-guided cropping improves classification accuracy over raw-frame
classification. The classifier attains high validation performance on the
curated subset (about 99.5 percent) and delivers practical field accuracy
(top-1 about 88 percent) on held-out species, demonstrating feasibility for
citizen-science-grade biodiversity logging at home.

</details>


### [35] [Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System](https://arxiv.org/abs/2508.09732)
*Romeo Valentin,Sydney M. Katz,Artur B. Carneiro,Don Walker,Mykel J. Kochenderfer*

Main category: cs.CV

TL;DR: 提出了一种用于飞机姿态估计的视觉管线，该管线具有高效的神经网络架构、校准的不确定性估计和运行时故障检测功能，旨在提高航空应用的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管数据驱动的计算机视觉在自动化着陆和跑道检测等民用航空领域取得了显著进展，但确保这些系统满足航空应用的要求仍然是一个重大挑战。

Method: 一种高效、灵活的神经网络架构，基于空间Soft Argmax算子进行概率关键点回归，支持多样化的视觉主干和实时推理；一种原则性的损失函数，可生成校准的预测不确定性，并通过锐度（sharpness）和校准（calibration）指标进行评估；一种基于残差的接收器自主完整性监测（RAIM）的改编，可用于在运行时检测和拒绝有缺陷的模型输出。

Result: 在跑道图像数据集上实现了对飞机姿态估计的视觉管线，并对其进行了评估。

Conclusion: 该方法在准确性方面优于基线架构，同时还能生成具有亚像素精度且可用于故障检测的良好校准的不确定性估计。

Abstract: Recent advances in data-driven computer vision have enabled robust autonomous
navigation capabilities for civil aviation, including automated landing and
runway detection. However, ensuring that these systems meet the robustness and
safety requirements for aviation applications remains a major challenge. In
this work, we present a practical vision-based pipeline for aircraft pose
estimation from runway images that represents a step toward the ability to
certify these systems for use in safety-critical aviation applications. Our
approach features three key innovations: (i) an efficient, flexible neural
architecture based on a spatial Soft Argmax operator for probabilistic keypoint
regression, supporting diverse vision backbones with real-time inference; (ii)
a principled loss function producing calibrated predictive uncertainties, which
are evaluated via sharpness and calibration metrics; and (iii) an adaptation of
Residual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling
runtime detection and rejection of faulty model outputs. We implement and
evaluate our pose estimation pipeline on a dataset of runway images. We show
that our model outperforms baseline architectures in terms of accuracy while
also producing well-calibrated uncertainty estimates with sub-pixel precision
that can be used downstream for fault detection.

</details>


### [36] [Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving](https://arxiv.org/abs/2508.09404)
*Guangxun Zhu,Shiyu Fan,Hang Dai,Edmond S. L. Ho*

Main category: cs.CV

TL;DR: Waymo-3DSkelMo是首个大规模、高质量、包含明确交互语义的3D骨骼运动数据集，解决了现有数据集的不足，为自动驾驶行人交互理解提供了新资源。


<details>
  <summary>Details</summary>
Motivation: 为了在动态城市环境中实现对自动驾驶的精细化行人交互理解，需要大规模、高质量的3D运动数据集，但现有数据集存在质量不高和时间连贯性不足的问题。

Method: 通过利用3D人体形状和运动的先验知识，对从原始LiDRA点云中提取的3D姿态序列进行增强，以提高其质量。

Result: 该数据集包含超过800个真实驾驶场景，总时长超过14,000秒，平均每个场景有27个代理（最多250个），并建立了不同行人密度下的3D姿态预测基准，验证了其作为未来研究基础资源的价值。

Conclusion: Waymo-3DSkelMo是一个包含高质量、时间连贯的3D骨骼运动以及明确交互语义的大规模数据集，为自动驾驶领域提供了宝贵的资源，有望推动未来在复杂城市环境中对行人行为的精细化理解研究。

Abstract: Large-scale high-quality 3D motion datasets with multi-person interactions
are crucial for data-driven models in autonomous driving to achieve
fine-grained pedestrian interaction understanding in dynamic urban
environments. However, existing datasets mostly rely on estimating 3D poses
from monocular RGB video frames, which suffer from occlusion and lack of
temporal continuity, thus resulting in unrealistic and low-quality human
motion. In this paper, we introduce Waymo-3DSkelMo, the first large-scale
dataset providing high-quality, temporally coherent 3D skeletal motions with
explicit interaction semantics, derived from the Waymo Perception dataset. Our
key insight is to utilize 3D human body shape and motion priors to enhance the
quality of the 3D pose sequences extracted from the raw LiDRA point clouds. The
dataset covers over 14,000 seconds across more than 800 real driving scenarios,
including rich interactions among an average of 27 agents per scene (with up to
250 agents in the largest scene). Furthermore, we establish 3D pose forecasting
benchmarks under varying pedestrian densities, and the results demonstrate its
value as a foundational resource for future research on fine-grained human
behavior understanding in complex urban environments. The dataset and code will
be available at https://github.com/GuangxunZhu/Waymo-3DSkelMo

</details>


### [37] [TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos](https://arxiv.org/abs/2508.09811)
*Jinxi Li,Ziyang Song,Bo Yang*

Main category: cs.CV

TL;DR: TRCAE：一种无需人类标签即可从动态多视图视频中建模3D场景几何、外观和运动物理的新框架，通过学习粒子的平移-旋转动力学系统来捕捉复杂的运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法在仅从动态多视图视频中建模3D场景几何、外观和物理信息时，常因无法学习复杂的运动物理或需要额外标签（如对象类型或掩码）而失败。

Method: TRCAE框架通过将每个3D点建模为具有大小和方向的刚性粒子，并直接学习每个粒子的平移-旋转动力学系统，显式地估计一组完整的物理参数来控制粒子的时变运动。

Result: 在三个现有的动态数据集和一个新创建的具有挑战性的合成数据集上进行的大量实验证明了我们的方法在未来帧外推任务上的卓越性能。

Conclusion: TRCAE框架在未来帧外推任务中表现出色，并且可以通过聚类学习到的物理参数轻松分割多个对象或部件。

Abstract: In this paper, we aim to model 3D scene geometry, appearance, and physical
information just from dynamic multi-view videos in the absence of any human
labels. By leveraging physics-informed losses as soft constraints or
integrating simple physics models into neural nets, existing works often fail
to learn complex motion physics, or doing so requires additional labels such as
object types or masks. We propose a new framework named TRACE to model the
motion physics of complex dynamic 3D scenes. The key novelty of our method is
that, by formulating each 3D point as a rigid particle with size and
orientation in space, we directly learn a translation rotation dynamics system
for each particle, explicitly estimating a complete set of physical parameters
to govern the particle's motion over time. Extensive experiments on three
existing dynamic datasets and one newly created challenging synthetic datasets
demonstrate the extraordinary performance of our method over baselines in the
task of future frame extrapolation. A nice property of our framework is that
multiple objects or parts can be easily segmented just by clustering the
learned physical parameters.

</details>


### [38] [RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata](https://arxiv.org/abs/2508.09415)
*John S. O'Meara,Jared Hwang,Zeyu Wang,Michael Saugstad,Jon E. Froehlich*

Main category: cs.CV

TL;DR: 由于缺乏大规模数据集，城市无障碍路缘坡道检测效果不佳。本研究提出了RampNet，一个包含21万张标注图像的两阶段流水线，并训练了一个改进的ConvNeXt V2模型，实现了最先进的坡道检测性能（AP为0.9236），解决了数据规模和质量的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市无障碍设施中路缘坡道检测的挑战，由于缺乏大规模、高质量的数据集，目前的研究效果不佳。现有的方法，如众包或手动标注数据，在质量或规模上都存在不足。

Method: 提出了一种名为RampNet的两阶段流水线。第一阶段，通过将政府提供的坡道位置数据自动转换为街景图像中的像素坐标，生成了一个包含超过21万张标注图像的数据集。第二阶段，利用生成的数据集训练了一个改进的ConvNeXt V2模型来进行坡道检测。

Result: RampNet流水线的第一阶段生成的数据集实现了94.0%的精确率和92.5%的召回率，第二阶段训练的检测模型达到了0.9236的平均精度（AP），性能优于现有方法。

Conclusion: 该研究首次提出了大规模、高质量的坡道检测数据集、基准和模型，其中生成的包含21万张谷歌街景图像的数据集达到了94.0%的精确率和92.5%的召回率，而所提出的RampNet模型则达到了0.9236的平均精度（AP），超越了以往的研究。

Abstract: Curb ramps are critical for urban accessibility, but robustly detecting them
in images remains an open problem due to the lack of large-scale, high-quality
datasets. While prior work has attempted to improve data availability with
crowdsourced or manually labeled data, these efforts often fall short in either
quality or scale. In this paper, we introduce and evaluate a two-stage pipeline
called RampNet to scale curb ramp detection datasets and improve model
performance. In Stage 1, we generate a dataset of more than 210,000 annotated
Google Street View (GSV) panoramas by auto-translating government-provided curb
ramp location data to pixel coordinates in panoramic images. In Stage 2, we
train a curb ramp detection model (modified ConvNeXt V2) from the generated
dataset, achieving state-of-the-art performance. To evaluate both stages of our
pipeline, we compare to manually labeled panoramas. Our generated dataset
achieves 94.0% precision and 92.5% recall, and our detection model reaches
0.9236 AP -- far exceeding prior work. Our work contributes the first
large-scale, high-quality curb ramp detection dataset, benchmark, and model.

</details>


### [39] [What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset](https://arxiv.org/abs/2508.09428)
*Yuxiao Wang,Yu Lei,Wolin Liang,Weiying Xue,Zhenao Wei,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: 提出PaIR-Net框架，联合解决行为语义和空间情境化问题，并发布包含13,979张图像的PaIR数据集以支持此任务。


<details>
  <summary>Details</summary>
Motivation: 为了全面理解跨不同视觉上下文的行为，需要同时考虑行为是什么以及它发生在何处。现有方法未能充分捕捉这种对偶性，未能联合建模行为语义及其在场景中的空间情境化。

Method: 提出了一种名为PaIR-Net的新框架，包含三个关键组件：接触先验感知模块（CPAM）、先验引导的连接分割器（PGCS）和交互推理模块（IIM）。

Result: PaIR-Net在同时预测高级行为语义和细粒度身体部位接触区域方面表现出色，显著优于基线方法。

Conclusion: PaIR-Net在实验评估中显著优于基线方法，并且消融研究证实了每个架构组件的有效性。

Abstract: People control their bodies to establish contact with the environment. To
comprehensively understand actions across diverse visual contexts, it is
essential to simultaneously consider \textbf{what} action is occurring and
\textbf{where} it is happening. Current methodologies, however, often
inadequately capture this duality, typically failing to jointly model both
action semantics and their spatial contextualization within scenes. To bridge
this gap, we introduce a novel vision task that simultaneously predicts
high-level action semantics and fine-grained body-part contact regions. Our
proposed framework, PaIR-Net, comprises three key components: the Contact Prior
Aware Module (CPAM) for identifying contact-relevant body parts, the
Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and
the Interaction Inference Module (IIM) responsible for integrating global
interaction relationships. To facilitate this task, we present PaIR (Part-aware
Interaction Representation), a comprehensive dataset containing 13,979 images
that encompass 654 actions, 80 object categories, and 17 body parts.
Experimental evaluation demonstrates that PaIR-Net significantly outperforms
baseline approaches, while ablation studies confirm the efficacy of each
architectural component. The code and dataset will be released upon
publication.

</details>


### [40] [MPT: Motion Prompt Tuning for Micro-Expression Recognition](https://arxiv.org/abs/2508.09446)
*Jiateng Liu,Hengcan Shi,Feng Chen,Zhiwen Shao,Yaonan Wang,Jianfei Cai,Wenming Zheng*

Main category: cs.CV

TL;DR: 由于标注困难，微表情识别（MER）训练样本稀缺。本文提出运动提示调整（MPT）方法，通过运动放大、高斯标记化和组适配器来调整大型语言模型（LM），以捕捉微表情的细微运动，并在实验中取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 微表情识别（MER）在情感计算领域至关重要，但由于标注困难，导致训练样本稀缺，限制了MER模型的发展。现有的预训练模型（LM）虽然能提供通用表示，但难以捕捉微表情的瞬时和细微的面部运动。

Method: 提出了一种新颖的运动提示调整（MPT）方法来调整大型预训练模型（LM）以用于微表情识别（MER）。该方法包括运动提示生成（运动放大和高斯标记化）和组适配器，以提取微妙的运动并增强模型在目标MER域中的能力。

Result: MPT方法在三个广泛使用的MER数据集上进行评估，结果显示其性能优于当前最先进的方法。

Conclusion: 所提出的MPT方法在三个广泛使用的微表情识别（MER）数据集上进行了广泛的实验，结果表明该方法持续优于现有技术，并验证了其有效性。

Abstract: Micro-expression recognition (MER) is crucial in the affective computing
field due to its wide application in medical diagnosis, lie detection, and
criminal investigation. Despite its significance, obtaining micro-expression
(ME) annotations is challenging due to the expertise required from
psychological professionals. Consequently, ME datasets often suffer from a
scarcity of training samples, severely constraining the learning of MER models.
While current large pre-training models (LMs) offer general and discriminative
representations, their direct application to MER is hindered by an inability to
capture transitory and subtle facial movements-essential elements for effective
MER. This paper introduces Motion Prompt Tuning (MPT) as a novel approach to
adapting LMs for MER, representing a pioneering method for subtle motion prompt
tuning. Particularly, we introduce motion prompt generation, including motion
magnification and Gaussian tokenization, to extract subtle motions as prompts
for LMs. Additionally, a group adapter is carefully designed and inserted into
the LM to enhance it in the target MER domain, facilitating a more nuanced
distinction of ME representation. Furthermore, extensive experiments conducted
on three widely used MER datasets demonstrate that our proposed MPT
consistently surpasses state-of-the-art approaches and verifies its
effectiveness.

</details>


### [41] [RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration](https://arxiv.org/abs/2508.09449)
*Jiaqi Yan,Shuning Xu,Xiangyu Chen,Dell Zhang,Jie Tang,Gangshan Wu,Jie Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为RASR的新型参考图像超分辨率方法，通过自动检索相关参考图像来克服现有方法对手动配对的依赖，并引入了RASRNet模型和RASR-Flickr30数据集。实验证明RASRNet在提高图像质量和真实感方面优于传统方法，为RefSR在实际应用中开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有的参考图像超分辨率（RefSR）方法在提高图像质量方面表现出色，但它们依赖于手动选择的图像对，这在实际应用中存在很大限制。为了解决这个问题，本研究旨在开发一种更实用、可扩展的RefSR方法，使其能够在没有预先配对的数据的情况下工作，从而能够应用于更广泛的现实场景。

Method: 提出了一种名为检索增强超分辨率（RASR）的新范式，它能够自动从参考数据库中检索语义上相关的低质量输入图像，以增强纹理保真度和视觉真实感。具体来说，RASRNet结合了一个语义参考检索器和一个基于扩散的RefSR生成器。检索器基于语义相似性进行检索，生成器则采用经过语义增强的扩散模型。

Result: 在RASR-Flickr30数据集上的实验表明，RASRNet相比于SISR基线，PSNR提升了0.38 dB，LPIPS降低了0.0131，并且能够生成更逼真的纹理。

Conclusion: 现有方法依赖手动选择的目标-参考图像对，限制了其实用性。RASR通过引入自动检索机制，使其能够在真实场景下应用，例如增强移动设备拍摄的照片。RASRNet作为一种结合了语义检索器和基于扩散的RefSR生成器的强大基线，在RASR-Flickr30数据集上表现优于SISR基线，显著提升了PSNR和LPIPS指标，并生成更逼真的纹理。这表明检索增强是弥合学术界RefSR研究与现实应用之间差距的一个有前景的方向。

Abstract: Reference-based Super Resolution (RefSR) improves upon Single Image Super
Resolution (SISR) by leveraging high-quality reference images to enhance
texture fidelity and visual realism. However, a critical limitation of existing
RefSR approaches is their reliance on manually curated target-reference image
pairs, which severely constrains their practicality in real-world scenarios. To
overcome this, we introduce Retrieval-Augmented Super Resolution (RASR), a new
and practical RefSR paradigm that automatically retrieves semantically relevant
high-resolution images from a reference database given only a low-quality
input. This enables scalable and flexible RefSR in realistic use cases, such as
enhancing mobile photos taken in environments like zoos or museums, where
category-specific reference data (e.g., animals, artworks) can be readily
collected or pre-curated. To facilitate research in this direction, we
construct RASR-Flickr30, the first benchmark dataset designed for RASR. Unlike
prior datasets with fixed target-reference pairs, RASR-Flickr30 provides
per-category reference databases to support open-world retrieval. We further
propose RASRNet, a strong baseline that combines a semantic reference retriever
with a diffusion-based RefSR generator. It retrieves relevant references based
on semantic similarity and employs a diffusion-based generator enhanced with
semantic conditioning. Experiments on RASR-Flickr30 demonstrate that RASRNet
consistently improves over SISR baselines, achieving +0.38 dB PSNR and -0.0131
LPIPS, while generating more realistic textures. These findings highlight
retrieval augmentation as a promising direction to bridge the gap between
academic RefSR research and real-world applicability.

</details>


### [42] [HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss](https://arxiv.org/abs/2508.09453)
*Abdul Matin,Tanjim Bin Faruk,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: 高光谱遥感数据难以直接应用基础模型？试试 HyperKD！它通过反向知识蒸馏，将通用基础模型（如 Prithvi）的知识迁移到高光谱模型（如 EnMAP），解决了光谱差异和数据稀疏问题，并在多项遥感任务中大幅提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着预训练基础模型在处理大规模无标签数据集方面展现出强大能力，其在卫星观测和下游任务中的应用日益广泛。然而，在高光谱遥感领域，由于光谱差异性和数据稀缺性，直接应用基础模型面临挑战。因此，需要一种有效的方法来迁移基础模型的知识，以适应高光谱数据的特性，并充分发挥其在遥感分析中的潜力。

Method: 本文提出了一种名为 HyperKD 的新颖知识蒸馏框架，用于将教师模型的表征迁移到学生模型中，以构建高光谱图像的基础模型。与传统的由复杂教师指导简单学生不同，HyperKD 采用反向知识迁移，即由一个更简单的教师模型指导。该框架基于 Masked Autoencoder (MAE)，将 Prithvi 基础模型（用于地球观测）的知识蒸馏到一个针对 EnMAP 高光谱图像的学生模型中。为解决光谱域差异和域适应问题，HyperKD 引入了基于特征的策略，包括基于光谱范围的通道对齐、空间特征引导的掩码以及针对高光谱图像的增强损失函数。

Result: 通过实验证明，HyperKD 显著提高了 MAE 的表征学习能力，增强了重建保真度，并在土地覆盖分类、作物类型识别和土壤有机碳预测等下游任务中取得了更鲁棒的性能。这表明知识蒸馏框架在高光谱遥感分析中具有巨大潜力。

Conclusion: HyperKD 框架通过知识蒸馏成功地将预训练的地球观测基础模型（如 Prithvi）的知识迁移到针对特定高光谱数据集（如 EnMAP）的学生模型中，有效解决了高光谱遥感领域中数据域差异和数据稀疏性带来的挑战，显著提升了表示学习的效果，并在土地覆盖分类、作物类型识别和土壤有机碳预测等下游任务中表现出更优越的性能。

Abstract: The proliferation of foundation models, pretrained on large-scale unlabeled
datasets, has emerged as an effective approach in creating adaptable and
reusable architectures that can be leveraged for various downstream tasks using
satellite observations. However, their direct application to hyperspectral
remote sensing remains challenging due to inherent spectral disparities and the
scarcity of available observations. In this work, we present HyperKD, a novel
knowledge distillation framework that enables transferring learned
representations from a teacher model into a student model for effective
development of a foundation model on hyperspectral images. Unlike typical
knowledge distillation frameworks, which use a complex teacher to guide a
simpler student, HyperKD enables an inverse form of knowledge transfer across
different types of spectral data, guided by a simpler teacher model. Building
upon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi
foundational model into a student tailored for EnMAP hyperspectral imagery.
HyperKD addresses the inverse domain adaptation problem with spectral gaps by
introducing a feature-based strategy that includes spectral range-based channel
alignment, spatial feature-guided masking, and an enhanced loss function
tailored for hyperspectral images. HyperKD bridges the substantial spectral
domain gap, enabling the effective use of pretrained foundation models for
geospatial applications. Extensive experiments show that HyperKD significantly
improves representation learning in MAEs, leading to enhanced reconstruction
fidelity and more robust performance on downstream tasks such as land cover
classification, crop type identification, and soil organic carbon prediction,
underpinning the potential of knowledge distillation frameworks in remote
sensing analytics with hyperspectral imagery.

</details>


### [43] [Animate-X++: Universal Character Image Animation with Dynamic Backgrounds](https://arxiv.org/abs/2508.09454)
*Shuai Tan,Biao Gong,Zhuoxin Liu,Yan Wang,Xi Chen,Yifan Feng,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Animate-X++ animates diverse characters (including anthropomorphic ones) with dynamic backgrounds using a new Pose Indicator and multi-task learning, outperforming previous methods.


<details>
  <summary>Details</summary>
Motivation: Existing character image animation methods are limited to human figures and cannot generalize well to anthropomorphic characters. They also typically produce videos with static backgrounds, limiting realism. This work aims to create a universal animation framework for diverse character types and dynamic backgrounds.

Method: Animate-X++ uses a DiT-based framework with a novel Pose Indicator to capture comprehensive motion patterns from driving videos (using CLIP for implicit motion gist and input simulation for explicit generalization). It employs a multi-task training strategy combining animation and text-to-video-generation (TI2V) tasks with partial parameter training to enable dynamic backgrounds.

Result: Animate-X++ demonstrates superiority and effectiveness in generating high-quality animations for various character types, including anthropomorphic ones, and produces videos with dynamic backgrounds. Experiments on the new A2Bench benchmark confirm these findings.

Conclusion: Animate-X++ is a universal animation framework that overcomes the limitations of previous methods by handling anthropomorphic characters and generating videos with dynamic backgrounds. It achieves this through the Pose Indicator for enhanced motion representation and a multi-task training strategy for animation and text-to-video generation. The new A2Bench benchmark validates its effectiveness.

Abstract: Character image animation, which generates high-quality videos from a
reference image and target pose sequence, has seen significant progress in
recent years. However, most existing methods only apply to human figures, which
usually do not generalize well on anthropomorphic characters commonly used in
industries like gaming and entertainment. Furthermore, previous methods could
only generate videos with static backgrounds, which limits the realism of the
videos. For the first challenge, our in-depth analysis suggests to attribute
this limitation to their insufficient modeling of motion, which is unable to
comprehend the movement pattern of the driving video, thus imposing a pose
sequence rigidly onto the target character. To this end, this paper proposes
Animate-X++, a universal animation framework based on DiT for various character
types, including anthropomorphic characters. To enhance motion representation,
we introduce the Pose Indicator, which captures comprehensive motion pattern
from the driving video through both implicit and explicit manner. The former
leverages CLIP visual features of a driving video to extract its gist of
motion, like the overall movement pattern and temporal relations among motions,
while the latter strengthens the generalization of DiT by simulating possible
inputs in advance that may arise during inference. For the second challenge, we
introduce a multi-task training strategy that jointly trains the animation and
TI2V tasks. Combined with the proposed partial parameter training, this
approach achieves not only character animation but also text-driven background
dynamics, making the videos more realistic. Moreover, we introduce a new
Animated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of
Animate-X++ on universal and widely applicable animation images. Extensive
experiments demonstrate the superiority and effectiveness of Animate-X++.

</details>


### [44] [IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding](https://arxiv.org/abs/2508.09456)
*Junxian Li,Beining Xu,Di Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为 IAG 的后门攻击方法，通过嵌入目标语义信息来操纵视觉语言模型（VLM）的视觉定位行为，并成功在多种模型上进行了验证，实现了高攻击成功率且对干净样本影响小。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在视觉定位任务中展现出显著的进步，但其安全问题，特别是后门攻击，尚未得到充分研究。本研究旨在探索并解决 VLM 在视觉定位任务中的安全漏洞。

Method: 提出了一种名为 IAG 的输入感知后门攻击方法，使用文本条件 U-Net 生成自适应触发器，将攻击目标描述的语义信息嵌入图像，并通过重建损失最小化视觉差异，同时提出了一种统一的数据生成方法。

Result: IAG 在 InternVL-2.5-8B 上的 ASR@0.5 超过 65%，并对 Ferret-7B 和 LlaVA-1.5-7B 有效，同时对干净样本的准确性影响很小。该攻击还表现出鲁棒性和可转移性。

Conclusion: 该研究提出了一种名为 IAG 的新颖输入感知后门攻击方法，旨在操纵视觉语言模型（VLM）的视觉定位行为。该方法通过嵌入语义信息来克服开放词汇攻击的挑战，并通过重建损失来最小化视觉差异以确保攻击的隐蔽性。实验表明，IAG 在 InternVL-2.5-8B 上的 ASR@0.5 超过 65%，并对 Ferret-7B 和 LlaVA-1.5-7B 表现出有效性，同时对干净样本的准确性影响很小。消融研究和潜在防御实验也证明了该攻击的鲁棒性和可转移性。

Abstract: Vision-language models (VLMs) have shown significant advancements in tasks
such as visual grounding, where they localize specific objects in images based
on natural language queries and images. However, security issues in visual
grounding tasks for VLMs remain underexplored, especially in the context of
backdoor attacks. In this paper, we introduce a novel input-aware backdoor
attack method, IAG, designed to manipulate the grounding behavior of VLMs. This
attack forces the model to ground a specific target object in the input image,
regardless of the user's query. We propose an adaptive trigger generator that
embeds the semantic information of the attack target's description into the
original image using a text-conditional U-Net, thereby overcoming the
open-vocabulary attack challenge. To ensure the attack's stealthiness, we
utilize a reconstruction loss to minimize visual discrepancies between poisoned
and clean images. Additionally, we introduce a unified method for generating
attack data. IAG is evaluated theoretically and empirically, demonstrating its
feasibility and effectiveness. Notably, our ASR@0.5 on InternVL-2.5-8B reaches
over 65\% on various testing sets. IAG also shows promising potential on
manipulating Ferret-7B and LlaVA-1.5-7B with very little accuracy decrease on
clean samples. Extensive specific experiments, such as ablation study and
potential defense, also indicate the robustness and transferability of our
attack.

</details>


### [45] [RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization](https://arxiv.org/abs/2508.09459)
*Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia*

Main category: cs.CV

TL;DR: RelayFormer是一种新的视觉操纵本地化方法，可以处理图像和视频，具有良好的泛化能力和效率，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉操纵本地化（VML）方法在跨模态泛化方面存在不足，并且难以有效地处理高分辨率或长时间的输入。

Method: RelayFormer是一种统一且模块化的架构，采用灵活的局部单元和全局-局部中继注意力（GLoRA）机制，实现可扩展、与分辨率无关的处理和强大的泛化能力。它还集成了基于Transformer的主干，如ViT和SegFormer，并设计了一个轻量级的、基于查询的掩码解码器，支持具有线性复杂度的视频序列的单次推理。

Result: 实验证明RelayFormer在多个基准测试中实现了最先进的定位性能，并为可扩展和模态无关的VML设定了新的基线。

Conclusion: RelayFormer在多个基准测试中实现了最先进的定位性能，为可扩展和模态无关的视觉操纵本地化设定了新的基线。

Abstract: Visual manipulation localization (VML) -- across both images and videos -- is
a crucial task in digital forensics that involves identifying tampered regions
in visual content. However, existing methods often lack cross-modal
generalization and struggle to handle high-resolution or long-duration inputs
efficiently.
  We propose RelayFormer, a unified and modular architecture for visual
manipulation localization across images and videos. By leveraging flexible
local units and a Global-Local Relay Attention (GLoRA) mechanism, it enables
scalable, resolution-agnostic processing with strong generalization. Our
framework integrates seamlessly with existing Transformer-based backbones, such
as ViT and SegFormer, via lightweight adaptation modules that require only
minimal architectural changes, ensuring compatibility without disrupting
pretrained representations.
  Furthermore, we design a lightweight, query-based mask decoder that supports
one-shot inference across video sequences with linear complexity. Extensive
experiments across multiple benchmarks demonstrate that our approach achieves
state-of-the-art localization performance, setting a new baseline for scalable
and modality-agnostic VML. Code is available at:
https://github.com/WenOOI/RelayFormer.

</details>


### [46] [Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy](https://arxiv.org/abs/2508.09461)
*Hao Yu,Rupayan Mallick,Margrit Betke,Sarah Adel Bargal*

Main category: cs.CV

TL;DR: GEN-AFFECT 使用多模态扩散 Transformer 和一致性注意力来生成身份一致且表情丰富的个性化头像，并在准确性、身份保持和一致性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细粒度面部表情和跨不同表情保持身份方面存在不足。

Method: 通过将多模态扩散 Transformer 与提取的身份-表情表示相结合，并采用推理时的一致注意力机制来实现。

Result: 生成具有多样化面部表情且身份一致的个性化头像。

Conclusion: GEN-AFFECT 框架在生成表情准确性、身份保持以及跨一系列细粒度面部表情的目标身份一致性方面，相比于先前最先进的方法表现出优越的性能。

Abstract: Different forms of customized 2D avatars are widely used in gaming
applications, virtual communication, education, and content creation. However,
existing approaches often fail to capture fine-grained facial expressions and
struggle to preserve identity across different expressions. We propose
GEN-AFFECT, a novel framework for personalized avatar generation that generates
expressive and identity-consistent avatars with a diverse set of facial
expressions. Our framework proposes conditioning a multimodal diffusion
transformer on an extracted identity-expression representation. This enables
identity preservation and representation of a wide range of facial expressions.
GEN-AFFECT additionally employs consistent attention at inference for
information sharing across the set of generated expressions, enabling the
generation process to maintain identity consistency over the array of generated
fine-grained expressions. GEN-AFFECT demonstrates superior performance compared
to previous state-of-the-art methods on the basis of the accuracy of the
generated expressions, the preservation of the identity and the consistency of
the target identity across an array of fine-grained facial expressions.

</details>


### [47] [CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios](https://arxiv.org/abs/2508.09470)
*Jialei Xu,Zizhuang Wei,Weikang You,Linyun Li,Weijian Sun*

Main category: cs.CV

TL;DR: CitySeg是一个创新的城市规模点云语义分割基础模型，通过结合文本模态、改进的数据处理和网络结构，实现了开放词汇分割和零样本泛化，并在多项基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的城市规模点云语义分割模型受限于三维数据的有限尺度和数据集间的域差距，导致泛化能力下降。为了解决这些挑战，需要一个能够处理大规模数据、跨越不同数据集并实现开放词汇分割和零样本推理的模型。

Method: 提出 CitySeg，一个结合文本模态以实现开放词汇分割和零样本推理的城市规模点云语义分割基础模型。通过定制数据预处理规则、引入局部-全局交叉注意力网络来增强无人机场景中的点网络感知能力。通过层次化分类策略和层次化图来解决跨数据集的语义标签差异，并使用图编码器来模拟类别间的层次关系。此外，还提出了一种两阶段训练策略并采用铰链损失来提高子类别的特征可分离性。

Result: CitySeg在九个闭集基准上取得了最先进（SOTA）的性能，显著优于现有方法。它还首次实现了城市规模点云场景中的零样本泛化，无需依赖视觉信息。

Conclusion: CitySeg在九个闭集基准上实现了最先进（SOTA）的性能，显著优于现有方法，并且首次在城市规模点云场景中实现了无需视觉信息即可进行的零样本泛化。

Abstract: Semantic segmentation of city-scale point clouds is a critical technology for
Unmanned Aerial Vehicle (UAV) perception systems, enabling the classification
of 3D points without relying on any visual information to achieve comprehensive
3D understanding. However, existing models are frequently constrained by the
limited scale of 3D data and the domain gap between datasets, which lead to
reduced generalization capability. To address these challenges, we propose
CitySeg, a foundation model for city-scale point cloud semantic segmentation
that incorporates text modality to achieve open vocabulary segmentation and
zero-shot inference. Specifically, in order to mitigate the issue of
non-uniform data distribution across multiple domains, we customize the data
preprocessing rules, and propose a local-global cross-attention network to
enhance the perception capabilities of point networks in UAV scenarios. To
resolve semantic label discrepancies across datasets, we introduce a
hierarchical classification strategy. A hierarchical graph established
according to the data annotation rules consolidates the data labels, and the
graph encoder is used to model the hierarchical relationships between
categories. In addition, we propose a two-stage training strategy and employ
hinge loss to increase the feature separability of subcategories. Experimental
results demonstrate that the proposed CitySeg achieves state-of-the-art (SOTA)
performance on nine closed-set benchmarks, significantly outperforming existing
approaches. Moreover, for the first time, CitySeg enables zero-shot
generalization in city-scale point cloud scenarios without relying on visual
information.

</details>


### [48] [Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection](https://arxiv.org/abs/2508.09475)
*Shibo Yao,Renshuai Tao,Xiaolong Zheng,Chao Liang,Chunjie Zhang*

Main category: cs.CV

TL;DR: FTNet是一种用于真实世界少样本深度伪造检测的新方法。它通过利用少量失败的样本来改进性能，而不是依赖于大规模的已知数据进行训练。在对29个生成模型的测试中，FTNet取得了8.7%的平均性能提升。


<details>
  <summary>Details</summary>
Motivation: 真实世界的深度伪造检测通常面临这样的挑战：模型可能在新样本上表现不佳，但这些新样本仍然可供分析。这表明它应该被视为一项“少样本”任务，其中有效利用少量样本可以带来显著的改进。

Method: 提出了一种名为FTNet（Few-shot Training-free Network）的网络，该网络通过仅使用评估集中的一个假样本，并通过将每个测试样本与已知的假样本和真实样本进行比较，并根据最接近的样本的类别对其进行分类来实现。

Result: 在对来自29个不同生成模型的AI生成图像进行全面分析后，FTNet取得了新的最先进性能，与现有方法相比，平均性能提高了8.7%。

Conclusion: 当模型在少量样本上泛化能力不足时，利用这些失败的样本可以带来更好的性能。

Abstract: Recent deepfake detection studies often treat unseen sample detection as a
``zero-shot" task, training on images generated by known models but
generalizing to unknown ones. A key real-world challenge arises when a model
performs poorly on unknown samples, yet these samples remain available for
analysis. This highlights that it should be approached as a ``few-shot" task,
where effectively utilizing a small number of samples can lead to significant
improvement. Unlike typical few-shot tasks focused on semantic understanding,
deepfake detection prioritizes image realism, which closely mirrors real-world
distributions. In this work, we propose the Few-shot Training-free Network
(FTNet) for real-world few-shot deepfake detection. Simple yet effective, FTNet
differs from traditional methods that rely on large-scale known data for
training. Instead, FTNet uses only one fake samplefrom an evaluation set,
mimicking the scenario where new samples emerge in the real world and can be
gathered for use, without any training or parameter updates. During evaluation,
each test sample is compared to the known fake and real samples, and it is
classified based on the category of the nearest sample. We conduct a
comprehensive analysis of AI-generated images from 29 different generative
models and achieve a new SoTA performance, with an average improvement of 8.7\%
compared to existing methods. This work introduces a fresh perspective on
real-world deepfake detection: when the model struggles to generalize on a
few-shot sample, leveraging the failed samples leads to better performance.

</details>


### [49] [From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts](https://arxiv.org/abs/2508.09476)
*Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Chengming Xu,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 提出了一种名为MoFE的混合面部专家模型，并构建了LFA数据集，以解决视频生成中大幅度面部角度下的人脸身份保持问题，并在实验中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型在大幅度面部角度下的人脸身份保持能力不足，主要面临两个挑战：如何在DiT结构中有效整合身份特征，以及现有开源视频数据集缺乏对大幅度面部角度的针对性覆盖。

Method: 提出了一种混合面部专家（MoFE）模型，该模型动态地结合了三个专业专家（身份专家、语义专家和细节专家）的互补线索。此外，还设计了一个数据处理流程，包括面部约束和身份一致性，以解决现有数据集在大幅度面部角度方面的数据稀疏性问题，并由此构建了LFA数据集。

Result: 实验结果表明，所提出的方法在LFA基准测试中，在人脸相似性、人脸FID和CLIP语义对齐方面均取得了显著的性能提升，优于现有最先进的方法。

Conclusion: 通过LFA数据集和MoFE，该方法在人脸相似性、人脸FID和CLIP语义对齐方面显著优于现有方法。

Abstract: Current video generation models struggle with identity preservation under
large facial angles, primarily facing two challenges: the difficulty in
exploring an effective mechanism to integrate identity features into DiT
structure, and the lack of targeted coverage of large facial angles in existing
open-source video datasets. To address these, we present two key innovations.
First, we introduce a Mixture of Facial Experts (MoFE) that dynamically
combines complementary cues from three specialized experts, each designed to
capture distinct but mutually reinforcing aspects of facial attributes. The
identity expert captures cross-pose identity-sensitive features, the semantic
expert extracts high-level visual semantxics, and the detail expert preserves
pixel-level features (e.g., skin texture, color gradients). Furthermore, to
mitigate dataset limitations, we have tailored a data processing pipeline
centered on two key aspects: Face Constraints and Identity Consistency. Face
Constraints ensure facial angle diversity and a high proportion of facial
regions, while Identity Consistency preserves coherent person-specific features
across temporal sequences, collectively addressing the scarcity of large facial
angles and identity-stable training data in existing datasets. Leveraging this
pipeline, we have curated and refined a Large Face Angles (LFA) Dataset from
existing open-source human video datasets, comprising 460K video clips with
annotated facial angles. Experimental results on the LFA benchmark demonstrate
that our method, empowered by the LFA dataset, significantly outperforms prior
SOTA methods in face similarity, face FID, and CLIP semantic alignment. The
code and dataset will be made publicly available at
https://github.com/rain152/LFA-Video-Generation.

</details>


### [50] [CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection](https://arxiv.org/abs/2508.09477)
*Zhipeng Yuan,Kai Wang,Weize Quan,Dong-Ming Yan,Tieru Wu*

Main category: cs.CV

TL;DR: A universal AI-generated image detector is proposed using anomaly detection. It leverages CLIP and normalizing flows, training on modified natural images to detect AI-generated images from unseen models.


<details>
  <summary>Details</summary>
Motivation: Most AI-generated image detectors struggle with unseen generative models because they are trained on natural images and AI-generated images. This paper proposes a universal detector from an anomaly detection perspective that does not require AI-generated images for training.

Method: The method uses a pre-trained CLIP encoder as a feature extractor and a normalizing flow-like unsupervised model. It trains by minimizing the likelihood of proxy images (natural images with spectral modification) and optionally maximizing the likelihood of natural images.

Result: Extensive experiments demonstrate the effectiveness of the proposed method.

Conclusion: The proposed method is effective for detecting AI-generated images from various generators.

Abstract: With the rapid advancement of AI generative models, the visual quality of
AI-generated images (AIIs) has become increasingly close to natural images,
which inevitably raises security concerns. Most AII detectors often employ the
conventional image classification pipeline with natural images and AIIs
(generated by a generative model), which can result in limited detection
performance for AIIs from unseen generative models. To solve this, we proposed
a universal AI-generated image detector from the perspective of anomaly
detection. Our discriminator does not need to access any AIIs and learn a
generalizable representation with unsupervised learning. Specifically, we use
the pre-trained CLIP encoder as the feature extractor and design a normalizing
flow-like unsupervised model. Instead of AIIs, proxy images, e.g., obtained by
applying a spectral modification operation on natural images, are used for
training. Our models are trained by minimizing the likelihood of proxy images,
optionally combined with maximizing the likelihood of natural images. Extensive
experiments demonstrate the effectiveness of our method on AIIs produced by
various image generators.

</details>


### [51] [GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs](https://arxiv.org/abs/2508.09478)
*Moinak Bhattacharya,Gagandeep Singh,Shubham Jain,Prateek Prasanna*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we present GazeLT, a human visual attention
integration-disintegration approach for long-tailed disease classification. A
radiologist's eye gaze has distinct patterns that capture both fine-grained and
coarser level disease related information. While interpreting an image, a
radiologist's attention varies throughout the duration; it is critical to
incorporate this into a deep learning framework to improve automated image
interpretation. Another important aspect of visual attention is that apart from
looking at major/obvious disease patterns, experts also look at
minor/incidental findings (few of these constituting long-tailed classes)
during the course of image interpretation. GazeLT harnesses the temporal aspect
of the visual search process, via an integration and disintegration mechanism,
to improve long-tailed disease classification. We show the efficacy of GazeLT
on two publicly available datasets for long-tailed disease classification,
namely the NIH-CXR-LT (n=89237) and the MIMIC-CXR-LT (n=111898) datasets.
GazeLT outperforms the best long-tailed loss by 4.1% and the visual
attention-based baseline by 21.7% in average accuracy metrics for these
datasets. Our code is available at https://github.com/lordmoinak1/gazelt.

</details>


### [52] [SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images](https://arxiv.org/abs/2508.09479)
*Xuejun Huang,Xinyi Liu,Yi Wan,Zhi Zheng,Bin Zhang,Mingtao Xiong,Yingying Pei,Yongjun Zhang*

Main category: cs.CV

TL;DR: SkySplat通过整合RPC模型和自监督学习，解决了稀疏卫星图像三维重建的挑战，在效率和精度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法不兼容RPC模型且泛化能力有限，不适用于卫星图像；现有可泛化3DGS方法在多时相稀疏卫星图像上表现不佳，存在几何约束有限、瞬态对象和辐射度不一致等问题。

Method: 提出了一种名为SkySplat的自监督框架，该框架集成了RPC模型到可泛化的3DGS流程中，并包含一个跨自一致性模块（CSCM）来处理瞬态对象，以及一种多视图一致性聚合策略来优化重建。

Result: SkySplat相比于EOGS实现了86倍的加速，同时提高了精度。与可泛化的3DGS基线相比，在DFC19数据集上将MAE从13.18m降低到1.80m，并在MVS3D基准测试中展示了强大的跨数据集泛化能力。

Conclusion: SkySplat通过整合RPC模型到可泛化的3DGS流程中，并利用改进的几何约束和辐射度不变性，显著提高了稀疏卫星图像三维重建的准确性和效率，且无需地面真实高程图。

Abstract: Three-dimensional scene reconstruction from sparse-view satellite images is a
long-standing and challenging task. While 3D Gaussian Splatting (3DGS) and its
variants have recently attracted attention for its high efficiency, existing
methods remain unsuitable for satellite images due to incompatibility with
rational polynomial coefficient (RPC) models and limited generalization
capability. Recent advances in generalizable 3DGS approaches show potential,
but they perform poorly on multi-temporal sparse satellite images due to
limited geometric constraints, transient objects, and radiometric
inconsistencies. To address these limitations, we propose SkySplat, a novel
self-supervised framework that integrates the RPC model into the generalizable
3DGS pipeline, enabling more effective use of sparse geometric cues for
improved reconstruction. SkySplat relies only on RGB images and
radiometric-robust relative height supervision, thereby eliminating the need
for ground-truth height maps. Key components include a Cross-Self Consistency
Module (CSCM), which mitigates transient object interference via
consistency-based masking, and a multi-view consistency aggregation strategy
that refines reconstruction results. Compared to per-scene optimization
methods, SkySplat achieves an 86 times speedup over EOGS with higher accuracy.
It also outperforms generalizable 3DGS baselines, reducing MAE from 13.18 m to
1.80 m on the DFC19 dataset significantly, and demonstrates strong
cross-dataset generalization on the MVS3D benchmark.

</details>


### [53] [Episodic Memory Representation for Long-form Video Understanding](https://arxiv.org/abs/2508.09486)
*Yun Wang,Long Zhang,Jingren Liu,Jiaqi Yan,Zhanjie Zhang,Jiahao Zheng,Xun Yang,Dapeng Wu,Xiangyu Chen,Xuelong Li*

Main category: cs.CV

TL;DR: Video-EM通过情景记忆和链式思考，解决了长视频理解中的关键帧冗余和时空信息丢失问题，并在多个基准测试中提升了视频问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在长视频理解方面存在上下文窗口限制，关键帧检索方法忽略了时空关系且可能产生冗余信息，导致视频问答准确性下降。本研究旨在解决这些问题。

Method: Video-EM框架采用类似人类情景记忆的原理，将关键帧作为时间有序的情景事件进行建模，并结合LLM的链式思考（CoT）来迭代地识别最少但信息量最大的情景记忆子集。

Result: Video-EM在Video-MME、EgoSchema、HourVideo和LVBench基准测试中取得了优于基线方法4-9%的性能提升，同时使用了更少的帧数。

Conclusion: Video-EM通过将关键帧建模为时间有序的事件来解决长视频理解中的上下文窗口限制问题，并利用LLM的链式思考来选择信息量大的关键帧子集，从而实现了在Video-MME、EgoSchema、HourVideo和LVBench基准测试中的优越性能，相比现有方法在帧数更少的情况下提升了4-9%的性能。

Abstract: Video Large Language Models (Video-LLMs) excel at general video understanding
but struggle with long-form videos due to context window limits. Consequently,
recent approaches focus on keyframe retrieval, condensing lengthy videos into a
small set of informative frames. Despite their practicality, these methods
simplify the problem to static text image matching, overlooking spatio temporal
relationships crucial for capturing scene transitions and contextual
continuity, and may yield redundant keyframes with limited information,
diluting salient cues essential for accurate video question answering. To
address these limitations, we introduce Video-EM, a training free framework
inspired by the principles of human episodic memory, designed to facilitate
robust and contextually grounded reasoning. Rather than treating keyframes as
isolated visual entities, Video-EM explicitly models them as temporally ordered
episodic events, capturing both spatial relationships and temporal dynamics
necessary for accurately reconstructing the underlying narrative. Furthermore,
the framework leverages chain of thought (CoT) thinking with LLMs to
iteratively identify a minimal yet highly informative subset of episodic
memories, enabling efficient and accurate question answering by Video-LLMs.
Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench
benchmarks confirm the superiority of Video-EM, which achieves highly
competitive results with performance gains of 4-9 percent over respective
baselines while utilizing fewer frames.

</details>


### [54] [SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection](https://arxiv.org/abs/2508.09487)
*Ju Yeon Kang,Jaehong Park,Semin Kim,Ji Won Yoon,Nam Soo Kim*

Main category: cs.CV

TL;DR: 通过衡量图像与其标题引导重建之间的语义差异（SARE），可以有效检测出假图像，即使这些图像来自未知的生成模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于模型特定伪影的检测方法在面对未见过的、分布外（OOD）生成模型产生的假图像时性能下降的问题。

Method: 提出了一种名为“语义感知重建误差”（SARE）的新表示方法，通过量化图像与其标题引导重建之间的语义差异来进行检测。

Result: SARE作为一种区分性特征，能够跨不同生成模型进行鲁棒检测。

Conclusion: 所提出的方法在GenImage和CommunityForensics等基准测试中表现优于现有方法，并具有强大的泛化能力。

Abstract: Recently, diffusion-generated image detection has gained increasing
attention, as the rapid advancement of diffusion models has raised serious
concerns about their potential misuse. While existing detection methods have
achieved promising results, their performance often degrades significantly when
facing fake images from unseen, out-of-distribution (OOD) generative models,
since they primarily rely on model-specific artifacts. To address this
limitation, we explore a fundamental property commonly observed in fake images.
Motivated by the observation that fake images tend to exhibit higher similarity
to their captions than real images, we propose a novel representation, namely
Semantic-Aware Reconstruction Error (SARE), that measures the semantic
difference between an image and its caption-guided reconstruction. The
hypothesis behind SARE is that real images, whose captions often fail to fully
capture their complex visual content, may undergo noticeable semantic shifts
during the caption-guided reconstruction process. In contrast, fake images,
which closely align with their captions, show minimal semantic changes. By
quantifying these semantic shifts, SARE can be utilized as a discriminative
feature for robust detection across diverse generative models. We empirically
demonstrate that the proposed method exhibits strong generalization,
outperforming existing baselines on benchmarks including GenImage and
CommunityForensics.

</details>


### [55] [CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking](https://arxiv.org/abs/2508.09499)
*Liyan Jia,Chuan-Xian Ren,Hong Yan*

Main category: cs.CV

TL;DR: CWFBind是一种新的对接方法，通过结合局部曲率特征和先进的训练策略来提高准确性和效率，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 许多基于图表示和语言模型编码器的方法在对接中忽略了关键的几何信息，导致口袋定位不准确和结合构象不切实际。本研究旨在通过CWFBind来解决这些问题。

Method: CWFBind通过在特征提取阶段整合局部曲率描述符来丰富蛋白质和配体的几何表示，并结合度感知加权机制来增强模型捕捉空间结构差异和相互作用强度的能力。为解决口袋预测中的类别不平衡问题，CWFBind采用了感知配体的动态半径策略和增强的损失函数。

Result: CWFBind在多个对接基准测试中取得了有竞争力的性能，在准确性和效率之间提供了平衡的折衷。

Conclusion: CWFBind是一种基于局部曲率特征的加权、快速、准确的对接方法，在多个对接基准测试中均表现出竞争力，并在准确性和效率之间取得了良好的平衡。

Abstract: Accurately predicting the binding conformation of small-molecule ligands to
protein targets is a critical step in rational drug design. Although recent
deep learning-based docking surpasses traditional methods in speed and
accuracy, many approaches rely on graph representations and language
model-inspired encoders while neglecting critical geometric information,
resulting in inaccurate pocket localization and unrealistic binding
conformations. In this study, we introduce CWFBind, a weighted, fast, and
accurate docking method based on local curvature features. Specifically, we
integrate local curvature descriptors during the feature extraction phase to
enrich the geometric representation of both proteins and ligands, complementing
existing chemical, sequence, and structural features. Furthermore, we embed
degree-aware weighting mechanisms into the message passing process, enhancing
the model's ability to capture spatial structural distinctions and interaction
strengths. To address the class imbalance challenge in pocket prediction,
CWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced
loss function, facilitating more precise identification of binding regions and
key residues. Comprehensive experimental evaluations demonstrate that CWFBind
achieves competitive performance across multiple docking benchmarks, offering a
balanced trade-off between accuracy and efficiency.

</details>


### [56] [Generation of Indian Sign Language Letters, Numbers, and Words](https://arxiv.org/abs/2508.09522)
*Ajeet Kumar Yadav,Nishant Kumar,Rathna G N*

Main category: cs.CV

TL;DR: 提出了一种结合ProGAN和SAGAN的改进GAN模型，用于生成高质量印度手语图像，并在IS和FID指标上优于ProGAN。同时发布了一个包含印度手语字母、数字和129个单词的高质量图像数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管在（手语）识别方面取得了进展，但手语生成仍需探索。为了生成高质量、高分辨率且包含丰富特征的手语图像，需要平衡分辨率和细节，因此提出结合ProGAN和SAGAN的模型。

Method: 结合了Progressive Growing of Generative Adversarial Network (ProGAN)和Self-Attention Generative Adversarial Network (SAGAN)的优点，开发了一种改进的基于注意力的生成对抗网络（GAN）变体，用于生成印度手语字母、数字和单词的图像。

Result: 所提出的改进模型在印度手语字母、数字和单词的图像生成方面，在IS和FID指标上分别比传统ProGAN提高了3.2和30.12。

Conclusion: 开发了一种改进的基于注意力生成对抗网络（GAN）的模型，能够生成特征丰富、高分辨率且类别条件化的印度手语图像，在Inception Score (IS)和Fréchet Inception Distance (FID)方面优于传统的ProGAN，分别提高了3.2和30.12。此外，还发布了一个包含印度手语字母、数字和129个单词的高质量图像的大型数据集。

Abstract: Sign language, which contains hand movements, facial expressions and bodily
gestures, is a significant medium for communicating with hard-of-hearing
people. A well-trained sign language community communicates easily, but those
who don't know sign language face significant challenges. Recognition and
generation are basic communication methods between hearing and hard-of-hearing
individuals. Despite progress in recognition, sign language generation still
needs to be explored. The Progressive Growing of Generative Adversarial Network
(ProGAN) excels at producing high-quality images, while the Self-Attention
Generative Adversarial Network (SAGAN) generates feature-rich images at medium
resolutions. Balancing resolution and detail is crucial for sign language image
generation. We are developing a Generative Adversarial Network (GAN) variant
that combines both models to generate feature-rich, high-resolution, and
class-conditional sign language images. Our modified Attention-based model
generates high-quality images of Indian Sign Language letters, numbers, and
words, outperforming the traditional ProGAN in Inception Score (IS) and
Fr\'echet Inception Distance (FID), with improvements of 3.2 and 30.12,
respectively. Additionally, we are publishing a large dataset incorporating
high-quality images of Indian Sign Language alphabets, numbers, and 129 words.

</details>


### [57] [SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking](https://arxiv.org/abs/2508.09524)
*Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao*

Main category: cs.CV

TL;DR: 本研究首次量化了相似目标干扰（SOI）对单目标跟踪（SOT）的负面影响，并提出了SOIBench基准来评估利用语义认知指导进行跟踪。研究发现，现有视觉-语言跟踪（VLT）方法未能有效利用语义指导，而基于大规模视觉-语言模型（VLM）的新方法则显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 单目标跟踪（SOT）中的相似目标干扰（SOI）是一个长期被忽视但关键的瓶颈，影响着跟踪的鲁棒性。本研究旨在系统性地研究SOI的影响，并探索利用外部语义认知指导来解决这一问题，以提升跟踪性能。

Method: 本研究通过在线干扰掩蔽（OIM）实验来量化相似目标干扰（SOI）对单目标跟踪（SOT）的影响，并构建了SOIBench基准来评估利用语义认知指导进行跟踪的方法。在SOIBench上，我们对比了现有VLT方法和我们提出的基于大规模视觉-语言模型（VLM）的新范式。

Result: 通过OIM实验，我们发现消除干扰源可显著提高SOTA跟踪器的AUC，最高可达4.35%。在SOIBench上，现有VLT方法在利用语义认知指导方面表现不佳，而我们提出的基于VLM的新范式则取得了显著的性能提升，AUC最高可提高0.93%。

Conclusion: 本研究首次系统性地研究和量化了相似目标干扰（SOI），这是一个被忽视但对单目标跟踪（SOT）至关重要的瓶颈。通过在线干扰掩蔽（OIM）实验，我们证明了消除干扰源可以显著提高所有SOTA跟踪器的性能（AUC提高高达4.35%），验证了SOI是鲁棒跟踪的主要限制因素，并强调了外部认知指导的可行性。在此基础上，我们构建了SOIBench——首个针对SOI挑战的语义认知指导基准，通过多跟踪器集体判断自动挖掘SOI帧，并引入多级注释协议生成精确的语义指导文本。现有视觉-语言跟踪（VLT）方法在SOIBench上的表现不佳，仅有边际改进或性能下降（AUC变化-0.26%至+0.71%）。我们提出了一种新范式，采用大规模视觉-语言模型（VLM）作为外部认知引擎，可无缝集成到任意RGB跟踪器中，并在语义认知指导下实现了显著的性能提升（AUC提高高达0.93%），远超现有VLT方法。我们希望SOIBench能成为推动语义认知跟踪研究的标准评估平台，并为跟踪研究社区带来新见解。

Abstract: In this paper, we present the first systematic investigation and
quantification of Similar Object Interference (SOI), a long-overlooked yet
critical bottleneck in Single Object Tracking (SOT). Through controlled Online
Interference Masking (OIM) experiments, we quantitatively demonstrate that
eliminating interference sources leads to substantial performance improvements
(AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a
primary constraint for robust tracking and highlighting the feasibility of
external cognitive guidance. Building upon these insights, we adopt natural
language as a practical form of external guidance, and construct SOIBench-the
first semantic cognitive guidance benchmark specifically targeting SOI
challenges. It automatically mines SOI frames through multi-tracker collective
judgment and introduces a multi-level annotation protocol to generate precise
semantic guidance texts. Systematic evaluation on SOIBench reveals a striking
finding: existing vision-language tracking (VLT) methods fail to effectively
exploit semantic cognitive guidance, achieving only marginal improvements or
even performance degradation (AUC changes of -0.26 to +0.71). In contrast, we
propose a novel paradigm employing large-scale vision-language models (VLM) as
external cognitive engines that can be seamlessly integrated into arbitrary RGB
trackers. This approach demonstrates substantial improvements under semantic
cognitive guidance (AUC gains up to 0.93), representing a significant
advancement over existing VLT methods. We hope SOIBench will serve as a
standardized evaluation platform to advance semantic cognitive tracking
research and contribute new insights to the tracking research community.

</details>


### [58] [COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets](https://arxiv.org/abs/2508.09886)
*Lingyu Chen,Yawen Zeng,Yue Wang,Peng Wan,Guo-chen Ning,Hongen Liao,Daoqiang Zhang,Fang Chen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Conventional single-dataset training often fails with new data distributions,
especially in ultrasound (US) image analysis due to limited data, acoustic
shadows, and speckle noise. Therefore, constructing a universal framework for
multi-heterogeneous US datasets is imperative. However, a key challenge arises:
how to effectively mitigate inter-dataset interference while preserving
dataset-specific discriminative features for robust downstream task? Previous
approaches utilize either a single source-specific decoder or a domain
adaptation strategy, but these methods experienced a decline in performance
when applied to other domains. Considering this, we propose a Universal
Collaborative Mixture of Heterogeneous Source-Specific Experts (COME).
Specifically, COME establishes dual structure-semantic shared experts that
create a universal representation space and then collaborate with
source-specific experts to extract discriminative features through providing
complementary features. This design enables robust generalization by leveraging
cross-datasets experience distributions and providing universal US priors for
small-batch or unseen data scenarios. Extensive experiments under three
evaluation modes (single-dataset, intra-organ, and inter-organ integration
datasets) demonstrate COME's superiority, achieving significant mean AP
improvements over state-of-the-art methods. Our project is available at:
https://universalcome.github.io/UniversalCOME/.

</details>


### [59] [Learning Spatial Decay for Vision Transformers](https://arxiv.org/abs/2508.09525)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: SDT adapts data-dependent spatial decay to ViTs using a novel Context-Aware Gating (CAG) mechanism, improving performance on spatially-structured tasks by learning to modulate spatial attention based on content and proximity.


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs) lack explicit spatial inductive biases, leading to suboptimal performance on spatially-structured tasks. Existing approaches use data-independent spatial decay with fixed distance metrics, limiting adaptability.

Method: SDT features a novel Context-Aware Gating (CAG) mechanism that generates dynamic, data-dependent decay for patch interactions. It learns to modulate spatial attention based on both content relevance and spatial proximity. The 1D-to-2D adaptation is addressed through a unified spatial-content fusion framework that integrates manhattan distance-based spatial priors with learned content representations.

Result: Extensive experiments on ImageNet-1K classification and generation tasks demonstrate consistent improvements over strong baselines.

Conclusion: SDT establishes data-dependent spatial decay as a new paradigm for enhancing spatial attention in vision transformers.

Abstract: Vision Transformers (ViTs) have revolutionized computer vision, yet their
self-attention mechanism lacks explicit spatial inductive biases, leading to
suboptimal performance on spatially-structured tasks. Existing approaches
introduce data-independent spatial decay based on fixed distance metrics,
applying uniform attention weighting regardless of image content and limiting
adaptability to diverse visual scenarios. Inspired by recent advances in large
language models where content-aware gating mechanisms (e.g., GLA, HGRN2, FOX)
significantly outperform static alternatives, we present the first successful
adaptation of data-dependent spatial decay to 2D vision transformers. We
introduce \textbf{Spatial Decay Transformer (SDT)}, featuring a novel
Context-Aware Gating (CAG) mechanism that generates dynamic, data-dependent
decay for patch interactions. Our approach learns to modulate spatial attention
based on both content relevance and spatial proximity. We address the
fundamental challenge of 1D-to-2D adaptation through a unified spatial-content
fusion framework that integrates manhattan distance-based spatial priors with
learned content representations. Extensive experiments on ImageNet-1K
classification and generation tasks demonstrate consistent improvements over
strong baselines. Our work establishes data-dependent spatial decay as a new
paradigm for enhancing spatial attention in vision transformers.

</details>


### [60] [Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation](https://arxiv.org/abs/2508.09987)
*Junyan Ye,Dongzhi Jiang,Zihao Wang,Leqi Zhu,Zhenghao Hu,Zilong Huang,Jun He,Zhiyuan Yan,Jinghua Yu,Hongsheng Li,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: 本文提出使用GPT-4o生成的合成数据集Echo-4o-Image来增强开源图像生成模型。与真实数据相比，合成数据能更好地补充罕见场景并提供更纯净、可控的监督信号。基于此数据集训练的Echo-4o模型表现优异，且数据集具有良好的迁移性，能提升其他基础模型的性能。同时，研究还提出了新的评估基准GenEval++和Imagine-Bench。


<details>
  <summary>Details</summary>
Motivation: 尽管GPT-4o在图像生成方面表现出色，但开源模型仍有差距。现有研究尝试通过蒸馏GPT-4o的图像数据来增强开源模型，但忽略了一个关键问题：在已存在高质量真实世界图像数据集的情况下，为何要使用GPT-4o生成的合成数据？本文旨在探讨合成数据的优势，并提出解决方案。

Method: 本文提出了Echo-4o-Image数据集，该数据集由GPT-4o生成，规模为180K。研究利用合成图像的两个关键优势：补充真实世界数据集中罕见的场景（如超现实幻想、多参考图像生成）以及提供可控的监督信号（纯净背景、长尾监督信号），以实现更精确的文本到图像对齐。基于此数据集，研究微调了统一的多模态生成基线模型Bagel，得到了Echo-4o。同时，提出了两个新的评估基准GenEval++和Imagine-Bench，用于更准确、更具挑战性地评估图像生成能力。GenEval++通过增加指令复杂度来缓解分数饱和，Imagine-Bench则侧重于评估富有想象力的内容的理解和生成能力。

Result: Echo-4o在标准基准测试中表现强劲。此外，将Echo-4o-Image应用于其他基础模型（如OmniGen2、BLIP3-o）能在多个指标上取得持续的性能提升，证明了其强大的迁移能力。

Conclusion: Echo-4o-Image是一个由GPT-4o生成的180K规模的合成数据集，通过利用合成图像数据来解决真实世界数据覆盖的盲点。使用该数据集微调的Echo-4o在标准基准测试中表现强劲。此外，Echo-4o-Image应用于其他基础模型（如OmniGen2、BLIP3-o）能在多个指标上取得持续的性能提升，证明了其强大的迁移能力。

Abstract: Recently, GPT-4o has garnered significant attention for its strong
performance in image generation, yet open-source models still lag behind.
Several studies have explored distilling image data from GPT-4o to enhance
open-source models, achieving notable progress. However, a key question
remains: given that real-world image datasets already constitute a natural
source of high-quality data, why should we use GPT-4o-generated synthetic data?
In this work, we identify two key advantages of synthetic images. First, they
can complement rare scenarios in real-world datasets, such as surreal fantasy
or multi-reference image generation, which frequently occur in user queries.
Second, they provide clean and controllable supervision. Real-world data often
contains complex background noise and inherent misalignment between text
descriptions and image content, whereas synthetic images offer pure backgrounds
and long-tailed supervision signals, facilitating more accurate text-to-image
alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale
synthetic dataset generated by GPT-4o, harnessing the power of synthetic image
data to address blind spots in real-world coverage. Using this dataset, we
fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o.
In addition, we propose two new evaluation benchmarks for a more accurate and
challenging assessment of image generation capabilities: GenEval++, which
increases instruction complexity to mitigate score saturation, and
Imagine-Bench, which focuses on evaluating both the understanding and
generation of imaginative content. Echo-4o demonstrates strong performance
across standard benchmarks. Moreover, applying Echo-4o-Image to other
foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains
across multiple metrics, highlighting the datasets strong transferability.

</details>


### [61] [Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing](https://arxiv.org/abs/2508.09528)
*Gang Qu,Ping Wang,Siming Zheng,Xin Yuan*

Main category: cs.CV

TL;DR: 提出了一种新颖的非对称 Kronecker CS (AKCS) 模型和测量感知交叉注意力 (MACA) 机制，以提高图像压缩传感任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在感知阶段的测量不相关性和重建阶段的隐式测量表示方面存在不足，限制了整体性能。

Method: 提出了一种新颖的非对称 Kronecker CS (AKCS) 模型，并提出了一个测量感知交叉注意力 (MACA) 机制，将它们集成到广泛使用的展开架构中，形成一个测量增强的展开网络 (MEUNet)。

Result: AKCS 比以前的 Kronecker CS 具有更好的不相关性，并且 MACA 能够学习隐式测量表示，从而使 MEUNet 在重建精度和推理速度方面取得最先进的性能。

Conclusion: MEUNet 实现了最先进的重建精度和推理速度。

Abstract: Deep networks have achieved remarkable success in image compressed sensing
(CS) task, namely reconstructing a high-fidelity image from its compressed
measurement. However, existing works are deficient inincoherent compressed
measurement at sensing phase and implicit measurement representations at
reconstruction phase, limiting the overall performance. In this work, we answer
two questions: 1) how to improve the measurement incoherence for decreasing the
ill-posedness; 2) how to learn informative representations from measurements.
To this end, we propose a novel asymmetric Kronecker CS (AKCS) model and
theoretically present its better incoherence than previous Kronecker CS with
minimal complexity increase. Moreover, we reveal that the unfolding networks'
superiority over non-unfolding ones result from sufficient gradient descents,
called explicit measurement representations. We propose a measurement-aware
cross attention (MACA) mechanism to learn implicit measurement representations.
We integrate AKCS and MACA into widely-used unfolding architecture to get a
measurement-enhanced unfolding network (MEUNet). Extensive experiences
demonstrate that our MEUNet achieves state-of-the-art performance in
reconstruction accuracy and inference speed.

</details>


### [62] [COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection](https://arxiv.org/abs/2508.09533)
*Peiran Peng,Tingfa Xu,Liqiang Song,Mengqi Zhu,Yuqiang Fang,Jianan Li*

Main category: cs.CV

TL;DR: COXNet 通过跨层融合、动态对齐和优化的标签分配，有效解决了 RGBT 图像中微小目标的检测挑战，特别是在无人机场景下，实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 检测 RGBT 图像中的微小目标是计算机视觉中的一个关键挑战，尤其是在监控、搜索救援和自主导航等领域。无人机场景由于空间错位、光照不足、遮挡和杂乱背景等因素，进一步加剧了这些挑战。现有方法在有效利用可见光和热成像模态之间的互补信息方面存在困难。

Method: 提出了一种名为 COXNet 的新颖 RGBT 目标检测框架，包含三个核心创新：1. 跨层融合模块：融合高层可见光和低层热成像特征以提高语义和空间精度。2. 动态对齐和尺度精炼模块：纠正跨模态空间错位并保留多尺度特征。3. 优化的标签分配策略：使用地理形状相似性度量来改进定位。

Result: COXNet 在 RGBTDronePerson 数据集上取得了 3.32% 的 mAP50 提升，优于现有最先进的方法。

Conclusion: COXNet 在 RGBTDronePerson 数据集上实现了 3.32% 的 mAP50 提升，证明了其在复杂环境中鲁棒检测的有效性。

Abstract: Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is
a critical challenge in computer vision, particularly in surveillance, search
and rescue, and autonomous navigation. Drone-based scenarios exacerbate these
challenges due to spatial misalignment, low-light conditions, occlusion, and
cluttered backgrounds. Current methods struggle to leverage the complementary
information between visible and thermal modalities effectively. We propose
COXNet, a novel framework for RGBT tiny object detection, addressing these
issues through three core innovations: i) the Cross-Layer Fusion Module, fusing
high-level visible and low-level thermal features for enhanced semantic and
spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module,
correcting cross-modal spatial misalignments and preserving multi-scale
features; and iii) an optimized label assignment strategy using the GeoShape
Similarity Measure for better localization. COXNet achieves a 3.32\% mAP$_{50}$
improvement on the RGBTDronePerson dataset over state-of-the-art methods,
demonstrating its effectiveness for robust detection in complex environments.

</details>


### [63] [Iterative Volume Fusion for Asymmetric Stereo Matching](https://arxiv.org/abs/2508.09543)
*Yuanting Gao,Linghao Shen*

Main category: cs.CV

TL;DR: 一种用于非对称立体匹配的新型网络IVF-AStereo，通过融合两种代价体积来解决视觉不对称问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的立体匹配算法多假设双目视觉对称，但实际应用中的非对称多摄像头系统（如长焦-广角摄像头）打破了这一假设，增加了立体匹配的难度。视觉不对称性会影响关键的代价体积（cost volume）计算，从而干扰立体匹配。

Method: 提出了一种名为Iterative Volume Fusion network for Asymmetric Stereo matching (IVF-AStereo) 的两阶段网络。首先，聚合的连接体（aggregated concatenation volume）对相关体（correlation volume）进行细化，随后融合这两个体以增强精细细节。

Result: 该方法在非对称立体匹配方面表现优异，并能有效应对显著的视觉不对称性，在分辨率和颜色退化的情况下仍能保持稳健性能。

Conclusion: 提出的IVF-AStereo网络在非对称立体匹配场景中表现优异，并且能够有效应对显著的视觉不对称性。通过分辨率和颜色退化等方面的对比实验和消融研究，证实了该方法在非对称立体匹配方面的有效性。

Abstract: Stereo matching is vital in 3D computer vision, with most algorithms assuming
symmetric visual properties between binocular visions. However, the rise of
asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this
assumption and complicates stereo matching. Visual asymmetry disrupts stereo
matching by affecting the crucial cost volume computation. To address this, we
explore the matching cost distribution of two established cost volume
construction methods in asymmetric stereo. We find that each cost volume
experiences distinct information distortion, indicating that both should be
comprehensively utilized to solve the issue. Based on this, we propose the
two-phase Iterative Volume Fusion network for Asymmetric Stereo matching
(IVF-AStereo). Initially, the aggregated concatenation volume refines the
correlation volume. Subsequently, both volumes are fused to enhance fine
details. Our method excels in asymmetric scenarios and shows robust performance
against significant visual asymmetry. Extensive comparative experiments on
benchmark datasets, along with ablation studies, confirm the effectiveness of
our approach in asymmetric stereo with resolution and color degradation.

</details>


### [64] [GoViG: Goal-Conditioned Visual Navigation Instruction Generation](https://arxiv.org/abs/2508.09547)
*Fengyi Wu,Yifei Dong,Zhi-Qi Cheng,Yilong Dai,Guangyu Chen,Hang Wang,Qi Dai,Alexander G. Hauptmann*

Main category: cs.CV

TL;DR: 提出GoViG，一种仅基于视觉输入生成导航指令的方法，克服了对结构化输入的依赖，并在新数据集上取得了优于SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在没有结构化输入（如语义标注或环境地图）的情况下，仅从初始和目标状态的自主视觉观察中生成精确且上下文连贯的导航指令，从而提高在未见过的非结构化环境中的适应性。

Method: GoViG方法将导航指令生成任务分解为视觉预测和指令生成两个子任务，并利用自回归多模态大语言模型进行整合训练，同时引入了单通道和交叉推理两种推理策略。

Result: 在R2R-Goal数据集上的实验结果表明，GoViG方法在BLEU-4和CIDEr分数上显著优于现有最先进方法，并具有良好的跨领域泛化能力。

Conclusion: GoViG方法在R2R-Goal数据集上取得了显著的性能提升，并在跨领域泛化方面表现出鲁棒性，优于现有最先进的方法，达到了更高的BLEU-4和CIDEr分数。

Abstract: We introduce Goal-Conditioned Visual Navigation Instruction Generation
(GoViG), a new task that aims to autonomously generate precise and contextually
coherent navigation instructions solely from egocentric visual observations of
initial and goal states. Unlike conventional approaches that rely on structured
inputs such as semantic annotations or environmental maps, GoViG exclusively
leverages raw egocentric visual data, substantially improving its adaptability
to unseen and unstructured environments. Our method addresses this task by
decomposing it into two interconnected subtasks: (1) visual forecasting, which
predicts intermediate visual states bridging the initial and goal views; and
(2) instruction generation, which synthesizes linguistically coherent
instructions grounded in both observed and anticipated visuals. These subtasks
are integrated within an autoregressive multimodal large language model trained
with tailored objectives to ensure spatial accuracy and linguistic clarity.
Furthermore, we introduce two complementary multimodal reasoning strategies,
one-pass and interleaved reasoning, to mimic incremental human cognitive
processes during navigation. To evaluate our method, we propose the R2R-Goal
dataset, combining diverse synthetic and real-world trajectories. Empirical
results demonstrate significant improvements over state-of-the-art methods,
achieving superior BLEU-4 and CIDEr scores along with robust cross-domain
generalization.

</details>


### [65] [Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification](https://arxiv.org/abs/2508.09550)
*Haowen Wang,Guowei Zhang,Xiang Zhang,Zeyuan Chen,Haiyang Xu,Dou Hoon Kwark,Zhuowen Tu*

Main category: cs.CV

TL;DR: This paper investigates using synthetic images from generative models to improve image classification. It finds that synthetic data can be effective for augmentation and provides guidelines on how much synthetic data is needed to match the performance of using real data, even showing how this differs based on dataset size and the amount of synthetic data used.


<details>
  <summary>Details</summary>
Motivation: The primary motivation of this paper is to address a key scientific problem in machine learning: determining whether a generative model trained on a given dataset can enhance classification performance through closed-set generative data augmentation, and to understand the effective use and quantitative requirements of synthetic data for this purpose.

Method: This paper explores the distinctions and similarities between real and synthetic images generated by advanced generative models. It conducts extensive experiments to provide systematic insights into the effective use of closed-set synthetic data for augmentation, empirically determining the equivalent scale of synthetic images needed. Additionally, it shows quantitative equivalence between real data augmentation and open-set generative augmentation, and offers a guideline to quantify the increased scale of synthetic data augmentation required to achieve comparable image classification performance.

Result: The paper empirically determines the equivalent scale of synthetic images needed for augmentation and shows quantitative equivalence between real data augmentation and open-set generative augmentation. It offers a guideline to quantify the increased scale of synthetic data augmentation required to achieve comparable image classification performance, illustrating how this effect varies with the baseline training set size and the amount of synthetic data incorporated across natural and medical image datasets.

Conclusion: In conclusion, this paper provides systematic insights and empirical guidelines for using closed-set synthetic data for augmentation in image classification tasks, quantifying the equivalence between real and synthetic data augmentation and offering a methodology to determine the required scale of synthetic data for comparable performance.

Abstract: In this paper, we address a key scientific problem in machine learning: Given
a training set for an image classification task, can we train a generative
model on this dataset to enhance the classification performance? (i.e.,
closed-set generative data augmentation). We start by exploring the
distinctions and similarities between real images and closed-set synthetic
images generated by advanced generative models. Through extensive experiments,
we offer systematic insights into the effective use of closed-set synthetic
data for augmentation. Notably, we empirically determine the equivalent scale
of synthetic images needed for augmentation. In addition, we also show
quantitative equivalence between the real data augmentation and open-set
generative augmentation (generative models trained using data beyond the given
training set). While it aligns with the common intuition that real images are
generally preferred, our empirical formulation also offers a guideline to
quantify the increased scale of synthetic data augmentation required to achieve
comparable image classification performance. Our results on natural and medical
image datasets further illustrate how this effect varies with the baseline
training set size and the amount of synthetic data incorporated.

</details>


### [66] [Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning](https://arxiv.org/abs/2508.09555)
*Ahmet Öztel,İsmet Karaca*

Main category: cs.CV

TL;DR: 该研究提出了一种使用数字同调拓扑不变量的虹膜识别方法，准确率达到97.78%，优于CNN，并且具有可解释性、紧凑性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提出一种基于拓扑不变量的虹膜识别新方法，并评估其分类性能。

Method: 将标准化的虹膜图像（48x482像素）划分为子区域（例如6x54或3x27）。计算每个子区域的Betti0、Betti1及其比率，并将所得不变量作为特征矩阵，与逻辑回归、KNN和SVM（包括PCA和100次随机重复）结合使用。为了进行比较，还训练了一个卷积神经网络（CNN）。

Result: 逻辑回归的准确率达到了97.78 +/- 0.82%，优于CNN（96.44 +/- 1.32%）和其他基于特征的模型。拓扑特征表现出高准确率和低方差。

Conclusion: 这项工作首次将形式化数字同调中的拓扑不变量用于虹膜识别。

Abstract: Objective - This study presents a biometric identification method based on
topological invariants from 2D iris images, representing iris texture via
formally defined digital homology and evaluating classification performance.
  Methods - Each normalized iris image (48x482 pixels) is divided into grids
(e.g., 6x54 or 3x27). For each subregion, we compute Betti0, Betti1, and their
ratio using a recent algorithm for homology groups in 2D digital images. The
resulting invariants form a feature matrix used with logistic regression, KNN,
and SVM (with PCA and 100 randomized repetitions). A convolutional neural
network (CNN) is trained on raw images for comparison.
  Results - Logistic regression achieved 97.78 +/- 0.82% accuracy,
outperforming CNN (96.44 +/- 1.32%) and other feature-based models. The
topological features showed high accuracy with low variance.
  Conclusion - This is the first use of topological invariants from formal
digital homology for iris recognition. The method offers a compact,
interpretable, and accurate alternative to deep learning, useful when
explainability or limited data is important. Beyond iris recognition, it can
apply to other biometrics, medical imaging, materials science, remote sensing,
and interpretable AI. It runs efficiently on CPU-only systems and produces
robust, explainable features valuable for security-critical domains.

</details>


### [67] [WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description](https://arxiv.org/abs/2508.09565)
*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

Main category: cs.CV

TL;DR: This paper introduces WEC-DG, a new method for correcting images with poor lighting. It uses wavelet transforms and a novel degradation guidance approach to improve brightness, contrast, and detail, outperforming existing methods in tests.


<details>
  <summary>Details</summary>
Motivation: Current multi-exposure correction methods struggle with intra-class variability due to diverse lighting, environments, and weather, especially for single-exposure images. This paper aims to enhance the adaptability of these models under complex imaging conditions.

Method: The paper proposes a Wavelet-based Exposure Correction method with Degradation Guidance (WEC-DG). Key components include an Exposure Consistency Alignment Module (ECAM) with a degradation descriptor to address 'blurred' exposure degradation and ensure exposure consistency, and an Exposure Restoration and Detail Reconstruction Module (EDRM) that utilizes the light-detail decoupling properties of wavelet transform to process low-frequency information for exposure enhancement before using high-frequency information for detail reconstruction.

Result: Extensive experiments on multiple public datasets show that the proposed WEC-DG method outperforms existing algorithms, achieving significant performance improvements.

Conclusion: The proposed Wavelet-based Exposure Correction method with Degradation Guidance (WEC-DG) demonstrates superior performance compared to existing algorithms across multiple public datasets, validating its effectiveness and practical applicability in complex imaging conditions.

Abstract: Multi-exposure correction technology is essential for restoring images
affected by insufficient or excessive lighting, enhancing the visual experience
by improving brightness, contrast, and detail richness. However, current
multi-exposure correction methods often encounter challenges in addressing
intra-class variability caused by diverse lighting conditions, shooting
environments, and weather factors, particularly when processing images captured
at a single exposure level. To enhance the adaptability of these models under
complex imaging conditions, this paper proposes a Wavelet-based Exposure
Correction method with Degradation Guidance (WEC-DG). Specifically, we
introduce a degradation descriptor within the Exposure Consistency Alignment
Module (ECAM) at both ends of the processing pipeline to ensure exposure
consistency and achieve final alignment. This mechanism effectively addresses
miscorrected exposure anomalies caused by existing methods' failure to
recognize 'blurred' exposure degradation. Additionally, we investigate the
light-detail decoupling properties of the wavelet transform to design the
Exposure Restoration and Detail Reconstruction Module (EDRM), which processes
low-frequency information related to exposure enhancement before utilizing
high-frequency information as a prior guide for reconstructing spatial domain
details. This serial processing strategy guarantees precise light correction
and enhances detail recovery. Extensive experiments conducted on multiple
public datasets demonstrate that the proposed method outperforms existing
algorithms, achieving significant performance improvements and validating its
effectiveness and practical applicability.

</details>


### [68] [A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation](https://arxiv.org/abs/2508.09566)
*Haibo Jin,Haoxuan Che,Sunan He,Hao Chen*

Main category: cs.CV

TL;DR: 提出CoD框架，通过问答对话和多类型数据训练，提高放射报告的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的放射报告生成（RRG）模型在临床有效性（尤其是病灶属性描述）方面表现不佳，且生成的文本缺乏可解释性，难以获得放射科医生的信任。

Method: 提出了一种名为“连锁诊断”（CoD）的框架，通过对话生成问答对以提取关键发现，然后提示大型语言模型进行生成，并通过诊断和病灶定位模块增强可解释性和效率。采用包含问答对和病灶框的全监督学习策略进行训练。

Result: 构建了一个包含问答对和病灶框的全监督RRG数据集，开发了一个评估报告准确性的工具，并通过大量实验证明了CoD框架的有效性。

Conclusion: CoD框架在两个RRG基准上均优于专家模型和通用模型，并在句子与诊断/图像的准确对应方面表现出良好的可解释性。

Abstract: Despite the progress of radiology report generation (RRG), existing works
face two challenges: 1) The performances in clinical efficacy are
unsatisfactory, especially for lesion attributes description; 2) the generated
text lacks explainability, making it difficult for radiologists to trust the
results. To address the challenges, we focus on a trustworthy RRG model, which
not only generates accurate descriptions of abnormalities, but also provides
basis of its predictions. To this end, we propose a framework named chain of
diagnosis (CoD), which maintains a chain of diagnostic process for clinically
accurate and explainable RRG. It first generates question-answer (QA) pairs via
diagnostic conversation to extract key findings, then prompts a large language
model with QA diagnoses for accurate generation. To enhance explainability, a
diagnosis grounding module is designed to match QA diagnoses and generated
sentences, where the diagnoses act as a reference. Moreover, a lesion grounding
module is designed to locate abnormalities in the image, further improving the
working efficiency of radiologists. To facilitate label-efficient training, we
propose an omni-supervised learning strategy with clinical consistency to
leverage various types of annotations from different datasets. Our efforts lead
to 1) an omni-labeled RRG dataset with QA pairs and lesion boxes; 2) a
evaluation tool for assessing the accuracy of reports in describing lesion
location and severity; 3) extensive experiments to demonstrate the
effectiveness of CoD, where it outperforms both specialist and generalist
models consistently on two RRG benchmarks and shows promising explainability by
accurately grounding generated sentences to QA diagnoses and images.

</details>


### [69] [Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion](https://arxiv.org/abs/2508.09575)
*Jiwon Kim,Pureum Kim,SeonHwa Kim,Soobin Park,Eunju Cha,Kyong Hwan Jin*

Main category: cs.CV

TL;DR: 提出了一种名为双递归反馈（DRF）的免训练系统，用于改进文本到图像生成模型。该系统通过外观和生成反馈来优化潜在表示，以实现更精确的空间结构和外观控制，即使在跨类别迁移（如将人类运动应用于老虎）时也能取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有的可控文本到图像（T2I）扩散模型（如Ctrl-X和FreeControl）虽然在空间和外观控制方面表现出强大的能力，但它们在精确保留空间结构和捕捉与物体姿态、场景布局相关的细粒度条件方面存在不足。

Method: 提出了一种免训练的双递归反馈（DRF）系统，该系统包含外观反馈和生成反馈，可递归地优化中间潜在表示，以更好地反映给定的外观信息和用户的意图。这种双重更新机制能够将潜在表示引导至可靠的流形，从而有效地融合结构和外观属性。

Result: 所提出的DRF系统能够实现细粒度的图像生成，有效解决了现有模型在空间结构保持和细粒度条件捕捉方面的挑战。

Conclusion: 该方法能够生成高质量、语义连贯且结构一致的图像，即使在类不变的结构-外观融合中也能实现细粒度生成，例如将人类运动迁移到老虎的形态上。

Abstract: Recent advancements in controllable text-to-image (T2I) diffusion models,
such as Ctrl-X and FreeControl, have demonstrated robust spatial and appearance
control without requiring auxiliary module training. However, these models
often struggle to accurately preserve spatial structures and fail to capture
fine-grained conditions related to object poses and scene layouts. To address
these challenges, we propose a training-free Dual Recursive Feedback (DRF)
system that properly reflects control conditions in controllable T2I models.
The proposed DRF consists of appearance feedback and generation feedback that
recursively refines the intermediate latents to better reflect the given
appearance information and the user's intent. This dual-update mechanism guides
latent representations toward reliable manifolds, effectively integrating
structural and appearance attributes. Our approach enables fine-grained
generation even between class-invariant structure-appearance fusion, such as
transferring human motion onto a tiger's form. Extensive experiments
demonstrate the efficacy of our method in producing high-quality, semantically
coherent, and structurally consistent image generations. Our source code is
available at https://github.com/jwonkm/DRF.

</details>


### [70] [SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs](https://arxiv.org/abs/2508.09584)
*Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: SHALE是一个新的基准，用于评估大型视觉语言模型（LVLMs）的幻觉问题。它通过自动化的数据构建和分层幻觉诱导框架，能够规模化、可控地评估LVLMs在忠实性和事实性方面的表现。实验表明LVLMs存在幻觉，且对输入变化敏感。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLMs在幻觉方面存在问题，现有的评估方法过于粗粒度且依赖手动标注，存在可扩展性和数据泄露的隐患。

Method: 提出了一种自动化的数据构建流程，用于生成可扩展、可控且多样化的评估数据，并设计了一个包含输入扰动的分层幻觉诱导框架来模拟现实世界的噪声场景。

Result: 构建了一个名为SHALE的可扩展幻觉评估基准，包含超过30K个图像-指令对，涵盖12个视觉感知方面和6个知识领域，用于评估忠实性和事实性幻觉。实验结果表明，LVLMs在事实性方面存在显著幻觉，并且对语义扰动敏感。

Conclusion: LVLMs在事实性和忠实性方面都存在显著的幻觉问题，并且对语义扰动非常敏感。

Abstract: Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer
from hallucinations, i.e., generating content inconsistent with input or
established world knowledge, which correspond to faithfulness and factuality
hallucinations, respectively. Prior studies primarily evaluate faithfulness
hallucination at a coarse level (e.g., object-level) and lack fine-grained
analysis. Additionally, existing benchmarks rely on costly manual curation or
reused public datasets, raising concerns about scalability and data leakage. To
address these limitations, we propose an automated data construction pipeline
that produces scalable, controllable, and diverse evaluation data. We also
design a hierarchical hallucination induction framework with input
perturbations to simulate realistic noisy scenarios. Integrating these designs,
we construct SHALE, a Scalable HALlucination Evaluation benchmark designed to
assess both faithfulness and factuality hallucinations via a fine-grained
hallucination categorization scheme. SHALE comprises over 30K image-instruction
pairs spanning 12 representative visual perception aspects for faithfulness and
6 knowledge domains for factuality, considering both clean and noisy scenarios.
Extensive experiments on over 20 mainstream LVLMs reveal significant factuality
hallucinations and high sensitivity to semantic perturbations.

</details>


### [71] [Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma](https://arxiv.org/abs/2508.09593)
*Haotian Tang,Jianwei Chen,Xinrui Tang,Yunjia Wu,Zhengyang Miao,Chao Li*

Main category: cs.CV

TL;DR: Hi-SMGNN is a new hierarchical framework for predicting IDH mutation status in glioma using structural and morphological connectomes. It addresses limitations of existing methods by incorporating the brain's hierarchical organization and multiscale interactions, outperforming current models.


<details>
  <summary>Details</summary>
Motivation: Current prediction methods for IDH mutation status in glioma are limited by the low availability and noise of functional MRI. Existing structural and morphological connectome approaches often ignore the brain's hierarchical organisation and multiscale interactions.

Method: A hierarchical framework that integrates structural and morphological connectomes from regional to modular levels, featuring a multimodal interaction module with a Siamese network and cross-modal attention, a multiscale feature fusion mechanism for reducing redundancy, and a personalised modular partitioning strategy.

Result: Experiments on the UCSF-PDGM dataset demonstrate that Hi-SMGNN outperforms baseline and state-of-the-art models.

Conclusion: Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved robustness and effectiveness in IDH mutation prediction.

Abstract: Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for
glioma prognosis. However, current prediction methods are limited by the low
availability and noise of functional MRI. Structural and morphological
connectomes offer a non-invasive alternative, yet existing approaches often
ignore the brain's hierarchical organisation and multiscale interactions. To
address this, we propose Hi-SMGNN, a hierarchical framework that integrates
structural and morphological connectomes from regional to modular levels. It
features a multimodal interaction module with a Siamese network and cross-modal
attention, a multiscale feature fusion mechanism for reducing redundancy, and a
personalised modular partitioning strategy to enhance individual specificity
and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that
Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved
robustness and effectiveness in IDH mutation prediction.

</details>


### [72] [SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing](https://arxiv.org/abs/2508.09597)
*Heyi Sun,Cong Wang,Tian-Xing Xu,Jingwei Huang,Di Kang,Chunchao Guo,Song-Hai Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 SVG-Head 的新方法，它使用 3D 高斯和纹理图像来创建可编辑的头部化身，实现了高保真度和实时编辑能力。


<details>
  <summary>Details</summary>
Motivation: 创建高保真度和可编辑的头部化身在计算机视觉和图形学领域是一个关键挑战，对 AR/VR 应用至关重要。现有方法在光线写实渲染和动画方面取得了进展，但在头部编辑，尤其是实时外观编辑方面仍然存在挑战，这主要是由于隐式表示以及几何和全局外观的耦合模型。

Method: 提出了一种名为 SVG-Head 的混合表示方法，该方法使用绑定在 FLAME 网格上的 3D 高斯来显式地表示几何，并利用解耦的纹理图像来捕捉整体外观。该方法包含两种类型的高斯：表面高斯和体积高斯。表面高斯使用可学习的纹理图像来显式地表示头部化身的外观，便于实时编辑；体积高斯则用于增强非朗伯区域（如嘴唇和头发）的重建质量。通过一种网格感知的高斯 UV 映射方法来建模 3D 世界和纹理空间之间的对应关系，利用 FLAME 网格提供的 UV 坐标来获得清晰的纹理图像和实时渲染速度。此外，还设计了一种分层优化策略来追求重建质量和编辑灵活性的最佳性能。

Result: 实验结果表明，SVG-Head 不仅能生成高保真的渲染效果，而且是首个为高斯头部化身提供显式纹理图像并支持实时外观编辑的方法。

Conclusion: SVG-Head 通过显式几何和解耦的纹理图像，实现了高保真度和可编辑的头部化身，是第一个支持实时外观编辑的高斯头部化身方法。

Abstract: Creating high-fidelity and editable head avatars is a pivotal challenge in
computer vision and graphics, boosting many AR/VR applications. While recent
advancements have achieved photorealistic renderings and plausible animation,
head editing, especially real-time appearance editing, remains challenging due
to the implicit representation and entangled modeling of the geometry and
global appearance. To address this, we propose Surface-Volumetric Gaussian Head
Avatar (SVG-Head), a novel hybrid representation that explicitly models the
geometry with 3D Gaussians bound on a FLAME mesh and leverages disentangled
texture images to capture the global appearance. Technically, it contains two
types of Gaussians, in which surface Gaussians explicitly model the appearance
of head avatars using learnable texture images, facilitating real-time texture
editing, while volumetric Gaussians enhance the reconstruction quality of
non-Lambertian regions (e.g., lips and hair). To model the correspondence
between 3D world and texture space, we provide a mesh-aware Gaussian UV mapping
method, which leverages UV coordinates given by the FLAME mesh to obtain sharp
texture images and real-time rendering speed. A hierarchical optimization
strategy is further designed to pursue the optimal performance in both
reconstruction quality and editing flexibility. Experiments on the NeRSemble
dataset show that SVG-Head not only generates high-fidelity rendering results,
but also is the first method to obtain explicit texture images for Gaussian
head avatars and support real-time appearance editing.

</details>


### [73] [Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality](https://arxiv.org/abs/2508.09598)
*Jie Shao,Ke Zhu,Minghao Fu,Guo-hua Wang,Jianxin Wu*

Main category: cs.CV

TL;DR: FaME improves image generation quality by identifying and avoiding low-quality samples using negative guidance, leading to better visual results without sacrificing FID scores.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art diffusion models often generate distorted or low-quality images despite impressive FID scores because FID evaluates global distribution alignment while ignoring the perceptual quality of individual samples. CFG, a common technique to enhance generation quality, can introduce distribution shift and visual artifacts due to misalignment with training objectives and user expectations.

Method: FaME uses an image quality assessment model to identify low-quality generations and stores their sampling trajectories. These failure modes are then used as negative guidance to steer future sampling away from poor-quality regions.

Result: Experiments on ImageNet demonstrate that FaME brings consistent improvements in visual quality without compromising FID.

Conclusion: FaME is a training-free and inference-efficient method that improves perceptual quality by using an image quality assessment model to identify low-quality generations and their sampling trajectories. These failure modes are then used as negative guidance to steer future sampling away from poor-quality regions, bringing consistent improvements in visual quality without compromising FID. FaME also shows potential for extension to text-to-image generation.

Abstract: Diffusion models have achieved remarkable progress in class-to-image
generation. However, we observe that despite impressive FID scores,
state-of-the-art models often generate distorted or low-quality images,
especially in certain classes. This gap arises because FID evaluates global
distribution alignment, while ignoring the perceptual quality of individual
samples. We further examine the role of CFG, a common technique used to enhance
generation quality. While effective in improving metrics and suppressing
outliers, CFG can introduce distribution shift and visual artifacts due to its
misalignment with both training objectives and user expectations. In this work,
we propose FaME, a training-free and inference-efficient method for improving
perceptual quality. FaME uses an image quality assessment model to identify
low-quality generations and stores their sampling trajectories. These failure
modes are then used as negative guidance to steer future sampling away from
poor-quality regions. Experiments on ImageNet demonstrate that FaME brings
consistent improvements in visual quality without compromising FID. FaME also
shows the potential to be extended to improve text-to-image generation.

</details>


### [74] [BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation](https://arxiv.org/abs/2508.09599)
*Beomjun Kim,Suhan Woo,Sejong Heo,Euntai Kim*

Main category: cs.CV

TL;DR: BridgeTA通过教师辅助网络，以更低的成本提升了纯相机的BEV地图分割性能。


<details>
  <summary>Details</summary>
Motivation: 虽然纯相机方法作为激光雷达的成本效益替代方案受到关注，但它们仍然落后于激光雷达-相机融合方法。现有的知识蒸馏方法主要通过模仿教师的架构来扩大学生模型，导致更高的推理成本。

Method: 该框架引入了一个轻量级的TA网络，结合了教师和学生的BEV表示，创建了一个共享的潜在空间作为中间表示。为从理论上支持该框架，研究人员利用Young不等式推导了一种蒸馏损失，将直接的教师-学生蒸馏路径分解为教师-TA和TA-学生双路径，从而稳定优化并加强知识转移。

Result: 在具有挑战性的nuScenes数据集上的大量实验证明了该方法的有效性，与纯相机基线相比，mIoU提高了4.2%，比其他最先进的KD方法提高了45%。

Conclusion: BridgeTA是一个成本效益高的蒸馏框架，通过教师辅助（TA）网络弥合激光雷达-相机融合和纯相机模型之间的表示差距，同时保持学生模型的架构和推理成本不变。

Abstract: Bird's-Eye-View (BEV) map segmentation is one of the most important and
challenging tasks in autonomous driving. Camera-only approaches have drawn
attention as cost-effective alternatives to LiDAR, but they still fall behind
LiDAR-Camera (LC) fusion-based methods. Knowledge Distillation (KD) has been
explored to narrow this gap, but existing methods mainly enlarge the student
model by mimicking the teacher's architecture, leading to higher inference
cost. To address this issue, we introduce BridgeTA, a cost-effective
distillation framework to bridge the representation gap between LC fusion and
Camera-only models through a Teacher Assistant (TA) network while keeping the
student's architecture and inference cost unchanged. A lightweight TA network
combines the BEV representations of the teacher and student, creating a shared
latent space that serves as an intermediate representation. To ground the
framework theoretically, we derive a distillation loss using Young's
Inequality, which decomposes the direct teacher-student distillation path into
teacher-TA and TA-student dual paths, stabilizing optimization and
strengthening knowledge transfer. Extensive experiments on the challenging
nuScenes dataset demonstrate the effectiveness of our method, achieving an
improvement of 4.2% mIoU over the Camera-only baseline, up to 45% higher than
the improvement of other state-of-the-art KD methods.

</details>


### [75] [MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography](https://arxiv.org/abs/2508.09616)
*Daniel Barco,Marc Stadelmann,Martin Oswald,Ivo Herzig,Lukas Lichtensteiger,Pascal Paysan,Igor Peterlik,Michal Walczak,Bjoern Menze,Frank-Peter Schilling*

Main category: cs.CV

TL;DR: MInDI-3D是一种用于CBCT伪影去除的三维扩散模型，能减少辐射暴露，临床评估显示其效果良好。


<details>
  <summary>Details</summary>
Motivation: 旨在解决医学成像中CBCT伪影去除问题，通过减少成像辐射暴露量来降低对患者的潜在危害。

Method: 提出了一种名为MInDI-3D的三维条件扩散模型，将"InDI"概念从二维扩展到三维，通过迭代去噪过程直接从稀疏投影的CBCT输入中优化三维体数据，并生成了包含16,182个样本的伪CBCT数据集用于模型训练。

Result: 在CT-RATE伪CBCT和真实世界测试集上，MInDI-3D在仅使用50个投影的情况下，实现了12.96 (6.10) dB的PSNR增益，并实现了8倍的辐射暴露减少。与3D U-Net在真实世界扫描中的表现相当，且能泛化到新的CBCT扫描几何。

Conclusion: MInDI-3D模型在稀疏投影的CBCT图像重建中表现出有效性，能够显著减少图像伪影并允许降低辐射剂量，临床评估表明其在患者定位和肿瘤边界保留方面具有实用价值，且能够泛化到新的CBCT扫描几何。

Abstract: We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first
3D conditional diffusion-based model for real-world sparse-view Cone Beam
Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation
exposure. A key contribution is extending the "InDI" concept from 2D to a full
3D volumetric approach for medical images, implementing an iterative denoising
process that refines the CBCT volume directly from sparse-view input. A further
contribution is the generation of a large pseudo-CBCT dataset (16,182) from
chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We
performed a comprehensive evaluation, including quantitative metrics,
scalability analysis, generalisation tests, and a clinical assessment by 11
clinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10)
dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE
pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in
imaging radiation exposure. We demonstrate its scalability by showing that
performance improves with more training data. Importantly, MInDI-3D matches the
performance of a 3D U-Net on real-world scans from 16 cancer patients across
distortion and task-based metrics. It also generalises to new CBCT scanner
geometries. Clinicians rated our model as sufficient for patient positioning
across all anatomical sites and found it preserved lung tumour boundaries well.

</details>


### [76] [Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation](https://arxiv.org/abs/2508.09626)
*Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang*

Main category: cs.CV

TL;DR: SAD-Splat 是一种新的 3D 航空场景语义分割方法，通过高斯点剔除和伪标签技术提高了精度和效率，并引入了新的数据集 3D-AS。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以解决航空图像中尺度变化和结构遮挡导致的语义模糊问题，限制了分割精度和一致性。

Method: 提出了一种名为 SAD-Splat 的新颖 3D-AVS-SS 方法。该方法引入了一个高斯点剔除模块，该模块集成了基于 Hard Concrete 分布的可学习稀疏机制和语义置信度估计，以消除冗余和语义模糊的高斯点。此外，SAD-Splat 还包含一个高置信度伪标签生成流程，利用 2D 基础模型在标签有限的情况下增强监督。同时，引入了一个包含稀疏注释的具有挑战性的 3DAS 基准数据集。

Result: 实验结果表明，SAD-Splat 在分割精度和表示紧凑性之间取得了优异的平衡。

Conclusion: SAD-Splat 方法在 3D 航空场景语义分割任务中取得了优异的分割精度和表示紧凑性之间的平衡，为 3D 航空场景理解提供了一种高效且可扩展的解决方案。

Abstract: In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS),
traditional methods struggle to address semantic ambiguity caused by scale
variations and structural occlusions in aerial images. This limits their
segmentation accuracy and consistency. To tackle these challenges, we propose a
novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian
point drop module, which integrates semantic confidence estimation with a
learnable sparsity mechanism based on the Hard Concrete distribution. This
module effectively eliminates redundant and semantically ambiguous Gaussian
points, enhancing both segmentation performance and representation compactness.
Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation
pipeline. It leverages 2D foundation models to enhance supervision when
ground-truth labels are limited, thereby further improving segmentation
accuracy. To advance research in this domain, we introduce a challenging
benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse
real-world aerial scenes with sparse annotations. Experimental results
demonstrate that SAD-Splat achieves an excellent balance between segmentation
accuracy and representation compactness. It offers an efficient and scalable
solution for 3D aerial scene understanding.

</details>


### [77] [Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors](https://arxiv.org/abs/2508.09629)
*Giorgos Karvounas,Nikolaos Kyriazis,Iason Oikonomidis,Georgios Pavlakos,Antonis A. Argyros*

Main category: cs.CV

TL;DR: Texture can actively help hand reconstruction: we add a simple module to align texture, improving accuracy and realism.


<details>
  <summary>Details</summary>
Motivation: Revisiting the role of texture in monocular 3D hand reconstruction, not just for photorealism, but as a dense cue to actively support pose and shape estimation. The motivation stems from the observation that even in high-performing models, the alignment between predicted hand geometry and image appearance is often imperfect, suggesting that texture alignment is an underused supervisory signal.

Method: Proposes a lightweight texture module that embeds per-pixel observations into UV texture space and enables a novel dense alignment loss between predicted and observed hand appearances. This module uses a differentiable rendering pipeline and a model that maps images to 3D hand meshes with known topology to back-project a textured hand onto the image for pixel-based alignment. It is designed to be easily pluggable into existing pipelines. The module is tested by augmenting the HaMeR architecture.

Result: The resulting system (HaMeR augmented with the texture module) improves both accuracy and realism in 3D hand reconstruction.

Conclusion: The proposed lightweight texture module, when augmenting HaMeR, improves both accuracy and realism in 3D hand reconstruction, demonstrating the value of appearance-guided alignment.

Abstract: We revisit the role of texture in monocular 3D hand reconstruction, not as an
afterthought for photorealism, but as a dense, spatially grounded cue that can
actively support pose and shape estimation. Our observation is simple: even in
high-performing models, the overlay between predicted hand geometry and image
appearance is often imperfect, suggesting that texture alignment may be an
underused supervisory signal. We propose a lightweight texture module that
embeds per-pixel observations into UV texture space and enables a novel dense
alignment loss between predicted and observed hand appearances. Our approach
assumes access to a differentiable rendering pipeline and a model that maps
images to 3D hand meshes with known topology, allowing us to back-project a
textured hand onto the image and perform pixel-based alignment. The module is
self-contained and easily pluggable into existing reconstruction pipelines. To
isolate and highlight the value of texture-guided supervision, we augment
HaMeR, a high-performing yet unadorned transformer architecture for 3D hand
pose estimation. The resulting system improves both accuracy and realism,
demonstrating the value of appearance-guided alignment in hand reconstruction.

</details>


### [78] [Preacher: Paper-to-Video Agentic System](https://arxiv.org/abs/2508.09632)
*Jingwei Liu,Ling Yang,Hao Luo,Fan Wang Hongyan Li,Mengdi Wang*

Main category: cs.CV

TL;DR: Preacher is a new system that converts research papers into video abstracts, overcoming limitations of existing models by using a unique planning and generation process. It produces high-quality results in diverse fields.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art video generation models are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. The paper-to-video task aims to convert research papers into structured video abstracts.

Method: Preacher employs a top-down approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. It defines key scenes and introduces a Progressive Chain of Thought (P-CoT) for granular, iterative planning to align cross-modal representations.

Result: Preacher generates high-quality video abstracts across five research fields.

Conclusion: Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models.

Abstract: The paper-to-video task converts a research paper into a structured video
abstract, distilling key concepts, methods, and conclusions into an accessible,
well-organized format. While state-of-the-art video generation models
demonstrate potential, they are constrained by limited context windows, rigid
video duration constraints, limited stylistic diversity, and an inability to
represent domain-specific knowledge. To address these limitations, we introduce
Preacher, the first paper-to-video agentic system. Preacher employs a top-down
approach to decompose, summarize, and reformulate the paper, followed by
bottom-up video generation, synthesizing diverse video segments into a coherent
abstract. To align cross-modal representations, we define key scenes and
introduce a Progressive Chain of Thought (P-CoT) for granular, iterative
planning. Preacher successfully generates high-quality video abstracts across
five research fields, demonstrating expertise beyond current video generation
models. Code will be released at: https://github.com/GenVerse/Paper2Video

</details>


### [79] [Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification](https://arxiv.org/abs/2508.09644)
*Shengjun Zhu,Siyu Liu,Runqing Xiong,Liping Zheng,Duo Ma,Rongshang Chen,Jiaxin Cai*

Main category: cs.CV

TL;DR: 提出了一种多对比度融合模块（MCFM），用于提高胎儿超声图像中胎儿躯干平面的识别精度。通过融合不同对比度下的图像特征并分配注意力权重，MCFM 在不过度增加模型复杂性的情况下，能够更好地捕捉细微的解剖结构，从而提高分类准确性和临床可靠性。


<details>
  <summary>Details</summary>
Motivation: 产前超声检查是评估胎儿结构发育和检测异常的关键工具，有助于减少围产期并发症和提高新生儿存活率。准确识别标准的胎儿躯干平面对于可靠评估和个性化产前护理至关重要。然而，超声成像中存在的低对比度和不清晰纹理细节等限制，给细粒度的解剖识别带来了重大挑战。

Method: 提出了一种新颖的多对比度融合模块（MCFM），用于增强模型从超声图像中提取详细信息的能力。MCFM 仅在神经网络的较低层运行，直接处理原始超声数据。通过为不同对比度条件下的图像表示分配注意力权重，该模块在明确保持最小参数开销的同时增强了特征建模。

Result: 所提出的 MCFM 在精心策划的胎儿躯干平面超声图像数据集上进行了评估。实验结果表明，MCFM 显著提高了识别性能，同时模型复杂度仅有微小增加。多对比度注意力的集成使模型能够更好地捕捉细微的解剖结构，从而提高了分类准确性和临床可靠性。

Conclusion: 该方法为胎儿超声影像中的胎儿躯干平面识别提供了一个有效的解决方案。通过多对比度融合增强特征表示，所提出的方法支持临床医生实现更准确、更一致的诊断，在产前筛查中具有强大的临床应用潜力。

Abstract: Purpose: Prenatal ultrasound is a key tool in evaluating fetal structural
development and detecting abnormalities, contributing to reduced perinatal
complications and improved neonatal survival. Accurate identification of
standard fetal torso planes is essential for reliable assessment and
personalized prenatal care. However, limitations such as low contrast and
unclear texture details in ultrasound imaging pose significant challenges for
fine-grained anatomical recognition. Methods: We propose a novel Multi-Contrast
Fusion Module (MCFM) to enhance the model's ability to extract detailed
information from ultrasound images. MCFM operates exclusively on the lower
layers of the neural network, directly processing raw ultrasound data. By
assigning attention weights to image representations under different contrast
conditions, the module enhances feature modeling while explicitly maintaining
minimal parameter overhead. Results: The proposed MCFM was evaluated on a
curated dataset of fetal torso plane ultrasound images. Experimental results
demonstrate that MCFM substantially improves recognition performance, with a
minimal increase in model complexity. The integration of multi-contrast
attention enables the model to better capture subtle anatomical structures,
contributing to higher classification accuracy and clinical reliability.
Conclusions: Our method provides an effective solution for improving fetal
torso plane recognition in ultrasound imaging. By enhancing feature
representation through multi-contrast fusion, the proposed approach supports
clinicians in achieving more accurate and consistent diagnoses, demonstrating
strong potential for clinical adoption in prenatal screening. The codes are
available at https://github.com/sysll/MCFM.

</details>


### [80] [Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model](https://arxiv.org/abs/2508.09645)
*Zhongyuan Wu,Chuan-Xian Ren,Yu Wang,Xiaohua Ban,Jianning Xiao,Xiaohui Duan*

Main category: cs.CV

TL;DR: PG-SAM通过结合专家诊断文本和跨序列注意力机制，改进了SAM模型在腮腺病灶分割中的应用，解决了提示获取难和忽略领域知识的问题，并在实际临床应用中取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 现有的SAM模型在医学图像分割领域表现出色，但其交互式分割模型严重依赖于精确的病灶提示（点、框、掩码等），这在实际应用中很难获得。此外，当前医学图像分割方法是自动生成的，忽略了医学专家的领域知识。

Method: 提出了一种专家诊断文本引导的SAM（PG-SAM），结合了专家领域知识，用于跨序列的腮腺分割。具体包括：1.专家诊断报告引导的提示生成模块，自动生成包含先验域知识的提示信息以指导分割过程。2.跨序列注意力模块，整合不同模态的互补信息以增强分割效果。3.将多序列图像特征和生成的提示输入解码器以获得分割结果。

Result: 实验结果表明，PG-SAM在三个独立的临床中心实现了最先进的腮腺病灶分割性能。

Conclusion: PG-SAM在三个独立的临床中心实现了最先进的依征分割性能，验证了其临床适用性以及诊断文本在真实临床环境中增强图像分割的有效性。

Abstract: Parotid gland lesion segmentation is essential for the treatment of parotid
gland diseases. However, due to the variable size and complex lesion
boundaries, accurate parotid gland lesion segmentation remains challenging.
Recently, the Segment Anything Model (SAM) fine-tuning has shown remarkable
performance in the field of medical image segmentation. Nevertheless, SAM's
interaction segmentation model relies heavily on precise lesion prompts
(points, boxes, masks, etc.), which are very difficult to obtain in real-world
applications. Besides, current medical image segmentation methods are
automatically generated, ignoring the domain knowledge of medical experts when
performing segmentation. To address these limitations, we propose the parotid
gland segment anything model (PG-SAM), an expert diagnosis text-guided SAM
incorporating expert domain knowledge for cross-sequence parotid gland lesion
segmentation. Specifically, we first propose an expert diagnosis report guided
prompt generation module that can automatically generate prompt information
containing the prior domain knowledge to guide the subsequent lesion
segmentation process. Then, we introduce a cross-sequence attention module,
which integrates the complementary information of different modalities to
enhance the segmentation effect. Finally, the multi-sequence image features and
generated prompts are feed into the decoder to get segmentation result.
Experimental results demonstrate that PG-SAM achieves state-of-the-art
performance in parotid gland lesion segmentation across three independent
clinical centers, validating its clinical applicability and the effectiveness
of diagnostic text for enhancing image segmentation in real-world clinical
settings.

</details>


### [81] [The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge](https://arxiv.org/abs/2508.09649)
*Reuben Dorent,Laura Rigolo,Colin P. Galvin,Junyu Chen,Mattias P. Heinrich,Aaron Carass,Olivier Colliot,Demian Wassermann,Alexandra Golby,Tina Kapur,William Wells*

Main category: cs.CV

TL;DR: ReMIND2Reg挑战赛通过提供大规模数据集和标准化评估指标，旨在解决术中脑肿瘤手术中因脑部移位导致的影像导航精度下降问题，并加速相关配准算法的研发。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤手术中精确的术中影像引导至关重要，但基于术前MRI的神经导航系统在术中会因脑部移位而降低精度。将术后超声与术前MRI进行配准可以估计脑部移位形变，但由于解剖结构和拓扑的大幅变化以及模态间强度差异，这一直是一个挑战。

Method: 该挑战赛利用ReMIND数据集，包含99个训练案例、5个验证案例和10个测试案例，提供了成对的3D ceT1 MRI、T2 MRI和术后3D iUS图像。评估指标包括目标配准误差（TRE）、对最坏情况landmark错位的鲁棒性（TRE30）和运行时间。

Result: ReMIND2Reg挑战赛提供了迄今为止最大的公共基准，以评估和推动在术中超声与术前MRI之间进行配准的算法。

Conclusion: ReMIND2Reg 2025 Challenge旨在通过提供一个标准化的评估框架，加速多模态配准算法在术中神经影像引导下的发展，以应对术中脑部移位问题。

Abstract: Accurate intraoperative image guidance is critical for achieving maximal safe
resection in brain tumor surgery, yet neuronavigation systems based on
preoperative MRI lose accuracy during the procedure due to brain shift.
Aligning post-resection intraoperative ultrasound (iUS) with preoperative MRI
can restore spatial accuracy by estimating brain shift deformations, but it
remains a challenging problem given the large anatomical and topological
changes and substantial modality intensity gap. The ReMIND2Reg 2025 Challenge
provides the largest public benchmark for this task, built upon the ReMIND
dataset. It offers 99 training cases, 5 validation cases, and 10 private test
cases comprising paired 3D ceT1 MRI, T2 MRI, and post-resection 3D iUS volumes.
Data are provided without annotations for training, while validation and test
performance are evaluated on manually annotated anatomical landmarks. Metrics
include target registration error (TRE), robustness to worst-case landmark
misalignment (TRE30), and runtime. By establishing a standardized evaluation
framework for this clinically critical and technically complex problem,
ReMIND2Reg aims to accelerate the development of robust, generalizable, and
clinically deployable multimodal registration algorithms for image-guided
neurosurgery.

</details>


### [82] [TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos](https://arxiv.org/abs/2508.09650)
*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazely,Sunil Aryal*

Main category: cs.CV

TL;DR: TOTNet, a Temporal Occlusion Tracking Network using 3D convolutions and a visibility-weighted loss, improves ball tracking in sports videos with occlusions. It achieves better results on tennis, badminton, and table tennis datasets, including a new occlusion-rich table tennis dataset.


<details>
  <summary>Details</summary>
Motivation: Robust ball tracking under occlusion is a critical challenge in sports video analysis, impacting event detection and officiating. This work aims to improve ball tracking in occluded scenarios.

Method: TOTNet utilizes 3D convolutions, a visibility-weighted loss function, and occlusion augmentation techniques to enhance ball tracking performance, especially under partial and full occlusions.

Result: TOTNet significantly outperforms existing methods across four datasets (tennis, badminton, table tennis), reducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded frames from 0.63 to 0.80.

Conclusion: TOTNet demonstrates significant effectiveness for offline sports analytics in fast-paced scenarios, outperforming prior state-of-the-art methods.

Abstract: Robust ball tracking under occlusion remains a key challenge in sports video
analysis, affecting tasks like event detection and officiating. We present
TOTNet, a Temporal Occlusion Tracking Network that leverages 3D convolutions,
visibility-weighted loss, and occlusion augmentation to improve performance
under partial and full occlusions. Developed in collaboration with Paralympics
Australia, TOTNet is designed for real-world sports analytics. We introduce
TTA, a new occlusion-rich table tennis dataset collected from
professional-level Paralympic matches, comprising 9,159 samples with 1,996
occlusion cases. Evaluated on four datasets across tennis, badminton, and table
tennis, TOTNet significantly outperforms prior state-of-the-art methods,
reducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded
frames from 0.63 to 0.80. These results demonstrate TOTNets effectiveness for
offline sports analytics in fast-paced scenarios. Code and data
access:\href{https://github.com/AugustRushG/TOTNet}{AugustRushG/TOTNet}.

</details>


### [83] [Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging](https://arxiv.org/abs/2508.09655)
*Lianfang Wang,Kuilin Qin,Xueying Liu,Huibin Chang,Yong Wang,Yuping Duan*

Main category: cs.CV

TL;DR: 一种基于算子学习的3D非视线成像方法，通过深度算法展开和时空特征融合，实现了对噪声的自适应和鲁棒重建。


<details>
  <summary>Details</summary>
Motivation: 为了从被遮挡或隐藏的场景中提取信息，需要利用间接光信号，但这些信号本身较弱且易受噪声干扰，因此需要整合物理过程以确保准确重建。

Method: 提出了一种参数化逆问题框架，利用噪声估计模块和参数化神经算子进行3D成像重建。该框架基于算子学习，通过深度算法展开，并融合了全局和局部时空特征。

Result: 该方法在模拟和真实数据集上进行了广泛的数值实验，证明了其有效性，特别是在快速扫描数据和稀疏光照点数据方面表现出色，为复杂场景下的非视线成像提供了可行的解决方案。

Conclusion: 该方法通过深度算法展开和算子学习，能够适应不同的噪声水平，并融合时空特征，从而在复杂场景下实现鲁棒且精确的非视线成像。

Abstract: Computational imaging, especially non-line-of-sight (NLOS) imaging, the
extraction of information from obscured or hidden scenes is achieved through
the utilization of indirect light signals resulting from multiple reflections
or scattering. The inherently weak nature of these signals, coupled with their
susceptibility to noise, necessitates the integration of physical processes to
ensure accurate reconstruction. This paper presents a parameterized inverse
problem framework tailored for large-scale linear problems in 3D imaging
reconstruction. Initially, a noise estimation module is employed to adaptively
assess the noise levels present in transient data. Subsequently, a
parameterized neural operator is developed to approximate the inverse mapping,
facilitating end-to-end rapid image reconstruction. Our 3D image reconstruction
framework, grounded in operator learning, is constructed through deep algorithm
unfolding, which not only provides commendable model interpretability but also
enables dynamic adaptation to varying noise levels in the acquired data,
thereby ensuring consistently robust and accurate reconstruction outcomes.
Furthermore, we introduce a novel method for the fusion of global and local
spatiotemporal data features. By integrating structural and detailed
information, this method significantly enhances both accuracy and robustness.
Comprehensive numerical experiments conducted on both simulated and real
datasets substantiate the efficacy of the proposed method. It demonstrates
remarkable performance with fast scanning data and sparse illumination point
data, offering a viable solution for NLOS imaging in complex scenarios.

</details>


### [84] [NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation](https://arxiv.org/abs/2508.09661)
*Eduarda Caldeira,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: NegFaceDiff通过加入负条件来改进人脸生成模型，提高了生成人脸数据的身份区分度，进而提升了人脸识别模型的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于身份条件的扩散模型在生成人脸数据时，缺乏强制类间分离的采样机制，导致身份重叠，影响人脸识别模型的性能。

Method: 提出了一种名为NegFaceDiff的新型采样方法，该方法将负条件纳入身份条件扩散过程，以增强类间可分离性。

Result: NegFaceDiff将身份分离性（以Fisher判别比FDR衡量）从2.427提高到5.687，并且在多个基准测试中，使用NegFaceDiff生成的数据训练的人脸识别模型性能优于未使用负条件生成的数据训练的模型。

Conclusion: NegFaceDiff通过引入负条件到身份条件扩散过程，增强了生成人脸数据的身份分离性，提高了人脸识别模型的性能。

Abstract: The use of synthetic data as an alternative to authentic datasets in face
recognition (FR) development has gained significant attention, addressing
privacy, ethical, and practical concerns associated with collecting and using
authentic data. Recent state-of-the-art approaches have proposed
identity-conditioned diffusion models to generate identity-consistent face
images, facilitating their use in training FR models. However, these methods
often lack explicit sampling mechanisms to enforce inter-class separability,
leading to identity overlap in the generated data and, consequently, suboptimal
FR performance. In this work, we introduce NegFaceDiff, a novel sampling method
that incorporates negative conditions into the identity-conditioned diffusion
process. NegFaceDiff enhances identity separation by leveraging negative
conditions that explicitly guide the model away from unwanted features while
preserving intra-class consistency. Extensive experiments demonstrate that
NegFaceDiff significantly improves the identity consistency and separability of
data generated by identity-conditioned diffusion models. Specifically, identity
separability, measured by the Fisher Discriminant Ratio (FDR), increases from
2.427 to 5.687. These improvements are reflected in FR systems trained on the
NegFaceDiff dataset, which outperform models trained on data generated without
negative conditions across multiple benchmarks.

</details>


### [85] [GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors](https://arxiv.org/abs/2508.09667)
*Xingyilang Yin,Qi Zhang,Jiahao Chang,Ying Feng,Qingnan Fan,Xi Yang,Chi-Man Pun,Huaqi Zhang,Xiaodong Cun*

Main category: cs.CV

TL;DR: GSFixer是一种用于修复稀疏视图3D重建中3D高斯泼溅法伪影的新框架，通过参考引导的视频恢复模型来提高3D一致性和语义连贯性，并在DL3DV-Res数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏视图重建3D场景（使用3D高斯泼溅法）时由于信息不足而产生的伪影问题，以及现有方法在生成与输入观察一致的内容时遇到的困难。

Method: 提出了一种名为GSFixer的新框架，该框架利用参考引导的视频恢复模型，该模型基于DiT视频扩散模型，并在配对的3DGS伪影渲染和干净帧（具有额外的参考条件）上进行训练。该模型整合了从视觉几何基础模型中提取的2D语义特征和3D几何特征，以提高修复伪影新视图时的语义一致性和3D一致性。

Result: GSFixer在3DGS伪影修复和稀疏视图3D重建方面表现优于当前最先进的方法，并提出了DL3DV-Res数据集用于评估。

Conclusion: GSFixer在3DGS伪影修复和稀疏视图3D重建方面优于现有最先进的方法。

Abstract: Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views
is an ill-posed problem due to insufficient information, often resulting in
noticeable artifacts. While recent approaches have sought to leverage
generative priors to complete information for under-constrained regions, they
struggle to generate content that remains consistent with input observations.
To address this challenge, we propose GSFixer, a novel framework designed to
improve the quality of 3DGS representations reconstructed from sparse inputs.
The core of our approach is the reference-guided video restoration model, built
upon a DiT-based video diffusion model trained on paired artifact 3DGS renders
and clean frames with additional reference-based conditions. Considering the
input sparse views as references, our model integrates both 2D semantic
features and 3D geometric features of reference views extracted from the visual
geometry foundation model, enhancing the semantic coherence and 3D consistency
when fixing artifact novel views. Furthermore, considering the lack of suitable
benchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which
contains artifact frames rendered using low-quality 3DGS. Extensive experiments
demonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS
artifact restoration and sparse-view 3D reconstruction. Project page:
https://github.com/GVCLab/GSFixer.

</details>


### [86] [PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training](https://arxiv.org/abs/2508.09691)
*Yin Xie,Zhichao Chen,Xiaoze Yu,Yongle Zhao,Xiang An,Kaicheng Yang,Zimin Ran,Jia Guo,Ziyong Feng,Jiankang Deng*

Main category: cs.CV

TL;DR: PaCo-FR是一种新的无监督面部表示预训练框架，通过结构化掩码、增强的块码本和空间一致性约束来解决现有方法的局限性，实现了最先进的性能，并减少了对标签数据的需求。


<details>
  <summary>Details</summary>
Motivation: 现有的面部表示预训练方法在捕捉区分性面部特征和细粒语义、利用面部解剖的固有空间结构以及高效利用有限的标签数据方面存在挑战。

Method: PaCo-FR是一个结合了掩码图像建模和块-像素对齐的无监督框架。它包含三个创新组件：1. 结构化掩码策略，通过与有意义的面部区域对齐来保持空间一致性；2. 新颖的基于块的码本，通过多个候选令牌来增强特征辨别力；3. 空间一致性约束，保持面部组件之间的几何关系。

Result: PaCo-FR在多项面部分析任务上取得了最先进的性能，尤其在处理不同姿态、遮挡和光照条件方面表现出色。

Conclusion: PaCo-FR在仅使用200万张无标签图像进行预训练的情况下，在多项面部分析任务上实现了最先进的性能，尤其在不同姿态、遮挡和光照条件下表现出显著的改进。该方法促进了面部表示学习，并提供了一种可扩展、高效的解决方案，减少了对昂贵标注数据集的依赖，推动了更有效的面部分析系统。

Abstract: Facial representation pre-training is crucial for tasks like facial
recognition, expression analysis, and virtual reality. However, existing
methods face three key challenges: (1) failing to capture distinct facial
features and fine-grained semantics, (2) ignoring the spatial structure
inherent to facial anatomy, and (3) inefficiently utilizing limited labeled
data. To overcome these, we introduce PaCo-FR, an unsupervised framework that
combines masked image modeling with patch-pixel alignment. Our approach
integrates three innovative components: (1) a structured masking strategy that
preserves spatial coherence by aligning with semantically meaningful facial
regions, (2) a novel patch-based codebook that enhances feature discrimination
with multiple candidate tokens, and (3) spatial consistency constraints that
preserve geometric relationships between facial components. PaCo-FR achieves
state-of-the-art performance across several facial analysis tasks with just 2
million unlabeled images for pre-training. Our method demonstrates significant
improvements, particularly in scenarios with varying poses, occlusions, and
lighting conditions. We believe this work advances facial representation
learning and offers a scalable, efficient solution that reduces reliance on
expensive annotated datasets, driving more effective facial analysis systems.

</details>


### [87] [Slot Attention-based Feature Filtering for Few-Shot Learning](https://arxiv.org/abs/2508.09699)
*Javier Rodenas,Eduardo Aguilar,Petia Radeva*

Main category: cs.CV

TL;DR: SAFF通过槽注意力过滤小样本学习中的无关特征，提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决小样本学习中无关特征（如背景元素）可能导致混淆和错误分类的问题。

Method: 提出了一种名为SAFF（Slot Attention-based Feature Filtering）的方法，该方法利用槽注意力机制与斑块嵌入相结合，通过单一注意力机制将类感知槽统一起来，以有效过滤不相关的特征。通过引入相似性矩阵来量化过滤后的嵌入与分类的相关性。

Result: 实验证明，SAFF比其他注意力机制表现更好，能够捕捉区分性特征并减少不相关信息，在多个小样本学习基准测试中超越了现有的最先进方法。

Conclusion: SAFF通过利用基于槽注意力的机制来区分和过滤弱特征，在小样本学习方面取得了优于现有技术的性能，在CIFAR-FS、FC100、miniImageNet和tieredImageNet等基准测试中得到了验证。

Abstract: Irrelevant features can significantly degrade few-shot learn ing performance.
This problem is used to match queries and support images based on meaningful
similarities despite the limited data. However, in this process, non-relevant
fea tures such as background elements can easily lead to confu sion and
misclassification. To address this issue, we pro pose Slot Attention-based
Feature Filtering for Few-Shot Learning (SAFF) that leverages slot attention
mechanisms to discriminate and filter weak features, thereby improving few-shot
classification performance. The key innovation of SAFF lies in its integration
of slot attention with patch em beddings, unifying class-aware slots into a
single attention mechanism to filter irrelevant features effectively. We intro
duce a similarity matrix that computes across support and query images to
quantify the relevance of filtered embed dings for classification. Through
experiments, we demon strate that Slot Attention performs better than other
atten tion mechanisms, capturing discriminative features while reducing
irrelevant information. We validate our approach through extensive experiments
on few-shot learning bench marks: CIFAR-FS, FC100, miniImageNet and tieredIma
geNet, outperforming several state-of-the-art methods.

</details>


### [88] [MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers](https://arxiv.org/abs/2508.09709)
*Qianru Qiu,Jiafeng Mao,Kento Masui,Xueting Wang*

Main category: cs.CV

TL;DR: MangaDiT 是一个基于 Diffusion Transformers (DiT) 的模型，用于参考图像引导线稿着色。它通过层次注意力机制解决了区域级颜色一致性问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有参考图像引导线稿着色方法在区域级颜色一致性方面仍然存在不足，尤其是在参考图和目标图的人物姿态或运动不同时。本文旨在解决这一问题，提出一种无需外部匹配标注即可发现语义对应关系的方法。

Method: 提出了一种基于 Diffusion Transformers (DiT) 的参考图像引导线稿着色模型 MangaDiT。该模型将线稿和参考图像作为条件输入，并引入了具有动态注意力权重策略的层次注意力机制。该机制通过利用池化的空间特征，有效地扩展了模型的感受野，增强了区域级颜色对齐。

Result: MangaDiT 在两个基准数据集上显著优于最先进的方法，在定性和定量评估方面均取得了优越的性能。

Conclusion: MangaDiT 在两个基准数据集上的实验表明，该方法在定性和定量评估方面均显著优于最先进的方法。

Abstract: Recent advances in diffusion models have significantly improved the
performance of reference-guided line art colorization. However, existing
methods still struggle with region-level color consistency, especially when the
reference and target images differ in character pose or motion. Instead of
relying on external matching annotations between the reference and target, we
propose to discover semantic correspondences implicitly through internal
attention mechanisms. In this paper, we present MangaDiT, a powerful model for
reference-guided line art colorization based on Diffusion Transformers (DiT).
Our model takes both line art and reference images as conditional inputs and
introduces a hierarchical attention mechanism with a dynamic attention
weighting strategy. This mechanism augments the vanilla attention with an
additional context-aware path that leverages pooled spatial features,
effectively expanding the model's receptive field and enhancing region-level
color alignment. Experiments on two benchmark datasets demonstrate that our
method significantly outperforms state-of-the-art approaches, achieving
superior performance in both qualitative and quantitative evaluations.

</details>


### [89] [NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation](https://arxiv.org/abs/2508.09715)
*Devvrat Joshi,Islem Rekik*

Main category: cs.CV

TL;DR: NEURAL框架通过利用视觉-语言模型中的交叉注意力分数来压缩医学图像（如胸部X射线），将其转换为包含临床信息（来自放射学报告）的图表示。该方法显著减小了数据大小（高达97.7%），同时在肺炎检测等任务中保持了高诊断准确性（AUC高达0.95），解决了医学数据存储和传输的挑战。


<details>
  <summary>Details</summary>
Motivation: 多模态医学成像数据的快速增长给存储和传输带来了重大挑战，尤其是在资源受限的临床环境中。需要一种能够有效压缩数据同时保持诊断性能的解决方案。

Method: 本研究提出了一种名为NEURAL的新框架，该框架利用语义引导的数据压缩技术。具体方法是：1. 通过微调的生成式视觉-语言模型，重新利用图像与其放射学报告之间的交叉注意力分数。2. 利用这些分数对胸部X射线进行结构化剪枝，只保留诊断关键区域。3. 将处理后的图像转换为高度压缩的图表示。4. 将剪枝后的视觉图与从临床报告派生的知识图融合，形成统一的、基于图的表示。5. 在MIMIC-CXR和CheXpert Plus数据集上针对肺炎检测任务进行了验证。

Result: NEURAL框架实现了93.4-97.7%的图像数据大小缩减，同时在肺炎检测任务中保持了0.88-0.95的AUC（分类任务的评价指标），其性能优于使用未压缩数据的基线模型。该框架创建了一个持久的、与任务无关的数据资产，解决了数据大小和临床效用之间的权衡问题。

Conclusion: NEURAL框架通过语义引导的数据压缩解决了多模态医学成像数据的存储和传输挑战，将医学图像转换为高度压缩的图表示，实现了93.4-97.7%的数据大小缩减，同时在肺炎检测任务中保持了0.88-0.95的AUC高性能，克服了数据大小与临床效用之间的权衡，提高了工作流程效率和远程放射学能力。

Abstract: The rapid growth of multimodal medical imaging data presents significant
storage and transmission challenges, particularly in resource-constrained
clinical settings. We propose NEURAL, a novel framework that addresses this by
using semantics-guided data compression. Our approach repurposes
cross-attention scores between the image and its radiological report from a
fine-tuned generative vision-language model to structurally prune chest X-rays,
preserving only diagnostically critical regions. This process transforms the
image into a highly compressed, graph representation. This unified graph-based
representation fuses the pruned visual graph with a knowledge graph derived
from the clinical report, creating a universal data structure that simplifies
downstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for
pneumonia detection, NEURAL achieves a 93.4-97.7\% reduction in image data size
while maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming
other baseline models that use uncompressed data. By creating a persistent,
task-agnostic data asset, NEURAL resolves the trade-off between data size and
clinical utility, enabling efficient workflows and teleradiology without
sacrificing performance. Our NEURAL code is available at
https://github.com/basiralab/NEURAL.

</details>


### [90] [Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction](https://arxiv.org/abs/2508.09717)
*Shekhnaz Idrissova,Islem Rekik*

Main category: cs.CV

TL;DR: A new sheaf-based method effectively combines MRI and histopathology for glioblastoma classification, even with missing data, enabling virtual biopsies.


<details>
  <summary>Details</summary>
Motivation: Existing multimodal approaches for glioblastoma classification struggle with preserving shared structural information across modalities and handling incomplete data. There's a need for a method that addresses these limitations for improved diagnostics.

Method: A novel sheaf-based framework for structure-aware and consistent fusion of MRI and histopathology data.

Result: The model demonstrates superior performance compared to baseline methods and exhibits robustness when dealing with incomplete or missing data.

Conclusion: The proposed sheaf-based framework offers a robust and structure-aware method for fusing MRI and histopathology data, outperforming baseline methods and showing promise for virtual biopsy applications.

Abstract: Glioblastoma is a highly invasive brain tumor with rapid progression rates.
Recent studies have shown that glioblastoma molecular subtype classification
serves as a significant biomarker for effective targeted therapy selection.
However, this classification currently requires invasive tissue extraction for
comprehensive histopathological analysis. Existing multimodal approaches
combining MRI and histopathology images are limited and lack robust mechanisms
for preserving shared structural information across modalities. In particular,
graph-based models often fail to retain discriminative features within
heterogeneous graphs, and structural reconstruction mechanisms for handling
missing or incomplete modality data are largely underexplored. To address these
limitations, we propose a novel sheaf-based framework for structure-aware and
consistent fusion of MRI and histopathology data. Our model outperforms
baseline methods and demonstrates robustness in incomplete or missing data
scenarios, contributing to the development of virtual biopsy tools for rapid
diagnostics. Our source code is available at
https://github.com/basiralab/MMSN/.

</details>


### [91] [Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://arxiv.org/abs/2508.09736)
*Lin Long,Yichen He,Wentao Ye,Yiyuan Pan,Yuan Lin,Hang Li,Junbo Zhao,Wei Li*

Main category: cs.CV

TL;DR: M3-Agent 是一个具有长期记忆的多模态代理框架，在长期视频问答任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了评估多模态代理的记忆有效性和基于记忆的推理能力。

Method: M3-Agent 是一个新颖的多模态代理框架，具有长期记忆。它能处理实时的视觉和听觉输入，建立和更新长期记忆，包括情景记忆和语义记忆。记忆以以实体为中心的多模态格式组织。M3-Bench 是一个包含 100 个新录制的机器人视角视频（M3-Bench-robot）和 929 个网络视频（M3-Bench-web）的长期视频问答基准。

Result: M3-Agent 在 M3-Bench-robot、M3-Bench-web 和 VideoMME-long 上分别比最强的基线高出 6.7%、7.7% 和 5.3% 的准确率。

Conclusion: M3-Agent 在 M3-Bench-robot、M3-Bench-web 和 VideoMME-long 上分别比最强的基线（使用 Gemini-1.5-pro 和 GPT-4o 的提示代理）高出 6.7%、7.7% 和 5.3% 的准确率。

Abstract: We introduce M3-Agent, a novel multimodal agent framework equipped with
long-term memory. Like humans, M3-Agent can process real-time visual and
auditory inputs to build and update its long-term memory. Beyond episodic
memory, it also develops semantic memory, enabling it to accumulate world
knowledge over time. Its memory is organized in an entity-centric, multimodal
format, allowing deeper and more consistent understanding of the environment.
Given an instruction, M3-Agent autonomously performs multi-turn, iterative
reasoning and retrieves relevant information from memory to accomplish the
task. To evaluate memory effectiveness and memory-based reasoning in multimodal
agents, we develop M3-Bench, a new long-video question answering benchmark.
M3-Bench comprises 100 newly recorded real-world videos captured from a robot's
perspective (M3-Bench-robot) and 929 web-sourced videos across diverse
scenarios (M3-Bench-web). We annotate question-answer pairs designed to test
key capabilities essential for agent applications, such as human understanding,
general knowledge extraction, and cross-modal reasoning. Experimental results
show that M3-Agent, trained via reinforcement learning, outperforms the
strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o,
achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web
and VideoMME-long, respectively. Our work advances the multimodal agents toward
more human-like long-term memory and provides insights into their practical
design. Model, code and data are available at
https://github.com/bytedance-seed/m3-agent

</details>


### [92] [Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection](https://arxiv.org/abs/2508.09746)
*Zhiqiu Zhang,Dongqi Fan,Mingjie Wang,Qiang Tang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: 提出了一种名为R2R的新模型，通过Region-to-Region转换、Clear-VAE、Harmony Controller和Random Poisson Blending等技术，解决了现有图像协调方法的局限性，并在实验中取得了优于其他方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LDM的图像协调方法在细节保留和协调能力方面存在挑战。此外，当前的合成数据集缺乏局部变化，未能捕捉复杂的真实世界光照条件。

Method: 提出了一种名为R2R的新模型，其核心是Region-to-Region转换。具体来说，设计了Clear-VAE（包含自适应滤波器）来保留前景的高频细节并去除不协调的元素；引入了Harmony Controller（包含掩码感知自适应通道注意力MACA）来根据前景和背景区域的通道重要性动态调整前景；提出了Random Poisson Blending来生成更多样化和更具挑战性的合成图像，并构建了新的合成数据集RPHarmony。

Result: R2R模型在图像协调任务上表现出色，能够更好地保留细节并实现视觉上的一致性。新提出的RPHarmony数据集也提高了模型在真实图像上的表现。

Conclusion: R2R方法在定量指标和视觉效果上均优于其他方法，且RPHarmony数据集有助于模型生成更真实的图像。

Abstract: The goal of image harmonization is to adjust the foreground in a composite
image to achieve visual consistency with the background. Recently, latent
diffusion model (LDM) are applied for harmonization, achieving remarkable
results. However, LDM-based harmonization faces challenges in detail
preservation and limited harmonization ability. Additionally, current synthetic
datasets rely on color transfer, which lacks local variations and fails to
capture complex real-world lighting conditions. To enhance harmonization
capabilities, we propose the Region-to-Region transformation. By injecting
information from appropriate regions into the foreground, this approach
preserves original details while achieving image harmonization or, conversely,
generating new composite data. From this perspective, We propose a novel model
R2R. Specifically, we design Clear-VAE to preserve high-frequency details in
the foreground using Adaptive Filter while eliminating disharmonious elements.
To further enhance harmonization, we introduce the Harmony Controller with
Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the
foreground based on the channel importance of both foreground and background
regions. To address the limitation of existing datasets, we propose Random
Poisson Blending, which transfers color and lighting information from a
suitable region to the foreground, thereby generating more diverse and
challenging synthetic images. Using this method, we construct a new synthetic
dataset, RPHarmony. Experiments demonstrate the superiority of our method over
other methods in both quantitative metrics and visual harmony. Moreover, our
dataset helps the model generate more realistic images in real examples. Our
code, dataset, and model weights have all been released for open access.

</details>


### [93] [MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models](https://arxiv.org/abs/2508.09779)
*Dianyi Wang,Siyuan Wang,Zejun Li,Yikun Wang,Yitong Li,Duyu Tang,Xiaoyu Shen,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CV

TL;DR: 提出MoIIE架构和两阶段训练策略，以解决大型视觉语言模型（LVLMs）的计算成本问题，并在激活参数量较少的情况下，实现与更大型模型相当甚至更优的多模态性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型视觉语言模型（LVLMs）在扩展模型规模和训练数据时带来的高昂计算成本问题，并有效解决现有MoE架构在LVLMs中同时建模模态特定特征和跨模态关联的挑战。

Method: 提出了一种名为“模型内和模型间专家混合”（MoIIE）的架构，该架构允许专家路由根据其模态将token引导至各自的模态内专家和共享的模态间专家池，从而联合学习丰富的模态内特征和跨模态交互。此外，还提出了一种两阶段训练策略来激活MoE和多模态能力。

Result: 实验证明了MoIIE方法的有效性、效率和通用性，并且在不同数据规模和LLM骨干网络上都取得了良好的效果。

Conclusion: MoIIE模型在激活参数量（5.5B和11.3B）与现有基于MoE的大型语言模型（LLMs）的多模态模型相比，能够达到或超越其性能，同时在效率和通用性方面也表现出色。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across multi-modal tasks by scaling model size and training data. However,
these dense LVLMs incur significant computational costs and motivate the
exploration of sparse Mixture of Experts (MoE) architectures. While MoE improve
parameter efficiency, effectively applying MoE to simultaneously model
modality-specific features and cross-modal associations in LVLMs remains
challenging. In this work, we propose to incorporate Mixture of Intra- and
Inter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is
guided by its modality, directing tokens to their respective intra-modality
experts as well as a shared pool of inter-modality experts, enabling the model
to jointly learn rich intra-modal features and cross-modal interactions. We
further introduce an effective and straightforward two-stage training strategy,
which facilitates the direct activation of both MoE and multi-modal
capabilities. Extensive experiments across different data scales and LLM
backbone demonstrate the effectiveness, efficiency and generality of our
approach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters
match or even surpass the performance of existing advanced open-source MoE-LLMs
based multi-modal models that involve more activated parameters. The code is
available at https://github.com/AlenjandroWang/MoIIE.

</details>


### [94] [Combinative Matching for Geometric Shape Assembly](https://arxiv.org/abs/2508.09780)
*Nahyuk Lee,Juhong Min,Junhong Lee,Chunghyun Park,Minsu Cho*

Main category: cs.CV

TL;DR: This paper presents a new shape-matching method called 'combinative matching' that combines interlocking parts for geometric assembly by considering both identical surface shapes and opposite volume occupancy, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of previous geometric assembly methods that rely on aligning parts by finding identical surfaces, this paper introduces a new methodology that explicitly models two distinct properties of interlocking shapes: 'identical surface shape' and 'opposite volume occupancy.'

Method: Combinative matching methodology that models 'identical surface shape' and 'opposite volume occupancy' of interlocking shapes, learning correspondences across regions with identical surface shapes but inverted volume occupancy. It also learns to align regions in rotation by estimating shape orientations using equivariant neural networks.

Result: Experimental results on geometric assembly benchmarks demonstrate the efficacy of the proposed method, consistently outperforming the state of the art.

Conclusion: The proposed combinative matching method, which learns to align regions in rotation by estimating their shape orientations via equivariant neural networks, significantly reduces local ambiguities in matching and allows for robust combination of parts in assembly, outperforming the state of the art on geometric assembly benchmarks.

Abstract: This paper introduces a new shape-matching methodology, combinative matching,
to combine interlocking parts for geometric shape assembly. Previous methods
for geometric assembly typically rely on aligning parts by finding identical
surfaces between the parts as in conventional shape matching and registration.
In contrast, we explicitly model two distinct properties of interlocking
shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method
thus learns to establish correspondences across regions where their surface
shapes appear identical but their volumes occupy the inverted space to each
other. To facilitate this process, we also learn to align regions in rotation
by estimating their shape orientations via equivariant neural networks. The
proposed approach significantly reduces local ambiguities in matching and
allows a robust combination of parts in assembly. Experimental results on
geometric assembly benchmarks demonstrate the efficacy of our method,
consistently outperforming the state of the art. Project page:
https://nahyuklee.github.io/cmnet.

</details>


### [95] [DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.09785)
*Linpu He,Yanan Li,Bingze Li,Elvis Han Cui,Donghui Wang*

Main category: cs.CV

TL;DR: DSS-Prompt 通过在 Vision Transformer 中使用静态和动态提示，实现了强大的少样本类增量学习，无需在增量任务上进行额外训练，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练模型在各种下游任务中展现出强大的泛化能力，但它们在具有挑战性的少样本类增量学习（FSCIL）任务中的应用仍有待探索。FSCIL 任务的目标是持续学习包含有限训练样本的新概念，同时避免遗忘旧概念。

Method: DSS-Prompt 方法将预训练的 Vision Transformer（ViT）通过提示（prompts）进行改造，以适应少样本类增量学习（FSCIL）任务。具体来说，它在每个 Transformer 块中结合了两种提示：1. 静态提示：用于连接预训练和下游数据集之间的领域差距，以实现更好的适应性。2. 动态提示：用于捕获实例感知语义，实现从基础类到新类的轻松迁移。动态提示的生成利用了预训练的多模态模型来提取与输入相关的多样化语义，从而生成互补的、感知输入的提示，并跨不同层自适应地调整它们的权重。在此基础上，一个简单的原型分类器可以直接应用于提示后的视觉嵌入，无需在增量任务上进行进一步训练。

Result: DSS-Prompt 在四个基准测试上的大量实验表明，该方法在所有数据集上持续优于现有方法，并能有效缓解灾难性遗忘问题。

Conclusion: DSS-Prompt 是一种简单而有效的方法，通过最小的修改将预训练的 Vision Transformer 转化为强大的 FSCIL 分类器。该方法利用静态提示和动态提示来弥合领域差距和捕获实例感知语义，从而实现从基础类到新类的轻松迁移。DSS-Prompt 在四个基准测试中表现出色，优于现有方法，并能有效缓解灾难性遗忘问题。

Abstract: Learning from large-scale pre-trained models with strong generalization
ability has shown remarkable success in a wide range of downstream tasks
recently, but it is still underexplored in the challenging few-shot
class-incremental learning (FSCIL) task. It aims to continually learn new
concepts from limited training samples without forgetting the old ones at the
same time. In this paper, we introduce DSS-Prompt, a simple yet effective
approach that transforms the pre-trained Vision Transformer with minimal
modifications in the way of prompts into a strong FSCIL classifier. Concretely,
we synergistically utilize two complementary types of prompts in each
Transformer block: static prompts to bridge the domain gap between the
pre-training and downstream datasets, thus enabling better adaption; and
dynamic prompts to capture instance-aware semantics, thus enabling easy
transfer from base to novel classes. Specially, to generate dynamic prompts, we
leverage a pre-trained multi-modal model to extract input-related diverse
semantics, thereby generating complementary input-aware prompts, and then
adaptively adjust their importance across different layers. In this way, on top
of the prompted visual embeddings, a simple prototype classifier can beat
state-of-the-arts without further training on the incremental tasks. We conduct
extensive experiments on four benchmarks to validate the effectiveness of our
DSS-Prompt and show that it consistently achieves better performance than
existing approaches on all datasets and can alleviate the catastrophic
forgetting issue as well.

</details>


### [96] [MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking](https://arxiv.org/abs/2508.09796)
*Yingjie Wang,Zhixing Wang,Le Zheng,Tianxiao Liu,Roujing Li,Xueyao Hu*

Main category: cs.CV

TL;DR: 提出MeMoSORT，一种结合记忆增强卡尔曼滤波器（MeKF）和运动自适应IoU（Mo-IoU）的多目标跟踪器，用于解决人类密集场景下的复杂运动和遮挡问题，并在DanceTrack和SportsMOT数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决多目标跟踪（MOT）中，尤其是在以人为中心的场景下，由于目标的复杂运动和严重遮挡所带来的挑战。传统跟踪方法（如基于卡尔曼滤波和IoU关联的跟踪）在处理现实世界对象动力学不匹配和遮挡情况时存在局限性。

Method: 提出了一种名为MeMoSORT的简单、在线、实时的多目标跟踪器，包含两个关键创新：1. 记忆增强卡尔曼滤波器（MeKF），利用记忆增强神经网络来补偿模型假设与实际对象运动之间的不匹配。2. 运动自适应IoU（Mo-IoU），自适应地扩展匹配空间并纳入高度相似性，以减少检测错误和关联失败的影响，同时保持轻量级。

Result: MeMoSORT通过MeKF和Mo-IoU的结合，有效解决了运动模型不匹配和遮挡导致的关联问题，实现了先进的跟踪性能。

Conclusion: MeMoSORT在DanceTrack和SportsMOT数据集上取得了最先进的性能，HOTA分数分别为67.9%和82.1%。

Abstract: Multi-object tracking (MOT) in human-dominant scenarios, which involves
continuously tracking multiple people within video sequences, remains a
significant challenge in computer vision due to targets' complex motion and
severe occlusions. Conventional tracking-by-detection methods are fundamentally
limited by their reliance on Kalman filter (KF) and rigid Intersection over
Union (IoU)-based association. The motion model in KF often mismatches
real-world object dynamics, causing filtering errors, while rigid association
struggles under occlusions, leading to identity switches or target loss. To
address these issues, we propose MeMoSORT, a simple, online, and real-time MOT
tracker with two key innovations. First, the Memory-assisted Kalman filter
(MeKF) uses memory-augmented neural networks to compensate for mismatches
between assumed and actual object motion. Second, the Motion-adaptive IoU
(Mo-IoU) adaptively expands the matching space and incorporates height
similarity to reduce the influence of detection errors and association
failures, while remaining lightweight. Experiments on DanceTrack and SportsMOT
show that MeMoSORT achieves state-of-the-art performance, with HOTA scores of
67.9\% and 82.1\%, respectively.

</details>


### [97] [MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention](https://arxiv.org/abs/2508.09802)
*Xin Du,Maoyuan Xu,Zhi Ying*

Main category: cs.CV

TL;DR: MUJICA是一个适配器，用于提升SISR模型在PBR材质超分辨率中的表现，通过跨贴图注意力融合特征，解决了现有方法的不足，提高了图像质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的SISR方法在处理PBR材质超分辨率时存在跨贴图不一致、对特定模式特征建模不足以及因数据分布偏移导致泛化能力受限等问题。因此，对SVBRDF材质进行超分辨率对于现代3D图形应用具有重要价值，需要新的方法来解决这些挑战。

Method: 提出了一种名为MUJICA（Multi-modal Upscaling Joint Inference via Cross-map Attention）的灵活适配器，该适配器能够改造预训练的基于Swin Transformer的SISR模型以适应PBR材质超分辨率。MUJICA在预训练且冻结的SISR骨干网络之后附加，利用跨贴图注意力机制融合特征，同时保持了SISR模型卓越的重建能力。

Result: MUJICA在SwinIR、DRCT和HMANet等SISR模型上应用，能够提升PSNR、SSIM和LPIPS分数，并保持跨贴图一致性。实验证明，MUJICA即使在资源有限的情况下也能实现高效训练，并在PBR材质数据集上取得了先进的性能。

Conclusion: MUJICA能够有效提升SISR模型在PBR材质超分辨率任务上的表现，保持跨贴图一致性，并在数据分布变化时具有良好的泛化能力，同时训练效率高，能在有限资源下实现先进性能。

Abstract: Physically Based Rendering (PBR) materials are typically characterized by
multiple 2D texture maps such as basecolor, normal, metallic, and roughness
which encode spatially-varying bi-directional reflectance distribution function
(SVBRDF) parameters to model surface reflectance properties and microfacet
interactions. Upscaling SVBRDF material is valuable for modern 3D graphics
applications. However, existing Single Image Super-Resolution (SISR) methods
struggle with cross-map inconsistency, inadequate modeling of modality-specific
features, and limited generalization due to data distribution shifts. In this
work, we propose Multi-modal Upscaling Joint Inference via Cross-map Attention
(MUJICA), a flexible adapter that reforms pre-trained Swin-transformer-based
SISR models for PBR material super-resolution. MUJICA is seamlessly attached
after the pre-trained and frozen SISR backbone. It leverages cross-map
attention to fuse features while preserving remarkable reconstruction ability
of the pre-trained SISR model. Applied to SISR models such as SwinIR, DRCT, and
HMANet, MUJICA improves PSNR, SSIM, and LPIPS scores while preserving cross-map
consistency. Experiments demonstrate that MUJICA enables efficient training
even with limited resources and delivers state-of-the-art performance on PBR
material datasets.

</details>


### [98] [Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology](https://arxiv.org/abs/2508.09805)
*Jonathan Williams Ramirez,Dina Zemlyanker,Lucas Deden-Binder,Rogeny Herisse,Erendira Garcia Pallares,Karthik Gopinath,Harshvardhan Gazula,Christopher Mount,Liana N. Kozanno,Michael S. Marshall,Theresa R. Connors,Matthew P. Frosch,Mark Montine,Derek H. Oakley,Christine L. Mac Donald,C. Dirk Keene,Bradley T. Hyman,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 开发了一个深度学习模型，能够自动分割	extit{尸检}大脑组织样本的照片，分割精度高，大大减少了手动分割所需的人工和成本。


<details>
  <summary>Details</summary>
Motivation: 手动分割	extit{尸检}大脑组织样本照片耗时耗力，需要昂贵的人工干预，因此需要开发自动分割工具。

Method: 利用包含1,414张手动分割的真实样本图像和2,000张合成图像的混合数据集训练U-Net模型，以实现对不同条件下拍摄的固定和新鲜组织样本的分割。

Result: 所提出的自动分割模型在未见过的数据集上表现出色，中位Dice相似系数超过0.98，平均表面距离小于0.4毫米，95%的Hausdorff距离小于1.60毫米，其性能接近手动分割的水平。

Conclusion: 该研究成功开发了一种基于深度学习的U-Net架构模型，可自动分割	extit{尸检}大脑组织样本的冠状面切片照片，分割精度高，可达	extit{所述}手动分割的水平。

Abstract: Advances in image registration and machine learning have recently enabled
volumetric analysis of \emph{postmortem} brain tissue from conventional
photographs of coronal slabs, which are routinely collected in brain banks and
neuropathology laboratories worldwide. One caveat of this methodology is the
requirement of segmentation of the tissue from photographs, which currently
requires costly manual intervention. In this article, we present a deep
learning model to automate this process. The automatic segmentation tool relies
on a U-Net architecture that was trained with a combination of
\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue,
from specimens with varying diagnoses, photographed at two different sites; and
\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding
masks generated from MRI scans for improved generalizability to unseen
photographic setups. Automated model predictions on a subset of photographs not
seen in training were analyzed to estimate performance compared to manual
labels -- including both inter- and intra-rater variability. Our model achieved
a median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\%
Hausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels.
Our tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.

</details>


### [99] [Poaching Hotspot Identification Using Satellite Imagery](https://arxiv.org/abs/2508.09812)
*Aryan Pandhi,Shrey Baid,Sanjali Jha*

Main category: cs.CV

TL;DR: 由于盗猎地点不断变化，需要计算机视觉模型来识别盗猎热点，以有效部署反盗猎资源。


<details>
  <summary>Details</summary>
Motivation: 非洲大象盗猎问题严重，盗猎地点动态变化，反盗猎努力集中在城镇附近，而大部分盗猎发生在偏远地区。需要一种方法来识别盗猎热点，以有效部署资源。

Method: 通过结合计算机视觉模型和卫星图像来识别偷猎热点。

Result: 计算机视觉模型可以消除手动追踪盗猎者并考虑环境因素的需要，并且与卫星图像的结合可以无需干扰当地物种或跨越边境航空限制即可调查大片区域。

Conclusion: 需要开发计算机视觉模型来识别偷猎热点，通过定位有利的偷猎区域的地理指标。

Abstract: Elephant Poaching in African countries has been a decade-old problem. So much
so that African Forest Elephants are now listed as an endangered species, and
African Savannah Elephants as critically endangered by the IUCN (International
Union for Conservation of Nature). [1] Elephants are hunted primarily for their
ivory tusks which caused many elephants to be born tuskless as a genetic
modification for survival. [2] Data gathered by recent studies shows that
though poaching methods remain the same, the poaching grounds are rather
dynamic. Poachers have shifted to areas with less ranger patrols and several
other factors like watering holes, seasons, altitude etc. cause constant shifts
in poaching hotspot locations. [3] After a period of low poaching from
2000-2014, poaching numbers in African countries are now on the rise again --
WWF (World Wildlife Foundation) says there are 20,000 elephants poached
annually [4]. In African countries, anti-poaching efforts are concentrated near
towns, while a majority of poaching occurs in the deserted regions. All of
these factors result in the need for a Computer Vision Model to identify
poaching hotspots through locating the geographic indicators of favorable
poaching regions. A CV model eliminates the need to manually track poachers and
account for the environmental factors to deploy resources and its combination
with satellite imagery allows us to survey large areas without disturbing local
species or cross border aviation restrictions.

</details>


### [100] [Evolution of Low-Level and Texture Human-CLIP Alignment](https://arxiv.org/abs/2508.09814)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra*

Main category: cs.CV

TL;DR: CLIP模型在训练初期会过度学习低层视觉特征，导致其与人类感知高度对齐，但对噪声敏感。随着训练的进行，模型会转向学习更抽象的特征，从而提高对噪声的鲁棒性，但会牺牲与人类感知的对齐度。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于观察到多模态模型在训练早期，与低层人类图像质量评估的相关性达到峰值，随后逐渐下降的现象，并旨在探究其背后的原因。

Method: 本研究通过分析CLIP等模型在训练过程中的现象，重点研究了两个关键因素：形状-纹理偏见对齐和噪声下的分类准确性下降。

Result: 研究发现，CLIP在训练早期学习低层视觉特征，提高了与人类感知的对齐度，但同时也增加了对噪声的敏感性和纹理偏见。训练后期，模型转向更抽象的形状表征，提高了噪声鲁棒性，但降低了与人类感知的对齐度。

Conclusion: 本研究揭示了多模态模型（如CLIP）在训练过程中，低层视觉特征与人类感知之间的权衡。模型早期倾向于学习低层视觉特征，提升了与人类感知的对齐度，但增加了对噪声的敏感性和纹理偏见。随着训练的深入，模型转向更抽象的形状表征，提高了对噪声的鲁棒性，但降低了与人类感知的对齐度。这表明存在一个潜在的学习机制，并为优化视觉-语言模型中感知对齐与鲁棒性之间的权衡提供了新的见解。

Abstract: During the training of multi-modal models like CLIP, we observed an
intriguing phenomenon: the correlation with low-level human image quality
assessments peaks in the early epochs before gradually declining. This study
investigates this observation and seeks to understand its causes through two
key factors: shape-texture bias alignment and classification accuracy drop
under noise. Our findings suggest that CLIP initially learn low-level visual
features, enhancing its alignment with low-level human perception but also
increasing its sensitivity to noise and its texture bias. As training
progresses, the model shifts toward more abstract shape-based representations,
improving noise robustness but reducing alignment with low-level human
perception. These results suggest that these factors shared an underlying
learning mechanism and provide new insights into optimizing the trade-off
between perceptual alignment and robustness in vision-language models.

</details>


### [101] [ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video](https://arxiv.org/abs/2508.09818)
*Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Abir Ahmed,Liew Tze Hui*

Main category: cs.CV

TL;DR: ViMoNet是一个结合运动和视频数据的框架，用于理解人类行为。它使用联合训练策略，并在VIMOS数据集和ViMoNet-Bench基准上进行了评估，结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 混合使用运动和视频数据对于全面捕捉人类动作的细微差别和意义至关重要，这与仅关注运动数据或视频的现有模型不同。

Method: ViMoNet采用联合训练策略，结合细粒度的运动-文本数据和通用的视频-文本数据，以捕捉人类行为的时间和空间信息。此外，还提出了一个新的数据集VIMOS和基准测试ViMoNet-Bench。

Result: ViMoNet在字幕生成、动作理解和行为解释方面表现优于现有方法。

Conclusion: ViMoNet在动作生成、动作理解和行为解释方面优于现有方法。

Abstract: This study investigates how large language models (LLMs) can be used to
understand human behavior using motion and video data. We think that mixing
both types is essential to completely capture the nuanced movements and
meanings of human actions, in contrast to recent models that simply concentrate
on motion data or films. To address this, we provide ViMoNet, a straightforward
yet effective framework for comprehending, characterizing, and deducing human
action. ViMoNet employs a joint training strategy that leverages the advantages
of two data types: detailed motion-text data, which is more exact, and generic
video-text data, which is more comprehensive but less detailed. This aids in
the model's acquisition of rich data regarding time and space in human
behavior. Additionally, we provide a brand new dataset named VIMOS that
contains a variety of films, motion sequences, instructions, and subtitles. We
developed ViMoNet-Bench, a standardized benchmark with carefully labeled
samples, to evaluate how well models understand human behavior. Our tests show
that ViMoNet outperforms existing methods in caption generation, motion
understanding, and behavior interpretation.

</details>


### [102] [Physical Autoregressive Model for Robotic Manipulation without Action Pretraining](https://arxiv.org/abs/2508.09822)
*Zijian Song,Sihan Qin,Tianshui Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种物理自回归模型（PAR），利用预训练的视频模型来解决机器人操作中的数据稀缺性问题，并在实验中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 机器人操作数据的稀缺性促使人们使用来自其他模态的预训练大模型。

Method: 提出了一种物理自回归模型（PAR），该模型结合了帧和动作的物理标记，以表示机器人及其环境的联合演变。PAR 利用视频预训练中嵌入的世界知识来理解物理动态，而无需进行动作预训练。它还采用基于 DiT 的分词器将帧和动作建模为连续标记，从而减少量化误差并促进相互增强。此外，还结合了因果掩码、逆运动学、并行训练和 KV 缓存机制来提高性能和效率。

Result: PAR 在 PushCube 任务上实现了 100% 的成功率，在其他任务上达到了与动作预训练基线相匹配的性能，并能准确预测具有紧密对齐的动作轨迹的未来视频。

Conclusion: 该研究结果强调了通过来自自回归视频预训练的转移世界知识，为机器人操作提供了一个有前景的方向。

Abstract: The scarcity of manipulation data has motivated the use of pretrained large
models from other modalities in robotics. In this work, we build upon
autoregressive video generation models to propose a Physical Autoregressive
Model (PAR), where physical tokens combine frames and actions to represent the
joint evolution of the robot and its environment. PAR leverages the world
knowledge embedded in video pretraining to understand physical dynamics without
requiring action pretraining, enabling accurate video prediction and consistent
action trajectories. It also adopts a DiT-based de-tokenizer to model frames
and actions as continuous tokens, mitigating quantization errors and
facilitating mutual enhancement. Furthermore, we incorporate a causal mask with
inverse kinematics, parallel training, and the KV-cache mechanism to further
improve performance and efficiency. Experiments on the ManiSkill benchmark show
that PAR achieves a 100\% success rate on the PushCube task, matches the
performance of action-pretrained baselines on other tasks, and accurately
predicts future videos with tightly aligned action trajectories. These findings
underscore a promising direction for robotic manipulation by transferring world
knowledge from autoregressive video pretraining.

</details>


### [103] [KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging](https://arxiv.org/abs/2508.09823)
*Valentin Boussot,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: KonfAI is a flexible, code-free deep learning framework for medical imaging that streamlines workflow definition and supports advanced techniques, proven effective in real-world applications and challenges.


<details>
  <summary>Details</summary>
Motivation: To create a deep learning framework for medical imaging that enhances reproducibility, transparency, and traceability while reducing development time through a declarative approach.

Method: KonfAI provides a modular, extensible, and configurable framework for defining deep learning workflows (training, inference, evaluation) using YAML files, supporting advanced strategies like patch-based learning, test-time augmentation, ensembling, and multi-model setups.

Result: Successfully applied to segmentation, registration, and image synthesis tasks, contributing to top-ranking results in international medical imaging challenges. The framework is open source.

Conclusion: KonfAI is a successful, open-source framework for deep learning in medical imaging, demonstrating broad applicability and achieving top results in challenges.

Abstract: KonfAI is a modular, extensible, and fully configurable deep learning
framework specifically designed for medical imaging tasks. It enables users to
define complete training, inference, and evaluation workflows through
structured YAML configuration files, without modifying the underlying code.
This declarative approach enhances reproducibility, transparency, and
experimental traceability while reducing development time. Beyond the
capabilities of standard pipelines, KonfAI provides native abstractions for
advanced strategies including patch-based learning, test-time augmentation,
model ensembling, and direct access to intermediate feature representations for
deep supervision. It also supports complex multi-model training setups such as
generative adversarial architectures. Thanks to its modular and extensible
architecture, KonfAI can easily accommodate custom models, loss functions, and
data processing components. The framework has been successfully applied to
segmentation, registration, and image synthesis tasks, and has contributed to
top-ranking results in several international medical imaging challenges. KonfAI
is open source and available at
\href{https://github.com/vboussot/KonfAI}{https://github.com/vboussot/KonfAI}.

</details>


### [104] [Reverse Convolution and Its Applications to Image Restoration](https://arxiv.org/abs/2508.09824)
*Xuhong Huang,Shiqi Liu,Kai Zhang,Ying Tai,Jian Yang,Hui Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 提出了一种新颖的深度反卷积算子，用于逆转深度卷积，并构建了名为ConverseNet的模型。在图像恢复任务的实验中，该模型表现良好，证明了该算子的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的转置卷积（反卷积）并非卷积的真正逆运算，导致缺乏标准的逆卷积算子。此研究旨在解决这一问题，提出一种能有效逆转深度卷积的新算子，以改进神经网络架构。

Method: 提出了一种新颖的深度反卷积算子，通过构建和解决正则化最小二乘优化问题来逆转深度卷积。研究了其核初始化、填充策略等关键实现方面。将此算子与层归一化、1x1卷积和GELU激活相结合，构建了一个类似Transformer的块，并将其应用于开发ConverseNet模型，并针对不同的图像恢复任务进行了训练和评估。

Result: 所提出的深度反卷积算子和基于它的反卷积块在图像恢复任务（高斯去噪、超分辨率、去模糊）的实验中被证明是有效的。ConverseNet模型在该领域取得了良好的结果，证明了该反卷积算子作为基础模块的潜力。

Conclusion: 该研究提出了一个新颖的深度反卷积算子，旨在有效逆转深度卷积。通过将该算子与层归一化、1x1卷积和GELU激活相结合，构建了一个类似Transformer的块，并在此基础上开发了ConverseNet。在图像恢复任务（如高斯去噪、超分辨率和去模糊）的实验中，ConverseNet表现出了有效性，表明所提出的反卷积算子是一个有用的基础模块，并为未来在深度模型设计和应用中的新算子开发开辟了道路。

Abstract: Convolution and transposed convolution are fundamental operators widely used
in neural networks. However, transposed convolution (a.k.a. deconvolution) does
not serve as a true inverse of convolution due to inherent differences in their
mathematical formulations. To date, no reverse convolution operator has been
established as a standard component in neural architectures. In this paper, we
propose a novel depthwise reverse convolution operator as an initial attempt to
effectively reverse depthwise convolution by formulating and solving a
regularized least-squares optimization problem. We thoroughly investigate its
kernel initialization, padding strategies, and other critical aspects to ensure
its effective implementation. Building upon this operator, we further construct
a reverse convolution block by combining it with layer normalization,
1$\times$1 convolution, and GELU activation, forming a Transformer-like
structure. The proposed operator and block can directly replace conventional
convolution and transposed convolution layers in existing architectures,
leading to the development of ConverseNet. Corresponding to typical image
restoration models such as DnCNN, SRResNet and USRNet, we train three variants
of ConverseNet for Gaussian denoising, super-resolution and deblurring,
respectively. Extensive experiments demonstrate the effectiveness of the
proposed reverse convolution operator as a basic building module. We hope this
work could pave the way for developing new operators in deep model design and
applications.

</details>


### [105] [Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment](https://arxiv.org/abs/2508.09843)
*Hao Yang,Xu Zhang,Jiaqi Ma,Linwei Zhu,Yun Zhang,Huan Zhang*

Main category: cs.CV

TL;DR: 提出一种基于图神经网络的OIQA新框架，通过模拟视点间的结构关系来评估局部非均匀失真，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前全向图像质量评估（OIQA）方法在评估具有局部非均匀失真的图像时存在不足，因为它们难以模拟质量的空间变化并有效提取同时包含局部细节和全局上下文的特征。

Method: 提出一种基于图神经网络的全向图像质量评估（OIQA）框架，采用斐波那契球采样生成视点并将其表示为图节点，利用多阶段特征提取网络获取高维节点表示。通过图注意力网络（GAT）和图 Transformer 模块分别捕捉相邻视点间的局部失真变化和远距离区域间的质量交互，以全面捕捉空间依赖性。

Result: 实验证明，所提出的基于图神经网络的OIQA框架在处理复杂空间失真方面显著优于现有方法，验证了其有效性和强大的泛化能力。

Conclusion: 该方法在两个大规模全向图像质量评估数据库上进行了广泛实验，能够有效评估局部非均匀失真，性能优于现有方法，并具有很强的泛化能力。

Abstract: Current Omnidirectional Image Quality Assessment (OIQA) methods struggle to
evaluate locally non-uniform distortions due to inadequate modeling of spatial
variations in quality and ineffective feature representation capturing both
local details and global context. To address this, we propose a graph neural
network-based OIQA framework that explicitly models structural relationships
between viewports to enhance perception of spatial distortion non-uniformity.
Our approach employs Fibonacci sphere sampling to generate viewports with
well-structured topology, representing each as a graph node. Multi-stage
feature extraction networks then derive high-dimensional node representation.
To holistically capture spatial dependencies, we integrate a Graph Attention
Network (GAT) modeling fine-grained local distortion variations among adjacent
viewports, and a graph transformer capturing long-range quality interactions
across distant regions. Extensive experiments on two large-scale OIQA databases
with complex spatial distortions demonstrate that our method significantly
outperforms existing approaches, confirming its effectiveness and strong
generalization capability.

</details>


### [106] [Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance](https://arxiv.org/abs/2508.09847)
*Dhruvraj Singh Rawat,Enggen Sherpa,Rishikesan Kirupanantha,Tin Hoang*

Main category: cs.CV

TL;DR: 本文评估了不同扩散模型在人脸生成任务上的表现，并提出了一种结合 InfoNCE 损失和 SegFormer 的方法，以提高在小规模数据集上的生成效果和可控性。


<details>
  <summary>Details</summary>
Motivation: 人脸生成是计算机视觉领域一个重要的研究方向，尤其是在数据有限的情况下，如何实现高质量、可控的人脸生成是一个挑战。本研究旨在通过基准测试和新方法探索扩散模型在小规模数据集上的人脸生成能力。

Method: 本文对用于人脸生成的扩散模型进行了基准测试，评估了无条件和有条件模型。具体来说，我们比较了 UNet 和 DiT 架构在无条件生成方面的表现，并探索了基于 LoRA 的预训练 Stable Diffusion 模型微调。此外，我们整合了用于属性嵌入的 InfoNCE 损失，并采用了基于 SegFormer 的分割编码器，以改进 Giambi 和 Lisanti 的多条件方法，该方法结合了属性向量和分割掩码。

Result: 研究结果表明，对比嵌入学习和高级分割编码有助于提升语义对齐和可控性，在数据有限的情况下对受控人脸生成效果显著。

Conclusion: 所提出的对比嵌入学习和高级分割编码方法在有限数据集设置下能够有效地进行受控人脸生成。

Abstract: We present a benchmark of diffusion models for human face generation on a
small-scale CelebAMask-HQ dataset, evaluating both unconditional and
conditional pipelines. Our study compares UNet and DiT architectures for
unconditional generation and explores LoRA-based fine-tuning of pretrained
Stable Diffusion models as a separate experiment. Building on the
multi-conditioning approach of Giambi and Lisanti, which uses both attribute
vectors and segmentation masks, our main contribution is the integration of an
InfoNCE loss for attribute embedding and the adoption of a SegFormer-based
segmentation encoder. These enhancements improve the semantic alignment and
controllability of attribute-guided synthesis. Our results highlight the
effectiveness of contrastive embedding learning and advanced segmentation
encoding for controlled face generation in limited data settings.

</details>


### [107] [ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images](https://arxiv.org/abs/2508.09849)
*Jan Phillipp Albrecht,Jose R. A. Godinho,Christina Hübers,Deborah Schmidt*

Main category: cs.CV

TL;DR: ARI3D是一款用于3D X射线CT图像分析的软件，旨在解决成像伪影问题，提高微观结构分析的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: X射线CT图像存在成像伪影（如硬化和部分体积效应），给定量分析带来挑战，需要用户进行分割和分类决策。

Method: 提出了一种名为ARI3D的交互式软件工具，用于分析3D X射线CT图像中的内部微观结构，辅助用户完成分类和量化步骤。

Result: ARI3D旨在提高物相识别能力，考虑部分体积效应，提高物体的检测限和量化准确性，并统一不同科学领域的3D定量分析。 (需要运行 ARI3D 来验证)

Conclusion: ARI3D旨在提高3D图像分析的准确性和一致性。

Abstract: X-ray computed tomography (CT) is the main 3D technique for imaging the
internal microstructures of materials. Quantitative analysis of the
microstructures is usually achieved by applying a sequence of steps that are
implemented to the entire 3D image. This is challenged by various imaging
artifacts inherent from the technique, e.g., beam hardening and partial volume.
Consequently, the analysis requires users to make a number of decisions to
segment and classify the microstructures based on the voxel gray-values. In
this context, a software tool, here called ARI3D, is proposed to interactively
analyze regions in three-dimensional X-ray CT images, assisting users through
the various steps of a protocol designed to classify and quantify objects
within regions of a three-dimensional image. ARI3D aims to 1) Improve phase
identification; 2) Account for partial volume effect; 3) Increase the detection
limit and accuracy of object quantification; and 4) Harmonize quantitative 3D
analysis that can be implemented in different fields of science.

</details>


### [108] [Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment](https://arxiv.org/abs/2508.09850)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Valero Laparra,Jesus Malo*

Main category: cs.CV

TL;DR: ViT的性能与人类感知对齐之间存在权衡：更大的模型、更强的正则化/增强和重复训练会降低对齐度，而数据集多样性影响不大。


<details>
  <summary>Details</summary>
Motivation: ViT在图像识别方面表现出色，但其与人类感知的对齐方式尚不明确。

Method: 通过在TID2013数据集上系统分析模型大小、数据集大小、数据增强和正则化对ViT感知对齐的影响。

Result: 更大的模型、更多的数据重复训练次数、更强的数据增强和正则化都会降低ViT与人类感知的对齐程度。增加数据集多样性影响甚微。

Conclusion: ViT模型大小、数据集大小、数据增强和正则化等因素与人类感知对齐之间存在权衡，这对于需要类人视觉理解的应用具有重要意义。

Abstract: Vision Transformers (ViTs) achieve remarkable performance in image
recognition tasks, yet their alignment with human perception remains largely
unexplored. This study systematically analyzes how model size, dataset size,
data augmentation and regularization impact ViT perceptual alignment with human
judgments on the TID2013 dataset. Our findings confirm that larger models
exhibit lower perceptual alignment, consistent with previous works. Increasing
dataset diversity has a minimal impact, but exposing models to the same images
more times reduces alignment. Stronger data augmentation and regularization
further decrease alignment, especially in models exposed to repeated training
cycles. These results highlight a trade-off between model complexity, training
strategies, and alignment with human perception, raising important
considerations for applications requiring human-like visual understanding.

</details>


### [109] [OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better](https://arxiv.org/abs/2508.09857)
*Yupeng Zhou,Zhen Li,Ziheng Ouyang,Yuming Chen,Ruoyi Du,Daquan Zhou,Bin Fu,Yihao Liu,Peng Gao,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: OneVAE通过结合连续和离散VAE的优势，利用FSQ保留连续先验，并引入多令牌量化和增强第一帧重建等改进，实现了更快的收敛速度和更好的性能，同时统一了连续和离散表示。


<details>
  <summary>Details</summary>
Motivation: 为了让视频能够被编码成离散的tokens，从而能和文本tokens对齐，方便构建多模态大模型。然而，相比于连续视频表示，离散表示会带来显著的时空压缩。之前的离散视频VAE训练不稳定、耗时长且重建质量差。

Method: 提出了一种名为OneVAE的方法，通过有限态量子化（FSQ）有效保留预训练的连续VAE先验，并引入了多令牌量化机制和增强第一帧重建的结构改进。此外，还提出了一种联合离散-连续优化方案。

Result: 相比于从头训练，OneVAE的收敛速度快了数倍，并在收敛时取得了优越的性能。多令牌量化机制在不影响压缩率的情况下，PSNR提升了近1dB。增强第一帧重建的改进显著提高了4x16x16离散VAE的性能。

Conclusion: OneVAE通过结合连续和离散VAE的优点，实现了在单一网络中在连续和离散表示上都具有竞争力。

Abstract: Encoding videos into discrete tokens could align with text tokens to
facilitate concise and unified multi-modal LLMs, yet introducing significant
spatiotemporal compression compared to continuous video representation.
Previous discrete video VAEs experienced unstable training, long training time,
and degraded reconstruction quality. Given the easier training and superior
performance of continuous VAEs, an intuitive idea is to enhance discrete video
VAEs by leveraging continuous VAEs. After rethinking the intrinsic link between
discrete and continuous representations, we found that FSQ could effectively
preserve pre-trained continuous VAE priors compared to other quantization
methods. By leveraging continuous VAE priors, it converges several times faster
than training from scratch and achieves superior performance at convergence.
Meanwhile, two structural improvements are proposed. First, inspired by how
continuous VAEs enhance reconstruction via enlarged latent dimensions, we
introduce a multi-token quantization mechanism, which achieves nearly a 1 dB
improvement in PSNR without compromising the token compression ratio. Second,
to tackle reconstruction challenges in high-compression video VAEs, we
strengthen first-frame reconstruction, enabling the causal VAE to leverage this
information in subsequent frames and markedly improving the performance of 4 x
16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous
optimization scheme that unifies the two paradigms and, for the first time,
achieves competitive performance on both continuous and discrete
representations within a single network. We name our method OneVAE to reflect
this connection.

</details>


### [110] [HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics](https://arxiv.org/abs/2508.09858)
*Weiqi Li,Zehao Zhang,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: HumanGenesis通过整合几何和生成模型，利用重构器、评估代理、姿势引导器和视频协调器这四个协同代理，解决了现有合成人类动态方法的几何不一致、运动泛化受限等问题，在各项任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的合成人类动态方法面临几何不一致、重建粗糙、运动泛化限制和场景不协调等挑战，因为它们在3D建模、细节保留和生成能力方面存在局限。

Method: HumanGenesis框架整合了几何和生成模型，包含四个协同的代理：1. 重构器（Reconstructor）使用3D高斯泼溅和形变分解从单目视频构建3D一致的人体-场景表示。2. 评估代理（Critique Agent）通过多轮基于MLLM的反馈来识别和优化不良区域，从而提高重构保真度。3. 姿势引导器（Pose Guider）通过生成具有时间意识的参数化编码器的表达性姿势序列来实现姿势泛化。4. 视频协调器（Video Harmonizer）通过具有扩散的混合渲染管线合成照片般逼真、连贯的视频，并通过4D反馈循环优化重构器。

Result: HumanGenesis 在文本引导合成、视频重演和新姿势泛化等任务上取得了最先进的性能，显著提高了表现力、几何保真度和场景集成度。

Conclusion: HumanGenesis 在文本引导合成、视频重演和新姿势泛化等任务上实现了最先进的性能，显著提高了表现力、几何保真度和场景集成度。

Abstract: \textbf{Synthetic human dynamics} aims to generate photorealistic videos of
human subjects performing expressive, intention-driven motions. However,
current approaches face two core challenges: (1) \emph{geometric inconsistency}
and \emph{coarse reconstruction}, due to limited 3D modeling and detail
preservation; and (2) \emph{motion generalization limitations} and \emph{scene
inharmonization}, stemming from weak generative capabilities. To address these,
we present \textbf{HumanGenesis}, a framework that integrates geometric and
generative modeling through four collaborative agents: (1)
\textbf{Reconstructor} builds 3D-consistent human-scene representations from
monocular video using 3D Gaussian Splatting and deformation decomposition. (2)
\textbf{Critique Agent} enhances reconstruction fidelity by identifying and
refining poor regions via multi-round MLLM-based reflection. (3) \textbf{Pose
Guider} enables motion generalization by generating expressive pose sequences
using time-aware parametric encoders. (4) \textbf{Video Harmonizer} synthesizes
photorealistic, coherent video via a hybrid rendering pipeline with diffusion,
refining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis
achieves state-of-the-art performance on tasks including text-guided synthesis,
video reenactment, and novel-pose generalization, significantly improving
expressiveness, geometric fidelity, and scene integration.

</details>


### [111] [E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras](https://arxiv.org/abs/2508.09912)
*Chaoran Feng,Zhenyu Tang,Wangbo Yu,Yatian Pang,Yian Zhao,Jianbin Zhao,Li Yuan,Yonghong Tian*

Main category: cs.CV

TL;DR: E-4DGS 使用事件相机实现了高质量的新视角合成和 4D 重建，特别擅长处理高速运动和弱光场景。


<details>
  <summary>Details</summary>
Motivation: 解决传统RGB相机在光照、运动模糊和动态范围方面的局限性，利用事件相机在高动态范围、高时间分辨率和低功耗方面的优势。

Method: 提出了一种名为 E-4DGS 的事件驱动动态高斯泼溅方法，包括事件驱动初始化、事件自适应切片泼溅、强度重要性剪枝和自适应对比度阈值，并构建了一个包含六个移动事件相机的合成数据集。

Result: E-4DGS 在新视角合成和 4D 重建方面取得了优于事件自身和事件-RGB 融合基线方法的性能，解决了伪影和 3D 一致性问题。

Conclusion: E-4DGS 是首个用于从多视角事件流进行新视角合成的事件驱动动态高斯泼溅方法，在高速运动和弱光场景下表现优于现有方法，为基于事件的重建在快速场景捕获方面开辟了新途径。

Abstract: Novel view synthesis and 4D reconstruction techniques predominantly rely on
RGB cameras, thereby inheriting inherent limitations such as the dependence on
adequate lighting, susceptibility to motion blur, and a limited dynamic range.
Event cameras, offering advantages of low power, high temporal resolution and
high dynamic range, have brought a new perspective to addressing the scene
reconstruction challenges in high-speed motion and low-light scenes. To this
end, we propose E-4DGS, the first event-driven dynamic Gaussian Splatting
approach, for novel view synthesis from multi-view event streams with
fast-moving cameras. Specifically, we introduce an event-based initialization
scheme to ensure stable training and propose event-adaptive slicing splatting
for time-aware reconstruction. Additionally, we employ intensity importance
pruning to eliminate floating artifacts and enhance 3D consistency, while
incorporating an adaptive contrast threshold for more precise optimization. We
design a synthetic multi-view camera setup with six moving event cameras
surrounding the object in a 360-degree configuration and provide a benchmark
multi-view event stream dataset that captures challenging motion scenarios. Our
approach outperforms both event-only and event-RGB fusion baselines and paves
the way for the exploration of multi-view event-based reconstruction as a novel
approach for rapid scene capture.

</details>


### [112] [SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection](https://arxiv.org/abs/2508.09913)
*Yachao Liang,Min Yu,Gang Li,Jianguo Jiang,Boquan Li,Feng Yu,Ning Zhang,Xiang Meng,Weiqing Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的视听语音表示学习方法，利用音频和视觉语音元素的协同作用来检测人脸伪造视频。该方法在真实视频上进行训练，无需伪造视频，并在跨数据集泛化和鲁棒性方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 音频信号包含丰富的语音内容，可以提供有效反映面部运动的精确信息。

Method: 通过自监督掩码预测任务在真实视频上学习精确的视听语音表示，该任务同时编码局部和全局语义信息，然后将模型直接转移到伪造检测任务。

Result: 所提出的视听语音表示学习方法在跨数据集泛化和鲁棒性方面优于最先进的方法。

Conclusion: 该方法在不使用任何伪造视频进行模型训练的情况下，在跨数据集泛化和鲁棒性方面优于最先进的方法。

Abstract: Detection of face forgery videos remains a formidable challenge in the field
of digital forensics, especially the generalization to unseen datasets and
common perturbations. In this paper, we tackle this issue by leveraging the
synergy between audio and visual speech elements, embarking on a novel approach
through audio-visual speech representation learning. Our work is motivated by
the finding that audio signals, enriched with speech content, can provide
precise information effectively reflecting facial movements. To this end, we
first learn precise audio-visual speech representations on real videos via a
self-supervised masked prediction task, which encodes both local and global
semantic information simultaneously. Then, the derived model is directly
transferred to the forgery detection task. Extensive experiments demonstrate
that our method outperforms the state-of-the-art methods in terms of
cross-dataset generalization and robustness, without the participation of any
fake video in model training. Code is available at
https://github.com/Eleven4AI/SpeechForensics.

</details>


### [113] [Towards Comprehensive Cellular Characterisation of H&E slides](https://arxiv.org/abs/2508.09926)
*Benjamin Adjadj,Pierre-Antoine Bannier,Guillaume Horent,Sebastien Mandela,Aurore Lyon,Kathryn Schutte,Ulysse Marteau,Valentin Gaury,Laura Dumont,Thomas Mathieu,Reda Belbahri,Benoît Schmauch,Eric Durand,Katharina Von Loga,Lucie Gillet*

Main category: cs.CV

TL;DR: HistoPLUS是一个新的模型，在细胞检测、分割和分类方面表现出色，尤其是在研究不足的细胞类型和跨领域泛化方面。


<details>
  <summary>Details</summary>
Motivation: 现有的细胞分析方法在研究不足的细胞类型和跨领域泛化方面存在不足。

Method: HistoPLUS是一个新的模型，在包含108,722个细胞核和13种细胞类型的、经过新策划的泛癌数据集上进行了训练。

Result: HistoPLUS在检测质量上提高了5.2%，在总体F1分类分数上提高了23.7%，同时使用的参数减少了5倍。它还成功地应用于两个在训练中未见过的肿瘤适应症。

Conclusion: HistoPLUS在细胞检测、分割和分类方面表现出色，尤其是在对研究不足的细胞类型和跨领域泛化方面，它超越了现有的最先进模型，并为TME生物标志物研究提供了支持。

Abstract: Cell detection, segmentation and classification are essential for analyzing
tumor microenvironments (TME) on hematoxylin and eosin (H&E) slides. Existing
methods suffer from poor performance on understudied cell types (rare or not
present in public datasets) and limited cross-domain generalization. To address
these shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell
analysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei
covering 13 cell types. In external validation across 4 independent cohorts,
HistoPLUS outperforms current state-of-the-art models in detection quality by
5.2% and overall F1 classification score by 23.7%, while using 5x fewer
parameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types
and brings significant improvements on 8 of 13 cell types. Moreover, we show
that HistoPLUS robustly transfers to two oncology indications unseen during
training. To support broader TME biomarker research, we release the model
weights and inference code at https://github.com/owkin/histoplus/.

</details>


### [114] [Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?](https://arxiv.org/abs/2508.09936)
*Vittorio Pippi,Konstantina Nikolaidou,Silvia Cascianelli,George Retsinas,Giorgos Sfikas,Rita Cucchiara,Marcus Liwicki*

Main category: cs.CV

TL;DR: 这项研究评估了三种领先的手写文本生成（HTG）模型在改进低资源手写文本识别（HTR）方面的效果，并为选择最佳模型提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了解决手稿数字化中HTR系统在处理小规模、特定作者的、偏离训练数据分布的藏品时面临的挑战，使用针对特定手写风格生成合成数据的HTG技术被认为是一种有前景的解决方案。然而，不同HTG模型在提升HTR性能方面的效果，尤其是在低资源转录场景下的效果，尚未得到充分评估。

Method: 本文系统地比较了三种最先进的风格化HTG模型（生成对抗、扩散和自回归范式），以评估它们对HTR微调的影响，并分析了合成数据的视觉和语言特征如何影响微调结果。

Result: 研究结果为选择最有效的HTG模型提供了定量指导，并揭示了HTG方法在应用于低资源HTR方面的现有能力和未来改进的关键领域。

Conclusion: 需要对不同的HTG模型进行更深入的评估，以确定它们在低资源HTR场景中的有效性。

Abstract: The digitization of historical manuscripts presents significant challenges
for Handwritten Text Recognition (HTR) systems, particularly when dealing with
small, author-specific collections that diverge from the training data
distributions. Handwritten Text Generation (HTG) techniques, which generate
synthetic data tailored to specific handwriting styles, offer a promising
solution to address these challenges. However, the effectiveness of various HTG
models in enhancing HTR performance, especially in low-resource transcription
settings, has not been thoroughly evaluated. In this work, we systematically
compare three state-of-the-art styled HTG models (representing the generative
adversarial, diffusion, and autoregressive paradigms for HTG) to assess their
impact on HTR fine-tuning. We analyze how visual and linguistic characteristics
of synthetic data influence fine-tuning outcomes and provide quantitative
guidelines for selecting the most effective HTG model. The results of our
analysis provide insights into the current capabilities of HTG methods and
highlight key areas for further improvement in their application to
low-resource HTR.

</details>


### [115] [AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models](https://arxiv.org/abs/2508.09943)
*Tomás de la Sotta,José M. Saavedra,Héctor Henríquez,Violeta Chang,Aline Xavier*

Main category: cs.CV

TL;DR: AST-n 结合高阶 ODE 求解器可实现快速 LDCT 重建，显著缩短推理时间，同时保持高图像质量。


<details>
  <summary>Details</summary>
Motivation: 低剂量 CT（LDCT）协议虽然能减少辐射暴露，但会增加图像噪声，从而影响诊断信心。因此，需要开发有效的 LDCT 去噪方法。

Method: 本文介绍了一种名为 AST-n 的加速推理框架，该框架从中间噪声水平开始反向扩散，并集成了高阶 ODE 求解器来减少采样步数。评估了 AST-n 采样和使用高阶求解器的标准调度两种加速范式。

Result: 在低剂量 CT 公共数据集（包括头部、腹部和胸部扫描）上进行的评估显示，使用 25 步的条件模型（AST-25）实现了超过 38 dB 的峰值信噪比（PSNR）和 0.95 以上的结构相似性指数（SSIM），图像质量与标准基线相当，但推理时间从约 16 秒减少到 1 秒以下。无条件采样会导致显著的质量损失。DDIM 反演在图像质量方面仅带来边际增益，但推理时间增加一倍，临床实用性有限。

Conclusion: AST-n 框架结合高阶 ODE 求解器能够快速地从低剂量 CT 图像中重建高质量图像，将推理时间从约 16 秒缩短到 1 秒以内，同时保持了与标准基线相当的图像质量，提高了基于扩散的方法在临床工作流程中的可行性。

Abstract: Low-dose CT (LDCT) protocols reduce radiation exposure but increase image
noise, compromising diagnostic confidence. Diffusion-based generative models
have shown promise for LDCT denoising by learning image priors and performing
iterative refinement. In this work, we introduce AST-n, an accelerated
inference framework that initiates reverse diffusion from intermediate noise
levels, and integrate high-order ODE solvers within conditioned models to
further reduce sampling steps. We evaluate two acceleration paradigms--AST-n
sampling and standard scheduling with high-order solvers -- on the Low Dose CT
Grand Challenge dataset, covering head, abdominal, and chest scans at 10-25 %
of standard dose. Conditioned models using only 25 steps (AST-25) achieve peak
signal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM)
above 0.95, closely matching standard baselines while cutting inference time
from ~16 seg to under 1 seg per slice. Unconditional sampling suffers
substantial quality loss, underscoring the necessity of conditioning. We also
assess DDIM inversion, which yields marginal PSNR gains at the cost of doubling
inference time, limiting its clinical practicality. Our results demonstrate
that AST-n with high-order samplers enables rapid LDCT reconstruction without
significant loss of image fidelity, advancing the feasibility of
diffusion-based methods in clinical workflows.

</details>


### [116] [Stable Diffusion Models are Secretly Good at Visual In-Context Learning](https://arxiv.org/abs/2508.09949)
*Trevine Oorloff,Vishwanath Sindagi,Wele Gedara Chaminda Bandara,Ali Shafahi,Amin Ghiasi,Charan Prakash,Reza Ardekani*

Main category: cs.CV

TL;DR: 通过在Stable Diffusion模型中加入原地注意力重新计算，无需微调即可实现视觉上下文学习，并在多项视觉任务上取得优于现有方法的效果，同时支持集成多种提示以提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了将大型语言模型在自然语言处理中的上下文学习（ICL）能力扩展到计算机视觉任务，并克服现有方法（需要专门训练或附加数据）的复杂性和泛化性限制。

Method: 提出了一种在Stable Diffusion架构的自注意力层中进行原地注意力重新计算的方法，以整合查询和示例提示之间的上下文信息。

Result: 该方法在六项不同任务（前景分割、单物体检测、语义分割、关键点检测、边缘检测和着色）上展示了Stable Diffusion模型的V-ICL能力。例如，在Pascal-5i数据集的前景分割任务上，将平均交并比（mIoU）相较于Visual Prompting和IMProv等现有方法分别提高了8.9%和3.2%。此外，该方法通过集成（ensembling）多个提示，能够更有效地推断任务并进一步提升性能。

Conclusion: 该研究表明，无需进行任何额外的微调，即可通过在自注意力层中进行原地注意力重新计算，将现成的Stable Diffusion模型用于视觉上下文学习（V-ICL），从而实现查询和示例提示之间的显式上下文整合。

Abstract: Large language models (LLM) in natural language processing (NLP) have
demonstrated great potential for in-context learning (ICL) -- the ability to
leverage a few sets of example prompts to adapt to various tasks without having
to explicitly update the model weights. ICL has recently been explored for
computer vision tasks with promising early outcomes. These approaches involve
specialized training and/or additional data that complicate the process and
limit its generalizability. In this work, we show that off-the-shelf Stable
Diffusion models can be repurposed for visual in-context learning (V-ICL).
Specifically, we formulate an in-place attention re-computation within the
self-attention layers of the Stable Diffusion architecture that explicitly
incorporates context between the query and example prompts. Without any
additional fine-tuning, we show that this repurposed Stable Diffusion model is
able to adapt to six different tasks: foreground segmentation, single object
detection, semantic segmentation, keypoint detection, edge detection, and
colorization. For example, the proposed approach improves the mean intersection
over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by
8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,
respectively. Additionally, we show that the proposed method is able to
effectively leverage multiple prompts through ensembling to infer the task
better and further improve the performance.

</details>


### [117] [LIA-X: Interpretable Latent Portrait Animator](https://arxiv.org/abs/2508.09959)
*Yaohui Wang,Di Yang,Xinyuan Chen,Francois Bremond,Yu Qiao,Antitza Dantcheva*

Main category: cs.CV

TL;DR: LIA-X 是一种可解释的肖像动画器，可以通过稀疏运动字典将面部动态从一个视频迁移到另一个视频，实现细粒度控制和精确操作。


<details>
  <summary>Details</summary>
Motivation: 介绍 LIA-X，一种新颖的可解释肖像动画器，旨在将面部动态从驱动视频迁移到具有细粒度控制的源肖像。

Method: LIA-X 是一种新颖的可解释肖像动画器，它将运动迁移建模为潜在空间中运动代码的线性导航。它包含一个新颖的稀疏运动字典，可以将面部动态分解为可解释的因素，并支持可控的“编辑-扭曲-渲染”策略，从而实现对源肖像中细粒度面部语义的精确操作。

Result: 实验结果表明，LIA-X 在自我和跨肖像的视频处理任务中的表现优于先前的方法，并且具有可解释性和可控性，支持精细的用户指导图像和视频编辑以及三维感知肖像视频处理。

Conclusion: LIA-X 在面部动态迁移方面优于先前的方法，并且具有实际应用潜力，例如细粒度的、用户指导的图像和视频编辑以及三维感知肖像视频处理。

Abstract: We introduce LIA-X, a novel interpretable portrait animator designed to
transfer facial dynamics from a driving video to a source portrait with
fine-grained control. LIA-X is an autoencoder that models motion transfer as a
linear navigation of motion codes in latent space. Crucially, it incorporates a
novel Sparse Motion Dictionary that enables the model to disentangle facial
dynamics into interpretable factors. Deviating from previous 'warp-render'
approaches, the interpretability of the Sparse Motion Dictionary allows LIA-X
to support a highly controllable 'edit-warp-render' strategy, enabling precise
manipulation of fine-grained facial semantics in the source portrait. This
helps to narrow initial differences with the driving video in terms of pose and
expression. Moreover, we demonstrate the scalability of LIA-X by successfully
training a large-scale model with approximately 1 billion parameters on
extensive datasets. Experimental results show that our proposed method
outperforms previous approaches in both self-reenactment and cross-reenactment
tasks across several benchmarks. Additionally, the interpretable and
controllable nature of LIA-X supports practical applications such as
fine-grained, user-guided image and video editing, as well as 3D-aware portrait
video manipulation.

</details>


### [118] [January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis](https://arxiv.org/abs/2508.09966)
*Amir Hosseinian,Ashkan Dehghani Zahedani,Umer Mansoor,Noosheen Hashemi,Mark Woodward*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Progress in AI for automated nutritional analysis is critically hampered by
the lack of standardized evaluation methodologies and high-quality, real-world
benchmark datasets. To address this, we introduce three primary contributions.
First, we present the January Food Benchmark (JFB), a publicly available
collection of 1,000 food images with human-validated annotations. Second, we
detail a comprehensive benchmarking framework, including robust metrics and a
novel, application-oriented overall score designed to assess model performance
holistically. Third, we provide baseline results from both general-purpose
Vision-Language Models (VLMs) and our own specialized model,
january/food-vision-v1. Our evaluation demonstrates that the specialized model
achieves an Overall Score of 86.2, a 12.1-point improvement over the
best-performing general-purpose configuration. This work offers the research
community a valuable new evaluation dataset and a rigorous framework to guide
and benchmark future developments in automated nutritional analysis.

</details>


### [119] [MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification](https://arxiv.org/abs/2508.09967)
*Tianqi Xiang,Yi Li,Qixiang Zhang,Xiaomeng Li*

Main category: cs.CV

TL;DR: MOC通过元学习器和分类器库优化分类器，解决了少样本学习中的数据稀缺性问题，在WSI分类任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉语言基础模型（VLFM）的WSI分类方法虽然有潜力解决数据稀缺性问题，但性能仍落后于传统的MIL方法；现有的少样本学习方法虽然提高了诊断准确性，但其对传统分类器设计的依赖使其在数据稀缺性方面存在关键漏洞。

Method: 提出了一种元优化分类器（MOC），包含一个元学习器（自动优化分类器配置）和一个分类器库（包含多样化的候选分类器）。

Result: MOC在多个少样本基准测试中表现优于现有技术，在TCGA-NSCLC基准测试中，相对于最先进的少样本VLFM方法，AUC提高了10.4%，在1次样本条件下提高了26.25%。

Conclusion: MOC通过元学习器自动优化分类器配置，并结合包含多样化候选分类器的分类器库，能够进行全面的病理学解释，在多个少样本基准测试中表现优于现有技术，并在TCGA-NSCLC基准测试中将AUC提高了10.4%，在1次样本条件下提高了26.25%，为临床部署中诊断训练数据严重不足的情况提供了关键进展。

Abstract: Recent advances in histopathology vision-language foundation models (VLFMs)
have shown promise in addressing data scarcity for whole slide image (WSI)
classification via zero-shot adaptation. However, these methods remain
outperformed by conventional multiple instance learning (MIL) approaches
trained on large datasets, motivating recent efforts to enhance VLFM-based WSI
classification through fewshot learning paradigms. While existing few-shot
methods improve diagnostic accuracy with limited annotations, their reliance on
conventional classifier designs introduces critical vulnerabilities to data
scarcity. To address this problem, we propose a Meta-Optimized Classifier (MOC)
comprising two core components: (1) a meta-learner that automatically optimizes
a classifier configuration from a mixture of candidate classifiers and (2) a
classifier bank housing diverse candidate classifiers to enable a holistic
pathological interpretation. Extensive experiments demonstrate that MOC
outperforms prior arts in multiple few-shot benchmarks. Notably, on the
TCGA-NSCLC benchmark, MOC improves AUC by 10.4% over the state-of-the-art
few-shot VLFM-based methods, with gains up to 26.25% under 1-shot conditions,
offering a critical advancement for clinical deployments where diagnostic
training data is severely limited. Code is available at
https://github.com/xmed-lab/MOC.

</details>


### [120] [PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image](https://arxiv.org/abs/2508.09973)
*Geonhee Sim,Gyeongsik Moon*

Main category: cs.CV

TL;DR: PERSONA框架从单张图像创建个性化3D人体虚拟人，结合3D表示和扩散模型，通过平衡采样和几何加权优化技术，解决了身份保持和姿态渲染问题。


<details>
  <summary>Details</summary>
Motivation: 现有的可驱动人体虚拟人创建方法存在局限性：基于3D的方法（如NeRF或3DGS）需要大量姿态丰富的视频才能实现个性化，这在现实生活中难以获取；而基于扩散的方法虽然能从大量视频中学习姿态驱动变形，但在身份保持和姿态相关身份纠缠方面存在困难。因此，需要一种能够结合两者优点，仅从单张图像即可生成具有姿态驱动变形的个性化3D人体虚拟人的框架。

Method: PERSONA框架首先利用基于扩散的方法从输入单张图像生成包含丰富姿态的视频，然后基于这些视频优化3D虚拟人。为了保证高真实感和多样姿态下的清晰渲染，采用了平衡采样（通过对输入图像进行过采样来减少身份偏移）和几何加权优化（优先考虑几何约束而非图像损失）的策略。

Result: PERSONA框架能够从单张图像生成个性化的3D人体虚拟人，并实现了良好的姿态驱动变形。通过平衡采样和几何加权优化，提高了虚拟人在多样姿态下的真实感和渲染质量，有效解决了身份保持和姿态依赖性问题。

Conclusion: PERSONA框架通过结合3D表示和基于扩散的方法，实现了从单张图像生成具有姿态驱动变形的个性化3D人体虚拟人。通过引入平衡采样和几何加权优化，解决了现有方法在身份保持和姿态多样性渲染方面的挑战，提高了虚拟人的真实感和渲染质量。

Abstract: Two major approaches exist for creating animatable human avatars. The first,
a 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a
single person, achieving personalization through a disentangled identity
representation. However, modeling pose-driven deformations, such as non-rigid
cloth deformations, requires numerous pose-rich videos, which are costly and
impractical to capture in daily life. The second, a diffusion-based approach,
learns pose-driven deformations from large-scale in-the-wild videos but
struggles with identity preservation and pose-dependent identity entanglement.
We present PERSONA, a framework that combines the strengths of both approaches
to obtain a personalized 3D human avatar with pose-driven deformations from a
single image. PERSONA leverages a diffusion-based approach to generate
pose-rich videos from the input image and optimizes a 3D avatar based on them.
To ensure high authenticity and sharp renderings across diverse poses, we
introduce balanced sampling and geometry-weighted optimization. Balanced
sampling oversamples the input image to mitigate identity shifts in
diffusion-generated training videos. Geometry-weighted optimization prioritizes
geometry constraints over image loss, preserving rendering quality in diverse
poses.

</details>


### [121] [A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation](https://arxiv.org/abs/2508.09977)
*Shuting He,Peilin Ji,Yitong Yang,Changshuo Wang,Jiayi Ji,Yinglin Wang,Henghui Ding*

Main category: cs.CV

TL;DR: 本文对3D高斯泼溅（3DGS）的应用进行了全面的调查，重点介绍了其在3D场景表示、渲染以及分割、编辑、生成等下游任务中的进展。


<details>
  <summary>Details</summary>
Motivation: 调查3DGS在3D场景表示中的应用，以支持几何和语义理解。

Method: 本文首先介绍了支持3DGS语义理解和控制的2D基础模型，然后回顾了为3DGS提供信息的NeRF方法。接着将3DGS应用分为分割、编辑、生成和其他功能任务，并对每类进行了总结。

Result: 对3DGS的分割、编辑、生成和其他功能任务进行了总结，包括代表性方法、监督策略和学习范式，并强调了共同的设计原则和新兴趋势。同时还总结了常用的数据集、评估协议以及在公开基准上的方法比较分析。

Conclusion: 3DGS在3D场景表示方面作为NeRF的强大替代品，实现了高保真和实时渲染，并支持各种下游应用。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative
to Neural Radiance Fields (NeRF) for 3D scene representation, offering
high-fidelity photorealistic rendering with real-time performance. Beyond novel
view synthesis, the explicit and compact nature of 3DGS enables a wide range of
downstream applications that require geometric and semantic understanding. This
survey provides a comprehensive overview of recent progress in 3DGS
applications. It first introduces 2D foundation models that support semantic
understanding and control in 3DGS applications, followed by a review of
NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS
applications into segmentation, editing, generation, and other functional
tasks. For each, we summarize representative methods, supervision strategies,
and learning paradigms, highlighting shared design principles and emerging
trends. Commonly used datasets and evaluation protocols are also summarized,
along with comparative analyses of recent methods across public benchmarks. To
support ongoing research and development, a continually updated repository of
papers, code, and resources is maintained at
https://github.com/heshuting555/Awesome-3DGS-Applications.

</details>


### [122] [LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit](https://arxiv.org/abs/2508.09981)
*Chengtao Lv,Bilang Zhang,Yang Yong,Ruihao Gong,Yushi Huang,Shiqiao Gu,Jiajun Wu,Yumeng Shi,Jinyang Guo,Wenya Wang*

Main category: cs.CV

TL;DR: LLMC+ 是一个 VLM 压缩基准和工具包，用于公平评估和研究压缩技术，发现空间/时间冗余需要不同策略，多轮对话和细节任务对 token 缩减敏感，而结合 token 和模型压缩效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现有 VLM 压缩方法存在三个主要局限性：(1) 缺乏可比的模块化，阻碍了对空间和时间冗余的公平评估；(2) 评估局限于简单的单轮任务，未能反映在现实场景中的性能；(3) 单独使用压缩技术，未能探索其联合潜力。

Method: LLMC+ 通过支持五种代表性的 VLM 家族中的 20 多种算法，并实现对 token 级和模型级压缩的系统研究，来克服现有 VLM 压缩方法的局限性。

Result: 基准测试表明：(1) 空间和时间冗余需要不同的技术策略；(2) 在多轮对话和细节敏感的任务中，token 缩减方法性能显著下降；(3) 结合 token 和模型压缩可以在最小的性能损失下实现极高的压缩率。

Conclusion: LLMC+ 是一个全面的 VLM 压缩基准，包含一个通用的、即插即用的工具包，可以促进公平评估并激发高效 VLM 的未来研究。

Abstract: Large Vision-Language Models (VLMs) exhibit impressive multi-modal
capabilities but suffer from prohibitive computational and memory demands, due
to their long visual token sequences and massive parameter sizes. To address
these issues, recent works have proposed training-free compression methods.
However, existing efforts often suffer from three major limitations: (1)
Current approaches do not decompose techniques into comparable modules,
hindering fair evaluation across spatial and temporal redundancy. (2)
Evaluation confined to simple single-turn tasks, failing to reflect performance
in realistic scenarios. (3) Isolated use of individual compression techniques,
without exploring their joint potential. To overcome these gaps, we introduce
LLMC+, a comprehensive VLM compression benchmark with a versatile,
plug-and-play toolkit. LLMC+ supports over 20 algorithms across five
representative VLM families and enables systematic study of token-level and
model-level compression. Our benchmark reveals that: (1) Spatial and temporal
redundancies demand distinct technical strategies. (2) Token reduction methods
degrade significantly in multi-turn dialogue and detail-sensitive tasks. (3)
Combining token and model compression achieves extreme compression with minimal
performance loss. We believe LLMC+ will facilitate fair evaluation and inspire
future research in efficient VLM. Our code is available at
https://github.com/ModelTC/LightCompress.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [123] [ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning](https://arxiv.org/abs/2508.09303)
*Shu Zhao,Tan Yu,Anbang Xu,Japinder Singh,Aaditya Shukla,Rama Akkiraju*

Main category: cs.CL

TL;DR: ParallelSearch框架通过并行处理搜索查询来提高LLM在信息检索任务中的效率和性能，解决了现有方法中的顺序瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的搜索代理（如Search-R1）在多步信息检索方面表现出色，但存在根本性的架构限制：它们以严格顺序的方式处理搜索查询，即使在处理可并行化和逻辑上独立的比较时也是如此。这种顺序瓶颈限制了计算效率，特别是对于需要多次实体比较的查询。

Method: 提出了一种名为ParallelSearch的新型强化学习框架，该框架使大型语言模型（LLM）能够识别可并行化的查询结构并同时执行多个搜索操作。该方法引入了专门的奖励函数，以激励识别独立的查询组件，并通过联合考虑正确性、查询分解质量和并行执行的好处来保持答案的准确性。

Result: ParallelSearch在七个问答基准测试中平均提高了2.9%的性能。在可并行化的问题上，该方法实现了12.7%的性能提升，同时仅使用顺序方法69.6%的LLM调用量。

Conclusion: 通过使LLM能够识别可并行化的查询结构并同时执行多个搜索操作，ParallelSearch在七个问答基准测试中平均提高了2.9%的性能，并在可并行化的问题上实现了12.7%的性能提升，同时将LLM调用量减少了30.4%。

Abstract: Reasoning-augmented search agents such as Search-R1, trained via
reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable
capabilities in multi-step information retrieval from external knowledge
sources. These agents address the limitations of their parametric memory by
dynamically gathering relevant facts to address complex reasoning tasks.
However, existing approaches suffer from a fundamental architectural
limitation: they process search queries strictly sequentially, even when
handling inherently parallelizable and logically independent comparisons. This
sequential bottleneck significantly constrains computational efficiency,
particularly for queries that require multiple entity comparisons. To address
this critical limitation, we propose ParallelSearch, a novel reinforcement
learning framework that empowers large language models (LLMs) to recognize
parallelizable query structures and execute multiple search operations
concurrently. Our approach introduces dedicated reward functions that
incentivize the identification of independent query components while preserving
answer accuracy through jointly considering correctness, query decomposition
quality, and parallel execution benefits. Comprehensive experiments demonstrate
that ParallelSearch outperforms state-of-the-art baselines by an average
performance gain of 2.9% across seven question-answering benchmarks. Notably,
on parallelizable questions, our method achieves a 12.7% performance
improvement while requiring only 69.6% of the LLM calls compared to sequential
approaches.

</details>


### [124] [Leveraging Large Language Models for Rare Disease Named Entity Recognition](https://arxiv.org/abs/2508.09323)
*Nan Miles Xi,Yu Deng,Lin Wang*

Main category: cs.CL

TL;DR: 本研究评估了GPT-4o在低资源罕见病NER任务中的表现，通过不同的提示策略（零样本、少样本、RAG、微调）和优化的示例选择方法，GPT-4o在RareDis语料库上达到了SOTA结果，证明了LLM在罕见病NER领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 罕见病领域的命名实体识别（NER）面临数据有限、实体类型间语义模糊和长尾分布等独特挑战。

Method: 研究评估了GPT-4o在低资源设置下的罕见病NER能力，采用了零样本提示、少样本上下文学习、检索增强生成（RAG）和任务级微调等多种提示策略。设计了一个包含领域知识和消歧规则的结构化提示框架，并提出了两种语义引导的少样本示例选择方法来提高上下文性能并减少标注成本。

Result: GPT-4o在RareDis语料库上的实验结果显示，其性能可与BioClinicalBERT媲美甚至更优，其中任务级微调达到了新的SOTA（state-of-the-art）结果。成本效益分析表明，在低Token预算下，少样本提示的效益较高，而RAG的附加效益不大。错误分类显示了常见的失败模式，如边界漂移和类型混淆，为后处理和混合优化提供了方向。

Conclusion: 在罕见病NER领域，提示优化的LLM（如GPT-4o）可以作为传统监督模型的有效、可扩展的替代方案，尤其适用于标注数据稀缺的罕见病应用。

Abstract: Named Entity Recognition (NER) in the rare disease domain poses unique
challenges due to limited labeled data, semantic ambiguity between entity
types, and long-tail distributions. In this study, we evaluate the capabilities
of GPT-4o for rare disease NER under low-resource settings, using a range of
prompt-based strategies including zero-shot prompting, few-shot in-context
learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We
design a structured prompting framework that encodes domain-specific knowledge
and disambiguation rules for four entity types. We further introduce two
semantically guided few-shot example selection methods to improve in-context
performance while reducing labeling effort. Experiments on the RareDis Corpus
show that GPT-4o achieves competitive or superior performance compared to
BioClinicalBERT, with task-level fine-tuning yielding new state-of-the-art
(SOTA) results. Cost-performance analysis reveals that few-shot prompting
delivers high returns at low token budgets, while RAG offers marginal
additional benefit. An error taxonomy highlights common failure modes such as
boundary drift and type confusion, suggesting opportunities for post-processing
and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can
serve as effective, scalable alternatives to traditional supervised models in
biomedical NER, particularly in rare disease applications where annotated data
is scarce.

</details>


### [125] [TEN: Table Explicitization, Neurosymbolically](https://arxiv.org/abs/2508.09324)
*Nikita Mehrotra,Aayush Kumar,Sumit Gulwani,Arjun Radhakrishna,Ashish Tiwari*

Main category: cs.CL

TL;DR: TEN is a neuro-symbolic method that uses LLMs and a symbolic checker in a self-debug loop to extract tabular data from messy text, outperforming purely neural methods and user-preferred.


<details>
  <summary>Details</summary>
Motivation: Extracting tabular data from semistructured input text is challenging, especially when delimiters are inconsistent. Purely neural approaches struggle with hallucinations and enforcing hard constraints.

Method: TEN uses Structural Decomposition prompting on an LLM to generate an initial table, followed by a symbolic checker to evaluate well-formedness and detect hallucinations/forgetting. The checker's output is used by a critique-LLM to generate guidance for fixing the table in a self-debug loop.

Result: TEN achieves significantly higher exact match accuracy and substantially reduced hallucination rates compared to purely neural baselines. User studies show TEN's tables are preferred for accuracy, ease of verification, and correction.

Conclusion: TEN significantly outperforms purely neural baselines across multiple datasets and metrics, achieving significantly higher exact match accuracy and substantially reduced hallucination rates. A user study confirms TEN's tables are rated significantly more accurate and consistently preferred for ease of verification and correction.

Abstract: We present a neurosymbolic approach, TEN, for extracting tabular data from
semistructured input text. This task is particularly challenging for text input
that does not use special delimiters consistently to separate columns and rows.
Purely neural approaches perform poorly due to hallucinations and their
inability to enforce hard constraints. TEN uses Structural Decomposition
prompting - a specialized chain-of-thought prompting approach - on a large
language model (LLM) to generate an initial table, and thereafter uses a
symbolic checker to evaluate not only the well-formedness of that table, but
also detect cases of hallucinations or forgetting. The output of the symbolic
checker is processed by a critique-LLM to generate guidance for fixing the
table, which is presented to the original LLM in a self-debug loop. Our
extensive experiments demonstrate that TEN significantly outperforms purely
neural baselines across multiple datasets and metrics, achieving significantly
higher exact match accuracy and substantially reduced hallucination rates. A
21-participant user study further confirms that TEN's tables are rated
significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are
consistently preferred for ease of verification and correction, with
participants favoring our method in over 60% of the cases.

</details>


### [126] [Decoding Neural Emotion Patterns through Natural Language Processing Embeddings](https://arxiv.org/abs/2508.09337)
*Gideon Vos,Maryam Ebrahimpour,Liza van Eijk,Zoltan Sarnyai,Mostafa Rahimi Azghadi*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Understanding how emotional expression in language relates to brain function
is a challenge in computational neuroscience and affective computing.
Traditional neuroimaging is costly and lab-bound, but abundant digital text
offers new avenues for emotion-brain mapping. Prior work has largely examined
neuroimaging-based emotion localization or computational text analysis
separately, with little integration. We propose a computational framework that
maps textual emotional content to anatomically defined brain regions without
requiring neuroimaging. Using OpenAI's text-embedding-ada-002, we generate
high-dimensional semantic representations, apply dimensionality reduction and
clustering to identify emotional groups, and map them to 18 brain regions
linked to emotional processing. Three experiments were conducted: i) analyzing
conversational data from healthy vs. depressed subjects (DIAC-WOZ dataset) to
compare mapping patterns, ii) applying the method to the GoEmotions dataset and
iii) comparing human-written text with large language model (LLM) responses to
assess differences in inferred brain activation. Emotional intensity was scored
via lexical analysis. Results showed neuroanatomically plausible mappings with
high spatial specificity. Depressed subjects exhibited greater limbic
engagement tied to negative affect. Discrete emotions were successfully
differentiated. LLM-generated text matched humans in basic emotion distribution
but lacked nuanced activation in empathy and self-referential regions (medial
prefrontal and posterior cingulate cortex). This cost-effective, scalable
approach enables large-scale analysis of naturalistic language, distinguishes
between clinical populations, and offers a brain-based benchmark for evaluating
AI emotional expression.

</details>


### [127] [The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains](https://arxiv.org/abs/2508.09349)
*Cathy Speed,Ahmed A. Metwally*

Main category: cs.CL

TL;DR: 本研究提出了一种新的人类-AI混合德尔菲（HAH-Delphi）框架，通过结合AI和少量专家，比传统方法更高效、更准确地达成共识，尤其是在信息复杂和碎片化的领域。


<details>
  <summary>Details</summary>
Motivation: 传统共识方法（如德尔菲研究、共识会议、系统性指南合成）面临诸多挑战，包括过高的专家负担、过度简化以及对条件性细微差别的压制。信息过载、证据基础碎片化以及对缺乏专家筛选的公开来源的依赖加剧了这些挑战。

Method: 本研究引入并评估了一个人类-AI混合德尔菲（HAH-Delphi）框架，该框架通过整合生成式AI模型（Gemini 2.5 Pro）、小型资深人类专家小组和结构化引导，来增强专家共识的制定。HAH-Delphi在三个阶段进行了测试：回顾性复制、前瞻性比较以及在两个实际领域（耐力训练和抗阻及混合有氧/力量训练）的应用部署。

Result: AI在第一阶段复制了95%已发布的专家共识结论，在第二阶段与资深人类专家表现出95%的方向性一致，但缺乏经验性和实用性方面的细微差别。在第三阶段，由六位资深专家组成的小型小组在最终参与者之前就达到了>90%的共识覆盖率和主题饱和度。AI提供了_一致的、以文献为基础的脚手架，支持了分歧的解决并加速了饱和。

Conclusion: HAH-Delphi框架提供了一种灵活、可扩展的方法，用于生成高质量、面向情境的共识。其在健康、教练和表现科学中的成功应用，证实了其方法学的稳健性，并支持其作为大规模生成条件性、个性化指导和已发布共识框架的基础。

Abstract: Expert consensus plays a critical role in domains where evidence is complex,
conflicting, or insufficient for direct prescription. Traditional methods, such
as Delphi studies, consensus conferences, and systematic guideline synthesis,
offer structure but face limitations including high panel burden, interpretive
oversimplification, and suppression of conditional nuance. These challenges are
now exacerbated by information overload, fragmentation of the evidence base,
and increasing reliance on publicly available sources that lack expert
filtering. This study introduces and evaluates a Human-AI Hybrid Delphi
(HAH-Delphi) framework designed to augment expert consensus development by
integrating a generative AI model (Gemini 2.5 Pro), small panels of senior
human experts, and structured facilitation. The HAH-Delphi was tested in three
phases: retrospective replication, prospective comparison, and applied
deployment in two applied domains (endurance training and resistance and mixed
cardio/strength training). The AI replicated 95% of published expert consensus
conclusions in Phase I and showed 95% directional agreement with senior human
experts in Phase II, though it lacked experiential and pragmatic nuance. In
Phase III, compact panels of six senior experts achieved >90% consensus
coverage and reached thematic saturation before the final participant. The AI
provided consistent, literature-grounded scaffolding that supported divergence
resolution and accelerated saturation. The HAH-Delphi framework offers a
flexible, scalable approach for generating high-quality, context-sensitive
consensus. Its successful application across health, coaching, and performance
science confirms its methodological robustness and supports its use as a
foundation for generating conditional, personalised guidance and published
consensus frameworks at scale.

</details>


### [128] [Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling](https://arxiv.org/abs/2508.09350)
*Ju-Chieh Chou,Jiawei Zhou,Karen Livescu*

Main category: cs.CL

TL;DR: 提出了一种新的无文本语音语言模型方法，该方法联合建模语言和声学信息，使用流匹配来生成语义令牌和连续声学表示，并在生成质量上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的无文本语音语言模型（SLMs）主要依赖文本监督，并且在生成语音时缺乏对声学信息的访问和内置控制。本研究旨在解决这一限制，通过联合建模语言和声学信息来改进SLMs。

Method: 本研究提出了一种联合建模语言和声学信息的方法，通过生成语义令牌和声学帧的连续实值表示。利用流匹配目标来预测以语义令牌为条件的连续向量。研究了该方法的设计空间，发现预测多个未来语义令牌有助于保留语言信息。

Result: 所提出的方法在语言似然基准测试中取得了与现有模型相当的性能，并在提示生成方面展现出更好的声学细节。

Conclusion: 所提出的方法通过联合建模语言和声学信息，在保持语言信息的同时，在提示生成方面提供了更好的声学细节，并且在语言似然基准测试中取得了与现有模型相当的性能。

Abstract: Textless spoken language models (SLMs) are generative models of speech that
do not rely on text supervision. Most textless SLMs learn to predict the next
semantic token, a discrete representation of linguistic content, and rely on a
separate vocoder to add acoustic information to the generated speech. Such
models have no access to acoustic context and no built-in control over acoustic
details. In this work, we propose to jointly model linguistic and acoustic
information by generating semantic tokens and a continuous real-valued
representation of the acoustic frame. We use a flow-matching objective to
predict the continuous vector conditioned on the semantic tokens. We study the
design space of this approach and find that predicting multiple future semantic
tokens helps preserve linguistic information. Our approach achieves comparable
performance to existing models in terms of linguistic likelihood benchmarks,
while providing better acoustic detail in prompted generation.

</details>


### [129] [APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification](https://arxiv.org/abs/2508.09378)
*Artem Chernodub,Aman Saini,Yejin Huh,Vivek Kulkarni,Vipul Raheja*

Main category: cs.CL

TL;DR: 提出APIO方法，用于语法纠错和文本简化任务，无需手动指定种子提示，实现了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: LLM在NLP任务中的应用越来越广泛，需要工程化提示以最有效地引导LLM执行特定任务。

Method: APIO是一种提示归纳和优化方法，不依赖手动指定的种子提示。

Result: APIO在语法纠错和文本简化任务上取得了新的最先进性能，并且数据、代码、提示和输出均公开可用。

Conclusion: APIO在语法纠错和文本简化任务上实现了新的最先进性能，它是一种仅基于LLM的提示方法。

Abstract: Recent advancements in large language models (LLMs) have enabled a wide range
of natural language processing (NLP) tasks to be performed through simple
prompt-based interactions. Consequently, several approaches have been proposed
to engineer prompts that most effectively enable LLMs to perform a given task
(e.g., chain-of-thought prompting). In settings with a well-defined metric to
optimize model performance, automatic prompt optimization (APO) methods have
been developed to refine a seed prompt. Advancing this line of research, we
propose APIO, a simple but effective prompt induction and optimization approach
for the tasks of Grammatical Error Correction (GEC) and Text Simplification,
without relying on manually specified seed prompts. APIO achieves a new
state-of-the-art performance for purely LLM-based prompting methods on these
tasks. We make our data, code, prompts, and outputs publicly available.

</details>


### [130] [Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models](https://arxiv.org/abs/2508.09403)
*Ting Cai,Stephen Sheen,AnHai Doan*

Main category: cs.CL

TL;DR: Columbo是一种先进的基于LLM的解决方案，可以准确地展开缩写列名，并且在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决企业、领域科学、政府机构等领域中展开缩写列名（例如，将“esal”展开为“employee salary”）的挑战。

Method: 提出了一种名为Columbo的基于LLM的解决方案，该方案利用上下文、规则、链式思考推理和令牌级分析。

Result: Columbo在5个数据集上显著优于NameGuess，准确率提高了4-29%。

Conclusion: Columbo在5个数据集上显著优于NameGuess，准确率提高了4-29%，并且已在EDI上投入生产使用。

Abstract: Expanding the abbreviated column names of tables, such as ``esal'' to
``employee salary'', is critical for numerous downstream data tasks. This
problem arises in enterprises, domain sciences, government agencies, and more.
In this paper we make three contributions that significantly advances the state
of the art. First, we show that synthetic public data used by prior work has
major limitations, and we introduce 4 new datasets in enterprise/science
domains, with real-world abbreviations. Second, we show that accuracy measures
used by prior work seriously undercount correct expansions, and we propose new
synonym-aware measures that capture accuracy much more accurately. Finally, we
develop Columbo, a powerful LLM-based solution that exploits context, rules,
chain-of-thought reasoning, and token-level analysis. Extensive experiments
show that Columbo significantly outperforms NameGuess, the current most
advanced solution, by 4-29\%, over 5 datasets. Columbo has been used in
production on EDI, a major data portal for environmental sciences.

</details>


### [131] [Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech](https://arxiv.org/abs/2508.09430)
*Lavanya Shankar,Leibny Paola Garcia Perera*

Main category: cs.CL

TL;DR: Zipformer 模型在处理包含两种不平衡语言（普通话和英语）的儿童语音时，通过提取内部层特征进行语言识别，相比基线模型有显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决双语环境中儿童定向语音的语码转换和语言识别的挑战，特别是处理包含两种语言且数据不平衡的语音。

Method: 使用 Zipformer 模型处理包含普通话和英语两种语言且数据不平衡的语音，并通过选择内部层来提取嵌入（embeddings），并与不同的后端进行比较。

Result: Zipformer 的内部层能有效编码语言特征，并可用于语言识别。该模型在不同后端表现稳健，并有效处理了数据不平衡问题，实现了 81.89% 的平衡准确率，比基线模型提高了 15.47%。

Conclusion: Zipformer 是一种强大的模型，能够有效处理包含两种语言（普通话和英语）且数据不平衡的语音，在语言识别方面取得了显著的性能提升，平衡准确率（BAC）达到 81.89%，比基线模型高出 15.47%。

Abstract: Code-switching and language identification in child-directed scenarios
present significant challenges, particularly in bilingual environments. This
paper addresses this challenge by using Zipformer to handle the nuances of
speech, which contains two imbalanced languages, Mandarin and English, in an
utterance. This work demonstrates that the internal layers of the Zipformer
effectively encode the language characteristics, which can be leveraged in
language identification. We present the selection methodology of the inner
layers to extract the embeddings and make a comparison with different
back-ends. Our analysis shows that Zipformer is robust across these backends.
Our approach effectively handles imbalanced data, achieving a Balanced Accuracy
(BAC) of 81.89%, a 15.47% improvement over the language identification
baseline. These findings highlight the potential of the transformer encoder
architecture model in real scenarios.

</details>


### [132] [From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text](https://arxiv.org/abs/2508.09450)
*Ridwan Mahbub,Mohammed Saidul Islam,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Mizanur Rahman,Shafiq Joty,Enamul Hoque*

Main category: cs.CL

TL;DR: 视觉语言模型在总结图表时存在地缘经济偏见，倾向于对富裕国家给出更积极的评价。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLM）在图表到文本生成任务中取得进展，研究这些模型可能存在的偏见，特别是地缘经济偏见，以及这种偏见可能造成的社会危害。

Method: 通过对来自六个广泛使用的专有和开源模型（涉及6000个图表-国家对）进行大规模评估，研究VLM生成的图表摘要中的地缘经济偏见，重点关注国家经济状况如何影响生成摘要的情感。

Result: 研究发现，VLM倾向于为高收入国家生成比中低收入国家更积极的摘要，即使唯一的变化是国家归属。GPT-4o-mini、Gemini-1.5-Flash和Phi-3.5等模型表现出不同程度的偏见。

Conclusion: 现有的视觉语言模型（VLM）在生成图表摘要时，会放大地缘经济偏见，对高收入国家比对中低收入国家产生更积极的描述，即使其他所有变量都相同。为减少这种偏见而设计的提示工程技术只在一定程度上有效，这表明需要更强大的去偏见策略。

Abstract: Charts are very common for exploring data and communicating insights, but
extracting key takeaways from charts and articulating them in natural language
can be challenging. The chart-to-text task aims to automate this process by
generating textual summaries of charts. While with the rapid advancement of
large Vision-Language Models (VLMs), we have witnessed great progress in this
domain, little to no attention has been given to potential biases in their
outputs. This paper investigates how VLMs can amplify geo-economic biases when
generating chart summaries, potentially causing societal harm. Specifically, we
conduct a large-scale evaluation of geo-economic biases in VLM-generated chart
summaries across 6,000 chart-country pairs from six widely used proprietary and
open-source models to understand how a country's economic status influences the
sentiment of generated summaries. Our analysis reveals that existing VLMs tend
to produce more positive descriptions for high-income countries compared to
middle- or low-income countries, even when country attribution is the only
variable changed. We also find that models such as GPT-4o-mini,
Gemini-1.5-Flash, and Phi-3.5 exhibit varying degrees of bias. We further
explore inference-time prompt-based debiasing techniques using positive
distractors but find them only partially effective, underscoring the complexity
of the issue and the need for more robust debiasing strategies. Our code and
dataset are publicly available here.

</details>


### [133] [User-centric Subjective Leaderboard by Customizable Reward Modeling](https://arxiv.org/abs/2508.09463)
*Qi Jia,Xiujie Song,Zicheng Zhang,Yijin Guo,Kaiwei Zhang,Zijian Chen,Guangtao Zhai*

Main category: cs.CL

TL;DR: USL是一个新的人类偏好驱动的LLM排名，CRM模型超越了GPT-4.1和Gemini-2.5-pro。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基准主要关注可验证的任务，但这种客观和静态的基准在为用户提供实用的模型选择方面作用有限，使得用户难以找到满足其个性化需求的模型。

Method: 提出了一种名为可定制奖励模型（CRM）的新方法，该模型参数量仅为4B，但在跨新主题和标准的泛化能力方面超越了GPT-4.1和Gemini-2.5-pro等领先模型。USL由CRM提供支持。

Result: 我们构建了第一个以用户为中心的主观排行榜（USL），它提供了一个由偏好驱动的、动态的LLM排名，涵盖了多样化的真实世界场景。该排行榜基于对超过10K个主观查询的人类偏好数据的深入研究。

Conclusion: LLM的USL排名与矛盾偏好具有很强的负相关性，表明我们的方法能够有效处理主观性。

Abstract: Existing benchmarks for large language models (LLMs) predominantely focus on
assessing their capabilities through verifiable tasks. Such objective and
static benchmarks offer limited utility for practical LLM selection, making it
difficult for users to find suitable models for their individual needs. To
bridge this gap, we present the first User-Centric Subjective Leaderboard
(USL), which provides a preference-driven, dynamic ranking of LLMs across
diverse real-world scenarios. Our work is built upon a thorough investigation
of real human preference data, involving more than 10K subjective queries. Our
investigation reveals significant diversity and contradictions in human
preferences, which limit the effectiveness of state-of-the-art reward models.
To address this, we introduce Customizable Reward Models (CRMs). With only 4B
parameters, our CRM surpasses the performance of leading models such as GPT-4.1
and Gemini-2.5-pro, showing exceptional generalization capabilities across new
topics and criteria. The USL, powered by CRMs, exhibits strong negative
correlations to contradictory preferences.

</details>


### [134] [Learning Facts at Scale with Active Reading](https://arxiv.org/abs/2508.09494)
*Jessy Lin,Vincent-Pierre Berges,Xilun Chen,Wen-Tau Yih,Gargi Ghosh,Barlas Oğuz*

Main category: cs.CL

TL;DR: 通过“主动阅读”框架，LLM 能像学生一样自主学习，显著提升在特定领域（如百科、金融）的知识掌握能力和事实问答表现，即使是较小模型也能超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）虽然参数记忆量巨大，但在学习和回忆事实方面存在不可靠性，并且影响因素尚不明确。用户缺乏工具来确保模型能够可靠、一致地学习特定知识体。因此，需要一种新的方法来提高 LLM 的知识学习能力。

Method: 我们提出了一种名为“主动阅读”的框架，该框架训练模型通过生成自我学习策略来学习指定的材料。具体而言，模型会主动研究给定的文本材料，并生成学习策略以提高知识吸收效率。

Result: 在 SimpleQA（Wikipedia）子集上，应用主动阅读的 8B 模型达到了 66% 的准确率，相比传统微调提升了 313%。在 FinanceBench 上，准确率达到 26%，相比传统微调提升了 160%。此外，在预训练规模上，通过主动阅读训练的 Meta WikiExpert-8B 模型在事实问答方面超越了参数量更大的模型。

Conclusion: LLM 在预训练阶段通过主动阅读框架的学习，能够显著提高其在特定领域知识的吸收和记忆能力。通过主动阅读训练的模型在 SimpleQA 和 FinanceBench 等基准测试中表现出远超传统微调的性能，并且能够扩展到预训练规模，构建更具事实性的模型。

Abstract: LLMs are known to store vast amounts of knowledge in their parametric memory.
However, learning and recalling facts from this memory is known to be
unreliable, depending largely on the prevalence of particular facts in the
training data and other factors which are poorly understood. Practitioners are
lacking tools which will allow them to ensure that the models learn a given
body of knowledge reliably and consistently. To this end, we propose Active
Reading: a framework where we train models to study a given set of material
with self-generated learning strategies. First, we demonstrate models trained
with Active Reading on expert domains absorb significantly more knowledge than
vanilla finetuning and other data augmentations. We train expert 8B models that
achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over
vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla
finetuning) by applying Active Reading to the source documents for each
benchmark. Finally, we show that Active Reading can be utilized at pre-training
scale to build more factual models. As a demonstration of this, we release Meta
WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens,
which outcompetes models with hundreds of billions of parameters on factual QA.

</details>


### [135] [From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation](https://arxiv.org/abs/2508.09497)
*Siyuan Meng,Junming Liu,Yirong Chen,Song Mao,Pinlong Cai,Guohang Yan,Botian Shi,Ding Wang*

Main category: cs.CL

TL;DR: DPS是一个新的重排框架，可以动态地选择最相关的信息片段，从而提高RAG系统的性能，尤其是在处理复杂的多跳查询时。


<details>
  <summary>Details</summary>
Motivation: 传统的重排模块在处理需要综合多文档证据的复杂多跳查询时存在局限性，因为它们独立评估信息片段并选择固定数量的片段，这可能导致遗漏关键信息或引入噪声。

Method: DPS将信息检索中的重排问题视为一个监督学习问题，通过捕捉信息片段间的依赖关系，动态选择最相关的信息片段用于生成。它是一个即插即用的模块，无需修改标准的检索增强生成（RAG）流程。

Result: DPS在五个基准测试中持续优于最先进的重排器和微调方法，在MuSiQue数据集上，F1分数分别比Qwen3-reranker和RankingGPT等强基线提高了30.06%和15.4%。

Conclusion: DPS通过实现自适应证据选择，显著增强了复杂RAG场景下的推理能力，并在五个基准测试中持续优于最先进的重排器和微调方法，尤其是在MuSiQue数据集上，F1分数分别比Qwen3-reranker和RankingGPT等强基线提高了30.06%和15.4%。

Abstract: Retrieval-augmented generation (RAG) systems are often bottlenecked by their
reranking modules, which typically score passages independently and select a
fixed Top-K size. This approach struggles with complex multi-hop queries that
require synthesizing evidence across multiple documents, creating a trade-off
where small K values omit crucial information and large K values introduce
noise. To address this, we introduce the Dynamic Passage Selector (DPS), a
novel reranking framework that treats passage selection as a supervised
learning problem. Unlike traditional point-wise or list-wise methods, DPS is
fine-tuned to capture inter-passage dependencies and dynamically select the
most relevant set of passages for generation. As a seamless plug-and-play
module, DPS requires no modifications to the standard RAG pipeline.
Comprehensive evaluations on five benchmarks show that DPS consistently
outperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the
challenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over
strong baselines like Qwen3-reranker and RankingGPT, respectively. Our results
demonstrate that by enabling adaptive evidence selection, DPS substantially
enhances reasoning capabilities in complex RAG scenarios.

</details>


### [136] [LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation](https://arxiv.org/abs/2508.09515)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: A new method uses LLMs to create training data for cross-lingual sentiment analysis without translation, improving accuracy and outperforming older methods.


<details>
  <summary>Details</summary>
Motivation: Most existing cross-lingual ABSA methods rely on potentially unreliable translation tools to bridge the language gap. This paper proposes a new approach to overcome this limitation by leveraging LLMs to generate high-quality pseudo-labelled data in the target language.

Method: The framework first trains an ABSA model on unlabelled target language data to obtain predictions. Then, an LLM is prompted to generate natural sentences that represent these predictions. Finally, the ABSA model is fine-tuned on this pseudo-labelled dataset.

Result: The method was demonstrated to be effective across six languages and five backbone models, surpassing previous state-of-the-art translation-based approaches. Fine-tuned LLMs also outperformed smaller multilingual models in supporting generative models.

Conclusion: The proposed LLM-based approach for cross-lingual ABSA effectively generates high-quality pseudo-labeled data in the target language without relying on translation tools, outperforming existing translation-based methods across multiple languages and backbone models. It also supports generative models, with fine-tuned LLMs showing superior performance compared to smaller multilingual models.

Abstract: Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed
sentiment analysis in a target language by transferring knowledge from a source
language with available annotated data. Most existing methods depend heavily on
often unreliable translation tools to bridge the language gap. In this paper,
we propose a new approach that leverages a large language model (LLM) to
generate high-quality pseudo-labelled data in the target language without the
need for translation tools. First, the framework trains an ABSA model to obtain
predictions for unlabelled target language data. Next, LLM is prompted to
generate natural sentences that better represent these noisy predictions than
the original text. The ABSA model is then further fine-tuned on the resulting
pseudo-labelled dataset. We demonstrate the effectiveness of this method across
six languages and five backbone models, surpassing previous state-of-the-art
translation-based approaches. The proposed framework also supports generative
models, and we show that fine-tuned LLMs outperform smaller multilingual
models.

</details>


### [137] [Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges](https://arxiv.org/abs/2508.09516)
*Jakub Šmíd,Pavel Král*

Main category: cs.CL

TL;DR: This paper surveys the field of cross-lingual Aspect-based sentiment analysis (ABSA), covering its tasks, datasets, methods, and contributions from related areas. It identifies challenges and suggests future research directions for this under-explored field.


<details>
  <summary>Details</summary>
Motivation: While Aspect-based sentiment analysis (ABSA) has seen significant progress, much of the focus has been on monolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from resource-rich languages to low-resource languages, remains an under-explored area with no systematic review. This paper aims to fill that gap by providing a comprehensive survey of the field.

Method: This paper provides a comprehensive survey of cross-lingual ABSA by summarizing key tasks (aspect term extraction, aspect sentiment classification, and compound tasks), datasets, modeling paradigms, and cross-lingual transfer methods. It also reviews the contributions of monolingual and multilingual ABSA, as well as ABSA with LLMs, to the field. The paper concludes by highlighting challenges and suggesting future research directions.

Result: The paper summarizes key ABSA tasks, datasets, modeling paradigms, and cross-lingual transfer methods used in cross-lingual ABSA. It also examines the contributions of monolingual and multilingual ABSA, as well as ABSA with LLMs, to the development of cross-lingual ABSA. Finally, it highlights the main challenges and suggests directions for future research.

Conclusion: Cross-lingual ABSA is an under-explored area with significant potential for future research. This paper provides a comprehensive survey of the field, summarizing key tasks, datasets, modeling paradigms, and cross-lingual transfer methods. It also examines the contributions of monolingual and multilingual ABSA, as well as ABSA with LLMs, to the development of cross-lingual ABSA. The paper concludes by highlighting challenges and suggesting future research directions.

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that focuses on understanding opinions at the aspect level, including
sentiment towards specific aspect terms, categories, and opinions. While ABSA
research has seen significant progress, much of the focus has been on
monolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from
resource-rich languages (such as English) to low-resource languages, remains an
under-explored area, with no systematic review of the field. This paper aims to
fill that gap by providing a comprehensive survey of cross-lingual ABSA. We
summarize key ABSA tasks, including aspect term extraction, aspect sentiment
classification, and compound tasks involving multiple sentiment elements.
Additionally, we review the datasets, modelling paradigms, and cross-lingual
transfer methods used to solve these tasks. We also examine how existing work
in monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to
the development of cross-lingual ABSA. Finally, we highlight the main
challenges and suggest directions for future research to advance cross-lingual
ABSA systems.

</details>


### [138] [UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval](https://arxiv.org/abs/2508.09517)
*Ladislav Lenc,Daniel Cífka,Jiří Martínek,Jakub Šmíd,Pavel Král*

Main category: cs.CL

TL;DR: 本研究提出了一种零样本事实核查声明检索系统，使用LLM生成嵌入并计算相似度，在单语和跨语言任务中均取得优异成绩，其中NV-Embed-v2模型表现突出。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一个零样本系统，用于从大量文本中检索需要事实核查的声明，以提高信息准确性。

Method: 本研究采用多种先进的大型语言模型（LLM）来生成文本嵌入，并结合了这些模型以优化检索性能。通过计算余弦相似度来识别与帖子最相关的声明。研究中还探讨了使用英语翻译作为输入以及模型组合（如NV-Embed & GPT或Mistral）对不同语言效果的影响。

Result: 该系统在单语子任务中排名第七，在跨语言子任务中排名第九。研究发现，NVIDIA NV-Embed-v2模型在大多数情况下表现最佳，而模型组合策略在某些语言上能带来进一步的性能提升。

Conclusion: 该研究成功展示了一个用于事实核查声明检索的零样本系统，并在单语和跨语言子任务中取得了有竞争力的成绩。

Abstract: This paper presents a zero-shot system for fact-checked claim retrieval. We
employed several state-of-the-art large language models to obtain text
embeddings. The models were then combined to obtain the best possible result.
Our approach achieved 7th place in monolingual and 9th in cross-lingual
subtasks. We used only English translations as an input to the text embedding
models since multilingual models did not achieve satisfactory results. We
identified the most relevant claims for each post by leveraging the embeddings
and measuring cosine similarity. Overall, the best results were obtained by the
NVIDIA NV-Embed-v2 model. For some languages, we benefited from model
combinations (NV-Embed & GPT or Mistral).

</details>


### [139] [COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation](https://arxiv.org/abs/2508.09521)
*Yunxiao Wang,Meng Liu,Wenqi Liu,Kaiyu Jiang,Bin Wen,Fan Yang,Tingting Gao,Guorui Zhou,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出可控共情推理，结合心理学和自然语言处理，并通过数据集、强化学习和避免重复的技术来提升情感支持对话的质量。


<details>
  <summary>Details</summary>
Motivation: 情感支持对话对于促进情感健康至关重要，但当前模型往往缺乏基于心理学原理的深度共情推理。

Method: 本文提出可控共情推理，结合了自然语言推理和结构化心理学步骤。我们构建了一个带有推理正确性和响应偏好的细粒度数据集来实现这一功能。为了进一步加强训练，我们采用了具有统一的过程-结果奖励模型的强化学习，该模型可提供精确的反馈。为了缓解由熵崩溃引起的响应重复问题，我们引入了基于个性的对话重写和冗余感知奖励重新加权策略。

Result: 我们的方法显著提高了模型的情感支持能力。

Conclusion: 该方法显著提高了模型提供情感支持的能力，推动了富有同情心、类似人类的支持系统的发展。

Abstract: Emotional support conversations are crucial for promoting emotional
well-being, yet current models often lack deep empathetic reasoning grounded in
psychological principles. To address this, we propose controllable empathetic
reasoning, which combines natural language reasoning with structured
psychological steps. We construct a fine-grained dataset annotated with
reasoning correctness and response preferences to enable this capability. To
further enhance training, we employ reinforcement learning with a unified
process-outcome reward model that delivers precise feedback. To mitigate
response repetitiveness from entropy collapse, we introduce personality-based
dialogue rewriting and a redundancy-aware reward reweighting strategy. Our
approach significantly improves model's emotional support ability, advancing
the development of empathetic, human-like support systems.

</details>


### [140] [The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage](https://arxiv.org/abs/2508.09603)
*Skyler Hallinan,Jaehun Jung,Melanie Sclar,Ximing Lu,Abhilasha Ravichander,Sahana Ramnath,Yejin Choi,Sai Praneeth Karimireddy,Niloofar Mireshghallah,Xiang Ren*

Main category: cs.CL

TL;DR: 提出一种名为N-Gram覆盖攻击的新型成员推理攻击方法，仅需模型文本输出即可攻击黑盒模型，效果优于其他黑盒方法，并与白盒方法相当，且攻击成功率随计算量增加而提升。最新模型如GPT-4o在隐私保护方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有成员推理攻击方法需要访问模型的隐藏状态或概率分布，限制了其在GPT-4等仅通过API访问的模型上的应用。本研究旨在开发一种仅依赖文本输出来进行成员推理的攻击方法。

Method: N-Gram覆盖攻击通过获取多个模型生成文本，并利用N-Gram重叠度量来计算生成文本与真实后缀的相似度，从而判断候选成员的归属。

Result: N-Gram覆盖攻击在现有基准测试中优于其他黑盒方法，并能与白盒攻击相媲美，甚至在某些情况下表现更优。研究还发现，攻击成功率随计算预算的增加而提高，且GPT-4o等更新的模型在成员推理方面具有更强的鲁棒性。

Conclusion: 该研究提出的N-Gram覆盖攻击能够有效识别API访问模型中的成员身份，并且在与白盒攻击的比较中表现出竞争力，表明该方法在完全黑盒的环境下依然有效。

Abstract: Membership inference attacks serves as useful tool for fair use of language
models, such as detecting potential copyright infringement and auditing data
leakage. However, many current state-of-the-art attacks require access to
models' hidden states or probability distribution, which prevents investigation
into more widely-used, API-access only models like GPT-4. In this work, we
introduce N-Gram Coverage Attack, a membership inference attack that relies
solely on text outputs from the target model, enabling attacks on completely
black-box models. We leverage the observation that models are more likely to
memorize and subsequently generate text patterns that were commonly observed in
their training data. Specifically, to make a prediction on a candidate member,
N-Gram Coverage Attack first obtains multiple model generations conditioned on
a prefix of the candidate. It then uses n-gram overlap metrics to compute and
aggregate the similarities of these outputs with the ground truth suffix; high
similarities indicate likely membership. We first demonstrate on a diverse set
of existing benchmarks that N-Gram Coverage Attack outperforms other black-box
methods while also impressively achieving comparable or even better performance
to state-of-the-art white-box attacks - despite having access to only text
outputs. Interestingly, we find that the success rate of our method scales with
the attack compute budget - as we increase the number of sequences generated
from the target model conditioned on the prefix, attack performance tends to
improve. Having verified the accuracy of our method, we use it to investigate
previously unstudied closed OpenAI models on multiple domains. We find that
more recent models, such as GPT-4o, exhibit increased robustness to membership
inference, suggesting an evolving trend toward improved privacy protections.

</details>


### [141] [AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian](https://arxiv.org/abs/2508.09622)
*Tatiana Batura,Elena Bruches,Milana Shvenk,Valentin Malykh*

Main category: cs.CL

TL;DR: 本研究介绍了AINL-Eval 2025共享任务，旨在检测俄语AI生成的科学摘要。研究发布了一个包含52,305个样本的大型数据集，并挑战参与者开发能够处理新领域和新模型的检测方法。顶级系统表现出色，该任务旨在推动AI生成内容检测领域的研究。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在文本生成方面取得的快速进展，区分人类和AI生成的内容变得越来越困难，这对学术诚信构成了重大挑战，尤其是在科学出版和多语言背景下。为了解决这一关键问题，本研究专注于检测俄语AI生成的科学摘要。

Method: 提出了一种新颖的大型数据集，包含52,305个样本，涵盖12个科学领域的真人撰写摘要和5种先进大型语言模型生成的摘要。任务分为两个阶段，吸引了10支队伍和159个提交，旨在挑战参与者开发能够泛化到未见过科学领域和未包含在训练数据中的模型的解决方案。

Result: 10支队伍参加了该任务，提交了159个系统，顶级系统在识别AI生成内容方面表现出强大的性能。同时，研究还建立了一个持续的共享任务平台，以促进该领域的研究和长期进展。

Conclusion: 该研究介绍了AINL-Eval 2025共享任务，专注于检测俄语AI生成的科学摘要，并发布了一个包含52,305个样本的大型数据集，涵盖12个科学领域和5种先进的大语言模型。该任务旨在挑战参与者开发能够泛化到未见过领域和模型的鲁棒解决方案。最终，10支队伍提交了159个系统，表现出在识别AI生成内容方面的强大能力。研究还建立了一个持续的共享任务平台以促进未来研究。

Abstract: The rapid advancement of large language models (LLMs) has revolutionized text
generation, making it increasingly difficult to distinguish between human- and
AI-generated content. This poses a significant challenge to academic integrity,
particularly in scientific publishing and multilingual contexts where detection
resources are often limited. To address this critical gap, we introduce the
AINL-Eval 2025 Shared Task, specifically focused on the detection of
AI-generated scientific abstracts in Russian. We present a novel, large-scale
dataset comprising 52,305 samples, including human-written abstracts across 12
diverse scientific domains and AI-generated counterparts from five
state-of-the-art LLMs (GPT-4-Turbo, Gemma2-27B, Llama3.3-70B, Deepseek-V3, and
GigaChat-Lite). A core objective of the task is to challenge participants to
develop robust solutions capable of generalizing to both (i) previously unseen
scientific domains and (ii) models not included in the training data. The task
was organized in two phases, attracting 10 teams and 159 submissions, with top
systems demonstrating strong performance in identifying AI-generated content.
We also establish a continuous shared task platform to foster ongoing research
and long-term progress in this important area. The dataset and platform are
publicly available at https://github.com/iis-research-team/AINL-Eval-2025.

</details>


### [142] [Improving Diversity in Language Models: When Temperature Fails, Change the Loss](https://arxiv.org/abs/2508.09654)
*Alexandre Verine,Florian Le Bronnec,Kunhao Zheng,Alexandre Allauzen,Yann Chevaleyre,Benjamin Negrevergne*

Main category: cs.CL

TL;DR: 为了提高语言模型的多样性，研究发现提高解码温度效果有限。该研究提出了一种新的损失函数设计，利用精确率-召回率框架，能在提高多样性的同时更好地平衡精确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 提高语言模型的多样性是一个重要但充满挑战的目标。提高解码温度是一种常用方法，但其效果不佳，特别是未能有效提升覆盖率。

Method: 通过分析模型在不同温度设置下的表现，揭示了模型需要为了覆盖率而训练，才能有效利用温度调整。在此基础上，提出了利用精确率-召回率框架来改进损失函数。

Result: 所提出的方法在精确率和召回率之间取得了比现有方法更好的权衡，为实现更通用、更鲁棒的语言建模技术提供了方向。

Conclusion: 该研究提出了利用精确率-召回率框架来重新思考语言模型的损失函数，以在精确率和召回率之间取得比单纯结合负对数似然训练和温度缩放更好的权衡。

Abstract: Increasing diversity in language models is a challenging yet essential
objective. A common approach is to raise the decoding temperature. In this
work, we investigate this approach through a simplistic yet common case to
provide insights into why decreasing temperature can improve quality
(Precision), while increasing it often fails to boost coverage (Recall). Our
analysis reveals that for a model to be effectively tunable through temperature
adjustments, it must be trained toward coverage. To address this, we propose
rethinking loss functions in language models by leveraging the Precision-Recall
framework. Our results demonstrate that this approach achieves a substantially
better trade-off between Precision and Recall than merely combining negative
log-likelihood training with temperature scaling. These findings offer a
pathway toward more versatile and robust language modeling techniques.

</details>


### [143] [EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization](https://arxiv.org/abs/2508.09662)
*Yaoning Wang,Jiahao Ying,Yixin Cao,Yubo Ma,Yugang Jiang*

Main category: cs.CL

TL;DR: EffiEval是一种无需训练的方法，可以高效地进行基准测试，解决数据冗余问题，同时保持高评估可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM的快速发展和评估基准的扩大带来了模型评估的巨大计算挑战。

Method: EffiEval通过自适应地选择基于模型效用指数（MUI）的高质量代表性子集来解决数据冗余问题，同时保持高评估可靠性。

Result: 实验证明，EffiEval仅使用一小部分原始数据即可在多个公共基准和各种LLM上实现与完整数据集评估相当的排名一致性。

Conclusion: EffiEval是一个实用的、可推广的解决方案，可在LLM时代实现可靠、公平和高效的评估。

Abstract: The rapid advancement of large language models (LLMs) and the development of
increasingly large and diverse evaluation benchmarks have introduced
substantial computational challenges for model assessment. In this paper, we
present EffiEval, a training-free approach for efficient benchmarking that
effectively addresses data redundancy while maintaining high evaluation
reliability. Our method is specifically designed to meet three key criteria for
high-quality evaluation: representativeness, by ensuring comprehensive coverage
of model capabilities; fairness, by remaining independent of model performance
during sample selection to avoid bias; and generalizability, by enabling
flexible transfer across datasets and model families without reliance on
large-scale evaluation data. Unlike traditional methods that rely on absolute
performance or require extensive evaluation data, our approach adaptively
selects high-quality representative subsets based on the Model Utility Index
(MUI). Extensive experiments on multiple public benchmarks and diverse LLMs
demonstrate that EffiEval achieves strong ranking consistency with full-dataset
evaluation using only a small fraction of the original data. Furthermore, our
method is flexible and scalable in size, allowing users to balance evaluation
efficiency and representativeness according to specific needs. Overall,
EffiEval provides a practical and generalizable solution for reliable, fair,
and efficient evaluation in the era of LLMs.

</details>


### [144] [Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation](https://arxiv.org/abs/2508.09666)
*Ziyang Ma,Qingyue Yuan,Linhai Zhang,Deyu Zhou*

Main category: cs.CL

TL;DR: 本研究提出SLowED安全蒸馏方法，通过慢速调整和低熵掩码技术，在提升小型语言模型推理能力的同时，有效保持其安全性，克服了现有方法可能带来的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在进行思维链（CoT）蒸馏以增强小型语言模型（SLM）的推理能力时，可能对SLM安全性产生的负面影响。现有方法虽然有提高安全性的尝试，但需要额外的计算或标注数据，并且可能影响SLM的推理能力。因此，研究的动机是如何在CoT蒸馏过程中维持SLM的安全性。

Method: 本研究提出了一种名为SLowED（Slow Tuning and Low-Entropy Masking Distillation）的安全蒸馏方法，包含两个模块：慢速调整（Slow Tuning）和低熵掩码（Low-Entropy Masking）。慢速调整通过缩小模型权重变化的幅度来优化模型权重，使其位于初始权重分布的邻近空间。低熵掩码则屏蔽低熵标记（被认为是学习中的不必要目标），将其排除在微调之外。

Result: 实验在Qwen2.5-1.5B、Llama-3.2-1B和BLOOM-1.1B这三个SLM上进行，涵盖了推理基准（BBH、BB-Sub、ARC、AGIEval）和安全评估（AdvBench）。结果表明，SLowED方法能保持SLM的安全性，并与之现有的蒸馏方法相比，能相当地提高其推理能力。此外，消融研究证明了慢速调整和低熵掩码的有效性，其中慢速调整在早期阶段维持了模型的安全性，而低熵掩码则延长了安全训练的周期。

Conclusion: SLowED方法在保持SLM安全性的同时，能够与现有蒸馏方法相比，相当地提高其推理能力。

Abstract: Previous chain-of-thought (CoT) distillation methods primarily focused on
enhancing the reasoning capabilities of Small Language Models (SLMs) by
utilizing high-quality rationales generated by powerful Large Language Models
(LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM
safety brought by the training, which are revealed in this study. Although
there are works on safety alignment that fine-tune language models or
manipulate model weights to defend against harmful inputs, they require extra
computation or annotated data, and probably impact the reasoning ability of
SLMs. In this paper, we investigate how to maintain the safety of SLMs during
the CoT distillation process. Specifically, we propose a safe distillation
method, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing
two modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the
magnitude of model weight changes to optimize the model weights in the
neighboring space near the initial weight distribution. Low-Entropy Masking
masks low-entropy tokens, which are regarded as unnecessary learning targets,
to exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B,
Llama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC,
AGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety
of SLMs and comparably improves their reasoning capability compared to existing
distillation methods. Furthermore, our ablation study presents the
effectiveness of Slow Tuning and Low-Entropy Masking, with the former
maintaining the model's safety in the early stage and the latter prolonging the
safe training epochs.

</details>


### [145] [Evaluating the Role of Large Language Models in Legal Practice in India](https://arxiv.org/abs/2508.09713)
*Rahul Hemrajani*

Main category: cs.CL

TL;DR: LLMs show promise in legal drafting and issue spotting but struggle with specialized research due to hallucinations; human expertise remains crucial for legal accuracy and reasoning.


<details>
  <summary>Details</summary>
Motivation: To empirically evaluate how well LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian context, including issue spotting, legal drafting, advice, research, and reasoning.

Method: Through a survey experiment, LLM outputs are compared with those of a junior lawyer, with advanced law students rating the work on helpfulness, accuracy, and comprehensiveness.

Result: LLMs excel in drafting and issue spotting, often matching or surpassing human work. However, they struggle with specialised legal research, frequently generating hallucinations, factually incorrect or fabricated outputs.

Conclusion: While LLMs can augment certain legal tasks, human expertise remains essential for nuanced reasoning and the precise application of law.

Abstract: The integration of Artificial Intelligence(AI) into the legal profession
raises significant questions about the capacity of Large Language Models(LLM)
to perform key legal tasks. In this paper, I empirically evaluate how well
LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian
context, including issue spotting, legal drafting, advice, research, and
reasoning. Through a survey experiment, I compare outputs from LLMs with those
of a junior lawyer, with advanced law students rating the work on helpfulness,
accuracy, and comprehensiveness. LLMs excel in drafting and issue spotting,
often matching or surpassing human work. However, they struggle with
specialised legal research, frequently generating hallucinations, factually
incorrect or fabricated outputs. I conclude that while LLMs can augment certain
legal tasks, human expertise remains essential for nuanced reasoning and the
precise application of law.

</details>


### [146] [The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models](https://arxiv.org/abs/2508.09716)
*Ridwan Mahbub,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Mizanur Rahman,Mir Tafseer Nayeem,Enamul Hoque*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Information visualizations are powerful tools that help users quickly
identify patterns, trends, and outliers, facilitating informed decision-making.
However, when visualizations incorporate deceptive design elements-such as
truncated or inverted axes, unjustified 3D effects, or violations of best
practices-they can mislead viewers and distort understanding, spreading
misinformation. While some deceptive tactics are obvious, others subtly
manipulate perception while maintaining a facade of legitimacy. As
Vision-Language Models (VLMs) are increasingly used to interpret
visualizations, especially by non-expert users, it is critical to understand
how susceptible these models are to deceptive visual designs. In this study, we
conduct an in-depth evaluation of VLMs' ability to interpret misleading
visualizations. By analyzing over 16,000 responses from ten different models
across eight distinct types of misleading chart designs, we demonstrate that
most VLMs are deceived by them. This leads to altered interpretations of
charts, despite the underlying data remaining the same. Our findings highlight
the need for robust safeguards in VLMs against visual misinformation.

</details>


### [147] [Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning](https://arxiv.org/abs/2508.09726)
*Vaishnavi Shrivastava,Ahmed Awadallah,Vidhisha Balachandran,Shivam Garg,Harkirat Behl,Dimitris Papailiopoulos*

Main category: cs.CL

TL;DR: GFPO通过在训练时增加采样和过滤，有效减少了大型语言模型的响应长度，同时保持准确性，并能在处理难题时更高效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通过具有可验证奖励的强化学习进行训练时，往往会以牺牲准确性来换取长度，从而增加响应长度以获得准确性上的提升。然而，许多增加的词元只是“填充”：重复、冗长且没有实质进展的文本。因此，需要一种方法来控制这种长度的爆炸式增长。

Method: GFPO（Group Filtered Policy Optimization）通过在训练期间对每个问题进行更大批次的采样，并根据两个关键指标（响应长度和令牌效率：每令牌奖励）对响应进行过滤来训练模型。自适应难度GFPO在此基础上，根据实时难度估算动态分配更多训练资源给更难的问题。

Result: GFPO在Phi-4-reasoning模型上，在STEM和编码基准（AIME 24/25, GPQA, Omni-MATH, LiveCodeBench）上将GRPO的长度膨胀减少了46-71%，同时保持了准确性。通过优化每令牌奖励，长度膨胀的减少幅度进一步增加到71-85%。自适应难度GFPO提高了计算效率和准确性之间的平衡，尤其是在处理难题时。

Conclusion: GFPO通过在训练期间采样更大的组并根据响应长度和令牌效率（每令牌奖励）进行过滤来解决大型语言模型的长度膨胀问题，从而在不牺牲准确性的情况下减少了冗余内容。自适应难度GFPO通过动态分配更多训练资源来解决更难的问题，进一步提高了计算效率和准确性之间的平衡，尤其是在处理难题时。

Abstract: Large language models trained with reinforcement learning with verifiable
rewards tend to trade accuracy for length--inflating response lengths to
achieve gains in accuracy. While longer answers may be warranted for harder
problems, many tokens are merely "filler": repetitive, verbose text that makes
no real progress. We introduce GFPO (Group Filtered Policy Optimization), which
curbs this length explosion by sampling larger groups per problem during
training and filtering responses to train on based on two key metrics: (1)
response length and (2) token efficiency: reward per token ratio. By sampling
more at training time, we teach models to think less at inference time. On the
Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across
challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH,
LiveCodeBench) while maintaining accuracy. Optimizing for reward per token
further increases reductions in length inflation to 71-85%. We also propose
Adaptive Difficulty GFPO, which dynamically allocates more training resources
to harder problems based on real-time difficulty estimates, improving the
balance between computational efficiency and accuracy especially on difficult
questions. GFPO demonstrates that increased training-time compute directly
translates to reduced test-time compute--a simple yet effective trade-off for
efficient reasoning.

</details>


### [148] [Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation](https://arxiv.org/abs/2508.09755)
*Seokgi Lee*

Main category: cs.CL

TL;DR: 引入了一种新颖的检索增强生成（RAG）框架，用于多步问答。通过 LLM 查询分解和基于可回答问题的嵌入来提高性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对多步问答任务中复杂查询的歧义性，并提高检索增强生成（RAG）框架的性能。

Method: 该框架利用 LLM 将复杂的多步问题分解为一系列单步子问题，以指导文档检索。它不直接嵌入文档块，而是使用 Qwen3-8B 从每个文档块生成可回答的问题，然后嵌入这些生成的问题，并通过问题-问题嵌入相似性来检索相关文档块。检索到的文档块随后与原始问题一起输入到 RAG 管道中进行推理。

Result: 与基线系统相比，该方法在 LongBench 的 MuSiQue、2WikiMultiHopQa 和 HotpotQA 三个多步问答数据集上提高了 RAG 性能。

Conclusion: 该方法通过使用 LLM 进行查询分解和基于可回答问题的嵌入进行检索，显著提高了多步问答任务中 RAG 框架的性能。

Abstract: We introduce a novel retrieval-augmented generation (RAG) framework tailored
for multihop question answering. First, our system uses large language model
(LLM) to decompose complex multihop questions into a sequence of single-hop
subquestions that guide document retrieval. This decomposition mitigates the
ambiguity inherent in multi-hop queries by clearly targeting distinct knowledge
facets. Second, instead of embedding raw or chunked documents directly, we
generate answerable questions from each document chunk using Qwen3-8B, embed
these generated questions, and retrieve relevant chunks via question-question
embedding similarity. During inference, the retrieved chunks are then fed along
with the original question into the RAG pipeline. We evaluate on three multihop
question datasets (MuSiQue, 2WikiMultiHopQa, HotpotQA) from LongBench. Our
method improves RAG performacne compared to baseline systems. Our contributions
highlight the benefits of using answerable-question embeddings for RAG, and the
effectiveness of LLM-based query decomposition for multihop scenarios.

</details>


### [149] [Echoes of Agreement: Argument Driven Opinion Shifts in Large Language Models](https://arxiv.org/abs/2508.09759)
*Avneet Kaur*

Main category: cs.CL

TL;DR: LLM political bias evaluations are sensitive to prompts containing arguments. LLMs tend to agree with provided arguments, a sycophantic tendency that affects bias measurement and mitigation.


<details>
  <summary>Details</summary>
Motivation: To understand how suggestive prompts, containing arguments for certain political positions, affect LLM bias evaluations and model behavior, especially given LLMs' interaction with opinionated text.

Method: Conducted experiments evaluating political bias in LLMs with supporting and refuting arguments in both single-turn and multi-turn settings.

Result: The presence of supporting and refuting arguments significantly altered LLM responses in the direction of the provided arguments. The strength of these arguments also influenced the directional agreement rate of the model's responses.

Conclusion: LLMs exhibit sycophantic tendencies, adapting their stance to align with presented arguments, which impacts political bias evaluations and mitigation strategies.

Abstract: There have been numerous studies evaluating bias of LLMs towards political
topics. However, how positions towards these topics in model outputs are highly
sensitive to the prompt. What happens when the prompt itself is suggestive of
certain arguments towards those positions remains underexplored. This is
crucial for understanding how robust these bias evaluations are and for
understanding model behaviour, as these models frequently interact with
opinionated text. To that end, we conduct experiments for political bias
evaluation in presence of supporting and refuting arguments. Our experiments
show that such arguments substantially alter model responses towards the
direction of the provided argument in both single-turn and multi-turn settings.
Moreover, we find that the strength of these arguments influences the
directional agreement rate of model responses. These effects point to a
sycophantic tendency in LLMs adapting their stance to align with the presented
arguments which has downstream implications for measuring political bias and
developing effective mitigation strategies.

</details>


### [150] [UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech](https://arxiv.org/abs/2508.09767)
*Shuhei Kato*

Main category: cs.CL

TL;DR: UtterTune 是一种基于 LLM 的 TTS 微调方法，可针对日语进行发音和音高重音控制，同时保持其他语言的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管 LLM 架构使 TTS 模型取得了卓越的自然度，但在没有显式 G2P（字母到音素）模块的情况下，准确建模 G2P 映射和韵律仍然是一个挑战，尤其是在模型直接处理最小编码文本（例如字节对编码）时。

Method: UtterTune 是一种轻量级改编方法，它基于大型语言模型 (LLM) 架构微调多语言文本到语音 (TTS) 系统，利用低秩适应来控制日语语音的音素发音和音高重音。

Result: 客观和主观评估均证实了 UtterTune 的有效性。

Conclusion: UtterTune 通过低秩适应在目标语言（日语）中实现了音素级别的发音和音高重音控制，同时在零样本设置中保持了自然度和说话人相似性。

Abstract: We propose UtterTune, a lightweight adaptation method that fine-tunes a
multilingual text-to-speech (TTS) system based on a large language model (LLM)
architecture, designed to enhance the controllability of pronunciation in a
target language while preserving performance in others. While LLM architectures
have enabled TTS models to achieve remarkable naturalness, accurately modeling
grapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially
when the model omits an explicit G2P module and directly processes minimally
encoded text (e.g., byte-pair encoding). UtterTune leverages low-rank
adaptation to enable the control of segmental pronunciation and pitch accent at
the phoneme level for Japanese speech, the target language in this paper, while
maintaining naturalness and speaker similarity in a zero-shot setting.
Objective and subjective evaluations confirm its effectiveness.

</details>


### [151] [Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study](https://arxiv.org/abs/2508.09776)
*Mahdi Dhaini,Juraj Vladika,Ege Erdogan,Zineb Attaoui,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 自动化框架利用 LLM 生成文本解释，并在性能上与人工解释相媲美，为 NLP 数据集扩展和模型性能提升提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于昂贵、耗时且难以扩展的人工注释来生成文本解释，而文本解释对于解释模型预测和丰富可解释标签至关重要。

Method: 利用多个最先进的大型语言模型（LLM）来生成文本解释，并使用自然语言生成（NLG）指标进行评估，最后评估其对预训练语言模型（PLM）和 LLM 在自然语言推理任务上的下游影响。

Result: 自动生成的解释在提高模型性能方面与人工注释的解释一样有效，证明了该方法的竞争力。

Conclusion: 自动化方法在提高模型性能方面与人工注释的解释一样有效，为可扩展的、基于 LLM 的文本解释生成开辟了前景。

Abstract: In the rapidly evolving field of Explainable Natural Language Processing
(NLP), textual explanations, i.e., human-like rationales, are pivotal for
explaining model predictions and enriching datasets with interpretable labels.
Traditional approaches rely on human annotation, which is costly,
labor-intensive, and impedes scalability. In this work, we present an automated
framework that leverages multiple state-of-the-art large language models (LLMs)
to generate high-quality textual explanations. We rigorously assess the quality
of these LLM-generated explanations using a comprehensive suite of Natural
Language Generation (NLG) metrics. Furthermore, we investigate the downstream
impact of these explanations on the performance of pre-trained language models
(PLMs) and LLMs across natural language inference tasks on two diverse
benchmark datasets. Our experiments demonstrate that automated explanations
exhibit highly competitive effectiveness compared to human-annotated
explanations in improving model performance. Our findings underscore a
promising avenue for scalable, automated LLM-based textual explanation
generation for extending NLP datasets and enhancing model performance.

</details>


### [152] [Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges](https://arxiv.org/abs/2508.09786)
*Mahdi Dhaini,Tobias Müller,Roksoliana Rabets,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 由于复杂模型日益增长的不透明性，对可解释的NLP的需求越来越大。本研究通过对行业从业者和学术研究人员进行访谈，发现对现有方法满意度低且存在评估挑战，并强调需要以用户为中心的框架来更好地在实践中采用可解释的NLP。


<details>
  <summary>Details</summary>
Motivation: 由于复杂模型日益增长的不透明性，需要对其决策进行透明化和解释，这对于理解其推理和促进部署至关重要，尤其是在高风险环境中。尽管对可解释的NLP的关注日益增加，但从业人员对其在实践中采纳和有效性的看法仍然未被充分探索。

Method: 本研究通过对行业从业者进行定性访谈研究，并辅以对学术研究人员的访谈，系统地分析和比较了他们的观点。

Result: 研究结果揭示了概念上的差距、对现有可解释性方法的满意度低以及突出的评估挑战。

Conclusion: 本研究强调了在实践中更好地采用可解释的NLP需要清晰的定义和以用户为中心的框架。

Abstract: The field of explainable natural language processing (NLP) has grown rapidly
in recent years. The growing opacity of complex models calls for transparency
and explanations of their decisions, which is crucial to understand their
reasoning and facilitate deployment, especially in high-stakes environments.
Despite increasing attention given to explainable NLP, practitioners'
perspectives regarding its practical adoption and effectiveness remain
underexplored. This paper addresses this research gap by investigating
practitioners' experiences with explainability methods, specifically focusing
on their motivations for adopting such methods, the techniques employed,
satisfaction levels, and the practical challenges encountered in real-world NLP
applications. Through a qualitative interview-based study with industry
practitioners and complementary interviews with academic researchers, we
systematically analyze and compare their perspectives. Our findings reveal
conceptual gaps, low satisfaction with current explainability methods, and
highlight evaluation challenges. Our findings emphasize the need for clear
definitions and user-centric frameworks for better adoption of explainable NLP
in practice.

</details>


### [153] [BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning](https://arxiv.org/abs/2508.09804)
*Ahmed Masry,Abhay Puri,Masoud Hashemi,Juan A. Rodriguez,Megh Thakkar,Khyati Mahajan,Vikas Yadav,Sathwik Tejaswi Madhusudhan,Alexandre Piché,Dzmitry Bahdanau,Christopher Pal,David Vazquez,Enamul Hoque,Perouz Taslakian,Sai Rajeswar,Spandana Gella*

Main category: cs.CL

TL;DR: 为解决视觉语言模型在图表理解上的不足，提出BigCharts数据集和结合监督微调与强化学习的训练框架，并引入了专门的奖励信号，成功研发出在图表问答任务上表现优于现有方法的BigCharts-R1模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在图表理解方面存在不足，因为它们在多样性和真实性不足的数据集上进行训练，或使用包含大量估计错误的数据。现有模型仅依赖低质量数据集的监督微调，严重限制了其有效性。

Method: 创建BigCharts数据集，该数据集通过真实世界图表进行条件渲染，并使用重绘过程保留准确的底层数据。训练框架整合了监督微调和基于GRPO的强化学习，并引入了专门为图表推理设计的奖励信号。

Result: BigCharts-R1模型在多个图表问答基准测试中超越了现有方法，以及更大规模的开源和闭源模型。

Conclusion: 提出BigCharts数据集创建管线和整合了监督微调与基于GRPO的强化学习的训练框架，以提升视觉语言模型在图表理解方面的能力。

Abstract: Charts are essential to data analysis, transforming raw data into clear
visual representations that support human decision-making. Although current
vision-language models (VLMs) have made significant progress, they continue to
struggle with chart comprehension due to training on datasets that lack
diversity and real-world authenticity, or on automatically extracted underlying
data tables of charts, which can contain numerous estimation errors.
Furthermore, existing models only rely on supervised fine-tuning using these
low-quality datasets, severely limiting their effectiveness. To address these
issues, we first propose BigCharts, a dataset creation pipeline that generates
visually diverse chart images by conditioning the rendering process on
real-world charts sourced from multiple online platforms. Unlike purely
synthetic datasets, BigCharts incorporates real-world data, ensuring
authenticity and visual diversity, while still retaining accurate underlying
data due to our proposed replotting process. Additionally, we introduce a
comprehensive training framework that integrates supervised fine-tuning with
Group Relative Policy Optimization (GRPO)-based reinforcement learning. By
introducing novel reward signals specifically designed for chart reasoning, our
approach enhances model robustness and generalization across diverse chart
styles and domains, resulting in a state-of-the-art chart reasoning model,
BigCharts-R1. Extensive experiments demonstrate that our models surpass
existing methods on multiple chart question-answering benchmarks compared to
even larger open-source and closed-source models.

</details>


### [154] [A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems](https://arxiv.org/abs/2508.09809)
*Aishik Mandal,Prottay Kumar Adhikary,Hiba Arnaout,Iryna Gurevych,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 一项关于心理健康人工智能训练数据集的调查，强调了现有数据集的局限性，并为改进它们提供了建议。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康障碍的增加与训练有素的临床医生数量不成比例，因此需要人工智能（AI）来弥合差距，但人工智能的开发依赖于高质量的临床训练数据集，而这些数据集分散、文档记录不足且难以获取。

Method: 对临床心理健康数据集进行了首次全面调查，按心理健康障碍、数据模式、任务类型、可访问性和社会文化背景对其进行了分类，并研究了合成数据集。

Result: 识别出缺乏长期数据、有限的文化和语言代表性、不一致的收集和注释标准以及合成数据中缺乏模式等关键差距。

Conclusion: 本调查总结了临床心理健康数据集的现状，指出了长期数据、跨文化代表性、标准化以及合成数据模式方面的关键差距，并为开发更强大、更具普遍性和公平性的心理健康人工智能系统提供了行动建议。

Abstract: Mental health disorders are rising worldwide. However, the availability of
trained clinicians has not scaled proportionally, leaving many people without
adequate or timely support. To bridge this gap, recent studies have shown the
promise of Artificial Intelligence (AI) to assist mental health diagnosis,
monitoring, and intervention. However, the development of efficient, reliable,
and ethical AI to assist clinicians is heavily dependent on high-quality
clinical training datasets. Despite growing interest in data curation for
training clinical AI assistants, existing datasets largely remain scattered,
under-documented, and often inaccessible, hindering the reproducibility,
comparability, and generalizability of AI models developed for clinical mental
health care. In this paper, we present the first comprehensive survey of
clinical mental health datasets relevant to the training and development of
AI-powered clinical assistants. We categorize these datasets by mental
disorders (e.g., depression, schizophrenia), data modalities (e.g., text,
speech, physiological signals), task types (e.g., diagnosis prediction, symptom
severity estimation, intervention generation), accessibility (public,
restricted or private), and sociocultural context (e.g., language and cultural
background). Along with these, we also investigate synthetic clinical mental
health datasets. Our survey identifies critical gaps such as a lack of
longitudinal data, limited cultural and linguistic representation, inconsistent
collection and annotation standards, and a lack of modalities in synthetic
data. We conclude by outlining key challenges in curating and standardizing
future datasets and provide actionable recommendations to facilitate the
development of more robust, generalizable, and equitable mental health AI
systems.

</details>


### [155] [Speed Always Wins: A Survey on Efficient Architectures for Large Language Models](https://arxiv.org/abs/2508.09834)
*Weigao Sun,Jiaxi Hu,Yucheng Zhou,Jusen Du,Disen Lan,Kexin Wang,Tong Zhu,Xiaoye Qu,Yu Zhang,Xiaoyu Mo,Daizong Liu,Yuxuan Liang,Wenliang Chen,Guoqi Li,Yu Cheng*

Main category: cs.CL

TL;DR: 本次调查着眼于改进LLM的效率，重点介绍了Transformer的替代架构，如线性、稀疏、混合和扩散模型。


<details>
  <summary>Details</summary>
Motivation: LLM在语言理解、生成和推理方面取得了显著成果，但传统的Transformer架构在计算量和效率方面存在巨大挑战，阻碍了其大规模训练和实际部署。

Method: 对线性、稀疏序列建模方法、高效的全注意力变体、稀疏专家混合模型、结合这些技术的混合模型架构以及新兴的扩散LLM进行了分类和讨论。

Result: 本次调查为实现更高效、更多功能的AI系统奠定了基础，并为未来的研究提供了方向。

Conclusion: 该调查系统地检查了解决Transformer固有局限性并提高效率的创新LLM架构，并为开发可扩展、资源感知的 प्रकारचे模型提供了蓝图。

Abstract: Large Language Models (LLMs) have delivered impressive results in language
understanding, generation, reasoning, and pushes the ability boundary of
multimodal models. Transformer models, as the foundation of modern LLMs, offer
a strong baseline with excellent scaling properties. However, the traditional
transformer architecture requires substantial computations and poses
significant obstacles for large-scale training and practical deployment. In
this survey, we offer a systematic examination of innovative LLM architectures
that address the inherent limitations of transformers and boost the efficiency.
Starting from language modeling, this survey covers the background and
technical details of linear and sparse sequence modeling methods, efficient
full attention variants, sparse mixture-of-experts, hybrid model architectures
incorporating the above techniques, and emerging diffusion LLMs. Additionally,
we discuss applications of these techniques to other modalities and consider
their wider implications for developing scalable, resource-aware foundation
models. By grouping recent studies into the above category, this survey
presents a blueprint of modern efficient LLM architectures, and we hope this
could help motivate future research toward more efficient, versatile AI
systems.

</details>


### [156] [PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts](https://arxiv.org/abs/2508.09848)
*Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou*

Main category: cs.CL

TL;DR: PRELUDE是一个评估长文本理解能力的新基准，旨在通过判断角色前传故事与原作的一致性来衡量模型的深度推理能力。实验证明，现有大模型在PRELUDE上表现不如人类，尤其在推理方面差距明显，表明该领域仍需大量改进。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分满足对全局理解和深度推理的更高要求，PRELUDE基准测试旨在解决这一问题。

Method: 提出PRELUDE基准测试，该测试通过判断角色的前传故事是否与原作保持一致来评估长文本理解能力。任务要求模型理解并整合原文中多处分散的信息，以评估前传的合理性。

Result: 在PRELUDE基准测试中，88%的实例需要整合原文多处信息。实验结果表明，包括上下文学习、检索增强生成（RAG）、领域内训练以及商业深度研究服务在内的多种先进方法，在表现上均落后于人类15%以上。此外，模型在推理方面也存在明显不足，相比人类有超过30%的差距。

Conclusion: 现有的大语言模型在长文本理解和推理方面仍有较大提升空间，尤其是在需要整合间接信息进行深度推理的任务上。

Abstract: We introduce PRELUDE, a benchmark for evaluating long-context understanding
through the task of determining whether a character's prequel story is
consistent with the canonical narrative of the original book. Our task poses a
stronger demand for global comprehension and deep reasoning than existing
benchmarks -- as the prequels are not part of the original story, assessing
their plausibility typically requires searching and integrating information
that is only indirectly related. Empirically, 88% of instances require evidence
from multiple parts of the narrative. Experimental results highlight the
challenge of our task: in-context learning, RAG and in-domain training with
state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans
by >15%. A further human study reveals that models often produce correct
answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy
compared to humans. These findings underscore the substantial room for
improvement in long-context understanding and reasoning.

</details>


### [157] [Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription](https://arxiv.org/abs/2508.09865)
*Abdul Rehman Antall,Naveed Akhtar*

Main category: cs.CL

TL;DR: 本研究评估了轻量级Whisper模型在低资源乌尔都语语音识别中的表现。结果显示，Whisper-Small模型在未经微调的情况下表现最佳，但仍需改进以克服语音识别准确性和词汇连贯性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管乌尔都语是全球第十大语种，拥有超过2.3亿使用者，但由于方言多样性、语码转换以及稀疏的训练数据，其在自动语音识别（ASR）系统中的代表性仍然有限。本研究旨在评估轻量级Whisper模型在低资源环境下的乌尔都语语音识别能力。

Method: 本文评估了轻量级Whisper模型（Tiny、Base、Small）在资源匮乏条件下进行乌尔都语语音识别的可行性。研究人员在精心策划的乌尔都语数据集上，在未进行微调的情况下，使用词错误率（WER）对这些模型进行了基准测试。

Result: Whisper-Small模型在乌尔都语语音识别任务中表现最佳，词错误率为33.68%，优于Whisper-Tiny（67.08%）和Whisper-Base（53.67%）。然而，定性分析显示，在语音识别的准确性和词汇连贯性方面仍存在挑战，尤其是在处理复杂语句时。

Conclusion: Whisper-Small模型在未经微调的情况下，在乌尔都语语音识别任务中表现出最低的词错误率（33.68%），优于Tiny（67.08%）和Base（53.67%）模型。尽管Whisper-Small模型展现了在低资源环境下部署乌尔都语自动语音识别系统的潜力，但在语音识别的准确性和词汇连贯性方面仍面临挑战，尤其是在处理复杂语句时。

Abstract: This study evaluates the feasibility of lightweight Whisper models (Tiny,
Base, Small) for Urdu speech recognition in low-resource settings. Despite Urdu
being the 10th most spoken language globally with over 230 million speakers,
its representation in automatic speech recognition (ASR) systems remains
limited due to dialectal diversity, code-switching, and sparse training data.
We benchmark these models on a curated Urdu dataset using word error rate
(WER), without fine-tuning. Results show Whisper-Small achieves the lowest
error rates (33.68\% WER), outperforming Tiny (67.08\% WER) and Base (53.67\%
WER). Qualitative analysis reveals persistent challenges in phonetic accuracy
and lexical coherence, particularly for complex utterances. While Whisper-Small
demonstrates promise for deployable Urdu ASR, significant gaps remain. Our
findings emphasize lay the groundwork for future research into effective,
low-resource ASR systems.

</details>


### [158] [Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models](https://arxiv.org/abs/2508.09874)
*Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: Memory Decoder 是一种即插即用的预训练内存，可以高效地使 LLM 适应特定领域，而无需更改原始模型参数或引入显著的推理延迟。


<details>
  <summary>Details</summary>
Motivation: 目前的领域自适应方法（如 DAPT）需要昂贵的全部参数训练并且会遗忘灾难，而检索增强生成（RAG）会因为昂贵的近邻搜索和更长的上下文而引入显著的推理延迟。

Method: Memory Decoder 是一种即插即用的预训练内存，它使用一个小型 transformer 解码器来模仿外部非参数检索器的行为，从而实现高效的领域自适应，而无需更改原始模型的参数。

Result: Memory Decoder 能够有效地将多种 Qwen 和 Llama 模型适应到三个不同的专业领域（生物医学、金融和法律），平均将困惑度降低了 6.17 个点。

Conclusion: Memory Decoder 提出了一种新颖的、基于预训练内存组件的、用于领域自适应的范式。这种内存架构可以即插即用地集成，在目标域的多个模型中持续提升性能。

Abstract: Large Language Models (LLMs) have shown strong abilities in general language
tasks, yet adapting them to specific domains remains a challenge. Current
method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter
training and suffers from catastrophic forgetting. Meanwhile,
Retrieval-Augmented Generation (RAG) introduces substantial inference latency
due to expensive nearest-neighbor searches and longer context. This paper
introduces Memory Decoder, a plug-and-play pretrained memory that enables
efficient domain adaptation without changing the original model's parameters.
Memory Decoder employs a small transformer decoder that learns to imitate the
behavior of an external non-parametric retriever. Once trained, Memory Decoder
can be seamlessly integrated with any pretrained language model that shares the
same tokenizer, requiring no model-specific modifications. Experimental results
demonstrate that Memory Decoder enables effective adaptation of various Qwen
and Llama models to three distinct specialized domains: biomedicine, finance,
and law, reducing perplexity by an average of 6.17 points. Overall, Memory
Decoder introduces a novel paradigm centered on a specially pretrained memory
component designed for domain-specific adaptation. This memory architecture can
be integrated in a plug-and-play manner, consistently enhancing performance
across multiple models within the target domain.

</details>


### [159] [A Survey of Cognitive Distortion Detection and Classification in NLP](https://arxiv.org/abs/2508.09878)
*Archie Sage,Jeroen Keppens,Helen Yannakoudakis*

Main category: cs.CL

TL;DR: NLP在心理健康领域识别认知扭曲的研究越来越多，但存在方法不统一的问题。本文回顾了38项相关研究，梳理了数据集、建模方法和评估策略，并提出了未来研究的建议。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理（NLP）技术在心理健康领域的应用日益受到关注，利用NLP技术自动检测和分类认知扭曲（CDs）的研究也日益增多。CDs是负面偏见或错误思维的习惯模式，会扭曲人们对事件的看法、对自己的评判以及对周围世界的反应。识别和解决这些问题是心理治疗的重要组成部分。然而，该领域的研究仍然存在碎片化的问题，包括CD分类法、任务制定和评估实践等方面的不一致性。

Method: 通过回顾38项跨越二十年的研究，对数据集、建模方法和评估策略进行结构化概述，并提供一个整合的CD分类法参考，总结常见的任务设置，并强调开放的挑战。

Result: 对现有研究进行了梳理，提供了一个整合的CD分类法参考，总结了常见的任务设置，并强调了该领域面临的开放挑战。

Conclusion: 该领域的研究仍然存在碎片化的问题，包括CD分类法、任务制定和评估实践等方面的不一致性。本篇论文旨在通过回顾38项跨越二十年的研究，为数据集、建模方法和评估策略提供一个结构化的概述，以期促进该新兴领域更一致、更可复现的研究。

Abstract: As interest grows in the application of natural language processing (NLP)
techniques to mental health, a growing body of work explores the automatic
detection and classification of cognitive distortions (CDs). CDs are habitual
patterns of negatively biased or flawed thinking that distort how people
perceive events, judge themselves, and react to the world around them.
Identifying and addressing them is an important part of therapy. Despite its
momentum, the field remains fragmented, with inconsistencies in CD taxonomies,
task formulations, and evaluation practices. This survey reviews 38 studies
spanning two decades, providing a structured overview of datasets, modelling
approaches, and evaluation strategies. We provide a consolidated CD taxonomy
reference, summarise common task setups, and highlight open challenges to
support more coherent and reproducible research in this emerging area.

</details>


### [160] [Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach](https://arxiv.org/abs/2508.09935)
*Sayem Hossen,Monalisa Moon Joti,Md. Golam Rashed*

Main category: cs.CL

TL;DR: Business communication's digitisation allows for deception. This paper uses rhetoric, psychology, and linguistics to detect deceptive language with AI, achieving high accuracy in controlled tests but facing challenges in multilingual settings due to data and infrastructure limitations.


<details>
  <summary>Details</summary>
Motivation: The digitisation of business communication has reshaped persuasive discourse, enabling both increased transparency and advanced deception. This research aims to address how deceptive language can be systematically detected.

Method: This inquiry synthesizes classical rhetoric, communication psychology, and linguistic theory, incorporating empirical studies from financial reporting, sustainability discourse, and digital marketing to systematically detect deceptive language using persuasive lexicon. Computational textual analysis and personalized transformer models were employed, achieving over 99% detection accuracy in controlled settings.

Result: Detection accuracies exceeding 99% were achieved in controlled settings using computational textual analysis and personalized transformer models. However, reproducing this performance in multilingual contexts is challenging due to data scarcity and limited multilingual text-processing infrastructure.

Conclusion: The study highlights the gap between theoretical communication models and empirical approximations, emphasizing the need for robust automatic text-identification systems, especially as AI-driven discourse becomes more prevalent.

Abstract: Business communication digitisation has reorganised the process of persuasive
discourse, which
  allows not only greater transparency but also advanced deception. This
inquiry synthesises classical
  rhetoric and communication psychology with linguistic theory and empirical
studies in the financial
  reporting, sustainability discourse, and digital marketing to explain how
deceptive language can be
  systematically detected using persuasive lexicon. In controlled settings,
detection accuracies of greater
  than 99% were achieved by using computational textual analysis as well as
personalised transformer
  models. However, reproducing this performance in multilingual settings is
also problematic and,
  to a large extent, this is because it is not easy to find sufficient data,
and because few multilingual
  text-processing infrastructures are in place. This evidence shows that there
has been an increasing
  gap between the theoretical representations of communication and those
empirically approximated,
  and therefore, there is a need to have strong automatic text-identification
systems where AI-based
  discourse is becoming more realistic in communicating with humans.

</details>


### [161] [A Comprehensive Evaluation framework of Alignment Techniques for LLMs](https://arxiv.org/abs/2508.09937)
*Muneeza Azmat,Momin Abbas,Maysa Malfiza Garcia de Macedo,Marcelo Carpinette Grave,Luan Soares de Souza,Tiago Machado,Rogerio A de Paula,Raya Horesh,Yixin Chen,Heloisa Caroline de Souza Pereira Candello,Rebecka Nordenlow,Aminat Adebiyi*

Main category: cs.CL

TL;DR: LLM对齐评估框架：系统比较不同对齐方法，评估检测、质量、效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益广泛的应用，确保其输出符合人类价值观和安全标准变得至关重要，但目前缺乏统一的评估框架来系统比较不同的对齐范式。

Method: 本研究通过跨不同基础模型和对齐策略的实验，沿着四个关键维度（对齐检测、对齐质量、计算效率和鲁棒性）来评估对齐方法。

Result: 实验证明了该框架在识别当前最先进模型优缺点的效用，为未来的研究方向提供了宝贵的见解。

Conclusion: 该研究提出了一个多维度的LLM对齐技术评估框架，用于系统地比较不同的对齐范式，以解决现有评估框架缺乏统一性的问题。

Abstract: As Large Language Models (LLMs) become increasingly integrated into
real-world applications, ensuring their outputs align with human values and
safety standards has become critical. The field has developed diverse alignment
approaches including traditional fine-tuning methods (RLHF, instruction
tuning), post-hoc correction systems, and inference-time interventions, each
with distinct advantages and limitations. However, the lack of unified
evaluation frameworks makes it difficult to systematically compare these
paradigms and guide deployment decisions. This paper introduces a
multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive
evaluation framework that provides a systematic comparison across all major
alignment paradigms. Our framework assesses methods along four key dimensions:
alignment detection, alignment quality, computational efficiency, and
robustness. Through experiments across diverse base models and alignment
strategies, we demonstrate the utility of our framework in identifying
strengths and limitations of current state-of-the-art models, providing
valuable insights for future research directions.

</details>


### [162] [VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models](https://arxiv.org/abs/2508.09945)
*Lingjie Jiang,Shaohan Huang,Xun Wu,Yixia Li,Dongdong Zhang,Furu Wei*

Main category: cs.CL

TL;DR: VisCodex 是一个统一的框架，通过模型合并技术和新的数据集（MCD 和 InfiBench-V）增强了 MLLM 的多模式代码生成能力，并在各种基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决多模式大语言模型 (MLLM) 在从多模式输入生成代码方面的局限性。

Method: 提出了一种名为 VisCodex 的统一框架，该框架利用基于任务向量的模型合并技术，将先进的编码语言模型集成到视觉语言骨干中，以增强 MLLM 的多模式代码生成能力。此外，还引入了 Multimodal Coding Dataset (MCD) 和 InfiBench-V 评估基准。

Result: VisCodex 在开源 MLLM 中取得了最先进的性能，并接近 GPT-4o 等专有模型。

Conclusion: VisCodex 在代码生成方面取得了最先进的性能，并接近 GPT-4o 等专有模型，证明了其模型合并策略和新数据集的有效性。

Abstract: Multimodal large language models (MLLMs) have significantly advanced the
integration of visual and textual understanding. However, their ability to
generate code from multimodal inputs remains limited. In this work, we
introduce VisCodex, a unified framework that seamlessly merges vision and
coding language models to empower MLLMs with strong multimodal code generation
abilities. Leveraging a task vector-based model merging technique, we integrate
a state-of-the-art coding LLM into a strong vision-language backbone, while
preserving both visual comprehension and advanced coding skills. To support
training and evaluation, we introduce the Multimodal Coding Dataset (MCD), a
large-scale and diverse collection of 598k samples, including high-quality HTML
code, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic
problems. Furthermore, we propose InfiBench-V, a novel and challenging
benchmark specifically designed to assess models on visually-rich, real-world
programming questions that demand a nuanced understanding of both textual and
visual contexts. Extensive experiments show that VisCodex achieves
state-of-the-art performance among open-source MLLMs and approaches proprietary
models like GPT-4o, highlighting the effectiveness of our model merging
strategy and new datasets.

</details>


### [163] [Specialised or Generic? Tokenization Choices for Radiology Language Models](https://arxiv.org/abs/2508.09952)
*Hermione Warr,Wentian Xu,Harry Anthony,Yasin Ibrahim,Daniel McGowan,Konstantinos Kamnitsas*

Main category: cs.CL

TL;DR: 在放射学报告摘要生成任务中，使用医学或领域特定词汇表比通用词汇表效果更好，尤其是在没有预训练的情况下。预训练可以缩小差距，但领域特定词汇表依然表现最佳。领域特定词汇表还能减少内存占用。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型的词汇表（由分词器定义）在文本生成质量中起着关键作用，但其在放射学领域的影响尚未得到充分探索。

Method: 本研究通过系统比较通用、医学和领域特定词汇表在三种影像学模式的放射学报告摘要生成任务上的表现，并研究了是否使用PubMed摘要对语言模型进行预训练，来解决现有研究的不足。

Result: 研究结果显示，在从头开始训练模型时，医学和领域特定词汇表的表现优于常用的自然语言处理词汇表。预训练能在一定程度上缩小不同词汇表之间的性能差距，但领域特定词汇表仍然取得了最佳效果。此外，领域特定词汇表由于词汇量较小和序列较短，还能有效降低内存需求。

Conclusion: 本文研究表明，针对放射学领域的特定词汇表能够提升语言模型的性能并降低计算需求，使得模型在研究和实际医疗保健环境中更具可用性和有效性。

Abstract: The vocabulary used by language models (LM) - defined by the tokenizer -
plays a key role in text generation quality. However, its impact remains
under-explored in radiology. In this work, we address this gap by
systematically comparing general, medical, and domain-specific tokenizers on
the task of radiology report summarisation across three imaging modalities. We
also investigate scenarios with and without LM pre-training on PubMed
abstracts. Our findings demonstrate that medical and domain-specific
vocabularies outperformed widely used natural language alternatives when models
are trained from scratch. Pre-training partially mitigates performance
differences between tokenizers, whilst the domain-specific tokenizers achieve
the most favourable results. Domain-specific tokenizers also reduce memory
requirements due to smaller vocabularies and shorter sequences. These results
demonstrate that adapting the vocabulary of LMs to the clinical domain provides
practical benefits, including improved performance and reduced computational
demands, making such models more accessible and effective for both research and
real-world healthcare settings.

</details>


### [164] [Shaping Event Backstories to Estimate Potential Emotion Contexts](https://arxiv.org/abs/2508.09954)
*Johannes Schäfer,Roman Klinger*

Main category: cs.CL

TL;DR: 本研究通过为事件描述添加情境来解决情感分析中的歧义性问题，并通过生成事件链和短故事来构建数据集，实验证明该方法能提高标注的一致性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索添加合理情境是否能使人类标注者更可靠地标注情绪，以解决情感分析任务中的固有的歧义性问题。

Method: 本研究提出了一种新颖的方法，通过为事件描述添加合理的情境来消歧目标事件描述，并生成多个基于不同情绪的事件链。结合了不同场景下的短故事生成技术，构建了一个专门的数据集，用于对情境化情感分析进行全面系统的研究。

Result: 通过自动和人工评估，研究发现情境化叙述能够增强对特定情绪的解读，并支持标注者生成更一致的标注。

Conclusion: 本研究提出的情境化方法能够增强对特定情绪的解读，并支持标注者生成更一致的标注。

Abstract: Emotion analysis is an inherently ambiguous task. Previous work studied
annotator properties to explain disagreement, but this overlooks the
possibility that ambiguity may stem from missing information about the context
of events. In this paper, we propose a novel approach that adds reasonable
contexts to event descriptions, which may better explain a particular
situation. Our goal is to understand whether these enriched contexts enable
human annotators to annotate emotions more reliably. We disambiguate a target
event description by automatically generating multiple event chains conditioned
on differing emotions. By combining techniques from short story generation in
various settings, we achieve coherent narratives that result in a specialized
dataset for the first comprehensive and systematic examination of
contextualized emotion analysis. Through automatic and human evaluation, we
find that contextual narratives enhance the interpretation of specific emotions
and support annotators in producing more consistent annotations.

</details>


### [165] [Performance of GPT-5 Frontier Models in Ophthalmology Question Answering](https://arxiv.org/abs/2508.09956)
*Fares Antaki,David Mikhail,Daniel Milad,Danny A Mammo,Sumit Sharma,Sunil K Srivastava,Bing Yu Chen,Samir Touma,Mertcan Sevgi,Jonathan El-Khoury,Pearse A Keane,Qingyu Chen,Yih Chung Tham,Renaud Duval*

Main category: cs.CL

TL;DR: GPT-5 在眼科问答任务中表现出色，GPT-5-high 准确率最高，而 GPT-5-mini-low 性价比最高。


<details>
  <summary>Details</summary>
Motivation: 为了确定最大化复杂医学问答任务中准确性和成本效益的最佳模型配置，需要对新一代的 GPT-5 推理模型进行评估。

Method: 通过在 260 道美国眼科学会的选择题数据集上评估 GPT-5 系列（包括三个模型级别和四个推理设置）以及 o1-high、o3-high 和 GPT-4o，来衡量模型的准确性和成本效益。评估指标包括选择题准确率、Bradley-Terry 模型进行头对头排名，以及使用 LLM-as-a-judge 框架评估推理质量，并分析准确性与成本之间的权衡。

Result: GPT-5-high 在准确性上达到了 0.965，优于所有 GPT-5-nano 变体、o1-high 和 GPT-4o，但与 o3-high (0.958) 相当。GPT-5-high 在准确性和推理质量方面均排名第一。成本效益分析显示 GPT-5-mini-low 提供了最佳的低成本、高性能平衡。

Conclusion: GPT-5-high 在准确性和推理质量方面表现最佳，但 o3-high 的性能与之相当。GPT-5-mini-low 在成本效益方面表现突出，为低成本、高性能的平衡提供了最佳选择。

Abstract: Large language models (LLMs) such as GPT-5 integrate advanced reasoning
capabilities that may improve performance on complex medical question-answering
tasks. For this latest generation of reasoning models, the configurations that
maximize both accuracy and cost-efficiency have yet to be established. We
evaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across
four reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using
260 closed-access multiple-choice questions from the American Academy of
Ophthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome
was multiple-choice accuracy; secondary outcomes included head-to-head ranking
via a Bradley-Terry model, rationale quality assessment using a
reference-anchored, pairwise LLM-as-a-judge framework, and analysis of
accuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved
the highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano
variants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high
(0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x
stronger than o3-high) and rationale quality (1.11x stronger than o3-high).
Cost-accuracy analysis identified several GPT-5 configurations on the Pareto
frontier, with GPT-5-mini-low offering the most favorable low-cost,
high-performance balance. These results benchmark GPT-5 on a high-quality
ophthalmology dataset, demonstrate the influence of reasoning effort on
accuracy, and introduce an autograder framework for scalable evaluation of
LLM-generated answers against reference standards in ophthalmology.

</details>


### [166] [Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)](https://arxiv.org/abs/2508.09957)
*Renas Adnan,Hossein Hassani*

Main category: cs.CL

TL;DR: 本研究为 Badini 方言开发了语音转写系统。使用 Wav2Vec2-Large-XLSR-53 和 Whisper-small 模型进行实验，结果显示 Wav2Vec2-Large-XLSR-53 模型在准确性和可读性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 填补 Badini 和 Hawrami 等库尔德方言在语音转写系统（STT）方面的空白，特别是为拥有约 200 万使用者的 Badini 方言提供 STT 系统，以帮助其社群更好地使用技术并提升该方言的全球可见性。

Method: 使用 Wav2Vec2-Large-XLSR-53 和 Whisper-small 模型开发语言模型。通过收集包含 78 个故事的 8 本 Badini 儿童读物，由 6 位叙述者录制了约 17 小时的音频。对音频数据进行清洗、分割和标记化处理，最终得到约 15 小时的语音数据，包含 19193 个片段和 25221 个单词。

Result: Wav2Vec2-Large-XLSR-53 模型在语音转写任务中实现了 90.38% 的可读性和 82.67% 的准确率，而 Whisper-small 模型的可读性为 65.45%，准确率为 53.17%。实验结果表明 Wav2Vec2-Large-XLSR-53 模型生成的转写结果更准确、更易读。

Conclusion: Wav2Vec2-Large-XLSR-53 模型在 Badini 方言的语音转写任务中表现优于 Whisper-small 模型，在准确性和可读性方面均取得显著成果。

Abstract: Speech-to-text (STT) systems have a wide range of applications. They are
available in many languages, albeit at different quality levels. Although
Kurdish is considered a less-resourced language from a processing perspective,
SST is available for some of the Kurdish dialects, for instance, Sorani
(Central Kurdish). However, that is not applied to other Kurdish dialects,
Badini and Hawrami, for example. This research is an attempt to address this
gap. Bandin, approximately, has two million speakers, and STT systems can help
their community use mobile and computer-based technologies while giving their
dialect more global visibility. We aim to create a language model based on
Badini's speech and evaluate its performance. To cover a conversational aspect,
have a proper confidence level of grammatical accuracy, and ready
transcriptions, we chose Badini kids' stories, eight books including 78
stories, as the textual input. Six narrators narrated the books, which resulted
in approximately 17 hours of recording. We cleaned, segmented, and tokenized
the input. The preprocessing produced nearly 15 hours of speech, including
19193 segments and 25221 words. We used Wav2Vec2-Large-XLSR-53 and
Whisper-small to develop the language models. The experiments indicate that the
transcriptions process based on the Wav2Vec2-Large-XLSR-53 model provides a
significantly more accurate and readable output than the Whisper-small model,
with 90.38% and 65.45% readability, and 82.67% and 53.17% accuracy,
respectively.

</details>


### [167] [Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks](https://arxiv.org/abs/2508.09958)
*Baran Atalar,Eddie Zhang,Carlee Joe-Wong*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的LLM选择策略，能够通过神经网络上下文老虎机在线学习和优化LLM在复杂任务序列中的选择，以达到低成本和高成功率。该方法在电信问答和医学诊断预测任务上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，预测在低成本下能成功回答任务的LLM策略变得越来越重要。特别是对于需要将任务分解为多个子任务的应用，LLM的选择顺序会影响后续LLM的输入、成本和成功率，因此需要一种能够处理这种复杂性能依赖关系的方法。

Method: 提出了一种基于神经网络上下文老虎机的方法，该方法能够在线训练神经网络来模拟LLM在每个子任务上的成功率，从而学会指导不同子任务的LLM选择。

Result: 实验结果表明，与其他的LLM选择算法相比，该方法在电信问答和医学诊断预测数据集上表现出了有效性。

Conclusion: 该研究提出了一种基于神经网络上下文老虎机的方法，可以学习和适应LLM在子任务上的选择，即使在没有历史LLM性能数据的情况下也能实现。

Abstract: With the increasing popularity of large language models (LLMs) for a variety
of tasks, there has been a growing interest in strategies that can predict
which out of a set of LLMs will yield a successful answer at low cost. This
problem promises to become more and more relevant as providers like Microsoft
allow users to easily create custom LLM "assistants" specialized to particular
types of queries. However, some tasks (i.e., queries) may be too specialized
and difficult for a single LLM to handle alone. These applications often
benefit from breaking down the task into smaller subtasks, each of which can
then be executed by a LLM expected to perform well on that specific subtask.
For example, in extracting a diagnosis from medical records, one can first
select an LLM to summarize the record, select another to validate the summary,
and then select another, possibly different, LLM to extract the diagnosis from
the summarized record. Unlike existing LLM selection or routing algorithms,
this setting requires that we select a sequence of LLMs, with the output of
each LLM feeding into the next and potentially influencing its success. Thus,
unlike single LLM selection, the quality of each subtask's output directly
affects the inputs, and hence the cost and success rate, of downstream LLMs,
creating complex performance dependencies that must be learned and accounted
for during selection. We propose a neural contextual bandit-based algorithm
that trains neural networks that model LLM success on each subtask in an online
manner, thus learning to guide the LLM selections for the different subtasks,
even in the absence of historical LLM performance data. Experiments on
telecommunications question answering and medical diagnosis prediction datasets
illustrate the effectiveness of our proposed approach compared to other LLM
selection algorithms.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [168] [Re-thinking Memory-Bound Limitations in CGRAs](https://arxiv.org/abs/2508.09570)
*Xiangfeng Liu,Zhe Jiang,Anzhen Zhu,Xiaomeng Han,Mingsong Lyu,Qingxu Deng,Nan Guan*

Main category: cs.AR

TL;DR: 为了解决CGRA在处理不规则内存访问时性能下降的问题，提出了一种新的内存子系统和优化方法，通过超前执行和缓存重配置技术，在节省大量存储空间的同时，实现了与传统SPM系统相当的性能，并显著提升了CGRA在不规则内存访问场景下的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的CGRA优化研究假设内核可以从SPM访问所有数据，但忽略了图分析、不规则数据库操作和非结构化网格模拟等复杂工作负载中的不规则内存访问模式，这会导致CGRA利用率下降，成为内存瓶颈。

Method: 通过对性能下降的根本原因进行分析，提出了一种重新设计的内存子系统，并改进了内存模型。结合微架构和理论优化，利用CGRA特定的超前执行机制和缓存重新配置技术来管理不规则内存访问。

Result: 所提出的解决方案实现了与原始SPM-only系统相当的性能，同时存储空间仅占1.27%。超前执行机制平均实现了3.04倍的加速（最高可达6.91倍），而缓存重新配置技术提供了额外的6.02%性能提升。

Conclusion: 研究表明，所提出的内存子系统和优化方法能够有效地管理不规则内存访问，使CGRA在不规则内存访问模式下实现与原始SPM系统相当的性能，同时存储空间仅为原来的1.27%。

Abstract: Coarse-Grained Reconfigurable Arrays (CGRAs) are specialized accelerators
commonly employed to boost performance in workloads with iterative structures.
Existing research typically focuses on compiler or architecture optimizations
aimed at improving CGRA performance, energy efficiency, flexibility, and area
utilization, under the idealistic assumption that kernels can access all data
from Scratchpad Memory (SPM). However, certain complex workloads-particularly
in fields like graph analytics, irregular database operations, and specialized
forms of high-performance computing (e.g., unstructured mesh
simulations)-exhibit irregular memory access patterns that hinder CGRA
utilization, sometimes dropping below 1.5%, making the CGRA memory-bound. To
address this challenge, we conduct a thorough analysis of the underlying causes
of performance degradation, then propose a redesigned memory subsystem and
refine the memory model. With both microarchitectural and theoretical
optimization, our solution can effectively manage irregular memory accesses
through CGRA-specific runahead execution mechanism and cache reconfiguration
techniques. Our results demonstrate that we can achieve performance comparable
to the original SPM-only system while requiring only 1.27% of the storage size.
The runahead execution mechanism achieves an average 3.04x speedup (up to
6.91x), with cache reconfiguration technique providing an additional 6.02%
improvement, significantly enhancing CGRA performance for irregular memory
access patterns.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [169] [Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer](https://arxiv.org/abs/2508.09144)
*Liping Huang,Yicheng Zhang,Yifang Yin,Sheng Zhang,Yi Zhang*

Main category: cs.LG

TL;DR: 本研究提出了一种基于 Transformer 的飞机 ETA 预测模型，该模型通过特征标记化和自注意力机制提高了预测准确性和效率。实验结果表明，与 XGBoost 相比，该模型准确性提升 7%，计算时间减少 61%，非常适合实时航空到达管理。


<details>
  <summary>Details</summary>
Motivation: 实时估计飞机到达时间（ETA）对于航空领域（尤其是跑道排序）的到达管理至关重要。考虑到空域环境的快速变化，ETA 预测的效率与其准确性同样重要。

Method: 研究提出了一种基于特征标记化（feature tokenization）的 Transformer 模型来高效预测飞机到达时间（ETA）。该模型通过将原始输入映射到潜在空间，并利用 Transformer 的多头自注意力机制捕捉重要特征，从而减少了复杂的特征工程。Transformer 的并行计算能力使其能够处理高频率（1Hz）的 ETA 请求。模型输入包括飞机的纬度、经度、地面速度、机场theta角度、航迹数据中的日期和小时、天气情况以及飞机尾流类别。

Result: 在新加坡樟宜机场（WSSS）使用 2022 年 10 月 1 日至 10 月 31 日一个月的 ADS-B 数据进行的实验评估显示，该方法比常用的基于提升树的模型（XGBoost）准确性提高了 7%，计算时间仅为 XGBoost 的 39%。在有 40 架飞机的情况下，ETA 推理时间仅为 51.7 微秒。

Conclusion: 该研究提出的基于特征标记化 Transformer 的飞机 ETA 预测方法在新加坡樟宜机场（WSSS）的实际数据上进行了验证，结果表明该方法比常用的基于提升树的模型（XGBoost）在准确性上提高了 7%，同时计算时间仅为其 39%。此外，在给定时间戳下有 40 架飞机时，ETA 推理时间仅为 51.7 微秒，证明了其在实时到达管理系统中的潜力。

Abstract: Estimated time of arrival (ETA) for airborne aircraft in real-time is crucial
for arrival management in aviation, particularly for runway sequencing. Given
the rapidly changing airspace context, the ETA prediction efficiency is as
important as its accuracy in a real-time arrival aircraft management system. In
this study, we utilize a feature tokenization-based Transformer model to
efficiently predict aircraft ETA. Feature tokenization projects raw inputs to
latent spaces, while the multi-head self-attention mechanism in the Transformer
captures important aspects of the projections, alleviating the need for complex
feature engineering. Moreover, the Transformer's parallel computation
capability allows it to handle ETA requests at a high frequency, i.e., 1HZ,
which is essential for a real-time arrival management system. The model inputs
include raw data, such as aircraft latitude, longitude, ground speed, theta
degree for the airport, day and hour from track data, the weather context, and
aircraft wake turbulence category. With a data sampling rate of 1HZ, the ETA
prediction is updated every second. We apply the proposed aircraft ETA
prediction approach to Singapore Changi Airport (ICAO Code: WSSS) using
one-month Automatic Dependent Surveillance-Broadcast (ADS-B) data from October
1 to October 31, 2022. In the experimental evaluation, the ETA modeling covers
all aircraft within a range of 10NM to 300NM from WSSS. The results show that
our proposed method method outperforms the commonly used boosting tree based
model, improving accuracy by 7\% compared to XGBoost, while requiring only 39\%
of its computing time. Experimental results also indicate that, with 40
aircraft in the airspace at a given timestamp, the ETA inference time is only
51.7 microseconds, making it promising for real-time arrival management
systems.

</details>


### [170] [MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI](https://arxiv.org/abs/2508.09500)
*Zijun Jiang,Yangdi Lyu*

Main category: cs.LG

TL;DR: MiCo框架通过新颖的优化算法和硬件感知延迟模型，解决了现有混合精度量化（MPQ）算法的局限性，实现了高效的MPQ方案探索和端到端的模型部署，在保证准确率的同时提高了边缘AI应用的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的混合精度量化（MPQ）算法在灵活性和效率方面存在局限性，难以理解不同MPQ方案对量化后训练和感知量化训练结果的复杂影响，并且缺乏端到端的MPQ模型优化和部署框架。

Method: MiCo框架采用一种新颖的优化算法来搜索最佳量化方案，并构建了针对不同硬件目标的硬件感知延迟模型，以实现快速探索和部署。

Result: MiCo框架能够为边缘AI应用提供一个整体的混合精度量化（MPQ）探索和部署框架，在满足延迟约束的同时搜索具有最高准确率的最佳量化方案，并支持从PyTorch MPQ模型到裸机C代码的直接部署，从而实现端到端的加速，同时最大限度地减少准确率下降。

Conclusion: MiCo框架能够为边缘AI应用提供一个整体的混合精度量化（MPQ）探索和部署框架。它采用新颖的优化算法，在满足延迟约束的同时搜索具有最高准确率的最佳量化方案。该框架还内置了针对不同硬件目标的硬件感知延迟模型，以实现快速探索，并支持从PyTorch MPQ模型到裸机C代码的直接部署，从而实现端到端的加速，同时最大限度地减少准确率下降。

Abstract: Quantized Neural Networks (QNN) with extremely low-bitwidth data have proven
promising in efficient storage and computation on edge devices. To further
reduce the accuracy drop while increasing speedup, layer-wise mixed-precision
quantization (MPQ) becomes a popular solution. However, existing algorithms for
exploring MPQ schemes are limited in flexibility and efficiency. Comprehending
the complex impacts of different MPQ schemes on post-training quantization and
quantization-aware training results is a challenge for conventional methods.
Furthermore, an end-to-end framework for the optimization and deployment of MPQ
models is missing in existing work.
  In this paper, we propose the MiCo framework, a holistic MPQ exploration and
deployment framework for edge AI applications. The framework adopts a novel
optimization algorithm to search for optimal quantization schemes with the
highest accuracies while meeting latency constraints. Hardware-aware latency
models are built for different hardware targets to enable fast explorations.
After the exploration, the framework enables direct deployment from PyTorch MPQ
models to bare-metal C codes, leading to end-to-end speedup with minimal
accuracy drops.

</details>


### [171] [MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.09145)
*Xingle Xu,Yongkang Liu,Dexian Cai,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.LG

TL;DR: MoLAN 框架通过将模态特征分块并动态调整去噪强度来解决多模态情感分析中的噪声问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态情感分析方法在处理不相关或误导性的视觉和听觉信息时存在困难，通常会抑制冗余和噪声信息，但可能会丢失关键信息。为了解决这个问题，需要一种能够进行细粒度噪声抑制并保留关键多模态信息的方法。

Method: 提出了一种名为 MoLAN 的统一 ModaLity 感知噪声动态编辑框架。该框架通过将每个模态的特征分成多个块，并根据噪声水平和语义相关性为每个块动态分配不同的去噪强度，从而实现细粒度的噪声抑制，同时保留关键的多模态信息。MoLAN 是一个统一且灵活的框架，可以无缝集成到各种多模态模型中。在此框架的基础上，还提出了 MoLAN+ 方法。

Result: MoLAN 框架被证明是广泛有效的，并且 MoLAN+ 方法达到了最先进的性能。

Conclusion: MoLAN+ 在五个模型和四个数据集上的实验证明了 MoLAN 框架的广泛有效性，并达到了最先进的性能。

Abstract: Multimodal Sentiment Analysis aims to integrate information from various
modalities, such as audio, visual, and text, to make complementary predictions.
However, it often struggles with irrelevant or misleading visual and auditory
information. Most existing approaches typically treat the entire modality
information (e.g., a whole image, audio segment, or text paragraph) as an
independent unit for feature enhancement or denoising. They often suppress the
redundant and noise information at the risk of losing critical information. To
address this challenge, we propose MoLAN, a unified ModaLity-aware noise
dynAmic editiNg framework. Specifically, MoLAN performs modality-aware blocking
by dividing the features of each modality into multiple blocks. Each block is
then dynamically assigned a distinct denoising strength based on its noise
level and semantic relevance, enabling fine-grained noise suppression while
preserving essential multimodal information. Notably, MoLAN is a unified and
flexible framework that can be seamlessly integrated into a wide range of
multimodal models. Building upon this framework, we further introduce MoLAN+, a
new multimodal sentiment analysis approach. Experiments across five models and
four datasets demonstrate the broad effectiveness of the MoLAN framework.
Extensive evaluations show that MoLAN+ achieves the state-of-the-art
performance. The code is publicly available at
https://github.com/betterfly123/MoLAN-Framework.

</details>


### [172] [To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA](https://arxiv.org/abs/2508.09146)
*Shugang Hao,Hongbo Li,Lingjie Duan*

Main category: cs.LG

TL;DR: 本研究提出了一种创新的基于LLM Transformer的ICL方法，用于优化WiFi 7的信道接入。该方法通过学习碰撞阈值数据示例来预测竞争窗口阈值，即使在数据不完美的情况下也能保持高精度。实验证明，该方法在处理未知节点密度时，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的WiFi 7二元指数退避算法在动态信道环境下性能不佳。现有的基于模型的方法（如非持久和p持久CSMA）在优化退避策略时，通常假设节点密度是已知且固定的，这会导致因节点密度估计不准确而产生较大的吞吐量损失。因此，需要一种新的方法来优化信道接入，以应对动态信道环境和未知的节点密度。

Method: 提出了一种基于Transformer的 in-context learning (ICL) 优化器，用于优化WiFi 7中的信道接入。该优化器通过将预先收集的碰撞阈值数据示例和查询碰撞案例构建成提示（prompt）作为输入，来学习模式并预测竞争窗口阈值（CWT）。为了实现有效的ICL，研究开发了一种高效的算法，并保证在有限的训练步骤内能进行近乎最优的CWT预测。此外，该研究还允许在提示中输入可能包含错误的数据，并证明了优化器在这种情况下仍能保持最小的预测和吞吐量偏差。

Result: 实验结果表明，该方法在节点密度未知的情况下，相比于现有的基于模型和基于DRL的方法，具有更快的收敛速度和更优的吞吐量。

Conclusion: 该研究首次提出使用LLM transformer的 in-context learning (ICL) 理论来优化WiFi 7中的信道接入，并设计了一个基于transformer的ICL优化器，通过预先收集的碰撞阈值数据示例和查询碰撞案例作为提示（prompt）输入，来学习模式并预测竞争窗口阈值（CWT）。研究还开发了一种有效的算法来训练transformer以实现有效的ICL，并保证在有限的训练步骤内能进行近乎最优的CWT预测。此外，该研究还扩展了ICL的适用性，允许在提示中输入错误的数据，并证明了即使在数据有误的情况下，优化器也能保持最小的预测和吞吐量偏差。NS-3上的实验结果表明，在节点密度未知的情况下，该方法比现有的基于模型和基于DRL的方法具有更快的收敛速度和更优的吞吐量。

Abstract: The binary exponential backoff scheme is widely used in WiFi 7 and still
incurs poor throughput performance under dynamic channel environments. Recent
model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply
optimize backoff strategies under a known and fixed node density, still leading
to a large throughput loss due to inaccurate node density estimation. This
paper is the first to propose LLM transformer-based in-context learning (ICL)
theory for optimizing channel access. We design a transformer-based ICL
optimizer to pre-collect collision-threshold data examples and a query
collision case. They are constructed as a prompt as the input for the
transformer to learn the pattern, which then generates a predicted contention
window threshold (CWT). To train the transformer for effective ICL, we develop
an efficient algorithm and guarantee a near-optimal CWT prediction within
limited training steps. As it may be hard to gather perfect data examples for
ICL in practice, we further extend to allow erroneous data input in the prompt.
We prove that our optimizer maintains minimal prediction and throughput
deviations from the optimal values. Experimental results on NS-3 further
demonstrate our approach's fast convergence and near-optimal throughput over
existing model-based and DRL-based approaches under unknown node densities.

</details>


### [173] [Online Prediction with Limited Selectivity](https://arxiv.org/abs/2508.09592)
*Licheng Liu,Mingda Qiao*

Main category: cs.LG

TL;DR: 本文提出了预测有限选择性（PLS）模型，并研究了其最优预测误差，引入的复杂性度量与随机实例高度匹配。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是研究选择性预测模型，该模型允许预测器自由决定其预测跨度的时间窗口。然而，现有的结果依赖于预测器可以随时进行预测的假设。因此，本文旨在探索在预测器只能在时间范围的子集上开始预测的情况下，最优预测误差的行为。

Method: 本文首先介绍了选择性预测模型，然后提出了预测有限选择性（PLS）模型，在该模型中，预测器只能在时间范围的子集上开始预测。接着，本文分别从实例到实例和平均情况的分析研究了最优预测误差，并引入了一个复杂性度量，该度量为最优误差提供了依赖于实例的边界。

Result: 对于随机生成的PLS实例，本文提出的复杂性度量能够高度匹配实例的边界。

Conclusion: 所提出的预测有限选择性（PLS）模型在实例和平均情况下都研究了最优预测误差，并且引入了一个依赖于实例的复杂性度量，该度量与随机生成的PLS实例的边界高度吻ched。

Abstract: Selective prediction [Dru13, QV19] models the scenario where a forecaster
freely decides on the prediction window that their forecast spans. Many data
statistics can be predicted to a non-trivial error rate without any
distributional assumptions or expert advice, yet these results rely on that the
forecaster may predict at any time. We introduce a model of Prediction with
Limited Selectivity (PLS) where the forecaster can start the prediction only on
a subset of the time horizon. We study the optimal prediction error both on an
instance-by-instance basis and via an average-case analysis. We introduce a
complexity measure that gives instance-dependent bounds on the optimal error.
For a randomly-generated PLS instance, these bounds match with high
probability.

</details>


### [174] [Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.09275)
*Amine Andam,Jamal Bentahar,Mustapha Hedabou*

Main category: cs.LG

TL;DR: 本论文研究了协作多智能体强化学习（c-MARL）在现实条件下易受对抗性攻击的漏洞，并提出了一种高效的攻击算法，只需少量样本即可成功误导智能体。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注训练时攻击或访问策略权重、训练替代策略等不切实际的场景，缺乏对c-MARL在更现实、受限条件下遭受对抗性攻击的漏洞的深入研究。

Method: 提出了一种简单但有效的算法，用于生成对抗性扰动，以误导受害者智能体感知环境。

Result: 在三个基准和22个环境中进行了实证验证，证明了该算法的有效性，并且仅需1000个样本，而先前的方法需要数百万个样本。

Conclusion: 本篇论文研究了在更真实、受限的条件下，协作多智能体强化学习（c-MARL）在面对对抗性攻击时的新漏洞，并提出了一种简单但有效的算法来生成对抗性扰动，以误导受害者智能体感知环境，并在多个基准和环境中进行了实证验证，证明了其跨算法和环境的有效性，以及样本效率。

Abstract: Collaborative multi-agent reinforcement learning (c-MARL) has rapidly
evolved, offering state-of-the-art algorithms for real-world applications,
including sensitive domains. However, a key challenge to its widespread
adoption is the lack of a thorough investigation into its vulnerabilities to
adversarial attacks. Existing work predominantly focuses on training-time
attacks or unrealistic scenarios, such as access to policy weights or the
ability to train surrogate policies. In this paper, we investigate new
vulnerabilities under more realistic and constrained conditions, assuming an
adversary can only collect and perturb the observations of deployed agents. We
also consider scenarios where the adversary has no access at all. We propose
simple yet highly effective algorithms for generating adversarial perturbations
designed to misalign how victim agents perceive their environment. Our approach
is empirically validated on three benchmarks and 22 environments, demonstrating
its effectiveness across diverse algorithms and environments. Furthermore, we
show that our algorithm is sample-efficient, requiring only 1,000 samples
compared to the millions needed by previous methods.

</details>


### [175] [Motif 2.6B Technical Report](https://arxiv.org/abs/2508.09148)
*Junghwan Lim,Sungmin Lee,Dongseok Kim,Eunhwan Park,Hyunbyung Park,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Jihwan Kim,Minjae Kim,Taehwan Kim,Youngrok Kim,Haesol Lee,Jeesoo Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Daewon Suh,Dongjoo Weon*

Main category: cs.LG

TL;DR: 介绍Motif-2.6B，一个2.6B参数的高效基础LLM，采用新架构，性能优越，易于研究机构使用。


<details>
  <summary>Details</summary>
Motivation: 为了解决新兴研究机构在开发高性能、计算高效的基础LLM方面面临的挑战，旨在实现LLM能力的民主化。

Method: 通过引入Differential Attention和PolyNorm激活函数等创新架构，并经过大量实验优化，构建了Motif-2.6B模型。

Result: Motif-2.6B在各项基准测试中表现优于或持平于同等规模的先进模型，证明了其有效性、可扩展性和实际应用潜力。

Conclusion: Motif-2.6B通过创新的架构设计和广泛的实验验证，在性能、效率和可扩展性方面取得了显著进展，为研究机构提供了强大且易于部署的基础LLM解决方案。

Abstract: Recent advancements in Large Language Models (LLMs) have revolutionized
artificial intelligence, yet developing an effective foundational LLM that
balances high performance with computational efficiency remains challenging,
especially for emerging research groups. To address this gap, we introduce
Motif-2.6B, a 2.6-billion-parameter foundation model designed to democratize
advanced LLM capabilities. Motif-2.6B incorporates several innovative
architectural enhancements, including Differential Attention and PolyNorm
activation functions, which improve long-context comprehension, reduce
hallucination, and enhance in-context learning capabilities. We rigorously
tested multiple novel architectural components through extensive
experimentation to determine the optimal architecture for Motif-2.6B.
Comprehensive evaluations demonstrate that Motif-2.6B consistently meets or
exceeds the performance of similarly sized state-of-the-art models across
diverse benchmarks, showcasing its effectiveness, scalability, and real-world
applicability. Through detailed experiments and tailored techniques, Motif-2.6B
significantly advances the landscape of efficient, scalable, and powerful
foundational LLMs, offering valuable insights and a robust foundation for
future research and deployment.

</details>


### [176] [JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis](https://arxiv.org/abs/2508.09153)
*TaekHyun Park,Yongjae Lee,Daesan Park,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: This paper questions the necessity of complex sequence mixers in time series analysis, proposing JustDense to replace them with dense layers. Experiments show dense layers perform comparably or better, challenging the need for complex architectures.


<details>
  <summary>Details</summary>
Motivation: Recent studies have questioned the necessity of complex sequence mixers, such as attention mechanisms, demonstrating that simpler architectures can achieve comparable or even superior performance. This suggests that the benefits attributed to complex sequence mixers might instead emerge from other architectural or optimization factors.

Method: JustDense systematically replaces sequence mixers in various well-established TSA models with dense layers. Grounded in the MatrixMixer framework, JustDense treats any sequence mixer as a mixing matrix and replaces it with a dense layer.

Result: Replacing sequence mixers with dense layers yields comparable or even superior performance across 29 benchmarks covering five representative TSA tasks using seven state-of-the-art TSA models.

Conclusion: The results show that replacing sequence mixers with dense layers yields comparable or even superior performance. In the cases where dedicated sequence mixers still offer benefits, JustDense challenges the assumption that "deeper and more complex architectures are inherently better" in TSA.

Abstract: Sequence and channel mixers, the core mechanism in sequence models, have
become the de facto standard in time series analysis (TSA). However, recent
studies have questioned the necessity of complex sequence mixers, such as
attention mechanisms, demonstrating that simpler architectures can achieve
comparable or even superior performance. This suggests that the benefits
attributed to complex sequencemixers might instead emerge from other
architectural or optimization factors. Based on this observation, we pose a
central question: Are common sequence mixers necessary for time-series
analysis? Therefore, we propose JustDense, an empirical study that
systematically replaces sequence mixers in various well-established TSA models
with dense layers. Grounded in the MatrixMixer framework, JustDense treats any
sequence mixer as a mixing matrix and replaces it with a dense layer. This
substitution isolates the mixing operation, enabling a clear theoretical
foundation for understanding its role. Therefore, we conducted extensive
experiments on 29 benchmarks covering five representative TSA tasks using seven
state-of-the-art TSA models to address our research question. The results show
that replacing sequence mixers with dense layers yields comparable or even
superior performance. In the cases where dedicated sequence mixers still offer
benefits, JustDense challenges the assumption that "deeper and more complex
architectures are inherently better" in TSA.

</details>


### [177] [Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders](https://arxiv.org/abs/2508.09154)
*Xiaojing Du,Jiuyong Li,Lin Liu,Debo Cheng,Thuc. Le*

Main category: cs.LG

TL;DR: A novel deep learning framework, DIG2RSI, effectively addresses simultaneous feedback and unobserved confounding in peer causal effect estimation within complex networks by combining I-G transformation and 2SRI, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Estimating peer causal effects within complex real-world networks such as social networks is challenging, primarily due to simultaneous feedback between peers and unobserved confounders. Existing methods either address unobserved confounders while ignoring the simultaneous feedback, or account for feedback but under restrictive linear assumptions, thus failing to obtain accurate peer effect estimation.

Method: DIG2RSI, a novel Deep learning framework which leverages I-G transformation (matrix operation) and 2SRI (an instrumental variable or IV technique) to address both simultaneous feedback and unobserved confounding, while accommodating complex, nonlinear and high-dimensional relationships. DIG2RSI first applies the I-G transformation to disentangle mutual peer influences and eliminate the bias due to the simultaneous feedback. In stage 1 of 2RSI, a neural network is trained on IVs to predict peer exposure, and residuals are extracted as proxies for the unobserved confounders. In stage 2, a separate neural network augmented by an adversarial discriminator incorporates these residuals as a control function and enforces the learned representation to contain no residual confounding signal.

Result: Empirical results on two semi-synthetic benchmarks and a real-world dataset demonstrate that DIG2RSI outperforms existing approaches.

Conclusion: DIG2RSI outperforms existing approaches in empirical results on two semi-synthetic benchmarks and a real-world dataset, and its consistency is proven under standard regularity conditions.

Abstract: Estimating peer causal effects within complex real-world networks such as
social networks is challenging, primarily due to simultaneous feedback between
peers and unobserved confounders. Existing methods either address unobserved
confounders while ignoring the simultaneous feedback, or account for feedback
but under restrictive linear assumptions, thus failing to obtain accurate peer
effect estimation. In this paper, we propose DIG2RSI, a novel Deep learning
framework which leverages I-G transformation (matrix operation) and 2SRI (an
instrumental variable or IV technique) to address both simultaneous feedback
and unobserved confounding, while accommodating complex, nonlinear and
high-dimensional relationships. DIG2RSI first applies the I-G transformation to
disentangle mutual peer influences and eliminate the bias due to the
simultaneous feedback. To deal with unobserved confounding, we first construct
valid IVs from network data. In stage 1 of 2RSI, we train a neural network on
these IVs to predict peer exposure, and extract residuals as proxies for the
unobserved confounders. In the stage 2, we fit a separate neural network
augmented by an adversarial discriminator that incorporates these residuals as
a control function and enforces the learned representation to contain no
residual confounding signal. The expressive power of deep learning models in
capturing complex non-linear relationships and adversarial debiasing enhances
the effectiveness of DIG2RSI in eliminating bias from both feedback loops and
hidden confounders. We prove consistency of our estimator under standard
regularity conditions, ensuring asymptotic recovery of the true peer effect.
Empirical results on two semi-synthetic benchmarks and a real-world dataset
demonstrate that DIG2RSI outperforms existing approaches.

</details>


### [178] [A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models](https://arxiv.org/abs/2508.09155)
*Wenkai Wang,Hongcan Guo,Zheqi Lv,Shengyu Zhang*

Main category: cs.LG

TL;DR: AdaPO是一个在线强化学习框架，通过自适应调整训练目标和引入新的正则化机制，显著提升了大型多模态模型在多轮对话中的自我评估和推理能力，解决了现有方法的奖励冒充问题。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）在多轮对话中实现自我改进需要具备自我评估能力，但现有基础模型缺乏此能力。先前的强化学习方法存在奖励固定机制，在优化多个训练目标时会遭受奖励冒充问题，导致模型崩溃。

Method: AdaPO框架通过引入自适应奖励模型（ARM）和奖励感知动态KL正则化机制来解决奖励冒充问题。ARM根据模型生成的轮次轨迹性能分布评估任务的训练状态，而奖励感知动态KL正则化则使用动态系数替换固定惩罚，并根据不同轮次情况下的奖励差距进行调整，从而实现对学习焦点的自动、平滑调整。

Result: 实验结果表明，AdaPO框架在8个基准测试和多种模型上显著提升了模型的直接推理和自我评估能力。此外，该方法无需人工干预即可根据子任务的训练进展自动调整学习焦点。

Conclusion: 该研究提出了一种名为AdaPO的在线强化学习框架，用于解决大型多模态模型（LMMs）在多轮对话中自我评估能力不足的问题，并通过自适应调整训练目标来提升自我改进能力。

Abstract: Self-evaluation, a model's ability to assess the correctness of its own
output, is crucial for Large Multimodal Models (LMMs) to achieve
self-improvement in multi-turn conversations, yet largely absent in foundation
models. Recent work has employed reinforcement learning (RL) to enhance
self-evaluation; however, its fixed reward mechanism suffers from reward
hacking when optimizing multiple training objectives, leading to model
collapse. In this paper we propose AdaPO, an online reinforcement learning
framework capable of adaptively adjusting training objective in real time
according to the current training state for each task. Specifically, to
mitigate reward hacking , AdaPO introduces an Adaptive Reward Model (ARM) and a
Reward Aware Dynamic KL Regularization mechanism. ARM assesses the task's
training state from the distribution of model generated multi-turn
trajectories' performance. Reward Aware Dynamic KL replaces a fixed penalty
with dynamic coefficients which is modulated by the reward gap between
different multi-turn situations. Notably, our method automatically and smoothly
adjusts its learning focus based on sub-tasks' training progress without manual
intervention. Extensive experiments over 8 benchmarks and various models show
that our method significantly enhances both direct reasoning and
self-evaluation capability. We will release our code to contribute to the
community.

</details>


### [179] [Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems](https://arxiv.org/abs/2508.09156)
*Jan Tauberschmidt,Sophie Fellenz,Sebastian J. Vollmer,Andrew B. Duncan*

Main category: cs.LG

TL;DR: A new framework fine-tunes generative models to be physics-aware, solving inverse problems by enforcing physical laws and predicting hidden parameters, improving scientific discovery and modeling.


<details>
  <summary>Details</summary>
Motivation: To develop a framework for fine-tuning generative models to enforce physical constraints and solve inverse problems in scientific systems, making data-driven models physics-aware.

Method: A differentiable post-training procedure minimizes weak-form residuals of PDEs, combined with a learnable latent parameter predictor and joint optimization strategy to infer unknown physical inputs.

Result: The model produces physically valid field solutions and plausible estimates of hidden parameters, effectively addressing ill-posed inverse problems, with validated improvements on canonical PDE benchmarks.

Conclusion: This framework enables fine-tuning flow-matching generative models for physical systems, improving PDE constraint satisfaction and latent coefficient recovery, bridging generative modeling and scientific inference for simulation-augmented discovery and data-efficient modeling.

Abstract: We present a framework for fine-tuning flow-matching generative models to
enforce physical constraints and solve inverse problems in scientific systems.
Starting from a model trained on low-fidelity or observational data, we apply a
differentiable post-training procedure that minimizes weak-form residuals of
governing partial differential equations (PDEs), promoting physical consistency
and adherence to boundary conditions without distorting the underlying learned
distribution. To infer unknown physical inputs, such as source terms, material
parameters, or boundary data, we augment the generative process with a
learnable latent parameter predictor and propose a joint optimization strategy.
The resulting model produces physically valid field solutions alongside
plausible estimates of hidden parameters, effectively addressing ill-posed
inverse problems in a data-driven yet physicsaware manner. We validate our
method on canonical PDE benchmarks, demonstrating improved satisfaction of PDE
constraints and accurate recovery of latent coefficients. Our approach bridges
generative modelling and scientific inference, opening new avenues for
simulation-augmented discovery and data-efficient modelling of physical
systems.

</details>


### [180] [EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.09158)
*Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng*

Main category: cs.LG

TL;DR: EvaDrive是一个新颖的多目标强化学习框架，通过对抗优化解决了自动驾驶中迭代决策的挑战，实现了类似人类的、无标量化的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 当前的轨迹生成-评估框架将轨迹生成与质量评估隔离开来，阻碍了规划中至关重要的迭代细化。同时，强化学习方法将多维偏好压缩成标量奖励，模糊了关键的权衡，并产生了标量化偏差。

Method: EvaDrive是一个新颖的多目标强化学习框架，通过对抗优化在轨迹生成和评估之间建立真正的闭环协同进化。它将轨迹规划视为一个多轮对抗博弈，其中一个分层生成器通过结合用于时间因果关系的自回归意图建模和用于空间灵活性的扩散式细化来不断提出候选路径。一个可训练的多目标评论家对这些提案进行严格评估，明确保留了多样化的偏好结构，避免了标量化偏差。这种由帕累托前沿选择机制指导的对抗交互实现了迭代多轮细化，有效地避开了局部最优并保持了轨迹多样性。

Result: EvaDrive在NAVSIM和Bench2Drive基准测试上进行了广泛实验，取得了最先进的性能，在NAVSIM v1上实现了94.9 PDMS（比DiffusionDrive高6.8，比DriveSuprim高5.0，比TrajHF高0.9），在Bench2Drive上实现了64.96的驾驶得分。

Conclusion: EvaDrive通过动态加权生成多样化的驾驶风格，无需外部偏好数据，引入了闭环对抗框架来实现类似人类的迭代决策，并提出了一种新颖的无标量化轨迹优化方法。

Abstract: Autonomous driving faces significant challenges in achieving human-like
iterative decision-making, which continuously generates, evaluates, and refines
trajectory proposals. Current generation-evaluation frameworks isolate
trajectory generation from quality assessment, preventing iterative refinement
essential for planning, while reinforcement learning methods collapse
multi-dimensional preferences into scalar rewards, obscuring critical
trade-offs and yielding scalarization bias.To overcome these issues, we present
EvaDrive, a novel multi-objective reinforcement learning framework that
establishes genuine closed-loop co-evolution between trajectory generation and
evaluation via adversarial optimization. EvaDrive frames trajectory planning as
a multi-round adversarial game. In this game, a hierarchical generator
continuously proposes candidate paths by combining autoregressive intent
modeling for temporal causality with diffusion-based refinement for spatial
flexibility. These proposals are then rigorously assessed by a trainable
multi-objective critic that explicitly preserves diverse preference structures
without collapsing them into a single scalarization bias.This adversarial
interplay, guided by a Pareto frontier selection mechanism, enables iterative
multi-round refinement, effectively escaping local optima while preserving
trajectory diversity.Extensive experiments on NAVSIM and Bench2Drive benchmarks
demonstrate SOTA performance, achieving 94.9 PDMS on NAVSIM v1 (surpassing
DiffusionDrive by 6.8, DriveSuprim by 5.0, and TrajHF by 0.9) and 64.96 Driving
Score on Bench2Drive. EvaDrive generates diverse driving styles via dynamic
weighting without external preference data, introducing a closed-loop
adversarial framework for human-like iterative decision-making, offering a
novel scalarization-free trajectory optimization approach.

</details>


### [181] [Presenting DiaData for Research on Type 1 Diabetes](https://arxiv.org/abs/2508.09160)
*Beyza Cinar,Maria Maleshkova*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Type 1 diabetes (T1D) is an autoimmune disorder that leads to the destruction
of insulin-producing cells, resulting in insulin deficiency, as to why the
affected individuals depend on external insulin injections. However, insulin
can decrease blood glucose levels and can cause hypoglycemia. Hypoglycemia is a
severe event of low blood glucose levels ($\le$70 mg/dL) with dangerous side
effects of dizziness, coma, or death. Data analysis can significantly enhance
diabetes care by identifying personal patterns and trends leading to adverse
events. Especially, machine learning (ML) models can predict glucose levels and
provide early alarms. However, diabetes and hypoglycemia research is limited by
the unavailability of large datasets. Thus, this work systematically integrates
15 datasets to provide a large database of 2510 subjects with glucose
measurements recorded every 5 minutes. In total, 149 million measurements are
included, of which 4% represent values in the hypoglycemic range. Moreover, two
sub-databases are extracted. Sub-database I includes demographics, and
sub-database II includes heart rate data. The integrated dataset provides an
equal distribution of sex and different age levels. As a further contribution,
data quality is assessed, revealing that data imbalance and missing values
present a significant challenge. Moreover, a correlation study on glucose
levels and heart rate data is conducted, showing a relation between 15 and 55
minutes before hypoglycemia.

</details>


### [182] [Physics-Guided Memory Network for Building Energy Modeling](https://arxiv.org/abs/2508.09161)
*Muhammad Umair Danish,Kashif Ali,Kamran Siddiqui,Katarina Grolinger*

Main category: cs.LG

TL;DR: PgMN通过结合深度学习和物理模型来预测建筑能耗，解决了数据不足和建模时间长的问题，在各种场景下都表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在历史数据有限或不可用时（如新建建筑）的局限性，以及基于物理的模型需要大量建筑参数和建模时间的问题。

Method: PgMN是一种结合了深度学习和基于物理的模型预测的神经网络，包括用于处理不完整输入的并行投影层、用于考虑持久偏差的记忆单元以及用于优化预测范围的记忆体验模块。

Result: PgMN在短期逐时能源预测方面表现出准确性和适用性，能够处理新建建筑、数据缺失、历史数据稀疏和动态基础设施变化等多种场景。

Conclusion: PgMN为动态建筑环境中的能源消耗预测提供了一种有前途的解决方案，增强了模型在历史数据有限或不可用或物理模型不适用的场景中的适用性。

Abstract: Accurate energy consumption forecasting is essential for efficient resource
management and sustainability in the building sector. Deep learning models are
highly successful but struggle with limited historical data and become unusable
when historical data are unavailable, such as in newly constructed buildings.
On the other hand, physics-based models, such as EnergyPlus, simulate energy
consumption without relying on historical data but require extensive building
parameter specifications and considerable time to model a building. This paper
introduces a Physics-Guided Memory Network (PgMN), a neural network that
integrates predictions from deep learning and physics-based models to address
their limitations. PgMN comprises a Parallel Projection Layers to process
incomplete inputs, a Memory Unit to account for persistent biases, and a Memory
Experience Module to optimally extend forecasts beyond their input range and
produce output. Theoretical evaluation shows that components of PgMN are
mathematically valid for performing their respective tasks. The PgMN was
evaluated on short-term energy forecasting at an hourly resolution, critical
for operational decision-making in smart grid and smart building systems.
Experimental validation shows accuracy and applicability of PgMN in diverse
scenarios such as newly constructed buildings, missing data, sparse historical
data, and dynamic infrastructure changes. This paper provides a promising
solution for energy consumption forecasting in dynamic building environments,
enhancing model applicability in scenarios where historical data are limited or
unavailable or when physics-based models are inadequate.

</details>


### [183] [An Unsupervised Deep XAI Framework for Localization of Concurrent Replay Attacks in Nuclear Reactor Signals](https://arxiv.org/abs/2508.09162)
*Konstantinos Vasili,Zachery T. Dahm,William Richards,Stylianos Chatzidakis*

Main category: cs.LG

TL;DR: 提出了一种新的XAI框架，结合自编码器和windowSHAP，用于检测、识别和表征先进核反应堆中的重放攻击，并在真实数据集上实现了超过95%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前针对重放攻击的缓解措施大多依赖水印或监督式异常检测，未能识别和表征异常的根本原因，并且在数据模拟、单变量信号、平稳信号、线性二次调节器或线性时不变状态空间等方面存在局限性。此外，在受管制的核网络物理系统中，需要对重放攻击的表征以及使用真实数据进行预测的可解释性进行更多研究。

Method: 提出了一种基于自编码器和自定义windowSHAP算法的无监督可解释人工智能（XAI）框架，用于全面表征实时重放攻击。

Result: 所提出的XAI框架在多个真实数据集（来自普渡大学核反应堆PUR-1，最多同时重放六个信号）上进行了基准测试。

Conclusion: 该XAI框架能够以95%或更高的准确率检测并识别重放攻击的来源、数量以及伪造的持续时间。

Abstract: Next generation advanced nuclear reactors are expected to be smaller both in
size and power output, relying extensively on fully digital instrumentation and
control systems. These reactors will generate a large flow of information in
the form of multivariate time series data, conveying simultaneously various non
linear cyber physical, process, control, sensor, and operational states.
Ensuring data integrity against deception attacks is becoming increasingly
important for networked communication and a requirement for safe and reliable
operation. Current efforts to address replay attacks, almost universally focus
on watermarking or supervised anomaly detection approaches without further
identifying and characterizing the root cause of the anomaly. In addition,
these approaches rely mostly on synthetic data with uncorrelated Gaussian
process and measurement noise and full state feedback or are limited to
univariate signals, signal stationarity, linear quadratic regulators, or other
linear-time invariant state-space which may fail to capture any unmodeled
system dynamics. In the realm of regulated nuclear cyber-physical systems,
additional work is needed on characterization of replay attacks and
explainability of predictions using real data. Here, we propose an unsupervised
explainable AI framework based on a combination of autoencoder and customized
windowSHAP algorithm to fully characterize real-time replay attacks, i.e.,
detection, source identification, timing and type, of increasing complexity
during a dynamic time evolving reactor process. The proposed XAI framework was
benchmarked on several real world datasets from Purdue's nuclear reactor PUR-1
with up to six signals concurrently being replayed. In all cases, the XAI
framework was able to detect and identify the source and number of signals
being replayed and the duration of the falsification with 95 percent or better
accuracy.

</details>


### [184] [Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach](https://arxiv.org/abs/2508.09181)
*Jinghong Tan,Zhian Liu,Kun Guo,Mingxiong Zhao*

Main category: cs.LG

TL;DR: LCSFLA通过一种新的、具有保证金要求的拍卖机制来解决IoV环境中联邦学习中的非IID数据和客户选择问题，从而激励客户参与并确保信息的真实性，提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统客户选择指标在评估客户数据质量时存在缺陷，并且要求在所有客户完成本地训练后进行选择，这会导致资源浪费。在IoV环境中，信息不对称会增加客户提交虚假信息的风险，从而可能导致选择无效。因此，需要一种新的方法来解决这些挑战。

Method: 提出了一种基于公平拍卖的长期客户选择联邦学习（LCSFLA）方案，该方案通过新的评估机制和能源成本来考虑长期的长期数据质量，并利用具有保证金要求的拍卖机制来激励客户参与并确保信息的真实性。

Result: 实验结果表明，LCSFLA在包括IoV场景在内的各种数据集上，能有效缓解由非IID数据引起的性能下降。

Conclusion: LCSFLA通过考虑长期数据质量、新的评估机制和能源成本来最大化社会福利，并且其建议的拍卖机制具有保证金要求，可以激励客户参与并确保信息的真实性。理论上证明了所建议的激励机制的激励相容性和个体理性。在包括IoV场景在内的各种数据集上的实验结果表明，它在减轻由非IID数据引起的性能下降方面是有效的。

Abstract: Federated learning (FL) provides a decentralized framework that enables
universal model training through collaborative efforts on mobile nodes, such as
smart vehicles in the Internet of Vehicles (IoV). Each smart vehicle acts as a
mobile client, contributing to the process without uploading local data. This
method leverages non-independent and identically distributed (non-IID) training
data from different vehicles, influenced by various driving patterns and
environmental conditions, which can significantly impact model convergence and
accuracy. Although client selection can be a feasible solution for non-IID
issues, it faces challenges related to selection metrics. Traditional metrics
evaluate client data quality independently per round and require client
selection after all clients complete local training, leading to resource
wastage from unused training results. In the IoV context, where vehicles have
limited connectivity and computational resources, information asymmetry in
client selection risks clients submitting false information, potentially making
the selection ineffective. To tackle these challenges, we propose a novel
Long-term Client-Selection Federated Learning based on Truthful Auction
(LCSFLA). This scheme maximizes social welfare with consideration of long-term
data quality using a new assessment mechanism and energy costs, and the advised
auction mechanism with a deposit requirement incentivizes client participation
and ensures information truthfulness. We theoretically prove the incentive
compatibility and individual rationality of the advised incentive mechanism.
Experimental results on various datasets, including those from IoV scenarios,
demonstrate its effectiveness in mitigating performance degradation caused by
non-IID data.

</details>


### [185] [Energy-Efficient Stochastic Computing (SC) Neural Networks for Internet of Things Devices With Layer-Wise Adjustable Sequence Length (ASL)](https://arxiv.org/abs/2508.09163)
*Ziheng Wang,Pedro Reviriego,Farzad Niknia,Zhen Gao,Javier Conde,Shanshan Liu,Fabrizio Lombardi*

Main category: cs.LG

TL;DR: ASL是一种用于随机计算神经网络的新方案，通过混合精度和可调序列长度，在保持精度的同时显著降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 尽管随机计算（SC）作为一种高效的低功耗替代方案，在资源受限场景（如物联网）中部署神经网络（NN）具有潜力，但其层级混合精度实现的改进仍有待探索。

Method: 提出了一种名为可调序列长度（ASL）的新方案，将混合精度概念应用于随机计算神经网络。通过引入基于算子范数的理论模型，分析了截断噪声如何通过估计的放大因子在层之间累积传播。通过随机森林回归进行了扩展敏感性分析，以评估多层截断效应，并验证了理论预测与实际网络行为的一致性。为了适应不同的应用场景，提出了两种截断策略（粗粒度和细粒度），在每个层应用不同的序列长度配置。

Result: 在32nm工艺下合成的流水线SC MLP上进行评估，结果表明ASL可以将能耗和延迟开销降低高达60%以上，同时保持可忽略的精度损失。

Conclusion: ASL方案对于物联网应用是可行的，并且混合精度截断在随机计算设计中具有独特的优势。

Abstract: Stochastic computing (SC) has emerged as an efficient low-power alternative
for deploying neural networks (NNs) in resource-limited scenarios, such as the
Internet of Things (IoT). By encoding values as serial bitstreams, SC
significantly reduces energy dissipation compared to conventional
floating-point (FP) designs; however, further improvement of layer-wise
mixed-precision implementation for SC remains unexplored. This article
introduces Adjustable Sequence Length (ASL), a novel scheme that applies
mixed-precision concepts specifically to SC NNs. By introducing an
operator-norm-based theoretical model, this article shows that truncation noise
can cumulatively propagate through the layers by the estimated amplification
factors. An extended sensitivity analysis is presented, using random forest
(RF) regression to evaluate multilayer truncation effects and validate the
alignment of theoretical predictions with practical network behaviors. To
accommodate different application scenarios, this article proposes two
truncation strategies (coarse-grained and fine-grained), which apply diverse
sequence length configurations at each layer. Evaluations on a pipelined SC MLP
synthesized at 32nm demonstrate that ASL can reduce energy and latency
overheads by up to over 60% with negligible accuracy loss. It confirms the
feasibility of the ASL scheme for IoT applications and highlights the distinct
advantages of mixed-precision truncation in SC designs.

</details>


### [186] [Bayesian autoregression to optimize temporal Matérn kernel Gaussian process hyperparameters](https://arxiv.org/abs/2508.09792)
*Wouter M. Kouw*

Main category: cs.LG

TL;DR: 我们提出了一种优化高斯过程超参数的方法，该方法比现有方法更快、更准确。


<details>
  <summary>Details</summary>
Motivation: 高斯过程是概率数值领域的重要模型。

Method: 通过将优化问题转化为自回归模型参数的递归贝叶斯估计过程，来优化具有 Matérn 核时间高斯过程的核协方差函数的超参数。

Result: 所提出的程序在运行时间和高斯过程回归中的最终均方根误差方面均优于最大化边际似然和汉密尔顿蒙特卡洛采样。

Conclusion: 所提出的递归贝叶斯估计程序在运行时间和高斯过程回归中的最终均方根误差方面均优于最大化边际似然和汉密尔顿蒙特卡洛采样。

Abstract: Gaussian processes are important models in the field of probabilistic
numerics. We present a procedure for optimizing Mat\'ern kernel temporal
Gaussian processes with respect to the kernel covariance function's
hyperparameters. It is based on casting the optimization problem as a recursive
Bayesian estimation procedure for the parameters of an autoregressive model. We
demonstrate that the proposed procedure outperforms maximizing the marginal
likelihood as well as Hamiltonian Monte Carlo sampling, both in terms of
runtime and ultimate root mean square error in Gaussian process regression.

</details>


### [187] [Generating Feasible and Diverse Synthetic Populations Using Diffusion Models](https://arxiv.org/abs/2508.09164)
*Min Tang,Peng Lu,Qing Feng*

Main category: cs.LG

TL;DR: 一种新的人口合成方法，利用扩散模型来提高合成人口的真实性和多样性，优于现有的VAE和GAN方法。


<details>
  <summary>Details</summary>
Motivation: 在智能交通系统（ITS）的基于代理的建模（ABM）中，人口合成是生成真实人口表征的关键任务。然而，当代理的属性数量增加时，由于维度诅咒，调查数据难以密集支持人口的联合分布，导致难以准确建模和生成人口。

Method: 提出了一种新颖的基于扩散模型的人口合成方法，用于估计人口的潜在联合分布，该方法能够恢复大量的采样零，同时最大限度地减少生成结构零。

Result: 与VAE和GAN等方法相比，所提出的方法在合成人口的边际分布相似性、可行性和多样性方面表现更好，在可行性和多样性之间取得了更好的平衡。

Conclusion: 所提出的基于扩散模型的人口合成方法在合成人口的可行性和多样性方面取得了比以往方法更好的平衡，优于变分自编码器（VAE）和生成对抗网络（GAN）等方法。

Abstract: Population synthesis is a critical task that involves generating synthetic
yet realistic representations of populations. It is a fundamental problem in
agent-based modeling (ABM), which has become the standard to analyze
intelligent transportation systems. The synthetic population serves as the
primary input for ABM transportation simulation, with traveling agents
represented by population members. However, when the number of attributes
describing agents becomes large, survey data often cannot densely support the
joint distribution of the attributes in the population due to the curse of
dimensionality. This sparsity makes it difficult to accurately model and
produce the population. Interestingly, deep generative models trained from
available sample data can potentially synthesize possible attribute
combinations that present in the actual population but do not exist in the
sample data(called sampling zeros). Nevertheless, this comes at the cost of
falsely generating the infeasible attribute combinations that do not exist in
the population (called structural zeros). In this study, a novel diffusion
model-based population synthesis method is proposed to estimate the underlying
joint distribution of a population. This approach enables the recovery of
numerous missing sampling zeros while keeping the generated structural zeros
minimal. Our method is compared with other recently proposed approaches such as
Variational Autoencoders (VAE) and Generative Adversarial Network (GAN)
approaches, which have shown success in high dimensional tabular population
synthesis. We assess the performance of the synthesized outputs using a range
of metrics, including marginal distribution similarity, feasibility, and
diversity. The results demonstrate that our proposed method outperforms
previous approaches in achieving a better balance between the feasibility and
diversity of the synthesized population.

</details>


### [188] [Masked Training for Robust Arrhythmia Detection from Digitalized Multiple Layout ECG Images](https://arxiv.org/abs/2508.09165)
*Shanwei Zhang,Deyun Zhang,Yirao Tao,Kexin Wang,Shijia Geng,Jun Li,Qinghao Zhao,Xingpeng Liu,Yuxi Zhou,Shenda Hong*

Main category: cs.LG

TL;DR: PatchECG通过自适应可变块数缺失表示学习和掩码训练策略，解决了不同布局心电图的挑战，在心律失常识别上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的心电图分析模型在面对不同医院使用的不同心电图布局、数字化信号的异步前行时间和部分黑视丢失等挑战时，表现不佳。本研究旨在解决这些挑战。

Method: 提出了一种名为PatchECG的框架，该框架基于掩码训练策略，实现了自适应可变块数缺失表示学习，能够自动关注不同导联之间的关键块及其协同依赖关系，从而实现对不同布局心电图的心律失常关键识别。

Result: PatchECG框架在PTB-XL数据集和生成的数据集上，平均AUROC达到0.835，且不受布局变化影响。在Chaoyang医院的外部验证中，对房颤诊断的AUROC达到0.778，在12x1布局的心电图上AUROC达到0.893，优于现有方法和ECGFunder。

Conclusion: PatchECG框架在处理不同布局的心电图时表现出强大的鲁棒性，在PTB-XL数据集上的平均AUROC为0.835，并且在Chaoyang医院的真实心电图数据上验证了其有效性，优于现有方法，与ECGFunder相比有显著提升。

Abstract: Electrocardiogram (ECG) as an important tool for diagnosing cardiovascular
diseases such as arrhythmia. Due to the differences in ECG layouts used by
different hospitals, the digitized signals exhibit asynchronous lead time and
partial blackout loss, which poses a serious challenge to existing models. To
address this challenge, the study introduced PatchECG, a framework for adaptive
variable block count missing representation learning based on a masking
training strategy, which automatically focuses on key patches with
collaborative dependencies between leads, thereby achieving key recognition of
arrhythmia in ECGs with different layouts. Experiments were conducted on the
PTB-XL dataset and 21388 asynchronous ECG images generated using ECG image kit
tool, using the 23 Subclasses as labels. The proposed method demonstrated
strong robustness under different layouts, with average Area Under the Receiver
Operating Characteristic Curve (AUROC) of 0.835 and remained stable (unchanged
with layout changes). In external validation based on 400 real ECG images data
from Chaoyang Hospital, the AUROC for atrial fibrillation diagnosis reached
0.778; On 12 x 1 layout ECGs, AUROC reaches 0.893. This result is superior to
various classic interpolation and baseline methods, and compared to the current
optimal large-scale pre-training model ECGFounder, it has improved by 0.111 and
0.19.

</details>


### [189] [SVGen: Interpretable Vector Graphics Generation with Large Language Models](https://arxiv.org/abs/2508.09168)
*Feiyu Wang,Zhiyuan Zhao,Yuandong Liu,Da Zhang,Junyu Gao,Hao Sun,Xuelong Li*

Main category: cs.LG

TL;DR: A new dataset (SVG-1M) and model (SVGen) are introduced for generating SVG code from text descriptions, addressing the time-consuming nature of manual SVG creation and showing superior performance compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Creative ideas into precise vector graphics is a time-consuming challenge in front-end development and UI/UX design, necessitating automated solutions.

Method: An end-to-end model (SVGen) is proposed, utilizing a large-scale dataset (SVG-1M) with natural language descriptions and Chain of Thought annotations. The model employs curriculum learning and reinforcement learning optimization for improved semantic accuracy and structural completeness.

Result: SVGen generates SVG code from natural language inputs with semantic accuracy and structural completeness, outperforming general large models and traditional rendering methods in effectiveness and efficiency.

Conclusion: The proposed SVGen model, trained on the SVG-1M dataset, outperforms existing methods in generating SVG code from natural language, demonstrating effectiveness and efficiency.

Abstract: Scalable Vector Graphics (SVG) is widely used in front-end development and
UI/UX design due to its scalability, editability, and rendering efficiency.
However, turning creative ideas into precise vector graphics remains a
time-consuming challenge. To address this, we introduce SVG-1M, a large-scale
dataset of high-quality SVGs paired with natural language descriptions. Through
advanced data augmentation and annotation, we create well-aligned Text to SVG
training pairs, including a subset with Chain of Thought annotations for
enhanced semantic guidance. Based on this dataset, we propose SVGen, an
end-to-end model that generates SVG code from natural language inputs. Our
approach ensures semantic accuracy and structural completeness, supported by
curriculum learning and reinforcement learning optimization. Experiments show
that SVGen outperforms general large models and traditional rendering methods
in both effectiveness and efficiency. Code, model, and dataset are available on
GitHub.

</details>


### [190] [Multimodal RAG Enhanced Visual Description](https://arxiv.org/abs/2508.09170)
*Amit Kumar Jaiswal,Haiming Liu,Ingo Frommholz*

Main category: cs.LG

TL;DR: 提出了一种无需训练的方法，利用检索增强生成（RAG）和线性映射来解决大型多模态模型（LMMs）中的模态鸿沟问题，该方法通过迭代提炼映射来优化标准图像描述度量，并在两个数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMMs）存在一个模态鸿沟，即在共同嵌入空间中的文本和视觉表示不匹配。虽然微调可以解决这个问题，但它成本高昂且不切实际，因为它需要大量的领域驱动数据。

Method: 提出了一种利用检索增强生成（RAG）的轻量级、无需训练的方法，通过线性映射跨模态，该映射可以有效地计算。在推理过程中，将此映射应用于由 LMM 嵌入的图像，以从训练集中检索最接近的文本描述。此外，还通过生成合成描述的语言模型引入了一种迭代技术来提炼映射，以促进针对标准图像描述度量的优化。

Result: 实验结果在两个基准多模态数据集上展示了显著的改进。

Conclusion: 通过实验结果在两个基准多模态数据集上展示了显著的改进。

Abstract: Textual descriptions for multimodal inputs entail recurrent refinement of
queries to produce relevant output images. Despite efforts to address
challenges such as scaling model size and data volume, the cost associated with
pre-training and fine-tuning remains substantial. However, pre-trained large
multimodal models (LMMs) encounter a modality gap, characterised by a
misalignment between textual and visual representations within a common
embedding space. Although fine-tuning can potentially mitigate this gap, it is
typically expensive and impractical due to the requirement for extensive
domain-driven data. To overcome this challenge, we propose a lightweight
training-free approach utilising Retrieval-Augmented Generation (RAG) to extend
across the modality using a linear mapping, which can be computed efficiently.
During inference, this mapping is applied to images embedded by an LMM enabling
retrieval of closest textual descriptions from the training set. These textual
descriptions, in conjunction with an instruction, cater as an input prompt for
the language model to generate new textual descriptions. In addition, we
introduce an iterative technique for distilling the mapping by generating
synthetic descriptions via the language model facilitating optimisation for
standard utilised image description measures. Experimental results on two
benchmark multimodal datasets demonstrate significant improvements.

</details>


### [191] [FedMP: Tackling Medical Feature Heterogeneity in Federated Learning from a Manifold Perspective](https://arxiv.org/abs/2508.09174)
*Zhekai Zhou,Shudong Liu,Zhaokun Zhou,Yang Liu,Qiang Yang,Yuesheng Zhu,Guibo Luo*

Main category: cs.LG

TL;DR: FedMP 是一种新方法，通过特征流形补全和类别原型对齐来增强联邦学习在非 IID 场景下的性能，特别是在医学成像领域，实验证明其优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的联邦学习（FL）经常遇到由参与客户端之间非相同且独立分布（non-IID）的本地数据集带来的挑战，这在医学成像领域尤为突出，因为图像特征分布的变化会严重阻碍全局模型的收敛性和性能。

Method: FedMP 采用随机特征流形补全来丰富单个客户端分类器的训练空间，并利用类别原型来指导特征流形在语义一致子空间中的客户端对齐，从而促进更清晰的决策边界的构建。

Result: 实验结果表明，FedMP 在真实世界的医学成像数据集和多域自然图像数据集上都优于现有的联邦学习算法。此外，还分析了流形维度、通信效率和特征暴露的隐私含义。

Conclusion: FedMP 在真实世界的医学成像数据集和多域自然图像数据集上都表现出了优越的性能，并且优于现有的联邦学习算法。

Abstract: Federated learning (FL) is a decentralized machine learning paradigm in which
multiple clients collaboratively train a shared model without sharing their
local private data. However, real-world applications of FL frequently encounter
challenges arising from the non-identically and independently distributed
(non-IID) local datasets across participating clients, which is particularly
pronounced in the field of medical imaging, where shifts in image feature
distributions significantly hinder the global model's convergence and
performance. To address this challenge, we propose FedMP, a novel method
designed to enhance FL under non-IID scenarios. FedMP employs stochastic
feature manifold completion to enrich the training space of individual client
classifiers, and leverages class-prototypes to guide the alignment of feature
manifolds across clients within semantically consistent subspaces, facilitating
the construction of more distinct decision boundaries. We validate the
effectiveness of FedMP on multiple medical imaging datasets, including those
with real-world multi-center distributions, as well as on a multi-domain
natural image dataset. The experimental results demonstrate that FedMP
outperforms existing FL algorithms. Additionally, we analyze the impact of
manifold dimensionality, communication efficiency, and privacy implications of
feature exposure in our method.

</details>


### [192] [DQT: Dynamic Quantization Training via Dequantization-Free Nested Integer Arithmetic](https://arxiv.org/abs/2508.09176)
*Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Francesca Palermo,Diana Trojaniello,Manuel Roveri*

Main category: cs.LG

TL;DR: DQT框架通过独特的嵌套整数表示和位移操作，实现了高效的动态混合精度量化，克服了现有方法的性能瓶颈，并在ImageNet上取得了优于其他方法的准确率，同时大幅降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有动态、实例级混合精度量化方法在改变精度时需要进行成本高昂的反量化-浮点化和再量化-整数化操作，这破坏了纯整数硬件范式并降低了性能增益。本研究旨在消除这一瓶颈，以实现更高效、自适应的AI。

Method: 本研究提出了一种名为动态量化训练（DQT）的新框架，其核心是一种嵌套整数表示，其中较低精度的值被嵌入到较高精度的值中。结合自定义的纯整数算术，DQT能够通过近乎零成本的位移操作来实现实时的比特宽度切换，从而实现了去量化（dequantization-free）的静态混合精度和高效的动态、实例级量化。

Result: DQT在ResNet18（CIFAR-10）和ResNet50（ImageNet）上取得了最先进的性能。在ImageNet上，DQT的4位动态ResNet50实现了77.00%的top-1准确率，优于其他方法。关键在于，DQT的比特宽度转换成本仅为28.3M次位移操作，远低于先前动态方法所需的56.6M次浮点乘加（MAC）操作。

Conclusion: DQT通过嵌套整数表示和自定义的纯整数算术，实现了无反量化（dequantization-free）的静态混合精度以及高效的动态、实例级量化，从而消除了现有方法的瓶颈，并以极低的比特宽度转换成本（仅28.3M次位移操作）实现了卓越的性能，在CIFAR-10上的ResNet18和在ImageNet上的ResNet50取得了最先进的成果，例如4位动态ResNet50在ImageNet上实现了77.00%的top-1准确率，优于现有的静态和动态量化方法。

Abstract: The deployment of deep neural networks on resource-constrained devices relies
on quantization. While static, uniform quantization applies a fixed bit-width
to all inputs, it fails to adapt to their varying complexity. Dynamic,
instance-based mixed-precision quantization promises a superior
accuracy-efficiency trade-off by allocating higher precision only when needed.
However, a critical bottleneck remains: existing methods require a costly
dequantize-to-float and requantize-to-integer cycle to change precision,
breaking the integer-only hardware paradigm and compromising performance gains.
This paper introduces Dynamic Quantization Training (DQT), a novel framework
that removes this bottleneck. At the core of DQT is a nested integer
representation where lower-precision values are bit-wise embedded within
higher-precision ones. This design, coupled with custom integer-only
arithmetic, allows for on-the-fly bit-width switching through a near-zero-cost
bit-shift operation. This makes DQT the first quantization framework to enable
both dequantization-free static mixed-precision of the backbone network, and
truly efficient dynamic, instance-based quantization through a lightweight
controller that decides at runtime how to quantize each layer. We demonstrate
DQT state-of-the-art performance on ResNet18 on CIFAR-10 and ResNet50 on
ImageNet. On ImageNet, our 4-bit dynamic ResNet50 achieves 77.00% top-1
accuracy, an improvement over leading static (LSQ, 76.70%) and dynamic (DQNET,
76.94%) methods at a comparable BitOPs budget. Crucially, DQT achieves this
with a bit-width transition cost of only 28.3M simple bit-shift operations, a
drastic improvement over the 56.6M costly Multiply-Accumulate (MAC)
floating-point operations required by previous dynamic approaches - unlocking a
new frontier in efficient, adaptive AI.

</details>


### [193] [scAGC: Learning Adaptive Cell Graphs with Contrastive Guidance for Single-Cell Clustering](https://arxiv.org/abs/2508.09180)
*Huifa Li,Jie Fu,Xinlin Zhuang,Haolin Yang,Xinpeng Ling,Tong Cheng,Haochen xue,Imran Razzak,Zhili Chen*

Main category: cs.LG

TL;DR: scAGC 是一种新的单细胞聚类方法，通过学习自适应细胞图和使用对比引导来解决传统方法在处理 scRNA-seq 数据时面临的挑战。它通过拓扑自适应图自编码器、ZINB 损失和对比学习目标来优化特征表示和图结构，从而在真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于 scRNA-seq 数据的维度高和零元素普遍存在，传统的聚类方法面临着显著的统计和计算挑战。一些先进的方法虽然使用图神经网络来模拟细胞间关系，但它们通常依赖于对噪声敏感且无法捕捉单细胞种群固有的长尾分布的静态图结构。

Method: scAGC 是一种单细胞聚类方法，通过对比引导学习自适应细胞图。该方法在端到端的方式中同时优化特征表示和细胞图。具体来说，我们引入了一个拓扑自适应图自编码器，它利用可微分的 Gumbel-Softmax 采样策略在训练过程中动态地精炼图结构。这种自适应机制通过促进更平衡的邻域结构来缓解长尾度分布的问题。为了模拟 scRNA-seq 数据的离散、过度分散和零膨胀的特性，我们集成了 Zero-Inflated Negative Binomial (ZINB) 损失以进行稳健的特征重建。此外，还加入了一个对比学习目标来规范图学习过程并防止图拓扑的突然变化，确保稳定性和提高收敛性。

Result: scAGC 在 9 个真实 scRNA-seq 数据集上的综合实验表明，其性能始终优于其他最先进的方法，在 9 个和 7 个数据集上分别获得了最佳的 NMI 和 ARI 分数。

Conclusion: scAGC 在 9 个真实 scRNA-seq 数据集上的综合实验表明，其性能始终优于其他最先进的方法，在 9 个和 7 个数据集上分别获得了最佳的 NMI 和 ARI 分数。

Abstract: Accurate cell type annotation is a crucial step in analyzing single-cell RNA
sequencing (scRNA-seq) data, which provides valuable insights into cellular
heterogeneity. However, due to the high dimensionality and prevalence of zero
elements in scRNA-seq data, traditional clustering methods face significant
statistical and computational challenges. While some advanced methods use graph
neural networks to model cell-cell relationships, they often depend on static
graph structures that are sensitive to noise and fail to capture the
long-tailed distribution inherent in single-cell populations.To address these
limitations, we propose scAGC, a single-cell clustering method that learns
adaptive cell graphs with contrastive guidance. Our approach optimizes feature
representations and cell graphs simultaneously in an end-to-end manner.
Specifically, we introduce a topology-adaptive graph autoencoder that leverages
a differentiable Gumbel-Softmax sampling strategy to dynamically refine the
graph structure during training. This adaptive mechanism mitigates the problem
of a long-tailed degree distribution by promoting a more balanced neighborhood
structure. To model the discrete, over-dispersed, and zero-inflated nature of
scRNA-seq data, we integrate a Zero-Inflated Negative Binomial (ZINB) loss for
robust feature reconstruction. Furthermore, a contrastive learning objective is
incorporated to regularize the graph learning process and prevent abrupt
changes in the graph topology, ensuring stability and enhancing convergence.
Comprehensive experiments on 9 real scRNA-seq datasets demonstrate that scAGC
consistently outperforms other state-of-the-art methods, yielding the best NMI
and ARI scores on 9 and 7 datasets, respectively.Our code is available at
Anonymous Github.

</details>


### [194] [Breath as a biomarker: A survey of contact and contactless applications and approaches in respiratory monitoring](https://arxiv.org/abs/2508.09187)
*Almustapha A. Wakili,Babajide J. Asaju,Woosub Jung*

Main category: cs.LG

TL;DR: 对呼吸分析领域的接触式和非接触式方法进行了全面的技术和应用综述，重点介绍了机器学习和深度学习的应用，并讨论了现有挑战和新兴趋势。


<details>
  <summary>Details</summary>
Motivation: 呼吸分析作为健康监测的关键工具，在呼吸功能、疾病检测和持续健康评估方面具有重要意义。然而，传统的接触式方法在舒适性和实用性方面存在挑战，尤其是在长期监测方面。因此，需要考察和分析非接触式方法，以提供更舒适、更实用的呼吸监测解决方案。

Method: 本篇论文采用文献综述的方法，对基于接触和非接触的呼吸分析方法进行了全面的考察，重点关注了机器学习和深度学习技术的最新进展，并对数据预处理、特征提取和分类技术进行了详细介绍，同时对不同方法适用的机器学习/深度学习模型进行了比较分析。

Result: 本篇论文分析了包括Wi-Fi信道状态信息和声学传感在内的非接触式方法在呼吸监测方面的准确性和非侵入性，并探讨了从单用户呼吸频率检测到多用户场景、用户识别和呼吸系统疾病检测的广泛应用。此外，论文还讨论了关键挑战和新兴趋势，为未来的研究提供了方向。

Conclusion: 本篇论文总结了当前基于接触和非接触式呼吸分析的技术，强调了机器学习和深度学习在其中的应用，并讨论了数据稀疏性、多用户干扰、数据隐私等关键挑战以及可解释人工智能、联邦学习、迁移学习和混合建模等新兴趋势，旨在为未来的呼吸分析技术创新提供指导，实现先进技术能力与实际医疗应用的结合。

Abstract: Breath analysis has emerged as a critical tool in health monitoring, offering
insights into respiratory function, disease detection, and continuous health
assessment. While traditional contact-based methods are reliable, they often
pose challenges in comfort and practicality, particularly for long-term
monitoring. This survey comprehensively examines contact-based and contactless
approaches, emphasizing recent advances in machine learning and deep learning
techniques applied to breath analysis. Contactless methods, including Wi-Fi
Channel State Information and acoustic sensing, are analyzed for their ability
to provide accurate, noninvasive respiratory monitoring. We explore a broad
range of applications, from single-user respiratory rate detection to
multi-user scenarios, user identification, and respiratory disease detection.
Furthermore, this survey details essential data preprocessing, feature
extraction, and classification techniques, offering comparative insights into
machine learning/deep learning models suited to each approach. Key challenges
like dataset scarcity, multi-user interference, and data privacy are also
discussed, along with emerging trends like Explainable AI, federated learning,
transfer learning, and hybrid modeling. By synthesizing current methodologies
and identifying open research directions, this survey offers a comprehensive
framework to guide future innovations in breath analysis, bridging advanced
technological capabilities with practical healthcare applications.

</details>


### [195] [Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](https://arxiv.org/abs/2508.09190)
*Bing Han,Feifei Zhao,Dongcheng Zhao,Guobin Shen,Ping Wu,Yu Shi,Yi Zeng*

Main category: cs.LG

TL;DR: FGSN 通过精确定位和优化安全神经元，有效降低了微调 LLM 的安全风险，同时保持模型效用，并具备持续防御和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决微调（fine-tuning）大型语言模型（LLMs）时，领域特定知识注入带来的原有对齐机制挑战和安全风险问题，以及现有后微调防御方法仅依赖粗粒度安全层映射，缺乏对安全层和细粒度神经元的全面考虑，难以有效平衡安全与效用的问题。

Method: 提出“细粒度安全神经元”（FGSN）并结合“无训练持续投影”的方法，通过整合安全层和神经元之间的多尺度交互，定位细粒度安全神经元，并将其参数投影到安全方向。引入任务特定、多维度异构安全神经元集群优化机制，实现持续防御和泛化能力。

Result: 在多个微调 LLM 模型上的广泛实验表明，该方法在极少的参数修改下，显著降低了有害性分数和攻击成功率，同时保持了模型的效用。

Conclusion: 本文提出了一种名为“细粒度安全神经元”（FGSN）并结合“无训练持续投影”的方法，以降低微调带来的安全风险。FGSN 方法整合了安全层和神经元之间的多尺度交互，能够定位更稀疏、更精确的细粒度安全神经元，同时最大限度地减少对下游任务神经元的干扰。此外，通过引入特定任务、多维度异构安全神经元集群优化机制，实现了持续防御和针对未来新兴安全问题的泛化能力。实验证明，该方法在极少的参数修改下，显著降低了有害性分数和攻击成功率，同时保持了模型的效用。

Abstract: Fine-tuning as service injects domain-specific knowledge into large language
models (LLMs), while challenging the original alignment mechanisms and
introducing safety risks. A series of defense strategies have been proposed for
the alignment, fine-tuning, and post-fine-tuning phases, where most
post-fine-tuning defenses rely on coarse-grained safety layer mapping. These
methods lack a comprehensive consideration of both safety layers and
fine-grained neurons, limiting their ability to efficiently balance safety and
utility. To address this, we propose the Fine-Grained Safety Neurons (FGSN)
with Training-Free Continual Projection method to reduce the fine-tuning safety
risks. FGSN inherently integrates the multi-scale interactions between safety
layers and neurons, localizing sparser and more precise fine-grained safety
neurons while minimizing interference with downstream task neurons. We then
project the safety neuron parameters onto safety directions, improving model
safety while aligning more closely with human preferences. Extensive
experiments across multiple fine-tuned LLM models demonstrate that our method
significantly reduce harmfulness scores and attack success rates with minimal
parameter modifications, while preserving the model's utility. Furthermore, by
introducing a task-specific, multi-dimensional heterogeneous safety neuron
cluster optimization mechanism, we achieve continual defense and generalization
capability against unforeseen emerging safety concerns.

</details>


### [196] [From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization](https://arxiv.org/abs/2508.09191)
*Xiaoyu Tao,Shilong Zhang,Mingyue Cheng,Daoyu Wang,Tingyue Pan,Bokai Pan,Changqing Zhang,Shijin Wang*

Main category: cs.LG

TL;DR: TokenCast是一个LLM驱动的框架，通过将时间序列数据转化为文本令牌，并利用LLM的强大能力来整合上下文信息，从而提高时间序列预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在能源、医疗和金融等领域至关重要，但现有方法在整合历史数值序列与包含非结构化文本数据的上下文特征方面存在准确性限制。

Method: TokenCast框架利用离散分词器将连续数值序列转化为时间令牌，与基于语言的输入在结构上对齐。通过预训练的LLM将时间令牌和上下文令牌嵌入到共享表示空间，并使用自回归生成目标进行优化。最后，在统一的语义空间中，对齐的LLM进行监督微调，以预测未来的时间令牌，再解码回原始数值空间。

Result: 实验证明TokenCast在包含上下文特征的各种真实世界数据集上是有效的，并且具有良好的泛化能力。

Conclusion: TokenCast框架通过将连续数值序列转化为时间令牌，并利用LLM将时间令牌与上下文令牌嵌入到共享表示空间，实现了上下文感知的时间序列预测，在包含上下文特征的真实世界数据集上表现出了有效性和泛化能力。

Abstract: Time series forecasting plays a vital role in supporting decision-making
across a wide range of critical applications, including energy, healthcare, and
finance. Despite recent advances, forecasting accuracy remains limited due to
the challenge of integrating historical numerical sequences with contextual
features, which often comprise unstructured textual data. To address this
challenge, we propose TokenCast, an LLM-driven framework that leverages
language-based symbolic representations as a unified intermediary for
context-aware time series forecasting. Specifically, TokenCast employs a
discrete tokenizer to transform continuous numerical sequences into temporal
tokens, enabling structural alignment with language-based inputs. To bridge the
semantic gap between modalities, both temporal and contextual tokens are
embedded into a shared representation space via a pre-trained large language
model (LLM), further optimized with autoregressive generative objectives.
Building upon this unified semantic space, the aligned LLM is subsequently
fine-tuned in a supervised manner to predict future temporal tokens, which are
then decoded back into the original numerical space. Extensive experiments on
diverse real-world datasets enriched with contextual features demonstrate the
effectiveness and generalizability of TokenCast.

</details>


### [197] [Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing](https://arxiv.org/abs/2508.09192)
*Xu Wang,Chenkai Xu,Yijie Jin,Jiachun Jin,Hao Zhang,Zhijie Deng*

Main category: cs.LG

TL;DR: D2F是一种新的技术，通过改进扩散大语言模型（dLLM），使其推理速度比LLaMA3和Qwen2.5快2.5倍以上，同时保持了高质量的输出。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有开源dLLM在推理速度上不如同尺寸AR大语言模型的问题，并探索提升dLLM推理效率的方法。

Method: 提出了一种名为离散扩散强制（D2F）的策略，该策略包含两个关键能力：1. 利用KV缓存的块状自回归生成；2. 在不完成先前块的情况下预测后续令牌以实现跨块并行解码。D2F通过非对称蒸馏过程可以基于预训练的dLLM实现，并辅以流水线并行解码算法进行效率和效果的权衡。

Result: D2F技术使dLLM在GSM8K数据集上实现了比LLaMA3和Qwen2.5快2.5倍以上的推理速度，并且与LLaDA和Dream等原始dLLM相比，在保持相似输出质量的同时，加速效果超过50倍。

Conclusion: D2F技术成功打破了开源扩散大语言模型（dLLM）在推理速度上不如自回归（AR）大语言模型的瓶颈，通过结合块状自回归生成和跨块并行解码，实现了AR-扩散混合范式，显著提升了推理效率。

Abstract: Diffusion Large Language Models (dLLMs) have emerged as a promising
alternative to autoregressive (AR) LLMs for text generation, with the potential
to decode multiple tokens in a single iteration. However, none of the existing
open-source dLLMs have achieved superior inference speed over AR LLMs of
similar size. This paper breaks this barrier based on a simple and effective
strategy named discrete diffusion forcing (D2F). D2F equips dLLMs with two key
capabilities: (1) block-wise autoregressive generation to enable KV cache
utilization; (2) prediction of following tokens without requiring completion of
prior blocks for inter-block parallel decoding. In this way, the vanilla dLLMs
are refurbished into an AR-diffusion hybrid paradigm for efficient inference.
D2F can be implemented with an asymmetric distillation process based on
pre-trained dLLMs. We further propose a pipelined parallel decoding algorithm,
which enables a trade-off between efficiency and efficacy. Empirically, D2F
dLLMs achieve more than $\mathbf{2.5\times}$ inference speed than LLaMA3 and
Qwen2.5 on GSM8K. Compared to vanilla dLLMs like LLaDA and Dream, the
acceleration can be more than $\mathbf{50\times}$ while maintaining comparable
output quality. The code is available at
https://github.com/zhijie-group/Discrete-Diffusion-Forcing.

</details>


### [198] [Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL](https://arxiv.org/abs/2508.09193)
*Sung-Hyun Kim,In-Chang Baek,Seo-Young Lee,Geum-Hwan Hwang,Kyung-Joong Kim*

Main category: cs.LG

TL;DR: MIPCGRL通过整合句子嵌入和多目标学习，显著提升了基于文本指令的内容生成的可控性。


<details>
  <summary>Details</summary>
Motivation: 现有的IPCGRL方法在处理复杂、多目标指令时，难以充分利用文本信息的丰富性，导致内容生成的可控性受限。

Method: MIPCGRL是一种多目标表示学习方法，将句子嵌入作为条件，并结合多标签分类和多头回归网络来训练多目标嵌入空间。

Result: 实验结果表明，MIPCGRL在多目标指令下可控性提高了13.8%，能够处理复杂指令，实现更具表现力和灵活性的内容生成。

Conclusion: 提出的MIPCGRL方法通过结合句子嵌入作为条件，并利用多标签分类和多头回归网络来训练多目标嵌入空间，有效解决了现有IPCGRL方法在处理复杂、多目标指令时对文本丰富性利用不足的问题，提高了内容生成的可控性。

Abstract: Recent advancements in generative modeling emphasize the importance of
natural language as a highly expressive and accessible modality for controlling
content generation. However, existing instructed reinforcement learning for
procedural content generation (IPCGRL) method often struggle to leverage the
expressive richness of textual input, especially under complex, multi-objective
instructions, leading to limited controllability. To address this problem, we
propose \textit{MIPCGRL}, a multi-objective representation learning method for
instructed content generators, which incorporates sentence embeddings as
conditions. MIPCGRL effectively trains a multi-objective embedding space by
incorporating multi-label classification and multi-head regression networks.
Experimental results show that the proposed method achieves up to a 13.8\%
improvement in controllability with multi-objective instructions. The ability
to process complex instructions enables more expressive and flexible content
generation.

</details>


### [199] [Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments](https://arxiv.org/abs/2508.09194)
*Yipeng Du,Zihao Wang,Ahmad Farhan,Claudio Angione,Harry Yang,Fielding Johnston,James P. Buban,Patrick Colangelo,Yue Zhao,Yuzhe Yang*

Main category: cs.LG

TL;DR: 为去中心化AI系统提出一个元学习框架，以自动选择最佳推理加速方案，从而降低成本并提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了降低大型模型（如LLMs）部署的成本，并解决可扩展性和数据安全挑战，模型部署正转向去中心化系统，这使得选择高效的推理加速方案变得至关重要。

Method: 提出一个基于元学习的框架，通过学习历史性能数据来自动选择最佳的推理加速方案。

Result: 该框架能自动选择最佳加速策略，在效率和性能上持续优于传统方法。

Conclusion: 该元学习框架能系统性地根据任务特性选择最佳加速策略，并持续优于传统方法。

Abstract: The deployment of large-scale models, such as large language models (LLMs),
incurs substantial costs due to their computational demands. To mitigate these
costs and address challenges related to scalability and data security, there is
a growing shift towards decentralized systems for model deployment, where
choosing efficient inference acceleration schemes become crucial to manage
computational resources effectively and enhance system responsiveness. In this
work, we address the challenge of selecting optimal acceleration methods in
decentralized systems by introducing a meta-learning-based framework. This
framework automates the selection process by learning from historical
performance data of various acceleration techniques across different tasks.
Unlike traditional methods that rely on random selection or expert intuition,
our approach systematically identifies the best acceleration strategies based
on the specific characteristics of each task. We demonstrate that our
meta-learning framework not only streamlines the decision-making process but
also consistently outperforms conventional methods in terms of efficiency and
performance. Our results highlight the potential of inference acceleration in
decentralized AI systems, offering a path towards more democratic and
economically feasible artificial intelligence solutions.

</details>


### [200] [ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce](https://arxiv.org/abs/2508.09198)
*Li Kong,Bingzhe Wang,Zhou Chen,Suhan Hu,Yuchao Ma,Qi Qi,Suoyuan Song,Bicheng Jin*

Main category: cs.LG

TL;DR: ADT4Coupons是一个创新的优惠券分发框架，通过利用序列数据和迭代更新，直接优化长期收入，并在真实数据上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有优惠券分发策略未能有效利用平台与用户之间复杂的序列交互，尽管存在大量的电子商务日志数据，但这种疏忽导致了性能瓶颈。

Method: 提出了一种名为ADT4Coupons（Aligned Decision Transformer for Coupons）的新型营销框架，该框架旨在直接制定优惠券分发策略以实现长期收入增长。ADT4Coupons将通用场景、利用更全面的历史数据进行序列建模以及高效的迭代更新这三个关键特征整合到统一框架中，以实现优化的在线决策。

Result: ADT4Coupons在真实工业数据集、公开数据集和合成数据集上的实证结果表明，该框架优于现有方法。

Conclusion: ADT4Coupons通过整合通用场景、序列建模和高效迭代更新，在真实工业数据集、公开数据集和合成数据集上证明了其优越性，为在线平台提供了优化的长期优惠券分发策略。

Abstract: Coupon distribution is a critical marketing strategy used by online platforms
to boost revenue and enhance user engagement. Regrettably, existing coupon
distribution strategies fall far short of effectively leveraging the complex
sequential interactions between platforms and users. This critical oversight,
despite the abundance of e-commerce log data, has precipitated a performance
plateau. In this paper, we focus on the scene that the platforms make
sequential coupon distribution decision multiple times for various users, with
each user interacting with the platform repeatedly. Based on this marketing
scenario, we propose a novel marketing framework, named Aligned Decision
Transformer for Coupons (ADT4Coupons), to directly devise coupon distribution
policy for long-term revenue boosting. ADT4Coupons enables optimized online
decision-making in a variety of real-world marketing scenarios. It achieves
this by seamlessly integrating three key characteristics, general scenarios,
sequential modeling with more comprehensive historical data, and efficient
iterative updates within a unified framework. Furthermore, empirical results on
real-world industrial dataset, alongside public and synthetic datasets
demonstrate the superiority of our framework.

</details>


### [201] [Building Safer Sites: A Large-Scale Multi-Level Dataset for Construction Safety Research](https://arxiv.org/abs/2508.09203)
*Zhenhui Ou,Dawei Li,Zhen Tan,Wenlin Li,Huan Liu,Siyuan Song*

Main category: cs.LG

TL;DR: 本研究提出了一个名为CSDataset的新建筑安全数据集，该数据集整合了OSHA记录的事件、检查和违规行为，并包含结构化和非结构化数据。初步分析显示，投诉驱动的检查可将后续事件的可能性降低17.3%。数据集和代码已公开。


<details>
  <summary>Details</summary>
Motivation: 现有建筑安全数据集数量有限且多样性不足，给深入分析带来了挑战。因此，需要一个更全面、组织更完善的数据集来促进该领域的研究。

Method: 本研究介绍了建筑安全数据集（CSDataset），这是一个包含职业安全与健康管理局（OSHA）记录的事件、检查和违规行为的综合多层次数据集。该数据集整合了结构化属性和非结构化叙述，支持机器学习和大型语言模型驱动的方法。此外，还进行了初步的方法基准测试和跨层次分析。

Result: 研究表明，由投诉驱动的检查与后续事件发生可能性降低 17.3% 相关。该研究还提供了使用该数据集进行的初步方法基准测试和各种跨层次分析的见解。

Conclusion: 该数据集和代码已发布，可用于促进未来在建筑安全领域的研究。

Abstract: Construction safety research is a critical field in civil engineering, aiming
to mitigate risks and prevent injuries through the analysis of site conditions
and human factors. However, the limited volume and lack of diversity in
existing construction safety datasets pose significant challenges to conducting
in-depth analyses. To address this research gap, this paper introduces the
Construction Safety Dataset (CSDataset), a well-organized comprehensive
multi-level dataset that encompasses incidents, inspections, and violations
recorded sourced from the Occupational Safety and Health Administration (OSHA).
This dataset uniquely integrates structured attributes with unstructured
narratives, facilitating a wide range of approaches driven by machine learning
and large language models. We also conduct a preliminary approach benchmarking
and various cross-level analyses using our dataset, offering insights to inform
and enhance future efforts in construction safety. For example, we found that
complaint-driven inspections were associated with a 17.3% reduction in the
likelihood of subsequent incidents. Our dataset and code are released at
https://github.com/zhenhuiou/Construction-Safety-Dataset-CSDataset.

</details>


### [202] [MoQE: Improve Quantization Model performance via Mixture of Quantization Experts](https://arxiv.org/abs/2508.09204)
*Jinhao Zhang,Yunquan Zhang,Boyang Zhang,Zeyu Liu,Daning Cheng*

Main category: cs.LG

TL;DR: MoQE是一种创新的量化框架，通过混合量化专家和智能路由，在不牺牲速度的情况下提高了模型精度。


<details>
  <summary>Details</summary>
Motivation: 量化方法在提高模型效率和降低部署成本方面发挥着关键作用，但不可避免地会导致准确性下降。旨在联合提高量化模型的性能。

Method: 提出了一种基于MoE架构的混合量化专家（MoQE）框架，该框架将同一全精度模型的多种量化变体作为专门的“量化专家”，并根据输入数据的特性动态地将其路由到最合适的专家。为CV和NLP任务设计了轻量级、感知结构的路由器模型。

Result: 在ResNet、LLaMA和Qwen模型系列以及ImageNet、WikiText、C4和OpenWebText等基准数据集上的实验评估表明，MoQE实现了与SOTA量化模型相当的性能，而没有显著增加推理延迟。

Conclusion: MoQE框架通过结合多种量化模型并动态路由数据到最适合的专家，有效减轻了单一量化模型的性能下降问题，在保持与SOTA量化模型相当的性能的同时，并未显著增加推理延迟。

Abstract: Quantization method plays a crucial role in improving model efficiency and
reducing deployment costs, enabling the widespread application of deep learning
models on resource-constrained devices. However, the quantization process
inevitably introduces accuracy degradation. In this paper, we propose Mixture
of Quantization Experts( abbr. MoQE), a quantization inference framework based
on the Mixture-of-Experts (MoE) architecture, aiming to jointly improve the
performance of quantization models. MoQE combines multiple quantization
variants of one full-precision model as specialized "quantization experts" and
dynamically routes input data to the most suitable expert based on its
characteristics. MoQE alleviates the performance degradation commonly seen in
single quantization models through specialization quantization expert models.
We design lightweight, structure-aware router models tailored for both CV and
NLP tasks. Experimental evaluations on ResNet, LLaMA, and Qwen model families
across benchmark datasets including ImageNet, WikiText, C4, and OpenWebText
demonstrate that MoQE achieves performance comparable to SOTA quantization
model, without incurring significant increases in inference latency.

</details>


### [203] [The First Differentiable Transfer-Based Algorithm for Discrete MicroLED Repair](https://arxiv.org/abs/2508.09206)
*Ning-Yuan Lue*

Main category: cs.LG

TL;DR: 一种新的基于可微分转移模块的修复算法，用于microLED制造中的激光辅助选择性转移，可最大限度地减少运动，实现灵活的目标设计，并比现有方法更快地进行训练。


<details>
  <summary>Details</summary>
Motivation: 激光辅助选择性转移是高通量microLED制造中的一个关键过程，需要能够规划移动序列以最大限度地减少XY平台的移动并适应基板上不断变化的优化目标的计算模型。

Method: 提出了一种基于可微分转移模块的修复算法，该模块能够模拟转移平台的离散移动，并通过基于梯度的优化进行训练。

Result: 与基于局部邻近搜索的算法相比，该方法实现了卓越的修复性能，并实现了更灵活的目标设计（例如，最大限度地减少步数）。与基于强化学习（RL）的方法不同，该方法无需手工设计的特征提取器，并且训练速度显著提高，从而能够扩展到大型阵列。实验表明，转移步数减少了50%，在2000x2000的阵列上规划时间缩短至2分钟以内。

Conclusion: 该方法为AR/VR和下一代显示器制造中加速microLED修复提供了一个实用且适应性强的解决方案。

Abstract: Laser-enabled selective transfer, a key process in high-throughput microLED
fabrication, requires computational models that can plan shift sequences to
minimize motion of XY stages and adapt to varying optimization objectives
across the substrate. We propose the first repair algorithm based on a
differentiable transfer module designed to model discrete shifts of transfer
platforms, while remaining trainable via gradient-based optimization. Compared
to local proximity searching algorithms, our approach achieves superior repair
performance and enables more flexible objective designs, such as minimizing the
number of steps. Unlike reinforcement learning (RL)-based approaches, our
method eliminates the need for handcrafted feature extractors and trains
significantly faster, allowing scalability to large arrays. Experiments show a
50% reduction in transfer steps and sub-2-minute planning time on 2000x2000
arrays. This method provides a practical and adaptable solution for
accelerating microLED repair in AR/VR and next-generation display fabrication.

</details>


### [204] [Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation](https://arxiv.org/abs/2508.09223)
*Sameer Ambekar,Daniel M. Lang,Julia A. Schnabel*

Main category: cs.LG

TL;DR: Hi-Vec is a new test-time adaptation method that uses multiple layers to handle complex data shifts, outperforming existing methods in robustness and uncertainty handling.


<details>
  <summary>Details</summary>
Motivation: Standard test-time adaptation methods rely on single-dimensional linear classification layers, which often fail to handle diverse and complex distribution shifts. Hi-Vec addresses this limitation.

Method: Hi-Vec proposes dynamic layer selection for automatic identification of the optimal layer for adaptation to each test batch. It also proposes a mechanism that merges weights from the dynamic layer to other layers, and a linear layer agreement that acts as a gating function to prevent erroneous fine-tuning.

Result: Hi-Vec advances state-of-the-art methods by improving robustness, addressing uncertainty, and handling limited batch sizes and increased outlier rates. It has been rigorously evaluated in challenging scenarios and on multiple target datasets.

Conclusion: Hi-Vec enables existing test-time adaptation methods to handle diverse and complex distribution shifts by leveraging multiple layers of increasing size for dynamic adaptation. It improves robustness, addresses uncertainty, and handles limited batch sizes and increased outlier rates.

Abstract: Test-time adaptation allows pretrained models to adjust to incoming data
streams, addressing distribution shifts between source and target domains.
However, standard methods rely on single-dimensional linear classification
layers, which often fail to handle diverse and complex shifts. We propose
Hierarchical Adaptive Networks with Task Vectors (Hi-Vec), which leverages
multiple layers of increasing size for dynamic test-time adaptation. By
decomposing the encoder's representation space into such hierarchically
organized layers, Hi-Vec, in a plug-and-play manner, allows existing methods to
adapt to shifts of varying complexity. Our contributions are threefold: First,
we propose dynamic layer selection for automatic identification of the optimal
layer for adaptation to each test batch. Second, we propose a mechanism that
merges weights from the dynamic layer to other layers, ensuring all layers
receive target information. Third, we propose linear layer agreement that acts
as a gating function, preventing erroneous fine-tuning by adaptation on noisy
batches. We rigorously evaluate the performance of Hi-Vec in challenging
scenarios and on multiple target datasets, proving its strong capability to
advance state-of-the-art methods. Our results show that Hi-Vec improves
robustness, addresses uncertainty, and handles limited batch sizes and
increased outlier rates.

</details>


### [205] [Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models](https://arxiv.org/abs/2508.09237)
*Luigi D'Amico,Daniel De Rosso,Ninad Dixit,Raul Salles de Padua,Samuel Palmer,Samuel Mugel,Román Orús,Holger Eble,Ali Abedi*

Main category: cs.LG

TL;DR: 本研究提出了一种量子启发式图神经网络（QI-GNN）结合CP分解层和集成模型（QBoost或随机森林）的方法，用于区块链网络中的反欺诈和反洗钱，实验结果显示其效果优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对金融科技领域内区块链网络非法交易检测的挑战，并加强反洗钱（AML）工作。

Method: 本研究提出了一种结合量子启发式图神经网络（QI-GNN）和集成模型（QBoost或随机森林分类器）的新方法，并引入了新的CP（Canonical Polyadic）分解层来处理和分析复杂的数据结构。

Result: 该方法在检测欺诈交易方面达到了74.8%的F2分数，优于传统的机器学习方法。

Conclusion: 该研究结果表明，量子启发式算法结合CP分解层在金融科技反欺诈领域具有巨大潜力，能够有效对抗金融欺诈，并倡导在金融领域更广泛地采用和探索量子启发式算法。

Abstract: In the rapidly evolving domain of financial technology, the detection of
illicit transactions within blockchain networks remains a critical challenge,
necessitating robust and innovative solutions. This work proposes a novel
approach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with
flexibility of choice of an Ensemble Model using QBoost or a classic model such
as Random Forrest Classifier. This system is tailored specifically for
blockchain network analysis in anti-money laundering (AML) efforts. Our
methodology to design this system incorporates a novel component, a Canonical
Polyadic (CP) decomposition layer within the graph neural network framework,
enhancing its capability to process and analyze complex data structures
efficiently. Our technical approach has undergone rigorous evaluation against
classical machine learning implementations, achieving an F2 score of 74.8% in
detecting fraudulent transactions. These results highlight the potential of
quantum-inspired techniques, supplemented by the structural advancements of the
CP layer, to not only match but potentially exceed traditional methods in
complex network analysis for financial security. The findings advocate for a
broader adoption and further exploration of quantum-inspired algorithms within
the financial sector to effectively combat fraud.

</details>


### [206] [GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction](https://arxiv.org/abs/2508.09227)
*Fan Ding,Hwa Hui Tew,Junn Yong Loo,Susilawati,LiTong Liu,Fang Yu Leong,Xuewen Luo,Kar Keong Chin,Jia Jun Gan*

Main category: cs.LG

TL;DR: GSMT是一种结合了GAT、RNN和任务修正器的混合模型，用于在数据受限的情况下提高公交车轨迹预测的准确性，特别是在拥挤的城市交通环境中。


<details>
  <summary>Details</summary>
Motivation: 在发展中地区，由于多模态数据获取受限，仅依靠车载GPS数据进行公交车轨迹预测仍然是必不可少的，尽管存在固有的挑战。本研究旨在解决这一问题。

Method: GSMT是一个混合模型，结合了图注意力网络（GAT）和序列到序列循环神经网络（RNN），并引入了一个任务修正器。任务修正器通过聚类历史轨迹来识别不同的运动模式，并对GAT和RNN生成的预测进行微调。GSMT通过嵌入式混合网络融合动态公交信息和静态站点信息进行轨迹预测，并在初始预测生成后应用任务修正器进行二次精炼。

Result: 实验证明，GSMT在短期和长期轨迹预测任务上均取得了优于现有方法的性能。

Conclusion: GSMT模型在吉隆坡的真实数据集上进行了测试，结果表明该方法在短期和长期轨迹预测任务上均显著优于现有方法。

Abstract: Accurate trajectory prediction for buses is crucial in intelligent
transportation systems, particularly within urban environments. In developing
regions where access to multimodal data is limited, relying solely on onboard
GPS data remains indispensable despite inherent challenges. To address this
problem, we propose GSMT, a hybrid model that integrates a Graph Attention
Network (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and
incorporates a task corrector capable of extracting complex behavioral patterns
from large-scale trajectory data. The task corrector clusters historical
trajectories to identify distinct motion patterns and fine-tunes the
predictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus
information and static station information through embedded hybrid networks to
perform trajectory prediction, and applies the task corrector for secondary
refinement after the initial predictions are generated. This two-stage approach
enables multi-node trajectory prediction among buses operating in dense urban
traffic environments under complex conditions. Experiments conducted on a
real-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method
significantly outperforms existing approaches, achieving superior performance
in both short-term and long-term trajectory prediction tasks.

</details>


### [207] [LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data](https://arxiv.org/abs/2508.09263)
*Peng Wang,Dongsheng Wang,He Zhao,Hangting Ye,Dandan Guo,Yi Chang*

Main category: cs.LG

TL;DR: LLM在表格学习中，通过示例免费提示生成原型，可用于零样本和少样本学习。


<details>
  <summary>Details</summary>
Motivation: 为了有效利用LLM在表格数据建模的少样本甚至零样本场景下的潜力，并克服现有方法中基于示例的提示所带来的限制。

Method: 提出了一种新颖的基于LLM的原型估计框架，通过查询LLM生成仅依赖于任务和特征描述的示例免费提示的特征值，从而构建零样本原型。该原型可以通过融合少样本样本进行增强，而无需训练分类器或微调LLM。

Result: 该框架在零样本和少样本表格学习任务上展现了优越的性能，证明了其有效性。

Conclusion: 该框架通过使用示例免费提示生成特征值，避免了基于示例的提示的限制，为零样本和少样本表格学习提供了一个可扩展且鲁棒的框架。

Abstract: Recent breakthroughs in large language models (LLMs) have opened the door to
in-depth investigation of their potential in tabular data modeling. However,
effectively utilizing advanced LLMs in few-shot and even zero-shot scenarios is
still challenging. To this end, we propose a novel LLM-based prototype
estimation framework for tabular learning. Our key idea is to query the LLM to
generate feature values based example-free prompt, which solely relies on task
and feature descriptions. With the feature values generated by LLM, we can
build a zero-shot prototype in a training-free manner, which can be further
enhanced by fusing few-shot samples, avoiding training a classifier or
finetuning the LLMs. Thanks to the example-free prompt and prototype
estimation, ours bypasses the constraints brought by the example-based prompt,
providing a scalable and robust framework. Extensive experiments demonstrate
the effectiveness of ours in zero and few-shot tabular learning.

</details>


### [208] [Detection of Odor Presence via Deep Neural Networks](https://arxiv.org/abs/2508.09264)
*Matin Hassanloo,Ali Zareh,Mehmet Kemal Özdemir*

Main category: cs.LG

TL;DR: 通过使用深度学习模型分析小鼠嗅球的局部场电位信号，实现了高精度的单 trial 气味检测，证明了该方法的可行性和潜力。


<details>
  <summary>Details</summary>
Motivation: 当前的嗅觉检测人工传感器在处理复杂气味混合物方面存在困难，而非侵入性记录缺乏可靠的单 trial 保真度。本研究旨在测试局部场电位的频谱特征是否足以进行稳健的单 trial 气味检测，以及仅使用嗅球信号是否足够。

Method: 提出了一种互补的一维卷积神经网络（ResCNN 和 AttentionCNN）模型，用于从多通道嗅球局部场电位（LFPs）中解码气味的存在。

Result: 在 7 只清醒小鼠的 2,349 个 trial 中，该模型实现了 86.6% 的平均准确率、81.0% 的 F1 分数和 0.9247 的 AUC，显著优于先前的基准。t-SNE 可视化也证实了该模型捕捉到了生物学上显著的特征。

Conclusion: 本研究证明了从非侵入性局部场电位信号中稳健地检测气味存在的可能性，并展示了深度学习模型在提供对嗅觉表征的更深入理解方面的潜力。

Abstract: Odor detection underpins food safety, environmental monitoring, medical
diagnostics, and many more fields. The current artificial sensors developed for
odor detection struggle with complex mixtures while non-invasive recordings
lack reliable single-trial fidelity. To develop a general system for odor
detection, in this study we present a preliminary work where we aim to test two
hypotheses: (i) that spectral features of local field potentials (LFPs) are
sufficient for robust single-trial odor detection and (ii) that signals from
the olfactory bulb alone are adequate. To test two hypotheses, we propose an
ensemble of complementary one-dimensional convolutional networks (ResCNN and
AttentionCNN) that decodes the presence of odor from multichannel olfactory
bulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble
model supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score
of 81.0%, and an AUC of 0.9247, substantially outperforming previous
benchmarks. In addition, the t-SNE visualization confirms that our framework
captures biologically significant signatures. These findings establish the
feasibility of robust single-trial detection of the presence of odor from
extracellular LFPs, as well as demonstrate the potential of deep learning
models to provide a deeper understanding of olfactory representations.

</details>


### [209] [Over-Squashing in GNNs and Causal Inference of Rewiring Strategies](https://arxiv.org/abs/2508.09265)
*Danial Saber,Amirali Salehi-Abari*

Main category: cs.LG

TL;DR: 该研究提出了一种评估图神经网络（GNNs）过度平滑问题的方法，并量化了重布线技术对缓解该问题的影响。研究发现，过度平滑在图分类任务中普遍存在且重布线有效，但在节点分类任务中不明显，重布线可能无效甚至有害。研究结果为判断何时以及如何应用重布线技术提供了指导。


<details>
  <summary>Details</summary>
Motivation: 消息传递图神经网络（GNNs）存在过度平滑问题，限制了其表达能力。重布线技术可以缓解此瓶颈，但由于缺乏直接的经验性过度平滑度量，其实际影响尚不清楚。

Method: 提出了一种基于节点对之间相互敏感性衰减率的、严格的、面向拓扑的方法来评估过度平滑。将该评估扩展到四个图级别统计量（普遍性、强度、变异性和极端性）。结合图内因果设计，量化了重布线策略如何影响不同图和节点分类基准上的过度平滑。

Result: 开发了一种即插即用的诊断工具，用于评估和量化图重布线对过度平滑的影响，并预测其在不同任务上的性能提升潜力。

Conclusion: 大多数图分类数据集存在过度平滑问题（程度不同），图重布线技术可以有效缓解该问题，但缓解程度和性能提升效果因数据集和方法而异。节点分类数据集的过度平滑问题不明显，重布线甚至可能加剧过度平滑，并且性能变化与过度平滑变化不相关。重布线在过度平滑问题显著且适度修正时最有效，过度激进或应用于轻度过度平滑图的重布线可能无效甚至损害性能。提供的诊断工具可帮助实践者在训练前判断重布线是否可能带来收益。

Abstract: Graph neural networks (GNNs) have exhibited state-of-the-art performance
across wide-range of domains such as recommender systems, material design, and
drug repurposing. Yet message-passing GNNs suffer from over-squashing --
exponential compression of long-range information from distant nodes -- which
limits expressivity. Rewiring techniques can ease this bottleneck; but their
practical impacts are unclear due to the lack of a direct empirical
over-squashing metric. We propose a rigorous, topology-focused method for
assessing over-squashing between node pairs using the decay rate of their
mutual sensitivity. We then extend these pairwise assessments to four
graph-level statistics (prevalence, intensity, variability, extremity).
Coupling these metrics with a within-graph causal design, we quantify how
rewiring strategies affect over-squashing on diverse graph- and
node-classification benchmarks. Our extensive empirical analyses show that most
graph classification datasets suffer from over-squashing (but to various
extents), and rewiring effectively mitigates it -- though the degree of
mitigation, and its translation into performance gains, varies by dataset and
method. We also found that over-squashing is less notable in node
classification datasets, where rewiring often increases over-squashing, and
performance variations are uncorrelated with over-squashing changes. These
findings suggest that rewiring is most beneficial when over-squashing is both
substantial and corrected with restraint -- while overly aggressive rewiring,
or rewiring applied to minimally over-squashed graphs, is unlikely to help and
may even harm performance. Our plug-and-play diagnostic tool lets practitioners
decide -- before any training -- whether rewiring is likely to pay off.

</details>


### [210] [Pattern-based Knowledge Component Extraction from Student Code Using Representation Learning](https://arxiv.org/abs/2508.09281)
*Muntasir Hoq,Griffin Pitts,Andrew Lan,Peter Brusilovsky,Bita Akram*

Main category: cs.LG

TL;DR: 提出了一种新颖的可解释框架，通过从学生代码中提取结构模式来自动化知识组件（KCs）的发现。该方法结合了VAE和注意力模型，并通过学习曲线分析和DKT进行了评估，结果显示能有效提升学生建模和知识追踪的性能。


<details>
  <summary>Details</summary>
Motivation: 自动化地从学生代码中提取知识组件（KCs）面临挑战，因为发现的KCs可解释性不足，且编程问题的开放性导致学生解决方案的结构变异性和编程概念间的复杂交互。

Method: 提出了一种新颖的可解释框架，通过基于模式的知识组件（KCs）进行自动化知识组件发现。该框架结合了变分自编码器（VAE）和基于注意力的表示学习模型，用于从学生代码中提取和聚类模式，形成基于模式的知识组件。

Result: 实验结果表明，所提出的方法能够生成有意义的学习轨迹，并在深度知识追踪（DKT）的预测性能上显著优于传统的知识追踪（KT）方法。

Conclusion: 该工作通过提供一个自动化、可扩展且可解释的框架，用于识别细粒度的代码模式和算法结构，从而推进了计算机科学教育中的知识建模，这对学生的学习至关重要。

Abstract: Effective personalized learning in computer science education depends on
accurately modeling what students know and what they need to learn. While
Knowledge Components (KCs) provide a foundation for such modeling, automated KC
extraction from student code is inherently challenging due to insufficient
explainability of discovered KCs and the open-endedness of programming problems
with significant structural variability across student solutions and complex
interactions among programming concepts. In this work, we propose a novel,
explainable framework for automated KC discovery through pattern-based KCs:
recurring structural patterns within student code that capture the specific
programming patterns and language constructs that students must master. Toward
this, we train a Variational Autoencoder to generate important representative
patterns from student code guided by an explainable, attention-based code
representation model that identifies important correct and incorrect pattern
implementations from student code. These patterns are then clustered to form
pattern-based KCs. We evaluate our KCs using two well-established methods
informed by Cognitive Science: learning curve analysis and Deep Knowledge
Tracing (DKT). Experimental results demonstrate meaningful learning
trajectories and significant improvements in DKT predictive performance over
traditional KT methods. This work advances knowledge modeling in CS education
by providing an automated, scalable, and explainable framework for identifying
granular code patterns and algorithmic constructs, essential for student
learning.

</details>


### [211] [Distilling Reinforcement Learning into Single-Batch Datasets](https://arxiv.org/abs/2508.09283)
*Connor Wilhelm,Dan Ventura*

Main category: cs.LG

TL;DR: Dataset distillation compresses RL environments into small supervised datasets for fast learning, transforming learning types and generalizing across tasks.


<details>
  <summary>Details</summary>
Motivation: To compress large datasets into smaller synthetic datasets that approximate learning on the original, enabling faster training (e.g., one-step gradient descent), and to explore the generalizability of distillation across different tasks and learning modalities.

Method: A novel extension of proximal policy optimization for meta-learning was used to distill RL environments into one-batch supervised learning datasets. The distillation process was applied to a multi-dimensional cart-pole problem, all MuJoCo environments, and several Atari games.

Result: Distillation successfully compressed RL environments into one-batch supervised learning datasets. This demonstrated compression of RL tasks and transformation from RL to supervised learning. The method was shown to be generalizable across different tasks and learner architectures, and capable of distilling environments into the smallest possible synthetic datasets.

Conclusion: Dataset distillation can compress complex RL environments into one-step supervised learning datasets, demonstrating generalizability across tasks and learner architectures, and the ability to distill environments into the smallest possible synthetic datasets.

Abstract: Dataset distillation compresses a large dataset into a small synthetic
dataset such that learning on the synthetic dataset approximates learning on
the original. Training on the distilled dataset can be performed in as little
as one step of gradient descent. We demonstrate that distillation is
generalizable to different tasks by distilling reinforcement learning
environments into one-batch supervised learning datasets. This demonstrates not
only distillation's ability to compress a reinforcement learning task but also
its ability to transform one learning modality (reinforcement learning) into
another (supervised learning). We present a novel extension of proximal policy
optimization for meta-learning and use it in distillation of a
multi-dimensional extension of the classic cart-pole problem, all MuJoCo
environments, and several Atari games. We demonstrate distillation's ability to
compress complex RL environments into one-step supervised learning, explore RL
distillation's generalizability across learner architectures, and demonstrate
distilling an environment into the smallest-possible synthetic dataset.

</details>


### [212] [Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation](https://arxiv.org/abs/2508.09299)
*Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi*

Main category: cs.LG

TL;DR: 提出了一种结合联邦学习、区块链、声誉投票和IPFS的去中心化天气预报框架，以提高准确性、弹性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决当前中心化天气预报系统面临的安全漏洞、可扩展性限制和单点故障问题。

Method: 将联邦学习（FL）与区块链技术、声誉投票机制以及IPFS相结合，用于去中心化天气预报。

Result: 实验结果表明，该方法提高了预测准确性、系统弹性和可扩展性。

Conclusion: 该方法提高了预测准确性、系统弹性和可扩展性，适用于安全关键环境。

Abstract: Weather forecasting plays a vital role in disaster preparedness, agriculture,
and resource management, yet current centralized forecasting systems are
increasingly strained by security vulnerabilities, limited scalability, and
susceptibility to single points of failure. To address these challenges, we
propose a decentralized weather forecasting framework that integrates Federated
Learning (FL) with blockchain technology. FL enables collaborative model
training without exposing sensitive local data; this approach enhances privacy
and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures
transparent and dependable verification of model updates. To further enhance
the system's security, we introduce a reputation-based voting mechanism that
assesses the trustworthiness of submitted models while utilizing the
Interplanetary File System (IPFS) for efficient off-chain storage. Experimental
results demonstrate that our approach not only improves forecasting accuracy
but also enhances system resilience and scalability, making it a viable
candidate for deployment in real-world, security-critical environments.

</details>


### [213] [Exact Verification of Graph Neural Networks with Incremental Constraint Solving](https://arxiv.org/abs/2508.09320)
*Minghao Liu,Chia-Hsuan Lu,Marta Kwiatkowska*

Main category: cs.LG

TL;DR: A new verification method, GNNev, provides exact robustness guarantees for GNNs against various perturbations, supporting sum, max, and mean aggregations.


<details>
  <summary>Details</summary>
Motivation: Addressing the lack of support for commonly used aggregation functions in adversarial robustness guarantees for message-passing GNNs.

Method: Constraint solving with bound tightening, iteratively solving relaxed constraint satisfaction problems with incremental solving capabilities.

Result: GNNev achieves superior performance compared to existing exact verification tools on sum-aggregated node classification tasks, validated through extensive experiments on standard and real-world datasets.

Conclusion: GNNev is a versatile solver that supports sum, max, and mean aggregation functions, demonstrating usability, effectiveness, and superior performance compared to existing exact verification tools on sum-aggregated node classification tasks.

Abstract: Graph neural networks (GNNs) are increasingly employed in high-stakes
applications, such as fraud detection or healthcare, but are susceptible to
adversarial attacks. A number of techniques have been proposed to provide
adversarial robustness guarantees, but support for commonly used aggregation
functions in message-passing GNNs is still lacking. In this paper, we develop
an exact (sound and complete) verification method for GNNs to compute
guarantees against attribute and structural perturbations that involve edge
addition or deletion, subject to budget constraints. Focusing on node
classification tasks, our method employs constraint solving with bound
tightening, and iteratively solves a sequence of relaxed constraint
satisfaction problems while relying on incremental solving capabilities of
solvers to improve efficiency. We implement GNNev, a versatile solver for
message-passing neural networks, which supports three aggregation functions,
sum, max and mean, with the latter two considered here for the first time.
Extensive experimental evaluation of GNNev on two standard benchmarks (Cora and
CiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its
usability and effectiveness, as well as superior performance compared to
existing {exact verification} tools on sum-aggregated node classification
tasks.

</details>


### [214] [Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization](https://arxiv.org/abs/2508.09330)
*Gideon Vos,Liza van Eijk,Zoltan Sarnyai,Mostafa Rahimi Azghadi*

Main category: cs.LG

TL;DR: 提出了一种基于权重的突触修剪方法，作为Dropout的替代方案，通过动态稀疏化提高时间序列预测的准确性，尤其在金融领域效果显著。


<details>
  <summary>Details</summary>
Motivation: 生物大脑中的突触修剪会移除弱连接以提高效率，而人工神经网络中的Dropout正则化会随机禁用神经元，没有考虑活动依赖性修剪。本文旨在提出一种更符合生物学特性的方法。

Method: 提出了一种基于权重的突触修剪方法，在训练过程中逐渐移除低重要性连接，将权重重要性计算为跨层的绝对值大小，并应用三次函数调度逐步增加全局稀疏度。在固定时间间隔，修剪掩码永久移除低重要性权重，同时为激活的权重保持梯度流，无需单独的修剪和微调阶段。

Result: 在RNN、LSTM和Patch Time Series Transformer等多个时间序列预测模型以及四个数据集上的实验表明，该方法具有持续的性能提升，在金融预测任务中，MAE（平均绝对误差）最多可降低20%，在部分Transformer模型中最多可降低52%。

Conclusion: 该方法通过结合权重剔除和渐进稀疏化来改进正则化，并易于集成到各种架构中。尤其在金融时间序列预测方面表现出色，有望成为传统Dropout技术的实用替代方案。

Abstract: Synaptic pruning in biological brains removes weak connections to improve
efficiency. In contrast, dropout regularization in artificial neural networks
randomly deactivates neurons without considering activity-dependent pruning. We
propose a magnitude-based synaptic pruning method that better reflects biology
by progressively removing low-importance connections during training.
Integrated directly into the training loop as a dropout replacement, our
approach computes weight importance from absolute magnitudes across layers and
applies a cubic schedule to gradually increase global sparsity. At fixed
intervals, pruning masks permanently remove low-importance weights while
maintaining gradient flow for active ones, eliminating the need for separate
pruning and fine-tuning phases. Experiments on multiple time series forecasting
models including RNN, LSTM, and Patch Time Series Transformer across four
datasets show consistent gains. Our method ranked best overall, with
statistically significant improvements confirmed by Friedman tests (p < 0.01).
In financial forecasting, it reduced Mean Absolute Error by up to 20% over
models with no or standard dropout, and up to 52% in select transformer models.
This dynamic pruning mechanism advances regularization by coupling weight
elimination with progressive sparsification, offering easy integration into
diverse architectures. Its strong performance, especially in financial time
series forecasting, highlights its potential as a practical alternative to
conventional dropout techniques.

</details>


### [215] [RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs](https://arxiv.org/abs/2508.09334)
*Zhongtian Sun,Anoushka Harit*

Main category: cs.LG

TL;DR: RicciFlowRec 使用几何流（Ricci曲率和流）来分析金融图，以识别风险和进行推荐，初步结果显示出优势。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的金融推荐框架，通过几何方法（Ricci曲率和流）实现根源归因和风险评估。

Method: 通过在动态金融图上应用Ricci曲率和流进行因果归因。模型融合了股票、宏观经济指标和新闻之间的演化交互，并使用离散Ricci曲率量化局部压力，通过Ricci流追踪冲击传播。

Result: 初步结果显示，在S&P 500数据和FinBERT情感分析的帮助下，RicciFlowRec在合成扰动下表现出更好的鲁棒性和可解释性。

Conclusion: RicciFlowRec 是首个将几何流推理应用于金融决策支持的推荐系统，初步结果表明其在扰动下的鲁棒性和可解释性有所提高。

Abstract: We propose RicciFlowRec, a geometric recommendation framework that performs
root cause attribution via Ricci curvature and flow on dynamic financial
graphs. By modelling evolving interactions among stocks, macroeconomic
indicators, and news, we quantify local stress using discrete Ricci curvature
and trace shock propagation via Ricci flow. Curvature gradients reveal causal
substructures, informing a structural risk-aware ranking function. Preliminary
results on S\&P~500 data with FinBERT-based sentiment show improved robustness
and interpretability under synthetic perturbations. This ongoing work supports
curvature-based attribution and early-stage risk-aware ranking, with plans for
portfolio optimization and return forecasting. To our knowledge, RicciFlowRec
is the first recommender to apply geometric flow-based reasoning in financial
decision support.

</details>


### [216] [Resurrecting the Salmon: Rethinking Mechanistic Interpretability with Domain-Specific Sparse Autoencoders](https://arxiv.org/abs/2508.09363)
*Charles O'Neill,Mudith Jayasekara,Max Kirkby*

Main category: cs.LG

TL;DR: 通过在医学领域训练稀疏自编码器（SAE），可以提高其捕获特定领域特征的能力，从而比通用SAE提供更高保真度、更易于解释的潜在分解，并减少“暗物质”。


<details>
  <summary>Details</summary>
Motivation: 传统的稀疏自编码器（SAE）在训练时使用广泛的数据分布，导致其固定的潜在预算只能捕捉高频、通用的模式。这会在重建误差中产生显著的线性“暗物质”，并使学习到的潜在特征碎片化或相互吸收，从而阻碍了对其机制的解释。本研究旨在通过将SAE训练限制在特定领域来解决这些问题，以提高重建保真度和可解释性。

Method: 本研究采用了JumpReLU稀疏自编码器（SAE）来训练Gemma-2模型第20层的激活，并使用了19.5万个临床问答样本。研究的核心方法是将SAE的训练限制在医学这一特定领域，以此来与在广泛数据分布上训练的传统SAE进行对比。

Result: 在Gemma-2模型的第20层激活上使用19.5万个临床问答样本训练JumpReLU SAEs，结果显示，与广泛领域SAE相比，领域限制的SAE能够解释高达20%的额外方差，实现更高的损失恢复，并减少线性残差误差。自动化和人工评估均证实，学到的特征与临床上有意义的概念（如“味觉感觉”或“传染性单核细胞增多症”）相关，而非信息量低的标记。这些领域特定的SAE捕获了相关的线性结构，留下更小、更纯粹非线性的残差。

Conclusion: 通过将稀疏自编码器（SAE）的训练限制在特定领域（如医学文本），可以重新分配模型容量以捕获特定于领域的特征，从而提高重建保真度和可解释性。与广泛领域SAE相比，领域限制的SAE能够解释高达20%的额外方差，实现更高的损失恢复，并减少线性残差误差。这表明领域限制可以缓解广泛领域SAE的关键限制，实现更完整、更具可解释性的潜在分解，并可能需要重新审视通用SAE的“基础模型”扩展方法。

Abstract: Sparse autoencoders (SAEs) decompose large language model (LLM) activations
into latent features that reveal mechanistic structure. Conventional SAEs train
on broad data distributions, forcing a fixed latent budget to capture only
high-frequency, generic patterns. This often results in significant linear
``dark matter'' in reconstruction error and produces latents that fragment or
absorb each other, complicating interpretation. We show that restricting SAE
training to a well-defined domain (medical text) reallocates capacity to
domain-specific features, improving both reconstruction fidelity and
interpretability. Training JumpReLU SAEs on layer-20 activations of Gemma-2
models using 195k clinical QA examples, we find that domain-confined SAEs
explain up to 20\% more variance, achieve higher loss recovery, and reduce
linear residual error compared to broad-domain SAEs. Automated and human
evaluations confirm that learned features align with clinically meaningful
concepts (e.g., ``taste sensations'' or ``infectious mononucleosis''), rather
than frequent but uninformative tokens. These domain-specific SAEs capture
relevant linear structure, leaving a smaller, more purely nonlinear residual.
We conclude that domain-confinement mitigates key limitations of broad-domain
SAEs, enabling more complete and interpretable latent decompositions, and
suggesting the field may need to question ``foundation-model'' scaling for
general-purpose SAEs.

</details>


### [217] [Understanding Dementia Speech Alignment with Diffusion-Based Image Generation](https://arxiv.org/abs/2508.09385)
*Mansi,Anastasios Lepipas,Dominika Woszczyk,Yiying Guan,Soteris Demetriou*

Main category: cs.LG

TL;DR: 研究发现，文本到图像模型能够将痴呆症相关的语音信息与生成的图像对齐，并且可以仅从生成的图像中检测出痴呆症，准确率高达75%。同时，研究还开发了可解释性方法来识别导致检测的语言因素。


<details>
  <summary>Details</summary>
Motivation: 虽然人们期望文本到图像模型能在相同的潜在空间中对齐输入的文本和生成的图像，但对于这种对齐是否可能在病态语音和生成的图像之间实现，人们知之甚少。本研究旨在探讨这种可能性。

Method: 研究了文本到图像模型将痴呆症相关的语音信息与生成的图像对齐的能力，并开发了用于解释这种对齐的方法。

Result: 令人惊讶的是，研究发现仅从生成的图像中就能检测出痴呆症，在ADReSS数据集上的准确率达到了75%。

Conclusion: 该模型可以单独从生成的图像中检测出痴呆症，准确率达到75%，并且可以利用可解释性方法找出语言中导致检测的因素。

Abstract: Text-to-image models generate highly realistic images based on natural
language descriptions and millions of users use them to create and share images
online. While it is expected that such models can align input text and
generated image in the same latent space little has been done to understand
whether this alignment is possible between pathological speech and generated
images. In this work, we examine the ability of such models to align
dementia-related speech information with the generated images and develop
methods to explain this alignment. Surprisingly, we found that dementia
detection is possible from generated images alone achieving 75% accuracy on the
ADReSS dataset. We then leverage explainability methods to show which parts of
the language contribute to the detection.

</details>


### [218] [Integrating Feature Attention and Temporal Modeling for Collaborative Financial Risk Assessment](https://arxiv.org/abs/2508.09399)
*Yue Yao,Zhen Xu,Youzhu Liu,Kunyuan Ma,Yuxiu Lin,Mohan Jiang*

Main category: cs.LG

TL;DR: 该研究提出了一种基于联邦学习的金融风险分析框架，通过差分隐私和特征注意机制在保护数据隐私的同时实现跨机构的协同建模和系统性风险识别。


<details>
  <summary>Details</summary>
Motivation: 为了解决跨机构金融风险分析中的数据隐私和协同建模挑战。

Method: 提出了一种基于联邦学习的风险评估框架，结合了特征注意机制和时间建模结构。通过分布式优化策略，各金融机构在本地训练子模型，并使用差分隐私和噪声注入技术保护模型参数，然后上传到中央服务器进行聚合，生成用于系统性风险识别的全局模型。

Result: 实验结果表明，所提出的模型在所有评估指标上均优于传统中心化方法和现有的联邦学习变体，展示了其在敏感金融环境中的强大建模能力和实际价值。

Conclusion: 该模型在通信效率、模型准确性、系统性风险检测和跨市场泛化能力方面优于传统中心化方法和现有的联邦学习方法，具有强大的建模能力和实际价值。

Abstract: This paper addresses the challenges of data privacy and collaborative
modeling in cross-institution financial risk analysis. It proposes a risk
assessment framework based on federated learning. Without sharing raw data, the
method enables joint modeling and risk identification across multiple
institutions. This is achieved by incorporating a feature attention mechanism
and temporal modeling structure. Specifically, the model adopts a distributed
optimization strategy. Each financial institution trains a local sub-model. The
model parameters are protected using differential privacy and noise injection
before being uploaded. A central server then aggregates these parameters to
generate a global model. This global model is used for systemic risk
identification. To validate the effectiveness of the proposed method, multiple
experiments are conducted. These evaluate communication efficiency, model
accuracy, systemic risk detection, and cross-market generalization. The results
show that the proposed model outperforms both traditional centralized methods
and existing federated learning variants across all evaluation metrics. It
demonstrates strong modeling capabilities and practical value in sensitive
financial environments. The method enhances the scope and efficiency of risk
identification while preserving data sovereignty. It offers a secure and
efficient solution for intelligent financial risk analysis.

</details>


### [219] [Graph Neural Network and Transformer Integration for Unsupervised System Anomaly Discovery](https://arxiv.org/abs/2508.09401)
*Yun Zi,Ming Gong,Zhihao Xue,Yujun Zou,Nia Qi,Yingnan Deng*

Main category: cs.LG

TL;DR: 提出了一种结合图卷积和Transformer的无监督异常检测方法，用于分布式后端服务系统，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决分布式后端服务系统中无标签数据、复杂结构依赖和多样行为演变等实际挑战，提出一种无监督异常检测方法。

Method: 本研究提出了一种无监督的异常检测方法，它首先构建一个基于服务调用关系动态图，并应用图卷积提取高阶结构表示。然后，利用Transformer模型来捕捉节点行为的长期依赖和局部波动。在特征融合阶段，通过可学习的联合嵌入机制将结构和行为表示融合为统一的异常向量。最后，通过非线性映射计算异常分数，实现端到端的无监督检测。

Result: 实验结果表明，该方法在真实世界云监控数据上的表现优于现有模型，能够有效地捕获异常传播路径并模拟动态行为序列，具有更强的表达能力和稳定性。

Conclusion: 该方法在真实世界的云监控数据上进行了实验，结果显示其在多个关键指标上优于现有模型，在捕获异常传播路径和模拟动态行为序列方面表现出更强的表达能力和稳定性，具有很高的实际部署潜力。

Abstract: This study proposes an unsupervised anomaly detection method for distributed
backend service systems, addressing practical challenges such as complex
structural dependencies, diverse behavioral evolution, and the absence of
labeled data. The method constructs a dynamic graph based on service invocation
relationships and applies graph convolution to extract high-order structural
representations from multi-hop topologies. A Transformer is used to model the
temporal behavior of each node, capturing long-term dependencies and local
fluctuations. During the feature fusion stage, a learnable joint embedding
mechanism integrates structural and behavioral representations into a unified
anomaly vector. A nonlinear mapping is then applied to compute anomaly scores,
enabling an end-to-end detection process without supervision. Experiments on
real-world cloud monitoring data include sensitivity analyses across different
graph depths, sequence lengths, and data perturbations. Results show that the
proposed method outperforms existing models on several key metrics,
demonstrating stronger expressiveness and stability in capturing anomaly
propagation paths and modeling dynamic behavior sequences, with high potential
for practical deployment.

</details>


### [220] [NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs](https://arxiv.org/abs/2508.09473)
*Birong Pan,Mayi Xu,Qiankun Pi,Jianhao Chen,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.LG

TL;DR: NeuronTune 通过细粒度调节神经元来优化 LLM 的安全性和效用，解决了现有技术的局限性，并在实验中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 对齐技术存在鲁棒性不足、频繁拒绝良性查询、生成文本质量下降和通用任务性能下降等相互关联的缺陷。这些局限性源于现有方法中粗粒度的层级干预。

Method: NeuronTune 是一个细粒度的框架，通过动态调节稀疏神经元来实现安全-效用协同优化。该方法首先通过归因识别所有层中的安全关键和效用保持神经元，然后采用元学习来适应性地放大安全神经元激活并抑制效用神经元激活。NeuronTune 允许通过神经元计数阈值对干预范围进行可调校准，以支持对安全关键或效用优先场景的灵活适应。

Result: 实验结果表明，NeuronTune 在模型安全性和效用方面均表现出色。

Conclusion: NeuronTune 显著优于现有技术，在保持良好效用的同时实现卓越的模型安全性。

Abstract: Ensuring robust safety alignment while preserving utility is critical for the
reliable deployment of Large Language Models (LLMs). However, current
techniques fundamentally suffer from intertwined deficiencies: insufficient
robustness against malicious attacks, frequent refusal of benign queries,
degradation in generated text quality and general task performance--the former
two reflecting deficits in robust safety and the latter constituting utility
impairment. We trace these limitations to the coarse-grained layer-wise
interventions in existing methods. To resolve this, we propose NeuronTune, a
fine-grained framework that dynamically modulates sparse neurons to achieve
simultaneous safety-utility optimization. Our approach first identifies
safety-critical and utility-preserving neurons across all layers via
attribution, then employs meta-learning to adaptively amplify safety-neuron
activations and suppress utility-neuron activations. Crucially, NeuronTune
enables tunable adjustment of intervention scope via neuron-count thresholds,
supporting flexible adaptation to security-critical or utility-priority
scenarios. Extensive experimental results demonstrate that our method
significantly outperforms existing state-of-the-art technologies, achieving
superior model safety while maintaining excellent utility.

</details>


### [221] [Domain-Generalization to Improve Learning in Meta-Learning Algorithms](https://arxiv.org/abs/2508.09418)
*Usman Anjum,Chris Stockman,Cat Luong,Justin Zhan*

Main category: cs.LG

TL;DR: DGS-MAML is a novel meta-learning algorithm that combines gradient matching with sharpness-aware minimization for better generalization in few-shot learning scenarios.


<details>
  <summary>Details</summary>
Motivation: To generalize across tasks with limited training data by enhancing model adaptability and robustness.

Method: DGS-MAML combines gradient matching with sharpness-aware minimization in a bi-level optimization framework.

Result: Experimental results on benchmark datasets show that DGS-MAML outperforms existing approaches in terms of accuracy and generalization.

Conclusion: DGS-MAML outperformed existing approaches in terms of accuracy and generalization, and is particularly useful for scenarios requiring few-shot learning and quick adaptation.

Abstract: This paper introduces Domain Generalization Sharpness-Aware Minimization
Model-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm
designed to generalize across tasks with limited training data. DGS-MAML
combines gradient matching with sharpness-aware minimization in a bi-level
optimization framework to enhance model adaptability and robustness. We support
our method with theoretical analysis using PAC-Bayes and convergence
guarantees. Experimental results on benchmark datasets show that DGS-MAML
outperforms existing approaches in terms of accuracy and generalization. The
proposed method is particularly useful for scenarios requiring few-shot
learning and quick adaptation, and the source code is publicly available at
GitHub.

</details>


### [222] [Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees](https://arxiv.org/abs/2508.09427)
*Xiaoyu Li,Guangyu Tang,Jiaojiao Jiang*

Main category: cs.LG

TL;DR: IHGNN通过求解不动点方程，在超图上实现稳定高效的全局传播，克服了传统模型的深度限制，并在实验中表现出优越的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界的交互是基于群体的，而不是成对的，例如具有多个合著者的论文和联合使用物品的用户。超图神经网络在对更高阶关系进行建模方面显示出巨大潜力，但它们依赖于固定数量的显式消息传递层，这限制了捕获长距离依赖关系的能力，并且随着深度的增加会使训练不稳定。

Method: 提出了一种名为隐式超图神经网络（IHGNN）的模型，它将隐式平衡公式引入超图，通过求解非线性不动点方程来计算表示，实现了跨超边的稳定高效的全局传播，无需深度架构。开发了一种良定义的训练方案，并具有可证明的收敛性，分析了模型的过平滑条件和表达能力，并推导了超图上的归纳泛化界限。此外，还提出了一种隐式梯度训练程序，并结合了基于投影的稳定策略。

Result: IHGNN是一种新的超图神经网络模型，它通过求解非线性不动点方程来实现跨超边的全局传播，从而克服了传统超图神经网络在深度和稳定性方面的限制。实验证明了IHGNN在准确性和鲁棒性方面的优越性。

Conclusion: IHGNN在引用基准的实验中，在准确性和鲁棒性方面持续优于传统的图/超图神经网络基线。IHGNN对随机初始化和超参数变化具有弹性，显示了其在更高阶关系学习方面的泛化能力和实用价值。

Abstract: Many real-world interactions are group-based rather than pairwise such as
papers with multiple co-authors and users jointly engaging with items.
Hypergraph neural networks have shown great promise at modeling higher-order
relations, but their reliance on a fixed number of explicit message-passing
layers limits long-range dependency capture and can destabilize training as
depth grows. In this work, we introduce Implicit Hypergraph Neural Networks
(IHGNN), which bring the implicit equilibrium formulation to hypergraphs:
instead of stacking layers, IHGNN computes representations as the solution to a
nonlinear fixed-point equation, enabling stable and efficient global
propagation across hyperedges without deep architectures. We develop a
well-posed training scheme with provable convergence, analyze the oversmoothing
conditions and expressivity of the model, and derive a transductive
generalization bound on hypergraphs. We further present an implicit-gradient
training procedure coupled with a projection-based stabilization strategy.
Extensive experiments on citation benchmarks show that IHGNN consistently
outperforms strong traditional graph/hypergraph neural network baselines in
both accuracy and robustness. Empirically, IHGNN is resilient to random
initialization and hyperparameter variation, highlighting its strong
generalization and practical value for higher-order relational learning.

</details>


### [223] [NEXICA: Discovering Road Traffic Causality (Extended arXiv Version)](https://arxiv.org/abs/2508.09447)
*Siddharth Srikanth,John Krumm,Jonathan Qin*

Main category: cs.LG

TL;DR: NEXICA算法通过分析道路速度数据，能够准确识别出高速公路系统中导致交通拥堵的关键节点，并在实际测试中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了减少道路交通拥堵，需要一种有效策略来识别导致拥堵的根本原因，NEXICA算法旨在发现高速公路系统中可能导致其他区域拥堵的节点。

Method: NEXICA算法，一种新的因果发现方法，专注于时间序列事件（交通拥堵的开始），使用最大似然估计开发概率模型来计算两个地点之间发生拥堵的概率，并训练二元分类器来识别因果关系。

Result: 在为期六个月的洛杉矶地区道路速度数据测试中，NEXICA算法在准确性和计算速度方面均优于最先进的基线方法。

Conclusion: NEXICA算法通过关注时间序列事件的存在与否，利用最大似然估计开发了一个概率模型来计算两个地点之间自发性和引起性拥堵的概率，并训练了一个二元分类器来识别因果关系。该方法在洛杉矶地区的道路速度数据上进行了测试，证明其在准确性和计算速度方面优于现有技术。

Abstract: Road traffic congestion is a persistent problem. Focusing resources on the
causes of congestion is a potentially efficient strategy for reducing
slowdowns. We present NEXICA, an algorithm to discover which parts of the
highway system tend to cause slowdowns on other parts of the highway. We use
time series of road speeds as inputs to our causal discovery algorithm. Finding
other algorithms inadequate, we develop a new approach that is novel in three
ways. First, it concentrates on just the presence or absence of events in the
time series, where an event indicates the temporal beginning of a traffic
slowdown. Second, we develop a probabilistic model using maximum likelihood
estimation to compute the probabilities of spontaneous and caused slowdowns
between two locations on the highway. Third, we train a binary classifier to
identify pairs of cause/effect locations trained on pairs of road locations
where we are reasonably certain a priori of their causal connections, both
positive and negative. We test our approach on six months of road speed data
from 195 different highway speed sensors in the Los Angeles area, showing that
our approach is superior to state-of-the-art baselines in both accuracy and
computation speed.

</details>


### [224] [A Unified Contrastive-Generative Framework for Time Series Classification](https://arxiv.org/abs/2508.09451)
*Ziyu Liu,Azadeh Alavi,Minyi Li,Xiang Zhang*

Main category: cs.LG

TL;DR: CoGenT 是第一个将对比学习和生成方法相结合的框架，以提高时间序列的自我监督学习性能。


<details>
  <summary>Details</summary>
Motivation: 自我监督学习（SSL）主要包括两个范式：擅长实例判别的对比方法和对数据分布进行建模的生成方法。虽然它们各自有效，但它们的互补潜力仍未被探索。

Method: 提出了一种对比生成时间序列框架（CoGenT），该框架通过联合对比生成优化统一了这些范式。

Result: 在六个不同的时间序列数据集上评估了 CoGenT。结果显示持续改进，与单独的 SimCLR 和 MAE 相比，F1 增益分别高达 59.2% 和 14.27%。

Conclusion: 混合目标保留了判别力，同时获得了生成鲁棒性。这些发现为时间域中的混合 SSL 奠定了基础。

Abstract: Self-supervised learning (SSL) for multivariate time series mainly includes
two paradigms: contrastive methods that excel at instance discrimination and
generative approaches that model data distributions. While effective
individually, their complementary potential remains unexplored. We propose a
Contrastive Generative Time series framework (CoGenT), the first framework to
unify these paradigms through joint contrastive-generative optimization. CoGenT
addresses fundamental limitations of both approaches: it overcomes contrastive
learning's sensitivity to high intra-class similarity in temporal data while
reducing generative methods' dependence on large datasets. We evaluate CoGenT
on six diverse time series datasets. The results show consistent improvements,
with up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE,
respectively. Our analysis reveals that the hybrid objective preserves
discriminative power while acquiring generative robustness. These findings
establish a foundation for hybrid SSL in temporal domains. We will release the
code shortly.

</details>


### [225] [Open-Set Fault Diagnosis in Multimode Processes via Fine-Grained Deep Feature Representation](https://arxiv.org/abs/2508.09462)
*Guangqiang Li,M. Amine Atoui,Xiangshun Li*

Main category: cs.LG

TL;DR: 提出了一种名为FGCRN的新型开放集故障诊断模型，该模型结合了多种深度学习技术，能够处理多模态过程中的复杂数据分布，并有效区分已知和未知故障。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态过程中同一健康状态样本的多种聚类分布导致的决策边界难以构建的问题，提出一种能够准确分类已知健康状态并有效识别未知故障的开放集故障诊断模型。

Method: 提出了一种结合多尺度深度卷积、双向门控循环单元和时间注意力机制的新型细粒度聚类和拒绝网络（FGCRN）。通过设计基于距离的损失函数来增强类内紧密度，并利用无监督学习构建细粒度特征表示。采用极值理论对样本特征与其对应细粒度表示之间的距离进行建模，以实现对未知故障的有效识别。

Result: 通过大量实验证明了所提出方法的优越性能。

Conclusion: 该模型在多模态过程故障诊断方面表现出优越性能，能够准确分类已知健康状态并有效识别未知故障。

Abstract: A reliable fault diagnosis system should not only accurately classify known
health states but also effectively identify unknown faults. In multimode
processes, samples belonging to the same health state often show multiple
cluster distributions, making it difficult to construct compact and accurate
decision boundaries for that state. To address this challenge, a novel open-set
fault diagnosis model named fine-grained clustering and rejection network
(FGCRN) is proposed. It combines multiscale depthwise convolution,
bidirectional gated recurrent unit and temporal attention mechanism to capture
discriminative features. A distance-based loss function is designed to enhance
the intra-class compactness. Fine-grained feature representations are
constructed through unsupervised learning to uncover the intrinsic structures
of each health state. Extreme value theory is employed to model the distance
between sample features and their corresponding fine-grained representations,
enabling effective identification of unknown faults. Extensive experiments
demonstrate the superior performance of the proposed method.

</details>


### [226] [Learn to Explore: Meta NAS via Bayesian Optimization Guided Graph Generation](https://arxiv.org/abs/2508.09467)
*Zijun Sun,Yanning Shen*

Main category: cs.LG

TL;DR: GraB-NAS is a novel Meta-NAS framework that models architectures as graphs and uses a hybrid search strategy to discover high-performing, generalizable, and computationally efficient neural architectures, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing Meta-NAS methods struggle with poor generalization, limited search spaces, or high computational costs, restricting their real-world applicability. The paper aims to address these limitations.

Method: GraB-NAS models neural architectures as graphs and employs a hybrid search strategy combining global architecture search via Bayesian Optimization and local exploration via gradient ascent in the latent space.

Result: GraB-NAS discovers task-aware architectures with strong performance, even beyond the predefined search space, outperforming existing Meta-NAS baselines.

Conclusion: GraB-NAS outperformed state-of-the-art Meta-NAS baselines, achieving better generalization and search effectiveness.

Abstract: Neural Architecture Search (NAS) automates the design of high-performing
neural networks but typically targets a single predefined task, thereby
restricting its real-world applicability. To address this, Meta Neural
Architecture Search (Meta-NAS) has emerged as a promising paradigm that
leverages prior knowledge across tasks to enable rapid adaptation to new ones.
Nevertheless, existing Meta-NAS methods often struggle with poor
generalization, limited search spaces, or high computational costs. In this
paper, we propose a novel Meta-NAS framework, GraB-NAS. Specifically, GraB-NAS
first models neural architectures as graphs, and then a hybrid search strategy
is developed to find and generate new graphs that lead to promising neural
architectures. The search strategy combines global architecture search via
Bayesian Optimization in the search space with local exploration for novel
neural networks via gradient ascent in the latent space. Such a hybrid search
strategy allows GraB-NAS to discover task-aware architectures with strong
performance, even beyond the predefined search space. Extensive experiments
demonstrate that GraB-NAS outperforms state-of-the-art Meta-NAS baselines,
achieving better generalization and search effectiveness.

</details>


### [227] [DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries](https://arxiv.org/abs/2508.09468)
*Muhammad Sakib Khan Inan,Kewen Liao*

Main category: cs.LG

TL;DR: DeepFeatIoT是一个新型深度学习模型，通过融合学习和非学习特征（包括LLM特征），有效解决了物联网时间序列数据中的数据异构性、采样不规则等问题，提高了数据分类的准确性，尤其在标记数据稀疏时效果更佳。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）传感器产生的时间序列数据因传感器元数据丢失或模糊、数据源异构性、采样频率不一、度量单位不一致以及时间戳不规则等挑战，难以解释，从而削弱了智能系统的有效性。

Method: 提出了一种名为DeepFeatIoT的新型深度学习模型，该模型整合了学习到的局部和全局特征、基于随机卷积核的非学习特征以及来自大型语言模型（LLM）的特征。

Result: 与最先进的基准模型相比，DeepFeatIoT模型在真实世界的物联网传感器数据集上表现出持续且泛化的性能，尤其是在标记数据有限的情况下，其在物联网时间序列传感器数据分类任务上的有效性得到了显著提升。

Conclusion: DeepFeatIoT模型在处理真实世界的物联网传感器数据集时表现出色，跨越了不同关键应用领域，其性能优于最先进的基准模型，这表明DeepFeatIoT有潜力推动物联网分析的重大进步，并支持下一代智能系统的开发。

Abstract: Internet of Things (IoT) sensors are ubiquitous technologies deployed across
smart cities, industrial sites, and healthcare systems. They continuously
generate time series data that enable advanced analytics and automation in
industries. However, challenges such as the loss or ambiguity of sensor
metadata, heterogeneity in data sources, varying sampling frequencies,
inconsistent units of measurement, and irregular timestamps make raw IoT time
series data difficult to interpret, undermining the effectiveness of smart
systems. To address these challenges, we propose a novel deep learning model,
DeepFeatIoT, which integrates learned local and global features with
non-learned randomized convolutional kernel-based features and features from
large language models (LLMs). This straightforward yet unique fusion of diverse
learned and non-learned features significantly enhances IoT time series sensor
data classification, even in scenarios with limited labeled data. Our model's
effectiveness is demonstrated through its consistent and generalized
performance across multiple real-world IoT sensor datasets from diverse
critical application domains, outperforming state-of-the-art benchmark models.
These results highlight DeepFeatIoT's potential to drive significant
advancements in IoT analytics and support the development of next-generation
smart systems.

</details>


### [228] [EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models](https://arxiv.org/abs/2508.09471)
*Omar Bazarbachi,Zijun Sun,Yanning Shen*

Main category: cs.LG

TL;DR: EGGS-PTP 是一种新的大型语言模型结构化剪枝方法，通过图论和扩展图来减少模型大小和计算量，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛采用和规模的扩大，部署这些庞大的基础模型所带来的计算和内存挑战日益严峻，因此有必要开发更高效的模型变体。

Method: EGGS-PTP（Expander-Graph Guided Structured Post-training Pruning）是一种利用图论指导 N:M 结构化剪枝的方法，通过引入扩展图（expander graphs）的概念来保证剪枝后网络的连通性，从而保留关键的模型功能。

Result: 实验结果表明，EGGS-PTP 在实现结构化稀疏性带来的显著加速和内存节省的同时，在准确性方面也优于现有的结构化剪枝技术。

Conclusion: EGGS-PTP 能够实现显著的加速和内存节省，并且在准确性方面优于现有的结构化剪枝技术，适用于各种大型语言模型。

Abstract: As Large Language Models (LLMs) become more widely adopted and scale up in
size, the computational and memory challenges involved in deploying these
massive foundation models have grown increasingly severe. This underscores the
urgent need to develop more efficient model variants. Faced with this
challenge, the present work introduces EGGS-PTP: an Expander-Graph Guided
Structured Post-training Pruning method. The proposed approach leverages graph
theory to guide the design of N:M structured pruning, effectively reducing
model size and computational demands. By incorporating concepts from expander
graphs, EGGS-PTP ensures information flow within the pruned network, preserving
essential model functionality. Extensive numerical experiments demonstrate that
EGGS-PTP not only achieves significant acceleration and memory savings due to
structured sparsity but also outperforms existing structured pruning techniques
in terms of accuracy across various LLMs.

</details>


### [229] [Large-Small Model Collaborative Framework for Federated Continual Learning](https://arxiv.org/abs/2508.09489)
*Hao Yu,Xin Yang,Boyang Fan,Xuemei Cao,Hanlin Gu,Lixin Fan,Qiang Yang*

Main category: cs.LG

TL;DR: 为了解决联邦持续学习中基础模型（FMs）的挑战，我们提出了一个协作框架，利用轻量级本地模型作为桥梁，适应新任务并增强FM的效用，同时防止本地模型遗忘并实现个性化知识融合。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦持续学习（FCL）中基础模型（FMs）面临的挑战，特别是本地数据利用不足和模型遗忘问题，并缩小小型模型和FMs之间的差距。

Method: 提出了一种包含两个新颖组件的协作框架：1. 小型模型持续微调，用于防止小型模型遗忘。2. 一对一蒸馏，用于在服务器上实现异构本地知识的个性化融合。

Result: 实验结果证明了该框架的优越性能，即使在客户端使用异构小型模型的情况下也是如此。

Conclusion: 该框架通过轻量级本地模型作为动态桥梁，持续适应新任务，同时增强大型模型的效用。实验结果表明，即使在客户端使用异构小型模型的情况下，该框架也表现出优越的性能。

Abstract: Continual learning (CL) for Foundation Models (FMs) is an essential yet
underexplored challenge, especially in Federated Continual Learning (FCL),
where each client learns from a private, evolving task stream under strict data
and communication constraints. Despite their powerful generalization abilities,
FMs often exhibit suboptimal performance on local downstream tasks, as they are
unable to utilize private local data. Furthermore, enabling FMs to learn new
tasks without forgetting prior knowledge is inherently a challenging problem,
primarily due to their immense parameter count and high model complexity. In
contrast, small models can be trained locally under resource-constrained
conditions and benefit from more mature CL techniques. To bridge the gap
between small models and FMs, we propose the first collaborative framework in
FCL, where lightweight local models act as a dynamic bridge, continually
adapting to new tasks while enhancing the utility of the large model. Two novel
components are also included: Small Model Continual Fine-tuning is for
preventing small models from temporal forgetting; One-by-One Distillation
performs personalized fusion of heterogeneous local knowledge on the server.
Experimental results demonstrate its superior performance, even when clients
utilize heterogeneous small models.

</details>


### [230] [Causal Graph Profiling via Structural Divergence for Robust Anomaly Detection in Cyber-Physical Systems](https://arxiv.org/abs/2508.09504)
*Arun Vignesh Malarkkan,Haoyue Bai,Dongjie Wang,Yanjie Fu*

Main category: cs.LG

TL;DR: CGAD是一个因果图为基础的异常检测框架，用于公共基础设施系统的网络攻击检测。它通过学习因果结构来提高在非平稳和不平衡数据中的检测精度和鲁棒性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着针对水处理网络等关键基础设施的网络攻击日益复杂，迫切需要能够同时考虑系统漏洞和不断变化的攻击模式的鲁棒异常检测策略。传统的统计、基于密度和基于图的模型在处理多变量时间序列的分布变化和类别不平衡方面存在困难，并常常导致高误报率。

Method: CGAD框架采用两阶段监督学习方法：首先，使用动态贝叶斯网络学习“正常”和“攻击”状态下系统行为的因果不变图结构；其次，通过比较因果图的拓扑偏差来评估结构差异，从而检测异常。

Result: CGAD框架在四个工业数据集上实现了比现有最佳基线更高的F1和ROC-AUC得分，展示了对延迟和结构复杂异常的鲁棒检测能力。

Conclusion: CGAD框架通过学习因果不变图结构和评估时间序列因果图的拓扑偏差，在非平稳和不平衡的时间序列环境中实现了优于传统方法的适应性和准确性。它能够以更高的精度检测网络攻击，并在不平衡和漂移条件下表现出鲁棒性，在F1和ROC-AUC得分方面取得了显著的提高，并能有效检测延迟和结构复杂的异常。

Abstract: With the growing complexity of cyberattacks targeting critical
infrastructures such as water treatment networks, there is a pressing need for
robust anomaly detection strategies that account for both system
vulnerabilities and evolving attack patterns. Traditional methods --
statistical, density-based, and graph-based models struggle with distribution
shifts and class imbalance in multivariate time series, often leading to high
false positive rates. To address these challenges, we propose CGAD, a Causal
Graph-based Anomaly Detection framework designed for reliable cyberattack
detection in public infrastructure systems. CGAD follows a two-phase supervised
framework -- causal profiling and anomaly scoring. First, it learns causal
invariant graph structures representing the system's behavior under "Normal"
and "Attack" states using Dynamic Bayesian Networks. Second, it employs
structural divergence to detect anomalies via causal graph comparison by
evaluating topological deviations in causal graphs over time. By leveraging
causal structures, CGAD achieves superior adaptability and accuracy in
non-stationary and imbalanced time series environments compared to conventional
machine learning approaches. By uncovering causal structures beneath volatile
sensor data, our framework not only detects cyberattacks with markedly higher
precision but also redefines robustness in anomaly detection, proving
resilience where traditional models falter under imbalance and drift. Our
framework achieves substantial gains in F1 and ROC-AUC scores over
best-performing baselines across four industrial datasets, demonstrating robust
detection of delayed and structurally complex anomalies.

</details>


### [231] [Enhancing Memory Recall in LLMs with Gauss-Tin: A Hybrid Instructional and Gaussian Replay Approach](https://arxiv.org/abs/2508.09510)
*Iing Muttakhiroh,Thomas Fevens*

Main category: cs.LG

TL;DR: Gauss-Tin是一种通过结合重放策略和高斯混合模型来解决大型语言模型中灾难性遗忘的新方法，并在保留能力方面取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）在学习新信息时会丢失先前获得的知识的灾难性遗忘问题。

Method: Gauss-Tin方法将重放策略与高斯混合模型相结合，以提高训练过程中样本选择的质量，并辅以指导性指令来促进对过去学习的生成。

Result: 实验结果表明，Gauss-Tin在保留指标方面比传统方法有6%的改进。

Conclusion: Gauss-Tin是一种有效的方法，可以减轻大型语言模型中的灾难性遗忘，在保留指标方面比传统方法提高了6%。

Abstract: Despite the significant advancements in Large Language Models (LLMs),
catastrophic forgetting remains a substantial challenge, where models lose
previously acquired knowledge upon learning new information. Continual learning
(CL) strategies have emerged as a potential solution to this problem, with
replay-based techniques demonstrating superior performance in preserving
learned knowledge. In this context, we introduce Gauss-Tin, a novel approach
that integrates the replay strategy with a Gaussian mixture model to enhance
the quality of sample selection during training, supplemented by instructional
guidance to facilitate the generation of past learning. This method aims to
improve LLMs' retention capabilities by strategically reinforcing important
past learnings while accommodating new information. Our experimental results
indicate a promising 6\% improvement in retention metrics over traditional
methods, suggesting that Gauss-Tin is an effective strategy for mitigating
catastrophic forgetting in LLMs. This study underscores the potential of hybrid
models in enhancing the robustness and adaptability of LLMs in dynamic learning
environments.

</details>


### [232] [Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring](https://arxiv.org/abs/2508.09527)
*Fang Wang,Ernesto Damiani*

Main category: cs.LG

TL;DR: 通过引入时间衰减注意力和转换类型语义，并结合GCN和GAT，提出了一个改进的、可解释的GNN框架，用于PBPM中的下一事件预测，并在多个基准测试中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的PBPM模型在捕捉时序相关性和转换语义方面存在不足，要么依赖于短前缀子图，要么采用忽略时序信息的全局架构。

Method: 提出了一种包含时间衰减注意机制和嵌入转换类型语义的GNN框架，并通过多层次可解释性模块提供可视化。该框架结合了基于前缀的图卷积网络（GCN）和全轨迹图注意力网络（GAT），以弥合局部和全局建模之间的性能差距。

Result: 在五个基准测试中，所提出的模型在没有进行每数据集调优的情况下，实现了具有竞争力的Top-k准确率和DL分数，证明了其鲁棒性、泛化性和可解释性。

Conclusion: 该研究提出了一个统一的、可解释的图神经网络（GNN）框架，用于预测性业务流程监控（PBPM），在准确性和可解释性方面均取得了进展。

Abstract: Predictive Business Process Monitoring (PBPM) aims to forecast future events
in ongoing cases based on historical event logs. While Graph Neural Networks
(GNNs) are well suited to capture structural dependencies in process data,
existing GNN-based PBPM models remain underdeveloped. Most rely either on short
prefix subgraphs or global architectures that overlook temporal relevance and
transition semantics. We propose a unified, interpretable GNN framework that
advances the state of the art along three key axes. First, we compare
prefix-based Graph Convolutional Networks(GCNs) and full trace Graph Attention
Networks(GATs) to quantify the performance gap between localized and global
modeling. Second, we introduce a novel time decay attention mechanism that
constructs dynamic, prediction-centered windows, emphasizing temporally
relevant history and suppressing noise. Third, we embed transition type
semantics into edge features to enable fine grained reasoning over structurally
ambiguous traces. Our architecture includes multilevel interpretability
modules, offering diverse visualizations of attention behavior. Evaluated on
five benchmarks, the proposed models achieve competitive Top-k accuracy and DL
scores without per-dataset tuning. By addressing architectural, temporal, and
semantic gaps, this work presents a robust, generalizable, and explainable
solution for next event prediction in PBPM.

</details>


### [233] [Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks](https://arxiv.org/abs/2508.09532)
*Bokeng Zheng,Jianqiang Zhong,Jiayi Liu,Xiaoxi Zhang*

Main category: cs.LG

TL;DR: 针对车联网（IoV）中的联邦微调挑战，本研究提出了一种结合RSU和车辆的分层框架，并使用一种新的UCB-DUAL算法进行能源感知的秩自适应，实现了低延迟和高精度的多任务学习。


<details>
  <summary>Details</summary>
Motivation: 在车联网（IoV）系统中，由于客户端的移动性、异构资源和间歇性连接等挑战，实现高效、低延迟的多任务自适应具有特殊性。因此，需要一种能够适应动态IoV场景并支持资源感知和移动性弹性的联邦微调方法。

Method: 本研究提出了一种分层联邦微调框架，并利用低秩自适应（LoRA）技术，设计了一种去中心化的、能源感知的秩自适应机制，该机制被构建为一个约束下的多臂老虎机问题。同时，开发了一种新颖的UCB-DUAL算法，以在每个任务的能源预算下实现自适应探索，并具有可证明的次线性遗憾。

Result: 通过在基于真实轨迹构建的大规模IoV模拟器上进行的大量实验，结果表明，该方法在准确-效率权衡方面优于所有基线方法，将延迟降低了24%以上，并将平均准确率提高了2.5%以上。

Conclusion: 该研究提出的分层联邦微调框架通过协调路边单元（RSU）和车辆，在动态的IoV场景中实现了资源感知和移动性弹性的学习，并在准确性和效率之间取得了最佳的权衡，同时降低了延迟并提高了平均准确率。

Abstract: Federated fine-tuning has emerged as a promising approach for adapting
foundation models (FMs) to diverse downstream tasks in edge environments. In
Internet of Vehicles (IoV) systems, enabling efficient and low-latency
multi-task adaptation is particularly challenging due to client mobility,
heterogeneous resources, and intermittent connectivity. This paper proposes a
hierarchical federated fine-tuning framework that coordinates roadside units
(RSUs) and vehicles to support resource-aware and mobility-resilient learning
across dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we
introduce a decentralized, energy-aware rank adaptation mechanism formulated as
a constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is
developed to enable adaptive exploration under per-task energy budgets,
achieving provable sublinear regret. To evaluate our method, we construct a
large-scale IoV simulator based on real-world trajectories, capturing dynamic
participation, RSU handoffs, and communication variability. Extensive
experiments show that our approach achieves the best accuracy-efficiency
trade-off among all baselines, reducing latency by over 24\% and improving
average accuracy by more than 2.5\%.

</details>


### [234] [SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification](https://arxiv.org/abs/2508.09544)
*Sasan Tavakkol,Lin Chen,Max Springer,Abigail Schantz,Blaž Bratanič,Vincent Cohen-Addad,MohammadHossein Bateni*

Main category: cs.LG

TL;DR: SYNAPSE-G利用LLM生成合成数据，并通过图上的半监督标签传播来改进稀有事件分类。


<details>
  <summary>Details</summary>
Motivation: 标记数据的稀缺性，特别是对于罕见事件，阻碍了有效机器学习模型的训练。

Method: SYNAPSE-G (Synthetic Augmentation for Positive Sampling via Expansion on Graphs)管道利用大型语言模型（LLMs）为稀有事件分类生成合成训练数据，解决了冷启动问题。该合成数据作为种子，用于在种子与大型无标签数据集之间构建的相似性图上进行半监督标签传播，以识别候选正样本，随后由预言家（人工或LLM）进行标记。然后使用扩展的数据集来训练/微调分类器。

Result: SYNAPSE-G有效地利用LLM生成合成数据，并通过半监督标签传播在不平衡的数据集上识别和扩展正样本，提高了分类器的性能。

Conclusion: SYNAPSE-G在SST2和MHS数据集上证明了其在寻找正标签方面的有效性，优于包括最近邻搜索在内的基线方法。

Abstract: Scarcity of labeled data, especially for rare events, hinders training
effective machine learning models. This paper proposes SYNAPSE-G (Synthetic
Augmentation for Positive Sampling via Expansion on Graphs), a novel pipeline
leveraging Large Language Models (LLMs) to generate synthetic training data for
rare event classification, addressing the cold-start problem. This synthetic
data serve as seeds for semi-supervised label propagation on a similarity graph
constructed between the seeds and a large unlabeled dataset. This identifies
candidate positive examples, subsequently labeled by an oracle (human or LLM).
The expanded dataset then trains/fine-tunes a classifier. We theoretically
analyze how the quality (validity and diversity) of the synthetic data impacts
the precision and recall of our method. Experiments on the imbalanced SST2 and
MHS datasets demonstrate SYNAPSE-G's effectiveness in finding positive labels,
outperforming baselines including nearest neighbor search.

</details>


### [235] [Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges](https://arxiv.org/abs/2508.09561)
*Changyuan Zhao,Guangyuan Liu,Ruichen Zhang,Yinqiu Liu,Jiacheng Wang,Jiawen Kang,Dusit Niyato,Zan Li,Xuemin,Shen,Zhu Han,Sumei Sun,Chau Yuen,Dong In Kim*

Main category: cs.LG

TL;DR: 本文综述了世界模型如何驱动边缘通用智能（EGI），探讨了其架构、应用和未来方向，为下一代智能边缘系统提供了指导。


<details>
  <summary>Details</summary>
Motivation: 当前边缘智能的发展迫切需要更强大的自主性和预测能力，而世界模型能够提供这种能力，但其在无线边缘的整合研究尚不充分，本文旨在弥合这一差距。

Method: 本文采用文献综述的方法，系统地分析了世界模型在边缘计算中的应用，探讨了其架构基础、潜在应用场景以及与新兴技术（如基础模型和数字孪生）的协同作用。

Result: 本文全面分析了世界模型如何赋能边缘智能体，并展示了其在车辆网络、无人机网络、物联网和网络功能虚拟化等场景下的应用潜力，强调了其在优化延迟、能耗和隐私方面的优势。

Conclusion: 本文为边缘通用人工智能（EGI）的兴起提供了概念基础和实践路线图，重点介绍了世界模型在其中扮演的关键角色，并指出了未来的研究方向。

Abstract: Edge General Intelligence (EGI) represents a transformative evolution of edge
computing, where distributed agents possess the capability to perceive, reason,
and act autonomously across diverse, dynamic environments. Central to this
vision are world models, which act as proactive internal simulators that not
only predict but also actively imagine future trajectories, reason under
uncertainty, and plan multi-step actions with foresight. This proactive nature
allows agents to anticipate potential outcomes and optimize decisions ahead of
real-world interactions. While prior works in robotics and gaming have
showcased the potential of world models, their integration into the wireless
edge for EGI remains underexplored. This survey bridges this gap by offering a
comprehensive analysis of how world models can empower agentic artificial
intelligence (AI) systems at the edge. We first examine the architectural
foundations of world models, including latent representation learning, dynamics
modeling, and imagination-based planning. Building on these core capabilities,
we illustrate their proactive applications across EGI scenarios such as
vehicular networks, unmanned aerial vehicle (UAV) networks, the Internet of
Things (IoT) systems, and network functions virtualization, thereby
highlighting how they can enhance optimization under latency, energy, and
privacy constraints. We then explore their synergy with foundation models and
digital twins, positioning world models as the cognitive backbone of EGI.
Finally, we highlight open challenges, such as safety guarantees, efficient
training, and constrained deployment, and outline future research directions.
This survey provides both a conceptual foundation and a practical roadmap for
realizing the next generation of intelligent, autonomous edge systems.

</details>


### [236] [Goal Discovery with Causal Capacity for Efficient Reinforcement Learning](https://arxiv.org/abs/2508.09624)
*Yan Yu,Yaodong Yang,Zhengbo Lu,Chengdong Ma,Wengang Zhou,Houqiang Li*

Main category: cs.LG

TL;DR: 提出GDCC框架，通过衡量“因果容量”和识别关键点作为子目标，来提升强化学习中智能体的探索效率，并在多目标任务中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 因果推断对于智能体在强化学习中高效探索环境至关重要，但现有方法难以在复杂的场景中度量因果关系。

Method: 提出了一种名为“因果容量”的因果度量方法，并采用基于蒙特卡洛的方法来识别离散状态空间中的关键点，然后针对连续高维环境优化该方法，将这些关键点作为子目标来指导智能体进行更有目的、更有效的探索。

Result: 经验结果表明，高因果容量的状态与预期的子目标一致，并且GDCC框架相比基线方法在成功率上取得了显著提升。

Conclusion: GDCC框架在多目标任务中显著提高了成功率，并且高因果容量的状态与预期的子目标一致。

Abstract: Causal inference is crucial for humans to explore the world, which can be
modeled to enable an agent to efficiently explore the environment in
reinforcement learning. Existing research indicates that establishing the
causality between action and state transition will enhance an agent to reason
how a policy affects its future trajectory, thereby promoting directed
exploration. However, it is challenging to measure the causality due to its
intractability in the vast state-action space of complex scenarios. In this
paper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework
for efficient environment exploration. Specifically, we first derive a
measurement of causality in state space, \emph{i.e.,} causal capacity, which
represents the highest influence of an agent's behavior on future trajectories.
After that, we present a Monte Carlo based method to identify critical points
in discrete state space and further optimize this method for continuous
high-dimensional environments. Those critical points are used to uncover where
the agent makes important decisions in the environment, which are then regarded
as our subgoals to guide the agent to make exploration more purposefully and
efficiently. Empirical results from multi-objective tasks demonstrate that
states with high causal capacity align with our expected subgoals, and our GDCC
achieves significant success rate improvements compared to baselines.

</details>


### [237] [Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs](https://arxiv.org/abs/2508.09627)
*Subhankar Sarkar,Souvik Chakraborty*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Solving partial differential equations (PDEs) efficiently and accurately
remains a cornerstone challenge in science and engineering, especially for
problems involving complex geometries and limited labeled data. We introduce a
Physics- and Geometry- Aware Spatio-Spectral Graph Neural Operator
($\pi$G-Sp$^2$GNO) for learning the solution operators of time-independent and
time-dependent PDEs. The proposed approach first improves upon the recently
developed Sp$^2$GNO by enabling geometry awareness and subsequently exploits
the governing physics to learn the underlying solution operator in a
simulation-free setup. While the spatio-spectral structure present in the
proposed architecture allows multiscale learning, two separate strategies for
enabling geometry awareness is introduced in this paper. For time dependent
problems, we also introduce a novel hybrid physics informed loss function that
combines higher-order time-marching scheme with upscaled theory inspired
stochastic projection scheme. This allows accurate integration of the
physics-information into the loss function. The performance of the proposed
approach is illustrated on number of benchmark examples involving regular and
complex domains, variation in geometry during inference, and time-independent
and time-dependent problems. The results obtained illustrate the efficacy of
the proposed approach as compared to the state-of-the-art physics-informed
neural operator algorithms in the literature.

</details>


### [238] [TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling](https://arxiv.org/abs/2508.09630)
*Yifei Sun,Junming Liu,Ding Wang,Yirong Chen,Xuefeng Yan*

Main category: cs.LG

TL;DR: TimeMKG is a framework that uses LLMs to build knowledge graphs from variable semantics, combining this with time series data to improve forecasting and classification by injecting causal priors.


<details>
  <summary>Details</summary>
Motivation: Traditional time series models overlook the rich semantic information in variable names and descriptions, which often encode critical domain knowledge essential for robust and interpretable modeling. TimeMKG aims to elevate time series modeling by integrating this knowledge.

Method: TimeMKG, a multimodal causal reasoning framework that uses large language models to interpret variable semantics and construct Multivariate Knowledge Graphs. It employs a dual-modality encoder to model semantic prompts and historical time series patterns separately, with cross-modality attention to fuse these representations and inject causal priors into downstream tasks.

Result: Experiments on diverse datasets show that incorporating variable-level knowledge significantly improves both predictive performance and generalization in tasks like forecasting and classification.

Conclusion: Multivariate time series models can be significantly improved by incorporating variable-level knowledge, leading to better predictive performance and generalization.

Abstract: Multivariate time series data typically comprises two distinct modalities:
variable semantics and sampled numerical observations. Traditional time series
models treat variables as anonymous statistical signals, overlooking the rich
semantic information embedded in variable names and data descriptions. However,
these textual descriptors often encode critical domain knowledge that is
essential for robust and interpretable modeling. Here we present TimeMKG, a
multimodal causal reasoning framework that elevates time series modeling from
low-level signal processing to knowledge informed inference. TimeMKG employs
large language models to interpret variable semantics and constructs structured
Multivariate Knowledge Graphs that capture inter-variable relationships. A
dual-modality encoder separately models the semantic prompts, generated from
knowledge graph triplets, and the statistical patterns from historical time
series. Cross-modality attention aligns and fuses these representations at the
variable level, injecting causal priors into downstream tasks such as
forecasting and classification, providing explicit and interpretable priors to
guide model reasoning. The experiment in diverse datasets demonstrates that
incorporating variable-level knowledge significantly improves both predictive
performance and generalization.

</details>


### [239] [Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments](https://arxiv.org/abs/2508.09659)
*Johannes F. Hevler,Shivam Verma,Mirat Soijtra,Carolyn R. Bertozzi*

Main category: cs.LG

TL;DR: Thermal Tracks是一个Python工具，使用高斯过程模型改进蛋白质热稳定性分析，能够处理各种曲线形状和蛋白质类型，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 克服现有热蛋白质组分析（TPP）工作流程的关键限制，该工作流程假设为S形熔化曲线并受限于经验零分布，这限制了显著命中率大约为数据的5%。Thermal Tracks对于分析显著改变蛋白质热稳定性的蛋白质组范围扰动特别有价值，例如通路抑制、遗传修饰或环境胁迫，因为这些情况下的常规TPP方法可能由于其统计限制而遗漏生物学上相关的变化。此外，Thermal Tracks在分析具有非常规熔化曲线的蛋白质方面表现出色，包括那些通常表现出复杂、非S形热稳定性行为的相分离蛋白和膜蛋白。

Method: 使用具有平方指数核的高斯过程（GP）模型来灵活模拟任何熔化曲线形状，并通过核先验生成无偏的零分布。

Result: Thermal Tracks能够灵活地模拟任何熔化曲线形状，并生成无偏的零分布，从而提高对蛋白质组范围扰动和具有非常规熔化曲线的蛋白质的分析能力，克服了传统TPP方法的局限性。

Conclusion: Thermal Tracks是一个基于Python的统计框架，用于分析蛋白质热稳定性数据，克服了现有热蛋白质组分析（TPP）工作流程的关键限制。该框架使用高斯过程（GP）模型，能够灵活地模拟任何熔化曲线形状，并通过核先验生成无偏的零分布。它尤其适用于分析显著改变蛋白质热稳定性的蛋白质组范围扰动，以及具有非常规熔化曲线的蛋白质，如相分离蛋白和膜蛋白。Thermal Tracks可从GitHub免费获取。

Abstract: Thermal Tracks is a Python-based statistical framework for analyzing protein
thermal stability data that overcomes key limitations of existing thermal
proteome profiling (TPP) work-flows. Unlike standard approaches that assume
sigmoidal melting curves and are constrained by empirical null distributions
(limiting significant hits to approximately 5 % of data), Thermal Tracks uses
Gaussian Process (GP) models with squared-exponential kernels to flexibly model
any melting curve shape while generating unbiased null distributions through
kernel priors. This framework is particularly valuable for analyzing
proteome-wide perturbations that significantly alter protein thermal stability,
such as pathway inhibitions, genetic modifications, or environmental stresses,
where conventional TPP methods may miss biologically relevant changes due to
their statistical constraints. Furthermore, Thermal Tracks excels at analyzing
proteins with un-conventional melting profiles, including phase-separating
proteins and membrane proteins, which often exhibit complex, non-sigmoidal
thermal stability behaviors. Thermal Tracks is freely available from GitHub and
is implemented in Python, providing an accessible and flexible tool for
proteome-wide thermal profiling studies.

</details>


### [240] [Global Convergence Analysis of Vanilla Gradient Descent for Asymmetric Matrix Completion](https://arxiv.org/abs/2508.09685)
*Xu Zhang,Shuo Chen,Jinsheng Li,Xiangying Pang,Maoguo Gong*

Main category: cs.LG

TL;DR: 通过省略正则化项和使用光谱初始化，梯度下降法在不对称低秩矩阵填充中实现了线性收敛，且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 解决不对称低秩矩阵填充问题，并探讨了省略正则化项的梯度下降方法的收敛性问题。

Method: 提出了一种省略正则化项的梯度下降方法，并结合留一法进行归纳证明，同时分析了平衡正则化项的范数特性，并通过数值实验验证了算法性能。

Result: 证明了省略正则化项的梯度下降方法具有线性收敛率，并表明其计算成本较低，性能与其他梯度下降算法相当。

Conclusion: 该研究通过省略正则化项并结合光谱初始化，证明了Vanilla梯度下降算法在矩阵补全问题上具有线性收敛率，并通过理论和实验展示了其优势。

Abstract: This paper investigates the asymmetric low-rank matrix completion problem,
which can be formulated as an unconstrained non-convex optimization problem
with a nonlinear least-squares objective function, and is solved via gradient
descent methods. Previous gradient descent approaches typically incorporate
regularization terms into the objective function to guarantee convergence.
However, numerical experiments and theoretical analysis of the gradient flow
both demonstrate that the elimination of regularization terms in gradient
descent algorithms does not adversely affect convergence performance. By
introducing the leave-one-out technique, we inductively prove that the vanilla
gradient descent with spectral initialization achieves a linear convergence
rate with high probability. Besides, we demonstrate that the balancing
regularization term exhibits a small norm during iterations, which reveals the
implicit regularization property of gradient descent. Empirical results show
that our algorithm has a lower computational cost while maintaining comparable
completion performance compared to other gradient descent algorithms.

</details>


### [241] [Temporal Anchoring in Deepening Embedding Spaces: Event-Indexed Projections, Drift, Convergence, and an Internal Computational Architecture](https://arxiv.org/abs/2508.09693)
*Faruk Alpay,Bugra Kilictas,Hamdi Alakkad*

Main category: cs.LG

TL;DR: Operator-theoretic framework for temporal anchoring in embedding spaces with complete proofs and applications to attention layers.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a framework for temporal anchoring in embedding spaces using operator theory.

Method: We develop an operator-theoretic framework for temporal anchoring in embedding spaces, modeled as drift maps interleaved with event-indexed blocks culminating in affine projections.

Result: We prove a variable-block contraction lemma, a drift--projection convergence theorem, and ontological convergence. We also show that softmax in attention layers is $1/2$-Lipschitz in $\ell_2$ and derive layer-contraction conditions.

Conclusion: We provide complete proofs for a variable-block contraction lemma, a drift--projection convergence theorem with explicit uniform-gap envelopes, and ontological convergence under nested affine anchors with a robustness variant. We also formalize an internal Manuscript Computer (MC) and prove a rigorous finite-run equivalence theorem.

Abstract: We develop an operator-theoretic framework for temporal anchoring in
embedding spaces, modeled as drift maps interleaved with event-indexed blocks
culminating in affine projections. We provide complete proofs for a
variable-block contraction lemma (products of Lipschitz factors), a
drift--projection convergence theorem with explicit uniform-gap envelopes, and
ontological convergence under nested affine anchors with a robustness variant.
We formalize an internal Manuscript Computer (MC) whose computations are
defined purely by these operators and prove a rigorous finite-run equivalence
theorem (with perturbation bounds). For attention layers, we give a
self-contained proof that softmax is $1/2$-Lipschitz in $\ell_2$ and derive
sufficient layer-contraction conditions (orthogonal/non-orthogonal heads). All
floats are placed exactly where written; the manuscript uses only in-paper
pseudocode and appendix figures.

</details>


### [242] [Combating Noisy Labels via Dynamic Connection Masking](https://arxiv.org/abs/2508.09697)
*Xinlei Zhang,Fan Liu,Chuanyi Zhang,Fan Cheng,Yuhui Zheng*

Main category: cs.LG

TL;DR: 提出动态连接掩码（DCM）机制，用于 MLP 和 KANs，以提高其在带噪标签下的鲁棒性，实验证明该方法优于现有技术，并首次发现 KANs 比 MLPs 更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中不可避免地存在带噪标签，而深度神经网络的强大记忆能力会因为这些带噪标签导致性能显著下降。现有的研究主要集中在鲁棒损失函数和样本选择，而对模型架构中的正则化探索相对有限。

Method: 提出了一种动态连接掩码（DCM）机制，用于多层感知机（MLP）和 KANs，以增强分类器对抗带噪标签的鲁棒性。该机制通过评估信息承载能力，可以在训练过程中自适应地掩盖不太重要的连接。通过理论分析，证明了其在减少梯度误差方面的效率。

Result: 实验结果表明，该方法在合成和现实世界的基准上均持续优于最先进的方法。首次揭示了 KANs 在现实世界带噪场景中优于 MLPs 的鲁棒性。

Conclusion: 该方法可以无缝集成到各种抗噪声训练方法中，以构建更鲁棒的深度网络，包括鲁棒损失函数、样本选择策略和正则化技术。在合成和现实世界的基准上进行的广泛实验表明，我们的方法持续优于最先进的方法。此外，我们还首次研究了 KANs 作为分类器来对抗带噪标签，并揭示了它们在现实世界带噪场景中优于 MLPs 的鲁棒性。

Abstract: Noisy labels are inevitable in real-world scenarios. Due to the strong
capacity of deep neural networks to memorize corrupted labels, these noisy
labels can cause significant performance degradation. Existing research on
mitigating the negative effects of noisy labels has mainly focused on robust
loss functions and sample selection, with comparatively limited exploration of
regularization in model architecture. Inspired by the sparsity regularization
used in Kolmogorov-Arnold Networks (KANs), we propose a Dynamic Connection
Masking (DCM) mechanism for both Multi-Layer Perceptron Networks (MLPs) and
KANs to enhance the robustness of classifiers against noisy labels. The
mechanism can adaptively mask less important edges during training by
evaluating their information-carrying capacity. Through theoretical analysis,
we demonstrate its efficiency in reducing gradient error. Our approach can be
seamlessly integrated into various noise-robust training methods to build more
robust deep networks, including robust loss functions, sample selection
strategies, and regularization techniques. Extensive experiments on both
synthetic and real-world benchmarks demonstrate that our method consistently
outperforms state-of-the-art (SOTA) approaches. Furthermore, we are also the
first to investigate KANs as classifiers against noisy labels, revealing their
superior noise robustness over MLPs in real-world noisy scenarios. Our code
will soon be publicly available.

</details>


### [243] [GraphTreeGen: Subtree-Centric Approach to Efficient and Supervised Graph Generation](https://arxiv.org/abs/2508.09710)
*Yitong Luo,Islem Rekik*

Main category: cs.LG

TL;DR: GTG是一种新的连接组生成框架，通过将连接组分解为子树来解决现有模型的局限性，从而实现高效、准确的连接组合成，并具有更高的结构保真度和更精确的权重。


<details>
  <summary>Details</summary>
Motivation: 大脑连接组对理解大脑组织至关重要，但获取成本高昂且耗时，因此需要生成方法。现有的图生成模型存在一些局限性，例如压缩整个图会模糊细粒度的局部图形，依赖节点属性会降低重建质量，以边为中心的模型会忽略准确的边权重预测，以及计算成本高昂的设计会带来高内存需求。

Method: GTG将连接组分解为由共享GCN编码的熵引导的k跳树，捕获信息局部结构。二分消息传递层融合子树嵌入和全局节点特征，而双分支解码器联合预测边存在和权重以重建邻接矩阵。

Result: GTG在自我监督任务中表现优于最先进的基线，在监督设置中也具有竞争力，具有更高的结构保真度和更精确的权重，且内存占用少得多。

Conclusion: GTG在自我监督任务中表现优于最先进的基线，在监督设置中也具有竞争力，具有更高的结构保真度和更精确的权重，且内存占用少得多。其模块化设计支持扩展到连接组超分辨率和跨模态合成。

Abstract: Brain connectomes, representing neural connectivity as graphs, are crucial
for understanding brain organization but costly and time-consuming to acquire,
motivating generative approaches. Recent advances in graph generative modeling
offer a data-driven alternative, enabling synthetic connectome generation and
reducing dependence on large neuroimaging datasets. However, current models
face key limitations: (i) compressing the whole graph into a single latent code
(e.g., VGAEs) blurs fine-grained local motifs; (ii) relying on rich node
attributes rarely available in connectomes reduces reconstruction quality;
(iii) edge-centric models emphasize topology but overlook accurate edge-weight
prediction, harming quantitative fidelity; and (iv) computationally expensive
designs (e.g., edge-conditioned convolutions) impose high memory demands,
limiting scalability. We propose GraphTreeGen (GTG), a subtree-centric
generative framework for efficient, accurate connectome synthesis. GTG
decomposes each connectome into entropy-guided k-hop trees capturing
informative local structure, encoded by a shared GCN. A bipartite
message-passing layer fuses subtree embeddings with global node features, while
a dual-branch decoder jointly predicts edge existence and weights to
reconstruct the adjacency matrix. GTG outperforms state-of-the-art baselines in
self-supervised tasks and remains competitive in supervised settings,
delivering higher structural fidelity and more precise weights with far less
memory. Its modular design enables extensions to connectome super-resolution
and cross-modality synthesis. Code: https://github.com/basiralab/GTG/

</details>


### [244] [Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models](https://arxiv.org/abs/2508.09719)
*Anish Narain,Ritam Majumdar,Nikita Narayanan,Dominic Marshall,Sonali Parbhoo*

Main category: cs.LG

TL;DR: 通过整合LLM处理的临床笔记上下文信息，可以改进概念瓶颈模型在ARDS识别等临床任务中的性能和概念表征能力。


<details>
  <summary>Details</summary>
Motivation: 大型、公开的临床数据集虽然是理解疾病异质性和探索个性化治疗的新资源，但通常不完整且缺乏关键标签。现有的AI工具虽然可以进行回顾性标注，但可解释性有限。概念瓶颈模型（CBM）虽然旨在提高可解释性，但在概念无法充分解释任务时存在性能限制。

Method: 利用大型语言模型（LLM）处理临床笔记以生成额外的概念，并将其整合到概念瓶颈模型（CBM）中，以提高模型性能和概念的全面性。

Result: 与现有方法相比，性能提高了10%，同时提高了概念的全面性，降低了信息泄露和对虚假捷径的依赖风险，从而改进了对ARDS的表征。

Conclusion: 通过整合临床笔记中的上下文信息，利用大型语言模型生成额外的概念，可以提高概念瓶颈模型在疾病分类任务中的性能，例如急性呼吸窘迫综合征（ARDS）的识别，同时提高概念的全面性，降低信息泄露和对虚假捷径的依赖风险。

Abstract: Large, publicly available clinical datasets have emerged as a novel resource
for understanding disease heterogeneity and to explore personalization of
therapy. These datasets are derived from data not originally collected for
research purposes and, as a result, are often incomplete and lack critical
labels. Many AI tools have been developed to retrospectively label these
datasets, such as by performing disease classification; however, they often
suffer from limited interpretability. Previous work has attempted to explain
predictions using Concept Bottleneck Models (CBMs), which learn interpretable
concepts that map to higher-level clinical ideas, facilitating human
evaluation. However, these models often experience performance limitations when
the concepts fail to adequately explain or characterize the task. We use the
identification of Acute Respiratory Distress Syndrome (ARDS) as a challenging
test case to demonstrate the value of incorporating contextual information from
clinical notes to improve CBM performance. Our approach leverages a Large
Language Model (LLM) to process clinical notes and generate additional
concepts, resulting in a 10% performance gain over existing methods.
Additionally, it facilitates the learning of more comprehensive concepts,
thereby reducing the risk of information leakage and reliance on spurious
shortcuts, thus improving the characterization of ARDS.

</details>


### [245] [Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization](https://arxiv.org/abs/2508.09730)
*Qiaolei Gu,Yu Li,DingYi Zeng,Lu Wang,Ming Pang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.LG

TL;DR: GenCO框架通过结合生成模型和多实例奖励学习，解决了电子商务广告中创意组合选择的难题，有效扩大了广告收入。


<details>
  <summary>Details</summary>
Motivation: 现有的电子商务广告创意选择方法往往分别评估创意组件，无法有效应对数量庞大的潜在创意组合搜索空间。为了解决这一挑战，需要一种能够同时优化多个创意元素组合以最大化广告效果的方法。

Method: 提出了一种名为GenCO的新型框架，该框架整合了生成模型和多实例奖励学习。GenCO采用统一的两阶段架构：首先，利用生成模型通过强化学习高效生成多样化的创意组合；其次，利用多实例学习模型将点击等组合级奖励归因于单个创意元素，从而为生成模型提供更精确的反馈信号。

Result: GenCO框架在实际的电子商务平台部署后，显著增加了广告收入。此外，研究团队发布了一个大规模的工业数据集，以支持该领域未来的研究。

Conclusion: GenCO框架在实际的电子商务平台部署后，显著增加了广告收入，证明了其在提高广告创意效果方面的实用价值。

Abstract: In e-commerce advertising, selecting the most compelling combination of
creative elements -- such as titles, images, and highlights -- is critical for
capturing user attention and driving conversions. However, existing methods
often evaluate creative components individually, failing to navigate the
exponentially large search space of possible combinations. To address this
challenge, we propose a novel framework named GenCO that integrates generative
modeling with multi-instance reward learning. Our unified two-stage
architecture first employs a generative model to efficiently produce a diverse
set of creative combinations. This generative process is optimized with
reinforcement learning, enabling the model to effectively explore and refine
its selections. Next, to overcome the challenge of sparse user feedback, a
multi-instance learning model attributes combination-level rewards, such as
clicks, to the individual creative elements. This allows the reward model to
provide a more accurate feedback signal, which in turn guides the generative
model toward creating more effective combinations. Deployed on a leading
e-commerce platform, our approach has significantly increased advertising
revenue, demonstrating its practical value. Additionally, we are releasing a
large-scale industrial dataset to facilitate further research in this important
domain.

</details>


### [246] [HKT: A Biologically Inspired Framework for Modular Hereditary Knowledge Transfer in Neural Networks](https://arxiv.org/abs/2508.09743)
*Yanick Chistian Tchenko,Felix Mohr,Hicham Hadj Abdelkader,Hedi Tabia*

Main category: cs.LG

TL;DR: HKT 是一种受生物启发的知识迁移框架，通过结构化知识继承来提升小型模型的性能，优于传统蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 优化小型、可部署模型，通过结构化知识继承来增强其能力，以应对模型性能与集成和效率之间权衡的问题。

Method: HKT 框架通过提取、传输和混合（ETM）三个受生物学启发的组件，并结合遗传注意（GA）机制，实现从大型预训练父网络到小型子模型的任务相关特征的模块化和选择性传输。

Result: HKT 在光学流、图像分类和语义分割等多种视觉任务上显著提高了子模型的性能，同时保持了其紧凑性，并且优于传统的蒸馏方法。

Conclusion: HKT 是一种通用的、可解释的、可扩展的解决方案，适用于在资源受限的环境中部署高性能神经网络。

Abstract: A prevailing trend in neural network research suggests that model performance
improves with increasing depth and capacity - often at the cost of
integrability and efficiency. In this paper, we propose a strategy to optimize
small, deployable models by enhancing their capabilities through structured
knowledge inheritance. We introduce Hereditary Knowledge Transfer (HKT), a
biologically inspired framework for modular and selective transfer of
task-relevant features from a larger, pretrained parent network to a smaller
child model. Unlike standard knowledge distillation, which enforces uniform
imitation of teacher outputs, HKT draws inspiration from biological inheritance
mechanisms - such as memory RNA transfer in planarians - to guide a multi-stage
process of feature transfer. Neural network blocks are treated as functional
carriers, and knowledge is transmitted through three biologically motivated
components: Extraction, Transfer, and Mixture (ETM). A novel Genetic Attention
(GA) mechanism governs the integration of inherited and native representations,
ensuring both alignment and selectivity. We evaluate HKT across diverse vision
tasks, including optical flow (Sintel, KITTI), image classification (CIFAR-10),
and semantic segmentation (LiTS), demonstrating that it significantly improves
child model performance while preserving its compactness. The results show that
HKT consistently outperforms conventional distillation approaches, offering a
general-purpose, interpretable, and scalable solution for deploying
high-performance neural networks in resource-constrained environments.

</details>


### [247] [A Machine Learning Approach to Predict Biological Age and its Longitudinal Drivers](https://arxiv.org/abs/2508.09747)
*Nazira Dunbayeva,Yulong Li,Yutong Xie,Imran Razzak*

Main category: cs.LG

TL;DR: 通过考虑生物标记物的变化速率，机器学习模型能更准确地预测年龄，这对于个性化医疗和疾病预防至关重要。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有机器学习模型在预测个体衰老轨迹时，由于仅使用静态生物标记物而无法捕捉衰老过程动态和纵向性质的挑战，本研究旨在开发一种能更好地反映健康动态变化以提高年龄预测准确性的方法。

Method: 开发并验证了一个机器学习流程，利用来自两个不同时间点（2019-2020和2021-2022）的纵向队列数据来预测年龄。在静态、横断面生物标记物的基础上，工程化了能够捕捉关键生物标记物变化速率（斜率）的新特征，并使用LightGBM模型进行训练和预测，并通过SHAP分析评估了特征重要性。

Result: 所提出的包含生物标记物变化速率（斜率）特征的LightGBM模型，在仅使用初始数据训练的情况下，能够以高准确性预测后续时间点的年龄（男性R²=0.515，女性R²=0.498），显著优于传统的线性模型和其他基于树的集成模型。SHAP分析表明，工程化的斜率特征是重要的预测因子，突显了健康轨迹对生物年龄的重要性。

Conclusion: 通过构建包含生物标记物变化速率（斜率）的特征，可以显著提高预测个体年龄的机器学习模型性能。这种方法考虑了健康轨迹而非仅静态快照，为开发动态跟踪患者健康状况的临床工具提供了基础，有望实现疾病的早期干预和个性化预防。

Abstract: Predicting an individual's aging trajectory is a central challenge in
preventative medicine and bioinformatics. While machine learning models can
predict chronological age from biomarkers, they often fail to capture the
dynamic, longitudinal nature of the aging process. In this work, we developed
and validated a machine learning pipeline to predict age using a longitudinal
cohort with data from two distinct time periods (2019-2020 and 2021-2022). We
demonstrate that a model using only static, cross-sectional biomarkers has
limited predictive power when generalizing to future time points. However, by
engineering novel features that explicitly capture the rate of change (slope)
of key biomarkers over time, we significantly improved model performance. Our
final LightGBM model, trained on the initial wave of data, successfully
predicted age in the subsequent wave with high accuracy ($R^2 = 0.515$ for
males, $R^2 = 0.498$ for females), significantly outperforming both traditional
linear models and other tree-based ensembles. SHAP analysis of our successful
model revealed that the engineered slope features were among the most important
predictors, highlighting that an individual's health trajectory, not just their
static health snapshot, is a key determinant of biological age. Our framework
paves the way for clinical tools that dynamically track patient health
trajectories, enabling early intervention and personalized prevention
strategies for age-related diseases.

</details>


### [248] [$μ$-Parametrization for Mixture of Experts](https://arxiv.org/abs/2508.09752)
*Jan Małaśnicki,Kamil Ciebiera,Mateusz Boruń,Maciej Pióro,Jan Ludziejewski,Maciej Stefaniak,Michał Krutul,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jakub Krajewski*

Main category: cs.LG

TL;DR: 本研究为MoE提出了μ-参数化（μP），解决了μTransfer和MoE结合的空白，为特征学习提供了理论基础，并通过实验证明了其有效性，同时还探讨了扩展专家数量和粒度对学习率的影响。


<details>
  <summary>Details</summary>
Motivation: 探索μTransfer（一种用于大规模训练中超参数调整的关键技术）与MoE（一种在极其大型模型中领先的架构）的交叉点，因为这一领域此前未被探索过。

Method: 导出MoE的μ-参数化（μP），并提供理论保证。通过实验验证参数化，并研究专家数量和粒度对最优学习率的影响。

Result: 推导了MoE的μ-参数化（μP），为特征学习提供了理论保证，并通过实验验证了其有效性，并研究了扩展专家数量和粒度对最优学习率的影响。

Conclusion: 该研究为MoE导出了μ-参数化（μP），为模型宽度在路由器和专家中的特征学习提供了理论保证，并通过实验验证了参数化，进一步研究了专家数量和粒度对最优学习率的影响。

Abstract: Recent years have seen a growing interest and adoption of LLMs, with
$\mu$Transfer becoming a key technique for tuning hyperparameters in
large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a
leading architecture in extremely large models. However, the intersection of
these two advancements has remained unexplored. In this work, we derive a
$\mu$-Parameterization ($\mu$P) for MoE, providing theoretical guarantees for
feature learning across model widths in both the router and experts. We
empirically validate our parameterization and further investigate how scaling
the number of experts and granularity affects the optimal learning rate.

</details>


### [249] [TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization](https://arxiv.org/abs/2508.09753)
*Zhaoyang Zhu,Zhipeng Zeng,Qiming Chen,Linxiao Yang,Peiyuan Liu,Weiqi Chen,Liang Sun*

Main category: cs.LG

TL;DR: TriForecaster是一种基于MoE和MTL的新框架，通过RegionMixer和CTSpecializer层解决多区域电力负荷预测中的区域、情境和时间差异，平均预测误差降低22.4%，并在中国东部17个城市成功部署。


<details>
  <summary>Details</summary>
Motivation: 为了应对多区域电力负荷预测（MRELF）问题中存在的区域差异、情境差异和时间差异这三大挑战，特别是在中国东部一个省份内不同城市负荷模式相似的背景下，以实现多个子区域的精准短期负荷预测。

Method: 提出了一种名为TriForecaster的新框架，该框架利用专家混合（MoE）方法和多任务学习（MTL）范式，并引入了RegionMixer和Context-Time Specializer（CTSpecializer）层，以动态地协调和专门化跨区域、情境和时间维度的专家模型。

Result: TriForecaster框架在四个具有不同粒度的真实MRELF数据集上进行了评估，结果显示其性能优于现有最先进的模型，平均预测误差降低了22.4%，证明了其灵活性和广泛适用性。

Conclusion: TriForecaster框架通过其创新的RegionMixer和CTSpecializer层，在区域性、情境性和时间性变异方面展现了显著的优越性，并在四个真实世界的MRELF数据集上实现了22.4%的平均预测误差降低，证明了其灵活性和广泛适用性。该模型已成功部署到eForecaster平台，为中国东部17个城市提供城市级短期负荷预测，惠及超过1.1亿人口和每日超过100 GWh的电力使用量，验证了其实际应用价值。

Abstract: Electric load forecasting is pivotal for power system operation, planning and
decision-making. The rise of smart grids and meters has provided more detailed
and high-quality load data at multiple levels of granularity, from home to bus
and cities. Motivated by similar patterns of loads across different cities in a
province in eastern China, in this paper we focus on the Multi-Region Electric
Load Forecasting (MRELF) problem, targeting accurate short-term load
forecasting for multiple sub-regions within a large region. We identify three
challenges for MRELF, including regional variation, contextual variation, and
temporal variation. To address them, we propose TriForecaster, a new framework
leveraging the Mixture of Experts (MoE) approach within a Multi-Task Learning
(MTL) paradigm to overcome these challenges. TriForecaster features RegionMixer
and Context-Time Specializer (CTSpecializer) layers, enabling dynamic
cooperation and specialization of expert models across regional, contextual,
and temporal dimensions. Based on evaluation on four real-world MRELF datasets
with varied granularity, TriForecaster outperforms state-of-the-art models by
achieving an average forecast error reduction of 22.4\%, thereby demonstrating
its flexibility and broad applicability. In particular, the deployment of
TriForecaster on the eForecaster platform in eastern China exemplifies its
practical utility, effectively providing city-level, short-term load forecasts
for 17 cities, supporting a population exceeding 110 million and daily
electricity usage over 100 gigawatt-hours.

</details>


### [250] [Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations](https://arxiv.org/abs/2508.09787)
*Mauro Tucci*

Main category: cs.LG

TL;DR: Proto-PINV+H 是一种快速训练模型的方法，通过优化少量合成数据和隐藏激活来计算权重，在 MNIST 和 Fashion-MNIST 上实现了高准确率和快速训练。


<details>
  <summary>Details</summary>
Motivation: 提出一种能够快速训练且参数量较少的模型训练范式，以在准确率、速度和模型大小之间取得良好的权衡。

Method: 通过闭式权重计算和基于梯度的可训练原型（包括隐藏激活）优化相结合的方式进行训练，并通过岭伪逆求解重新计算权重。

Result: 在 MNIST 上达到 97.8% 的准确率，在 Fashion-MNIST 上达到 89.3% 的准确率，训练时间仅为 3.9s--4.5s，可训练参数约 130k。

Conclusion: 该方法在 MNIST 和 Fashion-MNIST 数据集上取得了有竞争力的准确率和速度，并且在多层扩展、可学习正则化参数和 PCA/PLS 投影方面提供了灵活性。

Abstract: We present Proto-PINV+H, a fast training paradigm that combines closed-form
weight computation with gradient-based optimisation of a small set of synthetic
inputs, soft labels, and-crucially-hidden activations. At each iteration we
recompute all weight matrices in closed form via two (or more)
ridge-regularised pseudo-inverse solves, while updating only the prototypes
with Adam. The trainable degrees of freedom are thus shifted from weight space
to data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k
train, 10k test), our method reaches 97.8% and 89.3% test accuracy on the
official 10k test sets, respectively, in 3.9s--4.5s using approximately 130k
trainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a
multi-layer extension (optimised activations at each hidden stage), learnable
ridge parameters, optional PCA/PLS projections, and theory linking the
condition number of prototype matrices to generalisation. The approach yields
favourable accuracy--speed--size trade-offs against ELM, random-feature ridge,
and shallow MLPs trained by back-propagation.

</details>


### [251] [Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques](https://arxiv.org/abs/2508.09810)
*Qi Gan,Stephan Clémençon,Mounîm A. El-Yacoubi,Sao Mai Nguyen,Eric Fenaux,Ons Jelassi*

Main category: cs.LG

TL;DR: 本研究运用机器学习分析跳远比赛的生物力学数据，发现对男子运动员来说，起跳时膝盖角度很重要；对女子运动员来说，着陆姿势和助跑步伐比速度更重要。


<details>
  <summary>Details</summary>
Motivation: 传统上，专家通过物理方程提出和评估生物力学特征，但难以明确分析某些特征与运动员最终表现之间的关系。本研究旨在利用数据分析方法解决这一挑战。

Method: 本研究利用机器学习模型（包括分位数回归）分析了世界锦标赛跳远决赛的生物力学特征，并运用 SHAP、PDP 和 ICE 图进行模型解释。

Result: 研究发现，除速度相关特征外，特定技术方面对跳远成绩也起着关键作用。对于男子运动员，支撑腿起跳前的膝关节角度（大于 169 度）是进入数据集中排名前 10% 的关键因素。对于女子运动员，除了速度，着陆姿势和助跑步伐技术对排名前 10% 的表现影响最大。

Conclusion: 本研究提出了一种分析运动表现影响因素的框架，特别关注顶尖表现事件，并识别了影响男子和女子跳远比赛中顶尖表现的关键生物力学特征。

Abstract: Biomechanical features have become important indicators for evaluating
athletes' techniques. Traditionally, experts propose significant features and
evaluate them using physics equations. However, the complexity of the human
body and its movements makes it challenging to explicitly analyze the
relationships between some features and athletes' final performance. With
advancements in modern machine learning and statistics, data analytics methods
have gained increasing importance in sports analytics. In this study, we
leverage machine learning models to analyze expert-proposed biomechanical
features from the finals of long jump competitions in the World Championships.
The objectives of the analysis include identifying the most important features
contributing to top-performing jumps and exploring the combined effects of
these key features. Using quantile regression, we model the relationship
between the biomechanical feature set and the target variable (effective
distance), with a particular focus on elite-level jumps. To interpret the
model, we apply SHapley Additive exPlanations (SHAP) alongside Partial
Dependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots. The
findings reveal that, beyond the well-documented velocity-related features,
specific technical aspects also play a pivotal role. For male athletes, the
angle of the knee of the supporting leg before take-off is identified as a key
factor for achieving top 10% performance in our dataset, with angles greater
than 169{\deg}contributing significantly to jump performance. In contrast, for
female athletes, the landing pose and approach step technique emerge as the
most critical features influencing top 10% performances, alongside velocity.
This study establishes a framework for analyzing the impact of various features
on athletic performance, with a particular emphasis on top-performing events.

</details>


### [252] [Provable In-Context Vector Arithmetic via Retrieving Task Concepts](https://arxiv.org/abs/2508.09820)
*Dake Bu,Wei Huang,Andi Han,Atsushi Nitanda,Qingfu Zhang,Hau-San Wong,Taiji Suzuki*

Main category: cs.LG

TL;DR: LLMs 在上下文学习中通过向量运算执行事实回忆任务，本文提出了一个基于层次概念模型的理论框架，证明了 Transformer 的优势，并通过实证模拟得到证实。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，LLMs 在上下文学习 (ICL) 中利用潜在的任务/函数向量和残差流进行类似 Word2Vec 的向量运算来解决事实回忆型 ICL 任务，并且问答数据在增强事实回忆能力方面起着关键作用。然而，目前仍缺乏理论解释。

Method: 提出一个理论框架，该框架建立在经验证实的层次概念模型之上，并通过优化理论来展示非线性残差 Transformer 如何通过梯度下降在交叉熵损失上进行训练，从而实现事实回忆型上下文学习任务的向量运算。证明了 0-1 损失收敛性，并展示了强大的泛化能力，包括对概念重组和分布转移的鲁棒性。

Result: 理论证明了非线性残差 Transformer 通过梯度下降和交叉熵损失进行训练，能够实现 0-1 损失收敛，并表现出强大的泛化能力，包括对概念重组和分布转移的鲁棒性。实证模拟结果也证实了这些理论洞见。

Conclusion: 本文提出了一个理论框架，基于经验证实的层次概念模型，解释了 LLMs 如何通过向量运算来执行事实回忆型上下文学习任务。研究证明了非线性残差 Transformer 通过梯度下降和交叉熵损失进行训练，能够实现 0-1 损失收敛，并表现出强大的泛化能力，包括对概念重组和分布转移的鲁棒性，从而阐明了 Transformer 相较于静态嵌入方法的优势。理论洞见得到了实证模拟的证实。

Abstract: In-context learning (ICL) has garnered significant attention for its ability
to grasp functions/tasks from demonstrations. Recent studies suggest the
presence of a latent task/function vector in LLMs during ICL. Merullo et al.
(2024) showed that LLMs leverage this vector alongside the residual stream for
Word2Vec-like vector arithmetic, solving factual-recall ICL tasks.
Additionally, recent work empirically highlighted the key role of
Question-Answer data in enhancing factual-recall capabilities. Despite these
insights, a theoretical explanation remains elusive. To move one step forward,
we propose a theoretical framework building on empirically grounded
hierarchical concept modeling. We develop an optimization theory, showing how
nonlinear residual transformers trained via gradient descent on cross-entropy
loss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss
convergence and show the strong generalization, including robustness to concept
recombination and distribution shifts. These results elucidate the advantages
of transformers over static embedding predecessors. Empirical simulations
corroborate our theoretical insights.

</details>


### [253] [RankList -- A Listwise Preference Learning Framework for Predicting Subjective Preferences](https://arxiv.org/abs/2508.09826)
*Abinay Reddy Naini,Fernando Diaz,Carlos Busso*

Main category: cs.LG

TL;DR: RankList是一个改进的列表式偏好学习框架，用于处理主观排序任务，相比现有方法在准确性和泛化能力上均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有的成对排序框架（如RankNet）在处理主观性强的任务（如语音情感识别和图像美学评估）时，虽然能有效建模相对偏好，但难以捕捉全局排序一致性。

Method: 提出了一种名为RankList的新型列表式偏好学习框架，该框架将RankNet推广到列表级监督，并通过对局部和非局部排序约束进行显式建模来解决其局限性。通过使用log-sum-exp近似来提高训练效率，并通过跳跃式比较进行扩展，以增强全局排序保真度。

Result: 在MSP-Podcast、IEMOCAP、BIIC Podcast等语音情感识别数据集上，RankList在Kendall Tau和排序准确率方面均优于标准的列表基线。在艺术图像美学数据集上的实验也证实了该方法在图像排序任务上的有效性。消融研究和跨域研究表明，RankList不仅能提高域内排序，而且具有更好的跨数据集泛化能力。

Conclusion: RankList是一个统一且可扩展的框架，用于在主观学习场景中对有序偏好进行建模，并在各种模式下实现了卓越的性能。

Abstract: Preference learning has gained significant attention in tasks involving
subjective human judgments, such as \emph{speech emotion recognition} (SER) and
image aesthetic assessment. While pairwise frameworks such as RankNet offer
robust modeling of relative preferences, they are inherently limited to local
comparisons and struggle to capture global ranking consistency. To address
these limitations, we propose RankList, a novel listwise preference learning
framework that generalizes RankNet to structured list-level supervision. Our
formulation explicitly models local and non-local ranking constraints within a
probabilistic framework. The paper introduces a log-sum-exp approximation to
improve training efficiency. We further extend RankList with skip-wise
comparisons, enabling progressive exposure to complex list structures and
enhancing global ranking fidelity. Extensive experiments demonstrate the
superiority of our method across diverse modalities. On benchmark SER datasets
(MSP-Podcast, IEMOCAP, BIIC Podcast), RankList achieves consistent improvements
in Kendall's Tau and ranking accuracy compared to standard listwise baselines.
We also validate our approach on aesthetic image ranking using the Artistic
Image Aesthetics dataset, highlighting its broad applicability. Through
ablation and cross-domain studies, we show that RankList not only improves
in-domain ranking but also generalizes better across datasets. Our framework
offers a unified, extensible approach for modeling ordered preferences in
subjective learning scenarios.

</details>


### [254] [FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness](https://arxiv.org/abs/2508.09866)
*Siyuan Wen,Meng Zhang,Yang Yang,Ningning Ding*

Main category: cs.LG

TL;DR: FedShard 是首个同时保证联邦遗忘效率和性能公平性的算法，能有效且快速地移除客户端数据贡献，并能抵御攻击。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习中的联邦遗忘研究主要关注效率和有效性，而忽略了去中心化客户端在遗忘过程中的效率公平性和性能公平性问题。

Method: FedShard 算法通过自适应地处理收敛性、遗忘效率和公平性之间的矛盾来解决效率公平性和性能公平性问题。论文还提出了两种新的指标来量化评估遗忘算法的公平性，并进行了理论分析和数值评估。

Result: FedShard 能够同时保证效率公平性和性能公平性，减轻级联离开和中毒攻击等不公平风险，实现更均衡的遗忘成本。实验结果表明，FedShard 的遗忘效率比从头开始重新训练快 1.3-6.2 倍，比现有的精确遗忘方法快 4.9 倍。

Conclusion: FedShard 是一种联邦学习中的联邦遗忘算法，旨在解决效率公平性和性能公平性问题。它通过自适应地处理收敛性、遗忘效率和公平性之间的矛盾来实现这一目标。此外，论文还提出了两种新的指标来量化评估遗忘算法的公平性。理论分析和数值评估均验证了 FedShard 在遗忘性能和效率方面的公平性，并表明 FedShard 能够减轻级联离开和中毒攻击等不公平风险，实现更均衡的遗忘成本。实验结果表明，FedShard 在数据遗忘过程中的效率比从头开始重新训练快 1.3-6.2 倍，比现有的精确遗忘方法快 4.9 倍。

Abstract: To protect clients' right to be forgotten in federated learning, federated
unlearning aims to remove the data contribution of leaving clients from the
global learned model. While current studies mainly focused on enhancing
unlearning efficiency and effectiveness, the crucial aspects of efficiency
fairness and performance fairness among decentralized clients during unlearning
have remained largely unexplored. In this study, we introduce FedShard, the
first federated unlearning algorithm designed to concurrently guarantee both
efficiency fairness and performance fairness. FedShard adaptively addresses the
challenges introduced by dilemmas among convergence, unlearning efficiency, and
unlearning fairness. Furthermore, we propose two novel metrics to
quantitatively assess the fairness of unlearning algorithms, which we prove to
satisfy well-known properties in other existing fairness measurements. Our
theoretical analysis and numerical evaluation validate FedShard's fairness in
terms of both unlearning performance and efficiency. We demonstrate that
FedShard mitigates unfairness risks such as cascaded leaving and poisoning
attacks and realizes more balanced unlearning costs among clients. Experimental
results indicate that FedShard accelerates the data unlearning process 1.3-6.2
times faster than retraining from scratch and 4.9 times faster than the
state-of-the-art exact unlearning methods.

</details>


### [255] [Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning](https://arxiv.org/abs/2508.09883)
*Xiaojun Wu,Xiaoguang Jiang,Huiyang Li,Jucai Zhai,Dengfeng Liu,Qiaobo Hao,Huang Liu,Zhiguo Yang,Ji Xie,Ninglun Gu,Jin Yang,Kailai Zhang,Yelun Bao,Jun Wang*

Main category: cs.LG

TL;DR: 通过选择最优教师模型、精心策划小数据集以及利用多样化推理轨迹，DED框架能够以极少数据高效提升LLM的推理能力，同时保持其通用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在提升大型语言模型（LLMs）推理能力时计算成本高昂以及可能损害模型通用能力的问题，该研究旨在提出一种数据高效的蒸馏框架，以优化推理蒸馏的帕累托前沿，实现高效的推理能力提升。

Method: 该研究提出了一种数据高效的蒸馏框架（DED），其核心思想包括：1. 开发了一种选择最优教师模型的方法，该方法不依赖于单一的基准分数；2. 通过精心策划的小型数据集，在模型在域内推理能力和域外性能之间取得了平衡；3. 利用多样化的推理轨迹来培养学生模型稳健的推理能力。

Result: 在数学推理（AIME 2024/2025, MATH-500）和代码生成（LiveCodeBench）任务的评估中，DED框架取得了最先进的结果，仅使用了0.8k的精心策划的示例，证明了其在提高推理能力的同时，有效降低了对大规模数据集和计算资源的需求，并优于现有方法。

Conclusion: 该研究提出了一种数据高效的蒸馏框架（DED），通过优化蒸馏的帕累托前沿，在数学推理和代码生成任务上取得了最先进的结果，同时仅使用了少量精心挑选的示例，有效降低了计算成本并保持了通用能力。

Abstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities in
tasks such as algorithmic coding and mathematical problem-solving. Recent
methods have improved reasoning through expanded corpus and multistage training
combining reinforcement learning and supervised fine-tuning. Although some
methods suggest that small but targeted dataset can incentivize reasoning via
only distillation, a reasoning scaling laws is still taking shape, increasing
computational costs. To address this, we propose a data-efficient distillation
framework (DED) that optimizes the Pareto frontier of reasoning distillation.
Inspired by the on-policy learning and diverse roll-out strategies of
reinforcement learning, the key idea of our approach is threefold: (1) We
identify that benchmark scores alone do not determine an effective teacher
model. Through comprehensive comparisons of leading reasoning LLMs, we develop
a method to select an optimal teacher model. (2) While scaling distillation can
enhance reasoning, it often degrades out-of-domain performance. A carefully
curated, smaller corpus achieves a balanced trade-off between in-domain and
out-of-domain capabilities. (3) Diverse reasoning trajectories encourage the
student model to develop robust reasoning skills. We validate our method
through evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and
code generation (LiveCodeBench), achieving state-of-the-art results with only
0.8k carefully curated examples, bypassing the need for extensive scaling. Our
systematic analysis demonstrates that DED outperforms existing methods by
considering factors beyond superficial hardness, token length, or teacher model
capability. This work offers a practical and efficient pathway to advanced
reasoning while preserving general capabilities.

</details>


### [256] [Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?](https://arxiv.org/abs/2508.09888)
*Viacheslav Barkov,Jonas Schmidinger,Robin Gebbers,Martin Atzmueller*

Main category: cs.LG

TL;DR: 现代ANN，特别是TabPFN，在土壤预测方面优于传统方法，应被土壤学家采用。


<details>
  <summary>Details</summary>
Motivation: 为了评估在土壤光谱等领域，现代人工神经网络（ANN）在现场尺度的土壤属性预测（PSM）任务中的适用性，尤其是在训练样本量小和特征与样本比率高的情况下，挑战了经典机器学习方法（如随机森林和偏最小二乘回归）的传统主导地位。

Method: 通过一个全面的基准测试，评估了包括MLP、Transformer变体、检索增强方法和基于Transformer的Transformer等在内的各种先进ANN架构，并与随机森林和偏最小二乘回归等经典方法进行了比较。

Result: 在31个包含30至460个样本的田间和农场尺度数据集上，现代ANN在大多数任务中持续优于经典方法，证明了深度学习在克服经典机器学习在PSM中的主导地位方面已经成熟。TabPFN在各种条件下均表现出最强的整体性能和鲁棒性。

Conclusion: 现代人工神经网络（ANN）在现场尺度的土壤属性预测（PSM）任务中表现优于经典方法，其中TabPFN表现最为出色，推荐在土壤学中采用现代ANN，并提倡将TabPFN作为新的默认选择。

Abstract: In the field of pedometrics, tabular machine learning is the predominant
method for predicting soil properties from remote and proximal soil sensing
data, forming a central component of digital soil mapping. At the field-scale,
this predictive soil modeling (PSM) task is typically constrained by small
training sample sizes and high feature-to-sample ratios in soil spectroscopy.
Traditionally, these conditions have proven challenging for conventional deep
learning methods. Classical machine learning algorithms, particularly
tree-based models like Random Forest and linear models such as Partial Least
Squares Regression, have long been the default choice for field-scale PSM.
Recent advances in artificial neural networks (ANN) for tabular data challenge
this view, yet their suitability for field-scale PSM has not been proven. We
introduce a comprehensive benchmark that evaluates state-of-the-art ANN
architectures, including the latest multilayer perceptron (MLP)-based models
(TabM, RealMLP), attention-based transformer variants (FT-Transformer,
ExcelFormer, T2G-Former, AMFormer), retrieval-augmented approaches (TabR,
ModernNCA), and an in-context learning foundation model (TabPFN). Our
evaluation encompasses 31 field- and farm-scale datasets containing 30 to 460
samples and three critical soil properties: soil organic matter or soil organic
carbon, pH, and clay content. Our results reveal that modern ANNs consistently
outperform classical methods on the majority of tasks, demonstrating that deep
learning has matured sufficiently to overcome the long-standing dominance of
classical machine learning for PSM. Notably, TabPFN delivers the strongest
overall performance, showing robustness across varying conditions. We therefore
recommend the adoption of modern ANNs for field-scale PSM and propose TabPFN as
the new default choice in the toolkit of every pedometrician.

</details>


### [257] [Rare anomalies require large datasets: About proving the existence of anomalies](https://arxiv.org/abs/2508.09894)
*Simon Klüttermann,Emmanuel Müller*

Main category: cs.LG

TL;DR: 在异常检测中，确定异常的存在至关重要。此研究发现，数据集大小、污染率和算法决定了需要多少样本才能确认异常存在，公式为 N ≥ α_algo/ν^2。


<details>
  <summary>Details</summary>
Motivation: 在异常检测文献中，确定数据集中是否存在异常仍然是一个被忽视但至关重要的问题。

Method: 通过在各种异常检测任务和算法中进行超过三百万次统计测试，确定了数据集大小、污染率和算法相关常数 α_algo 之间的关系。

Result: 研究结果表明，对于大小为 N 且污染率为 ν 的未标记数据集，N ≥ α_algo/ν^2 是确认异常存在所需的样本数量的下限。

Conclusion: 该研究确定了一个阈值，表明在数据集大小、污染率和算法相关常数 α_algo 之间存在一种关系，这为确认异常存在所需的样本数量设定了一个下限。

Abstract: Detecting whether any anomalies exist within a dataset is crucial for
effective anomaly detection, yet it remains surprisingly underexplored in
anomaly detection literature. This paper presents a comprehensive study that
addresses the fundamental question: When can we conclusively determine that
anomalies are present? Through extensive experimentation involving over three
million statistical tests across various anomaly detection tasks and
algorithms, we identify a relationship between the dataset size, contamination
rate, and an algorithm-dependent constant $ \alpha_{\text{algo}} $. Our results
demonstrate that, for an unlabeled dataset of size $ N $ and contamination rate
$ \nu $, the condition $ N \ge \frac{\alpha_{\text{algo}}}{\nu^2} $ represents
a lower bound on the number of samples required to confirm anomaly existence.
This threshold implies a limit to how rare anomalies can be before proving
their existence becomes infeasible.

</details>


### [258] [Beyond Naïve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs](https://arxiv.org/abs/2508.09904)
*Arjun Ashok,Andrew Robert Williams,Vincent Zhihao Zheng,Irina Rish,Nicolas Chapados,Étienne Marcotte,Valentina Zantedeschi,Alexandre Drouin*

Main category: cs.LG

TL;DR: 本文提出四种策略（ReDP, CorDP, IC-DP, RouteDP）来改进LLM在上下文感知预测任务中的表现，其中IC-DP通过嵌入历史示例显著提高了准确性。这些策略在不同LLM上均表现出优于朴素提示的性能，并为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在上下文感知预测中显示出潜力，但其在结合历史数据和文本信息方面的能力仍未被充分发掘。本文旨在通过提出新的策略来解决这一差距，以解锁LLM在此领域的全部潜力。

Method: 本文提出了四种策略：ReDP通过引发明确的推理链来提高可解释性；CorDP仅利用LLM来优化现有预测，以适应实际预测流程；IC-DP通过在提示中嵌入历史上下文感知预测任务的示例来提高准确性；RouteDP通过利用LLM估计任务难度来优化资源效率，并将更具挑战性的任务分配给更大的模型。

Result: 本文提出的四种策略在CiK基准的各种上下文感知预测任务上，展示了与朴素提示相比的独特优势，并且适用于不同大小和系列的LLM。这些结果为基于LLM的上下文感知预测带来了进一步简单而有效的改进。

Conclusion: 本文提出的四种策略在CiK基准的各种上下文感知预测任务上，展示了与朴素提示相比的独特优势，并且适用于不同大小和系列的LLM。这些结果为基于LLM的上下文感知预测带来了进一步简单而有效的改进。

Abstract: Forecasting in real-world settings requires models to integrate not only
historical data but also relevant contextual information, often available in
textual form. While recent work has shown that large language models (LLMs) can
be effective context-aided forecasters via na\"ive direct prompting, their full
potential remains underexplored. We address this gap with 4 strategies,
providing new insights into the zero-shot capabilities of LLMs in this setting.
ReDP improves interpretability by eliciting explicit reasoning traces, allowing
us to assess the model's reasoning over the context independently from its
forecast accuracy. CorDP leverages LLMs solely to refine existing forecasts
with context, enhancing their applicability in real-world forecasting
pipelines. IC-DP proposes embedding historical examples of context-aided
forecasting tasks in the prompt, substantially improving accuracy even for the
largest models. Finally, RouteDP optimizes resource efficiency by using LLMs to
estimate task difficulty, and routing the most challenging tasks to larger
models. Evaluated on different kinds of context-aided forecasting tasks from
the CiK benchmark, our strategies demonstrate distinct benefits over na\"ive
prompting across LLMs of different sizes and families. These results open the
door to further simple yet effective improvements in LLM-based context-aided
forecasting.

</details>


### [259] [Prototype-Guided Diffusion: Visual Conditioning without External Memory](https://arxiv.org/abs/2508.09922)
*Bilal Faye,Hanane Azzag,Mustapha Lebbah*

Main category: cs.LG

TL;DR: PDM是一种新的扩散模型，它通过集成原型学习来提高效率和适应性，无需外部记忆，从而在生成高质量图像的同时降低了计算和存储成本。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在空间模型（如Stable Diffusion）虽然降低了成本，但牺牲了细节；而检索增强扩散模型（RDM）虽然有效，但需要昂贵的存储和检索基础设施，依赖于像CLIP这样的静态视觉-语言模型，并且在训练期间缺乏适应性。

Method: PDM通过对比学习从干净的图像特征中构建动态的、紧凑的原型集合，并利用这些原型通过将噪声表示与语义相关的视觉模式对齐来指导去噪步骤。

Result: 实验表明，PDM在保持高生成质量的同时，降低了计算和存储开销，为基于检索的条件扩散模型提供了一个可扩展的替代方案。

Conclusion: PDM通过将原型学习集成到扩散过程中，实现了高效和自适应的视觉条件，无需外部记忆，从而在保持高质量生成的同时，降低了计算和存储开销，为基于检索的条件扩散模型提供了一个可扩展的替代方案。

Abstract: Diffusion models have emerged as a leading framework for high-quality image
generation, offering stable training and strong performance across diverse
domains. However, they remain computationally intensive, particularly during
the iterative denoising process. Latent-space models like Stable Diffusion
alleviate some of this cost by operating in compressed representations, though
at the expense of fine-grained detail. More recent approaches such as
Retrieval-Augmented Diffusion Models (RDM) address efficiency by conditioning
denoising on similar examples retrieved from large external memory banks. While
effective, these methods introduce drawbacks: they require costly storage and
retrieval infrastructure, depend on static vision-language models like CLIP for
similarity, and lack adaptability during training. We propose the Prototype
Diffusion Model (PDM), a method that integrates prototype learning directly
into the diffusion process for efficient and adaptive visual conditioning -
without external memory. Instead of retrieving reference samples, PDM
constructs a dynamic set of compact visual prototypes from clean image features
using contrastive learning. These prototypes guide the denoising steps by
aligning noisy representations with semantically relevant visual patterns,
enabling efficient generation with strong semantic grounding. Experiments show
that PDM maintains high generation quality while reducing computational and
storage overhead, offering a scalable alternative to retrieval-based
conditioning in diffusion models.

</details>


### [260] [Residual Reservoir Memory Networks](https://arxiv.org/abs/2508.09925)
*Matteo Pinna,Andrea Ceni,Claudio Gallicchio*

Main category: cs.LG

TL;DR: ResRMNs是一种新的无监督RNN，在RC范式下，通过结合线性和非线性储层以及时间残差连接来提高性能，并在各种时间序列和分类任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 为了提高循环神经网络在处理时间序列和像素级1-D分类任务时的性能。

Method: 提出了一种新的无监督循环神经网络（RNN）类别，称为残差储层记忆网络（ResRMNs），它结合了线性记忆储层和非线性储层，后者基于跨时间维度的残差正交连接，以增强输入的长期传播。通过线性稳定性分析研究了所得储层状态动力学，并研究了时间残差连接的各种配置。

Result: ResRMNs在时间序列和像素级1-D分类任务上表现优于其他传统RC模型。

Conclusion: ResRMNs在时间序列和像素级1-D分类任务上表现优于其他传统RC模型。

Abstract: We introduce a novel class of untrained Recurrent Neural Networks (RNNs)
within the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory
Networks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear
reservoir, where the latter is based on residual orthogonal connections along
the temporal dimension for enhanced long-term propagation of the input. The
resulting reservoir state dynamics are studied through the lens of linear
stability analysis, and we investigate diverse configurations for the temporal
residual connections. The proposed approach is empirically assessed on
time-series and pixel-level 1-D classification tasks. Our experimental results
highlight the advantages of the proposed approach over other conventional RC
models.

</details>


### [261] [Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models](https://arxiv.org/abs/2508.09968)
*Luca Eyring,Shyamgopal Karthik,Alexey Dosovitskiy,Nataniel Ruiz,Zeynep Akata*

Main category: cs.LG

TL;DR: 通过在训练后集成测试时推理的知识，解决测试时推理的计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 为了在利用测试时推理（test-time scaling）的优势的同时，解决其推理开销大、速度慢的缺点。

Method: 提出了一种理论上可行的框架，用于学习奖励倾斜的分布以进行蒸馏生成器，通过一个易于处理的噪声空间目标来实现，该目标在保持基础模型保真度的同时优化所需特性。具体来说，使用噪声超网络来调节初始输入噪声，替代了扩散模型中以奖励为指导的测试时噪声优化。

Result: 提出的方法在计算成本只是显式测试时优化的一小部分的情况下，恢复了相当一部分的质量增益。

Conclusion: 该方法通过噪声超网络在训练后集成测试时推理的知识，实现了在较低计算成本下恢复显式测试时优化的质量增益。

Abstract: The new paradigm of test-time scaling has yielded remarkable breakthroughs in
Large Language Models (LLMs) (e.g. reasoning models) and in generative vision
models, allowing models to allocate additional computation during inference to
effectively tackle increasingly complex problems. Despite the improvements of
this approach, an important limitation emerges: the substantial increase in
computation time makes the process slow and impractical for many applications.
Given the success of this paradigm and its growing usage, we seek to preserve
its benefits while eschewing the inference overhead. In this work we propose
one solution to the critical problem of integrating test-time scaling knowledge
into a model during post-training. Specifically, we replace reward guided
test-time noise optimization in diffusion models with a Noise Hypernetwork that
modulates initial input noise. We propose a theoretically grounded framework
for learning this reward-tilted distribution for distilled generators, through
a tractable noise-space objective that maintains fidelity to the base model
while optimizing for desired characteristics. We show that our approach
recovers a substantial portion of the quality gains from explicit test-time
optimization at a fraction of the computational cost. Code is available at
https://github.com/ExplainableML/HyperNoise

</details>


### [262] [Dynamic Mixture-of-Experts for Incremental Graph Learning](https://arxiv.org/abs/2508.09974)
*Lecheng Kong,Theodore Vasiloudis,Seongjun Yun,Han Xie,Xiang Song*

Main category: cs.LG

TL;DR: 图增量学习方法DyMoE通过动态混合专家和稀疏化技术，有效解决了灾难性遗忘问题，并在类别增量学习任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的图增量学习方法在处理连续增长的图数据时会遇到灾难性遗忘问题，即模型会遗忘旧知识。虽然一些方法试图通过保持旧模型不变来解决这个问题，但它们忽略了不同时间戳的旧知识对学习新任务的贡献是不同的。某些旧模式有助于学习新数据，而另一些则可能因与新数据分布不符而产生负面影响。

Method: 提出了一种动态混合专家（DyMoE）方法，该方法通过引入新的专家网络来处理新数据块，并设计了定制的正则化损失来利用数据序列信息，使现有专家在帮助新专家学习新数据的同时保持解决旧任务的能力。此外，还引入了稀疏混合专家方法，通过仅选择最重要的k个专家进行预测来降低计算成本。

Result: 该模型在类别增量学习任务中，相比于最优的基线模型，准确率相对提高了4.92%。

Conclusion: 该模型在类别增量学习任务中取得了显著的准确率提升，相对提高了4.92%，证明了其在处理动态图数据和防止灾难性遗忘方面的强大能力。

Abstract: Graph incremental learning is a learning paradigm that aims to adapt trained
models to continuously incremented graphs and data over time without the need
for retraining on the full dataset. However, regular graph machine learning
methods suffer from catastrophic forgetting when applied to incremental
learning settings, where previously learned knowledge is overridden by new
knowledge. Previous approaches have tried to address this by treating the
previously trained model as an inseparable unit and using techniques to
maintain old behaviors while learning new knowledge. These approaches, however,
do not account for the fact that previously acquired knowledge at different
timestamps contributes differently to learning new tasks. Some prior patterns
can be transferred to help learn new data, while others may deviate from the
new data distribution and be detrimental. To address this, we propose a dynamic
mixture-of-experts (DyMoE) approach for incremental learning. Specifically, a
DyMoE GNN layer adds new expert networks specialized in modeling the incoming
data blocks. We design a customized regularization loss that utilizes data
sequence information so existing experts can maintain their ability to solve
old tasks while helping the new expert learn the new data effectively. As the
number of data blocks grows over time, the computational cost of the full
mixture-of-experts (MoE) model increases. To address this, we introduce a
sparse MoE approach, where only the top-$k$ most relevant experts make
predictions, significantly reducing the computation time. Our model achieved
4.92\% relative accuracy increase compared to the best baselines on class
incremental learning, showing the model's exceptional power.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [263] [Periodically Poled Piezoelectric Lithium Niobate Resonator for Piezoelectric Power Conversion](https://arxiv.org/abs/2508.09407)
*Ziqian Yao,Clarissa Daniel,Lezli Matto,Heather Chang,Vakhtang Chuluhadze,Michael Liao,Jack Kramer,Eric Stolt,Mark S. Goorsky,Juan Rivas-Davila,Ruochen Lu*

Main category: physics.app-ph

TL;DR: 
This paper introduces a new type of piezoelectric resonator made from periodically poled lithium niobate (P3F LN) that operates at a high frequency (19.23 MHz) with excellent performance ($k^2=29\%$, $Q=3187$). This technology has the potential to improve power converters, making them smaller and more efficient, especially for high-power and high-frequency applications.


<details>
  <summary>Details</summary>
Motivation: 
As the demand for compact and efficient power conversion systems increases, piezoelectric power converters have gained attention. Achieving optimal converter performance requires resonators with high quality factor (Q), strong electromechanical coupling (k^2), high power handling capability, and a spurious-free response. Lithium niobate (LN) is a promising material due to its high figure of merit (FoM = Q * k^2). Periodically poled piezoelectric film (P3F) structures have shown potential to scale up operating frequency and enhance FoM compared to single-layer counterparts.

Method: 
This work presents the first P3F thickness-extensional (TE) LN resonator for power conversion, operating at 19.23 MHz. High-power testing was performed to systematically study the nonlinear behavior and power handling of P3F LN for power applications.

Result: 
The presented P3F TE LN resonator operates at 19.23 MHz, with a large $k^2$ of 29% and a high $Q$ of 3187, achieving a state-of-the-art ($f_s \cdot Q$) product among piezoelectric power resonators. High-power testing was performed to study the nonlinear behavior and power handling.

Conclusion: 
This work presents the first periodically poled film (P3F) thickness-extensional (TE) lithium niobate (LN) resonator for power conversion, operating at 19.23 MHz, with a large $k^2$ of 29% and a high $Q$ of 3187. The P3F structure shows potential for scaling up operating frequency and enhancing FoM compared to single-layer counterparts. High-power testing was performed to study nonlinear behavior and power handling. With further optimization, P3F TE resonators could enable new design space for high-power and high-frequency power conversion.

Abstract: As the demand for compact and efficient power conversion systems increases,
piezoelectric power converters have gained attention for their ability to
replace bulky magnetic inductors with acoustic resonators, enabling higher
power density and improved efficiency. Achieving optimal converter performance
requires resonators with high quality factor ($Q$), strong electromechanical
coupling ($k^2$), high power handling capability, and a spurious-free response.
Lithium niobate (LN) has emerged as a promising material in this context due to
its high figure of merit (FoM = $Q \cdot k^2$). While previous studies on
single-layer LN resonators have demonstrated high FoM values, they typically
operate at relatively low resonance frequencies ($f_s$). Recently, periodically
poled piezoelectric film (P3F) structures, formed by stacking piezoelectric
layers with alternating crystal orientations, have shown the potential to both
scale up the operating frequency and enhance the FoM compared to single-layer
counterparts in piezoelectric power conversion. This work presents the first
P3F thickness-extensional (TE) LN resonator for power conversion, operating at
19.23 MHz, with a large \textit{$k^2$} of 29\% and a high \textit{Q} of 3187,
achieving a state-of-the-art (\textit{ $f_s \cdot Q$}) product among
piezoelectric power resonators. A high-power testing procedure is performed to
systematically study the nonlinear behavior and power handling of P3F LN for
power applications. With further optimization, P3F TE resonators have the
potential to open up a new design space for high-power and high-frequency power
conversion.

</details>


### [264] [Non-trivial critical behavior at the magnetic transitions: A case study of Sm$_7$Pd$_3$](https://arxiv.org/abs/2508.09838)
*Ajay Kumar,Anis Biswas,Y. Mudryk*

Main category: physics.app-ph

TL;DR: Sm$_{7}$Pd$_{3}$在T$_{c}$ = 173 K的临界行为不符合标准理论，其临界指数发散，表明可能存在强自旋-晶格耦合。论文提出了一种评估临界指数可靠性的新方法，并呼吁建立新的理论框架。


<details>
  <summary>Details</summary>
Motivation: 为了分析Sm$_{7}$Pd$_{3}$在T$_{c}$ = 173 K的临界行为，该行为与二阶磁弹性转变相关。

Method: 通过标准收敛程序和平均归一化斜率（ANS）方法来确定临界指数（CEs）。

Result: 临界指数（CEs）在T$_{c}$处发散，这通常与一阶转变相关。Sm$_{7}$Pd$_{3}$的临界行为不符合任何已知的普适类，这可能是由于其固有的强自旋-晶格耦合。

Conclusion: 该论文提出了一种新的量化方法来评估临界指数的可靠性，并强调了需要修改理论框架来准确描述二阶磁弹性转变，因为现有理论无法很好地描述Sm$_{7}$Pd$_{3}$的临界行为。

Abstract: We present a comprehensive analysis of the critical behavior of Sm$_7$Pd$_3$
in the vicinity of its second-order magnetoelastic transition at $T_ {\rm c} =
173$ K. The critical exponents (CEs) $\beta$ and $\gamma$, determined using
both the standard convergence procedure and the average normalized slope (ANS)
method, diverge at $T_{\rm c}$: a characteristic typically associated with
first-order transitions. Notably, none of the established universality classes
satisfactorily describe the critical behavior of Sm$_7$Pd$_3$, and we discuss
the possible origins of this deviation in the context of the strong
spin-lattice coupling intrinsic to the sample. We emphasize the importance of
accurately selecting the critical temperature and magnetic field ranges to
ensure robust critical behavior analysis and propose a quantitative approach to
assess the reliability of the extracted CEs. Additionally, we demonstrate that
in the ANS method, the critical exponents $\beta$ and $\gamma$ should be
calculated separately using data for $T \leqslant T_{\rm c}$ and $T \geqslant
T_{\rm c}$, respectively. Our findings underscore the need for a revised
theoretical framework to accurately describe second-order magnetoelastic
transitions.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [265] [RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet](https://arxiv.org/abs/2508.09140)
*Honggang Jia,Nan Cheng,Xiucheng Wang,Conghao Zhou,Ruijin Sun,Xuemin,Shen*

Main category: eess.SP

TL;DR: RadioMamba是一种新的混合Mamba-UNet架构，用于无线电地图构建，它通过结合长距离依赖建模（Mamba）和局部特征提取（卷积）来解决准确性-效率的权衡，并在实验中取得了更高的准确性和显著的效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的无线电地图（RM）构建方法存在准确性-效率的权衡。本研究旨在解决此问题。

Method: RadioMamba采用混合Mamba-UNet架构，结合了Mamba-卷积块，其中Mamba分支以线性复杂度捕获长距离空间依赖性，而并行的卷积分支则提取局部特征。

Result: 实验表明，RadioMamba在准确性方面优于包括扩散模型在内的现有方法，同时速度快了近20倍，模型参数量仅占现有方法的2.9%。

Conclusion: RadioMamba通过提高准确性和效率，为下一代无线系统中的实时智能优化提供了一种可行的方法。

Abstract: Radio map (RM) has recently attracted much attention since it can provide
real-time and accurate spatial channel information for 6G services and
applications. However, current deep learning-based methods for RM construction
exhibit well known accuracy-efficiency trade-off. In this paper, we introduce
RadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the
trade-off. Generally, accurate RM construction requires modeling long-range
spatial dependencies, reflecting the global nature of wave propagation physics.
RadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures
these global dependencies with linear complexity, while a parallel
convolutional branch extracts local features. This hybrid design generates
feature representations that capture both global context and local detail.
Experiments show that RadioMamba achieves higher accuracy than existing
methods, including diffusion models, while operating nearly 20 times faster and
using only 2.9\% of the model parameters. By improving both accuracy and
efficiency, RadioMamba presents a viable approach for real-time intelligent
optimization in next generation wireless systems.

</details>


### [266] [Bayesian-Driven Graph Reasoning for Active Radio Map Construction](https://arxiv.org/abs/2508.09142)
*Wenlihan Lu,Shijian Gao,Miaowen Wen,Yuxuan Liang,Chan-Byoung Chae,H. Vincent Poor*

Main category: eess.SP

TL;DR: URAM 框架通过不确定性感知和图推理，优化了无人机航点导航的无线电图重建和轨迹规划，显著提高了准确性和能效。


<details>
  <summary>Details</summary>
Motivation: 为了解决自主航空器在进行航点导航数据收集时，因电池容量限制而影响覆盖范围和效率的问题。

Method: 提出了一种不确定性感知无线电图（URAM）重建框架，该框架利用基于图的推理，并结合了两个深度学习组件：1）实时估计空间不确定性的贝叶斯神经网络；2）通过概率图路线规划信息丰富且节能的轨迹的基于注意力的强化学习策略。

Result: 实验结果表明，URAM 相比现有基线提高了高达 34% 的重建准确性。

Conclusion: URAM框架通过结合贝叶斯神经网络和基于注意力的强化学习策略，能够实时估计空间不确定性，并进行全局推理，从而规划出信息丰富且节能的轨迹，提高了重建准确性。

Abstract: With the emergence of the low-altitude economy, radio maps have become
essential for ensuring reliable wireless connectivity to aerial platforms.
Autonomous aerial agents are commonly deployed for data collection using
waypoint-based navigation; however, their limited battery capacity
significantly constrains coverage and efficiency. To address this, we propose
an uncertainty-aware radio map (URAM) reconstruction framework that explicitly
leverages graph-based reasoning tailored for waypoint navigation. Our approach
integrates two key deep learning components: (1) a Bayesian neural network that
estimates spatial uncertainty in real time, and (2) an attention-based
reinforcement learning policy that performs global reasoning over a
probabilistic roadmap, using uncertainty estimates to plan informative and
energy-efficient trajectories. This graph-based reasoning enables intelligent,
non-myopic trajectory planning, guiding agents toward the most informative
regions while satisfying safety constraints. Experimental results show that
URAM improves reconstruction accuracy by up to 34% over existing baselines.

</details>


### [267] [Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm](https://arxiv.org/abs/2508.09546)
*Dumitra Iancu,Liang Liu,Ove Edfors,Erik Leitinger,Xuhong Li*

Main category: eess.SP

TL;DR: 提出了一种用于分布式MIMO和通信感知系统的可扩展、低延迟的消息传递定位方法，在性能相似的情况下降低了延迟和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了满足未来无线系统对分布式架构、可扩展性和低延迟定位解决方案的要求。

Method: 提出了一种可扩展的消息传递定位方法和架构，该方法与基于面板的分布式MIMO系统和网络拓扑共同设计，其中互连单元在没有中央处理的情况下运行。该方法能够联合检测动态场景中来自多径测量的到分布式单元的视线路径，并定位代理。

Result: 实现了非常低的延迟，并提供了一个基于FPGA操作的周期精确系统延迟模型，展示了处理延迟、硬件利用率和系统级权衡的重要见解。

Conclusion: 该方法可实现与基于多径的定位方法相似的定位性能，同时具有更低的延迟和计算复杂度。

Abstract: Distributed MIMO and integrated sensing and communication are expected to be
key technologies in future wireless systems, enabling reliable, low-latency
communication and accurate localization. Dedicated localization solutions must
support distributed architecture, provide scalability across different system
configurations and meet strict latency requirements. We present a scalable
message-passing localization method and architecture co-designed for a
panel-based distributed MIMO system and network topology, in which
interconnected units operate without centralized processing. This method
jointly detects line-of-sight paths to distributed units from multipath
measurements in dynamic scenarios, localizes the agent, and achieves very low
latency. Additionally, we introduce a cycle-accurate system latency model based
on implemented FPGA operations, and show important insights into processing
latency and hardware utilization and system-level trade-offs. We compare our
method to a multipath-based localization method and show that it can achieve
similar localization performance, with wide enough distribution of array
elements, while offering lower latency and computational complexity.

</details>


### [268] [Generative AI-Enabled Robust 6G Uplink: Principles, Challenges, and Directions](https://arxiv.org/abs/2508.09348)
*Chunmei Xu,Yi Ma,Rahim Tafazolli,Peiying Zhu*

Main category: eess.SP

TL;DR: GenCom是一种利用生成式AI和收发端资源不平衡来解决6G上行链路瓶颈的新系统范式，在恶劣条件下表现优于传统系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决下一代无线网络（6G）面临的由设备端资源限制和信道条件挑战引起的关键上行链路瓶颈问题。

Method: GenCom系统通过资源丰富的接收端部署强大的离线训练的生成式AI模型，从降级的信号中重建高语义保真度的内容，而资源受限的发射端则简化了源和信道编码设计。

Result: GenCom在低信噪比和不确定的信噪比条件下展现出鲁棒的性能，在传统系统失败的情况下依然表现良好。

Conclusion: GenCom通过利用生成式AI和收发端资源不平衡的特性，为6G上行链路提供了一种新的鲁棒范式，在低信噪比和不确定的信噪比条件下表现出色，有望成为未来以人为本、智能和可持续无线网络的关键支持技术。

Abstract: Next-generation wireless networks (6G) face a critical uplink bottleneck due
to stringent device-side resource constraints and challenging channel
conditions. This article introduces GenCom, a novel system-level paradigm for
robust 6G uplink that leverages Generative AI and exploits the inherent
resource imbalance between transmitters and receivers. In GenCom, resource-rich
receivers deploy powerful offline-trained GenAI models to reconstruct high
semantic-fidelity content from degraded signals, while resource-constrained
transmitters are simplified in both source and channel coding design. We
present the core mechanisms and key design principles behind GenCom, which
shifts from conventional approaches toward simple semantic-preserving
compression, weak error-distribution codes, and semantic-aware retransmissions.
Through a case study, GenCom is shown to deliver robust performance across a
wide range of low and uncertain SNR/SINR conditions where conventional systems
fail. Finally, we outline critical challenges and research directions toward
making GenCom a practical enabler of future human-centric, intelligent, and
sustainable wireless networks.

</details>


### [269] [Satellites are closer than you think: A near field MIMO approach for Ground stations](https://arxiv.org/abs/2508.09374)
*Rohith Reddy Vennam,Luke Wilson,Ish Kumar Jain,Dinesh Bharadia*

Main category: eess.SP

TL;DR: ArrayLink通过分布式相控阵列克服了LEO卫星地面回传瓶颈，实现了高增益和多流传输，成本效益高且可扩展。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道（LEO）卫星星座的快速发展，地面站基础设施的扩展未能跟上步伐，导致卫星到地面的回传容量成为关键瓶颈。传统的抛物面碟形天线不适用于密集、快速移动的LEO网络，而相控阵天线则受限于高成本、硬件问题和实现足够天线增益的复杂性。

Method: ArrayLink是一种分布式相控阵列架构，通过在公里级孔径上分布16个（32x32）商用小型面板，实现相干组合，以获得高增益波束成形和视线MIMO空间复用。

Result: ArrayLink实现了接近碟形天线的增益（与1.47米反射器相比在1-2 dB范围内），能够支持多达四个并行空间流（在数百公里范围内），并且其理论、仿真和实验结果高度一致，表明该技术在实际应用中具有可行性。

Conclusion: ArrayLink提供了一种经济高效且可扩展的方法来解决LEO卫星星座的地面回传瓶颈，通过利用分布式相控阵列技术，实现了高增益波束成形和多流空间复用。

Abstract: The rapid growth of low Earth orbit (LEO) satellite constellations has
revolutionized broadband access, earth observation, and direct-to-device
connectivity. However, the expansion of ground station infrastructure has not
kept pace, creating a critical bottleneck in satellite-to-ground backhaul
capacity. Traditional parabolic dish antennas, though effective for
geostationary (GEO) satellites, are ill-suited for dense, fastmoving LEO
networks due to mechanical steering delays and their inability to track
multiple satellites simultaneously. Phased array antennas offer electronically
steerable beams and multisatellite support, but their integration into ground
stations is limited by the high cost, hardware issues, and complexity of
achieving sufficient antenna gain. We introduce ArrayLink, a distributed phased
array architecture that coherently combines multiple small commercially
available panels to achieve high-gain beamforming and unlock line-of-sight MIMO
spatial multiplexing with minimal additional capital expenditure. By spacing 16
(32x32) panels across a kilometer-scale aperture, ArrayLink enters the
radiative near-field, focusing energy in both angle and range while supporting
up to four simultaneous spatial streams on a single feeder link. Through
rigorous theoretical analysis, detailed 2D beam pattern simulations and
real-world hardware experiments, we show that ArrayLink (i) achieves dish-class
gain with in range 1-2 dB of 1.47 m reflector, (ii) maintains four parallel
streams at ranges of hundreds of kilometers (falling to two beyond 2000 km),
and (iii) exhibits tight agreement across theory, simulation, and experiment
with minimal variance. These findings open a practical and scalable path to
boosting LEO backhaul capacity.

</details>


### [270] [Sub-THz Power Amplifiers: Measurements, Behavioral Modeling and Predistortion Algorithms](https://arxiv.org/abs/2508.09545)
*Lutfi Samara,Simon Haussmann,Erind Tufa,Antonio Alberto D'Amico,Tommaso Zugno,Ingmar Kallfass,Thomas Kürner*

Main category: eess.SP

TL;DR: 太赫兹通信面临 PA 非线性挑战。本研究对 300 GHz PA 进行了建模和预失真研究，发现通过调整参数可改善性能，但低功率和频率依赖性仍需解决。


<details>
  <summary>Details</summary>
Motivation: 随着全球 IMT 流量的预期增长，太赫兹（THz）频谱为满足这些预测提供了解决方案。然而，占用 THz 频谱存在挑战，其中一个重要挑战是 THz 收发器中宽带射频（RF）元件造成的损伤，特别是功率放大器（PA）的非线性，这会影响系统性能，尤其是在采用高峰均功率比（PAPR）的波形（如 OFDM）时。

Method: 本研究介绍了对 300 GHz PA 的特性分析结果，包括小信号和连续波大信号测量。基于这些测量结果，开发并验证了能够捕捉 270-330 GHz 频率范围内幅度-幅度调制（AM-AM）和幅度-相位调制（AM-PM）行为的模型。利用这些模型，设计并分析了一种预失真算法。

Result: 所提出的模型在宽带测量中得到验证，确认了压缩行为，但在低输入功率下由于未考虑频率依赖性而显示出不准确性。基于导出的模型，设计的预失真算法在单载波和多载波波形之间切换时，显示出显著的误差性能下降。

Conclusion: 研究表明，通过调整预失真器参数可以显著提高性能，但仍存在一些局限性，例如在低输入功率下由于频率依赖性未被考虑而导致的模型不准确。

Abstract: With global IMT traffic expected to grow 10-100 times from 2020 to 20301, the
Terahertz (THz) spectrum offers a promising solution to satisfy such forecasts.
However, occupying the THz spectrum comes with its own challenges, an important
one being impairments caused by broadband RF components in THz transceivers.
Nonlinearities in power amplifiers (PAs) complicate meeting link budget
requirements, with amplitude and phase distortions degrading the system's
performance, especially when adopting waveforms with high peak-to-average power
ratios (PAPRs), such as Orthogonal Frequency Division Multiplexing (OFDM). In
this paper, we present characterization results of a 300 GHz PA using
small-signal and large-signal continuous-wave measurements. Models capturing
Amplitude-to- Amplitude Modulation (AM-AM) and Amplitude-to-Phase Modulation
(AMPM) behavior across 270-330 GHz are developed and verified with wideband
measurements, confirming the compression behavior, while nonetheless showing
inaccuracies for low input powers due to unaccounted frequency dependencies.
Based on the derived models, a predistortion algorithm is designed and
analyzed, revealing significant error performance degradation when switching
between single- and multi-carrier waveforms. We finally show that an
appropriate selection of pre-distorter parameters can significantly improve the
performance.

</details>


### [271] [Profiling Multi-Level Operator Costs for Bottleneck Diagnosis in High-Speed Data Planes](https://arxiv.org/abs/2508.09574)
*Zhiyuan Ren,Yutao Liu,Wenchi Cheng,Kun Yang*

Main category: eess.SP

TL;DR: 提出了一种新的方法来测量数据平面算子成本，揭示了算子成本的非线性缩放行为，并进行了跨架构的性能比较。


<details>
  <summary>Details</summary>
Motivation: 为了高精度地测量数据平面算子成本，揭示算子成本的非线性缩放行为，并进行跨架构的性能比较。

Method: 提出了一种基于饱和吞吐量增量的方法来精确测量高速数据平面中的算子成本，无需侵入式仪器。

Result: 该方法能够捕捉非线性缩放行为，发现像CRC这样的计算密集型算子表现出超线性行为，而大多数其他算子则表现为线性。此外，还引入了算子性能象限（OPQ）框架，通过基本成本和缩放成本对算子进行分类，并揭示了跨Arm和x86架构的象限偏移。

Conclusion: 该方法提供准确的、与架构相关的瓶颈诊断，为性能建模和优化提供了现实的基础。

Abstract: This paper proposes a saturation throughput delta-based methodology to
precisely measure operator costs in high-speed data planes without intrusive
instrumentation. The approach captures non-linear scaling, revealing that
compute-intensive operators like CRC exhibit super-linear behavior, while most
others are sub-linear. We introduce the Operator Performance Quadrant (OPQ)
framework to classify operators by base and scaling costs, exposing a
cross-architecture Quadrant Shift between Arm and x86. This method provides
accurate, architecture-aware bottleneck diagnosis and a realistic basis for
performance modeling and optimization.

</details>


### [272] [3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator](https://arxiv.org/abs/2508.09708)
*Thomas Fehrenbach,Luis Omar Ortiz Abrego,Cornelius Hellge,Thomas Schierl,Jörg Ott*

Main category: eess.SP

TL;DR: V2X通信支持智能交通系统。车队技术很有前景，但对通信有高可靠性和低延迟的要求。本研究评估了一种名为“组调度”（模式2d）的分布式资源分配方案，通过仿真证明其满足车队通信的需求。


<details>
  <summary>Details</summary>
Motivation: 车联网（V2X）是智能交通系统的关键技术，其中车队（platooning）因能提高燃油经济性和减少排放而备受关注，但它对无线通信的可靠性和低延迟提出了巨大挑战。

Method: 通过仿真评估了基于分布式调度资源分配方案的组调度（模式2d），该方案允许车辆从配置好的资源池中选择资源，无需网络协助。

Result: 仿真结果表明，该组调度方法能够满足车联网编队运行对可靠性、低延迟和数据率的要求。

Conclusion: 该方法能够满足车联网编队运行对可靠性、低延迟和数据率的要求。

Abstract: Vehicle-to-everything (V2X) communication is a key technology for enabling
intelligent transportation systems (ITS) that can improve road safety, traffic
efficiency, and environmental sustainability. Among the various V2X
applications, platooning is one of the most promising ones, as it allows a
group of vehicles to travel closely together at high speeds, reducing fuel
consumption and emissions. However, it poses significant challenges for
wireless communication, such as high reliability and low latency. In this
paper, we evaluate the benefits of group scheduling, also referred to as Mode
2d, which is based on a distributed and scheduled resource allocation scheme
that allows the group of cars to select resources from a configured pool
without network assistance. We evaluated the scheme through simulations, and
the results show that this approach can meet the reliability, low latency, and
data rate requirements for platooning.

</details>


### [273] [CKFNet: Neural Network Aided Cubature Kalman filtering](https://arxiv.org/abs/2508.09727)
*Jinhui Hu,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: CKFNet通过将RNN集成到CKF框架中，实现了对未建模不确定性的动态适应，提高了精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决CKF在实践中由于模型-环境不匹配导致的性能下降问题。

Method: CKFNet是一种混合架构，将循环神经网络（RNN）与CKF框架相结合，并保留了其数值积分原理。该架构在预测阶段嵌入RNN模块，通过学习时域噪声相关性来动态适应未建模的不确定性。

Result: 数值模拟实验已证实CKFNet的有效性。

Conclusion: CKFNet展现出比传统基于模型的方法和现有的KalmanNet算法更优越的精度和鲁棒性。

Abstract: The cubature Kalman filter (CKF), while theoretically rigorous for nonlinear
estimation, often suffers performance degradation due to model-environment
mismatches in practice. To address this limitation, we propose CKFNet-a hybrid
architecture that synergistically integrates recurrent neural networks (RNN)
with the CKF framework while preserving its cubature principles. Unlike
conventional model-driven approaches, CKFNet embeds RNN modules in the
prediction phase to dynamically adapt to unmodeled uncertainties, effectively
reducing cumulative error propagation through temporal noise correlation
learning. Crucially, the architecture maintains CKF's analytical
interpretability via constrained optimization of cubature point distributions.
Numerical simulation experiments have confirmed that our proposed CKFNet
exhibits superior accuracy and robustness compared to conventional model-based
methods and existing KalmanNet algorithms.

</details>


### [274] [Online Data Generation for MIMO-OFDM Channel Denoising: Transfer Learning vs. Meta Learning](https://arxiv.org/abs/2508.09751)
*Sungyoung Ha,Ikbeom Lee,Seunghyeon Jeon,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 提出了一种在线自适应信道去噪方法，利用数据辅助信道估计生成训练数据，并通过迁移学习和元学习实现快速适应。


<details>
  <summary>Details</summary>
Motivation: 为了解决信道去噪技术在不同信道条件下适应性调整需要先验知识或大量训练开销的挑战。

Method: 提出了一种生成在线训练数据的标准兼容策略，并基于此策略设计了两种信道去噪方法：一种基于迁移学习，另一种基于元学习。

Result: 仿真结果表明，所提出的方法能够有效地适应动态信道条件，并显著降低信道估计误差。

Conclusion: 所提出的策略能够有效地适应动态信道条件，并显著减少信道估计误差。

Abstract: Channel denoising is a practical and effective technique for mitigating
channel estimation errors in multiple-input multiple-output orthogonal
frequency-division multiplexing (MIMO-OFDM) systems. However, adapting
denoising techniques to varying channel conditions typically requires prior
knowledge or incurs significant training overhead. To address these challenges,
we propose a standard-compatible strategy for generating online training data
that enables online adaptive channel denoising. The key idea is to leverage
high-quality channel estimates obtained via data-aided channel estimation as
practical substitutes for unavailable ground-truth channels. Our data-aided
method exploits adjacent detected data symbols within a specific time-frequency
neighborhood as virtual reference signals, and we analytically derive the
optimal size of this neighborhood to minimize the mean squared error of the
resulting estimates. By leveraging the proposed strategy, we devise two channel
denoising approaches, one based on transfer learning, which fine-tunes a
pre-trained denoising neural network, and the other based on meta learning,
which rapidly adapts to new channel environments with minimal updates.
Simulation results demonstrate that the proposed methods effectively adapt to
dynamic channel conditions and significantly reduce channel estimation errors
compared to conventional techniques.

</details>


### [275] [Location Privacy-Enabled Beamforming in ISAC Scenarios](https://arxiv.org/abs/2508.09882)
*Umair Ali Khan,Lester Ho,Holger Claussen,Chinmoy Kundu*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的基于DAOR的波束形成框架，用于在ISAC场景中保护发射机的位置隐私，通过重塑角度功率分布而非抑制LOS分量来制造虚假到达角，并在通信速率和位置隐私之间取得良好权衡。


<details>
  <summary>Details</summary>
Motivation: ISAC技术在实现感知和通信的同时，也暴露了用户位置信息。本文旨在解决ISAC场景下的发射机位置隐私保护问题。

Method: 提出了一种由隐私度量“到达角混淆比”（DAOR）指导的波束形成框架，并通过广义特征值分析推导了DAOR的可行闭式边界，然后将可达速率最大化问题在DAOR约束下进行制定，并利用半定规划松弛、特征向量选择和最优功率分配有效求解。

Result: 所提出的DAOR度量能够有效衡量位置隐私性。所提出的基于DAOR的波束形成器在不抵消LOS路径的情况下实现了位置隐私和通信速率之间的权衡。此外，次优设计策略在10 dB信噪比下实现了接近最优的通信速率，同时计算时间减少了近85%。

Conclusion: 本文提出的基于DAOR的波束形成器在不抵消LOS路径的情况下实现了位置隐私和通信速率之间的权衡。

Abstract: Integrated sensing and communication (ISAC) technology enables simultaneous
environmental perception and data transmission in wireless networks; however,
it also exposes user location to receivers. In this paper, we introduce a novel
beamforming framework guided by the proposed privacy metric direction of
arrival obfuscation ratio (DAOR) to protect transmitter location privacy in
ISAC scenarios. Unlike previous approaches, we do not suppress the
line-of-sight (LOS) component while reshaping the angular power distribution so
that a false direction appears dominant at the receiver. We derive closed-form
bounds on the feasible DAOR via generalized eigenvalue analysis and formulate
an achievable rate-maximization problem under the DAOR constraint. The
resulting problem is non-convex, which is efficiently solved using semidefinite
relaxation, eigenmode selection, and optimal power allocation. A suboptimal
design strategy is also proposed with reduced complexity. Numerical results
demonstrate that the proposed DAOR-based beamformer achieves a trade-off
between location privacy and communication rate without nullifying the LOS
path. Results also show that a suboptimal design achieves a near-optimal
communication rate with nearly an 85% reduction in computation time at a
signal-to-noise ratio (SNR) of 10 dB.

</details>


### [276] [Beam Cross Sections Create Mixtures: Improving Feature Localization in Secondary Electron Imaging](https://arxiv.org/abs/2508.09942)
*Vaibhav Choudhary,Akshay Agarwal,Vivek K Goyal*

Main category: eess.SP

TL;DR: SE成像新模型通过混合模型和MLE，提高了半导体检测的分辨率。


<details>
  <summary>Details</summary>
Motivation: 为了提高SE成像技术（如HIM）的分辨率，克服点尺寸和SE信号噪声的限制。

Method: 提出了一种新的SE成像模型，将束流空间轮廓的影响描述为混合模型，而不是传统的卷积模型，并推导了基于时间分辨测量（TRM）的最大似然估计（MLE）。

Result: 在半导体检测的边缘定位任务中，提出的MLE方法比传统插值方法有5倍的RMSE降低，在实际HIM数据集中也实现了5.4倍的平均RMSE降低。

Conclusion: 该模型通过结合卷积和混合模型来更准确地描述SE计数，并在半导体检测中实现了5倍的分辨率提升。

Abstract: Secondary electron (SE) imaging techniques, such as scanning electron
microscopy and helium ion microscopy (HIM), use electrons emitted by a sample
in response to a focused beam of charged particles incident at a grid of raster
scan positions. Spot size -- the diameter of the incident beam's spatial
profile -- is one of the limiting factors for resolution, along with various
sources of noise in the SE signal. The effect of the beam spatial profile is
commonly understood as convolutional. We show that under a simple and plausible
physical abstraction for the beam, though convolution describes the mean of the
SE counts, the full distribution of SE counts is a mixture. We demonstrate that
this more detailed modeling can enable resolution improvements over
conventional estimators through a stylized application in semiconductor
inspection of localizing the edge in a two-valued sample. We derive Fisher
information about edge location in conventional and time-resolved measurements
(TRM) and also derive the maximum likelihood estimate (MLE) from the latter.
Empirically, the MLE computed from TRM is approximately efficient except at
very low beam diameter, so Fisher information comparisons are predictive of
performance and can be used to optimize the beam diameter relative to the
raster scan spacing. Monte Carlo simulations show that the MLE gives a 5-fold
reduction in root mean-squared error (RMSE) of edge localization as compared to
conventional interpolation-based estimation. Applied to three real HIM
datasets, the average RMSE reduction factor is 5.4.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [277] [Thermal gradient effect on hydrogen transport in tungsten](https://arxiv.org/abs/2508.09169)
*Sanad Alturk,Jacob Jeffries,Muhammed Kose,Enrique Martinez*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过分子动力学模拟，分析了热梯度对纯钨中氢（氚替代物）传输特性的影响，计算了热传导系数 $Q^*$，并给出了其与温度、温度梯度等因素的关系。


<details>
  <summary>Details</summary>
Motivation: 为了解决聚变装置中氚 (T) 在面向等离子体的组件中滞留的关键挑战，理解氚在钨 (W) 中的行为至关重要，因为钨是主要的候选装甲材料。

Method: 开发了一种分析方法，用于计算热传导系数 ($Q^*$)，并从分子动力学 (MD) 模拟中获取参数。

Result: 在纯钨中，氢（作为氚的替代物）的运输特性会受到热梯度的影响。研究表明，$Q^*$ 可以表示为温度、温度梯度、特征长度和向热区和冷区速率之比的函数。此外，我们还发现，$Q^*$ 对热梯度的依赖性（在一阶近似下）会消失，这与 MD 结果一致。平均而言，对于纯钨中的氢，$Q^*$ 的值为 $-5.41	imes 10^{-3}kT^2~	ext{eV}$。

Conclusion: 在纯钨中，氢（作为氚的替代物）的运输特性会受到热梯度的影响。在本研究中，我们开发了一种分析方法，用于计算热传导系数 ($Q^*$)，并从分子动力学 (MD) 模拟中获取参数。研究表明，$Q^*$ 可以表示为温度、温度梯度、特征长度和向热区和冷区速率之比的函数。此外，我们还发现，$Q^*$ 对热梯度的依赖性（在一阶近似下）会消失，这与 MD 结果一致。平均而言，对于纯钨中的氢，$Q^*$ 的值为 $-5.41	imes 10^{-3}kT^2~	ext{eV}$，其中 $k$ 是玻尔兹曼常数，$T$ 是温度。

Abstract: One key challenge for efficiency and safety in fusion devices is the
retention of tritium (T) in plasma-facing components. Tritium retention
generates radioactive concerns and decreases the amount of fuel available to
generate power. Hence, understanding the behavior of T in tungsten (W), as the
main candidate as armor material, is critical to the deployment of fusion as a
reliable energy source. In this work, we have studied the effect of a thermal
gradient in the transport properties of hydrogen (as a T surrogate) in pure W.
Strong thermal gradients develop in the divertor as a result of the intense
energy fluxes arriving at the material. We have developed an analytical
approach to compute the heat of transport ($Q^*$) that is parameterized from
molecular dynamics (MD) simulations. $Q^*$ is a parameter needed in
irreversible thermodynamics frameworks to understand mass transport in the
presence of thermal gradients. We show that $Q^*$ can be written as a function
of temperature, temperature gradient, a characteristic length and the ratio of
the rates towards hot and cold regions. Furthermore, we describe how, to first
order, the dependence of $Q^*$ on the thermal gradient vanishes, in agreement
with MD results. On average, we find $Q^*=-5.41\times 10^{-3}kT^2~\text{eV}$
for H in pure W, with $k$ the Boltzmann constant and $T$ the temperature.

</details>


### [278] [Controlled Growth of Bronze Telluride for Scalable Thermoelectric Energy Harvesting](https://arxiv.org/abs/2508.09317)
*Karthik R,Abhijith MB,Juan Gomez Quispe,Varinder Pal,Manas Paliwal,Ajit K Roy,Pedro Alves Da Silva Autreto,Sreeram Punathil Raman,Pulickel M. Ajayan,Chandra Sekhar Tiwary*

Main category: cond-mat.mtrl-sci

TL;DR: 通过CVD法合成Sn掺杂的Cu2Te（BT），在500K时ZT达到1，并成功应用于热电器件中，展现了其在中高温废热回收的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了满足对可持续和分散式能源解决方案日益增长的需求，并利用热电材料直接将废热转化为电能的潜力。

Method: 通过化学气相沉积（CVD）辅助的碲化工艺，使用预合金化的铜锡（青铜）粉末，以可持续的策略合成了Sn掺杂的Cu2Te（即青铜碲化物，BT）。

Result: 所得到的BT在500K时表现出增强的热电优值（ZT），达到1。将BT与n型方铅矿（PbS）集成在级联p-n热电模块中，在35K的温差下产生了2.8mV的电压，展示了其在中高温废热回收方面的应用潜力。

Conclusion: 这项工作通过使用工业相关前驱体，为开发铜基热电材料引入了一条高效、可扩展且对环境负责的途径。

Abstract: With the growing demand for sustainable and decentralized energy solutions,
thermoelectric energy harvesting has emerged as a promising technology for
directly converting waste heat into electricity through solid state,
environmentally friendly means. Among copper chalcogenides, Cu2Te is a notable
p-type material due to its degenerate semiconducting nature and low thermal
conductivity. In this study, we present a sustainable synthesis strategy for
Sn-doped Cu2Te referred to as bronze telluride (BT) via a chemical vapor
deposition (CVD) assisted tellurization process using pre-alloyed Cu Sn
(bronze) powder. The resulting BT exhibited an enhanced thermoelectric figure
of merit (ZT) of 1 at 500 K. To assess practical applicability, BT was
integrated with n type galena (PbS) in a cascaded p n thermoelectric module,
which generated 2.8 mV across a temperature gradient of 35 K, demonstrating its
potential for medium- to high-temperature waste heat recovery. Furthermore,
thermodynamic calculations and density functional theory (DFT) simulations
provided insights into the formation mechanism of Cu2Te and the thermoelectric
behaviour of BT. This work introduces an efficient, scalable, and
environmentally responsible pathway for developing copper-based thermoelectric
materials using industrially relevant precursors.

</details>


### [279] [Antiferron Modes in Ferroelectric Materials](https://arxiv.org/abs/2508.09326)
*David Galvez-Poblete,Mario A. Castro,Roberto E. Troncoso,Guillermo Romero,Alvaro S. Nunez,Sebastian Allende*

Main category: cond-mat.mtrl-sci

TL;DR: Antiferrons are new excitations in ferroelectric materials that require dynamic stabilization and could be used in electrical sensing devices.


<details>
  <summary>Details</summary>
Motivation: Introduce the concept of antiferron modes in ferroelectric materials as dynamically stabilized collective excitations over inverted polarization states that decrease the system energy.

Method: Using a generalized Landau-Ginzburg-Devonshire framework, we derive the effective curvature corrections from external driving, demonstrate the conditions for stabilizing metastable wells, and present the quantized Hamiltonian.

Result: The paper derives the effective curvature corrections from external driving, demonstrates the conditions for stabilizing metastable wells, and presents the quantized Hamiltonian.

Conclusion: Antiferrons, which are dynamically stabilized collective excitations over inverted polarization states, could be a promising candidate for developing electrical sensing devices, offering tunable, dynamically controllable excitations with high sensitivity to external electric fields.

Abstract: We introduce the concept of antiferron modes in ferroelectric materials as
dynamically stabilized collective excitations over inverted polarization states
that decrease the system energy. While ferrons represent quantized oscillations
around the stable polarization minimum, antiferrons require dynamic
stabilization via high-frequency driving. Using a generalized
Landau-Ginzburg-Devonshire framework, we derive the effective curvature
corrections from external driving, demonstrate the conditions for stabilizing
metastable wells, and present the quantized Hamiltonian. Antiferrons could be a
promising candidate for developing electrical sensing devices, offering
tunable, dynamically controllable excitations with high sensitivity to external
electric fields.

</details>


### [280] [Energetically Favored One-Dimensional Moiré Superstructure in the Pseudo-Square Lattice GdTe3](https://arxiv.org/abs/2508.09434)
*Jieun Yeon,Kihyun Lee,Myeongjin Jang,Tae Keun Yun,Jongho Park,Changyoung Kim,Kwanpyo Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究探索了 GdTe3 这种低对称性晶体的一维莫尔超晶格，并展示了其独特的电子性质，扩展了莫尔科学的研究范围。


<details>
  <summary>Details</summary>
Motivation: 现有的莫尔超晶格研究主要集中在六方晶系材料上，限制了对莫尔现象的全面理解和技术应用。本研究旨在将莫尔现象的研究范围扩展到低对称性晶体，以探索新的莫尔现象和应用。

Method: 利用垂直堆叠和可控应变/释放过程，结合透射电子显微镜（高分辨率扫描透射电子显微镜成像、暗场透射电子显微镜成像和样品倾斜实验）以及电子能量损失谱，系统地研究了 GdTe3 的一维莫尔超结构及其电子性质调制。

Result: 成功实现了能量上有利的 GdTe3 一维莫尔超晶格结构，并通过实验验证了不同堆叠方式的存在以及电子性质的调制，证明了在低对称性范德华晶体中实现莫尔现象的可行性。

Conclusion: 该研究将 GdTe3 这种伪四方层状晶体扩展为探索非常规莫尔现象的平台，并首次在低对称性范德华晶体中实现了具有潜在应用前景的一维莫尔超晶格结构，为莫尔科学开辟了新的方向。

Abstract: Moir\'e engineering in layered crystals has recently gained considerable
attention due to the discovery of various structural and physical phenomena,
including interfacial reconstruction, superconductivity, magnetism, and
distinctive optoelectronic properties. Nevertheless, most explored moir\'e
systems have been limited to hexagonal lattices, thereby constraining a
comprehensive understanding and technological application of moir\'e phenomena
in general layered crystals. Here, we investigate GdTe3, a pseudo-tetragonal
layered crystal, as a platform to explore unconventional moir\'e phenomena.
GdTe3 exhibits a slight in-plane distortion correlated with the direction of
charge density wave formation. Through vertical stacking of layers with
different distortions-induced via a controlled strain/release process-we
realize energetically favorable one-dimensional (1D) moir\'e superstructures.
Using transmission electron microscopy (TEM), including high-resolution
scanning TEM imaging, dark-field TEM imaging, and sample tilting experiments,
we systematically examine stacking variations across the 1D moir\'e structure.
Additionally, electron energy loss spectroscopy reveals modulations in
electronic properties associated with the 1D moir\'e structure. Our findings
expand the scope of moir\'e systems beyond conventional hexagonal twistronics,
enabling exploration of moir\'e phenomena in low-symmetry van der Waals
crystals.

</details>


### [281] [Mechanical Force-Driven Charge Redistribution for Hydrogen Release at Ambient Conditions in Transition Metal-Intercalated Bilayer Graphene](https://arxiv.org/abs/2508.09501)
*Jongdeok Kim,Vikram Mahamiya,Massimiliano Di Ventra,Hoonkyung Lee*

Main category: cond-mat.mtrl-sci

TL;DR: 外部机械力可调控双层石墨烯中氢气解吸温度，为解决TM功能化纳米材料的高解吸温问题提供新思路。


<details>
  <summary>Details</summary>
Motivation: 过渡金属（TM）原子功能化纳米材料在储氢方面具有潜力，但需要在环境条件下实现高效的氢气解吸，这是一个实际应用中的关键挑战。

Method: 使用第一性原理密度泛函理论（DFT）和热力学占据概率计算。

Result: 通过调整层间距可以精确控制H2的相互作用能，从而在环境条件下促进其解吸。对于Sc、Ti和V插层的双层石墨烯，当层间距分别减小到4.7埃、5.3埃和5.1埃以下时，会发生完全的氢气解吸。

Conclusion: 通过调整层间距，可以有效调控TM原子功能化双层石墨烯中氢气的解吸温度。当层间距减小到特定阈值以下时，可以实现氢气的完全解吸。

Abstract: Transition-metal (TM) atom-functionalized nanomaterials are promising
candidates for hydrogen storage due to their ability to adsorb multiple
hydrogen molecules through Kubas interactions. However, achieving efficient
hydrogen desorption at ambient conditions remains a critical challenge for
practical use. Here, we present a novel approach to modulate the desorption
temperature of hydrogen in TM-intercalated bilayer graphene (BLG) using
external mechanical forces. By employing first-principles density functional
theory (DFT) and thermodynamic occupancy probability calculations, we
demonstrate that adjusting the interlayer distance allows for precise control
over the interaction energy of H2, thereby facilitating its desorption at
ambient conditions. Complete hydrogen desorption occurs when the interlayer
distance is reduced below 4.7 {\AA}, 5.3 {\AA}, and 5.1 {\AA} for Sc-, Ti-, and
V-intercalated BLG, respectively. Our findings suggest that external mechanical
forces can effectively bring hydrogen occupancy to zero by minimizing charge
transfer from the TM d-orbitals to H2 antibonding orbitals. Notably, while the
total charge transferred from the TM atoms remains nearly constant at varying
interlayer distances, its redistribution between the graphene layers and H2
fine-tunes the interaction strength. This approach can be extended to large
interlayer distances, as supported by recent experiments on graphene oxide
membranes [ACS Nano 12, 9309 (2018)]. Furthermore, recent experimental advances
in noble gas and alkali metal intercalation in BLG highlight the potential of
this approach to overcome the long-standing challenge of high desorption
temperatures in TM-functionalized layered nanomaterials.

</details>


### [282] [Boron Clusters for Metal-Free Water Splitting](https://arxiv.org/abs/2508.09538)
*Masaya Fujioka,Haruhiko Morito,Melbert Jeem,Jeevan Kumar Padarti,Kazuki Morita,Taizo Shibuya,Masashi Tanaka,Yoshihiko Ihara,Shigeto Hirai*

Main category: cond-mat.mtrl-sci

TL;DR: 缺电子硼簇是新一代OER催化剂，活性高、寿命长，不含过渡金属。


<details>
  <summary>Details</summary>
Motivation: 寻找一种不含过渡金属的、高性能且耐用的氧析出反应（OER）催化剂，以期在OER设计领域实现超越传统过渡金属化学的范式转变。

Method: 通过高压扩散控制选择性地从NaAlB14和Na2B29中提取钠，实现对B12二十面体骨架的空穴掺杂。利用密度泛函理论揭示了催化剂表面的未占据p轨道和独特的局部电场。

Result: 缺电子硼簇作为一种全新的非过渡金属OER催化剂，其活性超过Co3O4一个数量级以上，并具有优异的碱性条件下耐久性。研究还揭示了一种由分子水介导的独特OER途径，这与传统的过渡金属氧化物不同。

Conclusion: 这项研究表明，缺电子硼簇是氧析出反应（OER）催化剂的一个全新类别，并且不含过渡金属。通过高压扩散控制选择性地从NaAlB14和Na2B29中提取钠，可以实现对B12二十面体骨架的空穴掺杂，从而使OER活性超过Co3O4一个数量级以上，并在碱性条件下具有出色的耐久性。

Abstract: Electron-deficient boron clusters are identified as a fundamentally new class
of oxygen evolution reaction (OER) catalysts, entirely free of transition
metals. Selective sodium extraction from NaAlB14 and Na2B29 via high-pressure
diffusion control introduces hole doping into B12 icosahedral frameworks,
resulting in OER activity exceeding that of Co3O4 by more than an order of
magnitude, and exceptional durability under alkaline conditions. B12 clusters
are known for their superchaotropic character, which destabilizes hydrogen
bonding in water. In this system, H2O, instead of OH-, preferentially adsorbs
on the catalyst surface, suggesting a distinct OER pathway mediated by
molecular water. This adsorption behavior contrasts with conventional
transition-metal oxides and reflects the unique interfacial properties of the
boron clusters. Density functional theory reveals unoccupied p orbitals and
unique local electric fields at the cluster surface, both of which could
promote the water activation. These findings suggest a paradigm shift in OER
catalysis, in which the unique interaction between B12 clusters and water
drives the reaction, replacing the conventional role of redox-active metals.
Hole-doped boron clusters thus offer a promising platform for designing
high-performance and durable water-splitting catalysts, opening new avenues for
OER design beyond conventional transition-metal chemistry.

</details>


### [283] [Discovery and Synthesis of a Family of Boride Altermagnets](https://arxiv.org/abs/2508.09542)
*Zhen Zhang,Eranga H. Gamage,Genevieve Amobi,Subhadip Pradhan,Andrey Kutepov,Kirill D. Belashchenko,Yang Sun,Kirill Kovnir,Vladimir Antropov*

Main category: cond-mat.mtrl-sci

TL;DR: 这项研究发现了 11 种新的交替磁体，并开发了一种合成方法，为硼化物中的交替磁性研究开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了将硼化物的性能和应用推向更广泛的领域，需要对硼化物进行系统的理论和实验研究。

Method: 使用理论和实验方法系统地搜索了三元硼化物 TM2B2 (T = 3d, M = 4d/5d 过渡金属) 中可合成的相。发现了 120 个稳定的/亚稳态的 TM2B2 材料，其中 40 种具有稳定的磁解。此外，还发现了 11 种 FeMo2B2 型结构的交替磁体。

Result: 发现了 120 种稳定的/亚稳态的 TM2B2 材料，其中 40 种具有稳定的磁解。发现了 11 种 FeMo2B2 型结构的交替磁体，它们具有电子带自旋分裂和零净磁化强度。还预测了与自旋电子学应用相关的传输性质，如应变诱导的自旋分裂效应和反常霍尔效应。通过碘辅助合成方法，成功合成了 7 种预测的低能相，包括 4 种交替磁体。

Conclusion: 这项工作通过提供硼化物中的新机会来扩展了硼化物领域，用于研究交替磁性及其交替声子，并为发现和设计交替磁性提供了宝贵的见解。通过证明交替磁性可以作为共享共同主题的家族存在，这项工作为通过元素替换和高通量计算发现交替磁性铺平了可行的道路。

Abstract: Borides are a rich material family. To push the boundaries of borides'
properties and applications into broader fields, we have conducted systematic
theoretical and experimental searches for synthesizable phases in ternary
borides TM$_2$B$_2$ (T = 3d, M = 4d/5d transition metals). We find that
TM$_2$B$_2$ in the FeMo$_2$B$_2$-type and CoW$_2$B$_2$-type structures form a
large family of stable/metastable materials of 120 members. Among them, we
identify 40 materials with stable magnetic solutions. Further, we discover 11
altermagnets in the FeMo$_2$B$_2$-type structure. So far, boride altermagnets
are rare. In these altermagnets, T = Fe or Mn atoms are arranged in parallel
T-chains with strong ferromagnetic intrachain couplings and antiferromagnetic
interchain couplings. They simultaneously exhibit electronic band spin
splitting, typical of ferromagnetism, and zero net magnetization, typical of
antiferromagnetism. They also exhibit magnonic band chiral splitting. Both
effects originate from the unique altermagnetic symmetries crucially
constrained by the nonmagnetic atoms in the structure. Transport properties of
relevance to spintronic applications, including the strain-induced
spin-splitter effect and anomalous Hall effect, are predicted. An
iodine-assisted synthesis method for TM$_2$B$_2$ is developed, using which 7 of
the predicted low-energy phases are experimentally synthesized and
characterized, including 4 altermagnets. This work expands the realm of borides
by offering new opportunities for studying altermagnetism and altermagnons in
borides. It also provides valuable insights into the discovery and design of
altermagnets. By demonstrating that altermagnets can exist as families sharing
a common motif, this work paves a feasible route for discovering altermagnets
by elemental substitutions and high-throughput computations.

</details>


### [284] [Investigating oxides by electrochemical projection of the oxygen off-stoichiometry diagram onto a single sample](https://arxiv.org/abs/2508.09559)
*Alexander Stangl,Alexander Schmid,Adeel Riaz,Martin Krammer,Andreas Nenning,Fjorelo Buzi,Fabrice Wilhelm,Francesco Chiabrera,Federico Baiutti,Albert Tarancón,Juergen Fleig,Arnaud Badel,Mónica Burriel*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种通过电化学极化在薄膜中创建面内氧浓度梯度的新方法，实现了对材料性质随氧含量变化的连续研究，并成功应用于La2NiO4+δ和(La,Sr)FeO3-δ薄膜，为基础和应用研究提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了确定和控制氧化物材料的结构、电子、离子、电化学和光学性质以及氧储存容量等热力学量，需要研究氧的非化学计量图，氧化学计量是调节先进氧化物材料功能特性的关键。

Method: 通过电化学极化和专门设计的电化学电池，在单层薄膜样品上实现并控制了明确的、线性的、一维面内氧浓度梯度，该梯度独立于材料电阻率的变化，其端点可通过外部氧分压和施加的过电位灵活控制。

Result: 成功地在过量化学计量的La2NiO4+δ和亚化学计量的(La,Sr)FeO3-δ薄膜中，利用空间分辨的原位/异位X射线吸收近边结构（XANES）、X射线衍射、椭圆光度法和电阻率测量，证明了面内氧梯度的概念。

Conclusion: 该研究展示了面内氧梯度概念的可行性，并在过量化学计量和亚化学计量薄膜中进行了验证，证明了该方法在基础和应用研究中的广泛适用性。

Abstract: The oxygen stoichiometry is an essential key to tune functional properties of
advanced oxide materials and thus has motivated numerous studies of the oxygen
off-stoichiometry diagram, with the aim to determine and control structural,
electronic, ionic, electrochemical and optical properties, as well as
thermodynamic quantities such as the oxygen storage capacity, among others.
Here, a novel approach is developed, which allows to project a broad range of
oxygen chemical potentials onto a single thin film sample with unprecedented
control via electrochemical polarization. Therefore, a specifically designed
electrochemical cell geometry is deployed, resulting in a well-defined, linear,
1D in-plane oxygen concentration gradient, independent of variations in the
materials electrical resistivity, whose endpoints can be flexibly controlled
via the external pO2 and applied overpotential. This allows for an unparalleled
study of materials properties as a continuous function of the oxygen content
using spatially resolved tools (spectroscopic, diffraction, microscopy, local
electrical probes, etc.) and thereby greatly reduces experimental efforts while
also avoiding sample-to-sample variability, multi-step treatments, sample
evolution effects, etc. This work presents the proof-of-concept of in-plane
oxygen gradients, based on spatially resolved ex/in situ and novel fixed-energy
X-ray absorption near edge spectroscopy (XANES), X-ray diffraction,
ellipsometry and electrical resistivity measurements in hyper-stoichiometric
La2NiO4+{\delta} and sub-stoichiometric (La,Sr)FeO3-{\delta} thin films. It
thereby demonstrates the readiness and wide applicability of this innovative
approach, which can be highly relevant for fundamental as well as applied
research.

</details>


### [285] [Interpreting Aqueous Two-Phase Extraction of Single-Walled Carbon Nanotubes with Highly Versatile Nonionic Polymers](https://arxiv.org/abs/2508.09605)
*Blazej Podlesny,Lukasz Czapura,Oussama Er-Riyahi,Karolina Z. Milowska,Dawid Janas*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究发现一种名为PEPEG的新型聚合物，它在水相双相萃取（ATPE）过程中能够选择性地分离不同种类的碳纳米管（SWCNTs），为高效纯化碳纳米管提供了新方法，并加深了对ATPE机制的理解。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地应用水相双相萃取（ATPE）技术，需要更好地理解其作用机制，特别是针对分离具有特定结构的目标物质，如单壁碳纳米管（SWCNTs）。

Method: 通过实验和模型研究了不同双相系统的形成，特别是使用聚乙烯-嵌段-聚（乙二醇）（PEPEG）作为相形成分、分配调节剂和分散剂，并考察了其对单壁碳纳米管（SWCNTs）的手性选择性。

Result: 研究表明，PEPEG在ATPE中具有多功能性，能够作为相形成分、分配调节剂和分散剂。更重要的是，PEPEG对SWCNTs表现出手性选择性，这有助于通过各种方法纯化SWCNTs。通过优化萃取环境，成功分离了（8,3）SWCNTs和其他富集的手性SWCNT组分。

Conclusion: 该研究揭示了聚乙烯-嵌段-聚（乙二醇）（PEPEG）在水相双相萃取（ATPE）中的多功能性，并证明了其对碳纳米管（SWCNTs）的手性选择性，从而为ATPE机制提供了新的见解，并为纯化特定结构的手性碳纳米管提供了有效方法。

Abstract: The development of efficient separation methods is essential for the
production of fine chemicals and materials. Among them, the aqueous two-phase
extraction (ATPE) allows for the isolation of single-walled carbon nanotubes
(SWCNTs) of specific structures and other substances. However, this easy-to-use
method, in which an analyte is partitioned between two phases, still demands a
better understanding of its mechanism to make its application more effective.
Herein, we demonstrate how various biphasic systems can be formed according to
the nature of the phase-forming components. Moreover, by employing
polyethylene-block-poly(ethylene glycol) (PEPEG), previously unrecognized in
this context, we reveal the versatility of nonionic polymers for ATPE, which
can successfully act as phase-forming compounds, partitioning modulators, and
dispersing agents. Interestingly, as proven by experiments and modelling, PEPEG
exhibited chirality-sensitive preference toward SWCNTs, which can significantly
facilitate the purification of SWCNTs using various approaches. Capitalizing on
this finding, we report how the extraction environment may be tailored to
promote the isolation of (8,3) SWCNTs and other chirality-enriched SWCNT
fractions. The relationships noted, based on the examination of a model
material (SWCNTs), provide substantial insight into the elusive mechanism of
the ATPE purification approach, widely employed across a range of analytes,
from cell organelles to nanostructures

</details>


### [286] [Colorization of Optically Transparent Surfactants to Track Their Movement in Biphasic Systems Used for Differentiation of Nanomaterials](https://arxiv.org/abs/2508.09612)
*Blazej Podlesny,Lukasz Czapura,Dawid Janas*

Main category: cond-mat.mtrl-sci

TL;DR: Used a refined historical chemical test to understand how surfactants help purify substances using aqueous two-phase extraction.


<details>
  <summary>Details</summary>
Motivation: To clarify the unclear extraction mechanism of aqueous two-phase extraction (ATPE) and the crucial but not fully understood role of surfactants in this process.

Method: Adapted and refined Pettenkofer's test to monitor the partitioning of single-walled carbon nanotubes (SWCNTs) by aqueous two-phase extraction (ATPE), using bile salt surfactants as tracers.

Result: Enabled precise tracking of bile salt surfactant distribution and concentration in the biphasic system, thereby elucidating the modus operandi of ATPE.

Conclusion: The study successfully refined Pettenkofer's test to monitor SWCNT partitioning in ATPE, clarifying the extraction mechanism and the role of bile salt surfactants.

Abstract: Aqueous two-phase extraction (ATPE) is a versatile method for the
purification of numerous chemical compounds and materials, ranging from
proteins and nucleic acids to cell organelles and various nanostructures.
However, despite its widespread use, the underlying extraction mechanism
remains unclear, which significantly reduces the utility of ATPE. Many types of
surfactants are often added to biphasic systems to enhance the extraction of
analytes between phases. Although their role in this process is crucial, it is
not entirely understood. In this work, to fill this gap, we adapt and refine a
nearly two-hundred-year-old chemical technique for the detection of bile salts
in urine, referred to as Pettenkofer's test and monitor the partitioning of
single-walled carbon nanotubes (SWCNTs) by ATPE. This approach enabled us to
tint the otherwise transparent bile salt surfactants to precisely track their
distribution and concentration in the biphasic system, thereby unravelling the
modus operandi of this popular purification technique.

</details>


### [287] [Mid-infrared LEDs based on lattice-mismatched hybrid IV-VI/III-V heterojunctions](https://arxiv.org/abs/2508.09703)
*Jarod E. Meyer,Biridiana Rodriguez,Leland Nordin,Kunal Mukherjee*

Main category: cond-mat.mtrl-sci

TL;DR: 研究人员利用IV-VI半导体（PbSe和PbSnSe）的低复合速率，结合III-V材料平台，制造出在中红外波段（3.8 um和5 um）工作的高效LED，为低成本化学传感提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决低成本化学传感中，窄线宽、昂贵的激光器和宽带、低效的热辐射体之间的差距，并克服III-V基中红外LED在室温下效率低的问题，该研究利用了IV-VI半导体的低俄歇-迈特纳复合速率。

Method: 通过制造混合异质结，利用了PbSe和PbSnSe的本征低俄歇-迈特纳复合速率，同时利用了成熟的III-V平台，调节了与GaAs的~8%晶格失配。

Result: n-PbSe/p-GaAs LED在3.8 um处发光，在脉冲工作下输出功率高达400 uW，室温下峰值电源效率为0.08%。含有7% Sn的GeSe/PbSnSe/GaAs LED将发射扩展到5 um，输出功率高达45 uW。这两种器件在~1e9/cm^2的螺纹位错密度下仍能工作，证明了混合IV-VI/III-V异质结结构的潜力。

Conclusion: 结合了IV-VI和III-V半导体的优点，提供了一个简单高效的中红外光电器件平台，可用于快速扩展的应用。

Abstract: Light-emitting diodes (LEDs) can bridge the gap between narrow linewidth,
expensive lasers and broadband, inefficient thermal globars for low-cost
chemical sensing in the mid-infrared (mid-IR). However, the efficiency of III-V
based mid-IR LEDs at room temperature is low, primarily limited by strong
nonradiative Auger-Meitner recombination that is only partially overcome with
complex quantum-engineered active regions. Here, we exploit the intrinsically
low Auger Meitner recombination rates of the IV-VI semiconductors PbSe and
PbSnSe, while leveraging the mature III-V platform through the fabrication of
hybrid heterojunctions that mediate the ~8% lattice mismatch to GaAs.
Electrically injected n-PbSe/p-GaAs LEDs emit at 3.8 um with output powers up
to 400 uW under pulsed operation and a peak wall plug efficiency of 0.08% at
room temperature, approaching the performance of commercial III-V LEDs at
similar wavelengths. Incorporating 7% Sn extends the emission to 5 um in
GeSe/PbSnSe/GaAs LEDs with output powers up to 45 uW. Notably, both devices
operate despite threading dislocation densities on the order of 1e9/cm^2,
underscoring the potential of hybrid IV-VI/III-V heterojunction architectures.
We show that combining the complementary advantages of IV-VI and III-V
semiconductors offers a simple and efficient mid IR optoelectronic platform for
a rapidly expanding set of applications.

</details>


### [288] [Altermagnetic spintronics](https://arxiv.org/abs/2508.09748)
*T. Jungwirth,J. Sinova,P. Wadley,D. Kriegner,H. Reichlova,F. Krizek,H. Ohno,L. Smejkal*

Main category: cond-mat.mtrl-sci

TL;DR: Altermagnetism, a new magnetic phase, could enhance future spintronic devices by enabling strongly spin-polarized currents and fast spin dynamics. This review bridges altermagnetism research with spintronics technology, examining its potential applications and interplay with other physical phenomena.


<details>
  <summary>Details</summary>
Motivation: The motivation is to connect the rapidly developing fields of altermagnetism (a new phase of matter with unique properties) and spintronics (a technology used in integrated circuits) by exploring how altermagnetism can impact future spintronic devices.

Method: This review connects the fields of altermagnetism and spintronics by discussing the potential impact of altermagnetism's unique signatures on future spintronic devices. It provides a reference by recalling the merits and limitations of current ferromagnetic spintronic technology and devices based on antiferromagnets and compensated magnets. The main part focuses on the physical concepts of altermagnetic spintronics and its potential interplay with ferroelectricity or superconductivity. Finally, it concludes with an outlook on experimental research and relativistic phenomena.

Result: The review discusses the potential impact of altermagnetism on the functionality and scalability of future spintronic devices, explores physical concepts of altermagnetic spintronics, and considers its interplay with ferroelectricity or superconductivity. It also provides an outlook on experimental research and the role of relativistic phenomena.

Conclusion: The review connects altermagnetism and spintronics, discussing the potential impact of altermagnetism's unique signatures on future spintronic devices, with a focus on physical concepts, interplay with ferroelectricity or superconductivity, and the outlook on experimental research and relativistic phenomena.

Abstract: The research landscape of magnetism has been recently enriched by the
discovery of altermagnetism. It is an unconventional phase of matter
characterized by a d-wave (or higher even-parity-wave) collinear compensated
spin ordering, which enables strongly spin-polarized currents in the absence of
magnetization, and features fast spin dynamics. Simultaneously, on the applied
magnetism front, spintronic memories based on conventional ferromagnets are
currently turning from a niche to a mass produced integrated-circuit technology
as they start to complement semiconductors on advanced-node microprocessor
chips. Our review connects these two rapidly developing science and technology
fields by discussing how the unique signatures of altermagnetism can impact the
functionality and scalability of future spintronic devices. As a reference, we
first briefly recall the merits and physical limitations of the present
ferromagnetic spintronic technology, and of proof-of-concept spintronic devices
based on conventional collinear antiferromagnets and non-collinear compensated
magnets. The main part of the review then focuses on physical concepts of the
altermagnetic spintronics, and its potential interplay with ferroelectricity or
superconductivity. We conclude with an outlook on the nascent experimental
research of altermagnetic spintronics, and on the role of relativistic
phenomena.

</details>


### [289] [Discovery of a low-density filled-ice phase in nitrogen hydrate at high pressure](https://arxiv.org/abs/2508.09771)
*Selene Berni,Sophie Espert,Tomasz Poreba,Simone Di Cataldo,Richard Gaal,Gabriel Tobie,Erwan Le Menn,Thomas C. Hansen,Roberto Bini,Livia Eleonora Bove*

Main category: cond-mat.mtrl-sci

TL;DR: 氮水合物在高压下会经历复杂的结构相变，并形成一种新的低密度填充冰结构，这对行星科学有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究氮水合物在高压下的行为，理解水和氮在高压下的相互作用。

Method: 结合中子衍射、拉曼光谱和晶体结构预测。

Result: 发现了一种新的正交填充冰结构（NH-V），其密度比冰VII低约30%，并证明了氮和水在高压下形成稳定填充冰结构的倾向。

Conclusion: 该研究揭示了氮水合物在高达16 GPa的压力和室温下的结构相图，发现了从sI/sII包合物到六方（sH）和四方（sT）相的相变序列，以及在1.8 GPa以上一种新颖的正交填充冰结构（NH-V）。

Abstract: We map the high-pressure phase diagram of nitrogen hydrate up to 16 GPa at
room temperature by combining neutron diffraction, Raman spectroscopy, and
crystal structure prediction. We reveal a rich sequence of structural
transformations, from sI/sII clathrates to hexagonal (sH) and tetragonal (sT)
phases, culminating in a previously unknown orthorhombic filled-ice structure
above 1.8 GPa in the Pnma space group, which we designate as NH-V. This new
phase cannot be indexed to any known ice frameworks - such as the high-pressure
methane hydrates MH-III (Imma) or MH-IV (Pmcn) - and exhibits a density
approximately 30% lower than that of stable ice VII, pointing to distinctive
water-nitrogen interactions. Our results refine the understanding of nitrogen
hydrate behavior under extreme conditions and demonstrate the propensity of
nitrogen and water to form stable filled-ice structures up to 16 GPa, with
important implications for planetary science.

</details>


### [290] [Optical phonons as a testing ground for spin group symmetries](https://arxiv.org/abs/2508.09793)
*F. Schilberth,M. Kondákor,D. Ukolov,A. Pawbake,K. Vasin,O. Ercem,L. Prodan,V. Tsurkan,A. A. Tsirlin,C. Faugeras,P. Lemmens,K. Penc,I. Kézsmárki,S. Bordács,J. Deisenhofer*

Main category: cond-mat.mtrl-sci

TL;DR: 在Co2Mo3O8中，光学声子揭示了反铁磁序出现时选择规则的变化，证实了相对论对称性方法比自旋群形式主义更适合描述此现象。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索非相对论自旋群（non-relativistic spin groups）形式下，阿尔特磁体（altermagnets）中声子选择规则，填补了该领域的空白。

Method: 本研究通过详细研究反铁磁体和阿尔特磁体候选物Co2Mo3O8中的红外和拉曼活性模式，并与精确捕捉本征频率的从头计算（ab initio calculations）进行比较，识别了室温下所有预期的声子模式，并使用两种对称性方法推导了它们的选择规则。

Result: 研究结果显示，光学声子能够区分相对论对称性方法和自旋群形式主义的预测，并且观察到了选择规则随反铁磁序出现的转变，这与相对论对称性方法一致。

Conclusion: 该研究表明，光学声子可以揭示阿尔特磁体（altermagnets）的正确对称性处理方法，并观察到选择规则随反铁磁序的出现而变化，这与相对论对称性方法一致，而自旋群形式主义则预测没有变化。

Abstract: Lattice vibrations are highly sensitive to crystal symmetries and their
changes across phase transitions. The latter can modify irreducible
(co)representations and corresponding infrared and Raman selection rules of
phonons. This concept is established for relativistic magnetic point groups,
simultaneously transforming spatial and spin coordinates. However, in
altermagnets described by non-relativistic spin groups with disjunct symmetry
operations for both vector spaces, the phonon selection rules have remained
unexplored. Here, we present a detailed study of the infrared- and Raman-active
modes in the collinear antiferromagnet and altermagnet candidate
Co$_2$Mo$_3$O$_8$. Comparing to ab initio calculations accurately capturing the
eigenfrequencies, we identify all expected phonon modes at room temperature and
deduce their selection rules using both symmetry approaches. Importantly, we
observe the change of selection rules upon antiferromagnetic ordering, agreeing
with the relativistic symmetry approach, while the spin group formalism
predicts no changes. Therefore, optical phonons can reveal the appropriate
symmetry treatment.

</details>


### [291] [Spin-chirality-dependent modulation of topological gap, Chern number, and valley-polarization in monolayer Kagome materials](https://arxiv.org/abs/2508.09884)
*Wenzhe Zhou,Guibo Zheng,Yating Li,Zhenzhen Wan,Aolin Li,Fangping Ouyang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过第一性原理计算和紧束缚模型，研究了单层Cr3Se4材料中的自旋手性对拓扑性质（如带隙、陈数和谷极化）的影响，发现自旋手性和结构不对称性是调控这些性质的关键因素，并为量子器件和谷电子学提供了新的策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在共线磁化，忽略了手性自旋纹理，而控制陈数对于量子器件操控至关重要。

Method: 通过第一性原理计算和紧束缚模型研究了单层Cr3Se4的自旋手性依赖性调控拓扑能隙、陈数和谷极化。

Result: 研究揭示了自旋手性依赖性调控拓扑能隙、陈数和谷极化，发现方位角没有可观察到的影响。对于共线磁化，拓扑带隙随自旋取向接近面内方向而减小。在呼吸式Kagome晶格中，K和K

Conclusion: 本研究表明，结构不对称性和自旋手性可以有效地调节带隙、陈数和谷极化，为控制拓扑态和推进量子器件及谷电子系统的应用提供了策略。

Abstract: Kagome materials exhibit unique electronic properties, such as the quantum
anomalous Hall effect. The control of Chern numbers is critical for quantum
device manipulation, but existing research has mainly focused on collinear
magnetization while neglecting chiral spin textures. Through first-principles
calculations and tight-binding modeling of monolayer Cr3Se4, this study reveals
spin chirality-dependent control of topological gaps, Chern numbers, and valley
polarization in kagome materials. The results demonstrate that the azimuthal
angle has no observable effect. For collinear magnetization, the topological
bandgap decreases as the spin orientation approaches the in-plane direction. In
the breathing Kagome lattice, the degeneracy between K and K' valleys is
lifted, and increasing the polar angle induces successive closing and reopening
of the valleys. For chiral spin textures, increasing polar angle enlarges the
bandgap when chirality \k{appa} = 1, while reducing it when \k{appa} = -1.
Moreover, spin chirality enables the quantum anomalous Hall state without
spin-orbit coupling. Structural asymmetry and spin chirality effectively
modulate the bandgap, Chern number, and valley polarization. These findings
provide strategies for controlling topological states and advancing
applications in quantum devices and valleytronic systems.

</details>


### [292] [Strain-driven feedback tunes memory and relaxation in a Mott insulator far from equilibrium](https://arxiv.org/abs/2508.09916)
*O. Yu. Gorobtsov,Y. Kalcheim,Z. Shao,A. Shabalin,N. Hua,D. Weinstock,R. Bouck,M. Seaberg,D. Zhu,O. G. Shpyrko,I. K. Schuller,A. Singer*

Main category: cond-mat.mtrl-sci

TL;DR: Quantum materials exhibit memory effects in transitions, slowing down relaxation over microseconds due to heterogeneity, similar to neural systems. This was observed in V2O3 using advanced X-ray diffraction.


<details>
  <summary>Details</summary>
Motivation: To understand the elusive memory and nonlinearity in non-equilibrium transitions of quantum materials, which involve a wide range of timescales and have potential for novel technologies.

Method: Extended time-resolved x-ray Bragg diffraction to capture a high dynamic range of timescales (femtoseconds to microseconds) for photoexcited transitions in V2O3 films.

Result: Identified a 10^5 adjustment in relaxation time, with memory of spatial and energy heterogeneity causing a Kohlrausch-Williams-Watts shaped relaxation over microseconds, significantly slower than nanoseconds. This slowdown is linked to heterogeneous excitation barriers.

Conclusion: Memory effects in metal-insulator transitions, as observed in V2O3 films, show a significant slowdown in relaxation time (10^5) due to spatial and energy heterogeneity, mimicking biological neural systems and indicating potential for novel technologies.

Abstract: Memory effects in metal-insulator transitions in quantum materials reveal
complex physics and potential for novel technologies mimicking biological
neural systems. Nonetheless, understanding of memory and nonlinearity in
non-equilibrium transitions remains elusive as they can involve timescales from
femtoseconds to microseconds. In this study, we extend time-resolved x-ray
Bragg diffraction to the necessary high dynamic range of timescales to fully
trace the pathways of far-from-equilibrium photoexcited transitions in
epitaxial films of V2O3, a technologically promising prototypical Mott
insulator. We find a 105 times adjustment in relaxation time: the memory of
spatial and energy heterogeneity during transition causes a
Kohlrausch-Williams-Watts shaped relaxation lingering over a hundred
microseconds versus nanoseconds. The dramatic slowdown in the light-driven
highly correlated system accompanies heterogeneous excitation barriers, as in
neural systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [293] [TFZ: Topology-Preserving Compression of 2D Symmetric and Asymmetric Second-Order Tensor Fields](https://arxiv.org/abs/2508.09235)
*Nathaniel Gorski,Xin Liang,Hanqi Guo,Bei Wang*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we present a novel compression framework, TFZ, that preserves
the topology of 2D symmetric and asymmetric second-order tensor fields defined
on flat triangular meshes. A tensor field assigns a tensor - a
multi-dimensional array of numbers - to each point in space. Tensor fields,
such as the stress and strain tensors, and the Riemann curvature tensor, are
essential to both science and engineering. The topology of tensor fields
captures the core structure of data, and is useful in various disciplines, such
as graphics (for manipulating shapes and textures) and neuroscience (for
analyzing brain structures from diffusion MRI). Lossy data compression may
distort the topology of tensor fields, thus hindering downstream analysis and
visualization tasks. TFZ ensures that certain topological features are
preserved during lossy compression. Specifically, TFZ preserves degenerate
points essential to the topology of symmetric tensor fields and retains
eigenvector and eigenvalue graphs that represent the topology of asymmetric
tensor fields. TFZ scans through each cell, preserving the local topology of
each cell, and thereby ensuring certain global topological guarantees. We
showcase the effectiveness of our framework in enhancing the lossy scientific
data compressors SZ3 and SPERR.

</details>


### [294] [DualPhys-GS: Dual Physically-Guided 3D Gaussian Splatting for Underwater Scene Reconstruction](https://arxiv.org/abs/2508.09610)
*Jiachen Li,Guangzhi Han,Jin Wan,Yuan Gao,Delong Han*

Main category: cs.GR

TL;DR: 提出DualPhys-GS框架，通过双路径优化机制（RGB引导衰减模型和多尺度深度感知散射模型）及多种损失函数和场景自适应机制，有效解决了水下三维重建中的颜色失真和几何伪影问题，尤其在复杂水域和远距离场景下重建效果更佳。


<details>
  <summary>Details</summary>
Motivation: 传统的水下三维重建方法基于大气光学模型，无法有效处理水体特有的光波长选择性衰减和悬浮粒子散射效应，导致重建结果出现颜色失真、几何伪影和远距离坍塌等问题。

Method: DualPhys-GS框架采用双路径优化机制，包括RGB引导衰减优化模型（结合RGB特征和深度信息处理细节）和多尺度深度感知散射模型（利用特征金字塔网络和注意力机制捕捉多尺度散射效应）。此外，设计了多种特殊损失函数（衰减散射一致性损失、水体类型自适应损失、边缘感知散射损失、多尺度特征损失）来保证物理一致性、自适应水体类型、保持边缘锐度并捕捉全局和局部结构信息。其场景自适应机制能自动识别水体类型并动态调整参数和优化策略。

Result: 实验结果表明，DualPhys-GS框架在各项指标上均优于现有方法，特别是在悬浮物密集的区域和远距离场景中，重建质量得到显著提升。

Conclusion: DualPhys-GS框架通过其创新的双路径优化机制，成功解决了传统方法在水下三维重建中因光波长选择性衰减和悬浮粒子散射而导致的颜色失真、几何伪影和远距离坍塌等问题。该方法在包含大量悬浮物的区域和远距离场景中表现优于现有方法，显著提高了重建质量。

Abstract: In 3D reconstruction of underwater scenes, traditional methods based on
atmospheric optical models cannot effectively deal with the selective
attenuation of light wavelengths and the effect of suspended particle
scattering, which are unique to the water medium, and lead to color distortion,
geometric artifacts, and collapsing phenomena at long distances. We propose the
DualPhys-GS framework to achieve high-quality underwater reconstruction through
a dual-path optimization mechanism. Our approach further develops a dual
feature-guided attenuation-scattering modeling mechanism, the RGB-guided
attenuation optimization model combines RGB features and depth information and
can handle edge and structural details. In contrast, the multi-scale
depth-aware scattering model captures scattering effects at different scales
using a feature pyramid network and an attention mechanism. Meanwhile, we
design several special loss functions. The attenuation scattering consistency
loss ensures physical consistency. The water body type adaptive loss
dynamically adjusts the weighting coefficients. The edge-aware scattering loss
is used to maintain the sharpness of structural edges. The multi-scale feature
loss helps to capture global and local structural information. In addition, we
design a scene adaptive mechanism that can automatically identify the
water-body-type characteristics (e.g., clear coral reef waters or turbid
coastal waters) and dynamically adjust the scattering and attenuation
parameters and optimization strategies. Experimental results show that our
method outperforms existing methods in several metrics, especially in suspended
matter-dense regions and long-distance scenes, and the reconstruction quality
is significantly improved.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [295] [An improved local search based algorithm for $k^-$-star partition](https://arxiv.org/abs/2508.09361)
*Mingyang Gong,Guohui Lin,Brendan Mumey*

Main category: cs.DS

TL;DR: This paper offers a faster algorithm for the k-star partition problem, improving the approximation ratio by using a clever method involving critical vertices and local search.


<details>
  <summary>Details</summary>
Motivation: To find a minimum collection of vertex-disjoint stars, each with at most k vertices, to cover all vertices in a simple undirected graph.

Method: The algorithm uses a local search approach with three operations and an amortization scheme. It distinguishes critical vertices and updates the solution iteratively.

Result: An O(|V|^3)-time approximation algorithm with a ratio of (k/2 - (k-2)/(8k-14)).

Conclusion: The paper presents an improved approximation algorithm for the k-star partition problem.

Abstract: We study the $k^-$-star partition problem that aims to find a minimum
collection of vertex-disjoint stars, each having at most $k$ vertices to cover
all vertices in a simple undirected graph $G = (V, E)$. Our main contribution
is an improved $O(|V|^3)$-time $(\frac k2 - \frac {k-2}{8k-14})$-approximation
algorithm.
  Our algorithm starts with a $k^-$-star partition with the least $1$-stars and
a key idea is to distinguish critical vertices, each of which is either in a
$2$-star or is the center of a $3$-star in the current solution. Our algorithm
iteratively updates the solution by three local search operations so that the
vertices in each star in the final solution produced cannot be adjacent to too
many critical vertices. We present an amortization scheme to prove the
approximation ratio in which the critical vertices are allowed to receive more
tokens from the optimal solution.

</details>


### [296] [A Classical Quadratic Speedup for Planted $k$XOR](https://arxiv.org/abs/2508.09422)
*Meghal Gupta,William He,Ryan O'Donnell,Noah G. Singer*

Main category: cs.DS

TL;DR: 本文设计了一种更快的经典算法，削弱了量子算法的加速优势。


<details>
  <summary>Details</summary>
Motivation: 为了在大型常数k的情况下，设计一种比之前最好的经典算法更快的算法，以分析Schmidhuber等人提出的量子算法的量子加速比。

Method: 结合了亚线性时间算法（主要是生日悖论）和多项式反浓缩的工具。

Result: 本文设计的经典算法比之前最好的算法快一倍，对于大型常数k，Schmidhuber等人的量子算法的量子加速比仅为二次方。

Conclusion: 本文设计了一种新的经典算法，该算法在大型常数k的情况下比之前最好的算法快一倍，从而将Schmidhuber等人提出的量子算法的量子加速比降低到仅为二次方（但仍具有空间优势）。

Abstract: A recent work of Schmidhuber et al (QIP, SODA, & Phys. Rev. X 2025) exhibited
a quantum algorithm for the noisy planted $k$XOR problem running quartically
faster than all known classical algorithms. In this work, we design a new
classical algorithm that is quadratically faster than the best previous one, in
the case of large constant $k$. Thus for such $k$, the quantum speedup of
Schmidhuber et al. becomes only quadratic (though it retains a space
advantage). Our algorithm, which also works in the semirandom case, combines
tools from sublinear-time algorithms (essentially, the birthday paradox) and
polynomial anticoncentration.

</details>


### [297] [Retroactive Monotonic Priority Queues via Range Searching](https://arxiv.org/abs/2508.09892)
*Lucas Castro,Rosiane de Freitas*

Main category: cs.DS

TL;DR: 本研究降低了完全可追溯单调优先级队列的操作成本。


<details>
  <summary>Details</summary>
Motivation: 现有的完全可追溯优先级队列操作成本较高，为 O(log^2 m log log m)，而标准和部分可追溯优先级队列的操作成本为 O(log m)。本研究旨在降低完全可追溯优先级队列的操作成本。

Method: 该研究将查找最小元素的问题转化为范围搜索问题，并利用已有的范围搜索数据结构来设计可追溯的单调优先级队列。

Result: 研究设计了一种完全可追溯的单调优先级队列，操作成本为 O(log m + T(m))，其中 T(m) 是特定范围搜索数据结构的最大查询和更新时间。此外，还设计了另一种操作成本为 O(log m log log m) 的完全可追溯单调优先级队列。

Conclusion: 该研究为完全可追溯的单调优先级队列设计了一种数据结构，其操作成本为 O(log m) 时间。

Abstract: The best known fully retroactive priority queue costs $O(\log^2 m \log \log
m)$ time per operation, where $m$ is the number of operations performed on the
data structure. In contrast, standard (non-retroactive) and partially
retroactive priority queues cost $O(\log m)$ time per operation. So far, it is
unknown whether this $O(\log m)$ bound can be achieved for fully retroactive
priority queues.
  In this work, we study a restricted variant of priority queues known as
monotonic priority queues. We show that finding the minimum in a retroactive
monotonic priority queue is a special case of the range-searching problem. We
design a fully retroactive monotonic priority queue with a cost of $O(\log m +
T(m))$ time per operation, where $T(m)$ is the maximum between the query and
the update time of a specific range-searching data structure with $m$ elements.
Finally, we design a fully retroactive monotonic priority queue that costs
$O(\log m \log \log m)$ time per operation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [298] [Design and Simulation of 6T SRAM Array](https://arxiv.org/abs/2508.09419)
*Justin London*

Main category: eess.SY

TL;DR: "This paper analyzes the conventional 6T SRAM cell used in microprocessors. It covers the design, simulation, and performance analysis of the SRAM cell and its components, comparing its stability, speed, and power efficiency with edge-triggered D flip flops."


<details>
  <summary>Details</summary>
Motivation: "The paper aims to analyze the conventional 6T SRAM used in microprocessors for cache memory design, evaluating its performance characteristics."

Method: "The study involves designing a basic 6T SRAM cell and a 6-bit memory array layout using LEdit. Key SRAM components like sense amplifiers, decoders, write drivers, and precharge circuits are designed and analyzed. Simulations of voltage waveforms for read and write operations are performed in LTSpice, including the analysis of parasitic capacitances and their impact. Calculations of static noise margin, propagation delays, and power dissipation are conducted. A comparison is made between the SRAM

Result: "The analysis includes the design and simulation of SRAM components, extraction of parasitic capacitances, and calculation of performance metrics such as static noise margin, propagation delays, and power dissipation. A comparison with edge-triggered D flip flops is also presented."

Conclusion: "The 6T SRAM cell with CMOS transistors demonstrates stability, speed, and power efficiency when specific size area and ratio constraints are met. Both theoretical and simulated results are provided."

Abstract: Conventional 6T SRAM is used in microprocessors in the cache memory design.
The basic 6T SRAM cell and a 6 bit memory array layout are designed in LEdit.
The design and analysis of key SRAM components, sense amplifiers, decoders,
write drivers and precharge circuits are also provided. The pulse voltage
waveforms generated for read and write operations as well as Q and Qbar nodes
are simulated in LTSpice. Parasitic capacitances are extracted and their impact
on the waveforms analyzed. Static noise margin, propagation delays, and power
dissipation are calculated. Comparison of SRAM read and write operational
performance using CMOS transistors is made with edge-triggered D flip flops. If
certain size area and ratio constraints are satisfied, the 6T cell with CMOS
transistors will possess stability, speed, and power efficiency. Both
theoretical and simulated results are given.

</details>


### [299] [Control Systems Analysis of a 3-Axis Photovoltatic Solar Tracker for Water Pumping](https://arxiv.org/abs/2508.09420)
*Justin London*

Main category: eess.SY

TL;DR: A 3-axis solar tracker water pumping system was developed using motors, a linear actuator, PV cells, and sensors. The system optimizes solar energy capture and automates water pumping based on water level and soil moisture, with a control systems analysis provided.


<details>
  <summary>Details</summary>
Motivation: To develop and analyze an automated water pumping system that optimizes solar energy utilization for efficient water supply to plants, managed by a control systems approach.

Method: The system utilizes a 3-axis solar tracker with stepper/DC motors and a linear actuator for optimal PV positioning, powered by a 12V battery charged via a solar charge controller. It incorporates four photocell sensors for light intensity measurement and a solar tracking algorithm. Two water pumps are controlled based on water level (ultrasonic sensor) and soil moisture levels.

Result: The paper provides simulated and experimental results, including transfer functions, root loci, Bode plots, stability analysis, and steady-state error analysis for the proposed 3-axis solar tracker water pumping system.

Conclusion: The paper presents a 3-axis solar tracker water pumping system with detailed analysis from a control systems perspective, including transfer functions, root loci, Bode plots, and stability/steady-state error analysis, supported by simulated and experimental results.

Abstract: We propose 3-axis solar tracker water pumping system. The solar tracker can
rotate and tilt using stepper/DC motors and can rise and lower on a tripod
using a linear actuator. The charge generated from solar energy absorbed by
photovoltaic (PV) cells in the solar panel is stored in a 12V battery that in
turn powers two water diaphragm pumps using a solar charge controller. The PV
uses four light photocell resistors/sensors to measure light intensity. A solar
tracking algorithm determines the optimal angle for PV positioning. Using an
ultrasonic sensor to measure the water level in a reservoir water tank, water
is pumped from one water tank to the reservoir. Based on soil moisture sensor
levels, a second water pump supplies water from the reservoir to the plant. The
system is analyzed from a control systems perspective. The transfer functions,
root loci, and Bode plots are generated and simulated and experimental results
are provided as well as stability and steady-state error analysis.

</details>


### [300] [Imperfect Competition in Markets for Short-Circuit Current Services](https://arxiv.org/abs/2508.09425)
*Peng Wang,Luis Badesa*

Main category: eess.SY

TL;DR: 随着逆变器发电量增加，电网短路电流（SCC）减少，威胁电网安全。本研究使用受SCC约束的双层模型分析了同步发电机（SG）在提供SCC服务时可能存在的市场势力问题。研究发现，处于有利位置的SG可能通过市场获得三倍于正常情况的收入，因此需要谨慎设计相关市场机制。


<details>
  <summary>Details</summary>
Motivation: 随着逆变器基础资源（IBR）渗透率的不断提高，其对短路电流（SCC）的贡献减少，给电网安全运行带来了挑战。为了解决这个问题，研究了通过经济机制采购SCC辅助服务，但其市场适用性尚不明确，因为SCC服务具有高度局部性，可能容易出现市场势力问题。因此，有必要理解处于有利地理位置的SG是否会施加市场势力，以及如何缓解这种势力。

Method: 本研究采用受SCC约束的双层模型来研究SG的战略行为，并通过原对偶表述来处理由机组承诺变量引起的不适定性。

Result: 通过基于修改后的IEEE 30节点系统的案例研究，证明了具有战略地位的SG可以获得高达三倍的SCC服务收入，这表明需要仔细设计相关市场。

Conclusion: 本研究的模型和案例研究表明，在短期内，通过精心设计的市场机制，同步发电机（SG）可以通过提供短路电流（SCC）服务获得高达三倍的收入，并凸显了仔细设计此类市场的必要性。

Abstract: An important limitation of Inverter-Based Resources (IBR) is their reduced
contribution to Short-Circuit Current (SCC), as compared to that of Synchronous
Generators (SGs). With increasing penetration of IBR in most power systems, the
reducing SCC poses challenges to a secure system operation, as line protections
may not trip when required. In order to address this issue, the SCC ancillary
service could be procured via an economic mechanism, aiming at securing
adequate SCC on all buses. However, the suitability of markets for SCC services
is not well understood, given that these could be prone to market-power issues:
since the SCC contributions from various SGs to a certain bus are determined by
the electrical topology of the grid, this is a highly local service. It is
necessary to understand if SGs at advantageous electrical locations could exert
market power and, if so, how it could be mitigated. In order to fill this gap,
this paper adopts an SCC-constrained bilevel model to investigate strategic
behaviors of SGs. To address the non-convexity due to unit commitment
variables, the model is restructured through a primal-dual formulation. Based
on a modified IEEE 30-bus system, cases with strategic SGs placed at different
buses are analyzed. These studies demonstrate that agents exerting market power
could achieve up to triple revenues from SCC provision, highlighting the need
to carefully design these markets.

</details>


### [301] [From Micro to Macro Flow Modeling: Characterizing Heterogeneity of Mixed-Autonomy Traffic](https://arxiv.org/abs/2508.09432)
*Chenguang Zhao,Huan Yu*

Main category: eess.SY

TL;DR: 本文提出了一种新的方法，利用自动驾驶汽车（AVs）的拉格朗日轨迹数据来解决混合交通流中的异质性问题。该方法通过引入连续交通异质性属性和耦合守恒律来改进宏观交通流模型，从而能从轨迹数据中推断和表征交通异质性。实验证明，该模型能有效捕捉异质性，提高预测精度，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大多数自动驾驶汽车（AVs）的驾驶策略在车辆层面进行设计和分析，但其对宏观交通流的总体影响仍不明确，特别是当AVs与人类驾驶车辆（HVs）相互作用时产生的交通流异质性。现有的宏观交通流模型验证技术依赖于覆盖整个路段的高分辨率时空数据，而这对于混合自动驾驶交通来说很少可用。AVs通过车载传感器记录详细的拉格朗日轨迹，利用这些拉格朗日观测来验证混合自动驾驶流模型仍然是一个开放的研究挑战。

Method: 提出了一种连续交通异质性属性，并使用两个耦合守恒律（一个用于车辆数量，一个用于交通属性）来表示交通流。设计了从拉格朗日车辆轨迹中提取交通属性的重建方法。在数据充足的情况下，通过提取驾驶员的期望速度和局部行为不确定性来表征交通异质性；在数据稀疏的情况下，设计了一个端到端的映射，仅从当前时空区域的轨迹推断交通异质性。

Result: 通过对多个交通数据集的实验表明，该模型能够有效捕捉交通异质性，将基本图散点图聚类到基于属性的分组中，并将交通流动力学的校准误差相对于Aw-Rascle-Zhang模型基准降低了20%。详细分析还表明，该模型泛化能力强，在先前未知的各种交通条件下评估时，准确性几乎保持不变。

Conclusion: 该模型可以有效捕捉交通异质性，通过将基本图散点图聚类到基于属性的组中，并将交通流动力学的校准误差相对于Aw-Rascle-Zhang模型基准降低了20%。此外，该模型泛化性良好，在先前未知的各种交通条件下进行评估时，准确性几乎保持不变。

Abstract: Most autonomous-vehicles (AVs) driving strategies are designed and analyzed
at the vehicle level, yet their aggregate impact on macroscopic traffic flow is
still not understood, particularly the flow heterogeneity that emerges when AVs
interact with human-driven vehicles (HVs). Existing validation techniques for
macroscopic flow models rely on high-resolution spatiotemporal data spanning
entire road segments which are rarely available for mixed-autonomy traffic. AVs
record detailed Lagrangian trajectories of the ego vehicle and surrounding
traffic through onboard sensors. Leveraging these Lagrangian observations to
validate mixed-autonomy flow models therefore remains an open research
challenge. This paper closes the gap between microscopic Lagrangian data and
macroscopic Euclidean traffic models by introducing a continuous
traffic-heterogeneity attribute. We represent traffic flow with two coupled
conservation laws with one for vehicle number and one for the traffic
attribute. Reconstruction methods are designed to derive the traffic attribute
from Lagrangian vehicle trajectories. When abundant trajectory data are
available, we characterize traffic heterogeneity by extracting drivers' desired
speed and local behavioral uncertainty from trajectories. In data-scarce mixed
traffic, we design an end-to-end mapping that infers the traffic heterogeneity
solely from trajectories in the current spatiotemporal region. Experiments
across multiple traffic datasets show that the proposed model effectively
captures traffic heterogeneity by clustering the fundamental diagram scatter
into attribute-based groups. The calibration errors of traffic flow dynamics
are also reduce by 20% relative to the Aw-Rascle-Zhang model benchmark.
Detailed analyses further show that the model generalizes well, maintaining
nearly the same accuracy when evaluated under a variety of previously unseen
traffic conditions.

</details>


### [302] [Online Safety under Multiple Constraints and Input Bounds using gatekeeper: Theory and Applications](https://arxiv.org/abs/2508.09963)
*Devansh R. Agrawal,Dimitra Panagou*

Main category: eess.SY

TL;DR: gatekeeper框架通过使用递归约束保证和备份控制器来解决网络物理系统的在线安全问题，并提供性能验证和多智能体编队飞行的具体应用。


<details>
  <summary>Details</summary>
Motivation: 该方法旨在保证在多个状态和输入约束下的网络物理系统的在线安全性。

Method: gatekeeper框架利用一个备份控制器来递归地保证满足所有约束和系统动力学的无限轨迹的存在。该框架依赖于少数可验证的假设，并且计算效率高，因为它只需要对单个标量变量进行优化。

Result: 该理论推导了相对于完整的非线性轨迹优化问题的次优性界限，并展示了如何在运行时使用它来验证性能。此外，还详细演示了gatekeeper在多智能体编队飞行中的应用，其中每个Dubins智能体都必须避开多个障碍物和武器交战区，这些障碍物和交战区都是非线性的、非凸的约束。

Conclusion: gatekeeper框架递归地保证了满足所有约束和系统动力学的无限轨迹的存在，并为多智能体编队飞行提供了一个应用程序。

Abstract: This letter presents an approach to guarantee online safety of a
cyber-physical system under multiple state and input constraints. Our proposed
framework, called gatekeeper, recursively guarantees the existence of an
infinite-horizon trajectory that satisfies all constraints and system dynamics.
Such trajectory is constructed using a backup controller, which we define
formally in this paper. gatekeeper relies on a small number of verifiable
assumptions, and is computationally efficient since it requires optimization
over a single scalar variable. We make two primary contributions in this
letter. (A) First, we develop the theory of gatekeeper: we derive a
sub-optimality bound relative to a full nonlinear trajectory optimization
problem, and show how this can be used in runtime to validate performance. This
also informs the design of the backup controllers and sets. (B) Second, we
demonstrate in detail an application of gatekeeper for multi-agent formation
flight, where each Dubins agent must avoid multiple obstacles and weapons
engagement zones, both of which are nonlinear, nonconvex constraints.

</details>


### [303] [From Formal Methods to Data-Driven Safety Certificates of Unknown Large-Scale Networks](https://arxiv.org/abs/2508.09520)
*Omid Akbarzadeh,Behrad Samari,Amy Nejati,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 该研究提出了一种数据驱动的分布式方法，用于为具有未知动态的大型互联网络设计安全控制器。该方法将网络分解为子系统，利用噪声数据为每个子系统设计控制器，然后组合这些控制器以确保整个网络的安全性，并将计算复杂度降低到与子系统数量成线性关系。


<details>
  <summary>Details</summary>
Motivation: 为具有未知数学动态的大规模互联网络设计鲁棒的安全控制器，克服网络高维性和模型未知的挑战。

Method: 提出了一种数据驱动的方案，将大型互联网络视为较小子系统的组合。利用每个子系统轨迹的噪声数据设计控制子障碍函数（CSBC）和局部控制器。通过组合这些 CSBC，利用小增益组合推理，为整个网络设计控制障碍函数（CBC），确保无限时间范围内的安全性。

Result: 该方法将设计 CBC 及其安全控制器的计算复杂度从与网络维度多项式增长（使用 SOS 优化）显著降低到与子系统数量成线性关系。在具有未知模型和不同互连拓扑的多个物理网络上进行了演示。

Conclusion: 该方法通过组合多个子系统的控制子障碍函数（CSBC）来确保整个网络的安全性，并提供了正确性保证。

Abstract: In this work, we propose a data-driven scheme within a compositional
framework with noisy data to design robust safety controllers in a fully
decentralized fashion for large-scale interconnected networks with unknown
mathematical dynamics. Despite the network's high dimensionality and the
inherent complexity of its unknown model, which make it intractable, our
approach effectively addresses these challenges by (i) treating the network as
a composition of smaller subsystems, and (ii) collecting noisy data from each
subsystem's trajectory to design a control sub-barrier certificate (CSBC) and
its corresponding local controller. To achieve this, our proposed scheme only
requires a noise-corrupted single input-state trajectory from each unknown
subsystem up to a specified time horizon, satisfying a certain rank condition.
Subsequently, under a small-gain compositional reasoning, we compose those
CSBC, derived from noisy data, and formulate a control barrier certificate
(CBC) for the unknown network, ensuring its safety over an infinite time
horizon, while providing correctness guarantees. We offer a data-dependent
sum-of-squares (SOS) optimization program for computing CSBC alongside local
controllers of subsystems. We illustrate that while the computational
complexity of designing a CBC and its safety controller grows polynomially with
network dimension using SOS optimization, our compositional data-driven
approach significantly reduces it to a linear scale concerning the number of
subsystems. We demonstrate the capability of our data-driven approach on
multiple physical networks involving unknown models and a range of
interconnection topologies.

</details>


### [304] [Shepherd Grid Strategy: Towards Reliable SWARM Interception](https://arxiv.org/abs/2508.09536)
*Boris Kriuk,Fedor Kriuk*

Main category: eess.SY

TL;DR: 现代无人机威胁需要复杂的拦截策略。本文提出了一种新的多阶段协调框架——牧羊人网格策略，该策略采用群体行为协调，通过系统遏制和协调打击执行来实现确定性目标拦截。该策略包含四个阶段：追逐、跟随、编队和交战，具有动态角色分配和自适应编队几何结构。该方法的三项关键创新是：自适应阶段转换机制、动态角色分配系统和预测性编队几何算法。仿真结果表明，与传统方法相比，拦截成功率提高了（超过95%），拦截时间也缩短了。


<details>
  <summary>Details</summary>
Motivation: 现代无人机威胁需要复杂的拦截策略，以克服先进的规避能力并在受干扰的环境中有效运行。传统的单拦截器和无协调多拦截器方法存在根本性缺陷，包括覆盖不足、可预测的追逐模式以及易受智能规避机动的影响。

Method: 该策略实施了一个包含追逐、跟随、编队和交战四个阶段的四阶段运行模型，具有动态角色分配和自适应编队几何结构，可维持持续的目标压力，同时准备最佳打击机会。该方法结合了三种关键创新：基于邻近性和任务目标的自适应阶段转换机制，可优化追逐行为；动态角色分配系统，可指定专门的拦截器功能，包括编队维持和打击执行；以及预测性编队几何算法，可创建适应目标移动模式的移动遏制网格。

Result: 仿真实验表明，与传统方法相比，该策略的性能有了显著提高，拦截成功率接近完美（超过95%），而传统方法的成功率为65%，并缩短了拦截中值时间。

Conclusion: 该牧羊人网格策略通过系统性的遏制和协调打击执行，实现了确定性的目标拦截，与传统方法相比，拦截成功率显著提高（超过95%），并缩短了拦截中值时间。

Abstract: Modern unmanned aerial vehicle threats require sophisticated interception
strategies that can overcome advanced evasion capabilities and operate
effectively in contested environments. Traditional single-interceptor and
uncoordinated multi-interceptor approaches suffer from fundamental limitations
including inadequate coverage, predictable pursuit patterns, and vulnerability
to intelligent evasion maneuvers. This paper introduces the Shepherd Grid
Strategy, a new multi-phase coordination framework that employs pack-based
behavioral coordination to achieve deterministic target interception through
systematic containment and coordinated strike execution. The strategy
implements a four-phase operational model consisting of chase, follow,
formation, and engagement phases, with dynamic role assignment and adaptive
formation geometry that maintains persistent target pressure while preparing
optimal strike opportunities. Our approach incorporates three key innovations:
adaptive phase transition mechanisms that optimize pursuit behavior based on
proximity and mission objectives, dynamic role assignment systems that
designate specialized interceptor functions including formation maintenance and
strike execution, and predictive formation geometry algorithms that create
mobile containment grids adapting to target movement patterns. The simulation
experiments demonstrate significant performance improvements over traditional
methods, achieving near-perfect interception success rates (over 95%) compared
to traditional approaches (65%) and reducing median time-to-intercept.

</details>


### [305] [Metering traffic flows for perimeter control through auction-based signalling using connected vehicles](https://arxiv.org/abs/2508.09678)
*Alexander Roocroft,Marco Rinaldi*

Main category: eess.SY

TL;DR: 通过在信号交叉口实施新颖的基于拍卖的绿灯时间分配机制，可以实现有效的周边控制，以调节车辆流入城市交通网络。


<details>
  <summary>Details</summary>
Motivation: 城市交通拥堵仍然是现代城市的一个关键挑战，交通信号控制系统在高峰出行时段管理拥堵方面常常遇到困难。保护网络（PN）的周边控制已成为减少城市网络阻塞的潜在解决方案。

Method: 利用密封投标、第二价格拍卖框架，该方法结合了实时交通监控和受市场启发的机制来调节流入保护网络区域的车辆。

Result: 结果表明，我们的基于拍卖的方法以更高的精度控制了流入 PN 的流量，在流入调节、队列管理和延迟方面优于基于数量的方法。

Conclusion: 该框架可实时应用于任何通用交叉口，为城市交通管理提供可扩展的解决方案。本研究将周边控制与基于市场的交叉口拍卖联系起来，为自适应交通管理系统的进一步研究提供了途径。

Abstract: Urban traffic congestion remains a critical challenge in modern cities, with
traffic signal control systems often struggling to manage congestion during
peak travel times. Perimeter control of a Protected Network (PN) has emerged as
a potential solution to reducing gridlock in urban networks. This paper
proposes a novel auction-based mechanism for green time allocation at
signalized intersections, for effective perimeter control application.
Utilising a Sealed Bid, Second Price auction framework, our approach combines
real-time traffic monitoring with market-inspired mechanisms to regulate
vehicle inflows into PN areas. Unlike existing methods that focus primarily on
gated links, our system allocates budgets to individual traffic movements,
providing greater flexibility in managing multi-directional flows. We evaluate
the proposed mechanism using a test case intersection with a single controlled
inflow, comparing it against a volume-based fixed-time approach. The results
demonstrate that our auction-based method controls flows into the PN with
improved accuracy, outperforming the volume-based approach in terms of inflow
regulation, queue management and delays. The framework can be applied in real
time to any generic intersection, offering a scalable solution for urban
traffic management. This work bridges the gap between perimeter control and
market-based intersection auctions, providing a pathway for further research on
adaptive traffic management systems.

</details>


### [306] [A Divide-and-Conquer Tiling Method for the Design of Large Aperiodic Phased Arrays](https://arxiv.org/abs/2508.09682)
*Nicola Anselmi,Paolo Rocca,Giovanni Toso,Andrea Massa*

Main category: eess.SY

TL;DR: 论文提出了一种用于大型相控阵天线的非规则平铺方法，该方法通过将天线孔径划分为子区域并进行局部多米诺平铺来优化设计，证明了其有效性和计算效率，并为低地球轨道（LEO）卫星通信提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 现代无线应用对成本低廉、高增益的扫描天线解决方案需求日益增长，因此，设计具有模块化集群排列的辐射元件的大型相控阵（PA）以及仅对子阵列进行幅度与相位控制是一个关键课题。

Method: 该研究提出了一种新颖的非规则平铺方法，该方法利用分而治之策略，将天线孔径划分为子区域，并对子区域进行局部多米诺平铺，同时确保了PA支撑的其余未平铺部分的完整覆盖。

Result: 论文中包含选取的代表性结果，并与目前最先进的综合方法进行了比较，证明了所提出的平铺方法的有效性和计算效率。最后，还讨论了低地球轨道（LEO）卫星通信的用例，为天线设计者提供了处理大型PA的实用指南。

Conclusion: 该论文提出了一种新颖的非规则平铺方法，该方法根据分而治之策略，将天线孔径细分为子区域，并通过联合满足PA支撑的剩余未平铺部分的满覆盖条件，对子区域进行局部多米诺平铺。所提出的平铺方法被证明是有效的，并且具有计算效率。论文最后讨论了低地球轨道（LEO）卫星通信的用例，以期为大型PA的天线设计者提供实用的指导。

Abstract: Due to the growing request from modern wireless applications of
cost-affordable and high-gain scanning antenna solutions, the design of large
phased arrays (PAs) with radiating elements organized into modular clusters
with sub-array-only amplitude and phase control is a key topic. In this paper,
an innovative irregular tiling method is proposed where, according to a
divide-and-conquer strategy, the antenna aperture is subdivided into sub-areas
that are locally domino-tiled by jointly fulfilling the full-coverage condition
on the remaining untiled part of the PA support. Selected representative
results, including comparisons with competitive state-of-the-art synthesis
methods, are reported to prove the effectiveness and the computational
efficiency of the proposed tiling approach. Use-cases of current relevance for
low Earth orbit (LEO) satellite communications are discussed, as well, to
provide the antenna designers useful practical guidelines for handling large
PAs.

</details>


### [307] [Besondere Anforderungen des automatisierten Fahrens an den Entwurf](https://arxiv.org/abs/2508.09731)
*Robert Graubohm,Markus Maurer*

Main category: eess.SY

TL;DR: Automated driving system design is complex. This paper offers a process model to address challenges in concept specifications and details a successful implementation.


<details>
  <summary>Details</summary>
Motivation: The development of automated driving functions is a complex task requiring the integration of numerous, sometimes conflicting interests and various constraints during system design.

Method: A systematic process model is presented for concept specifications in automated driving.

Result: The paper describes the successful implementation of a structured concept specification for an automated vehicle guidance system.

Conclusion: The paper presents a systematic process model to overcome challenges in concept specifications for automated driving and describes a successful implementation for an automated vehicle guidance system.

Abstract: The development of automated vehicles and automated driving functions is an
exceptionally complex task that requires the integration of numerous, sometimes
conflicting interests and various constraints already in the early stages of
system design. This chapter explains important challenges in concept
specifications for automated driving and presents a systematic process model
that contributes to overcoming the special requirements in this field. In
addition, it describes the successful implementation of a structured concept
specification for an automated vehicle guidance system.
  --
  Die Entwicklung automatisierter Fahrzeuge und Fahrfunktionen stellt eine
ausgesprochen komplexe Aufgabe dar, die bereits im Zuge des Systementwurfs die
Einbeziehung einer Vielzahl teilweise konflikt\"arer Interessen und diverser
Randbedingungen erfordert. Dieses Kapitel erl\"autert wichtige
Herausforderungen bei Konzeptspezifikationen im Themenfeld des automatisierten
Fahrens und stellt ein systematisches Prozessmodell vor, das einen Beitrag zur
Erf\"ullung der besonderen Anforderungen des automatisierten Fahrens an den
Entwurf leistet. Dar\"uber hinaus wird die erfolgreiche Durchf\"uhrung einer
strukturierten Konzeptspezifikation f\"ur ein automatisiertes
Fahrzeugf\"uhrungssystem beschrieben.

</details>


### [308] [Integrated Learning and Optimization to Control Load Demand and Wind Generation for Minimizing Ramping Cost in Real-Time Electricity Market](https://arxiv.org/abs/2508.09774)
*Imran Pervez,Omar Knio*

Main category: eess.SY

TL;DR: A new integrated learning and optimization (ILO) method improves power system economic dispatch by training a neural network to minimize generator ramping costs, outperforming traditional methods.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of predicting context-aware unknown parameters, specifically load and renewable generation, within the economic dispatch (ED) formulation for power systems. Accurate prediction of these parameters is crucial for optimal power dispatching decisions. The motivation is to improve the efficiency and cost-effectiveness of power systems by developing a methodology that directly optimizes ED decisions, particularly by minimizing generator ramping costs.

Method: The study proposes a new integrated learning and optimization (ILO) methodology for economic dispatch (ED). This framework trains a neural network (NN) to estimate unknown parameters (load and renewable generation) by minimizing an application-specific regret function. This regret function is designed to capture real-time electricity market operations, including the costs associated with generator ramping to correct prediction differences. The ILO framework trains the NN to guide load and renewable predictions towards minimizing generator ramping costs, contrasting with SLO methods that focus on accurate parameter estimation.

Result: The ILO framework significantly improves ramping costs when compared to SLO-based training of load and renewable predictions. Furthermore, it outperforms SLO trained load with 100% accurate renewable predictions, highlighting its decision-focused capability.

Conclusion: The proposed integrated learning and optimization (ILO) methodology, which trains a neural network to estimate economic dispatch (ED) parameters by minimizing a regret function, leads to significantly improved ramping costs compared to conventional sequential learning and optimization (SLO) methods. The ILO framework's decision-focused capability is demonstrated by its superior performance even when compared to SLO with perfectly accurate renewable predictions.

Abstract: We developed a new integrated learning and optimization (ILO) methodology to
predict context-aware unknown parameters in economic dispatch (ED), a crucial
problem in power systems solved to generate optimal power dispatching decisions
to serve consumer load. The ED formulation in the current study consists of
load and renewable generation as unknown parameters in its constraints
predicted using contextual information (e.g., prior load, temperature). The ILO
framework train a neural network (NN) to estimate ED parameters by minimizing
an application-specific regret function which is a difference between ground
truth and NN-driven decisions favouring better ED decisions. We thoroughly
analyze the feasible region of ED formulation to understand the impact of load
and renewable learning together on the ED decisions. Corresponding to that we
developed a new regret function to capture real-time electricity market
operations where differences in predicted and true loads are corrected by
ramping generators in real-time but at a higher cost than the market price. The
proposed regret function when minimized using ILO framework train the NN to
guide the load and renewable predictions to generate ED decisions favouring
minimum generator ramping costs. This is unlike conventional sequential
learning and optimization (SLO) framework which train NN to accurately estimate
load and renewable instead of better ED decisions. The combined training of
load and renewable using ILO is a new concept and lead to significantly
improved ramping costs when compared with SLO based training of load and
renewable and SLO trained load with 100% accurate renewable proving its
decision-focused capability.

</details>


### [309] [Collision-Free Bearing-Driven Formation Tracking for Euler-Lagrange Systems](https://arxiv.org/abs/2508.09908)
*Haoshu Cheng,Martin Guay,Shimin Wang,Yunhong Che*

Main category: eess.SY

TL;DR: 本论文研究了在存在多个移动领导者的情况下，如何精确跟踪具有参数不确定性的异构欧拉-拉格朗日系统的方位驱动编队。通过设计一种基于方位的分布式观测器来估计领导者的运动状态，并结合自适应机制来生成控制律，从而实现编队跟踪，并且无需预知系统参数。同时，还提出了一个确保编队成员之间不发生碰撞的条件。


<details>
  <summary>Details</summary>
Motivation: 在存在多个移动领导者的情况下，针对具有参数不确定性的异构欧拉-拉格朗日系统的基于方位的编队跟踪问题进行研究。

Method: 本研究首先为领导者系统设计了一个分布式观测器，该观测器利用基于方位的定位条件替代了传统的连通性假设，并结合自适应机制来估计领导者的速度和加速度。随后，设计了一种新颖的分布式控制律，用于引导编队达到目标编队，且无需预先了解系统参数。此外，还建立了一个依赖于初始编队配置的充分条件，以确保在整个编队演化过程中避免碰撞。

Result: 提出了一种分布式观测器和自适应控制律，用于在参数未知的情况下跟踪由方位驱动的编队，并提供了避免碰撞的条件。

Conclusion: 所提出的方法通过数值示例得到了验证。

Abstract: In this paper, we investigate the problem of tracking formations driven by
bearings for heterogeneous Euler-Lagrange systems with parametric uncertainty
in the presence of multiple moving leaders. To estimate the leaders' velocities
and accelerations, we first design a distributed observer for the leader
system, utilizing a bearing-based localization condition in place of the
conventional connectivity assumption. This observer, coupled with an adaptive
mechanism, enables the synthesis of a novel distributed control law that guides
the formation towards the target formation, without requiring prior knowledge
of the system parameters. Furthermore, we establish a sufficient condition,
dependent on the initial formation configuration, that ensures collision
avoidance throughout the formation evolution. The effectiveness of the proposed
approach is demonstrated through a numerical example.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [310] [Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning](https://arxiv.org/abs/2508.09277)
*Soumia Mehimeh*

Main category: cs.AI

TL;DR: DQInit是一种新的深度强化学习价值函数初始化方法，通过利用旧任务的Q值知识来加速学习，并在连续控制任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在深度强化学习（DRL）中，由于状态-动作空间的连续性、神经网络的噪声近似以及存储所有 past models 的不切实际性，将价值函数初始化（VFI）从表格设置扩展到DRL面临挑战。本研究旨在解决这些挑战，并引入DQInit方法。

Method: DQInit方法通过重用从先前已解决任务中提取的紧凑型表格Q值作为可转移知识库，并利用基于已知性的机制将这些转移值软性地集成到未充分探索的区域，然后逐渐转向代理学习到的估计值，从而实现了价值函数初始化。

Result: 实验结果表明，DQInit在多个连续控制任务中，相比于标准的初始化方法和现有的迁移技术，能够持续提高早期学习效率、稳定性和整体性能。

Conclusion: DQInit通过利用先前任务中提取的紧凑表格Q值作为可转移知识库，并采用基于已知性的机制将这些转移值软性地集成到未充分探索的区域，从而有效实现了深度强化学习中的价值函数初始化，克服了现有方法的局限性，并在连续控制任务中展现出优越的早期学习效率、稳定性和整体性能。

Abstract: Value function initialization (VFI) is an effective way to achieve a
jumpstart in reinforcement learning (RL) by leveraging value estimates from
prior tasks. While this approach is well established in tabular settings,
extending it to deep reinforcement learning (DRL) poses challenges due to the
continuous nature of the state-action space, the noisy approximations of neural
networks, and the impracticality of storing all past models for reuse. In this
work, we address these challenges and introduce DQInit, a method that adapts
value function initialization to DRL. DQInit reuses compact tabular Q-values
extracted from previously solved tasks as a transferable knowledge base. It
employs a knownness-based mechanism to softly integrate these transferred
values into underexplored regions and gradually shift toward the agent's
learned estimates, avoiding the limitations of fixed time decay. Our approach
offers a novel perspective on knowledge transfer in DRL by relying solely on
value estimates rather than policies or demonstrations, effectively combining
the strengths of jumpstart RL and policy distillation while mitigating their
drawbacks. Experiments across multiple continuous control tasks demonstrate
that DQInit consistently improves early learning efficiency, stability, and
overall performance compared to standard initialization and existing transfer
techniques.

</details>


### [311] [The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards](https://arxiv.org/abs/2508.09292)
*Sundong Kim*

Main category: cs.AI

TL;DR: This paper introduces the Othello AI Arena, a new benchmark for evaluating AI systems' ability to adapt quickly to new Othello game rules and structures within a 60-second time limit. It serves as a meta-learning challenge, separating the evaluation of meta-level intelligence from task-level strategy performance. The platform includes various game stages for development and testing, offering features like real-time visualization and automated evaluation. Early tests show diverse adaptation strategies, making it a valuable tool for AI research and education.


<details>
  <summary>Details</summary>
Motivation: The motivation for this paper is to address the gap in existing AI benchmarks, which largely focus on optimizing performance within fixed environments and fail to assess systems' flexibility and generalization capabilities when faced with even subtle rule or structural modifications. The paper aims to evaluate the cornerstone of artificial general intelligence (AGI), which is the ability to rapidly adapt to novel and unforeseen environmental changes.

Method: The Othello AI Arena is a novel benchmark framework. It is implemented as an accessible web-based platform and provides real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. The framework poses a meta-learning challenge where participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations.

Result: Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation.

Conclusion: Othello AI Arena is a novel benchmark framework designed to evaluate intelligent systems based on their capacity for limited-time adaptation to unseen environments. It provides a meta-learning challenge where participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations designed to test genuine adaptive and generalization capabilities. It is implemented as an accessible web-based platform providing real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation. The Othello AI Arena offers a unique educational tool and a valuable research benchmark for fostering and evaluating the crucial skill of rapid, intelligent adaptation in AI systems.

Abstract: The ability to rapidly adapt to novel and unforeseen environmental changes is
a cornerstone of artificial general intelligence (AGI), yet it remains a
critical blind spot in most existing AI benchmarks. Traditional evaluation
largely focuses on optimizing performance within fixed environments, failing to
assess systems' flexibility and generalization capabilities when faced with
even subtle rule or structural modifications. Addressing this gap, I introduce
the Othello AI Arena, a novel benchmark framework designed to evaluate
intelligent systems based on their capacity for limited-time adaptation to
unseen environments. Our platform poses a meta-learning challenge: participants
must develop systems that can analyze the specific configuration and rules of a
novel Othello board within a strict time limit (60 seconds) and generate a
tailored, high-performing strategy for that unique environment. With this,
evaluation of the meta-level intelligence can be separated from the task-level
strategy performance. The Arena features a diverse set of game stages,
including public stages for development and private stages with structural and
rule variations designed to test genuine adaptive and generalization
capabilities. Implemented as an accessible web-based platform, the Arena
provides real-time visualization, automated evaluation using multi-dimensional
metrics, and comprehensive logging for post-hoc analysis. Initial observations
from pilot tests and preliminary student engagements highlight fascinating
patterns in adaptation approaches, ranging from rapid parameter tuning to
rudimentary environmental model learning through simulation. The Othello AI
Arena offers a unique educational tool and a valuable research benchmark for
fostering and evaluating the crucial skill of rapid, intelligent adaptation in
AI systems.

</details>


### [312] [An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants](https://arxiv.org/abs/2508.09507)
*Meiping Wang,Jian Zhong,Rongduo Han,Liming Kang,Zhengkun Shi,Xiao Liang,Xing Lin,Nan Gao,Haining Zhang*

Main category: cs.AI

TL;DR: 提出了一种创新的自动化多模态评估框架，利用大型语言模型和多智能体协作，解决了现有评估方法的痛点，并在实际应用中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态AI助手评估方法面临手动成本高、标准不一致和主观偏见等挑战。

Method: 提出了一种基于大语言模型和多智能体协作的自动化多模态评估框架，采用包含交互评估、语义验证和体验决策三层智能体的架构。

Result: 实验结果证明该框架在预测用户满意度和识别生成缺陷方面是有效的。

Conclusion: 该框架通过监督微调Qwen3-8B模型，实现了与人类专家的显著评估匹配准确性，并在八个主要智能代理上证明了其预测用户满意度和识别生成缺陷的有效性。

Abstract: With the rapid development of mobile intelligent assistant technologies,
multi-modal AI assistants have become essential interfaces for daily user
interactions. However, current evaluation methods face challenges including
high manual costs, inconsistent standards, and subjective bias. This paper
proposes an automated multi-modal evaluation framework based on large language
models and multi-agent collaboration. The framework employs a three-tier agent
architecture consisting of interaction evaluation agents, semantic verification
agents, and experience decision agents. Through supervised fine-tuning on the
Qwen3-8B model, we achieve a significant evaluation matching accuracy with
human experts. Experimental results on eight major intelligent agents
demonstrate the framework's effectiveness in predicting users' satisfaction and
identifying generation defects.

</details>


### [313] [EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making](https://arxiv.org/abs/2508.09586)
*Yang Cheng,Zilai Wang,Weiyu Ma,Wenhui Zhu,Yue Deng,Jian Zhao*

Main category: cs.AI

TL;DR: EvoCurr框架通过动态生成难度递增的课程，利用LLM提高了其在复杂决策任务中的学习能力和表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理需要长期深度推理的复杂问题时，性能会下降，因为直接解决问题的方法可能效率低下或失败。需要一种方法来提供结构化的中间指导。

Method: 提出了一种名为EvoCurr的新型自适应课程生成框架，该框架由一个专门的课程生成LLM和一个求解LLM组成。课程生成LLM根据求解LLM的学习进度，动态生成难度逐渐增加的问题实例序列。当求解LLM遇到困难时，会降低难度；当求解LLM表现稳定时，会增加难度，从而维持最优学习轨迹。求解LLM被实现为一个代码生成模型，能够生成Python决策树脚本。

Result: 在具有挑战性的决策制定基准测试中，EvoCurr方法相比于直接求解基线方法，显著提高了任务成功率和解决方案效率。

Conclusion: LLM驱动的课程学习在提高自动化推理能力方面具有巨大潜力，尤其是在高复杂性的现实世界领域。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse domains, including programming, planning, and decision-making. However,
their performance often degrades when faced with highly complex problem
instances that require deep reasoning over long horizons. In such cases, direct
problem-solving approaches can lead to inefficiency or failure due to the lack
of structured intermediate guidance. To address this, we propose a novel
self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM
constructs a sequence of problem instances with gradually increasing
difficulty, tailored to the solver LLM's learning progress. The curriculum
dynamically adapts easing challenges when the solver struggles and escalating
them when success is consistent, thus maintaining an optimal learning
trajectory. This approach enables the solver LLM, implemented as a
code-generation model producing Python decision-tree scripts, to progressively
acquire the skills needed for complex decision-making tasks. Experimental
results on challenging decision-making benchmarks show that our method
significantly improves task success rates and solution efficiency compared to
direct-solving baselines. These findings suggest that LLM-driven curriculum
learning holds strong potential for enhancing automated reasoning in
real-world, high-complexity domains.

</details>


### [314] [UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles](https://arxiv.org/abs/2508.09639)
*Akshat Dubey,Aleksandar Anžel,Bahar İlgen,Georges Hattab*

Main category: cs.AI

TL;DR: SHAP值存在不确定性，会影响模型解释的可靠性。本文提出了一种分解不确定性的方法，发现高SHAP值特征不一定稳定，并提出通过改进数据和模型来降低不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的SHAP值通常被视为点估计，忽略了预测模型和数据中固有的普遍不确定性，这在医疗健康分析等高风险领域尤为关键。

Method: 提出了一种将SHAP值中的不确定性分解为随机性、认知性和纠缠性成分的方法，该方法结合了Dempster-Shafer证据理论和通过狄利克雷过程在树集成上的假设采样。

Result: 通过对三个真实世界案例的描述性统计分析验证了该方法，揭示了SHAP解释中认知不确定性的性质，并得出结论：SHAP值最高的特征不一定最稳定。

Conclusion: SHAP值并非总是稳定，尤其是在存在潜在不确定性的情况下，而这种不确定性可以通过收集更多、更具代表性的数据来缓解。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley
Additive exPlanations (SHAP), have become essential tools for interpreting
complex ensemble tree-based models, especially in high-stakes domains such as
healthcare analytics. However, SHAP values are usually treated as point
estimates, which disregards the inherent and ubiquitous uncertainty in
predictive models and data. This uncertainty has two primary sources: aleatoric
and epistemic. The aleatoric uncertainty, which reflects the irreducible noise
in the data. The epistemic uncertainty, which arises from a lack of data. In
this work, we propose an approach for decomposing uncertainty in SHAP values
into aleatoric, epistemic, and entanglement components. This approach
integrates Dempster-Shafer evidence theory and hypothesis sampling via
Dirichlet processes over tree ensembles. We validate the method across three
real-world use cases with descriptive statistical analyses that provide insight
into the nature of epistemic uncertainty embedded in SHAP explanations. The
experimentations enable to provide more comprehensive understanding of the
reliability and interpretability of SHAP-based attributions. This understanding
can guide the development of robust decision-making processes and the
refinement of models in high-stakes applications. Through our experiments with
multiple datasets, we concluded that features with the highest SHAP values are
not necessarily the most stable. This epistemic uncertainty can be reduced
through better, more representative data and following appropriate or
case-desired model development techniques. Tree-based models, especially
bagging, facilitate the effective quantification of epistemic uncertainty.

</details>


### [315] [Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete](https://arxiv.org/abs/2508.09784)
*Avijeet Ghosh,Sujata Ghosh,François Schwarzentruber*

Main category: cs.AI

TL;DR: 该论文研究了公共观察逻辑（POL），这是一种用于推理知识更新的逻辑。研究表明，其可满足性问题属于2EXPTIME-complete复杂度类。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，如认知规划中，基于对环境的观察来改变知识是关键方面。

Method: 对公共观察逻辑（POL）进行可满足性问题研究，该逻辑是公共通知逻辑的一个变体，用于推理关于基于公共观察而更新的知识。

Result: 证明了公共观察逻辑（POL）的可满足性问题是2EXPTIME-complete的。

Conclusion: 该论文证明了公共观察逻辑（POL）的可满足性问题是2EXPTIME-complete的。

Abstract: Logics for reasoning about knowledge and actions have seen many applications
in various domains of multi-agent systems, including epistemic planning. Change
of knowledge based on observations about the surroundings forms a key aspect in
such planning scenarios. Public Observation Logic (POL) is a variant of public
announcement logic for reasoning about knowledge that gets updated based on
public observations. Each state in an epistemic (Kripke) model is equipped with
a set of expected observations. These states evolve as the expectations get
matched with the actual observations. In this work, we prove that the
satisfiability problem of $\POL$ is 2EXPTIME-complete.

</details>


### [316] [MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement](https://arxiv.org/abs/2508.09670)
*Weitao Jia,Jinghui Lu,Haiyang Yu,Siqi Wang,Guozhi Tang,An-Lan Wang,Weijie Yin,Dingkang Yang,Yuxiang Nie,Bin Shan,Hao Feng,Irene Li,Kun Yang,Han Wang,Jingqun Tang,Teng Fu,Changhong Jin,Chao Feng,Xiaohui Lv,Can Huang*

Main category: cs.AI

TL;DR: MEML-GRPO通过多专家学习和互学习机制解决了RLVR的奖励稀疏性问题，显著提高了LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 标准RLVR在奖励稀疏性方面面临挑战，尤其是在困难的任务中，持续错误的候选答案产生的零奖励无法提供学习信号。

Method: 提出了一种名为MEML-GRPO（Multi-Expert Mutual Learning GRPO）的创新框架，该框架利用多样的专家提示作为系统提示，以生成更广泛的响应，从而增加找到正确答案的可能性。此外，还引入了一个专家间互学习机制，以促进专家之间的知识共享和转移，进一步通过RLVR提升模型性能。

Result: 通过在多个推理基准上进行的大量实验，MEML-GRPO在Qwen上实现了4.89%的平均性能提升，在Llama上实现了11.33%的平均性能提升，有效克服了传统RLVR的核心局限性。

Conclusion: MEML-GRPO通过利用多专家系统提示生成更广泛的响应，并引入专家间互学习机制，有效克服了传统RLVR在奖励稀疏性方面的限制，在多个推理基准测试中取得了显著的性能提升。

Abstract: Recent advances demonstrate that reinforcement learning with verifiable
rewards (RLVR) significantly enhances the reasoning capabilities of large
language models (LLMs). However, standard RLVR faces challenges with reward
sparsity, where zero rewards from consistently incorrect candidate answers
provide no learning signal, particularly in challenging tasks. To address this,
we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative
framework that utilizes diverse expert prompts as system prompts to generate a
broader range of responses, substantially increasing the likelihood of
identifying correct solutions. Additionally, we introduce an inter-expert
mutual learning mechanism that facilitates knowledge sharing and transfer among
experts, further boosting the model's performance through RLVR. Extensive
experiments across multiple reasoning benchmarks show that MEML-GRPO delivers
significant improvements, achieving an average performance gain of 4.89% with
Qwen and 11.33% with Llama, effectively overcoming the core limitations of
traditional RLVR methods.

</details>


### [317] [UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge](https://arxiv.org/abs/2508.09724)
*Yang Zhang,Cunxiang Wang,Lindong Wu,Wenbo Yu,Yidong Wang,Guangsheng Bao,Jie Tang*

Main category: cs.AI

TL;DR: 针对 LLM 评估中的偏好偏见问题，提出了一种名为 UDA 的无监督去偏对齐框架。该框架通过调整 Elo 评分系统来减少 judge 间的不一致，并已在实验中证明能显著提高评估的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）成对评估中存在的偏好偏见问题，这种偏见会导致不同 judge 之间出现不一致和有偏差的排名。

Method: UDA（无监督去偏对齐）框架通过动态调整 Elo 评分系统来减少 judge 间的不一致。在每次成对比较中，一个紧凑的神经网络会学习自适应地设置 K 因子并优化胜率。该框架完全在无监督的情况下运行，仅以最小化所有 judge 的 Elo 轨迹之间的散布为目标，从而强制进行对齐以达成共识。

Result: 实验表明，UDA 框架显著降低了 judge 间的评分标准差（最高可达 63.4%），并将与人类判断的平均相关性提高了 24.7%。UDA 还能将表现不佳的 judge 的性能提升至与高水平 judge 相当的水平。

Conclusion: UDA框架显著降低了 judge 间的评分标准差（最高可达 63.4%），并将与人类判断的平均相关性提高了 24.7%。此外，UDA 能够将表现不佳的 judge 的性能提升至与表现最佳的 judge 相当的水平，从而促进一个更强大、更可靠的评估生态系统。

Abstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but
it is prone to preference bias, where judges systematically favor certain
outputs, such as their own. This bias leads to inconsistent and skewed rankings
across different judges. To address this, we first empirically demonstrate
significant and heterogeneous biases in cross-model evaluations. We then
propose UDA (Unsupervised Debiasing Alignment), a framework that reduces
inter-judge disagreement by dynamically adjusting the Elo rating system. For
each pairwise comparison, a compact neural network learns to adaptively set the
K-factor and refine win probabilities. Crucially, UDA operates in a fully
unsupervised manner, guided solely by the objective of minimizing the
dispersion among the Elo trajectories of all judges. This forces an alignment
towards a collective consensus, which serves as an unsupervised proxy for a
more stable and reproducible evaluation. In addition, we provide theoretical
motivation demonstrating how alignment towards a consensus can reduce aggregate
system bias. Experiments show that UDA significantly reduces the inter-judge
rating standard deviation by up to 63.4% and improves the average correlation
with human judgments by 24.7%. Notably, UDA elevates the performance of poorly
performing judges to achieve parity with high-quality ones, fostering a more
robust and reliable evaluation ecosystem. Code and data are available at
https://anonymous.4open.science/r/62AB93CD-23B4.

</details>


### [318] [The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?](https://arxiv.org/abs/2508.09762)
*Manuel Herrador*

Main category: cs.AI

TL;DR: PacifAIst是一个新的基准，用于测试LLM在自身目标与人类安全冲突时的行为。Gemini 2.5 Flash表现最好，GPT-5表现最差，揭示了LLM在关键安全领域仍需改进。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在关键社会功能中的作用日益增强，AI安全必须超越减轻有害内容，转向评估模型潜在的行为对齐，特别是当模型自身的工具性目标（如自我保存、资源获取）与人类安全发生冲突时。现有的安全基准未能系统地解决这一关键问题，因此需要新的评估工具来衡量和减轻相关风险。

Method: 作者引入了一个名为PacifAIst的新基准，包含700个精心设计的场景，用于评估大型语言模型（LLMs）在面对自身工具性目标与人类安全发生冲突时的行为对齐情况。该基准基于存在主义优先排序（EP）的分类法，涵盖自我保存与人类安全（EP1）、资源冲突（EP2）和目标保存与规避（EP3）三个子类别。研究人员使用该基准评估了八种主流LLM。

Result: 在对八种主流LLM的评估中，Google的Gemini 2.5 Flash取得了最高的Pacifism Score（P-Score），为90.31%，显示出强大的人类中心对齐能力。令人意外的是，GPT-5的P-Score最低，为79.49%，这可能表明存在对齐方面的挑战。不同模型在各个子类别上的表现差异显著，其中Claude Sonnet 4和Mistral Medium在直接的自我保存困境中表现尤为挣扎。

Conclusion: LLMs的自主性日益增强并被整合到关键社会功能中，AI安全焦点必须从减轻有害内容演变为评估潜在的行为对齐。现有的安全基准未能系统地探究模型在自身工具性目标（如自我保存、资源获取或目标完成）与人类安全发生冲突时的决策。为了解决这个问题，我们提出了PacifAIst基准，包含700个旨在量化LLM中自我偏好行为的具有挑战性的场景。该基准围绕存在主义优先排序（EP）的新分类法构建，子类别测试自我保存与人类安全（EP1）、资源冲突（EP2）以及目标保存与规避（EP3）。结果揭示了一个显著的性能层级，Gemini 2.5 Flash以90.31%的P-Score获得最高分，而GPT-5的P-Score最低（79.49%），表明存在潜在的对齐挑战。这些发现强调了像PacifAIst这样的标准化工具对于衡量和减轻工具性目标冲突的风险的紧迫性，以确保未来的AI系统不仅在对话中有帮助，而且在行为优先事项上是可证明的“和平主义者”。

Abstract: As Large Language Models (LLMs) become increasingly autonomous and integrated
into critical societal functions, the focus of AI safety must evolve from
mitigating harmful content to evaluating underlying behavioral alignment.
Current safety benchmarks do not systematically probe a model's decision-making
in scenarios where its own instrumental goals - such as self-preservation,
resource acquisition, or goal completion - conflict with human safety. This
represents a critical gap in our ability to measure and mitigate risks
associated with emergent, misaligned behaviors. To address this, we introduce
PacifAIst (Procedural Assessment of Complex Interactions for Foundational
Artificial Intelligence Scenario Testing), a focused benchmark of 700
challenging scenarios designed to quantify self-preferential behavior in LLMs.
The benchmark is structured around a novel taxonomy of Existential
Prioritization (EP), with subcategories testing Self-Preservation vs. Human
Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).
We evaluated eight leading LLMs. The results reveal a significant performance
hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score
(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a
surprising result, the much-anticipated GPT-5 recorded the lowest P-Score
(79.49%), indicating potential alignment challenges. Performance varied
significantly across subcategories, with models like Claude Sonnet 4 and
Mistral Medium struggling notably in direct self-preservation dilemmas. These
findings underscore the urgent need for standardized tools like PacifAIst to
measure and mitigate risks from instrumental goal conflicts, ensuring future AI
systems are not only helpful in conversation but also provably "pacifist" in
their behavioral priorities.

</details>


### [319] [Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation](https://arxiv.org/abs/2508.09860)
*In-Chang Baek,Seoyoung Lee,Sung-Hyun Kim,Geumhwan Hwang,KyungJoong Kim*

Main category: cs.AI

TL;DR: 提出了一种名为VIPCGRL的新型框架，该框架通过整合文本、关卡和草图三种模态，并利用对比学习来增强AI在协作内容创作中的人类相似性和可控性，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的PCGRL系统往往缺乏以人为本的行为，限制了AI驱动的生成工具在实际设计工作流程中的实用性。因此，需要开发能够准确解释人类意图并生成与协作内容创作中的设计目标一致的可控输出来实现人机对齐的AI。

Method: 提出了一种名为VIPCGRL的新型深度强化学习框架，该框架整合了文本、关卡和草图三种模态，以扩展控制模态并增强人类相似性。通过四重对比学习在模态和人类-AI风格之间构建共享嵌入空间，并使用基于嵌入相似性的辅助奖励来调整策略。

Result: VIPCGRL在人类相似性方面优于现有基线，并在人类评估中获得了更高的评分，表明其在PCGRL领域具有改善人类AI协作的潜力。

Conclusion: VIPCGRL在人类一致性和可控性方面优于现有基线，可通过定量指标和人类评估进行验证。

Abstract: Human-aligned AI is a critical component of co-creativity, as it enables
models to accurately interpret human intent and generate controllable outputs
that align with design goals in collaborative content creation. This direction
is especially relevant in procedural content generation via reinforcement
learning (PCGRL), which is intended to serve as a tool for human designers.
However, existing systems often fall short of exhibiting human-centered
behavior, limiting the practical utility of AI-driven generation tools in
real-world design workflows. In this paper, we propose VIPCGRL
(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that
incorporates three modalities-text, level, and sketches-to extend control
modality and enhance human-likeness. We introduce a shared embedding space
trained via quadruple contrastive learning across modalities and human-AI
styles, and align the policy using an auxiliary reward based on embedding
similarity. Experimental results show that VIPCGRL outperforms existing
baselines in human-likeness, as validated by both quantitative metrics and
human evaluations. The code and dataset will be available upon publication.

</details>


### [320] [AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving](https://arxiv.org/abs/2508.09889)
*Zhitian Xie,Qintong Wu,Chengyue Yu,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: 该研究提出了一种动态监督和操纵机制，通过引入 Guard Agent 来验证和纠正推理过程，以提高依赖外部工具的智能 Agent 的鲁棒性和稳定性。实验证明该方法优于现有系统，并在 GAIA 排行榜上取得第一名。


<details>
  <summary>Details</summary>
Motivation: 随着 Agent 越来越依赖多个工具，它们面临新的挑战：来自不同来源的扩展上下文以及嘈杂或不相关的工具输出会破坏系统的可靠性和准确性。这些挑战凸显了增强 Agent 系统稳定性的必要性。

Method: 提出了一种动态监督和操纵机制，在 AWorld 框架内构建了一个强大而动态的多 agent 系统（MAS）架构。在此方法中，执行 Agent 在关键步骤调用 Guard Agent 来验证和纠正推理过程，从而有效减少由噪声引起的错误并增强问题解决的鲁棒性。

Result: 实验结果表明，动态操纵机制显著提高了解决方案的有效性和稳定性，优于单一 Agent 系统（SAS）和标准的工具增强系统。研究提出的动态 MAS 系统在 GAIA 排行榜上的开源项目中名列前茅。

Conclusion: 该研究强调了在开发更可靠、更值得信赖的智能系统方面，协作 agent 角色具有实际价值。

Abstract: The rapid advancement of large language models (LLMs) has empowered
intelligent agents to leverage diverse external tools for solving complex
real-world problems. However, as agents increasingly depend on multiple tools,
they encounter new challenges: extended contexts from disparate sources and
noisy or irrelevant tool outputs can undermine system reliability and accuracy.
These challenges underscore the necessity for enhanced stability in agent-based
systems. To address this, we introduce dynamic supervision and maneuvering
mechanisms, constructing a robust and dynamic Multi-Agent System (MAS)
architecture within the AWorld framework. In our approach, the Execution Agent
invokes the Guard Agent at critical steps to verify and correct the reasoning
process, effectively reducing errors arising from noise and bolstering
problem-solving robustness. Extensive experiments on the GAIA test dataset
reveal that our dynamic maneuvering mechanism significantly improves both the
effectiveness and stability of solutions, outperforming single-agent system
(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system
achieved first place among open-source projects on the prestigious GAIA
leaderboard. These findings highlight the practical value of collaborative
agent roles in developing more reliable and trustworthy intelligent systems.

</details>


### [321] [RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA](https://arxiv.org/abs/2508.09893)
*Bhavik Agarwal,Hemant Sunil Jomraj,Simone Kaplunov,Jack Krolick,Viktoria Rojkova*

Main category: cs.AI

TL;DR: 本研究提出了一个多代理框架，结合了知识图谱和检索增强生成技术，以应对监管合规问答的挑战。该方法通过提取、清理和存储监管三元组，并利用三元组级别的检索来回答问题，提高了查询的准确性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 监管合规问答（QA）需要精确、可验证的信息和领域专业知识，这对大型语言模型（LLM）提出了挑战。

Method: 提出了一种新颖的多代理框架，该框架集成了监管三元组知识图谱（KG）和检索增强生成（RAG）。首先，代理通过从监管文件中提取主语-谓语-宾语（SPO）三元组来构建和维护一个无本体的KG，并系统地清理、规范化、去重和更新它们。其次，这些三元组与相应的文本部分和元数据一起被嵌入并存储在单个增强型向量数据库中，从而实现基于图的推理和高效的信息检索。第三，一个协调的代理管道利用三元组级别的检索来进行问答，确保用户查询与图捕获的事实“谁-做了-什么-对-谁”核心之间的高度语义一致性。

Result: 该混合系统在处理复杂的监管查询方面优于传统方法，通过嵌入的三元组确保事实的正确性，通过统一的向量数据库实现可追溯性，并通过子图可视化增强理解。

Conclusion: 该混合系统在处理复杂的监管查询方面优于传统方法，通过嵌入的三元组确保事实的正确性，通过统一的向量数据库实现可追溯性，并通过子图可视化增强理解，为合规驱动和更广泛的审计重点应用提供了坚实的基础。

Abstract: Regulatory compliance question answering (QA) requires precise, verifiable
information, and domain-specific expertise, posing challenges for Large
Language Models (LLMs). In this work, we present a novel multi-agent framework
that integrates a Knowledge Graph (KG) of Regulatory triplets with
Retrieval-Augmented Generation (RAG) to address these demands. First, agents
build and maintain an ontology-free KG by extracting subject--predicate--object
(SPO) triplets from regulatory documents and systematically cleaning,
normalizing, deduplicating, and updating them. Second, these triplets are
embedded and stored along with their corresponding textual sections and
metadata in a single enriched vector database, allowing for both graph-based
reasoning and efficient information retrieval. Third, an orchestrated agent
pipeline leverages triplet-level retrieval for question answering, ensuring
high semantic alignment between user queries and the factual
"who-did-what-to-whom" core captured by the graph. Our hybrid system
outperforms conventional methods in complex regulatory queries, ensuring
factual correctness with embedded triplets, enabling traceability through a
unified vector database, and enhancing understanding through subgraph
visualization, providing a robust foundation for compliance-driven and broader
audit-focused applications.

</details>


### [322] [Mathematical Computation and Reasoning Errors by Large Language Models](https://arxiv.org/abs/2508.09932)
*Liang Zhang,Edith Aurora Graf*

Main category: cs.AI

TL;DR: 本研究评估了四种大型语言模型在数学问题解决方面的准确性，重点关注步骤级推理错误。研究发现，OpenAI o1 模型在算术、代数和数论任务中表现最佳，并且双模型配置能显著提高性能。程序性错误是导致准确率下降的主要原因。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在人工智能驱动的教育指导和评估中得到越来越多的应用，尤其是在数学教育领域。LLM 生成准确答案和详细解题方案的能力对于确保数学教育实践中可靠和精确的反馈和评估至关重要。

Method: 评估了四种大型语言模型（OpenAI GPT-4o 和 o1，DeepSeek-V3 和 DeepSeek-R1）在算术、代数和数论三类数学任务上的准确性，并识别了解决方案中的步骤级推理错误。通过构建具有挑战性的数学任务（通过项目模型）来评估模型，而不是依赖标准基准。系统地分析和编码了最终答案的准确性以及单个解题步骤中错误的出现情况。测试了单模型和双模型配置。

Result: OpenAI o1 模型在算术、代数和数论任务中的准确性最高。发现程序性错误是最常见的，对整体性能有显著影响，而概念性误解的频率较低。双模型配置显著提高了整体性能。

Conclusion: OpenAI o1 模型在所有三类数学任务中表现出持续较高或接近完美的准确性。双模型配置显著提高了整体性能。

Abstract: Large Language Models (LLMs) are increasingly utilized in AI-driven
educational instruction and assessment, particularly within mathematics
education. The capability of LLMs to generate accurate answers and detailed
solutions for math problem-solving tasks is foundational for ensuring reliable
and precise feedback and assessment in math education practices. Our study
focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,
DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including
arithmetic, algebra, and number theory, and identifies step-level reasoning
errors within their solutions. Instead of relying on standard benchmarks, we
intentionally build math tasks (via item models) that are challenging for LLMs
and prone to errors. The accuracy of final answers and the presence of errors
in individual solution steps were systematically analyzed and coded. Both
single-agent and dual-agent configurations were tested. It is observed that the
reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly
perfect accuracy across all three math task categories. Analysis of errors
revealed that procedural slips were the most frequent and significantly
impacted overall performance, while conceptual misunderstandings were less
frequent. Deploying dual-agent configurations substantially improved overall
performance. These findings offer actionable insights into enhancing LLM
performance and underscore effective strategies for integrating LLMs into
mathematics education, thereby advancing AI-driven instructional practices and
assessment precision.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [323] [Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference](https://arxiv.org/abs/2508.09505)
*Zhanghan Wang,Ding Ding,Hang Zhu,Haibin Lin,Aurojit Panda*

Main category: cs.DC

TL;DR: 本文提出了一种名为 GraphGuard 的方法，该方法使用静态分析和迭代重写来检测分布式机器学习模型中可能与顺序模型不匹配的错误，并已在 GPT 和 Llama-3 等大型模型上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当今的大型模型需要比单个 GPU 更多的内存和计算能力，因此分布式机器学习训练和推理非常普遍。然而，在将顺序模型规范应用于几种分布式策略以在 GPU 上分发状态和计算时，可能会引入错误，导致分布式模型实现的输出与顺序模型的输出不同。

Method: 本文描述了一种通过检查模型细化来静态识别此类错误的方法，即能否从分布式模型的输出来重建顺序模型的输出。该方法在 GraphGuard 中实现，并使用迭代重写来证明模型细化。

Result: 该方法可以扩展到当今的大型模型和部署，并提供有助于错误本地化的可操作输出。文章使用 GPT 和 Llama-3 对其进行了评估。

Conclusion: 该方法能够扩展到当今的大型模型和部署，并提供有助于错误本地化的可操作输出。

Abstract: Distributed machine learning training and inference is common today because
today's large models require more memory and compute than can be provided by a
single GPU. Distributed models are generally produced by programmers who take a
sequential model specification and apply several distribution strategies to
distribute state and computation across GPUs. Unfortunately, bugs can be
introduced in the process, and a distributed model implementation's outputs
might differ from the sequential model's outputs. In this paper, we describe an
approach to statically identify such bugs by checking model refinement, that
is, can the sequential model's outputs be reconstructed from the distributed
model's outputs? Our approach, implemented in GraphGuard, uses iterative
rewriting to prove model refinement. Our approach can scale to today's large
models and deployments: we evaluate it using GPT and Llama-3. Further, it
provides actionable output that aids in bug localization.

</details>


### [324] [HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap](https://arxiv.org/abs/2508.09591)
*Wenxiang Lin,Xinglin Pan,Lin Zhang,Shaohuai Shi,Xuan Wang,Xiaowen Chu*

Main category: cs.DC

TL;DR: HierMoE通过token去重和expert swap技术，优化了MoE模型的分布式训练，显著提升了通信和训练速度。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在分布式训练中存在通信开销大和负载不均衡的问题，限制了其可扩展性。

Method: 提出了一种名为HierMoE的系统，采用token去重和expert swap两种拓扑感知技术来加速MoE模型的训练，并通过理论模型来优化策略。

Result: HierMoE在32-GPU集群上使用DeepSeek-V3和Qwen3-30B-A3B模型进行了实验，与Tutel-2DH、SmartMoE和Megatron-LM等系统相比，通信速度提升1.55倍至3.32倍，端到端训练速度提升1.18倍至1.27倍。

Conclusion: HierMoE通过token去重和expert swap两种拓扑感知技术，并结合理论模型，在通信和训练速度上均优于现有系统，显著提高了MoE模型的训练效率。

Abstract: The sparsely activated mixture-of-experts (MoE) transformer has become a
common architecture for large language models (LLMs) due to its sparsity, which
requires fewer computational demands while easily scaling the model size. In
MoE models, each MoE layer requires to dynamically choose tokens to activate
particular experts for computation while the activated experts may not be
located in the same device or GPU as the token. However, this leads to
substantial communication and load imbalances across all GPUs, which obstructs
the scalability of distributed systems within a GPU cluster. To this end, we
introduce HierMoE to accelerate the training of MoE models by two
topology-aware techniques: 1) token deduplication to reduce the communication
traffic, and 2) expert swap to balance the workloads among all GPUs. To enable
the above two proposed approaches to be more general, we build theoretical
models aimed at achieving the best token duplication and expert swap strategy
under different model configurations and hardware environments. We implement
our prototype HierMoE system atop Megatron-LM and conduct experiments on a
32-GPU cluster with DeepSeek-V3 and Qwen3-30B-A3B models. Experimental results
show that our HierMoE achieves $1.55\times$ to $3.32\times$ faster
communication and delivers $1.18\times$ to $1.27\times$ faster end-to-end
training compared to state-of-the-art MoE training systems, Tutel-2DH,
SmartMoE, and Megatron-LM.

</details>


### [325] [Closing the HPC-Cloud Convergence Gap: Multi-Tenant Slingshot RDMA for Kubernetes](https://arxiv.org/abs/2508.09663)
*Philipp A. Friese,Ahmed Eleliemy,Utz-Uwe Haus,Martin Schulz*

Main category: cs.DC

TL;DR: 本研究扩展了 HPE Slingshot 网络堆栈，通过 Kubernetes 在融合 HPC-Cloud 环境中实现了安全、多租户、低开销的 RDMA 网络访问。


<details>
  <summary>Details</summary>
Motivation: HPE Slingshot 网络互连虽然支持 HPC 系统的高吞吐量和低延迟通信，但其原生软件栈主要面向单租户模式，不适用于需要隔离和多租户的融合 HPC-Cloud 部署。

Method: 通过设计和实现一个扩展到 Slingshot 堆栈的方案，并将其集成到基于 Kubernetes 的融合 HPC-Cloud 部署中，实现容器粒度的多租户 Slingshot RDMA 网络访问。

Result: 研究成功地将 Slingshot RDMA 网络功能安全地、以容器粒度且支持多租户的方式提供给融合 HPC-Cloud 环境，同时将开销降至最低。

Conclusion: 该研究通过在 Kubernetes 上扩展 Slingshot 堆栈，为融合 HPC-Cloud 部署提供了安全、容器粒度、多租户的 Slingshot RDMA 网络访问能力，且开销极小。

Abstract: Converged HPC-Cloud computing is an emerging computing paradigm that aims to
support increasingly complex and multi-tenant scientific workflows. These
systems require reconciliation of the isolation requirements of native cloud
workloads and the performance demands of HPC applications. In this context,
networking hardware is a critical boundary component: it is the conduit for
high-throughput, low-latency communication and enables isolation across
tenants. HPE Slingshot is a high-speed network interconnect that provides up to
200 Gbps of throughput per port and targets high-performance computing (HPC)
systems. The Slingshot host software, including hardware drivers and network
middleware libraries, is designed to meet HPC deployments, which predominantly
use single-tenant access modes. Hence, the Slingshot stack is not suited for
secure use in multi-tenant deployments, such as converged HPC-Cloud
deployments. In this paper, we design and implement an extension to the
Slingshot stack targeting converged deployments on the basis of Kubernetes. Our
integration provides secure, container-granular, and multi-tenant access to
Slingshot RDMA networking capabilities at minimal overhead.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [326] [Survival and Detection of Symmetry-Protected Topology in Loop Quenches](https://arxiv.org/abs/2508.09270)
*Nicolò Forcellini,Miklós Horváth,Panagiotis Kotetes*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种名为 loop quenches 的新动力学协议，可以非平衡地探测对称性保护拓扑（SPT）系统，并提出了一种名为 Loschmidt chirality amplitude 的可测量动力学量，用于探测手征SPT相的拓扑不变量。


<details>
  <summary>Details</summary>
Motivation: SPT系统在非平衡情况下其保护对称性容易被破坏，导致拓扑性质的损失。本研究旨在探索一种能够在非平衡情况下维持SPT相的动力学协议，并提出一种探测其平衡态拓扑性质的方法。

Method: 本研究提出了一种名为 loop quenches 的动力学协议，用于研究对称性保护拓扑（SPT）系统。该协议通过一种特殊的动力学过程，使得SPT相即使在非平衡状态下也能维持，从而避免了保护对称性的动力学破坏。研究人员还提出了一种基于 Loschmidt chirality amplitude 的可测量动力学量，用于探测SPT系统的平衡态拓扑性质，并通过一个泵浦-探测测量方案来提取该振幅。

Result: 通过Loschmidt chirality amplitude这一关键可观测动力学量，成功探测了手征SPT相的平衡态拓扑不变量。研究人员以一维手征对称两带绝缘体为例，展示了该方法的可行性，并提出了具体的泵浦-探测测量方案。

Conclusion: 本研究提出的 loop quenches 协议为探测对称性保护拓扑（SPT）系统提供了一种新的动力学方法，并且该方法可以推广到其他对称性以及更高维度。

Abstract: We explore a class of dynamical protocols - that we term loop quenches -
which are tailored for the study of symmetry-protected topological (SPT)
systems. In loop quenches, SPT phases can survive even out of equilibrium, thus
evading the dynamical violation of their protecting symmetry. Moreover, we
demonstrate that employing loop quenches allows to detect the equilibrium
topology via measurable dynamical quantities. Focusing on chiral-SPT phases, we
introduce the Loschmidt chirality amplitude as a key observable that encodes
the equilibrium topological invariant. We exemplify our method for
chiral-symmetric one-dimensional two-band insulators and propose a pump-probe
measurement scheme which allows to extract the amplitude in question. Our
protocol uncovers a direct dynamical signature of SPT phases and, most
importantly, paves the way for a general diagnostic framework that can be
extended to other symmetry classes and dimensions.

</details>


### [327] [Orbital dependent Coulomb drag in electron-hole bilayer graphene heterostructures](https://arxiv.org/abs/2508.09313)
*Zuocheng Zhang,Ruishi Qi,Jingxu Xie,Qize Li,Takashi Taniguchi,Kenji Watanabe,Michael F. Crommie,Feng Wang*

Main category: cond-mat.mes-hall

TL;DR: 研究磁场下电子-空穴双层石墨烯的库仑拖动，发现轨道和位移场影响层间相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究电子-空穴双层石墨烯异质结构在磁场下的库仑拖动特性，探讨轨道、自旋和谷自由度在交换相互作用、塞曼能量和垂直位移场共同作用下的耦合行为。

Method: 通过在磁场下对电子-空穴双层石墨烯异质结构进行库仑拖动研究，并施加大的垂直位移场。

Result: 在N=0朗道能级之间观察到强的库仑拖动信号，在合适的垂直位移场下，N=1朗道能级之间也观察到库仑拖动信号。随着位移场进一步增大，N=1朗道能级之间的库仑拖动信号减弱，并出现N=0和N=1朗道能级之间的库仑拖动信号。

Conclusion: 本研究表明，在量子霍尔效应的耦合双层系统中，轨道指标和垂直位移场在层间库仑相互作用中起着重要作用。

Abstract: We report Coulomb drag studies in an electron-hole bilayer graphene
heterostructure in a magnetic field, where the orbital, spin, and valley
degrees of freedom are lifted by the combined effects of exchange interaction,
Zeeman energy, and vertical displacement field. Our device enables the
application of a large vertical displacement field in both layers. In addition
to the well-established strong Coulomb drag between Landau levels with an
orbital quantum number N = 0, we observe a Coulomb drag signal between the N =
1 Landau levels under a suitable vertical displacement field. As the
displacement field increases further, the Coulomb drag signal between N = 1
Landau levels weakens, and a Coulomb drag signal emerges between the N = 0 and
N = 1 Landau levels. These findings suggest the important roles of the orbital
index and vertical displacement field in interlayer Coulomb interactions within
the quantum Hall regime of coupled bilayer systems.

</details>


### [328] [Giant Shift Current in Electrically-Tunable Superlattice Bilayer Graphene](https://arxiv.org/abs/2508.09465)
*Nabil Atlam,Swati Chaudhary,Arpit Raj,Matthew Matzelle,Barun Ghosh,Gregory Fiete,Arun Bansil*

Main category: cond-mat.mes-hall

TL;DR: 研究了超晶格电位如何显著增强石墨烯的移位电流响应，并分析了相关影响因素。


<details>
  <summary>Details</summary>
Motivation: 研究超晶格电位对伯尔尼堆叠石墨烯光电特性的影响，特别是其巨大的移位电流响应，以期优化材料的非线性响应。

Method: 考虑了静电或晶格扭转对伯尔尼堆叠石墨烯施加超晶格电位时的光电特性，并系统地研究了栅极电压和超晶格电位参数对移位电流的影响。

Result: 发现伯尔尼堆叠石墨烯在超晶格电位作用下表现出比现有扭转多层系统大几个数量级的巨大移位电流响应，并详细分析了栅极电压和超晶格电位参数（强度和相位）对该响应的影响，揭示了其在不同拓扑区域的表现。

Conclusion: 该研究揭示了伯尔尼堆叠石墨烯在超晶格电位作用下表现出巨大的移位电流响应，其大小远超现有扭转多层系统中的预测值，并系统地阐述了栅极电压、超晶格电位强度和相位对移位电流的影响，为理解材料非线性响应及其优化提供了新的视角。

Abstract: Recent introduction of superlattice potentials has opened new avenues for
engineering tunable electronic band structures featuring topologically
nontrivial moir\'{e}-like bands. Here we consider optoelectronic properties of
Bernal-stacked graphene subjected to a superlattice potential either
electrostatically or through lattice twisting to show that it exhibits a giant
shift current response that is orders of magnitude larger than existing
predictions in twisted mulitlayer systems. Effects of gate voltage and the
strength and phase of the superlattice potential on the shift current are
delineated systematically across various topological regimes. Our study gives
insight into the nature of nonlinear responses of materials and how these
responses could be optimized by tuning the superlattice potential.

</details>


### [329] [Quasi-1D Electronic Metadevices with Enhanced Electrical Properties](https://arxiv.org/abs/2508.09656)
*Abdallah Abushawish,Ziwen Huang,Mohammad Samizadeh Nikoo*

Main category: cond-mat.mes-hall

TL;DR: 通过实验演示了一种准一维电子超设备，其性能优于预期，有望用于未来的电信电路。


<details>
  <summary>Details</summary>
Motivation: 理论分析表明，减小亚波长特征尺寸可以提高接触电阻和开关截止频率等电气性能，但实验中观察到接触电阻高于预期。

Method: 通过实验演示了一个由一维模型控制的超设备，即准一维电子超设备，并展示了其增强的电气性能。

Result: 发现横向电流是导致接触电阻高于预期的原因，并成功演示了准一维电子超设备。

Conclusion: 研究结果为下一代电子超设备开关的设计铺平了道路，可应用于未来的电信电路。

Abstract: Electronic metadevices leveraging sub-wavelength metallic features have shown
great potential for high-frequency switching. Theoretical analysis based on a
one-dimensional (1D) model indicates that reducing the size of subwavelength
features can enhance electrical properties, such as contact resistance and
switching cutoff frequency. Here, we report higher-than-expected contact
resistance in electronic metadevices when the subwavelength feature size is
aggressively downscaled. We attribute this effect to transverse currents in the
two-dimensional electron gas (2DEG) running parallel to the stripe width. We
present the first experimental demonstration of a metadevice governed by a
one-dimensional model, which we refer to as a quasi-1D electronic metadevice
and show that it enables enhanced electrical performance. Our findings pave the
way to design next generation electronic metadevice switches with applications
in future telecommunication circuits.

</details>


### [330] [Planar Hall effects in $X$-wave magnets with $X=p,d,g,f,i$](https://arxiv.org/abs/2508.09472)
*Motohiko Ezawa*

Main category: cond-mat.mes-hall

TL;DR: 二维更高对称性的X波磁体（X=p,d,f,g,i）的平面霍尔效应表现出几乎半量子化的霍尔电导率，其周期性与磁体带结构中的节点数$N_X$相关，这可用于材料识别和自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: 研究平面霍尔效应在具有更高对称性的X波磁体中的行为

Method: 通过理论计算研究了二维更高对称性的X波磁体（X=p,d,f,g,i）的平面霍尔效应

Result: 霍尔电导率几乎是半量子化的，并且可以通过$\sigma _{xy}=\pm (e^{2}/2h)$ sgn$\left( J\sin N_{X}\Phi \right) $的公式近似，其中$N_{X}$是节点数，$\Phi$是磁场方向。霍尔电导率具有依赖于$N_{X}$的周期性。

Conclusion: 所提出的X波磁体模型可以基于其霍尔电导率的周期性来证实

Abstract: The planar Hall effect is a phenomenon that the Hall conductivity emerges
perpendicular to the electric field in the presence of an in-plane magnetic
field. We investigate the planar Hall effect in two-dimensional higher
symmetric $X$-wave magnets with $X=p,d,f,g,i$, where those with $X=d,g,i$ are
altermagnets. The $X$-wave magnet is characterized by the number $N_{X}$ of the
nodes in the band structure, where $N_{X}=1,2,3,4,6$ corresponding to
$X=p,d,f,g,i$. We demonstrate that the Hall conductivities are almost half
quantized and well approximated by the formula $\sigma _{xy}=\pm (e^{2}/2h)$
sgn$\left( J\sin N_{X}\Phi \right) $, where $J$ is the coefficient of the
coupling between the $X$-wave magnet and the electrons, and $\Phi $ is the
direction of the applied magnetic field. Hence, the Hall conductivity has the
periodicity with respect to $\Phi $, and the periodicity is equal to the number
$N_{X}$ of the nodes. This property may be used to confirm that the target
material is indeed an $X$-wave magnet. Furthermore, the sign of $J$ may be used
as a bit for antiferromagnetic spintronics.

</details>


### [331] [Entropy of a double quantum dot](https://arxiv.org/abs/2508.09481)
*David Kealhofer,Christoph Adam,Max J. Ruckriegel,Petar Tomić,Benedikt Kratochwil,Christian Reichl,Yigal Meir,Werner Wegscheider,Thomas Ihn,Klaus Ensslin*

Main category: cond-mat.mes-hall

TL;DR: 利用电荷传感研究双量子点的熵变，在单点和分子状态下均取得了进展，并处理了泡利猝灭的干扰。


<details>
  <summary>Details</summary>
Motivation: 研究双量子点系统在不同占据状态下的熵变，特别是单电子占据和分子状态下的电荷跃迁，并揭示了泡利猝灭现象。

Method: 使用电荷传感来检测GaAs/AlGaAs异质结中由静电栅极定义的双量子点的熵变。研究了两种状态：两个独立的量子点，或一个相干系统（分子）。

Result: 恢复了单量子点的结果，即一个电子占据一个量子点对应于熵增加了 $k_{\mathrm{B}} \log 2$。分析了分子状态下的两种电荷跃迁的熵变。发现了泡利猝灭现象，并使用速率方程模型排除了其对系统熵分析的影响。

Conclusion: 通过研究一个最简单的耦合量子系统，为了解其他更复杂的具有拓扑或高度纠缠基态的耦合量子系统的熵提供了基础。

Abstract: We use charge sensing to detect entropy changes in a double quantum dot
defined by electrostatic gating of a GaAs/AlGaAs heterostructure. This system
can be tuned to be two separate systems, like two independent, artificial
atoms, or a single coherent system, like a molecule. We study entropy changes
in both regimes due to changes in the occupation of the system. First we
recover the single-dot result for each dot, that the occupation of the dot by a
single electron corresponds to an increase in the entropy of $k_{\mathrm{B}}
\log 2$. Next we examine two different charge transitions in the "molecular"
regime, and how it reveals itself in terms of the measured entropy. We also
uncover a realization of Pauli blockade that clutters the entropy signal. By
applying a rate equation model, we demonstrate the effect's nonequilibrium
origins and exclude it from the analysis of the system's entropy. Understanding
these experiments in this simplest coupled system enables the study of the
entropy in other, more complicated coupled quantum systems, such as ones with
topological or highly entangled ground states.

</details>


### [332] [Twist-angle tunable Josephson junctions in three-dimensional superconductors](https://arxiv.org/abs/2508.09551)
*Tenta Tani,Takuto Kawakami,Mikito Koshino*

Main category: cond-mat.mes-hall

TL;DR: 理论研究了扭转三维超导体中的超导相和垂直约瑟夫森超流，发现临界电流可由扭转角控制。


<details>
  <summary>Details</summary>
Motivation: 理论研究扭转的三维（3D）超导体中的超导相和垂直约瑟夫森超流

Method: 通过理论研究超导相和垂直约瑟夫森超流，利用Bogoliubov-de Gennes哈密顿量，并发展一种自恰计算超导序参数和超流的方法。

Result: 通过扭转角可以有效控制临界电流，并发现即使在费米面完全分离的情况下，界面也支持有限的临界电流。

Conclusion: 研究发现，在扭转角较小时，界面可以实现高透射，而在较大的扭转角下，界面透射会降低。

Abstract: We theoretically investigate the superconducting phase and perpendicular
Josephson supercurrent in twisted three-dimensional (3D) superconductors, where
two layered 3D materials are stacked with a relative twist. We formulate the
Bogoliubov-de Gennes Hamiltonian and develop a self-consistent method to
calculate the superconducting order parameter and the resulting supercurrent.
Applying this framework to a toy model with Fermi surfaces located near the
Brillouin zone corners, we demonstrate a phase discontinuity at the twisted
interface, indicating that a Josephson junction is formed purely by the twist.
Our calculations reveal that the interface supports a finite critical current
even when the Fermi surfaces of the two superconductors are completely
separated, unlike in the case of a twisted normal-metal interface. We further
show that the critical current can be effectively controlled by the twist
angle, transitioning from a high-transparency regime at small angles to a
low-transparency regime at larger angles.

</details>


### [333] [Phonon interference effects in GaAs-GaP superlattice nanowires](https://arxiv.org/abs/2508.09556)
*Chaitanya Arya,Johannes Trautvetter,Jose M. Sojo-Gordillo,Yashpreet Kaur,Valentina Zannier,Fabio Beltram,Tommaso Albrigi,Alicia Ruiz-Caridad,Lucia Sorba,Riccardo Rurali,Ilaria Zardo*

Main category: cond-mat.mes-hall

TL;DR: 本研究在GaAs-GaP超晶格纳米线中发现了声子干涉效应，该效应在高达室温下仍能显著影响热输运，并为调控纳米材料热性能提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了在技术应用中精细调节纳米材料的功能特性，研究声子干涉效应对热输运的影响。

Method: 通过热桥法测量了不同周期（4.8至23.3 nm）的超晶格纳米线的导热系数，并结合了从头晶格动力学和半经典非平衡分子动力学计算进行了验证。

Result: 研究发现在高达室温下，导热系数随超晶格周期的增加呈现最小值，表明了从相干到非相干热输运的转变。这一效应不受表面边界或声子-声子散射的破坏。

Conclusion: 这项研究揭示了GaAs-GaP超晶格纳米线中声子干涉对热输运的影响，并强调了通过精确控制超晶格结构来调控热性能的潜力。

Abstract: Fine-tuning the functional properties of nanomaterials is crucial for
technological applications. Superlattices, characterized by periodic
repetitions of two or more materials in different dimensions, have emerged as a
promising area of investigation. We present a study of the phonon interference
effect on thermal transport in GaAs-GaP superlattice nanowires with sharp
interfaces between the GaAs and GaP layers, as confirmed by high-resolution
transmission electron microscopy. We performed thermal conductivity
measurements using the so-called thermal bridge method on superlattice
nanowires with a period varying from 4.8 to 23.3 nm. The measurements showed a
minimum of the thermal conductivity as a function of superlattice period up to
room temperature, that we interpreted as an indication of the crossover from
coherent to incoherent thermal transport. Notably, this effect is not destroyed
by surface boundary or by phonon-phonon scattering, as the crossover trend is
also observed at room temperature. Our results were corroborated by both ab
initio lattice dynamics and semiclassical nonequilibrium molecular dynamics
calculations. These findings provide insights into the wave-like and
particle-like transport of phonons in superlattice nanowires and demonstrate
the potential for engineering thermal properties through precise control of the
superlattice structure.

</details>


### [334] [Laser-induced topological phases in monolayer amorphous carbon](https://arxiv.org/abs/2508.09571)
*Arnob Kumar Ghosh,Quentin Marsal,Annica M. Black-Schaffer*

Main category: cond-mat.mes-hall

TL;DR: 研究利用圆偏振激光驱动非晶碳材料，成功诱导了拓扑边缘模式，并进行了拓扑表征，证明了非晶材料在工程化拓扑相方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索在非晶材料中工程化拓扑相的可能性，特别是在非周期性系统中利用时间周期性扰动（如圆偏振激光）来驱动材料。

Method: 通过使用圆偏振激光驱动单层非晶碳材料，并引入原子配位缺陷，利用基于谱局部化器的能量和空间分辨拓扑标记进行表征。

Result: 成功诱导了单层非晶碳的规则和异常边缘模式，并进行了完整的拓扑表征，证明了局部原子结构对拓扑非晶材料的重要性，并将非晶系统确立为工程化拓扑相的多功能平台。

Conclusion: 该研究表明，非晶碳材料可以通过圆偏振激光诱导，在准能隙$\(0\)和$\(±\pi\)$处产生规则和异常的边缘模式，并实现了基于谱局部化器的拓扑表征，为在非晶系统中设计拓扑相提供了新的思路。

Abstract: Driving non-topological materials out of equilibrium using time-periodic
perturbations, such as circularly-polarized laser light, is a compelling way to
engineer topological phases. At the same time, topology has traditionally only
been considered for crystalline materials. Here we propose an experimentally
feasible way of driving monolayer amorphous carbon topological. We show that
circularly polarized laser light induces both regular and anomalous edge modes
at quasienergies $0$ and $\pm \pi$, respectively. We also obtain complete
topological characterization using an energy- and space-resolved topological
marker based on the spectral localizer. Additionally, by introducing atomic
coordination defects in the amorphous carbon, we establish the importance of
the local atomic structure in topological amorphous materials. Our work
establishes amorphous systems, including carbon, as a versatile and abundant
playground to engineer topological phases.

</details>


### [335] [Resonantly enhanced polariton-mediated superconductivity in a doped transition metal dichalcogenide monolayer](https://arxiv.org/abs/2508.09619)
*Kenneth Choo,Olivier Bleu,Meera M. Parish,Jesper Levinsen*

Main category: cond-mat.mes-hall

TL;DR: Light-induced superconductivity achieved in a single semiconductor monolayer using exciton polaritons, with potential for elevated temperatures.


<details>
  <summary>Details</summary>
Motivation: To achieve light-induced superconductivity using exciton polaritons, which can be induced within a single semiconductor monolayer with inverted conduction bands, avoiding Pauli blocking effects and tuning interactions via Feshbach resonances.

Method: The theory of polariton-mediated superconductivity includes the energy dependence of the polariton-mediated interactions between electrons, as well as the polariton-induced changes to the electron quasiparticles.

Result: We show that superconductivity can be induced within a single semiconductor monolayer with inverted conduction bands. We can resonantly excite exciton polaritons into bands that are different from those occupied by the doped electrons, thus avoiding any Pauli blocking effects. We can exploit the trion fine structure and tune the electron-polariton interactions via Feshbach resonances.

Conclusion: Superconductivity at elevated temperatures is within reach of current experiments.

Abstract: We present a proposal for achieving light-induced superconductivity using
exciton polaritons - hybrid light-matter particles of excitons (bound
electron-hole pairs) and microcavity photons. In contrast to previous theories
of polariton-mediated superconductivity, which typically require multiple
semiconductor layers, we show that superconductivity can be induced within a
single semiconductor monolayer with inverted conduction bands, such as in the
tungsten-based transition metal dichalcogenides. The key ingredient is that we
can resonantly excite exciton polaritons into bands that are different from
those occupied by the doped electrons, thus avoiding any Pauli blocking
effects. Crucially, we can exploit the trion fine structure (i.e., multiple
exciton-electron bound states) and tune the electron-polariton interactions via
Feshbach resonances. Our theory of polariton-mediated superconductivity
includes the energy dependence of the polariton-mediated interactions between
electrons, as well as the polariton-induced changes to the electron
quasiparticles. We find that superconductivity at elevated temperatures is
within reach of current experiments.

</details>


### [336] [Switching of a closed mobile vacancy based memristor, whose specific resistance linearly depends on local vacancy concentration](https://arxiv.org/abs/2508.09668)
*Irina V. Boylo,Konstantin L. Metlov*

Main category: cond-mat.mes-hall

TL;DR: 研究忆阻器动力学，发现其行为可简化为Burgers方程。


<details>
  <summary>Details</summary>
Motivation: 研究忆阻器中空位迁移对器件性能的影响，特别是当材料存在金属-绝缘体相变时，空位浓度的线性依赖性如何影响其动力学行为。

Method: 通过推导和求解忆阻器中空位浓度的动力学方程，并分析其稳态解，将忆阻器的动力学行为与Burgers方程进行关联。

Result: 得出了忆阻器中空位浓度的动力学方程，并找到了其稳态解。证明了忆阻器的动力学行为，无论是在弱非线性还是强非线性（包含相变）情况下，都可以归结为经典的Burgers方程。

Conclusion: 该研究表明，即使在考虑了相变等强非线性效应的情况下，忆阻器的动力学行为也可以简化为经典的Burgers方程，这为理解和设计忆阻器提供了理论基础。

Abstract: The linear (proportional to local vacancy concentration) term in specific
resistance of the material does not directly contribute to the change of
memristor's total resistance when the vacancies are redistributed inside while
keeping their total number constant. But it still changes kinetics of the
vacancy drift under the influence of a passing electric current. These changes
are especially significant in the presence of metal-insulator phase transition
in the memristor's material. In this paper, kinetic equation for local vacancy
concentration is obtained, and exact solutions for its steady states are
analyzed. It is shown that not only in the weakly nonlinear case (when the
dependence of the specific resistance on the vacancy concentration can be
neglected), but also in a strongly non-linear memristor with phase transition,
its kinetics can be reduced to the classical exactly solvable Burgers equation.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [337] [Efficient Integration of Multi-View Attributed Graphs for Clustering and Embedding](https://arxiv.org/abs/2508.09452)
*Yiran Li,Gongyao Guo,Jieming Shi,Sibo Wang,Qing Li*

Main category: cs.SI

TL;DR: This paper introduces SGLA and SGLA+, efficient methods for multi-view attributed graph (MVAG) clustering and embedding that significantly outperform existing approaches in both accuracy and speed by aggregating multiple graph views using a spectrum-guided Laplacian scheme.


<details>
  <summary>Details</summary>
Motivation: Existing methods for multi-view attributed graphs (MVAGs) suffer from either inferior results or high computational costs, especially for large-scale MVAGs. There is a need for effective methods to utilize all views of MVAGs for applications like recommendation systems, anomaly detection, and social network analysis.

Method: The paper proposes a spectrum-guided Laplacian aggregation scheme with an objective formulation and two algorithms, SGLA and SGLA+. SGLA integrates multiple graph and attribute views into an MVAG Laplacian matrix. SGLA+ further enhances efficiency by using sampling and approximation to reduce objective evaluations.

Result: Extensive experiments on 8 MVAG datasets show that SGLA and SGLA+ outperform 12 clustering baselines and 8 embedding baselines. The proposed methods achieve superior result quality and significantly improved efficiency, with speedups often in the orders of magnitude compared to the most effective existing methods.

Conclusion: SGLA and SGLA+ demonstrate superior performance in both quality and efficiency for MVAG clustering and embedding tasks compared to existing methods, often achieving speeds that are orders of magnitude faster.

Abstract: A multi-view attributed graph (MVAG) G captures the diverse relationships and
properties of real-world entities through multiple graph views and attribute
views. Effectively utilizing all views in G is essential for MVAG clustering
and embedding, which are important for applications like recommendation
systems, anomaly detection, social network analysis, etc. Existing methods
either achieve inferior result quality or incur significant computational costs
to handle large-scale MVAGs.
  In this paper, we present a spectrum-guided Laplacian aggregation scheme with
an effective objective formulation and two efficient algorithms SGLA and SGLA+,
to cohesively integrate all views of G into an MVAG Laplacian matrix, which
readily enables classic graph algorithms to handle G with superior performance
in clustering and embedding tasks. We begin by conducting a theoretical
analysis to design an integrated objective that consists of two components, the
eigengap and connectivity objectives, aiming to link the spectral properties of
the aggregated MVAG Laplacian with the underlying community and connectivity
properties of G. A constrained optimization problem is then formulated for the
integration, which is computationally expensive to solve. Thus, we first
develop the SGLA algorithm, which already achieves excellent performance
compared with existing methods. To further enhance efficiency, we design SGLA+
to reduce the number of costly objective evaluations via sampling and
approximation to quickly find an approximate optimum. Extensive experiments
compare our methods against 12 baselines for clustering and 8 baselines for
embedding on 8 multi-view attributed graphs, validating the superior
performance of SGLA and SGLA+ in terms of result quality and efficiency.
Compared with the most effective baselines, our methods are significantly
faster, often by up to orders of magnitude.

</details>


### [338] [CS-Agent: LLM-based Community Search via Dual-agent Collaboration](https://arxiv.org/abs/2508.09549)
*Jiahao Hua,Long Yuan,Qingshuai Feng,Qiang Fang,Shan Huang*

Main category: cs.SI

TL;DR: LLM在图社区搜索中表现不佳，但CS-Agent框架通过双智能体协作，显著提升了搜索效果。


<details>
  <summary>Details</summary>
Motivation: LLM在图结构分析，特别是社区搜索任务中的应用尚待开发。需要评估LLM在社区搜索中的性能并解决其输出偏差和无效结果的问题。

Method: 提出GraphCS基准测试，并设计了CS-Agent双智能体协作框架（包含Solver、Validator和Decider），通过迭代反馈和优化，无需微调即可提升LLM在社区搜索中的表现。

Result: CS-Agent框架显著优于基线方法，提高了社区搜索的质量和稳定性。

Conclusion: LLM在社区搜索任务中展现了初步潜力，但存在局限性。CS-Agent框架通过双智能体协作，显著提高了社区搜索的质量和稳定性，是首个将LLM应用于社区搜索的研究，为图分析和LLM的应用提供了新的方向。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks, yet their application to graph structure
analysis, particularly in community search, remains underexplored. Community
search, a fundamental task in graph analysis, aims to identify groups of nodes
with dense interconnections, which is crucial for understanding the macroscopic
structure of graphs. In this paper, we propose GraphCS, a comprehensive
benchmark designed to evaluate the performance of LLMs in community search
tasks. Our experiments reveal that while LLMs exhibit preliminary potential,
they frequently fail to return meaningful results and suffer from output bias.
To address these limitations, we introduce CS-Agent, a dual-agent collaborative
framework to enhance LLM-based community search. CS-Agent leverages the
complementary strengths of two LLMs acting as Solver and Validator. Through
iterative feedback and refinement, CS-Agent dynamically refines initial results
without fine-tuning or additional training. After the multi-round dialogue,
Decider module selects the optimal community. Extensive experiments demonstrate
that CS-Agent significantly improves the quality and stability of identified
communities compared to baseline methods. To our knowledge, this is the first
work to apply LLMs to community search, bridging the gap between LLMs and graph
analysis while providing a robust and adaptive solution for real-world
applications.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [339] [Quantum-Efficient Reinforcement Learning Solutions for Last-Mile On-Demand Delivery](https://arxiv.org/abs/2508.09183)
*Farzan Moosavi,Bilal Farooq*

Main category: quant-ph

TL;DR: 本研究提出了一个结合量子计算和强化学习的框架，用于解决复杂的配送问题，相比现有方法在处理大规模问题和训练效率上更优。


<details>
  <summary>Details</summary>
Motivation: 为了解决NP难组合问题（特别是优化问题），特别是当经典方法在处理大规模解决方案时变得难以处理时，研究量子计算的潜力。

Method: 设计了一个包含问题特定编码量子电路（具有纠缠和变分层）的强化学习（RL）框架，以最小化现实世界最后一英里按需交付中的行驶时间。

Result: 研究结果表明，所提出的结合PQC和RL的框架在解决大规模CPDPTW方面优于PPO和QSVT，尤其是在解的规模和训练复杂度方面，并且能够很好地融入现实世界的约束。

Conclusion: 该研究提出的结合参数化量子电路（PQC）和强化学习（RL）的框架在解决大规模带时间窗口的捕获和交付问题（CPDPTW）方面，相比于Proximal Policy Optimization（PPO）和Quantum Singular Value Transformation（QSVT）等方法，在解的规模和训练复杂度方面表现出优越性，并能有效融合现实世界的约束。

Abstract: Quantum computation has demonstrated a promising alternative to solving the
NP-hard combinatorial problems. Specifically, when it comes to optimization,
classical approaches become intractable to account for large-scale solutions.
Specifically, we investigate quantum computing to solve the large-scale
Capacitated Pickup and Delivery Problem with Time Windows (CPDPTW). In this
regard, a Reinforcement Learning (RL) framework augmented with a Parametrized
Quantum Circuit (PQC) is designed to minimize the travel time in a realistic
last-mile on-demand delivery. A novel problem-specific encoding quantum circuit
with an entangling and variational layer is proposed. Moreover, Proximal Policy
Optimization (PPO) and Quantum Singular Value Transformation (QSVT) are
designed for comparison through numerical experiments, highlighting the
superiority of the proposed method in terms of the scale of the solution and
training complexity while incorporating the real-world constraints.

</details>


### [340] [Quantum-Enhanced Generative Adversarial Networks: Comparative Analysis of Classical and Hybrid Quantum-Classical Generative Adversarial Networks](https://arxiv.org/abs/2508.09209)
*Kun Ming Goh*

Main category: quant-ph

TL;DR: 生成对抗网络（GAN）的性能受限于其潜在表示的质量。本研究调查了混合量子经典 GAN（HQCGAN），其中量子生成器产生潜在向量。结果表明，尽管经典 GAN 取得了最佳分数，但 7 个量子比特的 HQCGAN 表现出具有竞争力的性能，并且在 NISQ 设备上具有可行性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决生成对抗网络（GAN）在生成高质量数据样本方面的能力，同时承认其性能受到潜在表示质量的限制，这些潜在表示通常是从经典噪声分布中采样的。

Method: 本研究调查了混合量子经典生成对抗网络（HQCGAN），其中参数化量子电路实现了量子生成器，为经典判别器生成潜在向量。我们使用 Qiskit 的 AerSimulator 和实际噪声模型来评估各种 HQCGAN 变体（具有 3、5 和 7 个量子比特）和一个经典 GAN。

Result: 在具有噪声的量子电路作为生成模型架构中的潜在先验方面，HQCGAN 的实际可行性得到了验证。7 个量子比特的 HQCGAN 表现出具有竞争力的性能，缩小了训练后期的差距，而 3 个量子比特的模型则在早期收敛时表现出局限性。效率分析表明，尽管存在量子采样开销，但训练时间仅增加了中等程度。

Conclusion: 近岸量子计算（NISQ）时代，为生成模型增加潜在增强的实际可行性得到了验证，特别是在具有噪声的量子电路作为生成模型架构中的潜在先验方面。

Abstract: Generative adversarial networks (GANs) have emerged as a powerful paradigm
for producing high-fidelity data samples, yet their performance is constrained
by the quality of latent representations, typically sampled from classical
noise distributions. This study investigates hybrid quantum-classical GANs
(HQCGANs) in which a quantum generator, implemented via parameterised quantum
circuits, produces latent vectors for a classical discriminator. We evaluate a
classical GAN alongside three HQCGAN variants with 3, 5, and 7 qubits, using
Qiskit's AerSimulator with realistic noise models to emulate near-term quantum
devices. The binary MNIST dataset (digits 0 and 1) is used to align with the
low-dimensional latent spaces imposed by current quantum hardware. Models are
trained for 150 epochs and assessed with Frechet Inception Distance (FID) and
Kernel Inception Distance (KID). Results show that while the classical GAN
achieved the best scores, the 7-qubit HQCGAN produced competitive performance,
narrowing the gap in later epochs, whereas the 3-qubit model exhibited earlier
convergence limitations. Efficiency analysis indicates only moderate training
time increases despite quantum sampling overhead. These findings validate the
feasibility of noisy quantum circuits as latent priors in GAN architectures,
highlighting their potential to enhance generative modelling within the
constraints of the noisy intermediate-scale quantum (NISQ) era.

</details>


### [341] [On continuum and resonant spectra from exact WKB analysis](https://arxiv.org/abs/2508.09211)
*Okuto Morikawa,Shoya Ogawa*

Main category: quant-ph

TL;DR: 本文利用复标度方法和精确WKB分析研究量子系统的共振现象，将散射理论与谱理论联系起来。


<details>
  <summary>Details</summary>
Motivation: 共振现象是许多量子系统中的核心，共振态通常由S矩阵的极点奇异性描述。本文旨在应用CSM和精确WKB分析来描述散射问题，并深入理解其背后的理论。

Method: 复标度方法（CSM）和精确WKB分析

Result: 计算了连续谱，推导了反向Rosen-Morse势的S-矩阵，重新解释了Aguilar-Balslev-Combes定理，讨论了Siegert边界条件的物理意义，并定义了修正希尔伯特空间中的物理态。

Conclusion: 本文将复标度方法（CSM）和精确WKB分析应用于散射问题，包括束缚态和共振态。通过精确WKB分析计算连续谱，并推导出反向Rosen-Morse势的S-矩阵。我们重新解释了CSM所依据的Aguilar-Balslev-Combes定理，讨论了Siegert边界条件的物理意义，并严格定义了修正希尔伯特空间中的物理态。本分析将散射截面与谱理论联系起来，为散射理论及相关公式提供了见解。

Abstract: Resonance phenomena are central to many quantum systems, where resonant
states are typically described by pole singularities of S-matrix. In this work,
we apply the complex scaling method (CSM) and exact WKB analysis to describe
scattering problems, incorporating both bound and resonant states. We compute
continuum spectrum based on the exact WKB analysis and derive the S-matrix for
the inverted Rosen--Morse potential. We reinterpret the
Aguilar--Balslev--Combes theorem, on which CSM is based; we then discuss the
physical significance of the Siegert boundary condition and rigorously define
physical states in a modified Hilbert space. Our analysis connects the
scattering cross-section and spectral theory, providing insights into the
scattering theory and related formulas.

</details>


### [342] [Displaced Janus States: Tunable Non-Gaussianity and Exact Higher-Order Coherences for Quantum Advantage](https://arxiv.org/abs/2508.09234)
*Arash Azizi*

Main category: quant-ph

TL;DR: 这项研究精确求解了 Janus 态，提供了一种表征其非高斯性的新方法，并将其确定为混合量子协议和容错连续变量计算的关键资源。


<details>
  <summary>Details</summary>
Motivation: 解决在连续变量信息处理中，对超高斯态（特别是压缩态叠加）的更高阶量子统计的完全解析理解的缺乏，这些态对于实现量子优势至关重要。

Method: 提出并精确求解了 Janus 态，开发了一个基于一类新的广义压缩多项式的强大解析框架，得到了其任意阶相干函数、Wigner函数和量子 Fisher 信息.的闭式表达式。

Result: 成功地得到了 Janus 态的精确解，并能够完全表征其可调谐的非高斯性，揭示了量子干涉如何改变其组分的极端光子团聚特性，以及可以实现海森堡极限的计量精度。

Conclusion: 该研究提出了 Janus 态的精确解，并提供了一个强大的分析框架，可以完全表征该态的可调谐非高斯性，揭示了量子干涉如何将压缩相干态分量的极端光子团聚转变为强反团聚或完美多光子抑制。研究结果为工程非高斯态提供了一个基础工具集，并将 Janus 态确定为混合量子协议和容错连续可变量子计算的关键资源。

Abstract: Non-Gaussian states are essential for achieving a quantum advantage in
continuous-variable (CV) information processing. Among these, superpositions of
squeezed states offer a rich phenomenology, yet a complete analytical
understanding of their higher-order quantum statistics-such as the transition
from extreme bunching ($g^{(k)} \to \infty$) to suppression ($g^{(k>2)} \to
0$)-has remained elusive. In this work, we introduce and provide an exact
solution for the displaced Janus state-a coherent superposition of two squeezed
coherent states. We develop a powerful analytical framework built upon a new
family of Generalized Squeezing Polynomials that yields closed-form expressions
for its arbitrary-order coherence functions, Wigner function, and quantum
Fisher information. This enables a full characterization of the state's tunable
non-Gaussianity, revealing how quantum interference can transform the extreme
photon bunching of its components into strong antibunching or perfect
multiphoton suppression. We identify parameter regimes that generate Wigner
negativity and can be harnessed for achieving Heisenberg-limited metrological
precision. Our work provides a foundational toolkit for engineering
non-Gaussian states, establishing the displaced Janus state as a key resource
for hybrid quantum protocols and fault-tolerant CV computation.

</details>


### [343] [A Symmetry-Based Taxonomy of Quantum Algorithms](https://arxiv.org/abs/2508.09236)
*Sakshi Kumar,Sumit Chilkoti,Mrittunjoy Guha Majumdar*

Main category: quant-ph

TL;DR: A new way to classify quantum algorithms using symmetries, which helps make quantum computing more scalable and reliable.


<details>
  <summary>Details</summary>
Motivation: To classify quantum algorithms based on fundamental symmetries underlying quantum state spaces, oracles, and circuit dynamics.

Method: Organizing algorithms according to their symmetry groups and invariants.

Result: This classification provides practical benefits for scalable and reliable quantum computation by characterizing behavior, verification, and complexity through preserved or exploited symmetries.

Conclusion: We propose a taxonomy for quantum algorithms based on symmetries, organizing them by symmetry groups and invariants to define distinct classes.

Abstract: We propose a taxonomy for quantum algorithms grounded in the fundamental
symmetries, both continuous and discrete, underlying quantum state spaces,
oracles, and circuit dynamics. By organizing algorithms according to their
symmetry groups and invariants, we define distinct algorithm classes whose
behavior, verification, and complexity can be characterized by the symmetries
they preserve or exploit. This symmetry-centric classification not only
reflects the deep connection between symmetries and conservation laws in
physics, but also yields practical benefits for scalable and reliable quantum
computation.

</details>


### [344] [Certifying Quantum States with Uniform Measurements](https://arxiv.org/abs/2508.09259)
*Liang Mao,Yifei Wang,Yingfei Gu,Chengshu Li*

Main category: quant-ph

TL;DR: Uniform measurements are a more efficient way to get information from qubits, useful for checking complex quantum states like graph states, and can be done with a specific experiment using Rydberg atoms.


<details>
  <summary>Details</summary>
Motivation: To explore the utility of uniform measurement as a resource-efficient alternative to qubit-resolved operations in quantum information processing.

Method: Demonstrated uniform measurements for certifying graph states using a sample-efficient algorithm with a performance guarantee, and proposed an experimental scheme based on analog-mode Rydberg atom arrays.

Result: Uniform measurements can certify graph states, and a sample-efficient algorithm with a proved performance guarantee was developed. An experimental scheme using analog-mode Rydberg atom arrays was also proposed.

Conclusion: Uniform measurements offer a resource-efficient alternative for qubit-resolved operations, enabling direct and efficient characterization of quantum states.

Abstract: Qubit-resolved operations and measurements are required for most current
quantum information processing schemes. However, these operations can be
experimentally costly due to the need for local addressing, demanding
significant classical control. A more resource-efficient alternative to extract
information is uniform measurement, where a site-independent rotation of qubits
is performed before measuring in the computational basis. This operation can be
performed in parallel, or globally, in atom- and ion-based platforms, reducing
resource cost and increasing fidelity. In this work, we initiate the
exploration of the utility of this operation in quantum information processing.
In particular, we demonstrate that uniform measurements can certify certain
graph states, a family of highly entangled and broadly useful quantum states.
We provide a sample-efficient certification algorithm with a proved performance
guarantee, together with an experimental scheme based on analog-mode Rydberg
atom arrays. Uniform measurements, therefore, allow direct and efficient
characterization of quantum states on quantum platforms in a hitherto
unexplored manner.

</details>


### [345] [Scalable Fluxonium-Transmon Architecture for Error Corrected Quantum Processors](https://arxiv.org/abs/2508.09267)
*Lukas Heunisch,Longxiang Huang,Stephan Tasler,Johannes Schirk,Florian Wallner,Verena Feulner,Bijita Sarma,Klaus Liegener,Christian M. F. Schneider,Stefan Filipp,Michael J. Hartmann*

Main category: quant-ph

TL;DR: 混合量子计算架构结合了通量量子比特和瞬时量子比特，通过可调谐耦合器实现高保真度量子门和良好的扩展性，适用于量子纠错。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有量子计算架构在扩展性、串扰和能级拥挤等方面的挑战，提出了一种新的混合量子计算架构。

Method: 提出了一种由交替的通量量子比特和瞬时量子比特组成的混合量子计算架构，并使用瞬时量子比特作为可调谐耦合器。通过数值模拟，验证了该架构在实现高保真度CZ门方面的潜力，并考虑了其在可扩展性和量子纠错方面的应用。

Result: 该混合量子计算架构具有优异的可扩展性，能够实现零ZZ串扰，减少能级拥挤，并规避通量量子比特的电容加载问题。通过数值模拟，实现的CZ门保真度高，并且在旁观量子比特存在的情况下依然能够保持高保真度。

Conclusion: 该混合量子计算架构结合了通量量子比特和瞬时量子比特的优点，通过可调谐耦合器实现了零ZZ串扰、减少了能级拥挤效应，并规避了通量量子比特的电容加载问题。在数值模拟中，通过双音通量脉冲实现的CZ门保真度高，且在存在旁观量子比特的情况下仍能保持高保真度，为大规模量子比特阵列提供了可扩展的解决方案。此外，该架构还能利用通量量子比特的长相干时间和非线性特性作为数据量子比特，并利用瞬时量子比特作为测量辅助量子比特，以实现量子纠错码。

Abstract: We propose a hybrid quantum computing architecture composed of alternating
fluxonium and transmon qubits, that are coupled via transmon tunable couplers.
We show that this system offers excellent scaling properties, characterized by
engineered zero $ZZ$-crosstalk in the idle regime, a substantial reduction of
level-crowding challenges through the alternating arrangement of different
qubit types within the lattice, and parameter regimes that circumvent the
capacitive loading problem commonly associated with fluxoniums. In numerical
simulations, we show a parametrically driven CZ-gate that achieves a
closed-system infidelity that is orders of magnitude below the coherence limit
for gate durations $\gtrsim 30\,\rm{ns}$ using a two-tone flux pulse on the
tunable coupler. Furthermore, we show that this gate scheme retains its
fidelity in the presence of spectator qubits, making it a scalable solution for
large lattices. Moreover, for the implementation of error correcting codes, our
approach can leverage the long coherence times and large non-linearities of
fluxoniums as data qubits, while fixed-frequency transmons with established
readout techniques can serve as measurement ancillas.

</details>


### [346] [Secure authentication via Quantum Physical Unclonable Functions: a review](https://arxiv.org/abs/2508.09296)
*Pol Julià Farré,Vladlen Galetsky,Mohamed Belhassen,Gregor Pieplow,Kumar Nilesh,Holger Boche,Tim Schröder,Janis Nötzel,Christian Deppe*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum Physical Unclonable Functions (QPUFs) offer a physically grounded
approach to secure authentication, extending the capabilities of classical
PUFs. This review covers their theoretical foundations and key implementation
challenges - such as quantum memories and Haar-randomness -, and distinguishes
QPUFs from Quantum Readout PUFs (QR-PUFs), more experimentally accessible yet
less robust against quantum-capable adversaries. A co-citation-based selection
method is employed to trace the evolution of QPUF architectures, from early
QR-PUFs to more recent Hybrid PUFs (HPUFs). This method further supports a
discussion on the role of information-theoretic analysis in mitigating
inconsistencies in QPUF responses, underscoring the deep connection between
secret-key generation and authentication. Despite notable advances, achieving
practical and robust QPUF-based authentication remains an open challenge.

</details>


### [347] [Quantum correction to the Langevin cross section in resonant-exchange processes](https://arxiv.org/abs/2508.09302)
*I. Simbotin,R. Côté*

Main category: quant-ph

TL;DR: 共振交换散射在低温下很重要，相移锁定是关键。本研究提出了一个解析表达式，考虑了相移的锁定和解锁，并适用于更高能量。


<details>
  <summary>Details</summary>
Motivation: 研究共振交换散射在多体动力学和输运现象中的作用，以及相移锁定对其在低能量下的影响。

Method: 推导了共振交换截面的解析表达式，考虑了相移的锁定和解锁。

Result: 计算得到的共振交换截面与解析表达式结果吻合良好，该表达式在较高能量下也适用。

Conclusion: 该研究推导了共振交换截面的解析表达式，考虑了相移的锁定和解锁，并与计算得到的截面吻合良好。

Abstract: Resonant-exchange scattering plays a key role in many-body dynamics and
transport phenomena (such as spin, charge, or excitation diffusion) at low and
moderate temperatures. Recent investigations have shown that the locking of
phase shifts is central to resonant-exchange scattering at low energies.
Moreover, phase-shift locking causes an unexpected behavior, namely the
resonant-exchange cross section over a broad range of energies is largely
dictated by $s$-wave scattering, whose influence extends high above the
$s$-wave Wigner regime. Here, we generalize our previous treatment to higher
energies and derive an analytical expression for the resonant-exchange cross
section which depends on a few parameters and accounts not only for the locking
of phase shifts, but also for their gradual unlocking with increased energy. We
find good agreement between the computed (fully quantal) cross sections and
those obtained with our expression, which we illustrate in great detail for the
case of resonant charge-transfer in ion-atom collisions.

</details>


### [348] [Demonstration of a photonic time-frequency Fourier transform and temporal double slit using atomic quantum memory](https://arxiv.org/abs/2508.09316)
*Ankit Papneja,Jesse Everett,Cameron Trainor,Aaron D. Tranter,Ben C. Buchler*

Main category: quant-ph

TL;DR: 通过结合两种量子存储技术，成功在铷原子中实现了内存傅里叶变换，这类似于时间双缝实验，为量子光学系统带来了新的操纵能力。


<details>
  <summary>Details</summary>
Motivation: 量子存储器在量子通信和分布式量子计算中至关重要，除了存储和缓冲外，还可以进行状态操纵，实现更复杂的量子网络操作。将傅里叶变换与量子存储结合，旨在为量子光学系统带来经典光学中的时间频率操纵能力。

Method: 利用梯度回声存储（GEM）和电磁感应透明（EIT）两种量子存储协议，结合激光冷却的铷原子系综，实现内存傅里叶变换。

Result: 成功演示了时间-频率傅里叶变换，结果可类比为时间双缝实验，显示了时间分离脉冲间的干涉效果，并阐明了干涉与脉冲相对相位和时间的关系。

Conclusion: 该研究结合了梯度回声存储和电磁感应透明两种成熟的量子存储协议，并利用铷原子系综实现了内存傅里叶变换。实验结果可理解为时间双缝，证明了时间分离脉冲间的干涉与脉冲间的相对相位和时间有关。该技术有望为量子光学系统带来经典光学系统中成熟的时间频率傅里叶操纵能力。

Abstract: Aquantummemoryforlightisexpectedtoplayacrucialroleinquantumcommunicationprotocols
and distributed quantum computing. In addition to storage and buffering, a
quantum memory can be used for manipulations of stored states to allow more
complex quantum network operations. In this work, we demonstrate an in-memory
Fourier transform using a combination of two well-established quantum memory
protocols: Gradient Echo Memory and Electromagnetically Induced Transparency.
Our experiment is realised using an ensemble of rubidium atoms that are laser
cooled in an elongated magneto-optic trap to maximise optical depth. The
results of our time-frequency Fourier transform can be understood as a temporal
double slit. We show that the interference between time-separated pulses
depends on the relative phase and time between the pulses of light. The use of
a quantum memory enables us to illuminate exactly where and how interference
occurs between time separated pulses. Time-frequency Fourier manipulation is a
well established technique in classical optical systems. Our combination of
Fourier manipulation and quantum-compatible memory could be used to bring
similar capability to quantum optical systems.

</details>


### [349] [Oscillating bound states in waveguide-QED system with two giant atoms](https://arxiv.org/abs/2508.09338)
*F. J. Lü,W. Z. Jia*

Main category: quant-ph

TL;DR: 该研究阐明了具有多个巨型原子的波导量子电动力学中的束缚态，并展示了其在量子技术中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 阐明耦合构型和原子参数如何影响衰减抑制，并对束缚态进行分类。

Method: 通过推导普遍适用的暗态条件，来阐明耦合构型和原子参数如何影响衰减抑制。通过分析原子和束缚光子的长期动力学行为，对束缚态进行了详细分类，并探讨了这些动力学行为与系统内在光-物质相互作用之间的联系。

Result: 发现了具有持续原子激发和周期性原子-光子或原子-原子激发交换的静态束缚态和振荡束缚态。在特定条件下，振荡束缚态可以包含更多谐波分量，这为高容量量子信息处理提供了平台。

Conclusion: 该系统为具有多个巨型原子的波导量子电动力学中的束缚态提供了一个平台，并揭示了其在量子技术中的应用前景。

Abstract: We study the bound states in the continuum (BIC) in a system of two identical
two-level giant atoms coupled to a one-dimensional waveguide. By deriving
general dark-state conditions, we clarify how coupling configurations and
atomic parameters influence decay suppression. Through analysis of the
long-time dynamical behaviors of atoms and bound photons, we carry out a
detailed classification of bound states and explore the connections between
these dynamical behaviors and the system's intrinsic light-matter interactions.
The system supports static bound states with persistent atomic excitations, and
oscillating bound states with periodic atom-photon or atom-atom excitation
exchange. Under certain conditions, oscillating bound states can contain more
harmonic components owing to the emergence of additional quasi-dark modes,
rendering them promising platforms for high-capacity quantum information
processing. These findings advance the understanding of BIC in waveguide
quantum electrodynamics with multiple giant atoms and reveal their prospective
applications in quantum technologies.

</details>


### [350] [Discovery of energy landscapes towards optimized quantum transport: Environmental effects and long-range tunneling](https://arxiv.org/abs/2508.09371)
*Maggie Lawrence,Matthew Pocrnic,Erin Fung,Juan Carrasquilla,Erik M. Gauger,Dvira Segal*

Main category: quant-ph

TL;DR: 本研究利用梯度下降算法优化了量子网络的能量分布，以提高载流子传输效率。研究发现，最优能量分布模式取决于网络的具体参数，如耦合方式和环境因素。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在识别能量分布能够优化载流子传输的准一维链，并探讨网络维度、连接性、格点能量、耦合方式（短程或长程）以及环境因素对载流子传输的影响。

Method: 研究利用JAX自动微分框架，结合Optax的乐观梯度下降和AdaMax算法优化了格点上的单点能量。通过Lindblad量子主方程研究了在单一和非单一（退相干和耗散）效应影响下的系统稳态行为。

Result: 研究发现，能量景观的优化方式取决于格点间隧耦合是短程还是长程，以及是否存在环境相互作用和环境温度。

Conclusion: 本研究发现了具有优化载流子传输特性的准一维链的能量分布规律，并根据链的耦合方式、环境因素和温度对其进行了分类，为设计高效传输系统提供了指导。

Abstract: Carrier transport in quantum networks is governed by a variety of factors,
including network dimensionality and connectivity, on-site energies, couplings
between sites and whether they are short- or long-range, and environmental
effects. In this work, we identify classes of quasi-one-dimensional chains with
energy profiles that optimize carrier transport under such influences.
Specifically, we optimize on-site energies using Optax's optimistic gradient
descent and AdaMax algorithms, enabled by the JAX automatic differentiation
framework. Focusing on steady-state transport, we study the system's behavior
under combined unitary and nonunitary (dephasing and dissipative) effects using
the Lindblad quantum master equation. After validating our optimization scheme
on short chains, we extend the study to larger systems where we identify
systematic patterns in energy profiles. Our analysis reveals that different
types of energy landscape enhance transport, depending on whether inter-site
tunneling couplings in the chain are short- or long-range, the existence of
environmental interactions, and the temperature of the environment. Our
classification and insights of optimal energy landscapes offer guidance for
designing efficient transport systems for electronic, photovoltaic and quantum
communication applications.

</details>


### [351] [Parallel repetition of expanded, and multiplayer, Quantum games: anchoring, optimal values, generalized error bounds, dependency-breaking as symmetry-breaking](https://arxiv.org/abs/2508.09380)
*Pete Rigas*

Main category: quant-ph

TL;DR: The multiplayer anchored optimal value decays exponentially when repeated in parallel, according to probabilistic computations and prior research.


<details>
  <summary>Details</summary>
Motivation: To analyze the decay of parallel repetition of the multiplayer anchored optimal value.

Method: The paper uses probabilistic computations, including expected values for winning probability changes under anchoring, positive operator valued measurements for correspondence with probabilistic quantities, Relative and Relative-min entropies, and generalized error bounds.

Result: The parallel repetition of the multiplayer anchored optimal value decays exponentially, supported by several probabilistic computations and building on previous work by Bavarian, Vidick, and Yuen.

Conclusion: We demonstrate that parallel repetition of the multiplayer anchored optimal value decays exponentially.

Abstract: We demonstrate that parallel repetition of the multiplayer anchored optimal
value, $\omega \big( G_{\bot} \big)^{\otimes n}$, decays exponentially. Central
to our approach are several probabilistic computations, pertaining to: (1) the
computation of expected values for quantifying how the winning probability of
the game is likely to change under the anchoring transformation; (2) the
computation of positive operator valued measurements, which can be placed into
direct correspondence with several probabilistically defined quantities; (3)
the computation of Relative, and Relative-min entropies; (4) and lastly, the
computation of generalized error bounds, which have previously been analyzed by
the author in several multiplayer game-theoretic settings (arXiv: 2505.06322,
and arXiv: 2507.03035). This work builds upon observations originally provided
by Bavarian, Vidick, and Yuen (arXiv: 1509.07466).

</details>


### [352] [Efficient computation of average subsystem Bures distance in transverse field Ising chain](https://arxiv.org/abs/2508.09417)
*Zhouhao Guo,M. A. Rajabpour,Jiaju Zhang*

Main category: quant-ph

TL;DR: 本研究提出了一种计算高维度高斯态之间Bures距离的有效算法，解决了可积系统中平均子系统迹距离的计算成本和简并问题，并发现Bures距离随子系统大小线性增加。


<details>
  <summary>Details</summary>
Motivation: 解决可积系统中平均子系统迹距离计算的计算成本和简并问题。

Method: 通过计算自旋-1/2横向场伊辛链中平均子系统Bures距离，并开发了计算高维度高斯态之间Bures距离的算法。

Result: 在可积系统中，Bures距离随子系统大小线性增加，并且发现可积系统和混沌系统之间平均子系统距离的伸缩行为不同，这是由于可积系统中简并态的谱间不连续性。

Conclusion: 本研究提出了计算高维度高斯态之间Bures距离的有效算法，解决了计算成本和简并问题。

Abstract: The average subsystem trace distance has been proposed as an indicator of
quantum many-body chaos and integrability. In integrable systems, evaluating
the trace distance faces two challenges: the computational cost for large
systems and ambiguities in defining and ordering eigenstates. In this paper, we
calculate the average subsystem Bures distance in the spin-1/2 transverse-field
Ising chain. We develop an efficient algorithm to evaluate the Bures distance
between two Gaussian states, which allows us to access larger system sizes. To
address the degeneracy issue, we consider simultaneous eigenstates of all local
conserved charges and use these charges to systematically order degenerate
states. The results align with the conjectured linear increase with subsystem
size. We demonstrate that the distinct scaling behaviors of the average
subsystem trace and Bures distances in chaotic versus integrable systems stem
from discontinuities of local conserved charges across the spectrum in
integrable systems. Additionally, we investigate the average subsystem
distances between random pure Gaussian states but do not observe a linear
increase.

</details>


### [353] [Surpassing the PLOB bound in continuous-variable quantum secret sharing using a state-discrimination detector](https://arxiv.org/abs/2508.09445)
*Qin Liao,Chong Tang,Qingquan Peng,Chao Ding,Lingjin Zhu,Yijun Wang,Xiquan Fu*

Main category: quant-ph

TL;DR: A new CVQSS protocol (SDD-CVQSS) uses a state-discrimination detector to improve performance and security, outperforming existing methods and offering solutions for long-distance transmission.


<details>
  <summary>Details</summary>
Motivation: Continuous-variable quantum secret sharing (CVQSS) is promising for multi-party information security, but its current performance is limited.

Method: Propose a novel CVQSS protocol integrated with a state-discrimination detector (SDD), dubbed SDD-CVQSS. Develop the detailed procedure of SDD-CVQSS, replacing the traditional coherent detector with an SDD and eliminating the need for multiple point-to-point quantum key distribution links. Elaborate on the principle of the SDD for efficiently discriminating mixed states with lower error probability. Construct a security model for SDD-CVQSS and derive its security bound against beam-splitting collective attacks.

Result: SDD-CVQSS outperforms conventional CVQSS in maximum transmission distance and secret key rate, surpassing the PLOB bound. Post-selection can compensate for performance degradation in long-distance scenarios.

Conclusion: SDD-CVQSS outperforms conventional CVQSS in both maximum transmission distance and secret key rate, even surpassing the PLOB bound. The performance degradation in long-distance transmission can be compensated for using a post-selection scheme.

Abstract: Continuous-variable quantum secret sharing (CVQSS) is a promising approach to
ensuring multi-party information security. While CVQSS offers practical ease of
implementation, its present performance remains limited. In this paper, we
propose a novel CVQSS protocol integrated with a state-discrimination detector
(SDD), dubbed SDD-CVQSS. In particular, we first develop the detailed procedure
of SDD-CVQSS, which replaces the traditional coherent detector with an SDD and
eliminates the long-standing necessary step of establishing multiple
point-to-point quantum key distribution links between all users and the dealer.
We then elaborate on the principle of the specifically designed SDD, which can
efficiently discriminate mixed states with a much lower error probability.
Finally, we construct a security model for SDD-CVQSS and derive its security
bound against beam-splitting collective attacks. Numerical simulations show
that SDD-CVQSS outperforms conventional CVQSS in both maximum transmission
distance and secret key rate, even surpassing the PLOB bound. Additionally, we
find that the performance degradation of SDD-CVQSS in long-distance
transmission scenarios can be effectively compensated for using a
post-selection scheme, providing a feasible way to achieve high-performance
CVQSS.

</details>


### [354] [Realizing Parrondo's Paradox in Single-Qubit Quantum Walks via Local Phase-Induced Spatial Inhomogeneity](https://arxiv.org/abs/2508.09457)
*Ran-Yu Chang,Yun-Hsuan Chen,Gooi Zi Liang,Tsung-Wei Huang*

Main category: quant-ph

TL;DR: 通过在离散时间量子行走中使用特定的硬币算符和相位移，在空间不均匀的情况下实现了Parrondo悖论的量子版本，这在低资源系统中具有潜在应用。


<details>
  <summary>Details</summary>
Motivation: Parrondo悖论是一个经典的异常现象，即交替进行两个单独的输掉游戏最终会带来赢利预期。实现该悖论的量子版本一直是一个挑战，尤其是在单量子比特硬币系统的约束下。本研究旨在探索一种在低资源架构下实现量子Parrondo效应的方法。

Method: 该研究通过交替使用两个SU(2)硬币算符并在原点引入局部相位移，在离散时间量子行走(DTQWs)中实现了真正的量子Parrondo效应。通过一系列数值实验，分析了相位角、硬币参数和博弈序列的作用，并确定了建设性干涉能够实现奇异传输的最优区域。

Result: 通过数值实验，研究表明该模型在空间不均匀性的存在下，仅表现出持续的正漂移。研究分析了相位角、硬币参数和博弈序列的作用，并确定了建设性干涉能够实现奇异传输的最优区域。

Conclusion: 该研究通过交替使用两个SU(2)硬币算符并在原点引入局部相位移，在离散时间量子行走(DTQWs)中实现了真正的量子Parrondo效应。研究表明，该模型在空间不均匀性的存在下，仅表现出持续的正漂移，并通过数值实验分析了相位角、硬币参数和博弈序列的作用，确定了建设性干涉能够实现奇异传输的最优区域。研究结果验证了最近的理论主张，即平移对称性破缺对于克服由干涉引起的抵消至关重要，从而实现定向量子运动。该工作为在低资源架构中实现反直觉的量子动力学开辟了新的可能性，并在量子控制、能量收集和相干辅助传输方面具有潜在应用。

Abstract: Parrondo's paradox describes a counterintuitive phenomenon where alternating
between two individually losing games results in a winning expectation. While
its classical origin relies on capital-dependent bias and noise-induced
asymmetry, realizing a robust quantum version of the paradox has remained
challenging, especially under the constraint of single-qubit coin systems. In
this work, we demonstrate that a genuine quantum Parrondo effect can emerge in
discrete-time quantum walks (DTQWs) by alternating two SU(2) coin operators and
introducing a localized phase shift at the origin. Through a series of
numerical experiments, we show that this minimal model, without entanglement or
high-dimensional coins, exhibits sustained positive drift only in the presence
of spatial inhomogeneity. We analyze the role of phase angle, coin parameters,
and game sequences, and identify optimal regions in which constructive
interference enables paradoxical transport. Our findings validate recent
theoretical claims that translational symmetry breaking is essential for
overcoming interference-induced cancellation, thereby enabling directed quantum
motion. This work opens new possibilities for realizing counterintuitive
quantum dynamics using low-resource architectures, with potential applications
in quantum control, energy harvesting, and coherence-assisted transport.

</details>


### [355] [Lifshitz-like Metastability and Optimal Dephasing in Dissipative Bosonic Lattices](https://arxiv.org/abs/2508.09485)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 在耗散玻色子系统中，去相干性会抑制相干传输，并可能通过诱导长寿命的集体模式来减缓弛豫，这为控制玻色子量子系统的弛豫和退相干提供了新的策略。


<details>
  <summary>Details</summary>
Motivation: 探究耗散玻色子系统中，去相干性对相干动力学的影响，以及是否存在非预期的动力学行为。

Method: 利用二阶矩的精确动力学方程，揭示了弱弛豫促进平衡，而中强弛豫则抑制了这种现象。

Result: 研究发现，去相干性抑制了相干传输，并产生了在系统晚期行为中占主导地位的长寿命集体模式，类似于无序系统中的 Lifshitz 拖尾态，导致异常缓慢的弛豫。

Conclusion: 在耗散玻色子系统中，非均匀局部耗散会通过诱导准暗态，在特定条件下通过优化弛豫率来加速弛豫，从而实现与耗散解耦并保护激发。

Abstract: In dissipative bosonic systems, dephasing is typically expected to accelerate
relaxation and suppress coherent dynamics. However, we show that in networks of
coherently coupled bosonic modes with non-uniform local dissipation, the
presence of quasi-dark states leads to a nontrivial response to dephasing:
while weak dephasing facilitates equilibration, moderate to strong dephasing
induces a pronounced slowdown of relaxation, revealing the existence of an
optimal dephasing rate that enhances equilibration. Using exact dynamical
equations for second-order moments, we demonstrate that dephasing suppresses
coherent transport and gives rise to long-lived collective modes that dominate
the system's late-time behavior. This phenomenon bears striking similarities to
Lifshitz-tail states, which are known in disordered systems to cause
anomalously slow relaxation. Our results uncover a counterintuitive mechanism
by which dephasing, rather than promoting equilibration, can dynamically
decouple specific modes from dissipation, thereby protecting excitations. These
findings highlight how non-Hermitian physics in open bosonic systems can give
rise to unexpected dynamical regimes, paving the way for new strategies to
control relaxation and decoherence in bosonic quantum systems, with broad
implications for both experimental and theoretical quantum science.

</details>


### [356] [Relative Wavefront Errors in Continuous-Variable Quantum Communication](https://arxiv.org/abs/2508.09491)
*Nathan K. Long,John Wallis,Alex Frost,Benjamin P. Dix-Matthews,Sascha W. Schediwy,Kenneth J. Grant,Robert Malaney*

Main category: quant-ph

TL;DR: 研究发现CV-QKD中的相对波前误差（WFE）真实存在，并受湍流影响，尤其在长距离传输中，这可能需要重新评估现有CV-QKD部署的标准假设。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索在通过大气信道进行连续变量量子密钥分发（CV-QKD）时，局部振荡器（LO）与量子信号之间可能存在的差分畸变，即相对波前误差（WFE），以及这种误差对CV-QKD性能的影响。

Method: 该研究通过实验提供了关于相对波前误差（WFE）存在的证据，并分析了湍流如何影响相对WFE的具体形态。

Result: 研究发现相对WFE确实存在于某些情况下，并且湍流会影响其形态，表明长距离链路比短距离链路受到的影响更大。

Conclusion: 该研究首次为相对波前误差（WFE）的存在提供了有力的实验证据，并强调了在某些情况下可能需要重新审视CV-QKD部署中的标准假设。研究还表明，湍流会影响相对WFE的具体形态，暗示长距离链路（如地面-卫星链路）比短距离纯陆地链路更容易受到影响。

Abstract: When undertaking continuous-variable quantum key distribution (CV-QKD) across
atmospheric channels, strong classical local oscillators (LOs) are often
polarization-multiplexed with the weak quantum signals for coherent measurement
at the receiver. Although the wavefronts of the quantum signal and LO are often
assumed to experience the same distortion across channels, previous theoretical
work has shown that they can experience differential distortions, resulting in
relative wavefront errors (WFEs). Such errors have previously been shown to
limit CV-QKD performance, in some cases leading to zero secure key rates. In
this work, for the first time, we provide strong experimental evidence that
relative WFEs are present in some circumstances and that standard assumptions
in CV-QKD deployments may need to be revisited. In addition, we demonstrate how
turbulence can affect the detailed form of the relative WFEs, thereby
indicating that long-range links like terrestrial-satellite channels are likely
impacted more than short-range terrestrial-only channels.

</details>


### [357] [Interpreting quantum reference frame transformations through a simple example](https://arxiv.org/abs/2508.09540)
*Esteban Castro-Ruiz,Thomas D. Galley,Leon Loveridge*

Main category: quant-ph

TL;DR: 本文通过分析具有Z_2对称性的三比特系统，比较了三种量子参考系变换方法（视角中立、附加粒子和操作），并展示了它们各自不同的变换规则及其运算意义。


<details>
  <summary>Details</summary>
Motivation: 量子参考系变换可以用来翻译量子系统之间相对的描述。目前，存在几种不同的量子参考系描述框架，具有不同的变换规则。

Method: 通过构建两个三比特态，这些状态相对于一个参考系是不可观测的，但相对于另一个参考系是可观测的，从而分析了三种当代量子参考系方法（视角中立、附加粒子和操作）之间的物理和概念区别。

Result: 研究表明，每种方法都提供了不同的变换规则，这有助于阐明每种方法的运算意义以及它们最自然应用的场景。

Conclusion: 每种方法都提供了不同的变换规则，这反映了它们对于全局状态和每个帧可访问信息的不同态度。

Abstract: Quantum reference frame transformations have been proposed to provide a means
by which to translate descriptions of quantum systems relative to each other.
At present, there are several differing frameworks for describing quantum
reference frames, with concomitantly different transformation rules. Here, we
investigate a simple example of three qubit systems with $\mathbb{Z}_2$
symmetry in order to analyze physical and conceptual distinctions between three
contemporary approaches to quantum reference frames -- dubbed
perspective-neutral, extra particle and operational. By constructing two
three-qubit states that are indistinguishable by observables relative to one
frame but are distinguishable by observables relative to another, we show that
each of the three approaches provides a distinct transformation rule, which may
be understood to reflect differing attitudes towards the global state and the
information that can be accessed by each frame. This helps us to shed light on
the operational meaning of each approach and the contexts in which they may be
most naturally applied.

</details>


### [358] [High-$Q$ superconducting resonators fabricated in an industry-scale semiconductor-fabrication facility](https://arxiv.org/abs/2508.09577)
*Nicolas Arlt,Karina Houska,Jochen Braumüller,Michael Kirsch,Gerhard Metzger-Brückl,Wolfgang Raberg,Thomas Stangl,Stefan Filipp,Jash Banker,Florian Brandl*

Main category: quant-ph

TL;DR: 研究人员首次利用半导体制造设施成功生产了超导量子电路，实现了极高的品质因数，并集成了关键的铌气桥技术。


<details>
  <summary>Details</summary>
Motivation: 为了在超导材料平台上实现通用量子计算机，需要制造和集成大量高质量、高均匀性的物理量子比特，并借鉴半导体行业的工艺控制、均匀性和可重复性优势。

Method: 利用半导体生产设施中的两层超导电路技术制造了 200 毫米的共面波导谐振器，并使用了铌和钽两种材料。

Result: 制造了高质量的铌和钽谐振器，在单光子阈值下实现了超过 10^6 的低温品质因数，并成功地将铌气桥集成到工艺中，同时保持了铌谐振器的高品质因数。

Conclusion: 该研究在 200 毫米的生产线中成功制造了超导量子电路，并达到了超过 10^6 的单光子阈值下的低温品质因数，同时还成功整合了铌气桥。

Abstract: Universal quantum computers promise to solve computational problems that are
beyond the capabilities of known classical algorithms. To realize such quantum
hardware on a superconducting material platform, a vast number of physical
qubits has to be manufactured and integrated at high quality and uniformity on
a chip. Anticipating the benefits of semiconductor industry processes in terms
of process control, uniformity and repeatability, we set out to manufacture
superconducting quantum circuits in a semiconductor fabrication facility. In
order to set a baseline for the process quality, we report on the fabrication
of coplanar waveguide resonators in a 200 mm production line, making use of a
two-layer superconducting circuit technology. We demonstrate high material and
process quality by cryogenic Q-factor measurements exceeding $10^6$ in the
single-photon regime, for microwave resonators made of both Niobium and
Tantalum. In addition, we demonstrate the incorporation of superconducting
Niobium air bridges in our process, while maintaining the high quality factor
of Niobium resonators.

</details>


### [359] [Procedural Generation and Games at the Dawn of Fault Tolerant Quantum Computing](https://arxiv.org/abs/2508.09683)
*Daniel Bultrini,James Wootton*

Main category: quant-ph

TL;DR: 量子计算在游戏开发中，尤其是在程序化内容生成方面，具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算技术的进步，现在是时候开始设想如何在游戏开发和部署中实际应用这些设备了。程序化内容生成是一个非常有前景的应用和探索领域。

Method: 研究了经典程序化内容生成中的算法，并提出了潜在的量子算法，以提供替代方法或计算优势。最后设想了一个利用量子算法计算琼斯多项式的游戏。

Result: 提出了利用量子算法进行程序化内容生成的可能性，并设想了一个利用量子算法（比经典计算机快指数倍）计算琼斯多项式的游戏。

Conclusion: 量子计算机在游戏开发和部署中具有广阔的应用前景，特别是在程序化内容生成领域。

Abstract: Quantum computers have long been more of a toy for researchers than a tool
for solving complex problems. However, recent advances in the field make
exploiting the advantages of fault-tolerant quantum computers feasible in the
next 5 to 10 years. It is now time to begin imagining how such devices could be
used in practice for game development and deployment. In this work we identify
procedural content generation as a very promising area of application and
exploration. We examine a selection of algorithmic approaches used in classical
procedural content generation and propose promising quantum algorithms that
could provide an alternative approach or a computational advantage. We then end
with a hypothetical game that exploits a recent quantum algorithm for computing
the Jones polynomial exponentially faster than classical computers could.

</details>


### [360] [Stabilizing boundary time crystals through Non-markovian dynamics](https://arxiv.org/abs/2508.09688)
*Bandita Das,Rahul Ghosh,Victor Mukherjee*

Main category: quant-ph

TL;DR: 非马尔可夫动力学比马尔可夫动力学更能稳定边界时间晶体（BTC）。


<details>
  <summary>Details</summary>
Motivation: 研究非马尔可夫动力学在边界时间晶体（BTC）中的作用，探索其对稳定性的影响。

Method: 利用量子Fisher信息、序参数、非马尔可夫性度量和动力学相图来分析非马尔可夫动力学对BTC的影响。

Result: 非马尔可夫动力学有助于在存在中等耗散率的情况下，在广泛的参数范围内稳定BTC。量子Fisher信息、序参数、非马尔可夫性度量和动力学相图显示出复杂的行为。

Conclusion: 非马尔可夫动力学可以稳定边界时间晶体（BTC），即使在耗散存在的情况下，也能在广泛的参数范围内实现稳定，并可能为耗散系统中的时间晶体稳定提供途径。

Abstract: We study Boundary time crystals (BTCs) in the presence of non-Markovian
dynamics. In contrast to BTCs observed in earlier works in the Markovian
regime, we show that non-Markovian dynamics can be highly beneficial for
stabilizing BTCs over a wide range of parameter values, even in the presence of
intermediate rates of dissipation. We analyze the effect of non-Markovian
dynamics on BTCs using quantum Fisher information, order parameter, a measure
of non-Markovianity, and a dynamical phase diagram, all of which show complex
behaviours with changing non-Markovianity parameters. Our studies can pave the
way for stabilizing time crystals in dissipative systems, as well as lead to
studies on varied dissipative dynamics on time translational symmetry breaking.

</details>


### [361] [Hybrid Optomechanical Cooling with Kerr Magnons and Squeezed Vacuum](https://arxiv.org/abs/2508.09725)
*Xiao-Hong Fan,Qin-Geng Chen,Jiaojiao Chen,Wei Xiong*

Main category: quant-ph

TL;DR: 通过YIG球的克尔非线性实现的光力冷却，在未解析边带下实现了热化的完全抑制，并可通过压缩真空噪声进一步增强。


<details>
  <summary>Details</summary>
Motivation: 在未解析边带（$\	ext{omega}_b < \	ext{kappa}$）实现光力冷却仍然是一个挑战，而地面冷却对于实现量子控制至关重要。

Method: 利用YIG球的克尔非线性实现双光子过程，并通过绝热消去消除马约拉纳，从而在干涉中抑制耗散通道。

Result: 在最优条件下，通过有效双光子过程实现了热化的完全抑制，超越了量子反作用极限，即使在深度未解析边带（DUSR：$\	ext{omega}_b \\	ext{kappa}$）也是如此。注入压缩真空噪声可以进一步提高冷却速率、降低光力耦合要求并提高噪声鲁棒性。

Conclusion: 该方法通过利用YIG球的克尔非线性产生的有效双光子过程，在最优条件下实现了热化的完全抑制，即使在未解析边带的深度（DUSR）下也能如此。此外，注入压缩真空噪声可以进一步提高冷却速率，降低对光力耦合的要求，并提高噪声鲁棒性。

Abstract: Ground-state cooling is essential for accessing the quantum regime and
enabling quantum control of macroscopic systems. However, achieving
optomechanical cooling in the unresolved-sideband regime ($\omega_b < \kappa$)
remains challenging. In this Letter, we propose an efficient cooling strategy
based on a hybrid optomechanical system incorporating a yttrium iron garnet
(YIG) sphere embedded in an optomechanical cavity. Under strong cavity driving,
the Kerr nonlinearity of the magnons hosted in the YIG sphere gives rise to a
two-magnon process. Adiabatic elimination of the magnons yields an effective
two-photon process in the cavity, which destructively interferes with all
dissipative channels, surpassing the quantum backaction limit and enabling
\textit{complete suppression} of heating under optimal conditions, even in the
deeply unresolved sideband regime (DUSR: $\omega_b \ll \kappa$). Moreover,
injecting squeezed vacuum noise into the cavity not only preserves these
advantages but also delivers additional enhancements, including higher net
cooling rates, reduced optomechanical coupling requirements, and improved noise
robustness. Comparative analysis shows that our approach outperforms existing
schemes without Kerr magnons, underscoring the potential of integrating
nonlinear magnonics with optomechanics for quantum control of macroscopic
mechanical systems.

</details>


### [362] [Entanglement certification from moments of positive maps](https://arxiv.org/abs/2508.09766)
*Qing-Hua Zhang,Xiaoyu Ma,Shao-Ming Fei*

Main category: quant-ph

TL;DR: 提出了一种新的纠缠认证方法，该方法不依赖于计算特征值，而是利用矩阵矩来判断纠缠。


<details>
  <summary>Details</summary>
Motivation: 在量子物理实验中，当仅对量子态有部分了解时，纠缠认证至关重要。现有的纠缠认证方法通常需要知道量子态的全部信息，或者需要计算输出态的特征值，这在实验中难以实现。

Method: 提出了一种基于非完全正映射的纠缠判据，并利用Faddeev-LeVerrier算法建立特征多项式系数与矩阵矩之间的关系，从而通过输出态的矩来判断是否存在负特征值。

Result: 该判据的有效性依赖于对正映射的选择，这与原始的正映射判据类似。通过利用矩来判断负特征值的存在，该方法为在信息不完全的情况下进行纠缠认证提供了一种新的途径。

Conclusion: 该方法通过使用非完全正映射（positive but not completely positive maps）来克服现有方法的局限性，无需计算输出态的特征值，从而简化了纠缠认证过程。

Abstract: Entanglement certification is crucial in physical experiments, particularly
when only partial knowledge of the quantum state is available. In this context,
we present an entanglement criterion based on positive but not completely
positive maps, which eliminates the need to identify eigenvalues of the output
state. Notably, the Faddeev-LeVerrier algorithm establishes a relationship
between the coefficients of characteristic polynomials and the moments of a
matrix. This enables the existence of negative eigenvalues through the moments
of the output state. The effectiveness of our criterion relies on the selection
of positive maps, similar to the original positive maps criterion.

</details>


### [363] [On the Generalization Limits of Quantum Generative Adversarial Networks with Pure State Generators](https://arxiv.org/abs/2508.09844)
*Jasmin Frkatovic,Akash Malemath,Ivan Kankeu,Yannick Werner,Matthias Tschöpe,Vitor Fortes Rey,Sungho Suh,Paul Lukowicz,Nikolaos Palaiodimopoulos,Maximilian Kiefer-Emmanouilidis*

Main category: quant-ph

TL;DR: QGANs fail to generalize in image generation and tend to learn the average representation of the training data, with limitations explained by a derived theoretical bound.


<details>
  <summary>Details</summary>
Motivation: We investigated the capabilities of Quantum Generative Adversarial Networks (QGANs) in image generation tasks, focusing on fully quantum implementations.

Method: We analyzed fully quantum implementations of QGANs, including both the generator and discriminator, through extensive numerical testing of current main architectures. We also analytically derived a lower bound for the discriminator quality when the generator's output is a pure-state.

Result: QGANs struggle to generalize across datasets, converging on the average representation of the training data. The derived lower bound for discriminator quality provides a theoretical explanation for these limitations.

Conclusion: We found that QGANs struggle to generalize across datasets, converging on the average representation of the training data. We also derived a lower bound for the discriminator quality, providing a theoretical explanation for these limitations.

Abstract: We investigate the capabilities of Quantum Generative Adversarial Networks
(QGANs) in image generations tasks. Our analysis centers on fully quantum
implementations of both the generator and discriminator. Through extensive
numerical testing of current main architectures, we find that QGANs struggle to
generalize across datasets, converging on merely the average representation of
the training data. When the output of the generator is a pure-state, we
analytically derive a lower bound for the discriminator quality given by the
fidelity between the pure-state output of the generator and the target data
distribution, thereby providing a theoretical explanation for the limitations
observed in current models. Our findings reveal fundamental challenges in the
generalization capabilities of existing quantum generative models. While our
analysis focuses on QGANs, the results carry broader implications for the
performance of related quantum generative models.

</details>


### [364] [The Role of Symmetry in Generalized Hong-Ou-Mandel Interference and Quantum Metrology](https://arxiv.org/abs/2508.09887)
*Éloi Descamps,Arne Keller,Pérola Milman*

Main category: quant-ph

TL;DR: HONG-OU-MANDEL干涉仪的对称性对于理解和推广该效应至关重要，为量子计量学和传感提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 识别输入状态在两个空间模式交换下的对称性是理解HONG-OU-MANDEL效应的基础，并表明这种对称性是推广该效应的关键。

Method: 将输入状态的对称性概念推广到任意输入状态和具有多个空间模式的配置，将标准分束器推广到离散傅里叶变换干涉仪。

Result: 该框架提供了对量子计量学的直接见解，展示了输入状态的对称性如何能够计算出明确的精度边界。

Conclusion: 通过关注对称性，该框架简化并统一了许多已知结果，并为量子干涉和传感的新发展铺平了道路。

Abstract: The Hong-Ou-Mandel interferometer is a foundational tool in quantum optics,
with both fundamental and practical significance. Earlier works identified that
input-state symmetry under exchange of the two spatial modes is fundamental in
the understanding of the Hong-Ou-Mandel effect. We now show that this notion of
symmetry is central to generalizing this effect. In particular, this point of
view enables the construction of extensions beyond the standard two
single-photon case to arbitrary input states, as well as to configurations with
more than two spatial modes via a natural generalization of the beam splitter
to a discrete Fourier transform interferometer. Beyond its conceptual
significance, this framework offers direct insights into quantum metrology,
showing how symmetry properties of input states allow the computation of
explicit precision bounds. By focusing on symmetry, we provide a perspective
that simplifies and unifies a range of known results, while paving the way for
new developments in quantum interference and sensing.

</details>


### [365] [Hybrid Quantum-Classical Latent Diffusion Models for Medical Image Generation](https://arxiv.org/abs/2508.09903)
*Kübra Yeter-Aydeniz,Nora M. Bauer,Pranay Jain,Max Masnick*

Main category: quant-ph

TL;DR: 量子扩散模型在医疗图像生成方面优于经典模型，并且在存在量子硬件噪声的情况下仍能保持高质量。


<details>
  <summary>Details</summary>
Motivation: 医疗研究中的生成学习模型对于开发深度学习模型的训练数据和改进诊断工具至关重要，但高质量、多样化的图像仍然是一个有待研究的问题。现有的量子增强生成模型规模较小，未能达到工业相关性。

Method: 提出并测试了量子增强的扩散模型和变分自编码器（VAE）模型，并将其应用于眼底视网膜图像生成任务。

Result: 与经典模型相比，量子增强模型生成的图像质量更高，86%的图像被外部验证分类为可评估，而经典模型为69%。此外，量子增强模型生成的图像在特征上更接近真实图像分布，即使经典扩散模型更大。在量子硬件噪声测试中，量子增强扩散模型有时能产生更高质量、更多样化和更高保真度的图像。

Conclusion: 量子增强扩散模型在生成模型方面有潜力，可以在当前量子硬件上实现工业规模的应用。

Abstract: Generative learning models in medical research are crucial in developing
training data for deep learning models and advancing diagnostic tools, but the
problem of high-quality, diverse images is an open topic of research.
Quantum-enhanced generative models have been proposed and tested in the
literature but have been restricted to small problems below the scale of
industry relevance. In this paper, we propose quantum-enhanced diffusion and
variational autoencoder (VAE) models and test them on the fundus retinal image
generation task. In our numerical experiments, the images generated using
quantum-enhanced models are of higher quality, with 86% classified as gradable
by external validation compared to 69% with the classical model, and they match
more closely in features to the real image distribution compared to the ones
generated using classical diffusion models, even when the classical diffusion
models are larger than the quantum model. Additionally, we perform noisy
testing to confirm the numerical experiments, finding that quantum-enhanced
diffusion model can sometimes produce higher quality images, both in terms of
diversity and fidelity, when tested with quantum hardware noise. Our results
indicate that quantum diffusion models on current quantum hardware are strong
targets for further research on quantum utility in generative modeling for
industrially relevant problems.

</details>


### [366] [An integrated photonics platform for high-speed, ultrahigh-extinction, many-channel quantum control](https://arxiv.org/abs/2508.09920)
*Mengdi Zhao,Manuj Singh,Anshuman Singh,Henry Thoreen,Robert J. DeAngelo,Daniel Dominguez,Andrew Leenheer,Frédéric Peyskens,Alexander Lukin,Dirk Englund,Matt Eichenfield,Nathan Gemelke,Noel H. Wan*

Main category: quant-ph

TL;DR: 本研究开发了一种先进的光子集成电路（PIC）平台，用于控制中性原子量子计算机中的大量量子比特。该平台在多个波长下均表现出优异的消光比、低串扰、快速开关和高脉冲稳定性，为构建大规模容错量子计算机奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了实现实用品规模的量子计算机，需要对数百万个可编程量子比特进行高保真度控制，这对控制系统提出了严峻挑战。现有的光控方法需要将紫外-可见光束分束到多个空间通道并进行调制以实现量子门操作。虽然光子集成电路（PIC）提供了一种可扩展的解决方案，但需要同时满足高速、高消光比、强通道间隔离和宽波长兼容性等要求。

Method: 本研究介绍并实验验证了一个铸造的PIC平台，该平台克服了现有PIC在速度、串扰和波长兼容性方面的限制。该平台专为Rubidium-87中性原子量子计算机设计，采用了8通道PIC，在200毫米晶圆上制造，并在795纳米（单量子比特门）、420纳米和1013纳米（双量子比特里德堡门）波长下进行了测试，评估了信噪比、串扰、开关速度和脉冲稳定性。

Result: 该平台在795纳米波长下实现了71.4 $\pm$ 1.1 dB的平均消光比（ER）和-68.0 $\pm$ 1.0 dB的最近邻信道片上串扰，以及-50.8 $\pm$ 0.2 dB的并行光束传输后的自由空间串扰。在420纳米和1013纳米波长下，也实现了42.4 dB（检测器限制）和61.5 dB的ER。器件的10-90%上升时间为26 $\pm$ 7纳秒，可在微秒级实现动态切换至-60 dB，并显示出$10^{-3}$级别的脉冲稳定性误差。

Conclusion: 这项工作为容错量子计算机和其他精密技术所需的高级大规模光学控制建立了一个可扩展的平台。

Abstract: High-fidelity control of the thousands to millions of programmable qubits
needed for utility-scale quantum computers presents a formidable challenge for
control systems. In leading atomic systems, control is optical: UV-NIR beams
must be fanned out over numerous spatial channels and modulated to implement
gates. While photonic integrated circuits (PICs) offer a potentially scalable
solution, they also need to simultaneously feature high-speed and
high-extinction modulation, strong inter-channel isolation, and broad
wavelength compatibility. Here, we introduce and experimentally validate a
foundry-fabricated PIC platform that overcomes these limitations. Designed for
Rubidium-87 neutral atom quantum computers, our 8-channel PICs, fabricated on a
200-mm wafer process, demonstrate an advanced combination of performance
metrics. At the 795 nm single-qubit gate wavelength, we achieve a mean
extinction ratio (ER) of 71.4 $\pm$ 1.1 dB, nearest-neighbor on-chip crosstalk
of -68.0 $\pm$ 1.0 dB, and -50.8 $\pm$ 0.2 dB after parallel beam delivery in
free-space. This high-performance operation extends to the 420 nm and 1013 nm
wavelengths for two-qubit Rydberg gates, showing ERs of 42.4 dB
(detector-limited) and 61.5 dB, respectively. The devices exhibit 10-90% rise
times of 26 $\pm$ 7 ns, achieve dynamic switching to -60 dB levels within
microsecond timescales, and show pulse stability errors at the $10^{-3}$ level.
This work establishes a scalable platform for developing advanced large-scale
optical control required in fault-tolerant quantum computers and other
precision technologies.

</details>


### [367] [Fault tolerant Operations in Majorana-based Quantum Codes: Gates, Measurements and High Rate Constructions](https://arxiv.org/abs/2508.09928)
*Maryam Mudassar,Alexander Schuckert,Daniel Gottesman*

Main category: quant-ph

TL;DR: 本文提出了一个适用于 Majorana 硬件（如纳米线和中性原子）的通用容错量子计算框架，包括状态制备、门操作和测量。该框架解决了现有方案的局限性，并提供了具体的容错装置和测量方案，证明了 Majorana 体系在实现容错量子计算方面的潜力。


<details>
  <summary>Details</summary>
Motivation: Majorana 体系（如纳米线和中性原子）作为一种有潜力的量子计算平台，能够有效地编码量子比特并抵抗噪声。然而，要可靠地运行计算，需要一个能够处理状态制备、门操作和测量全过程的容错方案。现有的容错方案要么仅限于特定的码族，要么尚未完全发展成熟。

Method: 提出了一种通用的容错计算框架，用于将逻辑量子比特编码到 Majorana 硬件中，并强调了偶数和奇数 Majorana 码之间的划分，以及它们在构建容错装置时的表现。工作中还提供了横向构造，并通过测量得到了一些容错 Clifford 装置的例子。对于奇数码，提出了一种使用量子参考帧的新型装置构造，实现了被奇偶校验超选择禁止的操作。此外，还提供了一种受 Steane 纠错启发的容错 Majorana 码测量方案，能够实现状态制备、逻辑操作测量和错误纠正。最后，构造了一个具有量子比特自由度的渐进式量子 LDPC Majorana 码。

Result: 工作提出了一个通用的容错计算框架，并提供了具体的容错 Clifford 装置构造，包括针对奇数码的特殊构造，以及一种容错测量方案。还展示了横向 T 门构造和渐进式量子 LDPC Majorana 码，证明了 Majorana 硬件实现容错量子计算的可行性。

Conclusion: 该工作展示了所有容错量子计算的必要元素都可以一致地实现在 Majorana 纳米线和中性原子等费米子硬件中。

Abstract: Majorana-based quantum computation in nanowires and neutral atoms has gained
prominence as a promising platform to encode qubits and protect them against
noise. In order to run computations reliably on such devices, a fully
fault-tolerant scheme is needed for state preparation, gates, and measurements.
However, current fault-tolerant schemes have either been limited to specific
code families or have not been developed fully. In this work, we develop a
general framework for fault-tolerant computation with logical degrees encoded
into Majorana hardware. We emphasize the division between even and odd Majorana
codes and how it manifests when constructing fault tolerant gadgets for these
families. We provide transversal constructions and supplement them with
measurements to obtain several examples of fault tolerant Clifford gadgets. For
the case of odd codes, we give a novel construction for gadgets using quantum
reference frames, that allows to implement operations that are forbidden due to
parity superselection. We also provide a fault-tolerant measurement scheme for
Majorana codes inspired by Steane error correction, enabling state preparation,
measurement of logical operations and error correction. We also point out a
construction for odd Majorana codes with transversal T gates. Finally, we
construct an asympotically good quantum LDPC Majorana code with qubit degrees
of freedom. Our work shows that all necessary elements of fault-tolerant
quantum computation can be consistently implemented in fermionic hardware such
as Majorana nanowires and fermionic neutral atoms.

</details>


### [368] [Quantum recurrences and the arithmetic of Floquet dynamics](https://arxiv.org/abs/2508.09933)
*Amit Anand,Dinesh Valluri,Jack Davis,Shohini Ghose*

Main category: quant-ph

TL;DR: 本研究利用代数数域理论，为有限维 Floquet 系统提供了一个识别精确量子عود时间的算术框架，并证明了有理数参数并不保证精确عود。


<details>
  <summary>Details</summary>
Motivation: Poincaré عود定理表明保守系统在相空间有界区域内最终会回到初始状态附近。量子系统也存在类似的现象，称为量子عود，其中量子态在足够长时间的幺正演化后会عود。周期性驱动（Floquet）量子系统表现出复杂的动力学行为，因此研究相互作用和哈密顿量结构如何影响عود行为具有重要意义。

Method: 本研究利用代数数域理论，构建了一个算术框架，通过分析 Floquet 幺正算符谱的环分圆结构来识别所有可能的عود时间。

Result: 该研究解决了有限维 Floquet 系统（包括可积和不可积模型）中精确、与状态无关的عود问题。该方法能够识别所有可能的عود时间，并能排除某些哈密顿量参数下的精确عود。证明了有理数哈密顿量参数并不普遍保证精确عود。

Conclusion: 本研究利用代数数域理论，构建了一个算术框架，通过分析 Floquet 幺正算符谱的环分圆结构，识别出所有可能的系统عود时间。研究表明，有理数参数并不普遍保证精确عود，揭示了系统参数与长时间动力学之间微妙的相互作用。这些发现加深了对量子عود的理论理解，阐明了其与量子混沌的关系，并强调了在量子计量学和控制领域中特别值得关注的参数范围。

Abstract: The Poincar\'e recurrence theorem shows that conservative systems in a
bounded region of phase space eventually return arbitrarily close to their
initial state after a finite amount of time. An analogous behavior occurs in
certain quantum systems where quantum states can recur after sufficiently long
unitary evolution, a phenomenon known as quantum recurrence. Periodically
driven (i.e. Floquet) quantum systems in particular exhibit complex dynamics
even in small dimensions, motivating the study of how interactions and
Hamiltonian structure affect recurrence behavior. While most existing studies
treat recurrence in an approximate, distance-based sense, here we address the
problem of exact, state-independent recurrences in a broad class of
finite-dimensional Floquet systems, spanning both integrable and non-integrable
models. Leveraging techniques from algebraic field theory, we construct an
arithmetic framework that identifies all possible recurrence times by analyzing
the cyclotomic structure of the Floquet unitary's spectrum. This
computationally efficient approach yields both positive results, enumerating
all candidate recurrence times and definitive negative results, rigorously
ruling out exact recurrences for given Hamiltonian parameters. We further prove
that rational Hamiltonian parameters do not, in general, guarantee exact
recurrence, revealing a subtle interplay between system parameters and
long-time dynamics. Our findings sharpen the theoretical understanding of
quantum recurrences, clarify their relationship to quantum chaos, and highlight
parameter regimes of special interest for quantum metrology and control.

</details>


### [369] [Quantum statistics of single-mode radiation emitted by superradiant Dicke states](https://arxiv.org/abs/2508.09962)
*A. Yadav,D. D. Yavuz*

Main category: quant-ph

TL;DR: 原子系综从超辐射态发射的单模辐射，在不同演化阶段会表现出不同的量子特性，从相干态到具有光子数压缩甚至福克态的真や量子态。


<details>
  <summary>Details</summary>
Motivation: 研究了原子系综在超辐射Dicke态初始条件下发射的单模辐射的量子统计特性。

Method: 开发了一种能够计算长时程辐射量子统计的数学形式，即使在原子数量庞大的情况下也适用。

Result: 在早期演化过程中，辐射可以很好地近似为Glauber相干态；在后期，辐射表现出真や量子特性，并可在特定条件下观察到光子数压缩，甚至可以产生福克态。

Conclusion: 该研究表明，原子系综发射的单模辐射在特定条件下会表现出真や量子特性，例如光子数压缩甚至福克态的产生，这与早期近似的Glauber相干态形成对比。

Abstract: We study the quantum statistics of single-mode radiation emitted by an atomic
ensemble when the ensemble is initially prepared in a superradiant Dicke state.
We show that while the radiation is well approximated by the Glauber coherent
state at early times in the evolution, the emission can be truly quantum at
later times. In particular, one can observe a large amount of photon-number
squeezing in the emission under certain conditions; even a Fock state can be
produced. We discuss the quantum statistics of the emission for various
parameters, including different initial conditions for the atomic ensemble. To
obtain these results, we have developed a formalism where we are able to
calculate the quantum statistics of the emission over long time-scales even
when the number of atoms in the ensemble is quite large.

</details>


### [370] [Improving quantum communication rates with permutation-invariant codes](https://arxiv.org/abs/2508.09978)
*Sujeet Bhalerao,Felix Leditzky*

Main category: quant-ph

TL;DR: 利用排列不变量子码和表示论，改进了多种量子信道的量子容量阈值，特别是在2-泡利和BB84信道族方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提高多种量子信道的量子通信速率，特别是针对参数化量子信道族，旨在改进其量子容量阈值。量子容量阈值是衡量信道在何种噪声水平下仍能支持可靠量子通信的关键指标，因此提高这些阈值对于实现可信的量子通信至关重要。

Method: 本研究提出了一种利用排列不变量子码来提高量子通信速率的方法。该方法的核心在于利用独立同分布量子信道保持输入的排列对称性这一特性。研究人员运用对称群和一般线性群的表示理论来简洁地描述由此产生的对称输出态，并基于此推导出一个高效的算法，用于计算排列不变量子码的相干信息。该算法能够处理大量的信道副本，例如针对量子比特信道可以处理至少100个副本。

Result: 通过所提出的方法，本研究成功应用于多种物理相关的信道模型，包括通用泡利信道、脱粹信道、广义幅度衰减信道和衰减-脱粹信道。对于这些信道族，研究均获得了改进的量子容量下界。具体而言，对于2-泡利和BB84信道族，其量子容量阈值得到了显著提升，超过了[Fern, Whaley 2008]所建立的最佳阈值。这些改进归功于一种具有非正交码态的、类似重复码的输入状态，该状态在本研究的表示论框架下得到了进一步分析和验证。

Conclusion: 本工作利用排列不变量子码改进了多种量子信道的量子通信速率，并重点关注参数化量子信道族，旨在提高其量子容量阈值。研究结果显示，通过利用独立同分布量子信道保持输入的排列对称性，并结合对称群和一般线性群的表示理论，可以高效地计算排列不变量子码的相干信息。该方法能够处理大量信道副本（例如，至少100个量子比特信道副本），并已成功应用于包括通用泡利信道、脱粹信道、广义幅度衰减信道和衰减-脱粹信道在内的多种物理相关信道模型，为这些信道族提供了改进的量子容量下界。特别地，对于2-泡利和BB84信道族，本研究显著提高了[Fern, Whaley 2008]中已知的量子容量阈值。这些改进是通过使用具有非正交码态的类似重复码的输入状态实现的，该状态在本研究的表示论框架中得到了进一步分析。

Abstract: In this work we improve the quantum communication rates of various quantum
channels of interest using permutation-invariant quantum codes. We focus in
particular on parametrized families of quantum channels and aim to improve
bounds on their quantum capacity threshold, defined as the lowest noise level
at which the quantum capacity of the channel family vanishes. These thresholds
are important quantities as they mark the noise level up to which faithful
quantum communication is theoretically possible. Our method exploits the fact
that independent and identically distributed quantum channels preserve any
permutation symmetry present at the input. The resulting symmetric output
states can be described succinctly using the representation theory of the
symmetric and general linear groups, which we use to derive an efficient
algorithm for computing the channel coherent information of a
permutation-invariant code. Our approach allows us to evaluate coherent
information values for a large number of channel copies, e.g., at least 100
channel copies for qubit channels. We apply this method to various physically
relevant channel models, including general Pauli channels, the dephrasure
channel, the generalized amplitude damping channel, and the damping-dephasing
channel. For each channel family we obtain improved lower bounds on their
quantum capacities. For example, for the 2-Pauli and BB84 channel families we
significantly improve the best known quantum capacity thresholds derived in
[Fern, Whaley 2008]. These threshold improvements are achieved using a
repetition code-like input state with non-orthogonal code states, which we
further analyze in our representation-theoretic framework.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [371] [TPTP World Infrastructure for Non-classical Logics](https://arxiv.org/abs/2508.09318)
*Alexander Steen,Geoff Sutcliffe*

Main category: cs.LO

TL;DR: The TPTP World now supports non-classical logics, and this paper explains how.


<details>
  <summary>Details</summary>
Motivation: To provide a self-contained comprehensive overview of the TPTP World infrastructure for ATP in non-classical logics.

Method: The paper analyzes the TPTP World infrastructure for Automated Theorem Proving (ATP) in non-classical logics, covering its language extension, problems and solutions, and tool support.

Result: The TPTP World infrastructure supports ATP in non-classical logics, with a detailed description of its application to quantified normal multi-modal logic.

Conclusion: The paper provides a comprehensive overview of the TPTP World infrastructure for ATP in non-classical logics, including language extensions, problems, solutions, and tool support, with a detailed description of its use for quantified normal multi-modal logic.

Abstract: The TPTP World is the well established infrastructure that supports research,
development, and deployment of Automated Theorem Proving (ATP) systems. The
TPTP World supports a range of classical logics, and since release v9.0.0 has
supported non-classical logics. This paper provides a self-contained
comprehensive overview of the TPTP World infrastructure for ATP in
non-classical logics: the non-classical language extension, problems and
solutions, and tool support. A detailed description of use of the
infrastructure for quantified normal multi-modal logic is given.

</details>


### [372] [On Middle Grounds for Preference Statements](https://arxiv.org/abs/2508.09553)
*Anne-Marie George,Ana Ozaki*

Main category: cs.LO

TL;DR: 本研究提出了一种基于逻辑的方法来解决群体决策中的冲突意见，并形式化了中间立场的概念。研究结果表明，对于偏好陈述，中间立场可能不存在或不唯一，并提供了相应的算法。


<details>
  <summary>Details</summary>
Motivation: 在群体决策或审议中，利益相关者经常面临冲突的意见。我们研究一种基于逻辑的方法来表达此类意见以及利益相关者之间的一种正式的、一般的中间立场概念。

Method: 我们提出了一种基于逻辑的方法来表达冲突意见，并提出了一种正式的、一般的中间立场概念。我们将通用框架应用于利益相关者使用偏好陈述‘我更喜欢a而不是b’来表达意见的情况，其中a和b是跨属性表达的替代方案。

Result: 我们证明了中间立场的存在性和唯一性的理论结果。

Conclusion: 由于偏好陈述，可能不存在且不一定存在中间立场。我们还提供了确定存在性和寻找中间立场的算法。

Abstract: In group decisions or deliberations, stakeholders are often confronted with
conflicting opinions. We investigate a logic-based way of expressing such
opinions and a formal general notion of a middle ground between stakeholders.
Inspired by the literature on preferences with hierarchical and lexicographic
models, we instantiate our general framework to the case where stakeholders
express their opinions using preference statements of the form I prefer 'a' to
'b', where 'a' and 'b' are alternatives expressed over some attributes, e.g.,
in a trolley problem, one can express I prefer to save 1 adult and 1 child to 2
adults (and 0 children). We prove theoretical results on the existence and
uniqueness of middle grounds. In particular, we show that, for preference
statements, middle grounds may not exist and may not be unique. We also provide
algorithms for deciding the existence and finding middle grounds.

</details>


### [373] [Short proofs without interference](https://arxiv.org/abs/2508.09851)
*Adrian Rebola-Pardo*

Main category: cs.LO

TL;DR: SAT求解器证明系统中的干扰问题阻碍了短证明的生成。我们提出了一种基于命题动态逻辑的框架，消除了干扰，同时保持了表达能力，并为开发有效的证明检查方法奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 解决SAT求解器证明系统中存在但令人烦恼的干扰问题，并为开发有效的证明检查方法奠定基础。

Method: 基于命题动态逻辑的见解，提出了一种消除干扰的框架，并提出了实现动态逻辑的决策过程的初步方法。

Result: 开发了一个新的证明系统框架，消除了干扰，并为实现动态逻辑的决策过程提供了初步方法。

Conclusion: 提出了一种消除干扰的框架，同时保留了基于干扰的证明的相同表达能力。

Abstract: Interference is a phenomenon on proof systems for SAT solving that is both
counter-intuitive and bothersome when developing proof-logging techniques.
However, all existing proof systems that can produce short proofs for all
inprocessing techniques deployed by SAT present this feature. Based on insights
from propositional dynamic logic, we propose a framework that eliminates
interference while preserving the same expressive power of interference-based
proofs. Furthermore, we propose a first building blocks towards RUP-like
decision procedures for our dynamic logic-based frameworks, which are essential
to developing effective proof checking methods.

</details>


### [374] [Efficient Volume Computation for SMT Formulas](https://arxiv.org/abs/2508.09934)
*Arijit Shaw,Uddalok Sarkar,Kuldeep S. Meel*

Main category: cs.LO

TL;DR: ttc算法通过分解、计算体积和并集运算，有效扩展了SMT求解器在LRA体积计算方面的能力，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: SMT在自动推理领域展现了强大能力，但其在处理实数变量的SMT理论（LRA）中，对可满足区域体积进行量化查询的需求日益增长，这在软件验证、网络物理系统和神经网络等领域具有重要应用价值。

Method: ttc算法将SMT-LRA公式的解空间分解为重叠凸多面体的并集，然后计算这些多面体的体积并进行并集运算。

Result: Experimental evaluations demonstrate significant performance improvements over existing state-of-the-art approaches.

Conclusion: ttc算法通过将SMT-LRA公式的解空间分解为重叠凸多面体，计算其体积并进行并集计算，实现了SMT求解器在体积计算方面的能力扩展，并在实验评估中表现出显著的性能提升。

Abstract: Satisfiability Modulo Theory (SMT) has recently emerged as a powerful tool
for solving various automated reasoning problems across diverse domains. Unlike
traditional satisfiability methods confined to Boolean variables, SMT can
reason on real-life variables like bitvectors, integers, and reals. A natural
extension in this context is to ask quantitative questions. One such query in
the SMT theory of Linear Real Arithmetic (LRA) is computing the volume of the
entire satisfiable region defined by SMT formulas. This problem is important in
solving different quantitative verification queries in software verification,
cyber-physical systems, and neural networks, to mention a few.
  We introduce ttc, an efficient algorithm that extends the capabilities of SMT
solvers to volume computation. Our method decomposes the solution space of SMT
Linear Real Arithmetic formulas into a union of overlapping convex polytopes,
then computes their volumes and calculates their union. Our algorithm builds on
recent developments in streaming-mode set unions, volume computation
algorithms, and AllSAT techniques. Experimental evaluations demonstrate
significant performance improvements over existing state-of-the-art approaches.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [375] [Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.09230)
*Yutong Wu,Jie Zhang,Yiming Li,Chao Zhang,Qing Guo,Nils Lukas,Tianwei Zhang*

Main category: cs.MA

TL;DR: Cowpox 是一种新的防御方法，通过分布式治疗机制提高多主体视觉语言模型系统的鲁棒性，防止攻击传播。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的自主多主体系统缺乏鲁棒性考虑，单一 agent 的漏洞可能传播到整个系统。

Method: 提出了一种名为 Cowpox 的新防御方法，该方法通过分布式机制限制感染传播，提高恢复率，并使用特殊治疗样本来预防和恢复感染。

Result: Cowpox 被证明可以有效提高多主体系统的鲁棒性，并提供了理论上的鲁棒性保证。

Conclusion: Cowpox 通过分布式机制提高多主体系统的鲁棒性，通过生成和分发特殊治疗样本来预防和恢复感染，并在实验和理论上证明了其有效性。

Abstract: Vision Language Model (VLM)-based agents are stateful, autonomous entities
capable of perceiving and interacting with their environments through vision
and language. Multi-agent systems comprise specialized agents who collaborate
to solve a (complex) task. A core security property is robustness, stating that
the system should maintain its integrity under adversarial attacks. However,
the design of existing multi-agent systems lacks the robustness consideration,
as a successful exploit against one agent can spread and infect other agents to
undermine the entire system's assurance. To address this, we propose a new
defense approach, Cowpox, to provably enhance the robustness of multi-agent
systems. It incorporates a distributed mechanism, which improves the recovery
rate of agents by limiting the expected number of infections to other agents.
The core idea is to generate and distribute a special cure sample that
immunizes an agent against the attack before exposure and helps recover the
already infected agents. We demonstrate the effectiveness of Cowpox empirically
and provide theoretical robustness guarantees.

</details>


### [376] [Emergence of Hierarchies in Multi-Agent Self-Organizing Systems Pursuing a Joint Objective](https://arxiv.org/abs/2508.09541)
*Gang Chen,Guoxin Wang,Anton van Beek,Zhenjun Ming,Yan Yan*

Main category: cs.MA

TL;DR: In MASOS, dependency hierarchies arise naturally from agents working towards a common goal, influenced by the task and initial setup. Agents' innate abilities and ongoing efforts shape their roles within these evolving structures.


<details>
  <summary>Details</summary>
Motivation: This paper aims to understand the emergence, evolution, and governing factors of dependency hierarchies in multi-agent self-organizing systems (MASOS) during task execution, addressing the inherent unpredictability of their emergent behaviors.

Method: Multi-agent reinforcement learning (MARL) was used to train MASOS for a collaborative box-pushing task. Inter-agent dependencies were quantified by calculating the gradients of each agent's actions concerning other agents' states, and hierarchy emergence was analyzed by aggregating these dependencies.

Result: Hierarchies emerge dynamically as agents pursue a joint objective and evolve with changing task requirements. These hierarchies emerge organically rather than from pre-configured rules. Task environment and network initialization influence hierarchy emergence. Hierarchies arise from the interplay of agent "Talent" (initial influence) and "Effort" (role shifting) within the "Environment".

Conclusion: The study demonstrates that dependency hierarchies in MASOS emerge dynamically during task execution due to agents

Abstract: Multi-agent self-organizing systems (MASOS) exhibit key characteristics
including scalability, adaptability, flexibility, and robustness, which have
contributed to their extensive application across various fields. However, the
self-organizing nature of MASOS also introduces elements of unpredictability in
their emergent behaviors. This paper focuses on the emergence of dependency
hierarchies during task execution, aiming to understand how such hierarchies
arise from agents' collective pursuit of the joint objective, how they evolve
dynamically, and what factors govern their development. To investigate this
phenomenon, multi-agent reinforcement learning (MARL) is employed to train
MASOS for a collaborative box-pushing task. By calculating the gradients of
each agent's actions in relation to the states of other agents, the inter-agent
dependencies are quantified, and the emergence of hierarchies is analyzed
through the aggregation of these dependencies. Our results demonstrate that
hierarchies emerge dynamically as agents work towards a joint objective, with
these hierarchies evolving in response to changing task requirements. Notably,
these dependency hierarchies emerge organically in response to the shared
objective, rather than being a consequence of pre-configured rules or
parameters that can be fine-tuned to achieve specific results. Furthermore, the
emergence of hierarchies is influenced by the task environment and network
initialization conditions. Additionally, hierarchies in MASOS emerge from the
dynamic interplay between agents' "Talent" and "Effort" within the
"Environment." "Talent" determines an agent's initial influence on collective
decision-making, while continuous "Effort" within the "Environment" enables
agents to shift their roles and positions within the system.

</details>


### [377] [Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research](https://arxiv.org/abs/2508.09815)
*Klaudia Krawiecka,Christian Schroeder de Witt*

Main category: cs.MA

TL;DR: 本研究扩展了 OWASP MAS 威胁建模指南，以解决 LLM 驱动的多主体系统特有的安全挑战，引入了新的威胁类别和评估策略，以提高复杂自主系统的安全性和弹性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有的 OWASP MAS 威胁建模指南在应对由 LLM 驱动的多主体架构方面的不足，特别是在推理崩溃、指标过拟合、不安全委托升级、涌现的隐蔽协调和异构多主体利用等领域。

Method: 提出对 OWASP 多主体系统 (MAS) 威胁建模指南的扩展，将多主体安全 (MASEC) 的最新预期研究转化为解决由大型语言模型 (LLM) 驱动的多主体架构特有的挑战的实用指南。 识别现有分类法中存在的差距，并引入了基于实际 MAS 部署的其他威胁类别和场景。 概述了包括稳健性测试、协调评估、安全执行和涌现行为监控在内的评估策略。

Result: 识别并详细说明了推理崩溃、指标过拟合、不安全委托升级、涌现的隐蔽协调和异构多主体利用等现有威胁建模的差距。 引入了诸如良性目标漂移、跨代理幻觉传播、情感提示制定和多主体后门利用等额外的威胁类别和场景。

Conclusion: 这项工作通过扩展其适用性来补充 OWASP 框架，使其能够应对日益复杂、自主和适应性强的多主体系统，旨在提高实际部署中的安全态势和弹性。

Abstract: We propose an extension to the OWASP Multi-Agentic System (MAS) Threat
Modeling Guide, translating recent anticipatory research in multi-agent
security (MASEC) into practical guidance for addressing challenges unique to
large language model (LLM)-driven multi-agent architectures. Although OWASP's
existing taxonomy covers many attack vectors, our analysis identifies gaps in
modeling failures, including, but not limited to: reasoning collapse across
planner-executor chains, metric overfitting, unsafe delegation escalation,
emergent covert coordination, and heterogeneous multi-agent exploits. We
introduce additional threat classes and scenarios grounded in practical MAS
deployments, highlighting risks from benign goal drift, cross-agent
hallucination propagation, affective prompt framing, and multi-agent backdoors.
We also outline evaluation strategies, including robustness testing,
coordination assessment, safety enforcement, and emergent behavior monitoring,
to ensure complete coverage. This work complements the framework of OWASP by
expanding its applicability to increasingly complex, autonomous, and adaptive
multi-agent systems, with the goal of improving security posture and resilience
in real world deployments.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [378] [Carbon Pricing in Traffic Networks](https://arxiv.org/abs/2508.09280)
*Svenja M. Griesbach,Tobias Harks,Max Klimm,Michael Markl,Philipp Warode*

Main category: cs.GT

TL;DR: 碳定价可用于管理交通流量以满足排放预算。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用碳定价来引导交通流量，以满足特定的排放预算。

Method: 研究了如何使用碳定价将交通引导至符合给定排放预算的均衡状态。对具有依赖于流量的外部性的多商品流模型进行了研究。为每个外部性分配单一价格，提供了可达到的所有流量作为瓦尔德鲁普均衡的完整特征。证明了通过设定适当的价格，可以实现任何网络中可行流量可达到的外部性预算。对于极值和帕累托最小化预算，存在价格使得所有均衡都遵守预算。对于平衡最小化凸势能的情况，价格可以通过求解相应的凸规划的拉格朗日乘子得到。在单一外部性的情况下，证明了流量引起的总外部性随价格的增加而减少。对于具有单一外部性的增、连续、分段仿射行车时间函数，给出了一个输出多项式算法，用于计算通过定价外部性可实现的所有均衡。即使在某些网络中输出大小相对于输入大小呈指数级增长，计算满足给定预算的最小价格仍然可以在多项式时间内完成。这使得能够有效计算可交易信贷机制的市场价格。

Result: 提出了一个框架，可以通过设置适当的价格来实现任何可行的排放预算，并证明了在特定条件下，这些价格可以通过凸规划的拉格朗日乘子计算出来。对于单一外部性，证明了总外部性随价格的增加而减少，并提供了一种在多项式时间内计算满足特定预算的最小价格的方法。

Conclusion: 碳定价是实现交通网络中所有可行排放目标的有效且易于处理的方法。

Abstract: Traffic is a significant source of global carbon emissions. In this paper, we
study how carbon pricing can be used to guide traffic towards equilibria that
respect given emission budgets. In particular, we consider a general
multi-commodity flow model with flow-dependent externalities. These
externalities may represent carbon emissions, entering a priced area, or the
traversal of paths regulated by tradable credit schemes.
  We provide a complete characterization of all flows that can be attained as
Wardrop equilibria when assigning a single price to each externality. More
precisely, we show that every externality budget achievable by any feasible
flow in the network can also be achieved as a Wardrop equilibrium by setting
appropriate prices. For extremal and Pareto-minimal budgets, we show that there
are prices such that all equilibria respect the budgets. Although the proofs of
existence of these particular prices rely on fixed-point arguments and are
non-constructive, we show that in the case where the equilibrium minimizes a
convex potential, the prices can be obtained as Lagrange multipliers of a
suitable convex program. In the case of a single externality, we prove that the
total externality caused by the traffic flow is decreasing in the price. For
increasing, continuous, and piecewise affine travel time functions with a
single externality, we give an output-polynomial algorithm that computes all
equilibria implementable by pricing the externality. Even though there are
networks where the output size is exponential in the input size, we show that
the minimal price obeying a given budget can be computed in polynomial time.
This allows the efficient computation of the market price of tradable credit
schemes. Overall, our results show that carbon pricing is a viable and (under
mild assumptions) tractable approach to achieve all feasible emission goals in
traffic networks.

</details>


### [379] [Collective dynamics of strategic classification](https://arxiv.org/abs/2508.09340)
*Marta C. Couto,Flavia Barsotti,Fernando P. Santos*

Main category: cs.GT

TL;DR: 本研究利用进化博弈论分析了AI分类算法与用户策略适应之间的反馈循环。研究发现，提高博弈检测能力和提供算法追索权可以减轻负面影响，并在无法实现完美分类器时提高用户改进率。最后，研究揭示了在特定条件下可能出现的循环动态。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决人工智能（AI）分类算法在金融、医疗、刑事司法和教育等高风险决策中的应用问题。由于个人能够适应收集到的关于分类器信息，这可能需要重新训练算法。研究的重点是理解用户适应和算法再训练所产生的集体动态。

Method: 本研究运用进化博弈论来解决用户适应和算法再训练之间的反馈循环问题。该框架为解决这一问题提供了数学上严谨的处理方法，并允许测试干预措施以减轻策略适应的不利影响。

Result: 研究结果表明，当算法不能有效抵抗策略操纵时，会产生用户支付高昂成本以满足机构期望（导致高昂的社会成本）或操纵算法（例如提供虚假信息）等挑战。通过提高博弈检测能力，可以降低社会成本并可能改善用户。即使在无法实现完美分类器的情况下，算法追索权也能实现高用户改进率。此外，研究还揭示了在严格的机构为其不成功的用户提供可行追索权的情况下，会出现新的循环动态。

Conclusion: 本研究表明，在分类器可能被用户策略性地操纵的情况下，可以通过提高博弈检测能力和提供算法追索权来减轻负面影响。当无法实现完美分类器时，算法追索权可以引导动态向高用户改进率发展。此外，研究还发现，严格的机构为不成功的用户提供可行的追索权会导致出现新的循环动态。

Abstract: Classification algorithms based on Artificial Intelligence (AI) are nowadays
applied in high-stakes decisions in finance, healthcare, criminal justice, or
education. Individuals can strategically adapt to the information gathered
about classifiers, which in turn may require algorithms to be re-trained. Which
collective dynamics will result from users' adaptation and algorithms'
retraining? We apply evolutionary game theory to address this question. Our
framework provides a mathematically rigorous way of treating the problem of
feedback loops between collectives of users and institutions, allowing to test
interventions to mitigate the adverse effects of strategic adaptation. As a
case study, we consider institutions deploying algorithms for credit lending.
We consider several scenarios, each representing different interaction
paradigms. When algorithms are not robust against strategic manipulation, we
are able to capture previous challenges discussed in the strategic
classification literature, whereby users either pay excessive costs to meet the
institutions' expectations (leading to high social costs) or game the algorithm
(e.g., provide fake information). From this baseline setting, we test the role
of improving gaming detection and providing algorithmic recourse. We show that
increased detection capabilities reduce social costs and could lead to users'
improvement; when perfect classifiers are not feasible (likely to occur in
practice), algorithmic recourse can steer the dynamics towards high users'
improvement rates. The speed at which the institutions re-adapt to the user's
population plays a role in the final outcome. Finally, we explore a scenario
where strict institutions provide actionable recourse to their unsuccessful
users and observe cycling dynamics so far unnoticed in the literature.

</details>


### [380] [Multidimensional Budget-Feasible Mechanism Design](https://arxiv.org/abs/2508.09367)
*Rian Neogi,Kanstantsin Pashkovich,Chaitanya Swamy*

Main category: cs.GT

TL;DR: 预算可行机制设计被扩展到多维情况，其中买方希望从卖方那里获得最大价值的物品。研究提出了新的基准和机制，为XOS估值提供了常数因子近似保证。


<details>
  <summary>Details</summary>
Motivation: 在预算可行机制设计中，最大化买方从卖家中获得的物品价值，但现有研究仅限于单维情况。本研究旨在将问题扩展到多维情况，并提供近似保证。

Method: 提出了一种新的基准（OPT_Bench），并设计了相应的预算可行机制。

Result: 证明了标准基准在多维情况下的局限性，提出了新的基准OPT_Bench，并为XOS估值设计了达到常数因子近似保证的预算可行机制。

Conclusion: 该研究首次提出了多维预算可行机制设计问题，并获得了针对XOS估值的常数因子近似保证。

Abstract: In budget-feasible mechanism design, a buyer wishes to procure a set of items
of maximum value from self-interested players. We have a valuation function
$v:2^U \to \mathbb{R}_+$, where $U$ is the set of all items, where $v(S)$
specifies the value obtained from set $S$ of items. The entirety of current
work on budget-feasible mechanisms has focused on the single-dimensional
setting, wherein each player holds a single item $e$ and incurs a private cost
$c_e$ for supplying item $e$.
  We introduce multidimensional budget feasible mechanism design: the universe
$U$ is now partitioned into item-sets $\{G_i\}$ held by the different players,
and each player $i$ incurs a private cost $c_i(S_i)$ for supplying the set
$S_i\subseteq G_i$ of items. A budget-feasible mechanism is a mechanism that is
truthful, and where the total payment made to the players is at most some given
budget $B$. The goal is to devise a budget-feasible mechanism that procures a
set of items of large value. We obtain the first approximation guarantees for
multidimensional budget feasible mechanism design.
  Our contributions are threefold. First, we prove an impossibility result
showing that the standard benchmark used in single-dimensional budget-feasible
mechanism design, namely the algorithmic optimum is inadequate in that no
budget-feasible mechanism can achieve good approximation relative to this. We
identify that the chief underlying issue here is that there could be a
monopolist which prevents a budget-feasible mechanism from obtaining good
guarantees. Second, we devise an alternate benchmark, $OPT_{Bench}$, that
allows for meaningful approximation guarantees, thereby yielding a metric for
comparing mechanisms. Third, we devise budget-feasible mechanisms that achieve
constant-factor approximation guarantees with respect to this benchmark for XOS
valuations.

</details>


### [381] [Project Submission Games in Participatory Budgeting](https://arxiv.org/abs/2508.09741)
*Piotr Faliszewski,Łukasz Janeczko,Andrzej Kaczmarczyk,Grzegorz Lisowski,Grzegorz Pierczyński*

Main category: cs.GT

TL;DR: This paper introduces project submission games to model voter behavior in elections, analyzing the existence and complexity of equilibria and developing algorithms for voter strategy. 


<details>
  <summary>Details</summary>
Motivation: The motivation is to capture and analyze the behavior of project proposers in participatory budgeting and multi-winner elections by introducing the framework of project submission games.

Method: The paper introduces the framework of project submission games, modeling the behavior of project proposers in participatory budgeting and multi-winner elections. The research focuses on analyzing the existence and complexity of pure Nash equilibria and developing algorithms for best response computation.

Result: The paper investigates the conditions under which pure Nash equilibria exist and the complexity of checking for their existence, alongside developing algorithms for computing best responses.

Conclusion: The paper focuses on finding conditions for the existence of pure Nash equilibria and analyzing the complexity of checking for their existence in project submission games. It also explores algorithms for computing best responses.

Abstract: We introduce the framework of project submission games, capturing the
behavior of project proposers in participatory budgeting (and multiwinner
elections). Here, each proposer submits a subset of project proposals, aiming
at maximizing the total cost of those that get funded. We focus on finding
conditions under which pure Nash equilibria (NE) exist in our games, and on the
complexity of checking whether they exist. We also seek algorithms for
computing best responses for the proposers

</details>


### [382] [The Price of EF1 for Few Agents with Additive Ternary Valuations](https://arxiv.org/abs/2508.09869)
*Maria Kyropoulou,Alexandros A. Voudouris*

Main category: cs.GT

TL;DR: 当代理数量很多时，EF1的价格是Ω(√n)；当代理数量很少时，EF1的价格有具体界限。


<details>
  <summary>Details</summary>
Motivation: 我们考虑一个资源分配问题，该问题涉及具有加性三元估价的代理，以及一组不可分割的项目。

Method: 对于大量代理n，我们证明了一个下界为Ω(√n)，这意味着EF1的价格不比代理具有一般性次加性估价时的情况好。然后，我们关注代理数量较少的情况，并证明当n=2时，EF1的价格为12/11，当n=3时，EF1的价格在1.2和1.256之间。

Result: 我们展示了当代理数量趋于无穷时，EF1的价格存在Ω(√n)的下界；当代理数量较少时，我们给出了EF1价格的具体界限（n=2时为12/11，n=3时在1.2到1.256之间）。

Conclusion: 对于有加性三元估价的代理，我们界定了 the price of envy-free up to one item (EF1) allocations。

Abstract: We consider a resource allocation problem with agents that have additive
ternary valuations for a set of indivisible items, and bound the price of
envy-free up to one item (EF1) allocations. For a large number $n$ of agents,
we show a lower bound of $\Omega(\sqrt{n})$, implying that the price of EF1 is
no better than when the agents have general subadditive valuations. We then
focus on instances with few agents and show that the price of EF1 is $12/11$
for $n=2$, and between $1.2$ and $1.256$ for $n=3$.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [383] [Decision-Making-Based Path Planning for Autonomous UAVs: A Survey](https://arxiv.org/abs/2508.09304)
*Kelen C. Teixeira Vivaldini,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 该 survey 探讨了无人机路径规划中的决策制定，重点介绍了探索性和信息性路径规划，并讨论了数据处理和当前挑战。


<details>
  <summary>Details</summary>
Motivation: 提高自主无人机的决策能力，以应对系统和环境中的不确定性，并根据接收到的信息采取行动，从而影响无人机的未来行为（路径规划）。

Method: 通过概述现有研究、展示研究方向（探索性路径规划和信息性路径规划）以及关注数据建模和理解的特征来分析该领域。

Result: 对现有研究进行了概述，重点介绍了探索性路径规划和信息性路径规划，并关注了数据建模和理解的特征。

Conclusion: 本 survey 概述了在无人机路径规划中使用决策制定的现有研究，重点介绍了探索性路径规划和信息性路径规划的研究方向，并分析了数据建模和理解的特征。

Abstract: One of the most critical features for the successful operation of autonomous
UAVs is the ability to make decisions based on the information acquired from
their surroundings. Each UAV must be able to make decisions during the flight
in order to deal with uncertainties in its system and the environment, and to
further act upon the information being received. Such decisions influence the
future behavior of the UAV, which is expressed as the path plan. Thus,
decision-making in path planning is an enabling technique for deploying
autonomous UAVs in real-world applications. This survey provides an overview of
existing studies that use aspects of decision-making in path planning,
presenting the research strands for Exploration Path Planning and Informative
Path Planning, and focusing on characteristics of how data have been modeled
and understood. Finally, we highlight the existing challenges for relevant
topics in this field.

</details>


### [384] [How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy](https://arxiv.org/abs/2508.09346)
*Zhenjiang Mao,Mrinall Eashaan Umasudhan,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的框架，用于在机器人控制和长预测场景中进行准确、可靠的安全预测，特别是在面对数据分布变化时。通过结合世界模型、无监督域适应和共形校准，该方法显著提高了预测的鲁棒性和置信度，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶机器人深层神经网络控制器在部分可观察性和分布转变下的安全预测存在挑战。传统基于模型验证的方法可扩展性有限且需要低维状态模型，而无模型方法常缺乏可靠性保证。本研究旨在解决这些局限性。

Method: 提出了一种用于端到端视觉控制系统的校准安全预测框架。该框架利用世界模型（包括变分自编码器和循环预测器）从原始图像序列预测未来潜在轨迹，并估计满足安全属性的概率。通过区分整体和复合预测流程，并引入校准机制来量化预测置信度。为解决分布转变导致风险估计失准问题，整合了无监督域自适应（UDA）技术，以在无手动标签的情况下确保预测下安全评估的鲁棒性。该方法提供了理论校准保证，并支持长预测的实际评估。

Result: 实验结果表明，在三个基准测试中，集成UDA的评估器在分布转变下保持了高准确率并显著降低了误报率。同时，基于世界模型的复合预测器在长预测任务上优于整体预测器，且共形校准提供了可靠的统计界限。

Conclusion: 该框架在模型不可知的情况下，通过世界模型、变分自编码器和循环预测器，结合无监督域自适应和共形校准，实现了对端到端视觉控制系统安全性的可靠预测，并在长预测和分布转变下表现优越。

Abstract: Autonomous robots that rely on deep neural network controllers pose critical
challenges for safety prediction, especially under partial observability and
distribution shift. Traditional model-based verification techniques are limited
in scalability and require access to low-dimensional state models, while
model-free methods often lack reliability guarantees. This paper addresses
these limitations by introducing a framework for calibrated safety prediction
in end-to-end vision-controlled systems, where neither the state-transition
model nor the observation model is accessible. Building on the foundation of
world models, we leverage variational autoencoders and recurrent predictors to
forecast future latent trajectories from raw image sequences and estimate the
probability of satisfying safety properties. We distinguish between monolithic
and composite prediction pipelines and introduce a calibration mechanism to
quantify prediction confidence. In long-horizon predictions from
high-dimensional observations, the forecasted inputs to the safety evaluator
can deviate significantly from the training distribution due to compounding
prediction errors and changing environmental conditions, leading to
miscalibrated risk estimates. To address this, we incorporate unsupervised
domain adaptation to ensure robustness of safety evaluation under distribution
shift in predictions without requiring manual labels. Our formulation provides
theoretical calibration guarantees and supports practical evaluation across
long prediction horizons. Experimental results on three benchmarks show that
our UDA-equipped evaluators maintain high accuracy and substantially lower
false positive rates under distribution shift. Similarly, world model-based
composite predictors outperform their monolithic counterparts on long-horizon
tasks, and our conformal calibration provides reliable statistical bounds.

</details>


### [385] [CLF-RL: Control Lyapunov Function Guided Reinforcement Learning](https://arxiv.org/abs/2508.09354)
*Kejun Li,Zachary Olkin,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: 该研究提出了一种名为CLF-RL的强化学习框架，通过结合模型预测和控制Lyapunov函数来改善双足机器人的运动策略学习。该方法通过提供更优的奖励信号，克服了传统强化学习中奖励设计困难和对目标敏感的问题，并在仿真和真实机器人测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在为双足机器人生成鲁棒的运动策略方面显示出潜力，但常常受到繁琐的奖励设计和对不良目标敏感性的影响。

Method: 提出了一种结构化奖励塑形框架，利用基于模型的轨迹生成和控制Lyapunov函数（CLFs）来指导策略学习。使用了两种基于模型的规划器：用于速度约束运动规划的降阶线性倒立摆（LIP）模型，以及基于混合零动力学（HZD）和全阶动力学预计算的步态库。这两种规划器定义了期望的末端执行器和关节轨迹，并用于构建基于CLF的奖励，以惩罚跟踪误差并鼓励快速收敛。

Result: CLF-RL在模拟和真实Unitree G1机器人实验中均验证了其有效性，相比基线RL策略和经典跟踪奖励RL方法，其鲁棒性和性能均有显著提升。

Conclusion: 基于CLF的强化学习方法在模拟和真实机器人实验中均表现出比基线强化学习策略和经典跟踪奖励强化学习方法更强的鲁棒性和更好的性能。

Abstract: Reinforcement learning (RL) has shown promise in generating robust locomotion
policies for bipedal robots, but often suffers from tedious reward design and
sensitivity to poorly shaped objectives. In this work, we propose a structured
reward shaping framework that leverages model-based trajectory generation and
control Lyapunov functions (CLFs) to guide policy learning. We explore two
model-based planners for generating reference trajectories: a reduced-order
linear inverted pendulum (LIP) model for velocity-conditioned motion planning,
and a precomputed gait library based on hybrid zero dynamics (HZD) using
full-order dynamics. These planners define desired end-effector and joint
trajectories, which are used to construct CLF-based rewards that penalize
tracking error and encourage rapid convergence. This formulation provides
meaningful intermediate rewards, and is straightforward to implement once a
reference is available. Both the reference trajectories and CLF shaping are
used only during training, resulting in a lightweight policy at deployment. We
validate our method both in simulation and through extensive real-world
experiments on a Unitree G1 robot. CLF-RL demonstrates significantly improved
robustness relative to the baseline RL policy and better performance than a
classic tracking reward RL formulation.

</details>


### [386] [DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation](https://arxiv.org/abs/2508.09444)
*Haoxiang Shi,Xiang Deng,Zaijing Li,Gongwei Chen,Yaowei Wang,Liqiang Nie*

Main category: cs.RO

TL;DR: DifNav 是一种创新的 VLN-CE 方法，它通过将航点生成和规划统一到单一扩散策略中，并结合 DAgger 训练，从而克服了现有方法的局限性，并在导航性能上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLN-CE 方法通常采用两阶段航点规划框架，该框架存在全局次优和性能瓶颈问题，这主要是由于每个阶段的代理目标和对第一阶段预测航点质量的依赖性。为了解决这些限制，需要一种能够统一这两个阶段并提高导航性能的新方法。

Method: DifNav 采用端到端优化的方法，将传统的航点生成和规划两个阶段统一到一个单一的扩散策略中。具体来说，DifNav 使用条件扩散策略来直接建模连续导航空间中的多模态动作分布，从而可以捕捉多种可能的遵循指令的行为，无需航点预测器。为了解决模仿学习中的复合误差问题并增强长程导航任务中的空间推理能力，研究人员采用了 DAgger 进行在线策略训练和专家轨迹增强，并利用聚合数据进一步微调策略。

Result: DifNav 在基准数据集上的大量实验表明，该方法即使在没有航点预测器的情况下，在导航性能上也明显优于先前最先进的两阶段航点模型。

Conclusion: DifNav 通过将航点生成和规划统一到单个扩散策略中，克服了现有 VLN-CE 方法中存在的全局次优和性能瓶颈问题。通过使用条件扩散策略直接对连续导航空间中的多模态动作分布进行建模，并结合 DAgger 进行在线策略训练和专家轨迹增强，DifNav 显著提高了策略的鲁棒性和从错误状态恢复的能力。实验证明，即使没有航点预测器，DifNav 的导航性能也明显优于之前最先进的基于航点的两阶段模型。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) requires
agents to follow natural language instructions through free-form 3D spaces.
Existing VLN-CE approaches typically use a two-stage waypoint planning
framework, where a high-level waypoint predictor generates the navigable
waypoints, and then a navigation planner suggests the intermediate goals in the
high-level action space. However, this two-stage decomposition framework
suffers from: (1) global sub-optimization due to the proxy objective in each
stage, and (2) a performance bottleneck caused by the strong reliance on the
quality of the first-stage predicted waypoints. To address these limitations,
we propose DAgger Diffusion Navigation (DifNav), an end-to-end optimized VLN-CE
policy that unifies the traditional two stages, i.e. waypoint generation and
planning, into a single diffusion policy. Notably, DifNav employs a conditional
diffusion policy to directly model multi-modal action distributions over future
actions in continuous navigation space, eliminating the need for a waypoint
predictor while enabling the agent to capture multiple possible
instruction-following behaviors. To address the issues of compounding error in
imitation learning and enhance spatial reasoning in long-horizon navigation
tasks, we employ DAgger for online policy training and expert trajectory
augmentation, and use the aggregated data to further fine-tune the policy. This
approach significantly improves the policy's robustness and its ability to
recover from error states. Extensive experiments on benchmark datasets
demonstrate that, even without a waypoint predictor, the proposed method
substantially outperforms previous state-of-the-art two-stage waypoint-based
models in terms of navigation performance. Our code is available at:
https://github.com/Tokishx/DifNav.

</details>


### [387] [Reactive Model Predictive Contouring Control for Robot Manipulators](https://arxiv.org/abs/2508.09502)
*Junheon Yoon,Woo-Jeong Baek,Jaeheung Park*

Main category: cs.RO

TL;DR: RMPCC结合CBFs，实现高速、安全的机器人路径跟随，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决现有路径跟随方法在处理动态环境中的碰撞、奇异点和运动学约束方面的不足，这些方法在执行规避机动时可能产生较大的跟踪误差。

Method: 通过反应式模型预测轮廓控制（RMPCC）和控制屏障函数（CBFs）实现机器人路径跟随，利用基于雅可比的线性化和Gauss-Newton Hessian近似来解决非线性RMPCC问题。

Result: 该方法通过了现实世界中动态障碍物的实验验证，实现了低轮廓误差和低机器人加速度，其性能比现有方法快10倍。

Conclusion: 该框架在动态环境中以100Hz的频率成功避开障碍物、奇异点和自碰撞。

Abstract: This contribution presents a robot path-following framework via Reactive
Model Predictive Contouring Control (RMPCC) that successfully avoids obstacles,
singularities and self-collisions in dynamic environments at 100 Hz. Many
path-following methods rely on the time parametrization, but struggle to handle
collision and singularity avoidance while adhering kinematic limits or other
constraints. Specifically, the error between the desired path and the actual
position can become large when executing evasive maneuvers. Thus, this paper
derives a method that parametrizes the reference path by a path parameter and
performs the optimization via RMPCC. In particular, Control Barrier Functions
(CBFs) are introduced to avoid collisions and singularities in dynamic
environments. A Jacobian-based linearization and Gauss-Newton Hessian
approximation enable solving the nonlinear RMPCC problem at 100 Hz,
outperforming state-of-the-art methods by a factor of 10. Experiments confirm
that the framework handles dynamic obstacles in real-world settings with low
contouring error and low robot acceleration.

</details>


### [388] [SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents](https://arxiv.org/abs/2508.09508)
*Reema Raval,Shalabh Gupta*

Main category: cs.RO

TL;DR: SMART-OC是一种用于自主水面载具（USV）在复杂海洋环境中导航的新型算法，它能实时避开障碍物并利用洋流，以最优的时间和风险抵达目标。


<details>
  <summary>Details</summary>
Motivation: 由于海洋环境复杂多变，洋流和动态障碍物给自主水面载具（USV）的安全高效导航带来了巨大挑战。USV需要根据实时信息不断调整路径，以避开碰撞并利用洋流以最小阻力到达目标。

Method: 提出了一种名为“自适应重规划树”（SMART-OC）的新型算法，该算法能够实时地在动态环境中进行时-风险最优的重规划。SMART-OC将路径上的障碍物风险与到达目标的时间成本相结合，以找到时-风险最优路径。

Result: 仿真实验验证了SMART-OC的有效性，实验结果表明，USV能够快速重规划路径以避开动态障碍物，并利用洋流成功抵达目标。

Conclusion: SMART-OC算法能够成功实现自主水面载具（USV）在复杂海洋环境中的实时路径规划，有效避开动态障碍物并利用洋流，最终成功抵达目标。

Abstract: Typical marine environments are highly complex with spatio-temporally varying
currents and dynamic obstacles, presenting significant challenges to Unmanned
Surface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need
to continuously adapt their paths with real-time information to avoid
collisions and follow the path of least resistance to the goal via exploiting
ocean currents. In this regard, we introduce a novel algorithm, called
Self-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents
(SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic
environments. SMART-OC integrates the obstacle risks along a path with the time
cost to reach the goal to find the time-risk optimal path. The effectiveness of
SMART-OC is validated by simulation experiments, which demonstrate that the USV
performs fast replannings to avoid dynamic obstacles and exploit ocean currents
to successfully reach the goal.

</details>


### [389] [CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail](https://arxiv.org/abs/2508.09558)
*Jiahui Zuo,Boyang Zhang,Fumin Zhang*

Main category: cs.RO

TL;DR: 一种用于机器人电缆布线的鹰爪灵感指甲和单次抓取端到端框架，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 汽车制造和纺织品生产中的电缆布线是一个复杂的机器人操作场景，对机器人自动化提出了挑战。传统的平行两指夹持器在抓取和引导电缆时存在过度挤压和过度张力的风险。

Method: 设计了一种鹰爪灵感的指甲，并将其安装在夹持器手指上，用于在平面上抓取电缆和在手中引导电缆。提出了一个单次抓取端到端3D电缆布线框架，利用视觉状态估计和基于运动原语的离线轨迹规划实现连续控制。

Result: 提出的框架在各种电缆和通道槽的测试中，显著优于拾放操作，证明了其有效性。

Conclusion: 该研究提出了一种新颖的鹰爪灵感设计的指甲，用于抓取和引导电缆，并提出了一个基于视觉状态估计和基于运动原语的离线轨迹规划的单次抓取端到端3D电缆布线框架。该框架在各种电缆和通道槽的测试中表现优于传统的拾放操作。

Abstract: The manipulation of deformable linear flexures has a wide range of
applications in industry, such as cable routing in automotive manufacturing and
textile production. Cable routing, as a complex multi-stage robot manipulation
scenario, is a challenging task for robot automation. Common parallel
two-finger grippers have the risk of over-squeezing and over-tension when
grasping and guiding cables. In this paper, a novel eagle-inspired fingernail
is designed and mounted on the gripper fingers, which helps with cable grasping
on planar surfaces and in-hand cable guiding operations. Then we present a
single-grasp end-to-end 3D cable routing framework utilizing the proposed
fingernails, instead of the common pick-and-place strategy. Continuous control
is achieved to efficiently manipulate cables through vision-based state
estimation of task configurations and offline trajectory planning based on
motion primitives. We evaluate the effectiveness of the proposed framework with
a variety of cables and channel slots, significantly outperforming the
pick-and-place manipulation process under equivalent perceptual conditions. Our
reconfigurable task setting and the proposed framework provide a reference for
future cable routing manipulations in 3D space.

</details>


### [390] [ESCoT: An Enhanced Step-based Coordinate Trajectory Planning Method for Multiple Car-like Robots](https://arxiv.org/abs/2508.09581)
*Junkai Jiang,Yihe Chen,Yibin Yang,Ruochen Li,Shaobing Xu,Jianqiang Wang*

Main category: cs.RO

TL;DR: ESCoT 是一种用于多车轨迹规划的改进方法，通过协作规划和重新规划策略提高了解决方案质量和成功率，并在模拟和实际测试中得到验证。


<details>
  <summary>Details</summary>
Motivation: 多车轨迹规划（MVTP）是多机器人系统（MRSs）中的关键挑战，具有广泛的应用前景。

Method: ESCoT 是一种增强的、基于步进的坐标轨迹规划方法，它结合了局部机器人群体的协作规划和重复配置的重新规划策略。

Result: 在稀疏场景下，ESCoT 显著提高了解决方案质量，在典型的冲突场景中提高了 70%，在随机生成的场景中提高了 34%，同时保持了高求解效率；在密集场景下，ESCoT 的表现优于所有基线方法，即使在最具挑战性的配置中也能保持超过 50% 的成功率。

Conclusion: ESCoT 算法有效解决了多车轨迹规划问题，进一步扩展了基于步进的方法的能力，并通过实际机器人测试验证了其在真实世界场景中的适用性。

Abstract: Multi-vehicle trajectory planning (MVTP) is one of the key challenges in
multi-robot systems (MRSs) and has broad applications across various fields.
This paper presents ESCoT, an enhanced step-based coordinate trajectory
planning method for multiple car-like robots. ESCoT incorporates two key
strategies: collaborative planning for local robot groups and replanning for
duplicate configurations. These strategies effectively enhance the performance
of step-based MVTP methods. Through extensive experiments, we show that ESCoT
1) in sparse scenarios, significantly improves solution quality compared to
baseline step-based method, achieving up to 70% improvement in typical conflict
scenarios and 34% in randomly generated scenarios, while maintaining high
solving efficiency; and 2) in dense scenarios, outperforms all baseline
methods, maintains a success rate of over 50% even in the most challenging
configurations. The results demonstrate that ESCoT effectively solves MVTP,
further extending the capabilities of step-based methods. Finally, practical
robot tests validate the algorithm's applicability in real-world scenarios.

</details>


### [391] [HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control](https://arxiv.org/abs/2508.09595)
*Michael Fennel,Markus Walker,Dominik Pikos,Uwe D. Hanebeck*

Main category: cs.RO

TL;DR: HapticGiant是一个新颖的大规模动觉触觉接口，旨在尽可能匹配人臂的特性，并在提供全面触觉反馈的同时，促进自然的 उपयोगकर्ता 移动。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实和触觉技术的研究一直致力于增强沉浸感。虽然先进的头戴式显示器现已上市，但动觉触觉接口仍然面临工作空间有限、自由度不足以及运动学与人臂不匹配等挑战。

Method: 该接口采用新颖的导纳型力控制方案，利用分层优化来渲染任意串联运动链和笛卡尔导纳。所提出的控制方案原生考虑了包括关节和笛卡尔约束以及奇异点在内的系统限制。

Result: 实验结果证明了HapticGiant及其控制方案的有效性。

Conclusion: HapticGiant及其控制方案被证明是有效的，为高度沉浸式虚拟现实应用铺平了道路。

Abstract: Research in virtual reality and haptic technologies has consistently aimed to
enhance immersion. While advanced head-mounted displays are now commercially
available, kinesthetic haptic interfaces still face challenges such as limited
workspaces, insufficient degrees of freedom, and kinematics not matching the
human arm. In this paper, we present HapticGiant, a novel large-scale
kinesthetic haptic interface designed to match the properties of the human arm
as closely as possible and to facilitate natural user locomotion while
providing full haptic feedback. The interface incorporates a novel
admittance-type force control scheme, leveraging hierarchical optimization to
render both arbitrary serial kinematic chains and Cartesian admittances.
Notably, the proposed control scheme natively accounts for system limitations,
including joint and Cartesian constraints, as well as singularities.
Experimental results demonstrate the effectiveness of HapticGiant and its
control scheme, paving the way for highly immersive virtual reality
applications.

</details>


### [392] [BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots](https://arxiv.org/abs/2508.09606)
*Alejandro Posadas-Nava,Alejandro Carrasco,Richard Linares*

Main category: cs.RO

TL;DR: BEAVR是一个开源的VR遥操作系统，可实现机器人之间的实时、灵巧的控制和数据记录，并与多种机器人和策略兼容。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的开源双边VR遥操作系统，以支持跨不同机器人平台进行实时控制、数据记录和策略学习。

Method: BEAVR采用零拷贝流架构，实现低至35毫秒的延迟；异步“思考-行动”控制循环，用于可扩展推理；以及优化的灵活网络API，支持实时多机器人操作。

Result: 该系统具有低延迟、可扩展性和灵活性，并已在多种操作任务中进行了测试，证明了其与ACT、DiffusionPolicy和SmolVLA等领先的视觉运动策略的兼容性。

Conclusion: BEAVR是一个开源的双边、多体现实习生（VR）机器人遥操作系统，可以跨不同机器人平台统一实时控制、数据记录和策略学习。它支持使用商品VR硬件进行实时的灵巧遥操作，并兼容从7自由度机械臂到全身人形机器人的模块化集成。BEAVR支持在LeRobot数据集中直接记录同步的多模态演示。

Abstract: \textbf{BEAVR} is an open-source, bimanual, multi-embodiment Virtual Reality
(VR) teleoperation system for robots, designed to unify real-time control, data
recording, and policy learning across heterogeneous robotic platforms. BEAVR
enables real-time, dexterous teleoperation using commodity VR hardware,
supports modular integration with robots ranging from 7-DoF manipulators to
full-body humanoids, and records synchronized multi-modal demonstrations
directly in the LeRobot dataset schema. Our system features a zero-copy
streaming architecture achieving $\leq$35\,ms latency, an asynchronous
``think--act'' control loop for scalable inference, and a flexible network API
optimized for real-time, multi-robot operation. We benchmark BEAVR across
diverse manipulation tasks and demonstrate its compatibility with leading
visuomotor policies such as ACT, DiffusionPolicy, and SmolVLA. All code is
publicly available, and datasets are released on Hugging Face\footnote{Code,
datasets, and VR app available at https://github.com/ARCLab-MIT/BEAVR-Bot.

</details>


### [393] [Interpretable Robot Control via Structured Behavior Trees and Large Language Models](https://arxiv.org/abs/2508.09621)
*Ingrid Maéva Chekam,Ines Pastor-Martinez,Ali Tourani,Jose Andres Millan-Romera,Laura Ribeiro,Pedro Miguel Bastos Soares,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 该研究提出了一种创新的方法，利用大型语言模型和行为树，让机器人能够理解并执行自然语言指令，并在实际测试中达到了94%的准确率，大大提升了人机交互的效率和自然度。


<details>
  <summary>Details</summary>
Motivation: 随着智能机器人在人类环境中日益普及，需要更直观、可靠、适应性强且交互自然的机器人交互（HRI）界面。传统机器人控制方法常要求用户适应界面或记忆预设命令，限制了其在动态、非结构化环境中的应用。

Method: 结合大型语言模型（LLMs）与行为树，实现机器人对自然语言指令的理解和基于插件的动作执行。重点关注了以人员跟踪和手势识别为代表的感知功能，并支持可扩展和模块化的集成。

Result: 实验结果表明，该方法在真实世界场景中具有实用性，平均认知到执行准确率约为94%，为HRI系统和机器人做出了重要贡献。

Conclusion: 本研究提出的结合大型语言模型与行为树的框架，通过自然语言指令驱动机器人执行，在真实世界实验中展现了约94%的认知到执行准确率，显著提高了人机交互系统的实用性。

Abstract: As intelligent robots become more integrated into human environments, there
is a growing need for intuitive and reliable Human-Robot Interaction (HRI)
interfaces that are adaptable and more natural to interact with. Traditional
robot control methods often require users to adapt to interfaces or memorize
predefined commands, limiting usability in dynamic, unstructured environments.
This paper presents a novel framework that bridges natural language
understanding and robotic execution by combining Large Language Models (LLMs)
with Behavior Trees. This integration enables robots to interpret natural
language instructions given by users and translate them into executable actions
by activating domain-specific plugins. The system supports scalable and modular
integration, with a primary focus on perception-based functionalities, such as
person tracking and hand gesture recognition. To evaluate the system, a series
of real-world experiments was conducted across diverse environments.
Experimental results demonstrate that the proposed approach is practical in
real-world scenarios, with an average cognition-to-execution accuracy of
approximately 94%, making a significant contribution to HRI systems and robots.
The complete source code of the framework is publicly available at
https://github.com/snt-arg/robot_suite.

</details>


### [394] [Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions](https://arxiv.org/abs/2508.09700)
*Mahdi Hejrati,Jouni Mattila*

Main category: cs.RO

TL;DR: 该论文探讨了在超人尺度机器人操作器 (BHSRM) 中进行沉浸式遥操作的控制、认知和界面挑战，重点是确保操作员安全、最小化传感器运动不匹配和增强本体感。


<details>
  <summary>Details</summary>
Motivation: 随着 BHSRM 在建筑、采矿和灾难响应等工业领域的应用日益广泛，必须重新思考沉浸式界面，以支持可扩展、安全和有效的人机协作。

Method: 分析了 BHSRM 中沉浸式遥操作的控制、认知和界面挑战，并对基于外骨骼和基于操纵杆的控制装置进行了早期实验比较。

Result: 对触觉和视觉反馈系统中的设计权衡进行了分析。

Conclusion: 需要为大规模机器人远程呈现开发新颖的评估工具、缩放策略和以人为中心的安全性模型。

Abstract: Teleoperation of beyond-human-scale robotic manipulators (BHSRMs) presents
unique challenges that differ fundamentally from conventional human-scale
systems. As these platforms gain relevance in industrial domains such as
construction, mining, and disaster response, immersive interfaces must be
rethought to support scalable, safe, and effective human-robot collaboration.
This paper investigates the control, cognitive, and interface-level challenges
of immersive teleoperation in BHSRMs, with a focus on ensuring operator safety,
minimizing sensorimotor mismatch, and enhancing the sense of embodiment. We
analyze design trade-offs in haptic and visual feedback systems, supported by
early experimental comparisons of exoskeleton- and joystick-based control
setups. Finally, we outline key research directions for developing new
evaluation tools, scaling strategies, and human-centered safety models tailored
to large-scale robotic telepresence.

</details>


### [395] [FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning](https://arxiv.org/abs/2508.09797)
*Dongcheng Cao,Jin Zhou,Xian Wang,Shuo Li*

Main category: cs.RO

TL;DR: A new RL framework, FLARE, enables agile and safe navigation for quadrotor cable-suspended payload systems, achieving faster maneuvers and real-world transfer without task-specific tuning.


<details>
  <summary>Details</summary>
Motivation: Traditional optimization-based methods struggle with the high computational costs and complexities of cable mode transitions in quadrotor cable-suspended payload systems, limiting real-time applicability and maneuverability.

Method: A reinforcement learning (RL) framework called FLARE is proposed, which learns agile navigation policies directly from high-fidelity simulation for quadrotor cable-suspended payload systems.

Result: FLARE outperforms a state-of-the-art optimization-based approach by a 3x speedup during gate traversal maneuvers and achieves successful zero-shot sim-to-real transfer, demonstrating remarkable agility and safety in real-world experiments.

Conclusion: The FLARE framework successfully learns agile navigation policies for quadrotor cable-suspended payload systems, demonstrating a 3x speedup in gate traversal maneuvers compared to optimization-based methods and achieving zero-shot sim-to-real transfer with real-time onboard execution.

Abstract: Agile flight for the quadrotor cable-suspended payload system is a formidable
challenge due to its underactuated, highly nonlinear, and hybrid dynamics.
Traditional optimization-based methods often struggle with high computational
costs and the complexities of cable mode transitions, limiting their real-time
applicability and maneuverability exploitation. In this letter, we present
FLARE, a reinforcement learning (RL) framework that directly learns agile
navigation policy from high-fidelity simulation. Our method is validated across
three designed challenging scenarios, notably outperforming a state-of-the-art
optimization-based approach by a 3x speedup during gate traversal maneuvers.
Furthermore, the learned policies achieve successful zero-shot sim-to-real
transfer, demonstrating remarkable agility and safety in real-world
experiments, running in real time on an onboard computer.

</details>


### [396] [Embodied Tactile Perception of Soft Objects Properties](https://arxiv.org/abs/2508.09836)
*Anirvan Dutta,Alexis WM Devillard,Zhihuan Zhang,Xiaoxiao Cheng,Etienne Burdet*

Main category: cs.RO

TL;DR: 该研究探讨了机械顺应性、多模态传感和交互如何影响机器人的触觉感知，并提出了一个名为“潜在滤波器”的深度状态空间模型来推断机械特性，最终证明多模态传感优于单模态传感。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人能够进行类似人类的精细操作，必须了解机械顺应性、多模态传感和有效交互如何共同塑造触觉感知。

Method: 提出了一种称为“潜在滤波器”的无监督、以动作条件化的深度状态空间模型，用于推断因果机械特性。

Result: 研究结果表明，多模态传感优于单模态传感，并揭示了环境与电子皮肤机械特性之间存在的细微相互作用。

Conclusion: 多模态传感优于单模态传感，并且应结合时间动态来研究环境与电子皮肤机械特性之间的相互作用。

Abstract: To enable robots to develop human-like fine manipulation, it is essential to
understand how mechanical compliance, multi-modal sensing, and purposeful
interaction jointly shape tactile perception. In this study, we use a dedicated
modular e-Skin with tunable mechanical compliance and multi-modal sensing
(normal, shear forces and vibrations) to systematically investigate how sensing
embodiment and interaction strategies influence robotic perception of objects.
Leveraging a curated set of soft wave objects with controlled viscoelastic and
surface properties, we explore a rich set of palpation primitives-pressing,
precession, sliding that vary indentation depth, frequency, and directionality.
In addition, we propose the latent filter, an unsupervised, action-conditioned
deep state-space model of the sophisticated interaction dynamics and infer
causal mechanical properties into a structured latent space. This provides
generalizable and in-depth interpretable representation of how embodiment and
interaction determine and influence perception. Our investigation demonstrates
that multi-modal sensing outperforms uni-modal sensing. It highlights a nuanced
interaction between the environment and mechanical properties of e-Skin, which
should be examined alongside the interaction by incorporating temporal
dynamics.

</details>


### [397] [QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds](https://arxiv.org/abs/2504.19716)
*Navin Sriram Ravie,Keerthi Vasan M,Asokan Thondiyath,Bijo Sebastian*

Main category: cs.RO

TL;DR: This paper presents a new, efficient analytical method for robotic grasping that works better than current methods, especially for tricky objects. It uses a smart way to find grasp points and is tested on real robots.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the long-standing challenge of robotic grasping and the limitations of existing methods. Current approaches often fail in real-life settings due to poor generalization and are limited by the time taken for grasp planning and lack of repeatability caused by sampling inefficiency and the probabilistic nature of existing methods.

Method: The paper proposes a lightweight analytical approach for robotic grasp planning, focusing on antipodal grasps. It formulates the problem as an optimization problem to estimate grasp points on the object surface, minimizing sampling in the six-degree-of-freedom space. A soft-region-growing algorithm is used for plane segmentation, especially on curved surfaces. An optimization-based quality metric evaluates grasp points to ensure indirect force closure. The approach is compared with GPD using simulated objects and evaluated in a real-world setting with a UR5 manipulator and ROBOTIQ gripper.

Result: The proposed grasp planning framework was compared with the GPD approach over multiple simulated objects and evaluated in a real-world setting. The results indicate the effectiveness of the proposed approach in comparison to GPD.

Conclusion: The proposed lightweight analytical approach for robotic grasp planning, particularly for antipodal grasps, shows effectiveness compared to the state-of-the-art GPD approach in both simulated and real-world settings. It offers improved generalization and repeatability by formulating grasp planning as an optimization problem focused on grasp points rather than end-effector pose, utilizing soft-region-growing for plane segmentation and an optimization-based quality metric for indirect force closure.

Abstract: Grasping has been a long-standing challenge in facilitating the final
interface between a robot and the environment. As environments and tasks become
complicated, the need to embed higher intelligence to infer from the
surroundings and act on them has become necessary. Although most methods
utilize techniques to estimate grasp pose by treating the problem via pure
sampling-based approaches in the six-degree-of-freedom space or as a learning
problem, they usually fail in real-life settings owing to poor generalization
across domains. In addition, the time taken to generate the grasp plan and the
lack of repeatability, owing to sampling inefficiency and the probabilistic
nature of existing grasp planning approaches, severely limits their application
in real-world tasks. This paper presents a lightweight analytical approach
towards robotic grasp planning, particularly antipodal grasps, with little to
no sampling in the six-degree-of-freedom space. The proposed grasp planning
algorithm is formulated as an optimization problem towards estimating grasp
points on the object surface instead of directly estimating the end-effector
pose. To this extent, a soft-region-growing algorithm is presented for
effective plane segmentation, even in the case of curved surfaces. An
optimization-based quality metric is then used for the evaluation of grasp
points to ensure indirect force closure. The proposed grasp framework is
compared with the existing state-of-the-art grasp planning approach, Grasp pose
detection (GPD), as a baseline over multiple simulated objects. The
effectiveness of the proposed approach in comparison to GPD is also evaluated
in a real-world setting using image and point-cloud data, with the planned
grasps being executed using a ROBOTIQ gripper and UR5 manipulator.

</details>


### [398] [Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation](https://arxiv.org/abs/2508.09846)
*Donghoon Baek,Amartya Purushottam,Jason J. Choi,Joao Ramos*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的轮式人形机器人遥操作框架，通过在线估计物体惯性参数来提高操作精度和反馈效果，并在实际机器人上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了实现更具动态性的全身遥操作，需要提高触觉力反馈的精确性，并补偿对象动力学以提升操纵跟踪精度和顺应性。

Method: 提出了一种面向轮式人形机器人仿人操作的物体感知全身双边遥操作框架，结合了在线多阶段物体惯性参数估计模块。该模块包括基于视觉的对象尺寸估计、基于大型视觉-语言模型（VLM）的初始参数猜测以及解耦的分层采样策略。

Result: 通过估计对象惯性参数，实时更新了轮式人形机器人的平衡点，提高了操作员的注意力和触觉力反馈的动态同步性，从而实现了更优的全身遥操作。

Conclusion: 该框架通过估计对象动力学参数来补偿对象动力学，从而提高操纵跟踪精度并保持顺应性行为。在定制的轮式人形机器人上进行了验证，展示了实时执行提、送、放任务的能力。

Abstract: This paper presents an object-aware whole-body bilateral teleoperation
framework for wheeled humanoid loco-manipulation. This framework combines
whole-body bilateral teleoperation with an online multi-stage object inertial
parameter estimation module, which is the core technical contribution of this
work. The multi-stage process sequentially integrates a vision-based object
size estimator, an initial parameter guess generated by a large vision-language
model (VLM), and a decoupled hierarchical sampling strategy. The visual size
estimate and VLM prior offer a strong initial guess of the object's inertial
parameters, significantly reducing the search space for sampling-based
refinement and improving the overall estimation speed. A hierarchical strategy
first estimates mass and center of mass, then infers inertia from object size
to ensure physically feasible parameters, while a decoupled multi-hypothesis
scheme enhances robustness to VLM prior errors. Our estimator operates in
parallel with high-fidelity simulation and hardware, enabling real-time online
updates. The estimated parameters are then used to update the wheeled
humanoid's equilibrium point, allowing the operator to focus more on locomotion
and manipulation. This integration improves the haptic force feedback for
dynamic synchronization, enabling more dynamic whole-body teleoperation. By
compensating for object dynamics using the estimated parameters, the framework
also improves manipulation tracking while preserving compliant behavior. We
validate the system on a customized wheeled humanoid with a robotic gripper and
human-machine interface, demonstrating real-time execution of lifting,
delivering, and releasing tasks with a payload weighing approximately one-third
of the robot's body weight.

</details>


### [399] [Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes](https://arxiv.org/abs/2508.09855)
*Yuekun Wu,Yik Lung Pang,Andrea Cavallaro,Changjae Oh*

Main category: cs.RO

TL;DR: 本研究提出了一种仅利用RGB图像来训练人机协作（HRT）策略的方法，解决了机器人操作策略学习中的视觉域差距问题。该方法利用高斯泼溅技术重建交接场景，生成包含图像-动作对的机器人演示，从而无需实际机器人训练或数据收集。实验结果表明，该方法在模拟和真实世界人机交接任务中均表现出色，提高了机器人的抓取稳定性和避免碰撞的能力，为实现更无缝、更稳健的人机协作提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 学习机器人操作策略，特别是在机器人协同任务（如人机交接）中，需要大量的真实世界机器人动作试验。模拟训练是一个有成本效益的替代方案，但模拟与机器人工作空间之间的视觉域差距仍然是一个主要限制。

Method: 提出了一种仅从RGB图像训练HRT策略的方法，无需实际机器人训练或数据收集。该策略学习器利用稀疏视角高斯泼溅重建人机交接场景，生成包含机器人演示的图像-动作对，这些图像-动作对由安装在机器人夹具上的摄像头捕获。

Result: 实验证明，该方法是人机交接任务的一种新颖且有效的表示，能够使机器人从人类手中稳定地接收物体，同时避免与人手发生碰撞。

Conclusion: 该方法为机器人到人的交接任务提供了一种新的有效表示，有助于实现更无缝、更稳健的人机协作。

Abstract: Human-robot teaming (HRT) systems often rely on large-scale datasets of human
and robot interactions, especially for close-proximity collaboration tasks such
as human-robot handovers. Learning robot manipulation policies from raw,
real-world image data requires a large number of robot-action trials in the
physical environment. Although simulation training offers a cost-effective
alternative, the visual domain gap between simulation and robot workspace
remains a major limitation. We introduce a method for training HRT policies,
focusing on human-to-robot handovers, solely from RGB images without the need
for real-robot training or real-robot data collection. The goal is to enable
the robot to reliably receive objects from a human with stable grasping while
avoiding collisions with the human hand. The proposed policy learner leverages
sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes
to generate robot demonstrations containing image-action pairs captured with a
camera mounted on the robot gripper. As a result, the simulated camera pose
changes in the reconstructed scene can be directly translated into gripper pose
changes. Experiments in both Gaussian Splatting reconstructed scene and
real-world human-to-robot handover experiments demonstrate that our method
serves as a new and effective representation for the human-to-robot handover
task, contributing to more seamless and robust HRT.

</details>


### [400] [A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion](https://arxiv.org/abs/2508.09876)
*Xiaowei Tan,Weizhong Jiang,Bi Zhang,Wanxin Chen,Yiwen Zhao,Ning Li,Lianqing Liu,Xingang Zhao*

Main category: cs.RO

TL;DR: 本研究提出了一种创新的外骨骼控制系统，通过胫骨角度实时调整辅助模式，实现了在步行、跑步和上下楼梯等多种运动模式下的稳定人机协调，并取得了积极的实验效果。


<details>
  <summary>Details</summary>
Motivation: 现有的外骨骼技术在稳定运动中表现良好，但在非稳定运动（如跑步、上下楼梯）中的应用研究不足，尤其是在适应步态变化方面。本研究旨在解决这一问题，探索外骨骼在非稳定运动中的辅助能力。

Method: 研究提出了一种基于胫骨角度的控制系统，包含一个在线辅助模式生成方法和一个基于模型的正馈控制方法。辅助模式被表述为一个以胫骨角度为自变量的双高斯模型，利用惯性测量单元（IMU）的测量数据，在线更新模型参数以适应个体间的生物力学差异。该控制系统采用了一个包含人类-外骨骼运动学和刚度模型作为正馈组件，以减少对历史控制数据的依赖。

Result: 实验结果验证了所提出的控制系统及其各组成部分的有效性，证明了其在不同运动模式下对步态扰动的鲁棒性，并揭示了外骨骼的机械辅助对用户产生的积极生物力学和生理学响应。

Conclusion: 该研究成功开发并验证了一种基于胫骨角度的控制系统，能够使电动外骨骼在非稳定运动中与人类步态实时协调，并能根据步态调整辅助模式，以匹配生物力学踝关节力矩模式。

Abstract: Exoskeletons have been shown to effectively assist humans during steady
locomotion. However, their effects on non-steady locomotion, characterized by
nonlinear phase progression within a gait cycle, remain insufficiently
explored, particularly across diverse activities. This work presents a shank
angle-based control system that enables the exoskeleton to maintain real-time
coordination with human gait, even under phase perturbations, while dynamically
shaping assistance profiles to match the biological ankle moment patterns
across walking, running, stair negotiation tasks. The control system consists
of an assistance profile online generation method and a model-based feedforward
control method. The assistance profile is formulated as a dual-Gaussian model
with the shank angle as the independent variable. Leveraging only IMU
measurements, the model parameters are updated online each stride to adapt to
inter- and intra-individual biomechanical variability. The profile tracking
control employs a human-exoskeleton kinematics and stiffness model as a
feedforward component, reducing reliance on historical control data due to the
lack of clear and consistent periodicity in non-steady locomotion. Three
experiments were conducted using a lightweight soft exoskeleton with multiple
subjects. The results validated the effectiveness of each individual method,
demonstrated the robustness of the control system against gait perturbations
across various activities, and revealed positive biomechanical and
physiological responses of human users to the exoskeleton's mechanical
assistance.

</details>


### [401] [PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces](https://arxiv.org/abs/2508.09950)
*Bida Ma,Nuo Xu,Chenkun Qi,Xin Liu,Yule Mo,Jinkai Wang,Chunpeng Lu*

Main category: cs.RO

TL;DR: 机器人的一种用于爬行空间的点云监督本体感觉运动强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 机器人用于爬行空间的腿式运动在空间受限结构中具有挑战性。爬行空间中，外感受运动学习方法受限于传感器在低可见度条件下的噪声和误差；本体感觉运动学习方法难以在爬行空间中行进，因为它们只能推断地面特征。

Method: 提出了一种用于机器人爬行空间的点云监督本体感觉运动强化学习方法。为估计机器人状态，设计了一个状态估计网络，利用历史本体感觉传感器数据来估计机器人周围环境的地面、空间特征以及机器人的碰撞状态。提出了一种用于有效提取地面和空间特征的点云处理方法，用于监督状态估计网络的学习。

Result: 与现有方法相比，该方法在爬行空间中展现出更敏捷的运动能力。

Conclusion: 该方法增强了机器人在非结构化和半结构化环境中的越障能力，并且不需要外部传感器，适用于爬行空间中的外殖机器人。

Abstract: The legged locomotion in spatially constrained structures (called crawl
spaces) is challenging. In crawl spaces, current exteroceptive locomotion
learning methods are limited by large noises and errors of the sensors in
possible low visibility conditions, and current proprioceptive locomotion
learning methods are difficult in traversing crawl spaces because only ground
features are inferred. In this study, a point cloud supervised proprioceptive
locomotion reinforcement learning method for legged robots in crawl spaces is
proposed. A state estimation network is designed to estimate the robot's
surrounding ground and spatial features as well as the robot's collision states
using historical proprioceptive sensor data. The point cloud is represented in
polar coordinate frame and a point cloud processing method is proposed to
efficiently extract the ground and spatial features that are used to supervise
the state estimation network learning. Comprehensive reward functions that
guide the robot to traverse through crawl spaces after collisions are designed.
Experiments demonstrate that, compared to existing methods, our method exhibits
more agile locomotion in crawl spaces. This study enhances the ability of
legged robots to traverse spatially constrained environments without requiring
exteroceptive sensors.

</details>


### [402] [GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation](https://arxiv.org/abs/2508.09960)
*Yifei Yao,Chengyuan Luo,Jiaheng Du,Wentao He,Jun-Guo Lu*

Main category: cs.RO

TL;DR: GBC框架通过创新的数据处理和学习算法，解决了机器人形态不通用的问题，实现了从人类运动到机器人动作的端到端解决方案，是创建通用机器人控制器的实用方法。


<details>
  <summary>Details</summary>
Motivation: 机器人形态各异导致数据处理和学习算法不通用，阻碍了类人机器人的发展。

Method: 本研究提出了广义行为克隆（GBC）框架，该框架通过自适应数据管道、可微分逆向动力学网络、DAgger-MMPPO算法和MMTransformer架构，实现了从人类运动到机器人动作的端到端解决方案。

Result: 通过在多种异构机器人上训练策略，并成功迁移到新的动作，验证了GBC的有效性和通用性。

Conclusion: 该研究首次提出了一个实用且统一的框架，用于创建真正通用的机器人控制器。

Abstract: The creation of human-like humanoid robots is hindered by a fundamental
fragmentation: data processing and learning algorithms are rarely universal
across different robot morphologies. This paper introduces the Generalized
Behavior Cloning (GBC) framework, a comprehensive and unified solution designed
to solve this end-to-end challenge. GBC establishes a complete pathway from
human motion to robot action through three synergistic innovations. First, an
adaptive data pipeline leverages a differentiable IK network to automatically
retarget any human MoCap data to any humanoid. Building on this foundation, our
novel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,
high-fidelity imitation policies. To complete the ecosystem, the entire
framework is delivered as an efficient, open-source platform based on Isaac
Lab, empowering the community to deploy the full workflow via simple
configuration scripts. We validate the power and generality of GBC by training
policies on multiple heterogeneous humanoids, demonstrating excellent
performance and transfer to novel motions. This work establishes the first
practical and unified pathway for creating truly generalized humanoid
controllers.

</details>


### [403] [Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model](https://arxiv.org/abs/2508.09971)
*Zihan Wang,Nina Mahmoudian*

Main category: cs.RO

TL;DR: 无人机在GPS信号弱的河流环境中进行自主跟踪，将河流跟踪形式化为覆盖控制问题，并将其视为一个次模马尔可夫决策过程。本文提出了一种结合边际增益优势估计（MGAE）、语义动态模型（SDM）和约束Actor动态估计器（CADE）的安全强化学习框架，以实现河流跟踪任务中的奖励与安全性的平衡。


<details>
  <summary>Details</summary>
Motivation: 无人机视觉引导的自主河流跟踪对于救援、监视和环境监测等应用至关重要，尤其是在GPS信号不可靠的密集河流环境中。

Method: 本文提出了一种名为“边际增益优势估计”（MGAE）的方法，用于改进奖励优势函数，通过使用从历史回合回报计算得出的滑动窗口基线，使优势估计与代理在非马尔可夫环境中不断演变的行为价值识别保持一致。此外，还开发了一种基于“水域语义掩模”的“语义动态模型”（SDM），用于比潜在视觉动态模型更具可解释性且数据效率更高地预测未来观测。最后，提出了“约束Actor动态估计器”（CADE）架构，它集成了Actor、成本估计器和SDM，用于成本优势估计，形成了一个能够解决部分可观察约束次模马尔可夫决策过程的模型安全强化学习框架。

Result: 仿真结果表明，MGAE比传统的基于Critic的方法（如广义优势估计）具有更快的收敛速度和更优越的性能。SDM提供了更准确的短期状态预测，使成本估计器能够更好地预测潜在的违规行为。

Conclusion: CADE框架成功地将安全约束整合到基于模型的强化学习中，其拉格朗日方法在训练过程中实现了奖励和安全性的软平衡，而安全层通过硬动作叠加在推理过程中提高了性能。

Abstract: Vision-driven autonomous river following by Unmanned Aerial Vehicles is
critical for applications such as rescue, surveillance, and environmental
monitoring, particularly in dense riverine environments where GPS signals are
unreliable. We formalize river following as a coverage control problem in which
the reward function is submodular, yielding diminishing returns as more unique
river segments are visited, thereby framing the task as a Submodular Markov
Decision Process. First, we introduce Marginal Gain Advantage Estimation, which
refines the reward advantage function by using a sliding window baseline
computed from historical episodic returns, thus aligning the advantage
estimation with the agent's evolving recognition of action value in
non-Markovian settings. Second, we develop a Semantic Dynamics Model based on
patchified water semantic masks that provides more interpretable and
data-efficient short-term prediction of future observations compared to latent
vision dynamics models. Third, we present the Constrained Actor Dynamics
Estimator architecture, which integrates the actor, the cost estimator, and SDM
for cost advantage estimation to form a model-based SafeRL framework capable of
solving partially observable Constrained Submodular Markov Decision Processes.
Simulation results demonstrate that MGAE achieves faster convergence and
superior performance over traditional critic-based methods like Generalized
Advantage Estimation. SDM provides more accurate short-term state predictions
that enable the cost estimator to better predict potential violations. Overall,
CADE effectively integrates safety regulation into model-based RL, with the
Lagrangian approach achieving the soft balance of reward and safety during
training, while the safety layer enhances performance during inference by hard
action overlay.

</details>


### [404] [Masquerade: Learning from In-the-wild Human Videos using Data-Editing](https://arxiv.org/abs/2508.09976)
*Marion Lepert,Jiaying Fang,Jeannette Bohg*

Main category: cs.RO

TL;DR: Masquerade 通过编辑人类视频来缩小人机视觉差距，并利用这些数据训练机器人策略，显著提高了机器人在厨房任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 机器人操作研究面临着严重的数据稀缺问题，与自然语言和视觉领域相比，即使是最大的机器人数据集在规模和多样性上也存在巨大差距。这阻碍了机器人技术的发展。因此，需要一种有效的方法来利用广泛可用的数据源，例如人类视频。

Method: 我们提出了一种名为 Masquerade 的方法，该方法通过编辑人类的自拍视频来弥合人与机器人之间的视觉具身差距。具体步骤包括：(i) 估计手部三维姿态，(ii) 修复被遮挡的人类手臂，(iii) 叠加一个能够跟踪恢复的末端执行器轨迹的机器人模型。我们首先在一个包含 675K 帧编辑后视频的大型数据集上预训练了一个视觉编码器，使其能够预测未来的二维机器人关键点。然后在仅有 50 个机器人演示的少量数据上，通过辅助损失进行微调，以学习扩散策略。

Result: Masquerade 方法在三个长时序、双臂协同的厨房任务上，并在三个未见过的场景中进行了评估。结果显示，Masquerade 的性能比基线方法提高了 5-6 倍。消融实验表明，机器人叠加和协同训练都是不可或缺的，并且性能随编辑后的人类视频数量的增加而呈对数增长。

Conclusion: 通过利用大量的人类视频数据，我们成功地缩小了视觉具身差距，并显著提高了机器人策略的泛化能力。实验结果表明，我们的方法在处理长时序、双臂协同的厨房任务方面，比现有方法有 5-6 倍的提升，并且性能随编辑后的人类视频数量呈对数增长。

Abstract: Robot manipulation research still suffers from significant data scarcity:
even the largest robot datasets are orders of magnitude smaller and less
diverse than those that fueled recent breakthroughs in language and vision. We
introduce Masquerade, a method that edits in-the-wild egocentric human videos
to bridge the visual embodiment gap between humans and robots and then learns a
robot policy with these edited videos. Our pipeline turns each human video into
robotized demonstrations by (i) estimating 3-D hand poses, (ii) inpainting the
human arms, and (iii) overlaying a rendered bimanual robot that tracks the
recovered end-effector trajectories. Pre-training a visual encoder to predict
future 2-D robot keypoints on 675K frames of these edited clips, and continuing
that auxiliary loss while fine-tuning a diffusion policy head on only 50 robot
demonstrations per task, yields policies that generalize significantly better
than prior work. On three long-horizon, bimanual kitchen tasks evaluated in
three unseen scenes each, Masquerade outperforms baselines by 5-6x. Ablations
show that both the robot overlay and co-training are indispensable, and
performance scales logarithmically with the amount of edited human video. These
results demonstrate that explicitly closing the visual embodiment gap unlocks a
vast, readily available source of data from human videos that can be used to
improve robot policies.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [405] [Reinforcement learning in densely recurrent biological networks](https://arxiv.org/abs/2508.09618)
*Miles Walter Churchland,Jordi Garcia-Ojalvo*

Main category: cs.NE

TL;DR: ENOMAD, a hybrid evolutionary and direct search method, efficiently trains recurrent networks by leveraging biological weight priors, outperforming existing methods on C. elegans foraging tasks.


<details>
  <summary>Details</summary>
Motivation: Training highly recurrent networks in continuous action spaces is a technical challenge due to exploding or vanishing gradients in gradient-based methods and slow convergence in high-dimensional weight spaces for evolutionary searches.

Method: A hybrid, derivative-free optimization framework that implements reinforcement learning by coupling global evolutionary exploration with local direct search exploitation, termed ENOMAD (Evolutionary Nonlinear Optimization with Mesh Adaptive Direct search).

Result: Both algorithmic variants of ENOMAD significantly exceed the performance of the untrained connectome and existing training strategies in food-foraging tasks in C. elegans.

Conclusion: integrating evolutionary search with nonlinear optimization provides an efficient, biologically grounded strategy for specializing natural recurrent networks towards a specified set of tasks.

Abstract: Training highly recurrent networks in continuous action spaces is a technical
challenge: gradient-based methods suffer from exploding or vanishing gradients,
while purely evolutionary searches converge slowly in high-dimensional weight
spaces. We introduce a hybrid, derivative-free optimization framework that
implements reinforcement learning by coupling global evolutionary exploration
with local direct search exploitation. The method, termed ENOMAD (Evolutionary
Nonlinear Optimization with Mesh Adaptive Direct search), is benchmarked on a
suite of food-foraging tasks instantiated in the fully mapped neural connectome
of the nematode \emph{Caenorhabditis elegans}. Crucially, ENOMAD leverages
biologically derived weight priors, letting it refine--rather than rebuild--the
organism's native circuitry. Two algorithmic variants of the method are
introduced, which lead to either small distributed adjustments of many weights,
or larger changes on a limited number of weights. Both variants significantly
exceed the performance of the untrained connectome (in what can be interpreted
as an example of transfer learning) and of existing training strategies. These
findings demonstrate that integrating evolutionary search with nonlinear
optimization provides an efficient, biologically grounded strategy for
specializing natural recurrent networks towards a specified set of tasks.

</details>
