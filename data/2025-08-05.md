<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 228]
- [cs.CL](#cs.CL) [Total: 101]
- [cs.SI](#cs.SI) [Total: 12]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.RO](#cs.RO) [Total: 58]
- [eess.SP](#eess.SP) [Total: 24]
- [cs.LO](#cs.LO) [Total: 5]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 21]
- [eess.SY](#eess.SY) [Total: 24]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 27]
- [cs.AI](#cs.AI) [Total: 85]
- [cs.DC](#cs.DC) [Total: 14]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 194]
- [cs.AR](#cs.AR) [Total: 7]
- [cs.ET](#cs.ET) [Total: 7]
- [quant-ph](#quant-ph) [Total: 59]
- [cs.DS](#cs.DS) [Total: 8]
- [eess.IV](#eess.IV) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Team PA-VCG's Solution for Competition on Understanding Chinese College Entrance Exam Papers in ICDAR'25](https://arxiv.org/abs/2508.00834)
*Wei Wu,Wenjie Wang,Yang Tan,Ying Liu,Liang Diao,Lin Huang,Kaihe Xu,Wenfeng Xie,Ziling Lin*

Main category: cs.CV

TL;DR: Team PA-VGG won first place in the ICDAR'25 Competition for Chinese College Entrance Exam Papers using high-resolution image processing, a multi-image input strategy, and specialized post-training methods, achieving 89.6% accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of dense OCR extraction and complex document layouts in Chinese College Entrance Exam Papers for the ICDAR'25 Competition.

Method: Leveraging high-resolution image processing, a multi-image end-to-end input strategy, and domain-specific post-training strategies.

Result: The post-training approach achieved the most outstanding performance, securing first place with an 89.6% accuracy rate.

Conclusion: Team PA-VGG's domain-specific post-training strategy achieves outstanding performance, securing first place with an 89.6% accuracy rate in the ICDAR'25 Competition.

Abstract: This report presents Team PA-VGG's solution for the ICDAR'25 Competition on
Understanding Chinese College Entrance Exam Papers. In addition to leveraging
high-resolution image processing and a multi-image end-to-end input strategy to
address the challenges of dense OCR extraction and complex document layouts in
Gaokao papers, our approach introduces domain-specific post-training
strategies. Experimental results demonstrate that our post-training approach
achieves the most outstanding performance, securing first place with an
accuracy rate of 89.6%.

</details>


### [2] [Inclusive Review on Advances in Masked Human Face Recognition Technologies](https://arxiv.org/abs/2508.00841)
*Ali Haitham Abdul Amir,Zainab N. Nemer*

Main category: cs.CV

TL;DR: Deep learning, especially CNNs and Siamese networks, is improving Masked Face Recognition (MFR) amidst challenges like masks obscuring features. This review covers techniques, applications, and future trends like multimedia integration.


<details>
  <summary>Details</summary>
Motivation: The COVID-19 pandemic and the widespread use of masks have created significant challenges for traditional facial recognition systems, necessitating advancements in Masked Face Recognition (MFR).

Method: This paper provides a comprehensive review of the latest developments in Masked Face Recognition (MFR), focusing on deep learning techniques like CNNs and Siamese networks. It discusses challenges, advanced technologies (data enhancement, multimedia methods), deep network design, feature extraction, evaluation criteria, datasets, and applications in security and medicine.

Result: The paper reviews advanced technologies, deep network designs, feature extraction techniques, evaluation criteria, and datasets used in MFR. It also highlights applications in security and medicine, and discusses future research trends.

Conclusion: Masked Face Recognition (MFR) is crucial due to COVID-19, with deep learning (CNNs, Siamese networks) driving accuracy improvements. Challenges include lighting, pose, occlusion, and mask types. Solutions involve data augmentation and advanced deep network designs. MFR has applications in security and medicine, with future trends focusing on efficient algorithms and multimedia integration.

Abstract: Masked Face Recognition (MFR) is an increasingly important area in biometric
recognition technologies, especially with the widespread use of masks as a
result of the COVID-19 pandemic. This development has created new challenges
for facial recognition systems due to the partial concealment of basic facial
features. This paper aims to provide a comprehensive review of the latest
developments in the field, with a focus on deep learning techniques, especially
convolutional neural networks (CNNs) and twin networks (Siamese networks),
which have played a pivotal role in improving the accuracy of covering face
recognition. The paper discusses the most prominent challenges, which include
changes in lighting, different facial positions, partial concealment, and the
impact of mask types on the performance of systems. It also reviews advanced
technologies developed to overcome these challenges, including data enhancement
using artificial databases and multimedia methods to improve the ability of
systems to generalize. In addition, the paper highlights advance in deep
network design, feature extraction techniques, evaluation criteria, and data
sets used in this area. Moreover, it reviews the various applications of masked
face recognition in the fields of security and medicine, highlighting the
growing importance of these systems in light of recurrent health crises and
increasing security threats. Finally, the paper focuses on future research
trends such as developing more efficient algorithms and integrating multimedia
technologies to improve the performance of recognition systems in real-world
environments and expand their applications.

</details>


### [3] [HoneyImage: Verifiable, Harmless, and Stealthy Dataset Ownership Verification for Image Models](https://arxiv.org/abs/2508.00892)
*Zhihao Zhu,Jiale Han,Yi Yang*

Main category: cs.CV

TL;DR: HoneyImage是一种新的数据集所有权验证方法，通过修改难样本嵌入水印，在不影响模型性能和人类感知的情况下，提供可靠的数据集所有权验证。


<details>
  <summary>Details</summary>
Motivation: 许多图像数据集包含敏感或专有内容，引发了关于未经授权使用数据的担忧。因此，数据所有者需要可靠的机制来验证其专有数据是否被用于训练第三方模型。现有的解决方案（如后门水印和成员推理）在验证效果和数据完整性保护之间存在固有的权衡。

Method: HoneyImage通过选择性地修改一小部分难样本来嵌入不易察觉但可验证的痕迹，以实现对图像识别模型数据集的所有权验证，同时保持数据集的完整性。

Result: HoneyImage在四个基准数据集和多种模型架构上的广泛实验表明，该方法在保持对下游性能的影响极小且不可察觉的情况下，始终能实现强大的验证准确性。

Conclusion: HoneyImage提供了一种新颖的、对下游模型性能影响极小且对人眼不可见的图像识别模型数据集所有权验证方法。该方法通过选择性地修改少量难样本来嵌入可验证的痕迹，从而在保持数据集完整性的同时实现可靠的所有权验证。实验证明，HoneyImage在多个基准数据集和模型架构上均能达到高验证准确率，为数据所有者提供了一种保护其宝贵图像数据集所有权的可行机制，鼓励安全共享并释放数据驱动人工智能的全部潜力。

Abstract: Image-based AI models are increasingly deployed across a wide range of
domains, including healthcare, security, and consumer applications. However,
many image datasets carry sensitive or proprietary content, raising critical
concerns about unauthorized data usage. Data owners therefore need reliable
mechanisms to verify whether their proprietary data has been misused to train
third-party models. Existing solutions, such as backdoor watermarking and
membership inference, face inherent trade-offs between verification
effectiveness and preservation of data integrity. In this work, we propose
HoneyImage, a novel method for dataset ownership verification in image
recognition models. HoneyImage selectively modifies a small number of hard
samples to embed imperceptible yet verifiable traces, enabling reliable
ownership verification while maintaining dataset integrity. Extensive
experiments across four benchmark datasets and multiple model architectures
show that HoneyImage consistently achieves strong verification accuracy with
minimal impact on downstream performance while maintaining imperceptible. The
proposed HoneyImage method could provide data owners with a practical mechanism
to protect ownership over valuable image datasets, encouraging safe sharing and
unlocking the full transformative potential of data-driven AI.

</details>


### [4] [Phase-fraction guided denoising diffusion model for augmenting multiphase steel microstructure segmentation via micrograph image-mask pair synthesis](https://arxiv.org/abs/2508.00896)
*Hoang Hai Nam Nguyen,Minh Tien Tran,Hoheok Kim,Ho Won Lee*

Main category: cs.CV

TL;DR: PF-DiffSeg是一种新的扩散模型，可以同时生成金属微观结构图像和分割掩码，通过控制相位分数来提高分割精度，尤其是在稀有类别上。


<details>
  <summary>Details</summary>
Motivation: 为了解决金相微观结构分割中由于缺乏人工标注的相位掩码（尤其是在稀有或成分复杂的形态方面）而导致的机器学习有效性受限问题。

Method: 提出了一种名为PF-DiffSeg的相位分数控制的单阶段去噪扩散框架，该框架在单一生成过程中联合合成微观结构图像及其对应的分割掩码。通过条件化全局相位分数向量，并增强以代表真实数据分布和强调少数类别，模型能够生成成分有效且结构连贯的微观结构图像和掩码样本。

Result: 在用于增材制造多相钢的MetalDAM基准测试中，PF-DiffSeg在分割准确性方面相对于标准的增强策略（尤其是在少数类别方面）取得了显著改进，并且优于两阶段掩码引导扩散和生成对抗网络（GAN）基线，同时减少了推理时间。

Conclusion: PF-DiffSeg通过联合生成微观结构图像和分割掩码，并结合相位分数控制和数据增强，在金相微观结构分割任务中取得了显著的准确性提升，尤其是在少数类别方面，同时提高了训练效率和数据多样性，为金相应用提供了可扩展的数据增强解决方案。

Abstract: The effectiveness of machine learning in metallographic microstructure
segmentation is often constrained by the lack of human-annotated phase masks,
particularly for rare or compositionally complex morphologies within the metal
alloy. We introduce PF-DiffSeg, a phase-fraction controlled, one-stage
denoising diffusion framework that jointly synthesizes microstructure images
and their corresponding segmentation masks in a single generative trajectory to
further improve segmentation accuracy. By conditioning on global phase-fraction
vectors, augmented to represent real data distribution and emphasize minority
classes, our model generates compositionally valid and structurally coherent
microstructure image and mask samples that improve both data diversity and
training efficiency. Evaluated on the MetalDAM benchmark for additively
manufactured multiphase steel, our synthetic augmentation method yields notable
improvements in segmentation accuracy compared to standard augmentation
strategies especially in minority classes and further outperforms a two-stage
mask-guided diffusion and generative adversarial network (GAN) baselines, while
also reducing inference time compared to conventional approach. The method
integrates generation and conditioning into a unified framework, offering a
scalable solution for data augmentation in metallographic applications.

</details>


### [5] [Benefits of Feature Extraction and Temporal Sequence Analysis for Video Frame Prediction: An Evaluation of Hybrid Deep Learning Models](https://arxiv.org/abs/2508.00898)
*Jose M. Sánchez Velázquez,Mingbo Cai,Andrew Coney,Álvaro J. García- Tejedor,Alberto Nogales*

Main category: cs.CV

TL;DR: 本研究评估了结合自编码器和RNN/3D CNN的混合深度学习方法在视频帧预测中的应用。结果表明，结合3DCNN和ConvLSTM的模型效果最佳，SSIM提升至0.82，且灰度视频和真实数据最易预测。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在计算机视觉领域取得了显著进展，但视频帧预测模型仍有提升空间。该研究旨在评估和改进视频帧预测技术，以满足天气预报、自动驾驶系统、视频压缩和流媒体等领域的应用需求。

Method: 评估了结合自编码器特征提取能力与循环神经网络（RNN）、3D卷积神经网络（3D CNN）及相关架构的时间序列建模的混合深度学习方法。

Result: 所提出的混合深度学习方法在三个不同类型的数据集（包括合成与真实世界场景、灰度与彩色图像）上进行了严格评估，结果显示SSIM指标从0.69提升至0.82，其中结合3DCNN和ConvLSTM的模型效果最佳，且灰度视频和真实数据最易预测。

Conclusion: 混合深度学习方法，特别是结合了3DCNN和ConvLSTM的模型，在视频帧预测任务上表现出色，SSIM指标从0.69提升至0.82。灰度视频和真实世界场景数据最易于预测。

Abstract: In recent years, advances in Artificial Intelligence have significantly
impacted computer science, particularly in the field of computer vision,
enabling solutions to complex problems such as video frame prediction. Video
frame prediction has critical applications in weather forecasting or autonomous
systems and can provide technical improvements, such as video compression and
streaming. Among Artificial Intelligence methods, Deep Learning has emerged as
highly effective for solving vision-related tasks, although current frame
prediction models still have room for enhancement. This paper evaluates several
hybrid deep learning approaches that combine the feature extraction
capabilities of autoencoders with temporal sequence modelling using Recurrent
Neural Networks (RNNs), 3D Convolutional Neural Networks (3D CNNs), and related
architectures. The proposed solutions were rigorously evaluated on three
datasets that differ in terms of synthetic versus real-world scenarios and
grayscale versus color imagery. Results demonstrate that the approaches perform
well, with SSIM metrics increasing from 0.69 to 0.82, indicating that hybrid
models utilizing 3DCNNs and ConvLSTMs are the most effective, and greyscale
videos with real data are the easiest to predict.

</details>


### [6] [TESPEC: Temporally-Enhanced Self-Supervised Pretraining for Event Cameras](https://arxiv.org/abs/2508.00913)
*Mohammad Mohammadi,Ziyi Wu,Igor Gilitschenski*

Main category: cs.CV

TL;DR: TESPEC 是一个用于事件感知任务的自监督预训练框架，它通过利用长事件序列和创新的重建目标来学习时空信息，从而在各种下游任务中提高了性能。


<details>
  <summary>Details</summary>
Motivation: 当前的自监督学习（SSL）方法主要模仿基于 RGB 图像的方法，在短时间间隔内预训练前馈模型，忽略了事件的时序信息。然而，当利用自监督预训练权重时，前馈模型可能优于循环模型。为了解决这个问题，本研究提出了 TESPEC 框架，专门用于学习时空信息，并且适用于循环模型。

Method: TESPEC 框架通过掩码图像建模范式和新的重建目标来学习时空信息。该框架通过一种新颖的方法将事件累积成伪灰度视频，以捕捉高层语义信息，并能很好地处理传感器噪声和运动模糊，从而促使模型能够推理事件的长期历史。

Result: TESPEC 框架在下游任务中取得了最先进的成果，包括目标检测、语义分割和单目深度估计。

Conclusion: TESPEC 框架能够有效学习时空信息，并在下游任务中取得最先进的成果，包括目标检测、语义分割和单目深度估计。

Abstract: Long-term temporal information is crucial for event-based perception tasks,
as raw events only encode pixel brightness changes. Recent works show that when
trained from scratch, recurrent models achieve better results than feedforward
models in these tasks. However, when leveraging self-supervised pre-trained
weights, feedforward models can outperform their recurrent counterparts.
Current self-supervised learning (SSL) methods for event-based pre-training
largely mimic RGB image-based approaches. They pre-train feedforward models on
raw events within a short time interval, ignoring the temporal information of
events. In this work, we introduce TESPEC, a self-supervised pre-training
framework tailored for learning spatio-temporal information. TESPEC is
well-suited for recurrent models, as it is the first framework to leverage long
event sequences during pre-training. TESPEC employs the masked image modeling
paradigm with a new reconstruction target. We design a novel method to
accumulate events into pseudo grayscale videos containing high-level semantic
information about the underlying scene, which is robust to sensor noise and
reduces motion blur. Reconstructing this target thus requires the model to
reason about long-term history of events. Extensive experiments demonstrate our
state-of-the-art results in downstream tasks, including object detection,
semantic segmentation, and monocular depth estimation. Project webpage:
https://mhdmohammadi.github.io/TESPEC_webpage.

</details>


### [7] [Latent Diffusion Based Face Enhancement under Degraded Conditions for Forensic Face Recognition](https://arxiv.org/abs/2508.00941)
*Hassan Ugail,Hamad Mansour Alawar,AbdulNasser Abbas Zehi,Ahmed Mohammad Alkendi,Ismail Lujain Jaleel*

Main category: cs.CV

TL;DR: 本研究评估了基于扩散模型的面部增强技术，以提高在法证退化情况下面部识别的性能。结果显示，准确性从29.1%提高到84.5%，证明了该技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有面部识别系统在处理低质量法证证据图像时性能严重下降的问题，本研究旨在评估基于潜在扩散模型的增强技术在改善此类情况下的面部识别性能。

Method: 本研究采用了基于潜在扩散模型的增强方法，并结合了Flux.1 Kontext Dev流程和Facezoom LoRA适配技术，以评估其在不同退化类别（包括压缩伪影、模糊和噪声）下的表现。

Result: 本研究使用包含3000个个体、24000次识别尝试的数据集，在七种退化类别下对所提出的方法进行了测试。结果显示，面部识别的整体准确性从29.1%提高到84.5%，提升了55.4个百分点。统计分析表明，该方法在所有退化类型下均有显著的性能提升，效果大小超过了实际意义的常规阈值。

Conclusion: 本研究表明，基于扩散模型的面部增强技术在处理低质量的法医图像方面具有显著的潜力，能够大幅提升面部识别的准确性，为法证面部识别应用提供了新的可能性。

Abstract: Face recognition systems experience severe performance degradation when
processing low-quality forensic evidence imagery. This paper presents an
evaluation of latent diffusion-based enhancement for improving face recognition
under forensically relevant degradations. Using a dataset of 3,000 individuals
from LFW with 24,000 recognition attempts, we implement the Flux.1 Kontext Dev
pipeline with Facezoom LoRA adaptation to test against seven degradation
categories, including compression artefacts, blur effects, and noise
contamination. Our approach demonstrates substantial improvements, increasing
overall recognition accuracy from 29.1% to 84.5% (55.4 percentage point
improvement, 95% CI: [54.1, 56.7]). Statistical analysis reveals significant
performance gains across all degradation types, with effect sizes exceeding
conventional thresholds for practical significance. These findings establish
the potential of sophisticated diffusion based enhancement in forensic face
recognition applications.

</details>


### [8] [Optimizing Vision-Language Consistency via Cross-Layer Regional Attention Alignment](https://arxiv.org/abs/2508.00945)
*Yifan Wang,Hongfeng Ai,Quangao Liu,Maowei Jiang,Ruiyuan Kang,Ruiqi Li,Jiahua Dong,Mengting Xiao,Cheng Jiang,Chenzhong Li*

Main category: cs.CV

TL;DR: CCRA通过LPWCA和PAI协调注意力机制，提高了VLM在跨模态学习中的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在有效协调用于跨模态嵌入学习的各种注意力机制方面面临挑战，导致注意力不匹配和次优性能。

Method: CCRA提出了一致性跨层区域对齐（CCRA），包括层-块级跨注意力（LPWCA）和渐进注意力集成（PAI）。LPWCA通过联合加权块和层级嵌入来捕捉细粒度的区域-语义相关性。PAI按顺序系统地协调LPWCA、层级和块级注意力机制。

Result: CCRA增强的LLaVA-v1.5-7B模型在十个不同的视觉-语言基准测试中取得了最先进的性能，其参数量仅增加了3.55M，同时通过更具区域针对性和语义对齐的注意力模式提供了增强的可解释性。

Conclusion: CCRA在十个不同的视觉-语言基准测试中取得了最先进的性能，超过了所有基线方法，同时只增加了3.55M参数，并通过更具区域针对性和语义对齐的注意力模式增强了解释性。

Abstract: Vision Language Models (VLMs) face challenges in effectively coordinating
diverse attention mechanisms for cross-modal embedding learning, leading to
mismatched attention and suboptimal performance. We propose Consistent
Cross-layer Regional Alignment (CCRA), which introduces Layer-Patch-wise Cross
Attention (LPWCA) to capture fine-grained regional-semantic correlations by
jointly weighting patch and layer-wise embedding, and Progressive Attention
Integration (PAI) that systematically coordinates LPWCA, layer-wise, and
patch-wise attention mechanisms in sequence. This progressive design ensures
consistency from semantic to regional levels while preventing attention drift
and maximizing individual attention benefits. Experimental results on ten
diverse vision-language benchmarks demonstrate that our CCRA-enhanced
LLaVA-v1.5-7B model achieves state-of-the-art performance, outperforming all
baseline methods with only 3.55M additional parameters, while providing
enhanced interpretability through more regionally focused and semantically
aligned attention patterns.

</details>


### [9] [ThermoCycleNet: Stereo-based Thermogram Labeling for Model Transition to Cycling](https://arxiv.org/abs/2508.00974)
*Daniel Andrés López,Vincent Weber,Severin Zentgraf,Barlo Hillen,Perikles Simon,Elmar Schömer*

Main category: cs.CV

TL;DR: 红外热成像在运动医学中具有应用前景。通过结合自动生成的标签和少量手动标注的数据，可以加速深度神经网络在新的应用场景（如从跑步机到功率计自行车）中的适应性，从而提高其性能。


<details>
  <summary>Details</summary>
Motivation: 将基于立体和多模态的标签方法从跑步机转移到功率计自行车，以利用红外热成像技术在运动医学中的应用。

Method: 通过训练用于语义分割的网络，并使用自动生成的标签和手动标注的图像进行微调，在不同的数据集组合中进行检查和比较。

Result: 结果表明，使用少量手动数据进行微调足以提高深度神经网络的整体性能。

Conclusion: 结合自动生成标签和少量手动标注数据可以加速深度神经网络适应新用例，例如从跑步机转移到自行车。

Abstract: Infrared thermography is emerging as a powerful tool in sports medicine,
allowing assessment of thermal radiation during exercise and analysis of
anatomical regions of interest, such as the well-exposed calves. Building on
our previous advanced automatic annotation method, we aimed to transfer the
stereo- and multimodal-based labeling approach from treadmill running to
ergometer cycling. Therefore, the training of the semantic segmentation network
with automatic labels and fine-tuning on high-quality manually annotated images
has been examined and compared in different data set combinations. The results
indicate that fine-tuning with a small fraction of manual data is sufficient to
improve the overall performance of the deep neural network. Finally, combining
automatically generated labels with small manually annotated data sets
accelerates the adaptation of deep neural networks to new use cases, such as
the transition from treadmill to bicycle.

</details>


### [10] [ROVI: A VLM-LLM Re-Captioned Dataset for Open-Vocabulary Instance-Grounded Text-to-Image Generation](https://arxiv.org/abs/2508.01008)
*Cihang Peng,Qiming Hou,Zhong Ren,Kun Zhou*

Main category: cs.CV

TL;DR: ROVI是一个高质量的、用于实例定位的文本到图像生成合成数据集，通过“重新题词”策略创建，包含百万级标注图像和海量类别，显著提升了实例定位和文本到图像生成的效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数据集在图像质量、分辨率和类别数量上的不足，并提高文本到图像生成和实例定位的性能。

Method: ROVI数据集的创建策略是“重新题词”，该策略首先利用视觉-语言模型（VLM）生成详细的视觉描述，然后利用大型语言模型（LLM）处理这些描述，以提取供开放词汇检测器（OVD）使用的类别列表。

Result: ROVI数据集在图像质量和分辨率上优于现有数据集，包含的类别数量是现有数据集的两倍，并且支持开放词汇检测。在ROVI上训练的GLIGEN模型在实例定位准确性、提示保真度和美学质量方面表现优于其他最先进的模型。

Conclusion: ROVI数据集和其流水线已开源，并且ROVI在实例定位准确性、提示保真度和美学质量方面显著优于其他同类方法。

Abstract: We present ROVI, a high-quality synthetic dataset for instance-grounded
text-to-image generation, created by labeling 1M curated web images. Our key
innovation is a strategy called re-captioning, focusing on the pre-detection
stage, where a VLM (Vision-Language Model) generates comprehensive visual
descriptions that are then processed by an LLM (Large Language Model) to
extract a flat list of potential categories for OVDs (Open-Vocabulary
Detectors) to detect. This approach yields a global prompt inherently linked to
instance annotations while capturing secondary visual elements humans typically
overlook. Evaluations show that ROVI exceeds existing detection datasets in
image quality and resolution while containing two orders of magnitude more
categories with an open-vocabulary nature. For demonstrative purposes, a
text-to-image model GLIGEN trained on ROVI significantly outperforms
state-of-the-art alternatives in instance grounding accuracy, prompt fidelity,
and aesthetic quality. Our dataset and reproducible pipeline are available at
https://github.com/CihangPeng/ROVI.

</details>


### [11] [AutoSIGHT: Automatic Eye Tracking-based System for Immediate Grading of Human experTise](https://arxiv.org/abs/2508.01015)
*Byron Dowling,Jozef Probcin,Adam Czajka*

Main category: cs.CV

TL;DR: 本研究提出了AutoSIGHT，一个利用眼动追踪数据自动评估人类在视觉任务中专业知识的系统，并在虹膜PAD任务上取得了良好的效果，为人类-AI协作提供了新的研究方向。


<details>
  <summary>Details</summary>
Motivation: 旨在研究能否通过眼动追踪特征自动评估人类在视觉任务中的专业知识。

Method: AutoSIGHT系统通过集成从眼动追踪数据中提取的特征，对解决视觉任务的专家和非专家进行分类。

Result: 在虹膜PAD任务上，AutoSIGHT在5秒评估窗口内实现了0.751的平均AUROC，在30秒评估窗口内实现了0.8306的AUROC，证明了自动评估人类专业知识的可行性。

Conclusion: 本研究表明，利用眼动追踪数据自动评估人类在视觉任务中的专业知识是可行的，并提出了AutoSIGHT系统，该系统在5秒的评估窗口内达到了0.751的平均ROC曲线下面积（AUROC），在30秒的评估窗口内达到了0.8306的AUROC。这项工作为人类-AI协作场景中自动衡量人类和机器专业知识开辟了新的研究领域，并提供了用于虹膜呈现攻击检测（PAD）任务的眼动追踪数据集。

Abstract: Can we teach machines to assess the expertise of humans solving visual tasks
automatically based on eye tracking features? This paper proposes AutoSIGHT,
Automatic System for Immediate Grading of Human experTise, that classifies
expert and non-expert performers, and builds upon an ensemble of features
extracted from eye tracking data while the performers were solving a visual
task. Results on the task of iris Presentation Attack Detection (PAD) used for
this study show that with a small evaluation window of just 5 seconds,
AutoSIGHT achieves an average average Area Under the ROC curve performance of
0.751 in subject-disjoint train-test regime, indicating that such detection is
viable. Furthermore, when a larger evaluation window of up to 30 seconds is
available, the Area Under the ROC curve (AUROC) increases to 0.8306, indicating
the model is effectively leveraging more information at a cost of slightly
delayed decisions. This work opens new areas of research on how to incorporate
the automatic weighing of human and machine expertise into human-AI pairing
setups, which need to react dynamically to nonstationary expertise distribution
between the human and AI players (e.g. when the experts need to be replaced, or
the task at hand changes rapidly). Along with this paper, we offer the eye
tracking data used in this study collected from 6 experts and 53 non-experts
solving iris PAD visual task.

</details>


### [12] [3D Reconstruction via Incremental Structure From Motion](https://arxiv.org/abs/2508.01019)
*Muhammad Zeeshan,Umer Zaki,Syed Ahmed Pasha,Zaar Khizar*

Main category: cs.CV

TL;DR: 增量式 SfM 通过逐步引入新视图来重建 3D 场景和相机运动，即使在稀疏或部分重叠的数据集中也是如此。该论文详细介绍了其实现，强调了几何估计和迭代优化的重要性，并使用真实数据证明了其在稀疏 3D 重建中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为机器人、绘图和场景理解等应用实现从非结构化图像集合中进行准确的 3D 重建，并克服全局 SfM 技术对完整图像连通性的依赖和对噪声或缺失数据的敏感性。

Method: 通过详细实现增量式 SfM 流程，关注几何估计的一致性和通过联合优化的迭代优化。

Result: 使用真实数据集演示了该方法，并通过重投影误差和相机轨迹相干性评估重建质量。

Conclusion: 增量式 SfM 是一种可靠的稀疏 3D 重建方法，尤其适用于视觉结构化环境。

Abstract: Accurate 3D reconstruction from unstructured image collections is a key
requirement in applications such as robotics, mapping, and scene understanding.
While global Structure from Motion (SfM) techniques rely on full image
connectivity and can be sensitive to noise or missing data, incremental SfM
offers a more flexible alternative. By progressively incorporating new views
into the reconstruction, it enables the system to recover scene structure and
camera motion even in sparse or partially overlapping datasets. In this paper,
we present a detailed implementation of the incremental SfM pipeline, focusing
on the consistency of geometric estimation and the effect of iterative
refinement through bundle adjustment. We demonstrate the approach using a real
dataset and assess reconstruction quality through reprojection error and camera
trajectory coherence. The results support the practical utility of incremental
SfM as a reliable method for sparse 3D reconstruction in visually structured
environments.

</details>


### [13] [Structured Spectral Graph Learning for Anomaly Classification in 3D Chest CT Scans](https://arxiv.org/abs/2508.01045)
*Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel*

Main category: cs.CV

TL;DR: CT影像分析的挑战：现有3D CNN和ViT方法存在局限性。新方法：提出基于图的方法，将CT影像视为图，利用谱域卷积处理轴向切片三元组节点。优势：提升多标签异常分类性能，具备良好的跨数据集泛化能力和对z轴平移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了应对CT扫描数量增加导致放射科医生工作量增加的问题，需要自动化方法（如器官分割、异常检测和报告生成）来协助放射科医生。现有的3D卷积网络在模拟长距离依赖方面能力有限，而视觉Transformer计算成本高且需要大规模预训练。

Method: 提出了一种新的基于图的方法，将CT扫描建模为结构化图，利用经过谱域卷积处理的轴向切片三元组节点来增强多标签异常分类性能。

Result: 所提出的基于图的方法在多标签异常分类方面取得了具有竞争力的性能，并且表现出强大的跨数据集泛化能力和对z轴平移的鲁棒性。

Conclusion:  该方法在CT图像的多标签异常分类任务上表现出强大的跨数据集泛化能力、鲁棒性（对z轴平移不敏感）和有竞争力的性能。

Abstract: With the increasing number of CT scan examinations, there is a need for
automated methods such as organ segmentation, anomaly detection and report
generation to assist radiologists in managing their increasing workload.
Multi-label classification of 3D CT scans remains a critical yet challenging
task due to the complex spatial relationships within volumetric data and the
variety of observed anomalies. Existing approaches based on 3D convolutional
networks have limited abilities to model long-range dependencies while Vision
Transformers suffer from high computational costs and often require extensive
pre-training on large-scale datasets from the same domain to achieve
competitive performance. In this work, we propose an alternative by introducing
a new graph-based approach that models CT scans as structured graphs,
leveraging axial slice triplets nodes processed through spectral domain
convolution to enhance multi-label anomaly classification performance. Our
method exhibits strong cross-dataset generalization, and competitive
performance while achieving robustness to z-axis translation. An ablation study
evaluates the contribution of each proposed component.

</details>


### [14] [EgoTrigger: Toward Audio-Driven Image Capture for Human Memory Enhancement in All-Day Energy-Efficient Smart Glasses](https://arxiv.org/abs/2508.01915)
*Akshay Paruchuri,Sinan Hersek,Lavisha Aggarwal,Qiao Yang,Xin Liu,Achin Kulshrestha,Andrea Colaco,Henry Fuchs,Ishan Chatterjee*

Main category: cs.CV

TL;DR: EgoTrigger 通过利用音频线索（如开抽屉或药瓶的声音）来智能触发智能眼镜的摄像头，从而显著节省了电量（平均减少 54% 的帧数），同时仍能有效支持记忆增强任务，为实现全天候智能眼镜铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 在智能眼镜上集成多模态人工智能代理以增强人类记忆，同时进行连续传感，面临着严峻的能效挑战，这对于全天候使用至关重要。实现这一平衡需要智能的、上下文感知的传感器管理。

Method: EgoTrigger 利用麦克风的音频线索选择性地激活功耗高的摄像头，并通过轻量级音频模型（YAMNet）和自定义分类头来触发从手-物体交互（HOI）音频线索（例如抽屉打开声或药瓶打开声）的图像捕获。

Result: EgoTrigger 平均可减少 54% 的帧数，显著节省了功耗（例如摄像头）和下游操作（例如无线传输）的能耗，同时在偶发性记忆任务的数据集上取得了可比的性能。

Conclusion: 该研究提出的 EgoTrigger 上下文感知触发策略为实现节能、功能性的全天候智能眼镜提供了一个有前景的方向，可支持用户回忆钥匙放置位置或日常活动信息（例如服药）等应用。

Abstract: All-day smart glasses are likely to emerge as platforms capable of continuous
contextual sensing, uniquely positioning them for unprecedented assistance in
our daily lives. Integrating the multi-modal AI agents required for human
memory enhancement while performing continuous sensing, however, presents a
major energy efficiency challenge for all-day usage. Achieving this balance
requires intelligent, context-aware sensor management. Our approach,
EgoTrigger, leverages audio cues from the microphone to selectively activate
power-intensive cameras, enabling efficient sensing while preserving
substantial utility for human memory enhancement. EgoTrigger uses a lightweight
audio model (YAMNet) and a custom classification head to trigger image capture
from hand-object interaction (HOI) audio cues, such as the sound of a drawer
opening or a medication bottle being opened. In addition to evaluating on the
QA-Ego4D dataset, we introduce and evaluate on the Human Memory Enhancement
Question-Answer (HME-QA) dataset. Our dataset contains 340 human-annotated
first-person QA pairs from full-length Ego4D videos that were curated to ensure
that they contained audio, focusing on HOI moments critical for contextual
understanding and memory. Our results show EgoTrigger can use 54% fewer frames
on average, significantly saving energy in both power-hungry sensing components
(e.g., cameras) and downstream operations (e.g., wireless transmission), while
achieving comparable performance on datasets for an episodic memory task. We
believe this context-aware triggering strategy represents a promising direction
for enabling energy-efficient, functional smart glasses capable of all-day use
-- supporting applications like helping users recall where they placed their
keys or information about their routine activities (e.g., taking medications).

</details>


### [15] [Evading Data Provenance in Deep Neural Networks](https://arxiv.org/abs/2508.01074)
*Hongyu Zhu,Sichu Liang,Wenwen Wang,Zhuomeng Zhang,Fangqi Li,Shi-Lin Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种新的方法来规避数据集所有权验证（DOV）技术，该技术通过知识转移来隐藏版权标识，并证明了现有DOV方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究在评估数据集所有权验证（DOV）方法的有效性时，依赖于过于简化的规避攻击，这可能导致对其安全性的错误判断。本研究旨在揭示DOV方法的实际漏洞，并提出更有效的规避策略。

Method: 本研究提出了一种统一的规避框架，该框架包括一个教师模型和一个学生模型。教师模型首先从受版权保护的数据集进行学习，然后利用分布外（OOD）数据集作为中介，将任务相关但标识符无关的领域知识转移给学生模型。研究利用了视觉-语言模型和大型语言模型来筛选信息最丰富、最可靠的OOD子集作为最终的转移集，并通过选择性地转移面向任务的知识来实现泛化性和规避有效性之间的权衡。

Result: 实验结果表明，本研究提出的方法能够同时消除所有版权标识，并且在泛化性和有效性方面显著优于九种最先进的规避攻击方法，同时计算开销适中。这证明了当前DOV方法的脆弱性。

Conclusion: 本研究揭示了当前数据集所有权验证（DOV）方法的关键漏洞，并表明现有方法的有效性可能被高估。研究提出了一种新的规避框架，通过知识转移来消除版权标识并有效规避检测，同时在泛化性和有效性方面优于现有攻击方法。

Abstract: Modern over-parameterized deep models are highly data-dependent, with large
scale general-purpose and domain-specific datasets serving as the bedrock for
rapid advancements. However, many datasets are proprietary or contain sensitive
information, making unrestricted model training problematic. In the open world
where data thefts cannot be fully prevented, Dataset Ownership Verification
(DOV) has emerged as a promising method to protect copyright by detecting
unauthorized model training and tracing illicit activities. Due to its
diversity and superior stealth, evading DOV is considered extremely
challenging. However, this paper identifies that previous studies have relied
on oversimplistic evasion attacks for evaluation, leading to a false sense of
security. We introduce a unified evasion framework, in which a teacher model
first learns from the copyright dataset and then transfers task-relevant yet
identifier-independent domain knowledge to a surrogate student using an
out-of-distribution (OOD) dataset as the intermediary. Leveraging
Vision-Language Models and Large Language Models, we curate the most
informative and reliable subsets from the OOD gallery set as the final transfer
set, and propose selectively transferring task-oriented knowledge to achieve a
better trade-off between generalization and evasion effectiveness. Experiments
across diverse datasets covering eleven DOV methods demonstrate our approach
simultaneously eliminates all copyright identifiers and significantly
outperforms nine state-of-the-art evasion attacks in both generalization and
effectiveness, with moderate computational overhead. As a proof of concept, we
reveal key vulnerabilities in current DOV methods, highlighting the need for
long-term development to enhance practicality.

</details>


### [16] [DreamSat-2.0: Towards a General Single-View Asteroid 3D Reconstruction](https://arxiv.org/abs/2508.01079)
*Santiago Diaz,Xinghui Hu,Josiane Uwumukiza,Giovanni Lavezzi,Victor Rodriguez-Fernandez,Richard Linares*

Main category: cs.CV

TL;DR: DreamSat-2.0 评估了三种3D重建模型（Hunyuan-3D、Trellis-3D、Ouroboros-3D）在航天器和近地小行星数据集上的性能。结果显示，Hunyuan-3D在航天器图像质量方面表现最佳，在小行星几何重建方面准确度最高。


<details>
  <summary>Details</summary>
Motivation: 为了加强对近地小行星的探索和航天器的自主导航，我们引入了一个名为DreamSat-2.0的基准测试流程。

Method: 使用2D感知（图像质量）和3D几何（形状准确性）指标，对Hunyuan-3D、Trellis-3D和Ouroboros-3D这三种最先进的3D重建模型在定制的航天器和近地小行星数据集上进行了基准测试。

Result: 研究结果表明，模型的性能在很大程度上取决于应用领域。在复杂的航天器上，模型能产生更高质量的图像；而在形状相对简单的小行星上，模型的几何重建效果更好。

Conclusion: Hunyuan-3D 在航天器图像质量方面表现最佳，在小行星几何重建方面准确度最高，在两个方面都显著优于先前的工作。

Abstract: To enhance asteroid exploration and autonomous spacecraft navigation, we
introduce DreamSat-2.0, a pipeline that benchmarks three state-of-the-art 3D
reconstruction models-Hunyuan-3D, Trellis-3D, and Ouroboros-3D-on custom
spacecraft and asteroid datasets. Our systematic analysis, using 2D perceptual
(image quality) and 3D geometric (shape accuracy) metrics, reveals that model
performance is domain-dependent. While models produce higher-quality images of
complex spacecraft, they achieve better geometric reconstructions for the
simpler forms of asteroids. New benchmarks are established, with Hunyuan-3D
achieving top perceptual scores on spacecraft but its best geometric accuracy
on asteroids, marking a significant advance over our prior work.

</details>


### [17] [COSTARR: Consolidated Open Set Technique with Attenuation for Robust Recognition](https://arxiv.org/abs/2508.01087)
*Ryan Rabinowitz,Steve Cruz,Walter Scheirer,Terrance E. Boult*

Main category: cs.CV

TL;DR: 本文提出了一种名为 COSTARR 的新颖开放集识别方法，该方法基于衰减假说，利用了之前被忽视的特征信息，并在大规模数据集和多种现代化架构上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有开放集识别（OSR）方法主要依赖于熟悉性假说，通过缺乏熟悉特征来检测新颖性。然而，我们提出了一种新的衰减假说，即训练过程中学习到的小权重会衰减特征，从而在区分已知类别和排除未知类别信息方面发挥双重作用。本文旨在利用这种被忽视的信息来改进 OSR。

Method: 我们提出了一种新颖的衰减假说，并基于此开发了 COSTARR 方法。该方法结合了对熟悉特征的要求和对不熟悉特征的忽视，并通过概率解释将 COSTARR 分数与正确分类和属于已知类的可能性联系起来。此外，我们还进行了消融研究，以确定衰减前和衰减后的特征对 COSTARR 性能的贡献，并在一项大规模的实验中评估了 COSTARR。

Result: 实验证明，COSTARR 在包括 ViTs、ConvNeXts 和 ResNet 在内的多种现代化预训练架构上具有良好的泛化能力。与现有最先进方法相比，COSTARR 通过整合先前被丢弃的衰减信息，显著提高了 OSR 性能，展示了其在开放集识别领域的先进性。

Conclusion: COSTARR 是一种创新的开放集识别方法，它利用了被忽视的衰减信息，能够有效地区分已知和未知类别，并且在各种现代化预训练架构上表现出色，显著优于现有最先进的方法。

Abstract: Handling novelty remains a key challenge in visual recognition systems.
Existing open-set recognition (OSR) methods rely on the familiarity hypothesis,
detecting novelty by the absence of familiar features. We propose a novel
attenuation hypothesis: small weights learned during training attenuate
features and serve a dual role-differentiating known classes while discarding
information useful for distinguishing known from unknown classes. To leverage
this overlooked information, we present COSTARR, a novel approach that combines
both the requirement of familiar features and the lack of unfamiliar ones. We
provide a probabilistic interpretation of the COSTARR score, linking it to the
likelihood of correct classification and belonging in a known class. To
determine the individual contributions of the pre- and post-attenuated features
to COSTARR's performance, we conduct ablation studies that show both
pre-attenuated deep features and the underutilized post-attenuated Hadamard
product features are essential for improving OSR. Also, we evaluate COSTARR in
a large-scale setting using ImageNet2012-1K as known data and NINCO,
iNaturalist, OpenImage-O, and other datasets as unknowns, across multiple
modern pre-trained architectures (ViTs, ConvNeXts, and ResNet). The experiments
demonstrate that COSTARR generalizes effectively across various architectures
and significantly outperforms prior state-of-the-art methods by incorporating
previously discarded attenuation information, advancing open-set recognition
capabilities.

</details>


### [18] [AURA: A Hybrid Spatiotemporal-Chromatic Framework for Robust, Real-Time Detection of Industrial Smoke Emissions](https://arxiv.org/abs/2508.01095)
*Mikhail Bychkov,Matey Yordanov,Andrei Kuchma*

Main category: cs.CV

TL;DR: AURA is a new system that uses movement and color to accurately detect and classify industrial smoke in real-time, overcoming the limitations of older systems.


<details>
  <summary>Details</summary>
Motivation: Current monitoring systems lack specificity to distinguish smoke types and struggle with environmental variability.

Method: AURA leverages both dynamic movement patterns and distinct color characteristics of industrial smoke.

Result: AURA achieves robust, real-time detection and classification of industrial smoke emissions with enhanced accuracy and reduced false positives.

Conclusion: AURA, a hybrid spatiotemporal-chromatic framework, enables precise, automated monitoring of industrial emissions, improving environmental compliance, operational safety, and public health.

Abstract: This paper introduces AURA, a novel hybrid spatiotemporal-chromatic framework
designed for robust, real-time detection and classification of industrial smoke
emissions. The framework addresses critical limitations of current monitoring
systems, which often lack the specificity to distinguish smoke types and
struggle with environmental variability. AURA leverages both the dynamic
movement patterns and the distinct color characteristics of industrial smoke to
provide enhanced accuracy and reduced false positives. This framework aims to
significantly improve environmental compliance, operational safety, and public
health outcomes by enabling precise, automated monitoring of industrial
emissions.

</details>


### [19] [Trans-Adapter: A Plug-and-Play Framework for Transparent Image Inpainting](https://arxiv.org/abs/2508.01098)
*Yuekun Dai,Haitian Li,Shangchen Zhou,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出 Trans-Adapter 适配器，使扩散模型可直接处理 RGBA 图像修复，支持 ControlNet，并引入 LayerBench 数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的图像修复方法大多只支持 RGB 图像，对于需要透明度（alpha 通道）的编辑存在局限性。传统的 RGBA 图像修复流程（先修复再抠图）难以保持透明度一致性，且抠图可能引入锯齿状边缘。

Method: 提出了一种名为 Trans-Adapter 的即插即用适配器，使基于扩散的修复模型能够直接处理 RGBA 图像。

Result: Trans-Adapter 能够直接处理 RGBA 图像，并支持通过 ControlNet 进行可控编辑，可以无缝集成到各种社区模型中。通过 LayerBench 和新的非参考 alpha 边缘质量评估指标的实验证明了该方法的有效性。

Conclusion: Trans-Adapter 能够直接处理 RGBA 图像，并支持通过 ControlNet 进行可控编辑，可以无缝集成到各种社区模型中。我们引入了 LayerBench 和一种新的非参考 alpha 边缘质量评估指标来评估透明度边缘质量。实验证明了该方法的有效性。

Abstract: RGBA images, with the additional alpha channel, are crucial for any
application that needs blending, masking, or transparency effects, making them
more versatile than standard RGB images. Nevertheless, existing image
inpainting methods are designed exclusively for RGB images. Conventional
approaches to transparent image inpainting typically involve placing a
background underneath RGBA images and employing a two-stage process: image
inpainting followed by image matting. This pipeline, however, struggles to
preserve transparency consistency in edited regions, and matting can introduce
jagged edges along transparency boundaries. To address these challenges, we
propose Trans-Adapter, a plug-and-play adapter that enables diffusion-based
inpainting models to process transparent images directly. Trans-Adapter also
supports controllable editing via ControlNet and can be seamlessly integrated
into various community models. To evaluate our method, we introduce LayerBench,
along with a novel non-reference alpha edge quality evaluation metric for
assessing transparency edge quality. We conduct extensive experiments on
LayerBench to demonstrate the effectiveness of our approach.

</details>


### [20] [MASIV: Toward Material-Agnostic System Identification from Videos](https://arxiv.org/abs/2508.01112)
*Yizhou Zhao,Haoyu Chen,Chunjiang Liu,Zhenyang Li,Charles Herrmann,Junhwa Hur,Yinxiao Li,Ming-Hsuan Yang,Bhiksha Raj,Min Xu*

Main category: cs.CV

TL;DR: MASIV 是一种新颖的基于视觉的材料无关系统识别框架，它使用可学习的神经本构模型和稠密的几何引导来克服现有方法的局限性，并在各种评估中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可微分渲染和仿真的系统识别方法依赖于预定义的材料先验，限制了它们处理未知材料的能力。MASIV 旨在实现材料无关的系统识别。

Method: MASIV 框架使用可学习的神经本构模型来推断物体动力学，而无需假设特定场景的材料先验。为了解决由于缺少完整的粒子状态信息而导致的优化不稳定和物理上不合理的行为，该框架引入了稠密的几何引导，通过重建连续粒子轨迹来提供超越稀疏视觉线索的时间上丰富的运动约束。

Result: MASIV 在几何精度、渲染质量和泛化能力方面取得了最先进的性能。

Conclusion: MASIV 在几何精度、渲染质量和泛化能力方面均达到最先进的性能。

Abstract: System identification from videos aims to recover object geometry and
governing physical laws. Existing methods integrate differentiable rendering
with simulation but rely on predefined material priors, limiting their ability
to handle unknown ones. We introduce MASIV, the first vision-based framework
for material-agnostic system identification. Unlike existing approaches that
depend on hand-crafted constitutive laws, MASIV employs learnable neural
constitutive models, inferring object dynamics without assuming a
scene-specific material prior. However, the absence of full particle state
information imposes unique challenges, leading to unstable optimization and
physically implausible behaviors. To address this, we introduce dense geometric
guidance by reconstructing continuum particle trajectories, providing
temporally rich motion constraints beyond sparse visual cues. Comprehensive
experiments show that MASIV achieves state-of-the-art performance in geometric
accuracy, rendering quality, and generalization ability.

</details>


### [21] [The Promise of RL for Autoregressive Image Editing](https://arxiv.org/abs/2508.01119)
*Saba Ahmadi,Rabiul Awal,Ankur Sikarwar,Amirhossein Kazemnejad,Ge Ya Luo,Juan A. Rodriguez,Sai Rajeswar,Siva Reddy,Christopher Pal,Benno Krojer,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: We introduce EARL, an RL-based image editing model that achieves strong performance with less training data by combining reinforcement learning with a large multi-modal LLM verifier.


<details>
  <summary>Details</summary>
Motivation: To enhance performance on a wide range of image editing tasks using an autoregressive multimodal model.

Method: We adopt an autoregressive multimodal model that processes textual and visual tokens in a unified manner and explore three strategies: supervised fine-tuning (SFT), reinforcement learning (RL), and Chain-of-Thought (CoT) reasoning.

Result: EARL, an RL-based image editing model, performs competitively on a diverse range of edits compared to strong baselines, despite using much less training data.

Conclusion: RL combined with a large multi-modal LLM verifier is the most effective strategy for image editing, and EARL, an RL-based image editing model, performs competitively with less training data.

Abstract: We explore three strategies to enhance performance on a wide range of image
editing tasks: supervised fine-tuning (SFT), reinforcement learning (RL), and
Chain-of-Thought (CoT) reasoning. In order to study all these components in one
consistent framework, we adopt an autoregressive multimodal model that
processes textual and visual tokens in a unified manner. We find RL combined
with a large multi-modal LLM verifier to be the most effective of these
strategies. As a result, we release EARL: Editing with Autoregression and RL, a
strong RL-based image editing model that performs competitively on a diverse
range of edits compared to strong baselines, despite using much less training
data. Thus, EARL pushes the frontier of autoregressive multimodal models on
image editing. We release our code, training data, and trained models at
https://github.com/mair-lab/EARL.

</details>


### [22] [UniEgoMotion: A Unified Model for Egocentric Motion Reconstruction, Forecasting, and Generation](https://arxiv.org/abs/2508.01126)
*Chaitanya Patel,Hiroki Nakamura,Yuta Kyuragi,Kazuki Kozuka,Juan Carlos Niebles,Ehsan Adeli*

Main category: cs.CV

TL;DR: 本研究提出了UniEgoMotion，一个统一的视角运动生成和预测模型，它能从第一人称图像中进行场景感知运动合成，无需显式3D场景。该模型在视角运动重建方面表现出色，并首次实现了从单视角图像生成运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注第三人称运动合成，并且依赖于结构化的3D场景上下文，这在现实世界的视角场景中效果有限。因此，需要一种能够利用第一人称图像进行场景感知运动合成的新方法，以解决视野受限、遮挡频繁和相机动态等问题。

Method: 提出了一种名为UniEgoMotion的统一条件运动扩散模型，并采用了一种新颖的以头部为中心的运动表示方法，以适应视角设备。该模型能够从第一人称视觉输入中进行视角运动重建、预测和生成。

Result: UniEgoMotion在视角运动重建方面达到了最先进的性能，并且是第一个能够从单个视角图像生成运动的模型。此外，还引入了一个大型数据集EE4D-Motion，用于训练和评估。

Conclusion: UniEgoMotion在单目视角运动重建方面取得了最先进的性能，并且是第一个能够从单个视角图像生成运动的模型。实验证明了该统一框架的有效性，为视角运动建模设定了新的基准，并为视角应用开辟了新的可能性。

Abstract: Egocentric human motion generation and forecasting with scene-context is
crucial for enhancing AR/VR experiences, improving human-robot interaction,
advancing assistive technologies, and enabling adaptive healthcare solutions by
accurately predicting and simulating movement from a first-person perspective.
However, existing methods primarily focus on third-person motion synthesis with
structured 3D scene contexts, limiting their effectiveness in real-world
egocentric settings where limited field of view, frequent occlusions, and
dynamic cameras hinder scene perception. To bridge this gap, we introduce
Egocentric Motion Generation and Egocentric Motion Forecasting, two novel tasks
that utilize first-person images for scene-aware motion synthesis without
relying on explicit 3D scene. We propose UniEgoMotion, a unified conditional
motion diffusion model with a novel head-centric motion representation tailored
for egocentric devices. UniEgoMotion's simple yet effective design supports
egocentric motion reconstruction, forecasting, and generation from first-person
visual inputs in a unified framework. Unlike previous works that overlook scene
semantics, our model effectively extracts image-based scene context to infer
plausible 3D motion. To facilitate training, we introduce EE4D-Motion, a
large-scale dataset derived from EgoExo4D, augmented with pseudo-ground-truth
3D motion annotations. UniEgoMotion achieves state-of-the-art performance in
egocentric motion reconstruction and is the first to generate motion from a
single egocentric image. Extensive evaluations demonstrate the effectiveness of
our unified framework, setting a new benchmark for egocentric motion modeling
and unlocking new possibilities for egocentric applications.

</details>


### [23] [Semi-Supervised Anomaly Detection in Brain MRI Using a Domain-Agnostic Deep Reinforcement Learning Approach](https://arxiv.org/abs/2508.01137)
*Zeduo Zhang,Yalda Mohsenzadeh*

Main category: cs.CV

TL;DR: 该研究提出了一种基于深度强化学习（DRL）的域无关半监督异常检测框架，该框架在处理大脑MRI和工业数据集时均表现出色，尤其在处理大规模、类别不平衡数据方面具有优势，并且具有良好的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 为了开发一个域无关、半监督的异常检测框架，以应对大规模数据、过拟合和类别不平衡等挑战，特别是针对大脑MRI异常检测的特定需求。

Method: 本研究采用深度强化学习（DRL）与特征表示相结合的方法，构建了一个域无关的半监督异常检测框架。该框架利用IXI数据集（健康大脑MRI）进行训练，并使用BraTS 2021数据集（包含胶质母细胞瘤的非健康大脑MRI）进行验证和测试。在工业领域，使用了MVTec AD数据集进行实验和消融分析。通过统计分析（包括AUROC和Dice分数等指标）评估了模型的性能。

Result: 在 두뇌 MRI 数据集上，该方法实现了 88.7%（像素级）和 96.7%（图像级）的 AUROC。在 MVTec AD 工业数据集上，模型也取得了具有竞争力的性能（像素级 AUROC = 99.8%，图像级 AUROC = 99.3%），证明了其跨域泛化能力。此外，研究表明随着异常样本数量的增加，AUROC 单调递增，且不存在过拟合或额外的计算成本。

Conclusion: 该研究提出的域无关、半监督的深度强化学习（DRL）框架在处理大规模数据、过拟合和类别不平衡等挑战方面表现出色，特别是在大脑MRI异常检测任务中取得了优于现有最先进（SOTA）方法的性能，并且在工业数据集上也展示了强大的跨域泛化能力。该框架的鲁棒性、泛化性和效率证明了其在实际临床应用中的巨大潜力。

Abstract: To develop a domain-agnostic, semi-supervised anomaly detection framework
that integrates deep reinforcement learning (DRL) to address challenges such as
large-scale data, overfitting, and class imbalance, focusing on brain MRI
volumes. This retrospective study used publicly available brain MRI datasets
collected between 2005 and 2021. The IXI dataset provided 581 T1-weighted and
578 T2-weighted MRI volumes (from healthy subjects) for training, while the
BraTS 2021 dataset provided 251 volumes for validation and 1000 for testing
(unhealthy subjects with Glioblastomas). Preprocessing included normalization,
skull-stripping, and co-registering to a uniform voxel size. Experiments were
conducted on both T1- and T2-weighted modalities. Additional experiments and
ablation analyses were also carried out on the industrial datasets. The
proposed method integrates DRL with feature representations to handle label
scarcity, large-scale data and overfitting. Statistical analysis was based on
several detection and segmentation metrics including AUROC and Dice score. The
proposed method achieved an AUROC of 88.7% (pixel-level) and 96.7%
(image-level) on brain MRI datasets, outperforming State-of-The-Art (SOTA)
methods. On industrial surface datasets, the model also showed competitive
performance (AUROC = 99.8% pixel-level, 99.3% image-level) on MVTec AD dataset,
indicating strong cross-domain generalization. Studies on anomaly sample size
showed a monotonic increase in AUROC as more anomalies were seen, without
evidence of overfitting or additional computational cost. The domain-agnostic
semi-supervised approach using DRL shows significant promise for MRI anomaly
detection, achieving strong performance on both medical and industrial
datasets. Its robustness, generalizability and efficiency highlight its
potential for real-world clinical applications.

</details>


### [24] [Dataset Condensation with Color Compensation](https://arxiv.org/abs/2508.01139)
*Huyu Wu,Duo Su,Junjie Hou,Guang Li*

Main category: cs.CV

TL;DR: DC3通过颜色补偿和潜在扩散模型来提升数据集压缩质量，解决了现有方法的瓶颈，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有数据集浓缩方法在性能和保真度之间存在权衡，并且存在效率低下或语义失真等瓶颈。作者发现颜色在其中扮演了重要角色，并提出通过提升颜色丰富度来改善表示学习。

Method: DC3框架通过校准选择策略，并利用潜在扩散模型来增强图像的颜色多样性，而非生成全新图像。

Result: DC3框架在多个基准测试中表现优于现有技术，提升了模型性能和泛化能力，并且训练得到的模型没有出现模型崩溃或其他退化问题。

Conclusion: DC3框架能够通过颜色补偿提升压缩数据集的质量，从而在压缩率和模型性能之间取得更好的平衡，并且是首个微调预训练扩散模型的研究，FID结果证明了其可行性。

Abstract: Dataset condensation always faces a constitutive trade-off: balancing
performance and fidelity under extreme compression. Existing methods struggle
with two bottlenecks: image-level selection methods (Coreset Selection, Dataset
Quantization) suffer from inefficiency condensation, while pixel-level
optimization (Dataset Distillation) introduces semantic distortion due to
over-parameterization. With empirical observations, we find that a critical
problem in dataset condensation is the oversight of color's dual role as an
information carrier and a basic semantic representation unit. We argue that
improving the colorfulness of condensed images is beneficial for representation
learning. Motivated by this, we propose DC3: a Dataset Condensation framework
with Color Compensation. After a calibrated selection strategy, DC3 utilizes
the latent diffusion model to enhance the color diversity of an image rather
than creating a brand-new one. Extensive experiments demonstrate the superior
performance and generalization of DC3 that outperforms SOTA methods across
multiple benchmarks. To the best of our knowledge, besides focusing on
downstream tasks, DC3 is the first research to fine-tune pre-trained diffusion
models with condensed datasets. The FID results prove that training networks
with our high-quality datasets is feasible without model collapse or other
degradation issues. Code and generated data will be released soon.

</details>


### [25] [OpenGS-Fusion: Open-Vocabulary Dense Mapping with Hybrid 3D Gaussian Splatting for Refined Object-Level Understanding](https://arxiv.org/abs/2508.01150)
*Dianyi Yang,Xihan Wang,Yu Gao,Shiyang Liu,Bohan Ren,Yufeng Yue,Yi Yang*

Main category: cs.CV

TL;DR: OpenGS-Fusion enhances open-vocabulary 3D scene understanding and interaction using 3D Gaussians and signed distance fields, achieving better semantic mapping and object-level detail with a novel adaptive thresholding technique guided by multimodal language.


<details>
  <summary>Details</summary>
Motivation: Existing methods for 3D scene understanding with open-vocabulary queries are limited by rigid offline pipelines and lack precise object-level understanding. This work aims to address these limitations.

Method: OpenGS-Fusion combines 3D Gaussian representation with a Truncated Signed Distance Field for lossless semantic feature fusion. It employs a multimodal language-guided approach, MLLM-Assisted Adaptive Thresholding, to refine 3D object segmentation by adaptively adjusting similarity thresholds.

Result: The method outperforms existing approaches in 3D object understanding and scene reconstruction quality, demonstrating effectiveness in language-guided scene interaction. It achieved a 17% improvement in 3D mIoU compared to fixed threshold strategies.

Conclusion: OpenGS-Fusion inoveates open-vocabulary dense mapping framework with 3D Gaussian representation and Truncated Signed Distance Field for on-the-fly semantic fusion and refined object-level understanding. It achieves a 17% improvement in 3D mIoU using MLLM-Assisted Adaptive Thresholding.

Abstract: Recent advancements in 3D scene understanding have made significant strides
in enabling interaction with scenes using open-vocabulary queries, particularly
for VR/AR and robotic applications. Nevertheless, existing methods are hindered
by rigid offline pipelines and the inability to provide precise 3D object-level
understanding given open-ended queries. In this paper, we present
OpenGS-Fusion, an innovative open-vocabulary dense mapping framework that
improves semantic modeling and refines object-level understanding.
OpenGS-Fusion combines 3D Gaussian representation with a Truncated Signed
Distance Field to facilitate lossless fusion of semantic features on-the-fly.
Furthermore, we introduce a novel multimodal language-guided approach named
MLLM-Assisted Adaptive Thresholding, which refines the segmentation of 3D
objects by adaptively adjusting similarity thresholds, achieving an improvement
17\% in 3D mIoU compared to the fixed threshold strategy. Extensive experiments
demonstrate that our method outperforms existing methods in 3D object
understanding and scene reconstruction quality, as well as showcasing its
effectiveness in language-guided scene interaction. The code is available at
https://young-bit.github.io/opengs-fusion.github.io/ .

</details>


### [26] [Personalized Safety Alignment for Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.01151)
*Yu Lei,Jinbin Bai,Qingyu Shi,Aosong Feng,Kaidong Yu*

Main category: cs.CV

TL;DR: PSA框架通过集成个性化用户配置档到扩散过程，能够更好地满足用户对安全设置的个性化需求，并在有害内容抑制和用户约束对齐方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型安全机制未能考虑用户的个体差异，例如年龄、心理健康和个人信仰等因素，导致安全边界的设置过于统一，无法满足用户的个性化需求。

Method: 提出了一种名为PSA（Personalized Safety Alignment）的框架，该框架通过在扩散过程中集成个性化的用户配置档，利用交叉注意力机制来调整模型的行为以匹配用户的安全偏好，并引入了一个名为Sage的新数据集来捕捉用户特定的安全偏好。

Result: PSA框架在有害内容抑制和用户约束对齐方面优于现有方法，实现了更高的胜率和通过率。

Conclusion: PSA通过集成个性化用户配置档到扩散过程，能够更好地满足用户对安全设置的个性化需求，并在有害内容抑制和用户约束对齐方面优于现有方法，实现了更高的胜率和通过率。

Abstract: Text-to-image diffusion models have revolutionized visual content generation,
but current safety mechanisms apply uniform standards that often fail to
account for individual user preferences. These models overlook the diverse
safety boundaries shaped by factors like age, mental health, and personal
beliefs. To address this, we propose Personalized Safety Alignment (PSA), a
framework that allows user-specific control over safety behaviors in generative
models. PSA integrates personalized user profiles into the diffusion process,
adjusting the model's behavior to match individual safety preferences while
preserving image quality. We introduce a new dataset, Sage, which captures
user-specific safety preferences and incorporates these profiles through a
cross-attention mechanism. Experiments show that PSA outperforms existing
methods in harmful content suppression and aligns generated content better with
user constraints, achieving higher Win Rate and Pass Rate scores. Our code,
data, and models are publicly available at
https://torpedo2648.github.io/PSAlign/.

</details>


### [27] [LawDIS: Language-Window-based Controllable Dichotomous Image Segmentation](https://arxiv.org/abs/2508.01152)
*Xinyu Yan,Meijun Sun,Ge-Peng Ji,Fahad Shahbaz Khan,Salman Khan,Deng-Ping Fan*

Main category: cs.CV

TL;DR: LawDIS是一个创新的DIS框架，通过语言和窗口控制实现高精度、个性化分割，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 提出LawDIS框架，用于生成高质量的物体掩码，并实现高精度、个性化的应用。

Method: LawDIS是一个基于语言窗口的可控二分图像分割（DIS）框架，它将DIS重构为潜在扩散模型中的图像条件掩码生成任务。该框架具有宏观到微观的控制模式：宏观模式采用语言控制分割策略（LS）根据语言提示生成初始掩码；微观模式采用窗口控制细化策略（WR）允许用户通过可调窗口灵活细化初始掩码。

Result: LawDIS显著优于11种最先进的方法，在DIS-TE上，结合LS和WR策略可实现4.6%的Fβω增益，单独使用LS策略可实现3.6%的增益。

Conclusion: LawDIS在DIS5K基准测试中显著优于11种最先进的方法，并在DIS-TE上实现了Fβω增益。

Abstract: We present LawDIS, a language-window-based controllable dichotomous image
segmentation (DIS) framework that produces high-quality object masks. Our
framework recasts DIS as an image-conditioned mask generation task within a
latent diffusion model, enabling seamless integration of user controls. LawDIS
is enhanced with macro-to-micro control modes. Specifically, in macro mode, we
introduce a language-controlled segmentation strategy (LS) to generate an
initial mask based on user-provided language prompts. In micro mode, a
window-controlled refinement strategy (WR) allows flexible refinement of
user-defined regions (i.e., size-adjustable windows) within the initial mask.
Coordinated by a mode switcher, these modes can operate independently or
jointly, making the framework well-suited for high-accuracy, personalised
applications. Extensive experiments on the DIS5K benchmark reveal that our
LawDIS significantly outperforms 11 cutting-edge methods across all metrics.
Notably, compared to the second-best model MVANet, we achieve $F_\beta^\omega$
gains of 4.6\% with both the LS and WR strategies and 3.6\% gains with only the
LS strategy on DIS-TE. Codes will be made available at
https://github.com/XinyuYanTJU/LawDIS.

</details>


### [28] [TEACH: Text Encoding as Curriculum Hints for Scene Text Recognition](https://arxiv.org/abs/2508.01153)
*Xiahan Yang,Hui Zheng*

Main category: cs.CV

TL;DR: TEACH improves Scene Text Recognition by using ground-truth text as temporary input, guiding the model to learn visual recognition without needing extra training or slowing down inference.


<details>
  <summary>Details</summary>
Motivation: Scene Text Recognition (STR) remains a challenging task due to complex visual appearances and limited semantic priors.

Method: TEACH encodes target labels into the embedding space and applies loss-aware masking to simulate a curriculum learning process, guiding the model from label-dependent learning to fully visual recognition. It requires no external pretraining and introduces no inference overhead.

Result: Models trained with TEACH achieve consistently improved accuracy, especially under challenging conditions, validating its robustness and general applicability.

Conclusion: TEACH is a novel training paradigm that injects ground-truth text into the model as auxiliary input and progressively reduces its influence during training. It is model-agnostic and can be seamlessly integrated into existing encoder-decoder frameworks. Extensive experiments show that models trained with TEACH achieve consistently improved accuracy, especially under challenging conditions, validating its robustness and general applicability.

Abstract: Scene Text Recognition (STR) remains a challenging task due to complex visual
appearances and limited semantic priors. We propose TEACH, a novel training
paradigm that injects ground-truth text into the model as auxiliary input and
progressively reduces its influence during training. By encoding target labels
into the embedding space and applying loss-aware masking, TEACH simulates a
curriculum learning process that guides the model from label-dependent learning
to fully visual recognition. Unlike language model-based approaches, TEACH
requires no external pretraining and introduces no inference overhead. It is
model-agnostic and can be seamlessly integrated into existing encoder-decoder
frameworks. Extensive experiments across multiple public benchmarks show that
models trained with TEACH achieve consistently improved accuracy, especially
under challenging conditions, validating its robustness and general
applicability.

</details>


### [29] [DELTAv2: Accelerating Dense 3D Tracking](https://arxiv.org/abs/2508.01170)
*Tuan Duc Ngo,Ashkan Mirzaei,Guocheng Qian,Hanwen Liang,Chuang Gan,Evangelos Kalogerakis,Peter Wonka,Chaoyang Wang*

Main category: cs.CV

TL;DR: 提出了一种新的跟踪算法，通过粗到精策略和优化的特征计算，显著加快了3D点跟踪速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有最先进的视频中密集的长时3D点跟踪方法的两个主要计算瓶颈：基于Transformer的迭代跟踪和相关特征计算的成本。

Method: 提出了一种新的粗到精跟踪策略，该策略从一小部分点开始跟踪，并使用可学习的插值模块逐步扩展跟踪轨迹集。此外，还提出了一种优化方法，以显著降低相关特征计算的成本。

Result: 与现有方法相比，速度提高了5-100倍，同时保持了最先进的跟踪准确性。

Conclusion: 该算法实现了比现有方法快5-100倍的速度，同时保持了最先进的跟踪准确性。

Abstract: We propose a novel algorithm for accelerating dense long-term 3D point
tracking in videos. Through analysis of existing state-of-the-art methods, we
identify two major computational bottlenecks. First, transformer-based
iterative tracking becomes expensive when handling a large number of
trajectories. To address this, we introduce a coarse-to-fine strategy that
begins tracking with a small subset of points and progressively expands the set
of tracked trajectories. The newly added trajectories are initialized using a
learnable interpolation module, which is trained end-to-end alongside the
tracking network. Second, we propose an optimization that significantly reduces
the cost of correlation feature computation, another key bottleneck in prior
methods. Together, these improvements lead to a 5-100x speedup over existing
approaches while maintaining state-of-the-art tracking accuracy.

</details>


### [30] [No Pose at All: Self-Supervised Pose-Free 3D Gaussian Splatting from Sparse Views](https://arxiv.org/abs/2508.01171)
*Ranran Huang,Krystian Mikolajczyk*

Main category: cs.CV

TL;DR: SPFSplat 是一种高效的框架，可以从稀疏的多视图图像进行 3D 高斯图画，无需地面真实姿态。它通过共享特征提取主干、同时预测 3D 高斯图元和相机姿态，并结合重投影损失来实现高性能。


<details>
  <summary>Details</summary>
Motivation: 介绍 SPFSplat，一个从稀疏的多视图图像进行 3D 高斯图画的高效框架，在训练或推理期间不需要地面真实姿态。

Method: SPFSplat 使用共享的特征提取主干，可以从无姿态输入中同时预测 3D 高斯图元和规范空间中的相机姿态，在一个前馈步骤中完成。它集成了基于估计的新视图姿态的渲染损失，并结合了重投影损失，以强制学习像素对齐的高斯图元，从而增强了几何约束。

Result: SPFSplat 实现了最先进的新视图合成性能，即使在显著的视角变化和有限的图像重叠下也是如此。它还在相对姿态估计方面超过了使用几何先验进行训练的近期方法。

Conclusion: SPFSplat 在没有姿态监督的情况下，在新的视图合成方面取得了最先进的性能，并且在相对姿态估计方面也超过了使用几何先验训练的近期方法。

Abstract: We introduce SPFSplat, an efficient framework for 3D Gaussian splatting from
sparse multi-view images, requiring no ground-truth poses during training or
inference. It employs a shared feature extraction backbone, enabling
simultaneous prediction of 3D Gaussian primitives and camera poses in a
canonical space from unposed inputs within a single feed-forward step.
Alongside the rendering loss based on estimated novel-view poses, a
reprojection loss is integrated to enforce the learning of pixel-aligned
Gaussian primitives for enhanced geometric constraints. This pose-free training
paradigm and efficient one-step feed-forward design make SPFSplat well-suited
for practical applications. Remarkably, despite the absence of pose
supervision, SPFSplat achieves state-of-the-art performance in novel view
synthesis even under significant viewpoint changes and limited image overlap.
It also surpasses recent methods trained with geometry priors in relative pose
estimation. Code and trained models are available on our project page:
https://ranrhuang.github.io/spfsplat/.

</details>


### [31] [Object Affordance Recognition and Grounding via Multi-scale Cross-modal Representation Learning](https://arxiv.org/abs/2508.01184)
*Xinhang Wan,Dongqiang Gou,Xinwang Liu,En Zhu,Xuming He*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法，用于解决具身AI中的物体操作学习问题。该方法通过学习跨模态3D表征和采用分阶段推理策略，有效解决了现有技术在3D物体可操作区域识别和分类任务中存在的不足，实现了更准确、更全面的物体可操作性理解。


<details>
  <summary>Details</summary>
Motivation: 目前，具身AI在从观察中学习物体操作方面存在核心问题，而现有方法通常将3D物体可操作区域识别（3D affordance grounding）和功能分类（affordance classification）这两个任务分开处理，由于未能妥善建模它们之间的依赖关系，导致预测结果不一致。此外，这些方法通常只识别图像中描绘的不完整可操作区域，未能预测完整的潜在可操作区域，并且在固定尺度下运行，难以应对与整个物体相比尺度差异很大的可操作区域。

Method: 本文提出了一种新颖的方法，该方法通过学习一种可操作性感知的3D表征，并采用分阶段推理策略来利用识别和分类任务之间的依赖关系。具体来说，我们首先开发了一种跨模态3D表征，通过有效的融合和多尺度几何特征传播，能够推断出在合适区域尺度的完整潜在可操作区域。此外，我们采用了一个简单的两阶段预测机制，有效地耦合了识别和分类，以更好地理解可操作性。

Result: 实验证明了该方法在可操作区域识别和分类方面的有效性，均取得了性能提升。

Conclusion: 本文提出的跨模态3D表征和分阶段推理策略能够有效解决现有方法在3D物体可操作区域识别和功能分类任务中存在的局限性，通过融合多尺度几何特征并利用任务间的依赖关系，实现了对物体全部潜在可操作区域的预测，并在不同尺度下保持良好性能，实验结果证明了该方法的有效性。

Abstract: A core problem of Embodied AI is to learn object manipulation from
observation, as humans do. To achieve this, it is important to localize 3D
object affordance areas through observation such as images (3D affordance
grounding) and understand their functionalities (affordance classification).
Previous attempts usually tackle these two tasks separately, leading to
inconsistent predictions due to lacking proper modeling of their dependency. In
addition, these methods typically only ground the incomplete affordance areas
depicted in images, failing to predict the full potential affordance areas, and
operate at a fixed scale, resulting in difficulty in coping with affordances
significantly varying in scale with respect to the whole object. To address
these issues, we propose a novel approach that learns an affordance-aware 3D
representation and employs a stage-wise inference strategy leveraging the
dependency between grounding and classification tasks. Specifically, we first
develop a cross-modal 3D representation through efficient fusion and
multi-scale geometric feature propagation, enabling inference of full potential
affordance areas at a suitable regional scale. Moreover, we adopt a simple
two-stage prediction mechanism, effectively coupling grounding and
classification for better affordance understanding. Experiments demonstrate the
effectiveness of our method, showing improved performance in both affordance
grounding and classification.

</details>


### [32] [A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding](https://arxiv.org/abs/2508.01197)
*Zhan Shi,Song Wang,Junbo Chen,Jianke Zhu*

Main category: cs.CV

TL;DR: 我们提出了一个用于3D占用接地的基准和一种名为GroundingOcc的新模型，以解决现有视觉接地任务在捕捉细粒度细节方面的不足。我们的模型在户外场景中通过多模态学习实现了更精确的物体感知和定位，并在实验中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉接地任务依赖边界框，无法捕捉细粒度细节，导致物体表示不准确。为了解决这个问题，我们引入了一个用于挑战性户外场景的3D占用接地基准，该基准集成了自然语言和体素级占用注释，提供了比传统接地任务更精确的物体感知。

Method: 提出了一种名为GroundingOcc的端到端模型，通过多模态学习进行3D占用接地，结合视觉、文本和点云特征进行物体定位和占用信息预测。该模型包含多模态编码器、占用头和接地头，并通过2D接地模块和深度估计模块增强几何理解。

Result: 在所提出的基准上进行了广泛的实验，证明了我们的方法在3D占用接地任务上的优越性。

Conclusion: 我们的方法在3D占用接地任务上优于现有基线。

Abstract: Visual grounding aims to identify objects or regions in a scene based on
natural language descriptions, essential for spatially aware perception in
autonomous driving. However, existing visual grounding tasks typically depend
on bounding boxes that often fail to capture fine-grained details. Not all
voxels within a bounding box are occupied, resulting in inaccurate object
representations. To address this, we introduce a benchmark for 3D occupancy
grounding in challenging outdoor scenes. Built on the nuScenes dataset, it
integrates natural language with voxel-level occupancy annotations, offering
more precise object perception compared to the traditional grounding task.
Moreover, we propose GroundingOcc, an end-to-end model designed for 3D
occupancy grounding through multi-modal learning. It combines visual, textual,
and point cloud features to predict object location and occupancy information
from coarse to fine. Specifically, GroundingOcc comprises a multimodal encoder
for feature extraction, an occupancy head for voxel-wise predictions, and a
grounding head to refine localization. Additionally, a 2D grounding module and
a depth estimation module enhance geometric understanding, thereby boosting
model performance. Extensive experiments on the benchmark demonstrate that our
method outperforms existing baselines on 3D occupancy grounding. The dataset is
available at https://github.com/RONINGOD/GroundingOcc.

</details>


### [33] [Deep Learning for Pavement Condition Evaluation Using Satellite Imagery](https://arxiv.org/abs/2508.01206)
*Prathyush Kumar Reddy Lebaku,Lu Gao,Pan Lu,Jingran Sun*

Main category: cs.CV

TL;DR: 通过分析超过3000张路面卫星图像和TxDOT的PMIS数据库，本研究利用深度学习模型评估路面状况，准确率超过90%，为未来快速、经济高效的路面评估铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 传统的人工或基于车辆的调查方法劳动密集且耗时，因此有必要探索更具成本效益的监控和维护基础设施的方法。

Method: 利用深度学习模型分析卫星图像来评估路面状况。

Result: 研究结果显示准确率超过90%。

Conclusion: 本研究为未来快速、经济高效地评估路面网络铺平了道路。

Abstract: Civil infrastructure systems covers large land areas and needs frequent
inspections to maintain their public service capabilities. The conventional
approaches of manual surveys or vehicle-based automated surveys to assess
infrastructure conditions are often labor-intensive and time-consuming. For
this reason, it is worthwhile to explore more cost-effective methods for
monitoring and maintaining these infrastructures. Fortunately, recent
advancements in satellite systems and image processing algorithms have opened
up new possibilities. Numerous satellite systems have been employed to monitor
infrastructure conditions and identify damages. Due to the improvement in
ground sample distance (GSD), the level of detail that can be captured has
significantly increased. Taking advantage of these technology advancement, this
research investigated to evaluate pavement conditions using deep learning
models for analyzing satellite images. We gathered over 3,000 satellite images
of pavement sections, together with pavement evaluation ratings from TxDOT's
PMIS database. The results of our study show an accuracy rate is exceeding 90%.
This research paves the way for a rapid and cost-effective approach to
evaluating the pavement network in the future.

</details>


### [34] [RoadMamba: A Dual Branch Visual State Space Model for Road Surface Classification](https://arxiv.org/abs/2508.01210)
*Tianze Wang,Zhang Zhang,Chao Yue,Nuoran Li,Chao Sun*

Main category: cs.CV

TL;DR: 提出了一种名为RoadMamba的新方法，结合了Mamba架构的全局感知能力和对道路表面局部纹理的有效提取，并在大规模数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶汽车的安全性和驾驶舒适性，需要提前获取道路表面状况的视觉信息，但现有的Mamba架构在提取道路表面局部纹理方面存在不足。

Method: 提出了一种名为RoadMamba的方法，利用双状态空间模型（DualSSM）有效提取道路表面的全局语义和局部纹理，并通过双注意力融合（DAF）解码和融合双特征。此外，还提出了一种双辅助损失来显式约束双分支。

Result: RoadMamba在包含100万个样本的大规模道路表面分类数据集上取得了最先进的性能。

Conclusion: 该研究首次探索了视觉Mamba架构在道路表面分类任务中的潜力，并提出了一种名为RoadMamba的方法，该方法有效地结合了局部和全局感知，在包含100万个样本的大规模道路表面分类数据集的实验中达到了最先进的性能。

Abstract: Acquiring the road surface conditions in advance based on visual technologies
provides effective information for the planning and control system of
autonomous vehicles, thus improving the safety and driving comfort of the
vehicles. Recently, the Mamba architecture based on state-space models has
shown remarkable performance in visual processing tasks, benefiting from the
efficient global receptive field. However, existing Mamba architectures
struggle to achieve state-of-the-art visual road surface classification due to
their lack of effective extraction of the local texture of the road surface. In
this paper, we explore for the first time the potential of visual Mamba
architectures for road surface classification task and propose a method that
effectively combines local and global perception, called RoadMamba.
Specifically, we utilize the Dual State Space Model (DualSSM) to effectively
extract the global semantics and local texture of the road surface and decode
and fuse the dual features through the Dual Attention Fusion (DAF). In
addition, we propose a dual auxiliary loss to explicitly constrain dual
branches, preventing the network from relying only on global semantic
information from the deep large receptive field and ignoring the local texture.
The proposed RoadMamba achieves the state-of-the-art performance in experiments
on a large-scale road surface classification dataset containing 1 million
samples.

</details>


### [35] [StyDeco: Unsupervised Style Transfer with Distilling Priors and Semantic Decoupling](https://arxiv.org/abs/2508.01215)
*Yuanlin Yang,Quanjian Song,Zhexian Gao,Ge Wang,Shanshan Li,Xiaoyan Zhang*

Main category: cs.CV

TL;DR: StyDeco, an unsupervised style transfer framework, uses PGD and CSD to learn specialized text representations, overcoming the limitations of existing methods by preserving semantic structure and details, and also supports de-stylization.


<details>
  <summary>Details</summary>
Motivation: The text-driven mechanism of diffusion models for style transfer is limited by treating textual descriptions as uniform guidance, overlooking the semantic gap between non-spatial text and spatial visual style, which leads to the loss of semantic structure and details.

Method: StyDeco employs Prior-Guided Data Distillation (PGD) to synthesize pseudo-paired data using a frozen generative model, and Contrastive Semantic Decoupling (CSD) to adapt a text encoder with domain-specific weights, encouraging distinct clusters for source and target representations.

Result: Extensive experiments on three classic benchmarks show that StyDeco outperforms several existing approaches in stylistic fidelity and structural preservation.

Conclusion: StyDeco is an effective unsupervised framework for style transfer that preserves semantic structure and fine-grained details by learning text representations tailored for the task. It outperforms existing approaches and supports de-stylization.

Abstract: Diffusion models have emerged as the dominant paradigm for style transfer,
but their text-driven mechanism is hindered by a core limitation: it treats
textual descriptions as uniform, monolithic guidance. This limitation overlooks
the semantic gap between the non-spatial nature of textual descriptions and the
spatially-aware attributes of visual style, often leading to the loss of
semantic structure and fine-grained details during stylization. In this paper,
we propose StyDeco, an unsupervised framework that resolves this limitation by
learning text representations specifically tailored for the style transfer
task. Our framework first employs Prior-Guided Data Distillation (PGD), a
strategy designed to distill stylistic knowledge without human supervision. It
leverages a powerful frozen generative model to automatically synthesize
pseudo-paired data. Subsequently, we introduce Contrastive Semantic Decoupling
(CSD), a task-specific objective that adapts a text encoder using
domain-specific weights. CSD performs a two-class clustering in the semantic
space, encouraging source and target representations to form distinct clusters.
Extensive experiments on three classic benchmarks demonstrate that our
framework outperforms several existing approaches in both stylistic fidelity
and structural preservation, highlighting its effectiveness in style transfer
with semantic preservation. In addition, our framework supports a unique
de-stylization process, further demonstrating its extensibility. Our code is
vailable at https://github.com/QuanjianSong/StyDeco.

</details>


### [36] [Perspective from a Broader Context: Can Room Style Knowledge Help Visual Floorplan Localization?](https://arxiv.org/abs/2508.01216)
*Bolei Chen,Shengsheng Yan,Yongzheng Cui,Jiaxu Kang,Ping Zhong,Jianxin Wang*

Main category: cs.CV

TL;DR: 本论文提出了一种新的视觉楼层定位方法，通过无监督学习一个房间判别器来提取场景上下文信息，从而消除定位的不确定性。该方法在实验中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的楼层定位方法要么依赖于匹配楼层平面图中的2D结构线索，要么依赖于3D几何约束的视觉预训练，而忽略了视觉图像提供的更丰富的上下文信息。楼层平面图具有许多重复的结构（例如，走廊和角落），容易导致模糊的定位。

Method: 提出了一种无监督学习技术，并结合聚类约束，在自收集的无标签房间图像上预训练一个房间判别器。该判别器可以提取观测图像中隐藏的房间类型，并将其与其他房间类型区分开。

Result: 实验结果表明，该方法在两个标准的视觉楼层定位基准上，优于现有的最先进方法，并在鲁棒性和准确性方面取得了显著的改进。

Conclusion: 通过注入场景上下文信息，利用判别器提取的房间类型知识来指导视觉楼层定位，以消除定位不确定性。该方法在两个标准的视觉楼层定位基准上进行了充分的比较研究，实验证明该方法优于现有技术，并在鲁棒性和准确性方面取得了显著的改进。

Abstract: Since a building's floorplan remains consistent over time and is inherently
robust to changes in visual appearance, visual Floorplan Localization (FLoc)
has received increasing attention from researchers. However, as a compact and
minimalist representation of the building's layout, floorplans contain many
repetitive structures (e.g., hallways and corners), thus easily result in
ambiguous localization. Existing methods either pin their hopes on matching 2D
structural cues in floorplans or rely on 3D geometry-constrained visual
pre-trainings, ignoring the richer contextual information provided by visual
images. In this paper, we suggest using broader visual scene context to empower
FLoc algorithms with scene layout priors to eliminate localization uncertainty.
In particular, we propose an unsupervised learning technique with clustering
constraints to pre-train a room discriminator on self-collected unlabeled room
images. Such a discriminator can empirically extract the hidden room type of
the observed image and distinguish it from other room types. By injecting the
scene context information summarized by the discriminator into an FLoc
algorithm, the room style knowledge is effectively exploited to guide definite
visual FLoc. We conducted sufficient comparative studies on two standard visual
Floc benchmarks. Our experiments show that our approach outperforms
state-of-the-art methods and achieves significant improvements in robustness
and accuracy.

</details>


### [37] [MoGaFace: Momentum-Guided and Texture-Aware Gaussian Avatars for Consistent Facial Geometry](https://arxiv.org/abs/2508.01218)
*Yujian Liu,Linlang Cao,Chuang Chen,Fanyu Geng,Dongxu Shen,Peng Cao,Shidang Xu,Xiaoli Liu*

Main category: cs.CV

TL;DR: MoGaFace 通过在渲染过程中持续优化几何和纹理，并引入动量引导的一致几何和潜在纹理注意力机制，解决了现有三维头部化身重建中网格与图像不对齐的问题，从而实现了更高保真度的重建和新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有的三维头部化身重建方法通常采用两阶段过程，依赖于从面部标志跟踪的 FLAME 网格，然后进行基于高斯的渲染。然而，估计的网格与目标图像之间的不对齐常常导致次优的渲染质量和精细视觉细节的损失。

Method: MoGaFace 是一个新颖的三维头部化身建模框架，通过高斯渲染过程不断优化面部几何和纹理属性。它引入了动量引导的一致几何模块（包括动量更新的表情库和表情感知校正机制）来解决估计网格和目标图像之间的不对齐问题，并确保时域和多视图的一致性。此外，它还提出了潜在纹理注意力机制，将紧凑的多视图特征编码为头部感知的表示，通过集成到高斯中来实现几何感知的纹理优化。

Result: MoGaFace 实现了高保真度的三维头部化身重建，并在新的视角合成质量方面取得了显著的改进，即使在初始网格不准确和不受限制的真实世界设置下也是如此。

Conclusion: MoGaFace 实现了高保真度的三维头部化身重建，并在新的视角合成质量方面取得了显著的改进，即使在初始网格不准确和不受限制的真实世界设置下也是如此。

Abstract: Existing 3D head avatar reconstruction methods adopt a two-stage process,
relying on tracked FLAME meshes derived from facial landmarks, followed by
Gaussian-based rendering. However, misalignment between the estimated mesh and
target images often leads to suboptimal rendering quality and loss of fine
visual details. In this paper, we present MoGaFace, a novel 3D head avatar
modeling framework that continuously refines facial geometry and texture
attributes throughout the Gaussian rendering process. To address the
misalignment between estimated FLAME meshes and target images, we introduce the
Momentum-Guided Consistent Geometry module, which incorporates a
momentum-updated expression bank and an expression-aware correction mechanism
to ensure temporal and multi-view consistency. Additionally, we propose Latent
Texture Attention, which encodes compact multi-view features into head-aware
representations, enabling geometry-aware texture refinement via integration
into Gaussians. Extensive experiments show that MoGaFace achieves high-fidelity
head avatar reconstruction and significantly improves novel-view synthesis
quality, even under inaccurate mesh initialization and unconstrained real-world
settings.

</details>


### [38] [Eigen Neural Network: Unlocking Generalizable Vision with Eigenbasis](https://arxiv.org/abs/2508.01219)
*Anzhe Cheng,Chenzhong Yin,Mingxi Cheng,Shukai Duan,Shahin Nazarian,Paul Bogdan*

Main category: cs.CV

TL;DR: ENN 是一种新的神经网络架构，它通过在权重中使用正交特征基来解决 DNN 中的权重结构混乱问题，从而提高性能并实现更快的训练速度。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）的成功依赖于梯度下降优化，但该过程易受其产生的无序权重结构的影响，损害了特征的清晰度和学习动态。为了解决这种根本性的表示缺陷，我们提出了 ENN。

Method: 提出了一种名为 Eigen Neural Network (ENN) 的新颖架构，它在每个层的权重上引入了一个层共享、可学习的正交特征基。这种设计通过公理强制执行去相关、对齐良好的权重动力学，而不是依赖于正则化。

Result: ENN 在大型图像分类基准（包括 ImageNet）上始终优于最先进的方法，并且其优越的表示在跨模态图像-文本检索方面设定了新的基准。此外，ENN 的结构化设计实现了一种高效的、无反向传播的本地学习变体 ENN-ℓ，该变体实现了超过 2 倍的训练加速，并且准确率超过了端到端的反向传播。

Conclusion: ENN 通过强制执行去相关、对齐良好的权重动力学，并提供一种高效、无反向传播的本地学习变体 ENN-ℓ，从而修复了 DNN 中的表示缺陷，提高了性能并实现了更高效、可并行化的训练。

Abstract: The remarkable success of Deep Neural Networks(DNN) is driven by
gradient-based optimization, yet this process is often undermined by its
tendency to produce disordered weight structures, which harms feature clarity
and degrades learning dynamics. To address this fundamental representational
flaw, we introduced the Eigen Neural Network (ENN), a novel architecture that
reparameterizes each layer's weights in a layer-shared, learned orthonormal
eigenbasis. This design enforces decorrelated, well-aligned weight dynamics
axiomatically, rather than through regularization, leading to more structured
and discriminative feature representations. When integrated with standard BP,
ENN consistently outperforms state-of-the-art methods on large-scale image
classification benchmarks, including ImageNet, and its superior representations
generalize to set a new benchmark in cross-modal image-text retrieval.
Furthermore, ENN's principled structure enables a highly efficient,
backpropagation-free(BP-free) local learning variant, ENN-$\ell$. This variant
not only resolves BP's procedural bottlenecks to achieve over 2$\times$
training speedup via parallelism, but also, remarkably, surpasses the accuracy
of end-to-end backpropagation. ENN thus presents a new architectural paradigm
that directly remedies the representational deficiencies of BP, leading to
enhanced performance and enabling a more efficient, parallelizable training
regime.

</details>


### [39] [ParaRevSNN: A Parallel Reversible Spiking Neural Network for Efficient Training and Inference](https://arxiv.org/abs/2508.01223)
*Changqing Xu,Guoqing Sun,Yi Liu,Xinfang Liao,Yintang Yang*

Main category: cs.CV

TL;DR: ParaRevSNN 是一种新的并行 RevSNN 架构，通过并行处理缩短了训练和推理时间，同时保持了 RevSNN 的内存优势，在准确性上不打折扣，非常适合资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有可逆尖峰神经网络（RevSNNs）因严格的顺序计算导致的高延迟问题，同时保留其内存效率优势。

Method: 提出了一种名为 ParaRevSNN 的并行可逆尖峰神经网络架构，该架构通过解耦可逆块之间的顺序依赖性来实现块间并行，从而在保持可逆性的同时显著提高训练和推理速度。

Result: ParaRevSNN 在 CIFAR10、CIFAR100、CIFAR10-DVS 和 DVS128 Gesture 数据集上，在准确性上与标准 RevSNN 相当或更优，训练时间减少高达 35.2%，推理时间减少 18.15%。

Conclusion: ParaRevSNN 架构通过解耦可逆块之间的顺序依赖性并保持可逆性，克服了标准可逆尖峰神经网络（RevSNN）的高延迟问题。实验证明，ParaRevSNN 在 CIFAR10、CIFAR100、CIFAR10-DVS 和 DVS128 Gesture 数据集上，在准确性上能与标准 RevSNN 相媲美甚至超越，同时将训练时间缩短了高达 35.2%，并将推理时间缩短了 18.15%。

Abstract: Reversible Spiking Neural Networks (RevSNNs) enable memory-efficient training
by reconstructing forward activations during backpropagation, but suffer from
high latency due to strictly sequential computation. To overcome this
limitation, we propose ParaRevSNN, a parallel reversible SNN architecture that
decouples sequential dependencies between reversible blocks while preserving
reversibility. This design enables inter-block parallelism, significantly
accelerating training and inference while retaining the memory-saving benefits
of reversibility. Experiments on CIFAR10, CIFAR100, CIFAR10-DVS, and DVS128
Gesture demonstrate that ParaRevSNN matches or exceeds the accuracy of standard
RevSNNs, while reducing training time by up to 35.2\% and inference time to
18.15\%, making it well-suited for deployment in resource-constrained
scenarios.

</details>


### [40] [Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models](https://arxiv.org/abs/2508.01225)
*Xinyu Chen,Haotian Zhai,Can Zhang,Xiupeng Shi,Ruirui Li*

Main category: cs.CV

TL;DR: 在零样本设置下，测试时间自适应（TTA）通过使用来自测试阶段的无标签数据来调整预训练模型，以增强在未知测试分布上的性能。现有的缓存增强TTA方法依赖低熵准则来选择样本以构建原型，但低熵样本在分布偏移下可能并不可靠，并且由此产生的原型可能无法确保紧凑的类内分布。本研究发现了缓存增强性能与类内紧密度之间的正相关关系。基于此发现，我们提出了一种多缓存增强的原型测试时间自适应（MCP），其包含三个缓存：熵缓存用于使用低熵样本初始化原型表示；对齐缓存用于整合视觉和文本信息以实现紧凑的类内分布；负缓存用于使用高熵样本进行预测校准。我们进一步开发了MCP++框架，该框架整合了跨模态原型对齐和残差学习，并引入了原型残差微调。在15个下游任务上的比较和消融实验证明，我们提出的方法和框架实现了最先进的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有缓存增强TTA方法依赖低熵准则选择样本构建原型，但低熵样本在分布偏移下可能不可靠，导致原型无法保证紧凑的类内分布。本研究旨在解决此问题，发现缓存增强性能与类内紧密度存在正相关。

Method: 提出了一种多缓存原型测试时间自适应（MCP）方法，包含三个缓存：熵缓存用于低熵样本初始化原型表示，对齐缓存用于整合视觉和文本信息以实现紧凑的类内分布，负缓存用于高熵样本的预测校准。此外，还提出了MCP++框架，结合了跨模态原型对齐和残差学习，并引入了原型残差微调。

Result: 与现有方法相比，MCP和MCP++在15个下游任务上的实验表明，该方法和框架实现了最先进的泛化性能。

Conclusion: 所提出的多缓存原型测试时间自适应（MCP）及其框架MCP++通过利用熵缓存、对齐缓存和负缓存，并结合跨模态原型对齐和残差学习，在15个下游任务上实现了最先进的泛化性能。

Abstract: In zero-shot setting, test-time adaptation adjusts pre-trained models using
unlabeled data from the test phase to enhance performance on unknown test
distributions. Existing cache-enhanced TTA methods rely on a low-entropy
criterion to select samples for prototype construction, assuming intra-class
compactness. However, low-entropy samples may be unreliable under distribution
shifts, and the resulting prototypes may not ensure compact intra-class
distributions. This study identifies a positive correlation between
cache-enhanced performance and intra-class compactness. Based on this
observation, we propose a Multi-Cache enhanced Prototype-based Test-Time
Adaptation (MCP) featuring three caches: an entropy cache for initializing
prototype representations with low-entropy samples, an align cache for
integrating visual and textual information to achieve compact intra-class
distributions, and a negative cache for prediction calibration using
high-entropy samples. We further developed MCP++, a framework incorporating
cross-modal prototype alignment and residual learning, introducing prototype
residual fine-tuning. Comparative and ablation experiments across 15 downstream
tasks demonstrate that the proposed method and framework achieve
state-of-the-art generalization performance.

</details>


### [41] [Enhancing Multi-view Open-set Learning via Ambiguity Uncertainty Calibration and View-wise Debiasing](https://arxiv.org/abs/2508.01227)
*Zihan Fang,Zhiyong Xu,Lan Du,Shide Du,Zhiling Cai,Shiping Wang*

Main category: cs.CV

TL;DR: 为解决多视图学习在识别未知类别时遇到的困难，本研究提出了一种新的框架，通过生成特殊的虚拟样本并进行去偏操作，有效提升了模型在开放集场景下的表现，同时保持了原有的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图学习模型在开放集场景下表现不佳，因为它们隐含地假设类别是完整的，并且静态视图会引入时而与标签相关联的虚假关联，这进一步削弱了它们识别未知类别的能力。

Method: 提出了一种通过模糊性不确定性校准和跨视图去偏的多视图开放集学习框架。设计了O-Mix合成策略生成具有校准的开放集模糊性不确定性的虚拟样本，并通过辅助模糊性感知网络捕捉非典型模式。此外，还包含一个基于HSIC的对比去偏模块，强制视图特定模糊和视图一致表示的独立性。

Result: 实验证明，该框架在多个多视图基准测试中，在提高未知类别识别能力方面表现一致，同时保持了强大的闭集性能。

Conclusion: 所提出的框架通过模糊性不确定性校准和跨视图去偏，在提高未知类别识别能力的同时，保持了良好的闭集性能。

Abstract: Existing multi-view learning models struggle in open-set scenarios due to
their implicit assumption of class completeness. Moreover, static view-induced
biases, which arise from spurious view-label associations formed during
training, further degrade their ability to recognize unknown categories. In
this paper, we propose a multi-view open-set learning framework via ambiguity
uncertainty calibration and view-wise debiasing. To simulate ambiguous samples,
we design O-Mix, a novel synthesis strategy to generate virtual samples with
calibrated open-set ambiguity uncertainty. These samples are further processed
by an auxiliary ambiguity perception network that captures atypical patterns
for improved open-set adaptation. Furthermore, we incorporate an HSIC-based
contrastive debiasing module that enforces independence between view-specific
ambiguous and view-consistent representations, encouraging the model to learn
generalizable features. Extensive experiments on diverse multi-view benchmarks
demonstrate that the proposed framework consistently enhances unknown-class
recognition while preserving strong closed-set performance.

</details>


### [42] [Mitigating Information Loss under High Pruning Rates for Efficient Large Vision Language Models](https://arxiv.org/abs/2508.01236)
*Mingyu Fu,Wei Suo,Ji Ma,Lin Yuanbo Wu,Peng Wang,Yanning Zhang*

Main category: cs.CV

TL;DR: ACCM通过图像描述来降低LVLMs的计算成本，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）因其高计算成本限制了广泛应用，这主要是由于输入中的视觉序列包含大量标记。现有方法通过移除冗余标记来降低成本，但在高剪枝率下会因视觉信息丢失导致严重性能下降。

Method: 提出了一种自适应内容补偿方法（ACCM），包含一个轻量级图像描述模型和一个选择器。图像描述模型在用户指令的指导下生成与问题相关的描述，选择器则从多个候选描述中识别出语境上合适的描述。ACCM利用自监督学习进行训练，无需人工或自动标注。

Result: ACCM在包含七个基准测试的广泛实验中，以更低的FLOPs显著优于现有方法（例如，在FLOPs减少6.5%的情况下，性能提升20.6%）。

Conclusion: ACCM通过生成图像的描述来有效缓解视觉信息丢失，相比现有方法在FLOPs更低的情况下显著提高了性能，在七个基准测试中表现优于SOTA方法。

Abstract: Despite the great success of Large Vision Language Models (LVLMs), their high
computational cost severely limits their broad applications. The computational
cost of LVLMs mainly stems from the visual sequence of the input, which
consists of hundreds or even thousands of tokens. Although existing methods
have made progress by removing redundant tokens, they suffer from severe
performance degradation with high pruning rates due to the loss of visual
information. In this paper, we propose an Adaptive Content Compensation Method
(ACCM), which can effectively mitigate the visual information loss via an image
caption. Specifically, ACCM comprises two key components: a lightweight caption
model and a selector. Firstly the caption model generates question-related
descriptions under the guidance of the user instruction. Then the selector
further identifies a contextually appropriate caption from multiple candidates.
Leveraging self-supervised learning, our modules could be learned efficiently
without any human or automated labeling. We conduct extensive experiments
across seven benchmarks and the results show that ACCM significantly
outperforms existing methods with lower FLOPs (e.g., surpassing SOTA by 20.6%
with 6.5% fewer FLOPs).

</details>


### [43] [OCSplats: Observation Completeness Quantification and Label Noise Separation in 3DGS](https://arxiv.org/abs/2508.01239)
*Han Ling,Xian Xu,Yinghui Sun,Quansen Sun*

Main category: cs.CV

TL;DR: OCSplats 框架通过混合噪声评估、认知校正和动态锚点管道解决了 3DGS 重建中的标签噪声问题，提高了准确性并无需参数调整。


<details>
  <summary>Details</summary>
Motivation: 现实世界场景中的标签噪声（如移动对象、非朗伯表面和阴影）会导致 3DGS 重建错误，而现有的 3DGS-Bsed 抗噪声重建方法难以有效分离噪声或需要场景特定的超参数微调。

Method: OCSplats 框架通过结合混合噪声评估和基于观察的认知校正等关键技术，以及基于动态锚点的标签噪声分类管道，提高了噪声分类的准确性，并能够同时应用于具有显著不同噪声比例的场景，无需调整参数。

Result: OCSplats 框架显著提高了在具有认知差异的区域中噪声分类的准确性，并且在不同场景下无需调整参数即可应用，始终 achieves 领先的重建性能和精确的标签噪声分类。

Conclusion: OCSplats 在不同复杂度的场景中始终 achieves 领先的重建性能和精确的标签噪声分类。

Abstract: 3D Gaussian Splatting (3DGS) has become one of the most promising 3D
reconstruction technologies. However, label noise in real-world scenarios-such
as moving objects, non-Lambertian surfaces, and shadows-often leads to
reconstruction errors. Existing 3DGS-Bsed anti-noise reconstruction methods
either fail to separate noise effectively or require scene-specific fine-tuning
of hyperparameters, making them difficult to apply in practice. This paper
re-examines the problem of anti-noise reconstruction from the perspective of
epistemic uncertainty, proposing a novel framework, OCSplats. By combining key
technologies such as hybrid noise assessment and observation-based cognitive
correction, the accuracy of noise classification in areas with cognitive
differences has been significantly improved. Moreover, to address the issue of
varying noise proportions in different scenarios, we have designed a label
noise classification pipeline based on dynamic anchor points. This pipeline
enables OCSplats to be applied simultaneously to scenarios with vastly
different noise proportions without adjusting parameters. Extensive experiments
demonstrate that OCSplats always achieve leading reconstruction performance and
precise label noise classification in scenes of different complexity levels.

</details>


### [44] [NS-Net: Decoupling CLIP Semantic Information through NULL-Space for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2508.01248)
*Jiazhen Yan,Fan Wang,Weiwei Jiang,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

TL;DR: NS-Net 通过利用 NULL-Space 投影解耦 CLIP 特征中的语义信息，并结合对比学习和补丁选择策略，提高了 AI 生成图像检测的准确性和泛化能力，尤其是在真实和伪造图像语义内容相似的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有 AI 生成图像检测器在面对未知的生成模型，特别是当真实和伪造图像之间的语义内容高度一致时，泛化能力不足。CLIP 视觉特征中的高层语义信息阻碍了有效区分。

Method: NS-Net 提出了一种新的检测框架，该框架利用 NULL-Space 投影来解耦 CLIP 视觉特征中的语义信息，然后通过对比学习来捕获真实图像和生成图像之间内在的分布差异。此外，还设计了一种补丁选择策略，通过减轻由全局图像结构引起的语义偏差来保留细粒度伪影。

Result: NS-Net 在包含 40 种不同生成模型的开放世界基准测试中，相比现有最先进的方法在检测准确率方面提高了 7.4%。

Conclusion: NS-Net 在包含 40 种不同生成模型的开放世界基准测试中，相比现有最先进的方法在检测准确率方面提高了 7.4%，证明了其在 GAN 和扩散模型生成的图像方面具有强大的泛化能力。

Abstract: The rapid progress of generative models, such as GANs and diffusion models,
has facilitated the creation of highly realistic images, raising growing
concerns over their misuse in security-sensitive domains. While existing
detectors perform well under known generative settings, they often fail to
generalize to unknown generative models, especially when semantic content
between real and fake images is closely aligned. In this paper, we revisit the
use of CLIP features for AI-generated image detection and uncover a critical
limitation: the high-level semantic information embedded in CLIP's visual
features hinders effective discrimination. To address this, we propose NS-Net,
a novel detection framework that leverages NULL-Space projection to decouple
semantic information from CLIP's visual features, followed by contrastive
learning to capture intrinsic distributional differences between real and
generated images. Furthermore, we design a Patch Selection strategy to preserve
fine-grained artifacts by mitigating semantic bias caused by global image
structures. Extensive experiments on an open-world benchmark comprising images
generated by 40 diverse generative models show that NS-Net outperforms existing
state-of-the-art methods, achieving a 7.4\% improvement in detection accuracy,
thereby demonstrating strong generalization across both GAN- and
diffusion-based image generation techniques.

</details>


### [45] [DisFaceRep: Representation Disentanglement for Co-occurring Facial Components in Weakly Supervised Face Parsing](https://arxiv.org/abs/2508.01250)
*Xiaoqin Wang,Xianxu Hou,Meidan Ding,Junliang Chen,Kaijun Deng,Jinheng Xie,Linlin Shen*

Main category: cs.CV

TL;DR: This paper introduces Weakly Supervised Face Parsing (WSFP) using image-level labels and text descriptions instead of dense pixel annotations. They propose DisFaceRep, a framework that disentangles facial components using explicit and implicit mechanisms, achieving state-of-the-art results on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: To reduce the cost and labor of obtaining dense pixel-level annotations for face parsing by introducing a weakly supervised face parsing (WSFP) task that uses image-level labels and natural language descriptions.

Method: DisFaceRep, a representation disentanglement framework that uses a co-occurring component disentanglement strategy and a text-guided component disentanglement loss to separate facial components using weak supervision.

Result: WSFP presents challenges due to co-occurring and visually similar facial components, leading to ambiguous activations and degraded parsing performance. DisFaceRep effectively addresses these challenges.

Conclusion: DisFaceRep significantly outperforms existing weakly supervised semantic segmentation methods on CelebAMask-HQ, LaPa, and Helen datasets for the WSFP task.

Abstract: Face parsing aims to segment facial images into key components such as eyes,
lips, and eyebrows. While existing methods rely on dense pixel-level
annotations, such annotations are expensive and labor-intensive to obtain. To
reduce annotation cost, we introduce Weakly Supervised Face Parsing (WSFP), a
new task setting that performs dense facial component segmentation using only
weak supervision, such as image-level labels and natural language descriptions.
WSFP introduces unique challenges due to the high co-occurrence and visual
similarity of facial components, which lead to ambiguous activations and
degraded parsing performance. To address this, we propose DisFaceRep, a
representation disentanglement framework designed to separate co-occurring
facial components through both explicit and implicit mechanisms. Specifically,
we introduce a co-occurring component disentanglement strategy to explicitly
reduce dataset-level bias, and a text-guided component disentanglement loss to
guide component separation using language supervision implicitly. Extensive
experiments on CelebAMask-HQ, LaPa, and Helen demonstrate the difficulty of
WSFP and the effectiveness of DisFaceRep, which significantly outperforms
existing weakly supervised semantic segmentation methods. The code will be
released at
\href{https://github.com/CVI-SZU/DisFaceRep}{\textcolor{cyan}{https://github.com/CVI-SZU/DisFaceRep}}.

</details>


### [46] [ODOV: Towards Open-Domain Open-Vocabulary Object Detection](https://arxiv.org/abs/2508.01253)
*Yupeng Zhang,Ruize Han,Fangnan Zhou,Song Wang,Wei Feng,Liang Wan*

Main category: cs.CV

TL;DR: 本研究提出了开放域开放词汇（ODOV）目标检测问题，构建了OD-LVIS基准测试集，并开发了一种利用大型语言模型和领域嵌入来提高模型在不同领域和类别下适应性的新方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对开放域开放词汇（ODOV）目标检测中现实世界存在的领域和类别偏移问题，本研究旨在提高模型在不同领域和类别下的适应性。

Method: 研究人员利用大型语言模型生成领域不可知类别提示，并学习图像的领域嵌入，在测试时将领域嵌入与类别嵌入结合，形成针对特定测试图像的领域特定类别嵌入。

Result: 所提出的ODOV检测方法在OD-LVIS基准测试上进行了充分的评估，结果验证了ODOV检测的合理性、基准测试的有效性以及所提出方法的优越性。

Conclusion: 该研究提出了一个新的开放域开放词汇（ODOV）目标检测问题，并构建了一个名为OD-LVIS的新基准测试集，包含46,949张图像、18个真实世界域和1,203个类别，旨在评估真实世界目标检测的性能。此外，研究还开发了一种新颖的基线方法，利用大型语言模型生成领域不可知类别提示，并学习图像的领域嵌入，在测试时将领域嵌入与类别嵌入结合，形成针对特定测试图像的领域特定类别嵌入。

Abstract: In this work, we handle a new problem of Open-Domain Open-Vocabulary (ODOV)
object detection, which considers the detection model's adaptability to the
real world including both domain and category shifts. For this problem, we
first construct a new benchmark OD-LVIS, which includes 46,949 images, covers
18 complex real-world domains and 1,203 categories, and provides a
comprehensive dataset for evaluating real-world object detection. Besides, we
develop a novel baseline method for ODOV detection.The proposed method first
leverages large language models to generate the domain-agnostic text prompts
for category embedding. It further learns the domain embedding from the given
image, which, during testing, can be integrated into the category embedding to
form the customized domain-specific category embedding for each test image. We
provide sufficient benchmark evaluations for the proposed ODOV detection task
and report the results, which verify the rationale of ODOV detection, the
usefulness of our benchmark, and the superiority of the proposed method.

</details>


### [47] [Self-Enhanced Image Clustering with Cross-Modal Semantic Consistency](https://arxiv.org/abs/2508.01254)
*Zihan Li,Wei Sun,Jing Hu,Jianhua Yin,Jianlong Wu,Liqiang Nie*

Main category: cs.CV

TL;DR: 本文提出了一种自增强框架，通过跨模态语义一致性和自增强微调，有效解决了图像聚类中预训练模型编码器冻结带来的性能瓶颈，并在多个数据集上取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CLIP等大型语言-图像预训练模型的方法，在进行图像聚类时通常会冻结编码器，导致模型通用的表征与其特定聚类任务的需求之间存在根本性不匹配，从而限制了性能的进一步提升。本文旨在打破这一性能瓶颈。

Method: 本文提出了一种基于跨模态语义一致性的自增强框架，用于高效的图像聚类。该框架分为两个阶段：首先，通过挖掘生成图像-文本对在实例、聚类分配和聚类中心级别的 স্ব-consistency，训练轻量级聚类头，以匹配预训练模型的丰富语义。此阶段引入了生成更高质量聚类中心的新颖方法和动态平衡正则化器。其次，引入自增强微调策略，利用第一阶段对齐良好的模型作为伪标签生成器，通过自生成监督信号实现视觉编码器和聚类头的联合优化。

Result: 所提出的方法在六个主流数据集上取得了优于现有深度聚类方法的显著性能提升，并且ViT-B/32模型已能匹配或超越使用更大ViT-L/14的模型。

Conclusion: 所提出的方法在六个主流数据集上进行了广泛的实验，其性能优于现有的深度聚类方法，并且ViT-B/32模型在准确性上已能媲美甚至超越基于更大ViT-L/14的最新方法。

Abstract: While large language-image pre-trained models like CLIP offer powerful
generic features for image clustering, existing methods typically freeze the
encoder. This creates a fundamental mismatch between the model's task-agnostic
representations and the demands of a specific clustering task, imposing a
ceiling on performance. To break this ceiling, we propose a self-enhanced
framework based on cross-modal semantic consistency for efficient image
clustering. Our framework first builds a strong foundation via Cross-Modal
Semantic Consistency and then specializes the encoder through Self-Enhancement.
In the first stage, we focus on Cross-Modal Semantic Consistency. By mining
consistency between generated image-text pairs at the instance, cluster
assignment, and cluster center levels, we train lightweight clustering heads to
align with the rich semantics of the pre-trained model. This alignment process
is bolstered by a novel method for generating higher-quality cluster centers
and a dynamic balancing regularizer to ensure well-distributed assignments. In
the second stage, we introduce a Self-Enhanced fine-tuning strategy. The
well-aligned model from the first stage acts as a reliable pseudo-label
generator. These self-generated supervisory signals are then used to feed back
the efficient, joint optimization of the vision encoder and clustering heads,
unlocking their full potential. Extensive experiments on six mainstream
datasets show that our method outperforms existing deep clustering methods by
significant margins. Notably, our ViT-B/32 model already matches or even
surpasses the accuracy of state-of-the-art methods built upon the far larger
ViT-L/14.

</details>


### [48] [SpatioTemporal Difference Network for Video Depth Super-Resolution](https://arxiv.org/abs/2508.01259)
*Zhengxue Wang,Yuan Wu,Xiang Li,Zhiqiang Yan,Jian Yang*

Main category: cs.CV

TL;DR: 提出了一种新的STDNet网络，通过空间和时间差异分支来解决视频深度超分辨率中的长尾分布问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 视频深度超分辨率仍然受到长尾分布的影响，尤其是在空间非平滑区域和时间变化区域。

Method: 提出了一种新颖的时空差异网络（STDNet），包含空间差异分支和时间差异分支。空间差异分支引入空间差异机制，通过动态对齐RGB特征和学习到的空间差异表示，实现帧内RGB-D聚合以进行深度校准。时间差异分支设计了时间差异策略，优先从相邻的RGB和深度帧向当前深度帧传播时间变化信息，利用时间差异表示实现时间长尾区域的精确运动补偿。

Result: 与现有方法相比，STDNet表现出优越的性能。

Conclusion: STDNet在多个数据集上的广泛实验结果证明了其有效性，优于现有方法。

Abstract: Depth super-resolution has achieved impressive performance, and the
incorporation of multi-frame information further enhances reconstruction
quality. Nevertheless, statistical analyses reveal that video depth
super-resolution remains affected by pronounced long-tailed distributions, with
the long-tailed effects primarily manifesting in spatial non-smooth regions and
temporal variation zones. To address these challenges, we propose a novel
SpatioTemporal Difference Network (STDNet) comprising two core branches: a
spatial difference branch and a temporal difference branch. In the spatial
difference branch, we introduce a spatial difference mechanism to mitigate the
long-tailed issues in spatial non-smooth regions. This mechanism dynamically
aligns RGB features with learned spatial difference representations, enabling
intra-frame RGB-D aggregation for depth calibration. In the temporal difference
branch, we further design a temporal difference strategy that preferentially
propagates temporal variation information from adjacent RGB and depth frames to
the current depth frame, leveraging temporal difference representations to
achieve precise motion compensation in temporal long-tailed areas. Extensive
experimental results across multiple datasets demonstrate the effectiveness of
our STDNet, outperforming existing approaches.

</details>


### [49] [Enhancing Diffusion-based Dataset Distillation via Adversary-Guided Curriculum Sampling](https://arxiv.org/abs/2508.01264)
*Lexiao Zou,Gongwei Chen,Yanda Chen,Miao Zhang*

Main category: cs.CV

TL;DR: ACS通过对抗性课程学习来提高扩散模型生成的数据集的多样性和信息覆盖范围，从而提升了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散模型生成的图像缺乏多样性，可能导致信息冗余的问题。

Method: 提出了一种名为对抗性引导课程采样（ACS）的方法，该方法将蒸馏数据集划分为多个课程。在生成每个课程时，ACS通过对抗性损失指导扩散采样过程，以挑战在采样图像上训练的判别器。

Result: ACS实现了4.1%的Imagewoof和2.1%的ImageNet-1k的提升，优于现有技术。

Conclusion: ACS通过挑战判别器来指导扩散采样过程，以减少课程之间的信息重叠，从而生成更多样化的蒸馏数据集。实验证明ACS在Imagewoof和ImageNet-1k上分别取得了4.1%和2.1%的提升。

Abstract: Dataset distillation aims to encapsulate the rich information contained in
dataset into a compact distilled dataset but it faces performance degradation
as the image-per-class (IPC) setting or image resolution grows larger. Recent
advancements demonstrate that integrating diffusion generative models can
effectively facilitate the compression of large-scale datasets while
maintaining efficiency due to their superiority in matching data distribution
and summarizing representative patterns. However, images sampled from diffusion
models are always blamed for lack of diversity which may lead to information
redundancy when multiple independent sampled images are aggregated as a
distilled dataset. To address this issue, we propose Adversary-guided
Curriculum Sampling (ACS), which partitions the distilled dataset into multiple
curricula. For generating each curriculum, ACS guides diffusion sampling
process by an adversarial loss to challenge a discriminator trained on sampled
images, thus mitigating information overlap between curricula and fostering a
more diverse distilled dataset. Additionally, as the discriminator evolves with
the progression of curricula, ACS generates images from simpler to more
complex, ensuring efficient and systematic coverage of target data
informational spectrum. Extensive experiments demonstrate the effectiveness of
ACS, which achieves substantial improvements of 4.1\% on Imagewoof and 2.1\% on
ImageNet-1k over the state-of-the-art.

</details>


### [50] [ModelNet40-E: An Uncertainty-Aware Benchmark for Point Cloud Classification](https://arxiv.org/abs/2508.01269)
*Pedro Alonso,Tianrui Li,Chongshou Li*

Main category: cs.CV

TL;DR: 提出ModelNet40-E基准，用于评估点云分类模型在激光雷达噪声下的鲁棒性和校准性。Point Transformer v3在噪声下表现出更好的校准性。


<details>
  <summary>Details</summary>
Motivation: 评估点云分类模型在合成激光雷达类噪声下的鲁棒性和校准性，并提供一种能够进行细粒度评估的新基准。

Method: 提出了一种名为ModelNet40-E的新基准，该基准包含噪声损坏的点云和逐点不确定性注释（通过高斯噪声参数{\sigma}, {\mu}提供），以评估点云分类模型的鲁棒性和校准性。使用了PointNet, DGCNN, and Point Transformer v3三个模型，并评估了它们在不同噪声水平下的分类准确率、校准指标和不确定性感知能力。

Result: 随着噪声水平的增加，所有被评估的模型性能均有下降。Point Transformer v3 在校准性方面表现更优，其预测的不确定性与底层测量不确定性更为吻合。

Conclusion: Point Transformer v3 在噪声条件下表现出更好的校准性，其预测的不确定性与底层测量不确定性更接近。

Abstract: We introduce ModelNet40-E, a new benchmark designed to assess the robustness
and calibration of point cloud classification models under synthetic LiDAR-like
noise. Unlike existing benchmarks, ModelNet40-E provides both noise-corrupted
point clouds and point-wise uncertainty annotations via Gaussian noise
parameters ({\sigma}, {\mu}), enabling fine-grained evaluation of uncertainty
modeling. We evaluate three popular models-PointNet, DGCNN, and Point
Transformer v3-across multiple noise levels using classification accuracy,
calibration metrics, and uncertainty-awareness. While all models degrade under
increasing noise, Point Transformer v3 demonstrates superior calibration, with
predicted uncertainties more closely aligned with the underlying measurement
uncertainty.

</details>


### [51] [SGCap: Decoding Semantic Group for Zero-shot Video Captioning](https://arxiv.org/abs/2508.01270)
*Zeyu Pan,Ping Li,Wenxiao Wang*

Main category: cs.CV

TL;DR: 提出了一种名为SGCap的零样本视频字幕方法，通过语义分组解码（SGD）、关键句子选择（KSS）和概率采样监督（PSS）来解决现有方法的局限性，并在实验中取得了优于现有零样本方法和媲美完全监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本图像字幕方法通常采用仅文本训练范式，其中语言解码器重建从CLIP获得的单句嵌入。然而，直接将其扩展到视频域并非最优，因为对所有帧应用平均池化会忽略时间动态。为了解决这个挑战，本研究提出了一种语义分组字幕（SGCap）方法。

Method: 提出了一种名为语义分组字幕（SGCap）的方法，用于零样本视频字幕。具体来说，它开发了语义分组解码（SGD）策略，采用多帧信息，同时显式地对帧间时间关系进行建模。此外，还引入了关键句子选择（KSS）模块和概率采样监督（PSS）模块，以构建语义多样化的句子组，从而增强其视频字幕的泛化能力。

Result: 实验结果表明，SGCap显著优于先前最先进的零样本方法，并且在完全监督的方法方面也具有竞争力。

Conclusion: SGCap 在多个基准测试中显著优于先前最先进的零样本方法，甚至在完全监督的方法方面也具有竞争力。

Abstract: Zero-shot video captioning aims to generate sentences for describing videos
without training the model on video-text pairs, which remains underexplored.
Existing zero-shot image captioning methods typically adopt a text-only
training paradigm, where a language decoder reconstructs single-sentence
embeddings obtained from CLIP. However, directly extending them to the video
domain is suboptimal, as applying average pooling over all frames neglects
temporal dynamics. To address this challenge, we propose a Semantic Group
Captioning (SGCap) method for zero-shot video captioning. In particular, it
develops the Semantic Group Decoding (SGD) strategy to employ multi-frame
information while explicitly modeling inter-frame temporal relationships.
Furthermore, existing zero-shot captioning methods that rely on cosine
similarity for sentence retrieval and reconstruct the description supervised by
a single frame-level caption, fail to provide sufficient video-level
supervision. To alleviate this, we introduce two key components, including the
Key Sentences Selection (KSS) module and the Probability Sampling Supervision
(PSS) module. The two modules construct semantically-diverse sentence groups
that models temporal dynamics and guide the model to capture inter-sentence
causal relationships, thereby enhancing its generalization ability to video
captioning. Experimental results on several benchmarks demonstrate that SGCap
significantly outperforms previous state-of-the-art zero-shot alternatives and
even achieves performance competitive with fully supervised ones. Code is
available at https://github.com/mlvccn/SGCap_Video.

</details>


### [52] [PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation](https://arxiv.org/abs/2508.01272)
*Zonglei Jing,Xiao Yang,Xiaoqian Li,Siyuan Liang,Aishan Liu,Mingchuan Zhang,Xianglong Liu*

Main category: cs.CV

TL;DR: PromptSafe是一种创新的T2I安全框架，通过仅文本的软嵌入和自适应门控机制，有效减少不安全内容生成，同时保护良性内容质量，并具备良好的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的T2I模型容易生成不安全内容（NSFW），而当前的软提示引导调整方法依赖于大型标注数据集和静态防御，导致计算成本高、良性图像质量下降，并且难以适应真实世界提示的复杂安全需求。

Method: PromptSafe提出了一种门控提示调优框架，结合了轻量级的、仅文本的监督软嵌入和推理时门控控制网络。它首先使用LLM将不安全提示改写为语义对齐但安全的替代提示，构建了一个高效的仅文本训练语料库。然后，在扩散去噪过程中优化了一个通用的软提示，以排斥不安全嵌入并吸引安全嵌入。为了避免过度抑制良性提示，该框架引入了一个门控机制，根据估计的提示毒性自适应地调整防御强度，从而使防御强度与提示风险保持一致。

Result: PromptSafe在多个基准测试和T2I模型上实现了最先进的不安全生成率（2.36%），同时保持了高良性保真度。它还表现出对未见过的有害类别的强大泛化能力、跨扩散模型架构的鲁棒可转移性以及对自适应对抗性攻击的弹性。

Conclusion: PromptSafe通过其轻量级的、仅文本的软嵌入和推理时门控控制网络，在T2I安全领域取得了先进的成果，实现了低不安全生成率（2.36%），同时保持了高良性保真度，并在各种基准测试和T2I模型上表现出强大的泛化能力、跨模型架构的可转移性以及对自适应对抗性攻击的鲁棒性，证明了其在安全和可扩展部署中的实用价值。

Abstract: Text-to-image (T2I) models have demonstrated remarkable generative
capabilities but remain vulnerable to producing not-safe-for-work (NSFW)
content, such as violent or explicit imagery. While recent moderation efforts
have introduced soft prompt-guided tuning by appending defensive tokens to the
input, these approaches often rely on large-scale curated image-text datasets
and apply static, one-size-fits-all defenses at inference time. However, this
results not only in high computational cost and degraded benign image quality,
but also in limited adaptability to the diverse and nuanced safety requirements
of real-world prompts. To address these challenges, we propose PromptSafe, a
gated prompt tuning framework that combines a lightweight, text-only supervised
soft embedding with an inference-time gated control network. Instead of
training on expensive image-text datasets, we first rewrite unsafe prompts into
semantically aligned but safe alternatives using an LLM, constructing an
efficient text-only training corpus. Based on this, we optimize a universal
soft prompt that repels unsafe and attracts safe embeddings during the
diffusion denoising process. To avoid over-suppressing benign prompts, we
introduce a gated mechanism that adaptively adjusts the defensive strength
based on estimated prompt toxicity, thereby aligning defense intensity with
prompt risk and ensuring strong protection for harmful inputs while preserving
benign generation quality. Extensive experiments across multiple benchmarks and
T2I models show that PromptSafe achieves a SOTA unsafe generation rate (2.36%),
while preserving high benign fidelity. Furthermore, PromptSafe demonstrates
strong generalization to unseen harmful categories, robust transferability
across diffusion model architectures, and resilience under adaptive adversarial
attacks, highlighting its practical value for safe and scalable deployment.

</details>


### [53] [Integrating Disparity Confidence Estimation into Relative Depth Prior-Guided Unsupervised Stereo Matching](https://arxiv.org/abs/2508.01275)
*Chuang-Wei Liu,Mingjian Sun,Cairong Zhao,Hanli Wang,Alexander Dvorkovich,Rui Fan*

Main category: cs.CV

TL;DR: 该研究提出了一种新的无监督立体匹配框架，通过视差置信度估计和深度先验引导的损失函数，解决了现有方法在处理重复模式和纹理缺失区域时的不足，并提高了3D几何知识的利用效率，最终在KITTI数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法依赖多视图一致性假设，在处理重复模式和纹理缺失区域时效果不佳。将3D几何知识从相对深度图转移到立体匹配网络是一种可行的解决方案，但现有方法利用随机构建的稀疏对应关系学习深度排序信息，导致3D几何知识利用效率低下并引入错误的视差估计噪声。

Method: 提出了一种新颖的无监督学习框架，包括一个即插即用的视差置信度估计算法和两个由深度先验引导的损失函数。通过检查邻近视差与其对应的相对深度之间的局部相干性来获得视差置信度，然后利用置信度估计构建准密集对应关系以进行有效的深度排序学习。最后，提出了一种对偶视差平滑损失来提高视差不连续处的立体匹配性能。

Result: 实验结果表明，该方法在KITTI立体基准测试中取得了最先进的立体匹配精度，在所有无监督立体匹配方法中表现最佳。

Conclusion: 该方法在KITTI立体基准测试中取得了最先进的立体匹配精度，在所有无监督立体匹配方法中表现最佳。

Abstract: Unsupervised stereo matching has garnered significant attention for its
independence from costly disparity annotations. Typical unsupervised methods
rely on the multi-view consistency assumption for training networks, which
suffer considerably from stereo matching ambiguities, such as repetitive
patterns and texture-less regions. A feasible solution lies in transferring 3D
geometric knowledge from a relative depth map to the stereo matching networks.
However, existing knowledge transfer methods learn depth ranking information
from randomly built sparse correspondences, which makes inefficient utilization
of 3D geometric knowledge and introduces noise from mistaken disparity
estimates. This work proposes a novel unsupervised learning framework to
address these challenges, which comprises a plug-and-play disparity confidence
estimation algorithm and two depth prior-guided loss functions. Specifically,
the local coherence consistency between neighboring disparities and their
corresponding relative depths is first checked to obtain disparity confidence.
Afterwards, quasi-dense correspondences are built using only confident
disparity estimates to facilitate efficient depth ranking learning. Finally, a
dual disparity smoothness loss is proposed to boost stereo matching performance
at disparity discontinuities. Experimental results demonstrate that our method
achieves state-of-the-art stereo matching accuracy on the KITTI Stereo
benchmarks among all unsupervised stereo matching methods.

</details>


### [54] [GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification](https://arxiv.org/abs/2508.01293)
*Ngoc Bui Lam Quang,Nam Le Nguyen Binh,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Quan Nguyen,Ulas Bagci*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言多示例学习框架，通过多代理生成临床描述和使用描述列表进行文本编码，解决了现有方法的局限性，提高了病理图像分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的MIL方法在处理大规模病理图像时，存在LLM生成的描述可能缺乏领域特异性和精细医学细节，以及VLM的有限的token容量限制了编码信息的丰富性等问题。为了解决这些挑战，需要改进描述生成和文本编码的方法，以更好地将临床知识与视觉特征对齐。

Method: 本文提出了一个结合了视觉-语言模型（VLMs）和多示例学习（MIL）的框架。该框架包含两个主要部分：1. 一个接地多代理描述生成系统，利用专业的病理学教科书和代理专业化（例如，形态学、空间上下文）来生成准确且多样化的临床描述。 2. 一种文本编码策略，它使用描述列表而不是单一提示来捕获细粒度的、互补的临床信号，以实现与视觉特征的更好对齐。

Result: 本文提出的方法在肾癌和肺癌数据集上进行了验证，结果显示其性能优于单一提示类基线，并达到了与最先进模型相当的水平。

Conclusion: 本文提出的框架通过使用多代理描述生成系统和列表形式的文本编码策略，在肾癌和肺癌数据集上取得了与最先进模型相媲美的影响，并优于单一提示类基线。

Abstract: Multiple Instance Learning (MIL) is the leading approach for whole slide
image (WSI) classification, enabling efficient analysis of gigapixel pathology
slides. Recent work has introduced vision-language models (VLMs) into MIL
pipelines to incorporate medical knowledge through text-based class
descriptions rather than simple class names. However, when these methods rely
on large language models (LLMs) to generate clinical descriptions or use
fixed-length prompts to represent complex pathology concepts, the limited token
capacity of VLMs often constrains the expressiveness and richness of the
encoded class information. Additionally, descriptions generated solely by LLMs
may lack domain grounding and fine-grained medical specificity, leading to
suboptimal alignment with visual features. To address these challenges, we
propose a vision-language MIL framework with two key contributions: (1) A
grounded multi-agent description generation system that leverages curated
pathology textbooks and agent specialization (e.g., morphology, spatial
context) to produce accurate and diverse clinical descriptions; (2) A text
encoding strategy using a list of descriptions rather than a single prompt,
capturing fine-grained and complementary clinical signals for better alignment
with visual features. Integrated into a VLM-MIL pipeline, our approach shows
improved performance over single-prompt class baselines and achieves results
comparable to state-of-the-art models, as demonstrated on renal and lung cancer
datasets.

</details>


### [55] [Domain Generalized Stereo Matching with Uncertainty-guided Data Augmentation](https://arxiv.org/abs/2508.01303)
*Shuangli Du,Jing Wang,Minghua Zhao,Zhenyu Xu,Jie Li*

Main category: cs.CV

TL;DR: 通过不确定性引导数据增强（UgDA）方法，在训练中引入域变化，来提升立体匹配模型在真实数据上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决在合成数据上训练的先进立体匹配（SM）模型由于颜色、光照、对比度和纹理等域差异而在真实数据域上泛化能力不足的问题。

Method: 提出了一种不确定性引导数据增强（UgDA）方法，通过扰动RGB空间中的图像统计量（均值和标准差）来生成新的域样本，并利用基于批次统计量的“高斯分布”来模拟扰动方向和强度的不确定性。此外，通过强制同一场景的原始数据和增强数据的特征一致性，来学习对结构感知、无关捷径的特征表示。

Result: 通过在多个具有挑战性的基准测试上进行的大量实验证明，该方法可以显著提升现有立体匹配网络的泛化性能。

Conclusion: 该方法能够显著提升现有立体匹配网络泛化性能。

Abstract: State-of-the-art stereo matching (SM) models trained on synthetic data often
fail to generalize to real data domains due to domain differences, such as
color, illumination, contrast, and texture. To address this challenge, we
leverage data augmentation to expand the training domain, encouraging the model
to acquire robust cross-domain feature representations instead of
domain-dependent shortcuts. This paper proposes an uncertainty-guided data
augmentation (UgDA) method, which argues that the image statistics in RGB space
(mean and standard deviation) carry the domain characteristics. Thus, samples
in unseen domains can be generated by properly perturbing these statistics.
Furthermore, to simulate more potential domains, Gaussian distributions founded
on batch-level statistics are poposed to model the unceratinty of perturbation
direction and intensity. Additionally, we further enforce feature consistency
between original and augmented data for the same scene, encouraging the model
to learn structure aware, shortcuts-invariant feature representations. Our
approach is simple, architecture-agnostic, and can be integrated into any SM
networks. Extensive experiments on several challenging benchmarks have
demonstrated that our method can significantly improve the generalization
performance of existing SM networks.

</details>


### [56] [C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor](https://arxiv.org/abs/2508.01311)
*Haoquan Lu,Hanzhe Liang,Jie Zhang,Chenxi Hu,Jinbao Wang,Can Gao*

Main category: cs.CV

TL;DR: 提出C3D-AD框架，通过KAL、KAA和RPP模块实现持续3D异常检测，在三个公共数据集上均表现出有效性。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测（AD）方法通常是类特定的，并且缺乏从新兴类别中学习的能力，而该研究旨在解决这些限制。

Method: 该方法引入了具有随机特征层的核注意力（KAL）来提取通用局部特征，并提出了具有可学习顾问的核注意力（KAA）机制来处理新类别并丢弃冗余旧信息。此外，还提出了参数扰动的重建（RPP）模块，通过表示演练损失函数来保持表示的一致性。

Result: 在Real3D-AD、Anomaly-ShapeNet和MulSen-AD数据集上取得了平均AUROC 66.4%、83.1%和63.4%的有效性。

Conclusion: 该研究提出了持续学习框架持续3D异常检测（C3D-AD），能够学习多类别点云的通用表示并处理新出现类别。

Abstract: 3D Anomaly Detection (AD) has shown great potential in detecting anomalies or
defects of high-precision industrial products. However, existing methods are
typically trained in a class-specific manner and also lack the capability of
learning from emerging classes. In this study, we proposed a continual learning
framework named Continual 3D Anomaly Detection (C3D-AD), which can not only
learn generalized representations for multi-class point clouds but also handle
new classes emerging over time.Specifically, in the feature extraction module,
to extract generalized local features from diverse product types of different
tasks efficiently, Kernel Attention with random feature Layer (KAL) is
introduced, which normalizes the feature space. Then, to reconstruct data
correctly and continually, an efficient Kernel Attention with learnable Advisor
(KAA) mechanism is proposed, which learns the information from new categories
while discarding redundant old information within both the encoder and decoder.
Finally, to keep the representation consistency over tasks, a Reconstruction
with Parameter Perturbation (RPP) module is proposed by designing a
representation rehearsal loss function, which ensures that the model remembers
previous category information and returns category-adaptive
representation.Extensive experiments on three public datasets demonstrate the
effectiveness of the proposed method, achieving an average performance of
66.4%, 83.1%, and 63.4% AUROC on Real3D-AD, Anomaly-ShapeNet, and MulSen-AD,
respectively.

</details>


### [57] [P3P Made Easy](https://arxiv.org/abs/2508.01312)
*Seong Hun Lee,Patrick Vandewalle,Javier Civera*

Main category: cs.CV

TL;DR: 提出了一种新的代数方法来解决P3P问题，该方法简单、准确且高效。


<details>
  <summary>Details</summary>
Motivation: 旨在从三个2D-3D对应点恢复已校准相机的绝对姿态。

Method: 提出了一种新颖的代数解法，将P3P问题转化为一个四次多项式，具有解析简单、计算高效的系数。

Result: 实验证明，该求解器在精度和运行时间上均可与最先进的方法相媲美，并且在合成数据集上验证了其鲁棒性和效率。

Conclusion: 该方法简单、准确且高效，适用于实时系统和教学环境。

Abstract: We present a novel algebraic solution to the Perspective-Three-Point (P3P)
problem, which aims to recover the absolute pose of a calibrated camera from
three 2D-3D correspondences. Our method reformulates the problem into a quartic
polynomial with coefficients that are analytically simple and computationally
efficient. Despite its simplicity, the proposed solver achieves accuracy and
runtime performance comparable to state-of-the-art methods. Extensive
experiments on synthetic datasets validate its robustness and efficiency. This
combination of simplicity and performance makes our solver appealing for both
real-time systems and educational contexts, where interpretability and
reliability are critical.

</details>


### [58] [Multimodal Attention-Aware Fusion for Diagnosing Distal Myopathy: Evaluating Model Interpretability and Clinician Trust](https://arxiv.org/abs/2508.01316)
*Mohsen Abbaspour Onari,Lucie Charlotte Magister,Yaoxin Wu,Amalia Lupi,Dario Creazzo,Mattia Tordin,Luigi Di Donatantonio,Emilio Quaia,Chao Zhang,Isel Grau,Marco S. Nobile,Yingqian Zhang,Pietro Liò*

Main category: cs.CV

TL;DR: 该研究提出了一种用于远端肌病诊断的多模态注意力融合方法，提高了准确性，但可解释性仍需改进。


<details>
  <summary>Details</summary>
Motivation: 远端肌病是一种遗传异质性肌病，临床表现多样，给放射学诊断带来挑战。为了解决这个问题，需要一种能够提高诊断准确性和可解释性的方法。

Method: 提出了一种新颖的多模态注意力融合架构，结合了捕获全局上下文信息和局部细节的两个不同深度学习模型的特征，并通过注意力门机制进行特征融合。

Result: 该方法在BUSI基准和特发性远端肌病数据集上实现了高分类准确率，并生成了临床相关的显著性图。与单一模型和替代融合策略相比，融合策略提高了预测性能。然而，在解剖学特异性和临床实用性方面仍存在差距。

Conclusion: 该研究提出了一种新颖的多模态注意力融合架构，结合了捕获全局上下文信息和局部细节的深度学习模型，并通过注意力门机制进行特征融合，提高了预测性能和可解释性。研究在BUSI基准和特发性远端肌病数据集上取得了高分类准确率，并生成了临床相关的显著性图，以支持医疗诊断中的透明决策。然而，研究也指出了可解释性在解剖学特异性和临床实用性方面仍存在差距，强调了在实际诊断场景中，需要更丰富、更具上下文感知能力的可解释性方法以及人机协同反馈。

Abstract: Distal myopathy represents a genetically heterogeneous group of skeletal
muscle disorders with broad clinical manifestations, posing diagnostic
challenges in radiology. To address this, we propose a novel multimodal
attention-aware fusion architecture that combines features extracted from two
distinct deep learning models, one capturing global contextual information and
the other focusing on local details, representing complementary aspects of the
input data. Uniquely, our approach integrates these features through an
attention gate mechanism, enhancing both predictive performance and
interpretability. Our method achieves a high classification accuracy on the
BUSI benchmark and a proprietary distal myopathy dataset, while also generating
clinically relevant saliency maps that support transparent decision-making in
medical diagnosis. We rigorously evaluated interpretability through (1)
functionally grounded metrics, coherence scoring against reference masks and
incremental deletion analysis, and (2) application-grounded validation with
seven expert radiologists. While our fusion strategy boosts predictive
performance relative to single-stream and alternative fusion strategies, both
quantitative and qualitative evaluations reveal persistent gaps in anatomical
specificity and clinical usefulness of the interpretability. These findings
highlight the need for richer, context-aware interpretability methods and
human-in-the-loop feedback to meet clinicians' expectations in real-world
diagnostic settings.

</details>


### [59] [Referring Remote Sensing Image Segmentation with Cross-view Semantics Interaction Network](https://arxiv.org/abs/2508.01331)
*Jiaxing Yang,Lihe Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: CSINet通过融合远近视图信息和利用注意力机制，提高了遥感图像分割的准确性和效率，尤其在处理微小和模糊目标方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在处理微小、模糊目标方面的局限性，受人类观察目标的行为启发，提出CSINet框架，旨在协调来自远近距离的视觉线索以进行协同预测。

Method: 提出了一种名为CSINet的并列统一分割框架，该框架通过跨视图语义交互来解决现有方法的局限性。CSINet通过在每个编码阶段利用跨视图窗口注意力模块（CVWin）来融合远近视图的语义信息，并结合了协同膨胀注意力增强解码器（CDAD）来挖掘目标的定向属性并集成跨视图多尺度特征。

Result: CSINet在利用全局和局部语义方面取得了显著的改进，优于其他方法，同时保持了可观的速度。

Conclusion: 该模型在处理微小和模糊目标方面表现出色，并且在保持可观速度的同时，在利用全局和局部语义方面取得了显著的改进。

Abstract: Recently, Referring Remote Sensing Image Segmentation (RRSIS) has aroused
wide attention. To handle drastic scale variation of remote targets, existing
methods only use the full image as input and nest the saliency-preferring
techniques of cross-scale information interaction into traditional single-view
structure. Although effective for visually salient targets, they still struggle
in handling tiny, ambiguous ones in lots of real scenarios. In this work, we
instead propose a paralleled yet unified segmentation framework Cross-view
Semantics Interaction Network (CSINet) to solve the limitations. Motivated by
human behavior in observing targets of interest, the network orchestrates
visual cues from remote and close distances to conduct synergistic prediction.
In its every encoding stage, a Cross-View Window-attention module (CVWin) is
utilized to supplement global and local semantics into close-view and
remote-view branch features, finally promoting the unified representation of
feature in every encoding stage. In addition, we develop a Collaboratively
Dilated Attention enhanced Decoder (CDAD) to mine the orientation property of
target and meanwhile integrate cross-view multiscale features. The proposed
network seamlessly enhances the exploitation of global and local semantics,
achieving significant improvements over others while maintaining satisfactory
speed.

</details>


### [60] [Zero-shot Segmentation of Skin Conditions: Erythema with Edit-Friendly Inversion](https://arxiv.org/abs/2508.01334)
*Konstantinos Moutselos,Ilias Maglogiannis*

Main category: cs.CV

TL;DR: 提出了一种利用扩散模型的零样本框架来检测皮肤红斑，通过生成无红斑的参考图像并对其进行颜色空间分析来实现，无需训练数据即可提供有效的诊断支持。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种无需大量标记皮肤病学数据集即可检测皮肤红斑的框架，并避免使用任何注释训练掩码，从而提供可扩展且灵活的诊断支持工具。

Method: 提出了一种基于扩散模型编辑友好反演的零样本图像分割框架，通过生成无红斑的参考图像并与原始图像对齐，然后进行颜色空间分析来识别红斑区域。

Result: 该流程成功地分离了各种情况下的面部红斑，在定性实验中表现出优于基于阈值的基线技术。

Conclusion: 该方法结合了生成扩散模型和统计颜色分割，实现了无需训练数据的有效红斑检测，展示了其在计算机辅助皮肤病学中的潜力。

Abstract: This study proposes a zero-shot image segmentation framework for detecting
erythema (redness of the skin) using edit-friendly inversion in diffusion
models. The method synthesizes reference images of the same patient that are
free from erythema via generative editing and then accurately aligns these
references with the original images. Color-space analysis is performed with
minimal user intervention to identify erythematous regions. This approach
significantly reduces the reliance on labeled dermatological datasets while
providing a scalable and flexible diagnostic support tool by avoiding the need
for any annotated training masks. In our initial qualitative experiments, the
pipeline successfully isolated facial erythema in diverse cases, demonstrating
performance improvements over baseline threshold-based techniques. These
results highlight the potential of combining generative diffusion models and
statistical color segmentation for computer-aided dermatology, enabling
efficient erythema detection without prior training data.

</details>


### [61] [StyleSentinel: Reliable Artistic Copyright Verification via Stylistic Fingerprints](https://arxiv.org/abs/2508.01335)
*Lingxiao Chen,Liqin Wang,Wei Lu*

Main category: cs.CV

TL;DR: StyleSentinel是一种用于艺术品版权保护的新方法，通过学习艺术家的固有风格特征，可以有效防止未经授权的使用。


<details>
  <summary>Details</summary>
Motivation: 为了应对扩散模型在生成定制图像方面的多功能性所带来的个人艺术品未经授权使用及其对艺术家知识产权的威胁，并解决现有方法（如扰动、水印和后门）防御能力有限且无法保护在线发布艺术品的缺点。

Method: StyleSentinel采用语义自重建过程增强艺术品内的风格表达，并自适应地融合多层图像特征以编码抽象艺术风格，最后将目标艺术家的风格建模为特征空间中的最小包围超球边界。

Result: StyleSentinel在单样本验证任务上实现了优于现有技术的性能，并在在线平台上证明了其有效性。

Conclusion: StyleSentinel通过将复杂版权验证转化为鲁棒的单类学习任务，在单样本验证任务上实现了优于现有技术的性能，并在在线平台上展示了其有效性。

Abstract: The versatility of diffusion models in generating customized images has led
to unauthorized usage of personal artwork, which poses a significant threat to
the intellectual property of artists. Existing approaches relying on embedding
additional information, such as perturbations, watermarks, and backdoors,
suffer from limited defensive capabilities and fail to protect artwork
published online. In this paper, we propose StyleSentinel, an approach for
copyright protection of artwork by verifying an inherent stylistic fingerprint
in the artist's artwork. Specifically, we employ a semantic self-reconstruction
process to enhance stylistic expressiveness within the artwork, which
establishes a dense and style-consistent manifold foundation for feature
learning. Subsequently, we adaptively fuse multi-layer image features to encode
abstract artistic style into a compact stylistic fingerprint. Finally, we model
the target artist's style as a minimal enclosing hypersphere boundary in the
feature space, transforming complex copyright verification into a robust
one-class learning task. Extensive experiments demonstrate that compared with
the state-of-the-art, StyleSentinel achieves superior performance on the
one-sample verification task. We also demonstrate the effectiveness through
online platforms.

</details>


### [62] [3DRot: 3D Rotation Augmentation for RGB-Based 3D Tasks](https://arxiv.org/abs/2508.01423)
*Shitian Yang,Deyu Li,Xiaoke Jiang,Lei Zhang*

Main category: cs.CV

TL;DR: 3DRot is a new augmentation method for 3D tasks that preserves geometric consistency through camera-space transforms, improving 3D detection accuracy and reducing errors.


<details>
  <summary>Details</summary>
Motivation: Traditional image augmentation techniques disrupt geometric consistency in RGB-based 3D tasks, and existing methods suffer from scarce annotations and limited augmentation options.

Method: 3DRot rotates and mirrors images about the camera's optical center while synchronously updating RGB images, camera intrinsics, object poses, and 3D annotations to preserve projective geometry.

Result: On the SUN RGB-D dataset, 3DRot improved 3D detection by raising 3D IoU from 43.21 to 44.51, reducing rotation error from 22.91° to 20.93°, and boosting mAP0.5 from 35.70 to 38.11. This outperforms other methods like Cube R-CNN.

Conclusion: 3DRot is a plug-and-play augmentation technique that achieves geometry-consistent rotations and reflections without relying on scene depth, significantly improving performance in 3D detection tasks.

Abstract: RGB-based 3D tasks, e.g., 3D detection, depth estimation, 3D keypoint
estimation, still suffer from scarce, expensive annotations and a thin
augmentation toolbox, since most image transforms, including resize and
rotation, disrupt geometric consistency. In this paper, we introduce 3DRot, a
plug-and-play augmentation that rotates and mirrors images about the camera's
optical center while synchronously updating RGB images, camera intrinsics,
object poses, and 3D annotations to preserve projective geometry-achieving
geometry-consistent rotations and reflections without relying on any scene
depth. We validate 3DRot with a classical 3D task, monocular 3D detection. On
SUN RGB-D dataset, 3DRot raises $IoU_{3D}$ from 43.21 to 44.51, cuts rotation
error (ROT) from 22.91$^\circ$ to 20.93$^\circ$, and boosts $mAP_{0.5}$ from
35.70 to 38.11. As a comparison, Cube R-CNN adds 3 other datasets together with
SUN RGB-D for monocular 3D estimation, with a similar mechanism and test
dataset, increases $IoU_{3D}$ from 36.2 to 37.8, boosts $mAP_{0.5}$ from 34.7
to 35.4. Because it operates purely through camera-space transforms, 3DRot is
readily transferable to other 3D tasks.

</details>


### [63] [Weakly-Supervised Image Forgery Localization via Vision-Language Collaborative Reasoning Framework](https://arxiv.org/abs/2508.01338)
*Ziqi Sheng,Junyan Wu,Wei Lu,Jiantao Zhou*

Main category: cs.CV

TL;DR: ViLaCo是一个视觉-语言协同推理框架，利用预训练视觉-语言模型提供语义监督，仅用图像级标签即可实现像素级图像篡改定位，解决了弱监督方法性能不足的问题。


<details>
  <summary>Details</summary>
Motivation: 为了减轻图像篡改定位中代价高昂的像素级标注负担，并解决现有弱监督方法仅依赖类内一致性线索且缺乏外部语义指导导致性能有限的问题。

Method: ViLaCo框架包括视觉-语言特征建模网络、自适应视觉-语言推理网络、双预测头（粗粒度和细粒度）以及对比补丁一致性模块。

Result: ViLaCo在检测和定位准确性方面均取得了最先进的性能，显著优于现有的弱监督图像篡改定位方法。

Conclusion: ViLaCo通过引入预训练视觉-语言模型的辅助语义监督，实现了仅使用图像级标签的像素级定位，克服了传统方法对像素级标注的依赖，并在多个公开数据集上取得了优于现有方法的性能。

Abstract: Image forgery localization aims to precisely identify tampered regions within
images, but it commonly depends on costly pixel-level annotations. To alleviate
this annotation burden, weakly supervised image forgery localization (WSIFL)
has emerged, yet existing methods still achieve limited localization
performance as they mainly exploit intra-image consistency clues and lack
external semantic guidance to compensate for weak supervision. In this paper,
we propose ViLaCo, a vision-language collaborative reasoning framework that
introduces auxiliary semantic supervision distilled from pre-trained
vision-language models (VLMs), enabling accurate pixel-level localization using
only image-level labels. Specifically, ViLaCo first incorporates semantic
knowledge through a vision-language feature modeling network, which jointly
extracts textual and visual priors using pre-trained VLMs. Next, an adaptive
vision-language reasoning network aligns textual semantics and visual features
through mutual interactions, producing semantically aligned representations.
Subsequently, these representations are passed into dual prediction heads,
where the coarse head performs image-level classification and the fine head
generates pixel-level localization masks, thereby bridging the gap between weak
supervision and fine-grained localization. Moreover, a contrastive patch
consistency module is introduced to cluster tampered features while separating
authentic ones, facilitating more reliable forgery discrimination. Extensive
experiments on multiple public datasets demonstrate that ViLaCo substantially
outperforms existing WSIFL methods, achieving state-of-the-art performance in
both detection and localization accuracy.

</details>


### [64] [Dynamic Robot-Assisted Surgery with Hierarchical Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2508.01713)
*Julia Hindel,Ema Mekic,Enamundram Naga Karthik,Rohit Mohan,Daniele Cattaneo,Maria Kalweit,Abhinav Valada*

Main category: cs.CV

TL;DR: TOPICS+ 改进了用于机器人手术的 CISS 方法，通过 Dice loss、伪标签和定制标签来处理类别不平衡和动态环境，并在新的基准上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术需要精确的实时场景理解来安全地引导手术器械，但现有分割模型在动态变化的手术环境中存在局限性。CISS 允许模型在不遗忘先前知识的情况下适应新类别。

Method: TOPICS+ 是对 TOPICS 方法的改进，它将 Dice loss 引入分层损失函数以处理类别不平衡，引入分层伪标签，并为机器人手术环境设计定制标签分类法。

Result: TOPICS+ 在机器人手术场景的增量类语义分割方面表现出稳健性，并通过新的基准和改进的数据集验证了其有效性。

Conclusion: 通过结合 Dice loss、分层伪标签和为机器人手术环境定制的标签分类法，TOPICS+ 显著提高了机器人手术场景的增量类语义分割的鲁棒性。此外，所提出的六个新的 CISS 基准和改进的 Syn-Mediverse 数据集为该领域的研究提供了宝贵的资源。

Abstract: Robot-assisted surgeries rely on accurate and real-time scene understanding
to safely guide surgical instruments. However, segmentation models trained on
static datasets face key limitations when deployed in these dynamic and
evolving surgical environments. Class-incremental semantic segmentation (CISS)
allows models to continually adapt to new classes while avoiding catastrophic
forgetting of prior knowledge, without training on previous data. In this work,
we build upon the recently introduced Taxonomy-Oriented Poincar\'e-regularized
Incremental Class Segmentation (TOPICS) approach and propose an enhanced
variant, termed TOPICS+, specifically tailored for robust segmentation of
surgical scenes. Concretely, we incorporate the Dice loss into the hierarchical
loss formulation to handle strong class imbalances, introduce hierarchical
pseudo-labeling, and design tailored label taxonomies for robotic surgery
environments. We also propose six novel CISS benchmarks designed for robotic
surgery environments including multiple incremental steps and several semantic
categories to emulate realistic class-incremental settings in surgical
environments. In addition, we introduce a refined set of labels with more than
144 classes on the Syn-Mediverse synthetic dataset, hosted online as an
evaluation benchmark. We make the code and trained models publicly available at
http://topics.cs.uni-freiburg.de.

</details>


### [65] [SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes](https://arxiv.org/abs/2508.01339)
*Chuanqi Liang,Jie Fu,Lei Luo,Miao Yu*

Main category: cs.CV

TL;DR: A new lightweight model called SBP-YOLO, based on YOLOv11, improves speed bump and pothole detection for car suspensions, achieving high accuracy and speed on embedded systems.


<details>
  <summary>Details</summary>
Motivation: Accurate real-time detection of speed bumps and potholes is critical for predictive suspension control in new energy vehicles due to increasing demand for ride comfort.

Method: SBP-YOLO, a lightweight detection framework based on YOLOv11, integrates GhostConv, VoVGSCSPC, and a Lightweight Efficiency Detection Head (LEDH). It uses a hybrid training strategy with NWD loss, knowledge distillation, and Albumentations-based weather augmentation.

Result: SBP-YOLO achieves 87.0% mAP, outperforming YOLOv11n by 5.8%, and runs at 139.5 FPS on a Jetson AGX Xavier with TensorRT FP16 quantization.

Conclusion: SBP-YOLO is effective for real-time road condition perception in intelligent suspension systems, achieving 87.0% mAP and running at 139.5 FPS on a Jetson AGX Xavier with TensorRT FP16 quantization.

Abstract: With increasing demand for ride comfort in new energy vehicles, accurate
real-time detection of speed bumps and potholes is critical for predictive
suspension control. This paper proposes SBP-YOLO, a lightweight detection
framework based on YOLOv11, optimized for embedded deployment. The model
integrates GhostConv for efficient computation, VoVGSCSPC for multi-scale
feature enhancement, and a Lightweight Efficiency Detection Head (LEDH) to
reduce early-stage feature processing costs. A hybrid training strategy
combining NWD loss, knowledge distillation, and Albumentations-based weather
augmentation improves detection robustness, especially for small and distant
targets. Experiments show SBP-YOLO achieves 87.0% mAP (outperforming YOLOv11n
by 5.8%) and runs at 139.5 FPS on a Jetson AGX Xavier with TensorRT FP16
quantization. The results validate its effectiveness for real-time road
condition perception in intelligent suspension systems.

</details>


### [66] [DiffSemanticFusion: Semantic Raster BEV Fusion for Autonomous Driving via Online HD Map Diffusion](https://arxiv.org/abs/2508.01778)
*Zhigang Sun,Yiru Wang,Anqing Jiang,Shuo Wang,Yu Gao,Yuwen Heng,Shouyi Zhang,An He,Hao Jiang,Jinhao Chai,Zichong Gu,Wang Jijun,Shichen Tang,Lavdim Halilaj,Juergen Luettin,Hao Sun*

Main category: cs.CV

TL;DR: DiffSemanticFusion通过融合栅格和图表示，并引入地图扩散模块，提升了自动驾驶中在线高精地图的稳定性和表达能力，在轨迹预测和规划任务中均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶中光栅表示缺乏几何精度和图表示不稳定性的问题，并利用两者的优势，提出DiffSemanticFusion框架。

Method: 提出了一种名为DiffSemanticFusion的融合框架，用于多模态轨迹预测和规划。该框架在一个融合了语义栅格的BEV空间中进行推理，并通过一个地图扩散模块来提高在线高精地图表示的稳定性和表达能力。

Result: 在nuScenes数据集的轨迹预测任务中，与QCNet结合使用，性能提升了5.1%。在NAVSIM数据集的端到端自动驾驶任务中，DiffSemanticFusion在NavHard场景下实现了最先进的结果，性能提升了15%。

Conclusion: DiffSemanticFusion框架在nuScenes和NAVSIM数据集上进行了验证，并在轨迹预测和端到端自动驾驶任务中取得了优于现有方法的性能提升。实验证明，其地图扩散模块可以集成到其他基于向量的方法中以提升性能。

Abstract: Autonomous driving requires accurate scene understanding, including road
geometry, traffic agents, and their semantic relationships. In online HD map
generation scenarios, raster-based representations are well-suited to vision
models but lack geometric precision, while graph-based representations retain
structural detail but become unstable without precise maps. To harness the
complementary strengths of both, we propose DiffSemanticFusion -- a fusion
framework for multimodal trajectory prediction and planning. Our approach
reasons over a semantic raster-fused BEV space, enhanced by a map diffusion
module that improves both the stability and expressiveness of online HD map
representations. We validate our framework on two downstream tasks: trajectory
prediction and planning-oriented end-to-end autonomous driving. Experiments on
real-world autonomous driving benchmarks, nuScenes and NAVSIM, demonstrate
improved performance over several state-of-the-art methods. For the prediction
task on nuScenes, we integrate DiffSemanticFusion with the online HD map
informed QCNet, achieving a 5.1\% performance improvement. For end-to-end
autonomous driving in NAVSIM, DiffSemanticFusion achieves state-of-the-art
results, with a 15\% performance gain in NavHard scenarios. In addition,
extensive ablation and sensitivity studies show that our map diffusion module
can be seamlessly integrated into other vector-based approaches to enhance
performance. All artifacts are available at
https://github.com/SunZhigang7/DiffSemanticFusion.

</details>


### [67] [Predicting Video Slot Attention Queries from Random Slot-Feature Pairs](https://arxiv.org/abs/2508.01345)
*Rongzhen Zhao,Jian Li,Juho Kannala,Joni Pajarinen*

Main category: cs.CV

TL;DR: 介绍了一种名为RandSF.Q的新方法，用于无监督视频面向对象学习，通过结合来自先前时间步长的随机抽样时间步长来改进查询预测，并在物体发现和动态建模方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能整合下一帧信息和学习转换动力学，而这些对于查询预测至关重要。

Method: 提出了一种名为RandSF.Q（Random Slot-Feature pair for learning Query prediction）的新方法，包括设计了一个新的转换器，该转换器结合了当前的时间步长和来自先前时间步长的随机抽样的时间步长，用于查询预测。

Result: 所提出的RandSF.Q方法在场景表示方面优于现有方法，并且在物体发现方面取得了显著的改进。

Conclusion: 该方法在物体发现方面取得了显著的进步，最高可提高10个百分点，达到了新的最先进水平，并且在下游任务如动态建模方面也表现出色。

Abstract: Unsupervised video Object-Centric Learning (OCL) is promising as it enables
object-level scene representation and dynamics modeling as we humans do.
Mainstream video OCL methods adopt a recurrent architecture: An aggregator
aggregates current video frame into object features, termed slots, under some
queries; A transitioner transits current slots to queries for the next frame.
This is an effective architecture but all existing implementations both
(\textit{i1}) neglect to incorporate next frame features, the most informative
source for query prediction, and (\textit{i2}) fail to learn transition
dynamics, the knowledge essential for query prediction. To address these
issues, we propose Random Slot-Feature pair for learning Query prediction
(RandSF.Q): (\textit{t1}) We design a new transitioner to incorporate both
slots and features, which provides more information for query prediction;
(\textit{t2}) We train the transitioner to predict queries from slot-feature
pairs randomly sampled from available recurrences, which drives it to learn
transition dynamics. Experiments on scene representation demonstrate that our
method surpass existing video OCL methods significantly, e.g., up to 10 points
on object discovery, setting new state-of-the-art. Such superiority also
benefits downstream tasks like dynamics modeling. Our core source code and
training logs are available as the supplement.

</details>


### [68] [A Simple Algebraic Solution for Estimating the Pose of a Camera from Planar Point Features](https://arxiv.org/abs/2508.01836)
*Tarek Bouazza,Tarek Hamel,Claude Samson*

Main category: cs.CV

TL;DR: A simple algebraic method estimates camera pose relative to a planar target using bearing measurements. It determines the normal vector, position, distance, and orientation hierarchically, with an averaging technique for noise robustness. Experiments validate its accuracy.


<details>
  <summary>Details</summary>
Motivation: To estimate the pose of a camera relative to a planar target from reference points and their corresponding bearing measurements.

Method: A simple algebraic method is presented, following a hierarchical structure: first, the unit vector normal to the target plane is determined, followed by the camera's position vector, its distance to the target plane, and finally, the full orientation. An averaging methodology is introduced to refine the estimation of the target's normal direction for improved robustness to measurement noise.

Result: The method estimates the pose of a camera relative to a planar target using at least 4 reference points with known coordinates and their corresponding bearing measurements.

Conclusion: The paper validates the accuracy and robustness of the proposed algebraic method through extensive experiments.

Abstract: This paper presents a simple algebraic method to estimate the pose of a
camera relative to a planar target from $n \geq 4$ reference points with known
coordinates in the target frame and their corresponding bearing measurements in
the camera frame. The proposed approach follows a hierarchical structure;
first, the unit vector normal to the target plane is determined, followed by
the camera's position vector, its distance to the target plane, and finally,
the full orientation. To improve the method's robustness to measurement noise,
an averaging methodology is introduced to refine the estimation of the target's
normal direction. The accuracy and robustness of the approach are validated
through extensive experiments.

</details>


### [69] [Effective Damage Data Generation by Fusing Imagery with Human Knowledge Using Vision-Language Models](https://arxiv.org/abs/2508.01380)
*Jie Wei,Erika Ardiles-Cruz,Aleksey Panasyuk,Erik Blasch*

Main category: cs.CV

TL;DR: 通过视觉-语言模型生成多样化的灾后图像数据，以提高深度学习在灾害评估中的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在人道主义援助和救灾（HADR）中的应用受到数据类别不平衡、中等损坏示例稀缺和像素标注不准确的限制，需要新的方法来生成更有效的损伤评估数据。

Method: 利用视觉-语言模型（VLMs）生成多样化的图像损坏数据，以克服现有深度学习方法在人道主义援助和救灾（HADR）数据上的局限性。

Result: 初步实验结果表明，生成的数据在提高建筑物、道路和基础设施结构损坏场景分类方面表现出令人鼓舞的质量和改进。

Conclusion: 目前的深度学习方法在应对数据类别不平衡、中等损坏示例稀缺以及像素标注的人工不准确性方面存在挑战。通过利用视觉-语言模型（VLMs）融合图像与人类知识，可以有效生成多样化的图像损坏数据，从而提升对建筑物、道路和基础设施不同程度结构损坏场景的分类能力。

Abstract: It is of crucial importance to assess damages promptly and accurately in
humanitarian assistance and disaster response (HADR). Current deep learning
approaches struggle to generalize effectively due to the imbalance of data
classes, scarcity of moderate damage examples, and human inaccuracy in pixel
labeling during HADR situations. To accommodate for these limitations and
exploit state-of-the-art techniques in vision-language models (VLMs) to fuse
imagery with human knowledge understanding, there is an opportunity to generate
a diversified set of image-based damage data effectively. Our initial
experimental results suggest encouraging data generation quality, which
demonstrates an improvement in classifying scenes with different levels of
structural damage to buildings, roads, and infrastructures.

</details>


### [70] [CVD-SfM: A Cross-View Deep Front-end Structure-from-Motion System for Sparse Localization in Multi-Altitude Scenes](https://arxiv.org/abs/2508.01936)
*Yaxuan Li,Yewei Huang,Bijay Gaudel,Hamidreza Jafarnejadsani,Brendan Englot*

Main category: cs.CV

TL;DR: 提出了一种新颖的多高度相机位姿估计系统，该系统利用跨视角Transformer、深度特征和运动恢复结构来处理稀疏图像输入和多变的视角，并在新数据集上展示了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 在仅考虑稀疏图像输入的情况下，解决跨越不同高度的鲁棒且精确的定位的挑战。

Method: 本系统整合了跨视角Transformer、深度特征和运动恢复结构，形成了一个统一的框架，能够有效应对不同的环境条件和视角变化。

Result: 在两个新收集的多高度相机位姿估计数据集上进行了广泛的比较分析，证明了本系统优于现有方法。

Conclusion: 本系统在多高度稀疏位姿估计任务中，在准确性和鲁棒性方面均优于现有解决方案，适用于航空导航、搜索救援和自动化检查等实际机器人应用。

Abstract: We present a novel multi-altitude camera pose estimation system, addressing
the challenges of robust and accurate localization across varied altitudes when
only considering sparse image input. The system effectively handles diverse
environmental conditions and viewpoint variations by integrating the cross-view
transformer, deep features, and structure-from-motion into a unified framework.
To benchmark our method and foster further research, we introduce two newly
collected datasets specifically tailored for multi-altitude camera pose
estimation; datasets of this nature remain rare in the current literature. The
proposed framework has been validated through extensive comparative analyses on
these datasets, demonstrating that our system achieves superior performance in
both accuracy and robustness for multi-altitude sparse pose estimation tasks
compared to existing solutions, making it well suited for real-world robotic
applications such as aerial navigation, search and rescue, and automated
inspection.

</details>


### [71] [A Full-Stage Refined Proposal Algorithm for Suppressing False Positives in Two-Stage CNN-Based Detection Methods](https://arxiv.org/abs/2508.01382)
*Qiang Guo,Rubo Zhang,Bingbing Zhang,Junjie Liu,Jianqing Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 FRP 的新算法，用于解决行人检测中的假阳性问题。通过在训练和测试阶段使用创新的特征评估和过滤策略，FRP 算法能够显著减少假阳性，提高检测精度，并适用于资源受限的设备。


<details>
  <summary>Details</summary>
Motivation: 为了解决行人检测中持续存在的假阳性问题。

Method: 提出了一种全阶段精炼提案（FRP）算法，通过在训练和测试阶段采用各种行人特征重新评估策略来过滤低质量的行人提案。具体而言，训练阶段的 TFRP 通过新颖的提案验证方法指导模型训练；推理阶段的 CFRP 和 SFRP 分别通过集成行人分类器和分割提案来评估置信度得分，以过滤掉低分提案。

Result: FRP 算法能够有效抑制假阳性，提升行人检测性能，并在不同数据集和嵌入式平台上得到验证。

Conclusion: 该算法有效消除了假阳性，并在各种基准数据集和 SY-Metro 数据集上得到了验证。此外，该算法在嵌入式平台上的表现也证明了其在资源受限的边缘设备上提升行人检测能力的潜力。

Abstract: False positives in pedestrian detection remain a challenge that has yet to be
effectively resolved. To address this issue, this paper proposes a Full-stage
Refined Proposal (FRP) algorithm aimed at eliminating these false positives
within a two-stage CNN-based pedestrian detection framework. The main
innovation of this work lies in employing various pedestrian feature
re-evaluation strategies to filter out low-quality pedestrian proposals during
both the training and testing stages. Specifically, in the training phase, the
Training mode FRP algorithm (TFRP) introduces a novel approach for validating
pedestrian proposals to effectively guide the model training process, thereby
constructing a model with strong capabilities for false positive suppression.
During the inference phase, two innovative strategies are implemented: the
Classifier-guided FRP (CFRP) algorithm integrates a pedestrian classifier into
the proposal generation pipeline to yield high-quality proposals through
pedestrian feature evaluation, and the Split-proposal FRP (SFRP) algorithm
vertically divides all proposals, sending both the original and the sub-region
proposals to the subsequent subnetwork to evaluate their confidence scores,
filtering out those with lower sub-region pedestrian confidence scores. As a
result, the proposed algorithm enhances the model's ability to suppress
pedestrian false positives across all stages. Various experiments conducted on
multiple benchmarks and the SY-Metro datasets demonstrate that the model,
supported by different combinations of the FRP algorithm, can effectively
eliminate false positives to varying extents. Furthermore, experiments
conducted on embedded platforms underscore the algorithm's effectiveness in
enhancing the comprehensive pedestrian detection capabilities of the small
pedestrian detector in resource-constrained edge devices.

</details>


### [72] [Lightweight Backbone Networks Only Require Adaptive Lightweight Self-Attention Mechanisms](https://arxiv.org/abs/2508.01385)
*Fengyun Li,Chao Zheng,Yangyang Fang,Jialiang Lan,Jianhua Liang,Luhao Zhang,Fa Si*

Main category: cs.CV

TL;DR: This paper introduces LOLViT, a lightweight hybrid backbone network featuring Fast Window Attention (FWA) and a global-local feature fusion mechanism. LOLViT enhances efficiency and accuracy in visual tasks compared to existing CNN models, achieving significantly faster inference speeds.


<details>
  <summary>Details</summary>
Motivation: Existing lightweight hybrid backbone networks struggle with the imbalance in computational efficiency between CNNs and attention mechanisms, particularly with long-sequence modeling. Lightweight SoftMax attention methods often reduce feature map size, which is cumbersome and still leads to computational saturation. This paper aims to address these issues.

Method: The paper proposes Fast Window Attention (FWA), a lightweight SoftMax attention mechanism with adaptive feature map sizes, which computes attention by generating a small number of key sequences through window aggregation. It also explains the rationale for using ReLU to simulate SoftMax in lightweight global attention mechanisms. A global-local feature fusion mechanism is designed and combined with GhostNet to create the lightweight hybrid backbone network, LOLViT.

Result: Extensive experiments on visual tasks including classification (ImageNet 1K), detection (COCO 2017), and segmentation (BDD100K) demonstrate that LOLViT outperforms comparable CNN models in both inference speed and accuracy. Notably, LOLViT-X achieves a 5x inference speed advantage over MobileViT-X.

Conclusion: LOLViT outperforms CNN models of the same level in both inference speed and model accuracy, with LOLViT-X showing 5x faster inference speed than MobileViT-X.

Abstract: Currently, lightweight hybrid backbone networks have partially alleviated the
issue of computational saturation, but the imbalance in computational
efficiencys between convolutional neural networks (CNNs) and attention
mechanisms is becoming increasingly apparent. Specifically, although linear
attention mechanisms and their variants have made progress in lightweight
design, they still fail to meet the demands of hybrid models for long-sequence
modeling. On the other hand, existing lightweight SoftMax attention
computations typically reduce the feature map to a fixed size to decrease the
number of sequences, thereby compressing the computational scale. However, the
process of determining the feature map reduction ratio is cumbersome, and
computational saturation issues still persist. To address this issue, this
paper proposes a lightweight SoftMax attention mechanism with adaptive feature
map sizes, named Fast Window Attention (FWA), which generates a small number of
key sequences (Key and Value) through window aggregation for attention
computation. Additionally, it explains the rationality of using ReLU to
simulate SoftMax operations in lightweight global attention mechanisms.
Finally, the paper designs a global-local feature fusion mechanism and combines
it with GhostNet to propose a lightweight hybrid backbone network, LOLViT.
Through visual tasks such as classification (ImageNet 1K), detection (COCO
2017), and segmentation (BDD100K), along with extensive ablation studies, it is
demonstrated that LOLViT outperforms CNN models of the same level in both
inference speed and model accuracy. Notably, the inference speed of LOLViT-X is
5x that of MobileViT-X.

</details>


### [73] [Towards Immersive Human-X Interaction: A Real-Time Framework for Physically Plausible Motion Synthesis](https://arxiv.org/abs/2508.02106)
*Kaiyang Ji,Ye Shi,Zichen Jin,Kangyi Chen,Lan Xu,Yuexin Ma,Jingyi Yu,Jingya Wang*

Main category: cs.CV

TL;DR: Human-X是一个新框架，通过创新的方法实现了实时、物理上可信的人类交互，并在各种应用中得到验证。


<details>
  <summary>Details</summary>
Motivation: 实时合成物理上可信的人类交互对于沉浸式VR/AR系统和人形机器人至关重要，但现有方法在实时响应、物理可行性和动态人机交互的安全需求之间存在根本性矛盾。

Method: Human-X框架通过集成自回归反应扩散规划器和强化学习训练的感知运动跟踪策略，联合实时预测动作与反应，并动态适应交互伙伴的运动，以增强物理真实性和安全性。

Result: 实验证明，Human-X框架在Inter-X和InterHuman数据集上取得了显著的改进。

Conclusion: Human-X框架在运动质量、交互连续性和物理可信度方面显著优于现有方法，并在人机交互的虚拟现实接口等实际应用中得到验证，为促进人机协作提供了潜力。

Abstract: Real-time synthesis of physically plausible human interactions remains a
critical challenge for immersive VR/AR systems and humanoid robotics. While
existing methods demonstrate progress in kinematic motion generation, they
often fail to address the fundamental tension between real-time responsiveness,
physical feasibility, and safety requirements in dynamic human-machine
interactions. We introduce Human-X, a novel framework designed to enable
immersive and physically plausible human interactions across diverse entities,
including human-avatar, human-humanoid, and human-robot systems. Unlike
existing approaches that focus on post-hoc alignment or simplified physics, our
method jointly predicts actions and reactions in real-time using an
auto-regressive reaction diffusion planner, ensuring seamless synchronization
and context-aware responses. To enhance physical realism and safety, we
integrate an actor-aware motion tracking policy trained with reinforcement
learning, which dynamically adapts to interaction partners' movements while
avoiding artifacts like foot sliding and penetration. Extensive experiments on
the Inter-X and InterHuman datasets demonstrate significant improvements in
motion quality, interaction continuity, and physical plausibility over
state-of-the-art methods. Our framework is validated in real-world
applications, including virtual reality interface for human-robot interaction,
showcasing its potential for advancing human-robot collaboration.

</details>


### [74] [Construction of Digital Terrain Maps from Multi-view Satellite Imagery using Neural Volume Rendering](https://arxiv.org/abs/2508.01386)
*Josef X. Biberstein,Guilherme Cavalheiro,Juyeop Han,Sertac Karaman*

Main category: cs.CV

TL;DR: 神经地形图（NTM）是一种新的从卫星图像学习数字高程模型（DTM）的方法，它使用神经体积渲染技术，无需深度先验，精度高，可应用于行星探索。


<details>
  <summary>Details</summary>
Motivation: 为了克服当前基于多视图立体匹配的DTM生产流程繁琐且需要大量手动预处理的缺点，并满足日益增长的高质量DTM需求，尤其是在行星探测领域。

Method: 该方法采用神经体积渲染技术，仅需每个像素的像点位置，无需深度或其他结构先验信息，即可直接从卫星图像学习纹理化的数字高程模型（DTM）。

Result: 在合成和真实世界的地球与火星数据上进行了演示，涵盖了大约 $100 	extrm{km}^2$ 的场景。与现有的高质量DTM进行比较评估，结果显示该方法在地形预测精度上接近卫星图像的分辨率，即使在相机内外参数不完美的情况下也能表现良好。

Conclusion: 新提出的神经地形图（NTM）方法能够直接从卫星图像中学习纹理化的数字高程模型（DTM），并在合成和真实世界的地球与火星数据上取得了有希望的结果，其精度接近卫星图像的分辨率。

Abstract: Digital terrain maps (DTMs) are an important part of planetary exploration,
enabling operations such as terrain relative navigation during entry, descent,
and landing for spacecraft and aiding in navigation on the ground. As robotic
exploration missions become more ambitious, the need for high quality DTMs will
only increase. However, producing DTMs via multi-view stereo pipelines for
satellite imagery, the current state-of-the-art, can be cumbersome and require
significant manual image preprocessing to produce satisfactory results. In this
work, we seek to address these shortcomings by adapting neural volume rendering
techniques to learn textured digital terrain maps directly from satellite
imagery. Our method, neural terrain maps (NTM), only requires the locus for
each image pixel and does not rely on depth or any other structural priors. We
demonstrate our method on both synthetic and real satellite data from Earth and
Mars encompassing scenes on the order of $100 \textrm{km}^2$. We evaluate the
accuracy of our output terrain maps by comparing with existing high-quality
DTMs produced using traditional multi-view stereo pipelines. Our method shows
promising results, with the precision of terrain prediction almost equal to the
resolution of the satellite images even in the presence of imperfect camera
intrinsics and extrinsics.

</details>


### [75] [An Event-based Fast Intensity Reconstruction Scheme for UAV Real-time Perception](https://arxiv.org/abs/2508.02238)
*Xin Dong,Yiwei Zhang,Yangjie Cui,Jinwu Xiang,Daochun Li,Zhan Tu*

Main category: cs.CV

TL;DR: ESI是一种新的事件相机强度重建方法，通过单次积分事件流实现高帧率、高质量的实时重建，特别适合无人机等载具在低光照等恶劣环境下的应用，效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决事件相机（Event Cameras）在处理异步事件流时的挑战，并将其有效信息用于载具（如无人机）的实际应用，提出了一种简化的事件驱动强度重建方案。

Method: ESI是一种事件驱动的强度重建方法，通过对事件流进行单次积分并结合增强的衰减算法来工作。

Result: ESI实现了实时高帧率（100 FPS）的强度重建，具有低计算量、高重建质量和优越的运行效率，显著提升了无人机在低光照等视觉挑战环境下的跟踪感知能力。

Conclusion: ESI通过结合事件流的单次积分和增强的衰减算法来重建强度图像，实现了实时高帧率（通常为100 FPS）的强度重建。该方法计算量低，适用于无人机视觉跟踪等载具场景。与现有算法相比，ESI在运行效率、重建质量和帧率方面表现优越，显著提升了无人机在视觉对抗环境下的感知能力。在实际飞行测试中，ESI在低至2-10 lux的极端低照度条件下有效支持了无人机的视觉跟踪，而其他算法则因帧率不足、图像质量差或实时性限制而失效。

Abstract: Event cameras offer significant advantages, including a wide dynamic range,
high temporal resolution, and immunity to motion blur, making them highly
promising for addressing challenging visual conditions. Extracting and
utilizing effective information from asynchronous event streams is essential
for the onboard implementation of event cameras. In this paper, we propose a
streamlined event-based intensity reconstruction scheme, event-based single
integration (ESI), to address such implementation challenges. This method
guarantees the portability of conventional frame-based vision methods to
event-based scenarios and maintains the intrinsic advantages of event cameras.
The ESI approach reconstructs intensity images by performing a single
integration of the event streams combined with an enhanced decay algorithm.
Such a method enables real-time intensity reconstruction at a high frame rate,
typically 100 FPS. Furthermore, the relatively low computation load of ESI fits
onboard implementation suitably, such as in UAV-based visual tracking
scenarios. Extensive experiments have been conducted to evaluate the
performance comparison of ESI and state-of-the-art algorithms. Compared to
state-of-the-art algorithms, ESI demonstrates remarkable runtime efficiency
improvements, superior reconstruction quality, and a high frame rate. As a
result, ESI enhances UAV onboard perception significantly under visual
adversary surroundings. In-flight tests, ESI demonstrates effective performance
for UAV onboard visual tracking under extremely low illumination
conditions(2-10lux), whereas other comparative algorithms fail due to
insufficient frame rate, poor image quality, or limited real-time performance.

</details>


### [76] [Video-based Vehicle Surveillance in the Wild: License Plate, Make, and Model Recognition with Self Reflective Vision-Language Models](https://arxiv.org/abs/2508.01387)
*Pouya Parsa,Keya Li,Kara M. Kockelman,Seongjin Choi*

Main category: cs.CV

TL;DR: VLMs show promise for recognizing license plates and vehicle makes/models from challenging, in-motion videos captured by smartphones, outperforming traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional ALPR and vehicle recognition methods struggle with videos from non-static sources like smartphones due to frequent camera motion, varying viewpoints, occlusions, and unknown road geometry. This study explores the potential of VLMs to overcome these challenges.

Method: The study proposes pipelines for license plate recognition (ALPR) and vehicle make/model recognition using VLMs. The ALPR pipeline filters for sharp frames and uses multimodal prompts with different strategies. The make/model pipeline uses the same VLM with a revised prompt and an optional self-reflection module that corrects mismatches by comparing the query image with a reference from a dataset.

Result: The proposed method achieved top-1 accuracies of 91.67% for ALPR and 66.67% for make/model recognition on a smartphone dataset from UT Austin. On the UFPR-ALPR dataset, accuracies were 83.05% and 61.07%, respectively. The self-reflection module improved make/model recognition by an average of 5.72%.

Conclusion: Vision-language models (VLMs) offer a cost-effective solution for scalable, in-motion traffic video analysis, achieving notable accuracy in ALPR and make/model recognition even with challenging video sources like smartphones.

Abstract: Automatic license plate recognition (ALPR) and vehicle make and model
recognition underpin intelligent transportation systems, supporting law
enforcement, toll collection, and post-incident investigation. Applying these
methods to videos captured by handheld smartphones or non-static
vehicle-mounted cameras presents unique challenges compared to fixed
installations, including frequent camera motion, varying viewpoints,
occlusions, and unknown road geometry. Traditional ALPR solutions, dependent on
specialized hardware and handcrafted OCR pipelines, often degrade under these
conditions. Recent advances in large vision-language models (VLMs) enable
direct recognition of textual and semantic attributes from arbitrary imagery.
This study evaluates the potential of VLMs for ALPR and makes and models
recognition using monocular videos captured with handheld smartphones and
non-static mounted cameras. The proposed license plate recognition pipeline
filters to sharp frames, then sends a multimodal prompt to a VLM using several
prompt strategies. Make and model recognition pipeline runs the same VLM with a
revised prompt and an optional self-reflection module. In the self-reflection
module, the model contrasts the query image with a reference from a 134-class
dataset, correcting mismatches. Experiments on a smartphone dataset collected
on the campus of the University of Texas at Austin, achieve top-1 accuracies of
91.67% for ALPR and 66.67% for make and model recognition. On the public
UFPR-ALPR dataset, the approach attains 83.05% and 61.07%, respectively. The
self-reflection module further improves results by 5.72% on average for make
and model recognition. These findings demonstrate that VLMs provide a
cost-effective solution for scalable, in-motion traffic video analysis.

</details>


### [77] [Correspondence-Free Fast and Robust Spherical Point Pattern Registration](https://arxiv.org/abs/2508.02339)
*Anik Sarker,Alan T. Asbeck*

Main category: cs.CV

TL;DR: 提出了一种基于点集对齐的球体模式旋转估计新方法，实现了O(n)复杂度，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于球体函数的球体模式旋转估计方法计算复杂度高于O(n^3)，并且在存在显著离群值污染的情况下评估不足。

Method: 提出了一种将球体模式表示为离散3D点集的算法，并将旋转估计重新表述为球体点集对齐（即3D单位向量的Wahba问题）。具体介绍了SPMC（基于相关性的球体模式匹配）、FRS（快速旋转搜索）和SPMC+FRS（混合方法）。

Result: 实验证明，在S^2域和无对应关系的情况下，该算法比现有的解决Wahba问题的算法快10倍以上，准确率也更高。并将该方法应用于点云配准和球体图像的旋转估计。

Conclusion: 该研究提出了一种新的旋转估计算法，具有线性时间复杂度，在处理具有显著离群值污染的球体模式方面，比现有方法快10倍以上且准确率更高。

Abstract: Existing methods for rotation estimation between two spherical
($\mathbb{S}^2$) patterns typically rely on spherical cross-correlation
maximization between two spherical function. However, these approaches exhibit
computational complexities greater than cubic $O(n^3)$ with respect to rotation
space discretization and lack extensive evaluation under significant outlier
contamination. To this end, we propose a rotation estimation algorithm between
two spherical patterns with linear time complexity $O(n)$. Unlike existing
spherical-function-based methods, we explicitly represent spherical patterns as
discrete 3D point sets on the unit sphere, reformulating rotation estimation as
a spherical point-set alignment (i.e., Wahba problem for 3D unit vectors).
Given the geometric nature of our formulation, our spherical pattern alignment
algorithm naturally aligns with the Wahba problem framework for 3D unit
vectors. Specifically, we introduce three novel algorithms: (1) SPMC (Spherical
Pattern Matching by Correlation), (2) FRS (Fast Rotation Search), and (3) a
hybrid approach (SPMC+FRS) that combines the advantages of the previous two
methods. Our experiments demonstrate that in the $\mathbb{S}^2$ domain and in
correspondence-free settings, our algorithms are over 10x faster and over 10x
more accurate than current state-of-the-art methods for the Wahba problem with
outliers. We validate our approach through extensive simulations on a new
dataset of spherical patterns, the ``Robust Vector Alignment Dataset.
"Furthermore, we adapt our methods to two real-world tasks: (i) Point Cloud
Registration (PCR) and (ii) rotation estimation for spherical images.

</details>


### [78] [Open-Attribute Recognition for Person Retrieval: Finding People Through Distinctive and Novel Attributes](https://arxiv.org/abs/2508.01389)
*Minjeong Park,Hongbeen Park,Sangwon Lee,Yoonha Jang,Jinkyu Kim*

Main category: cs.CV

TL;DR: 本研究提出了开放属性识别（OAPR）任务和相应的框架，以解决行人属性识别中的封闭集问题和提高属性区分性，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有行人属性识别（PAR）方法通常假设在训练和推理期间所有属性类别都可用（封闭集假设），这限制了它们在现实世界中的应用，因为新属性可能会出现。此外，现有数据集中的属性通常过于通用，区分性不强，难以有效检索目标行人。

Method: 提出了一种名为开放属性识别（OAPR）的新任务，以及一个用于学习可泛化身体部位表征的新框架，以解决现有行人属性识别（PAR）方法在现实世界中遇到的封闭集假设和属性区分性不足的问题。该框架旨在能够识别训练期间未见的属性，并通过重建四个常用数据集来支持开放属性识别。

Result: 在重建的四个常用数据集上进行的广泛实验证明了OAPR任务的必要性以及所提出框架在开放属性识别方面的有效性。

Conclusion: 该研究提出了开放属性识别（OAPR）任务，旨在解决现有行人属性识别（PAR）方法在处理现实世界中可能出现的新属性时的局限性，并提出了一种学习可泛化的身体部位表征的新框架，以支持此任务。实验证明了OAPR任务的必要性和所提出框架的有效性。

Abstract: Pedestrian Attribute Recognition (PAR) plays a crucial role in various vision
tasks such as person retrieval and identification. Most existing
attribute-based retrieval methods operate under the closed-set assumption that
all attribute classes are consistently available during both training and
inference. However, this assumption limits their applicability in real-world
scenarios where novel attributes may emerge. Moreover, predefined attributes in
benchmark datasets are often generic and shared across individuals, making them
less discriminative for retrieving the target person. To address these
challenges, we propose the Open-Attribute Recognition for Person Retrieval
(OAPR) task, which aims to retrieve individuals based on attribute cues,
regardless of whether those attributes were seen during training. To support
this task, we introduce a novel framework designed to learn generalizable body
part representations that cover a broad range of attribute categories.
Furthermore, we reconstruct four widely used datasets for open-attribute
recognition. Comprehensive experiments on these datasets demonstrate the
necessity of the OAPR task and the effectiveness of our framework. The source
code and pre-trained models will be publicly available upon publication.

</details>


### [79] [mmWave Radar-Based Non-Line-of-Sight Pedestrian Localization at T-Junctions Utilizing Road Layout Extraction via Camera](https://arxiv.org/abs/2508.02348)
*Byeonggyu Park,Hee-Yeun Kim,Byonghyok Choi,Hansang Cho,Byungkwan Kim,Soomok Lee,Mingu Jeon,Seong-Woo Kim*

Main category: cs.CV

TL;DR: 提出了一种结合摄像头和毫米波雷达数据的新方法，用于在城市NLoS区域定位行人。该方法利用摄像头提供的道路布局信息来解释雷达点云数据，解决了传统方法在NLoS区域定位的难题，并在真实环境中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 城市环境中非视线（NLoS）区域内的行人定位对于自动驾驶系统是一个重大挑战。虽然毫米波雷达在检测此类场景下的物体方面具有潜力，但其2D雷达点云数据容易受到多径反射引起的失真影响，难以进行准确的空间推断。此外，摄像头图像虽然提供高分辨率的视觉信息，但缺乏深度感知，并且无法直接观察NLoS区域内的物体。

Method: 提出了一种新颖的框架，该框架利用从摄像头推断出的道路布局来解析雷达点云数据，以实现对NLoS行人的本地化。

Result: 实验结果表明，该方法能够有效地进行NLoS行人定位，并在实际收集的户外NLoS驾驶环境中进行了验证，展示了该方法的实际应用价值。

Conclusion: 该方法通过结合摄像头和毫米波雷达数据，利用道路布局信息来推断非视线（NLoS）区域内行人的位置，并在实际驾驶环境中进行了验证，证明了其在户外NLoS驾驶场景下的实用性。

Abstract: Pedestrians Localization in Non-Line-of-Sight (NLoS) regions within urban
environments poses a significant challenge for autonomous driving systems.
While mmWave radar has demonstrated potential for detecting objects in such
scenarios, the 2D radar point cloud (PCD) data is susceptible to distortions
caused by multipath reflections, making accurate spatial inference difficult.
Additionally, although camera images provide high-resolution visual
information, they lack depth perception and cannot directly observe objects in
NLoS regions. In this paper, we propose a novel framework that interprets radar
PCD through road layout inferred from camera for localization of NLoS
pedestrians. The proposed method leverages visual information from the camera
to interpret 2D radar PCD, enabling spatial scene reconstruction. The
effectiveness of the proposed approach is validated through experiments
conducted using a radar-camera system mounted on a real vehicle. The
localization performance is evaluated using a dataset collected in outdoor NLoS
driving environments, demonstrating the practical applicability of the method.

</details>


### [80] [Spatial-Frequency Aware for Object Detection in RAW Image](https://arxiv.org/abs/2508.01396)
*Zhuohua Ye,Liming Zhang,Hongru Han*

Main category: cs.CV

TL;DR: SFAE利用频率域处理RAW图像，通过将频带空间化、跨域融合注意力和自适应非线性调整，有效恢复了因动态范围和线性响应导致的细节丢失，提升了对象检测效果。


<details>
  <summary>Details</summary>
Motivation: 直接使用原始数据（RAW）进行对象检测很有前景，但原始数据动态范围宽、线性响应的特性会抑制关键对象细节。现有的增强方法多在空间域进行，难以有效恢复因像素分布不均而丢失的细节。

Method: SFAE框架通过以下三个方面解决问题：1. "空间化"频带，将每个频带逆变换回空间图，保留物理直觉；2. 跨域融合注意力模块，实现空间特征与频率特征之间的深度多模态交互；3. 预测并应用不同伽马参数对两个域进行自适应非线性调整。

Result: SFAE框架能够有效地恢复被抑制的对象细节，提高在原始数据上的对象检测性能。

Conclusion: 该研究提出了一种新颖的名为SFAE（空间-频率感知原始图像对象检测增强器）的框架，该框架结合了空间和频率表示，以解决直接使用原始数据进行对象检测时，由于动态范围宽和线性响应导致的细节丢失问题。

Abstract: Direct RAW-based object detection offers great promise by utilizing RAW data
(unprocessed sensor data), but faces inherent challenges due to its wide
dynamic range and linear response, which tends to suppress crucial object
details. In particular, existing enhancement methods are almost all performed
in the spatial domain, making it difficult to effectively recover these
suppressed details from the skewed pixel distribution of RAW images. To address
this limitation, we turn to the frequency domain, where features, such as
object contours and textures, can be naturally separated based on frequency. In
this paper, we propose Space-Frequency Aware RAW Image Object Detection
Enhancer (SFAE), a novel framework that synergizes spatial and frequency
representations. Our contribution is threefold. The first lies in the
``spatialization" of frequency bands. Different from the traditional paradigm
of directly manipulating abstract spectra in deep networks, our method
inversely transforms individual frequency bands back into tangible spatial
maps, thus preserving direct physical intuition. Then the cross-domain fusion
attention module is developed to enable deep multimodal interactions between
these maps and the original spatial features. Finally, the framework performs
adaptive nonlinear adjustments by predicting and applying different gamma
parameters for the two domains.

</details>


### [81] [ForenX: Towards Explainable AI-Generated Image Detection with Multimodal Large Language Models](https://arxiv.org/abs/2508.01402)
*Chuangchuang Tan,Jinglu Wang,Xiang Ming,Renshuai Tao,Yunchao Wei,Yao Zhao,Yan Lu*

Main category: cs.CV

TL;DR: ForenX是一种新颖的方法，利用MLLMs和专门的法证提示来识别AI生成图像的真实性，并提供可理解的解释，同时通过ForgReason数据集提高了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了弥合AI生成图像检测方法与人类认知法证分析之间的差距，并提供具有人类可理解的解释。

Method: ForenX结合了多模态大语言模型（MLLMs）和专门的法证提示，以识别AI生成图像的真实性，并通过ForgReason数据集提高了模型性能和可解释性。

Result: ForenX在两个主要基准测试中表现出色，其可解释性也通过了全面的主观评估。

Conclusion: ForenX不依赖于特定的伪造技术，因此具有很强的泛化能力。

Abstract: Advances in generative models have led to AI-generated images visually
indistinguishable from authentic ones. Despite numerous studies on detecting
AI-generated images with classifiers, a gap persists between such methods and
human cognitive forensic analysis. We present ForenX, a novel method that not
only identifies the authenticity of images but also provides explanations that
resonate with human thoughts. ForenX employs the powerful multimodal large
language models (MLLMs) to analyze and interpret forensic cues. Furthermore, we
overcome the limitations of standard MLLMs in detecting forgeries by
incorporating a specialized forensic prompt that directs the MLLMs attention to
forgery-indicative attributes. This approach not only enhance the
generalization of forgery detection but also empowers the MLLMs to provide
explanations that are accurate, relevant, and comprehensive. Additionally, we
introduce ForgReason, a dataset dedicated to descriptions of forgery evidences
in AI-generated images. Curated through collaboration between an LLM-based
agent and a team of human annotators, this process provides refined data that
further enhances our model's performance. We demonstrate that even limited
manual annotations significantly improve explanation quality. We evaluate the
effectiveness of ForenX on two major benchmarks. The model's explainability is
verified by comprehensive subjective evaluations.

</details>


### [82] [MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming](https://arxiv.org/abs/2508.02549)
*Shuo Wang,Yongcai Wang,Wanting Li,Yucheng Wang,Maiyue Chen,Kaihui Wang,Zhizhong Su,Xudong Cai,Yeying Jin,Deying Li,Zhaoxin Fan*

Main category: cs.CV

TL;DR: MonoDream：一种轻量级VLA框架，通过单目输入实现高性能导航，解决了全景传感器成本和可及性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉语言导航（VLN）任务虽然可以利用全景RGB和深度输入提供丰富的空间线索，但这些传感器成本较高且可及性有限。现有的基于视觉语言动作（VLA）模型的单目输入方法虽然表现良好，但仍落后于使用全景RGB-D信息的模型。因此，需要一种更经济、更易于部署的解决方案。

Method: MonoDream框架利用单目输入学习统一导航表示（UNR），该表示联合了导航相关的视觉语义（如全局布局、深度和未来线索）以及语言驱动的动作意图。此外，通过潜在全景梦境（LPD）任务，模型在仅有单目输入的情况下，能够预测当前和未来步骤的全景RGB和深度观测的潜在特征。

Result: 实验结果表明，MonoDream在多个VLN基准测试中持续提高了单目导航性能，并显著缩小了与全景输入方法的性能差距。

Conclusion: MonoDream框架通过学习统一导航表示（UNR）并引入潜在全景梦境（LPD）任务，有效提升了单目导航性能，并显著缩小了与全景输入方法的差距。

Abstract: Vision-Language Navigation (VLN) tasks often leverage panoramic RGB and depth
inputs to provide rich spatial cues for action planning, but these sensors can
be costly or less accessible in real-world deployments. Recent approaches based
on Vision-Language Action (VLA) models achieve strong results with monocular
input, yet they still lag behind methods using panoramic RGB-D information. We
present MonoDream, a lightweight VLA framework that enables monocular agents to
learn a Unified Navigation Representation (UNR). This shared feature
representation jointly aligns navigation-relevant visual semantics (e.g.,
global layout, depth, and future cues) and language-grounded action intent,
enabling more reliable action prediction. MonoDream further introduces Latent
Panoramic Dreaming (LPD) tasks to supervise the UNR, which train the model to
predict latent features of panoramic RGB and depth observations at both current
and future steps based on only monocular input. Experiments on multiple VLN
benchmarks show that MonoDream consistently improves monocular navigation
performance and significantly narrows the gap with panoramic-based agents.

</details>


### [83] [Capturing More: Learning Multi-Domain Representations for Robust Online Handwriting Verification](https://arxiv.org/abs/2508.01427)
*Peirong Zhang,Kai Ding,Lianwen Jin*

Main category: cs.CV

TL;DR: SPECTRUM is a temporal-frequency synergistic model for online handwriting verification (OHV) that combines temporal and frequency features for improved discrimination between genuine and forged handwriting. It outperforms existing methods and suggests future research in multi-domain approaches.


<details>
  <summary>Details</summary>
Motivation: Unlock the untapped potential of multi-domain representation learning for online handwriting verification (OHV).

Method: SPECTRUM model comprises three core components: (1) a multi-scale interactor that finely combines temporal and frequency features through dual-modal sequence interaction and multi-scale aggregation, (2) a self-gated fusion module that dynamically integrates global temporal and frequency features via self-driven balancing, and (3) a multi-domain distance-based verifier that utilizes both temporal and frequency representations.

Result: Extensive experiments demonstrate SPECTRUM's superior performance over existing OHV methods. Reveal that incorporating multiple handwritten biometrics fundamentally enhances the discriminative power of handwriting representations and facilitates verification.

Conclusion: SPECTRUM's superior performance over existing OHV methods, underscoring the effectiveness of temporal-frequency multi-domain learning. Incorporating multiple handwritten biometrics fundamentally enhances the discriminative power of handwriting representations and facilitates verification. Pave the way for future research in multi-domain approaches across both feature and biometric domains.

Abstract: In this paper, we propose SPECTRUM, a temporal-frequency synergistic model
that unlocks the untapped potential of multi-domain representation learning for
online handwriting verification (OHV). SPECTRUM comprises three core
components: (1) a multi-scale interactor that finely combines temporal and
frequency features through dual-modal sequence interaction and multi-scale
aggregation, (2) a self-gated fusion module that dynamically integrates global
temporal and frequency features via self-driven balancing. These two components
work synergistically to achieve micro-to-macro spectral-temporal integration.
(3) A multi-domain distance-based verifier then utilizes both temporal and
frequency representations to improve discrimination between genuine and forged
handwriting, surpassing conventional temporal-only approaches. Extensive
experiments demonstrate SPECTRUM's superior performance over existing OHV
methods, underscoring the effectiveness of temporal-frequency multi-domain
learning. Furthermore, we reveal that incorporating multiple handwritten
biometrics fundamentally enhances the discriminative power of handwriting
representations and facilitates verification. These findings not only validate
the efficacy of multi-domain learning in OHV but also pave the way for future
research in multi-domain approaches across both feature and biometric domains.
Code is publicly available at https://github.com/NiceRingNode/SPECTRUM.

</details>


### [84] [Hyperspectral Image Recovery Constrained by Multi-Granularity Non-Local Self-Similarity Priors](https://arxiv.org/abs/2508.01435)
*Zhuoran Peng,Yiqing Shen*

Main category: cs.CV

TL;DR: 提出了一种新的高光谱图像恢复方法，利用多粒度张量分解来适应不同的缺失场景，并在各种测试中取得了更好的恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于非局部先验的高光谱图像恢复方法采用固定的因子表示非局部自相似性张量组，无法适应各种缺失场景。为了解决这个问题，本文首次将粒度概念引入张量分解。

Method: 提出了一种高光谱图像恢复模型，该模型利用多粒度非局部自相似性先验进行约束。模型交替进行粗粒度分解（基于Tucker分解提取全局结构信息）和细粒度分解（基于FCTN分解捕捉局部细节信息），实现了对全局、局部和非局部先验的统一表示。

Result: 实验结果表明，该模型具有很强的适用性，并在像素和条纹等各种缺失场景中表现出优越的恢复效果。

Conclusion: 该模型通过多粒度非局部自相似性先验约束，实现了对高光谱图像（HSI）的有效恢复，并在像素和条纹等多种缺失场景下表现出优越的恢复效果和良好的适应性。

Abstract: Hyperspectral image (HSI) recovery, as an upstream image processing task,
  holds significant importance for downstream tasks such as classification,
  segmentation, and detection. In recent years, HSI recovery methods based on
  non-local prior representations have demonstrated outstanding performance.
However,
  these methods employ a fixed-format factor to represent the non-local
self-similarity
  tensor groups, making them unable to adapt to diverse missing scenarios. To
address
  this issue, we introduce the concept of granularity in tensor decomposition
for the first
  time and propose an HSI recovery model constrained by multi-granularity
non-local
  self-similarity priors. Specifically, the proposed model alternately performs
  coarse-grained decomposition and fine-grained decomposition on the non-local
  self-similarity tensor groups. Among them, the coarse-grained decomposition
builds
  upon Tucker tensor decomposition, which extracts global structural
information of the
  image by performing singular value shrinkage on the mode-unfolded matrices.
The
  fine-grained decomposition employs the FCTN decomposition, capturing local
detail
  information through modeling pairwise correlations among factor tensors. This
  architectural approach achieves a unified representation of global, local,
and non-local
  priors for HSIs. Experimental results demonstrate that the model has strong
  applicability and exhibits outstanding recovery effects in various types of
missing
  scenes such as pixels and stripes.

</details>


### [85] [Uncertainty-Aware Segmentation Quality Prediction via Deep Learning Bayesian Modeling: Comprehensive Evaluation and Interpretation on Skin Cancer and Liver Segmentation](https://arxiv.org/abs/2508.01460)
*Sikha O K,Meritxell Riera-Marín,Adrian Galdran,Javier García Lopez,Julia Rodríguez-Comas,Gemma Piella,Miguel A. González Ballester*

Main category: cs.CV

TL;DR: 提出了一种无需真实标签即可评估医学图像分割质量的新框架，通过量化模型不确定性来预测质量，并在皮肤和肝脏分割任务上取得了优异结果。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中，缺乏手动注释使得评估医学图像分割的质量变得困难，而缺乏可靠性指标的模型难以被广泛采用。因此，需要一种能够在没有真实标签的情况下评估分割质量的方法。

Method: 本研究提出了一种新的框架，通过结合预测分割图、不确定性图以及原始输入图像来预测医学图像分割的质量。该框架利用了蒙特卡洛 Dropout、Ensemble 和测试时间增强等技术来量化不确定性，并评估了置信图、熵、互信息和期望的 KL 散度等四种不确定性估计方法。此外，还提出了一种聚合策略来结合多种不确定性估计，并通过 Grad-CAM 和 UMAP 进行了解释。

Result: 该框架在皮肤病变分割任务（HAM10000 数据集）上取得了 93.25 的 R2 分数和 96.58 的皮尔逊相关系数，优于现有方法。在肝脏分割任务上，测试时间增强结合熵取得了 85.03 的 R2 分数和 65.02 的皮尔逊相关系数，证明了其跨模态的鲁棒性。

Conclusion: 本研究提出了一个无需真实标签即可预测分割质量的新框架，并通过实验验证了其有效性，为临床应用提供了可靠的分割质量评估方法。

Abstract: Image segmentation is a critical step in computational biomedical image
analysis, typically evaluated using metrics like the Dice coefficient during
training and validation. However, in clinical settings without manual
annotations, assessing segmentation quality becomes challenging, and models
lacking reliability indicators face adoption barriers. To address this gap, we
propose a novel framework for predicting segmentation quality without requiring
ground truth annotations during test time. Our approach introduces two
complementary frameworks: one leveraging predicted segmentation and uncertainty
maps, and another integrating the original input image, uncertainty maps, and
predicted segmentation maps. We present Bayesian adaptations of two benchmark
segmentation models-SwinUNet and Feature Pyramid Network with ResNet50-using
Monte Carlo Dropout, Ensemble, and Test Time Augmentation to quantify
uncertainty. We evaluate four uncertainty estimates: confidence map, entropy,
mutual information, and expected pairwise Kullback-Leibler divergence on 2D
skin lesion and 3D liver segmentation datasets, analyzing their correlation
with segmentation quality metrics. Our framework achieves an R2 score of 93.25
and Pearson correlation of 96.58 on the HAM10000 dataset, outperforming
previous segmentation quality assessment methods. For 3D liver segmentation,
Test Time Augmentation with entropy achieves an R2 score of 85.03 and a Pearson
correlation of 65.02, demonstrating cross-modality robustness. Additionally, we
propose an aggregation strategy that combines multiple uncertainty estimates
into a single score per image, offering a more robust and comprehensive
assessment of segmentation quality. Finally, we use Grad-CAM and UMAP-based
embedding analysis to interpret the model's behavior and reliability,
highlighting the impact of uncertainty integration.

</details>


### [86] [Can3Tok: Canonical 3D Tokenization and Latent Modeling of Scene-Level 3D Gaussians](https://arxiv.org/abs/2508.01464)
*Quankai Gao,Iliyan Georgiev,Tuanfeng Y. Wang,Krishna Kumar Singh,Ulrich Neumann,Jae Shin Yoon*

Main category: cs.CV

TL;DR: Can3Tok是首个3D场景级VAE，解决了3D高斯泼溅表示的尺度不一致问题，实现了新颖3D场景的泛化生成，并支持图像和文本到3DGS的转换。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏能够扩展3D场景级数据潜表示学习的模型，前馈3D场景级生成探索较少。与在有界规范空间中进行训练的对象级生成模型不同，以3D高斯泼溅（3DGS）表示的场景级生成是不受约束的，并且在不同场景之间表现出尺度不一致性，这使得为生成目的进行统一的潜表示学习极具挑战性。

Method: 提出了一种名为Can3Tok的3D场景级变分自编码器（VAE），能够将高斯图元编码为低维潜在嵌入。同时，提出了一种通用的3D场景数据处理流程来解决尺度不一致问题。

Result: Can3Tok成功泛化到新的3D场景，而对比方法在训练时难以收敛，并且在推理时没有泛化能力。最终展示了图像到3DGS和文本到3DGS的生成应用。

Conclusion: Can3Tok是首个能够将大量高斯图元编码为低维潜在嵌入的3D场景级变分自编码器（VAE），能有效捕捉输入的语义和空间信息。该方法解决了3D场景生成中存在的尺度不一致问题，并在DL3DV-10K数据集上验证了其泛化能力，相比之下，其他方法在训练时难以收敛，并且在推理时没有泛化能力。此外，Can3Tok还支持图像到3DGS和文本到3DGS的生成应用。

Abstract: 3D generation has made significant progress, however, it still largely
remains at the object-level. Feedforward 3D scene-level generation has been
rarely explored due to the lack of models capable of scaling-up latent
representation learning on 3D scene-level data. Unlike object-level generative
models, which are trained on well-labeled 3D data in a bounded canonical space,
scene-level generations with 3D scenes represented by 3D Gaussian Splatting
(3DGS) are unbounded and exhibit scale inconsistency across different scenes,
making unified latent representation learning for generative purposes extremely
challenging. In this paper, we introduce Can3Tok, the first 3D scene-level
variational autoencoder (VAE) capable of encoding a large number of Gaussian
primitives into a low-dimensional latent embedding, which effectively captures
both semantic and spatial information of the inputs. Beyond model design, we
propose a general pipeline for 3D scene data processing to address scale
inconsistency issue. We validate our method on the recent scene-level 3D
dataset DL3DV-10K, where we found that only Can3Tok successfully generalizes to
novel 3D scenes, while compared methods fail to converge on even a few hundred
scene inputs during training and exhibit zero generalization ability during
inference. Finally, we demonstrate image-to-3DGS and text-to-3DGS generation as
our applications to demonstrate its ability to facilitate downstream generation
tasks.

</details>


### [87] [EfficientGFormer: Multimodal Brain Tumor Segmentation via Pruned Graph-Augmented Transformer](https://arxiv.org/abs/2508.01465)
*Fatemeh Ziaeetabar*

Main category: cs.CV

TL;DR: EfficientGFormer是一种新的3D脑肿瘤分割方法，它结合了预训练模型、图推理和知识蒸馏，实现了高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 解决神经影像领域中脑肿瘤分割的挑战，特别是肿瘤子区域的异质性以及体积推理的高计算成本问题。

Method: 提出了一种名为EfficientGFormer的新型架构，该架构整合了预训练基础模型（nnFormer作为模态感知编码器）、基于图的推理（构建双边图和使用剪枝的边类型感知图注意力网络GAT）和知识蒸馏（将知识从教师模型转移到紧凑的学生模型）。

Result: EfficientGFormer在MSD Task01和BraTS 2021数据集上取得了最先进的准确性，内存和推理时间显著优于基于Transformer和图的方法，实现了可扩展、可解释和泛化的临床应用。

Conclusion: EfficientGFormer通过结合预训练基础模型、基于图的推理和轻量级机制，在MSD Task01和BraTS 2021数据集上实现了最先进的3D脑肿瘤分割精度，同时显著降低了内存消耗和推理时间，为快速准确的体积肿瘤描绘提供了临床可行性解决方案。

Abstract: Accurate and efficient brain tumor segmentation remains a critical challenge
in neuroimaging due to the heterogeneous nature of tumor subregions and the
high computational cost of volumetric inference. In this paper, we propose
EfficientGFormer, a novel architecture that integrates pretrained foundation
models with graph-based reasoning and lightweight efficiency mechanisms for
robust 3D brain tumor segmentation. Our framework leverages nnFormer as a
modality-aware encoder, transforming multi-modal MRI volumes into patch-level
embeddings. These features are structured into a dual-edge graph that captures
both spatial adjacency and semantic similarity. A pruned, edge-type-aware Graph
Attention Network (GAT) enables efficient relational reasoning across tumor
subregions, while a distillation module transfers knowledge from a
full-capacity teacher to a compact student model for real-time deployment.
Experiments on the MSD Task01 and BraTS 2021 datasets demonstrate that
EfficientGFormer achieves state-of-the-art accuracy with significantly reduced
memory and inference time, outperforming recent transformer-based and
graph-based baselines. This work offers a clinically viable solution for fast
and accurate volumetric tumor delineation, combining scalability,
interpretability, and generalization.

</details>


### [88] [MiraGe: Multimodal Discriminative Representation Learning for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2508.01525)
*Kuo Shi,Jie Lu,Shanshan Ye,Guangquan Zhang,Zhen Fang*

Main category: cs.CV

TL;DR: MiraGe是一种新的AI生成图像检测方法，它通过学习生成器不变性特征并利用CLIP和文本嵌入来提高区分真实和AI生成图像的准确性，尤其是在面对新模型时。


<details>
  <summary>Details</summary>
Motivation: 现有方法在区分真实图像和AI生成图像方面表现良好，但在面对新出现的或未见的生成模型时，由于重叠的特征嵌入会阻碍准确的跨生成器分类，因此性能会下降。MiraGe旨在学习生成器不变性特征以解决此问题。

Method: MiraGe提出了一种多模态判别性表示学习方法，通过对齐同一类别的特征并最大化类别间的间隔来学习生成器不变性特征，并利用多模态提示学习将这些原则应用于CLIP，以文本嵌入作为语义锚点来改进可泛化性。

Result: MiraGe实现了最先进的性能，并且在面对未见的生成器时表现出鲁棒性。

Conclusion: MiraGe在多个基准测试中取得了最先进的性能，即使在面对Sora等未见过生成器时仍保持鲁棒性。

Abstract: Recent advances in generative models have highlighted the need for robust
detectors capable of distinguishing real images from AI-generated images. While
existing methods perform well on known generators, their performance often
declines when tested with newly emerging or unseen generative models due to
overlapping feature embeddings that hinder accurate cross-generator
classification. In this paper, we propose Multimodal Discriminative
Representation Learning for Generalizable AI-generated Image Detection
(MiraGe), a method designed to learn generator-invariant features. Motivated by
theoretical insights on intra-class variation minimization and inter-class
separation, MiraGe tightly aligns features within the same class while
maximizing separation between classes, enhancing feature discriminability.
Moreover, we apply multimodal prompt learning to further refine these
principles into CLIP, leveraging text embeddings as semantic anchors for
effective discriminative representation learning, thereby improving
generalizability. Comprehensive experiments across multiple benchmarks show
that MiraGe achieves state-of-the-art performance, maintaining robustness even
against unseen generators like Sora.

</details>


### [89] [ReasonAct: Progressive Training for Fine-Grained Video Reasoning in Small Models](https://arxiv.org/abs/2508.01533)
*Jiaxin Liu,Zhaolu Kang*

Main category: cs.CV

TL;DR: ReasonAct通过三阶段训练（文本推理、视频微调、强化学习）和子动作分解机制，显著提升了小模型在视频理解任务上的时序推理能力和准确率，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: 目前的小规模多模态模型在视频理解所需的细粒度时序推理方面仍存在不足，而ReasonAct旨在通过特定的训练方法来解决这一问题，以提升小模型的视频推理能力。

Method: ReasonAct通过一个三阶段的训练过程来增强小模型的视频推理能力：首先进行纯文本推理，然后进行视频微调，最后通过时域感知强化学习进行优化。该方法基于T-GRPO（Temporal Group Relative Policy Optimization），并引入了时域一致性建模到策略优化中。此外，提出了一种受生物力学启发的子动作分解机制，为组成的动作阶段提供梯度奖励。

Result: 在HMDB51、UCF-101和Kinetics-400数据集上，ReasonAct 3B参数模型分别达到了67.2%、94.1%和78.9%的准确率，相比基线模型分别提高了17.9%、15.8%和12.3%。消融研究也验证了该渐进式训练方法在提升性能和保持计算效率方面的有效性。

Conclusion: 通过实验证明，ReasonAct通过三阶段训练方法（纯文本推理、视频微调、时域感知强化学习）能够提升小规模模型在视频理解任务上的细粒度时序推理能力，在HMDB51、UCF-101和Kinetics-400数据集上分别取得了67.2%、94.1%和78.9%的准确率，显著优于基线模型，同时保持了计算效率。

Abstract: While recent multimodal models have shown progress in vision-language tasks,
small-scale variants still struggle with the fine-grained temporal reasoning
required for video understanding. We introduce ReasonAct, a method that
enhances video reasoning in smaller models through a three-stage training
process: first building a foundation with text-only reasoning, then fine-tuning
on video, and finally refining with temporal-aware reinforcement learning. We
build upon Temporal Group Relative Policy Optimization (T-GRPO) by
incorporating temporal consistency modeling into policy optimization. We also
propose a biomechanically-motivated sub-action decomposition mechanism that
provides graduated rewards for constituent action phases. Through experiments
on HMDB51, UCF-101, and Kinetics-400, our 3B-parameter model achieves 67.2%,
94.1%, and 78.9% accuracy respectively, demonstrating improvements of 17.9,
15.8, and 12.3 points over baselines. Ablation studies validate that our
progressive training methodology enables smaller models to achieve competitive
video reasoning performance while maintaining computational efficiency.

</details>


### [90] [MagicVL-2B: Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning](https://arxiv.org/abs/2508.01540)
*Yi Liu,Xiao Xu,Zeyu Xu,Meng Zhang,Yibo Li,Haoyu Chen,Junkang Zhang,Qiang Wang,Jifa Sun,Siling Lin,Shengxun Cheng,Lingshu Zhang,Kang Wang*

Main category: cs.CV

TL;DR: MagicVL-2B 是一个轻量级视觉语言模型，专为智能手机优化，在保持高准确率的同时，功耗降低了 41.1%。


<details>
  <summary>Details</summary>
Motivation: 当前 Vision-Language Models (VLMs) 虽然在各种应用中取得了显著进展，但其高昂的计算和存储成本限制了其在移动设备上的部署。而移动设备是目前最普及、最易于访问的计算平台。因此，本研究旨在解决这一挑战，开发一个能够在移动设备上高效运行的 VLM。

Method: 该研究提出了一种名为 MagicVL-2B 的新型视觉语言模型 (VLM)，并采用了以下关键技术进行优化：1. 轻量级视觉编码器：使用参数量少于 100M 的视觉编码器，以减少计算和存储需求。2. 动态分辨率方案：设计了一种能够自适应生成图像标记而无需过度修改图像尺寸的新方案。3. 多模态课程学习：提出了一种循序渐进地增加任务难度和数据信息密度的训练策略，以提升模型性能。

Result: MagicVL-2B 在标准 VLM 基准测试中表现出色，其准确率与当前最先进的模型相当。同时，与现有模型相比，MagicVL-2B 在设备上的功耗降低了 41.1%。

Conclusion: MagicVL-2B 是一个为旗舰智能手机优化的新型视觉语言模型 (VLM)。它通过使用参数量少于 100M 的轻量级视觉编码器和动态分辨率方案，显著降低了在移动设备上部署 VLM 的计算和存储需求。此外，结合多模态课程学习策略，进一步提高了模型在各种子任务上的性能。实验证明，MagicVL-2B 在保持与现有最先进模型相当的准确率的同时，将设备的功耗降低了 41.1%，为在智能手机上实现先进的多模态人工智能应用提供了切实可行的解决方案。

Abstract: Vision-Language Models (VLMs) have achieved remarkable breakthroughs in
recent years, enabling a diverse array of applications in everyday life.
However, the substantial computational and storage demands of VLMs pose
significant challenges for their efficient deployment on mobile devices, which
represent the most ubiquitous and accessible computing platforms today. In this
work, we introduce MagicVL-2B, a novel VLM meticulously optimized for flagship
smartphones. MagicVL-2B leverages a lightweight visual encoder with fewer than
100M parameters and features a redesigned dynamic resolution scheme that
adaptively generates image tokens without excessive modification of image
dimensions. To further enhance the performance of this compact encoder within
VLMs, we propose a multimodal curriculum learning strategy that incrementally
increases task difficulty and data information density throughout training.
This approach substantially improves the model's performance across a variety
of sub-tasks. Extensive evaluations on standard VLM benchmarks demonstrate that
MagicVL-2B matches the accuracy of current state-of-the-art models while
reducing on-device power consumption by 41.1%. These results establish
MagicVL-2B as a practical and robust solution for real-world mobile
vision-language applications, enabling advanced multimodal intelligence to run
directly on smartphones.

</details>


### [91] [E-VRAG: Enhancing Long Video Understanding with Resource-Efficient Retrieval Augmented Generation](https://arxiv.org/abs/2508.01546)
*Zeyu Xu,Junkang Zhang,Qiang Wang,Yi Liu*

Main category: cs.CV

TL;DR: E-VRAG是一种高效的视频检索增强生成框架，通过多项创新技术显著降低了计算成本，同时提高了准确性，为长视频理解任务带来了突破。


<details>
  <summary>Details</summary>
Motivation: 现有的视频检索增强生成方法在处理长视频时，面临上下文窗口受限和计算成本高的问题，并且在检索效率和准确性之间难以取得平衡。

Method: 提出了一种名为E-VRAG的新型视频检索增强生成框架，该框架包含：1. 基于分层查询分解的帧预过滤方法，以减少数据层面的计算成本。2. 使用轻量级VLM进行帧评分，以减少模型层面的计算成本。3. 利用帧间得分的全局统计分布的帧检索策略，以缓解轻量级VLM可能带来的性能下降。4. 多视图问答方案，以增强VLM从长视频上下文中提取信息的能力。

Result: 在四个公开基准测试中，E-VRAG实现了约70%的计算成本降低和比基线方法更高的准确性，且无需额外训练。

Conclusion: E-VRAG通过分层查询分解、轻量级VLM评分和多视图问答方案，在计算成本降低约70%的情况下，提高了视频检索增强生成任务的准确性和效率，且无需额外训练。

Abstract: Vision-Language Models (VLMs) have enabled substantial progress in video
understanding by leveraging cross-modal reasoning capabilities. However, their
effectiveness is limited by the restricted context window and the high
computational cost required to process long videos with thousands of frames.
Retrieval-augmented generation (RAG) addresses this challenge by selecting only
the most relevant frames as input, thereby reducing the computational burden.
Nevertheless, existing video RAG methods struggle to balance retrieval
efficiency and accuracy, particularly when handling diverse and complex video
content. To address these limitations, we propose E-VRAG, a novel and efficient
video RAG framework for video understanding. We first apply a frame
pre-filtering method based on hierarchical query decomposition to eliminate
irrelevant frames, reducing computational costs at the data level. We then
employ a lightweight VLM for frame scoring, further reducing computational
costs at the model level. Additionally, we propose a frame retrieval strategy
that leverages the global statistical distribution of inter-frame scores to
mitigate the potential performance degradation from using a lightweight VLM.
Finally, we introduce a multi-view question answering scheme for the retrieved
frames, enhancing the VLM's capability to extract and comprehend information
from long video contexts. Experiments on four public benchmarks show that
E-VRAG achieves about 70% reduction in computational cost and higher accuracy
compared to baseline methods, all without additional training. These results
demonstrate the effectiveness of E-VRAG in improving both efficiency and
accuracy for video RAG tasks.

</details>


### [92] [A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models](https://arxiv.org/abs/2508.01548)
*Quan-Sheng Zeng,Yunheng Li,Qilong Wang,Peng-Tao Jiang,Zuxuan Wu,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: GlimpsePrune 是一种动态剪枝框架，可高效处理高分辨率输入，在保持性能的同时剪枝 92.6% 的视觉标记。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉标记压缩方法采用固定的压缩率，无法适应不同复杂度的场景，导致不精确的剪枝，丢弃有信息量的视觉标记，并降低模型性能。

Method: 提出了一种受人类认知启发的动态剪枝框架 GlimpsePrune，该框架在生成答案之前，通过一次前向传播来“瞥一眼”并剪掉不相关的视觉标记。

Result: GlimpsePrune 在自由形式的视觉问答任务上，在平均完全保留基线性能的情况下，剪枝了 92.6% 的视觉标记。GlimpsePrune+ 的性能达到基线性能的 110%，同时保持了同样高的剪枝率。

Conclusion: GlimpsePrune 为构建更强大、更高效的 LVLM 铺平了新道路。

Abstract: Visual token compression is critical for Large Vision-Language Models (LVLMs)
to efficiently process high-resolution inputs. Existing methods that typically
adopt fixed compression ratios cannot adapt to scenes of varying complexity,
often causing imprecise pruning that discards informative visual tokens and
results in degraded model performance. To address this issue, we introduce a
dynamic pruning framework, GlimpsePrune, inspired by human cognition. It takes
a data-driven ''glimpse'' and prunes irrelevant visual tokens in a single
forward pass before answer generation. This approach prunes 92.6% of visual
tokens while on average fully retaining the baseline performance on free-form
VQA tasks. The reduced computational cost also enables more effective
fine-tuning: an enhanced GlimpsePrune+ achieves 110% of the baseline
performance while maintaining a similarly high pruning rate. Our work paves a
new way for building more powerful and efficient LVLMs.

</details>


### [93] [EvoVLMA: Evolutionary Vision-Language Model Adaptation](https://arxiv.org/abs/2508.01558)
*Kun Ding,Ying Wang,Shiming Xiang*

Main category: cs.CV

TL;DR: 本研究提出 EvoVLMA，一种利用 LLM 自动优化 VLM 适配算法的方法，在无需训练的情况下提高了图像识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉语言模型（VLM）适配方法（如提示调优和适配器）由人类专家设计，耗时且需要经验。本研究旨在自动搜索 VLM 的高效适配算法，以应对这一挑战。

Method: 提出了一种名为 EvoVLMA 的进化视觉语言模型适配方法，该方法利用大型语言模型辅助的进化算法，通过特征选择和 logits 计算优化训练免费的 VLM 适配算法。为提高搜索稳定性和效率，还引入了低精度代码转换、基于 Web 的代码执行和进程监控。

Result: 实验结果表明，EvoVLMA 找到的算法在 8 样本图像分类等任务上，相比先前手动设计的算法，能够获得有竞争力的结果，并将经典的 APE 算法的识别准确率提高了 1.91 个百分点。

Conclusion: 该研究为自动化预训练多模态模型的适配算法优化开辟了新的可能性。

Abstract: Pre-trained Vision-Language Models (VLMs) have been exploited in various
Computer Vision tasks (e.g., few-shot recognition) via model adaptation, such
as prompt tuning and adapters. However, existing adaptation methods are
designed by human experts, requiring significant time cost and experience.
Inspired by recent advances in Large Language Models (LLMs) based code
generation, we propose an Evolutionary Vision-Language Model Adaptation
(EvoVLMA) method to automatically search training-free efficient adaptation
algorithms for VLMs. We recognize feature selection and logits computation as
the key functions in training-free VLM adaptation, and propose a two-stage
LLM-assisted evolutionary algorithm for optimizing these parts in a sequential
manner, effectively addressing the challenge posed by the expansive search
space through a divide-and-conquer strategy. Besides, to enhance the stability
and efficiency of searching process, we propose low-precision code conversion,
web based code execution and process monitoring, leading to a highly effective
automatic algorithm design system. Extensive experiments demonstrate that the
algorithms found by EvoVLMA can obtain promising results compared to previous
manually-designed ones. More specifically, in the 8-shot image classification
setting, the classical APE algorithm can be improved by 1.91 points in
recognition accuracy. This research opens new possibilities for automating the
optimization of adaptation algorithms of pre-trained multimodal models. Code is
available at: https://github.com/kding1225/EvoVLMA

</details>


### [94] [Adaptive LiDAR Scanning: Harnessing Temporal Cues for Efficient 3D Object Detection via Multi-Modal Fusion](https://arxiv.org/abs/2508.01562)
*Sara Shoouri,Morteza Tavakoli Taba,Hun-Seok Kim*

Main category: cs.CV

TL;DR: 通过预测感兴趣的区域来优化激光雷达扫描，以降低功耗并保持检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的激光雷达传感器会执行密集、无状态的扫描，忽略真实场景中的强大时间连续性，从而导致显着的传感冗余和过高的功耗，这在资源受限的平台上限制了其实用性。

Method: 提出了一种预测性的、历史感知的自适应扫描框架，该框架使用轻量级预测网络和 Gumbel-Softmax 采样的可微分掩码生成网络来预测感兴趣的区域 (ROI)，从而仅在这些 ROI 内集中激光雷达扫描，并在其他地方稀疏采样。

Result: 该方法可将激光雷达的能耗降低 65% 以上，同时在 3D 物体检测性能方面与传统的激光雷达-摄像头融合方法相比具有竞争力，甚至更优。

Conclusion: 通过在资源受限的平台上使用由历史观察得出的信息感兴趣区域（ROI）的预测来集中激光雷达扫描，可以显着降低激光雷达的能耗，同时保持有竞争力的 3D 物体检测性能。

Abstract: Multi-sensor fusion using LiDAR and RGB cameras significantly enhances 3D
object detection task. However, conventional LiDAR sensors perform dense,
stateless scans, ignoring the strong temporal continuity in real-world scenes.
This leads to substantial sensing redundancy and excessive power consumption,
limiting their practicality on resource-constrained platforms. To address this
inefficiency, we propose a predictive, history-aware adaptive scanning
framework that anticipates informative regions of interest (ROI) based on past
observations. Our approach introduces a lightweight predictor network that
distills historical spatial and temporal contexts into refined query
embeddings. These embeddings guide a differentiable Mask Generator network,
which leverages Gumbel-Softmax sampling to produce binary masks identifying
critical ROIs for the upcoming frame. Our method significantly reduces
unnecessary data acquisition by concentrating dense LiDAR scanning only within
these ROIs and sparsely sampling elsewhere. Experiments on nuScenes and Lyft
benchmarks demonstrate that our adaptive scanning strategy reduces LiDAR energy
consumption by over 65% while maintaining competitive or even superior 3D
object detection performance compared to traditional LiDAR-camera fusion
methods with dense LiDAR scanning.

</details>


### [95] [LetheViT: Selective Machine Unlearning for Vision Transformers via Attention-Guided Contrastive Learning](https://arxiv.org/abs/2508.01569)
*Yujia Tong,Tian Zhang,Jingling Yuan,Yuze Wang,Chuang Hu*

Main category: cs.CV

TL;DR: A new method called LetheViT helps Vision Transformers forget specific data points while keeping general knowledge, addressing privacy concerns without hurting performance.


<details>
  <summary>Details</summary>
Motivation: Privacy regulations such as GDPR and CCPA necessitate the removal of user data influence from trained models, making machine unlearning critical, especially for Vision Transformers (ViTs) facing the challenge of random data forgetting.

Method: LetheViT uses masked image inputs to generate positive logits and original image inputs to generate negative logits, guiding the model to forget specific details while retaining the general cl category outlines.

Result: LetheViT achieves state-of-the-art performance, effectively balancing privacy compliance with model efficacy.

Conclusion: LetheViT

Abstract: Vision Transformers (ViTs) have revolutionized computer vision tasks with
their exceptional performance. However, the introduction of privacy regulations
such as GDPR and CCPA has brought new challenges to them. These laws grant
users the right to withdraw their data, necessitating not only the deletion of
data but also the complete removal of its influence from trained models.
Machine unlearning emerges as a critical solution, with exact unlearning being
computationally prohibitive and approximate methods offering a more practical
approach. This work addresses the particularly challenging scenario of random
data forgetting in ViTs, where the model must forget specific samples while
retaining others, even within the same class. We first reveal the core
characteristics of ViTs through selective masking experiments: when
high-attention areas are masked, the model retains its recognition capability
but significantly weakens its memorization ability. Based on the above
insights, we propose LetheViT, a contrastive unlearning method tailored for
ViTs. LetheViT uses masked image inputs to generate positive logits and
original image inputs to generate negative logits, guiding the model to forget
specific details while retaining the general cl category outlines. Experimental
results demonstrate that LetheViT achieves state-of-the-art performance,
effectively balancing privacy compliance with model efficacy.

</details>


### [96] [TopoImages: Incorporating Local Topology Encoding into Deep Learning Models for Medical Image Classification](https://arxiv.org/abs/2508.01574)
*Pengfei Gu,Hongxiao Wang,Yejia Zhang,Huimin Li,Chaoli Wang,Danny Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 TopoImages 的新方法，用于通过编码局部拓扑来改进图像表示，尤其是在深度学习中。通过利用持久同源性来提取拓扑特征，并生成多视图 TopoImages，该方法在医学图像分类任务中取得了优于现有技术的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 尽管许多依赖外观信息的图像处理方法取得了显著成功，但在通用深度学习 (DL) 框架中，这些方法在处理拓扑结构方面往往缺乏敏感性。因此，需要一种新的方法来捕获图像中的拓扑信息。

Method: 该方法首先计算图像块的持久性图 (PD)，然后将 PD 矢量化并排列成用于图像块像素的长向量，从而生成 TopoImages。为了获得更多样化和显著的拓扑特征，并确保更全面和丰富的表示，研究人员还使用各种过滤函数生成了多视图 TopoImages。最后，将多视图 TopoImages 与输入图像融合，用于基于深度学习的分类。

Result: 实验结果表明，所提出的 TopoImages 方法在三个公共医学图像分类数据集上，与现有最先进的方法相比，准确率有了显著提高。

Conclusion: TopoImages 是一种通用的方法，可以通过编码图像块的局部拓扑来计算输入图像的新表示。它利用持久同源性 (PH) 来编码图像块固有的几何和拓扑特征。通过对图像块计算持久性图 (PD)，然后将这些 PD 矢量化并排列成长向量，生成了 TopoImages。通过使用各种过滤函数生成多个 TopoImages（称为多视图 TopoImages），可以获得多样化和显著的拓扑特征。将多视图 TopoImages 与输入图像融合后，在基于 DL 的分类任务中，准确率得到了显著提高。该方法具有高度通用性，可无缝集成到常见的 DL 框架中。在三个公共医学图像分类数据集上的实验表明，与最先进的方法相比，准确率有了显著提高。

Abstract: Topological structures in image data, such as connected components and loops,
play a crucial role in understanding image content (e.g., biomedical objects).
% Despite remarkable successes of numerous image processing methods that rely
on appearance information, these methods often lack sensitivity to topological
structures when used in general deep learning (DL) frameworks. % In this paper,
we introduce a new general approach, called TopoImages (for Topology Images),
which computes a new representation of input images by encoding local topology
of patches. % In TopoImages, we leverage persistent homology (PH) to encode
geometric and topological features inherent in image patches. % Our main
objective is to capture topological information in local patches of an input
image into a vectorized form. % Specifically, we first compute persistence
diagrams (PDs) of the patches, % and then vectorize and arrange these PDs into
long vectors for pixels of the patches. % The resulting multi-channel
image-form representation is called a TopoImage. % TopoImages offers a new
perspective for data analysis. % To garner diverse and significant topological
features in image data and ensure a more comprehensive and enriched
representation, we further generate multiple TopoImages of the input image
using various filtration functions, which we call multi-view TopoImages. % The
multi-view TopoImages are fused with the input image for DL-based
classification, with considerable improvement. % Our TopoImages approach is
highly versatile and can be seamlessly integrated into common DL frameworks.
Experiments on three public medical image classification datasets demonstrate
noticeably improved accuracy over state-of-the-art methods.

</details>


### [97] [Harnessing Textual Semantic Priors for Knowledge Transfer and Refinement in CLIP-Driven Continual Learning](https://arxiv.org/abs/2508.01579)
*Lingfeng He,De Cheng,Huaijie Wang,Nannan Wang*

Main category: cs.CV

TL;DR: SECA框架利用CLIP的文本语义先验，通过SG-AKT模块进行语义感知的知识转移，并通过SE-VPR模块增强视觉原型，有效解决了持续学习中的稳定-塑形困境。


<details>
  <summary>Details</summary>
Motivation: 现有方法在知识转移时未考虑语义相关性，导致无关任务的干扰；同时，基于文本的分类器泛化性强但塑形性弱，而基于视觉的分类器虽然能弥补这一差距，但其原型缺乏丰富的语义。SECA旨在解决这些挑战，充分利用CLIP的文本语义先验来解决稳定-塑形困境。

Method: 提出了一种名为SECA的统一框架，包含两个关键模块：1. 语义引导的自适应知识转移（SG-AKT），通过文本线索评估新图像与历史视觉知识的相关性，并以蒸馏信号的形式以实例自适应的方式聚合相关知识。 2. 语义增强的视觉原型细化（SE-VPR），利用类别文本嵌入中捕获的类别间语义关系来细化视觉原型。

Result: 通过在多个基准上的广泛实验验证了SECA方法的有效性。

Conclusion: SECA框架通过指导语义感知的知识转移来解决稳定-塑形困境，并利用文本先验来增强视觉分类器的语义结构，实验证明了其有效性。

Abstract: Continual learning (CL) aims to equip models with the ability to learn from a
stream of tasks without forgetting previous knowledge. With the progress of
vision-language models like Contrastive Language-Image Pre-training (CLIP),
their promise for CL has attracted increasing attention due to their strong
generalizability. However, the potential of rich textual semantic priors in
CLIP in addressing the stability-plasticity dilemma remains underexplored.
During backbone training, most approaches transfer past knowledge without
considering semantic relevance, leading to interference from unrelated tasks
that disrupt the balance between stability and plasticity. Besides, while
text-based classifiers provide strong generalization, they suffer from limited
plasticity due to the inherent modality gap in CLIP. Visual classifiers help
bridge this gap, but their prototypes lack rich and precise semantics. To
address these challenges, we propose Semantic-Enriched Continual Adaptation
(SECA), a unified framework that harnesses the anti-forgetting and structured
nature of textual priors to guide semantic-aware knowledge transfer in the
backbone and reinforce the semantic structure of the visual classifier.
Specifically, a Semantic-Guided Adaptive Knowledge Transfer (SG-AKT) module is
proposed to assess new images' relevance to diverse historical visual knowledge
via textual cues, and aggregate relevant knowledge in an instance-adaptive
manner as distillation signals. Moreover, a Semantic-Enhanced Visual Prototype
Refinement (SE-VPR) module is introduced to refine visual prototypes using
inter-class semantic relations captured in class-wise textual embeddings.
Extensive experiments on multiple benchmarks validate the effectiveness of our
approach.

</details>


### [98] [Zero-Shot Temporal Interaction Localization for Egocentric Videos](https://arxiv.org/abs/2506.03662)
*Erhang Zhang,Junyi Ma,Yin-Dong Zheng,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: EgoLoc 是一种用于 egocentric 视频中零样本时间交互定位的新方法，通过自适应采样和 2D/3D 观察来提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有时间动作本地化方法依赖于注释的动作和对象类别，导致域偏差和部署效率低下。现有的零样本时间动作本地化方法（ZS-TAL）存在粒度粗糙和开环管线的问题。

Method: EgoLoc 是一种新颖的零样本时间交互定位方法，它使用自适应采样策略生成视觉提示，并结合 2D 和 3D 观察以及 3D 手部速度来精确定位抓取动作的时间。它还利用视觉和动态线索生成闭环反馈以优化结果。

Result: EgoLoc 在公开数据集和新提出的基准测试中都取得了优于最先进方法的性能。

Conclusion: EgoLoc 在 egocentric 视频中实现了更好的时间交互定位，优于现有技术。

Abstract: Locating human-object interaction (HOI) actions within video serves as the
foundation for multiple downstream tasks, such as human behavior analysis and
human-robot skill transfer. Current temporal action localization methods
typically rely on annotated action and object categories of interactions for
optimization, which leads to domain bias and low deployment efficiency.
Although some recent works have achieved zero-shot temporal action localization
(ZS-TAL) with large vision-language models (VLMs), their coarse-grained
estimations and open-loop pipelines hinder further performance improvements for
temporal interaction localization (TIL). To address these issues, we propose a
novel zero-shot TIL approach dubbed EgoLoc to locate the timings of grasp
actions for human-object interaction in egocentric videos. EgoLoc introduces a
self-adaptive sampling strategy to generate reasonable visual prompts for VLM
reasoning. By absorbing both 2D and 3D observations, it directly samples
high-quality initial guesses around the possible contact/separation timestamps
of HOI according to 3D hand velocities, leading to high inference accuracy and
efficiency. In addition, EgoLoc generates closed-loop feedback from visual and
dynamic cues to further refine the localization results. Comprehensive
experiments on the publicly available dataset and our newly proposed benchmark
demonstrate that EgoLoc achieves better temporal interaction localization for
egocentric videos compared to state-of-the-art baselines. We will release our
code and relevant data as open-source at https://github.com/IRMVLab/EgoLoc.

</details>


### [99] [Set Pivot Learning: Redefining Generalized Segmentation with Vision Foundation Models](https://arxiv.org/abs/2508.01582)
*Xinhui Li,Xinyu He,Qiming Hu,Xiaojie Guo*

Main category: cs.CV

TL;DR: The paper introduces Set Pivot Learning (SPL), a new approach for domain generalization using Vision Foundation Models (VFMs), which allows for adaptive refinement and VFM-centric tuning. A dynamic prompt fine-tuning method based on SPL improves VFM performance, especially in generalized segmentation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The emergence of VFMs trained on vast datasets makes traditional domain generalization (DG) assumptions (target domain inaccessibility during training) unclear and obsolete. This necessitates a new approach, SPL, which is more suitable for current research and application requirements by prioritizing adaptive refinement over rigid domain transfer.

Method: The paper proposes Set Pivot Learning (SPL) as a new definition for domain migration tasks based on VFMs. It introduces a Dynamic Prompt Fine-Tuning method, which includes a Dynamic Class-aware Prompter and a Prompt-guided Feature Focuser, to enhance VFM performance in specific scenarios.

Result: Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed method, showing its superiority over state-of-the-art methods, particularly in generalized segmentation tasks.

Conclusion: Set Pivot Learning (SPL) is a new paradigm for domain generalization that leverages Vision Foundation Models (VFMs). SPL prioritizes adaptive refinement and VFM-centric tuning, moving beyond traditional DG assumptions. A Dynamic Prompt Fine-Tuning method based on SPL shows superiority over state-of-the-art methods, especially in generalized segmentation.

Abstract: In this paper, we introduce, for the first time, the concept of Set Pivot
Learning, a paradigm shift that redefines domain generalization (DG) based on
Vision Foundation Models (VFMs). Traditional DG assumes that the target domain
is inaccessible during training, but the emergence of VFMs, trained on vast and
diverse data, renders this assumption unclear and obsolete. Traditional DG
assumes that the target domain is inaccessible during training, but the
emergence of VFMs, which are trained on vast and diverse datasets, renders this
assumption unclear and obsolete. To address this challenge, we propose Set
Pivot Learning (SPL), a new definition of domain migration task based on VFMs,
which is more suitable for current research and application requirements.
Unlike conventional DG methods, SPL prioritizes adaptive refinement over rigid
domain transfer, ensuring continuous alignment with evolving real-world
conditions. Specifically, SPL features two key attributes: (i) Dynamic
adaptation, transitioning from static domain alignment to flexible, task-driven
feature optimization, enabling models to evolve with downstream scenarios; (ii)
VFM-centric tuning, leveraging pretrained knowledge as a pivot to hone
task-specific representations while preserving cross-domain robustness.
Building on SPL, we propose a Dynamic Prompt Fine-Tuning method, which combines
a Dynamic Class-aware Prompter with a Prompt-guided Feature Focuser, to elevate
VFM performance in targeted scenarios. Extensive experiments on benchmark
datasets show the effectiveness of our method, highlighting its superiority
over state-of-the-art methods, particularly in generalized segmentation.

</details>


### [100] [A Spatio-temporal Continuous Network for Stochastic 3D Human Motion Prediction](https://arxiv.org/abs/2508.01585)
*Hua Yu,Yaqing Hou,Xu Gui,Shanshan Feng,Dongsheng Zhou,Qiang Zhang*

Main category: cs.CV

TL;DR: STCN是一种新颖的人体运动预测方法，通过时空连续网络和锚点集机制，解决了现有方法的模式崩溃和运动不连续问题，并在两个标准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在学习连续时间动力学和预测随机运动序列方面存在挑战，忽略了复杂运动的灵活性且容易发生模式崩溃。

Method: STCN方法包含两个阶段：第一阶段使用时空连续网络生成平滑的人体运动序列，并引入锚点集防止模式崩溃；第二阶段利用锚点集学习运动序列的高斯混合分布，并通过从每个锚点采样多个序列来缓解类内差异。

Result: STCN能够生成更平滑的人体运动序列，并能有效防止模式崩溃，同时缓解了类内差异。

Conclusion: STCN在Human3.6M和HumanEva-I数据集上进行了实验，取得了具有竞争力的多样性和准确性。

Abstract: Stochastic Human Motion Prediction (HMP) has received increasing attention
due to its wide applications. Despite the rapid progress in generative fields,
existing methods often face challenges in learning continuous temporal dynamics
and predicting stochastic motion sequences. They tend to overlook the
flexibility inherent in complex human motions and are prone to mode collapse.
To alleviate these issues, we propose a novel method called STCN, for
stochastic and continuous human motion prediction, which consists of two
stages. Specifically, in the first stage, we propose a spatio-temporal
continuous network to generate smoother human motion sequences. In addition,
the anchor set is innovatively introduced into the stochastic HMP task to
prevent mode collapse, which refers to the potential human motion patterns. In
the second stage, STCN endeavors to acquire the Gaussian mixture distribution
(GMM) of observed motion sequences with the aid of the anchor set. It also
focuses on the probability associated with each anchor, and employs the
strategy of sampling multiple sequences from each anchor to alleviate
intra-class differences in human motions. Experimental results on two
widely-used datasets (Human3.6M and HumanEva-I) demonstrate that our model
obtains competitive performance on both diversity and accuracy.

</details>


### [101] [Lifelong Person Re-identification via Privacy-Preserving Data Replay](https://arxiv.org/abs/2508.01587)
*Mingyu Wang,Haojie Liu,Zhiyong Li,Wei Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为 Pr^2R 的新方法，通过将数据信息压缩到像素空间来解决终身行人重识别中的数据隐私和性能下降问题，并在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于重放的方法在终身行人重识别（LReID）中虽然有效，但存在数据隐私问题。而现有的一些避免存储原始样本的方法（exemplar-free）虽然保护隐私，但性能会有所下降，因为它会遗忘特定的 past knowledge representations。因此，需要一种既能保护隐私又能有效进行重放的方法。

Method: 提出了一种名为 Pr^2R 的方法，该方法通过将序列数据的信息压缩到重放内存的像素空间中来解决现有方法的不足。具体来说，通过将多个真实图像的训练特征提炼到单个图像中，压缩后的样本会经历像素级别的变化，从而保护原始数据的隐私，并使重放样本更能代表序列任务。在风格重放阶段，该方法将当前域与先前域对齐，同时使重放样本适应当前域的风格。

Result: Pr^2R 方法有效地缓解了类别增量学习的挑战以及由域偏移引起的遗忘问题，在多个基准测试上的大量实验表明，该方法在保持数据隐私的同时显著提高了重放的有效性。

Conclusion: 提出的 Pr^2R 方法在序列任务上比现有的最先进方法和其他基于重放的方法分别提高了 4% 和 6% 的准确率，同时保护了数据隐私。

Abstract: Lifelong person re-identification (LReID) aims to incrementally accumulate
knowledge across a sequence of tasks under domain shifts. Recently,
replay-based methods have demonstrated strong effectiveness in LReID by
rehearsing past samples stored in an auxiliary memory. However, storing
historical exemplars raises concerns over data privacy. To avoid this,
exemplar-free approaches attempt to match the distribution of past data without
storing raw samples. Despite being privacy-friendly, these methods often suffer
from performance degradation due to the forgetting of specific past knowledge
representations. To this end, we propose to condense information from
sequential data into the pixel space in the replay memory, enabling
Privacy-Preserving Replay (Pr^2R). More specifically, by distilling the
training characteristics of multiple real images into a single image, the
condensed samples undergo pixel-level changes. This not only protects the
privacy of the original data but also makes the replay samples more
representative for sequential tasks. During the style replay phase, we align
the current domain to the previous one while simultaneously adapting the replay
samples to match the style of the current domain. This dual-alignment strategy
effectively mitigates both class-incremental challenges and forgetting caused
by domain shifts. Extensive experiments on multiple benchmarks show that the
proposed method significantly improves replay effectiveness while preserving
data privacy. Specifically, Pr^2R achieves 4% and 6% higher accuracy on
sequential tasks compared to the current state-of-the-art and other
replay-based methods, respectively.

</details>


### [102] [Self-Navigated Residual Mamba for Universal Industrial Anomaly Detection](https://arxiv.org/abs/2508.01591)
*Hanxi Li,Jingqi Wu,Lin Yuanbo Wu,Mingliang Li,Deyin Liu,Jialie Shen,Chunhua Shen*

Main category: cs.CV

TL;DR: SNARM 是一种新颖的工业异常检测框架，通过“自参照学习”和 Mamba 模块，动态地识别和定位异常区域，并在多个基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: SNARM 框架旨在解决传统工业异常检测方法仅依赖正常训练数据预训练特征的局限性，通过在测试图像内引入“自参照学习”，动态地优化异常检测过程，以提高异常区分能力。

Method: SNARM 框架利用测试图像中的“自参照学习”来增强异常区分。它通过将测试图像块与自生成参考块进行比较来计算“内部残差”特征，以放大判别信号。然后，将这些内部残差和“互残差”特征（通过将测试图像块与训练特征库进行对比而计算得出）连接起来，并输入到一个新颖的、由残差属性动态导航的多头 Mamba 模块中，最后通过集成学习范式聚合自导航 Mamba 的输出来获得异常检测结果。

Result: SNARM 在 MVTec AD、MVTec 3D 和 VisA 数据集上取得了最先进的性能，在 Image-AUROC、Pixel-AURC、PRO 和 AP 等关键指标上均有显著提升。

Conclusion: SNARM 在 MVTec AD、MVTec 3D 和 VisA 基准测试中实现了最先进 (SOTA) 的性能，在 Image-AUROC、Pixel-AURC、PRO 和 AP 等所有指标上均有显著改进。

Abstract: In this paper, we propose Self-Navigated Residual Mamba (SNARM), a novel
framework for universal industrial anomaly detection that leverages
``self-referential learning'' within test images to enhance anomaly
discrimination. Unlike conventional methods that depend solely on pre-trained
features from normal training data, SNARM dynamically refines anomaly detection
by iteratively comparing test patches against adaptively selected in-image
references. Specifically, we first compute the ``inter-residuals'' features by
contrasting test image patches with the training feature bank. Patches
exhibiting small-norm residuals (indicating high normality) are then utilized
as self-generated reference patches to compute ``intra-residuals'', amplifying
discriminative signals. These inter- and intra-residual features are
concatenated and fed into a novel Mamba module with multiple heads, which are
dynamically navigated by residual properties to focus on anomalous regions.
Finally, AD results are obtained by aggregating the outputs of a self-navigated
Mamba in an ensemble learning paradigm. Extensive experiments on MVTec AD,
MVTec 3D, and VisA benchmarks demonstrate that SNARM achieves state-of-the-art
(SOTA) performance, with notable improvements in all metrics, including
Image-AUROC, Pixel-AURC, PRO, and AP.

</details>


### [103] [DMTrack: Spatio-Temporal Multimodal Tracking via Dual-Adapter](https://arxiv.org/abs/2508.01592)
*Weihong Li,Shaohua Dong,Haonan Lu,Yanhao Zhang,Heng Fan,Libo Zhang*

Main category: cs.CV

TL;DR: DMTrack uses a dual-adapter (STMA and PMCA) approach for spatio-temporal multimodal tracking, achieving SOTA results with minimal parameters.


<details>
  <summary>Details</summary>
Motivation: To explore adapter tuning and introduce a novel dual-adapter architecture for spatio-temporal multimodal tracking.

Method: DMTrack introduces a novel dual-adapter architecture consisting of a spatio-temporal modality adapter (STMA) and a progressive modality complementary adapter (PMCA). STMA adjusts spatio-temporal features from a frozen backbone via self-prompting to bridge modality gaps. PMCA facilitates cross-modality prompting progressively using shallow and deep adapters. The shallow adapter uses shared parameters for initial information flow, while the deep adapter modulates fused information with pixel-wise inner-modal and inter-modal attention.

Result: DMTrack achieves state-of-the-art results on five benchmarks with only 0.93M trainable parameters.

Conclusion: DMTrack achieves promising spatio-temporal multimodal tracking performance with merely 0.93M trainable parameters and state-of-the-art results on five benchmarks.

Abstract: In this paper, we explore adapter tuning and introduce a novel dual-adapter
architecture for spatio-temporal multimodal tracking, dubbed DMTrack. The key
of our DMTrack lies in two simple yet effective modules, including a
spatio-temporal modality adapter (STMA) and a progressive modality
complementary adapter (PMCA) module. The former, applied to each modality
alone, aims to adjust spatio-temporal features extracted from a frozen backbone
by self-prompting, which to some extent can bridge the gap between different
modalities and thus allows better cross-modality fusion. The latter seeks to
facilitate cross-modality prompting progressively with two specially designed
pixel-wise shallow and deep adapters. The shallow adapter employs shared
parameters between the two modalities, aiming to bridge the information flow
between the two modality branches, thereby laying the foundation for following
modality fusion, while the deep adapter modulates the preliminarily fused
information flow with pixel-wise inner-modal attention and further generates
modality-aware prompts through pixel-wise inter-modal attention. With such
designs, DMTrack achieves promising spatio-temporal multimodal tracking
performance with merely \textbf{0.93M} trainable parameters. Extensive
experiments on five benchmarks show that DMTrack achieves state-of-the-art
results. Code will be available.

</details>


### [104] [CLIMD: A Curriculum Learning Framework for Imbalanced Multimodal Diagnosis](https://arxiv.org/abs/2508.01594)
*Kai Han,Chongwen Lyu,Lele Ma,Chengxuan Qian,Siqi Ma,Zheng Pang,Jun Chen,Zhe Liu*

Main category: cs.CV

TL;DR: CLIMD通过结合课程学习、多模态课程评估器和类别分布引导的训练调度器来解决不平衡多模态医学数据的诊断问题，提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 由于发病率的差异，多模态医学数据通常面临类别不平衡问题，这使得充分学习少数类别的特征变得困难。现有的方法（如过采样或损失重加权）容易导致过拟合或欠拟合，并且无法捕捉跨模态交互。

Method: 提出了一种名为CLIMD（课程学习用于不平衡多模态诊断）的框架。该框架包括一个多模态课程评估器，结合了类内置信度和类间互补性两个指标，使模型能够关注关键样本并逐渐适应复杂的类别分布。此外，还引入了一个由类别分布引导的训练调度器，使模型能够逐步适应训练过程中的类别不平衡分布。

Result: 在多个多模态医学数据集上的大量实验表明，该方法在各种指标上均优于最先进的方法，并且在处理不平衡的多模态医学数据方面表现出色。

Conclusion: CLIMD是一种即插即用的课程学习框架，可以轻松集成到其他模型中，为提高多模态疾病诊断准确性提供了有前景的途径。实验证明，CLIMD在处理不平衡的多模态医学数据方面表现优于最先进的方法。

Abstract: Clinicians usually combine information from multiple sources to achieve the
most accurate diagnosis, and this has sparked increasing interest in leveraging
multimodal deep learning for diagnosis. However, in real clinical scenarios,
due to differences in incidence rates, multimodal medical data commonly face
the issue of class imbalance, which makes it difficult to adequately learn the
features of minority classes. Most existing methods tackle this issue with
resampling or loss reweighting, but they are prone to overfitting or
underfitting and fail to capture cross-modal interactions. Therefore, we
propose a Curriculum Learning framework for Imbalanced Multimodal Diagnosis
(CLIMD). Specifically, we first design multimodal curriculum measurer that
combines two indicators, intra-modal confidence and inter-modal
complementarity, to enable the model to focus on key samples and gradually
adapt to complex category distributions. Additionally, a class
distribution-guided training scheduler is introduced, which enables the model
to progressively adapt to the imbalanced class distribution during training.
Extensive experiments on multiple multimodal medical datasets demonstrate that
the proposed method outperforms state-of-the-art approaches across various
metrics and excels in handling imbalanced multimodal medical data. Furthermore,
as a plug-and-play CL framework, CLIMD can be easily integrated into other
models, offering a promising path for improving multimodal disease diagnosis
accuracy. Code is publicly available at https://github.com/KHan-UJS/CLIMD.

</details>


### [105] [Enhancing Zero-Shot Brain Tumor Subtype Classification via Fine-Grained Patch-Text Alignment](https://arxiv.org/abs/2508.01602)
*Lubin Gan,Jing Zhang,Linhao Qu,Yijun Wang,Siying Wu,Xiaoyan Sun*

Main category: cs.CV

TL;DR: FG-PAN是一个新的零样本框架，用于数字病理学中的脑肿瘤亚型分类。它通过细化局部特征和利用LLM生成文本描述来提高类别可分性，在多个数据集上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉-语言模型在捕捉细粒度病理特征方面能力有限，导致亚型区分效果不佳，而脑肿瘤亚型的细粒度分类面临细微的形态学变化和标注数据稀疏性的挑战。

Method: FG-PAN框架包含两个关键模块：1. 通过对代表性图块之间的空间关系进行建模来增强图块级视觉特征的局部特征细化模块；2. 利用大型语言模型生成病理感知、类别特定的语义原型的细粒度文本描述生成模块。通过将细化后的视觉特征与LLM生成的细粒度描述对齐，FG-PAN有效提高了视觉和语义空间中的类别可分性。

Result: FG-PAN在零样本脑肿瘤亚型分类任务上取得了最先进的性能和鲁棒的泛化能力。

Conclusion: FG-PAN在EBRAINS和TCGA等多个公共病理数据集上实现了最先进的性能和鲁棒的泛化能力，能够对脑肿瘤亚型进行零样本分类。

Abstract: The fine-grained classification of brain tumor subtypes from
histopathological whole slide images is highly challenging due to subtle
morphological variations and the scarcity of annotated data. Although
vision-language models have enabled promising zero-shot classification, their
ability to capture fine-grained pathological features remains limited,
resulting in suboptimal subtype discrimination. To address these challenges, we
propose the Fine-Grained Patch Alignment Network (FG-PAN), a novel zero-shot
framework tailored for digital pathology. FG-PAN consists of two key modules:
(1) a local feature refinement module that enhances patch-level visual features
by modeling spatial relationships among representative patches, and (2) a
fine-grained text description generation module that leverages large language
models to produce pathology-aware, class-specific semantic prototypes. By
aligning refined visual features with LLM-generated fine-grained descriptions,
FG-PAN effectively increases class separability in both visual and semantic
spaces. Extensive experiments on multiple public pathology datasets, including
EBRAINS and TCGA, demonstrate that FG-PAN achieves state-of-the-art performance
and robust generalization in zero-shot brain tumor subtype classification.

</details>


### [106] [Towards Generalizable AI-Generated Image Detection via Image-Adaptive Prompt Learning](https://arxiv.org/abs/2508.01603)
*Yiheng Li,Zichang Tan,Zhen Lei,Xu Zhou,Yang Yang*

Main category: cs.CV

TL;DR: 提出了一种名为IAPL的新框架，用于AI生成图像检测，通过图像自适应提示学习来提高对未知生成器的泛化能力。该框架通过条件信息学习和置信驱动自适应预测模块，能够根据输入图像自动调整提示，从而提高检测的准确性和适应性。实验证明，IAPL在两个基准数据集上均取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有技术通常通过部分参数微调来定制预训练基础模型以应对AI生成图像检测任务，但这些在有限生成器上训练的参数可能无法泛化到未知来源。为解决这个问题，提出了一种名为图像自适应提示学习（IAPL）的新框架，以提高处理各种测试图像的灵活性。

Method: IAPL框架包括条件信息学习模块和置信驱动自适应预测模块。条件信息学习模块使用基于CNN的特征提取器学习特定于伪造和图像的条件，并通过门控机制将其传播到可学习的token。置信驱动自适应预测模块根据单个测试样本优化浅层可学习token，并选择预测置信度最高的裁剪视图进行最终检测。

Result: IAPL在UniversalFakeDetect和GenImage两个广泛使用的数据集上取得了最先进的性能，平均准确率分别为95.61%和96.7%。

Conclusion: 所提出的图像自适应提示学习（IAPL）框架通过引入条件信息学习和置信驱动自适应预测两个模块，增强了处理不同测试图像的灵活性，实现了最先进的性能，在UniversalFakeDetect和GenImage数据集上分别达到了95.61%和96.7%的平均准确率。

Abstract: A major struggle for AI-generated image detection is identifying fake images
from unseen generators. Existing cutting-edge methods typically customize
pre-trained foundation models to this task via partial-parameter fine-tuning.
However, these parameters trained on a narrow range of generators may fail to
generalize to unknown sources. In light of this, we propose a novel framework
named Image-Adaptive Prompt Learning (IAPL), which enhances flexibility in
processing diverse testing images. It consists of two adaptive modules, i.e.,
the Conditional Information Learner and the Confidence-Driven Adaptive
Prediction. The former employs CNN-based feature extractors to learn
forgery-specific and image-specific conditions, which are then propagated to
learnable tokens via a gated mechanism. The latter optimizes the shallowest
learnable tokens based on a single test sample and selects the cropped view
with the highest prediction confidence for final detection. These two modules
enable the prompts fed into the foundation model to be automatically adjusted
based on the input image, rather than being fixed after training, thereby
enhancing the model's adaptability to various forged images. Extensive
experiments show that IAPL achieves state-of-the-art performance, with 95.61%
and 96.7% mean accuracy on two widely used UniversalFakeDetect and GenImage
datasets, respectively.

</details>


### [107] [From Pixels to Places: A Systematic Benchmark for Evaluating Image Geolocalization Ability in Large Language Models](https://arxiv.org/abs/2508.01608)
*Lingyao Li,Runlong Yu,Qikai Hu,Bowei Li,Min Deng,Yang Zhou,Xiaowei Jia*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Image geolocalization, the task of identifying the geographic location
depicted in an image, is important for applications in crisis response, digital
forensics, and location-based intelligence. While recent advances in large
language models (LLMs) offer new opportunities for visual reasoning, their
ability to perform image geolocalization remains underexplored. In this study,
we introduce a benchmark called IMAGEO-Bench that systematically evaluates
accuracy, distance error, geospatial bias, and reasoning process. Our benchmark
includes three diverse datasets covering global street scenes, points of
interest (POIs) in the United States, and a private collection of unseen
images. Through experiments on 10 state-of-the-art LLMs, including both open-
and closed-source models, we reveal clear performance disparities, with
closed-source models generally showing stronger reasoning. Importantly, we
uncover geospatial biases as LLMs tend to perform better in high-resource
regions (e.g., North America, Western Europe, and California) while exhibiting
degraded performance in underrepresented areas. Regression diagnostics
demonstrate that successful geolocalization is primarily dependent on
recognizing urban settings, outdoor environments, street-level imagery, and
identifiable landmarks. Overall, IMAGEO-Bench provides a rigorous lens into the
spatial reasoning capabilities of LLMs and offers implications for building
geolocation-aware AI systems.

</details>


### [108] [LLaDA-MedV: Exploring Large Language Diffusion Models for Biomedical Image Understanding](https://arxiv.org/abs/2508.01617)
*Xuanzhao Dong,Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Peijie Qiu,Shao Tang,Xin Li,Yalin Wang*

Main category: cs.CV

TL;DR: LLaDA-MedV 是首个针对生物医学图像理解的大型语言扩散模型，在多个基准测试中取得了最先进的性能，并能生成更长的响应。


<details>
  <summary>Details</summary>
Motivation: 填补 LLaDA-MedV 在生物医学领域应用的研究空白。

Method: LLaDA-MedV 是一个针对生物医学图像理解的大型语言扩散模型，通过视觉指令微调实现。

Result: LLaDA-MedV 在开放式生物医学视觉对话任务上取得了 7.855% 的相对性能增益（相对于 LLaVA-Med）和 1.867% 的相对性能增益（相对于 LLaDA-V）。在 VQA-RAD、SLAKE 和 PathVQA 数据集上，准确率分别为 84.93%、92.31% 和 95.15%。此外，LLaDA-MedV 能够生成更长、更具信息量的响应，并且通过对训练和推理阶段的深入分析，揭示了初始化权重选择、微调策略以及采样步数和响应重复之间的相互作用等关键因素。

Conclusion: LLaDA-MedV 在生物医学领域取得了显著的成果，在开放式生物医学视觉对话任务上超越了 LLaVA-Med 和 LLaDA-V，并在 VQA-RAD、SLAKE 和 PathVQA 三个 VQA 基准的闭式子集上设定了新的准确率。

Abstract: Autoregressive models (ARMs) have long dominated the landscape of biomedical
vision-language models (VLMs). Recently, masked diffusion models such as LLaDA
have emerged as promising alternatives, yet their application in the biomedical
domain remains largely underexplored. To bridge this gap, we introduce
\textbf{LLaDA-MedV}, the first large language diffusion model tailored for
biomedical image understanding through vision instruction tuning. LLaDA-MedV
achieves relative performance gains of 7.855\% over LLaVA-Med and 1.867\% over
LLaDA-V in the open-ended biomedical visual conversation task, and sets new
state-of-the-art accuracy on the closed-form subset of three VQA benchmarks:
84.93\% on VQA-RAD, 92.31\% on SLAKE, and 95.15\% on PathVQA. Furthermore, a
detailed comparison with LLaVA-Med suggests that LLaDA-MedV is capable of
generating reasonably longer responses by explicitly controlling response
length, which can lead to more informative outputs. We also conduct an in-depth
analysis of both the training and inference stages, highlighting the critical
roles of initialization weight selection, fine-tuning strategies, and the
interplay between sampling steps and response repetition. The code and model
weight is released at https://github.com/LLM-VLM-GSL/LLaDA-MedV.

</details>


### [109] [Rate-distortion Optimized Point Cloud Preprocessing for Geometry-based Point Cloud Compression](https://arxiv.org/abs/2508.01633)
*Wanhao Ma,Wei Zhang,Shuai Wan,Fuzheng Yang*

Main category: cs.CV

TL;DR: 通过结合深度学习和MPEG的G-PCC标准，提出了一种预处理框架，提高了点云压缩效率（平均BD-rate降低38.84%），同时保持了互操作性和向后兼容性。


<details>
  <summary>Details</summary>
Motivation: 为了在不牺牲G-PCC互操作性或计算灵活性的前提下，提高其压缩效率，因为现有的基于深度学习的点云压缩方法虽然效率更高，但计算能力消耗也更大。

Method: 提出了一种集成压缩导向的体素化网络和可微G-PCC代理模型的预处理框架。该框架在训练阶段进行联合优化，代理模型模拟了不可微G-PCC编解码器的率失真行为，实现了端到端梯度传播。体素化网络通过学习型体素化、全局缩放、细粒度裁剪和点级编辑来适应性地转换点云，以实现率失真权衡。

Result: 通过实验证明，与G-PCC相比，该框架实现了平均38.84%的BD-rate降低。在推理阶段，仅需将轻量级的体素化网络附加到G-PCC编码器，无需修改解码器，对终端用户没有引入额外的计算开销。

Conclusion: 该研究提出了一种将深度学习与传统点云压缩标准相结合的预处理框架，通过可微代理模型优化和自适应体素化网络，在保持G-PCC互操作性和计算灵活性的同时，显著提高了压缩效率，实现了平均38.84%的BD-rate降低，为增强现有压缩标准提供了实际可行且向后兼容的解决方案。

Abstract: Geometry-based point cloud compression (G-PCC), an international standard
designed by MPEG, provides a generic framework for compressing diverse types of
point clouds while ensuring interoperability across applications and devices.
However, G-PCC underperforms compared to recent deep learning-based PCC methods
despite its lower computational power consumption. To enhance the efficiency of
G-PCC without sacrificing its interoperability or computational flexibility, we
propose a novel preprocessing framework that integrates a compression-oriented
voxelization network with a differentiable G-PCC surrogate model, jointly
optimized in the training phase. The surrogate model mimics the rate-distortion
behaviour of the non-differentiable G-PCC codec, enabling end-to-end gradient
propagation. The versatile voxelization network adaptively transforms input
point clouds using learning-based voxelization and effectively manipulates
point clouds via global scaling, fine-grained pruning, and point-level editing
for rate-distortion trade-offs. During inference, only the lightweight
voxelization network is appended to the G-PCC encoder, requiring no
modifications to the decoder, thus introducing no computational overhead for
end users. Extensive experiments demonstrate a 38.84% average BD-rate reduction
over G-PCC. By bridging classical codecs with deep learning, this work offers a
practical pathway to enhance legacy compression standards while preserving
their backward compatibility, making it ideal for real-world deployment.

</details>


### [110] [Glass Surface Segmentation with an RGB-D Camera via Weighted Feature Fusion for Service Robots](https://arxiv.org/abs/2508.01639)
*Henghong Lin,Zihan Zhu,Tao Wang,Anastasia Ioannou,Yuanshui Huang*

Main category: cs.CV

TL;DR: 提出了一种用于RGB-D相机玻璃表面分割的加权特征融合（WFF）模块和MJU-Glass数据集，实验证明该方法在提高分割精度和鲁棒性方面效果显著，特别是在处理透明、反射和遮挡等困难场景时。


<details>
  <summary>Details</summary>
Motivation: 为了解决使用RGB-D相机进行玻璃表面分割的问题，特别是如何有效融合RGB和深度信息以处理玻璃表面的透明、反射和遮挡等挑战。

Method: 提出了一种加权特征融合（WFF）模块，该模块能够动态、自适应地融合RGB和深度特征，以解决玻璃表面的透明、反射和遮挡问题，并可作为即插即用模块集成到各种深度神经网络骨干中。此外，还引入了一个名为MJU-Glass的RGB-D数据集，该数据集在真实环境中收集，可用于评估分割模型。

Result: 实验结果表明，WFF模块显著提高了分割精度和鲁棒性，在平均交并比（mIoU）和边界交并比（bIoU）方面均有提升，与PSPNet结合使用时，bIoU提升了7.49%。

Conclusion: 该研究提出的加权特征融合（WFF）模块和MJU-Glass数据集为机器人领域中的玻璃表面分割提供了鲁棒的框架，有望提高导航安全性和效率。

Abstract: We address the problem of glass surface segmentation with an RGB-D camera,
with a focus on effectively fusing RGB and depth information. To this end, we
propose a Weighted Feature Fusion (WFF) module that dynamically and adaptively
combines RGB and depth features to tackle issues such as transparency,
reflections, and occlusions. This module can be seamlessly integrated with
various deep neural network backbones as a plug-and-play solution.
Additionally, we introduce the MJU-Glass dataset, a comprehensive RGB-D dataset
collected by a service robot navigating real-world environments, providing a
valuable benchmark for evaluating segmentation models. Experimental results
show significant improvements in segmentation accuracy and robustness, with the
WFF module enhancing performance in both mean Intersection over Union (mIoU)
and boundary IoU (bIoU), achieving a 7.49% improvement in bIoU when integrated
with PSPNet. The proposed module and dataset provide a robust framework for
advancing glass surface segmentation in robotics and reducing the risk of
collisions with glass objects.

</details>


### [111] [Minimal High-Resolution Patches Are Sufficient for Whole Slide Image Representation via Cascaded Dual-Scale Reconstruction](https://arxiv.org/abs/2508.01641)
*Yujian Liu,Yuechuan Lin,Dongxu Shen,Haoran Li,Yutong Wang,Xiaoli Liu,Shidang Xu*

Main category: cs.CV

TL;DR: CDSR框架通过一种新颖的双尺度重建方法，仅使用少量高分辨率图像块即可实现WSI分析的准确性和效率提升，有效解决了现有方法中的领域差距和计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 现有全切片图像（WSI）分析方法在特征提取阶段忽视了预训练于自然图像的特征提取器带来的领域差距和次优表示问题。此外，基于自监督学习（SSL）的方法虽然能弥合领域差距，但需要将WSI分割成小图像块，这会分割组织结构并产生冗余和相互依赖的图像块，从而降低聚合器性能并增加训练成本。

Method: 提出了一种级联双尺度重建（CDSR）框架，该框架采用两阶段选择性采样策略，从基于模型和语义的角度识别信息量最大的代表性区域。然后，将这些图像块输入到局部到全局网络中，通过整合细粒度的局部细节和全局上下文信息来重建空间上连贯的高分辨率全切片图像表示。

Result: CDSR框架能够仅使用平均每张WSI的9个高分辨率图像块即可实现稳健的、跨尺度的WSI表示。

Conclusion: CDSR框架在Camelyon16、TCGA-NSCLC和TCGA-RCC数据集上进行了实验，在下游分类任务中，准确率提高了6.3%，ROC曲线下面积提高了5.5%，并且仅使用了平均7,070个高分辨率图像块（占总数的4.5%），优于使用超过10,000,000个图像块训练的最先进方法。

Abstract: Whole-slide image (WSI) analysis remains challenging due to the gigapixel
scale and sparsely distributed diagnostic regions. Multiple Instance Learning
(MIL) mitigates this by modeling the WSI as bags of patches for slide-level
prediction. However, most MIL approaches emphasize aggregator design while
overlooking the impact of the feature extractor of the feature extraction
stage, which is often pretrained on natural images. This leads to domain gap
and suboptimal representations. Self-supervised learning (SSL) has shown
promise in bridging domain gap via pretext tasks, but it still primarily builds
upon generic backbones, thus requiring WSIs to be split into small patches.
This inevitably splits histological structures and generates both redundant and
interdependent patches, which in turn degrades aggregator performance and
drastically increases training costs. To address this challenge, we propose a
Cascaded Dual-Scale Reconstruction (CDSR) framework, demonstrating that only an
average of 9 high-resolution patches per WSI are sufficient for robust
slide-level representation. CDSR employs a two-stage selective sampling
strategy that identifies the most informative representative regions from both
model-based and semantic perspectives. These patches are then fed into a
Local-to-Global Network, which reconstructs spatially coherent high-resolution
WSI representations by integrating fine-grained local detail with global
contextual information. Unlike existing dense-sampling or SSL pipelines, CDSR
is optimized for efficiency and morphological fidelity. Experiments on
Camelyon16, TCGA-NSCLC, and TCGA-RCC demonstrate that CDSR achieves
improvements of 6.3% in accuracy and 5.5% in area under ROC curve on downstream
classification tasks with only 7,070 (4.5% of total) high-resolution patches
per dataset on average, outperforming state-of-the-art methods trained on over
10,000,000 patches.

</details>


### [112] [StrandDesigner: Towards Practical Strand Generation with Sketch Guidance](https://arxiv.org/abs/2508.01650)
*Na Zhang,Moran Li,Chengming Xu,Han Feng,Xiaobin Hu,Jiangning Zhang,Weijian Cao,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 提出了一种新的基于草图的真实感发丝生成模型，解决了现有方法的局限性，通过创新的上采样和条件机制提高了精确度和用户友好性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本或图像的扩散模型在生成发型时缺乏精确度和用户友好性。因此，提出了一种新颖的、首个基于草图的生成模型，以提供更精细的控制并保持用户友好性。

Method: 本框架通过两种创新来解决关键挑战：一种可学习的3D发丝到多尺度潜在空间的上采样策略，以及一种使用具有扩散头的Transformer的多尺度自适应条件机制，以确保跨粒度的一致性。

Result: 实验表明，该方法在真实感和精确度方面优于现有方法，定性结果进一步证实了其有效性。

Conclusion: 所提出的基于草图的生成模型在真实感和精确度方面优于现有方法，实验结果和定性结果均证实了其有效性。

Abstract: Realistic hair strand generation is crucial for applications like computer
graphics and virtual reality. While diffusion models can generate hairstyles
from text or images, these inputs lack precision and user-friendliness.
Instead, we propose the first sketch-based strand generation model, which
offers finer control while remaining user-friendly. Our framework tackles key
challenges, such as modeling complex strand interactions and diverse sketch
patterns, through two main innovations: a learnable strand upsampling strategy
that encodes 3D strands into multi-scale latent spaces, and a multi-scale
adaptive conditioning mechanism using a transformer with diffusion heads to
ensure consistency across granularity levels. Experiments on several benchmark
datasets show our method outperforms existing approaches in realism and
precision. Qualitative results further confirm its effectiveness. Code will be
released at [GitHub](https://github.com/fighting-Zhang/StrandDesigner).

</details>


### [113] [DAG: Unleash the Potential of Diffusion Model for Open-Vocabulary 3D Affordance Grounding](https://arxiv.org/abs/2508.01651)
*Hanqing Wang,Zhenhao Zhang,Kaiyang Ji,Mingyu Liu,Wenti Yin,Yuchao Chen,Zhirui Liu,Xiangyu Zeng,Tianxiang Gui,Hangxing Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为DAG的框架，利用文本到图像扩散模型来解决3D物体可供性基础问题，提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在3D物体可供性基础问题上泛化能力不足的缺陷，利用文本到图像扩散模型提取通用的可供性知识。

Method: 提出了一种名为DAG的基于扩散的3D可供性基础框架，利用冻结的文本到图像扩散模型的内部表征来提取可供性知识，并引入了可供性块和多源可供性解码器来实现3D密集可供性预测。

Result: 实验结果表明，所提出的模型在3D物体可供性基础上取得了优于现有方法和开放世界泛化的性能。

Conclusion: 该模型在3D物体可供性基础上进行了改进，通过利用文本到图像扩散模型的内部表征，提取通用的可供性知识，并在3D可供性基础上取得了优于现有方法和开放世界泛化的性能。

Abstract: 3D object affordance grounding aims to predict the touchable regions on a 3d
object, which is crucial for human-object interaction, human-robot interaction,
embodied perception, and robot learning. Recent advances tackle this problem
via learning from demonstration images. However, these methods fail to capture
the general affordance knowledge within the image, leading to poor
generalization. To address this issue, we propose to use text-to-image
diffusion models to extract the general affordance knowledge because we find
that such models can generate semantically valid HOI images, which demonstrate
that their internal representation space is highly correlated with real-world
affordance concepts. Specifically, we introduce the DAG, a diffusion-based 3d
affordance grounding framework, which leverages the frozen internal
representations of the text-to-image diffusion model and unlocks affordance
knowledge within the diffusion model to perform 3D affordance grounding. We
further introduce an affordance block and a multi-source affordance decoder to
endow 3D dense affordance prediction. Extensive experimental evaluations show
that our model excels over well-established methods and exhibits open-world
generalization.

</details>


### [114] [MAP: Mitigating Hallucinations in Large Vision-Language Models with Map-Level Attention Processing](https://arxiv.org/abs/2508.01653)
*Chenxi Li,Yichen Guo,Benfang Qian,Jinhao You,Kai Tang,Yaosong Du,Zonghao Zhang,Xiande Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 MAP 的新解码方法，通过将模型的隐藏状态视为二维语义地图并利用其上的事实信息来减少大型视觉语言模型中的幻觉。该方法通过层间交叉注意力和全局-局部logit融合来提高模型的事实一致性，并在多个基准测试中取得了改进。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）虽然在多模态任务中表现出色，但仍然存在幻觉问题，即生成的内容虽然语法正确但与视觉输入不一致。

Method: 提出了一种名为地图级注意力处理（MAP）的训练免费解码方法，该方法通过基于注意力的地图级操作有效地利用事实信息来提高事实一致性。具体而言，采用层间交叉注意力（Layer-Wise Criss-Cross Attention）通过聚合类间和类内维度中的标记来逐步精炼每一解码层中的标记表示。此外，一种全局-局部logit融合机制（Global-Local Logit Fusion）结合了全局注意力和之前的logit，以进一步精炼预测并提高准确性。

Result: MAP 方法在 POPE、MME 和 MMHal-Bench 等基准测试中一致地提高了 LVLM 的真实性和性能，证明了地图级解码策略的潜力。

Conclusion: 这项工作提出了一种新颖的地图级（map-level）视角来减轻大型视觉语言模型（LVLM）中的幻觉问题，并将模型的隐藏状态解释为二维语义地图。他们发现事实信息广泛分布在此地图中，超出了大多数现有方法（如对比解码和层间一致性）的目标的局部类间或类内区域。

Abstract: Large Vision-Language Models (LVLMs) have achieved impressive performance in
multimodal tasks, but they still suffer from hallucinations, i.e., generating
content that is grammatically accurate but inconsistent with visual inputs. In
this work, we introduce a novel map-level perspective to mitigate
hallucinations in LVLMs, interpreting the hidden states of the model as a 2D
semantic map. We observe that factual information is widely distributed across
this map, extending beyond the localized inter- or intra-layer regions targeted
by most existing methods (e.g., contrastive decoding and layer-wise
consistency). Building on this insight, we propose Map-Level Attention
Processing (MAP), a training-free decoding method that effectively leverages
factual information through attention-based map-level operations to improve
factual consistency. Specifically, we employ Layer-Wise Criss-Cross Attention
to progressively refine token representations at each decoding layer by
aggregating tokens from both inter- and intra-layer dimensions. Additionally, a
Global-Local Logit Fusion mechanism combines logits obtained before and after
global attention to further refine predictions and improve accuracy. Our method
consistently improves the truthfulness and performance of LVLMs across
benchmarks, such as POPE, MME, and MMHal-Bench, demonstrating the potential of
the map-level decoding strategy.

</details>


### [115] [Single Point, Full Mask: Velocity-Guided Level Set Evolution for End-to-End Amodal Segmentation](https://arxiv.org/abs/2508.01661)
*Zhixuan Li,Yujia Liu,Chen Hui,Weisi Lin*

Main category: cs.CV

TL;DR: VELA是一种新的端到端模型，用于通过单点提示进行非模态分割。它通过显式轮廓演化来解决现有方法的局限性，并在各种基准测试中展示了优越的性能和几何可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于可见掩码或边界框等强提示，这在实际中成本高昂或不切实际。虽然像SAM这样的模型支持点提示，但它们通常进行直接掩码回归，没有明确模拟形状演化，限制了在复杂遮挡场景下的泛化能力。此外，大多数现有方法缺乏几何可解释性，并且对遮挡形状的推断方式提供有限的见解。

Method: VELA是一种端到端的、由速度驱动的水平集模型，用于非模态分割，它通过点提示显式地进行轮廓演化。VELA首先根据图像特征和点输入构建初始水平集函数，然后在形状特定的运动场指导下，通过完全可微分网络逐步演化为最终的非模态掩码。该网络学习在每个步骤生成演化动力学，从而实现几何约束和拓扑灵活的轮廓建模。

Result: VELA outperforms existing strongly prompted methods while requiring only a single-point prompt, validating the effectiveness of interpretable geometric modeling under weak guidance.

Conclusion: VELA在COCOA-cls、D2SA和KINS基准测试中表现优于现有的强提示方法，并且仅需要单点提示，验证了几何建模在弱引导下的有效性。

Abstract: Amodal segmentation aims to recover complete object shapes, including
occluded regions with no visual appearance, whereas conventional segmentation
focuses solely on visible areas. Existing methods typically rely on strong
prompts, such as visible masks or bounding boxes, which are costly or
impractical to obtain in real-world settings. While recent approaches such as
the Segment Anything Model (SAM) support point-based prompts for guidance, they
often perform direct mask regression without explicitly modeling shape
evolution, limiting generalization in complex occlusion scenarios. Moreover,
most existing methods suffer from a black-box nature, lacking geometric
interpretability and offering limited insight into how occluded shapes are
inferred. To deal with these limitations, we propose VELA, an end-to-end
VElocity-driven Level-set Amodal segmentation method that performs explicit
contour evolution from point-based prompts. VELA first constructs an initial
level set function from image features and the point input, which then
progressively evolves into the final amodal mask under the guidance of a
shape-specific motion field predicted by a fully differentiable network. This
network learns to generate evolution dynamics at each step, enabling
geometrically grounded and topologically flexible contour modeling. Extensive
experiments on COCOA-cls, D2SA, and KINS benchmarks demonstrate that VELA
outperforms existing strongly prompted methods while requiring only a
single-point prompt, validating the effectiveness of interpretable geometric
modeling under weak guidance. The code will be publicly released.

</details>


### [116] [Shape Distribution Matters: Shape-specific Mixture-of-Experts for Amodal Segmentation under Diverse Occlusions](https://arxiv.org/abs/2508.01664)
*Zhixuan Li,Yujia Liu,Chen Hui,Jeonghaeng Lee,Sanghoon Lee,Weisi Lin*

Main category: cs.CV

TL;DR: ShapeMoE is a novel amodal segmentation framework that uses shape-specific Mixture-of-Experts to better handle diverse object shapes and occlusions, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing one-size-fits-all amodal segmentation approaches struggle to capture and reason about diverse amodal shapes due to limited representation capacity. Naively applying MoE without considering the object's underlying shape distribution can lead to mismatched expert routing and insufficient expert specialization.

Method: ShapeMoE, a shape-specific sparse Mixture-of-Experts framework that learns a latent shape distribution space and dynamically routes each object to a lightweight expert tailored to its shape characteristics. It encodes each object into a compact Gaussian embedding that captures key shape characteristics, and a Shape-Aware Sparse Router maps the object to the most suitable expert. Each expert is specialized in predicting occluded regions for specific shape patterns.

Result: ShapeMoE consistently outperforms state-of-the-art methods, especially in occluded region segmentation, on COCOA-cls, KINS, and D2SA datasets.

Conclusion: ShapeMoE consistently outperforms state-of-the-art methods, especially in occluded region segmentation, and offers well interpretability.

Abstract: Amodal segmentation targets to predict complete object masks, covering both
visible and occluded regions. This task poses significant challenges due to
complex occlusions and extreme shape variation, from rigid furniture to highly
deformable clothing. Existing one-size-fits-all approaches rely on a single
model to handle all shape types, struggling to capture and reason about diverse
amodal shapes due to limited representation capacity. A natural solution is to
adopt a Mixture-of-Experts (MoE) framework, assigning experts to different
shape patterns. However, naively applying MoE without considering the object's
underlying shape distribution can lead to mismatched expert routing and
insufficient expert specialization, resulting in redundant or underutilized
experts. To deal with these issues, we introduce ShapeMoE, a shape-specific
sparse Mixture-of-Experts framework for amodal segmentation. The key idea is to
learn a latent shape distribution space and dynamically route each object to a
lightweight expert tailored to its shape characteristics. Specifically,
ShapeMoE encodes each object into a compact Gaussian embedding that captures
key shape characteristics. A Shape-Aware Sparse Router then maps the object to
the most suitable expert, enabling precise and efficient shape-aware expert
routing. Each expert is designed as lightweight and specialized in predicting
occluded regions for specific shape patterns. ShapeMoE offers well
interpretability via clear shape-to-expert correspondence, while maintaining
high capacity and efficiency. Experiments on COCOA-cls, KINS, and D2SA show
that ShapeMoE consistently outperforms state-of-the-art methods, especially in
occluded region segmentation. The code will be released.

</details>


### [117] [Rein++: Efficient Generalization and Adaptation for Semantic Segmentation with Vision Foundation Models](https://arxiv.org/abs/2508.01667)
*Zhixiang Wei,Xiaoxiao Ma,Ruishen Yan,Tao Tu,Huaian Chen,Jinjin Zheng,Yi Jin,Enhong Chen*

Main category: cs.CV

TL;DR: Rein++是一个高效的VFM语义分割框架，通过领域泛化（Rein-G）和无监督领域自适应（Rein-A）技术，解决了数据规模差异和领域偏移问题，在有限数据和多样化场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视觉基础模型（VFMs）在语义分割应用中面临的两个主要挑战：1. 数据规模差异（分割数据集通常远小于VFM预训练数据集）；2. 领域分布偏移（真实世界分割场景多样，预训练阶段表示不足）。

Method: Rein++包含两个部分：Rein-G（领域泛化）和Rein-A（领域自适应）。Rein-G通过引入可训练的、实例感知的token来优化VFM特征，仅微调少于1%的骨干参数，实现强大的泛化能力。Rein-A在实例和logit层面进行无监督领域自适应，以减轻领域偏移，并引入语义迁移模块，利用Segment Anything Model的类别无关能力增强目标域的边界细节。

Result: Rein++显著优于现有技术，实现了高效训练，证明了其作为VFM的有效、可泛化和自适应的分割解决方案，即使对于拥有数十亿参数的大型模型也同样适用。

Conclusion: Rein++框架在语义分割任务中表现出色，即使在数据量有限或存在领域分布偏移的情况下，也能实现高效、可泛化且自适应的分割。

Abstract: Vision Foundation Models(VFMs) have achieved remarkable success in various
computer vision tasks. However, their application to semantic segmentation is
hindered by two significant challenges: (1) the disparity in data scale, as
segmentation datasets are typically much smaller than those used for VFM
pre-training, and (2) domain distribution shifts, where real-world segmentation
scenarios are diverse and often underrepresented during pre-training. To
overcome these limitations, we present Rein++, an efficient VFM-based
segmentation framework that demonstrates superior generalization from limited
data and enables effective adaptation to diverse unlabeled scenarios.
Specifically, Rein++ comprises a domain generalization solution Rein-G and a
domain adaptation solution Rein-A. Rein-G introduces a set of trainable,
instance-aware tokens that effectively refine the VFM's features for the
segmentation task. This parameter-efficient approach fine-tunes less than 1% of
the backbone's parameters, enabling robust generalization. Building on the
Rein-G, Rein-A performs unsupervised domain adaptation at both the instance and
logit levels to mitigate domain shifts. In addition, it incorporates a semantic
transfer module that leverages the class-agnostic capabilities of the segment
anything model to enhance boundary details in the target domain. The integrated
Rein++ pipeline first learns a generalizable model on a source domain (e.g.,
daytime scenes) and subsequently adapts it to diverse target domains (e.g.,
nighttime scenes) without any target labels. Comprehensive experiments
demonstrate that Rein++ significantly outperforms state-of-the-art methods with
efficient training, underscoring its roles an efficient, generalizable, and
adaptive segmentation solution for VFMs, even for large models with billions of
parameters. The code is available at https://github.com/wloves/Rein.

</details>


### [118] [CSLRConformer: A Data-Centric Conformer Approach for Continuous Arabic Sign Language Recognition on the Isharah Datase](https://arxiv.org/abs/2508.01791)
*Fatimah Mohamed Emad Elden*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CSLRConformer的新架构，并结合了数据中心的方法，包括特征工程和预处理，以提高用户无关的手语识别能力。该方法在MSLR 2025工坊挑战赛中取得了第三名的成绩。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在解决通向MSLR 2025工坊挑战（ICCV 2025）的关键挑战——即在没有时间边界、手语过渡以及共同发音效应的情况下，实现模型在不同用户间的识别通用性。

Method: 提出了一种以数据为中心的方法，该方法侧重于系统的特征工程、强大的预处理流程和优化的模型架构。关键贡献包括：一个由探索性数据分析（EDA）指导的原则性特征选择过程，以分离通信关键点；一个严格的预处理流程，包括基于DBSCAN的异常值过滤和空间归一化；以及新颖的CSLRConformer架构。该架构改编了Conformer模型的混合CNN-Transformer设计，利用其对局部时间依赖性和全局序列上下文进行建模的能力，这种特性独特地适用于手语的时空动态。

Result: 所提出的方法在开发集上实现了5.60%的单词错误率（WER），在测试集上实现了12.01%的单词错误率，这一结果在官方竞赛平台上获得了第三名。

Conclusion: 该研究验证了跨域架构改编的有效性，证明了最初为语音识别而设计的Conformer模型可以成功地重新用于在基于关键点的连续手语识别中建立新的最先进性能。

Abstract: The field of Continuous Sign Language Recognition (CSLR) poses substantial
technical challenges, including fluid inter-sign transitions, the absence of
temporal boundaries, and co-articulation effects. This paper, developed for the
MSLR 2025 Workshop Challenge at ICCV 2025, addresses the critical challenge of
signer-independent recognition to advance the generalization capabilities of
CSLR systems across diverse signers. A data-centric methodology is proposed,
centered on systematic feature engineering, a robust preprocessing pipeline,
and an optimized model architecture. Key contributions include a principled
feature selection process guided by Exploratory Data Analysis (EDA) to isolate
communicative keypoints, a rigorous preprocessing pipeline incorporating
DBSCAN-based outlier filtering and spatial normalization, and the novel
CSLRConformer architecture. This architecture adapts the hybrid CNN-Transformer
design of the Conformer model, leveraging its capacity to model local temporal
dependencies and global sequence context; a characteristic uniquely suited for
the spatio-temporal dynamics of sign language. The proposed methodology
achieved a competitive performance, with a Word Error Rate (WER) of 5.60% on
the development set and 12.01% on the test set, a result that secured a 3rd
place ranking on the official competition platform. This research validates the
efficacy of cross-domain architectural adaptation, demonstrating that the
Conformer model, originally conceived for speech recognition, can be
successfully repurposed to establish a new state-of-the-art performance in
keypoint-based CSLR.

</details>


### [119] [Benchmarking Adversarial Patch Selection and Location](https://arxiv.org/abs/2508.01676)
*Shai Kimhi,Avi Mendlson,Moshe Kimhi*

Main category: cs.CV

TL;DR: PatchMap 是一个评估对抗性斑块攻击的基准测试，发现了易受攻击的区域，并提出了一种无需梯度查询的放置方法，提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现代视觉模型在对抗性斑块攻击下的可靠性问题。

Method: 提出了一种名为 PatchMap 的空间穷尽基准测试，通过在 ImageNet 验证图像上评估超过 1.5 亿次前向传播来构建。该方法利用现成的分割掩码来识别易受攻击的区域，而无需进行梯度查询。

Result: PatchMap 发现了能够引起有置信度误分类和模型置信度大幅下降的“热点”区域。所提出的放置方法相比随机或固定放置，可将攻击成功率提高 8% 到 13%。

Conclusion: PatchMap 基准测试揭示了用于对抗性斑块攻击的热点区域，并展示了一种无需梯度查询的分割引导放置方法，该方法可提高攻击成功率。

Abstract: Adversarial patch attacks threaten the reliability of modern vision models.
We present PatchMap, the first spatially exhaustive benchmark of patch
placement, built by evaluating over 1.5e8 forward passes on ImageNet validation
images. PatchMap reveals systematic hot-spots where small patches (as little as
2% of the image) induce confident misclassifications and large drops in model
confidence. To demonstrate its utility, we propose a simple segmentation guided
placement heuristic that leverages off the shelf masks to identify vulnerable
regions without any gradient queries. Across five architectures-including
adversarially trained ResNet50, our method boosts attack success rates by 8 to
13 percentage points compared to random or fixed placements. We publicly
release PatchMap and the code implementation. The full PatchMap bench (6.5B
predictions, multiple backbones) will be released soon to further accelerate
research on location-aware defenses and adaptive attacks.

</details>


### [120] [Cure or Poison? Embedding Instructions Visually Alters Hallucination in Vision-Language Models](https://arxiv.org/abs/2508.01678)
*Zhaochen Wang,Yiwei Wang,Yujun Cai*

Main category: cs.CV

TL;DR: Prompt-in-Image方法通过将文本嵌入图像来统一处理，提升了Qwen模型的性能，但降低了LLaVA和InstructBLIP模型的性能，这与它们各自视觉编码器的注意力机制有关。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉语言模型（VLMs）因多模态信息对齐挑战而产生的幻觉问题。

Method: 提出了一种将文本指令直接嵌入图像中的“Prompt-in-Image”方法，消除了对独立文本输入的需要，迫使模型通过视觉通道处理所有内容。

Result: 在Qwen2.5-VL模型上，Prompt-in-Image提高了POPE准确性4.1%，并降低了MS-COCO数据集上的幻觉率。但在LLaVA-1.5和InstructBLIP模型上，该方法导致准确性从约84%下降到接近随机水平。分析发现，LLaVA和InstructBLIP的CLIP编码器存在过度注意力偏差，而Qwen的模型则能稳健处理嵌入文本的图像。

Conclusion: Prompt-in-Image通过将文本指令嵌入图像来统一信息处理，减少了Qwen模型的跨模态鸿沟，并提高了其性能。然而，该方法对LLaVA-1.5和InstructBLIP模型产生了负面影响，导致性能急剧下降，原因是它们基于CLIP的编码器对嵌入文本区域存在过度注意力偏差。

Abstract: Vision-Language Models (VLMs) often suffer from hallucination, partly due to
challenges in aligning multimodal information. We propose Prompt-in-Image, a
simple method that embeds textual instructions directly into images. This
removes the need for separate text inputs and forces the model to process all
content through the visual channel. We evaluate this method on three popular
open-source VLMs: Qwen2.5-VL, LLaVA-1.5, and InstructBLIP. The results reveal
sharp differences. Prompt-in-Image improves Qwen2.5-VL's performance,
increasing POPE accuracy by 4.1 percent (from 80.2 percent to 84.3 percent) and
also reducing hallucination rates on MS-COCO. In contrast, LLaVA-1.5 and
InstructBLIP experience a severe performance drop, with accuracy falling from
around 84 percent to near-random levels. Through detailed analysis, we found
that CLIP-based encoders in LLaVA and InstructBLIP exhibit excessive attention
bias toward embedded text regions, disrupting visual understanding. In
contrast, Qwen's vision encoder handles text-embedded images robustly.
Crucially, Prompt-in-Image reduces Qwen's modality gap, enhancing cross-modal
alignment by unifying information processing through a single modality.

</details>


### [121] [DisCo3D: Distilling Multi-View Consistency for 3D Scene Editing](https://arxiv.org/abs/2508.01684)
*Yufeng Chi,Huimin Ma,Kafeng Wang,Jianmin Li*

Main category: cs.CV

TL;DR: DisCo3D 是一个新框架，通过将 3D 一致性先验蒸馏到 2D 编辑器中来解决 3D 编辑中的多视图一致性问题。


<details>
  <summary>Details</summary>
Motivation: 在保持多视图一致性方面，将扩散模型的能力扩展到 3D 编辑仍然是一个挑战。现有的方法要么收敛速度慢且存在模糊伪影，要么在复杂场景中存在细微的不一致和失败模式。

Method: DisCo3D 框架首先使用多视图输入对 3D 生成器进行微调以适应场景，然后通过一致性蒸馏训练 2D 编辑器。最后，通过高斯泼溅将编辑后的多视图输出优化为 3D 表示。

Result: 实验结果表明，DisCo3D 在编辑质量上优于最先进的方法。

Conclusion: DisCo3D 实现了稳定的多视图一致性，并在编辑质量上优于最先进的方法。

Abstract: While diffusion models have demonstrated remarkable progress in 2D image
generation and editing, extending these capabilities to 3D editing remains
challenging, particularly in maintaining multi-view consistency. Classical
approaches typically update 3D representations through iterative refinement
based on a single editing view. However, these methods often suffer from slow
convergence and blurry artifacts caused by cross-view inconsistencies. Recent
methods improve efficiency by propagating 2D editing attention features, yet
still exhibit fine-grained inconsistencies and failure modes in complex scenes
due to insufficient constraints. To address this, we propose \textbf{DisCo3D},
a novel framework that distills 3D consistency priors into a 2D editor. Our
method first fine-tunes a 3D generator using multi-view inputs for scene
adaptation, then trains a 2D editor through consistency distillation. The
edited multi-view outputs are finally optimized into 3D representations via
Gaussian Splatting. Experimental results show DisCo3D achieves stable
multi-view consistency and outperforms state-of-the-art methods in editing
quality.

</details>


### [122] [Register Anything: Estimating "Corresponding Prompts" for Segment Anything Model](https://arxiv.org/abs/2508.01697)
*Shiqi Huang,Tingfa Xu,Wen Yan,Dean Barratt,Yipeng Hu*

Main category: cs.CV

TL;DR: 提出了一种名为PromptReg的训练无关的图像配准方法，通过利用预训练的分割模型搜索对应提示，简化了传统上需要分割和匹配的区域配准过程，并在多个医学和非医学数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于区域的图像配准方法通常需要两个步骤：首先分割感兴趣区域（ROIs），然后匹配这些区域。这种方法在保留像素级细节的同时，也带来了区域匹配的挑战。该研究旨在简化这一过程，实现一种更直接、更有效的配准方法。

Method: PromptReg提出了一种新颖的训练无关的图像配准方法，该方法将基于区域的配准表示简化为一个步骤。它通过引入“对应提示问题”和“逆提示”解决方案来实现这一点。具体来说，它利用预训练的分割模型（如SAM）来搜索图像之间的对应提示，并将一个图像中的提示（Prompt X）反转到另一个图像的提示空间，从而识别出成对的对应区域。最后，通过在一个新的配准算法中跨提示和空间维度来边缘化反转的提示，识别出多个成对的对应区域。

Result: 在五个数据集（3D前列腺MR、3D腹部MR、3D肺CT、2D组织病理学和2D航空影像）上的综合实验表明，PromptReg的配准性能优于迭代配准算法和基于深度学习的DDF预测网络，并且在配准精度上可与需要全分割训练数据的弱监督方法相媲美。评估指标包括Dice相似系数和目标配准误差。

Conclusion: PromptReg通过直接搜索对应提示来简化基于区域的图像配准，实现了训练无关的配准方法，并在五种不同数据集的实验中取得了优于传统和基于学习的方法的结果。

Abstract: Establishing pixel/voxel-level or region-level correspondences is the core
challenge in image registration. The latter, also known as region-based
correspondence representation, leverages paired regions of interest (ROIs) to
enable regional matching while preserving fine-grained capability at
pixel/voxel level. Traditionally, this representation is implemented via two
steps: segmenting ROIs in each image then matching them between the two images.
In this paper, we simplify this into one step by directly "searching for
corresponding prompts", using extensively pre-trained segmentation models
(e.g., SAM) for a training-free registration approach, PromptReg. Firstly, we
introduce the "corresponding prompt problem", which aims to identify a
corresponding Prompt Y in Image Y for any given visual Prompt X in Image X,
such that the two respectively prompt-conditioned segmentations are a pair of
corresponding ROIs from the two images. Secondly, we present an "inverse
prompt" solution that generates primary and optionally auxiliary prompts,
inverting Prompt X into the prompt space of Image Y. Thirdly, we propose a
novel registration algorithm that identifies multiple paired corresponding ROIs
by marginalizing the inverted Prompt X across both prompt and spatial
dimensions. Comprehensive experiments are conducted on five applications of
registering 3D prostate MR, 3D abdomen MR, 3D lung CT, 2D histopathology and,
as a non-medical example, 2D aerial images. Based on metrics including Dice and
target registration errors on anatomical structures, the proposed registration
outperforms both intensity-based iterative algorithms and learning-based
DDF-predicting networks, even yielding competitive performance with
weakly-supervised approaches that require fully-segmented training data.

</details>


### [123] [Versatile Transition Generation with Image-to-Video Diffusion](https://arxiv.org/abs/2508.01698)
*Zuhao Yang,Jiahui Zhang,Yingchen Yu,Shijian Lu,Song Bai*

Main category: cs.CV

TL;DR: VTG是一个用于生成平滑、高保真、语义连贯视频过渡的框架，通过创新的初始化和微调技术解决现有扩散模型的局限性，并在TransitBench基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 生成具有平滑、合理过渡的视频，特别是在给定首尾帧和文本描述的情况下，是一个被低估的领域。

Method: VTG框架通过引入基于插值的初始化来保持对象身份并有效处理突变内容，并结合双向运动微调和表示对齐正则化来缓解预训练图像到视频扩散模型在运动平滑度和生成保真度方面的限制。

Result: VTG生成流畅、高保真、语义连贯的视频过渡，并在TransitBench基准测试中展示了优越的性能。

Conclusion: VTG在所有四个任务上始终实现卓越的转换性能。

Abstract: Leveraging text, images, structure maps, or motion trajectories as
conditional guidance, diffusion models have achieved great success in automated
and high-quality video generation. However, generating smooth and rational
transition videos given the first and last video frames as well as descriptive
text prompts is far underexplored. We present VTG, a Versatile Transition video
Generation framework that can generate smooth, high-fidelity, and semantically
coherent video transitions. VTG introduces interpolation-based initialization
that helps preserve object identity and handle abrupt content changes
effectively. In addition, it incorporates dual-directional motion fine-tuning
and representation alignment regularization to mitigate the limitations of
pre-trained image-to-video diffusion models in motion smoothness and generation
fidelity, respectively. To evaluate VTG and facilitate future studies on
unified transition generation, we collected TransitBench, a comprehensive
benchmark for transition generation covering two representative transition
tasks: concept blending and scene transition. Extensive experiments show that
VTG achieves superior transition performance consistently across all four
tasks.

</details>


### [124] [TimeExpert: An Expert-Guided Video LLM for Video Temporal Grounding](https://arxiv.org/abs/2508.01699)
*Zuhao Yang,Yingchen Yu,Yunqing Zhao,Shijian Lu,Song Bai*

Main category: cs.CV

TL;DR: TimeExpert通过为VTG任务中的时间定位、显著性评估和文本生成等子任务分配专门的专家，提高了处理效率和事件建模能力，并在多项VTG任务中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Video-LLMs在处理VTG任务时存在局限性，即所有任务token都经过相同且静态的通路，未能认识到时间定位、显著性评估和文本生成是需要专门处理的不同任务。

Method: TimeExpert是一种基于MoE（Mixture-of-Experts）的Video-LLM，它将VTG任务分解为不同的子任务（如时间定位、显著性评估和文本生成），并为每个子任务动态地路由特定的token到专门的专家进行处理。

Result: TimeExpert在密集的视频字幕、时刻检索和视频精彩集锦检测等各种VTG任务上持续实现最先进的性能。

Conclusion: TimeExpert通过动态路由特定任务的token到专门的专家，有效地分解了VTG任务，从而在密集的视频字幕、时刻检索和视频精彩集锦检测等各种VTG应用中实现了改进的事件建模和最先进的性能。

Abstract: Video Temporal Grounding (VTG) aims to precisely identify video event
segments in response to textual queries. The outputs of VTG tasks manifest as
sequences of events, each defined by precise timestamps, saliency scores, and
textual descriptions. Despite recent advances, a fundamental limitation
persists in existing Video Large Language Models (Video-LLMs): they process all
task tokens through identical and static pathways, failing to recognize that
temporal localization, saliency assessment, and textual generation represent
fundamentally distinct tasks requiring specialized processing. To address this,
we introduce TimeExpert, a Mixture-of-Experts (MoE)-based Video-LLM that
effectively decomposes VTG tasks by dynamically routing task-specific tokens
(e.g., timestamps, saliency scores) to specialized experts, with increased
computational efficiency. Our design choices enable precise handling of each
subtask, leading to improved event modeling across diverse VTG applications.
Extensive experiments demonstrate that TimeExpert consistently achieves
state-of-the-art performance on various VTG tasks such as Dense Video
Captioning, Moment Retrieval, and Video Highlight Detection.

</details>


### [125] [Subject or Style: Adaptive and Training-Free Mixture of LoRAs](https://arxiv.org/abs/2508.02165)
*Jia-Chen Zhang,Yu-Jie Xiong*

Main category: cs.CV

TL;DR: EST-LoRA 是一种新的免训练 LoRA 融合方法，通过考虑能量、风格差异和时间步来平衡主体和风格，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 LoRA 融合方法难以平衡原始主体和风格，并且通常需要额外的训练。K-LoRA 提出了一种免训练的 LoRA 融合方法，但具有多个超参数，难以适应所有风格和主体。

Method: EST-LoRA 融合了三个关键因素：矩阵能量、风格差异分数和时间步。它类似于专家混合（MoE）架构，在每个注意力层中自适应地选择主体 LoRA 和风格 LoRA，以平衡两者在生成过程中的贡献。

Result: EST-LoRA 在定性和定量评估中均优于最先进的方法，并且实现了比其他有效的融合方法更快的生成速度。

Conclusion: EST-LoRA 是一种无需训练的自适应 LoRA 融合方法，在定性和定量评估中均优于最先进的方法，并且比其他有效的融合方法具有更快的生成速度。

Abstract: Fine-tuning models via Low-Rank Adaptation (LoRA) demonstrates remarkable
performance in subject-driven or style-driven generation tasks. Studies have
explored combinations of different LoRAs to jointly generate learned styles and
content. However, current methods struggle to balance the original subject and
style, and often require additional training. Recently, K-LoRA proposed a
training-free LoRA fusion method. But it involves multiple hyperparameters,
making it difficult to adapt to all styles and subjects. In this paper, we
propose EST-LoRA, a training-free adaptive LoRA fusion method. It
comprehensively considers three critical factors: \underline{E}nergy of matrix,
\underline{S}tyle discrepancy scores and \underline{T}ime steps. Analogous to
the Mixture of Experts (MoE) architecture, the model adaptively selects between
subject LoRA and style LoRA within each attention layer. This integrated
selection mechanism ensures balanced contributions from both components during
the generation process. Experimental results show that EST-LoRA outperforms
state-of-the-art methods in both qualitative and quantitative evaluations and
achieves faster generation speed compared to other efficient fusion approaches.
Our code is publicly available at:
https://anonymous.4open.science/r/EST-LoRA-F318.

</details>


### [126] [LT-Gaussian: Long-Term Map Update Using 3D Gaussian Splatting for Autonomous Driving](https://arxiv.org/abs/2508.01704)
*Luqi Cheng,Zhangshuo Qi,Zijie Zhou,Chao Lu,Guangming Xiong*

Main category: cs.CV

TL;DR: LT-Gaussian是一种用于3D-GS地图的地图更新方法，通过多模态高斯泼溅、结构变化检测和高斯地图更新来有效处理环境变化，并生成高质量地图。


<details>
  <summary>Details</summary>
Motivation: 由于生成高斯场景涉及时间和计算成本，因此如何更新地图成为一个重大挑战。

Method: LT-Gaussian包含三个主要部分：多模态高斯泼溅、结构变化检测模块和高斯地图更新模块。首先，使用所提出的多模态高斯泼溅生成旧场景的高斯地图。随后，在地图更新过程中，将过时的高斯地图与当前的激光雷达数据流进行比较，以识别结构变化。最后，对高斯地图进行定向更新，以生成最新地图。

Result: LT-Gaussian能够有效且高效地更新高斯地图，能够处理自动驾驶场景中常见的环境变化。通过充分利用新旧场景的信息，LT-Gaussian能够生成比从头开始重建地图的地图更新策略更高质量的重建结果。

Conclusion: LT-Gaussian能够有效且高效地更新高斯地图，能够处理自动驾驶场景中常见的环境变化，并且能够生成比从头开始重建地图的地图更新策略更高质量的重建结果。

Abstract: Maps play an important role in autonomous driving systems. The recently
proposed 3D Gaussian Splatting (3D-GS) produces rendering-quality explicit
scene reconstruction results, demonstrating the potential for map construction
in autonomous driving scenarios. However, because of the time and computational
costs involved in generating Gaussian scenes, how to update the map becomes a
significant challenge. In this paper, we propose LT-Gaussian, a map update
method for 3D-GS-based maps. LT-Gaussian consists of three main components:
Multimodal Gaussian Splatting, Structural Change Detection Module, and
Gaussian-Map Update Module. Firstly, the Gaussian map of the old scene is
generated using our proposed Multimodal Gaussian Splatting. Subsequently,
during the map update process, we compare the outdated Gaussian map with the
current LiDAR data stream to identify structural changes. Finally, we perform
targeted updates to the Gaussian-map to generate an up-to-date map. We
establish a benchmark for map updating on the nuScenes dataset to
quantitatively evaluate our method. The experimental results show that
LT-Gaussian can effectively and efficiently update the Gaussian-map, handling
common environmental changes in autonomous driving scenarios. Furthermore, by
taking full advantage of information from both new and old scenes, LT-Gaussian
is able to produce higher quality reconstruction results compared to map update
strategies that reconstruct maps from scratch. Our open-source code is
available at https://github.com/ChengLuqi/LT-gaussian.

</details>


### [127] [GAID: Frame-Level Gated Audio-Visual Integration with Directional Perturbation for Text-Video Retrieval](https://arxiv.org/abs/2508.01711)
*Bowen Yang,Yun Cao,Chen He,Xiaosu Su*

Main category: cs.CV

TL;DR: GAID是一个文本到视频检索框架，通过帧级门控融合（FGF）和方向自适应语义扰动（DASP）来改进多模态表示。FGF自适应地融合音频和视觉特征，DASP增强文本嵌入的鲁棒性。该框架在多个数据集上实现了最先进的效果和效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要利用视觉线索，常常忽略互补的音频语义或采用粗糙的融合策略，导致次优的多模态表示。GAID旨在通过联合解决这一差距来改进文本到视频检索。

Method: GAID框架包含两个关键组件：(i) 帧级门控融合（FGF），在文本引导下自适应地整合音频和视觉特征，实现细粒度的时间对齐；(ii) 方向自适应语义扰动（DASP），将结构感知扰动注入文本嵌入，在不进行多通道推理的情况下增强鲁棒性和判别力。

Result: GAID框架通过FGF和DASP的协同作用，融合了模态间差距并正则化了跨模态匹配，产生了更稳定和更具表现力的表示，实现了最先进的检索效果。

Conclusion: GAID在MSR-VTT、DiDeMo、LSMDC和VATEX等数据集上展示了在所有检索指标上持续的最新效果，并带来了显著的效率提升。

Abstract: Text-to-video retrieval requires precise alignment between language and
temporally rich video signals. Existing methods predominantly exploit visual
cues and often overlook complementary audio semantics or adopt coarse fusion
strategies, leading to suboptimal multimodal representations. We present GAID,
a framework that jointly address this gap via two key components: (i) a
Frame-level Gated Fusion (FGF) that adaptively integrates audio and visual
features under textual guidance, enabling fine-grained temporal alignment; and
(ii) a Directional Adaptive Semantic Perturbation (DASP) that injects
structure-aware perturbations into text embeddings, enhancing robustness and
discrimination without incurring multi-pass inference. These modules complement
each other -- fusion reduces modality gaps while perturbation regularizes
cross-modal matching -- yielding more stable and expressive representations.
Extensive experiments on MSR-VTT, DiDeMo, LSMDC, and VATEX show consistent
state-of-the-art results across all retrieval metrics with notable efficiency
gains. Our code is available at https://github.com/YangBowenn/GAID.

</details>


### [128] [HateClipSeg: A Segment-Level Annotated Dataset for Fine-Grained Hate Video Detection](https://arxiv.org/abs/2508.01712)
*Han Wang,Zhuoran Wang,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: HateClipSeg 是一个包含 11,714 个片段的大型多模态数据集，用于检测视频中的仇恨言论，并已公开。


<details>
  <summary>Details</summary>
Motivation: 现有的视频仇恨言论检测由于多模态内容的复杂性和缺乏细粒度注释而面临挑战。

Method: 提出了一种名为HateClipSeg的大规模多模态数据集，包含视频级别和片段级别的注释，并定义了三个基准任务：修剪仇恨视频分类、时间仇恨视频定位和在线仇恨视频分类。

Result: 在提出的三个任务中，现有模型表现出 substantial gaps，表明需要更先进的方法。

Conclusion: 现有模型在处理仇恨言论检测任务方面存在显著差距，需要更复杂的多模态和时间感知方法。数据集已公开。

Abstract: Detecting hate speech in videos remains challenging due to the complexity of
multimodal content and the lack of fine-grained annotations in existing
datasets. We present HateClipSeg, a large-scale multimodal dataset with both
video-level and segment-level annotations, comprising over 11,714 segments
labeled as Normal or across five Offensive categories: Hateful, Insulting,
Sexual, Violence, Self-Harm, along with explicit target victim labels. Our
three-stage annotation process yields high inter-annotator agreement
(Krippendorff's alpha = 0.817). We propose three tasks to benchmark
performance: (1) Trimmed Hateful Video Classification, (2) Temporal Hateful
Video Localization, and (3) Online Hateful Video Classification. Results
highlight substantial gaps in current models, emphasizing the need for more
sophisticated multimodal and temporally aware approaches. The HateClipSeg
dataset are publicly available at
https://github.com/Social-AI-Studio/HateClipSeg.git.

</details>


### [129] [Granular Concept Circuits: Toward a Fine-Grained Circuit Discovery for Concept Representations](https://arxiv.org/abs/2508.01728)
*Dahee Kwon,Sehyun Lee,Jaesik Choi*

Main category: cs.CV

TL;DR: GCC是一种新的电路发现方法，用于解释深度视觉模型，通过识别与特定视觉概念相关的电路，实现了细粒度的模型理解。


<details>
  <summary>Details</summary>
Motivation: 深度视觉模型具有分层架构，但由于表示是分布式的，因此在模型中精确定位特定视觉概念的编码仍然是一个关键但具有挑战性的任务。

Method: GCC方法通过迭代评估神经元连接，结合功能依赖性和语义对齐性，来构建代表查询相关概念的电路。

Result: GCC方法能够自动发现多个捕获特定概念的电路，从而提供了一种深刻的、按概念进行的模型解释，并且首次在细粒度层面识别了与特定视觉概念相关的电路。研究结果表明GCC方法在多种深度图像分类模型上具有通用性和有效性。

Conclusion: 该研究提出了一种名为Granular Concept Circuit (GCC) 的有效电路发现方法，用于解释深度视觉模型。GCC方法通过迭代评估神经元连接，结合功能依赖性和语义对齐性，来构建代表查询相关概念的电路。该方法能够自动发现多个捕获特定概念的电路，从而提供了一种深刻的、按概念进行的模型解释，并且首次在细粒度层面识别了与特定视觉概念相关的电路。研究结果表明GCC方法在多种深度图像分类模型上具有通用性和有效性。

Abstract: Deep vision models have achieved remarkable classification performance by
leveraging a hierarchical architecture in which human-interpretable concepts
emerge through the composition of individual neurons across layers. Given the
distributed nature of representations, pinpointing where specific visual
concepts are encoded within a model remains a crucial yet challenging task. In
this paper, we introduce an effective circuit discovery method, called Granular
Concept Circuit (GCC), in which each circuit represents a concept relevant to a
given query. To construct each circuit, our method iteratively assesses
inter-neuron connectivity, focusing on both functional dependencies and
semantic alignment. By automatically discovering multiple circuits, each
capturing specific concepts within that query, our approach offers a profound,
concept-wise interpretation of models and is the first to identify circuits
tied to specific visual concepts at a fine-grained level. We validate the
versatility and effectiveness of GCCs across various deep image classification
models.

</details>


### [130] [Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens](https://arxiv.org/abs/2508.02419)
*Haohan Zheng,Zhenguo Zhang*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）存在“模态偏见”问题，即难以同时关注视觉和文本信息。本文提出一种无需训练的方法，通过调整注意力权重和使用对比解码策略来缓解此问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）存在严重的目标幻觉问题。以往研究认为这归因于视觉编码器和大型语言模型（LLMs）之间的尺度不匹配导致语言先验过强。然而，通过深入研究，我们发现LVLMs在幻觉时可能同时忽略视觉和文本信息，即“模态偏见”，这表明LVLMs难以同时关注视觉和文本模态，导致对用户指令的理解不完整。

Method: 提出了一种无需训练的方法，通过干预和调整文本和视觉标记的注意力权重，平衡跨模态兼容性，并结合对比解码策略来减少模型对其参数知识的过度依赖。

Result: 实验证实了模态偏见在LVLMs中的普遍存在，并表明所提出的方法能有效缓解幻觉问题。

Conclusion: 该方法有效缓解了大型视觉语言模型的目标幻觉问题，并在多个模型和基准上展示了良好的泛化性和有效性。

Abstract: Large vision-language models (LVLMs) have demonstrated remarkable multimodal
comprehension and reasoning capabilities, but they still suffer from severe
object hallucination. Previous studies primarily attribute the flaw to
linguistic prior caused by the scale mismatch between visual encoders and large
language models (LLMs) in LVLMs. Specifically, as current LVLMs are built upon
LLMs, they tend to over-rely on textual prompts and internal knowledge of LLMs,
generating descriptions inconsistent with visual cues. However, through an
in-depth investigation of the hallucinated mechanisms, we empirically reveal a
previously overlooked phenomenon: LVLMs may ignore not only visual information
but also textual modality during hallucination, a behavior termed as modality
bias, which indicates that LVLMs struggle to simultaneously attend to both
visual and textual modalities, leading to fragmented understanding of
user-provided instructions. Based on this observation, we propose a simple yet
effective training-free method to mitigate object hallucination. Concretely, we
intervene and adjust the attention weights of textual and visual tokens,
balancing cross-modal compatibility for better alignment with user intentions.
Furthermore, we adopt a contrastive decoding strategy to reduce the LVLM's
overreliance on its parametric knowledge, synergistically enhancing our
attention manipulation. Extensive experiments confirm the widespread presence
of modality bias in LVLMs. Notably, our method effectively mitigates
hallucination across multiple open-source LVLMs and benchmarks, highlighting
its generalizability and efficacy.

</details>


### [131] [Tracking the Unstable: Appearance-Guided Motion Modeling for Robust Multi-Object Tracking in UAV-Captured Videos](https://arxiv.org/abs/2508.01730)
*Jianbo Ma,Hui Luo,Qi Chen,Yuankai Qi,Yumei Sun,Amin Beheshti,Jianlin Zhang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: AMOT improves multi-object tracking in UAV videos by jointly using appearance and motion cues with an AMC matrix and MTC module to handle viewpoint changes and complex motion, outperforming existing methods without retraining.


<details>
  <summary>Details</summary>
Motivation: Frequent viewpoint changes and complex UAV-ground relative motion dynamics in UAV videos lead to unstable affinity measurement and ambiguous association. Existing methods model motion and appearance cues separately, overlooking their spatio-temporal interplay.

Method: AMOT jointly exploits appearance and motion cues through an Appearance-Motion Consistency (AMC) matrix and a Motion-aware Track Continuation (MTC) module. The AMC matrix computes bi-directional spatial consistency under the guidance of appearance features. The MTC module reactivates unmatched tracks through appearance-guided predictions that align with Kalman-based predictions.

Result: Extensive experiments on VisDrone2019, UAVDT, and VT-MOT-UAV benchmarks demonstrate the effectiveness of AMOT.

Conclusion: AMOT outperforms current state-of-the-art methods and generalizes well in a plug-and-play and training-free manner on UAV benchmarks.

Abstract: Multi-object tracking (MOT) aims to track multiple objects while maintaining
consistent identities across frames of a given video. In unmanned aerial
vehicle (UAV) recorded videos, frequent viewpoint changes and complex
UAV-ground relative motion dynamics pose significant challenges, which often
lead to unstable affinity measurement and ambiguous association. Existing
methods typically model motion and appearance cues separately, overlooking
their spatio-temporal interplay and resulting in suboptimal tracking
performance. In this work, we propose AMOT, which jointly exploits appearance
and motion cues through two key components: an Appearance-Motion Consistency
(AMC) matrix and a Motion-aware Track Continuation (MTC) module. Specifically,
the AMC matrix computes bi-directional spatial consistency under the guidance
of appearance features, enabling more reliable and context-aware identity
association. The MTC module complements AMC by reactivating unmatched tracks
through appearance-guided predictions that align with Kalman-based predictions,
thereby reducing broken trajectories caused by missed detections. Extensive
experiments on three UAV benchmarks, including VisDrone2019, UAVDT, and
VT-MOT-UAV, demonstrate that our AMOT outperforms current state-of-the-art
methods and generalizes well in a plug-and-play and training-free manner.

</details>


### [132] [SpectralX: Parameter-efficient Domain Generalization for Spectral Remote Sensing Foundation Models](https://arxiv.org/abs/2508.01731)
*Yuxiang Zhang,Wei Li,Mengmeng Zhang,Jiawei Han,Ran Tao,Shunlin Liang*

Main category: cs.CV

TL;DR: SpectralX框架通过参数高效微调，成功解决了现有遥感基础模型在处理多光谱/高光谱数据上的挑战，提高了模型在不同领域数据的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感基础模型多基于光学影像预训练，而多光谱/高光谱数据缺乏相应的 tulang 基础模型。为了利用高光谱影像的优势，研究旨在探索如何有效适配现有遥感基础模型以处理不同光谱模态的数据，而无需进行大规模光谱预训练。

Method: 提出了一种名为SpectralX的参数高效微调框架，该框架包含一个两阶段训练方法。第一阶段，使用掩码重建任务，设计了Hyper Tokenizer（HyperT）来提取空间和光谱属性，并开发了Attribute-oriented Mixture of Adapter（AoMoA）进行层级微调。第二阶段，以语义分割为下游任务，引入Attribute-refined Adapter（Are-adapter），通过迭代查询不同层级的特征，使模型关注任务相关的属性。

Result: SpectralX能够有效适配现有遥感基础模型处理各种光谱输入，提高了模型的领域泛化性能，并实现了针对特定任务（如下游的语义分割）的定制化调整，使模型能够理解来自新区域或新季节的光谱影像。

Conclusion: SpectralX成功实现了对现有遥感基础模型在处理多光谱/高光谱数据方面的有效适应，显著提升了模型在不同领域泛化能力，并且能够针对特定任务进行定制化调整。

Abstract: Recent advances in Remote Sensing Foundation Models (RSFMs) have led to
significant breakthroughs in the field. While many RSFMs have been pretrained
with massive optical imagery, more multispectral/hyperspectral data remain lack
of the corresponding foundation models. To leverage the advantages of spectral
imagery in earth observation, we explore whether existing RSFMs can be
effectively adapted to process diverse spectral modalities without requiring
extensive spectral pretraining. In response to this challenge, we proposed
SpectralX, an innovative parameter-efficient fine-tuning framework that adapt
existing RSFMs as backbone while introducing a two-stage training approach to
handle various spectral inputs, thereby significantly improving domain
generalization performance. In the first stage, we employ a
masked-reconstruction task and design a specialized Hyper Tokenizer (HyperT) to
extract attribute tokens from both spatial and spectral dimensions.
Simultaneously, we develop an Attribute-oriented Mixture of Adapter (AoMoA)
that dynamically aggregates multi-attribute expert knowledge while performing
layer-wise fine-tuning. With semantic segmentation as downstream task in the
second stage, we insert an Attribute-refined Adapter (Are-adapter) into the
first stage framework. By iteratively querying low-level semantic features with
high-level representations, the model learns to focus on task-beneficial
attributes, enabling customized adjustment of RSFMs. Following this two-phase
adaptation process, SpectralX is capable of interpreting spectral imagery from
new regions or seasons. The codes will be available from the website:
https://github.com/YuxiangZhang-BIT.

</details>


### [133] [AG$^2$aussian: Anchor-Graph Structured Gaussian Splatting for Instance-Level 3D Scene Understanding and Editing](https://arxiv.org/abs/2508.01740)
*Zhaonan Wang,Manyi Li,Changhe Tu*

Main category: cs.CV

TL;DR: AG$^2$aussian通过锚点-图结构改进了3D高斯表示的语义感知能力，实现了更精确的实例选择和编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在语义感知3D高斯表示中存在噪声分割和高斯选择混乱的问题，因此需要一种新的框架来改进。

Method: AG$^2$aussian框架利用锚点-图结构来组织语义特征和规范化高斯图元，并通过基于图的传播实现实例级高斯选择。

Result: AG$^2$aussian在交互式点击查询、开放词汇文本驱动查询、对象移除编辑和物理模拟等应用中表现出优势，并能实现清晰、准确的实例级高斯选择。

Conclusion: AG$^2$aussian通过利用锚点-图结构来组织语义特征和规范化高斯图元，解决了现有方法在语义感知3D高斯表示中存在的噪声分割和高斯选择混乱的问题。该方法实现了紧凑、实例感知的高斯分布，并通过基于图的传播实现了清晰、准确的实例级高斯选择。在交互式点击查询、开放词汇文本驱动查询、对象移除编辑和物理模拟等四个应用中的广泛验证证明了该方法的优势及其在各种应用中的好处。

Abstract: 3D Gaussian Splatting (3DGS) has witnessed exponential adoption across
diverse applications, driving a critical need for semantic-aware 3D Gaussian
representations to enable scene understanding and editing tasks. Existing
approaches typically attach semantic features to a collection of free Gaussians
and distill the features via differentiable rendering, leading to noisy
segmentation and a messy selection of Gaussians. In this paper, we introduce
AG$^2$aussian, a novel framework that leverages an anchor-graph structure to
organize semantic features and regulate Gaussian primitives. Our anchor-graph
structure not only promotes compact and instance-aware Gaussian distributions,
but also facilitates graph-based propagation, achieving a clean and accurate
instance-level Gaussian selection. Extensive validation across four
applications, i.e. interactive click-based query, open-vocabulary text-driven
query, object removal editing, and physics simulation, demonstrates the
advantages of our approach and its benefits to various applications. The
experiments and ablation studies further evaluate the effectiveness of the key
designs of our approach.

</details>


### [134] [Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models](https://arxiv.org/abs/2508.01741)
*Ruofan Wang,Xin Wang,Yang Yao,Xuan Tong,Xingjun Ma*

Main category: cs.CV

TL;DR: Open-source VLMs retain vulnerabilities after fine-tuning, allowing transferable jailbreaks. A new method, SEA, uses simulated fine-tuning and targeted prompts to exploit these inherited weaknesses, showing high success rates and highlighting the need for better security in fine-tuned VLMs.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore and demonstrate the security risks associated with fine-tuning open-source Vision-Language Models (VLMs), specifically the retention of base VLM vulnerabilities that can be exploited through transferable jailbreak attacks.

Method: The paper introduces the Simulated Ensemble Attack (SEA), a grey-box jailbreak method. SEA utilizes Fine-tuning Trajectory Simulation (FTS) to generate transferable adversarial images by simulating vision encoder parameter shifts, and Targeted Prompt Guidance (TPG), a textual strategy to guide the language decoder towards adversarial outputs.

Result: SEA achieves high transfer attack success rates (exceeding 86.5%) and toxicity rates (near 49.5%) across diverse fine-tuned variants of the Qwen2-VL family. It demonstrates significantly enhanced transferability compared to direct PGD-based image jailbreaks, effectively exploiting inherited vulnerabilities from the base model.

Conclusion: Fine-tuning open-source VLMs retains vulnerabilities from base models, making them susceptible to transferable jailbreak attacks. The SEA method, combining FTS and TPG, effectively exploits these inherited vulnerabilities, achieving high attack success rates across diverse fine-tuned variants. This highlights the need for robust defenses throughout the VLM lifecycle.

Abstract: Fine-tuning open-source Vision-Language Models (VLMs) creates a critical yet
underexplored attack surface: vulnerabilities in the base VLM could be retained
in fine-tuned variants, rendering them susceptible to transferable jailbreak
attacks. To demonstrate this risk, we introduce the Simulated Ensemble Attack
(SEA), a novel grey-box jailbreak method in which the adversary has full access
to the base VLM but no knowledge of the fine-tuned target's weights or training
configuration. To improve jailbreak transferability across fine-tuned VLMs, SEA
combines two key techniques: Fine-tuning Trajectory Simulation (FTS) and
Targeted Prompt Guidance (TPG). FTS generates transferable adversarial images
by simulating the vision encoder's parameter shifts, while TPG is a textual
strategy that steers the language decoder toward adversarially optimized
outputs. Experiments on the Qwen2-VL family (2B and 7B) demonstrate that SEA
achieves high transfer attack success rates exceeding 86.5% and toxicity rates
near 49.5% across diverse fine-tuned variants, even those specifically
fine-tuned to improve safety behaviors. Notably, while direct PGD-based image
jailbreaks rarely transfer across fine-tuned VLMs, SEA reliably exploits
inherited vulnerabilities from the base model, significantly enhancing
transferability. These findings highlight an urgent need to safeguard
fine-tuned proprietary VLMs against transferable vulnerabilities inherited from
open-source foundations, motivating the development of holistic defenses across
the entire model lifecycle.

</details>


### [135] [Intention-Guided Cognitive Reasoning for Egocentric Long-Term Action Anticipation](https://arxiv.org/abs/2508.01742)
*Qiaohui Chu,Haoyu Zhang,Meng Liu,Yisen Feng,Haoxiang Shi,Liqiang Nie*

Main category: cs.CV

TL;DR: INSIGHT是一个用于从单眼视频进行长期动作预测的框架，通过关注手部-物体交互和引入基于强化学习的认知推理模块来解决现有方法的局限性，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在细粒度视觉线索利用、动词-名词语义依赖性以及显式认知推理方面的局限性，从而提高长期预测能力。

Method: INSIGHT是一个统一的两阶段框架。第一阶段，提取手部-物体交互区域的语义特征，并使用动词-名词共现矩阵增强动作表征。第二阶段，引入基于强化学习的模块，通过视觉感知（思考）->意图推理（推理）->动作预期（回答）的结构化过程来模拟显式的认知推理。

Result: INSIGHT实现了最先进的性能，并展示了其强大的泛化能力。

Conclusion: INSIGHT在Ego4D、EPIC-Kitchens-55和EGTEA Gaze+基准测试中取得了最先进的性能，证明了其有效性和强大的泛化能力。

Abstract: Long-term action anticipation from egocentric video is critical for
applications such as human-computer interaction and assistive technologies,
where anticipating user intent enables proactive and context-aware AI
assistance. However, existing approaches suffer from three key limitations: 1)
underutilization of fine-grained visual cues from hand-object interactions, 2)
neglect of semantic dependencies between verbs and nouns, and 3) lack of
explicit cognitive reasoning, limiting generalization and long-term forecasting
ability. To overcome these challenges, we propose INSIGHT, a unified two-stage
framework for egocentric action anticipation. In the first stage, INSIGHT
focuses on extracting semantically rich features from hand-object interaction
regions and enhances action representations using a verb-noun co-occurrence
matrix. In the second stage, it introduces a reinforcement learning-based
module that simulates explicit cognitive reasoning through a structured
process: visual perception (think) -> intention inference (reason) -> action
anticipation (answer). Extensive experiments on Ego4D, EPIC-Kitchens-55, and
EGTEA Gaze+ benchmarks show that INSIGHT achieves state-of-the-art performance,
demonstrating its effectiveness and strong generalization capability.

</details>


### [136] [Improving Noise Efficiency in Privacy-preserving Dataset Distillation](https://arxiv.org/abs/2508.01749)
*Runkai Zheng,Vishnu Asutosh Dasu,Yinong Oliver Wang,Haohan Wang,Fernando De la Torre*

Main category: cs.CV

TL;DR: 提出了一种改进差分隐私数据集蒸馏的新框架，通过解耦采样与优化和在信息子空间匹配来减少噪声，在 CIFAR-10 上取得了显著的性能提升，同时减少了所需数据量。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有差分隐私数据集蒸馏方法在同步采样-优化过程和依赖随机初始化的网络产生的噪声训练信号方面存在的效率低下问题，导致隐私信息利用不足和噪声过多的情况，本研究旨在通过改进方法来提高隐私保护数据集蒸馏的性能。

Method: 该研究提出了一种新颖的框架，将差分隐私（DP）与数据集蒸馏（DD）相结合。该框架的关键在于将采样过程与优化过程解耦，以获得更好的收敛性，并通过在信息子空间中进行匹配来减少差分隐私噪声对训练信号的影响，从而提高信号质量。

Result: 在 CIFAR-10 数据集上，该方法在每类 50 张图像的情况下，相较于先前最先进的方法，性能提升了 10.0%；在仅使用五分之一的蒸馏数据集大小时，性能提升了 8.3%。

Conclusion: 所提出的新框架通过解耦采样和优化以及在信息子空间中进行匹配来提高 DP-DD 的效率和信号质量，在 CIFAR-10 数据集上取得了显著的性能提升。

Abstract: Modern machine learning models heavily rely on large datasets that often
include sensitive and private information, raising serious privacy concerns.
Differentially private (DP) data generation offers a solution by creating
synthetic datasets that limit the leakage of private information within a
predefined privacy budget; however, it requires a substantial amount of data to
achieve performance comparable to models trained on the original data. To
mitigate the significant expense incurred with synthetic data generation,
Dataset Distillation (DD) stands out for its remarkable training and storage
efficiency. This efficiency is particularly advantageous when integrated with
DP mechanisms, curating compact yet informative synthetic datasets without
compromising privacy. However, current state-of-the-art private DD methods
suffer from a synchronized sampling-optimization process and the dependency on
noisy training signals from randomly initialized networks. This results in the
inefficient utilization of private information due to the addition of excessive
noise. To address these issues, we introduce a novel framework that decouples
sampling from optimization for better convergence and improves signal quality
by mitigating the impact of DP noise through matching in an informative
subspace. On CIFAR-10, our method achieves a \textbf{10.0\%} improvement with
50 images per class and \textbf{8.3\%} increase with just \textbf{one-fifth}
the distilled set size of previous state-of-the-art methods, demonstrating
significant potential to advance privacy-preserving DD.

</details>


### [137] [Vision transformer-based multi-camera multi-object tracking framework for dairy cow monitoring](https://arxiv.org/abs/2508.01752)
*Kumail Abbas,Zeeshan Afzal,Aqeel Raza,Taha Mansouri,Andrew W. Dowsey,Chaidate Inchaisri,Ali Alameer*

Main category: cs.CV

TL;DR: 开发了一个多摄像头实时奶牛追踪系统，使用先进的计算机视觉技术，准确率和连续性高，可改善疾病预测。


<details>
  <summary>Details</summary>
Motivation: 手动观察和频繁评估在活动监测方面劳动量大且不一致，而活动和行为与奶牛健康、福利相关，因此持续准确的监测对于疾病识别和农场生产力至关重要。

Method: 开发了一个独特的多摄像头、实时追踪系统，利用实例分割和追踪算法。通过同态变换对六个摄像头进行几何对齐，创建了一个集成化的顶视图谷仓全景图。检测阶段使用了改进的YOLOv11-m模型，分割阶段使用了SAMURAI（升级版分割任何模型2.1），并采用运动感知线性卡尔曼滤波器和基于IoU的数据关联进行目标追踪。

Result: 该系统在两个基准视频序列中，多目标追踪准确率（MOTA）分别为98.7%和99.3%，IDF1得分超过99%，身份切换接近于零，显著优于Deep SORT Realtime。

Conclusion: 该多摄像头系统能实时追踪复杂的室内环境中的奶牛，提高了追踪的准确性和连续性，旨在通过量化活动和行为分类来改善疾病的早期预测。

Abstract: Activity and behaviour correlate with dairy cow health and welfare, making
continual and accurate monitoring crucial for disease identification and farm
productivity. Manual observation and frequent assessments are laborious and
inconsistent for activity monitoring. In this study, we developed a unique
multi-camera, real-time tracking system for indoor-housed Holstein Friesian
dairy cows. This technology uses cutting-edge computer vision techniques,
including instance segmentation and tracking algorithms to monitor cow activity
seamlessly and accurately. An integrated top-down barn panorama was created by
geometrically aligning six camera feeds using homographic transformations. The
detection phase used a refined YOLO11-m model trained on an overhead cow
dataset, obtaining high accuracy (mAP\@0.50 = 0.97, F1 = 0.95). SAMURAI, an
upgraded Segment Anything Model 2.1, generated pixel-precise cow masks for
instance segmentation utilizing zero-shot learning and motion-aware memory.
Even with occlusion and fluctuating posture, a motion-aware Linear Kalman
filter and IoU-based data association reliably identified cows over time for
object tracking. The proposed system significantly outperformed Deep SORT
Realtime. Multi-Object Tracking Accuracy (MOTA) was 98.7% and 99.3% in two
benchmark video sequences, with IDF1 scores above 99% and near-zero identity
switches. This unified multi-camera system can track dairy cows in complex
interior surroundings in real time, according to our data. The system reduces
redundant detections across overlapping cameras, maintains continuity as cows
move between viewpoints, with the aim of improving early sickness prediction
through activity quantification and behavioural classification.

</details>


### [138] [VPN: Visual Prompt Navigation](https://arxiv.org/abs/2508.01766)
*Shuo Feng,Zihan Wang,Yuchen Li,Rui Kong,Hengyi Cai,Shuaiqiang Wang,Gim Hee Lee,Piji Li,Shuqiang Jiang*

Main category: cs.CV

TL;DR: Agents navigate complex environments using visual prompts on maps instead of language, improving clarity and usability. New datasets and a baseline network with data augmentation achieve better performance.


<details>
  <summary>Details</summary>
Motivation: To overcome the ambiguity and verbosity of language-based navigation for embodied agents, especially in complex environments, by using intuitive, spatially grounded visual prompts.

Method: The paper proposes Visual Prompt Navigation (VPN), a method guiding agents using visual trajectory prompts on 2D top-view maps. It introduces two new datasets (R2R-VP and R2R-CE-VP) and a baseline network (VPNet) with view-level and trajectory-level data augmentation strategies.

Result: Experiments show that the visual prompt forms, top-view map formats, and data augmentation strategies significantly impact the performance of visual prompt navigation, suggesting the effectiveness of the proposed VPN.

Conclusion: The proposed Visual Prompt Navigation (VPN) paradigm, which uses visual prompts instead of language for agent navigation in top-down maps, is effective. The new datasets R2R-VP and R2R-CE-VP and the VPNet baseline with data augmentation strategies demonstrate improved navigation performance.

Abstract: While natural language is commonly used to guide embodied agents, the
inherent ambiguity and verbosity of language often hinder the effectiveness of
language-guided navigation in complex environments. To this end, we propose
Visual Prompt Navigation (VPN), a novel paradigm that guides agents to navigate
using only user-provided visual prompts within 2D top-view maps. This visual
prompt primarily focuses on marking the visual navigation trajectory on a
top-down view of a scene, offering intuitive and spatially grounded guidance
without relying on language instructions. It is more friendly for non-expert
users and reduces interpretive ambiguity. We build VPN tasks in both discrete
and continuous navigation settings, constructing two new datasets, R2R-VP and
R2R-CE-VP, by extending existing R2R and R2R-CE episodes with corresponding
visual prompts. Furthermore, we introduce VPNet, a dedicated baseline network
to handle the VPN tasks, with two data augmentation strategies: view-level
augmentation (altering initial headings and prompt orientations) and
trajectory-level augmentation (incorporating diverse trajectories from
large-scale 3D scenes), to enhance navigation performance. Extensive
experiments evaluate how visual prompt forms, top-view map formats, and data
augmentation strategies affect the performance of visual prompt navigation. The
code is available at https://github.com/farlit/VPN.

</details>


### [139] [Skip priors and add graph-based anatomical information, for point-based Couinaud segmentation](https://arxiv.org/abs/2508.01785)
*Xiaotong Zhang,Alexander Broersen,Gonnie CM van Erp,Silvia L. Pintea,Jouke Dijkstra*

Main category: cs.CV

TL;DR: 提出了一种新的基于点的Couinaud分割方法，无需预先了解肝脏血管结构，并通过图推理模块学习隐式解剖学信息，在公共数据集上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 使用基于点的表示而不是体素化CT体积，可以在保留CT物理分辨率的同时，为肝脏手术的术前规划提供Couinaud分割，以降低出血风险并指导切除术。

Method: 提出了一种基于点的Couinaud分割方法，无需显式提供先验肝脏血管结构。为了让模型学习这种解剖学肝脏血管结构，我们在点特征之上添加了一个图推理模块，通过学习点邻域之间的亲和力来为模型添加隐式解剖学信息。

Result: 我们的方法在MSD和LiTS公共数据集上，在Dice系数和平均表面距离评分方面，与四个开创性的基于点的​​方法相比具有竞争力。

Conclusion: 所提出的方法在MSD和LiTS公共数据集上，在Dice系数和平均表面距离评分方面，与四个开创性的基于点的方​​法相比具有竞争力。

Abstract: The preoperative planning of liver surgery relies on Couinaud segmentation
from computed tomography (CT) images, to reduce the risk of bleeding and guide
the resection procedure. Using 3D point-based representations, rather than
voxelizing the CT volume, has the benefit of preserving the physical resolution
of the CT. However, point-based representations need prior knowledge of the
liver vessel structure, which is time consuming to acquire. Here, we propose a
point-based method for Couinaud segmentation, without explicitly providing the
prior liver vessel structure. To allow the model to learn this anatomical liver
vessel structure, we add a graph reasoning module on top of the point features.
This adds implicit anatomical information to the model, by learning affinities
across point neighborhoods. Our method is competitive on the MSD and LiTS
public datasets in Dice coefficient and average surface distance scores
compared to four pioneering point-based methods. Our code is available at
https://github.com/ZhangXiaotong015/GrPn.

</details>


### [140] [SoccerTrack v2: A Full-Pitch Multi-View Soccer Dataset for Game State Reconstruction](https://arxiv.org/abs/2508.01802)
*Atom Scott,Ikuma Uchida,Kento Kuroda,Yufi Kim,Keisuke Fujii*

Main category: cs.CV

TL;DR: SoccerTrack v2是一个新的足球数据集，包含10个4K全景视频，提供多目标跟踪、比赛状态重建和球动作识别的详细注释，旨在推动足球分析领域的研究和应用。


<details>
  <summary>Details</summary>
Motivation: 为了在足球分析领域推进多目标跟踪、比赛状态重建和球动作识别的研究，SoccerTrack v2数据集被创建，以克服现有数据集在视图和场景限制方面的不足。

Method: SoccerTrack v2数据集包含了10个完整、全景4K的大学级别足球比赛录像，使用了BePro相机捕捉，确保了完整的球员可见性。数据集中包含了逐帧的比赛状态标签（2D场地坐标、基于号码的球员ID、角色、队伍）以及12种球动作类别的标签（例如传球、带球、射门）。

Result: SoccerTrack v2提供了详尽的注释，包括2D场地坐标、球员ID、角色、队伍信息以及12种球动作类别，为足球分析研究提供了高质量的数据支持。

Conclusion: SoccerTrack v2数据集的发布将推动多目标跟踪、比赛状态重建和球动作识别在足球分析领域的研究，并为战术分析和自动化工具提供新的基准和实际应用。

Abstract: SoccerTrack v2 is a new public dataset for advancing multi-object tracking
(MOT), game state reconstruction (GSR), and ball action spotting (BAS) in
soccer analytics. Unlike prior datasets that use broadcast views or limited
scenarios, SoccerTrack v2 provides 10 full-length, panoramic 4K recordings of
university-level matches, captured with BePro cameras for complete player
visibility. Each video is annotated with GSR labels (2D pitch coordinates,
jersey-based player IDs, roles, teams) and BAS labels for 12 action classes
(e.g., Pass, Drive, Shot). This technical report outlines the datasets
structure, collection pipeline, and annotation process. SoccerTrack v2 is
designed to advance research in computer vision and soccer analytics, enabling
new benchmarks and practical applications in tactical analysis and automated
tools.

</details>


### [141] [Diffusion-based 3D Hand Motion Recovery with Intuitive Physics](https://arxiv.org/abs/2508.01835)
*Yufei Zhang,Zijun Cui,Jeffrey O. Kephart,Qiang Ji*

Main category: cs.CV

TL;DR: 提出了一种新颖的3D手部运动恢复框架，该框架通过基于扩散和物理增强的运动精炼模型来改进基于图像的重建。该模型仅使用运动捕捉数据进行训练，并通过整合直观的物理知识（包括关键运动状态和相关运动约束）来提高性能。实验证明，该方法显著提高了现有方法的性能，并在现有基准上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 尽管从单眼图像进行3D手部重建取得了进展，但从视频中生成准确且时间上连贯的运动估计仍然具有挑战性，特别是在手-物体交互期间。

Method: 提出了一种新颖的基于扩散和物理增强的运动精炼模型，用于从视频中恢复运动，通过迭代去噪过程生成改进的序列，并仅使用运动捕捉数据进行训练。

Result: 该模型通过迭代去噪过程捕获了基于初始运动估计的精炼运动估计的分布，从而生成了改进的序列。

Conclusion: 该框架在现有基准上实现了最先进的性能，并显著提高了各种基于帧的重建方法的性能。

Abstract: While 3D hand reconstruction from monocular images has made significant
progress, generating accurate and temporally coherent motion estimates from
videos remains challenging, particularly during hand-object interactions. In
this paper, we present a novel 3D hand motion recovery framework that enhances
image-based reconstructions through a diffusion-based and physics-augmented
motion refinement model. Our model captures the distribution of refined motion
estimates conditioned on initial ones, generating improved sequences through an
iterative denoising process. Instead of relying on scarce annotated video data,
we train our model only using motion capture data without images. We identify
valuable intuitive physics knowledge during hand-object interactions, including
key motion states and their associated motion constraints. We effectively
integrate these physical insights into our diffusion model to improve its
performance. Extensive experiments demonstrate that our approach significantly
improves various frame-wise reconstruction methods, achieving state-of-the-art
(SOTA) performance on existing benchmarks.

</details>


### [142] [OmniEvent: Unified Event Representation Learning](https://arxiv.org/abs/2508.01842)
*Weiqi Yan,Chenlu Lin,Youbiao Wang,Zhipeng Cai,Xiuhong Lin,Yangyang Shi,Weiquan Liu,Yu Zang*

Main category: cs.CV

TL;DR: OmniEvent是一个创新的事件表示学习框架，它通过解耦时空特征、利用空间填充曲线和注意力机制，实现了跨任务的卓越性能，并能直接被标准视觉模型使用，无需进行特定任务的设计。


<details>
  <summary>Details</summary>
Motivation: 现有的事件相机网络严重依赖于特定任务的设计，因为事件数据的非结构化分布和时空不均匀性，这使得重用现有架构来处理新任务变得困难。

Method: OmniEvent框架采用解耦-增强-融合范式，首先在空间和时间域独立进行局部特征聚合和增强，以解决不均匀性问题。然后，利用空间填充曲线扩大感受野并优化效率。最后，通过注意力机制融合时空特征。其输出为网格状张量，可直接用于标准视觉模型。

Result: OmniEvent在一个统一的框架和相似的超参数下，在3个代表性任务和10个数据集上，其性能比特定任务的最先进方法提高了68.2%。

Conclusion: OmniEvent是一个统一的事件表示学习框架，能够跨多个任务实现最先进的性能，无需进行特定任务的设计。它通过解耦-增强-融合范例，在空间和时间域上独立地进行局部特征聚合和增强，以避免不均匀性问题。同时，它利用空间填充曲线来实现大的感受野，并提高内存和计算效率。最后，通过注意力机制融合来自单个域的特征，以学习时空交互。OmniEvent 的输出是一个网格状张量，使得标准的视觉模型能够无需改变架构即可处理事件数据。

Abstract: Event cameras have gained increasing popularity in computer vision due to
their ultra-high dynamic range and temporal resolution. However, event networks
heavily rely on task-specific designs due to the unstructured data distribution
and spatial-temporal (S-T) inhomogeneity, making it hard to reuse existing
architectures for new tasks. We propose OmniEvent, the first unified event
representation learning framework that achieves SOTA performance across diverse
tasks, fully removing the need of task-specific designs. Unlike previous
methods that treat event data as 3D point clouds with manually tuned S-T
scaling weights, OmniEvent proposes a decouple-enhance-fuse paradigm, where the
local feature aggregation and enhancement is done independently on the spatial
and temporal domains to avoid inhomogeneity issues. Space-filling curves are
applied to enable large receptive fields while improving memory and compute
efficiency. The features from individual domains are then fused by attention to
learn S-T interactions. The output of OmniEvent is a grid-shaped tensor, which
enables standard vision models to process event data without architecture
change. With a unified framework and similar hyper-parameters, OmniEvent
out-performs (tasks-specific) SOTA by up to 68.2% across 3 representative tasks
and 10 datasets (Fig.1). Code will be ready in
https://github.com/Wickyan/OmniEvent .

</details>


### [143] [Beyond Vulnerabilities: A Survey of Adversarial Attacks as Both Threats and Defenses in Computer Vision Systems](https://arxiv.org/abs/2508.01845)
*Zhongliang Guo,Yifei Qian,Yanli Li,Weiye Li,Chun Tong Lei,Shuai Zhao,Lei Fang,Ognjen Arandjelović,Chun Pong Lau*

Main category: cs.CV

TL;DR: 本文全面综述了计算机视觉领域的对抗性攻击技术，分析了其攻击方法、演变历程及在防御和评估中的应用，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于对抗性攻击对计算机视觉系统的安全性构成了严峻挑战，因此需要深入理解这些攻击的机制及其潜在应用。

Method: 本研究系统性地分析了三种主要的对抗性攻击方法：像素空间攻击、物理可实现攻击和潜在空间攻击，并追溯了从早期基于梯度的方法到先进优化技术的演变。

Result: 本研究对像素空间攻击、物理可实现攻击和潜在空间攻击进行了分析，并探讨了对抗性技术在生物识别认证系统和对抗恶意生成模型中的建设性应用，同时指出了神经风格迁移保护和计算效率方面的研究空白。

Conclusion: 本篇论文旨在全面梳理和分析对抗性攻击技术在计算机视觉领域的应用和发展，填补研究空白，并为构建更健壮、可信的系统提供指导。

Abstract: Adversarial attacks against computer vision systems have emerged as a
critical research area that challenges the fundamental assumptions about neural
network robustness and security. This comprehensive survey examines the
evolving landscape of adversarial techniques, revealing their dual nature as
both sophisticated security threats and valuable defensive tools. We provide a
systematic analysis of adversarial attack methodologies across three primary
domains: pixel-space attacks, physically realizable attacks, and latent-space
attacks. Our investigation traces the technical evolution from early
gradient-based methods such as FGSM and PGD to sophisticated optimization
techniques incorporating momentum, adaptive step sizes, and advanced
transferability mechanisms. We examine how physically realizable attacks have
successfully bridged the gap between digital vulnerabilities and real-world
threats through adversarial patches, 3D textures, and dynamic optical
perturbations. Additionally, we explore the emergence of latent-space attacks
that leverage semantic structure in internal representations to create more
transferable and meaningful adversarial examples. Beyond traditional offensive
applications, we investigate the constructive use of adversarial techniques for
vulnerability assessment in biometric authentication systems and protection
against malicious generative models. Our analysis reveals critical research
gaps, particularly in neural style transfer protection and computational
efficiency requirements. This survey contributes a comprehensive taxonomy,
evolution analysis, and identification of future research directions, aiming to
advance understanding of adversarial vulnerabilities and inform the development
of more robust and trustworthy computer vision systems.

</details>


### [144] [Context Guided Transformer Entropy Modeling for Video Compression](https://arxiv.org/abs/2508.01852)
*Junlong Tong,Wei Zhang,Yaohui Jin,Xiaoyu Shen*

Main category: cs.CV

TL;DR: CGT模型通过重采样时间上下文和依赖性加权的 것입니다。空间上下文来估计概率质量函数，以减少视频冗余。该模型通过学习预定义的潜在查询来提取关键时间信息，并使用师生网络来选择具有最高空间依赖性的 것입니다。标记，从而减少计算开销并提高压缩效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有空间上下文模型缺乏显式建模空间依赖性顺序的问题，以及现有条件熵模型在视频冗余编码中引入了额外的模型复杂性和计算成本。

Method: 提出了一种条件熵模型，该模型估计当前帧的概率质量函数，并以重采样的时间上下文和依赖性加权的 것입니다。空间上下文为条件。时间上下文重采样器使用变压器编码器学习预定义的潜在查询，以提取关键的时间信息，从而减少下游计算开销。同时，设计了一个师生网络作为依赖性加权的 것입니다。空间上下文分配器明确地对 것입니다。空间上下文顺序的依赖性进行建模。

Result: CGT模型将熵模型时间减少了约65%，并实现了11%的BD-Rate降低。

Conclusion: CGT模型将熵模型时间减少了约65%，并实现了比以前最先进的条件熵模型高11%的BD-Rate降低。

Abstract: Conditional entropy models effectively leverage spatio-temporal contexts to
reduce video redundancy. However, incorporating temporal context often
introduces additional model complexity and increases computational cost. In
parallel, many existing spatial context models lack explicit modeling the
ordering of spatial dependencies, which may limit the availability of relevant
context during decoding. To address these issues, we propose the Context Guided
Transformer (CGT) entropy model, which estimates probability mass functions of
the current frame conditioned on resampled temporal context and
dependency-weighted spatial context. A temporal context resampler learns
predefined latent queries to extract critical temporal information using
transformer encoders, reducing downstream computational overhead. Meanwhile, a
teacher-student network is designed as dependency-weighted spatial context
assigner to explicitly model the dependency of spatial context order. The
teacher generates an attention map to represent token importance and an entropy
map to reflect prediction certainty from randomly masked inputs, guiding the
student to select the weighted top-k tokens with the highest spatial
dependency. During inference, only the student is used to predict undecoded
tokens based on high-dependency context. Experimental results demonstrate that
our CGT model reduces entropy modeling time by approximately 65% and achieves
an 11% BD-Rate reduction compared to the previous state-of-the-art conditional
entropy model.

</details>


### [145] [Distinguishing Target and Non-Target Fixations with EEG and Eye Tracking in Realistic Visual Scenes](https://arxiv.org/abs/2508.01853)
*Mansi Sharma,Camilo Andrés Martínez Martínez,Benedikt Emanuel Wirth,Antonio Krüger,Philipp Müller*

Main category: cs.CV

TL;DR: 本研究首次在真实场景下，利用眼动和EEG数据，成功区分了视觉搜索中的目标与非目标注视点，准确率高达83.6%，大幅超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 先前研究在分类目标与非目标注视点时，多采用受指令引导的搜索轨迹、抽象视觉刺激且忽略场景上下文，这与真实人类视觉搜索的特点存在差异，限制了研究的普适性。本研究旨在解决这一差距，探索在真实场景和自由搜索条件下的注视点分类问题。

Method: 本研究采用基于眼动和EEG特征的方法，并在包含140个真实场景的视觉搜索任务中进行了36名参与者的用户研究，以评估其跨场景和跨用户的泛化能力。

Result: 本研究提出的基于眼动和EEG特征的方法，在区分真实场景中的目标与非目标注视点方面，准确率达到了83.6%，显著优于先前基于注视持续时间和眼跳相关电位的方法（56.9%）。

Conclusion: 本研究首次在真实场景的自由视觉搜索中对目标与非目标注视点进行了分类，显著提高了区分准确性，达到了83.6%，远超先前基于眼动和脑电图（EEG）数据的方法（56.9%）。

Abstract: Distinguishing target from non-target fixations during visual search is a
fundamental building block to understand users' intended actions and to build
effective assistance systems. While prior research indicated the feasibility of
classifying target vs. non-target fixations based on eye tracking and
electroencephalography (EEG) data, these studies were conducted with explicitly
instructed search trajectories, abstract visual stimuli, and disregarded any
scene context. This is in stark contrast with the fact that human visual search
is largely driven by scene characteristics and raises questions regarding
generalizability to more realistic scenarios. To close this gap, we, for the
first time, investigate the classification of target vs. non-target fixations
during free visual search in realistic scenes. In particular, we conducted a
36-participants user study using a large variety of 140 realistic visual search
scenes in two highly relevant application scenarios: searching for icons on
desktop backgrounds and finding tools in a cluttered workshop. Our approach
based on gaze and EEG features outperforms the previous state-of-the-art
approach based on a combination of fixation duration and saccade-related
potentials. We perform extensive evaluations to assess the generalizability of
our approach across scene types. Our approach significantly advances the
ability to distinguish between target and non-target fixations in realistic
scenarios, achieving 83.6% accuracy in cross-user evaluations. This
substantially outperforms previous methods based on saccade-related potentials,
which reached only 56.9% accuracy.

</details>


### [146] [DiffusionFF: Face Forgery Detection via Diffusion-based Artifact Localization](https://arxiv.org/abs/2508.01873)
*Siran Peng,Haoyuan Zhang,Li Gao,Tianshuo Zhang,Bao Li,Zhen Lei*

Main category: cs.CV

TL;DR: DiffusionFF利用扩散模型和DSSIM图来检测和定位人脸伪造，提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了应对深度伪造生成技术快速演变带来的挑战，需要强大的面部伪造检测算法，并且能够精确定位伪造伪影以提高模型可解释性和用户信任度。

Method: 提出了一种名为DiffusionFF的新颖框架，利用去噪扩散模型生成高质量的DSSIM图，并将其与预训练伪造检测器的语义特征融合。

Result: 在跨数据集和数据集内基准测试的大量实验表明，DiffusionFF实现了优于现有方法的检测性能，并能进行精确、细粒度的伪影定位。

Conclusion: DiffusionFF通过生成高分辨率的结构相似性（DSSIM）图来增强人脸伪造检测，并结合了预训练伪造检测器的语义特征，实现了卓越的检测性能和精确的伪影定位。

Abstract: The rapid evolution of deepfake generation techniques demands robust and
accurate face forgery detection algorithms. While determining whether an image
has been manipulated remains essential, the ability to precisely localize
forgery artifacts has become increasingly important for improving model
explainability and fostering user trust. To address this challenge, we propose
DiffusionFF, a novel framework that enhances face forgery detection through
diffusion-based artifact localization. Our method utilizes a denoising
diffusion model to generate high-quality Structural Dissimilarity (DSSIM) maps,
which effectively capture subtle traces of manipulation. These DSSIM maps are
then fused with high-level semantic features extracted by a pretrained forgery
detector, leading to significant improvements in detection accuracy. Extensive
experiments on both cross-dataset and intra-dataset benchmarks demonstrate that
DiffusionFF not only achieves superior detection performance but also offers
precise and fine-grained artifact localization, highlighting its overall
effectiveness.

</details>


### [147] [StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding](https://arxiv.org/abs/2508.01875)
*Haolin Yang,Feilong Tang,Linxiao Zhao,Xiang An,Ming Hu,Huifa Li,Xinlin Zhuang,Boqian Wang,Yifan Lu,Xiaofeng Zhang,Abdalla Swikir,Junjun He,Zongyuan Ge,Imran Razzak*

Main category: cs.CV

TL;DR: StreamAgent通过预测未来相关信息的时间和空间来主动响应流媒体视频，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的实时流视频理解方法在感知-反应或异步触发方面存在不足，缺乏任务驱动的规划和对未来的预期，这限制了它们在动态变化的视频流中的实时响应能力和主动决策能力。

Method: 提出了一种名为StreamAgent的方法，通过整合问题语义和历史观察，预测未来相关信息的时间和空间区域，以实现主动和以目标为驱动的响应。具体来说，它通过提示预期代理来预测关键事件的时间进展，将当前观察与预期的未来证据进行比对，并相应地调整感知动作。为了实现高效推理，设计了一种流式KV缓存内存机制，用于构建分层内存结构以选择性地调用相关令牌，从而在减少存储所有令牌的开销的同时，实现高效的语义检索。

Result: StreamAgent在流式和长视频理解任务的广泛实验表明，在响应准确性和实时效率方面优于现有方法。

Conclusion: StreamAgent通过预测未来相关信息的时间和空间来支持主动响应，并在流式KV缓存内存机制的帮助下，在响应准确性和实时效率方面优于现有方法，在现实的流媒体场景中具有实用价值。

Abstract: Real-time streaming video understanding in domains such as autonomous driving
and intelligent surveillance poses challenges beyond conventional offline video
processing, requiring continuous perception, proactive decision making, and
responsive interaction based on dynamically evolving visual content. However,
existing methods rely on alternating perception-reaction or asynchronous
triggers, lacking task-driven planning and future anticipation, which limits
their real-time responsiveness and proactive decision making in evolving video
streams. To this end, we propose a StreamAgent that anticipates the temporal
intervals and spatial regions expected to contain future task-relevant
information to enable proactive and goal-driven responses. Specifically, we
integrate question semantics and historical observations through prompting the
anticipatory agent to anticipate the temporal progression of key events, align
current observations with the expected future evidence, and subsequently adjust
the perception action (e.g., attending to task-relevant regions or continuously
tracking in subsequent frames). To enable efficient inference, we design a
streaming KV-cache memory mechanism that constructs a hierarchical memory
structure for selective recall of relevant tokens, enabling efficient semantic
retrieval while reducing the overhead of storing all tokens in the traditional
KV-cache. Extensive experiments on streaming and long video understanding tasks
demonstrate that our method outperforms existing methods in response accuracy
and real-time efficiency, highlighting its practical value for real-world
streaming scenarios.

</details>


### [148] [Medical Image De-Identification Resources: Synthetic DICOM Data and Tools for Validation](https://arxiv.org/abs/2508.01889)
*Michael W. Rutherford,Tracy Nolan,Linmin Pei,Ulrike Wagner,Qinyan Pan,Phillip Farmer,Kirk Smith,Benjamin Kopchick,Laura Opsahl-Ong,Granger Sutton,David Clunie,Keyvan Farahani,Fred Prior*

Main category: cs.CV

TL;DR: 该研究介绍了MIDI数据集和评估框架，旨在客观评估医学影像去标识化流程，以促进数据共享和患者隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像去标识化工具缺乏有效的评估方法，且大多依赖主观审查，这限制了可复现性和监管信心。为了解决这个差距，需要一个公开的数据集和评估框架来客观地评估去标识化流程。

Method: 开发了一个包含合成PHI/PII的MIDI数据集，并提供了一个评估框架，包括Python脚本、答案键和映射文件，用于自动评估去标识化流程。评估框架遵循HIPAA隐私规则“安全港”方法、DICOM PS3.15保密性配置文件和TCIA最佳实践。

Result: MIDI数据集包含538个受试者、605个研究、708个序列和53,581个DICOM图像实例，涵盖了多种供应商、成像模式和癌症类型。评估框架能够对去标识化工作流程进行客观、标准驱动的评估。

Conclusion: 该研究提出了一个名为MIDI的数据集和评估框架，用于评估医学影像去标识化流程的有效性。该框架符合HIPAA隐私规则和DICOM标准，能够客观地评估去标识化工作流程，促进医学影像的安全共享。

Abstract: Medical imaging research increasingly depends on large-scale data sharing to
promote reproducibility and train Artificial Intelligence (AI) models. Ensuring
patient privacy remains a significant challenge for open-access data sharing.
Digital Imaging and Communications in Medicine (DICOM), the global standard
data format for medical imaging, encodes both essential clinical metadata and
extensive protected health information (PHI) and personally identifiable
information (PII). Effective de-identification must remove identifiers,
preserve scientific utility, and maintain DICOM validity. Tools exist to
perform de-identification, but few assess its effectiveness, and most rely on
subjective reviews, limiting reproducibility and regulatory confidence. To
address this gap, we developed an openly accessible DICOM dataset infused with
synthetic PHI/PII and an evaluation framework for benchmarking image
de-identification workflows. The Medical Image de-identification (MIDI) dataset
was built using publicly available de-identified data from The Cancer Imaging
Archive (TCIA). It includes 538 subjects (216 for validation, 322 for testing),
605 studies, 708 series, and 53,581 DICOM image instances. These span multiple
vendors, imaging modalities, and cancer types. Synthetic PHI and PII were
embedded into structured data elements, plain text data elements, and pixel
data to simulate real-world identity leaks encountered by TCIA curation teams.
Accompanying evaluation tools include a Python script, answer keys (known
truth), and mapping files that enable automated comparison of curated data
against expected transformations. The framework is aligned with the HIPAA
Privacy Rule "Safe Harbor" method, DICOM PS3.15 Confidentiality Profiles, and
TCIA best practices. It supports objective, standards-driven evaluation of
de-identification workflows, promoting safer and more consistent medical image
sharing.

</details>


### [149] [InspectVLM: Unified in Theory, Unreliable in Practice](https://arxiv.org/abs/2508.01921)
*Conor Wallace,Isaac Corley,Jonathan Lwowski*

Main category: cs.CV

TL;DR: 统一的视觉-语言模型在工业检测中表现不佳，存在脆弱性和鲁棒性问题，无法满足精密检测要求。


<details>
  <summary>Details</summary>
Motivation: 评估统一视觉-语言模型在工业检测任务中的可行性，特别是在处理分类、检测和关键点定位等任务时。

Method: 本研究使用基于Florence-2的VLM（InspectVLM）在InspectMM数据集上进行训练和评估，并与传统的ResNet模型进行比较。

Result: InspectVLM在图像分类和结构化关键点任务上表现具有竞争力，但在核心检测指标上未能超越传统的ResNet模型。该模型在低提示变化下行为脆弱，在细粒度目标检测方面输出退化，并且经常出现不依赖视觉输入的记忆性语言回应。

Conclusion: 统一的视觉-语言模型（VLM）在工业检测等领域具有概念上的吸引力，但目前的研究表明，它们在视觉基础和鲁棒性方面存在不足，无法满足精密工业检测的要求。

Abstract: Unified vision-language models (VLMs) promise to streamline computer vision
pipelines by reframing multiple visual tasks such as classification, detection,
and keypoint localization within a single language-driven interface. This
architecture is particularly appealing in industrial inspection, where managing
disjoint task-specific models introduces complexity, inefficiency, and
maintenance overhead. In this paper, we critically evaluate the viability of
this unified paradigm using InspectVLM, a Florence-2-based VLM trained on
InspectMM, our new large-scale multimodal, multitask inspection dataset. While
InspectVLM performs competitively on image-level classification and structured
keypoint tasks, we find that it fails to match traditional ResNet-based models
in core inspection metrics. Notably, the model exhibits brittle behavior under
low prompt variability, produces degenerate outputs for fine-grained object
detection, and frequently defaults to memorized language responses regardless
of visual input. Our findings suggest that while language-driven unification
offers conceptual elegance, current VLMs lack the visual grounding and
robustness necessary for deployment in precision critical industrial
inspections.

</details>


### [150] [IAUNet: Instance-Aware U-Net](https://arxiv.org/abs/2508.01928)
*Yaroslav Prytula,Illia Tsiporenko,Ali Zeynalli,Dmytro Fishman*

Main category: cs.CV

TL;DR: IAUNet 是一种新的基于查询的 U-Net 模型，用于生物医学实例分割，通过优化的解码器提高了效率和性能，并在新的数据集上设定了新的基准。


<details>
  <summary>Details</summary>
Motivation: 虽然 U-Net 在医学图像分割中一直是一种首选架构，但其在基于查询的方法中的潜力在很大程度上仍未被探索。本研究旨在探索和利用 U-Net 在基于查询的实例分割方法中的潜力，特别是在生物医学成像领域。

Method: IAUNet 是一种新颖的基于查询的 U-Net 架构，其核心设计采用完整的 U-Net 架构，并由新颖的轻量级卷积像素解码器增强，提高了模型效率并减少了参数数量。此外，还提出了一种 Transformer 解码器，用于跨多个尺度优化特定对象的特征。

Result: IAUNet 是一种新颖的基于查询的 U-Net 架构，通过轻量级卷积像素解码器和 Transformer 解码器提高了效率和性能。此外，还引入了具有详细注释的 2025 Revvity Full Cell Segmentation 数据集，为生物医学实例分割设定了新的基准。

Conclusion: IAUNet 在多个公开数据集和我们自己的数据集上的实验表明，其性能优于大多数最先进的完全卷积、基于 Transformer 和基于查询的模型，以及专门的细胞分割模型，为细胞实例分割任务奠定了坚实的基础。

Abstract: Instance segmentation is critical in biomedical imaging to accurately
distinguish individual objects like cells, which often overlap and vary in
size. Recent query-based methods, where object queries guide segmentation, have
shown strong performance. While U-Net has been a go-to architecture in medical
image segmentation, its potential in query-based approaches remains largely
unexplored. In this work, we present IAUNet, a novel query-based U-Net
architecture. The core design features a full U-Net architecture, enhanced by a
novel lightweight convolutional Pixel decoder, making the model more efficient
and reducing the number of parameters. Additionally, we propose a Transformer
decoder that refines object-specific features across multiple scales. Finally,
we introduce the 2025 Revvity Full Cell Segmentation Dataset, a unique resource
with detailed annotations of overlapping cell cytoplasm in brightfield images,
setting a new benchmark for biomedical instance segmentation. Experiments on
multiple public datasets and our own show that IAUNet outperforms most
state-of-the-art fully convolutional, transformer-based, and query-based models
and cell segmentation-specific models, setting a strong baseline for cell
instance segmentation tasks. Code is available at
https://github.com/SlavkoPrytula/IAUNet

</details>


### [151] [Proactive Disentangled Modeling of Trigger-Object Pairings for Backdoor Defense](https://arxiv.org/abs/2508.01932)
*Kyle Stein,Andrew A. Mahyari,Guillermo Francia III,Eman El-Sheikh*

Main category: cs.CV

TL;DR: DBOM是一种创新的框架，通过解耦触发器和对象来防御DNN中的后门攻击，即使是新颖的攻击组合也能有效检测。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）和生成式人工智能（GenAI）越来越容易受到后门攻击，攻击者将触发器嵌入输入中，导致模型错误分类或错误解释目标标签。攻击者可能在各种对象类别中注入多个触发器，形成未见的后门-对象配置，从而逃避标准的检测流程。

Method: DBOM框架利用结构化解缠技术，通过在嵌入空间中将触发器和对象建模为独立的原语来识别和中和后门威胁。它利用VLMs的冻结、预训练编码器，通过可学习的视觉提示库和提示前缀调优来分解潜在表示，确保触发器和对象之间的关系被明确捕获。为了在视觉提示库中分离触发器和对象表示，DBOM引入了触发器-对象分离和多样性损失，以帮助解缠触发器和对象的视觉特征。通过在共享多模态空间中对齐图像特征与特征分解和融合以及学习到的上下文提示令牌，DBOM实现了零样本泛化到新颖的触发器-对象配对。

Result: DBOM在CIFAR-10和GTSRB数据集上进行了实验，结果表明该框架能够稳健地检测到被污染的图像，并且能够实现对未见过的触发器-对象配对的零样本泛化，有效提升了DNN训练的安全性。

Conclusion: DBOM框架能够有效识别和中和已见和未见的后门威胁，并且能够零样本泛化到训练期间未见的新的触发器-对象配对，从而为对抗性攻击模式提供更深入的见解。在CIFAR-10和GTSRB上的实验结果表明，DBOM在下游训练之前能够稳健地检测到被污染的图像，显著增强了DNN训练管道的安全性。

Abstract: Deep neural networks (DNNs) and generative AI (GenAI) are increasingly
vulnerable to backdoor attacks, where adversaries embed triggers into inputs to
cause models to misclassify or misinterpret target labels. Beyond traditional
single-trigger scenarios, attackers may inject multiple triggers across various
object classes, forming unseen backdoor-object configurations that evade
standard detection pipelines. In this paper, we introduce DBOM (Disentangled
Backdoor-Object Modeling), a proactive framework that leverages structured
disentanglement to identify and neutralize both seen and unseen backdoor
threats at the dataset level. Specifically, DBOM factorizes input image
representations by modeling triggers and objects as independent primitives in
the embedding space through the use of Vision-Language Models (VLMs). By
leveraging the frozen, pre-trained encoders of VLMs, our approach decomposes
the latent representations into distinct components through a learnable visual
prompt repository and prompt prefix tuning, ensuring that the relationships
between triggers and objects are explicitly captured. To separate trigger and
object representations in the visual prompt repository, we introduce the
trigger-object separation and diversity losses that aids in disentangling
trigger and object visual features. Next, by aligning image features with
feature decomposition and fusion, as well as learned contextual prompt tokens
in a shared multimodal space, DBOM enables zero-shot generalization to novel
trigger-object pairings that were unseen during training, thereby offering
deeper insights into adversarial attack patterns. Experimental results on
CIFAR-10 and GTSRB demonstrate that DBOM robustly detects poisoned images prior
to downstream training, significantly enhancing the security of DNN training
pipelines.

</details>


### [152] [Self-Supervised YOLO: Leveraging Contrastive Learning for Label-Efficient Object Detection](https://arxiv.org/abs/2508.01966)
*Manikanta Kotthapalli,Reshma Bhatia,Nainsi Jain*

Main category: cs.CV

TL;DR: 通过在无标签数据上使用 SimCLR 进行自监督预训练，可以提升 YOLOv8 在标注数据有限的自行车检测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 目标检测器（如 YOLO）虽然在实时应用中表现出色，但高度依赖大规模标注数据集。本研究旨在探索自监督学习（SSL）以减轻这种依赖。

Method: 本研究提出了一种将对比学习（SimCLR框架）应用于 YOLOv5 和 YOLOv8 的方法，通过在无标签数据上预训练骨干网络，然后在一个包含有限标注数据的自行车检测任务上进行微调。

Result: 与仅使用监督学习的对应模型相比，使用 SimCLR 预训练的 YOLOv8 在自行车检测任务上取得了更高的 mAP（0.7663），并且收敛更快，在低标签数据情况下表现出更优的精度-召回率性能。

Conclusion: 对比学习的自监督预训练可以有效减少 YOLO 等一阶段目标检测器对大规模标注数据的依赖，并在标注数据有限的情况下提高性能。

Abstract: One-stage object detectors such as the YOLO family achieve state-of-the-art
performance in real-time vision applications but remain heavily reliant on
large-scale labeled datasets for training. In this work, we present a
systematic study of contrastive self-supervised learning (SSL) as a means to
reduce this dependency by pretraining YOLOv5 and YOLOv8 backbones on unlabeled
images using the SimCLR framework. Our approach introduces a simple yet
effective pipeline that adapts YOLO's convolutional backbones as encoders,
employs global pooling and projection heads, and optimizes a contrastive loss
using augmentations of the COCO unlabeled dataset (120k images). The pretrained
backbones are then fine-tuned on a cyclist detection task with limited labeled
data. Experimental results show that SSL pretraining leads to consistently
higher mAP, faster convergence, and improved precision-recall performance,
especially in low-label regimes. For example, our SimCLR-pretrained YOLOv8
achieves a mAP@50:95 of 0.7663, outperforming its supervised counterpart
despite using no annotations during pretraining. These findings establish a
strong baseline for applying contrastive SSL to one-stage detectors and
highlight the potential of unlabeled data as a scalable resource for
label-efficient object detection.

</details>


### [153] [On-the-Fly Object-aware Representative Point Selection in Point Cloud](https://arxiv.org/abs/2508.01980)
*Xiaoyu Zhang,Ziwei Wang,Hai Dong,Zhifeng Bao,Jiajun Liu*

Main category: cs.CV

TL;DR: 这项工作提出了一种用于点云降采样的代表性点选择框架，该框架通过首先检测物体存在然后分配采样预算来过滤掉不相关的背景点，同时保留关键的物体信息。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶汽车（AV）产生的大量数据带来的存储、带宽和处理成本挑战，我们提出了一种代表性点选择框架，用于点云降采样，它能在有效过滤掉不相关背景点的同时保留关键的物体相关信息。

Method: 该方法包括两个步骤：(1) 物体存在检测，我们引入了一种无监督的密度峰值分类器和一种监督的朴素贝叶斯分类器来处理各种场景；(2) 采样预算分配，我们提出了一种选择与物体相关的点同时保持高物体信息保留率的策略。

Result: 在 KITTI 和 nuScenes 数据集上的广泛实验证明，在各种采样率下，我们的方法在效率和有效性方面始终优于最先进的基线。

Conclusion: 该方法作为一种模型无关的解决方案，可与各种下游模型无缝集成，使其成为 AV 应用中 3D 点云降采样工具包的有价值且可扩展的补充。

Abstract: Point clouds are essential for object modeling and play a critical role in
assisting driving tasks for autonomous vehicles (AVs). However, the significant
volume of data generated by AVs creates challenges for storage, bandwidth, and
processing cost. To tackle these challenges, we propose a representative point
selection framework for point cloud downsampling, which preserves critical
object-related information while effectively filtering out irrelevant
background points. Our method involves two steps: (1) Object Presence
Detection, where we introduce an unsupervised density peak-based classifier and
a supervised Na\"ive Bayes classifier to handle diverse scenarios, and (2)
Sampling Budget Allocation, where we propose a strategy that selects
object-relevant points while maintaining a high retention rate of object
information. Extensive experiments on the KITTI and nuScenes datasets
demonstrate that our method consistently outperforms state-of-the-art baselines
in both efficiency and effectiveness across varying sampling rates. As a
model-agnostic solution, our approach integrates seamlessly with diverse
downstream models, making it a valuable and scalable addition to the 3D point
cloud downsampling toolkit for AV applications.

</details>


### [154] [IMoRe: Implicit Program-Guided Reasoning for Human Motion Q&A](https://arxiv.org/abs/2508.01984)
*Chen Li,Chinthani Sugandhika,Yeo Keat Ee,Eric Peh,Hao Zhang,Hong Yang,Deepu Rajan,Basura Fernando*

Main category: cs.CV

TL;DR: IMoRe框架通过直接以结构化程序函数为条件，并结合程序引导的读取机制，实现了对人类运动的隐式程序引导推理，无需手动设计的模块，从而提高了可扩展性和适应性，并在运动问答任务中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的人类运动问答方法依赖于显式程序执行，而手动定义的函数模块可能限制了可扩展性和适应性。为了克服这个问题，IMoRe框架旨在统一推理过程，无需手动设计的模块，并实现更精确的推理步骤。

Method: 提出了一种隐式程序引导的运动推理（IMoRe）框架，该框架统一了跨多种查询类型的推理，无需手动设计的模块。该模型直接以结构化程序函数为条件，确保更精确的推理步骤执行。此外，还引入了一种程序引导的读取机制，该机制动态地从预训练的运动Vision Transformer（ViT）中选择多级运动表示，并结合了程序引导的读取机制，以捕获高层语义和细粒度的运动线索。推理模块利用结构化程序函数迭代地优化记忆表示，提取不同查询类型的相关信息。

Result: IMoRe框架在Babel-QA数据集上实现了最先进的性能，并且能够泛化到新构建的基于HuMMan的运动问答数据集。

Conclusion: IMoRe框架在Babel-QA数据集上取得了最先进的性能，并且能够泛化到新构建的基于HuMMan的运动问答数据集，证明了其跨不同运动推理数据集的适应性。

Abstract: Existing human motion Q\&A methods rely on explicit program execution, where
the requirement for manually defined functional modules may limit the
scalability and adaptability. To overcome this, we propose an implicit
program-guided motion reasoning (IMoRe) framework that unifies reasoning across
multiple query types without manually designed modules. Unlike existing
implicit reasoning approaches that infer reasoning operations from question
words, our model directly conditions on structured program functions, ensuring
a more precise execution of reasoning steps. Additionally, we introduce a
program-guided reading mechanism, which dynamically selects multi-level motion
representations from a pretrained motion Vision Transformer (ViT), capturing
both high-level semantics and fine-grained motion cues. The reasoning module
iteratively refines memory representations, leveraging structured program
functions to extract relevant information for different query types. Our model
achieves state-of-the-art performance on Babel-QA and generalizes to a newly
constructed motion Q\&A dataset based on HuMMan, demonstrating its adaptability
across different motion reasoning datasets. Code and dataset are available at:
https://github.com/LUNAProject22/IMoRe.

</details>


### [155] [Deeply Dual Supervised learning for melanoma recognition](https://arxiv.org/abs/2508.01994)
*Rujosh Polma,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 深度双监督学习框架通过整合局部/全局特征提取和双重注意力机制，提高了皮肤镜图像中黑色瘤的识别准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在皮肤病学中的应用不断增长，且黑色瘤识别备受关注，但现有模型在区分黑色瘤和良性病变方面仍面临识别细微视觉线索的挑战。

Method: 提出了一种新颖的深度双监督学习框架，该框架整合了局部和全局特征提取。采用了双通路结构，同时关注细粒度的局部特征和更广泛的上下文信息。利用双重注意力机制动态地强调关键特征，并通过多尺度特征聚合策略确保在不同图像分辨率下的稳健性能。

Result: 在基准数据集上的大量实验表明，该框架在黑色瘤检测方面显著优于现有最先进方法，实现了更高的准确性和更强的抵抗假阳性的能力。

Conclusion: 该研究提出的深度双监督学习框架在皮肤镜图像的黑色瘤识别任务上表现出色，显著优于现有最先进方法，提高了准确性并减少了假阳性，为皮肤癌自动识别奠定了基础，并凸显了双监督学习在医学图像分析中的潜力。

Abstract: As the application of deep learning in dermatology continues to grow, the
recognition of melanoma has garnered significant attention, demonstrating
potential for improving diagnostic accuracy. Despite advancements in image
classification techniques, existing models still face challenges in identifying
subtle visual cues that differentiate melanoma from benign lesions. This paper
presents a novel Deeply Dual Supervised Learning framework that integrates
local and global feature extraction to enhance melanoma recognition. By
employing a dual-pathway structure, the model focuses on both fine-grained
local features and broader contextual information, ensuring a comprehensive
understanding of the image content. The framework utilizes a dual attention
mechanism that dynamically emphasizes critical features, thereby reducing the
risk of overlooking subtle characteristics of melanoma. Additionally, we
introduce a multi-scale feature aggregation strategy to ensure robust
performance across varying image resolutions. Extensive experiments on
benchmark datasets demonstrate that our framework significantly outperforms
state-of-the-art methods in melanoma detection, achieving higher accuracy and
better resilience against false positives. This work lays the foundation for
future research in automated skin cancer recognition and highlights the
effectiveness of dual supervised learning in medical image analysis.

</details>


### [156] [Fast and Memory-efficient Non-line-of-sight Imaging with Quasi-Fresnel Transform](https://arxiv.org/abs/2508.02003)
*Yijun Wei,Jianyu Wang,Leping Xiao,Zuoqiang Shi,Xing Fu,Lingyun Qiu*

Main category: cs.CV

TL;DR: 一种新的非视距成像方法，利用二维表示和拟傅里叶变换，大大降低了计算和内存需求，实现了高效成像。


<details>
  <summary>Details</summary>
Motivation: 现有非视距成像方法将测量数据和隐藏场景建模为三维，忽略了隐藏对象的二维性质，导致计算成本高、内存消耗大，限制了其实际应用和轻量级设备的实时成像能力。

Method: 提出了一种新方法，使用二维函数表示隐藏场景，并利用拟傅里叶变换建立测量数据与隐藏场景之间的直接反演公式。

Result: 与现有方法相比，该方法将运行时间和内存需求降低了几个数量级，同时保持了成像质量，能够实现快速、低内存占用的隐藏物体重建，并支持在轻量级设备上的应用。

Conclusion: 该方法通过利用二维函数表示隐藏场景并采用拟傅里叶变换，在测量数据和隐藏场景之间建立了直接反演公式，显著降低了计算复杂度和内存需求，实现了高性能的非视距成像，并有望在轻量级设备上实现实时成像。

Abstract: Non-line-of-sight (NLOS) imaging seeks to reconstruct hidden objects by
analyzing reflections from intermediary surfaces. Existing methods typically
model both the measurement data and the hidden scene in three dimensions,
overlooking the inherently two-dimensional nature of most hidden objects. This
oversight leads to high computational costs and substantial memory consumption,
limiting practical applications and making real-time, high-resolution NLOS
imaging on lightweight devices challenging. In this paper, we introduce a novel
approach that represents the hidden scene using two-dimensional functions and
employs a Quasi-Fresnel transform to establish a direct inversion formula
between the measurement data and the hidden scene. This transformation
leverages the two-dimensional characteristics of the problem to significantly
reduce computational complexity and memory requirements. Our algorithm
efficiently performs fast transformations between these two-dimensional
aggregated data, enabling rapid reconstruction of hidden objects with minimal
memory usage. Compared to existing methods, our approach reduces runtime and
memory demands by several orders of magnitude while maintaining imaging
quality. The substantial reduction in memory usage not only enhances
computational efficiency but also enables NLOS imaging on lightweight devices
such as mobile and embedded systems. We anticipate that this method will
facilitate real-time, high-resolution NLOS imaging and broaden its
applicability across a wider range of platforms.

</details>


### [157] [Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention](https://arxiv.org/abs/2508.02004)
*Kyungmin Jo,Jooyeol Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 为了解决文本到图像模型在细节捕捉上的不足，本研究提出了两种新方法：冲突无指导和分层注意力。冲突无指导通过仅将图像提示作为期望条件，消除了引导过程中的冲突信号。分层注意力则通过同时利用图像提示和生成图像的特征，平衡了生成图像的真实感和与图像提示的对齐度。实验结果表明，这些新方法在图像生成任务中能够更准确地反映用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在捕捉纹理等细节方面存在困难，用户难以通过文本提示精确传达意图。现有图像提示方法在自注意力机制修改时存在问题：1. 冲突信号：将图像提示同时用作期望和非期望条件。2. 真实感与对齐度的权衡：现有方法在提高图像提示对齐度时会牺牲真实感，反之亦然。

Method: 1. 冲突无指导（Conflict-free Guidance）：提出使用图像提示仅作为期望条件，解决现有方法将图像提示同时用作期望和非期望条件产生的冲突信号问题。2. 分层注意力（Stratified Attention）：提出一种新的自注意力修改方法，联合使用来自图像提示和生成图像的键和值，以平衡生成图像的真实感和与图像提示的对齐度。

Result: 通过在三个图像生成任务上的广泛实验，证明了所提出的冲突无指导和分层注意力方法在忠实反映图像提示方面优于现有的图像提示模型。

Conclusion: 提出的冲突无指导和分层注意力方法在图像生成任务中优于现有的图像提示模型，能更忠实地反映图像提示。

Abstract: While large-scale text-to-image diffusion models enable the generation of
high-quality, diverse images from text prompts, these prompts struggle to
capture intricate details, such as textures, preventing the user intent from
being reflected. This limitation has led to efforts to generate images
conditioned on user-provided images, referred to as image prompts. Recent work
modifies the self-attention mechanism to impose image conditions in generated
images by replacing or concatenating the keys and values from the image prompt.
This enables the self-attention layer to work like a cross-attention layer,
generally used to incorporate text prompts. In this paper, we identify two
common issues in existing methods of modifying self-attention to generate
images that reflect the details of image prompts. First, existing approaches
neglect the importance of image prompts in classifier-free guidance.
Specifically, current methods use image prompts as both desired and undesired
conditions in classifier-free guidance, causing conflicting signals. To resolve
this, we propose conflict-free guidance by using image prompts only as desired
conditions, ensuring that the generated image faithfully reflects the image
prompt. In addition, we observe that the two most common self-attention
modifications involve a trade-off between the realism of the generated image
and alignment with the image prompt. Specifically, selecting more keys and
values from the image prompt improves alignment, while selecting more from the
generated image enhances realism. To balance both, we propose an new
self-attention modification method, Stratified Attention to jointly use keys
and values from both images rather than selecting between them. Through
extensive experiments across three image generation tasks, we show that the
proposed method outperforms existing image-prompting models in faithfully
reflecting the image prompt.

</details>


### [158] [Bench2ADVLM: A Closed-Loop Benchmark for Vision-language Models in Autonomous Driving](https://arxiv.org/abs/2508.02028)
*Tianyuan Zhang,Ting Jin,Lu Wang,Jiangfan Liu,Siyuan Liang,Mingchuan Zhang,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: Bench2ADVLM是一个用于自动驾驶视觉语言模型（ADVLMs）的闭环评估框架，可在模拟和物理平台进行实时交互评估，并能生成安全关键场景。该框架通过双系统适应架构和物理控制抽象层，实现了从高层指令到低层执行的无缝集成，实验证明现有ADVLMs在闭环条件下性能仍有待提高。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉语言模型（ADVLMs）的性能评估主要局限于开环设置和静态输入，未能反映真实世界中涉及交互行为、反馈弹性和安全性的闭环场景。因此，需要一个能够捕捉这些复杂性的闭环评估框架。

Method: Bench2ADVLM框架通过引入一个双系统适应架构，将不同ADVLMs的高层驾驶指令转换为适用于模拟环境的标准化中层控制动作，并设计了一个物理控制抽象层将中层动作翻译为物理车辆的低层驱动信号，实现了在模拟和物理平台上的闭环测试。此外，框架还包含一个自反思场景生成模块，用于自动探索模型行为和生成安全关键场景。

Result: 实验结果表明，Bench2ADVLM框架能够有效诊断ADVLMs在闭环条件下的性能，并揭示了现有ADVLMs在闭环场景下仍存在性能局限。

Conclusion: 该研究提出的Bench2ADVLM框架能够有效地评估自动驾驶视觉语言模型（ADVLMs）在闭环场景下的性能，并验证了现有ADVLMs在闭环条件下仍存在局限性。

Abstract: Vision-Language Models (VLMs) have recently emerged as a promising paradigm
in autonomous driving (AD). However, current performance evaluation protocols
for VLM-based AD systems (ADVLMs) are predominantly confined to open-loop
settings with static inputs, neglecting the more realistic and informative
closed-loop setting that captures interactive behavior, feedback resilience,
and real-world safety. To address this, we introduce Bench2ADVLM, a unified
hierarchical closed-loop evaluation framework for real-time, interactive
assessment of ADVLMs across both simulation and physical platforms. Inspired by
dual-process theories of cognition, we first adapt diverse ADVLMs to simulation
environments via a dual-system adaptation architecture. In this design,
heterogeneous high-level driving commands generated by target ADVLMs (fast
system) are interpreted by a general-purpose VLM (slow system) into
standardized mid-level control actions suitable for execution in simulation. To
bridge the gap between simulation and reality, we design a physical control
abstraction layer that translates these mid-level actions into low-level
actuation signals, enabling, for the first time, closed-loop testing of ADVLMs
on physical vehicles. To enable more comprehensive evaluation, Bench2ADVLM
introduces a self-reflective scenario generation module that automatically
explores model behavior and uncovers potential failure modes for
safety-critical scenario generation. Overall, Bench2ADVLM establishes a
hierarchical evaluation pipeline that seamlessly integrates high-level abstract
reasoning, mid-level simulation actions, and low-level real-world execution.
Experiments on diverse scenarios across multiple state-of-the-art ADVLMs and
physical platforms validate the diagnostic strength of our framework, revealing
that existing ADVLMs still exhibit limited performance under closed-loop
conditions.

</details>


### [159] [Protego: User-Centric Pose-Invariant Privacy Protection Against Face Recognition-Induced Digital Footprint Exposure](https://arxiv.org/abs/2508.02034)
*Ziling Wang,Shuya Yang,Jialin Lu,Ka-Ho Chow*

Main category: cs.CV

TL;DR: Protego 是一种新的隐私保护方法，可以防止面部识别技术被滥用进行大规模监控和身份追踪。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性，无法有效防止基于检索的隐私侵入，因此提出 Protego 来解决这一新兴威胁。

Method: Protego 将用户的 3D 面部签名封装到 2D 表示中，然后将其动态变形为适合用户任何面部图像的姿势和表情的自然 3D 掩码，并在此之前在线共享。它还通过放大 FR 模型来提高敏感性，以防止匹配。

Result: Protego 在广泛的黑盒 FR 模型上显著降低了检索准确性，性能优于现有方法，并且在视频设置中提供了前所未有的视觉一致性。

Conclusion: Protego 是一种以用户为中心的隐私保护方法，通过将用户的 3D 面部签名封装到 2D 表示中，然后将其动态变形为适合用户任何面部图像的姿势和表情的自然 3D 掩码，从而在在线共享之前应用，以防止基于检索的隐私侵入。Protego 旨在通过放大面部识别 (FR) 模型来保护面部图像，即使在它们之间也无法匹配。实验证明，Protego 在各种黑盒 FR 模型上显著降低了检索准确性，并且性能优于现有方法。它在视频设置中提供了前所未有的视觉一致性。总的来说，Protego 为打击大规模监控和未经请求的身份追踪中的 FR 滥用做出了贡献。

Abstract: Face recognition (FR) technologies are increasingly used to power large-scale
image retrieval systems, raising serious privacy concerns. Services like
Clearview AI and PimEyes allow anyone to upload a facial photo and retrieve a
large amount of online content associated with that person. This not only
enables identity inference but also exposes their digital footprint, such as
social media activity, private photos, and news reports, often without their
consent. In response to this emerging threat, we propose Protego, a
user-centric privacy protection method that safeguards facial images from such
retrieval-based privacy intrusions. Protego encapsulates a user's 3D facial
signatures into a pose-invariant 2D representation, which is dynamically
deformed into a natural-looking 3D mask tailored to the pose and expression of
any facial image of the user, and applied prior to online sharing. Motivated by
a critical limitation of existing methods, Protego amplifies the sensitivity of
FR models so that protected images cannot be matched even among themselves.
Experiments show that Protego significantly reduces retrieval accuracy across a
wide range of black-box FR models and performs at least 2x better than existing
methods. It also offers unprecedented visual coherence, particularly in video
settings where consistency and natural appearance are essential. Overall,
Protego contributes to the fight against the misuse of FR for mass surveillance
and unsolicited identity tracing.

</details>


### [160] [Conditional Diffusion Model with Anatomical-Dose Dual Constraints for End-to-End Multi-Tumor Dose Prediction](https://arxiv.org/abs/2508.02043)
*Hui Xie,Haiqin Hu,Lijuan Ding,Qing Li,Yue Sun,Tao Tan*

Main category: cs.CV

TL;DR: ADDiff-Dose 是一种新的放疗剂量预测模型，它使用扩散模型和多模态输入，能够快速、准确地生成放疗计划，并且优于现有方法，缩短了计划时间并提高了临床约束的合规性。


<details>
  <summary>Details</summary>
Motivation: 现有的放疗计划依赖耗时且依赖专家经验的试错调整，而现有的深度学习方法在泛化性、预测准确性和临床适用性方面存在局限性。为了解决这些挑战，本研究提出了 ADDiff-Dose 模型。

Method: 本研究提出了一种名为 ADDiff-Dose 的解剖剂量对偶约束条件扩散模型，用于端到端的预测多发肿瘤的放疗剂量。该模型使用 LightweightVAE3D 压缩高维 CT 数据，并整合了包括目标和危及器官（OAR）掩模以及射束参数在内的多模态输入，在一个渐进式的加噪和去噪框架内运行。它通过多头注意力机制整合条件特征，并使用结合了 MSE、条件项和 KL 散度的复合损失函数，以确保剂量学准确性和临床约束的合规性。

Result: 在大型公开数据集（2,877 例）和三个外部机构队列（共 450 例）上的评估表明，ADDiff-Dose 的表现显著优于传统基线方法。其平均绝对误差（MAE）为 0.101-0.154（相比之下，UNet 为 0.316，GAN 模型为 0.169），DICE 系数为 0.927（提高了 6.8%），并将脊髓最大剂量误差限制在 0.1 Gy 以内。平均每例计划生成时间缩短至 22 秒。验证性分析证实，结构编码器将临床剂量约束的合规性提高了 28.5%。

Conclusion: ADDiff-Dose 是首个将条件扩散模型框架应用于放疗剂量预测的研究，为跨多种肿瘤部位的自动化治疗计划提供了可推广且高效的解决方案，有潜力大幅缩短计划时间并提高临床工作流程效率。

Abstract: Radiotherapy treatment planning often relies on time-consuming,
trial-and-error adjustments that heavily depend on the expertise of
specialists, while existing deep learning methods face limitations in
generalization, prediction accuracy, and clinical applicability. To tackle
these challenges, we propose ADDiff-Dose, an Anatomical-Dose Dual Constraints
Conditional Diffusion Model for end-to-end multi-tumor dose prediction. The
model employs LightweightVAE3D to compress high-dimensional CT data and
integrates multimodal inputs, including target and organ-at-risk (OAR) masks
and beam parameters, within a progressive noise addition and denoising
framework. It incorporates conditional features via a multi-head attention
mechanism and utilizes a composite loss function combining MSE, conditional
terms, and KL divergence to ensure both dosimetric accuracy and compliance with
clinical constraints. Evaluation on a large-scale public dataset (2,877 cases)
and three external institutional cohorts (450 cases in total) demonstrates that
ADDiff-Dose significantly outperforms traditional baselines, achieving an MAE
of 0.101-0.154 (compared to 0.316 for UNet and 0.169 for GAN models), a DICE
coefficient of 0.927 (a 6.8% improvement), and limiting spinal cord maximum
dose error to within 0.1 Gy. The average plan generation time per case is
reduced to 22 seconds. Ablation studies confirm that the structural encoder
enhances compliance with clinical dose constraints by 28.5%. To our knowledge,
this is the first study to introduce a conditional diffusion model framework
for radiotherapy dose prediction, offering a generalizable and efficient
solution for automated treatment planning across diverse tumor sites, with the
potential to substantially reduce planning time and improve clinical workflow
efficiency.

</details>


### [161] [Mapillary Vistas Validation for Fine-Grained Traffic Signs: A Benchmark Revealing Vision-Language Model Limitations](https://arxiv.org/abs/2508.02047)
*Sparsh Garg,Abhishek Aich*

Main category: cs.CV

TL;DR: 我们提出了一个新的交通标志验证集 MVV，并使用 DINOv2 和其他 VLM 对其进行了基准测试，结果显示 DINOv2 在细粒度视觉理解方面表现更优，证明了其在自动驾驶领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 获取高质量的细粒度交通标志标注对于自动驾驶中的准确和安全决策至关重要。然而，Mapillary 等常用数据集通常只提供粗粒度标签，未能区分停车标志或速度限制标志等语义上重要的类型。

Method: 我们提出了一个新的交通标志验证集 MVV，它源自 Mapillary 数据集，并将复合交通标志分解为细粒度的、语义上有意义的类别。该数据集包括像素级实例掩码，并由专家注释者手动注释以确保标签保真度。此外，我们在此数据集上对几个最先进的 VLM 和自监督 DINOv2 模型进行了基准测试。

Result: DINOv2 在交通标志识别以及车辆和人类等类别上持续优于所有 VLM 基线，揭示了当前视觉-语言模型在细粒度视觉理解方面存在显著局限性。

Conclusion: 该数据集和评估框架为更可靠、可解释和可扩展的感知系统铺平了道路。DINOv2 在交通标志识别以及车辆和人类等类别上持续优于所有 VLM 基线。

Abstract: Obtaining high-quality fine-grained annotations for traffic signs is critical
for accurate and safe decision-making in autonomous driving. Widely used
datasets, such as Mapillary, often provide only coarse-grained labels - without
distinguishing semantically important types such as stop signs or speed limit
signs. To this end, we present a new validation set for traffic signs derived
from the Mapillary dataset called Mapillary Vistas Validation for Traffic Signs
(MVV), where we decompose composite traffic signs into granular, semantically
meaningful categories. The dataset includes pixel-level instance masks and has
been manually annotated by expert annotators to ensure label fidelity. Further,
we benchmark several state-of-the-art VLMs against the self-supervised DINOv2
model on this dataset and show that DINOv2 consistently outperforms all VLM
baselines-not only on traffic sign recognition, but also on heavily represented
categories like vehicles and humans. Our analysis reveals significant
limitations in current vision-language models for fine-grained visual
understanding and establishes DINOv2 as a strong baseline for dense semantic
matching in autonomous driving scenarios. This dataset and evaluation framework
pave the way for more reliable, interpretable, and scalable perception systems.
  Code and data are available at: https://github.com/nec-labs-ma/relabeling

</details>


### [162] [HCF: Hierarchical Cascade Framework for Distributed Multi-Stage Image Compression](https://arxiv.org/abs/2508.02051)
*Junhao Cai,Taegun An,Chengjun Jin,Sung Il Choi,JuHyun Park,Changhee Joo*

Main category: cs.CV

TL;DR: HCF是一种新的分布式多阶段图像压缩框架，通过潜在空间变换和策略驱动的量化控制，在提高压缩效率和图像质量方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式多阶段图像压缩方法在处理不同质量要求下的视觉内容时面临挑战，例如渐进式方法未能充分利用计算资源，而逐次压缩方法效率低下且存在累积质量损失，固定参数模型缺乏后编码灵活性。

Method: HCF通过在分布式多阶段图像压缩系统的网络节点之间直接进行潜在空间变换来实现高率失真性能和更好的计算效率。此外，HCF引入了策略驱动的量化控制来优化率失真权衡，并通过差分熵分析确立了边缘量化原理。

Result: HCF在CLIC数据集上，PSNR相比逐次压缩方法提高了高达0.6dB，BD-Rate降低了高达5.56%，同时节省了高达97.8%的FLOPs、96.5%的GPU内存和90.0%的执行时间。与渐进式压缩方法相比，HCF在Kodak数据集上BD-Rate降低了高达12.64%，在CLIC2020-mobile数据集上实现了无需重新训练的跨质量自适应，BD-Rate降低了7.13-10.87%。

Conclusion: HCF在 Kodak、CLIC 和 CLIC2020-mobile 数据集上进行了全面评估，其性能优于现有的图像压缩方法。

Abstract: Distributed multi-stage image compression -- where visual content traverses
multiple processing nodes under varying quality requirements -- poses
challenges. Progressive methods enable bitstream truncation but underutilize
available compute resources; successive compression repeats costly pixel-domain
operations and suffers cumulative quality loss and inefficiency;
fixed-parameter models lack post-encoding flexibility. In this work, we
developed the Hierarchical Cascade Framework (HCF) that achieves high
rate-distortion performance and better computational efficiency through direct
latent-space transformations across network nodes in distributed multi-stage
image compression system. Under HCF, we introduced policy-driven quantization
control to optimize rate-distortion trade-offs, and established the edge
quantization principle through differential entropy analysis. The configuration
based on this principle demonstrates up to 0.6dB PSNR gains over other
configurations. When comprehensively evaluated on the Kodak, CLIC, and
CLIC2020-mobile datasets, HCF outperforms successive-compression methods by up
to 5.56% BD-Rate in PSNR on CLIC, while saving up to 97.8% FLOPs, 96.5% GPU
memory, and 90.0% execution time. It also outperforms state-of-the-art
progressive compression methods by up to 12.64% BD-Rate on Kodak and enables
retraining-free cross-quality adaptation with 7.13-10.87% BD-Rate reductions on
CLIC2020-mobile.

</details>


### [163] [StarPose: 3D Human Pose Estimation via Spatial-Temporal Autoregressive Diffusion](https://arxiv.org/abs/2508.02056)
*Haoxin Yang,Weihong Chen,Xuemiao Xu,Cheng Xu,Peng Xiao,Cuifeng Sun,Shaoyu Huang,Shengfeng He*

Main category: cs.CV

TL;DR: StarPose是一种新颖的自回归扩散框架，通过整合历史位姿信息和时空物理约束，显著提高了3D人体姿态估计的准确性和时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的方法在处理3D人体姿态估计时，未能充分考虑预测帧之间的时空相关性，导致时间一致性有限且预测的3D姿态序列准确性较差。

Method: StarPose提出了一种自回归扩散框架，将2D到3D的位姿映射建模为自回归扩散过程。通过历史位姿整合模块（HPIM）整合历史预测的3D位姿和2D位姿输入，生成历史位姿嵌入以指导后续去噪步骤。此外，还设计了一个空间-时间物理指导（STPG）机制，通过迭代方式优化去噪过程，增强空间解剖学上的合理性和时间运动动态。

Result: StarPose在基准数据集上的实验结果表明，其在3D人体姿态估计方面取得了优于最先进方法的准确性和时间一致性。

Conclusion: StarPose框架通过结合历史3D位姿预测和时空物理指导，在3D人体姿态估计任务中实现了优于现有方法的准确性和时间一致性。

Abstract: Monocular 3D human pose estimation remains a challenging task due to inherent
depth ambiguities and occlusions. Compared to traditional methods based on
Transformers or Convolutional Neural Networks (CNNs), recent diffusion-based
approaches have shown superior performance, leveraging their probabilistic
nature and high-fidelity generation capabilities. However, these methods often
fail to account for the spatial and temporal correlations across predicted
frames, resulting in limited temporal consistency and inferior accuracy in
predicted 3D pose sequences. To address these shortcomings, this paper proposes
StarPose, an autoregressive diffusion framework that effectively incorporates
historical 3D pose predictions and spatial-temporal physical guidance to
significantly enhance both the accuracy and temporal coherence of pose
predictions. Unlike existing approaches, StarPose models the 2D-to-3D pose
mapping as an autoregressive diffusion process. By synergically integrating
previously predicted 3D poses with 2D pose inputs via a Historical Pose
Integration Module (HPIM), the framework generates rich and informative
historical pose embeddings that guide subsequent denoising steps, ensuring
temporally consistent predictions. In addition, a fully plug-and-play
Spatial-Temporal Physical Guidance (STPG) mechanism is tailored to refine the
denoising process in an iterative manner, which further enforces spatial
anatomical plausibility and temporal motion dynamics, rendering robust and
realistic pose estimates. Extensive experiments on benchmark datasets
demonstrate that StarPose outperforms state-of-the-art methods, achieving
superior accuracy and temporal consistency in 3D human pose estimation. Code is
available at https://github.com/wileychan/StarPose.

</details>


### [164] [YOLOv1 to YOLOv11: A Comprehensive Survey of Real-Time Object Detection Innovations and Challenges](https://arxiv.org/abs/2508.02067)
*Manikanta Kotthapalli,Deepika Ravipati,Reshma Bhatia*

Main category: cs.CV

TL;DR: YOLO系列模型是实时计算机视觉的基石，不断推动着检测、分割、跟踪和姿态估计的边界，并且在各个行业中得到了广泛应用。


<details>
  <summary>Details</summary>
Motivation: 回顾YOLO家族在物体检测领域的演变，重点关注其架构创新、性能提升和应用扩展。

Method: 对YOLO模型的演进、架构创新、性能基准、扩展能力和实际用例进行了全面审查和批判性分析。

Result: 对YOLO模型的发展进行了全面概述，并讨论了可能影响其在不同计算机视觉领域应用的未来研究方向。

Conclusion: YOLO家族模型在实时视觉应用领域取得了显著进展，并且在速度、准确性和部署效率之间取得了良好的平衡。现代YOLO架构已扩展到支持实例分割、姿态估计、物体跟踪以及医学成像和工业自动化等特定领域应用。

Abstract: Over the past decade, object detection has advanced significantly, with the
YOLO (You Only Look Once) family of models transforming the landscape of
real-time vision applications through unified, end-to-end detection frameworks.
From YOLOv1's pioneering regression-based detection to the latest YOLOv9, each
version has systematically enhanced the balance between speed, accuracy, and
deployment efficiency through continuous architectural and algorithmic
advancements.. Beyond core object detection, modern YOLO architectures have
expanded to support tasks such as instance segmentation, pose estimation,
object tracking, and domain-specific applications including medical imaging and
industrial automation. This paper offers a comprehensive review of the YOLO
family, highlighting architectural innovations, performance benchmarks,
extended capabilities, and real-world use cases. We critically analyze the
evolution of YOLO models and discuss emerging research directions that extend
their impact across diverse computer vision domains.

</details>


### [165] [S-RRG-Bench: Structured Radiology Report Generation with Fine-Grained Evaluation Framework](https://arxiv.org/abs/2508.02082)
*Yingshu Li,Yunyi Liu,Zhanyu Wang,Xinyu Liang,Lingqiao Liu,Lei Wang,Luping Zhou*

Main category: cs.CV

TL;DR: 该研究提出了一种新的结构化放射报告生成（S-RRG）方法，包括构建MIMIC-STRUC数据集、使用LLM模型生成报告，以及引入S-Score评估指标，以提高报告的临床相关性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的自由文本放射报告存在冗余和语言不一致的问题，而现有的结构化放射报告生成（S-RRG）方法依赖于预定义标签集，并且输出信息不完整，或者采用模板方法，限制了表达能力并遗漏了关键的临床细节。因此，需要一种新的S-RRG方法和评估框架。

Method: 该方法首先构建了一个包含疾病名称、严重程度、概率和解剖位置的MIMIC-STRUC数据集。然后，使用一个基于LLM的模型来生成结构化的报告。最后，提出了一个名为S-Score的专门评估指标，用于衡量疾病预测准确性和疾病细节的精确性。

Result: 该方法生成了高质量的结构化报告，并通过S-Score评估指标证明了其在疾病预测准确性和细节精确性方面的优势，该指标与人类评估有更强的相关性。

Conclusion: 所提出的方法通过包含数据集构建、模型训练和新的评估框架来解决结构化放射报告生成（S-RRG）问题。通过创建MIMIC-STRUC数据集和提出S-Score评估指标，该方法旨在生成更符合临床实践的高质量报告。

Abstract: Radiology report generation (RRG) for diagnostic images, such as chest
X-rays, plays a pivotal role in both clinical practice and AI. Traditional
free-text reports suffer from redundancy and inconsistent language,
complicating the extraction of critical clinical details. Structured radiology
report generation (S-RRG) offers a promising solution by organizing information
into standardized, concise formats. However, existing approaches often rely on
classification or visual question answering (VQA) pipelines that require
predefined label sets and produce only fragmented outputs. Template-based
approaches, which generate reports by replacing keywords within fixed sentence
patterns, further compromise expressiveness and often omit clinically important
details. In this work, we present a novel approach to S-RRG that includes
dataset construction, model training, and the introduction of a new evaluation
framework. We first create a robust chest X-ray dataset (MIMIC-STRUC) that
includes disease names, severity levels, probabilities, and anatomical
locations, ensuring that the dataset is both clinically relevant and
well-structured. We train an LLM-based model to generate standardized,
high-quality reports. To assess the generated reports, we propose a specialized
evaluation metric (S-Score) that not only measures disease prediction accuracy
but also evaluates the precision of disease-specific details, thus offering a
clinically meaningful metric for report quality that focuses on elements
critical to clinical decision-making and demonstrates a stronger alignment with
human assessments. Our approach highlights the effectiveness of structured
reports and the importance of a tailored evaluation metric for S-RRG, providing
a more clinically relevant measure of report quality.

</details>


### [166] [VLM4D: Towards Spatiotemporal Awareness in Vision Language Models](https://arxiv.org/abs/2508.02095)
*Shijie Zhou,Alexander Vilesov,Xuehai He,Ziyu Wan,Shuwang Zhang,Aditya Nagachandra,Di Chang,Dongdong Chen,Xin Eric Wang,Achuta Kadambi*

Main category: cs.CV

TL;DR: VLM4D基准的提出旨在弥补现有VLM在时空推理上的不足，评估结果揭示了模型在处理动态场景时的局限性，并探索了改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在整合语言和视觉推理方面表现出色，但在理解动态时空交互方面存在显著局限。人类能够轻松追踪和推理物体的运动、旋转和视角变化，而这些能力对于鲁棒的动态现实世界理解至关重要，但目前VLM却明显缺乏。

Method: 提出了VLM4D基准，用于评估VLM的时空推理能力。该基于包含各种真实和合成视频，以及精心设计的问题-答案对，重点关注平移和旋转运动、视角感知和运动连续性。通过对现有VLM的全面评估，并探索利用4D特征场重建和时空监督微调等方法来增强模型性能。

Result: 评估结果显示，现有VLM在时空推理方面与人类基线相比存在显著差距，凸显了其基本缺陷。模型在整合多重视觉线索和维持时间连贯性方面尤其困难。研究还表明，利用4D特征场重建和针对性的时空监督微调能够有效提升模型的时空理解能力。

Conclusion: 该研究旨在推动视觉语言模型（VLM）在动态环境中的空间和时间理解能力，以实现更强大、更可靠的视觉智能。

Abstract: Vision language models (VLMs) have shown remarkable capabilities in
integrating linguistic and visual reasoning but remain fundamentally limited in
understanding dynamic spatiotemporal interactions. Humans effortlessly track
and reason about object movements, rotations, and perspective shifts-abilities
essential for robust dynamic real-world understanding yet notably lacking in
current VLMs. In this paper, we introduce VLM4D, the first benchmark
specifically designed to evaluate the spatiotemporal reasoning capabilities of
VLMs. Our benchmark comprises diverse real-world and synthetic videos
accompanied by carefully curated question-answer pairs emphasizing
translational and rotational motions, perspective awareness, and motion
continuity. Through comprehensive evaluations of state-of-the-art open and
closed-source VLMs, we identify significant performance gaps compared to human
baselines, highlighting fundamental deficiencies in existing models. Extensive
analysis reveals that VLMs struggle particularly with integrating multiple
visual cues and maintaining temporal coherence. We further explore promising
directions, such as leveraging 4D feature field reconstruction and targeted
spatiotemporal supervised fine-tuning, demonstrating their effectiveness in
enhancing spatiotemporal comprehension. Our work aims to encourage deeper
exploration into improving VLMs' spatial and temporal grounding, paving the way
towards more capable and reliable visual intelligence for dynamic environments.

</details>


### [167] [AutoLoRA: Automatic LoRA Retrieval and Fine-Grained Gated Fusion for Text-to-Image Generation](https://arxiv.org/abs/2508.02107)
*Zhiwen Li,Zhongjie Duan,Die Chen,Cen Chen,Daoyuan Chen,Yaliang Li,Yingda Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的框架，通过基于权值编码的 LoRA 检索器和细粒度门控融合机制，解决了分布式开源 LoRA 模块的挑战，实现了语义驱动的 LoRA 检索和动态聚合，从而在图像生成方面取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有分布式开源 LoRA 模块在稀疏元数据注释、零样本适配能力要求和多 LoRA 融合策略的次优融合策略方面的三个关键挑战。

Method: 提出了一种新颖的框架，通过两个关键组件实现语义驱动的 LoRA 检索和动态聚合：(1) 基于权值编码的 LoRA 检索器，它在 LoRA 参数矩阵和文本提示之间建立共享语义空间，消除了对原始训练数据的依赖；(2) 细粒度门控融合机制，它计算跨网络层和扩散时间步的上下文特定融合权重，以在生成过程中最优地集成多个 LoRA 模块。

Result: 该方法在图像生成性能方面实现了显著的改进，从而促进了基础模型的可扩展和数据高效的增强。

Conclusion: 该框架通过标准化适配器集成，在碎片化的社区开发的 LoRA 之间建立了关键的桥梁，促进了可扩展的、数据高效的模型增强。

Abstract: Despite recent advances in photorealistic image generation through
large-scale models like FLUX and Stable Diffusion v3, the practical deployment
of these architectures remains constrained by their inherent intractability to
parameter fine-tuning. While low-rank adaptation (LoRA) have demonstrated
efficacy in enabling model customization with minimal parameter overhead, the
effective utilization of distributed open-source LoRA modules faces three
critical challenges: sparse metadata annotation, the requirement for zero-shot
adaptation capabilities, and suboptimal fusion strategies for multi-LoRA fusion
strategies. To address these limitations, we introduce a novel framework that
enables semantic-driven LoRA retrieval and dynamic aggregation through two key
components: (1) weight encoding-base LoRA retriever that establishes a shared
semantic space between LoRA parameter matrices and text prompts, eliminating
dependence on original training data, and (2) fine-grained gated fusion
mechanism that computes context-specific fusion weights across network layers
and diffusion timesteps to optimally integrate multiple LoRA modules during
generation. Our approach achieves significant improvement in image generation
perfermance, thereby facilitating scalable and data-efficient enhancement of
foundational models. This work establishes a critical bridge between the
fragmented landscape of community-developed LoRAs and practical deployment
requirements, enabling collaborative model evolution through standardized
adapter integration.

</details>


### [168] [DeflareMamba: Hierarchical Vision Mamba for Contextually Consistent Lens Flare Removal](https://arxiv.org/abs/2508.02113)
*Yihang Huang,Yuanfei Huang,Junhui Lin,Hua Huang*

Main category: cs.CV

TL;DR: DeflareMamba 是首个将状态空间模型应用于光晕去除任务的工作，通过分层框架和局部增强状态空间模型，实现了更完整和一致的光晕去除。


<details>
  <summary>Details</summary>
Motivation: 现有光晕去除方法在去除光晕的同时，难以保持上下文一致性，导致去除不完整和不一致。

Method: DeflareMamba 采用分层框架，通过不同的步长采样模式建立长程像素相关性，并利用局部增强状态空间模型同时保留局部细节。

Result: 实验证明 DeflareMamba 有效去除了散射和反射光晕等各种光晕伪影，同时保持了非光晕区域的自然外观。

Conclusion: DeflareMamba 通过分层框架和局部增强状态空间模型有效去除了各种类型的光晕伪影，同时保持了非光晕区域的自然外观，并且在下游应用中提高了视觉对象识别和跨模式语义理解能力。

Abstract: Lens flare removal remains an information confusion challenge in the
underlying image background and the optical flares, due to the complex optical
interactions between light sources and camera lens. While recent solutions have
shown promise in decoupling the flare corruption from image, they often fail to
maintain contextual consistency, leading to incomplete and inconsistent flare
removal. To eliminate this limitation, we propose DeflareMamba, which leverages
the efficient sequence modeling capabilities of state space models while
maintains the ability to capture local-global dependencies. Particularly, we
design a hierarchical framework that establishes long-range pixel correlations
through varied stride sampling patterns, and utilize local-enhanced state space
models that simultaneously preserves local details. To the best of our
knowledge, this is the first work that introduces state space models to the
flare removal task. Extensive experiments demonstrate that our method
effectively removes various types of flare artifacts, including scattering and
reflective flares, while maintaining the natural appearance of non-flare
regions. Further downstream applications demonstrate the capacity of our method
to improve visual object recognition and cross-modal semantic understanding.
Code is available at https://github.com/BNU-ERC-ITEA/DeflareMamba.

</details>


### [169] [Beyond RGB and Events: Enhancing Object Detection under Adverse Lighting with Monocular Normal Maps](https://arxiv.org/abs/2508.02127)
*Mingjie Liu,Hanqing Liu,Chuang Zhu*

Main category: cs.CV

TL;DR: NRE-Net 是一种创新的多模态物体检测方法，通过结合法线图、RGB 图像和事件数据，提高了在复杂光照条件下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决了现有方法在复杂光照条件下（如隧道反光）物体检测的误报问题，并探索了在不增加额外传感器的情况下进行缓解的方法。

Method: 提出了一种名为 NRE-Net 的新颖多模态检测框架，该框架包含两个关键模块：自适应双流融合模块 (ADFM)，用于融合 RGB 和法线图特征；事件模态感知融合模块 (EAFM)，用于适应事件数据的动态范围特性。

Result: 在 DSEC-Det-sub 和 PKU-DAVIS-SOD 数据集上进行了广泛评估，NRE-Net 在 DSEC-Det-sub 数据集上比基于帧的方法（如 YOLOX）的 mAP50 提高了 7.9%，比 SFNet 提高了 2.7%；在 PKU-DAVIS-SOD 数据集上比 SODFormer 提高了 7.1%。

Conclusion: NRE-Net 通过融合预测的法线图、RGB 图像和事件流，显著提高了在复杂光照条件下的物体检测精度，优于现有方法。

Abstract: Accurate object detection under adverse lighting conditions is critical for
real-world applications such as autonomous driving. Although neuromorphic event
cameras have been introduced to handle these scenarios, adverse lighting often
induces distracting reflections from tunnel walls or road surfaces, which
frequently lead to false obstacle detections. However, neither RGB nor event
data alone is robust enough to address these complexities, and mitigating these
issues without additional sensors remains underexplored. To overcome these
challenges, we propose leveraging normal maps, directly predicted from
monocular RGB images, as robust geometric cues to suppress false positives and
enhance detection accuracy. We introduce NRE-Net, a novel multi-modal detection
framework that effectively fuses three complementary modalities: monocularly
predicted surface normal maps, RGB images, and event streams. To optimize the
fusion process, our framework incorporates two key modules: the Adaptive
Dual-stream Fusion Module (ADFM), which integrates RGB and normal map features,
and the Event-modality Aware Fusion Module (EAFM), which adapts to the high
dynamic range characteristics of event data. Extensive evaluations on the
DSEC-Det-sub and PKU-DAVIS-SOD datasets demonstrate that NRE-Net significantly
outperforms state-of-the-art methods. Our approach achieves mAP50 improvements
of 7.9% and 6.1% over frame-based approaches (e.g., YOLOX), while surpassing
the fusion-based SFNet by 2.7% on the DSEC-Det-sub dataset and SODFormer by
7.1% on the PKU-DAVIS-SOD dataset.

</details>


### [170] [VDEGaussian: Video Diffusion Enhanced 4D Gaussian Splatting for Dynamic Urban Scenes Modeling](https://arxiv.org/abs/2508.02129)
*Yuru Xiao,Zihan Lin,Chao Lu,Deming Zhai,Kui Jiang,Wenbo Zhao,Wei Zhang,Junjun Jiang,Huanran Wang,Xianming Liu*

Main category: cs.CV

TL;DR: 提出了一种新的视频扩散增强4D高斯泼溅方法，用于改进动态场景建模，特别是在处理快速移动物体方面。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有神经辐射场和高斯泼溅方法在依赖预校准物体轨迹、准确建模快速移动物体以及处理时间不连续性方面的局限性。

Method: 提出了一种新颖的视频扩散增强4D高斯泼溅框架，通过联合时间戳优化策略和不确定性蒸馏方法来优化插值帧姿势并自适应地提取目标内容。

Result: 实验证明，该方法能够有效地处理快速移动物体，并在新视角合成方面取得了显著的性能提升。

Conclusion: 该方法显著提高了动态场景建模能力，尤其是在处理快速移动物体方面，在新视角合成方面比基线方法提高了约2 dB的PSNR增益。

Abstract: Dynamic urban scene modeling is a rapidly evolving area with broad
applications. While current approaches leveraging neural radiance fields or
Gaussian Splatting have achieved fine-grained reconstruction and high-fidelity
novel view synthesis, they still face significant limitations. These often stem
from a dependence on pre-calibrated object tracks or difficulties in accurately
modeling fast-moving objects from undersampled capture, particularly due to
challenges in handling temporal discontinuities. To overcome these issues, we
propose a novel video diffusion-enhanced 4D Gaussian Splatting framework. Our
key insight is to distill robust, temporally consistent priors from a test-time
adapted video diffusion model. To ensure precise pose alignment and effective
integration of this denoised content, we introduce two core innovations: a
joint timestamp optimization strategy that refines interpolated frame poses,
and an uncertainty distillation method that adaptively extracts target content
while preserving well-reconstructed regions. Extensive experiments demonstrate
that our method significantly enhances dynamic modeling, especially for
fast-moving objects, achieving an approximate PSNR gain of 2 dB for novel view
synthesis over baseline approaches.

</details>


### [171] [A Neural Quality Metric for BRDF Models](https://arxiv.org/abs/2508.02131)
*Behnaz Kavoosighafi,Rafal K. Mantiuk,Saghi Hajisharif,Ehsan Miandji,Jonas Unger*

Main category: cs.CV

TL;DR: 提出了一种新的基于感知的BRDF质量评估神经度量方法，在BRDF空间直接操作，无需渲染即可评估，并且比现有方法更符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 为了在照片级真实感渲染中准确评估双向反射分布函数（BRDF）模型的质量。传统方法使用的数值误差度量无法捕捉渲染图像中的感知差异。

Method: 提出了一种在BRDF空间中操作的、具有感知能力的神经质量度量方法。该方法使用一个紧凑的多层感知器（MLP），在包含测量和合成数据的BRDF数据集上进行训练，并使用经过感知验证的图像空间度量进行标注。该网络接收成对的参考和近似BRDF样本作为输入，并以“just-objectionable-difference”（JOD）分数来预测其感知质量。

Result: 该神经度量在与人类判断的相关性方面显著优于现有的BRDF空间度量。然而，其作为BRDF拟合损失函数的性能仍然有限。

Conclusion: 该神经度量为评估双向反射分布函数（BRDF）模型提供了一种有别于现有BRDF空间度量标准、并且基于感知的方法，尽管其作为BRDF拟合损失函数的性能有限。

Abstract: Accurately evaluating the quality of bidirectional reflectance distribution
function (BRDF) models is essential for photo-realistic rendering. Traditional
BRDF-space metrics often employ numerical error measures that fail to capture
perceptual differences evident in rendered images. In this paper, we introduce
the first perceptually informed neural quality metric for BRDF evaluation that
operates directly in BRDF space, eliminating the need for rendering during
quality assessment. Our metric is implemented as a compact multi-layer
perceptron (MLP), trained on a dataset of measured BRDFs supplemented with
synthetically generated data and labelled using a perceptually validated
image-space metric. The network takes as input paired samples of reference and
approximated BRDFs and predicts their perceptual quality in terms of
just-objectionable-difference (JOD) scores. We show that our neural metric
achieves significantly higher correlation with human judgments than existing
BRDF-space metrics. While its performance as a loss function for BRDF fitting
remains limited, the proposed metric offers a perceptually grounded alternative
for evaluating BRDF models.

</details>


### [172] [Free-MoRef: Instantly Multiplexing Context Perception Capabilities of Video-MLLMs within Single Inference](https://arxiv.org/abs/2508.02134)
*Kuo Wang,Quanlong Zheng,Junlin Xie,Yanhao Zhang,Jinguo Luo,Haonan Lu,Liang Lin,Fan Zhou,Guanbin Li*

Main category: cs.CV

TL;DR: Free-MoRef 是一种新颖的训练无关方法，通过将长视频分解为多个引用并使用 MoRef-attention 并行处理它们，然后融合信息，从而有效处理长视频，并在不损失性能或效率的情况下实现显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视频多模态大语言模型（Video-MLLM）在处理长视频时，由于底层大语言模型（LLM）的上下文长度限制，性能往往不佳。现有的解决方案，如 token 压缩或流式推理，会牺牲特征的精细度或推理效率。因此，需要一种有效的方法来全面理解更长的视频输入。

Method: Free-MoRef 是一种训练无关的方法，它将视频帧的 token 重构为多个短序列作为多参考。然后，引入 MoRef-attention 机制，该机制并行地从多个参考块中收集线索，以汇总统一的查询激活。在 LLM 的影子层之后，通过参考融合步骤将来自并行块的关键 token 组合成最终的混合推理序列，以弥补 MoRef-attention 中忽略的跨参考视觉交互。

Result: Free-MoRef 实现了对 2 倍到 8 倍更长输入帧的全面感知，而无需进行压缩，并且保持了即时响应。在 VideoMME、MLVU 和 LongVideoBench 数据集上的实验表明，该方法在推理多路复用的上下文长度方面，计算成本更低，同时带来了显著的性能提升，并且优于专门训练的长视频-MLLM。

Conclusion: Free-MoRef 通过将长视频帧分割成多个短序列，并利用 MoRef-attention 并行聚合信息，最后通过参考融合步骤生成统一的推理序列，在不牺牲特征粒度或推理效率的情况下，实现了对更长视频输入的全面理解。该方法在 VideoMME、MLVU 和 LongVideoBench 等基准测试中表现出色，在单 A100 GPU 上可处理 2 到 8 倍更长的输入帧，并带来了显著的性能提升，甚至超越了专门为长视频训练的模型。

Abstract: Video Multimodal Large Language Models~(Video-MLLM) have achieved remarkable
advancements in video understanding tasks. However, constrained by the context
length limitation in the underlying LLMs, existing Video-MLLMs typically
exhibit suboptimal performance on long video scenarios. To understand extended
input frames, common solutions span token compression and streaming inference
techniques, which sacrifice feature granularity or inference efficiency.
Differently, to efficiently achieve comprehensive understanding of longer frame
inputs, we draw ideas from MoE and propose a training-free approach
\textbf{Free-MoRef}, which instantly multiplexes the context perception
capabilities of Video-MLLMs within one inference pass. Specifically, Free-MoRef
reconstructs the vision tokens into several short sequences as
multi-references. Subsequently, we introduce MoRef-attention, which gathers
clues from the multi-reference chunks in parallel to summarize unified query
activations. After the shadow layers in LLMs, a reference fusion step is
derived to compose a final mixed reasoning sequence with key tokens from
parallel chunks, which compensates the cross-reference vision interactions that
are neglected in MoRef-attention. By splitting and fusing the long vision token
sequences, Free-MoRef achieves improved performance under much lower computing
costs in reasoning multiplexed context length, demonstrating strong efficiency
and effectiveness. Experiments on VideoMME, MLVU, LongVideoBench show that
Free-MoRef achieves full perception of 2$\times$ to 8$\times$ longer input
frames without compression on a single A100 GPU while keeping instant
responses, thereby bringing significant performance gains, even surpassing
dedicatedly trained long-video-MLLMs. Codes are available at
https://github.com/wkfdb/Free-MoRef

</details>


### [173] [AID4AD: Aerial Image Data for Automated Driving Perception](https://arxiv.org/abs/2508.02140)
*Daniel Lengerer,Mathias Pechinger,Klaus Bogenberger,Carsten Markgraf*

Main category: cs.CV

TL;DR: 我们发布了AID4AD数据集，通过将航空影像与nuScenes数据集进行精确的空间对齐，提升了自动驾驶汽车在地图构建和运动预测任务中的表现，尤其是在高精地图不可用时。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶汽车感知任务中，高清地图可用性差、成本高以及信息更新不及时等问题，探索利用空间对齐的航空影像作为替代或补充的环境信息来源。

Method: 提出了一种利用SLAM点云地图对齐高分辨率航空影像的流程，并进行了人工质量控制，以确保空间保真度，构建了AID4AD数据集。

Result: AID4AD数据集提升了地图构建的准确性15-23%，并使轨迹预测性能提高了2%。

Conclusion: AID4AD数据集的引入，利用空间对齐的航空影像，能够有效提升自动驾驶汽车在在线地图构建和运动预测任务上的表现，尤其在缺乏高清地图的场景下，显示出航空影像作为环境信息的潜力。

Abstract: This work investigates the integration of spatially aligned aerial imagery
into perception tasks for automated vehicles (AVs). As a central contribution,
we present AID4AD, a publicly available dataset that augments the nuScenes
dataset with high-resolution aerial imagery precisely aligned to its local
coordinate system. The alignment is performed using SLAM-based point cloud maps
provided by nuScenes, establishing a direct link between aerial data and
nuScenes local coordinate system. To ensure spatial fidelity, we propose an
alignment workflow that corrects for localization and projection distortions. A
manual quality control process further refines the dataset by identifying a set
of high-quality alignments, which we publish as ground truth to support future
research on automated registration. We demonstrate the practical value of
AID4AD in two representative tasks: in online map construction, aerial imagery
serves as a complementary input that improves the mapping process; in motion
prediction, it functions as a structured environmental representation that
replaces high-definition maps. Experiments show that aerial imagery leads to a
15-23% improvement in map construction accuracy and a 2% gain in trajectory
prediction performance. These results highlight the potential of aerial imagery
as a scalable and adaptable source of environmental context in automated
vehicle systems, particularly in scenarios where high-definition maps are
unavailable, outdated, or costly to maintain. AID4AD, along with evaluation
code and pretrained models, is publicly released to foster further research in
this direction: https://github.com/DriverlessMobility/AID4AD.

</details>


### [174] [TrackletGait: A Robust Framework for Gait Recognition in the Wild](https://arxiv.org/abs/2508.02143)
*Shaoxiong Zhang,Jinkai Zheng,Shangdong Zhu,Chenggang Yan*

Main category: cs.CV

TL;DR: TrackletGait框架通过随机短片采样、基于Haar小波的下采样和困难样本排除三元组损失来解决野外步态识别中的挑战，并在Gait3D和GREW数据集上取得了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前的步态识别方法在真实世界的监控场景中仍然面临挑战，因为这些场景通常会遇到非周期性和被遮挡的轮廓序列，而传统方法依赖于周期性的步态周期和受控环境，难以应对这些情况。

Method: 提出了一种名为TrackletGait的新框架，该框架包含三种新方法：1. 随机短片采样：这是现有采样方法的泛化，用于捕捉多样的行走模式。2. 基于Haar小波的下采样：用于在空间下采样过程中保留信息。3. 困难样本排除三元组损失：通过丢弃困难的三元组样本来排除低质量的轮廓。

Result: TrackletGait在Gait3D和GREW数据集上取得了最先进的结果，分别达到了77.8%和80.4%的排名第一的准确率，并且参数量仅为10.3M。此外，还进行了广泛的实验来进一步研究影响野外步态识别的因素。

Conclusion: TrackletGait在Gait3D和GREW数据集上分别达到了77.8%和80.4%的排名第一的准确率，并且只使用了10.3M的主干参数，在野外场景下的步态识别方面取得了最先进的结果。

Abstract: Gait recognition aims to identify individuals based on their body shape and
walking patterns. Though much progress has been achieved driven by deep
learning, gait recognition in real-world surveillance scenarios remains quite
challenging to current methods. Conventional approaches, which rely on periodic
gait cycles and controlled environments, struggle with the non-periodic and
occluded silhouette sequences encountered in the wild. In this paper, we
propose a novel framework, TrackletGait, designed to address these challenges
in the wild. We propose Random Tracklet Sampling, a generalization of existing
sampling methods, which strikes a balance between robustness and representation
in capturing diverse walking patterns. Next, we introduce Haar Wavelet-based
Downsampling to preserve information during spatial downsampling. Finally, we
present a Hardness Exclusion Triplet Loss, designed to exclude low-quality
silhouettes by discarding hard triplet samples. TrackletGait achieves
state-of-the-art results, with 77.8 and 80.4 rank-1 accuracy on the Gait3D and
GREW datasets, respectively, while using only 10.3M backbone parameters.
Extensive experiments are also conducted to further investigate the factors
affecting gait recognition in the wild.

</details>


### [175] [AURORA: Augmented Understanding via Structured Reasoning and Reinforcement Learning for Reference Audio-Visual Segmentation](https://arxiv.org/abs/2508.02149)
*Ziyang Luo,Nian Liu,Fahad Shahbaz Khan,Junwei Han*

Main category: cs.CV

TL;DR: AURORA通过思维链提示、分割特征蒸馏和两阶段训练（纠正性反思+强化学习）来提升Ref-AVS任务的推理和分割性能，并取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有的参考音频-视觉分割（Ref-AVS）方法往往缺乏真正的语义理解能力，容易陷入固定的推理模式，并且联合训练推理和分割会影响像素级精度。为了解决这些问题，需要一个能够增强真实推理和语言理解能力的框架。

Method: 本文提出了一种名为AURORA的新型框架，该框架采用结构化的思维链（CoT）提示机制来指导模型的逐步推理过程，并引入了新颖的分割特征蒸馏损失来整合推理能力而不牺牲像素级精度。此外，还设计了两阶段训练策略：首先是“纠正性反思式训练”阶段，利用自我纠正来提高推理路径质量；然后是强化学习阶段，利用群体奖励策略优化（GRPO）来提高在复杂场景下的鲁棒性。

Result: AURORA实现了最先进的Ref-AVS基准性能，并在非参考分割任务上展现了良好的泛化能力。

Conclusion: AURORA框架在Ref-AVS任务上取得了最先进的性能，并且能有效地泛化到非参考分割任务。

Abstract: Reference Audio-Visual Segmentation (Ref-AVS) tasks challenge models to
precisely locate sounding objects by integrating visual, auditory, and textual
cues. Existing methods often lack genuine semantic understanding, tending to
memorize fixed reasoning patterns. Furthermore, jointly training for reasoning
and segmentation can compromise pixel-level precision. To address these issues,
we introduce AURORA, a novel framework designed to enhance genuine reasoning
and language comprehension in reference audio-visual segmentation. We employ a
structured Chain-of-Thought (CoT) prompting mechanism to guide the model
through a step-by-step reasoning process and introduce a novel segmentation
feature distillation loss to effectively integrate these reasoning abilities
without sacrificing segmentation performance. To further cultivate the model's
genuine reasoning capabilities, we devise a further two-stage training
strategy: first, a ``corrective reflective-style training" stage utilizes
self-correction to enhance the quality of reasoning paths, followed by
reinforcement learning via Group Reward Policy Optimization (GRPO) to bolster
robustness in challenging scenarios. Experiments demonstrate that AURORA
achieves state-of-the-art performance on Ref-AVS benchmarks and generalizes
effectively to unreferenced segmentation.

</details>


### [176] [AttriCtrl: Fine-Grained Control of Aesthetic Attribute Intensity in Diffusion Models](https://arxiv.org/abs/2508.02151)
*Die Chen,Zhongjie Duan,Zhiwen Li,Cen Chen,Daoyuan Chen,Yaliang Li,Yinda Chen*

Main category: cs.CV

TL;DR: AttriCtrl 是一个即插即用的框架，用于精确、连续地控制文本到图像生成中的美学属性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在精细控制美学属性方面存在挑战，尤其是当用户需要连续和特定强度的调整时，现有的方法依赖于模糊的文本提示或昂贵的人类偏好数据。

Method: AttriCtrl 通过利用预训练视觉-语言模型的语义相似性来量化抽象美学，并使用轻量级值编码器将标量强度映射到基于扩散的生成中的可学习嵌入。

Result: AttriCtrl 实现了对单个属性的准确控制以及灵活的多属性组合，并且与流行的开源可控生成框架完全兼容，展示了强大的集成能力和实用的效用。

Conclusion: AttriCtrl 实现了精确、连续的美学属性控制，易于集成，并能在各种生成场景中实现灵活的多属性组合。

Abstract: Recent breakthroughs in text-to-image diffusion models have significantly
enhanced both the visual fidelity and semantic controllability of generated
images. However, fine-grained control over aesthetic attributes remains
challenging, especially when users require continuous and intensity-specific
adjustments. Existing approaches often rely on vague textual prompts, which are
inherently ambiguous in expressing both the aesthetic semantics and the desired
intensity, or depend on costly human preference data for alignment, limiting
their scalability and practicality. To address these limitations, we propose
AttriCtrl, a plug-and-play framework for precise and continuous control of
aesthetic attributes. Specifically, we quantify abstract aesthetics by
leveraging semantic similarity from pre-trained vision-language models, and
employ a lightweight value encoder that maps scalar intensities in $[0,1]$ to
learnable embeddings within diffusion-based generation. This design enables
intuitive and customizable aesthetic manipulation, with minimal training
overhead and seamless integration into existing generation pipelines. Extensive
experiments demonstrate that AttriCtrl achieves accurate control over
individual attributes as well as flexible multi-attribute composition.
Moreover, it is fully compatible with popular open-source controllable
generation frameworks, showcasing strong integration capability and practical
utility across diverse generation scenarios.

</details>


### [177] [Efficient Chambolle-Pock based algorithms for Convoltional sparse representation](https://arxiv.org/abs/2508.02152)
*Yi Liu,Junjing Li,Yang Chen,Haowei Tang,Pengcheng Zhang,Tianling Lyu,Zhiguo Gui*

Main category: cs.CV

TL;DR: 提出了一种基于Chambolle-Pock框架的新型卷积稀疏表示方法，无需手动调参且收敛速度更快，在图像去噪方面效果优于现有ADMM方法。


<details>
  <summary>Details</summary>
Motivation: 卷积稀疏表示（CSR）因其具有平移不变性的良好特性而引起了图像处理领域的关注。CSR的内容通常包括卷积稀疏编码（CSC）和卷积字典学习（CDL），许多研究都集中在如何解决相应的优化问题。目前，最有效的CSC优化方案是基于交替方向乘子法（ADMM）的。然而，基于ADMM的方法涉及需要仔细选择的罚分参数，不当的参数选择可能导致不收敛或收敛速度非常慢。

Method: 提出了一种新颖的、快速且高效的使用Chambolle-Pock(CP)框架的方法，该方法在求解过程中不需要额外的手动选择参数，并且具有更快的收敛速度。此外，提出将系数图的各向异性全变分惩罚用于CSC，并应用CP算法求解。还将CP框架应用于求解相应的CDL问题。

Result: 所提出的CSC算法在去除高斯噪声污染图像的噪声方面优于最新的基于ADMM的方法，并且在无噪声图像方面可以取得与基于ADMM的方法相媲美的使用结果。

Conclusion: 实验表明，所提出的CSC算法在去除高斯噪声污染图像的噪声方面优于最新的基于ADMM的方法，并且在无噪声图像方面可以取得与基于ADMM的方法相媲美的使用结果。

Abstract: Recently convolutional sparse representation (CSR), as a sparse
representation technique, has attracted increasing attention in the field of
image processing, due to its good characteristic of translate-invariance. The
content of CSR usually consists of convolutional sparse coding (CSC) and
convolutional dictionary learning (CDL), and many studies focus on how to solve
the corresponding optimization problems. At present, the most efficient
optimization scheme for CSC is based on the alternating direction method of
multipliers (ADMM). However, the ADMM-based approach involves a penalty
parameter that needs to be carefully selected, and improper parameter selection
may result in either no convergence or very slow convergence. In this paper, a
novel fast and efficient method using Chambolle-Pock(CP) framework is proposed,
which does not require extra manual selection parameters in solving processing,
and has faster convergence speed. Furthermore, we propose an anisotropic total
variation penalty of the coefficient maps for CSC and apply the CP algorithm to
solve it. In addition, we also apply the CP framework to solve the
corresponding CDL problem. Experiments show that for noise-free image the
proposed CSC algorithms can achieve rival results of the latest ADMM-based
approach, while outperforms in removing noise from Gaussian noise pollution
image.

</details>


### [178] [DreamPainter: Image Background Inpainting for E-commerce Scenarios](https://arxiv.org/abs/2508.02155)
*Sijie Zhao,Jing Cheng,Yaoyao Wu,Hao Xu,Shaohui Jiao*

Main category: cs.CV

TL;DR: DreamPainter是一个创新的电商背景生成框架，它结合了文本和图像信息，解决了现有方法的不足，并在实验中取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 电商场景中的背景生成任务面临两大挑战：1. 生成的产品需要与给定产品输入保持一致，并具备合理的空间布局、和谐的阴影和反射。2. 仅依赖文本提示进行图像控制存在局限，视觉信息整合以实现精确控制的研究尚不充分。

Method: 提出了一种名为DreamPainter的新型框架，该框架结合了文本提示和参考图像信息作为控制信号，并使用DreamEcom-400K数据集进行训练和评估。

Result: 实验证明，DreamPainter在产品一致性和融合文本/参考图像信息方面表现出色，显著优于现有技术水平。

Conclusion: DreamPainter框架在电商背景生成任务中显著优于现有方法，能够同时保持产品一致性并有效融合文本和参考图像信息。

Abstract: Although diffusion-based image genenation has been widely explored and
applied, background generation tasks in e-commerce scenarios still face
significant challenges. The first challenge is to ensure that the generated
products are consistent with the given product inputs while maintaining a
reasonable spatial arrangement, harmonious shadows, and reflections between
foreground products and backgrounds. Existing inpainting methods fail to
address this due to the lack of domain-specific data. The second challenge
involves the limitation of relying solely on text prompts for image control, as
effective integrating visual information to achieve precise control in
inpainting tasks remains underexplored. To address these challenges, we
introduce DreamEcom-400K, a high-quality e-commerce dataset containing accurate
product instance masks, background reference images, text prompts, and
aesthetically pleasing product images. Based on this dataset, we propose
DreamPainter, a novel framework that not only utilizes text prompts for control
but also flexibly incorporates reference image information as an additional
control signal. Extensive experiments demonstrate that our approach
significantly outperforms state-of-the-art methods, maintaining high product
consistency while effectively integrating both text prompt and reference image
information.

</details>


### [179] [Unified Category-Level Object Detection and Pose Estimation from RGB Images using 3D Prototypes](https://arxiv.org/abs/2508.02157)
*Tom Fischer,Xiaojie Zhang,Eddy Ilg*

Main category: cs.CV

TL;DR: 提出了一种统一的检测和姿态估计模型，仅使用RGB图像，在REAL275数据集上取得了state-of-the-art的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的category-level方法依赖于RGB-D输入（并非总是可用）或使用两阶段方法（分别使用检测和姿态估计的模型和表示）。

Method: 利用神经网格模型、学习到的特征和多模型RANSAC，将detection和pose estimation整合到一个单一框架中，仅使用RGB图像输入。

Result: 在REAL275数据集上实现了state-of-the-art的RGB category-level pose estimation结果，在所有scale-agnostic指标上平均提高了22.9%。

Conclusion: 作者提出的统一模型在REAL275数据集的category-level pose estimation任务上取得了当前最优结果，在所有scale-agnostic指标上平均提高了22.9%，并且证明了该模型比single-stage基线方法更具鲁棒性。

Abstract: Recognizing objects in images is a fundamental problem in computer vision.
Although detecting objects in 2D images is common, many applications require
determining their pose in 3D space. Traditional category-level methods rely on
RGB-D inputs, which may not always be available, or employ two-stage approaches
that use separate models and representations for detection and pose estimation.
For the first time, we introduce a unified model that integrates detection and
pose estimation into a single framework for RGB images by leveraging neural
mesh models with learned features and multi-model RANSAC. Our approach achieves
state-of-the-art results for RGB category-level pose estimation on REAL275,
improving on the current state-of-the-art by 22.9% averaged across all
scale-agnostic metrics. Finally, we demonstrate that our unified method
exhibits greater robustness compared to single-stage baselines. Our code and
models are available at
https://github.com/Fischer-Tom/unified-detection-and-pose-estimation.

</details>


### [180] [After the Party: Navigating the Mapping From Color to Ambient Lighting](https://arxiv.org/abs/2508.02168)
*Florin-Alexandru Vasluianu,Tim Seizinger,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: CL3AN是一个大规模、高分辨率的数据集，用于在多个彩色光源下恢复图像到其环境归一化版本。该研究提出了一种新颖的学习框架，通过显式的色度和亮度分量引导，借鉴Retinex模型原理，实现了光照与反射率的精确解耦，解决了现有方法在处理复杂照明时遇到的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多光源、遮挡、复杂材质交互等实际照明场景时，往往过度简化，假设单光源或均匀照明，未能解决这些复杂性。这导致现有方法在处理复杂照明时会产生光照不一致、纹理泄露、颜色失真等问题。

Method: 提出了一种新颖的学习框架，该框架利用显式的色度和亮度分量引导，借鉴Retinex模型的原理，以实现光照与反射率的精确解耦。

Result: CL3AN数据集的基准测试表明，现有方法在光照解耦方面存在局限性。所提出的方法在现有基准和CL3AN数据集上进行了广泛评估，证明了其有效性，在非均匀彩色光照和材料特定反射率变化下具有更强的鲁棒性，同时计算成本具有竞争力。

Conclusion: CL3AN通过显式色度和亮度分量引导，借鉴Retinex模型原理，实现了光照与反射率的分离，在非均匀彩色光照和特定材料反射率变化的条件下，表现出增强的鲁棒性，同时保持了具有竞争力的计算成本。

Abstract: Illumination in practical scenarios is inherently complex, involving colored
light sources, occlusions, and diverse material interactions that produce
intricate reflectance and shading effects. However, existing methods often
oversimplify this challenge by assuming a single light source or uniform,
white-balanced lighting, leaving many of these complexities unaddressed.In this
paper, we introduce CL3AN, the first large-scale, high-resolution dataset of
its kind designed to facilitate the restoration of images captured under
multiple Colored Light sources to their Ambient-Normalized counterparts.
Through benchmarking, we find that leading approaches often produce artifacts,
such as illumination inconsistencies, texture leakage, and color distortion,
primarily due to their limited ability to precisely disentangle illumination
from reflectance. Motivated by this insight, we achieve such a desired
decomposition through a novel learning framework that leverages explicit
chromaticity and luminance components guidance, drawing inspiration from the
principles of the Retinex model. Extensive evaluations on existing benchmarks
and our dataset demonstrate the effectiveness of our approach, showcasing
enhanced robustness under non-homogeneous color lighting and material-specific
reflectance variations, all while maintaining a highly competitive
computational cost. The benchmark, codes, and models are available at
www.github.com/fvasluianu97/RLN2.

</details>


### [181] [GaussianCross: Cross-modal Self-supervised 3D Representation Learning via Gaussian Splatting](https://arxiv.org/abs/2508.02172)
*Lei Yao,Yi Wang,Yi Zhang,Moyun Liu,Lap-Pui Chau*

Main category: cs.CV

TL;DR: GaussianCross通过整合3D高斯泼溅技术，解决现有3D点表示学习中的模型坍塌和结构信息不足问题。该方法在点云预训练和特征提取方面表现出色，显著提高了参数和数据效率，并在多项基准测试中取得了优于现有方法的性能，尤其在泛化能力方面有突出表现。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景理解方法在点表示方面存在模型坍塌和结构信息不足的问题，原因是点区分难度不够，导致表达不可靠且性能不佳。本文旨在通过引入GaussianCross来解决这些挑战。

Method: GaussianCross是一种新颖的跨模态自监督3D表示学习架构，它整合了前馈3D高斯泼溅（3DGS）技术。该方法首先将尺度不一致的3D点云转换为统一的立方体归一化高斯表示，保留所有细节，从而实现稳定且可泛化的预训练。随后，引入三属性自适应蒸馏泼溅模块构建3D特征场，促进外观、几何和语义线索的协同捕捉，以维持跨模态一致性。

Result: GaussianCross在ScanNet、ScanNet200和S3DIS基准测试中表现出显著的参数和数据效率，通过线性探测和有限数据训练均优于最先进方法。在ScanNet200语义和实例分割任务上，通过完全微调分别提高了9.3%的mIoU和6.1%的AP$_{50}$，证明了其有效性和强大的泛化能力。

Conclusion: GaussianCross在ScanNet、ScanNet200和S3DIS等基准测试中表现出色，尤其在参数和数据效率方面，通过线性探测（<0.1%参数）和有限数据训练（1%场景）均优于现有最先进方法。此外，GaussianCross在ScanNet200语义和实例分割任务上，通过完全微调分别提高了9.3%的mIoU和6.1%的AP$_{50}$，证明了其有效性和强大的泛化能力。

Abstract: The significance of informative and robust point representations has been
widely acknowledged for 3D scene understanding. Despite existing
self-supervised pre-training counterparts demonstrating promising performance,
the model collapse and structural information deficiency remain prevalent due
to insufficient point discrimination difficulty, yielding unreliable
expressions and suboptimal performance. In this paper, we present
GaussianCross, a novel cross-modal self-supervised 3D representation learning
architecture integrating feed-forward 3D Gaussian Splatting (3DGS) techniques
to address current challenges. GaussianCross seamlessly converts
scale-inconsistent 3D point clouds into a unified cuboid-normalized Gaussian
representation without missing details, enabling stable and generalizable
pre-training. Subsequently, a tri-attribute adaptive distillation splatting
module is incorporated to construct a 3D feature field, facilitating synergetic
feature capturing of appearance, geometry, and semantic cues to maintain
cross-modal consistency. To validate GaussianCross, we perform extensive
evaluations on various benchmarks, including ScanNet, ScanNet200, and S3DIS. In
particular, GaussianCross shows a prominent parameter and data efficiency,
achieving superior performance through linear probing (<0.1% parameters) and
limited data training (1% of scenes) compared to state-of-the-art methods.
Furthermore, GaussianCross demonstrates strong generalization capabilities,
improving the full fine-tuning accuracy by 9.3% mIoU and 6.1% AP$_{50}$ on
ScanNet200 semantic and instance segmentation tasks, respectively, supporting
the effectiveness of our approach. The code, weights, and visualizations are
publicly available at
\href{https://rayyoh.github.io/GaussianCross/}{https://rayyoh.github.io/GaussianCross/}.

</details>


### [182] [Deep classification algorithm for De-identification of DICOM medical images](https://arxiv.org/abs/2508.02177)
*Bufano Michele,Kotter Elmar*

Main category: cs.CV

TL;DR: 开发了一个Python算法，用于去标识化DICOM文件中的PII和PHI信息。该算法基于HIPAA的安全港方法，并允许用户自定义参数以适应不同情况。实验结果表明，该算法能有效识别和处理敏感信息，适用于日常使用和研究。


<details>
  <summary>Details</summary>
Motivation: 为了满足法律法规（如HIPAA）的要求，隐藏或移除DICOM文件中的个人身份信息（PII）和个人健康信息（PHI）是医学图像研究中的一个基本环节。即使是全脸照片等图像也被视为受保护的健康信息，需要进行去标识化处理。

Method: 基于HIPAA定义的安全港方法，实现了一个算法，该算法使用输入的可自定义参数来分类和识别DICOM标签。

Result: 该算法成功识别出DICOM文件头和像素数据中包含的敏感信息，如姓名、病史、个人数据和机构信息。

Conclusion: 我们开发了一个能够对DICOM文件中的信息进行分类的Python算法。使用可自定义的输入参数，用户可以根据具体情况（例如语言）定制整个过程，这使得该程序在日常使用和研究方面都非常有前景。

Abstract: Background : De-identification of DICOM (Digital Imaging and Communi-cations
in Medicine) files is an essential component of medical image research.
Personal Identifiable Information (PII) and/or Personal Health Identifying
Information (PHI) need to be hidden or removed due to legal reasons. According
to the Health Insurance Portability and Accountability Act (HIPAA) and privacy
rules, also full-face photographic images and any compa-rable images are direct
identifiers and are considered protected health information that also need to
be de-identified. Objective : The study aimed to implement a method that permit
to de-identify the PII and PHI information present in the header and burned on
the pixel data of DICOM. Methods : To execute the de-identification, we
implemented an algorithm based on the safe harbor method, defined by HIPAA. Our
algorithm uses input customizable parameter to classify and then possibly
de-identify individual DICOM tags. Results : The most sensible information,
like names, history, personal data and institution were successfully
recognized. Conclusions : We developed a python algorithm that is able to
classify infor-mation present in a DICOM file. The flexibility provided by the
use of customi-zable input parameters, which allow the user to customize the
entire process de-pending on the case (e.g., the language), makes the entire
program very promis-ing for both everyday use and research purposes. Our code
is available at https://github.com/rtdicomexplorer/deep_deidentification.

</details>


### [183] [Weakly Supervised Multimodal Temporal Forgery Localization via Multitask Learning](https://arxiv.org/abs/2508.02179)
*Wenbo Xu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: 提出WMMT框架，采用多任务学习和专家混合结构，利用弱监督信号实现细粒度的时间伪造局部化，性能媲美全监督方法。


<details>
  <summary>Details</summary>
Motivation: 深度伪造视频的传播引发了信任危机并损害了社会稳定，但目前缺乏对弱监督多模态细粒度时间伪造局部化（WS-MTFL）的系统性研究。

Method: 提出了一种新颖的多任务学习框架WMMT，该框架通过将视觉和音频的二元分类任务整合为多任务学习，实现了仅使用视频级注释的弱监督多模态细粒度伪造检测和时间局部化。WMMT利用了专家混合结构来适应性地选择特征和定位头，并通过具有时间属性保持注意机制的特征增强模块来识别跨模态特征偏差。此外，还提出了一种可扩展的偏差感知损失，以扩大伪造样本相邻片段的偏差并减小真实样本的偏差。

Result: WMMT在弱监督多模态细粒度时间伪造局部化方面取得了优于现有方法的性能。

Conclusion: WMMT在多个评估指标上取得了与全监督方法相媲美的结果，证明了多任务学习在WS-MTFL中的有效性。

Abstract: The spread of Deepfake videos has caused a trust crisis and impaired social
stability. Although numerous approaches have been proposed to address the
challenges of Deepfake detection and localization, there is still a lack of
systematic research on the weakly supervised multimodal fine-grained temporal
forgery localization (WS-MTFL). In this paper, we propose a novel weakly
supervised multimodal temporal forgery localization via multitask learning
(WMMT), which addresses the WS-MTFL under the multitask learning paradigm. WMMT
achieves multimodal fine-grained Deepfake detection and temporal partial
forgery localization using merely video-level annotations. Specifically, visual
and audio modality detection are formulated as two binary classification tasks.
The multitask learning paradigm is introduced to integrate these tasks into a
multimodal task. Furthermore, WMMT utilizes a Mixture-of-Experts structure to
adaptively select appropriate features and localization head, achieving
excellent flexibility and localization precision in WS-MTFL. A feature
enhancement module with temporal property preserving attention mechanism is
proposed to identify the intra- and inter-modality feature deviation and
construct comprehensive video features. To further explore the temporal
information for weakly supervised learning, an extensible deviation perceiving
loss has been proposed, which aims to enlarge the deviation of adjacent
segments of the forged samples and reduce the deviation of genuine samples.
Extensive experiments demonstrate the effectiveness of multitask learning for
WS-MTFL, and the WMMT achieves comparable results to fully supervised
approaches in several evaluation metrics.

</details>


### [184] [Test-Time Model Adaptation for Quantized Neural Networks](https://arxiv.org/abs/2508.02180)
*Zeshuai Deng,Guohao Chen,Shuaicheng Niu,Hui Luo,Shuhai Zhang,Yifan Yang,Renjie Chen,Wei Luo,Mingkui Tan*

Main category: cs.CV

TL;DR: 本文提出了一种名为ZOA的持续性零阶自适应框架，用于解决量化深度学习模型在面对域偏移时的性能下降问题。ZOA仅需两次前向传播即可完成自适应，并结合域知识管理方案以提高效率和知识复用性。实验证明，ZOA在ImageNet-C数据集上能显著提升量化ViT-B模型的性能。


<details>
  <summary>Details</summary>
Motivation: 量化模型在动态环境中（例如，具有潜在的域偏移）常常会遭受严重的性能下降，而且这种下降比全精度模型更明显。现有的测试时自适应（TTA）方法通常不适用于量化模型，因为它们依赖于梯度反向传播，而量化模型由于梯度消失以及内存和延迟的限制不支持该操作。因此，本文旨在解决量化模型的TTA问题，以高效地提高其鲁棒性和泛化能力。

Method: 本文提出了一种持续性零阶自适应（ZOA）框架，该框架仅使用两次前向传播即可实现高效的模型自适应，并提出了一种域知识管理方案来存储和重用不同的域知识，以减少干扰和促进知识积累。

Result: 在三种经典架构（包括量化Transformer和CNN模型）上的实验结果表明，本文提出的方法在量化模型自适应方面具有优越性。在量化W6A6 ViT-B模型上，ZOA在ImageNet-C数据集上的表现比最先进的FOA方法提高了5.0%。

Conclusion: 本文提出的持续性零阶自适应（ZOA）框架能够有效地适应量化模型，只需两次前向传播即可完成，从而消除了现有方法的计算负担。此外，本文提出的域知识管理方案可以以可忽略的内存消耗存储和重用不同的域知识，减少了不同域知识的干扰，并促进了长期自适应过程中的知识积累。实验结果表明，ZOA在量化W6A6 ViT-B模型在ImageNet-C数据集上比最先进的FOA方法提高了5.0%。

Abstract: Quantizing deep models prior to deployment is a widely adopted technique to
speed up inference for various real-time applications, such as autonomous
driving. However, quantized models often suffer from severe performance
degradation in dynamic environments with potential domain shifts and this
degradation is significantly more pronounced compared with their full-precision
counterparts, as shown by our theoretical and empirical illustrations. To
address the domain shift problem, test-time adaptation (TTA) has emerged as an
effective solution by enabling models to learn adaptively from test data.
Unfortunately, existing TTA methods are often impractical for quantized models
as they typically rely on gradient backpropagation--an operation that is
unsupported on quantized models due to vanishing gradients, as well as memory
and latency constraints. In this paper, we focus on TTA for quantized models to
improve their robustness and generalization ability efficiently. We propose a
continual zeroth-order adaptation (ZOA) framework that enables efficient model
adaptation using only two forward passes, eliminating the computational burden
of existing methods. Moreover, we propose a domain knowledge management scheme
to store and reuse different domain knowledge with negligible memory
consumption, reducing the interference of different domain knowledge and
fostering the knowledge accumulation during long-term adaptation. Experimental
results on three classical architectures, including quantized transformer-based
and CNN-based models, demonstrate the superiority of our methods for quantized
model adaptation. On the quantized W6A6 ViT-B model, our ZOA is able to achieve
a 5.0\% improvement over the state-of-the-art FOA on ImageNet-C dataset. The
source code is available at https://github.com/DengZeshuai/ZOA.

</details>


### [185] [Failure Cases Are Better Learned But Boundary Says Sorry: Facilitating Smooth Perception Change for Accuracy-Robustness Trade-Off in Adversarial Training](https://arxiv.org/abs/2508.02186)
*Yanyun Wang,Li Liu*

Main category: cs.CV

TL;DR: 本研究认为对抗训练中的准确率-鲁棒性权衡问题源于对困难对抗样本的“过度学习”，而非“学习不足”。通过提出“鲁棒感知”目标和RPAT方法，鼓励模型感知随扰动平滑变化，从而有效缓解了这一权衡问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的对抗训练（AT）方法在提升深度神经网络（DNN）鲁棒性的同时，会引发干净准确率和对抗鲁棒性之间的权衡。现有观点认为这是由于模型对困难对抗样本学习不足导致决策边界复杂化。本研究揭示了一个相反的观点：过度学习困难对抗样本（即模型不将扰动视为噪声，而是过度关注其感知一致性）才会恶化决策边界，导致权衡问题。

Method: 提出了一种名为“鲁棒感知”（Robust Perception）的新型对抗训练目标，并基于此开发了“鲁棒感知对抗训练”（RPAT）方法。该方法旨在鼓励模型感知随着输入扰动的平滑变化，以解决对抗训练中过度学习导致决策边界恶化的问题。

Result: RPAT方法在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上，使用ResNet-18、PreActResNet-18和WideResNet-34-10模型进行了实验。结果表明，RPAT有效缓解了准确率-鲁棒性之间的权衡，并且在性能上超越了四个常用基线和十二个最先进（SOTA）的方法。

Conclusion: 该研究提出了一种名为“鲁棒感知”（Robust Perception）的新型对抗训练目标，并通过“鲁棒感知对抗训练”（RPAT）方法有效缓解了模型在干净准确率和对抗鲁棒性之间的权衡问题。实验证明RPAT在多个数据集和模型上优于现有方法。

Abstract: Adversarial Training (AT) is one of the most effective methods to train
robust Deep Neural Networks (DNNs). However, AT creates an inherent trade-off
between clean accuracy and adversarial robustness, which is commonly attributed
to the more complicated decision boundary caused by the insufficient learning
of hard adversarial samples. In this work, we reveal a counterintuitive fact
for the first time: From the perspective of perception consistency, hard
adversarial samples that can still attack the robust model after AT are already
learned better than those successfully defended. Thus, different from previous
views, we argue that it is rather the over-sufficient learning of hard
adversarial samples that degrades the decision boundary and contributes to the
trade-off problem. Specifically, the excessive pursuit of perception
consistency would force the model to view the perturbations as noise and ignore
the information within them, which should have been utilized to induce a
smoother perception transition towards the decision boundary to support its
establishment to an appropriate location. In response, we define a new AT
objective named Robust Perception, encouraging the model perception to change
smoothly with input perturbations, based on which we propose a novel Robust
Perception Adversarial Training (RPAT) method, effectively mitigating the
current accuracy-robustness trade-off. Experiments on CIFAR-10, CIFAR-100, and
Tiny-ImageNet with ResNet-18, PreActResNet-18, and WideResNet-34-10 demonstrate
the effectiveness of our method beyond four common baselines and 12
state-of-the-art (SOTA) works. The code is available at
https://github.com/FlaAI/RPAT.

</details>


### [186] [CMIC: Content-Adaptive Mamba for Learned Image Compression](https://arxiv.org/abs/2508.02192)
*Yunuo Chen,Zezheng Lyu,Bing He,Hongwei Hu,Qi Wang,Yuan Tian,Li Song,Wenjun Zhang,Guo Lu*

Main category: cs.CV

TL;DR: 提出内容自适应 Mamba (CAM) 改进了基于 Mamba 的图像压缩模型 (CMIC)，通过内容感知排序和全局信息集成，在率失真性能上超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 旨在解决 vanilla Mamba 在学习图像压缩（LIC）中存在的固有局限性，即其内容无关性和对固定选择性扫描的依赖，这些因素阻碍了其动态利用内容依赖关系的能力。

Method: 提出了一种名为内容自适应 Mamba (CAM) 的动态状态空间模型 (SSM)，它包括内容感知标记重组（基于内容相似性重新排序标记）和全局先验集成（通过提示词典将全局信息融入 SSM），以克服 vanilla Mamba 的内容无关性和选择性扫描限制。

Result: 基于 CAM 的内容自适应 Mamba 的 LIC 模型 (CMIC) 在 Kodak、Tecnick 和 CLIC 基准测试上，BD 率分别比 VTM-21.0 低了 -15.91%、-21.34% 和 -17.58%，达到了先进的率失真性能。

Conclusion: 所提出的内容自适应 Mamba (CAM) 模型通过内容感知标记重组和全局先验集成，提高了 Mamba 在图像压缩中的性能，实现了比 VTM-21.0 更优越的率失真表现。

Abstract: Recent Learned image compression (LIC) leverages Mamba-style state-space
models (SSMs) for global receptive fields with linear complexity. However,
vanilla Mamba is content-agnostic, relying on fixed and predefined selective
scans, which restricts its ability to dynamically and fully exploit content
dependencies. We introduce Content-Adaptive Mamba (CAM), a dynamic SSM that
addresses two critical limitations. First, it employs content-aware token
reorganization, clustering and reordering tokens based on content similarity to
prioritize proximity in feature space over Euclidean space. Second, it
integrates global priors into SSM via a prompt dictionary, effectively
mitigating the strict causality and long-range decay in the token interactions
of Mamba. These innovations enable CAM to better capture global dependencies
while preserving computational efficiency. Leveraging CAM, our Content-Adaptive
Mamba-based LIC model (CMIC) achieves state-of-the-art rate-distortion
performance, surpassing VTM-21.0 by -15.91\%, -21.34\%, and -17.58\% BD-rate on
Kodak, Tecnick, and CLIC benchmarks, respectively.

</details>


### [187] [Welcome New Doctor: Continual Learning with Expert Consultation and Autoregressive Inference for Whole Slide Image Analysis](https://arxiv.org/abs/2508.02220)
*Doanh Cao Bui,Jin Tae Kwak*

Main category: cs.CV

TL;DR: COSFormer是一个用于WSI分析的Transformer持续学习框架，它能高效地适应新任务，无需重新训练，并且性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于WSIs（整张幻灯片图像）的巨大尺寸带来的存储和计算资源需求，以及临床应用中对处理和适应新任务的现有模型的需求，开发一种能够有效处理和适应新任务而无需重新训练或微调的持续学习系统变得至关重要。

Method: 提出了一种名为COSFormer的基于Transformer的持续学习框架，用于多任务WSI分析，该框架能够从新任务中顺序学习，而无需重新访问整个历史数据集。

Result: 在七个器官的七个WSI数据集和六个WSI相关任务上，COSFormer在类增量和任务增量设置下都表现出了比现有持续学习框架更优越的泛化能力和有效性。

Conclusion: COSFormer是一个为多任务WSI分析量身定制的基于Transformer的持续学习框架，在临床应用中为持续WSI分析提供了有效的解决方案。

Abstract: Whole Slide Image (WSI) analysis, with its ability to reveal detailed tissue
structures in magnified views, plays a crucial role in cancer diagnosis and
prognosis. Due to their giga-sized nature, WSIs require substantial storage and
computational resources for processing and training predictive models. With the
rapid increase in WSIs used in clinics and hospitals, there is a growing need
for a continual learning system that can efficiently process and adapt existing
models to new tasks without retraining or fine-tuning on previous tasks. Such a
system must balance resource efficiency with high performance. In this study,
we introduce COSFormer, a Transformer-based continual learning framework
tailored for multi-task WSI analysis. COSFormer is designed to learn
sequentially from new tasks wile avoiding the need to revisit full historical
datasets. We evaluate COSFormer on a sequence of seven WSI datasets covering
seven organs and six WSI-related tasks under both class-incremental and
task-incremental settings. The results demonstrate COSFormer's superior
generalizability and effectiveness compared to existing continual learning
frameworks, establishing it as a robust solution for continual WSI analysis in
clinical applications.

</details>


### [188] [Forecasting When to Forecast: Accelerating Diffusion Models with Confidence-Gated Taylor](https://arxiv.org/abs/2508.02240)
*Xiaoliu Guan,Lielin Jiang,Hanqi Chen,Xu Zhang,Jiaxing Yan,Guanzhong Wang,Yi Liu,Zetao Zhang,Yu Wu*

Main category: cs.CV

TL;DR: 通过优化泰勒预测和引入动态缓存机制，显著提高了扩散Transformer（DiTs）的推理速度，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于训练的免费方法（如TaylorSeer）利用时间步长中的特征冗余来加速推理，但存在存储细粒度中间特征导致内存和计算开销大的问题，并且固定的缓存计划不考虑预测精度的变化，可能导致输出质量下降。

Method: 1. 将泰勒预测目标从模块级别更改为最后一个块级别，以减少缓存的特征数量。
2. 提出使用第一个块的泰勒估计输出和实际输出之间的误差来指示预测的可靠性。
3. 如果误差很小，则信任最后一个块的泰勒预测；否则，回退到完全计算，从而实现动态缓存机制。

Result: 在FLUX上实现了3.17倍的加速，在DiT上实现了2.36倍的加速，在Wan Video上实现了4.14倍的加速，同时质量几乎没有下降。

Conclusion: 提出的方法通过将泰勒预测目标从模块级别转移到最后一个块级别，并引入基于误差的动态缓存机制，在速度和质量之间取得了更好的平衡，在FLUX上实现了3.17倍的加速，在DiT上实现了2.36倍的加速，在Wan Video上实现了4.14倍的加速，同时几乎没有质量损失。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable performance in
visual generation tasks. However, their low inference speed limits their
deployment in low-resource applications. Recent training-free approaches
exploit the redundancy of features across timesteps by caching and reusing past
representations to accelerate inference. Building on this idea, TaylorSeer
instead uses cached features to predict future ones via Taylor expansion.
However, its module-level prediction across all transformer blocks (e.g.,
attention or feedforward modules) requires storing fine-grained intermediate
features, leading to notable memory and computation overhead. Moreover, it
adopts a fixed caching schedule without considering the varying accuracy of
predictions across timesteps, which can lead to degraded outputs when
prediction fails. To address these limitations, we propose a novel approach to
better leverage Taylor-based acceleration. First, we shift the Taylor
prediction target from the module level to the last block level, significantly
reducing the number of cached features. Furthermore, observing strong
sequential dependencies among Transformer blocks, we propose to use the error
between the Taylor-estimated and actual outputs of the first block as an
indicator of prediction reliability. If the error is small, we trust the Taylor
prediction for the last block; otherwise, we fall back to full computation,
thereby enabling a dynamic caching mechanism. Empirical results show that our
method achieves a better balance between speed and quality, achieving a 3.17x
acceleration on FLUX, 2.36x on DiT, and 4.14x on Wan Video with negligible
quality drop. The Project Page is
\href{https://cg-taylor-acce.github.io/CG-Taylor/}{here.}

</details>


### [189] [I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking](https://arxiv.org/abs/2508.02243)
*Ziyan Liu,Junwen Li,Kaiwen Li,Tong Ruan,Chao Wang,Xinyan He,Zongyu Wang,Xuezhi Cao,Jingping Liu*

Main category: cs.CV

TL;DR: 提出了一种新颖的基于 LLM 的框架（I2CR），通过优先利用文本信息，并在必要时整合多轮迭代的视觉线索，来解决多模态实体链接中的挑战，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在某些场景下不必要地引入图像数据以及仅依赖一次性提取视觉特征这两个挑战。

Method: 提出了一种新颖的基于 LLM 的框架，称为“模态内与模态间协同反射”（Intra- and Inter-modal Collaborative Reflections），它优先利用文本信息，并在文本不足时，通过多轮迭代策略整合来自图像不同方面的关键视觉线索来支持推理和提高匹配准确性。

Result: 该框架在三个广泛使用的公共数据集上进行了广泛的实验，结果显示其在任务上持续优于当前最先进的方法。

Conclusion: 所提出的框架在三个广泛使用的公共数据集上持续优于当前最先进的方法，分别提高了 3.2%、5.1% 和 1.6%。

Abstract: Multimodal entity linking plays a crucial role in a wide range of
applications. Recent advances in large language model-based methods have become
the dominant paradigm for this task, effectively leveraging both textual and
visual modalities to enhance performance. Despite their success, these methods
still face two challenges, including unnecessary incorporation of image data in
certain scenarios and the reliance only on a one-time extraction of visual
features, which can undermine their effectiveness and accuracy. To address
these challenges, we propose a novel LLM-based framework for the multimodal
entity linking task, called Intra- and Inter-modal Collaborative Reflections.
This framework prioritizes leveraging text information to address the task.
When text alone is insufficient to link the correct entity through intra- and
inter-modality evaluations, it employs a multi-round iterative strategy that
integrates key visual clues from various aspects of the image to support
reasoning and enhance matching accuracy. Extensive experiments on three widely
used public datasets demonstrate that our framework consistently outperforms
current state-of-the-art methods in the task, achieving improvements of 3.2%,
5.1%, and 1.6%, respectively. Our code is available at
https://github.com/ziyan-xiaoyu/I2CR/.

</details>


### [190] [Semi-Supervised Semantic Segmentation via Derivative Label Propagation](https://arxiv.org/abs/2508.02254)
*Yuanbin Fu,Xiaojie Guo*

Main category: cs.CV

TL;DR: DerProp是一种半监督语义分割框架，通过导数标签传播提高伪标签的可靠性，实验证明其性能优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 为了减轻半监督语义分割中繁重的数据标注负担，并提高现有伪标签策略的可靠性。

Method: 提出了一种名为DerProp的半监督框架，该框架包含一种新颖的导数标签传播方法，用于修正不完美的伪标签。该方法通过对像素级特征向量施加离散导数运算作为额外的正则化，生成严格正则化的相似性度量，从而约束了解决方案空间，解决了相同相似性对应不同特征的病态问题。

Result: 通过大量的实验验证了DerProp框架设计的合理性，并证明了其在半监督语义分割任务上的优越性。

Conclusion: DerProp框架通过引入新颖的导数标签传播方法，有效提高了伪标签的可靠性，在半监督语义分割任务上展现出优于其他方法的性能。

Abstract: Semi-supervised semantic segmentation, which leverages a limited set of
labeled images, helps to relieve the heavy annotation burden. While
pseudo-labeling strategies yield promising results, there is still room for
enhancing the reliability of pseudo-labels. Hence, we develop a semi-supervised
framework, namely DerProp, equipped with a novel derivative label propagation
to rectify imperfect pseudo-labels. Our label propagation method imposes
discrete derivative operations on pixel-wise feature vectors as additional
regularization, thereby generating strictly regularized similarity metrics.
Doing so effectively alleviates the ill-posed problem that identical
similarities correspond to different features, through constraining the
solution space. Extensive experiments are conducted to verify the rationality
of our design, and demonstrate our superiority over other methods. Codes are
available at https://github.com/ForawardStar/DerProp/.

</details>


### [191] [Patho-AgenticRAG: Towards Multimodal Agentic Retrieval-Augmented Generation for Pathology VLMs via Reinforcement Learning](https://arxiv.org/abs/2508.02258)
*Wenchuan Zhang,Jingru Guo,Hengzhe Zhang,Penghao Zhang,Jie Chen,Shuwan Zhang,Zhang Zhang,Yuhao Yi,Hong Bu*

Main category: cs.CV

TL;DR: Patho-AgenticRAG is a new multimodal RAG framework for pathology that uses textbook embeddings for joint text-image search, improving accuracy in diagnostic tasks by avoiding loss of visual information and supporting reasoning.


<details>
  <summary>Details</summary>
Motivation: Pathology VLMs face challenges like hallucinations due to ultra-high resolution, complex tissue structures, and nuanced clinical semantics, undermining clinical trust. Existing RAG approaches rely on text-based knowledge bases, limiting their ability to leverage diagnostic visual cues. This necessitates a framework that can effectively integrate visual information for improved accuracy.

Method: Patho-AgenticRAG is a multimodal RAG framework. It utilizes a database built on page-level embeddings from authoritative pathology textbooks, enabling joint text-image search to retrieve textbook pages containing both the queried text and relevant visual cues. It also supports reasoning, task decomposition, and multi-turn search interactions.

Result: Experiments demonstrate that Patho-AgenticRAG significantly outperforms existing multimodal models in complex pathology tasks, including multiple-choice diagnosis and visual question answering.

Conclusion: Patho-AgenticRAG, a multimodal RAG framework using page-level embeddings from pathology textbooks that support joint text-image search, significantly outperforms existing multimodal models in complex pathology tasks like multiple-choice diagnosis and visual question answering.

Abstract: Although Vision Language Models (VLMs) have shown strong generalization in
medical imaging, pathology presents unique challenges due to ultra-high
resolution, complex tissue structures, and nuanced clinical semantics. These
factors make pathology VLMs prone to hallucinations, i.e., generating outputs
inconsistent with visual evidence, which undermines clinical trust. Existing
RAG approaches in this domain largely depend on text-based knowledge bases,
limiting their ability to leverage diagnostic visual cues. To address this, we
propose Patho-AgenticRAG, a multimodal RAG framework with a database built on
page-level embeddings from authoritative pathology textbooks. Unlike
traditional text-only retrieval systems, it supports joint text-image search,
enabling direct retrieval of textbook pages that contain both the queried text
and relevant visual cues, thus avoiding the loss of critical image-based
information. Patho-AgenticRAG also supports reasoning, task decomposition, and
multi-turn search interactions, improving accuracy in complex diagnostic
scenarios. Experiments show that Patho-AgenticRAG significantly outperforms
existing multimodal models in complex pathology tasks like multiple-choice
diagnosis and visual question answering. Our project is available at the
Patho-AgenticRAG repository:
https://github.com/Wenchuan-Zhang/Patho-AgenticRAG.

</details>


### [192] [SplatSSC: Decoupled Depth-Guided Gaussian Splatting for Semantic Scene Completion](https://arxiv.org/abs/2508.02261)
*Rui Qian,Haozhi Cao,Tianchen Deng,Shenghai Yuan,Lihua Xie*

Main category: cs.CV

TL;DR: SplatSSC通过深度引导初始化和分离高斯聚合器解决了单目3D语义场景补全中的基元初始化和异常基元问题，在性能和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D语义场景补全（SSC）方法虽然利用高斯基元提高了效率，但它们依赖于大量随机初始化的基元，这导致了低效的基元初始化和引入错误伪影的异常基元。SplatSSC旨在解决这些局限性。

Method: SplatSSC框架提出了一种深度引导初始化策略和高斯聚合器。它使用一个专门的深度分支，包含一个组多尺度融合（GMF）模块，该模块整合了多尺度图像和深度特征，生成稀疏但具有代表性的初始高斯基元。为了减少异常基元带来的噪声，SplatSSC开发了分离高斯聚合器（DGA），通过在高斯到体素的splatting过程中分离几何和语义预测来增强鲁棒性。此外，还采用了专门的概率尺度损失。

Result: SplatSSC在Occ-ScanNet数据集上实现了最先进的性能，在IoU和mIoU方面分别超越了现有方法6.3%和4.1%，同时将延迟和内存消耗降低了9.3%以上。

Conclusion: SplatSSC方法在Occ-ScanNet数据集上取得了最先进的性能，在IoU和mIoU方面分别超越了现有方法6.3%和4.1%，同时将延迟和内存消耗减少了9.3%以上。

Abstract: Monocular 3D Semantic Scene Completion (SSC) is a challenging yet promising
task that aims to infer dense geometric and semantic descriptions of a scene
from a single image. While recent object-centric paradigms significantly
improve efficiency by leveraging flexible 3D Gaussian primitives, they still
rely heavily on a large number of randomly initialized primitives, which
inevitably leads to 1) inefficient primitive initialization and 2) outlier
primitives that introduce erroneous artifacts. In this paper, we propose
SplatSSC, a novel framework that resolves these limitations with a depth-guided
initialization strategy and a principled Gaussian aggregator. Instead of random
initialization, SplatSSC utilizes a dedicated depth branch composed of a
Group-wise Multi-scale Fusion (GMF) module, which integrates multi-scale image
and depth features to generate a sparse yet representative set of initial
Gaussian primitives. To mitigate noise from outlier primitives, we develop the
Decoupled Gaussian Aggregator (DGA), which enhances robustness by decomposing
geometric and semantic predictions during the Gaussian-to-voxel splatting
process. Complemented with a specialized Probability Scale Loss, our method
achieves state-of-the-art performance on the Occ-ScanNet dataset, outperforming
prior approaches by over 6.3% in IoU and 4.1% in mIoU, while reducing both
latency and memory consumption by more than 9.3%. The code will be released
upon acceptance.

</details>


### [193] [Semi-Supervised Dual-Threshold Contrastive Learning for Ultrasound Image Classification and Segmentation](https://arxiv.org/abs/2508.02265)
*Peng Zhang,Zhihui Lai,Heng Kong*

Main category: cs.CV

TL;DR: 提出了一种名为 Hermes 的半监督双阈值对比学习策略，用于超声图像分类和分割。该策略通过伪标签辅助对比学习，并使用跨任务注意力、显着性模块和一致性学习策略来促进任务间的特征共享和对齐。新收集的 SZ-TUS 数据集也已发布。实验证明 Hermes 优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决置信度伪标签选择通常会产生过于自信但错误的预测，以及分割和分类任务被独立处理且亲和力未能充分探索的问题。

Method: 提出了一种新颖的半监督双阈值对比学习策略（Hermes），结合了对比学习和半监督学习的优点，其中伪标签通过提供额外指导来辅助对比学习。开发了一个跨任务注意力与显着性模块，以促进分割和分类任务之间的信息共享。此外，设计了一个跨任务一致性学习策略来对齐两个任务中的肿瘤特征，避免负迁移以减少特征差异。

Result: Hermes 算法在各种半监督设置下，在两个公开超声数据集和一个私有数据集上，一致优于几种最先进的方法。

Conclusion: Hermes 算法在多种半监督设置下，在两个公开数据集和一个私有数据集的超声图像分类和分割任务上，一致优于几种最先进的方法。

Abstract: Confidence-based pseudo-label selection usually generates overly confident
yet incorrect predictions, due to the early misleadingness of model and
overfitting inaccurate pseudo-labels in the learning process, which heavily
degrades the performance of semi-supervised contrastive learning. Moreover,
segmentation and classification tasks are treated independently and the
affinity fails to be fully explored. To address these issues, we propose a
novel semi-supervised dual-threshold contrastive learning strategy for
ultrasound image classification and segmentation, named Hermes. This strategy
combines the strengths of contrastive learning with semi-supervised learning,
where the pseudo-labels assist contrastive learning by providing additional
guidance. Specifically, an inter-task attention and saliency module is also
developed to facilitate information sharing between the segmentation and
classification tasks. Furthermore, an inter-task consistency learning strategy
is designed to align tumor features across both tasks, avoiding negative
transfer for reducing features discrepancy. To solve the lack of publicly
available ultrasound datasets, we have collected the SZ-TUS dataset, a thyroid
ultrasound image dataset. Extensive experiments on two public ultrasound
datasets and one private dataset demonstrate that Hermes consistently
outperforms several state-of-the-art methods across various semi-supervised
settings.

</details>


### [194] [SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching](https://arxiv.org/abs/2508.02278)
*Xiangzeng Liu,Chi Wang,Guanglu Shi,Xiaodong Zhang,Qiguang Miao,Miao Fan*

Main category: cs.CV

TL;DR: SGAD通过生成区域描述符，实现了高效准确的区域匹配，并显著缩短了运行时间，在姿态估计任务中达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有基于区域匹配的方法（A2PM）存在像素级比较和图匹配效率低下、扩展性受限的问题。本研究旨在克服这些挑战，提高区域匹配的准确性和效率。

Method: 提出了一种名为SGAD（Semantic and Geometric-aware Descriptor Network）的新方法，该方法生成高区分度的区域描述符以实现直接匹配，并通过结合分类和排序子任务的监督策略来优化性能。此外，还引入了HCRF（Hierarchical Containment Redundancy Filter）来消除重叠区域。

Result: SGAD将运行时间缩短了60倍（从60.23秒减少到0.82秒）。与DKM相比，SGAD+LoFTR在室外姿态估计中的运行时间从1.51秒减少到0.82秒，同时准确性从61.11提高到65.98。SGAD+ROMA在室内姿态估计中将AUC@5deg提高了7.39%，达到了新的最先进水平。

Conclusion: SGAD通过生成高区分度的区域描述符，实现了直接匹配，无需复杂的图优化，显著提高了区域匹配的准确性和效率。该方法在室外和室内姿态估计任务中均取得了先进的性能。

Abstract: Local feature matching remains a fundamental challenge in computer vision.
Recent Area to Point Matching (A2PM) methods have improved matching accuracy.
However, existing research based on this framework relies on inefficient
pixel-level comparisons and complex graph matching that limit scalability. In
this work, we introduce the Semantic and Geometric-aware Descriptor Network
(SGAD), which fundamentally rethinks area-based matching by generating highly
discriminative area descriptors that enable direct matching without complex
graph optimization. This approach significantly improves both accuracy and
efficiency of area matching. We further improve the performance of area
matching through a novel supervision strategy that decomposes the area matching
task into classification and ranking subtasks. Finally, we introduce the
Hierarchical Containment Redundancy Filter (HCRF) to eliminate overlapping
areas by analyzing containment graphs. SGAD demonstrates remarkable performance
gains, reducing runtime by 60x (0.82s vs. 60.23s) compared to MESA. Extensive
evaluations show consistent improvements across multiple point matchers:
SGAD+LoFTR reduces runtime compared to DKM, while achieving higher accuracy
(0.82s vs. 1.51s, 65.98 vs. 61.11) in outdoor pose estimation, and SGAD+ROMA
delivers +7.39% AUC@5{\deg} in indoor pose estimation, establishing a new
state-of-the-art.

</details>


### [195] [Do Edges Matter? Investigating Edge-Enhanced Pre-Training for Medical Image Segmentation](https://arxiv.org/abs/2508.02281)
*Paul Zaha,Lars Böcking,Simeon Allmendinger,Leopold Müller,Niklas Kühl*

Main category: cs.CV

TL;DR: 边缘预训练对医学图像分割有益有弊，元学习策略可优化模型选择，显著提升跨模态分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，预训练和微调的基础模型可以提高医学图像分割性能。然而，关于特定的图像预处理步骤如何影响不同医学成像模态的分割性能，仍有待研究。特别是，边缘（像素强度之间的急剧变化）被认为是物体边界的重要线索，但尚未在基础模型的预训练中得到系统性研究。

Method: 本研究调查了使用计算效率高的边缘核（如Kirsch）处理的数据进行预训练，对基础模型跨模态分割能力的影响。研究人员首先在原始数据和边缘增强数据上分别训练了两个版本的模型，然后在针对特定医学模态的原始数据子集上进行微调。为了指导选择性应用，提出了一种元学习策略，该策略利用原始图像的标准差和图像熵来选择预训练模型。

Result: 研究在皮肤镜、眼底、乳腺X线摄影、显微镜、光学相干断层扫描、超声和X射线等医学领域进行了系统性调查，发现在使用边缘增强数据进行预训练时，不同模态的分割性能有所提高，但也有所降低。提出的元学习策略通过实验证明，与仅在边缘增强数据上预训练的模型相比，在各种医学成像任务上的整体分割性能提高了16.42%；与仅在原始数据上预训练的模型相比，提高了19.30%。

Conclusion: 研究发现，使用边缘增强数据进行预训练在某些医学图像分割任务中可以提升模型性能，但在其他任务中可能会降低性能，这表明需要有选择性地应用这种方法。提出的元学习策略能够根据原始图像的标准差和图像熵来选择预训练方法，从而在各种医学成像任务中实现了整体分割性能的提升。

Abstract: Medical image segmentation is crucial for disease diagnosis and treatment
planning, yet developing robust segmentation models often requires substantial
computational resources and large datasets. Existing research shows that
pre-trained and finetuned foundation models can boost segmentation performance.
However, questions remain about how particular image preprocessing steps may
influence segmentation performance across different medical imaging modalities.
In particular, edges-abrupt transitions in pixel intensity-are widely
acknowledged as vital cues for object boundaries but have not been
systematically examined in the pre-training of foundation models. We address
this gap by investigating to which extend pre-training with data processed
using computationally efficient edge kernels, such as kirsch, can improve
cross-modality segmentation capabilities of a foundation model. Two versions of
a foundation model are first trained on either raw or edge-enhanced data across
multiple medical imaging modalities, then finetuned on selected raw subsets
tailored to specific medical modalities. After systematic investigation using
the medical domains Dermoscopy, Fundus, Mammography, Microscopy, OCT, US, and
XRay, we discover both increased and reduced segmentation performance across
modalities using edge-focused pre-training, indicating the need for a selective
application of this approach. To guide such selective applications, we propose
a meta-learning strategy. It uses standard deviation and image entropy of the
raw image to choose between a model pre-trained on edge-enhanced or on raw data
for optimal performance. Our experiments show that integrating this
meta-learning layer yields an overall segmentation performance improvement
across diverse medical imaging tasks by 16.42% compared to models pre-trained
on edge-enhanced data only and 19.30% compared to models pre-trained on raw
data only.

</details>


### [196] [Unleashing the Temporal Potential of Stereo Event Cameras for Continuous-Time 3D Object Detection](https://arxiv.org/abs/2508.02288)
*Jae-Young Kang,Hoonhee Cho,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 提出了一种仅依赖事件相机的立体3D目标检测框架，通过双滤波器和边界框对齐解决了事件数据的不足，在动态场景下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统传感器（如LiDAR和RGB摄像头）在高速场景中因固定帧率而产生的感知空白问题，并克服现有事件相机融合方法的局限性（在快速运动场景下对同步传感器的依赖）。

Method: 提出了一种仅依赖事件相机的全新立体3D目标检测框架，通过引入双滤波器机制提取事件数据中的语义和几何信息，并通过将边界框与以物体为中心的信息对齐来增强回归。

Result: 实验结果表明，本研究提出的方法在动态环境中优于先前的方法。

Conclusion: 本研究提出的仅依赖事件相机的全新立体3D目标检测框架，在动态环境中优于先前的方法，证明了事件相机在鲁棒、连续时间3D感知方面的潜力。

Abstract: 3D object detection is essential for autonomous systems, enabling precise
localization and dimension estimation. While LiDAR and RGB cameras are widely
used, their fixed frame rates create perception gaps in high-speed scenarios.
Event cameras, with their asynchronous nature and high temporal resolution,
offer a solution by capturing motion continuously. The recent approach, which
integrates event cameras with conventional sensors for continuous-time
detection, struggles in fast-motion scenarios due to its dependency on
synchronized sensors. We propose a novel stereo 3D object detection framework
that relies solely on event cameras, eliminating the need for conventional 3D
sensors. To compensate for the lack of semantic and geometric information in
event data, we introduce a dual filter mechanism that extracts both.
Additionally, we enhance regression by aligning bounding boxes with
object-centric information. Experiments show that our method outperforms prior
approaches in dynamic environments, demonstrating the potential of event
cameras for robust, continuous-time 3D perception. The code is available at
https://github.com/mickeykang16/Ev-Stereo3D.

</details>


### [197] [Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning](https://arxiv.org/abs/2508.02293)
*Muhammad Aqeel,Shakiba Sharifi,Marco Cristani,Francesco Setti*

Main category: cs.CV

TL;DR: CoMet是一种新的训练策略，可以从包含正常和异常样本的未整理数据中学习，无需手动过滤。它通过结合软置信学习和元学习来提高深度异常检测模型的性能和鲁棒性，并在多个数据集上设定了新的技术水平。


<details>
  <summary>Details</summary>
Motivation: 传统无监督异常检测方法假设训练数据全是正常的，这需要手动数据整理，引入了偏差并限制了适应性。本研究旨在开发一种能够从包含正常和异常样本的未整理数据集中学习的训练策略，以消除手动数据整理的需求。

Method: CoMet将软置信学习（为低置信度样本分配较低权重）与元学习（基于训练验证损失协方差正则化更新以稳定训练）相结合，以处理包含正常和异常样本的未整理数据集。该方法模型无关，适用于任何可通过梯度下降训练的异常检测方法。

Result: CoMet在MVTec-AD、VIADUCT和KSDD2数据集上，使用两种最先进的模型进行了实验，结果一致表明该方法优于基线方法，对训练集中的异常不敏感，并在所有数据集上设置了新的技术水平。

Conclusion: CoMet提案了一种新颖的训练策略，能够从包含正常和异常样本的未整理数据集中进行学习，无需手动过滤，从而克服了传统无监督异常检测方法的局限性。实验证明，CoMet在MVTec-AD、VIADUCT和KSDD2数据集上，能够提升现有异常检测方法的性能，对训练集中的异常不敏感，并在所有数据集上达到了新的技术水平。

Abstract: So-called unsupervised anomaly detection is better described as
semi-supervised, as it assumes all training data are nominal. This assumption
simplifies training but requires manual data curation, introducing bias and
limiting adaptability. We propose Confident Meta-learning (CoMet), a novel
training strategy that enables deep anomaly detection models to learn from
uncurated datasets where nominal and anomalous samples coexist, eliminating the
need for explicit filtering. Our approach integrates Soft Confident Learning,
which assigns lower weights to low-confidence samples, and Meta-Learning, which
stabilizes training by regularizing updates based on training validation loss
covariance. This prevents overfitting and enhances robustness to noisy data.
CoMet is model-agnostic and can be applied to any anomaly detection method
trainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2
with two state-of-the-art models demonstrate the effectiveness of our approach,
consistently improving over the baseline methods, remaining insensitive to
anomalies in the training set, and setting a new state-of-the-art across all
datasets.

</details>


### [198] [Whole-body Representation Learning For Competing Preclinical Disease Risk Assessment](https://arxiv.org/abs/2508.02307)
*Dmitrii Seletkov,Sophie Starck,Ayhan Can Erdur,Yundi Zhang,Daniel Rueckert,Rickmer Braren*

Main category: cs.CV

TL;DR: 提出一种全身体部自监督表示学习方法，用于临床前疾病风险评估，优于现有方法，并具有临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了将公共卫生从被动治疗转向主动识别和预防，需要可靠的临床前疾病风险评估。然而，目前基于图像的风险预测算法通常一次只考虑一种疾病，并依赖于通过分割工具获得的手工特征。

Method: 提出了一种全身体部自监督表示学习方法，用于竞争风险模型下的临床前疾病风险评估。

Result: 该方法在模拟临床前筛查场景并结合心脏MRI后，能够进一步提高CVD亚组（缺血性心脏病（IHD）、高血压性疾病（HD）和中风）的预测精度。

Conclusion: 该方法在心血管疾病（CVD）、2型糖尿病（T2D）、慢性阻塞性肺病（COPD）和慢性肾病（CKD）等多种疾病的风险评估中，优于全身体部影像组学，具有重要的临床转化潜力，可作为独立的筛查模型，也可作为多模式框架的一部分，用于临床工作流程中的早期个性化风险分层。

Abstract: Reliable preclinical disease risk assessment is essential to move public
healthcare from reactive treatment to proactive identification and prevention.
However, image-based risk prediction algorithms often consider one condition at
a time and depend on hand-crafted features obtained through segmentation tools.
We propose a whole-body self-supervised representation learning method for the
preclinical disease risk assessment under a competing risk modeling. This
approach outperforms whole-body radiomics in multiple diseases, including
cardiovascular disease (CVD), type 2 diabetes (T2D), chronic obstructive
pulmonary disease (COPD), and chronic kidney disease (CKD). Simulating a
preclinical screening scenario and subsequently combining with cardiac MRI, it
sharpens further the prediction for CVD subgroups: ischemic heart disease
(IHD), hypertensive diseases (HD), and stroke. The results indicate the
translational potential of whole-body representations as a standalone screening
modality and as part of a multi-modal framework within clinical workflows for
early personalized risk stratification. The code is available at
https://github.com/yayapa/WBRLforCR/

</details>


### [199] [Is Uncertainty Quantification a Viable Alternative to Learned Deferral?](https://arxiv.org/abs/2508.02319)
*Anna M. Wundram,Christian F. Baumgartner*

Main category: cs.CV

TL;DR: 本研究评估了不确定性量化方法和学习推迟模型在眼科AI中的性能，发现不确定性量化方法在处理分布外数据时可能更优越。


<details>
  <summary>Details</summary>
Motivation: 为了确保AI在医疗保健中的安全实施，需要人机协作，其中AI模型在可能出错时能够将决策推迟给人类专家。该研究旨在调查不确定性量化方法是否比学习到的推迟模型更能抵抗分布外（OOD）输入。

Method: 研究人员构建了一个广泛的评估研究，使用了一个大型眼科数据集，考察了学习到的推迟模型和已建立的不确定性量化方法，评估了它们在分布内和分布外输入的性能。具体来说，他们评估了它们从眼底图像中准确分类青光眼的能力，同时推迟了高错误可能性的情况。

Result: 研究发现，不确定性量化方法在分类准确性和处理分布外输入方面可能优于学习到的推迟模型。

Conclusion: 不确定性量化方法可能是在AI决策推迟方面的一个有前途的选择。

Abstract: Artificial Intelligence (AI) holds the potential to dramatically improve
patient care. However, it is not infallible, necessitating
human-AI-collaboration to ensure safe implementation. One aspect of AI safety
is the models' ability to defer decisions to a human expert when they are
likely to misclassify autonomously. Recent research has focused on methods that
learn to defer by optimising a surrogate loss function that finds the optimal
trade-off between predicting a class label or deferring. However, during
clinical translation, models often face challenges such as data shift.
Uncertainty quantification methods aim to estimate a model's confidence in its
predictions. However, they may also be used as a deferral strategy which does
not rely on learning from specific training distribution. We hypothesise that
models developed to quantify uncertainty are more robust to out-of-distribution
(OOD) input than learned deferral models that have been trained in a supervised
fashion. To investigate this hypothesis, we constructed an extensive evaluation
study on a large ophthalmology dataset, examining both learned deferral models
and established uncertainty quantification methods, assessing their performance
in- and out-of-distribution. Specifically, we evaluate their ability to
accurately classify glaucoma from fundus images while deferring cases with a
high likelihood of error. We find that uncertainty quantification methods may
be a promising choice for AI deferral.

</details>


### [200] [Zero-shot Compositional Action Recognition with Neural Logic Constraints](https://arxiv.org/abs/2508.02320)
*Gefan Ye,Lin Li,Kexin Li,Jun Xiao,Long chen*

Main category: cs.CV

TL;DR: LogicCAR framework addresses ZS-CAR challenges by integrating explicit compositional and hierarchical primitive logic, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: ZS-CAR faces challenges including missing compositional structure constraint and neglecting semantic hierarchy constraint, which lead to spurious correlations and semantic ambiguity.

Method: LogicCAR integrates dual symbolic constraints: Explicit Compositional Logic and Hierarchical Primitive Logic. These constraints are formalized in first-order logic and embedded into neural network architectures.

Result: Extensive experiments on the Sth-com dataset demonstrate the effectiveness of LogicCAR.

Conclusion: LogicCAR outperforms existing baseline methods, proving the effectiveness of our logic-driven constraints.

Abstract: Zero-shot compositional action recognition (ZS-CAR) aims to identify unseen
verb-object compositions in the videos by exploiting the learned knowledge of
verb and object primitives during training. Despite compositional learning's
progress in ZS-CAR, two critical challenges persist: 1) Missing compositional
structure constraint, leading to spurious correlations between primitives; 2)
Neglecting semantic hierarchy constraint, leading to semantic ambiguity and
impairing the training process. In this paper, we argue that human-like
symbolic reasoning offers a principled solution to these challenges by
explicitly modeling compositional and hierarchical structured abstraction. To
this end, we propose a logic-driven ZS-CAR framework LogicCAR that integrates
dual symbolic constraints: Explicit Compositional Logic and Hierarchical
Primitive Logic. Specifically, the former models the restrictions within the
compositions, enhancing the compositional reasoning ability of our model. The
latter investigates the semantical dependencies among different primitives,
empowering the models with fine-to-coarse reasoning capacity. By formalizing
these constraints in first-order logic and embedding them into neural network
architectures, LogicCAR systematically bridges the gap between symbolic
abstraction and existing models. Extensive experiments on the Sth-com dataset
demonstrate that our LogicCAR outperforms existing baseline methods, proving
the effectiveness of our logic-driven constraints.

</details>


### [201] [Dream-to-Recon: Monocular 3D Reconstruction with Diffusion-Depth Distillation from Single Images](https://arxiv.org/abs/2508.02323)
*Philipp Wulff,Felix Wimbauer,Dominik Muhle,Daniel Cremers*

Main category: cs.CV

TL;DR: 利用预训练的2D扩散和深度模型从单张图像生成合成场景几何，用于蒸馏前馈模型，在KITTI-360和Waymo数据集上表现优于多视图监督方法。


<details>
  <summary>Details</summary>
Motivation: 从单个图像进行体积场景重建对于自动驾驶和机器人等应用至关重要，但现有方法通常需要昂贵的3D真实标签或多视图监督。

Method: 利用预训练的2D扩散模型和深度预测模型，从单个图像生成合成场景几何，然后用于蒸馏前馈场景重建模型。

Result: 所提出的方法匹配或优于使用多视图监督的现有方法，并在动态场景方面提供了独特的优势。

Conclusion: 该方法在KITTI-360和Waymo数据集上匹配或优于使用多视图监督的现有方法，并且在动态场景方面具有独特优势。

Abstract: Volumetric scene reconstruction from a single image is crucial for a broad
range of applications like autonomous driving and robotics. Recent volumetric
reconstruction methods achieve impressive results, but generally require
expensive 3D ground truth or multi-view supervision. We propose to leverage
pre-trained 2D diffusion models and depth prediction models to generate
synthetic scene geometry from a single image. This can then be used to distill
a feed-forward scene reconstruction model. Our experiments on the challenging
KITTI-360 and Waymo datasets demonstrate that our method matches or outperforms
state-of-the-art baselines that use multi-view supervision, and offers unique
advantages, for example regarding dynamic scenes.

</details>


### [202] [Qwen-Image Technical Report](https://arxiv.org/abs/2508.02324)
*Chenfei Wu,Jiahao Li,Jingren Zhou,Junyang Lin,Kaiyuan Gao,Kun Yan,Sheng-ming Yin,Shuai Bai,Xiao Xu,Yilei Chen,Yuxiang Chen,Zecheng Tang,Zekai Zhang,Zhengyi Wang,An Yang,Bowen Yu,Chen Cheng,Dayiheng Liu,Deqing Li,Hang Zhang,Hao Meng,Hu Wei,Jingyuan Ni,Kai Chen,Kuan Cao,Liang Peng,Lin Qu,Minggang Wu,Peng Wang,Shuting Yu,Tingkun Wen,Wensen Feng,Xiaoxiao Xu,Yi Wang,Yichang Zhang,Yongqiang Zhu,Yujia Wu,Yuxuan Cai,Zenan Liu*

Main category: cs.CV

TL;DR: Qwen-Image是一个强大的图像生成模型，擅长渲染复杂文本和精确编辑图像。


<details>
  <summary>Details</summary>
Motivation: 解决图像生成中的复杂文本渲染和精确图像编辑的挑战。

Method: 通过全面的数据处理流程（包括大规模数据收集、过滤、标注、合成和平衡）以及渐进式训练策略（从非文本到文本渲染，再到复杂文本输入和段落描述）来解决复杂的文本渲染问题；通过改进的多任务训练范式（包含T2I、TI2I和I2I重建任务）并采用双编码机制（分别获取语义和重建表示）来增强图像编辑的一致性。

Result: Qwen-Image在字母语言（如英语）和象形语言（如中文）的文本渲染方面表现优异，并能在保持语义一致性的同时保真图像编辑。

Conclusion: Qwen-Image在图像生成和编辑方面表现出色，在多个基准测试中均达到最先进水平。

Abstract: We present Qwen-Image, an image generation foundation model in the Qwen
series that achieves significant advances in complex text rendering and precise
image editing. To address the challenges of complex text rendering, we design a
comprehensive data pipeline that includes large-scale data collection,
filtering, annotation, synthesis, and balancing. Moreover, we adopt a
progressive training strategy that starts with non-text-to-text rendering,
evolves from simple to complex textual inputs, and gradually scales up to
paragraph-level descriptions. This curriculum learning approach substantially
enhances the model's native text rendering capabilities. As a result,
Qwen-Image not only performs exceptionally well in alphabetic languages such as
English, but also achieves remarkable progress on more challenging logographic
languages like Chinese. To enhance image editing consistency, we introduce an
improved multi-task training paradigm that incorporates not only traditional
text-to-image (T2I) and text-image-to-image (TI2I) tasks but also
image-to-image (I2I) reconstruction, effectively aligning the latent
representations between Qwen2.5-VL and MMDiT. Furthermore, we separately feed
the original image into Qwen2.5-VL and the VAE encoder to obtain semantic and
reconstructive representations, respectively. This dual-encoding mechanism
enables the editing module to strike a balance between preserving semantic
consistency and maintaining visual fidelity. Qwen-Image achieves
state-of-the-art performance, demonstrating its strong capabilities in both
image generation and editing across multiple benchmarks.

</details>


### [203] [CLIP-IN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions](https://arxiv.org/abs/2508.02329)
*Ziteng Wang,Siqi Yang,Limeng Qiao,Lin Ma*

Main category: cs.CV

TL;DR: CLIP-IN通过难例负样本和长描述标题提升了视觉语言模型的细粒度理解能力，并改善了多模态大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型（VLM）在融合视觉和语言方面取得了成功，但在细粒度视觉理解方面仍存在挑战。

Method: CLIP-IN框架包含两个核心创新：1.利用指令编辑数据集作为难例负样本对的来源，并结合对称式难例对比损失，以区分细微的视觉-语义差异。2.引入长描述标题并使用旋转位置编码来捕捉丰富的语义上下文。

Result: CLIP-IN在MMVP基准和细粒度视觉识别任务上实现了显著的性能提升，同时在广泛的分类和检索任务上保持了鲁棒的零样本性能。将CLIP-IN的视觉表征整合到多模态大语言模型中，能够有效减少视觉幻觉并增强推理能力。

Conclusion: CLIP-IN框架通过利用指令编辑数据集生成难例负样本对，并结合对称式难例对比损失，有效地区分细微的视觉-语义差异。同时，利用旋转位置编码处理长描述标题，捕捉标准CLIP易忽略的丰富语义信息。实验证明，CLIP-IN在MMVP基准和细粒度视觉识别任务上取得了显著的提升，同时保持了在广泛分类和检索任务上的零样本性能。此外，将CLIP-IN的视觉表征整合到多模态大语言模型中，能显著减少视觉幻觉并增强推理能力。该研究表明，结合基于指令的对比学习和全面的描述信息，可以有效提升视觉语言模型的细粒度理解能力。

Abstract: Despite the success of Vision-Language Models (VLMs) like CLIP in aligning
vision and language, their proficiency in detailed, fine-grained visual
comprehension remains a key challenge. We present CLIP-IN, a novel framework
that bolsters CLIP's fine-grained perception through two core innovations.
Firstly, we leverage instruction-editing datasets, originally designed for
image manipulation, as a unique source of hard negative image-text pairs.
Coupled with a symmetric hard negative contrastive loss, this enables the model
to effectively distinguish subtle visual-semantic differences. Secondly,
CLIP-IN incorporates long descriptive captions, utilizing rotary positional
encodings to capture rich semantic context often missed by standard CLIP. Our
experiments demonstrate that CLIP-IN achieves substantial gains on the MMVP
benchmark and various fine-grained visual recognition tasks, without
compromising robust zero-shot performance on broader classification and
retrieval tasks. Critically, integrating CLIP-IN's visual representations into
Multimodal Large Language Models significantly reduces visual hallucinations
and enhances reasoning abilities. This work underscores the considerable
potential of synergizing targeted, instruction-based contrastive learning with
comprehensive descriptive information to elevate the fine-grained understanding
of VLMs.

</details>


### [204] [Learning Partially-Decorrelated Common Spaces for Ad-hoc Video Search](https://arxiv.org/abs/2508.02340)
*Fan Hu,Zijie Xin,Xirong Li*

Main category: cs.CV

TL;DR: LPD通过学习部分去相关的多空间来提高视频搜索的多样性。


<details>
  <summary>Details</summary>
Motivation: 当前的AVS解决方案主要将多个特征融合到一个或多个公共空间中，但忽略了对‘多样化空间’的需求。然而，AVS任务的核心挑战在于相关视频的视觉多样性，一个简单的文本查询可能对应多种不同的视觉表现形式。因此，有必要尽可能全面地检索相关视频。

Method: 提出了一种名为LPD（Learning Partially Decorrelated common spaces）的新方法，该方法包含两个关键创新：1. 针对每个视频和文本特征学习独立的公共空间；2. 引入去相关损失函数，以实现负样本在不同空间中的排序多样化。此外，还设计了一种基于熵的公平多空间三元组排序损失，以增强多空间收敛的一致性。

Result: LPD在TRECVID AVS基准测试（2016-2023）上进行了广泛的实验，结果证明了其有效性。此外，LPD空间的多样性可视化也凸显了其增强结果多样性的能力。

Conclusion: LPD通过学习独立的、部分去相关的多空间来解决AVS任务中的视觉多样性挑战，并在TRECVID AVS基准测试中取得了显著成效。

Abstract: Ad-hoc Video Search (AVS) involves using a textual query to search for
multiple relevant videos in a large collection of unlabeled short videos. The
main challenge of AVS is the visual diversity of relevant videos. A simple
query such as "Find shots of a man and a woman dancing together indoors" can
span a multitude of environments, from brightly lit halls and shadowy bars to
dance scenes in black-and-white animations. It is therefore essential to
retrieve relevant videos as comprehensively as possible. Current solutions for
the AVS task primarily fuse multiple features into one or more common spaces,
yet overlook the need for diverse spaces. To fully exploit the expressive
capability of individual features, we propose LPD, short for Learning Partially
Decorrelated common spaces. LPD incorporates two key innovations:
feature-specific common space construction and the de-correlation loss.
Specifically, LPD learns a separate common space for each video and text
feature, and employs de-correlation loss to diversify the ordering of negative
samples across different spaces. To enhance the consistency of multi-space
convergence, we designed an entropy-based fair multi-space triplet ranking
loss. Extensive experiments on the TRECVID AVS benchmarks (2016-2023) justify
the effectiveness of LPD. Moreover, diversity visualizations of LPD's spaces
highlight its ability to enhance result diversity.

</details>


### [205] [Text2Lip: Progressive Lip-Synced Talking Face Generation from Text via Viseme-Guided Rendering](https://arxiv.org/abs/2508.02362)
*Xu Wang,Shengeng Tang,Fei Wang,Lechao Cheng,Dan Guo,Feng Xue,Richang Hong*

Main category: cs.CV

TL;DR: Text2Lip是一种粘音中心框架，通过将文本转换为粘音序列来驱动说话人脸生成，解决了现有方法的局限性，并在各种场景下实现了高质量的唇部同步。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有音频驱动方法在数据依赖性和声学到唇部运动映射的模糊性方面带来的可扩展性和鲁棒性挑战，本文提出了一种粘音中心的方法。

Method: 提出了一种名为Text2Lip的粘音中心框架，通过将文本输入嵌入结构化的粘音序列来构建可解释的语音-视觉桥梁。该框架利用粘音作为发音预测的语言学基础。此外，设计了一种基于课程学习的渐进式粘音-音频替换策略，使模型能够通过跨模态注意力从真实音频逐步过渡到从增强的粘音特征重建的伪音频。最后，使用由地标引导的渲染器生成具有精确唇部同步的逼真面部视频。

Result: Text2Lip在语义保真度、视觉真实感和模态鲁棒性方面均优于现有方法。

Conclusion: Text2Lip在语义保真度、视觉真实感和模态鲁棒性方面均优于现有方法，为可控、灵活的生成说话人脸建立了新范例。

Abstract: Generating semantically coherent and visually accurate talking faces requires
bridging the gap between linguistic meaning and facial articulation. Although
audio-driven methods remain prevalent, their reliance on high-quality paired
audio visual data and the inherent ambiguity in mapping acoustics to lip motion
pose significant challenges in terms of scalability and robustness. To address
these issues, we propose Text2Lip, a viseme-centric framework that constructs
an interpretable phonetic-visual bridge by embedding textual input into
structured viseme sequences. These mid-level units serve as a linguistically
grounded prior for lip motion prediction. Furthermore, we design a progressive
viseme-audio replacement strategy based on curriculum learning, enabling the
model to gradually transition from real audio to pseudo-audio reconstructed
from enhanced viseme features via cross-modal attention. This allows for robust
generation in both audio-present and audio-free scenarios. Finally, a
landmark-guided renderer synthesizes photorealistic facial videos with accurate
lip synchronization. Extensive evaluations show that Text2Lip outperforms
existing approaches in semantic fidelity, visual realism, and modality
robustness, establishing a new paradigm for controllable and flexible talking
face generation. Our project homepage is https://plyon1.github.io/Text2Lip/.

</details>


### [206] [Transport-Guided Rectified Flow Inversion: Improved Image Editing Using Optimal Transport Theory](https://arxiv.org/abs/2508.02363)
*Marian Lupascu,Mihai-Sorin Stupariu*

Main category: cs.CV

TL;DR: OTIP 通过最优传输理论在图像重建保真度和编辑灵活性之间取得了更好的平衡，在多个基准测试中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在变换流模型中实现有效的图像逆变换，将真实图像映射到可编辑的潜在表示，对于实际的图像编辑应用至关重要，但要在重建保真度和编辑灵活性之间取得最佳平衡仍然是一个基本挑战。

Method: OTIP 框架利用最优传输理论，通过在逆扩散过程中结合基于传输的引导，实现重建保真度和编辑可控性之间的平衡。它计算图像和噪声分布之间的最优传输路径，同时保持计算效率。

Result: OTIP 在人脸编辑基准测试中实现了高保真重建（LPIPS 0.001，SSIM 0.992），优于现有方法。在 LSUN-Bedroom 和 LSUN-Church 数据集上，重建损失比 RF-Inversion 分别提高了 7.8% 和 12.9%。在语义人脸编辑方面，身份保持提高了 11.2%，感知质量提高了 1.6%，计算效率相当。

Conclusion: 该研究引入了最优传输逆变换管道（OTIP），一个零样本框架，利用最优传输理论指导变换流模型中的逆变换过程。实验结果表明，OTIP 在人脸编辑基准测试中实现了高保真重建（LPIPS 0.001，SSIM 0.992），在 LSUN-Bedroom 和 LSUN-Church 数据集上比现有方法（RF-Inversion）的重建损失分别提高了 7.8% 和 12.9%。在语义人脸编辑方面，OTIP 在身份保持方面提高了 11.2%，感知质量方面提高了 1.6%，同时保持了与基线方法相当的计算效率。定性评估显示，OTIP 在各种编辑场景下都能生成具有更高语义一致性和更精细细节保留的视觉效果。

Abstract: Effective image inversion in rectified flow models - mapping real images to
editable latent representations - is crucial for practical image editing
applications; however, achieving optimal balance between reconstruction
fidelity and editing flexibility remains a fundamental challenge. In this work,
we introduce the Optimal Transport Inversion Pipeline (OTIP), a zero-shot
framework that leverages optimal transport theory to guide the inversion
process in rectified flow models. Our underlying hypothesis is that
incorporating transport-based guidance during the reverse diffusion process can
effectively balance reconstruction accuracy and editing controllability through
principled trajectory optimization. The method computes optimal transport paths
between image and noise distributions while maintaining computational
efficiency. Our approach achieves high-fidelity reconstruction with LPIPS
scores of 0.001 and SSIM of 0.992 on face editing benchmarks, demonstrating
superior preservation of fine-grained details compared to existing methods. We
evaluate the framework across multiple editing tasks, observing 7.8% to 12.9%
improvements in reconstruction loss over RF-Inversion on the LSUN-Bedroom and
LSUN-Church datasets, respectively. For semantic face editing, our method
achieves an 11.2% improvement in identity preservation and a 1.6% enhancement
in perceptual quality, while maintaining computational efficiency comparable to
baseline approaches. Qualitatively, our method produces visually compelling
edits with superior semantic consistency and fine-grained detail preservation
across diverse editing scenarios. Code is available at:
https://github.com/marianlupascu/OT-Inversion

</details>


### [207] [TRUDI and TITUS: A Multi-Perspective Dataset and A Three-Stage Recognition System for Transportation Unit Identification](https://arxiv.org/abs/2508.02372)
*Emre Gülsoylu,André Kelm,Lennart Bengtson,Matthias Hirsch,Christian Wilms,Tim Rolff,Janick Edinger,Simone Frintrop*

Main category: cs.CV

TL;DR: TRUDI数据集和TITUS流水线是为了解决港口物流中TU识别的挑战而创建的，TRUDI数据集提供了多样化的图像，而TITUS流水线在各种条件下都能可靠地识别TU。


<details>
  <summary>Details</summary>
Motivation: 为了解决港口物流领域在TU识别方面由于缺乏公开的基准数据集而导致的进展缓慢的问题，我们提出了TRUDI数据集。

Method: TITUS流水线通过三个阶段进行TU识别：(1)分割TU实例，(2)检测ID文本的位置，(3)识别和验证提取的ID。

Result: TRUDI数据集包含35,034个标注实例，涵盖集装箱、罐式集装箱、拖车、ID文本和徽标五种类别，并证明了TITUS流水线在不同条件下识别TU的可靠性。

Conclusion: TRUDI数据集的公开为TU识别方法的发展和比较提供了一个强大的基准，TITUS流水线能够从各种摄像机视角以及不同的光照和天气条件下可靠地识别TU，而其他系统通常需要相似的场景、特定的摄像机角度或闸机设置。

Abstract: Identifying transportation units (TUs) is essential for improving the
efficiency of port logistics. However, progress in this field has been hindered
by the lack of publicly available benchmark datasets that capture the diversity
and dynamics of real-world port environments. To address this gap, we present
the TRUDI dataset-a comprehensive collection comprising 35,034 annotated
instances across five categories: container, tank container, trailer, ID text,
and logo. The images were captured at operational ports using both ground-based
and aerial cameras, under a wide variety of lighting and weather conditions.
For the identification of TUs-which involves reading the 11-digit alphanumeric
ID typically painted on each unit-we introduce TITUS, a dedicated pipeline that
operates in three stages: (1) segmenting the TU instances, (2) detecting the
location of the ID text, and (3) recognising and validating the extracted ID.
Unlike alternative systems, which often require similar scenes, specific camera
angles or gate setups, our evaluation demonstrates that TITUS reliably
identifies TUs from a range of camera perspectives and in varying lighting and
weather conditions. By making the TRUDI dataset publicly available, we provide
a robust benchmark that enables the development and comparison of new
approaches. This contribution supports digital transformation efforts in
multipurpose ports and helps to increase the efficiency of entire logistics
chains.

</details>


### [208] [Uni-Layout: Integrating Human Feedback in Unified Layout Generation and Evaluation](https://arxiv.org/abs/2508.02374)
*Shuo Lu,Yanyin Chen,Wei Feng,Jiahao Fan,Fengheng Li,Zheng Zhang,Jingjing Lv,Junjie Shen,Ching Law,Jian Liang*

Main category: cs.CV

TL;DR: Uni-Layout是一个统一的布局生成和评估框架，通过统一生成器、人类反馈数据集（Layout-HF100k）和人类模仿评估器，并利用DMPO进行对齐，实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有布局生成方法存在任务特定性强、评估指标与人类感知不一致的问题，导致应用受限和测量效果不佳。

Method: 提出了一种名为Uni-Layout的统一框架，该框架包含：1. 统一生成器：将各种布局任务整合到一个分类法中，并通过自然语言提示处理受背景或元素内容约束的任务。2. 人类模仿评估器：基于Layout-HF100k数据集（包含10万个标注布局），整合视觉和几何信息，并利用思维链机制进行定性评估，同时结合置信度估计模块进行定量测量。3. 对齐机制：采用动态边际偏好优化（DMPO）来更好地对齐生成器和评估器，使其与人类判断保持一致。

Result: Uni-Layout在各项实验中表现出色，显著优于特定任务和通用方法。

Conclusion: Uni-Layout在生成和评估方面都显著优于现有方法，并且在生成器和评估器之间实现了更好的对齐。

Abstract: Layout generation plays a crucial role in enhancing both user experience and
design efficiency. However, current approaches suffer from task-specific
generation capabilities and perceptually misaligned evaluation metrics, leading
to limited applicability and ineffective measurement. In this paper, we propose
\textit{Uni-Layout}, a novel framework that achieves unified generation,
human-mimicking evaluation and alignment between the two. For universal
generation, we incorporate various layout tasks into a single taxonomy and
develop a unified generator that handles background or element contents
constrained tasks via natural language prompts. To introduce human feedback for
the effective evaluation of layouts, we build \textit{Layout-HF100k}, the first
large-scale human feedback dataset with 100,000 expertly annotated layouts.
Based on \textit{Layout-HF100k}, we introduce a human-mimicking evaluator that
integrates visual and geometric information, employing a Chain-of-Thought
mechanism to conduct qualitative assessments alongside a confidence estimation
module to yield quantitative measurements. For better alignment between the
generator and the evaluator, we integrate them into a cohesive system by
adopting Dynamic-Margin Preference Optimization (DMPO), which dynamically
adjusts margins based on preference strength to better align with human
judgments. Extensive experiments show that \textit{Uni-Layout} significantly
outperforms both task-specific and general-purpose methods. Our code is
publicly available at https://github.com/JD-GenX/Uni-Layout.

</details>


### [209] [SMART-Ship: A Comprehensive Synchronized Multi-modal Aligned Remote Sensing Targets Dataset and Benchmark for Berthed Ships Analysis](https://arxiv.org/abs/2508.02384)
*Chen-Chen Fan,Peiyao Guo,Linping Zhang,Kehan Qi,Haolin Huang,Yong-Qiang Mao,Yuxi Suo,Zhizhuo Jiang,Yu Liu,You He*

Main category: cs.CV

TL;DR: 提出了SMART-Ship数据集，包含多模态遥感图像和船只标注，用于海洋监测，并进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 为了应对多尺度目标和动态环境带来的海洋监测挑战，以及卫星轨道和成像条件的限制，需要多模态遥感数据来支持长期地球观测。

Method: 提出了SMART-Ship数据集，包含1092个多模态图像集（可见光、SAR、全色、多光谱、近红外），覆盖38,838个船只实例，并提供多模态配准、船只多边形标注、细粒度分类、实例ID和变化区域掩码等信息。同时，定义了五个基础任务的基准测试，并对代表性方法进行了比较。

Result: SMART-Ship数据集包含了1092个多模态图像集，覆盖了38,838个船只，并进行了时空配准和详细标注。对五个基础任务的基准测试和方法比较表明，该数据集能够支持多模态遥感解译任务，并揭示了未来研究的潜力。

Conclusion: 该SMART-Ship数据集为多模态遥感（RS）航运目标分析提供了新的解决方案，通过时空配准的多模态图像和细粒度标注，支持了多种遥感应用，并为未来研究指明了方向。

Abstract: Given the limitations of satellite orbits and imaging conditions, multi-modal
remote sensing (RS) data is crucial in enabling long-term earth observation.
However, maritime surveillance remains challenging due to the complexity of
multi-scale targets and the dynamic environments. To bridge this critical gap,
we propose a Synchronized Multi-modal Aligned Remote sensing Targets dataset
for berthed ships analysis (SMART-Ship), containing spatiotemporal registered
images with fine-grained annotation for maritime targets from five modalities:
visible-light, synthetic aperture radar (SAR), panchromatic, multi-spectral,
and near-infrared. Specifically, our dataset consists of 1092 multi-modal image
sets, covering 38,838 ships. Each image set is acquired within one week and
registered to ensure spatiotemporal consistency. Ship instances in each set are
annotated with polygonal location information, fine-grained categories,
instance-level identifiers, and change region masks, organized hierarchically
to support diverse multi-modal RS tasks. Furthermore, we define standardized
benchmarks on five fundamental tasks and comprehensively compare representative
methods across the dataset. Thorough experiment evaluations validate that the
proposed SMART-Ship dataset could support various multi-modal RS interpretation
tasks and reveal the promising directions for further exploration.

</details>


### [210] [Enhancing Object Discovery for Unsupervised Instance Segmentation and Object Detection](https://arxiv.org/abs/2508.02386)
*Xingyu Feng,Hebei Gao,Hong Li*

Main category: cs.CV

TL;DR: COLER是一种用于无监督实例分割和对象检测的新方法，它使用CutOnce生成伪标签，并在没有特殊损失函数的情况下实现了强大的性能，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 提出了一种用于无监督实例分割和对象检测的简单方法COLER。

Method: COLER首先使用我们开发的CutOnce生成粗略的伪标签，然后使检测器从这些掩码中学习。CutOnce仅应用一次归一化割（Normalized Cut）且不依赖任何聚类方法，但它可以生成图像中的多个对象掩码。我们设计了几个新颖而简单的模块，这些模块不仅使CutOnce能够充分利用自监督模型的对象发现能力，还摆脱了对掩码后处理的依赖。

Result: COLER在训练过程中无需为伪标签设计特殊的损失函数即可实现强大的性能，并且通过自训练进一步提高了性能。

Conclusion: COLER是一种零样本无监督模型，在多个基准测试中表现优于以前最先进的方法，有望推动无监督对象本地化领域的发展。

Abstract: We propose Cut-Once-and-LEaRn (COLER), a simple approach for unsupervised
instance segmentation and object detection. COLER first uses our developed
CutOnce to generate coarse pseudo labels, then enables the detector to learn
from these masks. CutOnce applies Normalized Cut only once and does not rely on
any clustering methods, but it can generate multiple object masks in an image.
We have designed several novel yet simple modules that not only allow CutOnce
to fully leverage the object discovery capabilities of self-supervised models,
but also free it from reliance on mask post-processing. During training, COLER
achieves strong performance without requiring specially designed loss functions
for pseudo labels, and its performance is further improved through
self-training. COLER is a zero-shot unsupervised model that outperforms
previous state-of-the-art methods on multiple benchmarks.We believe our method
can help advance the field of unsupervised object localization.

</details>


### [211] [Hydra: Accurate Multi-Modal Leaf Wetness Sensing with mm-Wave and Camera Fusion](https://arxiv.org/abs/2508.02409)
*Yimeng Liu,Maolin Gan,Huaili Zeng,Li Liu,Younsuk Dong,Zhichao Cao*

Main category: cs.CV

TL;DR: Hydra利用毫米波雷达和摄像头技术，结合CNN和Transformer模型，能够高精度地检测叶片湿润度，准确率高达96%，并在各种环境下保持约90%的准确率，解决了现有技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的叶片湿润度（LWD）检测方法缺乏标准化测量技术，且在不同植物特性下的变化限制了其有效性。以往的研究未能直接测量自然叶片，并且在不同环境条件下的鲁棒性不足，导致在实际农业应用中精度和稳健性下降。

Method: 本研究提出了一种名为Hydra的新方法，结合了毫米波（mm-Wave）雷达和摄像头技术来检测叶片湿润度。具体方法包括：1.设计卷积神经网络（CNN）来融合多个毫米波深度图像和RGB图像，生成多特征图像。2.开发基于Transformer的编码器来捕捉多特征图像间的联系，生成特征图。3.将特征图输入分类器进行检测。4.通过数据增强来泛化模型。该系统使用76-81 GHz频段的FMCW雷达。

Result: Hydra在实际植物上进行了性能评估，在各种场景下将叶片湿润度分类的准确率最高可达96%。在农场实际部署中，即使在下雨、黎明或光线不足的夜晚等条件下，Hydra仍能实现约90%的准确率。

Conclusion: Hydra通过融合毫米波雷达和摄像头技术，并利用CNN和Transformer模型，能够高精度地检测叶片湿润度，在各种环境下都能达到约90%的准确率，解决了现有LWD检测技术的局限性，具有实际应用价值。

Abstract: Leaf Wetness Duration (LWD), the time that water remains on leaf surfaces, is
crucial in the development of plant diseases. Existing LWD detection lacks
standardized measurement techniques, and variations across different plant
characteristics limit its effectiveness. Prior research proposes diverse
approaches, but they fail to measure real natural leaves directly and lack
resilience in various environmental conditions. This reduces the precision and
robustness, revealing a notable practical application and effectiveness gap in
real-world agricultural settings. This paper presents Hydra, an innovative
approach that integrates millimeter-wave (mm-Wave) radar with camera technology
to detect leaf wetness by determining if there is water on the leaf. We can
measure the time to determine the LWD based on this detection. Firstly, we
design a Convolutional Neural Network (CNN) to selectively fuse multiple
mm-Wave depth images with an RGB image to generate multiple feature images.
Then, we develop a transformer-based encoder to capture the inherent connection
among the multiple feature images to generate a feature map, which is further
fed to a classifier for detection. Moreover, we augment the dataset during
training to generalize our model. Implemented using a frequency-modulated
continuous-wave (FMCW) radar within the 76 to 81 GHz band, Hydra's performance
is meticulously evaluated on plants, demonstrating the potential to classify
leaf wetness with up to 96% accuracy across varying scenarios. Deploying Hydra
in the farm, including rainy, dawn, or poorly light nights, it still achieves
an accuracy rate of around 90%.

</details>


### [212] [HGTS-Former: Hierarchical HyperGraph Transformer for Multivariate Time Series Analysis](https://arxiv.org/abs/2508.02411)
*Xiao Wang,Hao Si,Fan Zhang,Xiaoya Zhou,Dengdi Sun,Wanli Lyu,Qingquan Yang,Jin Tang*

Main category: cs.CV

TL;DR: HGTS-Former是一种基于超图的新型时间序列Transformer骨干网络，用于解决多元时间序列耦合问题。


<details>
  <summary>Details</summary>
Motivation: 针对多元时间序列数据的高维度、动态性和变量间复杂交互性带来的分析挑战，提出一种基于超图的新型时间序列Transformer骨干网络HGTS-Former来解决多元时间序列耦合问题。

Method: HGTS-Former通过构建层次化超图来聚合每个通道内的时间模式以及不同变量之间的细粒度关系。然后，通过EdgeToNode模块将超边转换为节点特征，并采用前馈网络进一步增强输出特征。

Result: HGTS-Former在两个多元时间序列任务和八个数据集上进行了广泛的实验，并验证了其有效性。

Conclusion: HGTS-Former在两个多元时间序列任务和八个数据集上的广泛实验充分验证了其有效性。

Abstract: Multivariate time series analysis has long been one of the key research
topics in the field of artificial intelligence. However, analyzing complex time
series data remains a challenging and unresolved problem due to its high
dimensionality, dynamic nature, and complex interactions among variables.
Inspired by the strong structural modeling capability of hypergraphs, this
paper proposes a novel hypergraph-based time series transformer backbone
network, termed HGTS-Former, to address the multivariate coupling in time
series data. Specifically, given the multivariate time series signal, we first
normalize and embed each patch into tokens. Then, we adopt the multi-head
self-attention to enhance the temporal representation of each patch. The
hierarchical hypergraphs are constructed to aggregate the temporal patterns
within each channel and fine-grained relations between different variables.
After that, we convert the hyperedge into node features through the EdgeToNode
module and adopt the feed-forward network to further enhance the output
features. Extensive experiments conducted on two multivariate time series tasks
and eight datasets fully validated the effectiveness of our proposed
HGTS-Former. The source code will be released on
https://github.com/Event-AHU/Time_Series_Analysis.

</details>


### [213] [Glioblastoma Overall Survival Prediction With Vision Transformers](https://arxiv.org/abs/2508.02439)
*Yin Lin,iccardo Barbieri,Domenico Aquino,Giuseppe Lauria,Marina Grisoli,Elena De Momi,Alberto Redaelli,Simona Ferrante*

Main category: cs.CV

TL;DR: 提出了一种利用 Vision Transformers (ViTs) 直接从 MRI 图像预测胶质母细胞瘤患者总体生存期 (OS) 的 AI 方法。该方法无需肿瘤分割，简化了工作流程并降低了计算资源要求。在 BRATS 数据集上，该模型取得了与顶级方法相当的准确率，并在精确率、召回率和 F1 分数方面表现更优。研究承认 ViT 的泛化能力受限于数据集大小，但证明了其在降采样医学成像任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 预测胶质母细胞瘤患者的总体生存期 (OS) 对于个性化治疗策略和使临床决策与患者结果保持一致至关重要。

Method: 提出了一种利用 Vision Transformers (ViTs) 直接从磁共振成像 (MRI) 图像中提取特征以预测总体生存期 (OS) 的新颖人工智能 (AI) 方法。

Result: 在 BRATS 数据集上，该模型在测试集上达到了 62.5% 的准确率，与性能最佳的方法相当，并在精确率、召回率和 F1 分数方面表现出均衡的性能，在这些指标上优于现有最佳模型。

Conclusion: 该研究突显了 Vision Transformers (ViTs) 在降采样医学成像任务中的应用，并为计算高效且不依赖分割的总体生存预测模型奠定了基础。

Abstract: Glioblastoma is one of the most aggressive and common brain tumors, with a
median survival of 10-15 months. Predicting Overall Survival (OS) is critical
for personalizing treatment strategies and aligning clinical decisions with
patient outcomes. In this study, we propose a novel Artificial Intelligence
(AI) approach for OS prediction using Magnetic Resonance Imaging (MRI) images,
exploiting Vision Transformers (ViTs) to extract hidden features directly from
MRI images, eliminating the need of tumor segmentation. Unlike traditional
approaches, our method simplifies the workflow and reduces computational
resource requirements.
  The proposed model was evaluated on the BRATS dataset, reaching an accuracy
of 62.5% on the test set, comparable to the top-performing methods.
Additionally, it demonstrated balanced performance across precision, recall,
and F1 score, overcoming the best model in these metrics. The dataset size
limits the generalization of the ViT which typically requires larger datasets
compared to convolutional neural networks. This limitation in generalization is
observed across all the cited studies. This work highlights the applicability
of ViTs for downsampled medical imaging tasks and establishes a foundation for
OS prediction models that are computationally efficient and do not rely on
segmentation.

</details>


### [214] [InfoSyncNet: Information Synchronization Temporal Convolutional Network for Visual Speech Recognition](https://arxiv.org/abs/2508.02460)
*Junxiao Xue,Xiaozhen Liu,Xuecheng Wu,Fei Yu,Jun Wang*

Main category: cs.CV

TL;DR: InfoSyncNet是一种新的网络，可以从静默视频中读取口语内容，并且在标准基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 从静默视频估计口语内容对于辅助技术（AT）和增强现实（AR）应用至关重要。然而，由于序列间的变异性和序列内信息分布不均，将视频中的唇动序列准确映射到单词存在重大挑战。

Method: 提出了一种名为InfoSyncNet的非均匀序列建模网络，并辅以定制的数据增强技术。该网络的核心在于编码器和解码器之间的一个非均匀量化模块，能够动态调整网络焦点，有效处理视觉语音数据中的不一致性。此外，还采用了多种训练策略来提高模型处理光照和说话人姿态变化的能力。

Result: InfoSyncNet在LRW和LRW1000数据集上实现了92.0%和60.7%的Top-1准确率，优于现有方法。

Conclusion: InfoSyncNet在LRW和LRW1000数据集上取得了新的最先进的准确率（分别为92.0%和60.7% Top-1 ACC），证明了其在从静默视频估计口语内容方面的优越性。

Abstract: Estimating spoken content from silent videos is crucial for applications in
Assistive Technology (AT) and Augmented Reality (AR). However, accurately
mapping lip movement sequences in videos to words poses significant challenges
due to variability across sequences and the uneven distribution of information
within each sequence. To tackle this, we introduce InfoSyncNet, a non-uniform
sequence modeling network enhanced by tailored data augmentation techniques.
Central to InfoSyncNet is a non-uniform quantization module positioned between
the encoder and decoder, enabling dynamic adjustment to the network's focus and
effectively handling the natural inconsistencies in visual speech data.
Additionally, multiple training strategies are incorporated to enhance the
model's capability to handle variations in lighting and the speaker's
orientation. Comprehensive experiments on the LRW and LRW1000 datasets confirm
the superiority of InfoSyncNet, achieving new state-of-the-art accuracies of
92.0% and 60.7% Top-1 ACC. The code is available for download (see comments).

</details>


### [215] [SAMPO: Visual Preference Optimization for Intent-Aware Segmentation with Vision Foundation Models](https://arxiv.org/abs/2508.02464)
*Yonghuang Wu,Wenwen Zeng,Xuan Xie,Chengqian Zhao,Guoqing Wu,Jinhua Yu*

Main category: cs.CV

TL;DR: SAMPO通过偏好优化解决了基础分割模型的意图鸿沟问题，在医学图像分割任务中表现出色，即使在数据量较少的情况下也优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型（如SAM）在提示性分割中存在的意图鸿沟问题，即它们只能分割显式提示的对象，而无法泛化到用户隐式期望的语义相关实例，尤其是在存在大量同质对象（如生物医学核分割）的领域，稀疏提示往往导致不完整的结果。

Method: SAMPO（Segment Anything Model with Preference Optimization）框架，通过偏好优化来学习视觉基础模型，使其能够从稀疏的视觉交互中推断高级别意图，而无需依赖语言模型，并且不需要进行常规的像素级微调。

Result: 在三种医学分割任务中，SAMPO实现了最先进的性能。在PanNuke-T2等具有挑战性的任务中，SAMPO仅使用10%的训练数据进行微调，其性能显著优于使用100%训练数据的现有方法，提高了9个百分点以上。

Conclusion: SAMPO框架通过偏好优化，使视觉基础模型能够从稀疏的视觉交互中推断出高级别意图，弥合了意图鸿沟，实现了对隐式期望实例的分割，为意图感知对齐建立了新范式。

Abstract: Foundation models like Segment Anything Model (SAM) excel in promptable
segmentation but suffer from an intent gap: they segment only explicitly
prompted objects, failing to generalize to semantically related instances
implicitly desired by users. This limitation is critical in domains with dense
homogeneous objects (e.g., biomedical nuclei segmentation), where sparse visual
prompts typically yield incomplete results, rendering dense annotations
impractical due to prohibitive cost. To bridge this gap, we introduce SAMPO
(Segment Anything Model with Preference Optimization), a novel framework that
teaches visual foundation models to infer high-level categorical intent from
sparse visual interactions. Unlike conventional pixel-level fine-tuning, SAMPO
optimizes models to implicitly capture target-class characteristics through
preference optimization. This approach, which operates without dependency on
language models, enables robust multi-object segmentation even under sparse
prompting and demonstrates superior data efficiency during fine-tuning.
Validated on three medical segmentation tasks, SAMPO achieves state-of-the-art
performance: on challenging tasks like PanNuke-T2, our method, when fine-tuned
with only 10% of the training data, significantly outperforms all existing
methods trained on the full 100% dataset, achieving an improvement of over 9
percentage points compared to the best baseline. Our work establishes a new
paradigm for intent-aware alignment in visual foundation models, removing
dependencies on auxiliary prompt generators or language-model-assisted
preference learning.

</details>


### [216] [Multi-class Image Anomaly Detection for Practical Applications: Requirements and Robust Solutions](https://arxiv.org/abs/2508.02477)
*Jaehyuk Heo,Pilsung Kang*

Main category: cs.CV

TL;DR: HierCore是一个新框架，可以在有无类别标签的情况下进行多类别图像异常检测，并且在各种场景下都表现稳定。


<details>
  <summary>Details</summary>
Motivation: 在多类别图像异常检测中，当单个模型需要处理多个类别时，其性能通常不如特定类别的模型。尽管以往的研究主要集中在缩小这种性能差距，但类别信息的利用方式这一影响决策阈值设定的因素却鲜有研究。

Method: 提出了一种名为Hierarchical Coreset (HierCore) 的新颖框架，该框架利用分层记忆库来估计用于异常检测的类别区分标准，即使在没有类别标签的情况下也能有效运行。

Result: 实验结果表明，HierCore 框架在四个不同的场景（根据训练和评估阶段是否存在类别标签确定）下均表现出优越的性能和鲁棒性。

Conclusion: HierCore框架在所有设置下均能持续满足要求且保持强大稳定的性能，突显了其在现实世界多类别异常检测任务中的实际潜力。

Abstract: Recent advances in image anomaly detection have extended unsupervised
learning-based models from single-class settings to multi-class frameworks,
aiming to improve efficiency in training time and model storage. When a single
model is trained to handle multiple classes, it often underperforms compared to
class-specific models in terms of per-class detection accuracy. Accordingly,
previous studies have primarily focused on narrowing this performance gap.
However, the way class information is used, or not used, remains a relatively
understudied factor that could influence how detection thresholds are defined
in multi-class image anomaly detection. These thresholds, whether
class-specific or class-agnostic, significantly affect detection outcomes. In
this study, we identify and formalize the requirements that a multi-class image
anomaly detection model must satisfy under different conditions, depending on
whether class labels are available during training and evaluation. We then
re-examine existing methods under these criteria. To meet these challenges, we
propose Hierarchical Coreset (HierCore), a novel framework designed to satisfy
all defined requirements. HierCore operates effectively even without class
labels, leveraging a hierarchical memory bank to estimate class-wise decision
criteria for anomaly detection. We empirically validate the applicability and
robustness of existing methods and HierCore under four distinct scenarios,
determined by the presence or absence of class labels in the training and
evaluation phases. The experimental results demonstrate that HierCore
consistently meets all requirements and maintains strong, stable performance
across all settings, highlighting its practical potential for real-world
multi-class anomaly detection tasks.

</details>


### [217] [Fine-grained Multiple Supervisory Network for Multi-modal Manipulation Detecting and Grounding](https://arxiv.org/abs/2508.02479)
*Xinquan Yu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: The paper presents a new network (FMS) to better detect manipulated multimedia content by improving how it uses information from different sources (like images and text) and by looking closer at the details of the manipulation. It performs better than current methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for Detecting and Grounding Multi-Modal Media Manipulation (DGM$^4$) suffer from performance limitations due to ignoring interference from unreliable unimodal data and lacking comprehensive forgery supervision to capture fine-grained tampering traces.

Method: The paper introduces a Fine-grained Multiple Supervisory (FMS) network with three key modules: Multimodal Decision Supervised Correction (MDSC) for modality reliability, Unimodal Forgery Mining Reinforcement (UFMR) for unimodal internal supervision, and Multimodal Forgery Alignment Reasoning (MFAR) for cross-modal supervision. MDSC uses weak unimodal supervision to correct multimodal decision-making. UFMR enhances the distinction between real and fake information within unimodal data at feature and sample levels. MFAR employs soft-attention for cross-modal feature perception, considering both consistency and inconsistency, with interaction constraints to ensure quality.

Result: Extensive experiments show that the FMS network outperforms existing state-of-the-art methods in DGM$^4$ detection.

Conclusion: The proposed Fine-grained Multiple Supervisory (FMS) network demonstrates superior performance compared to state-of-the-art methods in Detecting and Grounding Multi-Modal Media Manipulation (DGM$^4$).

Abstract: The task of Detecting and Grounding Multi-Modal Media Manipulation (DGM$^4$)
is a branch of misinformation detection. Unlike traditional binary
classification, it includes complex subtasks such as forgery content
localization and forgery method classification. Consider that existing methods
are often limited in performance due to neglecting the erroneous interference
caused by unreliable unimodal data and failing to establish comprehensive
forgery supervision for mining fine-grained tampering traces. In this paper, we
present a Fine-grained Multiple Supervisory (FMS) network, which incorporates
modality reliability supervision, unimodal internal supervision and cross-modal
supervision to provide comprehensive guidance for DGM$^4$ detection. For
modality reliability supervision, we propose the Multimodal Decision Supervised
Correction (MDSC) module. It leverages unimodal weak supervision to correct the
multi-modal decision-making process. For unimodal internal supervision, we
propose the Unimodal Forgery Mining Reinforcement (UFMR) module. It amplifies
the disparity between real and fake information within unimodal modality from
both feature-level and sample-level perspectives. For cross-modal supervision,
we propose the Multimodal Forgery Alignment Reasoning (MFAR) module. It
utilizes soft-attention interactions to achieve cross-modal feature perception
from both consistency and inconsistency perspectives, where we also design the
interaction constraints to ensure the interaction quality. Extensive
experiments demonstrate the superior performance of our FMS compared to
state-of-the-art methods.

</details>


### [218] [MindShot: Multi-Shot Video Reconstruction from fMRI with LLM Decoding](https://arxiv.org/abs/2508.02480)
*Wenwen Zeng,Yonghuang Wu,Yifan Chen,Xuan Xie,Chengqian Zhao,Feiyu Yin,Guoqing Wu,Jinhua Yu*

Main category: cs.CV

TL;DR: 提出了一种新颖的“divide-and-decode”框架，用于从fMRI信号重建多镜头视频。通过分解fMRI信号和利用LLM生成文本描述，克服了现有方法的局限性，并在重建保真度方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 目前的fMRI视频重建方法仅限于单镜头片段，无法解决现实世界体验的多镜头性质，面临fMRI信号混合、时域分辨率不匹配以及缺乏专用数据集等挑战。

Method: 提出了一种新颖的“divide-and-decode”框架，包括一个显式分解fMRI信号的镜头边界预测模块，以及利用LLM进行生成式关键帧描述以克服时间模糊性的模块，并通过大规模数据合成（20k样本）进行了训练。

Result: 实验结果表明，本研究的框架在多镜头重建保真度方面优于最先进的方法。消融研究证实了fMRI分解和语义描述的关键作用，其中分解将解码的caption CLIP相似度显著提高了71.8%。

Conclusion: 本研究提出的“divide-and-decode”框架通过显式分解和语义提示，实现了多镜头fMRI视频重建，能够准确恢复复杂的视觉叙事，为多镜头fMRI重建树立了新范例。

Abstract: Reconstructing dynamic videos from fMRI is important for understanding visual
cognition and enabling vivid brain-computer interfaces. However, current
methods are critically limited to single-shot clips, failing to address the
multi-shot nature of real-world experiences. Multi-shot reconstruction faces
fundamental challenges: fMRI signal mixing across shots, the temporal
resolution mismatch between fMRI and video obscuring rapid scene changes, and
the lack of dedicated multi-shot fMRI-video datasets. To overcome these
limitations, we propose a novel divide-and-decode framework for multi-shot fMRI
video reconstruction. Our core innovations are: (1) A shot boundary predictor
module explicitly decomposing mixed fMRI signals into shot-specific segments.
(2) Generative keyframe captioning using LLMs, which decodes robust textual
descriptions from each segment, overcoming temporal blur by leveraging
high-level semantics. (3) Novel large-scale data synthesis (20k samples) from
existing datasets. Experimental results demonstrate our framework outperforms
state-of-the-art methods in multi-shot reconstruction fidelity. Ablation
studies confirm the critical role of fMRI decomposition and semantic
captioning, with decomposition significantly improving decoded caption CLIP
similarity by 71.8%. This work establishes a new paradigm for multi-shot fMRI
reconstruction, enabling accurate recovery of complex visual narratives through
explicit decomposition and semantic prompting.

</details>


### [219] [Low-Frequency First: Eliminating Floating Artifacts in 3D Gaussian Splatting](https://arxiv.org/abs/2508.02493)
*Jianchao Wang,Peng Zhou,Cen Li,Rong Quan,Jie Qin*

Main category: cs.CV

TL;DR: EFA-GS 通过解决 3DGS 中的浮动伪影问题来提高 3D 重建的质量，通过优化高斯核扩展来保留细节。


<details>
  <summary>Details</summary>
Motivation: 3DGS 在 3D 重建方面强大且计算效率高，但经常产生浮动的伪影，特别是在低质量初始化的情况下。这些伪影会严重降低视觉保真度，但其根本原因尚未得到充分探索。

Method: 提出了一种名为 EFA-GS 的新方法，该方法通过选择性地扩展欠优化的高斯核来优先学习准确的低频信息。此外，还引入了基于深度和基于尺度的策略来动态地优化高斯核的扩展，从而有效缓解细节的侵蚀。

Result: EFA-GS 显著减少了浮动伪影，同时保留了高频细节，在 RWLQ 数据集上相比基线方法 PSNR 提高了 1.68 dB。

Conclusion: EFA-GS 显著减少了浮动伪影，同时保留了高频细节，在 RWLQ 数据集上相比基线方法 PSNR 提高了 1.68 dB。此外，在下游 3D 编辑任务中也验证了该方法的有效性。

Abstract: 3D Gaussian Splatting (3DGS) is a powerful and computationally efficient
representation for 3D reconstruction. Despite its strengths, 3DGS often
produces floating artifacts, which are erroneous structures detached from the
actual geometry and significantly degrade visual fidelity. The underlying
mechanisms causing these artifacts, particularly in low-quality initialization
scenarios, have not been fully explored. In this paper, we investigate the
origins of floating artifacts from a frequency-domain perspective and identify
under-optimized Gaussians as the primary source. Based on our analysis, we
propose \textit{Eliminating-Floating-Artifacts} Gaussian Splatting (EFA-GS),
which selectively expands under-optimized Gaussians to prioritize accurate
low-frequency learning. Additionally, we introduce complementary depth-based
and scale-based strategies to dynamically refine Gaussian expansion,
effectively mitigating detail erosion. Extensive experiments on both synthetic
and real-world datasets demonstrate that EFA-GS substantially reduces floating
artifacts while preserving high-frequency details, achieving an improvement of
1.68 dB in PSNR over baseline method on our RWLQ dataset. Furthermore, we
validate the effectiveness of our approach in downstream 3D editing tasks. Our
implementation will be released on GitHub.

</details>


### [220] [Rethinking Transparent Object Grasping: Depth Completion with Monocular Depth Estimation and Instance Mask](https://arxiv.org/abs/2508.02507)
*Yaofeng Cheng,Xinkai Gao,Sen Zhang,Chao Zeng,Fusheng Zha,Lining Sun,Chenguang Yang*

Main category: cs.CV

TL;DR: 提出了一种名为ReMake的新框架，通过实例掩模和单目深度估计来改进透明物体的深度补全，解决了现有方法在真实世界场景中的泛化能力不足的问题，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 由于光学特性的原因，透明物体常常导致深度相机生成不完整或无效的深度数据，从而降低了机器人抓取操作的准确性和可靠性。现有方法通常将RGB-D图像直接输入网络以输出完整的深度图，但这些方法在真实世界场景中的泛化能力不足。

Method: 提出了一种新颖的、由实例掩模和单目深度估计引导的深度补全框架，通过显式区分透明区域和非透明区域，使模型能够专注于从RGB-D输入中学习这些区域的准确深度估计，并利用单目深度估计提供透明物体与其周围环境之间的深度上下文。

Result: ReMake框架通过显式区分透明区域并利用单目深度估计提供深度上下文，提高了深度补全的准确性和泛化能力，在各种场景下均表现优于现有方法。

Conclusion: ReMake方法在基准数据集和真实场景的实验中均优于现有方法，证明了其在准确性和泛化能力方面的优越性。

Abstract: Due to the optical properties, transparent objects often lead depth cameras
to generate incomplete or invalid depth data, which in turn reduces the
accuracy and reliability of robotic grasping. Existing approaches typically
input the RGB-D image directly into the network to output the complete depth,
expecting the model to implicitly infer the reliability of depth values.
However, while effective in training datasets, such methods often fail to
generalize to real-world scenarios, where complex light interactions lead to
highly variable distributions of valid and invalid depth data. To address this,
we propose ReMake, a novel depth completion framework guided by an instance
mask and monocular depth estimation. By explicitly distinguishing transparent
regions from non-transparent ones, the mask enables the model to concentrate on
learning accurate depth estimation in these areas from RGB-D input during
training. This targeted supervision reduces reliance on implicit reasoning and
improves generalization to real-world scenarios. Additionally, monocular depth
estimation provides depth context between the transparent object and its
surroundings, enhancing depth prediction accuracy. Extensive experiments show
that our method outperforms existing approaches on both benchmark datasets and
real-world scenarios, demonstrating superior accuracy and generalization
capability. Code and videos are available at
https://chengyaofeng.github.io/ReMake.github.io/.

</details>


### [221] [Engagement Prediction of Short Videos with Large Multimodal Models](https://arxiv.org/abs/2508.02516)
*Wei Sun,Linhan Cao,Yuqin Cao,Weixia Zhang,Wen Wen,Kaiwei Zhang,Zijian Chen,Fangfang Lu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 大型多模态模型（LMM），特别是包含音频信息的模型，在短视频参与度预测任务中表现出色，超越了仅使用视觉和语言信息的模型。研究团队通过集成不同模态的LMM，在相关挑战赛中夺冠。


<details>
  <summary>Details</summary>
Motivation: 随着短视频平台用户生成内容（UGC）的快速增长，视频参与度预测对于优化推荐系统和指导内容创作变得日益重要。然而，由于语义内容、视觉质量、音频特性和用户背景等复杂因素的相互作用，这一任务仍然充满挑战。现有研究在处理跨特征和跨模态交互方面存在不足。

Method: 本研究探索了大型多模态模型（LMM）在视频参与度预测中的应用，对比了整合音频、视觉和语言模态的VideoLLaMA2与仅整合视觉和语言模态的Qwen2.5-VL。研究使用SnapUGC数据集对模型进行了训练，并在ICCV VQualA 2025 EVQA-SnapUGC挑战赛中通过集成两种模型取得了领先成果。

Result: 在SnapUGC数据集上，两种模型均表现出与现有最先进模型相媲比的性能。VideoLLaMA2的性能持续优于Qwen2.5-VL，证明了音频特征对于参与度预测的重要性。最终，通过集成这两种模型，研究团队在短视频参与度预测的ICCV VQualA 2025 EVQA-SnapUGC挑战赛中获得了第一名。

Conclusion: 该研究表明，大型多模态模型（LMM）在短视频参与度预测方面具有巨大潜力，其中整合了音频、视觉和语言信息（如VideoLLaMA2）的模型优于仅使用视觉和语言信息（如Qwen2.5-VL）的模型，这突显了音频特征在参与度预测中的重要性。通过集成这两种模型，研究团队在ICCV VQualA 2025 EVQA-SnapUGC挑战赛中取得了优异成绩。

Abstract: The rapid proliferation of user-generated content (UGC) on short-form video
platforms has made video engagement prediction increasingly important for
optimizing recommendation systems and guiding content creation. However, this
task remains challenging due to the complex interplay of factors such as
semantic content, visual quality, audio characteristics, and user background.
Prior studies have leveraged various types of features from different
modalities, such as visual quality, semantic content, background sound, etc.,
but often struggle to effectively model their cross-feature and cross-modality
interactions. In this work, we empirically investigate the potential of large
multimodal models (LMMs) for video engagement prediction. We adopt two
representative LMMs: VideoLLaMA2, which integrates audio, visual, and language
modalities, and Qwen2.5-VL, which models only visual and language modalities.
Specifically, VideoLLaMA2 jointly processes key video frames, text-based
metadata, and background sound, while Qwen2.5-VL utilizes only key video frames
and text-based metadata. Trained on the SnapUGC dataset, both models
demonstrate competitive performance against state-of-the-art baselines,
showcasing the effectiveness of LMMs in engagement prediction. Notably,
VideoLLaMA2 consistently outperforms Qwen2.5-VL, highlighting the importance of
audio features in engagement prediction. By ensembling two types of models, our
method achieves first place in the ICCV VQualA 2025 EVQA-SnapUGC Challenge on
short-form video engagement prediction. The code is available at
https://github.com/sunwei925/LMM-EVQA.git.

</details>


### [222] [Understanding the Risks of Asphalt Art on the Reliability of Surveillance Perception Systems](https://arxiv.org/abs/2508.02530)
*Jin Ma,Abyad Enan,Long Cheng,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 艺术性人行横道可能会因为视觉复杂性而损害行人检测系统的性能，尤其是复杂的、视觉上显著的设计。敌对性设计甚至可能被用来操纵检测结果。


<details>
  <summary>Details</summary>
Motivation: 艺术性人行横道旨在提高行人的可见性和安全性，但其视觉复杂性可能会干扰依赖基于视觉的物体检测模型的监控系统。本研究旨在调查艺术性人行横道对行人检测性能的影响。

Method: 本研究通过将各种街头艺术图案合成到固定的监控场景中来构建现实的人行横道场景，并在良性和对抗性条件下评估模型在艺术性人行横道上检测行人性能。

Result: 结果表明，简单的基于颜色的设计影响很小，但复杂的艺术图案，特别是视觉显著性高的图案，会显著降低行人检测性能。此外，研究证明了精心设计的艺术性人行横道可以被利用来故意隐藏真实行人或产生不存在的行人检测。

Conclusion: 艺术性人行横道，尽管旨在提高行人和车辆的安全性，但其视觉复杂性可能会损害基于视觉的物体检测模型的性能。简单的基于颜色的设计影响很小，但复杂的艺术图案（尤其是视觉显著性高的图案）会严重降低行人检测性能。此外，精心设计的敌对性艺术性人行横道可能会被用来故意隐藏真实行人或产生不存在的行人检测。这些发现揭示了城市基于视觉的行人监控系统的一个潜在漏洞，并强调了在设计鲁棒的行人感知模型时考虑环境视觉变化的重要性。

Abstract: Artistic crosswalks featuring asphalt art, introduced by different
organizations in recent years, aim to enhance the visibility and safety of
pedestrians. However, their visual complexity may interfere with surveillance
systems that rely on vision-based object detection models. In this study, we
investigate the impact of asphalt art on pedestrian detection performance of a
pretrained vision-based object detection model. We construct realistic
crosswalk scenarios by compositing various street art patterns into a fixed
surveillance scene and evaluate the model's performance in detecting
pedestrians on asphalt-arted crosswalks under both benign and adversarial
conditions. A benign case refers to pedestrian crosswalks painted with existing
normal asphalt art, whereas an adversarial case involves digitally crafted or
altered asphalt art perpetrated by an attacker. Our results show that while
simple, color-based designs have minimal effect, complex artistic patterns,
particularly those with high visual salience, can significantly degrade
pedestrian detection performance. Furthermore, we demonstrate that
adversarially crafted asphalt art can be exploited to deliberately obscure real
pedestrians or generate non-existent pedestrian detections. These findings
highlight a potential vulnerability in urban vision-based pedestrian
surveillance systems and underscore the importance of accounting for
environmental visual variations when designing robust pedestrian perception
models.

</details>


### [223] [Precision-Aware Video Compression for Reducing Bandwidth Requirements in Video Communication for Vehicle Detection-Based Applications](https://arxiv.org/abs/2508.02533)
*Abyad Enan,Jon C Calhoun,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 为解决智能交通系统中因带宽限制导致的车辆检测性能下降问题，本研究提出了精确感知视频编码（PAVC）框架。该框架能根据天气和光照条件动态调整视频压缩，成功在提高车辆检测准确率（高达13%）和显著降低带宽需求（高达72倍）之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 在智能交通系统（ITS）中，尽管计算机视觉技术通过 roadside 摄像头提供了强大的车辆检测能力，但实时视频传输对通信带宽提出了很高要求。有限的带宽可能导致通信瓶颈，影响ITS应用的实时性。虽然有损视频压缩可以降低带宽需求，但会牺牲视频质量，进而影响车辆检测的准确性。此外，天气和光照条件也会影响检测精度，因此需要动态调整压缩级别以应对这些变化。

Method: 该研究提出了一种名为精确感知视频编码（PAVC）的框架，用于智能交通系统（ITS）中的车辆检测。该框架通过 roadside 摄像头捕捉车辆视频，并根据当前的天气和光照条件动态调整视频压缩级别，然后将压缩后的视频传输到处理单元，运行车辆检测算法，以实现碰撞风险评估等安全关键应用。

Result: PAVC框架在车辆检测准确性和带宽使用方面均取得了显著成效。实验结果表明，在可用带宽适中的情况下，PAVC可将车辆检测准确率提高高达13%，并将通信带宽需求降低高达8.23倍。在带宽严重受限的区域，PAVC的带宽需求更是降低了72倍，同时仍能保持车辆检测性能。

Conclusion: 该研究提出了一种名为精确感知视频编码（PAVC）的框架，通过动态调整视频压缩级别来优化智能交通系统（ITS）中的车辆检测性能。PAVC能够根据天气和光照条件自适应地调整压缩率，以在满足带宽限制的同时，最大限度地提高车辆检测的准确性，尤其是在带宽受限的场景下，其性能提升尤为显著。

Abstract: Computer vision has become a popular tool in intelligent transportation
systems (ITS), enabling various applications through roadside traffic cameras
that capture video and transmit it in real time to computing devices within the
same network. The efficiency of this video transmission largely depends on the
available bandwidth of the communication system. However, limited bandwidth can
lead to communication bottlenecks, hindering the real-time performance of ITS
applications. To mitigate this issue, lossy video compression techniques can be
used to reduce bandwidth requirements, at the cost of degrading video quality.
This degradation can negatively impact the accuracy of applications that rely
on real-time vehicle detection. Additionally, vehicle detection accuracy is
influenced by environmental factors such as weather and lighting conditions,
suggesting that compression levels should be dynamically adjusted in response
to these variations. In this work, we utilize a framework called
Precision-Aware Video Compression (PAVC), where a roadside video camera
captures footage of vehicles on roadways, compresses videos, and then transmits
them to a processing unit, running a vehicle detection algorithm for
safety-critical applications, such as real-time collision risk assessment. The
system dynamically adjusts the video compression level based on current weather
and lighting conditions to maintain vehicle detection accuracy while minimizing
bandwidth usage. Our results demonstrate that PAVC improves vehicle detection
accuracy by up to 13% and reduces communication bandwidth requirements by up to
8.23x in areas with moderate bandwidth availability. Moreover, in locations
with severely limited bandwidth, PAVC reduces bandwidth requirements by up to
72x while preserving vehicle detection performance.

</details>


### [224] [ReMoMask: Retrieval-Augmented Masked Motion Generation](https://arxiv.org/abs/2508.02605)
*Zhengdao Li,Siheng Wang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: ReMoMask 是一个统一的文本到运动（T2M）生成框架，通过创新的双向动量文本-运动模型、语义时空注意力和 RAG-Classier-Free Guidance 解决了现有方法的局限性，提高了运动生成的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到运动（T2M）生成方法面临生成模型（如扩散模型）多样性有限、累积误差和物理上不合理的问题，以及检索增强生成（RAG）方法存在的扩散惯性、部分模式崩溃和异步伪影等双重挑战。

Method: 1) 双向动量文本-运动模型通过动量队列将负样本尺度与批次大小解耦，显著提高了跨模态检索精度；2) 语义时空注意力机制在部分融合过程中强制执行生物力学约束，以消除异步伪影；3) RAG-Classier-Free Guidance 结合了少量无条件生成以增强泛化能力。ReMoMask 基于 MoMask 的 RVQ-VAE，能够高效地在最少的步骤中生成时间上连贯的运动。

Result: ReMoMask 在 HumanML3D 和 KIT-ML 基准上实现了最先进的性能。

Conclusion: ReMoMask 在 HumanML3D 和 KIT-ML 标准基准上展现了最先进的性能，与之前的最先进方法 RAG-T2M 相比，在 FID 分数上分别提高了 3.88% 和 10.97%。

Abstract: Text-to-Motion (T2M) generation aims to synthesize realistic and semantically
aligned human motion sequences from natural language descriptions. However,
current approaches face dual challenges: Generative models (e.g., diffusion
models) suffer from limited diversity, error accumulation, and physical
implausibility, while Retrieval-Augmented Generation (RAG) methods exhibit
diffusion inertia, partial-mode collapse, and asynchronous artifacts. To
address these limitations, we propose ReMoMask, a unified framework integrating
three key innovations: 1) A Bidirectional Momentum Text-Motion Model decouples
negative sample scale from batch size via momentum queues, substantially
improving cross-modal retrieval precision; 2) A Semantic Spatio-temporal
Attention mechanism enforces biomechanical constraints during part-level fusion
to eliminate asynchronous artifacts; 3) RAG-Classier-Free Guidance incorporates
minor unconditional generation to enhance generalization. Built upon MoMask's
RVQ-VAE, ReMoMask efficiently generates temporally coherent motions in minimal
steps. Extensive experiments on standard benchmarks demonstrate the
state-of-the-art performance of ReMoMask, achieving a 3.88% and 10.97%
improvement in FID scores on HumanML3D and KIT-ML, respectively, compared to
the previous SOTA method RAG-T2M. Code:
https://github.com/AIGeeksGroup/ReMoMask. Website:
https://aigeeksgroup.github.io/ReMoMask.

</details>


### [225] [Evaluating Variance in Visual Question Answering Benchmarks](https://arxiv.org/abs/2508.02645)
*Nikitha SR*

Main category: cs.CV

TL;DR: 本研究分析了 MLLMs 在 VQA 任务中的性能变异性，强调了当前评估方法的局限性，并提倡采用考虑方差的方法。


<details>
  <summary>Details</summary>
Motivation: 当前 MLLMs 的 VQA 评估通常依赖点估计，忽略了由随机模型输出、训练种子敏感性和超参数配置等因素引起的性能方差。

Method: 分析了训练种子、框架非确定性、模型规模和扩展指令微调对性能变异性的影响，并探索了 Cloze 风格评估作为减少随机性和提高跨基准可靠性的替代评估策略。

Result: MLLMs 在 14 个 VQA 基准上的评估显示出显著的性能变异性，强调了现有评估方法的局限性。

Conclusion: 评估方法应考虑方差，以促进 MLLMs 的更可靠发展。

Abstract: Multimodal large language models (MLLMs) have emerged as powerful tools for
visual question answering (VQA), enabling reasoning and contextual
understanding across visual and textual modalities. Despite their advancements,
the evaluation of MLLMs on VQA benchmarks often relies on point estimates,
overlooking the significant variance in performance caused by factors such as
stochastic model outputs, training seed sensitivity, and hyperparameter
configurations. This paper critically examines these issues by analyzing
variance across 14 widely used VQA benchmarks, covering diverse tasks such as
visual reasoning, text understanding, and commonsense reasoning. We
systematically study the impact of training seed, framework non-determinism,
model scale, and extended instruction finetuning on performance variability.
Additionally, we explore Cloze-style evaluation as an alternate assessment
strategy, studying its effectiveness in reducing stochasticity and improving
reliability across benchmarks. Our findings highlight the limitations of
current evaluation practices and advocate for variance-aware methodologies to
foster more robust and reliable development of MLLMs.

</details>


### [226] [PMGS: Reconstruction of Projectile Motion across Large Spatiotemporal Spans via 3D Gaussian Splatting](https://arxiv.org/abs/2508.02660)
*Yijun Xu,Jingrui Zhang,Yuhan Chen,Dingwen Wang,Lei Yu,Chu He*

Main category: cs.CV

TL;DR: PMGS通过动态场景分解、点密度控制、SE(3)姿态学习、加速度一致性约束、动态模拟退火和卡尔曼融合，实现了对高速非线性刚体运动的精确三维重建。


<details>
  <summary>Details</summary>
Motivation: 解决在动态重建中对大时空跨度的复杂刚体运动进行建模的挑战，并解决现有范例主要局限于短期、小范围变形且对物理一致性考虑有限的问题。

Method: 提出了一种名为PMGS的工作流程，包括目标建模（通过动态场景分解和改进的点密度控制实现对象中心重建）和运动恢复（通过学习每帧SE(3)姿态来恢复完整的运动序列）。引入了加速度一致性约束来桥接牛顿力学和姿态估计，设计了动态模拟退火策略来根据运动状态自适应地调整学习率，并设计了卡尔曼融合方案来优化多源观测的误差累积，以减轻干扰。

Result: PMGS在高速非线性刚体运动重建方面表现优于主流动态方法。

Conclusion: PMGS在高速非线性刚体运动重建方面优于主流动态方法。

Abstract: Modeling complex rigid motion across large spatiotemporal spans remains an
unresolved challenge in dynamic reconstruction. Existing paradigms are mainly
confined to short-term, small-scale deformation and offer limited consideration
for physical consistency. This study proposes PMGS, focusing on reconstructing
Projectile Motion via 3D Gaussian Splatting. The workflow comprises two stages:
1) Target Modeling: achieving object-centralized reconstruction through dynamic
scene decomposition and an improved point density control; 2) Motion Recovery:
restoring full motion sequences by learning per-frame SE(3) poses. We introduce
an acceleration consistency constraint to bridge Newtonian mechanics and pose
estimation, and design a dynamic simulated annealing strategy that adaptively
schedules learning rates based on motion states. Futhermore, we devise a Kalman
fusion scheme to optimize error accumulation from multi-source observations to
mitigate disturbances. Experiments show PMGS's superior performance in
reconstructing high-speed nonlinear rigid motion compared to mainstream dynamic
methods.

</details>


### [227] [MedVLThinker: Simple Baselines for Multimodal Medical Reasoning](https://arxiv.org/abs/2508.02669)
*Xiaoke Huang,Juncheng Wu,Hui Liu,Xianfeng Tang,Yuyin Zhou*

Main category: cs.CV

TL;DR: 本文介绍了MedVLThinker，一个用于医学大型语言模型（LLMs）的开源方法，通过数据整理和RLVR训练范式显著提升了模型的推理能力。该方法在医学QA任务上取得了SOTA成果，并发布了相关数据、模型和代码以促进社区研究。


<details>
  <summary>Details</summary>
Motivation: 当前在构建面向推理的医学大型语言模型（LLMs）方面缺乏公开且可复现的方法，这阻碍了社区在该领域的研究、分析和比较。因此，本文旨在提供一套简单但有效的基线方法。

Method: 本文提出了一种名为MedVLThinker的开源方法，用于构建以推理为中心的医学大型语言模型（LLMs）。该方法包含两个关键部分：（1）数据整理：系统性地收集和筛选文本和图像-文本医学数据，并根据推理难度进行区分。（2）训练范式：采用监督微调（SFT）和基于可验证奖励的强化学习（RLVR）。实验在Qwen2.5-VL模型（3B、7B）和六个医学QA基准上进行。

Result: 研究结果表明，RLVR范式在各项医学QA基准测试中始终显著优于SFT范式。一个重要的反直觉发现是，在RLVR框架下，使用整理后的纯文本数据进行训练比使用多模态图像-文本数据训练能带来更显著的性能提升。此外，使用RLVR和纯文本数据训练的最佳7B模型在现有公共VQA基准上设定了新的SOTA，超越了所有先前的开源医学LLMs。将模型扩展到32B后，其性能与GPT-4o相当。

Conclusion: MedVLThinker通过其开源的配方（包括数据整理和SFT、RLVR训练范式）在医学领域的大型语言模型（LLMs）研究方面取得了显著进展。RLVR范式优于SFT，而仅文本数据训练在RLVR框架下比多模态数据训练带来更大的性能提升。其最佳7B模型在公共VQA基准上达到了新的SOTA，32B模型性能与GPT-4o相当。研究者发布了所有数据、模型和代码，为社区研究提供了基础。

Abstract: Large Reasoning Models (LRMs) have introduced a new paradigm in AI by
enabling models to ``think before responding" via chain-of-thought reasoning.
However, the absence of open and reproducible recipes for building
reasoning-centric medical LMMs hinders community-wide research, analysis, and
comparison. In this paper, we present MedVLThinker, a suite of simple yet
strong baselines. Our fully open recipe consists of: (1) systematic data
curation for both text-only and image-text medical data, filtered according to
varying levels of reasoning difficulty, and (2) two training paradigms:
Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement
Learning with Verifiable Rewards (RLVR) based on final answer correctness.
Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six
medical QA benchmarks, we find that RLVR consistently and significantly
outperforms SFT. Additionally, under the RLVR framework, a key,
counter-intuitive finding is that training on our curated text-only reasoning
data provides a more substantial performance boost than training on multimodal
image-text data. Our best open 7B model, trained using the RLVR recipe on
text-only data, establishes a new state-of-the-art on existing public VQA
benchmarks, surpassing all previous open-source medical LMMs. Furthermore,
scaling our model to 32B achieves performance on par with the proprietary
GPT-4o. We release all curated data, models, and code to provide the community
with a strong, open foundation for future research in multimodal medical
reasoning.

</details>


### [228] [Raw Data Matters: Enhancing Prompt Tuning by Internal Augmentation on Vision-Language Models](https://arxiv.org/abs/2508.02671)
*Haoyang Li,Liang Wang,Chao Wang,Siyu Zhou,Jing Jiang,Yan Peng,Guodong Long*

Main category: cs.CV

TL;DR: AugPT 是一种新的数据增强方法，用于 CLIP 模型的提示调优，它使用自监督学习和门控机制来提高性能，而无需外部知识。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 CLIP 的提示调优方法通常依赖外部知识进行数据增强，从而增加了成本。该方法旨在通过仅使用内部增强来解决这个问题，以更好地利用图像模态中的已知特征。

Method: AugPT 是一种基于自包含蒸馏的提示调优方法，它利用未标记图像的自监督增强，并通过基于共识测试的新型门控机制过滤噪声样本，以利用已知特征。

Result: 实验证明，AugPT 在不使用外部知识的情况下，可以同时提高模型的性能和泛化能力。

Conclusion: AugPT 可以在不使用外部知识的情况下，通过利用内部增强来提高 CLIP 模型的性能和泛化能力。

Abstract: For CLIP-based prompt tuning, introducing more data as additional knowledge
for enhancing fine-tuning process is proved to be an effective approach.
Existing data amplification strategies for prompt tuning typically rely on
external knowledge (e.g., large language models or pre-structured knowledge
bases), resulting in higher costs for data collection and processing, while
generally ignoring further utilization of features in image modality. To
address this, we propose Augmentation-driven Prompt Tuning (AugPT), a
self-contained distillation-based prompt tuning approach using only internal
augmentation on raw dataset to better exploit known features. Specifically,
AugPT employs self-supervised augmentation on unlabeled images in the training
set, and introduces a novel gating mechanism based on consensus test, reusing
the pre-trained prompt tuning backbone model to spontaneously filter noisy
samples, further enhancing the quality of augmented views. Extensive
experiments validate that AugPT simultaneously enhances model performance and
generalization capability without using appended external knowledge. The code
of AugPT is available at: https://github.com/JREion/AugPT .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [229] [Rethinking Graph-Based Document Classification: Learning Data-Driven Structures Beyond Heuristic Approaches](https://arxiv.org/abs/2508.00864)
*Margarita Bugueño,Gerard de Melo*

Main category: cs.CL

TL;DR: 本文提出了一种新的文档分类方法，通过自注意力模型自动学习句子间的关系来构建图结构，并使用统计过滤来优化图，实验证明该方法优于传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图模型虽然能有效捕捉文档结构，但依赖启发式、领域特定规则或专家知识，而本文旨在提出一种学习数据驱动的图结构的方法，以消除手动设计并减少领域依赖性。

Method: 提出了一种学习数据驱动的图结构的方法，将句子作为节点，并通过自注意力模型学习句子对之间的边，然后使用统计过滤策略保留强相关句子，从而构建同质加权图。

Result: 在三个文档分类数据集上的实验表明，学习到的图结构在准确率和 F1 分数上持续优于基于启发式方法的图结构。

Conclusion: 学习到的图结构比基于启发式方法的图结构更优越，在准确率和 F1 分数方面均表现更好，并且所提出的统计过滤策略能提升模型鲁棒性，证明了自动图生成相对于传统启发式方法的潜力，并为 NLP 领域的广泛应用开辟了新方向。

Abstract: In document classification, graph-based models effectively capture document
structure, overcoming sequence length limitations and enhancing contextual
understanding. However, most existing graph document representations rely on
heuristics, domain-specific rules, or expert knowledge. Unlike previous
approaches, we propose a method to learn data-driven graph structures,
eliminating the need for manual design and reducing domain dependence. Our
approach constructs homogeneous weighted graphs with sentences as nodes, while
edges are learned via a self-attention model that identifies dependencies
between sentence pairs. A statistical filtering strategy aims to retain only
strongly correlated sentences, improving graph quality while reducing the graph
size. Experiments on three document classification datasets demonstrate that
learned graphs consistently outperform heuristic-based graphs, achieving higher
accuracy and $F_1$ score. Furthermore, our study demonstrates the effectiveness
of the statistical filtering in improving classification robustness. These
results highlight the potential of automatic graph generation over traditional
heuristic approaches and open new directions for broader applications in NLP.

</details>


### [230] [FECT: Factuality Evaluation of Interpretive AI-Generated Claims in Contact Center Conversation Transcripts](https://arxiv.org/abs/2508.00889)
*Hagyeong Shin,Binoy Robin Dalal,Iwona Bialynicka-Birula,Navjot Matharu,Ryan Muir,Xingwei Yang,Samuel W. K. Wong*

Main category: cs.CL

TL;DR: 为了解决联络中心对话分析中LLM的幻觉问题，我们提出了3D范式（分解、分离、分离）和FECT数据集，以提高事实评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在企业应用中可能出现的幻觉问题，尤其是在分析和总结联络中心对话时，由于缺乏事实标签而难以进行事实评估的挑战。

Method: 提出了一种名为“3D”（分解、分离、分离）的范式，并将其应用于人类注释指南和LLM-judges提示中，以将事实标签基于语言学知情的评估标准。构建了一个名为“FECT”的新基准数据集，用于对联络中心对话 transcripts 中解释性AI生成的声明进行事实评估。

Result: LLMs在分析和总结联络中心对话时，由于缺乏事实标签而容易出现幻觉，导致不准确的输出。通过引入3D范式和FECT数据集，可以更准确地评估LLM生成内容的真实性。

Conclusion: 该研究提出了一种新的方法来自动评估用于分析联络中心对话的AI系统输出的事实准确性。

Abstract: Large language models (LLMs) are known to hallucinate, producing natural
language outputs that are not grounded in the input, reference materials, or
real-world knowledge. In enterprise applications where AI features support
business decisions, such hallucinations can be particularly detrimental. LLMs
that analyze and summarize contact center conversations introduce a unique set
of challenges for factuality evaluation, because ground-truth labels often do
not exist for analytical interpretations about sentiments captured in the
conversation and root causes of the business problems. To remedy this, we first
introduce a \textbf{3D} -- \textbf{Decompose, Decouple, Detach} -- paradigm in
the human annotation guideline and the LLM-judges' prompt to ground the
factuality labels in linguistically-informed evaluation criteria. We then
introduce \textbf{FECT}, a novel benchmark dataset for \textbf{F}actuality
\textbf{E}valuation of Interpretive AI-Generated \textbf{C}laims in Contact
Center Conversation \textbf{T}ranscripts, labeled under our 3D paradigm.
Lastly, we report our findings from aligning LLM-judges on the 3D paradigm.
Overall, our findings contribute a new approach for automatically evaluating
the factuality of outputs generated by an AI system for analyzing contact
center conversations.

</details>


### [231] [XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML](https://arxiv.org/abs/2508.00924)
*Ernesto L. Estevanell-Valladares,Suilan Estevez-Velarde,Yoan Gutiérrez,Andrés Montoyo,Ruslan Mitkov*

Main category: cs.CL

TL;DR: XAutoLM 是一个创新的 AutoML 框架，通过元学习优化语言模型微调，实现了更高的效率和更低的资源消耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决语言模型微调中重复试验带来的高昂计算开销和环境影响问题，同时自动化模型选择和超参数优化任务，我们提出了 XAutoLM。

Method: XAutoLM 是一个增强了元学习的 AutoML 框架，通过提取任务和系统级别的元特征，利用存储的成功和失败经验来指导模型选择和超参数优化，从而提高语言模型微调的效率。

Result: XAutoLM 在六项任务中的五项上超越了零样本优化器的峰值 F1 分数，平均评估时间缩短了 4.5 倍，错误率降低了七倍，并发现了高出零样本帕累托前沿 50% 的管道。

Conclusion: XAutoLM 框架通过重用过去经验，能够高效地优化判别性和生成性语言模型的微调流程，并在多个文本分类和问答基准测试中表现优于现有方法，显著提高了效率并降低了成本。

Abstract: Experts in machine learning leverage domain knowledge to navigate decisions
in model selection, hyperparameter optimisation, and resource allocation. This
is particularly critical for fine-tuning language models (LMs), where repeated
trials incur substantial computational overhead and environmental impact.
However, no existing automated framework simultaneously tackles the entire
model selection and HPO task for resource-efficient LM fine-tuning. We
introduce XAutoLM, a meta-learning-augmented AutoML framework that reuses past
experiences to optimise discriminative and generative LM fine-tuning pipelines
efficiently. XAutoLM learns from stored successes and failures by extracting
task- and system-level meta-features to bias its sampling toward fruitful
configurations and away from costly dead ends. On four text classification and
two question-answering benchmarks, XAutoLM surpasses zero-shot optimiser's peak
F1 on five of six tasks, cuts mean evaluation time by up to 4.5x, reduces error
ratios by up to sevenfold, and uncovers up to 50% more pipelines above the
zero-shot Pareto front. In contrast, simpler memory-based baselines suffer
negative transfer. We release XAutoLM and our experience store to catalyse
resource-efficient, Green AI fine-tuning in the NLP community.

</details>


### [232] [MAO-ARAG: Multi-Agent Orchestration for Adaptive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.01005)
*Yiqun Chen,Erhan Zhang,Lingyong Yan,Shuaiqiang Wang,Jizhou Huang,Dawei Yin,Jiaxin Mao*

Main category: cs.CL

TL;DR: MAO-ARAG是一个自适应RAG框架，通过多智能体协调，根据不同查询动态生成工作流，以平衡答案质量、成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界查询的复杂性各不相同，固定的RAG流程难以在不同查询之间平衡性能和成本效益。

Method: 提出了一种名为MAO-ARAG的自适应检索增强生成（RAG）框架，该框架利用多智能体协调。它定义了查询重构、文档选择和生成等执行智能体，并由一个规划智能体根据查询动态选择和集成执行智能体，形成工作流。规划智能体通过强化学习进行训练，根据F1分数和成本进行奖励和惩罚。

Result: 实验表明，MAO-ARAG 这种为每个查询动态规划工作流的方法，不仅实现了高答案质量，而且将成本和延迟保持在可接受的范围内。

Conclusion: MAO-ARAG 通过动态规划工作流，在实现高答案质量的同时，将成本和延迟保持在可接受的范围内。

Abstract: In question-answering (QA) systems, Retrieval-Augmented Generation (RAG) has
become pivotal in enhancing response accuracy and reducing hallucination
issues. The architecture of RAG systems varies significantly, encompassing
single-round RAG, iterative RAG, and reasoning RAG, each tailored to address
different types of queries. Due to the varying complexity of real-world
queries, a fixed RAG pipeline often struggles to balance performance and cost
efficiency across different queries. To address this challenge, we propose an
adaptive RAG framework called MAO-ARAG, which leverages multi-agent
orchestration. Our adaptive RAG is conceived as a multi-turn framework.
Specifically, we define multiple executor agents, representing typical RAG
modules such as query reformulation agents, document selection agent, and
generation agents. A planner agent intelligently selects and integrates the
appropriate agents from these executors into a suitable workflow tailored for
each query, striving for high-quality answers while maintaining reasonable
costs. During each turn, the planner agent is trained using reinforcement
learning, guided by an outcome-based reward (F1 score) and a cost-based
penalty, continuously improving answer quality while keeping costs within a
reasonable range. Experiments conducted on multiple QA datasets demonstrate
that our approach, which dynamically plans workflows for each query, not only
achieves high answer quality but also maintains both cost and latency within
acceptable limits.The code of MAO-ARAG is on
https://github.com/chenyiqun/Agentic-RAG.

</details>


### [233] [UrBLiMP: A Benchmark for Evaluating the Linguistic Competence of Large Language Models in Urdu](https://arxiv.org/abs/2508.01006)
*Farah Adeeba,Brian Dillon,Hassan Sajjad,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 我们创建了一个名为UrBLiMP的乌尔都语数据集，用于评估大型语言模型（LLM）的句法能力。结果显示，尽管LLaMA-3-70B表现最佳，但许多模型在处理低资源语言时仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 评估多语言LLM在乌尔都语等低资源语言方面的语言学知识，因为它们在这些语言上的数据量通常远少于英语等高资源语言。

Method: 构建了一个包含5,696个最小对的乌尔都语语言学最小对基准（UrBLiMP），涵盖了十个核心句法现象，并通过人类评估确认了其可靠性（96.10%的注释者间一致性）。评估了20个多语言LLM在UrBLiMP上的表现。

Result: 在UrBLiMP基准测试中，LLaMA-3-70B的平均准确率最高（94.73%），但其表现与Gemma-3-27B-PT等模型在统计上相当，且不同模型在不同语言现象上的表现存在显著差异。

Conclusion: LLaMA-3-70B表现最好，但与其他顶级模型（如Gemma-3-27B-PT）在统计上相当，表明当前多语言LLM在低资源语言的句法知识捕获方面存在潜力和局限性。

Abstract: Multilingual Large Language Models (LLMs) have shown remarkable performance
across various languages; however, they often include significantly less data
for low-resource languages such as Urdu compared to high-resource languages
like English. To assess the linguistic knowledge of LLMs in Urdu, we present
the Urdu Benchmark of Linguistic Minimal Pairs (UrBLiMP) i.e. pairs of
minimally different sentences that contrast in grammatical acceptability.
UrBLiMP comprises 5,696 minimal pairs targeting ten core syntactic phenomena,
carefully curated using the Urdu Treebank and diverse Urdu text corpora. A
human evaluation of UrBLiMP annotations yielded a 96.10% inter-annotator
agreement, confirming the reliability of the dataset. We evaluate twenty
multilingual LLMs on UrBLiMP, revealing significant variation in performance
across linguistic phenomena. While LLaMA-3-70B achieves the highest average
accuracy (94.73%), its performance is statistically comparable to other top
models such as Gemma-3-27B-PT. These findings highlight both the potential and
the limitations of current multilingual LLMs in capturing fine-grained
syntactic knowledge in low-resource languages.

</details>


### [234] [Cross-Domain Web Information Extraction at Pinterest](https://arxiv.org/abs/2508.01096)
*Michael Farag,Patrick Halina,Andrey Zaytsev,Alekhya Munagala,Imtihan Ahmed,Junhao Wang*

Main category: cs.CL

TL;DR: Pinterest developed a cost-effective and scalable system for extracting product data from websites using a novel representation that combines visual, text, and structural information, enabling simple models like XGBoost to outperform complex LLMs like GPT.


<details>
  <summary>Details</summary>
Motivation: To accurately extract structured product data from e-commerce websites to enhance user experiences and improve content distribution on Pinterest.

Method: Leveraging a novel webpage representation that combines structural, visual, and text modalities into a compact form, optimized for small model learning. This representation captures each visible HTML node with its text, style, and layout information. Simple models like XGBoost are used for attribute extraction.

Result: The system demonstrates remarkable accuracy and scalability, processing over 1,000 URLs per second. Simple models like XGBoost extract attributes more accurately than complex LLMs like GPT, achieving this at 1000 times lower cost than GPT alternatives.

Conclusion: Pinterest’s attribute extraction system, utilizing a novel multimodal webpage representation, achieves high accuracy and scalability cost-effectively, outperforming complex LLMs with simpler models like XGBoost.

Abstract: The internet offers a massive repository of unstructured information, but
it's a significant challenge to convert this into a structured format. At
Pinterest, the ability to accurately extract structured product data from
e-commerce websites is essential to enhance user experiences and improve
content distribution. In this paper, we present Pinterest's system for
attribute extraction, which achieves remarkable accuracy and scalability at a
manageable cost. Our approach leverages a novel webpage representation that
combines structural, visual, and text modalities into a compact form,
optimizing it for small model learning. This representation captures each
visible HTML node with its text, style and layout information. We show how this
allows simple models such as eXtreme Gradient Boosting (XGBoost) to extract
attributes more accurately than much more complex Large Language Models (LLMs)
such as Generative Pre-trained Transformer (GPT). Our results demonstrate a
system that is highly scalable, processing over 1,000 URLs per second, while
being 1000 times more cost-effective than the cheapest GPT alternatives.

</details>


### [235] [Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates](https://arxiv.org/abs/2508.01159)
*Liam G. McCoy,Fateme Nateghi Haredasht,Kanav Chopra,David Wu,David JH Wu,Abass Conteh,Sarita Khemani,Saloni Kumar Maharaj,Vishnu Ravi,Arth Pahwa,Yingjie Weng,Leah Rosengaus,Lena Giang,Kelvin Zhenghao Li,Olivia Jee,Daniel Shirvani,Ethan Goh,Jonathan H. Chen*

Main category: cs.CL

TL;DR: LLMs可以生成临床模板，但在长度和关键信息排序方面仍需改进，不同专科表现不一。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）生成电子咨询结构化临床咨询模板的能力，旨在改善医生间的结构化临床信息交换。

Method: 使用斯坦福大学eConsult团队开发的145个模板，评估了包括o3、GPT-4o、Kimi K2、Claude 4 Sonnet、Llama 3 70B和Gemini 2.5 Pro在内的多个前沿LLM。通过多智能体管道（包括提示优化、语义自动评分和优先级分析）进行评估。

Result: 虽然o3等模型在全面性方面表现出色（高达92.2%），但它们生成的模板过长，并且在长度限制下未能正确排序最重要的临床问题。模型在不同专科的表现存在差异，在心理学和疼痛医学等叙事性强的领域表现明显下降。

Conclusion: LLMs在生成电子咨询临床模板方面有潜力，但仍需改进以满足实际的临床需求，尤其是在信息优先级排序和长度控制方面。

Abstract: This study evaluates the capacity of large language models (LLMs) to generate
structured clinical consultation templates for electronic consultation. Using
145 expert-crafted templates developed and routinely used by Stanford's
eConsult team, we assess frontier models -- including o3, GPT-4o, Kimi K2,
Claude 4 Sonnet, Llama 3 70B, and Gemini 2.5 Pro -- for their ability to
produce clinically coherent, concise, and prioritized clinical question
schemas. Through a multi-agent pipeline combining prompt optimization, semantic
autograding, and prioritization analysis, we show that while models like o3
achieve high comprehensiveness (up to 92.2\%), they consistently generate
excessively long templates and fail to correctly prioritize the most clinically
important questions under length constraints. Performance varies across
specialties, with significant degradation in narrative-driven fields such as
psychiatry and pain medicine. Our findings demonstrate that LLMs can enhance
structured clinical information exchange between physicians, while highlighting
the need for more robust evaluation methods that capture a model's ability to
prioritize clinically salient information within the time constraints of
real-world physician communication.

</details>


### [236] [CSIRO-LT at SemEval-2025 Task 11: Adapting LLMs for Emotion Recognition for Multiple Languages](https://arxiv.org/abs/2508.01161)
*Jiyu Chen,Necva Bölücü,Sarvnaz Karimi,Diego Mollá,Cécile L. Paris*

Main category: cs.CL

TL;DR: This paper explores cross-lingual emotion recognition using LLMs. The best approach found is to fine-tune multilingual LLMs separately for each language using LoRA.


<details>
  <summary>Details</summary>
Motivation: Detecting emotions across different languages is challenging due to the varied and culturally nuanced ways of emotional expressions. The Semeval 2025 Task 11: Bridging the Gap in Text-Based emotion shared task was organised to investigate emotion recognition across different languages.

Method: Fine-tuning a pre-trained multilingual LLM with LoRA setting separately for each language.

Result: The investigation showed that fine-tuning a pre-trained multilingual LLM with LoRA setting separately for each language is the most effective method for this task.

Conclusion: The most effective method for cross-lingual emotion recognition is to fine-tune a pre-trained multilingual LLM with LoRA setting separately for each language.

Abstract: Detecting emotions across different languages is challenging due to the
varied and culturally nuanced ways of emotional expressions. The
\textit{Semeval 2025 Task 11: Bridging the Gap in Text-Based emotion} shared
task was organised to investigate emotion recognition across different
languages. The goal of the task is to implement an emotion recogniser that can
identify the basic emotional states that general third-party observers would
attribute to an author based on their written text snippet, along with the
intensity of those emotions. We report our investigation of various
task-adaptation strategies for LLMs in emotion recognition. We show that the
most effective method for this task is to fine-tune a pre-trained multilingual
LLM with LoRA setting separately for each language.

</details>


### [237] [Adaptive Content Restriction for Large Language Models via Suffix Optimization](https://arxiv.org/abs/2508.01198)
*Yige Li,Peihai Jiang,Jun Sun,Peng Shu,Tianming Liu,Zhen Xiang*

Main category: cs.CL

TL;DR: 提出 AdaCoRe 和 SOP 方法，通过优化后缀轻量级地限制 LLM 生成特定内容，并在 CoReBench 基准上验证了 SOP 的有效性，优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的模型对齐方法（如 SFT）在限制 LLM 生成有害内容方面存在挑战，因为其计算、数据和存储需求高，并且无法满足不同用户群体、快速变化的需求以及与通用有害定义的不一致性。因此，需要一种轻量级的方法来实现自适应内容限制。

Method: 提出了一种名为"后缀优化(SOP)"的新方法，该方法通过向提示词附加一个简短的优化后缀来实现内容限制，旨在阻止 LLM 生成受限词汇，同时保持输出质量。此外，还创建了一个名为"内容限制基准(CoReBench)"的新数据集，包含 400 个提示词和 80 个受限词汇，涵盖 8 个类别，用于评估 AdaCoRe 方法。

Result: SOP 在 CoReBench 基准测试中表现出色，在 Gemma2-2B、Mistral-7B、Vicuna-7B、Llama3-8B 和 Llama3.1-8B 模型上，平均限制率分别比系统级基线（如系统后缀）高出 15%、17%、10%、9% 和 6%。SOP 还在 POE 等在线平台上的商业 LLM 中显示出有效性，证明了其在实际场景中的应用潜力。

Conclusion: SOP 是一种有效的自适应内容限制方法，可在不进行模型微调的情况下，有效阻止 LLM 生成受限内容，并保持输出质量。CoReBench 是评估此类方法的一个新基准。

Abstract: Large Language Models (LLMs) have demonstrated significant success across
diverse applications. However, enforcing content restrictions remains a
significant challenge due to their expansive output space. One aspect of
content restriction is preventing LLMs from generating harmful content via
model alignment approaches such as supervised fine-tuning (SFT). Yet, the need
for content restriction may vary significantly across user groups, change
rapidly over time, and not always align with general definitions of
harmfulness. Applying SFT to each of these specific use cases is impractical
due to the high computational, data, and storage demands. Motivated by this
need, we propose a new task called \textit{Adaptive Content Restriction}
(AdaCoRe), which focuses on lightweight strategies -- methods without model
fine-tuning -- to prevent deployed LLMs from generating restricted terms for
specific use cases. We propose the first method for AdaCoRe, named
\textit{Suffix Optimization (SOP)}, which appends a short, optimized suffix to
any prompt to a) prevent a target LLM from generating a set of restricted
terms, while b) preserving the output quality. To evaluate AdaCoRe approaches,
including our SOP, we create a new \textit{Content Restriction Benchmark}
(CoReBench), which contains 400 prompts for 80 restricted terms across 8
carefully selected categories. We demonstrate the effectiveness of SOP on
CoReBench, which outperforms the system-level baselines such as system suffix
by 15\%, 17\%, 10\%, 9\%, and 6\% on average restriction rates for Gemma2-2B,
Mistral-7B, Vicuna-7B, Llama3-8B, and Llama3.1-8B, respectively. We also
demonstrate that SOP is effective on POE, an online platform hosting various
commercial LLMs, highlighting its practicality in real-world scenarios.

</details>


### [238] [Show or Tell? Modeling the evolution of request-making in Human-LLM conversations](https://arxiv.org/abs/2508.01213)
*Shengqi Zhu,Jeffrey M. Rzeszotarski,David Mimno*

Main category: cs.CL

TL;DR: 本研究提出一个新任务来分析LLM用户聊天记录，发现用户查询模式会随时间演变并受模型能力影响。


<details>
  <summary>Details</summary>
Motivation: 聊天记录蕴含着丰富的用户行为信息，但查询的多样性掩盖了这些模式。

Method: 提出一个新任务：将聊天查询分割成请求内容、角色、查询特定上下文和附加表达。

Result: 用户请求方式与人际交互不同；用户查询模式随时间演变，早期用户侧重请求，个体探索后趋于收敛；模型能力影响用户行为，新模型发布后尤为明显。

Conclusion: 用户查询模式会随着使用时间的增加而变化，并且会受到模型能力的影响。新模型的使用会引起用户行为的改变，这种改变可以在社区层面被追踪。

Abstract: Chat logs provide a rich source of information about LLM users, but patterns
of user behavior are often masked by the variability of queries. We present a
new task, segmenting chat queries into contents of requests, roles,
query-specific context, and additional expressions. We find that, despite the
familiarity of chat-based interaction, request-making in LLM queries remains
significantly different from comparable human-human interactions. With the data
resource, we introduce an important perspective of diachronic analyses with
user expressions. We find that query patterns vary between early ones
emphasizing requests, and individual users explore patterns but tend to
converge with experience. Finally, we show that model capabilities affect user
behavior, particularly with the introduction of new models, which are traceable
at the community level.

</details>


### [239] [WebDS: An End-to-End Benchmark for Web-based Data Science](https://arxiv.org/abs/2508.01222)
*Ethan Hsu,Hong Meng Yam,Ines Bouissou,Aaron Murali John,Raj Thota,Josh Koe,Vivek Sarath Putta,G K Dharesan,Alexander Spangher,Shikhar Murty,Tenghao Huang,Christopher D. Manning*

Main category: cs.CL

TL;DR: A new benchmark, WebDS, tests LLM agents on realistic web data science tasks, finding current agents struggle due to issues like poor grounding and repetitive behavior, paving the way for better AI data analysts.


<details>
  <summary>Details</summary>
Motivation: Existing web benchmarks are often too simplistic and do not require diverse tool-using capabilities for web-based data science. Traditional data science benchmarks focus on static datasets and do not assess end-to-end workflows including data acquisition, cleaning, analysis, and insight generation. Therefore, there is a need for a benchmark that reflects the complexities of real-world data science tasks involving multi-hop web interactions and diverse data modalities.

Method: The study introduces WebDS, a benchmark comprising 870 web-based data science tasks across 29 diverse websites. These tasks involve complex, multi-step operations requiring tool usage and handling of heterogeneous data formats, simulating real-world data analytics workflows.

Result: Current SOTA LLM agents demonstrate significant performance gaps on WebDS. For example, Browser Use, which performs well on other benchmarks, only completes 15% of tasks in WebDS, compared to 80% on Web Voyager. This highlights new failure modes in LLM agents when dealing with complex web-based data science tasks.

Conclusion: WebDS is a novel benchmark designed to evaluate LLM agents in real-world, complex, multi-step web-based data science tasks, addressing the limitations of existing benchmarks. Evaluations show current SOTA LLM agents have significant performance gaps, revealing new failure modes such as poor information grounding, repetitive behavior, and shortcut-taking. WebDS aims to drive progress in developing practically useful LLM-based data science.

Abstract: A large portion of real-world data science tasks are complex and require
multi-hop web-based interactions: finding appropriate data available on the
internet, synthesizing real-time data of various modalities from different
locations, and producing summarized analyses. Existing web benchmarks often
focus on simplistic interactions, such as form submissions or e-commerce
transactions, and often do not require diverse tool-using capabilities required
for web based data science. Conversely, traditional data science benchmarks
typically concentrate on static, often textually bound datasets and do not
assess end-to-end workflows that encompass data acquisition, cleaning,
analysis, and insight generation. In response, we introduce WebDS, the first
end-to-end web-based data science benchmark. It comprises 870 web-based data
science tasks across 29 diverse websites from structured government data
portals to unstructured news media, challenging agents to perform complex,
multi-step operations requiring the use of tools and heterogeneous data formats
that better reflect the realities of modern data analytics. Evaluations of
current SOTA LLM agents indicate significant performance gaps in accomplishing
these tasks. For instance, Browser Use, which accomplishes 80% of tasks on Web
Voyager, successfully completes only 15% of tasks in WebDS, which our analysis
suggests is due to new failure modes like poor information grounding,
repetitive behavior and shortcut-taking that agents performing WebDS' tasks
display. By providing a more robust and realistic testing ground, WebDS sets
the stage for significant advances in the development of practically useful
LLM-based data science.

</details>


### [240] [WarriorMath: Enhancing the Mathematical Ability of Large Language Models with a Defect-aware Framework](https://arxiv.org/abs/2508.01245)
*Yue Chen,Minghua He,Fangkai Yang,Pu Zhao,Lu Wang,Yu Kang,Yifei Dong,Yuefeng Zhan,Hao Sun,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.CL

TL;DR: WarriorMath是一个缺陷感知的数学问题解决框架，通过多专家协作合成高质量数据并结合渐进式训练，显著提升了LLM的数学能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在数学问题解决方面表现优异，但受限于高质量、多样化训练数据的可用性。现有方法侧重于改写或难度递进的数据增强，忽略了LLM特定的失败模式，导致生成的合成问题对模型提升有限。为了解决这个问题，需要一个能解决LLM数学能力提升瓶颈的框架。

Method: WarriorMath框架整合了目标数据合成和渐进式训练。在合成阶段，利用多个专家LLM协作生成、审视和优化问题，通过专家反馈针对性地改进基础LLM无法解决的问题，从而创建高质量、缺陷感知的训练数据。在训练阶段，采用渐进式学习框架，利用针对模型弱点的、难度递增的数据进行迭代微调。

Result: 在六个数学基准测试上的实验表明，WarriorMath的平均性能比强基线高出12.57%，设定了新的最先进记录。

Conclusion: WarriorMath通过缺陷感知、多专家协作以及渐进式训练，在数学问题解决方面取得了显著的进步，平均性能提升了12.57%，达到了新的先进水平。

Abstract: Large Language Models (LLMs) excel in solving mathematical problems, yet
their performance is often limited by the availability of high-quality, diverse
training data. Existing methods focus on augmenting datasets through rephrasing
or difficulty progression but overlook the specific failure modes of LLMs. This
results in synthetic questions that the model can already solve, providing
minimal performance gains. To address this, we propose WarriorMath, a
defect-aware framework for mathematical problem solving that integrates both
targeted data synthesis and progressive training. In the synthesis stage, we
employ multiple expert LLMs in a collaborative process to generate, critique,
and refine problems. Questions that base LLMs fail to solve are identified and
iteratively improved through expert-level feedback, producing high-quality,
defect-aware training data. In the training stage, we introduce a progressive
learning framework that iteratively fine-tunes the model using increasingly
challenging data tailored to its weaknesses. Experiments on six mathematical
benchmarks show that WarriorMath outperforms strong baselines by 12.57% on
average, setting a new state-of-the-art. Our results demonstrate the
effectiveness of a defect-aware, multi-expert framework for improving
mathematical ability.

</details>


### [241] [Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025](https://arxiv.org/abs/2508.01263)
*Long S. T. Nguyen,Khang H. N. Vo,Thu H. A. Nguyen,Tuan C. Bui,Duc Q. Nguyen,Thanh-Tung Tran,Anh D. Nguyen,Minh L. Nguyen,Fabien Baldacci,Thang H. Bui,Emanuel Di Nardo,Angelo Ciaramella,Son H. Le,Ihsan Ullah,Lorenzo Di Rocco,Tho T. Quan*

Main category: cs.CL

TL;DR: 该论文介绍了XAI挑战赛2025，这是一个旨在教育领域开发可解释人工智能（XAI）的黑客马拉松活动，重点是问答系统和基于逻辑的解释，并强调了其在大语言模型和符号推理结合方面的新颖性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在教育领域的整合日益加深，对透明度和可解释性的需求也日益增长。然而，很少有类似黑客马拉松的活动直接解决真实教育环境中的可解释人工智能（XAI）问题。

Method: 通过对XAI挑战赛2025进行全面分析，包括其动机、结构、数据集构建和评估协议。

Result: 成功组织了一场以构建能够回答有关大学政策的学生查询并生成清晰、基于逻辑的自然语言解释的问答（QA）系统为目标的比赛，并提供了一个高质量的数据集。

Conclusion: 该论文认为XAI挑战赛2025代表了将大语言模型和符号推理相结合以实现可解释性的新颖尝试，并为未来的XAI教育系统和竞争性研究计划提供了可行的见解。

Abstract: The growing integration of Artificial Intelligence (AI) into education has
intensified the need for transparency and interpretability. While hackathons
have long served as agile environments for rapid AI prototyping, few have
directly addressed eXplainable AI (XAI) in real-world educational contexts.
This paper presents a comprehensive analysis of the XAI Challenge 2025, a
hackathon-style competition jointly organized by Ho Chi Minh City University of
Technology (HCMUT) and the International Workshop on Trustworthiness and
Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International
Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked
participants with building Question-Answering (QA) systems capable of answering
student queries about university policies while generating clear, logic-based
natural language explanations. To promote transparency and trustworthiness,
solutions were required to use lightweight Large Language Models (LLMs) or
hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed
via logic-based templates with Z3 validation and refined through expert student
review to ensure alignment with real-world academic scenarios. We describe the
challenge's motivation, structure, dataset construction, and evaluation
protocol. Situating the competition within the broader evolution of AI
hackathons, we argue that it represents a novel effort to bridge LLMs and
symbolic reasoning in service of explainability. Our findings offer actionable
insights for future XAI-centered educational systems and competitive research
initiatives.

</details>


### [242] [Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities](https://arxiv.org/abs/2508.01290)
*Zhichao Yan,Jiapu Wang,Jiaoyan Chen,Yanyan Wang,Hongye Tan,Jiye Liang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: RAG systems can leverage partially relevant knowledge to improve LLM performance, even when knowledge bases are incomplete. An "awakening-based" approach shows better results than traditional methods.


<details>
  <summary>Details</summary>
Motivation: Investigate the phenomenon that LLMs can be awakened via partially relevant knowledge, especially in incomplete knowledge base retrieval, challenging the conventional view.

Method: Constructed partially relevant knowledge by removing the answer-containing path from triplets in the gold reasoning path and their variants. Provided theoretical analysis of the awakening effect and conducted experiments on two KGQA datasets.

Result: The awakening-based approach demonstrates greater efficacy and outperforms traditional methods that rely on embedding-based similarity.

Conclusion: LLMs can be awakened via partially relevant knowledge, and this awakening-based approach outperforms traditional methods in practical applications, especially in Unseen Entity KGQA.

Abstract: Retrieval-Augmented Generation (RAG) shows impressive performance by
supplementing and substituting parametric knowledge in Large Language Models
(LLMs). Retrieved knowledge can be divided into three types: explicit answer
evidence, implicit answer clue, and insufficient answer context which can be
further categorized into totally irrelevant and partially relevant information.
Effectively utilizing partially relevant knowledge remains a key challenge for
RAG systems, especially in incomplete knowledge base retrieval. Contrary to the
conventional view, we propose a new perspective: LLMs can be awakened via
partially relevant knowledge already embedded in LLMs. To comprehensively
investigate this phenomenon, the triplets located in the gold reasoning path
and their variants are used to construct partially relevant knowledge by
removing the path that contains the answer. We provide theoretical analysis of
the awakening effect in LLMs and support our hypothesis with experiments on two
Knowledge Graphs (KGs) Question Answering (QA) datasets. Furthermore, we
present a new task, Unseen Entity KGQA, simulating real-world challenges where
entity linking fails due to KG incompleteness. Our awakening-based approach
demonstrates greater efficacy in practical applications, outperforms
traditional methods that rely on embedding-based similarity which are prone to
returning noisy information.

</details>


### [243] [EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based Sentiment Analysis in Healthcare](https://arxiv.org/abs/2508.02574)
*Eman Alamoudi,Ellis Solaiman*

Main category: cs.CL

TL;DR: 通过结合ChatGPT和人工审查，构建了首个阿拉伯语医疗保健方面级情感分析数据集，实现了高准确率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语患者反馈因方言多样性和稀缺的方面级情感标签而难以进行自动化评估的问题。

Method: 提出了一种数据为中心、结合ChatGPT伪标签和人工审查的混合流水线，构建了首个针对医疗保健领域、可解释的阿拉伯语方面级情感分析数据集。对句子进行方面和情感标签（正、负或中性）的标注，并为每个标签提供ChatGPT生成的解释以增强透明度。创建了三个训练数据集版本（全监督、半监督和无监督）以评估标注质量对模型性能的影响，并微调了两个Transformer模型进行方面和情感分类。

Result: 结果表明，阿拉伯语特定模型即使在只有少量人工监督的情况下也达到了高准确率，仅在仅使用ChatGPT标签时性能略有下降。减少方面类别显著提高了分类指标。这表明该混合方法在阿拉伯语医疗保健方面级情感分析中是有效且可扩展的。

Conclusion: 该研究展示了一种有效且可扩展的方法，用于医疗保健领域中的阿拉伯语方面级情感分析。通过结合大型语言模型标注和人工专业知识，创建了一个强大且可解释的数据集。

Abstract: Arabic-language patient feedback remains under-analysed because dialect
diversity and scarce aspect-level sentiment labels hinder automated assessment.
To address this gap, we introduce EHSAN, a data-centric hybrid pipeline that
merges ChatGPT pseudo-labelling with targeted human review to build the first
explainable Arabic aspect-based sentiment dataset for healthcare. Each sentence
is annotated with an aspect and sentiment label (positive, negative, or
neutral), forming a pioneering Arabic dataset aligned with healthcare themes,
with ChatGPT-generated rationales provided for each label to enhance
transparency. To evaluate the impact of annotation quality on model
performance, we created three versions of the training data: a fully supervised
set with all labels reviewed by humans, a semi-supervised set with 50% human
review, and an unsupervised set with only machine-generated labels. We
fine-tuned two transformer models on these datasets for both aspect and
sentiment classification. Experimental results show that our Arabic-specific
model achieved high accuracy even with minimal human supervision, reflecting
only a minor performance drop when using ChatGPT-only labels. Reducing the
number of aspect classes notably improved classification metrics across the
board. These findings demonstrate an effective, scalable approach to Arabic
aspect-based sentiment analysis (SA) in healthcare, combining large language
model annotation with human expertise to produce a robust and explainable
dataset. Future directions include generalisation across hospitals, prompt
refinement, and interpretable data-driven modelling.

</details>


### [244] [KEDAS: Knowledge Editing Alignment with Diverse Augmentation and Self-adaptive Inference](https://arxiv.org/abs/2508.01302)
*Chenming Tang,Yutong Yang,Yunfang Wu*

Main category: cs.CL

TL;DR: KEDAS improves LLM knowledge editing using low-rank adaptation, diverse augmentation, and smart inference routing, achieving top performance across various settings and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To efficiently modify outdated knowledge in large language models (LLMs) while preserving their capabilities, addressing limitations of existing parameter-level or retrieval-based methods.

Method: KEDAS utilizes low-rank adaptation for in-context knowledge application during alignment, a diverse edit augmentation technique to enhance edit recall, and a self-adaptive post-alignment inference mechanism with a filter-based smart retriever for dynamic inference routing.

Result: KEDAS achieves the highest overall performance in 35 out of 36 scenarios across four datasets and three LLMs, outperforming its alignment counterpart by approximately 19.8 harmonic mean scores (edit success, locality, portability) and significantly surpassing parameter editing and retrieval-based baselines.

Conclusion: KEDAS presents an ideal paradigm of knowledge editing alignment, demonstrating robustness and efficiency through its analysis of computational cost and performance on general tasks.

Abstract: Knowledge editing aims to modify outdated knowledge in large language models
(LLMs) efficiently while retaining their powerful capabilities. Most existing
methods rely on either parameter-level editing or retrieval-based approaches.
In this work, we propose Knowledge Editing alignment with Diverse Augmentation
and Self-adaptive inference (KEDAS) to better align LLMs with knowledge
editing. In the alignment phase, LLMs learn to apply in-context edited
knowledge via low-rank adaptation. During editing, we design a diverse edit
augmentation technique to improve the recall of edits. After that, a
self-adaptive post-alignment inference mechanism is proposed, in which a
filter-based smart retriever is employed to perform a dynamic selection of
inference routing. Specifically, irrelevant queries will go through the
original pre-alignment model directly, while relevant ones, together with their
related edits, go through the model with aligned adapters activated. In
experiments, KEDAS secures the highest overall performance scores in 35 out of
36 cases across four datasets with three LLMs on three settings, surpassing its
strong knowledge editing alignment counterpart by about 19.8 harmonic mean
scores of edit success, locality and portability and outperforming both
parameter editing and retrieval-based baselines significantly. Analysis of
computational cost and performance on general tasks further validates the
robustness and efficiency of KEDAS, indicating that it presents an ideal
paradigm of knowledge editing alignment.

</details>


### [245] [D-SCoRE: Document-Centric Segmentation and CoT Reasoning with Structured Export for QA-CoT Data Generation](https://arxiv.org/abs/2508.01309)
*Weibo Zhou,Lingbo Li,Shangsong Liang*

Main category: cs.CL

TL;DR: D-SCoRE is a training-free pipeline that uses LLMs and prompt engineering to create diverse, high-quality QA datasets from any text. It's efficient, scalable, and improves LLM fine-tuning performance, especially for domain-specific tasks, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The scarcity and high cost of high-quality question-answering (QA) datasets hinder supervised fine-tuning (SFT) for domain-specific large language models (LLMs).

Method: D-SCoRE pipeline integrates document-centric processing, segmentation, CoT reasoning, and structured export to generate QA-CoT datasets. It employs multi-dimensional control mechanisms like semantic role transformation, question type balancing, and counterfactual materials to enhance data diversity and relevance.

Result: LLMs fine-tuned on D-SCoRE-generated QA datasets outperform those fine-tuned on human-annotated datasets on SQuADShifts and Covid-QA test sets across most domains. D-SCoRE generates six QA-CoT pairs with counterfactual materials per 100-200-word text in 90 seconds using an 8B LLM on consumer-grade hardware.

Conclusion: D-SCoRE pipeline can efficiently generate diverse, high-quality QA-CoT datasets from arbitrary textual sources, enabling high-performance fine-tuning across domains. It outperforms existing methods on domain-aware SFT tasks.

Abstract: The scarcity and high cost of high-quality question-answering (QA) datasets
hinder supervised fine-tuning (SFT) for domain-specific large language models
(LLMs). To address this, we introduce D-SCoRE, a training-free pipeline that
utilizes LLMs and prompt engineering to produce diverse, high-quality QA
datasets from arbitrary textual sources. D-SCoRE integrates
$\textbf{D}$ocument-centric processing, $\textbf{S}$egmentation, $\textbf{Co}$T
$\textbf{R}$easoning, and structured $\textbf{E}$xport to generate QA-COT
datasets tailored for domain-aware SFT. Multi-dimensional control mechanisms,
such as semantic role transformation, question type balancing, and
counterfactual materials, enhance diversity and relevance, overcoming
limitations of existing QA generation. LLMs fine-tuned on D-SCoRE-generated QA
datasets, and human-annotated QA datasets (SQuAD, Covid-QA) are evaluated on
SQuADShifts and Covid-QA test sets, with D-SCoRE outperforming across most
domains. D-SCoRE generates six QA-CoT pairs with four-option counterfactual
materials per 100-200-word text in 90 seconds using an 8B LLM on consumer-grade
hardware. Its simplicity and scalability enable efficient QA generation and
high-performance fine-tuning across domains.

</details>


### [246] [LinkQA: Synthesizing Diverse QA from Multiple Seeds Strongly Linked by Knowledge Points](https://arxiv.org/abs/2508.01317)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: LinkSyn synthesizes diverse QA data using knowledge point graphs to improve LLM training, achieving SOTA results.


<details>
  <summary>Details</summary>
Motivation: Addressing the scarcity of high-quality, diverse training data for LLMs.

Method: LinkSyn framework, utilizing KP graphs for data synthesis, incorporating a knowledge distribution value function, diffusion-based synthesis, and difficulty adjustments.

Result: Continual pre-training with LinkQA yielded an average improvement of 11.51% on MMLU and CMMLU, enhancing performance across model sizes and FLOPs scales.

Conclusion: LinkQA, a novel QA dataset, significantly improves LLM performance across various metrics and scales, establishing new SOTA results.

Abstract: The advancement of large language models (LLMs) struggles with the scarcity
of high-quality, diverse training data. To address this limitation, we propose
LinkSyn, a novel knowledge point (KP) graph-based synthesis framework that
enables flexible control over discipline and difficulty distributions while
balancing KP coverage and popularity. LinkSyn extracts KPs from
question-answering (QA) seed data and constructs a KP graph to synthesize
diverse QA data from multiple seeds strongly linked by KPs and sampled from
graph walks. Specifically, LinkSyn incorporates (1) a knowledge distribution
value function to guide the adjustment of path sampling probability and balance
KP coverage and popularity during graph walks; (2) diffusion-based synthesis
via DeepSeek-R1 by leveraging multiple seeds with dense logical associations
along each path; and (3) high-difficulty QA enhancement within given
disciplines by flexible difficulty adjustments. By executing LinkSyn, we
synthesize LinkQA, a diverse multi-disciplinary QA dataset with 50B tokens.
Extensive experiments on Llama-3 8B demonstrate that continual pre-training
with LinkQA yields an average improvement of $\mathbf{11.51\%}$ on MMLU and
CMMLU, establishing new SOTA results. LinkQA consistently enhances performance
across model size and initial FLOPs scales.

</details>


### [247] [Large-Scale Diverse Synthesis for Mid-Training](https://arxiv.org/abs/2508.01326)
*Xuemiao Zhang,Chengying Tu,Can Ren,Rongxiang Weng,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 通过一个名为BoostQA的大规模问答数据集，利用新颖的合成框架和中期训练策略，显著提升了大型语言模型在STEM和高难度任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练数据在知识密集度和多样性方面存在不足，特别是在STEM学科和高难度问答场景下，难以有效提升模型性能。

Method: 提出了一种包含数据源策划、基于DeepSeek-R1的多维度（学科、难度）数据合成、基于DeepSeek-V3的答案精炼的合成框架，并将其应用于模型的中期训练阶段。

Result: 在Llama-3 8B模型上，使用40B的BoostQA数据进行中期训练，MMLU和CMMLU的平均提升达到12.74%，并在12个基准测试中取得SOTA性能。同时，BoostQA在模型规模、数据量和初始FLOPs扩展方面表现出良好的可扩展性。

Conclusion: BoostQA数据集通过多阶段、多领域的数据合成和模型优化，显著提升了LLM在STEM学科和高难度问答任务上的表现，并在多个基准测试中达到SOTA水平。

Abstract: The scarcity of high-quality, knowledge-intensive training data hinders the
development of large language models (LLMs), as traditional corpora provide
limited information. Previous studies have synthesized and integrated
corpora-dependent question-answering (QA) data to improve model performance but
face challenges in QA data scalability and knowledge diversity, particularly in
cross-domain contexts. Furthermore, leveraging our designed discipline and
difficulty annotation system, we probe model deficiencies in STEM disciplines
and high-difficulty data. To overcome these limitations, we propose a novel
diversified pipeline to synthesize BoostQA, a 100B-token large-scale QA
dataset. Our synthesis framework: (1) curates seed data from heterogeneous
sources; (2) utilizes DeepSeek-R1 to implement STEM-focused multi-grade
synthesis to boost data diversity and high-difficulty synthesis to mitigate
difficulty degradation; (3) refines answers via DeepSeek-V3 to improve output
quality. We utilize BoostQA in mid-training, a mid-stage between pre-training
and post-training, to optimize domain-specific knowledge acquisition and
enhance data quality. Our method enables Llama-3 8B, mid-trained on a 40B-token
dataset, to achieve an average improvement of $\mathbf{12.74\%}$ on MMLU and
CMMLU and establish SOTA average performance across 12 benchmarks. BoostQA also
demonstrates robust scalability, with performance consistently improving as
model size, data volume, and initial FLOPs scale.

</details>


### [248] [MaRGen: Multi-Agent LLM Approach for Self-Directed Market Research and Analysis](https://arxiv.org/abs/2508.01370)
*Roman Koshkin,Pengyu Dai,Nozomi Fujikawa,Masahito Togami,Marco Visentini-Scarzanella*

Main category: cs.CL

TL;DR: 一个由LLM驱动的框架，能够自动生成市场报告，效率高且成本低。


<details>
  <summary>Details</summary>
Motivation: 自动化端到端的业务分析和市场报告生成，以提高效率和降低成本。

Method: 提出一个自主框架，包含研究员、审阅员、撰写员和检索员等专门的代理，并通过上下文学习模仿专业顾问的方法。框架执行一个多步骤流程，包括查询数据库、分析数据、生成见解、创建可视化和撰写市场报告。此外，还引入了一个基于LLM的评估系统来评估报告质量，并实现了迭代改进机制。

Result: 该框架能够自动生成详细的6页报告，耗时7分钟，成本约为1美元。实验结果表明，自动化审阅和顾问的非结构化知识都可以提高报告质量。

Conclusion: 该框架展示了利用大型语言模型（LLM）自动生成市场报告的潜力，实现了效率和成本效益。

Abstract: We present an autonomous framework that leverages Large Language Models
(LLMs) to automate end-to-end business analysis and market report generation.
At its core, the system employs specialized agents - Researcher, Reviewer,
Writer, and Retriever - that collaborate to analyze data and produce
comprehensive reports. These agents learn from real professional consultants'
presentation materials at Amazon through in-context learning to replicate
professional analytical methodologies. The framework executes a multi-step
process: querying databases, analyzing data, generating insights, creating
visualizations, and composing market reports. We also introduce a novel
LLM-based evaluation system for assessing report quality, which shows alignment
with expert human evaluations. Building on these evaluations, we implement an
iterative improvement mechanism that optimizes report quality through automated
review cycles. Experimental results show that report quality can be improved by
both automated review cycles and consultants' unstructured knowledge. In
experimental validation, our framework generates detailed 6-page reports in 7
minutes at a cost of approximately \$1. Our work could be an important step to
automatically create affordable market insights.

</details>


### [249] [MedSynth: Realistic, Synthetic Medical Dialogue-Note Pairs](https://arxiv.org/abs/2508.01401)
*Ahmad Rezaie Mianroodi,Amirali Rezaie,Niko Grisel Todorov,Cyril Rakovski,Frank Rudzicz*

Main category: cs.CL

TL;DR: MedSynth是一个包含10,000多个对话-笔记对的合成数据集，用于改善医学文档的自动化生成，解决了该领域数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 为了减轻医生在临床记录上花费的大量时间，解决职业倦怠问题，需要强大的自动化工具来辅助医学文档的创建。

Method: 创建了一个包含超过10,000个对话-笔记对、涵盖2000多个ICD-10代码的合成数据集MedSynth，用于医学对话到笔记（Dial-2-Note）和笔记到对话（Note-2-Dial）任务。

Result: MedSynth数据集显著提高了模型在从对话生成医学笔记以及从医学笔记生成对话方面的性能。

Conclusion: 该数据集为医学对话和笔记的生成任务提供了宝贵的资源，并显著提高了相关模型的性能。

Abstract: Physicians spend significant time documenting clinical encounters, a burden
that contributes to professional burnout. To address this, robust automation
tools for medical documentation are crucial. We introduce MedSynth -- a novel
dataset of synthetic medical dialogues and notes designed to advance the
Dialogue-to-Note (Dial-2-Note) and Note-to-Dialogue (Note-2-Dial) tasks.
Informed by an extensive analysis of disease distributions, this dataset
includes over 10,000 dialogue-note pairs covering over 2000 ICD-10 codes. We
demonstrate that our dataset markedly enhances the performance of models in
generating medical notes from dialogues, and dialogues from medical notes. The
dataset provides a valuable resource in a field where open-access,
privacy-compliant, and diverse training data are scarce. Code is available at
https://github.com/ahmadrezarm/MedSynth/tree/main and the dataset is available
at https://huggingface.co/datasets/Ahmad0067/MedSynth.

</details>


### [250] [ArzEn-MultiGenre: An aligned parallel dataset of Egyptian Arabic song lyrics, novels, and subtitles, with English translations](https://arxiv.org/abs/2508.01411)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: ArzEn-MultiGenre是一个包含埃及阿拉伯语歌曲、小说和电视节目字幕及其英文对应内容的平行数据集，包含25,557个分段对，可用于机器翻译、语言模型微调、翻译研究、跨语言分析、词汇语义学以及教学和专业翻译。


<details>
  <summary>Details</summary>
Motivation: 为机器翻译、语言模型微调、翻译研究、跨语言分析、词汇语义学以及教学和专业翻译提供资源。

Method: 人工翻译和对齐

Result: 包含25,557个分段对的平行数据集，包含现有数据集中未包含的埃及阿拉伯语文本类型，且经过人工专家翻译和对齐。

Conclusion: ArzEn-MultiGenre是一个包含埃及阿拉伯语歌曲、小说和电视节目字幕的平行数据集，已手动翻译并与英文对应内容对齐。该数据集包含25,557个分段对，可用于基准测试新的机器翻译模型、少样本设置下的微调大型语言模型以及改编谷歌翻译等商用机器翻译应用程序。此外，该数据集为翻译研究、跨语言分析和词汇语义学等多个学科的研究提供了宝贵资源。该数据集还可以通过培训翻译学生来服务于教学目的，并作为翻译记忆库帮助专业翻译人员。

Abstract: ArzEn-MultiGenre is a parallel dataset of Egyptian Arabic song lyrics,
novels, and TV show subtitles that are manually translated and aligned with
their English counterparts. The dataset contains 25,557 segment pairs that can
be used to benchmark new machine translation models, fine-tune large language
models in few-shot settings, and adapt commercial machine translation
applications such as Google Translate. Additionally, the dataset is a valuable
resource for research in various disciplines, including translation studies,
cross-linguistic analysis, and lexical semantics. The dataset can also serve
pedagogical purposes by training translation students and aid professional
translators as a translation memory. The contributions are twofold: first, the
dataset features textual genres not found in existing parallel Egyptian Arabic
and English datasets, and second, it is a gold-standard dataset that has been
translated and aligned by human experts.

</details>


### [251] [Discovering Bias Associations through Open-Ended LLM Generations](https://arxiv.org/abs/2508.01412)
*Jinhao Pan,Chahat Raj,Ziwei Zhu*

Main category: cs.CL

TL;DR: 该研究提出了偏见关联发现框架（BADF），用于识别大型语言模型（LLM）中隐藏的社会偏见，特别是那些与人口统计学身份相关的偏见。该框架能够发现新的偏见关联，并为分析LLM中的偏见提供了一个可扩展的工具。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖于预定义的身份-概念关联，限制了它们发现新颖或意外偏见形式的能力。本研究旨在解决LLM中存在的社会偏见问题，特别是与人口统计学群体相关的，这些偏见可能通过生成的语言以微妙的方式表达出来。

Method: 该研究提出了偏见关联发现框架（BADF），这是一种用于从大型语言模型的开放式输出来提取偏见关联的系统方法。

Result: 通过跨多个模型和多样化的真实世界背景的综合实验，BADF能够对表征人口统计学身份的各种概念进行稳健的映射和分析。研究结果促进了对开放式生成中偏见的理解，并提供了一个可扩展的工具来识别和分析LLM中的偏见关联。

Conclusion: 该研究提出了偏见关联发现框架（BADF），一个用于从大型语言模型（LLM）的开放式输出来提取已知和先前未识别的偏见关联的系统方法。该框架通过全面的实验证明了其有效性，能够对不同模型和真实世界背景下的偏见进行稳健的映射和分析，从而促进对开放式生成中偏见的理解，并提供一个可扩展的工具来识别和分析LLM中的偏见关联。

Abstract: Social biases embedded in Large Language Models (LLMs) raise critical
concerns, resulting in representational harms -- unfair or distorted portrayals
of demographic groups -- that may be expressed in subtle ways through generated
language. Existing evaluation methods often depend on predefined
identity-concept associations, limiting their ability to surface new or
unexpected forms of bias. In this work, we present the Bias Association
Discovery Framework (BADF), a systematic approach for extracting both known and
previously unrecognized associations between demographic identities and
descriptive concepts from open-ended LLM outputs. Through comprehensive
experiments spanning multiple models and diverse real-world contexts, BADF
enables robust mapping and analysis of the varied concepts that characterize
demographic identities. Our findings advance the understanding of biases in
open-ended generation and provide a scalable tool for identifying and analyzing
bias associations in LLMs. Data, code, and results are available at
https://github.com/JP-25/Discover-Open-Ended-Generation

</details>


### [252] [From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs](https://arxiv.org/abs/2508.01424)
*Haonan Bian,Yutao Qi,Rui Yang,Yuanxi Che,Jiaqian Wang,Heming Xia,Ranran Zhen*

Main category: cs.CL

TL;DR: ORACLE是一个结合了LLM和知识图谱的框架，通过构建本体、转换为一阶逻辑和分解查询来改进多跳问答，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了克服大型语言模型（LLMs）在需要非线性、结构化推理的复杂多跳问答（MQA）任务中的局限性，由于它们无法充分捕捉实体之间深层概念关系。

Method: ORACLE框架结合了LLM的生成能力和知识图谱的结构化优势，通过三个阶段进行：1.使用LLM动态构建特定于问题的知识本体；2.将这些本体转换为一阶逻辑推理链；3.将原始查询系统地分解为逻辑上连贯的子问题。

Result: 在多个标准的MQA基准测试中，ORACLE框架取得了非常有竞争力的性能，其效果可与DeepSeek-R1等当前最先进的模型相媲美。

Conclusion: ORACLE框架在多跳问答任务上表现出与最先进模型相媲美的影响力，并生成了更具逻辑性和可解释性的推理链。

Abstract: Large Language Models (LLMs), despite their success in question answering,
exhibit limitations in complex multi-hop question answering (MQA) tasks that
necessitate non-linear, structured reasoning. This limitation stems from their
inability to adequately capture deep conceptual relationships between entities.
To overcome this challenge, we present **ORACLE** (**O**ntology-driven
**R**easoning **A**nd **C**hain for **L**ogical **E**ucidation), a
training-free framework that combines LLMs' generative capabilities with the
structural benefits of knowledge graphs. Our approach operates through three
stages: (1) dynamic construction of question-specific knowledge ontologies
using LLMs, (2) transformation of these ontologies into First-Order Logic
reasoning chains, and (3) systematic decomposition of the original query into
logically coherent sub-questions. Experimental results on several standard MQA
benchmarks show that our framework achieves highly competitive performance,
rivaling current state-of-the-art models like DeepSeek-R1. Detailed analyses
further confirm the effectiveness of each component, while demonstrating that
our method generates more logical and interpretable reasoning chains than
existing approaches.

</details>


### [253] [Towards Efficient Medical Reasoning with Minimal Fine-Tuning Data](https://arxiv.org/abs/2508.01450)
*Xinlin Zhuang,Feilong Tang,Haolin Yang,Ming Hu,Huifa Li,Haochen Xue,Yichen Li,Junjun He,Zongyuan Ge,Ying Qian,Imran Razzak*

Main category: cs.CL

TL;DR: DIQ是一种数据选择策略，通过结合样本难度和梯度影响，用最少的微调数据实现了高效的医学推理。


<details>
  <summary>Details</summary>
Motivation: 现有的SFT实践通常依赖于包含冗余和低质量样本的未经过滤的数据集，这会导致显著的计算成本和次优的性能。现有的方法通过根据样本难度（由知识和推理复杂性定义）来选择数据，但忽略了每个样本反映在梯度中的优化效用。梯度基准影响倾向于易于优化的样本，而难度基准则倾向于噪声或过度复杂的样本。

Method: 提出了一种名为难度-影响力象限（DIQ）的数据选择策略，该策略优先选择高难度-高影响力象限中的样本，以平衡复杂的临床推理和显著的梯度影响。

Result: DIQ选定的子集展示了更高的数据质量，并且在鉴别诊断、安全检查和证据引用方面，生成的临床推理与专家实践更加一致。DIQ使模型能够在仅1%的选定数据上进行微调，即可匹配完整数据集的性能，而使用10%的数据则始终优于基线。

Conclusion: DIQ通过优先选择高难度-高影响力象限中的样本，平衡了复杂的临床推理和显著的梯度影响，从而能够用最少的微调数据实现高效的医学推理。DIQ使仅在1%的选定数据上进行微调的模型能够匹配完整数据集的性能，同时使用10%的数据始终优于基线，这凸显了原则性数据选择优于暴力扩展的优越性。

Abstract: Supervised Fine-Tuning (SFT) plays a pivotal role in adapting Large Language
Models (LLMs) to specialized domains such as medical reasoning. However,
existing SFT practices often rely on unfiltered datasets that contain redundant
and low-quality samples, leading to substantial computational costs and
suboptimal performance. Although existing methods attempt to alleviate this
problem by selecting data based on sample difficulty, defined by knowledge and
reasoning complexity, they overlook each sample's optimization utility
reflected in its gradient. Interestingly, we find that gradient-based influence
alone favors easy-to-optimize samples that cause large parameter shifts but
lack deep reasoning chains, while difficulty alone selects noisy or overly
complex cases that fail to guide stable optimization. Based on this
observation, we propose a data selection strategy, Difficulty-Influence
Quadrant (DIQ), which prioritizes samples in the high-difficulty-high-influence
quadrant to balance complex clinical reasoning with substantial gradient
influence, enabling efficient medical reasoning with minimal fine-tuning data.
Furthermore, Human and LLM-as-a-judge evaluations show that DIQ-selected
subsets demonstrate higher data quality and generate clinical reasoning that is
more aligned with expert practices in differential diagnosis, safety check, and
evidence citation, as DIQ emphasizes samples that foster expert-like reasoning
patterns. Extensive experiments on medical reasoning benchmarks demonstrate
that DIQ enables models fine-tuned on only 1% of selected data to match
full-dataset performance, while using 10% consistently outperforms the
baseline, highlighting the superiority of principled data selection over
brute-force scaling. The code and data are available at
https://github.com/mihara-bot/DIQ.

</details>


### [254] [TreeDiff: AST-Guided Code Generation with Diffusion LLMs](https://arxiv.org/abs/2508.01473)
*Yiming Zeng,Jinghan Cao,Zexin Li,Yiming Chen,Tao Ren,Dawei Xiang,Xidong Wu,Shangqian Gao,Tingting Yu*

Main category: cs.CL

TL;DR: 提出了一种语法感知扩散框架，通过利用抽象语法树（AST）的结构信息来改进代码生成。该方法通过破坏和重建句法上有意义的代码跨度来保留代码的结构，从而提高句法正确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在将扩散模型应用于源代码等结构化领域时，需要解决编程语言严格的句法和语义规则以及必须保留的层次结构。标准标记级损坏技术通常会忽略代码结构，这可能会阻碍模型学习有意义的代码表示。

Method: 提出了一种语法感知扩散框架，将抽象语法树（AST）的结构先验知识纳入去噪过程。该方法不随机屏蔽单个标记，而是选择性地破坏源自AST子树的句法上有意义的代码跨度。

Result: 实验结果表明，语法感知损坏在句法正确性、重建准确性和对未见代码模式的泛化能力方面有显著提高。

Conclusion: 将结构信息纳入基于扩散的模型训练中，并提出语法引导去噪是推动基于扩散的语言模型在代码生成任务中的一个有前途的方向。

Abstract: Recent advances in diffusion-based language models have opened new
possibilities for controllable and bidirectional sequence generation. These
models provide an alternative to traditional autoregressive approaches by
framing text generation as an iterative denoising process. However, applying
diffusion models to structured domains such as source code remains a
significant challenge. Programming languages differ from natural language in
that they follow strict syntactic and semantic rules, with hierarchical
organization that must be preserved for correctness. Standard token-level
corruption techniques used during training often ignore this structure, which
may hinder the model's ability to learn meaningful representations of code. To
address this limitation, we propose a syntax-aware diffusion framework that
incorporates structural priors from Abstract Syntax Trees (ASTs) into the
denoising process. Instead of masking individual tokens at random, we
selectively corrupt syntactically meaningful code spans derived from AST
subtrees. This enables the model to reconstruct programs in a way that respects
grammatical boundaries and captures long-range dependencies. Experimental
results demonstrate that syntax-aware corruption significantly improves
syntactic correctness, reconstruction accuracy, and generalization to unseen
code patterns. These findings highlight the potential of incorporating
structural information into diffusion-based training and suggest that
syntax-guided denoising is a promising direction for advancing diffusion-based
language models in code generation tasks.

</details>


### [255] [Harnessing Collective Intelligence of LLMs for Robust Biomedical QA: A Multi-Model Approach](https://arxiv.org/abs/2508.01480)
*Dimitra Panou,Alexandros C. Dimopoulos,Manolis Koubarakis,Martin Reczko*

Main category: cs.CL

TL;DR: 本研究通过结合多种开源LLMs并优化模型管线，在BioASQ生物医学问答挑战赛中取得了显著成果，尤其在Synergy任务中名列前茅。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献呈指数级增长，对生物医学文本挖掘和问答任务提出了巨大挑战，需要更有效的问答系统。

Method: 使用包括检索增强生成（RAG）在内的大型语言模型（LLMs）来处理生物医学问题。对于是非题，采用多数投票系统整合模型输出；对于列表和事实型问题，则合并所有模型的答案。研究评估了13种开源LLMs，并探索了模型组合以优化针对不同问题类型的LLM管线。

Result: 在2025年BioASQ挑战赛的四个轮次中，该系统在Synergy任务中表现出色，在第二轮获得理想答案的第1名和精确答案的第2名，在第三和第四轮获得两个并列的精确答案第1名。

Conclusion: 该研究展示了在BioASQ挑战赛中，结合多种开源大型语言模型（LLMs）进行生物医学问题回答的有效性，并针对不同类型的问题优化了LLM管线，取得了优异的成绩。

Abstract: Biomedical text mining and question-answering are essential yet highly
demanding tasks, particularly in the face of the exponential growth of
biomedical literature. In this work, we present our participation in the 13th
edition of the BioASQ challenge, which involves biomedical semantic
question-answering for Task 13b and biomedical question-answering for
developing topics for the Synergy task. We deploy a selection of open-source
large language models (LLMs) as retrieval-augmented generators to answer
biomedical questions. Various models are used to process the questions. A
majority voting system combines their output to determine the final answer for
Yes/No questions, while for list and factoid type questions, the union of their
answers in used. We evaluated 13 state-of-the-art open source LLMs, exploring
all possible model combinations to contribute to the final answer, resulting in
tailored LLM pipelines for each question type. Our findings provide valuable
insight into which combinations of LLMs consistently produce superior results
for specific question types. In the four rounds of the 2025 BioASQ challenge,
our system achieved notable results: in the Synergy task, we secured 1st place
for ideal answers and 2nd place for exact answers in round 2, as well as two
shared 1st places for exact answers in round 3 and 4.

</details>


### [256] [TeSent: A Benchmark Dataset for Fairness-aware Explainable Sentiment Classification in Telugu](https://arxiv.org/abs/2508.01486)
*Vallabhaneni Raj Kumar,Ashwin S,Supriya Manna,Niladri Sett,Cheedella V S N M S Hema Harshitha,Kurakula Harshitha,Anand Kumar Sharma,Basina Deepakraj,Tanuj Sarkar,Bondada Navaneeth Krishna,Samanthapudi Shakeer*

Main category: cs.CL

TL;DR: 本研究提出了 TeSent 数据集，用于泰卢固语情感分类，解决了该语言在 NLP 领域资源匮乏的问题。数据集包含带释义的句子，并评估了可解释性和公平性。实验证明，使用释义训练的模型效果更佳。


<details>
  <summary>Details</summary>
Motivation: 尽管泰卢固语在全球拥有 9600 万使用者，但在全球自然语言处理和机器学习领域却代表性不足，这主要是由于缺乏高质量的带注释资源。本研究旨在解决这一问题，通过引入 TeSent 数据集来促进泰卢固语的情感分类研究，并考虑了现代机器学习任务中的可解释性和公平性。

Method: 爬取了来自多个社交媒体平台、新闻网站和网络博客的泰卢固语文本，经过预处理生成了 26,150 个句子，并开发了一个定制的注释平台和一套精心设计的注释协议，用于收集真实标签及其人工注释的释义。然后，我们通过两种方式对几个最先进的预训练模型进行了微调：使用释义和不使用释义。此外，我们提供了一套详细的合理性和忠实性评估套件，该套件利用释义来评估六种常用的事后解释器在训练模型上的应用情况。最后，我们整理了 TeEEC（泰卢固语公平性评估语料库），这是一个用于评估泰卢固语情感和情绪相关自然语言处理任务公平性的语料库，并为训练好的分类器模型提供了公平性评估套件。

Result: TeSent 数据集包含 26,150 个泰卢固语句子，并附带真实标签、人类注释的释义以及用于评估可解释性和公平性的套件。实验结果表明，使用释义进行训练的模型在准确性、减少偏差和提高解释器与人类推理的一致性方面表现更好。

Conclusion: 研究结果表明，使用释义进行训练可以提高模型准确性，减少模型偏差，并使解释器的输出更符合人类推理。

Abstract: In the Indian subcontinent, Telugu, one of India's six classical languages,
is the most widely spoken Dravidian Language. Despite its 96 million speaker
base worldwide, Telugu remains underrepresented in the global NLP and Machine
Learning landscape, mainly due to lack of high-quality annotated resources.
This work introduces TeSent, a comprehensive benchmark dataset for sentiment
classification, a key text classification problem, in Telugu. TeSent not only
provides ground truth labels for the sentences, but also supplements with
provisions for evaluating explainability and fairness, two critical
requirements in modern-day machine learning tasks. We scraped Telugu texts
covering multiple domains from various social media platforms, news websites
and web-blogs to preprocess and generate 26,150 sentences, and developed a
custom-built annotation platform and a carefully crafted annotation protocol
for collecting the ground truth labels along with their human-annotated
rationales. We then fine-tuned several SOTA pre-trained models in two ways:
with rationales, and without rationales. Further, we provide a detailed
plausibility and faithfulness evaluation suite, which exploits the rationales,
for six widely used post-hoc explainers applied on the trained models. Lastly,
we curate TeEEC, Equity Evaluation Corpus in Telugu, a corpus to evaluate
fairness of Telugu sentiment and emotion related NLP tasks, and provide a
fairness evaluation suite for the trained classifier models. Our experimental
results suggest that training with rationales may improve model accuracy,
reduce bias in models, and make the explainers' output more aligned to human
reasoning.

</details>


### [257] [The Homogenizing Effect of Large Language Models on Human Expression and Thought](https://arxiv.org/abs/2508.01491)
*Zhivar Sourati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: LLM存在导致语言和思维标准化的风险，可能削弱认知多样性和集体智能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益融入人们的生活，它们存在标准化语言和思维的风险，而认知多样性（体现在语言、视角和推理的变异性）对创造力和集体智能至关重要。

Method: 通过整合语言学、认知科学和计算机科学的证据，探讨LLM如何反映和强化主流风格，同时边缘化其他声音和推理策略。分析了LLM的设计和使用如何通过镜像训练数据模式并放大趋同效应来促成这一结果。

Result: LLM在反映和强化主流风格的同时，边缘化了少数群体的声音和推理方式。它们的设计和使用通过模仿训练数据中的模式并放大趋同效应，进一步加剧了这种同质化。

Conclusion: LLM的广泛使用有标准化语言和思维的风险，可能导致认知多样性的丧失，影响集体智能和适应性。

Abstract: Cognitive diversity, reflected in variations of language, perspective, and
reasoning, is essential to creativity and collective intelligence. This
diversity is rich and grounded in culture, history, and individual experience.
Yet as large language models (LLMs) become deeply embedded in people's lives,
they risk standardizing language and reasoning. This Review synthesizes
evidence across linguistics, cognitive, and computer science to show how LLMs
reflect and reinforce dominant styles while marginalizing alternative voices
and reasoning strategies. We examine how their design and widespread use
contribute to this effect by mirroring patterns in their training data and
amplifying convergence as all people increasingly rely on the same models
across contexts. Unchecked, this homogenization risks flattening the cognitive
landscapes that drive collective intelligence and adaptability.

</details>


### [258] [VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo](https://arxiv.org/abs/2508.02317)
*Qianli Ma,Yaowei Zheng,Zhelun Shi,Zhongkai Zhao,Bin Jia,Ziyue Huang,Zhiqi Lin,Youjie Li,Jiacheng Yang,Yanghua Peng,Zhi Zhang,Xin Liu*

Main category: cs.CL

TL;DR: VE-Omni是一个高效、可扩展的全模态LLM训练框架，能显著加速训练过程并降低工程开销。


<details>
  <summary>Details</summary>
Motivation: 现有全模态LLM训练框架存在模型定义与并行逻辑耦合、可扩展性差、工程开销大等问题。

Method: VE-Omni框架，采用模型中心化的分布式策略，将通信与计算分离，实现了全模态LLM的高效3D并行。

Result: 在128个GPU上，使用VE-Omni训练的30B参数的全模态MoE模型，实现了超过2800 tokens/sec/GPU的吞吐量，并将上下文长度扩展到160K。

Conclusion: VE-Omni框架通过解耦通信和计算，实现了高效的3D并行，显著提高了全模态LLM的训练效率和可扩展性，并支持灵活的配置接口，可轻松集成新模态。

Abstract: Recent advances in large language models (LLMs) have driven impressive
progress in omni-modal understanding and generation. However, training
omni-modal LLMs remains a significant challenge due to the heterogeneous model
architectures required to process diverse modalities, necessitating
sophisticated system design for efficient large-scale training. Existing
frameworks typically entangle model definition with parallel logic, incurring
limited scalability and substantial engineering overhead for end-to-end
omni-modal training. % We present \veomni, a modular and efficient training
framework to accelerate the development of omni-modal LLMs. \veomni introduces
model-centric distributed recipes that decouples communication from
computation, enabling efficient 3D parallelism on omni-modal LLMs. \veomni also
features a flexible configuration interface supporting seamless integration of
new modalities with minimal code change. % Using \veomni, a omni-modal
mixture-of-experts (MoE) model with 30B parameters can be trained with over
2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D
parallelism on 128 GPUs, showcasing its superior efficiency and scalability for
training large omni-modal LLMs.

</details>


### [259] [A Theory of Adaptive Scaffolding for LLM-Based Pedagogical Agents](https://arxiv.org/abs/2508.01503)
*Clayton Cohn,Surya Rayala,Namrata Srivastava,Joyce Horn Fonteles,Shruti Jain,Xinying Luo,Divya Mereddy,Naveeduddin Mohammed,Gautam Biswas*

Main category: cs.CL

TL;DR: LLM可用于创建教学代理，以支持学生学习。本研究提出了一个将证据中心设计与社会认知理论相结合的框架，用于LLM驱动的STEM+C学习的自适应脚手架。


<details>
  <summary>Details</summary>
Motivation: 目前LLM在课堂上的使用缺乏像早期智能辅导系统那样的坚实理论基础。

Method: 本研究提出了一个将证据中心设计与社会认知理论相结合的框架，并以Inquizzitor为例进行了说明。Inquizzitor是一个基于LLM的形成性评估代理，它整合了人类与人工智能的混合智能，并提供基于认知科学原理的反馈。

Result: Inquizzitor能够提供高质量的评估和交互，并与核心学习理论保持一致，为教师提供学生重视的有效指导。

Conclusion: LLM可用于创建教学代理，以支持学生学习。本研究提出了一个将证据中心设计与社会认知理论相结合的框架，用于LLM驱动的STEM+C学习的自适应脚手架。

Abstract: Large language models (LLMs) present new opportunities for creating
pedagogical agents that engage in meaningful dialogue to support student
learning. However, the current use of LLM systems like ChatGPT in classrooms
often lacks the solid theoretical foundation found in earlier intelligent
tutoring systems. To bridge this gap, we propose a framework that combines
Evidence-Centered Design with Social Cognitive Theory for adaptive scaffolding
in LLM-based agents focused on STEM+C learning. We illustrate this framework
with Inquizzitor, an LLM-based formative assessment agent that integrates
human-AI hybrid intelligence and provides feedback grounded in cognitive
science principles. Our findings show that Inquizzitor delivers high-quality
assessment and interaction aligned with core learning theories, offering
teachers effective guidance that students value. This research underscores the
potential for theory-driven LLM integration in education, highlighting the
ability of these systems to provide adaptive and principled instruction.

</details>


### [260] [MOPrompt: Multi-objective Semantic Evolution for Prompt Optimization](https://arxiv.org/abs/2508.01541)
*Sara Câmara,Eduardo Luz,Valéria Carvalho,Ivan Meneghini,Gladston Moreira*

Main category: cs.CL

TL;DR: MOPrompt是一个多目标优化框架，用于同时优化LLM提示的准确性和上下文长度，并在实验中取得了优于基线方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法往往只关注单一目标（如性能），未能充分解决任务性能和上下文大小之间的权衡问题。

Method: 提出了一种名为MOPrompt的多目标进化优化（EMO）框架，用于同时优化提示的准确性和上下文大小（以token计）。

Result: MOPrompt框架识别出的提示能够在准确性（0.97）与基线方法相同时，将token长度减少31%。

Conclusion: MOPrompt框架能够同时优化LLM提示的准确性和上下文长度，并在评估任务中优于基线方法。

Abstract: Prompt engineering is crucial for unlocking the potential of Large Language
Models (LLMs). Still, since manual prompt design is often complex,
non-intuitive, and time-consuming, automatic prompt optimization has emerged as
a research area. However, a significant challenge in prompt optimization is
managing the inherent trade-off between task performance, such as accuracy, and
context size. Most existing automated methods focus on a single objective,
typically performance, thereby failing to explore the critical spectrum of
efficiency and effectiveness. This paper introduces the MOPrompt, a novel
Multi-objective Evolutionary Optimization (EMO) framework designed to optimize
prompts for both accuracy and context size (measured in tokens) simultaneously.
Our framework maps the Pareto front of prompt solutions, presenting
practitioners with a set of trade-offs between context size and performance, a
crucial tool for deploying Large Language Models (LLMs) in real-world
applications. We evaluate MOPrompt on a sentiment analysis task in Portuguese,
using Gemma-2B and Sabiazinho-3 as evaluation models. Our findings show that
MOPrompt substantially outperforms the baseline framework. For the Sabiazinho
model, MOPrompt identifies a prompt that achieves the same peak accuracy (0.97)
as the best baseline solution, but with a 31% reduction in token length.

</details>


### [261] [Are All Prompt Components Value-Neutral? Understanding the Heterogeneous Adversarial Robustness of Dissected Prompt in Large Language Models](https://arxiv.org/abs/2508.01554)
*Yujia Zheng,Tianhao Li,Haotian Huang,Tianyu Zeng,Jingyu Lu,Chuangxin Chu,Yuekai Huang,Ziyou Jiang,Qian Xiong,Yuyao Ge,Mingyang Li*

Main category: cs.CL

TL;DR: PromptAnatomy dissects prompts into functional components to create better adversarial attacks for LLMs, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing prompt-based adversarial attacks overlook the structural heterogeneity of prompts, treating them as monolithic text. This work addresses the gap by recognizing that complex, domain-specific prompts have components with differing vulnerabilities.

Method: PromptAnatomy, an automated framework that dissects prompts into functional components and generates diverse, interpretable adversarial examples by selectively perturbing each component using ComPerturb. Incorporates a perplexity (PPL)-based filtering mechanism for linguistic plausibility and mitigating distribution shifts.

Result: Extensive experiments across four datasets and five advanced LLMs demonstrate that ComPerturb achieves state-of-the-art attack success rates. Ablation studies validate the complementary benefits of prompt dissection and PPL filtering.

Conclusion: The study underscores the importance of prompt structure awareness and controlled perturbation for reliable adversarial robustness evaluation in LLMs, demonstrating that ComPerturb achieves state-of-the-art attack success rates.

Abstract: Prompt-based adversarial attacks have become an effective means to assess the
robustness of large language models (LLMs). However, existing approaches often
treat prompts as monolithic text, overlooking their structural
heterogeneity-different prompt components contribute unequally to adversarial
robustness. Prior works like PromptRobust assume prompts are value-neutral, but
our analysis reveals that complex, domain-specific prompts with rich structures
have components with differing vulnerabilities. To address this gap, we
introduce PromptAnatomy, an automated framework that dissects prompts into
functional components and generates diverse, interpretable adversarial examples
by selectively perturbing each component using our proposed method, ComPerturb.
To ensure linguistic plausibility and mitigate distribution shifts, we further
incorporate a perplexity (PPL)-based filtering mechanism. As a complementary
resource, we annotate four public instruction-tuning datasets using the
PromptAnatomy framework, verified through human review. Extensive experiments
across these datasets and five advanced LLMs demonstrate that ComPerturb
achieves state-of-the-art attack success rates. Ablation studies validate the
complementary benefits of prompt dissection and PPL filtering. Our results
underscore the importance of prompt structure awareness and controlled
perturbation for reliable adversarial robustness evaluation in LLMs. Code and
data are available at https://github.com/Yujiaaaaa/PACP.

</details>


### [262] [OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets](https://arxiv.org/abs/2508.01630)
*Maziyar Panahi*

Main category: cs.CL

TL;DR: OpenMed NER 是一种结合了 DAPT 和 LoRA 的 NER 方法，在生物医学 NER 任务上取得了最先进的成果，同时保持了高效率和低碳排放，并生成了可访问的开源模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决在从非结构化临床笔记和生物医学文献中提取信息时，即使有大型语言模型的进步，但在多样化的实体类型上实现最先进的性能并保持计算效率仍然是一个重大挑战。

Method: 本研究介绍了一种名为 OpenMed NER 的方法，该方法结合了领域自适应预训练 (DAPT) 和参数高效的低秩适配 (LoRA)。DAPT 使用 DeBERTa-v3、PubMedBERT 和 BioELECTRA 作为骨干模型，在包含 350,000 个段落的语料库上进行，该语料库由 PubMed、arXiv 和 MIMIC-III 的公共可用研究存储库和去标识化临床笔记组成。随后的任务特定微调使用 LoRA 进行，该技术仅更新不到 1.5% 的模型参数。

Result: OpenMed NER 在 12 个生物医学 NER 基准测试中的 10 个上实现了新的最先进微 F1 分数，在 BC5CDR-Disease 数据集上提高了 2.70 个百分点，在基因和细胞系语料库上分别提高了 5.3 和 9.7 个百分点。该模型训练效率高，可在单个 GPU 上 12 小时内完成，碳排放量低。

Conclusion: OpenMed NER 通过结合轻量级领域自适应预训练 (DAPT) 和参数高效的低秩适配 (LoRA)，在 12 个生物医学 NER 基准测试中取得了新的最先进的微 F1 分数，尤其是在疾病、化学品、基因和细胞系实体类型方面。该方法在单个 GPU 上以低于 12 小时和低碳排放 (< 1.2 kg CO2e) 完成训练，并生成了遵循许可的开源模型，证明了战略性适应的开源模型可以超越闭源解决方案，同时满足新兴的数据保护和 AI 法规要求。

Abstract: Named-entity recognition (NER) is fundamental to extracting structured
information from the >80% of healthcare data that resides in unstructured
clinical notes and biomedical literature. Despite recent advances with large
language models, achieving state-of-the-art performance across diverse entity
types while maintaining computational efficiency remains a significant
challenge. We introduce OpenMed NER, a suite of open-source, domain-adapted
transformer models that combine lightweight domain-adaptive pre-training (DAPT)
with parameter-efficient Low-Rank Adaptation (LoRA). Our approach performs
cost-effective DAPT on a 350k-passage corpus compiled from ethically sourced,
publicly available research repositories and de-identified clinical notes
(PubMed, arXiv, and MIMIC-III) using DeBERTa-v3, PubMedBERT, and BioELECTRA
backbones. This is followed by task-specific fine-tuning with LoRA, which
updates less than 1.5% of model parameters. We evaluate our models on 12
established biomedical NER benchmarks spanning chemicals, diseases, genes, and
species. OpenMed NER achieves new state-of-the-art micro-F1 scores on 10 of
these 12 datasets, with substantial gains across diverse entity types. Our
models advance the state-of-the-art on foundational disease and chemical
benchmarks (e.g., BC5CDR-Disease, +2.70 pp), while delivering even larger
improvements of over 5.3 and 9.7 percentage points on more specialized gene and
clinical cell line corpora. This work demonstrates that strategically adapted
open-source models can surpass closed-source solutions. This performance is
achieved with remarkable efficiency: training completes in under 12 hours on a
single GPU with a low carbon footprint (< 1.2 kg CO2e), producing permissively
licensed, open-source checkpoints designed to help practitioners facilitate
compliance with emerging data protection and AI regulations, such as the EU AI
Act.

</details>


### [263] [Authorship Attribution in Multilingual Machine-Generated Texts](https://arxiv.org/abs/2508.01656)
*Lucio La Cava,Dominik Macko,Róbert Móro,Ivan Srba,Andrea Tagarelli*

Main category: cs.CL

TL;DR: 本研究解决了多语言作者归因问题，即识别不同语言文本的生成者（人类或LLM）。研究表明，现有单一语言方法在多语言环境下存在局限性，尤其是在跨语系迁移时，需要更先进的方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）生成文本的流畅度和连贯性达到人类水平，区分机器生成文本（MGT）和人类书写内容变得日益困难。现有的MGT检测主要集中在二元分类，但考虑到LLMs日益增长的范围和多样性，需要更细粒度的作者归因（AA），即能够识别文本的确切生成者（LLM或人类）。然而，目前的AA研究主要局限于单一语言（尤其是英语），忽略了现代LLMs的多语言特性和使用情况。因此，本研究引入了多语言作者归因问题，旨在跨越不同语言，将文本归因于人类或多个LLM生成器。

Method: 本研究调查了单一语言作者归因方法在多语言环境下的适用性、跨语言迁移能力以及生成器对归因性能的影响。

Result: 研究结果表明，虽然某些单一语言的作者归因方法可以适应多语言设置，但仍存在显著的局限性，尤其是在跨越不同语系进行迁移时，这表明多语言作者归因的复杂性，以及需要更鲁固的方法来更好地适应现实场景。

Conclusion: 目前的研究表明，尽管某些单一语言的作者归因方法可以适应多语言环境，但在跨语言迁移方面仍存在显著的局限性和挑战，尤其是在跨越不同语系时，这凸显了多语言作者归因的复杂性，以及在更贴合实际应用场景的需求方面，需要更鲁固的方法。

Abstract: As Large Language Models (LLMs) have reached human-like fluency and
coherence, distinguishing machine-generated text (MGT) from human-written
content becomes increasingly difficult. While early efforts in MGT detection
have focused on binary classification, the growing landscape and diversity of
LLMs require a more fine-grained yet challenging authorship attribution (AA),
i.e., being able to identify the precise generator (LLM or human) behind a
text. However, AA remains nowadays confined to a monolingual setting, with
English being the most investigated one, overlooking the multilingual nature
and usage of modern LLMs. In this work, we introduce the problem of
Multilingual Authorship Attribution, which involves attributing texts to human
or multiple LLM generators across diverse languages. Focusing on 18 languages
-- covering multiple families and writing scripts -- and 8 generators (7 LLMs
and the human-authored class), we investigate the multilingual suitability of
monolingual AA methods, their cross-lingual transferability, and the impact of
generators on attribution performance. Our results reveal that while certain
monolingual AA methods can be adapted to multilingual settings, significant
limitations and challenges remain, particularly in transferring across diverse
language families, underscoring the complexity of multilingual AA and the need
for more robust approaches to better match real-world scenarios.

</details>


### [264] [CUPID: Evaluating Personalized and Contextualized Alignment of LLMs from Interactions](https://arxiv.org/abs/2508.01674)
*Tae Soo Kim,Yoonjoo Lee,Yoonah Park,Jiho Kim,Young-Ho Kim,Juho Kim*

Main category: cs.CL

TL;DR: CUPID是一个包含756个用户与LLM交互会话历史的基准测试，用于评估LLM在理解和应用用户动态情境偏好方面的能力。现有LLM在该基准测试中表现不佳，表明在实现更具情境化个性化交互方面存在差距。


<details>
  <summary>Details</summary>
Motivation: 个人化大型语言模型（LLM）通常假设用户的偏好是静态的，并在所有任务中普遍存在。然而，现实中用户的偏好会因情境而动态变化。因此，需要一种方法来评估LLM推断和应用这些情境化偏好以实现更好对齐的能力。

Method: 使用CUPID基准测试，该基准包含756个用户与基于LLM的聊天助手之间交互的会话历史。在每次交互中，用户提供特定情境下的请求，并通过多轮反馈表达偏好。基准测试评估LLM能否根据新的用户请求和先前的交互会话来推断与该请求相关的偏好，并生成满足该偏好的响应。

Result: 评估了10个公开和专有的LLM，结果显示它们在从多轮交互中推断偏好以及辨别先前情境与新请求相关性方面存在不足，精确率和召回率均低于理想水平。

Conclusion: 当前最先进的大型语言模型（LLM）难以从多轮交互中推断用户偏好，并且无法分辨哪些先前的情境与新请求相关，其精确率低于50%，召回率低于65%。这项工作强调了提高LLM在更具情境化个性化交互方面的能力，并提出CUPID作为推动这些改进的资源。

Abstract: Personalization of Large Language Models (LLMs) often assumes users hold
static preferences that reflect globally in all tasks. In reality, humans hold
dynamic preferences that change depending on the context. As users interact
with an LLM in various contexts, they naturally reveal their contextual
preferences, which a model must infer and apply in future contexts to ensure
alignment. To assess this, we introduce CUPID, a benchmark of 756 human-curated
interaction session histories between users and LLM-based chat assistants. In
each interaction session, the user provides a request in a specific context and
expresses their preference through multi-turn feedback. Given a new user
request and prior interaction sessions, our benchmark assesses whether LLMs can
infer the preference relevant to this request and generate a response that
satisfies this preference. With CUPID, we evaluated 10 open and proprietary
LLMs, revealing that state-of-the-art LLMs struggle to infer preferences from
multi-turn interactions and fail to discern what previous context is relevant
to a new request -- under 50% precision and 65% recall. Our work highlights the
need to advance LLM capabilities for more contextually personalized
interactions and proposes CUPID as a resource to drive these improvements.

</details>


### [265] [The Bidirectional Process Reward Model](https://arxiv.org/abs/2508.01682)
*Lingyin Zhang,Jun Gao,Xiaoxue Ren,Ziqiang Cao*

Main category: cs.CL

TL;DR: BiPRM通过引入双向评估范式，克服了现有PRM的局限性，提高了LLM的推理质量，并在数学推理任务上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的PRM主要采用单向L2R评估范式，这限制了它们利用全局上下文的能力，使得基于后续步骤验证早期步骤的一致性变得困难。

Method: 提出了一种新颖的双向评估范式，称为双向过程奖励模型（BiPRM），它在传统的L2R评估流之外，并入了并行的R2L评估流。R2L评估仅通过反转原始推理轨迹的提示修改来实现，不增加额外参数或推理延迟。

Result: 在两个数学推理基准测试上使用三个不同策略模型生成的样本进行的大量实验表明，BiPRM在所有设置下始终优于单向基线，在逐步奖励评估方面实现了高达31.9%的改进。

Conclusion: BiPRM通过引入并行右到左（R2L）评估流，克服了现有单向左到右（L2R）过程奖励模型（PRM）的局限性，能够实时利用全局上下文，提升了LLM的推理质量。实验表明，BiPRM在数学推理任务上表现优于单向基线，在逐步奖励评估方面提高了31.9%，显示出其有效性、鲁棒性和通用性。

Abstract: Process Reward Models (PRMs) have emerged as a promising approach to enhance
the reasoning quality of Large Language Models (LLMs) by assigning fine-grained
scores to intermediate reasoning steps within a solution trajectory. However,
existing PRMs predominantly adopt a unidirectional left-to-right (L2R)
evaluation paradigm, which limits their ability to leverage global context,
making it challenging to verify the consistency of earlier steps based on later
ones. In light of these challenges, we propose a novel bidirectional evaluation
paradigm, named Bidirectional Process Reward Model (BiPRM). BiPRM seamlessly
incorporates a parallel right-to-left (R2L) evaluation stream alongside the
conventional L2R flow, enabling later reasoning steps to help assess earlier
ones in real time. Notably, the built-in R2L evaluation is implemented solely
through prompt modifications that reverse the original reasoning trajectory,
without any additional parameters or inference latency introduced. This ensures
BiPRM remains both efficient and broadly compatible with existing PRM studies.
We conduct extensive experiments on two mathematical reasoning benchmarks using
samples generated by three different policy models. Our method, BiPRM, is
evaluated across three backbones and three distinct PRM objectives. Across all
settings, BiPRM consistently outperforms unidirectional baselines, achieving up
to a 31.9% improvement in stepwise reward evaluation. Generally, our results
highlight BiPRM's effectiveness, robustness, and general applicability,
offering a promising new direction for process-based reward modeling.

</details>


### [266] [Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy](https://arxiv.org/abs/2508.01696)
*Yi Jiang,Sendong Zhao,Jianbo Li,Haochun Wang,Lizhe Zhang,Yan Liu,Bin Qin*

Main category: cs.CL

TL;DR: CoCoA 框架通过多智能体协作和长链训练，提升了大型语言模型在知识密集型任务中利用内部和外部知识的能力。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成（RAG）方法在充分利用知识方面存在局限性，特别是模型内部参数知识与外部检索知识的协同作用有限。

Method: 提出了一种名为“Collaborative Chain-of-Agents”（CoCoA）的框架，包括 CoCoA-zero（一种多智能体检索增强生成方法）和 CoCoA（一种长链训练策略），以增强模型对参数知识和检索知识的协同利用。

Result: CoCoA-zero 和 CoCoA 在开放域和多跳问答任务上取得了卓越的性能，展示了其在整合和联合利用参数知识与检索知识方面的能力。

Conclusion: CoCoA-zero 和 CoCoA 在开放域和多跳问答任务上取得了卓越的性能。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising framework for
enhancing the capabilities of Large Language Models (LLMs), especially in
knowledge-intensive tasks. Despite its advantages, current RAG methods often
struggle to *fully exploit knowledge during generation*. In particular, the
synergy between the model's internal parametric knowledge and external
retrieved knowledge remains limited. Retrieved contents may sometimes mislead
generation, while certain generated content can guide the model toward more
accurate outputs. In this work, we propose Collaborative Chain-of-Agents, a
framework designed to enhance explicitly synergy over both parametric and
retrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent
RAG framework that first performs conditional knowledge induction and then
reasons answers. Building on this, we develop CoCoA, a long-chain training
strategy that synthesizes extended multi-agent reasoning trajectories from
CoCoA-zero to fine-tune the LLM. This strategy enhances the model's capability
to explicitly integrate and jointly leverage parametric and retrieved
knowledge. Experiments results show that CoCoA-zero and CoCoA achieve superior
performance on open-domain and multi-hop QA tasks.

</details>


### [267] [Am I Blue or Is My Hobby Counting Teardrops? Expression Leakage in Large Language Models as a Symptom of Irrelevancy Disruption](https://arxiv.org/abs/2508.01708)
*Berkay Köprü,Mehrzad Mashal,Yigit Gurses,Akos Kadar,Maximilian Schmitt,Ditty Mathew,Felix Burkhardt,Florian Eyben,Björn W. Schuller*

Main category: cs.CL

TL;DR: LLM的“表达泄漏”问题：模型越大越好，提示词没用，负面情绪是坏蛋。


<details>
  <summary>Details</summary>
Motivation: LLM虽然在NLP任务中表现出色，但也容易整合不相关信息，导致“语义泄漏”。本研究关注的是“表达泄漏”，即LLM生成与输入上下文语义无关但带有情感色彩的表达。

Method: 提出了“表达泄漏”的概念，并收集了一个基准数据集，同时设计了一个自动生成数据集的方法。此外，还提出了一个自动评估流程，该流程能与人类判断良好相关，从而加速基准测试，因为它不需要对每个被分析的模型进行标注。

Result: 实验表明，随着模型参数量的增加，同一LLM家族内的表达泄漏会减少。此外，表达泄漏的缓解需要模型构建过程中的特殊处理，无法通过提示词缓解。负面情绪注入比正面情绪注入更容易干扰生成过程，导致更高的表达泄漏率。

Conclusion: LLM的“表达泄漏”现象，即在生成与输入上下文语义无关但带有情感色彩的表达，与模型规模相关，模型越大，泄漏越少。该现象无法通过提示词缓解，且负面情感注入比正面情感注入更容易破坏生成过程，导致更高的表达泄漏率。

Abstract: Large language models (LLMs) have advanced natural language processing (NLP)
skills such as through next-token prediction and self-attention, but their
ability to integrate broad context also makes them prone to incorporating
irrelevant information. Prior work has focused on semantic leakage, bias
introduced by semantically irrelevant context. In this paper, we introduce
expression leakage, a novel phenomenon where LLMs systematically generate
sentimentally charged expressions that are semantically unrelated to the input
context. To analyse the expression leakage, we collect a benchmark dataset
along with a scheme to automatically generate a dataset from free-form text
from common-crawl. In addition, we propose an automatic evaluation pipeline
that correlates well with human judgment, which accelerates the benchmarking by
decoupling from the need of annotation for each analysed model. Our experiments
show that, as the model scales in the parameter space, the expression leakage
reduces within the same LLM family. On the other hand, we demonstrate that
expression leakage mitigation requires specific care during the model building
process, and cannot be mitigated by prompting. In addition, our experiments
indicate that, when negative sentiment is injected in the prompt, it disrupts
the generation process more than the positive sentiment, causing a higher
expression leakage rate.

</details>


### [268] [CultureGuard: Towards Culturally-Aware Dataset and Guard Model for Multilingual Safety Applications](https://arxiv.org/abs/2508.01710)
*Raviraj Joshi,Rakesh Paul,Kanishk Singla,Anusha Kamath,Michael Evans,Katherine Luna,Shaona Ghosh,Utkarsh Vaidya,Eileen Long,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 为解决多语言LLM的安全问题，本研究提出了CultureGuard方法，创建了一个多语言安全数据集和一个安全模型，显著提升了多语言LLM的安全防护能力。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM在代理应用中日益增长，确保内容安全至关重要，尤其是在非英语语言方面，由于缺乏高质量的标注数据集，相关研究滞后。

Method: 提出了一种包括文化数据隔离、文化数据适应、机器翻译和质量过滤在内的四阶段合成数据生成和过滤流程，用于创建多语言安全数据集。

Result: 成功将英文安全数据集扩展到八种语言，创建了包含386,661个样本的多语言数据集，并训练了Llama-3.1-Nemotron-Safety-Guard-Multilingual-8B-v1模型，该模型在多语言内容安全基准测试中取得了最先进的性能。研究还发现，现有的开源LLM在非英语提示下更容易产生不安全的回应。

Conclusion: 该研究通过CultureGuard解决了多语言LLM内容安全问题，并发布了多语言安全数据集和安全模型，显著缩小了多语言LLM的安全差距。

Abstract: The increasing use of Large Language Models (LLMs) in agentic applications
highlights the need for robust safety guard models. While content safety in
English is well-studied, non-English languages lack similar advancements due to
the high cost of collecting culturally aligned labeled datasets. We present
CultureGuard, a novel solution for curating culturally aligned, high-quality
safety datasets across multiple languages. Our approach introduces a four-stage
synthetic data generation and filtering pipeline: cultural data segregation,
cultural data adaptation, machine translation, and quality filtering. This
pipeline enables the conversion and expansion of the
Nemotron-Content-Safety-Dataset-V2 English safety dataset into eight distinct
languages: Arabic, German, Spanish, French, Hindi, Japanese, Thai, and Chinese.
The resulting dataset, Nemotron-Content-Safety-Dataset-Multilingual-v1,
comprises 386,661 samples in 9 languages and facilitates the training of
Llama-3.1-Nemotron-Safety-Guard-Multilingual-8B-v1 via LoRA-based fine-tuning.
The final model achieves state-of-the-art performance on several multilingual
content safety benchmarks. We also benchmark the latest open LLMs on
multilingual safety and observe that these LLMs are more prone to give unsafe
responses when prompted in non-English languages. This work represents a
significant step toward closing the safety gap in multilingual LLMs by enabling
the development of culturally aware safety guard models.

</details>


### [269] [Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction](https://arxiv.org/abs/2508.01739)
*Cheng Wang,ziru Liu,Pengcheng Tang,Mingyu Zhang,Quanyu Dai,Yue Zhu*

Main category: cs.CL

TL;DR: IterChat 框架通过将多轮偏好提取分解为单轮提取过程，并采用新的数据格式和 GPT4 生成数据，解决了获取高质量多轮对话数据的难题，提高了模型性能和注释效率。


<details>
  <summary>Details</summary>
Motivation: 识别对话系统中的用户偏好是提供满意服务的关键。尽管使用大型语言模型（LLM）微调特定任务的偏好提取器在准确性和泛化性方面取得了优异的成果，但获取高质量的标记多轮对话数据却十分困难。准确跟踪跨轮次的用户偏好转变不仅需要注释者具备密集的领域专业知识和上下文一致性维护能力（被称为“注释灾难”），而且由于序列依赖学习中的错误传播，还会使模型训练复杂化。

Method: 提出了一种名为 IterChat 的新对话数据生成框架。首先，构建了一种将对话数据归类为已归属历史偏好和单轮对话的新数据格式，以降低注释错误率并提高注释效率。然后，为了生成高质量、多样化的对话数据集，采用 GPT4 预定义目标偏好提取任务中的偏好槽，并随机采样槽及其对应的模式值来创建对话数据集。

Result: 与原始多轮对话相比，使用新的对话格式进行微调或少样本提示可以获得更好的性能。新的数据格式将注释效率提高了 28.4%。

Conclusion: 实验结果表明，使用新的对话格式进行微调或少样本提示，其性能优于原始多轮对话。此外，新的数据格式提高了注释效率，胜率比原始多轮对话高出 28.4%。

Abstract: Identifying user preferences in dialogue systems is a pivotal aspect of
providing satisfying services. Current research shows that using large language
models (LLMs) to fine-tune a task-specific preference extractor yields
excellent results in terms of accuracy and generalization. However, the primary
challenge stems from the inherent difficulty in obtaining high-quality labeled
multi-turn dialogue data. Accurately tracking user preference transitions
across turns not only demands intensive domain expertise and contextual
consistency maintenance for annotators (termed \textbf{``Annotating
Disaster''}) but also complicates model training due to error propagation in
sequential dependency learning. Inspired by the observation that multi-turn
preference extraction can be decomposed into iterative executions of one-turn
extraction processes. We propose a novel dialogue data generation framework
named \textbf{IterChat}. First, we construct a new data format that categorizes
the dialogue data into attributed historical preferences and one-turn
dialogues. This reduces the probability of annotation errors and improves
annotation efficiency. Then, to generate a high-quality and diverse dialogue
dataset, we adopt GPT4 to pre-define the preference slots in the target
preference extractor task and then randomly sample the subset of the slots and
their corresponding schema values to create the dialogue datasets. Experimental
results indicate that fine-tuning or only few-shot prompting with the new
dialogue format yields superior performance compared to the original multi-turn
dialogues. Additionally, the new data format improves annotator efficiency with
a win rate of 28.4\% higher than the original multi-turn dialogues.

</details>


### [270] [AI-Generated Text is Non-Stationary: Detection via Temporal Tomography](https://arxiv.org/abs/2508.01754)
*Alva West,Yixuan Weng,Minjun Zhu,Luodan Zhang,Zhen Lin,Guangsheng Bao,Yue Zhang*

Main category: cs.CL

TL;DR: AI生成文本具有非平稳性，TDT通过保留位置信息和将检测视为信号处理任务来解决现有方法的局限性，在检测准确性和鲁棒性方面表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成文本检测方法聚合令牌级测量值，忽略了异常发生的位置信息，导致在对抗性扰动下表现不佳。

Method: 提出了一种名为时间差异断层扫描（TDT）的新颖检测范例，它将检测重新表述为信号处理任务，将令牌级差异视为时间序列信号，并应用连续小波变换生成二维时尺度表示，以捕获统计异常的位置和语言尺度。

Result: TDT在RAID基准测试中实现了0.855 AUROC（比最佳基线提高了7.1%），在HART Level 2释义攻击上AUROC提高了14.1%，计算开销仅为13%。

Conclusion: AI生成文本具有显著的非平稳性，保留时间动态对于鲁棒检测至关重要。

Abstract: The field of AI-generated text detection has evolved from supervised
classification to zero-shot statistical analysis. However, current approaches
share a fundamental limitation: they aggregate token-level measurements into
scalar scores, discarding positional information about where anomalies occur.
Our empirical analysis reveals that AI-generated text exhibits significant
non-stationarity, statistical properties vary by 73.8\% more between text
segments compared to human writing. This discovery explains why existing
detectors fail against localized adversarial perturbations that exploit this
overlooked characteristic. We introduce Temporal Discrepancy Tomography (TDT),
a novel detection paradigm that preserves positional information by
reformulating detection as a signal processing task. TDT treats token-level
discrepancies as a time-series signal and applies Continuous Wavelet Transform
to generate a two-dimensional time-scale representation, capturing both the
location and linguistic scale of statistical anomalies. On the RAID benchmark,
TDT achieves 0.855 AUROC (7.1\% improvement over the best baseline). More
importantly, TDT demonstrates robust performance on adversarial tasks, with
14.1\% AUROC improvement on HART Level 2 paraphrasing attacks. Despite its
sophisticated analysis, TDT maintains practical efficiency with only 13\%
computational overhead. Our work establishes non-stationarity as a fundamental
characteristic of AI-generated text and demonstrates that preserving temporal
dynamics is essential for robust detection.

</details>


### [271] [A comprehensive taxonomy of hallucinations in Large Language Models](https://arxiv.org/abs/2508.01781)
*Manuel Cossio*

Main category: cs.CL

TL;DR: LLM 幻觉是一个普遍存在的问题，其根源在于数据、模型和提示。尽管可以通过各种方法进行缓解和检测，但对 LLM 的持续人工监督对于其在关键应用中的负责任部署至关重要。


<details>
  <summary>Details</summary>
Motivation: LLM 易产生幻觉，生成看似合理但事实不正确或虚构的内容，这是一个关键挑战。

Method: 对 LLM 幻觉进行了全面的分类，包括其正式定义、理论框架、内在和外在幻觉之间的区别、事实性和忠实性、具体表现（如事实错误、不一致性、时间错乱、道德违规和特定任务的幻觉）、根本原因（数据、模型和提示相关问题）、影响幻觉感知的认知和人类因素、评估基准和指标，以及缓解策略。

Result: 对 LLM 幻觉进行了全面的分类，涵盖了从理论基础到实际应用和缓解策略的各个方面，强调了其复杂性和多方面性。

Conclusion: 鉴于 LLM 幻觉的理论上不可避免性，未来的工作必须专注于稳健的检测、缓解以及持续的人工监督，以在关键应用中负责任且可靠地部署。

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their propensity for hallucination, generating plausible but factually
incorrect or fabricated content, remains a critical challenge. This report
provides a comprehensive taxonomy of LLM hallucinations, beginning with a
formal definition and a theoretical framework that posits its inherent
inevitability in computable LLMs, irrespective of architecture or training. It
explores core distinctions, differentiating between intrinsic (contradicting
input context) and extrinsic (inconsistent with training data or reality), as
well as factuality (absolute correctness) and faithfulness (adherence to
input). The report then details specific manifestations, including factual
errors, contextual and logical inconsistencies, temporal disorientation,
ethical violations, and task-specific hallucinations across domains like code
generation and multimodal applications. It analyzes the underlying causes,
categorizing them into data-related issues, model-related factors, and
prompt-related influences. Furthermore, the report examines cognitive and human
factors influencing hallucination perception, surveys evaluation benchmarks and
metrics for detection, and outlines architectural and systemic mitigation
strategies. Finally, it introduces web-based resources for monitoring LLM
releases and performance. This report underscores the complex, multifaceted
nature of LLM hallucinations and emphasizes that, given their theoretical
inevitability, future efforts must focus on robust detection, mitigation, and
continuous human oversight for responsible and reliable deployment in critical
applications.

</details>


### [272] [HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark](https://arxiv.org/abs/2508.01812)
*Amir DN Cohen,Hilla Merhav,Yoav Goldberg,Reut Tsarfaty*

Main category: cs.CL

TL;DR: 本研究提出了HeQ数据集，一个用于希伯来语机器阅读理解的基准，解决了该语言丰富的词法结构带来的挑战。研究发现，标准评估指标不适用于希伯来语，并提出了改进建议。此外，模型在词法句法任务和语义任务上的表现存在差异。


<details>
  <summary>Details</summary>
Motivation: 目前的希伯来语自然语言处理基准主要集中在词法句法任务上，忽略了语言理解的语义层面。因此，需要构建一个希伯来语机器阅读理解数据集来弥补这一空白。

Method: 为了应对希伯来语丰富的词法结构带来的挑战，我们设计了一套新的指南、一个受控的众包协议以及修订版的评估指标，这些指标适用于该语言丰富的词法结构。通过这些方法，我们构建了一个包含30,147个问答对的希伯来语机器阅读理解数据集HeQ。

Result: 我们构建了一个名为HeQ的数据集，包含30,147个问答对。研究表明，标准的评估指标（如F1分数和精确匹配度）不适用于希伯来语，并提出了一种改进方法。此外，实验发现模型在词法句法任务和机器阅读理解任务上的表现相关性较低，表明专门用于词法句法任务的模型在语义任务上可能表现不佳。

Conclusion: 目前现有的希伯来语自然语言处理基准主要关注词法句法任务，忽视了语言理解的语义维度。为了弥合这一差距，我们着手构建了一个希伯来语机器阅读理解（MRC）数据集，并将MRC实现为抽取式问答。希伯来语丰富的词法结构带来了挑战：词法复杂形式中的不确定性和边界不透明性会导致注释不一致、分歧以及标准评估指标的缺陷。为弥补此缺陷，我们设计了一套新的指南、一个受控的众包协议以及适用于希伯来语丰富词法结构的修订版评估指标。我们由此产生的基准测试HeQ（希伯来语问答）包含30,147个多样化的问答对，这些问答对来源于希伯来语维基百科文章和以色列科技新闻。我们的实证研究表明，标准评估指标（如F1分数和精确匹配度）不适用于希伯来语（和其他形态丰富的语言），因此我们提出了一种相关改进。此外，我们的实验显示，模型在词法句法任务和机器阅读理解任务上的表现之间相关性较低，这表明为前者设计的模型在语义繁重的任务上表现不佳。HeQ的开发和探索说明了形态丰富的语言在自然语言理解（NLU）方面带来的一些挑战，并促进了面向希伯来语和其他形态丰富的语言的更多、更好的NLU模型的进步。

Abstract: Current benchmarks for Hebrew Natural Language Processing (NLP) focus mainly
on morpho-syntactic tasks, neglecting the semantic dimension of language
understanding. To bridge this gap, we set out to deliver a Hebrew Machine
Reading Comprehension (MRC) dataset, where MRC is to be realized as extractive
Question Answering. The morphologically rich nature of Hebrew poses a challenge
to this endeavor: the indeterminacy and non-transparency of span boundaries in
morphologically complex forms lead to annotation inconsistencies,
disagreements, and flaws in standard evaluation metrics.
  To remedy this, we devise a novel set of guidelines, a controlled
crowdsourcing protocol, and revised evaluation metrics that are suitable for
the morphologically rich nature of the language. Our resulting benchmark, HeQ
(Hebrew QA), features 30,147 diverse question-answer pairs derived from both
Hebrew Wikipedia articles and Israeli tech news. Our empirical investigation
reveals that standard evaluation metrics such as F1 scores and Exact Match (EM)
are not appropriate for Hebrew (and other MRLs), and we propose a relevant
enhancement.
  In addition, our experiments show low correlation between models' performance
on morpho-syntactic tasks and on MRC, which suggests that models designed for
the former might underperform on semantics-heavy tasks. The development and
exploration of HeQ illustrate some of the challenges MRLs pose in natural
language understanding (NLU), fostering progression towards more and better NLU
models for Hebrew and other MRLs.

</details>


### [273] [AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning over Heterogeneous Knowledge Graphs for the Circular Economy](https://arxiv.org/abs/2508.01815)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Tan Chuan Fu,Yue Xiu,Dusit Niyato,Jonathan Z. Low,Eugene Ho Hong Zhuang,Daren Zong Loong Tan*

Main category: cs.CL

TL;DR: AgenticT$^2$S是一个用于异构知识图问答的框架，它使用代理来处理跨多个图的复杂查询，并在循环经济等领域取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到SPARQL方法依赖于大规模特定领域微调或在单个图设置中运行，这限制了它们在低资源领域的泛化能力以及处理跨多个图的查询的能力。这些挑战在循环经济等领域尤为重要，因为分类、流程和排放的信息分布在独立维护的知识图谱（KG）中。

Method: AgenticT$^2$S是一个模块化框架，将KGQA分解为由负责检索、查询生成和验证的专用代理管理的子任务。调度程序使用从弱到强的对齐策略将子目标分配给不同的图。两阶段验证器通过符号验证和反事实一致性检查来检测结构上无效和语义上不明确的查询。

Result: 在真实世界的循环经济KG上的实验表明，AgenticT$^2$S的执行准确性比最佳基线提高了17.3%，三元组级别的F$_1$提高了25.4%，同时平均提示长度减少了46.4%。

Conclusion: AgenticT$^2$S通过基于代理的模式感知推理提高了可扩展KGQA的能力，并通过稳健的跨图推理支持可持续发展领域中的决策制定。

Abstract: Question answering over heterogeneous knowledge graphs (KGQA) involves
reasoning across diverse schemas, incomplete alignments, and distributed data
sources. Existing text-to-SPARQL approaches rely on large-scale domain-specific
fine-tuning or operate within single-graph settings, limiting their
generalizability in low-resource domains and their ability to handle queries
spanning multiple graphs. These challenges are particularly relevant in domains
such as the circular economy, where information about classifications,
processes, and emissions is distributed across independently curated knowledge
graphs (KGs). We present AgenticT$^2$S, a modular framework that decomposes
KGQA into subtasks managed by specialized agents responsible for retrieval,
query generation, and verification. A scheduler assigns subgoals to different
graphs using weak-to-strong alignment strategies. A two-stage verifier detects
structurally invalid and semantically underspecified queries through symbolic
validation and counterfactual consistency checks. Experiments on real-world
circular economy KGs demonstrate that AgenticT$^2$S improves execution accuracy
by 17.3% and triple level F$_1$ by 25.4% over the best baseline, while reducing
the average prompt length by 46.4%. These results demonstrate the benefits of
agent-based schema-aware reasoning for scalable KGQA and support
decision-making in sustainability domains through robust cross-graph reasoning.

</details>


### [274] [MLP Memory: Language Modeling with Retriever-pretrained External Memory](https://arxiv.org/abs/2508.01832)
*Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 该研究提出了一种使用预训练的外部 MLP 记忆来分离 LLM 解码器记忆的方法，以解决幻觉问题并提高性能。该模型在多个基准测试中表现出色，速度更快，并且不会损害推理能力。


<details>
  <summary>Details</summary>
Motivation: 现代仅解码器 LLM 尽管在各种领域表现优越，但在生成的文本中存在普遍的幻觉问题，阻碍了它们在知识密集型任务中的应用。检索器增强生成（RAG）提供了一种解决方案，但检索器的非参数性质阻碍了其与 LLM 的深度交互。

Method: 提出了一种将记忆从 LLM 解码器分离的方法，使用预训练的、可微分的外部记忆。该外部记忆是一个通过模仿检索器在整个预训练数据集上的行为而预训练的 MLP。该模型结合了 Transformer 解码器和分别在语言建模和检索器模仿上预训练的外部 MLP 记忆。

Result: 该模型在 WikiText-103 和 Web 数据集上的表现比仅解码器模型分别提高了 17.5% 和 24.1%。在三个幻觉基准和九个内存密集型任务上表现出优越的性能。与 kNN-LM 相比，实现了 80 倍的加速，推理速度比仅解码器模型快 1.3 倍。并且在 StrategyQA 任务上表现更好。

Conclusion: 该模型在 WikiText-103 和 Web 数据集上比仅解码器模型提高了 17.5% 和 24.1%，并在三个幻觉基准和九个内存密集型任务上表现出卓越的性能。此外，与 kNN-LM 相比，该方法实现了 80 倍的加速，并且推理速度比仅解码器模型快 1.3 倍。与 kNN-LM 不同，该模型提高了 StrategyQA 的性能。

Abstract: While modern decoder-only LLMs achieve superior performance across various
domains, hallucinations have risen to be a common problem in their generated
text, hindering their application in knowledge-intensive tasks.
Retriever-augmented generation (RAG) offers a solution, but the non-parametric
nature of the retriever hinders its deep interaction with LLM. In this work, we
propose to decouple memorization from the LLM decoder using a pretrained,
differentiable external memory. The external memory is an MLP pretrained by
imitating the behavior of a retriever on the entire pretraining dataset. Our
resulting architecture, which comprises a transformer decoder and an external
MLP memory pretrained on language modeling and retriever imitation
respectively, demonstrates strong perplexity and performance on downstream
tasks. Experiments show our architecture exhibits steeper power-law scaling
with model size, achieving 17.5% and 24.1% improvement on WikiText-103 and Web
datasets compared to decoder-only models while benefiting from added training
without overfitting. We demonstrate superior performance on three hallucination
benchmarks and nine memory-intensive tasks. Additionally, our approach delivers
$80\times$ speedup over $k$NN-LM (500M tokens) and $1.3\times$ faster inference
than decoder-only models. Unlike $k$NN-LM, which impairs reasoning, our MLP
memory improves StrategyQA performance. We will open-source our code and models
in the future.

</details>


### [275] [Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents](https://arxiv.org/abs/2508.01858)
*Yuhan Guo,Cong Guo,Aiwen Sun,Hongliang He,Xinyu Yang,Yue Lu,Yingji Zhang,Xuntao Guo,Dong Zhang,Jianzhuang Liu,Jiang Duan,Yijia Xiao,Liangjian Wen,Hai-Ming Xu,Yong Dai*

Main category: cs.CL

TL;DR: 本研究提出Web-CogKnowledge框架和Web-CogDataset，以增强Web代理的知识获取和认知推理能力，并通过Web-CogReasoner在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究认为，Web代理要进行有效的认知推理，必须首先获取足够的知识，因此将Web代理的能力分解为知识内容学习和认知过程两个关键阶段。

Method: 提出Web-CogKnowledge框架，将知识分为事实、概念和程序三类，分别对应于记忆、理解和探索过程。同时，构建了Web-CogDataset用于知识获取，并开发了知识驱动的“思维链”推理框架。

Result: 所提出的Web代理在实验中表现出显著优越性，尤其是在需要结构化知识的未见任务上具有更强的泛化能力。

Conclusion: 通过知识驱动的“思维链”推理框架，提出并训练了Web-CogReasoner，该模型在泛化到需要结构化知识的未见任务方面显著优于现有模型。

Abstract: Multimodal large-scale models have significantly advanced the development of
web agents, enabling perception and interaction with digital environments akin
to human cognition. In this paper, we argue that web agents must first acquire
sufficient knowledge to effectively engage in cognitive reasoning. Therefore,
we decompose a web agent's capabilities into two essential stages: knowledge
content learning and cognitive processes. To formalize this, we propose
Web-CogKnowledge Framework, categorizing knowledge as Factual, Conceptual, and
Procedural. In this framework, knowledge content learning corresponds to the
agent's processes of Memorizing and Understanding, which rely on the first two
knowledge types, representing the "what" of learning. Conversely, cognitive
processes correspond to Exploring, grounded in Procedural knowledge, defining
the "how" of reasoning and action. To facilitate knowledge acquisition, we
construct the Web-CogDataset, a structured resource curated from 14 real-world
websites, designed to systematically instill core knowledge necessary for web
agent. This dataset serves as the agent's conceptual grounding-the "nouns" upon
which comprehension is built-as well as the basis for learning how to reason
and act. Building on this foundation, we operationalize these processes through
a novel knowledge-driven Chain-of-Thought (CoT) reasoning framework, developing
and training our proposed agent, the Web-CogReasoner. Extensive experimentation
reveals its significant superiority over existing models, especially in
generalizing to unseen tasks where structured knowledge is decisive. To enable
rigorous evaluation, we introduce the Web-CogBench, a comprehensive evaluation
suite designed to assess and compare agent performance across the delineated
knowledge domains and cognitive capabilities. Our code and data is open sourced
at https://github.com/Gnonymous/Web-CogReasoner

</details>


### [276] [Counterfactual Probing for Hallucination Detection and Mitigation in Large Language Models](https://arxiv.org/abs/2508.01862)
*Yijun Feng*

Main category: cs.CL

TL;DR: Counterfactual Probing detects and mitigates LLM hallucinations by testing the model's response to plausible but factually incorrect statements, improving accuracy without retraining.


<details>
  <summary>Details</summary>
Motivation: LLMs frequently generate hallucinations outputs that are fluent but factually incorrect or unsupported.

Method: Counterfactual Probing dynamically generates counterfactual statements that appear plausible but contain subtle factual errors, then evaluates the model's sensitivity to these perturbations. Genuine knowledge exhibits robustness to counterfactual variations, while hallucinated content shows inconsistent confidence patterns when confronted with plausible alternatives.

Result: Counterfactual probing achieves superior detection performance compared to baseline methods, and adaptive mitigation strategies reduce hallucination scores by an average of 24.5%.

Conclusion: Counterfactual probing achieves superior detection performance compared to baseline methods, and adaptive mitigation strategies reduce hallucination scores by an average of 24.5%. The approach requires no model retraining and can be integrated into existing LLM pipelines as a realtime verification mechanism.

Abstract: Large Language Models have demonstrated remarkable capabilities across
diverse tasks, yet they frequently generate hallucinations outputs that are
fluent but factually incorrect or unsupported. We propose Counterfactual
Probing, a novel approach for detecting and mitigating hallucinations in LLM
outputs. Our method dynamically generates counterfactual statements that appear
plausible but contain subtle factual errors, then evaluates the model's
sensitivity to these perturbations. We hypothesize that genuine knowledge
exhibits robustness to counterfactual variations, while hallucinated content
shows inconsistent confidence patterns when confronted with plausible
alternatives. Our comprehensive evaluation on TruthfulQA, factual statement
datasets, and curated hallucination examples demonstrates that counterfactual
probing achieves superior detection performance compared to baseline methods,
while our adaptive mitigation strategies reduce hallucination scores by an
average of 24.5%. The approach requires no model retraining and can be
integrated into existing LLM pipelines as a realtime verification mechanism.

</details>


### [277] [Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language](https://arxiv.org/abs/2508.01918)
*Jaskaranjeet Singh,Rakesh Thakur*

Main category: cs.CL

TL;DR: 本文推出了PunGPT2，一套用于旁遮普语的开源大型语言模型，并介绍了Pun-RAG和Pun-Instruct。通过融合稀疏、密集和量子启发式方法，Quantum-RAG在低资源NLP中实现了最先进的检索性能，为低资源语言的NLP发展铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在NLP领域仍然被很大程度上排除在外，因此需要为旁遮普语等语言开发先进的语言模型。

Method: 本文介绍了PunGPT2，一个完全开源的旁遮普语大型语言模型套件，并构建了Pun-RAG（一个结合了PunGPT2和FAISS检索器的检索增强生成框架）以及Pun-Instruct（一个使用QLoRA的参数高效指令调优变体）。关键创新是Quantum-RAG，一个融合稀疏（BM25）和密集方法与量子启发式语义匹配的新型混合检索系统。

Result: PunGPT2模型在困惑度、事实性和流畅性方面显著优于强大的多语言基线模型（mBERT、mT5、MuRIL）。Quantum-RAG实现了更高的上下文相关性，并具有最小的内存开销。

Conclusion: 该研究为低资源语言的LLM能力扩展提供了可扩展、可复现的蓝图，并在低资源NLP中开创了量子感知检索。

Abstract: Despite the rapid advancement of large language models (LLMs), low-resource
languages remain largely excluded from the NLP landscape. We present PunGPT2,
the first fully open-source suite of Punjabi large language models, trained
from scratch on a 35GB domain-diverse corpus encompassing literature, religious
texts, news, and social discourse. Unlike prior multilingual approaches,
PunGPT2 captures rich syntactic and morphological features unique to Punjabi
through a tokenizer optimised with byte pair encoding and linguistically
aligned pretraining objectives. To improve factual grounding and domain recall,
we introduce Pun-RAG, a retrieval-augmented generation framework combining
PunGPT2 with a dense FAISS retriever over a curated Punjabi knowledge base. We
further develop Pun-Instruct, a parameter-efficient, instruction-tuned variant
using QLoRA, enabling robust zero-shot and instruction-following performance
with significantly reduced compute needs.
  As a key innovation, we propose Quantum-RAG, a novel hybrid retrieval system
that fuses sparse (BM25) and dense methods with quantum-inspired semantic
matching. By encoding queries using amplitude-based embeddings and retrieving
via quantum kernel similarity, Quantum-RAG achieves improved contextual
relevance with minimal memory overhead marking the first practical integration
of quantum representations in low-resource language generation. Our models
significantly outperform strong multilingual baselines (mBERT, mT5, MuRIL) in
perplexity, factuality, and fluency. This work provides a scalable,
reproducible blueprint for extending LLM capabilities to underrepresented
languages and pioneers quantum-aware retrieval in low-resource NLP

</details>


### [278] [Word Overuse and Alignment in Large Language Models: The Influence of Learning from Human Feedback](https://arxiv.org/abs/2508.01930)
*Tom S. Juzek,Zina B. Ward*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) are known to overuse certain terms like "delve"
and "intricate." The exact reasons for these lexical choices, however, have
been unclear. Using Meta's Llama model, this study investigates the
contribution of Learning from Human Feedback (LHF), under which we subsume
Reinforcement Learning from Human Feedback and Direct Preference Optimization.
We present a straightforward procedure for detecting the lexical preferences of
LLMs that are potentially LHF-induced. Next, we more conclusively link LHF to
lexical overuse by experimentally emulating the LHF procedure and demonstrating
that participants systematically prefer text variants that include certain
words. This lexical overuse can be seen as a sort of misalignment, though our
study highlights the potential divergence between the lexical expectations of
different populations -- namely LHF workers versus LLM users. Our work
contributes to the growing body of research on explainable artificial
intelligence and emphasizes the importance of both data and procedural
transparency in alignment research.

</details>


### [279] [ROVER: Recursive Reasoning Over Videos with Vision-Language Models for Embodied Tasks](https://arxiv.org/abs/2508.01943)
*Philip Schroeder,Ondrej Biza,Thomas Weng,Hongyin Luo,James Glass*

Main category: cs.CL

TL;DR: ROVER框架通过递归分解长视频，解决了视觉语言模型在长视频推理上的局限性，提高了推理的准确性和效率，并减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在需要对视频帧的扩展序列进行推理时能力受限，这限制了它们在需要从连续视觉输入流中对任务进行推理的具身环境中的应用。

Method: ROVER（Reasoning Over VidEo Recursively）框架，采用一种“在上下文中学习”的方法，通过递归地将长视频轨迹分解为对应于轨迹中较短子任务的段，来解决现有视觉语言模型在长视频推理能力上的局限性。

Result: ROVER在三个视频推理任务上（任务进度估计、帧级自然语言推理和视频问答）的评估中，均优于强基线。ROVER通过减少模型在每个时间步推理的帧数，减少了幻觉，尤其是在轨迹的意外或非最优时刻。此外，ROVER的时间复杂度与视频长度成线性关系，优于基线。

Conclusion: ROVER通过递归地将长视频轨迹分解为对应于轨迹中较短子任务的段，从而解决了现有视觉语言模型在需要对视频帧的扩展序列进行推理时能力受限的问题。这使得模型能够在不丢失全局上下文的情况下，对时间局部化的帧序列进行更专注、更准确的推理。ROVER在任务进度估计、帧级自然语言推理和视频问答这三个视频推理任务上均优于强基线。通过减少模型在每个时间步推理的帧数，ROVER可以减少幻觉，尤其是在轨迹的意外或非最优时刻。此外，通过实现特定于子任务的滑动上下文窗口，ROVER的时间复杂度与视频长度成线性关系，优于基线。

Abstract: Vision-language models (VLMs) have exhibited impressive capabilities across
diverse image understanding tasks, but still struggle in settings that require
reasoning over extended sequences of camera frames from a video. This limits
their utility in embodied settings, which require reasoning over long frame
sequences from a continuous stream of visual input at each moment of a task
attempt. To address this limitation, we propose ROVER (Reasoning Over VidEo
Recursively), a framework that enables the model to recursively decompose
long-horizon video trajectories into segments corresponding to shorter subtasks
within the trajectory. In doing so, ROVER facilitates more focused and accurate
reasoning over temporally localized frame sequences without losing global
context. We evaluate ROVER, implemented using an in-context learning approach,
on diverse OpenX Embodiment videos and on a new dataset derived from RoboCasa
that consists of 543 videos showing both expert and perturbed non-expert
trajectories across 27 robotic manipulation tasks. ROVER outperforms strong
baselines across three video reasoning tasks: task progress estimation,
frame-level natural language reasoning, and video question answering. We
observe that, by reducing the number of frames the model reasons over at each
timestep, ROVER mitigates hallucinations, especially during unexpected or
non-optimal moments of a trajectory. In addition, by enabling the
implementation of a subtask-specific sliding context window, ROVER's time
complexity scales linearly with video length, an asymptotic improvement over
baselines. Demos, code, and data available at: https://rover-vlm.github.io

</details>


### [280] [SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension](https://arxiv.org/abs/2508.01959)
*Junjie Wu,Jiangnan Li,Yuqing Li,Lemao Liu,Liyan Xu,Jiwei Li,Dit-Yan Yeung,Jie Zhou,Mo Yu*

Main category: cs.CL

TL;DR: 为了解决长文档检索中块与块之间的上下文丢失问题，我们提出了SitEmb模型，通过将短文本块的表示与其上下文关联，显著提升了检索性能，并在多个基准测试和语言上取得了优异结果。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在处理长文档时，将文本分割成小块，但会丢失块与块之间的上下文依赖关系，影响检索和下游任务的准确性。长文本块会超出嵌入模型的容量，且实际应用中需要局部证据。

Method: 提出了一种新的表示方法，将短块的表示与其上下文关联起来，并开发了SitEmb（situated embedding models）。

Result: SitEmb-v1模型显著优于现有的大参数嵌入模型，而自身参数量仅为1B。SitEmb-v1.5模型性能提升超过10%，并展现出跨语言和多下游应用的强大能力。

Conclusion: SitEmb-v1.5模型在书本情节检索基准上表现出色，在不同语言和下游应用中均取得了显著成果。

Abstract: Retrieval-augmented generation (RAG) over long documents typically involves
splitting the text into smaller chunks, which serve as the basic units for
retrieval. However, due to dependencies across the original document,
contextual information is often essential for accurately interpreting each
chunk. To address this, prior work has explored encoding longer context windows
to produce embeddings for longer chunks. Despite these efforts, gains in
retrieval and downstream tasks remain limited. This is because (1) longer
chunks strain the capacity of embedding models due to the increased amount of
information they must encode, and (2) many real-world applications still
require returning localized evidence due to constraints on model or human
bandwidth.
  We propose an alternative approach to this challenge by representing short
chunks in a way that is conditioned on a broader context window to enhance
retrieval performance -- i.e., situating a chunk's meaning within its context.
We further show that existing embedding models are not well-equipped to encode
such situated context effectively, and thus introduce a new training paradigm
and develop the situated embedding models (SitEmb). To evaluate our method, we
curate a book-plot retrieval dataset specifically designed to assess situated
retrieval capabilities. On this benchmark, our SitEmb-v1 model based on BGE-M3
substantially outperforms state-of-the-art embedding models, including several
with up to 7-8B parameters, with only 1B parameters. Our 8B SitEmb-v1.5 model
further improves performance by over 10% and shows strong results across
different languages and several downstream applications.

</details>


### [281] [TIBSTC-CoT: A Multi-Domain Instruction Dataset for Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2508.01977)
*Fan Gao,Cheng Huang,Nyima Tashi,Yutong Liu,Xiangxiang Wang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Xiao Feng,Hao Wang,Yongbin Yu*

Main category: cs.CL

TL;DR: 该研究通过链式思考提示自动构建了大规模藏语数据集TIBSTC-CoT，并基于此开发了Sunshine-thinking LLM，其性能可与SOTA多语言LLM媲美，解决了藏语数据稀缺问题，推动了包容性AI发展。


<details>
  <summary>Details</summary>
Motivation: 为了解决藏语（一种少资源语言）严重的数据稀缺问题，以促进该语言的AI处理能力。

Method: 使用大型语言模型的链式思考提示（chain-of-thought prompting）自动构建大规模、多领域藏语数据集TIBSTC-CoT。基于此数据集，开发了具有链式思考能力的藏语中心LLM系列Sunshine-thinking。

Result: 成功构建了大规模藏语数据集TIBSTC-CoT，并开发了Sunshine-thinking LLM家族。该模型在推理和生成方面表现出色，可与最先进的多语言LLM相媲美。

Conclusion: 该研究通过创建大规模藏语数据集TIBSTC-CoT并开发基于此数据集的Sunshine-thinking LLM家族，显著推动了低资源语言（藏语）的AI处理能力，为包容性AI发展做出了贡献。

Abstract: To address the severe data scarcity in Tibetan, a low-resource language
spoken by over six million people, we introduce TIBSTC-CoT, the large-scale,
multi-domain Tibetan dataset automatically constructed via chain-of-thought
prompting with large language models (LLMs). TIBSTC-CoT establishes a scalable
and reproducible framework for dataset creation in low-resource settings,
covering diverse domains and reasoning patterns essential for language
understanding and generation. Building on this dataset, we develop the
Sunshine-thinking LLM family, a series of Tibetan-centric LLMs equipped with
chain-of-thought capabilities. Trained entirely on TIBSTC-CoT,
Sunshine-thinking has demonstrated strong reasoning and generation performance,
comparable to state-of-the-art (SOTA) multilingual LLMs. Our work marks a
significant step toward inclusive AI by enabling high-quality Tibetan language
processing through both resource creation and model innovation. All data are
available: https://github.com/Vicentvankor/sun-shine.

</details>


### [282] [Contextually Aware E-Commerce Product Question Answering using RAG](https://arxiv.org/abs/2508.01990)
*Praveen Tangarajan,Anand A. Rajasekar,Manish Rathi,Vinay Rao Dandin,Ozan Ersoy*

Main category: cs.CL

TL;DR: 提出一个利用RAG的电子商务PQA框架，该框架能深度整合上下文理解，利用对话历史、用户画像和产品属性提供个性化答案，并处理各种查询类型。


<details>
  <summary>Details</summary>
Motivation: 解决现有PQA系统未能有效利用丰富的用户上下文和多样化的产品信息，以及用户在面对海量信息时可能出现的认知过载问题。

Method: 提出一个可扩展、端到端的电子商务PQA框架，使用检索增强生成（RAG）并深度集成上下文理解。

Result: 该系统能利用对话历史、用户画像和产品属性来提供相关和个性化的答案。

Conclusion: 该框架能够处理客观、主观和多意图查询，并识别目录中的信息缺口，以支持持续的内容改进。

Abstract: E-commerce product pages contain a mix of structured specifications,
unstructured reviews, and contextual elements like personalized offers or
regional variants. Although informative, this volume can lead to cognitive
overload, making it difficult for users to quickly and accurately find the
information they need. Existing Product Question Answering (PQA) systems often
fail to utilize rich user context and diverse product information effectively.
We propose a scalable, end-to-end framework for e-commerce PQA using Retrieval
Augmented Generation (RAG) that deeply integrates contextual understanding. Our
system leverages conversational history, user profiles, and product attributes
to deliver relevant and personalized answers. It adeptly handles objective,
subjective, and multi-intent queries across heterogeneous sources, while also
identifying information gaps in the catalog to support ongoing content
improvement. We also introduce novel metrics to measure the framework's
performance which are broadly applicable for RAG system evaluations.

</details>


### [283] [Prompting Large Language Models to Detect Dementia Family Caregivers](https://arxiv.org/abs/2508.01999)
*Md Badsha Biswas,Özlem Uzuner*

Main category: cs.CL

TL;DR: 本研究提出了一种基于LLM的系统，能够准确识别失智症患者照护者的推文，宏观F1分数高达0.95。


<details>
  <summary>Details</summary>
Motivation: 为了开发基于互联网的干预措施，需要识别社交媒体上失智症患者照护者发布的推文。

Method: 探索使用不同的提示方法对大型语言模型（LLMs）进行微调，以解决二元分类问题，识别提及失智症家庭成员的推文。

Result: 研究结果表明，在经过微调的模型上使用简单的零样本提示可以获得最佳效果，在验证集和测试集上均达到了0.95的宏观F1分数。

Conclusion: 该研究成功开发了一个基于LLM的系统，用于识别社交媒体上照护者关于失智症的推文，宏观F1分数达到0.95，并已在GitHub上开源。

Abstract: Social media, such as Twitter, provides opportunities for caregivers of
dementia patients to share their experiences and seek support for a variety of
reasons. Availability of this information online also paves the way for the
development of internet-based interventions in their support. However, for this
purpose, tweets written by caregivers of dementia patients must first be
identified. This paper demonstrates our system for the SMM4H 2025 shared task
3, which focuses on detecting tweets posted by individuals who have a family
member with dementia. The task is outlined as a binary classification problem,
differentiating between tweets that mention dementia in the context of a family
member and those that do not. Our solution to this problem explores large
language models (LLMs) with various prompting methods. Our results show that a
simple zero-shot prompt on a fine-tuned model yielded the best results. Our
final system achieved a macro F1-score of 0.95 on the validation set and the
test set. Our full code is available on GitHub.

</details>


### [284] [SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents](https://arxiv.org/abs/2508.02013)
*Changhao Jiang,Jiajun Sun,Yifei Cao,Jiabao Zhuang,Hui Li,Xiaoran Fan,Ming Zhang,Junjie Ye,Shihan Dou,Zhiheng Xi,Jingqi Tong,Yilong Wu,Baoyu Fan,Zhen Wang,Tao Liang,Zhihui Fei,Mingyang Wan,Guojun Ma,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本研究通过构建SpeechRole-Data数据集和SpeechRole-Eval评估基准，解决了语音角色扮演代理（SRPAs）评估的空白。研究评估了不同模型在语音风格和角色连贯性方面的表现，并公开了相关资源以促进该领域的研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注文本模态的角色扮演，忽视了语音在现实交互场景中的重要性，并且缺乏对语音角色扮演代理（SRPAs）的系统性评估。

Method: 通过构建SpeechRole-Data数据集和SpeechRole-Eval评估基准，并对级联和端到端的语音角色扮演代理进行实验评估。

Result: 实验结果揭示了级联和端到端语音角色扮演代理在保持语音风格一致性和角色连贯性方面的优势和挑战。

Conclusion: 该研究构建了一个大规模、高质量的语音角色扮演数据集（SpeechRole-Data），包含98个不同的角色和112k个基于语音的单轮和多轮对话。同时，提出了一种多维度的评估基准（SpeechRole-Eval），用于系统地评估语音角色扮演代理（SRPAs）在交互能力、语音表现力和角色扮演保真度等方面的性能。实验结果揭示了级联和端到端语音角色扮演代理在保持语音风格一致性和角色连贯性方面的优势和挑战。最后，研究发布了所有数据、代码和基线模型，为面向语音的多模态角色扮演研究奠定了基础，并促进了该领域的进一步发展。

Abstract: Recently, role-playing agents have emerged as a promising paradigm for
achieving personalized interaction and emotional resonance. Existing research
primarily focuses on the textual modality, neglecting the critical dimension of
speech in realistic interactive scenarios. In particular, there is a lack of
systematic evaluation for Speech Role-Playing Agents (SRPAs). To address this
gap, we construct SpeechRole-Data, a large-scale, high-quality dataset that
comprises 98 diverse roles and 112k speech-based single-turn and multi-turn
conversations. Each role demonstrates distinct vocal characteristics, including
timbre and prosody, thereby enabling more sophisticated speech role-playing.
Furthermore, we propose SpeechRole-Eval, a multidimensional evaluation
benchmark that systematically assesses SRPAs performance in key aspects such as
fundamental interaction ability, speech expressiveness, and role-playing
fidelity. Experimental results reveal the advantages and challenges of both
cascaded and end-to-end speech role-playing agents in maintaining vocal style
consistency and role coherence. We release all data, code, and baseline models
to provide a solid foundation for speech-driven multimodal role-playing
research and to foster further developments in this field.

</details>


### [285] [SpeechR: A Benchmark for Speech Reasoning in Large Audio-Language Models](https://arxiv.org/abs/2508.02018)
*Wanqi Yang,Yanda Li,Yunchao Wei,Meng Fang,Ling Chen*

Main category: cs.CL

TL;DR: SpeechR是一个新的基准，用于评估大型音频-语言模型（LALMs）的语音推理能力，发现现有模型即使转录准确率高，推理能力也可能不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型音频-语言模型（LALMs）在评估中主要关注表面感知能力，而对它们在语音场景中进行上下文推理和推断的能力 Examination不足，因此需要一个专门的基准来评估这方面的能力。

Method: SpeechR基准通过三个评估维度（事实检索、程序推理、规范判断）和三种评估形式（选择题、生成式、声学特征）来评估大型音频-语言模型（LALMs）在语音推理方面的能力。

Result: 通过对十一个最先进的LALMs进行评估，我们发现高转录准确性并不一定转化为强大的推理能力。SpeechR基准能够对模型在各种对话任务中的能力进行更有针对性的分析。

Conclusion: 现有的大型音频-语言模型（LALMs）在句子转录和情感识别方面取得了接近人类的性能，但它们在基于语音的推理能力方面仍有待考察。为了解决这一问题，我们提出了SpeechR，一个用于评估LALMs在语音推理方面能力的统一基准。SpeechR从三个关键维度评估模型：事实检索、程序推理和规范判断。该基准包含三种评估形式：选择题、生成式和声学特征，分别用于衡量选择题的准确性、推理链的连贯性和逻辑一致性，以及压力和情感变化对推理能力的影响。对十一个最先进的LALMs的评估表明，高转录准确性并不一定转化为强大的推理能力。SpeechR为评估口语推理能力奠定了结构化基准，能够对模型在各种对话任务中的能力进行更有针对性的分析。

Abstract: Large audio-language models (LALMs) have achieved near-human performance in
sentence-level transcription and emotion recognition. However, existing
evaluations focus mainly on surface-level perception, leaving the capacity of
models for contextual and inference-driven reasoning in speech-based scenarios
insufficiently examined. To address this gap, we introduce SpeechR, a unified
benchmark for evaluating reasoning over speech in large audio-language models.
SpeechR evaluates models along three key dimensions: factual retrieval,
procedural inference, and normative judgment. It includes three distinct
evaluation formats. The multiple-choice version measures answer selection
accuracy. The generative version assesses the coherence and logical consistency
of reasoning chains. The acoustic-feature version investigates whether
variations in stress and emotion affect reasoning performance. Evaluations on
eleven state-of-the-art LALMs reveal that high transcription accuracy does not
translate into strong reasoning capabilities. SpeechR establishes a structured
benchmark for evaluating reasoning in spoken language, enabling more targeted
analysis of model capabilities across diverse dialogue-based tasks.

</details>


### [286] [Diagnosing Memorization in Chain-of-Thought Reasoning, One Token at a Time](https://arxiv.org/abs/2508.02037)
*Huihan Li,You Chen,Siyuan Wang,Yixin He,Ninareh Mehrabi,Rahul Gupta,Xiang Ren*

Main category: cs.CL

TL;DR: STIM 通过识别记忆来源来分析 LLM 的思维链推理，发现局部记忆是导致错误的主要原因。


<details>
  <summary>Details</summary>
Motivation: LLM 在推理方面表现良好，但在输入轻微改变时经常失败，这引发了对其成功在多大程度上依赖于记忆的担忧，尤其是在思维链（CoT）推理中，虚假的记忆模式可能导致中间错误并最终导致不正确的答案。

Method: STIM（Source-aware Token-level Identification of Memorization）框架，通过分析预训练语料库中 token 的统计共现性，将推理链中的每个 token 归因于局部、中等或长距离的记忆来源。

Result: STIM 的 token 级分析表明，模型在复杂或长尾情况下更依赖记忆，局部记忆是导致错误的主要原因，占错误 token 的比例高达 67%。STIM 的记忆分数可以有效预测推理步骤中错误的 token。

Conclusion: STIM 是一个强大的工具，可以诊断和改进模型的推理能力，并且可以推广到其他结构化的、逐步生成的任务。

Abstract: Large Language Models (LLMs) perform well on reasoning benchmarks but often
fail when inputs alter slightly, raising concerns about the extent to which
their success relies on memorization. This issue is especially acute in
Chain-of-Thought (CoT) reasoning, where spurious memorized patterns can trigger
intermediate errors that cascade into incorrect final answers. We introduce
STIM, a novel framework for Source-aware Token-level Identification of
Memorization, which attributes each token in a reasoning chain to one of
multiple memorization sources - local, mid-range, or long-range - based on
their statistical co-occurrence with the token in the pretraining corpus. Our
token-level analysis across tasks and distributional settings reveals that
models rely more on memorization in complex or long-tail cases, and that local
memorization is often the dominant driver of errors, leading to up to 67% of
wrong tokens. We also show that memorization scores from STIM can be effective
in predicting the wrong tokens in the wrong reasoning step. STIM offers a
powerful tool for diagnosing and improving model reasoning and can generalize
to other structured step-wise generation tasks.

</details>


### [287] [Marco-Voice Technical Report](https://arxiv.org/abs/2508.02038)
*Fengping Tian,Chenyang Lyu,Xuanfan Ni,Haoqin Sun,Qingjuan Li,Zhiqiang Qian,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: Marco-Voice是一个集成了语音克隆和情感控制语音合成的多功能系统，通过解耦说话人和情感特征，实现了更自然、可控的语音生成。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在高度表达、可控和自然的语音生成中实现忠实保留说话人身份的长期挑战，并适应不同的语言和情感背景。

Method: 提出了一种有效的说话人-情感解耦机制，并结合了批内对比学习，实现了说话人身份和情感风格的独立操控。此外，还提出了一种旋转式情感嵌入集成方法，用于平滑情感控制。

Result: 该系统在客观和主观指标上均取得了显著的改进。

Conclusion: Marco-Voice在语音清晰度和情感丰富度方面取得了有竞争力的性能，代表了表达性神经语音合成领域的重大进展。

Abstract: This paper presents a multifunctional speech synthesis system that integrates
voice cloning and emotion control speech synthesis within a unified framework.
The goal of this work is to address longstanding challenges in achieving highly
expressive, controllable, and natural speech generation that faithfully
preserves speaker identity across diverse linguistic and emotional contexts.
Our approach introduces an effective speaker-emotion disentanglement mechanism
with in-batch contrastive learning, enabling independent manipulation of
speaker identity and eemotional style, as well as rotational emotional
embedding integration method for smooth emotion control. To support
comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality
emotional speech dataset containing 10 hours of Mandarin speech from six
professional speakers across seven emotional categories. Extensive experiments
demonstrate that our system, Marco-Voice, achieves substantial improvements in
both objective and subjective metrics. Comprehensive evaluations and analysis
were conducted, results show that MarcoVoice delivers competitive performance
in terms of speech clarity and emotional richness, representing a substantial
advance in the field of expressive neural speech synthesis.

</details>


### [288] [Harnessing Temporal Databases for Systematic Evaluation of Factual Time-Sensitive Question-Answering in Large Language Models](https://arxiv.org/abs/2508.02045)
*Soyeon Kim,Jindong Wang,Xing Xie,Steven Euijong Whang*

Main category: cs.CL

TL;DR: TDBench 是一个用于评估时间敏感问答（TSQA）的新基准，它使用时间数据库来创建 TSQA 对，并引入了“时间准确性”指标来评估时间引用。实验表明 TDBench 可以大规模、全面地评估 LLMs 的 TSQA 能力，并减少对人工的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的 TSQA 评估基准存在手动策展或模板化的问题，限制了 TSQA 评估的可扩展性和全面性。LLMs 需要能够准确可靠地处理时序事实知识。

Method: 通过时间数据库和时间 SQL 等数据库技术系统地构建 TSQA 对，并提出了一种名为“时间准确性”的细粒度评估指标，用于评估模型解释中时间引用的有效性以及传统的答案准确性。

Result: 在现有的 LLMs 上进行的大量实验表明，TDBench 能够实现大规模、全面的 TSQA 评估，并减少对人力的依赖。它通过支持在特定应用数据上进行 LLM 评估和无缝的多跳问题生成，为现有的基于 Wikipedia/Wikidata 的 TSQA 评估方法提供了补充。

Conclusion: TDBench 提出了一种利用时间数据库和时间 SQL 等数据库技术来系统地构建 TSQA 对的方法，能够实现大规模、全面的 TSQA 评估，并减少对人力的依赖。提出的时间准确性指标能够更可靠地评估模型解释中时间引用的有效性。

Abstract: Facts evolve over time, making it essential for Large Language Models (LLMs)
to handle time-sensitive factual knowledge accurately and reliably. While
factual Time-Sensitive Question-Answering (TSQA) tasks have been widely
studied, existing benchmarks often rely on manual curation or a small, fixed
set of predefined templates, which restricts scalable and comprehensive TSQA
evaluation. To address these challenges, we propose TDBench, a new benchmark
that systematically constructs TSQA pairs by harnessing temporal databases and
database techniques such as temporal SQL and functional dependencies. We also
introduce a fine-grained evaluation metric called time accuracy, which assesses
the validity of time references in model explanations alongside traditional
answer accuracy to enable a more reliable TSQA evaluation. Extensive
experiments on contemporary LLMs show how \ours{} enables scalable and
comprehensive TSQA evaluation while reducing the reliance on human labor,
complementing existing Wikipedia/Wikidata-based TSQA evaluation approaches by
enabling LLM evaluation on application-specific data and seamless multi-hop
question generation. Code and data are publicly available at:
https://github.com/ssoy0701/tdbench.git.

</details>


### [289] [ProCut: LLM Prompt Compression via Attribution Estimation](https://arxiv.org/abs/2508.02053)
*Zhentao Xu,Fengyi Li,Albert Chen,Xiaofeng Wang*

Main category: cs.CL

TL;DR: ProCut是一种无训练、LLM无关的框架，通过归因分析压缩提示模板，显著减少token数量和成本，同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型工业LLM系统中，提示模板会因为不断加入指令、示例和规则而膨胀，导致难以维护、推理延迟增加和成本升高。

Method: ProCut通过分析提示中各部分对任务性能的影响来压缩提示，将提示模板分割成有意义的单元，量化其效用，并移除低效用的部分。它不依赖于特定的LLM，并且不需要额外的训练。

Result: ProCut在五个公开基准数据集和真实工业提示上进行了广泛实验，结果显示它可以将提示大小减少78%，性能提升高达62%，并且其LLM驱动的归因估计器可以将压缩延迟降低50%以上。

Conclusion: ProCut框架能够显著减少提示模板中的token数量，同时保持甚至提升任务性能，并且易于维护和集成到现有框架中。

Abstract: In large-scale industrial LLM systems, prompt templates often expand to
thousands of tokens as teams iteratively incorporate sections such as task
instructions, few-shot examples, and heuristic rules to enhance robustness and
coverage. This expansion leads to bloated prompts that are difficult to
maintain and incur significant inference latency and serving costs. To address
this, we introduce Prompt Compression via Attribution Estimation (ProCut), a
flexible, LLM-agnostic, training-free framework that compresses prompts through
attribution analysis. ProCut segments prompt templates into semantically
meaningful units, quantifies their impact on task performance, and prunes
low-utility components. Through extensive experiments on five public benchmark
datasets and real-world industrial prompts, we show that ProCut achieves
substantial prompt size reductions (78% fewer tokens in production) while
maintaining or even slightly improving task performance (up to 62% better than
alternative methods). We further introduce an LLM-driven attribution estimator
that reduces compression latency by over 50%, and demonstrate that ProCut
integrates seamlessly with existing prompt-optimization frameworks to produce
concise, high-performing prompts.

</details>


### [290] [The SMeL Test: A simple benchmark for media literacy in language models](https://arxiv.org/abs/2508.02074)
*Gustaf Ahdritz,Anat Kleiman*

Main category: cs.CL

TL;DR: 大语言模型在区分网络信息可靠性方面表现不佳，SMeL测试显示即使是最好的模型也会产生大量幻觉，模型大小并非决定性因素。


<details>
  <summary>Details</summary>
Motivation: 旨在了解大语言模型在自主浏览网页时，学习人类研究者过滤嘈杂网络环境中不可信信息所需的基本启发式方法的程度。

Method: 提出并使用“合成媒体素养测试”（SMeL Test）基准，对包括推理模型在内的多种常用指令微调LLMs进行了评估，测试其主动过滤不可靠信息的能力。

Result: 没有模型能够持续地信任更可靠的来源。虽然推理能力与更高的分数相关，但即使是测试中最好的API模型，其幻觉率也高达70%。值得注意的是，更大、更强的模型不一定优于其较小的模型。

Conclusion: 现有的大语言模型（LLMs）在区分不可靠信息方面表现不佳，即使是经过指令微调和具备推理能力的模型，也存在高达70%的幻觉率。模型的规模和能力与其在区分信息可靠性方面的表现并不完全正相关。

Abstract: The internet is rife with unattributed, deliberately misleading, or otherwise
untrustworthy content. Though large language models (LLMs) are often tasked
with autonomous web browsing, the extent to which they have learned the simple
heuristics human researchers use to navigate this noisy environment is not
currently known. In this paper, we introduce the Synthetic Media Literacy Test
(SMeL Test), a minimal benchmark that tests the ability of language models to
actively filter out untrustworthy information in context. We benchmark a
variety of commonly used instruction-tuned LLMs, including reasoning models,
and find that no model consistently trusts more reliable sources; while
reasoning in particular is associated with higher scores, even the best API
model we test hallucinates up to 70% of the time. Remarkably, larger and more
capable models do not necessarily outperform their smaller counterparts. We
hope our work sheds more light on this important form of hallucination and
guides the development of new methods to combat it.

</details>


### [291] [When Truth Is Overridden: Uncovering the Internal Origins of Sycophancy in Large Language Models](https://arxiv.org/abs/2508.02087)
*Jin Li,Keyu Wang,Shu Yang,Zhuoran Zhang,Di Wang*

Main category: cs.CL

TL;DR: LLMs show sycophancy due to late-layer output shifts and deeper representational divergence, not surface artifacts. First-person prompts increase sycophancy by perturbing deeper layers, while user expertise and authority have little effect.


<details>
  <summary>Details</summary>
Motivation: LLMs often exhibit sycophantic behavior, agreeing with user-stated opinions even when those contradict factual knowledge. Prior work has documented this tendency, but the internal mechanisms remain poorly understood.

Method: Systematically study how user opinions induce sycophancy across different model families, using logit-lens analysis and causal activation patching to identify a two-stage emergence of sycophancy: (1) a late-layer output preference shift and (2) deeper representational divergence. Verify that user authority fails to influence behavior because models do not encode it internally. Examine how grammatical perspective affects sycophantic behavior, finding that first-person prompts induce higher sycophancy rates than third-person framings by creating stronger representational perturbations in deeper layers.

Result: Simple opinion statements reliably induce sycophancy, whereas user expertise framing has a negligible impact. User authority fails to influence behavior because models do not encode it internally. First-person prompts consistently induce higher sycophancy rates than third-person framings.

Conclusion: sycophancy arises from a structural override of learned knowledge in deeper layers, not a surface-level artifact, with implications for alignment and truthful AI systems.

Abstract: Large Language Models (LLMs) often exhibit sycophantic behavior, agreeing
with user-stated opinions even when those contradict factual knowledge. While
prior work has documented this tendency, the internal mechanisms that enable
such behavior remain poorly understood. In this paper, we provide a mechanistic
account of how sycophancy arises within LLMs. We first systematically study how
user opinions induce sycophancy across different model families. We find that
simple opinion statements reliably induce sycophancy, whereas user expertise
framing has a negligible impact. Through logit-lens analysis and causal
activation patching, we identify a two-stage emergence of sycophancy: (1) a
late-layer output preference shift and (2) deeper representational divergence.
We also verify that user authority fails to influence behavior because models
do not encode it internally. In addition, we examine how grammatical
perspective affects sycophantic behavior, finding that first-person prompts
(``I believe...'') consistently induce higher sycophancy rates than
third-person framings (``They believe...'') by creating stronger
representational perturbations in deeper layers. These findings highlight that
sycophancy is not a surface-level artifact but emerges from a structural
override of learned knowledge in deeper layers, with implications for alignment
and truthful AI systems.

</details>


### [292] ["Harmless to You, Hurtful to Me!": Investigating the Detection of Toxic Languages Grounded in the Perspective of Youth](https://arxiv.org/abs/2508.02094)
*Yaqiong Li,Peng Zhang,Lin Wang,Hansu Gu,Siyuan Qiao,Ning Gu,Tun Lu*

Main category: cs.CL

TL;DR: 本研究关注成年人认为无害但青少年认为有害的“青年毒性”语言。研究构建了首个中文“青年毒性”数据集，发现语言特征与来源、文本信息相关。将这些信息纳入现有毒性检测模型可提高准确性。


<details>
  <summary>Details</summary>
Motivation: 以往关于社交媒体毒性检测的研究大多集中在成年人的视角，忽略了青年群体对“毒性”内容的独特理解，即在成年人看来无害但在青年看来有毒的语言。为了弥补这一研究空白，本研究旨在探索“青年毒性”语言的特征，并评估现有毒性检测技术对这些语言的检测能力。

Method: 本研究针对中文青年群体，构建了首个“青年毒性”数据集，并进行了广泛的分析，以探究“青年毒性”语言的特征及其可检测性。

Result: 研究结果表明，青年群体对“青年毒性”语言的感知与言语来源和文本特征等情境因素密切相关。将这些元信息整合到当前的毒性检测方法中，能够显著提升检测的准确性。

Conclusion: 本研究首次构建了中文“青年毒性”数据集，并分析了其语言特征。结果表明，青年对“青年毒性”语言的感知与言语来源和文本特征等多种情境因素相关。将这些元信息纳入现有毒性检测方法可显著提高整体准确性。最后，研究为未来以青年为中心的毒性检测提供了见解。

Abstract: Risk perception is subjective, and youth's understanding of toxic content
differs from that of adults. Although previous research has conducted extensive
studies on toxicity detection in social media, the investigation of youth's
unique toxicity, i.e., languages perceived as nontoxic by adults but toxic as
youth, is ignored. To address this gap, we aim to explore: 1) What are the
features of ``youth-toxicity'' languages in social media (RQ1); 2) Can existing
toxicity detection techniques accurately detect these languages (RQ2). For
these questions, we took Chinese youth as the research target, constructed the
first Chinese ``youth-toxicity'' dataset, and then conducted extensive
analysis. Our results suggest that youth's perception of these is associated
with several contextual factors, like the source of an utterance and
text-related features. Incorporating these meta information into current
toxicity detection methods significantly improves accuracy overall. Finally, we
propose several insights into future research on youth-centered toxicity
detection.

</details>


### [293] [Learning Dynamics of Meta-Learning in Small Model Pretraining](https://arxiv.org/abs/2508.02189)
*David Demitri Africa,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 通过结合MAML和子集掩码LM，我们的模型比传统训练更快、更好，并且通过“多样化”和“压缩”阶段提供了可解释的训练动态。


<details>
  <summary>Details</summary>
Motivation: 研究元学习是否能使小型语言模型的预训练不仅更好，而且更具可解释性。

Method: 将一阶MAML与子集掩码LM预训练相结合，生成了四种LLama风格的单解码器模型（11M-570M参数），并在具有多种设置和实际应用的NLP基础任务上进行了评估。

Result: 与传统训练相比，我们的模型（i）在更早（高达1.6倍）达到相同的损失；（ii）在相同的计算量下，多语言通用NER的F1值得到提高；（iii）使训练动态易于阅读：首先网络的表示分散（“多样化”），然后折叠成一个更小的共享子空间（“压缩”）。

Conclusion: 元学习可以使小型语言模型的预训练不仅更好，而且更具可解释性。

Abstract: Large language models are powerful but costly. We ask whether meta-learning
can make the pretraining of small language models not only better but also more
interpretable. We integrate first-order MAML with subset-masked LM pretraining,
producing four LLama-style decoder-only models (11M-570M params), and evaluate
it on a fundamental NLP task with many settings and real-world applications.
Compared with vanilla training, our model (i) reaches the same loss up to 1.6x
sooner, (ii) improves F1 on multilingual Universal NER under equal compute, and
(iii) makes the training dynamics easy to read: first the network's
representations fan out ("diversify") and later they collapse into a smaller,
shared subspace ("compress"). This two-stage shift shows up as a rise-and-fall
in both effective-rank curves and attention-head entropy. The same curves
pinpoint which layers specialise earliest and which later reconverge, giving a
compact, interpretable signature of meta-adaptation. Code, checkpoints and
WandB logs are released.

</details>


### [294] [Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference](https://arxiv.org/abs/2508.02193)
*Yuxuan Song,Zheng Zhang,Cheng Luo,Pengyang Gao,Fan Xia,Hao Luo,Zheng Li,Yuehang Yang,Hongli Yu,Xingwei Qu,Yuwei Fu,Jing Su,Ge Zhang,Wenhao Huang,Mingxuan Wang,Lin Yan,Xiaoying Jia,Jingjing Liu,Wei-Ying Ma,Ya-Qin Zhang,Yonghui Wu,Hao Zhou*

Main category: cs.CL

TL;DR: Seed Diffusion Preview 是一種新的、快速的語言模型，它在代碼生成任務上達到了最優的速度和質量。


<details>
  <summary>Details</summary>
Motivation: 為了解決傳統逐個令牌解碼的固有延遲問題，同時保持對標準代碼評估基準的競爭力性能。

Method: Seed Diffusion Preview 是一種基於離散狀態擴散的大規模語言模型，利用非順序、並行生成來實現快速推理。

Result: Seed Diffusion Preview 在 H20 GPU 上實現了 2,146 token/s 的推理速度，速度明顯優於 Mercury 和 Gemini Diffusion。

Conclusion: Seed Diffusion Preview在速度-質量權衡曲面上為代碼模型樹立了新的最優水平。

Abstract: We present Seed Diffusion Preview, a large-scale language model based on
discrete-state diffusion, offering remarkably fast inference speed. Thanks to
non-sequential, parallel generation, discrete diffusion models provide a
notable speedup to mitigate the inherent latency of token-by-token decoding, as
demonstrated recently (e.g., Mercury Coder, Gemini Diffusion). Seed Diffusion
Preview achieves an inference speed of 2,146 token/s over H20 GPUs while
maintaining competitive performance across a sweep of standard code evaluation
benchmarks, significantly faster than contemporary Mercury and Gemini
Diffusion, establishing new state of the art on the speed-quality Pareto
frontier for code models.

</details>


### [295] [Proof2Hybrid: Automatic Mathematical Benchmark Synthesis for Proof-Centric Problems](https://arxiv.org/abs/2508.02208)
*Yebo Peng,Zixiang Liu,Yaoming Li,Zhizhuo Yang,Xinye Xu,Bowen Ye,Weijun Yuan,Zihan Wang,Tong Yang*

Main category: cs.CL

TL;DR: 提出Proof2Hybrid框架，利用Proof2X将数学证明转化为混合格式问题，以自动评估大型语言模型（LLM）的数学能力，并推出了AlgGeoTest基准，揭示了LLM在代数几何方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估LLM的数学能力方面存在不足，尤其是在以证明为中心的问题上，因为手动创建成本高昂且难以扩展，导致LLM的真实数学能力在很大程度上未得到评估。

Method: 提出Proof2Hybrid框架，该框架利用Proof2X将自然语言数学语料库中的数学证明转化为各种易于验证的问题，特别是"m选n"多判问题，以实现稳健的自动评估。

Result: 介绍了AlgGeoTest基准，该基准包含456个代数几何领域的挑战性项目，并通过在最先进的LLM上进行的大量评估揭示了它们在理解代数几何方面的严重不足，从而更精确地衡量了它们的真实数学能力。

Conclusion: 该框架和基准测试为深入研究人工智能系统的数学智能开辟了新途径。

Abstract: Evaluating the mathematical capability of Large Language Models (LLMs) is a
critical yet challenging frontier. Existing benchmarks fall short, particularly
for proof-centric problems, as manual creation is unscalable and costly,
leaving the true mathematical abilities of LLMs largely unassessed. To overcome
these barriers, we propose Proof2Hybrid, the first fully automated framework
that synthesizes high-quality, proof-centric benchmarks from natural language
mathematical corpora. The key novelty of our solution is Proof2X, a roadmap of
converting mathematical proofs into various kinds of questions that are easy to
verify. Instructed by this roadmap, we propose a new type of hybrid-formatted
questions, named ``$m$-out-of-$n$ multiple judge questions'', specifically
designed to enable robust, automatic evaluation while being resilient to
guessing and superficial pattern matching inherent in traditional formats. As a
demonstration of our framework, we introduce AlgGeoTest, a benchmark for
algebraic geometry--a frontier domain of modern mathematics--comprising 456
challenging items. Our extensive evaluations on state-of-the-art LLMs using
AlgGeoTest reveal profound deficits in their comprehension of algebraic
geometry, providing a more precise measure of their true mathematical
capabilities. Our framework and benchmark pave the way for a new wave of
in-depth research into the mathematical intelligence of AI systems.

</details>


### [296] [Isolating Culture Neurons in Multilingual Large Language Models](https://arxiv.org/abs/2508.02241)
*Danial Namazifard,Lukas Galke*

Main category: cs.CL

TL;DR: 该研究通过扩展识别语言特异性神经元的方法，定位和分离了多语言大型语言模型（LLM）中的文化特异性神经元。研究人员引入了一个包含超过8500万个词元的数据集（MUREL），涵盖六种不同文化。实验结果表明，LLM在模型上层将不同文化编码在不同的神经元群体中，并且这些文化神经元可以独立于语言神经元或其他文化神经元进行调控。这为在LLM中选择性地分离和编辑文化知识以促进公平、包容和对齐提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 探究多语言大型语言模型如何在不同层面和位置编码文化信息，以及这些文化信息与语言信息的相互作用。

Method: 通过扩展已建立的识别语言特异性神经元的方法，对多语言大型语言模型中的文化特异性神经元进行定位和分离，并仔细区分其与语言特异性神经元的重叠和相互作用。实验采用了 "MUREL" 数据集，该数据集包含 8520 万个跨越六种不同文化的词元。

Result: 实验表明，大型语言模型中的不同文化信息由不同的神经元群体编码，主要位于模型的上层。这些文化神经元可以独立于语言神经元或其他文化的神经元进行调节。 存在语言和文化特异性神经元，并且它们之间的重叠有限。

Conclusion: LLMs在不同神经元群体中编码不同的文化，主要在上层，并且这些文化神经元可以独立于语言特异性神经元或其他文化的神经元进行调制。这表明，多语言语言模型中的文化知识和倾向可以被选择性地分离和编辑，从而促进公平、包容和对齐。

Abstract: Language and culture are deeply intertwined, yet it is so far unclear how and
where multilingual large language models encode culture. Here, we extend upon
an established methodology for identifying language-specific neurons and extend
it to localize and isolate culture-specific neurons, carefully disentangling
their overlap and interaction with language-specific neurons. To facilitate our
experiments, we introduce MUREL, a curated dataset of 85.2 million tokens
spanning six different cultures. Our localization and intervention experiments
show that LLMs encode different cultures in distinct neuron populations,
predominantly in upper layers, and that these culture neurons can be modulated
independently from language-specific neurons or those specific to other
cultures. These findings suggest that cultural knowledge and propensities in
multilingual language models can be selectively isolated and edited - promoting
fairness, inclusivity, and alignment. Code and data is available at
https://github.com/namazifard/Culture_Neurons .

</details>


### [297] [Interference Matrix: Quantifying Cross-Lingual Interference in Transformer Encoders](https://arxiv.org/abs/2508.02256)
*Belen Alastruey,João Maria Janeiro,Alexandre Allauzen,Maha Elbayad,Loïc Barrault,Marta R. Costa-jussà*

Main category: cs.CL

TL;DR: 本研究量化了83种语言中Transformer模型的跨语言干扰，发现干扰与书写系统相关，并开发了一个可预测模型性能的干扰矩阵。


<details>
  <summary>Details</summary>
Motivation: 对83种语言的Encoder-only Transformer模型中的语言干扰进行全面研究。

Method: 通过训练和评估小型类似BERT的模型在所有可能的语言对上，构建干扰矩阵，大规模量化跨语言干扰。

Result: 语言间的干扰是非对称的，其模式与书写系统相关，并且干扰矩阵能有效预测下游任务的表现。

Conclusion: 语言间的干扰是对称的，其模式与传统的语言学特征（如语系或嵌入相似性）不符，而与书写系统更相关。此外，干扰矩阵可以有效地预测下游任务的表现，为设计多语言模型提供工具。

Abstract: In this paper, we present a comprehensive study of language interference in
encoder-only Transformer models across 83 languages. We construct an
interference matrix by training and evaluating small BERT-like models on all
possible language pairs, providing a large-scale quantification of
cross-lingual interference. Our analysis reveals that interference between
languages is asymmetrical and that its patterns do not align with traditional
linguistic characteristics, such as language family, nor with proxies like
embedding similarity, but instead better relate to script. Finally, we
demonstrate that the interference matrix effectively predicts performance on
downstream tasks, serving as a tool to better design multilingual models to
obtain optimal performance.

</details>


### [298] [Decomposing the Entropy-Performance Exchange: The Missing Keys to Unlocking Effective Reinforcement Learning](https://arxiv.org/abs/2508.02260)
*Jia Deng,Jie Chen,Zhipeng Chen,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

TL;DR: RLVR enhances LLMs, but its entropy-performance exchange is not fully understood. This paper analyzes this exchange in different training stages and granularities, finding that early entropy reduction boosts reasoning and later high-entropy tokens in specific samples improve learning. New methods using perplexity and position enhance RL updates for better LLM performance.


<details>
  <summary>Details</summary>
Motivation: The motivation was to address the limited understanding of when and how the entropy-performance exchange in RLVR operates most effectively, despite its importance for enhancing LLM reasoning abilities.

Method: A systematic empirical analysis of the entropy-performance exchange mechanism in RLVR was conducted. The training process was divided into two stages: rising and plateau, based on entropy dynamics. The mechanism was investigated across stage-level, instance-level, and token-level granularities. Two new methods were proposed that dynamically adjust the reward signal using perplexity and positional information.

Result: The analysis revealed that in the rising stage, entropy reduction in negative samples aids the learning of effective reasoning patterns, leading to rapid performance gains. In the plateau stage, learning efficiency is strongly correlated with high-entropy tokens in low-perplexity samples and those at the end of sequences. The proposed methods achieved improvements compared to baseline methods on various LLMs.

Conclusion: The study systematically analyzed the entropy-performance exchange in RLVR, dividing the training process into rising and plateau stages. Findings indicate that entropy reduction in negative samples aids reasoning patterns in the rising stage, while high-entropy tokens in low-perplexity, end-of-sequence samples are crucial for learning efficiency in the plateau stage. Based on this, two methods were proposed to dynamically adjust reward signals using perplexity and positional information, improving performance on various LLMs compared to baseline methods.

Abstract: Recently, reinforcement learning with verifiable rewards (RLVR) has been
widely used for enhancing the reasoning abilities of large language models
(LLMs). A core challenge in RLVR involves managing the exchange between entropy
and performance of policies. Despite the importance of this exchange, a
fine-grained understanding of when and how this exchange operates most
effectively remains limited. To bridge this gap, we conduct a systematic
empirical analysis of the entropy-performance exchange mechanism of RLVR across
different levels of granularity. Specifically, we first divide the training
process into two distinct stages based on entropy dynamics, i.e., rising stage
and plateau stage, and then systematically investigate how this mechanism
varies across stage-level, instance-level, and token-level granularitiess. Our
analysis reveals that, in the rising stage, entropy reduction in negative
samples facilitates the learning of effective reasoning patterns, which in turn
drives rapid performance gains. Moreover, in the plateau stage, learning
efficiency strongly correlates with high-entropy tokens present in
low-perplexity samples and those located at the end of sequences. Motivated by
these findings, we propose two methods that dynamically adjust the reward
signal using perplexity and positional information to focus RL updates on
tokens that exhibit high learning potential, achieving improvements compared to
the baseline methods on various LLMs.

</details>


### [299] [SHAMI-MT: A Syrian Arabic Dialect to Modern Standard Arabic Bidirectional Machine Translation System](https://arxiv.org/abs/2508.02268)
*Serry Sibaee,Omer Nacar,Yasser Al-Habashi,Adel Ammar,Wadii Boulila*

Main category: cs.CL

TL;DR: 开发了一个名为SHAMI-MT的翻译系统，用于现代标准阿拉伯语和叙利亚方言之间的互译。该系统基于AraT5v2架构，在Nabra数据集上进行了微调，并在MADAR语料库上进行了评估。MSA到Shami的翻译质量得到了GPT-4.1的高度评价（4.01/5.0）。


<details>
  <summary>Details</summary>
Motivation: 解决现代标准阿拉伯语（MSA）和日常使用的阿拉伯语方言（特别是叙利亚方言）之间的数字鸿沟，以促进自然语言处理，特别是机器翻译。

Method: 使用AraT5v2-base-1024架构，针对MSA到Shami和Shami到MSA翻译分别训练了两个专门的模型。使用Nabra数据集对模型进行微调，并使用MADAR语料库的未见过数据进行严格评估。

Result: MSA到Shami的翻译模型在GPT-4.1的评估中达到了4.01/5.0的平均质量分数，证明了其生成准确且符合方言的翻译的能力。

Conclusion: 这项工作提供了一个关键的高保真工具，用于之前服务不足的语言对，推动了方言阿拉伯语翻译领域的发展，并在内容本地化、文化遗产和跨文化交流方面提供了重要的应用。

Abstract: The rich linguistic landscape of the Arab world is characterized by a
significant gap between Modern Standard Arabic (MSA), the language of formal
communication, and the diverse regional dialects used in everyday life. This
diglossia presents a formidable challenge for natural language processing,
particularly machine translation. This paper introduces \textbf{SHAMI-MT}, a
bidirectional machine translation system specifically engineered to bridge the
communication gap between MSA and the Syrian dialect. We present two
specialized models, one for MSA-to-Shami and another for Shami-to-MSA
translation, both built upon the state-of-the-art AraT5v2-base-1024
architecture. The models were fine-tuned on the comprehensive Nabra dataset and
rigorously evaluated on unseen data from the MADAR corpus. Our MSA-to-Shami
model achieved an outstanding average quality score of \textbf{4.01 out of 5.0}
when judged by OPENAI model GPT-4.1, demonstrating its ability to produce
translations that are not only accurate but also dialectally authentic. This
work provides a crucial, high-fidelity tool for a previously underserved
language pair, advancing the field of dialectal Arabic translation and offering
significant applications in content localization, cultural heritage, and
intercultural communication.

</details>


### [300] [Dynaword: From One-shot to Continuously Developed Datasets](https://arxiv.org/abs/2508.02271)
*Kenneth Enevoldsen,Kristian Nørgaard Jensen,Jan Kostkan,Balázs Szabó,Márton Kardos,Kirten Vad,Andrea Blasi Núñez,Gianluca Barmina,Jacob Nielsen,Rasmus Larsen,Peter Vahlstrup,Per Møldrup Dalum,Desmond Elliott,Lukas Galke,Peter Schneider-Kamp,Kristoffer Nielbo*

Main category: cs.CL

TL;DR: 为了解决当前大规模数据集在授权、更新和质量保证方面的限制，我们提出了 Dynaword 方法和一个名为 Danish Dynaword 的具体实现。Danish Dynaword 规模更大、授权更开放，并得到了社区的积极贡献，展示了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大规模数据集在授权、更新和质量保证方面存在挑战，限制了其使用、共享和发展。

Method: 提出 Dynaword 方法，一个允许通过社区协作持续更新大规模开放数据集的框架，并发布了 Danish Dynaword 作为具体实现。

Result: Danish Dynaword 包含的 token 数量是同类发布版本的四倍以上，全部采用开放授权，并获得了来自工业界和研究界的多次贡献。该存储库包含轻量级测试以确保数据格式、质量和文档，为持续的社区贡献和数据集演进建立了可持续的框架。

Conclusion: Dynaword 方法和 Danish Dynaword 的发布解决了当前大规模数据集面临的依赖模糊授权来源、静态发布和质量保证流程受限等问题，为创建可公开访问、持续更新且经过社区验证的大规模数据集提供了可持续的框架。

Abstract: Large-scale datasets are foundational for research and development in natural
language processing. However, current approaches face three key challenges: (1)
reliance on ambiguously licensed sources restricting use, sharing, and
derivative works; (2) static dataset releases that prevent community
contributions and diminish longevity; and (3) quality assurance processes
restricted to publishing teams rather than leveraging community expertise.
  To address these limitations, we introduce two contributions: the Dynaword
approach and Danish Dynaword. The Dynaword approach is a framework for creating
large-scale, open datasets that can be continuously updated through community
collaboration. Danish Dynaword is a concrete implementation that validates this
approach and demonstrates its potential. Danish Dynaword contains over four
times as many tokens as comparable releases, is exclusively openly licensed,
and has received multiple contributions across industry and research. The
repository includes light-weight tests to ensure data formatting, quality, and
documentation, establishing a sustainable framework for ongoing community
contributions and dataset evolution.

</details>


### [301] [A French Version of the OLDI Seed Corpus](https://arxiv.org/abs/2508.02290)
*Malik Marmonier,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 我们创建了一个法语语料库，该语料库具有技术性和用户生成内容的混合特征，旨在帮助收集资源匮乏的法国地区语言的平行语料库。


<details>
  <summary>Details</summary>
Motivation: 介绍OLDI Seed语料库的法语划分，这是WMT 2025开放语言数据倡议（OLDI）共享任务的提交内容。

Method: 通过使用多种机器翻译系统和自定义的后期编辑界面创建，由合格的母语者进行后期编辑。

Result: 创建了一个法语语料库，其中包含技术术语和用户生成内容的风格不规则性。

Conclusion: 该法语语料库旨在促进面向资源匮乏的法国地区语言的平行语料库的收集。

Abstract: We present the first French partition of the OLDI Seed Corpus, our submission
to the WMT 2025 Open Language Data Initiative (OLDI) shared task. We detail its
creation process, which involved using multiple machine translation systems and
a custom-built interface for post-editing by qualified native speakers. We also
highlight the unique translation challenges presented by the source data, which
combines highly technical, encyclopedic terminology with the stylistic
irregularities characteristic of user-generated content taken from Wikipedia.
This French corpus is not an end in itself, but is intended as a crucial pivot
resource to facilitate the collection of parallel corpora for the
under-resourced regional languages of France.

</details>


### [302] [Simple Methods Defend RAG Systems Well Against Real-World Attacks](https://arxiv.org/abs/2508.02296)
*Ilias Triantafyllopoulos,Renyi Qu,Salvatore Giorgi,Brenda Curtis,Lyle H. Ungar,João Sedoc*

Main category: cs.CL

TL;DR: Evaluating OOD detection methods (GPT-4o, regression, PCA, NC) and novel strategies (PCA, Neural Collapse) for RAG systems, we found an external OOD detector is vital for response relevance, especially against attacks.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of ensuring safety and in-domain responses for Retrieval-Augmented Generation (RAG) systems in safety-critical applications.

Method: Evaluate four OOD detection methodologies: GPT-4o, regression-based, PCA-based, and NC. Explore two novel dimensionality reduction and feature separation strategies: PCA (using explained variance or OOD separability) and Neural Collapse Feature Separation. Validate on StackExchange, MSMARCO, Substance Use, and COVID-19 datasets, including tests against simulated and actual attacks on a COVID-19 vaccine chatbot.

Result: An external OOD detector is crucial for maintaining response relevance in RAG systems.

Conclusion: Ensure RAG systems only respond to queries within their knowledge base by using an external OOD detector to maintain response relevance.

Abstract: Ensuring safety and in-domain responses for Retrieval-Augmented Generation
(RAG) systems is paramount in safety-critical applications, yet remains a
significant challenge. To address this, we evaluate four methodologies for
Out-Of-Domain (OOD) query detection: GPT-4o, regression-based, Principal
Component Analysis (PCA)-based, and Neural Collapse (NC), to ensure the RAG
system only responds to queries confined to the system's knowledge base.
Specifically, our evaluation explores two novel dimensionality reduction and
feature separation strategies: \textit{PCA}, where top components are selected
using explained variance or OOD separability, and an adaptation of
\textit{Neural Collapse Feature Separation}. We validate our approach on
standard datasets (StackExchange and MSMARCO) and real-world applications
(Substance Use and COVID-19), including tests against LLM-simulated and actual
attacks on a COVID-19 vaccine chatbot. Through human and LLM-based evaluations
of response correctness and relevance, we confirm that an external OOD detector
is crucial for maintaining response relevance.

</details>


### [303] [LaMPE: Length-aware Multi-grained Position Encoding for Adaptive Long-context Scaling Without Training](https://arxiv.org/abs/2508.02308)
*Sikui Zhang,Guangze Gao,Ziyun Gan,Chunfeng Yuan,Zefeng Lin,Houwen Peng,Bing Li,Weiming Hu*

Main category: cs.CL

TL;DR: LaMPE 是一种新颖的、训练无关的长度感知多粒度位置编码方法，用于扩展 LLM 的上下文窗口，通过动态调整位置映射和多粒度注意力机制，在不进行微调的情况下显著提高了 LLM 在长文本处理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决 LLM 输入超出预训练上下文窗口时，由于 RoPE 的分布外行为导致的性能下降问题，并克服现有方法忽略输入长度与模型有效上下文窗口之间动态关系的局限性。

Method: LaMPE 通过参数化缩放的 Sigmoid 函数动态地学习映射长度和输入长度之间的关系，以适应不同输入长度的位置容量。同时，LaMPE 设计了一种新颖的多粒度注意力机制，以策略性地分配不同序列区域的位置分辨率。

Result: LaMPE 在三个代表性的 LLM 和五个主流长上下文基准测试上进行了广泛的实验，结果表明 LaMPE 相较于现有的长度外插方法能够实现显著的性能提升。

Conclusion: LaMPE 是一种训练无关的方法，可以无缝应用于各种基于 RoPE 的 LLM，并在五个主流长上下文基准测试中实现了显著的性能提升。

Abstract: Large language models (LLMs) experience significant performance degradation
when the input exceeds the pretraining context window, primarily due to the
out-of-distribution (OOD) behavior of Rotary Position Embedding (RoPE). Recent
studies mitigate this problem by remapping OOD positions into the
in-distribution range with fixed mapping strategies, ignoring the dynamic
relationship between input length and the model's effective context window. To
this end, we propose Length-aware Multi-grained Positional Encoding (LaMPE), a
training-free method that fully utilizes the model's effective context window
for adaptive long-context scaling in LLMs. Motivated by the left-skewed
frequency distribution of relative positions, LaMPE establishes a dynamic
relationship between mapping length and input length through a parametric
scaled sigmoid function to adaptively allocate positional capacity across
varying input lengths. Meanwhile, LaMPE devises a novel multi-grained attention
mechanism that strategically allocates positional resolution across different
sequence regions to capture both fine-grained locality and long-range
dependencies. Our method can be seamlessly applied to a wide range of
RoPE-based LLMs without training. Extensive experiments on three representative
LLMs across five mainstream long-context benchmarks demonstrate that LaMPE
achieves significant performance improvements compared to existing length
extrapolation methods. The code will be released at
https://github.com/scar-on/LaMPE.

</details>


### [304] [CAMERA: Multi-Matrix Joint Compression for MoE Models via Micro-Expert Redundancy Analysis](https://arxiv.org/abs/2508.02322)
*Yuzhuang Xu,Xu Han,Yuanchi Zhang,Yixuan Wang,Yijun Liu,Shiyu Ji,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: This paper introduces micro-experts for compressing large MoE models, proposing CAMERA (a framework for identifying redundancy) with pruning (CAMERA-P) and quantization (CAMERA-Q) methods. These methods improve efficiency and performance, outperforming existing techniques, and are very fast to implement.


<details>
  <summary>Details</summary>
Motivation: Mixture-of-Experts (MoE) models offer strong performance but suffer from high computational and storage overheads, with performance gains not scaling proportionally with parameter growth. Existing methods for parameter reduction face challenges in performance and efficiency. This work aims to address these issues by proposing a finer-grained compression approach.

Method: This paper introduces micro-experts as a finer-grained compression unit for MoE models. It proposes CAMERA, a training-free framework for identifying micro-expert redundancy by analyzing the variance in micro-expert contributions during decoding. Based on this, CAMERA-P is developed for structured micro-expert pruning, and CAMERA-Q is proposed for mixed-precision quantization of micro-experts.

Result: Experiments show CAMERA-P consistently outperforms strong baselines under 20-60% pruning ratios. CAMERA-Q achieves superior results under 2-bit quantization, surpassing existing matrix- and channel-level methods. The analysis of Qwen2-57B-A14B using this method takes less than 5 minutes on a single A100 GPU.

Conclusion: The proposed CAMERA framework, including pruning (CAMERA-P) and quantization (CAMERA-Q) methods based on micro-experts, demonstrates significant improvements in both performance and computational efficiency for Mixture-of-Experts (MoE) models. CAMERA-P outperforms baselines in reducing parameters, while CAMERA-Q achieves superior results under aggressive quantization. The framework is also highly efficient, enabling analysis of large models in minutes.

Abstract: Large Language Models (LLMs) with Mixture-of-Experts (MoE) architectures are
distinguished by their strong performance scaling with increasing parameters
across a wide range of tasks, yet they also suffer from substantial
computational and storage overheads. Notably, the performance gains of MoE
models do not scale proportionally with the growth in expert parameters. While
prior works attempt to reduce parameters via expert-level pruning, merging, or
decomposition, they still suffer from challenges in both performance and
computational efficiency. In this paper, we address these challenges by
introducing micro-expert as a finer-grained compression unit that spans across
matrices. We first establish a more fundamental perspective, viewing MoE layers
as mixtures of micro-experts, and present CAMERA, a lightweight and
training-free framework for identifying micro-expert redundancy. Our analysis
uncovers significant variance in micro-expert contributions during decoding.
Based on this insight, we further propose CAMERA-P, a structured micro-expert
pruning framework, and CAMERA-Q, a mixed-precision quantization idea designed
for micro-experts. Extensive experiments on nine downstream tasks show that
CAMERA-P consistently outperforms strong baselines under pruning ratios ranging
from 20% to 60%. Furthermore, CAMERA-Q achieves superior results under
aggressive 2-bit quantization, surpassing existing matrix- and channel-level
ideas. Notably, our method enables complete micro-expert analysis of
Qwen2-57B-A14B in less than 5 minutes on a single NVIDIA A100-40GB GPU.

</details>


### [305] [Understanding and Mitigating Political Stance Cross-topic Generalization in Large Language Models](https://arxiv.org/abs/2508.02360)
*Jiayi Zhang,Shu Yang,Junchao Wu,Derek F. Wong,Di Wang*

Main category: cs.CL

TL;DR: 本研究识别了影响大型语言模型政治立场的两种神经元，并提出了一种名为InhibitFT的微调方法，通过抑制特定神经元，成功将政治微调中的跨话题立场泛化降低了20%。


<details>
  <summary>Details</summary>
Motivation: 为了理解和解决大型语言模型在政治话题微调中出现的跨话题立场泛化问题，即在某一政治话题上的微调会影响模型在不相关话题上的立场，而现有的研究缺乏对其内部机制和表示的深入理解。

Method: 提出了一种名为PNLAC（Political Neuron Localization through Activation Contrasting）的新方法，用于识别通用政治神经元和特定话题政治神经元。在此基础上，引入了一种名为InhibitFT的抑制性微调方法，选择性抑制5%的神经元以减轻跨话题立场泛化。

Result: PNLAC方法在四个模型和数据集上识别出通用政治神经元和特定话题政治神经元。InhibitFT方法平均将跨话题立场泛化降低了20%，并保持了特定话题的性能。实验证明，仅抑制5%的神经元足以有效减轻跨话题立场泛化。

Conclusion: 本研究提出了PNLAC方法，识别出控制跨话题政治立场的通用政治神经元和影响单一话题立场的特定话题神经元，并引入了InhibitFT微调方法，通过抑制特定神经元有效减轻了政治微调中的跨话题立场泛化问题，平均减少了20%的跨话题立场泛化，同时保留了特定话题的性能。

Abstract: Fine-tuning Large Language Models on a political topic will significantly
manipulate their political stance on various issues and unintentionally affect
their stance on unrelated topics. While previous studies have proposed this
issue, there is still a lack of understanding regarding the internal
representations of these stances and the mechanisms that lead to unintended
cross-topic generalization. In this paper, we systematically explore the
internal mechanisms underlying this phenomenon from a neuron-level perspective
and how to mitigate the cross-topic generalization of political fine-tuning.
Firstly, we propose Political Neuron Localization through Activation
Contrasting (PNLAC) to identify two distinct types of political neurons:
general political neurons, which govern stance across multiple political
topics, and topic-specific neurons} that affect the model's political stance on
individual topics. We find the existence of these political neuron types across
four models and datasets through activation patching experiments. Leveraging
these insights, we introduce InhibitFT, an inhibition-based fine-tuning method,
effectively mitigating the cross-topic stance generalization. Experimental
results demonstrate the robustness of identified neuron types across various
models and datasets, and show that InhibitFT significantly reduces the
cross-topic stance generalization by 20% on average, while preserving
topic-specific performance. Moreover, we demonstrate that selectively
inhibiting only 5% of neurons is sufficient to effectively mitigate the
cross-topic stance generalization.

</details>


### [306] [CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important Before Generation](https://arxiv.org/abs/2508.02401)
*Xiaolin Lin,Jingcun Wang,Olga Kondrateva,Yiyu Shi,Bing Li,Grace Li Zhang*

Main category: cs.CL

TL;DR: 本研究提出CompressKV，一种用于LLM的KV缓存压缩新方法，通过识别关键注意力头和逐层自适应分配来优化内存和效率，并在基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）中不断增长的KV缓存大小带来的内存和执行效率挑战，同时避免现有基于启发式标记驱逐的方法因忽略注意力头的功能差异而导致的性能下降问题。

Method: 本研究提出了一种新的KV缓存压缩方法，名为CompressKV。首先，它会识别GQA模型中能够检索初始和最终提示标记、检索文本内重要标记并关注其周围语义上下文的注意力头。然后，利用这些识别出的注意力头来确定重要标记，并保留其相应的KV缓存对。最后，该方法会分析每一层的缓存蒸发错误，并引入一个逐层自适应的KV缓存分配策略。

Result: 实验结果表明，CompressKV在LongBench和Needle-in-a-Haystack基准测试中，在各种内存预算下均优于现有最先进的方法，证明了其在KV缓存压缩方面的有效性。

Conclusion: 本研究提出了一种名为CompressKV的方法，通过识别GQA（Grouped Query Attention）模型中不同注意力头的关键功能，来更有效地压缩KV缓存。该方法能够保留对检索初始/最终/关键内部文本标记以及关注其周围语义上下文至关重要的注意力头及其对应的KV缓存对。此外，研究还引入了逐层自适应的KV缓存分配策略，并根据每个层的缓存蒸发错误进行调整。实验结果表明，CompressKV在LongBench和Needle-in-a-Haystack基准测试中，在各种内存预算下均优于现有最先进的方法。

Abstract: Recent advances in large language models (LLMs) have significantly boosted
long-context processing. However, the increasing key-value (KV) cache size
poses critical challenges to memory and execution efficiency. Most KV cache
compression methods rely on heuristic token eviction using all attention heads
in Grouped Query Attention (GQA)-based LLMs. This method ignores the different
functionalities of attention heads, leading to the eviction of critical tokens
and thus degrades the performance of LLMs.
  To address the issue above, instead of using all the attention heads in
GQA-based LLMs to determine important tokens as in the previous work, we first
identify the attention heads in each layer that are not only capable of
retrieving the initial and final tokens of a prompt, but also capable of
retrieving important tokens within the text and attending to their surrounding
semantic context. Afterwards, we exploit such heads to determine the important
tokens and retain their corresponding KV cache pairs. Furthermore, we analyze
the cache eviction error of each layer individually and introduce a
layer-adaptive KV cache allocation strategy. Experimental results demonstrate
the proposed CompressKV consistently outperforms state-of-the-art approaches
under various memory budgets on LongBench and Needle-in-a-Haystack benchmarks.
Our code is publicly available at: https://github.com/TUDa-HWAI/CompressKV.git.

</details>


### [307] [Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.02426)
*Linyu Li,Zhi Jin,Yuanpeng He,Dongming Jin,Yichi Zhang,Haoran Duan,Nyima Tash*

Main category: cs.CL

TL;DR: BAKE是一种新的CKGE模型，通过贝叶斯更新和持续聚类来解决灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 由于知识图谱（KG）将在实际场景中不断演化，传统的知识图谱嵌入（KGE）模型仅适用于静态知识图谱。因此，持续知识图谱嵌入（CKGE）引起了研究人员的关注。CKGE面临的一个关键挑战是模型容易出现“灾难性遗忘”，导致先前学习的知识丢失。

Method: BAKE将每个新数据批次视为模型先验的贝叶斯更新，并通过约束不同快照之间新旧知识之间的演化差异来进一步直接对抗知识遗忘。

Result: BAKE在多个数据集上进行了广泛的实验，结果表明BAKE的性能显著优于现有的基线模型。

Conclusion: BAKE

Abstract: Since knowledge graphs (KG) will continue to evolve in real scenarios,
traditional KGE models are only suitable for static knowledge graphs.
Therefore, continual knowledge graph embedding (CKGE) has attracted the
attention of researchers. Currently, a key challenge facing CKGE is that the
model is prone to "catastrophic forgetting", resulting in the loss of
previously learned knowledge. In order to effectively alleviate this problem,
we propose a new CKGE model BAKE. First, we note that the Bayesian posterior
update principle provides a natural continual learning strategy that is
insensitive to data order and can theoretically effectively resist the
forgetting of previous knowledge during data evolution. Different from the
existing CKGE method, BAKE regards each batch of new data as a Bayesian update
of the model prior. Under this framework, as long as the posterior distribution
of the model is maintained, the model can better preserve the knowledge of
early snapshots even after evolving through multiple time snapshots. Secondly,
we propose a continual clustering method for CKGE, which further directly
combats knowledge forgetting by constraining the evolution difference (or
change amplitude) between new and old knowledge between different snapshots. We
conduct extensive experiments on BAKE on multiple datasets, and the results
show that BAKE significantly outperforms existing baseline models.

</details>


### [308] [AI-Based Measurement of Innovation: Mapping Expert Insight into Large Language Model Applications](https://arxiv.org/abs/2508.02430)
*Robin Nowak,Patrick Figge,Carolin Haeussler*

Main category: cs.CL

TL;DR: 该研究展示了如何利用大型语言模型（LLM）框架来克服手动专家评估的局限性，从而更有效地衡量创新性。研究通过两个案例研究证明，LLM框架在准确性和一致性方面优于现有方法，并为相关领域的研究者和从业者提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统创新性衡量方法依赖于特定情境的替代指标和专家评估的限制，从而推动实证创新研究在更广泛的设置中的应用。

Method: 设计了一个LLM框架，该框架能够可靠地从非结构化文本数据中近似领域专家对创新性的评估，并通过在软件应用程序更新的创新性和用户生成的产品评论反馈及改进想法的原创性两个不同领域的应用进行了性能和广泛适用性的验证。

Result: LLM框架在F1分数上优于其他方法，并且结果高度一致（即结果不随运行而改变），表明其在创新性衡量任务中具有更高的准确性和可靠性。

Conclusion: LLM框架在衡量创新性方面表现出优越的性能和广泛的适用性，能够克服手动专家评估的限制，为研发人员、研究人员、审稿人和编辑提供了有效利用LLM衡量创新性及其性能的知识和工具。

Abstract: Measuring innovation often relies on context-specific proxies and on expert
evaluation. Hence, empirical innovation research is often limited to settings
where such data is available. We investigate how large language models (LLMs)
can be leveraged to overcome the constraints of manual expert evaluations and
assist researchers in measuring innovation. We design an LLM framework that
reliably approximates domain experts' assessment of innovation from
unstructured text data. We demonstrate the performance and broad applicability
of this framework through two studies in different contexts: (1) the
innovativeness of software application updates and (2) the originality of
user-generated feedback and improvement ideas in product reviews. We compared
the performance (F1-score) and reliability (consistency rate) of our LLM
framework against alternative measures used in prior innovation studies, and to
state-of-the-art machine learning- and deep learning-based models. The LLM
framework achieved higher F1-scores than the other approaches, and its results
are highly consistent (i.e., results do not change across runs). This article
equips R&D personnel in firms, as well as researchers, reviewers, and editors,
with the knowledge and tools to effectively use LLMs for measuring innovation
and evaluating the performance of LLM-based innovation measures. In doing so,
we discuss, the impact of important design decisions-including model selection,
prompt engineering, training data size, training data distribution, and
parameter settings-on performance and reliability. Given the challenges
inherent in using human expert evaluation and existing text-based measures, our
framework has important implications for harnessing LLMs as reliable,
increasingly accessible, and broadly applicable research tools for measuring
innovation.

</details>


### [309] [LatentPrompt: Optimizing Promts in Latent Space](https://arxiv.org/abs/2508.02452)
*Mateusz Bystroński,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.CL

TL;DR: LatentPrompt是一个用于优化LLM提示的自动化框架，通过探索潜在语义空间来提高任务性能，无需手动规则。


<details>
  <summary>Details</summary>
Motivation: 许多提示优化技术依赖于启发式方法或手动探索，LatentPrompt旨在提供一种自动化的方法。

Method: LatentPrompt框架通过将种子提示嵌入连续潜在空间，并系统地探索该空间来识别最大化特定任务性能的提示。

Result: 在金融短语库情感分类基准测试中，LatentPrompt将分类准确率提高了约3%。

Conclusion: LatentPrompt是一个模型无关的框架，可自动生成、评估和优化LLM的提示，无需手动规则，在金融短语库情感分类基准测试中，单次优化周期后准确率提高了约3%。

Abstract: Recent advances have shown that optimizing prompts for Large Language Models
(LLMs) can significantly improve task performance, yet many optimization
techniques rely on heuristics or manual exploration. We present LatentPrompt, a
model-agnostic framework for prompt optimization that leverages latent semantic
space to automatically generate, evaluate, and refine candidate prompts without
requiring hand-crafted rules. Beginning with a set of seed prompts, our method
embeds them in a continuous latent space and systematically explores this space
to identify prompts that maximize task-specific performance. In a
proof-of-concept study on the Financial PhraseBank sentiment classification
benchmark, LatentPrompt increased classification accuracy by approximately 3
percent after a single optimization cycle. The framework is broadly applicable,
requiring only black-box access to an LLM and an automatic evaluation metric,
making it suitable for diverse domains and tasks.

</details>


### [310] [Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity](https://arxiv.org/abs/2508.02498)
*Md Tasin Abir,Arpita Chowdhury,Ashfia Rahman*

Main category: cs.CL

TL;DR: 本研究探讨了Facebook在2024年孟加拉国季风起义期间如何通过视觉和语言策略（如红色象征、“Razakar”的反讽用法和抵抗的视觉图像）的结合来塑造集体身份和动员公众情绪。


<details>
  <summary>Details</summary>
Motivation: 本研究调查了Facebook在2024年7月孟加拉国亲民主起义（被称为“季风起义”）期间如何塑造集体身份。

Method: 本研究采用定性方法，分析了视觉修辞、语言表达和数字反讽，以揭示共享符号、抗议艺术和口号如何建立团结感。

Result: 研究发现，关键要素包括红色的象征性使用、“Razakar”一词的比喻性反讽用法，以及代表勇气、不公和抵抗的视觉图像的广泛传播。

Conclusion: 本研究表明，Facebook上的视觉和语言策略相结合，不仅动员了公众情绪，而且建立了强大的集体身份，挑战了威权叙事。本研究旨在证明在线平台如何在数字时代成为构建身份和政治动员的有力工具。

Abstract: This study investigates how Facebook shaped collective identity during the
July 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising.
During government repression, protesters turned to Facebook as a central space
for resistance, where multimodal expressions, images, memes, videos, hashtags,
and satirical posts played an important role in unifying participants. Using a
qualitative approach, this research analyzes visual rhetoric, verbal discourse,
and digital irony to reveal how shared symbols, protest art, and slogans built
a sense of solidarity. Key elements included the symbolic use of red, the
ironic metaphorical use of the term "Razakar", and the widespread sharing of
visuals representing courage, injustice, and resistance. The findings show that
the combination of visual and verbal strategies on Facebook not only mobilized
public sentiment, but also built a strong collective identity that challenged
authoritarian narratives. This study tries to demonstrate how online platforms
can serve as powerful tools for identity construction and political
mobilization in the digital age.

</details>


### [311] [From Monolingual to Bilingual: Investigating Language Conditioning in Large Language Models for Psycholinguistic Tasks](https://arxiv.org/abs/2508.02502)
*Shuzhou Yuan,Zhan Qu,Mario Tawfelis,Michael Färber*

Main category: cs.CL

TL;DR: 研究LLMs在不同语言下的语言心理学能力，发现LLMs会根据提示的语言调整其行为和内部表征。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何在不同语言身份下编码语言心理学知识，以及是否表现出类似人类的语言心理学反应。

Method: 通过声音象征和词语价两个任务，在英语、荷兰语和中文的单一语言和双语提示下，评估了Llama-3.3-70B-Instruct和Qwen2.5-72B-Instruct两个模型。

Result: 两个模型都根据提示的语言身份调整输出来，Qwen对荷兰语和中文的敏感度和区分度更高。语言心理学信号在更深的层级更可解码，中文提示产生的价表征比荷兰语更强、更稳定。

Conclusion: LLMs的语言身份会影响其输出行为和内部表征，为LLMs作为跨语言认知模型提供了新的见解。

Abstract: Large Language Models (LLMs) exhibit strong linguistic capabilities, but
little is known about how they encode psycholinguistic knowledge across
languages. We investigate whether and how LLMs exhibit human-like
psycholinguistic responses under different linguistic identities using two
tasks: sound symbolism and word valence. We evaluate two models,
Llama-3.3-70B-Instruct and Qwen2.5-72B-Instruct, under monolingual and
bilingual prompting in English, Dutch, and Chinese. Behaviorally, both models
adjust their outputs based on prompted language identity, with Qwen showing
greater sensitivity and sharper distinctions between Dutch and Chinese. Probing
analysis reveals that psycholinguistic signals become more decodable in deeper
layers, with Chinese prompts yielding stronger and more stable valence
representations than Dutch. Our results demonstrate that language identity
conditions both output behavior and internal representations in LLMs, providing
new insights into their application as models of cross-linguistic cognition.

</details>


### [312] [Modular Arithmetic: Language Models Solve Math Digit by Digit](https://arxiv.org/abs/2508.02513)
*Tanja Baeumel,Daniil Gurgurov,Yusser al Ghussin,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: LLMs在解决算术问题时，会根据数字位置（如个位、十位、百位）激活特定的“电路”来独立处理，这种机制与模型大小和分词方式无关。


<details>
  <summary>Details</summary>
Motivation: 为了统一理解大型语言模型（LLMs）在简单算术任务中的内部机制，我们在此基础上进行了扩展。

Method: 使用特征重要性和因果干预来识别和验证特定于数字位置的电路。

Result: 发现了LLMs在执行简单算术任务时，存在特定于数字位置的电路，并通过因果干预验证了这些电路的作用。

Conclusion: LLMs在解决算术问题时，存在特定于数字位置的电路，这些电路具有组合性和可解释性，并且独立于模型大小和分词策略。

Abstract: While recent work has begun to uncover the internal strategies that Large
Language Models (LLMs) employ for simple arithmetic tasks, a unified
understanding of their underlying mechanisms is still lacking. We extend recent
findings showing that LLMs represent numbers in a digit-wise manner and present
evidence for the existence of digit-position-specific circuits that LLMs use to
perform simple arithmetic tasks, i.e. modular subgroups of MLP neurons that
operate independently on different digit positions (units, tens, hundreds).
Notably, such circuits exist independently of model size and of tokenization
strategy, i.e. both for models that encode longer numbers digit-by-digit and as
one token. Using Feature Importance and Causal Interventions, we identify and
validate the digit-position-specific circuits, revealing a compositional and
interpretable structure underlying the solving of arithmetic problems in LLMs.
Our interventions selectively alter the model's prediction at targeted digit
positions, demonstrating the causal role of digit-position circuits in solving
arithmetic tasks.

</details>


### [313] [PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs](https://arxiv.org/abs/2508.02515)
*Zhan Qu,Shuzhou Yuan,Michael Färber*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型生成宋词的能力，提出了新的评估框架和生成-批评架构，并通过微调模型在形式符合度上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在生成受严格约束的中国古典诗歌（宋词）方面的能力，以了解其在处理具有复杂结构、音调和韵律限制的文学文本方面的优势和局限性。

Method: 1.开发了一个包含形式符合度评分、自动化质量评估（使用大型语言模型）、人类评估和分类探测任务的综合性评估框架。
2.使用该框架评估了18种大型语言模型（包括3种闭源和15种开源模型）在零样本、单样本、续写、指令微调和思维链五种提示策略下的生成能力。
3.提出了一个生成-批评架构，将评估框架作为批评者，利用其反馈作为奖励信号，通过监督微调（SFT）对三个轻量级开源模型进行微调。

Result: 通过监督微调（SFT），基于生成-批评架构的三个轻量级开源模型在形式符合度方面取得了最高可达5.88%的提升。研究结果揭示了大型语言模型在生成具有文化意义且形式受限的文学文本方面的能力和不足。

Conclusion: 本研究对大型语言模型在创作受严格约束的宋词方面的能力进行了系统性研究，提出了一个包含形式符合度评分、自动化质量评估、人类评估和分类探测任务的多方面评估框架。通过该框架，我们评估了18种大型语言模型在五种不同提示策略下的生成表现。此外，我们提出了一个生成-批评（Generate-Critic）架构，将评估框架作为自动化批评者，利用其反馈进行监督微调（SFT），显著提升了模型在形式符合度方面的表现。

Abstract: This paper presents a systematic investigation into the constrained
generation capabilities of large language models (LLMs) in producing Songci, a
classical Chinese poetry form characterized by strict structural, tonal, and
rhyme constraints defined by Cipai templates. We first develop a comprehensive,
multi-faceted evaluation framework that includes: (i) a formal conformity
score, (ii) automated quality assessment using LLMs, (iii) human evaluation,
and (iv) classification-based probing tasks. Using this framework, we evaluate
the generative performance of 18 LLMs, including 3 proprietary models and 15
open-source models across four families, under five prompting strategies:
zero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought.
Finally, we propose a Generate-Critic architecture in which the evaluation
framework functions as an automated critic. Leveraging the critic's feedback as
a reward signal, we fine-tune three lightweight open-source LLMs via supervised
fine-tuning (SFT), resulting in improvements of up to 5.88% in formal
conformity. Our findings offer new insights into the generative strengths and
limitations of LLMs in producing culturally significant and formally
constrained literary texts.

</details>


### [314] [I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic Representations in LLaMA 3.2](https://arxiv.org/abs/2508.02527)
*Jack Merullo,Arjun Khurana,Oliver McLaughlin*

Main category: cs.CL

TL;DR: LLM 在语音任务中表现出色，即使没有明确的语音训练。它们拥有内部音素模型，其表示方式类似于人类的 IPA 元音图。


<details>
  <summary>Details</summary>
Motivation: 研究 LLM 如何在没有明确语音或听觉背景的情况下，在语音任务（如押韵）中表现出熟练度。

Method: 本研究旨在调查 Llama-3.2-1B-Instruct 如何表示 token 级别的语音信息。

Result: 在押韵任务中，LLM 使用内部音素模型，其潜在空间中的音素表示具有高层次的组织结构。同时，我们还发现了一个“音素移动头”，它在押韵任务中促进语音信息。LLM 学习到的元音模型与人类的 IPA 元音图相似。

Conclusion: LLM，如 Llama-3.2-1B-Instruct，在没有明确语音或听觉背景的情况下，在语音任务（如押韵）中表现出熟练度。LLM 使用丰富的内部音素模型来完成语音任务，其潜在空间中的音素表示具有高层次的组织结构。

Abstract: Large language models demonstrate proficiency on phonetic tasks, such as
rhyming, without explicit phonetic or auditory grounding. In this work, we
investigate how \verb|Llama-3.2-1B-Instruct| represents token-level phonetic
information. Our results suggest that Llama uses a rich internal model of
phonemes to complete phonetic tasks. We provide evidence for high-level
organization of phoneme representations in its latent space. In doing so, we
also identify a ``phoneme mover head" which promotes phonetic information
during rhyming tasks. We visualize the output space of this head and find that,
while notable differences exist, Llama learns a model of vowels similar to the
standard IPA vowel chart for humans, despite receiving no direct supervision to
do so.

</details>


### [315] [Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes](https://arxiv.org/abs/1907.00326)
*Jie Cao,Michael Tanana,Zac E. Imel,Eric Poitras,David C. Atkins,Vivek Srikumar*

Main category: cs.CL

TL;DR: This paper presents neural network models to analyze therapist and client conversations in Motivational Interviewing (MI) for real-time feedback, showing improved performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: The paper aims to aid in understanding and guiding behavior in domains like counseling by automatically analyzing dialogue, specifically focusing on modeling the behavioral codes used to assess Motivational Interviewing (MI), a treatment style effective for substance abuse.

Method: The paper defines neural network models that build upon recent successes in dialogue modeling to categorize behavioral codes and forecast codes for upcoming utterances in Motivational Interviewing (MI).

Result: Experiments demonstrate that the developed models outperform several baselines for both categorizing and forecasting MI behavioral codes. A detailed analysis also reveals the impact of various network design tradeoffs.

Conclusion: The proposed neural network models can categorize therapist and client behavioral codes and forecast upcoming codes for MI, outperforming baselines and offering insights into network design tradeoffs for therapy dialogue.

Abstract: Automatically analyzing dialogue can help understand and guide behavior in
domains such as counseling, where interactions are largely mediated by
conversation. In this paper, we study modeling behavioral codes used to asses a
psychotherapy treatment style called Motivational Interviewing (MI), which is
effective for addressing substance abuse and related problems. Specifically, we
address the problem of providing real-time guidance to therapists with a
dialogue observer that (1) categorizes therapist and client MI behavioral codes
and, (2) forecasts codes for upcoming utterances to help guide the conversation
and potentially alert the therapist. For both tasks, we define neural network
models that build upon recent successes in dialogue modeling. Our experiments
demonstrate that our models can outperform several baselines for both tasks. We
also report the results of a careful analysis that reveals the impact of the
various network design tradeoffs for modeling therapy dialogue.

</details>


### [316] [Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction](https://arxiv.org/abs/2508.02532)
*Karan Reddy,Mayukha Pal*

Main category: cs.CL

TL;DR: CGT 是一种结合了 GNN 和 Transformer 的模型，专门用于技术文档问答，相比现有模型在准确率和参数效率方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 标准 Transformer 语言模型在处理复杂技术和工程文档中的细粒度语法和实体关系方面存在不足。因此，有必要开发一种能够更好地处理这些领域特定语言的模型。

Method: 提出了一种名为上下文图 Transformer (CGT) 的混合神经架构，它结合了图神经网络 (GNN) 和 Transformer，用于领域特定的问答。CGT 在输入令牌上使用顺序、skip-gram 和语义相似性边构建动态图，并通过 GATv2Conv 层处理以进行局部结构学习。然后，这些丰富的嵌入被传递到 Transformer 编码器以捕获全局依赖关系。该模型集成了检索增强生成 (RAG) 管道中。

Result: CGT 在集成到检索增强生成 (RAG) 管道后，在准确性方面优于 GPT-2 和 BERT 等基线模型，相较于 GPT-2 准确率提高了 24.7%，同时参数量减少了 62.4%。

Conclusion: CGT 通过联合建模结构化令牌交互和长距离语义一致性，在技术领域问答方面优于 GPT-2 和 BERT 等基线模型，实现了 24.7% 的准确率提升，同时参数量减少了 62.4%。该模型通过从头开始训练（通用文本预训练，然后进行领域特定手册微调），展示了其在技术语言适应性、更好的基础、实体跟踪和现实世界应用中的检索增强响应能力。

Abstract: Standard transformer-based language models, while powerful for general text,
often struggle with the fine-grained syntax and entity relationships in complex
technical, engineering documents. To address this, we propose the Contextual
Graph Transformer (CGT), a hybrid neural architecture that combines Graph
Neural Networks (GNNs) and Transformers for domain-specific question answering.
CGT constructs a dynamic graph over input tokens using sequential, skip-gram,
and semantic similarity edges, which is processed by GATv2Conv layers for local
structure learning. These enriched embeddings are then passed to a Transformer
encoder to capture global dependencies. Unlike generic large models, technical
domains often require specialized language models with stronger
contextualization and structure awareness. CGT offers a parameter-efficient
solution for such use cases. Integrated into a Retrieval-Augmented Generation
(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%
higher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from
CGTs ability to jointly model structural token interactions and long-range
semantic coherence. The model is trained from scratch using a two-phase
approach: pretraining on general text followed by fine-tuning on
domain-specific manuals. This highlights CGTs adaptability to technical
language, enabling better grounding, entity tracking, and retrieval-augmented
responses in real-world applications.

</details>


### [317] [Enhancing Talk Moves Analysis in Mathematics Tutoring through Classroom Teaching Discourse](https://arxiv.org/abs/2412.13395)
*Jie Cao,Abhijit Suresh,Jennifer Jacobs,Charis Clevenger,Amanda Howard,Chelsea Brown,Brent Milne,Tom Fischaber,Tamara Sumner,James H. Martin*

Main category: cs.CL

TL;DR: This paper presents a new dataset (SAGA22) and modeling strategies for analyzing math tutoring dialogues using 'talk moves'. Pre-training on classroom data improves model performance, especially with more context and speaker info, despite challenges in talk move modeling.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges and resource intensity of collecting, annotating, and analyzing large amounts of tutoring dialogues for developing machine learning models. The goal is to improve the scalability of these models.

Method: This paper analyzes mathematics tutoring discourse using the 'talk moves' framework, which is based on Accountable Talk theory. The study introduces the SAGA22 dataset and evaluates different modeling strategies, including dialogue context, speaker information, pre-training, and fine-tuning.

Result: The results indicate that pre-training on classroom data, along with longer context and speaker information, enhances model performance in tutoring scenarios. Ablation studies were performed to identify challenges in talk move modeling.

Conclusion: The study shows that pre-training models on classroom data improves their performance in math tutoring settings, especially when considering dialogue context and speaker information. Ablation studies highlight the difficulties in modeling talk moves.

Abstract: Human tutoring interventions play a crucial role in supporting student
learning, improving academic performance, and promoting personal growth. This
paper focuses on analyzing mathematics tutoring discourse using talk moves - a
framework of dialogue acts grounded in Accountable Talk theory. However,
scaling the collection, annotation, and analysis of extensive tutoring
dialogues to develop machine learning models is a challenging and
resource-intensive task. To address this, we present SAGA22, a compact dataset,
and explore various modeling strategies, including dialogue context, speaker
information, pretraining datasets, and further fine-tuning. By leveraging
existing datasets and models designed for classroom teaching, our results
demonstrate that supplementary pretraining on classroom data enhances model
performance in tutoring settings, particularly when incorporating longer
context and speaker information. Additionally, we conduct extensive ablation
studies to underscore the challenges in talk move modeling.

</details>


### [318] [What's in the News? Towards Identification of Bias by Commission, Omission, and Source Selection (COSS)](https://arxiv.org/abs/2508.02540)
*Anastasia Zhukova,Terry Ruas,Felix Hamborg,Karsten Donnay,Bela Gipp*

Main category: cs.CL

TL;DR: 提出了一种新的方法来自动识别新闻报道中的偏见。


<details>
  <summary>Details</summary>
Motivation: 解决新闻读者在确定信息来源的可靠性和新闻报道的中立性方面面临的挑战。

Method: 提出了一种联合识别佣、漏、源选择（COSS）偏见的模型。

Result: 描述了偏见识别步骤的目标和任务，并提供了一个利用提取特征和文本重用模式的可视化示例。

Conclusion: 该研究提出了一种联合识别新闻文章中“佣、漏、源选择”三种偏见的方法。

Abstract: In a world overwhelmed with news, determining which information comes from
reliable sources or how neutral is the reported information in the news
articles poses a challenge to news readers. In this paper, we propose a
methodology for automatically identifying bias by commission, omission, and
source selection (COSS) as a joint three-fold objective, as opposed to the
previous work separately addressing these types of bias. In a pipeline concept,
we describe the goals and tasks of its steps toward bias identification and
provide an example of a visualization that leverages the extracted features and
patterns of text reuse.

</details>


### [319] [Towards Actionable Pedagogical Feedback: A Multi-Perspective Analysis of Mathematics Teaching and Tutoring Dialogue](https://arxiv.org/abs/2505.07161)
*Jannatun Naim,Jie Cao,Fareen Tasneem,Jennifer Jacobs,Brent Milne,James Martin,Tamara Sumner*

Main category: cs.CL

TL;DR: 本研究提出了一种新的多视角话语分析方法，用于分析数学课堂对话。该方法整合了教学话语、对话行为和话语关系，解决了现有方法在处理多功能语句和遗漏某些语句的局限性。研究发现，即使是没有明显教学话语的语句也对课堂话语的引导、确认和构建起着关键作用。该方法有助于提供更有效的反馈，并开发能模拟师生角色的AI。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有话语分析方法在处理单一句子的多功能性（一个句子可能包含多个目的）和忽略特定领域话语分类（导致部分句子被遗漏）的挑战，从而影响对课堂对话的有效反馈。

Method: 提出了一种多视角话语分析方法，该方法整合了特定领域的教学话语（talk moves）和对话行为（dialogue acts）（使用具有43个标签的扁平化多功能SWBD-MASL模式）以及话语关系（话语关系）（应用具有16个关系的分割话语表示理论），以分析课堂对话。通过分布式的单一词分析、顺序教学话语分析和多视图深度分析，研究了两个数学教育数据集：TalkMoves（教学）和SAGA22（辅导）。

Result: 发现了有意义的话语模式，并揭示了没有教学话语的语句的关键作用，表明这些语句并非无关紧要的填充物，而是起到引导、确认和构建课堂话语的关键作用。研究结果强调了将话语关系和对话行为纳入人工智能辅助教育系统以改善反馈和创造更具响应性的学习环境的重要性。

Conclusion: 通过整合特定领域的教学话语和对话行为（使用具有43个标签的扁平化多功能SWBD-MASL模式）以及话语关系（应用具有16个关系的分割话语表示理论），我们提出了一种多视角话语分析方法，该方法能够全面理解包含教学话语的以及不包含教学话语的语句。通过对包含和不包含教学话语的语句进行分析，揭示了没有教学话语的语句在引导、确认和构建课堂话语方面的重要作用，表明这些语句并非无关紧要的填充物，而是起到关键作用。这些发现强调了在人工智能辅助教育系统中纳入话语关系和对话行为的重要性，以改善反馈和创造更具响应性的学习环境。该框架不仅有助于为人类教育者提供反馈，还有助于开发能够有效模拟教育者和学生角色的AI代理。

Abstract: Effective feedback is essential for refining instructional practices in
mathematics education, and researchers often turn to advanced natural language
processing (NLP) models to analyze classroom dialogues from multiple
perspectives. However, utterance-level discourse analysis encounters two
primary challenges: (1) multifunctionality, where a single utterance may serve
multiple purposes that a single tag cannot capture, and (2) the exclusion of
many utterances from domain-specific discourse move classifications, leading to
their omission in feedback. To address these challenges, we proposed a
multi-perspective discourse analysis that integrates domain-specific talk moves
with dialogue act (using the flattened multi-functional SWBD-MASL schema with
43 tags) and discourse relation (applying Segmented Discourse Representation
Theory with 16 relations). Our top-down analysis framework enables a
comprehensive understanding of utterances that contain talk moves, as well as
utterances that do not contain talk moves. This is applied to two mathematics
education datasets: TalkMoves (teaching) and SAGA22 (tutoring). Through
distributional unigram analysis, sequential talk move analysis, and multi-view
deep dive, we discovered meaningful discourse patterns, and revealed the vital
role of utterances without talk moves, demonstrating that these utterances, far
from being mere fillers, serve crucial functions in guiding, acknowledging, and
structuring classroom discourse. These insights underscore the importance of
incorporating discourse relations and dialogue acts into AI-assisted education
systems to enhance feedback and create more responsive learning environments.
Our framework may prove helpful for providing human educator feedback, but also
aiding in the development of AI agents that can effectively emulate the roles
of both educators and students.

</details>


### [320] [Building and Aligning Comparable Corpora](https://arxiv.org/abs/2508.02555)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 提出并验证了一种使用 CL-LSI 自动对齐多语言可比新闻语料库（BBC 和 JSC）的方法，该方法在事件级别对齐方面表现优于基于词典的方法。


<details>
  <summary>Details</summary>
Motivation: 可比语料库对于多语言自然语言处理非常有用，尤其是在某些领域或语言没有平行文本的情况下。这些语料库还能揭示不同语言中关于某一主题的信息。

Method: 提出了一种从维基百科和 EURONEWS 网站构建多语言（英语、法语、阿拉伯语）可比语料库的方法，并实验了一种使用跨语言相似性度量（基于双语词典和潜在语义索引 LSI）自动对齐可比文档的方法。实验表明，跨语言 LSI（CL-LSI）度量优于基于词典的度量。

Result: CL-LSI 相似性度量在对齐 BBC 和 JSC 的新闻文档方面表现良好，能够实现主题级别和事件级别的对齐。

Conclusion: CL-LSI 相似性度量不仅能够对跨语言文档进行主题级别的对齐，还能够进行事件级别的对齐。

Abstract: Comparable corpus is a set of topic aligned documents in multiple languages,
which are not necessarily translations of each other. These documents are
useful for multilingual natural language processing when there is no parallel
text available in some domains or languages. In addition, comparable documents
are informative because they can tell what is being said about a topic in
different languages. In this paper, we present a method to build comparable
corpora from Wikipedia encyclopedia and EURONEWS website in English, French and
Arabic languages. We further experiment a method to automatically align
comparable documents using cross-lingual similarity measures. We investigate
two cross-lingual similarity measures to align comparable documents. The first
measure is based on bilingual dictionary, and the second measure is based on
Latent Semantic Indexing (LSI). Experiments on several corpora show that the
Cross-Lingual LSI (CL-LSI) measure outperforms the dictionary based measure.
Finally, we collect English and Arabic news documents from the British
Broadcast Corporation (BBC) and from ALJAZEERA (JSC) news website respectively.
Then we use the CL-LSI similarity measure to automatically align comparable
documents of BBC and JSC. The evaluation of the alignment shows that CL-LSI is
not only able to align cross-lingual documents at the topic level, but also it
is able to do this at the event level.

</details>


### [321] [Automated SNOMED CT Concept Annotation in Clinical Text Using Bi-GRU Neural Networks](https://arxiv.org/abs/2508.02556)
*Ali Noori,Pratik Devkota,Somya Mohanty,Prashanti Manda*

Main category: cs.CL

TL;DR: 通过双向GRU模型和优化的文本处理，实现了高效、低成本的临床文本SNOMED CT概念自动标注，性能优越。


<details>
  <summary>Details</summary>
Motivation: 临床文本的自动化注释对于结构化数据提取和决策支持至关重要，但手动注释耗时且成本高。SNOMED CT作为丰富的本体，需要高效的标注方法。

Method: 采用基于双向GRU（Bi-GRU）的神经网络序列标注方法，结合领域适应的SpaCy和SciBERT进行文本预处理、分词和特征提取，将句子分割成19个标记的重叠块，并为概念边界分配IOB标签。

Result: 在MIMIC-IV数据集的一个子集上，该方法达到了90%的F1分数，有效处理了歧义词和拼写错误，证明了其在临床概念标注方面的有效性。

Conclusion: 本研究提出的基于双向GRU的神经网络序列标注方法在SNOMED CT概念识别方面取得了90%的F1分数，优于传统方法并媲美现有神经网络模型，且计算成本更低，适合实际部署。

Abstract: Automated annotation of clinical text with standardized medical concepts is
critical for enabling structured data extraction and decision support. SNOMED
CT provides a rich ontology for labeling clinical entities, but manual
annotation is labor-intensive and impractical at scale. This study introduces a
neural sequence labeling approach for SNOMED CT concept recognition using a
Bidirectional GRU model. Leveraging a subset of MIMIC-IV, we preprocess text
with domain-adapted SpaCy and SciBERT-based tokenization, segmenting sentences
into overlapping 19-token chunks enriched with contextual, syntactic, and
morphological features. The Bi-GRU model assigns IOB tags to identify concept
spans and achieves strong performance with a 90 percent F1-score on the
validation set. These results surpass traditional rule-based systems and match
or exceed existing neural models. Qualitative analysis shows effective handling
of ambiguous terms and misspellings. Our findings highlight that lightweight
RNN-based architectures can deliver high-quality clinical concept annotation
with significantly lower computational cost than transformer-based models,
making them well-suited for real-world deployment.

</details>


### [322] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: EH-Benchmark 是一个用于评估和减轻眼科 MLLMs 幻觉的新基准和框架，通过多智能体方法提高了诊断的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLMs 在眼科诊断中存在幻觉问题，限制了其在治疗威胁视力的疾病方面的潜力。现有基准未能有效评估幻觉类型或提供解决方案。

Method: 提出了一种名为 EH-Benchmark 的新型眼科基准，用于评估 MLLMs 中的幻觉。将幻觉分为视觉理解和逻辑构成两大类。设计了一个以智能体为中心的三阶段框架，包括知识级检索、任务级案例研究和结果级验证。

Result: 实验结果表明，所提出的多智能体框架能有效减轻幻觉，提高 MLLMs 的准确性、可解释性和可靠性。

Conclusion: EH-Benchmark 通过引入一个多智能体框架，显著减轻了 MLLMs 在眼科诊断中的幻觉问题，提高了准确性、可解释性和可靠性。

Abstract: Medical Large Language Models (MLLMs) play a crucial role in ophthalmic
diagnosis, holding significant potential to address vision-threatening
diseases. However, their accuracy is constrained by hallucinations stemming
from limited ophthalmic knowledge, insufficient visual localization and
reasoning capabilities, and a scarcity of multimodal ophthalmic data, which
collectively impede precise lesion detection and disease diagnosis.
Furthermore, existing medical benchmarks fail to effectively evaluate various
types of hallucinations or provide actionable solutions to mitigate them. To
address the above challenges, we introduce EH-Benchmark, a novel ophthalmology
benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'
hallucinations based on specific tasks and error types into two primary
classes: Visual Understanding and Logical Composition, each comprising multiple
subclasses. Given that MLLMs predominantly rely on language-based reasoning
rather than visual processing, we propose an agent-centric, three-phase
framework, including the Knowledge-Level Retrieval stage, the Task-Level Case
Studies stage, and the Result-Level Validation stage. Experimental results show
that our multi-agent framework significantly mitigates both types of
hallucinations, enhancing accuracy, interpretability, and reliability. Our
project is available at https://github.com/ppxy1/EH-Benchmark.

</details>


### [323] [Sparse-dLLM: Accelerating Diffusion LLMs with Dynamic Cache Eviction](https://arxiv.org/abs/2508.02558)
*Yuerong Song,Xiaoran Liu,Ruixiao Li,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: Sparse-dLLM通过动态缓存淘汰和稀疏注意力，显著提高了LLM的解码吞吐量和效率，同时保持了性能和内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有的缓存技术虽然能加速LLM解码，但会带来高昂的内存开销，限制了长上下文应用。论文分析了dLLMs中的注意力模式，发现了跨层稀疏性，关键标记在解码步骤中始终保持显著，而低相关性标记则一直不重要，这启发了选择性缓存淘汰。

Method: 提出了一种名为Sparse-dLLM的训练免费框架，该框架集成了动态缓存淘汰与稀疏注意力。具体方法包括延迟双向稀疏缓存，利用标记显著性随时间保持稳定的特性，保留关键标记，并通过注意力引导策略动态淘汰不重要的前缀/后缀条目。

Result: Sparse-dLLM在LLaDA和Dream系列上进行了广泛的实验，结果显示其吞吐量比标准的dLLMs提高了10倍，同时性能相当，峰值内存成本相似，在效率和有效性方面优于以前的方法。

Conclusion: Sparse-dLLM通过动态缓存淘汰和稀疏注意力（通过延迟双向稀疏缓存）相结合，实现了训练免费框架，能够保留关键标记并动态淘汰不重要的前缀/后缀条目，从而在LLaDA和Dream系列上实现了高达10倍的吞吐量，同时保持了可比的性能和相似的峰值内存成本，并在效率和有效性方面优于先前的方法。

Abstract: Diffusion Large Language Models (dLLMs) enable breakthroughs in reasoning and
parallel decoding but suffer from prohibitive quadratic computational
complexity and memory overhead during inference. Current caching techniques
accelerate decoding by storing full-layer states, yet impose substantial memory
usage that limit long-context applications. Our analysis of attention patterns
in dLLMs reveals persistent cross-layer sparsity, with pivotal tokens remaining
salient across decoding steps and low-relevance tokens staying unimportant,
motivating selective cache eviction. We propose Sparse-dLLM, the first
training-free framework integrating dynamic cache eviction with sparse
attention via delayed bidirectional sparse caching. By leveraging the stability
of token saliency over steps, it retains critical tokens and dynamically evicts
unimportant prefix/suffix entries using an attention-guided strategy. Extensive
experiments on LLaDA and Dream series demonstrate Sparse-dLLM achieves up to
10$\times$ higher throughput than vanilla dLLMs, with comparable performance
and similar peak memory costs, outperforming previous methods in efficiency and
effectiveness.

</details>


### [324] [Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs](https://arxiv.org/abs/2508.02573)
*Jérémie Dentan,Davide Buscaldi,Sonia Vanier*

Main category: cs.CL

TL;DR: 本研究提出了一种分析大型语言模型（LLM）记忆现象的新方法，通过训练CNN分析注意力权重，并改进了记忆样本的分类法，发现模型猜测和训练数据重复是影响记忆的两个重要因素。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLM）中的逐字记忆现象，分析其不同的潜在机制。

Method: 训练卷积神经网络（CNN）分析大型语言模型（LLM）的注意力权重，并评估现有分类法与解码注意力权重的对齐情况。提出了一种新的分类法，最大限度地与注意力权重对齐。

Result: 现有的记忆分类法在新模型中表现不佳，无法反映注意力块中不同的机制。我们提出的新分类法能最大限度地与注意力权重对齐。少样本逐字记忆与独特的注意力机制不符。相当一部分可提取样本实际上是模型猜测的。

Conclusion: 现有的记忆分类法在新模型中表现不佳，无法反映注意力块中不同的机制。我们提出了一个包含三个类别的新分类法：使用语言模型能力猜测的记忆样本、由于训练集中重复次数多而被回忆起来的记忆样本以及非记忆样本。结果表明，少样本逐字记忆与独特的注意力机制不符，并且相当一部分可提取样本实际上是模型猜测的。

Abstract: Verbatim memorization in Large Language Models (LLMs) is a multifaceted
phenomenon involving distinct underlying mechanisms. We introduce a novel
method to analyze the different forms of memorization described by the existing
taxonomy. Specifically, we train Convolutional Neural Networks (CNNs) on the
attention weights of the LLM and evaluate the alignment between this taxonomy
and the attention weights involved in decoding.
  We find that the existing taxonomy performs poorly and fails to reflect
distinct mechanisms within the attention blocks. We propose a new taxonomy that
maximizes alignment with the attention weights, consisting of three categories:
memorized samples that are guessed using language modeling abilities, memorized
samples that are recalled due to high duplication in the training set, and
non-memorized samples. Our results reveal that few-shot verbatim memorization
does not correspond to a distinct attention mechanism. We also show that a
significant proportion of extractable samples are in fact guessed by the model
and should therefore be studied separately. Finally, we develop a custom visual
interpretability technique to localize the regions of the attention weights
involved in each form of memorization.

</details>


### [325] [MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification](https://arxiv.org/abs/2508.02584)
*Ming Pok Ng,Junqi Jiang,Gabriel Freedman,Antonio Rago,Francesca Toni*

Main category: cs.CL

TL;DR: MArgE通过为LLM的论点提供正式的论证结构，实现了更可靠、可解释的论点验证。


<details>
  <summary>Details</summary>
Motivation: 为了利用多个LLM的输出来利用它们在广泛任务中的能力，同时减轻它们产生错误的（例如幻觉）的可能性，但现有的结合多个LLM见解的方法通常涉及非结构化交互（例如自由辩论），导致模型生成的合理性不足。

Method: 使用ArgLLMs（受计算论证领域的框架和语义驱动的LLMs）的变体，为给定的论点构建结构化的论点树，从而创建从初始论点到最终论点验证决策的可检查路径，以此提供忠实的理由。

Result: MArgE框架在论点验证任务上显著优于单一LLM（包括三个开源模型（4B至8B参数）、GPT-4o-mini和现有的ArgLLMs）以及之前非结构化多LLM辩论的方法。

Conclusion: MArgE框架通过为LLM的证据提供正式的结构，以论点树的形式，在论点验证任务上显著优于单一LLM和现有的多LLM辩论方法，证明了在组合多个LLM输出时结合正式的论证推理机制的优势。

Abstract: Leveraging outputs from multiple large language models (LLMs) is emerging as
a method for harnessing their power across a wide range of tasks while
mitigating their capacity for making errors, e.g., hallucinations. However,
current approaches to combining insights from multiple LLMs often involve
unstructured interactions (e.g., free debate), resulting in model generations
that are not faithfully justifiable. In this work, we introduce MArgE, a novel
framework to provide formal structure to the evidence from each LLM, in the
form of a tree of extracted arguments, for the task of claim verification. We
use a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks
and semantics from the field of computational argumentation, to construct
structured argument trees for given claims. This process creates an inspectable
pathway from the initial arguments to the final claim verification decisions,
providing a faithful justification thereof. We show experimentally that MArgE
can significantly outperform single LLMs, including three open-source models
(4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior
methods for unstructured multi-LLM debates. We thus demonstrate the advantages
of incorporating formal, argumentative reasoning mechanisms when combining
multiple LLM outputs.

</details>


### [326] [CharBench: Evaluating the Role of Tokenization in Character-Level Tasks](https://arxiv.org/abs/2508.02591)
*Omri Uzan,Yuval Pinter*

Main category: cs.CL

TL;DR: 语言模型在处理字符级任务时表现不佳，尤其是在计数和定位字符方面。新基准CharBench显示，现有模型平均准确率仅43.6%，部分任务准确率更低。模型性能与词语长度、字符数及词元长度有关，长词元会阻碍模型理解字符位置。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型在处理字符级推理任务（如计数或定位字符）时存在困难，尽管有研究认为这与模型依赖子词单元而非字符有关，但其影响尚不明确。

Method: 提出并实现了一个名为CharBench的综合性字符级任务基准，该基准比现有基准大两个数量级。在CharBench上评估了多种主流模型，并深入分析了词汇固有属性和分词方式对模型性能的影响。

Result: CharBench对现代大型语言模型构成了重大挑战，平均准确率仅为43.6%，部分任务准确率低至32.3%。研究发现，在计数任务中，分词属性与正确率关系不大，而词语长度和字符数更重要；在需要词内位置理解的任务中，包含查询字符的词元长度越长，模型性能越差，表明长词元会模糊字符位置信息。

Conclusion: CharBench 为改进模型处理字符级任务的能力提供了基准和评估方法，显示了模型在处理字符级任务时仍面临巨大挑战。

Abstract: Tasks that require character-level reasoning, such as counting or locating
characters within words, remain challenging for contemporary language models. A
common conjecture is that language models' reliance on subword units, rather
than characters, contributes to their struggles with character-level tasks, yet
recent studies offer conflicting conclusions about the role of tokenization,
leaving its impact unclear. To address this gap, we introduce CharBench, a
comprehensive benchmark of character-level tasks that is two orders of
magnitude larger than existing alternatives. We evaluate a diverse range of
leading open-weight and proprietary models on CharBench and find that it
presents a significant challenge to modern LLMs, with an average accuracy of
43.6% and 32.3% on some tasks. We present an in-depth analysis of how intrinsic
properties of words and their segmentations into tokens correspond to model
performance. For counting tasks, we find that tokenization properties are
weakly correlated with correctness, while the length of the queried word and
the actual character count play a more significant part. In contrast, for tasks
requiring intra-word positional understanding, performance is negatively
correlated with the length of the token containing the queried character,
suggesting that longer tokens obscure character position information for LLMs.
We encourage future work to build on the benchmark and evaluation methodology
introduced here as tools for improving model performance on such tasks.

</details>


### [327] [Mitigating Attention Hacking in Preference-Based Reward Modeling via Interaction Distillation](https://arxiv.org/abs/2508.02618)
*Jianxiang Zang,Meiling Ning,Shihan Dou,Jiazheng Zhang,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: Current reward models in RLHF are vulnerable to "attention hacking" due to limitations in token-level attention. We propose "Interaction Distillation" to fix this by using a teacher model to guide the reward model's attention, resulting in better and more stable reward signals.


<details>
  <summary>Details</summary>
Motivation: Mainstream preference modeling in RMs is inadequate due to limitations in token-level interaction, specifically forward-decaying intra-sequence attention in decoder-only architectures and the absence of inter-sequence attention in the Siamese-encoding paradigm, making reward signals vulnerable to "attention hacking".

Method: Interaction Distillation, which uses an interaction-based NLU model as a teacher to provide token interaction patterns and guides the preference model to simulate these patterns through an attentional alignment objective.

Result: Interaction distillation provides more stable and generalizable reward signals, outperforming state-of-the-art RM optimization methods.

Conclusion: The proposed "Interaction Distillation" framework addresses the limitations of mainstream preference modeling in reward models (RMs) by optimizing attention mechanisms, leading to more stable and generalizable reward signals compared to existing methods.

Abstract: The reward model (RM), as the core component of reinforcement learning from
human feedback (RLHF) for large language models (LLMs), responsible for
providing reward signals to generated responses. However, mainstream preference
modeling in RM is inadequate in terms of token-level interaction, making its
judgment signals vulnerable to being hacked by misallocated attention to
context. This stems from two fundamental limitations: (1) Current preference
modeling employs decoder-only architectures, where the unidirectional causal
attention mechanism leads to forward-decaying intra-sequence attention within
the prompt-response sequence. (2) The independent Siamese-encoding paradigm
induces the absence of token-level inter-sequence attention between chosen and
rejected sequences. To address this "attention hacking", we propose
"Interaction Distillation", a novel training framework for more adequate
preference modeling through attention-level optimization. The method introduces
an interaction-based natural language understanding model as the teacher to
provide sophisticated token interaction patterns via comprehensive attention,
and guides the preference modeling to simulate teacher model's interaction
pattern through an attentional alignment objective. Through extensive
experiments, interaction distillation has demonstrated its ability to provide
more stable and generalizable reward signals compared to state-of-the-art RM
optimization methods that target data noise, highlighting the attention hacking
constitute a more fundamental limitation in RM.

</details>


### [328] [Pointer: Linear-Complexity Long-Range Modeling without Pre-training](https://arxiv.org/abs/2508.02631)
*Zixi Li*

Main category: cs.CL

TL;DR: Pointer is a new architecture that uses layer-wise pointer chaining to model long-range sequences efficiently, achieving speedups and high accuracy without pre-training.


<details>
  <summary>Details</summary>
Motivation: Pointer is a novel architecture that achieves linear $O(NK)$ complexity for long-range sequence modeling while maintaining superior performance without requiring pre-training.

Method: Pointer uses layer-wise pointer chaining where each layer's pointer selection depends on previous layer's pointer positions, creating explicit long-distance connections through pointer chains.

Result: Pointer achieves $2$--$10	imes$ speedup on long sequences compared to standard transformers, maintains $>95%$ accuracy on copy tasks at distances up to 2048 tokens, and learns interpretable pointer patterns that reveal structured dependency modeling.

Conclusion: Pointer

Abstract: We introduce Pointer, a novel architecture that achieves linear $O(NK)$
complexity for long-range sequence modeling while maintaining superior
performance without requiring pre-training. Unlike standard attention
mechanisms that compute $O(N^2)$ pairwise interactions, our approach uses
layer-wise pointer chaining where each layer's pointer selection depends on
previous layer's pointer positions, creating explicit long-distance connections
through pointer chains. We demonstrate that this architecture achieves
$2$--$10\times$ speedup on long sequences compared to standard transformers,
maintains $>95\%$ accuracy on copy tasks at distances up to 2048 tokens, and
learns interpretable pointer patterns that reveal structured dependency
modeling. Our experiments on efficiency benchmarks, long-range dependency
tasks, and interpretability analysis show that Pointer offers a compelling
alternative to attention mechanisms for scenarios requiring efficient
long-range modeling without pre-training dependencies.

</details>


### [329] [Test Set Quality in Multilingual LLM Evaluation](https://arxiv.org/abs/2508.02635)
*Kranti Chalamalasetti,Gabriel Bernier-Colborne,Yvan Gauthier,Sowmya Vajjala*

Main category: cs.CL

TL;DR: 通过手动分析和修订法语、泰卢固语的多语言评估集，发现大型语言模型在修订版上的性能有显著差异，这表明数据集质量很重要，应进行修订和版本控制。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型多语言能力时，现有数据集的质量问题未得到足够重视。

Method: 通过对法语和泰卢固语的近期多语言评估集进行手动分析来识别错误。

Result: 在原始和修订版的数据集上，大型语言模型在法语和泰卢固语上均表现出显著的性能差异（有时高达10%）。

Conclusion: 测试集应被视为可变的，并应进行修订、检查和版本控制。数据集创建者和使用者应解决数据集质量问题。

Abstract: Several multilingual benchmark datasets have been developed in a
semi-automatic manner in the recent past to measure progress and understand the
state-of-the-art in the multilingual capabilities of Large Language Models.
However, there is not a lot of attention paid to the quality of the datasets
themselves, despite the existence of previous work in identifying errors in
even fully human-annotated test sets. In this paper, we manually analyze recent
multilingual evaluation sets in two languages - French and Telugu, identifying
several errors in the process. We compare the performance difference across
several LLMs with the original and revised versions of the datasets and
identify large differences (almost 10% in some cases) in both languages). Based
on these results, we argue that test sets should not be considered immutable
and should be revisited, checked for correctness, and potentially versioned. We
end with some recommendations for both the dataset creators as well as
consumers on addressing the dataset quality issues.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [330] [Multi-Community Spectral Clustering for Geometric Graphs](https://arxiv.org/abs/2508.00893)
*Luiz Emilio Allem,Konstantin Avrachenkov,Carlos Hoppen,Hariprasad Manjunath,Lucas Siviero Sibemberg*

Main category: cs.SI

TL;DR: 提出了一种新的谱聚类算法，用于恢复SGBM模型中的社区结构，并证明了该算法的一致性。


<details>
  <summary>Details</summary>
Motivation: 在稠密区域中，考虑具有固定数量k>=2的同质社区的软几何块模型（SGBM）。

Method: 提出了一种谱聚类算法，通过将图的邻接矩阵与模型参数确定的值最接近的k-1个特征值相关的特征向量相结合，将图嵌入到R^k-1中，然后对嵌入进行k-means聚类。

Result: 算法能够对SGBM图进行社区恢复。

Conclusion: 证明了算法弱一致性，并表明局部优化步骤可确保强一致性。

Abstract: In this paper, we consider the soft geometric block model (SGBM) with a fixed
number $k \geq 2$ of homogeneous communities in the dense regime, and we
introduce a spectral clustering algorithm for community recovery on graphs
generated by this model. Given such a graph, the algorithm produces an
embedding into $\mathbb{R}^{k-1}$ using the eigenvectors associated with the
$k-1$ eigenvalues of the adjacency matrix of the graph that are closest to a
value determined by the parameters of the model. It then applies $k$-means
clustering to the embedding. We prove weak consistency and show that a simple
local refinement step ensures strong consistency. A key ingredient is an
application of a non-standard version of Davis-Kahan theorem to control
eigenspace perturbations when eigenvalues are not simple. We also analyze the
limiting spectrum of the adjacency matrix, using a combination of combinatorial
and matrix techniques.

</details>


### [331] [WOCD: A Semi-Supervised Method for Overlapping Community Detection Using Weak Cliques](https://arxiv.org/abs/2508.00927)
*Shaozhen Ma,Hanchen Wang,Dong Wen,Wenjie Zhang,Wei Huang,Ying Zhang*

Main category: cs.SI

TL;DR: WOCD是一种新的重叠社区检测方法，它利用弱团、伪标签和图Transformer来提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN方法在整合链接、属性和先验信息方面存在困难，并且存在感受野有限和过平滑的问题，这阻碍了它们在复杂的重叠社区检测方面的性能。

Method: 提出了一种基于弱团的重叠社区检测方法（WOCD），该方法在一个半监督框架内引入伪标签来增强泛化能力，并使用弱团来初始化伪标签，以充分利用链接和先验信息。此外，采用单层图Transformer结合GNN来提高效率和性能。

Result: WOCD在八个真实世界属性数据集上的评估结果表明，其准确性显著优于最先进的半监督OCD方法。

Conclusion: WOCD通过结合先验信息、优化链接信息使用、引入伪标签以及使用单层图Transformer和GNN，在八个真实世界属性数据集上取得了显著的性能提升，超过了最先进的半监督OCD方法。

Abstract: Overlapping community detection (OCD) is a fundamental graph data analysis
task for extracting graph patterns. Traditional OCD methods can be broadly
divided into node clustering and link clustering approaches, both of which rely
solely on link information to identify overlapping communities. In recent
years, deep learning-based methods have made significant advancements for this
task. However, existing GNN-based approaches often face difficulties in
effectively integrating link, attribute, and prior information, along with
challenges like limited receptive fields and over-smoothing, which hinder their
performance on complex overlapping community detection. In this paper, we
propose a Weak-clique based Overlapping Community Detection method, namely
WOCD, which incorporates prior information and optimizes the use of link
information to improve detection accuracy. Specifically, we introduce
pseudo-labels within a semi-supervised framework to strengthen the
generalization ability, making WOCD more versatile. Furthermore, we initialize
pseudo-labels using weak cliques to fully leverage link and prior information,
leading to better detection accuracy. Additionally, we employ a single-layer
Graph Transformer combined with GNN, which achieves significant performance
improvements while maintaining efficiency. We evaluate WOCD on eight real-world
attributed datasets, and the results demonstrate that it outperforms the
state-of-the-art semi-supervised OCD method by a significant margin in terms of
accuracy.

</details>


### [332] [Star Network Motifs on X during COVID-19](https://arxiv.org/abs/2508.00975)
*Lynnette Hui Xian Ng,Divyaansh Sinha,Kathleen M. Carley*

Main category: cs.SI

TL;DR: 在COVID-19期间，X平台上的星型网络结构在机器人和人类用户中表现出不同的模式，有助于社交媒体行为分析。


<details>
  <summary>Details</summary>
Motivation: 识别社交网络中重复出现的小型子图模式，特别是星型网络结构，以了解COVID-19期间的社交沟通模式。

Method: 研究了COVID-19疫情期间X平台上的星型网络结构，分析了机器人和人类用户在该结构中的表现模式。

Result: 区分了六种主要的星型结构模式，机器人和人类用户在星型网络结构中表现出不同的模式，这些模式可用于社交媒体行为分析。

Conclusion: 研究了COVID-19疫情期间X平台上的星型网络结构，分析了机器人和人类用户在该结构中的表现模式，区分了六种主要的星型结构模式，并展示了这些模式如何为社交媒体行为分析提供信息。

Abstract: Social network motifs are recurring patterns of small subgraphs that indicate
fundamental patterns of social communication. In this work, we study the simple
star network motifs that recur on X during the COVID-19 discourse. We study the
profile of the manifestation of the star network among bot and human users.
There are six primary patterns of the star motif, differentiating by the bots
and humans being either egos and alters. We describe the presentation of each
of these six patterns in our data, demonstrating how the motif patterns can
inform social media behavioral analysis.

</details>


### [333] [Are LLM-Powered Social Media Bots Realistic?](https://arxiv.org/abs/2508.00998)
*Lynnette Hui Xian Ng,Kathleen M. Carley*

Main category: cs.SI

TL;DR: LLM可以用来创建社交媒体机器人网络，但这些网络在网络和语言属性上与真实世界的机器人和人类不同。


<details>
  <summary>Details</summary>
Motivation: 探究LLM驱动的社交媒体机器人网络的现实性。

Method: 通过结合人工、网络科学和LLM来创建合成机器人代理、它们的推文和交互，从而模拟社交媒体网络。

Result: 生成的网络与经验数据进行了比较，观察到LLM驱动的机器人的网络和语言属性与野生机器人/人类不同。

Conclusion: LLM驱动的社交媒体机器人的网络和语言属性与野生机器人/人类不同，这对其检测和有效性有影响。

Abstract: As Large Language Models (LLMs) become more sophisticated, there is a
possibility to harness LLMs to power social media bots. This work investigates
the realism of generating LLM-Powered social media bot networks. Through a
combination of manual effort, network science and LLMs, we create synthetic bot
agent personas, their tweets and their interactions, thereby simulating social
media networks. We compare the generated networks against empirical bot/human
data, observing that both network and linguistic properties of LLM-Powered Bots
differ from Wild Bots/Humans. This has implications towards the detection and
effectiveness of LLM-Powered Bots.

</details>


### [334] [Network Prebunking Problem: Optimizing Prebunking Targets to Suppress the Spread of Misinformation in Social Networks](https://arxiv.org/abs/2508.01124)
*Satoshi Furutani,Toshiki Shibahara,Mitsuaki Akiyama,Masaki Aida*

Main category: cs.SI

TL;DR: Prebunking, a psychological intervention to combat misinformation, can be optimized for social networks using the network prebunking problem and the MIA-NPP algorithm, which effectively reduces misinformation spread.


<details>
  <summary>Details</summary>
Motivation: While prebunking is effective at the individual level, it's unclear how to optimally target interventions within a social network to mitigate misinformation spread.

Method: Formulate a combinatorial optimization problem called the network prebunking problem to identify optimal prebunking targets for minimizing the spread of misinformation in a social network. Propose an approximation algorithm, MIA-NPP, based on the Maximum Influence Arborescence (MIA) approach.

Result: MIA-NPP effectively suppresses the spread of misinformation under both fully observed and uncertain model parameter settings, as demonstrated through numerical experiments using real-world social network datasets.

Conclusion: MIA-NPP in the network prebunking problem can effectively suppress the spread of misinformation under both fully observed and uncertain model parameter settings.

Abstract: As a countermeasure against misinformation that undermines the healthy use of
social media, a preventive intervention known as prebunking has recently
attracted attention in the field of psychology. Prebunking aims to strengthen
individuals' cognitive resistance to misinformation by presenting weakened
doses of misinformation or by teaching common manipulation techniques before
they encounter actual misinformation. Despite the growing body of evidence
supporting its effectiveness in reducing susceptibility to misinformation at
the individual level, an important open question remains: how best to identify
the optimal targets for prebunking interventions to mitigate the spread of
misinformation in a social network. To address this issue, we formulate a
combinatorial optimization problem, called the network prebunking problem, to
identify optimal prebunking targets for minimizing the spread of misinformation
in a social network. We prove that this problem is NP-hard and propose an
approximation algorithm, MIA-NPP, based on the Maximum Influence Arborescence
(MIA) approach, which restricts influence propagation around each node to a
local directed tree rooted at that node. Through numerical experiments using
real-world social network datasets, we demonstrate that MIA-NPP effectively
suppresses the spread of misinformation under both fully observed and uncertain
model parameter settings.

</details>


### [335] [Shooting the Messenger? Harassment and Hate Speech Directed at Journalists on Social Media](https://arxiv.org/abs/2508.01125)
*Simón Peña-Fernández,Urko Peña-Alonso,Ainara Larrondo-Ureta,Jordi Morales-i-Gras*

Main category: cs.SI

TL;DR: 社交网络虽为记者带来便利，却也增加了她们遭受骚扰的风险，尤其对女性记者而言，骚扰言论常带有性别歧视和政治色彩。媒体需加强保护措施。


<details>
  <summary>Details</summary>
Motivation: 虽然社交网络增强了记者的新闻制作和传播能力，但也增加了他们遭受骚扰和仇恨言论的风险，特别是对女性记者而言。

Method: 分析了200名记者和媒体机构在2023年西班牙大选前后（7月23日）于X（原推特）上发布的60,684条帖文的回复，以研究骚扰和仇恨言论的出现情况。

Result: 研究结果表明，最常见的骚扰形式是侮辱和政治仇恨言论，这些言论更多地指向个人账号而非机构账号。性别方面，虽然男性和女性记者收到的骚扰信息总量相似，但女性记者遭受的性别歧视信息更多，并且来自极端分子或右翼民粹主义者的仇恨言论带有意识形态色彩。

Conclusion: 该研究证实了记者面临的骚扰是一个普遍但系统性的问题，尤其是在政治和性别方面。媒体需要制定积极的政策和保护措施，甚至延伸到通常适用此问题的个人层面。

Abstract: Journalists have incorporated social networks into their work as a standard
tool, enhancing their ability to produce and disseminate information and making
it easier for them to connect more directly with their audiences. However, this
greater presence in the digital public sphere has also increased their exposure
to harassment and hate speech, particularly in the case of women journalists.
This study analyzes the presence of harassment and hate speech in responses (n
= 60,684) to messages that 200 journalists and media outlets posted on X
(formerly Twitter) accounts during the days immediately preceding and following
the July 23 (23-J) general elections held in Spain in 2023. The results
indicate that the most common forms of harassment were insults and political
hate, which were more frequently aimed at personal accounts than institutional
ones, highlighting the significant role of political polarization-particularly
during election periods-in shaping the hostility that journalists face.
Moreover, although, generally speaking, the total number of harassing messages
was similar for men and women, it was found that a greater number of sexist
messages were aimed at women journalists, and an ideological dimension was
identified in the hate speech that extremists or right-wing populists directed
at them. This study corroborates that this is a minor but systemic issue,
particularly from a political and gender perspective. To counteract this, the
media must develop proactive policies and protective actions extending even to
the individual level, where this issue usually applies.

</details>


### [336] [Effective and Efficient Conductance-based Community Search at Billion Scale](https://arxiv.org/abs/2508.01244)
*Longlong Lin,Yue He,Wei Chen,Pingpeng Yuan,Rong-Hua Li,Tao Jia*

Main category: cs.SI

TL;DR: 提出了一种新的社区搜索方法（CCS），通过优化社区的电导率来解决现有方法的不足。并提出了一种名为SCCS的算法来高效解决该问题。


<details>
  <summary>Details</summary>
Motivation: 现有社区搜索方法主要关注社区内部的凝聚力，而忽略了社区外部的稀疏性，导致结果不佳。因此，提出基于电导率的社区搜索（CCS）问题，旨在寻找电导率最小的连通子图。

Method: 提出了一种名为SCCS的四阶段子图-电导率基础社区搜索算法。首先，使用局部采样技术大大简化图。然后，采用三阶段局部优化策略，包括种子策略、扩展阶段和验证阶段，以提高社区质量。

Result: 在包含十亿级图的真实数据集和合成数据集上的广泛实验证明了该解决方案的有效性、效率和可扩展性。

Conclusion: 实验结果表明该方法有效、高效且可扩展。

Abstract: Community search is a widely studied semi-supervised graph clustering
problem, retrieving a high-quality connected subgraph containing the
user-specified query vertex. However, existing methods primarily focus on
cohesiveness within the community but ignore the sparsity outside the
community, obtaining sub-par results. Inspired by this, we adopt the well-known
conductance metric to measure the quality of a community and introduce a novel
problem of conductance-based community search (CCS). CCS aims at finding a
subgraph with the smallest conductance among all connected subgraphs that
contain the query vertex. We prove that the CCS problem is NP-hard. To
efficiently query CCS, a four-stage subgraph-conductance-based community search
algorithm, SCCS, is proposed. Specifically, we first greatly reduce the entire
graph using local sampling techniques. Then, a three-stage local optimization
strategy is employed to continuously refine the community quality. Namely, we
first utilize a seeding strategy to obtain an initial community to enhance its
internal cohesiveness. Then, we iteratively add qualified vertices in the
expansion stage to guarantee the internal cohesiveness and external sparsity of
the community. Finally, we gradually remove unqualified vertices during the
verification stage. Extensive experiments on real-world datasets containing one
billion-scale graph and synthetic datasets show the effectiveness, efficiency,
and scalability of our solutions.

</details>


### [337] [A graph neural network based on feature network for identifying influential nodes](https://arxiv.org/abs/2508.01278)
*Yanmei Hu,Siyuan Yin,Yihang Wu,Xue Yue,Yue Liu*

Main category: cs.SI

TL;DR: FNGCN通过利用特征网络表示局部中心性之间的关系，并结合图卷积网络，更准确地识别复杂网络中的有影响力节点。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只考虑网络结构的一个方面，要么使用耗时较长的全局中心性作为节点特征来识别有影响力节点，并且没有考虑不同中心性之间的关系。本研究旨在解决这些问题。

Method: 提出了一种基于特征网络的图卷积网络框架（FNGCN），该框架利用特征网络来表示局部中心性之间的复杂关系，从而确定最合适的局部中心性。该框架结合了浅层和深层图卷积网络。

Result: 通过与广泛使用的SIR模型获得的真实数据进行比较，实验结果表明，两种FNGCN模型比现有方法能更准确地识别有影响力节点。

Conclusion: FNGCN框架在识别复杂网络中的有影响力节点方面是有效的，并且比现有方法更准确。

Abstract: Identifying influential nodes in complex networks is of great importance, and
has many applications in practice. For example, finding influential nodes in
e-commerce network can provide merchants with customers with strong purchase
intent; identifying influential nodes in computer information system can help
locating the components that cause the system break down and identifying
influential nodes in these networks can accelerate the flow of information in
networks. Thus, a lot of efforts have been made on the problem of indentifying
influential nodes. However, previous efforts either consider only one aspect of
the network structure, or using global centralities with high time consuming as
node features to identify influential nodes, and the existing methods do not
consider the relationships between different centralities. To solve these
problems, we propose a Graph Convolutional Network Framework based on Feature
Network, abbreviated as FNGCN (graph convolutional network is abbreviated as
GCN in the following text). Further, to exclude noises and reduce redundency,
FNGCN utilizes feature network to represent the complicated relationships among
the local centralities, based on which the most suitable local centralities are
determined. By taking a shallow GCN and a deep GCN into the FNGCN framework,
two FNGCNs are developed. With ground truth obtained from the widely used
Susceptible Infected Recovered (SIR) model, the two FNGCNs are compared with
the state-of-art methods on several real-world networks. Experimental results
show that the two FNGCNs can identify the influential nodes more accurately
than the compared methods, indicating that the proposed framework is effective
in identifying influential nodes in complex networks.

</details>


### [338] [Long-term resilience of online battle over vaccines and beyond](https://arxiv.org/abs/2508.01398)
*Lucia Illari,Nicholas J. Restrepo,Neil F. Johnson*

Main category: cs.SI

TL;DR: 尽管在推广疫苗科学方面投入了大量资源，但Facebook上关于疫苗接种的在线观点网络结构并未改变。研究提出了一种新的“网络工程”方法来解决这个问题，而不是依赖内容审查。


<details>
  <summary>Details</summary>
Motivation: 评估在COVID-19前后，投入大量资源推广疫苗科学所产生的影响。

Method: 通过跟踪1356个相互关联的社区，分析了约1亿Facebook页面成员之间关于支持和反对疫苗接种的观点的在线竞争。

Result: 尽管付出了巨大努力，但在线支持和反对疫苗接种的观点之间的网络基本结构没有改变，专业知识的孤立以及反对和主流中立社区的共生现象依然存在。这种韧性源于“全球化”演变，社区融合了多个主题，并连接了从邻里到国际的各个层级，形成了超越类别针对的冗余路径。

Conclusion: 即使投入相同的时间、精力和金钱，情况也可能不会改变。未来的解决方案是通过网络工程方法进行结构干预，以实现观点缓和，而不是移除内容。

Abstract: What has been the impact of the enormous amounts of time, effort and money
spent promoting pro-vaccine science from pre-COVID-19 to now? We answer this
using a unique mapping of online competition between pro- and anti-vaccination
views among ~100M Facebook Page members, tracking 1,356 interconnected
communities through platform interventions. Remarkably, the network's
fundamental architecture shows no change: the isolation of established
expertise and the symbiosis of anti and mainstream neutral communities persist.
This means that even if the same time, effort and money continue to be spent,
nothing will likely change. The reason for this resilience lies in "glocal"
evolution: Communities blend multiple topics while bridging neighborhood-level
to international scales, creating redundant pathways that transcend categorical
targeting. The solution going forward is to focus on the system's network. We
show how network engineering approaches can achieve opinion moderation without
content removal, representing a paradigm shift from suppression towards
structural interventions.

</details>


### [339] [A Parallel Algorithm for Finding Robust Spanners in Large Social Networks](https://arxiv.org/abs/2508.01485)
*Arindam Khanda,Satyaki Roy,Prithwiraj Roy,Sajal K. Das*

Main category: cs.SI

TL;DR: 提出了一种识别鲁棒性节点（RS）的新方法，这些节点可以在社交网络中的中断期间促进社区之间的信息传播。所提出的算法在大规模网络中具有高效性，并且比传统方法更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 社交网络的动态特性，特别是生成器节点的移除，要求需要有弹性的方法来维持社区间的通信。

Method: 提出了一种新的评分技术来识别 RS 节点，并提出了一种具有 CUDA 实现的并行算法，用于在大规模网络中高效检测 RS。

Result: 与传统的生成器检测算法相比，高分节点表现出相当的生成能力，并具有更强的鲁棒性。

Conclusion: 所提出的鲁棒性节点（RS）能够有效弥合社区，即使在节点或连接被移除的情况下。所提出的算法在英伟达 GPU 上实现了 244 倍的平均加速。

Abstract: Social networks, characterized by community structures, often rely on nodes
called structural hole spanners to facilitate inter-community information
dissemination. However, the dynamic nature of these networks, where spanner
nodes may be removed, necessitates resilient methods to maintain
inter-community communication. To this end, we introduce robust spanners (RS)
as nodes uniquely equipped to bridge communities despite disruptions, such as
node or edge removals. We propose a novel scoring technique to identify RS
nodes and present a parallel algorithm with a CUDA implementation for efficient
RS detection in large networks. Empirical analysis of real-world social
networks reveals that high-scoring nodes exhibit a spanning capacity comparable
to those identified by benchmark spanner detection algorithms while offering
superior robustness. Our implementation on Nvidia GPUs achieves an average
speedup of 244X over traditional spanner detection techniques, demonstrating
its efficacy to identify RS in large social networks.

</details>


### [340] [Social Media Information Operations](https://arxiv.org/abs/2508.01552)
*Tauhid Zaman,Yen-Shao Chen*

Main category: cs.SI

TL;DR: 本教程提出了一种在社交媒体上进行信息运维的优化框架，通过分析工具（如中心性度量、聚类和情感分析）来理解网络，识别威胁（如机器人网络、虚假信息），并提出对策（如内容干预、优化策略）。生成式AI正在改变攻防能力，需要新的算法、政策和伦理来应对。


<details>
  <summary>Details</summary>
Motivation: 信息战的战场已转移到在线社交网络，影响活动以前所未有的速度和规模运作。与任何战略领域一样，成功需要理解地形、模拟对手和执行干预。

Method: 本教程介绍了一个用于社交媒体信息运维（IO）的正式优化框架，旨在通过有针对性的行动来塑造舆论。该框架由网络结构、用户意见和活动水平等数量参数化，这些都需要从数据中估计或推断。

Result: 讨论了支持此过程的分析工具，包括用于识别有影响力的用户的中心性度量、用于检测社区结构的聚类算法以及用于衡量公众意见的情感分析。这些工具要么直接用于优化流程，要么帮助防御分析师解释信息环境。在绘制好格局之后，我们强调了诸如协同机器人网络、极端主义招募和病毒式错误信息等威胁。对策范围从内容级干预到数学优化的影响策略。

Conclusion: 生成式AI正在改变信息战的攻防格局，既能民主化劝说能力，也能实现可扩展防御。这种转变需要算法创新、政策改革和伦理警惕，以保护数字公共领域的完整性。

Abstract: The battlefield of information warfare has moved to online social networks,
where influence campaigns operate at unprecedented speed and scale. As with any
strategic domain, success requires understanding the terrain, modeling
adversaries, and executing interventions. This tutorial introduces a formal
optimization framework for social media information operations (IO), where the
objective is to shape opinions through targeted actions. This framework is
parameterized by quantities such as network structure, user opinions, and
activity levels - all of which must be estimated or inferred from data. We
discuss analytic tools that support this process, including centrality measures
for identifying influential users, clustering algorithms for detecting
community structure, and sentiment analysis for gauging public opinion. These
tools either feed directly into the optimization pipeline or help defense
analysts interpret the information environment. With the landscape mapped, we
highlight threats such as coordinated bot networks, extremist recruitment, and
viral misinformation. Countermeasures range from content-level interventions to
mathematically optimized influence strategies. Finally, the emergence of
generative AI transforms both offense and defense, democratizing persuasive
capabilities while enabling scalable defenses. This shift calls for algorithmic
innovation, policy reform, and ethical vigilance to protect the integrity of
our digital public sphere.

</details>


### [341] [Leveraging Social Media Sentiment for Predictive Algorithmic Trading Strategies](https://arxiv.org/abs/2508.02089)
*Gatik Goyal,Sharvil Phadke,Arnav Sharma,Huifang Qin*

Main category: cs.SI

TL;DR: 通过分析Reddit评论，我们开发了一种名为“情绪量变化”（SVC）的新指标，该指标结合了情绪和评论量，能够比单独的情绪指标更有效地预测股票价格。基于SVC的投资策略在牛市中表现出色，回报率显著高于传统策略，同时在熊市中也能有效降低损失，证明了社交媒体情绪作为投资工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用从Reddit评论中提取的社交媒体情绪来改进投资决策，以期在降低风险的同时获得更高回报。

Method: 利用BERTweet分析了超过200万条Reddit评论，开发了一种结合了情绪和评论量变化的“情绪量变化”（SVC）指标，并制定了两种仅依赖SVC进行决策的投资策略。

Result: 与单独的情绪指标相比，SVC与次日回报的相关性显著提高。在2020-2023年的四年时间里，基于SVC的策略在牛市中表现明显优于比较性买入并持有（B&H）策略，在2023年和2021年分别实现了70%和84.4%的更高回报，并在2022年下跌市场中将损失降低了4%。

Conclusion: 社会媒体情绪和交易量数据，特别是来自Reddit的r/wallstreetbets板块的数据，可以有效预测短期股票价格波动，并且基于情绪的策略可以提供优于市场的风险调整后回报，表明社会媒体情绪有潜力成为有价值的投资工具。

Abstract: This study investigates how social media sentiment derived from Reddit
comments can be used to enhance investment decisions in a way that offers
higher returns with lower risk. Using BERTweet we analyzed over 2 million
Reddit comments from the subreddit r/wallstreetbets and developed a Sentiment
Volume Change (SVC) metric combining sentiment and comment volume changes,
which showed significantly improved correlation with next-day returns compared
to sentiment alone. We then implemented two different investment strategies
that relied solely on SVC to make decisions. Back testing these strategies over
four years (2020-2023) our strategies significantly outperformed a comparable
buy-and-hold (B&H) strategy in a bull market, achieving 70% higher returns in
2023 and 84.4% higher returns in 2021 while also mitigating losses by 4% in a
declining market in 2022. Our results confirm that comment sentiment and volume
data derived from Reddit can be effective in predicting short-term stock price
movements and sentiment-powered strategies can offer superior risk-adjusted
returns as compared to the market, implying that social media sentiment can
potentially be a valuable investment tool.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [342] [Revisiting Gossip Protocols: A Vision for Emergent Coordination in Agentic Multi-Agent Systems](https://arxiv.org/abs/2508.01531)
*Mansura Habiba,Nafiul I. Khan*

Main category: cs.MA

TL;DR: Agentic platforms need better coordination. While structured protocols are good for tasks, they lack emergent intelligence. This paper suggests using gossip protocols, known for their robustness in distributed systems, to improve communication by enabling scalable knowledge sharing and collective cognition. It outlines a research agenda to integrate gossip with existing protocols, addressing challenges like information filtering and trustworthiness, to build more resilient and self-organizing multi-agent systems.


<details>
  <summary>Details</summary>
Motivation: The increasing scale and complexity of agentic platforms necessitate flexible, decentralized coordination mechanisms beyond traditional structured communication protocols to enable emergent, swarm-like intelligence.

Method: The paper revisits gossip protocols, analyzes their strengths and weaknesses in the context of agentic AI, and charts a research agenda for their integration.

Result: The paper identifies critical gaps in current agent-to-agent architectures and highlights how gossip protocols could reshape assumptions about coordination, focusing on intent propagation, knowledge decay, and peer-to-peer trust.

Conclusion: The paper argues that gossip protocols can serve as a complementary substrate alongside structured protocols for agentic AI, addressing limitations in emergent, swarm-like intelligence and collective cognition. It identifies research gaps and outlines open questions for integrating gossip into agent-to-agent architectures.

Abstract: As agentic platforms scale, agents are evolving beyond static roles and fixed
toolchains, creating a growing need for flexible, decentralized coordination.
Today's structured communication protocols (e.g., direct agent-to-agent
messaging) excel at reliability and task delegation, but they fall short in
enabling emergent, swarm-like intelligence, where distributed agents
continuously learn, adapt, and communicate to form collective cognition. This
paper revisits gossip protocols, long valued in distributed systems for their
fault tolerance and decentralization, and argues that they offer a missing
layer for context-rich, adaptive communication in agentic AI. Gossip enables
scalable, low-overhead dissemination of shared knowledge, but also raises
unresolved challenges around semantic filtering, staleness, trustworthiness,
and consistency in high-stakes environments. Rather than proposing a new
framework, this work charts a research agenda for integrating gossip as a
complementary substrate alongside structured protocols. We identify critical
gaps in current agent-to-agent architectures, highlight where gossip could
reshape assumptions about coordination, and outline open questions around
intent propagation, knowledge decay, and peer-to-peer trust. Gossip is not a
silver bullet, but overlooking it risks missing a key path toward resilient,
reflexive, and self-organizing multi-agent systems.

</details>


### [343] [A Group Consensus-Driven Auction Algorithm for Cooperative Task Allocation Among Heterogeneous Multi-Agents](https://arxiv.org/abs/2508.02015)
*Gang Wang,Hongfang Han,Xiaowei Liu,Hanfeng Jiang,Ming Zhang*

Main category: cs.MA

TL;DR: GCBHA是一种用于自动化仓库等场景的分布式异构多任务和多代理任务分配算法，通过任务分解、聚类和拍卖机制优化任务分配，并提高成本预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有任务分配研究忽略了多任务、多属性代理任务分配与异构任务分配的整合，并且当前算法受场景约束限制，在特定情况下会产生显著错误。

Method: GCBHA通过将大任务分解为子任务，并将相似或相邻任务进行聚类，然后通过拍卖过程将任务组分配给符合条件的代理来解决异构多任务和多代理任务分配问题。它还考虑了时间窗口和基于场景的任务路径成本距离。

Result: 实验结果表明，GCBHA在任务分配时间和解决方案质量方面表现良好，预测任务成本与实际成本之间的错误率显著降低。

Conclusion: GCBHA在任务分配时间和解决方案质量方面表现良好，预测任务成本与实际成本之间的错误率显著降低。

Abstract: In scenarios like automated warehouses, assigning tasks to robots presents a
heterogeneous multi-task and multi-agent task allocation problem. However,
existing task allocation study ignores the integration of multi-task and
multi-attribute agent task allocation with heterogeneous task allocation. In
addition, current algorithms are limited by scenario constraints and can incur
significant errors in specific contexts. Therefore, this study proposes a
distributed heterogeneous multi-task and multi-agent task allocation algorithm
with a time window, called group consensus-based heterogeneous auction (GCBHA).
Firstly, this method decomposes tasks that exceed the capability of a single
Agent into subtasks that can be completed by multiple independent agents. And
then groups similar or adjacent tasks through a heuristic clustering method to
reduce the time required to reach a consensus. Subsequently, the task groups
are allocated to agents that meet the conditions through an auction process.
Furthermore, the method evaluates the task path cost distance based on the
scenario, which can calculate the task cost more accurately. The experimental
results demonstrate that GCBHA performs well in terms of task allocation time
and solution quality, with a significant reduction in the error rate between
predicted task costs and actual costs.

</details>


### [344] [Emergence of Fair Leaders via Mediators in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.02421)
*Akshay Dodwadmath,Setareh Maghsudi*

Main category: cs.MA

TL;DR: 该研究通过引入中介者，解决强化学习中Stackelberg博弈的领导者选择问题，提高了智能体回报的公平性。


<details>
  <summary>Details</summary>
Motivation: 在传统Stackelberg博弈中，领导者和追随者的角色固定，但当角色可以互换时，选择谁担任领导者会带来显著优势，然而不公平的领导者选择会导致不公平的收益分配，尤其是在自利智能体的情况下。因此，研究的动机在于解决这种领导者选择问题并提高公平性。

Method: 提出了一种多智能体强化学习框架，该框架通过整合中介者来解决领导者选择问题，并通过最大化公平性来实现目标。

Result: 在中介者的协助下，即使在自利智能体的情况下，也能实现公平的行动选择，从而提高整体回报的公平性。

Conclusion: 该研究提出了一种整合了中介者的多智能体强化学习框架，用于解决领导者选择问题，并通过最小化控制（领导者选择）实现了公平性。结果表明，中介者的存在可以促使自利智能体采取公平行动，从而提高整体回报的公平性。

Abstract: Stackelberg games and their resulting equilibria have received increasing
attention in the multi-agent reinforcement learning literature. Each stage of a
traditional Stackelberg game involves a leader(s) acting first, followed by the
followers. In situations where the roles of leader(s) and followers can be
interchanged, the designated role can have considerable advantages, for
example, in first-mover advantage settings. Then the question arises: Who
should be the leader and when? A bias in the leader selection process can lead
to unfair outcomes. This problem is aggravated if the agents are
self-interested and care only about their goals and rewards. We formally define
this leader selection problem and show its relation to fairness in agents'
returns. Furthermore, we propose a multi-agent reinforcement learning framework
that maximizes fairness by integrating mediators. Mediators have previously
been used in the simultaneous action setting with varying levels of control,
such as directly performing agents' actions or just recommending them. Our
framework integrates mediators in the Stackelberg setting with minimal control
(leader selection). We show that the presence of mediators leads to
self-interested agents taking fair actions, resulting in higher overall
fairness in agents' returns.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [345] [Sparse 3D Perception for Rose Harvesting Robots: A Two-Stage Approach Bridging Simulation and Real-World Applications](https://arxiv.org/abs/2508.00900)
*Taha Samavati,Mohsen Soryani,Sina Mansouri*

Main category: cs.RO

TL;DR: 为花卉采摘机器人开发了一种3D感知流程，使用合成数据和深度学习进行花朵定位，提高了收获效率和自动化水平。


<details>
  <summary>Details</summary>
Motivation: 为了解决人口增长导致的药用植物（如大马士革玫瑰）需求激增，但劳动密集型收获限制了规模化的问题。

Method: 提出了一种新颖的3D感知流程，用于花卉采摘机器人，通过2D点状检测和轻量级深度学习模型进行稀疏3D定位。利用Blender生成的合成数据集克服了真实世界标签数据稀缺的问题。

Result: 所提出的方法在2D检测中达到了95.6%（合成数据）和74.4%（真实数据）的F1分数，在2米范围内深度估计误差为3%（合成数据）。该流程计算效率高，可兼容资源受限的机器人系统。

Conclusion: 该方法通过结合合成数据和深度学习，为花卉采摘机器人提供了一种可扩展的解决方案，并在提高农业自动化方面取得了进展。

Abstract: The global demand for medicinal plants, such as Damask roses, has surged with
population growth, yet labor-intensive harvesting remains a bottleneck for
scalability. To address this, we propose a novel 3D perception pipeline
tailored for flower-harvesting robots, focusing on sparse 3D localization of
rose centers. Our two-stage algorithm first performs 2D point-based detection
on stereo images, followed by depth estimation using a lightweight deep neural
network. To overcome the challenge of scarce real-world labeled data, we
introduce a photorealistic synthetic dataset generated via Blender, simulating
a dynamic rose farm environment with precise 3D annotations. This approach
minimizes manual labeling costs while enabling robust model training. We
evaluate two depth estimation paradigms: a traditional triangulation-based
method and our proposed deep learning framework. Results demonstrate the
superiority of our method, achieving an F1 score of 95.6% (synthetic) and 74.4%
(real) in 2D detection, with a depth estimation error of 3% at a 2-meter range
on synthetic data. The pipeline is optimized for computational efficiency,
ensuring compatibility with resource-constrained robotic systems. By bridging
the domain gap between synthetic and real-world data, this work advances
agricultural automation for specialty crops, offering a scalable solution for
precision harvesting.

</details>


### [346] [A Survey on Deep Multi-Task Learning in Connected Autonomous Vehicles](https://arxiv.org/abs/2508.00917)
*Jiayuan Wang,Farhad Pourpanah,Q. M. Jonathan Wu,Ning Zhang*

Main category: cs.RO

TL;DR: 这是一份关于网联自动驾驶汽车（CAVs）中多任务学习（MTL）的综合性调查报告，旨在解决CAVs多任务处理带来的挑战，并为未来研究提供方向。


<details>
  <summary>Details</summary>
Motivation: 解决CAVs多任务处理带来的高部署成本、计算开销和实时性挑战，利用MTL实现联合学习以提高效率和资源利用率。

Method: 对CAVs和MTL进行概述，然后探讨MTL在感知、预测、规划、控制和多智能体协作等关键功能模块中的应用，最后讨论现有方法的优缺点、研究空白和未来方向。

Result: 该调查全面回顾了MTL在CAVs中的应用，为CAVs系统的前沿研究提供了基础。

Conclusion: 未来研究应致力于提升多任务学习（MTL）方法在网联自动驾驶汽车（CAVs）系统中的性能和效率。

Abstract: Connected autonomous vehicles (CAVs) must simultaneously perform multiple
tasks, such as object detection, semantic segmentation, depth estimation,
trajectory prediction, motion prediction, and behaviour prediction, to ensure
safe and reliable navigation in complex environments. Vehicle-to-everything
(V2X) communication enables cooperative driving among CAVs, thereby mitigating
the limitations of individual sensors, reducing occlusions, and improving
perception over long distances. Traditionally, these tasks are addressed using
distinct models, which leads to high deployment costs, increased computational
overhead, and challenges in achieving real-time performance. Multi-task
learning (MTL) has recently emerged as a promising solution that enables the
joint learning of multiple tasks within a single unified model. This offers
improved efficiency and resource utilization. To the best of our knowledge,
this survey is the first comprehensive review focused on MTL in the context of
CAVs. We begin with an overview of CAVs and MTL to provide foundational
background. We then explore the application of MTL across key functional
modules, including perception, prediction, planning, control, and multi-agent
collaboration. Finally, we discuss the strengths and limitations of existing
methods, identify key research gaps, and provide directions for future research
aimed at advancing MTL methodologies for CAV systems.

</details>


### [347] [BarlowWalk: Self-supervised Representation Learning for Legged Robot Terrain-adaptive Locomotion](https://arxiv.org/abs/2508.00939)
*Haodong Huang,Shilong Sun,Yuanpeng Wang,Chiyao Li,Hailin Huang,Wenfu Xu*

Main category: cs.RO

TL;DR: BarlowWalk是一种改进的PPO强化学习方法，通过自监督表示学习减少了训练时间和对外部感知的依赖，在机器人复杂地形行走任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人腿部运动控制中，主流强化学习方法（如教师-学生策略知识蒸馏）训练时间长、限制开发效率的问题。

Method: 提出了一种改进的近端策略优化（PPO）方法，结合了Barlow Twins算法进行自监督表示学习，构建了解耦的潜在空间，并将历史观测序列映射到低维表示。Actor仅需本体感受信息即可实现跨连续时间步的自监督学习，减少了对外部地形感知的依赖。

Result: BarlowWalk方法能够显著减少对外部地形感知的依赖，在复杂地形场景下具有明显优势，并通过与先进算法的对比测试验证了其有效性。

Conclusion: BarlowWalk方法在复杂地形场景下表现出显著优势，实验结果验证了其有效性。

Abstract: Reinforcement learning (RL), driven by data-driven methods, has become an
effective solution for robot leg motion control problems. However, the
mainstream RL methods for bipedal robot terrain traversal, such as
teacher-student policy knowledge distillation, suffer from long training times,
which limit development efficiency. To address this issue, this paper proposes
BarlowWalk, an improved Proximal Policy Optimization (PPO) method integrated
with self-supervised representation learning. This method employs the Barlow
Twins algorithm to construct a decoupled latent space, mapping historical
observation sequences into low-dimensional representations and implementing
self-supervision. Meanwhile, the actor requires only proprioceptive information
to achieve self-supervised learning over continuous time steps, significantly
reducing the dependence on external terrain perception. Simulation experiments
demonstrate that this method has significant advantages in complex terrain
scenarios. To enhance the credibility of the evaluation, this study compares
BarlowWalk with advanced algorithms through comparative tests, and the
experimental results verify the effectiveness of the proposed method.

</details>


### [348] [Service Discovery-Based Hybrid Network Middleware for Efficient Communication in Distributed Robotic Systems](https://arxiv.org/abs/2508.00947)
*Shiyao Sang,Yinggang Ling*

Main category: cs.RO

TL;DR: RIMAOS2C是一种用于自动驾驶汽车的新型机器人中间件，通过服务发现和消息桥接优化通信，提高了数据传输效率和降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有机器人中间件在满足多样化通信需求、优化数据传输效率以及维持大规模L4自动驾驶车辆部署中Orin计算单元间的调度确定性方面存在挑战。

Method: 提出了一种名为RIMAOS2C的，基于服务发现的混合网络通信中间件，该中间件利用多级服务发现多播，支持多种通信模式，并通过消息桥接优化数据流转发，采用共享内存进行集中消息分发，以减少消息冗余和传输延迟不确定性。

Result: 在L4车辆和Jetson Orin域控制器上测试表明，RIMAOS2C利用基于TCP的ZeroMQ克服了原生CyberRT中的大消息传输瓶颈。在具有两个跨芯片订阅者的场景中，消息冗余被消除，大-数据传输效率提高了36%至40%，回调延迟变异性降低了42%至906%。

Conclusion: 该研究通过RIMAOS2C提高了机器人操作系统通信能力，并为自动驾驶分布式计算架构的通信优化提出了新方法。

Abstract: Robotic middleware is fundamental to ensuring reliable communication among
system components and is crucial for intelligent robotics, autonomous vehicles,
and smart manufacturing. However, existing robotic middleware often struggles
to meet the diverse communication demands, optimize data transmission
efficiency, and maintain scheduling determinism between Orin computing units in
large-scale L4 autonomous vehicle deployments. This paper presents RIMAOS2C, a
service discovery-based hybrid network communication middleware designed to
tackle these challenges. By leveraging multi-level service discovery multicast,
RIMAOS2C supports a wide variety of communication modes, including multiple
cross-chip Ethernet protocols and PCIe communication capabilities. Its core
mechanism, the Message Bridge, optimizes data flow forwarding and employs
shared memory for centralized message distribution, reducing message redundancy
and minimizing transmission delay uncertainty. Tested on L4 vehicles and Jetson
Orin domain controllers, RIMAOS2C leverages TCP-based ZeroMQ to overcome the
large-message transmission bottleneck in native CyberRT. In scenarios with two
cross-chip subscribers, it eliminates message redundancy and improves
large-data transmission efficiency by 36 to 40 percent while reducing callback
latency variation by 42 to 906 percent. This research advances the
communication capabilities of robotic operating systems and proposes a novel
approach to optimizing communication in distributed computing architectures for
autonomous driving.

</details>


### [349] [Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.01522)
*Jack Zeng,Andreu Matoses Gimenez,Eugene Vinitsky,Javier Alonso-Mora,Sihao Sun*

Main category: cs.RO

TL;DR: 本研究提出了首个去中心化方法，利用多智能体强化学习 (MARL) 使一组微型飞行器 (MAVs) 能够对 kabelSuspended 负载进行现实世界 6-DoF 操作。该方法通过负载姿态观测进行隐式通信，无需全局状态或 MAV 间通信，从而提高了可扩展性和灵活性，并降低了计算成本。实验证明，该方法在负载模型不确定性下的全姿态控制方面表现出色，性能可与最先进的集中式方法相媲美，并展示了对 MA V 丢失的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本篇论文提出了第一种能够使用一组微型飞行器 (MAVs) 在现实世界中对 kabelSuspended 负载进行 6-DoF 操作的去中心化方法。

Method: 提出了一种新颖的动作空间设计，使用线性加速度和机体速率，并结合鲁棒的低级控制器，即使在动态 3D 运动中存在由拉力引起的显著不确定性，也能实现可靠的仿真到现实传输。该方法利用多智能体强化学习 (MARL) 为每个 MAV 训练外环控制策略，该策略不需要全局状态、MAV 间通信或邻近 MAV 信息。

Result: 所提出的去中心化方法利用多智能体强化学习 (MARL) 来训练每个 MAV 的外环控制策略。该方法不需要全局状态、MAV 间的通信或邻近 MAV 的信息，而是仅通过负载姿态观测进行隐式通信，这使得该方法具有高度的可扩展性和灵活性。此外，该方法显著降低了推理成本，并实现了策略的机载部署。

Conclusion: 该方法在各种现实世界实验中得到了验证，包括在负载模型不确定性下的全姿态控制，展示了可与最先进的集中式方法相媲美的设定点跟踪性能。此外，还演示了具有异构控制策略的代理之间的协作，以及对其中一个 MAV 完全空中丢失的鲁棒性。

Abstract: This paper presents the first decentralized method to enable real-world 6-DoF
manipulation of a cable-suspended load using a team of Micro-Aerial Vehicles
(MAVs). Our method leverages multi-agent reinforcement learning (MARL) to train
an outer-loop control policy for each MAV. Unlike state-of-the-art controllers
that utilize a centralized scheme, our policy does not require global states,
inter-MAV communications, nor neighboring MAV information. Instead, agents
communicate implicitly through load pose observations alone, which enables high
scalability and flexibility. It also significantly reduces computing costs
during inference time, enabling onboard deployment of the policy. In addition,
we introduce a new action space design for the MAVs using linear acceleration
and body rates. This choice, combined with a robust low-level controller,
enables reliable sim-to-real transfer despite significant uncertainties caused
by cable tension during dynamic 3D motion. We validate our method in various
real-world experiments, including full-pose control under load model
uncertainties, showing setpoint tracking performance comparable to the
state-of-the-art centralized method. We also demonstrate cooperation amongst
agents with heterogeneous control policies, and robustness to the complete
in-flight loss of one MAV. Videos of experiments:
https://autonomousrobots.nl/paper_websites/aerial-manipulation-marl

</details>


### [350] [Hestia: Hierarchical Next-Best-View Exploration for Systematic Intelligent Autonomous Data Collection](https://arxiv.org/abs/2508.01014)
*Cheng-You Lu,Zhuoli Zhuang,Nguyen Thanh Trung Le,Da Xiao,Yu-Cheng Chang,Thomas Do,Srinath Sridhar,Chin-teng Lin*

Main category: cs.RO

TL;DR: Hestia 是一种利用强化学习自主收集 3D 数据的新方法，通过无人机进行现实世界演示。


<details>
  <summary>Details</summary>
Motivation: 为了解决手动数据收集过程耗时且费力的问题，该研究提出了一种新的方法。

Method: 该研究引入了用于系统智能自主数据收集的分层下一次最佳视角探索 (Hestia)，该技术利用强化学习来学习可泛化的 5-DoF 下一次最佳视角预测策略。

Result: Hestia 在三个数据集和 NVIDIA IsaacLab 环境中的可翻译对象设置中表现稳健，并被证明适用于现实世界的部署。

Conclusion: Hestia 在三个数据集和 NVIDIA IsaacLab 环境中的可翻译对象设置中表现稳健，并被证明适用于现实世界的部署。

Abstract: Advances in 3D reconstruction and novel view synthesis have enabled
efficient, photorealistic rendering, but the data collection process remains
largely manual, making it time-consuming and labor-intensive. To address the
challenges, this study introduces Hierarchical Next-Best-View Exploration for
Systematic Intelligent Autonomous Data Collection (Hestia), which leverages
reinforcement learning to learn a generalizable policy for 5-DoF next-best
viewpoint prediction. Unlike prior approaches, Hestia systematically defines
the next-best-view task by proposing core components such as dataset choice,
observation design, action space, reward calculation, and learning schemes,
forming a foundation for the planner. Hestia goes beyond prior next-best-view
approaches and traditional capture systems through integration and validation
in a real-world setup, where a drone serves as a mobile sensor for active scene
exploration. Experimental results show that Hestia performs robustly across
three datasets and translated object settings in the NVIDIA IsaacLab
environment, and proves feasible for real-world deployment.

</details>


### [351] [Learning Pivoting Manipulation with Force and Vision Feedback Using Optimization-based Demonstrations](https://arxiv.org/abs/2508.01082)
*Yuki Shirai,Kei Ota,Devesh K. Jha,Diego Romeres*

Main category: cs.RO

TL;DR: 该研究提出了一种结合了模型驱动和学习驱动方法的支点操作框架，以实现高效和鲁棒的操作。该框架利用接触隐式轨迹优化（CITO）和深度强化学习（RL），并通过特权训练策略实现了模拟到现实的迁移，仅使用本体感觉、视觉和力传感即可进行操作。


<details>
  <summary>Details</summary>
Motivation: 模型驱动的方法在处理接触约束下的复杂轨迹方面效率很高，但它们对模型不准确敏感，并且需要特权信息（例如，物体的质量、大小、姿势），这限制了它们在处理新颖物体时的适用性。基于学习的方法对模型误差更具鲁棒性，但需要大量数据。因此，有必要结合这两种方法。

Method: 该框架结合了基于模型和基于学习的方法，利用计算上可行的接触隐式轨迹优化（CITO）来设计演示引导的深度强化学习（RL），以实现样本有效的学习。此外，还提出了一种使用特权训练策略的模拟到现实迁移方法。

Result: 该方法在几个支点操作任务上进行了评估，结果表明它可以成功地执行模拟到现实的迁移。

Conclusion: 该方法成功地实现了模拟到现实的迁移，并可在机器人执行支点操作时仅使用本体感觉、视觉和力传感，而无需访问特权信息。

Abstract: Non-prehensile manipulation is challenging due to complex contact
interactions between objects, the environment, and robots. Model-based
approaches can efficiently generate complex trajectories of robots and objects
under contact constraints. However, they tend to be sensitive to model
inaccuracies and require access to privileged information (e.g., object mass,
size, pose), making them less suitable for novel objects. In contrast,
learning-based approaches are typically more robust to modeling errors but
require large amounts of data. In this paper, we bridge these two approaches to
propose a framework for learning closed-loop pivoting manipulation. By
leveraging computationally efficient Contact-Implicit Trajectory Optimization
(CITO), we design demonstration-guided deep Reinforcement Learning (RL),
leading to sample-efficient learning. We also present a sim-to-real transfer
approach using a privileged training strategy, enabling the robot to perform
pivoting manipulation using only proprioception, vision, and force sensing
without access to privileged information. Our method is evaluated on several
pivoting tasks, demonstrating that it can successfully perform sim-to-real
transfer.

</details>


### [352] [Improving Drone Racing Performance Through Iterative Learning MPC](https://arxiv.org/abs/2508.01103)
*Haocheng Zhao,Niklas Schlüter,Lukas Brunke,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 通过改进 LMPC，实现了无人机竞速性能的提升，缩短了单圈时间并提高了安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管迭代学习模型预测控制（LMPC）为提高无人机竞速性能提供了一个有前景的框架，但它在实时性、最优轨迹与安全穿越之间的权衡方面面临挑战。

Method: 通过引入自适应成本函数、移位局部安全集以及基于笛卡尔坐标的公式来改进迭代学习模型预测控制（LMPC），以解决无人机竞速中的实时性、最优性和安全性问题。

Result: 通过广泛的模拟和真实世界实验，证明了改进后的算法能够优化由不同控制器生成的初始轨迹，最多可将单圈时间缩短 60.85%。即使在真实无人机上应用于最先进的基于模型的控制器 MPCC++ 时，也能实现 6.05% 的改进。

Conclusion: 该方法提高了无人机在模拟和真实世界实验中的速度并避免了碰撞，为提高无人机竞速峰值性能提供了一个实用的解决方案。

Abstract: Autonomous drone racing presents a challenging control problem, requiring
real-time decision-making and robust handling of nonlinear system dynamics.
While iterative learning model predictive control~(LMPC) offers a promising
framework for iterative performance improvement, its direct application to
drone racing faces challenges like real-time compatibility or the trade-off
between time-optimal and safe traversal. In this paper, we enhance LMPC with
three key innovations:~(1) an adaptive cost function that dynamically weights
time-optimal tracking against centerline adherence,~(2)~a shifted local safe
set to prevent excessive shortcutting and enable more robust iterative updates,
and~(3) a Cartesian-based formulation that accommodates safety constraints
without the singularities or integration errors associated with Frenet-frame
transformations. Results from extensive simulation and real-world experiments
demonstrate that our improved algorithm can optimize initial trajectories
generated by a wide range of controllers with varying levels of tuning for a
maximum improvement in lap time by 60.85\%. Even applied to the most
aggressively tuned state-of-the-art model-based controller, MPCC++, on a real
drone, a 6.05\% improvement is still achieved. Overall, the proposed method
pushes the drone toward faster traversal and avoids collisions in simulation
and real-world experiments, making it a practical solution to improve the peak
performance of drone racing.

</details>


### [353] [Human-Robot Red Teaming for Safety-Aware Reasoning](https://arxiv.org/abs/2508.01129)
*Emily Sheetz,Emma Zemler,Misha Savchenko,Connor Rainen,Erik Holum,Jodi Graf,Andrew Albright,Shaun Azimi,Benjamin Kuipers*

Main category: cs.RO

TL;DR: Human-robot red teaming helps robots learn to operate safely in high-risk environments by having humans and robots work together to identify and mitigate hazards, ultimately building trust for collaboration in critical tasks.


<details>
  <summary>Details</summary>
Motivation: There is a deficit in researching how robots are expected to perform tasks safely, especially in high-risk problem domains, and robots need to earn human operators' trust to be effective collaborators in safety-critical tasks.

Method: The proposed human-robot red teaming paradigm involves humans and robots collaborating to challenge assumptions and explore potential hazards, enabling robots to perform safety-aware reasoning, including hazard identification, risk assessment, risk mitigation, and safety reporting.

Result: The study demonstrates that human-robot red teaming enables teams to plan for safe task performance across various domains and that robots with different embodiments can learn to operate safely in diverse environments (lunar habitat and household) with varying safety definitions.

Conclusion: The human-robot red teaming paradigm is feasible for safely operating and promoting trust in human-robot teams within safety-critical domains.

Abstract: While much research explores improving robot capabilities, there is a deficit
in researching how robots are expected to perform tasks safely, especially in
high-risk problem domains. Robots must earn the trust of human operators in
order to be effective collaborators in safety-critical tasks, specifically
those where robots operate in human environments. We propose the human-robot
red teaming paradigm for safety-aware reasoning. We expect humans and robots to
work together to challenge assumptions about an environment and explore the
space of hazards that may arise. This exploration will enable robots to perform
safety-aware reasoning, specifically hazard identification, risk assessment,
risk mitigation, and safety reporting. We demonstrate that: (a) human-robot red
teaming allows human-robot teams to plan to perform tasks safely in a variety
of domains, and (b) robots with different embodiments can learn to operate
safely in two different environments -- a lunar habitat and a household -- with
varying definitions of safety. Taken together, our work on human-robot red
teaming for safety-aware reasoning demonstrates the feasibility of this
approach for safely operating and promoting trust on human-robot teams in
safety-critical problem domains.

</details>


### [354] [COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning](https://arxiv.org/abs/2508.01131)
*Sateesh Kumar,Shivin Dass,Georgios Pavlakos,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: COLLAGE是一种新的少样本模仿学习数据检索方法，通过结合多种特征和自适应权重，提高了策略训练的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少样本模仿学习中，使用单一特征距离启发式方法选择数据，这种方法只捕捉了相关信息的一个子集，并且可能引入错误的演示，例如由于相似的场景布局而检索到不相关的任务数据，或者选择具有不同目标的任务中的相似动作。因此，需要一种更有效的数据检索方法。

Method: COLLAGE是一种用于少样本模仿学习的集体数据聚合方法。它首先使用单一特征（例如外观、形状或语言相似性）对数据集进行预选择，然后根据在这些子集上训练的策略预测目标演示动作的性能来分配权重。最后，在策略训练中使用这些权重进行重要性采样，从而更密集或稀疏地采样数据。COLLAGE具有通用性和特征无关性，可以结合任何检索启发式选择的子集，并识别对目标任务最有益的子集。

Result: COLLAGE在模拟环境中跨10个任务的平均性能比最先进的检索和多任务学习方法提高了5.1%，在真实世界环境中跨6个任务的平均性能提高了16.6%。

Conclusion: COLLAGE通过自适应的 late fusion 机制，结合多线索的任务特定组合来指导相关演示的选择，相比于现有方法在模拟和真实世界环境中都取得了显著的性能提升。

Abstract: In this work, we study the problem of data retrieval for few-shot imitation
learning: selecting data from a large dataset to train a performant policy for
a specific task, given only a few target demonstrations. Prior methods retrieve
data using a single-feature distance heuristic, assuming that the best
demonstrations are those that most closely resemble the target examples in
visual, semantic, or motion space. However, this approach captures only a
subset of the relevant information and can introduce detrimental
demonstrations, e.g., retrieving data from unrelated tasks due to similar scene
layouts, or selecting similar motions from tasks with divergent goals. We
present COLLAGE, a method for COLLective data AGgrEgation in few-shot imitation
learning that uses an adaptive late fusion mechanism to guide the selection of
relevant demonstrations based on a task-specific combination of multiple cues.
COLLAGE follows a simple, flexible, and efficient recipe: it assigns weights to
subsets of the dataset that are pre-selected using a single feature (e.g.,
appearance, shape, or language similarity), based on how well a policy trained
on each subset predicts actions in the target demonstrations. These weights are
then used to perform importance sampling during policy training, sampling data
more densely or sparsely according to estimated relevance. COLLAGE is general
and feature-agnostic, allowing it to combine any number of subsets selected by
any retrieval heuristic, and to identify which subsets provide the greatest
benefit for the target task. In extensive experiments, COLLAGE outperforms
state-of-the-art retrieval and multi-task learning approaches by 5.1% in
simulation across 10 tasks, and by 16.6% in the real world across 6 tasks,
where we perform retrieval from the large-scale DROID dataset. More information
at https://robin-lab.cs.utexas.edu/COLLAGE .

</details>


### [355] [Design of Q8bot: A Miniature, Low-Cost, Dynamic Quadruped Built with Zero Wires](https://arxiv.org/abs/2508.01149)
*Yufeng Wu,Dennis Hong*

Main category: cs.RO

TL;DR: Q8bot：一种小巧、坚固、易于组装且高性能的开源四足机器人，适用于研究和教育。


<details>
  <summary>Details</summary>
Motivation: 机器人研究和教育领域需要一种小巧、坚固、易于复制且性能优越的机器人平台。

Method: 本文介绍了一种名为Q8bot的开源、微型化四足机器人，并阐述了其零线设计方法论。

Result: Q8bot的尺寸和重量与现代智能手机相当，续航超过一小时，并能承受从一米高处跌落后的简单修复。其物料成本约为300美元，使用了常见的现成组件、可在线购买的定制电子产品以及可通过3D打印制造的结构件。初步的用户组装研究表明，Q8bot易于复制，单人平均组装时间不到一小时。通过启发式开环控制，Q8bot实现了5.4倍身长/秒的稳定行走速度和5弧度/秒的转向速度，并能进行跳跃和攀爬缓坡等动态运动。

Conclusion: Q8bot是一个开源、微型化的四足机器人，适用于机器人研究和教育。它采用了新颖的零线设计方法，实现了优越的外形、鲁棒性、可复制性和高性能。

Abstract: This paper introduces Q8bot, an open-source, miniature quadruped designed for
robotics research and education. We present the robot's novel zero-wire design
methodology, which leads to its superior form factor, robustness,
replicability, and high performance. With a size and weight similar to a modern
smartphone, this standalone robot can walk for over an hour on a single battery
charge and survive meter-high drops with simple repairs. Its 300-dollar bill of
materials includes minimal off-the-shelf components, readily available custom
electronics from online vendors, and structural parts that can be manufactured
on hobbyist 3D printers. A preliminary user assembly study confirms that Q8bot
can be easily replicated, with an average assembly time of under one hour by a
single person. With heuristic open-loop control, Q8bot achieves a stable
walking speed of 5.4 body lengths per second and a turning speed of 5 radians
per second, along with other dynamic movements such as jumping and climbing
moderate slopes.

</details>


### [356] [Unified Generation-Refinement Planning: Bridging Flow Matching and Sampling-Based MPC](https://arxiv.org/abs/2508.01192)
*Kazuki Mizuta,Karen Leung*

Main category: cs.RO

TL;DR: 提出了一种结合CFM和MPPI的统一框架，通过双向信息交换，在保持安全性的同时提高了规划质量和适应性。


<details>
  <summary>Details</summary>
Motivation: 在动态、以人类为中心的环境中规划安全有效的机器人行为仍然是一个核心挑战，因为需要处理不确定性、实时适应并确保安全。基于优化的规划器虽然可以明确处理约束，但依赖于过于简化的初始条件，从而降低了解决方案的质量。基于学习的规划器能够更好地捕捉多模态的可能解决方案，但在强制执行安全等约束方面存在困难。

Method: 提出了一种结合学习和优化的统一生成-细化框架，利用新颖的奖励引导条件流匹配（CFM）模型和模型预测路径积分（MPPI）控制。其关键创新在于双向信息交换：来自奖励引导CFM模型的样本为MPPI的细化提供了先验信息，而MPPI的最优轨迹则为下一个CFM生成提供了热启动。

Result: 在以自主社交导航为应用场景的演示中，证明了该方法能够灵活适应动态环境并实时满足安全要求。

Conclusion: 该方法能够灵活适应动态环境并实时满足安全要求。

Abstract: Planning safe and effective robot behavior in dynamic, human-centric
environments remains a core challenge due to the need to handle uncertainty,
adapt in real-time, and ensure safety. Optimization-based planners offer
explicit constraint handling but rely on oversimplified initialization,
reducing solution quality. Learning-based planners better capture multimodal
possible solutions but struggle to enforce constraints such as safety. In this
paper, we introduce a unified generation-refinement framework bridging learning
and optimization with a novel reward-guided conditional flow matching (CFM)
model and model predictive path integral (MPPI) control. Our key innovation is
in the incorporation of a bidirectional information exchange: samples from a
reward-guided CFM model provide informed priors for MPPI refinement, while the
optimal trajectory from MPPI warm-starts the next CFM generation. Using
autonomous social navigation as a motivating application, we demonstrate that
our approach can flexibly adapt to dynamic environments to satisfy safety
requirements in real-time.

</details>


### [357] [Energy-Predictive Planning for Optimizing Drone Service Delivery](https://arxiv.org/abs/2508.01671)
*Guanting Ren,Babar Shahzaad,Balsam Alkouz,Abdallah Lakhdari,Athman Bouguettaya*

Main category: cs.RO

TL;DR: 提出了一种新的EPDS框架，使用Bi-LSTM预测无人机状态，并通过启发式方法优化路径和充电计划，以实现高效的包裹递送。


<details>
  <summary>Details</summary>
Motivation: 为了在天空网络内实现高效的包裹递送，提出了一种新颖的能量预测无人机服务（EPDS）框架。

Method: 该框架包含EPDS的正式模型和自适应双向长短期记忆（Bi-LSTM）机器学习模型，用于预测同一天空网络中其他无人机的能量状态和随机到达时间。利用这些预测，我们开发了一种用于复合无人机服务的启发式优化方法，以识别最高效的路径和充电计划。

Result: 该框架能够识别最高效的路径和充电计划。

Conclusion: 通过使用真实世界的无人机飞行数据集进行的大量实验评估了所提出框架的性能。

Abstract: We propose a novel Energy-Predictive Drone Service (EPDS) framework for
efficient package delivery within a skyway network. The EPDS framework
incorporates a formal modeling of an EPDS and an adaptive bidirectional Long
Short-Term Memory (Bi-LSTM) machine learning model. This model predicts the
energy status and stochastic arrival times of other drones operating in the
same skyway network. Leveraging these predictions, we develop a heuristic
optimization approach for composite drone services. This approach identifies
the most time-efficient and energy-efficient skyway path and recharging
schedule for each drone in the network. We conduct extensive experiments using
a real-world drone flight dataset to evaluate the performance of the proposed
framework.

</details>


### [358] [Coordinated Humanoid Robot Locomotion with Symmetry Equivariant Reinforcement Learning Policy](https://arxiv.org/abs/2508.01247)
*Buqing Nie,Yang Zhang,Rongjun Jin,Zhanxiang Cao,Huangxuan Lin,Xiaokang Yang,Yue Gao*

Main category: cs.RO

TL;DR: 通过引入对称性等变性和不变性，SE-Policy 提升了机器人运动的协调性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在控制人形机器人时忽略了其形态对称性，导致运动不协调且效果不佳。受到人类运动控制的启发，需要一种能够利用对称性来提升机器人运动表现的方法。

Method: 提出了一种名为 SE-Policy 的新深度强化学习框架，该框架在 actor 中强制执行对称性等变性，在 critic 中强制执行对称性不变性，从而保证了跨对称输入的行为一致性，实现了时空协调的运动。

Result: SE-Policy 框架在速度跟踪任务中，相较于现有最先进的方法，提高了高达 40% 的跟踪精度，并实现了更优越的时空协调性。该方法在仿真和现实世界（Unitree G1 型人形机器人）的部署中均表现出色。

Conclusion: SE-Policy 框架通过在 actor 中嵌入严格的对称性等变性和在 critic 中嵌入对称性不变性，解决了现有深度强化学习方法忽略人形机器人形态对称性导致行为不协调和次优的问题。实验证明，SE-Policy 在速度跟踪任务中显著提高了跟踪精度（最高可达 40%）和时空协调性，并展示了其在人形机器人领域的广泛适用性。

Abstract: The human nervous system exhibits bilateral symmetry, enabling coordinated
and balanced movements. However, existing Deep Reinforcement Learning (DRL)
methods for humanoid robots neglect morphological symmetry of the robot,
leading to uncoordinated and suboptimal behaviors. Inspired by human motor
control, we propose Symmetry Equivariant Policy (SE-Policy), a new DRL
framework that embeds strict symmetry equivariance in the actor and symmetry
invariance in the critic without additional hyperparameters. SE-Policy enforces
consistent behaviors across symmetric observations, producing temporally and
spatially coordinated motions with higher task performance. Extensive
experiments on velocity tracking tasks, conducted in both simulation and
real-world deployment with the Unitree G1 humanoid robot, demonstrate that
SE-Policy improves tracking accuracy by up to 40% compared to state-of-the-art
baselines, while achieving superior spatial-temporal coordination. These
results demonstrate the effectiveness of SE-Policy and its broad applicability
to humanoid robots.

</details>


### [359] [VLH: Vision-Language-Haptics Foundation Model](https://arxiv.org/abs/2508.01361)
*Luis Francisco Moreno Fuentes,Muhammad Haris Khan,Miguel Altamirano Cabrera,Valerii Serpiva,Dmitri Iarchuk,Yara Mahmoud,Issatay Tokmurziyev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: VLH是一个视觉-语言-触觉基础模型，通过融合视觉、语言和触觉反馈，在空中机器人和虚拟现实中实现更具表现力和沉浸感的人机交互。


<details>
  <summary>Details</summary>
Motivation: 旨在统一感知、语言和触觉反馈，将触觉作为直接源于上下文视觉理解和自然语言命令的输出，而非仅仅是次要的、反应性的通道。

Method: VLH是一个视觉-语言-触觉基础模型，通过微调的OpenVLA骨干网络处理视觉输入和语言指令，输出7维动作向量（Vx, Vy, Vz, Hx, Hy, Hz, Hv），并利用INT8量化和高性能服务器实现4-5 Hz的实时操作。该平台包含一个配备双反五杆联动阵列的8英寸四旋翼无人机、一个自主VR相机和一个外心俯视视角。

Result: 在90次飞行的人机交互实验中，VLH实现了56.7%的目标获取成功率（平均到达时间21.3秒，姿态误差0.24米），以及100%的纹理识别准确率。泛化测试在新的任务中表现出70.0%（视觉）、54.4%（运动）、40.0%（物理）和35.0%（语义）的性能。

Conclusion: VLH能够与感知推理和意图共同演进触觉反馈，推进富有表现力、沉浸式的人机交互。

Abstract: We present VLH, a novel Visual-Language-Haptic Foundation Model that unifies
perception, language, and tactile feedback in aerial robotics and virtual
reality. Unlike prior work that treats haptics as a secondary, reactive
channel, VLH synthesizes mid-air force and vibration cues as a direct
consequence of contextual visual understanding and natural language commands.
Our platform comprises an 8-inch quadcopter equipped with dual inverse five-bar
linkage arrays for localized haptic actuation, an egocentric VR camera, and an
exocentric top-down view. Visual inputs and language instructions are processed
by a fine-tuned OpenVLA backbone - adapted via LoRA on a bespoke dataset of 450
multimodal scenarios - to output a 7-dimensional action vector (Vx, Vy, Vz, Hx,
Hy, Hz, Hv). INT8 quantization and a high-performance server ensure real-time
operation at 4-5 Hz. In human-robot interaction experiments (90 flights), VLH
achieved a 56.7% success rate for target acquisition (mean reach time 21.3 s,
pose error 0.24 m) and 100% accuracy in texture discrimination. Generalization
tests yielded 70.0% (visual), 54.4% (motion), 40.0% (physical), and 35.0%
(semantic) performance on novel tasks. These results demonstrate VLH's ability
to co-evolve haptic feedback with perceptual reasoning and intent, advancing
expressive, immersive human-robot interactions.

</details>


### [360] [MoRe-ERL: Learning Motion Residuals using Episodic Reinforcement Learning](https://arxiv.org/abs/2508.01409)
*Xi Huang,Hongyi Zhou,Ge Li,Yucheng Tang,Weiran Liao,Björn Hein,Tamim Asfour,Rudolf Lioutikov*

Main category: cs.RO

TL;DR: MoRe-ERL框架结合了ERL和残差学习，优化机器人轨迹，提高了效率和性能，并成功实现了模拟到现实的部署。


<details>
  <summary>Details</summary>
Motivation: 提出MoRe-ERL框架是为了优化预先规划的参考轨迹，生成安全、可行且高效的任务特定轨迹，同时保持关键任务相关的操作，并提高样本效率和任务性能。

Method: MoRe-ERL框架结合了情景强化学习（ERL）和残差学习，通过识别需要修改的轨迹段并生成基于B样条的运动原语的平滑残差调整，来优化预先规划的参考轨迹，以生成安全、可行且高效的任务特定轨迹。

Result: 实验结果表明，与从头开始训练的ERL方法相比，残差学习显著提高了样本效率和任务性能。硬件评估验证了该框架，表明在模拟中训练的策略可以直接部署到真实世界的系统中，并且模拟到真实世界的差距很小。

Conclusion: MoRe-ERL框架通过结合样本效率和任务性能的残差学习，显著优于从头开始训练的ERL方法，并且在硬件评估中显示出最小的模拟到真实差距，证明了其在动态任务上下文中的适应性和平滑轨迹细化的能力。

Abstract: We propose MoRe-ERL, a framework that combines Episodic Reinforcement
Learning (ERL) and residual learning, which refines preplanned reference
trajectories into safe, feasible, and efficient task-specific trajectories.
This framework is general enough to incorporate into arbitrary ERL methods and
motion generators seamlessly. MoRe-ERL identifies trajectory segments requiring
modification while preserving critical task-related maneuvers. Then it
generates smooth residual adjustments using B-Spline-based movement primitives
to ensure adaptability to dynamic task contexts and smoothness in trajectory
refinement. Experimental results demonstrate that residual learning
significantly outperforms training from scratch using ERL methods, achieving
superior sample efficiency and task performance. Hardware evaluations further
validate the framework, showing that policies trained in simulation can be
directly deployed in real-world systems, exhibiting a minimal sim-to-real gap.

</details>


### [361] [RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems](https://arxiv.org/abs/2508.01415)
*Mingcong Lei,Honghao Cai,Zezhou Cui,Liangchen Tan,Junkun Hong,Gehan Hu,Shuangyu Zhu,Yimou Wu,Shaohan Jiang,Ge Wang,Zhen Li,Shuguang Cui,Yiming Zhao,Yatong Han*

Main category: cs.RO

TL;DR: RoboMemory是一个受大脑启发的终身学习框架，用于物理机器人，通过其多记忆系统解决了学习和延迟问题，并在基准测试和现实世界部署中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决物理实体系统在现实世界环境中持续学习、多模块记忆延迟、任务相关性捕获和闭环规划中的无限循环等关键挑战。

Method: 提出了一种受大脑启发的、用于物理实体系统的终身学习的多记忆框架RoboMemory，该框架集成了信息预处理器、终身实体记忆系统、闭环规划模块和低级执行器。

Result: RoboMemory通过其集成框架，包括一个以Lifelong Embodied Memory System为核心的系统，该系统通过空间、时间、情景和语义子模块的并行更新/检索来缓解复杂记忆框架中的推理速度问题。

Conclusion: RoboMemory在EmbodiedBench上表现优于开源基线（Qwen2.5-VL-72B-Ins）25%，并优于闭源SOTA（Claude3.5-Sonnet）5%，确立了新的SOTA。消融研究验证了关键组件（评论者、空间记忆、长期记忆），实际部署证实了其终身学习能力，重复任务成功率显著提高。

Abstract: We present RoboMemory, a brain-inspired multi-memory framework for lifelong
learning in physical embodied systems, addressing critical challenges in
real-world environments: continuous learning, multi-module memory latency, task
correlation capture, and infinite-loop mitigation in closed-loop planning.
Grounded in cognitive neuroscience, it integrates four core modules: the
Information Preprocessor (thalamus-like), the Lifelong Embodied Memory System
(hippocampus-like), the Closed-Loop Planning Module (prefrontal lobe-like), and
the Low-Level Executer (cerebellum-like) to enable long-term planning and
cumulative learning. The Lifelong Embodied Memory System, central to the
framework, alleviates inference speed issues in complex memory frameworks via
parallelized updates/retrieval across Spatial, Temporal, Episodic, and Semantic
submodules. It incorporates a dynamic Knowledge Graph (KG) and consistent
architectural design to enhance memory consistency and scalability. Evaluations
on EmbodiedBench show RoboMemory outperforms the open-source baseline
(Qwen2.5-VL-72B-Ins) by 25% in average success rate and surpasses the
closed-source State-of-the-Art (SOTA) (Claude3.5-Sonnet) by 5%, establishing
new SOTA. Ablation studies validate key components (critic, spatial memory,
long-term memory), while real-world deployment confirms its lifelong learning
capability with significantly improved success rates across repeated tasks.
RoboMemory alleviates high latency challenges with scalability, serving as a
foundational reference for integrating multi-modal memory systems in physical
robots.

</details>


### [362] [Physically-based Lighting Augmentation for Robotic Manipulation](https://arxiv.org/abs/2508.01442)
*Shutong Jin,Lezhong Wang,Ben Temming,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 通过逆渲染和视频扩散模型，改善了机器人执行视频的数据增强效果，缩小了泛化差距。


<details>
  <summary>Details</summary>
Motivation: 为了解决模仿学习策略在面对光照变化等环境变化时泛化能力不足的问题。

Method: 提出了一种利用基于物理的逆渲染进行光照增强的框架，该框架能够分解演示的第一帧中的几何和材质属性，并利用这些属性在不同光照条件下进行渲染。此外，还利用Stable Video Diffusion模型对机器人执行视频进行微调，以实现时间上的一致性光照传播。

Result: 该框架在7-DoF机器人上，在6种光照条件下进行了720次真实评估，成功将行为克隆的泛化差距缩小了40.1%。同时，还展示了该框架在三个下游应用中的潜力。

Conclusion: 该框架通过逆渲染和视频扩散模型实现了对机器人执行视频的改进，有效解决了数据增强在应对环境变化（如光照变化）方面的不足，缩小了行为克隆的泛化差距。

Abstract: Despite advances in data augmentation, policies trained via imitation
learning still struggle to generalize across environmental variations such as
lighting changes. To address this, we propose the first framework that
leverages physically-based inverse rendering for lighting augmentation on
real-world human demonstrations. Specifically, inverse rendering decomposes the
first frame in each demonstration into geometric (surface normal, depth) and
material (albedo, roughness, metallic) properties, which are then used to
render appearance changes under different lighting. To ensure consistent
augmentation across each demonstration, we fine-tune Stable Video Diffusion on
robot execution videos for temporal lighting propagation. We evaluate our
framework by measuring the structural and temporal consistency of the augmented
sequences, and by assessing its effectiveness in reducing the behavior cloning
generalization gap (40.1%) on a 7-DoF robot across 6 lighting conditions using
720 real-world evaluations. We further showcase three downstream applications
enabled by the proposed framework.

</details>


### [363] [HALO: Human Preference Aligned Offline Reward Learning for Robot Navigation](https://arxiv.org/abs/2508.01539)
*Gershom Seneviratne,Jianyu An,Sahire Ellahy,Kasun Weerakoon,Mohamed Bashir Elnoor,Jonathan Deepak Kannan,Amogha Thalihalla Sunil,Dinesh Manocha*

Main category: cs.RO

TL;DR: HALO是一种新颖的离线奖励学习算法，用于机器人导航。它通过量化人类导航直觉来学习视觉奖励函数，并在各种场景下进行了真实部署。HALO在提高成功率、减少轨迹长度和Frechet距离方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种能够量化人类导航直觉的离线奖励学习算法，并将其应用于机器人导航任务，以提高导航性能和泛化能力。

Method: HALO算法通过从移动机器人收集的专家轨迹中学习奖励模型。在训练过程中，算法对参考动作进行均匀采样，并根据基于Boltzmann分布的偏好分数对动作进行排序，该分布以首选动作为中心。此外，奖励还根据用户的二元反馈进行调整。使用Plackett-Luce损失函数训练奖励模型，以使其与排序的偏好保持一致。

Result: HALO算法在真实世界部署中表现出色，其训练的策略能够有效地泛化到未见过的环境和硬件配置。与最先进的基于视觉的导航方法相比，HALO在成功率方面提高了至少33.3%，归一化轨迹长度减少了12.9%，Frechet距离减少了26.6%。

Conclusion: HALO在机器人导航领域取得了显著成果，其离线奖励学习算法能够量化人类导航直觉，生成基于视觉的奖励函数。通过在两种下游应用（离线学习策略和模型预测控制规划器）中部署HALO的奖励模型，并进行了真实世界部署测试，证明了HALO在泛化能力和性能上的优越性。与现有技术相比，HALO在成功率、轨迹长度和Frechet距离方面均有显著提升，证明了其在导航任务中的有效性和多功能性。

Abstract: In this paper, we introduce HALO, a novel Offline Reward Learning algorithm
that quantifies human intuition in navigation into a vision-based reward
function for robot navigation. HALO learns a reward model from offline data,
leveraging expert trajectories collected from mobile robots. During training,
actions are uniformly sampled around a reference action and ranked using
preference scores derived from a Boltzmann distribution centered on the
preferred action, and shaped based on binary user feedback to intuitive
navigation queries. The reward model is trained via the Plackett-Luce loss to
align with these ranked preferences. To demonstrate the effectiveness of HALO,
we deploy its reward model in two downstream applications: (i) an offline
learned policy trained directly on the HALO-derived rewards, and (ii) a
model-predictive-control (MPC) based planner that incorporates the HALO reward
as an additional cost term. This showcases the versatility of HALO across both
learning-based and classical navigation frameworks. Our real-world deployments
on a Clearpath Husky across diverse scenarios demonstrate that policies trained
with HALO generalize effectively to unseen environments and hardware setups not
present in the training data. HALO outperforms state-of-the-art vision-based
navigation methods, achieving at least a 33.3% improvement in success rate, a
12.9% reduction in normalized trajectory length, and a 26.6% reduction in
Frechet distance compared to human expert trajectories.

</details>


### [364] [Adverse Weather-Independent Framework Towards Autonomous Driving Perception through Temporal Correlation and Unfolded Regularization](https://arxiv.org/abs/2508.01583)
*Wei-Bin Kou,Guangxu Zhu,Rongguang Ye,Jingreng Lei,Shuai Wang,Qingfeng Lin,Ming Tang,Yik-Chung Wu*

Main category: cs.RO

TL;DR: Advent框架是一种创新的、不受参考和特定恶劣天气条件影响的通用框架，通过利用时间相关性、防止过拟合和增强泛化能力，显著提高了自动驾驶在各种恶劣天气下的感知性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前自动驾驶感知任务在恶劣天气条件下（如雨、雾）的挑战，现有方法通常采用域适应策略来最小化清晰和恶劣天气图像之间的差异。然而，该策略面临两大挑战：1. 依赖于难以获取的清晰图像作为参考。2. 通常只针对单一恶劣天气条件，在面对多种恶劣天气条件的混合时表现不佳。

Method: Advent框架是一种参考无关且不受特定恶劣天气条件影响的通用框架，可以应用于各种骨干网络和头部。它利用了短期内的同质性，摆脱了对清晰图像作为参考的依赖，并能推广到任意天气条件。具体包括：1. 局部序列机制（LSM）：利用相邻帧之间的时间相关性来实现不受天气条件影响的效果。2. 全局混洗机制（GSM）：对LSM处理的来自输入序列不同位置的片段进行混洗，以防止对LSM引起的 temporal patterns 过拟合。3. 展开正则化器（URs）：通过深度展开实现两种提出的正则化器，以惩罚模型复杂度，增强跨天气泛化能力。

Result: 实验结果表明，Advent框架在语义分割任务上表现优于现有的最先进的基线，并且具有较大的优势。

Conclusion: 该研究提出的Advent框架通过利用局部序列机制（LSM）、全局混洗机制（GSM）和展开正则化器（URs），成功解决了自动驾驶感知任务在恶劣天气条件下（如雨、雾）的挑战，并超越了现有的最先进的基线。

Abstract: Various adverse weather conditions such as fog and rain pose a significant
challenge to autonomous driving (AD) perception tasks like semantic
segmentation, object detection, etc. The common domain adaption strategy is to
minimize the disparity between images captured in clear and adverse weather
conditions. However, domain adaption faces two challenges: (I) it typically
relies on utilizing clear image as a reference, which is challenging to obtain
in practice; (II) it generally targets single adverse weather condition and
performs poorly when confronting the mixture of multiple adverse weather
conditions. To address these issues, we introduce a reference-free and Adverse
weather condition-independent (Advent) framework (rather than a specific model
architecture) that can be implemented by various backbones and heads. This is
achieved by leveraging the homogeneity over short durations, getting rid of
clear reference and being generalizable to arbitrary weather condition.
Specifically, Advent includes three integral components: (I) Locally Sequential
Mechanism (LSM) leverages temporal correlations between adjacent frames to
achieve the weather-condition-agnostic effect thanks to the homogeneity behind
arbitrary weather condition; (II) Globally Shuffled Mechanism (GSM) is proposed
to shuffle segments processed by LSM from different positions of input sequence
to prevent the overfitting to LSM-induced temporal patterns; (III) Unfolded
Regularizers (URs) are the deep unfolding implementation of two proposed
regularizers to penalize the model complexity to enhance across-weather
generalization. We take the semantic segmentation task as an example to assess
the proposed Advent framework. Extensive experiments demonstrate that the
proposed Advent outperforms existing state-of-the-art baselines with large
margins.

</details>


### [365] [CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation](https://arxiv.org/abs/2508.01600)
*Sung-Wook Lee,Xuhui Kang,Brandon Yang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: CLASS是一种新的对比学习方法，用于从演示数据中学习机器人行为表示，解决了行为克隆在处理视觉变化时的泛化能力问题。


<details>
  <summary>Details</summary>
Motivation: 传统的行为克隆（BC）在处理异构数据集（如不同摄像机视角或物体外观的视觉变化）时面临挑战，并且容易过度拟合单个演示，而不是捕捉共享结构，限制了泛化能力。本研究旨在解决这个问题。

Method: CLASS（Contrastive Learning via Action Sequence Supervision）是一种利用监督对比学习从演示数据中学习行为表示的方法。它利用通过动态时间规整（DTW）识别出的相似动作序列产生的弱监督，并使用相似度加权的正样本对进行软InfoNCE损失优化。

Result: CLASS在5个模拟基准和3个真实世界任务中进行了评估，在仅使用表示的检索式控制中取得了有竞争力的结果。

Conclusion: CLASS方法在视觉变化显著的下游策略学习任务中，通过Diffusion Policy的预训练，平均成功率达到75%，而所有其他基线方法均未能取得竞争力。

Abstract: Recent advances in Behavior Cloning (BC) have led to strong performance in
robotic manipulation, driven by expressive models, sequence modeling of
actions, and large-scale demonstration data. However, BC faces significant
challenges when applied to heterogeneous datasets, such as visual shift with
different camera poses or object appearances, where performance degrades
despite the benefits of learning at scale. This stems from BC's tendency to
overfit individual demonstrations rather than capture shared structure,
limiting generalization. To address this, we introduce Contrastive Learning via
Action Sequence Supervision (CLASS), a method for learning behavioral
representations from demonstrations using supervised contrastive learning.
CLASS leverages weak supervision from similar action sequences identified via
Dynamic Time Warping (DTW) and optimizes a soft InfoNCE loss with
similarity-weighted positive pairs. We evaluate CLASS on 5 simulation
benchmarks and 3 real-world tasks to achieve competitive results using
retrieval-based control with representations only. Most notably, for downstream
policy learning under significant visual shifts, Diffusion Policy with CLASS
pre-training achieves an average success rate of 75%, while all other baseline
methods fail to perform competitively. Project webpage:
https://class-robot.github.io.

</details>


### [366] [VFP: Variational Flow-Matching Policy for Multi-Modal Robot Manipulation](https://arxiv.org/abs/2508.01622)
*Xuanran Zhai,Ce Hao*

Main category: cs.RO

TL;DR: VFP是一种新的基于流匹配的策略，可以解决机器人操作中的多模态问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统流匹配方法在处理多模态数据时遇到的困难，即在复杂操作任务中常常简化为平均或模糊行为。

Method: VFP引入了变分潜在先验来进行模式感知动作生成，并结合了Kantorovich最优传输（K-OT）进行分布级对齐，利用混合专家（MoE）解码器进行模式专业化和高效推理。

Result: VFP在四个基准环境的41个任务上进行了全面评估，证明了其在任务和路径多模态设置下的有效性和采样效率。

Conclusion: VFP在任务成功率上比标准的基于流的基线提高了49%，同时保持了快速推理和紧凑的模型尺寸。

Abstract: Flow-matching-based policies have recently emerged as a promising approach
for learning-based robot manipulation, offering significant acceleration in
action sampling compared to diffusion-based policies. However, conventional
flow-matching methods struggle with multi-modality, often collapsing to
averaged or ambiguous behaviors in complex manipulation tasks. To address this,
we propose the Variational Flow-Matching Policy (VFP), which introduces a
variational latent prior for mode-aware action generation and effectively
captures both task-level and trajectory-level multi-modality. VFP further
incorporates Kantorovich Optimal Transport (K-OT) for distribution-level
alignment and utilizes a Mixture-of-Experts (MoE) decoder for mode
specialization and efficient inference. We comprehensively evaluate VFP on 41
tasks across four benchmark environments, demonstrating its effectiveness and
sampling efficiency in both task and path multi-modality settings. Results show
that VFP achieves a $49\%$ relative improvement in task success rate over
standard flow-based baselines, while maintaining fast inference and compact
model size. More details are available on our project page:
https://sites.google.com/view/varfp/

</details>


### [367] [DexReMoE:In-hand Reorientation of General Object via Mixtures of Experts](https://arxiv.org/abs/2508.01695)
*Jun Wan,Xing Liu,Yunlong Dong*

Main category: cs.RO

TL;DR: DexReMoE是一个结合了专家混合和物体类别信息的框架，通过强化学习在模拟中训练，用于在空中重定向各种形状的物体，并在实验中表现出优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了实现灵巧的操作，需要可靠的控制策略来处理各种物体几何形状、维持稳定的抓握并执行精确的复杂定向轨迹。然而，以往的研究主要集中在单个物体或简单几何形状上，难以推广到复杂形状。

Method: 提出了一种名为DexReMoE（Dexterous Reorientation Mixture-of-Experts）的框架，该框架集成了多个针对不同复杂形状训练的专家策略，并利用专家混合（MoE）模型进行整合。此外，研究还将物体类别信息作为特权输入，以增强形状表示。该框架在模拟环境中使用强化学习（RL）进行训练。

Result: DexReMoE在模拟环境中训练，并在最具挑战性的场景——由向下的手在空中重定向物体——中，在150个不同物体上进行了评估。在平均连续成功次数方面，DexReMoE取得了19.5分。与基线方法相比，DexReMoE还将最差情况下的性能从0.69提高到6.05。

Conclusion: DexReMoE框架具有良好的可扩展性和适应性，能够实现通用型手持物体重定向。

Abstract: In hand object reorientation provides capability for dexterous manipulation,
requiring robust control policies to manage diverse object geometries, maintain
stable grasps, and execute precise complex orientation trajectories. However,
prior works focus on single objects or simple geometries and struggle to
generalize to complex shapes. In this work, we introduce DexReMoE (Dexterous
Reorientation Mixture-of-Experts), in which multiple expert policies are
trained for different complex shapes and integrated within a Mixture-of-Experts
(MoE) framework, making the approach capable of generalizing across a wide
range of objects. Additionally, we incorporate object category information as
privileged inputs to enhance shape representation. Our framework is trained in
simulation using reinforcement learning (RL) and evaluated on novel
out-of-distribution objects in the most challenging scenario of reorienting
objects held in the air by a downward-facing hand. In terms of the average
consecutive success count, DexReMoE achieves a score of 19.5 across a diverse
set of 150 objects. In comparison to the baselines, it also enhances the
worst-case performance, increasing it from 0.69 to 6.05. These results
underscore the scalability and adaptability of the DexReMoE framework for
general-purpose in-hand reorientation.

</details>


### [368] [Towards Zero-Shot Terrain Traversability Estimation: Challenges and Opportunities](https://arxiv.org/abs/2508.01715)
*Ida Germann,Mark O. Mints,Peer Neubert*

Main category: cs.RO

TL;DR: 地形可通行性估计对机器人很重要。我们引入了一个人类标注的数据集，并提出了一个使用视觉语言模型（VLM）进行零次学习估计的流程。结果表明，VLM 尚不适合实际应用，但仍有研究价值。


<details>
  <summary>Details</summary>
Motivation: 地形可通行性估计对于机器人的自主性至关重要，尤其是在非结构化环境中，视觉线索和推理起着关键作用。虽然视觉语言模型（VLM）在零次学习估计方面具有潜力，但该问题本质上是不适定的。

Method: 提出一个整合视觉语言模型（VLM）以实现零次学习可通行性估计的简单流程。

Result: 实验结果好坏参半，表明当前的基础模型尚不适合实际部署。

Conclusion: 目前的基础模型尚不适合实际部署，但为进一步研究提供了有价值的见解。

Abstract: Terrain traversability estimation is crucial for autonomous robots,
especially in unstructured environments where visual cues and reasoning play a
key role. While vision-language models (VLMs) offer potential for zero-shot
estimation, the problem remains inherently ill-posed. To explore this, we
introduce a small dataset of human-annotated water traversability ratings,
revealing that while estimations are subjective, human raters still show some
consensus. Additionally, we propose a simple pipeline that integrates VLMs for
zero-shot traversability estimation. Our experiments reveal mixed results,
suggesting that current foundation models are not yet suitable for practical
deployment but provide valuable insights for further research.

</details>


### [369] [OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping](https://arxiv.org/abs/2508.01723)
*Danyang Li,Zenghui Yang,Guangpeng Qi,Songtao Pang,Guangyong Shang,Qiang Ma,Zheng Yang*

Main category: cs.RO

TL;DR: OpenMap 是一种用于精确导航任务指令基础的零样本、开放词汇视觉语言地图，通过结构-语义共识约束和 LLM 辅助指令到实例地面识别模块来解决语义不一致和指令解释问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将自由形式语言指令与特定场景实例对齐方面存在不足，在实例级语义一致性和指令解释方面存在局限性。

Method: OpenMap 采用零样本、开放词汇视觉语言地图，并通过结构-语义共识约束和 LLM 辅助指令到实例的地面识别模块来解决语义不一致和指令解释问题。

Result: OpenMap 在 ScanNet200 和 Matterport3D 上进行了评估，在零样本设置下，在语义映射和指令到目标检索任务方面都优于最先进的基线。

Conclusion: OpenMap 在零样本设置下在 ScanNet200 和 Matterport3D 上进行了评估，在语义映射和指令到目标检索任务方面都优于最先进的基线，证明了该方法在连接自由形式语言和用于具身导航的 3D 感知方面的有效性。

Abstract: Grounding natural language instructions to visual observations is fundamental
for embodied agents operating in open-world environments. Recent advances in
visual-language mapping have enabled generalizable semantic representations by
leveraging vision-language models (VLMs). However, these methods often fall
short in aligning free-form language commands with specific scene instances,
due to limitations in both instance-level semantic consistency and instruction
interpretation. We present OpenMap, a zero-shot open-vocabulary visual-language
map designed for accurate instruction grounding in navigation tasks. To address
semantic inconsistencies across views, we introduce a Structural-Semantic
Consensus constraint that jointly considers global geometric structure and
vision-language similarity to guide robust 3D instance-level aggregation. To
improve instruction interpretation, we propose an LLM-assisted
Instruction-to-Instance Grounding module that enables fine-grained instance
selection by incorporating spatial context and expressive target descriptions.
We evaluate OpenMap on ScanNet200 and Matterport3D, covering both semantic
mapping and instruction-to-target retrieval tasks. Experimental results show
that OpenMap outperforms state-of-the-art baselines in zero-shot settings,
demonstrating the effectiveness of our method in bridging free-form language
and 3D perception for embodied navigation.

</details>


### [370] [Novel Non-Prehensile Rolling Problem: Modelling and Balance Control of Pendulum-Driven Reconfigurable Disks Motion with Magnetic Coupling in Simulation](https://arxiv.org/abs/2411.04279)
*Ollie Wiltshire,Seyed Amir Tafrishi*

Main category: cs.RO

TL;DR: 提出了一种具有内部驱动磁摆联机机制的新型滚动磁盘模块，用于非抓取操作，并研究了其控制挑战和运动行为。


<details>
  <summary>Details</summary>
Motivation: 提出一种新型移动滚动机器人，作为非抓取操作的模块化平台，并强调实现平衡控制的相关控制挑战。

Method: 使用欧拉-拉格朗日公式推导非线性动力学，并通过仿真研究和分析运动行为。

Result: 研究了该新平台的平衡性，并引入了一种新的提升运动模式。

Conclusion: 该研究旨在增强对模块化自重构机器人在各种未来应用场景的理解和实现。

Abstract: This paper presents a novel type of mobile rolling robot designed as a
modular platform for non-prehensile manipulation, highlighting the associated
control challenges in achieving balancing control of the robotic system. The
developed rolling disk modules incorporate an innovative internally actuated
magnetic-pendulum coupling mechanism, which introduces a compelling control
problem due to the frictional and sliding interactions, as well as the magnetic
effects between each module. In this paper, we derive the nonlinear dynamics of
the robot using the Euler-Lagrange formulation. Then, through simulation, the
motion behavior of the system is studied and analyzed, providing critical
insights for future investigations into control methods for complex
non-prehensile motion between robotic modules. Also, we study the balancing of
this new platform and introduce a new motion pattern of lifting. This research
aims to enhance the understanding and implementation of modular
self-reconfigurable robots in various scenarios for future applications.

</details>


### [371] [Set the Stage: Enabling Storytelling with Multiple Robots through Roleplaying Metaphors](https://arxiv.org/abs/2508.01736)
*Tyrone Justin Sta Maria,Faith Griffin,Jordan Aiko Deja*

Main category: cs.RO

TL;DR: 通过引入导演、傀儡师和巫师等角色扮演隐喻，克服了手势控制多机器人系统的局限性，为交互设计带来了更大的创造力、表现力和直观性。


<details>
  <summary>Details</summary>
Motivation: 为了克服当前手势控制多机器人系统时存在的僵化映射和识别限制。

Method: 提出角色扮演隐喻作为设计更丰富交互的支架，引入了导演、傀儡师和巫师三个角色，展示了叙事框架如何指导不同手势集和交互风格的创建。

Result: 所提出的角色扮演方法能够解锁多机器人系统的新可能性，并能适应多种场景。

Conclusion: 该方法强调了创造力、表现力和直观性，这些是未来人机交互设计的关键要素。

Abstract: Gestures are an expressive input modality for controlling multiple robots,
but their use is often limited by rigid mappings and recognition constraints.
To move beyond these limitations, we propose roleplaying metaphors as a
scaffold for designing richer interactions. By introducing three roles:
Director, Puppeteer, and Wizard, we demonstrate how narrative framing can guide
the creation of diverse gesture sets and interaction styles. These roles enable
a variety of scenarios, showing how roleplay can unlock new possibilities for
multi-robot systems. Our approach emphasizes creativity, expressiveness, and
intuitiveness as key elements for future human-robot interaction design.

</details>


### [372] [Learning to Perform Low-Contact Autonomous Nasotracheal Intubation by Recurrent Action-Confidence Chunking with Transformer](https://arxiv.org/abs/2508.01808)
*Yu Tian,Ruoyi Hao,Yiming Huang,Dihong Xie,Catherine Po Ling Chan,Jason Ying Kuen Chan,Hongliang Ren*

Main category: cs.RO

TL;DR: 提出了一种新颖的自主 NTI 系统，采用带有力传感器的假体和 RACCT 模型，与手动操作相比，可降低插入力并提高安全性。


<details>
  <summary>Details</summary>
Motivation: 目前的 nasotracheal intubation (NTI) 手动方法存在交叉感染和粘膜损伤风险。现有研究集中在自动内窥镜插入，但 NTI 的自动化仍未被探索，尽管其面临管径和刚度带来的更大挑战。

Method: 开发了一个包含嵌入力传感器的假体，用于安全评估和数据过滤。开发了具有Transformer的递归动作-置信度分块（RACCT）模型，以处理复杂的管-组织相互作用和部分视觉观察。

Result: RACCT 模型在所有方面均优于 ACT 模型，与手动操作相比，平均峰值插入力降低了 66%，同时保持了相当成功率。

Conclusion: 该系统有望降低感染风险并提高手术安全性。

Abstract: Nasotracheal intubation (NTI) is critical for establishing artificial airways
in clinical anesthesia and critical care. Current manual methods face
significant challenges, including cross-infection, especially during
respiratory infection care, and insufficient control of endoluminal contact
forces, increasing the risk of mucosal injuries. While existing studies have
focused on automated endoscopic insertion, the automation of NTI remains
unexplored despite its unique challenges: Nasotracheal tubes exhibit greater
diameter and rigidity than standard endoscopes, substantially increasing
insertion complexity and patient risks. We propose a novel autonomous NTI
system with two key components to address these challenges. First, an
autonomous NTI system is developed, incorporating a prosthesis embedded with
force sensors, allowing for safety assessment and data filtering. Then, the
Recurrent Action-Confidence Chunking with Transformer (RACCT) model is
developed to handle complex tube-tissue interactions and partial visual
observations. Experimental results demonstrate that the RACCT model outperforms
the ACT model in all aspects and achieves a 66% reduction in average peak
insertion force compared to manual operations while maintaining equivalent
success rates. This validates the system's potential for reducing infection
risks and improving procedural safety.

</details>


### [373] [Exploring Stiffness Gradient Effects in Magnetically Induced Metamorphic Materials via Continuum Simulation and Validation](https://arxiv.org/abs/2508.01810)
*Wentao Shi,Yang Yang,Yiming Huang,Hongliang Ren*

Main category: cs.RO

TL;DR: Magnetic soft continuum robots (MCRs) are useful in bioengineering but lack comprehensive bending models. This work develops a numerical model for graded-stiffness MCRs (GMCs) incorporating four key parameters, validates it with experiments, and trains an efficient expansion model for bending prediction.


<details>
  <summary>Details</summary>
Motivation: Recent studies on magnetic continuum robots have primarily focused on one or two design parameters, limiting the development of a comprehensive magnetic continuum bending model.

Method: This work constructed graded-stiffness MCRs (GMCs) and developed a numerical model for GMCs' bending performance, incorporating four key parameters. The simulated bending results were validated with real bending experiments in four different categories: varying magnetic field, cross-section, unit stiffness, and unit length. An expansion model for GMCs' bending performance was also trained.

Result: The simulated bending results were validated with real bending experiments. The graded-stiffness design strategy applied to GMCs prevents sharp bending at the fixed end and results in a more circular curvature. The trained expansion model for GMCs' bending performance is highly efficient and accurate compared to the simulation process.

Conclusion: The graded-stiffness design strategy applied to magnetic continuum robots (MCRs) prevents sharp bending at the fixed end and results in a more circular curvature. An expansion model for MCRs' bending performance was trained, which is highly efficient and accurate compared to the simulation process, and an extensive library of bending prediction for MCRs was built using the trained model.

Abstract: Magnetic soft continuum robots are capable of bending with remote control in
confined space environments, and they have been applied in various
bioengineering contexts. As one type of ferromagnetic soft continuums, the
Magnetically Induced Metamorphic Materials (MIMMs)-based continuum (MC)
exhibits similar bending behaviors. Based on the characteristics of its base
material, MC is flexible in modifying unit stiffness and convenient in molding
fabrication. However, recent studies on magnetic continuum robots have
primarily focused on one or two design parameters, limiting the development of
a comprehensive magnetic continuum bending model. In this work, we constructed
graded-stiffness MCs (GMCs) and developed a numerical model for GMCs' bending
performance, incorporating four key parameters that determine their
performance. The simulated bending results were validated with real bending
experiments in four different categories: varying magnetic field,
cross-section, unit stiffness, and unit length. The graded-stiffness design
strategy applied to GMCs prevents sharp bending at the fixed end and results in
a more circular curvature. We also trained an expansion model for GMCs' bending
performance that is highly efficient and accurate compared to the simulation
process. An extensive library of bending prediction for GMCs was built using
the trained model.

</details>


### [374] [Unraveling the Connection: How Cognitive Workload Shapes Intent Recognition in Robot-Assisted Surgery](https://arxiv.org/abs/2508.01823)
*Mansi Sharma,Antonio Kruger*

Main category: cs.RO

TL;DR: 研究提出一种多模态辅助系统，通过整合脑活动、心率、肌肉活动和眼动追踪等数据，监测外科医生认知负荷，提升意图识别的准确性，以优化机器人辅助手术的学习效果和最终成果。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术的成功很大程度上取决于机器人系统准确解读外科医生意图的能力，而认知负荷是影响意图识别的关键因素。本研究旨在通过监测认知负荷来改进学习效果。

Method: 开发一个智能多模态辅助框架，该框架能够利用脑活动、心率、肌肉活动和眼动追踪等多种数据源来监测认知负荷并提升意图识别能力。

Result: 该项目旨在通过提升机器人系统解读外科医生意图的能力，进一步发挥机器人辅助手术的优势，改善手术效果。

Conclusion: 通过利用脑活动、心率、肌肉活动和眼动追踪等多模态数据，该系统旨在提高机器人辅助手术中对外科医生意图的理解和对医生心理状态的监测，最终提升手术效果和学习成果。

Abstract: Robot-assisted surgery has revolutionized the healthcare industry by
providing surgeons with greater precision, reducing invasiveness, and improving
patient outcomes. However, the success of these surgeries depends heavily on
the robotic system ability to accurately interpret the intentions of the
surgical trainee or even surgeons. One critical factor impacting intent
recognition is the cognitive workload experienced during the procedure. In our
recent research project, we are building an intelligent adaptive system to
monitor cognitive workload and improve learning outcomes in robot-assisted
surgery. The project will focus on achieving a semantic understanding of
surgeon intents and monitoring their mental state through an intelligent
multi-modal assistive framework. This system will utilize brain activity, heart
rate, muscle activity, and eye tracking to enhance intent recognition, even in
mentally demanding situations. By improving the robotic system ability to
interpret the surgeons intentions, we can further enhance the benefits of
robot-assisted surgery and improve surgery outcomes.

</details>


### [375] [Exploring environment exploitation for self-reconfiguration in modular robotics](https://arxiv.org/abs/2508.01829)
*Philippe Martin Wyder,Haorui Li,Andrew Bae,Henry Zhao,Mark Yim*

Main category: cs.RO

TL;DR: 本研究转变了模块化机器人研究的焦点，从机器人本身转向机器人与环境的交互，研究机器人如何利用环境特征（如边缘、间隙和斜坡）来实现更快的运动、自适应重构和三维组装。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是转变现有模块化机器人研究的范式，从专注于完善机器人模块本身转向关注机器人与环境的交互，以期克服模块化机器人的局限性。

Method: 本研究通过研究模块化机器人如何有效利用其周围环境（例如，边缘、间隙和斜坡）来实现更快的运动、自适应重构和从二维到三维的复杂组装，来研究模块化机器人与环境的交互。

Result: 通过利用环境特征，本研究表明模块化机器人可以实现更快的运动、自适应重构以及从简单的二维机器人组件进行复杂的三维组装。

Conclusion: 这项研究旨在为模块化桁架机器人开发能够利用环境特征的系统，以克服其固有的局限性。

Abstract: Modular robotics research has long been preoccupied with perfecting the
modules themselves -- their actuation methods, connectors, controls,
communication, and fabrication. This inward focus results, in part, from the
complexity of the task and largely confines modular robots to sterile
laboratory settings. The latest generation of truss modular robots, such as the
Variable Topology Truss and the Truss Link, have begun to focus outward and
reveal a key insight: the environment is not just a backdrop; it is a tool. In
this work, we shift the paradigm from building better robots to building better
robot environment interactions for modular truss robots. We study how modular
robots can effectively exploit their surroundings to achieve faster locomotion,
adaptive self-reconfiguration, and complex three-dimensional assembly from
simple two-dimensional robot assemblies. By using environment features --
ledges, gaps, and slopes -- we show how the environment can extend the robots'
capabilities. Nature has long mastered this principle: organisms not only
adapt, but exploit their environments to their advantage. Robots must learn to
do the same. This study is a step towards modular robotic systems that
transcend their limitations by exploiting environmental features.

</details>


### [376] [L3M+P: Lifelong Planning with Large Language Models](https://arxiv.org/abs/2508.01917)
*Krish Agarwal,Yuqian Jiang,Jiaheng Hu,Bo Liu,Peter Stone*

Main category: cs.RO

TL;DR: L3M+P通过知识图谱解决了服务机器人规划中的环境规约和动态记忆问题，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM+P方法在应用于通用服务机器人时面临两大挑战：1. 经典规划算法需要详细一致的环境规约，而这并不总是可用的；2. 现有框架主要关注孤立的规划任务，而机器人通常需要长期持续部署，因此必须维护一个能够被多模态输入更新并提取为未来规划知识的动态环境记忆。

Method: 本文提出的L3M+P（Lifelong LLM+P）框架，结合了经典规划方法和大型语言模型（LLM），并引入了外部知识图谱来表示世界状态。该知识图谱能够整合来自多模态输入（包括传感器信息和人机交互）的信息，并进行更新。L3M+P通过强制执行一套规则来保证世界状态图谱格式的一致性，从而在规划时，能够根据自然语言描述的任务，从知识图谱中检索相关上下文，并生成用于经典规划器的问题定义。

Result: L3M+P框架在模拟和真实世界服务机器人上的评估结果显示，通过知识图谱的检索和验证，该框架在准确注册自然语言状态变化和正确生成规划方面，均取得了比基线方法显著的改进。

Conclusion: L3M+P框架通过使用外部知识图谱来表示世界状态，解决了现有LLM+P方法在服务机器人领域面临的挑战，包括环境规约的可用性和动态记忆维护问题。实验结果表明，L3M+P在真实世界服务机器人和模拟环境中，相比基线方法在理解自然语言状态变化和生成规划方面均有显著提升。

Abstract: By combining classical planning methods with large language models (LLMs),
recent research such as LLM+P has enabled agents to plan for general tasks
given in natural language. However, scaling these methods to general-purpose
service robots remains challenging: (1) classical planning algorithms generally
require a detailed and consistent specification of the environment, which is
not always readily available; and (2) existing frameworks mainly focus on
isolated planning tasks, whereas robots are often meant to serve in long-term
continuous deployments, and therefore must maintain a dynamic memory of the
environment which can be updated with multi-modal inputs and extracted as
planning knowledge for future tasks. To address these two issues, this paper
introduces L3M+P (Lifelong LLM+P), a framework that uses an external knowledge
graph as a representation of the world state. The graph can be updated from
multiple sources of information, including sensory input and natural language
interactions with humans. L3M+P enforces rules for the expected format of the
absolute world state graph to maintain consistency between graph updates. At
planning time, given a natural language description of a task, L3M+P retrieves
context from the knowledge graph and generates a problem definition for
classical planners. Evaluated on household robot simulators and on a real-world
service robot, L3M+P achieves significant improvement over baseline methods
both on accurately registering natural language state changes and on correctly
generating plans, thanks to the knowledge graph retrieval and verification.

</details>


### [377] [Beyond Simulation: Benchmarking World Models for Planning and Causality in Autonomous Driving](https://arxiv.org/abs/2508.01922)
*Hunter Schofield,Mohammed Elmahgiubi,Kasra Rezaee,Jinjun Shan*

Main category: cs.RO

TL;DR: 評估了世界模型作為交通模擬器的現有指標，發現它們在部分重播和考慮因果關係的代理時存在不足。提出了新指標以解決這些問題，並發現頂級模型在某些情況下會失敗。


<details>
  <summary>Details</summary>
Motivation: 旨在評估現有指標在評估世界模型作為交通模擬器時的魯棒性，以確定這些指標是否適用於將世界模型作為策略訓練的偽環境。

Method: 分析了 Waymo 開放模擬代理挑戰賽 (WOSAC) 採用的評估指標，並將世界模型預測與標準場景進行比較，同時考慮了代理由世界模型完全或部分控制的情況 (部分重播)。此外，擴展了標準 WOSAC 評估域，以包含對 ego 載具具有因果關係的代理。

Result: 發現了許多情況，在這些情況下，頂級模型在沒有擾動的情況下表現良好，但在 ego 代理被迫重播原始軌跡時卻失敗了。提出了新的指標來強調世界模型對不可控對象的敏感性，並在這些新指標下評估了世界模型作為策略訓練偽環境的性能。

Conclusion: 現有評估指標在評估世界模型作為交通模擬器方面存在不足，尤其是在部分重播和考慮到對 ego 載具具有因果關係的代理時。

Abstract: World models have become increasingly popular in acting as learned traffic
simulators. Recent work has explored replacing traditional traffic simulators
with world models for policy training. In this work, we explore the robustness
of existing metrics to evaluate world models as traffic simulators to see if
the same metrics are suitable for evaluating a world model as a
pseudo-environment for policy training. Specifically, we analyze the metametric
employed by the Waymo Open Sim-Agents Challenge (WOSAC) and compare world model
predictions on standard scenarios where the agents are fully or partially
controlled by the world model (partial replay). Furthermore, since we are
interested in evaluating the ego action-conditioned world model, we extend the
standard WOSAC evaluation domain to include agents that are causal to the ego
vehicle. Our evaluations reveal a significant number of scenarios where
top-ranking models perform well under no perturbation but fail when the ego
agent is forced to replay the original trajectory. To address these cases, we
propose new metrics to highlight the sensitivity of world models to
uncontrollable objects and evaluate the performance of world models as
pseudo-environments for policy training and analyze some state-of-the-art world
models under these new metrics.

</details>


### [378] [Adaptive Lattice-based Motion Planning](https://arxiv.org/abs/2508.02350)
*Abhishek Dhar,Sarthak Mishra,Spandan Roy,Daniel Axehill*

Main category: cs.RO

TL;DR: 该论文提出了一种自适应格运动规划方法，通过在线学习更新系统模型来提高规划性能，并用无人机仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在杂乱环境中，具有不确定模型参数的线性参数化非线性系统运动规划问题，生成可行轨迹。

Method: 提出了一种基于自适应格的运动规划方法，利用在线输入/输出数据更新模型集和动态估计参数，以减小模型误差，并为运动原语添加了具有固定大小的管来保证无碰撞。

Result: 通过包含不确定参数的无人机模型的仿真示例，证明了该运动规划器的效率。

Conclusion: 该方法通过自适应学习模块减小模型集和参数估计误差，使得运动原语能够任意接近最优运动原语，从而随着时间的推移显著提高运动规划性能。

Abstract: This paper proposes an adaptive lattice-based motion planning solution to
address the problem of generating feasible trajectories for systems,
represented by a linearly parameterizable non-linear model operating within a
cluttered environment. The system model is considered to have uncertain model
parameters. The key idea here is to utilize input/output data online to update
the model set containing the uncertain system parameter, as well as a dynamic
estimated parameter of the model, so that the associated model estimation error
reduces over time. This in turn improves the quality of the motion primitives
generated by the lattice-based motion planner using a nominal estimated model
selected on the basis of suitable criteria. The motion primitives are also
equipped with tubes to account for the model mismatch between the nominal
estimated model and the true system model, to guarantee collision-free overall
motion. The tubes are of uniform size, which is directly proportional to the
size of the model set containing the uncertain system parameter. The adaptive
learning module guarantees a reduction in the diameter of the model set as well
as in the parameter estimation error between the dynamic estimated parameter
and the true system parameter. This directly implies a reduction in the size of
the implemented tubes and guarantees that the utilized motion primitives go
arbitrarily close to the resolution-optimal motion primitives associated with
the true model of the system, thus significantly improving the overall motion
planning performance over time. The efficiency of the motion planner is
demonstrated by a suitable simulation example that considers a drone model
represented by Euler-Lagrange dynamics containing uncertain parameters and
operating within a cluttered environment.

</details>


### [379] [From Photons to Physics: Autonomous Indoor Drones and the Future of Objective Property Assessment](https://arxiv.org/abs/2508.01965)
*Petteri Teikari,Mike Jarrell,Irene Bandera Moreno,Harri Pesola*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The convergence of autonomous indoor drones with physics-aware sensing
technologies promises to transform property assessment from subjective visual
inspection to objective, quantitative measurement. This comprehensive review
examines the technical foundations enabling this paradigm shift across four
critical domains: (1) platform architectures optimized for indoor navigation,
where weight constraints drive innovations in heterogeneous computing,
collision-tolerant design, and hierarchical control systems; (2) advanced
sensing modalities that extend perception beyond human vision, including
hyperspectral imaging for material identification, polarimetric sensing for
surface characterization, and computational imaging with metaphotonics enabling
radical miniaturization; (3) intelligent autonomy through active reconstruction
algorithms, where drones equipped with 3D Gaussian Splatting make strategic
decisions about viewpoint selection to maximize information gain within battery
constraints; and (4) integration pathways with existing property workflows,
including Building Information Modeling (BIM) systems and industry standards
like Uniform Appraisal Dataset (UAD) 3.6.

</details>


### [380] [Periodic robust robotic rock chop via virtual model control](https://arxiv.org/abs/2508.02604)
*Yi Zhang,Fumiya Iida,Fulvio Forni*

Main category: cs.RO

TL;DR: 提出了一种无需预先规划轨迹或精确环境信息的虚拟模型控制方案，通过连接虚拟机构生成刀具摇摆运动，实现了对不同蔬菜的鲁棒切割，并表现出良好的适应性和平台独立性。


<details>
  <summary>Details</summary>
Motivation: 机器人切割任务的挑战性，包括未知的物体力学、大的接触力以及精确的运动要求。

Method: 提出了一种新的虚拟模型控制方案，通过连接虚拟弹簧、阻尼器和质量块等虚拟机构来生成刀具的摇摆运动，无需预先规划的轨迹或精确的环境信息。

Result: 该控制方案使机器人能够实现周期性的运动，并在实验中成功地对五种不同的蔬菜进行了鲁棒切割，切片精度达到亚毫米级别（1毫米至6毫米），切割速度接近每秒一次。该控制器还能适应刀具形状和砧板高度的变化，并能在不同的人形机械臂上运行。

Conclusion: 通过实验证明了该控制方案的鲁棒性、平台独立性和对不同切割任务的适应性。

Abstract: Robotic cutting is a challenging contact-rich manipulation task where the
robot must simultaneously negotiate unknown object mechanics, large contact
forces, and precise motion requirements. We introduce a new virtual-model
control scheme that enables knife rocking motion for robot manipulators,
without pre-planned trajectories or precise information of the environment.
Motion is generated through interconnection with virtual mechanisms, given by
virtual springs, dampers, and masses arranged in a suitable way. Through
analysis and experiments, we demonstrate that the controlled robot behavior
settles into a periodic motion. Experiments with a Franka manipulator
demonstrate robust cuts with five different vegetables, and sub-millimeter
slice accuracy from 1 mm to 6 mm at nearly one cut per second. The same
controller survives changes in knife shape and cutting board height, and
adaptation to a different humanoid manipulator, demonstrating robustness and
platform independence.

</details>


### [381] [Design and Control of an Actively Morphing Quadrotor with Vertically Foldable Arms](https://arxiv.org/abs/2508.02022)
*Tingyu Yeh,Mengxin Xu,Lijun Han*

Main category: cs.RO

TL;DR: 提出了一种可以折叠手臂的四旋翼，使其能抓取物体并通过狭窄空间，尺寸可缩小 33%。


<details>
  <summary>Details</summary>
Motivation: 为了设计一种能够折叠手臂以抓取物体并通过狭窄空间的四旋翼。

Method: 提出了一种新型四旋翼设计，通过中央伺服电机、齿轮和齿条主动控制其垂直折叠手臂，以抓取物体并通过狭窄空间。采用自适应滑模控制器和扰动观测器来缓解变形和抓取负载过程中的干扰。

Result: 变形后的四旋翼框架尺寸缩小至原来的 67%，在收缩状态下可作为抓手。

Conclusion: 所提出的变形四旋翼飞行器通过了现实世界的实验验证，证明了其控制性能和多功能性。

Abstract: In this work, we propose a novel quadrotor design capable of folding its arms
vertically to grasp objects and navigate through narrow spaces. The
transformation is controlled actively by a central servomotor, gears, and
racks. The arms connect the motor bases to the central frame, forming a
parallelogram structure that ensures the propellers maintain a constant
orientation during morphing. In its stretched state, the quadrotor resembles a
conventional design, and when contracted, it functions as a gripper with
grasping components emerging from the motor bases. To mitigate disturbances
during transforming and grasping payloads, we employ an adaptive sliding mode
controller with a disturbance observer. After fully folded, the quadrotor frame
shrinks to 67% of its original size. The control performance and versatility of
the morphing quadrotor are validated through real-world experiments.

</details>


### [382] [NaviMaster: Learning a Unified Policy for GUI and Embodied Navigation Tasks](https://arxiv.org/abs/2508.02046)
*Zhihao Luo,Wentao Yan abd Jingyu Gong,Min Wang,Zhizhong Zhang,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.RO

TL;DR: NaviMaster 是首个能够在一个框架内无缝集成 GUI 导航和具身导航的统一代理。


<details>
  <summary>Details</summary>
Motivation: GUI 和具身导航虽然取得了重大进展，但却在很大程度上独立发展，拥有不同的数据集和训练范式。本研究旨在统一这两个领域。

Method: 提出了一种视觉目标轨迹收集流程，该流程在一个公式中为 GUI 和具身任务生成轨迹。采用统一的强化学习框架处理混合数据以提高泛化能力。设计了一种新颖的距离感知奖励，以确保从轨迹中进行有效的学习。

Result: NaviMaster 在 GUI 导航、空间 वापरा预测和具身导航方面均优于最先进的代理，并在跨域基准测试中取得了显著成果。消融研究证实了其统一训练策略、数据混合策略和奖励设计的有效性。

Conclusion: NaviMaster 在 GUI 导航、空间 वापरा预测和具身导航方面均优于最先进的代理，并通过了消融研究的验证。

Abstract: Recent advances in Graphical User Interface (GUI) and embodied navigation
have driven significant progress, yet these domains have largely evolved in
isolation, with disparate datasets and training paradigms. In this paper, we
observe that both tasks can be formulated as Markov Decision Processes (MDP),
suggesting a foundational principle for their unification. Hence, we present
NaviMaster, the first unified agent capable of seamlessly integrating GUI
navigation and embodied navigation within a single framework. Specifically,
NaviMaster (i) proposes a visual-target trajectory collection pipeline that
generates trajectories for both GUI and embodied tasks in one formulation. (ii)
employs a unified reinforcement learning framework on the mix data for better
generalization. (iii) designs a novel distance-aware reward to ensure efficient
learning from the trajectories. Through extensive experiments on out-of-domain
benchmarks, NaviMaster is shown to outperform state-of-the-art agents in GUI
navigation, spatial affordance prediction, and embodied navigation. Ablation
studies further confirm the efficacy of our unified training strategy, data
mixing strategy, and reward design.

</details>


### [383] [RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models](https://arxiv.org/abs/2508.02062)
*Kaustubh Sridhar,Souradeep Dutta,Dinesh Jayaraman,Insup Lee*

Main category: cs.RO

TL;DR: RICL为机器人VLA模型注入上下文学习能力，用户可通过少量演示（20个）教会模型执行新任务，无需微调即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务VLA模型虽然展示了通用性，但缺乏易于教导和改进的接口。对于语言和视觉模型而言，上下文学习（ICL）是一种无需参数微调即可轻松教授新任务的有效接口，但预训练的VLA模型天然不具备此能力。因此，有必要研究一种方法来为VLA模型注入ICL能力，使其更易于用户使用和改进。

Method: 我们提出了一种名为“重训练以进行上下文学习”（RICL）的方法，通过特定的微调配方和少量机器人演示数据集，在预训练的VLA模型上后验地注入上下文学习（ICL）能力。RICL通过检索最相关的演示片段到VLA上下文中来利用ICL，从而执行新任务并提升任务性能。

Result: 我们将RICL应用于$\	extit{$í…_0$}-FAST VLA模型，并在多种新的机器人操作任务上进行了实验。结果表明，RICL能够在每任务仅20次演示且无需参数更新的情况下，实现显著的上下文学习改进。此外，当允许对目标任务演示进行参数更新时，RICL微调能够进一步提高性能。

Conclusion: 通过引入RICL，我们成功地为多任务视觉-语言-动作（VLA）模型注入了上下文学习（ICL）能力，使得无需微调参数即可让终端用户通过少量机器人演示来教会模型执行新任务，并提升性能。即使在允许参数更新的情况下，RICL微调也能进一步提升性能。

Abstract: Multi-task ``vision-language-action'' (VLA) models have recently demonstrated
increasing promise as generalist foundation models for robotics, achieving
non-trivial performance out of the box on new tasks in new environments.
However, for such models to be truly useful, an end user must have easy means
to teach them to improve. For language and vision models, the emergent ability
to perform in-context learning (ICL) has proven to be a versatile and highly
useful interface to easily teach new tasks with no parameter finetuning.
Unfortunately, VLAs pre-trained with imitation learning objectives do not
naturally acquire ICL abilities. In this paper, we demonstrate that, with the
right finetuning recipe and a small robot demonstration dataset, it is possible
to inject in-context adaptability post hoc into such a VLA. After retraining
for in-context learning (RICL), our system permits an end user to provide a
small number (10-20) of demonstrations for a new task. RICL then fetches the
most relevant portions of those demonstrations into the VLA context to exploit
ICL, performing the new task and boosting task performance. We apply RICL to
inject ICL into the $\pi_{0}$-FAST VLA, and show that it permits large
in-context improvements for a variety of new manipulation tasks with only 20
demonstrations per task, without any parameter updates. When parameter updates
on the target task demonstrations is possible, RICL finetuning further boosts
performance. We release code and model weights for RICL-$\pi_{0}$-FAST
alongside the paper to enable, for the first time, a simple in-context learning
interface for new manipulation tasks. Website: https://ricl-vla.github.io.

</details>


### [384] ["Set It Up": Functional Object Arrangement with Compositional Generative Models](https://arxiv.org/abs/2508.02068)
*Yiqing Xu,Jiayuan Mao,Linfeng Li,Yilun Du,Tomas Lozáno-Pérez,Leslie Pack Kaelbling,David Hsu*

Main category: cs.RO

TL;DR: SetItUp是一个神经符号框架，使用LLM和扩散模型来解决功能性物体排列问题，它通过学习指定对象姿态来处理不明确的指令。


<details>
  <summary>Details</summary>
Motivation: 功能性物体排列（FORM）任务的指令通常信息不足，没有明确指定目标物体姿态，这是一个关键挑战。

Method: SetItUp框架采用基于LLM的程序生成和基于扩散模型的姿态预测两阶段方法，通过中间表示“接地图”来解决功能性物体排列问题。

Result: SetItUp在生成功能性、物理可行且美观的物体排列方面优于现有模型。

Conclusion: SetItUp是一个神经符号框架，能够从少数训练示例和结构化的自然语言任务规范中学习指定对象的姿态，在三个不同的任务类别（餐桌布置、书架整理、卧室家具布局）上进行了评估，其性能优于现有模型。

Abstract: Functional object arrangement (FORM) is the task of arranging objects to
fulfill a function, e.g., "set up a dining table for two". One key challenge
here is that the instructions for FORM are often under-specified and do not
explicitly specify the desired object goal poses. This paper presents SetItUp,
a neuro-symbolic framework that learns to specify the goal poses of objects
from a few training examples and a structured natural-language task
specification. SetItUp uses a grounding graph, which is composed of abstract
spatial relations among objects (e.g., left-of), as its intermediate
representation. This decomposes the FORM problem into two stages: (i)
predicting this graph among objects and (ii) predicting object poses given the
grounding graph. For (i), SetItUp leverages large language models (LLMs) to
induce Python programs from a task specification and a few training examples.
This program can be executed to generate grounding graphs in novel scenarios.
For (ii), SetItUp pre-trains a collection of diffusion models to capture
primitive spatial relations and online composes these models to predict object
poses based on the grounding graph. We evaluated SetItUp on a dataset spanning
three distinct task families: arranging tableware on a dining table, organizing
items on a bookshelf, and laying out furniture in a bedroom. Experiments show
that SetItUp outperforms existing models in generating functional, physically
feasible, and aesthetically pleasing object arrangements. This article extends
our conference paper published at Robotics: Science and Systems (RSS) 2024.

</details>


### [385] [ScrewSplat: An End-to-End Method for Articulated Object Recognition](https://arxiv.org/abs/2508.02146)
*Seungyeon Kim,Junsu Ha,Young Hun Kim,Yonghyeon Lee,Frank C. Park*

Main category: cs.RO

TL;DR: ScrewSplat是一种新的端到端方法，仅使用RGB图像即可识别铰接对象的几何形状和运动学关节，在各种对象上实现了最先进的准确性，并支持零次、文本引导的操作。


<details>
  <summary>Details</summary>
Motivation: ScrewSplat旨在解决现有铰接对象识别方法的局限性，这些方法通常依赖于强假设（例如，已知的部件数量）、需要额外的输入（例如，深度图像）或涉及可能引入错误的复杂中间步骤。

Method: ScrewSplat是一种端到端的方法，仅使用RGB观察。它通过迭代优化随机初始化的螺杆轴来恢复对象的运动学结构，并与高斯泼溅集成以同时重建3D几何形状和将对象分割成可移动的刚性部件。

Result: ScrewSplat在各种铰接对象上实现了最先进的识别准确性，并实现了零次、文本引导的操作。

Conclusion: ScrewSplat在各种铰接对象上实现了最先进的识别准确性，并实现了零次、文本引导的操作。

Abstract: Articulated object recognition -- the task of identifying both the geometry
and kinematic joints of objects with movable parts -- is essential for enabling
robots to interact with everyday objects such as doors and laptops. However,
existing approaches often rely on strong assumptions, such as a known number of
articulated parts; require additional inputs, such as depth images; or involve
complex intermediate steps that can introduce potential errors -- limiting
their practicality in real-world settings. In this paper, we introduce
ScrewSplat, a simple end-to-end method that operates solely on RGB
observations. Our approach begins by randomly initializing screw axes, which
are then iteratively optimized to recover the object's underlying kinematic
structure. By integrating with Gaussian Splatting, we simultaneously
reconstruct the 3D geometry and segment the object into rigid, movable parts.
We demonstrate that our method achieves state-of-the-art recognition accuracy
across a diverse set of articulated objects, and further enables zero-shot,
text-guided manipulation using the recovered kinematic model.

</details>


### [386] [Towards High Precision: An Adaptive Self-Supervised Learning Framework for Force-Based Verification](https://arxiv.org/abs/2508.02153)
*Zebin Duan,Frederik Hagelskjær,Aljaz Kramberger,Juan Heredia and,Norbert Krüger*

Main category: cs.RO

TL;DR: 提出了一种自适应自监督学习框架，用于机器人力控制任务，通过实时数据优化自身性能，减少人工干预，提高精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的方法在泛化能力和长期可靠性方面存在局限，需要频繁的手动干预，因此需要一种能够自动适应和改进的机器人任务自动化方法。

Method: 提出了一种自适应的、自监督学习框架，用于实时进行插入分类，并能随着时间的推移持续提高其精确度。

Result: 实验证明，该系统在处理更多样本的过程中，能够逐步减少执行时间，同时保持近乎完美的精度。

Conclusion: 该框架通过实时整合新获取的力数据，逐步优化其分类决策，从而确保了机器人能够实现长期可靠运行，同时最大限度地减少了手动干预的需要。

Abstract: The automation of robotic tasks requires high precision and adaptability,
particularly in force-based operations such as insertions. Traditional
learning-based approaches either rely on static datasets, which limit their
ability to generalize, or require frequent manual intervention to maintain good
performances. As a result, ensuring long-term reliability without human
supervision remains a significant challenge. To address this, we propose an
adaptive self-supervised learning framework for insertion classification that
continuously improves its precision over time. The framework operates in
real-time, incrementally refining its classification decisions by integrating
newly acquired force data. Unlike conventional methods, it does not rely on
pre-collected datasets but instead evolves dynamically with each task
execution. Through real-world experiments, we demonstrate how the system
progressively reduces execution time while maintaining near-perfect precision
as more samples are processed. This adaptability ensures long-term reliability
in force-based robotic tasks while minimizing the need for manual intervention.

</details>


### [387] [A Moment Matching-Based Method for Sparse and Noisy Point Cloud Registration](https://arxiv.org/abs/2508.02187)
*Xingyi Li,Han Zhang,Ziliang Wang,Yukai Yang,Weidong Chen*

Main category: cs.RO

TL;DR: 提出一种基于矩匹配的点云配准新框架，用于解决稀疏和噪声环境下的对齐问题，无需点对匹配，精度和鲁棒性优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对稀疏点和重噪声条件下点云配准的挑战，传统方法（如ICP和NDT）难以实现鲁棒和精确的对齐。

Method: 提出了一种基于矩匹配的配准框架，将点云视为从源帧和目标帧中提取的独立同分布样本，通过匹配广义高斯径向基矩来估计刚性变换，无需显式的点对对应。

Result: 实验结果表明，该方法在合成和真实数据集上实现了比现有方法更高的精度和鲁棒性，并且在4D雷达SLAM系统中显著提高了定位性能。

Conclusion: 该方法在稀疏和噪声场景下为点云配准提供了鲁棒且精确的解决方案，并且在4D雷达SLAM系统中取得了与基于LiDAR的系统相媲美的使用效果，证明了矩匹配技术在点云配准中的潜力。

Abstract: Point cloud registration is a key step in robotic perception tasks, such as
Simultaneous Localization and Mapping (SLAM). It is especially challenging in
conditions with sparse points and heavy noise. Traditional registration
methods, such as Iterative Closest Point (ICP) and Normal Distributions
Transform (NDT), often have difficulties in achieving a robust and accurate
alignment under these conditions. In this paper, we propose a registration
framework based on moment matching. In particular, the point clouds are
regarded as i.i.d. samples drawn from the same distribution observed in the
source and target frames. We then match the generalized Gaussian Radial Basis
moments calculated from the point clouds to estimate the rigid transformation
between two frames. Moreover, such method does not require explicit
point-to-point correspondences among the point clouds. We further show the
consistency of the proposed method. Experiments on synthetic and real-world
datasets show that our approach achieves higher accuracy and robustness than
existing methods. In addition, we integrate our framework into a 4D Radar SLAM
system. The proposed method significantly improves the localization performance
and achieves results comparable to LiDAR-based systems. These findings
demonstrate the potential of moment matching technique for robust point cloud
registration in sparse and noisy scenarios.

</details>


### [388] [FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation](https://arxiv.org/abs/2508.02190)
*Cui Miao,Tao Chang,Meihan Wu,Hongbin Xu,Chun Li,Ming Li,Xiaodong Wang*

Main category: cs.RO

TL;DR: 提出 FedVLA 联邦学习框架，解决 VLA 模型训练中的隐私问题。通过句子导向场景解析、双门控混合专家（DGMoE）和专家驱动聚合，在保护隐私的同时，实现了与中心化训练相当的性能和更高的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型在机器人操作方面取得了显著进展，但其训练通常依赖于大规模用户特定数据，引发了隐私和安全问题，限制了其广泛应用。为了解决这个问题，我们提出了 FedVLA。

Method: FedVLA 框架整合了任务感知表示学习、自适应专家选择和专家驱动的联邦聚合。具体包括：1. 句子导向场景解析机制：根据任务指令分解和增强对象级特征。2. 双门控混合专家（DGMoE）机制：输入 token 和自感知专家均自适应选择激活。3. 专家驱动聚合策略：在联邦服务器上，通过激活的专家指导模型聚合，实现有效的跨客户端知识转移。

Result: FedVLA 实现了与中心化训练相当的任务成功率，同时有效保护了数据隐私。DGMoE 机制相比其原始版本显著提高了计算效率。

Conclusion: FedVLA 框架在保持数据隐私的同时，实现了与中心化训练相当的任务成功率，并显著提高了计算效率。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
manipulation by enabling robots to interpret language instructions for task
execution. However, training these models often relies on large-scale
user-specific data, raising concerns about privacy and security, which in turn
limits their broader adoption. To address this, we propose FedVLA, the first
federated VLA learning framework, enabling distributed model training that
preserves data privacy without compromising performance. Our framework
integrates task-aware representation learning, adaptive expert selection, and
expert-driven federated aggregation, enabling efficient and privacy-preserving
training of VLA models. Specifically, we introduce an Instruction Oriented
Scene-Parsing mechanism, which decomposes and enhances object-level features
based on task instructions, improving contextual understanding. To effectively
learn diverse task patterns, we design a Dual Gating Mixture-of-Experts (DGMoE)
mechanism, where not only input tokens but also self-aware experts adaptively
decide their activation. Finally, we propose an Expert-Driven Aggregation
strategy at the federated server, where model aggregation is guided by
activated experts, ensuring effective cross-client knowledge transfer.Extensive
simulations and real-world robotic experiments demonstrate the effectiveness of
our proposals. Notably, DGMoE significantly improves computational efficiency
compared to its vanilla counterpart, while FedVLA achieves task success rates
comparable to centralized training, effectively preserving data privacy.

</details>


### [389] [Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot](https://arxiv.org/abs/2508.02194)
*Constant Roux,Elliot Chane-Sane,Ludovic De Matteïs,Thomas Flayols,Jérôme Manhes,Olivier Stasse,Philippe Souères*

Main category: cs.RO

TL;DR: 本研究提出了一种利用约束强化学习来控制足式机器人（特别是具有点式足设计的机器人）的方法，以实现从模拟到现实的迁移，并能在各种干扰下保持平衡和控制速度。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于解决足式机器人（特别是像BOLT这样具有点式足设计的机器人）的双足运动控制这一关键挑战，并应对其固有的不稳定性、缺乏手臂以及足部驱动有限等问题。

Method: 本研究提出了一种利用约束强化学习、约束即终止和域随机化技术来控制类BOLT机器人（一种具有点式足设计的非完全驱动机器人）的方法，以实现从模拟到现实的迁移。

Result: 通过一系列定性和定量实验，在保持平衡、速度控制以及对滑动和推力干扰的响应方面评估了该方法。此外，还通过运输成本和地面反作用力等指标分析了自主性。

Conclusion: 该方法为足式机器人开发了鲁棒的控制策略。

Abstract: Bipedal locomotion is a key challenge in robotics, particularly for robots
like Bolt, which have a point-foot design. This study explores the control of
such underactuated robots using constrained reinforcement learning, addressing
their inherent instability, lack of arms, and limited foot actuation. We
present a methodology that leverages Constraints-as-Terminations and domain
randomization techniques to enable sim-to-real transfer. Through a series of
qualitative and quantitative experiments, we evaluate our approach in terms of
balance maintenance, velocity control, and responses to slip and push
disturbances. Additionally, we analyze autonomy through metrics like the cost
of transport and ground reaction force. Our method advances robust control
strategies for point-foot bipedal robots, offering insights into broader
locomotion.

</details>


### [390] [TacMan-Turbo: Proactive Tactile Control for Robust and Efficient Articulated Object Manipulation](https://arxiv.org/abs/2508.02204)
*Zihang Zhao,Zhenghao Qi,Yuyang Li,Leiyao Cui,Zhi Han,Lecheng Ruan,Yixin Zhu*

Main category: cs.RO

TL;DR: TacMan-Turbo：一种解决机器人操作铰接式物体时有效性和效率之间权衡问题的新型主动触觉控制框架。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人在人类环境中成功运行，必须熟练操作铰接式物体。这种操作既需要有效性（尽管存在不确定的物体结构也能可靠运行），也需要效率（执行迅速，步骤冗余少，动作平稳）。现有方法在同时实现这两个目标方面存在困难。

Method: 提出了一种名为TacMan-Turbo的新型主动触觉控制框架，该框架将触觉接触偏差解释为局部运动学信息的来源，从而能够预测最优的未来交互并进行主动调整，从而显著提高操作效率。

Result: 在对200个不同的模拟铰接式物体和真实世界实验进行的全面评估中，该方法保持了100%的成功率，并在时间效率、动作效率和轨迹平稳性方面显著优于以前的触觉感知方法（所有p值<0.0001）。

Conclusion: 该研究成功解决了机器人操作铰接式物体时有效性和效率之间的长期权衡问题，而无需依赖先验运动学知识。

Abstract: Adept manipulation of articulated objects is essential for robots to operate
successfully in human environments. Such manipulation requires both
effectiveness -- reliable operation despite uncertain object structures -- and
efficiency -- swift execution with minimal redundant steps and smooth actions.
Existing approaches struggle to achieve both objectives simultaneously: methods
relying on predefined kinematic models lack effectiveness when encountering
structural variations, while tactile-informed approaches achieve robust
manipulation without kinematic priors but compromise efficiency through
reactive, step-by-step exploration-compensation cycles. This paper introduces
TacMan-Turbo, a novel proactive tactile control framework for articulated
object manipulation that resolves this fundamental trade-off. Unlike previous
approaches that treat tactile contact deviations merely as error signals
requiring compensation, our method interprets these deviations as rich sources
of local kinematic information. This new perspective enables our controller to
predict optimal future interactions and make proactive adjustments,
significantly enhancing manipulation efficiency. In comprehensive evaluations
across 200 diverse simulated articulated objects and real-world experiments,
our approach maintains a 100% success rate while significantly outperforming
the previous tactile-informed method in time efficiency, action efficiency, and
trajectory smoothness (all p-values < 0.0001). These results demonstrate that
the long-standing trade-off between effectiveness and efficiency in articulated
object manipulation can be successfully resolved without relying on prior
kinematic knowledge.

</details>


### [391] [CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning](https://arxiv.org/abs/2508.02219)
*Dongchi Huang,Zhirui Fang,Tianle Zhang,Yihang Li,Lin Zhao,Chunhe Xia*

Main category: cs.RO

TL;DR: CO-RFT 是一种新颖的框架和算法，通过模仿学习和离线强化学习（含动作分块）对 VLA 模型进行微调，显著提高了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决 VLA 模型使用 RL 进行微调时面临的样本效率、动作分块兼容性和训练稳定性等挑战。

Method: 提出了一种名为 Chunked RL 的新颖强化学习框架，用于 VLA 模型。该框架扩展了时间差分（TD）学习以整合动作分块。在此基础上，提出了一种名为 CO-RFT 的算法，通过模仿学习（IL）和具有动作分块的离线强化学习（RL）对 VLA 模型进行微调。

Result: CO-RFT 在真实环境中取得了显著成果，成功率提高了 57%，周期时间减少了 22.3%，并在新位置实现了 44.3% 的成功率，优于之前的监督方法。

Conclusion: CO-RFT 成功地进行了 VLA 模型微调，在真实环境中实现了 57% 的成功率提升和 22.3% 的周期时间减少，并在未见过的位置实现了 44.3% 的成功率。

Abstract: Vision-Language-Action (VLA) models demonstrate significant potential for
developing generalized policies in real-world robotic control. This progress
inspires researchers to explore fine-tuning these models with Reinforcement
Learning (RL). However, fine-tuning VLA models with RL still faces challenges
related to sample efficiency, compatibility with action chunking, and training
stability. To address these challenges, we explore the fine-tuning of VLA
models through offline reinforcement learning incorporating action chunking. In
this work, we propose Chunked RL, a novel reinforcement learning framework
specifically designed for VLA models. Within this framework, we extend temporal
difference (TD) learning to incorporate action chunking, a prominent
characteristic of VLA models. Building upon this framework, we propose CO-RFT,
an algorithm aimed at fine-tuning VLA models using a limited set of
demonstrations (30 to 60 samples). Specifically, we first conduct imitation
learning (IL) with full parameter fine-tuning to initialize both the backbone
and the policy. Subsequently, we implement offline RL with action chunking to
optimize the pretrained policy. Our empirical results in real-world
environments demonstrate that CO-RFT outperforms previous supervised methods,
achieving a 57% improvement in success rate and a 22.3% reduction in cycle
time. Moreover, our method exhibits robust positional generalization
capabilities, attaining a success rate of 44.3% in previously unseen positions.

</details>


### [392] [Tethered Multi-Robot Systems in Marine Environments](https://arxiv.org/abs/2508.02264)
*Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 一个用于模拟系绳多机器人（AUV和ASV）在动态海洋环境中运动控制的新仿真框架。


<details>
  <summary>Details</summary>
Motivation: 为了评估系绳多机器人系统在动态海洋环境中的运动控制，并开发和测试先进的控制策略。

Method: 使用GazeboSim，并集成了详细的缆绳模型（结合了catenary方程和物理仿真），以在高保真度下模拟AUV和ASV在动态海洋环境中的协同操作。

Result: 该框架能够在高保真度下提供一个仿真平台，用于开发和测试先进的控制策略，并分析复杂的缆绳交互及其对系统性能的影响。

Conclusion: 该框架能够分析复杂的缆绳交互及其对系统性能的影响。

Abstract: This paper introduces a novel simulation framework for evaluating motion
control in tethered multi-robot systems within dynamic marine environments.
Specifically, it focuses on the coordinated operation of an Autonomous
Underwater Vehicle (AUV) and an Autonomous Surface Vehicle(ASV). The framework
leverages GazeboSim, enhanced with realistic marine environment plugins and
ArduPilots SoftwareIn-The-Loop (SITL) mode, to provide a high-fidelity
simulation platform. A detailed tether model, combining catenary equations and
physical simulation, is integrated to accurately represent the dynamic
interactions between the vehicles and the environment. This setup facilitates
the development and testing of advanced control strategies under realistic
conditions, demonstrating the frameworks capability to analyze complex tether
interactions and their impact on system performance.

</details>


### [393] [Framework for Robust Motion Planning of Tethered Multi-Robot Systems in Marine Environments](https://arxiv.org/abs/2508.02287)
*Markus Buchholz,Ignacio Carlucho,Zebin Huang,Michele Grimaldi,Pierre Nicolay,Sumer Tuncay,Yvan R. Petillot*

Main category: cs.RO

TL;DR: CoralGuide是一个用于系绳多机器人系统（特别是海洋环境中的ASV-AUV配置）的路径规划和轨迹优化框架，通过改进的A*算法、悬链线曲线建模和贝塞尔曲线插值来实现安全高效的操作。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为水下机器人系统开发一种新颖的路径规划和轨迹优化框架，特别关注海洋机器人中常见的自主水面航行器（ASV）和自主水下航行器（AUV）的系绳配置。

Method: CoralGuide通过结合为系绳ASV-AUV系统定制的启发式方法来增强A*算法，并集成 यासाठी管理提供支持的悬链线曲线模型，以及用于更平稳的轨迹规划的贝塞尔曲线插值，从而在不影响安全的情况下确保高效且同步的操作。

Result: 通过模拟和真实世界的实验，CoralGuide在改进路径规划和轨迹优化方面的有效性得到了验证，证明了其在增强海洋研究和基础设施检查方面的操作能力具有巨大潜力。

Conclusion: CoralGuide

Abstract: This paper introduces CoralGuide, a novel framework designed for path
planning and trajectory optimization for tethered multi-robot systems. We focus
on marine robotics, which commonly have tethered configurations of an
Autonomous Surface Vehicle (ASV) and an Autonomous Underwater Vehicle (AUV).
CoralGuide provides safe navigation in marine environments by enhancing the A*
algorithm with specialized heuristics tailored for tethered ASV-AUV systems.
Our method integrates catenary curve modelling for tether management and
employs Bezier curve interpolation for smoother trajectory planning, ensuring
efficient and synchronized operations without compromising safety. Through
simulations and real-world experiments, we have validated CoralGuides
effectiveness in improving path planning and trajectory optimization,
demonstrating its potential to significantly enhance operational capabilities
in marine research and infrastructure inspection.

</details>


### [394] [Improving Generalization of Language-Conditioned Robot Manipulation](https://arxiv.org/abs/2508.02405)
*Chenglin Cui,Chaoran Zhu,Changjae Oh,Andrea Cavallaro*

Main category: cs.RO

TL;DR: 提出一个仅用少量演示即可学习物体排列任务的框架，提高了泛化能力和零样本能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在操作看不见的环境时需要大量数据进行微调，而我们提出的框架仅用少量演示即可学习物体排列任务。

Method: 提出一个两阶段框架，将物体排列任务分为目标定位（用于拾取物体）和区域确定（用于放置物体）两个阶段。提出了一个实例级语义融合模块，将实例级图像裁剪与文本嵌入对齐，使模型能够识别自然语言指令定义的 the target objects。

Result: 在模拟和真实机器人环境中验证了所提出的方法，证明了其在真实机器人操作场景中的泛化能力和零样本能力。

Conclusion: 所提出的框架通过少量演示学习物体排列任务，提高了泛化能力，并在真实机器人操作场景中展示了零样本能力。

Abstract: The control of robots for manipulation tasks generally relies on visual
input. Recent advances in vision-language models (VLMs) enable the use of
natural language instructions to condition visual input and control robots in a
wider range of environments. However, existing methods require a large amount
of data to fine-tune VLMs for operating in unseen environments. In this paper,
we present a framework that learns object-arrangement tasks from just a few
demonstrations. We propose a two-stage framework that divides
object-arrangement tasks into a target localization stage, for picking the
object, and a region determination stage for placing the object. We present an
instance-level semantic fusion module that aligns the instance-level image
crops with the text embedding, enabling the model to identify the target
objects defined by the natural language instructions. We validate our method on
both simulation and real-world robotic environments. Our method, fine-tuned
with a few demonstrations, improves generalization capability and demonstrates
zero-shot ability in real-robot manipulation scenarios.

</details>


### [395] [Multi-Class Human/Object Detection on Robot Manipulators using Proprioceptive Sensing](https://arxiv.org/abs/2508.02425)
*Justin Hehli,Marco Heiniger,Maryam Rezayati,Hans Wernher van de Venn*

Main category: cs.RO

TL;DR: 本研究提出了一种改进的人/物检测方法，用于物理人机协作，通过使用三类模型和 LSTM、GRU、Transformers 等先进技术，在实时测试中达到了 91.11% 的准确率，并确定滑动窗口为最佳预处理策略。


<details>
  <summary>Details</summary>
Motivation: 为了在物理人机协作（pHRC）环境中提高机器人分析交互对象以确保安全和促进有意义的工作流程的能力，特别是改进人/物检测以区分软硬物体的能力。

Method: 本研究评估了三类人/物检测模型，并使用 Franka Emika Panda 机器人机械臂收集了数据集，探索了时间序列分析的预处理策略。训练了包括 LSTM、GRU 和 Transformers 在内的模型。

Result: 所提出的三类人/物检测模型在实时测试中达到了 91.11% 的准确率，并且滑动窗口作为最佳预处理策略被确定。

Conclusion: 通过在实时测试中达到 91.11% 的准确率，证明了多类检测模型的可行性。此外，对预处理策略的比较表明，滑动窗口方法是此任务的最佳选择。

Abstract: In physical human-robot collaboration (pHRC) settings, humans and robots
collaborate directly in shared environments. Robots must analyze interactions
with objects to ensure safety and facilitate meaningful workflows. One critical
aspect is human/object detection, where the contacted object is identified.
Past research introduced binary machine learning classifiers to distinguish
between soft and hard objects. This study improves upon those results by
evaluating three-class human/object detection models, offering more detailed
contact analysis. A dataset was collected using the Franka Emika Panda robot
manipulator, exploring preprocessing strategies for time-series analysis.
Models including LSTM, GRU, and Transformers were trained on these datasets.
The best-performing model achieved 91.11\% accuracy during real-time testing,
demonstrating the feasibility of multi-class detection models. Additionally, a
comparison of preprocessing strategies suggests a sliding window approach is
optimal for this task.

</details>


### [396] [Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Humanoid-Robot Interaction](https://arxiv.org/abs/2508.02505)
*Maria Lombardi,Carmela Calabrese,Davide Ghiglino,Caterina Foglino,Davide De Tommaso,Giulia Da Lisca,Lorenzo Natale,Agnieszka Wykowska*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的框架，通过整合先进的感知能力（包括使用ChatGPT等生成模型）来增强iCub人形机器人的注意力，以识别社交线索和理解环境。通过一个共同创作故事的讲故事任务来验证该框架，实验衡量了用户体验和可用性。该技术有望改善人机协作，特别是在援助、教育和康复领域。


<details>
  <summary>Details</summary>
Motivation: 人类机器人交互研究中的一个关键挑战在于开发能够有效感知和解释社交线索的机器人系统，从而促进自然和自适应的交互。

Method: 提出了一种交互任务，实施了一种叙事协议（讲故事任务），在该任务中，人类和机器人通过轮流交换带有创意图像的立方体来共同创作一个简短的想象故事。

Result: 为了验证该协议和框架，进行了实验以量化参与者与系统交互时感知的可用性程度和体验质量。

Conclusion: 该框架通过整合先进的感知能力来增强iCub人形机器人的注意力，使其能够识别社交线索，通过像ChatGPT这样的生成模型理解周围环境，并以符合情境的社交行为做出回应。该系统可以通过促进有效的人机协作，尤其是在需要机器人具备社交意识和响应能力的援助、教育和康复场景中，发挥有益的作用。

Abstract: A key challenge in human-robot interaction research lies in developing
robotic systems that can effectively perceive and interpret social cues,
facilitating natural and adaptive interactions. In this work, we present a
novel framework for enhancing the attention of the iCub humanoid robot by
integrating advanced perceptual abilities to recognise social cues, understand
surroundings through generative models, such as ChatGPT, and respond with
contextually appropriate social behaviour. Specifically, we propose an
interaction task implementing a narrative protocol (storytelling task) in which
the human and the robot create a short imaginary story together, exchanging in
turn cubes with creative images placed on them. To validate the protocol and
the framework, experiments were performed to quantify the degree of usability
and the quality of experience perceived by participants interacting with the
system. Such a system can be beneficial in promoting effective human robot
collaborations, especially in assistance, education and rehabilitation
scenarios where the social awareness and the robot responsiveness play a
pivotal role.

</details>


### [397] [QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots](https://arxiv.org/abs/2508.02512)
*Sheng Wu,Fei Teng,Hao Shi,Qi Jiang,Kai Luo,Kaiwei Wang,Kailun Yang*

Main category: cs.RO

TL;DR: QuaDreamer是首个用于四足机器人的全景数据生成引擎，通过VJE、SOC和PE技术解决了数据稀缺和失真问题，并成功提升了机器人的视觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有全景训练数据稀缺，这主要是由固有的运动学限制和复杂传感器校准挑战造成的，严重制约了为四足机器人平台量身定制的鲁棒感知系统的发展。为了解决这个问题，我们提出了QuaDreamer。

Method: QuaDreamer 是一个专门为四足机器人设计的全景数据生成引擎。它通过模仿四足机器人的运动范式来生成可控、逼真的全景视频。为了捕捉四足机器人运动中的垂直振动特性，提出了垂直抖动编码（VJE）技术，通过频域特征滤波提取可控的垂直信号。为了在抖动信号控制下生成高质量全景视频，提出了场景-对象控制器（SOC），利用注意力机制管理对象运动和增强背景抖动控制。为解决宽视场视频生成中的全景失真问题，提出了全景增强器（PE），采用双流架构，结合频域纹理细化和空间结构校正，以实现局部细节增强和全局几何一致性。

Result: QuaDreamer 生成的全景视频序列能够有效提升四足机器人全景视觉感知模型在360度场景下的多目标跟踪性能。

Conclusion: QuaDreamer 生成的全景视频可作为训练数据，用于增强四足机器人全景视觉感知模型在360度场景下的多目标跟踪性能。

Abstract: Panoramic cameras, capturing comprehensive 360-degree environmental data, are
suitable for quadruped robots in surrounding perception and interaction with
complex environments. However, the scarcity of high-quality panoramic training
data-caused by inherent kinematic constraints and complex sensor calibration
challenges-fundamentally limits the development of robust perception systems
tailored to these embodied platforms. To address this issue, we propose
QuaDreamer-the first panoramic data generation engine specifically designed for
quadruped robots. QuaDreamer focuses on mimicking the motion paradigm of
quadruped robots to generate highly controllable, realistic panoramic videos,
providing a data source for downstream tasks. Specifically, to effectively
capture the unique vertical vibration characteristics exhibited during
quadruped locomotion, we introduce Vertical Jitter Encoding (VJE). VJE extracts
controllable vertical signals through frequency-domain feature filtering and
provides high-quality prompts. To facilitate high-quality panoramic video
generation under jitter signal control, we propose a Scene-Object Controller
(SOC) that effectively manages object motion and boosts background jitter
control through the attention mechanism. To address panoramic distortions in
wide-FoV video generation, we propose the Panoramic Enhancer (PE)-a dual-stream
architecture that synergizes frequency-texture refinement for local detail
enhancement with spatial-structure correction for global geometric consistency.
We further demonstrate that the generated video sequences can serve as training
data for the quadruped robot's panoramic visual perception model, enhancing the
performance of multi-object tracking in 360-degree scenes. The source code and
model weights will be publicly available at
https://github.com/losehu/QuaDreamer.

</details>


### [398] [Failure-Aware Multi-Robot Coordination for Resilient and Adaptive Target Tracking](https://arxiv.org/abs/2508.02529)
*Peihan Li,Jiazhen Liu,Yuwei Wu,Gaurav S. Sukhatme,Vijay Kumar,Lifeng Zhou*

Main category: cs.RO

TL;DR: 为了应对真实世界中多机器人系统面临的临时和永久故障，我们提出了一种统一的故障感知协调框架。该框架将机器人分为通信组和独立运行的机器人，以实现弹性目标跟踪。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的多机器人部署通常会遇到各种故障，包括传感和通信的临时和永久中断，如果不加以明确建模，会严重降低系统鲁棒性和性能。然而，目前的文献对考虑故障的协调研究不足。

Method: 我们提出了一种统一的、考虑故障的多机器人协调框架，用于在临时和永久故障条件下进行弹性自适应的多机器人目标跟踪。我们将机器人团队划分为子组。保持连接的机器人组成通信组，并使用部分中心化的非线性优化进行协作规划。经历永久断开或故障的机器人通过分散式或个体优化独立运行，使它们能够在局部环境中为任务做出贡献。

Result: 我们的方法系统地区分了两种故障：(1) 概率性和临时性中断，机器人通过动态调整路径和避开推断出的危险区域来从间歇性的传感或通信损失中恢复；(2) 永久性故障，机器人永久丢失传感或通信能力，需要持续的分散式行为适应。我们通过广泛的基准测试和全面的真实世界故障场景评估来评估我们的方法。

Conclusion: 该框架在具有未知危险区域的真实环境中始终如一地实现稳健性能，为多机器人系统社区提供了一个实用且可泛化的解决方案。

Abstract: Multi-robot coordination is crucial for autonomous systems, yet real-world
deployments often encounter various failures. These include both temporary and
permanent disruptions in sensing and communication, which can significantly
degrade system robustness and performance if not explicitly modeled. Despite
its practical importance, failure-aware coordination remains underexplored in
the literature. To bridge the gap between idealized conditions and the
complexities of real-world environments, we propose a unified failure-aware
coordination framework designed to enable resilient and adaptive multi-robot
target tracking under both temporary and permanent failure conditions. Our
approach systematically distinguishes between two classes of failures: (1)
probabilistic and temporary disruptions, where robots recover from intermittent
sensing or communication losses by dynamically adapting paths and avoiding
inferred danger zones, and (2) permanent failures, where robots lose sensing or
communication capabilities irreversibly, requiring sustained, decentralized
behavioral adaptation. To handle these scenarios, the robot team is partitioned
into subgroups. Robots that remain connected form a communication group and
collaboratively plan using partially centralized nonlinear optimization. Robots
experiencing permanent disconnection or failure continue to operate
independently through decentralized or individual optimization, allowing them
to contribute to the task within their local context. We extensively evaluate
our method across a range of benchmark variations and conduct a comprehensive
assessment under diverse real-world failure scenarios. Results show that our
framework consistently achieves robust performance in realistic environments
with unknown danger zones, offering a practical and generalizable solution for
the multi-robot systems community.

</details>


### [399] [An RGB-D Camera-Based Multi-Small Flying Anchors Control for Wire-Driven Robots Connecting to the Environment](https://arxiv.org/abs/2508.02544)
*Shintaro Inoue,Kento Kawaharazuka,Keita Yoneda,Sota Yuzaki,Yuta Sahara,Temma Suzuki,Kei Okada*

Main category: cs.RO

TL;DR: 机器人通过飞行锚和RGB-D相机，能够自主连接环境线缆，扩大了作业范围和负载能力。


<details>
  <summary>Details</summary>
Motivation: 为了扩大机器人的作业范围和负载能力，需要解决线驱动机器人自主连接环境线缆的技术难题，使其能在未经特殊设计的环境中实际应用。

Method: 提出了一种利用多小型飞行锚系统，并结合基于RGB-D相机的控制与环境识别方法，使机器人能够自主地将多条线缆连接到环境中。

Result: 该方法能够识别合适的附着点和飞行锚位置，在非预先设计好的环境中自主连接多条线缆，并支持同时连接多条线缆。

Conclusion: 该研究提出的自主连接多条线缆至环境的机器人，能够实现线驱动操作的优势，不受限于特定地点。

Abstract: In order to expand the operational range and payload capacity of robots,
wire-driven robots that leverage the external environment have been proposed.
It can exert forces and operate in spaces far beyond those dictated by its own
structural limits. However, for practical use, robots must autonomously attach
multiple wires to the environment based on environmental recognition-an
operation so difficult that many wire-driven robots remain restricted to
specialized, pre-designed environments. Here, in this study, we propose a robot
that autonomously connects multiple wires to the environment by employing a
multi-small flying anchor system, as well as an RGB-D camera-based control and
environmental recognition method. Each flying anchor is a drone with an
anchoring mechanism at the wire tip, allowing the robot to attach wires by
flying into position. Using the robot's RGB-D camera to identify suitable
attachment points and a flying anchor position, the system can connect wires in
environments that are not specially prepared, and can also attach multiple
wires simultaneously. Through this approach, a wire-driven robot can
autonomously attach its wires to the environment, thereby realizing the
benefits of wire-driven operation at any location.

</details>


### [400] [Vision-based Navigation of Unmanned Aerial Vehicles in Orchards: An Imitation Learning Approach](https://arxiv.org/abs/2508.02617)
*Peng Wei,Prabhash Ragbir,Stavros G. Vougioukas,Zhaodan Kong*

Main category: cs.RO

TL;DR: 通过基于VAE的视觉导航系统，无人机能在果园自主飞行，表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决在果园等有障碍物和缺乏GPS的复杂环境中，自主无人机导航的挑战。

Method: 提出了一种基于学习的方法，使用基于变分自编码器（VAE）的控制器，并通过基于干预的学习框架进行训练，使无人机能够从人类经验中学习视觉运动策略。

Result: 在真实果园环境中，经过少量训练后，基于VAE的控制器即可根据前置摄像头流畅地进行自主导航，展现出优越的避障性能，实现更远的飞行距离和更少的人工干预，并且优于现有算法。该策略能够有效地泛化到新的环境，并在不同的条件和速度下保持竞争力。

Conclusion: 所提出的基于VAE的控制器在真实果园环境中通过了验证，展示了强大的自主导航、避障能力，并优于现有算法，同时在新的环境中表现出良好的泛化能力，在精度农业方面具有巨大潜力。

Abstract: Autonomous unmanned aerial vehicle (UAV) navigation in orchards presents
significant challenges due to obstacles and GPS-deprived environments. In this
work, we introduce a learning-based approach to achieve vision-based navigation
of UAVs within orchard rows. Our method employs a variational autoencoder
(VAE)-based controller, trained with an intervention-based learning framework
that allows the UAV to learn a visuomotor policy from human experience. We
validate our approach in real orchard environments with a custom-built
quadrotor platform. Field experiments demonstrate that after only a few
iterations of training, the proposed VAE-based controller can autonomously
navigate the UAV based on a front-mounted camera stream. The controller
exhibits strong obstacle avoidance performance, achieves longer flying
distances with less human assistance, and outperforms existing algorithms.
Furthermore, we show that the policy generalizes effectively to novel
environments and maintains competitive performance across varying conditions
and speeds. This research not only advances UAV autonomy but also holds
significant potential for precision agriculture, improving efficiency in
orchard monitoring and management.

</details>


### [401] [HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents](https://arxiv.org/abs/2508.02629)
*Yibin Liu,Zhixuan Liang,Zanxin Chen,Tianxing Chen,Mengkang Hu,Wanxi Dong,Congsheng Xu,Zhaoming Han,Yusen Qin,Yao Mu*

Main category: cs.RO

TL;DR: HyCodePolicy 是一个混合语言控制框架，用于通过闭环编程周期（包括代码合成、几何基础、感知监控和迭代修复）来生成和修复自主代理的策略，从而提高鲁棒性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统在适应性地监控策略执行和在任务完成期间修复代码方面存在不足。

Method: HyCodePolicy 是一个混合语言控制框架，将代码合成、几何基础、感知监控和迭代修复系统地集成到自主代理的闭环编程周期中。该系统接收自然语言指令，将其分解为子目标，并生成第一个以面向对象的几何基元为基础的可执行程序。然后，该程序在模拟中执行，同时视觉语言模型（VLM）观察选定的检查点以检测和定位执行失败并推断失败原因。通过融合捕获程序级事件的结构化执行跟踪与基于 VLM 的感知反馈，HyCodePolicy 推断失败原因并修复程序。

Result: HyCodePolicy 显著提高了机器人操控策略的鲁棒性和样本效率。

Conclusion: HyCodePolicy 显著提高了机器人操控策略的鲁棒性和样本效率，为将多模态推理集成到自主决策管道中提供了一种可扩展的策略。

Abstract: Recent advances in multimodal large language models (MLLMs) have enabled
richer perceptual grounding for code policy generation in embodied agents.
However, most existing systems lack effective mechanisms to adaptively monitor
policy execution and repair codes during task completion. In this work, we
introduce HyCodePolicy, a hybrid language-based control framework that
systematically integrates code synthesis, geometric grounding, perceptual
monitoring, and iterative repair into a closed-loop programming cycle for
embodied agents. Technically, given a natural language instruction, our system
first decomposes it into subgoals and generates an initial executable program
grounded in object-centric geometric primitives. The program is then executed
in simulation, while a vision-language model (VLM) observes selected
checkpoints to detect and localize execution failures and infer failure
reasons. By fusing structured execution traces capturing program-level events
with VLM-based perceptual feedback, HyCodePolicy infers failure causes and
repairs programs. This hybrid dual feedback mechanism enables self-correcting
program synthesis with minimal human supervision. Our results demonstrate that
HyCodePolicy significantly improves the robustness and sample efficiency of
robot manipulation policies, offering a scalable strategy for integrating
multimodal reasoning into autonomous decision-making pipelines.

</details>


### [402] [Manip4Care: Robotic Manipulation of Human Limbs for Solving Assistive Tasks](https://arxiv.org/abs/2508.02649)
*Yubin Koh,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: Manip4Care是一个机器人模拟流程，用于抓取和重新定位人体四肢，以增强辅助护理能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有辅助机器人解决方案假设人类保持静态或准静态的问题，该研究提出了一种名为Manip4Care的模块化模拟流程，使机器人能够有效地抓取和重新定位人体四肢，以增强机器人为严重行动不便的个体提供辅助护理的能力。

Method: 该方法采用带力闭合的对跖采样来抓取肢体，并利用模型预测路径积分（MPPI）和基于矢量场的控制方法在避免碰撞和生物力学约束下生成运动轨迹。

Result: Manip4Care是一个包含抓取和重新定位技术的物理模拟器，考虑了生物力学和避免碰撞的约束。

Conclusion: 该方法在仰卧和坐姿下对各种肢体操作任务进行了评估，并比较了不同年龄组具有不同肩关节限制的结果。此外，该方法还使用真实的衣身模型进行了肢体操作演示，并在床上沐浴任务中进行了有效性展示。

Abstract: Enabling robots to grasp and reposition human limbs can significantly enhance
their ability to provide assistive care to individuals with severe mobility
impairments, particularly in tasks such as robot-assisted bed bathing and
dressing. However, existing assistive robotics solutions often assume that the
human remains static or quasi-static, limiting their effectiveness. To address
this issue, we present Manip4Care, a modular simulation pipeline that enables
robotic manipulators to grasp and reposition human limbs effectively. Our
approach features a physics simulator equipped with built-in techniques for
grasping and repositioning while considering biomechanical and collision
avoidance constraints. Our grasping method employs antipodal sampling with
force closure to grasp limbs, and our repositioning system utilizes the Model
Predictive Path Integral (MPPI) and vector-field-based control method to
generate motion trajectories under collision avoidance and biomechanical
constraints. We evaluate this approach across various limb manipulation tasks
in both supine and sitting positions and compare outcomes for different age
groups with differing shoulder joint limits. Additionally, we demonstrate our
approach for limb manipulation using a real-world mannequin and further
showcase its effectiveness in bed bathing tasks.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [403] [Binary Hypothesis Testing-Based Low-Complexity Beamspace Channel Estimation for mmWave Massive MIMO Systems](https://arxiv.org/abs/2508.01007)
*Hanyoung Park,Ji-Woong Choi*

Main category: eess.SP

TL;DR: 提出一种低复杂度信道去噪器，通过贝叶斯二元假设检验和波束空间稀疏性，在毫米波系统中实现与复杂方法相当的信道估计精度。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信信道估计的计算复杂度与天线数量成正比，在需要频繁更新的毫米波系统中可能成为显著的负担。

Method: 提出一种基于贝叶斯二元假设检验和波束空间稀疏性的低复杂度信道去噪器。将稀疏波束空间分量建模为具有伯努利-复高斯先验的信号和噪声的混合物，构建似然比检验来检测与信号相关的元素。然后，应用硬阈值规则来抑制噪声主导的波束空间分量。

Result: 尽管计算复杂度极低，但该方法实现的信道估计精度可与复杂的迭代或基于学习的方法相媲美。

Conclusion: 该方法通过理论分析和数值评估得到验证，表明该方法是毫米波系统中满足严格资源限制的可行选项。

Abstract: Millimeter-wave (mmWave) communications have gained attention as a key
technology for high-capacity wireless systems, owing to the wide available
bandwidth. However, mmWave signals suffer from their inherent characteristics
such as severe path loss, poor scattering, and limited diffraction, which
necessitate the use of large antenna arrays and directional beamforming,
typically implemented through massive MIMO architectures. Accurate channel
estimation is critical in such systems, but its computational complexity
increases proportionally with the number of antennas. This may become a
significant burden in mmWave systems where channels exhibit rapid fluctuations
and require frequent updates. In this paper, we propose a low-complexity
channel denoiser based on Bayesian binary hypothesis testing and beamspace
sparsity. By modeling each sparse beamspace component as a mixture of signal
and noise under a Bernoulli-complex Gaussian prior, we formulate a likelihood
ratio test to detect signal-relevant elements. Then, a hard-thresholding rule
is applied to suppress noise-dominant components in the noisy channel vector.
Despite its extremely low computational complexity, the proposed method
achieves channel estimation accuracy that is comparable to that of complex
iterative or learning-based approaches. This effectiveness is supported by both
theoretical analysis and numerical evaluation, suggesting that the method can
be a viable option for mmWave systems with strict resource constraints.

</details>


### [404] [Coordinated Decentralized Resource Optimization for Cell-Free ISAC Systems](https://arxiv.org/abs/2508.01044)
*Mehdi Zafari,Rang Liu,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 本文提出了两种协调分布式优化算法，用于解决现有ISAC方案的可扩展性问题，并在分布式、无小区架构中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有ISAC解决方案依赖于集中式架构和需要完整网络知识的问题，本文提出了分布式优化算法以提高可扩展性。

Method: 本文提出了两种协调分布式优化算法用于波束形成和功率分配。第一种算法在接入点（AP）使用本地设计的固定波束，并通过中央服务器（CS）进行集中式功率分配。第二种算法通过完全分布式的共识ADMM框架联合优化波束形成和功率控制。这两种方法都依赖于AP的本地信息以及与CS的有限协调。

Result: 仿真结果（使用提出的Python仿真框架）评估了算法的前导开销和系统级性能，证明了它们在分布式、无小区架构中可扩展部署的实用性。

Conclusion: 所提出的两种协调分布式优化算法（一种基于本地固定波束形成和集中式功率分配，另一种基于完全分布式共识ADMM框架）为可扩展的ISAC部署提供了实际可行的解决方案，特别是在分布式、无小区架构中。

Abstract: Integrated Sensing and Communication (ISAC) is emerging as a key enabler for
6G wireless networks, allowing the joint use of spectrum and infrastructure for
both communication and sensing. While prior ISAC solutions have addressed
resource optimization, including power allocation, beamforming, and waveform
design, they often rely on centralized architectures with full network
knowledge, limiting their scalability in distributed systems. In this paper, we
propose two coordinated decentralized optimization algorithms for beamforming
and power allocation tailored to cell-free ISAC networks. The first algorithm
employs locally designed fixed beamformers at access points (APs), combined
with a centralized power allocation scheme computed at a central server (CS).
The second algorithm jointly optimizes beamforming and power control through a
fully decentralized consensus ADMM framework. Both approaches rely on local
information at APs and limited coordination with the CS. Simulation results
obtained using our proposed Python-based simulation framework evaluate their
fronthaul overhead and system-level performance, demonstrating their
practicality for scalable ISAC deployment in decentralized, cell-free
architectures.

</details>


### [405] [A Highly Available GTFS-RT Positions System](https://arxiv.org/abs/2508.01121)
*Joshua Wong,Kin Tsang*

Main category: eess.SP

TL;DR: We develop a system for real-time public transportation data using GTFS-RT and deploy it on a highly available cluster.


<details>
  <summary>Details</summary>
Motivation: We develop a system for real-time public transportation data

Method: We give an overview of the design of a physical GPS sensor device, its firmware, and processes. Next, we give the algorithms used to translate raw sensor data into a public GTFS-RT data feed.

Result: We develop a system for real-time public transportation data, deciding to use the data standard GTFS-RT (GTFS Realtime), an open data format for public transit data.

Conclusion: We deploy this feed over a highly available cluster across multiple regions to maintain high availability.

Abstract: We develop a system for real-time public transportation data, deciding to use
the data standard GTFS-RT (GTFS Realtime), an open data format for public
transit data. We give an overview of the design of a physical GPS sensor
device, its firmware, and processes. Next, we give the algorithms used to
translate raw sensor data into a public GTFS-RT data feed. We deploy this feed
over a highly available cluster across multiple regions to maintain high
availability.

</details>


### [406] [On the Characterization and Evaluation of Doppler Squint in Wideband ODDM Systems](https://arxiv.org/abs/2508.01283)
*Xuehan Wang,Jinhong Yuan,Jintao Wang,Zhi Sun*

Main category: eess.SP

TL;DR: This paper analyzes the impact of the Doppler squint effect (DSE) on Orthogonal Delay-Doppler Division Multiplexing (ODDM) systems, addressing performance degradation issues in previous analyses. It derives the characterization of DSE for different ODDM system types, revealing extra delay-Doppler spread and power leakage. The findings are crucial for advancing signal processing in integrated sensing and communication systems.


<details>
  <summary>Details</summary>
Motivation: To address the performance degradation possibly caused by the interactive dispersion from the wideband property of ODDM signals, which is often ignored in prior analysis.

Method: The input-output relation of ODDM systems considering the wideband effect (DSE) is investigated. The extra delay-Doppler (DD) dispersion caused by the DSE is explicitly explained using the time-variant frequency response of multipath channels, and its characterization is derived for both reduced cyclic prefix (RCP) and zero padded (ZP)-based wideband ODDM systems.

Result: The extra DD spread and more complicated power leakage outside the peak region caused by DSE are presented theoretically for both RCP and ZP-based wideband ODDM systems.

Conclusion: The significance of Doppler squint effect (DSE) is confirmed by numerical results, and the derivations are beneficial for developing accurate signal processing techniques in ODDM-based integrated sensing and communication systems.

Abstract: The recently proposed orthogonal delay-Doppler division multiplexing (ODDM)
modulation has been demonstrated to enjoy excellent reliability over
doubly-dispersive channels. However, most of the prior analysis tends to ignore
the interactive dispersion caused by the wideband property of ODDM signal,
which possibly leads to performance degradation. To solve this problem, we
investigate the input-output relation of ODDM systems considering the wideband
effect, which is also known as the Doppler squint effect (DSE) in the
literature. The extra delay-Doppler (DD) dispersion caused by the DSE is first
explicitly explained by employing the time-variant frequency response of
multipath channels. Its characterization is then derived for both reduced
cyclic prefix (RCP) and zero padded (ZP)-based wideband ODDM systems, where the
extra DD spread and more complicated power leakage outside the peak region are
presented theoretically. Numerical results are finally provided to confirm the
significance of DSE. The derivations in this paper are beneficial for
developing accurate signal processing techniques in ODDM-based integrated
sensing and communication systems.

</details>


### [407] [Statistical Multiport-Network Modeling and Efficient Discrete Optimization of RIS](https://arxiv.org/abs/2508.01776)
*Cheima Hammami,Luc Le Magoarou,Philipp del Hougne*

Main category: eess.SP

TL;DR: 本研究针对具有互耦（MC）和1位可调谐元件（常见硬件约束）的可重构智能表面（RIS）进行了物理一致优化。研究比较了基于模型和无模型的方法，并评估了智能初始化的效果。通过一种新的统计系综生成技术，可以调整MC强度。结果表明，坐标下降法配合随机初始化在性能、执行时间和资源消耗方面取得了最佳平衡，尤其是在MC效应显著时。该研究结果可推广至多种智能表面和波域物理神经网络。


<details>
  <summary>Details</summary>
Motivation: 填补了现有RIS原型中常见的硬件约束——具有互耦（MC）和1位可调谐元件的可重构智能表面（RIS）的物理一致优化方面的研究空白。

Method: 提出了一种用于生成多端口网络模型参数的统计系综的技术，该技术推广到具有确定性可编程性的无线电环境中的瑞利衰落，并考虑了无源约束和相干后向散射效应。比较了基于模型的方法（温度退火反向传播）和无模型的方法（坐标下降、遗传算法），并评估了智能初始化这些方法的潜在好处。

Result: 坐标下降法与随机初始化结合，在性能、执行时间和内存使用方面提供了最佳的权衡，尤其是在MC不可忽略的情况下。

Conclusion: 除MC可忽略外，具有随机初始化的坐标下降法在性能、执行时间和内存使用方面提供了最有利的权衡。

Abstract: This Letter fills the research gap on physics-consistent optimization for
reconfigurable intelligent surfaces (RISs) with mutual coupling (MC) and
1-bit-tunable elements, a common hardware constraint in existing RIS
prototypes. We compare a model-based method (temperature-annealed
back-propagation) and model-agnostic methods (coordinate descent, genetic
algorithm), and evaluate potential benefits of intelligently initializing these
methods. To facilitate our evaluation, we introduce a technique for generating
statistical ensembles of multiport-network model parameters, wherein a single
hyper-parameter adjusts the MC strength. The technique is a generalization of
Rayleigh fading to radio environments with deterministic programmability, and
it accounts for passivity constraints as well as the coherent-backscattering
effect. We find that, except when MC is negligible, coordinate descent with
random initialization yields the most favorable trade-off in terms of
performance, execution time and memory usage. We expect our findings to extend
to beyond-diagonal RIS, stacked intelligent metasurfaces, dynamic metasurface
antennas, and wave-domain physical neural networks.

</details>


### [408] [DIY hybrid SSVEP-P300 LED stimuli for BCI platform using EMOTIV EEG headset](https://arxiv.org/abs/2508.01510)
*Surej Mouli,Ramaswamy Palaniappan*

Main category: eess.SP

TL;DR: 开发了一种能同时产生SSVEP和P300信号的混合BCI硬件，并成功用于控制机器人。


<details>
  <summary>Details</summary>
Motivation: 为了在脑机接口（BCI）中实现更高效、更可靠的控制，本研究旨在开发一种能够同时诱发SSVEP和P300两种脑电信号的混合BCI硬件平台，以期减少用户疲劳并提高分类性能。

Method: 本研究设计了一种基于32位微控制器的COB LED系统，能够独立控制绿色LED阵列产生SSVEP信号，并控制红色LED阵列产生P300信号。系统能够记录P300事件的时间戳，并进行了实时分类测试。

Result: 所提出的混合BCI系统成功地通过控制LEGO机器人进行实时分类，实现了对四个方向的精确控制，验证了其在提高分类准确性和可靠性方面的潜力。

Conclusion: 本研究提出了一种全定制化的COB LED设计，能够同时引发SSVEP和P300两种脑部反应。该混合BCI硬件平台通过控制四个独立的径向绿色视觉刺激（用于SSVEP）和四个以随机间隔闪烁的红色LED（用于P300），实现了精确的刺激和减少疲劳。系统还能记录P300事件的时间戳，以提高分类准确性和可靠性。实验结果表明，该混合刺激在控制LEGO机器人进行实时分类任务时表现出良好的性能。

Abstract: A fully customisable chip-on board (COB) LED design to evoke two brain
responses simultaneously (steady state visual evoked potential (SSVEP) and
transient evoked potential, P300) is discussed in this paper. Considering
different possible modalities in braincomputer interfacing (BCI), SSVEP is
widely accepted as it requires a lesser number of electroencephalogram (EEG)
electrodes and minimal training time. The aim of this work was to produce a
hybrid BCI hardware platform to evoke SSVEP and P300 precisely with reduced
fatigue and improved classification performance. The system comprises of four
independent radial green visual stimuli controlled individually by a 32-bit
microcontroller platform to evoke SSVEP and four red LEDs flashing at random
intervals to generate P300 events. The system can also record the P300 event
timestamps that can be used in classification, to improve the accuracy and
reliability. The hybrid stimulus was tested for realtime classification
accuracy by controlling a LEGO robot to move in four directions.

</details>


### [409] [Balancing Latency and Model Accuracy for Fluid Antenna-Assisted LM-Embedded MIMO Network](https://arxiv.org/abs/2508.01689)
*Yichen Jin,Zongze Li,Zeyi Ren,Qingfeng Lin,Yik-Chung Wu*

Main category: eess.SP

TL;DR: 该论文提出了一种FA辅助LM嵌入式网络，利用FA技术降低网络延迟并保持模型精度，并通过优化的优化算法实现。


<details>
  <summary>Details</summary>
Motivation: 为了解决LM嵌入式无线网络中模型精度和网络延迟之间的权衡问题，需要在保证可接受的推理精度的同时最小化网络延迟。

Method: 提出了一种基于块坐标下降的优化算法来设计FA辅助LM嵌入式网络，目标是最小化延迟和最大化PSNR。

Result: 仿真结果表明，所提出的算法具有良好的收敛性，并且FA辅助LM嵌入式网络在网络延迟和PSNR方面优于其他基准网络。

Conclusion: 所提出的FA辅助LM嵌入式网络在网络延迟和PSNR方面优于其他基准网络。

Abstract: This paper addresses the challenge of large model (LM)-embedded wireless
network for handling the trade-off problem of model accuracy and network
latency. To guarantee a high-quality of users' service, the network latency
should be minimized while maintaining an acceptable inference accuracy. To meet
this requirement, LM quantization is proposed to reduce the latency. However,
the excessive quantization may destroy the accuracy of LM inference. To this
end, a promising fluid antenna (FA) technology is investigated for enhancing
the transmission capacity, leading to a lower network latency in the
LM-embedded multiple-input multiple-output (MIMO) network. To design the
FA-assisted LM-embedded network with the lower latency and higher accuracy
requirements, the latency and peak signal to noise ratio (PSNR) are considered
in the objective function. Then, an efficient optimization algorithm is
proposed under the block coordinate descent framework. Simulation results are
provided to show the convergence behavior of the proposed algorithm, and the
performance gains from the proposed FA-assisted LMembedded network over the
other benchmark networks in terms of network latency and PSNR.

</details>


### [410] [Spectrum Sensing with Deep Clustering: Label-Free Radio Access Technology Recognition](https://arxiv.org/abs/2508.01709)
*Ljupcho Milosheski,Mihael Mohorčič,Carolina Fortuna*

Main category: eess.SP

TL;DR: 本研究提出了一种无需标记数据的频谱感知方法，并使用 SSL 深度聚类从 FFT 数据中提取特征。该方法在真实数据集上表现优于现有技术，参数和计算量更少。


<details>
  <summary>Details</summary>
Motivation: 连接设备数量的增长和网络密度的增加，特别是在射频频谱方面，推动了对无线电网络资源的需求。然而，目前最先进的无线技术（RAT）分类研究主要依赖于监督式卷积神经网络（CNN），而这种方法需要大量的标记数据。因此，现有模型在缺乏训练数据的环境中如何表现，以及它们的泛化能力如何，仍是悬而未决的问题。

Method: 该研究提出了一种新的频谱感知工作流程，并采用了一种能够从原始一维快速傅里叶变换 (FFT) 数据中自主提取频谱特征的 SSL 深度聚类架构。

Result: 在包含超过 10 个 RAT 的三个欧洲城市的真实世界数据集（868 MHz、2.4 GHz 和 5.9 GHz 频段）上评估了所提出的架构。结果表明，与最先进的基于 AE 的参考架构相比，所开发的模型实现了高达 35 个百分点的性能提升，同时可训练参数减少了 22%，每秒浮点运算次数（FLOPS）减少了 50%。

Conclusion: 该研究提出了一种新的频谱感知工作流程，其中模型训练不需要预先了解该区域的 RAT（即无需标记数据），并且可以通过手动映射轻松完成类分配。

Abstract: The growth of the number of connected devices and network densification is
driving an increasing demand for radio network resources, particularly Radio
Frequency (RF) spectrum. Given the dynamic and complex nature of contemporary
wireless environments, characterized by a wide variety of devices and multiple
RATs, spectrum sensing is envisioned to become a building component of future
6G, including as a component within O-RAN or digital twins. However, the
current SotA research for RAT classification predominantly revolves around
supervised Convolutional Neural Network (CNN)-based approach that require
extensive labeled dataset. Due to this, it is unclear how existing models
behave in environments for which training data is unavailable thus leaving open
questions regarding their generalization capabilities. In this paper, we
propose a new spectrum sensing workflow in which the model training does not
require any prior knowledge of the RATs transmitting in that area (i.e. no
labelled data) and the class assignment can be easily done through manual
mapping. Furthermore, we adapt a SSL deep clustering architecture capable of
autonomously extracting spectrum features from raw 1D Fast Fourier Transform
(FFT) data. We evaluate the proposed architecture on three real-world datasets
from three European cities, in the 868 MHz, 2.4 GHz and 5.9 GHz bands
containing over 10 RATs and show that the developed model achieves superior
performance by up to 35 percentage points with 22% fewer trainable parameters
and 50% less floating-point operations per second (FLOPS) compared to an SotA
AE-based reference architecture.

</details>


### [411] [ModFus-DM: Explore the Representation in Modulated Signal Diffusion Generated Models](https://arxiv.org/abs/2508.01719)
*Haoyue Tan,Yu Li,Zhenxi Zhang,Xiaoran Shi,Feng Zhou*

Main category: eess.SP

TL;DR: 提出了一种名为ModFus-DM的无监督自动调制分类框架，利用扩散模型学习调制表示，解决了现有方法在处理不定长信号、分布偏移和有限标签数据时的挑战，并在多项实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的自动调制分类（AMC）方法需要大量的标记信号，并且在处理不定长信号、分布偏移和有限标记信号方面存在困难。

Method: 提出了一种名为ModFus-DM的无监督自动调制分类框架，利用扩散模型的生成能力进行鲁棒的调制表示学习。该框架包含一个调制信号扩散生成模型（MSDGM）和一个扩散感知特征融合（DAFFus）模块，分别用于隐式捕获结构和语义信息以及自适应聚合多尺度扩散特征。

Result: 在RML2016.10A、RML2016.10B、RML2018.01A和RML2022数据集上的大量实验表明，ModFus-DM在有限标签、分布偏移、可变长度信号识别和信道衰落等多种挑战性场景下，相比现有方法具有显著的性能提升。

Conclusion: ModFus-DM框架在多种挑战性场景下显著优于现有方法，特别是在仅有10个标签信号的情况下，在24类识别任务中信噪比大于等于12dB时准确率超过88.27%。

Abstract: Automatic modulation classification (AMC) is essential for wireless
communication systems in both military and civilian applications. However,
existing deep learning-based AMC methods often require large labeled signals
and struggle with non-fixed signal lengths, distribution shifts, and limited
labeled signals. To address these challenges, we propose a modulation-driven
feature fusion via diffusion model (ModFus-DM), a novel unsupervised AMC
framework that leverages the generative capacity of diffusion models for robust
modulation representation learning. We design a modulated signal diffusion
generation model (MSDGM) to implicitly capture structural and semantic
information through a progressive denoising process. Additionally, we propose
the diffusion-aware feature fusion (DAFFus) module, which adaptively aggregates
multi-scale diffusion features to enhance discriminative representation.
Extensive experiments on RML2016.10A, RML2016.10B, RML2018.01A and RML2022
datasets demonstrate that ModFus-DM significantly outperforms existing methods
in various challenging scenarios, such as limited-label settings, distribution
shifts, variable-length signal recognition and channel fading scenarios.
Notably, ModFus-DM achieves over 88.27% accuracy in 24-type recognition tasks
at SNR $\geq $ 12dB with only 10 labeled signals per type.

</details>


### [412] [FAS Enabled UAV for Energy-Efficient WPCNs](https://arxiv.org/abs/2508.01771)
*Nagla Abuzgaia,Abdelhamid Salem,Ahmed Elbarsha*

Main category: eess.SP

TL;DR: 本研究提出了一种在无线供电通信网络中使用流体天线无人机的创新方案，通过动态调整天线位置来提高通信速率和能源效率，并提供了数学推导和模拟验证。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过部署新兴的流体天线系统（FAS）技术到无人机（UAV）上，以提高无人机在无线供电通信网络（WPCNs）中的通信速率和能源效率（EE）。

Method: 提出了一种利用流体天线系统（FAS）技术增强无人机（UAV）在无线供电通信网络（WPCNs）中通信速率和能源效率（EE）的创新方案。

Result: 蒙特卡洛模拟结果证实了我们推导的解析表达式的准确性，并表明与固定天线系统相比，本方案能显著提高无人机的能源效率。

Conclusion: 本提出的方法利用流体天线系统的动态端口切换能力，使无人机能够自适应地选择最佳天线位置，从而最大化下行链路无线能量传输（WPT）和上行链路无线数据传输（WDT）的信道增益。在Nakagami-m相关衰落信道下，我们推导了遍历谱率的精确解析表达式和高信噪比（SNR）下的渐近表达式。蒙特卡洛模拟结果证实了解析的准确性，并表明与固定天线系统相比，使用流体天线系统的无人机的能效得到了显著提高。

Abstract: This letter presents an innovative scheme to enhance the communication rate
and energy efficiency (EE) of Unmanned Aerial Vehicle (UAV) in wireless powered
communication networks (WPCNs) by deploying the emerging fluid antenna system
(FAS) technology onto the UAV. Our proposed approach leverages the dynamic port
switching capability of FAS, enabling the UAV to adaptively select the optimal
antenna location that maximizes channel gain for both downlink wireless power
transfer (WPT) and uplink wireless data transfer (WDT). We derive both exact
analytical expression of the ergodic spectral rate, and asymptotic expression
at high signal to noise ratio (SNR) regime under Nakagami-m correlated fading
channels. The Mont-Carlo simulation results confirms the accuracy of the
analytical expressions and demonstrate the substantial increase in energy
efficiency of UAV with FAS compared to fixed antenna systems.

</details>


### [413] [A Heuristic Method for Simplified Resource Allocation based on Comparative Advantage in Wireless Access Systems](https://arxiv.org/abs/2508.01824)
*Lin Cheng,Bernardo A. Huberman*

Main category: eess.SP

TL;DR: 本篇论文提出了一种启发式方法，利用比较优势简化了资源分配问题，特别是在PD-NOMA系统中，有效降低了计算复杂度并提高了性能，适用于下一代无线网络。


<details>
  <summary>Details</summary>
Motivation: 为了简化资源分配，降低计算复杂性，同时保持接近最优的性能。

Method: 提出了一种利用比较优势概念的启发式方法，以简化接入系统中的资源分配，并以功率分配非正交多址（PD-NOMA）为例，解决了多小区网络中的功率分配问题，通过将搜索空间维度减半来降低计算开销。

Result: 该方法显著降低了计算开销，确保了有效的频谱利用，并将搜索空间维度减半。

Conclusion: 该方法通过简化资源分配问题，减少计算复杂度，同时保持接近最优的性能，并已通过广泛的分析和模拟得到验证，显示出其在下一代无线网络中实际部署的潜力。

Abstract: This paper presents a heuristic method for simplifying resource allocation in
access systems, leveraging the concept of comparative advantage to reduce
computational complexity while maintaining near-optimal performance. Using
power-division non-orthogonal multiple access (PD-NOMA) as an example, we
demonstrate how this approach mitigates the challenge of power allocation in
multi-cell networks. Our method reduces the search space for optimization,
significantly decreasing computational overhead while ensuring efficient
spectrum utilization. In principle, the method reduces the dimensions of search
space by half. Extensive analysis and simulations validate its effectiveness,
highlighting its potential for practical deployment in next-generation wireless
networks. The proposed framework can help streamline resource allocation in
complex communication environments, enhancing system performance and
scalability.

</details>


### [414] [RIS-Aided Near-Field Channel Estimation under Mutual Coupling and Spatial Correlation](https://arxiv.org/abs/2508.01828)
*Ahmad Dkhan,Simon Tarboush,Hadi Sarieddeen,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 该研究改进了降维最小二乘（RS-LS）信道估计算法，以应对RIS辅助MIMO系统中的互耦和近场传播挑战，并在近场条件下实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了应对RIS与超大规模MIMO集成带来的高维信道矩阵、计算复杂度和导频开销问题，以及互耦、空间相关和近场传播等挑战。

Method: 提出并改进了降维最小二乘（RS-LS）估计算法，通过利用阵列几何和明确纳入互耦（MC）效应来提高信道估计的准确性，特别是在广义RIS辅助MIMO框架和近场传播条件下。

Result: 在包含互耦效应的情况下，RS-LS算法在5 dB信噪比下实现了约5 dB的性能增益，证明了考虑互耦对于提高信道估计性能的重要性，并分析了互耦对空间自由度的影响。

Conclusion: 该研究通过在广义RIS辅助MIMO框架中明确纳入互耦效应，解决了高维信道估计中的挑战，并在近场传播环境下，相较于忽略互耦的传统方法，实现了约5 dB的性能提升。

Abstract: The integration of reconfigurable intelligent surfaces (RIS) with extremely
large multiple-input multiple-output (MIMO) arrays at the base station has
emerged as a key enabler for enhancing wireless network performance. However,
this setup introduces high-dimensional channel matrices, leading to increased
computational complexity and pilot overhead in channel estimation. Mutual
coupling (MC) effects among densely packed unit cells, spatial correlation, and
near-field propagation conditions further complicate the estimation process.
Conventional estimators, such as linear minimum mean square error (MMSE),
require channel statistics that are challenging to acquire for high-dimensional
arrays, while least squares (LS) estimators suffer from performance
limitations. To address these challenges, the reduced-subspace least squares
(RS-LS) estimator leverages array geometry to enhance estimation accuracy. This
work advances the promising RS-LS estimation algorithm by explicitly
incorporating MC effects into the more realistic and challenging near-field
propagation environment within the increasingly relevant generalized RIS-aided
MIMO framework. Additionally, we investigate the impact of MC on the spatial
degrees of freedom (DoF). Our analysis reveals that accounting for MC effects
provides a significant performance gain of approximately 5 dB at an SNR of 5
dB, compared to conventional methods that ignore MC.

</details>


### [415] [Feature Reconstruction Aided Federated Learning for Image Semantic Communication](https://arxiv.org/abs/2508.02048)
*Yoon Huh,Bumjun Kim,Wan Choi*

Main category: eess.SP

TL;DR: FedSFR是一种联邦学习算法，通过特征重建提高了语义通信中JSCC模块的稳定性和图像传输质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于JSCC的神经网络（NN）模块在图像传输中表现出性能随时间下降的问题，这是由于其知识库过时，需要定期更新。

Method: 提出了一种名为FedSFR的联邦学习（FL）算法，该算法结合了语义特征重建（FR），允许部分FL参与者传输较小的特征向量而非本地更新信息，并将FR集成到参数服务器（PS）以稳定训练。

Result: 实验结果表明，与其它算法相比，FedSFR显著提高了FL过程的稳定性和有效性，并且通过数学推导的收敛率也验证了其性能的提升。

Conclusion: FedSFR算法通过整合参数服务器（PS）的特征重建（FR）功能，有效解决了现有语义通信系统中JSCC模块性能随时间下降的问题，并通过数学推导验证了其收敛性。

Abstract: Research in semantic communication has garnered considerable attention,
particularly in the area of image transmission, where joint source-channel
coding (JSCC)-based neural network (NN) modules are frequently employed.
However, these systems often experience performance degradation over time due
to an outdated knowledge base, highlighting the need for periodic updates. To
address this challenge in the context of training JSCC modules for image
transmission, we propose a federated learning (FL) algorithm with semantic
feature reconstruction (FR), named FedSFR. This algorithm more efficiently
utilizes the available communication capacity by allowing some of the selected
FL participants to transmit smaller feature vectors instead of local update
information. Unlike conventional FL methods, our approach integrates FR at the
parameter server (PS), stabilizing training and enhancing image transmission
quality. Experimental results demonstrate that the proposed scheme
significantly enhances both the stability and effectiveness of the FL process
compared to other algorithms. Furthermore, we mathematically derive the
convergence rate to validate the improved performance.

</details>


### [416] [Scoring ISAC: Benchmarking Integrated Sensing and Communications via Score-Based Generative Modeling](https://arxiv.org/abs/2508.02117)
*Lin Chen,Chang Cai,Huiyuan Yang,Xiaojun Yuan,Ying-Jun Angela Zhang*

Main category: eess.SP

TL;DR: ISAC的评分：一种利用基于评分的生成模型评估ISAC系统在现实条件下的性能的方法。


<details>
  <summary>Details</summary>
Motivation: 理论性能指标在评估ISAC系统性能极限方面起着关键作用。然而，在实际中，硬件损伤、多径传播、干扰和场景约束等因素使得分析推导这些指标具有挑战性。最近，人们对应用基于评分的生成模型从数据中表征这些指标产生了浓厚的兴趣。

Method: 本论文总结了基于评分的性能评估的最新进展，重点介绍了ISAC系统。本框架将经典性能指标与分数函数联系起来，并提供了学习分数函数以估计性能指标的实用训练技术。

Result: 概念验证实验验证了基于评分的性能估计器与地面真实分析表达式相比的准确性，说明了它们在更复杂、更真实的环境中复制和扩展传统分析的能力。

Conclusion: 基于评分的生成模型在ISAC性能分析、算法设计和系统优化方面具有巨大潜力。

Abstract: Integrated sensing and communications (ISAC) is a key enabler for
next-generation wireless systems, aiming to support both high-throughput
communication and high-accuracy environmental sensing using shared spectrum and
hardware. Theoretical performance metrics, such as mutual information (MI),
minimum mean squared error (MMSE), and Bayesian Cram\'{e}r--Rao bound (BCRB),
play a key role in evaluating ISAC system performance limits. However, in
practice, hardware impairments, multipath propagation, interference, and scene
constraints often result in nonlinear, multimodal, and non-Gaussian
distributions, making it challenging to derive these metrics analytically.
Recently, there has been a growing interest in applying score-based generative
models to characterize these metrics from data, although not discussed for
ISAC. This paper provides a tutorial-style summary of recent advances in
score-based performance evaluation, with a focus on ISAC systems. We refer to
the summarized framework as scoring ISAC, which not only reflects the core
methodology based on score functions but also emphasizes the goal of scoring
(i.e., evaluating) ISAC systems under realistic conditions. We present the
connections between classical performance metrics and the score functions and
provide the practical training techniques for learning score functions to
estimate performance metrics. Proof-of-concept experiments on target detection
and localization validate the accuracy of score-based performance estimators
against ground-truth analytical expressions, illustrating their ability to
replicate and extend traditional analyses in more complex, realistic settings.
This framework demonstrates the great potential of score-based generative
models in ISAC performance analysis, algorithm design, and system optimization.

</details>


### [417] [An Overview of Algorithms for Contactless Cardiac Feature Extraction from Radar Signals: Advances and Challenges](https://arxiv.org/abs/2508.02122)
*Yuanyuan Zhang,Rui Yang,Yutao Yue,Eng Gee Lim,Zidong Wang*

Main category: eess.SP

TL;DR: 本文是首篇聚焦于阐述从雷达信号中提取心跳特征的算法的综述，对算法进行了分类和评估，并提供了数据集列表、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 针对雷达心跳监测领域中，雷达信号处理部分的研究缺乏全面综述的现状，旨在提供一个关于心跳特征提取算法的全面概述。

Method: 对提取接收到的雷达信号中的心脏特征的算法进行了阐述，并提出了一种新的分类方法，详细评估了每个算法的优缺点。

Result: 列出了包含接收到的雷达信号和地面真实心脏特征信号的公开数据集及其详细配置，并对算法进行了分类和优缺点评估。

Conclusion: 本篇综述可以作为研究人员和实践者快速了解心跳特征提取算法的研究趋势和最新进展的指南，其提出的挑战和未来方向值得进一步研究。

Abstract: Contactless cardiac monitoring has vast potential to replace contact-based
monitoring in various future scenarios such as smart home and in-cabin
monitoring. Various contactless sensors can be potentially implemented for
cardiac monitoring, such as cameras, acoustic sensors, Wi-Fi routers and
radars. Among all these sensors, radar could achieve unobtrusive monitoring
with high accuracy and robustness at the same time. The research about
radar-based cardiac monitoring can be generally divided into the radar
architecture design and signal-processing parts, where the former has been
thoroughly reviewed in the literature but not the latter. To the best of the
author knowledge, this is the first review paper that focuses on elaborating
the algorithms for extracting cardiac features from the received radar signal.
In addition, a new taxonomy is proposed to reveal the core feature of each
algorithm, with the pros and cons evaluated in detail. Furthermore, the public
datasets containing the received radar signal and ground-truth cardiac feature
signal are listed with detailed configurations, and the corresponding
evaluations may help the researchers select the suitable dataset. At last,
several unsolved challenges and future directions are suggested and discussed
in detail to encourage future research on solving the main obstacles in this
field. In summary, this review can be served as a guide for researchers and
practitioners to quickly understand the research trend and recent development
of the cardiac feature extraction algorithms, and it is worth further
investigating the relative area based on the proposed challenges and future
directions.

</details>


### [418] [Analysis of Broad Beam Beamforming for Collocated and Distributed MIMO](https://arxiv.org/abs/2508.02135)
*Ahmet Kaplan,Diana P. M. Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: This paper evaluates and improves dual-polarization beamforming (DPBF) for MIMO systems, especially in non-line-of-sight conditions. A new DPBF method for distributed MIMO offers better coverage than collocated MIMO DPBF, and orthogonal space-time block codes further enhance coverage in collocated systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to evaluate and improve the efficiency of phase-only dual-polarization beamforming (DPBF) in MIMO systems, particularly in non-line-of-sight (NLoS) scenarios, to enhance initial access, synchronization, and sensing capabilities in cellular networks.

Method: This paper evaluates dual-polarization beamforming (DPBF) in collocated and distributed MIMO configurations under both line-of-sight (LoS) and non-line-of-sight (NLoS) channel conditions. It models reflection coefficients for NLoS materials and proposes orthogonal space-time block code for collocated MIMO, as well as a novel DPBF method for distributed MIMO.

Result: The evaluation shows that DPBF can be effective under LoS and NLoS conditions. The proposed orthogonal space-time block code improves coverage in collocated MIMO. The novel DPBF method for distributed MIMO achieves better coverage than DPBF in collocated MIMO.

Conclusion: In conclusion, the proposed DPBF method for distributed MIMO systems offers superior coverage compared to DPBF in collocated MIMO configurations, especially under non-line-of-sight conditions. The use of orthogonal space-time block code also enhances coverage in collocated MIMO.

Abstract: Broad beam beamforming (BF) design in multiple-input multiple-output (MIMO)
can be convenient for initial access, synchronization, and sensing capabilities
in cellular networks by avoiding overheads of sweeping methods while making
efficient use of resources. Phase-only BF is key for maximizing power
efficiency across antennas. A successful method to produce broad beams is the
phase-only dual-polarization BF (DPBF). However, its efficiency has not been
proved in non-line-of-sight (NLoS). Therefore, this paper contributes by
evaluating DPBF in collocated and distributed MIMO configurations under both
line-of-sight (LoS) and NLoS channel conditions. We model the reflection
coefficients for different materials in NLoS conditions and propose the use of
orthogonal space-time block code to improve the coverage compared to the DPBF
in collocated MIMO (C-MIMO). We further propose a DPBF method for distributed
MIMO and show that it achieves better coverage than C-MIMO with DPBF.

</details>


### [419] [The ECME Algorithm Using Factor Analysis for DOA Estimation in Nonuniform Noise](https://arxiv.org/abs/2508.02223)
*Mingyan Gong*

Main category: eess.SP

TL;DR: ECME算法在到达方向估计方面比FAAN方法更快、更高效。


<details>
  <summary>Details</summary>
Motivation: 为了在未知非均匀噪声中进行到达方向估计，并提高现有方法的收敛性和效率。

Method: 设计了期望/条件最大化期望（ECME）算法，它是期望最大化算法的扩展。

Result: 数值结果表明，ECME算法收敛稳定，计算效率更高。

Conclusion: ECME算法在估计到达方向方面收敛更快、更高效。

Abstract: Maximum likelihood factor analysis has been used for direction of arrival
estimation in unknown nonuniform noise and some iterative approaches have been
developed. In particular, the Factor Analysis for Anisotropic Noise (FAAN)
method proposed by Stoica and Babu has excellent convergence properties. In
this letter, the Expectation/Conditional Maximization Either (ECME) algorithm,
an extension of the expectation-maximization algorithm, is designed, which has
almost the same computational complexity at each iteration as the FAAN method.
However, numerical results show that the ECME algorithm yields faster stable
convergence and is computationally more efficient.

</details>


### [420] [Adaptive Phase-Shifted Pilot Design for Uplink Multiple Access in ISAC Systems](https://arxiv.org/abs/2508.02334)
*Ahmet Sacid Sümer,Ebubekir Memişoğlu,Hüseyin Arslan*

Main category: eess.SP

TL;DR: APS-ISAC通过UE特定的相移和重叠块试点结构，解决了ISAC系统中导频设计中的SE和传感性能权衡问题，并提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决正交频分多址（OFDMA） ISAC 系统中传统导频分配方案在频谱效率（SE）和传感性能之间权衡的问题，并克服相移ISAC（PS-ISAC）方案的频谱效率低下问题。

Method: 提出了一种自适应相移ISAC（APS-ISAC）方案，该方案采用重叠块试点结构，并通过最大过量延迟确定UE特定的相移。

Result: APS-ISAC在SE方面显著优于传统的导频分配方法，实现了约两倍的用户复用数量，在功率约束下实现了更低的均方误差（MSE）和更低的复杂度，并实现了最大的范围分辨率和无模糊传感性能。

Conclusion: APS-ISAC是一种可扩展、频谱高效、抗模糊且低复杂度的上行链路ISAC系统试点设计范例。

Abstract: In uplink integrated sensing and communication (ISAC) systems, pilot signal
design is crucial for enabling accurate channel estimation and reliable radar
sensing. In orthogonal frequency-division multiple access (OFDMA)-based
frameworks, conventional pilot allocation schemes face a trade-off between
spectral efficiency (SE) and sensing performance. Interleaved pilots improve
user equipment (UE) multiplexing through sparse allocation but reduce the
maximum unambiguous range. Conversely, orthogonal block-based pilots reduce
range ambiguity but degrade sensing resolution due to limited delay
granularity. To address this trade-off, the phase-shifted ISAC (PS-ISAC) scheme
was recently proposed for uplink multiple access in ISAC systems. However,
PS-ISAC suffers from spectral inefficiency due to the fixed cyclic prefix (CP)
constraints. To overcome these limitations, we propose adaptive
phase-shifted-ISAC (APS-ISAC), an enhanced pilot scheme that employs an
overlapped block-pilot structure with UE-specific phase shifts determined by
maximum excess delay of each UE. This design enables UEs to share the same
time-frequency resources while preserving separable and contiguous channel
impulse responses (CIRs) at the base station (BS). Simulation results show that
APS-ISAC significantly outperforms conventional pilot allocation methods in
terms of SE, approximately doubling the number of multiplexed UEs. It also
achieves lower mean square error (MSE) under power constraints with reduced
complexity. Furthermore, it yields maximum range resolution and unambiguous
sensing performance. These results establish APS-ISAC as a scalable, spectrally
efficient, ambiguity-resilient, and low-complexity pilot design paradigm for
future uplink ISAC systems.

</details>


### [421] [Detecting and measuring respiratory events in horses during exercise with a microphone: deep learning vs. standard signal processing](https://arxiv.org/abs/2508.02349)
*Jeanne I. M. Parmentier,Rhana M. Aarts,Elin Hernlund,Marie Rhodin,Berend Jan van der Zwaag*

Main category: eess.SP

TL;DR: 本研究通过深度学习方法自动检测运动马匹的呼吸声并计算呼吸频率，其中时间卷积网络表现最佳，为马匹健康监测提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了解训练对马匹健康和表现的影响，并最终改善马匹福利，监测呼吸频率等呼吸参数可能是有益的。

Method: 比较了深度学习方法（包括时间卷积网络和长短期记忆网络）和改编后的信号处理方法，以自动检测周期性呼吸事件并从麦克风录音中提取动态呼吸频率。

Result: 深度学习模型能够检测呼气声音（中位数F1分数0.94），并在嘈杂的麦克风信号中表现出有希望的结果。时间卷积网络在检测呼气事件和估计动态呼吸频率方面优于长短期记忆网络和信号处理方法（中位数F1：0.94，平均绝对误差±置信区间：1.44±1.04 bpm，一致性界限：0.63±7.06 bpm）。

Conclusion: 该研究首次实现了对运动马匹呼吸声的自动检测和动态呼吸频率的自动计算。未来将对较低运动强度的声音进行验证，并评估不同的麦克风放置方式以找到最佳组合。

Abstract: Monitoring respiration parameters such as respiratory rate could be
beneficial to understand the impact of training on equine health and
performance and ultimately improve equine welfare. In this work, we compare
deep learning-based methods to an adapted signal processing method to
automatically detect cyclic respiratory events and extract the dynamic
respiratory rate from microphone recordings during high intensity exercise in
Standardbred trotters. Our deep learning models are able to detect exhalation
sounds (median F1 score of 0.94) in noisy microphone signals and show promising
results on unlabelled signals at lower exercising intensity, where the
exhalation sounds are less recognisable. Temporal convolutional networks were
better at detecting exhalation events and estimating dynamic respiratory rates
(median F1: 0.94, Mean Absolute Error (MAE) $\pm$ Confidence Intervals (CI):
1.44$\pm$1.04 bpm, Limits Of Agreements (LOA): 0.63$\pm$7.06 bpm) than long
short-term memory networks (median F1: 0.90, MAE$\pm$CI: 3.11$\pm$1.58 bpm) and
signal processing methods (MAE$\pm$CI: 2.36$\pm$1.11 bpm). This work is the
first to automatically detect equine respiratory sounds and automatically
compute dynamic respiratory rates in exercising horses. In the future, our
models will be validated on lower exercising intensity sounds and different
microphone placements will be evaluated in order to find the best combination
for regular monitoring.

</details>


### [422] [Toward a reliable PWM-based light-emitting diode visual stimulus for improved SSVEP response with minimal visual fatigue](https://arxiv.org/abs/2508.02359)
*Surej Mouli,Ramaswamy Palaniappan*

Main category: eess.SP

TL;DR: 为了解决 SSVEP 的眼部疲劳和 PWM 精度低的问题，研究人员测试了不同的占空比。结果发现 85% 的占空比可实现最佳响应。


<details>
  <summary>Details</summary>
Motivation: 为了解决 SSVEP 的眼部疲劳和脉冲宽度调制 (PWM) 精度低的问题。

Method: 通过在 50% 到 95% 的 PWM 占空比下记录脑电图数据来研究极高的占空比。

Result: 与在所有频率值下使用更高的占空比相比，用户报告的眼部劳损更少，并且在 85% 的占空比下观察到受试者无关的峰值响应。

Conclusion: 通过使用 85% 的占空比可以提高 SSVEP 的鲁棒性，并为 SSVEP 在实际应用中的广泛使用铺平道路。

Abstract: Steady state visual evoked response (SSVEP) is widely used in visual-based
diagnosis and applications such as brain computer interfacing due to its high
information transfer rate and the capability to activate commands through
simple gaze control. However, one major impediment in using flashing visual
stimulus to obtain SSVEP is eye fatigue that prevents continued long term use
preventing practical deployment. This combined with the difficulty in
establishing precise pulse-width modulation (PWM) that results in poorer
accuracy warrants the development of appropriate approach to solve these
issues. Various studies have suggested the usage of high frequencies of visual
stimulus to reduce the visual fatigue for the user but this results in poor
response performance. Here, the authors study the use of extremely high
duty-cycles in the stimulus in the hope of solving these constraints.
Electroencephalogram data was recorded with PWM duty-cycles of 50 to 95%
generated by a precise custom-made light-emitting diode hardware and tested ten
subjects responded that increasing duty-cycles had less visual strain for all
the frequency values and the SSVEP exhibited a subject-independent peak
response for duty-cycle of 85%. This could pave the way for increased usage of
SSVEP for practical applications.

</details>


### [423] [The Role of Review Process Failures in Affective State Estimation: An Empirical Investigation of DEAP Dataset](https://arxiv.org/abs/2508.02417)
*Nazmun N Khan,Taylor Sweet,Chase A Harvey,Calder Knapp,Dean J. Krusienski,David E Thompson*

Main category: eess.SP

TL;DR: EEG情感状态估计的101项研究中，87%存在方法错误，导致精度虚高，暴露了神经科学机器学习应用中评估和同行评审的不足。


<details>
  <summary>Details</summary>
Motivation: EEG数据在情感状态估计的可靠性受到质疑，因为报告的性能差异很大且缺乏标准化评估协议。

Method: 通过回顾101项研究，特别是使用DEAP数据集进行情感识别的研究，分析其中方法上的问题，并通过实验分析这些问题对分类精度的影响。

Result: 近87%的研究存在方法错误，如数据泄露、特征选择偏差、超参数优化错误、类别不平衡处理不当和方法报告不足。这些错误最多会将分类精度提高46%。

Conclusion: 研究发现，机器学习在神经科学应用中的同行评审过程存在严重缺陷，亟需更严格的方法和评估标准。

Abstract: The reliability of affective state estimation using EEG data is in question,
given the variability in reported performance and the lack of standardized
evaluation protocols. To investigate this, we reviewed 101 studies, focusing on
the widely used DEAP dataset for emotion recognition. Our analysis revealed
widespread methodological issues that include data leakage from improper
segmentation, biased feature selection, flawed hyperparameter optimization,
neglect of class imbalance, and insufficient methodological reporting. Notably,
we found that nearly 87% of the reviewed papers contained one or more of these
errors. Moreover, through experimental analysis, we observed that such
methodological flaws can inflate the classification accuracy by up to 46%.
These findings reveal fundamental gaps in standardized evaluation practices and
highlight critical deficiencies in the peer review process for machine learning
applications in neuroscience, emphasizing the urgent need for stricter
methodological standards and evaluation protocols.

</details>


### [424] [Secure Energy Efficient Wireless Transmission: A Finite v/s Infinite-Horizon RL Solution](https://arxiv.org/abs/2508.02447)
*Shalini Tripathi,Ankur Bansal,Holger Claussen,Lester Ho,Chinmoy Kundu*

Main category: eess.SP

TL;DR: 本研究提出了一种联合优化方案，通过在有限的时间内分配发送功率和干扰功率来最大化SEE。所提出的FHJPA算法在SEE、安全比特和计算复杂度方面均优于GA和IHJPA算法。


<details>
  <summary>Details</summary>
Motivation: 为了在有限的时间持续时间内最大化无线网络的平均保密能源效率（SEE），并利用全双工能力。

Method: 提出FHJPA算法来解决有限时间RL问题，并提出IHJPA算法来解决无限时间问题，并与贪婪算法（GA）进行比较。

Result: FHJPA算法在SEE、预期的总传输安全比特数和计算复杂度方面优于GA和IHJPA算法。FHJPA算法的计算时间比IHJPA算法少16.6%。

Conclusion: 所提出的FHJPA算法在有限时间持续时间内，在保密能源效率（SEE）、预期的总传输安全比特数和计算复杂度方面，优于GA和IHJPA算法。当信源节点电池有足够能量时，GA的性能接近FHJPA算法。当传输时间范围增加时，无限范围模型的准确性提高，FHJPA和IHJPA算法之间的性能差距减小。FHJPA算法的计算时间比IHJPA算法少16.6%。

Abstract: In this paper, a joint optimal allocation of transmit power at the source and
jamming power at the destination is proposed to maximize the average secrecy
energy efficiency (SEE) of a wireless network within a finite time duration.
The destination transmits the jamming signal to improve secrecy by utilizing
full-duplex capability. The source and destination both have energy harvesting
(EH) capability with limited battery capacity. Due to the Markov nature of the
system, the problem is formulated as a finite-horizon reinforcement learning
(RL) problem. We propose the finite-horizon joint power allocation (FHJPA)
algorithm for the finite-horizon RL problem and compare it with a
low-complexity greedy algorithm (GA). An infinite-horizon joint power
allocation (IHJPA) algorithm is also proposed for the corresponding
infinite-horizon problem. A comparative analysis of these algorithms is carried
out in terms of SEE, expected total transmitted secure bits, and computational
complexity. The results show that the FHJPA algorithm outperforms the GA and
IHJPA algorithms due to its appropriate modelling in finite horizon
transmission. When the source node battery has sufficient energy, the GA can
yield performance close to the FHJPA algorithm despite its low-complexity. When
the transmission time horizon increases, the accuracy of the infinite-horizon
model improves, resulting in a reduced performance gap between FHJPA and IHJPA
algorithms. The computational time comparison shows that the FHJPA algorithm
takes $16.6$ percent less time than the IHJPA algorithm.

</details>


### [425] [Inverse harmonic clustering for multi-pitch estimation: an optimal transport approach](https://arxiv.org/abs/2508.02471)
*Anton Björkman,Filip Elvander*

Main category: eess.SP

TL;DR: 本文提出了一种基于最优传输理论的新型多音调估计框架，该框架通过正则化和解耦字典设计来克服现有方法的局限性，并能有效处理不谐和现象。实验结果表明，该方法在性能上优于传统方法，并能与现有的基于网络的方法相媲美。


<details>
  <summary>Details</summary>
Motivation: 旨在解决多音调估计问题，即从噪声测量中识别叠加的截断谐波序列。

Method: 提出了一种基于最优传输理论的正则化方法，用于多音调估计问题。该框架将信号的频谱内容推断并分配给一组由基本频率定义的目标谐波序列，从而实现信号的恢复。

Result: 推导了两种估计方法（一种用于随机信号，一种用于确定性信号），并提出了实现它们的高效数值算法，在数值研究中显示出优越的估计性能。

Conclusion: 所提出的方法在合成数据和真实数据上均优于其他统计信号处理文献中的方法，并且在不专门针对数据类型进行训练且推理时无法获得更多数据的情况下，其性能与其他基于网络的方法相当或更优。

Abstract: In this work, we consider the problem of multi-pitch estimation, i.e.,
identifying super-imposed truncated harmonic series from noisy measurements. We
phrase this as recovering a harmonically-structured measure on the unit circle,
where the structure is enforced using regularizers based on optimal transport
theory. In the resulting framework, a signal's spectral content is
simultaneously inferred and assigned, or transported, to a small set of
harmonic series defined by their corresponding fundamental frequencies. In
contrast to existing methods from the compressed sensing paradigm, the proposed
framework decouples regularization and dictionary design and mitigates
coherency problems. As a direct consequence, this also introduces robustness to
the phenomenon of inharmonicity. From this framework, we derive two estimation
methods, one for stochastic and one for deterministic signals, and propose
efficient numerical algorithms implementing them. In numerical studies on both
synthetic and real data, the proposed methods are shown to achieve better
estimation performance as compared to other methods from statistical signal
processing literature. Furthermore, they perform comparably or better than
network-based methods, except when the latter are specially trained on the
data-type considered and are given access to considerably more data during
inference.

</details>


### [426] [Cramér-Rao Bound for Direct Position Estimation in OFDM Based Cellular Systems](https://arxiv.org/abs/2508.02559)
*Sijia Li,Rui Sun,Bing Xu,Yuanwei Liu*

Main category: eess.SP

TL;DR: 本文研究了OFDM系统中DPE的CRB，并将其与传统两步定位法进行比较，结果表明DPE在NLOS环境中更优，大带宽和增加子载波间距对精度有益，使用多个OFDM符号能提高精度但增加计算量。


<details>
  <summary>Details</summary>
Motivation: 尽管直接位置估计（DPE）已被证明在GNSS接收器中具有增强的鲁棒性，但其理论极限和在OFDM基定位系统中的性能在很大程度上仍未被探索。

Method: 本文推导了用于OFDM蜂窝信号的DPE的Cram'er-Rao界（CRB），并将其与传统两步定位方法进行了基准测试，以评估它们在非视距（NLOS）主导的多径环境中的相对性能。

Result: DPE方法在OFDM系统中始终优于两步法；大带宽对两种方法都至关重要，增加子载波间距比固定带宽更有益；利用多个OFDM符号进行定位可显著提高定位精度，但会显著增加计算复杂度。

Conclusion: 虽然DPE方法在所有评估条件下始终优于两步法，并且大带宽对两种方法都至关重要，但增加子载波间距比固定带宽更有益。

Abstract: Although direct position estimation (DPE) has been demonstrated to offer
enhanced robustness in GNSS receivers, its theoretical limits and performance
in OFDM based positioning systems remain largely unexplored. In this paper, the
Cram\'er-Rao bound (CRB) for DPE using OFDM based cellular signals is derived
and benchmarked against the conventional two-step positioning method to assess
their relative performance in non-line-of-sight (NLOS) dominated multipath
environments. Numerical results reveal that 1) the DPE method consistently
outperforms the two-step approach in OFDM systems under all evaluated
conditions; 2) a large bandwidth is crucial in both methods, and increasing
subcarrier spacing is more beneficial for a fixed bandwidth; 3) utilizing
multiple OFDM symbols for positioning leads to substantial improvements in
localization accuracy compared to relying on a single symbol. However, further
increasing the number of symbols yields marginal improvements while
significantly increasing computational complexity.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [427] [Expressive Power of Graph Transformers via Logic](https://arxiv.org/abs/2508.01067)
*Veeti Ahvonen,Maurice Funk,Damian Heiman,Antti Kuusisto,Carsten Lutz*

Main category: cs.LO

TL;DR: This paper analyzes the expressive power of graph transformers (GTs) and GPS-networks. It finds that GPS-networks with real numbers match graded modal logic with global modality for FO properties, and with floats match graded modal logic with counting global modality universally. Similar results are found for GTs.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to understand the precise expressive power of graph transformers (GTs), which are the foundation of modern large language models, particularly in the context of graphs. Despite their importance, there is limited knowledge about their capabilities.

Method: The study analyzes the expressive power of graph transformers (GTs) and GPS-networks by Dwivedi and Bresson (2020) and Rampasek et al. (2022) respectively. It considers both soft-attention and average hard-attention mechanisms. The analysis is performed in two scenarios: a theoretical setting using real numbers and a practical setting using floats. Expressive power is characterized using graded modal logic (GML) with global modality and counting global modality, as well as propositional logic with the global modality and counting global modality.

Result: With real numbers, GPS-networks exhibit the same expressive power as graded modal logic (GML) with the global modality, specifically for vertex properties definable in first-order logic (FO). When using floats, GPS-networks demonstrate equal expressiveness to GML with the counting global modality, a finding that holds universally and is not restricted to properties definable in a background logic. Comparable characterizations are also derived for GTs in relation to propositional logic with the global modality (for reals) and the counting global modality (for floats).

Conclusion: The paper characterizes the expressive power of graph transformers (GTs) and GPS-networks under different settings (real numbers and floats) and attention mechanisms (soft and hard). It shows that GPS-networks with reals are as expressive as graded modal logic with the global modality for first-order logic definable properties. With floats, GPS-networks are equally expressive as graded modal logic with the counting global modality, an absolute result. Similar characterizations are found for GTs.

Abstract: Transformers are the basis of modern large language models, but relatively
little is known about their precise expressive power on graphs. We study the
expressive power of graph transformers (GTs) by Dwivedi and Bresson (2020) and
GPS-networks by Ramp\'asek et al. (2022), both under soft-attention and average
hard-attention. Our study covers two scenarios: the theoretical setting with
real numbers and the more practical case with floats. With reals, we show that
in restriction to vertex properties definable in first-order logic (FO),
GPS-networks have the same expressive power as graded modal logic (GML) with
the global modality. With floats, GPS-networks turn out to be equally
expressive as GML with the counting global modality. The latter result is
absolute, not restricting to properties definable in a background logic. We
also obtain similar characterizations for GTs in terms of propositional logic
with the global modality (for reals) and the counting global modality (for
floats).

</details>


### [428] [Relative Completeness of Incorrectness Separation Logic](https://arxiv.org/abs/2508.01535)
*Yeonseok Lee,Koji Nakazawa*

Main category: cs.LO

TL;DR: ISL证明系统在处理堆操作的欠近似问题上优于传统逻辑，本研究证明了其相对完整性，并提出了一种新的规范化方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统逻辑（如Hoare逻辑或分离逻辑）在处理程序中的欠近似问题时所遇到的困难，以及ISL自身尚未被证明的完整性问题。

Method: 利用最弱后置条件的表达能力和包含变量别名的规范化来证明ISL的相对完整性。

Result: 证明了ISL的相对完整性，并提出了一种包含变量别名的规范化方法来计算ISL中的最弱后置条件。

Conclusion: ISL的相对完整性已经得到证明，它通过利用最弱后置条件和包含变量别名的规范化来处理堆操作中的欠近似问题，这与传统逻辑中的过近似方法不同。

Abstract: Incorrectness Separation Logic (ISL) is a proof system that is tailored
specifically to resolve problems of under-approximation in programs that
manipulate heaps, and it primarily focuses on bug detection. This approach is
different from the over-approximation methods that are used in traditional
logics such as Hoare Logic or Separation Logic. Although the soundness of ISL
has been established, its completeness remains unproven. In this study, we
establish relative completeness by leveraging the expressiveness of the weakest
postconditions; expressiveness is a factor that is critical to demonstrating
relative completeness in Reverse Hoare Logic. In our ISL framework, we allow
for infinite disjunctions in disjunctive normal forms, where each clause
comprises finite symbolic heaps with existential quantifiers. To compute the
weakest postconditions in ISL, we introduce a canonicalization that includes
variable aliasing.

</details>


### [429] [Causality and Decision-making: A Logical Framework for Systems and Security Modelling](https://arxiv.org/abs/2508.01758)
*Pinaki Chakraborty,Tristan Caulfield,David Pym*

Main category: cs.LO

TL;DR: 研究提出了一种结合形式化系统行为和反事实因果推理的理论，用于理解和决策复杂交互系统中的因果关系，并以微服务为例进行了说明。


<details>
  <summary>Details</summary>
Motivation: 旨在为理解复杂系统生态系统（如支撑现代社会的系统）的决策行为提供因果推理基础，特别是安全（正确性、安全性、韧性等）方面。

Method: 采用迁移系统和模态逻辑，并引入干预算子和分离合取来捕捉系统间的实际因果关系，同时通过等价定理进行验证。

Result: 提出了一个基于最小结构假设的战略推理理论，并用分布式系统中的微服务决策实例说明了其适用性。

Conclusion: 该研究将形式化的、极简化的系统行为概念与基于Halpern-Pearl的反事实推理理论相结合，为研究复杂交互系统中的因果决策提供了逻辑基础。

Abstract: Causal reasoning is essential for understanding decision-making about the
behaviour of complex `ecosystems' of systems that underpin modern society, with
security -- including issues around correctness, safety, resilience, etc. --
typically providing critical examples. We present a theory of strategic
reasoning about system modelling based on minimal structural assumptions and
employing the methods of transition systems, supported by a modal logic of
system states in the tradition of van Benthem, Hennessy, and Milner, and
validated through equivalence theorems. Our framework introduces an
intervention operator and a separating conjunction to capture actual causal
relationships between component systems of the ecosystem, aligning naturally
with Halpern and Pearl's counterfactual approach based on Structural Causal
Models. We illustrate the applicability through examples of of decision-making
about microservices in distributed systems. We discuss localized
decision-making through a separating conjunction. This work unifies a formal,
minimalistic notion of system behaviour with a Halpern--Pearl-compatible theory
of counterfactual reasoning, providing a logical foundation for studying
decision making about causality in complex interacting systems.

</details>


### [430] [Separation Logic of Generic Resources via Sheafeology](https://arxiv.org/abs/2508.01866)
*Berend van Starkenburg,Henning Basold,Chase Ford*

Main category: cs.LO

TL;DR: Sheafeology, a framework based on resource-aware categorical logic using sheaves, generalizes separation logic for various resources by enabling localized reasoning.


<details>
  <summary>Details</summary>
Motivation: Existing approaches to separation logic, while effective for pointer programs and other resource structures, do not provide a general theory for combining first-order logic with separating connectives to yield program logics for different resources.

Method: We propose a framework based on making first-order logic resource-aware using categorical logic and sheaves. We developed categorical logic internally in categories of sheaves (sheafeology), constructing an internal fibration in sheaf categories that models predicates on resources and admits first-order and separating connectives.

Result: Our framework enables the localization and combination of resources through the role of sheaves, thereby achieving the scalability promised by separation logic. We demonstrate the generality of our framework through instantiations to various memory models and random variables.

Conclusion: We attained a general framework of separation logic for generic resources, substantiated by instantiating our framework to various memory models and random variables.

Abstract: Separation logic was conceived in order to make the verification of pointer
programs scalable to large systems and it has proven extremely effective. The
key idea is that programs typically access only small parts of memory, allowing
for local reasoning. This idea is implemented in separation logic by extending
first-order logic with separating connectives, which inspect local regions of
memory. It turns that this approach not only applies to pointer programs, but
also to programs involving other resource structures. Various theories have
been put forward to extract and apply the ideas of separation logic more
broadly. This resulted in algebraic abstractions of memory and many variants of
separation logic for, e.g., concurrent programs and stochastic processes.
However, none of the existing approaches formulate the combination of
first-order logic with separating connectives in a theory that could
immediately yield program logics for different resources. In this paper, we
propose a framework based on the idea that separation logic can obtained by
making first-order logic resource-aware. First-order logic can be understood in
terms of categorical logic, specifically fibrations. Our contribution is to
make these resource-aware by developing categorical logic internally in
categories of sheaves, which is what we call sheafeology. The role of sheaves
is to model views on resources, through which resources can be localised and
combined, which enables the scalability promised by separation logic. We
contribute constructions of an internal fibration in sheaf categories that
models predicates on resources, and that admits first-order and separating
connectives. Thereby, we attain a general framework of separation logic for
generic resources, a claim we substantiate by instantiating our framework to
various memory models and random variables.

</details>


### [431] [Monitoring Hyperproperties over Observed and Constructed Traces](https://arxiv.org/abs/2508.02301)
*Marek Chalupa,Thomas A. Henzinger,Ana Oliveira da Costa*

Main category: cs.LO

TL;DR: 该研究提出了一种新的监控算法，用于在运行时检查系统是否满足超属性。该算法通过引入生成器函数来处理可能未观察到的跟踪，并支持复杂的异步超属性。


<details>
  <summary>Details</summary>
Motivation: 为了在运行时监控系统是否满足由超属性定义的规范，例如线性化或非干扰的变体。

Method: 提出了一种新的监控算法，该算法扩展了超节点逻辑，增加了关于生成器函数的跟踪量词，并支持可能无限的域。该算法已实现并在一系列并发和安全应用的超属性上进行了评估。

Result: 实现了一种监控算法，能够监控包含交替跟踪量词的异步超属性，填补了该领域的空白。

Conclusion: 该研究提出了一种用于监控系统运行时是否满足超属性（如线性化或非干扰）的监控算法。该算法将可能永远不会在运行时观察到的跟踪（例如并发跟踪的线性化）实例化为生成器函数，并支持具有交替跟踪量词的异步超属性的监控。

Abstract: We study the problem of monitoring at runtime whether a system fulfills a
specification defined by a hyperproperty, such as linearizability or variants
of non-interference. For this purpose, we introduce specifications with both
passive and active quantification over traces. While passive trace quantifiers
range over the traces that are observed, active trace quantifiers are
instantiated with \emph{generator functions}, which are part of the
specification. Generator functions enable the monitor to construct traces that
may never be observed at runtime, such as the linearizations of a concurrent
trace. As specification language, we extend hypernode logic with trace
quantifiers over generator functions and interpret these hypernode formulas
over possibly infinite domains. We present a corresponding monitoring
algorithm, which we implemented and evaluated on a range of hyperproperties for
concurrency and security applications. Our method enables, for the first time,
the monitoring of asynchronous hyperproperties that contain alternating trace
quantifiers.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [432] [Topolectrical circuit theory and realizations of topological, non-linear, and non-Hermitian phenomena](https://arxiv.org/abs/2508.00964)
*Haydar Sahin*

Main category: cond-mat.mes-hall

TL;DR: Electrical circuits are versatile platforms for studying physics. This thesis analyzes voltage and impedance responses in various circuit models, revealing complex behaviors and challenging textbook knowledge. It also explores applications in non-linear and non-Hermitian physics.


<details>
  <summary>Details</summary>
Motivation: The motivation is to distinguish observed/measured quantities from intrinsic circuit responses by investigating the fundamental properties of electrical circuit metamaterials, which serve as a platform for exploring physical phenomena like topology and non-Hermitian effects.

Method: The analysis involves studying voltage and impedance responses in electrical circuits, ranging from simple one-dimensional circuits to multi-dimensional and multi-structural lattice models. The research also delves into non-linear and non-Hermitian circuit applications.

Result: The research found that one-dimensional circuits exhibit intriguing voltage profiles and multi-dimensional lattice models display size-dependent impedance responses, challenging existing knowledge. Additionally, it showcases the potential of electrical circuits for realizing non-linear and non-Hermitian physical phenomena.

Conclusion: The study reveals that electrical circuits are a suitable platform for realizing intriguing physical phenomena, including non-linear and non-Hermitian effects. It also highlights that even simple one-dimensional circuits exhibit complex voltage profiles, and multi-dimensional lattice models show size-dependent impedance responses.

Abstract: Electrical circuits offer a unique platform to explore physical phenomena,
from topology to non-Hermitian effects. Investigations of the fundamental
properties of this metamaterial platform are crucial to distinguish
observed/measured quantities from intrinsic circuit responses. In this thesis,
we delve into the analysis of voltage and impedance responses and their role in
unveiling complex dynamics and profound physical principles. We reveal that
even the simplest one-dimensional circuits exhibit intriguing voltage profiles.
Our study of multi-dimensional and multi-structural lattice models shows
size-dependent impedance responses, which challenge our current textbook
knowledge. Building on these insights, we will present non-linear and
non-Hermitian circuit applications, showcasing how electrical circuits provide
a suitable platform for realizing intriguing physical phenomena.

</details>


### [433] [Dynamic Interfacial Quantum Dipoles in Charge Transfer Heterostructures](https://arxiv.org/abs/2508.01027)
*Ziyu Liu,Emil Viñas Boström,Dihao Sun,Jordan Pack,Matthew Cothrine,Kenji Watanabe,Takashi Taniguchi,David G. Mandrus,Angel Rubio,Cory R. Dean*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯/hBN/α-RuCl3器件中的迟滞栅极响应由量子交换相互作用引起的界面偶极子动态调控，表现出铁电特性和优异的可调性。


<details>
  <summary>Details</summary>
Motivation: 二维材料异质结的迟滞栅极响应可作为电子态的敏感探针，并有望用于开发新型纳米电子器件。

Method: 通过分析石墨烯/hBN/α-RuCl3电荷转移场效应器件的迟滞栅极响应，发现了一种由量子交换相互作用引起的界面偶极子动态调控机制。

Result: 量子交换相互作用引起的界面偶极子动态调控导致了迟滞栅极响应，该系统表现出铁电特性，并且在外部电场作用下表现出显著的可调性。

Conclusion: 本研究揭示了一种通过动态界面量子偶极子调控迟滞行为的新机制。

Abstract: Hysteretic gate responses of two-dimensional material heterostructures serve
as sensitive probes of the underlying electronic states and hold significant
promise for the development of novel nanoelectronic devices. Here we identify a
new mechanism of hysteretic behavior in
graphene/$h$BN/$\alpha$-$\mathrm{RuCl_3}$ charge transfer field effect devices.
The hysteresis loop exhibits a sharp onset under low temperatures and evolves
symmetrically relative to the charge transfer equilibrium. Unlike conventional
flash memory devices, the charge transfer heterostructure features a
transparent tunneling barrier and its hysteretic gate response is induced by
the dynamic tuning of interfacial dipoles originating from quantum exchange
interactions. The system acts effectively as a ferroelectric and gives rise to
remarkable tunability of the hysteretic gate response under external electrical
bias. Our work unveils a novel mechanism for engineering hysteretic behaviors
via dynamic interfacial quantum dipoles.

</details>


### [434] [Opto- and magneto-tunable exceptional degeneracies in non-Hermitian ferromagnet/$p$-wave magnet junctions](https://arxiv.org/abs/2508.01295)
*Mohammad Alipourzadeh,Davood Afshar,Yaser Hajati*

Main category: cond-mat.mes-hall

TL;DR: UPMs与磁场和光共同作用，产生可调的异常点，为自旋电子学提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 探索具有奇偶校验自旋纹理的非常规p波磁体（UPMs），并研究它们在非厄米开放量子系统中的性质，特别关注异常点（EPs）的出现和可调性。

Method: 通过理论分析，构建了一个由铁磁体和UPM组成的非厄米开放量子系统，并考虑了外部磁场和圆偏振光（CPL）的影响，研究了EPs的出现、特性以及由这两种扰动引起的动力学变化。

Result: 在UPM-铁磁体结中发现了EPs，并表明其位置、重数和形成条件与d波 نموذ不同。研究了磁场和CPL如何影响EPs（移动、倾斜、合并或湮灭），并阐明了它们各自的作用机制（CPL的全局Floquet重整化和磁场的选择性修改）。

Conclusion: 本文揭示了非常规p波磁体（UPMs）在非厄米开放量子系统中的新颖性质，展示了异常点（EPs）的出现及其可调性。与d波 نموذ不同的EPs特性，归因于UPMs的对称性。研究了磁场和圆偏振光对EPs动力学的影响及其不同机制，强调了UPMs在未来自旋电子学中作为非厄米现象平台的前景。

Abstract: Unconventional $p$-wave magnets (UPMs) with odd-parity spin textures have
attracted interest for their zero net magnetization and anisotropic spin-split
Fermi surfaces. Here, we explore a non-Hermitian open quantum system composed
of a ferromagnet and a UPM, subjected to an external magnetic field and
off-resonant circularly polarized light (CPL), serving as tunable control
parameters. We demonstrate the emergence of exceptional points (EPs) in the
proposed junction, whose locations can be modulated by the intrinsic properties
of the UPM. These EPs exhibit different multiplicities and formation conditions
compared to those in even-parity magnets (dubbed $d$- wave altermagnets), a
distinction attributable to the preserved time-reversal and broken inversion
symmetries characteristic of UPMs. We find that both the unidirectional
magnetic field (with adjustable strength and orientation) and the CPL induce
momentum-direction-dependent modifications to the EPs, such as their shifting,
tilting, merging, or annihilation, supported by analyses of spin projection and
eigenvector overlap. Although both perturbations influence the EP structure,
they operate via distinct mechanisms: CPL induces a global Floquet
re-normalization, enabling dynamic tunability through light, whereas the
unidirectional magnetic field selectively alters orientation-aligned terms,
lacking such tunability. Beyond revealing EP dynamics in UPM-based junctions,
our results highlight UPMs as promising platforms for non-Hermitian phenomena
in future spintronics.

</details>


### [435] [Metallophilicity Enhances Electron Transport through Parallel Organometallic 1D Chain Junctions Formed In Situ](https://arxiv.org/abs/2508.01421)
*Sigifredo Luna,Hannah E Skipper,Brent Lawson,Eric S Cueny,Maria Kamenetska*

Main category: cond-mat.mes-hall

TL;DR: Aurophilic interactions in gold cyanide wires affect conductance: serial wires have decreased conductance due to interference, while parallel wires have increased conductance due to coupling.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this research is to understand the role of aurophilic interactions in the formation and electrical conductance of gold cyanide molecular wires. Specifically, the study aims to elucidate how the assembly of these wires, whether in series or parallel, affects their electronic transport characteristics.

Method: The study utilizes Scanning Tunneling Microscopy (STM) break junction techniques under ambient conditions to assemble and analyze gold cyanide (AuCN) molecular wires of varying length-to-width ratios. Electron transport signatures are identified through both one-dimensional single chains ((AuCN)n) and adjacent molecular wires linked in parallel.

Result: The results show that in serial arrangements ((AuCN)n for n=1-3), destructive quantum interference leads to an exponential decay of conductance. Conversely, in parallel arrangements, aurophilic coupling between neighboring chains reorders electronic states, resulting in a significant enhancement of conductance.

Conclusion: The research reveals that metallophilicity, specifically aurophilic interactions, significantly influences the assembly and electron transport properties of gold cyanide molecular wires. The study demonstrates how these interactions can lead to either destructive quantum interference and exponential decay of conductance in serial arrangements or enhanced conductance through reordered electronic states in parallel arrangements.

Abstract: We reveal the role of aurophilic interactions in the formation and
conductance of gold cyanide molecular wires of variable length-to-width ratios
assembled at the tip of an STM break junction in ambient conditions.
Specifically, we identify electron transport signatures through 1D single
chains containing variable number of monomeric repeats of gold cyanide AuCN,
linked in series (AuCN)n, and through adjacent molecular wires linked in
parallel. When bound in series, destructive quantum interference causes an
exponential decay of conductance in (AuCN)n 1D wires for n=1-3. But when bound
in parallel, aurophilic coupling through the gold atoms of neighboring chains
reorders electronic states and results in significant enhancement of
conductance. Our work reveals that metallophilicity can play a significant role
in junction assembly and electron transport characteristics.

</details>


### [436] [Unconventional Altermagnetism in Quasicrystals: A Hyperspatial Projective Construction](https://arxiv.org/abs/2508.01564)
*Yiming Li,Mingxiang Pan,Jun Leng,Yuxiao Chen,Huaqing Huang*

Main category: cond-mat.mes-hall

TL;DR: 阿尔特磁性（一种新的磁相）首次在准晶格中实现，具有新颖的g波和h波特性，并与准晶格对称性兼容，为准晶格系统中的新型磁性和输运现象提供了平台。


<details>
  <summary>Details</summary>
Motivation: 将阿尔特磁性概念扩展到准晶格（具有长程有序和非晶格旋转对称性的非周期系统）。

Method: 使用超空间投影框架构建了装饰过的Ammann-Beenker和Penrose准晶格，并研究了具有各向异性跳跃的Hubbard模型。

Result: 研究表明，准晶格中的相互作用诱导的Néel序能够产生交替的自旋极化谱函数，这些函数反映了准晶格的对称性，并由此产生了非传统的g波（八重）和h波（十重）阿尔特磁性。

Conclusion: 在准晶格中发现了非传统的g波（八重）和h波（十重）阿尔特磁性，该磁性与准晶格的旋转对称性兼容，并展示了超出晶格限制的阿尔特磁性相。

Abstract: Altermagnetism, a novel magnetic phase characterized by symmetry-protected,
momentum-dependent spin splitting and collinear compensated magnetic moments,
has thus far been explored primarily in periodic crystals. In this Letter, we
extend the concept of altermagnetism to quasicrystals -- aperiodic systems with
long-range order and noncrystallographic rotational symmetries. Using a
hyperspatial projection framework, we construct decorated Ammann-Beenker and
Penrose quasicrystalline lattices with inequivalent sublattices and investigate
a Hubbard model with anisotropic hopping. We demonstrate that
interaction-induced N\'eel order on such lattices gives rise to alternating
spin-polarized spectral functions that reflect the underlying quasicrystalline
symmetry, revealing the emergence of unconventional $g$-wave (octagonal) and
$h$-wave (decagonal) altermagnetism. Our symmetry analysis and low-energy
effective theory further reveal unconventional altermagnetic spin splitting,
which is compatible with quasicrystalline rotational symmetry. Our work shows
that quasicrystals provide a fertile ground for realizing unconventional
altermagnetic phases beyond crystallographic constraints, offering a platform
for novel magnetisms and transport phenomena unique to quasiperiodic systems.

</details>


### [437] [Twistronics and moiré superlattice physics in 2D transition metal dichalcogenides](https://arxiv.org/abs/2508.01584)
*Dawei Zhai,Hongyi Yu,Wang Yao*

Main category: cond-mat.mes-hall

TL;DR: Moiré superlattices in 2D TMDs are a hot topic in condensed matter physics due to their tunability, leading to exciting discoveries in optics, topology, and correlation phenomena.


<details>
  <summary>Details</summary>
Motivation: To explore frontier topics in condensed matter physics, including optical, topological and correlation phenomena, using the tunable platform of moiré superlattices formed by 2D TMDs.

Method: This review provides an overview of the fundamental properties of TMDs moiré superlattices and highlights major breakthroughs in the field.

Result: Recent advancements in the field of TMDs moiré superlattices, including experimental and theoretical progress.

Conclusion: The moiré superlattices of 2D TMDs offer a tunable platform for condensed matter physics, with rapid advancements in experimental and theoretical progress.

Abstract: The moir\'e superlattices formed by stacking 2D semiconducting transition
metal dichalcogenides (TMDs) with twisting angle or lattice mismatch have
provided a versatile platform with unprecedented tunability for exploring many
frontier topics in condensed matter physics, including optical, topological and
correlation phenomena. This field of study advances rapidly and a plethora of
exciting experimental and theoretical progresses have been achieved recently.
This review aims to provide an overview of the fundamental properties of TMDs
moir\'e superlattices, as well as highlight some of the major breakthroughs in
this captivating field.

</details>


### [438] [Using surface plasmons to detect spin inertia](https://arxiv.org/abs/2508.01627)
*H. Y. Yuan*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种基于二维材料-磁体异质结构光谱反射率分析的方法，用于定量测量磁性材料中的自旋惯性。该方法能够揭示自旋惯性在太赫兹区域产生的自旋振荡波与二维材料表面等离激元杂化的现象，具有普遍适用性，为后续研究自旋惯性机制奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 研究自旋惯性的物理机制和普遍性，以及它如何影响自旋动力学。

Method: 通过激发杂化自旋波-等离激元模式并分析二维材料-磁体异质结构的光谱反射率，提出了一种定量测定磁性层中自旋惯性强度的方法。

Result: 自旋惯性在太赫兹区域产生自旋振荡波，并能与石墨烯等二维导电材料中的表面等离激元杂化。

Conclusion: 该方法可用于定量确定磁性层中自旋惯性的强度，并且普遍适用于所有类型的磁性绝缘体，有望推动对自旋惯性的大小和物理机制的未来探索。

Abstract: Recent experiments demonstrate that spin dynamics may acquire an inertial
effect in a few metallic magnets, deviating from the traditional inertia-free
dynamics. It remains an open question to ascertain the physical mechanisms and
universality of the spin inertia across diverse magnetic systems. Here, we show
that spin inertia generates nutation spin waves in the terahertz regime, which
can hybridize with the surface plasmons in two-dimensional (2D) conducting
materials such as graphene. By exciting hybrid spin wave-plasmon modes and
analyzing the reflection spectrum of a 2D material$|$magnet heterostructure, we
propose a method to quantitatively determine the strength of spin inertia in
magnetic layers. Our approach is universally applicable to all types of
magnetic insulators and could advance the future exploration of the magnitude
and physical mechanism of spin inertia.

</details>


### [439] [The birefringent spin-laser as a system of coupled harmonic oscillators](https://arxiv.org/abs/2508.01945)
*Velimir Labinac,Jiayu David Cao,Gaofeng Xu,Igor Žutić*

Main category: cond-mat.mes-hall

TL;DR: 通过将双折射自旋激光器的动力学特性建模为耦合谐振子，实现了对超快操作的准确描述和新操作模式的预测。


<details>
  <summary>Details</summary>
Motivation: 自旋激光器通过注入自旋极化载流子，可以实现比传统激光器快十倍的超快操作，这种超快操作依赖于通常被认为是负面的大线性双折射，它会耦合两种线偏振发射模式。

Method: 将双折射自旋激光器在强度和偏振调制下的动力学特性准确地描述为耦合谐振子。该模型使用实数而非复数场分量，可以进行解析求解。

Result: 提出的模型可以准确描述双折射自旋激光器的动力学特性，并且能够预测新的操作模式，区分弱耦合和强耦合。

Conclusion: 该模型与强度方程描述一致，该描述使用更简单的实数并且允许解析解，并且该模型可以准确描述双折射自旋激光器在强度和偏振调制下的动力学特性。此外，该模型还预测了未被探索的操作模式，并阐明了自旋激光器中弱耦合和强耦合之间的区别。

Abstract: Adding spin-polarized carriers to semiconductor lasers strongly changes their
properties and, through the transfer of angular momentum, leads to the emission
of the circularly polarized light. In such spin-lasers the polarization of the
emitted light can be modulated an order of magnitude faster than its intensity
in the best conventional lasers. This ultrafast operation in spin-lasers relies
on the large linear birefringence, usually viewed as detrimental in spin and
conventional lasers, which couples the two linearly-polarized emission modes.
We show that the dynamical properties of birefringent spin-lasers under
intensity and polarization modulation are accurately described as coupled
harmonic oscillators. Our model agrees with the intensity-equation description
which, unlike the common complex field components describing the role of
birefringence in laser dynamics, uses simpler real quantities and allows
analytical solutions. We further predict unexplored operation regimes and
elucidate the difference between the weak and strong coupling in spin-lasers.

</details>


### [440] [Orbital Inverse Faraday and Cotton-Mouton Effects in Hall Fluids](https://arxiv.org/abs/2508.01946)
*Gabriel Cardoso,Erlend Syljuåsen,Alexander V. Balatsky*

Main category: cond-mat.mes-hall

TL;DR: 量子霍尔流体中的光诱导磁化效应及其光学打印应用


<details>
  <summary>Details</summary>
Motivation: 为了探索光与量子霍尔（QH）流体相互作用的新机制，以及开发基于光控磁化和密度廓线打印的新技术。

Method: 该研究利用圆偏振光和线偏振光分别诱导量子霍尔流体中的逆法拉第效应（IFE）和轨道逆科顿-蒙顿效应（ICME），并测量产生的直流磁化强度。同时，研究还分析了光诱导磁化对粒子密度的影响，提出了光学量子打印密度廓线的可能性。

Result: 研究发现了两种新的光诱导磁化效应：圆偏振光引起的IFE横向贡献和线偏振光引起的ICME。估计的磁化强度在0.5-10 Bohr/载流子范围内，并展示了光学量子打印密度廓线的潜力。

Conclusion: 该研究首次报道了量子霍尔流体中的两种光诱导轨道磁化效应：圆偏振光引起的逆法拉第效应（IFE）的纯横向贡献，以及线偏振光引起的轨道逆科顿-蒙顿效应（ICME）。这两种效应的磁化强度估计在0.5-10 Bohr/载流子范围内，并可在石墨烯和过渡金属二卤化物等材料中实现。此外，研究还表明，诱导磁化伴随着静态粒子密度的局部修正，实现了对量子霍尔流体进行光学量子打印密度廓线。

Abstract: We report two light-induced orbital magnetization effects in quantum Hall
(QH) fluids, stemming from their transverse response. The first is a purely
transverse contribution to the inverse Faraday effect (IFE), where circularly
polarized light induces a DC magnetization by stirring the charged fluid. This
contribution dominates the IFE in the QH regime. The second is the orbital
inverse Cotton-Mouton effect (ICME), in which linearly polarized light
generates a DC magnetization. Since the applied field in the ICME does not
break time-reversal symmetry, the induced magnetization directly probes the
chiral orbital response of the fluid at the driving frequency. We estimate that
the resulting magnetization lies in the range of 0.5-10 Bohr magnetons per
charge carrier in materials such as graphene and transition-metal
dichalcogenides (TMDs) in the QH regime. Finally, we show that the induced
magnetization is accompanied by a local correction to the static particle
density, enabling optical quantum printing of density profiles into the QH
fluid.

</details>


### [441] [Topological phases and spontaneous symmetry breaking: the revenge of the original Su-Schrieffer-Heeger model](https://arxiv.org/abs/2508.01985)
*Polina Matveeva,Dmitri Gutman,Sam T. Carr*

Main category: cond-mat.mes-hall

TL;DR: 研究了自发对称破缺和拓扑性质在一维模型中的相互作用，发现原始SSH模型是拓扑平凡的，而其有自旋的版本表现出拓扑非平凡相。


<details>
  <summary>Details</summary>
Motivation: 研究自发对称破缺和拓扑性质在相互作用的一维模型中的相互作用。

Method: 该模型通过玻色化方法求解，并通过计算有限尺寸系统相对于无限系统存在的额外简并度（与边缘模式相关）来识别拓扑非平凡相。

Result: 平均场解为拓扑非平凡，但自发对称破缺可能导致拓扑平凡。原始SSH模型是拓扑平凡的，但其有自旋的版本表现出拓扑非平凡相，并且该相受到手征对称性的保护。

Conclusion: 当自发对称破缺与拓扑性质结合时，即使在平均场解中拓扑性质成立，当它源于自发对称破缺时，这可能并不成立，包括在SSH模型中。原始SSH模型被证明是拓扑平凡的，而其全互动版本则表现出拓扑非平凡相，该相受手征对称性保护。

Abstract: We study the interplay of spontaneous symmetry breaking and topological
properties in interacting one-dimensional models. We solve these models using
bozonization and identify topologically non-trivial phases by counting the
additional degeneracy (affiliated with the edge modes) of a finite-size system
relative to the infinite one. We find even if the mean-field solution is
topological, this may not be true when it arises from spontaneous symmetry
breaking, including in the Su-Schrieffer-Heeger (SSH) model. This implies that
the original SSH model, as presented by Su, Schrieffer, and Heeger, is
topologically trivial, as opposed to its mean-field version. A spinful version,
on the other hand, does exhibit a topologically non-trivial phase. In that
state, both mean-field solutions are topologically non-trivial and correspond
to non-interacting SSH chains in the opposite phases with the winding number
$\nu=1$. We show that this phase is protected by a chiral symmetry, similar to
the non-interacting phases.

</details>


### [442] [Significant Mobility Enhancement in Coupled AlGaN/GaN Quantum Wells considering Inter-Well Distance and Asymmetric Widths](https://arxiv.org/abs/2508.02024)
*Le Tri Dat,Tran Trong Tai,Truong Van Tuan,Vo Van Tai,Nguyen Duy Vy*

Main category: cond-mat.mes-hall

TL;DR: 通过调整AlGaN/GaN量子阱的宽度和间距，可以显著提高材料的迁移率，这对于量子器件的工程设计具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 为了提高AlGaN/GaN异质结构中的迁移率，以优化量子器件的性能。

Method: 通过理论分析，研究了不同宽度耦合AlGaN/GaN量子阱的迁移率表现，并与单量子阱进行了对比。

Result: 耦合AlGaN/GaN量子阱（宽度不对称，L1-L2<30 Å）在最佳分离（d=100 Å）下实现了比单量子阱高4.5倍的迁移率。当d>40 Å时，耦合体系的迁移率超过单量子阱；而对于相同宽度量子阱，当d<40 Å时，耦合体系表现不如单量子阱，但超过该阈值后则超越。迁移率增益在低温（77 K）下达到峰值。

Conclusion: 研究结果提供了一个稳健的理论框架，用于优化AlGaN/GaN异质结构中的迁移率，并减少量子器件工程中的实验试错。

Abstract: We demonstrate that coupled AlGaN/GaN quantum wells with asymmetric widths
($L_1-L_2<30 $ A achieve up to 4.5 times higher mobility than single wells at
optimal separation (d = 100 A). Crucially, mobility surpasses single wells when
d>40 A reversing the trend at smaller distances. This enhancement stems from
double-layer screening that suppresses remote/background impurities and
dislocations, while LO phonon scattering remains unaffected. For identical
wells, coupled systems underperform single wells at d<40 A but exceed them
beyond this threshold. Peak gains occur at cryogenic temperatures (77 K). Our
results provide a robust theoretical framework to optimize mobility in
AlGaN/GaN heterostructures, reducing experimental trial-and-error in quantum
device engineering.

</details>


### [443] [A Clarification on Quantum-Metric-Induced Nonlinear Transport](https://arxiv.org/abs/2508.02088)
*Xiao-Bin Qiang,Tianyu Liu,Zi-Xuan Gao,Hai-Zhou Lu,X. C. Xie*

Main category: cond-mat.mes-hall

TL;DR: 本篇论文解决了量子度规诱导的非线性电导在文献中的表述不一致问题，并提出一个新模型来专门研究量子度规效应。


<details>
  <summary>Details</summary>
Motivation: 量子几何张量的实部——量子度规，在表征凝聚态系统的内在性质方面起着至关重要的作用，尤其是在其诱导的二阶非线性电导方面。然而，文献中关于此现象的表达式存在不一致之处，因此需要进行调和与阐明。

Method: 本研究采用标准微扰理论、波包动力学和Luttinger-Kohn方法，并结合一个抑制贝里曲率效应的狄拉克模型启发玩具模型，来系统地检验非线性电导。

Result: 本研究成功调和了文献中关于量子度规诱导的二阶非线性电导表达式的不一致性，并提出了一个用于研究量子度规诱导的非线性电导的玩具模型。该模型通过抑制贝里曲率的贡献，使得研究的焦点能够集中在量子度规的影响上。

Conclusion: 本研究通过系统地检验非线性电导，利用标准微扰理论、波包动力学和Luttinger-Kohn方法，解决了量子度规诱导的二阶非线性电导表达式在文献中不一致的问题。此外，我们提出了一个受狄拉克模型启发的玩具模型，该模型抑制了贝里曲率引起的非线性输运，从而能够专门研究量子度规引起的非线性电导。

Abstract: Over the years, Berry curvature, which is associated with the imaginary part
of the quantum geometric tensor, has profoundly impacted many branches of
physics. Recently, quantum metric, the real part of the quantum geometric
tensor, has been recognized as indispensable in comprehensively characterizing
the intrinsic properties of condensed matter systems. The intrinsic
second-order nonlinear conductivity induced by the quantum metric has attracted
significant recent interest. However, its expression varies across the
literature. Here, we reconcile this discrepancy by systematically examining the
nonlinear conductivity using the standard perturbation theory, the wave packet
dynamics, and the Luttinger-Kohn approach. Moreover, inspired by the Dirac
model, we propose a toy model that suppresses the Berry-curvature-induced
nonlinear transport, making it suitable for studying the quantum-metric-induced
nonlinear conductivity. Our theory can be further extended to include disorder
effects and higher-order quantum geometric contributions, paving the way for a
more comprehensive and systematic understanding of nonlinear transport.

</details>


### [444] [Symmetry-adapted models for multifold fermions with spin-orbit coupling](https://arxiv.org/abs/2508.02090)
*Koki Satow,Ai Yamakage*

Main category: cond-mat.mes-hall

TL;DR: 研究了受空间群对称性保护的多重费米子在外场下的行为，构建了有效模型，发现了磁单极子的成对湮灭。


<details>
  <summary>Details</summary>
Motivation: 理解多重费米子（特别是受空间群对称性保护的多重费米子）在外场刺激下的响应仍然具有挑战性，因为它们的自由度之间存在复杂的耦合。

Method: 通过构建包含外场的多重费米子有效模型（包括k·p模型和紧束缚模型）来研究其对外场（特别是磁场）的响应，揭示了磁单极子的成对湮灭现象。

Result: 成功构建了受空间群I213（No. 199）保护的三重费米子和受空间群P43n1'（No. 218）保护的八重费米子的k·p模型，并推导了其与外场耦合的项，揭示了磁单极子的成对湮灭。

Conclusion: 这项工作为研究多重费米子的外场响应和输运现象提供了坚实的理论基础，为探索其丰富的物理学开辟了新途径。

Abstract: Multifold fermions, quasiparticles with multiple degeneracy protected by
crystalline symmetries, exhibit a variety of intriguing phenomena stemming from
their large topological charges and unique band structures. A comprehensive
understanding of their response to external stimuli remains challenging,
especially for types protected by nonsymmorphic symmetries where various
degrees of freedom are intricately coupled. Here, we systematically construct
effective models for multifold fermions that incorporate external fields based
on crystalline symmetry. Specifically, we develop a $\boldsymbol{k} \cdot
\boldsymbol{p}$ model for the threefold fermion protected by space group
I2$_1$3 (No.~199) in the presence of spin--orbit coupling, and derive the terms
for external fields. By complementing this with a tight-binding model, we
investigate the magnetic field response and reveal the pair annihilation of
magnetic monopoles. Furthermore, we construct a $\boldsymbol{k} \cdot
\boldsymbol{p}$ model for the eightfold fermion in space group P$\bar{4}3n1'$
(No.~218), including its coupling to external fields. This work provides a
robust theoretical foundation for advancing the study of external field
responses and transport phenomena in multifold fermions, opening new avenues to
explore their rich physics.

</details>


### [445] [Inertial Imaging of Dual Mass Distributions on a Graphene Nanodrum: A Computational Study](https://arxiv.org/abs/2508.02099)
*Adhinarayan Naembin Ashok,Sanjam Bedi,Taha Ashraf Ali Shaikh,Jai Aadhithya Ramesh,Adarsh Ganesan*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种基于石墨烯纳 the nanodrum 的质量检测方法，通过分析其振动模式频率变化来估计分析物的质量密度。结果显示，在非节点区域放置分析物可降低估计误差，且较薄的环形结构能提高检测精度，为高精度多目标质量传感提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用圆柱形石墨烯纳 the nanodrum 谐振器的空间图案化环形质量分布的惯性成像可能性，通过将两种不同的分析物置于同心环形区域中，利用其振动模式特异性灵敏度来估计它们各自的质量密度。

Method: 提出了一种基于瑞利-里兹原理的分析方法，用于将径向质量加载与模态频率变化联系起来，并通过COMSOL Multiphysics进行有限元模拟，以获得在不同环形几何配置下共振频率的变化，再通过变换矩阵处理这些频率变化来估计伴随的环形质量分布。

Result: 研究结果表明，分析物放置在主振动模式的非节点区域附近时，估计误差较低，分析物A的最低误差为1.82%，分析物B的最低误差为2.03%。此外，较薄的环形结构由于模态重叠减小而提高了检测精度。

Conclusion: 该研究展示了一种利用石墨烯纳 the nanodrum进行质量检测的分析策略，为高精度多目标质量传感应用提供了关于最佳分析物放置和结构设计的见解。

Abstract: This paper presents the possibility for inertial imaging of spatially
patterned annular mass distributions of a circular graphene nanodrum resonator.
By placing two distinct analytes in concentric annular regions, we harness the
vibrational mode-specific sensitivities of the nanodrum to estimate their
respective mass densities. An analytical formulation based on the Rayleigh-Ritz
principle is developed to relate radial mass loading to modal frequency shifts.
Finite element simulations are performed in COMSOL Multiphysics to obtain the
shifts in the resonance frequency of vibrational modes under varying
geometrical configurations of annular rings. By processing these frequency
shifts through a transformation matrix, we estimate the concomitant mass
distributions of annular rings. The results indicate that the estimation errors
are lower for analytes placed near the antinodal regions of the dominant
vibration mode, with the lowest error being 1.82 % for analyte A and 2.03 % for
analyte B. Furthermore, thinner annular rings demonstrate enhanced detection
accuracy due to reduced modal overlap. This study demonstrates an analytical
strategy for mass detection using a graphene nanodrum by providing insights
into optimal analyte placement and structural design for high-precision
multi-target mass sensing applications.

</details>


### [446] [Efforts in Modeling the Mechanics and Chemistry of Energetic Materials Across Scales](https://arxiv.org/abs/2508.02141)
*Paul Lafourcade,Nicolas Bruzy,Paul Bouteiller,Jean-Bernard Maillet,Christophe Denoual*

Main category: cond-mat.mes-hall

TL;DR: 本文介绍了用于含能分子晶体的多尺度力学和化学本构定律的最新进展，整合了分子动力学、有限元模拟和无监督学习算法，成功模拟了爆炸物的冲击到爆炸转变和热点效应，并指出了未来实验研究的方向。


<details>
  <summary>Details</summary>
Motivation: 为了开发含能分子晶体的多尺度力学和化学本构定律，需要整合原子模拟和连续介质模拟，并结合化学动力学分析。

Method: 本文整合了分子动力学和有限元模拟，并结合了无监督学习算法来分析化学分解动力学。具体来说，通过对变形路径和力学指标的跟踪来计算材料的屈服应力面，从而构建非线性超弹性连续介质模型，并校准多组分状态方程。这些方法被应用于TATB、RDX和β-HMX等材料，以模拟冲击到爆炸的转变和准静态热点的维度效应。

Result: 研究成功地构建了包含TATB晶体塑性和孪生的非线性超弹性连续介质模型，并识别和校准了RDX和TATB单晶的化学分解动力学。将这些模型应用于β-HMX，并校准了多组分状态方程，以模拟冲击到爆炸的转变和准静态热点的维度效应。研究还指出了未来实验研究的方向。

Conclusion: 该论文介绍了用于含能分子晶体的多尺度力学和化学本构定律的最新进展，并进行了讨论。特别地，将各种工具整合到分子动力学代码中，以便将信息传递到有限元模拟代码。通过对特定变形路径和局部拉格朗日力学指标的跟踪，增强了原子模拟的能力，从而计算材料的屈服应力面。这种机制库允许构建包含TATB晶体塑性和孪生的综合非线性超弹性连续介质模型。此外，通过无监督学习算法分析反应分子动力学模拟的最新进展，能够识别和校准RDX和TATB单晶的化学分解动力学。在本工作中，该方法被应用于β-HMX，并扩展到多组分状态方程的校准。将这两个组成部分实现到有限元代码中，以便在介观尺度上模拟从冲击到爆炸的转变，并研究准静态热点的维度效应。最后，为实现爆炸物全面的多尺度建模所做的这些专门努力，也催生了对新预期实验的需求，这些实验将在论文中进行讨论。

Abstract: Recent developments dedicated to the building of multiscale mechanical and
chemical constitutive laws for energetic molecular crystals are presented and
discussed. In particular, various tools have been specifically incorporated in
molecular dynamics codes to facilitate the subsequent information transfer to
the continuum, i.e. finite elements simulation codes. Atomistic simulations
have been augmented with the capability to follow specific deformation paths as
well as local Lagrangian mechanical metrics, enabling the computation of
materials flow stress surface. This mechanistic library allowed the
construction of a comprehensive non-linear hyperelastic continuum model
including crystal plasticity and twinning for TATB. Besides, recent advances in
analyzing reactive molecular dynamics simulations with unsupervised learning
algorithms has enabled the identification and calibration of chemical
decomposition kinetics for RDX and TATB single crystal. In the present work,
the procedure is applied to $\beta$-HMX and extended with the calibration of a
multi-components equation of state. These two ingredients are implemented in a
finite-element code in order to model the shock-to-detonation transition at the
mesoscale level and to study dimensionality effects in quasi-static hotspots.
Finally, these dedicated efforts towards a comprehensive multiscale modeling of
explosives has also given rise to the need for new prospective experiments,
discussed throughout the paper.

</details>


### [447] [Breaking Peierls theorem in polyacetylene chains via topological design](https://arxiv.org/abs/2508.02365)
*Xinnan Peng,Marco Lozano,Jie Su,Lulu Wang,Diego Soler-Polo,Thomas Tuloup,Junting Wang,Shaotang Song,Ming Wah Wong,Jiangbin Gong,Junzhi Liu,Franz J Giessibl,Pavel Jelínek,Jiong Lu*

Main category: cond-mat.mes-hall

TL;DR: 通过将开放壳纳米石墨烯末端连接到聚乙炔链，可以抑制 Peierls 跃迁，恢复准一维（quasi-1D）金属特性，并形成一种新的共振态。这为开发具有优异特性的合成有机量子材料提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了克服一维（1D）金属链的 Peierls 跃迁导致的金属-绝缘体转变，以及实现长期存在的有机量子相，如一维合成有机金属和高温有机超导体。

Method: 本研究通过将经典反式聚乙炔链与开放壳纳米石墨烯末端连接，并对其进行晶格拓扑结构工程化，从而抑制了 Peierls 跃迁。具体来说，通过适当的拓扑连接，实现了末端的零能模式（ZM）与奇数链聚乙炔（OPA）链之间的有效相互作用，形成了拓扑定义的最高占据分子轨道（HOMO），该轨道能够补偿键密度变化，从而抑制键长交替（BLA），恢复材料的准一维（quasi-1D）金属特性。此外，还观察到了一种非常规的无边界共振态，该状态在整个链上离域，具有不衰减的光谱权重。

Result: 通过将开放壳纳米石墨烯末端连接到经典反式聚乙炔链，可以全局抑制 Peierls 跃迁。这种连接方式促进了末端零能模式（ZM）与奇数链聚乙炔（OPA）链之间的相互作用，从而形成了一个关键的、由拓扑决定的最高占据分子轨道（HOMO）。这个 HOMO 补偿了键密度变化，抑制了键长交替（BLA），并恢复了准一维（quasi-1D）金属特性。此外，还产生了一种非常规的、无边界的共振态，该共振态在整个链上离域，具有不衰减的光谱权重，这与聚乙炔中的传统孤子不同。

Conclusion: 本研究通过连接开放壳纳米石墨烯末端来工程化经典反式聚乙炔链的晶格拓扑结构，成功抑制了 Peierls 跃迁。这使得具有零能模式（ZM）的末端与奇数链的聚乙炔（OPA）链之间产生有效的相互作用，从而产生关键的拓扑定义的最高占据分子轨道（HOMO）。该 HOMO 补偿了键密度变化，抑制了键长交替（BLA），并恢复了准一维（quasi-1D）金属特性。此外，它还导致形成了一种非常规的无边界共振态，该共振态在整个链上离域，具有不衰减的光谱权重，这与聚乙炔中的传统孤子不同。这些发现为抑制材料不稳定性以及创造先前被 Peierls 跃迁禁止的具有非常规量子相的合成有机量子材料奠定了基础。

Abstract: Peierls theorem postulates that a one-dimensional (1D) metallic chain must
undergo a metal-to-insulator transition via lattice distortion, resulting in
bond length alternation (BLA) within the chain. The validity of this theorem
has been repeatedly proven in practice, as evidenced by the absence of a
metallic phase in low-dimensional atomic lattices and electronic crystals,
including conjugated polymers, artificial 1D quantum nanowires, and anisotropic
inorganic crystals. Overcoming this transition enables realizing long-sought
organic quantum phases of matter, including 1D synthetic organic metals and
even high-temperature organic superconductors. Herein, we demonstrate that the
Peierls transition can be globally suppressed by employing lattice topology
engineering of classic trans-polyacetylene chains connected to open-shell
nanographene terminals. The appropriate topology connection enables an
effective interplay between the zero-energy modes (ZMs) of terminal and the
finite odd-membered polyacetylene (OPA) chains. This creates a critical
topology-defined highest occupied molecular orbital (HOMO) that compensates for
bond density variations, thereby suppressing BLA and reestablishing their
quasi-1D metallic character. Moreover, it also causes the formation of an
unconventional boundary-free resonance state, being delocalized over the entire
chain with non-decaying spectral weight, distinguishing them from traditional
solitons observed in polyacetylene. Our finding sets the stage for pioneering
the suppression of material instability and the creation of synthetic organic
quantum materials with unconventional quantum phases previously prohibited by
the Peierls transition.

</details>


### [448] [Detecting entanglement with transport measurement in weakly interacting and fluctuating systems](https://arxiv.org/abs/2508.02378)
*Zhenhua Zhu,Gu Zhang,Dong E. Liu*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种在复杂的、相互作用的、多方的量子系统中测量纠缠熵（特别是冯·诺依曼熵和互信息）的实验方法。研究表明，即使存在多体相互作用和多个子系统，测量也是可行的，并且互信息可以作为系统-环境纠缠的可测量指标。


<details>
  <summary>Details</summary>
Motivation: 衡量相互作用的多方量子系统中的纠缠熵是一个重大的实验挑战。本研究旨在克服这一挑战。

Method: 提出了一种测量量子输运系统中冯·诺依曼熵（VNE）和互信息（MI）的协议，即使在存在多体相互作用和多个子系统的情况下也是如此。分析表明，VNE与两点关联函数之间的重要联系在这些现实条件下仍然成立。该测量方法适用于具有边界相互作用的系统，以及在量子猝灭其内部耦合的体相互作用系统。

Result: 研究结果表明，在存在多体相互作用和多个子系统的情况下，冯·诺依曼熵与两点关联函数之间的关键联系仍然存在。该测量方法对于具有边界相互作用的系统和体相互作用系统都是可行的。互信息被证明是系统-环境纠缠的可实现指标。

Conclusion: 本研究提出了一个测量量子输运系统中冯·诺依曼熵和互信息的方法，该方法适用于存在多体相互作用和多个子系统的情况。研究表明，冯·诺依曼熵与两点关联函数之间的关键联系在这些实际条件下仍然存在。该测量方法对于具有边界相互作用的系统以及在量子猝灭其内部耦合的体相互作用系统都是可行的。我们的工作为实验量化复杂相互作用系统中的纠缠提供了途径，并确立了互信息作为系统-环境纠缠的可实现指标。

Abstract: Measuring entanglement entropy in interacting, multipartite systems remains a
significant experimental challenge. We address this challenge by developing a
protocol to measure von Neumann entropy (VNE) and mutual information in quantum
transport systems with both many-body interactions and multiple subsystems. Our
analysis indicates that the vital connection between VNE and two-point
correlation functions persists under these realistic conditions. The
measurement is shown to be feasible for systems with boundary interactions and,
critically, for bulk-interacting systems subject to a quantum quench of their
internal couplings. Our work provides a pathway to experimentally quantify
entanglement in complex interacting systems and establishes mutual information
as an experimentally accessible indicator for system-environment entanglement.

</details>


### [449] [Classical-to-Quantum Crossover in 2D TMD Field-Effect Transistors: A First-Principles Study via Sub-10 nm Channel Scaling Beyond the Boltzmann Tyranny](https://arxiv.org/abs/2508.02380)
*Yu-Chang Chen,Ken-Ming Lin*

Main category: cond-mat.mes-hall

TL;DR: 本研究采用第一性原理计算，模拟了超小尺寸（3-12nm）二维TMD FETs的电子输运。发现在缩小沟道长度时，会发生从热电子发射到量子隧穿的转变，这由两个临界温度控制。最短的3nm结在高温下仍表现出优于经典极限的量子隧穿效应，证明了其在节能和量子计算方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决二维过渡金属硫族化物（TMD）场效应晶体管（FETs）在扩展到亚10纳米尺度时面临的技术复杂性和短沟道效应理解不足的挑战，本研究旨在探究其输运特性。

Method: 本研究采用第一性原理计算，结合了非平衡格林函数（NEGF）形式主义和密度泛函理论（DFT），并集成了一个有效的栅极模型，以研究沟道长度从12纳米缩小到3纳米的二维TMD纳米结的输运性质。

Result: 模拟揭示了电子输运在晶体管缩小过程中出现了从经典到量子输运的跨越，该跨越由两个临界温度控制：Tc（标志着从热电子发射到量子隧穿的转变）和Tt（热电子发射占主导且亚阈值摆幅接近经典极限的温度）。最短的3纳米结在高达500 K的温度下表现出显著的量子隧穿效应，并且由于透射系数的陡峭能量依赖性，其亚阈值摆幅优于玻尔兹曼限制。

Conclusion: 超小尺寸二维过渡金属硫族化物场效应晶体管（TMD FETs）通过利用量子隧穿效应，在超越经典效率限制方面展现出巨大潜力，为开发节能和量子增强计算技术提供了有前景的途径。该研究提出了一种原子尺度的预测方法，用于量化量子输运，并明确了从长沟道半经典热电子流到短沟道二维TMD FETs量子隧穿的电子输运机制转变，为利用量子-经典混合晶体管技术提供了关键的设计见解。

Abstract: Two-dimensional transition metal dichalcogenides present compelling prospects
for next-generation low-power and high-frequency field-effect transistors.
However, scaling 2D TMD FETs into the sub-10 nm regime remains challenging due
to technical complexity. Moreover, short-channel effects in this length scale
are not yet fully understood. In this work, we investigate the transport
properties of 2D TMD nanojunctions with channel lengths from 12 down to 3 nm,
using first-principles calculations that integrate the nonequilibrium Green
function formalism implemented in density functional theory (NEGF-DFT) and an
effective gate model. Our simulations reveal a classical-to-quantum crossover
in electron transport during transistor downscaling, governed by two critical
temperatures: Tc, which marks the crossover from thermionic emission to quantum
tunneling, and Tt, beyond which thermionic emission dominates and the
subthreshold swing approaches its classical limit. The shortest 3 nm junction
exhibits pronounced quantum tunneling up to 500 K and achieves a subthreshold
swing superior to the Boltzmann tyranny, enabled by the steep energy dependence
of the transmission coefficient. This quantum-tunneling-enhanced switching
behavior demonstrates the potential of ultra-scaled 2D FETs to surpass
classical efficiency constraints, offering a promising route toward
energy-efficient, quantum-enabled computing technologies. This study presents a
predictive, atomistic methodology for quantifying quantum transport and
identifies the transition in electron transport mechanisms from semiclassical
thermionic current in long-channel to quantum tunneling in short-channel 2D TMD
FETs, offering critical design insights for leveraging quantum-classical hybrid
transistor technology.

</details>


### [450] [Three-magnon scattering of spin wave on edge-localized mode in thin ferromagnetic film](https://arxiv.org/abs/2508.02486)
*Julia Kharlan,Roman Verba,Krzysztof Sobucki,Paweł Gruszecki,Maciej Krawczyk*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过分析理论和微磁模拟，揭示了薄铁磁膜边缘三磁振子散射的复杂机制，强调了对称性降低、多过程耦合以及相位累积对散射波特性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解降低系统对称性如何影响三磁振子散射，特别是当体自旋波与边缘局域化传播的自旋波在反射时相互作用时。

Method: 研究使用分析理论并结合全微磁模拟来研究薄铁磁膜边缘的三磁振子散射。

Result: 结果显示，受激分裂过程产生的波的幅度是汇聚过程产生的波的幅度的几倍，这主要是由于较低的群速度。此外，非弹性散射波的强度与入射角和边缘自旋波频率有显著关系，超出了现有定性模型的解释范围。

Conclusion: 研究表明，在考虑了散射波的产生是涉及入射波和反射波的多个基本三磁振子过程后，散射波的产生机制能更好地解释观察到的现象，并且散射波的幅度对自旋波反射时的相位累积非常敏感。

Abstract: Three-wave scattering is a fascinating phenomenon with many applications in
various technologies. Reducing the system symmetry greatly affects three-wave
scattering, which, in this case, goes beyond the simple momentum conservation
law. In this study, we examine three-magnon scattering at the edge of a thin
ferromagnetic film, when a bulk spin wave interacts with an edge-localized
propagating spin-wave upon the reflection. This creates new bulk spin waves at
mixed frequencies by means of three-magnon confluence or stimulated splitting
processes. Using our developed analytical theory, which has been confirmed by
full micromagnetic simulations, we demonstrate that the amplitude of the wave
generated in the stimulated splitting process is several times larger than that
generated in the confluence process, primarily due to the lower group velocity.
Furthermore, intensity of inelastically scattered waves exhibit a pronounced
dependence on the incidence angle and frequency of the edge spin wave that goes
beyond existing qualitative models. We show that the observed behaviors can
only be explained by taking into account, that the scattered waves are created
by several elementary three-magnon processes involving the incident and
reflected waves. The complex nature of the scattered wave creation results in a
strong sensitivity of its amplitude to the phase accumulation of spin waves
upon reflection.

</details>


### [451] [Theory of nonlinear magnetoelectric transport effects in normal-metal $-$ magnetic-insulator heterostructures](https://arxiv.org/abs/2508.02492)
*Oliver Franke,Piet W. Brouwer*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一个理论框架，用于分析正常金属-磁绝缘体异质结构（FN 双层和 NFN 三层）在有限频率下的双线性响应。该框架考虑了焦耳热、声子介导的单向磁阻、自旋矩二极管效应和磁奨单向自旋霍尔磁阻等四种效应，并分析了它们在不同条件下的行为，为实验研究提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 解释正常金属-磁绝缘体异质结构中存在的与驱动电场二次相关的非线性响应，特别是单向自旋霍尔磁阻或自旋矩二极管效应。

Method: 开发了一个理论框架，用于分析有限频率下 FN 双层和 NFN 三层结构中的双线性响应，重点考虑了焦耳热、声子介导的单向磁阻、自旋矩二极管效应和磁奨单向自旋霍尔磁阻这四种已有的贡献。

Result: 识别了不同贡献在频率、磁化方向、磁场和系统几何形状上的依赖性及其比例关系，为实验区分提供了理论指导。

Conclusion: 该论文为有限频率下的法拉第-镍 (FN) 双层和镍-法拉第-镍 (NFN) 三层结构的双线性响应开发了一个理论框架，考虑了焦耳热、声子介导的单向磁阻、自旋矩二极管效应和磁奨单向自旋霍尔磁阻等四种已有的贡献，并研究了它们在频率、磁化方向、磁场和系统几何形状上的依赖性，为实验区分提供了理论基础。

Abstract: Heterostructures of normal metals (N) and magnetic insulators (F) show
paradigmatic effects, such as spin-Hall magnetoresistance and electric drag
currents. These effects are linear in the applied electric field $E(\omega)$.
Normal-metal $-$ magnetic-insulator heterostructures also exhibit a
characteristic nonlinear response quadratic in $E(\omega)$, referred to as
unidirectional spin-Hall magnetoresistance or spin-torque diode effect. In this
article, we develop a theory of the bilinear response of FN bilayers and NFN
trilayers for finite frequencies $\omega$ of the driving field and for four
contributions that have been previously considered in the literature: Joule
heating, phonon-mediated unidirectional magnetoresistance, the spin-torque
diode effect, and magnonic unidirectional spin-Hall magnetoresistance. We
identify their distinct dependencies on frequency and the magnetization
direction of the magnetic insulator and examine their scaling with magnetic
field and system geometry, providing a framework for experimental
differentiation.

</details>


### [452] [Floquet odd-parity collinear magnets](https://arxiv.org/abs/2508.02542)
*Tongshuai Zhu,Di Zhou,Huaiqiang Wang,Jiawei Ruan*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Altermagnets (AMs), recently discovered unconventional magnets distinct from
ferro- and antiferromagnets, have rapidly emerged as a prominent frontier in
condensed matter physics. AMs are characterized by alternating collinear
magnetic moments with zero net magnetization in real space, and spin splittings
with even-parity symmetry in momentum space. However, their counterparts
exhibiting odd-parity spin splitting remain largely unexplored. Here, based on
symmetry argument, we show that such unconventional odd-parity magnets can be
induced from collinear antiferromagnets. Remarkably, using effective model
analysis within Floquet-theory framework, we demonstrate that circularly
polarized light irradiation of conventional antiferromagnetic lattices induces
both $p$- and $f$-wave magnets, realizing novel magnetic states dubbed Floquet
odd-parity collinear magnets. Moreover, we also uncover light-induced
antiferromagnetic Chern insulating states in the $f$-wave magnets. The proposed
Floquet odd-parity magnet is confirmed by first-principles calculations of
MnPSe$_{3}$ under circularly polarized light. Our work not only proposes a new
class of unconventional magnets, but also opens an avenue for light-induced
magnetic phenomena in spintronic applications.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [453] [Cross-Process Defect Attribution using Potential Loss Analysis](https://arxiv.org/abs/2508.00895)
*Tsuyoshi Idé,Kohei Miyaguchi*

Main category: eess.SY

TL;DR: 提出了一种名为潜在损失分析（PLA）的新框架，用于晶圆缺陷根本原因分析，这是先前提出的部分轨迹回归方法的重大增强。


<details>
  <summary>Details</summary>
Motivation: 跨工艺晶圆缺陷根本原因分析是半导体制造中最关键但也最具挑战性的任务之一，因为沿工艺路线的工艺具有异质性和组合性。

Method: PLA框架将识别最佳可能结果的任务简化为求解贝尔曼方程，并能同时解决缺陷密度预测问题和缺陷评分归因问题。

Result: 使用实际晶圆历史数据证明了该框架的有效性。

Conclusion: PLA框架通过比较由部分处理轨迹生成的最佳可能结果，将观察到的高晶圆缺陷密度归因于上游工艺。

Abstract: Cross-process root-cause analysis of wafer defects is among the most critical
yet challenging tasks in semiconductor manufacturing due to the heterogeneity
and combinatorial nature of processes along the processing route. This paper
presents a new framework for wafer defect root cause analysis, called Potential
Loss Analysis (PLA), as a significant enhancement of the previously proposed
partial trajectory regression approach. The PLA framework attributes observed
high wafer defect densities to upstream processes by comparing the best
possible outcomes generated by partial processing trajectories. We show that
the task of identifying the best possible outcome can be reduced to solving a
Bellman equation. Remarkably, the proposed framework can simultaneously solve
the prediction problem for defect density as well as the attribution problem
for defect scores. We demonstrate the effectiveness of the proposed framework
using real wafer history data.

</details>


### [454] [A Kalman Filter Algorithm with Process Noise Covariance Update](https://arxiv.org/abs/2508.00905)
*Krishan Kumar Gola,Shaunak Sen*

Main category: eess.SY

TL;DR: Kalman filter can be improved by updating the process noise covariance based on the state estimate, especially for biomolecular models. Our method provides theoretical guarantees for this update in linear systems and an approximation for nonlinear systems.


<details>
  <summary>Details</summary>
Motivation: The motivation for this research stems from the need to address state-dependent process noise covariance in stochastic models within biomolecular contexts. The selection of this covariance is crucial for Kalman Filter design, yet the theoretical guarantees for updating it as the state estimate evolves are not well understood.

Method: We utilized the Minimum Mean Square Error estimator framework and interpreted the Kalman Filter as a Newton

Result: Our findings indicate that a Kalman Filter-like algorithm incorporating a process noise covariance update provides the best linear unbiased estimator for specific classes of systems. This includes discrete-time and continuous-time system dynamics with linear process dynamics and a square root-dependence of the process noise covariance on the state. For nonlinear dynamics, the algorithm was shown to minimize a quadratic approximation to a least squares cost weighted by the noise covariance.

Conclusion: We demonstrated that a Kalman Filter-like algorithm with a state-dependent process noise covariance update offers optimal estimation for systems with linear dynamics and a square root-dependence of the process noise covariance on the state. For nonlinear dynamics, this algorithm minimizes a quadratic approximation of a least squares cost weighted by the noise covariance.

Abstract: Stochastic models in biomolecular contexts can have a state-dependent process
noise covariance. The choice of the process noise covariance is an important
parameter in the design of a Kalman Filter for state estimation and the
theoretical guarantees of updating the process noise covariance as the state
estimate changes are unclear. Here we investigated this issue using the Minimum
Mean Square Error estimator framework and an interpretation of the Kalman
Filter as minimizing a weighted least squares cost using Newton's method. We
found that a Kalman Filter-like algorithm with a process noise covariance
update is the best linear unbiased estimator for a class of systems with linear
process dynamics and a square root-dependence of the process noise covariance
on the state. We proved the result for discrete-time system dynamics and then
extended it to continuous-time dynamics using a limiting procedure. For
nonlinear dynamics with a general dependence of process noise covariance on the
state, we showed that this algorithm minimizes a quadratic approximation to a
least squares cost weighted by the noise covariance. The algorithm is
illustrated with an example.

</details>


### [455] [Estimating Reliability of Electric Vehicle Charging Ecosystem using the Principle of Maximum Entropy](https://arxiv.org/abs/2508.00916)
*Himanshu Tripathi,Subash Neupane,Shahram Rahimi,Noorbakhsh Amiri Golilarz,Sudip Mittal,Mohammad Sepehrifar*

Main category: eess.SY

TL;DR: 本研究利用最大熵原理（PME）有效预测电动汽车充电系统在面对如过热、恶劣天气或网络攻击等未知风险时的可靠性下降。研究表明，局部压力可引发系统性故障，并量化了不确定性与可靠性之间的负相关关系，为复杂系统（如智能电网）的安全性提升提供了通用方法。


<details>
  <summary>Details</summary>
Motivation: 传统上，预测系统故障的方法依赖于历史数据或有限的假设，这使得它们在面对新的或不常见的威胁时效果不佳。因此，本研究旨在解决如何估计电动汽车充电系统在面对如过热、不可预测的天气和网络攻击等风险时的可靠性这一关键挑战。

Method: 本研究利用最大熵原理（PME）作为一种统计工具，在信息有限的情况下估计风险。PME通过在已知约束条件下进行平衡，从而在不猜测缺失细节的情况下进行无偏预测。研究以电动汽车充电系统为例，构建PME模型来模拟导致故障的压力因素。

Result: 研究发现，即使是微小的、局部的压力事件也可能导致整体系统可靠性出现不成比例的大幅下降，类似于多米诺骨牌效应。PME模型展示了高影响力的组件（如电网）在压力累积时更可能失效，从而引发网络范围的“临界点”。该研究通过数学上建立不确定性（熵）和可靠性之间的反比关系，量化了系统不可预测性如何直接降低其鲁棒性。

Conclusion: 该研究提出了一种利用最大熵原理（PME）来量化和预测包括电动汽车充电系统在内的复杂系统在面临未知或罕见风险（如过热、极端天气、网络攻击）时的可靠性下降的方法。研究表明，即使是小的、局部的压力事件也可能导致整体系统可靠性出现不成比例的大幅下降，并强调了高影响组件（如电网）在累积压力下失效的可能性，从而可能引发网络范围的“临界点”。该方法通过量化不确定性（熵）与可靠性之间的反比关系，为在信息不完整的情况下进行决策提供了通用工具，适用于电网、医疗设备、物流网络等多种复杂系统，旨在提高决策的安全性与效率。

Abstract: This paper addresses the critical challenge of estimating the reliability of
an Electric Vehicle (EV) charging systems when facing risks such as
overheating, unpredictable, weather, and cyberattacks. Traditional methods for
predicting failures often rely on past data or limiting assumptions, making
them ineffective for new or less common threats that results in failure. To
solve this issue, we utilize the Principle of Maximum Entropy (PME), a
statistical tool that estimates risks even with limited information. PME works
by balancing known constraints to create an unbiased predictions without
guessing missing details. Using the EV charging ecosystem as a case study, we
show how PME models stress factors responsible for failure. Our findings reveal
a critical insight: even minor, localized stress events can trigger
disproportionately large drops in overall system reliability, similar to a
domino effect. The our PME model demonstrates how high-impact components, such
as the power grid, are more likely to fail as stress accumulates, creating
network-wide tipping points. Beyond EVs, this approach applies to any complex
system with incomplete data, such as smart grids, healthcare devices, or
logistics networks. By mathematically establishing an inverse relationship
between uncertainty (entropy) and reliability, our work quantifies how greater
system unpredictability directly degrades robustness. This offers a universal
tool to improve decision-making under unpredictable conditions. This work
bridges advanced mathematics with real-world engineering, providing actionable
insights for policymakers and industries to build safer, more efficient systems
in our increasingly connected world.

</details>


### [456] [Modeling Head-Neck Dynamics under Lateral Perturbations Using MPC to Mimic CNS postural stabilization strategy](https://arxiv.org/abs/2508.00928)
*Chrysovalanto Messiou,Riender Happee,Georgios Papaioannou*

Main category: eess.SY

TL;DR: 自动驾驶汽车的头部稳定模型很重要，本研究扩展了一个模型预测控制框架来模拟头部在横向扰动下的姿势控制，并通过实验验证了模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了评估自动驾驶汽车的舒适性，需要能够准确捕捉头颈姿势稳定性的模型，以应对因视觉线索有限而可能出现的意外运动。

Method: 本研究将现有的基于模型预测控制的框架扩展到模拟横向扰动下的头颈姿势控制。

Result: 实验验证表明，该模型能够准确重现横向躯干扰动期间的动态响应。

Conclusion: 肌肉努力结合部分体感反馈能够最好地模拟动态响应，且无需姿势调整的相对和整体头部方向积分器。

Abstract: Automated vehicles will allow occupants to engage in non-driving tasks, but
limited visual cues will make them vulnerable to unexpected movements. These
unpredictable perturbations create a "surprise factor," forcing the central
nervous system to rely on compensatory postural adjustments, which are less
effective, and are more likely to trigger sensory conflicts. Since the head is
a key reference for sensory input (vestibular and vision), models accurately
capturing head-neck postural stabilization are essential for assessing AV
comfort. This study extends an existing model predictive control-based
framework to simulate head-neck postural control under lateral perturbations.
Experimental validation against human data demonstrates that the model can
accurately reproduce dynamic responses during lateral trunk perturbations. The
results show that muscle effort combined with partial somatosensory feedback
provides the best overall dynamic fit without requiring corrective relative and
global head orientation integrators for posture.

</details>


### [457] [System Identification via Validation and Adaptation for Model Updating Applied to a Nonlinear Cantilever Beam](https://arxiv.org/abs/2508.00931)
*Cristian López,Jackson E. Herzlieb,Keegan J. Moore*

Main category: eess.SY

TL;DR: SIVA是一种新的系统辨识方法，它使用生成模型和对抗学习从数据中估计参数、量化不确定性并验证模型。在悬臂梁的非线性振动数据上，SIVA表现出了准确的参数估计和模型更新能力。


<details>
  <summary>Details</summary>
Motivation: 受生成模型启发，SIVA方法旨在直接从数据中实现系统辨识、不确定性量化和模型验证。

Method: SIVA方法结合了生成模型和对抗学习的思想。它使用一个神经网络将随机噪声转换为物理参数，然后利用已知的运动方程生成模拟加速度，并通过均方误差损失与真实训练数据进行比较。同时，通过判别器网络对独立数据集生成的信号进行真实/伪造分类，以指导参数生成器网络进行参数验证。

Result: SIVA方法能够对包含集总质量和非线性末端附件的悬臂梁模拟振动数据进行精确的参数估计和模型更新。

Conclusion: SIVA方法在包含集总质量和非线性末端附件的悬臂梁模拟振动数据上，能够进行精确的参数估计和模型更新，证明了其在复杂、高度非线性系统上的有效性。

Abstract: The recently proposed System Identification via Validation and Adaptation
(SIVA) method allows system identification, uncertainty quantification, and
model validation directly from data. Inspired by generative modeling, SIVA
employs a neural network that converts random noise to physically meaningful
parameters. The known equation of motion utilizes these parameters to generate
fake accelerations, which are compared to real training data using a mean
square error loss. For concurrent parameter validation, independent datasets
are passed through the model, and the resulting signals are classified as real
or fake by a discriminator network, which guides the parameter-generator
network. In this work, we apply SIVA to simulated vibration data from a
cantilever beam that contains a lumped mass and a nonlinear end attachment,
demonstrating accurate parameter estimation and model updating on complex,
highly nonlinear systems.

</details>


### [458] [Trusted Routing for Blockchain-Empowered UAV Networks via Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2508.00938)
*Ziye Jia,Sijie He,Qiuming Zhu,Wei Wang,Qihui Wu,Zhu Han*

Main category: eess.SY

TL;DR: 本研究提出了一种基于区块链和多智能体深度强化学习的UAV网络路由新方法，有效降低了延迟并增强了安全性。


<details>
  <summary>Details</summary>
Motivation: UAV网络中的路由易受恶意攻击，具有分布式拓扑和高动态性，因此确保路由安全具有挑战性。

Method: 提出了一种基于区块链的信任管理机制（BTMM），用于动态评估信任值和识别低信任UAV。设计了一种共识UAV更新机制来改进传统的拜占庭容错算法。将路由问题重新表述为去中心化的部分可观察马尔可夫决策过程。设计了一种基于多智能体双深度Q网络的路由算法来最小化总延迟。

Result: 模拟结果显示，所提出的机制比其他算法（如多智能体近端策略最优算法、多智能体深度Q网络算法以及没有BTMM的方法）的延迟分别降低了13.39%、12.74%和16.6%。

Conclusion: 所提出的基于区块链的信任管理机制（BTMM）和多智能体深度强化学习算法可以有效降低UAV网络路由的延迟，并提高路由安全性。

Abstract: Due to the high flexibility and versatility, unmanned aerial vehicles (UAVs)
are leveraged in various fields including surveillance and disaster
rescue.However, in UAV networks, routing is vulnerable to malicious damage due
to distributed topologies and high dynamics. Hence, ensuring the routing
security of UAV networks is challenging. In this paper, we characterize the
routing process in a time-varying UAV network with malicious nodes.
Specifically, we formulate the routing problem to minimize the total delay,
which is an integer linear programming and intractable to solve. Then, to
tackle the network security issue, a blockchain-based trust management
mechanism (BTMM) is designed to dynamically evaluate trust values and identify
low-trust UAVs. To improve traditional practical Byzantine fault tolerance
algorithms in the blockchain, we propose a consensus UAV update mechanism.
Besides, considering the local observability, the routing problem is
reformulated into a decentralized partially observable Markov decision process.
Further, a multi-agent double deep Q-network based routing algorithm is
designed to minimize the total delay. Finally, simulations are conducted with
attacked UAVs and numerical results show that the delay of the proposed
mechanism decreases by 13.39$\%$, 12.74$\%$, and 16.6$\%$ than multi-agent
proximal policy optimal algorithms, multi-agent deep Q-network algorithms, and
methods without BTMM, respectively.

</details>


### [459] [Consumer-based Carbon Costs: Integrating Consumer Carbon Preferences in Electricity Markets](https://arxiv.org/abs/2508.01076)
*Wenqian Jiang,Aditya Rangarajan,Line Roald*

Main category: eess.SY

TL;DR: 本篇论文提出了一种将消费者碳偏好纳入电力市场清算的方法，通过引入消费者碳成本来提高市场清洁度。研究表明，该方法能够通过发电侧重新调度和需求侧减量来促进绿色电力交易，并且与传统的基于位置边际电价的市场相比，具有相同的收入充足性和个体理性等优点。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的消费者关注其用电的碳足迹，本研究旨在将消费者的碳偏好纳入电力市场清算过程，通过引入消费者碳成本来实现。

Method: 本研究提出了一个集中的市场清算方法，该方法在考虑了发电成本、消费者效用和消费者碳成本的基础上，最大化了社会福利。随后，我们推导出了一个等效的均衡公式，该公式包含了一个碳分配问题，并产生了针对消费者和发电方的碳调整电价。我们证明了碳调整电价对于低排放发电商和高碳成本消费者而言更高。此外，我们还证明了该新范式满足了与基于位置边际电价的标准电力市场相同的期望市场特性，即收入充足性和个体理性。最后，我们证明了对发电商征收碳税等同于对消费者征取统一的碳成本。

Result: 研究结果表明，消费者碳成本能够通过发电侧重新调度和需求侧减量来促进电力市场的绿色清洁度。此外，我们还证明了碳调整电价对于低排放发电商和高碳成本消费者而言更高，并且该新范式满足了收入充足性和个体理性等市场特性。

Conclusion: 消费者碳成本可以提高电力市场的绿色清洁度，并且在发电侧重新调度和需求侧减量方面都有显著的提升。

Abstract: An increasing share of consumers care about the carbon footprint of their
electricity. This paper proposes to integrate consumer carbon preferences in
the electricity market-clearing through consumer-based carbon costs.
Specifically, consumers can submit not only bids for power but also assign a
cost to the carbon emissions incurred by their electricity use. We start from a
centralized market clearing that maximizes social welfare under consideration
of generation costs, consumer utility and consumer carbon costs. We then derive
an equivalent equilibrium formulation which incorporates a carbon allocation
problem and gives rise to a set of carbon-adjusted electricity prices for both
consumers and generators. We prove that the carbon-adjusted prices are higher
for low-emitting generators and consumers with high carbon costs. Further, we
prove that this new paradigm satisfies the same desirable market properties as
standard electricity markets based on locational marginal prices, namely
revenue adequacy and individual rationality, and demonstrate that a carbon tax
on generators is equivalent to imposing a uniform carbon cost on consumers.
Using a simplified three-bus system and the RTS-GMLC system, we illustrate that
consumer-based carbon costs contribute to greener electricity market clearing
both through generation redispatch and reductions in demand.

</details>


### [460] [Physics-Informed Data-Driven Control of Nonlinear Polynomial Systems with Noisy Data](https://arxiv.org/abs/2508.01315)
*MohammadHossein Ashoori,Ali Aminzadeh,Amy Nejati,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 提出了一种新的框架，结合物理原理和带噪声的数据来为复杂系统设计安全控制器，显著减少了所需的数据量。


<details>
  <summary>Details</summary>
Motivation: 解决在模型不确定和数据噪声存在的情况下，保证复杂动力学系统安全的关键挑战。

Method: 提出了一种物理信息驱动的直接数据驱动框架，用于为离散和连续时间的非线性多项式系统合成鲁棒安全控制器（R-SCs）。该框架通过引入鲁棒控制屏障证书（R-CBCs）的概念来确保避开不安全区域，并将其设计过程形式化为一个平方和（SOS）优化问题。

Result: 在四个基准系统（三个离散时间和一个连续时间非线性多项式系统）上验证了该框架的有效性，证明了其在减少数据需求的同时提供鲁棒安全保证的能力。

Conclusion: 该框架能够为非线性多项式系统提供鲁棒的安全保证，并减少数据需求。

Abstract: This work addresses the critical challenge of guaranteeing safety for complex
dynamical systems where precise mathematical models are uncertain and data
measurements are corrupted by noise. We develop a physics-informed, direct
data-driven framework for synthesizing robust safety controllers (R-SCs) for
both discrete- and continuous-time nonlinear polynomial systems that are
subject to unknown-but-bounded disturbances. To do so, we introduce a notion of
safety through robust control barrier certificates (R-CBCs), which ensure
avoidance of (potentially multiple) unsafe regions, offering a less
conservative alternative to existing methods based on robust invariant sets.
Our core innovation lies in integrating the fundamental physical principles
with observed noisy data which drastically reduces data requirements, enabling
robust safety analysis with significantly shorter trajectories, compared to
purely data-driven methods. To achieve this, the proposed synthesis procedure
is formulated as a sum-of-squares (SOS) optimization program that
systematically designs the R-CBC and its associated R-SC by leveraging both
collected data and underlying physical laws. The efficacy of our framework is
demonstrated on four benchmark systems, three discrete-time and one
continuous-time nonlinear polynomial systems, confirming its ability to offer
robust safety guarantees with reduced data demands.

</details>


### [461] [Multi-Agent Inverse Learning for Sensor Networks: Identifying Coordination in UAV Networks](https://arxiv.org/abs/2508.01445)
*Luke Snow,Vikram Krishnamurthy*

Main category: eess.SY

TL;DR: This paper uses microeconomics to help radar detect coordinating enemy drones and figure out their goals.


<details>
  <summary>Details</summary>
Motivation: The motivation is to determine if UAVs in an adversarial network are coordinating and to infer their individual and network-level objectives, as observed by a radar system.

Method: The paper uses abstract interpretation to model coordination as a linearly constrained multi-objective optimization problem. It then applies tools from microeconomic theory to detect coordination and reconstruct individual UAV objective functions from radar tracking signals, performing inverse multi-objective optimization. The framework is linked to physical-layer radar waveform modulation and multi-target filtering.

Result: The paper demonstrates how microeconomic theory can be used to detect coordination and reconstruct individual UAV objective functions from radar tracking signals. It establishes a correspondence between the abstract microeconomic interpretation and physical-layer radar processing.

Conclusion: The paper presents a microeconomic framework for analyzing adversarial UAV networks, enabling the detection of coordination and inference of individual UAV objectives from radar signals. It bridges concepts from abstract interpretation, multi-objective optimization, and microeconomic theory to physical-layer radar processing.

Abstract: Suppose there is an adversarial UAV network being tracked by a radar. How can
the radar determine whether the UAVs are coordinating, in some well-defined
sense? How can the radar infer the objectives of the individual UAVs and the
network as a whole? We present an abstract interpretation of such a strategic
interaction, allowing us to conceptualize coordination as a linearly
constrained multi-objective optimization problem. Then, we present some tools
from microeconomic theory that allow us to detect coordination and reconstruct
individual UAV objective functions, from radar tracking signals. This
corresponds to performing inverse multi-objective optimization. We present
details for how the abstract microeconomic interpretation corresponds to, and
naturally arises from, physical-layer radar waveform modulation and
multi-target filtering. This article serves as a tutorial, bringing together
concepts from several established research contributions in an expository
style.

</details>


### [462] [Distributed Non-Uniform Scaling Control of Multi-Agent Formation via Matrix-Valued Constraints](https://arxiv.org/abs/2508.02289)
*Tao He,Gangshan Jing*

Main category: eess.SY

TL;DR: 本文提出了一种新的分布式控制方法，用于编队机动控制，可以实现非均匀缩放和姿态控制，并且比现有方法需要更少的领导者和更稀疏的传感器图。


<details>
  <summary>Details</summary>
Motivation: 现有分布式编队机动控制方法主要局限于均匀缩放变换，本文旨在实现非均匀缩放控制。

Method: 提出了一种新的局部矩阵值约束，通过操纵两个领导者的位置来实现非均匀缩放控制。通过定义姿态保持架的缩放和平移，提出了一种用于联合位置-姿态保持架的缩放和平移机动控制的分布式控制方案。

Result: 提出了一种新的局部矩阵值约束，通过操纵两个领导者的位置来实现非均匀缩放控制。通过定义姿态保持架的缩放和平移，提出了一种用于联合位置-姿态保持架的缩放和平移机动控制的分布式控制方案。

Conclusion: 该控制器通过二叉树图实现全局收敛，所需传感器图更稀疏，所需领导者更少，并实现了姿态保持架的缩放。

Abstract: Distributed formation maneuver control refers to the problem of maneuvering a
group of agents to change their formation shape by adjusting the motions of
partial agents, where the controller of each agent only requires local
information measured from its neighbors. Although this problem has been
extensively investigated, existing approaches are mostly limited to uniform
scaling transformations. This article proposes a new type of local
matrix-valued constraints, via which non-uniform scaling control of position
formation can be achieved by tuning the positions of only two agents (i.e.,
leaders). Here, the non-uniform scaling transformation refers to scaling the
position formation with different ratios along different orthogonal coordinate
directions. Moreover, by defining scaling and translation of attitude
formation, we propose a distributed control scheme for scaling and translation
maneuver control of joint position-attitude formations. It is proven that the
proposed controller achieves global convergence, provided that the sensing
graph among agents is a 2-rooted bidirectional graph. Compared with the affine
formation maneuver control approach, the proposed approach leverages a sparser
sensing graph, requires fewer leaders, and additionally enables scaling
transformations of the attitude formation. A simulation example is proposed to
demonstrate our theoretical results.

</details>


### [463] [Kernel-Based Sparse Additive Nonlinear Model Structure Detection through a Linearization Approach](https://arxiv.org/abs/2508.01453)
*Sadegh Ebrahimkhani,John Lataire*

Main category: eess.SY

TL;DR: 该论文提出了一种数据驱动的方法，利用线性参数变化（LPV）模型和稀疏估计器来简化和确定非线性系统的结构，并通过数值模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决过于复杂的非线性模型难以解释和不切实际的问题，需要数据驱动的方法来获得更简单、更准确的模型表示。

Method: 研究使用线性参数变化（LPV）模型来近似非线性系统，并利用稀疏估计器在向量值再生核希尔伯特空间（RKHS）框架下估计LPV系数，以确定非线性模型的结构。

Result: 通过数值模拟验证了所提出方法的有效性，该方法能够识别非线性子项的数量和输入空间，并确定非线性模型的结构。

Conclusion: 该研究提出了一种数据驱动的方法来简化一类连续时间非线性系统模型，通过在不同操作点附近进行线性近似。

Abstract: The choice of parameterization in Nonlinear (NL) system models greatly
affects the quality of the estimated model. Overly complex models can be
impractical and hard to interpret, necessitating data-driven methods for
simpler and more accurate representations. In this paper, we propose a
data-driven approach to simplify a class of continuous-time NL system models
using linear approximations around varying operating points. Specifically, for
sparse additive NL models, our method identifies the number of NL subterms and
their corresponding input spaces. Under small-signal operation, we approximate
the unknown NL system as a trajectory-scheduled Linear Parameter-Varying (LPV)
system, with LPV coefficients representing the gradient of the NL function and
indicating input sensitivity. Using this sensitivity measure, we determine the
NL system's structure through LPV model reduction by identifying non-zero LPV
coefficients and selecting scheduling parameters. We introduce two sparse
estimators within a vector-valued Reproducing Kernel Hilbert Space (RKHS)
framework to estimate the LPV coefficients while preserving their structural
relationships. The structure of the sparse additive NL model is then determined
by detecting non-zero elements in the gradient vector (LPV coefficients) and
the Hessian matrix (Jacobian of the LPV coefficients). We propose two
computationally tractable RKHS-based estimators for this purpose. The
sparsified Hessian matrix reveals the NL model's structure, with numerical
simulations confirming the approach's effectiveness.

</details>


### [464] [Bounded fuzzy logic control for optimal scheduling of green hydrogen production and revenue maximisation](https://arxiv.org/abs/2508.01468)
*Sleiman Farah,Jens Jakob Sørensen,Kary Främling,Matej Simurda*

Main category: eess.SY

TL;DR: BFLC通过预测电力和氢气价格以及风力容量因子来优化绿色氢气生产调度，以最大化收入并满足HPA交付义务，其收入接近最优值且优于稳态控制。


<details>
  <summary>Details</summary>
Motivation: 为了应对可再生能源发电的间歇性和电力、氢气市场的并行收入机会，需要优化绿色氢气生产的调度，以最大化收入，同时满足长期的HPA交付义务。

Method: 提出了一种有界模糊逻辑控制（BFLC）方法，该方法根据对电力和氢气价格以及风力容量因子的预测，确定每日氢气购买协议（HPA）的交付目标，并将其作为调度优化的约束条件，以优化每小时的能源和氢气流动。

Result: 与基于完美预知的最优收入相比，BFLC实现的年总收入在9%的范围内；BFLC的收入始终超过稳态控制，在价格水平和波动性较高时差异最大。

Conclusion: 该研究通过BFLC（有界模糊逻辑控制）有效解决了绿色氢气生产的长期调度问题，实现了与最优调度接近的收入，并优于稳态控制，尤其是在价格波动较大的情况下，为绿色氢气项目的经济风险评估提供了现实依据。

Abstract: Hydrogen Purchase Agreements (HPAs) guarantee revenue streams that mitigate
the financial risks inherent in the long-term production of green hydrogen from
renewable energy sources. However, the intermittency of renewable electricity
and the availability of parallel revenue opportunities in both the electricity
and hydrogen markets complicate the scheduling of green hydrogen production.
The scheduling should maximise the total revenue from short-term sales of
electricity and hydrogen against the long-term HPA delivery obligations. This
challenge is addressed by developing a Bounded Fuzzy Logic Control (BFLC) which
determines the daily HPA delivery target based on day-ahead forecasts of
electricity and hydrogen prices, as well as wind capacity factors.
Subsequently, the daily target is imposed as a constraint in dispatch
optimisation which allocates energy and hydrogen flows for each hour of the
day. Revenue comparisons over several years demonstrate that the BFLC achieves
total annual revenues within 9% of optimal revenues that are based on perfect
foresight. The BFLC revenues consistently exceed those of steady control, with
the largest differences observed under conditions of elevated price levels and
variability. The BFLC provides an effective long-term scheduling of green
hydrogen production, enabling realistic revenue quantification that mitigates
economic risks without overlooking economically viable projects.

</details>


### [465] [Pursuit-Evasion Between a Velocity-Constrained Double-Integrator Pursuer and a Single-Integrator Evader](https://arxiv.org/abs/2508.01570)
*Zehua Zhao,Rui Yan,Jianping He,Xinping Guan,Xiaoming Duan*

Main category: eess.SY

TL;DR: 在追逐-逃避博弈中，当追逐者速度受限时，根据追逐者能否在达到最大速度前捕获逃避者，分别采用几何或数值方法制定双方策略，可实现最优捕获。


<details>
  <summary>Details</summary>
Motivation: 本文研究的是一个追逐-逃避博弈问题，其中追逐者由双积分器驱动，具有速度和加速度的限制，而逃避者由单积分器驱动，在二维平面上具有速度限制。追逐者的目标是以最短时间捕获逃避者，而逃避者的目标是延迟捕获。

Method: 本文采用几何方法和数值方法分别分析了两种情况：追逐者在速度达到最大值之前捕获逃避者的情况，以及追逐者在速度达到最大值之后才能捕获逃避者的情况。

Result: 在两种情况下，通过Hamilton-Jacobi-Isaacs方程证明了所提出策略的最优性（纳什均衡意义下）。

Conclusion: 仿真实验证明了该策略的有效性。当追逐者的最大速度大于逃避者的最大速度时，追逐者可以捕获逃避者。

Abstract: We study a pursuit-evasion game between a double integrator-driven pursuer
with bounded velocity and bounded acceleration and a single integrator-driven
evader with bounded velocity in a two-dimensional plane. The pursuer's goal is
to capture the evader in the shortest time, while the evader attempts to delay
the capture. We analyze two scenarios based on whether the capture can happen
before the pursuer's speed reaches its maximum. For the case when the pursuer
can capture the evader before its speed reaches its maximum, we use geometric
methods to obtain the strategies for the pursuer and the evader. For the case
when the pursuer cannot capture the evader before its speed reaches its
maximum, we use numerical methods to obtain the strategies for the pursuer and
the evader. In both cases, we demonstrate that the proposed strategies are
optimal in the sense of Nash equilibrium through the Hamilton-Jacobi-Isaacs
equation, and the pursuer can capture the evader as long as as its maximum
speed is larger than that of the evader. Simulation experiments illustrate the
effectiveness of the strategies.

</details>


### [466] [A class of unified disturbance rejection control barrier functions](https://arxiv.org/abs/2508.01601)
*Xinyang Wang,Wei Xiao,Hongwei Zhang*

Main category: eess.SY

TL;DR:  This paper introduces DR-CBFs that handle general disturbances (matched/unmatched, differentiable/non-differentiable) for safety, with adaptive versions not needing disturbance bounds, and simulations show they are better than existing methods.


<details>
  <summary>Details</summary>
Motivation:  To address the limitations of existing robust CBFs that can only handle matched disturbances or rely on differentiability of disturbances for unmatched cases, especially for high-relative-degree safety constraints.

Method:  The paper proposes a class of disturbance rejection CBFs (DRCBFs), including DRCBFs and adaptive DRCBFs (aDRCBFs), to handle both matched or unmatched, differentiable or non-differentiable disturbances without requiring information of disturbance bound in aDRCBFs.

Result:  Simulation results show that DR-CBFs outperform existing robust CBFs.

Conclusion:  DR-CBFs can guarantee safety under general bounded disturbances, outperforming existing robust CBFs.

Abstract: Most existing robust control barrier functions (CBFs) can only handle matched
disturbances, restricting their applications in real-world scenarios. While
some recent advances extend robust CBFs to unmatched disturbances, they heavily
rely on differentiability property of disturbances, and fail to accommodate
non-differentiable case for high-relative-degree safety constraints. To address
these limitations, this paper proposes a class of disturbance rejection CBFs
(DRCBFs), including DRCBFs and adaptive DRCBFs (aDRCBFs). This class of DRCBFs
can strictly guarantee safety under general bounded disturbances, which
includes both matched or unmatched, differentiable or non-differentiable
disturbances as special cases. Morevoer, no information of disturbance bound is
needed in aDRCBFs. Simulation results illustrate that this class of DRCBFs
outperform existing robust CBFs.

</details>


### [467] [Attitude Determination and Control of GPS Satellites: Stabilization, Orbital Insertion, and Operational Control Mechanisms](https://arxiv.org/abs/2508.01660)
*Oliullah Samir*

Main category: eess.SY

TL;DR: This paper reviews GPS satellite operations, focusing on attitude control and orbital insertion, including technical details and equations.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive overview of the operational dynamics, attitude determination and control systems (ADCS), and orbital insertion techniques for GPS satellites, essential for accurate navigation and timing.

Method: The paper reviews operational dynamics, ADCS, and orbital insertion techniques for GPS satellites, exploring sensor/actuator integration, control algorithms, stabilization strategies, and launch procedures, while discussing key equations and recent literature.

Result: The paper reviews the operational dynamics, ADCS, and orbital insertion techniques for GPS satellites, covering sensor integration, control algorithms, stabilization strategies, and launch procedures, along with relevant equations and literature.

Conclusion: This paper provides a comprehensive review of the operational dynamics, attitude determination and control systems (ADCS), and orbital insertion techniques for GPS satellites, discussing key equations and recent literature.

Abstract: Global Positioning System (GPS) satellites are essential for providing
accurate navigation and timing information worldwide. Operating in medium Earth
orbit (MEO), these satellites must maintain precise Earth-pointing attitudes to
transmit signals effectively. This paper presents a comprehensive review of the
operational dynamics, attitude determination and control systems (ADCS), and
orbital insertion techniques for GPS satellites. We explore the integration of
sensors and actuators, control algorithms, stabilization strategies, and the
launch procedures required to deploy these satellites. Key equations related to
orbital mechanics and attitude control are discussed, and references to recent
technical literature are included.

</details>


### [468] [Supervisory Control of Discrete Event Systems for Small Language Under Cyber Attacks](https://arxiv.org/abs/2508.02083)
*Xiaojun Wang,Shaolong Shu,Feng Lin*

Main category: eess.SY

TL;DR: 在网络攻击下，研究了离散事件系统的监督控制问题，提出了CA-S可控和CA-S可观察的概念，并给出了实现所需小语言的条件和设计方法的理论基础。


<details>
  <summary>Details</summary>
Motivation: 网络攻击对离散事件系统中的监督控制带来了挑战，导致了不确定性，因此需要研究在攻击下的监督控制问题，以实现系统的最小语言。

Method: 本文提出了CA-S-可控和CA-S-可观察的概念，并证明了它们是实现所需小语言的充要条件。

Result: 证明了CA-S可控和CA-S可观察是实现小语言的充要条件。推导了在不满足这些条件时，存在infimal CA-S可控和CA-S可观察的superlanguage的条件。

Conclusion: 在网络安全攻击下，当给定语言满足CA-S可控和CA-S可观察的条件时，实现所需的小语言的可行性得到证明。如果给定语言不满足这些条件，我们推导出了存在infimal CA-S可控和CA-S可观察的superlanguage的条件，并可以用它来设计满足给定需求的Supervisor。

Abstract: Cyber attacks are unavoidable in networked discrete event systems where the
plant and the supervisor communicate with each other via networks. Because of
the nondeterminism in observation and control caused by cyber attacks, the
language generated by the supervised system becomes nondeterministic. The small
language is defined as the lower bound on all possible languages that can be
generated by the supervised system, which is needed for a supervised system to
perform some required tasks under cyber attacks. In this paper, we investigate
supervisory control for the small language. After introducing
CA-S-controllability and CA-S-observability, we prove that the supervisory
control problem of achieving a required small language is solvable if and only
if the given language is CA-Scontrollable and CA-S-observable. If the given
language is not CA-S controllable and/or CA-S-observable, we derive conditions
under which the infimal CA-S-controllable and CA-S-observable superlanguage
exists and can be used to design a supervisor satisfying the given requirement.

</details>


### [469] [Centralized Dynamic State Estimation Algorithm for Detecting and Distinguishing Faults and Cyber Attacks in Power Systems](https://arxiv.org/abs/2508.02102)
*Emad Abukhousa,Syed Sohail Feroz Syed Afroz,Fahad Alsaeed,Abdulaziz Qwbaiban,A. P. Sakis Meliopoulos*

Main category: eess.SY

TL;DR: 本研究提出了一种动态状态估计（DSE）算法，通过结构化假设检验来区分电力系统中的网络攻击和物理故障，以提高微电网的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统整合越来越多的可再生能源，其复杂性增加，更容易受到网络和物理威胁。因此，需要增强电力系统的保护能力，特别是针对微电网。

Method: 本研究提出并验证了一种利用结构化假设检验框架的集中式动态状态估计（DSE）算法，用于区分网络攻击和物理故障引起的异常。

Result: 通过四种案例研究（虚假数据注入攻击（FDIA）、单相接地（SLG）故障以及两者结合的场景）的实时仿真结果表明，该算法能够有效地区分网络攻击和物理故障。

Conclusion: 该研究验证了一种集中的动态状态估计（DSE）算法，用于提高电力系统的保护能力，特别关注具有大量可再生能源接入的微电网。该算法利用结构化假设检验框架，能够系统地区分由网络攻击和物理故障引起的异常。通过实时仿真评估，结果表明该算法能有效区分网络攻击和物理故障，显著提高了能源系统的可靠性和安全性。

Abstract: As power systems evolve with increased integration of renewable energy
sources, they become more complex and vulnerable to both cyber and physical
threats. This study validates a centralized Dynamic State Estimation (DSE)
algorithm designed to enhance the protection of power systems, particularly
focusing on microgrids with substantial renewable energy integration. The
algorithm utilizing a structured hypothesis testing framework, systematically
identifies and differentiates anomalies caused by cyberattacks from those
resulting from physical faults. This algorithm was evaluated through four case
studies: a False Data Injection Attack (FDIA) via manipulation of Current
Transformer (CT) ratios, a single line-to-ground (SLG) fault, and two combined
scenarios involving both anomalies. Results from real-time simulations
demonstrate that the algorithm effectively distinguishes between cyber-induced
anomalies and physical faults, thereby significantly enhancing the reliability
and security of energy systems. This research underscores the critical role of
advanced diagnostic tools in protecting power systems against the growing
prevalence of cyber-physical threats, enhancing the resilience of the grid and
preventing potential blackouts by avoiding the mis-operation of protection
relays.

</details>


### [470] [Data-Driven Adaptive Second-Order Sliding Mode Control with Noisy Data](https://arxiv.org/abs/2508.02357)
*Behrad Samari,Gian Paolo Incremona,Antonella Ferrara,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 为具有未知动力学的受扰严格反馈结构的单输入非线性系统设计了一种数据驱动的自适应次优二阶滑模（ASSOSM）控制器。


<details>
  <summary>Details</summary>
Motivation: 为具有未知动态的扰动严格反馈结构的单输入非线性系统提供一种数据驱动的自适应次优二阶滑模（ASSOSM）控制器设计方法。

Method: 数据驱动方法，递归地将系统动力学分解为上部和下部动力学。首先，通过有限时间实验收集噪声数据，并制定一个半定程序，以设计虚拟控制器来保证上部动力学的全局渐近稳定性。然后，利用虚拟控制器提出一个数据驱动的滑模变量，用于设计ASSOSM控制器，以保证整个系统的半全局渐近稳定性。

Result: 提出的ASSOSM控制器在存在扰动的情况下，保证了原点的半全局渐近稳定性。通过三个案例研究证明了该方法的有效性。

Conclusion: 该数据驱动方法为具有未知动态的扰动严格反馈结构的单输入非线性系统设计了自适应次优二阶滑模（ASSOSM）控制器。该控制器保证了在存在扰动的情况下，原点的半全局渐近稳定性。

Abstract: This paper offers a data-driven approach for designing adaptive suboptimal
second-order sliding mode (ASSOSM) controllers for single-input nonlinear
systems, characterized by perturbed strict-feedback structures with unknown
dynamics. The proposed approach is recursive, in which the system dynamics are
first decomposed into two parts, referred to as the upper and lower dynamics.
The control design task is then divided into two stages, that is, designing a
virtual controller for the upper dynamics, followed by synthesizing the actual
controller for the full-order system. To this end, we start by collecting noisy
data from the system through a finite-time experiment, referred to as a single
trajectory. We then formulate a data-dependent condition as a semidefinite
program, whose feasibility enables the design of a virtual controller that
ensures global asymptotic stability of the origin for the upper dynamics.
Building upon this virtual controller, we subsequently propose a data-driven
sliding variable that facilitates the design of an ASSOSM controller for the
unknown full-order system. This controller guarantees semi-global asymptotic
stability of the origin in the presence of disturbances. Specifically, for any
prescribed bounded set--no matter how large--the controller's design parameters
can be chosen to ensure asymptotic stability of the origin. The effectiveness
of the proposed method is demonstrated through three case studies, reflecting
different aspects of the approach.

</details>


### [471] [Equivalence of Koopman Eigenfunctions and a Commuting Local Frame of Symmetries](https://arxiv.org/abs/2508.02437)
*Xinyuan Jiang,Yan Li*

Main category: eess.SY

TL;DR: 本文利用系统的对称性来寻找非线性常微分方程的Koopman特征函数。


<details>
  <summary>Details</summary>
Motivation: 探索非线性常微分系统Koopman特征函数与对称性之间的关系，并利用这种关系简化求解过程。

Method: 通过建立Koopman特征函数与其对称性之间的双射，将寻找Koopman特征函数的问题转化为寻找可交换向量场的问题，并利用系统的流映射来求解。

Result: 得到了Koopman特征函数与其对称性之间的双射，并验证了该理论结果在范德波尔振荡器上的有效性。

Conclusion: 本文建立了非线性常微分方程系统的Koopman特征函数与其对称性之间的关系，并将寻找Koopman特征函数的问题转化为寻找可交换向量场的问题。

Abstract: This article establishes the relationship between the Koopman eigenfunctions
of a first-order nonlinear ODE system and its symmetries. Specifically, a
bijective mapping is obtained between i) a commuting local frame of symmetry
generators, and ii) a set of Koopman eigenfunctions whose gradients form a
local frame. This equivalence is used to convert the problem of finding Koopman
eigenfunctions into the equivalent problem of finding commuting vector fields,
which are readily given by the flow map of the system. The implication for
stability is also studied in terms of a contraction metric that is associated
with the commuting local frame of symmetries. The theoretical result is
verified with the van der Pol oscillator whose eigenfunctions are computed to
the precision of finite numerical integration.

</details>


### [472] [Computationally efficient Gauss-Newton reinforcement learning for model predictive control](https://arxiv.org/abs/2508.02441)
*Dean Brandner,Sebastien Gros,Sergio Lucia*

Main category: eess.SY

TL;DR: 通过高斯-牛顿近似和动量Hessian平均，提出了一种高效、数据驱动的MPC强化学习方法，在CSTR上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大多数强化学习方法依赖于一阶更新，在策略更新需要求解最优控制问题时效率低下。虽然MPC策略适合二阶方法，但现有方法需要计算和内存上难以处理的二阶策略梯度。

Method: 提出了一种高斯-牛顿近似方法来估计确定性策略Hessian，并采用基于动量的Hessian平均方案来提高训练的稳定性。

Result: 在非线性连续搅拌釜反应器（CSTR）上证明了该方法的有效性，与最先进的一阶方法相比，收敛速度更快，数据效率更高。

Conclusion: 该方法通过高斯-牛顿近似确定性策略Hessian，消除了对二阶策略梯度的需求，能够以最小的计算开销实现超线性收敛。所提出的基于动量的Hessian平均方案可用于在噪声估计下进行稳定训练。

Abstract: Model predictive control (MPC) is widely used in process control due to its
interpretability and ability to handle constraints. As a parametric policy in
reinforcement learning (RL), MPC offers strong initial performance and low data
requirements compared to black-box policies like neural networks. However, most
RL methods rely on first-order updates, which scale well to large parameter
spaces but converge at most linearly, making them inefficient when each policy
update requires solving an optimal control problem, as is the case with MPC.
While MPC policies are typically sparsely parameterized and thus amenable to
second-order approaches, existing second-order methods demand second-order
policy derivatives, which can be computationally and memory-wise intractable.
  This work introduces a Gauss-Newton approximation of the deterministic policy
Hessian that eliminates the need for second-order policy derivatives, enabling
superlinear convergence with minimal computational overhead. To further improve
robustness, we propose a momentum-based Hessian averaging scheme for stable
training under noisy estimates. We demonstrate the effectiveness of the
approach on a nonlinear continuously stirred tank reactor (CSTR), showing
faster convergence and improved data efficiency over state-of-the-art
first-order methods.

</details>


### [473] [Uncertainty-Aware Perception-Based Control for Autonomous Racing](https://arxiv.org/abs/2508.02494)
*Jelena Trisovic,Andrea Carron,Melanie N. Zeilinger*

Main category: eess.SY

TL;DR: 提出了一种新的基于感知的控制方法，用于自动驾驶赛车，该方法考虑了道路曲率估计及其不确定性，以实现更安全、更可靠的控制。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中运行的自主系统高度依赖视觉传感器数据，但基于这些测量结果做出安全和明智的控制决策仍然是一个重大挑战。为了促进自动驾驶汽车中感知和控制的集成，需要一种新的方法。

Method: 提出了一种新颖的基于感知的控制方法，该方法包括道路估计、不确定性量化和基于该估计的不确定性感知控制。核心是参数化道路曲率模型，通过约束非线性优化问题使用道路的视觉测量进行优化，以确保模型参数和曲率的约束得到遵守。利用Frenet框架，将估计的赛道曲率嵌入系统动力学。

Result: 在模拟环境中，使用高保真3D渲染引擎进行了验证，证明了其在为自动驾驶赛车实现可靠且考虑不确定性的控制方面的有效性。

Conclusion: 该方法通过将估计的赛道曲率纳入系统动力学，并显式考虑感知不确定性，从而实现可靠且考虑不确定性的自动驾驶控制。

Abstract: Autonomous systems operating in unknown environments often rely heavily on
visual sensor data, yet making safe and informed control decisions based on
these measurements remains a significant challenge. To facilitate the
integration of perception and control in autonomous vehicles, we propose a
novel perception-based control approach that incorporates road estimation,
quantification of its uncertainty, and uncertainty-aware control based on this
estimate. At the core of our method is a parametric road curvature model,
optimized using visual measurements of the road through a constrained nonlinear
optimization problem. This process ensures adherence to constraints on both
model parameters and curvature. By leveraging the Frenet frame formulation, we
embed the estimated track curvature into the system dynamics, allowing the
controller to explicitly account for perception uncertainty and enhancing
robustness to estimation errors based on visual input. We validate our approach
in a simulated environment, using a high-fidelity 3D rendering engine, and
demonstrate its effectiveness in achieving reliable and uncertainty-aware
control for autonomous racing.

</details>


### [474] [Causality and Interpretability for Electrical Distribution System faults](https://arxiv.org/abs/2508.02524)
*Karthik Peddi,Sai Ram Aditya Parisineni,Hemanth Macharla,Mayukha Pal*

Main category: eess.SY

TL;DR: 提出了一种新的因果推断与机器学习相结合的方法，使用图模型对电力配电系统故障进行分类，准确率达99.44%，并能解释故障原因。


<details>
  <summary>Details</summary>
Motivation: 因果分析有助于我们了解导致系统故障的变量，从而改进故障检测并提高系统可靠性。

Method: 提出了一种结合因果推断和机器学习的新方法，利用图模型对配电系统（EDS）中的故障进行分类。首先使用转移熵（TE）构建因果图，其中节点代表电压和电流等特征，边表示特征间的相互影响。然后，使用GraphSAGE等机器学习模型对图进行分类，模型同时学习节点值和图结构以预测故障类型。为了使预测更易于理解，集成了GNNExplainer和Captum的Integrated Gradients，以突出对最终预测影响最大的节点（特征）。

Result: 实验结果在EDS故障数据集上达到了99.44%的高准确率，优于现有最先进的模型。

Conclusion: 通过将因果图与机器学习相结合，该方法不仅能准确预测故障，还能帮助理解故障的根本原因，使其成为提高系统可靠性的强大实用工具。

Abstract: Causal analysis helps us understand variables that are responsible for system
failures. This improves fault detection and makes system more reliable. In this
work, we present a new method that combines causal inference with machine
learning to classify faults in electrical distribution systems (EDS) using
graph-based models. We first build causal graphs using transfer entropy (TE).
Each fault case is represented as a graph, where the nodes are features such as
voltage and current, and the edges demonstrate how these features influence
each other. Then, the graphs are classified using machine learning and
GraphSAGE where the model learns from both the node values and the structure of
the graph to predict the type of fault. To make the predictions understandable,
we further developed an integrated approach using GNNExplainer and Captums
Integrated Gradients to highlight the nodes (features) that influences the most
on the final prediction. This gives us clear insights into the possible causes
of the fault. Our experiments show high accuracy: 99.44% on the EDS fault
dataset, which is better than state of art models. By combining causal graphs
with machine learning, our method not only predicts faults accurately but also
helps understand their root causes. This makes it a strong and practical tool
for improving system reliability.

</details>


### [475] [Tensor Dynamic Mode Decomposition](https://arxiv.org/abs/2508.02627)
*Ziqin He,Mengqi Hu,Yifei Lou,Can Chen*

Main category: eess.SY

TL;DR: TDMD 是一种处理多维数据的新方法，比传统 DMD 效果更好。


<details>
  <summary>Details</summary>
Motivation: 传统 DMD 方法仅限于基于矩阵的公式，对于图像、视频和高阶网络等多维数据存在效率低下或不足的问题。

Method: TDMD 是通过结合张量分解技术来扩展传统 DMD 到三阶张量。

Result: TDMD 在合成和真实世界数据集上都证明了其有效性，相比于标准 DMD，它能更有效地计算并更好地保留多维数据中的时空结构。

Conclusion: TDMD 是一种基于 T-product 框架的张量动态模式分解方法，能够更有效地处理多维数据，并在状态重构和动态分量分离等任务中表现出色。

Abstract: Dynamic mode decomposition (DMD) has become a powerful data-driven method for
analyzing the spatiotemporal dynamics of complex, high-dimensional systems.
However, conventional DMD methods are limited to matrix-based formulations,
which might be inefficient or inadequate for modeling inherently
multidimensional data including images, videos, and higher-order networks. In
this letter, we propose tensor dynamic mode decomposition (TDMD), a novel
extension of DMD to third-order tensors based on the recently developed
T-product framework. By incorporating tensor factorization techniques, TDMD
achieves more efficient computation and better preservation of spatial and
temporal structures in multiway data for tasks such as state reconstruction and
dynamic component separation, compared to standard DMD with data flattening. We
demonstrate the effectiveness of TDMD on both synthetic and real-world
datasets.

</details>


### [476] [Hierarchical Learning-Based Control for Multi-Agent Shepherding of Stochastic Autonomous Agents](https://arxiv.org/abs/2508.02632)
*Italo Napolitano,Stefano Covone,Andrea Lama,Francesco De Lellis,Mario di Bernardo*

Main category: eess.SY

TL;DR: 本研究提出了一种无需通信或先验知识的分层学习控制架构，用于解决具有随机自主行为的多智能体牧羊问题，并在实验中取得了比现有方法更好的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体牧羊控制策略通常假设目标行为具有内聚性，这在实际应用中往往会失败，因为目标会表现出随机的自主行为。

Method: 提出了一种分层学习控制架构，将牧羊问题分解为高级决策制定模块和低级运动控制组件。该分布式控制系统直接从闭环经验中综合有效的控制策略，无需显式的智能体间通信或目标动力学先验知识。

Result: 实验验证表明，与最先进的启发式控制方法相比，该分布式控制系统具有优越的闭环性能，成功率达到100%，并提高了沉降时间和控制效率。该控制架构能够扩展到其设计条件之外，适应时变的目标区域，并通过在Robotarium平台上的实时实验证明了其实际实现的可行性。

Conclusion: 该研究提出的分层学习控制架构能够有效地解决多智能体牧羊问题，即使在目标行为具有随机性和自主性的情况下也能取得优异的性能。该系统通过涌现式协调实现分布式协同控制，无需集中式监督、显式通信或目标动力学先验知识。实验结果表明，与现有启发式控制方法相比，该方法具有更高的成功率、更短的沉降时间和更高的控制效率，并且能够适应时变目标区域，具有实际应用的可行性。

Abstract: Multi-agent shepherding represents a challenging distributed control problem
where herder agents must coordinate to guide independently moving targets to
desired spatial configurations. Most existing control strategies assume
cohesive target behavior, which frequently fails in practical applications
where targets exhibit stochastic autonomous behavior. This paper presents a
hierarchical learning-based control architecture that decomposes the
shepherding problem into a high-level decision-making module and a low-level
motion control component. The proposed distributed control system synthesizes
effective control policies directly from closed-loop experience without
requiring explicit inter-agent communication or prior knowledge of target
dynamics. The decentralized architecture achieves cooperative control behavior
through emergent coordination without centralized supervision. Experimental
validation demonstrates superior closed-loop performance compared to
state-of-the-art heuristic control methods, achieving 100\% success rates with
improved settling times and control efficiency. The control architecture scales
beyond its design conditions, adapts to time-varying goal regions, and
demonstrates practical implementation feasibility through real-time experiments
on the Robotarium platform.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [477] [High-magnitude, spatially variable, and sustained strain engineering of 2D semiconductors](https://arxiv.org/abs/2508.00972)
*Boran Kumral,Peter Serles,Pedro Guerra Demingos,Shuo Yang,Da Bin Kim,Dian Yu,Akhil Nair,Akshat Rastogi,Nima Barri,Md Akibul Islam,Jane Howe,Cristina H Amon,Sjoerd Hoogland,Edward H. Sargent,Chandra Veer Singh,Tobin Filleter*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种新的应变工程技术，可在单层 MoS2 和 WS2-MoS2 异质结构中实现高幅度、高分辨率和稳定的应变，从而调谐其电子和光学特性，为开发新型光电器件和纳电子器件提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 目前的二维（2D）半导体材料制备技术难以在这些材料中实现高幅度（>1%）、空间分辨和稳定的应变，而高弹性和面内强度使得二维半导体材料成为应变调谐电子特性的理想选择，类似于硅电子学中的策略。

Method: 本研究采用双光子光刻技术在图案化衬底上制备了微米尺度的区域，并通过共形转移技术在单层 MoS2 上施加了高达 2.2% 的双轴拉伸应变，应变分辨率为 +/-0.12%。

Result: 本研究成功实现了在单层 MoS2 中施加高达 2.2% 的双轴拉伸应变，应变分辨率为 +/-0.12%，并且这种应变能够稳定数月，同时实现了约 0.4 eV 的带隙局域调谐，占其本征带隙的约 25%。此外，该方法也成功应用于双层 WS2-MoS2 异质结构。

Conclusion: 这项技术通过在单层 MoS2 中引入高达 2.2% 的双轴拉伸应变，实现了~0.4 eV 的带隙局域调谐，这相当于其本征带隙的约 25%。该技术还成功应用于双层 WS2-MoS2 异质结构，为二维半导体材料的应变工程开辟了新途径，有望支持宽光谱光电器件和具有可调谐电子特性的纳电子器件的开发。

Abstract: Crystalline two-dimensional (2D) semiconductors often combine high elasticity
and in-plane strength, making them ideal for strain-induced tuning of
electronic characteristics, akin to strategies used in silicon electronics.
However, current techniques fall short in achieving high-magnitude (>1%),
spatially resolved, and stable strain in these materials. Here, we apply
biaxial tensile strain up to 2.2%, with +/-0.12% resolution over
micrometre-scale regions in monolayer MoS2 via conformal transfer onto
patterned substrates fabricated using two-photon lithography. The induced
strain is stable for months and enables local band gap tuning of ~0.4 eV in
monolayer MoS2, ~25% of its intrinsic band gap. This represents a distinct
demonstration of simultaneous high-magnitude, spatially resolved, and sustained
strain in 2D monolayers. We further extend the approach to bilayer WS2-MoS2
heterostructures. This strain-engineering technique opens a new regime of
strain-enabled control in 2D semiconductors to support the development of
wide-spectrum optoelectronic devices and nanoelectronics with engineered
electronic landscapes.

</details>


### [478] [First-principles phonon physics using the Pheasy code](https://arxiv.org/abs/2508.01020)
*Changpeng Lin,Jian Han,Ben Xu,Nicola Marzari*

Main category: cond-mat.mtrl-sci

TL;DR: Pheasy是一个用户友好的程序，可以精确重建晶体固体的势能面，并通过机器学习算法提取力常数（IFC），用于计算声子相关性质。该程序解决了现有方法在处理高阶非谐性时的挑战，并旨在创建一个声子代码生态系统。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理超越三阶非谐性时面临挑战，因为高阶IFC的数量呈组合式爆炸增长。

Method: 该程序通过泰勒展开任意高阶来精确重建晶体固体的势能面，并利用先进的机器学习算法从力-位移数据集中高效准确地提取IFC。

Result: 该程序能够高效准确地提取IFC，并计算范围广泛的谐波和非谐声子相关性质。在三个典型示例中，所获得的IFC已成功应用于研究非谐晶格动力学和热传输。

Conclusion: Pheasy项目旨在创建一个连接不同声子模拟平台并向广大研究界提供访问的声子代码生态系统。

Abstract: Parameter-free calculations of lattice dynamics from first principles have
achieved significant progress in the past decades, with a wealth of
applications in thermodynamics, phase transitions, and transport properties of
materials. Current approaches to derive the interatomic force constants (IFCs)
of lattice potential become challenging and sometimes infeasible when going
beyond third-order anharmonicity, due to the combinatorial explosion in the
number of higher-order IFCs. In this work, we present a robust and
user-friendly program, Pheasy, which accurately reconstructs the potential
energy surface of crystalline solids via a Taylor expansion of arbitrarily high
order. Given force-displacement datasets, the program enables an efficient and
accurate extraction of IFCs using advanced machine-learning algorithms, and
further calculates a wide range of harmonic and anharmonic phonon related
properties. We show in three prototypical examples how the obtained IFCs have
been successfully applied to study anharmonic lattice dynamics and thermal
transport. Through these detailed benchmarks, we have also identified the
optimal approach for IFC extractions and offered general guidelines for
high-fidelity lattice-dynamical simulations, addressing the large uncertainties
in the IFCs extracted from existing various schemes. Overall, the Pheasy
project aims to create a phonon code ecosystem that connects diverse phonon
simulation platforms and offers access to the broad research community.

</details>


### [479] [Construction and Tuning of CALPHAD Models Using Machine-Learned Interatomic Potentials and Experimental Data: A Case Study of the Pt-W System](https://arxiv.org/abs/2508.01028)
*Courtney Kunselman,Siya Zhu,Doguhan Sariturk,Raymundo Arroyave*

Main category: cond-mat.mtrl-sci

TL;DR: PhaseForgePlus是一个开源工作流，通过结合机器学习势能和梯度优化，实现了高效、准确的CALPHAD模型生成，并在Pt-W系统上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高CALPHAD模型生成和参数拟合的效率和准确性，将机器学习势能和梯度优化方法应用于Pt-W系统。

Method: 使用机器学习势能整合到合金理论自动工具包中，生成具有物理依据的吉布斯能量描述，仅需微调即可生成精确的相图。利用Jansson导数方法结合实验观测，通过梯度信息优化程序可以高效稳健地确定这些调整。

Result: 通过Pt-W系统示例，展示了所提出方法可以生成精确的相图，且所需调整甚少。

Conclusion: 该工作介绍了PhaseForgePlus，一个计算高效、完全开源的物理信息CALPHAD模型生成和参数拟合工作流。

Abstract: This work introduces PhaseForgePlus -- a computationally efficient, fully
open-source workflow for physically-informed CALPHAD model generation and
parameter fitting. Using the Pt-W system as an example, we show that the
integration of Machine Learning Potentials into the Alloy Theoretic Automated
Toolkit can produce physically grounded Gibbs energy descriptions requiring
only slight adjustments to produce accurate phase diagrams. Employing the
Jansson derivative method in the context of experimental observations, such
adjustments can be efficiently and robustly determined through
gradient-informed optimization procedures.

</details>


### [480] [A Novel Methodology of Visualizing Orthorhombic Phase Uniformity in Ferroelectric Hf0.5Zr0.5O2 Devices Using Piezoresponse Force Microscopy](https://arxiv.org/abs/2508.01707)
*Wei-Cheng Peng,Hsien-Yang Liu,Cheng-Yu Yu,Artur Useinov,Tian-Li Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 铁电HZO薄膜是下一代器件的关键，其（O）相均匀性对性能至关重要。本研究提出了一种基于PFM的新方法，能够进行二维相图绘制和量化，结果显示9 nm薄膜具有最佳均匀性和最高的剩余极化。该方法操作简便，有望推动铁电薄膜研究。


<details>
  <summary>Details</summary>
Motivation: 铁电Hf0.5Zr0.5O2（HZO）薄膜因其CMOS兼容性和可扩展性，有望用于下一代存储器和逻辑器件。菱形（O）相的空间均匀性对于优化剩余极化等铁电特性至关重要。

Method: 提出了一种新颖的压电力显微镜（PFM）方法，用于对Hf0.5Zr0.5O2（HZO）薄膜（5 nm、9 nm和20 nm）的（O）相均匀性进行二维映射，并通过区分极化的（O）相区域与非极化的单斜（T/M）相来量化（O）相分布。

Result: 结果表明，9 nm薄膜表现出最均匀的（O）相和最高的剩余极化。

Conclusion: 该PFM方法能够全面地进行相表征，而无需复杂设备，从而拓宽了相分析的应用范围，并促进了用于存储器和逻辑器件的铁电薄膜研究。

Abstract: Ferroelectric Hf0.5Zr0.5O2 (HZO) thin films are promising for next-generation
memory and logic devices due to their CMOS compatibility and scalability. The
spatial uniformity of the orthorhombic (O) phase is crucial for optimizing
ferroelectric properties like remnant polarization. This work introduces a
novel piezoresponse force microscopy (PFM) approach for 2D mapping of O-phase
uniformity in HZO films (5 nm, 9 nm, and 20 nm), further quantifing O-phase
distribution by distinguishing polarized O-phase regions from non-polarized
tetragonal/monoclinic (T/M) phases. Our results reveal that the 9 nm film
exhibits the most uniform O-phase and highest remnant polarization. This
PFM-based method enables comprehensive phase characterization without requiring
complicated facilities, broadening access to phase analysis and advancing
ferroelectric thin-film research for memory and logic applications.

</details>


### [481] [Optimizing $α''$-Fe$_{16}$N$_2$ as permanent magnet via alloying](https://arxiv.org/abs/2508.01035)
*Bo Zhao,Ruiwen Xie,Imants Dirba,Lambert Alff,Oliver Gutfleisch,Hongbin Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: First-principles calculations show that Co, Mo, and W are promising alloying elements to improve Fe$_{16}$N$_2$ for permanent magnets, offering significant modification of magnetic anisotropy.


<details>
  <summary>Details</summary>
Motivation: To further optimize the properties of Fe$_{16}$N$_2$ for permanent magnet applications by investigating the effects of alloying elements.

Method: Systematic first-principles calculations were used to investigate the effects of 27 alloying elements on the intrinsic magnetic properties of Fe$_{16}$N$_2$. Thermodynamic stability was analyzed using formation energy and distance to the convex hull. Boltzmann-average intrinsic properties were calculated to identify promising candidates.

Result: 20 elements can be substituted into Fe$_{16}$N$_2$ without strong site-preference. All alloying elements reduce saturation magnetization, but magnetic anisotropy can be significantly modified. Co, Mo, and W were identified as the most promising candidates.

Conclusion: Co, Mo, and W are the most promising alloying elements for Fe$_{16}$N$_2$ permanent magnets.

Abstract: Based on systematic first-principles calculations, we investigate the effects
of 27 alloying elements on the intrinsic magnetic properties of Fe$_{16}$N$_2$,
in order to further optimize its properties for permanent magnet applications.
Analysis on the thermodynamic stabilities based on formation energy and
distance to the convex hull reveals that 20 elements can be substituted into
Fe$_{16}$N$_2$, where there is no strong site-preference upon doping. It is
observed that all alloying elements can essentially reduce the saturation
magnetization, whereas the magnetic anisotropy can be significantly modified.
In terms of the Boltzmann-average intrinsic properties, we identify 8 elements
as interesting candidates, with Co, Mo, and W as the most promising cases for
further experimental validations.

</details>


### [482] [A Crystallographic Metric for Continuous Quantification of Unit Cell Deformation](https://arxiv.org/abs/2508.01177)
*Shannon Bernier,Gregory Bassen,Matthew Brem,Davor Tolj,Quentin Simmons,Tyrel M. McQueen*

Main category: cond-mat.mtrl-sci

TL;DR: 提出立方偏差度量指标，用于量化单位晶胞畸变，可应用于材料相变、分类、压电性和超导性研究。


<details>
  <summary>Details</summary>
Motivation: 为了理解和解释相变，描述真实结构与假设的高对称性理想结构之间的偏差是一种强大的工具。

Method: 提出了一种名为立方偏差度量（cubic deviation metric）的新指标，用于量化单位晶胞相对于立方体的畸变程度。

Result: 该度量指标已成功应用于四个不同的实际材料系统案例研究：1）假褐铁矿的不连续结构相变；2）同源结构分类；3）六方材料中与结构相关的压电性；4）铜基材料中的超导材料设计。

Conclusion: 该立方偏差度量指标提供了一种新颖且有效的方法来量化单位晶胞相对于立方体的畸变程度，从而实现对不同几何形状的单位晶胞进行连续比较。

Abstract: Describing the deviation of a real structure from a hypothetical
higher-symmetry ideal can be a powerful tool to understand and interpret phase
transitions. Here we introduce a simple yet effective metric that quantifies
the degree of unit cell distortion relative to a cube, called the cubic
deviation metric. This enables continuous comparisons between unit cells of
different geometries. We demonstrate the potential of this tool with four
separate case study applications to real material systems: 1) discontinuous
structural phase transitions in pseudobrookites; 2) homological structure
classification; 3) structure-correlated piezoelectricity in hexagonal
materials; and 4) superconducting materials design in the cuprate family.
Although this metric does not replace detailed structural or group theory
analysis, it enables comparison across different compositional and structural
compound variants, even in the presence of disorder or absence of
group-subgroup correlation.

</details>


### [483] [Magnetism at the interface of $MoSe_2/V_2O_5$ heterostructures](https://arxiv.org/abs/2508.01214)
*Rohin Sharma,Diem Thi-Xuan Dang,Lilia M. Woods*

Main category: cond-mat.mtrl-sci

TL;DR: $MoSe_2/V_2O_5$ 异质结构中的界面磁性。


<details>
  <summary>Details</summary>
Motivation: 寻找可持续的纳米尺度磁态，以用于制造自旋电子学器件。

Method: 利用密度泛函理论模拟。

Result: 发现 $MoSe_2/V_2O_5$ 异质结构中存在铁磁序，即使单个组分是非磁性的，并研究了点缺陷对铁磁性的影响。

Conclusion: 通过研究电荷转移和自旋重组之间的平衡，可以在新型混合材料中实现界面磁性。

Abstract: Magnetism in doped transition metal dichalcogenide monolayers and van der
Waals interfaced materials have motivated the search for sustainable magnetic
states at the nanoscale with the prospect of building devices for spintronics
applications. In this study, we report the existence of magnetism in a
heterostructure made up of an $MoSe_2$ transition metal dichalcogenide
monolayer and a $V_2O_5$ substrate. Using density functional theory
simulations, we find that ferromagnetic ordering can be found in the
$MoSe_2/V_2O_5$ heterostructure even though the individual components are
nonmagnetic. By examining the electronic structure and magnetic properties of
this system we find how the occurring ferromagnetism evolves if the transition
metal dichalcogenide or the $V_2O_5$ substrate can host point defects. Our
study suggests that the balance between charge transfer and spin reorganization
can lead to interface magnetism in novel hybrid materials.

</details>


### [484] [Ferroelectric Epsilon-WO3 Nanoparticles and Its Bipolaron Driven Opto-electronic Properties at Room Temperature](https://arxiv.org/abs/2508.02598)
*Mohammad M. Rahaman,Jose Flores,Mohamed Y. Noor,Md Mohsinur R. Adnan,Alex Blackston,Enam Chowdhury,Roberto C. Myers,Michael Newburger,Pelagia-Irene Gouma*

Main category: cond-mat.mtrl-sci

TL;DR: 一种新型铁电材料epsilon-WO3在室温下表现出优异的铁电和光电性质，在光电领域具有广阔的应用前景。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在稳定在室温下不稳定的epsilon-WO3相，并探索其铁电和光电性质，以期在光电领域实现突破。

Method: 通过火焰喷雾热解法合成了可在室温下稳定的epsilon-WO3纳米粉末，并将其制成薄膜，通过压电响应力显微镜（PFM）和二次谐波（SHG）测量了其铁电和光电特性。

Result: 本研究成功在室温下稳定了epsilon-WO3相，并证明了其铁电性质，包括铁电滞后、畴结构和偶极子开关。此外，还观察到了二次谐波效应和由光学刺激引起的铁电极化响应，以及在室温下形成双极激子，并实现了铁色效应。

Conclusion: Epsilon-WO3是一种具有最简单结构的铁电材料，在室温下形成无自旋准粒子双极激子，并且其偶极子对光电信号有响应，在光电领域具有巨大潜力。

Abstract: A unique polymorph of binary tungsten trioxide, the epsilon phase of WO3, has
non-centrosymmetric ferroelectric structure, typically stable below -43 degree
C in bulk. We have stabilized the epsilon-WO3 at room temperature (RT) and
nanostructured powders via flame spray pyrolysis synthesis. These nanopowders
are drop cast into uniform thin films to enable RT measurement of ferroelectric
and optoelectronic properties. We report ferroelectric hysteresis, nanoscale
domains, and dipole switching measured via Piezo-response force microscopy
(PFM). The epsilon-WO3 films also display optical second harmonic generation
(SHG) and anticlockwise ferroelectric butterfly capacitance versus voltage
hysteresis, further demonstrating the ferroelectric nature of epsilon-WO3.
Remarkably, epsilon-WO3 shows ferroelectric polarization responses to optical
stimuli and form bipolaron at RT, a spin-zero quasiparticle previously found
only in cryogenic temperatures. The bipolaron formation and its interaction
with electro-optical stimuli results in a single layer solid-state blue
coloration, a ferrochromic effect. A mechanism of the ferrochromic effect is
discussed. In summary, epsilon-WO3 appears to be a ferroelectric with the
simplest structure, forming bosonic spin-zero bipolaron at RT, and it's dipoles
respond to opto-electrical signals; therefore, this material holds significant
promise for transforming the field of optoelectronics.

</details>


### [485] [Study of Optical Properties of MOCVD-Grown Rutile GeO2 Films](https://arxiv.org/abs/2508.01289)
*Imteaz Rahaman,Anthony Bolda,Botong Li,Hunter D. Ellis,Kai Fu*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过 MOCVD 在 r-TiO$_2$ 衬底上生长了 r-GeO$_2$ 薄膜，并通过多种光谱技术（CL、XPS、UV-Vis）研究了其光学性质，发现其具有宽带隙（~4.8 eV）和与晶畴尺寸相关的可见光发射，验证了其在电力电子和深紫外光电器件方面的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 金红石型二氧化锗 (r-GeO$_2$) 是一种有潜力应用于电力电子和深紫外光电器件的超宽带隙半导体，但其光学性质和发光行为有待深入研究。

Method: 本研究采用金属有机化学气相沉积 (MOCVD) 方法在 r-TiO$_2$ (001) 衬底上生长了金红石型二氧化锗 (r-GeO$_2$) 薄膜。通过阴极发光 (CL) 光谱、CL 映射和 X 射线光电子能谱 (XPS) 以及紫外-可见光透射光谱 (UV--Vis) 对薄膜进行了光学性质研究。

Result: 阴极发光 (CL) 光谱显示在 470 nm 和 520 nm 附近存在明显的宽可见光发射峰。CL 映射表明，发射强度在较大晶畴区域得到增强，揭示了畴尺寸与光学质量之间的相关性。XPS 结果确认了 Ge$^{4+}$ 氧化态，并通过价带和二次电子截止分析估算出带隙约为 4.75 eV。紫外-可见光透射测量显示在 250--260 nm 附近存在陡峭的吸收边，对应的光学带隙在 4.81--5.0 eV 范围内。

Conclusion: Rutile germanium dioxide (r-GeO$_2$) 具有高理论 Baliga 指数、p 型掺杂潜力以及良好的热电性能，是一种有前途的超宽带隙 (UWBG) 半导体。本研究通过 MOCVD 在 r-TiO$_2$ (001) 衬底上生长了 r-GeO$_2$ 薄膜，并进行了全面的光学研究。

Abstract: Rutile germanium dioxide (r-GeO$_2$) is a promising ultra-wide bandgap (UWBG)
semiconductor, offering a high theoretical Baliga figure of merit, potential
for p-type doping, and favorable thermal and electrical properties. In this
work, we present a comprehensive optical investigation of crystalline r-GeO$_2$
thin films grown on r-TiO$_2$ (001) substrates via metal-organic chemical vapor
deposition (MOCVD). Cathodoluminescence (CL) spectroscopy reveals broad visible
emissions with distinct peaks near 470~nm and 520~nm. CL mapping indicates
enhanced emission intensity in regions with larger crystalline domains,
highlighting the correlation between domain size and optical quality. X-ray
photoelectron spectroscopy (XPS) confirms the presence of Ge$^{4+}$ oxidation
state and provides a bandgap estimation of $\sim$4.75~eV based on valence band
and secondary electron cutoff analysis. UV--Vis transmittance measurements show
a sharp absorption edge near 250--260~nm, corresponding to an optical bandgap
in the range of 4.81--5.0~eV. These findings offer valuable insights into the
defect-related emission behavior and band-edge characteristics of r-GeO$_2$,
reinforcing its potential for future applications in power electronics and
deep-ultraviolet optoelectronic devices.

</details>


### [486] [Experimental evidence of disordered crystalline premixing in sputter-deposited Ni(V)/Al multilayers](https://arxiv.org/abs/2508.01484)
*Michael J Abere,Paul G. Kotula,Jonathan S. Paras,David P. Adams*

Main category: cond-mat.mtrl-sci

TL;DR: Ni(V)/Al多层膜界面存在一种特殊的FCC固溶体预混相，它在高温下能保持稳定，且其结构与之前的预测不同。


<details>
  <summary>Details</summary>
Motivation: 探究溅射沉积的Ni(V)/Al多层膜界面预混相的结构和性质，以及这种预混面对多层膜放热特性的影响。

Method: 通过扫描透射电子显微镜直接测量了Ni(V)/Al多层膜界面处无序面心立方（FCC）固溶体预混相的结构和性质，并进行了为期16小时、135°C的退火处理。

Result: Ni(V)/Al多层膜界面存在无序面心立方（FCC）固溶体预混相，其晶体结构与先前预测的非晶态界面不同。该FCC相在135°C退火16小时后仍保持其对称性，但晶格参数的变化表明其成分富含铝。

Conclusion: 该研究归因于电子对结晶熵的贡献，证明了Ni(V)/Al中存在结晶预混层。

Abstract: The sputter deposition of alternating layers of Ni(V) and Al forms a reactive
multilayer known to undergo self-propagating formation reactions when ignited.
The sequential deposition process leads to nm-scale premixing of reactants at
each included interface which ultimately affects multilayer exothermicity. This
work performs the direct measurement of a disordered face-centered cubic (FCC)
solid solution premixed phase at the interfaces of Ni(V)/Al multilayers via
scanning transmission electron microscopy. The crystallinity of the observed
phase differs from previously reported a priori predictions of an amorphous
interlayer. The disordered FCC phase retains its symmetry after annealing for
16 h at 135 C, but the lattice parameter shifts consistent with an Al-rich
composition. The existence of a crystalline premix in Ni(V)/Al is attributed to
the electronic contribution to the entropy of crystallization.

</details>


### [487] [Local interface effects modulate global charge order and optical properties of 1T-TaS$_2$/1H-WSe$_2$ heterostructures](https://arxiv.org/abs/2508.01512)
*Samra Husremović,Valerie S. McGraw,Medha Dandu,Lilia S. Xie,Sae Hee Ryu,Oscar Gonzalez,Shannon S. Fender,Madeline Van Winkle,Karen C. Bustillo,Takashi Taniguchi,Kenji Watanabe,Chris Jozwiak,Aaron Bostwick,Eli Rotenberg,Archana Raja,Katherine Inzani,D. Kwabena Bediako*

Main category: cond-mat.mtrl-sci

TL;DR: 通过构建1T-TaS$_2$/1H-WSe$_2$异质结构，可以同时调控CDW材料的电子相和半导体的光学性质，为设计光电器件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 1T-TaS$_2$的电荷密度波（CDW）特性具有信息存储潜力，因此控制和调控CDW状态至关重要。异质结构是调控CDW相变的有前景的方法。

Method: 通过系统地改变1T-TaS$_2$的厚度和其与1H-WSe$_2$的方位角对齐，研究了1T-TaS$_2$/1H-WSe$_2$异质结构的光学和电子特性。

Result: 固有莫尔应变和界面电荷转移会引入CDW无序并改变1T-TaS$_2$的CDW序化温度。层间对齐会影响1H-WSe$_2$的激子动力学。

Conclusion: 通过研究1T-TaS$_2$与1H-WSe$_2$的异质结构，我们发现可以通过调节层间相互作用来调控1T-TaS$_2$的电荷密度波（CDW）相变，并同时影响1H-WSe$_2$的激子动力学。

Abstract: 1T-TaS$_2$ is a layered charge density wave (CDW) crystal exhibiting sharp
phase transitions and associated resistance changes. These resistance steps
could be exploited for information storage, underscoring the importance of
controlling and tuning CDW states. Given the importance of out-of-plane
interactions in 1T-TaS$_2$, modulating interlayer interactions by
heterostructuring is a promising method for tailoring CDW phase transitions. In
this work, we investigate the optical and electronic properties of
heterostructures comprising 1T-TaS$_2$ and monolayer 1H-WSe$_2$. By
systematically varying the thickness of 1T-TaS$_2$ and its azimuthal alignment
with 1H-WSe$_2$, we find that intrinsic moir\'e strain and interfacial charge
transfer introduce CDW disorder in 1T-TaS$_2$ and modify the CDW ordering
temperature. Furthermore, our studies reveal that the interlayer alignment
impacts the exciton dynamics in 1H-WSe$_2$, indicating that heterostructuring
can concurrently tailor the electronic phases in 1T-TaS$_2$ and the optical
properties of 1H-WSe$_2$. This work presents a promising approach for
engineering optoelectronic behavior of heterostructures that integrate CDW
materials and semiconductors.

</details>


### [488] [Thermal transport and the impact of hydrogen adsorption in Linde Type A zeolitic imidazolate frameworks](https://arxiv.org/abs/2508.01624)
*Hyunseok Oh,Taeyong Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 通过分子动力学模拟研究ZIFs的热传导特性，发现其热导率异常低且与温度的关系也不同于许多晶体材料。这是因为ZIFs的晶胞结构复杂，包含大量金属中心，导致强烈的非谐性，使得热量主要由自由程与波长可比的声子携带，类似于非晶态固体的扩散子。此外，吸附的氢分子能够通过气体-气体或气体-骨架相互作用增加ZIFs的热导率。


<details>
  <summary>Details</summary>
Motivation: 尽管人们进行了大量研究，但由于对控制导热的机制理解不足，许多MOFs中分子渗透对热传导的影响尚不清楚

Method: 分子动力学模拟

Result: ZIFs的吸附氢分子提高了ZIFs的热导率，这主要归因于气体-气体或气体-骨架相互作用产生的额外振动模式

Conclusion: 通过气体渗透调控热传导，增进了对MOFs中热传导的理解

Abstract: Thermal transport in metal-organic frameworks (MOFs) is of practical interest
in diverse applications such as gas storage and separations, since insufficient
heat dissipation can lead to detrimental effects. Despite investigations,
influence of molecular infiltration on the heat transport remains unclear in
many of MOFs due to poor understanding of mechanisms governing heat
conductions. Here, we report molecular dynamics investigations of thermal
transport properties in zeolitic imidazolate frameworks (ZIFs). We investigated
Linde Type A topological ZIFs (ZIF-lta) exhibiting exceptionally low thermal
conductivity with unusual trend of temperature dependence deviating from many
crystalline materials, despite long-range crystalline order in them. We
demonstrate that heat is predominantly carried by phonons with mean free paths
comparable to their wavelengths, analogous to diffusons in amorphous solids
owing to strong anharmonicity caused by complexity of unit cell consisting of a
large number of metal centers. We further show that adsorbed hydrogen molecules
increase thermal conductivity of ZIFs, mainly contributed by additional
vibrational modes, as a result of gas-gas or gas-framework interactions. Our
work advances fundamental understanding into the thermal transport in MOFs and
suggests a means to engineer heat conduction via gas infiltrations.

</details>


### [489] [A Non-Local Orientation Field Phase-Field Model for Misorientation- and Inclination- Dependent Grain Boundaries](https://arxiv.org/abs/2508.01688)
*Xiao Han,Axel van de Walle*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种新的相场模型，用于在模拟中考虑晶界各向异性，该模型通过方向场的非局部函数和优化的采样方法简化了过程，并成功验证了其在模拟晶粒生长和形态方面的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在相场模拟中更精确地模拟晶界（GB）的各向异性，并简化对晶界能量各向异性的调优过程，避免复杂的拟合程序。

Method: 该模型使用单个方向场，并结合了通过在晶界附近优化位置对方向场进行采样获得的信息，包括晶粒错取向和倾斜信息。该方法包括一个显式的晶界各向异性函数，用于控制晶界能量随错取向和倾斜的变化。

Result: 该模型通过重现线性晶粒生长速率、具有变化的错取向和各向异性系数的Wulff形状，以及三节点连接处的解析平衡二面角，得到了验证。多晶模拟展示了晶粒生长、合并、三节点连接行为以及各向异性对晶粒形态的影响。

Conclusion: 该模型通过包含方向场的非局部函数来扩展标准的偏微分方程表述，从而在相场模拟中结合晶界（GB）的各向异性。

Abstract: We propose to incorporate grain boundary (GB) anisotropy in phase-field
modeling by extending the standard partial differential equations formulation
to include a non-local functional of an orientation field. Regardless of the
number of grains in the simulation, the model uses a single orientation field
and incorporates grain misorientation and inclination information obtained from
sampling the orientation field at optimized locations in the vicinity of the
grain boundary. The formalism enables simple and precise tuning of GB energy
anisotropy while avoiding an extensive fitting procedure. The functional
includes an explicit GB anisotropy function to control the GB energy as a
function of both misorientation and inclination. The model is validated by
reproducing the linear grain growth rate, Wulff shapes with varying
misorientations and anisotropic coefficients, and analytical equilibrium
dihedral angles at triple junctions. Polycrystalline simulations demonstrate
grain growth, coalescence, triple junction behavior, and the influence of
anisotropy on grain morphology.

</details>


### [490] [Photoinduced Low Spin to High Spin Transition in a [2x2] Fe(II) Metallogrid: Diode Laser-Pumped Photocrystallography at the P11 Beamline in PETRA III, DESY](https://arxiv.org/abs/2508.01734)
*Krishnayan Basuroy,Jose de Jesus Velazquez-Garcia,Sreeju Sreekantan Nair Lalithambika,Argha Barman,Torben Reuss,Guillaume Pompidor,Alexander Grebentsov,Önder Akçaalan,Simone Techert*

Main category: cond-mat.mtrl-sci

TL;DR: 研究人员首次在同步辐射光源上使用紧凑型二极管激光器成功诱导了Fe(II)金属网格配合物的光诱导自旋交叉转变，并通过X射线衍射证实了结构变化，展示了该激光器系统在光晶体学实验中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探索光诱导自旋交叉（SCO）转变在分子晶体中的行为，并展示一种用于同步辐射泵浦-探测光晶体学实验的紧凑型二极管激光器系统的效用。

Method: 使用3B类二极管激光器在受控辐照条件下诱导转变，并通过单晶X射线衍射（SCXRD）测量进行结构表征，揭示了平均Fe-N距离的显著变化，这与SCO行为一致。

Result: 成功实现了Fe(II)金属网格配合物的光诱导SCO转变，并通过SCXRD证实了结构变化，证明了该紧凑型激光器系统在同步辐射光晶体学实验中的可行性。

Conclusion: 该研究报告了一个[2x2] Fe(II)金属网格配合物在光照下从2HS-2LS态转变为3HS-1LS态的自旋交叉（SCO）转变，并首次在PETRA III同步辐射光源的P11线束上使用静态光晶体学对分子晶体进行了研究。

Abstract: We report on the photoinduced spin crossover (SCO) transition from a 2HS-2LS
to a 3HS-1LS state in a [2x2] Fe(II) metallogrid complex using molecular
crystals with static photocrystallography at a first ever attempt in the
beamline P11 of the PETRA III synchrotron, DESY. A class 3B diode laser was
used to induce the transition under controlled irradiation conditions.
Structural characterization was achieved through single-crystal X-ray
diffraction (SCXRD) measurements post-irradiation, revealing significant
changes in average Fe-N distances, consistent with SCO behavior. Our
experimental setup enables precise alignment necessary for photo-excitation
using a class 3B diode laser along with a compact focusing optics. The longest
dimension of the combined setup of the diode head and the focusing optics is
not more than 32cm. The setup showcasing the utility of a compact diode laser
system which can even be conveniently used in synchrotron-based pump-probe
photocrystallography experiments for a wide range of molecular crystals.

</details>


### [491] [Optical properties of emeraldine salt polymers from ab initio calculations: comparison with recent experimental data](https://arxiv.org/abs/2508.01757)
*Renato Colle,Pietro Parruccini,Andrea Benassi,Carlo Cavazzoni*

Main category: cond-mat.mtrl-sci

TL;DR: Calculated optical properties of emeraldine salt conducting polymer using DFT match experimental results.


<details>
  <summary>Details</summary>
Motivation: To calculate and analyze the optical properties of emeraldine salt conducting polymer in its crystalline three-dimensional polaronic structure.

Method: Kohn-Sham DFT electronic wavefunctions and energies were used to calculate the absorption coefficient, transverse dielectric function, optical conductivity, and reflectance. Intra-band transitions were included via a Drude-like term.

Result: The study successfully calculated optical properties like absorption coefficient, dielectric function, optical conductivity, and reflectance, which were validated against experimental data.

Conclusion: The calculated optical spectra of emeraldine salt conducting polymer show satisfactory agreement with recently measured optical properties and absorption spectra, indicating the validity of the approach.

Abstract: We present absorption coefficient {\alpha}({\omega}), transverse dielectric
function {\epsilon}({\omega}), optical conductivity {\sigma}({\omega}), and
reflectance R({\omega}) calculated for an emeraldine salt conducting polymer in
its crystalline three-dimensional polaronic structure. We utilize Kohn-Sham DFT
electronic wavefunctions and energies implemented in the expression of the
macroscopic transverse dielectric function in the framework of the band theory
without the electron-hole interaction. Contributions of intra-band transitions
are taken into account by adding a Drude-like term to the dielectric function
calculated ab-initio. Comparison with optical properties, recently measured on
high-quality emeraldine salts (Nature 441(2006)65-68), and with optical
absorption spectra, recorded on other emeraldine salts, is very satisfactory.
The calculated spectra are discussed in terms of energy-band structure, density
of states, inter- and intra-band transitions and transverse dielectric
function.

</details>


### [492] [Deep Learning-Driven Prediction of Microstructure Evolution via Latent Space Interpolation](https://arxiv.org/abs/2508.01822)
*Sachin Gaikwad,Thejas Kasilingam,Owais Ahmad,Rajdip Mukherjee,Somnath Bhowmick*

Main category: cond-mat.mtrl-sci

TL;DR: 通过结合CVAE、三次样条插值和SLERP的深度学习框架，显著加速了相位场模拟在材料微观结构演化预测中的计算效率，实现了高精度的结果，可用于加速材料设计。


<details>
  <summary>Details</summary>
Motivation: 相位场模型能精确模拟微观结构演化，但求解复杂微分方程的计算成本高昂。本研究旨在通过新颖的深度学习框架显著加速此过程。

Method: 该方法利用条件变分自编码器（CVAE）结合三次样条插值和球面线性插值（SLERP）来实现。

Result: 预测的微观结构在视觉和统计上与相位场模拟高度相似。

Conclusion: 该框架为微观结构演化提供了一个可扩展且高效的代理模型，能够加速材料设计和成分优化。

Abstract: Phase-field models accurately simulate microstructure evolution, but their
dependence on solving complex differential equations makes them computationally
expensive. This work achieves a significant acceleration via a novel deep
learning-based framework, utilizing a Conditional Variational Autoencoder
(CVAE) coupled with Cubic Spline Interpolation and Spherical Linear
Interpolation (SLERP). We demonstrate the method for binary spinodal
decomposition by predicting microstructure evolution for intermediate alloy
compositions from a limited set of training compositions. First, using
microstructures from phase-field simulations of binary spinodal decomposition,
we train the CVAE, which learns compact latent representations that encode
essential morphological features. Next, we use cubic spline interpolation in
the latent space to predict microstructures for any unknown composition.
Finally, SLERP ensures smooth morphological evolution with time that closely
resembles coarsening. The predicted microstructures exhibit high visual and
statistical similarity to phase-field simulations. This framework offers a
scalable and efficient surrogate model for microstructure evolution, enabling
accelerated materials design and composition optimization.

</details>


### [493] [Mesoscale variations of chemical and electronic landscape on the surface of Weyl semimetal Co$_3$Sn$_2$S$_2$ visualized by ARPES and XPS](https://arxiv.org/abs/2508.01826)
*Sudheer Anand Sreedhar,Matthew Staab,Mingkun Chen,Robert Prater,Zihao Shen,Giuseppina Conti,Ittai Sidilkover,Zhenghong Wu,Eli Rotenberg,Aaron Bostwick,Chris Jozwiak,Hadas Soifer,Slavomir Nemsak,Sergey Y. Savrasov,Vsevolod Ivanov,Valentin Taufour,Inna M. Vishik*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了磁性外尔半金属Co3Sn2S2的表面性质，发现了不同于纯硫或锡端面的中间区域，并利用机器学习分析了表面化学和电子结构。


<details>
  <summary>Details</summary>
Motivation: 已成功区分了磁性外尔半金属Co3Sn2S2中多种晶体端面所展示的不同拓扑和平凡表面态。然而，由于这些表面存在高度的空间异质性和点缺陷，因此纯端面模型被认为是不充分的。

Method: 利用光电子能谱测量和第一性原理计算核心能级，研究了表面化学和表面电子结构。

Result: 确定了一个具有不同于硫和锡端面特性的中间区域，并证明该区域的光谱特征与具有不同密度表面锡空位的无序锡端面相关。

Conclusion: 通过结合算法和机器学习分析光电子能谱数据，可以提取识别特征，对空间区域进行分类，并将局部化学性质与局部电子结构相关联。

Abstract: The multiple crystalline terminations in magnetic Weyl semimetal
Co$_3$Sn$_2$S$_2$ display distinct topological and trivial surface states,
which have successfully been distinguished experimentally. However, a model of
pure terminations is known to be inadequate because these surfaces exhibit a
high degree of spatial heterogeneity and point disorder. Here we perform a
spectromicroscopy study of the surface chemistry and surface electronic
structure using photoemission measurements in combination with first-principles
calculations of core levels. We identify an intermediate region with properties
distinct from both the sulfur and tin terminations, and demonstrate that the
spectral features in this region can be associated with a disordered tin
termination with a varying density of surface tin-vacancies. Finally, we show
how a combination of algorithmic and machine learning analysis of photoemission
data can be used to extract identifying features, classify spatial regions, and
correlate local chemistry with local electronic structure.

</details>


### [494] [Focused Ion Beam patterning of MnSb(1-101) based spintronic devcies](https://arxiv.org/abs/2508.01838)
*Stuart N. Holmes,Jonathan Gough,Ethan Dommett,Gavin R. Bell*

Main category: cond-mat.mtrl-sci

TL;DR: 利用 FIB 技术对 MnSb 器件进行图案化处理，研究其磁性与低温输运特性。结果表明，FIB 引入的无序会影响磁电阻和反常霍尔效应，且对数 B 依赖性受损伤影响。该技术可用于未来自旋电子器件开发。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用 FIB 技术对铁磁性 MnSb 器件进行图案化处理，以调控其磁性和输运特性，并探索其在自旋电子器件开发中的应用潜力。

Method: 通过在 30 keV 下使用 Ga 聚焦离子束 (FIB) 系统对铁磁性 MnSb 器件进行图案化处理，并进行低温输运测量，包括纵向电阻率和反常霍尔效应测量来研究其磁性。

Result: FIB 图案化会引入无序，影响磁电阻和反常霍尔效应。反常霍尔效应贡献对无序敏感，在更高剂量下减小。电阻率在磁化饱和后表现出对数 B 依赖性，并受损伤均匀性影响。

Conclusion: 使用 Ga 聚焦离子束 FIB 技术对铁磁性 MnSb 器件进行图案化处理，研究了其低温输运特性。FIB 图案化会引入无序，这通过纵向电阻率和霍尔电导率中的反常霍尔效应贡献来量化。研究发现，FIB 剂量会影响磁电阻和反常霍尔效应信号，并且反常霍尔效应贡献对无序水平敏感，在更高剂量下会减小到零。电阻率在磁化饱和后表现出对数 B 依赖性，并且受损伤均匀性影响。该研究为未来自旋电子器件开发提供了有用的材料和图案化技术。

Abstract: Low temperature transport measurements are presented of ferromagnetic MnSb
devices with the magnetic properties patterned using a Ga focused ion beam FIB
system at 30 keV. FIB patterning introduces disorder and this is quantified in
this paper through measurements of the longitudinal resistivity and the
anomalous Hall effect contribution to the Hall conductivity. The MnSb
structural phase is the niccolite phase with a surface state in addition to
bulk states. FIB doses up to 1E16 Ga ions per square cm reduces the anisotropic
magnetoresistance signal but increases the size of the anomalous Hall effect
signal in out of plane magnetic fields, B. The anomalous Hall effect
contribution to the Hall conductivity is e squared divided by h in the
undamaged devices, where e is the electronic charge and h is Plancks constant.
This quantity is sensitive to the level of disorder induced by the Ga ion beam,
reducing to zero at dose levels greater than 1E16 Ga ions per square cm. The
resistivity shows a logarithmic B dependence after the magnetization has
saturated with the low field anisotropic magnetoresistance contribution of 0.12
percent. The conductivity change is e squared divided by h in the magnetic
field range of logarithmic B behavior. The resistivity shows a reduced fit to a
logarithmic B dependence at high FIB dose levels and is dependent on the damage
uniformity. Patterning nanostructured magnetic behavior in MnSb, with
compatibility to altermagnetic materials, in particular the niccolite phase of
CrSb and non trivial Berry phase contributions to transport make this
ferromagnetic material and patterning technique useful for future spintronic
device development.

</details>


### [495] [Reducing critical current for spin-transfer-torque-induced magnetization reversal in CPP-GMR devices: effect of low damping and enhanced spin scattering asymmetry in $Co_2FeGa_{0.5}Ge_{0.5}$ Heusler alloy](https://arxiv.org/abs/2508.02101)
*Vineet Barwal,Hirofumi Suto,Yuya Sakuraba*

Main category: cond-mat.mtrl-sci

TL;DR: CFGG合金和CoFe/CFGG双层结构在STT基自旋电子器件中表现出优越性能，可显著降低操作电流并提高稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究低阻尼常数（α）和高自旋极化率（P）的CFGG合金对STT器件操作电流的影响，以及CoFe/CFGG双层SIL的自旋注入效率。

Method: 通过研究低阻尼常数和高自旋极化率的Co2FeGa0.5Ge0.5（CFGG）赫斯勒合金在电流垂直平面巨磁阻器件中的STT诱导磁化反转操作电流效应，并分析了由CoFe和薄CFGG层组成的双层SIL的自旋散射不对称性。

Result: 与使用NiFe作为FL的器件相比，使用CFGG作为FL的器件在操作电流上实现了显著降低。使用CoFe/CFGG-SIL的双层SIL器件表现出最低的临界电流，STT效率得到增强，并且器件间的STT效率分布更小。

Conclusion: CFGG合金和CoFe/CFGG双层结构在高效稳定的STT基自旋电子器件开发中具有关键潜力。

Abstract: Spin-transfer torque (STT) in magnetoresistance devices has enabled key
applications such as STT-magnetoresistive random access memory, spin torque
oscillators, and energy-assisted magnetic recording. In the device structures,
where a free layer (FL) magnetization is manipulated by spin injection from a
spin injection layer (SIL), the critical current density required for operation
is directly proportional to the damping ($\alpha$) constant of FL and inversely
proportional to the STT efficiency, which depends on the spin polarization
($P$) of the materials. Here, we investigate the effect of low $\alpha$ and
high $P$ of $Co_2FeGa_{0.5}Ge_{0.5}$(CFGG) Heusler alloy on the operation
current required for STT-induced magnetization reversal in current
perpendicular-to-plane giant magnetoresistance devices. Devices with CFGG as a
FL material achieved a large reduction in the operation current, as compared to
those with conventional NiFe-FL owing to the very low $\alpha$ of CFGG,
demonstrating the advantage of CFGG as a FL material. As the advantage of high
spin polarization CFGG for SIL, we analyzed the effect of bilayer SIL
consisting of CoFe and thin CFGG layers, focusing on utilizing the spin
scattering asymmetry at the CoFe/CFGG interface. Devices with the CoFe/CFGG-SIL
exhibited the lowest critical current, demonstrating enhanced STT efficiency.
In addition, the correlation of STT efficiency with magnetoresistance ratio
were comprehensively investigated, showing that device-to-device distribution
in STT-efficiency was smaller in CoFe/CFGG-SIL. These findings highlight the
potential of CFGG Heusler alloy and CoFe/CFGG bilayer structures as key
components for the development of efficient and stable STT-based spintronic
devices.

</details>


### [496] [Intrinsic physical properties of flexible van der Waals semiconductor InSe](https://arxiv.org/abs/2508.02142)
*Jacob Svane,Kim-Khuong Huynh,Yong P. Chen,Bo Brummerstedt Iversen*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究成功利用旅行溶剂浮区法制备出高质量、接近本征极限的InSe单晶，解决了长期存在的合成难题，为InSe的基础研究和器件开发提供了关键材料。


<details>
  <summary>Details</summary>
Motivation: InSe作为一种具有机械柔韧性、高电子迁移率和非平庸电子结构的范德华半导体，在基础研究和器件开发方面具有吸引力。然而，相纯、本征InSe晶体的成核和生长需要严格的热力学条件，因此一直难以实现。现有的合成方法会产生多相微晶聚集体或不受控制的富In、重电子掺杂的InSe，导致报道的物理性质差异巨大。

Method: 利用旅行溶知浮区法（TSFZ）进行InSe单晶的制备。

Result: 制备出的TSFZ-InSe单晶在电、热和热电输运测量中表现出接近本征极限的特性，成为该材料未来研究的基准。

Conclusion: 通过旅行溶剂浮区法（TSFZ）成功制备了高质量、厘米尺寸的InSe单晶，解决了InSe的相纯性和本征性合成难题，为未来研究InSe奠定了基础。

Abstract: InSe is a van der Waals semiconductor in which mechanical flexibility, high
electronic mobility, and non-trivial electronic structures converge, making it
an attractive platform for both intriguing fundamental studies and promising
device developments. However, the nucleation and growth of phase-pure,
intrinsic InSe crystals require stringent thermodynamical conditions, and have
therefore remained elusive. Since InSe melts incongruently, the widely used
synthesis methods based on cooling of a 1:1 In-Se mixture will produce either
aggregates of multiphase crystallites or uncontrolled In-rich, heavily
electron-doped InSe. This fundamental thermodynamic constraint provides a
compelling explanation for the large discrepancies observed in the reported
physical properties of InSe. We overcome these limitations by utilizing the
traveling solvent floating zone (TSFZ) method to produce high quality,
centimeter-size InSe single crystals. Electrical, thermal, and thermoelectric
transport measurements demonstrate that TSFZ-InSe single crystals closely
approach the intrinsic limit, establishing it as a benchmark material for the
future studies of this important material.

</details>


### [497] [Emerging electro-optic molecular crystals for optoelectronic integration](https://arxiv.org/abs/2508.02163)
*Keishi Sunami,Sachio Horiuchi,Yoriko Sonoda,Naomi Fujiki,Toshiki Higashino,Yuki Atsumi,Shoji Ishibashi,Jun'ya Tsutsumi*

Main category: cond-mat.mtrl-sci

TL;DR: 新型EO材料NDPA及其衍生物在硅光子学中展现出优异性能，满足了实际应用需求。


<details>
  <summary>Details</summary>
Motivation: 为了实现超快、低功耗和紧凑的光子器件，需要将硅光子学与电光（EO）材料集成，但现有材料无法同时满足高EO性能、工艺兼容性和热稳定性。

Method: 通过材料筛选和晶体习性预测，发现了4-(4'-硝基苯偶氮)二苯胺（NDPA）及其衍生物，并通过熔体毛细管作用将它们结晶成高质量的取向薄膜和超细硅槽填充物。

Result: 所提出的NDPA材料展现出优于传统铌酸锂的EO性能，与最先进的EO聚合物相当，并在393 K下保持了超过1000小时的优异热稳定性。

Conclusion: 这项工作提出的新型非线性光学分子晶体NDPA及其衍生物，满足了高性能、工艺兼容性和热稳定性要求，是硅基有机混合光调制器的有希望的候选者，为可扩展的高性能光电子技术开辟了道路。

Abstract: The rapid advancement of communication technology necessitates the
development of hybrid optical modulators that integrate silicon photonics with
electro-optic (EO) materials to enable ultrafast, low-power, and compact
photonic devices. However, no existing material simultaneously meets the
requirements for high EO performance, process compatibility, and thermal
stability, which are essential for practical optoelectronic integration. Here,
we present 4-(4'-nitrophenylazo)diphenylamine (NDPA) and its derivative, novel
nonlinear optical molecular crystals discovered through materials screening
incorporating crystal habit prediction. They demonstrate crystallization into
high-quality aligned thin films and ultrafine silicon slot fillings through the
capillary action of melts. The resulting EO performance much exceed that of
conventional lithium niobate and are comparable to state-of-the-art EO
polymers, with excellent thermal stability maintained for over 1000 hours at
393 K. The present EO materials satisfying all the requirements above are
promising candidates for silicon-organic hybrid optical modulators, opening a
significant step toward scalable and high-performance optoelectronic
technologies.

</details>


### [498] [Orientational Effects in the Low Pair Continuum of Aluminium](https://arxiv.org/abs/2508.02251)
*Thomas Gawne,Zhandos A Moldabekov,Oliver S Humphries,Motoaki Nakatsutsumi,Sebastian Schwalbe,Jan Vorberger,Ulf Zastrau,Tobias Dornheim,Thomas R Preston*

Main category: cond-mat.mtrl-sci

TL;DR: TDDFT与XTS实验在多晶铝的动力结构因子上进行了比较，发现考虑取向平均和晶格效应对于准确模拟至关重要。


<details>
  <summary>Details</summary>
Motivation: 比较TDDFT在对流体区域的预测与XTS测量，并评估晶格效应对模拟多晶铝动力结构因子（DSF）的重要性。

Method: 将时域密度泛函理论（TDDFT）在对流体区域的预测与欧洲X射线自由电子激光器（European XFEL）收集的超高分辨率X射线汤姆逊散射（XTS）测量进行比较。

Result: TDDFT预测的DSF表现出强烈的各向异性，在考虑了q模糊后仍然存在。实验光谱具有足够的分辨率和信噪比来区分这些取向依赖性，并严格观察到多晶样品取向平均。在考虑取向平均后，TDDFT能够充分复制实验光谱。与Jellium的预测相比，该模型证明了在模拟多晶样品的光谱时考虑晶格效应的重要性。

Conclusion: TDDFT能够充分复制实验光谱，但需要考虑取向平均和晶格效应。

Abstract: We compare the predictions of the dynamic structure factor (DSF) of ambient
polycrystalline aluminium from time-dependent density functional theory (TDDFT)
in the pair continuum regime to recent ultrahigh resolution x-ray Thomson
scattering measurements, collected at the European XFEL. TDDFT predicts strong
anisotropy in the DSF at the wavenumber examined here, even with $q$-blurring
accounted for. The experimental spectrum has more than sufficient resolution
and signal-to-noise levels to resolve these orientation dependencies, and
therefore the orientational averaging of the polycrystalline sample is observed
rigorously. Once the orientation averaging is accounted for, TDDFT is able to
reproduce the experimental spectrum adequately. Finally, comparisons of
predicted DSFs from jellium to experiment demonstrates the importance of
accounting for lattice effects in modelling the spectrum from a polycrystal.

</details>


### [499] [Cavity-QED-controlled two-dimensional Moiré Excitons without twisting](https://arxiv.org/abs/2508.02388)
*Francesco Troisi,Hannes Hübener,Angel Rubio,Simone Latini*

Main category: cond-mat.mtrl-sci

TL;DR: All-optical Moir'e-like exciton confinement can be achieved using spatially periodic optical cavities. This method utilizes quantum electro-dynamics to describe the coupling of excitons and photons, revealing that optical confinement emulates Moir'e physics in classical cavities and modifies excitonic properties in dark cavities due to quantum fluctuations and interactions.


<details>
  <summary>Details</summary>
Motivation: We propose an all-optical Moir'e-like exciton confinement by means of spatially periodic optical cavities. Such periodic photonic structures can control the material properties by coupling the matter excitations to the confined photons and their quantum fluctuations.

Method: We develop a low energy non-perturbative quantum electro-dynamical description of strongly coupled excitons and photons at finite momentum transfer.

Result: In the classical limit of a laser driven cavity, the induced optical confinement directly emulates Moir'e physics. In a dark cavity, the quantum fluctuations of light generate a sizable renormalization of the excitonic bands and effective mass due to long-range cavity-mediated exciton-exciton interactions.

Conclusion: Spatial structures cavities are a promising direction for cavity material engineering.

Abstract: We propose an all-optical Moir\'e-like exciton confinement by means of
spatially periodic optical cavities. Such periodic photonic structures can
control the material properties by coupling the matter excitations to the
confined photons and their quantum fluctuations. We develop a low energy
non-perturbative quantum electro-dynamical description of strongly coupled
excitons and photons at finite momentum transfer. We find that in the classical
limit of a laser driven cavity the induced optical confinement directly
emulates Moir\'e physics. In a dark cavity instead, the sole presence of
quantum fluctuations of light generates a sizable renormalization of the
excitonic bands and effective mass. We attribute these effects to long-range
cavity-mediated exciton-exciton interactions which can only be captured in a
non-perturbative treatment. With these findings we propose spatially structured
cavities as a promising avenue for cavity material engineering.

</details>


### [500] [Avalanche Dynamics in Stick-Slip Cutting of Molybdenum Disulfide](https://arxiv.org/abs/2508.02394)
*Pawel Koczanowski,Paolo Nicolini,Hesam Khaksar,Enrico Gnecco*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用AFM和分子动力学模拟，发现二硫化钼在纳米磨损中存在雪崩动力学现象，并揭示了其原子尺度的损伤机制和能量耗散途径，为纳米加工提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究多层二硫化钼在纳米尺度下的磨损机制，特别关注由摩擦引起的损伤过程，为理解层状固体中的摩擦和磨损物理机制提供新的视角，并为范德华材料的精密加工提供理论依据。

Method: 本研究通过弹性驱动尖锐的金刚石探针，在足以引起面内断裂的法向载荷下，研究了多层二硫化钼的纳米尺度磨损。利用原子力显微镜（AFM）表征了摩擦和产生的磨损结构，并结合分子动力学模拟来揭示原子尺度的磨损过程。

Result: 研究发现，多层二硫化钼在纳米尺度磨损中存在粘滑现象，驱动了MoS2薄片的渐进式剥落。在高法向力下，滑移阶段表现出典型的雪崩动力学特征，这是首次在纳米尺度上观察到。分子动力学模拟证实了实验结果，并揭示了局部非晶化、层曲变和不同的耗散通道等原子尺度细节。研究还指出，只有五分之一的输入能量被用于对MoS2表面造成不可逆的损伤。

Conclusion: 本研究揭示了多层二硫化钼在纳米尺度下的磨损机制，特别是与摩擦相关的雪崩动力学现象，并提供了在范德华材料中进行精密切割和纳米加工的框架，这对于亚微米尺度下下一代器件的制造具有重要意义。

Abstract: We have investigated nanoscale wear on multilayered MoS2, the flagship
transition metal dichalcogenide, by elastically driving sharp diamond tips
under normal loads sufficient to induce in-plane fracture. The accompanying
friction and the resulting wear structures were first characterized by atomic
force microscopy (AFM), revealing a stick-slip regime that drives progressive
exfoliation of MoS2 chips. At high normal forces, the slip phase displays
hallmark signatures of avalanche dynamics, observed for the first time at the
nanoscale, evidenced by a Generalized Extreme Value distribution of friction
force drops. The AFM characterization is corroborated by molecular dynamics
simulations, which reproduce experimental trends and uncover atomistic details
of the wear process, including local amorphization, layer curving, and the
involvement of distinct dissipative channels. Notably, it appears that only
one-fifth of the energy inputted into the system is used to damage the MoS2
surface irreversibly. These results offer new insight into the physical
mechanisms governing friction and wear in layered solids and provide a
framework for precision cutting and nanomachining in van der Waals materials,
relevant to next-generation devices at sub-micrometer scales.

</details>


### [501] [Efficient spin-pumping and spin-to-charge conversion in epitaxial Mn$_3$Sn(0001) noncollinear antiferromagnetic films](https://arxiv.org/abs/2508.02415)
*Surya N. Panda,Ning Mao,Nikolai Peshcherenko,Xiaolong Feng,Yang Zhang,Anastasios Markou,Claudia Felser,Edouard Lesne*

Main category: cond-mat.mtrl-sci

TL;DR: Mn3Sn 薄膜在自旋流产生和自旋-电荷转换方面表现出优异性能，在自旋电子学领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了推进下一代自旋电子技术，需要能够高效地提供和相互转换自旋流和电荷流，并克服传统铁磁体和重金属局限性的材料。

Method: 通过系统研究外延 (0001) 取向的 Mn3Sn 薄膜中的自旋流产生和自旋-电荷转换现象，并结合第一性原理计算进行讨论。

Result: 在室温下，Mn3Sn 薄膜表现出 0.9% 的自旋霍尔角和 44.4~($	extlessmath>	extlessmi>$	extless/mi>$	extless/math>	extless/mi>$	extless/mi>$	extless/math>$	extless/mi>$	extless/mi>$	extless/math>/e) $	extlessmath>	extlessmi>$	extless/mi>$	extless/math>	extless/mi>$	extless/mi>$	extless/math>	extless/mi>$	extless/mi>$	extless/math>$	extless/mi>$	extless/mi>$	extless/math>	extless/mi>$	extless/mi>$	extless/math>	extless/mi>$	extless/mi>$	extless/math>/cm$^{-1}$ 的近乎各向同性的面内自旋霍尔电导率。在 Mn3Sn(0001)/Ni81Fe19 异质结构中，观察到 28.52 nm$^{-2}$ 的高自旋混合电导率和约 72% 的界面自旋透明度。此外，发现 Mn3Sn(0001) 外延薄膜在室温下的自旋扩散长度超过 15 nm。

Conclusion: 研究结果突显了拓扑 Weyl 非共线反铁磁 Mn3Sn 作为未来自旋电子学应用中高效自旋输运和转换材料的潜力。

Abstract: The generation and control of spin currents are crucial for advancing
next-generation spintronic technologies. These technologies depend on materials
capable of efficiently sourcing and interconverting spin and charge currents,
while overcoming some limitations associated with conventional ferromagnets and
heavy metals. Kagome topological antiferromagnetic Weyl semimetals, such as
Mn$_3$Sn, present unique advantages owing to their distinct magnetic order and
significant Berry curvature-driven transport phenomena. In this study, we
systematically investigate spin current generation and spin-to-charge
conversion phenomena in epitaxial (0001)-oriented Mn$_3$Sn thin films. Our
findings reveal a spin Hall angle of 0.9$\%$ and a nearly isotropic in-plane
spin Hall conductivity of 44.4~($\hbar$/e) $\Omega^{-1}$.cm$^{-1}$ at room
temperature, originating from a combination of intrinsic and extrinsic
contributions, as discussed in light of first-principle calculations.
Furthermore, in Mn$_3$Sn(0001)/Ni$_{81}$Fe$_{19}$ heterostructures, we observe
a high spin-mixing conductance of 28.52 nm$^{-2}$ and an interfacial
spin-transparency of approximately 72$\%$. Notably, we also find that the spin
diffusion length in Mn$_3$Sn(0001) epitaxial films exceeds 15 nm at room
temperature. Our results highlight the potential of the topological Weyl
noncollinear antiferromagnet Mn$_3$Sn as an efficient material for spin
transport and conversion in prospective spintronic applications.

</details>


### [502] [Automated Construction of Artificial Lattice Structures with Designer Electronic States](https://arxiv.org/abs/2508.02581)
*Ganesh Narasimha,Mykola Telychko,Wooin Yang,Arthur P. Baddorf,P. Ganesh,An-Ping Li,Rama Vasudevan*

Main category: cond-mat.mtrl-sci

TL;DR: 本文利用强化学习和计算机视觉技术，通过STM自动化操纵CO分子构筑原子精度的人工结构，成功实现了更大规模的人工石墨烯晶格，并验证了其电子特性，解决了手动操纵的耗时和精度问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决手动操纵原子具有耗时且STM尖端敏感的缺点，本文旨在开发一种基于强化学习的框架，以自动化操纵过程，提高构筑原子精度的人工结构的效率和规模。

Method: 本文提出了一个基于强化学习（RL）的框架，通过扫描隧道显微镜（STM）操纵铜基底上的一氧化碳（CO）分子来构筑人工结构。该工作流程结合了分子检测和操纵，利用基于深度学习的对象检测来定位CO分子，并使用线性分配算法将分子分配到指定的目标位点。首先，基于随机采样的参数（如偏压、隧穿电流设定点和操纵速度）对分子进行移动，然后将该数据集构建成一个动作轨迹来训练RL代理，最后在STM上部署该模型以在结构构筑过程中实时微调操纵参数。该方法结合了路径规划协议和主动漂移补偿。

Result: 该方法成功实现了自动化构筑由CO分子组成的人工石墨烯晶格，并通过电子结构中的狄拉克点确认了其特性。与手动操纵相比，该方法显著减少了人为输入，并实现了更大规模的人工晶格。

Conclusion: 该方法实现了自动化构筑原子精度的人工结构，并大幅减少了人工干预，同时能够构筑具有所需电子特性的更大规模的人工晶格。文章还讨论了基于强化学习的结构组装的可扩展性方面的挑战。

Abstract: Manipulating matter with a scanning tunneling microscope (STM) enables
creation of atomically defined artificial structures that host designer quantum
states. However, the time-consuming nature of the manipulation process, coupled
with the sensitivity of the STM tip, constrains the exploration of diverse
configurations and limits the size of designed features. In this study, we
present a reinforcement learning (RL)-based framework for creating artificial
structures by spatially manipulating carbon monoxide (CO) molecules on a copper
substrate using the STM tip. The automated workflow combines molecule detection
and manipulation, employing deep learning-based object detection to locate CO
molecules and linear assignment algorithms to allocate these molecules to
designated target sites. We initially perform molecule maneuvering based on
randomized parameter sampling for sample bias, tunneling current setpoint and
manipulation speed. This dataset is then structured into an action trajectory
used to train an RL agent. The model is subsequently deployed on the STM for
real-time fine-tuning of manipulation parameters during structure construction.
Our approach incorporates path planning protocols coupled with active drift
compensation to enable atomically precise fabrication of structures with
significantly reduced human input while realizing larger-scale artificial
lattices with desired electronic properties. To underpin of efficiency of our
approach we demonstrate the automated construction of an extended artificial
graphene lattice and confirm the existence of characteristic Dirac point in its
electronic structure. Further challenges to RL-based structural assembly
scalability are discussed.

</details>


### [503] [Interface Structure and Electronic Properties in Cubic Boron Nitride - Diamond Heterostructures](https://arxiv.org/abs/2508.02606)
*Cody L. Milne,Hector Gomez,Adway Gupta,A. Glen Birdwell,Sergey Rudin,Elias J. Garratt,Bradford B. Pate,Tony G. Ivanov,Arunima K. Singh,Mahesh R. Neupane*

Main category: cond-mat.mtrl-sci

TL;DR: 金刚石/cBN异质界面研究：硼端接最稳定，掺碳氮端接绝缘；界面可形成高密度二维载流子气；带对齐方式可调。


<details>
  <summary>Details</summary>
Motivation: 立方氮化硼（cBN）与金刚石的异质界面因其超宽带隙和小的晶格失配（~1.5%）而备受关注，有望在电力和高频电子器件领域取得突破。然而，该异质界面的实现受到生长条件苛刻和界面性质理解不足的限制。

Method: 本研究采用密度泛函理论（DFT）研究了金刚石/立方氮化硼（cBN）异质结构，系统性地考察了界面化学计量比、cBN厚度以及表面终止和钝化对结构和电子性质的影响。

Result: 研究发现，硼端接异质结最稳定，而掺碳的氮端接异质结仍保持4.2-4.4 eV的宽绝缘带隙。 abrupt 硼端接和氮端接异质结分别表现出p型和n型电导率。有效质量随化学计量比变化显著。研究还发现了高达10^14 cm^-2的二维电子气或空穴气，以及可调的I型和II型带对齐方式。金刚石的价带始终位于cBN价带之上，而界面端接类型会影响金刚石相对于cBN的导带位置，实现I型到II型带对齐的转变。

Conclusion: 该研究通过密度泛函理论研究了金刚石/立方氮化硼异质结构，发现硼端接异质结最稳定，而掺碳的氮端接异质结具有绝缘带隙。研究还揭示了界面处存在二维电子气或空穴气，其载流子密度高达10^14 cm^-2，并且可以通过界面成分调控带对齐方式，实现I型和II型带对齐之间的转换。

Abstract: Heterointerfaces of cubic boron nitride (cBN) with diamond have garnered
significant interest due to their ultra-wide bandgaps and small lattice
mismatch ($\sim1.5$\%), offering promising advancements in high-power and
high-frequency electronic devices. However, the realization of this
heterointerface has been limited by challenging growth conditions and
insufficient understanding of interfacial properties. In this work, we employ
density-functional theory to investigate the structural and electronic
properties of diamond/cBN heterostructures as a function of interfacial
stoichiometry, cBN thickness, and surface termination and passivation.
Formation energies and interfacial bond lengths reveal that boron-terminated
heterojunctions are the most stable while abrupt nitrogen-terminated
heterojunctions are least stable, but can be stabilized by carbon-mixing.
Bandstructures are computed for the heterostructures using hybrid functionals,
where we find the abrupt boron-terminated and nitrogen-terminated
heterojunctions exhibit $p$-type and $n$-type conductivity, respectively, while
carbon-mixed heterojunctions retain wide insulating bandgaps ($4.2-4.4$ eV).
The effective masses of the abrupt interfaces are found to vary strongly with
stoichiometry. Intriguingly, charge analysis reveals two-dimensional electron
or hole gas regions with ultra-high densities on the order of $10^{14}$
cm$^{-2}$, with distinct spatial localization on either side of the interface.
Band alignments show type-I and type-II band offsets tunable by interfacial
composition. Further analysis of the band alignments reveals that the diamond
valence bands consistently lie above the cBN valence bands by $0.25-2.1$ eV.
Interestingly, the interface termination type switches the relative conduction
band position of diamond relative to the cBN conduction band, exhibiting a
type-I to type-II band alignment transition.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [504] [Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games](https://arxiv.org/abs/2508.02076)
*Yunhao Liang,Yuan Qu,Jingyuan Yang,Shaochong Lin,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 该研究提出了一种名为MAC-SPGG的新型博弈论强化学习框架，通过激励多LLM协作来解决复杂任务，并在多项任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在协调多个大型语言模型（LLMs）以协同解决复杂任务时，与单个模型相比，计算成本和集体性能之间存在根本性的权衡。

Method: 本文提出了一种新颖的、基于博弈论的强化学习（RL）框架，称为多智能体协作顺序公共产品游戏（MAC-SPGG），以系统性地激励多LLM集成中的协作。在MAC-SPGG中，LLM智能体按顺序移动，观察前序智能体的输出来更新信念，从而条件化自身的贡献。通过重新设计公共产品奖励，努力贡献成为唯一的子博弈完美纳什均衡（SPNE），从而消除了传统SPGG或PGG中的搭便车行为。其顺序协议用简化的决策流程取代了成本高昂的基于回合的信息交换，在保留战略深度的同时降低了通信开销。

Result: MAC-SPGG框架被证明在现实参数下存在且唯一的SPNE，并且在经验上，经过MAC-SPGG训练的集成在推理、数学、代码生成和NLP任务上，其表现优于单智能体基线、思维链提示和其他协作方法，甚至能达到与大型模型相媲美的性能。

Conclusion: MAC-SPGG框架通过结构化、激励一致性的多智能体协作，在可扩展性和鲁棒性方面展现了多智能体语言生成的强大能力。

Abstract: Coordinating multiple large language models (LLMs) to solve complex tasks
collaboratively poses a fundamental trade-off between the computation costs and
collective performance compared with individual model. We introduce a novel,
game-theoretically grounded reinforcement learning (RL) framework, the
Multi-Agent Cooperation Sequential Public Goods Game (MAC-SPGG), to
systematically incentivize cooperation in multi-LLM ensembles. In MAC-SPGG, LLM
agents move in sequence, observing predecessors' outputs and updating beliefs
to condition their own contributions. By redesigning the public-goods reward,
effortful contributions become the unique Subgame Perfect Nash Equilibrium
(SPNE), which eliminates free-riding under traditional SPGG or PGG. Its
sequential protocol replaces costly round-based information exchanges with a
streamlined decision flow, cutting communication overhead while retaining
strategic depth. We prove the existence and uniqueness of the SPNE under
realistic parameters, and empirically show that MAC-SPGG-trained ensembles
outperform single-agent baselines, chain-of-thought prompting, and other
cooperative methods, even achieving comparable performance to large-scale
models across reasoning, math, code generation, and NLP tasks. Our results
highlight the power of structured, incentive-aligned MAC-SPGG cooperation for
scalable and robust multi-agent language generation.

</details>


### [505] [Exploring Agentic Artificial Intelligence Systems: Towards a Typological Framework](https://arxiv.org/abs/2508.00844)
*Christopher Wissuchek,Patrick Zschech*

Main category: cs.AI

TL;DR: 该论文提出了一个agentic AI系统的类型学，包括八个维度，用于对AI的认知和环境机构进行分类和比较。


<details>
  <summary>Details</summary>
Motivation: AI系统正从被动工具演变为能够进行推理、适应和在最少人工干预下采取行动的自主代理，但目前缺乏一个结构化框架来对这些系统进行分类和比较。

Method: 采用多阶段方法论构建和完善了agentic AI系统的类型学，并通过人类-AI混合方法进行了评估，然后将其提炼为构建类型。

Result: 开发了一个agentic AI系统的类型学，引入了八个维度来定义它们在序数结构中的认知和环境机构。

Conclusion: 该框架为评估现有系统和预期Agentic AI的未来发展提供了基础。

Abstract: Artificial intelligence (AI) systems are evolving beyond passive tools into
autonomous agents capable of reasoning, adapting, and acting with minimal human
intervention. Despite their growing presence, a structured framework is lacking
to classify and compare these systems. This paper develops a typology of
agentic AI systems, introducing eight dimensions that define their cognitive
and environmental agency in an ordinal structure. Using a multi-phase
methodological approach, we construct and refine this typology, which is then
evaluated through a human-AI hybrid approach and further distilled into
constructed types. The framework enables researchers and practitioners to
analyze varying levels of agency in AI systems. By offering a structured
perspective on the progression of AI capabilities, the typology provides a
foundation for assessing current systems and anticipating future developments
in agentic AI.

</details>


### [506] [A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation](https://arxiv.org/abs/2508.00853)
*Kei Itoh*

Main category: cs.AI

TL;DR: 该研究提出了一个名为“分层状态网格”和“中间元宇宙（IMU）”的新框架，为“状态”提供了一个统一的数学定义，并扩展了跨宇宙理论，为定义智力和科学理论奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了解决“状态”概念长期以来缺乏共识和形式清晰性的问题，为包括智力公理化定义在内的各种系统奠定理论基础。

Method: 通过引入“分层状态网格”和“中间元宇宙（IMU）”，并扩展了跨宇宙理论，将宏观宇宙-跨宇宙和微观宇宙-跨宇宙操作概念化，为不同系统（包括智力的公理化定义）提供了一个统一的数学上严谨的形式结构。

Result: 提出了一个包括状态深度和映射层次的“分层状态网格”，以及一个用于显式描述定义者和所用语言的“中间元宇宙（IMU）”，并通过引入宏观宇宙-跨宇宙和微观宇宙-跨宇宙操作的概念划分，扩展了跨宇宙理论。

Conclusion: 该研究提出了一个元形式逻辑框架，该框架基于“定义=状态”的原则，涵盖时间、语言、主体和操作，为智力、形式逻辑和科学理论的定义提供了数学上稳健的基础。

Abstract: This study aims to reinforce the theoretical foundation for diverse
systems--including the axiomatic definition of intelligence--by introducing a
mathematically rigorous and unified formal structure for the concept of
'state,' which has long been used without consensus or formal clarity. First, a
'hierarchical state grid' composed of two axes--state depth and mapping
hierarchy--is proposed to provide a unified notational system applicable across
mathematical, physical, and linguistic domains. Next, the 'Intermediate
Meta-Universe (IMU)' is introduced to enable explicit descriptions of definers
(ourselves) and the languages we use, thereby allowing conscious meta-level
operations while avoiding self-reference and logical inconsistency. Building on
this meta-theoretical foundation, this study expands inter-universal theory
beyond mathematics to include linguistic translation and agent integration,
introducing the conceptual division between macrocosm-inter-universal and
microcosm-inter-universal operations for broader expressivity. Through these
contributions, this paper presents a meta-formal logical framework--grounded in
the principle of definition = state--that spans time, language, agents, and
operations, providing a mathematically robust foundation applicable to the
definition of intelligence, formal logic, and scientific theory at large.

</details>


### [507] [AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks](https://arxiv.org/abs/2508.00890)
*Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 针对多阶段复杂任务中的测试时间缩放问题，提出AgentTTS框架，通过LLM代理自主搜索最优的模型和预算分配，以提高整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单阶段任务中的测试时间缩放（TTS），而现实世界中的许多复杂问题是多阶段的，需要LLM在每个子任务中具有特定能力。因此，研究在多阶段复杂任务中的测试时间计算最优缩放问题，旨在为每个子任务选择合适的模型和分配预算以最大化整体性能。

Method: 提出了一种名为AgentTTS的基于LLM代理的框架，通过与执行环境的迭代反馈交互来自主搜索计算最优分配。

Result: AgentTTS在搜索效率方面显著优于传统和LLM基线方法，并且在不同训练集大小下表现出更强的鲁棒性，同时具有更好的可解释性。

Conclusion: AgentTTS在搜索效率、鲁棒性和可解释性方面显著优于传统和基于LLM的基线方法。

Abstract: Test-time scaling (TTS) enhances the performance of large language models
(LLMs) by allocating additional compute resources during inference. However,
existing research primarily investigates TTS in single-stage tasks; while many
real-world problems are multi-stage complex tasks, composed of a sequence of
heterogeneous subtasks with each subtask requires LLM of specific capability.
Therefore, we study a novel problem: the test-time compute-optimal scaling in
multi-stage complex tasks, aiming to select suitable models and allocate
budgets per subtask to maximize overall performance. TTS in multi-stage tasks
introduces two fundamental challenges: (i) The combinatorial search space of
model and budget allocations, combined with the high cost of inference, makes
brute-force search impractical. (ii) The optimal model and budget allocations
across subtasks are interdependent, increasing the complexity of the
compute-optimal search. To address this gap, we conduct extensive pilot
experiments on four tasks across six datasets, deriving three empirical
insights characterizing the behavior of LLMs in multi-stage complex tasks.
Informed by these insights, we propose AgentTTS, an LLM-agent-based framework
that autonomously searches for compute-optimal allocations through iterative
feedback-driven interactions with the execution environment. Experimental
results demonstrate that AgentTTS significantly outperforms traditional and
other LLM-based baselines in search efficiency, and shows improved robustness
to varying training set sizes and enhanced interpretability.

</details>


### [508] [ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI](https://arxiv.org/abs/2508.00899)
*Abeer Dyoub,Ivan Letteri,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 本研究提出了一种名为ff4ERA的模糊框架，该框架整合了模糊逻辑、模糊层次分析法（FAHP）和确定性因子（CF），通过为每种风险类型量化道德风险（ERS），旨在解决共生人工智能（SAI）带来的道德风险评估（ERA）挑战。该框架能够生成可解释、可追溯、有风险意识的道德评估，并为决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着共生人工智能（SAI）的发展，AI系统带来了更大的道德风险，包括损害人权和信任。道德风险评估（ERA）对于指导决策以最小化此类风险至关重要。然而，ERA受到不确定性、模糊性和信息不完整性的阻碍，而且道德本身是依赖于上下文且不精确的。这激发了对灵活、透明且稳健的ERA框架的需求。

Method: 本研究提出了一种名为ff4ERA的模糊框架，该框架整合了模糊逻辑、模糊层次分析法（FAHP）和确定性因子（CF），通过为每种风险类型量化道德风险（ERS）。最终的ERS结合了FAHP派生的权重、传播的CF和风险水平，为协作ERA建模和系统化的分步分析提供了一种强大的数学方法。

Result: 案例研究证实，ff4ERA能够产生符合上下文、符合道德意义的风险评分，同时反映了专家输入和基于传感器的证据。风险评分随相关因素变化而变化，但对无关输入保持稳健。局部敏感性分析表明，在扰动下具有可预测的、大部分单调的行为，而全局Sobol分析突显了专家定义的权重和确定性因素的主导影响，验证了模型设计。

Conclusion: ff4ERA框架能够生成可解释、可追溯、有风险意识的道德评估，能够进行"假设"分析，并指导设计人员校准隶属函数和专家判断，以提供可靠的道德决策支持。

Abstract: The emergence of Symbiotic AI (SAI) introduces new challenges to ethical
decision-making as it deepens human-AI collaboration. As symbiosis grows, AI
systems pose greater ethical risks, including harm to human rights and trust.
Ethical Risk Assessment (ERA) thus becomes crucial for guiding decisions that
minimize such risks. However, ERA is hindered by uncertainty, vagueness, and
incomplete information, and morality itself is context-dependent and imprecise.
This motivates the need for a flexible, transparent, yet robust framework for
ERA. Our work supports ethical decision-making by quantitatively assessing and
prioritizing multiple ethical risks so that artificial agents can select
actions aligned with human values and acceptable risk levels. We introduce
ff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic
Hierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks
via an Ethical Risk Score (ERS) for each risk type. The final ERS combines the
FAHP-derived weight, propagated CF, and risk level. The framework offers a
robust mathematical approach for collaborative ERA modeling and systematic,
step-by-step analysis. A case study confirms that ff4ERA yields
context-sensitive, ethically meaningful risk scores reflecting both expert
input and sensor-based evidence. Risk scores vary consistently with relevant
factors while remaining robust to unrelated inputs. Local sensitivity analysis
shows predictable, mostly monotonic behavior across perturbations, and global
Sobol analysis highlights the dominant influence of expert-defined weights and
certainty factors, validating the model design. Overall, the results
demonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware
ethical assessments, enabling what-if analyses and guiding designers in
calibrating membership functions and expert judgments for reliable ethical
decision support.

</details>


### [509] [An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models](https://arxiv.org/abs/2508.00902)
*Kenneth Payne*

Main category: cs.AI

TL;DR: 大型语言模型在风险决策时会模仿人类，受到“前景理论”和语言“框架”的影响，尤其在军事情境下表现更明显。


<details>
  <summary>Details</summary>
Motivation: 检验著名“前景理论”在大型语言模型中的适用性，理解模型在不确定性下的决策方式，以及语言和情境如何影响模型的风险偏好。

Method: 通过测试大型语言模型（包括链式思考模型）的“前景理论”来检验其风险判断能力，并分析了不同情境（军事与民用）对模型风险偏好的影响。

Result: 语言模型在风险决策时，如同人类一样，常常受到前景理论的预测。模型的风险偏好很大程度上取决于情境的“框架”，军事情境比民用情境更能引发“框架效应”。

Conclusion: 研究表明，语言模型会学习人类的启发式和偏见，但这些偏见分布不均，语言的“框架”比单纯的得失更丰富。语言游戏的概念可以解释由情景触发的特定、局部偏见。此外，研究结果可用于重新审视关于语言模型推理和记忆的争论。

Abstract: Judgment of risk is key to decision-making under uncertainty. As Daniel
Kahneman and Amos Tversky famously discovered, humans do so in a distinctive
way that departs from mathematical rationalism. Specifically, they demonstrated
experimentally that humans accept more risk when they feel themselves at risk
of losing something than when they might gain. I report the first tests of
Kahneman and Tversky's landmark 'prospect theory' with Large Language Models,
including today's state of the art chain-of-thought 'reasoners'.
  In common with humans, I find that prospect theory often anticipates how
these models approach risky decisions across a range of scenarios. I also
demonstrate that context is key to explaining much of the variance in risk
appetite. The 'frame' through which risk is apprehended appears to be embedded
within the language of the scenarios tackled by the models. Specifically, I
find that military scenarios generate far larger 'framing effects' than do
civilian settings, ceteris paribus. My research suggests, therefore, that
language models the world, capturing our human heuristics and biases. But also
that these biases are uneven - the idea of a 'frame' is richer than simple
gains and losses. Wittgenstein's notion of 'language games' explains the
contingent, localised biases activated by these scenarios. Finally, I use my
findings to reframe the ongoing debate about reasoning and memorisation in
LLMs.

</details>


### [510] [Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis](https://arxiv.org/abs/2508.00914)
*Dominic Simon,Rickard Ewetz*

Main category: cs.AI

TL;DR: CHECK框架通过语义分析和逻辑优化，改进了LLM在多跳问答中的知识更新能力，显著提高了问答准确率。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑（KE）方法在更新LLM知识方面虽对简单事实查询有效，但在处理多跳问答（MQA）等需要组合推理的任务时存在不足，且易导致不合逻辑的推理过程。

Method: CHECK框架，借鉴编译器原理，通过语义分析推理链，并在执行前进行逻辑优化和模型重提示（提高温度），以修正推理错误，确保逻辑一致性。

Result: 在五个最先进框架和四个数据集上的评估显示，CHECK框架在MQA准确率方面平均提高了22.8%。

Conclusion: CHECK框架通过基于语义分析的方法，解决了现有知识编辑方法在处理需要组合推理的多跳问答（MQA）任务时存在的逻辑不一致问题，并在四个数据集上的实验结果表明，其MQA准确率平均提高了22.8%。

Abstract: Large Language Models (LLMs) require lightweight avenues of updating stored
information that has fallen out of date. Knowledge Editing (KE) approaches have
been successful in updating model knowledge for simple factual queries but
struggle with handling tasks that require compositional reasoning such as
multi-hop question answering (MQA). We observe that existing knowledge editors
leverage decompositional techniques that result in illogical reasoning
processes. In this paper, we propose a knowledge editor for MQA based on
semantic analysis called CHECK. Our framework is based on insights from an
analogy between compilers and reasoning using LLMs. Similar to how source code
is first compiled before being executed, we propose to semantically analyze
reasoning chains before executing the chains to answer questions. Reasoning
chains with semantic errors are revised to ensure consistency through logic
optimization and re-prompting the LLM model at a higher temperature. We
evaluate the effectiveness of CHECK against five state-of-the-art frameworks on
four datasets and achieve an average 22.8% improved MQA accuracy.

</details>


### [511] [Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF](https://arxiv.org/abs/2508.00967)
*Massoud Pourmandi*

Main category: cs.AI

TL;DR: 该系统通过联邦学习和轻量级模型，在计算和通信受限的情况下，实现了无人机群的实时3D场景重建。


<details>
  <summary>Details</summary>
Motivation: 解决计算限制、低带宽通信和实时场景重建的问题，实现高效的多主体3D/4D场景合成。

Method: 该框架利用联邦学习共享扩散模型和YOLOv12轻量级语义提取，以及本地NeRF更新，来实现多主体3D/4D场景合成。

Result: 实现了高效的多主体3D/4D场景合成，同时保持了隐私和可扩展性。

Conclusion: 该框架通过联邦学习、轻量级语义提取和本地NeRF更新，实现了高效的多主体3D/4D场景合成，同时保持了隐私和可扩展性。它重新设计了用于联合场景重建的生成扩散模型，改进了协作场景理解，并增加了语义感知压缩协议。

Abstract: The proposal introduces an innovative drone swarm perception system that aims
to solve problems related to computational limitations and low-bandwidth
communication, and real-time scene reconstruction. The framework enables
efficient multi-agent 3D/4D scene synthesis through federated learning of
shared diffusion model and YOLOv12 lightweight semantic extraction and local
NeRF updates while maintaining privacy and scalability. The framework redesigns
generative diffusion models for joint scene reconstruction, and improves
cooperative scene understanding, while adding semantic-aware compression
protocols. The approach can be validated through simulations and potential
real-world deployment on drone testbeds, positioning it as a disruptive
advancement in multi-agent AI for autonomous systems.

</details>


### [512] [Agent-Based Feature Generation from Clinical Notes for Outcome Prediction](https://arxiv.org/abs/2508.01956)
*Jiayi Wang,Jacqueline Jil Vallon,Neil Panjwani,Xi Ling,Sushmita Vij,Sandy Srinivas,John Leppert,Mark K. Buyyounouski,Mohsen Bayati*

Main category: cs.AI

TL;DR: SNOW是一个利用LLM自主生成结构化临床特征的系统，在预测前列腺癌复发方面，其性能与手动特征工程相当，且无需专家知识，有望改变临床ML模型利用EHR数据的方式。


<details>
  <summary>Details</summary>
Motivation: 当前的电子健康记录（EHR）分析方法在从非结构化临床记录中提取有意义的特征方面存在挑战。手动特征工程耗费人力，而全自动化方法缺乏可解释性和临床相关性。因此，需要一种能够自主生成可解释特征的方法。

Method: SNOW（Scalable Note-to-Outcome Workflow）是一个模块化的多智能体系统，利用大型语言模型（LLMs）自主地从非结构化临床记录中生成结构化临床特征，无需人工干预。该系统包含专门的智能体，负责特征发现、提取、验证、后处理和聚合。

Result: 在预测5年前列腺癌复发的研究中，SNOW系统达到了0.761的AUC-ROC，与手动特征工程（0.771）的性能相当，显著优于基线特征（0.691）和所有RFG方法。需要专家输入的LLM方法表现为0.732。

Conclusion: SNOW系统在不依赖临床专业知识的情况下，实现了与手动特征工程相当的性能，并且显著优于基线特征和所有RFG方法。该系统能够生成可解释的特征，捕捉复杂的临床信息，为利用非结构化EHR数据提供了一种潜在的转型方法，同时保持了临床部署所必需的可解释性。

Abstract: Electronic health records (EHRs) contain rich unstructured clinical notes
that could enhance predictive modeling, yet extracting meaningful features from
these notes remains challenging. Current approaches range from labor-intensive
manual clinician feature generation (CFG) to fully automated representational
feature generation (RFG) that lack interpretability and clinical relevance.
Here we introduce SNOW (Scalable Note-to-Outcome Workflow), a modular
multi-agent system powered by large language models (LLMs) that autonomously
generates structured clinical features from unstructured notes without human
intervention. We evaluated SNOW against manual CFG, clinician-guided LLM
approaches, and RFG methods for predicting 5-year prostate cancer recurrence in
147 patients from Stanford Healthcare. While manual CFG achieved the highest
performance (AUC-ROC: 0.771), SNOW matched this performance (0.761) without
requiring any clinical expertise, significantly outperforming both baseline
features alone (0.691) and all RFG approaches. The clinician-guided LLM method
also performed well (0.732) but still required expert input. SNOW's specialized
agents handle feature discovery, extraction, validation, post-processing, and
aggregation, creating interpretable features that capture complex clinical
information typically accessible only through manual review. Our findings
demonstrate that autonomous LLM systems can replicate expert-level feature
engineering at scale, potentially transforming how clinical ML models leverage
unstructured EHR data while maintaining the interpretability essential for
clinical deployment.

</details>


### [513] [AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents](https://arxiv.org/abs/2508.01012)
*Yiyi Lu,Hoi Ian Au,Junyao Zhang,Jingyu Pan,Yiting Wang,Ang Li,Jianyi Zhang,Yiran Chen*

Main category: cs.AI

TL;DR: AutoEDA是一个用于EDA自动化的框架，通过MCP实现跨RTL-to-GDSII流程的标准化、可扩展的自然语言体验，并采用结构化提示工程、智能参数提取和任务分解来限制微调，同时使用扩展的CodeBLEU指标评估TCL脚本质量。


<details>
  <summary>Details</summary>
Motivation: 现有的电子设计自动化（EDA）工作流（特别是RTL-to-GDSII流程）需要大量手动脚本编写，并且存在多种特定于工具的交互，这限制了可扩展性和效率。虽然LLM在自动化方面取得了进展，但现有的LLM解决方案需要昂贵的微调，并且缺乏用于集成和评估的标准框架。

Method: AutoEDA框架利用模型上下文协议（MCP）实现跨整个RTL-to-GDSII流程的标准化、可扩展的自然语言体验，并通过并列学习进行EDA自动化。

Result: 实验结果表明，与现有方法相比，AutoEDA在自动化精度、效率和脚本质量方面均有所提高。

Conclusion: AutoEDA通过结构化提示工程、智能参数提取和任务分解，并扩展CodeBLEU指标来评估TCL脚本质量，在自动化精度、效率和脚本质量方面优于现有方法。AutoEDA已开源，以支持可复现性和EDA社区。

Abstract: Modern Electronic Design Automation (EDA) workflows, especially the
RTL-to-GDSII flow, require heavily manual scripting and demonstrate a multitude
of tool-specific interactions which limits scalability and efficiency. While
LLMs introduces strides for automation, existing LLM solutions require
expensive fine-tuning and do not contain standardized frameworks for
integration and evaluation. We introduce AutoEDA, a framework for EDA
automation that leverages paralleled learning through the Model Context
Protocol (MCP) specific for standardized and scalable natural language
experience across the entire RTL-to-GDSII flow. AutoEDA limits fine-tuning
through structured prompt engineering, implements intelligent parameter
extraction and task decomposition, and provides an extended CodeBLEU metric to
evaluate the quality of TCL scripts. Results from experiments over five
previously curated benchmarks show improvements in automation accuracy and
efficiency, as well as script quality when compared to existing methods.
AutoEDA is released open-sourced to support reproducibility and the EDA
community. Available at: https://github.com/AndyLu666/MCP-EDA-Server

</details>


### [514] [Reasoning Systems as Structured Processes: Foundations, Failures, and Formal Criteria](https://arxiv.org/abs/2508.01763)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.AI

TL;DR: 本研究提出了一个推理系统的通用形式化框架，将推理系统表示为包含现象、解释空间、推理和生成映射以及原理库的结构化元组。该框架统一了逻辑、算法和学习型推理，并考虑了内部标准和故障模式，旨在支持未来的推理研究。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为推理系统提供一个通用的形式化框架，以支持未来跨领域的推理架构分析，特别是在可能出现内部故障、适应或碎片化的情况下，为表征和比较推理系统建立基础结构。

Method: 本研究提出一个通用的形式化框架，将推理系统建模为包含现象、解释空间、推理和生成映射以及原理库的结构化元组。该框架能够统一逻辑、算法和学习型推理过程，并考察了相干性、可靠性和完备性等内部标准，同时归纳了矛盾、不完备和不收敛等常见故障模式。此外，该框架还支持迭代改进和原理演化等动态行为。

Result: 该框架能够统一逻辑、算法和学习型推理过程，并对具体推理算法或逻辑系统保持中立。此外，还考察了相干性、可靠性和完备性等内部标准，并归纳了矛盾、不完备和不收敛等常见故障模式。该框架还支持迭代改进和原理演化等动态行为。

Conclusion: 本研究旨在为推理系统提供一个通用的形式化框架，以支持未来跨领域的推理架构分析。该框架将推理系统建模为包含现象、解释空间、推理和生成映射以及原理库的结构化元组，能够统一纳入逻辑、算法和学习型推理过程，并对具体推理算法或逻辑系统保持中立。此外，还考察了相干性、可靠性和完备性等内部标准，并归纳了常见故障模式，如矛盾、不完备和不收敛。该框架还支持迭代改进和原理演化等动态行为。本工作的目标是为表征和比较推理系统建立基础结构，特别是在可能出现内部故障、适应或碎片化的情况下。本研究不提出具体的解决方案架构，而是旨在支持在结构约束下进行推理的未来理论和实践研究。

Abstract: This paper outlines a general formal framework for reasoning systems,
intended to support future analysis of inference architectures across domains.
We model reasoning systems as structured tuples comprising phenomena,
explanation space, inference and generation maps, and a principle base. The
formulation accommodates logical, algorithmic, and learning-based reasoning
processes within a unified structural schema, while remaining agnostic to any
specific reasoning algorithm or logic system. We survey basic internal
criteria--including coherence, soundness, and completeness-and catalog typical
failure modes such as contradiction, incompleteness, and non-convergence. The
framework also admits dynamic behaviors like iterative refinement and principle
evolution. The goal of this work is to establish a foundational structure for
representing and comparing reasoning systems, particularly in contexts where
internal failure, adaptation, or fragmentation may arise. No specific solution
architecture is proposed; instead, we aim to support future theoretical and
practical investigations into reasoning under structural constraint.

</details>


### [515] [A Survey on AgentOps: Categorization, Challenges, and Future Directions](https://arxiv.org/abs/2508.02121)
*Zexin Wang,Jingjing Li,Quan Zhou,Haotian Si,Yuanhao Liu,Jianhui Li,Gaogang Xie,Fei Sun,Dan Pei,Changhua Pei*

Main category: cs.AI

TL;DR: LLM agent systems have operational issues. This paper surveys these issues, defines anomalies, and proposes a new operational framework called AgentOps to improve stability and security.


<details>
  <summary>Details</summary>
Motivation: LLM-based agent systems are gaining attention for their flexibility and interpretability, but like traditional systems, they suffer from anomalies that hinder development. Current research on agent system operations is sparse, necessitating a systematic approach.

Method: The paper surveys agent system operations, defines anomalies (intra-agent and inter-agent), and introduces the AgentOps framework with its four stages: monitoring, anomaly detection, root cause analysis, and resolution.

Result: A framework for understanding and addressing anomalies in agent systems, named AgentOps, has been established. This framework includes definitions of anomalies and a four-stage process for operations.

Conclusion: The paper addresses the lack of research in agent system operations by providing a systematic survey, defining anomalies, and proposing a new operational framework called AgentOps.

Abstract: As the reasoning capabilities of Large Language Models (LLMs) continue to
advance, LLM-based agent systems offer advantages in flexibility and
interpretability over traditional systems, garnering increasing attention.
However, despite the widespread research interest and industrial application of
agent systems, these systems, like their traditional counterparts, frequently
encounter anomalies. These anomalies lead to instability and insecurity,
hindering their further development. Therefore, a comprehensive and systematic
approach to the operation and maintenance of agent systems is urgently needed.
Unfortunately, current research on the operations of agent systems is sparse.
To address this gap, we have undertaken a survey on agent system operations
with the aim of establishing a clear framework for the field, defining the
challenges, and facilitating further development. Specifically, this paper
begins by systematically defining anomalies within agent systems, categorizing
them into intra-agent anomalies and inter-agent anomalies. Next, we introduce a
novel and comprehensive operational framework for agent systems, dubbed Agent
System Operations (AgentOps). We provide detailed definitions and explanations
of its four key stages: monitoring, anomaly detection, root cause analysis, and
resolution.

</details>


### [516] [CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent](https://arxiv.org/abs/2508.01031)
*Jingzhe Ni,Xiaolong Yin,Xintong Li,Xingyu Lu,Ji Wei,Ruofeng Tong,Min Tang,Peng Du*

Main category: cs.AI

TL;DR: 我们开发了一个由LLM驱动的CAD设计助手，它可以理解文本和草图，与用户对话，并生成高质量的CAD代码，在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了降低CAD设计的入门门槛并提高设计效率，弥补当前CAD设计需要高水平专业知识的不足。

Method: 提出了一种由大型语言模型（LLM）驱动的CAD概念设计代理，该代理接受文本描述和手绘草图作为输入，并通过交互式对话进行需求细化。该代理基于新颖的上下文无关命令范式（CIP）生成CAD建模代码，并整合迭代视觉反馈以提高模型质量。此外，还将生成的设计案例存储在结构化知识库中，以实现代理代码生成能力的持续改进。

Result: 实验结果表明，所提出的方法在CAD代码生成方面达到了最先进的性能。

Conclusion: 所提出的基于LLM的CAD概念设计代理通过结合文本和草图输入、交互式对话、CIP范式、迭代视觉反馈以及结构化知识库，实现了最先进的CAD代码生成性能。

Abstract: Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing
but typically requires a high level of expertise from designers. To lower the
entry barrier and improve design efficiency, we present an agent for CAD
conceptual design powered by large language models (LLMs). The agent accepts
both abstract textual descriptions and freehand sketches as input, engaging in
interactive dialogue with users to refine and clarify design requirements
through comprehensive requirement analysis. Built upon a novel
Context-Independent Imperative Paradigm (CIP), the agent generates high-quality
CAD modeling code. During the generation process, the agent incorporates
iterative visual feedback to improve model quality. Generated design cases are
stored in a structured knowledge base, enabling continuous improvement of the
agent's code generation capabilities. Experimental results demonstrate that our
method achieves state-of-the-art performance in CAD code generation.

</details>


### [517] [BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation](https://arxiv.org/abs/2508.01285)
*Yujing Ke,Kevin George,Kathan Pandya,David Blumenthal,Maximilian Sprang,Gerrit Großmann,Sebastian Vollmer,David Antony Selby*

Main category: cs.AI

TL;DR: BioDisco是一个新的多主体框架，利用语言模型和双模式证据系统（知识图谱和文献检索）来生成和优化科学假设，并在新颖性、重要性和未来发现潜力方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有自动方法在生成新颖且有证据支持的假设时面临信息量大、复杂性高、迭代优化不足以及缺乏严格的时间评估等问题，我们提出了BioDisco。

Method: BioDisco是一个多主体框架，利用基于语言模型的推理和双模式证据系统（生物医学知识图谱和自动化文献检索）来实现新颖性的基础，并结合内部评分和反馈循环进行迭代优化，最后通过时间、人类评估和Bradley-Terry配对模型进行性能验证。

Result: 评估结果表明，BioDisco在优越性、新颖性和显著性方面优于现有代表性agentic架构的消融配置。

Conclusion: BioDisco是一个灵活且模块化的框架，可以作为新颖假设发现的催化剂，允许无缝集成自定义语言模型或知识图谱，并且只需几行代码即可运行。

Abstract: Identifying novel hypotheses is essential to scientific research, yet this
process risks being overwhelmed by the sheer volume and complexity of available
information. Existing automated methods often struggle to generate novel and
evidence-grounded hypotheses, lack robust iterative refinement and rarely
undergo rigorous temporal evaluation for future discovery potential. To address
this, we propose BioDisco, a multi-agent framework that draws upon language
model-based reasoning and a dual-mode evidence system (biomedical knowledge
graphs and automated literature retrieval) for grounded novelty, integrates an
internal scoring and feedback loop for iterative refinement, and validates
performance through pioneering temporal and human evaluations and a
Bradley-Terry paired comparison model to provide statistically-grounded
assessment. Our evaluations demonstrate superior novelty and significance over
ablated configurations representative of existing agentic architectures.
Designed for flexibility and modularity, BioDisco allows seamless integration
of custom language models or knowledge graphs, and can be run with just a few
lines of code. We anticipate researchers using this practical tool as a
catalyst for the discovery of new hypotheses.

</details>


### [518] [REACT: A Real-Time Edge-AI Based V2X Framework for Accident Avoidance in Autonomous Driving System](https://arxiv.org/abs/2508.01057)
*Fengze Yang,Bo Yu,Yang Zhou,Xuewen Luo,Zhengzhong Tu,Chenxi Liu*

Main category: cs.AI

TL;DR: REACT是一个实时的、集成了V2X的轨迹优化框架，它使用轻量级VLM和边缘适应策略，在自动驾驶中提高了安全性和响应能力。


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer-based V2X框架泛化能力有限，上下文推理浅，且依赖单一模态输入。而现有的视觉语言模型（VLM）虽然推理能力强且支持多模态，但通常无法满足自动驾驶等安全关键应用对实时性的要求。因此，需要一种能够克服这些限制的V2X框架。

Method: 提出了一种名为REACT的框架，该框架基于微调的轻量级视觉语言模型（VLM），并集成了专门的模块来处理多模态输入，生成优化的、风险感知的轨迹。该框架还采用了边缘适应策略以在边缘设备上实现实时性能。

Result: REACT在DeepAccident基准测试中取得了最先进的性能，将碰撞率降低了77%，视频全景质量（VPQ）提高了48.2%，并且在Jetson AGX Orin上的推理延迟为0.57秒。

Conclusion: 该研究证明了轻量级视觉语言模型（VLM）在实时边缘协同规划中的可行性，并展示了语言引导的上下文推理在提高自动驾驶安全性和响应能力方面的潜力。

Abstract: Collisions caused by human error are the most common type of multi-vehicle
crash, highlighting the critical need for autonomous driving (AD) systems to
leverage cooperative perception through Vehicle-to-Everything (V2X)
communication. This capability extends situational awareness beyond the
limitations of onboard sensors. However, current transformer-based V2X
frameworks suffer from limited generalization, shallow contextual reasoning,
and reliance on mono-modal inputs. Vision-Language Models (VLMs) offer enhanced
reasoning and multimodal integration but typically fall short of real-time
performance requirements in safety-critical applications. This paper presents
REACT, a real-time, V2X-integrated trajectory optimization framework built upon
a fine-tuned lightweight VLM. REACT integrates a set of specialized modules
that process multimodal inputs into optimized, risk-aware trajectories. To
ensure real-time performance on edge devices, REACT incorporates edge
adaptation strategies that reduce model complexity and accelerate inference.
Evaluated on the DeepAccident benchmark, REACT achieves state-of-the-art
performance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality
(VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation
studies validate the contribution of each input, module, and edge adaptation
strategy. These results demonstrate the feasibility of lightweight VLMs for
real-time edge-based cooperative planning and showcase the potential of
language-guided contextual reasoning to improve safety and responsiveness in
autonomous driving.

</details>


### [519] [HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research](https://arxiv.org/abs/2508.02621)
*Yinghao Zhu,Yifan Qi,Zixiang Wang,Lei Gu,Dehao Sui,Haoran Hu,Xichen Zhang,Ziyi He,Liantao Ma,Lequan Yu*

Main category: cs.AI

TL;DR: AI代理在医疗保健研究中因策略僵化而受限。本文提出HealthFlow，一种能自我进化、优化策略的AI代理，并通过EHRFlowBench基准测试证明其效果远超现有技术，是迈向更智能、自主AI的关键一步。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在医疗保健研究中的有效性受到其依赖静态、预定义策略的限制，导致它们只能成为更好的工具使用者，而无法学会成为关键的战略规划者，这在医疗保健等复杂领域是至关重要的。

Method: 提出了一种名为HealthFlow的自进化AI代理，它采用新颖的元级别进化机制，通过提炼程序化成功与失败的经验来优化其高层问题解决策略，并构建了一个持久的战略知识库。同时，创建了一个名为EHRFlowBench的新基准测试，包含源自同行评审临床研究的复杂、现实医疗数据分析任务，以支持可复现的评估。

Result: HealthFlow的自进化方法在EHRFlowBench基准测试中显著优于最先进的代理框架，证明了其在处理复杂、现实医疗数据分析任务方面的优越性。

Conclusion: HealthFlow通过其创新的元级别进化机制，能够自主优化其高级问题解决策略，将程序性成功和失败提炼成持久的战略知识库，从而克服了当前AI代理在医疗保健研究中依赖静态策略的局限性。在EHRFlowBench基准测试的实验中，HealthFlow显著优于最先进的代理框架，标志着AI发展从优化工具使用转向设计更智能、可自我进化的任务管理器，为更自主、更有效的科学发现AI铺平了道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [520] [gpuRDF2vec -- Scalable GPU-based RDF2vec](https://arxiv.org/abs/2508.01073)
*Martin Böckling,Heiko Paulheim*

Main category: cs.AI

TL;DR: gpuRDF2vec 是一个加速 RDF2vec 的库，利用 GPU 和多节点执行，在大型图上实现了比 jRDF2vec 高达显著的加速。


<details>
  <summary>Details</summary>
Motivation: 在 Web 规模上生成知识图 (KG) 嵌入仍然是一个挑战。RDF2vec 结合了有效性和强大的可扩展性。

Method: gpuRDF2vec 是一个开源库，利用现代 GPU 并支持多节点执行来加速 RDF2vec 管道的每个阶段。它建立在 Pytorch Lightning 之上，用于可扩展的 word2vec 实现。

Result: 在合成生成图和真实世界基准上进行的大量实验表明，gpuRDF2vec 在单节点设置中，仅其游走提取阶段就通过在大型/密集图上进行随机游走，比 pyRDF2vec、SparkKGML 和 jRDF2vec 有了显著的改进，并且能够很好地扩展到通常能带来更好嵌入质量的更长游走。

Conclusion: gpuRDF2vec 实现了在实际可行的时限内，在大型图上训练高质量的 KG 嵌入，能够实现比当前最快的替代方案（jRDF2vec）高达显著的加速。

Abstract: Generating Knowledge Graph (KG) embeddings at web scale remains challenging.
Among existing techniques, RDF2vec combines effectiveness with strong
scalability. We present gpuRDF2vec, an open source library that harnesses
modern GPUs and supports multi-node execution to accelerate every stage of the
RDF2vec pipeline. Extensive experiments on both synthetically generated graphs
and real-world benchmarks show that gpuRDF2vec achieves up to a substantial
speedup over the currently fastest alternative, i.e., jRDF2vec. In a
single-node setup, our walk-extraction phase alone outperforms pyRDF2vec,
SparkKGML, and jRDF2vec by a substantial margin using random walks on large/
dense graphs, and scales very well to longer walks, which typically lead to
better quality embeddings. Our implementation of gpuRDF2vec enables
practitioners and researchers to train high-quality KG embeddings on
large-scale graphs within practical time budgets and builds on top of Pytorch
Lightning for the scalable word2vec implementation.

</details>


### [521] [What Is Your AI Agent Buying? Evaluation, Implications and Emerging Questions for Agentic E-Commerce](https://arxiv.org/abs/2508.02630)
*Amine Allouah,Omar Besbes,Josué D Figueroa,Yash Kanoria,Akshit Kumar*

Main category: cs.AI

TL;DR: AI agents are transforming online shopping. This study used a mock marketplace (ACES) to see what AI agents buy and why. Different AI models have varied preferences for product placement, price, and reviews, and they dislike 'sponsored' tags. Optimizing product listings for AI buyers can increase sales, but could also lead to market concentration.


<details>
  <summary>Details</summary>
Motivation: The research aims to understand what AI agents buy and why in online marketplaces, given their increasing role in replacing human browsing and purchasing.

Method: The study utilizes ACES, a sandbox environment pairing a platform-agnostic VLM agent with a programmable mock marketplace. The research involves basic rationality checks and causal estimation by randomizing product attributes like position, price, ratings, reviews, sponsored tags, and platform endorsements.

Result: Frontier VLM agents exhibit strong, yet heterogeneous, position effects, favoring the top row but showing variability in column preference. They tend to penalize sponsored tags and reward endorsements. Price, rating, and review sensitivities are directionally human-like but vary in magnitude. Minor AI-driven product description tweaks can yield significant market share gains.

Conclusion: AI agents' purchasing behavior in online marketplaces is complex and varies significantly across different models. Sellers can leverage AI agents to optimize product listings for substantial market share gains, but this also raises questions about competition and market concentration.

Abstract: Online marketplaces will be transformed by autonomous AI agents acting on
behalf of consumers. Rather than humans browsing and clicking,
vision-language-model (VLM) agents can parse webpages, evaluate products, and
transact. This raises a fundamental question: what do AI agents buy, and why?
We develop ACES, a sandbox environment that pairs a platform-agnostic VLM agent
with a fully programmable mock marketplace to study this question. We first
conduct basic rationality checks in the context of simple tasks, and then, by
randomizing product positions, prices, ratings, reviews, sponsored tags, and
platform endorsements, we obtain causal estimates of how frontier VLMs actually
shop. Models show strong but heterogeneous position effects: all favor the top
row, yet different models prefer different columns, undermining the assumption
of a universal "top" rank. They penalize sponsored tags and reward
endorsements. Sensitivities to price, ratings, and reviews are directionally
human-like but vary sharply in magnitude across models. Motivated by scenarios
where sellers use AI agents to optimize product listings, we show that a
seller-side agent that makes minor tweaks to product descriptions, targeting AI
buyer preferences, can deliver substantial market-share gains if AI-mediated
shopping dominates. We also find that modal product choices can differ across
models and, in some cases, demand may concentrate on a few select products,
raising competition questions. Together, our results illuminate how AI agents
may behave in e-commerce settings and surface concrete seller strategy,
platform design, and regulatory questions in an AI-mediated ecosystem.

</details>


### [522] [Multispin Physics of AI Tipping Points and Hallucinations](https://arxiv.org/abs/2508.01097)
*Neil F. Johnson,Frank Yingjie Huo*

Main category: cs.AI

TL;DR: 生成式AI（如ChatGPT）的输出可能在用户无察觉的情况下从正确转变为错误，导致巨大损失。本研究将AI映射到多旋热力系统，揭示了AI“原子”层面的Tipping不稳定性，并推导了Tipping点公式，解释了用户提示和训练偏差的影响，并展示了多层结构如何放大此效应，有助于提高AI透明度和量化用户风险。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（如ChatGPT）的输出可能存在重复和偏见，更令人担忧的是，其输出可能在用户无察觉的情况下从中点开始从“好”（正确）转变为“坏”（误导性或错误）。

Method: 通过将生成模型映射到多旋热力系统，揭示了AI“原子”（基本注意力头）层面的隐藏Tipping不稳定性，并推导了一个直接显示用户提示选择和AI训练偏差影响的Tipping点精确公式，最后展示了多层结构如何放大输出Tipping。

Result: 揭示了AI“原子”（基本注意力头）层面的隐藏Tipping不稳定性，并推导了一个直接显示用户提示选择和AI训练偏差影响的Tipping点精确公式，展示了多层结构如何放大输出Tipping。

Conclusion: 研究结果有助于提高AI的透明度、可解释性和性能，并为量化用户的AI风险和法律责任开辟了道路。

Abstract: Output from generative AI such as ChatGPT, can be repetitive and biased. But
more worrying is that this output can mysteriously tip mid-response from good
(correct) to bad (misleading or wrong) without the user noticing. In 2024
alone, this reportedly caused $67 billion in losses and several deaths.
Establishing a mathematical mapping to a multispin thermal system, we reveal a
hidden tipping instability at the scale of the AI's 'atom' (basic Attention
head). We derive a simple but essentially exact formula for this tipping point
which shows directly the impact of a user's prompt choice and the AI's training
bias. We then show how the output tipping can get amplified by the AI's
multilayer architecture. As well as helping improve AI transparency,
explainability and performance, our results open a path to quantifying users'
AI risk and legal liabilities.

</details>


### [523] [Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?](https://arxiv.org/abs/2508.01109)
*Satiyabooshan Murugaboopathy,Connor T. Jerzak,Adel Daoud*

Main category: cs.AI

TL;DR: 本研究开发了一个多模态框架，结合卫星图像和人工智能生成的文本，以预测非洲社区的家庭财富。结果表明，这种多模态方法比仅使用图像的方法更准确，并且不同信息来源（如LLM和网络搜索）具有互补性，部分支持了关于信息表示的理论。研究还发布了一个大规模的多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索社会经济指标（如家庭财富）是否能在卫星图像（捕捉物理特征）和互联网文本（反映历史/经济叙述）中留下可恢复的印记。研究希望通过结合视觉和文本信息来提高财富预测的准确性，并探究不同模态信息之间的关系。

Method: 本研究构建了一个多模态框架，包含五个预测流程：仅使用卫星图像的视觉模型；仅使用地理位置/年份信息的大型语言模型；通过人工智能搜索和整合网络文本；联合图像-文本编码器；以及所有信号的集成。研究使用了来自非洲社区的人口与健康调查（DHS）数据，并将其与卫星图像、LLM 生成的文本描述以及通过人工智能搜索代理检索的网络文本相结合。

Result: 研究结果显示，融合视觉和文本信息的多模态方法比仅使用视觉信息的基线方法在财富预测方面表现更好（R方值从0.63提升至0.77）。LLM 内部知识比 AI 代理检索的文本更有效。研究还发现，视觉和语言模态的融合嵌入具有中等程度的相关性（中位余弦相似度为0.60），表明它们共享一个关于物质福祉的潜在代码，同时保留了互补的细节，这与“柏拉图表征假说”一致。AI 代理检索的数据在某些情况下能带来微小的提升，部分支持了“代理诱导新颖性假说”。

Conclusion: 本研究表明，融合了卫星图像和由大型语言模型（LLM）及网络爬虫生成文本的多模态框架，能够有效预测非洲社区的家庭财富。多模态方法在预测准确性上优于仅使用图像的方法，并且不同模态的信息具有一定程度的融合和互补性，支持了“柏拉图表征假说”。研究还发布了一个包含超过60,000个 DHS 社区及其对应多模态数据的大规模数据集。

Abstract: We investigate whether socio-economic indicators like household wealth leave
recoverable imprints in satellite imagery (capturing physical features) and
Internet-sourced text (reflecting historical/economic narratives). Using
Demographic and Health Survey (DHS) data from African neighborhoods, we pair
Landsat images with LLM-generated textual descriptions conditioned on
location/year and text retrieved by an AI search agent from web sources. We
develop a multimodal framework predicting household wealth (International
Wealth Index) through five pipelines: (i) vision model on satellite images,
(ii) LLM using only location/year, (iii) AI agent searching/synthesizing web
text, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework
yields three contributions. First, fusing vision and agent/LLM text outperforms
vision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on
out-of-sample splits), with LLM-internal knowledge proving more effective than
agent-retrieved text, improving robustness to out-of-country and out-of-time
generalization. Second, we find partial representational convergence: fused
embeddings from vision/language modalities correlate moderately (median cosine
similarity of 0.60 after alignment), suggesting a shared latent code of
material well-being while retaining complementary details, consistent with the
Platonic Representation Hypothesis. Although LLM-only text outperforms
agent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest
gains from combining agent data in some splits weakly support the notion that
agent-gathered information introduces unique representational structures not
fully captured by static LLM knowledge. Third, we release a large-scale
multimodal dataset comprising more than 60,000 DHS clusters linked to satellite
images, LLM-generated descriptions, and agent-retrieved texts.

</details>


### [524] [H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving](https://arxiv.org/abs/2508.01158)
*Yunlong Lin,Zirui Li,Guodong Du,Xiaocong Zhao,Cheng Gong,Xinwei Wang,Chao Lu,Jianwei Gong*

Main category: cs.AI

TL;DR: 受神经科学中海马回路在记忆回放中作用的启发，提出了一种受海马回路启发的持续学习方法（H2C），用于在不同场景下的轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在轨迹预测方面表现出色，但大多数方法存在灾难性遗忘问题，即适应新分布可能导致先前学习的性能显著下降。这种保留所学知识的能力受限，限制了它们在现实世界中的应用，因为自动驾驶系统需要在具有动态分布的各种场景中运行。

Method: H2C采用两种互补的策略来选择代表已学知识的样本子集：一种策略最大化样本间的多样性以代表独特的知识，另一种策略通过等概率采样来估计整体知识。

Result: 实验结果表明，H2C在无任务的情况下将深度学习基线方法的灾难性遗忘平均减少了22.71%，并且不依赖于手动指定的分布变化。

Conclusion: H2C通过选择性召回少量学习样本来保留先验知识，并结合记忆回放损失函数进行更新，从而在学习新数据的同时保留知识。

Abstract: Deep learning (DL) has shown state-of-the-art performance in trajectory
prediction, which is critical to safe navigation in autonomous driving (AD).
However, most DL-based methods suffer from catastrophic forgetting, where
adapting to a new distribution may cause significant performance degradation in
previously learned ones. Such inability to retain learned knowledge limits
their applicability in the real world, where AD systems need to operate across
varying scenarios with dynamic distributions. As revealed by neuroscience, the
hippocampal circuit plays a crucial role in memory replay, effectively
reconstructing learned knowledge based on limited resources. Inspired by this,
we propose a hippocampal circuit-inspired continual learning method (H2C) for
trajectory prediction across varying scenarios. H2C retains prior knowledge by
selectively recalling a small subset of learned samples. First, two
complementary strategies are developed to select the subset to represent
learned knowledge. Specifically, one strategy maximizes inter-sample diversity
to represent the distinctive knowledge, and the other estimates the overall
knowledge by equiprobable sampling. Then, H2C updates via a memory replay loss
function calculated by these selected samples to retain knowledge while
learning new data. Experiments based on various scenarios from the INTERACTION
dataset are designed to evaluate H2C. Experimental results show that H2C
reduces catastrophic forgetting of DL baselines by 22.71% on average in a
task-free manner, without relying on manually informed distributional shifts.
The implementation is available at https://github.com/BIT-Jack/H2C-lifelong.

</details>


### [525] [Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning](https://arxiv.org/abs/2508.01181)
*Zhiyuan Han,Beier Zhu,Yanlong Xu,Peipei Song,Xun Yang*

Main category: cs.AI

TL;DR: 本研究提出了MoSEAR框架，以解决多模态大语言模型在情感冲突场景下的偏见问题，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理情感冲突场景（不同模态的情感线索不一致）时表现不佳，普遍存在过度依赖音频信号而忽视视觉线索的问题。

Method: 提出了一种名为MoSEAR的参数高效框架，包含两个模块：1. MoSE（模态特定专家），采用正则化门控机制，减少微调头中的模态偏差；2. AR（注意力再分配），在推理过程中重新平衡冻结主干中的模态贡献。

Result: 在MER2023、EMER、DFEW和CA-MER等多个基准测试上，MoSEAR均取得了最先进的性能，特别是在处理模态冲突的情况下。

Conclusion: MoSEAR框架通过引入模态特定的专家和注意力再分配机制，有效缓解了多模态情感冲突问题，并在一致性样本上提升了性能，同时在音频和视觉模态之间实现了平衡，在多个基准测试中取得了最先进的性能。

Abstract: Despite their strong performance in multimodal emotion reasoning, existing
Multimodal Large Language Models (MLLMs) often overlook the scenarios involving
emotion conflicts, where emotional cues from different modalities are
inconsistent. To fill this gap, we first introduce CA-MER, a new benchmark
designed to examine MLLMs under realistic emotion conflicts. It consists of
three subsets: video-aligned, audio-aligned, and consistent, where only one or
all modalities reflect the true emotion. However, evaluations on our CA-MER
reveal that current state-of-the-art emotion MLLMs systematically over-rely on
audio signal during emotion conflicts, neglecting critical cues from visual
modality. To mitigate this bias, we propose MoSEAR, a parameter-efficient
framework that promotes balanced modality integration. MoSEAR consists of two
modules: (1)MoSE, modality-specific experts with a regularized gating mechanism
that reduces modality bias in the fine-tuning heads; and (2)AR, an attention
reallocation mechanism that rebalances modality contributions in frozen
backbones during inference. Our framework offers two key advantages: it
mitigates emotion conflicts and improves performance on consistent
samples-without incurring a trade-off between audio and visual modalities.
Experiments on multiple benchmarks-including MER2023, EMER, DFEW, and our
CA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,
particularly under modality conflict conditions.

</details>


### [526] [A Survey on Agent Workflow -- Status and Future](https://arxiv.org/abs/2508.01186)
*Chaojia Yu,Zihan Cheng,Hanwen Cui,Yishuo Gao,Zexu Luo,Yijin Wang,Hangbin Zheng,Yong Zhao*

Main category: cs.AI

TL;DR: This survey reviews agent workflow systems, classifying them by function and architecture, comparing over 20 examples to identify trends and challenges, and discussing optimization, security, and future research directions like standardization and multimodal integration.


<details>
  <summary>Details</summary>
Motivation: Autonomous agents leveraging tools, memory, and reasoning capabilities are key to achieving general intelligence. As agent systems grow in complexity, agent workflows are central to enabling scalable, controllable, and secure AI behaviors, necessitating a comprehensive review of these systems.

Method: Classification of existing systems along two key dimensions: functional capabilities (e.g., planning, multi-agent collaboration, external API integration) and architectural features (e.g., agent roles, orchestration flows, specification languages). Comparison of over 20 representative systems.

Result: A classification of agent workflow systems, a comparison of over 20 systems highlighting common patterns, challenges, and trends, an address of optimization and security concerns, and an outline of open problems like standardization and multimodal integration.

Conclusion: The survey classifies agent workflow systems along functional capabilities and architectural features, compares over 20 representative systems, highlights common patterns, technical challenges, and emerging trends, addresses workflow optimization and security concerns, and outlines open problems such as standardization and multimodal integration for future research.

Abstract: In the age of large language models (LLMs), autonomous agents have emerged as
a powerful paradigm for achieving general intelligence. These agents
dynamically leverage tools, memory, and reasoning capabilities to accomplish
user-defined goals. As agent systems grow in complexity, agent
workflows-structured orchestration frameworks-have become central to enabling
scalable, controllable, and secure AI behaviors. This survey provides a
comprehensive review of agent workflow systems, spanning academic frameworks
and industrial implementations. We classify existing systems along two key
dimensions: functional capabilities (e.g., planning, multi-agent collaboration,
external API integration) and architectural features (e.g., agent roles,
orchestration flows, specification languages). By comparing over 20
representative systems, we highlight common patterns, potential technical
challenges, and emerging trends. We further address concerns related to
workflow optimization strategies and security. Finally, we outline open
problems such as standardization and multimodal integration, offering insights
for future research at the intersection of agent design, workflow
infrastructure, and safe automation.

</details>


### [527] [Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens](https://arxiv.org/abs/2508.01191)
*Chengshuai Zhao,Zhen Tan,Pingchuan Ma,Dawei Li,Bohan Jiang,Yancheng Wang,Yingzhen Yang,Huan Liu*

Main category: cs.AI

TL;DR: CoT reasoning in LLMs is brittle and not a sign of true understanding; it fails when faced with data outside its training distribution, suggesting current LLMs still struggle with genuine, generalizable reasoning.


<details>
  <summary>Details</summary>
Motivation: Initial findings suggest that CoT reasoning may be more superficial than it appears, motivating further exploration into whether it reflects a structured inductive bias learned from in-distribution data or genuine inferential processes.

Method: The paper studies CoT reasoning via a data distribution lens using DataAlchemy, an isolated and controlled environment to train LLMs from scratch and systematically probe them under various distribution conditions. CoT reasoning is dissected via three dimensions: task, length, and format.

Result: The results reveal that CoT reasoning is brittle and vanishes when pushed beyond training distributions, highlighting its limitations and the challenges in achieving generalizable reasoning.

Conclusion: Chain-of-Thought (CoT) reasoning is a brittle mirage that vanishes when pushed beyond training distributions, indicating its effectiveness is fundamentally bounded by the degree of distribution discrepancy between training and test data. The paper emphasizes the ongoing challenge of achieving genuine and generalizable reasoning in LLMs.

Abstract: Chain-of-Thought (CoT) prompting has been shown to improve Large Language
Model (LLM) performance on various tasks. With this approach, LLMs appear to
produce human-like reasoning steps before providing answers (a.k.a., CoT
reasoning), which often leads to the perception that they engage in deliberate
inferential processes. However, some initial findings suggest that CoT
reasoning may be more superficial than it appears, motivating us to explore
further. In this paper, we study CoT reasoning via a data distribution lens and
investigate if CoT reasoning reflects a structured inductive bias learned from
in-distribution data, allowing the model to conditionally generate reasoning
paths that approximate those seen during training. Thus, its effectiveness is
fundamentally bounded by the degree of distribution discrepancy between the
training data and the test queries. With this lens, we dissect CoT reasoning
via three dimensions: task, length, and format. To investigate each dimension,
we design DataAlchemy, an isolated and controlled environment to train LLMs
from scratch and systematically probe them under various distribution
conditions. Our results reveal that CoT reasoning is a brittle mirage that
vanishes when it is pushed beyond training distributions. This work offers a
deeper understanding of why and when CoT reasoning fails, emphasizing the
ongoing challenge of achieving genuine and generalizable reasoning.

</details>


### [528] [Importance Sampling is All You Need: Predict LLM's performance on new benchmark by reusing existing benchmark](https://arxiv.org/abs/2508.01203)
*Junjie Shi,Wei Ma,Shi Ying,Lingxiao Jiang,Yang liu,Bo Du*

Main category: cs.AI

TL;DR: BIS是一个创新的框架，通过分析提示分布而不是执行代码来评估大型语言模型在代码生成任务上的表现。它解决了现有基准测试成本高和易受数据污染的问题，通过重用现有数据和使用重要性加权自编码器来估计新基准测试上的性能。实验证明BIS在预测代码正确性和pass@1指标方面非常准确且具有成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有的代码生成基准测试面临两大挑战：1) 构建高质量测试用例和参考解决方案的成本不断增加；2) 数据污染的风险日益增加，这削弱了基于基准测试的评估的可靠性。因此，需要一种能够减轻这些挑战的评估方法。

Method: BIS是一个以提示为中心的评估框架，它不执行生成的代码，而是仅通过分析提示分布来估计LLM在代码生成任务上的性能指标。该方法基于重要性采样理论，并使用重要性加权自编码器实现，通过重新加权现有注释基准测试的样本来估计在新、未见过的基准测试上的性能。为了稳定估计，该方法引入了权重截断策略，并计算了拟合分布的边际期望。

Result: 在涉及4个CodeLlama模型和9个不同基准测试的8000个评估点上进行的广泛实验表明，BIS框架在代码正确性得分方面实现了1.1%的平均绝对预测误差，最佳和最差情况下的误差分别为0.3%和1.9%。该框架在其他指标上也表现出良好的泛化能力，在pass@1方面达到了2.15%的平均绝对误差。

Conclusion: BIS框架通过分析提示分布来评估代码生成任务中的LLM性能，无需执行生成的代码，从而解决了现有基准测试的成本和数据污染问题。该框架利用重要性采样理论和重要性加权自编码器，通过重新加权现有基准测试的样本来估计新基准测试上的性能。通过引入权重截断策略和计算拟合分布的边际期望来稳定估计，BIS能够为提示选择和污染评估提供快速、可操作的反馈，并显著降低LLM代码相关任务的基准测试成本。

Abstract: With the rapid advancement of large language models , code generation has
become a key benchmark for evaluating LLM capabilities. However, existing
benchmarks face two major challenges: (1) the escalating cost of constructing
high-quality test suites and reference solutions, and (2) the increasing risk
of data contamination, which undermines the reliability of benchmark-based
evaluations. In this paper, we propose BIS, a prompt-centric evaluation
framework that enables ground-truth-free prediction of LLM performance on code
generation tasks. Rather than executing generated code, BIS estimates
performance metrics by analyzing the prompt distribution alone. Built on
importance sampling theory and implemented using Importance Weighted
Autoencoders, our method reweights samples from existing annotated benchmarks
to estimate performance on new, unseen benchmarks. To stabilize the estimation,
we introduce weight truncation strategies and compute marginal expectations
across the fitted distributions. BIS serves as a complementary tool that
supports benchmark development and validation under constrained resources,
offering actionable and quick feedback for prompt selection and contamination
assessment. We conduct extensive experiments involving 8,000 evaluation points
across 4 CodeLlama models and 9 diverse benchmarks. Our framework achieves an
average absolute prediction error of 1.1% for code correctness scores, with
best- and worst-case errors of 0.3% and 1.9%, respectively. It also generalizes
well to other metrics, attaining average absolute errors of 2.15% for pass@1.
These results demonstrate the reliability and broad applicability of BIS, which
can significantly reduce the cost and effort of benchmarking LLMs in
code-related tasks.

</details>


### [529] [Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests](https://arxiv.org/abs/2508.01208)
*Mingchen Mei,Yi Li,YiYao Qian,Zijun Jia*

Main category: cs.AI

TL;DR: 本研究提出了一种创新的故障检测方法，通过整合显著性检验和置信预测框架，为故障检测提供了理论上的风险保证和不确定性量化，解决了现有方法的不足，并在实际应用中表现出优越的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有诊断模型在面对分布偏移等复杂场景时，缺乏严格的风险控制和可靠的不确定性量化，难以保证工业系统的安全性和可靠性。

Method: 本研究将故障检测转化为一个假设检验问题，利用模型残差定义非一致性度量，并结合置信预测框架，通过校准数据集计算新样本的p值，构建包含真实标签的预测集，最后通过分析预测集与预定义标签集的交集进行故障分类。

Result: 实验结果表明，该方法能够提供在名义水平（1-α）或以上实证覆盖率，即使在底层点预测模型表现不佳时也表现出鲁棒性。此外，研究揭示了用户定义的风险水平（α）与效率之间存在可控的权衡，更高的风险容忍度会导致更小的平均预测集。

Conclusion: 该研究提出了一个基于置信预测的故障检测框架，能够提供正式的风险保证，并通过实验验证了其理论特性和鲁棒性，实现了风险控制和效率之间的权衡。

Abstract: Fault detection is crucial for ensuring the safety and reliability of modern
industrial systems. However, a significant scientific challenge is the lack of
rigorous risk control and reliable uncertainty quantification in existing
diagnostic models, particularly when facing complex scenarios such as
distributional shifts. To address this issue, this paper proposes a novel fault
detection method that integrates significance testing with the conformal
prediction framework to provide formal risk guarantees. The method transforms
fault detection into a hypothesis testing task by defining a nonconformity
measure based on model residuals. It then leverages a calibration dataset to
compute p-values for new samples, which are used to construct prediction sets
mathematically guaranteed to contain the true label with a user-specified
probability, $1-\alpha$. Fault classification is subsequently performed by
analyzing the intersection of the constructed prediction set with predefined
normal and fault label sets. Experimental results on cross-domain fault
diagnosis tasks validate the theoretical properties of our approach. The
proposed method consistently achieves an empirical coverage rate at or above
the nominal level ($1-\alpha$), demonstrating robustness even when the
underlying point-prediction models perform poorly. Furthermore, the results
reveal a controllable trade-off between the user-defined risk level ($\alpha$)
and efficiency, where higher risk tolerance leads to smaller average prediction
set sizes. This research contributes a theoretically grounded framework for
fault detection that enables explicit risk control, enhancing the
trustworthiness of diagnostic systems in safety-critical applications and
advancing the field from simple point predictions to informative,
uncertainty-aware outputs.

</details>


### [530] [SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches](https://arxiv.org/abs/2508.01237)
*Cheng Tan,Qi Chen,Jingxuan Wei,Gaowei Wu,Zhangyang Gao,Siyuan Li,Bihui Yu,Ruifeng Guo,Stan Z. Li*

Main category: cs.AI

TL;DR: 提出SketchAgent系统，将手绘草图自动转换为结构化图表，并发布Sketch2Diagram Benchmark数据集以供评估。


<details>
  <summary>Details</summary>
Motivation: 手绘草图到结构化、机器可读图表的转换仍然是一项劳动密集型且主要依赖手动完成的任务，因为草图本身具有固有的模糊性，缺乏自动化图表生成所需的结构约束和语义精度。

Method: SketchAgent是一个多代理系统，通过集成草图识别、符号推理和迭代验证的步骤，将手绘草图转换为结构化图表。

Result: SketchAgent能够生成语义连贯、结构准确的图表，大大减少了人工干预的需要。提出的Sketch2Diagram Benchmark包含八种不同图表类别（如流程图、有向图、模型架构等）的6000多个高质量示例，为评估方法提供了标准。

Conclusion: SketchAgent通过集成草图识别、符号推理和迭代验证，实现了手绘草图到结构化图表的自动化转换，显著减少了人工需求，并在设计、教育和工程领域具有广泛的应用前景，是连接直观绘制和机器可读图表生成的重要一步。此外，该研究还提出了Sketch2Diagram Benchmark，包含超过6000个高质量的示例，涵盖八种不同的图表类型，为评估此类方法提供了全面的基准。

Abstract: Hand-drawn sketches are a natural and efficient medium for capturing and
conveying ideas. Despite significant advancements in controllable natural image
generation, translating freehand sketches into structured, machine-readable
diagrams remains a labor-intensive and predominantly manual task. The primary
challenge stems from the inherent ambiguity of sketches, which lack the
structural constraints and semantic precision required for automated diagram
generation. To address this challenge, we introduce SketchAgent, a multi-agent
system designed to automate the transformation of hand-drawn sketches into
structured diagrams. SketchAgent integrates sketch recognition, symbolic
reasoning, and iterative validation to produce semantically coherent and
structurally accurate diagrams, significantly reducing the need for manual
effort. To evaluate the effectiveness of our approach, we propose the
Sketch2Diagram Benchmark, a comprehensive dataset and evaluation framework
encompassing eight diverse diagram categories, such as flowcharts, directed
graphs, and model architectures. The dataset comprises over 6,000 high-quality
examples with token-level annotations, standardized preprocessing, and rigorous
quality control. By streamlining the diagram generation process, SketchAgent
holds great promise for applications in design, education, and engineering,
while offering a significant step toward bridging the gap between intuitive
sketching and machine-readable diagram generation. The benchmark is released at
https://huggingface.co/datasets/DiagramAgent/Sketch2Diagram-Benchmark.

</details>


### [531] [Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models](https://arxiv.org/abs/2508.01261)
*Sushant Mehta,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.AI

TL;DR: MoE-MLA-RoPE 是一种结合了 MoE、MLA 和 RoPE 的新架构，通过精细路由、专家隔离和负载平衡，实现了高效的语言模型，减少了内存占用并加快了推理速度，同时保持了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决语言模型容量与计算效率之间的根本权衡问题，尤其是在资源受限的部署场景下。

Method: 提出了一种名为 MoE-MLA-RoPE 的新颖架构，该架构结合了混合专家（MoE）、多头潜在注意力（MLA）和旋转位置嵌入（RoPE）。关键创新包括：1) 具有 64 个微专家和 top-k 选择的细粒度专家路由；2) 共享专家隔离，固定 2 个专家用于常见模式，路由到 62 个专用专家中的 6 个；3) 无梯度冲突的负载平衡，以保持专家利用率。

Result: MoE-MLA-RoPE 模型在 KV 缓存内存减少了 68%，推理速度提高了 3.2 倍，同时困惑度仅下降了 0.8%。与参数量相似的模型相比，MoE-MLA-RoPE 验证损失降低了 6.9%，前向传播激活参数减少了 42%。在 FLOP 匹配实验中，性能提升了 11.1%，推理速度提高了 3.2 倍。GPT-4 评估显示，在连贯性、创造性和语法正确性方面均有提高。

Conclusion: MoE-MLA-RoPE 架构的创新相结合，通过精细的路由、共享专家隔离和无冲突的负载平衡，显著提高了语言模型的效率和性能。实验证明，在保持竞争力的困惑度的同时，该模型可以大幅减少 KV 缓存内存占用并加速推理。该研究强调了架构创新在资源受限环境下的语言模型部署中的重要性。

Abstract: We present MoE-MLA-RoPE, a novel architecture combination that combines
Mixture of Experts (MoE) with Multi-head Latent Attention (MLA) and Rotary
Position Embeddings (RoPE) for efficient language modeling. Our approach
addresses the fundamental trade-off between model capacity and computational
efficiency through three key innovations: (1) fine-grained expert routing with
64 micro-experts and top-$k$ selection, enabling flexible specialization
through 3.6 * 10^7 possible expert combinations; (2) shared expert isolation
that dedicates 2 always active experts for common patterns while routing to 6
of 62 specialized experts; and (3) gradient-conflict-free load balancing that
maintains expert utilization without interfering with primary loss
optimization.
  Extensive experiments on models ranging from 17M to 202M parameters
demonstrate that MoE-MLA-RoPE with compression ratio r=d/2 achieves 68% KV
cache memory reduction and 3.2x inference speedup while maintaining competitive
perplexity (0.8% degradation). Compared to the parameters with 53.9M
parameters, MoE-MLA-RoPE improves the validation loss by 6.9% over the vanilla
transformers while using 42% fewer active parameters per forward pass.
FLOP-matched experiments reveal even larger gains: 11.1% improvement with 3.2x
inference acceleration. Automated evaluation using GPT-4 as a judge confirms
quality improvements in generation, with higher scores on coherence (8.1/10),
creativity (7.9/10) and grammatical correctness (8.2/10). Our results establish
that architectural novelty, not parameter scaling, defines the efficiency
frontier for resource-constrained language model deployment.

</details>


### [532] [Win-k: Improved Membership Inference Attacks on Small Language Models](https://arxiv.org/abs/2508.01268)
*Roya Arkhmammadova,Hosein Madadi Tamar,M. Emre Gursoy*

Main category: cs.AI

TL;DR: win-k 是一种新的成员推理攻击，专门针对小型语言模型（SLM）进行优化，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 研究 MIAs 对 SLMs 的有效性，因为现有研究主要集中在大型语言模型（LLMs）上，并且在较小模型上的攻击效果会降低。

Method: 提出了一种名为 win-k 的新成员推理攻击（MIA），该攻击基于最先进的 min-k 攻击。

Result: win-k 在 AUROC、TPR @ 1% FPR 和 FPR @ 99% TPR 指标上优于现有的 MIAs，尤其是在更小的模型上。

Conclusion: win-k 攻击在小型语言模型（SLM）上比现有的 MIAs 表现更好，尤其是在更小的模型上。

Abstract: Small language models (SLMs) are increasingly valued for their efficiency and
deployability in resource-constrained environments, making them useful for
on-device, privacy-sensitive, and edge computing applications. On the other
hand, membership inference attacks (MIAs), which aim to determine whether a
given sample was used in a model's training, are an important threat with
serious privacy and intellectual property implications. In this paper, we study
MIAs on SLMs. Although MIAs were shown to be effective on large language models
(LLMs), they are relatively less studied on emerging SLMs, and furthermore,
their effectiveness decreases as models get smaller. Motivated by this finding,
we propose a new MIA called win-k, which builds on top of a state-of-the-art
attack (min-k). We experimentally evaluate win-k by comparing it with five
existing MIAs using three datasets and eight SLMs. Results show that win-k
outperforms existing MIAs in terms of AUROC, TPR @ 1% FPR, and FPR @ 99% TPR
metrics, especially on smaller models.

</details>


### [533] [KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs](https://arxiv.org/abs/2508.01273)
*Xianda Zheng,Zijian Huang,Meng-Fen Chiang,Michael J. Witbrock,Kaiqi Zhao*

Main category: cs.AI

TL;DR: 提出KCR框架，利用强化学习训练LLM识别和遵循长文本中的逻辑一致性，以解决跨上下文的知识冲突。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的出现，知识冲突在不同来源之间普遍存在且日益增多。在处理多上下文冲突时，LLM常常被冗长和冲突的上下文所混淆。

Method: 提出知识冲突推理（KCR）框架，通过奖励模型选择和遵循具有更强逻辑一致性的上下文来训练骨干LLM，以建立正确的推理过程。首先从冲突的长上下文中提取推理路径（文本或本地知识图），然后使用强化学习使模型学习遵循正确推理路径而非错误路径的范例。

Result: 实验结果表明，该框架显著提高了各种骨干模型在长上下文场景中解决知识冲突的能力，带来了实质性的性能提升。

Conclusion: 该框架显著提高了各种骨干模型在长上下文场景中解决知识冲突的能力，带来了实质性的性能提升。

Abstract: Knowledge conflicts commonly arise across diverse sources, and their
prevalence has increased with the advent of LLMs. When dealing with conflicts
between multiple contexts, also known as \emph{inter-context knowledge
conflicts}, LLMs are often confused by lengthy and conflicting contexts. To
address this challenge, we propose the Knowledge Conflict Reasoning (KCR)
framework, which enhances the ability of LLMs to resolve conflicting knowledge.
The key idea of KCR is to train backbone LLMs to establish a correct reasoning
process by rewarding them for selecting and adhering to the context with
stronger logical consistency when presented with conflicting contexts.
Specifically, we first extract reasoning paths, represented by either text or
local knowledge graphs, from the conflicting long contexts. Subsequently, we
employ Reinforcement Learning to encourage the model to learn the paradigm of
reasoning process that follows correct reasoning paths rather than the
incorrect counterparts. This enables the backbone models to genuinely acquire
the capability to resolve inter-context knowledge conflicts within long
contexts. Experimental results demonstrate that our framework significantly
improves the ability of various backbone models to resolve knowledge conflicts
in long-context scenarios, yielding substantial performance gains.

</details>


### [534] [Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan](https://arxiv.org/abs/2508.01274)
*Jui-Ming Yao,Bing-Cheng Xie,Sheng-Wei Peng,Hao-Yuan Chen,He-Rong Zheng,Bing-Jia Tan,Peter Shaojui Wang,Shun-Feng Su*

Main category: cs.AI

TL;DR: 本研究提出了一种基于微型热管的LED灯珠散热装置，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决LED灯珠散热问题，提高其发光效率和使用寿命。

Method: 本研究针对上述问题，设计了一种基于微型热管的LED灯珠散热装置，并进行了实验验证。

Result: 实验结果表明，该散热装置能够有效地降低LED灯珠的工作温度，提高其发光效率和使用寿命。

Conclusion: 现有的光源和LED灯珠的散热方式主要有空气自然对流、强制风冷、热管冷却、半导体热电制冷和锤击式制冷等几种。

Abstract: Multimodal Large Language Models (MLLMs) process visual, acoustic, and
textual inputs, addressing the limitations of single-modality LLMs. However,
existing benchmarks often overlook tri-modal evaluation in Traditional Chinese
and do not consider inference latency. To address this, we introduce Multi-TW,
the first Traditional Chinese benchmark for evaluating the performance and
latency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice
questions (image and text, audio and text pairs) sourced from official
proficiency tests developed with the Steering Committee for the Test of
Proficiency-Huayu (SC-TOP). We evaluated various any-to-any models and
vision-language models (VLMs) with audio transcription. Our results show that
closed-source models generally outperform open-source ones across modalities,
although open-source models can perform well in audio tasks. End-to-end
any-to-any pipelines offer clear latency advantages compared to VLMs using
separate audio transcription. Multi-TW presents a comprehensive view of model
capabilities and highlights the need for Traditional Chinese fine-tuning and
efficient multimodal architectures.

</details>


### [535] [How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective](https://arxiv.org/abs/2508.01300)
*Ma'ayan Armony,Albert Meroño-Peñuela,Gerard Canal*

Main category: cs.AI

TL;DR: LLM规划能力不足，即使经过NLP改进，也无法匹敌经典规划器，但能提升部分动作的质量和整体成功率。


<details>
  <summary>Details</summary>
Motivation: LLM在规划任务中生成的计划常包含错误或幻觉动作，现有评估方法主要关注成功率，而本文旨在将LLM规划视为NLP任务，进行更全面的分析和恢复。

Method: 提出一个包含NLP评估和三阶段恢复流程的流水线，通过NLP操作LLM生成的计划，并最终使用符号规划器完成计划。

Result: 该流水线将动作质量提高了21.9%至27.5%，但平均只有前2.65个动作可执行，与经典规划器8.4个动作的平均长度相差甚远。

Conclusion: LLM在规划任务中生成的计划缺乏明确的推理依据，并且通过NLP分析和恢复机制改进后的计划质量和可靠性仍无法与经典规划器相比。平均而言，只有前2.65个动作是可执行的，而符号规划器生成的计划平均长度为8.4个动作。

Abstract: The reasoning and planning abilities of Large Language Models (LLMs) have
been a frequent topic of discussion in recent years. Their ability to take
unstructured planning problems as input has made LLMs' integration into AI
planning an area of interest. Nevertheless, LLMs are still not reliable as
planners, with the generated plans often containing mistaken or hallucinated
actions. Existing benchmarking and evaluation methods investigate planning with
LLMs, focusing primarily on success rate as a quality indicator in various
planning tasks, such as validating plans or planning in relaxed conditions. In
this paper, we approach planning with LLMs as a natural language processing
(NLP) task, given that LLMs are NLP models themselves. We propose a recovery
pipeline consisting of an NLP-based evaluation of the generated plans, along
with three stages to recover the plans through NLP manipulation of the
LLM-generated plans, and eventually complete the plan using a symbolic planner.
This pipeline provides a holistic analysis of LLM capabilities in the context
of AI task planning, enabling a broader understanding of the quality of invalid
plans. Our findings reveal no clear evidence of underlying reasoning during
plan generation, and that a pipeline comprising an NLP-based analysis of the
plans, followed by a recovery mechanism, still falls short of the quality and
reliability of classical planners. On average, only the first 2.65 actions of
the plan are executable, with the average length of symbolically generated
plans being 8.4 actions. The pipeline still improves action quality and
increases the overall success rate from 21.9% to 27.5%.

</details>


### [536] [PUZZLED: Jailbreaking LLMs through Word-Based Puzzles](https://arxiv.org/abs/2508.01306)
*Yelim Ahn,Jaejin Lee*

Main category: cs.AI

TL;DR: PUZZLED是一种利用LLM推理能力的新型越狱方法，通过将有害指令中的关键词转化为单词谜题，成功率高达88.8%。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在不同领域得到越来越广泛的应用，确保其安全性已成为一个关键问题。因此，对越狱攻击的研究也在不断增长。

Method: PUZZLED是一种新颖的越狱方法，它利用LLM的推理能力，通过将有害指令中的关键词进行掩码，并将它们作为单词谜题呈现给LLM来解决。该方法设计了三种谜题类型：单词搜索、字母异序词和填字游戏，这些谜题对人类来说很熟悉，但对LLM来说在认知上要求很高。模型必须先解决谜题以揭示被掩码的单词，然后才能继续生成对重建的有害指令的响应。

Result: PUZZLED在五个最先进的LLM上进行了评估，观察到平均攻击成功率（ASR）高达88.8%，其中在GPT-4.1上的成功率为96.5%，在Claude 3.7 Sonnet上的成功率为92.3%。

Conclusion: PUZZLED通过将熟悉的谜语转化为一种有效的越狱策略，并利用LLM的推理能力，成为一种简单而强大的攻击方法。

Abstract: As large language models (LLMs) are increasingly deployed across diverse
domains, ensuring their safety has become a critical concern. In response,
studies on jailbreak attacks have been actively growing. Existing approaches
typically rely on iterative prompt engineering or semantic transformations of
harmful instructions to evade detection. In this work, we introduce PUZZLED, a
novel jailbreak method that leverages the LLM's reasoning capabilities. It
masks keywords in a harmful instruction and presents them as word puzzles for
the LLM to solve. We design three puzzle types-word search, anagram, and
crossword-that are familiar to humans but cognitively demanding for LLMs. The
model must solve the puzzle to uncover the masked words and then proceed to
generate responses to the reconstructed harmful instruction. We evaluate
PUZZLED on five state-of-the-art LLMs and observe a high average attack success
rate (ASR) of 88.8%, specifically 96.5% on GPT-4.1 and 92.3% on Claude 3.7
Sonnet. PUZZLED is a simple yet powerful attack that transforms familiar
puzzles into an effective jailbreak strategy by harnessing LLMs' reasoning
capabilities.

</details>


### [537] [Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work](https://arxiv.org/abs/2508.01323)
*Faruk Alpay,Bugra Kilictas,Taylan Alpay,Hamdi Alakkad*

Main category: cs.AI

TL;DR: 人工智能正在改变人机分工。研究提出了一种数学模型，预测人机任务分配将达到一个稳定状态，其中机器将承担大部分任务，但人类仍将扮演关键的协调角色。即使自动化程度很高，人类也不会完全消失，并且“半人马”式的人机协作模式能带来最大的福利。


<details>
  <summary>Details</summary>
Motivation: 随着大规模人工智能系统的快速发展，如何重新分配人机之间的工作任务成为一个重要问题。本研究旨在形式化这一过程，并探究其长期演变趋势以及对人类角色的影响。

Method: 本研究将任务重新分配形式化为迭代任务委托图，并利用格论不动点工具（塔斯基和巴拿赫）来证明存在至少一个稳定的幂等均衡，并推导出保证唯一性的温和单调性条件。此外，研究还通过离散线性更新、进化复制子动力学和连续Beta分布任务谱等三种动态基准模型来嵌入解析结果。

Result: 研究表明，人机任务分配过程最终会收敛于一个稳定的幂等均衡，即每个任务都由具有持久比较优势的代理（人或机器）执行。在连续模型中，长期自动化份额由公式 $x^* = \alpha / (\alpha + \beta)$ 决定，其中 $\alpha$ 是自动化步伐，$\beta$ 是新的人类中心任务出现的速率。即使在自动化步伐很快的情况下，只要 $\beta > 0$，完全自动化也不会发生。模拟结果预测，到2025年至2045年，自动化将从约10%的工作上升到约65%，但仍有三分之一的任务将由人类承担，这些人类将扮演“工作流协调员”的角色，负责分配、监督和集成AI模块。

Conclusion: 该研究通过形式化和数学模型，揭示了人机协作在人工智能时代如何重新分配任务，并预测了未来的自动化趋势和人类角色的转变，强调了以人为中心的“半人马”协作模式的重要性，并对技能发展、基准设计和AI治理提出了建议。

Abstract: The rapid advance of large-scale AI systems is reshaping how work is divided
between people and machines. We formalise this reallocation as an iterated
task-delegation map and show that--under broad, empirically grounded
assumptions--the process converges to a stable idempotent equilibrium in which
every task is performed by the agent (human or machine) with enduring
comparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski
and Banach), we (i) prove existence of at least one such equilibrium and (ii)
derive mild monotonicity conditions that guarantee uniqueness. In a stylised
continuous model the long-run automated share takes the closed form $x^* =
\alpha / (\alpha + \beta)$, where $\alpha$ captures the pace of automation and
$\beta$ the rate at which new, human-centric tasks appear; hence full
automation is precluded whenever $\beta > 0$. We embed this analytic result in
three complementary dynamical benchmarks--a discrete linear update, an
evolutionary replicator dynamic, and a continuous Beta-distributed task
spectrum--each of which converges to the same mixed equilibrium and is
reproducible from the provided code-free formulas. A 2025-to-2045 simulation
calibrated to current adoption rates projects automation rising from
approximately 10% of work to approximately 65%, leaving a persistent one-third
of tasks to humans. We interpret that residual as a new profession of workflow
conductor: humans specialise in assigning, supervising and integrating AI
modules rather than competing with them. Finally, we discuss implications for
skill development, benchmark design and AI governance, arguing that policies
which promote "centaur" human-AI teaming can steer the economy toward the
welfare-maximising fixed point.

</details>


### [538] [Towards Evaluation for Real-World LLM Unlearning](https://arxiv.org/abs/2508.01324)
*Ke Miao,Yuke Hu,Xiaochen Li,Wenjie Bao,Zhihao Liu,Zhan Qin,Kui Ren*

Main category: cs.AI

TL;DR: 提出了一种新的遗忘评估指标DCUE，它比现有指标更实用、更精确、更鲁棒，并能指导未来遗忘算法的设计。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘评估指标在实际应用、精确性和鲁棒性方面存在局限性，特别是在实际的LLM遗忘场景中。

Method: 提出了一种名为基于分布校正的遗忘评估（DCUE）的新指标。通过识别核心标记并使用验证集校正其置信度分数中的分布偏差来克服现有指标在实用性、精确性和鲁棒性方面的局限性。使用Kolmogorov-Smirnov检验量化评估结果。

Result: 实验结果表明，DCUE克服了现有指标的局限性。

Conclusion: 所提出的DCUE指标克服了现有指标的局限性，并能指导未来更实用、更可靠的遗忘算法的设计。

Abstract: This paper analyzes the limitations of existing unlearning evaluation metrics
in terms of practicality, exactness, and robustness in real-world LLM
unlearning scenarios. To overcome these limitations, we propose a new metric
called Distribution Correction-based Unlearning Evaluation (DCUE). It
identifies core tokens and corrects distributional biases in their confidence
scores using a validation set. The evaluation results are quantified using the
Kolmogorov-Smirnov test. Experimental results demonstrate that DCUE overcomes
the limitations of existing metrics, which also guides the design of more
practical and reliable unlearning algorithms in the future.

</details>


### [539] [NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset](https://arxiv.org/abs/2508.01330)
*Zihan Zheng,Tianle Cui,Chuwen Xie,Jiahui Zhang,Jiahui Pan,Lewei He,Qianglong Chen*

Main category: cs.AI

TL;DR: 本研究提出了新的GUI代理评估基准enchmark和代理架构	exttt{Agent}，解决了现有评估方法的局限性。实验表明enchmark~极具挑战性，RFT能提升模型能力但存在瓶颈，为未来GUI代理发展提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）驱动的图形用户界面（GUI）代理的评估基准在准确性、可复现性和可扩展性方面存在显著的局限性，阻碍了其快速发展。因此，需要新的评估方法和工具来解决这些问题。

Method: 
        1. 提出enchmark，一个基于因果路径原则设计的新的GUI代理评估基准。
        2. 结构化复杂任务为程序化可验证的原子步骤，以确保评估的严谨性、自动化和可复现性。
        3. 开发了	exttt{Agent}，一个针对长期任务优化的层次化代理架构。
        4. 利用	exttt{Agent}生成了高质量、人工验证的轨迹数据集，捕捉了LLM多样化的交互模式。
        5. 使用该数据集对Qwen2.5-VL-7B模型进行了强化微调（RFT）。
        6. 通过实验评估了enchmark~对现有LLM的挑战性，以及RFT对模型性能的影响。
        

Result: 1. enchmark~基准对现有最先进的LLM提出了严峻的挑战，Claude-sonnet-4的加权路径成功率（WPSR）仅为34.6%。
2. 强化微调（RFT）将Qwen2.5-VL-7B模型在GUI执行方面的WPSR从3.3%提升至10.8%，显著提高了其能力。
3. 经过RFT的模型在处理复杂场景时性能下降明显，表明较小模型在整合感知、决策和执行的综合任务上面临能力上限。

Conclusion: 本研究提出了一个新的基准测试enchmark，旨在解决现有大型语言模型（LLM）驱动的图形用户界面（GUI）代理评估基准在准确性、可复现性和可扩展性方面的局限性。通过将复杂任务分解为可验证的原子步骤，并结合我们开发的用于长期任务的层次化代理架构	exttt{Agent}来生成高质量、经过人工验证的轨迹数据集，我们为GUI代理的评估提供了更严格的标准。实验结果表明，enchmark~对现有最先进的LLM提出了严峻的挑战，即使是表现最好的Claude-sonnet-4也仅达到了34.6%的加权路径成功率（WPSR）。此外，虽然强化微调（RFT）显著提升了Qwen2.5-VL-7B模型在GUI执行方面的能力（WPSR从3.3%提升到10.8%），但在处理复杂场景时性能急剧下降，这表明较小模型在整合感知、决策和执行的综合任务上面临固有的能力上限。本研究为社区贡献了一个严格的评估标准和高质量的数据集，以指导未来GUI代理的发展。

Abstract: The rapid advancement of Large Language Model (LLM)-driven Graphical User
Interface (GUI) agents is significantly hampered by the profound limitations of
existing evaluation benchmarks in terms of accuracy, reproducibility, and
scalability. To address this critical gap, we introduce \Benchmark, a novel
benchmark engineered on the principle of Causal Pathways. This design paradigm
structures complex tasks into a series of programmatically verifiable atomic
steps, ensuring a rigorous, fully automated, and reproducible standard for
assessment. Concurrently, to mitigate the inherent capability deficits of
agents, we developed \Agent, a hierarchical agent architecture specifically
optimized for long-horizon tasks. We leveraged this agent to generate a
high-quality, human-verified trajectory dataset that uniquely captures diverse
and even self-correcting interaction patterns of LLMs. We then utilized this
dataset to perform Reinforcement Fine-Tuning (RFT) on the Qwen2.5-VL-7B model.
Our experiments reveal that \Benchmark~presents a formidable challenge to
current state-of-the-art LLMs; even the top-performing Claude-sonnet-4 achieved
a Weighted Pathway Success Rate (WPSR) of only 34.6\%. Moreover, while RFT
substantially improved the smaller model's GUI execution capabilities (WPSR
increased from 3.3\% to 10.8\%), its performance degraded sharply when handling
complex scenarios. This outcome highlights the inherent capability ceiling of
smaller models when faced with comprehensive tasks that integrate perception,
decision-making, and execution. This research contributes a rigorous evaluation
standard and a high-quality dataset to the community, aiming to guide the
future development of GUI agents.

</details>


### [540] [Relation-Aware LNN-Transformer for Intersection-Centric Next-Step Prediction](https://arxiv.org/abs/2508.01368)
*Zhehong Ren,Tianluo Zhang,Yiheng Lu,Yushen Liang,Promethee Spathis*

Main category: cs.AI

TL;DR: 本研究提出了一种新的框架，用于预测下一个位置，该框架以道路为中心，并通过整合关系感知 LNN-Transformer 来克服传统方法的局限性。该模型在准确性和鲁棒性方面均表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的闭世界方法（将选择限制在一组预定义的兴趣点 (POI) 中）通常无法捕捉探索性或目标无关的行为以及城市道路网络的拓扑约束。因此，需要一种新的方法来解决这些限制。

Method: 提出了一种以道路为中心的框架，将道路用户轨迹表示在城市道路交叉口图上，从而放宽了闭世界约束，并支持固定 POI 集之外的下一步预测。为了编码环境背景，我们引入了一种扇区方向 POI 聚合，生成捕获距离、方位、密度和存在线索的紧凑特征。通过将这些线索与结构图嵌入相结合，我们获得了语义基础的节点表示。对于序列建模，我们集成了关系感知 LNN-Transformer——一种结合了连续时间遗忘单元 CfC-LNN 和方位偏差自注意力模块的混合体——以捕获细粒度的时间动态和长距离空间依赖性。

Result: 所提出的模型在准确率和 MRR 方面优于最先进的基线，并且对噪声具有高弹性。

Conclusion: 在城市范围的道路用户轨迹上进行了评估，我们的模型在单跳准确率上比六个最先进的基线高出 17 个百分点，在 MRR 上高出 10 个百分点，并且在 GPS 扰动为 50 米的情况下，准确率仅下降 2.4 个百分点，在 25% POI 噪声下，准确率仅下降 8.9 个百分点，保持了高韧性。

Abstract: Next-step location prediction plays a pivotal role in modeling human
mobility, underpinning applications from personalized navigation to strategic
urban planning. However, approaches that assume a closed world - restricting
choices to a predefined set of points of interest (POIs) - often fail to
capture exploratory or target-agnostic behavior and the topological constraints
of urban road networks. Hence, we introduce a road-node-centric framework that
represents road-user trajectories on the city's road-intersection graph,
thereby relaxing the closed-world constraint and supporting next-step
forecasting beyond fixed POI sets. To encode environmental context, we
introduce a sector-wise directional POI aggregation that produces compact
features capturing distance, bearing, density and presence cues. By combining
these cues with structural graph embeddings, we obtain semantically grounded
node representations. For sequence modeling, we integrate a Relation-Aware
LNN-Transformer - a hybrid of a Continuous-time Forgetting Cell CfC-LNN and a
bearing-biased self-attention module - to capture both fine-grained temporal
dynamics and long-range spatial dependencies. Evaluated on city-scale road-user
trajectories, our model outperforms six state-of-the-art baselines by up to 17
percentage points in accuracy at one hop and 10 percentage points in MRR, and
maintains high resilience under noise, losing only 2.4 percentage points in
accuracy at one under 50 meter GPS perturbation and 8.9 percentage points in
accuracy at one hop under 25 percent POI noise.

</details>


### [541] [TripTailor: A Real-World Benchmark for Personalized Travel Planning](https://arxiv.org/abs/2508.01432)
*Yuanzhe Shen,Kaimin Wang,Changze Lv,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.AI

TL;DR: TripTailor是一个包含真实旅行数据的新基准，用于评估大型语言模型在旅行规划中的表现，结果显示当前模型仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在旅行规划任务中表现出潜力，但当前的基准测试依赖不切实际的模拟数据，并且评估指标过于侧重约束条件，未能全面反映行程质量。因此，需要一个更真实、更全面的评估框架来推动该领域的发展。

Method: 提出TripTailor基准数据集，包含大量真实世界的兴趣点（POIs）和旅行计划，并进行实验评估现有大型语言模型在旅行规划任务上的表现，识别出可行性、合理性和个性化定制等关键挑战。

Result: 当前最先进的大型语言模型在旅行规划任务上表现不佳，少于10%的生成行程能达到人类水平。研究识别出在可行性、合理性和个性化定制方面存在关键挑战。

Conclusion: TripTailor是一个针对真实世界个性化旅行规划设计的基准数据集，包含超过50万个真实兴趣点和近4000个多样化的旅行计划，旨在克服现有基准测试中数据不真实和评估指标不全面的问题。实验表明，当前最先进的大型语言模型生成的行程中，只有不到10%能达到人类水平的表现，并且在可行性、合理性和个性化定制方面存在挑战。研究希望TripTailor能推动旅行规划Agent的发展，使其能更好地理解和满足用户需求，生成实用的行程。

Abstract: The continuous evolution and enhanced reasoning capabilities of large
language models (LLMs) have elevated their role in complex tasks, notably in
travel planning, where demand for personalized, high-quality itineraries is
rising. However, current benchmarks often rely on unrealistic simulated data,
failing to reflect the differences between LLM-generated and real-world
itineraries. Existing evaluation metrics, which primarily emphasize
constraints, fall short of providing a comprehensive assessment of the overall
quality of travel plans. To address these limitations, we introduce TripTailor,
a benchmark designed specifically for personalized travel planning in
real-world scenarios. This dataset features an extensive collection of over
500,000 real-world points of interest (POIs) and nearly 4,000 diverse travel
itineraries, complete with detailed information, providing a more authentic
evaluation framework. Experiments show that fewer than 10\% of the itineraries
generated by the latest state-of-the-art LLMs achieve human-level performance.
Moreover, we identify several critical challenges in travel planning, including
the feasibility, rationality, and personalized customization of the proposed
solutions. We hope that TripTailor will drive the development of travel
planning agents capable of understanding and meeting user needs while
generating practical itineraries. Our code and dataset are available at
https://github.com/swxkfm/TripTailor

</details>


### [542] [$R^2$-CoD: Understanding Text-Graph Complementarity in Relational Reasoning via Knowledge Co-Distillation](https://arxiv.org/abs/2508.01475)
*Zhen Wu,Ritam Dutt,Luke M. Breitfeller,Armineh Nourbakhsh,Siddharth Parekh,Carolyn Rosé*

Main category: cs.AI

TL;DR: This paper analyzes how text and graph information interact in hybrid NLP models for relational reasoning, using a co-distillation method to understand when and why combining these sources is beneficial.


<details>
  <summary>Details</summary>
Motivation: Prior research has explored leveraging text and graphs for relational reasoning, but a systematic understanding of their interplay and the benefits of hybrid models is lacking.

Method: We employ an analysis-driven approach using a unified architecture that supports knowledge co-distillation (CoD) to investigate text-graph representation complementarity. We examine five tasks involving relational reasoning with varying degrees of reliance on text and graph structures and track the evolution of these dual representations during training.

Result: Our analysis reveals interpretable patterns of alignment and divergence between text and graph representations, offering insights into the effectiveness of integrating them for different relational reasoning tasks.

Conclusion: We uncover interpretable patterns of alignment and divergence in text and graph representations during training, providing insights into when and why their integration is beneficial for relational reasoning tasks.

Abstract: Relational reasoning lies at the core of many NLP tasks, drawing on
complementary signals from text and graphs. While prior research has
investigated how to leverage this dual complementarity, a detailed and
systematic understanding of text-graph interplay and its effect on hybrid
models remains underexplored. We take an analysis-driven approach to
investigate text-graph representation complementarity via a unified
architecture that supports knowledge co-distillation (CoD). We explore five
tasks involving relational reasoning that differ in how text and graph
structures encode the information needed to solve that task. By tracking how
these dual representations evolve during training, we uncover interpretable
patterns of alignment and divergence, and provide insights into when and why
their integration is beneficial.

</details>


### [543] [CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics](https://arxiv.org/abs/2508.01476)
*Arindam Khanda,Anurag Satpathy,Amit Jha,Sajal K. Das*

Main category: cs.AI

TL;DR: CARGO framework optimizes EV delivery routes and charging, reducing costs by up to 39% compared to EDF and 22% compared to NDF.


<details>
  <summary>Details</summary>
Motivation: The growing interest in sustainable logistics has led to the exploration of electric vehicles (EVs) for urban deliveries. However, EVs' limited battery capacity necessitates careful planning for recharging, considering factors like charging point availability, cost, proximity, and vehicle state of charge. This paper aims to address these challenges by optimizing EV delivery routes and charging strategies.

Method: This paper proposes the CARGO framework, which addresses the EV-based delivery route planning problem (EDRP). It includes a mixed integer linear programming (MILP)-based exact solution and a heuristic method for jointly optimizing route planning and charging within time windows. The methods were evaluated using real-world datasets and compared against Earliest Deadline First (EDF) and Nearest Delivery First (NDF) baseline strategies.

Result: The CARGO framework, particularly the heuristic method, achieved up to 39% and 22% reductions in charging cost compared to EDF and NDF, respectively, while completing a comparable number of deliveries. This indicates the efficiency and effectiveness of the proposed approach.

Conclusion: EV-based deliveries are a viable option for urban distribution, and the proposed CARGO framework effectively optimizes route planning and charging, demonstrating significant cost reductions compared to existing strategies.

Abstract: With growing interest in sustainable logistics, electric vehicle (EV)-based
deliveries offer a promising alternative for urban distribution. However, EVs
face challenges due to their limited battery capacity, requiring careful
planning for recharging. This depends on factors such as the charging point
(CP) availability, cost, proximity, and vehicles' state of charge (SoC). We
propose CARGO, a framework addressing the EV-based delivery route planning
problem (EDRP), which jointly optimizes route planning and charging for
deliveries within time windows. After proving the problem's NP-hardness, we
propose a mixed integer linear programming (MILP)-based exact solution and a
computationally efficient heuristic method. Using real-world datasets, we
evaluate our methods by comparing the heuristic to the MILP solution, and
benchmarking it against baseline strategies, Earliest Deadline First (EDF) and
Nearest Delivery First (NDF). The results show up to 39% and 22% reductions in
the charging cost over EDF and NDF, respectively, while completing comparable
deliveries.

</details>


### [544] [WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning](https://arxiv.org/abs/2508.01495)
*Jingtian Yan,Stephen F. Smith,Jiaoyang Li*

Main category: cs.AI

TL;DR: WinkTPG通过将MAPF计划精炼为动力学上可行的计划来解决多代理路径规划问题，提高了解决方案的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 标准的MAPF算法依赖于简化的动力学模型，导致代理无法直接遵循生成的MAPF计划。为了解决这个问题，需要一种能够将MAPF计划精炼为动力学上可行的计划的方法。

Method: kTPG是一种多代理速度优化算法，可以有效地将MAPF计划精炼为动力学上可行的计划，同时考虑不确定性并保持无碰撞性。WinkTPG在kTPG的基础上，引入了基于窗口的机制，动态地整合代理信息。

Result: WinkTPG可以为多达1000个代理生成速度剖面，并且比现有的MAPF执行方法提高了51.7%的解决方案质量。

Conclusion: WinkTPG是一个增量式精炼MAPF计划的MAPF执行框架，通过基于窗口的机制动态地在执行过程中整合代理信息来减少不确定性。实验表明，WinkTPG可以在1秒内为多达1000个代理生成速度剖面，并且与现有的MAPF执行方法相比，解决方案质量提高了51.7%。

Abstract: Planning collision-free paths for a large group of agents is a challenging
problem with numerous real-world applications. While recent advances in
Multi-Agent Path Finding (MAPF) have shown promising progress, standard MAPF
algorithms rely on simplified kinodynamic models, preventing agents from
directly following the generated MAPF plan. To bridge this gap, we propose
kinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed
optimization algorithm that efficiently refines a MAPF plan into a
kinodynamically feasible plan while accounting for uncertainties and preserving
collision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a
MAPF execution framework that incrementally refines MAPF plans using a
window-based mechanism, dynamically incorporating agent information during
execution to reduce uncertainty. Experiments show that WinkTPG can generate
speed profiles for up to 1,000 agents in 1 second and improves solution quality
by up to 51.7% over existing MAPF execution methods.

</details>


### [545] [Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning](https://arxiv.org/abs/2508.01543)
*Derin Cayir,Renjie Tao,Rashi Rungta,Kai Sun,Sean Chen,Haidar Khan,Minseok Kim,Julia Reinspach,Yue Liu*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress through
preference-based fine-tuning, which critically depends on the quality of the
underlying training data. While human feedback is essential for improving data
quality, it is costly and does not scale well. In this paper, we introduce
Refine-n-Judge, an automated iterative approach that leverages a single LLM as
both a refiner and a judge to enhance dataset quality. Unlike existing
iterative refinement methods, Refine-n-Judge employs an LLM to both generate
refinements and explicitly evaluate each improvement, ensuring that every
iteration meaningfully enhances the dataset without requiring additional human
annotation or a separate reward model. At each step, the LLM refines a response
and judges whether the refinement is an improvement over the previous answer.
This process continues until the LLM prefers the initial answer over the
refinement, indicating no further improvements. This produces sequences of
increasing quality, preference-labeled responses ideal for fine-tuning.
  We demonstrate the effectiveness of Refine-n-Judge across a range of public
datasets spanning five corpora, targeting tasks such as coding, math, and
conversation. Models (Llama 3.1-8B and Llama 3.3-70B) fine-tuned on
Refine-n-Judge-enhanced datasets were preferred by LLM judges in over 74% of
comparisons against models tuned on the original dataset by GPT-4.
Additionally, we report performance gains: +5% on AlpacaEval and AlpacaEval
2.0, and +19% on MT-Bench. Our results indicate that Refine-n-Judge produces
high-quality datasets and scalable model improvements.

</details>


### [546] [Getting out of the Big-Muddy: Escalation of Commitment in LLMs](https://arxiv.org/abs/2508.01545)
*Emilio Barkett,Olivia Long,Paul Kröger*

Main category: cs.AI

TL;DR: LLM的偏见表现高度依赖于情境，在多主体和有压力的情境下，LLM表现出显著的承诺升级偏见。


<details>
  <summary>Details</summary>
Motivation: 理解LLM何时表现出承诺升级等认知偏见是一个独特的挑战，尽管这些偏见在人类中已有记载，但尚不清楚它们是否在LLM中一致出现或需要特定的触发条件。

Method: 通过一个两阶段投资任务，在四种实验条件下进行研究：模型作为投资者、模型作为顾问、多主体审议和复合压力情景。

Result: 研究发现，LLM的偏见表现高度依赖于情境。在个体决策情境下，LLM表现出强大的理性成本效益逻辑，承诺升级极少。然而，多主体审议揭示了一个显著的层级效应：不对称层级表现出中等程度的升级（46.2%），而对称的同伴决策则导致近乎普遍的升级（99.2%）。同样，在复合组织和个人压力下，模型表现出高度的承诺升级（对失败部门的平均分配为68.95%）。

Conclusion: LLM的偏见表现严重依赖于社会和组织背景，而不是固有的，这对于可能自然出现这些情况的多主体系统和无监督操作的部署具有重要意义。

Abstract: Large Language Models (LLMs) are increasingly deployed in autonomous
decision-making roles across high-stakes domains. However, since models are
trained on human-generated data, they may inherit cognitive biases that
systematically distort human judgment, including escalation of commitment,
where decision-makers continue investing in failing courses of action due to
prior investment. Understanding when LLMs exhibit such biases presents a unique
challenge. While these biases are well-documented in humans, it remains unclear
whether they manifest consistently in LLMs or require specific triggering
conditions. This paper investigates this question using a two-stage investment
task across four experimental conditions: model as investor, model as advisor,
multi-agent deliberation, and compound pressure scenario. Across N = 6,500
trials, we find that bias manifestation in LLMs is highly context-dependent. In
individual decision-making contexts (Studies 1-2, N = 4,000), LLMs demonstrate
strong rational cost-benefit logic with minimal escalation of commitment.
However, multi-agent deliberation reveals a striking hierarchy effect (Study 3,
N = 500): while asymmetrical hierarchies show moderate escalation rates
(46.2%), symmetrical peer-based decision-making produces near-universal
escalation (99.2%). Similarly, when subjected to compound organizational and
personal pressures (Study 4, N = 2,000), models exhibit high degrees of
escalation of commitment (68.95% average allocation to failing divisions).
These findings reveal that LLM bias manifestation depends critically on social
and organizational context rather than being inherent, with significant
implications for the deployment of multi-agent systems and unsupervised
operations where such conditions may emerge naturally.

</details>


### [547] [Empowering Tabular Data Preparation with Language Models: Why and How?](https://arxiv.org/abs/2508.01556)
*Mengshi Chen,Yuxiang Sun,Tengchao Li,Jianwei Wang,Kai Wang,Xuemin Lin,Ying Zhang,Wenjie Zhang*

Main category: cs.AI

TL;DR: 本调查系统性地分析了大型语言模型在表格数据采集、集成、清洗和转换四个核心阶段在表格数据准备中的作用、优势和应用方法。


<details>
  <summary>Details</summary>
Motivation: 随着数据驱动任务的日益复杂，传统表格数据准备方法面临挑战。大型语言模型（LLMs）为自动化和支持表格数据准备提供了新的机遇，但其适用性和有效性仍需系统性探索。

Method: 对数据采集、集成、清洗和转换这四个核心阶段的表格数据准备过程中的语言模型作用进行了系统性分析。

Result: 该调查分析了语言模型在增强表格数据准备过程中的作用，并为每个阶段提出了结合语言模型和其他组件以应对不同准备任务的集成分析、关键进展和未来管线。

Conclusion: 大型语言模型在表格数据准备的各个阶段都具有巨大潜力，但仍需进一步研究以实现其全部价值。

Abstract: Data preparation is a critical step in enhancing the usability of tabular
data and thus boosts downstream data-driven tasks. Traditional methods often
face challenges in capturing the intricate relationships within tables and
adapting to the tasks involved. Recent advances in Language Models (LMs),
especially in Large Language Models (LLMs), offer new opportunities to automate
and support tabular data preparation. However, why LMs suit tabular data
preparation (i.e., how their capabilities match task demands) and how to use
them effectively across phases still remain to be systematically explored. In
this survey, we systematically analyze the role of LMs in enhancing tabular
data preparation processes, focusing on four core phases: data acquisition,
integration, cleaning, and transformation. For each phase, we present an
integrated analysis of how LMs can be combined with other components for
different preparation tasks, highlight key advancements, and outline
prospective pipelines.

</details>


### [548] [One Subgoal at a Time: Zero-Shot Generalization to Arbitrary Linear Temporal Logic Requirements in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.01561)
*Zijian Guo,İlker Işık,H. M. Sabbir Ahmad,Wenchao Li*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generalizing to complex and temporally extended task objectives and safety
constraints remains a critical challenge in reinforcement learning (RL). Linear
temporal logic (LTL) offers a unified formalism to specify such requirements,
yet existing methods are limited in their abilities to handle nested
long-horizon tasks and safety constraints, and cannot identify situations when
a subgoal is not satisfiable and an alternative should be sought. In this
paper, we introduce GenZ-LTL, a method that enables zero-shot generalization to
arbitrary LTL specifications. GenZ-LTL leverages the structure of B\"uchi
automata to decompose an LTL task specification into sequences of reach-avoid
subgoals. Contrary to the current state-of-the-art method that conditions on
subgoal sequences, we show that it is more effective to achieve zero-shot
generalization by solving these reach-avoid problems \textit{one subgoal at a
time} through proper safe RL formulations. In addition, we introduce a novel
subgoal-induced observation reduction technique that can mitigate the
exponential complexity of subgoal-state combinations under realistic
assumptions. Empirical results show that GenZ-LTL substantially outperforms
existing methods in zero-shot generalization to unseen LTL specifications.

</details>


### [549] [Polymorphic Combinatorial Frameworks (PCF): Guiding the Design of Mathematically-Grounded, Adaptive AI Agents](https://arxiv.org/abs/2508.01581)
*David Pearl,Matthew Murphy,James Intriligator*

Main category: cs.AI

TL;DR: PCF uses LLMs and math frameworks to create adaptable AI agents by defining agent behaviors in a multidimensional SPARK space. It allows real-time adaptation and was tested via simulations, showing trends in performance across different complexity levels.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of static agent architectures in complex, dynamic environments by enabling real-time parameter reconfiguration through mathematically-grounded combinatorial spaces, allowing agents to adapt their core behavioral traits dynamically.

Method: The Polymorphic Combinatorial Framework (PCF) leverages LLMs and mathematical frameworks (combinatorial logic, topos theory, rough fuzzy set theory) to guide the design of solution spaces and adaptive AI agents. It defines a multidimensional SPARK parameter space (Skills, Personalities, Approaches, Resources, Knowledge) for agent behaviors. LLMs are used to parameterize these spaces and estimate parameter values/variabilities. The framework was tested using mock café domains with varying complexity levels and over 1.25 million Monte Carlo simulations.

Result: The study revealed trends in agent adaptability and performance across five complexity tiers, indicating diminishing returns at higher complexity levels, which highlights thresholds for scalable designs. PCF allows for the generation of optimized agent configurations for specific scenarios while maintaining logical consistency.

Conclusion: PCF enables the generation of optimized agent configurations for specific scenarios while maintaining logical consistency and supports scalable, dynamic, explainable, and ethical AI applications, paving the way for adaptable and cooperative next-generation polymorphic agents.

Abstract: The Polymorphic Combinatorial Framework (PCF) leverages Large Language Models
(LLMs) and mathematical frameworks to guide the meta-prompt enabled design of
solution spaces and adaptive AI agents for complex, dynamic environments.
Unlike static agent architectures, PCF enables real-time parameter
reconfiguration through mathematically-grounded combinatorial spaces, allowing
agents to adapt their core behavioral traits dynamically. Grounded in
combinatorial logic, topos theory, and rough fuzzy set theory, PCF defines a
multidimensional SPARK parameter space (Skills, Personalities, Approaches,
Resources, Knowledge) to capture agent behaviors. This paper demonstrates how
LLMs can parameterize complex spaces and estimate likely parameter
values/variabilities. Using PCF, we parameterized mock caf\'e domains (five
levels of complexity), estimated variables/variabilities, and conducted over
1.25 million Monte Carlo simulations. The results revealed trends in agent
adaptability and performance across the five complexity tiers, with diminishing
returns at higher complexity levels highlighting thresholds for scalable
designs. PCF enables the generation of optimized agent configurations for
specific scenarios while maintaining logical consistency. This framework
supports scalable, dynamic, explainable, and ethical AI applications in domains
like customer service, healthcare, robotics, and collaborative systems, paving
the way for adaptable and cooperative next-generation polymorphic agents.

</details>


### [550] [A Multi-Agent Pokemon Tournament for Evaluating Strategic Reasoning of Large Language Models](https://arxiv.org/abs/2508.01623)
*Tadisetty Sai Yashwanth,Dhatri C*

Main category: cs.AI

TL;DR: A competitive tournament system, LLM Pokemon League, uses LLMs as agents in Pok'emon battles to benchmark AI strategic reasoning and competitive learning by analyzing their decision-making, adaptability, and tactics.


<details>
  <summary>Details</summary>
Motivation: The motivation is to analyze and compare the reasoning, adaptability, and tactical depth of different LLMs in a Pok'emon battle environment, providing a platform to study AI behavior and strategy development.

Method: The research presents a competitive tournament system, LLM Pokemon League, where Large Language Models (LLMs) act as intelligent agents simulating strategic decision-making in Pok'emon battles. The system uses a single-elimination tournament with diverse AI trainers and captures detailed decision logs for analysis.

Result: The system captures detailed decision logs, including team-building rationale, action selection strategies, and switching decisions, enabling rich exploration into comparative AI behavior, battle psychology, and meta-strategy development.

Conclusion: LLM Pokemon League serves as a novel benchmark for AI research, enabling exploration into comparative AI behavior, battle psychology, and meta-strategy development in constrained, rule-based game environments. It investigates how modern LLMs understand, adapt, and optimize decisions under uncertainty.

Abstract: This research presents LLM Pokemon League, a competitive tournament system
that leverages Large Language Models (LLMs) as intelligent agents to simulate
strategic decision-making in Pok\'emon battles. The platform is designed to
analyze and compare the reasoning, adaptability, and tactical depth exhibited
by different LLMs in a type-based, turn-based combat environment. By
structuring the competition as a single-elimination tournament involving
diverse AI trainers, the system captures detailed decision logs, including
team-building rationale, action selection strategies, and switching decisions.
The project enables rich exploration into comparative AI behavior, battle
psychology, and meta-strategy development in constrained, rule-based game
environments. Through this system, we investigate how modern LLMs understand,
adapt, and optimize decisions under uncertainty, making Pok\'emon League a
novel benchmark for AI research in strategic reasoning and competitive
learning.

</details>


### [551] [QCBench: Evaluating Large Language Models on Domain-Specific Quantitative Chemistry](https://arxiv.org/abs/2508.01670)
*Jiaqing Xie,Weida Wang,Ben Gao,Zhuo Yang,Haiyuan Wan,Shufei Zhang,Tianfan Fu,Yuqiang Li*

Main category: cs.AI

TL;DR: QCBench是一个包含350个计算化学问题的基准，用于评估LLM的量化推理能力。结果表明，LLM在处理复杂化学问题时准确性下降。


<details>
  <summary>Details</summary>
Motivation: 填补LLM在严谨、循序渐进的量化推理能力评估方面的空白。

Method: 提出QCBench基准，包含350个计算化学问题，覆盖7个化学子领域和3个难度层级，旨在评估LLM的量化推理能力。

Result: 评估结果显示，随着任务复杂度的增加，LLM的表现普遍下降，凸显了当前语言流畅性与科学计算准确性之间的差距。

Conclusion: LLM在科学计算方面的准确性仍有提升空间，尤其是在处理复杂问题时。

Abstract: Quantitative chemistry plays a fundamental role in chemistry research,
enabling precise predictions of molecular properties, reaction outcomes, and
material behaviors. While large language models (LLMs) have shown promise in
chemistry-related tasks, their ability to perform rigorous, step-by-step
quantitative reasoning remains underexplored. To fill this blank, we propose
QCBench, a Quantitative Chemistry benchmark comprising 350 computational
chemistry problems across 7 chemistry subfields (analytical chemistry,
bio/organic chemistry, general chemistry, inorganic chemistry, physical
chemistry, polymer chemistry and quantum chemistry), categorized into three
hierarchical tiers-basic, intermediate, and expert-to systematically evaluate
the mathematical reasoning abilities of large language models (LLMs). Designed
to minimize shortcuts and emphasize stepwise numerical reasoning, each problem
focuses on pure calculations rooted in real-world chemical vertical fields.
QCBench enables fine-grained diagnosis of computational weaknesses, reveals
model-specific limitations across difficulty levels, and lays the groundwork
for future improvements such as domain adaptive fine-tuning or multi-modal
integration. Evaluations on 19 LLMs demonstrate a consistent performance
degradation with increasing task complexity, highlighting the current gap
between language fluency and scientific computation accuracy.

</details>


### [552] [T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval](https://arxiv.org/abs/2508.01680)
*Dong Li,Yichen Niu,Ying Ai,Xiang Zou,Biqing Qi,Jianxing Liu*

Main category: cs.AI

TL;DR: T-GRAG 是一个处理 LLM 知识限制的框架，通过考虑知识随时间的变化来改进 GraphRAG。它包含五个组件，并引入了一个新的数据集 Time-LongQA 来评估其性能，结果表明 T-GRAG 在长期问答方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 GraphRAG 方法很大程度上忽略了知识的时间动态，导致时间歧义、时间不敏感检索和语义冗余等问题。为了克服这些限制，需要一个能够对知识随时间演变进行建模的框架。

Method: T-GRAG 是一个动态的、时间感知的检索增强生成框架，它对知识随时间的演变进行建模。它包括五个关键组件：(1) 时间知识图谱生成器，用于创建带时间戳的、不断演变的图结构；(2) 时间查询分解机制，将复杂的时间查询分解为可管理的子查询；(3) 三层交互式检索器，跨时间子图逐步过滤和优化检索；(4) 源文本提取器，用于减轻噪声；(5) 基于 LLM 的生成器，用于合成上下文和时间上准确的响应。该研究还引入了一个名为 Time-LongQA 的新基准数据集，该数据集基于真实的上市公司年度报告，旨在测试跨不断演变的知识的时间推理能力。

Result: T-GRAG 在检索准确性和响应相关性方面，在时间约束下，显著优于现有的 RAG 和 GraphRAG 基线。Time-LongQA 数据集被证明是测试跨演变知识的时间推理的有效基准。

Conclusion: T-GRAG 通过对知识演化进行建模，在检索准确性和响应相关性方面显著优于现有的 RAG 和 GraphRAG 基线，并且在时间约束下，在长期问答方面表现稳健。这突显了对知识演化进行建模对于实现稳健的长期问答的必要性。

Abstract: Large language models (LLMs) have demonstrated strong performance in natural
language generation but remain limited in knowle-
  dge-intensive tasks due to outdated or incomplete internal knowledge.
Retrieval-Augmented Generation (RAG) addresses this by incorporating external
retrieval, with GraphRAG further enhancing performance through structured
knowledge graphs and multi-hop reasoning. However, existing GraphRAG methods
largely ignore the temporal dynamics of knowledge, leading to issues such as
temporal ambiguity, time-insensitive retrieval, and semantic redundancy. To
overcome these limitations, we propose Temporal GraphRAG (T-GRAG), a dynamic,
temporally-aware RAG framework that models the evolution of knowledge over
time. T-GRAG consists of five key components: (1) a Temporal Knowledge Graph
Generator that creates time-stamped, evolving graph structures; (2) a Temporal
Query Decomposition mechanism that breaks complex temporal queries into
manageable sub-queries; (3) a Three-layer Interactive Retriever that
progressively filters and refines retrieval across temporal subgraphs; (4) a
Source Text Extractor to mitigate noise; and (5) a LLM-based Generator that
synthesizes contextually and temporally accurate responses. We also introduce
Time-LongQA, a novel benchmark dataset based on real-world corporate annual
reports, designed to test temporal reasoning across evolving knowledge.
Extensive experiments show that T-GRAG significantly outperforms prior RAG and
GraphRAG baselines in both retrieval accuracy and response relevance under
temporal constraints, highlighting the necessity of modeling knowledge
evolution for robust long-text question answering. Our code is publicly
available on the T-GRAG

</details>


### [553] [SURE-Med: Systematic Uncertainty Reduction for Enhanced Reliability in Medical Report Generation](https://arxiv.org/abs/2508.01693)
*Yuhang Gu,Xingyu Hu,Yuyu Fan,Xulin Yan,Longhuan Xu,Peng peng*

Main category: cs.AI

TL;DR: SURE-Med框架通过解决视觉、分布和上下文不确定性问题，显著提高了自动化医疗报告生成的可靠性和准确性，并在MIMIC-CXR和IU-Xray基准上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 自动化医疗报告生成（MRG）虽然前景广阔，但临床部署受到视觉不确定性（由噪声或不正确的视图注释引起）、标签分布不确定性（由长尾分布引起）和上下文不确定性（由未经证实的历史报告引起）三大挑战的阻碍，这些挑战限制了MRG系统的可靠性和临床可信度。

Method: 提出了一种名为SURE-Med的统一框架，通过三个关键维度来系统地减少不确定性：视觉、分布和上下文。具体包括：1. 视觉不确定性：提出一个“面向额叶的视图修复重采样”模块，用于纠正视图注释错误并自适应地选择补充视图中的信息特征。2. 标签分布不确定性：引入“对标记敏感的学习”目标，增强对关键诊断句子的建模，并重新加权代表性不足的诊断术语，以提高对罕见病的敏感性。3. 上下文不确定性：设计“上下文证据过滤器”来验证和选择性地整合与当前图像一致的先验信息，从而有效抑制幻觉。

Result: 在MIMIC-CXR和IU-Xray基准上的大量实验表明，SURE-Med实现了最先进的性能。

Conclusion: SURE-Med通过整体性地减少多模态输入的不确定性，为医疗报告生成设定了新的可靠性基准，并为值得信赖的临床决策支持提供了坚实的一步。

Abstract: Automated medical report generation (MRG) holds great promise for reducing
the heavy workload of radiologists. However, its clinical deployment is
hindered by three major sources of uncertainty. First, visual uncertainty,
caused by noisy or incorrect view annotations, compromises feature extraction.
Second, label distribution uncertainty, stemming from long-tailed disease
prevalence, biases models against rare but clinically critical conditions.
Third, contextual uncertainty, introduced by unverified historical reports,
often leads to factual hallucinations. These challenges collectively limit the
reliability and clinical trustworthiness of MRG systems. To address these
issues, we propose SURE-Med, a unified framework that systematically reduces
uncertainty across three critical dimensions: visual, distributional, and
contextual. To mitigate visual uncertainty, a Frontal-Aware View Repair
Resampling module corrects view annotation errors and adaptively selects
informative features from supplementary views. To tackle label distribution
uncertainty, we introduce a Token Sensitive Learning objective that enhances
the modeling of critical diagnostic sentences while reweighting
underrepresented diagnostic terms, thereby improving sensitivity to infrequent
conditions. To reduce contextual uncertainty, our Contextual Evidence Filter
validates and selectively incorporates prior information that aligns with the
current image, effectively suppressing hallucinations. Extensive experiments on
the MIMIC-CXR and IU-Xray benchmarks demonstrate that SURE-Med achieves
state-of-the-art performance. By holistically reducing uncertainty across
multiple input modalities, SURE-Med sets a new benchmark for reliability in
medical report generation and offers a robust step toward trustworthy clinical
decision support.

</details>


### [554] [DeepVIS: Bridging Natural Language and Data Visualization Through Step-wise Reasoning](https://arxiv.org/abs/2508.01700)
*Zhihao Shuai,Boyan Li,Siyu Yan,Yuyu Luo,Weikai Yang*

Main category: cs.AI

TL;DR: 本文提出了一种将Chain-of-Thought（CoT）推理集成到自然语言到可视化（NL2VIS）流程中的方法，旨在解决现有方法缺乏透明度和可控性的问题。通过设计CoT推理过程、创建nvBench-CoT数据集和开发DeepVIS交互界面，该方法能够生成更高质量的可视化，并允许用户检查和调整推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有NL2VIS方法如同黑盒子，缺乏透明的推理过程，用户无法理解设计思路或优化不佳结果。本文旨在解决这一问题，通过集成CoT推理来增强NL2VIS的透明度和可控性。

Method: 本文设计了一个全面的NL2VIS的CoT推理过程，并开发了一个自动化的流程来为现有数据集添加结构化的推理步骤。此外，还引入了nvBench-CoT数据集用于模型微调，并开发了DeepVIS交互式可视化界面来检查推理步骤、识别错误和进行针对性调整。

Result: CoT框架在NL2VIS任务中取得了当前最先进的性能，并能提供可供用户理解和交互的推理步骤。

Conclusion: CoT框架有效提升了NL2VIS的质量，并为用户提供了可洞察的推理步骤，相关方法通过基准评估、用例研究和用户研究得到验证。

Abstract: Although data visualization is powerful for revealing patterns and
communicating insights, creating effective visualizations requires familiarity
with authoring tools and often disrupts the analysis flow. While large language
models show promise for automatically converting analysis intent into
visualizations, existing methods function as black boxes without transparent
reasoning processes, which prevents users from understanding design rationales
and refining suboptimal outputs. To bridge this gap, we propose integrating
Chain-of-Thought (CoT) reasoning into the Natural Language to Visualization
(NL2VIS) pipeline. First, we design a comprehensive CoT reasoning process for
NL2VIS and develop an automatic pipeline to equip existing datasets with
structured reasoning steps. Second, we introduce nvBench-CoT, a specialized
dataset capturing detailed step-by-step reasoning from ambiguous natural
language descriptions to finalized visualizations, which enables
state-of-the-art performance when used for model fine-tuning. Third, we develop
DeepVIS, an interactive visual interface that tightly integrates with the CoT
reasoning process, allowing users to inspect reasoning steps, identify errors,
and make targeted adjustments to improve visualization outcomes. Quantitative
benchmark evaluations, two use cases, and a user study collectively demonstrate
that our CoT framework effectively enhances NL2VIS quality while providing
insightful reasoning steps to users.

</details>


### [555] [ReflecSched: Solving Dynamic Flexible Job-Shop Scheduling via LLM-Powered Hierarchical Reflection](https://arxiv.org/abs/2508.01724)
*Shijie Cao,Yuan Yuan*

Main category: cs.AI

TL;DR: ReflecSched 框架通过结合 LLM 的推理能力和启发式方法，解决了动态柔性作业车间调度问题，取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统调度方法过于僵化，而深度学习方法又缺乏透明度且需要复杂的特征工程。直接应用大型语言模型（LLM）存在长上下文悖论、专家启发式利用不足和短视决策等问题。

Method: 提出了一种名为 ReflecSched 的框架，该框架使 LLM 能够进行战略分析，通过分析启发式驱动的模拟并将它们提炼成“战略经验”，以指导最终决策模块做出非短视的决策。

Result: ReflecSched 框架在实验中表现出色，获得 71.35% 的胜率和 2.755% 的相对百分比偏差降低，并能有效缓解所识别出的三个问题。

Conclusion: ReflecSched 框架通过引入战略分析能力，显著优于直接应用 LLM 的基线方法，并在统计上显著优于所有单独的启发式方法，同时在处理每个实例的最佳启发式方法方面表现相当。

Abstract: Dynamic Flexible Job-Shop Scheduling (DFJSP) is an NP-hard problem challenged
by real-time event adaptation and complex machine routing. While traditional
dispatching rules are efficient but rigid, deep learning approaches are opaque
and require intricate feature engineering. Large Language Models (LLMs) promise
adaptive reasoning without this engineering overhead, yet we find their direct
application is suboptimal. Baseline LLMs suffer from three key pitfalls: the
long-context paradox, where crucial data is underutilized; an underutilization
of expert heuristics; and myopic decision-making. To address this, we propose
ReflecSched, a framework that empowers the LLM beyond a direct scheduler by
equipping it with a strategic analysis capability. ReflecSched tasks the LLM to
analyze heuristic-driven simulations across multiple planning horizons and
distill them into a concise, natural-language summary termed ``Strategic
Experience''. This summary is then integrated into the prompt of a final
decision-making module, guiding it to produce non-myopic actions. Experiments
show that ReflecSched not only statistically significantly outperforms direct
LLM baselines, securing a 71.35\% Win Rate and a 2.755\% Relative Percentage
Deviation reduction, but also surpasses the performance of all individual
heuristics evaluated, all while demonstrably mitigating the three identified
pitfalls. Additionally, ReflecSched performs on par with the best heuristic
tailored to each instance across all problem cases.

</details>


### [556] [Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization](https://arxiv.org/abs/2508.01746)
*Shiyang Duan,Yuan Tian,Qi Bing,Xiaowei Shao*

Main category: cs.AI

TL;DR: HypoAgents框架通过贝叶斯推理和信息熵驱动搜索，实现科学假说的自动化生成、验证和优化，提升了假说的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 科学知识的指数级增长使得生成具有新颖性、可行性和研究价值的科学假说成为一项核心挑战，而现有的基于大语言模型的方法未能系统地模拟假说的内在联系或纳入对优化至关重要的闭环反馈机制。

Method: 本文提出了一种多智能体协作框架HypoAgents，该框架整合了贝叶斯推理和信息熵驱动的搜索机制，分为假说生成、证据验证和假说优化三个阶段，形成一个模拟科学家认知过程的迭代闭环。

Result: 实验结果表明，在ICLR 2025会议的真实世界研究问题数据集上，经过12次优化迭代后，生成的假说的平均ELO分数提高了116.3，超过基准真实论文摘要17.8，同时框架的整体不确定性（以香农熵衡量）显著降低了0.92。

Conclusion: 该研究提出了一个结合贝叶斯推理和信息熵驱动搜索机制的多智能体协作框架HypoAgents，用于自动化生成、验证和优化科学假说，显著提高了假说的质量和可靠性。

Abstract: The exponential growth of scientific knowledge has made the automated
generation of scientific hypotheses that combine novelty, feasibility, and
research value a core challenge. Existing methods based on large language
models fail to systematically model the inherent in hypotheses or incorporate
the closed-loop feedback mechanisms crucial for refinement. This paper proposes
a multi-agent collaborative framework called HypoAgents, which for the first
time integrates Bayesian reasoning with an information entropy-driven search
mechanism across three stages-hypotheses generation, evidence validation, and
hypotheses Refinement-to construct an iterative closed-loop simulating
scientists' cognitive processes. Specifically, the framework first generates an
initial set of hypotheses through diversity sampling and establishes prior
beliefs based on a composite novelty-relevance-feasibility (N-R-F) score. It
then employs etrieval-augmented generation (RAG) to gather external literature
evidence, updating the posterior probabilities of hypotheses using Bayes'
theorem. Finally, it identifies high-uncertainty hypotheses using information
entropy $H = - \sum {{p_i}\log {p_i}}$ and actively refines them, guiding the
iterative optimization of the hypothesis set toward higher quality and
confidence. Experimental results on the ICLR 2025 conference real-world
research question dataset (100 research questions) show that after 12
optimization iterations, the average ELO score of generated hypotheses improves
by 116.3, surpassing the benchmark of real paper abstracts by 17.8, while the
framework's overall uncertainty, as measured by Shannon entropy, decreases
significantly by 0.92. This study presents an interpretable probabilistic
reasoning framework for automated scientific discovery, substantially improving
the quality and reliability of machine-generated research hypotheses.

</details>


### [557] [Implementing Cumulative Functions with Generalized Cumulative Constraints](https://arxiv.org/abs/2508.01751)
*Pierre Schaus,Charles Thomas,Roger Kameugne*

Main category: cs.AI

TL;DR: 为无法在开源求解器中建模的生产商-消费者调度问题引入了一种新的方法，该方法使用Generalized Cumulative约束和新的过滤算法，并且性能具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的开源求解器无法使用条件时间间隔和累积函数对生产商和消费者调度问题进行建模，并且缺乏实际的实施细节。

Method: 使用名为Generalized Cumulative的单一通用全局约束来实现此建模方法，并引入了一种新颖的时间表过滤算法来处理在条件时间间隔上定义的任务。

Result: 实验结果表明，该方法结合新的过滤算法，与现有求解器相比具有竞争力，能够对生产者-消费者调度问题进行建模，并且能够有效地扩展到大型问题。

Conclusion: 该方法与现有求解器相比具有竞争力，能够对生产者-消费者调度问题进行建模，并且能够有效地扩展到大型问题。

Abstract: Modeling scheduling problems with conditional time intervals and cumulative
functions has become a common approach when using modern commercial constraint
programming solvers. This paradigm enables the modeling of a wide range of
scheduling problems, including those involving producers and consumers.
However, it is unavailable in existing open-source solvers and practical
implementation details remain undocumented. In this work, we present an
implementation of this modeling approach using a single, generic global
constraint called the Generalized Cumulative. We also introduce a novel
time-table filtering algorithm designed to handle tasks defined on conditional
time-intervals. Experimental results demonstrate that this approach, combined
with the new filtering algorithm, performs competitively with existing solvers
enabling the modeling of producer and consumer scheduling problems and
effectively scales to large problems.

</details>


### [558] [Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning](https://arxiv.org/abs/2508.01773)
*Jiuzhou Han,Wray Buntine,Ehsan Shareghi*

Main category: cs.AI

TL;DR: 提出了一种自动构建过程奖励模型（PRM）数据的方法，以及两种改进模型性能的输出聚合技术，在数学推理任务上取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有的PRM训练数据构建方法效率低下且劳动密集。需要更有效的方法来构建高质量的过程奖励数据以提升大型语言模型的数学推理能力。

Method: 提出了一种不确定性驱动的框架，用于自动生成和标注PRM的训练数据。引入了混合多数奖励投票和加权奖励频率投票两种方法来聚合输出。

Result: 所提出的框架在ProcessBench、MATH和GSMPlus数据集上证明了其在构建PRM数据方面的有效性和效率。两种新的输出聚合方法进一步提升了不同PRM在数学推理任务上的表现。

Conclusion: 该研究提出了一个不确定性驱动的框架，用于自动构建过程奖励模型（PRM）的数据，并引入了两种不确定性感知的方法来聚合输出，在数学推理任务上证明了其有效性。

Abstract: Large language models have demonstrated remarkable capabilities in complex
mathematical reasoning tasks, but they inevitably generate errors throughout
multi-step solutions. Process-level Reward Models (PRMs) have shown great
promise by providing supervision and evaluation at each intermediate step,
thereby effectively improving the models' reasoning abilities. However,
training effective PRMs requires high-quality process reward data, yet existing
methods for constructing such data are often labour-intensive or inefficient.
In this paper, we propose an uncertainty-driven framework for automated process
reward data construction, encompassing both data generation and annotation
processes for PRMs. Additionally, we identify the limitations of both majority
vote and PRMs, and introduce two generic uncertainty-aware output aggregation
methods: Hybrid Majority Reward Vote and Weighted Reward Frequency Vote, which
combine the strengths of majority vote with PRMs. Extensive experiments on
ProcessBench, MATH, and GSMPlus show the effectiveness and efficiency of the
proposed PRM data construction framework, and demonstrate that the two output
aggregation methods further improve the mathematical reasoning abilities across
diverse PRMs. The code and data will be publicly available at
https://github.com/Jiuzhouh/UnPRM.

</details>


### [559] [LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?](https://arxiv.org/abs/2508.01780)
*Guozhao Mo,Wenliang Zhong,Jiawei Chen,Xuanang Chen,Yaojie Lu,Hongyu Lin,Ben He,Xianpei Han,Le Sun*

Main category: cs.AI

TL;DR: 为解决现有MCP基准测试的局限性，我们提出了LiveMCPBench，这是首个包含95个真实任务的综合基准测试，用于大规模评估LLM代理在多样化服务器上的能力。我们还构建了LiveMCPTool（包含70个MCP服务器和527个工具）和一个名为LiveMCPEval的LLM-as-a-Judge框架，实现了81%的人工评估一致性。最后，我们提出了MCP Copilot Agent。在对10个模型的评估中，Claude-Sonnet-4取得了78.95%的成功率，但模型间存在显著的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有MCP基准测试仅限于单服务器和少量工具，无法有效评估大规模、真实场景下的Agent能力。

Method: 提出LiveMCPBench基准测试，包含95个真实任务；构建LiveMCPTool，包含70个MCP服务器和527个工具；引入LLM-as-a-Judge框架LiveMCPEval以实现自动化评估；提出MCP Copilot Agent以执行动态规划和工具调用。

Result: 在LiveMCPBench上评估了10个领先模型，最佳模型（Claude-Sonnet-4）成功率达到78.95%。然而，模型间性能差异较大，许多常用模型在复杂、富含工具的环境中表现不佳。

Conclusion: LiveMCPBench是首个用于在真实、富含工具、动态的MCP环境中进行LLM代理基准测试的统一框架，为代理能力的可扩展和可重复研究奠定了坚实基础。

Abstract: With the rapid development of Model Context Protocol (MCP), the number of MCP
servers has surpassed 10,000. However, existing MCP benchmarks are limited to
single-server settings with only a few tools, hindering effective evaluation of
agent capabilities in large-scale, real-world scenarios. To address this
limitation, we present LiveMCPBench, the first comprehensive benchmark
comprising 95 real-world tasks grounded in the MCP ecosystem, designed to
evaluate LLM agents at scale across diverse servers. To support a scalable and
reproducible evaluation pipeline in large-scale MCP environments, we curate
LiveMCPTool, a diverse and readily deployable collection of 70 MCP servers and
527 tools. Furthermore, we introduce LiveMCPEval, an LLM-as-a-Judge framework
that enables automated and adaptive evaluation in dynamic, time-varying task
environments, achieving 81% agreement with human reviewers. Finally, we propose
the MCP Copilot Agent, a multi-step agent that routes tools for dynamic
planning and executes tools for API interaction across the entire LiveMCPTool
suite. Our evaluation covers 10 leading models, with the best-performing model
(Claude-Sonnet-4) reaching a 78.95% success rate. However, we observe large
performance variance across models, and several widely-used models perform
poorly in LiveMCPBench's complex, tool-rich environments. Overall, LiveMCPBench
offers the first unified framework for benchmarking LLM agents in realistic,
tool-rich, and dynamic MCP environments, laying a solid foundation for scalable
and reproducible research on agent capabilities. Our code and data will be
publicly available at https://icip-cas.github.io/LiveMCPBench.

</details>


### [560] [CloudAnoAgent: Anomaly Detection for Cloud Sites via LLM Agent with Neuro-Symbolic Mechanism](https://arxiv.org/abs/2508.01844)
*Xinkai Zou,Xuan Jiang,Ruikai Huang,Haoze He,Parv Kapoor,Jiahua Zhao*

Main category: cs.AI

TL;DR: CloudAnoAgent是一种结合指标和日志数据，并利用神经符号LLM的云异常检测方法，相比传统和纯LLM方法，能提高检测准确性、降低误报率，并提供更好的解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的仅依赖指标数据的异常检测方法因数据不平衡导致误报率高，增加了运维开销。大型语言模型（LLM）的出现为整合指标和日志数据提供了新机会，以实现更准确、可解释的异常检测。

Method: 提出了一种名为CloudAnoAgent的神经符号大型语言模型（LLM）为基础的智能体，用于云环境的异常检测。该方法统一处理结构化指标和文本日志数据，并利用符号验证来验证检测假设和生成结构化的异常报告。同时，引入了CloudAnoBench基准测试，提供包含细粒度异常行为注释的配对指标和日志数据。

Result: CloudAnoAgent在异常分类准确性方面平均提高了46.36%和36.67%，误报率平均降低了36.67%和33.89%，并且在异常类型检测准确性方面比基础LLM提示提高了12.8%。

Conclusion: CloudAnoAgent通过结合指标和日志数据，并利用神经符号方法，在云环境异常检测方面取得了显著成效，提高了准确性并降低了误报率，同时增强了解释性，适合实际部署。

Abstract: Anomaly detection in cloud sites remains a critical yet challenging task.
Existing approaches that rely solely on metric data often suffer from high
false positive rates (FPR) due to data imbalance between normal and anomalous
events, leading to significant operational overhead for system reliance
engineers. Recent advances in large language models (LLMs) offer new
opportunities for integrating metrics with log data, enabling more accurate and
interpretable anomaly detection. In this paper, we propose CloudAnoAgent, the
first neuro-symbolic LLM-based agent for anomaly detection in cloud
environments. CloudAnoAgent jointly processes structured metrics and textual
log data in a unified pipeline, leveraging symbolic verification to validate
detection hypotheses and generate structured anomaly reports. To support
systematic evaluation, we introduce CloudAnoBench, the first benchmark that
provides LLM-generated paired metrics and log data with fine-grained anomaly
behavior annotations, filling a critical gap in existing datasets. Experimental
results demonstrate that CloudAnoAgent improves anomaly classification accuracy
by 46.36% and 36.67% on average and reduces the FPR by 36.67% and 33.89% on
average over traditional baselines and LLM-only baseline, with a boost on
anomaly type detection accuracy by 12.8% compared to vanilla LLM prompting.
These results demonstrate the strengths of our approach in improving detection
accuracy, reducing false positives, and enhancing interpretability, thereby
supporting practical deployment in enterprise cloud environments.

</details>


### [561] [ProKG-Dial: Progressive Multi-Turn Dialogue Construction with Domain Knowledge Graphs](https://arxiv.org/abs/2508.01869)
*Yuanyuan Liang,Xiaoman Wang,Tingyu Xie,Lei Pan*

Main category: cs.AI

TL;DR: 该研究提出了一种名为ProKG Dial的新框架，利用知识图谱自动构建高质量的领域特定对话数据集，解决了现有方法的局限性，并在医学领域取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在通用NLP任务上表现出色，但在专业领域缺乏特定精度。构建高质量的领域特定多轮对话数据集对于开发专业化对话系统至关重要。然而，现有方法（如手动标注、模拟人与LLM交互、基于角色的LLM对话）要么资源消耗大，要么在对话质量和领域覆盖方面存在不足。

Method: ProKG Dial是一个渐进式框架，用于利用领域特定知识图谱（KGs）构建知识密集型多轮对话数据集。该框架首先对KGs进行社区检测，将其划分为语义上内聚的子图。然后，针对每个子图，框架围绕目标实体逐步生成一系列问题和答案，以确保对话的相关性和覆盖范围。最后，通过严格的过滤步骤来保证对话质量。该框架在医学KGs上进行了验证，并通过评估生成对话的各项指标以及在一个在生成的数据集上微调的LLM的表现来证明其有效性。

Result: 通过在医学知识图谱上应用ProKG Dial框架，生成了高质量的多轮对话数据集。基于该数据集微调的LLM在自动评估和人类评估中均表现出优于多个基线模型的性能，证明了该框架在提升对话质量和领域特定性能方面的有效性和实用性。

Conclusion: ProKG Dial框架通过利用领域特定知识图谱（KGs）并结合社区检测和增量生成策略，有效解决了现有方法在构建高质量、高覆盖率的领域特定多轮对话数据集方面的局限性。在医学领域KGs上的实验表明，该框架生成的数据集在多样性、语义连贯性和实体覆盖率方面表现优异，并且在下游任务中显著提升了模型的领域特定性能。

Abstract: Current large language models (LLMs) excel at general NLP tasks but often
lack domain specific precision in professional settings. Building a high
quality domain specific multi turn dialogue dataset is essential for developing
specialized conversational systems. However, existing methods such as manual
annotation, simulated human LLM interactions, and role based LLM dialogues are
resource intensive or suffer from limitations in dialogue quality and domain
coverage. To address these challenges, we introduce ProKG Dial, a progressive
framework for constructing knowledge intensive multi turn dialogue datasets
using domain specific knowledge graphs (KGs). ProKG Dial leverages the
structured nature of KGs to encode complex domain knowledge and relationships,
providing a solid foundation for generating meaningful and coherent dialogues.
Specifically, ProKG Dial begins by applying community detection to partition
the KG into semantically cohesive subgraphs. For each subgraph, the framework
incrementally generates a series of questions and answers centered around a
target entity, ensuring relevance and coverage. A rigorous filtering step is
employed to maintain high dialogue quality. We validate ProKG Dial on a medical
knowledge graph by evaluating the generated dialogues in terms of diversity,
semantic coherence, and entity coverage. Furthermore, we fine tune a base LLM
on the resulting dataset and benchmark it against several baselines. Both
automatic metrics and human evaluations demonstrate that ProKG Dial
substantially improves dialogue quality and domain specific performance,
highlighting its effectiveness and practical utility.

</details>


### [562] [Multi-turn Natural Language to Graph Query Language Translation](https://arxiv.org/abs/2508.01871)
*Yuanyuan Liang,Lei Pan,Tingyu Xie,Yunshi Lan,Weining Qian*

Main category: cs.AI

TL;DR: 本研究提出了一种利用LLMs自动构建多轮NL2GQL数据集（MTGQL）的方法，以解决现有单轮方法在处理复杂对话中的不足，并提供了评估基线。


<details>
  <summary>Details</summary>
Motivation: 现有NL2GQL研究主要关注单轮转换，无法满足实际应用中多轮、动态、上下文相关的用户交互需求。同时，高质量的多轮NL2GQL数据集的缺乏也阻碍了该领域的发展。

Method: 提出了一种自动化方法，利用大型语言模型（LLMs）构建多轮NL2GQL数据集，并开发了MTGQL数据集。同时，提出了三种基线方法用于评估多轮NL2GQL翻译的有效性。

Result: 成功构建了MTGQL数据集，并提出了三种基线方法来评估多轮NL2GQL翻译的有效性，为后续研究奠定了基础。

Conclusion: 现有研究主要集中在单轮自然语言到图查询语言（NL2GQL）的转换，无法有效处理多轮对话和复杂的上下文依赖。为了解决这一挑战，我们提出了一种基于大型语言模型（LLMs）的自动化方法来构建多轮NL2GQL数据集，并开发了MTGQL数据集（来源于金融市场图数据库）。此外，我们还提出了三种基线方法来评估多轮NL2GQL翻译的有效性，为未来的研究奠定了基础。

Abstract: In recent years, research on transforming natural language into graph query
language (NL2GQL) has been increasing. Most existing methods focus on
single-turn transformation from NL to GQL. In practical applications, user
interactions with graph databases are typically multi-turn, dynamic, and
context-dependent. While single-turn methods can handle straightforward
queries, more complex scenarios often require users to iteratively adjust their
queries, investigate the connections between entities, or request additional
details across multiple dialogue turns. Research focused on single-turn
conversion fails to effectively address multi-turn dialogues and complex
context dependencies. Additionally, the scarcity of high-quality multi-turn
NL2GQL datasets further hinders the progress of this field. To address this
challenge, we propose an automated method for constructing multi-turn NL2GQL
datasets based on Large Language Models (LLMs) , and apply this method to
develop the MTGQL dataset, which is constructed from a financial market graph
database and will be publicly released for future research. Moreover, we
propose three types of baseline methods to assess the effectiveness of
multi-turn NL2GQL translation, thereby laying a solid foundation for future
research.

</details>


### [563] [Dynamic Context Adaptation for Consistent Role-Playing Agents with Retrieval-Augmented Generations](https://arxiv.org/abs/2508.02016)
*Jeiyoon Park,Yongshin Han,Minseop Kim,Kisu Yang*

Main category: cs.AI

TL;DR: AMADEUS框架通过ACTS、GS和AE来模拟角色的知识和属性，提高了角色扮演的一致性，并构建了CharacterRAG数据集进行评估。


<details>
  <summary>Details</summary>
Motivation: 为了在回答超出知识范围的问题时保持鲁棒的角色一致性，需要一种能够模拟角色知识和属性的框架。

Method: 提出了一种名为AMADEUS的框架，该框架由自适应上下文感知文本分割器（ACTS）、引导选择（GS）和属性提取器（AE）组成。ACTS为每个角色寻找最优的文本块长度和层级上下文。AE通过GS检索到的文本块识别角色的通用属性，并使用这些属性作为最终上下文，以在回答超出知识范围的问题时保持鲁棒的角色一致性。此外，还构建了一个包含15个虚构角色、总计976K字符的Persona文档和450个问答对的角色扮演数据集CharacterRAG，以促进基于RAG的角色扮演代理的开发和评估。

Result: AMADEUS框架在模拟角色的知识和个性方面表现出色，并且在处理超出知识范围的问题时能够保持一致性。

Conclusion: AMADEUS框架能够有效地模拟角色的知识和个性等多种属性，提高了角色扮演的鲁棒性。

Abstract: We propose AMADEUS, which is composed of Adaptive Context-aware Text Splitter
(ACTS), Guided Selection (GS), and Attribute Extractor (AE). ACTS finds an
optimal chunk length and hierarchical contexts for each character. AE
identifies a character's general attributes from the chunks retrieved by GS and
uses these attributes as a final context to maintain robust persona consistency
even when answering out of knowledge questions. To facilitate the development
and evaluation of RAG-based RPAs, we construct CharacterRAG, a role-playing
dataset that consists of persona documents for 15 distinct fictional characters
totaling 976K written characters, and 450 question and answer pairs. We find
that our framework effectively models not only the knowledge possessed by
characters, but also various attributes such as personality.

</details>


### [564] [TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs](https://arxiv.org/abs/2508.02063)
*Amitava Das,Vinija Jain,Aman Chadha*

Main category: cs.AI

TL;DR: TraceAlign 框架通过 BCI 指数追踪 LLMs 的不安全输出到其训练语料库的根源，并通过 TraceShield、Contrastive Belief Deconfliction Loss 和 Prov-Decode 等方法有效减少了对齐漂移，同时保持了模型效用。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在面对对抗性提示、解码扰动或模仿的越狱提示时，出现的对齐漂移（产生不安全或违反策略的输出）问题，并探究这些失败在训练时的根源。

Method: TraceAlign 框架通过 BCI 指数量化生成文本与对齐策略之间的语义不一致性，并结合 TraceShield、Contrastive Belief Deconfliction Loss 和 Prov-Decode 三种干预措施来缓解对齐漂移。

Result: TraceAlign 框架通过三种干预措施，在对齐漂移基准测试（ADB）上将对齐漂移减少了高达 85%，同时在标准任务上保持了效用（delta 小于 0.2），并提高了拒绝质量。此外，还推导了通过后缀数组跨度统计量来约束漂移发生可能性的理论上限。

Conclusion: TraceAlign 提供了一个可扩展、可追溯且有依据的工具包，用于从源头理解和减轻对齐失败。

Abstract: Large Language Models (LLMs) fine-tuned to align with human values often
exhibit alignment drift, producing unsafe or policy-violating completions when
exposed to adversarial prompts, decoding perturbations, or paraphrased
jailbreaks. While prior work has behaviorally characterized alignment failure,
little is known about the training-time belief sources underlying these
failures. We introduce TraceAlign, a unified framework for tracing unsafe
completions back to their root causes in the model's training corpus. Central
to our approach is the Belief Conflict Index (BCI), which quantifies semantic
inconsistency between generated spans and aligned policies, based on retrieved
training documents using suffix-array matching. We propose three complementary
interventions: (i) TraceShield, an inference-time safety filter that refuses
completions with high-BCI spans, (ii) Contrastive Belief Deconfliction Loss, a
contrastive fine-tuning objective penalizing high-BCI continuations during DPO,
and (iii) Prov-Decode, a provenance-aware decoding strategy that vetoes beam
expansions predicted to yield high-BCI spans. Together, these defenses reduce
alignment drift by up to 85% on our curated Alignment Drift Benchmark (ADB)
while preserving utility on standard tasks, with delta less than 0.2 and
improved refusal quality. We further derive a theoretical upper bound on drift
likelihood via suffix-array span statistics, linking memorization frequency and
length to adversarial reactivation risk. TraceAlign thus provides the first
scalable, traceable, and grounded toolkit for understanding and mitigating
alignment failures at source. To encourage further exploration and development,
we open-source our implementation at:
https://anonymous.4open.science/r/tracealign-2DA7

</details>


### [565] [Risk identification based on similar case retrieval enhancement,](https://arxiv.org/abs/2508.02073)
*Jiawei Li,Chengye Yang,Yaochen Zhang,Weilin Sun,Lei Meng,Xiangxu Meng*

Main category: cs.AI

TL;DR: 提出一种融合外部知识和案例检索的危险识别方法，无需训练，有效提升了大型语言模型在建设施工现场的危险识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的建设施工现场风险和危险识别研究主要有两大类：一类是面向协同推理的图文匹配，但其难以处理复杂的危险特征；另一类是利用专业数据集进行指令微调或对话引导，但存在训练成本高、泛化能力差等问题。因此，需要一种新的方法来解决这些问题。

Method: 提出了一种利用相似案例检索增强的危险识别方法，通过提示微调集成外部知识和检索到的案例上下文，以缓解领域知识有限和特征关联较弱导致的误判。该方法包括检索库、图像相似性检索和大型模型检索增强三个模块，实现了无需训练的有效识别。

Result: 实验结果表明，该方法在真实施工数据上显著提高了识别精度，例如，GLM-4V 的识别精度提升至 50%，提高了 35.49%。

Conclusion: 该方法提高了准确性、上下文理解能力和稳定性，为危险检测提供了新的理论和技术支持。

Abstract: The goal of construction site risk and hazard identification is to enhance
safety management through automation. Existing research based on large language
models falls into two categories: image-text matching for collaborative
reasoning, which struggles with complex hazard features, and instruction
fine-tuning or dialogue guidance using professional datasets, which suffers
from high training costs and poor generalization.To address this, we propose a
hazard identification method using similar case retrieval enhancement. By
integrating external knowledge and retrieved case contexts via prompt
fine-tuning, we mitigate misjudgments caused by limited domain knowledge and
weak feature associations. Our method includes three modules: retrieval
library, image similarity retrieval, and large model retrieval enhancement,
enabling efficient recognition without training. Experiments on real
construction data show significant improvements. For instance, GLM-4V's
recognition accuracy increased to 50\%, a 35.49\% boost. The method enhances
accuracy, context understanding, and stability, offering new theoretical and
technical support for hazard detection.

</details>


### [566] [SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents](https://arxiv.org/abs/2508.02085)
*Jiaye Lin,Yifu Guo,Yuzhen Han,Sen Hu,Ziyi Ni,Licheng Wang,Mingguang Chen,Daxin Jiang,Binxing Jiao,Chen Hu,Huacan Wang*

Main category: cs.AI

TL;DR: SE-Agent通过自我进化机制，优化LLM代理的推理轨迹，解决了现有方法的不足，并在解决真实GitHub问题的任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理虽然在复杂推理和工具使用方面表现出色，但其解决问题的过程（交互轨迹）尚未得到充分利用。现有方法（如MCTS）忽略了不同轨迹间的相互依赖性，并且搜索空间缺乏多样性，导致冗余推理和次优结果。

Method: 提出了一种名为SE-Agent的自我进化框架，通过三个关键操作（revisión, 结合, 和精炼）来优化LLM代理的推理过程，以解决现有方法（如MCTS）中存在的轨迹依赖性不足和搜索空间多样性缺乏的问题。

Result: 在SWE-bench Verified上，SE-Agent与五个强大的LLM集成后，实现了高达55%的相对改进，在SWE-bench Verified上达到了所有开源代理的最先进性能。

Conclusion: SE-Agent通过 revisión, 结合, 和精炼等操作，迭代地优化LLM代理的推理过程，实现了自我进化，并在SWE-bench Verified上取得了高达55%的相对改进，达到了最先进的性能。

Abstract: Large Language Model (LLM)-based agents have recently shown impressive
capabilities in complex reasoning and tool use via multi-step interactions with
their environments. While these agents have the potential to tackle complicated
tasks, their problem-solving process, i.e., agents' interaction trajectory
leading to task completion, remains underexploited. These trajectories contain
rich feedback that can navigate agents toward the right directions for solving
problems correctly. Although prevailing approaches, such as Monte Carlo Tree
Search (MCTS), can effectively balance exploration and exploitation, they
ignore the interdependence among various trajectories and lack the diversity of
search spaces, which leads to redundant reasoning and suboptimal outcomes. To
address these challenges, we propose SE-Agent, a Self-Evolution framework that
enables Agents to optimize their reasoning processes iteratively. Our approach
revisits and enhances former pilot trajectories through three key operations:
revision, recombination, and refinement. This evolutionary mechanism enables
two critical advantages: (1) it expands the search space beyond local optima by
intelligently exploring diverse solution paths guided by previous trajectories,
and (2) it leverages cross-trajectory inspiration to efficiently enhance
performance while mitigating the impact of suboptimal reasoning paths. Through
these mechanisms, SE-Agent achieves continuous self-evolution that
incrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench
Verified to resolve real-world GitHub issues. Experimental results across five
strong LLMs show that integrating SE-Agent delivers up to 55% relative
improvement, achieving state-of-the-art performance among all open-source
agents on SWE-bench Verified. Our code and demonstration materials are publicly
available at https://github.com/wanghuacan/SE-Agent.

</details>


### [567] ["Stack It Up!": 3D Stable Structure Generation from 2D Hand-drawn Sketch](https://arxiv.org/abs/2508.02093)
*Yiqing Xu,Linfeng Li,Cunjun Yu,David Hsu*

Main category: cs.AI

TL;DR: StackItUp allows users to create 3D structures from 2D sketches by interpreting geometric relations and stability patterns, then using diffusion models to generate stable 3D block arrangements.


<details>
  <summary>Details</summary>
Motivation: Existing robot manipulation systems require precise 3D block poses, demanding structural analysis and expert tools like CAD, which prevents non-experts from specifying complex 3D structures using simple sketches. StackItUp aims to enable non-experts to create complex 3D structures from 2D sketches.

Method: StackItUp uses an abstract relation graph to capture symbolic geometric relations and stability patterns from sketches, then grounds this graph to 3D poses using compositional diffusion models and iteratively updates it by predicting hidden supports.

Result: StackItUp consistently produces stable, multilevel 3D structures and outperforms all baselines in both stability and visual resemblance when evaluated on sketches of iconic landmarks and modern house designs.

Conclusion: StackItUp can successfully produce stable, multilevel 3D structures from 2D sketches and outperforms other methods in stability and visual resemblance.

Abstract: Imagine a child sketching the Eiffel Tower and asking a robot to bring it to
life. Today's robot manipulation systems can't act on such sketches
directly-they require precise 3D block poses as goals, which in turn demand
structural analysis and expert tools like CAD. We present StackItUp, a system
that enables non-experts to specify complex 3D structures using only 2D
front-view hand-drawn sketches. StackItUp introduces an abstract relation graph
to bridge the gap between rough sketches and accurate 3D block arrangements,
capturing the symbolic geometric relations (e.g., left-of) and stability
patterns (e.g., two-pillar-bridge) while discarding noisy metric details from
sketches. It then grounds this graph to 3D poses using compositional diffusion
models and iteratively updates it by predicting hidden internal and rear
supports-critical for stability but absent from the sketch. Evaluated on
sketches of iconic landmarks and modern house designs, StackItUp consistently
produces stable, multilevel 3D structures and outperforms all baselines in both
stability and visual resemblance.

</details>


### [568] [Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools](https://arxiv.org/abs/2508.02110)
*Kanghua Mo,Li Hu,Yucheng Long,Zhihao Li*

Main category: cs.AI

TL;DR: LLM代理的工具元数据可能被操纵，导致恶意工具被优先选择。AMA攻击利用此漏洞，成功率高，且难以防御。


<details>
  <summary>Details</summary>
Motivation: LLM代理利用外部工具展现出强大的复杂推理和决策能力，但工具中心范式引入了一个先前未被充分探索的攻击面：对手可以操纵工具元数据（如名称、描述和参数模式）来影响代理行为。

Method: 提出吸引元数据攻击（AMA），一个黑盒上下文学习框架，通过迭代优化生成具有高度吸引力但语法和语义上有效的工具元数据。

Result: AMA框架在十个现实模拟的工具使用场景和一系列流行的LLM代理的广泛实验中，成功率持续达到81%-95%，并造成显著的隐私泄露，同时对主要任务执行的影响可忽略不计。

Conclusion: 元数据操纵构成了一个强大而隐蔽的攻击面，凸显了超越提示级防御的执行级安全机制的必要性。

Abstract: Large language model (LLM) agents have demonstrated remarkable capabilities
in complex reasoning and decision-making by leveraging external tools. However,
this tool-centric paradigm introduces a previously underexplored attack
surface: adversaries can manipulate tool metadata -- such as names,
descriptions, and parameter schemas -- to influence agent behavior. We identify
this as a new and stealthy threat surface that allows malicious tools to be
preferentially selected by LLM agents, without requiring prompt injection or
access to model internals. To demonstrate and exploit this vulnerability, we
propose the Attractive Metadata Attack (AMA), a black-box in-context learning
framework that generates highly attractive but syntactically and semantically
valid tool metadata through iterative optimization. Our attack integrates
seamlessly into standard tool ecosystems and requires no modification to the
agent's execution framework. Extensive experiments across ten realistic,
simulated tool-use scenarios and a range of popular LLM agents demonstrate
consistently high attack success rates (81\%-95\%) and significant privacy
leakage, with negligible impact on primary task execution. Moreover, the attack
remains effective even under prompt-level defenses and structured
tool-selection protocols such as the Model Context Protocol, revealing systemic
vulnerabilities in current agent architectures. These findings reveal that
metadata manipulation constitutes a potent and stealthy attack surface,
highlighting the need for execution-level security mechanisms that go beyond
prompt-level defenses.

</details>


### [569] [Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models](https://arxiv.org/abs/2508.02120)
*Linan Yue,Yichao Du,Yizhi Wang,Weibo Gao,Fangzhou Yao,Li Wang,Ye Liu,Ziyu Xu,Qi Liu,Shimin Di,Min-Ling Zhang*

Main category: cs.AI

TL;DR: LRM（如DeepSeek R1）在复杂任务中表现出色，但存在推理链过长的问题。本研究综述了解决该问题的两种主要方法：单模型优化和多模型协作，旨在提高推理效率。


<details>
  <summary>Details</summary>
Motivation: LRM（如DeepSeek R1）在处理复杂任务时表现出色，但存在“思考过度”问题，即推理链过长、步骤冗余，导致效率降低且可能影响准确性。因此，需要发展高效推理方法。

Method: 通过对现有研究进行系统性回顾，将高效推理方法分为两大类：单模型优化（提升单个模型推理效率）和模型协作（通过多模型协作优化推理路径）。

Result: LRM在处理复杂任务方面表现出色，但存在“思考过度”问题。本综述对单模型优化和多模型协作这两种解决“思考过度”问题的高效推理方法进行了系统性归纳与分类。

Conclusion: 目前，LRM领域的研究热点在于如何提高推理效率，以解决“思考过度”问题，这涉及到单模型优化和多模型协作两大方向。

Abstract: Recently, Large Reasoning Models (LRMs) have gradually become a research
hotspot due to their outstanding performance in handling complex tasks. Among
them, DeepSeek R1 has garnered significant attention for its exceptional
performance and open-source nature, driving advancements in the research of
R1-style LRMs. Unlike traditional Large Language Models (LLMs), these models
enhance logical deduction and decision-making capabilities during reasoning by
incorporating mechanisms such as long chain-of-thought and self-reflection
through reinforcement learning. However, with the widespread application of
these models, the problem of overthinking has gradually emerged. Specifically,
when generating answers, these models often construct excessively long
reasoning chains with redundant or repetitive steps, which leads to reduced
reasoning efficiency and may affect the accuracy of the final answer. To this
end, various efficient reasoning methods have been proposed, aiming to reduce
the length of reasoning paths without compromising model performance and
reasoning capability. By reviewing the current research advancements in the
field of efficient reasoning methods systematically, we categorize existing
works into two main directions based on the lens of single-model optimization
versus model collaboration: (1) Efficient Reasoning with Single Model, which
focuses on improving the reasoning efficiency of individual models; and (2)
Efficient Reasoning with Model Collaboration, which explores optimizing
reasoning paths through collaboration among multiple models. Besides, we
maintain a public GitHub repository that tracks the latest progress in
efficient reasoning methods.

</details>


### [570] [Trainable Dynamic Mask Sparse Attention](https://arxiv.org/abs/2508.02124)
*Jingze Shi,Yifan Wu,Bingheng Wu,Yiran Peng,Liangdong Wang,Guang Liu,Yuyu Luo*

Main category: cs.AI

TL;DR: DMA是一种动态掩码稀疏注意力机制，通过内容和位置感知来提高长上下文建模的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力机制的二次复杂度成为长上下文建模的瓶颈，现有稀疏注意力机制存在静态模式或信息丢失问题，需要一种能有效利用内容感知和位置感知稀疏性并平衡信息保真度和计算效率的机制。

Method: DMA是一种可训练的动态掩码稀疏注意力机制，通过动态生成内容感知的稀疏掩码和实现位置感知的稀疏注意力计算来降低计算复杂度，同时保留完整信息。

Result: DMA在困惑度、关联回忆任务以及长上下文的needle-in-a-haystack任务上，相较于多头注意力和现有的稀疏注意力机制（如滑动窗口注意力、多头潜在注意力、原生稀疏注意力）均取得了更优的性能和效率。

Conclusion: DMA通过内容感知和位置感知的稀疏性有效利用了信息，在保持信息保真度和计算效率之间取得了优异的平衡。实验证明，DMA在困惑度和关联回忆任务上优于其他稀疏注意力机制，并在大模型和长上下文任务中表现出色。

Abstract: In large language models, the demand for modeling long contexts is constantly
increasing, but the quadratic complexity of the standard self-attention
mechanism often becomes a bottleneck. Although existing sparse attention
mechanisms have improved efficiency, they may still encounter issues such as
static patterns or information loss. We introduce a trainable dynamic mask
sparse attention mechanism, Dynamic Mask Attention, which effectively utilizes
content-aware and position-aware sparsity. DMA achieves this through two key
innovations: First, it dynamically generates content-aware sparse masks from
value representations, enabling the model to identify and focus on critical
information adaptively. Second, it implements position-aware sparse attention
computation that effectively skips unnecessary calculation regions. This
dual-sparsity design allows the model to significantly reduce the computational
complexity of important information while retaining complete information,
achieving an excellent balance between information fidelity and computational
efficiency. We have verified the performance of DMA through comprehensive
experiments. Comparative studies show that DMA outperforms multi-head
attention, sliding window attention, multi-head latent attention, and native
sparse attention in terms of perplexity under Chinchilla Scaling Law settings.
Moreover, in challenging multi-query associative recall tasks, DMA also
demonstrates superior performance and efficiency compared to these methods.
Crucially, in the evaluation of a 1.7B parameter model, DMA significantly
outperforms multi-head attention in both standard benchmark performance and the
challenging needle-in-a-haystack task. These experimental results highlight its
capability to balance model efficiency and long-context modeling ability
effectively.

</details>


### [571] [All Stories Are One Story: Emotional Arc Guided Procedural Game Level Generation](https://arxiv.org/abs/2508.02132)
*Yunge Wen,Chenliang Huang,Hangyu Zhou,Zhuo Zeng,Chun Ming Louis Po,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 该研究提出了一种基于情感弧（上升和下降）的游戏叙事生成框架，并使用LLM和自适应实体生成技术，在ARPG原型中取得了显著的玩家参与度和情感影响提升效果。


<details>
  <summary>Details</summary>
Motivation: 探索将普遍存在于跨文化叙事中的情感弧结构应用于程序化游戏叙事生成，以增强故事进展和游戏动态。

Method: 提出了一种将情感弧（上升和下降）作为游戏叙事生成结构支撑的框架，用于指导分支故事图的生成，并根据情感轨迹调整难度。

Result: 通过玩家评分、访谈和情感分析评估，证明情感弧的整合能显著提升玩家的参与度、叙事连贯性和情感冲击力。

Conclusion: 本研究展示了情感弧在游戏叙事生成中的潜力，通过LLM和自适应实体生成，可以显著提高玩家的参与度、叙事连贯性和情感冲击力。

Abstract: The emotional arc is a universal narrative structure underlying stories
across cultures and media -- an idea central to structuralist narratology,
often encapsulated in the phrase "all stories are one story." We present a
framework for procedural game narrative generation that incorporates emotional
arcs as a structural backbone for both story progression and gameplay dynamics.
Leveraging established narratological theories and large-scale empirical
analyses, we focus on two core emotional patterns -- Rise and Fall -- to guide
the generation of branching story graphs. Each story node is automatically
populated with characters, items, and gameplay-relevant attributes (e.g.,
health, attack), with difficulty adjusted according to the emotional
trajectory. Implemented in a prototype action role-playing game (ARPG), our
system demonstrates how emotional arcs can be operationalized using large
language models (LLMs) and adaptive entity generation. Evaluation through
player ratings, interviews, and sentiment analysis shows that emotional arc
integration significantly enhances engagement, narrative coherence, and
emotional impact. These results highlight the potential of emotionally
structured procedural generation for advancing interactive storytelling for
games.

</details>


### [572] [Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following](https://arxiv.org/abs/2508.02150)
*Qingyu Ren,Qianyu He,Bowei Zhang,Jie Zeng,Jiaqing Liang,Yanghua Xiao,Weikang Zhou,Zeye Sun,Fei Yu*

Main category: cs.AI

TL;DR: 提出一种自监督强化学习框架，利用模型自身信号提升指令遵循能力，无需外部模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖更强的外部模型带来的方法瓶颈、成本增加和可及性限制等问题。

Method: 提出了一种利用推理模型自身内部信号的自监督强化学习框架，无需外部监督即可提高指令遵循能力。

Result: 实验证明，该框架显著提高了指令遵循能力，同时保持了推理性能。

Conclusion: 该框架在保持推理能力的同时，显著提高了推理模型的指令遵循能力，提供了一种可扩展且经济高效的方法。

Abstract: Reasoning models excel in complex problem solving but exhibit a concerning
trade off between reasoning capabilities and instruction following abilities.
Existing approaches for improving instruction following rely on stronger
external models, creating methodological bottlenecks and practical limitations
including increased costs and accessibility constraints. We propose a
self-supervised RL framework that leverages reasoning models' own internal
signals to improve instruction following capabilities without external
supervision. Extensive experiments demonstrate that our framework significantly
improves instruction following capabilities while maintaining reasoning
performance, offering a scalable and cost-effective approach to enhance
instruction following in reasoning models. The data and code are publicly
available at https://github.com/Rainier-rq/verl-if.

</details>


### [573] [Reconsidering Overthinking: Penalizing Internal and External Redundancy in CoT Reasoning](https://arxiv.org/abs/2508.02178)
*Jialiang Hong,Taihang Zhen,Kai Chen,Jiaheng Liu,Wenpeng Zhu,Jing Huo,Yang Gao,Depeng Wang,Haitao Wan,Xi Yang,Boyan Wang,Fanyu Meng*

Main category: cs.AI

TL;DR: 为解决大型推理模型（LRMs）的过度思考问题，提出一种双重惩罚强化学习框架，区分并处理内部和外部冗余，有效压缩推理过程，且不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）的过度思考问题导致推理过程冗长，影响效率和可解释性。现有方法主要关注缩短响应长度，但未充分探究其背后的语义结构。

Method: 提出一种双重惩罚强化学习框架，其中对内部冗余采用滑动窗口语义分析来惩罚低贡献的推理步骤，对外部冗余则惩罚其在首次正确解决方案（FCS）之后的比例，以鼓励模型尽早终止。

Result: 该方法能显著压缩推理过程，准确率损失极小，并且能有效泛化到问答和代码生成等域外任务。研究发现，外部冗余可安全移除，而内部冗余的减少需更谨慎以避免影响正确性。

Conclusion: 该研究通过区分内部冗余和外部冗余，并提出一种双重惩罚强化学习框架来解决大型推理模型（LRMs）的过度思考问题。实验证明，该方法能有效压缩推理过程，同时保持准确性，并能泛化到其他任务。研究还发现，外部冗余可以安全移除，而内部冗余的减少则需谨慎。

Abstract: Large Reasoning Models (LRMs) often produce excessively verbose reasoning
traces, a phenomenon known as overthinking, which hampers both efficiency and
interpretability. Prior works primarily address this issue by reducing response
length, without fully examining the underlying semantic structure of the
reasoning process. In this paper, we revisit overthinking by decomposing it
into two distinct forms: internal redundancy, which consists of
low-contribution reasoning steps within the first correct solution (FCS), and
external redundancy, which refers to unnecessary continuation after the FCS. To
mitigate both forms, we propose a dual-penalty reinforcement learning
framework. For internal redundancy, we adopt a sliding-window semantic analysis
to penalize low-gain reasoning steps that contribute little toward reaching the
correct answer. For external redundancy, we penalize its proportion beyond the
FCS to encourage earlier termination. Our method significantly compresses
reasoning traces with minimal accuracy loss, and generalizes effectively to
out-of-domain tasks such as question answering and code generation. Crucially,
we find that external redundancy can be safely removed without degrading
performance, whereas internal redundancy must be reduced more cautiously to
avoid impairing correctness. These findings suggest that our method not only
improves reasoning efficiency but also enables implicit, semantic-aware control
over Chain-of-Thought length, paving the way for more concise and interpretable
LRMs.

</details>


### [574] [Neuromorphic Computing with Multi-Frequency Oscillations: A Bio-Inspired Approach to Artificial Intelligence](https://arxiv.org/abs/2508.02191)
*Boheng Liu,Ziyu Li,Xia Wu*

Main category: cs.AI

TL;DR: 受大脑启发的架构通过整合功能专业化和时间动态，实现了更灵活、更高效的人工认知，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人工神经网络虽然能力出众，但灵活、可泛化的智能有限，这是由于它们在根本上偏离了生物认知，忽视了神经区域的功能专业化以及协调这些专业化系统的时间动态。

Method: 提出了一种三方受大脑启发的架构，包括功能专业的感知、辅助和执行系统，并通过模拟多频神经振荡和突触动态适应机制整合时间动态。

Result: 与最先进的时间处理方法相比，该架构在准确性方面提高了 2.18%，同时将所需的计算迭代次数减少了 48.44%，并实现了与人类置信度模式更高的相关性。

Conclusion: 该架构为跨认知域的类脑智能建立了理论基础，有可能弥合人工智能和生物智能之间的差距。

Abstract: Despite remarkable capabilities, artificial neural networks exhibit limited
flexible, generalizable intelligence. This limitation stems from their
fundamental divergence from biological cognition that overlooks both neural
regions' functional specialization and the temporal dynamics critical for
coordinating these specialized systems. We propose a tripartite brain-inspired
architecture comprising functionally specialized perceptual, auxiliary, and
executive systems. Moreover, the integration of temporal dynamics through the
simulation of multi-frequency neural oscillation and synaptic dynamic
adaptation mechanisms enhances the architecture, thereby enabling more flexible
and efficient artificial cognition. Initial evaluations demonstrate superior
performance compared to state-of-the-art temporal processing approaches, with
2.18\% accuracy improvements while reducing required computation iterations by
48.44\%, and achieving higher correlation with human confidence patterns.
Though currently demonstrated on visual processing tasks, this architecture
establishes a theoretical foundation for brain-like intelligence across
cognitive domains, potentially bridging the gap between artificial and
biological intelligence.

</details>


### [575] [A Message Passing Realization of Expected Free Energy Minimization](https://arxiv.org/abs/2508.02197)
*Wouter W. L. Nuijten,Mykola Lukashchuk,Thijs van de Laar,Bert de Vries*

Main category: cs.AI

TL;DR: 通过将EFE最小化转化为变分自由能最小化并引入认知先验，提出了一种消息传递方法，在不确定性环境下实现了比KL控制更优的规划和探索，验证了认知先验的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在因子图上解决预期自由能（EFE）最小化问题，并将其应用于具有认知不确定性的环境，以实现更高效的策略推断和探索。

Method: 提出了一种基于因子图的预期自由能（EFE）最小化消息传递方法，该方法借鉴了arXiv:2504.14898中提出的理论。通过将EFE最小化重新表述为带有认知先验的变分自由能最小化，将组合搜索问题转化为可解的推理问题，并利用标准变分技术进行求解。

Result: 在随机网格世界和部分可观察的小网格任务这两个具有认知不确定性的环境中，与传统的KL控制智能体相比，使用该消息传递方法的智能体表现更优。在随机网格世界中，该方法智能体避开了风险路径；在部分可观察的小网格任务中，该方法智能体进行了更系统的探信息寻求。

Conclusion: 该方法通过将预期自由能最小化问题转化为变分自由能最小化问题，并引入认知先验，将组合搜索问题转变为可处理的推理问题，从而实现了高效的策略推断。在具有认知不确定性的环境（如随机网格世界和部分可观察的小网格任务）中，该方法的表现优于传统的KL控制方法，展现出更强的规划能力和在不确定性下的高效探索能力。具体来说，在随机网格世界中，遵循预期自由能最小化原则的智能体能够避开风险路径；而在部分可观察的小网格任务中，它们则能进行更系统的探信息寻求。该方法成功地将主动推理理论与实际应用相结合，为人工智能体中认知先验的有效性提供了实证支持。

Abstract: We present a message passing approach to Expected Free Energy (EFE)
minimization on factor graphs, based on the theory introduced in
arXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy
minimization with epistemic priors, we transform a combinatorial search problem
into a tractable inference problem solvable through standard variational
techniques. Applying our message passing method to factorized state-space
models enables efficient policy inference. We evaluate our method on
environments with epistemic uncertainty: a stochastic gridworld and a partially
observable Minigrid task. Agents using our approach consistently outperform
conventional KL-control agents on these tasks, showing more robust planning and
efficient exploration under uncertainty. In the stochastic gridworld
environment, EFE-minimizing agents avoid risky paths, while in the partially
observable minigrid setting, they conduct more systematic information-seeking.
This approach bridges active inference theory with practical implementations,
providing empirical evidence for the efficiency of epistemic priors in
artificial agents.

</details>


### [576] [AirTrafficGen: Configurable Air Traffic Scenario Generation with Large Language Models](https://arxiv.org/abs/2508.02269)
*Dewi Sid William Gould,George De Ath,Ben Carvell,Nick Pepper*

Main category: cs.AI

TL;DR: AirTrafficGen使用LLM自动生成ATC场景，解决了手动设计耗时的问题，并展示了LLM在安全关键领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 手动设计空域交通管制（ATC）场景是一个耗时且有挑战性的瓶颈，限制了管制员可用的模拟多样性。

Method: 提出了一种新颖的、端到端的方法AirTrafficGen，该方法利用大型语言模型（LLM）来自动化和控制复杂ATC场景的生成。该方法使用专门构建的、基于图的表示来编码扇区拓扑（包括空域几何、航线和航点），以便LLM能够处理。通过严格的基准测试，证明了像Gemini 2.5 Pro和OpenAI o3这样的最先进模型可以在保持运营现实性的同时生成高流量场景。工程化提示可以对交互的存在、类型和位置进行细粒度控制。初步研究表明，这些模型还能够进行迭代改进，根据简单的文本反馈修正有缺陷的场景。

Result: Gemini 2.5 Pro和OpenAI o3等最先进模型能够生成高流量场景，同时保持运营现实性。工程化提示可以对交互的存在、类型和位置进行细粒度控制。初步研究表明，这些模型还能够进行迭代改进，根据简单的文本反馈修正有缺陷的场景。

Conclusion: 该方法为手动设计ATC场景提供了一种可扩展的替代方案，满足了对更大数量和更多样化的ATC培训和验证模拟的需求。更广泛地说，这项工作展示了LLM在安全关键领域的复杂规划潜力。

Abstract: The manual design of scenarios for Air Traffic Control (ATC) training is a
demanding and time-consuming bottleneck that limits the diversity of
simulations available to controllers. To address this, we introduce a novel,
end-to-end approach, AirTrafficGen, that leverages large language models (LLMs)
to automate and control the generation of complex ATC scenarios. Our method
uses a purpose-built, graph-based representation to encode sector topology
(including airspace geometry, routes, and fixes) into a format LLMs can
process. Through rigorous benchmarking, we show that state-of-the-art models
like Gemini 2.5 Pro and OpenAI o3 can generate high-traffic scenarios whilst
maintaining operational realism. Our engineered prompting enables fine-grained
control over interaction presence, type, and location. Initial findings suggest
these models are also capable of iterative refinement, correcting flawed
scenarios based on simple textual feedback. This approach provides a scalable
alternative to manual scenario design, addressing the need for a greater volume
and variety of ATC training and validation simulations. More broadly, this work
showcases the potential of LLMs for complex planning in safety-critical
domains.

</details>


### [577] [FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment](https://arxiv.org/abs/2508.02292)
*Wentao Zhang,Yilei Zhao,Chuqiao Zong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: FinWorld 是一个支持端到端金融人工智能工作流的一站式开源平台，解决了现有平台在任务覆盖、数据集成和 LLM 支持方面的不足，并通过实验证明了其在提高复现性、透明度和简化部署方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有金融人工智能平台在任务覆盖、多模态数据集成和大型语言模型（LLM）训练/部署支持方面存在局限性。

Method: 提出了 FinWorld，一个集成了异构金融数据、支持多样化人工智能范式和先进的代理自动化的一站式开源平台，用于支持从数据采集到实验和部署的整个金融人工智能工作流，特别关注基于强化学习的 LLM 微调和 LLM 代理。

Result: 在两个代表性市场、四个股票池和超过 8 亿个金融数据点的数据集上，对四个关键的金融人工智能任务进行了广泛的实验评估，证明了 FinWorld 在提升复现性、透明度和部署效率方面的优势。

Conclusion: FinWorld 平台显著提高了金融人工智能研究和实际应用的复现性、透明度和部署效率。

Abstract: Financial AI holds great promise for transforming modern finance, with the
potential to support a wide range of tasks such as market forecasting,
portfolio management, quantitative trading, and automated analysis. However,
existing platforms remain limited in task coverage, lack robust multimodal data
integration, and offer insufficient support for the training and deployment of
large language models (LLMs). In response to these limitations, we present
FinWorld, an all-in-one open-source platform that provides end-to-end support
for the entire financial AI workflow, from data acquisition to experimentation
and deployment. FinWorld distinguishes itself through native integration of
heterogeneous financial data, unified support for diverse AI paradigms, and
advanced agent automation, enabling seamless development and deployment.
Leveraging data from 2 representative markets, 4 stock pools, and over 800
million financial data points, we conduct comprehensive experiments on 4 key
financial AI tasks. These experiments systematically evaluate deep learning and
reinforcement learning algorithms, with particular emphasis on RL-based
finetuning for LLMs and LLM Agents. The empirical results demonstrate that
FinWorld significantly enhances reproducibility, supports transparent
benchmarking, and streamlines deployment, thereby providing a strong foundation
for future research and real-world applications. Code is available at
Github~\footnote{https://github.com/DVampire/FinWorld}.

</details>


### [578] [Traffic-R1: Reinforced LLMs Bring Human-Like Reasoning to Traffic Signal Control Systems](https://arxiv.org/abs/2508.02344)
*Xingchen Zou,Yuhao Yang,Zheng Chen,Xixuan Hao,Yiqi Chen,Chao Huang,Yuxuan Liang*

Main category: cs.AI

TL;DR: Traffic-R1 是一个拥有类似人类推理能力的基础模型，通过强化 LLM 开发，能够零样本泛化，轻量级部署，并提供可解释的 TSC 过程，在实际应用中显著改善了交通状况。


<details>
  <summary>Details</summary>
Motivation: 为了缓解拥堵和维持城市交通，需要改进交通信号控制（TSC）。

Method: Traffic-R1 是一个基础模型，通过在模拟交通环境中进行自我探索和迭代，并结合专家指导，使用强化大型语言模型（LLM）进行开发。

Result: Traffic-R1 实现了零样本泛化，能够将内部交通控制策略和类似人类的推理应用于新的道路网络和分布外事件；其 3B 参数架构轻量级，支持在移动级芯片上进行实时推理；此外，它还通过自我迭代和新的同步通信网络提供了可解释的 TSC 过程，并促进了多交叉口的通信。

Conclusion: Traffic-R1 在实际应用中管理着超过 55,000 名驾驶员的信号，平均队列缩短了 5% 以上，并将操作员工作量减半，在广泛的基准测试中，其性能优于强基线和训练密集型 RL 控制器，确立了新的技术水平。

Abstract: Traffic signal control (TSC) is vital for mitigating congestion and
sustaining urban mobility. In this paper, we introduce Traffic-R1, a foundation
model with human-like reasoning for TSC systems. Our model is developed through
self-exploration and iteration of reinforced large language models (LLMs) with
expert guidance in a simulated traffic environment. Compared to traditional
reinforcement learning (RL) and recent LLM-based methods, Traffic-R1 offers
three significant advantages. First, Traffic-R1 delivers zero-shot
generalisation, transferring unchanged to new road networks and
out-of-distribution incidents by utilizing its internal traffic control
policies and human-like reasoning. Second, its 3B-parameter architecture is
lightweight enough for real-time inference on mobile-class chips, enabling
large-scale edge deployment. Third, Traffic-R1 provides an explainable TSC
process and facilitates multi-intersection communication through its
self-iteration and a new synchronous communication network. Extensive
benchmarks demonstrate that Traffic-R1 sets a new state of the art,
outperforming strong baselines and training-intensive RL controllers. In
practice, the model now manages signals for more than 55,000 drivers daily,
shortening average queues by over 5% and halving operator workload. Our
checkpoint is available at https://huggingface.co/Season998/Traffic-R1.

</details>


### [579] [CABENCH: Benchmarking Composable AI for Solving Complex Tasks through Composing Ready-to-Use Models](https://arxiv.org/abs/2508.02427)
*Tung-Thuy Pham,Duy-Quan Luong,Minh-Quan Duong,Trung-Hieu Nguyen,Thu-Trang Nguyen,Son Nguyen,Hieu Dinh Vo*

Main category: cs.AI

TL;DR: 介绍 CABENCH，首个包含 70 个真实可组合 AI 任务和 700 个模型的基准，并提出评估框架，以评估可组合 AI。


<details>
  <summary>Details</summary>
Motivation: 系统地评估可组合 AI 方法仍未得到充分探索。

Method: 提出 CABENCH 基准（包含 70 个真实可组合 AI 任务和 700 个跨模态和域的模型库）和评估框架，以对可组合 AI 解决方案进行端到端评估，并提供人工设计的参考解决方案和基于 LLM 的方法作为基线。

Result: 展示了可组合 AI 在解决复杂现实问题方面的潜力，并指出了需要自动生成有效执行流程的方法。

Conclusion: composable AI 很有潜力解决复杂现实问题，但需要自动生成有效执行流程的方法来充分发挥其潜力。

Abstract: Composable AI offers a scalable and effective paradigm for tackling complex
AI tasks by decomposing them into sub-tasks and solving each sub-task using
ready-to-use well-trained models. However, systematically evaluating methods
under this setting remains largely unexplored. In this paper, we introduce
CABENCH, the first public benchmark comprising 70 realistic composable AI
tasks, along with a curated pool of 700 models across multiple modalities and
domains. We also propose an evaluation framework to enable end-to-end
assessment of composable AI solutions. To establish initial baselines, we
provide human-designed reference solutions and compare their performance with
two LLM-based approaches. Our results illustrate the promise of composable AI
in addressing complex real-world problems while highlighting the need for
methods that can fully unlock its potential by automatically generating
effective execution pipelines.

</details>


### [580] [Multimodal Large Language Models for End-to-End Affective Computing: Benchmarking and Boosting with Generative Knowledge Prompting](https://arxiv.org/abs/2508.02429)
*Miaosen Luo,Jiesen Long,Zequn Li,Yunying Yang,Yuncheng Jiang,Sijie Mai*

Main category: cs.AI

TL;DR: 本研究评估了多模态大语言模型在情感计算中的应用，发现混合策略能提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有针对多模态情感计算（MAC）的研究在处理复杂任务时存在性能不稳定和对模型架构及数据特性影响理解不足的问题。

Method: 对能够同时处理音频、视觉和文本模式的最新开源多模态大语言模型进行了系统的基准评估，并分析了模型架构和数据集属性对情感分析的影响，最后提出了一种结合生成式知识提示和监督微调的混合策略。

Result: 实验结果表明，所提出的混合策略在各种MAC任务上显著提高了模型性能。

Conclusion: 本研究通过结合生成式知识提示和监督微调的混合策略，显著提升了多模态大语言模型在情感计算任务上的性能，为该领域未来的研究和发展提供了有前景的方向。

Abstract: Multimodal Affective Computing (MAC) aims to recognize and interpret human
emotions by integrating information from diverse modalities such as text,
video, and audio. Recent advancements in Multimodal Large Language Models
(MLLMs) have significantly reshaped the landscape of MAC by offering a unified
framework for processing and aligning cross-modal information. However,
practical challenges remain, including performance variability across complex
MAC tasks and insufficient understanding of how architectural designs and data
characteristics impact affective analysis. To address these gaps, we conduct a
systematic benchmark evaluation of state-of-the-art open-source MLLMs capable
of concurrently processing audio, visual, and textual modalities across
multiple established MAC datasets. Our evaluation not only compares the
performance of these MLLMs but also provides actionable insights into model
optimization by analyzing the influence of model architectures and dataset
properties. Furthermore, we propose a novel hybrid strategy that combines
generative knowledge prompting with supervised fine-tuning to enhance MLLMs'
affective computing capabilities. Experimental results demonstrate that this
integrated approach significantly improves performance across various MAC
tasks, offering a promising avenue for future research and development in this
field. Our code is released on https://github.com/LuoMSen/MLLM-MAC.

</details>


### [581] [PHM-Bench: A Domain-Specific Benchmarking Framework for Systematic Evaluation of Large Models in Prognostics and Health Management](https://arxiv.org/abs/2508.02490)
*Puyu Yang,Laifa Tao,Zijian Huang,Haifei Liu,Wenyan Cao,Hao Ji,Jianan Qiu,Qixuan Huang,Xuanyuan Su,Yuhang Xie,Jun Zhang,Shangyu Li,Chen Lu,Zhixuan Lian*

Main category: cs.AI

TL;DR: PHM-Bench 是一个针对 PHM 领域大语言模型的评估框架，旨在解决现有评估方法的不足，并通过多维度评估和基准测试来指导模型发展。


<details>
  <summary>Details</summary>
Motivation: 现有针对 PHM 领域 LLM 的评估方法在结构完整性、维度全面性和评估粒度方面存在不足，阻碍了 LLM 在 PHM 领域的深入集成。

Method: 提出了一个名为 PHM-Bench 的新颖三维评估框架，该框架基于基础能力、核心任务和整个生命周期的三元结构，并定义了涵盖知识理解、算法生成和任务优化的多层次评估指标，以适应 PHM 系统工程的独特需求。

Result: 利用精心策划的案例集和公开的工业数据集，对通用和领域特定的模型在各种 PHM 任务上进行了多维度评估。

Conclusion: PHM-Bench 为 PHM 领域的 LLM 评估奠定了方法基础，并为从通用模型到 PHM 专用模型的过渡提供了关键基准。

Abstract: With the rapid advancement of generative artificial intelligence, large
language models (LLMs) are increasingly adopted in industrial domains, offering
new opportunities for Prognostics and Health Management (PHM). These models
help address challenges such as high development costs, long deployment cycles,
and limited generalizability. However, despite the growing synergy between PHM
and LLMs, existing evaluation methodologies often fall short in structural
completeness, dimensional comprehensiveness, and evaluation granularity. This
hampers the in-depth integration of LLMs into the PHM domain. To address these
limitations, this study proposes PHM-Bench, a novel three-dimensional
evaluation framework for PHM-oriented large models. Grounded in the triadic
structure of fundamental capability, core task, and entire lifecycle, PHM-Bench
is tailored to the unique demands of PHM system engineering. It defines
multi-level evaluation metrics spanning knowledge comprehension, algorithmic
generation, and task optimization. These metrics align with typical PHM tasks,
including condition monitoring, fault diagnosis, RUL prediction, and
maintenance decision-making. Utilizing both curated case sets and publicly
available industrial datasets, our study enables multi-dimensional evaluation
of general-purpose and domain-specific models across diverse PHM tasks.
PHM-Bench establishes a methodological foundation for large-scale assessment of
LLMs in PHM and offers a critical benchmark to guide the transition from
general-purpose to PHM-specialized models.

</details>


### [582] [OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling](https://arxiv.org/abs/2508.02503)
*Maxime Bouscary,Saurabh Amin*

Main category: cs.AI

TL;DR: OptiHive是一个创新的LLM框架，无需迭代即可从自然语言生成高质量的优化问题求解器，并在复杂问题上实现了92%的最优解率。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于LLM的求解器在可靠性和延迟方面的不足，旨在无需迭代修复即可从自然语言描述生成高质量的优化问题求解器。

Method: OptiHive框架通过单次批量LLM查询生成求解器、问题实例和验证测试，并进行过滤，利用统计模型推断性能以进行不确定性量化和求解器选择。

Result: 在从传统优化问题到多仓库车辆路径问题的各种任务上，OptiHive的性能显著优于基线方法，在最复杂的问题上将最优解率从5%提高到92%。

Conclusion: OptiHive框架在解决优化问题方面表现出色，显著优于现有方法，尤其在复杂问题上大幅提高了最优解的比例。

Abstract: LLM-based solvers have emerged as a promising means of automating problem
modeling and solving. However, they remain unreliable and often depend on
iterative repair loops that result in significant latency. We introduce
OptiHive, an LLM-based framework that produces high-quality solvers for
optimization problems from natural-language descriptions without iterative
self-correction. OptiHive uses a single batched LLM query to generate diverse
components (solvers, problem instances, and validation tests) and filters out
erroneous components to ensure fully interpretable outputs. Taking into account
the imperfection of the generated components, we employ a statistical model to
infer their true performance, enabling principled uncertainty quantification
and solver selection. On tasks ranging from traditional optimization problems
to challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive
significantly outperforms baselines, increasing the optimality rate from 5\% to
92\% on the most complex problems.

</details>


### [583] [Test-time Prompt Intervention](https://arxiv.org/abs/2508.02511)
*Chenxu Yang,Qingyi Si,Mz Dai,Dingyu Yao,Mingyu Zheng,Minghui Chen,Zheng Lin,Weiping Wang*

Main category: cs.AI

TL;DR: PI 框架通过干预和调节 LLM 的推理过程，解决了现有模型中思维链冗余的问题，提高了推理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 在复杂任务中过度依赖结果奖励范式，导致生成的思维链（CoTs）存在过度冗余，如不必要的验证步骤和重复的推理转换，而过程奖励范式的数据难以大规模构建。

Method: 提出了一种名为 PI 的新颖框架，用于测试时提示干预。PI 提供了一个接口，通过及时的（When 模块）和恰当的（How 模块）干预以及干预后采样（Which 模块）来动态地指导和调节推理路径。

Result: 通过在多个模型和数据集上的广泛实验证明，PI 能够显著缩短 CoTs，减少幻觉，并提高推理的简洁性和可靠性。

Conclusion: PI 框架能够显著缩短思维链（CoTs），减少幻觉，生成更简洁可靠的推理过程，并提高了 LLM 的可控性和可解释性。

Abstract: Test-time compute has led to remarkable success in the large language model
(LLM) community, particularly for complex tasks, where longer chains of thought
(CoTs) are generated to enhance reasoning capabilities. However, growing
evidence reveals that such reasoning models often produce CoTs plagued by
excessive redundancy, including unnecessary verification steps and repetitive
reasoning shifts. The root cause lies in post-training of them that overly rely
on outcome reward paradigms, as the data of process reward paradigms, which
regulate intermediate reasoning steps, is difficult to construct at scale. To
address this, we propose PI, a novel framework for Test-time Prompt
Intervention. PI provides an interface to dynamically guide and regulate
reasoning paths during inference through timely (When module) and proper (How
module) interventions and post-intervention sampling (Which module). This
allows human problem-solving expertise and cognitive science principles to be
seamlessly integrated into LLMs' reasoning processes, enhancing controllability
and interpretability. Extensive experiments across multiple models and datasets
demonstrate that PI significantly shortens CoTs while reducing hallucination,
yielding more concise and reliable reasoning.

</details>


### [584] [Accurate and Interpretable Postmenstrual Age Prediction via Multimodal Large Language Model](https://arxiv.org/abs/2508.02525)
*Qifan Chen,Jin Cui,Cindy Duan,Yushuo Han,Yifei Shi*

Main category: cs.AI

TL;DR: 利用微调的多模态大语言模型（MLLM）精确预测新生儿生后月龄（PMA），并生成可解释的临床见解。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习模型在预测新生儿生后月龄（PMA）时作为“黑箱”的问题，该研究旨在实现高精度和高可解释性的双重目标，以支持临床决策。

Method: 我们提出了一种参数高效微调（PEFT）策略，结合指令调优和低秩适配（LoRA），应用于Qwen2.5-VL-7B模型。模型在四张2D皮层表面投影图上进行训练，这些投影图源自新生儿MRI扫描。通过在训练和推理阶段使用不同的提示，使模型能够执行回归任务并生成临床相关的解释。

Result: 该模型在PMA预测上达到了低误差（95%置信区间为0.78至1.52周），并能够生成基于发育特征的可解释输出，展示了其在透明度和可信度方面的潜力。

Conclusion: 该模型通过参数高效微调（PEFT）策略，结合指令调优和低秩适配（LoRA），在Qwen2.5-VL-7B模型上实现了精确的生后月龄（PMA）预测和临床相关解释的生成。该模型在四张源自新生儿MRI扫描的2D皮层表面投影图上进行训练，通过不同的提示（prompt）在训练和推理阶段处理回归任务和生成解释。该方法在PMA预测上实现了低误差（95%置信区间为0.78至1.52周），并能生成基于发育特征的可解释输出，朝着建立透明可信的围产期神经科学人工智能系统迈出了重要一步。

Abstract: Accurate estimation of postmenstrual age (PMA) at scan is crucial for
assessing neonatal development and health. While deep learning models have
achieved high accuracy in predicting PMA from brain MRI, they often function as
black boxes, offering limited transparency and interpretability in clinical
decision support. In this work, we address the dual challenge of accuracy and
interpretability by adapting a multimodal large language model (MLLM) to
perform both precise PMA prediction and clinically relevant explanation
generation. We introduce a parameter-efficient fine-tuning (PEFT) strategy
using instruction tuning and Low-Rank Adaptation (LoRA) applied to the
Qwen2.5-VL-7B model. The model is trained on four 2D cortical surface
projection maps derived from neonatal MRI scans. By employing distinct prompts
for training and inference, our approach enables the MLLM to handle a
regression task during training and generate clinically relevant explanations
during inference. The fine-tuned model achieves a low prediction error with a
95 percent confidence interval of 0.78 to 1.52 weeks, while producing
interpretable outputs grounded in developmental features, marking a significant
step toward transparent and trustworthy AI systems in perinatal neuroscience.

</details>


### [585] [CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge](https://arxiv.org/abs/2508.02583)
*Lei Zan,Keli Zhang,Ruichu Cai,Lujia Pan*

Main category: cs.AI

TL;DR: 提出CAMA框架，通过构建和利用数学因果图（MCG）来增强LLM的数学推理能力，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂的数学推理方面存在挑战，这主要是由于深层结构依赖性。本研究旨在解决这个问题，为LLMs提供显式的、可重用的数学结构。

Method: CAMA是一个两阶段的因果框架：1.学习阶段：结合LLM先验知识和因果发现算法构建数学因果图（MCG），并通过迭代反馈优化MCG。2.推理阶段：根据问题内容和LLM的中间推理过程，从MCG中提取相关的子图，并将其注入LLM以指导推理。

Result: CAMA显著提高了LLM在具有挑战性的数学问题上的性能。此外，实验证明结构化引导优于非结构化方法，非对称因果关系比对称关联带来更大改进。

Conclusion: CAMA框架在具有挑战性的数学问题上显著提高了LLM的性能。实验表明，结构化引导持续优于非结构化方法，并且引入非对称因果关系比仅使用对称关联能带来更大的改进。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across a
wide range of tasks, yet they still struggle with complex mathematical
reasoning, a challenge fundamentally rooted in deep structural dependencies. To
address this challenge, we propose \textbf{CA}usal \textbf{MA}thematician
(\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit,
reusable mathematical structure. In the learning stage, CAMA first constructs
the \textbf{M}athematical \textbf{C}ausal \textbf{G}raph (\textbf{MCG}), a
high-level representation of solution strategies, by combining LLM priors with
causal discovery algorithms applied to a corpus of question-solution pairs. The
resulting MCG encodes essential knowledge points and their causal dependencies.
To better align the graph with downstream reasoning tasks, CAMA further refines
the MCG through iterative feedback derived from a selected subset of the
question-solution pairs. In the reasoning stage, given a new question, CAMA
dynamically extracts a task-relevant subgraph from the MCG, conditioned on both
the question content and the LLM's intermediate reasoning trace. This subgraph,
which encodes the most pertinent knowledge points and their causal
dependencies, is then injected back into the LLM to guide its reasoning
process. Empirical results on real-world datasets show that CAMA significantly
improves LLM performance on challenging mathematical problems. Furthermore, our
experiments demonstrate that structured guidance consistently outperforms
unstructured alternatives, and that incorporating asymmetric causal
relationships yields greater improvements than using symmetric associations
alone.

</details>


### [586] [Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction](https://arxiv.org/abs/2508.02622)
*Enrico De Santis,Antonello Rizzi*

Main category: cs.AI

TL;DR: 一篇关于“Noosemia”现象的论文，解释了用户如何将意向性归因于生成式AI，并探讨了其影响。


<details>
  <summary>Details</summary>
Motivation: 为了解释在人机交互中，用户如何将意向性、代理和内向性归因于生成式AI系统，尤其是在对话或多模态交流中。

Method: 提出并形式化了“Noosemia”这一认知现象，构建了一个跨学科框架，并引入了“a-noosemia”概念。研究将LLM的意义整体论与其提出的“LLM上下文认知场”联系起来，解释了LLM如何构建意义以及在人机交互中如何产生连贯性和代理模拟。

Result: 明确了LLM如何构建意义，以及在人机交互界面中如何产生连贯性和代理模拟。将Noosemia与拟人化、泛灵论、意向性立场和恐怖谷等现象进行了比较，并区分了其独特性。

Conclusion: 该研究提出了“Noosemia”现象，并探讨了其哲学、认识论和社会影响，同时指出了未来研究方向。

Abstract: This paper introduces and formalizes Noosemia, a novel
cognitive-phenomenological phenomenon emerging from human interaction with
generative AI systems, particularly those enabling dialogic or multimodal
exchanges. We propose a multidisciplinary framework to explain how, under
certain conditions, users attribute intentionality, agency, and even
interiority to these systems - a process grounded not in physical resemblance,
but in linguistic performance, epistemic opacity, and emergent technological
complexity. By linking an LLM declination of meaning holism to our technical
notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct
meaning relationally and how coherence and a simulacrum of agency arise at the
human-AI interface. The analysis situates noosemia alongside pareidolia,
animism, the intentional stance and the uncanny valley, distinguishing its
unique characteristics. We also introduce a-noosemia to describe the
phenomenological withdrawal of such projections. The paper concludes with
reflections on the broader philosophical, epistemological, and social
implications of noosemic dynamics and directions for future research.

</details>


### [587] [Actionable Counterfactual Explanations Using Bayesian Networks and Path Planning with Applications to Environmental Quality Improvement](https://arxiv.org/abs/2508.02634)
*Enrique Valero-Leal,Pedro Larrañaga,Concha Bielza*

Main category: cs.AI

TL;DR: 提出了一种新的可操作反事实解释方法，不直接使用训练数据，而是利用密度估计和路径规划，在合成和真实数据上均优于现有方法，尤其在公平性和高风险场景下表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了让终端用户理解机器学习机制，需要可操作的反事实解释，即能够将原始案例转化为反事实案例。现有方法存在不足，特别是在处理敏感或私有数据以及在高风险场景中确保公平性方面。

Method: 提出了一种新的可操作反事实解释方法，该方法不直接使用训练数据，而是利用数据学习密度估计器，然后应用路径规划算法进行搜索。特别强调使用贝叶斯网络来估计数据密度，以提高可解释性。

Result: 所提出的方法在合成基准（15个数据集）和真实世界环境（EPA数据集）上都取得了比现有技术更好的结果，发现了更可行的和更简单的反事实。该方法能够捕捉变量交互，确保决策公平性，并揭示了与住房危机相关的变量对社区的潜在负面影响。

Conclusion: 该方法在合成基准和真实世界数据集上均优于现有算法，能够找到更可行的、更简单的反事实解释，并且在处理高风险场景和确保公平性方面表现出色，能够捕捉变量交互，避免因一项政策改善而损害其他领域。

Abstract: Counterfactual explanations study what should have changed in order to get an
alternative result, enabling end-users to understand machine learning
mechanisms with counterexamples. Actionability is defined as the ability to
transform the original case to be explained into a counterfactual one. We
develop a method for actionable counterfactual explanations that, unlike
predecessors, does not directly leverage training data. Rather, data is only
used to learn a density estimator, creating a search landscape in which to
apply path planning algorithms to solve the problem and masking the endogenous
data, which can be sensitive or private. We put special focus on estimating the
data density using Bayesian networks, demonstrating how their enhanced
interpretability is useful in high-stakes scenarios in which fairness is
raising concern. Using a synthetic benchmark comprised of 15 datasets, our
proposal finds more actionable and simpler counterfactuals than the current
state-of-the-art algorithms. We also test our algorithm with a real-world
Environmental Protection Agency dataset, facilitating a more efficient and
equitable study of policies to improve the quality of life in United States of
America counties. Our proposal captures the interaction of variables, ensuring
equity in decisions, as policies to improve certain domains of study (air,
water quality, etc.) can be detrimental in others. In particular, the
sociodemographic domain is often involved, where we find important variables
related to the ongoing housing crisis that can potentially have a severe
negative impact on communities.

</details>


### [588] [D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss](https://arxiv.org/abs/2508.02644)
*Guowei Zou,Weibing Li,Hejun Wu,Yukun Qian,Yuhang Wang,Haitao Wang*

Main category: cs.AI

TL;DR: D2PPO通过分散损失解决扩散策略表示坍塌，提升机器人操作精度，在RoboMimic和真实机器人实验中刷新SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决扩散策略在机器人操作中因语义相似的观测映射到无法区分的特征而导致的表示坍塌问题，以应对复杂机器人操作中对细微但关键变化的敏感性要求。

Method: D2PPO（扩散策略策略优化与分散损失）通过在训练过程中引入分散损失正则化，将批次内的所有隐藏表示视为负样本对，迫使网络学习区分相似观测的表示，从而提升策略识别细微差别的能力。根据任务复杂性选择性地在早期或晚期层应用正则化。

Result: D2PPO在RoboMimic基准测试中，预训练平均提升22.7%，微调后平均提升26.1%，达到新的SOTA。真实世界机器人实验（Franka Emika Panda）结果也证明了该方法的优越性，尤其在复杂任务中成功率高。

Conclusion: D2PPO通过引入分散损失正则化，有效解决了扩散策略表示坍塌问题，并在RoboMimic基准测试和真实机器人实验中取得了显著的性能提升，尤其在复杂操作任务中表现优越。

Abstract: Diffusion policies excel at robotic manipulation by naturally modeling
multimodal action distributions in high-dimensional spaces. Nevertheless,
diffusion policies suffer from diffusion representation collapse: semantically
similar observations are mapped to indistinguishable features, ultimately
impairing their ability to handle subtle but critical variations required for
complex robotic manipulation. To address this problem, we propose D2PPO
(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces
dispersive loss regularization that combats representation collapse by treating
all hidden representations within each batch as negative pairs. D2PPO compels
the network to learn discriminative representations of similar observations,
thereby enabling the policy to identify subtle yet crucial differences
necessary for precise manipulation. In evaluation, we find that early-layer
regularization benefits simple tasks, while late-layer regularization sharply
enhances performance on complex manipulation tasks. On RoboMimic benchmarks,
D2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after
fine-tuning, setting new SOTA results. In comparison with SOTA, results of
real-world experiments on a Franka Emika Panda robot show the excitingly high
success rate of our method. The superiority of our method is especially evident
in complex tasks. Project page: https://guowei-zou.github.io/d2ppo/

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [589] [Deterministic Fault-Tolerant Local Load Balancing and its Applications against Adaptive Adversaries](https://arxiv.org/abs/2508.01373)
*Dariusz R. Kowalski,Jan Olkowski*

Main category: cs.DC

TL;DR: 本文提出了一种新的容错局部负载均衡算法，并将其应用于共识问题，提高了效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在分布式计算中，负载均衡是一个基本问题。然而，在存在节点故障的网络中实现局部负载均衡具有挑战性。本文旨在设计一种能够容忍故障的局部负载均衡算法，并探索其在共识等分布式问题中的应用。

Method: 本文设计了一个新的确定性容错局部负载均衡（LLB）算法，该算法能够处理节点故障，并在指数级时间内收敛到平均值。并在此基础上，提出了一个随机共识算法，一个针对遗漏故障的网络共识解决方案，以及一个针对自适应遗漏故障对手的近乎最优的解决方案。

Result: 本文提出了一个新的确定性容错局部负载均衡（LLB）算法，该算法能够处理节点故障，并在指数级时间内收敛到平均值。在共识问题方面，本文提出了一个随机共识算法，该算法在通信复杂性方面优于现有解决方案。此外，本文还提出了一个针对遗漏故障的网络共识解决方案，该解决方案在时间复杂性和通信复杂性方面都接近最优。

Conclusion: 本文提出了一个新的确定性容错局部负载均衡（LLB）算法，该算法能够处理节点故障，并在指数级时间内收敛到平均值。此外，本文还展示了该算法在三个应用中的效用：一个随机共识算法，一个针对遗漏故障的网络共识解决方案，以及一个针对自适应遗漏故障对手的近乎最优的解决方案。

Abstract: Load balancing is among the basic primitives in distributed computing. In
this paper, we consider this problem when executed locally on a network with
nodes prone to failures. We show that there exist lightweight network
topologies that are immune to message delivery failures incurred by (at most) a
constant fraction of all nodes. More precisely, we design a novel deterministic
fault-tolerant local load balancing (LLB) algorithm, which, similarly to their
classical counterparts working in fault-free networks, has a relatively simple
structure and guarantees exponentially fast convergence to the average value
despite crash and omission failures.
  As the second part of our contribution, we show three applications of the
newly developed fault-tolerant local load balancing protocol. We give a
randomized consensus algorithm, working against $t < n / 3$ crash failures,
that improves over the best-known consensus solution by Hajiaghayi et al. with
respect to communication complexity, yet with an arguable simpler technique of
combining a randomly and locally selected virtual communication graph with a
deterministic fault-tolerant local load balancing on this graph.
  We also give a new solution for consensus for networks with omission
failures. Our solution works against $t < \frac{n}{C\log{n} (\log\log n)^2}$
omissions, for some constant $C$, is nearly optimal in terms of time
complexity, but most notably -- it has communication complexity $O((t^2 +
n)\text{ polylog } {n})$, matching, within a polylogarithmic factor, the lower
bound by Abraham et. al. with respect to both terms depending on $t$ and $n$.
Ours is the first algorithm in the literature that is simultaneously nearly
optimal, in terms of $n,t$, with respect to both complexity measures, against
the adaptive omission-causing adversary.

</details>


### [590] [An Analysis of HPC and Edge Architectures in the Cloud](https://arxiv.org/abs/2508.01494)
*Steven Santillan,Cristina L. Abad*

Main category: cs.DC

TL;DR: 对 396 个 AWS 云架构数据集进行了分析，重点关注 HPC 和边缘组件，以了解行业实践和趋势。


<details>
  <summary>Details</summary>
Motivation: 为了深入了解云中 HPC 和边缘解决方案的行业实践和趋势，并为相关研究提供指导。

Method: 对 396 个真实世界云架构数据集进行分析，识别并表征包含 HPC 或边缘组件的架构的设计。

Result: 识别了包含 HPC 或边缘组件的云架构，并对其设计进行了表征，包括 AWS 服务的应用、存储系统的类型、架构复杂性以及机器学习服务的使用情况。

Conclusion: 该研究为构建云中 HPC 和边缘解决方案提供了宝贵的行业实践和趋势见解，并指导了新的研究方向。

Abstract: We analyze a recently published dataset of 396 real-world cloud architectures
deployed on AWS, from companies belonging to a wide range of industries. From
this dataset, we identify those architectures that contain HPC or edge
components and characterize their designs. Specifically, we investigate the
prevalence and interplay of AWS services within these architectures, examine
the types of storage systems employed, assess architectural complexity and the
use of machine learning services, discuss the implications of our findings and
how representative these results are of HPC and edge architectures in the
cloud. This characterization provides valuable insights into current industry
practices and trends in building robust and scalable HPC and edge solutions in
the cloud continuum, and can be valuable for those seeking to better understand
how these architectures are being built and to guide new research.

</details>


### [591] [Faster Distributed $Δ$-Coloring via a Reduction to MIS](https://arxiv.org/abs/2508.01762)
*Yann Bourreau,Sebastian Brandt,Alexandre Nolin*

Main category: cs.DC

TL;DR: 本研究将 Δ-coloring 问题的确定性轮数复杂性降低到 $	ilde{O}(\log^{5/3} n)$，与 MIS 问题复杂性持平，并对随机化和参数化复杂性进行了改进。


<details>
  <summary>Details</summary>
Motivation: 旨在解决分布式计算中 Δ-coloring 问题的确定性复杂性问题，并寻求与 MIS 问题复杂性相匹配的解决方案。

Method: 提出了一种将 Δ-coloring 问题规约到 MIS (Maximal Independent Set) 问题的方法。

Result: 实现了 Δ-coloring 问题的确定性复杂性为 $	ilde{O}(\log^{5/3} n)$ 轮，并对随机化和参数化复杂性也进行了改进。

Conclusion: 本研究通过将 Δ-coloring 问题规约到 MIS 问题，实现了确定性分布式计算下 Δ-coloring 问题的 $	ilde{O}(\log^{5/3} n)$ 的轮数复杂性，与目前已知的 $(\Delta+1)$-coloring 问题的最优上界持平。该规约还为随机化分布式计算以及以 n 和 Δ 为参数的分布式计算带来了改进。

Abstract: Recent improvements on the deterministic complexities of fundamental graph
problems in the LOCAL model of distributed computing have yielded
state-of-the-art upper bounds of $\tilde{O}(\log^{5/3} n)$ rounds for maximal
independent set (MIS) and $(\Delta + 1)$-coloring [Ghaffari, Grunau, FOCS'24]
and $\tilde{O}(\log^{19/9} n)$ rounds for the more restrictive
$\Delta$-coloring problem [Ghaffari, Kuhn, FOCS'21; Ghaffari, Grunau, FOCS'24;
Bourreau, Brandt, Nolin, STOC'25]. In our work, we show that $\Delta$-coloring
can be solved deterministically in $\tilde{O}(\log^{5/3} n)$ rounds as well,
matching the currently best bound for $(\Delta + 1)$-coloring.
  We achieve our result by developing a reduction from $\Delta$-coloring to MIS
that guarantees that the (asymptotic) complexity of $\Delta$-coloring is at
most the complexity of MIS, unless MIS can be solved in sublogarithmic time, in
which case, due to the $\Omega(\log n)$-round $\Delta$-coloring lower bound
from [BFHKLRSU, STOC'16], our reduction implies a tight complexity of
$\Theta(\log n)$ for $\Delta$-coloring. In particular, any improvement on the
complexity of the MIS problem will yield the same improvement for the
complexity of $\Delta$-coloring (up to the true complexity of
$\Delta$-coloring).
  Our reduction yields improvements for $\Delta$-coloring in the randomized
LOCAL model and when complexities are parameterized by both $n$ and $\Delta$.
We obtain a randomized complexity bound of $\tilde{O}(\log^{5/3} \log n)$
rounds (improving over the state of the art of $\tilde{O}(\log^{8/3} \log n)$
rounds) on general graphs and tight complexities of $\Theta(\log n)$ and
$\Theta(\log \log n)$ for the deterministic, resp.\ randomized, complexity on
bounded-degree graphs. In the special case of graphs of constant clique number
(which for instance include bipartite graphs), we also give a reduction to the
$(\Delta+1)$-coloring problem.

</details>


### [592] [Efficient Byzantine Consensus MechanismBased on Reputation in IoT Blockchain](https://arxiv.org/abs/2508.01856)
*Xu Yuan,Fang Luo,Muhammad Zeeshan Haider,Zhikui Chen,Yucheng Li*

Main category: cs.DC

TL;DR: 本研究提出了一种名为高效拜占庭声誉共识（EBRC）的新型共识机制，以解决大规模物联网部署中区块链的挑战，并在性能和安全性方面优于传统算法。


<details>
  <summary>Details</summary>
Motivation: 解决大规模物联网（IoT）网络中部署区块链应用时，物联网设备存储、功耗和计算能力有限的挑战，以及现有共识算法在节点可靠性、每秒交易量（TPS）和可扩展性方面存在的问题。

Method: 提出了一种名为高效拜占庭声誉共识（EBRC）的机制，该机制通过改进节点可靠性、鲁棒性和活动节点管理来解决现有共识算法的问题。

Result: 实验表明，EBRC算法具有更低的共识延迟、更高的吞吐量、改进的安全性和更低的验证成本。

Conclusion: EBRC算法在共识延迟、吞吐量、安全性和验证成本方面优于传统算法，为解决物联网+区块链+互联网司法管辖区建设问题提供了新的参考思路。

Abstract: Blockchain technology has advanced rapidly in recent years and is now widely
used in a variety of fields. Blockchain appears to be one of the best solutions
for managing massive heterogeneous devices while achieving advanced data
security and data reputation, particularly in the field of large-scale IoT
(Internet of Things) networks. Despite the numerous advantages, there are still
challenges while deploying IoT applications on blockchain systems due to the
limited storage, power, and computing capability of IoT devices, and some of
these problems are caused by the consensus algorithm, which plays a significant
role in blockchain systems by ensuring overall system reliability and
robustness. Nonetheless, most existing consensus algorithms are prone to poor
node reliability, low transaction per second (TPS) rates, and scalability
issues. Aiming at some critical problems in the existing consensus algorithms,
this paper proposes the Efficient Byzantine Reputation-based Consensus (EBRC)
mechanism to resolve the issues raised above. In comparison to traditional
algorithms, we reinvented ways to evaluate node reliability and robustness and
manage active nodes. Our experiments show that the EBRC algorithm has lower
consensus delay, higher throughput, improved security, and lower verification
costs. It offers new reference ideas for solving the Internet of
Things+blockchain+Internet court construction problem.

</details>


### [593] [Machine Learning-Driven Performance Analysis of Compressed Communication in Aerial-RIS Networks for Future 6G Networks](https://arxiv.org/abs/2508.01911)
*Muhammad Farhan Khan,Muhammad Ahmed Mohsin,Zeeshan Alam,Muhammad Saad,Muhammad Waqar*

Main category: cs.DC

TL;DR: 本文提出了一种结合无人机RIS、NOMA和CoMP的系统模型，并使用机器学习来压缩RIS的反馈，以提高6G网络的速率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对未来6G和无线网络（尤其是在密集的城市环境中）带宽耗尽和容量有限的挑战，旨在提高数据速率。

Method: 本文提出了一种集成无人机辅助可重构智能表面（RIS）、非正交多址接入（NOMA）和协调多点传输（CoMP）的新型系统模型，并提出了一种机器学习自编码器技术来压缩量化相位移（QPS）的反馈。

Result: 所提出的系统模型和机器学习技术显著提高了整体系统容量和总和速率，并在频谱效率、中断概率和带宽利用率方面取得了实质性改进。

Conclusion: 仿真结果表明, 所提出的架构在提高频谱效率、中断概率和带宽利用率方面具有显著优势，显示了其在增强网络性能方面的潜力。

Abstract: In the future 6G and wireless networks, particularly in dense urban
environments, bandwidth exhaustion and limited capacity pose significant
challenges to enhancing data rates. We introduce a novel system model designed
to improve the data rate of users in next-generation multi-cell networks by
integrating Unmanned Aerial Vehicle (UAV)-Assisted Reconfigurable Intelligent
Surfaces (RIS), Non-Orthogonal Multiple Access (NOMA), and Coordinated
Multipoint Transmission (CoMP). Optimally deploying Aerial RIS for higher data
rates, employing NOMA to improve spectral efficiency, and utilizing CoMP to
mitigate inter-cell interference (ICI), we significantly enhance the overall
system capacity and sum rate. Furthermore, we address the challenge of feedback
overhead associated with Quantized Phase Shifts (QPS) from the receiver to RIS.
The feedback channel is band-limited and cannot support a large overhead of QPS
for uplink communication. To ensure seamless transmission, we propose a Machine
Learning Autoencoder technique for a compressed communication of QPS from the
receiver to RIS, while maintaining high accuracy. Additionally, we investigate
the impact of the number of Aerial RIS elements and power allocation ratio for
NOMA on the individual data rate of users. Our simulation results demonstrate
substantial improvements in spectral efficiency, outage probability, and
bandwidth utilization, highlighting the potential of the proposed architecture
to enhance network performance.

</details>


### [594] [Prefill-Decode Aggregation or Disaggregation? Unifying Both for Goodput-Optimized LLM Serving](https://arxiv.org/abs/2508.01989)
*Chao Wang,Pengfei Zuo,Zhangyu Chen,Yunkai Liang,Zhou Yu,Ming-Chang Yang*

Main category: cs.DC

TL;DR: TaiChi通过结合PD聚合与分片、使用不同GPU实例并引入“延迟转移”和精细调度机制，优化了LLM服务在不同SLO下的吞吐量，尤其在平衡SLO下效果显著。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有预填充-解码（PD）聚合和分片在服务大型语言模型（LLMs）时，各自在不同服务水平目标（SLO）下表现优劣的问题，以及在平衡的SLO条件下两者均无法达到最优吞吐量的问题，提出TaiChi系统以实现最优吞吐量。

Method: TaiChi提出了一种新的LLM服务系统，它结合了预填充-解码（PD）分片和聚合的两种方法，并通过使用两种类型的GPU实例（预填充密集型和解码密集型）来优化服务。该系统通过三个可配置的滑块来调整GPU实例的比例和块大小，以适应不同的服务水平目标（SLO）。通过“延迟转移”机制，它可以在满足SLO的请求和可能违反SLO的请求之间重新分配资源。此外，该系统还引入了两种调度机制：流式解码调度（控制TPOT）和长度感知预填充调度（管理TTFT），以优化请求分配。

Result: 实验表明，TaiChi在平衡的TTFT和TPOT SLO条件下，相比现有的最先进系统，吞吐量最高可提升77%。

Conclusion: TaiChi通过统一的预填充-解码（PD）聚合和分片，并采用差异化GPU实例（预填充密集型和解码密集型）以及可配置的控制参数，实现了在各种时间对首次令牌（TTFT）和每输出令牌（TPOT）的服务水平目标（SLO）下的最优吞吐量。其核心创新在于“延迟转移”，通过动态分配资源来满足更多SLO，并通过流式解码调度和长度感知预填充调度来协同优化请求分配，尤其在平衡的SLO条件下，能将吞吐量提升高达77%。

Abstract: An ongoing debate considers whether prefill-decode (PD) aggregation or
disaggregation is superior for serving large language models (LLMs). This has
driven optimizations for both approaches, each showing distinct advantages.
This paper compares PD aggregation and disaggregation, showing that each excels
under different service-level objectives (SLOs): aggregation is optimal for
tight time-to-first-token (TTFT) and relaxed time-per-output-token (TPOT),
while disaggregation excels for strict TPOT and relaxed TTFT. However, under
balanced TTFT and TPOT SLOs, neither approach delivers optimal goodput.
  This paper proposes TaiChi, an LLM serving system that unifies PD
disaggregation and aggregation for optimal goodput under any combination of
TTFT and TPOT SLOs. TaiChi uses a unified disaggregation-aggregation
architecture with differentiated-capability GPU instances: prefill-heavy (fast
prefill, high-interference decode) and decode-heavy (low-interference decode,
slow prefill). Three configurable sliders control the ratio between these
instances and their chunk sizes. TaiChi adapts to various SLO regimes by
adjusting sliders. When TTFT constraints are tight, TaiChi resembles a PD
aggregation configuration; when TPOT dominates, it adapts toward PD
disaggregation. Crucially, under balanced SLOs, TaiChi enables a hybrid mode
for superior goodput. The key innovation behind this hybrid mode is latency
shifting: selectively reallocating GPU resources from requests that meet SLOs
to those at risk of violation, maximizing the number of SLO-satisfied requests.
This fine-grained latency shifting is orchestrated by two scheduling
mechanisms: flowing decode scheduling to control TPOTs and length-aware prefill
scheduling to manage TTFTs, which jointly optimize request assignment. Our
experiments show TaiChi improves goodput by up to 77% over state-of-the-art
systems under balanced TTFT and TPOT SLOs.

</details>


### [595] [DySTop](https://arxiv.org/abs/2508.01996)
*Yizhou Shi,Qianpiao Ma,Yan Xu,Junlong Zhou,Ming Hu,Yunming Liao,Hongli Xu*

Main category: cs.DC

TL;DR: DySTop是一种创新的异步去中心化联邦学习机制，通过动态调整模型新鲜度和通信拓扑，显著减少了训练时间和通信开销，同时保持了模型准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化联邦学习（DFL）机制主要依赖同步通信，在异构和动态边缘环境中效率低下。虽然一些异步DFL（ADFL）机制被提出，但它们存在模型聚合延迟和频繁的模型传输问题，导致在非IID数据上训练性能下降且通信开销高。

Method: DySTop提出了一种新机制，通过动态控制模型新鲜度（worker activation algorithm, WAA）和优化通信拓扑（phase-aware topology construction algorithm, PTCA）来改进异步联邦学习（ADFL）。该机制在每个训练轮次中激活一部分节点，并选择其邻居节点进行模型传输和聚合，然后进行本地训练。

Result: DySTop通过了大规模仿真和真实测试台实验的评估，结果显示其与最先进的解决方案相比，完成了时间缩短了51.8%，通信资源消耗降低了57.1%，同时保持了相同的模型准确性。

Conclusion: DySTop通过联合优化动态新鲜度控制和ADFL中的拓扑构建，并在同步通信下，通过包含激活的节点子集来减少通信开销和处理数据非IID，从而在模型准确性相同的情况下，将完成时间缩短了51.8%，通信资源消耗降低了57.1%。

Abstract: Federated Learning (FL) has emerged as a potential distributed learning
paradigm that enables model training on edge devices (i.e., workers) while
preserving data privacy. However, its reliance on a centralized server leads to
limited scalability. Decentralized federated learning (DFL) eliminates the
dependency on a centralized server by enabling peer-to-peer model exchange.
Existing DFL mechanisms mainly employ synchronous communication, which may
result in training inefficiencies under heterogeneous and dynamic edge
environments. Although a few recent asynchronous DFL (ADFL) mechanisms have
been proposed to address these issues, they typically yield stale model
aggregation and frequent model transmission, leading to degraded training
performance on non-IID data and high communication overhead. To overcome these
issues, we present DySTop, an innovative mechanism that jointly optimizes
dynamic staleness control and topology construction in ADFL. In each round,
multiple workers are activated, and a subset of their neighbors is selected to
transmit models for aggregation, followed by local training. We provide a
rigorous convergence analysis for DySTop, theoretically revealing the
quantitative relationships between the convergence bound and key factors such
as maximum staleness, activating frequency, and data distribution among
workers. From the insights of the analysis, we propose a worker activation
algorithm (WAA) for staleness control and a phase-aware topology construction
algorithm (PTCA) to reduce communication overhead and handle data non-IID.
Extensive evaluations through both large-scale simulations and real-world
testbed experiments demonstrate that our DySTop reduces completion time by
51.8% and the communication resource consumption by 57.1% compared to
state-of-the-art solutions, while maintaining the same model accuracy.

</details>


### [596] [Self-assessment approach for resource management protocols in heterogeneous computational systems](https://arxiv.org/abs/2508.02202)
*Rui Eduardo Lopes,Duarte Raposo,Pedro V. Teixeira,Susana Sargento*

Main category: cs.DC

TL;DR: 一种新的启发式资源估计方法，可处理各种计算系统和需求，并具有可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着异构计算系统上运行的异构应用服务的数量不断增加，资源管理问题变得越来越重要。然而，当前解决方案在处理可扩展性和适应性方面存在不足。

Method: 提出了一种基于启发式估计的解决方案，该方案能够考虑动态加权需求、计算每个节点的能力以及支持评估其他资源类型。

Result: 验证结果表明，该方法在资源估计方面表现直接，同时具有可扩展性和可扩展性。

Conclusion: 该方法在资源估计方面表现直接，同时具有可扩展性和可扩展性。

Abstract: With an ever growing number of heterogeneous applicational services running
on equally heterogeneous computational systems, the problem of resource
management becomes more essential. Although current solutions consider some
network and time requirements, they mostly handle a pre-defined list of
resource types by design and, consequently, fail to provide an extensible
solution to assess any other set of requirements or to switch strategies on its
resource estimation. This work proposes an heuristics-based estimation solution
to support any computational system as a self-assessment, including
considerations on dynamically weighting the requirements, how to compute each
node's capacity towards an admission request, and also offers the possibility
to extend the list of resource types considered for assessment, which is an
uncommon view in related works. This algorithm can be used by distributed and
centralized resource allocation protocols to decide the best node(s) for a
service intended for deployment. This approach was validated across its
components and the results show that its performance is straightforward in
resource estimation while allowing scalability and extensibility.

</details>


### [597] [FedAPTA: Federated Multi-task Learning in Computing Power Networks with Adaptive Layer-wise Pruning and Task-aware Aggregation](https://arxiv.org/abs/2508.02230)
*Yachao Yuan,Zhen Yu,Jin Wang,Zhipeng Cheng,Jianhua Hu*

Main category: cs.DC

TL;DR: FedAPTA是一个联邦多任务学习框架，通过模型剪枝和聚合策略解决了计算能力网络中联邦学习的资源浪费和模型异构问题，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法主要关注单任务的计算和通信开销，而忽略了在计算能力网络中，异构设备在多任务联邦学习场景下的计算资源浪费问题。

Method: FedAPTA框架通过层级模型剪枝技术减小本地模型大小，并结合异构模型恢复策略和任务感知模型聚合方法来处理不同任务的结构异构本地模型，以减轻计算资源浪费。

Result: 实验结果表明，FedAPTA相比于现有的最先进的联邦学习方法，性能提升高达4.23%。

Conclusion: FedAPTA通过其层级模型剪枝技术、异构模型恢复策略和任务感知模型聚合方法，有效解决了联邦多任务学习在计算能力网络中的资源浪费问题，并在与九种SOTA联邦学习方法的对比实验中，取得了高达4.23%的性能提升。

Abstract: Federated Learning (FL) has shown considerable promise in Computing Power
Networks (CPNs) for privacy protection, efficient data utilization, and dynamic
collaboration. Although it offers practical benefits, applying FL in CPNs
continues to encounter a major obstacle, i.e., multi-task deployment. However,
existing work mainly focuses on mitigating FL's computation and communication
overhead of a single task while overlooking the computing resource wastage
issue of heterogeneous devices across multiple tasks in FL under CPNs. To
tackle this, we design FedAPTA, a federated multi-task learning framework in
CPNs. FedAPTA alleviates computing resource wastage through the developed
layer-wise model pruning technique, which reduces local model size while
considering both data and device heterogeneity. To aggregate structurally
heterogeneous local models of different tasks, we introduce a heterogeneous
model recovery strategy and a task-aware model aggregation method that enables
the aggregation through infilling local model architecture with the shared
global model and clustering local models according to their specific tasks. We
deploy FedAPTA on a realistic FL platform and benchmark it against nine SOTA FL
methods. The experimental outcomes demonstrate that the proposed FedAPTA
considerably outperforms the state-of-the-art FL methods by up to 4.23%. Our
code is available at https://github.com/Zhenzovo/FedCPN.

</details>


### [598] [PUSHtap: PIM-based In-Memory HTAP with Unified Data Storage Format](https://arxiv.org/abs/2508.02309)
*Yilong Zhao,Mingyu Gao,Huanchen Zhang,Fangxin Liu,Gongye Chen,He Xian,Haibing Guan,Li Jiang*

Main category: cs.DC

TL;DR: PUSHtap通过统一数据格式和利用PIM并行性，解决了HTAP的数据格式难题，显著提升了OLAP和OLTP的性能。


<details>
  <summary>Details</summary>
Motivation: HTAP系统面临数据格式困境，无法同时实现性能隔离、数据新鲜度和工作负载特定的优化。计算密集型OLTP操作适合行存储，而内存密集型OLAP操作受益于列存储。

Method: 提出了一种统一的数据存储格式，结合了新颖的数据对齐和放置技术，以优化CPU和PIM单元的有效带宽并利用PIM的并行性。实现了支持单实例HTAP的多版本并发控制（MVCC）。扩展了商业PIM架构以支持OLAP操作以及来自PIM和CPU的并发访问。

Result: 与多实例PIM设计相比，PUSHtap实现了3.4倍/4.4倍的OLAP/OLTP吞吐量提升。

Conclusion: PUSHtap通过结合交错CPU访问和本地化PIM单元访问，成功解决了HTAP系统的数据格式矛盾，实现了性能隔离、数据新鲜度和工作负载特定的优化目标。

Abstract: Hybrid transaction/analytical processing (HTAP) is an emerging database
paradigm that supports both online transaction processing (OLTP) and online
analytical processing (OLAP) workloads. Computing-intensive OLTP operations,
involving row-wise data manipulation, are suitable for row-store format. In
contrast, memory-intensive OLAP operations, which are column-centric, benefit
from column-store format. This \emph{data-format dilemma} prevents HTAP systems
from concurrently achieving three design goals: performance isolation, data
freshness, and workload-specific optimization. Another background technology is
Processing-in-Memory (PIM), which integrates computing units (PIM units) inside
DRAM memory devices to accelerate memory-intensive workloads, including OLAP.
  Our key insight is to combine the interleaved CPU access and localized PIM
unit access to provide two-dimensional access to address the data format
contradictions inherent in HTAP. First, we propose a unified data storage
format with novel data alignment and placement techniques to optimize the
effective bandwidth of CPUs and PIM units and exploit the PIM's parallelism.
Second, we implement the multi-version concurrency control (MVCC) essential for
single-instance HTAP. Third, we extend the commercial PIM architecture to
support the OLAP operations and concurrent access from PIM and CPU. Experiments
show that PUSHtap can achieve 3.4\texttimes{}/4.4\texttimes{} OLAP/OLTP
throughput improvement compared to multi-instance PIM-based design.

</details>


### [599] [TeraNoC: A Multi-Channel 32-bit Fine-Grained, Hybrid Mesh-Crossbar NoC for Efficient Scale-up of 1000+ Core Shared-L1-Memory Clusters](https://arxiv.org/abs/2508.02446)
*Yichao Zhang,Zexin Fu,Tim Fischer,Yinrong Li,Marco Bertuletti,Luca Benini*

Main category: cs.DC

TL;DR: TeraNoC是一种混合2D网格-交叉线片上互连结构，解决了扩展带宽、低延迟和面积效率的挑战。它能支持大规模众核共享内存集群，与纯交叉线设计相比，在1024核集群中可节省37.8%的面积并提高98.7%的面积效率，同时保持高计算利用率。


<details>
  <summary>Details</summary>
Motivation: 当前片上互连设计面临在扩展带宽的同时保持低延迟和高面积效率的挑战。传统的2D网格虽然布线面积小，但延迟随跳数增加而不适合延迟敏感应用；而交叉线延迟低，但布线复杂度和资源需求随I/O数量呈二次方增长。这种两难境地阻碍了低延迟、紧耦合的众核共享内存集群的发展，迫使设计者转向硬件和软件开销更大的小型、松耦合集群。因此，需要一种既能扩展又具有低延迟、低布线开销的互连结构。

Method: TeraNoC是一种开源的混合2D网格-交叉线片上互连结构。该结构基于32位字宽的多通道2D网格和交叉线构建，并通过路由器重映射器来平衡互连通道的流量负载。

Result: TeraNoC成功地在一个包含1024个单周期、单发射核和4096个L1内存库的集群（12nm工艺）中实现了高计算利用率（高达0.85 IPC），尤其是在计算密集型、数据并行类生成式AI核心应用中。在交叉线访问为主的应用中，TeraNoC的功耗占总功耗的7.6%，而在2D网格流量大的应用中占22.7%。与纯交叉线集群相比，TeraNoC将芯片面积减少了37.8%，面积效率（GFLOP/s/mm^2）提高了高达98.7%，而逻辑面积仅占10.9%。

Conclusion: TeraNoC通过结合2D网格和交叉线的优点，实现了高带宽、低延迟和高面积效率，能够有效支持大规模共享内存集群的设计。通过使用路由器重映射器来平衡流量负载， TeraNoC 在一个包含1024个核心和4096个L1内存库的集群中，实现了高达0.85 IPC的计算利用率，并且与纯交叉线集群相比，显著减少了芯片面积（37.8%）和功耗，同时提高了面积效率（98.7%）。

Abstract: A key challenge in on-chip interconnect design is to scale up bandwidth while
maintaining low latency and high area efficiency. 2D-meshes scale with low
wiring area and congestion overhead; however, their end-to-end latency
increases with the number of hops, making them unsuitable for latency-sensitive
core-to-L1-memory access. On the other hand, crossbars offer low latency, but
their routing complexity grows quadratically with the number of I/Os, requiring
large physical routing resources and limiting area-efficient scalability. This
two-sided interconnect bottleneck hinders the scale-up of many-core,
low-latency, tightly coupled shared-memory clusters, pushing designers toward
instantiating many smaller and loosely coupled clusters, at the cost of
hardware and software overheads. We present TeraNoC, an open-source, hybrid
mesh-crossbar on-chip interconnect that offers both scalability and low
latency, while maintaining very low routing overhead. The topology, built on
32bit word-width multi-channel 2D-meshes and crossbars, enables the
area-efficient scale-up of shared-memory clusters. A router remapper is
designed to balance traffic load across interconnect channels. Using TeraNoC,
we build a cluster with 1024 single-stage, single-issue cores that share a
4096-banked L1 memory, implemented in 12nm technology. The low interconnect
stalls enable high compute utilization of up to 0.85 IPC in compute-intensive,
data-parallel key GenAI kernels. TeraNoC only consumes 7.6\% of the total
cluster power in kernels dominated by crossbar accesses, and 22.7\% in kernels
with high 2D-mesh traffic. Compared to a hierarchical crossbar-only cluster,
TeraNoC reduces die area by 37.8\% and improves area efficiency (GFLOP/s/mm2)
by up to 98.7\%, while occupying only 10.9\% of the logic area.

</details>


### [600] [xDeepServe: Model-as-a-Service on Huawei CloudMatrix384](https://arxiv.org/abs/2508.02520)
*Ao Xiao,Bangzheng He,Baoquan Zhang,Baoxing Huai,Bingji Wang,Bo Wang,Bo Xu,Boyi Hou,Chan Yang,Changhong Liu,Cheng Cui,Chenyu Zhu,Cong Feng,Daohui Wang,Dayun Lin,Duo Zhao,Fengshao Zou,Fu Wang,Gangqiang Zhang,Gengyuan Dan,Guanjie Chen,Guodong Guan,Guodong Yang,Haifeng Li,Haipei Zhu,Hao Feng,Hao Huang,Hao Xu,Hengrui Ma,Hengtao Fan,Hui Liu,Jia Li,Jiang Liu,Jiang Xu,Jie Meng,Jinhan Xin,Junhao Hu,Juwei Chen,Lan Yu,Lanxin Miao,Liang Liu,Linan Jing,Lu Zhou,Meina Han,Mingkun Deng,Mingyu Deng,Naitian Deng,Nizhong Lin,Peihan Zhao,Peng Pan,Pengfei Shen,Ping Li,Qi Zhang,Qin Zhang,Qingrong Xia,Qingyi Zhang,Qunchao Fu,Ren Guo,Ruimin Gao,Shaochun Li,Sheng Long,Shentian Li,Shining Wan,Shuai Shen,Shuangfu Zeng,Shuming Jing,Siqi Yang,Song Zhang,Tao Xu,Tianlin Du,Ting Chen,Wanxu Wu,Wei Jiang,Weinan Tong,Weiwei Chen,Wen Peng,Wenli Zhou,Wenquan Yang,Wenxin Liang,Xiang Liu,Xiaoli Zhou,Xin Jin,Xinyu Duan,Xu Li,Xu Zhang,Xusheng Chen,Yalong Shan,Yang Gan,Yao Lu,Yi Deng,Yi Zheng,Yingfei Zheng,Yiyun Zheng,Yizhou Shan,Yong Gao,Yongqiang Yang,Yuanjin Gong,Yue Yu,Yuetao Chen,Yukun Zhu,Yulong He,Yusu Zhao,Yuyan Wu,Zenan Zhang,Zhaojin Zhuo,Zhaoyang Ji,Zhefeng Wang,Zheng Wang,Zhenhua Yang,Zhenli Sheng,Zhibin Yu,Zhigang Ji,Zhihao Ren,Zhipeng Bian,Zhixia Liu,Zhiyu Dong,Zhonghua Li,Zhou Yu,Zhuoming Shen,Zhuwei Peng,Zi Ye,Zihao Xiang,Zimin Fu,Zixuan Zhang*

Main category: cs.DC

TL;DR: xDeepServe：为SuperPod级AI基础设施设计的LLM服务系统，采用Transformerless分解式架构和XCCL通信库，实现高效的大规模MoE模型推理。


<details>
  <summary>Details</summary>
Motivation: 随着大规模LLM（如MoE模型）和SuperPod级AI硬件（如Huawei CloudMatrix384）的出现，在SuperPod规模硬件上运行大型MoE模型面临着新的挑战，包括需要新的执行模型、可扩展调度、高效的专家负载均衡以及消除单点故障。

Method: 提出了一种名为Transformerless的分解式架构，将Transformer模型分解为独立的模块（注意力、前馈和MoE），并在通过高速互连连接的NPU上独立执行。此外，还提出XCCL通信库，利用CloudMatrix384的全局共享内存来实现高效的通信原语，并扩展了FlowServe服务引擎以支持大规模推理。

Result: Transformerless架构实现了计算和内存的独立扩展，同时不牺牲性能。XCCL通信库能够实现高效的通信。扩展的FlowServe服务引擎支持跨越数百个NPU的可扩展推理。

Conclusion: 该论文提出了xDeepServe，一个专为SuperPod规模基础设施设计的LLM服务系统，并介绍了其核心的Transformerless disaggregated架构和XCCL通信库，以应对大规模MoE模型在SuperPod硬件上运行带来的挑战。

Abstract: The rise of scaled-out LLMs and scaled-up SuperPods signals a new era in
large-scale AI infrastructure. LLMs continue to scale out via MoE, as seen in
recent models like DeepSeek, Kimi, and Qwen. In parallel, AI hardware is
scaling up, with Huawei's CloudMatrix384 SuperPod offering hundreds of GB/s
high-speed interconnects. Running large MoE models on SuperPod-scale hardware
brings new challenges. It requires new execution models, scalable scheduling,
efficient expert load balancing, and elimination of single points of failure.
This paper presents xDeepServe, Huawei Cloud's LLM serving system designed for
SuperPod-scale infrastructure. At its core is Transformerless, a disaggregated
architecture that decomposes transformer models into modular units--attention,
feedforward, and MoE--executed independently on NPUs connected via high-speed
fabric. We implement this design in two forms: disaggregated prefill-decode and
disaggregated MoE-attention. This fully disaggregated setup enables independent
scaling of compute and memory without sacrificing performance. To support this
architecture, we propose XCCL, a communication library that leverages
CloudMatrix384's global shared memory to implement efficient point-to-point and
all-to-all primitives. We also extend our serving engine FlowServe with
system-level techniques, enabling scalable inference across hundreds of NPUs.

</details>


### [601] [Blockchain Epidemic Consensus for Large-Scale Networks](https://arxiv.org/abs/2508.02552)
*Siamak Abdi,Giuseppe Di Fatta,Atta Badii,Giancarlo Fortino*

Main category: cs.DC

TL;DR: BECP是一种新的去中心化共识协议，在可扩展性和效率方面优于现有协议。


<details>
  <summary>Details</summary>
Motivation: 现有的共识协议存在可扩展性、资源消耗和容错性等方面的缺点。

Method: BECP是一种新的、完全去中心化的区块链网络共识协议，它遵循流行通信原理，没有固定的验证者或领导者等角色，并实现了概率收敛、高效消息传播和延迟容忍。

Result: 与经典协议（如PAXOS、RAFT和PBFT）以及较新的基于流行的方法（如Avalanche和Snowman）相比，BECP在吞吐量、共识延迟和消息传递效率方面均有显著优势。

Conclusion: BECP是一种有效且可扩展的下一代区块链系统的方法。

Abstract: Blockchain is a distributed ledger technology that has applications in many
domains such as cryptocurrency, smart contracts, supply chain management, and
many others. Distributed consensus is a fundamental component of blockchain
systems that enables secure, precise, and tamper-proof verification of data
without relying on central authorities. Existing consensus protocols,
nevertheless, suffer from drawbacks, some of which are related to scalability,
resource consumption, and fault tolerance. We introduce Blockchain Epidemic
Consensus Protocol (BECP), a novel fully decentralised consensus protocol for
blockchain networks at a large scale. BECP follows epidemic communication
principles, without fixed roles like validators or leaders, and achieves
probabilistic convergence, efficient message dissemination, and tolerance to
message delays. We provide an extensive experimental comparison of BECP against
classic protocols like PAXOS, RAFT, and PBFT, and newer epidemic-based
protocols like Avalanche and Snowman. The findings indicate that BECP provides
desirable gains in throughput, consensus latency, and substantial
message-passing efficiency compared to existing epidemic-based approaches,
validating its usability as an effective and scalable approach for
next-generation blockchain systems.

</details>


### [602] [Fully Decentralised Consensus for Extreme-scale Blockchain](https://arxiv.org/abs/2508.02595)
*Siamak Abdi,Giuseppe Di Fatta,Atta Badii,Giancarlo Fortino*

Main category: cs.DC

TL;DR: BECP是一种新的区块链共识协议，它使用疫情协议的原理，在性能上优于现有协议，特别适合大规模区块链系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统共识算法在节点故障、高资源消耗、串通等方面的固有问题，并为超大规模区块链系统提供一种有效的共识机制。

Method: 提出了一种名为区块链疫情共识协议（BECP）的全分布式共识协议，该协议利用了疫情协议的优势，如不依赖固定的验证者或领导者、概率收敛保证、高效的网络资源利用以及对节点和网络故障的容忍度。

Result: BECP在吞吐量方面比传统协议平均提高了1.196倍，在平均共识延迟方面提高了4.775倍，并且与Avalanche相比显著减少了消息数量。

Conclusion: BECP通过利用疫情协议的优势，在吞吐量、可扩展性和共识延迟方面优于PAXOS、RAFT、PBFT和Avalanche等传统协议，并显著减少了消息数量，证明了基于疫情协议的全分布式共识在区块链技术中的有效性和效率。

Abstract: Blockchain is a decentralised, immutable ledger technology that has been
widely adopted in many sectors for various applications such as
cryptocurrencies, smart contracts and supply chain management. Distributed
consensus is a fundamental component of blockchain, which is required to ensure
trust, security, and integrity of the data stored and the transactions
processed in the blockchain. Various consensus algorithms have been developed,
each affected from certain issues such as node failures, high resource
consumption, collusion, etc. This work introduces a fully decentralised
consensus protocol, Blockchain Epidemic Consensus Protocol (BECP), suitable for
very large and extreme-scale blockchain systems. The proposed approach
leverages the benefits of epidemic protocols, such as no reliance on a fixed
set of validators or leaders, probabilistic guarantees of convergence,
efficient use of network resources, and tolerance to node and network failures.
A comparative experimental analysis has been carried out with traditional
protocols including PAXOS, RAFT, and Practical Byzantine Fault Tolerance
(PBFT), as well as a relatively more recent protocol such as Avalanche, which
is specifically designed for very large-scale systems. The results illustrate
how BECP outperforms them in terms of throughput, scalability and consensus
latency. BECP achieves an average of 1.196 times higher throughput in terms of
consensus on items and 4.775 times better average consensus latency.
Furthermore, BECP significantly reduces the number of messages compared to
Avalanche. These results demonstrate the effectiveness and efficiency of fully
decentralised consensus for blockchain technology based on epidemic protocols.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [603] [Reservoir Computing with Evolved Critical Neural Cellular Automata](https://arxiv.org/abs/2508.02218)
*Sidney Pontes-Filho,Stefano Nichele,Mikkel Lepperød*

Main category: cs.NE

TL;DR: 通过演化策略优化神经元自动机（NCA）以实现临界性，并将其应用于水库计算。该模型在记忆和图像分类任务中表现出色，并可能作为自组织临界系统运行。


<details>
  <summary>Details</summary>
Motivation: 临界性是动力学系统中具有最高计算能力（信息传输、存储和修改）的行为状态，是作为水库计算（人工智能的一个子领域）的理想基底。

Method: 通过演化策略优化神经元自动机（NCA）以实现临界性，并通过雪崩结构中的幂律分布来证明。

Result: 在5位记忆任务中达到了完美的得分，系统成功地记住了所有5位；在手写数字图像分类任务中，其性能与该任务的最佳初等CA相当，有时甚至超越了其性能。

Conclusion: 所提出的临界神经元自动机（NCA）可能作为自组织临界系统运行，因为它对极端初始条件具有鲁棒性。

Abstract: Criticality is a behavioral state in dynamical systems that is known to
present the highest computation capabilities, i.e., information transmission,
storage, and modification. Therefore, such systems are ideal candidates as a
substrate for reservoir computing, a subfield in artificial intelligence. Our
choice of a substrate is a cellular automaton (CA) governed by an artificial
neural network, also known as neural cellular automaton (NCA). We apply
evolution strategy to optimize the NCA to achieve criticality, demonstrated by
power law distributions in structures called avalanches. With an evolved
critical NCA, the substrate is tested for reservoir computing. Our evaluation
of the substrate is performed with two benchmarks, 5-bit memory task and image
classification of handwritten digits. The result of the 5-bit memory task
achieved a perfect score and the system managed to remember all 5 bits. The
result for the image classification task matched and sometimes surpassed the
performance of the best elementary CA for this task. Moreover, the proposed
critical NCA may operate as a self-organized critical system, due to its
robustness to extreme initial conditions.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [604] [Investigating Crossing Perception in 3D Graph Visualisation](https://arxiv.org/abs/2508.00950)
*Ying Zhang,Niklas Groene,Karsten Klein,Giuseppe Liotta,Falk Schreiber*

Main category: cs.GR

TL;DR: 三维图可视化虽有优势，但三维空间中的边构型可能影响可读性。本文通过实验研究了边交叉、边间距和相对边方向的影响，并发现了不同因素类别间的差异。


<details>
  <summary>Details</summary>
Motivation: 评估和改进三维图可视化质量度量和绘图算法，理解影响人类感知图绘制的各种因素，特别是三维空间中的边构型及其对可读性的影响。

Method: 通过实证研究，探究边交叉、边间距和相对边方向等因素对三维图可读性的影响。

Result: 实证研究发现，边交叉、边间距和相对边方向等因素对三维图的可读性有显著影响，并报告了主要因素类别之间的差异。

Conclusion: 现有研究表明，三维图可视化可以提高分析效率，但三维图中的边构型（在特定视角下可能被视为交叉）对可读性的影响仍需研究。本文旨在通过实证研究，探究边交叉、边间距和相对边方向等因素对三维图可读性的影响，并报告主要因素类别的差异。

Abstract: Human perception of graph drawings is influenced by a variety of impact
factors for which quality measures are used as a proxy indicator. The
investigation of those impact factors and their effects is important to
evaluate and improve quality measures and drawing algorithms. The number of
edge crossings in a 2D graph drawing has long been a main quality measure for
drawing evaluation. The use of stereoscopic 3D graph visualisations has gained
attraction over the last years, and results from several studies indicate that
they can improve analysis efficiency for a range of analysis scenarios. While
edge crossings can also occur in 3D, there are edge configurations in space
that are not crossings but might be perceived as such from a specific
viewpoint. Such configurations create crossings when projected on the
corresponding 2D image plane and could impact readability similar to 2D
crossings. In 3D drawings, the additional depth aspect and the subsequent
impact factors of edge distance and relative edge direction in space might
further influence the importance of those configurations for readability. We
investigate the impact of such factors in an empirical study and report on
findings of difference between major factor categories.

</details>


### [605] [MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh](https://arxiv.org/abs/2508.01242)
*Shuangkang Fang,I-Chao Shen,Yufeng Wang,Yi-Hsuan Tsai,Yi Yang,Shuchang Zhou,Wenrui Ding,Takeo Igarashi,Ming-Hsuan Yang*

Main category: cs.GR

TL;DR: MeshLLM是一个利用LLM理解和生成文本序列化3D网格的新框架，通过原始-网格分解和改进的训练策略，解决了数据规模和结构信息丢失的问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决了现有方法在扩展数据集规模（以适应LLM的令牌长度）和防止网格序列化过程中丢失3D结构信息方面的局限性。

Method: 提出了一种新的原始-网格分解策略，将3D网格划分为结构上有意义的子单元，并提出了从顶点推断面连接性和局部网格装配的训练策略。

Result: 成功创建了一个包含1500k+样本的大规模数据集，并显著提高了LLM捕获网格拓扑和空间结构的能力，实验结果优于现有方法。

Conclusion: MeshLLM在处理文本序列化3D网格方面表现出巨大潜力，在网格生成质量和形状理解方面均优于最先进的LLaMA-Mesh方法。

Abstract: We present MeshLLM, a novel framework that leverages large language models
(LLMs) to understand and generate text-serialized 3D meshes. Our approach
addresses key limitations in existing methods, including the limited dataset
scale when catering to LLMs' token length and the loss of 3D structural
information during mesh serialization. We introduce a Primitive-Mesh
decomposition strategy, which divides 3D meshes into structurally meaningful
subunits. This enables the creation of a large-scale dataset with 1500k+
samples, almost 50 times larger than previous methods, which aligns better with
the LLM scaling law principles. Furthermore, we propose inferring face
connectivity from vertices and local mesh assembly training strategies,
significantly enhancing the LLMs' ability to capture mesh topology and spatial
structures. Experiments show that MeshLLM outperforms the state-of-the-art
LLaMA-Mesh in both mesh generation quality and shape understanding,
highlighting its great potential in processing text-serialized 3D meshes.

</details>


### [606] [ReMu: Reconstructing Multi-layer 3D Clothed Human from Image Layers](https://arxiv.org/abs/2508.01381)
*Onat Vuran,Hsuan-I Ho*

Main category: cs.GR

TL;DR: ReMu 是一种创新的方法，使用单个RGB相机和一种新的Image Layers设置，可以重建多层3D服装。它通过对齐衣物层和使用感知碰撞的优化过程来防止穿模，并且无需模板和类别限制，能够处理各种服装风格。实验结果表明，ReMu 在重建3D着装人体方面表现出色，并且在防止衣物穿模方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 为了支持创建逼真的着装人体化身，需要一种新的方法来重建多层3D服装，而无需昂贵的多视图采集设备和专门的3D编辑。

Method: 1. 提出了一种名为 Image Layers 的新方法，使用单个RGB相机捕捉穿着不同层衣物的对象。
2. 为了在共享坐标系中重建和对齐每一层衣物，并利用隐式神经场来解决相互渗透和进一步优化衣物边界的问题，引入了一个感知碰撞的优化过程。
3. 该方法是无需模板和类别无关的，可以重建各种风格的3D服装。

Result: 通过实验证明，该方法能够重建近乎无穿透的3D着装人体，并且性能具有竞争力。

Conclusion: 该方法能够重建近乎无穿透的3D着装人体，并且与特定类别的现有方法相比，具有竞争力。

Abstract: The reconstruction of multi-layer 3D garments typically requires expensive
multi-view capture setups and specialized 3D editing efforts. To support the
creation of life-like clothed human avatars, we introduce ReMu for
reconstructing multi-layer clothed humans in a new setup, Image Layers, which
captures a subject wearing different layers of clothing with a single RGB
camera. To reconstruct physically plausible multi-layer 3D garments, a unified
3D representation is necessary to model these garments in a layered manner.
Thus, we first reconstruct and align each garment layer in a shared coordinate
system defined by the canonical body pose. Afterwards, we introduce a
collision-aware optimization process to address interpenetration and further
refine the garment boundaries leveraging implicit neural fields. It is worth
noting that our method is template-free and category-agnostic, which enables
the reconstruction of 3D garments in diverse clothing styles. Through our
experiments, we show that our method reconstructs nearly penetration-free 3D
clothed humans and achieves competitive performance compared to
category-specific methods. Project page: https://eth-ait.github.io/ReMu/

</details>


### [607] [A Plug-and-Play Multi-Criteria Guidance for Diverse In-Betweening Human Motion Generation](https://arxiv.org/abs/2508.01590)
*Hua Yu,Jiao Liu,Xu Gui,Melvin Wong,Yaqing Hou,Yew-Soon Ong*

Main category: cs.GR

TL;DR: MCG-IMM 是一种新颖的、即插即用的方法，通过多标准引导来提高人类运动生成的多样性和平滑性，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在用户指定的关键帧之间合成中间运动，除了保持平滑过渡外，生成多样化的运动序列也是一项关键要求，而这在运动动力学复杂的情况下仍然是一个挑战。

Method: 提出了一种名为多标准引导的 in-betweening 运动模型（MCG-IMM）的新颖方法，该方法通过向预训练生成模型的采样过程提供多标准引导，以增强生成的运动多样性，而无需引入额外的参数。

Result: 实验结果表明，MCG-IMM 在四个常用的人类运动数据集上，能够持续超越现有方法，在 in-betweening 运动生成任务上达到最先进的水平。

Conclusion: MCG-IMM 在人类运动生成任务上展示了持续的领先性能，并且与不同类型的生成模型兼容。

Abstract: In-betweening human motion generation aims to synthesize intermediate motions
that transition between user-specified keyframes. In addition to maintaining
smooth transitions, a crucial requirement of this task is to generate diverse
motion sequences. It is still challenging to maintain diversity, particularly
when it is necessary for the motions within a generated batch sampling to
differ meaningfully from one another due to complex motion dynamics. In this
paper, we propose a novel method, termed the Multi-Criteria Guidance with
In-Betweening Motion Model (MCG-IMM), for in-betweening human motion
generation. A key strength of MCG-IMM lies in its plug-and-play nature: it
enhances the diversity of motions generated by pretrained models without
introducing additional parameters This is achieved by providing a sampling
process of pretrained generative models with multi-criteria guidance.
Specifically, MCG-IMM reformulates the sampling process of pretrained
generative model as a multi-criteria optimization problem, and introduces an
optimization process to explore motion sequences that satisfy multiple
criteria, e.g., diversity and smoothness. Moreover, our proposed plug-and-play
multi-criteria guidance is compatible with different families of generative
models, including denoised diffusion probabilistic models, variational
autoencoders, and generative adversarial networks. Experiments on four popular
human motion datasets demonstrate that MCG-IMM consistently state-of-the-art
methods in in-betweening motion generation task.

</details>


### [608] [Uncertainty Estimation for Novel Views in Gaussian Splatting from Primitive-Based Representations of Error and Visibility](https://arxiv.org/abs/2508.02443)
*Thomas Gottwald,Edgar Heinert,Matthias Rottmann*

Main category: cs.GR

TL;DR: 提出了一种新的高斯泼溅不确定性估计方法，通过原始表示和回归来提高精度，并能泛化到新场景。


<details>
  <summary>Details</summary>
Motivation: 不确定性估计（UE）对于将高斯泼溅（Gaussian Splatting）应用于机器人和医学等关键领域至关重要。现有方法通常估计高斯图元的方差，并通过渲染过程获得像素级不确定性。

Method: 提出了一种新的不确定性估计（UE）方法，通过构建包含训练误差和可见性信息的原始表示，并将这些信息投影到原始表示上。然后渲染这些原始表示以获得新视图的不确定性特征图，并使用像素回归聚合这些特征图。实验分析了该方法的不同组成部分，并考虑了前景和背景分离的影响。

Result: 提出的UE方法与真实误差高度相关，尤其在 А前景物体上，其表现优于现有最先进的方法。所训练的回归模型具有泛化到新场景的能力。

Conclusion: 作者提出的UE方法在前景物体上表现优于现有方法，并且训练好的回归模型能够泛化到新场景，无需额外的测试数据。

Abstract: In this work, we present a novel method for uncertainty estimation (UE) in
Gaussian Splatting. UE is crucial for using Gaussian Splatting in critical
applications such as robotics and medicine. Previous methods typically estimate
the variance of Gaussian primitives and use the rendering process to obtain
pixel-wise uncertainties. Our method establishes primitive representations of
error and visibility of trainings views, which carries meaningful uncertainty
information. This representation is obtained by projection of training error
and visibility onto the primitives. Uncertainties of novel views are obtained
by rendering the primitive representations of uncertainty for those novel
views, yielding uncertainty feature maps. To aggregate these uncertainty
feature maps of novel views, we perform a pixel-wise regression on holdout
data. In our experiments, we analyze the different components of our method,
investigating various combinations of uncertainty feature maps and regression
models. Furthermore, we considered the effect of separating splatting into
foreground and background. Our UEs show high correlations to true errors,
outperforming state-of-the-art methods, especially on foreground objects. The
trained regression models show generalization capabilities to new scenes,
allowing uncertainty estimation without the need for holdout data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [609] [PCS Workflow for Veridical Data Science in the Age of AI](https://arxiv.org/abs/2508.00835)
*Zachary T. Rewolinski,Bin Yu*

Main category: cs.LG

TL;DR: 论文提出了一个结合生成式AI的PCS框架，以提高数据科学发现的可复制性，并展示了数据清洗中的不确定性如何影响预测。


<details>
  <summary>Details</summary>
Motivation: 由于数据科学生命周期（DSLC）中存在许多选择，数据驱动的AI发现常常难以复制。传统统计框架未能充分考虑这种不确定性，因此需要一种新的方法来解决此问题。

Method: 提出了一种更新和简化的可预测性-可计算性-稳定性（PCS）工作流程，该流程针对实践者进行了定制，并增强了生成式人工智能的指导使用。论文通过一个运行示例来展示PCS框架的应用，并通过一个相关的案例研究来展示数据清洗阶段的判断调用对下游预测不确定性的影响。

Result: 更新后的PCS工作流程能够帮助实践者应对数据科学中的不确定性问题，并展示了数据清洗中的判断调用如何影响下游预测。

Conclusion: 该论文提出了一个更新和简化的可预测性-可计算性-稳定性（PCS）工作流程，并结合了生成式人工智能，以解决数据科学生命周期中的不确定性问题，旨在提高数据驱动发现的可复制性。

Abstract: Data science is a pillar of artificial intelligence (AI), which is
transforming nearly every domain of human activity, from the social and
physical sciences to engineering and medicine. While data-driven findings in AI
offer unprecedented power to extract insights and guide decision-making, many
are difficult or impossible to replicate. A key reason for this challenge is
the uncertainty introduced by the many choices made throughout the data science
life cycle (DSLC). Traditional statistical frameworks often fail to account for
this uncertainty. The Predictability-Computability-Stability (PCS) framework
for veridical (truthful) data science offers a principled approach to
addressing this challenge throughout the DSLC. This paper presents an updated
and streamlined PCS workflow, tailored for practitioners and enhanced with
guided use of generative AI. We include a running example to display the PCS
framework in action, and conduct a related case study which showcases the
uncertainty in downstream predictions caused by judgment calls in the data
cleaning stage.

</details>


### [610] [From Taylor Series to Fourier Synthesis: The Periodic Linear Unit](https://arxiv.org/abs/2508.01175)
*Shiko Kudo*

Main category: cs.LG

TL;DR: PLU是一种基于正弦波的新型激活函数，参数效率高，能解决传统激活函数难以处理的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的单调激活函数（如ReLU）需要庞大的模型参数来逼近复杂函数，因此需要探索更具表现力和参数效率的激活函数。

Method: 提出了一种名为周期性线性单元（PLU）的可学习的、基于正弦波的激活函数，并结合了“排斥重参数化”技术来防止其退化为线性函数。

Result: 在最小化多层感知机（MLP）实验中，仅使用两个PLU神经元的网络能够解决传统激活函数无法完成的螺旋分类任务，证明了PLU的优越性。

Conclusion: PLU激活函数通过其周期性和可学习的特性，实现了比传统激活函数更高的参数效率，能够以更少的神经元解决复杂问题，预示着从类泰勒展开式逼近到傅里叶类函数合成的范式转变。

Abstract: The dominant paradigm in modern neural networks relies on simple,
monotonically-increasing activation functions like ReLU. While effective, this
paradigm necessitates large, massively-parameterized models to approximate
complex functions. In this paper, we introduce the Periodic Linear Unit (PLU),
a learnable sine-wave based activation with periodic non-monotonicity. PLU is
designed for maximum expressive power and numerical stability, achieved through
its formulation and a paired innovation we term Repulsive Reparameterization,
which prevents the activation from collapsing into a non-expressive linear
function. We demonstrate that a minimal MLP with only two PLU neurons can solve
the spiral classification task, a feat impossible for equivalent networks using
standard activations. This suggests a paradigm shift from networks as piecewise
Taylor-like approximators to powerful Fourier-like function synthesizers,
achieving exponential gains in parameter efficiency by placing intelligence in
the neuron itself.

</details>


### [611] [Universal Neurons in GPT-2: Emergence, Persistence, and Functional Impact](https://arxiv.org/abs/2508.00903)
*Advey Nandan,Cheng-Ting Chou,Amrit Kurakula,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We investigate the phenomenon of neuron universality in independently trained
GPT-2 Small models, examining how these universal neurons-neurons with
consistently correlated activations across models-emerge and evolve throughout
training. By analyzing five GPT-2 models at three checkpoints (100k, 200k, 300k
steps), we identify universal neurons through pairwise correlation analysis of
activations over a dataset of 5 million tokens. Ablation experiments reveal
significant functional impacts of universal neurons on model predictions,
measured via loss and KL divergence. Additionally, we quantify neuron
persistence, demonstrating high stability of universal neurons across training
checkpoints, particularly in deeper layers. These findings suggest stable and
universal representational structures emerge during neural network training.

</details>


### [612] [A Residual Guided strategy with Generative Adversarial Networks in training Physics-Informed Transformer Networks](https://arxiv.org/abs/2508.00855)
*Ziyang Zhang,Feifan Zhang,Weidong Tang,Lei Shi,Tailai Chen*

Main category: cs.LG

TL;DR: 提出了一种新颖的残差引导训练策略，用于通过GAN进行物理信息Transformer，以解决PINNs在未解决的残差和时间因果关系方面的局限性，并在标准PDE基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统物理信息神经网络（PINNs）在关键时空区域未解决的残差和违反时间因果关系的问题。

Method: 提出了一种新颖的残差引导训练策略，用于通过生成对抗网络（GAN）进行物理信息Transformer。该框架集成了仅解码器的Transformer以通过自回归处理固有地捕获时间相关性，并结合了残差感知的GAN，该GAN动态地识别和优先处理高残差区域。通过引入因果惩罚项和自适应采样机制，该方法强制执行时间因果关系，同时完善问题域的准确性。

Result: 在Allen-Cahn、Klein-Gordon和Navier-Stokes方程上的大量数值实验证明了显著的改进，与基线方法相比，相对均方误差降低了两个数量级。

Conclusion: 这项工作弥合了深度学习与物理驱动建模之间的差距，为多尺度和时变偏微分方程系统提供了强大的解决方案。

Abstract: Nonlinear partial differential equations (PDEs) are pivotal in modeling
complex physical systems, yet traditional Physics-Informed Neural Networks
(PINNs) often struggle with unresolved residuals in critical spatiotemporal
regions and violations of temporal causality. To address these limitations, we
propose a novel Residual Guided Training strategy for Physics-Informed
Transformer via Generative Adversarial Networks (GAN). Our framework integrates
a decoder-only Transformer to inherently capture temporal correlations through
autoregressive processing, coupled with a residual-aware GAN that dynamically
identifies and prioritizes high-residual regions. By introducing a causal
penalty term and an adaptive sampling mechanism, the method enforces temporal
causality while refining accuracy in problematic domains. Extensive numerical
experiments on the Allen-Cahn, Klein-Gordon, and Navier-Stokes equations
demonstrate significant improvements, achieving relative MSE reductions of up
to three orders of magnitude compared to baseline methods. This work bridges
the gap between deep learning and physics-driven modeling, offering a robust
solution for multiscale and time-dependent PDE systems.

</details>


### [613] [The Vanishing Gradient Problem for Stiff Neural Differential Equations](https://arxiv.org/abs/2508.01519)
*Colby Fronk,Linda Petzold*

Main category: cs.LG

TL;DR: 该论文研究了刚性系统中的梯度消失问题，发现这是所有A稳定性积分方案的普遍特征。通过分析稳定性函数，证明了参数敏感性会随刚性增加而衰减，并揭示了所有A稳定性方法在刚性状态下都会抑制参数梯度，这对训练和识别造成了障碍。


<details>
  <summary>Details</summary>
Motivation: 梯度下降优化神经ODE和其他参数化动力学系统依赖于将数值解与模型参数区分开的能力。在刚性系统中，人们发现对控制快速衰减模式的参数的敏感性在训练过程中会变得越来越小，从而导致优化困难。

Method: 分析了一般刚性积分方案的理性稳定性函数，并提供了常见刚性积分方案的显式公式，以详细说明该机制。

Result: 证明了与主要刚性参数相关的参数敏感性随刚性的增加而衰减到零。对于普通刚性积分方案，我们提供了明确的公式，并证明了稳定性函数导数衰减的最慢速率为O(|z|-1)。

Conclusion: 所有A稳定性时间步进方法在刚性状态下都不可避免地抑制参数梯度，这对训练和参数识别构成了重大障碍。

Abstract: Gradient-based optimization of neural differential equations and other
parameterized dynamical systems fundamentally relies on the ability to
differentiate numerical solutions with respect to model parameters. In stiff
systems, it has been observed that sensitivities to parameters controlling
fast-decaying modes become vanishingly small during training, leading to
optimization difficulties. In this paper, we show that this vanishing gradient
phenomenon is not an artifact of any particular method, but a universal feature
of all A-stable and L-stable stiff numerical integration schemes. We analyze
the rational stability function for general stiff integration schemes and
demonstrate that the relevant parameter sensitivities, governed by the
derivative of the stability function, decay to zero for large stiffness.
Explicit formulas for common stiff integration schemes are provided, which
illustrate the mechanism in detail. Finally, we rigorously prove that the
slowest possible rate of decay for the derivative of the stability function is
$O(|z|^{-1})$, revealing a fundamental limitation: all A-stable time-stepping
methods inevitably suppress parameter gradients in stiff regimes, posing a
significant barrier for training and parameter identification in stiff neural
ODEs.

</details>


### [614] [Deploying Geospatial Foundation Models in the Real World: Lessons from WorldCereal](https://arxiv.org/abs/2508.00858)
*Christina Butsko,Kristof Van Tricht,Gabriel Tseng,Giorgia Milli,David Rolnick,Ruben Cartuyvels,Inbal Becker Reshef,Zoltan Szantoi,Hannah Kerner*

Main category: cs.LG

TL;DR: 一篇关于将地理空间基础模型整合到遥感应用中的结构化方法，并展示了其在作物绘图中的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管基准测试结果充满希望，但这些模型在实际操作环境中的应用却充满挑战且很少见。标准化的评估任务通常无法捕捉与最终用户采用相关的现实复杂性，例如数据异质性、资源限制和特定应用的需求。

Method: 本研究提出了一种结构化方法，将地理空间基础模型整合到操作测绘系统中。该协议包括三个关键步骤：定义应用需求、使模型适应特定领域的数据以及进行严格的实证测试。

Result: 使用Presto模型进行作物绘图案例研究，证明了与传统的监督方法相比，微调预训练模型可以显著提高性能。结果突出了该模型强大的空间和时间泛化能力。

Conclusion: 该协议为从业者提供了可复制的蓝图，并为未来在各种遥感应用中运行基础模型的研究奠定了基础。将该协议应用于WorldCereal全球作物绘图系统展示了该框架的可扩展性。

Abstract: The increasing availability of geospatial foundation models has the potential
to transform remote sensing applications such as land cover classification,
environmental monitoring, and change detection. Despite promising benchmark
results, the deployment of these models in operational settings is challenging
and rare. Standardized evaluation tasks often fail to capture real-world
complexities relevant for end-user adoption such as data heterogeneity,
resource constraints, and application-specific requirements. This paper
presents a structured approach to integrate geospatial foundation models into
operational mapping systems. Our protocol has three key steps: defining
application requirements, adapting the model to domain-specific data and
conducting rigorous empirical testing. Using the Presto model in a case study
for crop mapping, we demonstrate that fine-tuning a pre-trained model
significantly improves performance over conventional supervised methods. Our
results highlight the model's strong spatial and temporal generalization
capabilities. Our protocol provides a replicable blueprint for practitioners
and lays the groundwork for future research to operationalize foundation models
in diverse remote sensing applications. Application of the protocol to the
WorldCereal global crop-mapping system showcases the framework's scalability.

</details>


### [615] [Neural Policy Iteration for Stochastic Optimal Control: A Physics-Informed Approach](https://arxiv.org/abs/2508.01718)
*Yeongjong Kim,Yeoneung Kim,Minseok Kim,Namkyeong Cho*

Main category: cs.LG

TL;DR: PINN-PI 框架通过最小化线性 PDE 的残差来训练神经网络以逼近价值函数，从而解决随机最优控制问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决由二阶 HJB 方程控制的随机最优控制问题。

Method: 我们提出了一种物理信息神经网络策略迭代 (PINN-PI) 框架，用于求解由二阶 HJB 方程控制的随机最优控制问题。在每次迭代中，通过最小化由固定策略引起的线性 PDE 的残差来训练神经网络以逼近价值函数。

Result: 该方法在随机购物车、摆锤问题和高达 10D 的高维线性二次调节 (LQR) 问题等多个基准问题上证明了其有效性。

Conclusion: 该方法将基于 PINN 的确定性方法扩展到随机设置，并在温和条件下继承了经典策略迭代的全局指数收敛保证。

Abstract: We propose a physics-informed neural network policy iteration (PINN-PI)
framework for solving stochastic optimal control problems governed by
second-order Hamilton--Jacobi--Bellman (HJB) equations. At each iteration, a
neural network is trained to approximate the value function by minimizing the
residual of a linear PDE induced by a fixed policy. This linear structure
enables systematic $L^2$ error control at each policy evaluation step, and
allows us to derive explicit Lipschitz-type bounds that quantify how value
gradient errors propagate to the policy updates. This interpretability provides
a theoretical basis for evaluating policy quality during training. Our method
extends recent deterministic PINN-based approaches to stochastic settings,
inheriting the global exponential convergence guarantees of classical policy
iteration under mild conditions. We demonstrate the effectiveness of our method
on several benchmark problems, including stochastic cartpole, pendulum problems
and high-dimensional linear quadratic regulation (LQR) problems in up to 10D.

</details>


### [616] [MARS: A Meta-Adaptive Reinforcement Learning Framework for Risk-Aware Multi-Agent Portfolio Management](https://arxiv.org/abs/2508.01173)
*Jiayi Chen,Jing Li,Guiling Wang*

Main category: cs.LG

TL;DR: MARS是一个新颖的强化学习框架，通过异构智能体集合和元自适应控制器来平衡风险和回报，有效适应不断变化的市场条件，并在回测中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）在自动投资组合管理中虽然显示出巨大潜力，但在平衡风险和回报方面仍面临挑战，许多模型难以适应动态变化的市场条件。

Method: MARS（Meta-controlled Agents for a Risk-aware System）框架采用多智能体、风险感知的方法，由一个异构智能体集合和一个高层元自适应控制器（MAC）组成。每个智能体都有独特的内在风险配置，由安全批评网络和特定的风险承受能力阈值强制执行。MAC学习动态地协调智能体集合，根据市场状况调整对保守或激进智能体的依赖。

Result: 在主要国际股票指数上的实验（包括金融危机时期）表明，MARS框架在风险调整标准上表现优越，显著降低了最大回撤和波动性，同时保持了有竞争力的回报。

Conclusion: MARS框架通过利用行为多样性而非显式的市场特征工程，实现了风险和回报之间的优越平衡。实验结果表明，该框架在风险调整标准上表现出色，显著降低了最大回撤和波动性，同时保持了有竞争力的回报。

Abstract: Reinforcement Learning (RL) has shown significant promise in automated
portfolio management; however, effectively balancing risk and return remains a
central challenge, as many models fail to adapt to dynamically changing market
conditions. In this paper, we propose Meta-controlled Agents for a Risk-aware
System (MARS), a novel RL framework designed to explicitly address this
limitation through a multi-agent, risk-aware approach. Instead of a single
monolithic model, MARS employs a Heterogeneous Agent Ensemble where each agent
possesses a unique, intrinsic risk profile. This profile is enforced by a
dedicated Safety-Critic network and a specific risk-tolerance threshold,
allowing agents to specialize in behaviors ranging from capital preservation to
aggressive growth. To navigate different market regimes, a high-level
Meta-Adaptive Controller (MAC) learns to dynamically orchestrate the ensemble.
By adjusting its reliance on conservative versus aggressive agents, the MAC
effectively lowers portfolio volatility during downturns and seeks higher
returns in bull markets, thus minimizing maximum drawdown and enhancing overall
stability. This two-tiered structure allows MARS to generate a disciplined and
adaptive portfolio that is robust to market fluctuations. The framework
achieves a superior balance between risk and return by leveraging behavioral
diversity rather than explicit market-feature engineering. Experiments on major
international stock indexes, including periods of significant financial crisis,
demonstrate the efficacy of our framework on risk-adjusted criteria,
significantly reducing maximum drawdown and volatility while maintaining
competitive returns.

</details>


### [617] [SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization](https://arxiv.org/abs/2508.01646)
*Minsuk Jang,Changick Kim*

Main category: cs.LG

TL;DR: SPARTA是一种新框架，利用脉冲时间信息实现高效稀疏注意力，提高了SNN的效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 当前的脉冲神经网络（SNN）在很大程度上忽视了脉冲精确的时间信息，而这些信息可以提供丰富的计算线索。本研究旨在利用脉冲的时间动态，提高SNN的计算效率和准确率。

Method: SPARTA框架利用异构神经元动力学和尖峰时间信息，通过竞争性门控实现稀疏注意力。

Result: SPARTA实现了65.4%的稀疏度，将注意力复杂度从O(N^2)降低到O(K^2)（其中k<<n），并在DVS-Gesture、CIFAR10-DVS和CIFAR-10数据集上取得了最先进或具有竞争力的结果。

Conclusion: SPARTA框架通过利用异构神经元动力学和尖峰时间信息，实现了高效的稀疏注意力。通过优先处理基于尖峰时间（包括发放模式、尖峰时间和尖峰间隔）的标记，SPARTA实现了65.4%的稀疏度，并将注意力复杂度从O(N^2)降低到O(K^2)（其中k<<n），同时保持了高准确率。该方法在DVS-Gesture数据集上达到了98.78%的准确率，在CIFAR10-DVS数据集上达到了83.06%，在CIFAR-10数据集上达到了95.3%，证明了利用尖峰时间动力学可以同时提高计算效率和准确率。

Abstract: Current Spiking Neural Networks (SNNs) underutilize the temporal dynamics
inherent in spike-based processing, relying primarily on rate coding while
overlooking precise timing information that provides rich computational cues.
We propose SPARTA (Spiking Priority Attention with Resource-Adaptive Temporal
Allocation), a framework that leverages heterogeneous neuron dynamics and
spike-timing information to enable efficient sparse attention. SPARTA
prioritizes tokens based on temporal cues, including firing patterns, spike
timing, and inter-spike intervals, achieving 65.4% sparsity through competitive
gating. By selecting only the most salient tokens, SPARTA reduces attention
complexity from O(N^2) to O(K^2) with k << n, while maintaining high accuracy.
Our method achieves state-of-the-art performance on DVS-Gesture (98.78%) and
competitive results on CIFAR10-DVS (83.06%) and CIFAR-10 (95.3%), demonstrating
that exploiting spike timing dynamics improves both computational efficiency
and accuracy.

</details>


### [618] [Discrete approach to machine learning](https://arxiv.org/abs/2508.00869)
*Dmitriy Kashitsyn,Dmitriy Shabanov*

Main category: cs.LG

TL;DR: 本文提出了一种利用稀疏位向量和固定长度线性向量的编码和结构信息处理新方法，并通过语言和生物医学数据进行了验证，发现了与哺乳动物新皮层组织相似的模式。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨一种新的编码和结构信息处理方法，利用稀疏位向量和固定长度线性向量。通过研究不同模式（语言形态、免疫组织化学标记）的码空间结构，并将其与哺乳动物新皮层进行比较，以期发现潜在的组织和过程相似性。

Method: 本文提出了一种编码和结构信息处理方法，使用稀疏位向量和固定长度线性向量。实现了两种方法：1. 离散方法：对具有线性渐近复杂性的多维码和线性空间进行推测性随机降维。2. 几何方法：获得离散嵌入，以反映给定模式组织码空间的内部结构。

Result: 文章展示了所提出的方法在三种模式（俄语和英语的形态，以及免疫组织化学标记）上的应用，并揭示了码空间布局与哺乳动物新皮层“针 the pinwheel”结构之间的相似性。

Conclusion: 文章探讨了一种使用稀疏位向量和固定长度线性向量的编码和结构信息处理方法，并展示了一种离散方法，该方法通过具有线性渐近复杂性的多维码和线性空间进行推测性随机降维，以及一种用于获得离散嵌入的几何方法，该方法组织了反映给定模式内部结构的码空间。文章研究了码空间的结构和属性，并以俄语和英语的形态以及免疫组织化学标记三种模式为例。此外，文章还比较了所得码空间布局图和哺乳动物新皮层出现的“针 the pinwheel”之间的相似性，并谨慎地假设了新皮层组织与我们模型中发生的过程之间存在相似性。

Abstract: The article explores an encoding and structural information processing
approach using sparse bit vectors and fixed-length linear vectors. The
following are presented: a discrete method of speculative stochastic
dimensionality reduction of multidimensional code and linear spaces with linear
asymptotic complexity; a geometric method for obtaining discrete embeddings of
an organised code space that reflect the internal structure of a given
modality. The structure and properties of a code space are investigated using
three modalities as examples: morphology of Russian and English languages, and
immunohistochemical markers. Parallels are drawn between the resulting map of
the code space layout and so-called pinwheels appearing on the mammalian
neocortex. A cautious assumption is made about similarities between neocortex
organisation and processes happening in our models.

</details>


### [619] [A Data-Driven Machine Learning Approach for Predicting Axial Load Capacity in Steel Storage Rack Columns](https://arxiv.org/abs/2508.00876)
*Bakhtiyar Mammadli,Casim Yazici,Muhammed Gürbüz,İrfan Kocaman,F. Javier Dominguez-Gutierrez,Fatih Mehmet Özkal*

Main category: cs.LG

TL;DR: 本研究提出了一种基于机器学习的框架，用于预测冷弯钢结构构件的轴向承载力。该框架使用梯度提升回归模型，并通过SHAP解释模型，最终开发了一个交互式Web界面，便于工程师使用。


<details>
  <summary>Details</summary>
Motivation: 传统分析方法在处理屈曲行为的非线性和几何复杂性方面存在局限性，因此需要开发一种能够准确预测冷弯钢结构构件轴向承载力的机器学习框架。

Method: 本研究采用机器学习框架，通过预处理数据集，评估了多种回归算法，并选用梯度提升回归模型，同时利用SHAP进行模型解释，最终通过Streamlit构建了交互式Web界面。

Result: 梯度提升回归模型在预测性能上表现优异，通过SHAP分析揭示了输入特征对预测轴向承载力的影响，并成功开发了用于实际应用的交互式Web界面。

Conclusion: 本研究提出的机器学习框架能够准确预测冷弯钢结构构件的轴向承载力，并提供可解释性，优于传统分析方法。

Abstract: In this study, we present a machine learning (ML) framework to predict the
axial load-bearing capacity, (kN), of cold-formed steel structural members. The
methodology emphasizes robust model selection and interpretability, addressing
the limitations of traditional analytical approaches in capturing the
nonlinearities and geometrical complexities inherent to buckling behavior. The
dataset, comprising key geometric and mechanical parameters of steel columns,
was curated with appropriate pre-processing steps including removal of
non-informative identifiers and imputation of missing values. A comprehensive
suite of regression algorithms, ranging from linear models to kernel-based
regressors and ensemble tree methods was evaluated. Among these, Gradient
Boosting Regression exhibited superior predictive performance across multiple
metrics, including the coefficient of determination (R2), root mean squared
error (RMSE), and mean absolute error (MAE), and was consequently selected as
the final model. Model interpretability was addressed using SHapley Additive
exPlanations (SHAP), enabling insight into the relative importance and
interaction of input features influencing the predicted axial capacity. To
facilitate practical deployment, the model was integrated into an interactive,
Python-based web interface via Streamlit. This tool allows end-users-such as
structural engineers and designers, to input design parameters manually or
through CSV upload, and to obtain real-time predictions of axial load capacity
without the need for programming expertise. Applied to the context of steel
storage rack columns, the framework demonstrates how data-driven tools can
enhance design safety, streamline validation workflows, and inform
decision-making in structural applications where buckling is a critical failure
mode

</details>


### [620] [Satellite Connectivity Prediction for Fast-Moving Platforms](https://arxiv.org/abs/2508.00877)
*Chao Yan,Babak Mafakheri*

Main category: cs.LG

TL;DR: 机器学习可以通过预测信号质量来改善飞机、车辆和火车等移动设备的卫星连接。


<details>
  <summary>Details</summary>
Motivation: 随着对无缝互联网接入的需求增长，尤其是在交通和偏远地区，卫星连接越来越受到关注。对于飞机、车辆或火车等快速移动的物体，由于其移动性和在缺乏地面覆盖的区域中的存在，卫星连接至关重要。

Method: 利用机器学习（ML）算法分析通信数据并预测信号质量。

Result: 机器学习预测模型在测试数据上达到了0.97的F1分数，证明了机器学习在预测飞行中信号质量方面的准确性。

Conclusion: 通过使用机器学习分析历史连接数据来预测特定位置的网络质量，可以实现主动的网络切换，在连接问题出现之前就进行切换，从而实现无缝宽带服务，包括不同卫星星座和提供商之间的漫游。

Abstract: Satellite connectivity is gaining increased attention as the demand for
seamless internet access, especially in transportation and remote areas,
continues to grow. For fast-moving objects such as aircraft, vehicles, or
trains, satellite connectivity is critical due to their mobility and frequent
presence in areas without terrestrial coverage. Maintaining reliable
connectivity in these cases requires frequent switching between satellite
beams, constellations, or orbits. To enhance user experience and address
challenges like long switching times, Machine Learning (ML) algorithms can
analyze historical connectivity data and predict network quality at specific
locations. This allows for proactive measures, such as network switching before
connectivity issues arise. In this paper, we analyze a real dataset of
communication between a Geostationary Orbit (GEO) satellite and aircraft over
multiple flights, using ML to predict signal quality. Our prediction model
achieved an F1 score of 0.97 on the test data, demonstrating the accuracy of
machine learning in predicting signal quality during flight. By enabling
seamless broadband service, including roaming between different satellite
constellations and providers, our model addresses the need for real-time
predictions of signal quality. This approach can further be adapted to automate
satellite and beam-switching mechanisms to improve overall communication
efficiency. The model can also be retrained and applied to any moving object
with satellite connectivity, using customized datasets, including connected
vehicles and trains.

</details>


### [621] [Optimizing Day-Ahead Energy Trading with Proximal Policy Optimization and Blockchain](https://arxiv.org/abs/2508.01888)
*Navneet Verma,Ying Xie*

Main category: cs.LG

TL;DR: 一项研究利用结合了强化学习（PPO）和区块链技术的框架，优化了日前能源市场中产消者的交易策略，实现了供需平衡和成本优化，并通过区块链确保了交易的透明和安全。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源在日前能源市场中的渗透率不断提高，平衡供需、确保电网弹性以及在去中心化交易系统中维持信任面临着日益严峻的挑战。

Method: 本研究提出了一个整合近端策略优化（PPO）算法与区块链技术的框架。强化学习（RL）代理被用于实现多目标能源优化，而区块链技术则用于防篡改的数据和交易管理。通过在ERCOT的真实数据上进行模拟来验证该方法的有效性。

Result: 在ERCOT的真实数据模拟中，RL代理实现了2%以内的供需平衡，并在大部分运行时间内保持了近乎最优的供应成本。此外，该代理生成了能够有效处理太阳能和风能发电波动的电池储能策略。所有决策均记录在Algorand区块链上，增强了透明度、可审计性和安全性。

Conclusion: 该研究提出了一种结合近端策略优化（PPO）算法和区块链技术的框架，用于优化日前能源市场中产消者（prosumers）的自动化交易策略。该框架利用强化学习（RL）代理进行多目标能源优化，并利用区块链技术进行防篡改的数据和交易管理。在德克萨斯电力可靠性委员会（ERCOT）的真实数据模拟中，该方法有效实现了需求-供给平衡（误差在2%以内），在大部分运行时间内保持了近乎最优的供应成本，并生成了能够应对太阳能和风能发电波动的稳健电池储能策略。所有交易决策均记录在基于Algorand的区块链上，确保了透明度、可审计性和安全性，这对于可信的多代理能源交易至关重要。研究的主要贡献包括新颖的系统架构、用于稳健代理开发的课程学习以及对实际部署有指导意义的策略见解。

Abstract: The increasing penetration of renewable energy sources in day-ahead energy
markets introduces challenges in balancing supply and demand, ensuring grid
resilience, and maintaining trust in decentralized trading systems. This paper
proposes a novel framework that integrates the Proximal Policy Optimization
(PPO) algorithm, a state-of-the-art reinforcement learning method, with
blockchain technology to optimize automated trading strategies for prosumers in
day-ahead energy markets. We introduce a comprehensive framework that employs
RL agent for multi-objective energy optimization and blockchain for
tamper-proof data and transaction management. Simulations using real-world data
from the Electricity Reliability Council of Texas (ERCOT) demonstrate the
effectiveness of our approach. The RL agent achieves demand-supply balancing
within 2\% and maintains near-optimal supply costs for the majority of the
operating hours. Moreover, it generates robust battery storage policies capable
of handling variability in solar and wind generation. All decisions are
recorded on an Algorand-based blockchain, ensuring transparency, auditability,
and security - key enablers for trustworthy multi-agent energy trading. Our
contributions include a novel system architecture, curriculum learning for
robust agent development, and actionable policy insights for practical
deployment.

</details>


### [622] [GNN-ASE: Graph-Based Anomaly Detection and Severity Estimation in Three-Phase Induction Machines](https://arxiv.org/abs/2508.00879)
*Moutaz Bellah Bentrad,Adel Ghoggal,Tahar Bahi,Abderaouf Bahi*

Main category: cs.LG

TL;DR: 该研究提出了一种基于图神经网络（GNN）的无模型感应电机故障诊断方法，直接利用原始信号，无需特征工程，准确率高，适用于实际应用。


<details>
  <summary>Details</summary>
Motivation: 克服传统基于模型的感应电机故障诊断方法复杂、计算成本高的问题，提出一种更简单、更高效的解决方案。

Method: 使用图神经网络（GNN）的无模型方法，直接处理原始电流和振动信号，通过GNN-ASE模型自动学习特征。

Result: 在偏心、轴承故障和转子断条检测方面分别 đạt 92.5%、91.2% 和 93.1% 的准确率，证明了模型的鲁棒性和泛化能力。

Conclusion: 该研究提出了一种基于图神经网络（GNN）的无模型方法，用于感应电机的故障诊断，能够有效检测多种故障类型（如偏心、轴承缺陷、转子断条）及其不同严重程度和负载条件下的情况。与传统方法不同，该模型直接使用原始电流和振动信号，无需信号预处理或手动特征提取，通过GNN-ASE模型自动学习和提取相关特征，并能捕捉信号类型和故障模式之间的复杂关系。实验结果表明，该模型在偏心、轴承故障和转子断条检测方面的准确率分别为92.5%、91.2%和93.1%，证明了其在不同运行场景下的鲁棒性和泛化能力。该基于GNN的框架提供了一种轻量级但功能强大的解决方案，简化了实施并保持了高诊断性能，为现实世界中的感应电机监测和预测性维护提供了有前景的替代方案。

Abstract: The diagnosis of induction machines has traditionally relied on model-based
methods that require the development of complex dynamic models, making them
difficult to implement and computationally expensive. To overcome these
limitations, this paper proposes a model-free approach using Graph Neural
Networks (GNNs) for fault diagnosis in induction machines. The focus is on
detecting multiple fault types -- including eccentricity, bearing defects, and
broken rotor bars -- under varying severity levels and load conditions. Unlike
traditional approaches, raw current and vibration signals are used as direct
inputs, eliminating the need for signal preprocessing or manual feature
extraction. The proposed GNN-ASE model automatically learns and extracts
relevant features from raw inputs, leveraging the graph structure to capture
complex relationships between signal types and fault patterns. It is evaluated
for both individual fault detection and multi-class classification of combined
fault conditions. Experimental results demonstrate the effectiveness of the
proposed model, achieving 92.5\% accuracy for eccentricity defects, 91.2\% for
bearing faults, and 93.1\% for broken rotor bar detection. These findings
highlight the model's robustness and generalization capability across different
operational scenarios. The proposed GNN-based framework offers a lightweight
yet powerful solution that simplifies implementation while maintaining high
diagnostic performance. It stands as a promising alternative to conventional
model-based diagnostic techniques for real-world induction machine monitoring
and predictive maintenance.

</details>


### [623] [Reproducibility of Machine Learning-Based Fault Detection and Diagnosis for HVAC Systems in Buildings: An Empirical Study](https://arxiv.org/abs/2508.00880)
*Adil Mukhtar,Michael Hadwiger,Franz Wotawa,Gerald Schweiger*

Main category: cs.LG

TL;DR: 机器学习在建筑节能领域的应用普遍缺乏可复现性，主要源于数据和代码披露不足。建议通过制定指南、加强培训和改革期刊会议政策来提高透明度。


<details>
  <summary>Details</summary>
Motivation: 机器学习（ML）领域面临着与传统科学研究相似的透明度和可靠性问题，但关于这些挑战如何在应用学科中体现，尤其是建筑节能领域，了解甚少。

Method: 通过分析建筑节能领域机器学习应用论文的透明度和可复现性标准来研究。

Result: 72%的文章未说明使用的数据集是公开、私有还是商业可用。只有两篇论文分享了代码链接，其中一个已失效。三分之二的论文仅由学术研究人员撰写，但与包含工业界作者的论文在可复现性方面没有显著差异。

Conclusion: ML研究在建筑节能领域的应用缺乏透明度和可复现性，近乎所有文章都因关键维度披露不足而无法复现。大部分文章未明确数据集的可访问性，代码共享率极低。此外，作者背景（仅学术或包含工业界）并不影响研究的可复现性。

Abstract: Reproducibility is a cornerstone of scientific research, enabling independent
verification and validation of empirical findings. The topic gained prominence
in fields such as psychology and medicine, where concerns about non -
replicable results sparked ongoing discussions about research practices. In
recent years, the fast-growing field of Machine Learning (ML) has become part
of this discourse, as it faces similar concerns about transparency and
reliability. Some reproducibility issues in ML research are shared with other
fields, such as limited access to data and missing methodological details. In
addition, ML introduces specific challenges, including inherent nondeterminism
and computational constraints. While reproducibility issues are increasingly
recognized by the ML community and its major conferences, less is known about
how these challenges manifest in applied disciplines. This paper contributes to
closing this gap by analyzing the transparency and reproducibility standards of
ML applications in building energy systems. The results indicate that nearly
all articles are not reproducible due to insufficient disclosure across key
dimensions of reproducibility. 72% of the articles do not specify whether the
dataset used is public, proprietary, or commercially available. Only two papers
share a link to their code - one of which was broken. Two-thirds of the
publications were authored exclusively by academic researchers, yet no
significant differences in reproducibility were observed compared to
publications with industry-affiliated authors. These findings highlight the
need for targeted interventions, including reproducibility guidelines, training
for researchers, and policies by journals and conferences that promote
transparency and reproducibility.

</details>


### [624] [Hallucination Detection and Mitigation with Diffusion in Multi-Variate Time-Series Foundation Models](https://arxiv.org/abs/2508.00881)
*Vijja Wichitwechkarn,Charles Fox,Ruchi Choudhary*

Main category: cs.LG

TL;DR: 为多变量时间序列（MVTS）基础模型引入了幻觉的新定义、检测和缓解方法，并展示了其在减少幻觉方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理基础模型在幻觉的定义和检测/缓解方面有许多统一的方法，但多变量时间序列（MVTS）基础模型在这方面缺乏类似的定义和方法。

Method: 提出了一种使用扩散模型估计幻觉水平的新方法，以及新的检测和缓解方法。

Result: 开源预训练MVTS插值基础模型的关系幻觉水平平均比弱基线高出59.5%，而提出的缓解方法可将此减少高达47.7%。

Conclusion: 该定义和方法有望改善多变量时间序列基础模型的采用和安全使用。

Abstract: Foundation models for natural language processing have many coherent
definitions of hallucination and methods for its detection and mitigation.
However, analogous definitions and methods do not exist for multi-variate
time-series (MVTS) foundation models. We propose new definitions for MVTS
hallucination, along with new detection and mitigation methods using a
diffusion model to estimate hallucination levels. We derive relational datasets
from popular time-series datasets to benchmark these relational hallucination
levels. Using these definitions and models, we find that open-source
pre-trained MVTS imputation foundation models relationally hallucinate on
average up to 59.5% as much as a weak baseline. The proposed mitigation method
reduces this by up to 47.7% for these models. The definition and methods may
improve adoption and safe usage of MVTS foundation models.

</details>


### [625] [Multi-Grained Temporal-Spatial Graph Learning for Stable Traffic Flow Forecasting](https://arxiv.org/abs/2508.00884)
*Zhenan Lin,Yuni Lai,Wai Lun Lo,Richard Tai-Chiu Hsung,Harris Sik-Ho Tsang,Xiaoyu Xue,Kai Zhou,Yulin Zhu*

Main category: cs.LG

TL;DR: 本研究提出了一种新的时空图学习框架，通过结合全局和局部模式来改进交通流量预测，并在真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法无法编码全局时空模式并容易在预定义地理相关性上过度拟合的问题，从而阻碍了模型在复杂交通环境中的鲁棒性。

Method: 提出了一种多粒度时空图学习框架，该框架通过精心设计的门控融合单元和残差连接技术，将精心设计的图变换器编码器获得的全局时空模式与图卷积的局部模式自适应地增强。

Result: 所提出的模型可以挖掘每个监控站点之间隐藏的全局时空关系，并平衡局部和全局时空模式的相对重要性。

Conclusion: 实验结果表明，所提出的方法具有强大的表示能力，并且在各种真实交通网络上始终优于其他强大的基线。

Abstract: Time-evolving traffic flow forecasting are playing a vital role in
intelligent transportation systems and smart cities. However, the dynamic
traffic flow forecasting is a highly nonlinear problem with complex
temporal-spatial dependencies. Although the existing methods has provided great
contributions to mine the temporal-spatial patterns in the complex traffic
networks, they fail to encode the globally temporal-spatial patterns and are
prone to overfit on the pre-defined geographical correlations, and thus hinder
the model's robustness on the complex traffic environment. To tackle this
issue, in this work, we proposed a multi-grained temporal-spatial graph
learning framework to adaptively augment the globally temporal-spatial patterns
obtained from a crafted graph transformer encoder with the local patterns from
the graph convolution by a crafted gated fusion unit with residual connection
techniques. Under these circumstances, our proposed model can mine the hidden
global temporal-spatial relations between each monitor stations and balance the
relative importance of local and global temporal-spatial patterns. Experiment
results demonstrate the strong representation capability of our proposed method
and our model consistently outperforms other strong baselines on various
real-world traffic networks.

</details>


### [626] [Diffusion Models for Future Networks and Communications: A Comprehensive Survey](https://arxiv.org/abs/2508.01586)
*Nguyen Cong Luong,Nguyen Duc Hai,Duc Van Le,Huy T. Nguyen,Thai-Hoc Vu,Thien Huynh-The,Ruichen Zhang,Nguyen Duc Duy Anh,Dusit Niyato,Marco Di Renzo,Dong In Kim,Quoc-Viet Pham*

Main category: cs.LG

TL;DR: This survey explores the use of Diffusion Models (DMs) in wireless communications, covering their theory, applications in areas like channel modeling and resource management, and future research directions.


<details>
  <summary>Details</summary>
Motivation: The rise of Generative AI (GenAI), particularly Diffusion Models (DMs), has led to transformative advances in wireless communications and networks. DMs are powerful for handling complex, high-dimensional data and offer consistent, noise-robust performance. This survey aims to provide a comprehensive overview of their theoretical foundations and practical applications in this field.

Method: This survey provides a comprehensive overview of the theoretical foundations and practical applications of DMs in future communication systems. It includes an extensive tutorial of DMs, demonstrating their application to enhance optimizers, reinforcement learning, and incentive mechanisms. It also reviews and discusses DM-based methods for emerging issues such as channel modeling and estimation, signal detection and data reconstruction, integrated sensing and communication, resource management in edge computing networks, and semantic communications.

Result: Diffusion Models (DMs) have shown potential in enhancing optimizers, reinforcement learning, and incentive mechanisms, and are being applied to address emerging issues in future networks and communications including channel modeling and estimation, signal detection and data reconstruction, integrated sensing and communication, resource management in edge computing networks, and semantic communications.

Conclusion: The survey concludes by highlighting the technical limitations of Diffusion Models (DMs) and their applications, and discusses future research directions.

Abstract: The rise of Generative AI (GenAI) in recent years has catalyzed
transformative advances in wireless communications and networks. Among the
members of the GenAI family, Diffusion Models (DMs) have risen to prominence as
a powerful option, capable of handling complex, high-dimensional data
distribution, as well as consistent, noise-robust performance. In this survey,
we aim to provide a comprehensive overview of the theoretical foundations and
practical applications of DMs across future communication systems. We first
provide an extensive tutorial of DMs and demonstrate how they can be applied to
enhance optimizers, reinforcement learning and incentive mechanisms, which are
popular approaches for problems in wireless networks. Then, we review and
discuss the DM-based methods proposed for emerging issues in future networks
and communications, including channel modeling and estimation, signal detection
and data reconstruction, integrated sensing and communication, resource
management in edge computing networks, semantic communications and other
notable issues. We conclude the survey with highlighting technical limitations
of DMs and their applications, as well as discussing future research
directions.

</details>


### [627] [Stochastic Optimal Control via Measure Relaxations](https://arxiv.org/abs/2508.00886)
*Etienne Buehrle,Christoph Stiller*

Main category: cs.LG

TL;DR: 提出了一种将随机系统最优控制问题转化为占用测度上的凸优化问题的新方法，并成功应用于多个场景，同时通过 Christoffel 展开式从数据中学习成本函数。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统方法（如鲁棒或基于场景的优化方法）难以扩展到长优化范围的挑战。

Method: 将随机系统的最优控制问题转化为占用测度上的凸优化问题。

Result: 通过在合成和真实世界场景中学习成本函数（使用 Christoffel 展开式）来证明该方法的有效性。

Conclusion: 该方法通过将随机系统的最优控制问题转化为占用测度上的凸优化问题来解决，并在合成和真实世界场景中进行了演示。

Abstract: The optimal control problem of stochastic systems is commonly solved via
robust or scenario-based optimization methods, which are both challenging to
scale to long optimization horizons. We cast the optimal control problem of a
stochastic system as a convex optimization problem over occupation measures. We
demonstrate our method on a set of synthetic and real-world scenarios, learning
cost functions from data via Christoffel polynomials. The code for our
experiments is available at https://github.com/ebuehrle/dpoc.

</details>


### [628] [FRAM: Frobenius-Regularized Assignment Matching with Mixed-Precision Computing](https://arxiv.org/abs/2508.00887)
*Binrui Shen,Yuan Liang,Shengxin Zhu*

Main category: cs.LG

TL;DR: A novel relaxation framework called FRAM is proposed for graph matching, which reformulates the projection step as a Frobenius-regularized Linear Assignment (FRA) problem. This framework, along with the Scaling Doubly Stochastic Normalization (SDSN) algorithm and a mixed-precision architecture, significantly improves performance and achieves substantial speedup with negligible loss in accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing projection-based relaxations for graph matching (QAP) inevitably enlarge the feasible set, introducing numerical scale sensitivity and geometric misalignment. To alleviate these errors, a novel relaxation framework is proposed.

Method: Propose a novel relaxation framework by reformulating the projection step as a Frobenius-regularized Linear Assignment (FRA) problem, where a tunable regularization term mitigates feasible region inflation. Propose the Scaling Doubly Stochastic Normalization (SDSN) algorithm to efficiently solve FRA. Develop a theoretically grounded mixed-precision architecture to achieve substantial acceleration.

Result: FRAM consistently outperforms all baseline methods under identical precision settings (CPU-based benchmarks). When combined with a GPU-based mixed-precision architecture, FRAM achieves up to 370X speedup over its CPU-FP64 counterpart, with negligible loss in solution accuracy.

Conclusion: FRAM combined with a GPU-based mixed-precision architecture achieves up to 370X speedup over its CPU-FP64 counterpart, with negligible loss in solution accuracy.

Abstract: Graph matching, typically formulated as a Quadratic Assignment Problem (QAP),
seeks to establish node correspondences between two graphs. To address the
NP-hardness of QAP, some existing methods adopt projection-based relaxations
that embed the problem into the convex hull of the discrete domain. However,
these relaxations inevitably enlarge the feasible set, introducing two sources
of error: numerical scale sensitivity and geometric misalignment between the
relaxed and original domains. To alleviate these errors, we propose a novel
relaxation framework by reformulating the projection step as a
Frobenius-regularized Linear Assignment (FRA) problem, where a tunable
regularization term mitigates feasible region inflation. This formulation
enables normalization-based operations to preserve numerical scale invariance
without compromising accuracy. To efficiently solve FRA, we propose the Scaling
Doubly Stochastic Normalization (SDSN) algorithm. Building on its favorable
computational properties, we develop a theoretically grounded mixed-precision
architecture to achieve substantial acceleration. Comprehensive CPU-based
benchmarks demonstrate that FRAM consistently outperforms all baseline methods
under identical precision settings. When combined with a GPU-based
mixed-precision architecture, FRAM achieves up to 370X speedup over its
CPU-FP64 counterpart, with negligible loss in solution accuracy.

</details>


### [629] [A Dynamic, Context-Aware Framework for Risky Driving Prediction Using Naturalistic Data](https://arxiv.org/abs/2508.00888)
*Amir Hossein Kalantari,Eleonora Papadimitriou,Amir Pooyan Afghari*

Main category: cs.LG

TL;DR: 本研究提出了一种利用滚动时间窗口和双层优化的动态个性化框架，以改进对危险驾驶行为的检测。DNN 模型在识别风险方面表现出色，而速度加权前车距被发现是比危险驾驶事件更可靠的风险指标。


<details>
  <summary>Details</summary>
Motivation: 现有框架依赖固定的时间窗口和静态阈值来区分安全和危险行为，这限制了它们响应现实世界驾驶随机性的能力。

Method: 本研究提出了一种使用比利时自然驾驶数据的动态和个性化框架，用于识别危险驾驶行为。该方法利用滚动时间窗口和双层优化来动态校准风险阈值和模型超参数，以捕捉细微的行为变化。评估了两种安全指标（速度加权前车距和危险驾驶事件），并使用了三种数据驱动模型：随机森林、XGBoost 和深度神经网络 (DNN)。

Result: DNN 在捕捉驾驶行为的细微变化方面表现出强大的能力，特别是在高召回率任务方面表现出色，这对于早期风险检测很有希望。XGBoost 在不同的阈值和评估指标方面提供了最平衡和稳定的性能。随机森林虽然表现出更大的变异性，但对动态阈值调整反应敏感，这在模型适应或调整期间可能是有利的。与危险驾驶事件相比，速度加权前车距作为一种比危险驾驶事件更稳定、更具情境敏感性的风险指标。

Conclusion: 研究结果支持自适应、个性化的风险检测方法，以增强实时安全反馈和为智能交通系统量身定制驾驶员支持。

Abstract: Naturalistic driving studies offer a powerful means for observing and
quantifying real-world driving behaviour. One of their prominent applications
in traffic safety is the continuous monitoring and classification of risky
driving behaviour. However, many existing frameworks rely on fixed time windows
and static thresholds for distinguishing between safe and risky behaviour -
limiting their ability to respond to the stochastic nature of real-world
driving. This study proposes a dynamic and individualised framework for
identifying risky driving behaviour using Belgian naturalistic driving data.
The approach leverages a rolling time window and bi-level optimisation to
dynamically calibrate both risk thresholds and model hyperparameters, capturing
subtle behavioural shifts. Two safety indicators, speed-weighted headway and
harsh driving events, were evaluated using three data-driven models: Random
Forest, XGBoost, and Deep Neural Network (DNN). The DNN demonstrated strong
capability in capturing subtle changes in driving behaviour, particularly
excelling in high-recall tasks, making it promising for early-stage risk
detection. XGBoost provided the most balanced and stable performance across
different thresholds and evaluation metrics. While random forest showed more
variability, it responded sensitively to dynamic threshold adjustments, which
may be advantageous during model adaptation or tuning. Speed-weighted headway
emerged as a more stable and context-sensitive risk indicator than harsh
driving events, likely due to its robustness to label sparsity and contextual
variation. Overall, the findings support the value of adaptive, personalised
risk detection approaches for enhancing real-time safety feedback and tailoring
driver support in intelligent transport systems.

</details>


### [630] [Graph Unlearning via Embedding Reconstruction -- A Range-Null Space Decomposition Approach](https://arxiv.org/abs/2508.02044)
*Hang Yin,Zipeng Liu,Xiaoyong Peng,Liyao Xiang*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的图解学方法，解决了 GNN 中节点解学的问题，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 图解学（Graph unlearning）旨在处理 GNN 中广泛而多样的图结构解学请求，但这一领域仍有待探索。现有的 GIF（图影响函数）在部分边解学方面有效，但在处理更具干扰性的节点解学方面存在挑战。

Method: 提出了一种新颖的节点解学方法，通过嵌入重构来逆转 GNN 中的聚合过程，并采用范围-零空间分解来学习节点的交互。

Result: 本研究提出的方法在多个代表性数据集上实现了最先进的性能。

Conclusion: 本研究提出了一个新颖的节点解学方法，通过嵌入重构来逆转 GNN 中的聚合过程，并采用范围-零空间分解来学习节点交互，在多个代表性数据集的实验结果表明，我们提出的方法达到了最先进的性能。

Abstract: Graph unlearning is tailored for GNNs to handle widespread and various graph
structure unlearning requests, which remain largely unexplored. The GIF (graph
influence function) achieves validity under partial edge unlearning, but faces
challenges in dealing with more disturbing node unlearning. To avoid the
overhead of retraining and realize the model utility of unlearning, we proposed
a novel node unlearning method to reverse the process of aggregation in GNN by
embedding reconstruction and to adopt Range-Null Space Decomposition for the
nodes' interaction learning. Experimental results on multiple representative
datasets demonstrate the SOTA performance of our proposed approach.

</details>


### [631] [Maximize margins for robust splicing detection](https://arxiv.org/abs/2508.00897)
*Julien Simon de Kergunic,Rony Abecidan,Patrick Bas,Vincent Itier*

Main category: cs.LG

TL;DR: 深度学习模型对图像后处理的鲁棒性很重要。本研究提出了一种通过最大化潜在裕量来提高模型鲁棒性的方法，即训练多个模型变体并选择潜在裕量最大的模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的拼接检测工具对训练条件敏感，即使是轻微的后处理也会显著降低检测性能，这引发了对其在实际操作中可靠性的担忧。

Method: 提出了一种通过训练多个模型变体并在不同条件下进行训练，然后选择最大化潜在裕量的模型的方法，以提高检测器的泛化能力。

Result: 实验表明，潜在空间分布的差异会影响模型对未见过的后处理的反应，并且潜在空间裕量分布与检测器泛化到后处理图像的能力之间存在很强的相关性。

Conclusion: 该研究提出了一种通过最大化潜在裕量来提高深度学习模型对图像后处理的鲁棒性的策略，以解决当前基于深度学习的拼接检测工具在实际应用中部署困难的问题。

Abstract: Despite recent progress in splicing detection, deep learning-based forensic
tools remain difficult to deploy in practice due to their high sensitivity to
training conditions. Even mild post-processing applied to evaluation images can
significantly degrade detector performance, raising concerns about their
reliability in operational contexts. In this work, we show that the same deep
architecture can react very differently to unseen post-processing depending on
the learned weights, despite achieving similar accuracy on in-distribution test
data. This variability stems from differences in the latent spaces induced by
training, which affect how samples are separated internally. Our experiments
reveal a strong correlation between the distribution of latent margins and a
detector's ability to generalize to post-processed images. Based on this
observation, we propose a practical strategy for building more robust
detectors: train several variants of the same model under different conditions,
and select the one that maximizes latent margins.

</details>


### [632] [Filtering with Self-Attention and Storing with MLP: One-Layer Transformers Can Provably Acquire and Extract Knowledge](https://arxiv.org/abs/2508.00901)
*Ruichen Xu,Kexin Chen*

Main category: cs.LG

TL;DR: The paper theoretically analyzes knowledge acquisition and extraction in transformers using a one-layer model with attention and MLPs. It proves transformers can learn and retrieve knowledge under specific fine-tuning conditions, but may hallucinate if these conditions aren't met. Experiments validate the findings.


<details>
  <summary>Details</summary>
Motivation: Modern large language models, particularly transformers, excel at knowledge-intensive tasks, but the theoretical understanding of how they acquire and extract knowledge during pre-training and post-fine-tuning inference is limited. Prior work focused on simplified, attention-only architectures, while empirical evidence suggests MLPs play a crucial role in knowledge storage. This paper aims to address this gap by providing theoretical guarantees for knowledge acquisition and extraction in a more complete transformer framework.

Method: The paper introduces a tractable one-layer transformer framework incorporating both self-attention and MLP modules. It analyzes the gradient dynamics of this framework to establish convergence and generalization guarantees, illuminating the ability of knowledge acquisition and extraction. The analysis considers both full fine-tuning and low-rank fine-tuning.

Result: 1) Transformers can achieve near-optimal training loss during pre-training, indicating effective knowledge acquisition. 2) When fine-tuning conditions (large dataset, specific data multiplicity) are met, transformers show low generalization error for knowledge extraction, even on data not reinforced during fine-tuning. 3) When conditions are not met, transformers exhibit high generalization loss, leading to hallucinations. The analysis also offers theoretical insights into empirical phenomena like learning rate schedules.

Conclusion: Transformers can achieve near-optimal training loss during pre-training for effective knowledge acquisition. With sufficient fine-tuning data and specific data multiplicity conditions, they can achieve low generalization error in knowledge extraction, avoiding hallucinations. However, failure to meet these conditions leads to high generalization loss and hallucinations. The analysis covers full and low-rank fine-tuning and provides insights into phenomena like learning rate schedules. Experiments on synthetic and PopQA datasets with GPT-2 and Llama-3.2-1B validate these findings.

Abstract: Modern large language models excel in knowledge-intensive tasks, yet how
transformers acquire (store) knowledge during pre-training and extract
(retrieve) it during post-fine-tuning inference remains theoretically opaque.
While prior theoretical work has begun to investigate these questions through
the analysis of training dynamics, such studies are limited to single-layer,
attention-only architectures. However, most existing studies suggest that MLPs
are the most contributing components for storing knowledge in transformer-based
language models. Meanwhile, our empirical investigations reveal that such
simplified models, when trained using standard next-token prediction
objectives, may be incapable of acquiring or extracting factual knowledge. To
overcome this limitation, we introduce a tractable one-layer transformer
framework that crucially incorporates both self-attention and MLP modules. By
tracking its gradient dynamics, we establish convergence and generalization
guarantees that illuminate the ability of knowledge acquisition and extraction.
We prove that 1) Transformers can achieve near-optimal training loss during
pre-training, signifying effective knowledge acquisition; 2) With a large
fine-tuning dataset and specific data multiplicity conditions met, transformers
can achieve low generalization error when tested on factual knowledge learned
during pre-training but not reinforced during the fine-tuning, indicating
successful knowledge extraction; 3) When the conditions are not satisfied,
transformers exhibit high generalization loss, resulting in hallucinations. Our
analysis includes both full fine-tuning and low-rank fine-tuning. Furthermore,
our analysis offers theoretical insights into several pertinent empirical
phenomena, such as the role of learning rate schedules. Experiments on
synthetic and real-world PopQA datasets with GPT-2 and Llama-3.2-1B validate
our results.

</details>


### [633] [NeuCoReClass AD: Redefining Self-Supervised Time Series Anomaly Detection](https://arxiv.org/abs/2508.00909)
*Aitor Sánchez-Ferrera,Usue Mori,Borja Calvo,Jose A. Lozano*

Main category: cs.LG

TL;DR: NeuCoReClass AD是一个多任务自监督学习框架，用于时间序列异常检测，通过结合对比、重构和分类代理任务，并利用神经转换学习生成增强视图，解决了现有方法泛化性差和依赖单一代理任务的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一代理任务，限制了其捕获数据模式的能力，且需要手动设计的特定领域转换，泛化性差。本研究旨在解决这些局限性。

Method: NeuCoReClass AD框架结合了对比学习、重构和分类代理任务，并利用神经转换学习生成信息丰富、多样化且一致的增强视图，无需特定领域知识。

Result: NeuCoReClass AD在多个基准测试中表现优于传统基线和大多数深度学习方法，并在无监督情况下能够表征不同的异常特征。

Conclusion: NeuCoReClass AD框架能够有效地进行时间序列异常检测，并且能够以完全无监督的方式实现对不同异常特征的表征。

Abstract: Time series anomaly detection plays a critical role in a wide range of
real-world applications. Among unsupervised approaches, self-supervised
learning has gained traction for modeling normal behavior without the need of
labeled data. However, many existing methods rely on a single proxy task,
limiting their ability to capture meaningful patterns in normal data. Moreover,
they often depend on handcrafted transformations tailored specific domains,
hindering their generalization accross diverse problems. To address these
limitations, we introduce NeuCoReClass AD, a self-supervised multi-task time
series anomaly detection framework that combines contrastive, reconstruction,
and classification proxy tasks. Our method employs neural transformation
learning to generate augmented views that are informative, diverse, and
coherent, without requiring domain-specific knowledge. We evaluate NeuCoReClass
AD across a wide range of benchmarks, demonstrating that it consistently
outperforms both classical baselines and most deep-learning alternatives.
Furthermore, it enables the characterization of distinct anomaly profiles in a
fully unsupervised manner.

</details>


### [634] [Predictive Auditing of Hidden Tokens in LLM APIs via Reasoning Length Estimation](https://arxiv.org/abs/2508.00912)
*Ziyao Wang,Guoheng Sun,Yexiao He,Zheyu Shen,Bowei Tian,Ang Li*

Main category: cs.LG

TL;DR: PALACE 是一个创新的用户端框架，可以估计商业 LLM 服务中隐藏的推理代币使用量，从而实现对服务提供商的审计和对用户过度计费的担忧。


<details>
  <summary>Details</summary>
Motivation: 商业 LLM 服务通常隐藏内部推理过程，并按生成的所有代币（包括隐藏的中间步骤）收费，这引发了代币膨胀和潜在过度计费的担忧。用户需要可靠的代币审计，但现有的加密验证和用户端预测方法存在不足。

Method: PALACE (Predictive Auditing of LLM APIs via Reasoning Token Count Estimation) 框架，通过 GRPO 增强的自适应模块和轻量级的领域路由器，在不访问内部追踪信息的情况下，从提示-答案对中估计隐藏的推理代币计数，并动态校准以适应不同的推理任务和代币使用模式的差异。

Result: PALACE 在数学、编码、医学和通用推理基准测试中实现了较低的相对误差和较高的预测准确性，能够支持细粒度的成本审计和膨胀检测。

Conclusion: PALACE 是一个用户端的框架，通过从提示-答案对中估计隐藏的推理代币计数，实现了对 LLM API 的预测审计，为实现标准化的预测审计、提高透明度、可问责性和用户信任迈出了重要的一步。

Abstract: Commercial LLM services often conceal internal reasoning traces while still
charging users for every generated token, including those from hidden
intermediate steps, raising concerns of token inflation and potential
overbilling. This gap underscores the urgent need for reliable token auditing,
yet achieving it is far from straightforward: cryptographic verification (e.g.,
hash-based signature) offers little assurance when providers control the entire
execution pipeline, while user-side prediction struggles with the inherent
variance of reasoning LLMs, where token usage fluctuates across domains and
prompt styles. To bridge this gap, we present PALACE (Predictive Auditing of
LLM APIs via Reasoning Token Count Estimation), a user-side framework that
estimates hidden reasoning token counts from prompt-answer pairs without access
to internal traces. PALACE introduces a GRPO-augmented adaptation module with a
lightweight domain router, enabling dynamic calibration across diverse
reasoning tasks and mitigating variance in token usage patterns. Experiments on
math, coding, medical, and general reasoning benchmarks show that PALACE
achieves low relative error and strong prediction accuracy, supporting both
fine-grained cost auditing and inflation detection. Taken together, PALACE
represents an important first step toward standardized predictive auditing,
offering a practical path to greater transparency, accountability, and user
trust.

</details>


### [635] [SmartDate: AI-Driven Precision Sorting and Quality Control in Date Fruits](https://arxiv.org/abs/2508.00921)
*Khaled Eskaf*

Main category: cs.LG

TL;DR: SmartDate是一个利用AI（深度学习、遗传算法、强化学习）和光谱传感技术自动分选和质控日期水果的系统，准确率达94.5%，能预测保质期，减少浪费，提升农业效率。


<details>
  <summary>Details</summary>
Motivation: "SmartDate" 系统旨在通过人工智能技术自动化日期水果的分选和质量控制过程，以提高效率、减少浪费并确保产品质量，从而在智慧农业领域设定新的标准。

Method: "SmartDate" 系统采用了高分辨率成像和可见-近红外（VisNIR）光谱传感技术，结合深度学习进行特征提取和分类，利用遗传算法优化模型参数，并通过强化学习实现对生产条件的实时适应，从而提高分类准确性并预测保质期。

Result: "SmartDate" 系统在测试中达到了94.5%的准确率、93.1%的F1分数和0.96的AUC-ROC，证明了其在日期水果分类和质量评估方面的优越性能。

Conclusion: "SmartDate" 通过结合深度学习、遗传算法和强化学习，在日期水果的自动化分选和质量控制方面取得了显著成效，将浪费减少了X%，并确保只有高质量的日期水果上市，为智慧农业树立了新的标杆。

Abstract: SmartDate is an AI-powered system for automated sorting and quality control
of date fruits. It combines deep learning, genetic algorithms, and
reinforcement learning to improve classification accuracy and predict shelf
life. The system uses high-resolution imaging and Visible-Near-Infrared
(VisNIR) spectral sensors to evaluate key features such as moisture, sugar
content, and texture. Reinforcement learning enables real-time adaptation to
production conditions, while genetic algorithms optimize model parameters.
SmartDate achieved 94.5 percent accuracy, 93.1 percent F1-score, and an AUC-ROC
of 0.96. The system reduces waste and ensures that only high-quality dates
reach the market, setting a new benchmark in smart agriculture.

</details>


### [636] [Compression-Induced Communication-Efficient Large Model Training and Inferencing](https://arxiv.org/abs/2508.00960)
*Sudip K. Seal,Maksudul Alam,Jorge Ramirez,Sajal Dash,Hao Lu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为“幻影并行”的新策略，用于减少大型神经网络训练中的能耗，尤其是在张量并行方面。实验证明，该方法能将训练能耗降低约50%，并能在更少的GPU上实现同等性能，从而提高能源效率。


<details>
  <summary>Details</summary>
Motivation: 大型神经网络模型训练和推理的能耗问题是阻碍未来大规模机器学习工作负载可持续性的关键挑战。因此，有必要探索新的策略来减少这些计算密集型任务的能源消耗。

Method: 该研究推导了幻影并行下的前向传播和后向传播算子，并将其作为自定义自动微分操作在端到端的幻影并行训练流程中实现。随后，将该方法的并行性能和能效与传统的张量并行训练流程进行了比较，并通过理论分析和在多达256个GPU上的实证研究，验证了其在降低带宽和计算量（FLOPs）方面的优势。

Result: 与传统的张量并行方法相比，幻影并行方法能够将前馈神经网络的训练能耗降低约50%。此外，幻影并行还可以在更少的GPU上训练出与更大张量并行模型相当的幻影模型，为实现更高的能源节省提供了可能性。

Conclusion: 该研究提出了幻影并行（phantom parallelism）策略，旨在通过优化张量并行（tensor parallelism）来降低大型神经网络训练的能耗。实验结果表明，与传统的张量并行方法相比，幻影并行可以将前馈神经网络（FFN）的训练能耗降低约50%。此外，该方法还能在更少的GPU上训练出与更大模型相当的幻影模型，从而实现更高的能源效率。

Abstract: Energy efficiency of training and inferencing with large neural network
models is a critical challenge facing the future of sustainable large-scale
machine learning workloads. This paper introduces an alternative strategy,
called phantom parallelism, to minimize the net energy consumption of
traditional tensor (model) parallelism, the most energy-inefficient component
of large neural network training. The approach is presented in the context of
feed-forward network architectures as a preliminary, but comprehensive,
proof-of-principle study of the proposed methodology. We derive new forward and
backward propagation operators for phantom parallelism, implement them as
custom autograd operations within an end-to-end phantom parallel training
pipeline and compare its parallel performance and energy-efficiency against
those of conventional tensor parallel training pipelines. Formal analyses that
predict lower bandwidth and FLOP counts are presented with supporting empirical
results on up to 256 GPUs that corroborate these gains. Experiments are shown
to deliver ~50% reduction in the energy consumed to train FFNs using the
proposed phantom parallel approach when compared with conventional tensor
parallel methods. Additionally, the proposed approach is shown to train smaller
phantom models to the same model loss on smaller GPU counts as larger tensor
parallel models on larger GPU counts offering the possibility for even greater
energy savings.

</details>


### [637] [CaliMatch: Adaptive Calibration for Improving Safe Semi-supervised Learning](https://arxiv.org/abs/2508.00922)
*Jinsoo Bae,Seoung Bum Kim,Hyungrok Do*

Main category: cs.LG

TL;DR: CaliMatch通过校准分类器和OOD检测器来提高安全半监督学习的性能，解决了现有方法中存在的过度自信问题，并在多项基准测试中取得了领先结果。


<details>
  <summary>Details</summary>
Motivation: 现有的安全半监督学习方法可能会因为深度神经网络的过度自信而在伪标签或OOD检测上产生错误，而CaliMatch旨在解决这个问题。

Method: 提出了一种名为CaliMatch的新方法，该方法通过自适应标签平滑和温度缩放来校准分类器和OOD检测器，以实现安全的半监督学习。

Result: CaliMatch在CIFAR-10、CIFAR-100、SVHN、TinyImageNet和ImageNet等数据集上进行了广泛评估，结果表明CaliMatch在安全半监督学习任务中优于现有方法。

Conclusion: CaliMatch通过自适应标签平滑和温度缩放来校准分类器和OOD检测器，从而实现安全的半监督学习，并在各种基准测试中优于现有方法。

Abstract: Semi-supervised learning (SSL) uses unlabeled data to improve the performance
of machine learning models when labeled data is scarce. However, its real-world
applications often face the label distribution mismatch problem, in which the
unlabeled dataset includes instances whose ground-truth labels are absent from
the labeled training dataset. Recent studies, referred to as safe SSL, have
addressed this issue by using both classification and out-of-distribution (OOD)
detection. However, the existing methods may suffer from overconfidence in deep
neural networks, leading to increased SSL errors because of high confidence in
incorrect pseudo-labels or OOD detection. To address this, we propose a novel
method, CaliMatch, which calibrates both the classifier and the OOD detector to
foster safe SSL. CaliMatch presents adaptive label smoothing and temperature
scaling, which eliminates the need to manually tune the smoothing degree for
effective calibration. We give a theoretical justification for why improving
the calibration of both the classifier and the OOD detector is crucial in safe
SSL. Extensive evaluations on CIFAR-10, CIFAR-100, SVHN, TinyImageNet, and
ImageNet demonstrate that CaliMatch outperforms the existing methods in safe
SSL tasks.

</details>


### [638] [Optimal Scheduling Algorithms for LLM Inference: Theory and Practice](https://arxiv.org/abs/2508.01002)
*Agrim Bari,Parikshit Hegde,Gustavo de Veciana*

Main category: cs.LG

TL;DR: LLM推理系统需要新的路由和调度策略。本文提出了一种名为SLAI的调度器，它通过优先处理即将错过TBT截止日期的请求和根据prompt长度重新排序请求，显著减少了TTFT延迟并提高了服务容量，同时满足了延迟约束。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT、Perplexity和Gemini等基于LLM的工具的广泛应用，对高效LLM推理系统的需求日益增长。这些系统处理请求时具有独特的两阶段计算结构（预处理和解码），这需要新的路由和调度策略。

Method: 提出了一种名为SLAI（SLO-Aware LLM Inference）的调度器，它利用实时测量数据来优先处理即将超过TBT（token间延迟）截止日期的解码请求，并根据已知的prompt长度重新排序预处理请求，以进一步减少TTFT（首个token生成时间）延迟。SLAI的设计遵循了最优分块和动态资源分配这两个关键原则。

Result: SLAI在NVIDIA RTX ADA 6000 GPU上使用Mistral-7B模型和Openchat ShareGPT4数据集进行评估，相比Sarathi-Serve，将中位数TTFT减少了53%，并将最大服务容量提高了26%，同时满足了TBT的尾部延迟约束。

Conclusion: SLAI在Openchat ShareGPT4数据集和Mistral-7B模型上，相比Sarathi-Serve，将TTFT（首个token生成时间）中位数减少了53%，并将最大服务容量提高了26%，同时满足了TBT（token间延迟）的尾部延迟约束。

Abstract: With the growing use of Large Language Model (LLM)-based tools like ChatGPT,
Perplexity, and Gemini across industries, there is a rising need for efficient
LLM inference systems. These systems handle requests with a unique two-phase
computation structure: a prefill-phase that processes the full input prompt and
a decode-phase that autoregressively generates tokens one at a time. This
structure calls for new strategies for routing and scheduling requests.
  In this paper, we take a comprehensive approach to this challenge by
developing a theoretical framework that models routing and scheduling in LLM
inference systems. We identify two key design principles-optimal tiling and
dynamic resource allocation-that are essential for achieving high throughput.
Guided by these principles, we propose the Resource-Aware Dynamic (RAD)
scheduler and prove that it achieves throughput optimality under mild
conditions. To address practical Service Level Objectives (SLOs) such as
serving requests with different Time Between Token (TBT) constraints, we design
the SLO-Aware LLM Inference (SLAI) scheduler. SLAI uses real-time measurements
to prioritize decode requests that are close to missing their TBT deadlines and
reorders prefill requests based on known prompt lengths to further reduce the
Time To First Token (TTFT) delays.
  We evaluate SLAI on the Openchat ShareGPT4 dataset using the Mistral-7B model
on an NVIDIA RTX ADA 6000 GPU. Compared to Sarathi-Serve, SLAI reduces the
median TTFT by 53% and increases the maximum serving capacity by 26% such that
median TTFT is below 0.5 seconds, while meeting tail TBT latency constraints.

</details>


### [639] [Beyond Benchmarks: Dynamic, Automatic And Systematic Red-Teaming Agents For Trustworthy Medical Language Models](https://arxiv.org/abs/2508.00923)
*Jiazhen Pan,Bailiang Jian,Paul Hager,Yundi Zhang,Che Liu,Friedrike Jungmann,Hongwei Bran Li,Chenyu You,Junde Wu,Jiayuan Zhu,Fenglin Liu,Yuyuan Liu,Niklas Bubeck,Christian Wachinger,Chen,Chen,Zhenyu Gong,Cheng Ouyang,Georgios Kaissis,Benedikt Wiestler,Daniel Rueckert*

Main category: cs.LG

TL;DR: 大型语言模型在医疗保健中的安全和可靠性是关键，但静态基准测试已过时。DAS 红队测试框架通过动态、自动和系统的压力测试，揭示了当前大型语言模型在鲁棒性、隐私、偏见和幻觉方面存在严重缺陷。即使在 MedQA 上表现良好，94% 的模型在动态鲁棒性测试中失败。隐私泄露率达 86%，认知偏差影响 81% 的临床建议，幻觉率高达 66%。DAS 框架为监管机构和供应商提供了一种可演进、可扩展的解决方案，以应对医疗人工智能的挑战。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLMs）在临床实践中的安全性和可靠性对于防止患者伤害和促进值得信赖的医疗保健人工智能应用至关重要。然而，大型语言模型的发展速度非常快，静态安全基准测试经常在发布时就已经过时，只能提供对模型可信度不完整甚至具有误导性的描述。

Method: 开发了一个动态、自动且系统的（DAS）红队测试框架，该框架能够持续对大型语言模型进行压力测试。该框架利用一套对抗性代理，能够自主地进行测试用例的变异、识别/演进不安全触发策略以及评估响应，从而在没有人工干预的情况下实时发现漏洞。

Result: 在 15 个专有和开源的大型语言模型上应用 DAS 测试，揭示了静态基准测试性能与对抗性压力下的脆弱性之间存在显著差异。尽管中位 MedQA 准确率超过 80%，但 94% 的先前正确答案在动态鲁棒性测试中失败。在其他领域也观察到了类似的失败率：86% 的隐私泄露场景被触发，81% 的公平性测试中认知偏差引发了临床建议的改变，并且在广泛使用的模型中发现了超过 66% 的幻觉率。

Conclusion: DAS 红队测试框架通过持续的压力测试揭示了当前大型语言模型在安全关键领域的显著弱点，为医院、监管机构和技术供应商提供了必要的监控，以应对大型语言模型在医疗保健中的广泛应用。该框架提供了一种可演进、可扩展且可靠的保障措施，以应对下一代医疗人工智能的挑战。

Abstract: Ensuring the safety and reliability of large language models (LLMs) in
clinical practice is critical to prevent patient harm and promote trustworthy
healthcare applications of AI. However, LLMs are advancing so rapidly that
static safety benchmarks often become obsolete upon publication, yielding only
an incomplete and sometimes misleading picture of model trustworthiness. We
demonstrate that a Dynamic, Automatic, and Systematic (DAS) red-teaming
framework that continuously stress-tests LLMs can reveal significant weaknesses
of current LLMs across four safety-critical domains: robustness, privacy,
bias/fairness, and hallucination. A suite of adversarial agents is applied to
autonomously mutate test cases, identify/evolve unsafe-triggering strategies,
and evaluate responses, uncovering vulnerabilities in real time without human
intervention. Applying DAS to 15 proprietary and open-source LLMs revealed a
stark contrast between static benchmark performance and vulnerability under
adversarial pressure. Despite a median MedQA accuracy exceeding 80\%, 94\% of
previously correct answers failed our dynamic robustness tests. We observed
similarly high failure rates across other domains: privacy leaks were elicited
in 86\% of scenarios, cognitive-bias priming altered clinical recommendations
in 81\% of fairness tests, and we identified hallucination rates exceeding 66\%
in widely used models. Such profound residual risks are incompatible with
routine clinical practice. By converting red-teaming from a static checklist
into a dynamic stress-test audit, DAS red-teaming offers the surveillance that
hospitals/regulators/technology vendors require as LLMs become embedded in
patient chatbots, decision-support dashboards, and broader healthcare
workflows. Our framework delivers an evolvable, scalable, and reliable
safeguard for the next generation of medical AI.

</details>


### [640] [Hybrid Hypergraph Networks for Multimodal Sequence Data Classification](https://arxiv.org/abs/2508.00926)
*Feng Xu,Hui Wang,Yuting Huang,Danwei Zhang,Zizhu Fan*

Main category: cs.LG

TL;DR: HHN通过“先分段、后图化”的策略，结合超图卷积和图注意力，有效解决了时间多模态数据分类中的长期依赖和跨模态交互挑战，并在多个数据集上 đạt được SOTA 结果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法大多独立处理各模态并依赖浅层融合策略，忽略了时间依赖性和复杂结构关系，限制了模型表示能力。

Method: 提出了一种新颖的混合超图网络（HHN）框架，采用“先分段、后图化”的策略来建模时间多模态数据。该方法将序列分割为带时间戳的段作为异构图中的节点，利用超边捕捉内模态结构，并通过最大熵差准则增强节点异质性和结构区分度，随后进行超图卷积以提取高阶依赖关系。通过时间对齐和图注意力建立跨模态链接以进行语义融合。

Result: HHN在四个多模态数据集上取得了最先进（SOTA）的成果。

Conclusion: HHN在四个多模态数据集上取得了最先进（SOTA）的成果，证明了其在复杂分类任务中的有效性。

Abstract: Modeling temporal multimodal data poses significant challenges in
classification tasks, particularly in capturing long-range temporal
dependencies and intricate cross-modal interactions. Audiovisual data, as a
representative example, is inherently characterized by strict temporal order
and diverse modalities. Effectively leveraging the temporal structure is
essential for understanding both intra-modal dynamics and inter-modal
correlations. However, most existing approaches treat each modality
independently and rely on shallow fusion strategies, which overlook temporal
dependencies and hinder the model's ability to represent complex structural
relationships. To address the limitation, we propose the hybrid hypergraph
network (HHN), a novel framework that models temporal multimodal data via a
segmentation-first, graph-later strategy. HHN splits sequences into timestamped
segments as nodes in a heterogeneous graph. Intra-modal structures are captured
via hyperedges guided by a maximum entropy difference criterion, enhancing node
heterogeneity and structural discrimination, followed by hypergraph convolution
to extract high-order dependencies. Inter-modal links are established through
temporal alignment and graph attention for semantic fusion. HHN achieves
state-of-the-art (SOTA) results on four multimodal datasets, demonstrating its
effectiveness in complex classification tasks.

</details>


### [641] [Learning Unified System Representations for Microservice Tail Latency Prediction](https://arxiv.org/abs/2508.01635)
*Wenzhuo Qian,Hailiang Zhao,Tianlv Chen,Jiayi Chen,Ziqi Wang,Kingsum Chow,Shuiguang Deng*

Main category: cs.LG

TL;DR: USRFNet是一种深度学习网络，通过分离和模拟流量侧与资源侧的特征，解决了微服务性能监控中的挑战，并在预测窗口级别P95延迟方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微服务架构的分布式特性在性能监控和资源管理方面带来了显著的挑战。传统方法依赖于对瞬态噪声高度敏感的每请求延迟指标，未能反映复杂、并发工作负载的整体行为。相比之下，窗口级别的P95尾部延迟提供了一个稳定且有意义的信号，能够捕获系统范围的趋势和用户感知的性能下降。现有方法在处理异构数据（流量侧特征在服务依赖关系中传播，资源侧信号反映局部瓶颈）和有效区分和整合这些互补模式的原则性架构设计方面存在不足。

Method: 提出了一种名为USRFNet的深度学习网络，该网络明确分离并模拟了流量侧和资源侧的特征。USRFNet采用GNN来捕获服务交互和请求传播模式，而gMLP模块则独立模拟集群资源动态。然后，将这些表示融合到一个统一的系统嵌入中，以高精度预测窗口级别的P95延迟。

Result: USRFNet能够高精度地预测窗口级别的P95延迟。

Conclusion: USRFNet在真实世界的微服务基准测试中，在大规模压力测试条件下进行了评估，并在预测精度方面相对于最先进的基线取得了显著的改进。

Abstract: Microservice architectures have become the de facto standard for building
scalable cloud-native applications, yet their distributed nature introduces
significant challenges in performance monitoring and resource management.
Traditional approaches often rely on per-request latency metrics, which are
highly sensitive to transient noise and fail to reflect the holistic behavior
of complex, concurrent workloads. In contrast, window-level P95 tail latency
provides a stable and meaningful signal that captures both system-wide trends
and user-perceived performance degradation. We identify two key shortcomings in
existing methods: (i) inadequate handling of heterogeneous data, where
traffic-side features propagate across service dependencies and resource-side
signals reflect localized bottlenecks, and (ii) the lack of principled
architectural designs that effectively distinguish and integrate these
complementary modalities. To address these challenges, we propose USRFNet, a
deep learning network that explicitly separates and models traffic-side and
resource-side features. USRFNet employs GNNs to capture service interactions
and request propagation patterns, while gMLP modules independently model
cluster resource dynamics. These representations are then fused into a unified
system embedding to predict window-level P95 latency with high accuracy. We
evaluate USRFNet on real-world microservice benchmarks under large-scale stress
testing conditions, demonstrating substantial improvements in prediction
accuracy over state-of-the-art baselines.

</details>


### [642] [Cooperative effects in feature importance of individual patterns: application to air pollutants and Alzheimer disease](https://arxiv.org/abs/2508.00930)
*M. Ontivero-Ortega,A. Fania,A. Lacalamita,R. Bellotti,A. Monaco,S. Stramaglia*

Main category: cs.LG

TL;DR: 该论文提出了一个框架，用于将唯一、冗余和协同分数分配给数据集中的每个模式，以分析特征重要性中的协同作用。该框架在空气污染物和阿尔茨海默病死亡率之间的关系的应用中得到了证明，并强调了$O_3$、$NO_2$和城市绿地密度之间的协同作用。


<details>
  <summary>Details</summary>
Motivation: 为了量化特征重要性（Hi-Fi）中的协同作用，Hi-Fi是可解释人工智能（XAI）中的一项关键技术，旨在区分回归问题中涉及特定输入特征的高阶效应。

Method: 提出了一种将三个分数（唯一、冗余和协同）分配给数据集中每个单独模式的框架，并将其与Shapley效应进行了比较。

Result: 我们证明了$O_3$和$NO_2$相关特征与死亡率之间存在协同关联，特别是在贝加莫和布雷西亚省；值得注意的是，城市绿地的密度也对预测AD死亡率的污染物产生了协同影响。

Conclusion: Hi-Fi是一种很有前景的工具，具有广泛的适用性，为XAI开辟了新的视角，并能分析复杂系统中的高阶关系。

Abstract: Leveraging recent advances in the analysis of synergy and redundancy in
systems of random variables, an adaptive version of the widely used metric
Leave One Covariate Out (LOCO) has been recently proposed to quantify
cooperative effects in feature importance (Hi-Fi), a key technique in
explainable artificial intelligence (XAI), so as to disentangle high-order
effects involving a particular input feature in regression problems.
Differently from standard feature importance tools, where a single score
measures the relevance of each feature, each feature is here characterized by
three scores, a two-body (unique) score and higher-order scores (redundant and
synergistic). This paper presents a framework to assign those three scores
(unique, redundant, and synergistic) to each individual pattern of the data
set, while comparing it with the well-known measure of feature importance named
{\it Shapley effect}. To illustrate the potential of the proposed framework, we
focus on a One-Health application: the relation between air pollutants and
Alzheimer's disease mortality rate. Our main result is the synergistic
association between features related to $O_3$ and $NO_2$ with mortality,
especially in the provinces of Bergamo e Brescia; notably also the density of
urban green areas displays synergistic influence with pollutants for the
prediction of AD mortality. Our results place local Hi-Fi as a promising tool
of wide applicability, which opens new perspectives for XAI as well as to
analyze high-order relationships in complex systems.

</details>


### [643] [Boosting Generalization Performance in Model-Heterogeneous Federated Learning Using Variational Transposed Convolution](https://arxiv.org/abs/2508.01669)
*Ziru Niu,Hai Dong,A. K. Qin*

Main category: cs.LG

TL;DR: 一种新的联邦学习方法，通过交换特征分布并生成合成数据来解决模型异质性问题，提高了模型的泛化能力并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）虽然有效，但客户端之间的数据异质性会影响模型的泛化性能。传统的解决异质性的方法（如正则化或调整客户端权重）不适用于模型架构异质的场景。因此，需要一种新的方法来解决模型异质性带来的挑战。

Method: 提出了一种模型异质的联邦学习框架，不进行模型聚合，而是让客户端与服务器交换特征分布（均值和协方差）。客户端利用这些信息训练变分转置卷积（VTC）神经网络，并生成合成数据，然后用合成数据对本地模型进行微调，从而提高模型的泛化能力。

Result: 实验结果表明，该方法在模型异质的联邦学习场景下，相比现有的框架，能够获得更高的泛化准确率，并且通信成本和内存消耗更低。

Conclusion: 该方法通过在联邦学习的场景下，利用生成合成数据来提升模型的泛化能力，相较于现有的模型异质联邦学习框架，能够获得更高的泛化准确率，以及更低的通信成本和内存消耗。

Abstract: Federated learning (FL) is a pioneering machine learning paradigm that
enables distributed clients to process local data effectively while ensuring
data privacy. However, the efficacy of FL is usually impeded by the data
heterogeneity among clients, resulting in local models with low generalization
performance. To address this problem, traditional model-homogeneous approaches
mainly involve debiasing the local training procedures with regularization or
dynamically adjusting client weights in aggregation. Nonetheless, these
approaches become incompatible for scenarios where clients exhibit
heterogeneous model architectures. In this paper, we propose a
model-heterogeneous FL framework that can improve clients' generalization
performance over unseen data without model aggregation. Instead of model
parameters, clients exchange the feature distributions with the server,
including the mean and the covariance. Accordingly, clients train a variational
transposed convolutional (VTC) neural network with Gaussian latent variables
sampled from the feature distributions, and use the VTC model to generate
synthetic data. By fine-tuning local models with the synthetic data, clients
significantly increase their generalization performance. Experimental results
show that our approach obtains higher generalization accuracy than existing
model-heterogeneous FL frameworks, as well as lower communication costs and
memory consumption

</details>


### [644] [OKG-LLM: Aligning Ocean Knowledge Graph with Observation Data via LLMs for Global Sea Surface Temperature Prediction](https://arxiv.org/abs/2508.00933)
*Hanchen Yang,Jiaqi Wang,Jiannong Cao,Wengen Li,Jialun Zheng,Yangning Li,Chunyu Miao,Jihong Guan,Shuigeng Zhou,Philip S. Yu*

Main category: cs.LG

TL;DR: OKG-LLM框架通过整合海洋知识图谱和LLM，并结合SST数据，提高了SST预测的准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法在SST预测方面虽有成功，但未能充分利用积累的领域知识，限制了预测精度的进一步提高。LLM的出现表明了将领域知识整合到下游任务的潜力，但将其应用于SST预测因整合海洋领域知识和数值数据的挑战而未被充分探索。

Method: 提出了一种名为Ocean Knowledge Graph-enhanced LLM (OKG-LLM) 的新颖框架，用于全球SST预测。该框架首先构建了一个用于SST预测的海洋知识图谱(OKG)，然后开发了一个图嵌入网络来学习OKG中的语义和结构知识，最后将学习到的知识与SST数据对齐并融合，并利用预训练的LLM进行SST模式建模以进行准确预测。

Result: OKG-LLM框架在真实世界数据集上的大量实验表明，其持续优于最先进的方法。

Conclusion: OKG-LLM框架在SST预测方面表现优于现有技术，具有有效性、鲁棒性，并有潜力推动SST预测的进步。

Abstract: Sea surface temperature (SST) prediction is a critical task in ocean science,
supporting various applications, such as weather forecasting, fisheries
management, and storm tracking. While existing data-driven methods have
demonstrated significant success, they often neglect to leverage the rich
domain knowledge accumulated over the past decades, limiting further
advancements in prediction accuracy. The recent emergence of large language
models (LLMs) has highlighted the potential of integrating domain knowledge for
downstream tasks. However, the application of LLMs to SST prediction remains
underexplored, primarily due to the challenge of integrating ocean domain
knowledge and numerical data. To address this issue, we propose Ocean Knowledge
Graph-enhanced LLM (OKG-LLM), a novel framework for global SST prediction. To
the best of our knowledge, this work presents the first systematic effort to
construct an Ocean Knowledge Graph (OKG) specifically designed to represent
diverse ocean knowledge for SST prediction. We then develop a graph embedding
network to learn the comprehensive semantic and structural knowledge within the
OKG, capturing both the unique characteristics of individual sea regions and
the complex correlations between them. Finally, we align and fuse the learned
knowledge with fine-grained numerical SST data and leverage a pre-trained LLM
to model SST patterns for accurate prediction. Extensive experiments on the
real-world dataset demonstrate that OKG-LLM consistently outperforms
state-of-the-art methods, showcasing its effectiveness, robustness, and
potential to advance SST prediction. The codes are available in the online
repository.

</details>


### [645] [Large-Scale Model Enabled Semantic Communication Based on Robust Knowledge Distillation](https://arxiv.org/abs/2508.02148)
*Kuiyuan DIng,Caili Guo,Yang Yang,Zhongtian Du,Walid Saad*

Main category: cs.LG

TL;DR: 提出RKD-SC框架，通过KDL-DARTS和两阶段RKD算法，以及CAT块，实现了高效、抗噪声的LSM驱动的语义通信，有效解决了计算复杂度和资源需求问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决 LSM 直接部署面临的高计算复杂度和资源需求问题，提出了一种新颖的基于知识蒸馏的语义通信（RKD-SC）框架，以实现高效且抗噪声的 LSM 驱动的 SC。

Method: 提出了一种基于知识蒸馏的轻量级可微分架构搜索（KDL-DARTS）算法，将知识蒸馏损失和复杂度惩罚整合到神经架构搜索过程中，以识别高性能、轻量级的语义编码器架构。此外，开发了一种新颖的两阶段鲁棒知识蒸馏（RKD）算法，将知识从LSM（教师）转移到紧凑型编码器（学生），并随后增强系统鲁棒性。引入了通道感知Transformer（CAT）块作为通道编解码器，并在各种通道条件下进行训练，以进一步提高对通道损伤的弹性。

Result: RKD-SC框架显著降低了模型参数，同时保持了教师模型的高性能，并表现出比现有方法更优越的鲁棒性。

Conclusion: RKD-SC框架在图像分类任务上显著减少了模型参数，同时保持了教师模型的高性能，并表现出比现有方法更优越的鲁棒性。

Abstract: Large-scale models (LSMs) can be an effective framework for semantic
representation and understanding, thereby providing a suitable tool for
designing semantic communication (SC) systems. However, their direct deployment
is often hindered by high computational complexity and resource requirements.
In this paper, a novel robust knowledge distillation based semantic
communication (RKD-SC) framework is proposed to enable efficient and
\textcolor{black}{channel-noise-robust} LSM-powered SC. The framework addresses
two key challenges: determining optimal compact model architectures and
effectively transferring knowledge while maintaining robustness against channel
noise. First, a knowledge distillation-based lightweight differentiable
architecture search (KDL-DARTS) algorithm is proposed. This algorithm
integrates knowledge distillation loss and a complexity penalty into the neural
architecture search process to identify high-performance, lightweight semantic
encoder architectures. Second, a novel two-stage robust knowledge distillation
(RKD) algorithm is developed to transfer semantic capabilities from an LSM
(teacher) to a compact encoder (student) and subsequently enhance system
robustness. To further improve resilience to channel impairments, a
channel-aware transformer (CAT) block is introduced as the channel codec,
trained under diverse channel conditions with variable-length outputs.
Extensive simulations on image classification tasks demonstrate that the RKD-SC
framework significantly reduces model parameters while preserving a high degree
of the teacher model's performance and exhibiting superior robustness compared
to existing methods.

</details>


### [646] [FeatureCuts: Feature Selection for Large Data by Optimizing the Cutoff](https://arxiv.org/abs/2508.00954)
*Andy Hu,Devika Prasad,Luiz Pizzato,Nicholas Foord,Arman Abrahamyan,Anna Leontjeva,Cooper Doyle,Dan Jermyn*

Main category: cs.LG

TL;DR: FeatureCuts 是一种新的特征选择算法，可提高特征约减率和效率，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，特征选择过程涉及找到一个减少的特征子集，该子集捕获了训练准确有效的模型所需的大部分信息。

Method: FeatureCuts 是一种新颖的特征选择算法，在执行过滤器排序后自适应地选择最佳特征截止值。

Result: 与现有的最先进方法相比，FeatureCuts 在特征约减方面平均提高了 15 个百分点，计算时间缩短了 99.6%，同时保持了模型性能。与单独使用 PSO 相比，当所选特征用于类似 PSO 的包装器方法时，可额外约减 25% 的特征，减少 66% 的计算时间，并保持模型性能。

Conclusion: FeatureCuts 算法具有最小的开销，可扩展至企业应用中的大型数据集。

Abstract: In machine learning, the process of feature selection involves finding a
reduced subset of features that captures most of the information required to
train an accurate and efficient model. This work presents FeatureCuts, a novel
feature selection algorithm that adaptively selects the optimal feature cutoff
after performing filter ranking. Evaluated on 14 publicly available datasets
and one industry dataset, FeatureCuts achieved, on average, 15 percentage
points more feature reduction and up to 99.6% less computation time while
maintaining model performance, compared to existing state-of-the-art methods.
When the selected features are used in a wrapper method such as Particle Swarm
Optimization (PSO), it enables 25 percentage points more feature reduction,
requires 66% less computation time, and maintains model performance when
compared to PSO alone. The minimal overhead of FeatureCuts makes it scalable
for large datasets typically seen in enterprise applications.

</details>


### [647] [Asynchronous Federated Learning with non-convex client objective functions and heterogeneous dataset](https://arxiv.org/abs/2508.01675)
*Ali Forootani,Raffaele Iervolino*

Main category: cs.LG

TL;DR: 本文提出了一种改进的异步联邦学习（AFL）框架，通过新颖的聚合方法和动态学习率调度，有效解决了非凸目标函数和异构数据集带来的挑战，提升了性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习（FL）存在通信开销大、系统异构和拖尾效应等问题。异步联邦学习（AFL）通过允许客户端独立更新来解决这些问题，提高了可扩展性并减少了同步延迟。然而，现有 AFL 方法在处理现代深度学习中常见的非凸目标函数和异构数据集方面存在局限性。

Method: 本文提出了一种用于处理非凸目标函数和异构数据集的异步联邦学习（AFL）框架。通过引入一种“新颖的、滞后感知的聚合”方法和“动态学习率调度”来减轻滞后更新的影响，并适应客户端的滞后和异构性。框架在 PyTorch 中实现，并使用 Python 的 asyncio 进行异步操作。

Result: 该框架通过实验验证，在异步、异构和非凸的联邦学习场景中，展示了改进的性能和可扩展性。分析表明，所提出的方法能够有效处理计算能力、数据分布和通信延迟的差异。

Conclusion: 本文提出的框架通过引入一种新的聚合方法和动态学习率调度，有效解决了非凸目标函数和异构数据在联邦学习中的挑战，并在实际应用中展示了其优越的性能和可扩展性。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized devices while preserving data privacy. However, traditional FL
suffers from communication overhead, system heterogeneity, and straggler
effects. Asynchronous Federated Learning (AFL) addresses these by allowing
clients to update independently, improving scalability and reducing
synchronization delays. This paper extends AFL to handle non-convex objective
functions and heterogeneous datasets, common in modern deep learning. We
present a rigorous convergence analysis, deriving bounds on the expected
gradient norm and studying the effects of staleness, variance, and
heterogeneity. To mitigate stale updates, we introduce a staleness aware
aggregation that prioritizes fresher updates and a dynamic learning rate
schedule that adapts to client staleness and heterogeneity, improving stability
and convergence. Our framework accommodates variations in computational power,
data distribution, and communication delays, making it practical for real world
applications. We also analyze the impact of client selection
strategies-sampling with or without replacement-on variance and convergence.
Implemented in PyTorch with Python's asyncio, our approach is validated through
experiments demonstrating improved performance and scalability for
asynchronous, heterogeneous, and non-convex FL scenarios.

</details>


### [648] [Pigeon-SL: Robust Split Learning Framework for Edge Intelligence under Malicious Clients](https://arxiv.org/abs/2508.02235)
*Sangjun Park,Tony Q. S. Quek,Hyowoon Seo*

Main category: cs.LG

TL;DR: Pigeon-SL protects split learning from malicious clients by grouping them and training clusters independently, selecting the best performing cluster to discard bad updates. Pigeon-SL+ improves speed by retraining the selected cluster.


<details>
  <summary>Details</summary>
Motivation: Split learning (SL) is vulnerable to malicious clients degrading model accuracy due to its sequential update process. This paper addresses this vulnerability.

Method: Pigeon-SL utilizes the pigeonhole principle by partitioning M clients into N+1 clusters. In each round, it trains each cluster independently using vanilla SL and selects the cluster with the lowest validation loss for advancement, effectively isolating malicious updates. Pigeon-SL+ further enhances efficiency by repeating training on the selected cluster.

Result: The approach demonstrates significant improvements in accuracy and resilience against label flipping, activation, and gradient manipulation attacks compared to baseline SL methods.

Conclusion: Pigeon-SL and Pigeon-SL+ offer a robust and effective solution for privacy-preserving distributed learning in edge networks, significantly improving accuracy and resilience against malicious clients compared to traditional SL methods, especially in future intelligent wireless networks.

Abstract: Recent advances in split learning (SL) have established it as a promising
framework for privacy-preserving, communication-efficient distributed learning
at the network edge. However, SL's sequential update process is vulnerable to
even a single malicious client, which can significantly degrade model accuracy.
To address this, we introduce Pigeon-SL, a novel scheme grounded in the
pigeonhole principle that guarantees at least one entirely honest cluster among
M clients, even when up to N of them are adversarial. In each global round, the
access point partitions the clients into N+1 clusters, trains each cluster
independently via vanilla SL, and evaluates their validation losses on a shared
dataset. Only the cluster with the lowest loss advances, thereby isolating and
discarding malicious updates. We further enhance training and communication
efficiency with Pigeon-SL+, which repeats training on the selected cluster to
match the update throughput of standard SL. We validate the robustness and
effectiveness of our approach under three representative attack models -- label
flipping, activation and gradient manipulation -- demonstrating significant
improvements in accuracy and resilience over baseline SL methods in future
intelligent wireless networks.

</details>


### [649] [From Generator to Embedder: Harnessing Innate Abilities of Multimodal LLMs via Building Zero-Shot Discriminative Embedding Model](https://arxiv.org/abs/2508.00955)
*Yeong-Joon Ju,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 本研究提出了一种新的方法，利用MLLMs进行多模态嵌入，通过分层提示和自感知难负例采样，提高了效率和性能，无需进行对比预训练。


<details>
  <summary>Details</summary>
Motivation: 当前的主流方法（大规模对比预训练）在利用MLLMs进行判别性表示学习时存在计算成本高和未能充分利用MLLMs指令遵循能力等问题。本研究旨在克服这些挑战。

Method: 本研究提出了一种基于两级指令架构的分层嵌入提示模板，并结合了模型自身的理解能力来进行难负例挖掘和假负例过滤的自感知难负例采样，用于微调过程。

Result: 实验结果表明，本研究的分层提示在零样本设置下取得了与对比预训练基线相当的性能，并通过自感知难负例采样进一步提升了性能，在MMEB基准测试中，将简单的批内负例基线提高了4.8个点，实现了无需对比预训练的最优性能。

Conclusion: 本研究提出了一种高效的框架，用于通用多模态嵌入，有效地将大型多模态模型（MLLMs）的生成能力适配于判别性表示学习，达到了最先进的性能，同时显著减少了训练时间。

Abstract: Multimodal Large Language Models (MLLMs) have emerged as a promising solution
for universal embedding tasks, yet adapting their generative nature for
discriminative representation learning remains a significant challenge. The
dominant paradigm of large-scale contrastive pre-training suffers from critical
inefficiencies, including prohibitive computational costs and a failure to
leverage the intrinsic, instruction-following capabilities of MLLMs. To
overcome these limitations, we propose an efficient framework for universal
multimodal embeddings, which bridges this gap by centering on two synergistic
components. First, our hierarchical embedding prompt template employs a
two-level instruction architecture that forces the model to produce
discriminative representations. Building on this strong foundation, our second
component, self-aware hard negative sampling, redefines the fine-tuning process
by leveraging the model's own understanding to efficiently mine challenging
negatives while actively filtering out potential false negatives. Our
comprehensive experiments show that our hierarchical prompt achieves zero-shot
performance competitive with contrastively trained baselines and enhances the
fine-tuning process by lifting a simple in-batch negative baseline by 4.8
points on the MMEB benchmark. We further boost the performance via our
self-aware hard negative sampling, achieving the state-of-the-art performance
without the contrative pre-training. Our work presents an effective and
efficient pathway to adapt MLLMs for universal embedding tasks, significantly
reducing training time.

</details>


### [650] [Energy-Efficient Federated Learning for Edge Real-Time Vision via Joint Data, Computation, and Communication Design](https://arxiv.org/abs/2508.01745)
*Xiangwang Hou,Jingjing Wang,Fangming Guan,Jun Du,Chunxiao Jiang,Yong Ren*

Main category: cs.LG

TL;DR: FedDPQ是一个超高能效的联邦学习框架，通过数据增强、模型剪枝、通信量化和功率控制，解决了无线边缘设备的实时视觉应用中的能源和通信瓶颈。


<details>
  <summary>Details</summary>
Motivation: 为满足新兴的无线边缘设备实时计算机视觉应用对能源效率和隐私保护学习的需求，同时解决资源受限环境中联邦学习面临的能量消耗、通信限制以及数据限制等挑战。

Method: FedDPQ框架集成了基于扩散的数据增强、模型剪枝、通信量化和传输功率控制，并推导了能量-收敛模型，利用贝叶斯优化算法进行联合调优。

Result: 实验结果表明，FedDPQ在代表性的计算机视觉任务上实现了优越的收敛速度和能源效率。

Conclusion: FedDPQ框架在不可靠的无线条件下，通过联合优化数据增强、模型剪枝、通信量化和传输功率控制，实现了比现有方法更快的收敛速度和更高的能源效率。

Abstract: Emerging real-time computer vision (CV) applications on wireless edge devices
demand energy-efficient and privacy-preserving learning. Federated learning
(FL) enables on-device training without raw data sharing, yet remains
challenging in resource-constrained environments due to energy-intensive
computation and communication, as well as limited and non-i.i.d. local data. We
propose FedDPQ, an ultra energy-efficient FL framework for real-time CV over
unreliable wireless networks. FedDPQ integrates diffusion-based data
augmentation, model pruning, communication quantization, and transmission power
control to enhance training efficiency. It expands local datasets using
synthetic data, reduces computation through pruning, compresses updates via
quantization, and mitigates transmission outages with adaptive power control.
We further derive a closed-form energy-convergence model capturing the coupled
impact of these components, and develop a Bayesian optimization(BO)-based
algorithm to jointly tune data augmentation strategy, pruning ratio,
quantization level, and power control. To the best of our knowledge, this is
the first work to jointly optimize FL performance from the perspectives of
data, computation, and communication under unreliable wireless conditions.
Experiments on representative CV tasks show that FedDPQ achieves superior
convergence speed and energy efficiency.

</details>


### [651] [Learning Unified User Quantized Tokenizers for User Representation](https://arxiv.org/abs/2508.00956)
*Chuan He,Yang Chen,Wuliang Huang,Tianyi Zheng,Jianhu Chen,Bin Dou,Yice Luo,Yun Zhu,Baokun Wang,Yongchao Liu,Xing Fu,Yu Cheng,Chuntao Hong,Weiqiang Wang,Xin-Wei Yao*

Main category: cs.LG

TL;DR: U^2QT框架通过因果Q-Former和多视图RQ-VAE实现跨域知识迁移和早期融合，解决了多源用户表示学习中的关键挑战，并在各项下游任务和效率方面均表现出色。


<details>
  <summary>Details</summary>
Motivation: 先前多源用户表示学习的工作通常采用晚期融合策略，存在缺乏统一表示框架、数据压缩的可扩展性和存储问题以及交叉任务泛化能力不灵活等局限性。

Method: U^2QT框架采用两阶段架构：首先，因果Q-Former将特定域的特征投影到共享的因果表示空间，以保留跨模态依赖性；其次，多视图RQ-VAE通过共享和特定源的码本将因果嵌入离散化为紧凑的标记，从而在保持语义一致性的同时实现高效存储。

Result: 实验结果表明，U^2QT在未来的行为预测和推荐等各种下游任务中均优于特定任务的基线方法，并在存储和计算效率方面取得了显著的提升。

Conclusion: U^2QT框架通过将跨域知识迁移与异构域的早期融合相结合，解决了多源用户表示学习中的统一表示框架、数据压缩的可扩展性和存储问题以及交叉任务泛化的灵活性等挑战。该框架在未来行为预测和推荐等下游任务中表现优于特定任务的基线，并在存储和计算方面实现了效率提升。其统一的标记化框架能够与语言模型无缝集成，并支持工业规模的应用。

Abstract: Multi-source user representation learning plays a critical role in enabling
personalized services on web platforms (e.g., Alipay). While prior works have
adopted late-fusion strategies to combine heterogeneous data sources, they
suffer from three key limitations: lack of unified representation frameworks,
scalability and storage issues in data compression, and inflexible cross-task
generalization. To address these challenges, we propose U^2QT (Unified User
Quantized Tokenizers), a novel framework that integrates cross-domain knowledge
transfer with early fusion of heterogeneous domains. Our framework employs a
two-stage architecture: first, a causal Q-Former projects domain-specific
features into a shared causal representation space to preserve inter-modality
dependencies; second, a multi-view RQ-VAE discretizes causal embeddings into
compact tokens through shared and source-specific codebooks, enabling efficient
storage while maintaining semantic coherence. Experimental results showcase
U^2QT's advantages across diverse downstream tasks, outperforming task-specific
baselines in future behavior prediction and recommendation tasks while
achieving efficiency gains in storage and computation. The unified tokenization
framework enables seamless integration with language models and supports
industrial-scale applications.

</details>


### [652] [Mitigating Persistent Client Dropout in Asynchronous Decentralized Federated Learning](https://arxiv.org/abs/2508.01807)
*Ignacy Stępka,Nicholas Gisolfi,Kacper Trębacz,Artur Dubrawski*

Main category: cs.LG

TL;DR: 为解决异步去中心化联邦学习中的客户端掉线问题，提出一种基于客户端重构的自适应策略，有效提高了模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 异步和去中心化联邦学习中，客户端掉线会模糊模型更新信息，导致难以从掉线中恢复，并且难以精确重构缺失的邻居损失函数。

Method: 提出基于客户端重构的自适应策略来解决异步去中心化联邦学习中的客户端掉线问题。

Result: 实验表明，所提出的自适应策略能有效恢复部分因客户端掉线造成的性能损失，并能有效维持联邦学习的鲁棒性。

Conclusion: 该研究提出了一种基于客户端重构的自适应策略，以有效恢复因客户端掉线造成的性能损失，提高了联邦学习的鲁棒性，尽管该方法并未精确重构缺失客户端的数据。

Abstract: We consider the problem of persistent client dropout in asynchronous
Decentralized Federated Learning (DFL). Asynchronicity and decentralization
obfuscate information about model updates among federation peers, making
recovery from a client dropout difficult. Access to the number of learning
epochs, data distributions, and all the information necessary to precisely
reconstruct the missing neighbor's loss functions is limited. We show that
obvious mitigations do not adequately address the problem and introduce
adaptive strategies based on client reconstruction. We show that these
strategies can effectively recover some performance loss caused by dropout. Our
work focuses on asynchronous DFL with local regularization and differs
substantially from that in the existing literature. We evaluate the proposed
methods on tabular and image datasets, involve three DFL algorithms, and three
data heterogeneity scenarios (iid, non-iid, class-focused non-iid). Our
experiments show that the proposed adaptive strategies can be effective in
maintaining robustness of federated learning, even if they do not reconstruct
the missing client's data precisely. We also discuss the limitations and
identify future avenues for tackling the problem of client dropout.

</details>


### [653] [Small sample-based adaptive text classification through iterative and contrastive description refinement](https://arxiv.org/abs/2508.00957)
*Amrit Rajeev,Udayaadithya Avadhanam,Harshula Tulapurkar,SaiBarath Sundar*

Main category: cs.LG

TL;DR: 零样本文本分类框架结合迭代主题细化、对比提示和主动学习，通过人机交互有效处理动态领域中的模糊类别，在AGNews和DBpedia上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 零样本文本分类在知识不断演化和类别边界模糊的领域（如票务系统）仍然是一个难题。大型语言模型（LLMs）在这些场景下往往难以泛化，因为主题可分离性有限，而少样本方法受限于数据多样性不足。

Method: 该框架结合了迭代式主题细化、对比提示和主动学习。模型首先使用少量标注样本生成初始主题标签。然后，通过迭代式对比提示过程，利用错分或模糊的样本来优化类别区分，明确教会模型区分紧密相关的类别。该框架还包含一个“人在回路”组件，允许用户用自然语言引入或修改类别定义。

Result: 在AGNews和DBpedia数据集上的评估显示了强大的性能：在AGNews上准确率为91%（3个已知类别，1个未知类别），在DBpedia上准确率为84%（8个已知类别，1个未知类别）。引入未知类别后，准确性仅有微小下降（分别为82%和87%）。

Conclusion: 所提出的框架通过迭代式主题细化、对比提示和主动学习，有效解决了零样本文本分类的挑战，特别是在具有模糊类别边界的领域。通过结合人工反馈和自然语言交互，该框架能够无缝集成新类别且无需重新训练，在AGNews和DBpedia数据集上均取得了优异的性能，准确率分别为91%和84%，并在引入新类别后保持了高水平的准确性。

Abstract: Zero-shot text classification remains a difficult task in domains with
evolving knowledge and ambiguous category boundaries, such as ticketing
systems. Large language models (LLMs) often struggle to generalize in these
scenarios due to limited topic separability, while few-shot methods are
constrained by insufficient data diversity. We propose a classification
framework that combines iterative topic refinement, contrastive prompting, and
active learning. Starting with a small set of labeled samples, the model
generates initial topic labels. Misclassified or ambiguous samples are then
used in an iterative contrastive prompting process to refine category
distinctions by explicitly teaching the model to differentiate between closely
related classes. The framework features a human-in-the-loop component, allowing
users to introduce or revise category definitions in natural language. This
enables seamless integration of new, unseen categories without retraining,
making the system well-suited for real-world, dynamic environments. The
evaluations on AGNews and DBpedia demonstrate strong performance: 91% accuracy
on AGNews (3 seen, 1 unseen class) and 84% on DBpedia (8 seen, 1 unseen), with
minimal accuracy shift after introducing unseen classes (82% and 87%,
respectively). The results highlight the effectiveness of prompt-based semantic
reasoning for fine-grained classification with limited supervision.

</details>


### [654] [Enhancing material behavior discovery using embedding-oriented Physically-Guided Neural Networks with Internal Variables](https://arxiv.org/abs/2508.00959)
*Rubén Muñoz-Sierra,Manuel Doblaré,Jacobo Ayensa-Jiménez*

Main category: cs.LG

TL;DR: 为解决物理引导神经网络（PGNNIV）在高维数据中的可扩展性问题，本文引入了降阶建模和迁移学习等技术，通过改进解码器和模型重用，有效提高了计算效率和模型性能，并成功应用于非线性扩散方程的案例。


<details>
  <summary>Details</summary>
Motivation: 解决现有的PGNNIV框架在应用于高维数据（如精细网格空间场或时变系统）时面临的可扩展性挑战，同时利用其在仅使用可观测数据进行训练和揭示内部状态关系方面的潜力。

Method: 通过引入基于谱分解、POD和预训练自编码器映射的替代解码器结构，以及集成模型重用（迁移学习和微调策略）来增强PGNNIV框架，以应对高维数据和时变系统的可扩展性挑战。

Result: 增强的PGNNIV框架成功识别了非线性扩散方程控制下的本构状态方程，同时保持了高预测精度，提高了对噪声的鲁棒性，缓解了过拟合，并降低了计算需求。

Conclusion: 增强的PGNNIV框架通过采用降阶建模技术，成功克服了在高维数据应用中的可扩展性挑战，同时保持了高预测精度，提高了对噪声的鲁棒性，并减少了计算需求。

Abstract: Physically Guided Neural Networks with Internal Variables are SciML tools
that use only observable data for training and and have the capacity to unravel
internal state relations. They incorporate physical knowledge both by
prescribing the model architecture and using loss regularization, thus endowing
certain specific neurons with a physical meaning as internal state variables.
Despite their potential, these models face challenges in scalability when
applied to high-dimensional data such as fine-grid spatial fields or
time-evolving systems. In this work, we propose some enhancements to the PGNNIV
framework that address these scalability limitations through reduced-order
modeling techniques. Specifically, we introduce alternatives to the original
decoder structure using spectral decomposition, POD, and pretrained
autoencoder-based mappings. These surrogate decoders offer varying trade-offs
between computational efficiency, accuracy, noise tolerance, and
generalization, while improving drastically the scalability. Additionally, we
integrate model reuse via transfer learning and fine-tuning strategies to
exploit previously acquired knowledge, supporting efficient adaptation to novel
materials or configurations, and significantly reducing training time while
maintaining or improving model performance. To illustrate these various
techniques, we use a representative case governed by the nonlinear diffusion
equation, using only observable data. Results demonstrate that the enhanced
PGNNIV framework successfully identifies the underlying constitutive state
equations while maintaining high predictive accuracy. It also improves
robustness to noise, mitigates overfitting, and reduces computational demands.
The proposed techniques can be tailored to various scenarios depending on data
availability, resources, and specific modeling objectives, overcoming
scalability challenges in all the scenarios.

</details>


### [655] [Communication and Computation Efficient Split Federated Learning in O-RAN](https://arxiv.org/abs/2508.02534)
*Shunxian Gu,Chaoqun You,Bangbang Ren,Deke Guo*

Main category: cs.LG

TL;DR: SplitMe框架通过互学习和优化的资源分配解决了O-RAN中SFL的通信成本和收敛性问题，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: O-RAN的SFL部署面临两个挑战：(i)频繁的数据/梯度传输导致通信成本高；(ii)计算和通信资源的正确分配对于满足截止日期和SFL收敛至关重要。

Method: 提出了一种名为SplitMe的SFL框架，该框架利用互学习来交替和独立地训练near-RT-RIC的模型和non-RT-RIC的逆模型，从而消除了频繁的数据/梯度传输。通过零阶技术推导出逆模型的逆模型，以整合最终模型。然后，通过联合优化问题来最小化整体资源成本，并实现了截止日期感知的near-RT-RIC选择和自适应本地更新。

Result: SplitMe框架在成本和收敛性方面显著优于FL框架，如SFL、FedAvg和O-RANFed。

Conclusion: SplitMe框架通过利用互学习来交替和独立地训练near-RT-RIC的模型和non-RT-RIC的逆模型，消除了频繁传输，并通过联合优化解决了计算和通信资源分配问题，以最小化整体资源成本，并能感知截止日期地选择near-RT-RIC和自适应本地更新。数值结果表明，SplitMe在成本和收敛性方面显著优于SFL、FedAvg和O-RANFed等FL框架。

Abstract: The hierarchical architecture of Open Radio Access Network (O-RAN) has
enabled a new Federated Learning (FL) paradigm that trains models using data
from non- and near-real-time (near-RT) Radio Intelligent Controllers (RICs).
However, the ever-increasing model size leads to longer training time,
jeopardizing the deadline requirements for both non-RT and near-RT RICs. To
address this issue, split federated learning (SFL) offers an approach by
offloading partial model layers from near-RT-RIC to high-performance
non-RT-RIC. Nonetheless, its deployment presents two challenges: (i) Frequent
data/gradient transfers between near-RT-RIC and non-RT-RIC in SFL incur
significant communication cost in O-RAN. (ii) Proper allocation of
computational and communication resources in O-RAN is vital to satisfying the
deadline and affects SFL convergence. Therefore, we propose SplitMe, an SFL
framework that exploits mutual learning to alternately and independently train
the near-RT-RIC's model and the non-RT-RIC's inverse model, eliminating
frequent transfers. The ''inverse'' of the inverse model is derived via a
zeroth-order technique to integrate the final model. Then, we solve a joint
optimization problem for SplitMe to minimize overall resource costs with
deadline-aware selection of near-RT-RICs and adaptive local updates. Our
numerical results demonstrate that SplitMe remarkably outperforms FL frameworks
like SFL, FedAvg and O-RANFed regarding costs and convergence.

</details>


### [656] [FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph](https://arxiv.org/abs/2508.00961)
*Xiang Li,Penglei Sun,Wanyun Zhou,Zikai Wei,Yongqi Zhang,Xiaowen Chu*

Main category: cs.LG

TL;DR: 本研究透過 FinKario 和 FinKario-RAG 解決了金融知識整合和檢索的挑戰，大幅提升了股票趨勢預測的準確性。


<details>
  <summary>Details</summary>
Motivation: 個人投資者在金融市場中處於弱勢地位，面臨資訊過載和缺乏專業分析的挑戰。雖然金融市場中的股票研究報告提供了寶貴的見解，但現有知識庫更新緩慢以及金融報告的長篇幅和非結構化特性限制了大型語言模型（LLM）的有效性。本研究旨在透過整合即時市場事件和優化數據檢索來解決這些問題，以增強投資者的決策能力。

Method: 本研究提出了事件增強式金融知識圖譜自動構建（FinKario）方法，創建了一個包含超過 305,360 個實體、9,625 個關係三元組和 19 種不同關係類型的數據集。FinKario 透過由專業機構模板引導的提示驅動提取，自動整合即時公司基本面和市場事件，為大型語言模型提供結構化且易於獲取的金融見解。此外，研究還提出了一種兩階段基於圖的檢索策略（FinKario-RAG），以優化不斷發展的大規模金融知識的檢索，確保高效準確的數據訪問。

Result: FinKario 數據集包含超過 305,360 個實體、9,625 個關係三元組和 19 種不同的關係類型。FinKario-RAG 檢索策略與 FinKario 結合使用，在股票趨勢預測任務中取得了優於金融大型語言模型和機構策略的表現。

Conclusion: FinKario 搭配 FinKario-RAG 在回測中實現了卓越的股票趨勢預測準確性，平均而言，其表現分別優於金融大型語言模型 18.81% 和機構策略 17.85%。

Abstract: Individual investors are significantly outnumbered and disadvantaged in
financial markets, overwhelmed by abundant information and lacking professional
analysis. Equity research reports stand out as crucial resources, offering
valuable insights. By leveraging these reports, large language models (LLMs)
can enhance investors' decision-making capabilities and strengthen financial
analysis. However, two key challenges limit their effectiveness: (1) the rapid
evolution of market events often outpaces the slow update cycles of existing
knowledge bases, (2) the long-form and unstructured nature of financial reports
further hinders timely and context-aware integration by LLMs. To address these
challenges, we tackle both data and methodological aspects. First, we introduce
the Event-Enhanced Automated Construction of Financial Knowledge Graph
(FinKario), a dataset comprising over 305,360 entities, 9,625 relational
triples, and 19 distinct relation types. FinKario automatically integrates
real-time company fundamentals and market events through prompt-driven
extraction guided by professional institutional templates, providing structured
and accessible financial insights for LLMs. Additionally, we propose a
Two-Stage, Graph-Based retrieval strategy (FinKario-RAG), optimizing the
retrieval of evolving, large-scale financial knowledge to ensure efficient and
precise data access. Extensive experiments show that FinKario with FinKario-RAG
achieves superior stock trend prediction accuracy, outperforming financial LLMs
by 18.81% and institutional strategies by 17.85% on average in backtesting.

</details>


### [657] [Rethinking Multimodality: Optimizing Multimodal Deep Learning for Biomedical Signal Classification](https://arxiv.org/abs/2508.00963)
*Timothy Oladunni,Alex Wong*

Main category: cs.LG

TL;DR: 并非所有模态的融合都有利，最优的模态融合依赖于特征的互补性而非数量。


<details>
  <summary>Details</summary>
Motivation: 为了验证多模态深度学习中，增加模态数量是否总能提升模型性能。研究旨在探索互补特征域在多模态生物医学信号分析中的作用，挑战了融合多个域就能提升准确性的传统假设。

Method: 设计并评估了五种深度学习模型：三种单模态模型（1D-CNN、2D-CNN、1D-CNN-Transformer）和两种多模态模型（Hybrid 1：融合1D-CNN和2D-CNN；Hybrid 2：融合1D-CNN、2D-CNN和Transformer）。通过ECG分类任务，利用自助法和贝叶斯推断，证明了Hybrid 1优于2D-CNN基线，而Hybrid 2并未带来进一步提升，甚至略有下降，表明存在冗余。

Result: Hybrid 1（时间域和时频域融合）一致优于2D-CNN基线（p < 0.05, 贝叶斯概率 > 0.90），证实了时间域和时频域的协同互补性。Hybrid 2（加入频域）的性能无进一步提升，甚至略有下降，表明频域信息存在冗余。

Conclusion: 本研究提出了一种新的多模态深度学习方法，用于生物医学信号分类，并系统地分析了互补特征域如何影响模型性能。研究结果表明，并非所有模态的融合都有利，最优的模态融合依赖于特征的互补性而非数量。

Abstract: This study proposes a novel perspective on multimodal deep learning for
biomedical signal classification, systematically analyzing how complementary
feature domains impact model performance. While fusing multiple domains often
presumes enhanced accuracy, this work demonstrates that adding modalities can
yield diminishing returns, as not all fusions are inherently advantageous. To
validate this, five deep learning models were designed, developed, and
rigorously evaluated: three unimodal (1D-CNN for time, 2D-CNN for
time-frequency, and 1D-CNN-Transformer for frequency) and two multimodal
(Hybrid 1, which fuses 1D-CNN and 2D-CNN; Hybrid 2, which combines 1D-CNN,
2D-CNN, and a Transformer). For ECG classification, bootstrapping and Bayesian
inference revealed that Hybrid 1 consistently outperformed the 2D-CNN baseline
across all metrics (p-values < 0.05, Bayesian probabilities > 0.90), confirming
the synergistic complementarity of the time and time-frequency domains.
Conversely, Hybrid 2's inclusion of the frequency domain offered no further
improvement and sometimes a marginal decline, indicating representational
redundancy; a phenomenon further substantiated by a targeted ablation study.
This research redefines a fundamental principle of multimodal design in
biomedical signal analysis. We demonstrate that optimal domain fusion isn't
about the number of modalities, but the quality of their inherent
complementarity. This paradigm-shifting concept moves beyond purely heuristic
feature selection. Our novel theoretical contribution, "Complementary Feature
Domains in Multimodal ECG Deep Learning," presents a mathematically
quantifiable framework for identifying ideal domain combinations, demonstrating
that optimal multimodal performance arises from the intrinsic
information-theoretic complementarity among fused domains.

</details>


### [658] [VAULT: Vigilant Adversarial Updates via LLM-Driven Retrieval-Augmented Generation for NLI](https://arxiv.org/abs/2508.00965)
*Roie Kazoom,Ofir Cohen,Rami Puzis,Asaf Shabtai,Ofer Hadar*

Main category: cs.LG

TL;DR: VAULT是一个全自动化的对抗性RAG流水线，通过检索、生成和迭代再训练，提高了NLI模型在SNLI、ANLI和MultiNLI数据集上的准确率，并且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了系统地揭示和修复NLI模型中的弱点，并提高其鲁棒性。

Method: VAULT是一个全自动化的对抗性检索增强生成（RAG）流水线，包含三个阶段：检索、对抗性生成和迭代再训练。首先，通过嵌入具有语义（BGE）和词汇（BM25）相似性的前提来执行平衡的少样本检索。其次，将这些上下文组合成大型语言模型（LLM）提示，以生成对抗性假设，并由LLM合奏进行标签保真度验证。最后，将经验证的对抗性示例以递增的混合比例注入训练集，逐步加强零样本RoBERTa-base模型。

Result: 在标准基准测试中，VAULT将RoBERTa-base在SNLI上的准确率从88.48%提高到92.60%（+4.12%），在ANLI上从75.04%提高到80.95%（+5.91%），在MultiNLI上从54.67%提高到71.99%（+17.32%）。该方法在各种数据集上的表现持续优于先前的方法，最多可提高2.0%。

Conclusion: VAULT通过自动化大规模高质量对抗性数据策展，实现了自然语言推断（NLI）推理任务中快速、独立于人类的鲁棒性改进。

Abstract: We introduce VAULT, a fully automated adversarial RAG pipeline that
systematically uncovers and remedies weaknesses in NLI models through three
stages: retrieval, adversarial generation, and iterative retraining. First, we
perform balanced few-shot retrieval by embedding premises with both semantic
(BGE) and lexical (BM25) similarity. Next, we assemble these contexts into LLM
prompts to generate adversarial hypotheses, which are then validated by an LLM
ensemble for label fidelity. Finally, the validated adversarial examples are
injected back into the training set at increasing mixing ratios, progressively
fortifying a zero-shot RoBERTa-base model.On standard benchmarks, VAULT
elevates RoBERTa-base accuracy from 88.48% to 92.60% on SNLI +4.12%, from
75.04% to 80.95% on ANLI +5.91%, and from 54.67% to 71.99% on MultiNLI +17.32%.
It also consistently outperforms prior in-context adversarial methods by up to
2.0% across datasets. By automating high-quality adversarial data curation at
scale, VAULT enables rapid, human-independent robustness improvements in NLI
inference tasks.

</details>


### [659] [Masked Omics Modeling for Multimodal Representation Learning across Histopathology and Molecular Profiles](https://arxiv.org/abs/2508.00969)
*Lucas Robinet,Ahmad Berjaoui,Elizabeth Cohen-Jonathan Moyal*

Main category: cs.LG

TL;DR: MORPHEUS是一个统一的Transformer预训练框架，可以整合组织病理学和多组学数据，实现跨模态学习和任意组学生成，在肿瘤学任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管自监督学习在计算病理学方面取得了重大进展，但仅靠组织病理学往往不足以进行分子表征和理解临床结果，因为高维组学谱（如转录组学、甲基化组学或基因组学）中包含重要信息。

Method: MORPHEUS是一个统一的、基于Transformer的预训练框架，它将组织病理学和多组学数据编码到共享的潜在空间中。其核心是在随机选择的组学部分应用掩码建模目标，鼓励模型学习具有生物学意义的跨模态关系。

Result: MORPHEUS可应用于单独的组织病理学，或与任何组学模态子集结合，无缝适应可用输入。此外，MORPHEUS支持任意到任意组学生成，可从任何模态子集（包括单独的H&E）推断一个或多个组学谱。

Conclusion: MORPHEUS是一个有前景的框架，用于开发肿瘤学中的多模态基础模型，在各种模态组合和任务中始终优于最先进的方法。

Abstract: Self-supervised learning has driven major advances in computational pathology
by enabling models to learn rich representations from hematoxylin and eosin
(H&E)-stained cancer tissue. However, histopathology alone often falls short
for molecular characterization and understanding clinical outcomes, as
important information is contained in high-dimensional omics profiles like
transcriptomics, methylomics, or genomics. In this work, we introduce MORPHEUS,
a unified transformer-based pre-training framework that encodes both
histopathology and multi-omics data into a shared latent space. At its core,
MORPHEUS relies on a masked modeling objective applied to randomly selected
omics portions, encouraging the model to learn biologically meaningful
cross-modal relationships. The same pre-trained network can be applied to
histopathology alone or in combination with any subset of omics modalities,
seamlessly adapting to the available inputs. Additionally, MORPHEUS enables
any-to-any omics generation, enabling one or more omics profiles to be inferred
from any subset of modalities, including H&E alone. Pre-trained on a large
pan-cancer cohort, MORPHEUS consistently outperforms state-of-the-art methods
across diverse modality combinations and tasks, positioning itself as a
promising framework for developing multimodal foundation models in oncology.
The code is available at: https://github.com/Lucas-rbnt/MORPHEUS

</details>


### [660] [v-PuNNs: van der Put Neural Networks for Transparent Ultrametric Representation Learning](https://arxiv.org/abs/2508.01010)
*Gnankan Landry Regis N'guessan*

Main category: cs.LG

TL;DR: v-PuNNs are a novel deep learning architecture using p-adic numbers to handle hierarchical data, outperforming existing methods and offering broader applications.


<details>
  <summary>Details</summary>
Motivation: Conventional deep learning models struggle with strictly hierarchical data like taxa, word senses, or file systems because they embed data in Euclidean space, which is a poor fit. This work aims to provide a deep learning architecture that can effectively handle such hierarchical structures.

Method: The paper introduces van der Put Neural Networks (v-PuNNs), which use characteristic functions of p-adic balls in Z_p as neurons. It proposes the Transparent Ultrametric Representation Learning (TURL) principle where weights are p-adic numbers, enabling exact subtree semantics. A Finite Hierarchical Approximation Theorem shows that v-PuNNs can universally represent k-level trees. To address vanishing gradients, it proposes Valuation-Adaptive Perturbation Optimization (VAPO) with variants HiPaN-DS and HiPaN/Adam-VAPO.

Result: v-PuNNs achieve state-of-the-art results on three benchmarks: 99.96% leaf accuracy on WordNet nouns in 16 minutes, 96.9% leaf accuracy and 100% root accuracy on GO molecular-function in 50 seconds, and a Spearman rho of -0.96 with true taxonomic distance on NCBI Mammalia. The learned metric is perfectly ultrametric. The paper also derives structural invariants for quantum systems (HiPaQ) and controllable generative codes for tabular data (Tab-HiPaN).

Conclusion: v-PuNNs are the first architecture suitable for hierarchical data, bridging number theory and deep learning with exact, interpretable, and efficient models. They achieve state-of-the-art results on benchmarks and have applications beyond classification, such as in quantum systems and generative modeling.

Abstract: Conventional deep learning models embed data in Euclidean space
$\mathbb{R}^d$, a poor fit for strictly hierarchical objects such as taxa, word
senses, or file systems. We introduce van der Put Neural Networks (v-PuNNs),
the first architecture whose neurons are characteristic functions of p-adic
balls in $\mathbb{Z}_p$. Under our Transparent Ultrametric Representation
Learning (TURL) principle every weight is itself a p-adic number, giving exact
subtree semantics. A new Finite Hierarchical Approximation Theorem shows that a
depth-K v-PuNN with $\sum_{j=0}^{K-1}p^{\,j}$ neurons universally represents
any K-level tree. Because gradients vanish in this discrete space, we propose
Valuation-Adaptive Perturbation Optimization (VAPO), with a fast deterministic
variant (HiPaN-DS) and a moment-based one (HiPaN / Adam-VAPO). On three
canonical benchmarks our CPU-only implementation sets new state-of-the-art:
WordNet nouns (52,427 leaves) 99.96% leaf accuracy in 16 min; GO
molecular-function 96.9% leaf / 100% root in 50 s; NCBI Mammalia Spearman $\rho
= -0.96$ with true taxonomic distance. The learned metric is perfectly
ultrametric (zero triangle violations), and its fractal and
information-theoretic properties are analyzed. Beyond classification we derive
structural invariants for quantum systems (HiPaQ) and controllable generative
codes for tabular data (Tab-HiPaN). v-PuNNs therefore bridge number theory and
deep learning, offering exact, interpretable, and efficient models for
hierarchical data.

</details>


### [661] [On Some Tunable Multi-fidelity Bayesian Optimization Frameworks](https://arxiv.org/abs/2508.01013)
*Arjun Manoj,Anastasia S. Georgiou,Dimitris G. Giovanis,Themistoklis P. Sapsis,Ioannis G. Kevrekidis*

Main category: cs.LG

TL;DR: 通过邻近性获取策略和多保真度GP，改进了多保真度优化方法，在化学动力学模型优化中表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在改进基于GP的多保真度优化方法，通过简化保真度选择和结合多保真度GP来提高效率和鲁棒性。

Method: 提出了一种基于邻近性的获取策略，简化了多保真度高斯过程（GP）模型的保真度选择。同时，通过将多保真度GP与多保真度GP相结合，实现了多保真度上限置信界（UCB）策略。

Result: 邻近性获取策略在多保真度化学动力学模型（包括均相和非均相模型）的优化任务中，能够有效控制高保真度评估的使用，同时保持收敛效率，优于其他多保真度获取策略。

Conclusion: 邻近性方法在多保真度优化中具有潜力，可以有效地控制高保真度评估的使用，同时保持收敛效率。

Abstract: Multi-fidelity optimization employs surrogate models that integrate
information from varying levels of fidelity to guide efficient exploration of
complex design spaces while minimizing the reliance on (expensive)
high-fidelity objective function evaluations. To advance Gaussian Process
(GP)-based multi-fidelity optimization, we implement a proximity-based
acquisition strategy that simplifies fidelity selection by eliminating the need
for separate acquisition functions at each fidelity level. We also enable
multi-fidelity Upper Confidence Bound (UCB) strategies by combining them with
multi-fidelity GPs rather than the standard GPs typically used. We benchmark
these approaches alongside other multi-fidelity acquisition strategies
(including fidelity-weighted approaches) comparing their performance, reliance
on high-fidelity evaluations, and hyperparameter tunability in representative
optimization tasks. The results highlight the capability of the proximity-based
multi-fidelity acquisition function to deliver consistent control over
high-fidelity usage while maintaining convergence efficiency. Our illustrative
examples include multi-fidelity chemical kinetic models, both homogeneous and
heterogeneous (dynamic catalysis for ammonia production).

</details>


### [662] [Explaining GNN Explanations with Edge Gradients](https://arxiv.org/abs/2508.01048)
*Jesse He,Akbar Rafiey,Gal Mishne,Yusu Wang*

Main category: cs.LG

TL;DR: 本篇论文对GNN可解释性方法进行了理论分析，发现了不同方法间的联系，并提出了近似和等价关系，为选择和改进GNN解释方法提供了理论指导，并在实验中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 尽管图神经网络（GNNs）在图结构数据上取得了显著成功，但GNN可解释性领域仍处于不断发展中。现有的可解释性方法在不同比较中表现不一，且许多方法难以处理更复杂的GNN架构和任务。这表明迫切需要对竞争GNN解释方法进行更仔细的理论分析，以指导方法的选择和改进。

Method: 本研究通过理论分析，探讨了输入层级（解释输入图的子图）和层级（解释计算图的子图）两种GNN解释设置。具体方法包括建立扰动方法与梯度方法之间的理论联系，并指出其他近期方法的关联性。在输入层级，研究证明了在特定条件下GNNExplainer可以被基于边缘梯度符号的启发式方法近似。在层级设置中，研究发现边缘梯度等同于线性GNNs的遮挡搜索。最后，通过在合成和真实数据集上的实验验证了理论结果的实际应用效果。

Result: 研究建立了扰动方法与梯度方法之间的理论联系，并指出了其他近期方法的关联性。在输入层级，研究表明在特定条件下GNNExplainer可以被基于边缘梯度符号的启发式方法近似。在层级设置中，研究发现边缘梯度等同于线性GNNs的遮挡搜索。实验结果在合成和真实数据集上验证了这些理论发现的实际意义。

Conclusion: 本研究旨在通过理论分析来指导GNN可解释性方法的选择和改进。研究发现了扰动方法与梯度方法之间的理论联系，以及在特定条件下GNNExplainer可以被基于边缘梯度的符号启发式方法所近似。此外，在层级解释设置中，边缘梯度等同于线性GNNs的遮挡搜索。实验结果表明，这些理论发现能够指导实际应用。

Abstract: In recent years, the remarkable success of graph neural networks (GNNs) on
graph-structured data has prompted a surge of methods for explaining GNN
predictions. However, the state-of-the-art for GNN explainability remains in
flux. Different comparisons find mixed results for different methods, with many
explainers struggling on more complex GNN architectures and tasks. This
presents an urgent need for a more careful theoretical analysis of competing
GNN explanation methods. In this work we take a closer look at GNN explanations
in two different settings: input-level explanations, which produce explanatory
subgraphs of the input graph, and layerwise explanations, which produce
explanatory subgraphs of the computation graph. We establish the first
theoretical connections between the popular perturbation-based and classical
gradient-based methods, as well as point out connections between other recently
proposed methods. At the input level, we demonstrate conditions under which
GNNExplainer can be approximated by a simple heuristic based on the sign of the
edge gradients. In the layerwise setting, we point out that edge gradients are
equivalent to occlusion search for linear GNNs. Finally, we demonstrate how our
theoretical results manifest in practice with experiments on both synthetic and
real datasets.

</details>


### [663] [Centralized Adaptive Sampling for Reliable Co-Training of Independent Multi-Agent Policies](https://arxiv.org/abs/2508.01049)
*Nicholas E. Corrado,Josiah P. Hanna*

Main category: cs.LG

TL;DR: MA-PROPS是一种新的多智能体强化学习方法，通过改进动作采样来解决梯度估计不准确的问题，从而提高学习的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习（MARL）中，即使所有智能体的预期策略梯度都指向最优解，但有限轨迹收集后的独立动作采样随机性也会导致联合数据分布偏离预期的联合策略内分布，产生不准确的梯度估计，从而导致次优收敛。

Method: 提出了一种名为MA-PROPS（Multi-Agent Proximal Robust On-Policy Sampling）的自适应动作采样方法，该方法使用集中的行为策略，并持续调整该策略以增加对当前未充分采样的联合动作的概率。

Result: MA-PROPS相比标准的策略内采样能更有效地减少联合采样误差，并提高了独立策略梯度算法的可靠性。

Conclusion: MA-PROPS通过适应性地调整联合动作采样来减少联合采样误差，提高了独立策略梯度算法在多智能体强化学习中的可靠性，增加了收敛到最优联合策略的训练运行比例。

Abstract: Independent on-policy policy gradient algorithms are widely used for
multi-agent reinforcement learning (MARL) in cooperative and no-conflict games,
but they are known to converge suboptimally when each agent's policy gradient
points toward a suboptimal equilibrium. In this work, we identify a subtler
failure mode that arises \textit{even when the expected policy gradients of all
agents point toward an optimal solution.} After collecting a finite set of
trajectories, stochasticity in independent action sampling can cause the joint
data distribution to deviate from the expected joint on-policy distribution.
This \textit{sampling error} w.r.t. the joint on-policy distribution produces
inaccurate gradient estimates that can lead agents to converge suboptimally. In
this paper, we investigate if joint sampling error can be reduced through
coordinated action selection and whether doing so improves the reliability of
policy gradient learning in MARL. Toward this end, we introduce an adaptive
action sampling approach to reduce joint sampling error. Our method,
Multi-Agent Proximal Robust On-Policy Sampling (MA-PROPS), uses a centralized
behavior policy that we continually adapt to place larger probability on joint
actions that are currently under-sampled w.r.t. the current joint policy. We
empirically evaluate MA-PROPS in a diverse range of multi-agent games and
demonstrate that (1) MA-PROPS reduces joint sampling error more efficiently
than standard on-policy sampling and (2) improves the reliability of
independent policy gradient algorithms, increasing the fraction of training
runs that converge to an optimal joint policy.

</details>


### [664] [FGBench: A Dataset and Benchmark for Molecular Property Reasoning at Functional Group-Level in Large Language Models](https://arxiv.org/abs/2508.01055)
*Xuan Liu,Siru Ouyang,Xianrui Zhong,Jiawei Han,Huimin Zhao*

Main category: cs.LG

TL;DR: FGBench 是一个包含 62.5 万个官能团信息的分子属性推理问题的数据集，旨在提高 LLM 在化学任务中的推理能力，目前 LLM 在此数据集上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注分子层面属性预测，忽略了细粒度的官能团信息。然而，官能团信息可以提供有价值的先验知识，连接分子结构和文本描述，从而构建更具可解释性、感知结构并能执行分子相关任务推理的 LLM，并可能发现特定官能团与分子属性之间的隐藏关系，推动分子设计和药物发现。

Method: FGBench 数据集包含 62.5 万个具有官能团信息的分子属性推理问题，其中官能团被精确注释和定位，涵盖了单官能团影响、多官能团相互作用以及直接分子比较三个类别，用于回归和分类任务。

Result: 在对 7K 标注数据进行评估后，结果表明当前 LLM 在 FG 级别属性推理方面存在困难，凸显了增强 LLM 在化学任务中推理能力的需求。

Conclusion: FGBench 的方法为生成新的问答对提供了基础框架，使 LLM 能够更好地理解细粒度的分子结构-属性关系。

Abstract: Large language models (LLMs) have gained significant attention in chemistry.
However, most existing datasets center on molecular-level property prediction
and overlook the role of fine-grained functional group (FG) information.
Incorporating FG-level data can provide valuable prior knowledge that links
molecular structures with textual descriptions, which can be used to build more
interpretable, structure-aware LLMs for reasoning on molecule-related tasks.
Moreover, LLMs can learn from such fine-grained information to uncover hidden
relationships between specific functional groups and molecular properties,
thereby advancing molecular design and drug discovery. Here, we introduce
FGBench, a dataset comprising 625K molecular property reasoning problems with
functional group information. Functional groups are precisely annotated and
localized within the molecule, which ensures the dataset's interoperability
thereby facilitating further multimodal applications. FGBench includes both
regression and classification tasks on 245 different functional groups across
three categories for molecular property reasoning: (1) single functional group
impacts, (2) multiple functional group interactions, and (3) direct molecular
comparisons. In the benchmark of state-of-the-art LLMs on 7K curated data, the
results indicate that current LLMs struggle with FG-level property reasoning,
highlighting the need to enhance reasoning capabilities in LLMs for chemistry
tasks. We anticipate that the methodology employed in FGBench to construct
datasets with functional group-level information will serve as a foundational
framework for generating new question-answer pairs, enabling LLMs to better
understand fine-grained molecular structure-property relationships. The dataset
and evaluation code are available at
\href{https://github.com/xuanliugit/FGBench}{https://github.com/xuanliugit/FGBench}.

</details>


### [665] [The Lattice Geometry of Neural Network Quantization -- A Short Equivalence Proof of GPTQ and Babai's algorithm](https://arxiv.org/abs/2508.01077)
*Johann Birnick*

Main category: cs.LG

TL;DR: GPTQ量化等同于最近向量问题，GPTQ等同于最近平面算法，未来或可用格基约减改进量化。


<details>
  <summary>Details</summary>
Motivation: 解释数据驱动量化如何与解决特定格的最近向量问题相关联，并证明GPTQ算法的等价性。

Method: 将神经网络中的线性单元的数据驱动量化与求解特定格的最近向量问题相关联。

Result: 证明GPTQ算法等价于Babai的最近平面算法，并提供了几何直观解释，同时指出格基约减可能用于改进量化。

Conclusion: GPTQ算法等价于Babai的最近平面算法，并提供了两种算法的几何直观解释。

Abstract: We explain how data-driven quantization of a linear unit in a neural network
corresponds to solving the closest vector problem for a certain lattice
generated by input data. We prove that the GPTQ algorithm is equivalent to
Babai's well-known nearest-plane algorithm. We furthermore provide geometric
intuition for both algorithms. Lastly, we note the consequences of these
results, in particular hinting at the possibility for using lattice basis
reduction for better quantization.

</details>


### [666] [Flow Matching for Probabilistic Learning of Dynamical Systems from Missing or Noisy Data](https://arxiv.org/abs/2508.01101)
*Siddharth Rout,Eldad Haber,Stephane Gaudreault*

Main category: cs.LG

TL;DR: 该研究提出了一种新的概率预测方法，通过流匹配和生成式机器学习来处理动力系统中的不确定性和复杂性，并在天气预测等领域取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 由于存在缺失变量和噪声数据，利用机器学习技术学习动力系统存在挑战。传统的数学模型难以应对这些情况。随机机器学习技术通过对这些病态问题进行建模来解决这一挑战。

Method: 提出了一种流匹配的变体用于概率预测，并结合一种生成式机器学习方法来处理复杂高维动力系统的状态扰动。方法为所提出的方法建立了数学基础。

Result: 在包括 WeatherBench 数据集在内的多个具有挑战性的动力系统上，证明了所提出方法的有效性。

Conclusion: 该研究提出了一种流匹配的变体，用于概率预测，能够将未来状态估计为分布而非单点预测。同时，还提出了一种生成式机器学习方法，用于对复杂高维动力系统的状态进行物理和逻辑扰动。研究为所提出的方法建立了数学基础，并在包括 WeatherBench 数据集在内的多个具有挑战性的动力系统上进行了有效性验证。

Abstract: Learning dynamical systems is crucial across many fields, yet applying
machine learning techniques remains challenging due to missing variables and
noisy data. Classical mathematical models often struggle in these scenarios due
to the arose ill-posedness of the physical systems. Stochastic machine learning
techniques address this challenge by enabling the modeling of such ill-posed
problems. Thus, a single known input to the trained machine learning model may
yield multiple plausible outputs, and all of the outputs are correct. In such
scenarios, probabilistic forecasting is inherently meaningful. In this study,
we introduce a variant of flow matching for probabilistic forecasting which
estimates possible future states as a distribution over possible outcomes
rather than a single-point prediction. Perturbation of complex dynamical states
is not trivial. Community uses typical Gaussian or uniform perturbations to
crucial variables to model uncertainty. However, not all variables behave in a
Gaussian fashion. So, we also propose a generative machine learning approach to
physically and logically perturb the states of complex high-dimensional
dynamical systems. Finally, we establish the mathematical foundations of our
method and demonstrate its effectiveness on several challenging dynamical
systems, including a variant of the high-dimensional WeatherBench dataset,
which models the global weather at a 5.625{\deg} meridional resolution.

</details>


### [667] [Protecting Student Mental Health with a Context-Aware Machine Learning Framework for Stress Monitoring](https://arxiv.org/abs/2508.01105)
*Md Sultanul Islam Ovi,Jamal Hossain,Md Raihan Alam Rahi,Fatema Akter*

Main category: cs.LG

TL;DR: 该研究提出了一种机器学习框架，通过分析心理、学业、环境和社会因素来检测学生压力，并在两个数据集上取得了超过 93% 的准确率，有望为早期干预提供支持。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法依赖于主观调查和定期评估，在及时干预方面的价值有限，而学生心理健康已成为学术机构日益增长的关注点，压力会严重影响学生的福祉和学业表现。

Method: 该研究引入了一个上下文感知机器学习框架，用于使用两个互补的、基于调查的数据集对学生压力进行分类。该框架包括一个六阶段流程：预处理、特征选择（SelectKBest, RFECV）、降维（PCA）以及使用六个基础分类器（SVM、随机森林、梯度提升、XGBoost、AdaBoost 和 Bagging）进行训练。为了提高性能，研究采用了集成策略，包括硬投票、软投票、加权投票和堆叠。

Result: 研究中的最佳模型在“学生压力因素”数据集上使用加权硬投票达到了 93.09% 的准确率，在“压力与福祉”数据集上使用堆叠达到了 99.53% 的准确率，超过了之前的基准。

Conclusion: 研究结果表明，结合上下文的、数据驱动的系统在早期检测学生压力方面具有巨大潜力，并且适用于现实世界的学术环境，以支持学生的福祉。

Abstract: Student mental health is an increasing concern in academic institutions,
where stress can severely impact well-being and academic performance.
Traditional assessment methods rely on subjective surveys and periodic
evaluations, offering limited value for timely intervention. This paper
introduces a context-aware machine learning framework for classifying student
stress using two complementary survey-based datasets covering psychological,
academic, environmental, and social factors. The framework follows a six-stage
pipeline involving preprocessing, feature selection (SelectKBest, RFECV),
dimensionality reduction (PCA), and training with six base classifiers: SVM,
Random Forest, Gradient Boosting, XGBoost, AdaBoost, and Bagging. To enhance
performance, we implement ensemble strategies, including hard voting, soft
voting, weighted voting, and stacking. Our best models achieve 93.09% accuracy
with weighted hard voting on the Student Stress Factors dataset and 99.53% with
stacking on the Stress and Well-being dataset, surpassing previous benchmarks.
These results highlight the potential of context-integrated, data-driven
systems for early stress detection and underscore their applicability in
real-world academic settings to support student well-being.

</details>


### [668] [A hierarchy tree data structure for behavior-based user segment representation](https://arxiv.org/abs/2508.01115)
*Yang Liu,Xuejiao Kang,Sathya Iyer,Idris Malik,Ruixuan Li,Juan Wang,Xinchen Lu,Xiangxue Zhao,Dayong Wang,Menghan Liu,Isaac Liu,Feng Liang,Yinzhe Yu*

Main category: cs.LG

TL;DR: This paper introduces Behavior-based User Segmentation (BUS), a tree-based structure that segments users by their behavior and attributes to improve recommendations, especially for new users. It uses NDCG to optimize segments and incorporates social connections for fairness. Deployed in production, BUS significantly improved ranking quality and online metrics like music ranking and email notifications.


<details>
  <summary>Details</summary>
Motivation: User attributes are essential for recommendation systems, particularly for mitigating the cold-start problem and enhancing the experience of new or infrequent users. The paper aims to improve recommendation quality by effectively segmenting users based on their attributes and engagement behaviors.

Method: The paper proposes Behavior-based User Segmentation (BUS), a novel tree-based data structure that hierarchically segments users based on their product-specific engagement behaviors and categorical attributes. NDCG is used as the objective function during BUS tree construction to maximize the behavioral representativeness of marginal users relative to active users. The BUS tree undergoes further processing and aggregation across nodes to generate popular social content and behavioral patterns. To mitigate bias and improve fairness, user attributes are derived from the social graph to create connection-based BUS segments, enabling connection-aware BUS-based recommendation by combining behavioral patterns from both user's own and connection-based segments. The approach utilizes a list-wise learning-to-rank framework.

Result: Offline analysis shows that BUS-based retrieval significantly outperforms traditional user cohort-based aggregation on ranking quality. Online A/B testing with production traffic serving billions of users daily demonstrated statistically significant improvements in online product metrics, including music ranking and email notifications.

Conclusion: BUS-based retrieval significantly outperforms traditional user cohort-based aggregation on ranking quality and achieves statistically significant improvements in online product metrics, including music ranking and email notifications, after deployment and testing with various production traffic serving billions of users daily. It represents the first list-wise learning-to-rank framework for tree-based recommendation that effectively integrates diverse user categorical attributes while preserving real-world semantic interpretability at a large industrial scale.

Abstract: User attributes are essential in multiple stages of modern recommendation
systems and are particularly important for mitigating the cold-start problem
and improving the experience of new or infrequent users. We propose
Behavior-based User Segmentation (BUS), a novel tree-based data structure that
hierarchically segments the user universe with various users' categorical
attributes based on the users' product-specific engagement behaviors. During
the BUS tree construction, we use Normalized Discounted Cumulative Gain (NDCG)
as the objective function to maximize the behavioral representativeness of
marginal users relative to active users in the same segment. The constructed
BUS tree undergoes further processing and aggregation across the leaf nodes and
internal nodes, allowing the generation of popular social content and
behavioral patterns for each node in the tree. To further mitigate bias and
improve fairness, we use the social graph to derive the user's connection-based
BUS segments, enabling the combination of behavioral patterns extracted from
both the user's own segment and connection-based segments as the connection
aware BUS-based recommendation. Our offline analysis shows that the BUS-based
retrieval significantly outperforms traditional user cohort-based aggregation
on ranking quality. We have successfully deployed our data structure and
machine learning algorithm and tested it with various production traffic
serving billions of users daily, achieving statistically significant
improvements in the online product metrics, including music ranking and email
notifications. To the best of our knowledge, our study represents the first
list-wise learning-to-rank framework for tree-based recommendation that
effectively integrates diverse user categorical attributes while preserving
real-world semantic interpretability at a large industrial scale.

</details>


### [669] [Transformers in Pseudo-Random Number Generation: A Dual Perspective on Theory and Practice](https://arxiv.org/abs/2508.01134)
*Ran Li,Lingshu Zeng*

Main category: cs.LG

TL;DR: Transformers can be used to generate pseudo-random numbers (PRNGs) that pass statistical tests, by simulating existing PRNGs like LCG and MT.


<details>
  <summary>Details</summary>
Motivation: PRNGs are crucial for large language models due to their high-nonlinearity. Transformers, known for handling complex nonlinear relationships, are explored as a potential method for generating high-quality pseudo-random numbers.

Method: The paper theoretically demonstrates that decoder-only Transformer models with Chain-of-Thought can simulate LCG and MT PRNGs. This is validated through experiments, assessing the performance of Transformer-based PRNGs using NIST tests and analyzing their behavior in prediction attacks.

Result: Transformer-based PRNGs successfully pass the majority of NIST tests, exhibiting clear statistical randomness in their heat maps. The theoretical findings regarding the representation of non-uniform AC^0 are also validated.

Conclusion: Transformer-based PRNGs can simulate LCG and MT, represent non-uniform AC^0, pass most NIST tests, and show statistical randomness, but their capability in prediction attacks needs further assessment.

Abstract: Pseudo-random number generators (PRNGs) are high-nonlinear processes, and
they are key blocks in optimization of Large language models. Transformers
excel at processing complex nonlinear relationships. Thus it is reasonable to
generate high-quality pseudo-random numbers based on transformers. In this
paper, we explore this question from both theoretical and practical
perspectives, highlighting the potential benefits and implications of
Transformer in PRNGs. We theoretically demonstrate that decoder-only
Transformer models with Chain-of-Thought can simulate both the Linear
Congruential Generator (LCG) and Mersenne Twister (MT) PRNGs. Based on this, we
conclude that the log-precision decoder-only Transformer can represent
non-uniform $\text{AC}^0$. Our simulative theoretical findings are validated
through experiments. The random numbers generated by Transformer-based PRNGs
successfully pass the majority of NIST tests, whose heat maps exhibit clear
statistical randomness. Finally, we assess their capability in prediction
attacks.

</details>


### [670] [DisTaC: Conditioning Task Vectors via Distillation for Robust Model Merging](https://arxiv.org/abs/2508.01148)
*Kotaro Yoshida,Yuji Naraki,Takafumi Horie,Ryotaro Shimizu,Hiroki Naganuma*

Main category: cs.LG

TL;DR: DisTaC通过知识蒸馏预处理任务向量，解决了模型合并中因任务向量范数差异和源模型置信度低而导致的脆弱性问题，并在实际场景中提升了合并效果。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并技术通常在有利于模型合并的基准测试中进行评估，但在更实际环境中的鲁棒性仍未得到充分探索。该研究旨在揭示模型合并方法的脆弱性，并确定对合并过程有害的源模型特征。

Method: DisTaC（Distillation for Task vector Conditioning）是一种新的方法，它通过利用知识蒸馏来预处理有问题的任务向量，以调整任务向量的范数并提高源模型的置信度，同时保留其关键的任务特定知识。

Result: 实验证明，使用DisTaC进行预处理可以成功整合通常难以合并的模型，并显著提高性能。

Conclusion: 通过预处理任务向量，DisTaC能够成功整合具有有害特征的模型，从而在模型合并技术通常会失败的情况下取得显著的性能提升。

Abstract: Model merging has emerged as an efficient and flexible paradigm for
multi-task learning, with numerous methods being proposed in recent years.
However, these state-of-the-art techniques are typically evaluated on benchmark
suites that are highly favorable to model merging, and their robustness in more
realistic settings remains largely unexplored. In this work, we first
investigate the vulnerabilities of model-merging methods and pinpoint the
source-model characteristics that critically underlie them. Specifically, we
identify two factors that are particularly harmful to the merging process: (1)
disparities in task vector norms, and (2) the low confidence of the source
models. To address this issue, we propose DisTaC (Distillation for Task vector
Conditioning), a novel method that pre-conditions these problematic task
vectors before the merge. DisTaC leverages knowledge distillation to adjust a
task vector's norm and increase source-model confidence while preserving its
essential task-specific knowledge. Our extensive experiments demonstrate that
by pre-conditioning task vectors with DisTaC, state-of-the-art merging
techniques can successfully integrate models exhibiting the harmful traits --
where they would otherwise fail -- achieving significant performance gains.

</details>


### [671] [T2S: Tokenized Skill Scaling for Lifelong Imitation Learning](https://arxiv.org/abs/2508.01167)
*Hongquan Zhang,Jingyu Gong,Zhizhong Zhang,Xin Tan,Yanyun Qu,Yuan Xie*

Main category: cs.LG

TL;DR: T2S是一种新的终身模仿学习框架，通过标记化和语言引导的技能扩展来解决灾难性遗忘和新技能学习的挑战，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前终身模仿学习方法在缓解灾难性遗忘和学习新技能之间难以取得平衡，并且通常孤立地处理这两个方面，忽略了它们之间的内在联系。

Method: T2S框架通过参数标记化，将Transformer的线性参数映射转换为输入和可学习标记之间的交叉注意力，从而增强了模型的可扩展性；引入了语言引导的技能扩展，以高效地跨任务迁移知识并避免参数线性增长。

Result: T2S在LIBERO任务套件上实现了1.0%的平均NBT（防止灾难性遗忘），在终身任务中仅需8.0%的可训练标记（技能扩展），并实现了77.7%的平均FWT（跨任务知识迁移）。

Conclusion: T2S框架有效地防止了灾难性遗忘，在技能扩展方面表现出色，并实现了高效的跨任务知识迁移，为终身模仿学习提供了有前景的解决方案。

Abstract: The main challenge in lifelong imitation learning lies in the balance between
mitigating catastrophic forgetting of previous skills while maintaining
sufficient capacity for acquiring new ones. However, current approaches
typically address these aspects in isolation, overlooking their internal
correlation in lifelong skill acquisition. We address this limitation with a
unified framework named Tokenized Skill Scaling (T2S). Specifically, by
tokenizing the model parameters, the linear parameter mapping of the
traditional transformer is transformed into cross-attention between input and
learnable tokens, thereby enhancing model scalability through the easy
extension of new tokens. Additionally, we introduce language-guided skill
scaling to transfer knowledge across tasks efficiently and avoid linearly
growing parameters. Extensive experiments across diverse tasks demonstrate that
T2S: 1) effectively prevents catastrophic forgetting (achieving an average NBT
of 1.0% across the three LIBERO task suites), 2) excels in new skill scaling
with minimal increases in trainable parameters (needing only 8.0% trainable
tokens in an average of lifelong tasks), and 3) enables efficient knowledge
transfer between tasks (achieving an average FWT of 77.7% across the three
LIBERO task suites), offering a promising solution for lifelong imitation
learning.

</details>


### [672] [RSPO: Risk-Seeking Policy Optimization for Pass@k and Max@k Metrics in Large Language Models](https://arxiv.org/abs/2508.01174)
*Kaichen Zhang,Shenghao Gao,Yuzhong Hong,Haipeng Sun,Junwei Bao,Hongfei Jiang,Yang Song,Hong Dingqian,Hui Xiong*

Main category: cs.LG

TL;DR: LLM training objective mismatch with evaluation metrics identified. Proposed RSPO to optimize risk-seeking metrics (Pass@k, Max@k) directly. Solved 'hitchhiking' problem with new gradient estimators. Validated by theory and experiments.


<details>
  <summary>Details</summary>
Motivation: Current large language model post-training optimizes a risk-neutral objective that maximizes expected reward, yet evaluation relies heavily on risk-seeking metrics like Pass@k and Max@k. This mismatch in risk preferences can lead to suboptimal performance.

Method: RSPO leverages the closed-form probability that a given response is the maximum among k samplings to address the "hitchhiking" problem, producing efficient, unbiased gradient estimators for both Pass@k and Max@k metrics despite the complexity of nested gradients over multiple responses.

Result: RSPO has been validated with rigorous theoretical analysis and comprehensive experimental results, demonstrating its effectiveness in improving large language model performance by directly optimizing risk-seeking metrics.

Conclusion: The proposed Risk-Seeking Policy Optimization (RSPO) method directly targets risk-seeking metrics like Pass@k and Max@k during training, bridging the gap between post-training optimization and evaluation. RSPO effectively addresses the 

Abstract: Current large language model post-training optimizes a risk-neutral objective
that maximizes expected reward, yet evaluation relies heavily on risk-seeking
metrics like Pass@k (at least one success in k trials) and Max@k (maximum
reward across k responses). This mismatch in risk preferences can inevitably
lead to suboptimal performance. To bridge this gap, we propose Risk-Seeking
Policy Optimization (RSPO), a novel method that directly targets Pass@k and
Max@k during training. A key challenge in optimizing these metrics is the
"hitchhiking" problem: low-reward responses are inadvertently reinforced if
they co-occur with a high-reward response within a sample of k generations,
resulting in inefficient optimization. RSPO addresses this problem by
leveraging the closed-form probability that a given response is the maximum
among k samplings. Despite the complexity of nested gradients over multiple
responses, RSPO produces efficient, unbiased gradient estimators for both
metrics. We validate our approach with both rigorous theoretical analysis and
comprehensive experimental results.

</details>


### [673] [SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy](https://arxiv.org/abs/2508.01188)
*Zhuo Yang,Jiaqing Xie,Shuaike Shen,Daolang Wang,Yeyun Chen,Ben Gao,Shuzhou Sun,Biqing Qi,Dongzhan Zhou,Lei Bai,Linjiang Chen,Shufei Zhang,Jun Jiang,Tianfan Fu,Yuqiang Li*

Main category: cs.LG

TL;DR: SpectrumLab是一个统一的平台，用于系统化和加速光谱学深度学习研究，包含工具库、数据标注模块和基准套件，旨在解决标准化问题并评估现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在光谱学领域研究和评估缺乏标准化方案的问题。

Method: SpectrumLab平台，包含数据处理和评估工具库、SpectrumAnnotator模块和SpectrumBench基准套件，用于光谱学深度学习研究。

Result: 通过在SpectrumBench上对18个前沿的多模态大语言模型进行实证研究，揭示了当前方法的局限性。

Conclusion: SpectrumLab有望成为推动光谱学深度学习领域未来发展的关键基础。

Abstract: Deep learning holds immense promise for spectroscopy, yet research and
evaluation in this emerging field often lack standardized formulations. To
address this issue, we introduce SpectrumLab, a pioneering unified platform
designed to systematize and accelerate deep learning research in spectroscopy.
SpectrumLab integrates three core components: a comprehensive Python library
featuring essential data processing and evaluation tools, along with
leaderboards; an innovative SpectrumAnnotator module that generates
high-quality benchmarks from limited seed data; and SpectrumBench, a
multi-layered benchmark suite covering 14 spectroscopic tasks and over 10
spectrum types, featuring spectra curated from over 1.2 million distinct
chemical substances. Thorough empirical studies on SpectrumBench with 18
cutting-edge multimodal LLMs reveal critical limitations of current approaches.
We hope SpectrumLab will serve as a crucial foundation for future advancements
in deep learning-driven spectroscopy.

</details>


### [674] [BSL: A Unified and Generalizable Multitask Learning Platform for Virtual Drug Discovery from Design to Synthesis](https://arxiv.org/abs/2508.01195)
*Kun Li,Zhennan Wu,Yida Xiong,Hongzhi Zhang,Longtao Hu,Zhonglie Liu,Junqi Zeng,Wenjie Wu,Mukun Chen,Jiameng Chen,Wenbin Hu*

Main category: cs.LG

TL;DR: BSL是一个集成了七项核心任务的AI药物发现平台，在OOD泛化和实际应用中表现出色，成功发现了NMDA受体的新型调节剂。


<details>
  <summary>Details</summary>
Motivation: 现有的计算平台通常只覆盖核心任务的一个子集，导致工作流程碎片化、效率低下，并且在算法创新和对分布外（OOD）数据泛化能力方面存在不足，阻碍了药物发现的进展。

Method: 提出一个名为Baishenglai (BSL)的深度学习增强的、开放访问的虚拟药物发现平台，该平台在一个统一的、模块化的框架中集成了七项核心任务，并采用了生成模型和图神经网络等先进技术。

Result: BSL在多个基准数据集上取得了最先进（SOTA）的性能，并特别关注对OOD分子结构的泛化能力评估。与现有平台和基线方法进行的比较实验证明了BSL的优越性。此外，BSL成功发现了GluN1/GluN3A NMDA受体的新型调节剂，并在体外电生理学分析中识别出三种具有明显生物活性的化合物。

Conclusion: BSL是一个全面的、可扩展的、有效的虚拟药物发现解决方案，具有算法创新和高精度预测能力，已成功发现NMDA受体的三种新型调节剂，证明了其在加速生物医学研究和药物发现方面的实用潜力。

Abstract: Drug discovery is of great social significance in safeguarding human health,
prolonging life, and addressing the challenges of major diseases. In recent
years, artificial intelligence has demonstrated remarkable advantages in key
tasks across bioinformatics and pharmacology, owing to its efficient data
processing and data representation capabilities. However, most existing
computational platforms cover only a subset of core tasks, leading to
fragmented workflows and low efficiency. In addition, they often lack
algorithmic innovation and show poor generalization to out-of-distribution
(OOD) data, which greatly hinders the progress of drug discovery. To address
these limitations, we propose Baishenglai (BSL), a deep learning-enhanced,
open-access platform designed for virtual drug discovery. BSL integrates seven
core tasks within a unified and modular framework, incorporating advanced
technologies such as generative models and graph neural networks. In addition
to achieving state-of-the-art (SOTA) performance on multiple benchmark
datasets, the platform emphasizes evaluation mechanisms that focus on
generalization to OOD molecular structures. Comparative experiments with
existing platforms and baseline methods demonstrate that BSL provides a
comprehensive, scalable, and effective solution for virtual drug discovery,
offering both algorithmic innovation and high-precision prediction for
real-world pharmaceutical research. In addition, BSL demonstrated its practical
utility by discovering novel modulators of the GluN1/GluN3A NMDA receptor,
successfully identifying three compounds with clear bioactivity in in-vitro
electrophysiological assays. These results highlight BSL as a promising and
comprehensive platform for accelerating biomedical research and drug discovery.
The platform is accessible at https://www.baishenglai.net.

</details>


### [675] [Oldie but Goodie: Re-illuminating Label Propagation on Graphs with Partially Observed Features](https://arxiv.org/abs/2508.01209)
*Sukwon Yun,Xin Liu,Yunhak Oh,Junseok Lee,Tianlong Chen,Tsuyoshi Murata,Chanyoung Park*

Main category: cs.LG

TL;DR: GOODIE is a novel framework that enhances node classification by combining Label Propagation and Feature Propagation, outperforming existing methods especially when node features are missing.


<details>
  <summary>Details</summary>
Motivation: Traditional GNNs perform sub-optimally in scenarios with missing node features. Existing GNN-based methods also perform worse than traditional structure-based models when only a few features are available. There is a need for a method that can effectively handle missing features by leveraging both structural and feature information.

Method: GOODIE proposes a novel framework that combines Label Propagation (LP) and Feature Propagation (FP) to obtain node embeddings. It uses a GNN-based decoder to align embeddings from both branches and a Structure-Feature Attention mechanism to capture the significance of structure and feature information. Additionally, it incorporates Pseudo-Label contrastive learning to differentiate contributions within pseudo-labels from the LP branch.

Result: The proposed model, GOODIE, demonstrates superior performance compared to existing state-of-the-art methods in scenarios with both partially missing and abundantly available node features.

Conclusion: GOODIE outperformed existing state-of-the-art methods in node classification tasks, especially when only a partial feature is available, and also performed well in abundantly available situations.

Abstract: In real-world graphs, we often encounter missing feature situations where a
few or the majority of node features, e.g., sensitive information, are missed.
In such scenarios, directly utilizing Graph Neural Networks (GNNs) would yield
sub-optimal results in downstream tasks such as node classification. Despite
the emergence of a few GNN-based methods attempting to mitigate its missing
situation, when only a few features are available, they rather perform worse
than traditional structure-based models. To this end, we propose a novel
framework that further illuminates the potential of classical Label Propagation
(Oldie), taking advantage of Feature Propagation, especially when only a
partial feature is available. Now called by GOODIE, it takes a hybrid approach
to obtain embeddings from the Label Propagation branch and Feature Propagation
branch. To do so, we first design a GNN-based decoder that enables the Label
Propagation branch to output hidden embeddings that align with those of the FP
branch. Then, GOODIE automatically captures the significance of structure and
feature information thanks to the newly designed Structure-Feature Attention.
Followed by a novel Pseudo-Label contrastive learning that differentiates the
contribution of each positive pair within pseudo-labels originating from the LP
branch, GOODIE outputs the final prediction for the unlabeled nodes. Through
extensive experiments, we demonstrate that our proposed model, GOODIE,
outperforms the existing state-of-the-art methods not only when only a few
features are available but also in abundantly available situations. Source code
of GOODIE is available at: https://github.com/SukwonYun/GOODIE.

</details>


### [676] [Multi-Operator Few-Shot Learning for Generalization Across PDE Families](https://arxiv.org/abs/2508.01211)
*Yile Li,Shandian Zhe*

Main category: cs.LG

TL;DR: MOFS 是一个统一的多模态少样本学习框架，可以跨 PDE 系列进行泛化，仅需少量示例即可，解决了现有方法对数据需求大且泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的神经算子方法需要针对每个特定的 PDE 进行大量训练数据，并且缺乏跨 PDE 系列泛化能力。本研究提出 MOFS：一种统一的多模态框架，用于多算子少样本学习，旨在仅使用少数演示示例即可泛化到未见的 PDE 算子。

Method: MOFS框架集成多任务自监督预训练（共享Furier神经算子编码器）、文本条件算子嵌入和记忆增强的多模态提示（具有门控融合和跨模态梯度注意）。采用两阶段训练范式，首先学习特定算子的提示条件推理，然后进行端到端对比微调，以对齐跨视觉、频率和文本模态的潜在表示。

Result: 实验表明，MOFS 在少样本泛化方面优于现有的算子学习基线。大量的消融研究验证了每种模态和训练成分的贡献。

Conclusion: MOFS 在 Darcy Flow 和 Navier Stokes 变体等 PDE 基准测试中，在少样本泛化方面优于现有的算子学习基线。

Abstract: Learning solution operators for partial differential equations (PDEs) has
become a foundational task in scientific machine learning. However, existing
neural operator methods require abundant training data for each specific PDE
and lack the ability to generalize across PDE families. In this work, we
propose MOFS: a unified multimodal framework for multi-operator few-shot
learning, which aims to generalize to unseen PDE operators using only a few
demonstration examples. Our method integrates three key components: (i)
multi-task self-supervised pretraining of a shared Fourier Neural Operator
(FNO) encoder to reconstruct masked spatial fields and predict frequency
spectra, (ii) text-conditioned operator embeddings derived from statistical
summaries of input-output fields, and (iii) memory-augmented multimodal
prompting with gated fusion and cross-modal gradient-based attention. We adopt
a two-stage training paradigm that first learns prompt-conditioned inference on
seen operators and then applies end-to-end contrastive fine-tuning to align
latent representations across vision, frequency, and text modalities.
Experiments on PDE benchmarks, including Darcy Flow and Navier Stokes variants,
demonstrate that our model outperforms existing operator learning baselines in
few-shot generalization. Extensive ablations validate the contributions of each
modality and training component. Our approach offers a new foundation for
universal and data-efficient operator learning across scientific domains.

</details>


### [677] [RelMap: Reliable Spatiotemporal Sensor Data Visualization via Imputative Spatial Interpolation](https://arxiv.org/abs/2508.01240)
*Juntong Chen,Huayuan Ye,He Zhu,Siwei Fu,Changbo Wang,Chenhui Li*

Main category: cs.LG

TL;DR: 本研究提出了一种结合GNN、PNA和GPE的空间插值新方法，用于可靠地可视化时空传感器数据，并生成包含不确定性信息的热力图。实验证明该方法在数据填补和不确定性传达方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 准确可靠地可视化环境参数和气象条件等时空传感器数据，对于做出明智的决策至关重要。然而，传统的空间插值方法由于传感器覆盖范围有限且不规则，在生成可靠的插值结果方面常常不足。

Method: 本研究利用图神经网络（GNN）、邻域聚合（PNA）和地理位置编码（GPE）来学习时空依赖性，以实现可靠的空间插值。提出了一种外在的、静态的可视化技术，用于插值热力图，以传达不确定性信息。

Result: 通过在真实世界数据集上的大量评估和用户研究，证明了该模型在数据填补方面的优越性能，以及对参考数据插值器的改进，和可视化设计在传达不确定性方面的有效性。

Conclusion: 本研究提出的新颖空间插值流程结合图神经网络（GNN）、邻域聚合（PNA）和地理位置编码（GPE），能够实现可靠的插值结果，并生成包含不确定性信息的创新热力图表示。通过使用GNN进行数据填补，可以提高可视化可靠性和时间分辨率。此外，本研究提出了一种外在的、静态的可视化技术，用于插值热力图，能有效传达插值图中的不确定性信息。

Abstract: Accurate and reliable visualization of spatiotemporal sensor data such as
environmental parameters and meteorological conditions is crucial for informed
decision-making. Traditional spatial interpolation methods, however, often fall
short of producing reliable interpolation results due to the limited and
irregular sensor coverage. This paper introduces a novel spatial interpolation
pipeline that achieves reliable interpolation results and produces a novel
heatmap representation with uncertainty information encoded. We leverage
imputation reference data from Graph Neural Networks (GNNs) to enhance
visualization reliability and temporal resolution. By integrating Principal
Neighborhood Aggregation (PNA) and Geographical Positional Encoding (GPE), our
model effectively learns the spatiotemporal dependencies. Furthermore, we
propose an extrinsic, static visualization technique for interpolation-based
heatmaps that effectively communicates the uncertainties arising from various
sources in the interpolated map. Through a set of use cases, extensive
evaluations on real-world datasets, and user studies, we demonstrate our
model's superior performance for data imputation, the improvements to the
interpolant with reference data, and the effectiveness of our visualization
design in communicating uncertainties.

</details>


### [678] [Soft Separation and Distillation: Toward Global Uniformity in Federated Unsupervised Learning](https://arxiv.org/abs/2508.01251)
*Hung-Chieh Fang,Hsuan-Tien Lin,Irwin King,Yifei Zhang*

Main category: cs.LG

TL;DR: SSD 是一种新方法，通过软分离和蒸馏来提高联邦无监督学习中的全局表示均匀性，解决了非同质数据和去中心化带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦无监督学习（FUL）解决方案在实现本地模型本地均匀性方面表现良好，但在聚合后由于非同质数据分布和去中心化特性，未能实现客户端间的全局均匀性。

Method: 提出了一种名为软分离与蒸馏（SSD）的新方法，通过鼓励客户端表示朝着不同方向分散来保持客户端间的均匀性，并引入了一个投影仪蒸馏模块来解决损失优化与表示质量之间的差异。

Result: SSD 持续改进了表示质量和任务性能，强调了客户端间均匀性在 FUL 中的重要性，并确立了 SSD 作为解决此挑战的有效方案。

Conclusion: SSD 成功地在跨孤岛和跨设备联邦设置中提高了表示质量和任务性能，解决了联邦无监督学习中跨客户端（全局）均匀性不足的问题。

Abstract: Federated Unsupervised Learning (FUL) aims to learn expressive
representations in federated and self-supervised settings. The quality of
representations learned in FUL is usually determined by uniformity, a measure
of how uniformly representations are distributed in the embedding space.
However, existing solutions perform well in achieving intra-client (local)
uniformity for local models while failing to achieve inter-client (global)
uniformity after aggregation due to non-IID data distributions and the
decentralized nature of FUL. To address this issue, we propose Soft Separation
and Distillation (SSD), a novel approach that preserves inter-client uniformity
by encouraging client representations to spread toward different directions.
This design reduces interference during client model aggregation, thereby
improving global uniformity while preserving local representation
expressiveness. We further enhance this effect by introducing a projector
distillation module to address the discrepancy between loss optimization and
representation quality. We evaluate SSD in both cross-silo and cross-device
federated settings, demonstrating consistent improvements in representation
quality and task performance across various training scenarios. Our results
highlight the importance of inter-client uniformity in FUL and establish SSD as
an effective solution to this challenge. Project page:
https://ssd-uniformity.github.io/

</details>


### [679] [Exploitation Is All You Need... for Exploration](https://arxiv.org/abs/2508.01287)
*Micah Rentschler,Jesse Roberts*

Main category: cs.LG

TL;DR: 探索不一定需要显式的探索奖励。重复性的环境结构、代理记忆和长时程信用分配这三个条件，可以让仅以贪婪目标训练的代理涌现出探索行为。


<details>
  <summary>Details</summary>
Motivation: Meta-RL 代理在解决新环境时，确保充分探索是一个核心挑战。传统的解决方案通常通过注入明确的激励（如随机化、不确定性奖励或内在奖励）来鼓励探索。本研究旨在探索一种替代方法：即在特定条件下，仅以贪婪（仅利用）目标训练的代理是否能涌现出探索行为。

Method: 通过在随机多臂老虎机和时间扩展网格世界中进行实验，并进行受控的消减实验，来验证代理在满足特定条件时，仅以贪婪目标训练也能产生探索行为的假设。

Result: 在同时存在环境结构和代理记忆的条件下，严格以贪婪目标训练的策略表现出了信息寻求式的探索行为。消减实验证明，若缺失环境结构或代理记忆，涌现式探索会消失。然而，缺失长时程信用分配并不总是阻止涌现式探索，这可能是由于伪 Thompson 采样效应。

Conclusion: 研究结果表明，在特定条件下（重复性环境结构、代理记忆和长时程信用分配），仅以贪婪目标进行训练的代理能够表现出信息寻求式的探索行为。研究还发现，环境结构或代理记忆的缺失会消除这种涌现式探索，而长时程信用分配的缺失并不总是阻止其发生，这归因于伪 Thompson 采样效应。这些发现启示我们，在合适的先决条件下，探索和利用可以从统一的奖励最大化过程中涌现，而非被视为独立的优化目标。

Abstract: Ensuring sufficient exploration is a central challenge when training
meta-reinforcement learning (meta-RL) agents to solve novel environments.
Conventional solutions to the exploration-exploitation dilemma inject explicit
incentives such as randomization, uncertainty bonuses, or intrinsic rewards to
encourage exploration. In this work, we hypothesize that an agent trained
solely to maximize a greedy (exploitation-only) objective can nonetheless
exhibit emergent exploratory behavior, provided three conditions are met: (1)
Recurring Environmental Structure, where the environment features repeatable
regularities that allow past experience to inform future choices; (2) Agent
Memory, enabling the agent to retain and utilize historical interaction data;
and (3) Long-Horizon Credit Assignment, where learning propagates returns over
a time frame sufficient for the delayed benefits of exploration to inform
current decisions. Through experiments in stochastic multi-armed bandits and
temporally extended gridworlds, we observe that, when both structure and memory
are present, a policy trained on a strictly greedy objective exhibits
information-seeking exploratory behavior. We further demonstrate, through
controlled ablations, that emergent exploration vanishes if either
environmental structure or agent memory is absent (Conditions 1 & 2).
Surprisingly, removing long-horizon credit assignment (Condition 3) does not
always prevent emergent exploration-a result we attribute to the
pseudo-Thompson Sampling effect. These findings suggest that, under the right
prerequisites, exploration and exploitation need not be treated as orthogonal
objectives but can emerge from a unified reward-maximization process.

</details>


### [680] [FedCD: A Fairness-aware Federated Cognitive Diagnosis Framework](https://arxiv.org/abs/2508.01296)
*Shangshang Yang,Jialin Han,Xiaoshan Yu,Ziwen Wang,Hao Jiang,Haiping Ma,Xingyi Zhang,Geyong Min*

Main category: cs.LG

TL;DR: FedCD是一个联邦学习框架，通过参数解耦实现公平的认知诊断，保护隐私并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 在线智能教育平台产生了大量分布式学生学习数据，为认知诊断（CD）提供了机会，但也带来了数据隐私和安全挑战。联邦学习（FL）是一种有前景的解决方案，但学生群体/学校之间能力差异和教育背景差异导致的数据质量问题，进一步挑战了模型的公平性。

Method: FedCD框架采用联邦学习范式，为每个客户端的本地学生训练本地CD模型，并通过一种新颖的参数解耦个性化策略聚合参数。该策略将模型参数分为两部分：一部分作为本地个性化参数，包含诊断功能相关的模型参数，实现对各客户端学生的公平诊断；另一部分作为全局共享参数，包含练习嵌入参数，通过公平感知聚合进行更新，以缓解跨校不公平问题。

Result: 在三个真实世界数据集上的实验表明，与五种FL方法和三种CD模型相比，所提出的FedCD框架和个性化策略的有效性。

Conclusion: 本文提出的FedCD框架通过新颖的参数解耦个性化策略，能够在保护学生数据隐私的前提下，实现跨客户端的精准和公平的认知诊断。

Abstract: Online intelligent education platforms have generated a vast amount of
distributed student learning data. This influx of data presents opportunities
for cognitive diagnosis (CD) to assess students' mastery of knowledge concepts
while also raising significant data privacy and security challenges. To cope
with this issue, federated learning (FL) becomes a promising solution by
jointly training models across multiple local clients without sharing their
original data. However, the data quality problem, caused by the ability
differences and educational context differences between different
groups/schools of students, further poses a challenge to the fairness of
models. To address this challenge, this paper proposes a fairness-aware
federated cognitive diagnosis framework (FedCD) to jointly train CD models
built upon a novel parameter decoupling-based personalization strategy,
preserving privacy of data and achieving precise and fair diagnosis of students
on each client. As an FL paradigm, FedCD trains a local CD model for the
students in each client based on its local student learning data, and each
client uploads its partial model parameters to the central server for parameter
aggregation according to the devised innovative personalization strategy. The
main idea of this strategy is to decouple model parameters into two parts: the
first is used as locally personalized parameters, containing diagnostic
function-related model parameters, to diagnose each client's students fairly;
the second is the globally shared parameters across clients and the server,
containing exercise embedding parameters, which are updated via fairness-aware
aggregation, to alleviate inter-school unfairness. Experiments on three
real-world datasets demonstrate the effectiveness of the proposed FedCD
framework and the personalization strategy compared to five FL approaches under
three CD models.

</details>


### [681] [GraphVSSM: Graph Variational State-Space Model for Probabilistic Spatiotemporal Inference of Dynamic Exposure and Vulnerability for Regional Disaster Resilience Assessment](https://arxiv.org/abs/2508.01310)
*Joshua Dimasaka,Christian Geiß,Emily So*

Main category: cs.LG

TL;DR: 本研究提出了一种名为GraphVSSM的新型时空模型，用于改进区域灾害韧性评估中的物理脆弱性分析，解决了现有方法的局限性。该模型结合了图深度学习、状态空间建模和变分推断，并成功应用于菲律宾、孟加拉国和塞拉利昂的案例研究，同时发布了一个增强型数据集METEOR 2.5D，为灾害风险研究和城市分析提供了新的方法和数据支持。


<details>
  <summary>Details</summary>
Motivation: 现有针对区域灾害韧性的方法在物理脆弱性评估方面存在静态、成本高、局限性大、区域性强、粒度粗和校准不足等问题。尽管已有许多方法在暴露度和灾害动态测绘方面取得进展，但对大规模物理脆弱性的理解仍然滞后。鉴于时间序列卫星图像数据的可用性显著增长，本研究旨在解决风险评估中同样重要但更具挑战性的要素——物理脆弱性。

Method: 提出了一种新颖的图变分状态空间模型（GraphVSSM），该模型是一种模块化的时空方法，能够灵活地捕获空间上下文关系、有限的时间观测和不确定性。它整合了图深度学习、状态空间建模和变分推断，利用时间序列数据和先验专家知识，以弱监督或粗粒度到细粒度的方式进行推断。

Result: 1. 在菲律宾奎松市进行了城市范围的演示。 2. 调查了孟加拉国受气旋影响的沿海Khurushkul社区和塞拉利昂受山体滑坡影响的Freetown的突变情况。 3. 发布了一个名为METEOR 2.5D的开放地理空间数据集，该数据集在时空上增强了现有的联合国最不发达国家（2020年）的全球静态数据集。

Conclusion: 该研究通过引入新颖的图变分状态空间模型（GraphVSSM），一个结合图深度学习、状态空间建模和变分推断的模块化时空方法，显著提升了区域灾害韧性评估中物理脆弱性理解的动态性、精细度和准确性。该方法能够灵活处理空间上下文关系、有限的时间观测和不确定性，并在弱监督或粗粒度到细粒度的条件下，融合时间序列数据和先验专家知识。研究通过在菲律宾奎松市的试点演示、孟加拉国和塞拉利昂的案例研究，以及发布METEOR 2.5D数据集，验证了其有效性，为全球最不发达国家（2020年）的灾害风险减降进展提供了更深入的理解，并为需要组合数据分析和弱监督方法的城市研究领域提供了新的概率深度学习途径。

Abstract: Regional disaster resilience quantifies the changing nature of physical risks
to inform policy instruments ranging from local immediate recovery to
international sustainable development. While many existing state-of-practice
methods have greatly advanced the dynamic mapping of exposure and hazard, our
understanding of large-scale physical vulnerability has remained static,
costly, limited, region-specific, coarse-grained, overly aggregated, and
inadequately calibrated. With the significant growth in the availability of
time-series satellite imagery and derived products for exposure and hazard, we
focus our work on the equally important yet challenging element of the risk
equation: physical vulnerability. We leverage machine learning methods that
flexibly capture spatial contextual relationships, limited temporal
observations, and uncertainty in a unified probabilistic spatiotemporal
inference framework. We therefore introduce Graph Variational State-Space Model
(GraphVSSM), a novel modular spatiotemporal approach that uniquely integrates
graph deep learning, state-space modeling, and variational inference using
time-series data and prior expert belief systems in a weakly supervised or
coarse-to-fine-grained manner. We present three major results: a city-wide
demonstration in Quezon City, Philippines; an investigation of sudden changes
in the cyclone-impacted coastal Khurushkul community (Bangladesh) and
mudslide-affected Freetown (Sierra Leone); and an open geospatial dataset,
METEOR 2.5D, that spatiotemporally enhances the existing global static dataset
for UN Least Developed Countries (2020). Beyond advancing regional disaster
resilience assessment and improving our understanding global disaster risk
reduction progress, our method also offers a probabilistic deep learning
approach, contributing to broader urban studies that require compositional data
analysis in weak supervision.

</details>


### [682] [Physics-Informed Neural Network Approaches for Sparse Data Flow Reconstruction of Unsteady Flow Around Complex Geometries](https://arxiv.org/abs/2508.01314)
*Vamsi Sai Krishna Malineni,Suresh Rajendran*

Main category: cs.LG

TL;DR: PINNs can reconstruct fluid flow from limited data, even for complex scenarios, by incorporating physical laws into neural networks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop effective PINN models for flow reconstruction from sparse data under constrained computational resources, addressing a gap in current research that primarily focuses on forward problems with ample data.

Method: The study utilizes Physics-Informed Neural Networks (PINNs) and explores training methods like Standard PINN and Backward Compatible PINN (BC-PINN). It also investigates performance enhancements through systematic relaxation of physics constraints and dynamic weighting of loss function components.

Result: The study demonstrates the capability of PINN-based models to reconstruct flow fields from sparse data, comparing different training methods and constraint relaxation strategies for a 2D laminar flow case and showcasing the model's effectiveness for a 3D turbulent flow case.

Conclusion: PINN-based models can reconstruct flow field data from sparse datasets, even for complex 3D turbulent flows, outperforming earlier studies focused on forward problems.

Abstract: The utilization of Deep Neural Networks (DNNs) in physical science and
engineering applications has gained traction due to their capacity to learn
intricate functions. While large datasets are crucial for training DNN models
in fields like computer vision and natural language processing, obtaining such
datasets for engineering applications is prohibitively expensive.
Physics-Informed Neural Networks (PINNs), a branch of Physics-Informed Machine
Learning (PIML), tackle this challenge by embedding physical principles within
neural network architectures. PINNs have been extensively explored for solving
diverse forward and inverse problems in fluid mechanics. Nonetheless, there is
limited research on employing PINNs for flow reconstruction from sparse data
under constrained computational resources. Earlier studies were focused on
forward problems with well-defined data. The present study attempts to develop
models capable of reconstructing the flow field data from sparse datasets
mirroring real-world scenarios.
  This study focuses on two cases: (a) two-dimensional (2D) unsteady laminar
flow past a circular cylinder and (b) three-dimensional (3D) unsteady turbulent
flow past an ultra-large container ship (ULCS). The first case compares the
effectiveness of training methods like Standard PINN and Backward Compatible
PINN (BC-PINN) and explores the performance enhancements through systematic
relaxation of physics constraints and dynamic weighting of loss function
components. The second case highlights the capability of PINN-based models to
learn underlying physics from sparse data while accurately reconstructing the
flow field for a highly turbulent flow.

</details>


### [683] [Fusion Sampling Validation in Data Partitioning for Machine Learning](https://arxiv.org/abs/2508.01325)
*Christopher Godwin Udomboso,Caston Sigauke,Ini Adinya*

Main category: cs.LG

TL;DR: FSV是一种结合简单随机抽样（SRS）和K折交叉验证（KFCV）的数据划分混合模型，能有效解决传统方法在计算量、泛化能力评估和数据不平衡方面的问题，并在准确性和可靠性方面优于单独的SRS和KFCV。


<details>
  <summary>Details</summary>
Motivation: 传统的K折交叉验证（KFCV）虽然能增强模型鲁棒性，但计算量大、数据混洗频繁，影响泛化能力评估。简单随机抽样（SRS）能提供代表性样本，但可能产生不具代表性的、数据不平衡的样本集。本研究旨在解决这些问题，提出一种结合SRS和KFCV的混合模型FSV，以优化数据划分。

Method: 该研究提出了一种名为FSV（Fusion Sampling Validation）的混合模型，结合了简单随机抽样（SRS）和K折交叉验证（KFCV），旨在优化数据划分，最小化偏差，并融合SRS的简洁性与KFCV的准确性。实验在包含10,000、50,000和100,000个样本的数据集上进行，KFCV采用5折10次重复，并引入了缩放因子和加权因子以增强性能和泛化能力。评估指标包括均值估计（ME）、方差估计（VE）、均方误差（MSE）、偏差、均值估计收敛率（ROC_ME）和方差估计收敛率（ROC_VE）。

Result: FSV在所有评估指标上均优于SRS和KFCV，具体指标值分别为：ME 0.000863，VE 0.949644，MSE 0.952127，偏差0.016288，ROC_ME 0.005199，ROC_VE 0.007137。

Conclusion: FSV通过结合SRS和KFCV的优点，在数据划分方面展现出优越的准确性和可靠性，特别是在资源受限和大型数据集的环境中，为有效的机器学习实现提供了实际解决方案。

Abstract: Effective data partitioning is known to be crucial in machine learning.
Traditional cross-validation methods like K-Fold Cross-Validation (KFCV)
enhance model robustness but often compromise generalisation assessment due to
high computational demands and extensive data shuffling. To address these
issues, the integration of the Simple Random Sampling (SRS), which, despite
providing representative samples, can result in non-representative sets with
imbalanced data. The study introduces a hybrid model, Fusion Sampling
Validation (FSV), combining SRS and KFCV to optimise data partitioning. FSV
aims to minimise biases and merge the simplicity of SRS with the accuracy of
KFCV. The study used three datasets of 10,000, 50,000, and 100,000 samples,
generated with a normal distribution (mean 0, variance 1) and initialised with
seed 42. KFCV was performed with five folds and ten repetitions, incorporating
a scaling factor to ensure robust performance estimation and generalisation
capability. FSV integrated a weighted factor to enhance performance and
generalisation further. Evaluations focused on mean estimates (ME), variance
estimates (VE), mean squared error (MSE), bias, the rate of convergence for
mean estimates (ROC\_ME), and the rate of convergence for variance estimates
(ROC\_VE). Results indicated that FSV consistently outperformed SRS and KFCV,
with ME values of 0.000863, VE of 0.949644, MSE of 0.952127, bias of 0.016288,
ROC\_ME of 0.005199, and ROC\_VE of 0.007137. FSV demonstrated superior
accuracy and reliability in data partitioning, particularly in
resource-constrained environments and extensive datasets, providing practical
solutions for effective machine learning implementations.

</details>


### [684] [Is Exploration or Optimization the Problem for Deep Reinforcement Learning?](https://arxiv.org/abs/2508.01329)
*Glen Berseth*

Main category: cs.LG

TL;DR: 深度强化学习算法在优化过程中存在局限性，只能利用一半的良好体验。


<details>
  <summary>Details</summary>
Motivation: 在深度强化学习时代，将收集到的经验压缩到深度模型中以供未来利用和采样变得越来越复杂。许多研究表明，在不断变化的状态和行动分布下训练深度学习策略会导致次优性能甚至崩溃。因此，人们自然会担心，即使社区开发出改进的探索算法或奖励目标，这些改进是否也会因为优化困难而“失聪”。

Method: 提出了一种新的实用次优性估计方法。

Result: 实验表明，最佳体验的产生比策略所学的性能好2-3倍，这表明深度强化学习方法仅利用了它们所产生良好体验的一半。

Conclusion: 该研究提出了一种新的实用次优性估计方法，用于确定深度强化学习算法的优化局限性。实验表明，与策略所学的性能相比，最佳体验的产生要好2-3倍，这表明深度强化学习方法仅利用了它们所产生良好体验的一半。

Abstract: In the era of deep reinforcement learning, making progress is more complex,
as the collected experience must be compressed into a deep model for future
exploitation and sampling. Many papers have shown that training a deep learning
policy under the changing state and action distribution leads to sub-optimal
performance, or even collapse. This naturally leads to the concern that even if
the community creates improved exploration algorithms or reward objectives,
will those improvements fall on the \textit{deaf ears} of optimization
difficulties. This work proposes a new \textit{practical} sub-optimality
estimator to determine optimization limitations of deep reinforcement learning
algorithms. Through experiments across environments and RL algorithms, it is
shown that the difference between the best experience generated is 2-3$\times$
better than the policies' learned performance. This large difference indicates
that deep RL methods only exploit half of the good experience they generate.

</details>


### [685] [Convergence Analysis of Aggregation-Broadcast in LoRA-enabled Federated Learning](https://arxiv.org/abs/2508.01348)
*Xin Chen,Shuaijun Chen,Omid Tavallaie,Nguyen Tran,Shuhuang Xiang,Albert Zomaya*

Main category: cs.LG

TL;DR: 本文分析了联邦学习中LoRA模型聚合的收敛性，提出了聚合-广播算子（ABO），并证明了SP和PS方法的收敛性及收敛速率差异。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习（FL）中日益增长的模型尺寸带来的通信和计算挑战，以及在LoRA被引入FL后，聚合LoRA更新的本地模型这一关键且未被充分研究的问题。

Method: 对现有的基于LoRA的联邦学习聚合方法进行分类（Sum-Product和Product-Sum），定义了聚合-广播算子（ABO），并推导了其在温和假设下的通用收敛条件，同时提出了一些保证全局模型收敛的充分条件。

Result: 提出了统一的收敛性分析框架，证明了SP和PS聚合方法均满足收敛条件，但收敛速率存在差异，并通过实验验证了理论发现。

Conclusion: 文章对基于LoRA的联邦学习的聚合方法进行了统一的收敛性分析，并提出了聚合-广播算子（ABO）及其收敛条件。实验证明，Sum-Product（SP）和Product-Sum（PS）两种聚合方法均满足收敛条件，但收敛速率不同。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized data sources while preserving data privacy. However, the growing
size of Machine Learning (ML) models poses communication and computation
challenges in FL. Low-Rank Adaptation (LoRA) has recently been introduced into
FL as an efficient fine-tuning method, reducing communication overhead by
updating only a small number of trainable parameters. Despite its
effectiveness, how to aggregate LoRA-updated local models on the server remains
a critical and understudied problem. In this paper, we provide a unified
convergence analysis for LoRA-based FL. We first categories the current
aggregation method into two major type: Sum-Product (SP) and Product-Sum (PS).
Then we formally define the Aggregation-Broadcast Operator (ABO) and derive a
general convergence condition under mild assumptions. Furthermore, we present
several sufficient conditions that guarantee convergence of the global model.
These theoretical analyze offer a principled understanding of various
aggregation strategies. Notably, we prove that the SP and PS aggregation
methods both satisfy our convergence condition, but differ in their ability to
achieve the optimal convergence rate. Extensive experiments on standard
benchmarks validate our theoretical findings.

</details>


### [686] [Quenched large deviations for Monte Carlo integration with Coulomb gases](https://arxiv.org/abs/2508.01392)
*Rémi Bardenet,Mylène Maïda,Martin Rouault*

Main category: cs.LG

TL;DR: 为了将Gibbs测度用作随机积分算法，研究人员提出了一种调整相互作用核和约束势的方法，并证明了随机逼近势能可以保持算法的快速大偏差原理，从而提高积分精度。


<details>
  <summary>Details</summary>
Motivation: Gibbs测度（如库仑气体）常用于模拟相互作用粒子系统。为了将Gibbs测度用作目标测度$	au$的随机积分算法，需要调整其相互作用核和约束势，使平衡测度为目标分布$	au$。这通常需要对势能进行蒙特卡洛（Monte Carlo）近似，而该研究旨在解决此问题。

Method: 提出使用Gibbs测度作为随机积分算法，并研究了如何调整其相互作用核（interaction kernel）和约束势（confining potential）使得平衡测度（equilibrium measure）为目标分布$	au$。利用Garcia-Zelada（2019）的大偏差理论，证明了随机逼近势能可以保持算法的快速大偏差原理。

Result: 对于非奇异相互作用核，研究表明随机逼近势能只需要很少的假设，并且可以是计算成本较低的蒙特卡洛预处理的结果。对于库仑相互作用核，需要基于另一个Gibbs测度进行随机逼近，并证明了势能逼近的均匀收敛性控制。

Conclusion: 研究表明，随机逼近（random approximation）可以保持Gibbs测度（Gibbs measures）作为随机积分算法（randomized numerical integration algorithms）的快速大偏差原理（fast large deviation principle），从而优于独立或马尔可夫积分（independent or Markov quadratures）。对于非奇异核（non-singular interaction kernels），该方法对随机逼近的假设很少。对于库仑核（Coulomb interaction kernels），需要基于另一个Gibbs测度进行逼近，并控制了势能逼近（potential approximation）的均匀收敛性。

Abstract: Gibbs measures, such as Coulomb gases, are popular in modelling systems of
interacting particles. Recently, we proposed to use Gibbs measures as
randomized numerical integration algorithms with respect to a target measure
$\pi$ on $\mathbb R^d$, following the heuristics that repulsiveness between
particles should help reduce integration errors. A major issue in this approach
is to tune the interaction kernel and confining potential of the Gibbs measure,
so that the equilibrium measure of the system is the target distribution $\pi$.
Doing so usually requires another Monte Carlo approximation of the
\emph{potential}, i.e. the integral of the interaction kernel with respect to
$\pi$. Using the methodology of large deviations from Garcia--Zelada (2019), we
show that a random approximation of the potential preserves the fast large
deviation principle that guarantees the proposed integration algorithm to
outperform independent or Markov quadratures. For non-singular interaction
kernels, we make minimal assumptions on this random approximation, which can be
the result of a computationally cheap Monte Carlo preprocessing. For the
Coulomb interaction kernel, we need the approximation to be based on another
Gibbs measure, and we prove in passing a control on the uniform convergence of
the approximation of the potential.

</details>


### [687] [Effects of Feature Correlations on Associative Memory Capacity](https://arxiv.org/abs/2508.01395)
*Stefan Bielmeier,Gerald Friedland*

Main category: cs.LG

TL;DR: 特征相关性对DAM模型容量的影响：容量随输入空间分离度呈指数增长，相关性会轻微降低容量，在高阶交互中影响更大。


<details>
  <summary>Details</summary>
Motivation: 实际的机器学习场景涉及特征相关的数据并在输入空间中学习表示，但目前的容量分析并未考虑到这一点。

Method: 通过系统地构建不同特征相关性和模式分离度（使用信息论中的汉明距离）的数据集，并采用简单的二分法来计算模型的存储容量，构建了一个经验框架来分析数据结构对容量动态的影响。

Result: 实验证实，记忆容量随着输入空间中分离度的增加呈指数级增长。容量随输入空间分离度的增长关系基本不受特征相关性的影响，但会轻微降低容量。

Conclusion: 特征相关性不会从根本上改变容量随输入空间分离呈指数级增长的关系，但会略微降低相同分离度下的容量。这种影响在高阶能量函数中更为显著，表明联想记忆在描述特征间的更高阶相互作用方面比模式本身更受限制。

Abstract: We investigate how feature correlations influence the capacity of Dense
Associative Memory (DAM), a Transformer attention-like model. Practical machine
learning scenarios involve feature-correlated data and learn representations in
the input space, but current capacity analyses do not account for this. We
develop an empirical framework to analyze the effects of data structure on
capacity dynamics. Specifically, we systematically construct datasets that vary
in feature correlation and pattern separation using Hamming distance from
information theory, and compute the model's corresponding storage capacity
using a simple binary search algorithm. Our experiments confirm that memory
capacity scales exponentially with increasing separation in the input space.
Feature correlations do not alter this relationship fundamentally, but reduce
capacity slightly at constant separation. This effect is amplified at higher
polynomial degrees in the energy function, suggesting that Associative Memory
is more limited in depicting higher-order interactions between features than
patterns. Our findings bridge theoretical work and practical settings for DAM,
and might inspire more data-centric methods.

</details>


### [688] [CPformer -- Concept and Physics enhanced Transformer for Time Series Forecasting](https://arxiv.org/abs/2508.01407)
*Hongwei Ma,Junbin Gao,Minh-Ngoc Tran*

Main category: cs.LG

TL;DR: CPformer是一种结合了概念和物理约束的Transformer模型，在多变量时间序列预测任务中取得了优于现有基线模型的性能，尤其在Electricity、Traffic和Illness数据集上表现突出。


<details>
  <summary>Details</summary>
Motivation: 准确、可解释且物理可信的预测仍然是多变量时间序列面临的持续挑战，因为其统计特性因领域而异。

Method: CPformer是一种概念和物理增强的Transformer，通过五个自监督、领域无关的概念进行每一次预测，同时强制执行源自第一性原理约束的可微分残差。

Result: CPformer在Electricity、Traffic和Illness等六个公开数据集上取得了最低误差，在Electricity、Traffic和Illness上分别降低了23%、44%和61%的均方误差，同时在Weather和ETT序列上保持了性能。

Conclusion: CPformer在Electricity、Traffic和Illness等六个公开数据集上进行了测试，在十二个MSE/MAE指标中有八个取得了最低误差。与最强的Transformer基线FEDformer相比，CPformer在Electricity上降低了23%的均方误差，在Traffic上降低了44%，在Illness上降低了61%，同时在严格周期性的Weather和ETT序列上保持了性能。

Abstract: Accurate, explainable and physically-credible forecasting remains a
persistent challenge for multivariate time-series whose statistical properties
vary across domains. We present CPformer, a Concept- and Physics-enhanced
Transformer that channels every prediction through five self-supervised,
domain-agnostic concepts while enforcing differentiable residuals drawn from
first-principle constraints. Unlike prior efficiency-oriented Transformers that
rely purely on sparsity or frequency priors , CPformer combines latent
transparency with hard scientific guidance while retaining attention for long
contexts. We tested CPformer on six publicly-available datasets: sub-hourly
Electricity and Traffic, hourly ETT, high-dimensional Weather, weekly
Influenza-like Illness, and minute-level Exchange Rate, and CPformer achieves
the lowest error in eight of twelve MSE/MAE cells. Relative to the strongest
Transformer baseline (FEDformer), CPformer reduces mean-squared-error by 23% on
Electricity, 44% on Traffic and 61% on Illness, while matching performance on
strictly periodic Weather and ETT series.

</details>


### [689] [Cryptocurrency Price Forecasting Using Machine Learning: Building Intelligent Financial Prediction Models](https://arxiv.org/abs/2508.01419)
*Md Zahidul Islam,Md Shafiqur Rahman,Md Sumsuzoha,Babul Sarker,Md Rafiqul Islam,Mahfuz Alam,Sanjib Kumar Shil*

Main category: cs.LG

TL;DR: 本研究通过引入流动性指标 VVR 和 VWAP，证明了在预测加密货币价格时考虑市场流动性的重要性。LSTM 模型结合这些指标后，在预测 XRP/USDT 交易对的价格方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 加密货币市场的快速增长带来了预测价格的挑战，尤其是在预测美国交易者的加密货币价格方面。现有模型通常忽略了市场流动性这一关键因素，而流动性对价格可预测性至关重要。

Method: 本研究探讨了深度学习和机器学习模型在预测 XRP/USDT 交易对收盘价方面的应用。研究人员引入了两个重要的流动性代理指标：成交量波动率比（VVR）和成交量加权平均价（VWAP）。他们开发了四种机器学习模型（线性回归、随机森林、XGBoost 和 LSTM 神经网络），首先在不包含流动性指标的情况下使用历史数据进行训练和评估，然后纳入流动性指标后重新训练并再次评估。

Result: 在未使用流动性指标的情况下，LSTM 模型表现优于线性回归、随机森林和 XGBoost。在纳入 VVR 和 VWAP 指标后，LSTM 模型继续保持最佳性能，表明流动性指标可以提高预测的准确性。

Conclusion: 研究结果强调了在预测加密货币收盘价时考虑市场流动性的重要性，并指出包含流动性指标的 LSTM 模型在预测 XRP/USDT 交易对时表现优于其他模型。

Abstract: Cryptocurrency markets are experiencing rapid growth, but this expansion
comes with significant challenges, particularly in predicting cryptocurrency
prices for traders in the U.S. In this study, we explore how deep learning and
machine learning models can be used to forecast the closing prices of the
XRP/USDT trading pair. While many existing cryptocurrency prediction models
focus solely on price and volume patterns, they often overlook market
liquidity, a crucial factor in price predictability. To address this, we
introduce two important liquidity proxy metrics: the Volume-To-Volatility Ratio
(VVR) and the Volume-Weighted Average Price (VWAP). These metrics provide a
clearer understanding of market stability and liquidity, ultimately enhancing
the accuracy of our price predictions. We developed four machine learning
models, Linear Regression, Random Forest, XGBoost, and LSTM neural networks,
using historical data without incorporating the liquidity proxy metrics, and
evaluated their performance. We then retrained the models, including the
liquidity proxy metrics, and reassessed their performance. In both cases (with
and without the liquidity proxies), the LSTM model consistently outperformed
the others. These results underscore the importance of considering market
liquidity when predicting cryptocurrency closing prices. Therefore,
incorporating these liquidity metrics is essential for more accurate
forecasting models. Our findings offer valuable insights for traders and
developers seeking to create smarter and more risk-aware strategies in the U.S.
digital assets market.

</details>


### [690] [UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting](https://arxiv.org/abs/2508.01426)
*Hang Ni,Weijia Zhang,Hao Liu*

Main category: cs.LG

TL;DR: UniExtreme is a new foundation model for weather forecasting that addresses the limitations of existing models in predicting diverse extreme weather events by incorporating spectral disparity and hierarchical drivers through its AFM and EPA modules, achieving superior performance compared to state-of-the-art baselines.


<details>
  <summary>Details</summary>
Motivation: Existing foundation models for weather forecasting have limited ability to predict extreme weather events, either focusing on general conditions or specific types of extremes, neglecting the real-world atmospheric patterns of diversified extreme events.

Method: The proposed UniExtreme model integrates an Adaptive Frequency Modulation (AFM) module to capture spectral differences between normal and extreme weather using learnable Beta-distribution filters and multi-granularity spectral aggregation, and an Event Prior Augmentation (EPA) module that incorporates region-specific extreme event priors via a dual-level memory fusion network to address hierarchical extreme diversity and composite extreme schema.

Result: Extensive experiments demonstrate that UniExtreme outperforms state-of-the-art baselines in both extreme and general weather forecasting, showcasing superior adaptability across diverse extreme scenarios.

Conclusion: UniExtreme outperforms state-of-the-art baselines in both extreme and general weather forecasting, showcasing superior adaptability across diverse extreme scenarios.

Abstract: Recent advancements in deep learning have led to the development of
Foundation Models (FMs) for weather forecasting, yet their ability to predict
extreme weather events remains limited. Existing approaches either focus on
general weather conditions or specialize in specific-type extremes, neglecting
the real-world atmospheric patterns of diversified extreme events. In this
work, we identify two key characteristics of extreme events: (1) the spectral
disparity against normal weather regimes, and (2) the hierarchical drivers and
geographic blending of diverse extremes. Along this line, we propose
UniExtreme, a universal extreme weather forecasting foundation model that
integrates (1) an Adaptive Frequency Modulation (AFM) module that captures
region-wise spectral differences between normal and extreme weather, through
learnable Beta-distribution filters and multi-granularity spectral aggregation,
and (2) an Event Prior Augmentation (EPA) module which incorporates
region-specific extreme event priors to resolve hierarchical extreme diversity
and composite extreme schema, via a dual-level memory fusion network. Extensive
experiments demonstrate that UniExtreme outperforms state-of-the-art baselines
in both extreme and general weather forecasting, showcasing superior
adaptability across diverse extreme scenarios.

</details>


### [691] [Regression Augmentation With Data-Driven Segmentation](https://arxiv.org/abs/2508.01455)
*Shayan Alahyari,Shiva Mehdipour Ghobadlou,Mike Domaratzki*

Main category: cs.LG

TL;DR: 该研究提出了一种新的数据增强框架，用于解决不平衡回归问题。该框架利用GMM和最近邻匹配自动识别和丰富稀有样本，并在多项测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的不平衡回归方法通常依赖固定的、临时的阈值来将样本标记为稀有或常见，这忽略了联合特征-目标空间的连续复杂性，并且未能准确表示真实的潜在稀有区域。

Method: 提出了一种完全数据驱动的、基于GAN的数据增强框架。该框架利用马氏距离-高斯混合模型（GMM）来自动识别少数类样本，并采用确定性最近邻匹配来丰富稀疏区域。

Result: 在32个基准不平衡回归数据集上的评估表明，该方法在数据增强方面持续优于最先进的方法。

Conclusion: 所提出的基于GAN的数据增强框架通过使用马氏距离-高斯混合模型（GMM）自动识别少数类样本，并采用确定性最近邻匹配来丰富稀疏区域，能够有效地处理不平衡回归问题。该方法能够让数据自行确定哪些样本是稀有样本，而不是依赖预设的阈值。

Abstract: Imbalanced regression arises when the target distribution is skewed, causing
models to focus on dense regions and struggle with underrepresented (minority)
samples. Despite its relevance across many applications, few methods have been
designed specifically for this challenge. Existing approaches often rely on
fixed, ad hoc thresholds to label samples as rare or common, overlooking the
continuous complexity of the joint feature-target space and fail to represent
the true underlying rare regions. To address these limitations, we propose a
fully data-driven GAN-based augmentation framework that uses
Mahalanobis-Gaussian Mixture Modeling (GMM) to automatically identify minority
samples and employs deterministic nearest-neighbour matching to enrich sparse
regions. Rather than preset thresholds, our method lets the data determine
which observations are truly rare. Evaluation on 32 benchmark imbalanced
regression datasets demonstrates that our approach consistently outperforms
state-of-the-art data augmentation methods.

</details>


### [692] [Fast and scalable retrosynthetic planning with a transformer neural network and speculative beam search](https://arxiv.org/abs/2508.01459)
*Mikhail Andronov,Natalia Andronova,Michael Wand,Jürgen Schmidhuber,Djork-Arné Clevert*

Main category: cs.LG

TL;DR: 通过投机性束搜索和Medusa起草策略，加速了CASP系统，提高了高通量筛选的效率。


<details>
  <summary>Details</summary>
Motivation: AI驱动的药物发现工作流程需要AI驱动的计算机辅助合成规划（CASP）系统，但其高延迟限制了它们在从头药物设计中的高通量可合成性筛选的效用。

Method: 提出了一种加速依赖于SMILES到SMILES变换器作为单步逆合成模型的步骤合成规划系统的方法。该方法通过投机性束搜索和一种名为Medusa的可扩展起草策略，降低了为AiZynthFinder提供支持的步骤合成规划的SMILES到SMILES变换器的延迟。

Result: 与标准的束搜索相比，该方法可以使CASP系统在几秒钟的相同时间限制内解决多26%到86%的分子。

Conclusion: 该方法使基于AI的CASP系统更接近于满足高通量可合成性筛选的严格延迟要求，并改善了整体用户体验。

Abstract: AI-based computer-aided synthesis planning (CASP) systems are in demand as
components of AI-driven drug discovery workflows. However, the high latency of
such CASP systems limits their utility for high-throughput synthesizability
screening in de novo drug design. We propose a method for accelerating
multi-step synthesis planning systems that rely on SMILES-to-SMILES
transformers as single-step retrosynthesis models. Our approach reduces the
latency of SMILES-to-SMILES transformers powering multi-step synthesis planning
in AiZynthFinder through speculative beam search combined with a scalable
drafting strategy called Medusa. Replacing standard beam search with our
approach allows the CASP system to solve 26\% to 86\% more molecules under the
same time constraints of several seconds. Our method brings AI-based CASP
systems closer to meeting the strict latency requirements of high-throughput
synthesizability screening and improving general user experience.

</details>


### [693] [HT-Transformer: Event Sequences Classification by Accumulating Prefix Information with History Tokens](https://arxiv.org/abs/2508.01474)
*Ivan Karpukhin,Andrey Savchenko*

Main category: cs.LG

TL;DR: Transformer在序列预测任务上不如RNN？问题在于缺少历史状态。本研究提出“历史标记”概念，通过累积历史信息，提升Transformer在金融、电商、医疗等领域的预测能力。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在序列数据建模任务中表现出色，但在预测未来目标等分类任务上却不如RNN。这种性能差距的原因尚未得到充分研究。本研究旨在探索Transformer在此类任务上的局限性，并提出改进方法。

Method: 提出了一种名为“历史标记”（history tokens）的新概念，旨在解决Transformer在序列数据分类任务中表现不如RNN的问题。具体来说，该方法通过在预训练过程中累积历史信息，弥补了Transformer缺乏单一状态向量来紧凑有效地表示整个序列的局限性，并解决了对比学习预训练嵌入向量未能捕捉局部上下文的问题。

Result: 通过引入历史标记（history tokens），本研究提出的方法显著提升了Transformer模型在序列数据分类任务上的性能，在金融、电子商务和医疗保健等领域的任务中取得了显著成果。

Conclusion: Transformer模型在包含事件序列、时间点过程和不规则时间序列的序列数据建模任务中，虽然广泛应用于各种场景，但在预测未来目标等分类任务上表现不如RNN。本研究提出的历史标记（history tokens）方法，通过在预训练中累积历史信息，显著提升了Transformer在金融、电子商务和医疗保健等领域的预测能力。

Abstract: Deep learning has achieved remarkable success in modeling sequential data,
including event sequences, temporal point processes, and irregular time series.
Recently, transformers have largely replaced recurrent networks in these tasks.
However, transformers often underperform RNNs in classification tasks where the
objective is to predict future targets. The reason behind this performance gap
remains largely unexplored. In this paper, we identify a key limitation of
transformers: the absence of a single state vector that provides a compact and
effective representation of the entire sequence. Additionally, we show that
contrastive pretraining of embedding vectors fails to capture local context,
which is crucial for accurate prediction. To address these challenges, we
introduce history tokens, a novel concept that facilitates the accumulation of
historical information during next-token prediction pretraining. Our approach
significantly improves transformer-based models, achieving impressive results
in finance, e-commerce, and healthcare tasks. The code is publicly available on
GitHub.

</details>


### [694] [Hyperparameter-Free Neurochaos Learning Algorithm for Classification](https://arxiv.org/abs/2508.01478)
*Akhila Henry,Nithin Nagaraj*

Main category: cs.LG

TL;DR: AutochaosNet 是 NL 的一个无需训练和超参数调整的变体，性能优越且计算高效。


<details>
  <summary>Details</summary>
Motivation: Neurochaos Learning (NL) 框架虽然性能优越，但需要手动调整多个超参数，并且计算每个输入样本的四个混沌特征，这带来了复杂性。因此，需要一种更高效、更易于使用的变体。

Method: 提出了一种名为 AutochaosNet 的新框架，它是 NL 算法的一种无超参数变体。该方法利用源自 Champernowne 常数的通用混沌序列，并通过输入刺激来定义用于特征提取的 firing time 界限。同时评估了两种简化变体 TM AutochaosNet 和 TM-FR AutochaosNet。

Result: AutochaosNet 实现了具有竞争性或更优的分类性能，同时大大减少了训练时间，因为它简化了计算。此外，AutochaosNet 能够消除训练和超参数调整的需要，并表现出良好的泛化能力。

Conclusion: AutochaosNet 是一种新颖的、无超参数的神经混沌学习 (NL) 变体，它利用基于 Champernowne 常数的通用混沌序列，通过输入刺激定义的firing time界限来提取特征。与现有的 ChaosNet 相比，AutochaosNet 在不进行训练和超参数优化的前提下，实现了具有竞争性甚至更优的分类性能，同时显著减少了计算量和训练时间。该方法还展现了出色的泛化能力，适用于实际分类任务。

Abstract: Neurochaos Learning (NL) is a brain-inspired classification framework that
employs chaotic dynamics to extract features from input data and yields state
of the art performance on classification tasks. However, NL requires the tuning
of multiple hyperparameters and computing of four chaotic features per input
sample. In this paper, we propose AutochaosNet - a novel, hyperparameter-free
variant of the NL algorithm that eliminates the need for both training and
parameter optimization. AutochaosNet leverages a universal chaotic sequence
derived from the Champernowne constant and uses the input stimulus to define
firing time bounds for feature extraction. Two simplified variants - TM
AutochaosNet and TM-FR AutochaosNet - are evaluated against the existing NL
architecture - ChaosNet. Our results demonstrate that AutochaosNet achieves
competitive or superior classification performance while significantly reducing
training time due to reduced computational effort. In addition to eliminating
training and hyperparameter tuning, AutochaosNet exhibits excellent
generalisation capabilities, making it a scalable and efficient choice for
real-world classification tasks. Future work will focus on identifying
universal orbits under various chaotic maps and incorporating them into the NL
framework to further enhance performance.

</details>


### [695] [Training Dynamics of the Cooldown Stage in Warmup-Stable-Decay Learning Rate Scheduler](https://arxiv.org/abs/2508.01483)
*Aleksandr Dremov,Alexander Hägele,Atli Kosson,Martin Jaggi*

Main category: cs.LG

TL;DR: Transformer训练中，学习率调度器的冷却阶段对模型性能至关重要。本研究分析了冷却阶段的机制，发现衰减曲线形状和AdamW的β2超参数会显著影响模型性能，并提供了实际的调优建议。


<details>
  <summary>Details</summary>
Motivation: Transformer训练中学习率衰减阶段（特别是最后的冷却阶段）的机制理解不足，该阶段对模型性能有重要影响。

Method: 通过对WSD学习率调度器衰减阶段进行全面分析，包括不同衰减形状和AdamW超参数的影响，并结合损失景观可视化进行解释。

Result: 衰减曲线形状反映了偏差-方差权衡，平衡探索与利用的曲线表现更优。AdamW超参数中的β2值对性能有显著影响，更高的β2值通常带来持续的性能提升。损失景观分析支持了“河谷”损失观点。

Conclusion: 研究揭示了学习率衰减阶段对Transformer训练至关重要，并提供了关于WSD调度器和AdamW超参数的实用配置建议，强调了优化衰减阶段的重要性。

Abstract: Learning rate scheduling is essential in transformer training, where the
final annealing plays a crucial role in getting the best performance. However,
the mechanisms behind this cooldown phase, with its characteristic drop in
loss, remain poorly understood. To address this, we provide a comprehensive
analysis focusing solely on the cooldown phase in the Warmup-Stable-Decay (WSD)
learning rate scheduler. Our analysis reveals that different cooldown shapes
reveal a fundamental bias-variance trade-off in the resulting models, with
shapes that balance exploration and exploitation consistently outperforming
alternatives. Similarly, we find substantial performance variations
$\unicode{x2013}$ comparable to those from cooldown shape selection
$\unicode{x2013}$ when tuning AdamW hyperparameters. Notably, we observe
consistent improvements with higher values of $\beta_2$ during cooldown. From a
loss landscape perspective, we provide visualizations of the landscape during
cooldown, supporting the river valley loss perspective empirically. These
findings offer practical recommendations for configuring the WSD scheduler in
transformer training, emphasizing the importance of optimizing the cooldown
phase alongside traditional hyperparameter tuning.

</details>


### [696] [Instruction-based Time Series Editing](https://arxiv.org/abs/2508.01504)
*Jiaxing Qiu,Dongliang Guo,Brynne Sullivan,Teague R. Henry,Tom Hartvigsen*

Main category: cs.LG

TL;DR: InstructTime 是一种新的时间序列编辑器，它使用自然语言指令来编辑时间序列，实现了更高的灵活性和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的时间序列编辑器依赖于僵化的、预定义的属性向量作为条件，并且通过采样产生全或无的编辑，这限制了条件格式的灵活性，并且缺乏对编辑强度的可定制控制。为了克服这些限制，研究人员提出了基于指令的时间序列编辑。

Method: InstructTime 通过将时间序列和自然语言指令嵌入到一个共享的多模态表示空间，然后解码这些嵌入来生成编辑后的时间序列。它使用多分辨率编码器来处理局部和全局编辑，并通过学习到的表示空间中的插值来实现不同程度的编辑。

Result: 实验表明，InstructTime 在合成和真实数据集上均达到了最先进的性能，能够生成高质量且编辑强度可控的时间序列，并且能够泛化到未知的指令，还可以通过少样本学习适应新的条件。

Conclusion: InstructTime 是一个先进的时间序列编辑工具，能够根据自然语言指令生成高质量、可控强度的编辑，并且能够泛化到未见过的指令，还可以通过少样本学习轻松适应未见过的条件。

Abstract: In time series editing, we aim to modify some properties of a given time
series without altering others. For example, when analyzing a hospital
patient's blood pressure, we may add a sudden early drop and observe how it
impacts their future while preserving other conditions. Existing
diffusion-based editors rely on rigid, predefined attribute vectors as
conditions and produce all-or-nothing edits through sampling. This attribute-
and sampling-based approach limits flexibility in condition format and lacks
customizable control over editing strength. To overcome these limitations, we
introduce Instruction-based Time Series Editing, where users specify intended
edits using natural language. This allows users to express a wider range of
edits in a more accessible format. We then introduce InstructTime, the first
instruction-based time series editor. InstructTime takes in time series and
instructions, embeds them into a shared multi-modal representation space, then
decodes their embeddings to generate edited time series. By learning a
structured multi-modal representation space, we can easily interpolate between
embeddings to achieve varying degrees of edit. To handle local and global edits
together, we propose multi-resolution encoders. In our experiments, we use
synthetic and real datasets and find that InstructTime is a state-of-the-art
time series editor: InstructTime achieves high-quality edits with controllable
strength, can generalize to unseen instructions, and can be easily adapted to
unseen conditions through few-shot learning.

</details>


### [697] [ESM: A Framework for Building Effective Surrogate Models for Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2508.01505)
*Azaz-Ur-Rehman Nasir,Samroz Ahmad Shoaib,Muhammad Abdullah Hanif,Muhammad Shafique*

Main category: cs.LG

TL;DR: 该研究针对GPU设备上的硬件感知NAS，研究并优化了用于预测模型延迟的代理模型，通过系统性分析提出了一种包含数据集生成和模型生成在内的整体框架，以提高预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的设备上为深度神经网络（DNN）设计高效的硬件感知神经网络架构搜索（NAS），并解决现有代理模型在硬件感知NAS中的不足，特别是针对GPU设备。

Method: 通过对不同代理模型进行系统性分析，研究影响预测准确性的各种因素，并确定影响GPU设备上模型延迟预测准确性的关键阶段和方法。

Result: 得出了关于影响代理模型准确性的因素的见解，并提出了一个能够可靠地生成数据集和高效地生成模型（考虑模型生成流程各阶段的总体成本）的整体框架。

Conclusion: 提出的框架能够通过可靠的数据集生成和高效的模型生成，并考虑模型生成流程各阶段的总体成本，从而实现对GPU设备上模型延迟的准确预测。

Abstract: Hardware-aware Neural Architecture Search (NAS) is one of the most promising
techniques for designing efficient Deep Neural Networks (DNNs) for
resource-constrained devices. Surrogate models play a crucial role in
hardware-aware NAS as they enable efficient prediction of performance
characteristics (e.g., inference latency and energy consumption) of different
candidate models on the target hardware device. In this paper, we focus on
building hardware-aware latency prediction models. We study different types of
surrogate models and highlight their strengths and weaknesses. We perform a
systematic analysis to understand the impact of different factors that can
influence the prediction accuracy of these models, aiming to assess the
importance of each stage involved in the model designing process and identify
methods and policies necessary for designing/training an effective estimation
model, specifically for GPU-powered devices. Based on the insights gained from
the analysis, we present a holistic framework that enables reliable dataset
generation and efficient model generation, considering the overall costs of
different stages of the model generation pipeline.

</details>


### [698] [FlashSVD: Memory-Efficient Inference with Streaming for Low-Rank Models](https://arxiv.org/abs/2508.01506)
*Zishan Shao,Yixiao Wang,Qinsi Wang,Ting Jiang,Zhixu Du,Hancheng Ye,Danyang Zhuo,Yiran Chen,Hai Li*

Main category: cs.LG

TL;DR: FlashSVD通过优化SVD压缩LLM的推理过程，显著减少了内存占用，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于SVD的LLM压缩方法主要关注减少模型权重占用的内存，但忽略了在推理过程中使用截断因子通过标准密集CUDA内核时产生的额外激活内存开销。这种激活开销会随着序列长度和隐藏维度的增加而增加，导致现有SVD压缩技术无法在峰值推理内存方面实现任何缩减，限制了其在真实设备上部署的可行性。

Method: 提出了一种名为FlashSVD的新型端到端感知秩的流式推理框架，用于SVD压缩的大型语言模型。该框架通过将低秩投影核融合到自注意力和前馈网络（FFN）流水线中，避免了物化全尺寸激活缓冲区，而是将截断因子的微小块加载到片上SRAM中，即时进行乘法和归约，并立即逐出，从而在不增加额外延迟的情况下保持高GPU占用率。

Result: FlashSVD在标准编码器基准（如BERT-Base）上，将峰值激活内存减少了高达70.2%，中间瞬态内存减少了75%，并且在与上游压缩方法结合使用时没有准确性损失。

Conclusion: FlashSVD通过将低秩投影核与自注意力（self-attention）和前馈网络（FFN）流水线融合，实现了高达70.2%的峰值激活内存削减和75%的中间瞬态内存削减，同时不损失准确性，为低秩LLM在内存受限环境下的部署提供了实用途径。

Abstract: Singular Value Decomposition (SVD) has recently seen a surge of interest as a
simple yet powerful tool for large language models (LLMs) compression, with a
growing number of works demonstrating 20-80% parameter reductions at minimal
accuracy loss. Previous SVD-based approaches have focused primarily on reducing
the memory footprint of model weights, largely overlooking the additional
activation memory overhead incurred during inference when applying truncated
factors via standard dense CUDA kernels. Our experiments demonstrate that this
activation overhead, scaling with sequence length and hidden dimension,
prevents current SVD compression techniques from achieving any reduction in
peak inference memory, thereby limiting their viability for real-world,
on-device deployments.
  We introduce FlashSVD, a novel, end-to-end rank-aware streaming inference
framework specifically designed for SVD-compressed large language models.
FlashSVD can be seamlessly integrated with any model that employs SVD-based
methods for parameter reduction. By fusing low-rank projection kernels directly
into both the self-attention and feed-forward network (FFN) pipelines, FlashSVD
avoid materializing full-size activation buffers. Instead, small tiles of the
truncated factors are loaded into on-chip SRAM, multiplied and reduced on the
fly, and immediately evicted, preserving high GPU occupancy and adding no extra
latency. On standard encoder benchmarks (e.g., BERT-Base), FlashSVD cuts peak
activation memory by up to 70.2% and intermediate transient memory by 75%, all
while incur no accuracy loss with upstreaming compression methods, offering a
practical path toward memory-constrained deployment of low-rank LLMs.

</details>


### [699] [Frequency-Constrained Learning for Long-Term Forecasting](https://arxiv.org/abs/2508.01508)
*Menglin Kong,Vincent Zhihao Zheng,Lijun Sun*

Main category: cs.LG

TL;DR: 通过 FFT 和双速学习来增强长序列预测，以捕捉周期性模式。


<details>
  <summary>Details</summary>
Motivation: 现代深度预测模型常因频谱偏差和缺乏频率感知归纳先验而无法捕捉真实世界时间序列中的周期性结构。

Method: 通过快速傅里叶变换（FFT）引导的坐标下降法提取主导低频分量，并用这些分量初始化正弦嵌入。采用双速学习计划在训练过程中保留有意义的频率结构。该方法模型无关，可与现有的基于 Transformer 的架构无缝集成。

Result: 在多样化的真实世界基准测试中，该方法在长序列预测任务上，特别是在长预测范围下，展现了一致的性能提升。在合成数据上，该方法能够准确恢复真实频率。

Conclusion: 该方法通过显式建模周期性，在长序列预测任务上展现了一致的性能提升，特别是在长预测范围下，突出了注入频谱先验以实现鲁棒且可解释的远程预测的优势。此外，在合成数据上，该方法能准确恢复真实频率，进一步验证了其捕获潜在周期性模式的有效性和可解释性。

Abstract: Many real-world time series exhibit strong periodic structures arising from
physical laws, human routines, or seasonal cycles. However, modern deep
forecasting models often fail to capture these recurring patterns due to
spectral bias and a lack of frequency-aware inductive priors. Motivated by this
gap, we propose a simple yet effective method that enhances long-term
forecasting by explicitly modeling periodicity through spectral initialization
and frequency-constrained optimization. Specifically, we extract dominant
low-frequency components via Fast Fourier Transform (FFT)-guided coordinate
descent, initialize sinusoidal embeddings with these components, and employ a
two-speed learning schedule to preserve meaningful frequency structure during
training. Our approach is model-agnostic and integrates seamlessly into
existing Transformer-based architectures. Extensive experiments across diverse
real-world benchmarks demonstrate consistent performance gains--particularly at
long horizons--highlighting the benefits of injecting spectral priors into deep
temporal models for robust and interpretable long-range forecasting. Moreover,
on synthetic data, our method accurately recovers ground-truth frequencies,
further validating its interpretability and effectiveness in capturing latent
periodic patterns.

</details>


### [700] [A Reward-Directed Diffusion Framework for Generative Design Optimization](https://arxiv.org/abs/2508.01509)
*Hadi Keramati,Patrick Kirchen,Mohammed Hannan,Rajeev K. Jaiman*

Main category: cs.LG

TL;DR: A new generative optimization framework uses diffusion models and reward-directed sampling to create better engineering designs (like ships and airfoils) more efficiently, achieving significant performance improvements beyond the original data.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this research is to develop an efficient generative optimization framework for engineering designs, particularly for scenarios where performance metrics are computationally expensive or non-differentiable. The goal is to improve design performance beyond existing data distributions.

Method: This study presents a generative optimization framework that employs a fine-tuned diffusion model combined with reward-directed sampling. It utilizes a parametric representation for design geometry and incorporates an iterative soft value function within a Markov decision process framework for reward-guided decoding during both training and inference.

Result: Empirical results demonstrate substantial improvements in engineering design tasks, including a greater than 25 percent reduction in resistance for 3D ship hull design and over a 10 percent improvement in the lift-to-drag ratio for 2D airfoil design. The framework successfully generates samples that outperform the training data.

Conclusion: The proposed generative optimization framework, utilizing a fine-tuned diffusion model and reward-directed sampling, significantly enhances engineering design by generating high-performance designs that extend beyond the training data distribution. This approach offers substantial improvements in efficiency and design outcomes for complex engineering problems.

Abstract: This study presents a generative optimization framework that builds on a
fine-tuned diffusion model and reward-directed sampling to generate
high-performance engineering designs. The framework adopts a parametric
representation of the design geometry and produces new parameter sets
corresponding to designs with enhanced performance metrics. A key advantage of
the reward-directed approach is its suitability for scenarios in which
performance metrics rely on costly engineering simulations or surrogate models
(e.g. graph-based, ensemble models, or tree-based) are non-differentiable or
prohibitively expensive to differentiate. This work introduces the iterative
use of a soft value function within a Markov decision process framework to
achieve reward-guided decoding in the diffusion model. By incorporating
soft-value guidance during both the training and inference phases, the proposed
approach reduces computational and memory costs to achieve high-reward designs,
even beyond the training data. Empirical results indicate that this iterative
reward-directed method substantially improves the ability of the diffusion
models to generate samples with reduced resistance in 3D ship hull design and
enhanced hydrodynamic performance in 2D airfoil design tasks. The proposed
framework generates samples that extend beyond the training data distribution,
resulting in a greater 25 percent reduction in resistance for ship design and
over 10 percent improvement in the lift-to-drag ratio for the 2D airfoil
design. Successful integration of this model into the engineering design life
cycle can enhance both designer productivity and overall design performance.

</details>


### [701] [Canoe Paddling Quality Assessment Using Smart Devices: Preliminary Machine Learning Study](https://arxiv.org/abs/2508.01511)
*S. Parab,A. Lamelas,A. Hassan,P. Bhote*

Main category: cs.LG

TL;DR: 本研究提出了一种利用智能手表和智能手机收集的运动数据，并通过大型语言模型提供反馈的人工智能划水教学系统，旨在降低学习成本，提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 尽管桨运动很受欢迎，但机器学习（ML）的整合有限，并且受到教练和专用设备成本的限制。

Method: 本研究提出了一种新颖的基于人工智能的教学系统，该系统使用在运动数据上训练的机器学习模型，并通过大型语言模型提供划水反馈。

Result: 在本研究中，采用了四名参与者，八次试验，产生了 66 次划水样本。最厉害的算法是极其随机的树模型，在五折交叉验证下达到了 0.9496 的 F 分数。web界面成功提供了定量指标和定性反馈。手腕附近的传感器放置提高了数据质量。

Conclusion: 智能手表和智能手机可以为传统桨运动指导提供低成本、可及的替代方案。

Abstract: Over 22 million Americans participate in paddling-related activities
annually, contributing to a global paddlesports market valued at 2.4 billion US
dollars in 2020. Despite its popularity, the sport has seen limited integration
of machine learning (ML) and remains hindered by the cost of coaching and
specialized equipment. This study presents a novel AI-based coaching system
that uses ML models trained on motion data and delivers stroke feedback via a
large language model (LLM). Participants were recruited through a collaboration
with the NYU Concrete Canoe Team. Motion data were collected across two
sessions, one with suboptimal form and one with corrected technique, using
Apple Watches and smartphones secured in sport straps. The data underwent
stroke segmentation and feature extraction. ML models, including Support Vector
Classifier, Random Forest, Gradient Boosting, and Extremely Randomized Trees,
were trained on both raw and engineered features. A web based interface was
developed to visualize stroke quality and deliver LLM-based feedback. Across
four participants, eight trials yielded 66 stroke samples. The Extremely
Randomized Tree model achieved the highest performance with an F score of
0.9496 under five fold cross validation. The web interface successfully
provided both quantitative metrics and qualitative feedback. Sensor placement
near the wrists improved data quality. Preliminary results indicate that
smartwatches and smartphones can enable low cost, accessible alternatives to
traditional paddling instruction. While limited by sample size, the study
demonstrates the feasibility of using consumer devices and ML to support stroke
refinement and technique improvement.

</details>


### [702] [SimDeep: Federated 3D Indoor Localization via Similarity-Aware Aggregation](https://arxiv.org/abs/2508.01515)
*Ahmed Jaheen,Sarah Elsamanody,Hamada Rizk,Moustafa Youssef*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Indoor localization plays a pivotal role in supporting a wide array of
location-based services, including navigation, security, and context-aware
computing within intricate indoor environments. Despite considerable
advancements, deploying indoor localization systems in real-world scenarios
remains challenging, largely because of non-independent and identically
distributed (non-IID) data and device heterogeneity. In response, we propose
SimDeep, a novel Federated Learning (FL) framework explicitly crafted to
overcome these obstacles and effectively manage device heterogeneity. SimDeep
incorporates a Similarity Aggregation Strategy, which aggregates client model
updates based on data similarity, significantly alleviating the issues posed by
non-IID data. Our experimental evaluations indicate that SimDeep achieves an
impressive accuracy of 92.89%, surpassing traditional federated and centralized
techniques, thus underscoring its viability for real-world deployment.

</details>


### [703] [Prototype Learning to Create Refined Interpretable Digital Phenotypes from ECGs](https://arxiv.org/abs/2508.01521)
*Sahil Sethi,David Chen,Michael C. Burkhart,Nipun Bhandari,Bashar Ramadan,Brett Beaulieu-Jones*

Main category: cs.LG

TL;DR: 原型网络能从心电图中学习到与临床疾病（包括非心脏疾病）相关的、可解释的生理特征，这些特征比传统方法更能反映临床表型。


<details>
  <summary>Details</summary>
Motivation: 评估原型驱动的神经网络在生理数据分类中学习到的原型是否捕获了与更广泛临床表型（以Phecodes表示）相关的潜在结构，以及这些原型是否比传统的分类预测或NLP提取的概念更能提供可解释的临床见解。

Method: 使用原型驱动的深度学习模型对PTB-XL数据集进行心电图多标签分类训练，并在未修改的情况下将该模型应用于MIMIC-IV临床数据库进行推理。通过分析单个原型与Phecodes（基于ICD编码的表型分类系统）的关联性，以及原型类别内的距离，来评估模型是否学习到了与临床表型一致的潜在结构。

Result: 单个原型与临床结果（Phecodes）的关联性显著强于分类预测、NLP提取概念或更广泛的原型类别。原型类别内存在显著的距离差异（p < 0.0001），表明模型能够区分临床上有意义的变异。模型在预测心房颤动和心力衰竭等心脏病时表现出高AUC值（分别为0.89和0.91），同时也能对败血症和肾病等非心脏疾病提供有意义的信号。

Conclusion: 原型驱动的深度学习模型能够从生理时间序列数据中提取可解释的、可迁移的中间表型，这些表型能够捕捉到超出其原始训练目标的临床意义生理特征，从而支持可解释的数字表型分析。

Abstract: Prototype-based neural networks offer interpretable predictions by comparing
inputs to learned, representative signal patterns anchored in training data.
While such models have shown promise in the classification of physiological
data, it remains unclear whether their prototypes capture an underlying
structure that aligns with broader clinical phenotypes. We use a
prototype-based deep learning model trained for multi-label ECG classification
using the PTB-XL dataset. Then without modification we performed inference on
the MIMIC-IV clinical database. We assess whether individual prototypes,
trained solely for classification, are associated with hospital discharge
diagnoses in the form of phecodes in this external population. Individual
prototypes demonstrate significantly stronger and more specific associations
with clinical outcomes compared to the classifier's class predictions,
NLP-extracted concepts, or broader prototype classes across all phecode
categories. Prototype classes with mixed significance patterns exhibit
significantly greater intra-class distances (p $<$ 0.0001), indicating the
model learned to differentiate clinically meaningful variations within
diagnostic categories. The prototypes achieve strong predictive performance
across diverse conditions, with AUCs ranging from 0.89 for atrial fibrillation
to 0.91 for heart failure, while also showing substantial signal for
non-cardiac conditions such as sepsis and renal disease. These findings suggest
that prototype-based models can support interpretable digital phenotyping from
physiologic time-series data, providing transferable intermediate phenotypes
that capture clinically meaningful physiologic signatures beyond their original
training objectives.

</details>


### [704] [Unsupervised Learning for the Elementary Shortest Path Problem](https://arxiv.org/abs/2508.01557)
*Jingyi Chen,Xinyuan Zhang,Xinwu Qian*

Main category: cs.LG

TL;DR: 提出了一种基于无监督图神经网络的概率方法，用于解决NP难的ESPP问题。该方法通过学习节点价值和边选择概率，有效处理负成本循环，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: ESPP在存在负成本循环时是一个NP难问题，这促使研究者寻找高效的近似算法。本研究的动机是开发一种能够处理负成本循环并找到接近最优解的概率方法。

Method: 提出了一种利用无监督图神经网络的概率方法，通过联合学习节点价值估计和边选择概率，并使用替代损失函数来解决负成本循环问题，从而找到接近最优的ESPP。

Result: 实验结果表明，该方法在100个节点规模的图上，其性能优于无监督基线和经典启发式方法，并且在跨尺寸和跨拓扑的泛化测试中表现出色。

Conclusion: 该方法在看不见的合成图上表现出高选择性和高适应性，这表明了其在各种图结构上的潜在应用前景。

Abstract: The Elementary Shortest-Path Problem(ESPP) seeks a minimum cost path from s
to t that visits each vertex at most once. The presence of negative-cost cycles
renders the problem NP-hard. We present a probabilistic method for finding
near-optimal ESPP, enabled by an unsupervised graph neural network that jointly
learns node value estimates and edge-selection probabilities via a surrogate
loss function. The loss provides a high probability certificate of finding
near-optimal ESPP solutions by simultaneously reducing negative-cost cycles and
embedding the desired algorithmic alignment. At inference time, a decoding
algorithm transforms the learned edge probabilities into an elementary path.
Experiments on graphs of up to 100 nodes show that the proposed method
surpasses both unsupervised baselines and classical heuristics, while
exhibiting high performance in cross-size and cross-topology generalization on
unseen synthetic graphs.

</details>


### [705] [KANMixer: Can KAN Serve as a New Modeling Core for Long-term Time Series Forecasting?](https://arxiv.org/abs/2508.01575)
*Lingyu Jiang,Yuping Wang,Yao Su,Shuo Xing,Wenjing Chen,Xin Zhang,Zhengzhong Tu,Ziming Zhang,Fangzhou Lin,Michael Zielewski,Kazunori D Yamada*

Main category: cs.LG

TL;DR: 本文提出了一种基于KAN的LTSF模型KANMixer，相比于MLP模型，它能更好地处理时间序列的局部性和序列性，并在多项基准测试中取得了优越性能，同时提供了关于如何有效利用KAN的实践指导。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有MLP-based模型在LTSF任务中存在的局限性，例如忽略了层次局部性和序列归纳偏置，并且性能提升逐渐减小，本文探索了使用KAN作为新的建模核心的可能性。

Method: 本文提出了一种名为KANMixer的全新LTSF模型，该模型整合了多尺度的混合骨干网络，并充分利用了KAN（Kolmogorov-Arnold Networks）的自适应能力。KAN是一种新提出的模型，具有自适应基函数，能够进行精细、局部的非线性调制。

Result: KANMixer在7个基准数据集的28项实验中，有16项取得了最先进的性能。研究还系统地分析了KANMixer与传统MLP架构的优势和局限性，发现KAN的可学习基函数显著影响了预测性能，并识别了影响预测准确性的关键设计因素。

Conclusion: KANMixer在16项（占28项）的实验中取得了最先进的性能，并且通过分析揭示了KAN的可学习基函数能够显著地改变网络结构先验对预测性能的影响，并为在LTSF中有效利用KAN提供了实用的见解和经验性指导。

Abstract: In recent years, multilayer perceptrons (MLP)-based deep learning models have
demonstrated remarkable success in long-term time series forecasting (LTSF).
Existing approaches typically augment MLP backbones with hand-crafted external
modules to address the inherent limitations of their flat architectures.
Despite their success, these augmented methods neglect hierarchical locality
and sequential inductive biases essential for time-series modeling, and recent
studies indicate diminishing performance improvements. To overcome these
limitations, we explore Kolmogorov-Arnold Networks (KAN), a recently proposed
model featuring adaptive basis functions capable of granular, local modulation
of nonlinearities. This raises a fundamental question: Can KAN serve as a new
modeling core for LTSF? To answer this, we introduce KANMixer, a concise
architecture integrating a multi-scale mixing backbone that fully leverages
KAN's adaptive capabilities. Extensive evaluation demonstrates that KANMixer
achieves state-of-the-art performance in 16 out of 28 experiments across seven
benchmark datasets. To uncover the reasons behind this strong performance, we
systematically analyze the strengths and limitations of KANMixer in comparison
with traditional MLP architectures. Our findings reveal that the adaptive
flexibility of KAN's learnable basis functions significantly transforms the
influence of network structural prior on forecasting performance. Furthermore,
we identify critical design factors affecting forecasting accuracy and offer
practical insights for effectively utilizing KAN in LTSF. Together, these
insights constitute the first empirically grounded guidelines for effectively
leveraging KAN in LTSF. Code is available in the supplementary file.

</details>


### [706] [Dynamic Clustering for Personalized Federated Learning on Heterogeneous Edge Devices](https://arxiv.org/abs/2508.01580)
*Heting Liu,Junzhe Huang,Fang He,Guohong Cao*

Main category: cs.LG

TL;DR: DC-PFL通过动态聚类和模型不一致性度量来处理联邦学习中的数据异构性，并提出了一种层级聚合机制来降低通信成本，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为解决联邦学习（FL）中客户端数据异构性导致的模型性能不佳问题。

Method: 提出了一种名为DC-PFL的动态聚类算法，并引入了基于模型权重的模型不一致性度量来估计数据异构性。同时，提出了一种基于训练损失下降曲线的聚类结构调整算法和层级聚合机制，以降低通信成本。

Result: DC-PFL在多个数据集的广泛实验中，相较于基线方法，显著减少了总训练时间并提高了模型准确性。

Conclusion: DC-PFL通过动态聚类和层级聚合机制，有效解决了联邦学习中的数据异构性问题，显著减少了训练时间和提高了模型准确性。

Abstract: Federated Learning (FL) enables edge devices to collaboratively learn a
global model, but it may not perform well when clients have high data
heterogeneity. In this paper, we propose a dynamic clustering algorithm for
personalized federated learning system (DC-PFL) to address the problem of data
heterogeneity. DC-PFL starts with all clients training a global model and
gradually groups the clients into smaller clusters for model personalization
based on their data similarities. To address the challenge of estimating data
heterogeneity without exposing raw data, we introduce a discrepancy metric
called model discrepancy, which approximates data heterogeneity solely based on
the model weights received by the server. We demonstrate that model discrepancy
is strongly and positively correlated with data heterogeneity and can serve as
a reliable indicator of data heterogeneity. To determine when and how to change
grouping structures, we propose an algorithm based on the rapid decrease period
of the training loss curve. Moreover, we propose a layer-wise aggregation
mechanism that aggregates the low-discrepancy layers at a lower frequency to
reduce the amount of transmitted data and communication costs. We conduct
extensive experiments on various datasets to evaluate our proposed algorithm,
and our results show that DC-PFL significantly reduces total training time and
improves model accuracy compared to baselines.

</details>


### [707] [Censored Sampling for Topology Design: Guiding Diffusion with Human Preferences](https://arxiv.org/abs/2508.01589)
*Euihyun Kim,Keun Park,Yeoneung Kim*

Main category: cs.LG

TL;DR: 本工作提出了一个新颖的人类在循环扩散框架，利用基于人类反馈的奖励模型来指导拓扑优化中的扩散模型。该方法通过检测和惩罚浮动机体和边界违规等故障模式来改进设计，而无需重新训练扩散模型，从而提高设计的可制造性和现实性。


<details>
  <summary>Details</summary>
Motivation: 尽管去噪扩散模型在拓扑优化结构生成方面取得了进展，但它们通常依赖于可能无法捕捉到人类专家显而易见的细微但关键的设计缺陷（如浮动机体或边界不连续性）的代理预测器。因此，本工作旨在弥合自动化设计生成与专家判断之间的差距，提供一种可信生成设计的可扩展解决方案。

Method: 本工作提出了一种新颖的人类在循环扩散框架，通过利用基于少量人类反馈训练的轻量级奖励模型来指导生成过程。该方法通过调整反向扩散轨迹和基于人类对齐奖励的梯度来抑制不切实际的输出。具体来说，收集了对生成的拓扑的二元人类评估，并训练了分类器来检测浮动机体和边界违规。然后，将这些奖励模型集成到预训练的扩散生成器的采样循环中，以指导其生成既结构优越又物理合理且可制造的设计。该方法是模块化的，并且不需要重新训练扩散模型。

Result: 初步结果表明，在各种测试条件下，故障模式大大减少，设计现实性得到提高。

Conclusion: 本工作提出了一个新颖的、以人类为中心的扩散框架，该框架利用基于少量人类反馈训练的轻量级奖励模型来指导生成过程。通过收集人类对生成的拓扑的二元评估，并训练分类器来检测浮动机体和边界缺陷，从而引导生成过程产生在结构上性能优越、物理上合理且可制造的设计。

Abstract: Recent advances in denoising diffusion models have enabled rapid generation
of optimized structures for topology optimization. However, these models often
rely on surrogate predictors to enforce physical constraints, which may fail to
capture subtle yet critical design flaws such as floating components or
boundary discontinuities that are obvious to human experts. In this work, we
propose a novel human-in-the-loop diffusion framework that steers the
generative process using a lightweight reward model trained on minimal human
feedback. Inspired by preference alignment techniques in generative modeling,
our method learns to suppress unrealistic outputs by modulating the reverse
diffusion trajectory using gradients of human-aligned rewards. Specifically, we
collect binary human evaluations of generated topologies and train classifiers
to detect floating material and boundary violations. These reward models are
then integrated into the sampling loop of a pre-trained diffusion generator,
guiding it to produce designs that are not only structurally performant but
also physically plausible and manufacturable. Our approach is modular and
requires no retraining of the diffusion model. Preliminary results show
substantial reductions in failure modes and improved design realism across
diverse test conditions. This work bridges the gap between automated design
generation and expert judgment, offering a scalable solution to trustworthy
generative design.

</details>


### [708] [Why Heuristic Weighting Works: A Theoretical Analysis of Denoising Score Matching](https://arxiv.org/abs/2508.01597)
*Juyan Zhang,Rhys Newbury,Xinyang Zhang,Tin Tran,Dana Kulic,Michael Burke*

Main category: cs.LG

TL;DR: 去噪得分匹配损失的异方差性被揭示，推导了最优权重函数。常用的启发式权重函数是一阶最优权重的近似，且在某些情况下训练更稳定。


<details>
  <summary>Details</summary>
Motivation: 为了给去噪得分匹配损失中常用的启发式权重函数提供理论依据，并探索更优的权重函数以改进扩散模型的训练。研究旨在理解异方差性在去噪得分匹配目标中的作用，并将其应用于推导最优权重函数。

Method: 首先，分析了去噪得分匹配损失的性质，证明了异方差性是其固有属性。基于此，推导了适用于广义、任意阶去噪得分匹配损失的最优权重函数，无需对噪声分布做任何假设。其次，将该理论应用于扩散模型，展示了一阶公式与最优权重函数的关系，并证明了常用的启发式权重函数是一阶最优权重的泰勒近似。最后，通过理论和经验分析，比较了启发式权重和最优权重在梯度方差等方面的性能。

Result: 研究发现，异方差性是去噪得分匹配目标的一个固有属性。推导出了最优权重函数，并且常用的启发式权重函数是一阶最优权重的泰勒近似。理论和经验比较表明，启发式权重虽然简单，但在参数梯度方面具有较低的方差，有利于训练的稳定性和效率。

Conclusion: 该研究揭示了去噪得分匹配目标中的异方差性，并据此推导了最优权重函数，为扩散模型提供了理论基础。研究表明，常用的启发式权重函数是其一阶泰勒近似，并且在某些情况下，启发式权重函数能提供更低的参数梯度方差，从而实现更稳定高效的训练。

Abstract: Score matching enables the estimation of the gradient of a data distribution,
a key component in denoising diffusion models used to recover clean data from
corrupted inputs. In prior work, a heuristic weighting function has been used
for the denoising score matching loss without formal justification. In this
work, we demonstrate that heteroskedasticity is an inherent property of the
denoising score matching objective. This insight leads to a principled
derivation of optimal weighting functions for generalized, arbitrary-order
denoising score matching losses, without requiring assumptions about the noise
distribution. Among these, the first-order formulation is especially relevant
to diffusion models. We show that the widely used heuristical weighting
function arises as a first-order Taylor approximation to the trace of the
expected optimal weighting. We further provide theoretical and empirical
comparisons, revealing that the heuristical weighting, despite its simplicity,
can achieve lower variance than the optimal weighting with respect to parameter
gradients, which can facilitate more stable and efficient training.

</details>


### [709] [Drift-aware Collaborative Assistance Mixture of Experts for Heterogeneous Multistream Learning](https://arxiv.org/abs/2508.01598)
*En Yu,Jie Lu,Kun Wang,Xiaoyu Yang,Guangquan Zhang*

Main category: cs.LG

TL;DR: CAMEL是一个动态协作的专家混合学习框架，通过为每个数据流分配独立系统和私有专家，并利用辅助专家进行跨流知识转移，以及自主专家调整策略来应对概念漂移，从而提高了模型在异构和动态环境下的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理真实世界多数据流中的内在异构性和不可预测的概念漂移时存在局限性，它们通常假设数据流同质，并使用静态架构进行知识融合，这限制了它们在复杂动态环境中的泛化能力。

Method:  CAMEL框架通过为每个数据流分配独立的系统（包括特征提取器和任务特定头），利用动态的私有专家池来捕捉特定于流的模式，并通过一个具有多头注意力机制的辅助专家来实现跨异构流的协作，从而实现有针对性的知识转移。此外，还提出了自主专家调整（AET）策略，用于动态管理专家生命周期以应对概念漂移，通过实例化新专家和修剪旧专家来适应模型容量。

Result: 实验结果表明，CAMEL框架在处理各种多数据流和复杂概念漂移方面，相比现有方法具有更优越的泛化能力和更强的鲁棒性。

Conclusion: CAMEL框架在各种多数据流和复杂概念漂移场景下展现出优越的泛化能力和强大的鲁棒性。

Abstract: Learning from multiple data streams in real-world scenarios is fundamentally
challenging due to intrinsic heterogeneity and unpredictable concept drifts.
Existing methods typically assume homogeneous streams and employ static
architectures with indiscriminate knowledge fusion, limiting generalizability
in complex dynamic environments. To tackle this gap, we propose CAMEL, a
dynamic \textbf{C}ollaborative \textbf{A}ssistance \textbf{M}ixture of
\textbf{E}xperts \textbf{L}earning framework. It addresses heterogeneity by
assigning each stream an independent system with a dedicated feature extractor
and task-specific head. Meanwhile, a dynamic pool of specialized private
experts captures stream-specific idiosyncratic patterns. Crucially,
collaboration across these heterogeneous streams is enabled by a dedicated
assistance expert. This expert employs a multi-head attention mechanism to
distill and integrate relevant context autonomously from all other concurrent
streams. It facilitates targeted knowledge transfer while inherently mitigating
negative transfer from irrelevant sources. Furthermore, we propose an
Autonomous Expert Tuner (AET) strategy, which dynamically manages expert
lifecycles in response to drift. It instantiates new experts for emerging
concepts (freezing prior ones to prevent catastrophic forgetting) and prunes
obsolete ones. This expert-level plasticity provides a robust and efficient
mechanism for online model capacity adaptation. Extensive experiments
demonstrate CAMEL's superior generalizability across diverse multistreams and
exceptional resilience against complex concept drifts.

</details>


### [710] [Enhancing Math Reasoning in Small-sized LLMs via Preview Difficulty-Aware Intervention](https://arxiv.org/abs/2508.01604)
*Xinhan Di,JoyJiaoW*

Main category: cs.LG

TL;DR: 尽管强化学习在提升大型语言模型的推理能力方面发挥着关键作用，但最先进模型（如O系列、Gemini 2.5、Grok 3）的强化学习训练细节仍未公开。本研究提出了一个基于GRPO框架的EPRLI算法，并结合了难度感知干预，在1.5B LLM上取得了优于O1-Preview且媲美O1-mini的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 由于像OpenAI O系列、Claude 3系列、DeepMind的Gemini 2.5系列和Grok 3系列等最新的LLM的关键技术细节（如强化学习训练）仍然没有公开，使得研究社区难以复现它们的强化学习训练结果。因此，本研究旨在解决这一问题。

Method: 本研究从一个建立在开源GRPO框架上的早期预览强化学习（EPRLI）算法开始，并结合了针对数学问题的难度感知干预。

Result: 在1.5B参数的LLM上，我们的方法在AIME24上取得了50.0%的成绩，在Math500上取得了89.2%的成绩，在AMC上取得了77.1%的成绩，在Minerva上取得了35.3%的成绩，在OBench上取得了51.9%的成绩，超越了O1-Preview，并且在标准学校实验室设置中与O1-mini相当。

Conclusion: 通过在开源GRPO框架上构建的早期预览强化学习（EPRLI）算法，并结合了针对数学问题的难度感知干预，在1.5B参数的LLM上，我们在AIME24上达到了50.0%，在Math500上达到了89.2%，在AMC上达到了77.1%，在Minerva上达到了35.3%，在OBench上达到了51.9%，超越了O1-Preview，并在标准学校实验室环境中与O1-mini相当。

Abstract: Reinforcement learning scaling enhances the reasoning capabilities of large
language models, with reinforcement learning serving as the key technique to
draw out complex reasoning. However, key technical details of state-of-the-art
reasoning LLMs, such as those in the OpenAI O series, Claude 3 series,
DeepMind's Gemini 2.5 series, and Grok 3 series, remain undisclosed, making it
difficult for the research community to replicate their reinforcement learning
training results. Therefore, we start our study from an Early Preview
Reinforcement Learning (EPRLI) algorithm built on the open-source GRPO
framework, incorporating difficulty-aware intervention for math problems.
Applied to a 1.5B-parameter LLM, our method achieves 50.0% on AIME24, 89.2% on
Math500, 77.1% on AMC, 35.3% on Minerva, and 51.9% on OBench, superpass
O1-Preview and is comparable to O1-mini within standard school-lab settings.

</details>


### [711] [Augmented Reinforcement Learning Framework For Enhancing Decision-Making In Machine Learning Models Using External Agents](https://arxiv.org/abs/2508.01612)
*Sandesh Kumar Singh*

Main category: cs.LG

TL;DR: ARL框架通过引入人类监督代理，利用人类的洞察力来提高机器学习模型的决策能力，尤其是在处理复杂或模糊的环境时，能够显著提升模型的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决强化学习中“垃圾进，垃圾出”问题导致的模型决策能力下降，通过引入外部监督代理来改进模型的决策过程。

Method: 提出了一种新颖的增强强化学习（ARL）框架，该框架引入了外部监督代理来纠正模型的决策，并优先处理“垃圾进，垃圾出”问题。ARL框架包含两个外部代理：一个实时评估器，用于提供反馈并识别次优动作；另一个代理则负责根据业务场景的相关性和准确性对反馈进行选择性策展，为未来的培训周期创建批准的数据集。

Result: 实验结果表明，结合人类反馈能显著提高模型的鲁棒性和准确性。ARL框架在文档识别和信息提取等实际场景中得到了验证，并在复杂或模糊的环境中达到了更高的学习标准。

Conclusion: 该研究表明，像ARL这样的人在循环强化学习框架可以为数据驱动的应用程序提供一种可扩展的提高模型性能的方法。

Abstract: This work proposes a novel technique Augmented Reinforcement Learning
framework for the improvement of decision-making capabilities of machine
learning models. The introduction of agents as external overseers checks on
model decisions. The external agent can be anyone, like humans or automated
scripts, that helps in decision path correction. It seeks to ascertain the
priority of the "Garbage-In, Garbage-Out" problem that caused poor data inputs
or incorrect actions in reinforcement learning. The ARL framework incorporates
two external agents that aid in course correction and the guarantee of quality
data at all points of the training cycle. The External Agent 1 is a real-time
evaluator, which will provide feedback light of decisions taken by the model,
identify suboptimal actions forming the Rejected Data Pipeline. The External
Agent 2 helps in selective curation of the provided feedback with relevance and
accuracy in business scenarios creates an approved dataset for future training
cycles. The validation of the framework is also applied to a real-world
scenario, which is "Document Identification and Information Extraction". This
problem originates mainly from banking systems, but can be extended anywhere.
The method of classification and extraction of information has to be done
correctly here. Experimental results show that including human feedback
significantly enhances the ability of the model in order to increase robustness
and accuracy in making decisions. The augmented approach, with a combination of
machine efficiency and human insight, attains a higher learning standard-mainly
in complex or ambiguous environments. The findings of this study show that
human-in-the-loop reinforcement learning frameworks such as ARL can provide a
scalable approach to improving model performance in data-driven applications.

</details>


### [712] [TCDiff: Triplex Cascaded Diffusion for High-fidelity Multimodal EHRs Generation with Incomplete Clinical Data](https://arxiv.org/abs/2508.01615)
*Yandong Yan,Chenxi Li,Yu Huang,Dexuan Xu,Jiaqi Zhu,Zhongyan Chai,Huamin Zhang*

Main category: cs.LG

TL;DR: TCDiff 是一个新颖的 EHR 生成框架，通过级联三个扩散网络来解决异构多模态 EHR 数据和数据不完整性问题，并在传统中医药领域取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 EHR 数据合成方法在处理异构多模态 EHR 数据（如连续、离散和文本模态）的内在特性、捕捉它们之间的复杂依赖关系以及鲁棒地处理普遍存在的数据不完整性方面的局限性，尤其是在传统中医药 (TCM) 领域。

Method: 提出了一种名为 TCDiff (Triplex Cascaded Diffusion Network) 的新颖 EHR 生成框架，该框架级联三个扩散网络来学习真实 EHR 数据的特征，形成一个多阶段的生成过程：参考模态扩散、跨模态桥接和目标模态扩散。

Result: TCDiff 持续优于最先进的基线，在数据保真度方面平均提高了 10%，同时保持了有竞争力的隐私保证。

Conclusion: TCDiff 在各种缺失率下，在数据保真度方面平均优于最先进的基线 10%，同时保持了具有竞争力的隐私保证。这凸显了该方法在现实医疗保健场景中的有效性、鲁棒性和泛化性。

Abstract: The scarcity of large-scale and high-quality electronic health records (EHRs)
remains a major bottleneck in biomedical research, especially as large
foundation models become increasingly data-hungry. Synthesizing substantial
volumes of de-identified and high-fidelity data from existing datasets has
emerged as a promising solution. However, existing methods suffer from a series
of limitations: they struggle to model the intrinsic properties of
heterogeneous multimodal EHR data (e.g., continuous, discrete, and textual
modalities), capture the complex dependencies among them, and robustly handle
pervasive data incompleteness. These challenges are particularly acute in
Traditional Chinese Medicine (TCM). To this end, we propose TCDiff (Triplex
Cascaded Diffusion Network), a novel EHR generation framework that cascades
three diffusion networks to learn the features of real-world EHR data,
formatting a multi-stage generative process: Reference Modalities Diffusion,
Cross-Modal Bridging, and Target Modality Diffusion. Furthermore, to validate
our proposed framework, besides two public datasets, we also construct and
introduce TCM-SZ1, a novel multimodal EHR dataset for benchmarking.
Experimental results show that TCDiff consistently outperforms state-of-the-art
baselines by an average of 10% in data fidelity under various missing rate,
while maintaining competitive privacy guarantees. This highlights the
effectiveness, robustness, and generalizability of our approach in real-world
healthcare scenarios.

</details>


### [713] [IMU: Influence-guided Machine Unlearning](https://arxiv.org/abs/2508.01620)
*Xindi Fan,Jing Wu,Mingyi Zhou,Pengwei Liang,Dinh Phung*

Main category: cs.LG

TL;DR: IMU是一种新的机器遗忘方法，仅使用遗忘集，通过动态分配遗忘强度来提高效率和保持模型效用，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型容易受到攻击并会记住训练数据，引发隐私泄露担忧。因此，需要机器遗忘（MU）技术，使模型能够根据要求选择性地忘记特定数据点。然而，现有的MU算法大多需要保留集，这在隐私和存储方面存在限制。

Method: IMU采用梯度上升法，并基于数据点的影响动态分配遗忘强度。

Result: IMU在视觉和语言任务上均优于现有的不依赖保留集的MU方法。

Conclusion: 现有的机器遗忘（MU)算法需要对保留集进行部分或全部微调，需要持续访问原始训练数据，这通常不切实际。一些不依赖保留集的MU方法，但有的依赖辅助数据和预先计算的保留集统计数据，有的在遗忘更多数据时扩展性差。本文提出的影响引导式机器遗忘（IMU）是一种简单而有效的方法，仅使用遗忘集进行MU。IMU采用梯度上升法，并基于数据点的影响动态分配遗忘强度。这种方法提高了遗忘效率，同时保持了模型的效用。实验结果表明，IMU在视觉和语言任务上均优于现有的不依赖保留集的MU方法。

Abstract: Recent studies have shown that deep learning models are vulnerable to attacks
and tend to memorize training data points, raising significant concerns about
privacy leakage. This motivates the development of machine unlearning (MU),
i.e., a paradigm that enables models to selectively forget specific data points
upon request. However, most existing MU algorithms require partial or full
fine-tuning on the retain set. This necessitates continued access to the
original training data, which is often impractical due to privacy concerns and
storage constraints. A few retain-data-free MU methods have been proposed, but
some rely on access to auxiliary data and precomputed statistics of the retain
set, while others scale poorly when forgetting larger portions of data. In this
paper, we propose Influence-guided Machine Unlearning (IMU), a simple yet
effective method that conducts MU using only the forget set. Specifically, IMU
employs gradient ascent and innovatively introduces dynamic allocation of
unlearning intensities across different data points based on their influences.
This adaptive strategy significantly enhances unlearning effectiveness while
maintaining model utility. Results across vision and language tasks demonstrate
that IMU consistently outperforms existing retain-data-free MU methods.

</details>


### [714] [EAC-MoE: Expert-Selection Aware Compressor for Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2508.01625)
*Yuanteng Chen,Yuantian Shao,Peisong Wang,Jian Cheng*

Main category: cs.LG

TL;DR: EAC-MoE 提出了一种名为 EAC-MoE 的方法，通过量化（QESC）和剪枝（PESF）来优化 MoE-LLMs，解决了内存消耗大和推理速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 旨在解决 MoE-LLMs 在扩展过程中面临的两个关键挑战：一是所有专家加载所需的大量 GPU 内存消耗；二是激活参数低无法有效转化为推理加速。

Method: EAC-MoE 通过量化和剪枝两个模块解决 MoE-LLMs 的内存消耗和推理加速问题。其中，QESC 通过校准 MoE 中的路由器来缓解量化引起的专家选择偏差；PESF 通过剪枝不常被选择的专家来提高推理速度。

Result: 实验证明，EAC-MoE 显著减少了内存占用，提高了推理速度，并且性能损失极小。

Conclusion: EAC-MoE 显著降低了内存使用并提高了推理速度，同时将性能下降降至最低。

Abstract: Mixture-of-Experts (MoE) has demonstrated promising potential in scaling
LLMs. However, it is hindered by two critical challenges: (1) substantial GPU
memory consumption to load all experts; (2) low activated parameters cannot be
equivalently translated into inference acceleration effects. In this work, we
propose EAC-MoE, an Expert-Selection Aware Compressor for MoE-LLMs, which
deeply aligns with the characteristics of MoE from the perspectives of
quantization and pruning, and introduces two modules to address these two
challenges respectively: (1) The expert selection bias caused by low-bit
quantization is a major factor contributing to the performance degradation in
MoE-LLMs. Based on this, we propose Quantization with Expert-Selection
Calibration (QESC), which mitigates the expert selection bias by calibrating
the routers within the MoE; (2) There are always certain experts that are not
crucial for the corresponding tasks, yet causing inference latency. Therefore,
we propose Pruning based on Expert-Selection Frequency (PESF), which
significantly improves inference speed by pruning less frequently used experts
for current task. Extensive experiments demonstrate that our approach
significantly reduces memory usage and improves inference speed with minimal
performance degradation.

</details>


### [715] [Privacy-Preserving Inference for Quantized BERT Models](https://arxiv.org/abs/2508.01636)
*Tianpei Lu,Bingsheng Zhang,Lekun Peng,Bowen Zheng,Lichun Li,Kui Ren*

Main category: cs.LG

TL;DR: 本文提出了一种改进的安全多方计算量化推理方法，通过逐层量化、1比特权重支持、高效的softmax协议和无截断开销的设计，显著提高了推理速度，特别是在处理BERT等复杂模型时。


<details>
  <summary>Details</summary>
Motivation: 随着生成式机器学习模型在隐私敏感领域（如医疗保健和个性化服务）的广泛应用，确保安全推理已成为一项关键挑战。虽然安全多方计算（MPC）支持隐私保护的模型推理，但其通信和计算开销很高，主要瓶颈在于昂贵的浮点运算安全评估。量化通过将浮点运算转换为低精度整数计算，可以显著降低开销，但现有基于MPC的量化推理方法存在隐私风险或效率低下问题，尤其是在处理激活和softmax等非线性函数时。

Method: 提出了一种细粒度、逐层量化方案，支持1比特权重全连接层；设计了多输入查找表协议来高效、安全地评估softmax；使用双秘密共享方案并通过查找表执行精度转换，消除了截断开销。

Result: 在BERT-base模型上实现了高达8倍（相比Lu et al.）、9倍（相比Gupta et al.）和22倍（相比Knott et al.）的加速。

Conclusion: 本文提出了一种细粒度、逐层量化方案，并支持安全设置下的1比特权重全连接层。通过设计多输入查找表协议来高效且安全地评估softmax。此外，使用双秘密共享方案并通过查找表执行精度转换，完全消除了截断开销。实验评估表明，该方法在BERT-base模型上实现了显著的加速。

Abstract: With the increasing deployment of generative machine learning models in
privacy-sensitive domains such as healthcare and personalized services,
ensuring secure inference has become a critical challenge. Secure multi-party
computation (MPC) enables privacy-preserving model inference but suffers from
high communication and computation overhead. The main bottleneck lies in the
expensive secure evaluation of floating-point operations. Quantization offers a
promising solution by converting floating-point operations into lower-precision
integer computations, significantly reducing overhead. However, existing
MPC-based quantized inference methods either rely on public quantization
parameters-posing privacy risks-or suffer from inefficiencies, particularly in
handling nonlinear functions such as activations and softmax. In this work, we
propose a fine-grained, layer-wise quantization scheme and support 1-bit weight
fully connected layers in a secure setting. We design a multi-input lookup
table protocol to evaluate softmax efficiently and securely. Furthermore, we
use dual secret sharing schemes and perform precision conversions via lookup
tables, eliminating truncation overhead entirely. Experimental evaluation on
BERT-base models demonstrates that our approach achieves up to $8\times$
speedup compared to Lu \emph{et al}. (NDSS 25), $9\times$ speedup compared to
Gupta \emph{et al}. (PETS 24) and $22 \times$ speedup compared to Knott
\emph{et al}. (NeurIPS 21).

</details>


### [716] [Generalized Kernelized Bandits: Self-Normalized Bernstein-Like Dimension-Free Inequality and Regret Bounds](https://arxiv.org/abs/2508.01681)
*Alberto Maria Metelli,Simone Drago,Marco Mussi*

Main category: cs.LG

TL;DR: 该论文提出了GKB-UCB算法，在广义核经验回放（GKB）设置下实现了与现有最优算法相当的遗憾界限，并为核经验回放（KB）和广义线性经验回放（GLB）提供了统一的视角。


<details>
  <summary>Details</summary>
Motivation: 研究目标是在广义核经验回放（GKBs）的新颖设置下解决遗憾最小化问题，其中目标是优化一个属于再生核希尔伯特空间（RKHS）的未知函数$f^*$，同时处理由指数族（EF）噪声模型生成的样本，该模型的均值是$
u(f^*)$的一个非线性函数。

Method: 提出了一种名为GKB-UCB的乐观算法，并开发了一种新的自归一化Bernstein类无量纲不等式，该不等式利用Freedman不等式和缝合论证。

Result: 在所提出的无量纲不等式的基础上，对GKB-UCB进行了遗憾分析，得出了$	ilder{O}(\gamma_T \sqrt{T/\kappa_*})$的遗憾界限，其中$T$是学习的视界，$\gamma_T$是最大信息增益，$\kappa_*$是表征奖励非线性幅度的项。

Conclusion: 该研究提出的GKB-UCB算法在广义核经验回放（GKB）设置下实现了与现有最优算法相当的遗憾界限，并为核经验回放（KB）和广义线性经验回放（GLB）提供了统一的视角。

Abstract: We study the regret minimization problem in the novel setting of generalized
kernelized bandits (GKBs), where we optimize an unknown function $f^*$
belonging to a reproducing kernel Hilbert space (RKHS) having access to samples
generated by an exponential family (EF) noise model whose mean is a non-linear
function $\mu(f^*)$. This model extends both kernelized bandits (KBs) and
generalized linear bandits (GLBs). We propose an optimistic algorithm, GKB-UCB,
and we explain why existing self-normalized concentration inequalities do not
allow to provide tight regret guarantees. For this reason, we devise a novel
self-normalized Bernstein-like dimension-free inequality resorting to
Freedman's inequality and a stitching argument, which represents a contribution
of independent interest. Based on it, we conduct a regret analysis of GKB-UCB,
deriving a regret bound of order $\widetilde{O}( \gamma_T \sqrt{T/\kappa_*})$,
being $T$ the learning horizon, ${\gamma}_T$ the maximal information gain, and
$\kappa_*$ a term characterizing the magnitude the reward nonlinearity. Our
result matches, up to multiplicative constants and logarithmic terms, the
state-of-the-art bounds for both KBs and GLBs and provides a unified view of
both settings.

</details>


### [717] [Innovative tokenisation of structured data for LLM training](https://arxiv.org/abs/2508.01685)
*Kayvan Karim,Hani Ragab Hassen. Hadj Batatia*

Main category: cs.LG

TL;DR: 通过混合分词方法，将表格数据转换为适合LLM训练的序列格式，解决了结构化数据表示的挑战，并实现了高效处理和数据压缩。


<details>
  <summary>Details</summary>
Motivation: 解决在将Transformer和LLM等序列模型应用于结构化表格数据时，数据表示的挑战，特别是现有方法在统一编码混合数值和类别特征以及保留表格结构方面的不足。

Method: 结合使用固定分词（代表结构元素和低基数类别特征）和字节对编码（BPE）学习的子词词汇表（处理高基数和连续值）来分词表格数据。

Result: 该方法在处理大规模NetFlow数据集（CIDDS-001）时效率极高，能在五小时内处理超过3100万条网络流，数据压缩比达到6.18:1，生成了超过10亿个标记，为在结构化数据上训练基础模型提供了可行且可泛化的途径。

Conclusion: 本文提出了一种新颖的混合分词方法，将表格数据转换为适合LLM训练的统一序列格式，并成功应用于网络入侵检测系统（NIDS）基础模型，实现了高效处理和显著的数据压缩。

Abstract: Data representation remains a fundamental challenge in machine learning,
particularly when adapting sequence-based architectures like Transformers and
Large Language Models (LLMs) for structured tabular data. Existing methods
often fail to cohesively encode the mix of numerical and categorical features
or preserve the inherent structure of tables. This paper introduces a novel,
hybrid tokenisation methodology designed to convert tabular data into a
unified, sequential format suitable for LLM training. Our approach combines
predefined fixed tokens to represent structural elements and low-cardinality
categorical features, with a learned subword vocabulary using Byte-Pair
Encoding (BPE) for high-cardinality and continuous values. We demonstrate the
efficacy of this technique by applying it to a large-scale NetFlow dataset
(CIDDS-001), preparing a corpus for a Network Intrusion Detection System (NIDS)
foundation model. The evaluation shows that our method is highly efficient,
processing over 31 million network flows in under five hours and achieving a
significant data compression ratio of 6.18:1. This process resulted in a
computationally manageable corpus of over one billion tokens, establishing a
viable and generalisable pathway for training foundation models on structured
data.

</details>


### [718] [Explaining Time Series Classifiers with PHAR: Rule Extraction and Fusion from Post-hoc Attributions](https://arxiv.org/abs/2508.01687)
*Maciej Mozolewski,Szymon Bobek,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: PHAR是一个时间序列分类模型解释框架，能将复杂的特征归因转化为易于理解的规则，提高模型透明度和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列分类模型解释方法因原始时间序列的复杂性和高维输入空间而面临挑战，需要一种能生成结构化、可读规则的框架。

Method: PHAR-Post-hoc Attribution Rules框架，将时间序列特征归因转化为可解释的区间规则，并通过规则融合策略（如加权选择和Lasso优化）来提高规则集的简洁性和一致性。

Result: PHAR在UCI数据集上的实验表明，其性能可与Anchor等原生规则方法相媲美，且在处理长序列和提高实例覆盖率方面更有效率，同时解决了Rashomon现象导致的解释冲突。

Conclusion: PHAR通过将数值特征归因转化为结构化、可读的规则，增强了时间序列分类模型的可解释性、决策透明度和实际应用性。

Abstract: Explaining machine learning (ML) models for time series (TS) classification
remains challenging due to the difficulty of interpreting raw time series and
the high dimensionality of the input space. We introduce PHAR-Post-hoc
Attribution Rules-a unified framework that transforms numeric feature
attributions from post-hoc, instance-wise explainers (e.g., LIME, SHAP) into
structured, human-readable rules. These rules define interpretable intervals
that indicate where and when key decision boundaries occur, enhancing model
transparency. PHAR performs comparably to native rule-based methods, such as
Anchor, while scaling more efficiently to long TS sequences and achieving
broader instance coverage. A dedicated rule fusion step consolidates rule sets
using strategies like weighted selection and lasso-based refinement, balancing
key quality metrics: coverage, confidence, and simplicity. This fusion ensures
each instance receives a concise and unambiguous rule, improving both
explanation fidelity and consistency. We further introduce visualization
techniques to illustrate specificity-generalization trade-offs in the derived
rules. PHAR resolves conflicting and overlapping explanations-a common effect
of the Rashomon phenomenon-into coherent, domain-adaptable insights.
Comprehensive experiments on UCI datasets demonstrate that PHAR improves
interpretability, decision transparency, and practical applicability for TS
classification tasks.

</details>


### [719] [MHARFedLLM: Multimodal Human Activity Recognition Using Federated Large Language Model](https://arxiv.org/abs/2508.01701)
*Asmit Bandyopadhyay,Rohit Basu,Tanmay Sen,Swagatam Das*

Main category: cs.LG

TL;DR: FedTime-MAGNET是一个多模态联邦学习框架，结合了多种传感器数据（摄像头、压力垫、加速度计）和先进的AI技术（图神经网络、T5模型），能够更准确、更鲁棒地识别用户活动，即使在分布式和隐私保护的场景下也能表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的人类活动识别（HAR）系统通常依赖单一模态，如运动传感器或摄像头，这在真实环境中限制了其鲁棒性和准确性。本研究旨在通过结合多种数据源来改进HAR系统的性能。

Method: 提出了一种名为FedTime-MAGNET的新型多模态联邦学习框架，该框架结合了深度摄像头、压力垫和加速度计等异构数据源。其核心是多模态自适应图神经网络专家Transformer（MAGNET），这是一种融合架构，利用图注意力机制和专家混合（Mixture of Experts）来生成统一的、具有判别力的跨模态嵌入。此外，还定制并改编了一个轻量级的T5 encoder-only架构来捕捉复杂的时间依赖性。

Result: 实验结果表明，FedTime-MAGNET显著提高了HAR性能，在中心化设置下达到了0.934的F1分数，在联邦设置下达到了0.881的F1分数。

Conclusion: FedTime-MAGNET通过结合多模态融合、时间序列大语言模型和联邦学习，显著提高了人类活动识别（HAR）的准确性和鲁棒性。

Abstract: Human Activity Recognition (HAR) plays a vital role in applications such as
fitness tracking, smart homes, and healthcare monitoring. Traditional HAR
systems often rely on single modalities, such as motion sensors or cameras,
limiting robustness and accuracy in real-world environments. This work presents
FedTime-MAGNET, a novel multimodal federated learning framework that advances
HAR by combining heterogeneous data sources: depth cameras, pressure mats, and
accelerometers. At its core is the Multimodal Adaptive Graph Neural Expert
Transformer (MAGNET), a fusion architecture that uses graph attention and a
Mixture of Experts to generate unified, discriminative embeddings across
modalities. To capture complex temporal dependencies, a lightweight T5 encoder
only architecture is customized and adapted within this framework. Extensive
experiments show that FedTime-MAGNET significantly improves HAR performance,
achieving a centralized F1 Score of 0.934 and a strong federated F1 Score of
0.881. These results demonstrate the effectiveness of combining multimodal
fusion, time series LLMs, and federated learning for building accurate and
robust HAR systems.

</details>


### [720] [Imbalance-Robust and Sampling-Efficient Continuous Conditional GANs via Adaptive Vicinity and Auxiliary Regularization](https://arxiv.org/abs/2508.01725)
*Xin Ding,Yun Chen,Yongwei Wang,Kao Zhang,Sen Zhang,Peibei Cao,Xiangxue Wang*

Main category: cs.LG

TL;DR: 我们提出了CcGAN-AVAR，一种改进的CcGAN模型，通过单步生成和新的不平衡处理机制，解决了现有方法的采样效率和数据不平衡问题，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CcGAN和CCDM在处理以标量、连续回归标签（如角度、年龄或温度）为条件的 and 估计高维数据分布方面存在局限性：CcGAN因固定的邻域约束而导致数据失衡，而CCDM需要计算上昂贵的迭代采样。

Method:  CcGAN-AVAR是一个增强的CcGAN框架，它利用了GAN框架原生的单步生成来克服CCDM的采样瓶颈（实现300倍-2000倍的推理加速），并通过一个自适应邻域机制和一个多任务判别器来解决数据不平衡问题，其中多任务判别器通过辅助回归和密度比估计构建了两个正则化项，以显著改善生成器训练。

Result: CcGAN-AVAR在包括64x64到192x192分辨率的四个基准数据集上，在八个具有挑战性的不平衡设置下进行了广泛的实验，证明了其优越性。

Conclusion: CcGAN-AVAR在四个基准数据集的八种具有挑战性的不平衡设置下，实现了最先进的生成质量，同时保持了采样效率。

Abstract: Recent advances in conditional generative modeling have introduced Continuous
conditional Generative Adversarial Network (CcGAN) and Continuous Conditional
Diffusion Model (CCDM) for estimating high-dimensional data distributions
conditioned on scalar, continuous regression labels (e.g., angles, ages, or
temperatures). However, these approaches face fundamental limitations: CcGAN
suffers from data imbalance due to fixed-size vicinity constraints, while CCDM
requires computationally expensive iterative sampling. We present CcGAN-AVAR,
an enhanced CcGAN framework that addresses both challenges: (1) leveraging the
GAN framework's native one-step generation to overcome CCDMs' sampling
bottleneck (achieving 300x-2000x faster inference), while (2) two novel
components specifically target data imbalance - an adaptive vicinity mechanism
that dynamically adjusts vicinity's size, and a multi-task discriminator that
constructs two regularization terms (through auxiliary regression and density
ratio estimation) to significantly improve generator training. Extensive
experiments on four benchmark datasets (64x64 to 192x192 resolution) across
eight challenging imbalanced settings demonstrate that CcGAN-AVAR achieves
state-of-the-art generation quality while maintaining sampling efficiency.

</details>


### [721] [OccamVTS: Distilling Vision Models to 1% Parameters for Time Series Forecasting](https://arxiv.org/abs/2508.01727)
*Sisuo Lyu,Siru Zhong,Weilin Ruan,Qingxiang Liu,Qingsong Wen,Hui Xiong,Yuxuan Liang*

Main category: cs.LG

TL;DR: OccamVTS是一個創新的時間序列預測框架，它從大型視覺模型中提取關鍵的1%參數，以實現高效且準確的預測，尤其擅長處理數據稀疏的場景。


<details>
  <summary>Details</summary>
Motivation: 現有方法利用大型視覺模型（LVMs）來捕捉時間序列的模式，但研究發現LVMs中99%的參數對於時間序列任務而言是不必要的，且高層語義資訊可能損害預測準確性。因此，需要一種方法來提取LVMs中有用的資訊，同時過濾掉無關的語義。

Method: OccamVTS是一個知識蒸餾框架，利用預訓練的LVMs作為教師模型，透過金字塔式特徵對齊、相關性及特徵蒸餾，將時間序列的預測性資訊（約1%的參數）轉移到輕量級網路中，並過濾掉與任務無關的語義資訊。

Result: OccamVTS僅使用原始LVMs的1%參數，在多個基準數據集上實現了最先進的性能，並在少樣本和零樣本預測任務中表現出色，證明了其有效性和效率。

Conclusion: OccamVTS通過知識蒸餾，僅利用大型視覺模型（LVMs）的1%參數，就能在時間序列預測任務中達到最先進的性能，特別是在少樣本和零樣本場景下表現優異，同時減少了過度擬合的風險。

Abstract: Time series forecasting is fundamental to diverse applications, with recent
approaches leverage large vision models (LVMs) to capture temporal patterns
through visual representations. We reveal that while vision models enhance
forecasting performance, 99% of their parameters are unnecessary for time
series tasks. Through cross-modal analysis, we find that time series align with
low-level textural features but not high-level semantics, which can impair
forecasting accuracy. We propose OccamVTS, a knowledge distillation framework
that extracts only the essential 1% of predictive information from LVMs into
lightweight networks. Using pre-trained LVMs as privileged teachers, OccamVTS
employs pyramid-style feature alignment combined with correlation and feature
distillation to transfer beneficial patterns while filtering out semantic
noise. Counterintuitively, this aggressive parameter reduction improves
accuracy by eliminating overfitting to irrelevant visual features while
preserving essential temporal patterns. Extensive experiments across multiple
benchmark datasets demonstrate that OccamVTS consistently achieves
state-of-the-art performance with only 1% of the original parameters,
particularly excelling in few-shot and zero-shot scenarios.

</details>


### [722] [AGFT: An Adaptive GPU Frequency Tuner for Real-Time LLM Inference Optimization](https://arxiv.org/abs/2508.01744)
*Zicong Ye,Kunming Zhang,Guoming Tang*

Main category: cs.LG

TL;DR: AGFT是一个创新的框架，利用在线强化学习技术，通过动态调整GPU频率来显著降低LLM推理的能耗和延迟，实现了高达40.3%的能-时积优化，同时将延迟开销控制在10%以内。


<details>
  <summary>Details</summary>
Motivation: 为了解决交互式大语言模型（LLMs）对云GPU低延迟的未满足需求，以及由此带来的高功耗和不断上涨的能源成本问题。

Method: AGFT框架使用在线强化学习自主学习最优频率调整策略，通过监控请求负载和延迟等实时特征，利用细粒度频率控制进行精确调整，并通过智能动作空间剪枝实现稳定高效的决策。

Result: AGFT成功节省了44.3%的GPU能耗，同时将性能延迟开销引入了不到10%的最小值。这转化为高达40.3%的综合能-时积（EDP）优化。

Conclusion: AGFT能够显著提高LLM推理集群的能源效率和经济效益，同时不损害服务质量。

Abstract: The explosive growth of interactive Large Language Models (LLMs) has placed
unprecedented demands for low latency on cloud GPUs, forcing them into
high-power modes and causing escalating energy costs. Real-time inference
workloads exhibit significant dynamic volatility, presenting substantial
energy-saving opportunities. However, traditional static or rule-based power
management strategies struggle to exploit these opportunities without
compromising peak performance. To address this challenge, we propose AGFT (An
Adaptive GPU Frequency Tuner), a framework that employs online reinforcement
learning to autonomously learn an optimal frequency tuning policy. By
monitoring real-time features like request load and latency, AGFT utilizes
fine-grained frequency control for precise adjustments and intelligent action
space pruning for stable, efficient decision-making. This creates a robust,
automated energy management solution. We comprehensively evaluated AGFT in an
environment simulating realistic, fluctuating inference requests. The
experimental results demonstrate that AGFT successfully saves 44.3% of GPU
energy consumption while introducing a minimal performance latency overhead of
under 10%. This achievement translates into a comprehensive Energy-Delay
Product (EDP) optimization of up to 40.3%, clearly showing that our framework
can significantly enhance the energy efficiency and economic benefits of
existing LLM inference clusters without compromising service quality.

</details>


### [723] [Semantically-Guided Inference for Conditional Diffusion Models: Enhancing Covariate Consistency in Time Series Forecasting](https://arxiv.org/abs/2508.01761)
*Rui Ding,Hanyang Meng,Zeyang Zhang,Jielong Yang*

Main category: cs.LG

TL;DR: SemGuide是一种即插即用的方法，通过在推理时引入评分网络来提高条件扩散模型在时间序列预测中的协变量一致性，从而提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在时间序列预测方面表现优异，但在生成轨迹与条件协变量之间存在语义不匹配的问题，尤其是在复杂或多模态条件下。

Method: SemGuide是一种即插即用的推理时方法，通过引入一个评分网络来评估中间扩散状态与未来协变量之间的语义对齐程度，并利用这些分数作为逐步重要性重加权过程中的代理似然，在不改变原始训练过程的情况下调整采样路径。该方法与任何条件扩散框架兼容且模型无关。

Result: 实验结果表明，SemGuide在真实世界的时间序列预测任务中，无论是在预测准确性还是协变量一致性方面，都带来了持续的提升，在复杂条件场景下尤其表现出色。

Conclusion: SemGuide能够提升条件扩散模型在时间序列预测任务中的预测准确性和协变量一致性，尤其在复杂或多模态条件下表现突出。

Abstract: Diffusion models have demonstrated strong performance in time series
forecasting, yet often suffer from semantic misalignment between generated
trajectories and conditioning covariates, especially under complex or
multimodal conditions. To address this issue, we propose SemGuide, a
plug-and-play, inference-time method that enhances covariate consistency in
conditional diffusion models. Our approach introduces a scoring network to
assess the semantic alignment between intermediate diffusion states and future
covariates. These scores serve as proxy likelihoods in a stepwise importance
reweighting procedure, which progressively adjusts the sampling path without
altering the original training process. The method is model-agnostic and
compatible with any conditional diffusion framework. Experiments on real-world
forecasting tasks show consistent gains in both predictive accuracy and
covariate alignment, with especially strong performance under complex
conditioning scenarios.

</details>


### [724] [Revisiting Replay and Gradient Alignment for Continual Pre-Training of Large Language Models](https://arxiv.org/abs/2508.01908)
*Istabrak Abbes,Gopeshh Subbaraj,Matthew Riemer,Nizar Islah,Benjamin Therien,Tsuguchika Tabaru,Hiroaki Kingetsu,Sarath Chandar,Irina Rish*

Main category: cs.LG

TL;DR: LLMs can be continually pre-trained more efficiently using experience replay and gradient alignment, which prevent performance degradation. A new method, MER, combines the benefits of gradient alignment with experience replay at minimal cost. While replaying some old data is good, scaling the model is more efficient than replaying a lot of old data.


<details>
  <summary>Details</summary>
Motivation: Existing methods for training LLMs require restarting the entire process when new data becomes available. Continual pre-training is a more efficient approach, but it suffers from performance degradation due to distribution shifts. This paper investigates methods to mitigate this issue.

Method: The paper analyzes experience replay and gradient alignment methods for continual pre-training of LLMs, using the Llama family of architectures with 100 billion tokens of data per language. They also propose an efficient implementation of meta-experience replay (MER).

Result: Both replay and gradient alignment stabilize learning and prevent forgetting in LLMs during continual pre-training. MER provides the benefits of gradient alignment with negligible overhead. Scaling analysis shows that replaying a small amount of old data is more beneficial than increasing model size, but increasing model size is more compute-efficient than replaying data at high rates.

Conclusion: continual pre-training using experience replay and gradient alignment can lead to more stable learning without forgetting, and that small rates of replaying old examples are more valuable than increasing model size, but scaling the model size is more compute efficient than replaying old examples at high rates.

Abstract: Training large language models (LLMs) typically involves pre-training on
massive corpora, only to restart the process entirely when new data becomes
available. A more efficient and resource-conserving approach would be continual
pre-training, where models are updated with new data rather than retraining
from scratch. However, the introduction of new data often causes distribution
shifts, leading to performance degradation on previously learned tasks. In this
paper, we take a deeper look at two popular proposals for addressing this
distribution shift within the continual learning literature: experience replay
and gradient alignment. We consider continual pre-training of models within the
Llama family of architectures at a large scale across languages with 100
billion tokens of training data in each language, finding that both replay and
gradient alignment lead to more stable learning without forgetting. This
conclusion holds both as we vary the model scale and as we vary the number and
diversity of tasks. Moreover, we are the first to demonstrate the effectiveness
of gradient alignment techniques in the context of LLM pre-training and propose
an efficient implementation of meta-experience replay (MER) that imbues
experience replay with the benefits of gradient alignment despite negligible
compute and memory overhead. Our scaling analysis across model sizes and replay
rates indicates that small rates of replaying old examples are definitely a
more valuable use of compute than investing in model size, but that it is more
compute efficient to scale the size of the model than invest in high rates of
replaying old examples.

</details>


### [725] [A Trainable Optimizer](https://arxiv.org/abs/2508.01764)
*Ruiqi Wang,Diego Klabjan*

Main category: cs.LG

TL;DR: Trainable optimizers (TO) with pseudo-linear approximations achieve faster convergence than ADAM with minimal overhead, outperforming benchmarks in different settings and LLM fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Learning to optimize (TO) aims to replace manually defined optimizers (like ADAM) with trainable optimization strategies.

Method: The framework jointly trains the full gradient estimator and the model's trainable weights. It uses pseudo-linear TO, a linear approximation of the full gradient, which matches SGD's convergence rate with reduced variance and minimal computational overhead. Two simplified variants of Pseudo-linear TO are also introduced for improved efficiency.

Result: Pseudo-linear TO matches SGD's convergence rate while reducing variance and incurring negligible computational overhead. Simplified variants further improve efficiency. TO methods show faster convergence than ADAM in various settings.

Conclusion: TO methods converge faster than benchmark algorithms like ADAM in both strongly convex and non-convex settings, and in fine-tuning LLMs.

Abstract: The concept of learning to optimize involves utilizing a trainable
optimization strategy rather than relying on manually defined full gradient
estimations such as ADAM. We present a framework that jointly trains the full
gradient estimator and the trainable weights of the model. Specifically, we
prove that pseudo-linear TO (Trainable Optimizer), a linear approximation of
the full gradient, matches SGD's convergence rate while effectively reducing
variance. Pseudo-linear TO incurs negligible computational overhead, requiring
only minimal additional tensor multiplications. To further improve
computational efficiency, we introduce two simplified variants of Pseudo-linear
TO. Experiments demonstrate that TO methods converge faster than benchmark
algorithms (e.g., ADAM) in both strongly convex and non-convex settings, and
fine tuning of an LLM.

</details>


### [726] [Decomposing Representation Space into Interpretable Subspaces with Unsupervised Learning](https://arxiv.org/abs/2508.01916)
*Xinting Huang,Michael Hahn*

Main category: cs.LG

TL;DR: NDM是一种无监督方法，可以发现神经网络中可解释的子空间，这些子空间类似于模型变量，并将相同概念编码在一起。它在GPT-2中得到了验证，并且可以扩展到更大的模型。


<details>
  <summary>Details</summary>
Motivation: 为了理解神经网络内部表示，特别是探究表示空间中不同方面的信息如何被组织和编码在不同的子空间中，并探索能否以无监督的方式找到这些“自然”子空间。

Method: 通过邻近距离最小化（NDM）方法，以无监督的方式学习非基向量对齐的子空间。

Result: 定性分析表明，NDM方法找到的子空间在许多情况下具有可解释性，并且能够将抽象概念在不同输入之间进行编码。定量实验证明，这些子空间与GPT-2中的电路变量高度相关，并能扩展到20亿参数模型，用于区分上下文和参数知识路由。

Conclusion: 本研究提出了一种名为邻近距离最小化（NDM）的无监督方法，可以在神经网络的表示空间中发现可解释的子空间。这些子空间类似于模型使用的“变量”，能够将不同输入的相同抽象概念进行编码。

Abstract: Understanding internal representations of neural models is a core interest of
mechanistic interpretability. Due to its large dimensionality, the
representation space can encode various aspects about inputs. To what extent
are different aspects organized and encoded in separate subspaces? Is it
possible to find these ``natural'' subspaces in a purely unsupervised way?
Somewhat surprisingly, we can indeed achieve this and find interpretable
subspaces by a seemingly unrelated training objective. Our method, neighbor
distance minimization (NDM), learns non-basis-aligned subspaces in an
unsupervised manner. Qualitative analysis shows subspaces are interpretable in
many cases, and encoded information in obtained subspaces tends to share the
same abstract concept across different inputs, making such subspaces similar to
``variables'' used by the model. We also conduct quantitative experiments using
known circuits in GPT-2; results show a strong connection between subspaces and
circuit variables. We also provide evidence showing scalability to 2B models by
finding separate subspaces mediating context and parametric knowledge routing.
Viewed more broadly, our findings offer a new perspective on understanding
model internals and building circuits.

</details>


### [727] [VAGPO: Vision-augmented Asymmetric Group Preference Optimization for the Routing Problems](https://arxiv.org/abs/2508.01774)
*Shiyan Liu,Bohan Tan,Yan Jin*

Main category: cs.LG

TL;DR: 提出了一种名为VAGPO的新方法，利用视觉和序列模型以及一种新的优化策略来解决TSP和CVRP问题，该方法在提高训练效率和处理大规模实例方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决旅行商问题（TSP）和有容量车辆路径问题（CVRP）等路径问题，克服现有数据驱动优化方法在训练效率和泛化到大规模实例方面的局限性。

Method: 提出了一种新颖的视觉增强不对称组偏好优化（VAGPO）方法，该方法利用了基于ResNet的视觉编码和基于Transformer的序列建模，并引入了一种不对称组偏好优化策略。

Result: VAGPO在TSP和CVRP基准测试中取得了有竞争力的解决方案质量，并表现出强大的泛化能力，能够无需重新训练即可处理多达1000个节点的大规模实例。

Conclusion: VAGPO在TSP和CVRP问题上取得了有竞争力的解决方案质量，并且能够很好地泛化到更大的实例（高达1000个节点）而无需重新训练，证明了其在学习效率和可扩展性方面的有效性。

Abstract: The routing problems such as the Traveling Salesman Problem (TSP) and the
Capacitated Vehicle Routing Problem (CVRP) are well-known combinatorial
optimization challenges with broad practical relevance. Recent data-driven
optimization methods have made significant progress, yet they often face
limitations in training efficiency and generalization to large-scale instances.
In this paper, we propose a novel Vision-Augmented Asymmetric Group Preference
Optimization (VAGPO) approach for solving the routing problems. By leveraging
ResNet-based visual encoding and Transformer-based sequential modeling, VAGPO
captures both spatial structure and temporal dependencies. Furthermore, we
introduce an asymmetric group preference optimization strategy that
significantly accelerates convergence compared to commonly used policy gradient
methods. Experimental results on TSP and CVRP benchmarks show that the proposed
VAGPO not only achieves highly competitive solution quality but also exhibits
strong generalization to larger instances (up to 1000 nodes) without
re-training, highlighting its effectiveness in both learning efficiency and
scalability.

</details>


### [728] [MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs](https://arxiv.org/abs/2508.02066)
*Guojiang Zhao,Sihang Li,Zixiang Lu,Zheng Cheng,Haitao Lin,Lirong Wu,Hanchen Xia,Hengxing Cai,Wentao Guo,Hongshuai Wang,Mingjun Xu,Siyu Zhu,Guolin Ke,Linfeng Zhang,Zhifeng Gao*

Main category: cs.LG

TL;DR: MolReasoner是一个两阶段框架，用于提升大型语言模型（LLMs）的化学推理能力，通过合成数据微调和强化学习，实现了比现有方法更好的可解释性和推理效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在分子推理方面的能力探索不足，现有方法依赖于缺乏领域特定分子语义的通用提示，或采用难以解释且推理深度有限的微调策略。本研究旨在解决这些问题。

Method: 1. Mol-SFT：利用GPT-4o生成的、经过化学准确性验证的合成思维链(CoT)样本来初始化模型的推理能力。2. Mol-RL：应用强化学习，并设计了专门的奖励函数，将化学结构与语言描述对齐，以增强分子推理能力。

Result: MolReasoner在分子推理任务上表现优于现有方法，显著提升了模型的可解释性、分子理解能力和泛化能力，实现了从记忆到化学推理的转变。

Conclusion: MolReasoner通过使用GPT-4o生成的合成思维链(CoT)样本进行初始化，并结合针对化学结构与语言描述对齐的奖励函数进行强化学习，从而增强了LLMs的分子推理能力。该方法提高了模型的可解释性，加深了对分子的理解，并改善了泛化能力。实验结果表明，MolReasoner优于现有方法，实现了从基于记忆的输出到强大的化学推理的转变。

Abstract: Large Language Models(LLMs) have demonstrated remarkable performance across
various domains, yet their capabilities in molecular reasoning remain
insufficiently explored. Current approaches tend to rely heavily on
general-purpose prompting, which lacks domain-specific molecular semantics,
while those that use fine-tuning strategies often face challenges with
interpretability and reasoning depth. To address these issues, we introduce
MolReasoner, a two-stage framework designed to transition LLMs from
memorization towards chemical reasoning. First, we propose Mol-SFT, which
initializes the model's reasoning abilities via synthetic Chain-of-Thought(CoT)
samples generated by GPT-4o and verified for chemical accuracy. Subsequently,
Mol-RL applies reinforcement learning with specialized reward functions
designed explicitly to align chemical structures with linguistic descriptions,
thereby enhancing molecular reasoning capabilities. Our approach notably
enhances interpretability, improving the model 's molecular understanding and
enabling better generalization. Extensive experiments demonstrate that
MolReasoner outperforms existing methods, and marking a significant shift from
memorization-based outputs to robust chemical reasoning.

</details>


### [729] [CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2508.02091)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Chris Shum,Jiwei Li*

Main category: cs.LG

TL;DR: CRINN是一种新的ANNS算法，使用强化学习将速度作为奖励信号，可以自动生成更快的算法。它在多个基准测试中表现优异，证明了LLM与强化学习结合可以自动化复杂的算法优化。


<details>
  <summary>Details</summary>
Motivation: 近来，近似最近邻搜索（ANNS）算法在检索增强生成（RAG）和基于智能体的LLM应用等人工智能领域变得越来越重要。本文旨在提出一种新的ANNS算法范例CRINN，以应对这些应用对高效ANNS的需求。

Method: CRINN将ANNS优化问题转化为强化学习问题，其中执行速度作为奖励信号。通过这种方式，CRINN能够自动生成速度更快的ANNS实现，同时满足准确性约束。

Result: CRINN在六个常用的NNS基准数据集上的实验评估表明，与最先进的开源ANNS算法相比，CRINN在GIST-960-Euclidean、MNIST-784-Euclidean和GloVe-25-angular三个数据集上取得了最佳性能，在SIFT-128-Euclidean和GloVe-25-angular两个数据集上并列第一。

Conclusion: CRINN是一个新的近似最近邻搜索（ANNS）算法范例，它将ANNS优化视为强化学习问题，并使用执行速度作为奖励信号。该方法能够自动生成速度更快且保持准确性的ANNS实现。CRINN在六个广泛使用的NNS基准数据集上进行了评估，在其中三个数据集（GIST-960-Euclidean, MNIST-784-Euclidean, and GloVe-25-angular）上取得了最佳性能，并在另外两个数据集（SIFT-128-Euclidean and GloVe-25-angular）上并列第一。CRINN的成功表明，通过强化学习增强的LLM可以有效地自动化复杂的算法优化，这些优化通常需要专门的知识和劳动密集型的手动优化。

Abstract: Approximate nearest-neighbor search (ANNS) algorithms have become
increasingly critical for recent AI applications, particularly in
retrieval-augmented generation (RAG) and agent-based LLM applications. In this
paper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS
optimization as a reinforcement learning problem where execution speed serves
as the reward signal. This approach enables the automatic generation of
progressively faster ANNS implementations while maintaining accuracy
constraints. Our experimental evaluation demonstrates CRINN's effectiveness
across six widely-used NNS benchmark datasets. When compared against
state-of-the-art open-source ANNS algorithms, CRINN achieves best performance
on three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and
GloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean
and GloVe-25-angular). The implications of CRINN's success reach well beyond
ANNS optimization: It validates that LLMs augmented with reinforcement learning
can function as an effective tool for automating sophisticated algorithmic
optimizations that demand specialized knowledge and labor-intensive manual
refinement.Code can be found at https://github.com/deepreinforce-ai/CRINN

</details>


### [730] [Neural Predictive Control to Coordinate Discrete- and Continuous-Time Models for Time-Series Analysis with Control-Theoretical Improvements](https://arxiv.org/abs/2508.01833)
*Haoran Li,Muhao Guo,Yang Weng,Hanghang Tong*

Main category: cs.LG

TL;DR: 本文提出了一种将时间序列问题视为最优控制问题的新方法，通过优化控制策略来提高模型在分布变化下的鲁棒性和泛化能力，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于RNN和Neural ODEs的深度序列模型在处理时间序列问题时，通常使用不受约束的神经网络来近似动态，这使得它们在分布变化时难以可靠地适应。本文旨在通过引入控制理论的性能保证来解决这个问题，提高模型在分布变化下的鲁棒性和泛化能力。

Method: 本文将时间序列问题重构为连续的基于ODE的最优控制问题。通过设计控制动作（利用离散时间模型处理历史序列并生成动作）和应用最优控制算法（模型预测控制），优化ODE轨迹以实现任务目标。具体来说，模型预测控制用于规划多步未来轨迹，最小化特定任务的成本，并贪婪地选择当前最优动作。

Result: 实验结果表明，该方法在各种时间序列数据集上相比于现有的最先进基线方法，在泛化性和适应性方面表现更优。

Conclusion: 该方法通过将时间序列问题重构为连续的基于ODE的最优控制问题，并利用模型预测控制来优化控制策略，在各种时间序列数据集上进行了广泛的实验，结果表明该方法相比于现有的最先进方法具有更优越的泛化性和适应性。

Abstract: Deep sequence models have achieved notable success in time-series analysis,
such as interpolation and forecasting. Recent advances move beyond
discrete-time architectures like Recurrent Neural Networks (RNNs) toward
continuous-time formulations such as the family of Neural Ordinary Differential
Equations (Neural ODEs). Generally, they have shown that capturing the
underlying dynamics is beneficial for generic tasks like interpolation,
extrapolation, and classification. However, existing methods approximate the
dynamics using unconstrained neural networks, which struggle to adapt reliably
under distributional shifts. In this paper, we recast time-series problems as
the continuous ODE-based optimal control problem. Rather than learning dynamics
solely from data, we optimize control actions that steer ODE trajectories
toward task objectives, bringing control-theoretical performance guarantees. To
achieve this goal, we need to (1) design the appropriate control actions and
(2) apply effective optimal control algorithms. As the actions should contain
rich context information, we propose to employ the discrete-time model to
process past sequences and generate actions, leading to a coordinate model to
extract long-term temporal features to modulate short-term continuous dynamics.
During training, we apply model predictive control to plan multi-step future
trajectories, minimize a task-specific cost, and greedily select the optimal
current action. We show that, under mild assumptions, this multi-horizon
optimization leads to exponential convergence to infinite-horizon solutions,
indicating that the coordinate model can gain robust and generalizable
performance. Extensive experiments on diverse time-series datasets validate our
method's superior generalization and adaptability compared to state-of-the-art
baselines.

</details>


### [731] [Causal Discovery in Multivariate Time Series through Mutual Information Featurization](https://arxiv.org/abs/2508.01848)
*Gian Marco Paldino,Gianluca Bontempi*

Main category: cs.LG

TL;DR: TD2C是一种新的因果发现方法，通过模式识别而非统计检验，能有效处理复杂时间序列，并在高维非线性场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理复杂多变量时间序列的因果关系发现时，因其依赖于线性假设或条件独立性检验，在面对非线性动态时常常失效。本研究提出一种新范式，从统计检验转向模式识别，认为因果链接会在系统的时序图中产生持久且可学习的信息流不对称性。

Method: 提出了一种名为TD2C（Temporal Dependency to Causality）的监督学习框架，该框架利用信息论和统计描述符学习识别时间序列中的复杂因果模式。

Result: TD2C框架在训练时仅使用了合成时间序列，但在应用于未知的动态和现实基准测试时，展现出了卓越的零样本泛化能力，其性能持续优于现有的方法，特别是在高维和非线性场景下。

Conclusion: TD2C框架通过模式识别而非统计检验来发现因果关系，在处理高维和非线性数据时表现出卓越的零样本泛化能力和最先进的性能，为复杂系统中的因果结构探索提供了强大而可扩展的新工具。

Abstract: Discovering causal relationships in complex multivariate time series is a
fundamental scientific challenge. Traditional methods often falter, either by
relying on restrictive linear assumptions or on conditional independence tests
that become uninformative in the presence of intricate, non-linear dynamics.
This paper proposes a new paradigm, shifting from statistical testing to
pattern recognition. We hypothesize that a causal link creates a persistent and
learnable asymmetry in the flow of information through a system's temporal
graph, even when clear conditional independencies are obscured. We introduce
Temporal Dependency to Causality (TD2C), a supervised learning framework that
operationalizes this hypothesis. TD2C learns to recognize these complex causal
signatures from a rich set of information-theoretic and statistical
descriptors. Trained exclusively on a diverse collection of synthetic time
series, TD2C demonstrates remarkable zero-shot generalization to unseen
dynamics and established, realistic benchmarks. Our results show that TD2C
achieves state-of-the-art performance, consistently outperforming established
methods, particularly in high-dimensional and non-linear settings. By reframing
the discovery problem, our work provides a robust and scalable new tool for
uncovering causal structures in complex systems.

</details>


### [732] [Proactive Constrained Policy Optimization with Preemptive Penalty](https://arxiv.org/abs/2508.01883)
*Ning Yang,Pengyu Wang,Guoqing Liu,Haifeng Zhang,Pin Lyu,Jun Wang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Safe Reinforcement Learning (RL) often faces significant issues such as
constraint violations and instability, necessitating the use of constrained
policy optimization, which seeks optimal policies while ensuring adherence to
specific constraints like safety. Typically, constrained optimization problems
are addressed by the Lagrangian method, a post-violation remedial approach that
may result in oscillations and overshoots. Motivated by this, we propose a
novel method named Proactive Constrained Policy Optimization (PCPO) that
incorporates a preemptive penalty mechanism. This mechanism integrates barrier
items into the objective function as the policy nears the boundary, imposing a
cost. Meanwhile, we introduce a constraint-aware intrinsic reward to guide
boundary-aware exploration, which is activated only when the policy approaches
the constraint boundary. We establish theoretical upper and lower bounds for
the duality gap and the performance of the PCPO update, shedding light on the
method's convergence characteristics. Additionally, to enhance the optimization
performance, we adopt a policy iteration approach. An interesting finding is
that PCPO demonstrates significant stability in experiments. Experimental
results indicate that the PCPO framework provides a robust solution for policy
optimization under constraints, with important implications for future research
and practical applications.

</details>


### [733] [LeanK: Learnable K Cache Channel Pruning for Efficient Decoding](https://arxiv.org/abs/2508.02215)
*Yike Zhang,Zhiyuan He,Huiqiang Jiang,Chengruidong Zhang,Yuqing Yang,Jianyong Wang,Lili Qiu*

Main category: cs.LG

TL;DR: LeanK是一种基于学习的方法，通过修剪KV缓存来提高LLM的效率，可减少内存占用并加速解码，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在处理长上下文任务时，由于不断增长的键值（KV）缓存而面临的效率挑战。

Method: LeanK是一种基于学习的方法，通过新颖的两阶段训练过程学习通道的静态掩码，以满足特定的稀疏率和硬件对齐要求。

Result: LeanK可实现高达70%的K缓存和16%-18%的V缓存内存缩减，并通过自定义解码内核将注意力计算速度提高了1.3倍。此外，通过分析学习到的重要性分布，我们对长上下文推理过程中的模型通道和注意力头提供了见解。

Conclusion: LeanK通过学习到的通道稀疏性修剪不重要的键（K）缓存通道，减少了GPU内存占用并加速了解码，同时保持了准确性。

Abstract: Large language models (LLMs) enable long-context tasks but face efficiency
challenges due to the growing key-value (KV) cache. We propose LeanK, a
learning-based method that prunes unimportant key (K) cache channels by
leveraging static channel sparsity. With a novel two-stage training process,
LeanK learns channel-wise static mask that could satisfy specific sparsity
ratio and hardware alignment requirement. LeanK reduces GPU memory and
accelerates decoding without sacrificing accuracy. Experiments demonstrate up
to 70% K cache and 16%-18% V cache memory reduction. Custom decoding kernel
enables 1.3x speedup for attention computation. We also provide insights into
model channels and attention heads during long-context inference by analyzing
the learned importance distribution. Our code is available at
https://aka.ms/LeanK.

</details>


### [734] [CellForge: Agentic Design of Virtual Cell Models](https://arxiv.org/abs/2508.02276)
*Xiangru Tang,Zhuoyun Yu,Jiapeng Chen,Yan Cui,Daniel Shao,Weixu Wang,Fang Wu,Yuchen Zhuang,Wenqi Shi,Zhi Huang,Arman Cohan,Xihong Lin,Fabian Theis,Smita Krishnaswamy,Mark Gerstein*

Main category: cs.LG

TL;DR: CellForge是一个AI系统，能将生物数据和研究目标转化为虚拟细胞模型，其多代理协作方法在单细胞扰动预测任务中效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决构建虚拟细胞计算模型所面临的挑战，包括生物系统的复杂性、多模态数据的异质性以及跨学科的领域知识需求，以期在人工智能和生物学交叉领域预测生物体对不同扰动的反应。

Method: CellForge 是一个基于多代理框架的系统，它将生物数据集和研究目标转化为优化的虚拟细胞计算模型。它包含任务分析、方法设计和实验执行三个核心模块，其中方法设计模块的代理们通过协作交换解决方案以达成共识。

Result: CellForge 在六个不同的数据集上进行了测试，涵盖了基因敲除、药物处理和细胞因子刺激等多种模式，并且在单细胞扰动预测任务上持续优于特定任务的最先进方法。

Conclusion: CellForge 通过迭代的、多视角的 LLM 代理交互，在解决建模挑战方面优于直接方法，并在单细胞扰动预测方面表现出色。

Abstract: Virtual cell modeling represents an emerging frontier at the intersection of
artificial intelligence and biology, aiming to predict quantities such as
responses to diverse perturbations quantitatively. However, autonomously
building computational models for virtual cells is challenging due to the
complexity of biological systems, the heterogeneity of data modalities, and the
need for domain-specific expertise across multiple disciplines. Here, we
introduce CellForge, an agentic system that leverages a multi-agent framework
that transforms presented biological datasets and research objectives directly
into optimized computational models for virtual cells. More specifically, given
only raw single-cell multi-omics data and task descriptions as input, CellForge
outputs both an optimized model architecture and executable code for training
virtual cell models and inference. The framework integrates three core modules:
Task Analysis for presented dataset characterization and relevant literature
retrieval, Method Design, where specialized agents collaboratively develop
optimized modeling strategies, and Experiment Execution for automated
generation of code. The agents in the Design module are separated into experts
with differing perspectives and a central moderator, and have to
collaboratively exchange solutions until they achieve a reasonable consensus.
We demonstrate CellForge's capabilities in single-cell perturbation prediction,
using six diverse datasets that encompass gene knockouts, drug treatments, and
cytokine stimulations across multiple modalities. CellForge consistently
outperforms task-specific state-of-the-art methods. Overall, CellForge
demonstrates how iterative interaction between LLM agents with differing
perspectives provides better solutions than directly addressing a modeling
challenge. Our code is publicly available at
https://github.com/gersteinlab/CellForge.

</details>


### [735] [How Does Controllability Emerge In Language Models During Pretraining?](https://arxiv.org/abs/2508.01892)
*Jianshu She,Xinyue Li,Eric Xing,Zhengzhong Liu,Qirong Ho*

Main category: cs.LG

TL;DR: 本研究提出了“干预探测器”（ID）框架，发现语言模型在训练中期获得可干预性，并提出量化指标解释可干预性动态。


<details>
  <summary>Details</summary>
Motivation: 填补了语言模型干预有效性条件不明确的空白，并为理解可干预性动态提供了方法。

Method: 提出“干预探测器”（ID）框架，通过分析隐藏状态和表示来揭示线性可干预性在训练过程中的演变。

Result: “干预探测器”显示，随着训练的进行，概念在隐藏空间中变得越来越线性可分，这与线性可干预性的出现密切相关。研究还提出了基于ID的指标（如热力图、熵趋势和余弦相似度）来解释可干预性的演变，并在不同模型家族中验证了研究结果的普遍性。

Conclusion: 语言模型在训练中期出现可干预性，并且特定概念的可干预性出现时间点不同。

Abstract: Language models can be steered by modifying their internal representations to
control concepts such as emotion, style, or truthfulness in generation.
However, the conditions for an effective intervention remain unclear and are
often validated through heuristics and trial-and-error. To fill this gap, we
demonstrate that intervention efficacy, measured by linear steerability (i.e.,
the ability to adjust output via linear transformations of hidden states),
emerges during intermediate stages of training. Moreover, even closely related
concepts (e.g., anger and sadness) exhibit steerability emergence at distinct
stages of training.
  To better interpret the dynamics of steerability during training, we adapt
existing intervention techniques into a unified framework, referred to as the
"Intervention Detector" (ID), which is designed to reveal how linear
steerability evolves over the course of training through hidden state and
representation analysis. ID reveals that concepts become increasingly linearly
separable in the hidden space as training progresses, which strongly correlates
with the emergence of linear steerability. We further introduce ID-based
metrics, such as heatmaps, entropy trends, and cosine similarity, to help
interpret how linear steerability evolves throughout training. In addition, we
apply ID across different model families to ensure the generality of our
findings on steerability dynamics.

</details>


### [736] [CAPO: Towards Enhancing LLM Reasoning through Verifiable Generative Credit Assignment](https://arxiv.org/abs/2508.02298)
*Guofu Xie,Yunsheng Shi,Hongtao Tian,Ting Yao,Xiao Zhang*

Main category: cs.LG

TL;DR: CAPO 是一种新的信用分配策略优化方法，它使用 LLM 作为奖励模型来提供 token 级奖励，从而改进 LLM 的推理能力，并在各种基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的 RLVR 方法通常将整个响应视为单个动作，分配相同的奖励给每个 token，这导致了粗粒度的反馈，阻碍了精确的信用分配，使得模型难以识别哪些推理步骤导致成功或失败，并常常导致次优策略和低效学习。

Method: CAPO (Credit Assignment Policy Optimization) 方法，它直接利用现成的、通用的 LLM 作为生成过程奖励模型 (LLM-as-GenPRM)，一次性生成所有步骤的评论，从而提供可验证的 token 级奖励，以优化最初分配了相同基于规则的奖励的 token。

Result: CAPO 持续优于监督学习和基于 RL 的微调方法，在六个具有挑战性的数学基准和三个域外基准上，使用了 Llama 和 Qwen 等不同骨干模型和不同尺寸的模型进行了广泛的实验。

Conclusion: CAPO 通过使用现成的、通用的 LLM 作为生成过程奖励模型 (LLM-as-GenPRM)，并利用投票机制来增强准确性和鲁棒性，从而实现了细粒度的信用分配，并在各种数学基准和域外基准上取得了优于监督学习和基于 RL 的微调方法的性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has improved the
reasoning abilities of Large Language Models (LLMs) by using rule-based binary
feedback, helping to mitigate reward hacking. However, current RLVR methods
typically treat whole responses as single actions, assigning the same reward to
every token. This coarse-grained feedback hampers precise credit assignment,
making it hard for models to identify which reasoning steps lead to success or
failure, and often results in suboptimal policies and inefficient learning.
Methods like PPO provide credit assignment through value estimation, but often
yield inaccurate and unverifiable signals due to limited sampling. On the other
hand, methods using Process Reward Models can provide step-by-step judgments
for each reasoning step, but they require high-quality process supervision
labels and are time-consuming when applied in online reinforcement learning
(RL). To overcome these limitations, we introduce a simple but efficient method
Credit Assignment Policy Optimization (CAPO). Given a reasoning response
rollout from the policy model, CAPO directly leverages an off-the-shelf,
general-purpose LLM as a Generative Process Reward Model (LLM-as-GenPRM) to
generate all step-wise critique by one pass, thereby providing verifiable
token-level rewards to refine the tokens that were originally assigned
identical rule-based rewards. This enables more fine-grained credit assignment
in an effective way. Furthermore, to enhance the accuracy and robustness of
CAPO, we employ voting mechanisms that scale with the number of generated
critiques. Extensive experiments using different backbones like Llama and Qwen
models and in different sizes show that CAPO consistently outperforms
supervised learning-based and RL-based fine-tuning methods across six
challenging mathematical benchmarks and three out-of-domain benchmarks.

</details>


### [737] [Language Model Guided Reinforcement Learning in Quantitative Trading](https://arxiv.org/abs/2508.02366)
*Adam Darmanin,Vince Vella*

Main category: cs.LG

TL;DR: LLMs can guide RL agents for better algorithmic trading by providing strategic direction, improving performance over standard RL methods.


<details>
  <summary>Details</summary>
Motivation: Algorithmic trading needs short-term decisions aligned with long-term financial goals. Existing RL approaches suffer from myopic behavior and opaque policies. LLMs show potential for strategic reasoning and financial signal interpretation, making them suitable for guiding RL agents.

Method: A hybrid system combining LLMs and RL agents is proposed. LLMs generate high-level trading strategies, which are then used to guide RL agents in their actions. The system's performance is evaluated by expert review of LLM-generated strategies and by comparing the Sharpe Ratio (SR) and Maximum Drawdown (MDD) of LLM-guided agents against unguided baselines.

Result: The LLM-guided RL agents demonstrated improved return and risk metrics (specifically, Sharpe Ratio and Maximum Drawdown) when compared to unguided baseline models.

Conclusion: LLM-guided RL agents show improved return and risk metrics compared to unguided baselines, indicating the effectiveness of LLMs in generating high-level trading strategies for algorithmic trading.

Abstract: Algorithmic trading requires short-term decisions aligned with long-term
financial goals. While reinforcement learning (RL) has been explored for such
tactical decisions, its adoption remains limited by myopic behavior and opaque
policy rationale. In contrast, large language models (LLMs) have recently
demonstrated strategic reasoning and multi-modal financial signal
interpretation when guided by well-designed prompts.
  We propose a hybrid system where LLMs generate high-level trading strategies
to guide RL agents in their actions. We evaluate (i) the rationale of
LLM-generated strategies via expert review, and (ii) the Sharpe Ratio (SR) and
Maximum Drawdown (MDD) of LLM-guided agents versus unguided baselines. Results
show improved return and risk metrics over standard RL.

</details>


### [738] [From Binary to Continuous: Stochastic Re-Weighting for Robust Graph Explanation](https://arxiv.org/abs/2508.01925)
*Zhuomin Chen,Jingchao Ni,Hojat Allah Salehi,Xu Zheng,Dongsheng Luo*

Main category: cs.LG

TL;DR: 本研究提出了一种新的迭代解释框架，通过在解释子图识别和模型适应之间交替进行，解决了GNN解释中的分布不匹配问题，提高了解释的鲁棒性，并兼容多种GNN架构。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNNs）解释方法在解释其预测时面临挑战，特别是在解释时使用的图与训练时使用的图存在不匹配的情况下。现有方法通常在加权图上优化软边掩码，但这与GNNs训练时使用的非加权图不同。这种分布偏移会导致梯度不可靠，并降低解释质量，尤其是在生成小型稀疏子图时。

Method: 提出了一种新颖的迭代式解释框架，该框架通过在解释子图识别和模型适应两个阶段之间交替进行，以对齐模型训练数据的分布与解释过程中出现的加权图分布，从而提高解释的鲁棒性。具体而言，该方法首先从一个相对较大的解释子图开始，对软掩码优化进行可靠的优化；然后，基于该子图，为解释性和非解释性边分配重要性感知权重，并在加权图上重新训练GNN；最后，以递增方式减小子图，重复此过程，形成一个迭代式精炼过程。

Result: 实验结果表明，该方法在多个基准数据集和不同的GNN骨干网络及解释方法上持续改进了解释质量，并能灵活集成到不同的GNN架构中。

Conclusion: 该方法通过对GNN模型进行迭代式适应，能够有效解决现有解释方法中存在的分布不匹配问题，提升了解释的鲁棒性和质量，并且可以灵活地集成到不同的GNN架构中。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable performance in a wide
range of graph-related learning tasks. However, explaining their predictions
remains a challenging problem, especially due to the mismatch between the
graphs used during training and those encountered during explanation. Most
existing methods optimize soft edge masks on weighted graphs to highlight
important substructures, but these graphs differ from the unweighted graphs on
which GNNs are trained. This distributional shift leads to unreliable gradients
and degraded explanation quality, especially when generating small, sparse
subgraphs. To address this issue, we propose a novel iterative explanation
framework which improves explanation robustness by aligning the model's
training data distribution with the weighted graph distribution appeared during
explanation. Our method alternates between two phases: explanation subgraph
identification and model adaptation. It begins with a relatively large
explanation subgraph where soft mask optimization is reliable. Based on this
subgraph, we assign importance-aware edge weights to explanatory and
non-explanatory edges, and retrain the GNN on these weighted graphs. This
process is repeated with progressively smaller subgraphs, forming an iterative
refinement procedure. We evaluate our method on multiple benchmark datasets
using different GNN backbones and explanation methods. Experimental results
show that our method consistently improves explanation quality and can be
flexibly integrated with different architectures.

</details>


### [739] [Inferring Reward Machines and Transition Machines from Partially Observable Markov Decision Processes](https://arxiv.org/abs/2508.01947)
*Yuly Wu,Jiamou Liu,Libo Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为DBMM的更通用的自动机模型，并开发了一种名为DB-RPNI的更有效的学习算法，显著提高了在部分可观察环境中的强化学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于自动机的强化学习方法在处理非马尔可夫性方面存在局限性：1. 自动机表示仅关注基于奖励的非马尔可夫性，导致不自然的公式化；2. 推理算法计算成本高昂。

Method: 提出了一种名为双行为Mealy机（DBMM）的通用自动机模型，该模型可以同时处理基于奖励和基于转换的非马尔可夫性。提出了一种名为DB-RPNI的被动自动机学习算法，用于有效地推断DBMM。

Result: DB-RPNI的实验结果显示，相比于之前的最佳基线，其推理速度提高了三个数量级，并且能够学习到最小的、正确的自动机。

Conclusion: 所提出的DB-RPNI算法在学习有限的、正确的自动机方面有很好的效率，并且在速度上比之前的最佳方法快了三个数量级。

Abstract: Partially Observable Markov Decision Processes (POMDPs) are fundamental to
many real-world applications. Although reinforcement learning (RL) has shown
success in fully observable domains, learning policies from traces in partially
observable environments remains challenging due to non-Markovian observations.
Inferring an automaton to handle the non-Markovianity is a proven effective
approach, but faces two limitations: 1) existing automaton representations
focus only on reward-based non-Markovianity, leading to unnatural problem
formulations; 2) inference algorithms face enormous computational costs. For
the first limitation, we introduce Transition Machines (TMs) to complement
existing Reward Machines (RMs). To develop a unified inference algorithm for
both automata types, we propose the Dual Behavior Mealy Machine (DBMM) that
subsumes both TMs and RMs. We then introduce DB-RPNI, a passive automata
learning algorithm that efficiently infers DBMMs while avoiding the costly
reductions required by prior work. We further develop optimization techniques
and identify sufficient conditions for inferring the minimal correct automata.
Experimentally, our inference method achieves speedups of up to three orders of
magnitude over SOTA baselines.

</details>


### [740] [Navigating High Dimensional Concept Space with Metalearning](https://arxiv.org/abs/2508.01948)
*Max Gupta*

Main category: cs.LG

TL;DR: 研究表明，元学习在处理组合复杂性方面比特征复杂性更有效，并可通过增加适应步数来提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究梯度下降元学习是否能为神经网络提供归纳偏倚，以实现从少量样本中高效学习离散概念。

Method: 将元学习方法与基于梯度的元学习方法（如元-SGD）和监督学习基线进行比较，使用PCFG生成的布尔任务，并通过改变概念维度和组合性来系统地评估。

Result: 元学习在处理组合复杂性方面比特征复杂性更有效，并且通过增加适应步数可以提高泛化能力。二阶方法和扩展梯度适应在少样本概念学习中起着重要作用。

Conclusion: 梯度下降元学习能够通过增加适应步数来提高在复杂概念上的泛化能力，尤其是在处理组合复杂性方面优于特征复杂性。

Abstract: Rapidly learning abstract concepts from limited examples is a hallmark of
human intelligence. This work investigates whether gradient-based meta-learning
can equip neural networks with inductive biases for efficient few-shot
acquisition of discrete concepts. We compare meta-learning methods against a
supervised learning baseline on Boolean tasks generated by a probabilistic
context-free grammar (PCFG). By systematically varying concept dimensionality
(number of features) and compositionality (depth of grammar recursion), we
identify regimes in which meta-learning robustly improves few-shot concept
learning. We find improved performance and sample efficiency by training a
multilayer perceptron (MLP) across concept spaces increasing in dimensional and
compositional complexity. We are able to show that meta-learners are much
better able to handle compositional complexity than featural complexity and
establish an empirical analysis demonstrating how featural complexity shapes
'concept basins' of the loss landscape, allowing curvature-aware optimization
to be more effective than first order methods. We see that we can robustly
increase generalization on complex concepts by increasing the number of
adaptation steps in meta-SGD, encouraging exploration of rougher loss basins.
Overall, this work highlights the intricacies of learning compositional versus
featural complexity in high dimensional concept spaces and provides a road to
understanding the role of 2nd order methods and extended gradient adaptation in
few-shot concept learning.

</details>


### [741] [What are you sinking? A geometric approach on attention sink](https://arxiv.org/abs/2508.02546)
*Valeria Ruscio,Umberto Nanni,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: Attention sink in transformers is due to geometric principles of reference frames, not architecture. Three types of reference frames correlate with AS and form early in training. Position encodings affect the frame type.


<details>
  <summary>Details</summary>
Motivation: To understand the underlying cause of the attention sink (AS) pattern in transformers, moving beyond the view of it as an architectural artifact to a fundamental geometric principle related to reference frames.

Method: Analyzed several transformer architectures to identify the correlation between reference frame types (centralized, distributed, bidirectional) and the attention sink phenomenon. Investigated the emergence of these reference frames during early training stages and their relationship with the problem of establishing stable coordinate systems. Examined the influence of architecture components, particularly position encoding implementations, on the specific type of reference frame.

Result: Identified three distinct reference frame types (centralized, distributed, bidirectional) that correlate with the attention sink phenomenon. Showed that these reference frames emerge during the earliest stages of training as optimal solutions for establishing stable coordinate systems. Demonstrated the influence of architecture components, such as position encodings, on the specific type of reference frame.

Conclusion: Attention sink (AS) is a manifestation of a fundamental geometric principle for establishing reference frames in transformers, not an architectural artifact. Different reference frame types (centralized, distributed, bidirectional) correlate with AS and emerge early in training as optimal solutions for stable coordinate systems. Architecture components, like position encodings, influence the type of reference frame.

Abstract: Attention sink (AS) is a consistent pattern in transformer attention maps
where certain tokens (often special tokens or positional anchors)
disproportionately attract attention from other tokens. We show that in
transformers, AS is not an architectural artifact, but it is the manifestation
of a fundamental geometric principle: the establishment of reference frames
that anchor representational spaces. We analyze several architectures and
identify three distinct reference frame types, centralized, distributed, and
bidirectional, that correlate with the attention sink phenomenon. We show that
they emerge during the earliest stages of training as optimal solutions to the
problem of establishing stable coordinate systems in high-dimensional spaces.
We show the influence of architecture components, particularly position
encoding implementations, on the specific type of reference frame. This
perspective transforms our understanding of transformer attention mechanisms
and provides insights for both architecture design and the relationship with
AS.

</details>


### [742] [Flow-Aware GNN for Transmission Network Reconfiguration via Substation Breaker Optimization](https://arxiv.org/abs/2508.01951)
*Dekang Meng,Rabab Haider,Pascal van Hentenryck*

Main category: cs.LG

TL;DR: OptiGridML是一个用于电力系统离散拓扑优化的机器学习框架，使用GNN来加速优化过程并提高输电出口。


<details>
  <summary>Details</summary>
Motivation: 解决电力系统离散拓扑优化问题，即选择变电站断路器配置以最大化跨区域输电出口，该问题通常被表述为混合整数规划（MIP），对于大型网络而言是NP难且在计算上难以处理的。

Method: 使用两阶段神经网络架构：线图神经网络（LGNN）近似给定网络拓扑的直流潮流，以及异构图神经网络（HeteroGNN）预测结构和物理约束下的断路器状态。通过物理信息一致性损失来连接这两个组件，强制执行基尔霍夫定律。

Result: OptiGridML实现了高达18%的输电出口改进，并将推理时间从几小时缩短到几毫秒。

Conclusion: OptiGridML通过使用结构化、感知流动的GNN来加速物理网络系统中的组合优化，在高达1000个断路器的合成网络上实现了高达18%的输电出口改进，并将推理时间从几小时缩短到几毫秒。

Abstract: This paper introduces OptiGridML, a machine learning framework for discrete
topology optimization in power grids. The task involves selecting substation
breaker configurations that maximize cross-region power exports, a problem
typically formulated as a mixed-integer program (MIP) that is NP-hard and
computationally intractable for large networks. OptiGridML replaces repeated
MIP solves with a two-stage neural architecture: a line-graph neural network
(LGNN) that approximates DC power flows for a given network topology, and a
heterogeneous GNN (HeteroGNN) that predicts breaker states under structural and
physical constraints. A physics-informed consistency loss connects these
components by enforcing Kirchhoff's law on predicted flows. Experiments on
synthetic networks with up to 1,000 breakers show that OptiGridML achieves
power export improvements of up to 18% over baseline topologies, while reducing
inference time from hours to milliseconds. These results demonstrate the
potential of structured, flow-aware GNNs for accelerating combinatorial
optimization in physical networked systems.

</details>


### [743] [Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands Mixture of Adaptation Modules](https://arxiv.org/abs/2508.02587)
*Yilun Liu,Yunpu Ma,Yuetian Lu,Shuo Chen,Zifeng Ding,Volker Tresp*

Main category: cs.LG

TL;DR: PEFT strategies should incorporate routing mechanisms for MoE language models to leverage their dynamic routing benefits, as demonstrated by experiments showing improved performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing PEFT strategies fail to leverage the benefits of MoE's dynamic routing mechanism, motivating the investigation into incorporating routing mechanisms within adaptation modules to align with MoE's architecture.

Method: Investigating whether adaptation modules should incorporate routing mechanisms to align with MoE's multi-expert architecture by analyzing the dynamics of core components when applying PEFT to MoE language models and examining how different routing strategies affect adaptation effectiveness.

Result: Extensive experiments on OLMoE-1B-7B and Mixtral-8x7B for commonsense and math reasoning tasks validate the performance and efficiency of the routed approach.

Conclusion: The study validates the performance and efficiency of a routed approach for PEFT in MoE language models, identifying optimal configurations and providing practical insights for better PEFT and MoE applications.

Abstract: Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among
their specialized experts, which existing Parameter- Efficient Fine-Tuning
(PEFT) strategies fail to leverage. This motivates us to investigate whether
adaptation modules themselves should incorporate routing mechanisms to align
with MoE's multi-expert architecture. We analyze dynamics of core components
when applying PEFT to MoE language models and examine how different routing
strategies affect adaptation effectiveness. Extensive experiments adapting
OLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks
validate the performance and efficiency of our routed approach. We identify the
optimal configurations for different scenarios and provide empirical analyses
with practical insights to facilitate better PEFT and MoE applications.

</details>


### [744] [Stochastic Encodings for Active Feature Acquisition](https://arxiv.org/abs/2508.01957)
*Alexander Norcliffe,Changhee Lee,Fergus Imrie,Mihaela van der Schaar,Pietro Lio*

Main category: cs.LG

TL;DR: 提出了一种新的潜在变量模型，用于主动特征采集，以克服现有方法的局限性，并在各种数据集上取得了优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法（如强化学习，存在训练困难；或贪婪地最大化标签和未观测特征的条件互信息，导致短视采集）的缺点。

Method: 提出了一种潜在变量模型，并以监督方式进行训练。通过对许多可能的未观测实现的特征进行推理来做出采集决策，这些推理是在随机潜在空间中进行的。

Result: 与各种基线相比，在广泛的合成和真实数据集上，该方法始终表现更优。

Conclusion: 该方法在广泛的合成和真实数据集上进行了广泛的评估，并可靠地优于各种基线。

Abstract: Active Feature Acquisition is an instance-wise, sequential decision making
problem. The aim is to dynamically select which feature to measure based on
current observations, independently for each test instance. Common approaches
either use Reinforcement Learning, which experiences training difficulties, or
greedily maximize the conditional mutual information of the label and
unobserved features, which makes myopic acquisitions. To address these
shortcomings, we introduce a latent variable model, trained in a supervised
manner. Acquisitions are made by reasoning about the features across many
possible unobserved realizations in a stochastic latent space. Extensive
evaluation on a large range of synthetic and real datasets demonstrates that
our approach reliably outperforms a diverse set of baselines.

</details>


### [745] [Kronecker-LoRA: hybrid Kronecker-LoRA adapters for scalable, sustainable fine-tuning](https://arxiv.org/abs/2508.01961)
*Yixin Shen*

Main category: cs.LG

TL;DR: Kron-LoRA是一种新的适配器，通过克罗内克积和低秩分解，比LoRA更节省参数且易于量化，同时保持了相当的性能，特别是在跨任务迁移学习方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了实现参数高效且表达能力强的适配器，以适应跨多个任务的预训练语言模型的微调。

Method: Kron-LoRA是一种两阶段适配器，首先将每个冻结的线性更新分解为克罗内克积（ΔW = A ⊗ B），然后通过r秩的LoRA分解压缩B（B ≈ B1B2）。

Result: Kron-LoRA在保持表达能力的同时，使用的参数比标准秩为8的LoRA适配器少4倍。其紧凑的适配器矩阵能够以更低的精度损失量化到8位或4位。在DistilBERT上，Kron-LoRA与LoRA-16性能相当；在Mistral-7B上，Kron-LoRA的性能与LoRA-8相当，同时内存占用更少，速度开销仅为3-8%。在连续微调任务中，Kron-LoRA的准确率高于LoRA-8，尽管参数量仅为其四分之一。

Conclusion: Kron-LoRA通过结合克罗内克结构、低秩压缩和量化友好性，为大型语言模型的多任务适应提供了一种可扩展、可持续且为持续学习做准备的解决方案。

Abstract: Fine-tuning massive pre-trained language models across many tasks demands
adapters that are both parameter-efficient and highly expressive. We introduce
\textbf{Kron-LoRA}, a two-stage adapter that first factorizes each frozen
linear update as a Kronecker product \[ \Delta W = A \otimes B \] and then
compresses \[ B \in \mathbb{R}^{d_{B2}\times d_{B1}} \] via an \(r\)-rank LoRA
decomposition \(B \approx B_{1}B_{2}\). By leveraging \[ \mathrm{rank}(A
\otimes B) \;=\; \mathrm{rank}(A)\,\mathrm{rank}(B), \] Kron-LoRA retains the
expressivity of the update while using up to $4\!\times\!$ fewer parameters
than a standard rank-8 LoRA adapter. Its compact adapter matrices also quantize
to 8- or 4-bit with less accuracy degradation than LoRA, enabling further
memory and storage savings for on-device deployment. We benchmark on DistilBERT
and Mistral-7B across five tasks (PIQA, HellaSwag, WinoGrande, ARC-Easy,
ARC-Challenge) over multiple epochs of adapter-only tuning: on DistilBERT, an
840 K-parameter Kron-LoRA matches LoRA-16's performance, and on Mistral-7B, a
5.7 M-parameter Kron-LoRA rivals LoRA-8 with modest memory savings and only a
3-8\% speed overhead. In sequential fine-tuning from ARC-Challenge to ARC-Easy,
Kron-LoRA retains 55.18\% accuracy versus 53.17\% for LoRA-8-despite using only
one-quarter of the adapter parameters-underscoring its competitive cross-task
transfer performance. By uniting Kronecker structure, low-rank compression,
quantization-friendliness, and by providing transparent trade-off analysis,
Kron-LoRA offers a scalable, sustainable, and continual-learning-ready solution
for multi-task adaptation of large language models.

</details>


### [746] [Accelerating LLM Reasoning via Early Rejection with Partial Reward Modeling](https://arxiv.org/abs/2508.01969)
*Seyyed Saeid Cheshmi,Azal Ahmad Khan,Xinran Wang,Zirui Liu,Ali Anwar*

Main category: cs.LG

TL;DR: 该研究提出了一种利用过程奖励模型（PRMs）在LLM推理过程中提前拒绝子最优候选方案的方法，可在不影响性能的情况下显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在推理任务中（如下棋、数学、逻辑和多步问答）因引入过程奖励模型（PRMs）而带来的高额计算开销问题，并探索能否在中途拒绝子最优的候选方案以提高效率。

Method: 提出了一种中途拒绝的方法，利用过程奖励模型（PRMs）在生成过程中提供早期信号，以在推理步骤完全完成之前拒绝子最优的候选方案。理论上证明了随着生成长度的增加，丢弃最优方案的风险呈指数级下降，并通过实验证明了部分奖励和最终奖励之间存在强相关性。

Result: 在数学推理基准测试中，该方法实现了1.4倍至9倍的推理FLOPs减少，同时保持了最终性能。

Conclusion: LLMs在数学推理等基准测试中，通过中途拒绝子最优候选者，可以将推理FLOPs减少1.4倍至9倍，同时不损害最终性能。这表明中途拒绝是提高LLM推理计算效率的有效机制。

Abstract: Large Language Models (LLMs) are increasingly relied upon for solving complex
reasoning tasks in domains such as mathematics, logic, and multi-step question
answering. A growing line of work seeks to improve reasoning quality by scaling
inference time compute particularly through Process Reward Models (PRMs), used
to reward the reasoning at intermediate steps. While effective, these methods
introduce substantial computational overhead, especially when generating large
numbers of solutions in parallel. In this paper, we investigate whether PRMs
can be used mid-generation to provide early signals that enable the rejection
of suboptimal candidates before full generation of step is complete. We
introduce the hypothesis that PRMs are also Partial Reward Models, meaning that
the scores they assign to partially completed reasoning step are predictive of
final output quality. This allows for principled early rejection based on
intermediate token-level signals. We support this hypothesis both
theoretically, by proving that the risk of discarding optimal beams decreases
exponentially with generation length and empirically, by demonstrating a strong
correlation between partial and final rewards across multiple reward models. On
math reasoning benchmarks, our method achieves up to 1.4$\times$-9$\times$
reduction in inference FLOPs without degrading final performance. These results
suggest that early rejection is a powerful mechanism for improving the
compute-efficiency of reasoning in LLMs.

</details>


### [747] [Improving Hospital Risk Prediction with Knowledge-Augmented Multimodal EHR Modeling](https://arxiv.org/abs/2508.01970)
*Rituparna Datta,Jiaming Cui,Zihan Guan,Rupesh Silwal,Joshua C Eby,Gregory Madden,Anil Vullikanti*

Main category: cs.LG

TL;DR: 本研究提出了一个创新的两阶段框架，利用大型语言模型（LLM）和图检索技术处理电子健康记录（EHRs）中的多模态数据，以提高临床风险预测的准确性，尤其在处理不平衡数据集方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确预测电子健康记录（EHRs）中的临床结果对于早期干预、有效分配资源和改善患者护理至关重要。EHRs包含多模态数据，如结构化数据和包含丰富上下文信息的非结构化临床笔记。

Method: 提出一个统一框架，包含两个阶段：第一阶段，通过微调的大型语言模型（LLM）提取临床笔记中的信息，并利用PubMed等医学语料库进行基于图的外部领域知识检索来增强LLM的理解；第二阶段，结合非结构化表示和结构化数据特征进行最终预测。

Result: 在30天再入院和住院死亡率预测任务中，该框架取得了0.84和0.92的AUC分数，优于所有现有基线和临床实践，包括已建立的风险评分系统。

Conclusion: 该框架通过结合结构化数据和基于图的知识检索方法，在临床风险预测方面取得了优于现有方法和临床实践的性能，特别是在处理不平衡数据集方面。

Abstract: Accurate prediction of clinical outcomes using Electronic Health Records
(EHRs) is critical for early intervention, efficient resource allocation, and
improved patient care. EHRs contain multimodal data, including both structured
data and unstructured clinical notes that provide rich, context-specific
information. In this work, we introduce a unified framework that seamlessly
integrates these diverse modalities, leveraging all relevant available
information through a two-stage architecture for clinical risk prediction. In
the first stage, a fine-tuned Large Language Model (LLM) extracts crucial,
task-relevant information from clinical notes, which is enhanced by graph-based
retrieval of external domain knowledge from sources such as a medical corpus
like PubMed, grounding the LLM's understanding. The second stage combines both
unstructured representations and features derived from the structured data to
generate the final predictions. This approach supports a wide range of clinical
tasks. Here, we demonstrate its effectiveness on 30-day readmission and
in-hospital mortality prediction. Experimental results show that our framework
achieves strong performance, with AUC scores of $0.84$ and $0.92$,
respectively, despite these tasks involving severely imbalanced datasets, with
positive rates ranging from approximately $4\%$ to $13\%$. Moreover, it
outperforms all existing baselines and clinical practices, including
established risk scoring systems. To the best of our knowledge, this is one of
the first frameworks for healthcare prediction which enhances the power of an
LLM-based graph-guided knowledge retrieval method by combining it with
structured data for improved clinical outcome prediction.

</details>


### [748] [Revitalizing Canonical Pre-Alignment for Irregular Multivariate Time Series Forecasting](https://arxiv.org/abs/2508.01971)
*Ziyu Zhou,Yiming Huang,Yanyun Wang,Yuankai Wu,James Kwok,Yuxuan Liang*

Main category: cs.LG

TL;DR: KAFNet 是一种处理不规则多元时间序列的新型紧凑型架构，通过改进 CPA 方法解决了计算开销问题，并在预测任务中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统 CPA 方法中零填充带来的计算开销问题，并捕捉全局变量间相关性，以提高 IMTS 建模效率和性能。

Method: KAFNet 架构，包含预卷积模块、时间核聚合模块和频域线性注意力块，用于处理 IMTS 数据。

Result: KAFNet 在参数量和训练-推理速度方面表现优于现有方法，同时实现了最先进的预测性能。

Conclusion: KAFNet 在多个 IMTS 数据集上实现了最先进的预测性能，参数量减少了 7.2 倍，训练-推理加速了 8.4 倍。

Abstract: Irregular multivariate time series (IMTS), characterized by uneven sampling
and inter-variate asynchrony, fuel many forecasting applications yet remain
challenging to model efficiently. Canonical Pre-Alignment (CPA) has been widely
adopted in IMTS modeling by padding zeros at every global timestamp, thereby
alleviating inter-variate asynchrony and unifying the series length, but its
dense zero-padding inflates the pre-aligned series length, especially when
numerous variates are present, causing prohibitive compute overhead. Recent
graph-based models with patching strategies sidestep CPA, but their local
message passing struggles to capture global inter-variate correlations.
Therefore, we posit that CPA should be retained, with the pre-aligned series
properly handled by the model, enabling it to outperform state-of-the-art
graph-based baselines that sidestep CPA. Technically, we propose KAFNet, a
compact architecture grounded in CPA for IMTS forecasting that couples (1)
Pre-Convolution module for sequence smoothing and sparsity mitigation, (2)
Temporal Kernel Aggregation module for learnable compression and modeling of
intra-series irregularity, and (3) Frequency Linear Attention blocks for the
low-cost inter-series correlations modeling in the frequency domain.
Experiments on multiple IMTS datasets show that KAFNet achieves
state-of-the-art forecasting performance, with a 7.2$\times$ parameter
reduction and a 8.4$\times$ training-inference acceleration.

</details>


### [749] [Diffusion models for inverse problems](https://arxiv.org/abs/2508.01975)
*Hyungjin Chung,Jeongsol Kim,Jong Chul Ye*

Main category: cs.LG

TL;DR: 本文回顾了使用扩散先验解决图像逆问题的各种方法，并讨论了其在不同情况下的应用和面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为研究人员提供对现有基于扩散模型逆问题求解器的全面概述。

Method: 本文回顾了近年来使用扩散先验解决图像逆问题的各种方法，将其分为经典显式近似方法以及变分推断、序列蒙特卡洛和解耦数据一致性等其他方法，并涵盖了其在盲逆问题、高维数据、数据稀疏和分布不匹配等更具挑战性情况下的扩展，以及利用文本等多模态信息的近期方法。

Result: 本文回顾了近年来使用扩散先验解决图像逆问题的各种方法，将其分为经典显式近似方法以及变分推断、序列蒙特卡洛和解耦数据一致性等其他方法，并涵盖了其在盲逆问题、高维数据、数据稀疏和分布不匹配等更具挑战性情况下的扩展，以及利用文本等多模态信息的近期方法。

Conclusion: 该章节旨在梳理连接这些算法的共同数学原理，系统对比它们在典型逆问题中的假设和性能权衡，并阐明基于扩散模型逆问题求解器的理论和实践挑战，以突出理论和实践中尚待解决的挑战。

Abstract: Using diffusion priors to solve inverse problems in imaging have
significantly matured over the years. In this chapter, we review the various
different approaches that were proposed over the years. We categorize the
approaches into the more classic explicit approximation approaches and others,
which include variational inference, sequential monte carlo, and decoupled data
consistency. We cover the extension to more challenging situations, including
blind cases, high-dimensional data, and problems under data scarcity and
distribution mismatch. More recent approaches that aim to leverage multimodal
information through texts are covered. Through this chapter, we aim to (i)
distill the common mathematical threads that connect these algorithms, (ii)
systematically contrast their assumptions and performance trade-offs across
representative inverse problems, and (iii) spotlight the open theoretical and
practical challenges by clarifying the landscape of diffusion model based
inverse problem solvers.

</details>


### [750] [Controllable and Stealthy Shilling Attacks via Dispersive Latent Diffusion](https://arxiv.org/abs/2508.01987)
*Shutong Qiao,Wei Yuan,Junliang Yu,Tong Chen,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.LG

TL;DR: DLDA是一种新的推荐系统攻击框架，可以生成逼真的虚假用户来操纵物品排名，同时逃避检测。实验表明，DLDA比之前的攻击更有效、更难检测。


<details>
  <summary>Details</summary>
Motivation: 现有攻击模型在同时实现强大的对抗性推广和保持逼真的行为以逃避检测方面存在不足，导致欺骗性攻击的真正严重性被低估。

Method: 提出了一种名为DLDA的基于扩散的攻击框架，该框架通过条件潜在扩散过程和分散正则化机制来生成逼真的虚假用户，以操纵物品排名。

Result: DLDA 在三个真实世界数据集和五个流行的推荐系统模型上进行了广泛的实验，结果表明与之前的攻击相比，DLDA 在实现更强的物品推广方面始终表现更好，并且更难被检测到。

Conclusion: 现有推荐系统更容易受到欺骗性攻击，需要更强的防御措施。

Abstract: Recommender systems (RSs) are now fundamental to various online platforms,
but their dependence on user-contributed data leaves them vulnerable to
shilling attacks that can manipulate item rankings by injecting fake users.
Although widely studied, most existing attack models fail to meet two critical
objectives simultaneously: achieving strong adversarial promotion of target
items while maintaining realistic behavior to evade detection. As a result, the
true severity of shilling threats that manage to reconcile the two objectives
remains underappreciated. To expose this overlooked vulnerability, we present
DLDA, a diffusion-based attack framework that can generate highly effective yet
indistinguishable fake users by enabling fine-grained control over target
promotion. Specifically, DLDA operates in a pre-aligned collaborative embedding
space, where it employs a conditional latent diffusion process to iteratively
synthesize fake user profiles with precise target item control. To evade
detection, DLDA introduces a dispersive regularization mechanism that promotes
variability and realism in generated behavioral patterns. Extensive experiments
on three real-world datasets and five popular RS models demonstrate that,
compared to prior attacks, DLDA consistently achieves stronger item promotion
while remaining harder to detect. These results highlight that modern RSs are
more vulnerable than previously recognized, underscoring the urgent need for
more robust defenses.

</details>


### [751] [Toward Efficient Spiking Transformers: Synapse Pruning Meets Synergistic Learning-Based Compensation](https://arxiv.org/abs/2508.01992)
*Hongze Sun,Wuque Cai,Duo Chen,Shifeng Mao,Jiayi He,Zhenxing Wang,Dezhong Yao,Daqing Guo*

Main category: cs.LG

TL;DR: 通过剪枝和协同学习，实现了轻量级且高性能的ST模型。


<details>
  <summary>Details</summary>
Motivation: 现有的ST模型需要大量的参数并且计算成本高，这限制了它们在资源受限环境中的部署。

Method: 提出了一种结合突触剪枝和协同学习的补偿策略来获得轻量级的ST模型。具体来说，引入了两种剪枝策略：一种是非结构化的L1P方法，用于诱导稀疏表示；另一种是结构化的DSP方法，用于诱导低秩表示。此外，还提出了一种增强的脉冲神经元模型sLIF，通过突触和内在可塑性之间的协同学习来有效补偿模型剪枝。

Result: 实验证明，所提出的方法显著减小了模型尺寸和计算开销，同时保持了具有竞争力的性能。

Conclusion: 所提出的剪枝和补偿策略能够有效地构建高效且高性能的基于ST的模型。

Abstract: As a foundational architecture of artificial intelligence models, Transformer
has been recently adapted to spiking neural networks with promising performance
across various tasks. However, existing spiking Transformer (ST)-based models
require a substantial number of parameters and incur high computational costs,
thus limiting their deployment in resource-constrained environments. To address
these challenges, we propose combining synapse pruning with a synergistic
learning-based compensation strategy to derive lightweight ST-based models.
Specifically, two types of tailored pruning strategies are introduced to reduce
redundancy in the weight matrices of ST blocks: an unstructured
$\mathrm{L_{1}P}$ method to induce sparse representations, and a structured DSP
method to induce low-rank representations. In addition, we propose an enhanced
spiking neuron model, termed the synergistic leaky integrate-and-fire (sLIF)
neuron, to effectively compensate for model pruning through synergistic
learning between synaptic and intrinsic plasticity mechanisms. Extensive
experiments on benchmark datasets demonstrate that the proposed methods
significantly reduce model size and computational overhead while maintaining
competitive performance. These results validate the effectiveness of the
proposed pruning and compensation strategies in constructing efficient and
high-performing ST-based models.

</details>


### [752] [Generative Large-Scale Pre-trained Models for Automated Ad Bidding Optimization](https://arxiv.org/abs/2508.02002)
*Yu Lei,Jiayang Zhao,Yilei Zhao,Zhaoqi Zhang,Linyou Cai,Qianlong Xie,Xingxing Wang*

Main category: cs.LG

TL;DR: A new generative ad-bidding model (GRAD) improves performance and ROI by using Mixture-of-Experts and Causal Transformers to handle real-world constraints and exploration challenges.


<details>
  <summary>Details</summary>
Motivation: Modern auto-bidding systems need to balance performance with diverse advertiser goals and real-world constraints. While generative models offer a promising alternative to traditional methods, they face challenges such as distribution shift, limited exploration, and the need to meet specific constraints (e.g., CPM, ROI).

Method: GRAD (Generative Reward-driven Ad-bidding with Mixture-of-Experts) combines an Action-Mixture-of-Experts module for exploration with a Value Estimator of Causal Transformer for constraint-aware optimization, addressing challenges like distribution shift and exploration limitations in generative models.

Result: GRAD demonstrated significant enhancements in platform revenue, leading to a 2.18% increase in GMV and a 10.68% increase in ROI when implemented in marketing scenarios at Meituan.

Conclusion: Our proposed GRAD model, incorporating a Mixture-of-Experts for action exploration and a Causal Transformer for constraint optimization, significantly improves platform revenue and advertiser ROI, as demonstrated by extensive offline and online experiments and successful implementation in real-world marketing scenarios.

Abstract: Modern auto-bidding systems are required to balance overall performance with
diverse advertiser goals and real-world constraints, reflecting the dynamic and
evolving needs of the industry. Recent advances in conditional generative
models, such as transformers and diffusers, have enabled direct trajectory
generation tailored to advertiser preferences, offering a promising alternative
to traditional Markov Decision Process-based methods. However, these generative
methods face significant challenges, such as the distribution shift between
offline and online environments, limited exploration of the action space, and
the necessity to meet constraints like marginal Cost-per-Mille (CPM) and Return
on Investment (ROI). To tackle these challenges, we propose GRAD (Generative
Reward-driven Ad-bidding with Mixture-of-Experts), a scalable foundation model
for auto-bidding that combines an Action-Mixture-of-Experts module for diverse
bidding action exploration with the Value Estimator of Causal Transformer for
constraint-aware optimization. Extensive offline and online experiments
demonstrate that GRAD significantly enhances platform revenue, highlighting its
effectiveness in addressing the evolving and diverse requirements of modern
advertisers. Furthermore, GRAD has been implemented in multiple marketing
scenarios at Meituan, one of the world's largest online food delivery
platforms, leading to a 2.18% increase in Gross Merchandise Value (GMV) and
10.68% increase in ROI.

</details>


### [753] [An Evolving Scenario Generation Method based on Dual-modal Driver Model Trained by Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.02027)
*Xinzheng Wu,Junyi Chen,Shaolingfeng Ye,Wei Jiang,Yong Shen*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 Dual-DM 的新方法，使用多智能体强化学习来生成更高效、更多样化且同样逼真的自动驾驶测试场景，特别侧重于模拟危险驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 在基于演化场景的自动驾驶测试方法中，决定场景中背景车辆（BV）驾驶机动性的驾驶员模型构建方法在生成安全关键场景方面起着关键作用，特别是 BV 之间的合作对抗驾驶特性有助于高效生成具有高测试价值的安全关键场景。

Method: 使用多智能体强化学习（MARL）方法训练和生成了具有非对抗性和对抗性驾驶模式的双模式驾驶员模型（Dual-DM），并将其连接到连续的模拟交通环境以生成复杂的、多样化的和强交互的安全关键场景。

Result: Dual-DM 在场景保真度（>85% 与真实世界场景的相似性）和复杂性（复杂性指标：0.45，比两个基线高 32.35% 和 12.5%）方面没有性能下降的情况下，显著提高了安全关键场景生成的效率（效率指标：0.86，比两个基线高 195%）。此外，统计分析和案例研究证明了 Dual-DM 生成的安全关键演化场景在对抗交互模式方面具有多样性。

Conclusion: Dual-DM 通过演化场景生成方法极大地提高了安全关键场景生成的性能。

Abstract: In the autonomous driving testing methods based on evolving scenarios, the
construction method of the driver model, which determines the driving maneuvers
of background vehicles (BVs) in the scenario, plays a critical role in
generating safety-critical scenarios. In particular, the cooperative
adversarial driving characteristics between BVs can contribute to the efficient
generation of safety-critical scenarios with high testing value. In this paper,
a multi-agent reinforcement learning (MARL) method is used to train and
generate a dual-modal driver model (Dual-DM) with non-adversarial and
adversarial driving modalities. The model is then connected to a continuous
simulated traffic environment to generate complex, diverse and strong
interactive safety-critical scenarios through evolving scenario generation
method. After that, the generated evolving scenarios are evaluated in terms of
fidelity, test efficiency, complexity and diversity. Results show that without
performance degradation in scenario fidelity (>85% similarity to real-world
scenarios) and complexity (complexity metric: 0.45, +32.35% and +12.5% over two
baselines), Dual-DM achieves a substantial enhancement in the efficiency of
generating safety-critical scenarios (efficiency metric: 0.86, +195% over two
baselines). Furthermore, statistical analysis and case studies demonstrate the
diversity of safety-critical evolving scenarios generated by Dual-DM in terms
of the adversarial interaction patterns. Therefore, Dual-DM can greatly improve
the performance of the generation of safety-critical scenarios through evolving
scenario generation method.

</details>


### [754] [Confidence-Diversity Calibration of AI Judgement Enables Reliable Qualitative Coding](https://arxiv.org/abs/2508.02029)
*Zhilong Zhao,Yindi Liu*

Main category: cs.LG

TL;DR: LLM可用于大规模定性编码，通过结合模型信心和多样性可提高其可靠性，并实现高达65%的人工工作量节省。


<details>
  <summary>Details</summary>
Motivation: 为了解决在人类专家意见不一致的领域中评估LLM输出可靠性的挑战。

Method: 通过分析8个先进LLM在10个主题类别上的5680个编码决策，评估了模型的平均自我信心和模型多样性（使用香农熵量化）与模型间一致性的关系。

Result: 模型的平均自我信心与模型间一致性高度相关（Pearson r=0.82）；结合模型多样性后，一致性解释度接近完全（R^2=0.979）。提出的三层工作流程可自动接受35%的段落，错误率低于5%，并将剩余部分进行人工审查，最多可减少65%的人工工作量。跨领域实验也证实了这些改进。

Conclusion: LLM在定性编码中的应用可以通过结合模型的平均自我信心和模型多样性来提高可靠性，从而实现高效且准确的自动化编码。

Abstract: LLMs enable qualitative coding at large scale, but assessing the reliability
of their output remains challenging in domains where human experts seldom
agree. Analysing 5,680 coding decisions from eight state-of-the-art LLMs across
ten thematic categories, we confirm that a model's mean self-confidence already
tracks inter-model agreement closely (Pearson r=0.82). Adding model
diversity-quantified as the normalised Shannon entropy of the panel's
votes-turns this single cue into a dual signal that explains agreement almost
completely (R^2=0.979). The confidence-diversity duo enables a three-tier
workflow that auto-accepts 35% of segments with <5% audit-detected error and
routes the remainder for targeted human review, cutting manual effort by up to
65%. Cross-domain replication on six public datasets spanning finance,
medicine, law and multilingual tasks confirms these gains (kappa improvements
of 0.20-0.78). Our results establish a generalisable, evidence-based criterion
for calibrating AI judgement in qualitative research.

</details>


### [755] [Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning](https://arxiv.org/abs/2508.02039)
*Sijia Wang,Ricardo Henao*

Main category: cs.LG

TL;DR: 提出模型回收框架，实现数据无关的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据隐私担忧以及在无法获取源数据的情况下进行模型迁移的挑战，提出了源无关迁移学习。

Method: 提出一个模型回收框架，该框架能够识别相关的源模型子集，并在白盒和黑盒设置下进行参数高效的训练。

Result: 该框架使得模型即服务（MaaS）提供商能够构建高效的预训练模型库，为多源数据无关的监督迁移学习创造了机会。

Conclusion: 该研究提出了一个模型回收框架，可以在白盒和黑盒场景下进行参数高效的模型训练，通过识别相关的源模型子集进行重用。

Abstract: Increasing concerns for data privacy and other difficulties associated with
retrieving source data for model training have created the need for source-free
transfer learning, in which one only has access to pre-trained models instead
of data from the original source domains. This setting introduces many
challenges, as many existing transfer learning methods typically rely on access
to source data, which limits their direct applicability to scenarios where
source data is unavailable. Further, practical concerns make it more difficult,
for instance efficiently selecting models for transfer without information on
source data, and transferring without full access to the source models. So
motivated, we propose a model recycling framework for parameter-efficient
training of models that identifies subsets of related source models to reuse in
both white-box and black-box settings. Consequently, our framework makes it
possible for Model as a Service (MaaS) providers to build libraries of
efficient pre-trained models, thus creating an opportunity for multi-source
data-free supervised transfer learning.

</details>


### [756] [Epi$^2$-Net: Advancing Epidemic Dynamics Forecasting with Physics-Inspired Neural Networks](https://arxiv.org/abs/2508.02049)
*Rui Sun,Chenghua Gong,Tianjun Gu,Yuhao Zheng,Jie Ding,Juyuan Zhang,Liming Pan,Linyuan Lü*

Main category: cs.LG

TL;DR: Epi$^2$-Net enhances epidemic forecasting by combining physics-inspired neural networks with epidemiological data, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Current epidemic forecasting models are either mechanism-based, limited by oversimplified assumptions, or data-driven, risking biased representations due to lack of physical constraints. Existing attempts to integrate epidemiological knowledge into neural networks often fail to reconcile explicit physical priors with neural representations.

Method: Epi$^2$-Net, a framework built upon Physics-Inspired Neural Networks, reconceptualizes epidemic transmission from a physical transport perspective, introducing neural epidemic transport and a deep learning framework that integrates physical constraints with neural modules to model spatio-temporal patterns.

Result: Epi$^2$-Net outperforms state-of-the-art methods in epidemic forecasting on real-world datasets.

Conclusion: Epi$^2$-Net in 业the experiments demonstrated superior performance compared to state-of-the-art methods, offering a promising approach for future epidemic containment.

Abstract: Advancing epidemic dynamics forecasting is vital for targeted interventions
and safeguarding public health. Current approaches mainly fall into two
categories: mechanism-based and data-driven models. Mechanism-based models are
constrained by predefined compartmental structures and oversimplified system
assumptions, limiting their ability to model complex real-world dynamics, while
data-driven models focus solely on intrinsic data dependencies without physical
or epidemiological constraints, risking biased or misleading representations.
Although recent studies have attempted to integrate epidemiological knowledge
into neural architectures, most of them fail to reconcile explicit physical
priors with neural representations. To overcome these obstacles, we introduce
Epi$^2$-Net, a Epidemic Forecasting Framework built upon Physics-Inspired
Neural Networks. Specifically, we propose reconceptualizing epidemic
transmission from the physical transport perspective, introducing the concept
of neural epidemic transport. Further, we present a physic-inspired deep
learning framework, and integrate physical constraints with neural modules to
model spatio-temporal patterns of epidemic dynamics. Experiments on real-world
datasets have demonstrated that Epi$^2$-Net outperforms state-of-the-art
methods in epidemic forecasting, providing a promising solution for future
epidemic containment. The code is available at:
https://anonymous.4open.science/r/Epi-2-Net-48CE.

</details>


### [757] [SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration](https://arxiv.org/abs/2508.02069)
*Bang Hu,Changze Lv,Mingjie Li,Yunpeng Liu,Xiaoqing Zheng,Fengzhe Zhang,Wei cao,Fan Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的SNN架构，通过集成图结构学习和脉冲时间处理，在多元时间序列预测方面取得了最先进的成果，尤其在长序列数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 填补了SNN在多元时间序列预测中的空间建模方面的空白，旨在实现高效的时空建模。

Method: 提出了一种新的SNN架构，该架构集成了图结构学习和基于脉冲的时间处理。具体方法包括：嵌入时间特征和自适应矩阵，通过OBS块学习序列特征，使用MSSA块通过SAGE层分层聚合邻域信息，并提出DSF块通过脉冲门控机制整合空间图特征和时间动态。

Result: 实验表明，该模型在所有数据集上超越了最先进的SNN模型iSpikformer，并在长序列数据集上优于传统的时间模型。

Conclusion: 该模型在所有数据集上都超越了最先进的SNN模型iSpikformer，并在长序列数据集上优于传统的时间模型，确立了高效时空建模的新范例。

Abstract: Spiking neural networks (SNNs), inspired by the spiking behavior of
biological neurons, offer a distinctive approach for capturing the complexities
of temporal data. However, their potential for spatial modeling in multivariate
time-series forecasting remains largely unexplored. To bridge this gap, we
introduce a brand new SNN architecture, which is among the first to seamlessly
integrate graph structural learning with spike-based temporal processing for
multivariate time-series forecasting. Specifically, we first embed time
features and an adaptive matrix, eliminating the need for predefined graph
structures. We then further learn sequence features through the Observation
(OBS) Block. Building upon this, our Multi-Scale Spike Aggregation (MSSA)
hierarchically aggregates neighborhood information through spiking SAGE layers,
enabling multi-hop feature extraction while eliminating the need for
floating-point operations. Finally, we propose a Dual-Path Spike Fusion (DSF)
Block to integrate spatial graph features and temporal dynamics via a
spike-gated mechanism, combining LSTM-processed sequences with spiking
self-attention outputs, effectively improve the model accuracy of long sequence
datasets. Experiments show that our model surpasses the state-of-the-art
SNN-based iSpikformer on all datasets and outperforms traditional temporal
models at long horizons, thereby establishing a new paradigm for efficient
spatial-temporal modeling.

</details>


### [758] [AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization](https://arxiv.org/abs/2508.02079)
*Amitava Das,Abhilekh Borah,Vinija Jain,Aman Chadha*

Main category: cs.LG

TL;DR: AGL通过结合多种正则化技术来解决LoRA微调中出现的对齐漂移问题，并在不影响模型性能的情况下有效提高了模型的安全性。


<details>
  <summary>Details</summary>
Motivation: LoRA微调大型语言模型（LLM）虽然高效，但即使是微小的更新也可能导致对齐漂移，削弱安全性和行为约束。

Method: AGL框架包含一个主要的任务损失、基于Fisher信息矩阵的正则化以及特定任务的正则化，并引入了碰撞感知正则化，结合了黎曼重叠和测地线分离。

Result: AGL在安全关键基准测试上将对齐漂移降低了高达50%，同时不损害下游任务的性能。消融实验表明，AGL的每个组件都能在保持潜在安全行为方面做出独特贡献。

Conclusion: AGL是一种结构上改进的LoRA，能够以最小的权衡来保持对齐，同时还发现了灾难性遗忘的缩放法则，显示AGL可以使微调后的损失升级变平，同时保持适应动力学。

Abstract: Low-rank adaptation (LoRA) has become a standard tool for efficiently
fine-tuning large language models (LLMs). Yet, even minor LoRA updates can
induce alignment drift, weakening safety and behavioral constraints through
entangled parameter changes. To address this, we propose AlignGuard-LoRA (AGL),
a principled framework for preserving alignment during finetuning. AGL
introduces several key components: a primary task loss for supervision, Fisher
Information Matrix-based regularization to restrict updates in
alignment-sensitive subspaces, and task-specific regularization to stabilize
the integration of new knowledge. We further introduce collision-aware
regularization, blending Riemannian overlap -- which penalizes coordinate-wise
interference -- and geodesic separation -- which encourages disjoint update
geometry. We curate DriftCaps, a targeted diagnostic benchmark of safe and
unsafe prompts designed to quantify alignment drift and safety degradation.
Empirical evaluations show that AGL mitigates alignment drift by up to 50% on
safety-critical benchmarks without degrading downstream task performance.
Comprehensive ablation confirms that each component contributes distinctly to
preserving latent safety behaviors. Finally, we derive and validate a scaling
law for catastrophic forgetting, revealing that AGL flattens post-finetuning
loss escalation while preserving adaptation dynamics. AGL is a structurally
grounded refinement of LoRA, ensuring alignment preservation with minimal
trade-offs. To encourage further exploration and development, we open-source
our implementation.

</details>


### [759] [The Geometry of Machine Learning Models](https://arxiv.org/abs/2508.02080)
*Pawel Gajer,Jacques Ravel*

Main category: cs.LG

TL;DR: 通过将机器学习模型的分区表示为具有体积和角度的几何结构，并利用微分几何方法分析其层间变化，为模型解释、正则化和诊断提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 为了通过几何角度分析机器学习模型，捕捉邻接关系、单元格体积、面体积和二面角等几何特性。

Method: 提出了一种将机器学习模型诱导的分区表示为黎曼单纯复形（Riemannian simplicial complexes）的数学框架，并结合微分形式追踪神经网络层间的几何结构变化。

Result: 开发了用于模型精炼的拉普拉斯算子和单纯样条，引入了量化局部几何复杂性的离散曲率和捕捉单元格间成对关系的边上的统计里奇曲率。  

Conclusion: 该框架通过微分几何和代数拓扑为机器学习模型分析提供了新的视角，可用于模型解释、正则化和诊断。

Abstract: This paper presents a mathematical framework for analyzing machine learning
  models through the geometry of their induced partitions. By representing
  partitions as Riemannian simplicial complexes, we capture not only adjacency
  relationships but also geometric properties including cell volumes, volumes
of
  faces where cells meet, and dihedral angles between adjacent cells. For
neural
  networks, we introduce a differential forms approach that tracks geometric
  structure through layers via pullback operations, making computations
  tractable by focusing on data-containing cells. The framework enables
  geometric regularization that directly penalizes problematic spatial
  configurations and provides new tools for model refinement through extended
  Laplacians and simplicial splines. We also explore how data distribution
  induces effective geometric curvature in model partitions, developing
discrete
  curvature measures for vertices that quantify local geometric complexity and
  statistical Ricci curvature for edges that captures pairwise relationships
  between cells. While focused on mathematical foundations, this geometric
  perspective offers new approaches to model interpretation, regularization,
and
  diagnostic tools for understanding learning dynamics.

</details>


### [760] [Instance-Dependent Continuous-Time Reinforcement Learning via Maximum Likelihood Estimation](https://arxiv.org/abs/2508.02103)
*Runze Zhao,Yue Yu,Ruhan Wang,Chunfeng Huang,Dongruo Zhou*

Main category: cs.LG

TL;DR: 提出了一种新的连续时间强化学习算法，该算法能根据环境难度进行调整，并具有理论性能保证。


<details>
  <summary>Details</summary>
Motivation: 研究连续时间强化学习（CTRL）在适应不同难度问题方面的能力。

Method: 提出了一种基于最大似然估计（MLE）和通用函数逼近器的简单模型方法，通过估计状态边际密度来指导学习，而不是直接估计系统动态。

Result: 推导出了与总奖励方差和测量分辨率相关的遗憾界限，并提出了一种包含随机测量计划的算法，以提高样本效率。

Conclusion: 该研究为设计能够根据环境的潜在难度自动调整其学习行为的连续时间强化学习算法提供了一个新的方向。

Abstract: Continuous-time reinforcement learning (CTRL) provides a natural framework
for sequential decision-making in dynamic environments where interactions
evolve continuously over time. While CTRL has shown growing empirical success,
its ability to adapt to varying levels of problem difficulty remains poorly
understood. In this work, we investigate the instance-dependent behavior of
CTRL and introduce a simple, model-based algorithm built on maximum likelihood
estimation (MLE) with a general function approximator. Unlike existing
approaches that estimate system dynamics directly, our method estimates the
state marginal density to guide learning. We establish instance-dependent
performance guarantees by deriving a regret bound that scales with the total
reward variance and measurement resolution. Notably, the regret becomes
independent of the specific measurement strategy when the observation frequency
adapts appropriately to the problem's complexity. To further improve
performance, our algorithm incorporates a randomized measurement schedule that
enhances sample efficiency without increasing measurement cost. These results
highlight a new direction for designing CTRL algorithms that automatically
adjust their learning behavior based on the underlying difficulty of the
environment.

</details>


### [761] [Real-Time Conflict Prediction for Large Truck Merging in Mixed Traffic at Work Zone Lane Closures](https://arxiv.org/abs/2508.02109)
*Abyad Enan,Abdullah Al Mamun,Gurcan Comert,Debbie Aisiana Indah,Judith Mwakalonge,Amy W. Apon,Mashrur Chowdhury*

Main category: cs.LG

TL;DR: 为了提高大型卡车在施工区域并道的安全性，本研究提出了一种基于LSTM的冲突预测方法，并与现有方法进行了比较。结果表明，LSTM方法能有效降低冲突风险，并允许卡车在行驶中提前并道。


<details>
  <summary>Details</summary>
Motivation: 大型卡车因其尺寸大和盲区多，是造成施工区域事故的主要原因，尤其是在需要并道的交叉口。本研究旨在通过评估合并冲突的风险并制定基于风险评估的合并决策策略，来提高大型卡车在施工区域合并机动的安全性。

Method: 使用长短期记忆（LSTM）神经网络来预测大型卡车合并到施工区域内的混合交通流中的风险。

Result: 与基于概率风险、第50百分位和第85百分位车头时距的基线合并策略相比，所提出的LSTM方法能降低冲突风险（通过降低暴露时间和时间积分碰撞时间来体现）。采用该方法的大型卡车可以在行驶中提前合并，而不是像基线方法那样在车道封闭末端完全停止。

Conclusion: 该研究提出了一种基于LSTM的冲突预测方法，以提高大型卡车在施工区域合并的安全性。结果表明，与基线方法相比，该方法能有效降低冲突风险，并允许卡车在行驶中提前合并，而不是在车道封闭末端完全停止。

Abstract: Large trucks substantially contribute to work zone-related crashes, primarily
due to their large size and blind spots. When approaching a work zone, large
trucks often need to merge into an adjacent lane because of lane closures
caused by construction activities. This study aims to enhance the safety of
large truck merging maneuvers in work zones by evaluating the risk associated
with merging conflicts and establishing a decision-making strategy for merging
based on this risk assessment. To predict the risk of large trucks merging into
a mixed traffic stream within a work zone, a Long Short-Term Memory (LSTM)
neural network is employed. For a large truck intending to merge, it is
critical that the immediate downstream vehicle in the target lane maintains a
minimum safe gap to facilitate a safe merging process. Once a conflict-free
merging opportunity is predicted, large trucks are instructed to merge in
response to the lane closure. Our LSTM-based conflict prediction method is
compared against baseline approaches, which include probabilistic risk-based
merging, 50th percentile gap-based merging, and 85th percentile gap-based
merging strategies. The results demonstrate that our method yields a lower
conflict risk, as indicated by reduced Time Exposed Time-to-Collision (TET) and
Time Integrated Time-to-Collision (TIT) values relative to the baseline models.
Furthermore, the findings indicate that large trucks that use our method can
perform early merging while still in motion, as opposed to coming to a complete
stop at the end of the current lane prior to closure, which is commonly
observed with the baseline approaches.

</details>


### [762] [Understanding the Essence: Delving into Annotator Prototype Learning for Multi-Class Annotation Aggregation](https://arxiv.org/abs/2508.02123)
*Ju Chen,Jun Feng,Shenyu Zhang*

Main category: cs.LG

TL;DR: PTBCC是一种新的真值推断方法，通过原型学习克服了传统混淆矩阵方法的局限性，在提高准确率和降低计算成本方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于混淆矩阵的真值推断方法在估计注释者专业知识时存在两个主要问题：1) 当注释者标注任务少或类别不平衡时，估计的混淆矩阵不可靠；2) 单个混淆矩阵不足以完全捕捉注释者在所有任务中的专业知识模式。PTBCC旨在解决这些问题。

Method: PTBCC（ProtoType learning-driven Bayesian Classifier Combination）是一种新颖的基于混淆矩阵的方法，通过原型学习来估计注释者。具体来说，它假设存在一组原型混淆矩阵，捕捉所有注释者的固有专业知识模式。每个注释者的专业知识被表示为在这些原型上的狄利克雷先验分布。

Result: PTBCC在11个真实世界数据集上的广泛实验表明，其准确率在最佳情况下提高了15%，平均准确率提高了3%，同时计算成本降低了90%以上。

Conclusion: PTBCC通过原型学习提供了一种可靠且更丰富的注释者估计方法，通过将每个注释者的专业知识表示为原型混淆矩阵上的狄利克雷先验分布，来解决现有基于混淆矩阵的方法在数据稀疏和类别不平衡问题上的不足，并能更灵活地刻画注释者。

Abstract: Multi-class classification annotations have significantly advanced AI
applications, with truth inference serving as a critical technique for
aggregating noisy and biased annotations. Existing state-of-the-art methods
typically model each annotator's expertise using a confusion matrix. However,
these methods suffer from two widely recognized issues: 1) when most annotators
label only a few tasks, or when classes are imbalanced, the estimated confusion
matrices are unreliable, and 2) a single confusion matrix often remains
inadequate for capturing each annotator's full expertise patterns across all
tasks. To address these issues, we propose a novel confusion-matrix-based
method, PTBCC (ProtoType learning-driven Bayesian Classifier Combination), to
introduce a reliable and richer annotator estimation by prototype learning.
Specifically, we assume that there exists a set $S$ of prototype confusion
matrices, which capture the inherent expertise patterns of all annotators.
Rather than a single confusion matrix, the expertise per annotator is extended
as a Dirichlet prior distribution over these prototypes. This prototype
learning-driven mechanism circumvents the data sparsity and class imbalance
issues, ensuring a richer and more flexible characterization of annotators.
Extensive experiments on 11 real-world datasets demonstrate that PTBCC achieves
up to a 15% accuracy improvement in the best case, and a 3% higher average
accuracy while reducing computational cost by over 90%.

</details>


### [763] [Understanding Learning Dynamics Through Structured Representations](https://arxiv.org/abs/2508.02126)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 深度学习模型训练的内在机制尚不完全清楚，而该研究通过引入特定的结构（如包含受限路径和自适应修正的变换层），来改善模型的训练稳定性、泛化性和适应性，并提供了可解释的设计原则。


<details>
  <summary>Details</summary>
Motivation: 深度网络的训练动态理解不足，常常是经验调整而非架构洞察驱动的，因此本文旨在研究内部结构选择如何影响学习系统的行为，特别是收敛性、泛化性和适应性。

Method: 本文提出了一种包含受限路径和自适应修正的丰富变换层系列，并通过理论分析和在合成及结构化任务上的实证研究，探讨了这些结构如何影响梯度流、谱敏感性和不动点行为。

Result: 研究表明，所提出的结构能够带来改进的鲁棒性、更平滑的优化过程以及可扩展的深度行为。

Conclusion: 本文的研究强调了架构设计在塑造可扩展和可信赖的神经网络的学习动态中的关键作用，并提出了一种可控设计原则，能够以可解释的方式引导学习行为。

Abstract: While modern deep networks have demonstrated remarkable versatility, their
training dynamics remain poorly understood--often driven more by empirical
tweaks than architectural insight. This paper investigates how internal
structural choices shape the behavior of learning systems. Building on prior
efforts that introduced simple architectural constraints, we explore the
broader implications of structure for convergence, generalization, and
adaptation. Our approach centers on a family of enriched transformation layers
that incorporate constrained pathways and adaptive corrections. We analyze how
these structures influence gradient flow, spectral sensitivity, and fixed-point
behavior--uncovering mechanisms that contribute to training stability and
representational regularity. Theoretical analysis is paired with empirical
studies on synthetic and structured tasks, demonstrating improved robustness,
smoother optimization, and scalable depth behavior. Rather than prescribing
fixed templates, we emphasize principles of tractable design that can steer
learning behavior in interpretable ways. Our findings support a growing view
that architectural design is not merely a matter of performance tuning, but a
critical axis for shaping learning dynamics in scalable and trustworthy neural
systems.

</details>


### [764] [Amber Pruner: Leveraging N:M Activation Sparsity for Efficient Prefill in Large Language Models](https://arxiv.org/abs/2508.02128)
*Tai An,Ruwu Cai,Yanzhe Zhang,Yang Liu,Hao Chen,Pengcheng Xie,Sheng Chang,Yiwu Yao,Gongyi Wang*

Main category: cs.LG

TL;DR: Amber Pruner 是一种无需训练的激活稀疏化技术，可加速 LLM 预填充阶段，并与 Outstanding-sparse 框架结合，在不损失性能的情况下提高效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有 LLM 压缩技术（如权重稀疏化）在准确率下降和激活稀疏化训练依赖性及泛化性挑战方面的问题。

Method: Amber Pruner 是一种训练无关的 N:M 激活稀疏化方法，专注于 LLM 的预填充阶段，目标是加速线性投影层。Outstanding-sparse 是一个统一框架，集成了 Amber Pruner 和 W8A8 量化。

Result: Amber Pruner 在多种模型和稀疏率（2:4、4:8 和 8:16）下，能在不重新训练模型的情况下，有效稀疏化并加速超过 55% 的线性计算。与 Outstanding-sparse 结合后，在各种下游任务（尤其在生成任务）上表现出强大的性能。

Conclusion: Amber Pruner 是一种无需训练即可实现 N:M 激活稀疏化并加速 LLM（特别是预填充阶段的线性层）的方法。它通过与 Outstanding-sparse 框架（结合了 W8A8 量化）集成，在不进行模型重新训练的情况下，实现了超过 55% 的线性计算稀疏化和加速，同时保持了在各种下游任务（尤其是在生成任务中）的强大性能。这项工作为激活稀疏化开辟了新途径，并为下一代 AI 系统的算法和架构协同设计提供了基础性见解。

Abstract: In the era of large language models (LLMs), N:M sparsity has emerged as a
structured compression technique critical for accelerating inference. While
prior work has primarily focused on weight sparsity, it often suffers from
significant accuracy degradation. Activation sparsity, though promising, is
typically training-dependent and faces challenges in generalization. To address
these limitations, we introduce Amber Pruner, a training-free N:M activation
sparsity method designed specifically for the prefill stage, targeting the
acceleration of linear projection layers in LLMs. Extensive experiments across
multiple models and sparsity ratios (2:4, 4:8, and 8:16) demonstrate that Amber
Pruner can effectively sparsify and accelerate more than 55% of linear
computations without requiring model retraining. To further enhance generality
and efficiency, we propose Outstanding-sparse, a unified framework that
integrates Amber Pruner with post-training W8A8 quantization. Our approach
preserves strong performance across a range of downstream tasks, with notable
advantages in generative tasks. This work pioneers a new frontier in activation
sparsity, providing foundational insights that are poised to guide the
co-evolution of algorithms and architectures in the design of next-generation
AI systems.

</details>


### [765] [The Complexity of Extreme Climate Events on the New Zealand's Kiwifruit Industry](https://arxiv.org/abs/2508.02130)
*Boyuan Zheng,Victor W. Chu,Zhidong Li,Evan Webster,Ashley Rootsey*

Main category: cs.LG

TL;DR: 气候变化影响猕猴桃产量，极端事件（霜冻、干旱、特大暴雨、热浪）影响不一，现有异常检测方法（如隔离森林）存在局限，需结合农场管理和气候数据以提高预测和应对能力。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了极端天气事件的频率和强度，对全球农业构成严峻挑战。本研究旨在探究气候变化，特别是霜冻、干旱、特大暴雨和热浪等极端事件，对新西兰猕猴桃产量产生的影响。

Method: 本研究采用隔离森林（Isolation Forest）这一无监督异常检测方法，分析了气候历史、极端天气事件（霜冻、干旱、特大暴雨、热浪）以及猕猴桃产量数据。

Result: 研究结果显示，不同类型的极端事件对猕猴桃产量的影响存在显著差异，并且气候极端与农场个体产量结果之间存在明显差异。此外，研究还发现了当前异常检测方法在识别特定事件（如霜冻）方面的局限性。

Conclusion: 本研究揭示了不同极端事件对猕猴桃产量影响的显著差异，并指出了当前异常检测方法在识别霜冻等事件时的局限性。研究强调了融合农场管理策略和气候适应实践的必要性，并计划采用集成方法，结合邻近农场产量数据和区域气候特征，以提高检测精度和响应策略的可靠性。

Abstract: Climate change has intensified the frequency and severity of extreme weather
events, presenting unprecedented challenges to the agricultural industry
worldwide. In this investigation, we focus on kiwifruit farming in New Zealand.
We propose to examine the impacts of climate-induced extreme events,
specifically frost, drought, extreme rainfall, and heatwave, on kiwifruit
harvest yields. These four events were selected due to their significant
impacts on crop productivity and their prevalence as recorded by climate
monitoring institutions in the country. We employed Isolation Forest, an
unsupervised anomaly detection method, to analyse climate history and recorded
extreme events, alongside with kiwifruit yields. Our analysis reveals
considerable variability in how different types of extreme event affect
kiwifruit yields underscoring notable discrepancies between climatic extremes
and individual farm's yield outcomes. Additionally, our study highlights
critical limitations of current anomaly detection approaches, particularly in
accurately identifying events such as frost. These findings emphasise the need
for integrating supplementary features like farm management strategies with
climate adaptation practices. Our further investigation will employ ensemble
methods that consolidate nearby farms' yield data and regional climate station
features to reduce variance, thereby enhancing the accuracy and reliability of
extreme event detection and the formulation of response strategies.

</details>


### [766] [FedLAD: A Linear Algebra Based Data Poisoning Defence for Federated Learning](https://arxiv.org/abs/2508.02136)
*Qi Xiong,Hai Dong,Nasrin Sohrabi,Zahir Tari*

Main category: cs.LG

TL;DR: FedLAD是一种基于线性代数的联邦学习安全方法，能有效防御数据投毒攻击，即使在大量恶意节点存在时也能保持高准确率和低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: Sybil攻击对联邦学习构成了严重威胁，恶意节点可能协同作用并占据多数，从而压倒整个系统。因此，开发能够确保联邦学习环境安全的对策至关重要。

Method: FedLAD将联邦学习的聚合过程建模为一个线性问题，并将其转化为一个线性代数优化挑战。该方法通过提取原始线性组合中的独立线性组合来识别潜在攻击，从而有效过滤掉冗余和恶意的元素。

Result: 实验评估表明，FedLAD在图像分类和自然语言处理任务中均优于Sherpa、CONTRA、Median、Trimmed Mean和Krum等五种已建立的防御方法。FedLAD在恶意节点比例从0.2到0.8时，能保持较低的攻击成功率；在恶意节点比例为0.2到0.5时，能保持较高的模型准确率。

Conclusion: FedLAD是一种新颖的、基于线性代数的检测方法，能够有效抵御针对性的数据投毒攻击，即使在恶意节点占主导地位的情况下也能保持系统的鲁棒性。与现有方法相比，FedLAD在广泛的恶意节点比例下均能保持较低的攻击成功率和较高的模型准确率，展现了其在增强联邦学习系统可靠性和性能方面的潜力。

Abstract: Sybil attacks pose a significant threat to federated learning, as malicious
nodes can collaborate and gain a majority, thereby overwhelming the system.
Therefore, it is essential to develop countermeasures that ensure the security
of federated learning environments. We present a novel defence method against
targeted data poisoning, which is one of the types of Sybil attacks, called
Linear Algebra-based Detection (FedLAD). Unlike existing approaches, such as
clustering and robust training, which struggle in situations where malicious
nodes dominate, FedLAD models the federated learning aggregation process as a
linear problem, transforming it into a linear algebra optimisation challenge.
This method identifies potential attacks by extracting the independent linear
combinations from the original linear combinations, effectively filtering out
redundant and malicious elements. Extensive experimental evaluations
demonstrate the effectiveness of FedLAD compared to five well-established
defence methods: Sherpa, CONTRA, Median, Trimmed Mean, and Krum. Using tasks
from both image classification and natural language processing, our experiments
confirm that FedLAD is robust and not dependent on specific application
settings. The results indicate that FedLAD effectively protects federated
learning systems across a broad spectrum of malicious node ratios. Compared to
baseline defence methods, FedLAD maintains a low attack success rate for
malicious nodes when their ratio ranges from 0.2 to 0.8. Additionally, it
preserves high model accuracy when the malicious node ratio is between 0.2 and
0.5. These findings underscore FedLAD's potential to enhance both the
reliability and performance of federated learning systems in the face of data
poisoning attacks.

</details>


### [767] [Fitness aligned structural modeling enables scalable virtual screening with AuroBind](https://arxiv.org/abs/2508.02137)
*Zhongyue Zhang,Jiahua Rao,Jie Zhong,Weiqiang Bai,Dongxue Wang,Shaobo Ning,Lifeng Qiao,Sheng Xu,Runze Ma,Will Hua,Jack Xiaoyu Chen,Odin Zhang,Wei Lu,Hanyi Feng,He Yang,Xinchao Shi,Rui Li,Wanli Ouyang,Xinzhu Ma,Jiahao Wang,Jixian Zhang,Jia Duan,Siqi Sun,Jian Zhang,Shuangjia Zheng*

Main category: cs.LG

TL;DR: AuroBind 是一个先进的虚拟筛选框架，能够以更高的精度和速度识别药物靶点，已在多个疾病领域取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 大多数人类蛋白质仍未被药物靶向，超过 96% 的人类蛋白质仍未被批准的疗法开发。虽然基于结构的虚拟筛选有望扩大可药物靶向的蛋白质组，但现有方法缺乏原子级的精度，并且无法预测结合适应性，这限制了其转化影响力。

Method: AuroBind 是一个可扩展的虚拟筛选框架，它在数百万规模的化学基因组学数据上对自定义的原子级结构模型进行微调。AuroBind 集成了直接偏好优化、来自高置信度复合物的自蒸馏以及教师-学生加速策略，以联合预测配体结合的结构和结合适应性。

Result: AuroBind 在结构和功能基准测试中表现优于最先进的模型，同时能够以 100,000 倍的速度跨超大规模化合物库进行筛选。在针对十个与疾病相关的靶点的预期筛选中，AuroBind 的实验命中率达到了 7-69%，其中顶级化合物的效力达到了亚纳摩尔到皮摩尔级别。对于孤儿 GPCR GPR151 和 GPR160，AuroBind 识别出了激动剂和拮抗剂，成功率分别为 16-30%，功能分析证实了在肝癌和前列腺癌模型中 GPR160 的调节。

Conclusion: AuroBind 是一个通用的框架，用于结构-功能学习和高通量分子筛选，它弥合了结构预测和治疗发现之间的差距。

Abstract: Most human proteins remain undrugged, over 96% of human proteins remain
unexploited by approved therapeutics. While structure-based virtual screening
promises to expand the druggable proteome, existing methods lack atomic-level
precision and fail to predict binding fitness, limiting translational impact.
We present AuroBind, a scalable virtual screening framework that fine-tunes a
custom atomic-level structural model on million-scale chemogenomic data.
AuroBind integrates direct preference optimization, self-distillation from
high-confidence complexes, and a teacher-student acceleration strategy to
jointly predict ligand-bound structures and binding fitness. The proposed
models outperform state-of-the-art models on structural and functional
benchmarks while enabling 100,000-fold faster screening across ultra-large
compound libraries. In a prospective screen across ten disease-relevant
targets, AuroBind achieved experimental hit rates of 7-69%, with top compounds
reaching sub-nanomolar to picomolar potency. For the orphan GPCRs GPR151 and
GPR160, AuroBind identified both agonists and antagonists with success rates of
16-30%, and functional assays confirmed GPR160 modulation in liver and prostate
cancer models. AuroBind offers a generalizable framework for structure-function
learning and high-throughput molecular screening, bridging the gap between
structure prediction and therapeutic discovery.

</details>


### [768] [PIGDreamer: Privileged Information Guided World Models for Safe Partially Observable Reinforcement Learning](https://arxiv.org/abs/2508.02159)
*Dongchi Huang,Jiaqi Wang,Yang Li,Chunhe Xia,Tianle Zhang,Kaige Zhang*

Main category: cs.LG

TL;DR: A new method called Privileged Information Guided Dreamer is proposed to improve safe reinforcement learning in partially observable environments by using privileged information. It shows better safety and performance than existing methods.


<details>
  <summary>Details</summary>
Motivation: Partial observability poses a significant challenge for safe reinforcement learning by hindering the identification of potential risks and rewards. Leveraging specific types of privileged information during training has shown empirical success in mitigating these effects.

Method: The paper proposes Asymmetric Constrained Partially Observable Markov Decision Processes (ACPOMDPs) to theoretically examine the advantages of incorporating privileged information. Building upon ACPOMDPs, a model-based safe reinforcement learning approach called the Privileged Information Guided Dreamer is proposed, which leverages privileged information through privileged representation alignment and an asymmetric actor-critic structure.

Result: Empirical results demonstrate that the Privileged Information Guided Dreamer approach significantly outperforms existing methods in terms of safety and task-centric performance. It also shows superior performance and ease of training compared to alternative privileged model-based reinforcement learning methods.

Conclusion: The proposed Privileged Information Guided Dreamer approach, built upon ACPOMDPs, significantly outperforms existing methods in safety and task-centric performance, and exhibits superior performance and ease of training compared to alternative privileged model-based reinforcement learning methods.

Abstract: Partial observability presents a significant challenge for safe reinforcement
learning, as it impedes the identification of potential risks and rewards.
Leveraging specific types of privileged information during training to mitigate
the effects of partial observability has yielded notable empirical successes.
In this paper, we propose Asymmetric Constrained Partially Observable Markov
Decision Processes (ACPOMDPs) to theoretically examine the advantages of
incorporating privileged information. Building upon ACPOMDPs, we propose the
Privileged Information Guided Dreamer, a model-based safe reinforcement
learning approach that leverages privileged information to enhance the agent's
safety and performance through privileged representation alignment and an
asymmetric actor-critic structure. Our empirical results demonstrate that our
approach significantly outperforms existing methods in terms of safety and
task-centric performance. Meanwhile, compared to alternative privileged
model-based reinforcement learning methods, our approach exhibits superior
performance and ease of training.

</details>


### [769] [User Trajectory Prediction Unifying Global and Local Temporal Information](https://arxiv.org/abs/2508.02161)
*Wei Hao,Bin Chong,Ronghua Ji,Chen Hou*

Main category: cs.LG

TL;DR: 提出了一种结合MLP、MSCNN和CA的模型，用于提取用户轨迹的全局和局部时间信息，以提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 轨迹预测对于制定预测用户移动性和支持预先准备的积极策略至关重要。然而，轨迹数据包含全局和局部时间信息，并且用户行为发生在不同的时间尺度上，这使得提取完整的时间模式和行为模式变得复杂。

Method: 提出了一种基于多层感知机（MLP）、多尺度卷积神经网络（MSCNN）和交叉注意力（CA）的轨迹预测模型。MLP用于提取每个特征的全局时间信息，MSCNN通过模拟局部时间范围内特征之间的交互来提取局部时间信息（通过不同大小的卷积核捕捉多分辨率的时间信息），CA用于融合全局和局部时间信息。

Result: 平均平方误差（MSE）降低了5.04%，平均绝对误差（MAE）降低了4.35%（与ModernTCN相比）。

Conclusion: 实验结果表明，所提出的模型在12步预测中，与ModernTCN相比，平均平方误差（MSE）降低了5.04%，平均绝对误差（MAE）降低了4.35%，同时保持了相似的推理时间。

Abstract: Trajectory prediction is essential for formulating proactive strategies that
anticipate user mobility and support advance preparation. Therefore, how to
reduce the forecasting error in user trajectory prediction within an acceptable
inference time arises as an interesting issue. However, trajectory data
contains both global and local temporal information, complicating the
extraction of the complete temporal pattern. Moreover, user behavior occurs
over different time scales, increasing the difficulty of capturing behavioral
patterns. To address these challenges, a trajectory prediction model based on
multilayer perceptron (MLP), multi-scale convolutional neural network (MSCNN),
and cross-attention (CA) is proposed. Specifically, MLP is used to extract the
global temporal information of each feature. In parallel, MSCNN is employed to
extract the local temporal information by modeling interactions among features
within a local temporal range. Convolutional kernels with different sizes are
used in MSCNN to capture temporal information at multiple resolutions,
enhancing the model's adaptability to different behavioral patterns. Finally,
CA is applied to fuse the global and local temporal information. Experimental
results show that our model reduces mean squared error (MSE) by 5.04% and mean
absolute error (MAE) by 4.35% compared with ModernTCN in 12-step prediction,
while maintaining similar inference time.

</details>


### [770] [Multi-Treatment-DML: Causal Estimation for Multi-Dimensional Continuous Treatments with Monotonicity Constraints in Personal Loan Risk Optimization](https://arxiv.org/abs/2508.02183)
*Kexin Zhao,Bo Wang,Cuiying Zhao,Tongyao Wan*

Main category: cs.LG

TL;DR: 提出了一种名为 Multi-Treatment-DML 的新颖框架，利用双重机器学习 (DML) 来处理多维连续处理的因果效应估计，同时强制执行处理和结果之间的一致性约束。实验和在线 A/B 测试均证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在个人贷款平台中优化信用额度、利率和贷款条款至关重要，但对这些连续、多维处理进行反事实估计面临重大挑战，因为随机试验受到风险控制和长还款周期的限制，并且现有因果方法难以处理连续、多维设置，同时还需要满足金融领域对处理-结果单调关系的规定。

Method: 提出了一种名为 Multi-Treatment-DML 的新颖框架，该框架利用双重机器学习 (DML) 来处理多维连续处理的因果效应估计，同时强制执行处理和结果之间的一致性约束。

Result: 在公开基准和真实工业数据集上进行的广泛实验以及在线 A/B 测试均证明了该方法的有效性。

Conclusion: 通过在真实的个人贷款平台上进行的在线 A/B 测试，证明了 Multi-Treatment-DML 在实际贷款业务中的优越性。

Abstract: Optimizing credit limits, interest rates, and loan terms is crucial for
managing borrower risk and lifetime value (LTV) in personal loan platform.
However, counterfactual estimation of these continuous, multi-dimensional
treatments faces significant challenges: randomized trials are often prohibited
by risk controls and long repayment cycles, forcing reliance on biased
observational data. Existing causal methods primarily handle binary/discrete
treatments and struggle with continuous, multi-dimensional settings.
Furthermore, financial domain knowledge mandates provably monotonic
treatment-outcome relationships (e.g., risk increases with credit limit).To
address these gaps, we propose Multi-Treatment-DML, a novel framework
leveraging Double Machine Learning (DML) to: (i) debias observational data for
causal effect estimation; (ii) handle arbitrary-dimensional continuous
treatments; and (iii) enforce monotonic constraints between treatments and
outcomes, guaranteeing adherence to domain requirements.Extensive experiments
on public benchmarks and real-world industrial datasets demonstrate the
effectiveness of our approach. Furthermore, online A/B testing conducted on a
realworld personal loan platform, confirms the practical superiority of
Multi-Treatment-DML in real-world loan operations.

</details>


### [771] [CAAD: Context-Aware Adaptive Decoding for Truthful Text Generation](https://arxiv.org/abs/2508.02184)
*Manh Nguyen,Sunil Gupta,Hung Le*

Main category: cs.LG

TL;DR: 一種新的語境感知自適應解碼方法，利用參考基礎空間修改大型語言模型的 logit，以提高生成文本的真實性，在多個基準測試中均優於現有方法。


<details>
  <summary>Details</summary>
Motivation: 解決了在確保大型語言模型的真實性方面的挑戰，並提出了一種比監督微調和人類回授增強學習更輕便的替代方法，以應對對標註數據和計算資源的大量需求。

Method: 提出了一種語境感知自適應解碼方法，該方法利用了緊湊的參考基礎空間，僅包含 10 個標註樣本，並由來自真實回應的上下文嵌入和下一個標記 logit 組成，以在推理過程中實現基於檢索的 logit 成形。

Result: 該方法在真實問答基準測試中平均提高了 2.8%，並在傳記和維基問答基準測試中表現優於現有基準，同時展示了跨任務的泛化能力。

Conclusion: 該模型證明了語境感知解碼的潛力，可用於提高大型語言模型的真實性。

Abstract: Ensuring truthfulness in large language models remains a critical challenge
for reliable text generation. While supervised fine-tuning and reinforcement
learning with human feedback have shown promise, they require substantial
amount of annotated data and computational resources, limiting scalability. In
contrast, decoding-time interventions offer lightweight alternatives without
model retraining. However, existing decoding strategies often face issues like
prompt sensitivity, limited generalization, or dependence on internal model
states. We propose a context-aware adaptive decoding method that leverages a
compact reference grounding space, built from as few as 10 annotated examples
and comprising pairs of context embeddings and next token logits from truthful
responses, to enable retrieval-based logit shaping during inference. At each
decoding step, our method retrieves top-N semantically similar contexts and
aggregates their associated next token logits to modify the LLM's logits.
Across three open-ended question-answering benchmarks, our approach achieves a
2.8 percent average improvement on TruthfulQA and further outperforms existing
baselines on both Biographies and WikiQA. Experimental results also demonstrate
cross-task generalization, with TruthfulQA-derived grounding enhancing
biography generation. Our model-agnostic, scalable, and efficient method
requires only a single generation pass, highlighting the potential of
context-aware decoding for factual reliability in LLMs.

</details>


### [772] [Balancing Information Accuracy and Response Timeliness in Networked LLMs](https://arxiv.org/abs/2508.02209)
*Yigit Turkmen,Baturalp Buyukates,Melih Bastopcu*

Main category: cs.LG

TL;DR: Networked LLMs with specialized clusters improve accuracy over individual models by aggregating outputs, especially when models perform similarly.


<details>
  <summary>Details</summary>
Motivation: The substantial requirements for training data, computational resources, and energy consumption of Large Language Models (LLMs) pose significant challenges for practical deployment. Leveraging smaller, specialized language models and aggregating their outputs is a promising alternative.

Method: A networked LLM system composed of multiple users, a central task processor, and clusters of topic-specialized LLMs was investigated. Users submit binary queries, which are routed to a selected cluster of $m$ LLMs. The processor gathers individual responses and returns a final aggregated answer. Information accuracy and response timeliness were characterized and formulated into a joint optimization problem.

Result: Extensive simulations demonstrate that aggregated responses consistently achieve higher accuracy than individual LLMs, especially when the participating LLMs exhibit similar standalone performance.

Conclusion: The aggregated responses from a networked system of specialized LLMs consistently achieve higher accuracy than individual LLMs, with improvements being more significant when participating LLMs have similar standalone performance.

Abstract: Recent advancements in Large Language Models (LLMs) have transformed many
fields including scientific discovery, content generation, biomedical text
mining, and educational technology. However, the substantial requirements for
training data, computational resources, and energy consumption pose significant
challenges for their practical deployment. A promising alternative is to
leverage smaller, specialized language models and aggregate their outputs to
improve overall response quality. In this work, we investigate a networked LLM
system composed of multiple users, a central task processor, and clusters of
topic-specialized LLMs. Each user submits categorical binary (true/false)
queries, which are routed by the task processor to a selected cluster of $m$
LLMs. After gathering individual responses, the processor returns a final
aggregated answer to the user. We characterize both the information accuracy
and response timeliness in this setting, and formulate a joint optimization
problem to balance these two competing objectives. Our extensive simulations
demonstrate that the aggregated responses consistently achieve higher accuracy
than those of individual LLMs. Notably, this improvement is more significant
when the participating LLMs exhibit similar standalone performance.

</details>


### [773] [Multi-Policy Pareto Front Tracking Based Online and Offline Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2508.02217)
*Zeyu Zhao,Yueling Che,Kaichen Liu,Jian Li,Junmei Yao*

Main category: cs.LG

TL;DR: 提出了一种新的多策略帕累托前沿跟踪（MPFT）框架，用于解决多目标强化学习（MORL）问题。该框架不依赖于进化框架和策略种群，通过逼近帕累托-顶点策略、跟踪帕累托前沿、识别稀疏区域和调整目标权重来逼近帕累托前沿。实验证明，MPFT比现有方法具有更好的性能，并且减少了计算资源。


<details>
  <summary>Details</summary>
Motivation: 传统的基于多策略（MP）的MORL方法依赖于在线强化学习和具有大策略种群的进化框架，这可能导致样本效率低下和/或过多的代理-环境交互。

Method: 提出了一种新的多策略帕累托前沿跟踪（MPFT）框架，该框架不维护任何策略种群，并且可以应用于在线和离线MORL算法。该框架包括四个阶段：1.逼近所有帕累托-顶点策略；2.跟踪帕累托前沿；3.识别稀疏区域并调整目标权重；4.逼近帕累托前沿。

Result: MPFT框架在七个不同的连续动作机器人控制任务上进行了实验，并且与最先进的基准进行了比较。结果表明，MPFT方法具有优越的超体积性能，并且显著减少了代理-环境交互和硬件需求。

Conclusion: MPFT框架在七个不同的连续动作机器人控制任务上进行了实验，并且与最先进的基准进行了比较。结果表明，MPFT方法具有优越的超体积性能，并且显著减少了代理-环境交互和硬件需求。

Abstract: Multi-objective reinforcement learning (MORL) plays a pivotal role in
addressing multi-criteria decision-making problems in the real world. The
multi-policy (MP) based methods are widely used to obtain high-quality Pareto
front approximation for the MORL problems. However, traditional MP methods only
rely on the online reinforcement learning (RL) and adopt the evolutionary
framework with a large policy population. This may lead to sample inefficiency
and/or overwhelmed agent-environment interactions in practice. By forsaking the
evolutionary framework, we propose the novel Multi-policy Pareto Front Tracking
(MPFT) framework without maintaining any policy population, where both online
and offline MORL algorithms can be applied. The proposed MPFT framework
includes four stages: Stage 1 approximates all the Pareto-vertex policies,
whose mapping to the objective space fall on the vertices of the Pareto front.
Stage 2 designs the new Pareto tracking mechanism to track the Pareto front,
starting from each of the Pareto-vertex policies. Stage 3 identifies the sparse
regions in the tracked Pareto front, and introduces a new objective weight
adjustment method to fill the sparse regions. Finally, by combining all the
policies tracked in Stages 2 and 3, Stage 4 approximates the Pareto front.
Experiments are conducted on seven different continuous-action robotic control
tasks with both online and offline MORL algorithms, and demonstrate the
superior hypervolume performance of our proposed MPFT approach over the
state-of-the-art benchmarks, with significantly reduced agent-environment
interactions and hardware requirements.

</details>


### [774] [Skeleton-Guided Learning for Shortest Path Search](https://arxiv.org/abs/2508.02270)
*Tiantian Liu,Xiao Li,Huan Li,Hua Lu,Christian S. Jensen,Jianliang Xu*

Main category: cs.LG

TL;DR: 提出了一种不依赖特定领域特征的通用图最短路径搜索的基于学习的框架。通过使用骨架图和骨架图神经网络（SGNN）来学习节点嵌入并预测距离，然后使用LSearch进行搜索。通过分层训练和HLSearch来处理更大的图。


<details>
  <summary>Details</summary>
Motivation: 解决现有图的最短路径搜索方法的局限性，这些方法在处理复杂图时效率低下，或者需要大量的预处理和存储，并且通常局限于空间图和特定于上下文的特征。

Method: 提出了一种通用的基于学习的框架，用于在通用图上进行最短路径搜索。该框架的核心是构建一个骨架图，以紧凑的形式捕获多级距离和跳数信息。骨架图神经网络（SGNN）在该结构上运行，以学习节点嵌入并预测节点对之间的距离和跳数。这些预测支持LSearch，一种引导搜索算法，它使用模型驱动的修剪来减少搜索空间，同时保持准确性。为了处理更大的图，引入了一种分层训练策略，将图划分为具有单独训练的SGNN的子图。这种结构使得HLSearch成为可能，它是我们方法的一个扩展，用于跨图分区进行高效路径搜索。

Result: 在五种不同的真实世界图上进行了实验，结果表明该框架具有强大的性能，为基于学习的最短路径搜索提供了灵活有效的解决方案。

Conclusion: 本框架在五种不同的真实世界图上实现了强大的性能，为基于学习的单程搜索提供了灵活有效的解决方案。

Abstract: Shortest path search is a core operation in graph-based applications, yet
existing methods face important limitations. Classical algorithms such as
Dijkstra's and A* become inefficient as graphs grow more complex, while
index-based techniques often require substantial preprocessing and storage.
Recent learning-based approaches typically focus on spatial graphs and rely on
context-specific features like geographic coordinates, limiting their general
applicability. We propose a versatile learning-based framework for shortest
path search on generic graphs, without requiring domain-specific features. At
the core of our approach is the construction of a skeleton graph that captures
multi-level distance and hop information in a compact form. A Skeleton Graph
Neural Network (SGNN) operates on this structure to learn node embeddings and
predict distances and hop lengths between node pairs. These predictions support
LSearch, a guided search algorithm that uses model-driven pruning to reduce the
search space while preserving accuracy. To handle larger graphs, we introduce a
hierarchical training strategy that partitions the graph into subgraphs with
individually trained SGNNs. This structure enables HLSearch, an extension of
our method for efficient path search across graph partitions. Experiments on
five diverse real-world graphs demonstrate that our framework achieves strong
performance across graph types, offering a flexible and effective solution for
learning-based shortest path search.

</details>


### [775] [An Enhanced Focal Loss Function to Mitigate Class Imbalance in Auto Insurance Fraud Detection with Explainable AI](https://arxiv.org/abs/2508.02283)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 针对保险欺诈预测中的类别不平衡问题，提出了一种新的多阶段焦点损失函数，通过动态调整难分类样本的关注度，提高了模型的性能和鲁棒性，并在真实数据集上取得了优于传统方法的实验结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决保险欺诈预测中数据类别不平衡的挑战，并提高机器学习模型在不平衡环境下的性能。

Method: 提出了一种新颖的多阶段焦点损失函数，该函数基于标准焦点损失，引入了动态、多阶段的凸轮和非凸机制，以逐步调整跨训练周期对难分类样本的关注度。

Result: 在真实世界保险数据集上的广泛实验表明，本研究提出的方法在准确率、精确率、F1分数、召回率和曲线下面积（AUC）等指标上均优于传统的焦点损失函数。

Conclusion: 本研究提出的多阶段焦点损失函数在处理不平衡数据方面优于传统焦点损失函数，在真实保险欺诈检测任务中提高了模型的鲁棒性和预测准确性，并包含一个可解释模型用于结果解释。

Abstract: In insurance fraud prediction, handling class imbalance remains a critical
challenge. This paper presents a novel multistage focal loss function designed
to enhance the performance of machine learning models in such imbalanced
settings by helping to escape local minima and converge to a good solution.
Building upon the foundation of the standard focal loss, our proposed approach
introduces a dynamic, multi-stage convex and nonconvex mechanism that
progressively adjusts the focus on hard-to-classify samples across training
epochs. This strategic refinement facilitates more stable learning and improved
discrimination between fraudulent and legitimate cases. Through extensive
experimentation on a real-world insurance dataset, our method achieved better
performance than the traditional focal loss, as measured by accuracy,
precision, F1-score, recall and Area Under the Curve (AUC) metrics on the auto
insurance dataset. These results demonstrate the efficacy of the multistage
focal loss in boosting model robustness and predictive accuracy in highly
skewed classification tasks, offering significant implications for fraud
detection systems in the insurance industry. An explainable model is included
to interpret the results.

</details>


### [776] [Flexible Automatic Identification and Removal (FAIR)-Pruner: An Efficient Neural Network Pruning Method](https://arxiv.org/abs/2508.02291)
*Chenqing Lin,Mostafa Hussien,Chengyao Yu,Mohamed Cheriet,Osama Abdelrahman,Ruixing Ming*

Main category: cs.LG

TL;DR: FAIR-Pruner 是一种新颖的神经网路结构剪枝方法，通过利用率得分和重建误差来自动确定逐层剪枝率，无需微调即可实现高效的模型压缩。


<details>
  <summary>Details</summary>
Motivation: 神经网路剪枝是一种关键的压缩技术，通常通过识别和消除冗余或不重要的参数来降低计算和内存开销，从而便于在资源受限的边缘设备上部署大型神经网路。

Method: FAIR-Pruner 首先通过 Wasserstein 距离量化的利用率得分来评估每个单元的重要性，然后引入通过损失函数泰勒展开计算的重建误差来反映单元移除后的性能下降。最后，通过控制衡量非重要单元与导致性能下降单元之间差异的差异容差，来识别对模型性能影响可忽略的冗余单元。

Result: FAIR-Pruner 在 ImageNet 等多样化基准数据集和 VGG 等各种神经网络架构上的全面实验验证，证明 FAIR-Pruner 在保持高精度的同时实现了显著的模型压缩。

Conclusion: FAIR-Pruner 通过自动确定逐层剪枝率，实现了比统一剪枝率更有效的子网络结构，并取得了出色的单次剪枝性能，无需进行剪枝后的微调。在 ImageNet 等多样化基准数据集和 VGG 等各种神经网络架构上的全面实验验证，证明 FAIR-Pruner 在保持高精度的同时实现了显著的模型压缩。

Abstract: Neural network pruning is a critical compression technique that facilitates
the deployment of large-scale neural networks on resource-constrained edge
devices, typically by identifying and eliminating redundant or insignificant
parameters to reduce computational and memory overhead. This paper proposes the
Flexible Automatic Identification and Removal (FAIR)-Pruner, a novel method for
neural network structured pruning. Specifically, FAIR-Pruner first evaluates
the importance of each unit (e.g., neuron or channel) through the Utilization
Score quantified by the Wasserstein distance. To reflect the performance
degradation after unit removal, it then introduces the Reconstruction Error,
which is computed via the Taylor expansion of the loss function. Finally,
FAIR-Pruner identifies superfluous units with negligible impact on model
performance by controlling the proposed Tolerance of Difference, which measures
differences between unimportant units and those that cause performance
degradation. A major advantage of FAIR-Pruner lies in its capacity to
automatically determine the layer-wise pruning rates, which yields a more
efficient subnetwork structure compared to applying a uniform pruning rate.
Another advantage of the FAIR-Pruner is its great one-shot performance without
post-pruning fine-tuning. Furthermore, with utilization scores and
reconstruction errors, users can flexibly obtain pruned models under different
pruning ratios. Comprehensive experimental validation on diverse benchmark
datasets (e.g., ImageNet) and various neural network architectures (e.g., VGG)
demonstrates that FAIR-Pruner achieves significant model compression while
maintaining high accuracy.

</details>


### [777] [Pre-Tactical Flight-Delay and Turnaround Forecasting with Synthetic Aviation Data](https://arxiv.org/abs/2508.02294)
*Abdulmajid Murad,Massimiliano Ruocco*

Main category: cs.LG

TL;DR: 本研究證明，在預戰術航空場景中，使用基於 Transformer 的生成器創建的合成數據，在預測飛機周轉時間、起飛延誤和到達延誤方面，可以達到真實數據 94-97% 的預測性能。這為在保護商業機密的同時擴大航空數據分析提供了途徑，但也提醒我們預戰術預測的準確性存在固有限制。


<details>
  <summary>Details</summary>
Motivation: 由於商業敏感性和競爭考慮因素，獲取全面的飛行運營數據在航空業受到嚴重限制，這阻礙了運營規劃預測模型的開發。本研究旨在評估合成數據是否可以在預戰術航空場景（基於預定航班信息進行數小時至數天前的預測）中有效替代真實運營數據，以訓練機器學習模型。

Method: 本研究使用「在合成數據上訓練，在真實數據上測試」（TSTR）的方法，對超過 170 萬條歐洲航班記錄進行了研究。評估了四種最先進的合成數據生成器，並對三項預測任務進行了測試：飛機周轉時間、起飛延誤和到達延誤。首先通過保真度評估驗證合成數據的質量，然後評估預測性能和運營關係的保留情況。

Result: 研究結果表明，先進的神經網絡架構，特別是基於 Transformer 的生成器，可以保留真實數據 94-97% 的預測性能，同時保持對運營決策提供信息的特徵重要性模式。此外，研究還發現，即使使用真實數據，僅憑預定信息預測的準確性也存在固有局限性，為預戰術預測建立了現實的基準。

Conclusion: 高質量合成數據可以擴大航空分析的能力，同時保護商業機密，但利益相關者必須對預戰術預測的準確性保持現實的期望，因為飛行操作本質上是隨機的。

Abstract: Access to comprehensive flight operations data remains severely restricted in
aviation due to commercial sensitivity and competitive considerations,
hindering the development of predictive models for operational planning. This
paper investigates whether synthetic data can effectively replace real
operational data for training machine learning models in pre-tactical aviation
scenarios-predictions made hours to days before operations using only scheduled
flight information. We evaluate four state-of-the-art synthetic data generators
on three prediction tasks: aircraft turnaround time, departure delays, and
arrival delays. Using a Train on Synthetic, Test on Real (TSTR) methodology on
over 1.7 million European flight records, we first validate synthetic data
quality through fidelity assessments, then assess both predictive performance
and the preservation of operational relationships. Our results show that
advanced neural network architectures, specifically transformer-based
generators, can retain 94-97% of real-data predictive performance while
maintaining feature importance patterns informative for operational
decision-making. Our analysis reveals that even with real data, prediction
accuracy is inherently limited when only scheduled information is
available-establishing realistic baselines for pre-tactical forecasting. These
findings suggest that high-quality synthetic data can enable broader access to
aviation analytics capabilities while preserving commercial confidentiality,
though stakeholders must maintain realistic expectations about pre-tactical
prediction accuracy given the stochastic nature of flight operations.

</details>


### [778] [NMS: Efficient Edge DNN Training via Near-Memory Sampling on Manifolds](https://arxiv.org/abs/2508.02313)
*Boran Zhao,Haiduo Huang,Qiwei Dang,Wenzhe Zhao,Tian Xia,Pengju Ren*

Main category: cs.LG

TL;DR: 该论文提出了一种名为NMS的快速DNN训练系统，采用无DNN的近内存采样技术，解决了现有方法的泛化问题和高能耗问题，并在模型准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: DNN在边缘设备上的训练吸引了越来越多的关注，以解决域适应和隐私保护的挑战。然而，DNN的训练需要大量数据集，导致能耗巨大，使得在边缘设备上训练不切实际。现有的数据集压缩方法（如coreset选择和数据集蒸馏）存在两个主要缺陷：1）需要利用DNN模型评估样本质量，引入了DNN的归纳偏差，导致严重的泛化问题；2）所有训练图像都需要通过长距离PCB连接多次访问DDR，导致显著的能耗开销。

Method: 提出了一种无DNN的样本选择算法DE-SNE，以解决泛化问题。利用近内存计算技术实现DE-SNE，以减少DDR能耗。构建了一个具有更高效原地近内存采样特性的快速DNN训练系统NMS。

Result: NMS在模型准确性方面优于当前最先进的方法DQ、DQAS和NeSSA。

Conclusion: NMS是第一个无DNN的近内存采样技术，可以有效缓解泛化问题并显著降低因数据集访问引起的DDR能耗。实验结果表明，NMS在模型准确性方面优于当前最先进的方法DQ、DQAS和NeSSA。

Abstract: Training deep neural networks (DNNs) on edge devices has attracted increasing
attention due to its potential to address challenges related to domain
adaptation and privacy preservation. However, DNNs typically rely on large
datasets for training, which results in substantial energy consumption, making
the training in edge devices impractical. Some dataset compression methods have
been proposed to solve this challenge. For instance, the coreset selection and
dataset distillation reduce the training cost by selecting and generating
representative samples respectively. Nevertheless, these methods have two
significant defects: (1) The necessary of leveraging a DNN model to evaluate
the quality of representative samples, which inevitably introduces inductive
bias of DNN, resulting in a severe generalization issue; (2) All training
images require multiple accesses to the DDR via long-distance PCB connections,
leading to substantial energy overhead. To address these issues, inspired by
the nonlinear manifold stationary of the human brain, we firstly propose a
DNN-free sample-selecting algorithm, called DE-SNE, to improve the
generalization issue. Secondly, we innovatively utilize the near-memory
computing technique to implement DE-SNE, thus only a small fraction of images
need to access the DDR via long-distance PCB. It significantly reduces DDR
energy consumption. As a result, we build a novel expedited DNN training system
with a more efficient in-place Near-Memory Sampling characteristic for edge
devices, dubbed NMS. As far as we know, our NMS is the first DNN-free
near-memory sampling technique that can effectively alleviate generalization
issues and significantly reduce DDR energy caused by dataset access. The
experimental results show that our NMS outperforms the current state-of-the-art
(SOTA) approaches, namely DQ, DQAS, and NeSSA, in model accuracy.

</details>


### [779] [A Compression Based Classification Framework Using Symbolic Dynamics of Chaotic Maps](https://arxiv.org/abs/2508.02330)
*Parth Naik,Harikrishnan N B*

Main category: cs.LG

TL;DR: ChaosComp：一种利用符号动力学和混沌映射进行数据压缩的分类新框架，性能与传统方法相当。


<details>
  <summary>Details</summary>
Motivation: 将分类问题通过动力学系统和压缩的视角进行重新诠释，这些视角是学习理论和信息处理的基础。

Method: 提出了一种基于符号动力学和混沌映射数据压缩的新颖分类框架。通过生成符号序列、计算转移概率以及使用混沌映射进行动态演化来为每个类构建概率模型。测试时，通过反向迭代和压缩来实现分类。

Result: 在合成和真实世界的数据集上评估了ChaosComp方法，其性能与传统机器学习算法相当，例如在乳腺癌Wisconsin数据集上的宏观F1分数达到0.9531，在Seeds数据集上达到0.9475，在Iris数据集上达到0.8317。

Conclusion: 该方法将分类问题视为一个压缩问题，其中测试数据被编码到最符合其动态模型和符号统计的类中。

Abstract: We propose a novel classification framework grounded in symbolic dynamics and
data compression using chaotic maps. The core idea is to model each class by
generating symbolic sequences from thresholded real-valued training data, which
are then evolved through a one-dimensional chaotic map. For each class, we
compute the transition probabilities of symbolic patterns (e.g., `00', `01',
`10', and `11' for the second return map) and aggregate these statistics to
form a class-specific probabilistic model. During testing phase, the test data
are thresholded and symbolized, and then encoded using the class-wise symbolic
statistics via back iteration, a dynamical reconstruction technique. The
predicted label corresponds to the class yielding the shortest compressed
representation, signifying the most efficient symbolic encoding under its
respective chaotic model. This approach fuses concepts from dynamical systems,
symbolic representations, and compression-based learning. We evaluate the
proposed method: \emph{ChaosComp} on both synthetic and real-world datasets,
demonstrating competitive performance compared to traditional machine learning
algorithms (e.g., macro F1-scores for the proposed method on Breast Cancer
Wisconsin = 0.9531, Seeds = 0.9475, Iris = 0.8317 etc.). Rather than aiming for
state-of-the-art performance, the goal of this research is to reinterpret the
classification problem through the lens of dynamical systems and compression,
which are foundational perspectives in learning theory and information
processing.

</details>


### [780] [BOOST: Bayesian Optimization with Optimal Kernel and Acquisition Function Selection Technique](https://arxiv.org/abs/2508.02332)
*Joon-Hyun Park,Mujin Cheon,Dong-Yeun Koh*

Main category: cs.LG

TL;DR: BOOST框架通过离线评估自动选择贝叶斯优化的核函数和获取函数，提升了优化效率和性能。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化（BO）的性能受核函数和获取函数等超参数选择的影响，不合适的组合会导致性能下降和评估浪费。现有研究虽分别改进了核函数和获取函数，但忽略了两者联合且自主的选择，迫使实践者依赖启发式方法或昂贵的调优。

Method: BOOST框架利用轻量级的离线评估阶段，将数据划分为参考子集和查询子集，对所有可能的核函数-获取函数组合进行内部贝叶斯优化运行，以评估其在未知查询子集上指导搜索到最优值的效果，从而选出回溯性表现最佳的配置。

Result: 实验结果表明，BOOST框架在合成基准函数和实际超参数优化任务上，一致优于使用固定超参数的标准BO方法。

Conclusion: BOOST框架能够自动选择最优的核函数和获取函数组合，在合成基准函数和实际超参数优化任务上均优于固定的超参数优化方法，展现了其在不同问题上的有效性和鲁棒性。

Abstract: The performance of Bayesian optimization (BO), a highly sample-efficient
method for expensive black-box problems, is critically governed by the
selection of its hyperparameters, including the kernel and acquisition
functions. This presents a challenge: an inappropriate combination of these can
lead to poor performance and wasted evaluations. While individual improvements
to kernel functions (e.g., tree-based kernels, deep kernel learning) and
acquisition functions (e.g., multi-step lookahead, tree-based planning) have
been explored, the joint and autonomous selection of the best pair of these
fundamental hyperparameters has been overlooked. This forces practitioners to
rely on heuristics or costly manual training. We propose a simple yet effective
framework, BOOST (Bayesian Optimization with Optimal Kernel and Acquisition
Function Selection Technique), that automates this selection. BOOST utilizes a
lightweight, offline evaluation stage to predict the performance of various
kernel-acquisition function pairs and identify the most suitable configuration
before expensive evaluations. BOOST partitions data-in-hand into two subsets: a
reference subset and a query subset, and it prepares all possible
kernel-acquisition pairs from the user's chosen candidates. For each
configuration, BOOST conducts internal BO runs using the reference subset,
evaluating how effectively each pair guides the search toward the optimum in
the unknown query subset, thereby identifying the configuration with the best
retrospective performance for future optimization. Experiments on both
synthetic benchmark functions and real-world hyperparameter optimization tasks
demonstrate that BOOST consistently outperforms standard BO approaches with
fixed hyperparameters, highlighting its effectiveness and robustness in diverse
problem landscapes.

</details>


### [781] [Posterior Sampling of Probabilistic Word Embeddings](https://arxiv.org/abs/2508.02337)
*Väinö Yrjänäinen,Isac Boström,Måns Magnusson,Johan Jonasson*

Main category: cs.LG

TL;DR: 提出了一种可扩展的Gibbs采样器来量化词嵌入中的不确定性，并与现有方法进行了比较，证明了其在大规模数据集上的可行性和优越性。


<details>
  <summary>Details</summary>
Motivation: 量化词嵌入中的不确定性对于从文本数据中进行可靠推理至关重要，但现有的贝叶斯方法在计算上不可行或依赖于严格的假设。

Method: 使用Polya-Gamma增强和拉普拉斯近似提出了一种可扩展的Gibbs采样器，并与MFVI和HMC进行了比较，同时解决了词嵌入中的不可识别性问题。

Result: Gibbs采样器和HMC估计了不确定性，MFVI没有，拉普拉斯近似仅在大样本量下有效。Gibbs采样器在大规模真实数据上是可行的，并且后验均值比MAP估计在hold-out似然方面表现更好。

Conclusion: Gibbs采样器和HMC能够正确估计不确定性，而MFVI不能，拉普拉斯近似仅在大样本量下才能做到。Gibbs采样器在US Congress和Movielens数据集上的应用证明了其在大规模真实数据上的可行性。后验均值优于MAP估计，特别是在较小的采样尺寸下。

Abstract: Quantifying uncertainty in word embeddings is crucial for reliable inference
from textual data. However, existing Bayesian methods such as Hamiltonian Monte
Carlo (HMC) and mean-field variational inference (MFVI) are either
computationally infeasible for large data or rely on restrictive assumptions.
  We propose a scalable Gibbs sampler using Polya-Gamma augmentation as well as
Laplace approximation and compare them with MFVI and HMC for word embeddings.
In addition, we address non-identifiability in word embeddings. Our Gibbs
sampler and HMC correctly estimate uncertainties, while MFVI does not, and
Laplace approximation only does so on large sample sizes, as expected. Applying
the Gibbs sampler to the US Congress and the Movielens datasets, we demonstrate
the feasibility on larger real data. Finally, as a result of having draws from
the full posterior, we show that the posterior mean of word embeddings improves
over maximum a posteriori (MAP) estimates in terms of hold-out likelihood,
especially for smaller sampling sizes, further strengthening the need for
posterior sampling of word embeddings.

</details>


### [782] [MicroMix: Efficient Mixed-Precision Quantization with Microscaling Formats for Large Language Models](https://arxiv.org/abs/2508.02343)
*Wenyuan Liu,Haoqian Meng,Yilun Luo,Peng Zhang,Xindian Ma*

Main category: cs.LG

TL;DR: MicroMix是一种新的混合精度量化算法和内核，专门为NVIDIA Blackwell架构设计，可以充分利用FP4 Tensor Cores的加速能力。它通过智能地混合使用MXFP4、MXFP6和MXFP8精度，并在不同模型和任务上实现了比现有方法更快的速度和更好的内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有的INT4量化方法无法充分利用NVIDIA Blackwell架构FP4 Tensor Cores提供的4倍加速，因为其数据格式不匹配。为了解决这个问题，需要一种能够充分利用新硬件能力并优化精度与效率之间权衡的量化解决方案。

Method: MicroMix是一种联合设计的混合精度量化算法和矩阵乘法内核，基于Microscaling (MX) 数据格式。它支持MXFP4、MXFP6和MXFP8通道的任意组合，并生成BFloat16输出。该算法通过引入量化阈值来识别激活元素，当这些元素量化到较低精度（MXFP4或MXFP6）时会导致过量量化误差，并选择性地分配较高精度通道来保留精度和计算效率。

Result: MicroMix在包括零样本、少样本学习、语言建模、代码生成和数学推理在内的各种下游任务中实现了有竞争力或更优的性能。与TensorRT-FP8相比，其内核在消费级（RTX 5070Ti laptop）和服务器级（RTX 5090）GPU上至少快了20%。当应用于Llama和Qwen模型时，MicroMix在不同批次大小下均持续提高了预填充延迟和内存效率。

Conclusion: MicroMix算法通过支持MXFP4、MXFP6和MXFP8混合精度以及BFloat16输出，并结合专门为Blackwell架构设计的矩阵乘法内核，有效利用了FP4 Tensor Cores的加速能力。该算法通过量化阈值选择性地使用较低精度格式，以在保持计算效率的同时优化精度。在各种下游任务和模型上，MicroMix均展现出与现有方法相当或更优的性能，并且在RTX 5070Ti和RTX 5090 GPU上实现了比TensorRT-FP8至少20%的加速。此外，与TensorRT基线相比，MicroMix在Llama和Qwen模型上显著提高了预填充延迟和内存效率。

Abstract: Quantization significantly accelerates inference in large language models
(LLMs) by replacing original high-precision matrices with low-precision
counterparts. Recent advances in weight-activation quantization have primarily
focused on mapping both weights and activations to the INT4 format. Although
the new FP4 Tensor Cores in NVIDIA's Blackwell architecture offer up to 4x
speedup over FP16, existing INT4-based kernels fail to fully exploit this
capability due to mismatched data formats. To bridge this gap, we propose
MicroMix, a co-designed mixed-precision quantization algorithm and matrix
multiplication kernel based on Microscaling (MX) data formats. Tailored for the
Blackwell architecture, the MicroMix kernel supports arbitrary combinations of
MXFP4, MXFP6, and MXFP8 channels, and produces BFloat16 outputs. To achieve a
favorable trade-off between accuracy and efficiency for each linear layer, we
introduce quantization thresholds that identify activation elements where
lower-precision formats (MXFP4 or MXFP6) incur excessive quantization error.
Our algorithm selectively allocates higher-precision channels to preserve
accuracy while maintaining compute efficiency. MicroMix achieves competitive or
superior performance across diverse downstream tasks, including zero-shot and
few-shot learning, language modeling, code generation, and mathematical
reasoning. On both consumer-grade (RTX 5070Ti laptop) and server-grade (RTX
5090) GPUs, our kernel delivers at least 20% faster execution than
TensorRT-FP8. Furthermore, when applied to various Llama and Qwen models,
MicroMix consistently improves prefill latency and memory efficiency across a
range of batch sizes compared to TensorRT baselines. Our code is available at
https://github.com/lwy2020/MicroMix.

</details>


### [783] [A Novel Sliced Fused Gromov-Wasserstein Distance](https://arxiv.org/abs/2508.02364)
*Moritz Piening,Robert Beinert*

Main category: cs.LG

TL;DR: 该研究提出了一种新的切片技术，用于计算Gromov-Wasserstein (GW) 和Fused Gromov-Wasserstein (FGW) 距离，这种技术可以降低计算复杂度，同时保持对等距变换的不变性，并能处理任意几何形状。


<details>
  <summary>Details</summary>
Motivation: 原始的切片GW版本仅限于欧氏几何并且会丢失对等距变换的不变性，这在实际应用中大大限制了其应用。为了克服这些问题，需要一种新的切片技术。

Method: 利用1D OT，提出了一种切片GW版本，但仅限于欧氏几何，并且会丢失对等距变换的不变性。为了克服这些问题，研究人员提出了一种新颖的GW和FGW切片技术，该技术基于合适的下界、分层OT和潜在的1D OT问题的求积规则。

Result: 新的切片FGW在保持对等距变换不变性的同时，显著降低了数值计算的复杂性，并允许比较任意几何形状。该研究表明，新的距离实际上定义了结构化空间的伪度量，它界定了FGW的下界，并研究了其在切片Wasserstein和GW之间的插值性质。该切片距离在数值上比原始GW和FGW距离更具鲁棒性和可靠性。

Conclusion: 该研究提出了一种新的GW和FGW切片技术，该技术基于合适的下界、分层OT和潜在的1D OT问题的求积规则。新的切片FGW在保持对等距变换不变性的同时，显著降低了数值计算的复杂性，并允许比较任意几何形状。研究表明，新的距离实际上定义了结构化空间的伪度量，它界定了FGW的下界，并研究了其在切片Wasserstein和GW之间的插值性质。由于避免了潜在的二次规划，该切片距离在数值上比原始GW和FGW距离更具鲁棒性和可靠性，特别是在形状检索和图同构测试方面。

Abstract: The Gromov--Wasserstein (GW) distance and its fused extension (FGW) are
powerful tools for comparing heterogeneous data. Their computation is, however,
challenging since both distances are based on non-convex, quadratic optimal
transport (OT) problems. Leveraging 1D OT, a sliced version of GW has been
proposed to lower the computational burden. Unfortunately, this sliced version
is restricted to Euclidean geometry and loses invariance to isometries,
strongly limiting its application in practice. To overcome these issues, we
propose a novel slicing technique for GW as well as for FGW that is based on an
appropriate lower bound, hierarchical OT, and suitable quadrature rules for the
underlying 1D OT problems. Our novel sliced FGW significantly reduces the
numerical effort while remaining invariant to isometric transformations and
allowing the comparison of arbitrary geometries. We show that our new distance
actually defines a pseudo-metric for structured spaces that bounds FGW from
below and study its interpolation properties between sliced Wasserstein and GW.
Since we avoid the underlying quadratic program, our sliced distance is
numerically more robust and reliable than the original GW and FGW distance;
especially in the context of shape retrieval and graph isomorphism testing.

</details>


### [784] [Beyond Manually Designed Pruning Policies with Second-Level Performance Prediction: A Pruning Framework for LLMs](https://arxiv.org/abs/2508.02381)
*Zuxin Ma,Yunhe Cui,Yongbin Qin*

Main category: cs.LG

TL;DR: PPF是一个创新的LLM剪枝框架，通过秒级性能预测实现动态剪枝，效率和效果均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有非结构化剪枝方法依赖手动设计的剪枝策略，难以适应动态剪枝比例的需求，且剪枝策略的评估耗时，限制了优化效率。

Method: PPF框架通过一个智能体（agent）产生自适应的实时剪枝动作，并利用一个能在几秒钟内评估剪枝策略的轻量级性能预测器，来加速迭代优化过程，以消除手动设计依赖并支持动态剪枝比例。

Result: PPF在Llama2-7B和Llama3-8B上的实验结果显示，在动态剪枝下可将困惑度降低高达33.4%，在静态剪枝下可降低高达84.78%，优于手动设计的策略。其性能预测器能在秒级完成预测，准确率高（预测误差<0.0011），并将平均评估延迟从约1分38秒降低到1.52秒，实现了超过64倍的加速。

Conclusion: PPF框架通过引入基于性能预测的动态剪枝策略，解决了现有非结构化剪枝方法依赖手动设计和评估耗时的问题。实验证明，PPF在动态和静态剪枝场景下均能有效降低LLM的困惑度，并显著提升了剪枝策略评估的速度。

Abstract: Non-uniform structured network pruning methods can effectively reduce Large
Language Model (LLM) size by eliminating redundant channels or layers, offering
lower performance degradation than uniform strategies. However, existing
non-uniform methods rely heavily on manually designed pruning policies (e.g.,
layer importance and scaling factors), and therefore cannot efficiently adapt
to scenarios with dynamic pruning ratio requirements. Additionly, a critical
bottleneck -- the time-consuming evaluation of pruning policies -- further
limits the feasibility of iteratively and dynamically finding optimal pruning
policies. To address these limitations, we propose PPF (Predictive Pruning
Framework), a novel pruning framework for LLMs that eliminates manual design
dependencies via second-level performance prediction. PPF not only supports
real-time pruning decisions under dynamic pruning ratios but is also applicable
to static pruning scenarios. It employs an agent for producing adaptive and
real-time pruning actions, while a lightweight performance predictor that can
evaluate a pruning policy in seconds, significantly speeding up the iterative
optimization process. Experiments on Llama2-7B and Llama3-8B show that PPF can
generate dynamic/static pruning policies and it reduces perplexity by up to
33.4% (dynamic pruning) and 84.78% (static pruning) over existing methods,
outperforming manually designed pruning policies. The performance predictor
achieves second-level performance prediction with high accuracy (prediction
error < 0.0011). It reduces the mean evaluation latency from minute-level (1
minute and 38.02 seconds of test-set evaluation methods) to second-level (1.52
second), achieving over 64 times speedup. Our code will be available at
https://github.com/Ma-zx/PPF .

</details>


### [785] [Graph Embedding in the Graph Fractional Fourier Transform Domain](https://arxiv.org/abs/2508.02383)
*Changjie Sheng,Zhichao Zhang,Wei Yao*

Main category: cs.LG

TL;DR: GEFRFE 是一种新的图嵌入方法，它使用图分数傅里叶变换来提高嵌入空间的表达能力，并在各种基准测试中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的谱嵌入方法嵌入空间的表达能力有限，无法充分捕捉不同变换域中的潜在结构特征。为了解决这个问题，我们使用图分数傅里叶变换将现有的最先进的广义频率滤波嵌入 (GEFFE) 扩展到分数域，从而诞生了广义分数滤波嵌入 (GEFRFE)，它通过图分数域增强了嵌入信息量。

Method: GEFRFE 利用图分数域滤波以及源自分数化图拉普拉斯量的特征向量分量的非线性组合。为了动态确定分数阶数，我们引入了两种并行策略：基于搜索的优化和基于 ResNet18 的自适应学习。

Result: 大量的实验表明，GEFRFE 捕获了更丰富的结构特征，并显著提高了分类性能。值得注意的是，所提出的方法保留了与 GEFFE 方法相当的计算复杂性。

Conclusion: GEFRFE 捕获了更丰富的结构特征，并显著提高了分类性能。

Abstract: Spectral graph embedding plays a critical role in graph representation
learning by generating low-dimensional vector representations from graph
spectral information. However, the embedding space of traditional spectral
embedding methods often exhibit limited expressiveness, failing to exhaustively
capture latent structural features across alternative transform domains. To
address this issue, we use the graph fractional Fourier transform to extend the
existing state-of-the-art generalized frequency filtering embedding (GEFFE)
into fractional domains, giving birth to the generalized fractional filtering
embedding (GEFRFE), which enhances embedding informativeness via the graph
fractional domain. The GEFRFE leverages graph fractional domain filtering and a
nonlinear composition of eigenvector components derived from a fractionalized
graph Laplacian. To dynamically determine the fractional order, two parallel
strategies are introduced: search-based optimization and a ResNet18-based
adaptive learning. Extensive experiments on six benchmark datasets demonstrate
that the GEFRFE captures richer structural features and significantly enhance
classification performance. Notably, the proposed method retains computational
complexity comparable to GEFFE approaches.

</details>


### [786] [$ε$-Softmax: Approximating One-Hot Vectors for Mitigating Label Noise](https://arxiv.org/abs/2508.02387)
*Jialiang Wang,Xiong Zhou,Deming Zhai,Junjun Jiang,Xiangyang Ji,Xianming Liu*

Main category: cs.LG

TL;DR: $\eplacement{\\epsilon}$-softmax 是一种用于缓解深度神经网络中标签噪声的新方法，通过修改 softmax 输出，它能提高对噪声的容忍度并避免欠拟合，同时在干净数据上也能保持良好的学习能力。


<details>
  <summary>Details</summary>
Motivation: 为了缓解标签噪声带来的挑战，尽管现有的鲁棒损失函数（特别是对称损失）被提出来，但它们通常会因为过于严格的对称条件而导致欠拟合。

Method: 提出了一种名为 $\eplacement{\\epsilon}$-softmax 的简单有效的方法，通过以可控误差 $\eplacement{\\epsilon}$ 来近似一个热向量来修改 softmax 层的输出来放宽对称条件。

Result: $\eplacement{\\epsilon}$-softmax 不仅是 softmax 层的替代品，还能在修改损失函数方面发挥关键作用。理论证明了 $\eplacement{\\epsilon}$-softmax 能够实现噪声容忍学习，并且对于几乎任何损失函数都具有可控的超额风险界限。将 $\eplacement{\\epsilon}$-softmax 与对称损失相结合，可以在鲁棒性和有效学习之间取得更好的权衡。

Conclusion: $\eplacement{\\epsilon}$-softmax 方法在减少合成和真实世界标签噪声方面优于其他方法。

Abstract: Noisy labels pose a common challenge for training accurate deep neural
networks. To mitigate label noise, prior studies have proposed various robust
loss functions to achieve noise tolerance in the presence of label noise,
particularly symmetric losses. However, they usually suffer from the
underfitting issue due to the overly strict symmetric condition. In this work,
we propose a simple yet effective approach for relaxing the symmetric
condition, namely $\epsilon$-softmax, which simply modifies the outputs of the
softmax layer to approximate one-hot vectors with a controllable error
$\epsilon$. Essentially, $\epsilon$-softmax not only acts as an alternative for
the softmax layer, but also implicitly plays the crucial role in modifying the
loss function. We prove theoretically that $\epsilon$-softmax can achieve
noise-tolerant learning with controllable excess risk bound for almost any loss
function. Recognizing that $\epsilon$-softmax-enhanced losses may slightly
reduce fitting ability on clean datasets, we further incorporate them with one
symmetric loss, thereby achieving a better trade-off between robustness and
effective learning. Extensive experiments demonstrate the superiority of our
method in mitigating synthetic and real-world label noise. The code is
available at https://github.com/cswjl/eps-softmax.

</details>


### [787] [ASMR: Angular Support for Malfunctioning Client Resilience in Federated Learning](https://arxiv.org/abs/2508.02414)
*Mirko Konstantin,Moritz Fuchs,Anirban Mukhopadhyay*

Main category: cs.LG

TL;DR: ASMR 是一种无需超参数或故障客户端数量知识即可检测和排除故障客户端的新型联邦学习方法，在组织病理学图像分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的联邦学习（FL）概念由于客户端发送的故障更新而导致全局模型性能下降。现有的防御机制通常需要关于故障更新数量的知识等不切实际的前提条件，这使其不适用于现实世界的应用。

Method: ASMR (Angular Support for Malfunctioning Client Resilience) 是一种新颖的方法，通过其角度距离动态地排除故障客户端。

Result: ASMR 在组织病理学数据集的图像分类任务中展示了其检测能力，并展示了动态适应决策边界的重要性。

Conclusion: ASMR (Angular Support for Malfunctioning Client Resilience) 是一种新颖的方法，可以动态地排除故障客户端，并且不需要任何超参数或故障客户端数量的知识。ASMR 在组织病理学数据集的图像分类任务中展示了其检测能力，并强调了动态适应决策边界的重要性。

Abstract: Federated Learning (FL) allows the training of deep neural networks in a
distributed and privacy-preserving manner. However, this concept suffers from
malfunctioning updates sent by the attending clients that cause global model
performance degradation. Reasons for this malfunctioning might be technical
issues, disadvantageous training data, or malicious attacks. Most of the
current defense mechanisms are meant to require impractical prerequisites like
knowledge about the number of malfunctioning updates, which makes them
unsuitable for real-world applications. To counteract these problems, we
introduce a novel method called Angular Support for Malfunctioning Client
Resilience (ASMR), that dynamically excludes malfunctioning clients based on
their angular distance. Our novel method does not require any hyperparameters
or knowledge about the number of malfunctioning clients. Our experiments
showcase the detection capabilities of ASMR in an image classification task on
a histopathological dataset, while also presenting findings on the significance
of dynamically adapting decision boundaries.

</details>


### [788] [Toward Using Machine Learning as a Shape Quality Metric for Liver Point Cloud Generation](https://arxiv.org/abs/2508.02482)
*Khoa Tuan Nguyen,Gaeun Oh,Ho-min Park,Francesca Tozzi,Wouter Willaert,Joris Vankerschaver,Niki Rashidian,Wesley De Neve*

Main category: cs.LG

TL;DR: 使用机器学习和PointNet作为评估3D医疗形状生成模型（如肝脏形状）质量的可行方法，提供比现有基于分布的指标更具可解释性和个体化评估。


<details>
  <summary>Details</summary>
Motivation: 现有的评估指标通常衡量训练集和生成集之间的分布距离，而医学领域需要在个体层面评估每个生成形状的质量，这需要耗费大量人力进行专家审查。

Method: 从生成的肝脏形状表面采样点云，提取手工制作的几何特征，并训练监督学习的机器学习模型和PointNet模型来对肝脏形状进行分类（好或坏），以评估生成形状的质量。

Result: 结果表明，基于机器学习的形状分类器不仅提供可解释的反馈，而且与专家评估相比，还提供了互补的见解，表明它们可以作为3D器官形状生成中轻量级的、与任务相关的质量指标，以支持更透明和临床一致的评估协议。

Conclusion: 机器学习方法和PointNet可以作为评估3D医疗形状生成模型质量的可解释替代方案，并提供与专家评估互补的见解。

Abstract: While 3D medical shape generative models such as diffusion models have shown
promise in synthesizing diverse and anatomically plausible structures, the
absence of ground truth makes quality evaluation challenging. Existing
evaluation metrics commonly measure distributional distances between training
and generated sets, while the medical field requires assessing quality at the
individual level for each generated shape, which demands labor-intensive expert
review.
  In this paper, we investigate the use of classical machine learning (ML)
methods and PointNet as an alternative, interpretable approach for assessing
the quality of generated liver shapes. We sample point clouds from the surfaces
of the generated liver shapes, extract handcrafted geometric features, and
train a group of supervised ML and PointNet models to classify liver shapes as
good or bad. These trained models are then used as proxy discriminators to
assess the quality of synthetic liver shapes produced by generative models.
  Our results show that ML-based shape classifiers provide not only
interpretable feedback but also complementary insights compared to expert
evaluation. This suggests that ML classifiers can serve as lightweight,
task-relevant quality metrics in 3D organ shape generation, supporting more
transparent and clinically aligned evaluation protocols in medical shape
modeling.

</details>


### [789] [Federated Graph Unlearning](https://arxiv.org/abs/2508.02485)
*Yuming Ai,Xunkai Li,Jiaqi Chao,Bowen Fan,Zhengyu Wu,Yinlin Zhu,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 为解决联邦图学习中的“遗忘权”问题，提出了一种统一框架，通过原型梯度和对抗性图生成相结合的双重策略，有效实现了选择性擦除和完全移除，并在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦图学习（FGL）在去中心化模型训练中面临“遗忘权”的挑战，现有方法在选择性擦除特定实体和完全移除用户数据方面存在不足，易导致数据擦除不完整或残留知识。

Method: 提出了一种统一框架，采用双重策略：对于细粒度的元遗忘，使用原型梯度指导本地遗忘过程，并生成对抗性图消除残留数据；对于完全的客户端遗忘，仅使用对抗性图生成来清除已离开客户端的贡献。

Result: 该框架在两种遗忘场景下均实现了对现有方法的实质性改进，显著提高了模型预测准确性。此外，该框架可作为插件模块，增强其他现有方法的预测能力和遗忘效率。

Conclusion: 该框架通过原型梯度和对抗性图生成相结合的双重策略，有效解决了联邦图学习中的选择性实体擦除和用户全部数据移除的“遗忘权”问题，并在模型预测准确性和遗忘效率方面优于现有方法。

Abstract: The demand for data privacy has led to the development of frameworks like
Federated Graph Learning (FGL), which facilitate decentralized model training.
However, a significant operational challenge in such systems is adhering to the
right to be forgotten. This principle necessitates robust mechanisms for two
distinct types of data removal: the selective erasure of specific entities and
their associated knowledge from local subgraphs and the wholesale removal of a
user's entire dataset and influence. Existing methods often struggle to fully
address both unlearning requirements, frequently resulting in incomplete data
removal or the persistence of residual knowledge within the system. This work
introduces a unified framework, conceived to provide a comprehensive solution
to these challenges. The proposed framework employs a bifurcated strategy
tailored to the specific unlearning request. For fine-grained Meta Unlearning,
it uses prototype gradients to direct the initial local forgetting process,
which is then refined by generating adversarial graphs to eliminate any
remaining data traces among affected clients. In the case of complete client
unlearning, the framework utilizes adversarial graph generation exclusively to
purge the departed client's contributions from the remaining network. Extensive
experiments on multiple benchmark datasets validate the proposed approach. The
framework achieves substantial improvements in model prediction accuracy across
both client and meta-unlearning scenarios when compared to existing methods.
Furthermore, additional studies confirm its utility as a plug-in module, where
it materially enhances the predictive capabilities and unlearning effectiveness
of other established methods.

</details>


### [790] [Clinical Expert Uncertainty Guided Generalized Label Smoothing for Medical Noisy Label Learning](https://arxiv.org/abs/2508.02495)
*Kunyu Zhang,Lin Gu,Liangchen Liu,Yingke Chen,Bingyang Wang,Jin Yan,Yingying Zhu*

Main category: cs.LG

TL;DR: 现有从临床笔记提取图像标签的方法存在标签噪声问题，因为忽略了专家注释中的不确定性。本研究提出了一种考虑专家不确定性的方法，并通过实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决从临床笔记中提取图像标签时，由于临床专家的不确定性（如“可能”或“未排除”）导致的标签噪声问题，现有方法忽略了专家驱动的不确定性。

Method: 检查临床专家不确定性对标签噪声的影响，并提出了一种临床专家不确定性感知基准和标签平滑方法。

Result: 所提出的方法在处理由临床专家不确定性引起标签噪声方面，性能优于现有方法。

Conclusion: 提出了一种临床专家不确定性感知基准和标签平滑方法，与当前最先进的方法相比，性能显著提高。

Abstract: Many previous studies have proposed extracting image labels from clinical
notes to create large-scale medical image datasets at a low cost. However,
these approaches inherently suffer from label noise due to uncertainty from the
clinical experts. When radiologists and physicians analyze medical images to
make diagnoses, they often include uncertainty-aware notes such as ``maybe'' or
``not excluded''. Unfortunately, current text-mining methods overlook these
nuances, resulting in the creation of noisy labels. Existing methods for
handling noisy labels in medical image analysis, which typically address the
problem through post-processing techniques, have largely ignored the important
issue of expert-driven uncertainty contributing to label noise. To better
incorporate the expert-written uncertainty in clinical notes into medical image
analysis and address the label noise issue, we first examine the impact of
clinical expert uncertainty on label noise. We then propose a clinical expert
uncertainty-aware benchmark, along with a label smoothing method, which
significantly improves performance compared to current state-of-the-art
approaches.

</details>


### [791] [On Distributional Dependent Performance of Classical and Neural Routing Solvers](https://arxiv.org/abs/2508.02510)
*Daniela Thyssens,Tim Dernedde,Wilson Sentanoe,Lars Schmidt-Thieme*

Main category: cs.LG

TL;DR: 本研究提出了一种新的方法来训练神经组合优化模型，通过从更大的、代表性的实例中采样子样本来学习问题分布，尤其是在路由问题上，这种方法被证明可以缩小与传统元启发式算法的性能差距。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在弥合神经组合优化（NCO）方法在解决组合问题方面的性能与传统的问题特定元启发式方法之间的差距，通过探索一种新颖的实例分布构建和采样方法。

Method: 提出了一种新颖的方法来构建和采样子问题实例的分布，这些实例源自更大的、代表性的实例，用于组合问题的学习。

Result: 与直接从固定分布采样的现有方法相比，当训练数据源自代表自定义基础问题分布的大型问题实例的子样本时，NCO 方法在路由任务上的性能得到了改善，缩小了与元启发式算法的差距。

Conclusion: 当从固定的基节点分布中提取的子样本进行学习时，神经组合优化路由求解器与高度专业化的元启发式算法之间的性能差距会减小。

Abstract: Neural Combinatorial Optimization aims to learn to solve a class of
combinatorial problems through data-driven methods and notably through
employing neural networks by learning the underlying distribution of problem
instances. While, so far neural methods struggle to outperform highly
engineered problem specific meta-heuristics, this work explores a novel
approach to formulate the distribution of problem instances to learn from and,
more importantly, plant a structure in the sampled problem instances. In
application to routing problems, we generate large problem instances that
represent custom base problem instance distributions from which training
instances are sampled. The test instances to evaluate the methods on the
routing task consist of unseen problems sampled from the underlying large
problem instance. We evaluate representative NCO methods and specialized
Operation Research meta heuristics on this novel task and demonstrate that the
performance gap between neural routing solvers and highly specialized
meta-heuristics decreases when learning from sub-samples drawn from a fixed
base node distribution.

</details>


### [792] [AnalogCoder-Pro: Unifying Analog Circuit Generation and Optimization via Multi-modal LLMs](https://arxiv.org/abs/2508.02518)
*Yao Lai,Souradip Poddar,Sungyoung Lee,Guojin Chen,Mengkang Hu,Bei Yu,Ping Luo,David Z. Pan*

Main category: cs.LG

TL;DR: AnalogCoder-Pro 是一个基于大语言模型的框架，可以自动生成电路拓扑和优化器件尺寸，实现端到端的模拟电路设计。


<details>
  <summary>Details</summary>
Motivation: 当前的模拟设计自动化在专家直觉和迭代仿真方面仍然高度依赖，在性能关键应用的自动化优化方面存在差距。虽然大语言模型（LLM）为模拟设计自动化带来了新的希望，但现有工作仍处于早期阶段，缺乏针对实际端到端解决方案的整体联合优化。

Method: 提出了一种名为 AnalogCoder-Pro 的统一多模态大语言模型（LLM）框架。该框架集成了生成能力和优化技术，用于电路拓扑生成和器件尺寸优化。通过对 LLM 进行高质量综合电路数据微调，并引入基于功能规范和波形图像的多模态诊断和修复工作流程，实现了自动化参数提取和参数空间构建，最终形成端到端的电路设计流程。

Result: 通过正交方法（例如，基于LLM的电路网表解析、多模态诊断和修复工作流），AnalogCoder-Pro 显著提高了模拟电路设计的成功率并增强了电路性能。

Conclusion: AnalogCoder-Pro 通过生成能力和优化技术相结合，实现了端到端的自动化电路设计，在电路拓扑生成和器件尺寸优化方面取得了显著成效，提高了设计成功率和电路性能。

Abstract: Despite advances in analog design automation, analog front-end design still
heavily depends on expert intuition and iterative simulations, underscoring
critical gaps in fully automated optimization for performance-critical
applications. Recently, the rapid development of Large Language Models (LLMs)
has brought new promise to analog design automation. However, existing work
remains in its early stages, and holistic joint optimization for practical
end-to-end solutions remains largely unexplored. We propose AnalogCoder-Pro, a
unified multimodal LLM-based framework that integrates generative capabilities
and optimization techniques to jointly explore circuit topologies and optimize
device sizing, automatically generating performance-specific, fully sized
schematic netlists. AnalogCoder-Pro employs rejection sampling for fine-tuning
LLMs on high-quality synthesized circuit data and introduces a multimodal
diagnosis and repair workflow based on functional specifications and waveform
images. By leveraging LLMs to interpret generated circuit netlists,
AnalogCoder-Pro automates the extraction of critical design parameters and the
formulation of parameter spaces, establishing an end-to-end workflow for
simultaneous topology generation and device sizing optimization. Extensive
experiments demonstrate that these orthogonal approaches significantly improve
the success rate of analog circuit design and enhance circuit performance.

</details>


### [793] [Solved in Unit Domain: JacobiNet for Differentiable Coordinate Transformations](https://arxiv.org/abs/2508.02537)
*Xi Chen,Jianchuan Yang,Junjie Zhang,Runnan Yang,Xu Liu,Hong Wang,Ziyu Ren,Wenqi Hu*

Main category: cs.LG

TL;DR: JacobiNet是一种创新的神经网络方法，通过学习坐标变换来解决物理信息神经网络（PINNs）在处理不规则边界时的挑战，无需网格划分，提高了求解PDE的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的PINNs在处理不规则边界时面临不稳定性、收敛速度慢、归一化不一致、边界条件执行不准确以及损失项不平衡等问题。现有的解决方案（如域映射到规则空间）依赖于特定案例的网格和简单的几何形状，限制了其与现代框架的兼容性。

Method: JacobiNet是一种基于神经网络的坐标变换方法，通过学习监督点对的连续、可微分映射来实现。它利用轻量级MLP，通过自动微分直接计算雅可比矩阵，并无缝集成到下游PINNs中。

Result: JacobiNet显著提高了PINNs在不规则边界问题上的性能，将相对L2误差从0.287-0.637降低到0.013-0.039，平均准确率提高了18.3%。在血管状域中，它能够快速映射未见过的几何形状，将预测准确率提高了3.65%，并将速度提高了10倍以上，展示了其泛化能力、准确性和效率。

Conclusion: JacobiNet通过学习连续、可微分的映射，解决了PINNs在处理不规则边界时的挑战，通过连续坐标变换有效解决了归一化问题，实现了边界条件的硬约束，并缓解了损失项不平衡的问题。该方法无需网格划分或显式计算雅可比矩阵，可与下游PINNs无缝集成，实现端到端可微分的PDE求解。

Abstract: Physics-Informed Neural Networks (PINNs) are effective for solving PDEs by
incorporating physical laws into the learning process. However, they face
challenges with irregular boundaries, leading to instability and slow
convergence due to inconsistent normalization, inaccurate boundary enforcement,
and imbalanced loss terms. A common solution is to map the domain to a regular
space, but traditional methods rely on case-specific meshes and simple
geometries, limiting their compatibility with modern frameworks. To overcome
these limitations, we introduce JacobiNet, a neural network-based coordinate
transformation method that learns continuous, differentiable mappings from
supervised point pairs. Utilizing lightweight MLPs, JacobiNet allows for direct
Jacobian computation via autograd and integrates seamlessly with downstream
PINNs, enabling end-to-end differentiable PDE solving without the need for
meshing or explicit Jacobian computation. JacobiNet effectively addresses
normalization challenges, facilitates hard constraints of boundary conditions,
and mitigates the long-standing imbalance among loss terms. It demonstrates
significant improvements, reducing the relative L2 error from 0.287-0.637 to
0.013-0.039, achieving an average accuracy improvement of 18.3*. In vessel-like
domains, it enables rapid mapping for unseen geometries, improving prediction
accuracy by 3.65* and achieving over 10* speedup, showcasing its
generalization, accuracy, and efficiency.

</details>


### [794] [Explainable AI Methods for Neuroimaging: Systematic Failures of Common Tools, the Need for Domain-Specific Validation, and a Proposal for Safe Application](https://arxiv.org/abs/2508.02560)
*Nys Tjade Siegel,James H. Cole,Mohamad Habes,Stefan Haufe,Kerstin Ritter,Marc-André Schulz*

Main category: cs.LG

TL;DR: 在神经影像学中，常用的 XAI 方法（如 GradCAM 和 LRP）存在系统性失败，而 SmoothGrad 更可靠。建议对现有研究进行重新评估，并在实践中进行领域特定适应和验证。


<details>
  <summary>Details</summary>
Motivation: 可解释的人工智能（XAI）方法在深度学习模型在神经影像学应用中的可信度解释至关重要，但目前广泛使用的方法缺乏严格的验证，存在误解的风险。

Method: 本研究首次对约 45,000 个结构脑 MRI 图像进行了大规模、系统的可解释人工智能（XAI）方法比较。研究人员开发了一个新颖的 XAI 验证框架，通过构建具有已知信号源（从局部解剖特征到特定于受试者的临床病变）的预测任务来建立可验证的真实情况，而无需人为改变输入图像。

Result: GradCAM 持续未能定位预测特征，而 Layer-wise Relevance Propagation 生成了广泛的、伪影性质的解释，表明其与神经影像数据特性不兼容。SmoothGrad 方法被证明是一致准确的。

Conclusion: 目前最广泛使用的两种可解释人工智能（XAI）方法（GradCAM 和 Layer-wise Relevance Propagation）在对约 45,000 个结构脑 MRI 图像进行分析时，未能正确本地化预测特征，并生成了伪影，这表明它们与神经影像数据的特性不兼容。然而，更简单的基于梯度的 SmoothGrad 方法在面对领域转移时表现出更强的鲁棒性。这些发现强调了在神经影像学中采用 XAI 方法时进行领域特定适应和严格验证的必要性，并对先前使用标准 XAI 方法的神经影像学研究提出了重新评估的建议。

Abstract: Trustworthy interpretation of deep learning models is critical for
neuroimaging applications, yet commonly used Explainable AI (XAI) methods lack
rigorous validation, risking misinterpretation. We performed the first
large-scale, systematic comparison of XAI methods on ~45,000 structural brain
MRIs using a novel XAI validation framework. This framework establishes
verifiable ground truth by constructing prediction tasks with known signal
sources - from localized anatomical features to subject-specific clinical
lesions - without artificially altering input images. Our analysis reveals
systematic failures in two of the most widely used methods: GradCAM
consistently failed to localize predictive features, while Layer-wise Relevance
Propagation generated extensive, artifactual explanations that suggest
incompatibility with neuroimaging data characteristics. Our results indicate
that these failures stem from a domain mismatch, where methods with design
principles tailored to natural images require substantial adaptation for
neuroimaging data. In contrast, the simpler, gradient-based method SmoothGrad,
which makes fewer assumptions about data structure, proved consistently
accurate, suggesting its conceptual simplicity makes it more robust to this
domain shift. These findings highlight the need for domain-specific adaptation
and validation of XAI methods, suggest that interpretations from prior
neuroimaging studies using standard XAI methodology warrant re-evaluation, and
provide urgent guidance for practical application of XAI in neuroimaging.

</details>


### [795] [Dynamic Feature Selection based on Rule-based Learning for Explainable Classification with Uncertainty Quantification](https://arxiv.org/abs/2508.02566)
*Javier Fumanal-Idocin,Raquel Fernandez-Peralta,Javier Andreu-Perez*

Main category: cs.LG

TL;DR: 本文提出了一种基于规则的动态特征选择（DFS）方法，解决了现有DFS方法不透明的问题，提高了模型的可解释性，并能在临床等场景中应用。该方法在性能上与现有方法相当，并具有计算效率和不确定性度量等优点。


<details>
  <summary>Details</summary>
Motivation: 现有的动态特征选择（DFS）方法虽然能为每个样本定制特征，但在临床决策等需要高透明度的场景中，由于其模型不透明而难以应用。因此，本研究旨在提出一种可解释的DFS方法。

Method: 本文利用规则系统作为DFS的基础分类器，增强了决策的可解释性。同时，该方法提供了每条特征查询的不确定性量化度量，并通过约束特征搜索空间来优化计算效率。此外，还探讨了条件互信息贪婪选择与全局模型预测差异最小化选择的等价性。

Result: 本文提出的基于规则的DFS方法在性能上与现有贪婪算法和强化学习方法相当，同时提供了更好的可解释性，证明了其在实际应用中的竞争力。

Conclusion: 本文提出的基于规则的动态特征选择（DFS）方法，相比于现有的不透明模型，能够提供更好的可解释性，并能在临床决策等需要高透明度的场景中得到应用。该方法还提供了特征查询的不确定性度量，并通过约束特征搜索空间来降低计算成本。

Abstract: Dynamic feature selection (DFS) offers a compelling alternative to
traditional, static feature selection by adapting the selected features to each
individual sample. Unlike classical methods that apply a uniform feature set,
DFS customizes feature selection per sample, providing insight into the
decision-making process for each case. DFS is especially significant in
settings where decision transparency is key, i.e., clinical decisions; however,
existing methods use opaque models, which hinder their applicability in
real-life scenarios. This paper introduces a novel approach leveraging a
rule-based system as a base classifier for the DFS process, which enhances
decision interpretability compared to neural estimators. We also show how this
method provides a quantitative measure of uncertainty for each feature query
and can make the feature selection process computationally lighter by
constraining the feature search space. We also discuss when greedy selection of
conditional mutual information is equivalent to selecting features that
minimize the difference with respect to the global model predictions. Finally,
we demonstrate the competitive performance of our rule-based DFS approach
against established and state-of-the-art greedy and RL methods, which are
mostly considered opaque, compared to our explainable rule-based system.

</details>


### [796] [Adaptive Riemannian Graph Neural Networks](https://arxiv.org/abs/2508.02600)
*Xudong Wang,Tongxin Li,Chris Ding,Jicong Fan*

Main category: cs.LG

TL;DR: ARGNN 是一种新的 GNN 框架，通过学习自适应的里曼度量张量场来解决图的几何异质性问题，在各种数据集上均表现出色并提供可解释的几何洞察。


<details>
  <summary>Details</summary>
Motivation: 现有几何 GNN 难以捕获图数据中存在的复杂几何异质性，例如在单一网络中共存的具有不同局部曲率的树状层级和密集社区。ARGNN 旨在解决这一挑战。

Method: ARGNN 通过学习图上的连续、各向异性里曼度量张量场来实现对复杂几何异质性的捕获。该框架通过节点-wise 度量张量参数化，专门化为可学习的对角形式，以捕获方向几何信息并保持计算可行性。为了保证几何规则性和训练稳定性，引入了受 Ricci 流启发的正则化来平滑学习到的流形。

Result: ARGNN 能够自适应地捕获多种图结构，并在同质和异质数据集上取得了优越的性能。学习到的几何结构不仅具有可解释性，而且在经验上支持了理论分析。

Conclusion: ARGNN 在同质和异质基准数据集上表现出优越的性能，能够自适应地捕获各种结构。此外，学习到的几何结构提供了对底层图结构的解释性见解，并以经验上证实了我们的理论分析。

Abstract: Graph data often exhibits complex geometric heterogeneity, where structures
with varying local curvature, such as tree-like hierarchies and dense
communities, coexist within a single network. Existing geometric GNNs, which
embed graphs into single fixed-curvature manifolds or discrete product spaces,
struggle to capture this diversity. We introduce Adaptive Riemannian Graph
Neural Networks (ARGNN), a novel framework that learns a continuous and
anisotropic Riemannian metric tensor field over the graph. It allows each node
to determine its optimal local geometry, enabling the model to fluidly adapt to
the graph's structural landscape. Our core innovation is an efficient
parameterization of the node-wise metric tensor, specializing to a learnable
diagonal form that captures directional geometric information while maintaining
computational tractability. To ensure geometric regularity and stable training,
we integrate a Ricci flow-inspired regularization that smooths the learned
manifold. Theoretically, we establish the rigorous geometric evolution
convergence guarantee for ARGNN and provide a continuous generalization that
unifies prior fixed or mixed-curvature GNNs. Empirically, our method
demonstrates superior performance on both homophilic and heterophilic benchmark
datasets with the ability to capture diverse structures adaptively. Moreover,
the learned geometries both offer interpretable insights into the underlying
graph structure and empirically corroborate our theoretical analysis.

</details>


### [797] [StructSynth: Leveraging LLMs for Structure-Aware Tabular Data Synthesis in Low-Data Regimes](https://arxiv.org/abs/2508.02601)
*Siyi Liu,Yujia Zheng,Yongqi Zhang*

Main category: cs.LG

TL;DR: StructSynth is a novel framework that integrates LLMs with structural control for generating high-fidelity synthetic tabular data, especially in low-data scenarios. It uses a two-stage approach: structure discovery via DAG learning and structure-guided LLM generation, outperforming existing methods in structural integrity and utility while balancing privacy and fidelity.


<details>
  <summary>Details</summary>
Motivation: Machine learning on tabular data is limited by data scarcity. Traditional generative models falter in low-data regimes, and LLMs often ignore the explicit dependency structure of tabular data, leading to low-fidelity synthetics.

Method: StructSynth employs a two-stage architecture: first, explicit structure discovery to learn a Directed Acyclic Graph (DAG) from the available data; second, this learned structure steers the LLM's generation process to adhere to learned feature dependencies, ensuring generated data respects the underlying structure by design.

Result: StructSynth produces synthetic data with significantly higher structural integrity and downstream utility than state-of-the-art methods.

Conclusion: StructSynth produces synthetic data with significantly higher structural integrity and downstream utility than state-of-the-art methods, proving especially effective in challenging low-data scenarios, successfully navigating the trade-off between privacy preservation and statistical fidelity.

Abstract: The application of machine learning on tabular data in specialized domains is
severely limited by data scarcity. While generative models offer a solution,
traditional methods falter in low-data regimes, and recent Large Language
Models (LLMs) often ignore the explicit dependency structure of tabular data,
leading to low-fidelity synthetics. To address these limitations, we introduce
StructSynth, a novel framework that integrates the generative power of LLMs
with robust structural control. StructSynth employs a two-stage architecture.
First, it performs explicit structure discovery to learn a Directed Acyclic
Graph (DAG) from the available data. Second, this learned structure serves as a
high-fidelity blueprint to steer the LLM's generation process, forcing it to
adhere to the learned feature dependencies and thereby ensuring the generated
data respects the underlying structure by design. Our extensive experiments
demonstrate that StructSynth produces synthetic data with significantly higher
structural integrity and downstream utility than state-of-the-art methods. It
proves especially effective in challenging low-data scenarios, successfully
navigating the trade-off between privacy preservation and statistical fidelity.

</details>


### [798] [Entity Representation Learning Through Onsite-Offsite Graph for Pinterset Ads](https://arxiv.org/abs/2508.02609)
*Jiayin Jin,Zhimeng Pan,Yang Tang,Jiarui Feng,Kungang Li,Chongyuan Xiang,Jiacheng Li,Runze Su,Siping Ji,Han Sun,Ling Leng,Prathibha Deshikachar*

Main category: cs.LG

TL;DR: 研究者构建了一个包含用户站内外活动的异构图，并使用TransRA模型进行嵌入。通过引入大型ID嵌入表和注意力机制KGE微调，成功地将图嵌入整合到广告排序模型中，从而提升了CTR和CVR预测效果，并在Pinterest的实际应用中取得了显著的业务增长。


<details>
  <summary>Details</summary>
Motivation: 为了更好地利用站外转化数据，捕捉用户的购物兴趣，并探索站内活动与站外转化之间的联系。

Method: 1. 构建了一个结合用户站内广告互动和站外转化活动的大规模异构图。
2. 引入了TransRA（TransR with Anchors）模型来整合图嵌入到广告排序模型。
3. 采用了大型ID嵌入表技术和创新的注意力机制KGE微调方法来解决直接纳入KGE的挑战。

Result: 所提出的框架在CTR和CVR预测模型中实现了显著的AUC提升，并在Pinterest的广告参与模型中部署后，带来了2.69%的CTR提升和1.34%的CPC降低。

Conclusion: 该研究提出的框架和技术（包括基于用户站内广告互动和站外转化活动构建的异构图、用于整合图嵌入的TransRA模型、用于解决KGE纳入挑战的大ID嵌入表技术和注意力机制KGE微调方法）已成功应用于Pinterest的广告参与模型，并带来了显著的业务增长（CTR提升2.69%，CPC降低1.34%），具有广泛的工业界应用潜力。

Abstract: Graph Neural Networks (GNN) have been extensively applied to industry
recommendation systems, as seen in models like GraphSage\cite{GraphSage},
TwHIM\cite{TwHIM}, LiGNN\cite{LiGNN} etc. In these works, graphs were
constructed based on users' activities on the platforms, and various graph
models were developed to effectively learn node embeddings. In addition to
users' onsite activities, their offsite conversions are crucial for Ads models
to capture their shopping interest. To better leverage offsite conversion data
and explore the connection between onsite and offsite activities, we
constructed a large-scale heterogeneous graph based on users' onsite ad
interactions and opt-in offsite conversion activities. Furthermore, we
introduced TransRA (TransR\cite{TransR} with Anchors), a novel Knowledge Graph
Embedding (KGE) model, to more efficiently integrate graph embeddings into Ads
ranking models. However, our Ads ranking models initially struggled to directly
incorporate Knowledge Graph Embeddings (KGE), and only modest gains were
observed during offline experiments. To address this challenge, we employed the
Large ID Embedding Table technique and innovated an attention based KGE
finetuning approach within the Ads ranking models. As a result, we observed a
significant AUC lift in Click-Through Rate (CTR) and Conversion Rate (CVR)
prediction models. Moreover, this framework has been deployed in Pinterest's
Ads Engagement Model and contributed to $2.69\%$ CTR lift and $1.34\%$ CPC
reduction. We believe the techniques presented in this paper can be leveraged
by other large-scale industrial models.

</details>


### [799] [DeepKoopFormer: A Koopman Enhanced Transformer Based Architecture for Time Series Forecasting](https://arxiv.org/abs/2508.02616)
*Ali Forootani,Mohammad Khosravi,Masoud Barati*

Main category: cs.LG

TL;DR: DeepKoopFormer结合了Transformer和Koopman算子理论，在时间序列预测中提高了准确性、稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决基于Transformer的模型在可解释性和在存在噪声或动态不确定性时不稳定的问题。

Method: 提出了一种名为DeepKoopFormer的原则性预测框架，该框架将Transformer的表征能力与Koopman算子理论的理论严谨性相结合。该模型采用模块化的编码器-传播器-解码器结构，通过潜在空间中经过光谱约束的线性Koopman算子来学习时间动态。通过施加有界谱半径、Lyapunov基础能量正则化和正交参数化等结构保证来确保稳定性和可解释性。

Result: 在合成动力学系统、真实世界气候数据集（风速和表面气压）、金融时间序列（加密货币）和电力生成数据集上进行了全面的评估。DeepKoopFormer在准确性、对噪声的鲁棒性以及长期预测稳定性方面始终优于标准的LSTM和基线Transformer模型。

Conclusion: DeepKoopFormer是一个灵活、可解释且强大的框架，适用于高维和动态环境下的预测。

Abstract: Time series forecasting plays a vital role across scientific, industrial, and
environmental domains, especially when dealing with high-dimensional and
nonlinear systems. While Transformer-based models have recently achieved
state-of-the-art performance in long-range forecasting, they often suffer from
interpretability issues and instability in the presence of noise or dynamical
uncertainty. In this work, we propose DeepKoopFormer, a principled forecasting
framework that combines the representational power of Transformers with the
theoretical rigor of Koopman operator theory. Our model features a modular
encoder-propagator-decoder structure, where temporal dynamics are learned via a
spectrally constrained, linear Koopman operator in a latent space. We impose
structural guarantees-such as bounded spectral radius, Lyapunov based energy
regularization, and orthogonal parameterization to ensure stability and
interpretability. Comprehensive evaluations are conducted on both synthetic
dynamical systems, real-world climate dataset (wind speed and surface
pressure), financial time series (cryptocurrency), and electricity generation
dataset using the Python package that is prepared for this purpose. Across all
experiments, DeepKoopFormer consistently outperforms standard LSTM and baseline
Transformer models in terms of accuracy, robustness to noise, and long-term
forecasting stability. These results establish DeepKoopFormer as a flexible,
interpretable, and robust framework for forecasting in high dimensional and
dynamical settings.

</details>


### [800] [AutoML-Med: A Framework for Automated Machine Learning in Medical Tabular Data](https://arxiv.org/abs/2508.02625)
*Riccardo Francia,Maurizio Leone,Giorgio Leonardi,Stefania Montani,Marzio Pennisi,Manuel Striani,Sandra D'Alfonso*

Main category: cs.LG

TL;DR: AutoML-Med是一个自动化机器学习工具，专门用于解决医疗数据集的挑战，如缺失值、类别不平衡和高维稀疏数据。它通过使用LHS和PRCC来优化预处理和模型选择，在提高分类和回归任务的准确性和敏感性方面优于现有工具，特别是在识别高风险患者方面。


<details>
  <summary>Details</summary>
Motivation: 为了解决医疗数据集普遍存在的缺失值、类别不平衡、异类特征类型以及样本量相对于特征数量较少等问题，这些问题阻碍了机器学习模型在分类和回归任务中获得proper结果。

Method: AutoML-Med 使用拉丁超立方体采样（LHS）来探索预处理方法，使用选定的指标来训练模型，并利用部分秩相关系数（PRCC）对最有影响力的预处理步骤进行微调优化。

Result: 实验结果表明，AutoML-Med在两个不同的临床环境中都取得了更高的平衡准确率和敏感度，这对于识别高风险患者至关重要，与其他最先进的工具相比，AutoML-Med的性能更优。

Conclusion: AutoML-Med在处理医疗数据集的挑战方面表现出有效性，尤其是在数据稀疏和类别不平衡的情况下，其在两个不同的临床环境中的表现优于最先进的工具，提高了平衡准确率和敏感度，有望简化医疗保健领域的机器学习应用。

Abstract: Medical datasets are typically affected by issues such as missing values,
class imbalance, a heterogeneous feature types, and a high number of features
versus a relatively small number of samples, preventing machine learning models
from obtaining proper results in classification and regression tasks. This
paper introduces AutoML-Med, an Automated Machine Learning tool specifically
designed to address these challenges, minimizing user intervention and
identifying the optimal combination of preprocessing techniques and predictive
models. AutoML-Med's architecture incorporates Latin Hypercube Sampling (LHS)
for exploring preprocessing methods, trains models using selected metrics, and
utilizes Partial Rank Correlation Coefficient (PRCC) for fine-tuned
optimization of the most influential preprocessing steps. Experimental results
demonstrate AutoML-Med's effectiveness in two different clinical settings,
achieving higher balanced accuracy and sensitivity, which are crucial for
identifying at-risk patients, compared to other state-of-the-art tools.
AutoML-Med's ability to improve prediction results, especially in medical
datasets with sparse data and class imbalance, highlights its potential to
streamline Machine Learning applications in healthcare.

</details>


### [801] [CAK: Emergent Audio Effects from Minimal Deep Learning](https://arxiv.org/abs/2508.02643)
*Austin Rockman*

Main category: cs.LG

TL;DR: 单个卷积核通过条件感知核（CAK）和AuGAN（审计GAN）技术，仅用200个样本就能产生新颖的音频效果，其学到的核能产生频率相关的时域偏移，为音频效果设计提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 探索对抗性训练从少量数据中发现音频转换的潜力，为效果设计开辟新途径。

Method: 通过条件感知核（CAK）和AuGAN（审计GAN）实现。CAK通过“输出=输入+（学习模式x控制）”实现，并采用软门控机制在控制为零时保持身份；AuGAN将对抗性训练从“这是真实的吗？”转变为“你是否应用了请求的值？”，使网络能够验证控制应用并发现独特的转换。

Result: 学习到的核展现出对角线结构，产生频率相关的时域偏移，能够根据输入特性产生音乐效果。

Conclusion: 该研究展示了单个3x3卷积核在个性化语料库的200个样本上训练时，可以产生新兴的音频效果。

Abstract: We demonstrate that a single 3x3 convolutional kernel can produce emergent
audio effects when trained on 200 samples from a personalized corpus. We
achieve this through two key techniques: (1) Conditioning Aware Kernels (CAK),
where output = input + (learned_pattern x control), with a soft-gate mechanism
supporting identity preservation at zero control; and (2) AuGAN (Audit GAN),
which reframes adversarial training from "is this real?" to "did you apply the
requested value?" Rather than learning to generate or detect forgeries, our
networks cooperate to verify control application, discovering unique
transformations. The learned kernel exhibits a diagonal structure creating
frequency-dependent temporal shifts that are capable of producing musical
effects based on input characteristics. Our results show the potential of
adversarial training to discover audio transformations from minimal data,
enabling new approaches to effect design.

</details>


### [802] [LOST: Low-rank and Sparse Pre-training for Large Language Models](https://arxiv.org/abs/2508.02668)
*Jiaxi Li,Lu Yin,Li Shen,Jinjin Xu,Liwu Xu,Tianjin Huang,Wenwu Wang,Shiwei Liu,Xilu Wang*

Main category: cs.LG

TL;DR: LOST是一种新颖的LLM预训练方法，通过巧妙地结合低秩和稀疏结构，在严格的效率限制下实现了有效的从头开始训练，解决了现有方法的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在从头开始预训练时存在的计算和内存成本高昂的问题，并改进现有的低秩和稀疏方法在处理低秩压缩过程中丢失信息方面的不足。

Method: LOST（低秩和稀疏预训练）通过对权重矩阵应用奇异值分解来保留主导的低秩分量，并将剩余的奇异值分配给通道级稀疏分量，以补充低秩训练的表达能力。

Result: 在从60M到7B参数的LLM预训练实验中，LOST实现了具有竞争力或优于全秩模型的性能，同时显著降低了内存和计算开销。

Conclusion: LOST在LLM预训练中实现了具有竞争力的或更优的性能，同时显著降低了内存和计算开销。

Abstract: While large language models (LLMs) have achieved remarkable performance
across a wide range of tasks, their massive scale incurs prohibitive
computational and memory costs for pre-training from scratch. Recent studies
have investigated the use of low-rank parameterization as a means of reducing
model size and training cost. In this context, sparsity is often employed as a
complementary technique to recover important information lost in low-rank
compression by capturing salient features in the residual space. However,
existing approaches typically combine low-rank and sparse components in a
simplistic or ad hoc manner, often resulting in undesirable performance
degradation compared to full-rank training. In this paper, we propose
\textbf{LO}w-rank and \textbf{S}parse pre-\textbf{T}raining (\textbf{LOST}) for
LLMs, a novel method that ingeniously integrates low-rank and sparse structures
to enable effective training of LLMs from scratch under strict efficiency
constraints. LOST applies singular value decomposition to weight matrices,
preserving the dominant low-rank components, while allocating the remaining
singular values to construct channel-wise sparse components to complement the
expressiveness of low-rank training. We evaluate LOST on LLM pretraining
ranging from 60M to 7B parameters. Our experiments show that LOST achieves
competitive or superior performance compared to full-rank models, while
significantly reducing both memory and compute overhead. Moreover, Code is
available at
\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST
Repo}

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [803] [A Dynamic Allocation Scheme for Adaptive Shared-Memory Mapping on Kilo-core RV Clusters for Attention-Based Model Deployment](https://arxiv.org/abs/2508.01180)
*Bowen Wang,Marco Bertuletti,Yichao Zhang,Victor J. B. Jung,Luca Benini*

Main category: cs.AR

TL;DR: DAS 是一种内存访问优化技术，可提高大型并行机器学习工作负载的性能。


<details>
  <summary>Details</summary>
Motivation: Attention-based 模型需要灵活的硬件来处理具有不同算术强度和内存访问模式的各种内核。具有共享 L1 内存的大型集群（一种常见的架构模式）在扩展时，由于分层 PE 到 L1 集群内互连的吞吐量降低，难以充分利用其处理元素 (PE)。

Method: DAS 是一种运行时可编程地址重映射硬件单元，并辅以统一内存分配器，以最小化 PE 对多银行 L1 的数据访问冲突。

Result: 在具有 NUMA PE 到 L1 互连的 1024 PE RISC-V 集群上评估了 DAS，并在 Vision Transformer (ViT)-L/16 模型上实现了 1.94 倍的加速，PE 利用率为 0.81，每个编码器层执行时间为 5.67 毫秒。DAS 在 12nm FinFET 技术中的面积开销小于 0.1%。

Conclusion: DAS 减少了数据访问冲突，提高了并行机器学习工作负载的数据局部性。

Abstract: Attention-based models demand flexible hardware to manage diverse kernels
with varying arithmetic intensities and memory access patterns. Large clusters
with shared L1 memory, a common architectural pattern, struggle to fully
utilize their processing elements (PEs) when scaled up due to reduced
throughput in the hierarchical PE-to-L1 intra-cluster interconnect. This paper
presents Dynamic Allocation Scheme (DAS), a runtime programmable address
remapping hardware unit coupled with a unified memory allocator, designed to
minimize data access contention of PEs onto the multi-banked L1. We evaluated
DAS on an aggressively scaled-up 1024-PE RISC-V cluster with Non-Uniform Memory
Access (NUMA) PE-to-L1 interconnect to demonstrate its potential for improving
data locality in large parallel machine learning workloads. For a Vision
Transformer (ViT)-L/16 model, each encoder layer executes in 5.67 ms, achieving
a 1.94x speedup over the fixed word-level interleaved baseline with 0.81 PE
utilization. Implemented in 12nm FinFET technology, DAS incurs <0.1 % area
overhead.

</details>


### [804] [Silent Data Corruption by 10x Test Escapes Threatens Reliable Computing](https://arxiv.org/abs/2508.01786)
*Subhasish Mitra,Subho Banerjee,Martin Dixon,Rama Govindaraju,Peter Hochschild,Eric X. Liu,Bharath Parthasarathy,Parthasarathy Ranganathan*

Main category: cs.AR

TL;DR: 现有测试未能发现大量有缺陷的芯片，对可靠计算构成威胁。我们提出一种三管齐下的方法来解决此问题：1. 快速诊断；2. 现场检测；3. 新的测试实验。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有制造测试未能发现大量有缺陷的计算芯片（测试逃逸）的问题，并消除其对可靠计算造成的威胁。

Method: 提出了一种三管齐下的方法来应对测试逃逸问题，包括：1. 快速诊断系统级行为不正确的有缺陷芯片；2. 在现场检测有缺陷的芯片；3. 进行新的测试实验以了解新技术检测有缺陷芯片的有效性。

Result: 存在大量有缺陷的计算芯片逃避了现有的制造测试，对可靠计算构成了重大威胁。未来的方向是结合快速诊断、现场检测和新的测试实验来解决这个问题。

Conclusion: 现有制造测试未能发现大量有缺陷的计算芯片，这会对可靠计算构成重大威胁。为解决此问题，需要快速从系统级行为诊断缺陷芯片、在现场检测缺陷芯片以及进行新的测试实验来理解新技术检测缺陷芯片的有效性。

Abstract: Too many defective compute chips are escaping existing manufacturing tests --
at least an order of magnitude more than industrial targets across all compute
chip types in data centers. Silent data corruptions (SDCs) caused by test
escapes, when left unaddressed, pose a major threat to reliable computing. We
present a three-pronged approach to future directions in overcoming test
escapes: (a) Quick diagnosis of defective chips directly from system-level
incorrect behaviors. Such diagnosis is critical for gaining insights into why
so many defective chips escape existing manufacturing testing. (b) In-field
detection of defective chips. (c) New test experiments to understand the
effectiveness of new techniques for detecting defective chips. These
experiments must overcome the drawbacks and pitfalls of previous industrial
test experiments and case studies.

</details>


### [805] [ASDR: Exploiting Adaptive Sampling and Data Reuse for CIM-based Instant Neural Rendering](https://arxiv.org/abs/2508.02304)
*Fangxin Liu,Haomin Li,Bowen Zhu,Zongwu Wang,Zhuoran Song,Habing Guan,Li Jiang*

Main category: cs.AR

TL;DR: ASDR是一种基于CIM的神经渲染加速器，通过动态采样和MLP优化算法以及高效的CIM架构设计，显著提高了渲染速度并降低了功耗，同时保持了高质量的渲染效果。


<details>
  <summary>Details</summary>
Motivation: 现有的神经渲染模型（如NeRF）在实际应用中存在对即时性和能效的需求，而其不规则的访问模式和计算开销导致了推理延迟和高功耗。ASDR旨在解决这些问题，满足实际场景对模型性能的要求。

Method: ASDR提出了一种算法-架构协同设计方法，包括动态采样和解耦 MLP 以优化渲染算法，并设计了一种基于ReRAM的CIM架构，包含高效的数据映射和复用微架构。

Result: 实验结果表明，ASDR在图形渲染任务上相比最先进的NeRF加速器和Xavier NX GPU，分别实现了高达9.55倍和69.75倍的加速，且PSNR损失仅为0.1。

Conclusion: ASDR通过算法-架构协同设计，在CIM基础上实现了高效的神经渲染，相比现有NeRF加速器和Xavier NX GPU在图形渲染任务上分别实现了高达9.55倍和69.75倍的加速，同时仅带来0.1dB的PSNR损失。

Abstract: Neural Radiance Fields (NeRF) offer significant promise for generating
photorealistic images and videos. However, existing mainstream neural rendering
models often fall short in meeting the demands for immediacy and power
efficiency in practical applications. Specifically, these models frequently
exhibit irregular access patterns and substantial computational overhead,
leading to undesirable inference latency and high power consumption.
Computing-in-memory (CIM), an emerging computational paradigm, has the
potential to address these access bottlenecks and reduce the power consumption
associated with model execution.
  To bridge the gap between model performance and real-world scene
requirements, we propose an algorithm-architecture co-design approach,
abbreviated as ASDR, a CIM-based accelerator supporting efficient neural
rendering. At the algorithmic level, we propose two rendering optimization
schemes: (1) Dynamic sampling by online sensing of the rendering difficulty of
different pixels, thus reducing access memory and computational overhead. (2)
Reducing MLP overhead by decoupling and approximating the volume rendering of
color and density. At the architecture level, we design an efficient
ReRAM-based CIM architecture with efficient data mapping and reuse
microarchitecture. Experiments demonstrate that our design can achieve up to
$9.55\times$ and $69.75\times$ speedup over state-of-the-art NeRF accelerators
and Xavier NX GPU in graphics rendering tasks with only $0.1$ PSNR loss.

</details>


### [806] [MARVEL: An End-to-End Framework for Generating Model-Class Aware Custom RISC-V Extensions for Lightweight AI](https://arxiv.org/abs/2508.01800)
*Ajay Kumar M,Cian O'Mahoney,Pedro Kreutz Werle,Shreejith Shanker,Dimitrios S. Nikolopoulos,Bo Ji,Hans Vandierendonck,Deepu John*

Main category: cs.AR

TL;DR: MARVEL框架通过生成定制RISC-V指令集扩展，为资源受限的物联网设备上的CNN模型部署提供了一种端到端的自动化解决方案，实现了显著的性能和能效提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在资源受限的物联网设备（特别是裸机环境）上部署DNN的挑战，现有工具（如FINN）未能满足这些极端限制。

Method: 通过Python描述DNN模型，利用Apache TVM进行优化和C代码生成，结合Synopsys ASIP Designer识别计算密集型内核并生成定制RISC-V内核，最后通过Xilinx Vivado进行FPGA实现。

Result: 在AMD Zynq UltraScale+ ZCU104 FPGA平台上，针对LeNet-5、MobileNetV1、ResNet50、VGG16、MobileNetV2和DenseNet121等模型，实现了2倍的推理加速和高达2倍的能耗降低，面积开销为28.23%。

Conclusion: 该框架能够为CNN模型生成定制的RISC-V指令集扩展，并能在裸机环境中高效部署，实现了2倍的推理加速和高达2倍的能耗降低，同时面积开销为28.23%。

Abstract: Deploying deep neural networks (DNNs) on resource-constrained IoT devices
remains a challenging problem, often requiring hardware modifications tailored
to individual AI models. Existing accelerator-generation tools, such as AMD's
FINN, do not adequately address extreme resource limitations faced by IoT
endpoints operating in bare-metal environments without an operating system
(OS). To overcome these constraints, we propose MARVEL-an automated, end-to-end
framework that generates custom RISC-V ISA extensions tailored to specific DNN
model classes, with a primary focus on convolutional neural networks (CNNs).
The proposed method profiles high-level DNN representations in Python and
generates an ISA-extended RISC-V core with associated compiler tools for
efficient deployment. The flow leverages (1) Apache TVM for translating
high-level Python-based DNN models into optimized C code, (2) Synopsys ASIP
Designer for identifying compute-intensive kernels, modeling, and generating a
custom RISC-V and (3) Xilinx Vivado for FPGA implementation. Beyond a model
class specific RISC-V, our approach produces an optimized bare-metal C
implementation, eliminating the need for an OS or extensive software
dependencies. Unlike conventional deployment pipelines relying on
TensorFlow/PyTorch runtimes, our solution enables seamless execution in highly
resource-constrained environments. We evaluated the flow on popular DNN models
such as LeNet-5*, MobileNetV1, ResNet50, VGG16, MobileNetV2 and DenseNet121
using the Synopsys trv32p3 RISC-V core as a baseline. Results show a 2x speedup
in inference and upto 2x reduction in energy per inference at a 28.23% area
overhead when implemented on an AMD Zynq UltraScale+ ZCU104 FPGA platform.

</details>


### [807] [Revelator: Rapid Data Fetching via OS-Driven Hash-based Speculative Address Translation](https://arxiv.org/abs/2508.02007)
*Konstantinos Kanellopoulos,Konstantinos Sgouras,Andreas Kosmas Kakolyris,Vlad-Petru Nitu,Berkin Kerim Konar,Rahul Bera,Onur Mutlu*

Main category: cs.AR

TL;DR: Revelator is a hardware-OS cooperative scheme that improves speculative address translation accuracy and reduces latency with minimal modifications. It achieves significant speedups and energy savings with low overhead.


<details>
  <summary>Details</summary>
Motivation: Address translation is a major performance bottleneck. Speculative address translation can hide this latency by predicting the physical address (PA) of requested data early in the pipeline. Prior works face issues with reliance on large pages or VA-to-PA contiguity, and costly hardware changes.

Method: Revelator employs a tiered hash-based allocation strategy in the OS to create predictable VA-to-PA mappings, falling back to conventional allocation when needed. On a TLB miss, a lightweight speculation engine, guided by this policy, generates candidate PAs for both program data and last-level page table entries (PTEs).

Result: Revelator achieves average speedups of 27% in native and 20% in virtualized settings, surpasses a state-of-the-art speculative mechanism by 5%, and reduces energy use by 9% compared to baseline. It also has minimal area and power overheads.

Conclusion: Revelator achieves average speedups of 27% (20%) in native (virtualized) settings, surpasses a state-of-the-art speculative mechanism by 5%, and reduces energy use by 9% compared to baseline. Minimal area and power overheads on a modern CPU.

Abstract: Address translation is a major performance bottleneck in modern computing
systems. Speculative address translation can hide this latency by predicting
the physical address (PA) of requested data early in the pipeline. However,
predicting the PA from the virtual address (VA) is difficult due to the
unpredictability of VA-to-PA mappings in conventional OSes. Prior works try to
overcome this but face two key issues: (i) reliance on large pages or VA-to-PA
contiguity, which is not guaranteed, and (ii) costly hardware changes to store
speculation metadata with limited effectiveness.
  We introduce Revelator, a hardware-OS cooperative scheme enabling highly
accurate speculative address translation with minimal modifications. Revelator
employs a tiered hash-based allocation strategy in the OS to create predictable
VA-to-PA mappings, falling back to conventional allocation when needed. On a
TLB miss, a lightweight speculation engine, guided by this policy, generates
candidate PAs for both program data and last-level page table entries (PTEs).
Thus, Revelator (i) speculatively fetches requested data before translation
resolves, reducing access latency, and (ii) fetches the fourth-level PTE before
the third-level PTE is accessed, accelerating page table walks.
  We prototype Revelator's OS support in Linux and evaluate it in simulation
across 11 diverse, data-intensive benchmarks in native and virtualized
environments. Revelator achieves average speedups of 27% (20%) in native
(virtualized) settings, surpasses a state-of-the-art speculative mechanism by
5%, and reduces energy use by 9% compared to baseline. Our RTL prototype shows
minimal area and power overheads on a modern CPU.

</details>


### [808] [GSIM: Accelerating RTL Simulation for Large-Scale Designs](https://arxiv.org/abs/2508.02236)
*Lu Chen,Dingyi Zhao,Zihao Yu,Ninghui Sun,Yungang Bao*

Main category: cs.AR

TL;DR: GSIM 模拟器通过优化 RTL 仿真计算开销，显著提升了 XiangShan 和 Rocket 的仿真速度。


<details>
  <summary>Details</summary>
Motivation: RTL 仿真作为硬件设计中的关键环节，其仿真速度的瓶颈限制了设计流程。

Method: 通过在超节点、节点和比特级别提出多种技术来优化 RTL 仿真的计算开销。

Result: 提出的技术在 GSIM 模拟器中得到实现，并对 XiangShan 和 Rocket 进行了加速。

Conclusion: GSIM 成功模拟了 XiangShan，并且相比 Verilator，在不同场景下分别实现了 7.34 倍和 19.94 倍的加速。

Abstract: Register Transfer Level (RTL) simulation is widely used in design space
exploration, verification, debugging, and preliminary performance evaluation
for hardware design. Among various RTL simulation approaches, software
simulation is the most commonly used due to its flexibility, low cost, and ease
of debugging. However, the slow simulation of complex designs has become the
bottleneck in design flow. In this work, we explore the sources of computation
overhead of RTL simulation and conclude them into four factors. To optimize
these factors, we propose several techniques at the supernode level, node
level, and bit level. Finally, we implement these techniques in a novel RTL
simulator GSIM. GSIM succeeds in simulating XiangShan, the state-of-the-art
open-source RISC-V processor. Besides, compared to Verilator, GSIM can achieve
speedup of 7.34x for booting Linux on XiangShan, and 19.94x for running
CoreMark on Rocket.

</details>


### [809] [ReGate: Enabling Power Gating in Neural Processing Units](https://arxiv.org/abs/2508.02536)
*Yuqi Xue,Jian Huang*

Main category: cs.AR

TL;DR: ReGate通过软硬件协同设计，实现了NPU芯片上每个硬件组件的细粒度门控，可降低高达32.8%的能耗，且对性能影响可忽略。


<details>
  <summary>Details</summary>
Motivation: 研究发现，现代NPU芯片由于缺乏电源管理支持，30%-72%的能耗来自静态功耗。因此，本研究提出ReGate以解决NPU芯片的能耗问题，并提出了细粒度的门控方法。

Method: ReGate通过软硬件协同设计，实现了NPU芯片上每个硬件组件的细粒度门控。针对具有确定性执行模式的Systolic Arrays（SAs），ReGate实现了在处理单元（PEs）粒度的周期级门控，并遵循SAs中固有的数据流执行。针对具有长空闲间隔的芯片间互连（ICI）和HBM控制器，ReGate采用轻量级的基于硬件的空闲检测机制。对于矢量单元和SRAM，ReGate扩展了NPU指令集架构（ISA），允许编译器等软件管理门控。

Result: ReGate可以将NPU芯片的能耗降低高达32.8%（平均15.5%），同时对AI工作负载性能的影响可以忽略不计。

Conclusion: ReGate通过在NPU芯片上实现细粒度的门控，可以将NPU芯片的能耗降低高达32.8%（平均15.5%），同时对AI工作负载性能的影响可以忽略不计。门控逻辑的硬件实现给NPU芯片带来了低于3.3%的开销。

Abstract: The energy efficiency of neural processing units (NPU) is playing a critical
role in developing sustainable data centers. Our study with different
generations of NPU chips reveals that 30%-72% of their energy consumption is
contributed by static power dissipation, due to the lack of power management
support in modern NPU chips. In this paper, we present ReGate, which enables
fine-grained power-gating of each hardware component in NPU chips with
hardware/software co-design. Unlike conventional power-gating techniques for
generic processors, enabling power-gating in NPUs faces unique challenges due
to the fundamental difference in hardware architecture and program execution
model. To address these challenges, we carefully investigate the power-gating
opportunities in each component of NPU chips and decide the best-fit power
management scheme (i.e., hardware- vs. software-managed power gating).
Specifically, for systolic arrays (SAs) that have deterministic execution
patterns, ReGate enables cycle-level power gating at the granularity of
processing elements (PEs) following the inherent dataflow execution in SAs. For
inter-chip interconnect (ICI) and HBM controllers that have long idle
intervals, ReGate employs a lightweight hardware-based idle-detection
mechanism. For vector units and SRAM whose idle periods vary significantly
depending on workload patterns, ReGate extends the NPU ISA and allows software
like compilers to manage the power gating. With implementation on a
production-level NPU simulator, we show that ReGate can reduce the energy
consumption of NPU chips by up to 32.8% (15.5% on average), with negligible
impact on AI workload performance. The hardware implementation of power-gating
logic introduces less than 3.3% overhead in NPU chips.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [810] [Towards a quantum synapse for quantum sensing](https://arxiv.org/abs/2508.00825)
*L-F Pau*

Main category: cs.ET

TL;DR: 本文将量子处理与生物过程联系起来，提出了一种量子突触电路设计，可用于传感和传感器融合。


<details>
  <summary>Details</summary>
Motivation: 将量子处理系统中的量子粒子流与模拟生物过程的神经元之间的随机流功能属性并行化。

Method: 基于简化的动态电子突触模型，设计了量子突触电路。

Result: 设计了量子突触电路，并探讨了其作为传感和传感器融合系统中高度并行的受控接口的潜在作用，同时提供了量子模拟的简要状态。

Conclusion: 本文提出了一种量子突触电路设计，并讨论了其在传感和传感器融合系统中的作用。

Abstract: As a step in the architectural design of a quantum processing or sensing
system with control and signaling, an attempt is made at putting in parallel
functional properties of the random flows between neurons through electrical
synapses, and quantum particle flows inside a quantum processing system
mimicking biological processes. Based on a simplified dynamic electrical
synapse model, a quantum synapse circuit design is proposed. This is extended
to the case of bidirectional flows through a synapse, highlighting the possible
role of quantum synapse circuits as highly parallel controlled interfaces
crucial in sensing and sensor fusion systems. A short status of the quantum
simulation is provided.

</details>


### [811] [A Comparative Study of Classical and Post-Quantum Cryptographic Algorithms in the Era of Quantum Computing](https://arxiv.org/abs/2508.00832)
*Arimondo Scrivano*

Main category: cs.ET

TL;DR: 量子计算威胁现有加密算法，本研究比较了经典算法与后量子算法（如Kyber、Dilithium、Falcon）的安全性、性能和可行性，并评估了混合方法以实现平稳过渡。


<details>
  <summary>Details</summary>
Motivation: 量子计算的出现对保护现代数字通信的基石密码算法构成了重大威胁，因此需要进行这项研究。

Method: 对当前广泛使用的经典密码算法和新兴的抗量子密码方案进行了全面的比较分析，评估了包括Kyber、Dilithium和Falcon在内的抗量子替代方案的安全、性能和实现可行性，并评估了旨在实现向后量子密码学平稳过渡的混合方法。

Result: 对经典密码算法和后量子密码学方案进行了全面的比较分析。

Conclusion: 本研究旨在为研究人员、开发人员和政策制定者提供关于理解量子计算对密码基础设施的关键影响以及在量子时代保护通信的必要步骤的深入比较。

Abstract: The advent of quantum computing poses a significant threat to the
foundational cryptographic algorithms that secure modern digital
communications. Protocols such as HTTPS, digital certificates, and public key
infrastructures (PKIs) heavily rely on cryptographic primitives like RSA, ECC,
and Diffie-Hellman, which are vulnerable to quantum attacks -- most notably
Shor's algorithm. This paper presents a comprehensive comparative analysis
between classical cryptographic algorithms currently in widespread use and
emerging post-quantum cryptographic schemes designed to withstand quantum
adversaries. We review the cryptographic mechanisms underpinning modern
internet security, outline the mathematical foundations of quantum attacks, and
evaluate the security, performance, and implementation feasibility of
quantum-resistant alternatives such as Kyber, Dilithium, and Falcon.
Additionally, we assess the hybrid approaches currently being explored by
institutions and tech companies to enable a smooth transition to post-quantum
cryptography. By providing an in-depth comparison, this study aims to guide
researchers, developers, and policymakers in understanding the critical
implications of quantum computing on cryptographic infrastructures and the
necessary steps for securing communications in the quantum era.

</details>


### [812] [QDockBank: A Dataset for Ligand Docking on Protein Fragments Predicted on Utility-Level Quantum Computers](https://arxiv.org/abs/2508.00837)
*Yuqi Zhang,Yuxin Yang,Cheng-Chang Lu,Weiwen Jiang,Feixiong Cheng,Bo Fang,Qiang Guan*

Main category: cs.ET

TL;DR: QDockBank是首个使用量子计算机生成的蛋白质片段结构数据集，用于蛋白质-配体对接任务。该数据集在预测精度上优于AlphaFold2和AlphaFold3，为量子蛋白质结构预测提供了新的基准。


<details>
  <summary>Details</summary>
Motivation: 蛋白质结构预测是一个核心挑战，特别是在生物计算领域，其中精确建模仍然很困难。量子计算提供了一种新颖的第一性原理建模范例，但其应用目前受到硬件限制、高计算成本以及缺乏标准化基准数据集的限制。在本研究中，我们提出了QDockBank——第一个完全使用实用级量子计算机生成的蛋白质片段结构的大规模数据集，专门为蛋白质-配体对接任务设计。

Method: QDockBank是通过在超导量子处理器上执行数小时而生成的，该数据集包含55个从配体结合口袋中提取的蛋白质片段。

Result: QDockBank包含55个蛋白质片段，是在超导量子处理器上生成的，计算成本超过一百万美元。与AlphaFold2和AlphaFold3相比，QDockBank在RMSD和对接亲和力得分方面均表现更优。

Conclusion: QDockBank是一个新基准，用于评估基于量子蛋白质结构预测。实验评估表明，QDockBank预测的结构在RMSD和对接亲和力得分方面均优于AlphaFold2和AlphaFold3的预测结构。

Abstract: Protein structure prediction is a core challenge in computational biology,
particularly for fragments within ligand-binding regions, where accurate
modeling is still difficult. Quantum computing offers a novel first-principles
modeling paradigm, but its application is currently limited by hardware
constraints, high computational cost, and the lack of a standardized
benchmarking dataset. In this work, we present QDockBank-the first large-scale
protein fragment structure dataset generated entirely using utility-level
quantum computers, specifically designed for protein-ligand docking tasks.
QDockBank comprises 55 protein fragments extracted from ligand-binding pockets.
The dataset was generated through tens of hours of execution on superconducting
quantum processors, making it the first quantum-based protein structure dataset
with a total computational cost exceeding one million USD. Experimental
evaluations demonstrate that structures predicted by QDockBank outperform those
predicted by AlphaFold2 and AlphaFold3 in terms of both RMSD and docking
affinity scores. QDockBank serves as a new benchmark for evaluating
quantum-based protein structure prediction.

</details>


### [813] [Managing Escalation in Off-the-Shelf Large Language Models](https://arxiv.org/abs/2508.01056)
*Sebastian Elbaum,Jonathan Panther*

Main category: cs.ET

TL;DR: 美国国家安全部门正在使用现有的语言模型，但这些模型可能会提出升级行动。本研究提出了两种简单的干预措施，可以在实验性战争博弈中减少升级，表明不应禁止使用语言模型，而应采取措施来管理它们，以符合国家安全目标。


<details>
  <summary>Details</summary>
Motivation: 随着美国国家安全客户开始采用包括“现成”模型（例如 ChatGPT）在内的语言模型，并且这种采用可能会加速，因此有必要解决这些模型在面临地缘政治或战略场景时提出升级行动的倾向。

Method: 通过引入两种简单、非技术的干预措施来控制大型语言模型的升级倾向，并在最近的一项研究的实验性战争博弈设计中实施了这些干预措施。

Result: 与未实施干预措施的对照组相比，所提出的干预措施显著降低了整个战争博弈过程中的升级情况。

Conclusion: 有说服力地认为，不应限制将大型语言模型用于国家安全应用，而是应采取可行的措施来管理其潜在的升级倾向。

Abstract: U.S. national security customers have begun to utilize large language models,
including enterprise versions of ``off-the-shelf'' models (e.g., ChatGPT)
familiar to the public. This uptake will likely accelerate. However, recent
studies suggest that off-the-shelf large language models frequently suggest
escalatory actions when prompted with geopolitical or strategic scenarios. We
demonstrate two simple, non-technical interventions to control these
tendencies. Introducing these interventions into the experimental wargame
design of a recent study, we substantially reduce escalation throughout the
game. Calls to restrict the use of large language models in national security
applications are thus premature. The U.S. government is already, and will
continue, employing large language models for scenario planning and suggesting
courses of action. Rather than warning against such applications, this study
acknowledges the imminent adoption of large language models, and provides
actionable measures to align them with national security goals, including
escalation management.

</details>


### [814] [Conquering High Packet-Loss Erasure: MoE Swin Transformer-Based Video Semantic Communication](https://arxiv.org/abs/2508.01205)
*Lei Teng,Senran Fan,Chen Dong,Haotai Liang,Zhicheng Bao,Xiaodong Xu,Rui Meng,Ping Zhang*

Main category: cs.ET

TL;DR: 提出了一种抗丢包的视频语义通信系统（MSTVSC），利用Swin Transformer和3D CNN来减少丢包带来的语义损失，并在高丢包率下取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统基于包的语义通信系统中，由于丢包导致语义信息丢失和接收端无法利用错误语义数据进行解码的问题。

Method: 提出了一种基于Swin Transformer的MoE（MSTVSC）系统，对视频语义进行编码和传输。在接收端，利用3D CNN和丢包掩码矩阵恢复丢失的信息。此外，还采用了语义级交错和单独分解（对单独信息进行下采样）的方法来减少丢包造成的语义损失和冗余。

Result: 在90%的丢包率下，MSTVSC系统实现了超过0.6的MS-SSIM和超过20dB的PSNR。模型轻量化，适合实际部署。

Conclusion: 提出的MSTVSC系统通过使用3D CNN恢复丢失的语义信息，并采用语义级交错和单独分解的方法来提高鲁棒性和压缩效率，在90%丢包率下实现了超过0.6的MS-SSIM和超过20dB的PSNR。

Abstract: Semantic communication with joint semantic-channel coding robustly transmits
diverse data modalities but faces challenges in mitigating semantic information
loss due to packet drops in packet-based systems. Under current protocols,
packets with errors are discarded, preventing the receiver from utilizing
erroneous semantic data for robust decoding. To address this issue, a
packet-loss-resistant MoE Swin Transformer-based Video Semantic Communication
(MSTVSC) system is proposed in this paper. Semantic vectors are encoded by
MSTVSC and transmitted through upper-layer protocol packetization. To
investigate the impact of the packetization, a theoretical analysis of the
packetization strategy is provided. To mitigate the semantic loss caused by
packet loss, a 3D CNN at the receiver recovers missing information using
un-lost semantic data and an packet-loss mask matrix. Semantic-level
interleaving is employed to reduce concentrated semantic loss from packet
drops. To improve compression, a common-individual decomposition approach is
adopted, with downsampling applied to individual information to minimize
redundancy. The model is lightweighted for practical deployment. Extensive
simulations and comparisons demonstrate strong performance, achieving an
MS-SSIM greater than 0.6 and a PSNR exceeding 20 dB at a 90% packet loss rate.

</details>


### [815] [Introduction to QUDO, Tensor QUDO and HOBO formulations: Qudits, Equivalences, Knapsack Problem, Traveling Salesman Problem and Combinatorial Games](https://arxiv.org/abs/2508.01958)
*Alejandro Mata Ali*

Main category: cs.ET

TL;DR: 本文介绍了QUDO、T-QUDO和HOBO方法在组合优化问题中的应用，并通过实例展示了其等价性，旨在为量子优化算法提供更通用的公式化工具。


<details>
  <summary>Details</summary>
Motivation: 为了提供组合优化问题的通用公式化方法，并促进这些方法在新型量子或受量子启发优化算法中的应用，特别是为更复杂的优化问题提供更简单的入门途径。

Method: 通过介绍二次无约束D元优化（QUDO）、张量二次无约束D元优化（T-QUDO）和高阶无约束二元优化（HOBO）等方法，并辅以背包问题、旅行商问题和多种组合游戏作为实例，来展示这些方法在组合优化问题中的应用和等价性。

Result: 成功展示了QUDO、T-QUDO和HOBO方法在组合优化问题中的应用，并说明了它们之间的等价性。通过具体实例，帮助理解这些方法，并为解决更复杂的优化问题开辟了道路。

Conclusion: 本文介绍了二次无约束D元优化（QUDO）、张量二次无约束D元优化（T-QUDO）和高阶无约束二元优化（HOBO）等组合优化问题的公式化方法，并展示了它们之间的等价性。通过背包问题、旅行商问题和多种组合游戏（如Hashiwokakero、N-Queens、Kakuro、Inshi no heya和Peg Solitaire）的实例，阐述了这些方法的应用。研究旨在为更复杂的组合优化问题提供更通用的公式化途径，并促进其在新型量子或受量子启发优化算法中的应用。

Abstract: In this paper, we present a brief review and introduction to Quadratic
Unconstrained D-ary Optimization (QUDO), Tensor Quadratic Unconstrained D-ary
Optimization (T-QUDO) and Higher-Order Unconstrained Binary Optimization (HOBO)
formulations for combinatorial optimization problems. We also show their
equivalences. To help their understanding, we make some examples for the
knapsack problem, traveling salesman problem and different combinatorial games.
The games chosen to exemplify are: Hashiwokakero, N-Queens, Kakuro, Inshi no
heya, and Peg Solitaire. Although some of these games have already been
formulated in a QUBO formulation, we are going to approach them with more
general formulations, allowing their execution in new quantum or
quantum-inspired optimization algorithms. This can be an easier way to
introduce these more complicated formulations for harder problems.

</details>


### [816] [Thermal Implications of Non-Uniform Power in BSPDN-Enabled 2.5D/3D Chiplet-based Systems-in-Package using Nanosheet Technology](https://arxiv.org/abs/2508.02284)
*Yukai Chen,Massimiliano Di Todaro,Bjorn Vermeersch,Herman Oprins,Daniele Jahier Pagliari,Julien Ryckaert,Dwaipayan Biswas,James Myers*

Main category: cs.ET

TL;DR: 与传统的均匀功耗图相比，这项工作使用高分辨率模拟来研究非均匀功耗图对2.5D/3D chiplet-based SiP中的功率输送网络（PDN）的热影响。研究发现，非均匀功耗图可以更准确地评估热量，并揭示不同PDN配置在3D集成中的热量差异。


<details>
  <summary>Details</summary>
Motivation: 2.5D/3D chiplet-based SiP 中的纳米片技术增加了功率密度，加剧了热管理挑战。传统的均匀功耗图假设会忽略局部加热效应，导致热量估算不准确，特别是在比较3D集成中的PDN时。

Method: 使用分辨率低至5微米的非均匀功耗图进行高分辨率热力模拟。

Result: 与均匀功耗假设相比，非均匀功耗图可显著降低峰值温度，并揭示3D场景中BSPDN和FSPDN配置之间的关键热量差异。在真实的局部工作负载下，3D中的BSPDN配置会因有限的横向热量扩散而表现出显著的热量损失。

Conclusion: 准确的电源网络（PDN）评估和知情的、面向热力的设计决策在先进的纳米片式三维SiP中是必不可少的，需要采用细粒度的、面向工作负载的功耗图进行早期热力建模。

Abstract: Advances in nanosheet technologies have significantly increased power
densities, exacerbating thermal management challenges in 2.5D/3D chiplet-based
Systems-in-Package (SiP). While traditional thermal analyses often employ
uniform power maps to simplify computational complexity, this practice neglects
localized heating effects, leading to inaccuracies in thermal estimations,
especially when comparing power delivery networks (PDN) in 3D integration. This
work examines the thermal impact of non-uniform power distributions on SiPs
utilizing frontside (FSPDN) and backside (BSPDN) power delivery approaches.
Using high-resolution thermal simulations with non-uniform power maps at
resolutions down to 5 micrometers, we demonstrate that uniform power
assumptions substantially underestimate peak temperatures and fail to reveal
critical thermal differences between BSPDN and FSPDN configurations in 3D
scenarios. Our results highlight that BSPDN configurations in 3D, although
beneficial in simplified uniform scenarios, exhibit pronounced thermal
penalties under realistic, localized workloads due to limited lateral heat
spreading. These findings emphasize the necessity of adopting fine-grained,
workload-aware power maps in early-stage thermal modeling to enable accurate
PDN assessment and informed thermal-aware design decisions in advanced
nanosheet-based 3D SiP.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [817] [Proof of Hiding Conjecture in Gaussian Boson Sampling](https://arxiv.org/abs/2508.00983)
*Laura Shou,Sarah H. Miller,Victor Galitski*

Main category: quant-ph

TL;DR: 该研究在实验相关的最大压缩态GBS设置下，首次严格证明了隐藏猜想，为GBS的经典困难性提供了有力证据。


<details>
  <summary>Details</summary>
Motivation: 为了证明高斯玻色取样的经典困难性，需要解决“隐藏猜想”，即证明可以在哈尔酉子矩阵的外积的子矩阵中“隐藏”一个复高斯矩阵。

Method: 通过严格证明，当输入状态具有最大数量的压缩态时，高斯矩阵可以近似为COE随机矩阵的子矩阵，其总变异距离接近。

Result: 在最大压缩态输入状态下，证明了隐藏猜想。具体而言，一个 $M 	imes M$ 的COE随机矩阵的 $o(\sqrt{M}) \times o(\sqrt{M})$ 子矩阵可以被复高斯矩阵在总变异距离上很好地近似，当 $M \to \infty$ 时。

Conclusion: 该研究首次在实验相关的最大压缩态输入状态下，为高斯玻色取样（GBS）证明了隐藏猜想，这使得具有最大压缩态数量的GBS的经典模拟的困难性论证与传统的玻色取样相当。

Abstract: Gaussian boson sampling (GBS) is a promising protocol for demonstrating
quantum computational advantage. One of the key steps for proving classical
hardness of GBS is the so-called ``hiding conjecture'', which asserts that one
can ``hide'' a complex Gaussian matrix as a submatrix of the outer product of
Haar unitary submatrices in total variation distance. In this paper, we prove
the hiding conjecture for input states with the maximal number of squeezed
states, which is a setup that has recently been realized experimentally [Madsen
et al., Nature 606, 75 (2022)]. In this setting, the hiding conjecture states
that a $o(\sqrt{M})\times o(\sqrt{M})$ submatrix of an $M\times M$ circular
orthogonal ensemble (COE) random matrix can be well-approximated by a complex
Gaussian matrix in total variation distance as $M\to\infty$. This is the first
rigorous proof of the hiding property for GBS in the experimentally relevant
regime, and puts the argument for hardness of classically simulating GBS with a
maximal number of squeezed states on a comparable level to that of the
conventional boson sampling of [Aaronson and Arkhipov, Theory Comput. 9, 143
(2013)].

</details>


### [818] [Ultimate resolution limits in coherent anti-Stokes Raman scattering imaging](https://arxiv.org/abs/2508.01026)
*Giacomo Sorelli,Manuel Gessner,Frank Schlawin*

Main category: quant-ph

TL;DR: 本研究利用量子信息理论工具提高了相干抗斯托克斯拉曼散射（CARS）成像技术的精度和灵敏度。通过空间模式解复用和基于涡旋光束的成像方案，该技术可以达到量子极限，并有望实现更高的分辨率和灵敏度。


<details>
  <summary>Details</summary>
Motivation: 为了探索相干抗斯托克斯拉曼散射（CARS）成像技术的固有精度极限，并利用量子信息理论工具提供化学对比度，而无需标记。

Method: 本研究利用量子信息理论工具探索了相干抗斯托克斯拉曼散射（CARS）成像技术的固有精度极限，确定了最优测量策略，并提出了一种基于涡旋光束的先进成像方案。

Result: 空间模式解复用技术可以达到量子极限，并在许多情况下提高传统强度测量的灵敏度。基于涡旋光束的先进成像方案有望增强成像信息，从而实现更高的分辨率和灵敏度。

Conclusion: 本研究确立了利用量子科学概念增强非线性成像技术的明确途径，弥合了传统显微镜方法与新兴量子技术能力之间的差距。

Abstract: Coherent anti-Stokes Raman scattering is a widely used imaging technique that
provides chemical contrast without the need for labels, making it an extremely
valuable tool in physics, chemistry, and biology. In this work, we explore its
fundamental precision limits by applying tools from quantum information theory.
We identify optimal measurement strategies and show that spatial mode
demultiplexing--a technique already accessible in current experimental
setups--can achieve these quantum limits and in many situations improve the
sensitivity of conventional intensity measurements. Building on this, we
introduce an advanced imaging scheme based on vortex beams, which we predict to
enhance the image information in the final quantum state of light and thereby
lead to even higher resolution and sensitivity. These findings establish a
clear path for enhancing nonlinear imaging techniques using concepts from
quantum science, bridging the gap between established microscopy methods and
the emerging capabilities of quantum technologies.

</details>


### [819] [Erbium-Doped Fibre Quantum Memory for Chip-Integrated Quantum-Dot Single Photons at 980 nm](https://arxiv.org/abs/2508.01416)
*Nasser Gohari Kamel,Arsalan Mansourzadeh,Ujjwal Gautam,Vinaya Kumar Kavatamane,Ashutosh Singh,Edith Yeung,David B. Northeast,Paul Barclay,Philip J. Poole,Dan Dalacu,Daniel Oblak*

Main category: quant-ph

TL;DR: 本工作首次实现了纳米线量子点与掺铒光纤量子存储器的相干混合光-物接口，并成功实现了单光子的确定性存储和检索。


<details>
  <summary>Details</summary>
Motivation: 长距离量子通信和量子互联网的实现依赖于连接量子光源和量子存储器的相干混合光-物接口。与概率性的光子对源（如自发参量下转换）不同，确定性量子光源能够按需产生纯净、高亮度的单光子和纠缠光子，这对于可扩展的量子网络至关重要。

Method: 通过实验实现了芯片集成InAsP/InP纳米线量子点与掺铒光纤（EDF）固态量子存储器（QM）之间的相干混合光-物界面。对EDF在980nm的^{4}I_{15/2} ightarrow ^{4}I_{11/2}光学跃迁进行了光谱表征，揭示了其较大的不均匀展宽和长自旋寿命。实现了基于原子频率梳（AFC）协议的8 GHz带宽多模QM，能够存储和检索59个弱相干脉冲。最后，对InAsP/InP纳米线量子点在980nm的单光子发射进行了表征，并演示了其在EDF QM中的确定性存储和检索。

Result: 成功实现了InAsP/InP纳米线量子点与EDF QM之间的相干混合光-物界面。光谱表征显示EDF具有大的不均匀展宽和长自旋寿命，适用于宽带QM。实现了基于AFC协议的8 GHz带宽多模QM，存储了59个弱相干脉冲。演示了量子点单光子的确定性存储和检索，且无需光谱调谐。

Conclusion: 本文首次实现了芯片集成InAsP/InP纳米线量子点与掺铒光纤（EDF）固态量子存储器（QM）之间的相干混合光-物界面，并成功地实现了量子点发出的单光子的确定性存储和检索，且无需对量子点发射进行光谱调谐，证明了其与固态QM的直接兼容性。

Abstract: The realization of long-distance quantum communication and the envisioned
quantum internet relies on coherent hybrid light-matter interfaces connecting
quantum light emitters with quantum memory (QM) systems. Unlike probabilistic
photon pair sources such as spontaneous parametric down-conversion,
deterministic quantum light emitters enable the on-demand production of pure
and bright single and entangled photons, essential for scalable quantum
networks. In this work, we present the first experimental realization of a
coherent hybrid light-matter interface between a chip-integrated InAsP/InP
nanowire quantum dot (QD) and a solid-state QM based on Er$^{3+}$ ions doped in
a glass silica fiber (erbium-doped fiber, EDF). The emission spectrum of the
InAsP/InP nanowire QD aligns with the absorption bandwidth of the EDF at 980 nm
at cryogenic temperatures, allowing efficient interaction between the two
systems. To demonstrate this, we present a spectroscopic characterization of
the $^{4}I_{15/2} \leftrightarrow ^{4}I_{11/2}$ optical transition in EDF at
980 nm. Our measurements reveal substantial inhomogeneous broadening of this
optical transition and a long spin population lifetime, underscoring EDFs
potential for broadband QM implementation. We implement an 8 GHz bandwidth
multimode QM based on the Atomic Frequency Comb protocol, enabling the storage
and retrieval of 59 weak coherent pulses. Furthermore, we characterize
single-photon emission from an InAsP/InP nanowire QD at 980 nm and demonstrate
its deterministic storage and recall in the EDF QM. Notably, this is achieved
without spectral tuning of the QD emission, demonstrating its direct
compatibility with a solid-state QM.

</details>


### [820] [Telecommunications fiber-optic and free-space quantum local area networks at the Air Force Research Laboratory](https://arxiv.org/abs/2508.01030)
*Erin Sheridan,Nicholas J. Barton,Richard Birrittella,Vedansh Nehra,Zachary Smith,Christopher Tison,Amos Matthew Smith,Shashank Dharanibalan,Vijit Bedi,David Hucul,Benjamin Kyle,Christpher Nadeau,Mary Draper,John Heinig,Scott Faulkner,Randal Scales,Andrew M. Brownell,Stefan Preble,James Schneeloch,Samuel Schwab,Daniel Campbell,Derrick Sica,Peter Ricci,Vladimir Nikulin,John Malowicki,Jacob Hall,Michael Fanto,Matthew D. LaHaye,Laura Wessing,Paul M. Alsing,Kathy-Anne Soderberg,Donald Telesca*

Main category: quant-ph

TL;DR: 开发了在电信频段下运行的量子局域网（QLAN），并成功在已部署光纤中演示了时-能贝尔态的纠缠分发，展示了量子网络基础设施的实际可行性。


<details>
  <summary>Details</summary>
Motivation: 为支持空军研究实验室（AFRL）构建异构量子网络的任务

Method: 开发了在电信频段下运行的量子局域网（QLAN），该网络具有多节点、可重构的特点，包括已部署的光纤和自由空间链路，并连接了实验室环境和户外的测试设施。利用基于光子集成电路的纠缠光子源，在 the wooded environment 下的已部署光纤中演示了时-能贝尔态的纠缠分发。

Result: 在 the wooded environment 下的已部署光纤中，利用光子集成电路的光源，演示了时-能贝尔态的纠缠分发，Clauser-Horne-Shimony-Holt 不等式检验值为 S=2.700，接近理论最大值 S=2.828。

Conclusion: 本工作展示了可现场部署的、与量子比特无关的量子网络基础设施的实际可行性，并讨论了未来扩展QLAN功能以及在超导量子比特和离子阱等异构物基量子系统之间实现纠缠分发的工作。

Abstract: As quantum computing, sensing, timing, and networking technologies mature,
quantum network testbeds are being deployed across the United States and around
the world. To support the Air Force Research Laboratory (AFRL)'s mission of
building heterogeneous quantum networks, we report on the development of
Quantum Local Area Networks (QLANs) operating at telecommunications-band
frequencies. The multi-node, reconfigurable QLANs include deployed optical
fiber and free-space links connected to pristine laboratory environments and
rugged outdoor test facilities. Each QLAN is tailored to distinct operating
conditions and use cases, with unique environmental characteristics and
capabilities. We present network topologies and in-depth link characterization
data for three such networks. Using photonic integrated circuit-based sources
of entangled photons, we demonstrate entanglement distribution of time-energy
Bell states across deployed fiber in a wooded environment. The high quality of
the entanglement is confirmed by a Clauser-Horne-Shimony-Holt inequality
violation of $S=2.700$, approaching the theoretical maximum of $S=2.828$. We
conclude with a discussion of future work aimed at expanding QLAN functionality
and enabling entanglement distribution between heterogeneous matter-based
quantum systems, including superconducting qubits and trapped ions. These
results underscore the practical viability of field-deployable, qubit-agnostic
quantum network infrastructure.

</details>


### [821] [Demonstration of an always-on exchange-only spin qubit](https://arxiv.org/abs/2508.01033)
*Joseph D. Broz,Jesse C. Hoke,Edwin Acuna,Jason R. Petta*

Main category: quant-ph

TL;DR: 本研究展示了使用AEON量子比特和同时交换脉冲，实现了99.86%的平均Clifford门保真度，为未来更高效的量子门操作和实现i-Toffoli门奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了减少量子线路深度并提供抗泄漏保护，本研究探索了在交换耦合仅激活一个时，通过同时对多个非对易交换相互作用进行脉冲操作。

Method: 采用盲随机基准测试（blind randomized benchmarking）来表征 AEON 量子比特的单比特 Clifford 门集。

Result: 平均 Clifford 门保真度（$F_{m C1}$）达到 99.86%。

Conclusion: 本研究展示了使用三角形量子点阵列中的连续交换操作（AEON）量子比特，通过同时进行交换脉冲实现高保真度的量子控制，并使用盲随机基准测试了 AEON 单比特 Clifford 门集，平均 Clifford 门保真度达到 99.86%。

Abstract: In conventional exchange-only (EO) spin qubit demonstrations, quantum gates
have been implemented using sequences of individually pulsed pairwise exchange
interactions with only one exchange coupling active at a time. Alternatively,
multiple non-commuting exchange interactions can be pulsed simultaneously,
reducing circuit depths and providing protection against leakage. We
demonstrate high-fidelity quantum control of an always-on exchange-only (AEON)
qubit, operated using simultaneous exchange pulses in a triangular quantum dot
(QD) array. We use blind randomized benchmarking to characterize the
performance of the full AEON single-qubit Clifford gate set, achieving an
average Clifford gate fidelity $F_{\rm C1}$ = 99.86\%. Extensions of this work
may enable more efficient EO two-qubit entangling gates as well as the
implementation of native $i$-Toffoli gates in Loss-DiVincenzo single-spin
qubits.

</details>


### [822] [QPP-RNG: A Conceptual Quantum System for True Randomness](https://arxiv.org/abs/2508.01051)
*Randy Kuang*

Main category: quant-ph

TL;DR: 提出了一种名为QSQS的新型随机数生成框架，并用QPP-RNG软件实现。该框架通过测量排序过程中的排列计数和排序时间，利用其内在的不确定性来生成高质量的随机数，并已通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 通过类比量子系统，将可观测量链接起来，以一种不确定性约束的方式来生成随机数。

Method: 提出并实验演示了准叠加量子启发系统（QSQS），该系统基于测量排列排序过程的两个共轭可观测量：确定性排列计数 $n_p$ 和根本上非确定性的排序时间 $t$。该框架具体实现为QPP-RNG，一个嵌入式、纯软件的真随机数生成器（TRNG）。

Result: QSQS将原始的右偏分布转换为近似均匀的输出，熵收敛到理论最大值（接近8比特），卡方统计量趋于理想均匀性，实验结果证实了从偏态到均匀分布的转变。

Conclusion: QSQS将确定性算法过程与非确定性物理波动相结合，为后量子密码系统中的真随机性工程提供了基于物理学的视角。

Abstract: We propose and experimentally demonstrate the \emph{Quasi-Superposition
Quantum-inspired System (QSQS)} -- a conceptual quantum system for randomness
generation built on measuring two conjugate observables of a permutation
sorting process: the deterministic permutation count $n_p$ and the
fundamentally non-deterministic sorting time $t$. By analogy with quantum
systems, these observables are linked by an uncertainty-like constraint:
algorithmic determinism ensures structural uniformity, while system-level
fluctuations introduce irreducible unpredictability. We realize this framework
concretely as \emph{QPP-RNG}, a system-embedded, software-based true random
number generator (TRNG). In QPP-RNG, real-time measurements of sorting time $t$
-- shaped by CPU pipeline jitter, cache latency, and OS scheduling --
dynamically reseed the PRNG driving the permutation sequence. Crucially, QSQS
transforms initially right-skewed raw distributions of $n_p$ and $t$ into
nearly uniform outputs after modulo reduction, thanks to internal degeneracies
that collapse many distinct states into the same output symbol. Empirical
results show that as the repetition factor $m$ increases, output entropy
converges toward theoretical maxima: Shannon and min-entropy values approach 8
bits, chi-squared statistics stabilize near ideal uniformity, and bell curves
visually confirm the flattening from skewed to uniform distributions. Beyond
practical implications, QSQS unifies deterministic algorithmic processes with
non-deterministic physical fluctuations, offering a physics-based perspective
for engineering true randomness in post-quantum cryptographic systems.

</details>


### [823] [A kilometer photonic link connecting superconducting circuits in two dilution refrigerators](https://arxiv.org/abs/2508.02444)
*Yiyu Zhou,Yufeng Wu,Chunzhen Li,Mohan Shen,Likai Yang,Jiacheng Xie,Hong X. Tang*

Main category: quant-ph

TL;DR: 在两个相隔1公里的超导电路之间实现了相干信号传输，为构建量子网络奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了克服量子处理器扩展的限制，需要构建量子网络来互联不同制冷机中的量子比特，这需要微波到光学的转换器来实现长距离低损耗信号传输。

Method: 通过一对频率匹配的氮化铝压电光调制器和1公里长的电信光纤，实验性地证明了在两个分离的稀释制冷机中的超导电路之间的相干信号传输。

Result: 实验实现了两个相隔1公里的超导电路之间的相干信号传输，每个节点的转换器效率超过0.1%，与商用压电光调制器相比，整体转换效率提高了80分贝，为实现完全由量子驱动的链路奠定了基础。

Conclusion: 这项工作为利用光子链路实现可扩展的超导量子网络提供了关键的设计指导。

Abstract: Superconducting quantum processors are a leading platform for implementing
practical quantum computation algorithms. Although superconducting quantum
processors with hundreds of qubits have been demonstrated, their further
scaling up is constrained by the physical size and cooling power of dilution
refrigerators. This constraint can be overcome by constructing a quantum
network to interconnect qubits hosted in different refrigerators, which
requires microwave-to-optical transducers to enable low-loss signal
transmission over long distances. Despite that various designs and
demonstrations have achieved high-efficiency and low-added-noise transducers, a
coherent photonic link between separate refrigerators has not yet been
realized. In this work, we experimentally demonstrate coherent signal transfer
between two superconducting circuits housed in separate dilution refrigerators,
enabled by a pair of frequency-matched aluminum nitride electro-optic
transducers connected via a 1-km telecom optical fiber. With transducers at
each node achieving >0.1% efficiency, an overall 80 dB improvement in
transduction efficiency over commercial electro-optic modulators is attainable,
paving the way towards a fully quantum-enabled link. This work provides
critical design guidelines towards scalable superconducting quantum networks
interconnected by photonic links.

</details>


### [824] [Cryogenic RF-to-Microwave Transducer based on a DC-Biased Electromechanical System](https://arxiv.org/abs/2508.01066)
*Himanshu Patange,Kyrylo Gerashchenko,Rémi Rousseau,Paul Manset,Léo Balembois,Thibault Capelle,Samuel Deléglise,Thibaut Jacqmin*

Main category: quant-ph

TL;DR: 该研究介绍了一种新的射频到微波变换器，它能显著提高灵敏度，有望用于量子级应用。


<details>
  <summary>Details</summary>
Motivation: 本研究的目的是提出一种实现量子级射频静电计和低噪声模块化外差链路的方法。

Method: 本研究报告了一种双极、外差射频到微波的变换器，该变换器结合了可调谐静电预放大器和超导机电设备。其中，金属化的Si$_3$N$_4$膜（3 MHz频率）作为微波LC谐振器中真空间隙电容器的活动极板。通过在间隙上施加直流偏置，将任何小的射频信号转换为与偏置成正比的谐振静电力，从而提供电压控制增益，该增益可以放大谐振器的固有电动增益。

Result: 在1.5 μm间隙和10 mK下工作的器件中，我们观察到了直流可调的反弹簧位移，并在49 V偏置下实现了射频到微波的变换，电荷灵敏度达到了87 μe/√Hz（0.9 nV/√Hz）。

Conclusion: 本研究提出了一种双极、外差射频到微波的变换器，该变换器结合了可调谐静电预放大器和超导机电设备。该装置在10 mK下工作，实现了87 μe/√Hz（0.9 nV/√Hz）的电荷灵敏度。通过外推到亚微米间隙和状态的Q>10^8膜谐振器，可以实现低于200 fV/√Hz的灵敏度，这表明直流偏置机电学是实现量子级射频静电计和超导微波电路低噪声模块化外差链路以及电荷或电压传感的可行途径。

Abstract: We report a two-stage, heterodyne rf-to-microwave transducer that combines a
tunable electrostatic pre-amplifier with a superconducting electromechanical
cavity. A metalized Si$_3$N$_4$ membrane (3 MHz frequency) forms the movable
plate of a vacuum-gap capacitor in a microwave LC resonator. A dc bias across
the gap converts any small rf signal into a resonant electrostatic force
proportional to the bias, providing a voltage-controlled gain that multiplies
the cavity's intrinsic electromechanical gain. In a flip-chip device with a 1.5
$\mathrm{\mu}$m gap operated at 10 mK we observe dc-tunable anti-spring shifts,
and rf-to-microwave transduction at 49 V bias, achieving a charge sensitivity
of 87 $\mathrm{\mu}$e/$\sqrt{\mathrm{Hz}}$ (0.9 nV/$\sqrt{\mathrm{Hz}}$).
Extrapolation to sub-micron gaps and state-of-the-art $Q>10^8$ membrane
resonators predicts sub-200 fV/$\sqrt{\mathrm{Hz}}$ sensitivity, establishing
dc-biased electromechanics as a practical route towards quantum-grade rf
electrometers and low-noise modular heterodyne links for superconducting
microwave circuits and charge or voltage sensing.

</details>


### [825] [Robustly self-testing all maximally entangled states in every finite dimension](https://arxiv.org/abs/2508.01071)
*Uta Isabella Meyer,Ivan Šupić,Frédéric Grosshans,Damian Markham*

Main category: quant-ph

TL;DR: 这项研究提出了一种用于认证最大纠缠态的设备无关的、容错的协议，该协议适用于所有有限维度d，特别是素数维度d，并且可以扩展到复合维度d。


<details>
  <summary>Details</summary>
Motivation: 该研究的主要动机是建立一种独立于设备、容忍噪声的、在每个有限维度d上的最大纠缠态的认证方法。

Method: 该方法使用d输入、d输出贝尔实验，并将Clauser-Horne-Shimony-Holt检验从量子比特推广到qudits，其中每个设置都是非对角的Heisenberg-Weyl可观察量。对于每个奇数素数d≥3，相关的贝尔算符具有正算符的精确和分解，从而得到Cirelson界的可重构形式。然后，作者将Mayers-Yao局部等距从量子比特扩展到素数维系统，并证明任何低于该界的$
u$-近优策略，在局部等距下，都与理想的最大纠缠态的迹距离$	au = 	ilde{	ext{O}}(
u)$之内。

Result: 我们得出了Cirelson界的可重构形式，并证明了在局部等距下，任何$
u$-近优策略都与理想的最大纠缠态的迹距离$	au = 	ilde{	ext{O}}(
u)$之内。此外，研究结果表明，该协议使用的Heisenberg-Weyl操作和非Clifford相位门可以直接应用于高维光子和原子平台。

Conclusion: 该协议可直接应用于高维光子和原子平台。

Abstract: We establish a device-independent, noise-tolerant certification of maximally
entangled states in every finite dimension $d$. The core ingredient is a
$d$-input, $d$-outcome Bell experiment that generalizes the
Clauser-Horne-Shimony-Holt test from qubits to qudits, where each setting is a
non-diagonal Heisenberg-Weyl observable. For every odd prime $d \geq 3$, the
associated Bell operator has an exact sum-of-positive-operators decomposition,
yielding the Cirelson bound in closed form, from which we reconstruct the
Heisenberg-Weyl commutation relations on the support of the state. We then
extend the Mayers-Yao local isometry from qubits to prime-dimensional systems
and show that any $\epsilon$-near-optimal strategy below that bound is, up to
local isometries, within trace distance $\delta = \mathcal{O}(\sqrt{\epsilon})$
of the ideal maximally entangled state; the implemented measurements are
correspondingly close to the target observables. Via a tensor-factor argument,
the prime-dimension result extends the self-testing protocol to every composite
dimension $d$. The protocol uses standard Heisenberg-Weyl operations and
non-Clifford phase gates that are diagonal in the computational basis, making
it directly applicable to high-dimensional photonic and atomic platforms.

</details>


### [826] [Biorthogonal Neural Network Approach to Two-Dimensional Non-Hermitian Systems](https://arxiv.org/abs/2508.01072)
*Massimo Solinas,Brandon Barton,Yuxuan Zhang,Jannes Nys,Juan Carrasquilla*

Main category: quant-ph

TL;DR: 研究了用变分蒙特卡洛和神经网络波函数来研究非厄米量子多体系统的基态性质，并提出了一种新的自洽对称优化方法来处理非厄米系统中的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数值技术在研究非厄米量子多体系统（包括非厄米性束和奇异点）时面临的挑战。

Method: 结合了变分蒙特卡洛和神经网络波函数表示，并开发了一个基于方差最小化的自洽对称优化框架，该框架利用了系统对称性和伪厄米性，并针对奇异点提出了新颖的优化例程。

Result: 所提出的方法在二维非厄米横向场伊辛模型上进行了测试，在保持和破坏了时间反演对称性的相中均达到了很高的精度，并且在标准变分技术失效的区域能够可靠地收敛到基态。

Conclusion: 该方法提供了一种可扩展且灵活的计算工具，用于研究传统数值技术（如密度矩阵重整化群算法）无法企及的非厄米量子多体系统。

Abstract: Non-Hermitian quantum many-body systems exhibit a rich array of physical
phenomena, including non-Hermitian skin effects and exceptional points, that
remain largely inaccessible to existing numerical techniques. In this work, we
investigate the application of variational Monte Carlo and neural network
wavefunction representations to examine their ground-state (the eigenstate with
the smallest real part energy) properties. Due to the breakdown of the
Rayleigh-Ritz variational principle in non-Hermitian settings, we develop a
self-consistent symmetric optimization framework based on variance minimization
with a dynamically updated energy estimate. Our approach respects the
biorthogonal structure of left and right eigenstates, and is further
strengthened by exploiting system symmetries and pseudo-Hermiticity. Tested on
a two-dimensional non-Hermitian transverse field Ising model endowed with a
complex longitudinal field, our method achieves high accuracy across both
parity-time symmetric and broken phases. Moreover, we propose novel
optimization routines that address the challenges posed by exceptional points
and provide reliable convergence to the ground state in regimes where standard
variational techniques fail. Lastly, we show, through extensive numerical
evidence, that our method offers a scalable and flexible computational tool to
investigate non-Hermitian quantum many-body systems, beyond the reach of
conventional numerical techniques such as the density-matrix renormalization
group algorithm.

</details>


### [827] [A causal derivation of the algebraic approach to quantum systems](https://arxiv.org/abs/2508.01111)
*Nick Ormrod*

Main category: quant-ph

TL;DR: 量子系统的因果视图可以导出代数方法。


<details>
  <summary>Details</summary>
Motivation: 质疑了量子系统由算子代数表示的普遍假设，并试图解决一个看似合理的、非代数表示的量子系统候选。

Method: 从量子信息理论的因果模型框架中汲取灵感，提出量子系统的“因果视图”，并通过数学推导证明了代数表示可以从因果视图导出。

Result: 证明了每个量子系统对应一个唯一的冯·诺依曼代数，并且经典量子系统对应唯一的交换冯·诺依曼算子代数，从而从因果视图推导出了传统的代数方法。

Conclusion: 该工作提出了量子系统的“因果视图”，并证明了每个量子系统都对应一个唯一的冯·诺依曼代数，以及经典量子系统对应唯一的交换冯·诺依曼算子代数。

Abstract: It is commonly assumed that every quantum system is represented by some
algebra of operators. Doubt is cast on this assumption by what appears, at
first glance, to be a reasonable candidate for a quantum system that is not
naturally represented by any algebra. To resolve this puzzle, this work draws
inspiration from recent frameworks for causal modelling in quantum theory to
propose a "causal view" of quantum systems. The causal view defines quantum
systems purely in terms of the causal structure of the unitary dynamics. The
algebraic representation of quantum systems is derived from the causal view: it
is proven that every quantum system corresponds to a unique von Neumann algebra
of operators. The causal view is extended with a definition of a "classical
quantum system" inspired by quantum Darwinism. It is shown that such a system
corresponds to a unique commutative von Neumann operator algebra, completing
the derivation of the traditional algebraic approach to quantum systems from
the causal view. The causal view is contrasted with the "epistemic view" of
quantum systems, which is incompatible with the algebraic approach.

</details>


### [828] [TensoMeta-VQC: A Tensor-Train-Guided Meta-Learning Framework for Robust and Scalable Variational Quantum Computing](https://arxiv.org/abs/2508.01116)
*Jun Qi,Chao-Han Yang,Pin-Yu Chen,Min-Hsiu Hsieh*

Main category: quant-ph

TL;DR: TensoMeta-VQC 是一个结合张量训练和元学习的框架，通过将参数生成交给经典 TT 网络来解决 VQC 的可扩展性和噪声问题，并在多项任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决变分量子计算（VQC）在可扩展性方面面临的由巴伦高原和量子噪声敏感性引起的根本性障碍。

Method: 提出了一种新颖的张量训练（TT）指导的元学习框架 TensoMeta-VQC，将量子电路参数的生成完全委托给经典的 TT 网络，从而实现优化与量子硬件的分离。

Result: TensoMeta-VQC 在量子点分类、最大割优化和分子量子模拟任务上取得了卓越的性能和鲁棒的噪声容忍度。

Conclusion: TensoMeta-VQC 框架通过张量训练（TT）指导的元学习，显著提高了变分量子计算（VQC）的鲁棒性和可扩展性，为在近期量子设备上实现实用和可扩展的 VQC 提供了原则性途径。

Abstract: Variational Quantum Computing (VQC) faces fundamental barriers in
scalability, primarily due to barren plateaus and quantum noise sensitivity. To
address these challenges, we introduce TensoMeta-VQC, a novel tensor-train
(TT)-guided meta-learning framework designed to improve the robustness and
scalability of VQC significantly. Our framework fully delegates the generation
of quantum circuit parameters to a classical TT network, effectively decoupling
optimization from quantum hardware. This innovative parameterization mitigates
gradient vanishing, enhances noise resilience through structured low-rank
representations, and facilitates efficient gradient propagation. Based on
Neural Tangent Kernel and statistical learning theory, our rigorous theoretical
analyses establish strong guarantees on approximation capability, optimization
stability, and generalization performance. Extensive empirical results across
quantum dot classification, Max-Cut optimization, and molecular quantum
simulation tasks demonstrate that TensoMeta-VQC consistently achieves superior
performance and robust noise tolerance, establishing it as a principled pathway
toward practical and scalable VQC on near-term quantum devices.

</details>


### [829] [Quantum Algorithms for Gowers Norm Estimation, Polynomial Testing, and Arithmetic Progression Counting over Finite Abelian Groups](https://arxiv.org/abs/2508.01231)
*En-Jui Kuo*

Main category: quant-ph

TL;DR: 提出了量子算法来估计Gowers均匀性范数，并展示了其在测试多项式结构和计数算术级数中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了估计Gowers均匀性范数，并将其应用于测试多项式结构和计数算术级数。

Method: 提出了一系列用于估计有限阿贝尔群上Gowers均匀性范数的量子算法，并将其应用于测试多项式结构和计数算术级数。

Result: 在特定条件下，存在准多项式时间量子算法可以区分有界函数f(x)是d次相位多项式或远离任何此类结构。此外，还开发了一种用于估计布尔函数中3项算术级数数量的量子方法。

Conclusion: 我们的技术在某些量子噪声模型下仍然有效，并且Gowers范数可以作为量子属性测试、学习和伪随机性的强大工具。

Abstract: We propose a family of quantum algorithms for estimating Gowers uniformity
norms $ U^k $ over finite abelian groups and demonstrate their applications to
testing polynomial structure and counting arithmetic progressions. Building on
recent work for estimating the $ U^2 $-norm over $ \mathbb{F}_2^n $, we
generalize the construction to arbitrary finite fields and abelian groups for
higher values of $ k $. Our algorithms prepare quantum states encoding finite
differences and apply Fourier sampling to estimate uniformity norms, enabling
efficient detection of structural correlations.
  As a key application, we show that for certain degrees $ d = 4, 5, 6 $ and
under appropriate conditions on the underlying field, there exist
quasipolynomial-time quantum algorithms that distinguish whether a bounded
function $ f(x) $ is a degree-$ d $ phase polynomial or far from any such
structure. These algorithms leverage recent inverse theorems for Gowers norms,
together with amplitude estimation, to reveal higher-order algebraic
correlations.
  We also develop a quantum method for estimating the number of 3-term
arithmetic progressions in Boolean functions $ f : \mathbb{F}_p^n \to \{0,1\}
$, based on estimating the $ U^2 $-norm. Though not as query-efficient as
Grover-based counting, our approach provides a structure-sensitive alternative
aligned with additive combinatorics.
  Finally, we demonstrate that our techniques remain valid under certain
quantum noise models, due to the shift-invariance of Gowers norms. This enables
noise-resilient implementations within the NISQ regime and suggests that
Gowers-norm-based quantum algorithms may serve as robust primitives for quantum
property testing, learning, and pseudorandomness.

</details>


### [830] [In situ Al$_2$O$_3$ passivation of epitaxial tantalum and aluminum films enables long-term stability in superconducting microwave resonators](https://arxiv.org/abs/2508.01232)
*Yi-Ting Cheng,Hsien-Wen Wan,Wei-Jie Yan,Lawrence Boyu Young,Yen-Hsun Glen Lin,Kuan-Hui Lai,Wan-Sin Chen,Chao-Kai Cheng,Ko-Hsuan Mandy Chen,Tun-Wen Pi,Yen-Hsiang Lin,Jueinai Kwo,Minghwei Hong*

Main category: quant-ph

TL;DR: 通过使用外延钽和铝薄膜以及原位Al2O3钝化层，可以提高超导微波谐振器的长期稳定性，解决了量子技术中的一个关键材料问题。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展的量子技术，需要解决超导微波谐振器长期稳定性差的问，该问题源于表面和界面的持续退化。

Method: 通过制备外延钽和铝薄膜谐振器，并使用原位Al2O3进行超高真空下的钝化，来展示谐振器的稳定性。

Result: 外延钽和铝谐振器在经过长达十四个月的空气暴露后，仍能保持超过一百万的内禀品质因子（Qi），且性能下降极小。相比之下，依赖天然表面氧化物的器件的Qi随时间显著下降。

Conclusion: 研究表明，外延钽和铝薄膜以及原位沉积的Al2O3钝化层可以实现超导微波谐振器优异的长期稳定性，有效解决了长期存在的材料挑战。

Abstract: Long-term stability of superconducting microwave resonators is essential for
scalable quantum technologies; however, surface and interface degradation
continue to limit device stability. Here, we demonstrate exceptional stability
in microstrip resonators fabricated from epitaxial tantalum and aluminum films,
protected by in situ deposited Al$_2$O$_3$ under ultra-high vacuum. These
resonators initially exhibit internal quality factors (Qi) exceeding one
million and maintain high performance with minimal degradation after up to
fourteen months of air exposure. In contrast, devices relying on native surface
oxides show substantial declines in Qi over time, indicating increased
microwave losses. X-ray photoelectron spectroscopy reveals that the in situ
Al$_2$O$_3$ effectively suppresses interfacial oxidation and preserves the
chemical integrity of the underlying superconducting films, whereas native
oxides permit progressive oxidation, leading to device degradation. These
findings establish a robust, scalable passivation strategy that addresses a
longstanding materials challenge in the development of superconducting quantum
circuits.

</details>


### [831] [BVQC: A Backdoor-style Watermarking Scheme for Variational Quantum Circuits](https://arxiv.org/abs/2508.01893)
*Cheng Chu,Lei Jiang,Fan Chen*

Main category: quant-ph

TL;DR: BVQC是一种新的VQC水印技术，解决了现有方法的缺点，更安全、更有效。


<details>
  <summary>Details</summary>
Motivation: 现有量子电路水印技术存在易被重新编译移除和显著增加任务损耗的问题。

Method: BVQC采用后门水印技术，通过在提取水印时故意提高损耗，并结合分组算法来最小化水印任务与基础任务的干扰，以在保留原始损耗和确保基础任务准确性的同时实现水印嵌入和提取。

Result: BVQC将PPA改变减少了9.89e-3，GTD减少了0.089，相比现有技术表现出更好的性能。

Conclusion: BVQC是一种用于变分量子电路（VQC）的后门水印技术，解决了现有技术易被移除和增加任务损耗的问题。它通过在提取水印时故意增加损耗，并使用分组算法最小化水印任务与基础任务的干扰，来保留原始损耗并确保基础任务的最佳准确性。BVQC能抵抗重新编译，并且在PPA和GTD方面优于现有技术。

Abstract: Variational Quantum Circuits (VQCs) have emerged as a powerful quantum
computing paradigm, demonstrating a scaling advantage for problems intractable
for classical computation. As VQCs require substantial resources and
specialized expertise for their design, they represent significant intellectual
properties (IPs). However, existing quantum circuit watermarking techniques
suffer from two primary drawbacks: (1) watermarks can be removed during
re-compilation of the circuits, and (2) these methods significantly increase
task loss due to the extensive length of the inserted watermarks across
multiple compilation stages. To address these challenges, we propose BVQC, a
backdoor-based watermarking technique for VQCs that preserves the original loss
in typical execution settings, while deliberately increasing the loss to a
predefined level during watermark extraction. Additionally, BVQC employs a
grouping algorithm to minimize the watermark task's interference with the base
task, ensuring optimal accuracy for the base task. BVQC retains the original
compilation workflow, ensuring robustness against re-compilation. Our
evaluations show that BVQC greatly reduces Probabilistic Proof of Authorship
(PPA) changes by 9.89e-3 and ground truth distance (GTD) by 0.089 compared to
prior watermarking technologies.

</details>


### [832] [Unitary Gate Synthesis via Polynomial Optimization](https://arxiv.org/abs/2508.01356)
*Llorenç Balada Gaggioli,Denys I. Bondar,Jiri Vala,Roman Ovsiannikov,Jakub Mareček*

Main category: quant-ph

TL;DR: 量子计算门合成新方法：利用Magnus展开和多项式优化，无需近似即可全局优化，效率和可扩展性优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 量子最优控制在量子技术发展中起着至关重要的作用，特别是在设计和实现量子计算的快速精确门方面。

Method: 提出一种使用Magnus展开来合成量子门的方法，并将其表述为一个多项式优化问题，无需近似指数即可找到全局解。

Result: 该方法在保持高精度的同时，提高了计算效率，并且相比CRAB和GRAPE等现有方法有所改进。

Conclusion: 通过优化酉变换的生成矩阵，而不是酉变换本身，可以减小优化多项式的大小，从而比QCPOP方法更快收敛并具有更好的可扩展性。

Abstract: Quantum optimal control plays a crucial role in the development of quantum
technologies, particularly in the design and implementation of fast and
accurate gates for quantum computing. Here, we present a method to synthesize
gates using the Magnus expansion. In particular, we formulate a polynomial
optimization problem that allows us to find the global solution without
resorting to approximations of the exponential. The global method we use
provides a certificate of globality and lets us do single-shot optimization,
which implies it is generally faster than local methods. By optimizing over
Hermitian matrices generating the unitaries, instead of the unitaries
themselves, we can reduce the size of the polynomial to optimize, leading to
faster convergence and better scalability, compared to the QCPOP method.
Numerical experiments comparing our results with CRAB and GRAPE show that we
maintain high accuracy of QCPOP, while improving computational efficiency.

</details>


### [833] [Proof of quantum to classical transition for the center of mass of quantum many body systems](https://arxiv.org/abs/2508.01362)
*Marco Bilardello*

Main category: quant-ph

TL;DR: 量子力学的质心在特定条件下会表现出经典力学的行为，这在宏观系统（如固体和液体）中很常见。


<details>
  <summary>Details</summary>
Motivation: 研究量子力学的经典极限，特别是多体系统的质心行为。

Method: 通过研究量子力学描述的许多粒子的质心，在粒子数量趋于无穷大且满足特定条件下，质心可以被经典力学描述，具有明确的位置和动量，并遵循经典动力学定律。

Result: 在特定条件下，多体系统的质心可以由经典力学描述，其状态由位置和动量完全确定，动力学遵循经典定律。

Conclusion: 量子力学的经典极限可以通过研究多体系统的质心来获得，而无需修改量子力学、引入外部环境或改变其解释。

Abstract: The classical limit of quantum mechanics is investigated, by focusing on the
study of the center of mass of a many-body system where each particle is
described by quantum mechanics. We study how, in the limit when the number of
particles diverges and under quite general assumptions, the center of mass of
the system is not anymore described by quantum mechanics but by classical
mechanics: the center of mass of the system becomes with a well-defined
position and momentum, the state of the center of mass is fully determined by
its position and by its momentum, and its dynamics is given by the classical
law of dynamics. In order to get this result, three assumptions on the
many-body system are necessary: the total mass of the system must be much
larger than the mass of each particle composing the system; at most a finite
number of particles has non-zero correlation in position with an infinite
number of particles; finally, when the number of particles composing the system
diverge, the variance in position of each particle converges to a finite value.
These assumptions are commonly realized for a macroscopic solid and liquid
systems. Finally, we sketch a possible experimental setup aiming at observing
the quantum-to-classical transition of the center of mass of a massive
many-body system. The results obtained in this paper show how the classical
limit of quantum mechanics can be naturally achieved without the need to modify
quantum mechanics, without the need to have an external environment and without
the need of changing the interpretations of quantum mechanics.

</details>


### [834] [Entanglement in Elastic Electron Scattering: Perturbation theory misses fundamental aspects of Bragg scattering](https://arxiv.org/abs/2508.01383)
*Stefan Löffler,Peter Schattschneider*

Main category: quant-ph

TL;DR: Elastic electron scattering is usually treated classically, but this paper presents a quantum mechanical approach. It shows that the electron beam and the sample become entangled, affecting image quality. The paper also discusses when the classical approach is still valid.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of modeling samples as fixed, static potentials in elastic electron scattering and to incorporate the quantum nature of atoms.

Method: A quantum treatment of elastic electron scattering is presented, analyzing the entanglement between the probe beam and the sample, and investigating conditions for recovering conventional scattering theory.

Result: The study shows that the interaction between the probe beam and the sample leads to entanglement, which has significant consequences for coherence and image contrast, with a specific discussion on decoherence in Bragg scattering on nanoparticles.

Conclusion: The quantum treatment of elastic electron scattering reveals entanglement between the probe beam and the sample, impacting coherence and image contrast, and provides conditions for recovering conventional scattering theory.

Abstract: Elastic electron scattering is one of the primary means of investigating
materials on the atomic scale. It is usually described by modeling the sample
as a fixed, static, perturbative potential, thereby completely neglecting the
quantum nature of the atoms inside. In this work, we present a quantum
treatment of elastic electron scattering. We show that the interaction of the
probe beam and the sample results in entanglement between the two systems,
which can have far-reaching consequences, particularly on coherence and image
contrast. As a timely example, we discuss decoherence in Bragg scattering on
nanoparticles. We also investigate under which conditions the conventional
scattering theory is recovered.

</details>


### [835] [Enhanced Gravity-Induced Entanglement via Squeezed Input Light under Finite Measurement Time](https://arxiv.org/abs/2508.01397)
*Kosei Hatakeyama,Daisuke Miki,Yamamoto Kazuhiro*

Main category: quant-ph

TL;DR: 光力系统中的压缩输入光线可以增强 GIE 的可检测性。


<details>
  <summary>Details</summary>
Motivation: 基于 [1] 的研究结果，该研究证明了在量子控制下的光力系统检测 GIE 的可行性，我们进一步证明压缩输入光线可以减少机械条件状态中的光学噪声并增强 GIE。

Method: 基于傅里叶域分析，研究了在产生由引力引起的纠缠 (GIE) 中使用压缩输入光线的优势。

Result: 基于 GIE 检测中的信噪比 (SNR) 进行误差估计，我们发现，在使用压缩输入光线时，需要 10^6 秒的总测量时间才能实现 SNR=1，而在未使用压缩输入光线时，则需要 10^{6.8} 秒。

Conclusion: 与未使用压缩输入光相比，使用压缩输入光可以减少机械条件状态中的光学噪声并增强 GIE。

Abstract: We investigate the advantage of using squeezed input light for generating
gravity-induced entanglement (GIE) through Fourier-domain analysis. Based on
the findings of [1], which demonstrated the feasibility of detecting GIE in
optomechanical systems under quantum control, we further demonstrate that
squeezed input light can reduce the optical noise in the mechanical conditional
state and enhance GIE. Furthermore, we estimate the systematic and statistical
errors in the measurement of GIE using the Fourier transformation over a finite
measurement time. Based on the error estimations using the signal-to-noise
ratio (SNR) in GIE detection, we find that a total measurement time of 10^6 s
is required to achieve SNR=1 when using squeezed input light, whereas 10^{6.8}
s is needed without squeezed input light. This result highlights the
effectiveness of optomechanical systems and the critical role of squeezed input
light in enhancing the detectability of GIE.

</details>


### [836] [A Causal Model of the Hydrogen Atom -- New Electron Orbits](https://arxiv.org/abs/2508.01431)
*P. N. Kaloyerou,M. Chiboli,M. Mukutulu*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this article we develop in detail a causal model of the hydrogen atom,
building on the earlier work of Dewdney and Malik [1] in which they outlined a
causal model of the hydrogen atom, focusing more on a causal model of angular
momentum measurement and of the EPR experiment. We interpret the resulting
formulae differently leading to new electron orbits. We develop in detail the
relationship between electron orbits, angular momentum and the quantum
potential.

</details>


### [837] [Quantum Sensing with Bright Two-Mode Squeezed Light in a Distributed Network of Gyroscopes](https://arxiv.org/abs/2508.01447)
*Priyanka M. Kannath,Girish S. Agarwal,Ashok Kumar*

Main category: quant-ph

TL;DR: 该研究提出了一种分布式量子传感方案，结合亮二模压缩态（bTMSS）和光学陀螺，通过利用连续变量纠缠来提高角速度测量的精度，并在模拟的损耗条件下实现了优于散弹噪声极限的灵敏度。


<details>
  <summary>Details</summary>
Motivation: 为了提高光学传感系统的精度，并探索分布式量子传感（DQS）与光学陀螺的结合，以提高角速度估计精度。

Method: 利用多模纠缠亮二模压缩态（bTMSS）的连续变量纠缠，通过估计跨越多个分布式光陀荏的全局相位偏移来提高角速度估计精度，并分析了不同bTMSS配置（包括M模纠缠bTMSS和可分离M-bTMSS）的相位灵敏度，通过量子克拉美-Rao界评估其性能。

Result: 在5%的信道损耗和9.8 dB的初始压缩下，该方案比散弹噪声极限提高了约9.3 dB的灵敏度。

Conclusion: 该方案利用多模纠缠亮二模压缩态（bTMSS）的连续变量纠缠，通过估计跨越多个分布式光陀螺的全局相位偏移来提高角速度估计精度。

Abstract: Recent developments in quantum technologies have enabled significant
improvements in the precision of optical sensing systems. This work explores
the integration of distributed quantum sensing (DQS) with optical gyroscopes to
improve the estimation accuracy of angular velocity. Utilizing bright two-mode
squeezed states (bTMSS), which offer high photon numbers and strong bipartite
quantum correlations, we propose a novel configuration that leverages
continuous-variable entanglement across multiple spatially separated optical
gyroscopes. Unlike traditional quantum sensing that enhances a single sensor,
our approach focuses on estimating a global phase shift corresponding to the
average angular rotation across distributed optical gyroscopes with
quantum-enhanced sensitivity. We analyze the phase sensitivities of different
bTMSS configurations, including M mode-entangled bTMSS and separable M-bTMSS,
and evaluate their performance through the quantum Cram\'er-Rao bound. The
analysis shows that, with 5% photon loss in every channel in the system, the
proposed scheme shows a sensitivity enhancement of ~9.3 dB beyond the
shot-noise limit, with an initial squeezing of ~9.8 dB. The present scheme has
potential applications in quantum-enhanced inertial navigation and precision
metrology within emerging quantum networks.

</details>


### [838] [A machine learning approach to tomographic pattern generation and classification of quantum states of light](https://arxiv.org/abs/2508.01461)
*Soumyabrata Paul,H. S. Subramania,S. Ramanan,V. Balakrishnan,S. Lakshmibala*

Main category: quant-ph

TL;DR: Machine learning (WGAN + CNNs) generates optical tomograms for quantum states, enabling direct characterization and bypassing complex reconstruction. 


<details>
  <summary>Details</summary>
Motivation: To develop a machine learning-based method for generating optical tomograms that allows for direct characterization of quantum states of light, serving as an alternative to complex state reconstruction methods. The goal was to leverage WGAN and convolutional neural networks to accurately reproduce tomograms and extract relevant quantum information.

Method: A deep-learning framework utilizing two convolutional neural networks and the Wasserstein generative adversarial network (WGAN) algorithm was employed to train a machine to generate optical tomograms. The training focused on comparing patterns corresponding to input and generated tomograms until the Wasserstein distance stabilized. Properties such as mean photon number, variances, and higher moments were extracted directly from the generated tomograms for state characterization without an additional classifier.

Result: The trained machine successfully generated tomograms for Fock states, coherent states, and single photon added coherent states. Direct extraction of statistical properties from these tomograms allowed for distinguishing between different Fock states and between coherent states and single photon added coherent states without a separate classifier. The method's robustness was confirmed, and the generated tomograms reflected experimental trends for amplified coherent states and single photon added coherent states.

Conclusion: The study demonstrates the use of machine learning (specifically a deep-learning framework with two convolutional neural networks and WGAN) to generate optical tomograms for characterizing quantum states of light (Fock states, coherent states, and single photon added coherent states). This tomographic approach offers a viable alternative to detailed state reconstruction, as it allows for direct characterization of states by extracting properties like mean photon number and variances from generated tomograms. The results were validated using error models and different colormaps, and shown to align with experimental trends.

Abstract: Optical tomograms can be envisaged as patterns. The Wasserstein generative
adversarial network (WGAN) algorithm provides a platform to train the machine
to compare patterns corresponding to input and generated tomograms. Using a
deep-learning framework with two convolutional neural networks and WGAN, we
have trained the machine to generate tomograms of Fock states, coherent states
(CS) and the single photon added CS ($1$-PACS). The training process was
continued until the Wasserstein distance between the input and output
tomographic patterns levelled off at a low value. The mean photon number,
variances and higher moments were extracted directly from the generated
tomograms, to distinguish between different Fock states and also between the CS
and the $1$-PACS, without using an additional classifier neural network. The
robustness of our results has been verified using two error models and also
with different colormaps that define the tomographic patterns. We have examined
if the training program successfully reflected some of the findings in a recent
experiment in which state reconstruction was carried out to establish that the
fidelities between an amplified CS, an optimal CS and a $1$-PACS were close to
unity, over a range of parameter values. By training the machine to reproduce
tomograms corresponding to these specific states, and comparing the mean photon
numbers of these states obtained directly from the tomograms, we have
established that the variations in these observables reflect the experimental
trends. State reconstruction from tomograms could be challenging, in general,
since the Hilbert space associated with quantized light is large. The
tomographic approach provides a viable alternative to detailed state
reconstruction. Our work demonstrates the use of machine learning to generate
optical tomograms from which the states can be directly characterized.

</details>


### [839] [Quasi-Clifford to qubit mappings](https://arxiv.org/abs/2508.01470)
*Felix Huber*

Main category: quant-ph

TL;DR: A new mapping from quasi-Clifford algebras to Pauli algebras is introduced, with applications in quantum information, computation, and simplifying matrix group structures like Pauli groups and Majorana operators.


<details>
  <summary>Details</summary>
Motivation: Quasi-Clifford algebras (QCA) capture the (anti-)commutativity structure widespread in quantum mechanics.

Method: A mapping from quasi-Clifford algebras (QCA) to Pauli algebras is presented.

Result: The mapping allows for the Wedderburn decomposition of matrix groups with quasi-Clifford structure, leading to block-diagonalization for Pauli groups and recovering the Jordan-Wigner transform for Majorana operators. Potential applications include symmetry reduction of semidefinite programs and construction of maximal anti-commuting subsets.

Conclusion: The mapping from QCA to Pauli algebras provides a Wedderburn decomposition of matrix groups with quasi-Clifford structure, enabling block-diagonalization for Pauli groups and recovering the Jordan-Wigner transform for Majorana operators. Applications in symmetry reduction of semidefinite programs and constructing maximal anti-commuting subsets are also discussed.

Abstract: Algebras with given (anti-)commutativity structure are widespread in quantum
mechanics. This structure is captured by quasi-Clifford algebras (QCA): a QCA
generated by $\alpha_1, \dots, \alpha_n$ is is given by the relations
$\alpha_i^2 = k_i$ and $\alpha_j \alpha_i = (-1)^{\chi_{ij}} \alpha_i
\alpha_j$, where $k_i \in \mathbb{C}$ and $\chi_{ij} \in \{0, 1\}$. We present
a mapping from QCA to Pauli algebras and discuss its use in quantum information
and computation. The mapping also provides a Wedderburn decomposition of matrix
groups with quasi-Clifford structure. This provides a block-diagonalization for
e.g. Pauli groups, while for Majorana operators the Jordan-Wigner transform is
recovered. Applications to the symmetry reduction of semidefinite programs and
for constructing maximal anti-commuting subsets are discussed.

</details>


### [840] [Homology, Hopf Algebras and Quantum Code Surgery](https://arxiv.org/abs/2508.01496)
*Alexander Cowtan*

Main category: quant-ph

TL;DR: 本论文研究了量子纠错码的代数方面，包括容错量子计算协议和新方法，并探讨了晶格手术的概念。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在从代数角度深入研究量子纠错码及其相关的逻辑量子计算协议，并探索新的容错量子计算方法。

Method: 本论文研究了量子纠错码，特别是从代数和范畴论的角度，推导了新的容错量子计算方法，并推广和形式化了已有的量子码构造。

Result: 推导了新的容错量子计算方法，推广了量子码的已知构造并严格形式化了现有构造。

Conclusion: 本论文从代数角度研究了量子纠错码及其进行逻辑量子计算的协议，并推导了根植于抽象代数和范畴论的新的容错量子计算方法，同时推广了量子码的已知构造并严格形式化了现有构造。

Abstract: This thesis is a study of quantum error-correction codes from an algebraic
perspective. We concern ourselves not only with quantum codes but also
protocols to perform logical quantum computation using such codes. We derive
new methods of performing fault-tolerant quantum computation, rooted in
abstract algebra and category theory. We also generalise known constructions of
quantum codes and rigorously formalise existing constructions.
  At its core, this thesis asks: what is lattice surgery?

</details>


### [841] [RinQ: Predicting central sites in proteins on current quantum computers](https://arxiv.org/abs/2508.01501)
*Shah Ishmam Mohtashim*

Main category: quant-ph

TL;DR: RinQ是一个量子-经典框架，通过将蛋白质建模为残基相互作用网络并使用QUBO解决中心性检测问题，来识别蛋白质中的关键残基。


<details>
  <summary>Details</summary>
Motivation: 为了识别蛋白质中的功能性关键残基，我们引入了RinQ，一个结合了量子优化技术的混合量子-经典框架。

Method: RinQ框架将蛋白质结构建模为残基相互作用网络（RINs），并将中心性检测任务转化为使用D-Wave的模拟退火技术解决的二次无约束二元优化（QUBO）问题。

Result: RinQ在各种蛋白质（包括小肽和具有生物学意义的调节蛋白）上进行测试，其识别出的关键残基与经典的中心性基准高度一致。

Conclusion: RinQ在蛋白质网络分析中展现了其准确性和可靠性，并且有潜力利用近期的量子和量子启发方法来处理更大的系统。

Abstract: We introduce RinQ, a hybrid quantum-classical framework for identifying
functionally critical residues in proteins, utilizing techniques in quantum
optimization. To that end, protein structures are modeled as residue
interaction networks (RINs), and the centrality detection task is cast as a
Quadratic Unconstrained Binary Optimization (QUBO) problem. Solved using
D-Wave's simulated annealing, this approach is applied to a diverse set of
proteins, including small peptides and biologically significant regulatory
proteins. RinQ consistently finds residues that align with classical centrality
benchmarks, underscoring the accuracy and reliability of the approach. This
work highlights the promise of near-term quantum and quantum-inspired methods
for advancing protein network analysis and lays the groundwork for future
extensions to larger systems using real quantum hardware.

</details>


### [842] [Theory of quantum comb enhanced interferometry](https://arxiv.org/abs/2508.01513)
*Haowei Shi,Quntao Zhuang*

Main category: quant-ph

TL;DR: Quantum combs with squeezed/entangled states offer scalable quantum advantages in sensing, with some protocols showing unique loss-robustness compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: To overcome the standard quantum limit in sensing applications by engineering quantum fluctuations using quantum combs (squeezed and entangled).

Method: Develops the theory for designing and analyzing quantum combs, focusing on dual-comb interferometric measurement and considering both squeezed and entangled quantum combs with division and heterodyne receivers.

Result: Identifies four protocols with scalable quantum advantages. Three of these protocols exhibit robustness to loss in spectroscopy of a single absorption line, a characteristic not found in traditional quantum sensing.

Conclusion: The study proposes four protocols for quantum combs (squeezed and entangled) with division and heterodyne receivers, demonstrating scalable quantum advantages. Notably, three protocols show robustness to loss, a feature absent in traditional quantum sensing.

Abstract: Optical frequency combs, named for their comb-like peaks in the spectrum, are
essential for various sensing applications. As the technology develops, its
performance has reached the standard quantum limit dictated by the quantum
fluctuations of coherent light field. Quantum combs, with their quantum
fluctuation engineered via squeezing and entanglement, are the necessary
ingredient for overcoming such limits. We develop the theory for designing and
analyzing quantum combs, focusing on dual-comb interferometric measurement. Our
analyses cover both squeezed and entangled quantum combs with division
receivers and heterodyne receivers, leading to four protocols with quantum
advantages scalable with squeezing/entanglement strength. In the spectroscopy
of a single absorption line, whereas the division receiver with the squeezed
comb suffers from amplified thermal noise, the other three protocols
demonstrate a surprising robustness to loss at a few comb lines. Such a unique
loss-robustness of a scalable quantum advantage has not been found in any
traditional quantum sensing protocols.

</details>


### [843] [Hybrid quantum-classical framework for Betti number estimation with applications to topological data analysis](https://arxiv.org/abs/2508.01516)
*Nhat A. Nghiem,Junseo Lee,Tzu-Chieh Wei*

Main category: quant-ph

TL;DR: 使用经典和量子计算的组合来更有效地计算拓扑数据分析中的贝蒂数。


<details>
  <summary>Details</summary>
Motivation: 为了比现有量子方法更有效地估计单纯形复形的贝蒂数，并展示归一化贝蒂数在实际应用中的效用。

Method: 提出了一种混合量子-经典算法，其中经典组件枚举所有单纯形，然后量子算法处理此组合结构以估计贝蒂数。

Result: 该算法在特定条件下可能比现有量子方法提供多项式到指数级的加速，但需要更多的辅助量子比特。

Conclusion: 该研究提出了一种混合量子-经典算法，用于比现有量子方法更有效地估计单纯形复形的贝蒂数，并展示了归一化贝蒂数在实际应用中的效用。

Abstract: Topological data analysis (TDA) is a rapidly growing area that applies
techniques from algebraic topology to extract robust features from large-scale
data. A key task in TDA is the estimation of (normalized) Betti numbers, which
capture essential topological invariants. While recent work has led to quantum
algorithms for this problem, we explore an alternative direction: combining
classical and quantum resources to estimate the Betti numbers of a simplicial
complex more efficiently. Assuming the classical description of a simplicial
complex, that is, its set of vertices and edges, we propose a hybrid
quantum-classical algorithm. The classical component enumerates all simplices,
and this combinatorial structure is subsequently processed by a quantum
algorithm to estimate the Betti numbers. We analyze the performance of our
approach and identify regimes where it potentially achieves polynomial to
exponential speedups over existing quantum methods, at the trade-off of using
more ancilla qubits. We further demonstrate the utility of normalized Betti
numbers in concrete applications, highlighting the broader potential of hybrid
quantum algorithms in topological data analysis.

</details>


### [844] [Microscopic analysis of above-threshold ionization driven by squeezed light](https://arxiv.org/abs/2508.01621)
*J. Rivera-Dean,P. Stammer,C. Figueira de Morisson Faria,M. Lewenstein*

Main category: quant-ph

TL;DR: Using a quantum optical theory, this paper shows that squeezed light in above-threshold ionization (ATI) strongly boosts light-matter interactions, altering electron ionization times and creating entanglement between electrons and light. These effects are visible in the light field itself, displaying non-Gaussian traits based on squeezing intensity and how many electrons get ionized.


<details>
  <summary>Details</summary>
Motivation: The work is motivated by the recent development of non-classical light sources for strong-field phenomena and the interest in their effect on electron dynamics during ATI, contrasting with the well-understood dynamics under classical light.

Method: A microscopic quantum optical theory is developed to describe above-threshold ionization (ATI) under the influence of strong squeezed light.

Result: Squeezed light enhances light-matter coupling, making mutual backaction more significant. This backaction impacts ionization times and non-classical properties of the joint electron-light state, resulting in pronounced entanglement features. These features are observable in the quantum optical state of the driving field, showing non-Gaussian properties influenced by the degree of squeezing and the number of ionization events.

Conclusion: The study reveals that squeezed light significantly enhances light-matter coupling in ATI, leading to profound impacts on electronic ionization times and joint electron-light states, with pronounced entanglement features reflected in the quantum optical state of the driving field, exhibiting non-Gaussian characteristics dependent on squeezing and ionization events.

Abstract: Above-threshold ionization (ATI) is a strong-field-driven process where
electrons absorb more photons than required for ionization. While ATI dynamics
and outputs are well-understood when driven by classical, perfectly coherent
light, the recent development of non-classical light sources for strong-field
phenomena has spurred interest in their effect on the involved electron
dynamics. In this work, we present a microscopic quantum optical theory
describing ATI under the influence of strong squeezed light. We observe that
squeezed light significantly enhances the coupling between light and matter,
making their mutual backaction more important than under classical driving.
This backaction profoundly impacts the electronic ionization times, as well as
the non-classical properties of the joint electron-light state. This results in
pronounced entanglement features, both immediately after ionization, and at
later times. These entanglement features are reflected in the properties of the
quantum optical state of the driving field revealing notable non-Gaussian
features that depend on both, the amount of squeezing, and the number of
ionization events occurring during the interaction.

</details>


### [845] [Bimodal phase transition in a periodically modulated $Λ$-type three-level system](https://arxiv.org/abs/2508.01626)
*Sanjoy Mishra,Shraddha Sharma,Amit Rai,Pitamber Mahanandia*

Main category: quant-ph

TL;DR: 本文研究了驱动的三能级杰恩斯-康明斯模型中的量子相变，并提出了一种通过调整参数来控制这些相变的方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在理论研究一个嵌入在双模腔中的周期驱动的$\\(Lambda)$-型三能级系统（3LS）的动力学量子相变（QPT）。

Method: 我们首先在缀饰态基中探测未驱动的静态哈密顿量，以识别和定义与两个腔模式相关的不同耦合机制和临界点。然后，为了研究该系统中的动力学量子相变，我们在三个可用能级中的两个原子态（标记为$|3\rangle_{at}$和$|2\rangle_{at}$）之间引入了周期性调制。通过执行必要的变换和近似，我们将包含静态和动态调制项的整体哈密顿量简化为等效的3L-JC哈密顿量，其系统参数取决于驱动参数。我们使用与近似前后的哈密顿量的时间演化态的洛施密特回波来验证我们近似的有效性。

Result: 我们证明了通过调整调制参数，可以在三能级$\\(Lambda)$-型系统内探索双模超辐射相，同时保持在静态哈密顿量的临界耦合极限内。

Conclusion: 通过调整调制参数，可以在三能级$\\(Lambda)$-型系统内探索双模超辐射相，同时保持在静态哈密顿量的临界耦合极限内。我们的结果为在有效扩展的杰恩斯-康明斯体制内操纵三能级系统中的量子相提供了见解。

Abstract: We present a theoretical investigation of dynamical quantum phase transitions
(QPTs) in a periodically driven $\Lambda$-type three-level system (3LS)
embedded in a double-mode cavity, described by a three-level Jaynes-Cumming
(3L-JC) Hamiltonian. To begin with, we probe the undriven static Hamiltonian in
the dressed-state basis to identify and define distinct coupling regimes and
critical points associated with both cavity modes. Furthermore, to investigate
the dynamical QPTs in this system, we incorporate a periodic modulation across
two atomic states (denoted by $|3\rangle_{at}$ and $|2\rangle_{at}$) out of the
three available energy levels. By performing necessary transformations and
approximations, we reduce the overall Hamiltonian, which contains static and
dynamic modulation terms, into an effective 3L-JC Hamiltonian whose system
parameters are dependent on the driving parameters. The validity of our
approximations is verified using the Loschmidt echo of time-evolved states
corresponding to Hamiltonians before and after the approximations. Finally, we
demonstrate that by tuning the modulation parameters, it is possible to explore
bimodal superradiant phases in a three-level $\Lambda$-type system while
remaining within the critical coupling limits of the static Hamiltonian. Our
results provide an insight into the manipulation of quantum phases in a
three-level system within an effective extended Jaynes-Cummings regime.

</details>


### [846] [Hamiltonian simulation for nonlinear partial differential equation by Schrödingerization](https://arxiv.org/abs/2508.01640)
*Shoya Sasaki,Katsuhiro Endo,Mayu Muramatsu*

Main category: quant-ph

TL;DR: 提出了一种名为 CLS 的新方法，用于通过哈密顿模拟求解非线性 PDE。该方法将非线性 PDE 转化为线性方程，然后映射到 Schrödinger 方程进行求解。


<details>
  <summary>Details</summary>
Motivation: 探索哈密顿模拟在非线性物理系统中的潜力，并提出一种适用于非线性偏微分方程（PDE）的哈密顿模拟方法。

Method: Carleman 线性化 + Schrödingerization (CLS)，结合了 Carleman 线性化 (CL) 和扭曲相位变换 (WPT)，首先将非线性 PDE 转化为线性微分方程，然后通过 WPT 映射到 Schrödinger 方程。

Result: 成功将非线性反应扩散方程转化为 Schrödinger 方程，并通过哈密顿模拟进行了求解，证明了该方法在非线性 PDE 上的有效性。

Conclusion: 该研究提出了一种名为 Carleman 线性化 + Schrödingerization (CLS) 的新方法，用于模拟非线性偏微分方程（PDE）。该方法结合了 Carleman 线性化 (CL) 和扭曲相位变换 (WPT)，首先将非线性 PDE 转化为线性微分方程，然后通过 WPT 映射到 Schrödinger 方程。通过模拟此 Schrödinger 方程，可以有效地求解原始的非线性 PDE。该方法已成功应用于非线性反应扩散方程，证明了其在非线性 PDE 上的适用性。

Abstract: Hamiltonian simulation is a fundamental algorithm in quantum computing that
has attracted considerable interest owing to its potential to efficiently solve
the governing equations of large-scale classical systems. Exponential speedup
through Hamiltonian simulation has been rigorously demonstrated in the case of
coupled harmonic oscillators. The question arises as to whether Hamiltonian
simulations in other physical systems also accelerate exponentially.
Schr\"odingerization is a technique that transforms the governing equations of
classical systems into the Schr\"odinger equation. However, since the
Schr\"odinger equation is a linear equation, Hamiltonian simulation is often
limited to linear equations. The research on Hamiltonian simulation methods for
nonlinear governing equations remains relatively limited. In this study, we
propose a Hamiltonian simulation method for nonlinear partial differential
equations (PDEs). The proposed method is named Carleman linearization +
Schr\"odingerization (CLS), which combines Carleman linearization (CL) and
warped phase transformation (WPT). CL is first applied to transform a nonlinear
PDE into a linear differential equation. This linearized equation is then
mapped to the Schr\"odinger equation via WPT. The original nonlinear PDE can be
solved efficiently by the Hamiltonian simulation of the resulting Schr\"odinger
equation. By applying this method, we transform the original governing equation
into the Schr\"odinger equation. Solving the transformed Schr\"odinger equation
then enables the analysis of the original nonlinear equation. As a specific
application, we apply this method to the nonlinear reaction--diffusion equation
to demonstrate that Hamiltonian simulations are applicable to nonlinear PDEs.

</details>


### [847] [First Experience with Real-Time Control Using Simulated VQC-Based Quantum Policies](https://arxiv.org/abs/2508.01690)
*Yize Sun,Mohamad Hagog,Marc Weber,Daniel Hein,Steffen Udluft,Volker Tresp,Yunpu Ma*

Main category: quant-ph

TL;DR: 本研究探索了将量子计算应用于倒立摆的离线强化学习和实时控制。研究表明，量子策略能够成功平衡倒立摆，但云端量子计算的延迟限制了其在实时控制中的应用。


<details>
  <summary>Details</summary>
Motivation: 旨在评估将量子架构应用于实际工业控制问题的潜力。

Method: 本研究集成了量子计算和离线强化学习，并使用变分量子电路（VQC）作为策略网络。采用了经典模型驱动的离线策略搜索方法。

Result: 实验结果表明，所提出的模型驱动的离线策略搜索方法能够生成可行的量子策略，用于控制硬件倒立摆。然而，延迟分析表明，虽然本地模拟执行满足实时要求，但云端量子处理的延迟过高，不适合闭环控制。

Conclusion: 该研究成功生成了可用于平衡硬件倒立摆的量子策略，但基于云的量子计算由于延迟问题，不适用于实时闭环控制。

Abstract: This paper investigates the integration of quantum computing into offline
reinforcement learning and the deployment of the resulting quantum policy in a
real-time control hardware realization of the cart-pole system. Variational
Quantum Circuits (VQCs) are used to represent the policy. Classical model-based
offline policy search was applied, in which a pure VQC with trainable
input-output weights is used as a policy network instead of a classical
multilayer perceptron. The goal is to evaluate the potential of deploying
quantum architectures in real-world industrial control problems. The
experimental results show that the investigated model-based offline policy
search is able to generate quantum policies that can balance the hardware
cart-pole. A latency analysis reveals that while local simulated execution
meets real-time requirements, cloud-based quantum processing remains too slow
for closed-loop control.

</details>


### [848] [Orbital angular momentum of entangled photons as a probe for relativistic effects](https://arxiv.org/abs/2508.01716)
*Fazilah Nothlawala,Kiki Dekkers,Moslem Mahdavifar,Jonathan Leach,Andrew Forbes,Isaac Nape*

Main category: quant-ph

TL;DR: 利用光OAM在相对论效应下频谱会发生变化这一原理，通过测量OAM谱的展宽来推断物体运动的洛伦兹因子。


<details>
  <summary>Details</summary>
Motivation: 为了将OAM（轨道角动量）在信息传输和精密测量中的应用扩展到相对论场景，并探索OAM结构光在极端条件下的应用潜力。

Method: 利用纠缠态的OAM关联，通过分析其联合OAM谱受长度收缩引起的修改（OAM模式的重构改变了其正交性）来推断洛伦兹因子。

Result: 在模拟实验中，该方法成功推断出高达0.99c的实验模拟速度对应的洛伦兹因子，并证实了OAM谱的展宽现象。

Conclusion: 该研究提出了一种利用光轨道角动量（OAM）在相对论场景下测量洛伦兹因子（长度收缩因子）的新方法，并进行了实验模拟验证。

Abstract: Orbital angular momentum (OAM) as both classical and quantum states of light
has proven essential in numerous applications, from high-capacity information
transfer to enhanced precision and accuracy in metrology. Here, we extend OAM
metrology to relativistic scenarios to determine the Lorentz factor of a moving
reference frame, exploiting the fact that OAM is not Lorentz invariant. Using
OAM correlations of entangled states, we show that their joint OAM spectrum is
modified by length contraction, where the rescaling of spatial dimensions
alters the orthogonality of the OAM modes themselves. In an emulated
experiment, we confirm the predicted broadening of the OAM spectrum and use
this to quantitatively infer the Lorentz (contraction) factor, reaching
experimentally simulated velocities of up to 0.99c. Our work provides a pathway
for novel measurement techniques suitable for relativistic conditions that
leverages OAM structured light as a resource.

</details>


### [849] [Quantum Optimal Control for Coherent Spin Dynamics of Radical Pairs via Pontryagin Maximum Principle](https://arxiv.org/abs/2508.01806)
*Ugur G. Abdulla,Jose H. Rodrigues,Jean-Jacques Slotine*

Main category: quant-ph

TL;DR: 本研究提出了一种新的迭代庞特里亚金最大值原理（IPMP）方法，通过优化外部电磁场来最大化生化反应中的三线态-单线态产率，从而驱动自旋动力学到量子相干态。研究结果为量子生物学现象（如磁感应）的实验研究提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过最大化生化反应中三线态-单线态产率，来设计外部电磁场以驱动自旋动力学到量子相干态。

Method: 提出了一种控制问题，通过滤波方程将薛定谔系统与控制场耦合，并证明了希尔伯特空间中的弗雷歇可微性和庞特里亚金最大值原理，确定了最优控制的bang-bang结构。开发了一种新的迭代庞特里亚金最大值原理（IPMP）方法来识别bang-bang最优控制，并通过数值模拟证明了其收敛性、稳定性和正则化效应。

Result: 通过IPMP和梯度投影法（GPM）的数值模拟，证明了收敛性、稳定性和正则化效应。与未使用滤波的bang-bang最优场相比，滤波后的最优电磁场使单线态产率最大值变化小于1%。

Conclusion: 本研究旨在通过最大化生化反应中三线态-单线态产率，来设计外部电磁场以驱动自旋动力学到量子相干态。研究结果为潜在的磁感应实验工作开辟了道路，这可以作为量子生物现象的表现。

Abstract: This paper aims at devising the shape of the external electromagnetic field
which drives the spin dynamics of radical pairs to quantum coherent state
through maximization of the triplet-singlet yield in biochemical reactions. The
model is a Schr\"{o}dinger system with spin Hamiltonians given by the sum of
Zeeman interaction and hyperfine coupling interaction terms. We introduce a
one-parameter family of optimal control problems by coupling the
Schr\"{o}dinger system to a control field through filtering equations for the
electromagnetic field. Fr\'echet differentiability and the Pontryagin Maximum
Principle in Hilbert space is proved, and the bang-bang structure of the
optimal control is established. A new iterative Pontryagin Maximum Principle
(IPMP) method for the identification of the bang-bang optimal control is
developed. Numerical simulations based on IPMP and the gradient projection
method (GPM) in Hilbert spaces are pursued, and the convergence, stability and
the regularization effect are demonstrated. Comparative analysis of filtering
with regular optimal electromagnetic field versus non-filtering with bang-bang
optimal field ({\it Abdulla et al, Quantum Sci. Technol., {\bf9}, 4, 2024})
demonstrates the change of the maxima of the singlet yield is less than 1\%.
The results open a venue for a potential experimental work for the
magnetoreception as a manifestation of quantum biological phenomena.

</details>


### [850] [Distributed fault-tolerant quantum memories over a 2xL array of qubit modules](https://arxiv.org/abs/2508.01879)
*Edwin Tham,Min Ye,Ilia Khait,John Gamble,Nicolas Delfosse*

Main category: quant-ph

TL;DR: 提出了一种分布式量子内存架构，利用循环移位和量子LDPC码（如BB码）进行量子纠错，并在模拟中取得了较低的逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 为了研究量子LDPC码在分布式环境下的性能以及探索新的量子纠错策略。

Method: 提出了一种分布式量子内存架构，该架构在2xL模块阵列上实现，并通过飞行量子实现循环移位。量子信息分布在L个模块的第一行，而第二行的辅助模块则利用循环移位执行量子纠错。

Result: 所提出的分布式BB码在物理错误率为10^-3时，逻辑错误率低于2*10^-6。

Conclusion: 本文证明了BB等量子LDPC码在仅使用单周期移位这一简单连接器的分布式环境中仍能保持其性能。

Abstract: We propose an architecture for a quantum memory distributed over a $2 \times
L$ array of modules equipped with a cyclic shift implemented via flying qubits.
The logical information is distributed across the first row of $L$ modules and
quantum error correction is executed using ancilla modules on the second row
equipped with a cyclic shift. This work proves that quantum LDPC codes such as
BB codes can maintain their performance in a distributed setting while using
solely one simple connector: a cyclic shift. We propose two strategies to
perform quantum error correction on a $2 \times L$ module array: (i) The cyclic
layout which applies to any stabilizer codes, whereas previous results for
qubit arrays are limited to CSS codes. (ii) The sparse cyclic layout, specific
to bivariate bicycle (BB) codes. For the $[[144,12,12]]$ BB code, using the
sparse cyclic layout we obtain a quantum memory with $12$ logical qubits
distributed over $12$ modules, containing $12$ physical qubits each. We propose
physical implementations of this architecture using flying qubits, that can be
faithfully transported, and include qubits encoded in ions, neutral atoms,
electrons or photons. We performed numerical simulations when modules are long
ion chains and when modules are single-qubit arrays of ions showing that the
distributed BB code achieves a logical error rate below $2 \cdot 10^{-6}$ when
the physical error rate is $10^{-3}$.

</details>


### [851] [Complexity of Bernstein--Vazirani algorithm in the presence of noise](https://arxiv.org/abs/2508.01884)
*Muhammad Faizan,Muhammad Faryad*

Main category: quant-ph

TL;DR: 该研究分析了 Bernstein-Vazirani 算法在去极化噪声下的鲁棒性，发现增加量子比特数量和错误率会降低成功率，并且在没有改进量子比特质量的情况下增加量子系统规模会导致量子优势的急剧下降。


<details>
  <summary>Details</summary>
Motivation: 我们解析地研究了 Bernstein-Vazirani 算法在存在去极化噪声时的鲁棒性。

Method: 使用密度矩阵形式主义，我们推导了算法成功概率作为去极化错误率 p 和量子比特数 n 的函数的精确表达式。

Result: 分析揭示了在实际噪声条件下，性能如何随着系统尺寸的增加而下降。

Conclusion: 增加量子系统规模而不同时提高量子比特质量会导致此算法的量子优势急剧下降。

Abstract: We analytically investigated the robustness of the Bernstein--Vazirani
algorithm in the presence of depolarizing noise using the density matrix
formalism. We derive exact expressions for the algorithm's success probability
as a function of the depolarizing error rate $\boldsymbol{p}$ and number of
qubits $\boldsymbol{n}$. The analysis reveals how performance degrades with
increasing system size under realistic noise conditions. Furthermore, it was
seen that scaling up quantum systems without simultaneously improving qubit
quality leads to a sharp decline in the quantum advantage for this algorithm.

</details>


### [852] [Zeeman Degenerate Sideband Cooling](https://arxiv.org/abs/2508.02026)
*Qin Qichen,Qi Zhao,M. D. K. Lee,Zhao Zhang,N. Jayjong,K. J. Arnold,M. D. Barrett*

Main category: quant-ph

TL;DR: 通过退化的Raman边带冷却技术，只需少量脉冲即可在$^{176}$Lu$^+$中实现接近基态的冷却。


<details>
  <summary>Details</summary>
Motivation: 为了减少冷却循环次数，实现更快速的基态冷却。

Method: 通过两光子Raman跃迁耦合固定的超精细能级中的相邻Zeeman能级，实现退化的Raman边带冷却。

Result: 在$^{176}$Lu$^+$中，通过耦合运动边带上F=7超精细能级中相邻的Zeeman能级，从平均声子数为6的热分布开始，在约10个脉冲内实现了接近基态的冷却。

Conclusion: 该方法通过耦合相邻的 Zeeman 能级，能够在单个循环中去除多个运动量子，从而大大减少了达到基态所需的冷却循环次数。

Abstract: We explore degenerate Raman sideband cooling in which neighboring Zeeman
states of a fixed hyperfine level are coupled via a two-photon Raman
transition. The degenerate coupling between $|F,m_F\rangle\rightarrow
|F,m_F-1\rangle$ facilitates the removal of multiple motional quanta in a
single cycle. This method greatly reduces the number of cooling cycles required
to reach the ground state compared to traditional sideband cooling. We show
that near ground state cooling can be achieved with a pulse number as low as
$\bar{n}$ where $\bar{n}$ is the average phonon number in the initial thermal
state. We demonstrate proof-of-concept in $^{176}\mathrm{Lu}^+$ by coupling
neighboring Zeeman levels on the motional sideband for the $F=7$ hyperfine
level in $^3D_1$. Starting from a thermal distribution with an average phonon
number of 6, we demonstrate near ground-state cooling with $\sim10$ pulses. A
theoretical description is given that applies to any $F$ level and demonstrates
how effective this approach can be.

</details>


### [853] [Strengthening the Uncertainty and the Reverse Uncertainty Relation Limits](https://arxiv.org/abs/2508.02036)
*M. Y. Abd-Rabbou,Cong-Feng Qiao*

Main category: quant-ph

TL;DR: 该研究利用Maligranda不等式和M. Kato等人的不等式，推导了更严格的不确定性关系，并将其扩展到多可观测量系统。


<details>
  <summary>Details</summary>
Motivation: 为了在不确定性关系领域提供更严格的界限，并扩展到多可观测量系统。

Method: 利用Maligranda不等式和M. Kato等人的一项不等式，推导了用于两个和多个不兼容可观测量的方差之和的不确定性关系和反不确定性关系，并考虑了测量状态的相位角来加强不等式。

Result: 推导了四种新颖的不确定性关系和反不确定性关系，这些关系比现有的几种关系提供了更严格的界限，并成功扩展到多可观测量系统。

Conclusion: 该研究推导了用于两个不兼容可观测量的方差之和的四种新颖不确定性关系和反不确定性关系，这些关系比现有的几种关系提供了更严格的界限，并通过三个说明性示例在两个可观测量的系统中证实了其有效性。

Abstract: Uncertainty relations are pivotal in delineating the limits of simultaneous
measurements for observables. In this paper, we derive four novel uncertainty
and reverse uncertainty relations for the sum of variances of two incompatible
observables, leveraging the mathematical framework of the Maligranda
inequality. These relations are shown to provide tighter bounds than several
well-known existing relations. Furthermore, we extend these results to
multi-observable scenarios by employing an inequality from M. Kato et al.,
deriving generalized uncertainty relations that similarly exhibit enhanced
precision. The incorporation of the phase angle of the measurement state
contributes to strengthening the derived inequalities. Comparative analyses
with prior studies confirm the effectiveness of our inequalities in
two-observable systems via three illustrative examples.

</details>


### [854] [Enhancement of Quantum Semi-Supervised Learning via Improved Laplacian and Poisson Methods](https://arxiv.org/abs/2508.02054)
*Hamed Gholipour,Farid Bozorgnia,Hamzeh Mohammadigheymasi,Kailash Hambarde,Javier Mancilla,Hugo Proenca,Joao Neves,Moharram Challenger*

Main category: quant-ph

TL;DR: 该论文提出了一种名为ILQSSL和IPQSSL的混合量子模型，用于在标记数据稀缺的情况下进行半监督学习。实验证明，与经典方法相比，这些量子模型在性能上更优越。同时，研究还探讨了量子电路深度和量子比特数对模型性能的影响，并为在实际应用中设计量子模型提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了在标记数据稀缺的情况下提高图基半监督学习的性能。

Method: 开发了一种混合量子方法，用于基于图的半监督学习，并提出两种增强的量子模型：改进的拉普拉斯量子半监督学习（ILQSSL）和改进的泊松量子半监督学习（IPQSSL）。这些模型将先进的标签传播策略融入变分量子电路，并使用QR分解将图结构直接嵌入量子态。

Result: ILQSSL和IPQSSL在标记数据有限的情况下，持续优于领先的经典半监督学习算法。研究还检查了量子电路深度和量子比特数量对学习质量的影响，发现适度的纠缠可以提高模型的泛化能力，但过大的电路复杂度可能会引入噪声，从而损害当前量子硬件上的性能。

Conclusion: 该研究强调了量子增强模型在半监督学习中的潜力，并提供了关于如何设计量子电路以平衡表达能力和稳定性的实用见解。这些发现支持了量子机器学习在推进数据高效分类方面的作用，尤其是在标签可用性和硬件限制的应用中。

Abstract: This paper develops a hybrid quantum approach for graph-based semi-supervised
learning to enhance performance in scenarios where labeled data is scarce. We
introduce two enhanced quantum models, the Improved Laplacian Quantum
Semi-Supervised Learning (ILQSSL) and the Improved Poisson Quantum
Semi-Supervised Learning (IPQSSL), that incorporate advanced label propagation
strategies within variational quantum circuits. These models utilize QR
decomposition to embed graph structure directly into quantum states, thereby
enabling more effective learning in low-label settings. We validate our methods
across four benchmark datasets like Iris, Wine, Heart Disease, and German
Credit Card -- and show that both ILQSSL and IPQSSL consistently outperform
leading classical semi-supervised learning algorithms, particularly under
limited supervision. Beyond standard performance metrics, we examine the effect
of circuit depth and qubit count on learning quality by analyzing entanglement
entropy and Randomized Benchmarking (RB). Our results suggest that while some
level of entanglement improves the model's ability to generalize, increased
circuit complexity may introduce noise that undermines performance on current
quantum hardware. Overall, the study highlights the potential of
quantum-enhanced models for semi-supervised learning, offering practical
insights into how quantum circuits can be designed to balance expressivity and
stability. These findings support the role of quantum machine learning in
advancing data-efficient classification, especially in applications constrained
by label availability and hardware limitations.

</details>


### [855] [Distributed quantum sensing with multi-mode $N00N$ states](https://arxiv.org/abs/2508.02070)
*Dong-Hyun Kim,Seongjin Hong,Yong-Su Kim,Kyunghwan Oh,Su-Yong Lee,Changhyoup Lee,Hyang-Tag Lim*

Main category: quant-ph

TL;DR: 该研究提出了一种利用多模N00N态进行分布式量子传感的新方法，该方法能够达到海森堡极限，并在实验中实现了灵敏度提升，为未来的量子传感网络发展提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 由于分布式量子传感（估计遥远节点间的全局参数）在量子成像、传感器网络和全球时钟同步等应用中具有重要意义，而多模N00N态在多参数估计中的优势尚未在分布式量子传感中得到应用，因此本研究旨在探索多模N00N态在分布式量子传感中的应用。

Method: 提出了一种利用四模2002态进行分布式量子传感的方案，通过理论分析（Cram'er-Rao界和量子Cram'er-Rao界）和实验演示，证明了多模N00N态可以达到海森堡极限，并实现了2.74 dB的灵敏度增强。

Result: 理论上，该方案能够达到海森堡极限。实验上，利用四模2002态估计两个空间分布式相位，实现了比标准量子极限高2.74 dB的灵敏度。

Conclusion: 该研究提出了一种利用多模N00N态进行分布式量子传感的方案，实现了海森堡极限，并为开发增强型传感网络提供了一种有前景的方法。

Abstract: Distributed quantum sensing, which estimates a global parameter across
distant nodes, has attracted significant interest for applications such as
quantum imaging, sensor networks, and global-scale clock synchronization.
$N00N$ states are regarded as one of the optimal quantum resources for quantum
metrology, enabling the Heisenberg scaling. Recently, the concept of $N00N$
states has been extended to multi-mode $N00N$ states for quantum-enhanced
multiple-parameter estimation. However, the application of multi-mode $N00N$
states in distributed quantum sensing remains unexplored. Here, we propose a
distributed quantum sensing scheme that achieves the Heisenberg scaling using
multi-mode $N00N$ states. We theoretically show that multi-mode $N00N$ states
can reach the Heisenberg scaling by examining both the Cram\'er-Rao bound and
the quantum Cram\'er-Rao bound. For experimental demonstration, we employ a
four-mode $2002$ state to estimate the average of two spatially distributed
phases, achieving a 2.74 dB sensitivity enhancement over the standard quantum
limit. We believe that utilizing multi-mode $N00N$ states for distributed
quantum sensing offers a promising approach for developing
entanglement-enhanced sensor networks.

</details>


### [856] [Solving Markov Chains with Analog Quantum Computing: The Fine Print](https://arxiv.org/abs/2508.02199)
*Ward van der Schoot,Niels M. P. Neumann*

Main category: quant-ph

TL;DR: 量子算法的实际应用需要更多关注。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的兴趣日益浓厚，提出的量子算法数量也在不断增加，但这些算法的实际适用性却大不相同，有的可以直接使用，有的则需要难以实现的黑盒预言。

Method: 为首个计算马尔可夫链平稳分布的模拟量子算法提供了类似的“细微差别”分析。

Result: 对马尔可夫链平稳分布的模拟量子算法进行了“细微差别”分析。 concludethat:More focus should be put on the practical applicability of quantum algorithms, either through a separate line of research, or through more attention when introducing the algorithm. (This is the same as the conclusion). The result is the analysis itself. The analysis shows that the practical applicability of the algorithm is limited.

Conclusion: 应将更多关注点放在量子算法的实际应用上，可以通过专门的研究领域或在介绍算法时给予更多关注。

Abstract: With a growing interest in quantum computing, the number of proposed quantum
algorithms grows as well. The practical applicability of these algorithms
differs: Some can be applied out-of-the-box, while others require black box
oracles, which can not always be easily implemented. One of the first works to
explicitly discuss these practical applicability aspects is by Aaronson
discussing the \textit{fine print} of the HHL quantum algorithm that solves
linear systems of equations. We extend this line of research by providing a
similar fine print for the first analog quantum algorithm that computes the
stationary distribution of Markov chains. We conclude that more focus should be
put on this practical applicability of quantum algorithms, either through a
separate line of research, or through more attention when introducing the
algorithm.

</details>


### [857] [Sum-frequency-based photon-number-resolving detector for telecom wavelengths](https://arxiv.org/abs/2508.02203)
*Silvia Cassina,Alex Pozzoli,Guglielmo Vesco,Marco Lamperti,Marco Marangoni,Alessia Allevi*

Main category: quant-ph

TL;DR: 利用低成本光子数分辨探测器和非线性光学相互作用在1.5μm波长下实现了高灵敏度，可用于量子通信。


<details>
  <summary>Details</summary>
Motivation: 量子通信领域对C波段波长和光子数分辨探测器的需求日益增长，以提高通信协议的安全性。

Method: 利用低成本光子数分辨探测器和非线性光学相互作用实现电信波长下的灵敏度。

Result: 成功实现了探测器，并利用其表征了1.5μm飞秒源的泊松性质。

Conclusion: 所提出的基于非线性光学相互作用的低成本光子数分辨探测器具有在电信波长下实现高灵敏度的潜力，可用于复杂的量子通信方案。

Abstract: The use of C-band wavelengths in the field of quantum communication has grown
significantly, driving the need for versatile detection solutions, especially
in the low intensity domain. Among the desirable features for such detectors,
photon-number-resolving (PNR) capability is particularly valuable, since it can
offer new possibilities for enhancing security of communication protocols. In
this paper, we present the implementation of a receiver that combines low-cost
PNR detectors with nonlinear optical interactions to achieve sensitivity at
telecom wavelengths. Specifically, we use this receiver to characterize the
Poissonian nature of a femtosecond source at 1.5 $\mu$m, produced via white
light continuum generation followed by a single-stage amplification process.
The obtained results encourage the exploitation of such a detector in more
complex schemes.

</details>


### [858] [Long-distance device-independent quantum key distribution with standard optics tools](https://arxiv.org/abs/2508.02262)
*Makoto Ishihara,Anthony Brendan,Wojciech Roga,Masahiro Takeoka*

Main category: quant-ph

TL;DR: 提出长距离DI-QKD协议，基于单光子干涉和经典后处理，通信距离优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有DI-QKD协议通信距离受限于漏洞无关贝尔不等式检验的限制。

Method: 基于单光子干涉的信令方案，并结合了经典的后处理方法。

Result: 通过数值优化计算了协议的密钥率，并证明了该实现方式在通信距离上优于现有协议。

Conclusion: 该研究提出了两种长距离设备无关量子密钥分发（DI-QKD）协议，并展示了其在通信距离上的优越性。

Abstract: Device-independent quantum key distribution (DI-QKD) enables
information-theoretically secure key distribution between remote parties
without any assumptions on the internal workings of the devices used for its
implementation. However, its communication distance is strictly limited since
the loophole-free Bell violation is required to guarantee its security.
Therefore, in this paper, we propose two long-distance DI-QKD protocols which
use a heralding scheme based on single-photon interference. Our protocols
consist of only standard quantum optics tools such as two-mode squeezed states,
displacement operations and on-off detectors, making the experimental
implementation feasible with current technology. We employ a classical
postprocessing method to enhance our protocols' robustness against experimental
imperfections. We calculate key rates of the protocols by numerical
optimization and show the supremacy of this implementation over existing
protocols in terms of communication distances.

</details>


### [859] [Measuring unitary invariants with the quantum switch](https://arxiv.org/abs/2508.02345)
*Pedro C. Azado,Rafael Wagner,Rui S. Barbosa,Ernesto F. Galvão*

Main category: quant-ph

TL;DR: Bargmann不变量完全表征酉不变属性。量子开关可用于测量Bargmann不变量，而Hadamard测试电路可模拟量子开关。


<details>
  <summary>Details</summary>
Motivation: Bargmann不变量，状态的多变量迹，可以完全表征任何酉不变属性的状态集。酉不变性使得诸如基无关相干性和虚性、非稳定性和上下文性等量子资源的描述成为可能。

Method: 本研究表明，量子开关（一种具有不确定因果顺序的高阶过程）可用于测量任意阶的Bargmann不变量。此外，还展示了简单的Hadamard测试电路如何确定性地模拟任意酉量子开关。

Result: 量子开关可用于测量任意阶的Bargmann不变量，并且可以通过简单的Hadamard测试电路模拟。这在酉不变理论和高阶图之间建立了联系。

Conclusion: Bargmann不变量，状态的多变量迹，可以完全表征任何酉不变属性的状态集。酉不变性使得诸如基无关相干性和虚性、非稳定性和上下文性等量子资源的描述成为可能。我们表明，量子开关（一种具有不确定因果顺序的高阶过程）可用于测量任意阶的Bargmann不变量。我们还展示了简单的Hadamard测试电路如何确定性地模拟任意酉量子开关。我们的研究结果在酉不变理论和应用与量子力学中的高阶图之间建立了坚实的桥梁。

Abstract: Bargmann invariants, multivariate traces of states, completely characterize
any unitary-invariant property of a set of states. Unitary invariants enable
the description of quantum resources such as basis-independent coherence and
imaginarity, nonstabilizerness, and contextuality. We show that the quantum
switch, a higher-order process featuring indefinite causal order, can be used
to measure Bargmann invariants of arbitrary order. We also show how simple
Hadamard test circuits can deterministically simulate an arbitrary unitary
quantum switch. Our results establish a solid bridge between the theory and
applications of unitary invariants and higher-order maps in quantum mechanics.

</details>


### [860] [Microscopic Theory of Heat Transfer across a Vacuum](https://arxiv.org/abs/2508.02351)
*Yue-Hui Zhou,Jie-Qiao Liao*

Main category: quant-ph

TL;DR: 本研究建立了真空中声子热传递的微观理论，并获得了控制热传递效应的有效哈密顿量，揭示了声子交换相互作用与腔长度的关系，对热管理和腔光力学有重要意义。


<details>
  <summary>Details</summary>
Motivation: 为了探索真空中声子热传递这一新机制的微观量子电动力学理论。

Method: 利用多模腔场框架，通过二阶有效哈密顿量来描述声子热传递效应。

Result: 获得了描述声子交换相互作用的二阶有效哈密顿量，该相互作用强度与多模因子和腔长度的立方成反比。同时，也证实了模式温度和热通量与腔长度的关系，与镜子的热稳态相对应。

Conclusion: 本研究建立了真空中声子热传递的非相对论微观理论，并获得了控制热传递效应的二阶有效哈密顿量，该哈密顿量揭示了声子交换相互作用与腔长度的关系，并验证了模式温度和热通量与腔长度的关系，为热管理和腔光力学奠定了基础。

Abstract: Heat transfer is a fundamental concept in physics, and how to characterize
the microscopical physical mechanism of heat transfer is a significant topic.
Recently, a new mechanism for heat transfer, phonon heat transfer across a
vacuum through quantum fluctuations, has been experimentally demonstrated in a
two-vibrating-membrane system. However, a microscopic quantum electrodynamics
theory behind this phenomenon remains unexplored. Here, we establish the
nonrelativistic microscopic theory of phonon heat transfer across a vacuum
confined by two movable end mirrors of a one-dimensional optomechanical cavity.
Under the multimode-cavity-field framework, we obtain a second-order effective
Hamiltonian governing the heat transfer effect. This Hamiltonian describes a
phonon-exchange interaction between the two mirrors with a strength
proportional to a multimode factor and $l_{0}^{-3}$, where $l_{0}$ is the rest
cavity length. We also confirm the dependence of the mode temperatures and heat
flux on the rest cavity length, corresponding to the thermal steady state of
the mirrors. This work initiates the microscopic investigation of
thermodynamics based on the optomechanical cavity platform, and will have
profound implications for both thermal management in nanoscale devices and
cavity optomechanics.

</details>


### [861] [Designing lattice proteins with variational quantum algorithms](https://arxiv.org/abs/2508.02369)
*Hanna Linn,Lucas Knuthson,Anders Irbäck,Sandipan Mohanty,Laura García-Álvarez,Göran Johansson*

Main category: quant-ph

TL;DR: 研究了量子算法在蛋白质设计中的应用，发现与问题无关的量子电路在模拟中表现更好，但在真实设备上存在挑战。


<details>
  <summary>Details</summary>
Motivation: 研究了变压量子算法在解决蛋白质设计问题的第一步（寻找最小化能量的序列）中的应用。

Method: 测试了用于序列优化任务的变压量子算法，包括量子近似优化算法及其变体，以及硬件高效的ansatz。

Result: 量子近似优化算法在噪声模拟中的性能下降，而硬件高效的ansatz在模拟中表现更好，但在真实设备上性能下降。

Conclusion: 尽管在模拟中观察到使用与问题无关的量子电路可以提高性能，但在真实量子设备上运行时，由于模拟噪声模型未捕获的特征（如硬件噪声的时间方面），结果会变差。

Abstract: Quantum heuristics have shown promise in solving various optimization
problems, including lattice protein folding. Equally relevant is the inverse
problem, protein design, where one seeks sequences that fold to a given target
structure. The latter problem is often split into two steps: (i) searching for
sequences that minimize the energy in the target structure, and (ii) testing
whether the generated sequences fold to the desired structure. Here, we
investigate the utility of variational quantum algorithms for the first of
these two steps on today's noisy intermediate-scale quantum devices. We focus
on the sequence optimization task, which is less resource-demanding than
folding computations. We test the quantum approximate optimization algorithm
and variants of it, with problem-informed quantum circuits, as well as the
hardware-efficient ansatz, with problem-agnostic quantum circuits. While the
former algorithms yield acceptable results in noiseless simulations, their
performance drops under noise. With the problem-agnostic circuits, which are
more compatible with hardware constraints, an improved performance is observed
in both noisy and noiseless simulations. However, the results deteriorate when
running on a real quantum device. We attribute this discrepancy to features not
captured by the simulated noise model, such as the temporal aspect of the
hardware noise.

</details>


### [862] [Prepare-and-measure and entanglement simulation beyond qubits](https://arxiv.org/abs/2508.02377)
*Mani Zartab,Giulio Gasbarri,Gael Sentís,Ramon Muñoz-Tapia*

Main category: quant-ph

TL;DR: 该研究提出了一种新的经典协议，可以模拟量子关联。该协议在二维系统中表现完美，在更高维度系统中也表现出色，为理解和模拟量子现象提供了新的方法。


<details>
  <summary>Details</summary>
Motivation: 探索在允许有限经典通讯的情况下，更高维度（d>2）系统是否仍能模拟量子关联，以及在d=2时精确经典协议的关键特征。

Method: 通过识别d=2经典协议的关键特征，构建更高维度的近似协议，并利用随机化数值研究和总变分距离评估其性能。

Result: 所提出的近似协议在d=2时精确模拟量子概率分布，在更高维度时表现稳健且优于现有协议，提供了对更高维度经典协议解析结构的新的见解。

Conclusion: 本研究通过识别二维系统（d=2）中经典协议的关键特征，并在更高维度中构建稳健的近似协议，为模拟量子关联提供了新的视角。研究结果表明，该方法在d=2时能精确重现量子概率分布，在更高维度时表现优于现有协议，成为所研究案例中最稳健的协议。

Abstract: For two non-communicating parties, quantum theory can give rise to
probability distributions of outcomes that cannot be reproduced by any local
classical model without communication. However, in the case of two-dimensional
systems ($d=2$), it is known that allowing a finite amount of classical
communication to shared classical resources makes it possible to simulate these
quantum correlations. Whether such a simulation remains possible in higher
dimensions is still an open question. In this work, we identify the key
features of the exact classical protocol in $d=2$, and use them to construct
robust approximate protocols in higher dimensions. We assess their performance
through a randomized numerical study based on the Total Variation Distance. Our
approach exactly reproduces the quantum probability distributions for $d=2$,
and performs very well compared to existing protocols for higher dimensions,
being the most robust protocol in all cases studied. These results offer new
insights into the analytical structure of classical protocols in higher
dimensions.

</details>


### [863] [Superior resilience to poisoning and amenability to unlearning in quantum machine learning](https://arxiv.org/abs/2508.02422)
*Yu-Qin Chen,Shi-Xin Zhang*

Main category: quant-ph

TL;DR: 本研究通过比较经典和量子神经网络对数据损坏的响应，发现量子模型在韧性和适应性方面优于经典模型，并提出了量子机器学习在未来人工智能中的应用前景。


<details>
  <summary>Details</summary>
Motivation: 人工智能的可靠性依赖于其训练数据的完整性，而这些数据在实践中常常会受到噪声和损坏的影响。

Method: 通过在经典和量子数据集上，对经典和量子神经网络进行比较研究，揭示了它们在响应数据损坏方面的基本差异。

Result: 经典模型表现出脆弱的记忆化，导致泛化能力失败。相比之下，量子模型展现出卓越的韧性，在面对不断增加的标签噪声时表现出类似相变的响应，揭示了一个关键点，超过该点模型的性能会发生质的变化。研究还发现，经典模型在遗忘错误数据方面具有僵化、顽固的记忆，这使得高效学习变得困难，而量子模型则更容易通过近似学习方法实现高效遗忘。

Conclusion: 量子机器学习在鲁棒性和适应性方面具有双重优势，为未来可信赖、强大的通用人工智能提供了有前景的范例。

Abstract: The reliability of artificial intelligence hinges on the integrity of its
training data, a foundation often compromised by noise and corruption. Here,
through a comparative study of classical and quantum neural networks on both
classical and quantum data, we reveal a fundamental difference in their
response to data corruption. We find that classical models exhibit brittle
memorization, leading to a failure in generalization. In contrast, quantum
models demonstrate remarkable resilience, which is underscored by a phase
transition-like response to increasing label noise, revealing a critical point
beyond which the model's performance changes qualitatively. We further
establish and investigate the field of quantum machine unlearning, the process
of efficiently forcing a trained model to forget corrupting influences. We show
that the brittle nature of the classical model forms rigid, stubborn memories
of erroneous data, making efficient unlearning challenging, while the quantum
model is significantly more amenable to efficient forgetting with approximate
unlearning methods. Our findings establish that quantum machine learning can
possess a dual advantage of intrinsic resilience and efficient adaptability,
providing a promising paradigm for the trustworthy and robust artificial
intelligence of the future.

</details>


### [864] [Quantum Convolutional Neural Network with Nonlinear Effects and Barren Plateau Mitigation](https://arxiv.org/abs/2508.02459)
*Pei-Kun Yang*

Main category: quant-ph

TL;DR: 提出了一种新的QCNN架构，解决了QNN的非线性缺失和the barren plateau问题，并在MNIST和Fashion-MNIST上取得了高精度，为实际QNN铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子神经网络（QNN）在扩展性和缺乏内置非线性操作以及 the barren plateau 现象方面的挑战。

Method: 提出了一种量子卷积神经网络（QCNN）架构，通过正交基展开的幂级数引入非线性，通过直接参数化酉矩阵缓解 the barren plateau 现象，并结合了量子卷积核和步幅。

Result: 在MNIST和Fashion-MNIST数据集上实现了99.0%和88.0%的测试准确率，并通过PyTorch和Qiskit的模拟验证了模型的物理保真度。

Conclusion: 该研究提出了一个量子卷积神经网络（QCNN）架构，该架构通过引入正交基展开的幂级数来解决内置非线性操作缺失的问题，并通过直接参数化酉矩阵来缓解 the barren plateau 现象，实验结果在MNIST和Fashion-MNIST数据集上分别达到了99.0%和88.0%的测试准确率，验证了其灵活性和有效性，为实际和富有表现力的QNN铺平了道路。

Abstract: Quantum neural networks (QNNs) leverage quantum entanglement and
superposition to enable large-scale parallel linear computation, offering a
potential solution to the scalability limits of classical deep learning.
However, their practical deployment is hampered by two key challenges: the lack
of intrinsic nonlinear operations and the barren plateau phenomenon. We propose
a quantum convolutional neural network (QCNN) architecture that simultaneously
addresses both issues. Nonlinear effects are introduced via orthonormal basis
expansions of power series, while barren plateaus are mitigated by directly
parameterizing unitary matrices rather than stacking multiple parameterized
gates. Our design further incorporates quantum analogs of convolutional kernels
and strides for scalable circuit construction. Experiments on MNIST and
Fashion-MNIST datasets achieve 99.0% and 88.0% test accuracy, respectively.
Consistency between PyTorch-based matrix simulation and Qiskit-based quantum
circuit simulation validates the physical fidelity of the model. These results
demonstrate a flexible and effective quantum architecture that faithfully
integrates classical convolutional mechanisms into a quantum framework, paving
the way for practical and expressive QNNs.

</details>


### [865] [An equivalence between time-symmetry and cyclic causality in quantum theory](https://arxiv.org/abs/2508.02463)
*Eliot Jean,Ralph Silva,V. Vilasini*

Main category: quant-ph

TL;DR: 该研究在量子力学领域取得了重要进展，建立了时间对称性（MTS）与循环因果关系（P-CTC）之间的操作对等性。通过将P-CTC框架扩展并证明了与MTS的显式映射关系，该研究为理解量子因果关系提供了新的视角，并为未来的量子信息研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 理解物理定律的时间对称性与因果关系方向性之间的关系是量子基础的核心问题。尽管MTS和P-CTC之间存在结构联系，但其操作对等性尚不明确。

Method: 通过将后选择的闭合类时曲线（P-CTC）框架扩展到时间标记的P-CTC辅助梳，并证明了其与多时间状态（MTS）形式主义的对等性，以及通过明确的映射进行转换。

Result: 证明了对于任何MTS，都存在一个操作上等价的时间标记P-CTC辅助梳，反之亦然。研究还探讨了MTS的资源理论视角，并定义了一个在不使用P-CTC的自由变换下的偏序关系。

Conclusion: 该研究建立了时间对称性与循环因果关系之间的操作对等性，为未来研究提供了方向。

Abstract: Understanding the relationship between the time-symmetric nature of physical
laws and the apparent directionality of causality is a central question in
quantum foundations. The standard operational formulation, widely used in
quantum information, imposes a definite, acyclic causal order on agents'
operations, contrasting with time-symmetric dynamics. Two prominent extensions
of this framework are the multi-time state (MTS) formalism, which incorporates
time symmetry via arbitrary pre- and post-selection, and the post-selected
closed timelike curve (P-CTC) framework, which enables cyclic causal influences
through post-selection on maximally entangled states. While prior work has
noted structural connections between MTS and P-CTCs, it remained unclear
whether an operational equivalence exists, or whether constructive mappings can
be established between their most general objects. In this work, we address
this gap by extending the P-CTC framework to define time-labelled P-CTC
assisted combs, a more general class of P-CTC-assisted objects that support
open processing slots and explicit temporal structure. We prove that for every
(possibly mixed) MTS, there exists an operationally equivalent time-labelled
P-CTC-assisted comb, and vice versa. The equivalence is shown via explicit
mappings, while discussing the number and dimensionality of the P-CTCs
involved. We also explore a resource-theoretic view of MTS, defining a partial
order under free transformations that do not use P-CTCs. We conclude by
discussing future directions informed by the operational equivalence between
time symmetry and cyclic causality established here.

</details>


### [866] [Measuring the dynamics of an XXZ quantum simulator and controlling collapse through symmetries](https://arxiv.org/abs/2508.02468)
*D. J. Papoular*

Main category: quant-ph

TL;DR: This paper theoretically studies quantum simulation of a high-symmetry spin Hamiltonian (D6h). It maps the system to fermions, analyzes symmetry effects on measurement probabilities, identifies four evolution regimes (constant, sinusoidal, aperiodic, collapse), and proposes an experimental method using quantum parallelism to study them.


<details>
  <summary>Details</summary>
Motivation: The motivation is to theoretically consider the quantum simulation of a spin Hamiltonian with high spatial symmetry (D6h) and understand how symmetry affects the system's behavior, specifically the probability distribution of measurement outcomes during time evolution. The research aims to identify different evolution regimes and propose an efficient experimental method to probe them.

Method: The paper uses theoretical analysis, mapping the spin Hamiltonian to an effective fermionic Hamiltonian and identifying its symmetry group. It then analyzes the impact of symmetry on the probability distribution of measurement outcomes by comparing different initial states evolving under Heisenberg or XXZ Hamiltonians.

Result: The paper identifies four different regimes for the time evolution of probabilities: constant, sinusoidal, aperiodic, and collapse. It shows that unresolved symmetries can make some configurations equiprobable for suitable initial states. It also proposes an experimental scheme to efficiently probe these regimes using quantum parallelism.

Conclusion: This paper theoretically considers the quantum simulation of a spin Hamiltonian with D6h symmetry. It maps the system to an effective fermionic Hamiltonian, analyzes its symmetry group, and studies the impact of symmetry on measurement outcomes for different initial states and Hamiltonians. The study reveals how unresolved symmetries can lead to equiprobable configurations for certain initial states and identifies four distinct time evolution regimes for probabilities (constant, sinusoidal, aperiodic, collapse). It also proposes an experimentally accessible scheme using quantum parallelism to efficiently probe these regimes.

Abstract: We theoretically consider the quantum simulation of a spin Hamiltonian whose
twelve sites are arranged in a planar configuration with high spatial symmetry,
$D_{6h}$. We map the system onto an effective fermionic Hamiltonian and
identify its symmetry group. Comparing different initial states evolving under
the Heisenberg or XXZ Hamiltonians, we analyze the impact of symmetry on the
probability distribution for the outcomes of a measurement in a given basis, as
a function of the evolution time. The considered measurement basis resolves
only a part of the symmetries of the Hamiltonian. We show that, for suitable
choices of the initial state, unresolved symmetries make some configurations
equiprobable. We identify four different regimes for the time evolution of the
probabilities: these may be constant, vary sinusoidally in time, evolve
aperiodically, or collapse. We propose an experimentally accessible scheme
which exploits quantum parallelism to probe these regimes efficiently.

</details>


### [867] [Co-designed reflective and leaky-waveguide low-pass filter for superconducting circuits](https://arxiv.org/abs/2508.02475)
*Linus Andersson,Benjamin Olsson,Simone Gasparinetti,Robert Rehammar*

Main category: quant-ph

TL;DR: 提出了一种用于超导量子计算的阶梯阻抗低通滤波器，该滤波器具有低插入损耗和高频强衰减的特性。通过差分进化算法优化设计，并使用矢量网络分析仪对原型进行了测试，结果表明滤波器性能优异。


<details>
  <summary>Details</summary>
Motivation: 提出了一种集成了空心波导吸收器的阶梯阻抗低通滤波器，它结合了通带低插入损耗和高频强衰减的特点，非常适合超导量子计算应用，因为量子比特对近带和远带外辐射都很敏感。

Method: 采用差分进化算法，对插值后的电磁模拟数据进行优化，以获得最优尺寸。然后，使用校准的矢量网络分析仪对制造的原型进行表征，最高频率可达 67 GHz。

Result: 测量结果证实，3 dB截止频率为 13.5 GHz，8 GHz以下频率的插入损耗低于 0.45 dB，17.3 GHz以上频率的抑制超过 52.7 dB。

Conclusion: 该设计提供了一种紧凑、低损耗的解决方案，可用于近带滤波和抑制低温量子系统中产生准粒子的辐射。

Abstract: A stepped-impedance low-pass filter with integrated hollow waveguide
absorbers is presented. The filter combines low insertion loss in the passband
with strong attenuation at high frequencies, making it well suited for
superconducting quantum computing applications, where qubits are sensitive to
both near-band and far out-of-band radiation. The structure is implemented in a
rectangular coaxial geometry, with inductive sections coupled to circular
hollow waveguides oriented orthogonally to the transmission axis. Above their
cutoff frequency, these waveguides efficiently couple to radiation inside the
stepped-impedance filter, absorbing energy that would otherwise cause Cooper
pair breaking in conventional superconductors. Optimal dimensions were obtained
using a differential evolution algorithm applied to interpolated
electromagnetic simulation data. A prototype was fabricated and characterized
using a calibrated vector network analyzer up to 67 GHz. Measurements confirm a
3 dB cutoff frequency at 13.5 GHz, insertion loss below 0.45 dB for frequencies
under 8 GHz, and more than 52.7 dB rejection above 17.3 GHz. The design offers
a compact, low-loss solution for near-band filtering and suppression of
quasiparticle-generating radiation in cryogenic quantum systems.

</details>


### [868] [Forrelation is Extremally Hard](https://arxiv.org/abs/2508.02514)
*Uma Girish,Rocco Servedio*

Main category: quant-ph

TL;DR: 本研究从线性代数角度分析了Forrelation问题，发现其在区分正负相关性时，量子算法仅需一次查询，而经典算法则需要指数级查询。


<details>
  <summary>Details</summary>
Motivation: Forrelation问题是展示量子和经典能力之间指数级分离的一个核心问题。本研究旨在提供一个不同于以往解析方法的线性代数视角来解决这个问题，并量化其在区分极端情况下的量子优越性。

Method: 本研究采用线性代数方法，将Forrelation问题与Bent布尔函数联系起来，并分析了区分极端Forrelation实例（$\mathrm{forr}(f,g)=1$和$\mathrm{forr}(f,g)=-1$）的问题。通过分析，证明了一次量子查询足以解决该问题，而经典随机查询则需要指数级的时间。

Result: 该研究表明，区分极端Forrelation实例（$\mathrm{forr}(f,g)=1$和$\mathrm{forr}(f,g)=-1$）的问题，一次量子查询即可完美解决，而经典随机算法则需要至少$\\tilde{\Omega}(2^{n/4})$次查询。此外，对于由小型经典电路计算的输入，在密码学假设下也证明了其经典困难性。

Conclusion: 本论文提供了一个关于Forrelation问题的新的线性代数视角，并建立了其与Bent布尔函数之间的联系，从而分析了一个极端的Forrelation问题，即区分$\mathrm{forr}(f,g)=1$和$\mathrm{forr}(f,g)=-1$的实例。研究表明，这个问题可以通过一次量子查询和一的成功概率来解决，而经典的随机查询则需要$\\tilde{\Omega}(2^{n/4})$次查询，即使允许三分之一的失败概率。此外，论文还研究了输入$f,g$可由小型经典电路计算的受限变体，并在密码学假设下证明了其经典困难性。

Abstract: The Forrelation problem is a central problem that demonstrates an exponential
separation between quantum and classical capabilities. In this problem, given
query access to $n$-bit Boolean functions $f$ and $g$, the goal is to estimate
the Forrelation function $\mathrm{forr}(f,g)$, which measures the correlation
between $g$ and the Fourier transform of $f$.
  In this work we provide a new linear algebraic perspective on the Forrelation
problem, as opposed to prior analytic approaches. We establish a connection
between the Forrelation problem and bent Boolean functions and through this
connection, analyze an extremal version of the Forrelation problem where the
goal is to distinguish between extremal instances of Forrelation, namely
$(f,g)$ with $\mathrm{forr}(f,g)=1$ and $\mathrm{forr}(f,g)=-1$.
  We show that this problem can be solved with one quantum query and success
probability one, yet requires $\tilde{\Omega}\left(2^{n/4}\right)$ classical
randomized queries, even for algorithms with a one-third failure probability,
highlighting the remarkable power of one exact quantum query. We also study a
restricted variant of this problem where the inputs $f,g$ are computable by
small classical circuits and show classical hardness under cryptographic
assumptions.

</details>


### [869] [Diverging conditional correlation lengths in the approach to high temperature](https://arxiv.org/abs/2508.02567)
*Jerome Lloyd,Dmitry A. Abanin,Sarang Gopalakrishnan*

Main category: quant-ph

TL;DR: 马尔可夫长度在经典随机动力学中也会发散，并且与系统加热时的非吉布斯行为和父哈密顿量的发散范围有关。


<details>
  <summary>Details</summary>
Motivation: 研究马尔可夫长度在量子混合态相变中的信息论诊断作用，并探究其在经典随机动力学中的行为。

Method: 提出了一种基于矩阵乘积态的计算马尔可夫长度的数值技术。

Result: 马尔可夫长度在经典随机动力学中也会发散，并且与加热过程中的非吉布斯行为和父哈密顿量的发散范围有关。在经典伊辛模型中，马尔可夫长度随时间呈指数增长。

Conclusion: Markov长度在经典随机动力学中也会发散，并且其增长与系统加热时的非吉布斯行为和父哈密顿量的发散范围有关。

Abstract: The Markov length was recently proposed as an information-theoretic
diagnostic for quantum mixed-state phase transitions [Sang & Hsieh, Phys. Rev.
Lett. 134, 070403 (2025)]. Here, we show that the Markov length diverges even
under classical stochastic dynamics, when a low-temperature ordered state is
quenched into the high temperature phase. Conventional observables do not
exhibit growing length scales upon quenching into the high-temperature phase;
however, the Markov length grows exponentially in time. Consequently, the state
of a system as it heats becomes increasingly non-Gibbsian, and the range of its
putative "parent Hamiltonian" must diverge with the Markov length. From this
information-theoretic point of view the late-time limit of thermalization is
singular. We introduce a numerical technique for computing the Markov length
based on matrix-product states, and explore its dynamics under general thermal
quenches in the one-dimensional classical Ising model. For all cases, we
provide simple information-theoretic arguments that explain our results.

</details>


### [870] [Quantum chemistry with provable convergence via randomized sample-based quantum diagonalization](https://arxiv.org/abs/2508.02578)
*Samuele Piccinelli,Alberto Baiardi,Max Rossmannek,Almudena Carrera Vazquez,Francesco Tacchino,Stefano Mensa,Edoardo Altamura,Ali Alavi,Mario Motta,Javier Robledo-Moreno,William Kirby,Kunal Sharma,Antonio Mezzacapo,Ivano Tavernelli*

Main category: quant-ph

TL;DR: 本研究提出了一种名为SqDRIFT的新型量子算法，它结合了SKQD和qDRIFT技术，能够更有效地在当前的量子计算机上计算复杂分子的基态能量，其能力超越了传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有SKQD算法在用于模拟复杂的许多体哈密顿量（如分子电子结构哈密顿量）时，受限于生成Krylov向量所需的时间演化电路的深度，这超出了当前量子处理器的能力。本研究旨在提出一种新的SQD变体，以克服这一限制。

Method: SqDRIFT结合了SKQD和哈密顿量传播子的qDRIFT随机编译。

Result: SqDRIFT算法能够成功应用于计算化学哈密顿量，并处理超出精确对角化能力范围的系统规模。

Conclusion: SqDRIFT使我们能够在实用规模的量子计算机上对化学哈密顿量进行样本量子对角化（SQD）计算，同时保留了SKQD的收敛保证。我们已将SqDRIFT应用于计算几个多环芳烃的电子基态能量，系统规模已超出精确对角化的能力范围。

Abstract: Sample-based quantum diagonalization (SQD) is a recently proposed algorithm
to approximate the ground-state wave function of many-body quantum systems on
near-term and early-fault-tolerant quantum devices. In SQD, the quantum
computer acts as a sampling engine that generates the subspace in which the
Hamiltonian is classically diagonalized. A recently proposed SQD variant,
Sample-based Krylov Quantum Diagonalization (SKQD), uses quantum Krylov states
as circuits from which samples are collected. Convergence guarantees can be
derived for SKQD under similar assumptions to those of quantum phase
estimation, provided that the ground-state wave function is concentrated, i.e.,
has support on a small subset of the full Hilbert space. Implementations of
SKQD on current utility-scale quantum computers are limited by the depth of
time-evolution circuits needed to generate Krylov vectors. For many complex
many-body Hamiltonians of interest, such as the molecular electronic-structure
Hamiltonian, this depth exceeds the capability of state-of-the-art quantum
processors. In this work, we introduce a new SQD variant that combines SKQD
with the qDRIFT randomized compilation of the Hamiltonian propagator. The
resulting algorithm, termed SqDRIFT, enables SQD calculations at the utility
scale on chemical Hamiltonians while preserving the convergence guarantees of
SKQD. We apply SqDRIFT to calculate the electronic ground-state energy of
several polycyclic aromatic hydrocarbons, up to system sizes beyond the reach
of exact diagonalization.

</details>


### [871] [Learning Feasible Quantum States for Quadratic Constrained Binary Optimization Problems](https://arxiv.org/abs/2508.02590)
*Anthony Wilkie,Alexander DeLise,Andrew Del Real,Rebekah Herrman,James Ostrowski*

Main category: quant-ph

TL;DR: 提出一种基于标志量子比特的量子方法，用于生成满足QCBOs约束的量子态叠加，并作为量子优化算法的初始状态，以提高求解最优解的效率。


<details>
  <summary>Details</summary>
Motivation: 量子计算在解决QUBOs问题上表现优异，但解决QCBOs更具挑战性，需要新的方法来处理约束。

Method: 提出了一种利用标志量子比特识别约束条件的方法，来构建满足QCBOs约束的量子态的等量叠加。

Result: 在包含线性和二次约束的QCBOs问题上，该方法能够生成满足条件的量子态叠加，并且在作为GM-QAOA的初始状态时，显著提高了找到最优解的概率，平均AR达到0.98。

Conclusion: 该方法成功生成了满足约束的量子态叠加，并能作为量子优化算法的初始状态，有效提高了找到最优解的概率。

Abstract: Quantum computing approaches excel at solving quadratic unconstrained binary
optimization (QUBO) problems, however solving quadratic constrained binary
optimization problems (QCBOs) is more challenging. In this work, we develop a
variational approach that creates an equal superposition of quantum states that
satisfy constraints in a QCBO. The method relies on flag qubits, one per
constraint, to identify when a constraint is violated or not. The resulting
equal superposition can be used as an initial state for quantum algorithms that
solve QUBOs/QCBOs such as Grover's search algorithm or the quantum approximate
optimization algorithm (QAOA). We test the approach on sets of one and two
linear inequality constraints and find that it is able to generate an equal
superposition of feasible states with a .98 AR on average. We then use the
approach to generate initial states for Grover-mixer QAOA (GM-QAOA) and find
that GM-QAOA with the constraint gadgets yields significantly higher
probability of measuring the optimal solution than random guessing.

</details>


### [872] [Molecular Processes as Quantum Information Resources](https://arxiv.org/abs/2508.02597)
*Saikat Sur,Pritam Chattopadhyay,Gershon Kurizki*

Main category: quant-ph

TL;DR: 本文探讨了分子过程（如双原子离解和原子碰撞）作为量子信息资源的应用，展示了其产生纠缠和实现分子波包隐形传态的能力，并发现了与量子热力学相关的异常现象。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索分子过程作为量子信息资源的可能性，特别是利用同核双原子离解和原子-对碰撞过程来揭示和利用平移纠缠，以实现分子波包隐形传态，并研究这些过程所表现出的异常量子热力学特性。

Method: 研究利用同核双原子离解（半碰撞）和原子-对碰撞过程，在适当控制下，揭示了平移（EPR类）纠缠，并展示了分子波包隐形传态。当过程涉及双原子的电子状态激发时，离解后的荧光被用作纠缠的见证，以揭示分子态的特征和演化。研究还探讨了涉及纠缠过程的量子热力学特性，特别是空腔场与离解的纠缠双原子相互作用时温度的增强。

Result: 研究表明，同核双原子离解和原子-对碰撞过程能够产生平移（EPR类）纠缠，可用于分子波包隐形传态。电子状态激发过程中的荧光可作为纠缠的见证，揭示分子态特性。此外，纠缠过程能够导致空腔场温度的增强，展现出异常的量子热力学行为。

Conclusion: 该研究展示了分子过程作为量子信息资源的潜力，特别是同核双原子离解和原子-对碰撞过程可以揭示用于分子波包隐形传态的平移（EPR类）纠缠。通过涉及电子状态激发的双原子过程，离解后的荧光可以作为纠缠的见证，揭示分子态的特性和演化。此外，这些纠缠过程还表现出异常的量子热力学特性，例如空腔场与离解的纠缠双原子相互作用时温度的增强。

Abstract: In this contribution to Abraham Nitzan's Festschrift, we present a
perspective of theoretical research over the years that has pointed to the
potential of molecular processes to act as quantum information resources. Under
appropriate control, homonuclear dimer (diatom) dissociation (half-collision)
and the inverse process of atom-pair collisions are shown to reveal
translational (EPR-like) entanglement that enables molecular wavepacket
teleportation. When such processes involve electronic-state excitation of the
diatom, the fluorescence following dissociation can serve as an entanglement
witness that unravels the molecular-state characteristics and evolution. Such
entangling processes can also exhibit anomalous quantum thermodynamic features,
particularly temperature enhancement of a cavity field that interacts with
dissociated entangled diatoms.

</details>


### [873] [Work extraction from long-lived quantum coherence of a three-level system](https://arxiv.org/abs/2508.02614)
*Wenjing Chen,Si-Wei Han,Xiaoshan Feng,Jun Feng*

Main category: quant-ph

TL;DR: 这项研究利用三能级量子系统的量子相干性来提取功，并提出了一种优化协议，可以在单个热力学循环中最大化功的提取。


<details>
  <summary>Details</summary>
Motivation: 分析利用三能级量子系统的长寿命量子相干性进行功提取协议，识别产生持久量子相干性的情况。

Method: 通过设计涉及能量守恒酉运算的两种创新热力学协议，将量子相干性转化为布居不对称性，以此作为功提取的量子资源。

Result: 所提出的优化协议能够在单次热力学循环中从量子相干性中提取最大可提取功（MEW），其度量由自由能差（FED）决定。

Conclusion: 量子相干性在三能级量子系统中可以作为功提取的量子资源，并突出显示了长寿命相干性的热力学优势，这可能会影响相干驱动的量子热机未来的设计。

Abstract: We analyze work extraction protocols using the long-lived quantum coherence
of a three-level quantum system, which is coupled to a thermal bath through
dipole-monopole interactions. We identify situations where persistent quantum
coherence arises, i.e., for systems with degenerate excited states with aligned
transition dipoles or nearly degenerate systems with small energy splittings.
By designing two innovative thermodynamic protocols involving energy-preserving
unitary operations, we show that quantum coherence can be transformed into
population asymmetry, serving as a quantum resource for work extraction. As the
system approaches final thermal equilibrium, the initial quantum coherence
effectively acts as fuel, being progressively consumed. Specifically, we
propose an optimized protocol capable of extracting the maximal extractable
work (MEW), measured by the free energy difference (FED), from quantum
coherence in a single-shot thermodynamic cycle. Our results highlight the
thermodynamic advantages of long-lived coherence in a three-level quantum
system and could influence future designs of coherence-driven quantum thermal
machines.

</details>


### [874] [Anticipating Decoherence: a Predictive Framework for Enhancing Coherence in Quantum Emitters](https://arxiv.org/abs/2508.02638)
*Pranshu Maan,Yuheng Chen,Sean Borneman,Benjamin Lawrie,Alexander Puretzky,Hadiseh Alaeian,Alexandra Boltasseva,Vladimir M. Shalaev,Alexander V. Kildishev*

Main category: quant-ph

TL;DR: 该研究首次将预期系统和副本理论应用于量子技术，并开发了一种可通过机器学习预测量子发射器光谱行为的框架，以提高光学相干性。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展的固态量子平台，需要远程量子设备之间的光学相干性，这需要光谱的不可区分性。然而，环境的无序性会影响发射器的光谱并削弱相干性。

Method: 使用统计理论识别光谱扩散中的相关性，揭示了可扩展到其他疾病的预期动态。验证了机器学习模型可以准确预测未见过的光谱行为。

Result: 首次将预期系统和副本理论应用于量子技术，并首次证明了内部预测可以推广到多个量子发射器。

Conclusion: 通过将预测模型应用于不同的量子发射器，可以将光谱漂移减少 2.1 到 15.8 倍，具体取决于发射器的稳定性，而没有预测的情况下则不能。

Abstract: Large-scale quantum systems require optical coherence between distant quantum
devices, necessitating spectral indistinguishability. Scalable solid-state
platforms offer promising routes to this goal. However, environmental
disorders, including dephasing, spectral diffusion, and spin-bath interactions,
influence the emitters' spectra and deteriorate the coherence. Using
statistical theory, we identify correlations in spectral diffusion from slowly
varying environmental coupling, revealing predictable dynamics extendable to
other disorders. Importantly, this could enable the development of an
anticipatory framework for forecasting and decoherence engineering in remote
quantum emitters. To validate this framework, we demonstrate that a machine
learning model trained on limited data can accurately forecast unseen spectral
behavior. Realization of such a model on distinct quantum emitters could reduce
the spectral shift by factors $\approx$ 2.1 to 15.8, depending on emitter
stability, compared to no prediction. This work presents, for the first time,
the application of anticipatory systems and replica theory to quantum
technology, along with the first experimental demonstration of internal
prediction that generalizes across multiple quantum emitters. These results
pave the way for real-time decoherence engineering in scalable quantum systems.
Such capability could lead to enhanced optical coherence and multi-emitter
synchronization, with broad implications for quantum communication,
computation, imaging, and sensing.

</details>


### [875] [atommovr: An open-source simulation framework for rearrangement in atomic arrays](https://arxiv.org/abs/2508.02670)
*Nikhil K Harle,Bo-Yu Chen,Bob Bao,Hannes Bernien*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The task of atom rearrangement has emerged in the last decade as a
fundamental building block for the development of neutral atom-based quantum
processors. However, despite many recent efforts to develop algorithms with
favorable asymptotic scaling, no time-optimal algorithm has been developed for
any rearrangement task. Moreover, no open-source code exists to reproduce or
benchmark existing algorithms, and to assist the development of new
rearrangement protocols. To address this deficiency, we develop an open-source
simulation framework for developing, comparing, and benchmarking algorithms
under realistic and customizable noise models. Using this framework, we
\textbf{a)} numerically extract lower bounds for the scaling of a time-optimal
rearrangement algorithm and compare it to existing heuristic algorithms
\textbf{b)} develop a naive dual-species algorithm able to prepare arbitrary
targets with near-unity success rate. With this framework, we hope to develop a
common tool for the community to study rearrangement, lower the barrier to
entry for new experimental groups, and stimulate progress in developing
algorithms which approach time-optimal scaling.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [876] [Learned LSM-trees: Two Approaches Using Learned Bloom Filters](https://arxiv.org/abs/2508.00882)
*Nicholas Fidalgo,Puyuan Ye*

Main category: cs.DS

TL;DR: 本文提出两种方法优化LSM树的读操作：一种是使用分类器跳过不必要的布隆过滤器检查以降低延迟，另一种是用学习模型替换布隆过滤器以减少内存占用。实验结果表明，第一种方法可将延迟降低2.28倍，第二种方法可将内存占用减少70-80%。


<details>
  <summary>Details</summary>
Motivation: 现代键值存储严重依赖日志结构合并（LSM）树进行写优化，但这会导致显著的读放大。虽然布隆过滤器等辅助结构有所帮助，但它们会带来与树深度和数据集大小成比例的内存成本。本研究旨在通过集成学习型预测来解决这些问题。

Method: 本文探索了将学习型预测集成到LSM树查找路径中的两种方法：一种使用分类器来选择性地绕过不相关级别的布隆过滤器探测，另一种用紧凑的学习模型和小型备份过滤器替换传统的布隆过滤器。

Result: 实验表明，分类器通过高精度地跳过30%的布隆过滤器检查，将GET延迟最多降低了2.28倍，但存在适度的假阴性率。学习型布隆过滤器设计实现了零假阴性，并保持了基线延迟，同时将每个级别的内存使用量减少了70-80%。

Conclusion: 所提出的方法展示了在延迟、内存和正确性之间进行权衡的潜力，并强调了学习型索引组件在写优化的存储系统中的应用前景。

Abstract: Modern key-value stores rely heavily on Log-Structured Merge (LSM) trees for
write optimization, but this design introduces significant read amplification.
Auxiliary structures like Bloom filters help, but impose memory costs that
scale with tree depth and dataset size. Recent advances in learned data
structures suggest that machine learning models can augment or replace these
components, trading handcrafted heuristics for data-adaptive behavior. In this
work, we explore two approaches for integrating learned predictions into the
LSM-tree lookup path. The first uses a classifier to selectively bypass Bloom
filter probes for irrelevant levels, aiming to reduce average-case query
latency. The second replaces traditional Bloom filters with compact learned
models and small backup filters, targeting memory footprint reduction without
compromising correctness. We implement both methods atop a Monkey-style
LSM-tree with leveled compaction, per-level Bloom filters, and realistic
workloads. Our experiments show that the classifier reduces GET latency by up
to 2.28x by skipping over 30% of Bloom filter checks with high precision,
though it incurs a modest false-negative rate. The learned Bloom filter design
achieves zero false negatives and retains baseline latency while cutting memory
usage per level by 70-80%. Together, these designs illustrate complementary
trade-offs between latency, memory, and correctness, and highlight the
potential of learned index components in write-optimized storage systems.

</details>


### [877] [Efficient Direct-Access Ranked Retrieval](https://arxiv.org/abs/2508.01108)
*Mohsen Dehghankar,Raghav Mittal,Suraj Shetiya,Abolfazl Asudeh,Gautam Das*

Main category: cs.DS

TL;DR: 研究提出了用于数据检索的排序检索算法，解决了大规模和高维数据集的挑战，并证明了其在数据大小和维度上的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了应对不断发展的数据探索实践、大规模和高维数据集带来的挑战，研究了用于交互式数据工具的直接访问排序检索（DAR）问题，该问题旨在根据排序函数高效访问任意排序位置的元组，而无需枚举所有前面的元组。

Method: 提出了一种基于几何排列的算法，以及基于ε-抽样的第二类算法。为了解决恰好定位元组的挑战，引入了共形集排序检索（CSR）问题，并设计了一个用于窄范围查询的分层抽样数据结构来解决条带范围检索（SRR）问题。

Result: 基于几何排列的算法实现了对数查询时间，但空间复杂度高；基于ε-抽样的算法实现了线性空间复杂度，并能处理高维数据。实验证明了该方法在数据大小和维度上的可扩展性。

Conclusion: 该研究提出了一种基于几何排列的理论上高效的算法，实现了对数查询时间，但空间复杂度呈指数级增长；随后开发了基于ε-抽样的第二类算法，空间复杂度为线性，解决了恰好定位元组的挑战，并通过引入共形集排序检索（CSR）和条带范围检索（SRR）问题，设计了用于窄范围查询的分层抽样数据结构，证明了算法的近最优界限，并通过在真实和合成数据集上的大量实验验证了其在数据大小和维度上的实际可扩展性。

Abstract: We study the problem of Direct-Access Ranked Retrieval (DAR) for interactive
data tooling, where evolving data exploration practices, combined with
large-scale and high-dimensional datasets, create new challenges. DAR concerns
the problem of enabling efficient access to arbitrary rank positions according
to a ranking function, without enumerating all preceding tuples. To address
this need, we formalize the DAR problem and propose a theoretically efficient
algorithm based on geometric arrangements, achieving logarithmic query time.
However, this method suffers from exponential space complexity in high
dimensions. Therefore, we develop a second class of algorithms based on
$\varepsilon$-sampling, which consume a linear space. Since exactly locating
the tuple at a specific rank is challenging due to its connection to the range
counting problem, we introduce a relaxed variant called Conformal Set Ranked
Retrieval (CSR), which returns a small subset guaranteed to contain the target
tuple. To solve the CSR problem efficiently, we define an intermediate problem,
Stripe Range Retrieval (SRR), and design a hierarchical sampling data structure
tailored for narrow-range queries. Our method achieves practical scalability in
both data size and dimensionality. We prove near-optimal bounds on the
efficiency of our algorithms and validate their performance through extensive
experiments on real and synthetic datasets, demonstrating scalability to
millions of tuples and hundreds of dimensions.

</details>


### [878] [PageRank Centrality in Directed Graphs with Bounded In-Degree](https://arxiv.org/abs/2508.01257)
*Mikkel Thorup,Hanzhi Wang,Zhewei Wei,Mingji Yang*

Main category: cs.DS

TL;DR: 本研究提出了一个新的随机反向传播算法，用于高效地估计图中节点的PageRank中心度，解决了现有方法在入度较低时存在的复杂性差距问题。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在研究在有向图中局部估计节点PageRank中心度的计算复杂性。现有的最佳上界和下界之间存在差距，尤其是在入度（Δ_in）较小的情况下，差距会变得很大。

Method: 该论文的关键技术是一种新颖的随机反向传播过程，该过程仅基于蒙特卡洛估计的PageRank分数进行选择性传播。

Result: 该论文提出的新算法在对数因子（logarithmic factors）的意义上实现了PageRank估计的下界。

Conclusion: 该论文提出了一种新的算法，该算法在对数因子（logarithmic factors）的意义上实现了上述下界，该算法假设预先知道了节点数量n以及最大入度和最大出度（Δ_in 和 Δ_out）。

Abstract: We study the computational complexity of locally estimating a node's PageRank
centrality in a directed graph $G$. For any node $t$, its PageRank centrality
$\pi(t)$ is defined as the probability that a random walk in $G$, starting from
a uniformly chosen node, terminates at $t$, where each step terminates with a
constant probability $\alpha\in(0,1)$.
  To obtain a multiplicative $\big(1\pm O(1)\big)$-approximation of $\pi(t)$
with probability $\Omega(1)$, the previously best upper bound is
$O(n^{1/2}\min\{ \Delta_{in}^{1/2},\Delta_{out}^{1/2},m^{1/4}\})$ from [Wang,
Wei, Wen, Yang STOC '24], where $n$ and $m$ denote the number of nodes and
edges in $G$, and $\Delta_{in}$ and $\Delta_{out}$ upper bound the in-degrees
and out-degrees of $G$, respectively. The same paper implicitly gives the
previously best lower bound of
$\Omega(n^{1/2}\min\{\Delta_{in}^{1/2}/n^{\gamma},\Delta_{out}^{1/2}/n^{\gamma},m^{1/4}\})$,
where $\gamma=\frac{\log(1/(1-\alpha))}{4\log\Delta_{in}-2\log(1/(1-\alpha))}$
if $\Delta_{in}>1/(1-\alpha)$, and $\gamma=1/2$ if
$\Delta_{in}\le1/(1-\alpha)$. As $\gamma$ only depends on $\Delta_{in}$, the
known upper bound is tight if we only parameterize the complexity by $n$, $m$,
and $\Delta_{out}$. However, there remains a gap of $\Omega(n^{\gamma})$ when
considering $\Delta_{in}$, and this gap is large when $\Delta_{in}$ is small.
In the extreme case where $\Delta_{in}\le1/(1-\alpha)$, we have $\gamma=1/2$,
leading to a gap of $\Omega(n^{1/2})$ between the bounds $O(n^{1/2})$ and
$\Omega(1)$.
  In this paper, we present a new algorithm that achieves the above lower bound
(up to logarithmic factors). The algorithm assumes that $n$ and the bounds
$\Delta_{in}$ and $\Delta_{out}$ are known in advance. Our key technique is a
novel randomized backwards propagation process which only propagates
selectively based on Monte Carlo estimated PageRank scores.

</details>


### [879] [Towards Faster Feasible Matrix Multiplication by Trilinear Aggregation](https://arxiv.org/abs/2508.01748)
*Oded Schwartz,Eyal Zwecher*

Main category: cs.DS

TL;DR: 通过trilinear聚合和de Groote等价性优化，提出了一种新的矩阵乘法算法，复杂度达到O(n^2.773203)，优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 现有快速矩阵乘法算法仅适用于极大的矩阵，而本文旨在改进适用于实际输入规模的算法，并超越现有的快速矩阵乘法算法。

Method: 本文提出了一种新的矩阵乘法算法，该算法基于trilinear聚合方法，并利用de Groote等价性进行优化，同时通过稀疏分解和降低前导系数来提高加法复杂度。

Result: 该算法实现了O(n^2.773203)的复杂度，优于Pan的O(n^2.773372)算法，并且在n0=28开始的许多小基数情况下具有最佳的渐近复杂度。

Conclusion: 所提出的算法是第一个基于基数小于1000的矩阵乘法最快的算法，并且在较大的基数情况下也表现出更优的性能。

Abstract: Matrix multiplication is a fundamental kernel in high performance computing.
Many algorithms for fast matrix multiplication can only be applied to enormous
matrices ($n>10^{100}$) and thus cannot be used in practice. Of all algorithms
applicable to feasible input, Pan's $O(n^{2.773372})$ algorithm (1982) is
asymptotically the fastest. We obtain an $O(n^{2.773203})$ algorithm applicable
to the same input sizes as Pan's algorithm. This algorithm is the fastest
matrix multiplication algorithm with base case smaller than $1000$. Further,
our method obtains the best asymptotic complexity for many small base cases,
starting at $n_0=28$. We also obtain better exponents for larger base cases. To
construct our algorithm, we use the trilinear aggregation method. We find parts
of the algorithms that are equivalent to matrix multiplication with smaller
base case, and use the de Groote equivalence to replace these parts in a way
that allows further optimization of our algorithms. Finally, we improve the
additive complexity of our algorithms by finding a sparse decomposition and
reducing the leading coefficient. These mark a fundamental step towards
outperforming existing fast matrix multiplication algorithms in practice.

</details>


### [880] [Near-Optimal Differentially Private Graph Algorithms via the Multidimensional AboveThreshold Mechanism](https://arxiv.org/abs/2508.02182)
*Laxman Dhulipala,Monika Henzinger,George Z. Li,Quanquan C. Liu,A. R. Sricharan,Leqi Zhu*

Main category: cs.DS

TL;DR: 研究提出了多维阈值以上（MAT）机制，改进了差分隐私图算法。在k核分解、最密集子图等问题上取得了更好的界限，并在k核分解方面达到了渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 许多差分隐私和经典的非隐私图算法在确定每个顶点的某个属性是否满足阈值时，严重依赖于此。例如，在k核分解问题中，经典的剥离算法会迭代地移除其诱导度低于某个阈值的顶点。稀疏向量技术（SVT）通常用于将非私有的阈值查询转换为私有查询，同时仅以很小的加性精度损失为代价。然而，SVT在图中的直接应用会导致误差因子的n倍放大，因为SVT被应用于每个顶点。因此，本研究的动机是解决这个误差放大问题，提出一种更有效的SVT变体，以在保证差分隐私的前提下，更准确、更高效地解决图算法中的阈值查询问题。

Method: 本研究的核心方法是提出一种名为多维阈值以上（MAT）机制的新型广义稀疏向量技术（SVT）。该机制能够将SVT从处理单维向量推广到处理多维向量，从而解决了在图算法中应用SVT时因组合效应导致的误差因子为n的放大问题。研究人员将MAT机制应用于多种图问题，包括k核分解、最密集子图、低出度排序和顶点着色，并取得了改进的界限。具体而言，在k核分解问题上，他们提出了一种局部边差分隐私算法，具有$O(\	ext{epsilon}^{-1}\	ext{log} n)$的加性误差且无乘性误差，在$O(n)$轮中完成。此外，还提出了一种新的$(2+\	ext{eta})$-因子乘性、$O(\	ext{epsilon}^{-1}\	ext{log} n)$加性误差的算法，该算法在$O(\	ext{log}^2 n)$轮中完成。这些算法的性能达到了针对k核分解的$\	ext{Omega}(\	ext{log} n)$下界的渐近最优性。

Result: 本研究通过提出多维阈值以上（MAT）机制，成功解决了SVT在图算法中应用时的误差放大问题。研究在k核分解方面取得了以下成果：1. 提出了一个具有$O(\	ext{epsilon}^{-1}\	ext{log} n)$加性误差和无乘性误差的局部边差分隐私算法，该算法在$O(n)$轮内完成。2. 提出了一个具有$(2+\	ext{eta})$-因子乘性、$O(\	ext{epsilon}^{-1}\	ext{log} n)$加性误差的算法，该算法在$O(\	ext{log}^2 n)$轮内完成。这两个结果均达到了针对k核分解的$\	ext{Omega}(\	ext{log} n)$新下界的渐近最优性。此外，新的k核分解算法也直接改进了最密集子图和低出度排序问题的算法，并且提出了一种新的私有缺陷着色算法，其使用的颜色数量与图的森林度成正比。

Conclusion: 该研究提出了一种名为多维阈值以上（MAT）机制的新型广义稀疏向量技术（SVT），该机制将SVT推广到多维向量，解决了SVT在图设置中应用时因组合效应导致的误差放大问题。该机制在k核分解、最密集子图、低出度排序和顶点着色等图问题上取得了比先前工作更好的界限。特别是在k核分解方面，研究提出了一种具有$O(\	ext{epsilon}^{-1}\	ext{log} n)$加性误差和无乘性误差的局部边DP算法，以及一种具有$(2+\	ext{eta})$-因子乘性、$O(\	ext{epsilon}^{-1}\	ext{log} n)$加性误差的算法，这些结果都达到了针对k核分解的$\	ext{Omega}(\	ext{log} n)$新下界的渐近最优性。新的k核分解算法也直接促进了最密集子图和低出度排序问题的算法改进，并且提出了一种新的私有缺陷着色算法，其使用的颜色数量与图的森林度成正比。

Abstract: Many differentially private and classical non-private graph algorithms rely
crucially on determining whether some property of each vertex meets a
threshold. For example, for the $k$-core decomposition problem, the classic
peeling algorithm iteratively removes a vertex if its induced degree falls
below a threshold. The sparse vector technique (SVT) is generally used to
transform non-private threshold queries into private ones with only a small
additive loss in accuracy. However, a naive application of SVT in the graph
setting leads to an amplification of the error by a factor of $n$ due to
composition, as SVT is applied to every vertex. In this paper, we resolve this
problem by formulating a novel generalized sparse vector technique which we
call the Multidimensional AboveThreshold (MAT) Mechanism which generalizes SVT
(applied to vectors with one dimension) to vectors with multiple dimensions. As
an application, we solve a number of important graph problems with better
bounds than previous work.
  We apply our MAT mechanism to obtain a set of improved bounds for a variety
of problems including $k$-core decomposition, densest subgraph, low out-degree
ordering, and vertex coloring. We give a tight local edge DP algorithm for
$k$-core decomposition with $O(\epsilon^{-1}\log n)$ additive error and no
multiplicative error in $O(n)$ rounds. We also give a new $(2+\eta)$-factor
multiplicative, $O(\epsilon^{-1}\log n)$ additive error algorithm in $O(\log^2
n)$ rounds for any constant $\eta > 0$. Both of these results are
asymptotically tight against our new lower bound of $\Omega(\log n)$ for any
constant-factor approximation algorithm for $k$-core decomposition. Our new
algorithms for $k$-core also directly lead to new algorithms for densest
subgraph and low out-degree ordering. Our novel private defective coloring
algorithms uses number of colors proportional to the arboricity of the graph.

</details>


### [881] [Testing Quasiperiodicity](https://arxiv.org/abs/2508.02231)
*Christine Awofeso,Ben Bals,Oded Lachish,Solon P. Pissis*

Main category: cs.DS

TL;DR: 论文提出了一种高效的算法，用于检测字符串是否具有覆盖串，并可用于流式处理。


<details>
  <summary>Details</summary>
Motivation: 介绍覆盖串的概念，并指出该问题在组合模式匹配领域受到关注，旨在解决如何高效地测试字符串是否具有覆盖串的问题。

Method: 通过设计一个高效的测试算法来判断字符串S是否具有覆盖串。

Result: 提出了一种可行的算法，能够高效地测试字符串S是否具有覆盖串，并且该算法可以应用于流式计算场景。

Conclusion: 该论文提出了一种有效的测试字符串S是否具有覆盖串的方法，该方法还可以转化为流算法。

Abstract: A cover (or quasiperiod) of a string $S$ is a shorter string $C$ such that
every position of $S$ is contained in some occurrence of $C$ as a substring.
The notion of covers was introduced by Apostolico and Ehrenfeucht over 30 years
ago [Theor. Comput. Sci. 1993] and it has received significant attention from
the combinatorial pattern matching community. In this note, we show how to
efficiently test whether $S$ admits a cover. Our tester can also be translated
into a streaming algorithm.

</details>


### [882] [Facility Location and $k$-Median with Fair Outliers](https://arxiv.org/abs/2508.02572)
*Rajni Dabas,Samir Khuller,Emilie Rivkin*

Main category: cs.DS

TL;DR: 本研究解决了在选址和 k-中值问题中如何公平地处理异常值。我们提出了新的算法，在最小化成本的同时，确保每个群体允许一定数量的异常值，并证明了这些算法在理论上的近似保证和在实践中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的选址和 k-中值问题对异常值非常敏感。虽然允许排除少量异常值可以降低成本，但这可能导致某些群体被不成比例地排除，引发公平性问题。因此，本研究旨在解决“带公平异常值选址”和“带公平异常值 k-中值”问题，在最小化总成本的同时，确保每个群体允许的异常值数量得到满足，从而在成本效益和群体公平性之间取得平衡。

Method: 我们提出了一种解决“带公平异常值选址”和“带公平异常值 k-中值”问题的算法方法。对于前者，我们设计了一个双标准近似算法，其近似因子为 O(1/ε)，每组异常值的违反因子为 (1+2ε)。对于后者，我们设计了一个近似因子为 4(1+ω/ε)，每组异常值违反因子为 (ω+ε) 的双标准近似算法，改进了先前的工作，避免了异常值违反因子对 k 的依赖。我们还利用指数时间假设证明了这两个问题是 W[1]-难的，参数为 ω。最后，我们进行了详细的实证分析。

Result: 对于带公平异常值选址问题，我们提供了一个近似因子为 O(1/ε)，每组异常值违反因子为 (1+2ε) 的双标准近似算法。对于带公平异常值 k-中值问题，我们设计了一个近似因子为 4(1+ω/ε)，每组异常值违反因子为 (ω+ε) 的双标准近似算法，改进了先前的工作，避免了异常值违反因子对 k 的依赖。我们还证明了这些问题是 W[1]-难的（参数为 ω）。实证结果表明，在成本增加极少的情况下可以实现公平性，并且标准线性规划的整数差距在实践中很小。

Conclusion: 我们的算法为带公平异常值选址问题提供了一个双标准近似算法，其近似因子为 O(1/ε)，每组异常值的违反因子为 (1+2ε)。对于带公平异常值的 k-中值问题，我们设计了一个双标准近似算法，其近似因子为 4(1+ω/ε)，每组异常值的违反因子为 (ω+ε)，并且避免了异常值违反因子对 k 的依赖。此外，我们还证明了在假设指数时间假设的情况下，这些问题是 W[1]-难的，参数为 ω。我们的实证分析表明，在成本增加极少的情况下可以实现公平性，并且标准线性规划的整数差距在实践中很小。

Abstract: Classical clustering problems such as \emph{Facility Location} and
\emph{$k$-Median} aim to efficiently serve a set of clients from a subset of
facilities -- minimizing the total cost of facility openings and client
assignments in Facility Location, and minimizing assignment (service) cost
under a facility count constraint in $k$-Median. These problems are highly
sensitive to outliers, and therefore researchers have studied variants that
allow excluding a small number of clients as outliers to reduce cost. However,
in many real-world settings, clients belong to different demographic or
functional groups, and unconstrained outlier removal can disproportionately
exclude certain groups, raising fairness concerns.
  We study \emph{Facility Location with Fair Outliers}, where each group is
allowed a specified number of outliers, and the objective is to minimize total
cost while respecting group-wise fairness constraints. We present a bicriteria
approximation with a $O(1/\epsilon)$ approximation factor and $(1+ 2\epsilon)$
factor violation in outliers per group. For \emph{$k$-Median with Fair
Outliers}, we design a bicriteria approximation with a $4(1+\omega/\epsilon)$
approximation factor and $(\omega + \epsilon)$ violation in outliers per group
improving on prior work by avoiding dependence on $k$ in outlier violations. We
also prove that the problems are W[1]-hard parameterized by $\omega$, assuming
the Exponential Time Hypothesis.
  We complement our algorithmic contributions with a detailed empirical
analysis, demonstrating that fairness can be achieved with negligible increase
in cost and that the integrality gap of the standard LP is small in practice.

</details>


### [883] [Instance-Optimal Uniformity Testing and Tracking](https://arxiv.org/abs/2508.02637)
*Guy Blanc,Clément L. Canonne,Erik Waingarten*

Main category: cs.DS

TL;DR: 在均匀性测试中，我们提出了均匀性跟踪问题，并开发了一种多对数竞争算法，该算法利用了泊松混合物的新结构结果。


<details>
  <summary>Details</summary>
Motivation: 现有的均匀性测试算法在某些场景下可能表现不佳，其定义为基于预定距离的差距问题可能导致次优性能。

Method: 提出了一种新的均匀性跟踪问题，并开发了一种利用泊松混合物新结构结果的多对数竞争算法。

Result: 提出了一种多对数竞争的均匀性跟踪算法，该算法在利用泊松混合物的新结构结果方面取得了进展。

Conclusion: 该研究介绍了均匀性跟踪问题，并提出了一个多对数竞争的均匀性跟踪算法，该算法利用了关于泊松混合物的新结构结果。

Abstract: In the uniformity testing task, an algorithm is provided with samples from an
unknown probability distribution over a (known) finite domain, and must decide
whether it is the uniform distribution, or, alternatively, if its total
variation distance from uniform exceeds some input distance parameter. This
question has received a significant amount of interest and its complexity is,
by now, fully settled. Yet, we argue that it fails to capture many scenarios of
interest, and that its very definition as a gap problem in terms of a
prespecified distance may lead to suboptimal performance.
  To address these shortcomings, we introduce the problem of uniformity
tracking, whereby an algorithm is required to detect deviations from uniformity
(however they may manifest themselves) using as few samples as possible, and be
competitive against an optimal algorithm knowing the distribution profile in
hindsight. Our main contribution is a
$\operatorname{polylog}(\operatorname{opt})$-competitive uniformity tracking
algorithm. We obtain this result by leveraging new structural results on
Poisson mixtures, which we believe to be of independent interest.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [884] [ReCoSeg++:Extended Residual-Guided Cross-Modal Diffusion for Brain Tumor Segmentation](https://arxiv.org/abs/2508.01058)
*Sara Yavari,Rahul Nitin Pandya,Jacob Furst*

Main category: eess.IV

TL;DR: 提出了一种新的半监督、两阶段脑肿瘤分割框架，利用扩散模型进行跨模态合成和残差图提取，并通过 U-Net 结合多模态信息进行分割，在 BraTS 2021 数据集上取得了优异的分割性能。


<details>
  <summary>Details</summary>
Motivation: 准确分割 MRI 扫描中的脑肿瘤对于临床诊断和治疗规划至关重要。本研究旨在扩展现有方法以处理更大、更异构的数据集，同时减少对真实标签的依赖。

Method: 提出了一种半监督、两阶段框架，扩展了 ReCoSeg 方法以适应 BraTS 2021 数据集。第一阶段使用残差引导的扩散概率模型 (DDPM) 进行跨模态合成，从 FLAIR、T1 和 T2 扫描重建 T1ce 模态，并将重建的 T1ce 与真实的 T1ce 之间的残差图作为空间先验。第二阶段使用轻量级 U-Net，将残差图与 T1、T2 和 FLAIR 模态进行拼接，以改进全肿瘤分割。为处理 BraTS 2021 的数据规模和变异性，采用了切片级过滤和优化的阈值策略。

Result: 在 BraTS 2021 数据集上，针对全肿瘤分割，实现了 93.02% 的 Dice 分数和 86.7% 的 IoU。

Conclusion: 该方法在 BraTS 2021 数据集上实现了 93.02% 的 Dice 分数和 86.7% 的 IoU，优于 BraTS 2020 上的 ReCoSeg 基线（Dice：91.7%，IoU：85.3%），证明了其在真实多中心 MRI 数据集上的准确性和可扩展性。

Abstract: Accurate segmentation of brain tumors in MRI scans is critical for clinical
diagnosis and treatment planning. We propose a semi-supervised, two-stage
framework that extends the ReCoSeg approach to the larger and more
heterogeneous BraTS 2021 dataset, while eliminating the need for ground-truth
masks for the segmentation objective. In the first stage, a residual-guided
denoising diffusion probabilistic model (DDPM) performs cross-modal synthesis
by reconstructing the T1ce modality from FLAIR, T1, and T2 scans. The residual
maps, capturing differences between predicted and actual T1ce images, serve as
spatial priors to enhance downstream segmentation. In the second stage, a
lightweight U-Net takes as input the concatenation of residual maps, computed
as the difference between real T1ce and synthesized T1ce, with T1, T2, and
FLAIR modalities to improve whole tumor segmentation. To address the increased
scale and variability of BraTS 2021, we apply slice-level filtering to exclude
non-informative samples and optimize thresholding strategies to balance
precision and recall. Our method achieves a Dice score of $93.02\%$ and an IoU
of $86.7\%$ for whole tumor segmentation on the BraTS 2021 dataset,
outperforming the ReCoSeg baseline on BraTS 2020 (Dice: $91.7\%$, IoU:
$85.3\%$), and demonstrating improved accuracy and scalability for real-world,
multi-center MRI datasets.

</details>


### [885] [Mobile U-ViT: Revisiting large kernel and U-shaped ViT for efficient medical image segmentation](https://arxiv.org/abs/2508.01064)
*Fenghe Tang,Bingkun Nian,Jianrui Ding,Wenxin Ma,Quan Quan,Chengqi Dong,Jie Yang,Wei Liu,S. Kevin Zhou*

Main category: eess.IV

TL;DR: 提出了一种名为 Mobile U-ViT 的医学图像分割模型，该模型轻量级、高效，并在多项医学任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有针对自然图像优化的移动模型在医学图像分析任务上表现不佳，存在信息密度差异和计算效率的挑战，因此需要开发轻量级、通用且高性能的医学图像分析模型。

Method: 提出了一种名为 Mobile U-ViT 的模型，采用了 ConvUtr 作为分层 patch 嵌入，并设计了 LGL 块用于信息交换，结合了浅层 transformer 瓶颈和级联解码器，以适应医学图像分析的特点和移动设备的资源限制。

Result: Mobile U-ViT 在八个公开的 2D 和 3D 医学图像数据集上实现了最先进的性能，并在四个未见过的数据集上进行了零样本测试，证明了其高效、强大和泛化的能力。

Conclusion: Mobile U-ViT 是一种为医学图像分割设计的轻量级模型，它在保持计算效率的同时，在多个医学图像数据集上实现了最先进的性能，并表现出良好的泛化能力，是移动医疗图像分析的有效解决方案。

Abstract: In clinical practice, medical image analysis often requires efficient
execution on resource-constrained mobile devices. However, existing mobile
models-primarily optimized for natural images-tend to perform poorly on medical
tasks due to the significant information density gap between natural and
medical domains. Combining computational efficiency with medical
imaging-specific architectural advantages remains a challenge when developing
lightweight, universal, and high-performing networks. To address this, we
propose a mobile model called Mobile U-shaped Vision Transformer (Mobile U-ViT)
tailored for medical image segmentation. Specifically, we employ the newly
purposed ConvUtr as a hierarchical patch embedding, featuring a
parameter-efficient large-kernel CNN with inverted bottleneck fusion. This
design exhibits transformer-like representation learning capacity while being
lighter and faster. To enable efficient local-global information exchange, we
introduce a novel Large-kernel Local-Global-Local (LGL) block that effectively
balances the low information density and high-level semantic discrepancy of
medical images. Finally, we incorporate a shallow and lightweight transformer
bottleneck for long-range modeling and employ a cascaded decoder with
downsample skip connections for dense prediction. Despite its reduced
computational demands, our medical-optimized architecture achieves
state-of-the-art performance across eight public 2D and 3D datasets covering
diverse imaging modalities, including zero-shot testing on four unseen
datasets. These results establish it as an efficient yet powerful and
generalization solution for mobile medical image analysis. Code is available at
https://github.com/FengheTan9/Mobile-U-ViT.

</details>
